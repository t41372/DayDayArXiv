[
  {
    "arxiv_id": "2403.00196v1",
    "title": "Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras",
    "authors": [
      "Mathias Viborg Andersen",
      "Ross Greer",
      "Andreas MÃ¸gelmose",
      "Mohan Trivedi"
    ],
    "abstract": "Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on\naccurate driver perception within the vehicle cabin, often leveraging a\ncombination of sensing modalities. However, these modalities operate at varying\nrates, posing challenges for real-time, comprehensive driver state monitoring.\nThis paper addresses the issue of missing data due to sensor frame rate\nmismatches, introducing a generative model approach to create synthetic yet\nrealistic thermal imagery. We propose using conditional generative adversarial\nnetworks (cGANs), specifically comparing the pix2pix and CycleGAN\narchitectures. Experimental results demonstrate that pix2pix outperforms\nCycleGAN, and utilizing multi-view input styles, especially stacked views,\nenhances the accuracy of thermal image generation. Moreover, the study\nevaluates the model's generalizability across different subjects, revealing the\nimportance of individualized training for optimal performance. The findings\nsuggest the potential of generative models in addressing missing frames,\nadvancing driver state monitoring for intelligent vehicles, and underscoring\nthe need for continued research in model generalization and customization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00196v1",
    "published_date": "2024-02-29 23:52:15 UTC",
    "updated_date": "2024-02-29 23:52:15 UTC"
  },
  {
    "arxiv_id": "2403.00190v1",
    "title": "Identification of important nodes in the information propagation network based on the artificial intelligence method",
    "authors": [
      "Bin Yuan",
      "Tianbo Song",
      "Jerry Yao"
    ],
    "abstract": "This study presents an integrated approach for identifying key nodes in\ninformation propagation networks using advanced artificial intelligence\nmethods. We introduce a novel technique that combines the Decision-making Trial\nand Evaluation Laboratory (DEMATEL) method with the Global Structure Model\n(GSM), creating a synergistic model that effectively captures both local and\nglobal influences within a network. This method is applied across various\ncomplex networks, such as social, transportation, and communication systems,\nutilizing the Global Network Influence Dataset (GNID). Our analysis highlights\nthe structural dynamics and resilience of these networks, revealing insights\ninto node connectivity and community formation. The findings demonstrate the\neffectiveness of our AI-based approach in offering a comprehensive\nunderstanding of network behavior, contributing significantly to strategic\nnetwork analysis and optimization.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00190v1",
    "published_date": "2024-02-29 23:43:08 UTC",
    "updated_date": "2024-02-29 23:43:08 UTC"
  },
  {
    "arxiv_id": "2403.00178v1",
    "title": "Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems",
    "authors": [
      "Zijie Huang",
      "Jeehyun Hwang",
      "Junkai Zhang",
      "Jinwoo Baik",
      "Weitong Zhang",
      "Dominik Wodarz",
      "Yizhou Sun",
      "Quanquan Gu",
      "Wei Wang"
    ],
    "abstract": "Real-world multi-agent systems are often dynamic and continuous, where the\nagents co-evolve and undergo changes in their trajectories and interactions\nover time. For example, the COVID-19 transmission in the U.S. can be viewed as\na multi-agent system, where states act as agents and daily population movements\nbetween them are interactions. Estimating the counterfactual outcomes in such\nsystems enables accurate future predictions and effective decision-making, such\nas formulating COVID-19 policies. However, existing methods fail to model the\ncontinuous dynamic effects of treatments on the outcome, especially when\nmultiple treatments (e.g., \"stay-at-home\" and \"get-vaccine\" policies) are\napplied simultaneously. To tackle this challenge, we propose Causal Graph\nOrdinary Differential Equations (CAG-ODE), a novel model that captures the\ncontinuous interaction among agents using a Graph Neural Network (GNN) as the\nODE function. The key innovation of our model is to learn time-dependent\nrepresentations of treatments and incorporate them into the ODE function,\nenabling precise predictions of potential outcomes. To mitigate confounding\nbias, we further propose two domain adversarial learning-based objectives,\nwhich enable our model to learn balanced continuous representations that are\nnot affected by treatments or interference. Experiments on two datasets (i.e.,\nCOVID-19 and tumor growth) demonstrate the superior performance of our proposed\nmodel.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00178v1",
    "published_date": "2024-02-29 23:07:07 UTC",
    "updated_date": "2024-02-29 23:07:07 UTC"
  },
  {
    "arxiv_id": "2403.00176v1",
    "title": "SoD$^2$: Statically Optimizing Dynamic Deep Neural Network",
    "authors": [
      "Wei Niu",
      "Gagan Agrawal",
      "Bin Ren"
    ],
    "abstract": "Though many compilation and runtime systems have been developed for DNNs in\nrecent years, the focus has largely been on static DNNs. Dynamic DNNs, where\ntensor shapes and sizes and even the set of operators used are dependent upon\nthe input and/or execution, are becoming common. This paper presents SoD$^2$, a\ncomprehensive framework for optimizing Dynamic DNNs. The basis of our approach\nis a classification of common operators that form DNNs, and the use of this\nclassification towards a Rank and Dimension Propagation (RDP) method. This\nframework statically determines the shapes of operators as known constants,\nsymbolic constants, or operations on these. Next, using RDP we enable a series\nof optimizations, like fused code generation, execution (order) planning, and\neven runtime memory allocation plan generation. By evaluating the framework on\n10 emerging Dynamic DNNs and comparing it against several existing systems, we\ndemonstrate both reductions in execution latency and memory requirements, with\nRDP-enabled key optimizations responsible for much of the gains. Our evaluation\nresults show that SoD$^2$ runs up to $3.9\\times$ faster than these systems\nwhile saving up to $88\\%$ peak memory consumption.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00176v1",
    "published_date": "2024-02-29 23:04:01 UTC",
    "updated_date": "2024-02-29 23:04:01 UTC"
  },
  {
    "arxiv_id": "2403.00863v2",
    "title": "LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction",
    "authors": [
      "Chenhao Fang",
      "Xiaohan Li",
      "Zezhong Fan",
      "Jianpeng Xu",
      "Kaushiki Nag",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "abstract": "Product attribute value extraction is a pivotal component in Natural Language\nProcessing (NLP) and the contemporary e-commerce industry. The provision of\nprecise product attribute values is fundamental in ensuring high-quality\nrecommendations and enhancing customer satisfaction. The recently emerging\nLarge Language Models (LLMs) have demonstrated state-of-the-art performance in\nnumerous attribute extraction tasks, without the need for domain-specific\ntraining data. Nevertheless, varying strengths and weaknesses are exhibited by\ndifferent LLMs due to the diversity in data, architectures, and\nhyperparameters. This variation makes them complementary to each other, with no\nsingle LLM dominating all others. Considering the diverse strengths and\nweaknesses of LLMs, it becomes necessary to develop an ensemble method that\nleverages their complementary potentials. In this paper, we propose a novel\nalgorithm called LLM-ensemble to ensemble different LLMs' outputs for attribute\nvalue extraction. We iteratively learn the weights for different LLMs to\naggregate the labels with weights to predict the final attribute value. Not\nonly can our proposed method be proven theoretically optimal, but it also\nensures efficient computation, fast convergence, and safe deployment. We have\nalso conducted extensive experiments with various state-of-the-art LLMs,\nincluding Llama2-13B, Llama2-70B, PaLM-2, GPT-3.5, and GPT-4, on Walmart's\ninternal data. Our offline metrics demonstrate that the LLM-ensemble method\noutperforms all the state-of-the-art single LLMs on Walmart's internal dataset.\nThis method has been launched in several production models, leading to improved\nGross Merchandise Volume (GMV), Click-Through Rate (CTR), Conversion Rate\n(CVR), and Add-to-Cart Rate (ATC).",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "SIGIR 2024 industry track",
    "pdf_url": "http://arxiv.org/pdf/2403.00863v2",
    "published_date": "2024-02-29 23:03:19 UTC",
    "updated_date": "2024-06-20 07:10:28 UTC"
  },
  {
    "arxiv_id": "2403.00175v2",
    "title": "FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything",
    "authors": [
      "Safouane El Ghazouali",
      "Youssef Mhirit",
      "Ali Oukhrid",
      "Umberto Michelucci",
      "Hichem Nouira"
    ],
    "abstract": "In the realm of computer vision, the integration of advanced techniques into\nthe processing of RGB-D camera inputs poses a significant challenge, given the\ninherent complexities arising from diverse environmental conditions and varying\nobject appearances. Therefore, this paper introduces FusionVision, an\nexhaustive pipeline adapted for the robust 3D segmentation of objects in RGB-D\nimagery. Traditional computer vision systems face limitations in simultaneously\ncapturing precise object boundaries and achieving high-precision object\ndetection on depth map as they are mainly proposed for RGB cameras. To address\nthis challenge, FusionVision adopts an integrated approach by merging\nstate-of-the-art object detection techniques, with advanced instance\nsegmentation methods. The integration of these components enables a holistic\n(unified analysis of information obtained from both color \\textit{RGB} and\ndepth \\textit{D} channels) interpretation of RGB-D data, facilitating the\nextraction of comprehensive and accurate object information. The proposed\nFusionVision pipeline employs YOLO for identifying objects within the RGB image\ndomain. Subsequently, FastSAM, an innovative semantic segmentation model, is\napplied to delineate object boundaries, yielding refined segmentation masks.\nThe synergy between these components and their integration into 3D scene\nunderstanding ensures a cohesive fusion of object detection and segmentation,\nenhancing overall precision in 3D object segmentation. The code and pre-trained\nmodels are publicly available at https://github.com/safouaneelg/FusionVision/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 9 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2403.00175v2",
    "published_date": "2024-02-29 22:59:27 UTC",
    "updated_date": "2024-05-01 12:34:53 UTC"
  },
  {
    "arxiv_id": "2403.00172v1",
    "title": "Go Beyond Black-box Policies: Rethinking the Design of Learning Agent for Interpretable and Verifiable HVAC Control",
    "authors": [
      "Zhiyu An",
      "Xianzhong Ding",
      "Wan Du"
    ],
    "abstract": "Recent research has shown the potential of Model-based Reinforcement Learning\n(MBRL) to enhance energy efficiency of Heating, Ventilation, and Air\nConditioning (HVAC) systems. However, existing methods rely on black-box\nthermal dynamics models and stochastic optimizers, lacking reliability\nguarantees and posing risks to occupant health. In this work, we overcome the\nreliability bottleneck by redesigning HVAC controllers using decision trees\nextracted from existing thermal dynamics models and historical data. Our\ndecision tree-based policies are deterministic, verifiable, interpretable, and\nmore energy-efficient than current MBRL methods. First, we introduce a novel\nverification criterion for RL agents in HVAC control based on domain knowledge.\nSecond, we develop a policy extraction procedure that produces a verifiable\ndecision tree policy. We found that the high dimensionality of the thermal\ndynamics model input hinders the efficiency of policy extraction. To tackle the\ndimensionality challenge, we leverage importance sampling conditioned on\nhistorical data distributions, significantly improving policy extraction\nefficiency. Lastly, we present an offline verification algorithm that\nguarantees the reliability of a control policy. Extensive experiments show that\nour method saves 68.4% more energy and increases human comfort gain by 14.8%\ncompared to the state-of-the-art method, in addition to an 1127x reduction in\ncomputation overhead. Our code and data are available at\nhttps://github.com/ryeii/Veri_HVAC",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted for the 61st Design Automation Conference (DAC)",
    "pdf_url": "http://arxiv.org/pdf/2403.00172v1",
    "published_date": "2024-02-29 22:42:23 UTC",
    "updated_date": "2024-02-29 22:42:23 UTC"
  },
  {
    "arxiv_id": "2403.00154v2",
    "title": "LLMs in Political Science: Heralding a New Era of Visual Analysis",
    "authors": [
      "Yu Wang"
    ],
    "abstract": "Interest is increasing among political scientists in leveraging the extensive\ninformation available in images. However, the challenge of interpreting these\nimages lies in the need for specialized knowledge in computer vision and access\nto specialized hardware. As a result, image analysis has been limited to a\nrelatively small group within the political science community. This landscape\ncould potentially change thanks to the rise of large language models (LLMs).\nThis paper aims to raise awareness of the feasibility of using Gemini for image\ncontent analysis. A retrospective analysis was conducted on a corpus of 688\nimages. Content reports were elicited from Gemini for each image and then\nmanually evaluated by the authors. We find that Gemini is highly accurate in\nperforming object detection, which is arguably the most common and fundamental\ntask in image analysis for political scientists. Equally important, we show\nthat it is easy to implement as the entire command consists of a single prompt\nin natural language; it is fast to run and should meet the time budget of most\nresearchers; and it is free to use and does not require any specialized\nhardware. In addition, we illustrate how political scientists can leverage\nGemini for other image understanding tasks, including face identification,\nsentiment analysis, and caption generation. Our findings suggest that Gemini\nand other similar LLMs have the potential to drastically stimulate and\naccelerate image research in political science and social sciences more\nbroadly.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.00154v2",
    "published_date": "2024-02-29 22:11:20 UTC",
    "updated_date": "2024-03-27 02:21:03 UTC"
  },
  {
    "arxiv_id": "2403.00143v2",
    "title": "Tree-Averaging Algorithms for Ensemble-Based Unsupervised Discontinuous Constituency Parsing",
    "authors": [
      "Behzad Shayegh",
      "Yuqiao Wen",
      "Lili Mou"
    ],
    "abstract": "We address unsupervised discontinuous constituency parsing, where we observe\na high variance in the performance of the only previous model in the\nliterature. We propose to build an ensemble of different runs of the existing\ndiscontinuous parser by averaging the predicted trees, to stabilize and boost\nperformance. To begin with, we provide comprehensive computational complexity\nanalysis (in terms of P and NP-complete) for tree averaging under different\nsetups of binarity and continuity. We then develop an efficient exact algorithm\nto tackle the task, which runs in a reasonable time for all samples in our\nexperiments. Results on three datasets show our method outperforms all\nbaselines in all metrics; we also provide in-depth analyses of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00143v2",
    "published_date": "2024-02-29 21:49:31 UTC",
    "updated_date": "2024-11-05 21:04:23 UTC"
  },
  {
    "arxiv_id": "2403.00144v2",
    "title": "EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation",
    "authors": [
      "Yuqiao Wen",
      "Behzad Shayegh",
      "Chenyang Huang",
      "Yanshuai Cao",
      "Lili Mou"
    ],
    "abstract": "The ability of zero-shot translation emerges when we train a multilingual\nmodel with certain translation directions; the model can then directly\ntranslate in unseen directions. Alternatively, zero-shot translation can be\naccomplished by pivoting through a third language (e.g., English). In our work,\nwe observe that both direct and pivot translations are noisy and achieve less\nsatisfactory performance. We propose EBBS, an ensemble method with a novel\nbi-level beam search algorithm, where each ensemble component explores its own\nprediction step by step at the lower level but they are synchronized by a \"soft\nvoting\" mechanism at the upper level. Results on two popular multilingual\ntranslation datasets show that EBBS consistently outperforms direct and pivot\ntranslations as well as existing ensemble techniques. Further, we can distill\nthe ensemble's knowledge back to the multilingual model to improve inference\nefficiency; profoundly, our EBBS-based distillation does not sacrifice, or even\nimproves, the translation quality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.6; I.2.m; I.5.1; I.7.m"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.00144v2",
    "published_date": "2024-02-29 21:49:31 UTC",
    "updated_date": "2025-02-05 19:44:43 UTC"
  },
  {
    "arxiv_id": "2403.00141v1",
    "title": "EROS: Entity-Driven Controlled Policy Document Summarization",
    "authors": [
      "Joykirat Singh",
      "Sehban Fazili",
      "Rohan Jain",
      "Md Shad Akhtar"
    ],
    "abstract": "Privacy policy documents have a crucial role in educating individuals about\nthe collection, usage, and protection of users' personal data by organizations.\nHowever, they are notorious for their lengthy, complex, and convoluted language\nespecially involving privacy-related entities. Hence, they pose a significant\nchallenge to users who attempt to comprehend organization's data usage policy.\nIn this paper, we propose to enhance the interpretability and readability of\npolicy documents by using controlled abstractive summarization -- we enforce\nthe generated summaries to include critical privacy-related entities (e.g.,\ndata and medium) and organization's rationale (e.g.,target and reason) in\ncollecting those entities. To achieve this, we develop PD-Sum, a\npolicy-document summarization dataset with marked privacy-related entity\nlabels. Our proposed model, EROS, identifies critical entities through a\nspan-based entity extraction model and employs them to control the information\ncontent of the summaries using proximal policy optimization (PPO). Comparison\nshows encouraging improvement over various baselines. Furthermore, we furnish\nqualitative and human evaluations to establish the efficacy of EROS.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00141v1",
    "published_date": "2024-02-29 21:44:50 UTC",
    "updated_date": "2024-02-29 21:44:50 UTC"
  },
  {
    "arxiv_id": "2403.00131v3",
    "title": "UniTS: A Unified Multi-Task Time Series Model",
    "authors": [
      "Shanghua Gao",
      "Teddy Koker",
      "Owen Queen",
      "Thomas Hartvigsen",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "abstract": "Although pre-trained transformers and reprogrammed text-based LLMs have shown\nstrong performance on time series tasks, the best-performing architectures vary\nwidely across tasks, with most models narrowly focused on specific areas, such\nas time series forecasting. Unifying predictive and generative time series\ntasks within a single model remains challenging. We introduce UniTS, a unified\nmulti-task time series model that utilizes task tokenization to integrate\npredictive and generative tasks into a single framework. UniTS employs a\nmodified transformer block to capture universal time series representations,\nenabling transferability from a heterogeneous, multi-domain pre-training\ndataset-characterized by diverse dynamic patterns, sampling rates, and temporal\nscales-to a wide range of downstream datasets with varied task specifications\nand data domains. Tested on 38 datasets across human activity sensors,\nhealthcare, engineering, and finance, UniTS achieves superior performance\ncompared to 12 forecasting models, 20 classification models, 18 anomaly\ndetection models, and 16 imputation models, including adapted text-based LLMs.\nUniTS also demonstrates strong few-shot and prompt capabilities when applied to\nnew domains and tasks. In single-task settings, UniTS outperforms competitive\ntask-specialized time series models. Code and datasets are available at\nhttps://github.com/mims-harvard/UniTS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00131v3",
    "published_date": "2024-02-29 21:25:58 UTC",
    "updated_date": "2024-11-25 20:12:55 UTC"
  },
  {
    "arxiv_id": "2403.00862v4",
    "title": "NewsBench: A Systematic Evaluation Framework for Assessing Editorial Capabilities of Large Language Models in Chinese Journalism",
    "authors": [
      "Miao Li",
      "Ming-Bin Chen",
      "Bo Tang",
      "Shengbin Hou",
      "Pengyu Wang",
      "Haiying Deng",
      "Zhiyu Li",
      "Feiyu Xiong",
      "Keming Mao",
      "Peng Cheng",
      "Yi Luo"
    ],
    "abstract": "We present NewsBench, a novel evaluation framework to systematically assess\nthe capabilities of Large Language Models (LLMs) for editorial capabilities in\nChinese journalism. Our constructed benchmark dataset is focused on four facets\nof writing proficiency and six facets of safety adherence, and it comprises\nmanually and carefully designed 1,267 test samples in the types of multiple\nchoice questions and short answer questions for five editorial tasks in 24 news\ndomains. To measure performances, we propose different GPT-4 based automatic\nevaluation protocols to assess LLM generations for short answer questions in\nterms of writing proficiency and safety adherence, and both are validated by\nthe high correlations with human evaluations. Based on the systematic\nevaluation framework, we conduct a comprehensive analysis of ten popular LLMs\nwhich can handle Chinese. The experimental results highlight GPT-4 and ERNIE\nBot as top performers, yet reveal a relative deficiency in journalistic safety\nadherence in creative writing tasks. Our findings also underscore the need for\nenhanced ethical guidance in machine-generated journalistic content, marking a\nstep forward in aligning LLMs with journalistic standards and safety\nconsiderations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Long paper, ACL 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2403.00862v4",
    "published_date": "2024-02-29 21:05:14 UTC",
    "updated_date": "2024-06-04 14:50:58 UTC"
  },
  {
    "arxiv_id": "2403.00861v1",
    "title": "Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights",
    "authors": [
      "Yuan Wang",
      "Lokesh Kumar Sambasivan",
      "Mingang Fu",
      "Prakhar Mehrotra"
    ],
    "abstract": "Generative AI applications, such as ChatGPT or DALL-E, have shown the world\ntheir impressive capabilities in generating human-like text or image. Diving\ndeeper, the science stakeholder for those AI applications are Deep Generative\nModels, a.k.a DGMs, which are designed to learn the underlying distribution of\nthe data and generate new data points that are statistically similar to the\noriginal dataset. One critical question is raised: how can we leverage DGMs\ninto morden retail supply chain realm? To address this question, this paper\nexpects to provide a comprehensive review of DGMs and discuss their existing\nand potential usecases in retail supply chain, by (1) providing a taxonomy and\noverview of state-of-the-art DGMs and their variants, (2) reviewing existing\nDGM applications in retail supply chain from a end-to-end view of point, and\n(3) discussing insights and potential directions on how DGMs can be further\nutilized on solving retail supply chain problems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00861v1",
    "published_date": "2024-02-29 21:03:46 UTC",
    "updated_date": "2024-02-29 21:03:46 UTC"
  },
  {
    "arxiv_id": "2403.00860v1",
    "title": "Parallel Algorithms for Exact Enumeration of Deep Neural Network Activation Regions",
    "authors": [
      "Sabrina Drammis",
      "Bowen Zheng",
      "Karthik Srinivasan",
      "Robert C. Berwick",
      "Nancy A. Lynch",
      "Robert Ajemian"
    ],
    "abstract": "A feedforward neural network using rectified linear units constructs a\nmapping from inputs to outputs by partitioning its input space into a set of\nconvex regions where points within a region share a single affine\ntransformation. In order to understand how neural networks work, when and why\nthey fail, and how they compare to biological intelligence, we need to\nunderstand the organization and formation of these regions. Step one is to\ndesign and implement algorithms for exact region enumeration in networks beyond\ntoy examples.\n  In this work, we present parallel algorithms for exact enumeration in deep\n(and shallow) neural networks. Our work has three main contributions: (1) we\npresent a novel algorithm framework and parallel algorithms for region\nenumeration; (2) we implement one of our algorithms on a variety of network\narchitectures and experimentally show how the number of regions dictates\nruntime; and (3) we show, using our algorithm's output, how the dimension of a\nregion's affine transformation impacts further partitioning of the region by\ndeeper layers.\n  To our knowledge, we run our implemented algorithm on networks larger than\nall of the networks used in the existing region enumeration literature.\nFurther, we experimentally demonstrate the importance of parallelism for region\nenumeration of any reasonably sized network.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00860v1",
    "published_date": "2024-02-29 20:48:39 UTC",
    "updated_date": "2024-02-29 20:48:39 UTC"
  },
  {
    "arxiv_id": "2403.00116v1",
    "title": "Federated Linear Contextual Bandits with Heterogeneous Clients",
    "authors": [
      "Ethan Blaser",
      "Chuanhao Li",
      "Hongning Wang"
    ],
    "abstract": "The demand for collaborative and private bandit learning across multiple\nagents is surging due to the growing quantity of data generated from\ndistributed systems. Federated bandit learning has emerged as a promising\nframework for private, efficient, and decentralized online learning. However,\nalmost all previous works rely on strong assumptions of client homogeneity,\ni.e., all participating clients shall share the same bandit model; otherwise,\nthey all would suffer linear regret. This greatly restricts the application of\nfederated bandit learning in practice. In this work, we introduce a new\napproach for federated bandits for heterogeneous clients, which clusters\nclients for collaborative bandit learning under the federated learning setting.\nOur proposed algorithm achieves non-trivial sub-linear regret and communication\ncost for all clients, subject to the communication protocol under federated\nlearning that at anytime only one model can be shared by the server.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00116v1",
    "published_date": "2024-02-29 20:39:31 UTC",
    "updated_date": "2024-02-29 20:39:31 UTC"
  },
  {
    "arxiv_id": "2403.00108v2",
    "title": "LoRATK: LoRA Once, Backdoor Everywhere in the Share-and-Play Ecosystem",
    "authors": [
      "Hongyi Liu",
      "Shaochen Zhong",
      "Xintong Sun",
      "Minghao Tian",
      "Mohsen Hariri",
      "Zirui Liu",
      "Ruixiang Tang",
      "Zhimeng Jiang",
      "Jiayi Yuan",
      "Yu-Neng Chuang",
      "Li Li",
      "Soo-Hyun Choi",
      "Rui Chen",
      "Vipin Chaudhary",
      "Xia Hu"
    ],
    "abstract": "Finetuning LLMs with LoRA has gained significant popularity due to its\nsimplicity and effectiveness. Often, users may even find pluggable,\ncommunity-shared LoRAs to enhance their base models for a specific downstream\ntask of interest; enjoying a powerful, efficient, yet customized LLM experience\nwith negligible investment. However, this convenient share-and-play ecosystem\nalso introduces a new attack surface, where attackers can distribute malicious\nLoRAs to a community eager to try out shared assets. Despite the high-risk\npotential, no prior art has comprehensively explored LoRA's attack surface\nunder the downstream-enhancing share-and-play context. In this paper, we\ninvestigate how backdoors can be injected into task-enhancing LoRAs and examine\nthe mechanisms of such infections. We find that with a simple, efficient, yet\nspecific recipe, a backdoor LoRA can be trained once and then seamlessly merged\n(in a training-free fashion) with multiple task-enhancing LoRAs, retaining both\nits malicious backdoor and benign downstream capabilities. This allows\nattackers to scale the distribution of compromised LoRAs with minimal effort by\nleveraging the rich pool of existing shared LoRA assets. We note that such\nmerged LoRAs are particularly infectious -- because their malicious intent is\ncleverly concealed behind improved downstream capabilities, creating a strong\nincentive for voluntary download -- and dangerous -- because under local\ndeployment, no safety measures exist to intervene when things go wrong. Our\nwork is among the first to study this new threat model of training-free\ndistribution of downstream-capable-yet-backdoor-injected LoRAs, highlighting\nthe urgent need for heightened security awareness in the LoRA ecosystem.\nWarning: This paper contains offensive content and involves a real-life\ntragedy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00108v2",
    "published_date": "2024-02-29 20:25:16 UTC",
    "updated_date": "2025-04-30 22:51:42 UTC"
  },
  {
    "arxiv_id": "2403.00859v1",
    "title": "Team Formation amidst Conflicts",
    "authors": [
      "Iasonas Nikolaou",
      "Evimaria Terzi"
    ],
    "abstract": "In this work, we formulate the problem of team formation amidst conflicts.\nThe goal is to assign individuals to tasks, with given capacities, taking into\naccount individuals' task preferences and the conflicts between them. Using\ndependent rounding schemes as our main toolbox, we provide efficient\napproximation algorithms. Our framework is extremely versatile and can model\nmany different real-world scenarios as they arise in educational settings and\nhuman-resource management. We test and deploy our algorithms on real-world\ndatasets and we show that our algorithms find assignments that are better than\nthose found by natural baselines. In the educational setting we also show how\nour assignments are far better than those done manually by human experts. In\nthe human resource management application we show how our assignments increase\nthe diversity of teams. Finally, using a synthetic dataset we demonstrate that\nour algorithms scale very well in practice.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00859v1",
    "published_date": "2024-02-29 20:15:13 UTC",
    "updated_date": "2024-02-29 20:15:13 UTC"
  },
  {
    "arxiv_id": "2403.00858v4",
    "title": "Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs",
    "authors": [
      "Raghavv Goel",
      "Mukul Gagrani",
      "Wonseok Jeon",
      "Junyoung Park",
      "Mingu Lee",
      "Christopher Lott"
    ],
    "abstract": "Text generation with Large Language Models (LLMs) is known to be memory bound\ndue to the combination of their auto-regressive nature, huge parameter counts,\nand limited memory bandwidths, often resulting in low token rates. Speculative\ndecoding has been proposed as a solution for LLM inference acceleration.\nHowever, since draft models are often unavailable in the modern open-source LLM\nfamilies, e.g., for Llama 2 7B, training a high-quality draft model is required\nto enable inference acceleration via speculative decoding. In this paper, we\npropose a simple draft model training framework for direct alignment to\nchat-capable target models. With the proposed framework, we train Llama 2 Chat\nDrafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\\% of\nthe original size. Our training framework only consists of pretraining,\ndistillation dataset generation, and finetuning with knowledge distillation,\nwith no additional alignment procedure. For the finetuning step, we use\ninstruction-response pairs generated by target model for distillation in\nplausible data distribution, and propose a new Total Variation Distance++\n(TVD++) loss that incorporates variance reduction techniques inspired from the\npolicy gradient method in reinforcement learning. Our empirical results show\nthat Llama 2 Chat Drafter 115M with speculative decoding achieves up to 2.3\nblock efficiency and 2.4$\\times$ speed-up relative to autoregressive decoding\non various tasks with no further task-specific fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures, Published at the ICLR 2024 Workshop on\n  Understanding of Foundation Models (ME-FoMo)",
    "pdf_url": "http://arxiv.org/pdf/2403.00858v4",
    "published_date": "2024-02-29 19:55:06 UTC",
    "updated_date": "2024-05-13 18:34:30 UTC"
  },
  {
    "arxiv_id": "2403.14662v1",
    "title": "Case Studies of AI Policy Development in Africa",
    "authors": [
      "Kadijatou Diallo",
      "Jonathan Smith",
      "Chinasa T. Okolo",
      "Dorcas Nyamwaya",
      "Jonas Kgomo",
      "Richard Ngamita"
    ],
    "abstract": "Artificial Intelligence (AI) requires new ways of evaluating national\ntechnology use and strategy for African nations. We conduct a survey of\nexisting 'readiness' assessments both for general digital adoption and for AI\npolicy in particular. We conclude that existing global readiness assessments do\nnot fully capture African states' progress in AI readiness and lay the\ngroundwork for how assessments can be better used for the African context. We\nconsider the extent to which these indicators map to the African context and\nwhat these indicators miss in capturing African states' on-the-ground work in\nmeeting AI capability. Through case studies of four African nations of diverse\ngeographic and economic dimensions, we identify nuances missed by global\nassessments and offer high-level policy considerations for how states can best\nimprove their AI readiness standards and prepare their societies to capture the\nbenefits of AI.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14662v1",
    "published_date": "2024-02-29 19:17:11 UTC",
    "updated_date": "2024-02-29 19:17:11 UTC"
  },
  {
    "arxiv_id": "2403.00071v2",
    "title": "Resonance RoPE: Improving Context Length Generalization of Large Language Models",
    "authors": [
      "Suyuchen Wang",
      "Ivan Kobyzev",
      "Peng Lu",
      "Mehdi Rezagholizadeh",
      "Bang Liu"
    ],
    "abstract": "This paper addresses the challenge of train-short-test-long (TSTL) scenarios\nin Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE),\nwhere models pre-trained on shorter sequences face difficulty with\nout-of-distribution (OOD) token positions in longer sequences. We introduce\nResonance RoPE, a novel approach designed to narrow the generalization gap in\nTSTL scenarios by refining the interpolation of RoPE features for OOD\npositions, significantly improving the model performance without additional\nonline computational costs. Furthermore, we present PosGen, a new synthetic\nbenchmark specifically designed for fine-grained behavior analysis in TSTL\nscenarios, aiming to isolate the constantly increasing difficulty of token\ngeneration on long contexts from the challenges of recognizing new token\npositions. Our experiments on synthetic tasks show that after applying\nResonance RoPE, Transformers recognize OOD position better and more robustly.\nOur extensive LLM experiments also show superior performance after applying\nResonance RoPE to the current state-of-the-art RoPE scaling method, YaRN, on\nboth upstream language modeling tasks and a variety of downstream long-text\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 4 figures, accepted at ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2403.00071v2",
    "published_date": "2024-02-29 19:02:03 UTC",
    "updated_date": "2024-06-10 13:30:34 UTC"
  },
  {
    "arxiv_id": "2402.19475v1",
    "title": "The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?",
    "authors": [
      "Alex Gu",
      "Wen-Ding Li",
      "Naman Jain",
      "Theo X. Olausson",
      "Celine Lee",
      "Koushik Sen",
      "Armando Solar-Lezama"
    ],
    "abstract": "While language models are increasingly more proficient at code generation,\nthey still frequently generate incorrect programs. Many of these programs are\nobviously wrong, but others are more subtle and pass weaker correctness checks\nsuch as being able to compile. In this work, we focus on these counterfeit\nsamples: programs sampled from a language model that 1) have a high enough\nlog-probability to be generated at a moderate temperature and 2) pass weak\ncorrectness checks. Overall, we discover that most models have a very shallow\nunderstanding of counterfeits through three clear failure modes. First, models\nmistakenly classify them as correct. Second, models are worse at reasoning\nabout the execution behaviour of counterfeits and often predict their execution\nresults as if they were correct. Third, when asking models to fix counterfeits,\nthe likelihood of a model successfully repairing a counterfeit is often even\nlower than that of sampling a correct program from scratch. Counterfeits also\nhave very unexpected properties: first, counterfeit programs for problems that\nare easier for a model to solve are not necessarily easier to detect and only\nslightly easier to execute and repair. Second, counterfeits from a given model\nare just as confusing to the model itself as they are to other models. Finally,\nboth strong and weak models are able to generate counterfeit samples that\nequally challenge all models. In light of our findings, we recommend that care\nand caution be taken when relying on models to understand their own samples,\nespecially when no external feedback is incorporated.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "54 pages, 25 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.19475v1",
    "published_date": "2024-02-29 18:59:25 UTC",
    "updated_date": "2024-02-29 18:59:25 UTC"
  },
  {
    "arxiv_id": "2402.19471v2",
    "title": "Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling",
    "authors": [
      "Gabriel Grand",
      "Valerio Pepe",
      "Jacob Andreas",
      "Joshua B. Tenenbaum"
    ],
    "abstract": "Questions combine our mastery of language with our remarkable facility for\nreasoning about uncertainty. How do people navigate vast hypothesis spaces to\npose informative questions given limited cognitive resources? We study these\ntradeoffs in a classic grounded question-asking task based on the board game\nBattleship. Our language-informed program sampling (LIPS) model uses large\nlanguage models (LLMs) to generate natural language questions, translate them\ninto symbolic programs, and evaluate their expected information gain. We find\nthat with a surprisingly modest resource budget, this simple Monte Carlo\noptimization strategy yields informative questions that mirror human\nperformance across varied Battleship board scenarios. In contrast, LLM-only\nbaselines struggle to ground questions in the board state; notably, GPT-4V\nprovides no improvement over non-visual baselines. Our results illustrate how\nBayesian models of question-asking can leverage the statistics of language to\ncapture human priors, while highlighting some shortcomings of pure LLMs as\ngrounded reasoners.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to CogSci 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.19471v2",
    "published_date": "2024-02-29 18:58:15 UTC",
    "updated_date": "2024-05-01 19:00:06 UTC"
  },
  {
    "arxiv_id": "2402.19467v4",
    "title": "TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning",
    "authors": [
      "Kate Sanders",
      "Nathaniel Weir",
      "Benjamin Van Durme"
    ],
    "abstract": "It is challenging for models to understand complex, multimodal content such\nas television clips, and this is in part because video-language models often\nrely on single-modality reasoning and lack interpretability. To combat these\nissues we propose TV-TREES, the first multimodal entailment tree generator.\nTV-TREES serves as an approach to video understanding that promotes\ninterpretable joint-modality reasoning by searching for trees of entailment\nrelationships between simple text-video evidence and higher-level conclusions\nthat prove question-answer pairs. We also introduce the task of multimodal\nentailment tree generation to evaluate reasoning quality. Our method's\nperformance on the challenging TVQA benchmark demonstrates interpretable,\nstate-of-the-art zero-shot performance on full clips, illustrating that\nmultimodal entailment tree generation can be a best-of-both-worlds alternative\nto black-box systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.19467v4",
    "published_date": "2024-02-29 18:57:01 UTC",
    "updated_date": "2024-10-10 15:25:14 UTC"
  },
  {
    "arxiv_id": "2402.19465v2",
    "title": "Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models",
    "authors": [
      "Chen Qian",
      "Jie Zhang",
      "Wei Yao",
      "Dongrui Liu",
      "Zhenfei Yin",
      "Yu Qiao",
      "Yong Liu",
      "Jing Shao"
    ],
    "abstract": "Ensuring the trustworthiness of large language models (LLMs) is crucial. Most\nstudies concentrate on fully pre-trained LLMs to better understand and improve\nLLMs' trustworthiness. In this paper, to reveal the untapped potential of\npre-training, we pioneer the exploration of LLMs' trustworthiness during this\nperiod, focusing on five key dimensions: reliability, privacy, toxicity,\nfairness, and robustness. To begin with, we apply linear probing to LLMs. The\nhigh probing accuracy suggests that \\textit{LLMs in early pre-training can\nalready distinguish concepts in each trustworthiness dimension}. Therefore, to\nfurther uncover the hidden possibilities of pre-training, we extract steering\nvectors from a LLM's pre-training checkpoints to enhance the LLM's\ntrustworthiness. Finally, inspired by~\\citet{choi2023understanding} that mutual\ninformation estimation is bounded by linear probing accuracy, we also probe\nLLMs with mutual information to investigate the dynamics of trustworthiness\nduring pre-training. We are the first to observe a similar two-phase\nphenomenon: fitting and compression~\\citep{shwartz2017opening}. This research\nprovides an initial exploration of trustworthiness modeling during LLM\npre-training, seeking to unveil new insights and spur further developments in\nthe field. We will make our code publicly accessible at\n\\url{https://github.com/ChnQ/TracingLLM}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.19465v2",
    "published_date": "2024-02-29 18:55:06 UTC",
    "updated_date": "2024-08-31 11:31:02 UTC"
  },
  {
    "arxiv_id": "2402.19464v1",
    "title": "Curiosity-driven Red-teaming for Large Language Models",
    "authors": [
      "Zhang-Wei Hong",
      "Idan Shenfeld",
      "Tsun-Hsuan Wang",
      "Yung-Sung Chuang",
      "Aldo Pareja",
      "James Glass",
      "Akash Srivastava",
      "Pulkit Agrawal"
    ],
    "abstract": "Large language models (LLMs) hold great potential for many natural language\napplications but risk generating incorrect or toxic content. To probe when an\nLLM generates unwanted content, the current paradigm is to recruit a\n\\textit{red team} of human testers to design input prompts (i.e., test cases)\nthat elicit undesirable responses from LLMs. However, relying solely on human\ntesters is expensive and time-consuming. Recent works automate red teaming by\ntraining a separate red team LLM with reinforcement learning (RL) to generate\ntest cases that maximize the chance of eliciting undesirable responses from the\ntarget LLM. However, current RL methods are only able to generate a small\nnumber of effective test cases resulting in a low coverage of the span of\nprompts that elicit undesirable responses from the target LLM. To overcome this\nlimitation, we draw a connection between the problem of increasing the coverage\nof generated test cases and the well-studied approach of curiosity-driven\nexploration that optimizes for novelty. Our method of curiosity-driven red\nteaming (CRT) achieves greater coverage of test cases while mantaining or\nincreasing their effectiveness compared to existing methods. Our method, CRT\nsuccessfully provokes toxic responses from LLaMA2 model that has been heavily\nfine-tuned using human preferences to avoid toxic outputs. Code is available at\n\\url{https://github.com/Improbable-AI/curiosity_redteam}",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.19464v1",
    "published_date": "2024-02-29 18:55:03 UTC",
    "updated_date": "2024-02-29 18:55:03 UTC"
  },
  {
    "arxiv_id": "2402.19457v3",
    "title": "$\\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation",
    "authors": [
      "Maxime Darrin",
      "Philippe Formont",
      "Jackie Chi Kit Cheung",
      "Pablo Piantanida"
    ],
    "abstract": "Assessing the quality of summarizers poses significant challenges. In\nresponse, we propose a novel task-oriented evaluation approach that assesses\nsummarizers based on their capacity to produce summaries that are useful for\ndownstream tasks, while preserving task outcomes. We theoretically establish a\ndirect relationship between the resulting error probability of these tasks and\nthe mutual information between source texts and generated summaries. We\nintroduce $\\texttt{COSMIC}$ as a practical implementation of this metric,\ndemonstrating its strong correlation with human judgment-based metrics and its\neffectiveness in predicting downstream task performance. Comparative analyses\nagainst established metrics like $\\texttt{BERTScore}$ and $\\texttt{ROUGE}$\nhighlight the competitive performance of $\\texttt{COSMIC}$.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.19457v3",
    "published_date": "2024-02-29 18:51:23 UTC",
    "updated_date": "2024-08-14 14:06:10 UTC"
  },
  {
    "arxiv_id": "2402.19450v1",
    "title": "Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap",
    "authors": [
      "Saurabh Srivastava",
      "Annarose M B",
      "Anto P V",
      "Shashank Menon",
      "Ajay Sukumar",
      "Adwaith Samod T",
      "Alan Philipose",
      "Stevin Prince",
      "Sooraj Thomas"
    ],
    "abstract": "We propose a framework for robust evaluation of reasoning capabilities of\nlanguage models, using functional variants of benchmarks. Models that solve a\nreasoning test should exhibit no difference in performance over the static\nversion of a problem compared to a snapshot of the functional variant. We have\nrewritten the relevant fragment of the MATH benchmark into its functional\nvariant MATH(), with functionalization of other benchmarks to follow. When\nevaluating current state-of-the-art models over snapshots of MATH(), we find a\nreasoning gap -- the percentage difference between the static and functional\naccuracies. We find reasoning gaps from 58.35% to 80.31% among the\nstate-of-the-art closed and open weights models that perform well on static\nbenchmarks, with the caveat that the gaps are likely to be smaller with more\nsophisticated prompting strategies. Here we show that models which anecdotally\nhave good reasoning performance over real-world tasks, have quantifiable lower\ngaps, motivating the open problem of building \"gap 0\" models. Code for\nevaluation and new evaluation datasets, three MATH() snapshots, are publicly\navailable at https://github.com/consequentai/fneval/.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "37 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.19450v1",
    "published_date": "2024-02-29 18:48:18 UTC",
    "updated_date": "2024-02-29 18:48:18 UTC"
  },
  {
    "arxiv_id": "2402.19446v1",
    "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL",
    "authors": [
      "Yifei Zhou",
      "Andrea Zanette",
      "Jiayi Pan",
      "Sergey Levine",
      "Aviral Kumar"
    ],
    "abstract": "A broad use case of large language models (LLMs) is in goal-directed\ndecision-making tasks (or \"agent\" tasks), where an LLM needs to not just\ngenerate completions for a given prompt, but rather make intelligent decisions\nover a multi-turn interaction to accomplish a task (e.g., when interacting with\nthe web, using tools, or providing customer support). Reinforcement learning\n(RL) provides a general paradigm to address such agent tasks, but current RL\nmethods for LLMs largely focus on optimizing single-turn rewards. By\nconstruction, most single-turn RL methods cannot endow LLMs with the ability to\nintelligently seek information over multiple turns, perform credit assignment,\nor reason about their past actions -- all of which are critical in agent tasks.\nThis raises the question: how can we design effective and efficient multi-turn\nRL algorithms for LLMs? In this paper, we develop a framework for building\nmulti-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility\nof existing single-turn RL methods for LLMs (e.g., proximal policy\noptimization), while accommodating multiple turns, long horizons, and delayed\nrewards effectively. To do this, our framework adopts a hierarchical RL\napproach and runs two RL algorithms in parallel: a high-level off-policy\nvalue-based RL algorithm to aggregate reward over utterances, and a low-level\nRL algorithm that utilizes this high-level value function to train a token\npolicy within each utterance or turn. Our hierarchical framework, Actor-Critic\nFramework with a Hierarchical Structure (ArCHer), can also give rise to other\nRL methods. Empirically, we find that ArCHer significantly improves efficiency\nand performance on agent tasks, attaining a sample efficiency of about 100x\nover existing methods, while also improving with larger model capacity (upto\nthe 7 billion scale that we tested on).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19446v1",
    "published_date": "2024-02-29 18:45:56 UTC",
    "updated_date": "2024-02-29 18:45:56 UTC"
  },
  {
    "arxiv_id": "2402.19443v1",
    "title": "Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems",
    "authors": [
      "Quentin Raymondaud",
      "Mickael Rouvier",
      "Richard Dufour"
    ],
    "abstract": "Deep learning architectures have made significant progress in terms of\nperformance in many research areas. The automatic speech recognition (ASR)\nfield has thus benefited from these scientific and technological advances,\nparticularly for acoustic modeling, now integrating deep neural network\narchitectures. However, these performance gains have translated into increased\ncomplexity regarding the information learned and conveyed through these\nblack-box architectures. Following many researches in neural networks\ninterpretability, we propose in this article a protocol that aims to determine\nwhich and where information is located in an ASR acoustic model (AM). To do so,\nwe propose to evaluate AM performance on a determined set of tasks using\nintermediate representations (here, at different layer levels). Regarding the\nperformance variation and targeted tasks, we can emit hypothesis about which\ninformation is enhanced or perturbed at different architecture steps.\nExperiments are performed on both speaker verification, acoustic environment\nclassification, gender classification, tempo-distortion detection systems and\nspeech sentiment/emotion identification. Analysis showed that neural-based AMs\nhold heterogeneous information that seems surprisingly uncorrelated with\nphoneme recognition, such as emotion, sentiment or speaker identity. The\nlow-level hidden layers globally appears useful for the structuring of\ninformation while the upper ones would tend to delete useless information for\nphoneme recognition.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19443v1",
    "published_date": "2024-02-29 18:43:53 UTC",
    "updated_date": "2024-02-29 18:43:53 UTC"
  },
  {
    "arxiv_id": "2402.19442v2",
    "title": "Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality",
    "authors": [
      "Siyu Chen",
      "Heejune Sheen",
      "Tianhao Wang",
      "Zhuoran Yang"
    ],
    "abstract": "We study the dynamics of gradient flow for training a multi-head softmax\nattention model for in-context learning of multi-task linear regression. We\nestablish the global convergence of gradient flow under suitable choices of\ninitialization. In addition, we prove that an interesting \"task allocation\"\nphenomenon emerges during the gradient flow dynamics, where each attention head\nfocuses on solving a single task of the multi-task model. Specifically, we\nprove that the gradient flow dynamics can be split into three phases -- a\nwarm-up phase where the loss decreases rather slowly and the attention heads\ngradually build up their inclination towards individual tasks, an emergence\nphase where each head selects a single task and the loss rapidly decreases, and\na convergence phase where the attention parameters converge to a limit.\nFurthermore, we prove the optimality of gradient flow in the sense that the\nlimiting model learned by gradient flow is on par with the best possible\nmulti-head softmax attention model up to a constant factor. Our analysis also\ndelineates a strict separation in terms of the prediction accuracy of ICL\nbetween single-head and multi-head attention models. The key technique for our\nconvergence analysis is to map the gradient flow dynamics in the parameter\nspace to a set of ordinary differential equations in the spectral domain, where\nthe relative magnitudes of the semi-singular values of the attention weights\ndetermines task allocation. To our best knowledge, our work provides the first\nconvergence result for the multi-head softmax attention model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "141 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.19442v2",
    "published_date": "2024-02-29 18:43:52 UTC",
    "updated_date": "2024-06-10 17:18:07 UTC"
  },
  {
    "arxiv_id": "2402.19437v1",
    "title": "Differentially Private Worst-group Risk Minimization",
    "authors": [
      "Xinyu Zhou",
      "Raef Bassily"
    ],
    "abstract": "We initiate a systematic study of worst-group risk minimization under\n$(\\epsilon, \\delta)$-differential privacy (DP). The goal is to privately find a\nmodel that approximately minimizes the maximal risk across $p$ sub-populations\n(groups) with different distributions, where each group distribution is\naccessed via a sample oracle. We first present a new algorithm that achieves\nexcess worst-group population risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon} +\n\\sqrt{\\frac{p}{K}})$, where $K$ is the total number of samples drawn from all\ngroups and $d$ is the problem dimension. Our rate is nearly optimal when each\ndistribution is observed via a fixed-size dataset of size $K/p$. Our result is\nbased on a new stability-based analysis for the generalization error. In\nparticular, we show that $\\Delta$-uniform argument stability implies\n$\\tilde{O}(\\Delta + \\frac{1}{\\sqrt{n}})$ generalization error w.r.t. the\nworst-group risk, where $n$ is the number of samples drawn from each sample\noracle. Next, we propose an algorithmic framework for worst-group population\nrisk minimization using any DP online convex optimization algorithm as a\nsubroutine. Hence, we give another excess risk bound of $\\tilde{O}\\left(\n\\sqrt{\\frac{d^{1/2}}{\\epsilon K}} +\\sqrt{\\frac{p}{K\\epsilon^2}} \\right)$.\nAssuming the typical setting of $\\epsilon=\\Theta(1)$, this bound is more\nfavorable than our first bound in a certain range of $p$ as a function of $K$\nand $d$. Finally, we study differentially private worst-group empirical risk\nminimization in the offline setting, where each group distribution is observed\nby a fixed-size dataset. We present a new algorithm with nearly optimal excess\nrisk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon})$.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19437v1",
    "published_date": "2024-02-29 18:38:20 UTC",
    "updated_date": "2024-02-29 18:38:20 UTC"
  },
  {
    "arxiv_id": "2403.00854v1",
    "title": "Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning",
    "authors": [
      "Lauren Stumpf",
      "Balasundaram Kadirvelu",
      "Sigourney Waibel",
      "A. Aldo Faisal"
    ],
    "abstract": "Dysarthria, a condition resulting from impaired control of the speech muscles\ndue to neurological disorders, significantly impacts the communication and\nquality of life of patients. The condition's complexity, human scoring and\nvaried presentations make its assessment and management challenging. This study\npresents a transformer-based framework for automatically assessing dysarthria\nseverity from raw speech data. It can offer an objective, repeatable,\naccessible, standardised and cost-effective and compared to traditional methods\nrequiring human expert assessors. We develop a transformer framework, called\nSpeaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task\nlearning objective and contrastive learning for speaker-independent multi-class\ndysarthria severity classification. The multi-task framework is designed to\nreduce reliance on speaker-specific characteristics and address the intrinsic\nintra-class variability of dysarthric speech. We evaluated on the Universal\nAccess Speech dataset using leave-one-speaker-out cross-validation, our model\ndemonstrated superior performance over traditional machine learning approaches,\nwith an accuracy of $70.48\\%$ and an F1 score of $59.23\\%$. Our SALR model also\nexceeded the previous benchmark for AI-based classification, which used support\nvector machines, by $16.58\\%$. We open the black box of our model by\nvisualising the latent space where we can observe how the model substantially\nreduces speaker-specific cues and amplifies task-specific ones, thereby showing\nits robustness. In conclusion, SALR establishes a new benchmark in\nspeaker-independent multi-class dysarthria severity classification using\ngenerative AI. The potential implications of our findings for broader clinical\napplications in automated dysarthria severity assessments.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "I.2.7; I.2.1; J.3"
    ],
    "primary_category": "q-bio.NC",
    "comment": "17 pages, 2 tables, 4 main figures, 2 supplemental figures, prepared\n  for journal submission",
    "pdf_url": "http://arxiv.org/pdf/2403.00854v1",
    "published_date": "2024-02-29 18:30:52 UTC",
    "updated_date": "2024-02-29 18:30:52 UTC"
  },
  {
    "arxiv_id": "2402.19431v1",
    "title": "Compositional API Recommendation for Library-Oriented Code Generation",
    "authors": [
      "Zexiong Ma",
      "Shengnan An",
      "Bing Xie",
      "Zeqi Lin"
    ],
    "abstract": "Large language models (LLMs) have achieved exceptional performance in code\ngeneration. However, the performance remains unsatisfactory in generating\nlibrary-oriented code, especially for the libraries not present in the training\ndata of LLMs. Previous work utilizes API recommendation technology to help LLMs\nuse libraries: it retrieves APIs related to the user requirements, then\nleverages them as context to prompt LLMs. However, developmental requirements\ncan be coarse-grained, requiring a combination of multiple fine-grained APIs.\nThis granularity inconsistency makes API recommendation a challenging task. To\naddress this, we propose CAPIR (Compositional API Recommendation), which adopts\na \"divide-and-conquer\" strategy to recommend APIs for coarse-grained\nrequirements. Specifically, CAPIR employs an LLM-based Decomposer to break down\na coarse-grained task description into several detailed subtasks. Then, CAPIR\napplies an embedding-based Retriever to identify relevant APIs corresponding to\neach subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out\nredundant APIs and provides the final recommendation. To facilitate the\nevaluation of API recommendation methods on coarse-grained requirements, we\npresent two challenging benchmarks, RAPID (Recommend APIs based on\nDocumentation) and LOCG (Library-Oriented Code Generation). Experimental\nresults on these benchmarks, demonstrate the effectiveness of CAPIR in\ncomparison to existing baselines. Specifically, on RAPID's Torchdata-AR\ndataset, compared to the state-of-the-art API recommendation approach, CAPIR\nimproves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On\nLOCG's Torchdata-Code dataset, compared to code generation without API\nrecommendation, CAPIR improves pass@100 from 16.0% to 28.0%.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19431v1",
    "published_date": "2024-02-29 18:27:27 UTC",
    "updated_date": "2024-02-29 18:27:27 UTC"
  },
  {
    "arxiv_id": "2402.19423v1",
    "title": "Leveraging AI Predicted and Expert Revised Annotations in Interactive Segmentation: Continual Tuning or Full Training?",
    "authors": [
      "Tiezheng Zhang",
      "Xiaoxi Chen",
      "Chongyu Qu",
      "Alan Yuille",
      "Zongwei Zhou"
    ],
    "abstract": "Interactive segmentation, an integration of AI algorithms and human\nexpertise, premises to improve the accuracy and efficiency of curating\nlarge-scale, detailed-annotated datasets in healthcare. Human experts revise\nthe annotations predicted by AI, and in turn, AI improves its predictions by\nlearning from these revised annotations. This interactive process continues to\nenhance the quality of annotations until no major revision is needed from\nexperts. The key challenge is how to leverage AI predicted and expert revised\nannotations to iteratively improve the AI. Two problems arise: (1) The risk of\ncatastrophic forgetting--the AI tends to forget the previously learned classes\nif it is only retrained using the expert revised classes. (2) Computational\ninefficiency when retraining the AI using both AI predicted and expert revised\nannotations; moreover, given the dominant AI predicted annotations in the\ndataset, the contribution of newly revised annotations--often account for a\nvery small fraction--to the AI training remains marginal. This paper proposes\nContinual Tuning to address the problems from two perspectives: network design\nand data reuse. Firstly, we design a shared network for all classes followed by\nclass-specific networks dedicated to individual classes. To mitigate\nforgetting, we freeze the shared network for previously learned classes and\nonly update the class-specific network for revised classes. Secondly, we reuse\na small fraction of data with previous annotations to avoid over-computing. The\nselection of such data relies on the importance estimate of each data. The\nimportance score is computed by combining the uncertainty and consistency of AI\npredictions. Our experiments demonstrate that Continual Tuning achieves a speed\n16x greater than repeatedly training AI from scratch without compromising the\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE International Symposium on Biomedical Imaging (ISBI)",
    "pdf_url": "http://arxiv.org/pdf/2402.19423v1",
    "published_date": "2024-02-29 18:22:12 UTC",
    "updated_date": "2024-02-29 18:22:12 UTC"
  },
  {
    "arxiv_id": "2402.19422v3",
    "title": "PEM: Prototype-based Efficient MaskFormer for Image Segmentation",
    "authors": [
      "NiccolÃ² Cavagnero",
      "Gabriele Rosi",
      "Claudia Cuttano",
      "Francesca Pistilli",
      "Marco Ciccone",
      "Giuseppe Averta",
      "Fabio Cermelli"
    ],
    "abstract": "Recent transformer-based architectures have shown impressive results in the\nfield of image segmentation. Thanks to their flexibility, they obtain\noutstanding performance in multiple segmentation tasks, such as semantic and\npanoptic, under a single unified framework. To achieve such impressive\nperformance, these architectures employ intensive operations and require\nsubstantial computational resources, which are often not available, especially\non edge devices. To fill this gap, we propose Prototype-based Efficient\nMaskFormer (PEM), an efficient transformer-based architecture that can operate\nin multiple segmentation tasks. PEM proposes a novel prototype-based\ncross-attention which leverages the redundancy of visual features to restrict\nthe computation and improve the efficiency without harming the performance. In\naddition, PEM introduces an efficient multi-scale feature pyramid network,\ncapable of extracting features that have high semantic content in an efficient\nway, thanks to the combination of deformable convolutions and context-based\nself-modulation. We benchmark the proposed PEM architecture on two tasks,\nsemantic and panoptic segmentation, evaluated on two different datasets,\nCityscapes and ADE20K. PEM demonstrates outstanding performance on every task\nand dataset, outperforming task-specific architectures while being comparable\nand even better than computationally-expensive baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024. Project page: https://niccolocavagnero.github.io/PEM",
    "pdf_url": "http://arxiv.org/pdf/2402.19422v3",
    "published_date": "2024-02-29 18:21:54 UTC",
    "updated_date": "2024-05-06 10:06:09 UTC"
  },
  {
    "arxiv_id": "2402.19421v1",
    "title": "Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines",
    "authors": [
      "Lijia Ma",
      "Xingchen Xu",
      "Yong Tan"
    ],
    "abstract": "In the domain of digital information dissemination, search engines act as\npivotal conduits linking information seekers with providers. The advent of\nchat-based search engines utilizing Large Language Models (LLMs) and Retrieval\nAugmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary\nleap in the search ecosystem. They demonstrate metacognitive abilities in\ninterpreting web information and crafting responses with human-like\nunderstanding and creativity. Nonetheless, the intricate nature of LLMs renders\ntheir \"cognitive\" processes opaque, challenging even their designers'\nunderstanding. This research aims to dissect the mechanisms through which an\nLLM-powered chat-based search engine, specifically Bing Chat, selects\ninformation sources for its responses. To this end, an extensive dataset has\nbeen compiled through engagements with New Bing, documenting the websites it\ncites alongside those listed by the conventional search engine. Employing\nnatural language processing (NLP) techniques, the research reveals that Bing\nChat exhibits a preference for content that is not only readable and formally\nstructured, but also demonstrates lower perplexity levels, indicating a unique\ninclination towards text that is predictable by the underlying LLM. Further\nenriching our analysis, we procure an additional dataset through interactions\nwith the GPT-4 based knowledge retrieval API, unveiling a congruent text\npreference between the RAG API and Bing Chat. This consensus suggests that\nthese text preferences intrinsically emerge from the underlying language\nmodels, rather than being explicitly crafted by Bing Chat's developers.\nMoreover, our investigation documents a greater similarity among websites cited\nby RAG technologies compared to those ranked highest by conventional search\nengines.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "J.4"
    ],
    "primary_category": "cs.IR",
    "comment": "38 pages, 2 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.19421v1",
    "published_date": "2024-02-29 18:20:37 UTC",
    "updated_date": "2024-02-29 18:20:37 UTC"
  },
  {
    "arxiv_id": "2402.19420v2",
    "title": "Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning",
    "authors": [
      "Greg d'Eon",
      "Neil Newman",
      "Kevin Leyton-Brown"
    ],
    "abstract": "Iterative combinatorial auctions are widely used in high stakes settings such\nas spectrum auctions. Such auctions can be hard to analyze, making it difficult\nfor bidders to determine how to behave and for designers to optimize auction\nrules to ensure desirable outcomes such as high revenue or welfare. In this\npaper, we investigate whether multi-agent reinforcement learning (MARL)\nalgorithms can be used to understand iterative combinatorial auctions, given\nthat these algorithms have recently shown empirical success in several other\ndomains. We find that MARL can indeed benefit auction analysis, but that\ndeploying it effectively is nontrivial. We begin by describing modelling\ndecisions that keep the resulting game tractable without sacrificing important\nfeatures such as imperfect information or asymmetry between bidders. We also\ndiscuss how to navigate pitfalls of various MARL algorithms, how to overcome\nchallenges in verifying convergence, and how to generate and interpret multiple\nequilibria. We illustrate the promise of our resulting approach by using it to\nevaluate a specific rule change to a clock auction, finding substantially\ndifferent auction outcomes due to complex changes in bidders' behavior.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "18 pages (body) + 11 pages (acknowledgements, references, appendices)",
    "pdf_url": "http://arxiv.org/pdf/2402.19420v2",
    "published_date": "2024-02-29 18:16:13 UTC",
    "updated_date": "2024-07-23 19:15:44 UTC"
  },
  {
    "arxiv_id": "2402.19406v2",
    "title": "On the Scaling Laws of Geographical Representation in Language Models",
    "authors": [
      "Nathan Godey",
      "Ãric de la Clergerie",
      "BenoÃ®t Sagot"
    ],
    "abstract": "Language models have long been shown to embed geographical information in\ntheir hidden representations. This line of work has recently been revisited by\nextending this result to Large Language Models (LLMs). In this paper, we\npropose to fill the gap between well-established and recent literature by\nobserving how geographical knowledge evolves when scaling language models. We\nshow that geographical knowledge is observable even for tiny models, and that\nit scales consistently as we increase the model size. Notably, we observe that\nlarger language models cannot mitigate the geographical bias that is inherent\nto the training data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.19406v2",
    "published_date": "2024-02-29 18:04:11 UTC",
    "updated_date": "2024-03-04 11:35:02 UTC"
  },
  {
    "arxiv_id": "2402.19402v1",
    "title": "A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting",
    "authors": [
      "Young-Jin Park",
      "Donghyun Kim",
      "FrÃ©dÃ©ric Odermatt",
      "Juho Lee",
      "Kyung-Min Kim"
    ],
    "abstract": "Time series forecasting is one of the most essential and ubiquitous tasks in\nmany business problems, including demand forecasting and logistics\noptimization. Traditional time series forecasting methods, however, have\nresulted in small models with limited expressive power because they have\ndifficulty in scaling their model size up while maintaining high accuracy. In\nthis paper, we propose Forecasting orchestra (Forchestra), a simple but\npowerful framework capable of accurately predicting future demand for a diverse\nrange of items. We empirically demonstrate that the model size is scalable to\nup to 0.8 billion parameters. The proposed method not only outperforms existing\nforecasting models with a significant margin, but it could generalize well to\nunseen data points when evaluated in a zero-shot fashion on downstream\ndatasets. Last but not least, we present extensive qualitative and quantitative\nstudies to analyze how the proposed model outperforms baseline models and\ndiffers from conventional approaches. The original paper was presented as a\nfull paper at ICDM 2022 and is available at:\nhttps://ieeexplore.ieee.org/document/10027662.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a full paper at ICDM 2022",
    "pdf_url": "http://arxiv.org/pdf/2402.19402v1",
    "published_date": "2024-02-29 18:01:07 UTC",
    "updated_date": "2024-02-29 18:01:07 UTC"
  },
  {
    "arxiv_id": "2402.19379v6",
    "title": "Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Rival Human Crowd Accuracy",
    "authors": [
      "Philipp Schoenegger",
      "Indre Tuminauskaite",
      "Peter S. Park",
      "Philip E. Tetlock"
    ],
    "abstract": "Human forecasting accuracy in practice relies on the 'wisdom of the crowd'\neffect, in which predictions about future events are significantly improved by\naggregating across a crowd of individual forecasters. Past work on the\nforecasting ability of large language models (LLMs) suggests that frontier\nLLMs, as individual forecasters, underperform compared to the gold standard of\na human crowd forecasting tournament aggregate. In Study 1, we expand this\nresearch by using an LLM ensemble approach consisting of a crowd of twelve\nLLMs. We compare the aggregated LLM predictions on 31 binary questions to that\nof a crowd of 925 human forecasters from a three-month forecasting tournament.\nOur preregistered main analysis shows that the LLM crowd outperforms a simple\nno-information benchmark and is not statistically different from the human\ncrowd. In exploratory analyses, we find that these two approaches are\nequivalent with respect to medium-effect-size equivalence bounds. We also\nobserve an acquiescence effect, with mean model predictions being significantly\nabove 50%, despite an almost even split of positive and negative resolutions.\nMoreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2)\ncan be improved by drawing on human cognitive output. We find that both models'\nforecasting accuracy benefits from exposure to the median human prediction as\ninformation, improving accuracy by between 17% and 28%: though this leads to\nless accurate predictions than simply averaging human and machine forecasts.\nOur results suggest that LLMs can achieve forecasting accuracy rivaling that of\nhuman crowd forecasting tournaments: via the simple, practically applicable\nmethod of forecast aggregation. This replicates the 'wisdom of the crowd'\neffect for LLMs, and opens up their use for a variety of applications\nthroughout society.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "20 pages; 13 visualizations (nine figures, four tables)",
    "pdf_url": "http://arxiv.org/pdf/2402.19379v6",
    "published_date": "2024-02-29 17:27:59 UTC",
    "updated_date": "2024-07-22 13:50:27 UTC"
  },
  {
    "arxiv_id": "2402.19371v1",
    "title": "OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models",
    "authors": [
      "Jenish Maharjan",
      "Anurag Garikipati",
      "Navan Preet Singh",
      "Leo Cyrus",
      "Mayank Sharma",
      "Madalina Ciobanu",
      "Gina Barnes",
      "Rahul Thapa",
      "Qingqing Mao",
      "Ritankar Das"
    ],
    "abstract": "LLMs have become increasingly capable at accomplishing a range of\nspecialized-tasks and can be utilized to expand equitable access to medical\nknowledge. Most medical LLMs have involved extensive fine-tuning, leveraging\nspecialized medical data and significant, thus costly, amounts of computational\npower. Many of the top performing LLMs are proprietary and their access is\nlimited to very few research groups. However, open-source (OS) models represent\na key area of growth for medical LLMs due to significant improvements in\nperformance and an inherent ability to provide the transparency and compliance\nrequired in healthcare. We present OpenMedLM, a prompting platform which\ndelivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks.\nWe evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks\n(MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of\nprompting strategies, including zero-shot, few-shot, chain-of-thought (random\nselection and kNN selection), and ensemble/self-consistency voting. We found\nthat OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks,\nsurpassing the previous best performing OS models that leveraged\ncomputationally costly extensive fine-tuning. The model delivers a 72.6%\naccuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and\nachieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the\nfirst OS LLM to surpass 80% accuracy on this benchmark. Our results highlight\nmedical-specific emergent properties in OS LLMs which have not yet been\ndocumented to date elsewhere, and showcase the benefits of further leveraging\nprompt engineering to improve the performance of accessible LLMs for medical\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19371v1",
    "published_date": "2024-02-29 17:19:39 UTC",
    "updated_date": "2024-02-29 17:19:39 UTC"
  },
  {
    "arxiv_id": "2402.19366v3",
    "title": "Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency",
    "authors": [
      "Akila Wickramasekara",
      "Frank Breitinger",
      "Mark Scanlon"
    ],
    "abstract": "The ever-increasing workload of digital forensic labs raises concerns about\nlaw enforcement's ability to conduct both cyber-related and non-cyber-related\ninvestigations promptly. Consequently, this article explores the potential and\nusefulness of integrating Large Language Models (LLMs) into digital forensic\ninvestigations to address challenges such as bias, explainability, censorship,\nresource-intensive infrastructure, and ethical and legal considerations. A\ncomprehensive literature review is carried out, encompassing existing digital\nforensic models, tools, LLMs, deep learning techniques, and the use of LLMs in\ninvestigations. The review identifies current challenges within existing\ndigital forensic processes and explores both the obstacles and the\npossibilities of incorporating LLMs. In conclusion, the study states that the\nadoption of LLMs in digital forensics, with appropriate constraints, has the\npotential to improve investigation efficiency, improve traceability, and\nalleviate the technical and judicial barriers faced by law enforcement\nentities.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19366v3",
    "published_date": "2024-02-29 17:13:44 UTC",
    "updated_date": "2025-01-31 08:27:13 UTC"
  },
  {
    "arxiv_id": "2402.19361v2",
    "title": "Watermark Stealing in Large Language Models",
    "authors": [
      "Nikola JovanoviÄ",
      "Robin Staab",
      "Martin Vechev"
    ],
    "abstract": "LLM watermarking has attracted attention as a promising way to detect\nAI-generated content, with some works suggesting that current schemes may\nalready be fit for deployment. In this work we dispute this claim, identifying\nwatermark stealing (WS) as a fundamental vulnerability of these schemes. We\nshow that querying the API of the watermarked LLM to approximately\nreverse-engineer a watermark enables practical spoofing attacks, as\nhypothesized in prior work, but also greatly boosts scrubbing attacks, which\nwas previously unnoticed. We are the first to propose an automated WS algorithm\nand use it in the first comprehensive study of spoofing and scrubbing in\nrealistic settings. We show that for under $50 an attacker can both spoof and\nscrub state-of-the-art schemes previously considered safe, with average success\nrate of over 80%. Our findings challenge common beliefs about LLM watermarking,\nstressing the need for more robust schemes. We make all our code and additional\nexamples available at https://watermark-stealing.org.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.19361v2",
    "published_date": "2024-02-29 17:12:39 UTC",
    "updated_date": "2024-06-24 14:48:29 UTC"
  },
  {
    "arxiv_id": "2402.19348v2",
    "title": "Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook",
    "authors": [
      "Xingchen Zou",
      "Yibo Yan",
      "Xixuan Hao",
      "Yuehong Hu",
      "Haomin Wen",
      "Erdong Liu",
      "Junbo Zhang",
      "Yong Li",
      "Tianrui Li",
      "Yu Zheng",
      "Yuxuan Liang"
    ],
    "abstract": "As cities continue to burgeon, Urban Computing emerges as a pivotal\ndiscipline for sustainable development by harnessing the power of cross-domain\ndata fusion from diverse sources (e.g., geographical, traffic, social media,\nand environmental data) and modalities (e.g., spatio-temporal, visual, and\ntextual modalities). Recently, we are witnessing a rising trend that utilizes\nvarious deep-learning methods to facilitate cross-domain data fusion in smart\ncities. To this end, we propose the first survey that systematically reviews\nthe latest advancements in deep learning-based data fusion methods tailored for\nurban computing. Specifically, we first delve into data perspective to\ncomprehend the role of each modality and data source. Secondly, we classify the\nmethodology into four primary categories: feature-based, alignment-based,\ncontrast-based, and generation-based fusion methods. Thirdly, we further\ncategorize multi-modal urban applications into seven types: urban planning,\ntransportation, economy, public safety, society, environment, and energy.\nCompared with previous surveys, we focus more on the synergy of deep learning\nmethods with urban computing applications. Furthermore, we shed light on the\ninterplay between Large Language Models (LLMs) and urban computing, postulating\nfuture research directions that could revolutionize the field. We firmly\nbelieve that the taxonomy, progress, and prospects delineated in our survey\nstand poised to significantly enrich the research community. The summary of the\ncomprehensive and up-to-date paper list can be found at\nhttps://github.com/yoshall/Awesome-Multimodal-Urban-Computing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19348v2",
    "published_date": "2024-02-29 16:56:23 UTC",
    "updated_date": "2024-06-16 10:16:00 UTC"
  },
  {
    "arxiv_id": "2402.19339v1",
    "title": "Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification",
    "authors": [
      "Delfina Sol Martinez Pandiani",
      "Nicolas Lazzari",
      "Valentina Presutti"
    ],
    "abstract": "The increasing demand for automatic high-level image understanding,\nparticularly in detecting abstract concepts (AC) within images, underscores the\nnecessity for innovative and more interpretable approaches. These approaches\nneed to harmonize traditional deep vision methods with the nuanced,\ncontext-dependent knowledge humans employ to interpret images at intricate\nsemantic levels. In this work, we leverage situated perceptual knowledge of\ncultural images to enhance performance and interpretability in AC image\nclassification. We automatically extract perceptual semantic units from images,\nwhich we then model and integrate into the ARTstract Knowledge Graph (AKG).\nThis resource captures situated perceptual semantics gleaned from over 14,000\ncultural images labeled with ACs. Additionally, we enhance the AKG with\nhigh-level linguistic frames. We compute KG embeddings and experiment with\nrelative representations and hybrid approaches that fuse these embeddings with\nvisual transformer embeddings. Finally, for interpretability, we conduct\nposthoc qualitative analyses by examining model similarities with training\ninstances. Our results show that our hybrid KGE-ViT methods outperform existing\ntechniques in AC image classification. The posthoc interpretability analyses\nreveal the visual transformer's proficiency in capturing pixel-level visual\nattributes, contrasting with our method's efficacy in representing more\nabstract and semantic scene elements. We demonstrate the synergy and\ncomplementarity between KGE embeddings' situated perceptual knowledge and deep\nvisual model's sensory-perceptual understanding for AC image classification.\nThis work suggests a strong potential of neuro-symbolic methods for knowledge\nintegration and robust image representation for use in downstream intricate\nvisual comprehension tasks. All the materials and code are available online.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.19339v1",
    "published_date": "2024-02-29 16:46:48 UTC",
    "updated_date": "2024-02-29 16:46:48 UTC"
  },
  {
    "arxiv_id": "2403.00046v2",
    "title": "SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation",
    "authors": [
      "Xue Jiang",
      "Yihong Dong",
      "Zhi Jin",
      "Ge Li"
    ],
    "abstract": "Although Large Language Models (LLMs) have made significant progress in code\ngeneration, they still struggle with code generation tasks in specific\nscenarios. These scenarios usually necessitate the adaptation of LLMs to\nfulfill specific needs, but the limited training samples available in practice\nlead to poor code generation performance. Therefore, how to effectively adapt\nLLMs to new scenarios with few training samples is a major challenge for\ncurrent code generation. In this paper, we propose a novel adaptation approach\nnamed SEED, which stands for Sample-Efficient adaptation with Error-Driven\nlearning for code generation. SEED leverages the errors made by LLMs as\nlearning opportunities, using error revision to overcome its own shortcomings,\nthus achieving efficient learning. Specifically, SEED involves identifying\nerror code generated by LLMs, employing Self-revise for code revision,\noptimizing the model with revised code, and iteratively adapting the process\nfor continuous improvement. Experimental results show that, compared to other\nmainstream fine-tuning approaches, SEED achieves superior performance with few\ntraining samples, showing an average relative improvement of 54.7% in Pass@1 on\nmultiple code generation benchmarks. We also validate the effectiveness of\nSelf-revise, which generates revised code that optimizes the model more\nefficiently compared to the code samples from datasets. Moreover, SEED\nconsistently demonstrates strong performance across various LLMs, underscoring\nits generalizability.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00046v2",
    "published_date": "2024-02-29 16:09:02 UTC",
    "updated_date": "2024-03-23 16:51:11 UTC"
  },
  {
    "arxiv_id": "2402.19299v1",
    "title": "RL-GPT: Integrating Reinforcement Learning and Code-as-policy",
    "authors": [
      "Shaoteng Liu",
      "Haoqi Yuan",
      "Minda Hu",
      "Yanwei Li",
      "Yukang Chen",
      "Shu Liu",
      "Zongqing Lu",
      "Jiaya Jia"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated proficiency in utilizing\nvarious tools by coding, yet they face limitations in handling intricate logic\nand precise control. In embodied tasks, high-level planning is amenable to\ndirect coding, while low-level actions often necessitate task-specific\nrefinement, such as Reinforcement Learning (RL). To seamlessly integrate both\nmodalities, we introduce a two-level hierarchical framework, RL-GPT, comprising\na slow agent and a fast agent. The slow agent analyzes actions suitable for\ncoding, while the fast agent executes coding tasks. This decomposition\neffectively focuses each agent on specific tasks, proving highly efficient\nwithin our pipeline. Our approach outperforms traditional RL methods and\nexisting GPT agents, demonstrating superior efficiency. In the Minecraft game,\nit rapidly obtains diamonds within a single day on an RTX3090. Additionally, it\nachieves SOTA performance across all designated MineDojo tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19299v1",
    "published_date": "2024-02-29 16:07:22 UTC",
    "updated_date": "2024-02-29 16:07:22 UTC"
  },
  {
    "arxiv_id": "2402.19294v1",
    "title": "Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes",
    "authors": [
      "Ying Fu",
      "Ye Kwon Huh",
      "Kaibo Liu"
    ],
    "abstract": "Operating units often experience various failure modes in complex systems,\nleading to distinct degradation paths. Relying on a prognostic model trained on\na single failure mode may lead to poor generalization performance across\nmultiple failure modes. Therefore, accurately identifying the failure mode is\nof critical importance. Current prognostic approaches either ignore failure\nmodes during degradation or assume known failure mode labels, which can be\nchallenging to acquire in practice. Moreover, the high dimensionality and\ncomplex relations of sensor signals make it challenging to identify the failure\nmodes accurately. To address these issues, we propose a novel failure mode\ndiagnosis method that leverages a dimension reduction technique called UMAP\n(Uniform Manifold Approximation and Projection) to project and visualize each\nunit's degradation trajectory into a lower dimension. Then, using these\ndegradation trajectories, we develop a time series-based clustering method to\nidentify the training units' failure modes. Finally, we introduce a\nmonotonically constrained prognostic model to predict the failure mode labels\nand RUL of the test units simultaneously using the obtained failure modes of\nthe training units. The proposed prognostic model provides failure\nmode-specific RUL predictions while preserving the monotonic property of the\nRUL predictions across consecutive time steps. We evaluate the proposed model\nusing a case study with the aircraft gas turbine engine dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19294v1",
    "published_date": "2024-02-29 15:57:09 UTC",
    "updated_date": "2024-02-29 15:57:09 UTC"
  },
  {
    "arxiv_id": "2402.19267v2",
    "title": "Robust Guidance for Unsupervised Data Selection: Capturing Perplexing Named Entities for Domain-Specific Machine Translation",
    "authors": [
      "Seunghyun Ji",
      "Hagai Raja Sinulingga",
      "Darongsae Kwon"
    ],
    "abstract": "Low-resourced data presents a significant challenge for neural machine\ntranslation. In most cases, the low-resourced environment is caused by high\ncosts due to the need for domain experts or the lack of language experts.\nTherefore, identifying the most training-efficient data within an unsupervised\nsetting emerges as a practical strategy. Recent research suggests that such\neffective data can be identified by selecting 'appropriately complex data'\nbased on its volume, providing strong intuition for unsupervised data\nselection. However, we have discovered that establishing criteria for\nunsupervised data selection remains a challenge, as the 'appropriate level of\ndifficulty' may vary depending on the data domain. We introduce a novel\nunsupervised data selection method named 'Capturing Perplexing Named Entities,'\nwhich leverages the maximum inference entropy in translated named entities as a\nmetric for selection. When tested with the 'Korean-English Parallel Corpus of\nSpecialized Domains,' our method served as robust guidance for identifying\ntraining-efficient data across different domains, in contrast to existing\nmethods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 3 figures, 5 tables. Oral presentation was given in SIGUL\n  2024, a satellite workshop of LREC-COLING 2024\n  (https://sigul-2024.ilc.cnr.it/wp-content/uploads/2024/05/Ji-et-al.pdf)",
    "pdf_url": "http://arxiv.org/pdf/2402.19267v2",
    "published_date": "2024-02-29 15:38:28 UTC",
    "updated_date": "2024-05-21 17:19:37 UTC"
  },
  {
    "arxiv_id": "2402.19265v1",
    "title": "Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach",
    "authors": [
      "Daniele Meli",
      "Alberto Castellini",
      "Alessandro Farinelli"
    ],
    "abstract": "Partially Observable Markov Decision Processes (POMDPs) are a powerful\nframework for planning under uncertainty. They allow to model state uncertainty\nas a belief probability distribution. Approximate solvers based on Monte Carlo\nsampling show great success to relax the computational demand and perform\nonline planning. However, scaling to complex realistic domains with many\nactions and long planning horizons is still a major challenge, and a key point\nto achieve good performance is guiding the action-selection process with\ndomain-dependent policy heuristics which are tailored for the specific\napplication domain. We propose to learn high-quality heuristics from POMDP\ntraces of executions generated by any solver. We convert the belief-action\npairs to a logical semantics, and exploit data- and time-efficient Inductive\nLogic Programming (ILP) to generate interpretable belief-based policy\nspecifications, which are then used as online heuristics. We evaluate\nthoroughly our methodology on two notoriously challenging POMDP problems,\ninvolving large action spaces and long planning horizons, namely, rocksample\nand pocman. Considering different state-of-the-art online POMDP solvers,\nincluding POMCP, DESPOT and AdaOPS, we show that learned heuristics expressed\nin Answer Set Programming (ASP) yield performance superior to neural networks\nand similar to optimal handcrafted task-specific heuristics within lower\ncomputational time. Moreover, they well generalize to more challenging\nscenarios not experienced in the training phase (e.g., increasing rocks and\ngrid size in rocksample, incrementing the size of the map and the aggressivity\nof ghosts in pocman).",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19265v1",
    "published_date": "2024-02-29 15:36:01 UTC",
    "updated_date": "2024-02-29 15:36:01 UTC"
  },
  {
    "arxiv_id": "2402.19263v1",
    "title": "Spinal Osteophyte Detection via Robust Patch Extraction on minimally annotated X-rays",
    "authors": [
      "Soumya Snigdha Kundu",
      "Yuanhan Mo",
      "Nicharee Srikijkasemwat",
      "BartÅomiej W. Papiez"
    ],
    "abstract": "The development and progression of arthritis is strongly associated with\nosteophytes, which are small and elusive bone growths. This paper presents one\nof the first efforts towards automated spinal osteophyte detection in spinal\nX-rays. A novel automated patch extraction process, called SegPatch, has been\nproposed based on deep learning-driven vertebrae segmentation and the\nenlargement of mask contours. A final patch classification accuracy of 84.5\\%\nis secured, surpassing a baseline tiling-based patch generation technique by\n9.5%. This demonstrates that even with limited annotations, SegPatch can\ndeliver superior performance for detection of tiny structures such as\nosteophytes. The proposed approach has potential to assist clinicians in\nexpediting the process of manually identifying osteophytes in spinal X-ray.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ISBI'24 Full Paper",
    "pdf_url": "http://arxiv.org/pdf/2402.19263v1",
    "published_date": "2024-02-29 15:32:25 UTC",
    "updated_date": "2024-02-29 15:32:25 UTC"
  },
  {
    "arxiv_id": "2405.00031v1",
    "title": "SegNet: A Segmented Deep Learning based Convolutional Neural Network Approach for Drones Wildfire Detection",
    "authors": [
      "Aditya V. Jonnalagadda",
      "Hashim A. Hashim"
    ],
    "abstract": "This research addresses the pressing challenge of enhancing processing times\nand detection capabilities in Unmanned Aerial Vehicle (UAV)/drone imagery for\nglobal wildfire detection, despite limited datasets. Proposing a Segmented\nNeural Network (SegNet) selection approach, we focus on reducing feature maps\nto boost both time resolution and accuracy significantly advancing processing\nspeeds and accuracy in real-time wildfire detection. This paper contributes to\nincreased processing speeds enabling real-time detection capabilities for\nwildfire, increased detection accuracy of wildfire, and improved detection\ncapabilities of early wildfire, through proposing a new direction for image\nclassification of amorphous objects like fire, water, smoke, etc. Employing\nConvolutional Neural Networks (CNNs) for image classification, emphasizing on\nthe reduction of irrelevant features vital for deep learning processes,\nespecially in live feed data for fire detection. Amidst the complexity of live\nfeed data in fire detection, our study emphasizes on image feed, highlighting\nthe urgency to enhance real-time processing. Our proposed algorithm combats\nfeature overload through segmentation, addressing challenges arising from\ndiverse features like objects, colors, and textures. Notably, a delicate\nbalance of feature map size and dataset adequacy is pivotal. Several research\npapers use smaller image sizes, compromising feature richness which\nnecessitating a new approach. We illuminate the critical role of pixel density\nin retaining essential details, especially for early wildfire detection. By\ncarefully selecting number of filters during training, we underscore the\nsignificance of higher pixel density for proper feature selection. The proposed\nSegNet approach is rigorously evaluated using real-world dataset obtained by a\ndrone flight and compared to state-of-the-art literature.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00031v1",
    "published_date": "2024-02-29 15:23:12 UTC",
    "updated_date": "2024-02-29 15:23:12 UTC"
  },
  {
    "arxiv_id": "2402.19251v1",
    "title": "A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving",
    "authors": [
      "Haicheng Liao",
      "Yongkang Li",
      "Zhenning Li",
      "Chengyue Wang",
      "Zhiyong Cui",
      "Shengbo Eben Li",
      "Chengzhong Xu"
    ],
    "abstract": "In autonomous vehicle (AV) technology, the ability to accurately predict the\nmovements of surrounding vehicles is paramount for ensuring safety and\noperational efficiency. Incorporating human decision-making insights enables\nAVs to more effectively anticipate the potential actions of other vehicles,\nsignificantly improving prediction accuracy and responsiveness in dynamic\nenvironments. This paper introduces the Human-Like Trajectory Prediction (HLTP)\nmodel, which adopts a teacher-student knowledge distillation framework inspired\nby human cognitive processes. The HLTP model incorporates a sophisticated\nteacher-student knowledge distillation framework. The \"teacher\" model, equipped\nwith an adaptive visual sector, mimics the visual processing of the human\nbrain, particularly the functions of the occipital and temporal lobes. The\n\"student\" model focuses on real-time interaction and decision-making, drawing\nparallels to prefrontal and parietal cortex functions. This approach allows for\ndynamic adaptation to changing driving scenarios, capturing essential\nperceptual cues for accurate prediction. Evaluated using the Macao Connected\nand Autonomous Driving (MoCAD) dataset, along with the NGSIM and HighD\nbenchmarks, HLTP demonstrates superior performance compared to existing models,\nparticularly in challenging environments with incomplete data. The project page\nis available at Github.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19251v1",
    "published_date": "2024-02-29 15:22:26 UTC",
    "updated_date": "2024-02-29 15:22:26 UTC"
  },
  {
    "arxiv_id": "2403.00044v1",
    "title": "Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC",
    "authors": [
      "Sikun Yang",
      "Heinz Koeppl"
    ],
    "abstract": "The edge partition model (EPM) is a generative model for extracting an\noverlapping community structure from static graph-structured data. In the EPM,\nthe gamma process (GaP) prior is adopted to infer the appropriate number of\nlatent communities, and each vertex is endowed with a gamma distributed\npositive memberships vector. Despite having many attractive properties,\ninference in the EPM is typically performed using Markov chain Monte Carlo\n(MCMC) methods that prevent it from being applied to massive network data. In\nthis paper, we generalize the EPM to account for dynamic enviroment by\nrepresenting each vertex with a positive memberships vector constructed using\nDirichlet prior specification, and capturing the time-evolving behaviour of\nvertices via a Dirichlet Markov chain construction. A simple-to-implement Gibbs\nsampler is proposed to perform posterior computation using Negative- Binomial\naugmentation technique. For large network data, we propose a stochastic\ngradient Markov chain Monte Carlo (SG-MCMC) algorithm for scalable inference in\nthe proposed model. The experimental results show that the novel methods\nachieve competitive performance in terms of link prediction, while being much\nfaster.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00044v1",
    "published_date": "2024-02-29 15:19:35 UTC",
    "updated_date": "2024-02-29 15:19:35 UTC"
  },
  {
    "arxiv_id": "2403.07924v2",
    "title": "AI and Identity",
    "authors": [
      "Sri Yash Tadimalla",
      "Mary Lou Maher"
    ],
    "abstract": "AI-empowered technologies' impact on the world is undeniable, reshaping\nindustries, revolutionizing how humans interact with technology, transforming\neducational paradigms, and redefining social codes. However, this rapid growth\nis accompanied by two notable challenges: a lack of diversity within the AI\nfield and a widening AI divide. In this context, This paper examines the\nintersection of AI and identity as a pathway to understand biases,\ninequalities, and ethical considerations in AI development and deployment. We\npresent a multifaceted definition of AI identity, which encompasses its\ncreators, applications, and their broader impacts. Understanding AI's identity\ninvolves understanding the associations between the individuals involved in\nAI's development, the technologies produced, and the social, ethical, and\npsychological implications. After exploring the AI identity ecosystem and its\nsocietal dynamics, We propose a framework that highlights the need for\ndiversity in AI across three dimensions: Creators, Creations, and Consequences\nthrough the lens of identity. This paper proposes the need for a comprehensive\napproach to fostering a more inclusive and responsible AI ecosystem through the\nlens of identity.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages, 4 figures, AAAI Spring Symposium",
    "pdf_url": "http://arxiv.org/pdf/2403.07924v2",
    "published_date": "2024-02-29 15:07:30 UTC",
    "updated_date": "2024-04-10 18:08:57 UTC"
  },
  {
    "arxiv_id": "2402.19197v2",
    "title": "Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction",
    "authors": [
      "Kennard Yanting Chan",
      "Fayao Liu",
      "Guosheng Lin",
      "Chuan Sheng Foo",
      "Weisi Lin"
    ],
    "abstract": "Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for\nsingle-view clothed human reconstruction. These models need to be trained using\na sampling training scheme. Existing sampling training schemes either fail to\ncapture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in\nreconstructed meshes. To address these problems, we introduce Fine\nStructured-Aware Sampling (FSS), a new sampling training scheme to train\npixel-aligned implicit models for single-view human reconstruction. FSS\nresolves the aforementioned problems by proactively adapting to the thickness\nand complexity of surfaces. In addition, unlike existing sampling training\nschemes, FSS shows how normals of sample points can be capitalized in the\ntraining process to improve results. Lastly, to further improve the training\nprocess, FSS proposes a mesh thickness loss signal for pixel-aligned implicit\nmodels. It becomes computationally feasible to introduce this loss once a\nslight reworking of the pixel-aligned implicit function framework is carried\nout. Our results show that our methods significantly outperform SOTA methods\nqualitatively and quantitatively. Our code is publicly available at\nhttps://github.com/kcyt/FSS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in Proceedings of the AAAI Conference on Artificial\n  Intelligence, 2024 (AAAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.19197v2",
    "published_date": "2024-02-29 14:26:46 UTC",
    "updated_date": "2024-11-11 14:04:57 UTC"
  },
  {
    "arxiv_id": "2402.19195v2",
    "title": "Negative Sampling in Knowledge Graph Representation Learning: A Review",
    "authors": [
      "Tiroshan Madushanka",
      "Ryutaro Ichise"
    ],
    "abstract": "Knowledge Graph Representation Learning (KGRL), or Knowledge Graph Embedding\n(KGE), is essential for AI applications such as knowledge construction and\ninformation retrieval. These models encode entities and relations into\nlower-dimensional vectors, supporting tasks like link prediction and\nrecommendation systems. Training KGE models relies on both positive and\nnegative samples for effective learning, but generating high-quality negative\nsamples from existing knowledge graphs is challenging. The quality of these\nsamples significantly impacts the model's accuracy. This comprehensive survey\npaper systematically reviews various negative sampling (NS) methods and their\ncontributions to the success of KGRL. Their respective advantages and\ndisadvantages are outlined by categorizing existing NS methods into six\ndistinct categories. Moreover, this survey identifies open research questions\nthat serve as potential directions for future investigations. By offering a\ngeneralization and alignment of fundamental NS concepts, this survey provides\nvaluable insights for designing effective NS methods in the context of KGRL and\nserves as a motivating force for further advancements in the field.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19195v2",
    "published_date": "2024-02-29 14:26:20 UTC",
    "updated_date": "2024-10-21 02:30:50 UTC"
  },
  {
    "arxiv_id": "2402.19173v1",
    "title": "StarCoder 2 and The Stack v2: The Next Generation",
    "authors": [
      "Anton Lozhkov",
      "Raymond Li",
      "Loubna Ben Allal",
      "Federico Cassano",
      "Joel Lamy-Poirier",
      "Nouamane Tazi",
      "Ao Tang",
      "Dmytro Pykhtar",
      "Jiawei Liu",
      "Yuxiang Wei",
      "Tianyang Liu",
      "Max Tian",
      "Denis Kocetkov",
      "Arthur Zucker",
      "Younes Belkada",
      "Zijian Wang",
      "Qian Liu",
      "Dmitry Abulkhanov",
      "Indraneil Paul",
      "Zhuang Li",
      "Wen-Ding Li",
      "Megan Risdal",
      "Jia Li",
      "Jian Zhu",
      "Terry Yue Zhuo",
      "Evgenii Zheltonozhskii",
      "Nii Osae Osae Dade",
      "Wenhao Yu",
      "Lucas KrauÃ",
      "Naman Jain",
      "Yixuan Su",
      "Xuanli He",
      "Manan Dey",
      "Edoardo Abati",
      "Yekun Chai",
      "Niklas Muennighoff",
      "Xiangru Tang",
      "Muhtasham Oblokulov",
      "Christopher Akiki",
      "Marc Marone",
      "Chenghao Mou",
      "Mayank Mishra",
      "Alex Gu",
      "Binyuan Hui",
      "Tri Dao",
      "Armel Zebaze",
      "Olivier Dehaene",
      "Nicolas Patry",
      "Canwen Xu",
      "Julian McAuley",
      "Han Hu",
      "Torsten Scholak",
      "Sebastien Paquet",
      "Jennifer Robinson",
      "Carolyn Jane Anderson",
      "Nicolas Chapados",
      "Mostofa Patwary",
      "Nima Tajbakhsh",
      "Yacine Jernite",
      "Carlos MuÃ±oz Ferrandis",
      "Lingming Zhang",
      "Sean Hughes",
      "Thomas Wolf",
      "Arjun Guha",
      "Leandro von Werra",
      "Harm de Vries"
    ],
    "abstract": "The BigCode project, an open-scientific collaboration focused on the\nresponsible development of Large Language Models for Code (Code LLMs),\nintroduces StarCoder2. In partnership with Software Heritage (SWH), we build\nThe Stack v2 on top of the digital commons of their source code archive.\nAlongside the SWH repositories spanning 619 programming languages, we carefully\nselect other high-quality data sources, such as GitHub pull requests, Kaggle\nnotebooks, and code documentation. This results in a training set that is 4x\nlarger than the first StarCoder dataset. We train StarCoder2 models with 3B,\n7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate\nthem on a comprehensive set of Code LLM benchmarks. We find that our small\nmodel, StarCoder2-3B, outperforms other Code LLMs of similar size on most\nbenchmarks, and also outperforms StarCoderBase-15B. Our large model,\nStarCoder2- 15B, significantly outperforms other models of comparable size. In\naddition, it matches or outperforms CodeLlama-34B, a model more than twice its\nsize. Although DeepSeekCoder- 33B is the best-performing model at code\ncompletion for high-resource languages, we find that StarCoder2-15B outperforms\nit on math and code reasoning benchmarks, as well as several low-resource\nlanguages. We make the model weights available under an OpenRAIL license and\nensure full transparency regarding the training data by releasing the SoftWare\nHeritage persistent IDentifiers (SWHIDs) of the source code data.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19173v1",
    "published_date": "2024-02-29 13:53:35 UTC",
    "updated_date": "2024-02-29 13:53:35 UTC"
  },
  {
    "arxiv_id": "2402.19170v2",
    "title": "Improving Legal Judgement Prediction in Romanian with Long Text Encoders",
    "authors": [
      "Mihai Masala",
      "Traian Rebedea",
      "Horia Velicu"
    ],
    "abstract": "In recent years,the entire field of Natural Language Processing (NLP) has\nenjoyed amazing novel results achieving almost human-like performance on a\nvariety of tasks. Legal NLP domain has also been part of this process, as it\nhas seen an impressive growth. However, general-purpose models are not readily\napplicable for legal domain. Due to the nature of the domain (e.g. specialized\nvocabulary, long documents) specific models and methods are often needed for\nLegal NLP. In this work we investigate both specialized and general models for\npredicting the final ruling of a legal case, task known as Legal Judgment\nPrediction (LJP). We particularly focus on methods to extend to sequence length\nof Transformer-based models to better understand the long documents present in\nlegal corpora. Extensive experiments on 4 LJP datasets in Romanian, originating\nfrom 2 sources with significantly different sizes and document lengths, show\nthat specialized models and handling long texts are critical for a good\nperformance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Rejected at LREC-COLING with 4/4/3",
    "pdf_url": "http://arxiv.org/pdf/2402.19170v2",
    "published_date": "2024-02-29 13:52:33 UTC",
    "updated_date": "2024-03-04 20:54:34 UTC"
  },
  {
    "arxiv_id": "2403.00843v2",
    "title": "Large Language Models are Learnable Planners for Long-Term Recommendation",
    "authors": [
      "Wentao Shi",
      "Xiangnan He",
      "Yang Zhang",
      "Chongming Gao",
      "Xinyue Li",
      "Jizhi Zhang",
      "Qifan Wang",
      "Fuli Feng"
    ],
    "abstract": "Planning for both immediate and long-term benefits becomes increasingly\nimportant in recommendation. Existing methods apply Reinforcement Learning (RL)\nto learn planning capacity by maximizing cumulative reward for long-term\nrecommendation. However, the scarcity of recommendation data presents\nchallenges such as instability and susceptibility to overfitting when training\nRL models from scratch, resulting in sub-optimal performance. In this light, we\npropose to leverage the remarkable planning capabilities over sparse data of\nLarge Language Models (LLMs) for long-term recommendation. The key to achieving\nthe target lies in formulating a guidance plan following principles of\nenhancing long-term engagement and grounding the plan to effective and\nexecutable actions in a personalized manner. To this end, we propose a Bi-level\nLearnable LLM Planner framework, which consists of a set of LLM instances and\nbreaks down the learning process into macro-learning and micro-learning to\nlearn macro-level guidance and micro-level personalized recommendation\npolicies, respectively. Extensive experiments validate that the framework\nfacilitates the planning ability of LLMs for long-term recommendation. Our code\nand data can be found at https://github.com/jizhi-zhang/BiLLP.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00843v2",
    "published_date": "2024-02-29 13:49:56 UTC",
    "updated_date": "2024-04-26 07:41:07 UTC"
  },
  {
    "arxiv_id": "2402.19161v2",
    "title": "MemoNav: Working Memory Model for Visual Navigation",
    "authors": [
      "Hongxin Li",
      "Zeyu Wang",
      "Xu Yang",
      "Yuran Yang",
      "Shuqi Mei",
      "Zhaoxiang Zhang"
    ],
    "abstract": "Image-goal navigation is a challenging task that requires an agent to\nnavigate to a goal indicated by an image in unfamiliar environments. Existing\nmethods utilizing diverse scene memories suffer from inefficient exploration\nsince they use all historical observations for decision-making without\nconsidering the goal-relevant fraction. To address this limitation, we present\nMemoNav, a novel memory model for image-goal navigation, which utilizes a\nworking memory-inspired pipeline to improve navigation performance.\nSpecifically, we employ three types of navigation memory. The node features on\na map are stored in the short-term memory (STM), as these features are\ndynamically updated. A forgetting module then retains the informative STM\nfraction to increase efficiency. We also introduce long-term memory (LTM) to\nlearn global scene representations by progressively aggregating STM features.\nSubsequently, a graph attention module encodes the retained STM and the LTM to\ngenerate working memory (WM) which contains the scene features essential for\nefficient navigation. The synergy among these three memory types boosts\nnavigation performance by enabling the agent to learn and leverage\ngoal-relevant scene features within a topological map. Our evaluation on\nmulti-goal tasks demonstrates that MemoNav significantly outperforms previous\nmethods across all difficulty levels in both Gibson and Matterport3D scenes.\nQualitative results further illustrate that MemoNav plans more efficient\nroutes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2024. Code: https://github.com/ZJULiHongxin/MemoNav",
    "pdf_url": "http://arxiv.org/pdf/2402.19161v2",
    "published_date": "2024-02-29 13:45:13 UTC",
    "updated_date": "2024-03-28 04:07:57 UTC"
  },
  {
    "arxiv_id": "2402.19135v2",
    "title": "Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool",
    "authors": [
      "Liudmila Zavolokina",
      "Kilian Sprenkamp",
      "Zoya Katashinskaya",
      "Daniel Gordon Jones",
      "Gerhard Schwabe"
    ],
    "abstract": "In today's digital age, characterized by rapid news consumption and\nincreasing vulnerability to propaganda, fostering citizens' critical thinking\nis crucial for stable democracies. This paper introduces the design of\nClarifAI, a novel automated propaganda detection tool designed to nudge readers\ntowards more critical news consumption by activating the analytical mode of\nthinking, following Kahneman's dual-system theory of cognition. Using Large\nLanguage Models, ClarifAI detects propaganda in news articles and provides\ncontext-rich explanations, enhancing users' understanding and critical\nthinking. Our contribution is threefold: first, we propose the design of\nClarifAI; second, in an online experiment, we demonstrate that this design\neffectively encourages news readers to engage in more critical reading; and\nthird, we emphasize the value of explanations for fostering critical thinking.\nThe study thus offers both a practical tool and useful design knowledge for\nmitigating propaganda in digital news.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "The paper is accepted for publication in proceedings of the CHI\n  Conference on Human Factors in Computing Systems (2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.19135v2",
    "published_date": "2024-02-29 13:12:31 UTC",
    "updated_date": "2024-08-06 14:53:43 UTC"
  },
  {
    "arxiv_id": "2402.19116v2",
    "title": "How to Understand \"Support\"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding",
    "authors": [
      "Jiamin Luo",
      "Jianing Zhao",
      "Jingjing Wang",
      "Guodong Zhou"
    ],
    "abstract": "Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the\nfine-grained phrase-region matching, while merely leveraging the coarse-grained\nsentence-image pairs for training. However, existing studies on WPG largely\nignore the implicit phrase-region matching relations, which are crucial for\nevaluating the capability of models in understanding the deep multimodal\nsemantics. To this end, this paper proposes an Implicit-Enhanced Causal\nInference (IECI) approach to address the challenges of modeling the implicit\nrelations and highlighting them beyond the explicit. Specifically, this\napproach leverages both the intervention and counterfactual techniques to\ntackle the above two challenges respectively. Furthermore, a high-quality\nimplicit-enhanced dataset is annotated to evaluate IECI and detailed\nevaluations show the great advantages of IECI over the state-of-the-art\nbaselines. Particularly, we observe an interesting finding that IECI\noutperforms the advanced multimodal LLMs by a large margin on this\nimplicit-enhanced dataset, which may facilitate more research to evaluate the\nmultimodal LLMs in this direction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19116v2",
    "published_date": "2024-02-29 12:49:48 UTC",
    "updated_date": "2024-03-04 08:42:56 UTC"
  },
  {
    "arxiv_id": "2402.19105v2",
    "title": "CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI",
    "authors": [
      "Domenique Zipperling",
      "Simeon Allmendinger",
      "Lukas Struppek",
      "Niklas KÃ¼hl"
    ],
    "abstract": "In the landscape of generative artificial intelligence, diffusion-based\nmodels present challenges for socio-technical systems in data requirements and\nprivacy. Traditional approaches like federated learning distribute the learning\nprocess but strain individual clients, especially with constrained resources\n(e.g., edge devices). In response to these challenges, we introduce CollaFuse,\na novel framework inspired by split learning. Tailored for efficient and\ncollaborative use of denoising diffusion probabilistic models, CollaFuse\nenables shared server training and inference, alleviating client computational\nburdens. This is achieved by retaining data and computationally inexpensive GPU\nprocesses locally at each client while outsourcing the computationally\nexpensive processes to the shared server. Demonstrated in a healthcare context,\nCollaFuse enhances privacy by highly reducing the need for sensitive\ninformation sharing. These capabilities hold the potential to impact various\napplication areas, such as the design of edge computing solutions, healthcare\nresearch, or autonomous driving. In essence, our work advances distributed\nmachine learning, shaping the future of collaborative GenAI networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Thirty-Second European Conference on Information Systems (ECIS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.19105v2",
    "published_date": "2024-02-29 12:36:10 UTC",
    "updated_date": "2024-08-16 11:28:13 UTC"
  },
  {
    "arxiv_id": "2402.19103v1",
    "title": "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models",
    "authors": [
      "Hongbang Yuan",
      "Pengfei Cao",
      "Zhuoran Jin",
      "Yubo Chen",
      "Daojian Zeng",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive capabilities but still\nsuffer from the issue of hallucinations. A significant type of this issue is\nthe false premise hallucination, which we define as the phenomenon when LLMs\ngenerate hallucinated text when confronted with false premise questions. In\nthis paper, we perform a comprehensive analysis of the false premise\nhallucination and elucidate its internal working mechanism: a small subset of\nattention heads (which we designate as false premise heads) disturb the\nknowledge extraction process, leading to the occurrence of false premise\nhallucination. Based on our analysis, we propose \\textbf{FAITH} (\\textbf{F}alse\npremise \\textbf{A}ttention head constra\\textbf{I}ining for mi\\textbf{T}igating\n\\textbf{H}allucinations), a novel and effective method to mitigate false\npremise hallucinations. It constrains the false premise attention heads during\nthe model inference process. Impressively, extensive experiments demonstrate\nthat constraining only approximately $1\\%$ of the attention heads in the model\nyields a notable increase of nearly $20\\%$ of model performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 5 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.19103v1",
    "published_date": "2024-02-29 12:35:45 UTC",
    "updated_date": "2024-02-29 12:35:45 UTC"
  },
  {
    "arxiv_id": "2402.19102v1",
    "title": "FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness",
    "authors": [
      "Matteo Gambella",
      "Fabrizio Pittorino",
      "Manuel Roveri"
    ],
    "abstract": "Neural Architecture Search (NAS) paves the way for the automatic definition\nof Neural Network (NN) architectures, attracting increasing research attention\nand offering solutions in various scenarios. This study introduces a novel NAS\nsolution, called Flat Neural Architecture Search (FlatNAS), which explores the\ninterplay between a novel figure of merit based on robustness to weight\nperturbations and single NN optimization with Sharpness-Aware Minimization\n(SAM). FlatNAS is the first work in the literature to systematically explore\nflat regions in the loss landscape of NNs in a NAS procedure, while jointly\noptimizing their performance on in-distribution data, their out-of-distribution\n(OOD) robustness, and constraining the number of parameters in their\narchitecture. Differently from current studies primarily concentrating on OOD\nalgorithms, FlatNAS successfully evaluates the impact of NN architectures on\nOOD robustness, a crucial aspect in real-world applications of machine and deep\nlearning. FlatNAS achieves a good trade-off between performance, OOD\ngeneralization, and the number of parameters, by using only in-distribution\ndata in the NAS exploration. The OOD robustness of the NAS-designed models is\nevaluated by focusing on robustness to input data corruptions, using popular\nbenchmark datasets in the literature.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19102v1",
    "published_date": "2024-02-29 12:33:14 UTC",
    "updated_date": "2024-02-29 12:33:14 UTC"
  },
  {
    "arxiv_id": "2402.19088v3",
    "title": "Survey in Characterization of Semantic Change",
    "authors": [
      "Jader Martins Camboim de SÃ¡",
      "Marcos Da Silveira",
      "CÃ©dric Pruski"
    ],
    "abstract": "Live languages continuously evolve to integrate the cultural change of human\nsocieties. This evolution manifests through neologisms (new words) or\n\\textbf{semantic changes} of words (new meaning to existing words).\nUnderstanding the meaning of words is vital for interpreting texts coming from\ndifferent cultures (regionalism or slang), domains (e.g., technical terms), or\nperiods. In computer science, these words are relevant to computational\nlinguistics algorithms such as translation, information retrieval, question\nanswering, etc. Semantic changes can potentially impact the quality of the\noutcomes of these algorithms. Therefore, it is important to understand and\ncharacterize these changes formally. The study of this impact is a recent\nproblem that has attracted the attention of the computational linguistics\ncommunity. Several approaches propose methods to detect semantic changes with\ngood precision, but more effort is needed to characterize how the meaning of\nwords changes and to reason about how to reduce the impact of semantic change.\nThis survey provides an understandable overview of existing approaches to the\n\\textit{characterization of semantic changes} and also formally defines three\nclasses of characterizations: if the meaning of a word becomes more general or\nnarrow (change in dimension) if the word is used in a more pejorative or\npositive/ameliorated sense (change in orientation), and if there is a trend to\nuse the word in a, for instance, metaphoric or metonymic context (change in\nrelation). We summarized the main aspects of the selected publications in a\ntable and discussed the needs and trends in the research activities on semantic\nchange characterization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19088v3",
    "published_date": "2024-02-29 12:13:50 UTC",
    "updated_date": "2024-07-18 12:28:27 UTC"
  },
  {
    "arxiv_id": "2402.19085v3",
    "title": "Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment",
    "authors": [
      "Yiju Guo",
      "Ganqu Cui",
      "Lifan Yuan",
      "Ning Ding",
      "Zexu Sun",
      "Bowen Sun",
      "Huimin Chen",
      "Ruobing Xie",
      "Jie Zhou",
      "Yankai Lin",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Alignment in artificial intelligence pursues the consistency between model\nresponses and human preferences as well as values. In practice, the\nmultifaceted nature of human preferences inadvertently introduces what is known\nas the \"alignment tax\" -a compromise where enhancements in alignment within one\nobjective (e.g.,harmlessness) can diminish performance in others\n(e.g.,helpfulness). However, existing alignment techniques are mostly\nunidirectional, leading to suboptimal trade-offs and poor flexibility over\nvarious objectives. To navigate this challenge, we argue the prominence of\ngrounding LLMs with evident preferences. We introduce controllable preference\noptimization (CPO), which explicitly specifies preference scores for different\nobjectives, thereby guiding the model to generate responses that meet the\nrequirements. Our experimental analysis reveals that the aligned models can\nprovide responses that match various preferences among the \"3H\" (helpfulness,\nhonesty, harmlessness) desiderata. Furthermore, by introducing diverse data and\nalignment goals, we surpass baseline methods in aligning with single\nobjectives, hence mitigating the impact of the alignment tax and achieving\nimprovements in multi-objective alignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2402.19085v3",
    "published_date": "2024-02-29 12:12:30 UTC",
    "updated_date": "2024-10-11 08:21:50 UTC"
  },
  {
    "arxiv_id": "2402.19078v3",
    "title": "Smooth Tchebycheff Scalarization for Multi-Objective Optimization",
    "authors": [
      "Xi Lin",
      "Xiaoyuan Zhang",
      "Zhiyuan Yang",
      "Fei Liu",
      "Zhenkun Wang",
      "Qingfu Zhang"
    ],
    "abstract": "Multi-objective optimization problems can be found in many real-world\napplications, where the objectives often conflict each other and cannot be\noptimized by a single solution. In the past few decades, numerous methods have\nbeen proposed to find Pareto solutions that represent optimal trade-offs among\nthe objectives for a given problem. However, these existing methods could have\nhigh computational complexity or may not have good theoretical properties for\nsolving a general differentiable multi-objective optimization problem. In this\nwork, by leveraging the smooth optimization technique, we propose a lightweight\nand efficient smooth Tchebycheff scalarization approach for gradient-based\nmulti-objective optimization. It has good theoretical properties for finding\nall Pareto solutions with valid trade-off preferences, while enjoying\nsignificantly lower computational complexity compared to other methods.\nExperimental results on various real-world application problems fully\ndemonstrate the effectiveness of our proposed method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 41st International Conference on Machine Learning\n  (ICML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.19078v3",
    "published_date": "2024-02-29 12:03:05 UTC",
    "updated_date": "2024-07-23 10:46:28 UTC"
  },
  {
    "arxiv_id": "2402.19072v4",
    "title": "TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables",
    "authors": [
      "Yuxuan Wang",
      "Haixu Wu",
      "Jiaxiang Dong",
      "Guo Qin",
      "Haoran Zhang",
      "Yong Liu",
      "Yunzhong Qiu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "Deep models have demonstrated remarkable performance in time series\nforecasting. However, due to the partially-observed nature of real-world\napplications, solely focusing on the target of interest, so-called endogenous\nvariables, is usually insufficient to guarantee accurate forecasting. Notably,\na system is often recorded into multiple variables, where the exogenous\nvariables can provide valuable external information for endogenous variables.\nThus, unlike well-established multivariate or univariate forecasting paradigms\nthat either treat all the variables equally or ignore exogenous information,\nthis paper focuses on a more practical setting: time series forecasting with\nexogenous variables. We propose a novel approach, TimeXer, to ingest external\ninformation to enhance the forecasting of endogenous variables. With deftly\ndesigned embedding layers, TimeXer empowers the canonical Transformer with the\nability to reconcile endogenous and exogenous information, where patch-wise\nself-attention and variate-wise cross-attention are used simultaneously.\nMoreover, global endogenous tokens are learned to effectively bridge the causal\ninformation underlying exogenous series into endogenous temporal patches.\nExperimentally, TimeXer achieves consistent state-of-the-art performance on\ntwelve real-world forecasting benchmarks and exhibits notable generality and\nscalability. Code is available at this repository:\nhttps://github.com/thuml/TimeXer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19072v4",
    "published_date": "2024-02-29 11:54:35 UTC",
    "updated_date": "2024-11-11 03:18:32 UTC"
  },
  {
    "arxiv_id": "2403.00041v2",
    "title": "Global and Local Prompts Cooperation via Optimal Transport for Federated Learning",
    "authors": [
      "Hongxia Li",
      "Wei Huang",
      "Jingya Wang",
      "Ye Shi"
    ],
    "abstract": "Prompt learning in pretrained visual-language models has shown remarkable\nflexibility across various downstream tasks. Leveraging its inherent\nlightweight nature, recent research attempted to integrate the powerful\npretrained models into federated learning frameworks to simultaneously reduce\ncommunication costs and promote local training on insufficient data. Despite\nthese efforts, current federated prompt learning methods lack specialized\ndesigns to systematically address severe data heterogeneities, e.g., data\ndistribution with both label and feature shifts involved. To address this\nchallenge, we present Federated Prompts Cooperation via Optimal Transport\n(FedOTP), which introduces efficient collaborative prompt learning strategies\nto capture diverse category traits on a per-client basis. Specifically, for\neach client, we learn a global prompt to extract consensus knowledge among\nclients, and a local prompt to capture client-specific category\ncharacteristics. Unbalanced Optimal Transport is then employed to align local\nvisual features with these prompts, striking a balance between global consensus\nand local personalization. By relaxing one of the equality constraints, FedOTP\nenables prompts to focus solely on the core regions of image patches. Extensive\nexperiments on datasets with various types of heterogeneities have demonstrated\nthat our FedOTP outperforms the state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00041v2",
    "published_date": "2024-02-29 11:43:04 UTC",
    "updated_date": "2024-04-03 15:16:58 UTC"
  },
  {
    "arxiv_id": "2403.00841v1",
    "title": "Offline Fictitious Self-Play for Competitive Games",
    "authors": [
      "Jingxiao Chen",
      "Weiji Xie",
      "Weinan Zhang",
      "Yong yu",
      "Ying Wen"
    ],
    "abstract": "Offline Reinforcement Learning (RL) has received significant interest due to\nits ability to improve policies in previously collected datasets without online\ninteractions. Despite its success in the single-agent setting, offline\nmulti-agent RL remains a challenge, especially in competitive games. Firstly,\nunaware of the game structure, it is impossible to interact with the opponents\nand conduct a major learning paradigm, self-play, for competitive games.\nSecondly, real-world datasets cannot cover all the state and action space in\nthe game, resulting in barriers to identifying Nash equilibrium (NE). To\naddress these issues, this paper introduces Off-FSP, the first practical\nmodel-free offline RL algorithm for competitive games. We start by simulating\ninteractions with various opponents by adjusting the weights of the fixed\ndataset with importance sampling. This technique allows us to learn best\nresponses to different opponents and employ the Offline Self-Play learning\nframework. In this framework, we further implement Fictitious Self-Play (FSP)\nto approximate NE. In partially covered real-world datasets, our methods show\nthe potential to approach NE by incorporating any single-agent offline RL\nmethod. Experimental results in Leduc Hold'em Poker show that our method\nsignificantly improves performances compared with state-of-the-art baselines.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00841v1",
    "published_date": "2024-02-29 11:36:48 UTC",
    "updated_date": "2024-02-29 11:36:48 UTC"
  },
  {
    "arxiv_id": "2403.04775v1",
    "title": "Superposition with Delayed Unification",
    "authors": [
      "Ahmed Bhayat",
      "Johannes Schoisswohl",
      "Michael Rawson"
    ],
    "abstract": "Classically, in saturation-based proof systems, unification has been\nconsidered atomic. However, it is also possible to move unification to the\ncalculus level, turning the steps of the unification algorithm into inferences.\nFor calculi that rely on unification procedures returning large or even\ninfinite sets of unifiers, integrating unification into the calculus is an\nattractive method of dovetailing unification and inference. This applies, for\nexample, to AC-superposition and higher-order superposition. We show that\nfirst-order superposition remains complete when moving unification rules to the\ncalculus level. We discuss some of the benefits this has even for standard\nfirst-order superposition and provide an experimental evaluation.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "16 pages, 0 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2403.04775v1",
    "published_date": "2024-02-29 11:35:49 UTC",
    "updated_date": "2024-02-29 11:35:49 UTC"
  },
  {
    "arxiv_id": "2402.19054v1",
    "title": "RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection",
    "authors": [
      "Yang Xu",
      "Yunlin Tan",
      "Cheng Zhang",
      "Kai Chi",
      "Peng Sun",
      "Wenyuan Yang",
      "Ju Ren",
      "Hongbo Jiang",
      "Yaoxue Zhang"
    ],
    "abstract": "Embedding watermarks into models has been widely used to protect model\nownership in federated learning (FL). However, existing methods are inadequate\nfor protecting the ownership of personalized models acquired by clients in\npersonalized FL (PFL). This is due to the aggregation of the global model in\nPFL, resulting in conflicts over clients' private watermarks. Moreover,\nmalicious clients may tamper with embedded watermarks to facilitate model\nleakage and evade accountability. This paper presents a robust watermark\nembedding scheme, named RobWE, to protect the ownership of personalized models\nin PFL. We first decouple the watermark embedding of personalized models into\ntwo parts: head layer embedding and representation layer embedding. The head\nlayer belongs to clients' private part without participating in model\naggregation, while the representation layer is the shared part for aggregation.\nFor representation layer embedding, we employ a watermark slice embedding\noperation, which avoids watermark embedding conflicts. Furthermore, we design a\nmalicious watermark detection scheme enabling the server to verify the\ncorrectness of watermarks before aggregating local models. We conduct an\nexhaustive experimental evaluation of RobWE. The results demonstrate that RobWE\nsignificantly outperforms the state-of-the-art watermark embedding schemes in\nFL in terms of fidelity, reliability, and robustness.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19054v1",
    "published_date": "2024-02-29 11:31:50 UTC",
    "updated_date": "2024-02-29 11:31:50 UTC"
  },
  {
    "arxiv_id": "2402.19041v1",
    "title": "Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors",
    "authors": [
      "P. Hill",
      "N. Anantrasirichai",
      "A. Achim",
      "D. R. Bull"
    ],
    "abstract": "Atmospheric turbulence poses a challenge for the interpretation and visual\nperception of visual imagery due to its distortion effects. Model-based\napproaches have been used to address this, but such methods often suffer from\nartefacts associated with moving content. Conversely, deep learning based\nmethods are dependent on large and diverse datasets that may not effectively\nrepresent any specific content. In this paper, we address these problems with a\nself-supervised learning method that does not require ground truth. The\nproposed method is not dependent on any dataset outside of the single data\nsequence being processed but is also able to improve the quality of any input\nraw sequences or pre-processed sequences. Specifically, our method is based on\nan accelerated Deep Image Prior (DIP), but integrates temporal information\nusing pixel shuffling and a temporal sliding window. This efficiently learns\nspatio-temporal priors leading to a system that effectively mitigates\natmospheric turbulence distortions. The experiments show that our method\nimproves visual quality results qualitatively and quantitatively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19041v1",
    "published_date": "2024-02-29 11:06:14 UTC",
    "updated_date": "2024-02-29 11:06:14 UTC"
  },
  {
    "arxiv_id": "2402.19027v2",
    "title": "How to Train your Antivirus: RL-based Hardening through the Problem-Space",
    "authors": [
      "Ilias Tsingenopoulos",
      "Jacopo Cortellazzi",
      "Branislav BoÅ¡anskÃ½",
      "Simone Aonzo",
      "Davy Preuveneers",
      "Wouter Joosen",
      "Fabio Pierazzi",
      "Lorenzo Cavallaro"
    ],
    "abstract": "ML-based malware detection on dynamic analysis reports is vulnerable to both\nevasion and spurious correlations. In this work, we investigate a specific ML\narchitecture employed in the pipeline of a widely-known commercial antivirus\ncompany, with the goal to harden it against adversarial malware. Adversarial\ntraining, the sole defensive technique that can confer empirical robustness, is\nnot applicable out of the box in this domain, for the principal reason that\ngradient-based perturbations rarely map back to feasible problem-space\nprograms. We introduce a novel Reinforcement Learning approach for constructing\nadversarial examples, a constituent part of adversarially training a model\nagainst evasion. Our approach comes with multiple advantages. It performs\nmodifications that are feasible in the problem-space, and only those; thus it\ncircumvents the inverse mapping problem. It also makes possible to provide\ntheoretical guarantees on the robustness of the model against a particular set\nof adversarial capabilities. Our empirical exploration validates our\ntheoretical insights, where we can consistently reach 0% Attack Success Rate\nafter a few adversarial retraining iterations.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages,4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.19027v2",
    "published_date": "2024-02-29 10:38:56 UTC",
    "updated_date": "2024-09-05 17:07:23 UTC"
  },
  {
    "arxiv_id": "2402.19025v1",
    "title": "Combination of Weak Learners eXplanations to Improve Random Forest eXplicability Robustness",
    "authors": [
      "Riccardo Pala",
      "Esteban GarcÃ­a-Cuesta"
    ],
    "abstract": "The notion of robustness in XAI refers to the observed variations in the\nexplanation of the prediction of a learned model with respect to changes in the\ninput leading to that prediction. Intuitively, if the input being explained is\nmodified slightly subtly enough so as to not change the prediction of the model\ntoo much, then we would expect that the explanation provided for that new input\ndoes not change much either. We argue that a combination through discriminative\naveraging of ensembles weak learners explanations can improve the robustness of\nexplanations in ensemble methods.This approach has been implemented and tested\nwith post-hoc SHAP method and Random Forest ensemble with successful results.\nThe improvements obtained have been measured quantitatively and some insights\ninto the explicability robustness in ensemble methods are presented.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T01",
      "I.2.0; I.2.1"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.19025v1",
    "published_date": "2024-02-29 10:37:40 UTC",
    "updated_date": "2024-02-29 10:37:40 UTC"
  },
  {
    "arxiv_id": "2402.19009v2",
    "title": "Unified Generation, Reconstruction, and Representation: Generalized Diffusion with Adaptive Latent Encoding-Decoding",
    "authors": [
      "Guangyi Liu",
      "Yu Wang",
      "Zeyu Feng",
      "Qiyu Wu",
      "Liping Tang",
      "Yuan Gao",
      "Zhen Li",
      "Shuguang Cui",
      "Julian McAuley",
      "Zichao Yang",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "abstract": "The vast applications of deep generative models are anchored in three core\ncapabilities -- generating new instances, reconstructing inputs, and learning\ncompact representations -- across various data types, such as discrete\ntext/protein sequences and continuous images. Existing model families, like\nvariational autoencoders (VAEs), generative adversarial networks (GANs),\nautoregressive models, and (latent) diffusion models, generally excel in\nspecific capabilities and data types but fall short in others. We introduce\nGeneralized Encoding-Decoding Diffusion Probabilistic Models (EDDPMs) which\nintegrate the core capabilities for broad applicability and enhanced\nperformance. EDDPMs generalize the Gaussian noising-denoising in standard\ndiffusion by introducing parameterized encoding-decoding. Crucially, EDDPMs are\ncompatible with the well-established diffusion model objective and training\nrecipes, allowing effective learning of the encoder-decoder parameters jointly\nwith diffusion. By choosing appropriate encoder/decoder (e.g., large language\nmodels), EDDPMs naturally apply to different data types. Extensive experiments\non text, proteins, and images demonstrate the flexibility to handle diverse\ndata and tasks and the strong improvement over various existing models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024 camera-ready. Code is available at\n  https://github.com/guangyliu/EDDPM",
    "pdf_url": "http://arxiv.org/pdf/2402.19009v2",
    "published_date": "2024-02-29 10:08:57 UTC",
    "updated_date": "2024-06-05 07:28:52 UTC"
  },
  {
    "arxiv_id": "2402.19002v1",
    "title": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction",
    "authors": [
      "Ching-Lin Lee",
      "Zhi-Xuan Wang",
      "Kuan-Ting Lai",
      "Amar Fadillah"
    ],
    "abstract": "Predicting the future trajectories of pedestrians on the road is an important\ntask for autonomous driving. The pedestrian trajectory prediction is affected\nby scene paths, pedestrian's intentions and decision-making, which is a\nmulti-modal problem. Most recent studies use past trajectories to predict a\nvariety of potential future trajectory distributions, which do not account for\nthe scene context and pedestrian targets. Instead of predicting the future\ntrajectory directly, we propose to use scene context and observed trajectory to\npredict the goal points first, and then reuse the goal points to predict the\nfuture trajectories. By leveraging the information from scene context and\nobserved trajectory, the uncertainty can be limited to a few target areas,\nwhich represent the \"goals\" of the pedestrians. In this paper, we propose\nGoalNet, a new trajectory prediction neural network based on the goal areas of\na pedestrian. Our network can predict both pedestrian's trajectories and\nbounding boxes. The overall model is efficient and modular, and its outputs can\nbe changed according to the usage scenario. Experimental results show that\nGoalNet significantly improves the previous state-of-the-art performance by\n48.7% on the JAAD and 40.8% on the PIE dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.19002v1",
    "published_date": "2024-02-29 09:53:19 UTC",
    "updated_date": "2024-02-29 09:53:19 UTC"
  },
  {
    "arxiv_id": "2402.18995v1",
    "title": "Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series",
    "authors": [
      "Rui Huang",
      "Sikun Yang",
      "Heinz Koeppl"
    ],
    "abstract": "Modeling count-valued time series has been receiving increasing attention\nsince count time series naturally arise in physical and social domains. Poisson\ngamma dynamical systems (PGDSs) are newly-developed methods, which can well\ncapture the expressive latent transition structure and bursty dynamics behind\ncount sequences. In particular, PGDSs demonstrate superior performance in terms\nof data imputation and prediction, compared with canonical linear dynamical\nsystem (LDS) based methods. Despite these advantages, PGDS cannot capture the\nheterogeneous overdispersed behaviours of the underlying dynamic processes. To\nmitigate this defect, we propose a negative-binomial-randomized gamma Markov\nprocess, which not only significantly improves the predictive performance of\nthe proposed dynamical system, but also facilitates the fast convergence of the\ninference algorithm. Moreover, we develop methods to estimate both\nfactor-structured and graph-structured transition dynamics, which enable us to\ninfer more explainable latent structure, compared with PGDSs. Finally, we\ndemonstrate the explainable latent structure learned by the proposed method,\nand show its superior performance in imputing missing data and forecasting\nfuture observations, compared with the related models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18995v1",
    "published_date": "2024-02-29 09:46:47 UTC",
    "updated_date": "2024-02-29 09:46:47 UTC"
  },
  {
    "arxiv_id": "2403.00039v1",
    "title": "FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use",
    "authors": [
      "Ingo Weber",
      "Hendrik Linka",
      "Daniel Mertens",
      "Tamara Muryshkin",
      "Heinrich Opgenoorth",
      "Stefan Langer"
    ],
    "abstract": "Since OpenAI's release of ChatGPT, generative AI has received significant\nattention across various domains. These AI-based chat systems have the\npotential to enhance the productivity of knowledge workers in diverse tasks.\nHowever, the use of free public services poses a risk of data leakage, as\nservice providers may exploit user input for additional training and\noptimization without clear boundaries. Even subscription-based alternatives\nsometimes lack transparency in handling user data. To address these concerns\nand enable Fraunhofer staff to leverage this technology while ensuring\nconfidentiality, we have designed and developed a customized chat AI called\nFhGenie (genie being a reference to a helpful spirit). Within few days of its\nrelease, thousands of Fraunhofer employees started using this service. As\npioneers in implementing such a system, many other organizations have followed\nsuit. Our solution builds upon commercial large language models (LLMs), which\nwe have carefully integrated into our system to meet our specific requirements\nand compliance constraints, including confidentiality and GDPR. In this paper,\nwe share detailed insights into the architectural considerations, design,\nimplementation, and subsequent updates of FhGenie. Additionally, we discuss\nchallenges, observations, and the core lessons learned from its productive\nusage.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00039v1",
    "published_date": "2024-02-29 09:43:50 UTC",
    "updated_date": "2024-02-29 09:43:50 UTC"
  },
  {
    "arxiv_id": "2402.18985v3",
    "title": "Blume-Capel model analysis with microcanonical population annealing method",
    "authors": [
      "Vyacheslav Mozolenko",
      "Lev Shchur"
    ],
    "abstract": "We present a modification of the Rose-Machta algorithm (Phys. Rev. E 100\n(2019) 063304) and estimate the density of states for a two-dimensional\nBlume-Capel model, simulating $10^5$ replicas in parallel for each set of\nparameters. We perform a finite-size analysis of the specific heat and Binder\ncumulant, determine the critical temperature along the critical line, and\nevaluate the critical exponents. The results obtained are in good agreement\nwith those obtained previously using various methods -- Markov Chain Monte\nCarlo simulation, Wang-Landau simulation, transfer matrix, and series\nexpansion. The simulation results clearly illustrate the typical behavior of\nspecific heat along the critical lines and through the tricritical point.",
    "categories": [
      "cond-mat.stat-mech",
      "cs.AI"
    ],
    "primary_category": "cond-mat.stat-mech",
    "comment": "9 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.18985v3",
    "published_date": "2024-02-29 09:39:39 UTC",
    "updated_date": "2024-04-17 20:06:35 UTC"
  },
  {
    "arxiv_id": "2403.00840v1",
    "title": "EyeGPT: Ophthalmic Assistant with Large Language Models",
    "authors": [
      "Xiaolan Chen",
      "Ziwei Zhao",
      "Weiyi Zhang",
      "Pusheng Xu",
      "Le Gao",
      "Mingpu Xu",
      "Yue Wu",
      "Yinwen Li",
      "Danli Shi",
      "Mingguang He"
    ],
    "abstract": "Artificial intelligence (AI) has gained significant attention in healthcare\nconsultation due to its potential to improve clinical workflow and enhance\nmedical communication. However, owing to the complex nature of medical\ninformation, large language models (LLM) trained with general world knowledge\nmight not possess the capability to tackle medical-related tasks at an expert\nlevel. Here, we introduce EyeGPT, a specialized LLM designed specifically for\nophthalmology, using three optimization strategies including role-playing,\nfinetuning, and retrieval-augmented generation. In particular, we proposed a\ncomprehensive evaluation framework that encompasses a diverse dataset, covering\nvarious subspecialties of ophthalmology, different users, and diverse inquiry\nintents. Moreover, we considered multiple evaluation metrics, including\naccuracy, understandability, trustworthiness, empathy, and the proportion of\nhallucinations. By assessing the performance of different EyeGPT variants, we\nidentify the most effective one, which exhibits comparable levels of\nunderstandability, trustworthiness, and empathy to human ophthalmologists (all\nPs>0.05). Overall, ur study provides valuable insights for future research,\nfacilitating comprehensive comparisons and evaluations of different strategies\nfor developing specialized LLMs in ophthalmology. The potential benefits\ninclude enhancing the patient experience in eye care and optimizing\nophthalmologists' services.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "47 pages, 4 figures, 1 table, 2 supplementary figures and 9\n  supplementary tables",
    "pdf_url": "http://arxiv.org/pdf/2403.00840v1",
    "published_date": "2024-02-29 09:35:41 UTC",
    "updated_date": "2024-02-29 09:35:41 UTC"
  },
  {
    "arxiv_id": "2402.18975v2",
    "title": "Theoretically Achieving Continuous Representation of Oriented Bounding Boxes",
    "authors": [
      "Zi-Kai Xiao",
      "Guo-Ye Yang",
      "Xue Yang",
      "Tai-Jiang Mu",
      "Junchi Yan",
      "Shi-min Hu"
    ],
    "abstract": "Considerable efforts have been devoted to Oriented Object Detection (OOD).\nHowever, one lasting issue regarding the discontinuity in Oriented Bounding Box\n(OBB) representation remains unresolved, which is an inherent bottleneck for\nextant OOD methods. This paper endeavors to completely solve this issue in a\ntheoretically guaranteed manner and puts an end to the ad-hoc efforts in this\ndirection. Prior studies typically can only address one of the two cases of\ndiscontinuity: rotation and aspect ratio, and often inadvertently introduce\ndecoding discontinuity, e.g. Decoding Incompleteness (DI) and Decoding\nAmbiguity (DA) as discussed in literature. Specifically, we propose a novel\nrepresentation method called Continuous OBB (COBB), which can be readily\nintegrated into existing detectors e.g. Faster-RCNN as a plugin. It can\ntheoretically ensure continuity in bounding box regression which to our best\nknowledge, has not been achieved in literature for rectangle-based object\nrepresentation. For fairness and transparency of experiments, we have developed\na modularized benchmark based on the open-source deep learning framework\nJittor's detection toolbox JDet for OOD evaluation. On the popular DOTA\ndataset, by integrating Faster-RCNN as the same baseline model, our new method\noutperforms the peer method Gliding Vertex by 1.13% mAP50 (relative improvement\n1.54%), and 2.46% mAP75 (relative improvement 5.91%), without any tricks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 12 tables, 8 figures. Accepted by CVPR'24. Code:\n  https://github.com/514flowey/JDet-COBB",
    "pdf_url": "http://arxiv.org/pdf/2402.18975v2",
    "published_date": "2024-02-29 09:27:40 UTC",
    "updated_date": "2024-04-16 09:49:15 UTC"
  },
  {
    "arxiv_id": "2402.18960v1",
    "title": "Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging",
    "authors": [
      "Jennie Karlsson",
      "Marisa Wodrich",
      "Niels Christian Overgaard",
      "Freja Sahlin",
      "Kristina LÃ¥ng",
      "Anders Heyden",
      "Ida Arvidsson"
    ],
    "abstract": "Deep learning has shown to have great potential in medical applications. In\ncritical domains as such, it is of high interest to have trustworthy algorithms\nwhich are able to tell when reliable assessments cannot be guaranteed.\nDetecting out-of-distribution (OOD) samples is a crucial step towards building\na safe classifier. Following a previous study, showing that it is possible to\nclassify breast cancer in point-of-care ultrasound images, this study\ninvestigates OOD detection using three different methods: softmax, energy score\nand deep ensembles. All methods are tested on three different OOD data sets.\nThe results show that the energy score method outperforms the softmax method,\nperforming well on two of the data sets. The ensemble method is the most\nrobust, performing the best at detecting OOD samples for all three OOD data\nsets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18960v1",
    "published_date": "2024-02-29 08:59:51 UTC",
    "updated_date": "2024-02-29 08:59:51 UTC"
  },
  {
    "arxiv_id": "2402.18945v4",
    "title": "SynGhost: Invisible and Universal Task-agnostic Backdoor Attack via Syntactic Transfer",
    "authors": [
      "Pengzhou Cheng",
      "Wei Du",
      "Zongru Wu",
      "Fengwei Zhang",
      "Libo Chen",
      "Zhuosheng Zhang",
      "Gongshen Liu"
    ],
    "abstract": "Although pre-training achieves remarkable performance, it suffers from\ntask-agnostic backdoor attacks due to vulnerabilities in data and training\nmechanisms. These attacks can transfer backdoors to various downstream tasks.\nIn this paper, we introduce $\\mathtt{maxEntropy}$, an entropy-based poisoning\nfilter that mitigates such risks. To overcome the limitations of manual target\nsetting and explicit triggers, we propose $\\mathtt{SynGhost}$, an invisible and\nuniversal task-agnostic backdoor attack via syntactic transfer, further\nexposing vulnerabilities in pre-trained language models (PLMs). Specifically,\n$\\mathtt{SynGhost}$ injects multiple syntactic backdoors into the pre-training\nspace through corpus poisoning, while preserving the PLM's pre-training\ncapabilities. Second, $\\mathtt{SynGhost}$ adaptively selects optimal targets\nbased on contrastive learning, creating a uniform distribution in the\npre-training space. To identify syntactic differences, we also introduce an\nawareness module to minimize interference between backdoors. Experiments show\nthat $\\mathtt{SynGhost}$ poses significant threats and can transfer to various\ndownstream tasks. Furthermore, $\\mathtt{SynGhost}$ resists defenses based on\nperplexity, fine-pruning, and $\\mathtt{maxEntropy}$. The code is available at\nhttps://github.com/Zhou-CyberSecurity-AI/SynGhost.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "17 pages, 16 figures, 12 tables, accepted at NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.18945v4",
    "published_date": "2024-02-29 08:20:49 UTC",
    "updated_date": "2025-03-03 06:34:48 UTC"
  },
  {
    "arxiv_id": "2402.18944v1",
    "title": "SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF)",
    "authors": [
      "Shivani Kumar",
      "Md Shad Akhtar",
      "Erik Cambria",
      "Tanmoy Chakraborty"
    ],
    "abstract": "We present SemEval-2024 Task 10, a shared task centred on identifying\nemotions and finding the rationale behind their flips within monolingual\nEnglish and Hindi-English code-mixed dialogues. This task comprises three\ndistinct subtasks - emotion recognition in conversation for code-mixed\ndialogues, emotion flip reasoning for code-mixed dialogues, and emotion flip\nreasoning for English dialogues. Participating systems were tasked to\nautomatically execute one or more of these subtasks. The datasets for these\ntasks comprise manually annotated conversations focusing on emotions and\ntriggers for emotion shifts (The task data is available at\nhttps://github.com/LCS2-IIITD/EDiReF-SemEval2024.git). A total of 84\nparticipants engaged in this task, with the most adept systems attaining\nF1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper\nsummarises the results and findings from 24 teams alongside their system\ndescriptions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 3 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.18944v1",
    "published_date": "2024-02-29 08:20:06 UTC",
    "updated_date": "2024-02-29 08:20:06 UTC"
  },
  {
    "arxiv_id": "2403.06994v1",
    "title": "Physics Sensor Based Deep Learning Fall Detection System",
    "authors": [
      "Zeyuan Qu",
      "Tiange Huang",
      "Yuxin Ji",
      "Yongjun Li"
    ],
    "abstract": "Fall detection based on embedded sensor is a practical and popular research\ndirection in recent years. In terms of a specific application: fall detection\nmethods based upon physics sensors such as [gyroscope and accelerator] have\nbeen exploited using traditional hand crafted features and feed them in machine\nlearning models like Markov chain or just threshold based classification\nmethods. In this paper, we build a complete system named TSFallDetect including\ndata receiving device based on embedded sensor, mobile deep-learning model\ndeploying platform, and a simple server, which will be used to gather models\nand data for future expansion. On the other hand, we exploit the sequential\ndeep-learning methods to address this falling motion prediction problem based\non data collected by inertial and film pressure sensors. We make a empirical\nstudy based on existing datasets and our datasets collected from our system\nseparately, which shows that the deep-learning model has more potential\nadvantage than other traditional methods, and we proposed a new deep-learning\nmodel based on the time series data to predict the fall, and it may be superior\nto other sequential models in this particular field.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.06994v1",
    "published_date": "2024-02-29 07:50:06 UTC",
    "updated_date": "2024-02-29 07:50:06 UTC"
  },
  {
    "arxiv_id": "2402.18929v2",
    "title": "Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Yinqiang Zheng",
      "Tieyong Zeng"
    ],
    "abstract": "Deep learning has led to a dramatic leap on Single Image Super-Resolution\n(SISR) performances in recent years. %Despite the substantial advancement%\nWhile most existing work assumes a simple and fixed degradation model (e.g.,\nbicubic downsampling), the research of Blind SR seeks to improve model\ngeneralization ability with unknown degradation. Recently, Kong et al pioneer\nthe investigation of a more suitable training strategy for Blind SR using\nDropout. Although such method indeed brings substantial generalization\nimprovements via mitigating overfitting, we argue that Dropout simultaneously\nintroduces undesirable side-effect that compromises model's capacity to\nfaithfully reconstruct fine details. We show both the theoretical and\nexperimental analyses in our paper, and furthermore, we present another easy\nyet effective training strategy that enhances the generalization ability of the\nmodel by simply modulating its first and second-order features statistics.\nExperimental results have shown that our method could serve as a model-agnostic\nregularization and outperforms Dropout on seven benchmark datasets including\nboth synthetic and real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18929v2",
    "published_date": "2024-02-29 07:44:31 UTC",
    "updated_date": "2024-03-01 05:48:17 UTC"
  },
  {
    "arxiv_id": "2402.18920v5",
    "title": "Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation",
    "authors": [
      "Dongliang Cao",
      "Marvin Eisenberger",
      "Nafie El Amrani",
      "Daniel Cremers",
      "Florian Bernard"
    ],
    "abstract": "Although 3D shape matching and interpolation are highly interrelated, they\nare often studied separately and applied sequentially to relate different 3D\nshapes, thus resulting in sub-optimal performance. In this work we present a\nunified framework to predict both point-wise correspondences and shape\ninterpolation between 3D shapes. To this end, we combine the deep functional\nmap framework with classical surface deformation models to map shapes in both\nspectral and spatial domains. On the one hand, by incorporating spatial maps,\nour method obtains more accurate and smooth point-wise correspondences compared\nto previous functional map methods for shape matching. On the other hand, by\nintroducing spectral maps, our method gets rid of commonly used but\ncomputationally expensive geodesic distance constraints that are only valid for\nnear-isometric shape deformations. Furthermore, we propose a novel test-time\nadaptation scheme to capture both pose-dominant and shape-dominant\ndeformations. Using different challenging datasets, we demonstrate that our\nmethod outperforms previous state-of-the-art methods for both shape matching\nand interpolation, even compared to supervised approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by CVPR2024",
    "pdf_url": "http://arxiv.org/pdf/2402.18920v5",
    "published_date": "2024-02-29 07:26:23 UTC",
    "updated_date": "2024-03-27 07:16:21 UTC"
  },
  {
    "arxiv_id": "2402.18913v1",
    "title": "AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging",
    "authors": [
      "Yiran Zhao",
      "Wenxuan Zhang",
      "Huiming Wang",
      "Kenji Kawaguchi",
      "Lidong Bing"
    ],
    "abstract": "As an effective alternative to the direct fine-tuning on target tasks in\nspecific languages, cross-lingual transfer addresses the challenges of limited\ntraining data by decoupling ''task ability'' and ''language ability'' by\nfine-tuning on the target task in the source language and another selected task\nin the target language, respectively. However, they fail to fully separate the\ntask ability from the source language or the language ability from the chosen\ntask. In this paper, we acknowledge the mutual reliance between task ability\nand language ability and direct our attention toward the gap between the target\nlanguage and the source language on tasks. As the gap removes the impact of\ntasks, we assume that it remains consistent across tasks. Based on this\nassumption, we propose a new cross-lingual transfer method called\n$\\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a\nreference task, we can determine that the divergence of adapters fine-tuned on\nthe reference task in both languages follows the same distribution as the\ndivergence of adapters fine-tuned on the target task in both languages. Hence,\nwe can obtain target adapters by combining the other three adapters.\nFurthermore, we propose a structure-adaptive adapter merging method. Our\nempirical results demonstrate that our approach yields new and effective\ncross-lingual transfer, outperforming existing methods across all settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18913v1",
    "published_date": "2024-02-29 07:11:24 UTC",
    "updated_date": "2024-02-29 07:11:24 UTC"
  },
  {
    "arxiv_id": "2402.18910v1",
    "title": "DIGIC: Domain Generalizable Imitation Learning by Causal Discovery",
    "authors": [
      "Yang Chen",
      "Yitao Liang",
      "Zhouchen Lin"
    ],
    "abstract": "Causality has been combined with machine learning to produce robust\nrepresentations for domain generalization. Most existing methods of this type\nrequire massive data from multiple domains to identify causal features by\ncross-domain variations, which can be expensive or even infeasible and may lead\nto misidentification in some cases. In this work, we make a different attempt\nby leveraging the demonstration data distribution to discover the causal\nfeatures for a domain generalizable policy. We design a novel framework, called\nDIGIC, to identify the causal features by finding the direct cause of the\nexpert action from the demonstration data distribution via causal discovery.\nOur framework can achieve domain generalizable imitation learning with only\nsingle-domain data and serve as a complement for cross-domain variation-based\nmethods under non-structural assumptions on the underlying causal models. Our\nempirical study in various control tasks shows that the proposed framework\nevidently improves the domain generalization performance and has comparable\nperformance to the expert in the original domain simultaneously.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18910v1",
    "published_date": "2024-02-29 07:09:01 UTC",
    "updated_date": "2024-02-29 07:09:01 UTC"
  },
  {
    "arxiv_id": "2402.18909v2",
    "title": "AKEW: Assessing Knowledge Editing in the Wild",
    "authors": [
      "Xiaobao Wu",
      "Liangming Pan",
      "William Yang Wang",
      "Anh Tuan Luu"
    ],
    "abstract": "Knowledge editing injects knowledge updates into language models to keep them\ncorrect and up-to-date. However, its current evaluations deviate significantly\nfrom practice: their knowledge updates solely consist of structured facts\nderived from meticulously crafted datasets, instead of practical sources --\nunstructured texts like news articles, and they often overlook practical\nreal-world knowledge updates. To address these issues, in this paper we propose\nAKEW (Assessing Knowledge Editing in the Wild), a new practical benchmark for\nknowledge editing. AKEW fully covers three editing settings of knowledge\nupdates: structured facts, unstructured texts as facts, and extracted triplets.\nIt further introduces new datasets featuring both counterfactual and real-world\nknowledge updates. Through extensive experiments, we demonstrate the\nconsiderable gap between state-of-the-art knowledge-editing methods and\npractical scenarios. Our analyses further highlight key insights to motivate\nfuture research for practical knowledge editing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2402.18909v2",
    "published_date": "2024-02-29 07:08:34 UTC",
    "updated_date": "2024-10-10 05:30:03 UTC"
  },
  {
    "arxiv_id": "2402.18908v3",
    "title": "Facility Location Games with Scaling Effects",
    "authors": [
      "Yu He",
      "Alexander Lam",
      "Minming Li"
    ],
    "abstract": "We take the classic facility location problem and consider a variation, in\nwhich each agent's individual cost function is equal to their distance from the\nfacility multiplied by a scaling factor which is determined by the facility\nplacement. In addition to the general class of continuous scaling functions, we\nalso provide results for piecewise linear scaling functions which can\neffectively approximate or model the scaling of many real world scenarios. We\nfocus on the objectives of total and maximum cost, describing the computation\nof the optimal solution. We then move to the approximate mechanism design\nsetting, observing that the agents' preferences may no longer be single-peaked.\nConsequently, we characterize the conditions on scaling functions which ensure\nthat agents have single-peaked preferences. Under these conditions, we find a\ncharacterization of continuous, strategyproof, and anonymous mechanisms, and\ncompute the total and maximum cost approximation ratios achievable by these\nmechanisms.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "This is an updated version of the paper which appeared at the 23rd\n  International Conference on Autonomous Agents and Multi-Agent Systems\n  (AAMAS-24)",
    "pdf_url": "http://arxiv.org/pdf/2402.18908v3",
    "published_date": "2024-02-29 07:08:18 UTC",
    "updated_date": "2024-12-05 16:05:48 UTC"
  },
  {
    "arxiv_id": "2402.18905v1",
    "title": "On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?",
    "authors": [
      "Shuqi Ke",
      "Charlie Hou",
      "Giulia Fanti",
      "Sewoong Oh"
    ],
    "abstract": "Differentially private (DP) machine learning pipelines typically involve a\ntwo-phase process: non-private pre-training on a public dataset, followed by\nfine-tuning on private data using DP optimization techniques. In the DP\nsetting, it has been observed that full fine-tuning may not always yield the\nbest test accuracy, even for in-distribution data. This paper (1) analyzes the\ntraining dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2)\nexplores the phenomenon of sequential fine-tuning, starting with linear probing\nand transitioning to full fine-tuning (LP-FT), and its impact on test loss. We\nprovide theoretical insights into the convergence of DP fine-tuning within an\noverparameterized neural network and establish a utility curve that determines\nthe allocation of privacy budget between linear probing and full fine-tuning.\nThe theoretical results are supported by empirical evaluations on various\nbenchmarks and models. The findings reveal the complex nature of DP fine-tuning\nmethods. These results contribute to a deeper understanding of DP machine\nlearning and highlight the importance of considering the allocation of privacy\nbudget in the fine-tuning process.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18905v1",
    "published_date": "2024-02-29 07:01:48 UTC",
    "updated_date": "2024-02-29 07:01:48 UTC"
  },
  {
    "arxiv_id": "2403.00037v2",
    "title": "Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media",
    "authors": [
      "Jiajun Zhang",
      "Zhixun Li",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "abstract": "With the rapid development of social media, the wide dissemination of fake\nnews on social media is increasingly threatening both individuals and society.\nOne of the unique challenges for fake news detection on social media is how to\ndetect fake news on future events. Recently, numerous fake news detection\nmodels that utilize textual information and the propagation structure of posts\nhave been proposed. Unfortunately, most of the existing approaches can hardly\nhandle this challenge since they rely heavily on event-specific features for\nprediction and cannot generalize to unseen events. To address this, we\nintroduce \\textbf{F}uture \\textbf{AD}aptive \\textbf{E}vent-based Fake news\nDetection (FADE) framework. Specifically, we train a target predictor through\nan adaptive augmentation strategy and graph contrastive learning to obtain\nhigher-quality features and make more accurate overall predictions.\nSimultaneously, we independently train an event-only predictor to obtain biased\npredictions. We further mitigate event bias by subtracting the event-only\npredictor's output from the target predictor's output to obtain the final\nprediction. Encouraging results from experiments designed to emulate real-world\nsocial media conditions validate the effectiveness of our method in comparison\nto existing state-of-the-art approaches.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00037v2",
    "published_date": "2024-02-29 06:40:53 UTC",
    "updated_date": "2024-11-11 18:27:18 UTC"
  },
  {
    "arxiv_id": "2403.00036v1",
    "title": "Influencing Bandits: Arm Selection for Preference Shaping",
    "authors": [
      "Viraj Nadkarni",
      "D. Manjunath",
      "Sharayu Moharir"
    ],
    "abstract": "We consider a non stationary multi-armed bandit in which the population\npreferences are positively and negatively reinforced by the observed rewards.\nThe objective of the algorithm is to shape the population preferences to\nmaximize the fraction of the population favouring a predetermined arm. For the\ncase of binary opinions, two types of opinion dynamics are considered --\ndecreasing elasticity (modeled as a Polya urn with increasing number of balls)\nand constant elasticity (using the voter model). For the first case, we\ndescribe an Explore-then-commit policy and a Thompson sampling policy and\nanalyse the regret for each of these policies. We then show that these\nalgorithms and their analyses carry over to the constant elasticity case. We\nalso describe a Thompson sampling based algorithm for the case when more than\ntwo types of opinions are present. Finally, we discuss the case where presence\nof multiple recommendation systems gives rise to a trade-off between their\npopularity and opinion shaping objectives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SY",
      "eess.SY",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figures, 24 references, proofs in appendix",
    "pdf_url": "http://arxiv.org/pdf/2403.00036v1",
    "published_date": "2024-02-29 05:59:27 UTC",
    "updated_date": "2024-02-29 05:59:27 UTC"
  },
  {
    "arxiv_id": "2402.18865v1",
    "title": "Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning",
    "authors": [
      "Weijieying Ren",
      "Xinlong Li",
      "Lei Wang",
      "Tianxiang Zhao",
      "Wei Qin"
    ],
    "abstract": "Existing research has shown that large language models (LLMs) exhibit\nremarkable performance in language understanding and generation. However, when\nLLMs are continuously fine-tuned on complex and diverse domain-specific\ndownstream tasks, the inference performance on historical tasks decreases\ndramatically, which is known as a catastrophic forgetting problem. A trade-off\nneeds to be kept between learning plasticity and memory stability. Plenty of\nexisting works have explored strategies like memory replay, regularization and\nparameter isolation, but little is known about the geometric connection of\nvarious adjacent minima in the continual LLMs fine-tuning scenarios. In this\nwork, we investigate the geometric connections of different minima through the\nlens of mode connectivity, which means different minima can be connected by a\nlow-loss valley. Through extensive experiments, we uncover the mode\nconnectivity phenomenon in the LLMs continual learning scenario and find that\nit can strike a balance between plasticity and stability. Building upon these\nfindings, we propose a simple yet effective method called Interpolation-based\nLoRA (I-LoRA), which constructs a dual-memory experience replay framework based\non LoRA parameter interpolations. Extensive experiments and analysis on eight\ndomain-specific CL benchmarks demonstrate that I-LoRA consistently show\nsignificant improvement over the previous state-of-the-art approaches with up\nto $11\\%$ performance gains, providing a strong baseline and insights for\nfuture research on the large language model continual learning problem. Our\ncode is available at \\url{https://github.com/which47/LLMCL}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18865v1",
    "published_date": "2024-02-29 05:27:45 UTC",
    "updated_date": "2024-02-29 05:27:45 UTC"
  },
  {
    "arxiv_id": "2403.15407v1",
    "title": "X-AMR Annotation Tool",
    "authors": [
      "Shafiuddin Rehan Ahmed",
      "Jon Z. Cai",
      "Martha Palmer",
      "James H. Martin"
    ],
    "abstract": "This paper presents a novel Cross-document Abstract Meaning Representation\n(X-AMR) annotation tool designed for annotating key corpus-level event\nsemantics. Leveraging machine assistance through the Prodigy Annotation Tool,\nwe enhance the user experience, ensuring ease and efficiency in the annotation\nprocess. Through empirical analyses, we demonstrate the effectiveness of our\ntool in augmenting an existing event corpus, highlighting its advantages when\nintegrated with GPT-4. Code and annotations:\nhttps://github.com/ahmeshaf/gpt_coref",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024 System Demonstration",
    "pdf_url": "http://arxiv.org/pdf/2403.15407v1",
    "published_date": "2024-02-29 05:16:19 UTC",
    "updated_date": "2024-02-29 05:16:19 UTC"
  },
  {
    "arxiv_id": "2402.18853v2",
    "title": "Rethinking Multi-domain Generalization with A General Learning Objective",
    "authors": [
      "Zhaorui Tan",
      "Xi Yang",
      "Kaizhu Huang"
    ],
    "abstract": "Multi-domain generalization (mDG) is universally aimed to minimize the\ndiscrepancy between training and testing distributions to enhance\nmarginal-to-label distribution mapping. However, existing mDG literature lacks\na general learning objective paradigm and often imposes constraints on static\ntarget marginal distributions. In this paper, we propose to leverage a\n$Y$-mapping to relax the constraint. We rethink the learning objective for mDG\nand design a new \\textbf{general learning objective} to interpret and analyze\nmost existing mDG wisdom. This general objective is bifurcated into two\nsynergistic amis: learning domain-independent conditional features and\nmaximizing a posterior. Explorations also extend to two effective\nregularization terms that incorporate prior information and suppress invalid\ncausality, alleviating the issues that come with relaxed constraints. We\ntheoretically contribute an upper bound for the domain alignment of\ndomain-independent conditional features, disclosing that many previous mDG\nendeavors actually \\textbf{optimize partially the objective} and thus lead to\nlimited performance. As such, our study distills a general learning objective\ninto four practical components, providing a general, robust, and flexible\nmechanism to handle complex domain shifts. Extensive empirical results indicate\nthat the proposed objective with $Y$-mapping leads to substantially better mDG\nperformance in various downstream tasks, including regression, segmentation,\nand classification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CVPR24",
    "pdf_url": "http://arxiv.org/pdf/2402.18853v2",
    "published_date": "2024-02-29 05:00:30 UTC",
    "updated_date": "2024-12-18 06:55:31 UTC"
  },
  {
    "arxiv_id": "2402.18851v1",
    "title": "Applications of 0-1 Neural Networks in Prescription and Prediction",
    "authors": [
      "Vrishabh Patil",
      "Kara Hoppe",
      "Yonatan Mintz"
    ],
    "abstract": "A key challenge in medical decision making is learning treatment policies for\npatients with limited observational data. This challenge is particularly\nevident in personalized healthcare decision-making, where models need to take\ninto account the intricate relationships between patient characteristics,\ntreatment options, and health outcomes. To address this, we introduce\nprescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed\ninteger programming that can be used with counterfactual estimation to optimize\npolicies in medium data settings. These models offer greater interpretability\nthan deep neural networks and can encode more complex policies than common\nmodels such as decision trees. We show that PNNs can outperform existing\nmethods in both synthetic data experiments and in a case study of assigning\ntreatments for postpartum hypertension. In particular, PNNs are shown to\nproduce policies that could reduce peak blood pressure by 5.47 mm Hg (p=0.02)\nover existing clinical practice, and by 2 mm Hg (p=0.01) over the next best\nprescriptive modeling technique. Moreover PNNs were more likely than all other\nmodels to correctly identify clinically significant features while existing\nmodels relied on potentially dangerous features such as patient insurance\ninformation and race that could lead to bias in treatment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18851v1",
    "published_date": "2024-02-29 05:00:01 UTC",
    "updated_date": "2024-02-29 05:00:01 UTC"
  },
  {
    "arxiv_id": "2402.18849v1",
    "title": "Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence",
    "authors": [
      "Mingyang Li",
      "Maoqin Yuan",
      "Luyao Li",
      "Han Pengsihua"
    ],
    "abstract": "This study discusses a new method combining image steganography technology\nwith Natural Language Processing (NLP) large models, aimed at improving the\naccuracy and robustness of extracting steganographic text. Traditional Least\nSignificant Bit (LSB) steganography techniques face challenges in accuracy and\nrobustness of information extraction when dealing with complex character\nencoding, such as Chinese characters. To address this issue, this study\nproposes an innovative LSB-NLP hybrid framework. This framework integrates the\nadvanced capabilities of NLP large models, such as error detection, correction,\nand semantic consistency analysis, as well as information reconstruction\ntechniques, thereby significantly enhancing the robustness of steganographic\ntext extraction. Experimental results show that the LSB-NLP hybrid framework\nexcels in improving the extraction accuracy of steganographic text, especially\nin handling Chinese characters. The findings of this study not only confirm the\neffectiveness of combining image steganography technology and NLP large models\nbut also propose new ideas for research and application in the field of\ninformation hiding. The successful implementation of this interdisciplinary\napproach demonstrates the great potential of integrating image steganography\ntechnology with natural language processing technology in solving complex\ninformation processing problems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18849v1",
    "published_date": "2024-02-29 04:53:06 UTC",
    "updated_date": "2024-02-29 04:53:06 UTC"
  },
  {
    "arxiv_id": "2402.18826v2",
    "title": "The Machine Can't Replace the Human Heart",
    "authors": [
      "Baihan Lin"
    ],
    "abstract": "What is the true heart of mental healthcare -- innovation or humanity? Can\nvirtual therapy ever replicate the profound human bonds where healing arises?\nAs artificial intelligence and immersive technologies promise expanded access,\nsafeguards must ensure technologies remain supplementary tools guided by\nproviders' wisdom. Implementation requires nuance balancing efficiency and\nempathy. If conscious of ethical risks, perhaps AI could restore humanity by\nautomating tasks, giving providers more time to listen. Yet no algorithm can\nreplicate the seat of dignity within. We must ask ourselves: What future has\npeople at its core? One where AI thoughtfully plays a collaborative role? Or\nwhere pursuit of progress leaves vulnerability behind? This commentary argues\nfor a balanced approach thoughtfully integrating technology while retaining\ncare's irreplaceable human essence, at the heart of this profoundly human\nprofession. Ultimately, by nurturing innovation and humanity together, perhaps\nwe reach new heights of empathy previously unimaginable.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "q-bio.NC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18826v2",
    "published_date": "2024-02-29 03:20:53 UTC",
    "updated_date": "2024-03-01 02:21:23 UTC"
  },
  {
    "arxiv_id": "2402.18815v3",
    "title": "How do Large Language Models Handle Multilingualism?",
    "authors": [
      "Yiran Zhao",
      "Wenxuan Zhang",
      "Guizhen Chen",
      "Kenji Kawaguchi",
      "Lidong Bing"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse languages. This study explores how LLMs handle multilingualism. Based\non observed language ratio shifts among layers and the relationships between\nnetwork structures and certain capabilities, we hypothesize the LLM's\nmultilingual workflow ($\\texttt{MWork}$): LLMs initially understand the query,\nconverting multilingual inputs into English for task-solving. In the\nintermediate layers, they employ English for thinking and incorporate\nmultilingual knowledge with self-attention and feed-forward structures,\nrespectively. In the final layers, LLMs generate responses aligned with the\noriginal language of the query. To verify $\\texttt{MWork}$, we introduce\nParallel Language-specific Neuron Detection ($\\texttt{PLND}$) to identify\nactivated neurons for inputs in different languages without any labeled data.\nUsing $\\texttt{PLND}$, we validate $\\texttt{MWork}$ through extensive\nexperiments involving the deactivation of language-specific neurons across\nvarious layers and structures. Moreover, $\\texttt{MWork}$ allows fine-tuning of\nlanguage-specific neurons with a small dataset, enhancing multilingual\nabilities in a specific language without compromising others. This approach\nresults in an average improvement of $3.6\\%$ for high-resource languages and\n$2.3\\%$ for low-resource languages across all tasks with just $400$ documents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18815v3",
    "published_date": "2024-02-29 02:55:26 UTC",
    "updated_date": "2024-11-10 12:49:15 UTC"
  },
  {
    "arxiv_id": "2402.18807v1",
    "title": "On the Decision-Making Abilities in Role-Playing using Large Language Models",
    "authors": [
      "Chenglei Shen",
      "Guofu Xie",
      "Xiao Zhang",
      "Jun Xu"
    ],
    "abstract": "Large language models (LLMs) are now increasingly utilized for role-playing\ntasks, especially in impersonating domain-specific experts, primarily through\nrole-playing prompts. When interacting in real-world scenarios, the\ndecision-making abilities of a role significantly shape its behavioral\npatterns. In this paper, we concentrate on evaluating the decision-making\nabilities of LLMs post role-playing thereby validating the efficacy of\nrole-playing. Our goal is to provide metrics and guidance for enhancing the\ndecision-making abilities of LLMs in role-playing tasks. Specifically, we first\nuse LLMs to generate virtual role descriptions corresponding to the 16\npersonality types of Myers-Briggs Type Indicator (abbreviated as MBTI)\nrepresenting a segmentation of the population. Then we design specific\nquantitative operations to evaluate the decision-making abilities of LLMs post\nrole-playing from four aspects: adaptability, exploration$\\&$exploitation\ntrade-off ability, reasoning ability, and safety. Finally, we analyze the\nassociation between the performance of decision-making and the corresponding\nMBTI types through GPT-4. Extensive experiments demonstrate stable differences\nin the four aspects of decision-making abilities across distinct roles,\nsignifying a robust correlation between decision-making abilities and the roles\nemulated by LLMs. These results underscore that LLMs can effectively\nimpersonate varied roles while embodying their genuine sociological\ncharacteristics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18807v1",
    "published_date": "2024-02-29 02:22:23 UTC",
    "updated_date": "2024-02-29 02:22:23 UTC"
  },
  {
    "arxiv_id": "2403.00839v1",
    "title": "ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph",
    "authors": [
      "Xukun Liu",
      "Zhiyuan Peng",
      "Xiaoyuan Yi",
      "Xing Xie",
      "Lirong Xiang",
      "Yuchen Liu",
      "Dongkuan Xu"
    ],
    "abstract": "While achieving remarkable progress in a broad range of tasks, large language\nmodels (LLMs) remain significantly limited in properly using massive external\ntools. Existing in-context learning approaches simply format tools into a list\nof plain text descriptions and input them to LLMs, from which, LLMs generate a\nsequence of tool calls to solve problems step by step. Such a paradigm ignores\nthe intrinsic dependency between tools and offloads all reasoning loads to\nLLMs, making them restricted to a limited number of specifically designed\ntools. It thus remains challenging for LLMs to operate on a library of massive\ntools, casting a great limitation when confronted with real-world scenarios.\nThis paper proposes ToolNet, a plug-and-play framework that scales up the\nnumber of tools to thousands with a moderate increase in token consumption.\nToolNet organizes tools into a directed graph. Each node represents a tool, and\nweighted edges denote tool transition. Starting from an initial tool node, an\nLLM navigates in the graph by iteratively choosing the next one from its\nsuccessors until the task is resolved. Extensive experiments show that ToolNet\ncan achieve impressive results in challenging multi-hop tool learning datasets\nand is resilient to tool failures.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00839v1",
    "published_date": "2024-02-29 02:04:00 UTC",
    "updated_date": "2024-02-29 02:04:00 UTC"
  },
  {
    "arxiv_id": "2402.18784v1",
    "title": "Brain-inspired and Self-based Artificial Intelligence",
    "authors": [
      "Yi Zeng",
      "Feifei Zhao",
      "Yuxuan Zhao",
      "Dongcheng Zhao",
      "Enmeng Lu",
      "Qian Zhang",
      "Yuwei Wang",
      "Hui Feng",
      "Zhuoya Zhao",
      "Jihang Wang",
      "Qingqun Kong",
      "Yinqian Sun",
      "Yang Li",
      "Guobin Shen",
      "Bing Han",
      "Yiting Dong",
      "Wenxuan Pan",
      "Xiang He",
      "Aorigele Bao",
      "Jin Wang"
    ],
    "abstract": "The question \"Can machines think?\" and the Turing Test to assess whether\nmachines could achieve human-level intelligence is one of the roots of AI. With\nthe philosophical argument \"I think, therefore I am\", this paper challenge the\nidea of a \"thinking machine\" supported by current AIs since there is no sense\nof self in them. Current artificial intelligence is only seemingly intelligent\ninformation processing and does not truly understand or be subjectively aware\nof oneself and perceive the world with the self as human intelligence does. In\nthis paper, we introduce a Brain-inspired and Self-based Artificial\nIntelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to\ncoordinating various cognitive functions and learning strategies in a\nself-organized manner to build human-level AI models and robotic applications.\nSpecifically, BriSe AI emphasizes the crucial role of the Self in shaping the\nfuture AI, rooted with a practical hierarchical Self framework, including\nPerception and Learning, Bodily Self, Autonomous Self, Social Self, and\nConceptual Self. The hierarchical framework of the Self highlights self-based\nenvironment perception, self-bodily modeling, autonomous interaction with the\nenvironment, social interaction and collaboration with others, and even more\nabstract understanding of the Self. Furthermore, the positive mutual promotion\nand support among multiple levels of Self, as well as between Self and\nlearning, enhance the BriSe AI's conscious understanding of information and\nflexible adaptation to complex environments, serving as a driving force\npropelling BriSe AI towards real Artificial General Intelligence.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18784v1",
    "published_date": "2024-02-29 01:15:17 UTC",
    "updated_date": "2024-02-29 01:15:17 UTC"
  }
]