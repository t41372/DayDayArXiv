[
  {
    "arxiv_id": "2409.00564v3",
    "title": "Using Deep Learning to Design High Aspect Ratio Fusion Devices",
    "authors": [
      "P. Curvo",
      "D. R. Ferreira",
      "R. Jorge"
    ],
    "abstract": "The design of fusion devices is typically based on computationally expensive\nsimulations. This can be alleviated using high aspect ratio models that employ\na reduced number of free parameters, especially in the case of stellarator\noptimization where non-axisymmetric magnetic fields with a large parameter\nspace are optimized to satisfy certain performance criteria. However,\noptimization is still required to find configurations with properties such as\nlow elongation, high rotational transform, finite plasma beta, and good fast\nparticle confinement. In this work, we train a machine learning model to\nconstruct configurations with favorable confinement properties by finding a\nsolution to the inverse design problem, that is, obtaining a set of model input\nparameters for given desired properties. Since the solution of the inverse\nproblem is non-unique, a probabilistic approach, based on mixture density\nnetworks, is used. It is shown that optimized configurations can be generated\nreliably using this method.",
    "categories": [
      "physics.plasm-ph",
      "cs.AI"
    ],
    "primary_category": "physics.plasm-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00564v3",
    "published_date": "2024-08-31 23:28:10 UTC",
    "updated_date": "2025-01-14 21:45:16 UTC"
  },
  {
    "arxiv_id": "2409.00557v3",
    "title": "Learning to Ask: When LLM Agents Meet Unclear Instruction",
    "authors": [
      "Wenxuan Wang",
      "Juluan Shi",
      "Zixuan Ling",
      "Yuk-Kit Chan",
      "Chaozheng Wang",
      "Cheryl Lee",
      "Youliang Yuan",
      "Jen-tse Huang",
      "Wenxiang Jiao",
      "Michael R. Lyu"
    ],
    "abstract": "Equipped with the capability to call functions, modern large language models\n(LLMs) can leverage external tools for addressing a range of tasks unattainable\nthrough language skills alone. However, the effective execution of these tools\nrelies heavily not just on the advanced capabilities of LLMs but also on\nprecise user instructions, which often cannot be ensured in the real world. To\nevaluate the performance of LLMs tool-use under imperfect instructions, we\nmeticulously examine the real-world instructions queried from users, analyze\nthe error patterns, and build a challenging tool-use benchmark called Noisy\nToolBench (NoisyToolBench). We find that due to the next-token prediction\ntraining objective, LLMs tend to arbitrarily generate the missed argument,\nwhich may lead to hallucinations and risks. To address this issue, we propose a\nnovel framework, Ask-when-Needed (AwN), which prompts LLMs to ask questions to\nusers whenever they encounter obstacles due to unclear instructions. Moreover,\nto reduce the manual labor involved in user-LLM interaction and assess LLMs\nperformance in tool utilization from both accuracy and efficiency perspectives,\nwe design an automated evaluation tool named ToolEvaluator. Our experiments\ndemonstrate that the AwN significantly outperforms existing frameworks for tool\nlearning in the NoisyToolBench. We will release all related code and datasets\nto support future research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00557v3",
    "published_date": "2024-08-31 23:06:12 UTC",
    "updated_date": "2025-02-16 14:50:40 UTC"
  },
  {
    "arxiv_id": "2409.00553v2",
    "title": "Multi-Output Distributional Fairness via Post-Processing",
    "authors": [
      "Gang Li",
      "Qihang Lin",
      "Ayush Ghosh",
      "Tianbao Yang"
    ],
    "abstract": "The post-processing approaches are becoming prominent techniques to enhance\nmachine learning models' fairness because of their intuitiveness, low\ncomputational cost, and excellent scalability. However, most existing\npost-processing methods are designed for task-specific fairness measures and\nare limited to single-output models. In this paper, we introduce a\npost-processing method for multi-output models, such as the ones used for\nmulti-task/multi-class classification and representation learning, to enhance a\nmodel's distributional parity, a task-agnostic fairness measure. Existing\nmethods for achieving distributional parity rely on the (inverse) cumulative\ndensity function of a model's output, restricting their applicability to\nsingle-output models. Extending previous works, we propose to employ optimal\ntransport mappings to move a model's outputs across different groups towards\ntheir empirical Wasserstein barycenter. An approximation technique is applied\nto reduce the complexity of computing the exact barycenter and a kernel\nregression method is proposed to extend this process to out-of-sample data. Our\nempirical studies evaluate the proposed approach against various baselines on\nmulti-task/multi-class classification and representation learning tasks,\ndemonstrating the effectiveness of the proposed approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00553v2",
    "published_date": "2024-08-31 22:41:26 UTC",
    "updated_date": "2025-03-20 16:42:22 UTC"
  },
  {
    "arxiv_id": "2409.00551v1",
    "title": "Testing and Evaluation of Large Language Models: Correctness, Non-Toxicity, and Fairness",
    "authors": [
      "Wenxuan Wang"
    ],
    "abstract": "Large language models (LLMs), such as ChatGPT, have rapidly penetrated into\npeople's work and daily lives over the past few years, due to their\nextraordinary conversational skills and intelligence. ChatGPT has become the\nfastest-growing software in terms of user numbers in human history and become\nan important foundational model for the next generation of artificial\nintelligence applications. However, the generations of LLMs are not entirely\nreliable, often producing content with factual errors, biases, and toxicity.\nGiven their vast number of users and wide range of application scenarios, these\nunreliable responses can lead to many serious negative impacts. This thesis\nintroduces the exploratory works in the field of language model reliability\nduring the PhD study, focusing on the correctness, non-toxicity, and fairness\nof LLMs from both software testing and natural language processing\nperspectives. First, to measure the correctness of LLMs, we introduce two\ntesting frameworks, FactChecker and LogicAsker, to evaluate factual knowledge\nand logical reasoning accuracy, respectively. Second, for the non-toxicity of\nLLMs, we introduce two works for red-teaming LLMs. Third, to evaluate the\nfairness of LLMs, we introduce two evaluation frameworks, BiasAsker and\nXCulturalBench, to measure the social bias and cultural bias of LLMs,\nrespectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "PhD Thesis",
    "pdf_url": "http://arxiv.org/pdf/2409.00551v1",
    "published_date": "2024-08-31 22:21:04 UTC",
    "updated_date": "2024-08-31 22:21:04 UTC"
  },
  {
    "arxiv_id": "2409.00547v1",
    "title": "Data Augmentation for Image Classification using Generative AI",
    "authors": [
      "Fazle Rahat",
      "M Shifat Hossain",
      "Md Rubel Ahmed",
      "Sumit Kumar Jha",
      "Rickard Ewetz"
    ],
    "abstract": "Scaling laws dictate that the performance of AI models is proportional to the\namount of available data. Data augmentation is a promising solution to\nexpanding the dataset size. Traditional approaches focused on augmentation\nusing rotation, translation, and resizing. Recent approaches use generative AI\nmodels to improve dataset diversity. However, the generative methods struggle\nwith issues such as subject corruption and the introduction of irrelevant\nartifacts. In this paper, we propose the Automated Generative Data Augmentation\n(AGA). The framework combines the utility of large language models (LLMs),\ndiffusion models, and segmentation models to augment data. AGA preserves\nforeground authenticity while ensuring background diversity. Specific\ncontributions include: i) segment and superclass based object extraction, ii)\nprompt diversity with combinatorial complexity using prompt decomposition, and\niii) affine subject manipulation. We evaluate AGA against state-of-the-art\n(SOTA) techniques on three representative datasets, ImageNet, CUB, and\niWildCam. The experimental evaluation demonstrates an accuracy improvement of\n15.6% and 23.5% for in and out-of-distribution data compared to baseline\nmodels, respectively. There is also a 64.3% improvement in SIC score compared\nto the baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10; I.5.1"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 15 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.00547v1",
    "published_date": "2024-08-31 21:16:43 UTC",
    "updated_date": "2024-08-31 21:16:43 UTC"
  },
  {
    "arxiv_id": "2409.11409v1",
    "title": "CyberNFTs: Conceptualizing a decentralized and reward-driven intrusion detection system with ML",
    "authors": [
      "Synim Selimi",
      "Blerim Rexha",
      "Kamer Vishi"
    ],
    "abstract": "The rapid evolution of the Internet, particularly the emergence of Web3, has\ntransformed the ways people interact and share data. Web3, although still not\nwell defined, is thought to be a return to the decentralization of\ncorporations' power over user data. Despite the obsolescence of the idea of\nbuilding systems to detect and prevent cyber intrusions, this is still a topic\nof interest. This paper proposes a novel conceptual approach for implementing\ndecentralized collaborative intrusion detection networks (CIDN) through a\nproof-of-concept. The study employs an analytical and comparative methodology,\nexamining the synergy between cutting-edge Web3 technologies and information\nsecurity. The proposed model incorporates blockchain concepts, cyber\nnon-fungible token (cyberNFT) rewards, machine learning algorithms, and\npublish/subscribe architectures. Finally, the paper discusses the strengths and\nlimitations of the proposed system, offering insights into the potential of\ndecentralized cybersecurity models.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "9 pages, 6 figures, 1 table, 1 algorithm, 1 listing, journal article",
    "pdf_url": "http://arxiv.org/pdf/2409.11409v1",
    "published_date": "2024-08-31 21:15:26 UTC",
    "updated_date": "2024-08-31 21:15:26 UTC"
  },
  {
    "arxiv_id": "2409.00544v1",
    "title": "Large Language Models-Enabled Digital Twins for Precision Medicine in Rare Gynecological Tumors",
    "authors": [
      "Jacqueline Lammert",
      "Nicole Pfarr",
      "Leonid Kuligin",
      "Sonja Mathes",
      "Tobias Dreyer",
      "Luise Modersohn",
      "Patrick Metzger",
      "Dyke Ferber",
      "Jakob Nikolas Kather",
      "Daniel Truhn",
      "Lisa Christine Adams",
      "Keno Kyrill Bressem",
      "Sebastian Lange",
      "Kristina Schwamborn",
      "Martin Boeker",
      "Marion Kiechle",
      "Ulrich A. Schatz",
      "Holger Bronger",
      "Maximilian Tschochohei"
    ],
    "abstract": "Rare gynecological tumors (RGTs) present major clinical challenges due to\ntheir low incidence and heterogeneity. The lack of clear guidelines leads to\nsuboptimal management and poor prognosis. Molecular tumor boards accelerate\naccess to effective therapies by tailoring treatment based on biomarkers,\nbeyond cancer type. Unstructured data that requires manual curation hinders\nefficient use of biomarker profiling for therapy matching. This study explores\nthe use of large language models (LLMs) to construct digital twins for\nprecision medicine in RGTs.\n  Our proof-of-concept digital twin system integrates clinical and biomarker\ndata from institutional and published cases (n=21) and literature-derived data\n(n=655 publications with n=404,265 patients) to create tailored treatment plans\nfor metastatic uterine carcinosarcoma, identifying options potentially missed\nby traditional, single-source analysis. LLM-enabled digital twins efficiently\nmodel individual patient trajectories. Shifting to a biology-based rather than\norgan-based tumor definition enables personalized care that could advance RGT\nmanagement and thus enhance patient outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.QM",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 2 figures, 3 tables, supplements, original article",
    "pdf_url": "http://arxiv.org/pdf/2409.00544v1",
    "published_date": "2024-08-31 21:14:09 UTC",
    "updated_date": "2024-08-31 21:14:09 UTC"
  },
  {
    "arxiv_id": "2409.03789v1",
    "title": "BreachSeek: A Multi-Agent Automated Penetration Tester",
    "authors": [
      "Ibrahim Alshehri",
      "Adnan Alshehri",
      "Abdulrahman Almalki",
      "Majed Bamardouf",
      "Alaqsa Akbar"
    ],
    "abstract": "The increasing complexity and scale of modern digital environments have\nexposed significant gaps in traditional cybersecurity penetration testing\nmethods, which are often time-consuming, labor-intensive, and unable to rapidly\nadapt to emerging threats. There is a critical need for an automated solution\nthat can efficiently identify and exploit vulnerabilities across diverse\nsystems without extensive human intervention. BreachSeek addresses this\nchallenge by providing an AI-driven multi-agent software platform that\nleverages Large Language Models (LLMs) integrated through LangChain and\nLangGraph in Python. This system enables autonomous agents to conduct thorough\npenetration testing by identifying vulnerabilities, simulating a variety of\ncyberattacks, executing exploits, and generating comprehensive security\nreports. In preliminary evaluations, BreachSeek successfully exploited\nvulnerabilities in exploitable machines within local networks, demonstrating\nits practical effectiveness. Future developments aim to expand its\ncapabilities, positioning it as an indispensable tool for cybersecurity\nprofessionals.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.03789v1",
    "published_date": "2024-08-31 19:15:38 UTC",
    "updated_date": "2024-08-31 19:15:38 UTC"
  },
  {
    "arxiv_id": "2409.00518v1",
    "title": "Mapping earth mounds from space",
    "authors": [
      "Baki Uzun",
      "Shivam Pande",
      "Gwendal Cachin-Bernard",
      "Minh-Tan Pham",
      "Sébastien Lefèvre",
      "Rumais Blatrix",
      "Doyle McKey"
    ],
    "abstract": "Regular patterns of vegetation are considered widespread landscapes, although\ntheir global extent has never been estimated. Among them, spotted landscapes\nare of particular interest in the context of climate change. Indeed, regularly\nspaced vegetation spots in semi-arid shrublands result from extreme resource\ndepletion and prefigure catastrophic shift of the ecosystem to a homogeneous\ndesert, while termite mounds also producing spotted landscapes were shown to\nincrease robustness to climate change. Yet, their identification at large scale\ncalls for automatic methods, for instance using the popular deep learning\nframework, able to cope with a vast amount of remote sensing data, e.g.,\noptical satellite imagery. In this paper, we tackle this problem and benchmark\nsome state-of-the-art deep networks on several landscapes and geographical\nareas. Despite the promising results we obtained, we found that more research\nis needed to be able to map automatically these earth mounds from space.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.00518v1",
    "published_date": "2024-08-31 18:08:37 UTC",
    "updated_date": "2024-08-31 18:08:37 UTC"
  },
  {
    "arxiv_id": "2409.00513v1",
    "title": "Plant detection from ultra high resolution remote sensing images: A Semantic Segmentation approach based on fuzzy loss",
    "authors": [
      "Shivam Pande",
      "Baki Uzun",
      "Florent Guiotte",
      "Thomas Corpetti",
      "Florian Delerue",
      "Sébastien Lefèvre"
    ],
    "abstract": "In this study, we tackle the challenge of identifying plant species from\nultra high resolution (UHR) remote sensing images. Our approach involves\nintroducing an RGB remote sensing dataset, characterized by millimeter-level\nspatial resolution, meticulously curated through several field expeditions\nacross a mountainous region in France covering various landscapes. The task of\nplant species identification is framed as a semantic segmentation problem for\nits practical and efficient implementation across vast geographical areas.\nHowever, when dealing with segmentation masks, we confront instances where\ndistinguishing boundaries between plant species and their background is\nchallenging. We tackle this issue by introducing a fuzzy loss within the\nsegmentation model. Instead of utilizing one-hot encoded ground truth (GT), our\nmodel incorporates Gaussian filter refined GT, introducing stochasticity during\ntraining. First experimental results obtained on both our UHR dataset and a\npublic dataset are presented, showing the relevance of the proposed\nmethodology, as well as the need for future improvement.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.00513v1",
    "published_date": "2024-08-31 17:40:17 UTC",
    "updated_date": "2024-08-31 17:40:17 UTC"
  },
  {
    "arxiv_id": "2409.00510v1",
    "title": "Streamlining Forest Wildfire Surveillance: AI-Enhanced UAVs Utilizing the FLAME Aerial Video Dataset for Lightweight and Efficient Monitoring",
    "authors": [
      "Lemeng Zhao",
      "Junjie Hu",
      "Jianchao Bi",
      "Yanbing Bai",
      "Erick Mas",
      "Shunichi Koshimura"
    ],
    "abstract": "In recent years, unmanned aerial vehicles (UAVs) have played an increasingly\ncrucial role in supporting disaster emergency response efforts by analyzing\naerial images. While current deep-learning models focus on improving accuracy,\nthey often overlook the limited computing resources of UAVs. This study\nrecognizes the imperative for real-time data processing in disaster response\nscenarios and introduces a lightweight and efficient approach for aerial video\nunderstanding. Our methodology identifies redundant portions within the video\nthrough policy networks and eliminates this excess information using frame\ncompression techniques. Additionally, we introduced the concept of a `station\npoint,' which leverages future information in the sequential policy network,\nthereby enhancing accuracy. To validate our method, we employed the wildfire\nFLAME dataset. Compared to the baseline, our approach reduces computation costs\nby more than 13 times while boosting accuracy by 3$\\%$. Moreover, our method\ncan intelligently select salient frames from the video, refining the dataset.\nThis feature enables sophisticated models to be effectively trained on a\nsmaller dataset, significantly reducing the time spent during the training\nprocess.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accpeted by Proceedings of the International Conference on\n  Intelligent Robots and Systems (2024 IROS)",
    "pdf_url": "http://arxiv.org/pdf/2409.00510v1",
    "published_date": "2024-08-31 17:26:53 UTC",
    "updated_date": "2024-08-31 17:26:53 UTC"
  },
  {
    "arxiv_id": "2409.00494v2",
    "title": "GenAI-powered Multi-Agent Paradigm for Smart Urban Mobility: Opportunities and Challenges for Integrating Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) with Intelligent Transportation Systems",
    "authors": [
      "Haowen Xu",
      "Jinghui Yuan",
      "Anye Zhou",
      "Guanhao Xu",
      "Wan Li",
      "Xuegang Ban",
      "Xinyue Ye"
    ],
    "abstract": "Leveraging recent advances in generative AI, multi-agent systems are\nincreasingly being developed to enhance the functionality and efficiency of\nsmart city applications. This paper explores the transformative potential of\nlarge language models (LLMs) and emerging Retrieval-Augmented Generation (RAG)\ntechnologies in Intelligent Transportation Systems (ITS), paving the way for\ninnovative solutions to address critical challenges in urban mobility. We begin\nby providing a comprehensive overview of the current state-of-the-art in\nmobility data, ITS, and Connected Vehicles (CV) applications. Building on this\nreview, we discuss the rationale behind RAG and examine the opportunities for\nintegrating these Generative AI (GenAI) technologies into the smart mobility\nsector. We propose a conceptual framework aimed at developing multi-agent\nsystems capable of intelligently and conversationally delivering smart mobility\nservices to urban commuters, transportation operators, and decision-makers. Our\napproach seeks to foster an autonomous and intelligent approach that (a)\npromotes science-based advisory to reduce traffic congestion, accidents, and\ncarbon emissions at multiple scales, (b) facilitates public education and\nengagement in participatory mobility management, and (c) automates specialized\ntransportation management tasks and the development of critical ITS platforms,\nsuch as data analytics and interpretation, knowledge representation, and\ntraffic simulations. By integrating LLM and RAG, our approach seeks to overcome\nthe limitations of traditional rule-based multi-agent systems, which rely on\nfixed knowledge bases and limited reasoning capabilities. This integration\npaves the way for a more scalable, intuitive, and automated multi-agent\nparadigm, driving advancements in ITS and urban mobility.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00494v2",
    "published_date": "2024-08-31 16:14:42 UTC",
    "updated_date": "2024-09-04 18:00:53 UTC"
  },
  {
    "arxiv_id": "2409.00489v1",
    "title": "Geospatial foundation models for image analysis: evaluating and enhancing NASA-IBM Prithvi's domain adaptability",
    "authors": [
      "Chia-Yu Hsu",
      "Wenwen Li",
      "Sizhe Wang"
    ],
    "abstract": "Research on geospatial foundation models (GFMs) has become a trending topic\nin geospatial artificial intelligence (AI) research due to their potential for\nachieving high generalizability and domain adaptability, reducing model\ntraining costs for individual researchers. Unlike large language models, such\nas ChatGPT, constructing visual foundation models for image analysis,\nparticularly in remote sensing, encountered significant challenges such as\nformulating diverse vision tasks into a general problem framework. This paper\nevaluates the recently released NASA-IBM GFM Prithvi for its predictive\nperformance on high-level image analysis tasks across multiple benchmark\ndatasets. Prithvi was selected because it is one of the first open-source GFMs\ntrained on time-series of high-resolution remote sensing imagery. A series of\nexperiments were designed to assess Prithvi's performance as compared to other\npre-trained task-specific AI models in geospatial image analysis. New\nstrategies, including band adaptation, multi-scale feature generation, and\nfine-tuning techniques, are introduced and integrated into an image analysis\npipeline to enhance Prithvi's domain adaptation capability and improve model\nperformance. In-depth analyses reveal Prithvi's strengths and weaknesses,\noffering insights for both improving Prithvi and developing future visual\nfoundation models for geospatial tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00489v1",
    "published_date": "2024-08-31 15:51:23 UTC",
    "updated_date": "2024-08-31 15:51:23 UTC"
  },
  {
    "arxiv_id": "2409.00488v2",
    "title": "Rapid Gyroscope Calibration: A Deep Learning Approach",
    "authors": [
      "Yair Stolero",
      "Itzik Klein"
    ],
    "abstract": "Low-cost gyroscope calibration is essential for ensuring the accuracy and\nreliability of gyroscope measurements. Stationary calibration estimates the\ndeterministic parts of measurement errors. To this end, a common practice is to\naverage the gyroscope readings during a predefined period and estimate the\ngyroscope bias. Calibration duration plays a crucial role in performance,\ntherefore, longer periods are preferred. However, some applications require\nquick startup times and calibration is therefore allowed only for a short time.\nIn this work, we focus on reducing low-cost gyroscope calibration time using\ndeep learning methods. We propose a deep-learning framework and explore the\npossibilities of using multiple real and virtual gyroscopes to improve the\ncalibration performance of single gyroscopes. To train and validate our\napproach, we recorded a dataset consisting of 169 hours of gyroscope readings,\nusing 24 gyroscopes of two different brands. We also created a virtual dataset\nconsisting of simulated gyroscope readings. The two datasets were used to\nevaluate our proposed approach. One of our key achievements in this work is\nreducing gyroscope calibration time by up to 89% using three low-cost\ngyroscopes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "10 Pages, 14 Figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00488v2",
    "published_date": "2024-08-31 15:47:31 UTC",
    "updated_date": "2024-10-02 12:55:53 UTC"
  },
  {
    "arxiv_id": "2409.12964v3",
    "title": "OpenRANet: Neuralized Spectrum Access by Joint Subcarrier and Power Allocation with Optimization-based Deep Learning",
    "authors": [
      "Siya Chen",
      "Chee Wei Tan",
      "Xiangping Zhai",
      "H. Vincent Poor"
    ],
    "abstract": "The next-generation radio access network (RAN), known as Open RAN, is poised\nto feature an AI-native interface for wireless cellular networks, including\nemerging satellite-terrestrial systems, making deep learning integral to its\noperation. In this paper, we address the nonconvex optimization challenge of\njoint subcarrier and power allocation in Open RAN, with the objective of\nminimizing the total power consumption while ensuring users meet their\ntransmission data rate requirements. We propose OpenRANet, an\noptimization-based deep learning model that integrates machine-learning\ntechniques with iterative optimization algorithms. We start by transforming the\noriginal nonconvex problem into convex subproblems through decoupling, variable\ntransformation, and relaxation techniques. These subproblems are then\nefficiently solved using iterative methods within the standard interference\nfunction framework, enabling the derivation of primal-dual solutions. These\nsolutions integrate seamlessly as a convex optimization layer within OpenRANet,\nenhancing constraint adherence, solution accuracy, and computational efficiency\nby combining machine learning with convex analysis, as shown in numerical\nexperiments. OpenRANet also serves as a foundation for designing\nresource-constrained AI-native wireless optimization strategies for broader\nscenarios like multi-cell systems, satellite-terrestrial networks, and future\nOpen RAN deployments with complex power consumption requirements.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "This paper has been accepted by the IEEE Transactions on Green\n  Communications and Networking",
    "pdf_url": "http://arxiv.org/pdf/2409.12964v3",
    "published_date": "2024-08-31 13:10:48 UTC",
    "updated_date": "2025-02-11 02:06:03 UTC"
  },
  {
    "arxiv_id": "2409.00448v1",
    "title": "PSLF: A PID Controller-incorporated Second-order Latent Factor Analysis Model for Recommender System",
    "authors": [
      "Jialiang Wang",
      "Yan Xia",
      "Ye Yuan"
    ],
    "abstract": "A second-order-based latent factor (SLF) analysis model demonstrates superior\nperformance in graph representation learning, particularly for high-dimensional\nand incomplete (HDI) interaction data, by incorporating the curvature\ninformation of the loss landscape. However, its objective function is commonly\nbi-linear and non-convex, causing the SLF model to suffer from a low\nconvergence rate. To address this issue, this paper proposes a PID\ncontroller-incorporated SLF (PSLF) model, leveraging two key strategies: a)\nrefining learning error estimation by incorporating the PID controller\nprinciples, and b) acquiring second-order information insights through\nHessian-vector products. Experimental results on multiple HDI datasets indicate\nthat the proposed PSLF model outperforms four state-of-the-art latent factor\nmodels based on advanced optimizers regarding convergence rates and\ngeneralization performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00448v1",
    "published_date": "2024-08-31 13:01:58 UTC",
    "updated_date": "2024-08-31 13:01:58 UTC"
  },
  {
    "arxiv_id": "2409.00447v1",
    "title": "The MERIT Dataset: Modelling and Efficiently Rendering Interpretable Transcripts",
    "authors": [
      "I. de Rodrigo",
      "A. Sanchez-Cuadrado",
      "J. Boal",
      "A. J. Lopez-Lopez"
    ],
    "abstract": "This paper introduces the MERIT Dataset, a multimodal (text + image + layout)\nfully labeled dataset within the context of school reports. Comprising over 400\nlabels and 33k samples, the MERIT Dataset is a valuable resource for training\nmodels in demanding Visually-rich Document Understanding (VrDU) tasks. By its\nnature (student grade reports), the MERIT Dataset can potentially include\nbiases in a controlled way, making it a valuable tool to benchmark biases\ninduced in Language Models (LLMs). The paper outlines the dataset's generation\npipeline and highlights its main features in the textual, visual, layout, and\nbias domains. To demonstrate the dataset's utility, we present a benchmark with\ntoken classification models, showing that the dataset poses a significant\nchallenge even for SOTA models and that these would greatly benefit from\nincluding samples from the MERIT Dataset in their pretraining phase.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00447v1",
    "published_date": "2024-08-31 12:56:38 UTC",
    "updated_date": "2024-08-31 12:56:38 UTC"
  },
  {
    "arxiv_id": "2409.02119v1",
    "title": "CoRA: Optimizing Low-Rank Adaptation with Common Subspace of Large Language Models",
    "authors": [
      "Xiaojun Xiao",
      "Sen Shen",
      "Qiming Bao",
      "Hongfei Rong",
      "Kairui Liu",
      "Zhongsheng Wang",
      "Jiamou Liu"
    ],
    "abstract": "In fine-tuning large language models (LLMs), conserving computational\nresources while maintaining effectiveness and improving outcomes within the\nsame computational constraints is crucial. The Low-Rank Adaptation (LoRA)\nstrategy balances efficiency and performance in fine-tuning large models by\nreducing the number of trainable parameters and computational costs. However,\ncurrent advancements in LoRA might be focused on its fine-tuning methodologies,\nwith not as much exploration as might be expected into further compression of\nLoRA. Since most of LoRA's parameters might still be superfluous, this may lead\nto unnecessary wastage of computational resources. In this paper, we propose\n\\textbf{CoRA}: leveraging shared knowledge to optimize LoRA training by\nsubstituting its matrix $B$ with a common subspace from large models. Our\ntwo-fold method includes (1) Freezing the substitute matrix $B$ to halve\nparameters while training matrix $A$ for specific tasks and (2) Using the\nsubstitute matrix $B$ as an enhanced initial state for the original matrix $B$,\nachieving improved results with the same parameters. Our experiments show that\nthe first approach achieves the same efficacy as the original LoRA fine-tuning\nwhile being more efficient than halving parameters. At the same time, the\nsecond approach has some improvements compared to LoRA's original fine-tuning\nperformance. They generally attest to the effectiveness of our work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.02119v1",
    "published_date": "2024-08-31 12:48:27 UTC",
    "updated_date": "2024-08-31 12:48:27 UTC"
  },
  {
    "arxiv_id": "2409.00438v1",
    "title": "Breaking Down Financial News Impact: A Novel AI Approach with Geometric Hypergraphs",
    "authors": [
      "Anoushka Harit",
      "Zhongtian Sun",
      "Jongmin Yu",
      "Noura Al Moubayed"
    ],
    "abstract": "In the fast-paced and volatile financial markets, accurately predicting stock\nmovements based on financial news is critical for investors and analysts.\nTraditional models often struggle to capture the intricate and dynamic\nrelationships between news events and market reactions, limiting their ability\nto provide actionable insights. This paper introduces a novel approach\nleveraging Explainable Artificial Intelligence (XAI) through the development of\na Geometric Hypergraph Attention Network (GHAN) to analyze the impact of\nfinancial news on market behaviours. Geometric hypergraphs extend traditional\ngraph structures by allowing edges to connect multiple nodes, effectively\nmodelling high-order relationships and interactions among financial entities\nand news events. This unique capability enables the capture of complex\ndependencies, such as the simultaneous impact of a single news event on\nmultiple stocks or sectors, which traditional models frequently overlook.\n  By incorporating attention mechanisms within hypergraphs, GHAN enhances the\nmodel's ability to focus on the most relevant information, ensuring more\naccurate predictions and better interpretability. Additionally, we employ\nBERT-based embeddings to capture the semantic richness of financial news texts,\nproviding a nuanced understanding of the content. Using a comprehensive\nfinancial news dataset, our GHAN model addresses key challenges in financial\nnews impact analysis, including the complexity of high-order interactions, the\nnecessity for model interpretability, and the dynamic nature of financial\nmarkets. Integrating attention mechanisms and SHAP values within GHAN ensures\ntransparency, highlighting the most influential factors driving market\npredictions.\n  Empirical validation demonstrates the superior effectiveness of our approach\nover traditional sentiment analysis and time-series models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, conference",
    "pdf_url": "http://arxiv.org/pdf/2409.00438v1",
    "published_date": "2024-08-31 12:18:45 UTC",
    "updated_date": "2024-08-31 12:18:45 UTC"
  },
  {
    "arxiv_id": "2409.00418v1",
    "title": "Robust off-policy Reinforcement Learning via Soft Constrained Adversary",
    "authors": [
      "Kosuke Nakanishi",
      "Akihiro Kubo",
      "Yuji Yasui",
      "Shin Ishii"
    ],
    "abstract": "Recently, robust reinforcement learning (RL) methods against input\nobservation have garnered significant attention and undergone rapid evolution\ndue to RL's potential vulnerability. Although these advanced methods have\nachieved reasonable success, there have been two limitations when considering\nadversary in terms of long-term horizons. First, the mutual dependency between\nthe policy and its corresponding optimal adversary limits the development of\noff-policy RL algorithms; although obtaining optimal adversary should depend on\nthe current policy, this has restricted applications to off-policy RL. Second,\nthese methods generally assume perturbations based only on the $L_p$-norm, even\nwhen prior knowledge of the perturbation distribution in the environment is\navailable. We here introduce another perspective on adversarial RL: an\nf-divergence constrained problem with the prior knowledge distribution. From\nthis, we derive two typical attacks and their corresponding robust learning\nframeworks. The evaluation of robustness is conducted and the results\ndemonstrate that our proposed methods achieve excellent performance in\nsample-efficient off-policy RL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 12 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.00418v1",
    "published_date": "2024-08-31 11:13:33 UTC",
    "updated_date": "2024-08-31 11:13:33 UTC"
  },
  {
    "arxiv_id": "2409.09054v1",
    "title": "Evaluating the Performance of Large Language Models in Competitive Programming: A Multi-Year, Multi-Grade Analysis",
    "authors": [
      "Adrian Marius Dumitran",
      "Adrian Catalin Badea",
      "Stefan-Gabriel Muscalu"
    ],
    "abstract": "This study explores the performance of large language models (LLMs) in\nsolving competitive programming problems from the Romanian Informatics Olympiad\nat the county level. Romania, a leading nation in computer science\ncompetitions, provides an ideal environment for evaluating LLM capabilities due\nto its rich history and stringent competition standards. We collected and\nanalyzed a dataset comprising 304 challenges from 2002 to 2023, focusing on\nsolutions written by LLMs in C++ and Python for these problems. Our primary\ngoal is to understand why LLMs perform well or poorly on different tasks. We\nevaluated various models, including closed-source models like GPT-4 and\nopen-weight models such as CodeLlama and RoMistral, using a standardized\nprocess involving multiple attempts and feedback rounds. The analysis revealed\nsignificant variations in LLM performance across different grades and problem\ntypes. Notably, GPT-4 showed strong performance, indicating its potential use\nas an educational tool for middle school students. We also observed differences\nin code quality and style across various LLMs",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "7 pages, Inista 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.09054v1",
    "published_date": "2024-08-31 10:39:54 UTC",
    "updated_date": "2024-08-31 10:39:54 UTC"
  },
  {
    "arxiv_id": "2409.10536v1",
    "title": "The potential functions of an international institution for AI safety. Insights from adjacent policy areas and recent trends",
    "authors": [
      "A. Leone De Castris",
      "C. Thomas"
    ],
    "abstract": "Governments, industry, and other actors involved in governing AI technologies\naround the world agree that, while AI offers tremendous promise to benefit the\nworld, appropriate guardrails are required to mitigate risks. Global\ninstitutions, including the OECD, the G7, the G20, UNESCO, and the Council of\nEurope, have already started developing frameworks for ethical and responsible\nAI governance. While these are important initial steps, they alone fall short\nof addressing the need for institutionalised international processes to\nidentify and assess potentially harmful AI capabilities. Contributing to the\nrelevant conversation on how to address this gap, this chapter reflects on what\nfunctions an international AI safety institute could perform. Based on the\nanalysis of both existing international governance models addressing safety\nconsiderations in adjacent policy areas and the newly established national AI\nsafety institutes in the UK and US, the chapter identifies a list of concrete\nfunctions that could be performed at the international level. While creating a\nnew international body is not the only way forward, understanding the structure\nof these bodies from a modular perspective can help us to identify the tools at\nour disposal. These, we suggest, can be categorised under three functional\ndomains: a) technical research and cooperation, b) safeguards and evaluations,\nc) policymaking and governance support.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10536v1",
    "published_date": "2024-08-31 10:04:53 UTC",
    "updated_date": "2024-08-31 10:04:53 UTC"
  },
  {
    "arxiv_id": "2409.10535v1",
    "title": "Learning Co-Speech Gesture Representations in Dialogue through Contrastive Learning: An Intrinsic Evaluation",
    "authors": [
      "Esam Ghaleb",
      "Bulat Khaertdinov",
      "Wim Pouw",
      "Marlou Rasenberg",
      "Judith Holler",
      "Aslı Özyürek",
      "Raquel Fernández"
    ],
    "abstract": "In face-to-face dialogues, the form-meaning relationship of co-speech\ngestures varies depending on contextual factors such as what the gestures refer\nto and the individual characteristics of speakers. These factors make co-speech\ngesture representation learning challenging. How can we learn meaningful\ngestures representations considering gestures' variability and relationship\nwith speech? This paper tackles this challenge by employing self-supervised\ncontrastive learning techniques to learn gesture representations from skeletal\nand speech information. We propose an approach that includes both unimodal and\nmultimodal pre-training to ground gesture representations in co-occurring\nspeech. For training, we utilize a face-to-face dialogue dataset rich with\nrepresentational iconic gestures. We conduct thorough intrinsic evaluations of\nthe learned representations through comparison with human-annotated pairwise\ngesture similarity. Moreover, we perform a diagnostic probing analysis to\nassess the possibility of recovering interpretable gesture features from the\nlearned representations. Our results show a significant positive correlation\nwith human-annotated gesture similarity and reveal that the similarity between\nthe learned representations is consistent with well-motivated patterns related\nto the dynamics of dialogue interaction. Moreover, our findings demonstrate\nthat several features concerning the form of gestures can be recovered from the\nlatent representations. Overall, this study shows that multimodal contrastive\nlearning is a promising approach for learning gesture representations, which\nopens the door to using such representations in larger-scale gesture analysis\nstudies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "I.4"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10535v1",
    "published_date": "2024-08-31 08:53:18 UTC",
    "updated_date": "2024-08-31 08:53:18 UTC"
  },
  {
    "arxiv_id": "2409.00391v1",
    "title": "Density Adaptive Attention-based Speech Network: Enhancing Feature Understanding for Mental Health Disorders",
    "authors": [
      "Georgios Ioannides",
      "Adrian Kieback",
      "Aman Chadha",
      "Aaron Elkins"
    ],
    "abstract": "Speech-based depression detection poses significant challenges for automated\ndetection due to its unique manifestation across individuals and data scarcity.\nAddressing these challenges, we introduce DAAMAudioCNNLSTM and\nDAAMAudioTransformer, two parameter efficient and explainable models for audio\nfeature extraction and depression detection. DAAMAudioCNNLSTM features a novel\nCNN-LSTM framework with multi-head Density Adaptive Attention Mechanism (DAAM),\nfocusing dynamically on informative speech segments. DAAMAudioTransformer,\nleveraging a transformer encoder in place of the CNN-LSTM architecture,\nincorporates the same DAAM module for enhanced attention and interpretability.\nThese approaches not only enhance detection robustness and interpretability but\nalso achieve state-of-the-art performance: DAAMAudioCNNLSTM with an F1 macro\nscore of 0.702 and DAAMAudioTransformer with an F1 macro score of 0.72 on the\nDAIC-WOZ dataset, without reliance on supplementary information such as vowel\npositions and speaker information during training/validation as in previous\napproaches. Both models' significant explainability and efficiency in\nleveraging speech signals for depression detection represent a leap towards\nmore reliable, clinically useful diagnostic tools, promising advancements in\nspeech and mental health care. To foster further research in this domain, we\nmake our code publicly available.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00391v1",
    "published_date": "2024-08-31 08:50:28 UTC",
    "updated_date": "2024-08-31 08:50:28 UTC"
  },
  {
    "arxiv_id": "2409.03788v1",
    "title": "HSF: Defending against Jailbreak Attacks with Hidden State Filtering",
    "authors": [
      "Cheng Qian",
      "Hainan Zhang",
      "Lei Sha",
      "Zhiming Zheng"
    ],
    "abstract": "With the growing deployment of LLMs in daily applications like chatbots and\ncontent generation, efforts to ensure outputs align with human values and avoid\nharmful content have intensified. However, increasingly sophisticated jailbreak\nattacks threaten this alignment, aiming to induce unsafe outputs. Current\ndefense efforts either focus on prompt rewriting or detection, which are\nlimited in effectiveness due to the various design of jailbreak prompts, or on\noutput control and detection, which are computationally expensive as they\nrequire LLM inference. Therefore, designing a pre-inference defense method that\nresists diverse jailbreak prompts is crucial for preventing LLM jailbreak\nattacks. We observe that jailbreak attacks, safe queries, and harmful queries\nexhibit different clustering patterns within the LLM's hidden state\nrepresentation space. This suggests that by leveraging the LLM's hidden state\nrepresentational capabilities, we can analyze the LLM's forthcoming behavior\nand proactively intervene for defense. In this paper, we propose a jailbreak\nattack defense strategy based on a Hidden State Filter (HSF), a lossless\narchitectural defense mechanism that enables the model to preemptively identify\nand reject adversarial inputs before the inference process begins. We activate\nits defensive potential through an additional plugin module, effectively\nframing the defense task as a classification problem. Experimental results on\ntwo benchmark datasets, utilizing three different LLMs, show that HSF\nsignificantly enhances resilience against six cutting-edge jailbreak attacks.\nIt significantly reduces the success rate of jailbreak attacks while minimally\nimpacting responses to benign user queries, with negligible inference overhead,\nand outperforming defense baselines.Our code and data are available at\nhttps://anonymous.4open.science/r/Hidden-State-Filtering-8652/",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.03788v1",
    "published_date": "2024-08-31 06:50:07 UTC",
    "updated_date": "2024-08-31 06:50:07 UTC"
  },
  {
    "arxiv_id": "2409.00359v1",
    "title": "Predicting Femicide in Veracruz: A Fuzzy Logic Approach with the Expanded MFM-FEM-VER-CP-2024 Model",
    "authors": [
      "Carlos Medel-Ramírez",
      "Hilario Medel-López"
    ],
    "abstract": "The article focuses on the urgent issue of femicide in Veracruz, Mexico, and\nthe development of the MFM_FEM_VER_CP_2024 model, a mathematical framework\ndesigned to predict femicide risk using fuzzy logic. This model addresses the\ncomplexity and uncertainty inherent in gender based violence by formalizing\nrisk factors such as coercive control, dehumanization, and the cycle of\nviolence. These factors are mathematically modeled through membership functions\nthat assess the degree of risk associated with various conditions, including\npersonal relationships and specific acts of violence. The study enhances the\noriginal model by incorporating new rules and refining existing membership\nfunctions, which significantly improve the model predictive accuracy.",
    "categories": [
      "cs.AI",
      "03E72, 91D10, 62P25, 91B76",
      "G.1; G.3; I.2; I.6"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 2 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00359v1",
    "published_date": "2024-08-31 06:00:49 UTC",
    "updated_date": "2024-08-31 06:00:49 UTC"
  },
  {
    "arxiv_id": "2409.00358v2",
    "title": "Predicting the Target Word of Game-playing Conversations using a Low-Rank Dialect Adapter for Decoder Models",
    "authors": [
      "Dipankar Srirag",
      "Aditya Joshi",
      "Jacob Eisenstein"
    ],
    "abstract": "Dialect adapters that improve the performance of LLMs for NLU tasks on\ncertain sociolects/dialects/national varieties ('dialects' for the sake of\nbrevity) have been reported for encoder models. In this paper, we extend the\nidea of dialect adapters to decoder models in our architecture called LoRDD.\nUsing MD-3, a publicly available dataset of word game-playing conversations\nbetween dialectal speakers, our task is Target Word Prediction (TWP) from a\nmasked conversation. LoRDD combines task adapters and dialect adapters where\nthe latter employ contrastive learning on pseudo-parallel conversations from\nMD-3. Our experiments on Indian English and Nigerian English conversations with\ntwo models (Mistral and Gemma) demonstrate that LoRDD outperforms four\nbaselines on TWP. Additionally, it significantly reduces the performance gap\nwith American English, narrowing it to 12% and 5.8% for word similarity, and\n25% and 4.5% for accuracy, respectively. The focused contribution of LoRDD is\nin its promise for dialect adaptation of decoder models using TWP, a simplified\nversion of the commonly used next-word prediction task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.00358v2",
    "published_date": "2024-08-31 05:53:39 UTC",
    "updated_date": "2025-01-31 07:32:54 UTC"
  },
  {
    "arxiv_id": "2409.00356v1",
    "title": "Contrastive Augmentation: An Unsupervised Learning Approach for Keyword Spotting in Speech Technology",
    "authors": [
      "Weinan Dai",
      "Yifeng Jiang",
      "Yuanjing Liu",
      "Jinkun Chen",
      "Xin Sun",
      "Jinglei Tao"
    ],
    "abstract": "This paper addresses the persistent challenge in Keyword Spotting (KWS), a\nfundamental component in speech technology, regarding the acquisition of\nsubstantial labeled data for training. Given the difficulty in obtaining large\nquantities of positive samples and the laborious process of collecting new\ntarget samples when the keyword changes, we introduce a novel approach\ncombining unsupervised contrastive learning and a unique augmentation-based\ntechnique. Our method allows the neural network to train on unlabeled data\nsets, potentially improving performance in downstream tasks with limited\nlabeled data sets. We also propose that similar high-level feature\nrepresentations should be employed for speech utterances with the same keyword\ndespite variations in speed or volume. To achieve this, we present a speech\naugmentation-based unsupervised learning method that utilizes the similarity\nbetween the bottleneck layer feature and the audio reconstructing information\nfor auxiliary training. Furthermore, we propose a compressed convolutional\narchitecture to address potential redundancy and non-informative information in\nKWS tasks, enabling the model to simultaneously learn local features and focus\non long-term information. This method achieves strong performance on the Google\nSpeech Commands V2 Dataset. Inspired by recent advancements in sign spotting\nand spoken term detection, our method underlines the potential of our\ncontrastive learning approach in KWS and the advantages of Query-by-Example\nSpoken Term Detection strategies. The presented CAB-KWS provide new\nperspectives in the field of KWS, demonstrating effective ways to reduce data\ncollection efforts and increase the system's robustness.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "This paper has been accepted by the ICPR2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00356v1",
    "published_date": "2024-08-31 05:40:37 UTC",
    "updated_date": "2024-08-31 05:40:37 UTC"
  },
  {
    "arxiv_id": "2409.02118v1",
    "title": "TSO: Self-Training with Scaled Preference Optimization",
    "authors": [
      "Kaihui Chen",
      "Hao Yi",
      "Qingyang Li",
      "Tianyu Qi",
      "Yulan Hu",
      "Fuzheng Zhang",
      "Yong Liu"
    ],
    "abstract": "Enhancing the conformity of large language models (LLMs) to human preferences\nremains an ongoing research challenge. Recently, offline approaches such as\nDirect Preference Optimization (DPO) have gained prominence as attractive\noptions due to offering effective improvement in simple, efficient, and stable\nwithout interactions with reward models. However, these offline preference\noptimization methods highly rely on the quality of pairwise preference samples.\nMeanwhile, numerous iterative methods require additional training of reward\nmodels to select positive and negative samples from the model's own generated\nresponses for preference learning. Furthermore, as LLMs' capabilities advance,\nit is quite challenging to continuously construct high-quality positive and\nnegative preference instances from the model's outputs due to the lack of\ndiversity. To tackle these challenges, we propose TSO, or Self-Training with\nScaled Preference Optimization, a framework for preference optimization that\nconducts self-training preference learning without training an additional\nreward model. TSO enhances the diversity of responses by constructing a model\nmatrix and incorporating human preference responses. Furthermore, TSO\nintroduces corrections for model preference errors through human and AI\nfeedback. Finally, TSO adopts iterative and dual clip reward strategies to\nupdate the reference model and its responses, adaptively adjusting preference\ndata and balancing the optimization process. Experimental results demonstrate\nthat TSO outperforms existing mainstream methods on various alignment\nevaluation benchmarks, providing practical insight into preference data\nconstruction and model training strategies in the alignment domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.02118v1",
    "published_date": "2024-08-31 05:37:01 UTC",
    "updated_date": "2024-08-31 05:37:01 UTC"
  },
  {
    "arxiv_id": "2409.00338v1",
    "title": "GSpect: Spectral Filtering for Cross-Scale Graph Classification",
    "authors": [
      "Xiaoyu Zhang",
      "Wenchuan Yang",
      "Jiawei Feng",
      "Bitao Dai",
      "Tianci Bu",
      "Xin Lu"
    ],
    "abstract": "Identifying structures in common forms the basis for networked systems design\nand optimization. However, real structures represented by graphs are often of\nvarying sizes, leading to the low accuracy of traditional graph classification\nmethods. These graphs are called cross-scale graphs. To overcome this\nlimitation, in this study, we propose GSpect, an advanced spectral graph\nfiltering model for cross-scale graph classification tasks. Compared with other\nmethods, we use graph wavelet neural networks for the convolution layer of the\nmodel, which aggregates multi-scale messages to generate graph representations.\nWe design a spectral-pooling layer which aggregates nodes to one node to reduce\nthe cross-scale graphs to the same size. We collect and construct the\ncross-scale benchmark data set, MSG (Multi Scale Graphs). Experiments reveal\nthat, on open data sets, GSpect improves the performance of classification\naccuracy by 1.62% on average, and for a maximum of 3.33% on PROTEINS. On MSG,\nGSpect improves the performance of classification accuracy by 15.55% on\naverage. GSpect fills the gap in cross-scale graph classification studies and\nhas potential to provide assistance in application research like diagnosis of\nbrain disease by predicting the brain network's label and developing new drugs\nwith molecular structures learned from their counterparts in other systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00338v1",
    "published_date": "2024-08-31 03:26:32 UTC",
    "updated_date": "2024-08-31 03:26:32 UTC"
  },
  {
    "arxiv_id": "2409.00335v1",
    "title": "Evaluating the Effectiveness of Large Language Models in Representing and Understanding Movement Trajectories",
    "authors": [
      "Yuhan Ji",
      "Song Gao"
    ],
    "abstract": "This research focuses on assessing the ability of AI foundation models in\nrepresenting the trajectories of movements. We utilize one of the large\nlanguage models (LLMs) (i.e., GPT-J) to encode the string format of\ntrajectories and then evaluate the effectiveness of the LLM-based\nrepresentation for trajectory data analysis. The experiments demonstrate that\nwhile the LLM-based embeddings can preserve certain trajectory distance metrics\n(i.e., the correlation coefficients exceed 0.74 between the Cosine distance\nderived from GPT-J embeddings and the Hausdorff and Dynamic Time Warping\ndistances on raw trajectories), challenges remain in restoring numeric values\nand retrieving spatial neighbors in movement trajectory analytics. In addition,\nthe LLMs can understand the spatiotemporal dependency contained in trajectories\nand have good accuracy in location prediction tasks. This research highlights\nthe need for improvement in terms of capturing the nuances and complexities of\nthe underlying geospatial data and integrating domain knowledge to support\nvarious GeoAI applications using LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2; E.2"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.00335v1",
    "published_date": "2024-08-31 02:57:25 UTC",
    "updated_date": "2024-08-31 02:57:25 UTC"
  },
  {
    "arxiv_id": "2409.00331v1",
    "title": "WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction",
    "authors": [
      "Oktie Hassanzadeh"
    ],
    "abstract": "Recently, there has been an increasing interest in the construction of\ngeneral-domain and domain-specific causal knowledge graphs. Such knowledge\ngraphs enable reasoning for causal analysis and event prediction, and so have a\nrange of applications across different domains. While great progress has been\nmade toward automated construction of causal knowledge graphs, the evaluation\nof such solutions has either focused on low-level tasks (e.g., cause-effect\nphrase extraction) or on ad hoc evaluation data and small manual evaluations.\nIn this paper, we present a corpus, task, and evaluation framework for causal\nknowledge graph construction. Our corpus consists of Wikipedia articles for a\ncollection of event-related concepts in Wikidata. The task is to extract causal\nrelations between event concepts from the corpus. The evaluation is performed\nin part using existing causal relations in Wikidata to measure recall, and in\npart using Large Language Models to avoid the need for manual or crowd-sourced\nevaluation. We evaluate a pipeline for causal knowledge graph construction that\nrelies on neural models for question answering and concept linking, and show\nhow the corpus and the evaluation framework allow us to effectively find the\nright model for each task. The corpus and the evaluation framework are publicly\navailable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Extended version; poster paper accepted at ISWC 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00331v1",
    "published_date": "2024-08-31 02:21:39 UTC",
    "updated_date": "2024-08-31 02:21:39 UTC"
  },
  {
    "arxiv_id": "2409.00327v1",
    "title": "Demo: FedCampus: A Real-world Privacy-preserving Mobile Application for Smart Campus via Federated Learning & Analytics",
    "authors": [
      "Jiaxiang Geng",
      "Beilong Tang",
      "Boyan Zhang",
      "Jiaqi Shao",
      "Bing Luo"
    ],
    "abstract": "In this demo, we introduce FedCampus, a privacy-preserving mobile application\nfor smart \\underline{campus} with \\underline{fed}erated learning (FL) and\nfederated analytics (FA). FedCampus enables cross-platform on-device FL/FA for\nboth iOS and Android, supporting continuously models and algorithms deployment\n(MLOps). Our app integrates privacy-preserving processed data via differential\nprivacy (DP) from smartwatches, where the processed parameters are used for\nFL/FA through the FedCampus backend platform. We distributed 100 smartwatches\nto volunteers at Duke Kunshan University and have successfully completed a\nseries of smart campus tasks featuring capabilities such as sleep tracking,\nphysical activity monitoring, personalized recommendations, and heavy hitters.\nOur project is opensourced at https://github.com/FedCampus/FedCampus_Flutter.\nSee the FedCampus video at https://youtu.be/k5iu46IjA38.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CR",
    "comment": "2 pages, 3 figures, accepted for publication in ACM Mobihoc 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.00327v1",
    "published_date": "2024-08-31 01:58:36 UTC",
    "updated_date": "2024-08-31 01:58:36 UTC"
  },
  {
    "arxiv_id": "2409.00316v1",
    "title": "Toward a More Complete OMR Solution",
    "authors": [
      "Guang Yang",
      "Muru Zhang",
      "Lin Qiu",
      "Yanming Wan",
      "Noah A. Smith"
    ],
    "abstract": "Optical music recognition (OMR) aims to convert music notation into digital\nformats. One approach to tackle OMR is through a multi-stage pipeline, where\nthe system first detects visual music notation elements in the image (object\ndetection) and then assembles them into a music notation (notation assembly).\nMost previous work on notation assembly unrealistically assumes perfect object\ndetection. In this study, we focus on the MUSCIMA++ v2.0 dataset, which\nrepresents musical notation as a graph with pairwise relationships among\ndetected music objects, and we consider both stages together. First, we\nintroduce a music object detector based on YOLOv8, which improves detection\nperformance. Second, we introduce a supervised training pipeline that completes\nthe notation assembly stage based on detection output. We find that this model\nis able to outperform existing models trained on perfect detection output,\nshowing the benefit of considering the detection and assembly stages in a more\nholistic way. These findings, together with our novel evaluation metric, are\nimportant steps toward a more complete OMR solution.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00316v1",
    "published_date": "2024-08-31 01:09:12 UTC",
    "updated_date": "2024-08-31 01:09:12 UTC"
  },
  {
    "arxiv_id": "2409.00315v1",
    "title": "An Empirical Study on Context Length for Open-Domain Dialog Generation",
    "authors": [
      "Xinyi Shen",
      "Zuoquan Lin"
    ],
    "abstract": "Transformer-based open-domain dialog models have become increasingly popular\nin recent years. These models typically represent context as a concatenation of\na dialog history. However, there is no criterion to decide how many utterances\nshould be kept adequate in a context. We try to figure out how the choice of\ncontext length affects the model. We experiment on three questions from coarse\nto fine: (i) Does longer context help model training? (ii) Is it necessary to\nchange the training context length when dealing with dialogs of different\ncontext lengths? (iii) Do different dialog samples have the same preference for\ncontext length? Our experimental results show that context length, an often\noverlooked setting, deserves attention when implementing Transformer-based\ndialog models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.00315v1",
    "published_date": "2024-08-31 00:56:36 UTC",
    "updated_date": "2024-08-31 00:56:36 UTC"
  },
  {
    "arxiv_id": "2409.00310v2",
    "title": "Objective Features Extracted from Motor Activity Time Series for Food Addiction Analysis Using Machine Learning",
    "authors": [
      "Mikhail Borisenkov",
      "Andrei Velichko",
      "Maksim Belyaev",
      "Dmitry Korzun",
      "Tatyana Tserne",
      "Larisa Bakutova",
      "Denis Gubin"
    ],
    "abstract": "This study investigates machine learning algorithms to identify objective\nfeatures for diagnosing food addiction (FA) and assessing confirmed symptoms\n(SC). Data were collected from 81 participants (mean age: 21.5 years, range:\n18-61 years, women: 77.8%) whose FA and SC were measured using the Yale Food\nAddiction Scale (YFAS). Participants provided demographic and anthropometric\ndata, completed the YFAS, the Zung Self-Rating Depression Scale, and the Dutch\nEating Behavior Questionnaire, and wore an actimeter on the non-dominant wrist\nfor a week to record motor activity. Analysis of the actimetric data identified\nsignificant statistical and entropy-based features that accurately predicted FA\nand SC using ML. The Matthews correlation coefficient (MCC) was the primary\nmetric. Activity-related features were more effective for FA prediction\n(MCC=0.88) than rest-related features (MCC=0.68). For SC, activity segments\nyielded MCC=0.47, rest segments MCC=0.38, and their combination MCC=0.51.\nSignificant correlations were also found between actimetric features related to\nFA, emotional, and restrained eating behaviors, supporting the model's\nvalidity. Our results support the concept of a human bionic suite composed of\nIoT devices and ML sensors, which implements health digital assistance with\nreal-time monitoring and analysis of physiological indicators related to FA and\nSC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "physics.med-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 3 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.00310v2",
    "published_date": "2024-08-31 00:33:17 UTC",
    "updated_date": "2024-12-05 06:28:11 UTC"
  }
]