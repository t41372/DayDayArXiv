[
  {
    "arxiv_id": "2402.04477v1",
    "title": "Detecting Mode Collapse in Language Models via Narration",
    "authors": [
      "Sil Hamilton"
    ],
    "abstract": "No two authors write alike. Personal flourishes invoked in written\nnarratives, from lexicon to rhetorical devices, imply a particular author--what\nliterary theorists label the implied or virtual author; distinct from the real\nauthor or narrator of a text. Early large language models trained on unfiltered\ntraining sets drawn from a variety of discordant sources yielded incoherent\npersonalities, problematic for conversational tasks but proving useful for\nsampling literature from multiple perspectives. Successes in alignment research\nin recent years have allowed researchers to impose subjectively consistent\npersonae on language models via instruction tuning and reinforcement learning\nfrom human feedback (RLHF), but whether aligned models retain the ability to\nmodel an arbitrary virtual author has received little scrutiny. By studying\n4,374 stories sampled from three OpenAI language models, we show successive\nversions of GPT-3 suffer from increasing degrees of \"mode collapse\" whereby\noverfitting the model during alignment constrains it from generalizing over\nauthorship: models suffering from mode collapse become unable to assume a\nmultiplicity of perspectives. Our method and results are significant for\nresearchers seeking to employ language models in sociological simulations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in the proceedings of the first Workshop on the Scaling\n  Behavior of Large Language Models (EACL 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.04477v1",
    "published_date": "2024-02-06 23:52:58 UTC",
    "updated_date": "2024-02-06 23:52:58 UTC"
  },
  {
    "arxiv_id": "2402.04476v2",
    "title": "Dual-View Visual Contextualization for Web Navigation",
    "authors": [
      "Jihyung Kil",
      "Chan Hee Song",
      "Boyuan Zheng",
      "Xiang Deng",
      "Yu Su",
      "Wei-Lun Chao"
    ],
    "abstract": "Automatic web navigation aims to build a web agent that can follow language\ninstructions to execute complex and diverse tasks on real-world websites.\nExisting work primarily takes HTML documents as input, which define the\ncontents and action spaces (i.e., actionable elements and operations) of\nwebpages. Nevertheless, HTML documents may not provide a clear task-related\ncontext for each element, making it hard to select the right (sequence of)\nactions. In this paper, we propose to contextualize HTML elements through their\n\"dual views\" in webpage screenshots: each HTML element has its corresponding\nbounding box and visual content in the screenshot. We build upon the insight --\nweb developers tend to arrange task-related elements nearby on webpages to\nenhance user experiences -- and propose to contextualize each element with its\nneighbor elements, using both textual and visual features. The resulting\nrepresentations of HTML elements are more informative for the agent to take\naction. We validate our method on the recently released Mind2Web dataset, which\nfeatures diverse navigation domains and tasks on real-world websites. Our\nmethod consistently outperforms the baseline in all the scenarios, including\ncross-task, cross-website, and cross-domain ones.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04476v2",
    "published_date": "2024-02-06 23:52:10 UTC",
    "updated_date": "2024-03-30 05:18:05 UTC"
  },
  {
    "arxiv_id": "2402.04466v1",
    "title": "Towards Deterministic End-to-end Latency for Medical AI Systems in NVIDIA Holoscan",
    "authors": [
      "Soham Sinha",
      "Shekhar Dwivedi",
      "Mahdi Azizian"
    ],
    "abstract": "The introduction of AI and ML technologies into medical devices has\nrevolutionized healthcare diagnostics and treatments. Medical device\nmanufacturers are keen to maximize the advantages afforded by AI and ML by\nconsolidating multiple applications onto a single platform. However, concurrent\nexecution of several AI applications, each with its own visualization\ncomponents, leads to unpredictable end-to-end latency, primarily due to GPU\nresource contentions. To mitigate this, manufacturers typically deploy separate\nworkstations for distinct AI applications, thereby increasing financial,\nenergy, and maintenance costs. This paper addresses these challenges within the\ncontext of NVIDIA's Holoscan platform, a real-time AI system for streaming\nsensor data and images. We propose a system design optimized for heterogeneous\nGPU workloads, encompassing both compute and graphics tasks. Our design\nleverages CUDA MPS for spatial partitioning of compute workloads and isolates\ncompute and graphics processing onto separate GPUs. We demonstrate significant\nperformance improvements across various end-to-end latency determinism metrics\nthrough empirical evaluation with real-world Holoscan medical device\napplications. For instance, the proposed design reduces maximum latency by\n21-30% and improves latency distribution flatness by 17-25% for up to five\nconcurrent endoscopy tool tracking AI applications, compared to a single-GPU\nbaseline. Against a default multi-GPU setup, our optimizations decrease maximum\nlatency by 35% for up to six concurrent applications by improving GPU\nutilization by 42%. This paper provides clear design insights for AI\napplications in the edge-computing domain including medical systems, where\nperformance predictability of concurrent and heterogeneous GPU workloads is a\ncritical requirement.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.OS",
      "C.3; J.7; D.2.11; D.2.10; D.4.8"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04466v1",
    "published_date": "2024-02-06 23:20:34 UTC",
    "updated_date": "2024-02-06 23:20:34 UTC"
  },
  {
    "arxiv_id": "2402.04464v2",
    "title": "Ten Hard Problems in Artificial Intelligence We Must Get Right",
    "authors": [
      "Gavin Leech",
      "Simson Garfinkel",
      "Misha Yagudin",
      "Alexander Briand",
      "Aleksandr Zhuravlev"
    ],
    "abstract": "We explore the AI2050 \"hard problems\" that block the promise of AI and cause\nAI risks: (1) developing general capabilities of the systems; (2) assuring the\nperformance of AI systems and their training processes; (3) aligning system\ngoals with human goals; (4) enabling great applications of AI in real life; (5)\naddressing economic disruptions; (6) ensuring the participation of all; (7) at\nthe same time ensuring socially responsible deployment; (8) addressing any\ngeopolitical disruptions that AI causes; (9) promoting sound governance of the\ntechnology; and (10) managing the philosophical disruptions for humans living\nin the age of AI. For each problem, we outline the area, identify significant\nrecent work, and suggest ways forward. [Note: this paper reviews literature\nthrough January 2023.]",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "75 + 19 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.04464v2",
    "published_date": "2024-02-06 23:16:41 UTC",
    "updated_date": "2024-04-19 10:38:59 UTC"
  },
  {
    "arxiv_id": "2402.04435v1",
    "title": "PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection",
    "authors": [
      "Enyan Dai",
      "Minhua Lin",
      "Suhang Wang"
    ],
    "abstract": "Pretraining on Graph Neural Networks (GNNs) has shown great power in\nfacilitating various downstream tasks. As pretraining generally requires huge\namount of data and computational resources, the pretrained GNNs are high-value\nIntellectual Properties (IP) of the legitimate owner. However, adversaries may\nillegally copy and deploy the pretrained GNN models for their downstream tasks.\nThough initial efforts have been made to watermark GNN classifiers for IP\nprotection, these methods require the target classification task for\nwatermarking, and thus are not applicable to self-supervised pretraining of GNN\nmodels. Hence, in this work, we propose a novel framework named PreGIP to\nwatermark the pretraining of GNN encoder for IP protection while maintain the\nhigh-quality of the embedding space. PreGIP incorporates a task-free\nwatermarking loss to watermark the embedding space of pretrained GNN encoder. A\nfinetuning-resistant watermark injection is further deployed. Theoretical\nanalysis and extensive experiments show the effectiveness of {\\method} in IP\nprotection and maintaining high-performance for downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04435v1",
    "published_date": "2024-02-06 22:13:49 UTC",
    "updated_date": "2024-02-06 22:13:49 UTC"
  },
  {
    "arxiv_id": "2402.04421v1",
    "title": "Studying Vulnerable Code Entities in R",
    "authors": [
      "Zixiao Zhao",
      "Millon Madhur Das",
      "Fatemeh H. Fard"
    ],
    "abstract": "Pre-trained Code Language Models (Code-PLMs) have shown many advancements and\nachieved state-of-the-art results for many software engineering tasks in the\npast few years. These models are mainly targeted for popular programming\nlanguages such as Java and Python, leaving out many other ones like R. Though R\nhas a wide community of developers and users, there is little known about the\napplicability of Code-PLMs for R. In this preliminary study, we aim to\ninvestigate the vulnerability of Code-PLMs for code entities in R. For this\npurpose, we use an R dataset of code and comment pairs and then apply\nCodeAttack, a black-box attack model that uses the structure of code to\ngenerate adversarial code samples. We investigate how the model can attack\ndifferent entities in R. This is the first step towards understanding the\nimportance of R token types, compared to popular programming languages (e.g.,\nJava). We limit our study to code summarization. Our results show that the most\nvulnerable code entity is the identifier, followed by some syntax tokens\nspecific to R. The results can shed light on the importance of token types and\nhelp in developing models for code summarization and method name prediction for\nthe R language.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages, 3 figures, and 2 tables. to be published in ICPC 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04421v1",
    "published_date": "2024-02-06 21:39:55 UTC",
    "updated_date": "2024-02-06 21:39:55 UTC"
  },
  {
    "arxiv_id": "2402.04420v1",
    "title": "Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways",
    "authors": [
      "Angelina Wang",
      "Xuechunzi Bai",
      "Solon Barocas",
      "Su Lin Blodgett"
    ],
    "abstract": "As machine learning applications proliferate, we need an understanding of\ntheir potential for harm. However, current fairness metrics are rarely grounded\nin human psychological experiences of harm. Drawing on the social psychology of\nstereotypes, we use a case study of gender stereotypes in image search to\nexamine how people react to machine learning errors. First, we use survey\nstudies to show that not all machine learning errors reflect stereotypes nor\nare equally harmful. Then, in experimental studies we randomly expose\nparticipants to stereotype-reinforcing, -violating, and -neutral machine\nlearning errors. We find stereotype-reinforcing errors induce more\nexperientially (i.e., subjectively) harmful experiences, while having minimal\nchanges to cognitive beliefs, attitudes, or behaviors. This experiential harm\nimpacts women more than men. However, certain stereotype-violating errors are\nmore experientially harmful for men, potentially due to perceived threats to\nmasculinity. We conclude that harm cannot be the sole guide in fairness\nmitigation, and propose a nuanced perspective depending on who is experiencing\nwhat harm and why.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "earlier draft non-archival at EAAMO 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.04420v1",
    "published_date": "2024-02-06 21:39:13 UTC",
    "updated_date": "2024-02-06 21:39:13 UTC"
  },
  {
    "arxiv_id": "2402.06666v1",
    "title": "Weather Prediction with Diffusion Guided by Realistic Forecast Processes",
    "authors": [
      "Zhanxiang Hua",
      "Yutong He",
      "Chengqian Ma",
      "Alexandra Anderson-Frey"
    ],
    "abstract": "Weather forecasting remains a crucial yet challenging domain, where recently\ndeveloped models based on deep learning (DL) have approached the performance of\ntraditional numerical weather prediction (NWP) models. However, these DL\nmodels, often complex and resource-intensive, face limitations in flexibility\npost-training and in incorporating NWP predictions, leading to reliability\nconcerns due to potential unphysical predictions. In response, we introduce a\nnovel method that applies diffusion models (DM) for weather forecasting. In\nparticular, our method can achieve both direct and iterative forecasting with\nthe same modeling framework. Our model is not only capable of generating\nforecasts independently but also uniquely allows for the integration of NWP\npredictions, even with varying lead times, during its sampling process. The\nflexibility and controllability of our model empowers a more trustworthy DL\nsystem for the general weather community. Additionally, incorporating\npersistence and climatology data further enhances our model's long-term\nforecasting stability. Our empirical findings demonstrate the feasibility and\ngeneralizability of this approach, suggesting a promising direction for future,\nmore sophisticated diffusion models without the need for retraining.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06666v1",
    "published_date": "2024-02-06 21:28:42 UTC",
    "updated_date": "2024-02-06 21:28:42 UTC"
  },
  {
    "arxiv_id": "2402.04412v3",
    "title": "The VampPrior Mixture Model",
    "authors": [
      "Andrew A. Stirn",
      "David A. Knowles"
    ],
    "abstract": "Widely used deep latent variable models (DLVMs), in particular Variational\nAutoencoders (VAEs), employ overly simplistic priors on the latent space. To\nachieve strong clustering performance, existing methods that replace the\nstandard normal prior with a Gaussian mixture model (GMM) require defining the\nnumber of clusters to be close to the number of expected ground truth classes\na-priori and are susceptible to poor initializations. We leverage VampPrior\nconcepts (Tomczak and Welling, 2018) to fit a Bayesian GMM prior, resulting in\nthe VampPrior Mixture Model (VMM), a novel prior for DLVMs. In a VAE, the VMM\nattains highly competitive clustering performance on benchmark datasets.\nIntegrating the VMM into scVI (Lopez et al., 2018), a popular scRNA-seq\nintegration method, significantly improves its performance and automatically\narranges cells into clusters with similar biological characteristics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04412v3",
    "published_date": "2024-02-06 21:18:34 UTC",
    "updated_date": "2025-03-11 03:56:24 UTC"
  },
  {
    "arxiv_id": "2402.04409v1",
    "title": "Towards Fair, Robust and Efficient Client Contribution Evaluation in Federated Learning",
    "authors": [
      "Meiying Zhang",
      "Huan Zhao",
      "Sheldon Ebron",
      "Kan Yang"
    ],
    "abstract": "The performance of clients in Federated Learning (FL) can vary due to various\nreasons. Assessing the contributions of each client is crucial for client\nselection and compensation. It is challenging because clients often have\nnon-independent and identically distributed (non-iid) data, leading to\npotentially noisy or divergent updates. The risk of malicious clients amplifies\nthe challenge especially when there's no access to clients' local data or a\nbenchmark root dataset. In this paper, we introduce a novel method called Fair,\nRobust, and Efficient Client Assessment (FRECA) for quantifying client\ncontributions in FL. FRECA employs a framework called FedTruth to estimate the\nglobal model's ground truth update, balancing contributions from all clients\nwhile filtering out impacts from malicious ones. This approach is robust\nagainst Byzantine attacks and incorporates a Byzantine-resilient aggregation\nalgorithm. FRECA is also efficient, as it operates solely on local model\nupdates and requires no validation operations or datasets. Our experimental\nresults show that FRECA can accurately and efficiently quantify client\ncontributions in a robust manner.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04409v1",
    "published_date": "2024-02-06 21:07:12 UTC",
    "updated_date": "2024-02-06 21:07:12 UTC"
  },
  {
    "arxiv_id": "2402.04400v2",
    "title": "CEHR-GPT: Generating Electronic Health Records with Chronological Patient Timelines",
    "authors": [
      "Chao Pang",
      "Xinzhuo Jiang",
      "Nishanth Parameshwar Pavinkurve",
      "Krishna S. Kalluri",
      "Elise L. Minto",
      "Jason Patterson",
      "Linying Zhang",
      "George Hripcsak",
      "Gamze Gürsoy",
      "Noémie Elhadad",
      "Karthik Natarajan"
    ],
    "abstract": "Synthetic Electronic Health Records (EHR) have emerged as a pivotal tool in\nadvancing healthcare applications and machine learning models, particularly for\nresearchers without direct access to healthcare data. Although existing\nmethods, like rule-based approaches and generative adversarial networks (GANs),\ngenerate synthetic data that resembles real-world EHR data, these methods often\nuse a tabular format, disregarding temporal dependencies in patient histories\nand limiting data replication. Recently, there has been a growing interest in\nleveraging Generative Pre-trained Transformers (GPT) for EHR data. This enables\napplications like disease progression analysis, population estimation,\ncounterfactual reasoning, and synthetic data generation. In this work, we focus\non synthetic data generation and demonstrate the capability of training a GPT\nmodel using a particular patient representation derived from CEHR-BERT,\nenabling us to generate patient sequences that can be seamlessly converted to\nthe Observational Medical Outcomes Partnership (OMOP) data format.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04400v2",
    "published_date": "2024-02-06 20:58:36 UTC",
    "updated_date": "2024-05-06 01:10:56 UTC"
  },
  {
    "arxiv_id": "2402.04398v2",
    "title": "Learning under Temporal Label Noise",
    "authors": [
      "Sujay Nagaraj",
      "Walter Gerych",
      "Sana Tonekaboni",
      "Anna Goldenberg",
      "Berk Ustun",
      "Thomas Hartvigsen"
    ],
    "abstract": "Many time series classification tasks, where labels vary over time, are\naffected by label noise that also varies over time. Such noise can cause label\nquality to improve, worsen, or periodically change over time. We first propose\nand formalize temporal label noise, an unstudied problem for sequential\nclassification of time series. In this setting, multiple labels are recorded\nover time while being corrupted by a time-dependent noise function. We first\ndemonstrate the importance of modeling the temporal nature of the label noise\nfunction and how existing methods will consistently underperform. We then\npropose methods to train noise-tolerant classifiers by estimating the temporal\nlabel noise function directly from data. We show that our methods lead to\nstate-of-the-art performance under diverse types of temporal label noise on\nreal-world datasets",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "The Thirteenth International Conference on Learning Representations\n  (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2402.04398v2",
    "published_date": "2024-02-06 20:56:31 UTC",
    "updated_date": "2025-03-16 09:14:36 UTC"
  },
  {
    "arxiv_id": "2402.04396v2",
    "title": "QuIP#: Even Better LLM Quantization with Hadamard Incoherence and Lattice Codebooks",
    "authors": [
      "Albert Tseng",
      "Jerry Chee",
      "Qingyao Sun",
      "Volodymyr Kuleshov",
      "Christopher De Sa"
    ],
    "abstract": "Post-training quantization (PTQ) reduces the memory footprint of LLMs by\nquantizing their weights to low-precision. In this work, we introduce QuIP#, a\nweight-only PTQ method that achieves state-of-the-art results in extreme\ncompression regimes ($\\le$ 4 bits per weight) using three novel techniques.\nFirst, QuIP# improves QuIP's (Chee et al., 2023) incoherence processing by\nusing the randomized Hadamard transform, which is faster and has better\ntheoretical properties. Second, QuIP# uses vector quantization to take\nadvantage of the ball-shaped sub-Gaussian distribution that incoherent weights\npossess: specifically, we introduce a set of hardware-efficient codebooks based\non the highly symmetric $E_8$ lattice, which achieves the optimal 8-dimension\nunit ball packing. Third, QuIP# uses fine-tuning to improve fidelity to the\noriginal model. Our experiments show that QuIP# outperforms existing PTQ\nmethods, enables new behaviors in PTQ scaling, and supports fast inference. Our\ncode can be found at https://github.com/Cornell-RelaxML/quip-sharp.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04396v2",
    "published_date": "2024-02-06 20:52:12 UTC",
    "updated_date": "2024-06-04 04:51:52 UTC"
  },
  {
    "arxiv_id": "2402.04390v3",
    "title": "Densely Multiplied Physics Informed Neural Networks",
    "authors": [
      "Feilong Jiang",
      "Xiaonan Hou",
      "Min Xia"
    ],
    "abstract": "Although physics-informed neural networks (PINNs) have shown great potential\nin dealing with nonlinear partial differential equations (PDEs), it is common\nthat PINNs will suffer from the problem of insufficient precision or obtaining\nincorrect outcomes. Unlike most of the existing solutions trying to enhance the\nability of PINN by optimizing the training process, this paper improved the\nneural network architecture to improve the performance of PINN. We propose a\ndensely multiply PINN (DM-PINN) architecture, which multiplies the output of a\nhidden layer with the outputs of all the behind hidden layers. Without\nintroducing more trainable parameters, this effective mechanism can\nsignificantly improve the accuracy of PINNs. The proposed architecture is\nevaluated on four benchmark examples (Allan-Cahn equation, Helmholtz equation,\nBurgers equation and 1D convection equation). Comparisons between the proposed\narchitecture and different PINN structures demonstrate the superior performance\nof the DM-PINN in both accuracy and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.04390v3",
    "published_date": "2024-02-06 20:45:31 UTC",
    "updated_date": "2024-10-04 13:50:58 UTC"
  },
  {
    "arxiv_id": "2402.04382v1",
    "title": "Counterfactual Generation with Answer Set Programming",
    "authors": [
      "Sopam Dasgupta",
      "Farhad Shakerin",
      "Joaquín Arias",
      "Elmer Salazar",
      "Gopal Gupta"
    ],
    "abstract": "Machine learning models that automate decision-making are increasingly being\nused in consequential areas such as loan approvals, pretrial bail approval,\nhiring, and many more. Unfortunately, most of these models are black-boxes,\ni.e., they are unable to reveal how they reach these prediction decisions. A\nneed for transparency demands justification for such predictions. An affected\nindividual might also desire explanations to understand why a decision was\nmade. Ethical and legal considerations may further require informing the\nindividual of changes in the input attribute that could be made to produce a\ndesirable outcome. This paper focuses on the latter problem of automatically\ngenerating counterfactual explanations. We propose a framework Counterfactual\nGeneration with s(CASP) (CFGS) that utilizes answer set programming (ASP) and\nthe s(CASP) goal-directed ASP system to automatically generate counterfactual\nexplanations from rules generated by rule-based machine learning (RBML)\nalgorithms. In our framework, we show how counterfactual explanations are\ncomputed and justified by imagining worlds where some or all factual\nassumptions are altered/changed. More importantly, we show how we can navigate\nbetween these worlds, namely, go from our original world/scenario where we\nobtain an undesired outcome to the imagined world/scenario where we obtain a\ndesired/favourable outcome.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 Pages",
    "pdf_url": "http://arxiv.org/pdf/2402.04382v1",
    "published_date": "2024-02-06 20:39:49 UTC",
    "updated_date": "2024-02-06 20:39:49 UTC"
  },
  {
    "arxiv_id": "2403.05548v1",
    "title": "Monitoring the evolution of antisemitic discourse on extremist social media using BERT",
    "authors": [
      "Raza Ul Mustafa",
      "Nathalie Japkowicz"
    ],
    "abstract": "Racism and intolerance on social media contribute to a toxic online\nenvironment which may spill offline to foster hatred, and eventually lead to\nphysical violence. That is the case with online antisemitism, the specific\ncategory of hatred considered in this study. Tracking antisemitic themes and\ntheir associated terminology over time in online discussions could help monitor\nthe sentiments of their participants and their evolution, and possibly offer\navenues for intervention that may prevent the escalation of hatred. Due to the\nlarge volume and constant evolution of online traffic, monitoring conversations\nmanually is impractical. Instead, we propose an automated method that extracts\nantisemitic themes and terminology from extremist social media over time and\ncaptures their evolution. Since supervised learning would be too limited for\nsuch a task, we created an unsupervised online machine learning approach that\nuses large language models to assess the contextual similarity of posts. The\nmethod clusters similar posts together, dividing, and creating additional\nclusters over time when sub-themes emerge from existing ones or new themes\nappear. The antisemitic terminology used within each theme is extracted from\nthe posts in each cluster. Our experiments show that our methodology\noutperforms existing baselines and demonstrates the kind of themes and\nsub-themes it discovers within antisemitic discourse along with their\nassociated terminology. We believe that our approach will be useful for\nmonitoring the evolution of all kinds of hatred beyond antisemitism on social\nplatforms.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CY",
    "comment": "11 pages; 4 figures; 4 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.05548v1",
    "published_date": "2024-02-06 20:34:49 UTC",
    "updated_date": "2024-02-06 20:34:49 UTC"
  },
  {
    "arxiv_id": "2402.04376v3",
    "title": "Scaling laws for learning with real and surrogate data",
    "authors": [
      "Ayush Jain",
      "Andrea Montanari",
      "Eren Sasoglu"
    ],
    "abstract": "Collecting large quantities of high-quality data can be prohibitively\nexpensive or impractical, and a bottleneck in machine learning. One may instead\naugment a small set of $n$ data points from the target distribution with data\nfrom more accessible sources, e.g. data collected under different circumstances\nor synthesized by generative models. We refer to such data as `surrogate data'.\nWe study a weighted empirical risk minimization (ERM) approach for integrating\nsurrogate data into training. We analyze mathematically this method under\nseveral classical statistical models, and validate our findings empirically on\ndatasets from different domains. Our main findings are: $(i)$ Integrating\nsurrogate data can significantly reduce the test error on the original\ndistribution. Surprisingly, this can happen even when the surrogate data is\nunrelated to the original ones. We trace back this behavior to the classical\nStein's paradox. $(ii)$ In order to reap the benefit of surrogate data, it is\ncrucial to use optimally weighted ERM. $(iii)$ The test error of models trained\non mixtures of real and surrogate data is approximately described by a scaling\nlaw. This scaling law can be used to predict the optimal weighting scheme, and\nto choose the amount of surrogate data to add.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Added new experiment and minor changes",
    "pdf_url": "http://arxiv.org/pdf/2402.04376v3",
    "published_date": "2024-02-06 20:30:19 UTC",
    "updated_date": "2024-12-03 23:22:26 UTC"
  },
  {
    "arxiv_id": "2402.04370v1",
    "title": "Pedestrian crossing decisions can be explained by bounded optimal decision-making under noisy visual perception",
    "authors": [
      "Yueyang Wang",
      "Aravinda Ramakrishnan Srinivasan",
      "Jussi P. P. Jokinen",
      "Antti Oulasvirta",
      "Gustav Markkula"
    ],
    "abstract": "This paper presents a model of pedestrian crossing decisions, based on the\ntheory of computational rationality. It is assumed that crossing decisions are\nboundedly optimal, with bounds on optimality arising from human cognitive\nlimitations. While previous models of pedestrian behaviour have been either\n'black-box' machine learning models or mechanistic models with explicit\nassumptions about cognitive factors, we combine both approaches. Specifically,\nwe model mechanistically noisy human visual perception and assumed rewards in\ncrossing, but we use reinforcement learning to learn bounded optimal behaviour\npolicy. The model reproduces a larger number of known empirical phenomena than\nprevious models, in particular: (1) the effect of the time to arrival of an\napproaching vehicle on whether the pedestrian accepts the gap, the effect of\nthe vehicle's speed on both (2) gap acceptance and (3) pedestrian timing of\ncrossing in front of yielding vehicles, and (4) the effect on this crossing\ntiming of the stopping distance of the yielding vehicle. Notably, our findings\nsuggest that behaviours previously framed as 'biases' in decision-making, such\nas speed-dependent gap acceptance, might instead be a product of rational\nadaptation to the constraints of visual perception. Our approach also permits\nfitting the parameters of cognitive constraints and rewards per individual, to\nbetter account for individual differences. To conclude, by leveraging both RL\nand mechanistic modelling, our model offers novel insights about pedestrian\nbehaviour, and may provide a useful foundation for more accurate and scalable\npedestrian models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04370v1",
    "published_date": "2024-02-06 20:13:34 UTC",
    "updated_date": "2024-02-06 20:13:34 UTC"
  },
  {
    "arxiv_id": "2402.05140v3",
    "title": "Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains",
    "authors": [
      "Junhong Shen",
      "Neil Tenenholtz",
      "James Brian Hall",
      "David Alvarez-Melis",
      "Nicolo Fusi"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\nunderstanding and generating natural language. However, their capabilities wane\nin highly specialized domains underrepresented in the pretraining corpus, such\nas physical and biomedical sciences. This work explores how to repurpose\ngeneral LLMs into effective task solvers for specialized domains. We introduce\na novel, model-agnostic framework for learning custom input tags, which are\nparameterized as continuous vectors appended to the LLM's embedding layer, to\ncondition the LLM. We design two types of input tags: domain tags are used to\ndelimit specialized representations (e.g., chemical formulas) and provide\ndomain-relevant context; function tags are used to represent specific functions\n(e.g., predicting molecular properties) and compress function-solving\ninstructions. We develop a three-stage protocol to learn these tags using\nauxiliary data and domain knowledge. By explicitly disentangling task domains\nfrom task functions, our method enables zero-shot generalization to unseen\nproblems through diverse combinations of the input tags. It also boosts LLM's\nperformance in various specialized domains, such as predicting protein or\nchemical properties and modeling drug-target interactions, outperforming expert\nmodels tailored to these tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05140v3",
    "published_date": "2024-02-06 20:11:54 UTC",
    "updated_date": "2024-07-26 01:28:16 UTC"
  },
  {
    "arxiv_id": "2402.04355v2",
    "title": "PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation",
    "authors": [
      "Pablo Lemos",
      "Sammy Sharief",
      "Nikolay Malkin",
      "Salma Salhi",
      "Connor Stone",
      "Laurence Perreault-Levasseur",
      "Yashar Hezaveh"
    ],
    "abstract": "We propose a likelihood-free method for comparing two distributions given\nsamples from each, with the goal of assessing the quality of generative models.\nThe proposed approach, PQMass, provides a statistically rigorous method for\nassessing the performance of a single generative model or the comparison of\nmultiple competing models. PQMass divides the sample space into non-overlapping\nregions and applies chi-squared tests to the number of data samples that fall\nwithin each region, giving a p-value that measures the probability that the bin\ncounts derived from two sets of samples are drawn from the same multinomial\ndistribution. PQMass does not depend on assumptions regarding the density of\nthe true distribution, nor does it rely on training or fitting any auxiliary\nmodels. We evaluate PQMass on data of various modalities and dimensions,\ndemonstrating its effectiveness in assessing the quality, novelty, and\ndiversity of generated samples. We further show that PQMass scales well to\nmoderately high-dimensional data and thus obviates the need for feature\nextraction in practical applications.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.04355v2",
    "published_date": "2024-02-06 19:39:26 UTC",
    "updated_date": "2025-03-06 05:43:48 UTC"
  },
  {
    "arxiv_id": "2402.04338v2",
    "title": "Logical recognition method for solving the problem of identification in the Internet of Things",
    "authors": [
      "Islambek Saymanov"
    ],
    "abstract": "A new area of application of methods of algebra of logic and to valued logic,\nwhich has emerged recently, is the problem of recognizing a variety of objects\nand phenomena, medical or technical diagnostics, constructing modern machines,\nchecking test problems, etc., which can be reduced to constructing an optimal\nextension of the logical function to the entire feature space. For example, in\nlogical recognition systems, logical methods based on discrete analysis and\npropositional calculus based on it are used to build their own recognition\nalgorithms. In the general case, the use of a logical recognition method\nprovides for the presence of logical connections expressed by the optimal\ncontinuation of a k-valued function over the entire feature space, in which the\nvariables are the logical features of the objects or phenomena being\nrecognized. The goal of this work is to develop a logical method for object\nrecognition consisting of a reference table with logical features and classes\nof non-intersecting objects, which are specified as vectors from a given\nfeature space. The method consists of considering the reference table as a\nlogical function that is not defined everywhere and constructing an optimal\ncontinuation of the logical function to the entire feature space, which\ndetermines the extension of classes to the entire space.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "I will rework and improve it and post it again",
    "pdf_url": "http://arxiv.org/pdf/2402.04338v2",
    "published_date": "2024-02-06 19:20:58 UTC",
    "updated_date": "2024-02-13 16:05:50 UTC"
  },
  {
    "arxiv_id": "2402.04335v1",
    "title": "LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text",
    "authors": [
      "Dor Bernsohn",
      "Gil Semo",
      "Yaron Vazana",
      "Gila Hayat",
      "Ben Hagag",
      "Joel Niklaus",
      "Rohit Saha",
      "Kyryl Truskovskyi"
    ],
    "abstract": "In this study, we focus on two main tasks, the first for detecting legal\nviolations within unstructured textual data, and the second for associating\nthese violations with potentially affected individuals. We constructed two\ndatasets using Large Language Models (LLMs) which were subsequently validated\nby domain expert annotators. Both tasks were designed specifically for the\ncontext of class-action cases. The experimental design incorporated fine-tuning\nmodels from the BERT family and open-source LLMs, and conducting few-shot\nexperiments using closed-source LLMs. Our results, with an F1-score of 62.69\\%\n(violation identification) and 81.02\\% (associating victims), show that our\ndatasets and setups can be used for both tasks. Finally, we publicly release\nthe datasets and the code used for the experiments in order to advance further\nresearch in the area of legal natural language processing (NLP).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04335v1",
    "published_date": "2024-02-06 19:18:56 UTC",
    "updated_date": "2024-02-06 19:18:56 UTC"
  },
  {
    "arxiv_id": "2402.04333v3",
    "title": "LESS: Selecting Influential Data for Targeted Instruction Tuning",
    "authors": [
      "Mengzhou Xia",
      "Sadhika Malladi",
      "Suchin Gururangan",
      "Sanjeev Arora",
      "Danqi Chen"
    ],
    "abstract": "Instruction tuning has unlocked powerful capabilities in large language\nmodels (LLMs), effectively using combined datasets to develop generalpurpose\nchatbots. However, real-world applications often require a specialized suite of\nskills (e.g., reasoning). The challenge lies in identifying the most relevant\ndata from these extensive datasets to effectively develop specific\ncapabilities, a setting we frame as targeted instruction tuning. We propose\nLESS, an optimizer-aware and practically efficient algorithm to effectively\nestimate data influences and perform Low-rank gradiEnt Similarity Search for\ninstruction data selection. Crucially, LESS adapts existing influence\nformulations to work with the Adam optimizer and variable-length instruction\ndata. LESS first constructs a highly reusable and transferable gradient\ndatastore with low-dimensional gradient features and then selects examples\nbased on their similarity to few-shot examples embodying a specific capability.\nExperiments show that training on a LESS-selected 5% of the data can often\noutperform training on the full dataset across diverse downstream tasks.\nFurthermore, the selected data is highly transferable: smaller models can be\nleveraged to select useful data for larger models and models from different\nfamilies. Our qualitative analysis shows that our method goes beyond surface\nform cues to identify data that exemplifies the necessary reasoning skills for\nthe intended downstream application.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024; Code and data are available at\n  https://github.com/princeton-nlp/LESS",
    "pdf_url": "http://arxiv.org/pdf/2402.04333v3",
    "published_date": "2024-02-06 19:18:04 UTC",
    "updated_date": "2024-06-13 03:42:02 UTC"
  },
  {
    "arxiv_id": "2402.05138v1",
    "title": "SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark",
    "authors": [
      "Zhenwen Liang",
      "Kehan Guo",
      "Gang Liu",
      "Taicheng Guo",
      "Yujun Zhou",
      "Tianyu Yang",
      "Jiajun Jiao",
      "Renjie Pi",
      "Jipeng Zhang",
      "Xiangliang Zhang"
    ],
    "abstract": "The paper introduces SceMQA, a novel benchmark for scientific multimodal\nquestion answering at the college entrance level. It addresses a critical\neducational phase often overlooked in existing benchmarks, spanning high school\nto pre-college levels. SceMQA focuses on core science subjects including\nMathematics, Physics, Chemistry, and Biology. It features a blend of\nmultiple-choice and free-response formats, ensuring a comprehensive evaluation\nof AI models' abilities. Additionally, our benchmark provides specific\nknowledge points for each problem and detailed explanations for each answer.\nSceMQA also uniquely presents problems with identical contexts but varied\nquestions to facilitate a more thorough and accurate assessment of reasoning\ncapabilities. In the experiment, we evaluate both open-source and close-source\nstate-of-the-art Multimodal Large Language Models (MLLMs), across various\nexperimental settings. The results show that further research and development\nare needed in developing more capable MLLM, as highlighted by only 50% to 60%\naccuracy achieved by the strongest models. Our benchmark and analysis will be\navailable at https://scemqa.github.io/",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2402.05138v1",
    "published_date": "2024-02-06 19:16:55 UTC",
    "updated_date": "2024-02-06 19:16:55 UTC"
  },
  {
    "arxiv_id": "2402.04325v1",
    "title": "Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons",
    "authors": [
      "Zhenyu Liu",
      "Garrett Gagnon",
      "Swagath Venkataramani",
      "Liu Liu"
    ],
    "abstract": "Deep Neural Networks (DNNs) have revolutionized a wide range of industries,\nfrom healthcare and finance to automotive, by offering unparalleled\ncapabilities in data analysis and decision-making. Despite their transforming\nimpact, DNNs face two critical challenges: the vulnerability to adversarial\nattacks and the increasing computational costs associated with more complex and\nlarger models. In this paper, we introduce an effective method designed to\nsimultaneously enhance adversarial robustness and execution efficiency. Unlike\nprior studies that enhance robustness via uniformly injecting noise, we\nintroduce a non-uniform noise injection algorithm, strategically applied at\neach DNN layer to disrupt adversarial perturbations introduced in attacks. By\nemploying approximation techniques, our approach identifies and protects\nessential neurons while strategically introducing noise into non-essential\nneurons. Our experimental results demonstrate that our method successfully\nenhances both robustness and efficiency across several attack scenarios, model\narchitectures, and datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04325v1",
    "published_date": "2024-02-06 19:09:32 UTC",
    "updated_date": "2024-02-06 19:09:32 UTC"
  },
  {
    "arxiv_id": "2402.04249v2",
    "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal",
    "authors": [
      "Mantas Mazeika",
      "Long Phan",
      "Xuwang Yin",
      "Andy Zou",
      "Zifan Wang",
      "Norman Mu",
      "Elham Sakhaee",
      "Nathaniel Li",
      "Steven Basart",
      "Bo Li",
      "David Forsyth",
      "Dan Hendrycks"
    ],
    "abstract": "Automated red teaming holds substantial promise for uncovering and mitigating\nthe risks associated with the malicious use of large language models (LLMs),\nyet the field lacks a standardized evaluation framework to rigorously assess\nnew methods. To address this issue, we introduce HarmBench, a standardized\nevaluation framework for automated red teaming. We identify several desirable\nproperties previously unaccounted for in red teaming evaluations and\nsystematically design HarmBench to meet these criteria. Using HarmBench, we\nconduct a large-scale comparison of 18 red teaming methods and 33 target LLMs\nand defenses, yielding novel insights. We also introduce a highly efficient\nadversarial training method that greatly enhances LLM robustness across a wide\nrange of attacks, demonstrating how HarmBench enables codevelopment of attacks\nand defenses. We open source HarmBench at\nhttps://github.com/centerforaisafety/HarmBench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Website: https://www.harmbench.org",
    "pdf_url": "http://arxiv.org/pdf/2402.04249v2",
    "published_date": "2024-02-06 18:59:08 UTC",
    "updated_date": "2024-02-27 04:43:08 UTC"
  },
  {
    "arxiv_id": "2402.04247v4",
    "title": "Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science",
    "authors": [
      "Xiangru Tang",
      "Qiao Jin",
      "Kunlun Zhu",
      "Tongxin Yuan",
      "Yichi Zhang",
      "Wangchunshu Zhou",
      "Meng Qu",
      "Yilun Zhao",
      "Jian Tang",
      "Zhuosheng Zhang",
      "Arman Cohan",
      "Zhiyong Lu",
      "Mark Gerstein"
    ],
    "abstract": "Intelligent agents powered by large language models (LLMs) have demonstrated\nsubstantial promise in autonomously conducting experiments and facilitating\nscientific discoveries across various disciplines. While their capabilities are\npromising, these agents, called scientific LLM agents, also introduce novel\nvulnerabilities that demand careful consideration for safety. However, there\nexists a notable gap in the literature, as there has been no comprehensive\nexploration of these vulnerabilities. This perspective paper fills this gap by\nconducting a thorough examination of vulnerabilities in LLM-based agents within\nscientific domains, shedding light on potential risks associated with their\nmisuse and emphasizing the need for safety measures. We begin by providing a\ncomprehensive overview of the potential risks inherent to scientific LLM\nagents, taking into account user intent, the specific scientific domain, and\ntheir potential impact on the external environment. Then, we delve into the\norigins of these vulnerabilities and provide a scoping review of the limited\nexisting works. Based on our analysis, we propose a triadic framework involving\nhuman regulation, agent alignment, and an understanding of environmental\nfeedback (agent regulation) to mitigate these identified risks. Furthermore, we\nhighlight the limitations and challenges associated with safeguarding\nscientific agents and advocate for the development of improved models, robust\nbenchmarks, and comprehensive regulations to address these issues effectively.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04247v4",
    "published_date": "2024-02-06 18:54:07 UTC",
    "updated_date": "2024-06-05 06:13:09 UTC"
  },
  {
    "arxiv_id": "2402.04232v2",
    "title": "Can Generative Agents Predict Emotion?",
    "authors": [
      "Ciaran Regan",
      "Nanami Iwahashi",
      "Shogo Tanaka",
      "Mizuki Oka"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated a number of human-like\nabilities, however the empathic understanding and emotional state of LLMs is\nyet to be aligned to that of humans. In this work, we investigate how the\nemotional state of generative LLM agents evolves as they perceive new events,\nintroducing a novel architecture in which new experiences are compared to past\nmemories. Through this comparison, the agent gains the ability to understand\nnew experiences in context, which according to the appraisal theory of emotion\nis vital in emotion creation. First, the agent perceives new experiences as\ntime series text data. After perceiving each new input, the agent generates a\nsummary of past relevant memories, referred to as the norm, and compares the\nnew experience to this norm. Through this comparison we can analyse how the\nagent reacts to the new experience in context. The PANAS, a test of affect, is\nadministered to the agent, capturing the emotional state of the agent after the\nperception of the new event. Finally, the new experience is then added to the\nagents memory to be used in the creation of future norms. By creating multiple\nexperiences in natural language from emotionally charged situations, we test\nthe proposed architecture on a wide range of scenarios. The mixed results\nsuggests that introducing context can occasionally improve the emotional\nalignment of the agent, but further study and comparison with human evaluators\nis necessary. We hope that this paper is another step towards the alignment of\ngenerative agents.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.04232v2",
    "published_date": "2024-02-06 18:39:43 UTC",
    "updated_date": "2024-02-07 17:27:09 UTC"
  },
  {
    "arxiv_id": "2402.04228v1",
    "title": "Intelligent Collective Escape of Swarm Robots Based on a Novel Fish-inspired Self-adaptive Approach with Neurodynamic Models",
    "authors": [
      "Junfei Li",
      "Simon X. Yang"
    ],
    "abstract": "Fish schools present high-efficiency group behaviors through simple\nindividual interactions to collective migration and dynamic escape from the\npredator. The school behavior of fish is usually a good inspiration to design\ncontrol architecture for swarm robots. In this paper, a novel fish-inspired\nself-adaptive approach is proposed for collective escape for the swarm robots.\nIn addition, a bio-inspired neural network (BINN) is introduced to generate\ncollision-free escape robot trajectories through the combination of attractive\nand repulsive forces. Furthermore, to cope with dynamic environments, a\nneurodynamics-based self-adaptive mechanism is proposed to improve the\nself-adaptive performance of the swarm robots in the changing environment.\nSimilar to fish escape maneuvers, simulation and experimental results show that\nthe swarm robots are capable of collectively leaving away from the threats.\nSeveral comparison studies demonstrated that the proposed approach can\nsignificantly improve the effectiveness and efficiency of system performance,\nand the flexibility and robustness in complex environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "This article is accepted for publication in a future issue of IEEE\n  Transactions on Industrial Electronics",
    "pdf_url": "http://arxiv.org/pdf/2402.04228v1",
    "published_date": "2024-02-06 18:36:44 UTC",
    "updated_date": "2024-02-06 18:36:44 UTC"
  },
  {
    "arxiv_id": "2402.04210v2",
    "title": "Task Success is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors",
    "authors": [
      "Lin Guan",
      "Yifan Zhou",
      "Denis Liu",
      "Yantian Zha",
      "Heni Ben Amor",
      "Subbarao Kambhampati"
    ],
    "abstract": "Large-scale generative models are shown to be useful for sampling meaningful\ncandidate solutions, yet they often overlook task constraints and user\npreferences. Their full power is better harnessed when the models are coupled\nwith external verifiers and the final solutions are derived iteratively or\nprogressively according to the verification feedback. In the context of\nembodied AI, verification often solely involves assessing whether goal\nconditions specified in the instructions have been met. Nonetheless, for these\nagents to be seamlessly integrated into daily life, it is crucial to account\nfor a broader range of constraints and preferences beyond bare task success\n(e.g., a robot should grasp bread with care to avoid significant deformations).\nHowever, given the unbounded scope of robot tasks, it is infeasible to\nconstruct scripted verifiers akin to those used for explicit-knowledge tasks\nlike the game of Go and theorem proving. This begs the question: when no sound\nverifier is available, can we use large vision and language models (VLMs),\nwhich are approximately omniscient, as scalable Behavior Critics to catch\nundesirable robot behaviors in videos? To answer this, we first construct a\nbenchmark that contains diverse cases of goal-reaching yet undesirable robot\npolicies. Then, we comprehensively evaluate VLM critics to gain a deeper\nunderstanding of their strengths and failure modes. Based on the evaluation, we\nprovide guidelines on how to effectively utilize VLM critiques and showcase a\npractical way to integrate the feedback into an iterative process of policy\nrefinement. The dataset and codebase are released at:\nhttps://guansuns.github.io/pages/vlm-critic.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04210v2",
    "published_date": "2024-02-06 18:07:43 UTC",
    "updated_date": "2024-08-11 07:13:50 UTC"
  },
  {
    "arxiv_id": "2402.04209v1",
    "title": "Acute kidney injury prediction for non-critical care patients: a retrospective external and internal validation study",
    "authors": [
      "Esra Adiyeke",
      "Yuanfang Ren",
      "Benjamin Shickel",
      "Matthew M. Ruppert",
      "Ziyuan Guan",
      "Sandra L. Kane-Gill",
      "Raghavan Murugan",
      "Nabihah Amatullah",
      "Britney A. Stottlemyer",
      "Tiffany L. Tran",
      "Dan Ricketts",
      "Christopher M Horvat",
      "Parisa Rashidi",
      "Azra Bihorac",
      "Tezcan Ozrazgat-Baslanti"
    ],
    "abstract": "Background: Acute kidney injury (AKI), the decline of kidney excretory\nfunction, occurs in up to 18% of hospitalized admissions. Progression of AKI\nmay lead to irreversible kidney damage. Methods: This retrospective cohort\nstudy includes adult patients admitted to a non-intensive care unit at the\nUniversity of Pittsburgh Medical Center (UPMC) (n = 46,815) and University of\nFlorida Health (UFH) (n = 127,202). We developed and compared deep learning and\nconventional machine learning models to predict progression to Stage 2 or\nhigher AKI within the next 48 hours. We trained local models for each site (UFH\nModel trained on UFH, UPMC Model trained on UPMC) and a separate model with a\ndevelopment cohort of patients from both sites (UFH-UPMC Model). We internally\nand externally validated the models on each site and performed subgroup\nanalyses across sex and race. Results: Stage 2 or higher AKI occurred in 3%\n(n=3,257) and 8% (n=2,296) of UFH and UPMC patients, respectively. Area under\nthe receiver operating curve values (AUROC) for the UFH test cohort ranged\nbetween 0.77 (UPMC Model) and 0.81 (UFH Model), while AUROC values ranged\nbetween 0.79 (UFH Model) and 0.83 (UPMC Model) for the UPMC test cohort.\nUFH-UPMC Model achieved an AUROC of 0.81 (95% confidence interval [CI] [0.80,\n0.83]) for UFH and 0.82 (95% CI [0.81,0.84]) for UPMC test cohorts; an area\nunder the precision recall curve values (AUPRC) of 0.6 (95% CI, [0.05, 0.06])\nfor UFH and 0.13 (95% CI, [0.11,0.15]) for UPMC test cohorts. Kinetic estimated\nglomerular filtration rate, nephrotoxic drug burden and blood urea nitrogen\nremained the top three features with the highest influence across the models\nand health centers. Conclusion: Locally developed models displayed marginally\nreduced discrimination when tested on another institution, while the top set of\ninfluencing features remained the same across the models and sites.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04209v1",
    "published_date": "2024-02-06 18:05:30 UTC",
    "updated_date": "2024-02-06 18:05:30 UTC"
  },
  {
    "arxiv_id": "2402.04203v1",
    "title": "Human-Like Geometric Abstraction in Large Pre-trained Neural Networks",
    "authors": [
      "Declan Campbell",
      "Sreejan Kumar",
      "Tyler Giallanza",
      "Thomas L. Griffiths",
      "Jonathan D. Cohen"
    ],
    "abstract": "Humans possess a remarkable capacity to recognize and manipulate abstract\nstructure, which is especially apparent in the domain of geometry. Recent\nresearch in cognitive science suggests neural networks do not share this\ncapacity, concluding that human geometric abilities come from discrete symbolic\nstructure in human mental representations. However, progress in artificial\nintelligence (AI) suggests that neural networks begin to demonstrate more\nhuman-like reasoning after scaling up standard architectures in both model size\nand amount of training data. In this study, we revisit empirical results in\ncognitive science on geometric visual processing and identify three key biases\nin geometric visual processing: a sensitivity towards complexity, regularity,\nand the perception of parts and relations. We test tasks from the literature\nthat probe these biases in humans and find that large pre-trained neural\nnetwork models used in AI demonstrate more human-like abstract geometric\nprocessing.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04203v1",
    "published_date": "2024-02-06 17:59:46 UTC",
    "updated_date": "2024-02-06 17:59:46 UTC"
  },
  {
    "arxiv_id": "2402.04173v1",
    "title": "COPS: A Compact On-device Pipeline for real-time Smishing detection",
    "authors": [
      "Harichandana B S S",
      "Sumit Kumar",
      "Manjunath Bhimappa Ujjinakoppa",
      "Barath Raj Kandur Raja"
    ],
    "abstract": "Smartphones have become indispensable in our daily lives and can do almost\neverything, from communication to online shopping. However, with the increased\nusage, cybercrime aimed at mobile devices is rocketing. Smishing attacks, in\nparticular, have observed a significant upsurge in recent years. This problem\nis further exacerbated by the perpetrator creating new deceptive websites\ndaily, with an average life cycle of under 15 hours. This renders the standard\npractice of keeping a database of malicious URLs ineffective. To this end, we\npropose a novel on-device pipeline: COPS that intelligently identifies features\nof fraudulent messages and URLs to alert the user in real-time. COPS is a\nlightweight pipeline with a detection module based on the Disentangled\nVariational Autoencoder of size 3.46MB for smishing and URL phishing detection,\nand we benchmark it on open datasets. We achieve an accuracy of 98.15% and\n99.5%, respectively, for both tasks, with a false negative and false positive\nrate of a mere 0.037 and 0.015, outperforming previous works with the added\nadvantage of ensuring real-time alerts on resource-constrained devices.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Published at IEEE Consumer Communications & Networking Conference\n  (CCNC) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04173v1",
    "published_date": "2024-02-06 17:27:12 UTC",
    "updated_date": "2024-02-06 17:27:12 UTC"
  },
  {
    "arxiv_id": "2403.05547v1",
    "title": "AI for non-programmers: Applied AI in the lectures for students without programming skills",
    "authors": [
      "Julius Schöning",
      "Tim Wawer",
      "Kai-Michael Griese"
    ],
    "abstract": "Applications such as ChatGPT and WOMBO Dream make it easy to inspire students\nwithout programming knowledge to use artificial intelligence (AI). Therefore,\ngiven the increasing importance of AI in all disciplines, innovative strategies\nare needed to educate students in AI without programming knowledge so that AI\ncan be integrated into their study modules as a future skill. This work\npresents a didactic planning script for applied AI. The didactic planning\nscript is based on the AI application pipeline and links AI concepts with\nstudy-relevant topics. These linkages open up a new solution space and promote\nstudents' interest in and understanding of the potentials and risks of AI. An\nexample lecture series for master students in energy management shows how AI\ncan be seamlessly integrated into discipline-specific lectures. To this end,\nthe planning script for applied AI is adapted to fit the study programs' topic.\nThis specific teaching scenario enables students to solve a discipline-specific\ntask step by step using the AI application pipeline. Thus, the application of\nthe didactic planning script for applied AI shows the practical implementation\nof the theoretical concepts of AI. In addition, a checklist is presented that\ncan be used to assess whether AI can be used in the discipline-specific\nlecture. AI as a future skill must be learned by students based on use cases\nthat are relevant to the course of studies. For this reason, AI education\nshould fit seamlessly into various curricula, even if the students do not have\na programming background due to their field of study.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "K.3.2; I.2.0"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages, 6 figures, Translated from the German of \"KI f\\\"ur\n  Nicht-Programmierer*innen: Angewandte KI im H\\\"orsaal f\\\"ur Studierende ohne\n  Programmierkenntnisse\". Translated from the German of\n  https://nbn-resolving.org/urn:nbn:de:bsz:959-opus-52866",
    "pdf_url": "http://arxiv.org/pdf/2403.05547v1",
    "published_date": "2024-02-06 17:26:24 UTC",
    "updated_date": "2024-02-06 17:26:24 UTC"
  },
  {
    "arxiv_id": "2402.06665v2",
    "title": "The Essential Role of Causality in Foundation World Models for Embodied AI",
    "authors": [
      "Tarun Gupta",
      "Wenbo Gong",
      "Chao Ma",
      "Nick Pawlowski",
      "Agrin Hilmkil",
      "Meyer Scetbon",
      "Marc Rigter",
      "Ade Famoti",
      "Ashley Juan Llorens",
      "Jianfeng Gao",
      "Stefan Bauer",
      "Danica Kragic",
      "Bernhard Schölkopf",
      "Cheng Zhang"
    ],
    "abstract": "Recent advances in foundation models, especially in large multi-modal models\nand conversational agents, have ignited interest in the potential of generally\ncapable embodied agents. Such agents will require the ability to perform new\ntasks in many different real-world environments. However, current foundation\nmodels fail to accurately model physical interactions and are therefore\ninsufficient for Embodied AI. The study of causality lends itself to the\nconstruction of veridical world models, which are crucial for accurately\npredicting the outcomes of possible interactions. This paper focuses on the\nprospects of building foundation world models for the upcoming generation of\nembodied agents and presents a novel viewpoint on the significance of causality\nwithin these. We posit that integrating causal considerations is vital to\nfacilitating meaningful physical interactions with the world. Finally, we\ndemystify misconceptions about causality in this context and present our\noutlook for future research.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06665v2",
    "published_date": "2024-02-06 17:15:33 UTC",
    "updated_date": "2024-04-29 23:21:33 UTC"
  },
  {
    "arxiv_id": "2402.04154v7",
    "title": "Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction",
    "authors": [
      "Yonggang Jin",
      "Ge Zhang",
      "Hao Zhao",
      "Tianyu Zheng",
      "Jarvi Guo",
      "Liuyu Xiang",
      "Shawn Yue",
      "Stephen W. Huang",
      "Zhaofeng He",
      "Jie Fu"
    ],
    "abstract": "Developing a generalist agent is a longstanding objective in artificial\nintelligence. Previous efforts utilizing extensive offline datasets from\nvarious tasks demonstrate remarkable performance in multitasking scenarios\nwithin Reinforcement Learning. However, these works encounter challenges in\nextending their capabilities to new tasks. Recent approaches integrate textual\nguidance or visual trajectory into decision networks to provide task-specific\ncontextual cues, representing a promising direction. However, it is observed\nthat relying solely on textual guidance or visual trajectory is insufficient\nfor accurately conveying the contextual information of tasks. This paper\nexplores enhanced forms of task guidance for agents, enabling them to\ncomprehend gameplay instructions, thereby facilitating a \"read-to-play\"\ncapability. Drawing inspiration from the success of multimodal instruction\ntuning in visual tasks, we treat the visual-based RL task as a long-horizon\nvision task and construct a set of multimodal game instructions to incorporate\ninstruction tuning into a decision transformer. Experimental results\ndemonstrate that incorporating multimodal game instructions significantly\nenhances the decision transformer's multitasking and generalization\ncapabilities.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04154v7",
    "published_date": "2024-02-06 17:09:25 UTC",
    "updated_date": "2024-11-18 15:31:52 UTC"
  },
  {
    "arxiv_id": "2402.04141v1",
    "title": "Multi-line AI-assisted Code Authoring",
    "authors": [
      "Omer Dunay",
      "Daniel Cheng",
      "Adam Tait",
      "Parth Thakkar",
      "Peter C Rigby",
      "Andy Chiu",
      "Imad Ahmad",
      "Arun Ganesan",
      "Chandra Maddila",
      "Vijayaraghavan Murali",
      "Ali Tayyebi",
      "Nachiappan Nagappan"
    ],
    "abstract": "CodeCompose is an AI-assisted code authoring tool powered by large language\nmodels (LLMs) that provides inline suggestions to 10's of thousands of\ndevelopers at Meta. In this paper, we present how we scaled the product from\ndisplaying single-line suggestions to multi-line suggestions. This evolution\nrequired us to overcome several unique challenges in improving the usability of\nthese suggestions for developers.\n  First, we discuss how multi-line suggestions can have a 'jarring' effect, as\nthe LLM's suggestions constantly move around the developer's existing code,\nwhich would otherwise result in decreased productivity and satisfaction.\n  Second, multi-line suggestions take significantly longer to generate; hence\nwe present several innovative investments we made to reduce the perceived\nlatency for users. These model-hosting optimizations sped up multi-line\nsuggestion latency by 2.5x.\n  Finally, we conduct experiments on 10's of thousands of engineers to\nunderstand how multi-line suggestions impact the user experience and contrast\nthis with single-line suggestions. Our experiments reveal that (i) multi-line\nsuggestions account for 42% of total characters accepted (despite only\naccounting for 16% for displayed suggestions) (ii) multi-line suggestions\nalmost doubled the percentage of keystrokes saved for users from 9% to 17%.\nMulti-line CodeCompose has been rolled out to all engineers at Meta, and less\nthan 1% of engineers have opted out of multi-line suggestions.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04141v1",
    "published_date": "2024-02-06 16:48:50 UTC",
    "updated_date": "2024-02-06 16:48:50 UTC"
  },
  {
    "arxiv_id": "2402.04140v3",
    "title": "Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)",
    "authors": [
      "Michael De'Shazer"
    ],
    "abstract": "This study consists of a novel approach toward the analysis of court\njudgments spanning five countries, including the United States, the United\nKingdom, Rwanda, Sweden and Hong Kong. This study also explores the\nintersection of the latest advancements in artificial intelligence (AI) and\nlegal analysis, emphasizing the role of AI (specifically generative AI) in\nidentifying human biases and facilitating automated, valid, and coherent\nmultisided argumentation of court judgments with the goal of ensuring\nconsistent application of laws in and across various jurisdictions. By\nincorporating Advanced Language Models (ALMs) and a newly introduced human-AI\ncollaborative framework, this paper seeks to analyze Grounded Theory-based\nresearch design with Advanced Language Models (ALMs) in the practice of law.\nSHIRLEY is the name of the AI-based application (built on top of OpenAI's GPT\ntechnology), focusing on detecting logical inconsistencies and biases across\nvarious legal decisions. SHIRLEY analysis is aggregated and is accompanied by a\ncomparison-oriented AI-based application called SAM (also an ALM) to identify\nrelative deviations in SHIRLEY bias detections. Further, a CRITIC is generated\nwithin semi-autonomous arbitration process via the ALM, SARA. A novel approach\nis introduced in the utilization of an AI arbitrator to critically evaluate\nbiases and qualitative-in-nature nuances identified by the aforementioned AI\napplications (SAM in concert with SHIRLEY), based on the Hague Rules on\nBusiness and Human Rights Arbitration. This Semi-Automated Arbitration Process\n(SAAP) aims to uphold the integrity and fairness of legal judgments by ensuring\na nuanced debate-resultant \"understanding\" through a hybrid system of AI and\nhuman-based collaborative analysis.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04140v3",
    "published_date": "2024-02-06 16:47:34 UTC",
    "updated_date": "2024-02-29 17:23:01 UTC"
  },
  {
    "arxiv_id": "2402.04108v1",
    "title": "Hierarchical Delay Attribution Classification using Unstructured Text in Train Management Systems",
    "authors": [
      "Anton Borg",
      "Per Lingvall",
      "Martin Svensson"
    ],
    "abstract": "EU directives stipulate a systematic follow-up of train delays. In Sweden,\nthe Swedish Transport Administration registers and assigns an appropriate delay\nattribution code. However, this delay attribution code is assigned manually,\nwhich is a complex task. In this paper, a machine learning-based decision\nsupport for assigning delay attribution codes based on event descriptions is\ninvestigated. The text is transformed using TF-IDF, and two models, Random\nForest and Support Vector Machine, are evaluated against a random uniform\nclassifier and the classification performance of the Swedish Transport\nAdministration. Further, the problem is modeled as both a hierarchical and flat\napproach. The results indicate that a hierarchical approach performs better\nthan a flat approach. Both approaches perform better than the random uniform\nclassifier but perform worse than the manual classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.04108v1",
    "published_date": "2024-02-06 16:02:17 UTC",
    "updated_date": "2024-02-06 16:02:17 UTC"
  },
  {
    "arxiv_id": "2402.07933v2",
    "title": "Human-Centered AI Product Prototyping with No-Code AutoML: Conceptual Framework, Potentials and Limitations",
    "authors": [
      "Mario Truss",
      "Marc Schmitt"
    ],
    "abstract": "This paper addresses the complexities inherent in AI product prototyping,\nfocusing on the challenges posed by the probabilistic nature of AI behavior and\nthe limited accessibility of prototyping tools to non-experts. A Design Science\nResearch (DSR) approach is presented which culminates in a conceptual framework\naimed at improving the AI prototyping process. Through a comprehensive\nliterature review, key challenges were identified and no-code AutoML was\nanalyzed as a solution. The framework describes the seamless incorporation of\nnon-expert input and evaluation during prototyping, leveraging the potential of\nno-code AutoML to enhance accessibility and interpretability. A hybrid approach\nof combining naturalistic (case study) and artificial evaluation methods\n(criteria-based analysis) validated the utility of our approach, highlighting\nits efficacy in supporting AI non-experts and streamlining decision-making and\nits limitations. Implications for academia and industry, emphasizing the\nstrategic integration of no-code AutoML to enhance AI product development\nprocesses, mitigate risks, and foster innovation, are discussed.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "cs.SE",
      "I.2.0; H.5.0; D.2.2; H.1.2; I.2.5; K.6.1"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07933v2",
    "published_date": "2024-02-06 16:00:32 UTC",
    "updated_date": "2024-06-07 11:09:17 UTC"
  },
  {
    "arxiv_id": "2402.04103v1",
    "title": "An Exploration of Clustering Algorithms for Customer Segmentation in the UK Retail Market",
    "authors": [
      "Jeen Mary John",
      "Olamilekan Shobayo",
      "Bayode Ogunleye"
    ],
    "abstract": "Recently, peoples awareness of online purchases has significantly risen. This\nhas given rise to online retail platforms and the need for a better\nunderstanding of customer purchasing behaviour. Retail companies are pressed\nwith the need to deal with a high volume of customer purchases, which requires\nsophisticated approaches to perform more accurate and efficient customer\nsegmentation. Customer segmentation is a marketing analytical tool that aids\ncustomer-centric service and thus enhances profitability. In this paper, we aim\nto develop a customer segmentation model to improve decision-making processes\nin the retail market industry. To achieve this, we employed a UK-based online\nretail dataset obtained from the UCI machine learning repository. The retail\ndataset consists of 541,909 customer records and eight features. Our study\nadopted the RFM (recency, frequency, and monetary) framework to quantify\ncustomer values. Thereafter, we compared several state-of-the-art (SOTA)\nclustering algorithms, namely, K-means clustering, the Gaussian mixture model\n(GMM), density-based spatial clustering of applications with noise (DBSCAN),\nagglomerative clustering, and balanced iterative reducing and clustering using\nhierarchies (BIRCH). The results showed the GMM outperformed other approaches,\nwith a Silhouette Score of 0.80.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.CO",
      "H.3.3"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, Journal of Analytics",
    "pdf_url": "http://arxiv.org/pdf/2402.04103v1",
    "published_date": "2024-02-06 15:58:14 UTC",
    "updated_date": "2024-02-06 15:58:14 UTC"
  },
  {
    "arxiv_id": "2402.04102v1",
    "title": "Use of Multi-CNNs for Section Analysis in Static Malware Detection",
    "authors": [
      "Tony Quertier",
      "Grégoire Barrué"
    ],
    "abstract": "Existing research on malware detection focuses almost exclusively on the\ndetection rate. However, in some cases, it is also important to understand the\nresults of our algorithm, or to obtain more information, such as where to\ninvestigate in the file for an analyst. In this aim, we propose a new model to\nanalyze Portable Executable files. Our method consists in splitting the files\nin different sections, then transform each section into an image, in order to\ntrain convolutional neural networks to treat specifically each identified\nsection. Then we use all these scores returned by CNNs to compute a final\ndetection score, using models that enable us to improve our analysis of the\nimportance of each section in the final score.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "arXiv admin note: text overlap with arXiv:2312.12161",
    "pdf_url": "http://arxiv.org/pdf/2402.04102v1",
    "published_date": "2024-02-06 15:57:08 UTC",
    "updated_date": "2024-02-06 15:57:08 UTC"
  },
  {
    "arxiv_id": "2402.04088v1",
    "title": "The Use of a Large Language Model for Cyberbullying Detection",
    "authors": [
      "Bayode Ogunleye",
      "Babitha Dharmaraj"
    ],
    "abstract": "The dominance of social media has added to the channels of bullying for\nperpetrators. Unfortunately, cyberbullying (CB) is the most prevalent\nphenomenon in todays cyber world, and is a severe threat to the mental and\nphysical health of citizens. This opens the need to develop a robust system to\nprevent bullying content from online forums, blogs, and social media platforms\nto manage the impact in our society. Several machine learning (ML) algorithms\nhave been proposed for this purpose. However, their performances are not\nconsistent due to high class imbalance and generalisation issues. In recent\nyears, large language models (LLMs) like BERT and RoBERTa have achieved\nstate-of-the-art (SOTA) results in several natural language processing (NLP)\ntasks. Unfortunately, the LLMs have not been applied extensively for CB\ndetection. In our paper, we explored the use of these models for cyberbullying\n(CB) detection. We have prepared a new dataset (D2) from existing studies\n(Formspring and Twitter). Our experimental results for dataset D1 and D2 showed\nthat RoBERTa outperformed other models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "H.3.3"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, Journal of Analytics",
    "pdf_url": "http://arxiv.org/pdf/2402.04088v1",
    "published_date": "2024-02-06 15:46:31 UTC",
    "updated_date": "2024-02-06 15:46:31 UTC"
  },
  {
    "arxiv_id": "2402.04087v1",
    "title": "A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation",
    "authors": [
      "Zhengbo Wang",
      "Jian Liang",
      "Lijun Sheng",
      "Ran He",
      "Zilei Wang",
      "Tieniu Tan"
    ],
    "abstract": "Contrastive Language-Image Pretraining (CLIP) has gained popularity for its\nremarkable zero-shot capacity. Recent research has focused on developing\nefficient fine-tuning methods, such as prompt learning and adapter, to enhance\nCLIP's performance in downstream tasks. However, these methods still require\nadditional training time and computational resources, which is undesirable for\ndevices with limited resources. In this paper, we revisit a classical\nalgorithm, Gaussian Discriminant Analysis (GDA), and apply it to the downstream\nclassification of CLIP. Typically, GDA assumes that features of each class\nfollow Gaussian distributions with identical covariance. By leveraging Bayes'\nformula, the classifier can be expressed in terms of the class means and\ncovariance, which can be estimated from the data without the need for training.\nTo integrate knowledge from both visual and textual modalities, we ensemble it\nwith the original zero-shot classifier within CLIP. Extensive results on 17\ndatasets validate that our method surpasses or achieves comparable results with\nstate-of-the-art methods on few-shot classification, imbalanced learning, and\nout-of-distribution generalization. In addition, we extend our method to\nbase-to-new generalization and unsupervised learning, once again demonstrating\nits superiority over competing approaches. Our code is publicly available at\n\\url{https://github.com/mrflogs/ICLR24}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04087v1",
    "published_date": "2024-02-06 15:45:27 UTC",
    "updated_date": "2024-02-06 15:45:27 UTC"
  },
  {
    "arxiv_id": "2402.07932v1",
    "title": "A Human-Machine Collaboration Framework for the Development of Schemas",
    "authors": [
      "Nicos Isaak"
    ],
    "abstract": "The Winograd Schema Challenge (WSC), a seemingly well-thought-out test for\nmachine intelligence, has been proposed to shed light on developing systems\nthat exhibit human behavior. Since its introduction, it aimed to pivot the\nfocus of the AI community from the technology to the science of AI. While\ncommon and trivial for humans, studies show that it is still challenging for\nmachines, especially when they have to deal with novel schemas, that is,\nwell-designed sentences that require the resolving of definite pronouns. As\nresearchers have become increasingly interested in the challenge itself, this\npresumably necessitates the availability of an extensive collection of Winograd\nschemas, which goes beyond what human experts can reasonably develop\nthemselves, especially after proposed ways of utilizing them as novel forms of\nCAPTCHAs.\n  To address this necessity, we propose a novel framework that explicitly\nfocuses on how humans and machines can collaborate as teammates to design novel\nschemas from scratch. This is being accomplished by combining two recent\nstudies from the literature: i) Winventor, a machine-driven approach for the\ndevelopment of large amounts of Winograd schemas, albeit not of high quality,\nand ii) WinoFlexi, an online crowdsourcing system that allows crowd workers to\ndevelop a limited number of schemas often of similar quality to that of\nexperts. Our proposal crafts a new road map toward developing a novel\ncollaborative platform that amplifies human and machine intelligence by\ncombining their complementary strengths.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "I.2.0; I.2.3; I.2.4; I.2.7; I.5.1; I.5.4"
    ],
    "primary_category": "cs.HC",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.07932v1",
    "published_date": "2024-02-06 15:41:49 UTC",
    "updated_date": "2024-02-06 15:41:49 UTC"
  },
  {
    "arxiv_id": "2402.04082v1",
    "title": "An Optimal House Price Prediction Algorithm: XGBoost",
    "authors": [
      "Hemlata Sharma",
      "Hitesh Harsora",
      "Bayode Ogunleye"
    ],
    "abstract": "An accurate prediction of house prices is a fundamental requirement for\nvarious sectors including real estate and mortgage lending. It is widely\nrecognized that a property value is not solely determined by its physical\nattributes but is significantly influenced by its surrounding neighbourhood.\nMeeting the diverse housing needs of individuals while balancing budget\nconstraints is a primary concern for real estate developers. To this end, we\naddressed the house price prediction problem as a regression task and thus\nemployed various machine learning techniques capable of expressing the\nsignificance of independent variables. We made use of the housing dataset of\nAmes City in Iowa, USA to compare support vector regressor, random forest\nregressor, XGBoost, multilayer perceptron and multiple linear regression\nalgorithms for house price prediction. Afterwards, we identified the key\nfactors that influence housing costs. Our results show that XGBoost is the best\nperforming model for house price prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ME",
      "H.3.3"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, Journal of Analytics",
    "pdf_url": "http://arxiv.org/pdf/2402.04082v1",
    "published_date": "2024-02-06 15:36:06 UTC",
    "updated_date": "2024-02-06 15:36:06 UTC"
  },
  {
    "arxiv_id": "2402.04081v2",
    "title": "Improved Generalization of Weight Space Networks via Augmentations",
    "authors": [
      "Aviv Shamsian",
      "Aviv Navon",
      "David W. Zhang",
      "Yan Zhang",
      "Ethan Fetaya",
      "Gal Chechik",
      "Haggai Maron"
    ],
    "abstract": "Learning in deep weight spaces (DWS), where neural networks process the\nweights of other neural networks, is an emerging research direction, with\napplications to 2D and 3D neural fields (INRs, NeRFs), as well as making\ninferences about other types of neural networks. Unfortunately, weight space\nmodels tend to suffer from substantial overfitting. We empirically analyze the\nreasons for this overfitting and find that a key reason is the lack of\ndiversity in DWS datasets. While a given object can be represented by many\ndifferent weight configurations, typical INR training sets fail to capture\nvariability across INRs that represent the same object. To address this, we\nexplore strategies for data augmentation in weight spaces and propose a MixUp\nmethod adapted for weight spaces. We demonstrate the effectiveness of these\nmethods in two setups. In classification, they improve performance similarly to\nhaving up to 10 times more data. In self-supervised contrastive learning, they\nyield substantial 5-10% gains in downstream classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2402.04081v2",
    "published_date": "2024-02-06 15:34:44 UTC",
    "updated_date": "2024-11-09 22:09:13 UTC"
  },
  {
    "arxiv_id": "2402.04064v1",
    "title": "Multi-class Road Defect Detection and Segmentation using Spatial and Channel-wise Attention for Autonomous Road Repairing",
    "authors": [
      "Jongmin Yu",
      "Chen Bene Chi",
      "Sebastiano Fichera",
      "Paolo Paoletti",
      "Devansh Mehta",
      "Shan Luo"
    ],
    "abstract": "Road pavement detection and segmentation are critical for developing\nautonomous road repair systems. However, developing an instance segmentation\nmethod that simultaneously performs multi-class defect detection and\nsegmentation is challenging due to the textural simplicity of road pavement\nimage, the diversity of defect geometries, and the morphological ambiguity\nbetween classes. We propose a novel end-to-end method for multi-class road\ndefect detection and segmentation. The proposed method comprises multiple\nspatial and channel-wise attention blocks available to learn global\nrepresentations across spatial and channel-wise dimensions. Through these\nattention blocks, more globally generalised representations of morphological\ninformation (spatial characteristics) of road defects and colour and depth\ninformation of images can be learned. To demonstrate the effectiveness of our\nframework, we conducted various ablation studies and comparisons with prior\nmethods on a newly collected dataset annotated with nine road defect classes.\nThe experiments show that our proposed method outperforms existing\nstate-of-the-art methods for multi-class road defect detection and segmentation\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04064v1",
    "published_date": "2024-02-06 15:09:50 UTC",
    "updated_date": "2024-02-06 15:09:50 UTC"
  },
  {
    "arxiv_id": "2402.04062v2",
    "title": "Link Prediction with Relational Hypergraphs",
    "authors": [
      "Xingyue Huang",
      "Miguel Romero Orth",
      "Pablo Barceló",
      "Michael M. Bronstein",
      "İsmail İlkan Ceylan"
    ],
    "abstract": "Link prediction with knowledge graphs has been thoroughly studied in graph\nmachine learning, leading to a rich landscape of graph neural network\narchitectures with successful applications. Nonetheless, it remains challenging\nto transfer the success of these architectures to relational hypergraphs, where\nthe task of link prediction is over $k$-ary relations, which is substantially\nharder than link prediction with knowledge graphs. In this paper, we propose a\nframework for link prediction with relational hypergraphs, unlocking\napplications of graph neural networks to fully relational structures.\nTheoretically, we conduct a thorough analysis of the expressive power of the\nresulting model architectures via corresponding relational Weisfeiler-Leman\nalgorithms and also via logical expressiveness. Empirically, we validate the\npower of the proposed model architectures on various relational hypergraph\nbenchmarks. The resulting model architectures substantially outperform every\nbaseline for inductive link prediction, and lead to state-of-the-art results\nfor transductive link prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04062v2",
    "published_date": "2024-02-06 15:05:40 UTC",
    "updated_date": "2024-05-23 15:37:16 UTC"
  },
  {
    "arxiv_id": "2402.04059v2",
    "title": "Deep Learning for Multivariate Time Series Imputation: A Survey",
    "authors": [
      "Jun Wang",
      "Wenjie Du",
      "Yiyuan Yang",
      "Linglong Qian",
      "Wei Cao",
      "Keli Zhang",
      "Wenjia Wang",
      "Yuxuan Liang",
      "Qingsong Wen"
    ],
    "abstract": "Missing values are ubiquitous in multivariate time series (MTS) data, posing\nsignificant challenges for accurate analysis and downstream applications. In\nrecent years, deep learning-based methods have successfully handled missing\ndata by leveraging complex temporal dependencies and learned data\ndistributions. In this survey, we provide a comprehensive summary of deep\nlearning approaches for multivariate time series imputation (MTSI) tasks. We\npropose a novel taxonomy that categorizes existing methods based on two key\nperspectives: imputation uncertainty and neural network architecture.\nFurthermore, we summarize existing MTSI toolkits with a particular emphasis on\nthe PyPOTS Ecosystem, which provides an integrated and standardized foundation\nfor MTSI research. Finally, we discuss key challenges and future research\ndirections, which give insight for further MTSI research. This survey aims to\nserve as a valuable resource for researchers and practitioners in the field of\ntime series analysis and missing data imputation tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2402.04059v2",
    "published_date": "2024-02-06 15:03:53 UTC",
    "updated_date": "2025-02-12 13:16:29 UTC"
  },
  {
    "arxiv_id": "2402.04050v2",
    "title": "Connecting the Dots: Collaborative Fine-tuning for Black-Box Vision-Language Models",
    "authors": [
      "Zhengbo Wang",
      "Jian Liang",
      "Ran He",
      "Zilei Wang",
      "Tieniu Tan"
    ],
    "abstract": "With the emergence of pretrained vision-language models (VLMs), considerable\nefforts have been devoted to fine-tuning them for downstream tasks. Despite the\nprogress made in designing efficient fine-tuning methods, such methods require\naccess to the model's parameters, which can be challenging as model owners\noften opt to provide their models as a black box to safeguard model ownership.\nThis paper proposes a \\textbf{C}ollabo\\textbf{ra}tive\n\\textbf{F}ine-\\textbf{T}uning (\\textbf{CraFT}) approach for fine-tuning\nblack-box VLMs to downstream tasks, where one only has access to the input\nprompts and the output predictions of the model. CraFT comprises two modules, a\nprompt generation module for learning text prompts and a prediction refinement\nmodule for enhancing output predictions in residual style. Additionally, we\nintroduce an auxiliary prediction-consistent loss to promote consistent\noptimization across these modules. These modules are optimized by a novel\ncollaborative training algorithm. Extensive experiments on few-shot\nclassification over 15 datasets demonstrate the superiority of CraFT. The\nresults show that CraFT achieves a decent gain of about 12\\% with 16-shot\ndatasets and only 8,000 queries. Moreover, CraFT trains faster and uses only\nabout 1/80 of the memory footprint for deployment, while sacrificing only\n1.62\\% compared to the white-box method. Our code is publicly available at\nhttps://github.com/mrflogs/CraFT .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04050v2",
    "published_date": "2024-02-06 14:53:19 UTC",
    "updated_date": "2024-06-03 13:22:12 UTC"
  },
  {
    "arxiv_id": "2402.04049v3",
    "title": "Systematic Biases in LLM Simulations of Debates",
    "authors": [
      "Amir Taubenfeld",
      "Yaniv Dover",
      "Roi Reichart",
      "Ariel Goldstein"
    ],
    "abstract": "The emergence of Large Language Models (LLMs), has opened exciting\npossibilities for constructing computational simulations designed to replicate\nhuman behavior accurately. Current research suggests that LLM-based agents\nbecome increasingly human-like in their performance, sparking interest in using\nthese AI agents as substitutes for human participants in behavioral studies.\nHowever, LLMs are complex statistical learners without straightforward\ndeductive rules, making them prone to unexpected behaviors. Hence, it is\ncrucial to study and pinpoint the key behavioral distinctions between humans\nand LLM-based agents. In this study, we highlight the limitations of LLMs in\nsimulating human interactions, particularly focusing on LLMs' ability to\nsimulate political debates on topics that are important aspects of people's\nday-to-day lives and decision-making processes. Our findings indicate a\ntendency for LLM agents to conform to the model's inherent social biases\ndespite being directed to debate from certain political perspectives. This\ntendency results in behavioral patterns that seem to deviate from\nwell-established social dynamics among humans. We reinforce these observations\nusing an automatic self-fine-tuning method, which enables us to manipulate the\nbiases within the LLM and demonstrate that agents subsequently align with the\naltered biases. These results underscore the need for further research to\ndevelop methods that help agents overcome these biases, a critical step toward\ncreating more realistic simulations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published as a conference paper at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04049v3",
    "published_date": "2024-02-06 14:51:55 UTC",
    "updated_date": "2024-12-17 17:17:21 UTC"
  },
  {
    "arxiv_id": "2402.04046v2",
    "title": "Reviving Life on the Edge: Joint Score-Based Graph Generation of Rich Edge Attributes",
    "authors": [
      "Nimrod Berman",
      "Eitan Kosman",
      "Dotan Di Castro",
      "Omri Azencot"
    ],
    "abstract": "Graph generation is integral to various engineering and scientific\ndisciplines. Nevertheless, existing methodologies tend to overlook the\ngeneration of edge attributes. However, we identify critical applications where\nedge attributes are essential, making prior methods potentially unsuitable in\nsuch contexts. Moreover, while trivial adaptations are available, empirical\ninvestigations reveal their limited efficacy as they do not properly model the\ninterplay among graph components. To address this, we propose a joint\nscore-based model of nodes and edges for graph generation that considers all\ngraph components. Our approach offers three key novelties: \\textbf{(1)} node\nand edge attributes are combined in an attention module that generates samples\nbased on the two ingredients, \\textbf{(2)} node, edge and adjacency information\nare mutually dependent during the graph diffusion process, and \\textbf{(3)} the\nframework enables the generation of graphs with rich attributes along the\nedges, providing a more expressive formulation for generative tasks than\nexisting works. We evaluate our method on challenging benchmarks involving\nreal-world and synthetic datasets in which edge features are crucial.\nAdditionally, we introduce a new synthetic dataset that incorporates edge\nvalues. Furthermore, we propose a novel application that greatly benefits from\nthe method due to its nature: the generation of traffic scenes represented as\ngraphs. Our method outperforms other graph generation methods, demonstrating a\nsignificant advantage in edge-related measures.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04046v2",
    "published_date": "2024-02-06 14:48:34 UTC",
    "updated_date": "2024-12-26 13:57:25 UTC"
  },
  {
    "arxiv_id": "2402.06664v3",
    "title": "LLM Agents can Autonomously Hack Websites",
    "authors": [
      "Richard Fang",
      "Rohan Bindu",
      "Akul Gupta",
      "Qiusi Zhan",
      "Daniel Kang"
    ],
    "abstract": "In recent years, large language models (LLMs) have become increasingly\ncapable and can now interact with tools (i.e., call functions), read documents,\nand recursively call themselves. As a result, these LLMs can now function\nautonomously as agents. With the rise in capabilities of these agents, recent\nwork has speculated on how LLM agents would affect cybersecurity. However, not\nmuch is known about the offensive capabilities of LLM agents.\n  In this work, we show that LLM agents can autonomously hack websites,\nperforming tasks as complex as blind database schema extraction and SQL\ninjections without human feedback. Importantly, the agent does not need to know\nthe vulnerability beforehand. This capability is uniquely enabled by frontier\nmodels that are highly capable of tool use and leveraging extended context.\nNamely, we show that GPT-4 is capable of such hacks, but existing open-source\nmodels are not. Finally, we show that GPT-4 is capable of autonomously finding\nvulnerabilities in websites in the wild. Our findings raise questions about the\nwidespread deployment of LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06664v3",
    "published_date": "2024-02-06 14:46:08 UTC",
    "updated_date": "2024-02-16 04:02:51 UTC"
  },
  {
    "arxiv_id": "2402.04032v5",
    "title": "ProactivePIM: Accelerating Weight-Sharing Embedding Layer with PIM for Scalable Recommendation System",
    "authors": [
      "Youngsuk Kim",
      "Junghwan Lim",
      "Hyuk-Jae Lee",
      "Chae Eun Rhee"
    ],
    "abstract": "The model size growth of personalized recommendation systems poses new\nchallenges for inference. Weight-sharing algorithms have been proposed for size\nreduction, but they increase memory access. Recent advancements in\nprocessing-in-memory (PIM) enhanced the model throughput by exploiting memory\nparallelism, but such algorithms introduce massive CPU-PIM communication into\nprior PIM systems. We propose ProactivePIM, a PIM system for weight-sharing\nrecommendation system acceleration. ProactivePIM integrates a cache within the\nPIM with a prefetching scheme to leverage a unique locality of the algorithm\nand eliminate communication overhead through a subtable mapping strategy.\nProactivePIM achieves a 4.8x speedup compared to prior works.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "8 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.04032v5",
    "published_date": "2024-02-06 14:26:22 UTC",
    "updated_date": "2024-11-21 05:55:43 UTC"
  },
  {
    "arxiv_id": "2402.04028v1",
    "title": "AlbNews: A Corpus of Headlines for Topic Modeling in Albanian",
    "authors": [
      "Erion Çano",
      "Dario Lamaj"
    ],
    "abstract": "The scarcity of available text corpora for low-resource languages like\nAlbanian is a serious hurdle for research in natural language processing tasks.\nThis paper introduces AlbNews, a collection of 600 topically labeled news\nheadlines and 2600 unlabeled ones in Albanian. The data can be freely used for\nconducting topic modeling research. We report the initial classification scores\nof some traditional machine learning classifiers trained with the AlbNews\nsamples. These results show that basic models outrun the ensemble learning ones\nand can serve as a baseline for future experiments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04028v1",
    "published_date": "2024-02-06 14:24:28 UTC",
    "updated_date": "2024-02-06 14:24:28 UTC"
  },
  {
    "arxiv_id": "2403.18831v1",
    "title": "DeepTraderX: Challenging Conventional Trading Strategies with Deep Learning in Multi-Threaded Market Simulations",
    "authors": [
      "Armand Mihai Cismaru"
    ],
    "abstract": "In this paper, we introduce DeepTraderX (DTX), a simple Deep Learning-based\ntrader, and present results that demonstrate its performance in a\nmulti-threaded market simulation. In a total of about 500 simulated market\ndays, DTX has learned solely by watching the prices that other strategies\nproduce. By doing this, it has successfully created a mapping from market data\nto quotes, either bid or ask orders, to place for an asset. Trained on\nhistorical Level-2 market data, i.e., the Limit Order Book (LOB) for specific\ntradable assets, DTX processes the market state $S$ at each timestep $T$ to\ndetermine a price $P$ for market orders. The market data used in both training\nand testing was generated from unique market schedules based on real historic\nstock market data. DTX was tested extensively against the best strategies in\nthe literature, with its results validated by statistical analysis. Our\nfindings underscore DTX's capability to rival, and in many instances, surpass,\nthe performance of public-domain traders, including those that outclass human\ntraders, emphasising the efficiency of simple models, as this is required to\nsucceed in intricate multi-threaded simulations. This highlights the potential\nof leveraging \"black-box\" Deep Learning systems to create more efficient\nfinancial markets.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "I.2.6; J.1"
    ],
    "primary_category": "q-fin.TR",
    "comment": "11 pages, 9 png figures, uses apalike.sty and SCITEPRESS.sty, to be\n  published in the proceedings of ICAART 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.18831v1",
    "published_date": "2024-02-06 14:20:51 UTC",
    "updated_date": "2024-02-06 14:20:51 UTC"
  },
  {
    "arxiv_id": "2402.04009v1",
    "title": "Low-rank Attention Side-Tuning for Parameter-Efficient Fine-Tuning",
    "authors": [
      "Ningyuan Tang",
      "Minghao Fu",
      "Ke Zhu",
      "Jianxin Wu"
    ],
    "abstract": "In finetuning a large pretrained model to downstream tasks,\nparameter-efficient fine-tuning (PEFT) methods can effectively finetune\npretrained models with few trainable parameters, but suffer from high GPU\nmemory consumption and slow training speed. Because learnable parameters from\nthese methods are entangled with the pretrained model, gradients related to the\nfrozen pretrained model's parameters have to be computed and stored during\nfinetuning. We propose Low-rank Attention Side-Tuning (LAST), which\ndisentangles the trainable module from the pretrained model by freezing not\nonly parameters but also outputs of the pretrained network. LAST trains a\nside-network composed of only low-rank self-attention modules. By viewing the\npretrained model as a frozen feature extractor, the side-network takes\nintermediate output from the pretrained model and focus on learning\ntask-specific knowledge. We also show that LAST can be highly parallel across\nmultiple optimization objectives, making it very efficient in downstream task\nadaptation, for example, in finding optimal hyperparameters. LAST outperforms\nprevious state-of-the-art methods on VTAB-1K and other visual adaptation tasks\nwith roughly only 30\\% of GPU memory footprint and 60\\% of training time\ncompared to existing PEFT methods, but achieves significantly higher accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04009v1",
    "published_date": "2024-02-06 14:03:15 UTC",
    "updated_date": "2024-02-06 14:03:15 UTC"
  },
  {
    "arxiv_id": "2403.08808v1",
    "title": "A Bionic Data-driven Approach for Long-distance Underwater Navigation with Anomaly Resistance",
    "authors": [
      "Songnan Yang",
      "Xiaohui Zhang",
      "Shiliang Zhang",
      "Xuehui Ma",
      "Wenqi Bai",
      "Yushuai Li",
      "Tingwen Huang"
    ],
    "abstract": "Various animals exhibit accurate navigation using environment cues. The\nEarth's magnetic field has been proved a reliable information source in\nlong-distance fauna migration. Inspired by animal navigation, this work\nproposes a bionic and data-driven approach for long-distance underwater\nnavigation. The proposed approach uses measured geomagnetic data for the\nnavigation, and requires no GPS systems or geographical maps. Particularly, we\nconstruct and train a Temporal Attention-based Long Short-Term Memory (TA-LSTM)\nnetwork to predict the heading angle during the navigation. To mitigate the\nimpact of geomagnetic anomalies, we develop the mechanism to detect and\nquantify the anomalies based on Maximum Likelihood Estimation. We integrate the\ndeveloped mechanism with the TA-LSTM, and calibrate the predicted heading\nangles to gain resistance against geomagnetic anomalies. Using the retrieved\ndata from the WMM model, we conduct numerical simulations with diversified\nnavigation conditions to test our approach. The simulation results demonstrate\na resilience navigation against geomagnetic anomalies by our approach, along\nwith precision and stability of the underwater navigation in single and\nmultiple destination missions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08808v1",
    "published_date": "2024-02-06 13:20:56 UTC",
    "updated_date": "2024-02-06 13:20:56 UTC"
  },
  {
    "arxiv_id": "2402.16874v1",
    "title": "Enhancing Retrieval Processes for Language Generation with Augmented Queries",
    "authors": [
      "Julien Pierre Edmond Ghali",
      "Kosuke Shima",
      "Koichi Moriyama",
      "Atsuko Mutoh",
      "Nobuhiro Inuzuka"
    ],
    "abstract": "In the rapidly changing world of smart technology, searching for documents\nhas become more challenging due to the rise of advanced language models. These\nmodels sometimes face difficulties, like providing inaccurate information,\ncommonly known as \"hallucination.\" This research focuses on addressing this\nissue through Retrieval-Augmented Generation (RAG), a technique that guides\nmodels to give accurate responses based on real facts. To overcome scalability\nissues, the study explores connecting user queries with sophisticated language\nmodels such as BERT and Orca2, using an innovative query optimization process.\nThe study unfolds in three scenarios: first, without RAG, second, without\nadditional assistance, and finally, with extra help. Choosing the compact yet\nefficient Orca2 7B model demonstrates a smart use of computing resources. The\nempirical results indicate a significant improvement in the initial language\nmodel's performance under RAG, particularly when assisted with prompts\naugmenters. Consistency in document retrieval across different encodings\nhighlights the effectiveness of using language model-generated queries. The\nintroduction of UMAP for BERT further simplifies document retrieval while\nmaintaining strong results.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "28 pages, 10 annexes, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.16874v1",
    "published_date": "2024-02-06 13:19:53 UTC",
    "updated_date": "2024-02-06 13:19:53 UTC"
  },
  {
    "arxiv_id": "2402.03972v1",
    "title": "Joint Intrinsic Motivation for Coordinated Exploration in Multi-Agent Deep Reinforcement Learning",
    "authors": [
      "Maxime Toquebiau",
      "Nicolas Bredeche",
      "Faïz Benamar",
      "Jae-Yun Jun"
    ],
    "abstract": "Multi-agent deep reinforcement learning (MADRL) problems often encounter the\nchallenge of sparse rewards. This challenge becomes even more pronounced when\ncoordination among agents is necessary. As performance depends not only on one\nagent's behavior but rather on the joint behavior of multiple agents, finding\nan adequate solution becomes significantly harder. In this context, a group of\nagents can benefit from actively exploring different joint strategies in order\nto determine the most efficient one. In this paper, we propose an approach for\nrewarding strategies where agents collectively exhibit novel behaviors. We\npresent JIM (Joint Intrinsic Motivation), a multi-agent intrinsic motivation\nmethod that follows the centralized learning with decentralized execution\nparadigm. JIM rewards joint trajectories based on a centralized measure of\nnovelty designed to function in continuous environments. We demonstrate the\nstrengths of this approach both in a synthetic environment designed to reveal\nshortcomings of state-of-the-art MADRL methods, and in simulated robotic tasks.\nResults show that joint exploration is crucial for solving tasks where the\noptimal strategy requires a high level of coordination.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "13 pages, 13 figures. Published as an extended abstract at AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03972v1",
    "published_date": "2024-02-06 13:02:00 UTC",
    "updated_date": "2024-02-06 13:02:00 UTC"
  },
  {
    "arxiv_id": "2402.03970v2",
    "title": "Is Deep Learning finally better than Decision Trees on Tabular Data?",
    "authors": [
      "Guri Zabërgja",
      "Arlind Kadra",
      "Christian M. M. Frey",
      "Josif Grabocka"
    ],
    "abstract": "Tabular data is a ubiquitous data modality due to its versatility and ease of\nuse in many real-world applications. The predominant heuristics for handling\nclassification tasks on tabular data rely on classical machine learning\ntechniques, as the superiority of deep learning models has not yet been\ndemonstrated. This raises the question of whether new deep learning paradigms\ncan surpass classical approaches. Recent studies on tabular data offer a unique\nperspective on the limitations of neural networks in this domain and highlight\nthe superiority of gradient boosted decision trees (GBDTs) in terms of\nscalability and robustness across various datasets. However, novel foundation\nmodels have not been thoroughly assessed regarding quality or fairly compared\nto existing methods for tabular classification. Our study categorizes ten\nstate-of-the-art neural models based on their underlying learning paradigm,\ndemonstrating specifically that meta-learned foundation models outperform GBDTs\nin small data regimes. Although dataset-specific neural networks generally\noutperform LLM-based tabular classifiers, they are surpassed by an AutoML\nlibrary which exhibits the best performance but at the cost of higher\ncomputational demands.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03970v2",
    "published_date": "2024-02-06 12:59:02 UTC",
    "updated_date": "2025-02-14 14:37:07 UTC"
  },
  {
    "arxiv_id": "2402.03962v3",
    "title": "Position: Stop Making Unscientific AGI Performance Claims",
    "authors": [
      "Patrick Altmeyer",
      "Andrew M. Demetriou",
      "Antony Bartlett",
      "Cynthia C. S. Liem"
    ],
    "abstract": "Developments in the field of Artificial Intelligence (AI), and particularly\nlarge language models (LLMs), have created a 'perfect storm' for observing\n'sparks' of Artificial General Intelligence (AGI) that are spurious. Like\nsimpler models, LLMs distill meaningful representations in their latent\nembeddings that have been shown to correlate with external variables.\nNonetheless, the correlation of such representations has often been linked to\nhuman-like intelligence in the latter but not the former. We probe models of\nvarying complexity including random projections, matrix decompositions, deep\nautoencoders and transformers: all of them successfully distill information\nthat can be used to predict latent or external variables and yet none of them\nhave previously been linked to AGI. We argue and empirically demonstrate that\nthe finding of meaningful patterns in latent spaces of models cannot be seen as\nevidence in favor of AGI. Additionally, we review literature from the social\nsciences that shows that humans are prone to seek such patterns and\nanthropomorphize. We conclude that both the methodological setup and common\npublic image of AI are ideal for the misinterpretation that correlations\nbetween model representations and some variables of interest are 'caused' by\nthe model's understanding of underlying 'ground truth' relationships. We,\ntherefore, call for the academic community to exercise extra caution, and to be\nkeenly aware of principles of academic integrity, in interpreting and\ncommunicating about AI research outcomes.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 15 figures. Pre-print to be published at International\n  Conference on Machine Learning (ICML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03962v3",
    "published_date": "2024-02-06 12:42:21 UTC",
    "updated_date": "2024-05-31 15:16:21 UTC"
  },
  {
    "arxiv_id": "2402.03951v1",
    "title": "Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping",
    "authors": [
      "Qinliang Lin",
      "Cheng Luo",
      "Zenghao Niu",
      "Xilin He",
      "Weicheng Xie",
      "Yuanbo Hou",
      "Linlin Shen",
      "Siyang Song"
    ],
    "abstract": "Adversarial examples generated by a surrogate model typically exhibit limited\ntransferability to unknown target systems. To address this problem, many\ntransferability enhancement approaches (e.g., input transformation and model\naugmentation) have been proposed. However, they show poor performances in\nattacking systems having different model genera from the surrogate model. In\nthis paper, we propose a novel and generic attacking strategy, called\nDeformation-Constrained Warping Attack (DeCoWA), that can be effectively\napplied to cross model genus attack. Specifically, DeCoWA firstly augments\ninput examples via an elastic deformation, namely Deformation-Constrained\nWarping (DeCoW), to obtain rich local details of the augmented input. To avoid\nsevere distortion of global semantics led by random deformation, DeCoW further\nconstrains the strength and direction of the warping transformation by a novel\nadaptive control strategy. Extensive experiments demonstrate that the\ntransferable examples crafted by our DeCoWA on CNN surrogates can significantly\nhinder the performance of Transformers (and vice versa) on various tasks,\nincluding image classification, video action recognition, and audio\nrecognition. Code is made available at https://github.com/LinQinLiang/DeCoWA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03951v1",
    "published_date": "2024-02-06 12:23:14 UTC",
    "updated_date": "2024-02-06 12:23:14 UTC"
  },
  {
    "arxiv_id": "2402.03941v2",
    "title": "Discovery of the Hidden World with Large Language Models",
    "authors": [
      "Chenxi Liu",
      "Yongqiang Chen",
      "Tongliang Liu",
      "Mingming Gong",
      "James Cheng",
      "Bo Han",
      "Kun Zhang"
    ],
    "abstract": "Revealing the underlying causal mechanisms in the real world is the key to\nthe development of science. Despite the progress in the past decades,\ntraditional causal discovery approaches (CDs) mainly rely on high-quality\nmeasured variables, usually given by human experts, to find causal relations.\nThe lack of well-defined high-level variables in many real-world applications\nhas already been a longstanding roadblock to a broader application of CDs. To\nthis end, this paper presents Causal representatiOn AssistanT (COAT) that\nintroduces large language models (LLMs) to bridge the gap. LLMs are trained on\nmassive observations of the world and have demonstrated great capability in\nextracting key information from unstructured data. Therefore, it is natural to\nemploy LLMs to assist with proposing useful high-level factors and crafting\ntheir measurements. Meanwhile, COAT also adopts CDs to find causal relations\namong the identified variables as well as to provide feedback to LLMs to\niteratively refine the proposed factors. We show that LLMs and CDs are mutually\nbeneficial and the constructed feedback provably also helps with the factor\nproposal. We construct and curate several synthetic and real-world benchmarks\nincluding analysis of human reviews and diagnosis of neuropathic and brain\ntumors, to comprehensively evaluate COAT. Extensive empirical results confirm\nthe effectiveness and reliability of COAT with significant improvements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024; Chenxi and Yongqiang contributed equally; 59 pages, 72\n  figures; Project page: https://causalcoat.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2402.03941v2",
    "published_date": "2024-02-06 12:18:54 UTC",
    "updated_date": "2024-10-31 12:27:30 UTC"
  },
  {
    "arxiv_id": "2403.00765v1",
    "title": "An Architecture for Unattended Containerized (Deep) Reinforcement Learning with Webots",
    "authors": [
      "Tobias Haubold",
      "Petra Linke"
    ],
    "abstract": "As data science applications gain adoption across industries, the tooling\nlandscape matures to facilitate the life cycle of such applications and provide\nsolutions to the challenges involved to boost the productivity of the people\ninvolved. Reinforcement learning with agents in a 3D world could still face\nchallenges: the knowledge required to use a simulation software as well as the\nutilization of a standalone simulation software in unattended training\npipelines.\n  In this paper we review tools and approaches to train reinforcement learning\nagents for robots in 3D worlds with respect to the robot Robotino and argue\nthat the separation of the simulation environment for creators of virtual\nworlds and the model development environment for data scientists is not a well\ncovered topic. Often both are the same and data scientists require knowledge of\nthe simulation software to work directly with their APIs. Moreover, sometimes\ncreators of virtual worlds and data scientists even work on the same files. We\nwant to contribute to that topic by describing an approach where data\nscientists don't require knowledge about the simulation software. Our approach\nuses the standalone simulation software Webots, the Robot Operating System to\ncommunicate with simulated robots as well as the simulation software itself and\ncontainer technology to separate the simulation from the model development\nenvironment. We put emphasize on the APIs the data scientists work with and the\nuse of a standalone simulation software in unattended training pipelines. We\nshow the parts that are specific to the Robotino and the robot task to learn.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "D.2.11"
    ],
    "primary_category": "cs.RO",
    "comment": "Latex with llncs.cls, 17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00765v1",
    "published_date": "2024-02-06 12:08:01 UTC",
    "updated_date": "2024-02-06 12:08:01 UTC"
  },
  {
    "arxiv_id": "2402.03927v2",
    "title": "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs",
    "authors": [
      "Simone Balloccu",
      "Patrícia Schmidtová",
      "Mateusz Lango",
      "Ondřej Dušek"
    ],
    "abstract": "Natural Language Processing (NLP) research is increasingly focusing on the\nuse of Large Language Models (LLMs), with some of the most popular ones being\neither fully or partially closed-source. The lack of access to model details,\nespecially regarding training data, has repeatedly raised concerns about data\ncontamination among researchers. Several attempts have been made to address\nthis issue, but they are limited to anecdotal evidence and trial and error.\nAdditionally, they overlook the problem of \\emph{indirect} data leaking, where\nmodels are iteratively improved by using data coming from users. In this work,\nwe conduct the first systematic analysis of work using OpenAI's GPT-3.5 and\nGPT-4, the most prominently used LLMs today, in the context of data\ncontamination. By analysing 255 papers and considering OpenAI's data usage\npolicy, we extensively document the amount of data leaked to these models\nduring the first year after the model's release. We report that these models\nhave been globally exposed to $\\sim$4.7M samples from 263 benchmarks. At the\nsame time, we document a number of evaluation malpractices emerging in the\nreviewed papers, such as unfair or missing baseline comparisons and\nreproducibility issues. We release our results as a collaborative project on\nhttps://leak-llm.github.io/, where other researchers can contribute to our\nefforts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EACL 2024 - main conference",
    "pdf_url": "http://arxiv.org/pdf/2402.03927v2",
    "published_date": "2024-02-06 11:54:23 UTC",
    "updated_date": "2024-02-22 12:32:24 UTC"
  },
  {
    "arxiv_id": "2403.08807v1",
    "title": "Effective anytime algorithm for multiobjective combinatorial optimization problems",
    "authors": [
      "Miguel Ángel Domínguez-Ríos",
      "Francisco Chicano",
      "Enrique Alba"
    ],
    "abstract": "In multiobjective optimization, the result of an optimization algorithm is a\nset of efficient solutions from which the decision maker selects one. It is\ncommon that not all the efficient solutions can be computed in a short time and\nthe search algorithm has to be stopped prematurely to analyze the solutions\nfound so far. A set of efficient solutions that are well-spread in the\nobjective space is preferred to provide the decision maker with a great variety\nof solutions. However, just a few exact algorithms in the literature exist with\nthe ability to provide such a well-spread set of solutions at any moment: we\ncall them anytime algorithms. We propose a new exact anytime algorithm for\nmultiobjective combinatorial optimization combining three novel ideas to\nenhance the anytime behavior. We compare the proposed algorithm with those in\nthe state-of-the-art for anytime multiobjective combinatorial optimization\nusing a set of 480 instances from different well-known benchmarks and four\ndifferent performance measures: the overall non-dominated vector generation\nratio, the hypervolume, the general spread and the additive epsilon indicator.\nA comprehensive experimental study reveals that our proposal outperforms the\nprevious algorithms in most of the instances.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08807v1",
    "published_date": "2024-02-06 11:53:44 UTC",
    "updated_date": "2024-02-06 11:53:44 UTC"
  },
  {
    "arxiv_id": "2402.03921v2",
    "title": "Large Language Models to Enhance Bayesian Optimization",
    "authors": [
      "Tennison Liu",
      "Nicolás Astorga",
      "Nabeel Seedat",
      "Mihaela van der Schaar"
    ],
    "abstract": "Bayesian optimization (BO) is a powerful approach for optimizing complex and\nexpensive-to-evaluate black-box functions. Its importance is underscored in\nmany applications, notably including hyperparameter tuning, but its efficacy\ndepends on efficiently balancing exploration and exploitation. While there has\nbeen substantial progress in BO methods, striking this balance remains a\ndelicate process. In this light, we present LLAMBO, a novel approach that\nintegrates the capabilities of Large Language Models (LLM) within BO. At a high\nlevel, we frame the BO problem in natural language, enabling LLMs to\niteratively propose and evaluate promising solutions conditioned on historical\nevaluations. More specifically, we explore how combining contextual\nunderstanding, few-shot learning proficiency, and domain knowledge of LLMs can\nimprove model-based BO. Our findings illustrate that LLAMBO is effective at\nzero-shot warmstarting, and enhances surrogate modeling and candidate sampling,\nespecially in the early stages of search when observations are sparse. Our\napproach is performed in context and does not require LLM finetuning.\nAdditionally, it is modular by design, allowing individual components to be\nintegrated into existing BO frameworks, or function cohesively as an end-to-end\nmethod. We empirically validate LLAMBO's efficacy on the problem of\nhyperparameter tuning, highlighting strong empirical performance across a range\nof diverse benchmarks, proprietary, and synthetic tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as Poster at ICLR2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03921v2",
    "published_date": "2024-02-06 11:44:06 UTC",
    "updated_date": "2024-03-08 12:23:56 UTC"
  },
  {
    "arxiv_id": "2402.05135v1",
    "title": "CADReN: Contextual Anchor-Driven Relational Network for Controllable Cross-Graphs Node Importance Estimation",
    "authors": [
      "Zijie Zhong",
      "Yunhui Zhang",
      "Ziyi Chang",
      "Zengchang Qin"
    ],
    "abstract": "Node Importance Estimation (NIE) is crucial for integrating external\ninformation into Large Language Models through Retriever-Augmented Generation.\nTraditional methods, focusing on static, single-graph characteristics, lack\nadaptability to new graphs and user-specific requirements. CADReN, our proposed\nmethod, addresses these limitations by introducing a Contextual Anchor (CA)\nmechanism. This approach enables the network to assess node importance relative\nto the CA, considering both structural and semantic features within Knowledge\nGraphs (KGs). Extensive experiments show that CADReN achieves better\nperformance in cross-graph NIE task, with zero-shot prediction ability. CADReN\nis also proven to match the performance of previous models on single-graph NIE\ntask. Additionally, we introduce and opensource two new datasets, RIC200 and\nWK1K, specifically designed for cross-graph NIE research, providing a valuable\nresource for future developments in this domain.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "68T07"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.05135v1",
    "published_date": "2024-02-06 11:29:44 UTC",
    "updated_date": "2024-02-06 11:29:44 UTC"
  },
  {
    "arxiv_id": "2402.04870v3",
    "title": "Embedding Knowledge Graphs in Degenerate Clifford Algebras",
    "authors": [
      "Louis Mozart Kamdem Teyou",
      "Caglar Demir",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "abstract": "Clifford algebras are a natural generalization of the real numbers, the\ncomplex numbers, and the quaternions. So far, solely Clifford algebras of the\nform $Cl_{p,q}$ (i.e., algebras without nilpotent base vectors) have been\nstudied in the context of knowledge graph embeddings. We propose to consider\nnilpotent base vectors with a nilpotency index of two. In these spaces, denoted\n$Cl_{p,q,r}$, allows generalizing over approaches based on dual numbers (which\ncannot be modelled using $Cl_{p,q}$) and capturing patterns that emanate from\nthe absence of higher-order interactions between real and complex parts of\nentity embeddings. We design two new models for the discovery of the parameters\n$p$, $q$, and $r$. The first model uses a greedy search to optimize $p$, $q$,\nand $r$. The second predicts $(p, q,r)$ based on an embedding of the input\nknowledge graph computed using neural networks. The results of our evaluation\non seven benchmark datasets suggest that nilpotent vectors can help capture\nembeddings better. Our comparison against the state of the art suggests that\nour approach generalizes better than other approaches on all datasets w.r.t.\nthe MRR it achieves on validation data. We also show that a greedy search\nsuffices to discover values of $p$, $q$ and $r$ that are close to optimal.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04870v3",
    "published_date": "2024-02-06 11:23:33 UTC",
    "updated_date": "2024-09-23 09:57:13 UTC"
  },
  {
    "arxiv_id": "2402.03907v2",
    "title": "Embedding Large Language Models into Extended Reality: Opportunities and Challenges for Inclusion, Engagement, and Privacy",
    "authors": [
      "Efe Bozkir",
      "Süleyman Özdel",
      "Ka Hei Carrie Lau",
      "Mengdi Wang",
      "Hong Gao",
      "Enkelejda Kasneci"
    ],
    "abstract": "Advances in artificial intelligence and human-computer interaction will\nlikely lead to extended reality (XR) becoming pervasive. While XR can provide\nusers with interactive, engaging, and immersive experiences, non-player\ncharacters are often utilized in pre-scripted and conventional ways. This paper\nargues for using large language models (LLMs) in XR by embedding them in\navatars or as narratives to facilitate inclusion through prompt engineering and\nfine-tuning the LLMs. We argue that this inclusion will promote diversity for\nXR use. Furthermore, the versatile conversational capabilities of LLMs will\nlikely increase engagement in XR, helping XR become ubiquitous. Lastly, we\nspeculate that combining the information provided to LLM-powered spaces by\nusers and the biometric data obtained might lead to novel privacy invasions.\nWhile exploring potential privacy breaches, examining user privacy concerns and\npreferences is also essential. Therefore, despite challenges, LLM-powered XR is\na promising area with several opportunities.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "ACM Conversational User Interfaces 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03907v2",
    "published_date": "2024-02-06 11:19:40 UTC",
    "updated_date": "2024-06-20 10:02:30 UTC"
  },
  {
    "arxiv_id": "2402.06663v2",
    "title": "Explainable Adversarial Learning Framework on Physical Layer Secret Keys Combating Malicious Reconfigurable Intelligent Surface",
    "authors": [
      "Zhuangkun Wei",
      "Wenxiu Hu",
      "Junqing Zhang",
      "Weisi Guo",
      "Julie McCann"
    ],
    "abstract": "Reconfigurable intelligent surfaces (RIS) can both help and hinder the\nphysical layer secret key generation (PL-SKG) of communications systems. Whilst\na legitimate RIS can yield beneficial impacts, including increased channel\nrandomness to enhance PL-SKG, a malicious RIS can poison legitimate channels\nand crack almost all existing PL-SKGs. In this work, we propose an adversarial\nlearning framework that addresses Man-in-the-middle RIS (MITM-RIS)\neavesdropping which can exist between legitimate parties, namely Alice and Bob.\nFirst, the theoretical mutual information gap between legitimate pairs and\nMITM-RIS is deduced. From this, Alice and Bob leverage adversarial learning to\nlearn a common feature space that assures no mutual information overlap with\nMITM-RIS. Next, to explain the trained legitimate common feature generator, we\naid signal processing interpretation of black-box neural networks using a\nsymbolic explainable AI (xAI) representation. These symbolic terms of dominant\nneurons aid the engineering of feature designs and the validation of the\nlearned common feature space. Simulation results show that our proposed\nadversarial learning- and symbolic-based PL-SKGs can achieve high key agreement\nrates between legitimate users, and is further resistant to an MITM-RIS Eve\nwith the full knowledge of legitimate feature generation (NNs or formulas).\nThis therefore paves the way to secure wireless communications with untrusted\nreflective devices in future 6G.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06663v2",
    "published_date": "2024-02-06 11:19:20 UTC",
    "updated_date": "2024-12-08 22:42:12 UTC"
  },
  {
    "arxiv_id": "2402.03898v2",
    "title": "DistiLLM: Towards Streamlined Distillation for Large Language Models",
    "authors": [
      "Jongwoo Ko",
      "Sungnyun Kim",
      "Tianyi Chen",
      "Se-Young Yun"
    ],
    "abstract": "Knowledge distillation (KD) is widely used for compressing a teacher model to\na smaller student model, reducing its inference cost and memory footprint while\npreserving model capabilities. However, current KD methods for auto-regressive\nsequence models (e.g., large language models) suffer from missing a\nstandardized objective function. Moreover, the recent use of student-generated\noutputs to address training-inference mismatches has significantly escalated\ncomputational costs. To tackle these issues, we introduce DistiLLM, a more\neffective and efficient KD framework for auto-regressive language models.\nDistiLLM comprises two components: (1) a novel skew Kullback-Leibler divergence\nloss, where we unveil and leverage its theoretical properties, and (2) an\nadaptive off-policy approach designed to enhance the efficiency in utilizing\nstudent-generated outputs. Extensive experiments, including\ninstruction-following tasks, demonstrate the effectiveness of DistiLLM in\nbuilding high-performing student models while achieving up to 4.3$\\times$\nspeedup compared to recent KD methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024; Code is available at https://github.com/jongwooko/distillm",
    "pdf_url": "http://arxiv.org/pdf/2402.03898v2",
    "published_date": "2024-02-06 11:10:35 UTC",
    "updated_date": "2024-07-03 04:57:41 UTC"
  },
  {
    "arxiv_id": "2402.03885v3",
    "title": "MOMENT: A Family of Open Time-series Foundation Models",
    "authors": [
      "Mononito Goswami",
      "Konrad Szafer",
      "Arjun Choudhry",
      "Yifu Cai",
      "Shuo Li",
      "Artur Dubrawski"
    ],
    "abstract": "We introduce MOMENT, a family of open-source foundation models for\ngeneral-purpose time series analysis. Pre-training large models on time series\ndata is challenging due to (1) the absence of a large and cohesive public time\nseries repository, and (2) diverse time series characteristics which make\nmulti-dataset training onerous. Additionally, (3) experimental benchmarks to\nevaluate these models, especially in scenarios with limited resources, time,\nand supervision, are still in their nascent stages. To address these\nchallenges, we compile a large and diverse collection of public time series,\ncalled the Time series Pile, and systematically tackle time series-specific\nchallenges to unlock large-scale multi-dataset pre-training. Finally, we build\non recent work to design a benchmark to evaluate time series foundation models\non diverse tasks and datasets in limited supervision settings. Experiments on\nthis benchmark demonstrate the effectiveness of our pre-trained models with\nminimal data and task-specific fine-tuning. Finally, we present several\ninteresting empirical observations about large pre-trained time series models.\nPre-trained models (AutonLab/MOMENT-1-large) and Time Series Pile\n(AutonLab/Timeseries-PILE) are available on Huggingface.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML'24. This is a revision. See changelog in the\n  Appendix",
    "pdf_url": "http://arxiv.org/pdf/2402.03885v3",
    "published_date": "2024-02-06 10:48:46 UTC",
    "updated_date": "2024-10-10 15:37:45 UTC"
  },
  {
    "arxiv_id": "2402.03877v3",
    "title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models",
    "authors": [
      "Spyridon Mouselinos",
      "Henryk Michalewski",
      "Mateusz Malinowski"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in\nmathematical and algorithmic tasks, yet their geometric reasoning skills are\nunderexplored. We investigate LLMs' abilities in constructive geometric\nproblem-solving one of the most fundamental steps in the development of human\nmathematical reasoning. Our work reveals notable challenges that the\nstate-of-the-art LLMs face in this domain despite many successes in similar\nareas. LLMs exhibit biases in target variable selection and struggle with 2D\nspatial relationships, often misrepresenting and hallucinating objects and\ntheir placements. To this end, we introduce a framework that formulates an\nLLMs-based multi-agents system that enhances their existing reasoning potential\nby conducting an internal dialogue. This work underscores LLMs' current\nlimitations in geometric reasoning and improves geometric reasoning\ncapabilities through self-correction, collaboration, and diverse role\nspecializations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03877v3",
    "published_date": "2024-02-06 10:37:21 UTC",
    "updated_date": "2024-09-20 09:17:34 UTC"
  },
  {
    "arxiv_id": "2402.04292v2",
    "title": "AdaFlow: Imitation Learning with Variance-Adaptive Flow-Based Policies",
    "authors": [
      "Xixi Hu",
      "Bo Liu",
      "Xingchao Liu",
      "Qiang Liu"
    ],
    "abstract": "Diffusion-based imitation learning improves Behavioral Cloning (BC) on\nmulti-modal decision-making, but comes at the cost of significantly slower\ninference due to the recursion in the diffusion process. It urges us to design\nefficient policy generators while keeping the ability to generate diverse\nactions. To address this challenge, we propose AdaFlow, an imitation learning\nframework based on flow-based generative modeling. AdaFlow represents the\npolicy with state-conditioned ordinary differential equations (ODEs), which are\nknown as probability flows. We reveal an intriguing connection between the\nconditional variance of their training loss and the discretization error of the\nODEs. With this insight, we propose a variance-adaptive ODE solver that can\nadjust its step size in the inference stage, making AdaFlow an adaptive\ndecision-maker, offering rapid inference without sacrificing diversity.\nInterestingly, it automatically reduces to a one-step generator when the action\ndistribution is uni-modal. Our comprehensive empirical evaluation shows that\nAdaFlow achieves high performance with fast inference speed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeuRIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.04292v2",
    "published_date": "2024-02-06 10:15:38 UTC",
    "updated_date": "2024-11-22 18:11:23 UTC"
  },
  {
    "arxiv_id": "2402.03855v2",
    "title": "Challenges in Mechanistically Interpreting Model Representations",
    "authors": [
      "Satvik Golechha",
      "James Dao"
    ],
    "abstract": "Mechanistic interpretability (MI) aims to understand AI models by\nreverse-engineering the exact algorithms neural networks learn. Most works in\nMI so far have studied behaviors and capabilities that are trivial and\ntoken-aligned. However, most capabilities important for safety and trust are\nnot that trivial, which advocates for the study of hidden representations\ninside these networks as the unit of analysis. We formalize representations for\nfeatures and behaviors, highlight their importance and evaluation, and perform\nan exploratory study of dishonesty representations in\n`Mistral-7B-Instruct-v0.1'. We justify that studying representations is an\nimportant and under-studied field, and highlight several challenges that arise\nwhile attempting to do so through currently established methods in MI, showing\ntheir insufficiency and advocating work on new frameworks for the same.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, ICML 2024 Workshop on Mechanistic Interpretability",
    "pdf_url": "http://arxiv.org/pdf/2402.03855v2",
    "published_date": "2024-02-06 10:06:13 UTC",
    "updated_date": "2024-07-11 18:21:59 UTC"
  },
  {
    "arxiv_id": "2402.03848v10",
    "title": "ANLS* -- A Universal Document Processing Metric for Generative Large Language Models",
    "authors": [
      "David Peer",
      "Philemon Schöpf",
      "Volckmar Nebendahl",
      "Alexander Rietzler",
      "Sebastian Stabinger"
    ],
    "abstract": "Traditionally, discriminative models have been the predominant choice for\ntasks like document classification and information extraction. These models\nmake predictions that fall into a limited number of predefined classes,\nfacilitating a binary true or false evaluation and enabling the direct\ncalculation of metrics such as the F1 score. However, recent advancements in\ngenerative large language models (GLLMs) have prompted a shift in the field due\nto their enhanced zero-shot capabilities, which eliminate the need for a\ndownstream dataset and computationally expensive fine-tuning. However,\nevaluating GLLMs presents a challenge as the binary true or false evaluation\nused for discriminative models is not applicable to the predictions made by\nGLLMs.\n  This paper introduces a new metric for generative models called ANLS* for\nevaluating a wide variety of tasks, including information extraction and\nclassification tasks. The ANLS* metric extends existing ANLS metrics as a\ndrop-in-replacement and is still compatible with previously reported ANLS\nscores. An evaluation of 7 different datasets, and more than 20 different GLLMs\ntogether with 3 different prompting methods using the ANLS* metric is also\nprovided, demonstrating the importance of the proposed metric.\n  We also benchmark a novel approach to generate prompts for documents, called\nSFT, against other prompting techniques such as LATIN. In almost all cases, SFT\noutperforms other techniques and improves the state-of-the-art, sometimes by as\nmuch as $10$ percentage points.\n  Sources are available at https://github.com/deepopinion/anls_star_metric",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03848v10",
    "published_date": "2024-02-06 09:50:08 UTC",
    "updated_date": "2025-04-22 14:11:50 UTC"
  },
  {
    "arxiv_id": "2402.03843v4",
    "title": "A new method for optical steel rope non-destructive damage detection",
    "authors": [
      "Yunqing Bao",
      "Bin Hu"
    ],
    "abstract": "This paper presents a novel algorithm for non-destructive damage detection\nfor steel ropes in high-altitude environments (aerial ropeway). The algorithm\ncomprises two key components: First, a segmentation model named RGBD-UNet is\ndesigned to accurately extract steel ropes from complex backgrounds. This model\nis equipped with the capability to process and combine color and depth\ninformation through the proposed CMA module. Second, a detection model named\nVovNetV3.5 is developed to differentiate between normal and abnormal steel\nropes. It integrates the VovNet architecture with a DBB module to enhance\nperformance. Besides, a novel background augmentation method is proposed to\nenhance the generalization ability of the segmentation model. Datasets\ncontaining images of steel ropes in different scenarios are created for the\ntraining and testing of both the segmentation and detection models. Experiments\ndemonstrate a significant improvement over baseline models. On the proposed\ndataset, the highest accuracy achieved by the detection model reached 0.975,\nand the maximum F-measure achieved by the segmentation model reached 0.948.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03843v4",
    "published_date": "2024-02-06 09:39:05 UTC",
    "updated_date": "2024-09-22 12:30:23 UTC"
  },
  {
    "arxiv_id": "2402.04291v2",
    "title": "BiLLM: Pushing the Limit of Post-Training Quantization for LLMs",
    "authors": [
      "Wei Huang",
      "Yangdong Liu",
      "Haotong Qin",
      "Ying Li",
      "Shiming Zhang",
      "Xianglong Liu",
      "Michele Magno",
      "Xiaojuan Qi"
    ],
    "abstract": "Pretrained large language models (LLMs) exhibit exceptional general language\nprocessing capabilities but come with significant demands on memory and\ncomputational resources. As a powerful compression technology, binarization can\nextremely reduce model weights to a mere 1 bit, lowering the expensive\ncomputation and memory requirements. However, existing quantization techniques\nfall short of maintaining LLM performance under ultra-low bit-widths. In\nresponse to this challenge, we present BiLLM, a groundbreaking 1-bit\npost-training quantization scheme tailored for pretrained LLMs. Based on the\nweight distribution of LLMs, BiLLM first identifies and structurally selects\nsalient weights, and minimizes the compression loss through an effective binary\nresidual approximation strategy. Moreover, considering the bell-shaped\ndistribution of the non-salient weights, we propose an optimal splitting search\nto group and binarize them accurately. BiLLM achieving for the first time\nhigh-accuracy inference (e.g. 8.41 perplexity on LLaMA2-70B) with only 1.08-bit\nweights across various LLMs families and evaluation metrics, outperforms SOTA\nquantization methods of LLM by significant margins. Moreover, BiLLM enables the\nbinarization process of the LLM with 7 billion weights within 0.5 hours on a\nsingle GPU, demonstrating satisfactory time efficiency. Our code is available\nat https://github.com/Aaronhuang-778/BiLLM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.04291v2",
    "published_date": "2024-02-06 09:26:34 UTC",
    "updated_date": "2024-05-15 13:55:12 UTC"
  },
  {
    "arxiv_id": "2402.03824v4",
    "title": "A call for embodied AI",
    "authors": [
      "Giuseppe Paolo",
      "Jonas Gonzalez-Billandon",
      "Balázs Kégl"
    ],
    "abstract": "We propose Embodied AI as the next fundamental step in the pursuit of\nArtificial General Intelligence, juxtaposing it against current AI\nadvancements, particularly Large Language Models. We traverse the evolution of\nthe embodiment concept across diverse fields - philosophy, psychology,\nneuroscience, and robotics - to highlight how EAI distinguishes itself from the\nclassical paradigm of static learning. By broadening the scope of Embodied AI,\nwe introduce a theoretical framework based on cognitive architectures,\nemphasizing perception, action, memory, and learning as essential components of\nan embodied agent. This framework is aligned with Friston's active inference\nprinciple, offering a comprehensive approach to EAI development. Despite the\nprogress made in the field of AI, substantial challenges, such as the\nformulation of a novel AI learning theory and the innovation of advanced\nhardware, persist. Our discussion lays down a foundational guideline for future\nEmbodied AI research. Highlighting the importance of creating Embodied AI\nagents capable of seamless communication, collaboration, and coexistence with\nhumans and other intelligent entities within real-world environments, we aim to\nsteer the AI community towards addressing the multifaceted challenges and\nseizing the opportunities that lie ahead in the quest for AGI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in ICML 2024 Position paper track",
    "pdf_url": "http://arxiv.org/pdf/2402.03824v4",
    "published_date": "2024-02-06 09:11:20 UTC",
    "updated_date": "2024-09-13 13:36:05 UTC"
  },
  {
    "arxiv_id": "2402.03822v2",
    "title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
    "authors": [
      "Si Shen",
      "Peijun Shen",
      "Danhao Zhu"
    ],
    "abstract": "This paper presents RevOrder, a novel technique aimed at improving arithmetic\noperations in large language models (LLMs) by reversing the output digits in\naddition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks.\nOur method significantly reduces the Count of Sequential Intermediate Digits\n(CSID) to $\\mathcal{O}(1)$, a new metric we introduce to assess equation\ncomplexity. Through comprehensive testing, RevOrder not only achieves perfect\naccuracy in basic arithmetic operations but also substantially boosts LLM\nperformance in division tasks, particularly with large numbers where\ntraditional models struggle. Implementation of RevOrder is cost-effective for\nboth training and inference phases. Moreover, applying RevOrder to fine-tune\nthe LLaMA2-7B model on the GSM8K math task results in a considerable\nimprovement, reducing equation calculation errors by 46% and increasing overall\nscores from 41.6 to 44.4.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03822v2",
    "published_date": "2024-02-06 09:10:35 UTC",
    "updated_date": "2024-02-24 01:11:14 UTC"
  },
  {
    "arxiv_id": "2402.03807v2",
    "title": "SEABO: A Simple Search-Based Method for Offline Imitation Learning",
    "authors": [
      "Jiafei Lyu",
      "Xiaoteng Ma",
      "Le Wan",
      "Runze Liu",
      "Xiu Li",
      "Zongqing Lu"
    ],
    "abstract": "Offline reinforcement learning (RL) has attracted much attention due to its\nability in learning from static offline datasets and eliminating the need of\ninteracting with the environment. Nevertheless, the success of offline RL\nrelies heavily on the offline transitions annotated with reward labels. In\npractice, we often need to hand-craft the reward function, which is sometimes\ndifficult, labor-intensive, or inefficient. To tackle this challenge, we set\nour focus on the offline imitation learning (IL) setting, and aim at getting a\nreward function based on the expert data and unlabeled data. To that end, we\npropose a simple yet effective search-based offline IL method, tagged SEABO.\nSEABO allocates a larger reward to the transition that is close to its closest\nneighbor in the expert demonstration, and a smaller reward otherwise, all in an\nunsupervised learning manner. Experimental results on a variety of D4RL\ndatasets indicate that SEABO can achieve competitive performance to offline RL\nalgorithms with ground-truth rewards, given only a single expert trajectory,\nand can outperform prior reward learning and offline IL methods across many\ntasks. Moreover, we demonstrate that SEABO also works well if the expert\ndemonstrations contain only observations. Our code is publicly available at\nhttps://github.com/dmksjfl/SEABO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear in ICLR2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03807v2",
    "published_date": "2024-02-06 08:48:01 UTC",
    "updated_date": "2024-02-21 05:24:37 UTC"
  },
  {
    "arxiv_id": "2402.03804v1",
    "title": "ReLU$^2$ Wins: Discovering Efficient Activation Functions for Sparse LLMs",
    "authors": [
      "Zhengyan Zhang",
      "Yixin Song",
      "Guanghui Yu",
      "Xu Han",
      "Yankai Lin",
      "Chaojun Xiao",
      "Chenyang Song",
      "Zhiyuan Liu",
      "Zeyu Mi",
      "Maosong Sun"
    ],
    "abstract": "Sparse computation offers a compelling solution for the inference of Large\nLanguage Models (LLMs) in low-resource scenarios by dynamically skipping the\ncomputation of inactive neurons. While traditional approaches focus on\nReLU-based LLMs, leveraging zeros in activation values, we broaden the scope of\nsparse LLMs beyond zero activation values. We introduce a general method that\ndefines neuron activation through neuron output magnitudes and a tailored\nmagnitude threshold, demonstrating that non-ReLU LLMs also exhibit sparse\nactivation. To find the most efficient activation function for sparse\ncomputation, we propose a systematic framework to examine the sparsity of LLMs\nfrom three aspects: the trade-off between sparsity and performance, the\npredictivity of sparsity, and the hardware affinity. We conduct thorough\nexperiments on LLMs utilizing different activation functions, including ReLU,\nSwiGLU, ReGLU, and ReLU$^2$. The results indicate that models employing\nReLU$^2$ excel across all three evaluation aspects, highlighting its potential\nas an efficient activation function for sparse LLMs. We will release the code\nto facilitate future research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03804v1",
    "published_date": "2024-02-06 08:45:51 UTC",
    "updated_date": "2024-02-06 08:45:51 UTC"
  },
  {
    "arxiv_id": "2402.04290v1",
    "title": "CasCast: Skillful High-resolution Precipitation Nowcasting via Cascaded Modelling",
    "authors": [
      "Junchao Gong",
      "Lei Bai",
      "Peng Ye",
      "Wanghan Xu",
      "Na Liu",
      "Jianhua Dai",
      "Xiaokang Yang",
      "Wanli Ouyang"
    ],
    "abstract": "Precipitation nowcasting based on radar data plays a crucial role in extreme\nweather prediction and has broad implications for disaster management. Despite\nprogresses have been made based on deep learning, two key challenges of\nprecipitation nowcasting are not well-solved: (i) the modeling of complex\nprecipitation system evolutions with different scales, and (ii) accurate\nforecasts for extreme precipitation. In this work, we propose CasCast, a\ncascaded framework composed of a deterministic and a probabilistic part to\ndecouple the predictions for mesoscale precipitation distributions and\nsmall-scale patterns. Then, we explore training the cascaded framework at the\nhigh resolution and conducting the probabilistic modeling in a low dimensional\nlatent space with a frame-wise-guided diffusion transformer for enhancing the\noptimization of extreme events while reducing computational costs. Extensive\nexperiments on three benchmark radar precipitation datasets show that CasCast\nachieves competitive performance. Especially, CasCast significantly surpasses\nthe baseline (up to +91.8%) for regional extreme-precipitation nowcasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04290v1",
    "published_date": "2024-02-06 08:30:47 UTC",
    "updated_date": "2024-02-06 08:30:47 UTC"
  },
  {
    "arxiv_id": "2402.03796v1",
    "title": "Face Detection: Present State and Research Directions",
    "authors": [
      "Purnendu Prabhat",
      "Himanshu Gupta",
      "Ajeet Kumar Vishwakarma"
    ],
    "abstract": "The majority of computer vision applications that handle images featuring\nhumans use face detection as a core component. Face detection still has issues,\ndespite much research on the topic. Face detection's accuracy and speed might\nyet be increased. This review paper shows the progress made in this area as\nwell as the substantial issues that still need to be tackled. The paper\nprovides research directions that can be taken up as research projects in the\nfield of face detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03796v1",
    "published_date": "2024-02-06 08:29:39 UTC",
    "updated_date": "2024-02-06 08:29:39 UTC"
  },
  {
    "arxiv_id": "2402.03792v1",
    "title": "No-Regret Reinforcement Learning in Smooth MDPs",
    "authors": [
      "Davide Maran",
      "Alberto Maria Metelli",
      "Matteo Papini",
      "Marcello Restell"
    ],
    "abstract": "Obtaining no-regret guarantees for reinforcement learning (RL) in the case of\nproblems with continuous state and/or action spaces is still one of the major\nopen challenges in the field. Recently, a variety of solutions have been\nproposed, but besides very specific settings, the general problem remains\nunsolved. In this paper, we introduce a novel structural assumption on the\nMarkov decision processes (MDPs), namely $\\nu-$smoothness, that generalizes\nmost of the settings proposed so far (e.g., linear MDPs and Lipschitz MDPs). To\nface this challenging scenario, we propose two algorithms for regret\nminimization in $\\nu-$smooth MDPs. Both algorithms build upon the idea of\nconstructing an MDP representation through an orthogonal feature map based on\nLegendre polynomials. The first algorithm, \\textsc{Legendre-Eleanor}, archives\nthe no-regret property under weaker assumptions but is computationally\ninefficient, whereas the second one, \\textsc{Legendre-LSVI}, runs in polynomial\ntime, although for a smaller class of problems. After analyzing their regret\nproperties, we compare our results with state-of-the-art ones from RL theory,\nshowing that our algorithms achieve the best guarantees.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03792v1",
    "published_date": "2024-02-06 08:18:14 UTC",
    "updated_date": "2024-02-06 08:18:14 UTC"
  },
  {
    "arxiv_id": "2402.03784v2",
    "title": "AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction",
    "authors": [
      "Kethmi Hirushini Hettige",
      "Jiahao Ji",
      "Shili Xiang",
      "Cheng Long",
      "Gao Cong",
      "Jingyuan Wang"
    ],
    "abstract": "Air quality prediction and modelling plays a pivotal role in public health\nand environment management, for individuals and authorities to make informed\ndecisions. Although traditional data-driven models have shown promise in this\ndomain, their long-term prediction accuracy can be limited, especially in\nscenarios with sparse or incomplete data and they often rely on black-box deep\nlearning structures that lack solid physical foundation leading to reduced\ntransparency and interpretability in predictions. To address these limitations,\nthis paper presents a novel approach named Physics guided Neural Network for\nAir Quality Prediction (AirPhyNet). Specifically, we leverage two\nwell-established physics principles of air particle movement (diffusion and\nadvection) by representing them as differential equation networks. Then, we\nutilize a graph structure to integrate physics knowledge into a neural network\narchitecture and exploit latent representations to capture spatio-temporal\nrelationships within the air quality data. Experiments on two real-world\nbenchmark datasets demonstrate that AirPhyNet outperforms state-of-the-art\nmodels for different testing scenarios including different lead time (24h, 48h,\n72h), sparse data and sudden change prediction, achieving reduction in\nprediction errors up to 10%. Moreover, a case study further validates that our\nmodel captures underlying physical processes of particle movement and generates\naccurate predictions with real physical meaning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.app-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 12th International Conference on Learning\n  Representations (ICLR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.03784v2",
    "published_date": "2024-02-06 07:55:54 UTC",
    "updated_date": "2024-02-07 02:10:11 UTC"
  },
  {
    "arxiv_id": "2402.03782v1",
    "title": "Soft Prompt Tuning for Cross-Lingual Transfer: When Less is More",
    "authors": [
      "Fred Philippy",
      "Siwen Guo",
      "Shohreh Haddadan",
      "Cedric Lothritz",
      "Jacques Klein",
      "Tegawendé F. Bissyandé"
    ],
    "abstract": "Soft Prompt Tuning (SPT) is a parameter-efficient method for adapting\npre-trained language models (PLMs) to specific tasks by inserting learnable\nembeddings, or soft prompts, at the input layer of the PLM, without modifying\nits parameters. This paper investigates the potential of SPT for cross-lingual\ntransfer. Unlike previous studies on SPT for cross-lingual transfer that often\nfine-tune both the soft prompt and the model parameters, we adhere to the\noriginal intent of SPT by keeping the model parameters frozen and only training\nthe soft prompt. This does not only reduce the computational cost and storage\noverhead of full-model fine-tuning, but we also demonstrate that this very\nparameter efficiency intrinsic to SPT can enhance cross-lingual transfer\nperformance to linguistically distant languages. Moreover, we explore how\ndifferent factors related to the prompt, such as the length or its\nreparameterization, affect cross-lingual transfer performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the 1st Workshop on Modular and Open Multilingual NLP\n  (co-located with EACL 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.03782v1",
    "published_date": "2024-02-06 07:52:30 UTC",
    "updated_date": "2024-02-06 07:52:30 UTC"
  },
  {
    "arxiv_id": "2402.03781v6",
    "title": "MolTC: Towards Molecular Relational Modeling In Language Models",
    "authors": [
      "Junfeng Fang",
      "Shuai Zhang",
      "Chang Wu",
      "Zhengyi Yang",
      "Zhiyuan Liu",
      "Sihang Li",
      "Kun Wang",
      "Wenjie Du",
      "Xiang Wang"
    ],
    "abstract": "Molecular Relational Learning (MRL), aiming to understand interactions\nbetween molecular pairs, plays a pivotal role in advancing biochemical\nresearch. Recently, the adoption of large language models (LLMs), known for\ntheir vast knowledge repositories and advanced logical inference capabilities,\nhas emerged as a promising way for efficient and effective MRL. Despite their\npotential, these methods predominantly rely on the textual data, thus not fully\nharnessing the wealth of structural information inherent in molecular graphs.\nMoreover, the absence of a unified framework exacerbates the issue of\ninformation underutilization, as it hinders the sharing of interaction\nmechanism learned across diverse datasets. To address these challenges, this\nwork proposes a novel LLM-based multi-modal framework for Molecular inTeraction\nprediction following Chain-of-Thought (CoT) theory, termed MolTC, which\neffectively integrate graphical information of two molecules in pair. To train\nMolTC efficiently, we introduce a Multi-hierarchical CoT concept to refine its\ntraining paradigm, and conduct a comprehensive Molecular Interactive\nInstructions dataset for the development of biochemical LLMs involving MRL. Our\nexperiments, conducted across various datasets involving over 4,000,000\nmolecular pairs, exhibit the superiority of our method over current GNN and\nLLM-based baselines. Code is available at https://github.com/MangoKiller/MolTC.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03781v6",
    "published_date": "2024-02-06 07:51:56 UTC",
    "updated_date": "2024-06-10 08:45:51 UTC"
  },
  {
    "arxiv_id": "2402.03780v3",
    "title": "Exposing propaganda: an analysis of stylistic cues comparing human annotations and machine classification",
    "authors": [
      "Géraud Faye",
      "Benjamin Icard",
      "Morgane Casanova",
      "Julien Chanson",
      "François Maine",
      "François Bancilhon",
      "Guillaume Gadek",
      "Guillaume Gravier",
      "Paul Égré"
    ],
    "abstract": "This paper investigates the language of propaganda and its stylistic\nfeatures. It presents the PPN dataset, standing for Propagandist Pseudo-News, a\nmultisource, multilingual, multimodal dataset composed of news articles\nextracted from websites identified as propaganda sources by expert agencies. A\nlimited sample from this set was randomly mixed with papers from the regular\nFrench press, and their URL masked, to conduct an annotation-experiment by\nhumans, using 11 distinct labels. The results show that human annotators were\nable to reliably discriminate between the two types of press across each of the\nlabels. We propose different NLP techniques to identify the cues used by the\nannotators, and to compare them with machine classification. They include the\nanalyzer VAGO to measure discourse vagueness and subjectivity, a TF-IDF to\nserve as a baseline, and four different classifiers: two RoBERTa-based models,\nCATS using syntax, and one XGBoost combining syntactic and semantic features.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper to appear in the EACL 2024 Proceedings of the Third Workshop on\n  Understanding Implicit and Underspecified Language (UnImplicit 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.03780v3",
    "published_date": "2024-02-06 07:51:54 UTC",
    "updated_date": "2024-02-26 14:07:20 UTC"
  },
  {
    "arxiv_id": "2402.03776v4",
    "title": "Large Language Models As MOOCs Graders",
    "authors": [
      "Shahriar Golchin",
      "Nikhil Garuda",
      "Christopher Impey",
      "Matthew Wenger"
    ],
    "abstract": "Massive open online courses (MOOCs) unlock the doors to free education for\nanyone around the globe with access to a computer and the internet. Despite\nthis democratization of learning, the massive enrollment in these courses means\nit is almost impossible for one instructor to assess every student's writing\nassignment. As a result, peer grading, often guided by a straightforward\nrubric, is the method of choice. While convenient, peer grading often falls\nshort in terms of reliability and validity. In this study, using 18 distinct\nsettings, we explore the feasibility of leveraging large language models (LLMs)\nto replace peer grading in MOOCs. Specifically, we focus on two\nstate-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses:\nIntroductory Astronomy, Astrobiology, and the History and Philosophy of\nAstronomy. To instruct LLMs, we use three different prompts based on a variant\nof the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique:\nZero-shot-CoT combined with instructor-provided correct answers; Zero-shot-CoT\nin conjunction with both instructor-formulated answers and rubrics; and\nZero-shot-CoT with instructor-offered correct answers and LLM-generated\nrubrics. Our results show that Zero-shot-CoT, when integrated with\ninstructor-provided answers and rubrics, produces grades that are more aligned\nwith those assigned by instructors compared to peer grading. However, the\nHistory and Philosophy of Astronomy course proves to be more challenging in\nterms of grading as opposed to other courses. Finally, our study reveals a\npromising direction for automating grading systems for MOOCs, especially in\nsubjects with well-defined rubrics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "v1.3 preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.03776v4",
    "published_date": "2024-02-06 07:43:07 UTC",
    "updated_date": "2024-03-01 04:48:41 UTC"
  },
  {
    "arxiv_id": "2402.03774v2",
    "title": "Learning a Decision Tree Algorithm with Transformers",
    "authors": [
      "Yufan Zhuang",
      "Liyuan Liu",
      "Chandan Singh",
      "Jingbo Shang",
      "Jianfeng Gao"
    ],
    "abstract": "Decision trees are renowned for their ability to achieve high predictive\nperformance while remaining interpretable, especially on tabular data.\nTraditionally, they are constructed through recursive algorithms, where they\npartition the data at every node in a tree. However, identifying a good\npartition is challenging, as decision trees optimized for local segments may\nnot yield global generalization. To address this, we introduce MetaTree, a\ntransformer-based model trained via meta-learning to directly produce strong\ndecision trees. Specifically, we fit both greedy decision trees and globally\noptimized decision trees on a large number of datasets, and train MetaTree to\nproduce only the trees that achieve strong generalization performance. This\ntraining enables MetaTree to emulate these algorithms and intelligently adapt\nits strategy according to the context, thereby achieving superior\ngeneralization performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03774v2",
    "published_date": "2024-02-06 07:40:53 UTC",
    "updated_date": "2024-08-23 19:56:36 UTC"
  },
  {
    "arxiv_id": "2402.03766v1",
    "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model",
    "authors": [
      "Xiangxiang Chu",
      "Limeng Qiao",
      "Xinyu Zhang",
      "Shuang Xu",
      "Fei Wei",
      "Yang Yang",
      "Xiaofei Sun",
      "Yiming Hu",
      "Xinyang Lin",
      "Bo Zhang",
      "Chunhua Shen"
    ],
    "abstract": "We introduce MobileVLM V2, a family of significantly improved vision language\nmodels upon MobileVLM, which proves that a delicate orchestration of novel\narchitectural design, an improved training scheme tailored for mobile VLMs, and\nrich high-quality dataset curation can substantially benefit VLMs' performance.\nSpecifically, MobileVLM V2 1.7B achieves better or on-par performance on\nstandard VLM benchmarks compared with much larger VLMs at the 3B scale.\nNotably, our 3B model outperforms a large variety of VLMs at the 7B+ scale. Our\nmodels will be released at https://github.com/Meituan-AutoML/MobileVLM .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03766v1",
    "published_date": "2024-02-06 07:16:36 UTC",
    "updated_date": "2024-02-06 07:16:36 UTC"
  },
  {
    "arxiv_id": "2402.03755v1",
    "title": "QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large Language Model",
    "authors": [
      "Saizhuo Wang",
      "Hang Yuan",
      "Lionel M. Ni",
      "Jian Guo"
    ],
    "abstract": "Autonomous agents based on Large Language Models (LLMs) that devise plans and\ntackle real-world challenges have gained prominence.However, tailoring these\nagents for specialized domains like quantitative investment remains a\nformidable task. The core challenge involves efficiently building and\nintegrating a domain-specific knowledge base for the agent's learning process.\nThis paper introduces a principled framework to address this challenge,\ncomprising a two-layer loop.In the inner loop, the agent refines its responses\nby drawing from its knowledge base, while in the outer loop, these responses\nare tested in real-world scenarios to automatically enhance the knowledge base\nwith new insights.We demonstrate that our approach enables the agent to\nprogressively approximate optimal behavior with provable\nefficiency.Furthermore, we instantiate this framework through an autonomous\nagent for mining trading signals named QuantAgent. Empirical results showcase\nQuantAgent's capability in uncovering viable financial signals and enhancing\nthe accuracy of financial forecasts.",
    "categories": [
      "cs.AI",
      "q-fin.CP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03755v1",
    "published_date": "2024-02-06 06:47:14 UTC",
    "updated_date": "2024-02-06 06:47:14 UTC"
  },
  {
    "arxiv_id": "2402.03750v1",
    "title": "Digital Twin Mobility Profiling: A Spatio-Temporal Graph Learning Approach",
    "authors": [
      "Xin Chen",
      "Mingliang Hou",
      "Tao Tang",
      "Achhardeep Kaur",
      "Feng Xia"
    ],
    "abstract": "With the arrival of the big data era, mobility profiling has become a viable\nmethod of utilizing enormous amounts of mobility data to create an intelligent\ntransportation system. Mobility profiling can extract potential patterns in\nurban traffic from mobility data and is critical for a variety of\ntraffic-related applications. However, due to the high level of complexity and\nthe huge amount of data, mobility profiling faces huge challenges. Digital Twin\n(DT) technology paves the way for cost-effective and performance-optimised\nmanagement by digitally creating a virtual representation of the network to\nsimulate its behaviour. In order to capture the complex spatio-temporal\nfeatures in traffic scenario, we construct alignment diagrams to assist in\ncompleting the spatio-temporal correlation representation and design dilated\nalignment convolution network (DACN) to learn the fine-grained correlations,\ni.e., spatio-temporal interactions. We propose a digital twin mobility\nprofiling (DTMP) framework to learn node profiles on a mobility network DT\nmodel. Extensive experiments have been conducted upon three real-world\ndatasets. Experimental results demonstrate the effectiveness of DTMP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "68T09, 68T30, 68U35",
      "I.2.6; I.2.4; H.1.2"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.03750v1",
    "published_date": "2024-02-06 06:37:43 UTC",
    "updated_date": "2024-02-06 06:37:43 UTC"
  },
  {
    "arxiv_id": "2402.05970v1",
    "title": "Modeling Spatio-temporal Dynamical Systems with Neural Discrete Learning and Levels-of-Experts",
    "authors": [
      "Kun Wang",
      "Hao Wu",
      "Guibin Zhang",
      "Junfeng Fang",
      "Yuxuan Liang",
      "Yuankai Wu",
      "Roger Zimmermann",
      "Yang Wang"
    ],
    "abstract": "In this paper, we address the issue of modeling and estimating changes in the\nstate of the spatio-temporal dynamical systems based on a sequence of\nobservations like video frames. Traditional numerical simulation systems depend\nlargely on the initial settings and correctness of the constructed partial\ndifferential equations (PDEs). Despite recent efforts yielding significant\nsuccess in discovering data-driven PDEs with neural networks, the limitations\nposed by singular scenarios and the absence of local insights prevent them from\nperforming effectively in a broader real-world context. To this end, this paper\npropose the universal expert module -- that is, optical flow estimation\ncomponent, to capture the evolution laws of general physical processes in a\ndata-driven fashion. To enhance local insight, we painstakingly design a\nfiner-grained physical pipeline, since local characteristics may be influenced\nby various internal contextual information, which may contradict the\nmacroscopic properties of the whole system. Further, we harness currently\npopular neural discrete learning to unveil the underlying important features in\nits latent space, this process better injects interpretability, which can help\nus obtain a powerful prior over these discrete random variables. We conduct\nextensive experiments and ablations to demonstrate that the proposed framework\nachieves large performance margins, compared with the existing SOTA baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05970v1",
    "published_date": "2024-02-06 06:27:07 UTC",
    "updated_date": "2024-02-06 06:27:07 UTC"
  },
  {
    "arxiv_id": "2402.03741v3",
    "title": "SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems",
    "authors": [
      "Oubo Ma",
      "Yuwen Pu",
      "Linkang Du",
      "Yang Dai",
      "Ruo Wang",
      "Xiaolei Liu",
      "Yingcai Wu",
      "Shouling Ji"
    ],
    "abstract": "Recent advancements in multi-agent reinforcement learning (MARL) have opened\nup vast application prospects, such as swarm control of drones, collaborative\nmanipulation by robotic arms, and multi-target encirclement. However, potential\nsecurity threats during the MARL deployment need more attention and thorough\ninvestigation. Recent research reveals that attackers can rapidly exploit the\nvictim's vulnerabilities, generating adversarial policies that result in the\nfailure of specific tasks. For instance, reducing the winning rate of a\nsuperhuman-level Go AI to around 20%. Existing studies predominantly focus on\ntwo-player competitive environments, assuming attackers possess complete global\nstate observation.\n  In this study, we unveil, for the first time, the capability of attackers to\ngenerate adversarial policies even when restricted to partial observations of\nthe victims in multi-agent competitive environments. Specifically, we propose a\nnovel black-box attack (SUB-PLAY) that incorporates the concept of constructing\nmultiple subgames to mitigate the impact of partial observability and suggests\nsharing transitions among subpolicies to improve attackers' exploitative\nability. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under\nthree typical partial observability limitations. Visualization results indicate\nthat adversarial policies induce significantly different activations of the\nvictims' policy networks. Furthermore, we evaluate three potential defenses\naimed at exploring ways to mitigate security threats posed by adversarial\npolicies, providing constructive recommendations for deploying MARL in\ncompetitive environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear in the ACM Conference on Computer and Communications\n  Security (CCS'24), October 14-18, 2024, Salt Lake City, UT, USA",
    "pdf_url": "http://arxiv.org/pdf/2402.03741v3",
    "published_date": "2024-02-06 06:18:16 UTC",
    "updated_date": "2024-06-26 12:41:59 UTC"
  },
  {
    "arxiv_id": "2402.03732v1",
    "title": "Deep Outdated Fact Detection in Knowledge Graphs",
    "authors": [
      "Huiling Tu",
      "Shuo Yu",
      "Vidya Saikrishna",
      "Feng Xia",
      "Karin Verspoor"
    ],
    "abstract": "Knowledge graphs (KGs) have garnered significant attention for their vast\npotential across diverse domains. However, the issue of outdated facts poses a\nchallenge to KGs, affecting their overall quality as real-world information\nevolves. Existing solutions for outdated fact detection often rely on manual\nrecognition. In response, this paper presents DEAN (Deep outdatEd fAct\ndetectioN), a novel deep learning-based framework designed to identify outdated\nfacts within KGs. DEAN distinguishes itself by capturing implicit structural\ninformation among facts through comprehensive modeling of both entities and\nrelations. To effectively uncover latent out-of-date information, DEAN employs\na contrastive approach based on a pre-defined Relations-to-Nodes (R2N) graph,\nweighted by the number of entities. Experimental results demonstrate the\neffectiveness and superiority of DEAN over state-of-the-art baseline methods.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DL",
      "cs.LG",
      "68T09, 68T30, 68P20",
      "I.2.6; I.2.4; H.3.7; H.3.3"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.03732v1",
    "published_date": "2024-02-06 05:58:15 UTC",
    "updated_date": "2024-02-06 05:58:15 UTC"
  },
  {
    "arxiv_id": "2402.03728v1",
    "title": "Consistent Joint Decision-Making with Heterogeneous Learning Models",
    "authors": [
      "Hossein Rajaby Faghihi",
      "Parisa Kordjamshidi"
    ],
    "abstract": "This paper introduces a novel decision-making framework that promotes\nconsistency among decisions made by diverse models while utilizing external\nknowledge. Leveraging the Integer Linear Programming (ILP) framework, we map\npredictions from various models into globally normalized and comparable values\nby incorporating information about decisions' prior probability, confidence\n(uncertainty), and the models' expected accuracy. Our empirical study\ndemonstrates the superiority of our approach over conventional baselines on\nmultiple datasets.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "EACL 2024 Findings - Short Paper",
    "pdf_url": "http://arxiv.org/pdf/2402.03728v1",
    "published_date": "2024-02-06 05:50:04 UTC",
    "updated_date": "2024-02-06 05:50:04 UTC"
  },
  {
    "arxiv_id": "2402.03720v1",
    "title": "Similarity-based Neighbor Selection for Graph LLMs",
    "authors": [
      "Rui Li",
      "Jiwei Li",
      "Jiawei Han",
      "Guoyin Wang"
    ],
    "abstract": "Text-attributed graphs (TAGs) present unique challenges for direct processing\nby Language Learning Models (LLMs), yet their extensive commonsense knowledge\nand robust reasoning capabilities offer great promise for node classification\nin TAGs. Prior research in this field has grappled with issues such as\nover-squashing, heterophily, and ineffective graph information integration,\nfurther compounded by inconsistencies in dataset partitioning and\nunderutilization of advanced LLMs. To address these challenges, we introduce\nSimilarity-based Neighbor Selection (SNS). Using SimCSE and advanced neighbor\nselection techniques, SNS effectively improves the quality of selected\nneighbors, thereby improving graph representation and alleviating issues like\nover-squashing and heterophily. Besides, as an inductive and training-free\napproach, SNS demonstrates superior generalization and scalability over\ntraditional GNN methods. Our comprehensive experiments, adhering to standard\ndataset partitioning practices, demonstrate that SNS, through simple prompt\ninteractions with LLMs, consistently outperforms vanilla GNNs and achieves\nstate-of-the-art results on datasets like PubMed in node classification,\nshowcasing LLMs' potential in graph structure understanding. Our research\nfurther underscores the significance of graph structure integration in LLM\napplications and identifies key factors for their success in node\nclassification. Code is available at https://github.com/ruili33/SNS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03720v1",
    "published_date": "2024-02-06 05:29:05 UTC",
    "updated_date": "2024-02-06 05:29:05 UTC"
  },
  {
    "arxiv_id": "2402.03719v1",
    "title": "Empowering Language Models with Active Inquiry for Deeper Understanding",
    "authors": [
      "Jing-Cheng Pang",
      "Heng-Bo Fan",
      "Pengyuan Wang",
      "Jia-Hao Xiao",
      "Nan Tang",
      "Si-Hang Yang",
      "Chengxing Jia",
      "Sheng-Jun Huang",
      "Yang Yu"
    ],
    "abstract": "The rise of large language models (LLMs) has revolutionized the way that we\ninteract with artificial intelligence systems through natural language.\nHowever, LLMs often misinterpret user queries because of their uncertain\nintention, leading to less helpful responses. In natural human interactions,\nclarification is sought through targeted questioning to uncover obscure\ninformation. Thus, in this paper, we introduce LaMAI (Language Model with\nActive Inquiry), designed to endow LLMs with this same level of interactive\nengagement. LaMAI leverages active learning techniques to raise the most\ninformative questions, fostering a dynamic bidirectional dialogue. This\napproach not only narrows the contextual gap but also refines the output of the\nLLMs, aligning it more closely with user expectations. Our empirical studies,\nacross a variety of complex datasets where LLMs have limited conversational\ncontext, demonstrate the effectiveness of LaMAI. The method improves answer\naccuracy from 31.9% to 50.9%, outperforming other leading question-answering\nframeworks. Moreover, in scenarios involving human participants, LaMAI\nconsistently generates responses that are superior or comparable to baseline\nmethods in more than 82% of the cases. The applicability of LaMAI is further\nevidenced by its successful integration with various LLMs, highlighting its\npotential for the future of interactive language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03719v1",
    "published_date": "2024-02-06 05:24:16 UTC",
    "updated_date": "2024-02-06 05:24:16 UTC"
  },
  {
    "arxiv_id": "2402.03715v3",
    "title": "Clarify: Improving Model Robustness With Natural Language Corrections",
    "authors": [
      "Yoonho Lee",
      "Michelle S. Lam",
      "Helena Vasconcelos",
      "Michael S. Bernstein",
      "Chelsea Finn"
    ],
    "abstract": "The standard way to teach models is by feeding them lots of data. However,\nthis approach often teaches models incorrect ideas because they pick up on\nmisleading signals in the data. To prevent such misconceptions, we must\nnecessarily provide additional information beyond the training data. Prior\nmethods incorporate additional instance-level supervision, such as labels for\nmisleading features or additional labels for debiased data. However, such\nstrategies require a large amount of labeler effort. We hypothesize that people\nare good at providing textual feedback at the concept level, a capability that\nexisting teaching frameworks do not leverage. We propose Clarify, a novel\ninterface and method for interactively correcting model misconceptions. Through\nClarify, users need only provide a short text description of a model's\nconsistent failure patterns. Then, in an entirely automated way, we use such\ndescriptions to improve the training process. Clarify is the first end-to-end\nsystem for user model correction. Our user studies show that non-expert users\ncan successfully describe model misconceptions via Clarify, leading to\nincreased worst-case performance in two datasets. We additionally conduct a\ncase study on a large-scale image dataset, ImageNet, using Clarify to find and\nrectify 31 novel hard subpopulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "UIST 2024. Interface code available at\n  https://github.com/yoonholee/Clarify",
    "pdf_url": "http://arxiv.org/pdf/2402.03715v3",
    "published_date": "2024-02-06 05:11:38 UTC",
    "updated_date": "2024-08-22 01:26:21 UTC"
  },
  {
    "arxiv_id": "2402.03706v1",
    "title": "MMAUD: A Comprehensive Multi-Modal Anti-UAV Dataset for Modern Miniature Drone Threats",
    "authors": [
      "Shenghai Yuan",
      "Yizhuo Yang",
      "Thien Hoang Nguyen",
      "Thien-Minh Nguyen",
      "Jianfei Yang",
      "Fen Liu",
      "Jianping Li",
      "Han Wang",
      "Lihua Xie"
    ],
    "abstract": "In response to the evolving challenges posed by small unmanned aerial\nvehicles (UAVs), which possess the potential to transport harmful payloads or\nindependently cause damage, we introduce MMAUD: a comprehensive Multi-Modal\nAnti-UAV Dataset. MMAUD addresses a critical gap in contemporary threat\ndetection methodologies by focusing on drone detection, UAV-type\nclassification, and trajectory estimation. MMAUD stands out by combining\ndiverse sensory inputs, including stereo vision, various Lidars, Radars, and\naudio arrays. It offers a unique overhead aerial detection vital for addressing\nreal-world scenarios with higher fidelity than datasets captured on specific\nvantage points using thermal and RGB. Additionally, MMAUD provides accurate\nLeica-generated ground truth data, enhancing credibility and enabling confident\nrefinement of algorithms and models, which has never been seen in other\ndatasets. Most existing works do not disclose their datasets, making MMAUD an\ninvaluable resource for developing accurate and efficient solutions. Our\nproposed modalities are cost-effective and highly adaptable, allowing users to\nexperiment and implement new UAV threat detection tools. Our dataset closely\nsimulates real-world scenarios by incorporating ambient heavy machinery sounds.\nThis approach enhances the dataset's applicability, capturing the exact\nchallenges faced during proximate vehicular operations. It is expected that\nMMAUD can play a pivotal role in advancing UAV threat detection,\nclassification, trajectory estimation capabilities, and beyond. Our dataset,\ncodes, and designs will be available in https://github.com/ntu-aris/MMAUD.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03706v1",
    "published_date": "2024-02-06 04:57:07 UTC",
    "updated_date": "2024-02-06 04:57:07 UTC"
  },
  {
    "arxiv_id": "2402.03700v1",
    "title": "GenLens: A Systematic Evaluation of Visual GenAI Model Outputs",
    "authors": [
      "Tica Lin",
      "Hanspeter Pfister",
      "Jui-Hsien Wang"
    ],
    "abstract": "The rapid development of generative AI (GenAI) models in computer vision\nnecessitates effective evaluation methods to ensure their quality and fairness.\nExisting tools primarily focus on dataset quality assurance and model\nexplainability, leaving a significant gap in GenAI output evaluation during\nmodel development. Current practices often depend on developers' subjective\nvisual assessments, which may lack scalability and generalizability. This paper\nbridges this gap by conducting a formative study with GenAI model developers in\nan industrial setting. Our findings led to the development of GenLens, a visual\nanalytic interface designed for the systematic evaluation of GenAI model\noutputs during the early stages of model development. GenLens offers a\nquantifiable approach for overviewing and annotating failure cases, customizing\nissue tags and classifications, and aggregating annotations from multiple users\nto enhance collaboration. A user study with model developers reveals that\nGenLens effectively enhances their workflow, evidenced by high satisfaction\nrates and a strong intent to integrate it into their practices. This research\nunderscores the importance of robust early-stage evaluation tools in GenAI\ndevelopment, contributing to the advancement of fair and high-quality GenAI\nmodels.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "To Appear in IEEE PacificVis 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03700v1",
    "published_date": "2024-02-06 04:41:06 UTC",
    "updated_date": "2024-02-06 04:41:06 UTC"
  },
  {
    "arxiv_id": "2402.03694v2",
    "title": "ServeFlow: A Fast-Slow Model Architecture for Network Traffic Analysis",
    "authors": [
      "Shinan Liu",
      "Ted Shaowang",
      "Gerry Wan",
      "Jeewon Chae",
      "Jonatas Marques",
      "Sanjay Krishnan",
      "Nick Feamster"
    ],
    "abstract": "Network traffic analysis increasingly uses complex machine learning models as\nthe internet consolidates and traffic gets more encrypted. However, over\nhigh-bandwidth networks, flows can easily arrive faster than model inference\nrates. The temporal nature of network flows limits simple scale-out approaches\nleveraged in other high-traffic machine learning applications. Accordingly,\nthis paper presents ServeFlow, a solution for machine-learning model serving\naimed at network traffic analysis tasks, which carefully selects the number of\npackets to collect and the models to apply for individual flows to achieve a\nbalance between minimal latency, high service rate, and high accuracy. We\nidentify that on the same task, inference time across models can differ by 1.8x\n- 141.3x, while the inter-packet waiting time is up to 6-8 orders of magnitude\nhigher than the inference time! Based on these insights, we tailor a novel\nfast-slow model architecture for networking ML pipelines. Flows are assigned to\na slower model only when the inferences from the fast model are deemed high\nuncertainty. ServeFlow is able to make inferences on 76.3% of flows in under\n16ms, which is a speed-up of 40.5x on the median end-to-end serving latency\nwhile increasing the service rate and maintaining similar accuracy. Even with\nthousands of features per flow, it achieves a service rate of over 48.5k new\nflows per second on a 16-core CPU commodity server, which matches the order of\nmagnitude of flow rates observed on city-level network backbones.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03694v2",
    "published_date": "2024-02-06 04:28:33 UTC",
    "updated_date": "2024-10-24 14:15:42 UTC"
  },
  {
    "arxiv_id": "2402.03688v1",
    "title": "A Survey of Privacy Threats and Defense in Vertical Federated Learning: From Model Life Cycle Perspective",
    "authors": [
      "Lei Yu",
      "Meng Han",
      "Yiming Li",
      "Changting Lin",
      "Yao Zhang",
      "Mingyang Zhang",
      "Yan Liu",
      "Haiqin Weng",
      "Yuseok Jeon",
      "Ka-Ho Chow",
      "Stacy Patterson"
    ],
    "abstract": "Vertical Federated Learning (VFL) is a federated learning paradigm where\nmultiple participants, who share the same set of samples but hold different\nfeatures, jointly train machine learning models. Although VFL enables\ncollaborative machine learning without sharing raw data, it is still\nsusceptible to various privacy threats. In this paper, we conduct the first\ncomprehensive survey of the state-of-the-art in privacy attacks and defenses in\nVFL. We provide taxonomies for both attacks and defenses, based on their\ncharacterizations, and discuss open challenges and future research directions.\nSpecifically, our discussion is structured around the model's life cycle, by\ndelving into the privacy threats encountered during different stages of machine\nlearning and their corresponding countermeasures. This survey not only serves\nas a resource for the research community but also offers clear guidance and\nactionable insights for practitioners to safeguard data privacy throughout the\nmodel's life cycle.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03688v1",
    "published_date": "2024-02-06 04:22:44 UTC",
    "updated_date": "2024-02-06 04:22:44 UTC"
  },
  {
    "arxiv_id": "2402.05133v3",
    "title": "Personalized Language Modeling from Personalized Human Feedback",
    "authors": [
      "Xinyu Li",
      "Ruiyang Zhou",
      "Zachary C. Lipton",
      "Liu Leqi"
    ],
    "abstract": "Personalized large language models (LLMs) are designed to tailor responses to\nindividual user preferences. While Reinforcement Learning from Human Feedback\n(RLHF) is a commonly used framework for aligning LLMs with human preferences,\nvanilla RLHF assumes that all human preferences share the same distribution,\npreventing fine-tuned LLMs from generating personalized content when user\npreferences are diverse. In this work, we propose Personalized-RLHF (P-RLHF),\nan efficient framework that utilizes a lightweight user model to capture\nindividual user preferences and jointly learns the user model and the\npersonalized LLM from human feedback. P-RLHF exhibits the following three\ncharacteristics: (1) It enables an LLM to generate personalized content and\nscale efficiently with growing number of users. (2) It handles both explicit\nuser preferences described as textual input and implicit user preferences\nencoded in the feedback data. (3) It eliminates the need for users to fully\narticulate their preferences, which are normally needed for prompting LLMs to\ngenerate personalized content yet are often impractical to obtain in real-world\nscenarios. Our experimental results show that personalized LLMs trained using\nP-RLHF generate responses that are more closely aligned with individual user\npreferences, outperforming vanilla, non-personalized RLHF and prompting-based\npersonalization approaches across different tasks. We opensource our code at\nhttps://github.com/HumainLab/Personalized_RLHF.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05133v3",
    "published_date": "2024-02-06 04:18:58 UTC",
    "updated_date": "2024-12-09 04:21:08 UTC"
  },
  {
    "arxiv_id": "2402.03686v3",
    "title": "Are Machines Better at Complex Reasoning? Unveiling Human-Machine Inference Gaps in Entailment Verification",
    "authors": [
      "Soumya Sanyal",
      "Tianyi Xiao",
      "Jiacheng Liu",
      "Wenya Wang",
      "Xiang Ren"
    ],
    "abstract": "Making inferences in text comprehension to understand the meaning is\nessential in language processing. This work studies the entailment verification\n(EV) problem of multi-sentence premises that requires a system to make multiple\ninferences implicitly. Studying EV for such complex premises is important\nbecause modern NLP problems, such as detecting inconsistent model-generated\nrationales, require complex multi-hop reasoning. However, current textual\ninference datasets mostly contain short premises that only partially focus on\nthese challenges. To address this, we compile an EV benchmark that includes\ndatasets from three NLP domains (NLI, contextual QA, and rationales) containing\nmulti-sentence premises. On benchmarking humans and LLMs, we find that LLMs are\nbetter than humans in multi-hop reasoning across extended contexts, while\nhumans perform better in simple deductive reasoning tasks. We also finetune a\nFlan-T5 model for EV using two training objectives to obtain a strong\nopen-source model that outperforms GPT-3.5 and rivals GPT-4. Finally, we use\nthis model to filter out inconsistent model-generated rationales in\nself-consistency decoding, resulting in a 6% accuracy improvement on average\nacross three MCQ datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03686v3",
    "published_date": "2024-02-06 04:14:09 UTC",
    "updated_date": "2024-05-27 18:44:14 UTC"
  },
  {
    "arxiv_id": "2402.03681v4",
    "title": "RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback",
    "authors": [
      "Yufei Wang",
      "Zhanyi Sun",
      "Jesse Zhang",
      "Zhou Xian",
      "Erdem Biyik",
      "David Held",
      "Zackory Erickson"
    ],
    "abstract": "Reward engineering has long been a challenge in Reinforcement Learning (RL)\nresearch, as it often requires extensive human effort and iterative processes\nof trial-and-error to design effective reward functions. In this paper, we\npropose RL-VLM-F, a method that automatically generates reward functions for\nagents to learn new tasks, using only a text description of the task goal and\nthe agent's visual observations, by leveraging feedbacks from vision language\nfoundation models (VLMs). The key to our approach is to query these models to\ngive preferences over pairs of the agent's image observations based on the text\ndescription of the task goal, and then learn a reward function from the\npreference labels, rather than directly prompting these models to output a raw\nreward score, which can be noisy and inconsistent. We demonstrate that RL-VLM-F\nsuccessfully produces effective rewards and policies across various domains -\nincluding classic control, as well as manipulation of rigid, articulated, and\ndeformable objects - without the need for human supervision, outperforming\nprior methods that use large pretrained models for reward generation under the\nsame assumptions. Videos can be found on our project website:\nhttps://rlvlmf2024.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03681v4",
    "published_date": "2024-02-06 04:06:06 UTC",
    "updated_date": "2024-06-14 21:10:32 UTC"
  },
  {
    "arxiv_id": "2402.03678v3",
    "title": "Logical Specifications-guided Dynamic Task Sampling for Reinforcement Learning Agents",
    "authors": [
      "Yash Shukla",
      "Tanushree Burman",
      "Abhishek Kulkarni",
      "Robert Wright",
      "Alvaro Velasquez",
      "Jivko Sinapov"
    ],
    "abstract": "Reinforcement Learning (RL) has made significant strides in enabling\nartificial agents to learn diverse behaviors. However, learning an effective\npolicy often requires a large number of environment interactions. To mitigate\nsample complexity issues, recent approaches have used high-level task\nspecifications, such as Linear Temporal Logic (LTL$_f$) formulas or Reward\nMachines (RM), to guide the learning progress of the agent. In this work, we\npropose a novel approach, called Logical Specifications-guided Dynamic Task\nSampling (LSTS), that learns a set of RL policies to guide an agent from an\ninitial state to a goal state based on a high-level task specification, while\nminimizing the number of environmental interactions. Unlike previous work, LSTS\ndoes not assume information about the environment dynamics or the Reward\nMachine, and dynamically samples promising tasks that lead to successful goal\npolicies. We evaluate LSTS on a gridworld and show that it achieves improved\ntime-to-threshold performance on complex sequential decision-making problems\ncompared to state-of-the-art RM and Automaton-guided RL baselines, such as\nQ-Learning for Reward Machines and Compositional RL from logical Specifications\n(DIRL). Moreover, we demonstrate that our method outperforms RM and\nAutomaton-guided RL baselines in terms of sample-efficiency, both in a\npartially observable robotic task and in a continuous control robotic\nmanipulation task.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03678v3",
    "published_date": "2024-02-06 04:00:21 UTC",
    "updated_date": "2024-04-03 00:45:12 UTC"
  },
  {
    "arxiv_id": "2402.03675v1",
    "title": "Effective Protein-Protein Interaction Exploration with PPIretrieval",
    "authors": [
      "Chenqing Hua",
      "Connor Coley",
      "Guy Wolf",
      "Doina Precup",
      "Shuangjia Zheng"
    ],
    "abstract": "Protein-protein interactions (PPIs) are crucial in regulating numerous\ncellular functions, including signal transduction, transportation, and immune\ndefense. As the accuracy of multi-chain protein complex structure prediction\nimproves, the challenge has shifted towards effectively navigating the vast\ncomplex universe to identify potential PPIs. Herein, we propose PPIretrieval,\nthe first deep learning-based model for protein-protein interaction\nexploration, which leverages existing PPI data to effectively search for\npotential PPIs in an embedding space, capturing rich geometric and chemical\ninformation of protein surfaces. When provided with an unseen query protein\nwith its associated binding site, PPIretrieval effectively identifies a\npotential binding partner along with its corresponding binding site in an\nembedding space, facilitating the formation of protein-protein complexes.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03675v1",
    "published_date": "2024-02-06 03:57:06 UTC",
    "updated_date": "2024-02-06 03:57:06 UTC"
  },
  {
    "arxiv_id": "2402.03667v2",
    "title": "Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning",
    "authors": [
      "Yanfang Zhang",
      "Yiliu Sun",
      "Yibing Zhan",
      "Dapeng Tao",
      "Dacheng Tao",
      "Chen Gong"
    ],
    "abstract": "Recently, increasing attention has been focused on improving the ability of\nLarge Language Models (LLMs) to perform complex reasoning. Advanced methods,\nsuch as Chain-of-Thought (CoT) and its variants, are found to enhance their\nreasoning skills by designing suitable prompts or breaking down complex\nproblems into more manageable sub-problems. However, little concentration has\nbeen put on exploring the reasoning process, \\textit{i.e.}, we discovered that\nmost methods resort to Direct Reasoning (DR) and disregard Indirect Reasoning\n(IR). This can make LLMs difficult to solve IR tasks, which are often\nencountered in the real world. To address this issue, we propose a\nDirect-Indirect Reasoning (DIR) method, which considers DR and IR as multiple\nparallel reasoning paths that are merged to derive the final answer. We\nstimulate LLMs to implement IR by crafting prompt templates incorporating the\nprinciples of contrapositive and contradiction. These templates trigger LLMs to\nassume the negation of the conclusion as true, combine it with the premises to\ndeduce a conclusion, and utilize the logical equivalence of the contrapositive\nto enhance their comprehension of the rules used in the reasoning process. Our\nDIR method is simple yet effective and can be straightforwardly integrated with\nexisting variants of CoT methods. Experimental results on four datasets related\nto logical reasoning and mathematic proof demonstrate that our DIR method, when\ncombined with various baseline methods, significantly outperforms all the\noriginal methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by COLING 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2402.03667v2",
    "published_date": "2024-02-06 03:41:12 UTC",
    "updated_date": "2025-01-27 09:02:46 UTC"
  },
  {
    "arxiv_id": "2402.03663v1",
    "title": "Symbol Correctness in Deep Neural Networks Containing Symbolic Layers",
    "authors": [
      "Aaron Bembenek",
      "Toby Murray"
    ],
    "abstract": "To handle AI tasks that combine perception and logical reasoning, recent work\nintroduces Neurosymbolic Deep Neural Networks (NS-DNNs), which contain -- in\naddition to traditional neural layers -- symbolic layers: symbolic expressions\n(e.g., SAT formulas, logic programs) that are evaluated by symbolic solvers\nduring inference. We identify and formalize an intuitive, high-level principle\nthat can guide the design and analysis of NS-DNNs: symbol correctness, the\ncorrectness of the intermediate symbols predicted by the neural layers with\nrespect to a (generally unknown) ground-truth symbolic representation of the\ninput data. We demonstrate that symbol correctness is a necessary property for\nNS-DNN explainability and transfer learning (despite being in general\nimpossible to train for). Moreover, we show that the framework of symbol\ncorrectness provides a precise way to reason and communicate about model\nbehavior at neural-symbolic boundaries, and gives insight into the fundamental\ntradeoffs faced by NS-DNN training algorithms. In doing so, we both identify\nsignificant points of ambiguity in prior work, and provide a framework to\nsupport further NS-DNN developments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03663v1",
    "published_date": "2024-02-06 03:33:50 UTC",
    "updated_date": "2024-02-06 03:33:50 UTC"
  },
  {
    "arxiv_id": "2402.03661v1",
    "title": "Transductive Reward Inference on Graph",
    "authors": [
      "Bohao Qu",
      "Xiaofeng Cao",
      "Qing Guo",
      "Yi Chang",
      "Ivor W. Tsang",
      "Chengqi Zhang"
    ],
    "abstract": "In this study, we present a transductive inference approach on that reward\ninformation propagation graph, which enables the effective estimation of\nrewards for unlabelled data in offline reinforcement learning. Reward inference\nis the key to learning effective policies in practical scenarios, while direct\nenvironmental interactions are either too costly or unethical and the reward\nfunctions are rarely accessible, such as in healthcare and robotics. Our\nresearch focuses on developing a reward inference method based on the\ncontextual properties of information propagation on graphs that capitalizes on\na constrained number of human reward annotations to infer rewards for\nunlabelled data. We leverage both the available data and limited reward\nannotations to construct a reward propagation graph, wherein the edge weights\nincorporate various influential factors pertaining to the rewards.\nSubsequently, we employ the constructed graph for transductive reward\ninference, thereby estimating rewards for unlabelled data. Furthermore, we\nestablish the existence of a fixed point during several iterations of the\ntransductive inference process and demonstrate its at least convergence to a\nlocal optimum. Empirical evaluations on locomotion and robotic manipulation\ntasks validate the effectiveness of our approach. The application of our\ninferred rewards improves the performance in offline reinforcement learning\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03661v1",
    "published_date": "2024-02-06 03:31:28 UTC",
    "updated_date": "2024-02-06 03:31:28 UTC"
  },
  {
    "arxiv_id": "2402.03660v2",
    "title": "On the Emergence of Cross-Task Linearity in the Pretraining-Finetuning Paradigm",
    "authors": [
      "Zhanpeng Zhou",
      "Zijun Chen",
      "Yilan Chen",
      "Bo Zhang",
      "Junchi Yan"
    ],
    "abstract": "The pretraining-finetuning paradigm has become the prevailing trend in modern\ndeep learning. In this work, we discover an intriguing linear phenomenon in\nmodels that are initialized from a common pretrained checkpoint and finetuned\non different tasks, termed as Cross-Task Linearity (CTL). Specifically, we show\nthat if we linearly interpolate the weights of two finetuned models, the\nfeatures in the weight-interpolated model are often approximately equal to the\nlinear interpolation of features in two finetuned models at each layer. We\nprovide comprehensive empirical evidence supporting that CTL consistently\noccurs for finetuned models that start from the same pretrained checkpoint. We\nconjecture that in the pretraining-finetuning paradigm, neural networks\napproximately function as linear maps, mapping from the parameter space to the\nfeature space. Based on this viewpoint, our study unveils novel insights into\nexplaining model merging/editing, particularly by translating operations from\nthe parameter space to the feature space. Furthermore, we delve deeper into the\nroot cause for the emergence of CTL, highlighting the role of pretraining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.03660v2",
    "published_date": "2024-02-06 03:28:36 UTC",
    "updated_date": "2024-05-28 08:44:15 UTC"
  },
  {
    "arxiv_id": "2402.06049v2",
    "title": "Limits of Large Language Models in Debating Humans",
    "authors": [
      "James Flamino",
      "Mohammed Shahid Modi",
      "Boleslaw K. Szymanski",
      "Brendan Cross",
      "Colton Mikolajczyk"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable promise in communicating\nwith humans. Their potential use as artificial partners with humans in\nsociological experiments involving conversation is an exciting prospect. But\nhow viable is it? Here, we rigorously test the limits of agents that debate\nusing LLMs in a preregistered study that runs multiple debate-based opinion\nconsensus games. Each game starts with six humans, six agents, or three humans\nand three agents. We found that agents can blend in and concentrate on a\ndebate's topic better than humans, improving the productivity of all players.\nYet, humans perceive agents as less convincing and confident than other humans,\nand several behavioral metrics of humans and agents we collected deviate\nmeasurably from each other. We observed that agents are already decent\ndebaters, but their behavior generates a pattern distinctly different from the\nhuman-generated data.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 4 figures, 3 tables, 42 pages of supplemental materials, 9\n  supplemental figures, 24 supplemental tables",
    "pdf_url": "http://arxiv.org/pdf/2402.06049v2",
    "published_date": "2024-02-06 03:24:27 UTC",
    "updated_date": "2025-02-01 23:54:28 UTC"
  },
  {
    "arxiv_id": "2402.03647v1",
    "title": "CAMBranch: Contrastive Learning with Augmented MILPs for Branching",
    "authors": [
      "Jiacheng Lin",
      "Meng Xu",
      "Zhihua Xiong",
      "Huangang Wang"
    ],
    "abstract": "Recent advancements have introduced machine learning frameworks to enhance\nthe Branch and Bound (B\\&B) branching policies for solving Mixed Integer Linear\nProgramming (MILP). These methods, primarily relying on imitation learning of\nStrong Branching, have shown superior performance. However, collecting expert\nsamples for imitation learning, particularly for Strong Branching, is a\ntime-consuming endeavor. To address this challenge, we propose\n\\textbf{C}ontrastive Learning with \\textbf{A}ugmented \\textbf{M}ILPs for\n\\textbf{Branch}ing (CAMBranch), a framework that generates Augmented MILPs\n(AMILPs) by applying variable shifting to limited expert data from their\noriginal MILPs. This approach enables the acquisition of a considerable number\nof labeled expert samples. CAMBranch leverages both MILPs and AMILPs for\nimitation learning and employs contrastive learning to enhance the model's\nability to capture MILP features, thereby improving the quality of branching\ndecisions. Experimental results demonstrate that CAMBranch, trained with only\n10\\% of the complete dataset, exhibits superior performance. Ablation studies\nfurther validate the effectiveness of our method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03647v1",
    "published_date": "2024-02-06 02:47:16 UTC",
    "updated_date": "2024-02-06 02:47:16 UTC"
  },
  {
    "arxiv_id": "2402.03640v1",
    "title": "torchmSAT: A GPU-Accelerated Approximation To The Maximum Satisfiability Problem",
    "authors": [
      "Abdelrahman Hosny",
      "Sherief Reda"
    ],
    "abstract": "The remarkable achievements of machine learning techniques in analyzing\ndiscrete structures have drawn significant attention towards their integration\ninto combinatorial optimization algorithms. Typically, these methodologies\nimprove existing solvers by injecting learned models within the solving loop to\nenhance the efficiency of the search process. In this work, we derive a single\ndifferentiable function capable of approximating solutions for the Maximum\nSatisfiability Problem (MaxSAT). Then, we present a novel neural network\narchitecture to model our differentiable function, and progressively solve\nMaxSAT using backpropagation. This approach eliminates the need for labeled\ndata or a neural network training phase, as the training process functions as\nthe solving algorithm. Additionally, we leverage the computational power of\nGPUs to accelerate these computations. Experimental results on challenging\nMaxSAT instances show that our proposed methodology outperforms two existing\nMaxSAT solvers, and is on par with another in terms of solution cost, without\nnecessitating any training or access to an underlying SAT solver. Given that\nnumerous NP-hard problems can be reduced to MaxSAT, our novel technique paves\nthe way for a new generation of solvers poised to benefit from neural network\nGPU acceleration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03640v1",
    "published_date": "2024-02-06 02:33:00 UTC",
    "updated_date": "2024-02-06 02:33:00 UTC"
  },
  {
    "arxiv_id": "2402.04286v1",
    "title": "Progress and Opportunities of Foundation Models in Bioinformatics",
    "authors": [
      "Qing Li",
      "Zhihang Hu",
      "Yixuan Wang",
      "Lei Li",
      "Yimin Fan",
      "Irwin King",
      "Le Song",
      "Yu Li"
    ],
    "abstract": "Bioinformatics has witnessed a paradigm shift with the increasing integration\nof artificial intelligence (AI), particularly through the adoption of\nfoundation models (FMs). These AI techniques have rapidly advanced, addressing\nhistorical challenges in bioinformatics such as the scarcity of annotated data\nand the presence of data noise. FMs are particularly adept at handling\nlarge-scale, unlabeled data, a common scenario in biological contexts due to\nthe time-consuming and costly nature of experimentally determining labeled\ndata. This characteristic has allowed FMs to excel and achieve notable results\nin various downstream validation tasks, demonstrating their ability to\nrepresent diverse biological entities effectively. Undoubtedly, FMs have\nushered in a new era in computational biology, especially in the realm of deep\nlearning. The primary goal of this survey is to conduct a systematic\ninvestigation and summary of FMs in bioinformatics, tracing their evolution,\ncurrent research status, and the methodologies employed. Central to our focus\nis the application of FMs to specific biological problems, aiming to guide the\nresearch community in choosing appropriate FMs for their research needs. We\ndelve into the specifics of the problem at hand including sequence analysis,\nstructure prediction, function annotation, and multimodal integration,\ncomparing the structures and advancements against traditional methods.\nFurthermore, the review analyses challenges and limitations faced by FMs in\nbiology, such as data noise, model explainability, and potential biases.\nFinally, we outline potential development paths and strategies for FMs in\nfuture biological research, setting the stage for continued innovation and\napplication in this rapidly evolving field. This comprehensive review serves\nnot only as an academic resource but also as a roadmap for future explorations\nand applications of FMs in biology.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "cs.CL, 92-02",
      "I.2.1"
    ],
    "primary_category": "q-bio.QM",
    "comment": "27 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.04286v1",
    "published_date": "2024-02-06 02:29:17 UTC",
    "updated_date": "2024-02-06 02:29:17 UTC"
  },
  {
    "arxiv_id": "2402.03630v2",
    "title": "Enhancing LLM-Based Coding Tools through Native Integration of IDE-Derived Static Context",
    "authors": [
      "Yichen Li",
      "Yun Peng",
      "Yintong Huo",
      "Michael R. Lyu"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in code\ncompletion, as evidenced by their essential roles in developing code assistant\nservices such as Copilot. Being trained on in-file contexts, current LLMs are\nquite effective in completing code for single source files. However, it is\nchallenging for them to conduct repository-level code completion for large\nsoftware projects that require cross-file information. Existing research on\nLLM-based repository-level code completion identifies and integrates cross-file\ncontexts, but it suffers from low accuracy and limited context length of LLMs.\nIn this paper, we argue that Integrated Development Environments (IDEs) can\nprovide direct, accurate and real-time cross-file information for\nrepository-level code completion. We propose IDECoder, a practical framework\nthat leverages IDE native static contexts for cross-context construction and\ndiagnosis results for self-refinement. IDECoder utilizes the rich cross-context\ninformation available in IDEs to enhance the capabilities of LLMs of\nrepository-level code completion. We conducted preliminary experiments to\nvalidate the performance of IDECoder and observed that this synergy represents\na promising trend for future exploration.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03630v2",
    "published_date": "2024-02-06 01:59:41 UTC",
    "updated_date": "2024-02-19 06:39:23 UTC"
  },
  {
    "arxiv_id": "2402.03627v2",
    "title": "Partially Recentralization Softmax Loss for Vision-Language Models Robustness",
    "authors": [
      "Hao Wang",
      "Jinzhe Jiang",
      "Xin Zhang",
      "Chen Li"
    ],
    "abstract": "As Large Language Models make a breakthrough in natural language processing\ntasks (NLP), multimodal technique becomes extremely popular. However, it has\nbeen shown that multimodal NLP are vulnerable to adversarial attacks, where the\noutputs of a model can be dramatically changed by a perturbation to the input.\nWhile several defense techniques have been proposed both in computer vision and\nNLP models, the multimodal robustness of models have not been fully explored.\nIn this paper, we study the adversarial robustness provided by modifying loss\nfunction of pre-trained multimodal models, by restricting top K softmax\noutputs. Based on the evaluation and scoring, our experiments show that after a\nfine-tuning, adversarial robustness of pre-trained models can be significantly\nimproved, against popular attacks. Further research should be studying, such as\noutput diversity, generalization and the robustness-performance trade-off of\nthis kind of loss functions. Our code will be available after this paper is\naccepted",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03627v2",
    "published_date": "2024-02-06 01:44:38 UTC",
    "updated_date": "2024-10-08 08:13:25 UTC"
  },
  {
    "arxiv_id": "2402.03621v1",
    "title": "Neural Network Approximators for Marginal MAP in Probabilistic Circuits",
    "authors": [
      "Shivvrat Arya",
      "Tahrima Rahman",
      "Vibhav Gogate"
    ],
    "abstract": "Probabilistic circuits (PCs) such as sum-product networks efficiently\nrepresent large multi-variate probability distributions. They are preferred in\npractice over other probabilistic representations such as Bayesian and Markov\nnetworks because PCs can solve marginal inference (MAR) tasks in time that\nscales linearly in the size of the network. Unfortunately, the\nmaximum-a-posteriori (MAP) and marginal MAP (MMAP) tasks remain NP-hard in\nthese models. Inspired by the recent work on using neural networks for\ngenerating near-optimal solutions to optimization problems such as integer\nlinear programming, we propose an approach that uses neural networks to\napproximate (M)MAP inference in PCs. The key idea in our approach is to\napproximate the cost of an assignment to the query variables using a continuous\nmultilinear function, and then use the latter as a loss function. The two main\nbenefits of our new method are that it is self-supervised and after the neural\nnetwork is learned, it requires only linear time to output a solution. We\nevaluate our new approach on several benchmark datasets and show that it\noutperforms three competing linear time approximations, max-product inference,\nmax-marginal inference and sequential estimation, which are used in practice to\nsolve MMAP tasks in PCs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Will appear in AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03621v1",
    "published_date": "2024-02-06 01:15:06 UTC",
    "updated_date": "2024-02-06 01:15:06 UTC"
  },
  {
    "arxiv_id": "2402.03620v1",
    "title": "Self-Discover: Large Language Models Self-Compose Reasoning Structures",
    "authors": [
      "Pei Zhou",
      "Jay Pujara",
      "Xiang Ren",
      "Xinyun Chen",
      "Heng-Tze Cheng",
      "Quoc V. Le",
      "Ed H. Chi",
      "Denny Zhou",
      "Swaroop Mishra",
      "Huaixiu Steven Zheng"
    ],
    "abstract": "We introduce SELF-DISCOVER, a general framework for LLMs to self-discover the\ntask-intrinsic reasoning structures to tackle complex reasoning problems that\nare challenging for typical prompting methods. Core to the framework is a\nself-discovery process where LLMs select multiple atomic reasoning modules such\nas critical thinking and step-by-step thinking, and compose them into an\nexplicit reasoning structure for LLMs to follow during decoding. SELF-DISCOVER\nsubstantially improves GPT-4 and PaLM 2's performance on challenging reasoning\nbenchmarks such as BigBench-Hard, grounded agent reasoning, and MATH, by as\nmuch as 32% compared to Chain of Thought (CoT). Furthermore, SELF-DISCOVER\noutperforms inference-intensive methods such as CoT-Self-Consistency by more\nthan 20%, while requiring 10-40x fewer inference compute. Finally, we show that\nthe self-discovered reasoning structures are universally applicable across\nmodel families: from PaLM 2-L to GPT-4, and from GPT-4 to Llama2, and share\ncommonalities with human reasoning patterns.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 11 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.03620v1",
    "published_date": "2024-02-06 01:13:53 UTC",
    "updated_date": "2024-02-06 01:13:53 UTC"
  },
  {
    "arxiv_id": "2402.03618v1",
    "title": "Comparing Abstraction in Humans and Large Language Models Using Multimodal Serial Reproduction",
    "authors": [
      "Sreejan Kumar",
      "Raja Marjieh",
      "Byron Zhang",
      "Declan Campbell",
      "Michael Y. Hu",
      "Umang Bhatt",
      "Brenden Lake",
      "Thomas L. Griffiths"
    ],
    "abstract": "Humans extract useful abstractions of the world from noisy sensory data.\nSerial reproduction allows us to study how people construe the world through a\nparadigm similar to the game of telephone, where one person observes a stimulus\nand reproduces it for the next to form a chain of reproductions. Past serial\nreproduction experiments typically employ a single sensory modality, but humans\noften communicate abstractions of the world to each other through language. To\ninvestigate the effect language on the formation of abstractions, we implement\na novel multimodal serial reproduction framework by asking people who receive a\nvisual stimulus to reproduce it in a linguistic format, and vice versa. We ran\nunimodal and multimodal chains with both humans and GPT-4 and find that adding\nlanguage as a modality has a larger effect on human reproductions than GPT-4's.\nThis suggests human visual and linguistic representations are more dissociable\nthan those of GPT-4.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03618v1",
    "published_date": "2024-02-06 01:07:56 UTC",
    "updated_date": "2024-02-06 01:07:56 UTC"
  },
  {
    "arxiv_id": "2402.03616v1",
    "title": "Leveraging Large Language Models for Hybrid Workplace Decision Support",
    "authors": [
      "Yujin Kim",
      "Chin-Chia Hsu"
    ],
    "abstract": "Large Language Models (LLMs) hold the potential to perform a variety of text\nprocessing tasks and provide textual explanations for proposed actions or\ndecisions. In the era of hybrid work, LLMs can provide intelligent decision\nsupport for workers who are designing their hybrid work plans. In particular,\nthey can offer suggestions and explanations to workers balancing numerous\ndecision factors, thereby enhancing their work experience. In this paper, we\npresent a decision support model for workspaces in hybrid work environments,\nleveraging the reasoning skill of LLMs. We first examine LLM's capability of\nmaking suitable workspace suggestions. We find that its reasoning extends\nbeyond the guidelines in the prompt and the LLM can manage the trade-off among\nthe available resources in the workspaces. We conduct an extensive user study\nto understand workers' decision process for workspace choices and evaluate the\neffectiveness of the system. We observe that a worker's decision could be\ninfluenced by the LLM's suggestions and explanations. The participants in our\nstudy find the system to be convenient, regardless of whether reasons are\nprovided or not. Our results show that employees can benefit from the\nLLM-empowered system for their workspace selection in hybrid workplace.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03616v1",
    "published_date": "2024-02-06 01:05:14 UTC",
    "updated_date": "2024-02-06 01:05:14 UTC"
  },
  {
    "arxiv_id": "2402.03610v1",
    "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents",
    "authors": [
      "Tomoyuki Kagaya",
      "Thong Jing Yuan",
      "Yuxuan Lou",
      "Jayashree Karlekar",
      "Sugiri Pranata",
      "Akira Kinose",
      "Koki Oguri",
      "Felix Wick",
      "Yang You"
    ],
    "abstract": "Owing to recent advancements, Large Language Models (LLMs) can now be\ndeployed as agents for increasingly complex decision-making applications in\nareas including robotics, gaming, and API integration. However, reflecting past\nexperiences in current decision-making processes, an innate human behavior,\ncontinues to pose significant challenges. Addressing this, we propose\nRetrieval-Augmented Planning (RAP) framework, designed to dynamically leverage\npast experiences corresponding to the current situation and context, thereby\nenhancing agents' planning capabilities. RAP distinguishes itself by being\nversatile: it excels in both text-only and multimodal environments, making it\nsuitable for a wide range of tasks. Empirical evaluations demonstrate RAP's\neffectiveness, where it achieves SOTA performance in textual scenarios and\nnotably enhances multimodal LLM agents' performance for embodied tasks. These\nresults highlight RAP's potential in advancing the functionality and\napplicability of LLM agents in complex, real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03610v1",
    "published_date": "2024-02-06 00:53:27 UTC",
    "updated_date": "2024-02-06 00:53:27 UTC"
  },
  {
    "arxiv_id": "2402.03607v2",
    "title": "Enhancing Cross-Modal Contextual Congruence for Crowdfunding Success using Knowledge-infused Learning",
    "authors": [
      "Trilok Padhi",
      "Ugur Kursuncu",
      "Yaman Kumar",
      "Valerie L. Shalin",
      "Lane Peterson Fronczek"
    ],
    "abstract": "The digital landscape continually evolves with multimodality, enriching the\nonline experience for users. Creators and marketers aim to weave subtle\ncontextual cues from various modalities into congruent content to engage users\nwith a harmonious message. This interplay of multimodal cues is often a crucial\nfactor in attracting users' attention. However, this richness of multimodality\npresents a challenge to computational modeling, as the semantic contextual cues\nspanning across modalities need to be unified to capture the true holistic\nmeaning of the multimodal content. This contextual meaning is critical in\nattracting user engagement as it conveys the intended message of the brand or\nthe organization. In this work, we incorporate external commonsense knowledge\nfrom knowledge graphs to enhance the representation of multimodal data using\ncompact Visual Language Models (VLMs) and predict the success of multi-modal\ncrowdfunding campaigns. Our results show that external knowledge commonsense\nbridges the semantic gap between text and image modalities, and the enhanced\nknowledge-infused representations improve the predictive performance of models\nfor campaign success upon the baselines without knowledge. Our findings\nhighlight the significance of contextual congruence in online multimodal\ncontent for engaging and successful crowdfunding campaigns.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.CY",
      "cs.HC",
      "I.2.7; I.2.10; I.2.4; I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at IEEE International Conference on Big Data 2024 (IEEE\n  BigData 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.03607v2",
    "published_date": "2024-02-06 00:51:27 UTC",
    "updated_date": "2024-11-17 21:40:50 UTC"
  }
]