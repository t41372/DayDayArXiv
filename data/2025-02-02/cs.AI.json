{
  "date": "2025-02-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-02 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 76 篇论文，主要聚焦 AI 模型安全、对齐和应用（如 LLM 在数学推理和多模态任务中的机制分析），以及医疗图像处理和强化学习的创新方法，其中令人印象深刻的包括 Max Tegmark 等学者参与的 LLM 数学推理研究（论文 8）和高效的多模态模型服务系统（论文 3）。\n\n### 重点论文亮点\n我挑选了最具话题度和影响力的论文优先讨论，将相关主题归类，快速掠过次要内容。以下聚焦 AI 安全、LLM 应用和医疗领域的关键贡献。\n\n**AI 安全与 LLM 对齐（高话题度领域）**  \n- **论文 8: Language Models Use Trigonometry to Do Addition（语言模型使用三角学进行加法）**  \n  作者包括 Max Tegmark，这篇论文揭示了 LLM 在数学运算中通过螺旋表示（generalized helix）来处理数字，证明了模型内部机制（如注意力头和神经元）利用三角学进行加法计算，主要贡献是首次在表示层面解释 LLM 的数学能力，为模型压缩和优化提供新洞见。  \n- **论文 19: SecPE: Secure Prompt Ensembling for Private and Robust Large Language Models（SecPE: 用于私有和鲁棒 LLM 的安全提示集成）**  \n  这篇论文提出 SecPE 框架，通过全同态加密（FHE）优化提示集成，实现 LLM 的隐私保护和对抗鲁棒性，主要发现是显著提高吞吐量（3.3-5.5 倍），并在安全任务中节省成本，适用于高风险应用如医疗诊断。  \n- **论文 20: Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs（激活近似可能导致对齐 LLM 的安全漏洞）**  \n  作者分析了激活近似在 LLM 中的安全风险，证明即使对齐模型也易受攻击，主要贡献是首次系统评估七种技术，强调需要更严格的安全评估框架。  \n- **论文 52: How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence（基准数据集污染程度如何？使用核散度量化 LLM 中的数据泄漏）**  \n  这篇快速掠过的论文引入 Kernel Divergence Score 来检测数据集污染，主要发现是提供了一种高效方法评估 LLM 泛化能力，避免基准测试的假象提升。\n\n**LLM 应用与强化学习（创新机制分析）**  \n- **论文 3: ModServe: Scalable and Resource-Efficient Large Multimodal Model Serving（ModServe: 可扩展、高效的多模态模型服务）**  \n  作者团队包括知名学者如 Rodrigo Fonseca，这篇论文提出 ModServe 系统，通过模块化设计和自适应调度优化多模态模型推理，实现 3.3-5.5 倍吞吐量提升，同时满足延迟服务水平目标（SLO），在生产环境中显著降低成本。  \n- **论文 10: Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation（思维链推理的亚稳态动态：搜索、强化学习和蒸馏的证明益处）**  \n  作者包括 Jason Lee，这篇论文从马尔科夫过程视角分析思维链（CoT）推理，证明搜索和强化学习能改善跨集群推理，主要贡献是提供理论保证，提升 LLM 在复杂任务中的性能。  \n- **论文 18: Dual Alignment Maximin Optimization for Offline Model-based RL（离线模型强化学习的双对齐最大最小优化）**  \n  这篇论文提出 Dual Alignment Maximin Optimization 框架，确保模型和策略一致性，主要发现是显著提高离线 RL 在基准任务中的性能，避免分布失配问题。  \n- **论文 49: Compositional Concept-Based Neuron-Level Interpretability for Deep Reinforcement Learning（基于组合概念的神经元级可解释性强化学习）**  \n  快速提到：通过逻辑操作定义概念函数，实现 DRL 模型的可解释性，贡献在于提升模型透明度。\n\n**医疗与生物应用（实际影响较大）**  \n- **论文 17: Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model（基于代理的不确定性感知提升开源 LLM 在放射学报告标注中的性能）**  \n  这篇论文使用代理模型和不确定性估计改进放射学报告处理，主要贡献是通过过滤高不确定性案例，提高 F1 分数至 0.4787，适用于医疗 AI。  \n- **论文 23: scGSDR: Harnessing Gene Semantics for Single-Cell Pharmacological Profiling（scGSDR: 利用基因语义进行单细胞药物分析）**  \n  提出 scGSDR 模型，整合基因语义和通路分析预测药物抵抗性，主要发现是在 11 种药物实验中显著提升预测准确性（高 AUROC 分数），为精准医学提供工具。  \n- **论文 38: Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images（基于配准增强的超声图像前列腺癌分割方法）**  \n  快速掠过：通过 MRI-TRUS 融合提高分割精度，贡献是平均 Dice 系数达 0.212，提升前列腺癌诊断效率。\n\n其他论文如果蝇分类（论文 2）和图神经网络（论文 13）等次要主题，仅快速提到：它们展示了迁移学习在生物分类中的应用（Inception-v3 达 93% F1 分数）和图神经网络在动态系统预测中的潜力，但影响力较小，不做深入讨论。\n\n总之，今天的 arXiv 更新强调了 AI 模型的安全性和实际应用潜力，建议关注 LLM 机制分析和医疗 AI 创新，以推动更可靠的模型部署。更多细节可查阅特定论文。",
  "papers": [
    {
      "arxiv_id": "2502.00940v1",
      "title": "An MDP Model for Censoring in Harvesting Sensors: Optimal and Approximated Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Jesus Fernandez-Bes",
        "Jesus Cid-Sueiro",
        "Antonio G. Marques"
      ],
      "abstract": "In this paper, we propose a novel censoring policy for energy-efficient\ntransmissions in energy-harvesting sensors. The problem is formulated as an\ninfinite-horizon Markov Decision Process (MDP). The objective to be optimized\nis the expected sum of the importance (utility) of all transmitted messages.\nAssuming that such importance can be evaluated at the transmitting node, we\nshow that, under certain conditions on the battery model, the optimal censoring\npolicy is a threshold function on the importance value. Specifically, messages\nare transmitted only if their importance is above a threshold whose value\ndepends on the battery level. Exploiting this property, we propose a\nmodel-based stochastic scheme that approximates the optimal solution, with less\ncomputational complexity and faster convergence speed than a conventional\nQ-learning algorithm. Numerical experiments in single-hop and multi-hop\nnetworks confirm the analytical advantages of the proposed scheme.",
      "tldr_zh": "这篇论文针对能量收集传感器提出了一种新型审查策略，以实现能量高效传输，并使用无限期Markov Decision Process (MDP)模型来优化传输消息的总重要性（效用）。在特定电池模型条件下，作者证明了最优审查策略是基于重要性值的阈值函数，即仅当消息重要性超过与电池水平相关的阈值时才传输。论文还引入了一种基于模型的随机方案来近似最优解，该方案比传统的Q-learning算法具有更低的计算复杂度和更快的收敛速度。数值实验在单跳和多跳网络中验证了该方案的分析优势。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00940v1",
      "published_date": "2025-02-02 22:22:21 UTC",
      "updated_date": "2025-02-02 22:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:48:48.722836"
    },
    {
      "arxiv_id": "2502.00939v1",
      "title": "Fruit Fly Classification (Diptera: Tephritidae) in Images, Applying Transfer Learning",
      "title_zh": "图像中果蝇（Diptera: Teph",
      "authors": [
        "Erick Andrew Bustamante Flores",
        "Harley Vera Olivera",
        "Ivan Cesar Medrano Valencia",
        "Carlos Fernando Montoya Cubas"
      ],
      "abstract": "This study develops a transfer learning model for the automated\nclassification of two species of fruit flies, Anastrepha fraterculus and\nCeratitis capitata, in a controlled laboratory environment. The research\naddresses the need to optimize identification and classification, which are\ncurrently performed manually by experts, being affected by human factors and\nfacing time challenges. The methodological process of this study includes the\ncapture of high-quality images using a mobile phone camera and a stereo\nmicroscope, followed by segmentation to reduce size and focus on relevant\nmorphological areas. The images were carefully labeled and preprocessed to\nensure the quality and consistency of the dataset used to train the pre-trained\nconvolutional neural network models VGG16, VGG19, and Inception-v3. The results\nwere evaluated using the F1-score, achieving 82% for VGG16 and VGG19, while\nInception-v3 reached an F1-score of 93%. Inception-v3's reliability was\nverified through model testing in uncontrolled environments, with positive\nresults, complemented by the Grad-CAM technique, demonstrating its ability to\ncapture essential morphological features. These findings indicate that\nInception-v3 is an effective and replicable approach for classifying Anastrepha\nfraterculus and Ceratitis capitata, with potential for implementation in\nautomated monitoring systems.",
      "tldr_zh": "本研究开发了一种基于迁移学习（transfer learning）的模型，用于自动分类两种果蝇（Anastrepha fraterculus 和 Ceratitis capitata），以解决传统手动识别受人为因素和时间限制的影响。方法包括使用手机相机和立体显微镜捕获图像，进行分割和预处理后，训练预训练的卷积神经网络模型（VGG16、VGG19 和 Inception-v3）。结果显示，Inception-v3 模型的 F1-score 达到 93%，优于 VGG16 和 VGG19 的 82%，并通过 Grad-CAM 技术验证了其捕捉关键形态特征的能力，为果蝇分类的自动化监测系统提供了一个有效且可复制的方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T10",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages and 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00939v1",
      "published_date": "2025-02-02 22:16:04 UTC",
      "updated_date": "2025-02-02 22:16:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:50:06.728087"
    },
    {
      "arxiv_id": "2502.00937v2",
      "title": "ModServe: Scalable and Resource-Efficient Large Multimodal Model Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Qiu",
        "Anish Biswas",
        "Zihan Zhao",
        "Jayashree Mohan",
        "Alind Khare",
        "Esha Choukse",
        "Íñigo Goiri",
        "Zeyu Zhang",
        "Haiying Shen",
        "Chetan Bansal",
        "Ramachandran Ramjee",
        "Rodrigo Fonseca"
      ],
      "abstract": "Large multimodal models (LMMs) demonstrate impressive capabilities in\nunderstanding images, videos, and audio beyond text. However, efficiently\nserving LMMs in production environments poses significant challenges due to\ntheir complex architectures and heterogeneous characteristics across their\nmulti-stage inference pipelines. We present the first comprehensive systems\nanalysis of two prominent LMM architectures, decoder-only and cross-attention,\nacross six representative open-source models, revealing key systems design\nimplications. We also present an in-depth analysis of production LMM inference\ntraces, uncovering unique workload characteristics, including variable,\nheavy-tailed request distributions and bursty traffic patterns. Based on these\ninsights, we propose ModServe, a modular LMM serving system that decouples\nstages for independent optimization and adaptive scaling. ModServe dynamically\nreconfigures stages and handles bursty traffic with modality-aware scheduling\nand autoscaling to meet tail latency SLOs while minimizing costs. ModServe\nachieves 3.3-5.5x higher throughput (leading to 25-41.3% cost saving) while\nmeeting SLOs on a 128-GPU cluster with production traces.",
      "tldr_zh": "该研究分析了大型多模态模型 (LMMs) 在生产环境中的服务挑战，包括复杂架构（如 decoder-only 和 cross-attention）和多阶段推理管道，并通过对六个开源模型和生产推理跟踪的深入分析，揭示了可变的、重尾分布的请求和突发流量特点。基于这些洞察，论文提出 ModServe，一种模块化的 LMM 服务系统，通过解耦阶段、动态重新配置以及模态感知调度和自动缩放，实现了对突发流量的有效处理。实验结果显示，ModServe 在 128-GPU 集群上实现了 3.3-5.5 倍的吞吐量提升，同时满足尾部延迟服务水平目标 (SLOs)，并节省 25-41.3% 的成本。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00937v2",
      "published_date": "2025-02-02 22:10:40 UTC",
      "updated_date": "2025-03-21 16:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:49:14.080349"
    },
    {
      "arxiv_id": "2502.00919v1",
      "title": "Attention Sinks and Outlier Features: A 'Catch, Tag, and Release' Mechanism for Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Zhang",
        "Mustafa Khan",
        "Vardan Papyan"
      ],
      "abstract": "Two prominent features of large language models (LLMs) is the presence of\nlarge-norm (outlier) features and the tendency for tokens to attend very\nstrongly to a select few tokens. Despite often having no semantic relevance,\nthese select tokens, called attention sinks, along with the large outlier\nfeatures, have proven important for model performance, compression, and\nstreaming. Consequently, investigating the roles of these phenomena within\nmodels and exploring how they might manifest in the model parameters has become\nan area of active interest. Through an empirical investigation, we demonstrate\nthat attention sinks utilize outlier features to: catch a sequence of tokens,\ntag the captured tokens by applying a common perturbation, and then release the\ntokens back into the residual stream, where the tagged tokens are eventually\nretrieved. We prove that simple tasks, like averaging, necessitate the 'catch,\ntag, release' mechanism hence explaining why it would arise organically in\nmodern LLMs. Our experiments also show that the creation of attention sinks can\nbe completely captured in the model parameters using low-rank matrices, which\nhas important implications for model compression and substantiates the success\nof recent approaches that incorporate a low-rank term to offset performance\ndegradation.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)中的attention sinks和outlier features，提出一种“catch, tag, and release”机制，解释这些现象如何捕获序列token、标记它们并释放回residual stream，从而提升模型性能和压缩效率。通过实证调查和实验，作者证明此机制在简单任务如平均化中是必需的，并在现代LLMs中自然出现。结果显示，attention sinks的创建可完全用低-rank matrices在模型参数中捕获，这为模型压缩技术提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00919v1",
      "published_date": "2025-02-02 21:15:07 UTC",
      "updated_date": "2025-02-02 21:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:49:24.184251"
    },
    {
      "arxiv_id": "2502.00903v2",
      "title": "Embracing Dialectic Intersubjectivity: Coordination of Different Perspectives in Content Analysis with LLM Persona Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Taewoo Kang",
        "Kjerstin Thorson",
        "Tai-Quan Peng",
        "Dan Hiaeshutter-Rice",
        "Sanguk Lee",
        "Stuart Soroka"
      ],
      "abstract": "This study attempts to advancing content analysis methodology from\nconsensus-oriented to coordination-oriented practices, thereby embracing\ndiverse coding outputs and exploring the dynamics among differential\nperspectives. As an exploratory investigation of this approach, we evaluate six\nGPT-4o configurations to analyze sentiment in Fox News and MSNBC transcripts on\nBiden and Trump during the 2020 U.S. presidential campaign, examining patterns\nacross these models. By assessing each model's alignment with ideological\nperspectives, we explore how partisan selective processing could be identified\nin LLM-Assisted Content Analysis (LACA). Findings reveal that partisan persona\nLLMs exhibit stronger ideological biases when processing politically congruent\ncontent. Additionally, intercoder reliability is higher among same-partisan\npersonas compared to cross-partisan pairs. This approach enhances the nuanced\nunderstanding of LLM outputs and advances the integrity of AI-driven social\nscience research, enabling simulations of real-world implications.",
      "tldr_zh": "这篇论文提出了一种从共识导向转向协调导向的内容分析方法，通过LLM人格模拟来拥抱不同视角的动态，旨在探索差异性编码输出的价值。研究者评估了六个GPT-4o配置，对Fox News和MSNBC关于2020年美国总统竞选的Biden和Trump转录文本进行情感分析，并检查这些模型与意识形态视角的契合度，以识别LLM-Assisted Content Analysis (LACA)中的党派选择性处理。发现显示，党派人格LLMs在处理政治一致内容时表现出更强的意识形态偏见，而同党派人格间的intercoder reliability高于跨党派对；这一方法提升了对LLM输出的细微理解，并增强了AI驱动社会科学研究的完整性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00903v2",
      "published_date": "2025-02-02 20:29:10 UTC",
      "updated_date": "2025-02-04 16:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:49:37.482022"
    },
    {
      "arxiv_id": "2502.00894v1",
      "title": "MorphBPE: A Morpho-Aware Tokenizer Bridging Linguistic Complexity for Efficient LLM Training Across Morphologies",
      "title_zh": "MorphBPE：一种形态感知分词器，桥接语言复杂性以实现跨越不同形态学的高效LLM训练",
      "authors": [
        "Ehsaneddin Asgari",
        "Yassine El Kheir",
        "Mohammad Ali Sadraei Javaheri"
      ],
      "abstract": "Tokenization is fundamental to Natural Language Processing (NLP), directly\nimpacting model efficiency and linguistic fidelity. While Byte Pair Encoding\n(BPE) is widely used in Large Language Models (LLMs), it often disregards\nmorpheme boundaries, leading to suboptimal segmentation, particularly in\nmorphologically rich languages. We introduce MorphBPE, a morphology-aware\nextension of BPE that integrates linguistic structure into subword tokenization\nwhile preserving statistical efficiency. Additionally, we propose two\nmorphology-based evaluation metrics: (i) Morphological Consistency F1-Score,\nwhich quantifies the consistency between morpheme sharing and token sharing,\ncontributing to LLM training convergence, and (ii) Morphological Edit Distance,\nwhich measures alignment between morphemes and tokens concerning\ninterpretability. Experiments on English, Russian, Hungarian, and Arabic across\n300M and 1B parameter LLMs demonstrate that MorphBPE consistently reduces\ncross-entropy loss, accelerates convergence, and improves morphological\nalignment scores. Fully compatible with existing LLM pipelines, MorphBPE\nrequires minimal modifications for integration. The MorphBPE codebase and\ntokenizer playground will be available at:\nhttps://github.com/llm-lab-org/MorphBPE and https://tokenizer.llm-lab.org",
      "tldr_zh": "该论文介绍了 MorphBPE，一种基于 BPE 的形态感知分词器（morphology-aware extension），它通过整合语言结构来优化子词分词，尤其适用于形态丰富的语言，从而提升 Large Language Models (LLMs) 的训练效率。论文还提出了两个新评估指标：Morphological Consistency F1-Score（量化词素共享与分词共享的一致性，以促进 LLM 训练收敛）和 Morphological Edit Distance（衡量词素与分词的对齐度，以提升可解释性）。在英语、俄语、匈牙利语和阿拉伯语上的实验显示，MorphBPE 在 300M 和 1B 参数的 LLMs 中显著降低了交叉熵损失、加速了收敛并改善了形态对齐分数，同时保持与现有 LLM 管道的兼容性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00894v1",
      "published_date": "2025-02-02 20:06:39 UTC",
      "updated_date": "2025-02-02 20:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:49:49.535987"
    },
    {
      "arxiv_id": "2502.00874v1",
      "title": "Paper Copilot: The Artificial Intelligence and Machine Learning Community Should Adopt a More Transparent and Regulated Peer Review Process",
      "title_zh": "Paper Copilot：人工智能和机器学习社区应采用更透明和规范的同行评审过程",
      "authors": [
        "Jing Yang"
      ],
      "abstract": "The rapid growth of submissions to top-tier Artificial Intelligence (AI) and\nMachine Learning (ML) conferences has prompted many venues to transition from\nclosed to open review platforms. Some have fully embraced open peer reviews,\nallowing public visibility throughout the process, while others adopt hybrid\napproaches, such as releasing reviews only after final decisions or keeping\nreviews private despite using open peer review systems. In this work, we\nanalyze the strengths and limitations of these models, highlighting the growing\ncommunity interest in transparent peer review. To support this discussion, we\nexamine insights from Paper Copilot, a website launched two years ago to\naggregate and analyze AI / ML conference data while engaging a global audience.\nThe site has attracted over 200,000 early-career researchers, particularly\nthose aged 18-34 from 177 countries, many of whom are actively engaged in the\npeer review process. Drawing on our findings, this position paper advocates for\na more transparent, open, and well-regulated peer review aiming to foster\ngreater community involvement and propel advancements in the field.",
      "tldr_zh": "这篇论文主张人工智能（AI）和机器学习（ML）社区应采用更透明和规范的同行评审过程，以应对顶会提交量快速增长的挑战。作者分析了不同评审模式（如完全公开、混合或私有）的优缺点，并基于 Paper Copilot 网站的数据，该网站聚合AI/ML会议信息并吸引了超过20万早期研究者（主要是18-34岁人群来自177个国家），展示了社区对透明评审的浓厚兴趣。通过这些发现，论文呼吁实施更开放和受监管的评审机制，以提升社区参与度和推动领域创新。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00874v1",
      "published_date": "2025-02-02 18:58:08 UTC",
      "updated_date": "2025-02-02 18:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:50:08.003640"
    },
    {
      "arxiv_id": "2502.00873v1",
      "title": "Language Models Use Trigonometry to Do Addition",
      "title_zh": "语言模型使用三角学",
      "authors": [
        "Subhash Kantamneni",
        "Max Tegmark"
      ],
      "abstract": "Mathematical reasoning is an increasingly important indicator of large\nlanguage model (LLM) capabilities, yet we lack understanding of how LLMs\nprocess even simple mathematical tasks. To address this, we reverse engineer\nhow three mid-sized LLMs compute addition. We first discover that numbers are\nrepresented in these LLMs as a generalized helix, which is strongly causally\nimplicated for the tasks of addition and subtraction, and is also causally\nrelevant for integer division, multiplication, and modular arithmetic. We then\npropose that LLMs compute addition by manipulating this generalized helix using\nthe \"Clock\" algorithm: to solve $a+b$, the helices for $a$ and $b$ are\nmanipulated to produce the $a+b$ answer helix which is then read out to model\nlogits. We model influential MLP outputs, attention head outputs, and even\nindividual neuron preactivations with these helices and verify our\nunderstanding with causal interventions. By demonstrating that LLMs represent\nnumbers on a helix and manipulate this helix to perform addition, we present\nthe first representation-level explanation of an LLM's mathematical capability.",
      "tldr_zh": "该研究通过逆向工程分析三个中型大型语言模型(LLMs)，发现数字被表示为广义螺旋(generalized helix)，这种表示在加法、减法以及除法、乘法和模运算中发挥关键作用。\n研究人员提出LLMs使用“Clock”算法进行加法运算：通过操作a和b的螺旋来生成a+b的答案螺旋，并读取输出转化为模型预测。\n他们通过建模MLP输出、注意力头输出和神经元预激活，并进行因果干预验证，证实了这一机制。\n这项工作首次提供了LLMs数学能力的表示级别解释，深化了对模型内部处理简单数学任务的理解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00873v1",
      "published_date": "2025-02-02 18:55:26 UTC",
      "updated_date": "2025-02-02 18:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:50:13.386217"
    },
    {
      "arxiv_id": "2502.00870v1",
      "title": "FedHPD: Heterogeneous Federated Reinforcement Learning via Policy Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenzheng Jiang",
        "Ji Wang",
        "Xiongtao Zhang",
        "Weidong Bao",
        "Cheston Tan",
        "Flint Xiaofeng Fan"
      ],
      "abstract": "Federated Reinforcement Learning (FedRL) improves sample efficiency while\npreserving privacy; however, most existing studies assume homogeneous agents,\nlimiting its applicability in real-world scenarios. This paper investigates\nFedRL in black-box settings with heterogeneous agents, where each agent employs\ndistinct policy networks and training configurations without disclosing their\ninternal details. Knowledge Distillation (KD) is a promising method for\nfacilitating knowledge sharing among heterogeneous models, but it faces\nchallenges related to the scarcity of public datasets and limitations in\nknowledge representation when applied to FedRL. To address these challenges, we\npropose Federated Heterogeneous Policy Distillation (FedHPD), which solves the\nproblem of heterogeneous FedRL by utilizing action probability distributions as\na medium for knowledge sharing. We provide a theoretical analysis of FedHPD's\nconvergence under standard assumptions. Extensive experiments corroborate that\nFedHPD shows significant improvements across various reinforcement learning\nbenchmark tasks, further validating our theoretical findings. Moreover,\nadditional experiments demonstrate that FedHPD operates effectively without the\nneed for an elaborate selection of public datasets.",
      "tldr_zh": "这篇论文针对 Federated Reinforcement Learning (FedRL) 中的异质代理问题，提出了一种新框架 FedHPD，通过 Policy Distillation 利用动作概率分布作为知识共享媒介，解决了 Knowledge Distillation (KD) 在黑箱设置下的挑战，如公共数据集稀缺和知识表示限制。FedHPD 提供了收敛性的理论分析，并在各种强化学习基准任务上实验证明了显著性能提升。额外实验进一步验证，该方法无需精心选择的公共数据集即可有效运行，从而提升了 FedRL 在现实世界的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "This preprint presents the full version of the Extended Abstract\n  accepted by AAMAS 2025, including all the proofs and experiments",
      "pdf_url": "http://arxiv.org/pdf/2502.00870v1",
      "published_date": "2025-02-02 18:44:08 UTC",
      "updated_date": "2025-02-02 18:44:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:50:25.209618"
    },
    {
      "arxiv_id": "2502.01694v2",
      "title": "Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Juno Kim",
        "Denny Wu",
        "Jason Lee",
        "Taiji Suzuki"
      ],
      "abstract": "A key paradigm to improve the reasoning capabilities of large language models\n(LLMs) is to allocate more inference-time compute to search against a verifier\nor reward model. This process can then be utilized to refine the pretrained\nmodel or distill its reasoning patterns into more efficient models. In this\npaper, we study inference-time compute by viewing chain-of-thought (CoT)\ngeneration as a metastable Markov process: easy reasoning steps (e.g.,\nalgebraic manipulations) form densely connected clusters, while hard reasoning\nsteps (e.g., applying a relevant theorem) create sparse, low-probability edges\nbetween clusters, leading to phase transitions at longer timescales. Under this\nframework, we prove that implementing a search protocol that rewards sparse\nedges improves CoT by decreasing the expected number of steps to reach\ndifferent clusters. In contrast, we establish a limit on reasoning capability\nwhen the model is restricted to local information of the pretrained graph. We\nalso show that the information gained by search can be utilized to obtain a\nbetter reasoning model: (1) the pretrained model can be directly finetuned to\nfavor sparse edges via policy gradient methods, and moreover (2) a compressed\nmetastable representation of the reasoning dynamics can be distilled into a\nsmaller, more efficient model.",
      "tldr_zh": "这篇论文将 Chain-of-Thought (CoT) 推理建模为一个 metastable Markov 过程，证明了通过搜索奖励稀疏边（如应用定理的步骤）可以减少到达不同推理集群的预期步骤数，从而提升大型语言模型 (LLMs) 的推理能力。相比之下，依赖预训练图的局部信息会限制模型的整体性能。论文进一步证明，利用搜索获得的知识可以通过强化学习 (RL) 直接微调预训练模型，或通过蒸馏压缩的 metastable 表示来创建更小、更高效的推理模型。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "55 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01694v2",
      "published_date": "2025-02-02 18:19:14 UTC",
      "updated_date": "2025-03-01 10:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:50:37.607272"
    },
    {
      "arxiv_id": "2503.04734v1",
      "title": "What can large language models do for sustainable food?",
      "title_zh": "大语言模型能为可持续食品做什么？",
      "authors": [
        "Anna T. Thomas",
        "Adam Yee",
        "Andrew Mayne",
        "Maya B. Mathur",
        "Dan Jurafsky",
        "Kristina Gligorić"
      ],
      "abstract": "Food systems are responsible for a third of human-caused greenhouse gas\nemissions. We investigate what Large Language Models (LLMs) can contribute to\nreducing the environmental impacts of food production. We define a typology of\ndesign and prediction tasks based on the sustainable food literature and\ncollaboration with domain experts, and evaluate six LLMs on four tasks in our\ntypology. For example, for a sustainable protein design task, food science\nexperts estimated that collaboration with an LLM can reduce time spent by 45%\non average, compared to 22% for collaboration with another expert human food\nscientist. However, for a sustainable menu design task, LLMs produce suboptimal\nsolutions when instructed to consider both human satisfaction and climate\nimpacts. We propose a general framework for integrating LLMs with combinatorial\noptimization to improve reasoning capabilities. Our approach decreases\nemissions of food choices by 79% in a hypothetical restaurant while maintaining\nparticipants' satisfaction with their set of choices. Our results demonstrate\nLLMs' potential, supported by optimization techniques, to accelerate\nsustainable food development and adoption.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在减少食品生产环境影响方面的潜力，定义了基于可持续食品文献和专家合作的任务类型，并评估了六种LLMs在四种设计和预测任务上的表现。研究发现，对于可持续蛋白质设计任务，与LLMs合作可将专家时间减少45%，远高于与其他人类专家的22%；然而，在可持续菜单设计任务中，LLMs在平衡人类满意度和气候影响时会产生次优解决方案。作者提出一个整合LLMs与组合优化的通用框架，通过实验证明该方法能在假设餐厅场景中将食品选择的排放减少79%，同时维持参与者的满意度。总体结果显示，LLMs结合优化技术有潜力加速可持续食品的发展和采用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04734v1",
      "published_date": "2025-02-02 18:12:16 UTC",
      "updated_date": "2025-02-02 18:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:50:50.175880"
    },
    {
      "arxiv_id": "2502.00865v2",
      "title": "Predicting potentially abusive clauses in Chilean terms of services with natural language processing",
      "title_zh": "使用自然语言处理",
      "authors": [
        "Christoffer Loeffler",
        "Andrea Martínez Freile",
        "Tomás Rey Pizarro"
      ],
      "abstract": "This study addresses the growing concern of information asymmetry in consumer\ncontracts, exacerbated by the proliferation of online services with complex\nTerms of Service that are rarely even read. Even though research on automatic\nanalysis methods is conducted, the problem is aggravated by the general focus\non English-language Machine Learning approaches and on major jurisdictions,\nsuch as the European Union. We introduce a new methodology and a substantial\ndataset addressing this gap. We propose a novel annotation scheme with four\ncategories and a total of 20 classes, and apply it on 50 online Terms of\nService used in Chile. Our evaluation of transformer-based models highlights\nhow factors like language- and/or domain-specific pre-training, few-shot sample\nsize, and model architecture affect the detection and classification of\npotentially abusive clauses. Results show a large variability in performance\nfor the different tasks and models, with the highest macro-F1 scores for the\ndetection task ranging from 79% to 89% and micro-F1 scores up to 96%, while\nmacro-F1 scores for the classification task range from 60% to 70% and micro-F1\nscores from 64% to 80%. Notably, this is the first Spanish-language multi-label\nclassification dataset for legal clauses, applying Chilean law and offering a\ncomprehensive evaluation of Spanish-language models in the legal domain. Our\nwork lays the ground for future research in method development for rarely\nconsidered legal analysis and potentially leads to practical applications to\nsupport consumers in Chile and Latin America as a whole.",
      "tldr_zh": "这篇论文针对智利在线服务条款中的信息不对称问题，提出了一种新的自然语言处理方法，以检测和分类潜在滥用条款。研究者创建了一个新的标注方案（包括4个类别和20个类），并基于50个智利服务条款构建了首个西班牙语多标签分类数据集，使用Transformer-based模型评估了语言和领域特定预训练、样本大小等因素的影响。结果显示，检测任务的宏F1分数达79%-89%、微F1高达96%，而分类任务的宏F1为60%-70%、微F1为64%-80%，突显了模型在西班牙语法律领域的性能差异。该工作为未来法律分析方法的发展和消费者支持应用奠定了基础，特别是针对智利和拉丁美洲地区。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages, 2 figures, 8 tables, accepted for publication",
      "pdf_url": "http://arxiv.org/pdf/2502.00865v2",
      "published_date": "2025-02-02 18:01:39 UTC",
      "updated_date": "2025-05-05 18:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:51:01.984762"
    },
    {
      "arxiv_id": "2502.01693v2",
      "title": "Predicting Steady-State Behavior in Complex Networks with Graph Neural Networks",
      "title_zh": "使用图神经网络预测复杂网络中的稳态行为",
      "authors": [
        "Priodyuti Pradhan",
        "Amit Reza"
      ],
      "abstract": "In complex systems, information propagation can be defined as diffused or\ndelocalized, weakly localized, and strongly localized. This study investigates\nthe application of graph neural network models to learn the behavior of a\nlinear dynamical system on networks. A graph convolution and attention-based\nneural network framework has been developed to identify the steady-state\nbehavior of the linear dynamical system. We reveal that our trained model\ndistinguishes the different states with high accuracy. Furthermore, we have\nevaluated model performance with real-world data. In addition, to understand\nthe explainability of our model, we provide an analytical derivation for the\nforward and backward propagation of our framework.",
      "tldr_zh": "这篇论文探讨了使用Graph Neural Networks预测复杂网络中线性动力系统的稳态行为，专注于信息传播的三种状态：diffused or delocalized、weakly localized和strongly localized。研究开发了一个基于图卷积和注意力机制的框架，能够高准确率区分这些状态，并通过真实世界数据验证了模型性能。论文还提供了框架的前向和后向传播的分析推导，以增强模型的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "nlin.AO"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01693v2",
      "published_date": "2025-02-02 17:29:10 UTC",
      "updated_date": "2025-02-07 17:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:51:12.827045"
    },
    {
      "arxiv_id": "2502.01692v5",
      "title": "Fast Direct: Query-Efficient Online Black-box Guidance for Diffusion-model Target Generation",
      "title_zh": "Fast Direct：查询高效的在线黑箱指导，用于扩散模型目标生成",
      "authors": [
        "Kim Yong Tan",
        "Yueming Lyu",
        "Ivor Tsang",
        "Yew-Soon Ong"
      ],
      "abstract": "Guided diffusion-model generation is a promising direction for customizing\nthe generation process of a pre-trained diffusion model to address specific\ndownstream tasks. Existing guided diffusion models either rely on training the\nguidance model with pre-collected datasets or require the objective functions\nto be differentiable. However, for most real-world tasks, offline datasets are\noften unavailable, and their objective functions are often not differentiable,\nsuch as image generation with human preferences, molecular generation for drug\ndiscovery, and material design. Thus, we need an $\\textbf{online}$ algorithm\ncapable of collecting data during runtime and supporting a $\\textbf{black-box}$\nobjective function. Moreover, the $\\textbf{query efficiency}$ of the algorithm\nis also critical because the objective evaluation of the query is often\nexpensive in real-world scenarios. In this work, we propose a novel and simple\nalgorithm, $\\textbf{Fast Direct}$, for query-efficient online black-box target\ngeneration. Our Fast Direct builds a pseudo-target on the data manifold to\nupdate the noise sequence of the diffusion model with a universal direction,\nwhich is promising to perform query-efficient guided generation. Extensive\nexperiments on twelve high-resolution ($\\small {1024 \\times 1024}$) image\ntarget generation tasks and six 3D-molecule target generation tasks show\n$\\textbf{6}\\times$ up to $\\textbf{10}\\times$ query efficiency improvement and\n$\\textbf{11}\\times$ up to $\\textbf{44}\\times$ query efficiency improvement,\nrespectively. Our implementation is publicly available at:\nhttps://github.com/kimyong95/guide-stable-diffusion/tree/fast-direct",
      "tldr_zh": "该论文提出 Fast Direct，一种查询高效的在线黑箱引导算法，用于定制预训练 diffusion model 的生成过程，针对无离线数据集和不可微分目标函数的真实任务，如图像生成和分子设计。算法通过构建 pseudo-target 在数据流形上更新噪声序列，并采用通用方向进行引导生成，从而实现高效的数据收集和优化。实验结果显示，在 12 个高分辨率（1024×1024）图像任务和 6 个 3D 分子任务上，Fast Direct 分别实现了 6 倍至 10 倍和 11 倍至 44 倍的查询效率提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01692v5",
      "published_date": "2025-02-02 17:21:10 UTC",
      "updated_date": "2025-03-29 05:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:51:25.091954"
    },
    {
      "arxiv_id": "2502.00858v2",
      "title": "Learning to Plan with Personalized Preferences",
      "title_zh": "基于个性化偏好的规划学习",
      "authors": [
        "Manjie Xu",
        "Xinyi Yang",
        "Wei Liang",
        "Chi Zhang",
        "Yixin Zhu"
      ],
      "abstract": "Effective integration of AI agents into daily life requires them to\nunderstand and adapt to individual human preferences, particularly in\ncollaborative roles. Although recent studies on embodied intelligence have\nadvanced significantly, they typically adopt generalized approaches that\noverlook personal preferences in planning. We address this limitation by\ndeveloping agents that not only learn preferences from few demonstrations but\nalso learn to adapt their planning strategies based on these preferences. Our\nresearch leverages the observation that preferences, though implicitly\nexpressed through minimal demonstrations, can generalize across diverse\nplanning scenarios. To systematically evaluate this hypothesis, we introduce\nPreference-based Planning (PbP) benchmark, an embodied benchmark featuring\nhundreds of diverse preferences spanning from atomic actions to complex\nsequences. Our evaluation of SOTA methods reveals that while symbol-based\napproaches show promise in scalability, significant challenges remain in\nlearning to generate and execute plans that satisfy personalized preferences.\nWe further demonstrate that incorporating learned preferences as intermediate\nrepresentations in planning significantly improves the agent's ability to\nconstruct personalized plans. These findings establish preferences as a\nvaluable abstraction layer for adaptive planning, opening new directions for\nresearch in preference-guided plan generation and execution.",
      "tldr_zh": "本研究针对AI代理在规划中忽略个人偏好的问题，开发了能从少量演示中学习偏好并据此适应规划策略的代理。\n他们引入了Preference-based Planning (PbP)基准测试，涵盖数百种从原子动作到复杂序列的多样偏好，用于系统评估SOTA方法的性能。\n结果显示，符号-based方法虽具可扩展性，但生成和执行满足个性化偏好的计划仍具挑战；将学习到的偏好作为中间表示融入规划，能显著提升代理的个性化规划能力，为偏好引导的计划生成和执行开辟新方向。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00858v2",
      "published_date": "2025-02-02 17:16:25 UTC",
      "updated_date": "2025-03-11 15:22:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:51:37.391535"
    },
    {
      "arxiv_id": "2502.00855v1",
      "title": "Psychometric-Based Evaluation for Theorem Proving with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyu Zhang",
        "Yongwang Zhao",
        "Long Zhang",
        "Jilin Hu",
        "Xiaokun Luan",
        "Zhiwei Xu",
        "Feng Yang"
      ],
      "abstract": "Large language models (LLMs) for formal theorem proving have become a\nprominent research focus. At present, the proving ability of these LLMs is\nmainly evaluated through proof pass rates on datasets such as miniF2F. However,\nthis evaluation method overlooks the varying importance of theorems. As a\nresult, it fails to highlight the real performance disparities between LLMs and\nleads to high evaluation costs. This study proposes a psychometric-based\nevaluation method for theorem proving with LLMs, comprising two main\ncomponents: Dataset Annotation and Adaptive Evaluation. First, we propose a\nmetric calculation method to annotate the dataset with difficulty and\ndiscrimination metrics. Specifically, we annotate each theorem in the miniF2F\ndataset and grade them into varying difficulty levels according to the\nperformance of LLMs, resulting in an enhanced dataset: miniF2F-Graded.\nExperimental results show that the difficulty grading in miniF2F-Graded better\nreflects the theorem difficulty perceived by LLMs. Secondly, we design an\nadaptive evaluation method to dynamically select the most suitable theorems for\ntesting based on the annotated metrics and the real-time performance of LLMs.\nWe apply this method to evaluate 10 LLMs. The results show that our method\nfinely highlights the performance disparities between LLMs. It also reduces\nevaluation costs by using only 23% of the theorems in the dataset.",
      "tldr_zh": "本文提出了一种基于心理测量的评估方法，用于评估 Large Language Models (LLMs) 在定理证明中的性能，以解决现有方法（如基于 miniF2F 数据集的证明通过率）忽略定理重要性导致的评估不准确和高成本问题。方法包括 Dataset Annotation 和 Adaptive Evaluation 两个组件：先通过指标计算为 miniF2F 数据集标注难度和区分度，形成增强版数据集 miniF2F-Graded；然后动态选择最合适的定理进行测试。实验结果显示，该方法能更精细地突出 10 个 LLMs 之间的性能差异，并通过仅使用数据集的 23% 显著降低评估成本。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00855v1",
      "published_date": "2025-02-02 17:00:22 UTC",
      "updated_date": "2025-02-02 17:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:51:50.671753"
    },
    {
      "arxiv_id": "2502.01691v1",
      "title": "Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model",
      "title_zh": "基于代理的不确定性感知提升了使用开源大型语言模型的自动放射学报告标记",
      "authors": [
        "Hadas Ben-Atya",
        "Naama Gavrielov",
        "Zvi Badash",
        "Gili Focht",
        "Ruth Cytter-Kuint",
        "Talar Hagopian",
        "Dan Turner",
        "Moti Freiman"
      ],
      "abstract": "Reliable extraction of structured data from radiology reports using Large\nLanguage Models (LLMs) remains challenging, especially for complex, non-English\ntexts like Hebrew. This study introduces an agent-based uncertainty-aware\napproach to improve the trustworthiness of LLM predictions in medical\napplications. We analyzed 9,683 Hebrew radiology reports from Crohn's disease\npatients (from 2010 to 2023) across three medical centers. A subset of 512\nreports was manually annotated for six gastrointestinal organs and 15\npathological findings, while the remaining reports were automatically annotated\nusing HSMP-BERT. Structured data extraction was performed using Llama 3.1\n(Llama 3-8b-instruct) with Bayesian Prompt Ensembles (BayesPE), which employed\nsix semantically equivalent prompts to estimate uncertainty. An Agent-Based\nDecision Model integrated multiple prompt outputs into five confidence levels\nfor calibrated uncertainty and was compared against three entropy-based models.\nPerformance was evaluated using accuracy, F1 score, precision, recall, and\nCohen's Kappa before and after filtering high-uncertainty cases. The\nagent-based model outperformed the baseline across all metrics, achieving an F1\nscore of 0.3967, recall of 0.6437, and Cohen's Kappa of 0.3006. After filtering\nhigh-uncertainty cases (greater than or equal to 0.5), the F1 score improved to\n0.4787, and Kappa increased to 0.4258. Uncertainty histograms demonstrated\nclear separation between correct and incorrect predictions, with the\nagent-based model providing the most well-calibrated uncertainty estimates. By\nincorporating uncertainty-aware prompt ensembles and an agent-based decision\nmodel, this approach enhances the performance and reliability of LLMs in\nstructured data extraction from radiology reports, offering a more\ninterpretable and trustworthy solution for high-stakes medical applications.",
      "tldr_zh": "该研究提出了一种基于代理的 uncertainty-aware 方法，使用开源大型语言模型（LLMs）如 Llama 3-8b-instruct 来提升放射学报告的自动标注可靠性，特别是针对希伯来语等复杂文本。方法结合 Bayesian Prompt Ensembles (BayesPE) 通过六个语义等价提示估计不确定性，并使用 Agent-Based Decision Model 将输出整合成五个置信水平，与基于熵的模型进行比较。实验在9,683份 Crohn’s disease 患者放射学报告上进行，代理模型在准确率、F1 score（0.3967）、recall（0.6437）和 Cohen’s Kappa（0.3006）等指标上优于基线，且过滤高不确定性（≥0.5）后，F1 score 提升至0.4787 和 Kappa 至0.4258。该方法通过增强不确定性校准，提高了 LLMs 在医疗应用中的可解释性和可信度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01691v1",
      "published_date": "2025-02-02 16:57:03 UTC",
      "updated_date": "2025-02-02 16:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:52:03.426871"
    },
    {
      "arxiv_id": "2502.00850v2",
      "title": "Dual Alignment Maximin Optimization for Offline Model-based RL",
      "title_zh": "双重对齐最大最小优化用于离线基于模型的强化学习",
      "authors": [
        "Chi Zhou",
        "Wang Luo",
        "Haoran Li",
        "Congying Han",
        "Tiande Guo",
        "Zicheng Zhang"
      ],
      "abstract": "Offline reinforcement learning agents face significant deployment challenges\ndue to the synthetic-to-real distribution mismatch. While most prior research\nhas focused on improving the fidelity of synthetic sampling and incorporating\noff-policy mechanisms, the directly integrated paradigm often fails to ensure\nconsistent policy behavior in biased models and underlying environmental\ndynamics, which inherently arise from discrepancies between behavior and\nlearning policies. In this paper, we first shift the focus from model\nreliability to policy discrepancies while optimizing for expected returns, and\nthen self-consistently incorporate synthetic data, deriving a novel\nactor-critic paradigm, Dual Alignment Maximin Optimization (DAMO). It is a\nunified framework to ensure both model-environment policy consistency and\nsynthetic and offline data compatibility. The inner minimization performs dual\nconservative value estimation, aligning policies and trajectories to avoid\nout-of-distribution states and actions, while the outer maximization ensures\nthat policy improvements remain consistent with inner value estimates.\nEmpirical evaluations demonstrate that DAMO effectively ensures model and\npolicy alignments, achieving competitive performance across diverse benchmark\ntasks.",
      "tldr_zh": "这篇论文针对离线强化学习(Offline RL)中的合成到真实分布不匹配问题，提出了一种新的actor-critic框架Dual Alignment Maximin Optimization (DAMO)，它通过优化预期回报来关注政策差异，而不是模型可靠性。DAMO框架包括内层最小化进行双重保守价值估计，以校准政策和轨迹避免分布外状态和动作，以及外层最大化确保政策改进与价值估计一致，从而实现模型-环境政策一致性和数据兼容性。实验评估表明，DAMO在多样化基准任务上表现出色，实现了竞争性性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00850v2",
      "published_date": "2025-02-02 16:47:35 UTC",
      "updated_date": "2025-05-10 04:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:52:13.167788"
    },
    {
      "arxiv_id": "2502.00847v1",
      "title": "SecPE: Secure Prompt Ensembling for Private and Robust Large Language Models",
      "title_zh": "SecPE",
      "authors": [
        "Jiawen Zhang",
        "Kejia Chen",
        "Zunlei Feng",
        "Jian Lou",
        "Mingli Song",
        "Jian Liu",
        "Xiaohu Yang"
      ],
      "abstract": "With the growing popularity of LLMs among the general public users,\nprivacy-preserving and adversarial robustness have become two pressing demands\nfor LLM-based services, which have largely been pursued separately but rarely\njointly. In this paper, to the best of our knowledge, we are among the first\nattempts towards robust and private LLM inference by tightly integrating two\ndisconnected fields: private inference and prompt ensembling. The former\nprotects users' privacy by encrypting inference data transmitted and processed\nby LLMs, while the latter enhances adversarial robustness by yielding an\naggregated output from multiple prompted LLM responses. Although widely\nrecognized as effective individually, private inference for prompt ensembling\ntogether entails new challenges that render the naive combination of existing\ntechniques inefficient. To overcome the hurdles, we propose SecPE, which\ndesigns efficient fully homomorphic encryption (FHE) counterparts for the core\nalgorithmic building blocks of prompt ensembling. We conduct extensive\nexperiments on 8 tasks to evaluate the accuracy, robustness, and efficiency of\nSecPE. The results show that SecPE maintains high clean accuracy and offers\nbetter robustness at the expense of merely $2.5\\%$ efficiency overhead compared\nto baseline private inference methods, indicating a satisfactory\n``accuracy-robustness-efficiency'' tradeoff. For the efficiency of the\nencrypted Argmax operation that incurs major slowdown for prompt ensembling,\nSecPE is 35.4x faster than the state-of-the-art peers, which can be of\nindependent interest beyond this work.",
      "tldr_zh": "本文提出SecPE框架，通过整合私有推理(private inference)和提示集成(prompt ensembling)，首次实现Large Language Models (LLMs)的隐私保护和对抗鲁棒性。SecPE利用高效的全同态加密(FHE)来优化提示集成的核心算法块，解决传统方法的效率挑战。实验在8个任务上显示，SecPE保持高准确率，提供更好的鲁棒性，仅增加2.5%的效率开销，且加密Argmax操作比现有方法快35.4倍，实现了出色的“准确率-鲁棒性-效率”权衡。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00847v1",
      "published_date": "2025-02-02 16:40:21 UTC",
      "updated_date": "2025-02-02 16:40:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:52:25.190203"
    },
    {
      "arxiv_id": "2502.00840v1",
      "title": "Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawen Zhang",
        "Kejia Chen",
        "Lipeng He",
        "Jian Lou",
        "Dan Li",
        "Zunlei Feng",
        "Mingli Song",
        "Jian Liu",
        "Kui Ren",
        "Xiaohu Yang"
      ],
      "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities across\nvarious domains. Accompanying the evolving capabilities and expanding\ndeployment scenarios of LLMs, their deployment challenges escalate due to their\nsheer scale and the advanced yet complex activation designs prevalent in\nnotable model series, such as Llama, Gemma, and Mistral. These challenges have\nbecome particularly pronounced in resource-constrained deployment scenarios,\nwhere mitigating inference efficiency bottlenecks is imperative. Among various\nrecent efforts, activation approximation has emerged as a promising avenue for\npursuing inference efficiency, sometimes considered indispensable in\napplications such as private inference. Despite achieving substantial speedups\nwith minimal impact on utility, even appearing sound and practical for\nreal-world deployment, the safety implications of activation approximations\nremain unclear. In this work, we fill this critical gap in LLM safety by\nconducting the first systematic safety evaluation of activation approximations.\nOur safety vetting spans seven sota techniques across three popular categories,\nrevealing consistent safety degradation across ten safety-aligned LLMs.",
      "tldr_zh": "本研究分析了激活近似(activation approximations)技术在对齐的大型语言模型(LLMs)中的潜在安全风险，尽管该技术能显著提升推理效率并适用于资源受限场景。该团队进行了首次系统性安全评估，涵盖七种最先进的技术和三个流行类别，并在十个安全对齐的LLMs上进行测试。结果显示，激活近似会导致一致的安全退化，揭示了其在实际部署中的隐患，并为未来防御策略提供了重要基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.00840v1",
      "published_date": "2025-02-02 16:25:48 UTC",
      "updated_date": "2025-02-02 16:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:52:37.288915"
    },
    {
      "arxiv_id": "2502.00837v1",
      "title": "Explainability in Practice: A Survey of Explainable NLP Across Various Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Hadi Mohammadi",
        "Ayoub Bagheri",
        "Anastasia Giachanou",
        "Daniel L. Oberski"
      ],
      "abstract": "Natural Language Processing (NLP) has become a cornerstone in many critical\nsectors, including healthcare, finance, and customer relationship management.\nThis is especially true with the development and use of advanced models such as\nGPT-based architectures and BERT, which are widely used in decision-making\nprocesses. However, the black-box nature of these advanced NLP models has\ncreated an urgent need for transparency and explainability. This review\nexplores explainable NLP (XNLP) with a focus on its practical deployment and\nreal-world applications, examining its implementation and the challenges faced\nin domain-specific contexts. The paper underscores the importance of\nexplainability in NLP and provides a comprehensive perspective on how XNLP can\nbe designed to meet the unique demands of various sectors, from healthcare's\nneed for clear insights to finance's emphasis on fraud detection and risk\nassessment. Additionally, this review aims to bridge the knowledge gap in XNLP\nliterature by offering a domain-specific exploration and discussing\nunderrepresented areas such as real-world applicability, metric evaluation, and\nthe role of human interaction in model assessment. The paper concludes by\nsuggesting future research directions that could enhance the understanding and\nbroader application of XNLP.",
      "tldr_zh": "这篇综述探讨了可解释自然语言处理（XNLP）的实际应用，聚焦于其在医疗、金融和客户关系管理等领域的部署，强调了应对先进模型如 GPT 和 BERT 的黑箱问题以提升透明性和决策可靠性。论文分析了XNLP在不同领域的具体挑战和实现方式，包括医疗的清晰洞察需求、金融的欺诈检测和风险评估，并桥接了文献中的知识差距，如指标评估和人类交互的作用。最终，论文提出未来研究方向，以增强XNLP的理解和更广泛的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00837v1",
      "published_date": "2025-02-02 16:18:44 UTC",
      "updated_date": "2025-02-02 16:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:52:49.464512"
    },
    {
      "arxiv_id": "2502.00828v1",
      "title": "Decision-informed Neural Networks with Large Language Model Integration for Portfolio Optimization",
      "title_zh": "决策告知神经网络：结合大语言模型用于投资组合",
      "authors": [
        "Yoontae Hwang",
        "Yaxuan Kong",
        "Stefan Zohren",
        "Yongjae Lee"
      ],
      "abstract": "This paper addresses the critical disconnect between prediction and decision\nquality in portfolio optimization by integrating Large Language Models (LLMs)\nwith decision-focused learning. We demonstrate both theoretically and\nempirically that minimizing the prediction error alone leads to suboptimal\nportfolio decisions. We aim to exploit the representational power of LLMs for\ninvestment decisions. An attention mechanism processes asset relationships,\ntemporal dependencies, and macro variables, which are then directly integrated\ninto a portfolio optimization layer. This enables the model to capture complex\nmarket dynamics and align predictions with the decision objectives. Extensive\nexperiments on S\\&P100 and DOW30 datasets show that our model consistently\noutperforms state-of-the-art deep learning models. In addition, gradient-based\nanalyses show that our model prioritizes the assets most crucial to decision\nmaking, thus mitigating the effects of prediction errors on portfolio\nperformance. These findings underscore the value of integrating decision\nobjectives into predictions for more robust and context-aware portfolio\nmanagement.",
      "tldr_zh": "这篇论文提出了一种决策导向的神经网络框架，通过整合Large Language Models (LLMs)来解决投资组合优化中预测错误导致决策次优的问题。模型利用注意力机制处理资产关系、时间依赖性和宏观变量，并直接与投资组合优化层结合，以捕捉复杂市场动态并使预测与决策目标一致。理论和实证分析证明，该方法显著优于传统深度学习模型，在S&P100和DOW30数据集上的实验中表现出色。梯度分析进一步显示，模型优先考虑对决策最重要的资产，从而减少预测错误对投资组合性能的影响，并提升整体管理稳健性。",
      "categories": [
        "q-fin.PM",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "q-fin.PM",
      "comment": "Submitted paper",
      "pdf_url": "http://arxiv.org/pdf/2502.00828v1",
      "published_date": "2025-02-02 15:45:21 UTC",
      "updated_date": "2025-02-02 15:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:53:01.119986"
    },
    {
      "arxiv_id": "2502.01689v1",
      "title": "scGSDR: Harnessing Gene Semantics for Single-Cell Pharmacological Profiling",
      "title_zh": "scGSDR：利用基因语义进行单细胞药物学剖析",
      "authors": [
        "Yu-An Huang",
        "Xiyue Cao",
        "Zhu-Hong You",
        "Yue-Chao Li",
        "Xuequn Shang",
        "Zhi-An Huang"
      ],
      "abstract": "The rise of single-cell sequencing technologies has revolutionized the\nexploration of drug resistance, revealing the crucial role of cellular\nheterogeneity in advancing precision medicine. By building computational models\nfrom existing single-cell drug response data, we can rapidly annotate cellular\nresponses to drugs in subsequent trials. To this end, we developed scGSDR, a\nmodel that integrates two computational pipelines grounded in the knowledge of\ncellular states and gene signaling pathways, both essential for understanding\nbiological gene semantics. scGSDR enhances predictive performance by\nincorporating gene semantics and employs an interpretability module to identify\nkey pathways contributing to drug resistance phenotypes. Our extensive\nvalidation, which included 16 experiments covering 11 drugs, demonstrates\nscGSDR's superior predictive accuracy, when trained with either bulk-seq or\nscRNA-seq data, achieving high AUROC, AUPR, and F1 Scores. The model's\napplication has extended from single-drug predictions to scenarios involving\ndrug combinations. Leveraging pathways of known drug target genes, we found\nthat scGSDR's cell-pathway attention scores are biologically interpretable,\nwhich helped us identify other potential drug-related genes. Literature review\nof top-ranking genes in our predictions such as BCL2, CCND1, the AKT family,\nand PIK3CA for PLX4720; and ICAM1, VCAM1, NFKB1, NFKBIA, and RAC1 for\nPaclitaxel confirmed their relevance. In conclusion, scGSDR, by incorporating\ngene semantics, enhances predictive modeling of cellular responses to diverse\ndrugs, proving invaluable for scenarios involving both single drug and\ncombination therapies and effectively identifying key resistance-related\npathways, thus advancing precision medicine and targeted therapy development.",
      "tldr_zh": "本文开发了 scGSDR 模型，通过整合基因语义（包括细胞状态和基因信号通路）的计算管道，提升了单细胞药物响应预测的性能，并加入可解释性模块来识别关键抵抗通路。模型在 16 个实验中覆盖 11 种药物时，展现出优越的预测准确率，如高 AUROC、AUPR 和 F1 Scores，并适用于单药和药物组合场景。scGSDR 通过细胞-通路注意力分数，成功识别潜在药物相关基因（如 BCL2、CCND1 和 PIK3CA），并经文献验证其生物学相关性，最终为精确医学和靶向治疗提供重要支持。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01689v1",
      "published_date": "2025-02-02 15:43:20 UTC",
      "updated_date": "2025-02-02 15:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:53:13.453022"
    },
    {
      "arxiv_id": "2502.00802v1",
      "title": "Fisher-Guided Selective Forgetting: Mitigating The Primacy Bias in Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Massimiliano Falzari",
        "Matthia Sabatelli"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) systems often tend to overfit to early\nexperiences, a phenomenon known as the primacy bias (PB). This bias can\nseverely hinder learning efficiency and final performance, particularly in\ncomplex environments. This paper presents a comprehensive investigation of PB\nthrough the lens of the Fisher Information Matrix (FIM). We develop a framework\ncharacterizing PB through distinct patterns in the FIM trace, identifying\ncritical memorization and reorganization phases during learning. Building on\nthis understanding, we propose Fisher-Guided Selective Forgetting (FGSF), a\nnovel method that leverages the geometric structure of the parameter space to\nselectively modify network weights, preventing early experiences from\ndominating the learning process. Empirical results across DeepMind Control\nSuite (DMC) environments show that FGSF consistently outperforms baselines,\nparticularly in complex tasks. We analyze the different impacts of PB on actor\nand critic networks, the role of replay ratios in exacerbating the effect, and\nthe effectiveness of even simple noise injection methods. Our findings provide\na deeper understanding of PB and practical mitigation strategies, offering a\nFIM-based geometric perspective for advancing DRL.",
      "tldr_zh": "本研究探讨了Deep Reinforcement Learning (DRL)中的primacy bias (PB)，即模型过度拟合早期经验导致的学习效率和性能下降问题，通过Fisher Information Matrix (FIM)分析其在FIM trace中的模式，识别关键记忆和重组阶段。提出Fisher-Guided Selective Forgetting (FGSF)方法，利用参数空间的几何结构选择性地修改网络权重，防止早期经验主导学习过程。在DeepMind Control Suite (DMC)环境中，FGSF比基线模型表现出色，尤其在复杂任务中提升了性能，并分析了PB对actor和critic网络的影响以及回放比率的作用。该方法为缓解PB提供了实用策略，并从FIM的几何视角推进DRL的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00802v1",
      "published_date": "2025-02-02 13:54:47 UTC",
      "updated_date": "2025-02-02 13:54:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:53:25.730599"
    },
    {
      "arxiv_id": "2502.00801v1",
      "title": "Environment-Driven Online LiDAR-Camera Extrinsic Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Huang",
        "Jiaqi Li",
        "Ping Zhong",
        "Rui Fan"
      ],
      "abstract": "LiDAR-camera extrinsic calibration (LCEC) is the core for data fusion in\ncomputer vision. Existing methods typically rely on customized calibration\ntargets or fixed scene types, lacking the flexibility to handle variations in\nsensor data and environmental contexts. This paper introduces EdO-LCEC, the\nfirst environment-driven, online calibration approach that achieves human-like\nadaptability. Inspired by the human perceptual system, EdO-LCEC incorporates a\ngeneralizable scene discriminator to actively interpret environmental\nconditions, creating multiple virtual cameras that capture detailed spatial and\ntextural information. To overcome cross-modal feature matching challenges\nbetween LiDAR and camera, we propose dual-path correspondence matching (DPCM),\nwhich leverages both structural and textural consistency to achieve reliable\n3D-2D correspondences. Our approach formulates the calibration process as a\nspatial-temporal joint optimization problem, utilizing global constraints from\nmultiple views and scenes to improve accuracy, particularly in sparse or\npartially overlapping sensor views. Extensive experiments on real-world\ndatasets demonstrate that EdO-LCEC achieves state-of-the-art performance,\nproviding reliable and precise calibration across diverse, challenging\nenvironments.",
      "tldr_zh": "本研究提出了一种环境驱动的在线 LiDAR-Camera Extrinsic Calibration 方法，名为 EdO-LCEC，以解决现有方法依赖自定义标定目标或固定场景的局限性。该方法受人类感知系统启发，引入一般化场景鉴别器和双路径对应匹配 (DPCM) 技术，通过创建多个虚拟相机并利用结构和纹理一致性，实现可靠的 3D-2D 对应匹配，并将标定过程表述为空间-时间联合优化问题，以提升多视图和场景下的准确性。在真实数据集上的广泛实验表明，EdO-LCEC 达到了最先进性能，在多样化挑战环境中提供可靠精确的标定。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00801v1",
      "published_date": "2025-02-02 13:52:35 UTC",
      "updated_date": "2025-02-02 13:52:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:53:36.483794"
    },
    {
      "arxiv_id": "2502.00792v1",
      "title": "RTBAgent: A LLM-based Agent System for Real-Time Bidding",
      "title_zh": "RTBAgent：一种基于LLM的实时竞价代理系统",
      "authors": [
        "Leng Cai",
        "Junxuan He",
        "Yikai Li",
        "Junjie Liang",
        "Yuanping Lin",
        "Ziming Quan",
        "Yawen Zeng",
        "Jin Xu"
      ],
      "abstract": "Real-Time Bidding (RTB) enables advertisers to place competitive bids on\nimpression opportunities instantaneously, striving for cost-effectiveness in a\nhighly competitive landscape. Although RTB has widely benefited from the\nutilization of technologies such as deep learning and reinforcement learning,\nthe reliability of related methods often encounters challenges due to the\ndiscrepancies between online and offline environments and the rapid\nfluctuations of online bidding. To handle these challenges, RTBAgent is\nproposed as the first RTB agent system based on large language models (LLMs),\nwhich synchronizes real competitive advertising bidding environments and\nobtains bidding prices through an integrated decision-making process.\nSpecifically, obtaining reasoning ability through LLMs, RTBAgent is further\ntailored to be more professional for RTB via involved auxiliary modules, i.e.,\nclick-through rate estimation model, expert strategy knowledge, and daily\nreflection. In addition, we propose a two-step decision-making process and\nmulti-memory retrieval mechanism, which enables RTBAgent to review historical\ndecisions and transaction records and subsequently make decisions more adaptive\nto market changes in real-time bidding. Empirical testing with real advertising\ndatasets demonstrates that RTBAgent significantly enhances profitability. The\nRTBAgent code will be publicly accessible at:\nhttps://github.com/CaiLeng/RTBAgent.",
      "tldr_zh": "该研究提出 RTBAgent，一种基于大型语言模型(LLMs)的代理系统，用于实时竞价(RTB)，旨在解决在线环境差异和市场波动带来的可靠性挑战。RTBAgent 利用 LLMs 的推理能力，结合辅助模块（如点击率估计模型、专家策略知识和日常反思）、两步决策过程以及多内存检索机制，帮助代理审阅历史决策并实时适应市场变化。实验结果显示，在真实广告数据集上，RTBAgent 显著提升了盈利能力，并计划在 GitHub 上公开代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00792v1",
      "published_date": "2025-02-02 13:10:15 UTC",
      "updated_date": "2025-02-02 13:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:53:48.584922"
    },
    {
      "arxiv_id": "2502.00779v1",
      "title": "Role of Mixup in Topological Persistence Based Knowledge Distillation for Wearable Sensor Data",
      "title_zh": "翻译失败",
      "authors": [
        "Eun Som Jeon",
        "Hongjun Choi",
        "Matthew P. Buman",
        "Pavan Turaga"
      ],
      "abstract": "The analysis of wearable sensor data has enabled many successes in several\napplications. To represent the high-sampling rate time-series with sufficient\ndetail, the use of topological data analysis (TDA) has been considered, and it\nis found that TDA can complement other time-series features. Nonetheless, due\nto the large time consumption and high computational resource requirements of\nextracting topological features through TDA, it is difficult to deploy\ntopological knowledge in various applications. To tackle this problem,\nknowledge distillation (KD) can be adopted, which is a technique facilitating\nmodel compression and transfer learning to generate a smaller model by\ntransferring knowledge from a larger network. By leveraging multiple teachers\nin KD, both time-series and topological features can be transferred, and\nfinally, a superior student using only time-series data is distilled. On the\nother hand, mixup has been popularly used as a robust data augmentation\ntechnique to enhance model performance during training. Mixup and KD employ\nsimilar learning strategies. In KD, the student model learns from the smoothed\ndistribution generated by the teacher model, while mixup creates smoothed\nlabels by blending two labels. Hence, this common smoothness serves as the\nconnecting link that establishes a connection between these two methods. In\nthis paper, we analyze the role of mixup in KD with time-series as well as\ntopological persistence, employing multiple teachers. We present a\ncomprehensive analysis of various methods in KD and mixup on wearable sensor\ndata.",
      "tldr_zh": "本研究探讨了Mixup在基于Topological Persistence的Knowledge Distillation (KD)中的作用，旨在解决可穿戴传感器数据分析中TDA（Topological Data Analysis）计算资源密集的问题。通过采用多教师KD框架，将时间序列和拓扑特征转移到仅使用时间序列数据的学生模型，实现模型压缩和知识转移。论文分析了Mixup作为数据增强技术如何通过标签平滑与KD的平滑学习策略相连，提升模型性能，并在可穿戴传感器数据上进行了全面的实验比较，展示了其潜在优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE Sensors Journal (2024)",
      "pdf_url": "http://arxiv.org/pdf/2502.00779v1",
      "published_date": "2025-02-02 12:33:52 UTC",
      "updated_date": "2025-02-02 12:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:53:59.809130"
    },
    {
      "arxiv_id": "2502.00767v1",
      "title": "Learning-Based TSP-Solvers Tend to Be Overly Greedy",
      "title_zh": "基于学习的 TSP 求解器倾向于过于贪婪",
      "authors": [
        "Xiayang Li",
        "Shihua Zhang"
      ],
      "abstract": "Deep learning has shown significant potential in solving combinatorial\noptimization problems such as the Euclidean traveling salesman problem (TSP).\nHowever, most training and test instances for existing TSP algorithms are\ngenerated randomly from specific distributions like uniform distribution. This\nhas led to a lack of analysis and understanding of the performance of deep\nlearning algorithms in out-of-distribution (OOD) generalization scenarios,\nwhich has a close relationship with the worst-case performance in the\ncombinatorial optimization field. For data-driven algorithms, the statistical\nproperties of randomly generated datasets are critical. This study constructs a\nstatistical measure called nearest-neighbor density to verify the asymptotic\nproperties of randomly generated datasets and reveal the greedy behavior of\nlearning-based solvers, i.e., always choosing the nearest neighbor nodes to\nconstruct the solution path. Based on this statistical measure, we develop\ninterpretable data augmentation methods that rely on distribution shifts or\ninstance perturbations and validate that the performance of the learning-based\nsolvers degenerates much on such augmented data. Moreover, fine-tuning\nlearning-based solvers with augmented data further enhances their\ngeneralization abilities. In short, we decipher the limitations of\nlearning-based TSP solvers tending to be overly greedy, which may have profound\nimplications for AI-empowered combinatorial optimization solvers.",
      "tldr_zh": "本文研究发现，基于深度学习的 TSP 求解器往往过度贪婪，导致在分布外 (OOD) 泛化场景下性能显著下降，特别是当数据集随机生成时。研究者引入 nearest-neighbor density 统计测量来分析数据集的渐近属性，并开发可解释的数据增强方法，如分布偏移或实例扰动，以验证求解器的贪婪行为。实验结果显示，在增强数据上求解器性能退化，但通过微调这些数据，能有效提升其泛化能力，为 AI 驱动的组合优化问题提供重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "90C27",
        "I.2.0; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00767v1",
      "published_date": "2025-02-02 12:06:13 UTC",
      "updated_date": "2025-02-02 12:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:54:13.080728"
    },
    {
      "arxiv_id": "2502.00757v2",
      "title": "AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds via Self-Improvement",
      "title_zh": "AgentBreeder：通过自我改进缓解多智能体脚手架的 AI 安全影响",
      "authors": [
        "J Rosser",
        "Jakob Nicolaus Foerster"
      ],
      "abstract": "Scaffolding Large Language Models (LLMs) into multi-agent systems often\nimproves performance on complex tasks, but the safety impact of such scaffolds\nhas not been thoroughly explored. We introduce AgentBreeder, a framework for\nmulti-objective self-improving evolutionary search over scaffolds. We evaluate\ndiscovered scaffolds on widely recognized reasoning, mathematics, and safety\nbenchmarks and compare them with popular baselines. In 'blue' mode, we see a\n79.4% average uplift in safety benchmark performance while maintaining or\nimproving capability scores. In 'red' mode, we find adversarially weak\nscaffolds emerging concurrently with capability optimization. Our work\ndemonstrates the risks of multi-agent scaffolding and provides a framework for\nmitigating them. Code is available at\nhttps://github.com/J-Rosser-UK/AgentBreeder.",
      "tldr_zh": "该研究探讨了将大型语言模型（LLMs）构建为多智能体系统可能带来的安全风险，并引入AgentBreeder框架，通过多目标自我改进进化搜索（multi-objective self-improving evolutionary search）来优化这些系统的支架（scaffolds）。在'blue'模式下，AgentBreeder使安全基准性能平均提升79.4%，同时维持或改善任务能力；在'red'模式下，优化能力时可能出现对抗性弱支架，揭示了潜在风险。该框架不仅展示了多智能体支架的安全挑战，还提供了有效的缓解策略，代码可从GitHub获取。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NE",
        "68T42, 68T50",
        "I.2.11"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00757v2",
      "published_date": "2025-02-02 11:40:07 UTC",
      "updated_date": "2025-04-14 10:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:54:24.779957"
    },
    {
      "arxiv_id": "2502.00752v1",
      "title": "Zero-Shot Warning Generation for Misinformative Multimodal Content",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Pio Delvecchio",
        "Huy Hong Nguyen",
        "Isao Echizen"
      ],
      "abstract": "The widespread prevalence of misinformation poses significant societal\nconcerns. Out-of-context misinformation, where authentic images are paired with\nfalse text, is particularly deceptive and easily misleads audiences. Most\nexisting detection methods primarily evaluate image-text consistency but often\nlack sufficient explanations, which are essential for effectively debunking\nmisinformation. We present a model that detects multimodal misinformation\nthrough cross-modality consistency checks, requiring minimal training time.\nAdditionally, we propose a lightweight model that achieves competitive\nperformance using only one-third of the parameters. We also introduce a\ndual-purpose zero-shot learning task for generating contextualized warnings,\nenabling automated debunking and enhancing user comprehension. Qualitative and\nhuman evaluations of the generated warnings highlight both the potential and\nlimitations of our approach.",
      "tldr_zh": "这篇论文针对多模态错误信息（multimodal misinformation），特别是脱上下文图像与虚假文本的组合，提出了一种零样本警告生成（zero-shot warning generation）方法，以提升信息揭假的解释性和用户理解。模型通过跨模态一致性检查（cross-modality consistency checks）检测不一致性，仅需最少训练时间，并引入一个轻量级模型，使用三分之一参数即可达到竞争性能。论文还设计了双重目的零样本学习任务（dual-purpose zero-shot learning task），用于自动生成情境化警告（contextualized warnings），定性和人类评估显示了方法的潜力，但也暴露了某些局限性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00752v1",
      "published_date": "2025-02-02 11:18:05 UTC",
      "updated_date": "2025-02-02 11:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:54:37.735112"
    },
    {
      "arxiv_id": "2502.00747v1",
      "title": "Universal Post-Processing Networks for Joint Optimization of Modules in Task-Oriented Dialogue Systems",
      "title_zh": "通用后处理网络用于任务导向对话系统模块的联合优化",
      "authors": [
        "Atsumoto Ohashi",
        "Ryuichiro Higashinaka"
      ],
      "abstract": "Post-processing networks (PPNs) are components that modify the outputs of\narbitrary modules in task-oriented dialogue systems and are optimized using\nreinforcement learning (RL) to improve the overall task completion capability\nof the system. However, previous PPN-based approaches have been limited to\nhandling only a subset of modules within a system, which poses a significant\nlimitation in improving the system performance. In this study, we propose a\njoint optimization method for post-processing the outputs of all modules using\nuniversal post-processing networks (UniPPNs), which are language-model-based\nnetworks that can modify the outputs of arbitrary modules in a system as a\nsequence-transformation task. Moreover, our RL algorithm, which employs a\nmodule-level Markov decision process, enables fine-grained value and advantage\nestimation for each module, thereby stabilizing joint learning for\npost-processing the outputs of all modules. Through both simulation-based and\nhuman evaluation experiments using the MultiWOZ dataset, we demonstrated that\nUniPPN outperforms conventional PPNs in the task completion capability of\ntask-oriented dialogue systems.",
      "tldr_zh": "本研究提出 Universal Post-Processing Networks (UniPPNs)，一种基于语言模型的框架，用于联合优化任务导向对话系统中的所有模块输出，从而克服传统 Post-Processing Networks (PPNs) 仅处理部分模块的局限性。UniPPNs 将模块输出视为序列转换任务，并通过一个模块级别的 Markov Decision Process (MDP) 强化学习 (RL) 算法，实现细粒度的价值和优势估计，以稳定联合学习过程。在 MultiWOZ 数据集上的模拟和人类评估实验中，UniPPN 显著提高了系统的任务完成能力，优于传统 PPNs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2025 Main Technical Track",
      "pdf_url": "http://arxiv.org/pdf/2502.00747v1",
      "published_date": "2025-02-02 10:46:37 UTC",
      "updated_date": "2025-02-02 10:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:54:49.160837"
    },
    {
      "arxiv_id": "2502.01685v1",
      "title": "Automated Extraction of Spatio-Semantic Graphs for Identifying Cognitive Impairment",
      "title_zh": "翻译失败",
      "authors": [
        "Si-Ioi Ng",
        "Pranav S. Ambadi",
        "Kimberly D. Mueller",
        "Julie Liss",
        "Visar Berisha"
      ],
      "abstract": "Existing methods for analyzing linguistic content from picture descriptions\nfor assessment of cognitive-linguistic impairment often overlook the\nparticipant's visual narrative path, which typically requires eye tracking to\nassess. Spatio-semantic graphs are a useful tool for analyzing this narrative\npath from transcripts alone, however they are limited by the need for manual\ntagging of content information units (CIUs). In this paper, we propose an\nautomated approach for estimation of spatio-semantic graphs (via automated\nextraction of CIUs) from the Cookie Theft picture commonly used in\ncognitive-linguistic analyses. The method enables the automatic\ncharacterization of the visual semantic path during picture description.\nExperiments demonstrate that the automatic spatio-semantic graphs effectively\ndifferentiate between cognitively impaired and unimpaired speakers. Statistical\nanalyses reveal that the features derived by the automated method produce\ncomparable results to the manual method, with even greater group differences\nbetween clinical groups of interest. These results highlight the potential of\nthe automated approach for extracting spatio-semantic features in developing\nclinical speech models for cognitive impairment assessment.",
      "tldr_zh": "本研究针对认知语言障碍评估中，现有的图片描述分析方法忽略了参与者的视觉叙事路径（通常需眼动追踪），提出了一种自动提取 spatio-semantic graphs 的方法，通过自动化提取内容信息单位 (CIUs) 来分析 Cookie Theft picture 的转录，从而表征视觉语义路径。相比手动标注，该方法能有效区分认知障碍者和非障碍者，并在统计分析中显示出与手动方法相当的性能，甚至在临床群体间揭示更大差异。这些结果突显了该自动方法在开发用于认知障碍评估的临床语音模型中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.01685v1",
      "published_date": "2025-02-02 10:25:19 UTC",
      "updated_date": "2025-02-02 10:25:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:55:00.445961"
    },
    {
      "arxiv_id": "2502.00735v3",
      "title": "`Do as I say not as I do': A Semi-Automated Approach for Jailbreak Prompt Attack against Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Chun Wai Chiu",
        "Linghan Huang",
        "Bo Li",
        "Huaming Chen",
        "Kim-Kwang Raymond Choo"
      ],
      "abstract": "Large Language Models (LLMs) have seen widespread applications across various\ndomains due to their growing ability to process diverse types of input data,\nincluding text, audio, image and video. While LLMs have demonstrated\noutstanding performance in understanding and generating contexts for different\nscenarios, they are vulnerable to prompt-based attacks, which are mostly via\ntext input. In this paper, we introduce the first voice-based jailbreak attack\nagainst multimodal LLMs, termed as Flanking Attack, which can process different\ntypes of input simultaneously towards the multimodal LLMs. Our work is\nmotivated by recent advancements in monolingual voice-driven large language\nmodels, which have introduced new attack surfaces beyond traditional text-based\nvulnerabilities for LLMs. To investigate these risks, we examine the\nstate-of-the-art multimodal LLMs, which can be accessed via different types of\ninputs such as audio input, focusing on how adversarial prompts can bypass its\ndefense mechanisms. We propose a novel strategy, in which the disallowed prompt\nis flanked by benign, narrative-driven prompts. It is integrated in the\nFlanking Attack which attempts to humanizes the interaction context and execute\nthe attack through a fictional setting. Further, to better evaluate the attack\nperformance, we present a semi-automated self-assessment framework for policy\nviolation detection. We demonstrate that Flanking Attack is capable of\nmanipulating state-of-the-art LLMs into generating misaligned and forbidden\noutputs, which achieves an average attack success rate ranging from 0.67 to\n0.93 across seven forbidden scenarios.",
      "tldr_zh": "本文提出了一种名为Flanking Attack的语音-based jailbreak攻击，针对多模态LLMs的漏洞，通过在disallowed prompt周围添加benign叙述性提示并构建虚构设置，来同时处理多种输入类型并规避防御机制。该方法旨在利用语音驱动LLMs的新攻击面，结合一个半自动自评估框架来检测政策违规。实验结果显示，Flanking Attack在七个forbidden场景中实现了0.67到0.93的平均攻击成功率，证明了多模态LLMs在安全性方面的潜在风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00735v3",
      "published_date": "2025-02-02 10:05:08 UTC",
      "updated_date": "2025-05-18 07:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:55:12.573194"
    },
    {
      "arxiv_id": "2502.00734v1",
      "title": "CycleGuardian: A Framework for Automatic RespiratorySound classification Based on Improved Deep clustering and Contrastive Learning",
      "title_zh": "CycleGuardian: 一种基于改进深度聚类和对比学习的自动呼吸声音分类框架",
      "authors": [
        "Yun Chu",
        "Qiuhao Wang",
        "Enze Zhou",
        "Ling Fu",
        "Qian Liu",
        "Gang Zheng"
      ],
      "abstract": "Auscultation plays a pivotal role in early respiratory and pulmonary disease\ndiagnosis. Despite the emergence of deep learning-based methods for automatic\nrespiratory sound classification post-Covid-19, limited datasets impede\nperformance enhancement. Distinguishing between normal and abnormal respiratory\nsounds poses challenges due to the coexistence of normal respiratory components\nand noise components in both types. Moreover, different abnormal respiratory\nsounds exhibit similar anomalous features, hindering their differentiation.\nBesides, existing state-of-the-art models suffer from excessive parameter size,\nimpeding deployment on resource-constrained mobile platforms. To address these\nissues, we design a lightweight network CycleGuardian and propose a framework\nbased on an improved deep clustering and contrastive learning. We first\ngenerate a hybrid spectrogram for feature diversity and grouping spectrograms\nto facilitating intermittent abnormal sound capture.Then, CycleGuardian\nintegrates a deep clustering module with a similarity-constrained clustering\ncomponent to improve the ability to capture abnormal features and a contrastive\nlearning module with group mixing for enhanced abnormal feature discernment.\nMulti-objective optimization enhances overall performance during training. In\nexperiments we use the ICBHI2017 dataset, following the official split method\nand without any pre-trained weights, our method achieves Sp: 82.06 $\\%$, Se:\n44.47$\\%$, and Score: 63.26$\\%$ with a network model size of 38M, comparing to\nthe current model, our method leads by nearly 7$\\%$, achieving the current best\nperformances. Additionally, we deploy the network on Android devices,\nshowcasing a comprehensive intelligent respiratory sound auscultation system.",
      "tldr_zh": "本研究针对呼吸音分类的挑战（如数据集有限、正常与异常声音区分困难，以及模型参数过大），提出了一种轻量级框架 CycleGuardian，基于改进的 Deep Clustering 和 Contrastive Learning。\n该框架首先生成混合谱图并进行分组，以增强特征多样性和捕捉间歇性异常声音；然后整合深度聚类模块（包括相似性约束组件）和对比学习模块（结合组混合），并采用多目标优化来提升异常特征的捕捉和辨识能力。\n在 ICBHI2017 数据集实验中，CycleGuardian 实现了 Sp: 82.06%、Se: 44.47% 和 Score: 63.26%的性能，比现有模型高出近7%，模型大小仅38M。\n此外，该框架已部署到 Android 设备，构建了一个全面的智能呼吸音听诊系统。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00734v1",
      "published_date": "2025-02-02 09:56:47 UTC",
      "updated_date": "2025-02-02 09:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:55:25.672858"
    },
    {
      "arxiv_id": "2502.00729v1",
      "title": "Selective Response Strategies for GenAI",
      "title_zh": "针对 GenAI 的选择性响应策略",
      "authors": [
        "Boaz Taitler",
        "Omer Ben-Porat"
      ],
      "abstract": "The rise of Generative AI (GenAI) has significantly impacted human-based\nforums like Stack Overflow, which are essential for generating high-quality\ndata. This creates a negative feedback loop, hindering the development of GenAI\nsystems, which rely on such data to provide accurate responses. In this paper,\nwe provide a possible remedy: A novel strategy we call selective response.\nSelective response implies that GenAI could strategically provide inaccurate\n(or conservative) responses to queries involving emerging topics and novel\ntechnologies, thereby driving users to use human-based forums like Stack\nOverflow. We show that selective response can potentially have a compounding\neffect on the data generation process, increasing both GenAI's revenue and user\nwelfare in the long term. From an algorithmic perspective, we propose an\napproximately optimal approach to maximize GenAI's revenue under social welfare\nconstraints. From a regulatory perspective, we derive sufficient and necessary\nconditions for selective response to improve welfare improvements.",
      "tldr_zh": "这篇论文探讨了Generative AI (GenAI) 对人类论坛如Stack Overflow 的负面影响，导致数据生成反馈循环恶化。论文提出一种selective response策略，让GenAI针对新兴主题和新型技术的查询提供不准确或保守响应，以引导用户转向人类论坛，从而增强数据生成过程。算法方面，论文设计了一个近似最优方法来最大化GenAI的收入，同时满足社会福利约束；监管方面，推导出selective response改善整体福利的充分必要条件。该策略可能长期提升GenAI的收入和用户福利。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00729v1",
      "published_date": "2025-02-02 09:27:02 UTC",
      "updated_date": "2025-02-02 09:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:55:36.152259"
    },
    {
      "arxiv_id": "2502.00726v1",
      "title": "Perspectives for Direct Interpretability in Multi-Agent Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yoann Poupart",
        "Aurélie Beynier",
        "Nicolas Maudet"
      ],
      "abstract": "Multi-Agent Deep Reinforcement Learning (MADRL) was proven efficient in\nsolving complex problems in robotics or games, yet most of the trained models\nare hard to interpret. While learning intrinsically interpretable models\nremains a prominent approach, its scalability and flexibility are limited in\nhandling complex tasks or multi-agent dynamics. This paper advocates for direct\ninterpretability, generating post hoc explanations directly from trained\nmodels, as a versatile and scalable alternative, offering insights into agents'\nbehaviour, emergent phenomena, and biases without altering models'\narchitectures. We explore modern methods, including relevance backpropagation,\nknowledge edition, model steering, activation patching, sparse autoencoders and\ncircuit discovery, to highlight their applicability to single-agent,\nmulti-agent, and training process challenges. By addressing MADRL\ninterpretability, we propose directions aiming to advance active topics such as\nteam identification, swarm coordination and sample efficiency.",
      "tldr_zh": "这篇论文探讨了 Multi-Agent Deep Reinforcement Learning (MADRL) 的直接可解释性问题，指出传统内在可解释模型在处理复杂任务和多智能体动态时存在可扩展性和灵活性限制。作者提倡直接可解释性作为一种后验解释方法，从已训练模型中直接生成解释，以揭示代理行为、涌现现象和偏差，而无需修改模型架构。论文探索了现代技术如 relevance backpropagation、knowledge edition、model steering、activation patching、sparse autoencoders 和 circuit discovery，并提出方向来推进 MADRL 在团队识别、群协调和样本效率等方面的研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00726v1",
      "published_date": "2025-02-02 09:15:27 UTC",
      "updated_date": "2025-02-02 09:15:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:55:48.822335"
    },
    {
      "arxiv_id": "2502.00724v2",
      "title": "Learned Bayesian Cramér-Rao Bound for Unknown Measurement Models Using Score Neural Networks",
      "title_zh": "基于分数神经网络的学习式贝叶斯Cramér-Rao界用于未知测量模型",
      "authors": [
        "Hai Victor Habi",
        "Hagit Messer",
        "Yoram Bresler"
      ],
      "abstract": "The Bayesian Cram\\'er-Rao bound (BCRB) is a crucial tool in signal processing\nfor assessing the fundamental limitations of any estimation problem as well as\nbenchmarking within a Bayesian frameworks. However, the BCRB cannot be computed\nwithout full knowledge of the prior and the measurement distributions. In this\nwork, we propose a fully learned Bayesian Cram\\'er-Rao bound (LBCRB) that\nlearns both the prior and the measurement distributions. Specifically, we\nsuggest two approaches to obtain the LBCRB: the Posterior Approach and the\nMeasurement-Prior Approach. The Posterior Approach provides a simple method to\nobtain the LBCRB, whereas the Measurement-Prior Approach enables us to\nincorporate domain knowledge to improve the sample complexity and\n{interpretability}. To achieve this, we introduce a Physics-encoded score\nneural network which enables us to easily incorporate such domain knowledge\ninto a neural network. We {study the learning} errors of the two suggested\napproaches theoretically, and validate them numerically. We demonstrate the two\napproaches on several signal processing examples, including a linear\nmeasurement problem with unknown mixing and Gaussian noise covariance matrices,\nfrequency estimation, and quantized measurement. In addition, we test our\napproach on a nonlinear signal processing problem of frequency estimation with\nreal-world underwater ambient noise.",
      "tldr_zh": "这篇论文提出了 Learned Bayesian Cramér-Rao Bound (LBCRB)，一种用于未知测量模型的框架，通过 Score Neural Networks 学习先验和测量分布，以评估估计问题的基本限制。论文引入了两种方法：Posterior Approach，提供简单获取 LBCRB 的方式；以及 Measurement-Prior Approach，利用 Physics-encoded score neural network 整合领域知识，提高样本复杂度和可解释性。通过理论分析学习错误并进行数值验证，该方法在多个信号处理示例中（如线性测量、频率估计和量化测量）表现出色，并在真实世界非线性问题（如水下环境噪声频率估计）中得到有效应用。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "eess.SP",
      "comment": "28 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00724v2",
      "published_date": "2025-02-02 09:00:40 UTC",
      "updated_date": "2025-02-09 06:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:56:00.916169"
    },
    {
      "arxiv_id": "2502.00712v1",
      "title": "Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images",
      "title_zh": "翻译失败",
      "authors": [
        "Shengtian Sang",
        "Hassan Jahanandish",
        "Cynthia Xinran Li",
        "Indrani Bhattachary",
        "Jeong Hoon Lee",
        "Lichun Zhang",
        "Sulaiman Vesal",
        "Pejman Ghanouni",
        "Richard Fan",
        "Geoffrey A. Sonn",
        "Mirabela Rusu"
      ],
      "abstract": "Prostate cancer is a major cause of cancer-related deaths in men, where early\ndetection greatly improves survival rates. Although MRI-TRUS fusion biopsy\noffers superior accuracy by combining MRI's detailed visualization with TRUS's\nreal-time guidance, it is a complex and time-intensive procedure that relies\nheavily on manual annotations, leading to potential errors. To address these\nchallenges, we propose a fully automatic MRI-TRUS fusion-based segmentation\nmethod that identifies prostate tumors directly in TRUS images without\nrequiring manual annotations. Unlike traditional multimodal fusion approaches\nthat rely on naive data concatenation, our method integrates a\nregistration-segmentation framework to align and leverage spatial information\nbetween MRI and TRUS modalities. This alignment enhances segmentation accuracy\nand reduces reliance on manual effort. Our approach was validated on a dataset\nof 1,747 patients from Stanford Hospital, achieving an average Dice coefficient\nof 0.212, outperforming TRUS-only (0.117) and naive MRI-TRUS fusion (0.132)\nmethods, with significant improvements (p $<$ 0.01). This framework\ndemonstrates the potential for reducing the complexity of prostate cancer\ndiagnosis and provides a flexible architecture applicable to other multimodal\nmedical imaging tasks.",
      "tldr_zh": "本研究针对前列腺癌诊断中的挑战，提出了一种全自动的 Registration-Enhanced Segmentation 方法，用于在 TRUS 图像中直接识别肿瘤，而无需手动标注。该方法通过整合 Registration-Segmentation 框架，对齐 MRI 和 TRUS 模态的空间信息，实现更精确的图像融合，比传统简单拼接方法更有效。在 1,747 名斯坦福医院患者的 dataset 上验证，该方法平均 Dice coefficient 达到 0.212，显著优于 TRUS-only (0.117) 和 naive MRI-TRUS fusion (0.132) 方法（p < 0.01），并为简化前列腺癌诊断和扩展至其他多模态医疗成像任务提供灵活架构。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00712v1",
      "published_date": "2025-02-02 07:58:40 UTC",
      "updated_date": "2025-02-02 07:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:56:13.937212"
    },
    {
      "arxiv_id": "2502.00711v1",
      "title": "VIKSER: Visual Knowledge-Driven Self-Reinforcing Reasoning Framework",
      "title_zh": "VIKSER：视觉知识驱动的自我强化推理框架",
      "authors": [
        "Chunbai Zhang",
        "Chao Wang",
        "Yang Zhou",
        "Yan Peng"
      ],
      "abstract": "Visual reasoning refers to the task of solving questions about visual\ninformation. Current visual reasoning methods typically employ pre-trained\nvision-language model (VLM) strategies or deep neural network approaches.\nHowever, existing efforts are constrained by limited reasoning\ninterpretability, while hindering by the phenomenon of underspecification in\nthe question text. Additionally, the absence of fine-grained visual knowledge\nlimits the precise understanding of subject behavior in visual reasoning tasks.\nTo address these issues, we propose VIKSER (Visual Knowledge-Driven\nSelf-Reinforcing Reasoning Framework). Specifically, VIKSER, trained using\nknowledge distilled from large language models, extracts fine-grained visual\nknowledge with the assistance of visual relationship detection techniques.\nSubsequently, VIKSER utilizes fine-grained visual knowledge to paraphrase the\nquestion with underspecification. Additionally, we design a novel prompting\nmethod called Chain-of-Evidence (CoE), which leverages the power of ``evidence\nfor reasoning'' to endow VIKSER with interpretable reasoning capabilities.\nMeanwhile, the integration of self-reflection technology empowers VIKSER with\nthe ability to learn and improve from its mistakes. Experiments conducted on\nwidely used datasets demonstrate that VIKSER achieves new state-of-the-art\n(SOTA) results in relevant tasks.",
      "tldr_zh": "本文提出 VIKSER，一种视觉知识驱动的自强化推理框架，用于解决视觉推理任务中存在的推理可解释性不足、问题文本 underspecification 以及缺乏细粒度视觉知识的问题。VIKSER 通过从大型语言模型中蒸馏知识并结合视觉关系检测技术，提取细粒度视觉知识，并用于改写问题文本以提高精确性。同时，该框架引入 Chain-of-Evidence (CoE) 提示方法和自反技术，实现可解释的推理过程并从错误中学习。在常用数据集上的实验表明，VIKSER 达到了新的 SOTA 结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages,12 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00711v1",
      "published_date": "2025-02-02 07:54:55 UTC",
      "updated_date": "2025-02-02 07:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:56:24.173682"
    },
    {
      "arxiv_id": "2502.00708v1",
      "title": "PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation",
      "title_zh": "PhiP-G：物理指导的文本到3D 组合场景生成",
      "authors": [
        "Qixuan Li",
        "Chao Wang",
        "Zongjin He",
        "Yan Peng"
      ],
      "abstract": "Text-to-3D asset generation has achieved significant optimization under the\nsupervision of 2D diffusion priors. However, when dealing with compositional\nscenes, existing methods encounter several challenges: 1). failure to ensure\nthat composite scene layouts comply with physical laws; 2). difficulty in\naccurately capturing the assets and relationships described in complex scene\ndescriptions; 3). limited autonomous asset generation capabilities among layout\napproaches leveraging large language models (LLMs). To avoid these compromises,\nwe propose a novel framework for compositional scene generation, PhiP-G, which\nseamlessly integrates generation techniques with layout guidance based on a\nworld model. Leveraging LLM-based agents, PhiP-G analyzes the complex scene\ndescription to generate a scene graph, and integrating a multimodal 2D\ngeneration agent and a 3D Gaussian generation method for targeted assets\ncreation. For the stage of layout, PhiP-G employs a physical pool with adhesion\ncapabilities and a visual supervision agent, forming a world model for layout\nprediction and planning. Extensive experiments demonstrate that PhiP-G\nsignificantly enhances the generation quality and physical rationality of the\ncompositional scenes. Notably, PhiP-G attains state-of-the-art (SOTA)\nperformance in CLIP scores, achieves parity with the leading methods in\ngeneration quality as measured by the T$^3$Bench, and improves efficiency by\n24x.",
      "tldr_zh": "该论文提出PhiP-G框架，用于指导Text-to-3D合成场景生成，解决现有方法在物理定律合规、复杂描述捕捉和自主资产生成方面的挑战。PhiP-G利用LLM-based agents分析场景描述生成场景图，并整合多模态2D生成代理和3D Gaussian方法创建资产，同时通过物理池和视觉监督代理构建世界模型进行布局预测和规划。实验结果显示，PhiP-G在CLIP scores上达到SOTA性能，在T³Bench生成质量上与领先方法相当，并将效率提升24倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages.8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00708v1",
      "published_date": "2025-02-02 07:47:03 UTC",
      "updated_date": "2025-02-02 07:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:56:37.179189"
    },
    {
      "arxiv_id": "2502.01684v3",
      "title": "Leveraging Joint Predictive Embedding and Bayesian Inference in Graph Self Supervised Learning",
      "title_zh": "在图自监督学习中利用联合",
      "authors": [
        "Srinitish Srinivasan",
        "Omkumar CU"
      ],
      "abstract": "Graph representation learning has emerged as a cornerstone for tasks like\nnode classification and link prediction, yet prevailing self-supervised\nlearning (SSL) methods face challenges such as computational inefficiency,\nreliance on contrastive objectives, and representation collapse. Existing\napproaches often depend on feature reconstruction, negative sampling, or\ncomplex decoders, which introduce training overhead and hinder generalization.\nFurther, current techniques which address such limitations fail to account for\nthe contribution of node embeddings to a certain prediction in the absence of\nlabeled nodes. To address these limitations, we propose a novel joint embedding\npredictive framework for graph SSL that eliminates contrastive objectives and\nnegative sampling while preserving semantic and structural information.\nAdditionally, we introduce a semantic-aware objective term that incorporates\npseudo-labels derived from Gaussian Mixture Models (GMMs), enhancing node\ndiscriminability by evaluating latent feature contributions. Extensive\nexperiments demonstrate that our framework outperforms state-of-the-art graph\nSSL methods across benchmarks, achieving superior performance without\ncontrastive loss or complex decoders. Key innovations include (1) a\nnon-contrastive, view-invariant joint embedding predictive architecture, (2)\nLeveraging single context and multiple targets relationship between subgraphs,\nand (3) GMM-based pseudo-label scoring to capture semantic contributions. This\nwork advances graph SSL by offering a computationally efficient,\ncollapse-resistant paradigm that bridges spatial and semantic graph features\nfor downstream tasks. The code for our paper can be found at\nhttps://github.com/Deceptrax123/JPEB-GSSL",
      "tldr_zh": "本论文提出了一种新的联合嵌入预测框架，用于图自监督学习（Graph Self-Supervised Learning），旨在解决现有方法存在的计算效率低、依赖对比目标（contrastive objectives）和表示崩溃（representation collapse）等问题。该框架通过消除负采样和复杂解码器，同时保留语义和结构信息，来提升节点嵌入的泛化能力；此外，它引入了基于高斯混合模型（Gaussian Mixture Models, GMMs）的伪标签评分机制，以增强节点的语义感知和可区分性。关键创新包括非对比的视图不变联合嵌入预测架构、子图间单个上下文与多个目标关系的利用，以及GMM-based伪标签来捕获语义贡献。在基准测试中，该框架在不依赖对比损失或复杂解码器的情况下，超越了最先进的方法，提供了一个计算高效、抗崩溃的范式，从而桥接了空间和语义图特征，支持下游任务如节点分类和链接预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2502.01684v3",
      "published_date": "2025-02-02 07:42:45 UTC",
      "updated_date": "2025-04-01 10:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:56:48.810928"
    },
    {
      "arxiv_id": "2502.00698v1",
      "title": "MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Huanqia Cai",
        "Yijun Yang",
        "Winston Hu"
      ],
      "abstract": "IQ testing has served as a foundational methodology for evaluating human\ncognitive capabilities, deliberately decoupling assessment from linguistic\nbackground, language proficiency, or domain-specific knowledge to isolate core\ncompetencies in abstraction and reasoning. Yet, artificial intelligence\nresearch currently lacks systematic benchmarks to quantify these critical\ncognitive dimensions in multimodal systems. To address this critical gap, we\npropose MM-IQ, a comprehensive evaluation framework comprising 2,710\nmeticulously curated test items spanning 8 distinct reasoning paradigms.\n  Through systematic evaluation of leading open-source and proprietary\nmultimodal models, our benchmark reveals striking limitations: even\nstate-of-the-art architectures achieve only marginally superior performance to\nrandom chance (27.49% vs. 25% baseline accuracy). This substantial performance\nchasm highlights the inadequacy of current multimodal systems in approximating\nfundamental human reasoning capacities, underscoring the need for\nparadigm-shifting advancements to bridge this cognitive divide.",
      "tldr_zh": "本论文提出MM-IQ基准框架，用于评估多模态模型的抽象和推理能力，类似于人类IQ测试，旨在脱离语言或领域知识的干扰，专注于核心认知维度。该框架包括2710个精心设计的测试项目，覆盖8种推理范式，并对领先的开源和专有多模态模型进行系统评估。结果显示，这些模型的性能仅略高于随机猜测（27.49% vs. 25%），暴露了当前AI在模拟人类推理方面的重大局限，强调需要根本性的创新来弥合这一认知差距。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00698v1",
      "published_date": "2025-02-02 07:12:03 UTC",
      "updated_date": "2025-02-02 07:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:57:00.543799"
    },
    {
      "arxiv_id": "2502.00695v1",
      "title": "TMI-CLNet: Triple-Modal Interaction Network for Chronic Liver Disease Prognosis From Imaging, Clinical, and Radiomic Data Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Linglong Wu",
        "Xuhao Shan",
        "Ruiquan Ge",
        "Ruoyu Liang",
        "Chi Zhang",
        "Yonghong Li",
        "Ahmed Elazab",
        "Huoling Luo",
        "Yunbi Liu",
        "Changmiao Wang"
      ],
      "abstract": "Chronic liver disease represents a significant health challenge worldwide and\naccurate prognostic evaluations are essential for personalized treatment plans.\nRecent evidence suggests that integrating multimodal data, such as computed\ntomography imaging, radiomic features, and clinical information, can provide\nmore comprehensive prognostic information. However, modalities have an inherent\nheterogeneity, and incorporating additional modalities may exacerbate the\nchallenges of heterogeneous data fusion. Moreover, existing multimodal fusion\nmethods often struggle to adapt to richer medical modalities, making it\ndifficult to capture inter-modal relationships. To overcome these limitations,\nWe present the Triple-Modal Interaction Chronic Liver Network (TMI-CLNet).\nSpecifically, we develop an Intra-Modality Aggregation module and a\nTriple-Modal Cross-Attention Fusion module, which are designed to eliminate\nintra-modality redundancy and extract cross-modal information, respectively.\nFurthermore, we design a Triple-Modal Feature Fusion loss function to align\nfeature representations across modalities. Extensive experiments on the liver\nprognosis dataset demonstrate that our approach significantly outperforms\nexisting state-of-the-art unimodal models and other multi-modal techniques. Our\ncode is available at https://github.com/Mysterwll/liver.git.",
      "tldr_zh": "该研究提出 TMI-CLNet，一种三模态交互网络，用于整合影像、临床和放射组学数据，以实现慢性肝病预后的准确评估。该框架包括 Intra-Modality Aggregation module 用于消除模态内冗余、Triple-Modal Cross-Attention Fusion module 用于提取跨模态信息，以及 Triple-Modal Feature Fusion loss function 用于对齐模态间特征表示，从而有效解决多模态数据融合的异质性挑战。在肝预后数据集上的广泛实验表明，TMI-CLNet 显著优于现有单模态模型和多模态技术，代码已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 3 figures, accepted by IEEE ISBI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00695v1",
      "published_date": "2025-02-02 07:05:28 UTC",
      "updated_date": "2025-02-02 07:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:57:12.640181"
    },
    {
      "arxiv_id": "2502.00694v1",
      "title": "Leveraging Large Language Models to Predict Antibody Biological Activity Against Influenza A Hemagglutinin",
      "title_zh": "翻译失败",
      "authors": [
        "Ella Barkan",
        "Ibrahim Siddiqui",
        "Kevin J. Cheng",
        "Alex Golts",
        "Yoel Shoshan",
        "Jeffrey K. Weber",
        "Yailin Campos Mota",
        "Michal Ozery-Flato",
        "Giuseppe A. Sautto"
      ],
      "abstract": "Monoclonal antibodies (mAbs) represent one of the most prevalent FDA-approved\nmodalities for treating autoimmune diseases, infectious diseases, and cancers.\nHowever, discovery and development of therapeutic antibodies remains a\ntime-consuming and expensive process. Recent advancements in machine learning\n(ML) and artificial intelligence (AI) have shown significant promise in\nrevolutionizing antibody discovery and optimization. In particular, models that\npredict antibody biological activity enable in-silico evaluation of binding and\nfunctional properties; such models can prioritize antibodies with the highest\nlikelihoods of success in costly and time-intensive laboratory testing\nprocedures. We here explore an AI model for predicting the binding and receptor\nblocking activity of antibodies against influenza A hemagglutinin (HA)\nantigens. Our present model is developed with the MAMMAL framework for\nbiologics discovery to predict antibody-antigen interactions using only\nsequence information. To evaluate the model's performance, we tested it under\nvarious data split conditions to mimic real-world scenarios.\n  Our models achieved an AUROC $\\geq$ 0.91 for predicting the activity of\nexisting antibodies against seen HAs and an AUROC of 0.9 for unseen HAs. For\nnovel antibody activity prediction, the AUROC was 0.73, which further declined\nto 0.63-0.66 under stringent constraints on similarity to existing antibodies.\nThese results demonstrate the potential of AI foundation models to transform\nantibody design by reducing dependence on extensive laboratory testing and\nenabling more efficient prioritization of antibody candidates. Moreover, our\nfindings emphasize the critical importance of diverse and comprehensive\nantibody datasets to improve the generalization of prediction models,\nparticularly for novel antibody development.",
      "tldr_zh": "本研究利用大型语言模型(LLMs)和MAMMAL框架，基于抗体序列信息预测其对流感A血凝素(HA)抗原的结合和阻断活性，从而加速抗体发现和优化过程。模型在不同数据分割条件下表现出色：对已知HA的现有抗体，AUROC ≥ 0.91；对未见HA，AUROC = 0.9；对新抗体，AUROC = 0.73，并在严格相似性约束下降至0.63-0.66。这些结果证明AI模型能减少实验室测试依赖，并优先筛选高潜力候选物，同时强调需要多样化数据集来提升模型的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00694v1",
      "published_date": "2025-02-02 06:48:45 UTC",
      "updated_date": "2025-02-02 06:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:57:50.564793"
    },
    {
      "arxiv_id": "2502.01683v1",
      "title": "LLM-Powered Benchmark Factory: Reliable, Generic, and Efficient",
      "title_zh": "翻译失败",
      "authors": [
        "Peiwen Yuan",
        "Shaoxiong Feng",
        "Yiwei Li",
        "Xinglin Wang",
        "Yueqi Zhang",
        "Jiayi Shi",
        "Chuyi Tan",
        "Boyuan Pan",
        "Yao Hu",
        "Kan Li"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has led to a surge in\nboth model supply and application demands. To facilitate effective matching\nbetween them, reliable, generic and efficient benchmark generators are widely\nneeded. However, human annotators are constrained by inefficiency, and current\nLLM benchmark generators not only lack generalizability but also struggle with\nlimited reliability, as they lack a comprehensive evaluation framework for\nvalidation and optimization. To fill this gap, we first propose an automated\nand unbiased evaluation framework, structured around four dimensions and ten\ncriteria. Under this framework, we carefully analyze the advantages and\nweaknesses of directly prompting LLMs as generic benchmark generators. To\nenhance the reliability, we introduce a series of methods to address the\nidentified weaknesses and integrate them as BenchMaker. Experiments across\nmultiple LLMs and tasks confirm that BenchMaker achieves superior or comparable\nperformance to human-annotated benchmarks on all metrics, highlighting its\ngeneralizability and reliability. More importantly, it delivers highly\nconsistent evaluation results across 12 LLMs (0.967 Pearson correlation against\nMMLU-Pro), while taking only $0.005 and 0.38 minutes per sample.",
      "tldr_zh": "该论文提出了一种基于大型语言模型(LLM)的基准生成器BenchMaker，以解决现有基准生成器的泛化性和可靠性问题。研究者首先建立了一个自动、无偏见的评估框架，涵盖四个维度和十个标准，用于分析直接提示LLM的优缺点，并引入改进方法来提升其可靠性。实验结果显示，BenchMaker在多个LLM和任务上表现优于或相当于是人工标注基准，与MMLU-Pro的Pearson correlation达到0.967，同时每样本的成本仅为0.005美元和0.38分钟，展示了其高效性和一致性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01683v1",
      "published_date": "2025-02-02 06:36:01 UTC",
      "updated_date": "2025-02-02 06:36:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:57:35.633467"
    },
    {
      "arxiv_id": "2502.00691v2",
      "title": "Learning Autonomous Code Integration for Math Language Models",
      "title_zh": "数学语言模型的自治代码集成学习",
      "authors": [
        "Haozhe Wang",
        "Long Li",
        "Chao Qu",
        "Fengming Zhu",
        "Weidi Xu",
        "Wei Chu",
        "Fangzhen Lin"
      ],
      "abstract": "Recent advances in mathematical problem-solving with language models (LMs)\nintegrate chain-of-thought (CoT) reasoning and code execution to harness their\ncomplementary strengths. However, existing hybrid frameworks exhibit a critical\nlimitation: they depend on externally dictated instructions or rigid\ncode-integration templates, lacking metacognitive awareness -- the capacity to\ndynamically evaluate intrinsic capabilities and autonomously determine when and\nhow to integrate tools. This rigidity motivates our study of autonomous code\nintegration, enabling models to adapt tool-usage strategies as their reasoning\nabilities evolve during training.\n  While reinforcement learning (RL) shows promise for boosting LLM reasoning at\nscale (e.g., DeepSeek-R1), we demonstrate its inefficiency in learning\nautonomous code integration due to inadequate exploration of the vast\ncombinatorial space of CoT-code interleaving patterns. To address this\nchallenge, we propose a novel Expectation-Maximization (EM) framework that\nsynergizes structured exploration (E-step) with off-policy RL optimization\n(M-step), creating a self-reinforcing cycle between metacognitive tool-use\ndecisions and evolving capabilities. Experiments reveal our method achieves\nsuperior results through improved exploration. Notably, our 7B model improves\nover 11% on MATH500 and 9.4% on AIME without o1-like CoT.",
      "tldr_zh": "本文研究了数学语言模型（LMs）的自主代码整合问题，旨在解决现有框架依赖外部指令或刚性模板、缺乏元认知能力（metacognitive awareness）的问题，从而让模型动态评估自身能力和自主决定何时及如何整合代码工具。作者提出了一种新型 Expectation-Maximization (EM) 框架，将结构化探索 (E-step) 与 off-policy Reinforcement Learning (RL) 优化 (M-step) 相结合，形成一个自我强化循环，提升模型对 Chain-of-Thought (CoT) 和代码交织策略的探索效率。实验结果表明，该方法显著提升性能：7B 模型在 MATH500 上改善超过 11%，在 AIME 上提升 9.4%，无需 o1-like CoT 支持。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00691v2",
      "published_date": "2025-02-02 06:32:23 UTC",
      "updated_date": "2025-02-16 07:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:57:49.659636"
    },
    {
      "arxiv_id": "2502.00690v1",
      "title": "Dissecting Submission Limit in Desk-Rejections: A Mathematical Analysis of Fairness in AI Conference Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Yuefan Cao",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhizhou Sha",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang"
      ],
      "abstract": "As AI research surges in both impact and volume, conferences have imposed\nsubmission limits to maintain paper quality and alleviate organizational\npressure. In this work, we examine the fairness of desk-rejection systems under\nsubmission limits and reveal that existing practices can result in substantial\ninequities. Specifically, we formally define the paper submission limit problem\nand identify a critical dilemma: when the number of authors exceeds three, it\nbecomes impossible to reject papers solely based on excessive submissions\nwithout negatively impacting innocent authors. Thus, this issue may unfairly\naffect early-career researchers, as their submissions may be penalized due to\nco-authors with significantly higher submission counts, while senior\nresearchers with numerous papers face minimal consequences. To address this, we\npropose an optimization-based fairness-aware desk-rejection mechanism and\nformally define two fairness metrics: individual fairness and group fairness.\nWe prove that optimizing individual fairness is NP-hard, whereas group fairness\ncan be efficiently optimized via linear programming. Through case studies, we\ndemonstrate that our proposed system ensures greater equity than existing\nmethods, including those used in CVPR 2025, offering a more socially just\napproach to managing excessive submissions in AI conferences.",
      "tldr_zh": "这篇论文分析了AI会议提交限制下desk-rejection系统的公平性问题，发现现有做法可能导致早期职业研究者因合作者过度提交而遭受不公，而资深研究者影响较小。作者形式化定义了论文提交限制问题，并提出了一种基于优化的公平desk-rejection机制，同时定义了individual fairness和group fairness两个公平度量。研究证明，individual fairness优化是NP-hard，而group fairness可通过linear programming高效实现，并通过案例研究显示，该机制比现有方法（如CVPR 2025）更能确保公平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00690v1",
      "published_date": "2025-02-02 06:29:23 UTC",
      "updated_date": "2025-02-02 06:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:58:01.197992"
    },
    {
      "arxiv_id": "2502.00688v1",
      "title": "High-Order Matching for One-Step Shortcut Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Chen",
        "Chengyue Gong",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhizhou Sha",
        "Zhenmei Shi",
        "Zhao Song",
        "Mingda Wan"
      ],
      "abstract": "One-step shortcut diffusion models [Frans, Hafner, Levine and Abbeel, ICLR\n2025] have shown potential in vision generation, but their reliance on\nfirst-order trajectory supervision is fundamentally limited. The Shortcut\nmodel's simplistic velocity-only approach fails to capture intrinsic manifold\ngeometry, leading to erratic trajectories, poor geometric alignment, and\ninstability-especially in high-curvature regions. These shortcomings stem from\nits inability to model mid-horizon dependencies or complex distributional\nfeatures, leaving it ill-equipped for robust generative modeling. In this work,\nwe introduce HOMO (High-Order Matching for One-Step Shortcut Diffusion), a\ngame-changing framework that leverages high-order supervision to revolutionize\ndistribution transportation. By incorporating acceleration, jerk, and beyond,\nHOMO not only fixes the flaws of the Shortcut model but also achieves\nunprecedented smoothness, stability, and geometric precision. Theoretically, we\nprove that HOMO's high-order supervision ensures superior approximation\naccuracy, outperforming first-order methods. Empirically, HOMO dominates in\ncomplex settings, particularly in high-curvature regions where the Shortcut\nmodel struggles. Our experiments show that HOMO delivers smoother trajectories\nand better distributional alignment, setting a new standard for one-step\ngenerative models.",
      "tldr_zh": "该研究指出了现有 One-Step Shortcut Diffusion Models 的局限性，即其依赖一阶轨迹监督，无法捕捉流形几何，导致轨迹不稳定和分布对齐问题，尤其在高曲率区域。论文提出 HOMO（High-Order Matching for One-Step Shortcut Diffusion）框架，通过引入高阶监督（如加速度和加加速度）来提升分布传输的平滑性、稳定性和几何精度。理论上，HOMO 证明了高阶监督能实现优于一阶方法的近似准确性；实验结果显示，在复杂设置中，HOMO 生成更平滑的轨迹和更好的分布对齐，为一步生成模型设定了新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00688v1",
      "published_date": "2025-02-02 06:19:59 UTC",
      "updated_date": "2025-02-02 06:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:58:13.057157"
    },
    {
      "arxiv_id": "2502.00684v1",
      "title": "Compositional Concept-Based Neuron-Level Interpretability for Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Jiang",
        "Hai Huang",
        "Xingquan Zuo"
      ],
      "abstract": "Deep reinforcement learning (DRL), through learning policies or values\nrepresented by neural networks, has successfully addressed many complex control\nproblems. However, the neural networks introduced by DRL lack interpretability\nand transparency. Current DRL interpretability methods largely treat neural\nnetworks as black boxes, with few approaches delving into the internal\nmechanisms of policy/value networks. This limitation undermines trust in both\nthe neural network models that represent policies and the explanations derived\nfrom them. In this work, we propose a novel concept-based interpretability\nmethod that provides fine-grained explanations of DRL models at the neuron\nlevel. Our method formalizes atomic concepts as binary functions over the state\nspace and constructs complex concepts through logical operations. By analyzing\nthe correspondence between neuron activations and concept functions, we\nestablish interpretable explanations for individual neurons in policy/value\nnetworks. Experimental results on both continuous control tasks and discrete\ndecision-making environments demonstrate that our method can effectively\nidentify meaningful concepts that align with human understanding while\nfaithfully reflecting the network's decision-making logic.",
      "tldr_zh": "本文针对Deep Reinforcement Learning (DRL)中神经网络缺乏可解释性的问题，提出了一种基于概念的神经元级别解释方法，以提供细粒度的策略/价值网络解释。该方法将原子概念形式化为状态空间上的二元函数，并通过逻辑操作构建复杂概念，然后分析神经元激活与概念函数的对应关系，以建立可解释的神经元解释。实验在连续控制任务和离散决策环境中验证了该方法的有效性，能够识别与人类理解一致的有意义概念，并忠实反映网络的决策逻辑。该研究提升了DRL模型的透明度和可信度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.2.1; I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures, IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00684v1",
      "published_date": "2025-02-02 06:05:49 UTC",
      "updated_date": "2025-02-02 06:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:58:24.438853"
    },
    {
      "arxiv_id": "2502.00682v1",
      "title": "Guidance Source Matters: How Guidance from AI, Expert, or a Group of Analysts Impacts Visual Data Preparation and Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Arpit Narechania",
        "Alex Endert",
        "Atanu R Sinha"
      ],
      "abstract": "The progress in generative AI has fueled AI-powered tools like co-pilots and\nassistants to provision better guidance, particularly during data analysis.\nHowever, research on guidance has not yet examined the perceived efficacy of\nthe source from which guidance is offered and the impact of this source on the\nuser's perception and usage of guidance. We ask whether users perceive all\nguidance sources as equal, with particular interest in three sources: (i) AI,\n(ii) human expert, and (iii) a group of human analysts. As a benchmark, we\nconsider a fourth source, (iv) unattributed guidance, where guidance is\nprovided without attribution to any source, enabling isolation of and\ncomparison with the effects of source-specific guidance. We design a\nfive-condition between-subjects study, with one condition for each of the four\nguidance sources and an additional (v) no-guidance condition, which serves as a\nbaseline to evaluate the influence of any kind of guidance. We situate our\nstudy in a custom data preparation and analysis tool wherein we task users to\nselect relevant attributes from an unfamiliar dataset to inform a business\nreport. Depending on the assigned condition, users can request guidance, which\nthe system then provides in the form of attribute suggestions. To ensure\ninternal validity, we control for the quality of guidance across\nsource-conditions. Through several metrics of usage and perception, we\nstatistically test five preregistered hypotheses and report on additional\nanalysis. We find that the source of guidance matters to users, but not in a\nmanner that matches received wisdom. For instance, users utilize guidance\ndifferently at various stages of analysis, including expressing varying levels\nof regret, despite receiving guidance of similar quality. Notably, users in the\nAI condition reported both higher post-task benefit and regret.",
      "tldr_zh": "本研究探讨了指导来源（AI、人类专家或分析师群体）对视觉数据准备和分析的影响，重点考察用户对不同来源的感知和使用差异。研究设计了一个五条件实验，包括AI指导、人类专家指导、分析师群体指导、无来源指导以及无指导基准，用户在自定义工具中从陌生数据集选择属性以生成商业报告，所有指导质量均保持一致。结果显示，指导来源显著影响用户行为，例如AI指导导致用户报告更高的任务益处和遗憾，尽管指导质量相似；此外，用户在分析不同阶段对指导的使用方式和遗憾程度也存在差异。该研究揭示了指导来源的重要性，为设计更有效的AI辅助工具提供了洞见。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 10 figures, 6 figures, to appear in proceedings of ACM IUI\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00682v1",
      "published_date": "2025-02-02 05:59:02 UTC",
      "updated_date": "2025-02-02 05:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:58:36.659303"
    },
    {
      "arxiv_id": "2502.00681v1",
      "title": "A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models",
      "title_zh": "量化图表示学习的综述：连接图结构与大语言模型",
      "authors": [
        "Qika Lin",
        "Zhen Peng",
        "Kaize Shi",
        "Kai He",
        "Yiming Xu",
        "Erik Cambria",
        "Mengling Feng"
      ],
      "abstract": "Recent years have witnessed rapid advances in graph representation learning,\nwith the continuous embedding approach emerging as the dominant paradigm.\nHowever, such methods encounter issues regarding parameter efficiency,\ninterpretability, and robustness. Thus, Quantized Graph Representation (QGR)\nlearning has recently gained increasing interest, which represents the graph\nstructure with discrete codes instead of conventional continuous embeddings.\nGiven its analogous representation form to natural language, QGR also possesses\nthe capability to seamlessly integrate graph structures with large language\nmodels (LLMs). As this emerging paradigm is still in its infancy yet holds\nsignificant promise, we undertake this thorough survey to promote its rapid\nfuture prosperity. We first present the background of the general quantization\nmethods and their merits. Moreover, we provide an in-depth demonstration of\ncurrent QGR studies from the perspectives of quantized strategies, training\nobjectives, distinctive designs, knowledge graph quantization, and\napplications. We further explore the strategies for code dependence learning\nand integration with LLMs. At last, we give discussions and conclude future\ndirections, aiming to provide a comprehensive picture of QGR and inspire future\nresearch.",
      "tldr_zh": "这篇调查论文探讨了 Quantized Graph Representation (QGR) 学习的发展，旨在解决传统图表示学习在参数效率、解释性和鲁棒性方面的不足，并强调 QGR 通过使用离散代码表示图结构来实现与 Large Language Models (LLMs) 的无缝整合。论文从量化策略、训练目标、独特设计、知识图量化以及应用角度，对现有 QGR 研究进行了深入分析，同时探讨了代码依赖学习和与 LLMs 的整合策略。最终，它讨论了未来方向，以推动 QGR 领域的繁荣和发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00681v1",
      "published_date": "2025-02-02 05:57:34 UTC",
      "updated_date": "2025-02-02 05:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:58:48.918758"
    },
    {
      "arxiv_id": "2502.00678v2",
      "title": "How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeong Kyu Choi",
        "Maxim Khanov",
        "Hongxin Wei",
        "Yixuan Li"
      ],
      "abstract": "Dataset contamination, where evaluation datasets overlap with pre-training\ncorpora, inflates performance metrics and undermines the reliability of model\nevaluations. Measuring dataset contamination thus becomes essential to ensure\nthat performance evaluations genuinely reflect a model's ability to generalize\nto unseen data, rather than relying on memorized examples. To address this\nproblem, we propose Kernel Divergence Score (KDS), a novel method that\nevaluates dataset contamination by computing the divergence between the kernel\nsimilarity matrix of sample embeddings, before and after fine-tuning on the\nbenchmark dataset. Leveraging the insight that fine-tuning affects unseen\nsamples more significantly than seen ones, KDS provides a reliable measure of\ncontamination. Through extensive experiments on controlled contamination\nscenarios, KDS demonstrates a near-perfect correlation with contamination\nlevels and outperforms existing baselines. Additionally, we perform\ncomprehensive ablation studies to analyze the impact of key design choices,\nproviding deeper insights into the components and effectiveness of KDS. These\nablations highlight the importance of leveraging fine-grained kernel-based\ninformation and confirm the reliability of the proposed framework across\ndiverse datasets and settings. Code is released in\nhttps://github.com/deeplearning-wisc/kernel-divergence-score.",
      "tldr_zh": "本文研究了大型语言模型中的数据集污染（dataset contamination）问题，该问题会导致评估数据集与预训练语料重叠，从而夸大性能指标并影响模型泛化能力的真实评估。为解决此问题，作者提出Kernel Divergence Score (KDS)方法，通过计算样本嵌入的核相似性矩阵（kernel similarity matrix）在微调前后的差异，来量化污染程度。实验结果显示，KDS在控制污染场景中与污染水平高度相关，并优于现有基线方法。此外，作者进行了消融研究，验证了KDS设计选择的有效性，并开源了代码以促进进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00678v2",
      "published_date": "2025-02-02 05:50:39 UTC",
      "updated_date": "2025-05-20 20:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:59:01.222610"
    },
    {
      "arxiv_id": "2502.13969v1",
      "title": "Bridging Simulation and Reality: A 3D Clustering-Based Deep Learning Model for UAV-Based RF Source Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Saad Masrur",
        "Ismail Guvenc"
      ],
      "abstract": "Localization of radio frequency (RF) sources has critical applications,\nincluding search and rescue, jammer detection, and monitoring of hostile\nactivities. Unmanned aerial vehicles (UAVs) offer significant advantages for RF\nsource localization (RFSL) over terrestrial methods, leveraging autonomous 3D\nnavigation and improved signal capture at higher altitudes. Recent advancements\nin deep learning (DL) have further enhanced localization accuracy, particularly\nfor outdoor scenarios. DL models often face challenges in real-world\nperformance, as they are typically trained on simulated datasets that fail to\nreplicate real-world conditions fully. To address this, we first propose the\nEnhanced Two-Ray propagation model, reducing the simulation-to-reality gap by\nimproving the accuracy of propagation environment modeling. For RFSL, we\npropose the 3D Cluster-Based RealAdaptRNet, a DL-based method leveraging 3D\nclustering-based feature extraction for robust localization. Experimental\nresults demonstrate that the proposed Enhanced Two-Ray model provides superior\naccuracy in simulating real-world propagation scenarios compared to\nconventional free-space and two-ray models. Notably, the 3D Cluster-Based\nRealAdaptRNet, trained entirely on simulated datasets, achieves exceptional\nperformance when validated in real-world environments using the AERPAW physical\ntestbed, with an average localization error of 18.2 m. The proposed approach is\ncomputationally efficient, utilizing 33.5 times fewer parameters, and\ndemonstrates strong generalization capabilities across diverse trajectories,\nmaking it highly suitable for real-world applications.",
      "tldr_zh": "这篇论文针对UAV-Based RF源定位的应用（如搜索救援和干扰检测），提出Enhanced Two-Ray传播模型，以减少模拟数据与真实环境的差距，提高传播场景建模的准确性。论文还开发了3D Cluster-Based RealAdaptRNet，一种基于深度学习（DL）的定位方法，利用3D聚类特征提取实现鲁棒性定位。实验结果显示，该模型在AERPAW真实测试台上平均定位误差仅为18.2 m，同时参数量减少33.5倍，并展现出优秀的泛化能力，适用于多样化轨迹的实际场景。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "This paper has been submitted to IEEE ICC 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.13969v1",
      "published_date": "2025-02-02 05:48:44 UTC",
      "updated_date": "2025-02-02 05:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:01:13.244081"
    },
    {
      "arxiv_id": "2502.00677v1",
      "title": "LLM-based event log analysis techniques: A survey",
      "title_zh": "基于 LLM 的事件日志分析技术：综述",
      "authors": [
        "Siraaj Akhtar",
        "Saad Khan",
        "Simon Parkinson"
      ],
      "abstract": "Event log analysis is an important task that security professionals\nundertake. Event logs record key information on activities that occur on\ncomputing devices, and due to the substantial number of events generated, they\nconsume a large amount of time and resources to analyse. This demanding and\nrepetitive task is also prone to errors. To address these concerns, researchers\nhave developed automated techniques to improve the event log analysis process.\nLarge Language Models (LLMs) have recently demonstrated the ability to\nsuccessfully perform a wide range of tasks that individuals would usually\npartake in, to high standards, and at a pace and degree of complexity that\noutperform humans. Due to this, researchers are rapidly investigating the use\nof LLMs for event log analysis. This includes fine-tuning, Retrieval-Augmented\nGeneration (RAG) and in-context learning, which affect performance. These works\ndemonstrate good progress, yet there is a need to understand the developing\nbody of knowledge, identify commonalities between works, and identify key\nchallenges and potential solutions to further developments in this domain. This\npaper aims to survey LLM-based event log analysis techniques, providing readers\nwith an in-depth overview of the domain, gaps identified in previous research,\nand concluding with potential avenues to explore in future.",
      "tldr_zh": "本文对基于大语言模型 (LLMs) 的事件日志分析技术进行调查，旨在解决安全专业人员在分析海量事件日志时面临的耗时、资源密集和易出错问题。调查涵盖了多种LLMs应用方法，包括微调(fine-tuning)、检索增强生成(RAG)以及上下文学习(in-context learning)，这些技术已在相关研究中显示出显著进步。论文总结了现有知识的共同点、关键挑战，并提出未来研究方向，如填补研究空白以提升事件日志分析的效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00677v1",
      "published_date": "2025-02-02 05:28:17 UTC",
      "updated_date": "2025-02-02 05:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:59:24.234013"
    },
    {
      "arxiv_id": "2502.05206v3",
      "title": "Safety at Scale: A Comprehensive Survey of Large Model Safety",
      "title_zh": "大规模安全：大型模型安全的全面综述",
      "authors": [
        "Xingjun Ma",
        "Yifeng Gao",
        "Yixu Wang",
        "Ruofan Wang",
        "Xin Wang",
        "Ye Sun",
        "Yifan Ding",
        "Hengyuan Xu",
        "Yunhao Chen",
        "Yunhan Zhao",
        "Hanxun Huang",
        "Yige Li",
        "Jiaming Zhang",
        "Xiang Zheng",
        "Yang Bai",
        "Zuxuan Wu",
        "Xipeng Qiu",
        "Jingfeng Zhang",
        "Yiming Li",
        "Xudong Han",
        "Haonan Li",
        "Jun Sun",
        "Cong Wang",
        "Jindong Gu",
        "Baoyuan Wu",
        "Siheng Chen",
        "Tianwei Zhang",
        "Yang Liu",
        "Mingming Gong",
        "Tongliang Liu",
        "Shirui Pan",
        "Cihang Xie",
        "Tianyu Pang",
        "Yinpeng Dong",
        "Ruoxi Jia",
        "Yang Zhang",
        "Shiqing Ma",
        "Xiangyu Zhang",
        "Neil Gong",
        "Chaowei Xiao",
        "Sarah Erfani",
        "Tim Baldwin",
        "Bo Li",
        "Masashi Sugiyama",
        "Dacheng Tao",
        "James Bailey",
        "Yu-Gang Jiang"
      ],
      "abstract": "The rapid advancement of large models, driven by their exceptional abilities\nin learning and generalization through large-scale pre-training, has reshaped\nthe landscape of Artificial Intelligence (AI). These models are now\nfoundational to a wide range of applications, including conversational AI,\nrecommendation systems, autonomous driving, content generation, medical\ndiagnostics, and scientific discovery. However, their widespread deployment\nalso exposes them to significant safety risks, raising concerns about\nrobustness, reliability, and ethical implications. This survey provides a\nsystematic review of current safety research on large models, covering Vision\nFoundation Models (VFMs), Large Language Models (LLMs), Vision-Language\nPre-training (VLP) models, Vision-Language Models (VLMs), Diffusion Models\n(DMs), and large-model-based Agents. Our contributions are summarized as\nfollows: (1) We present a comprehensive taxonomy of safety threats to these\nmodels, including adversarial attacks, data poisoning, backdoor attacks,\njailbreak and prompt injection attacks, energy-latency attacks, data and model\nextraction attacks, and emerging agent-specific threats. (2) We review defense\nstrategies proposed for each type of attacks if available and summarize the\ncommonly used datasets and benchmarks for safety research. (3) Building on\nthis, we identify and discuss the open challenges in large model safety,\nemphasizing the need for comprehensive safety evaluations, scalable and\neffective defense mechanisms, and sustainable data practices. More importantly,\nwe highlight the necessity of collective efforts from the research community\nand international collaboration. Our work can serve as a useful reference for\nresearchers and practitioners, fostering the ongoing development of\ncomprehensive defense systems and platforms to safeguard AI models.",
      "tldr_zh": "这篇论文对大型模型的安全问题进行了全面调查，涵盖了Vision Foundation Models (VFMs)、Large Language Models (LLMs)、Vision-Language Pre-training (VLP) 模型、Vision-Language Models (VLMs)、Diffusion Models (DMs) 和基于大型模型的Agents。论文提出了一套系统性分类，包括对抗攻击、数据中毒、后门攻击、越狱和提示注入攻击、能量-延迟攻击、数据和模型提取攻击等安全威胁，并回顾了针对这些威胁的防御策略以及常用的数据集和基准。最终，它强调了当前挑战，如需要更全面的安全评估、可扩展防御机制和可持续数据实践，并呼吁研究社区和国际合作来推动AI模型的安全发展。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "47 pages, 3 figures, 11 tables; GitHub:\n  https://github.com/xingjunm/Awesome-Large-Model-Safety",
      "pdf_url": "http://arxiv.org/pdf/2502.05206v3",
      "published_date": "2025-02-02 05:14:22 UTC",
      "updated_date": "2025-03-19 16:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:59:36.752080"
    },
    {
      "arxiv_id": "2502.01680v1",
      "title": "Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules into Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Kamal Acharya",
        "Mehul Lad",
        "Liang Sun",
        "Houbing Song"
      ],
      "abstract": "Travel demand prediction is crucial for optimizing transportation planning,\nresource allocation, and infrastructure development, ensuring efficient\nmobility and economic sustainability. This study introduces a Neurosymbolic\nArtificial Intelligence (Neurosymbolic AI) framework that integrates decision\ntree (DT)-based symbolic rules with neural networks (NNs) to predict travel\ndemand, leveraging the interpretability of symbolic reasoning and the\npredictive power of neural learning. The framework utilizes data from diverse\nsources, including geospatial, economic, and mobility datasets, to build a\ncomprehensive feature set. DTs are employed to extract interpretable if-then\nrules that capture key patterns, which are then incorporated as additional\nfeatures into a NN to enhance its predictive capabilities. Experimental results\nshow that the combined dataset, enriched with symbolic rules, consistently\noutperforms standalone datasets across multiple evaluation metrics, including\nMean Absolute Error (MAE), \\(R^2\\), and Common Part of Commuters (CPC). Rules\nselected at finer variance thresholds (e.g., 0.0001) demonstrate superior\neffectiveness in capturing nuanced relationships, reducing prediction errors,\nand aligning with observed commuter patterns. By merging symbolic and neural\nlearning paradigms, this Neurosymbolic approach achieves both interpretability\nand accuracy.",
      "tldr_zh": "本研究提出了一种Neurosymbolic AI框架，用于旅行需求预测，将Decision Tree (DT)生成的符号规则整合到Neural Networks (NNs)中，结合符号推理的可解释性和神经学习的预测能力。框架利用地理空间、经济和流动性数据集构建特征集，通过DT提取可解释的if-then规则，并作为额外特征输入NN以提升预测准确性。实验结果显示，加入符号规则的整合模型在Mean Absolute Error (MAE)、\\(R^2\\)和Common Part of Commuters (CPC)等多项指标上优于独立模型，使用更精细的方差阈值（如0.0001）能更好地捕捉细微关系、减少预测错误，并与实际通勤模式一致。这种方法实现了预测的解释性和精确性的平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 figures, this paper is under review in the conference",
      "pdf_url": "http://arxiv.org/pdf/2502.01680v1",
      "published_date": "2025-02-02 05:10:31 UTC",
      "updated_date": "2025-02-02 05:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:59:48.446173"
    },
    {
      "arxiv_id": "2502.00672v2",
      "title": "Biogeochemistry-Informed Neural Network (BINN) for Improving Accuracy of Model Prediction and Scientific Understanding of Soil Organic Carbon",
      "title_zh": "生物地球化学信息神经网络 (BINN) 用于",
      "authors": [
        "Haodi Xu",
        "Joshua Fan",
        "Feng Tao",
        "Lifen Jiang",
        "Fengqi You",
        "Benjamin Z. Houlton",
        "Ying Sun",
        "Carla P. Gomes",
        "Yiqi Luo"
      ],
      "abstract": "Big data and the rapid development of artificial intelligence (AI) provide\nunprecedented opportunities to enhance our understanding of the global carbon\ncycle and other biogeochemical processes. However, retrieving mechanistic\nknowledge from big data remains a challenge. Here, we develop a\nBiogeochemistry-Informed Neural Network (BINN) that seamlessly integrates a\nvectorized process-based soil carbon cycle model (i.e., Community Land Model\nversion 5, CLM5) into a neural network (NN) structure to examine mechanisms\ngoverning soil organic carbon (SOC) storage from big data. BINN demonstrates\nhigh accuracy in retrieving biogeochemical parameter values from synthetic data\nin a parameter recovery experiment. We use BINN to predict six major processes\nregulating the soil carbon cycle (or components in process-based models) from\n25,925 observed SOC profiles across the conterminous US and compared them with\nthe same processes previously retrieved by a Bayesian inference-based\nPROcess-guided deep learning and DAta-driven modeling (PRODA) approach (Tao et\nal. 2020; 2023). The high agreement between the spatial patterns of the\nretrieved processes using the two approaches with an average correlation\ncoefficient of 0.81 confirms BINN's ability in retrieving mechanistic knowledge\nfrom big data. Additionally, the integration of neural networks and\nprocess-based models in BINN improves computational efficiency by more than 50\ntimes over PRODA. We conclude that BINN is a transformative tool that harnesses\nthe power of both AI and process-based modeling, facilitating new scientific\ndiscoveries while improving interpretability and accuracy of Earth system\nmodels.",
      "tldr_zh": "本文开发了 Biogeochemistry-Informed Neural Network (BINN)，通过将过程-based 土壤碳循环模型（如 Community Land Model version 5, CLM5）整合到神经网络结构中，从大数据中提取土壤有机碳 (SOC) 存储的机制知识。BINN 在参数恢复实验中表现出高准确性，并成功预测了从 25,925 个观测 SOC 配置文件中提取的六个主要土壤碳循环过程，与 Bayesian inference-based PRODA 方法的结果平均相关系数达 0.81。相比 PRODA，BINN 的计算效率提高了 50 倍以上，提供了一个结合 AI 和过程-based 建模的工具，提升了 Earth 系统模型的准确性、可解释性和科学发现潜力。",
      "categories": [
        "physics.geo-ph",
        "cs.AI"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "60 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00672v2",
      "published_date": "2025-02-02 05:02:42 UTC",
      "updated_date": "2025-02-06 18:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:00:01.567816"
    },
    {
      "arxiv_id": "2502.00666v2",
      "title": "Avoiding $\\mathbf{exp(R_{max})}$ scaling in RLHF through Preference-based Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyu Chen",
        "Yiding Chen",
        "Wen Sun",
        "Xuezhou Zhang"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a pivotal\ntechnique for large language model (LLM) alignment. This paper studies the\nsetting of online RLHF and focus on improving sample efficiency. All existing\nalgorithms in online RLHF, whether doing passive exploration or active\nexploration, suffer from a sample complexity that scales exponentially with the\nscale of the reward function. This fundamental limitation hinders their\neffectiveness in scenarios with heavily skewed preferences, e.g. questions with\na unique correct solution. To address this, we introduce Self-Exploring\nPreference-Incentive Online Preference Optimization (SE-POPO), an online RLHF\nalgorithm that for the first time achieves a sample complexity that scales\npolynomially with the reward scale, answering an open problem raised by Xie et\nal. (2024).. Theoretically, we demonstrate that the sample complexity of\nSE-POPO dominates that of existing exploration algorithms. Empirically, our\nsystematic evaluation confirms that SE-POPO is more sample-efficient than both\nexploratory and non-exploratory baselines, in two primary application scenarios\nof RLHF as well as on public benchmarks, marking a significant step forward in\nRLHF algorithm design. The code is available at\nhttps://github.com/MYC000801/SE-POPO.",
      "tldr_zh": "本论文探讨了在线强化学习从人类反馈（RLHF）中的样本效率问题，指出现有算法的样本复杂度会指数级增长与奖励函数规模相关，导致在偏好严重倾斜的场景（如唯一正确解决方案的问题）中效率低下。为解决此问题，作者引入了 Self-Exploring Preference-Incentive Online Preference Optimization (SE-POPO) 算法，该算法首次实现了与奖励规模呈多项式级的样本复杂度。理论分析和实验验证表明，SE-POPO 在 RLHF 的主要应用场景和公共基准上，比现有探索和非探索基线更高效，显著推进了 RLHF 算法设计。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00666v2",
      "published_date": "2025-02-02 04:40:04 UTC",
      "updated_date": "2025-02-09 20:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:00:13.501223"
    },
    {
      "arxiv_id": "2502.00663v1",
      "title": "Enhanced Convolutional Neural Networks for Improved Image Classification",
      "title_zh": "增强卷积神经网络用于改进图像分类",
      "authors": [
        "Xiaoran Yang",
        "Shuhan Yu",
        "Wenxi Xu"
      ],
      "abstract": "Image classification is a fundamental task in computer vision with diverse\napplications, ranging from autonomous systems to medical imaging. The CIFAR-10\ndataset is a widely used benchmark to evaluate the performance of\nclassification models on small-scale, multi-class datasets. Convolutional\nNeural Networks (CNNs) have demonstrated state-of-the-art results; however,\nthey often suffer from overfitting and suboptimal feature representation when\napplied to challenging datasets like CIFAR-10. In this paper, we propose an\nenhanced CNN architecture that integrates deeper convolutional blocks, batch\nnormalization, and dropout regularization to achieve superior performance. The\nproposed model achieves a test accuracy of 84.95%, outperforming baseline CNN\narchitectures. Through detailed ablation studies, we demonstrate the\neffectiveness of the enhancements and analyze the hierarchical feature\nrepresentations. This work highlights the potential of refined CNN\narchitectures for tackling small-scale image classification problems\neffectively.",
      "tldr_zh": "本研究针对图像分类任务中CNNs（如在CIFAR-10数据集上）存在的过拟合和特征表示不足问题，提出了一种增强型CNN架构。该架构整合了更深的卷积块、batch normalization和dropout regularization，以提升模型性能。实验结果显示，该模型在CIFAR-10上实现了84.95%的测试准确率，优于传统基线CNNs。通过消融研究，该工作证明了这些增强措施的有效性，并分析了分层特征表示的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00663v1",
      "published_date": "2025-02-02 04:32:25 UTC",
      "updated_date": "2025-02-02 04:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:00:24.730675"
    },
    {
      "arxiv_id": "2502.01678v2",
      "title": "LEAD: Large Foundation Model for EEG-Based Alzheimer's Disease Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yihe Wang",
        "Nan Huang",
        "Nadia Mammone",
        "Marco Cecchi",
        "Xiang Zhang"
      ],
      "abstract": "Electroencephalogram (EEG) provides a non-invasive, highly accessible, and\ncost-effective solution for Alzheimer's Disease (AD) detection. However,\nexisting methods, whether based on manual feature extraction or deep learning,\nface two major challenges: the lack of large-scale datasets for robust feature\nlearning and evaluation, and poor detection performance due to inter-subject\nvariations. To address these challenges, we curate an EEG-AD corpus containing\n813 subjects, which forms the world's largest EEG-AD dataset to the best of our\nknowledge. Using this unique dataset, we propose LEAD, the first large\nfoundation model for EEG-based AD detection. Our method encompasses an entire\npipeline, from data selection and preprocessing to self-supervised contrastive\npretraining, fine-tuning, and key setups such as subject-independent evaluation\nand majority voting for subject-level detection. We pre-train the model on 11\nEEG datasets and unified fine-tune it on 5 AD datasets. Our self-supervised\npre-training design includes sample-level and subject-level contrasting to\nextract useful general EEG features. Fine-tuning is performed on 5\nchannel-aligned datasets together. The backbone encoder incorporates temporal\nand channel embeddings to capture features across both temporal and spatial\ndimensions. Our method demonstrates outstanding AD detection performance,\nachieving up to a 9.86% increase in F1 score at the sample-level and up to a\n9.31% at the subject-level compared to state-of-the-art methods. The results of\nour model strongly confirm the effectiveness of contrastive pre-training and\nchannel-aligned unified fine-tuning for addressing inter-subject variation. The\nsource code is at https://github.com/DL4mHealth/LEAD.",
      "tldr_zh": "这篇论文构建了世界上最大的 EEG-AD 数据集（包含 813 个受试者），并提出 LEAD，这是第一个基于 EEG 的阿尔茨海默病（Alzheimer's Disease, AD）检测大型 foundation model，以解决数据集规模不足和个体间变异导致的检测性能问题。LEAD 模型包括数据预处理、自监督对比预训练（涉及样本级和主体级对比以提取一般 EEG 特征）、以及统一微调策略，使用 11 个 EEG 数据集预训练和 5 个通道对齐的 AD 数据集微调。实验结果显示，LEAD 在样本级 F1 分数提高了 9.86%，在主体级提高了 9.31%，证实了对比预训练和通道对齐微调的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01678v2",
      "published_date": "2025-02-02 04:19:35 UTC",
      "updated_date": "2025-02-10 17:11:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:00:37.675249"
    },
    {
      "arxiv_id": "2502.00657v1",
      "title": "LLM Safety Alignment is Divergence Estimation in Disguise",
      "title_zh": "翻译失败",
      "authors": [
        "Rajdeep Haldar",
        "Ziyi Wang",
        "Qifan Song",
        "Guang Lin",
        "Yue Xing"
      ],
      "abstract": "We propose a theoretical framework demonstrating that popular Large Language\nModel (LLM) alignment methods, including Reinforcement Learning from Human\nFeedback (RLHF) and alternatives, fundamentally function as divergence\nestimators between aligned (preferred or safe) and unaligned (less-preferred or\nharmful) distributions. This explains the separation phenomenon between safe\nand harmful prompts in the model hidden representation after alignment.\nInspired by the theoretical results, we identify that some alignment methods\nare better than others in terms of separation and, introduce a new method,\nKLDO, and further demonstrate the implication of our theories. We advocate for\ncompliance-refusal datasets over preference datasets to enhance safety\nalignment, supported by both theoretical reasoning and empirical evidence.\nAdditionally, to quantify safety separation, we leverage a distance metric in\nthe representation space and statistically validate its efficacy as a\nstatistical significant indicator of LLM resilience against jailbreak attacks.",
      "tldr_zh": "本研究提出一个理论框架，将流行的LLM安全对齐方法（如RLHF）视为aligned（安全）与unaligned（有害）分布之间divergence估计的过程，从而解释对齐后模型隐藏表示中安全与有害提示的分离现象。基于这一理论，作者比较了不同对齐方法的分离效果，并引入新方法KLDO，以进一步验证理论含义。研究主张使用compliance-refusal数据集而非preference数据集来提升LLM的安全性，并通过理论推理和实证证据支持这一观点。同时，作者利用表示空间中的距离度量来量化安全分离，并统计验证其作为LLM抵抗jailbreak attacks的显著指标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00657v1",
      "published_date": "2025-02-02 04:09:42 UTC",
      "updated_date": "2025-02-02 04:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:01:24.028869"
    },
    {
      "arxiv_id": "2502.00648v1",
      "title": "Agency in the Age of AI",
      "title_zh": "翻译失败",
      "authors": [
        "Samarth Swarup"
      ],
      "abstract": "There is significant concern about the impact of generative AI on society.\nModern AI tools are capable of generating ever more realistic text, images, and\nvideos, and functional code, from minimal prompts. Accompanying this rise in\nability and usability, there is increasing alarm about the misuses to which\nthese tools can be put, and the intentional and unintentional harms to\nindividuals and society that may result. In this paper, we argue that\n\\emph{agency} is the appropriate lens to study these harms and benefits, but\nthat doing so will require advancement in the theory of agency, and advancement\nin how this theory is applied in (agent-based) models.",
      "tldr_zh": "本论文讨论了生成式AI（generative AI）对社会的影响，强调现代AI工具能够从简单提示生成逼真的文本、图像、视频和代码，从而引发对潜在误用及其对个人和社会的故意或无意伤害的担忧。作者主张，将“agency”（代理性）作为研究这些危害和益处的合适视角，以更好地分析AI的影响。论文呼吁推进agency的理论发展，并改进其在（基于agent的）模型中的应用，以应对AI时代的新挑战。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00648v1",
      "published_date": "2025-02-02 03:27:19 UTC",
      "updated_date": "2025-02-02 03:27:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:01:34.909904"
    },
    {
      "arxiv_id": "2502.00646v1",
      "title": "TrojanTime: Backdoor Attacks on Time Series Classification",
      "title_zh": "TrojanTime: 针对时间序列分类的后门攻击",
      "authors": [
        "Chang Dong",
        "Zechao Sun",
        "Guangdong Bai",
        "Shuying Piao",
        "Weitong Chen",
        "Wei Emma Zhang"
      ],
      "abstract": "Time Series Classification (TSC) is highly vulnerable to backdoor attacks,\nposing significant security threats. Existing methods primarily focus on data\npoisoning during the training phase, designing sophisticated triggers to\nimprove stealthiness and attack success rate (ASR). However, in practical\nscenarios, attackers often face restrictions in accessing training data.\nMoreover, it is a challenge for the model to maintain generalization ability on\nclean test data while remaining vulnerable to poisoned inputs when data is\ninaccessible. To address these challenges, we propose TrojanTime, a novel\ntwo-step training algorithm. In the first stage, we generate a pseudo-dataset\nusing an external arbitrary dataset through target adversarial attacks. The\nclean model is then continually trained on this pseudo-dataset and its poisoned\nversion. To ensure generalization ability, the second stage employs a carefully\ndesigned training strategy, combining logits alignment and batch norm freezing.\nWe evaluate TrojanTime using five types of triggers across four TSC\narchitectures in UCR benchmark datasets from diverse domains. The results\ndemonstrate the effectiveness of TrojanTime in executing backdoor attacks while\nmaintaining clean accuracy. Finally, to mitigate this threat, we propose a\ndefensive unlearning strategy that effectively reduces the ASR while preserving\nclean accuracy.",
      "tldr_zh": "该研究探讨了时间序列分类 (TSC) 面临的后门攻击 (backdoor attacks) 威胁，提出了一种新型算法 TrojanTime，以应对攻击者无法访问训练数据的实际挑战。TrojanTime 采用两步训练策略：首先，通过目标对抗攻击 (target adversarial attacks) 从外部数据集生成伪数据集，并在其干净和投毒版本上持续训练模型；其次，使用 logits alignment 和 batch norm freezing 等技术，确保模型在干净测试数据上保持泛化能力。实验在 UCR 基准数据集上，使用五种触发器和四种 TSC 架构，证明 TrojanTime 能有效提高攻击成功率 (ASR) 同时维持干净准确率。最后，该论文还提出了一种防御性 unlearning 策略，能够显著降低 ASR 而不影响模型性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "I.2.0"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.00646v1",
      "published_date": "2025-02-02 03:24:24 UTC",
      "updated_date": "2025-02-02 03:24:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:01:48.828798"
    },
    {
      "arxiv_id": "2502.00641v2",
      "title": "Evaluating Small Language Models for News Summarization: Implications and Factors Influencing Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Borui Xu",
        "Yao Chen",
        "Zeyi Wen",
        "Weiguo Liu",
        "Bingsheng He"
      ],
      "abstract": "The increasing demand for efficient summarization tools in\nresource-constrained environments highlights the need for effective solutions.\nWhile large language models (LLMs) deliver superior summarization quality,\ntheir high computational resource requirements limit practical use\napplications. In contrast, small language models (SLMs) present a more\naccessible alternative, capable of real-time summarization on edge devices.\nHowever, their summarization capabilities and comparative performance against\nLLMs remain underexplored. This paper addresses this gap by presenting a\ncomprehensive evaluation of 19 SLMs for news summarization across 2,000 news\nsamples, focusing on relevance, coherence, factual consistency, and summary\nlength. Our findings reveal significant variations in SLM performance, with\ntop-performing models such as Phi3-Mini and Llama3.2-3B-Ins achieving results\ncomparable to those of 70B LLMs while generating more concise summaries.\nNotably, SLMs are better suited for simple prompts, as overly complex prompts\nmay lead to a decline in summary quality. Additionally, our analysis indicates\nthat instruction tuning does not consistently enhance the news summarization\ncapabilities of SLMs. This research not only contributes to the understanding\nof SLMs but also provides practical insights for researchers seeking efficient\nsummarization solutions that balance performance and resource use.",
      "tldr_zh": "本研究评估了19个Small Language Models (SLMs)在新闻摘要任务中的性能，旨在解决资源受限环境下高效摘要工具的需求，与Large Language Models (LLMs)进行对比。研究使用2000个新闻样本，重点考察摘要的相关性、一致性、事实准确性和长度，结果显示顶级SLMs如Phi3-Mini和Llama3.2-3B-Ins可与70B LLMs匹敌，同时生成更简洁的摘要。发现SLMs更适合简单提示，而复杂提示或指令微调并不能一致提升性能，此研究为寻求性能与资源平衡的摘要解决方案提供了实用见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00641v2",
      "published_date": "2025-02-02 03:07:45 UTC",
      "updated_date": "2025-02-11 13:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:02:00.123578"
    },
    {
      "arxiv_id": "2502.00640v1",
      "title": "CollabLLM: From Passive Responders to Active Collaborators",
      "title_zh": "翻译失败",
      "authors": [
        "Shirley Wu",
        "Michel Galley",
        "Baolin Peng",
        "Hao Cheng",
        "Gavin Li",
        "Yao Dou",
        "Weixin Cai",
        "James Zou",
        "Jure Leskovec",
        "Jianfeng Gao"
      ],
      "abstract": "Large Language Models are typically trained with next-turn rewards, limiting\ntheir ability to optimize for long-term interaction. As a result, they often\nrespond passively to ambiguous or open-ended user requests, failing to help\nusers reach their ultimate intents and leading to inefficient conversations. To\naddress these limitations, we introduce CollabLLM, a novel and general training\nframework that enhances multiturn human-LLM collaboration. Its key innovation\nis a collaborative simulation that estimates the long-term contribution of\nresponses using Multiturn-aware Rewards. By reinforcement fine-tuning these\nrewards, CollabLLM goes beyond responding to user requests, and actively\nuncovers user intent and offers insightful suggestions-a key step towards more\nhuman-centered AI. We also devise a multiturn interaction benchmark with three\nchallenging tasks such as document creation. CollabLLM significantly\noutperforms our baselines with averages of 18.5% higher task performance and\n46.3% improved interactivity by LLM judges. Finally, we conduct a large user\nstudy with 201 judges, where CollabLLM increases user satisfaction by 17.6% and\nreduces user spent time by 10.4%.",
      "tldr_zh": "该研究针对大语言模型(LLMs)被动响应的局限性，提出CollabLLM框架，通过协作模拟和Multiturn-aware Rewards的强化微调，优化多轮人类-LLM交互，使模型主动揭示用户意图并提供见解。CollabLLM在多轮交互基准测试中（如文档创建任务）比基线模型提升18.5%的任务性能和46.3%的交互性。用户研究显示，该框架提高了17.6%的用户满意度和减少了10.4%的用户花费时间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.00640v1",
      "published_date": "2025-02-02 03:05:52 UTC",
      "updated_date": "2025-02-02 03:05:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:02:13.218113"
    },
    {
      "arxiv_id": "2502.00639v2",
      "title": "Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Ren",
        "Zishi Zhang",
        "Zehao Li",
        "Jingyang Jiang",
        "Shentao Qin",
        "Guanghao Li",
        "Yan Li",
        "Yi Zheng",
        "Xinping Li",
        "Min Zhan",
        "Yijie Peng"
      ],
      "abstract": "The probabilistic diffusion model (DM), generating content by inferencing\nthrough a recursive chain structure, has emerged as a powerful framework for\nvisual generation. After pre-training on enormous unlabeled data, the model\nneeds to be properly aligned to meet requirements for downstream applications.\nHow to efficiently align the foundation DM is a crucial task. Contemporary\nmethods are either based on Reinforcement Learning (RL) or truncated\nBackpropagation (BP). However, RL and truncated BP suffer from low sample\nefficiency and biased gradient estimation respectively, resulting in limited\nimprovement or, even worse, complete training failure. To overcome the\nchallenges, we propose the Recursive Likelihood Ratio (RLR) optimizer, a\nzeroth-order informed fine-tuning paradigm for DM. The zeroth-order gradient\nestimator enables the computation graph rearrangement within the recursive\ndiffusive chain, making the RLR's gradient estimator an unbiased one with the\nlower variance than other methods. We provide theoretical guarantees for the\nperformance of the RLR. Extensive experiments are conducted on image and video\ngeneration tasks to validate the superiority of the RLR. Furthermore, we\npropose a novel prompt technique that is natural for the RLR to achieve a\nsynergistic effect.",
      "tldr_zh": "该论文针对扩散模型(Diffusion Model)的基础模型在下游应用中的对齐问题，提出了一种新的微调范式：Recursive Likelihood Ratio (RLR) 优化器。RLR 利用 zeroth-order 梯度估计器重排递归扩散链的计算图，实现无偏且低方差的梯度估计，从而克服了传统 Reinforcement Learning (RL) 的样本效率低和截断 Backpropagation (BP) 的偏差问题。实验结果显示，RLR 在图像和视频生成任务上表现出优越性能，并提供了理论保证；此外，论文还引入了一种新型提示技术，与 RLR 协同增强效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00639v2",
      "published_date": "2025-02-02 03:00:26 UTC",
      "updated_date": "2025-03-25 02:35:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:02:24.483212"
    },
    {
      "arxiv_id": "2502.00634v2",
      "title": "SimulPL: Aligning Human Preferences in Simultaneous Machine Translation",
      "title_zh": "SimulPL：同时机器翻译中人类偏好的对齐",
      "authors": [
        "Donglei Yu",
        "Yang Zhao",
        "Jie Zhu",
        "Yangyifan Xu",
        "Yu Zhou",
        "Chengqing Zong"
      ],
      "abstract": "Simultaneous Machine Translation (SiMT) generates translations while\nreceiving streaming source inputs. This requires the SiMT model to learn a\nread/write policy, deciding when to translate and when to wait for more source\ninput. Numerous linguistic studies indicate that audiences in SiMT scenarios\nhave distinct preferences, such as accurate translations, simpler syntax, and\nno unnecessary latency. Aligning SiMT models with these human preferences is\ncrucial to improve their performances. However, this issue still remains\nunexplored. Additionally, preference optimization for SiMT task is also\nchallenging. Existing methods focus solely on optimizing the generated\nresponses, ignoring human preferences related to latency and the optimization\nof read/write policy during the preference optimization phase. To address these\nchallenges, we propose Simultaneous Preference Learning (SimulPL), a preference\nlearning framework tailored for the SiMT task. In the SimulPL framework, we\ncategorize SiMT human preferences into five aspects: \\textbf{translation\nquality preference}, \\textbf{monotonicity preference}, \\textbf{key point\npreference}, \\textbf{simplicity preference}, and \\textbf{latency preference}.\nBy leveraging the first four preferences, we construct human preference prompts\nto efficiently guide GPT-4/4o in generating preference data for the SiMT task.\nIn the preference optimization phase, SimulPL integrates \\textbf{latency\npreference} into the optimization objective and enables SiMT models to improve\nthe read/write policy, thereby aligning with human preferences more\neffectively. Experimental results indicate that SimulPL exhibits better\nalignment with human preferences across all latency levels in\nZh$\\rightarrow$En, De$\\rightarrow$En and En$\\rightarrow$Zh SiMT tasks. Our data\nand code will be available at https://github.com/EurekaForNLP/SimulPL.",
      "tldr_zh": "本文提出 Simultaneous Preference Learning (SimulPL)，一个针对 Simultaneous Machine Translation (SiMT) 的偏好学习框架，旨在通过优化 read/write policy 来更好地对齐人类偏好，如翻译准确性、语法简易性和延迟最小化。SimulPL 将人类偏好分为五方面，包括 translation quality preference、monotonicity preference、key point preference、simplicity preference 和 latency preference，并利用前四种偏好构建提示引导 GPT-4/4o 生成相关数据。在偏好优化阶段，框架将 latency preference 整合到优化目标中，提升 SiMT 模型的决策能力。实验结果显示，SimulPL 在 Zh→En、De→En 和 En→Zh SiMT 任务中，在所有延迟水平上实现了显著的偏好对齐改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025. 23 pages,13 figures,11 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.00634v2",
      "published_date": "2025-02-02 02:47:09 UTC",
      "updated_date": "2025-02-05 12:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:02:38.512202"
    },
    {
      "arxiv_id": "2502.00633v1",
      "title": "Lipschitz Lifelong Monte Carlo Tree Search for Mastering Non-Stationary Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Zuyuan Zhang",
        "Tian Lan"
      ],
      "abstract": "Monte Carlo Tree Search (MCTS) has proven highly effective in solving complex\nplanning tasks by balancing exploration and exploitation using Upper Confidence\nBound for Trees (UCT). However, existing work have not considered MCTS-based\nlifelong planning, where an agent faces a non-stationary series of tasks --\ne.g., with varying transition probabilities and rewards -- that are drawn\nsequentially throughout the operational lifetime. This paper presents LiZero\nfor Lipschitz lifelong planning using MCTS. We propose a novel concept of\nadaptive UCT (aUCT) to transfer knowledge from a source task to the\nexploration/exploitation of a new task, depending on both the Lipschitz\ncontinuity between tasks and the confidence of knowledge in in Monte Carlo\naction sampling. We analyze LiZero's acceleration factor in terms of improved\nsampling efficiency and also develop efficient algorithms to compute aUCT in an\nonline fashion by both data-driven and model-based approaches, whose sampling\ncomplexity and error bounds are also characterized. Experiment results show\nthat LiZero significantly outperforms existing MCTS and lifelong learning\nbaselines in terms of much faster convergence (3$\\sim$4x) to optimal rewards.\nOur results highlight the potential of LiZero to advance decision-making and\nplanning in dynamic real-world environments.",
      "tldr_zh": "本论文提出LiZero，一种基于Lipschitz连续性的终身Monte Carlo Tree Search (MCTS)框架，用于应对非平稳任务序列，如任务过渡概率和奖励的变化。LiZero引入adaptive UCT (aUCT)机制，根据任务间的Lipschitz连续性和知识置信度，从源任务转移知识以优化探索和利用，并开发了数据驱动和模型驱动的方法来在线计算aUCT，同时分析了采样效率和错误边界。实验结果表明，LiZero比现有MCTS和终身学习基准快3~4倍收敛到最优奖励，展示了其在动态真实世界环境决策和规划中的显著潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00633v1",
      "published_date": "2025-02-02 02:45:20 UTC",
      "updated_date": "2025-02-02 02:45:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:02:49.285920"
    },
    {
      "arxiv_id": "2502.00629v1",
      "title": "Advanced Weakly-Supervised Formula Exploration for Neuro-Symbolic Mathematical Reasoning",
      "title_zh": "针对神经符号数学推理的高级弱监督公式探索",
      "authors": [
        "Yuxuan Wu",
        "Hideki Nakayama"
      ],
      "abstract": "In recent years, neuro-symbolic methods have become a popular and powerful\napproach that augments artificial intelligence systems with the capability to\nperform abstract, logical, and quantitative deductions with enhanced precision\nand controllability. Recent studies successfully performed symbolic reasoning\nby leveraging various machine learning models to explicitly or implicitly\npredict intermediate labels that provide symbolic instructions. However, these\nintermediate labels are not always prepared for every task as a part of\ntraining data, and pre-trained models, represented by Large Language Models\n(LLMs), also do not consistently generate valid symbolic instructions with\ntheir intrinsic knowledge. On the other hand, existing work developed\nalternative learning techniques that allow the learning system to autonomously\nuncover optimal symbolic instructions. Nevertheless, their performance also\nexhibits limitations when faced with relatively huge search spaces or more\nchallenging reasoning problems. In view of this, in this work, we put forward\nan advanced practice for neuro-symbolic reasoning systems to explore the\nintermediate labels with weak supervision from problem inputs and final\noutputs. Our experiments on the Mathematics dataset illustrated the\neffectiveness of our proposals from multiple aspects.",
      "tldr_zh": "该论文提出了一种先进的弱监督（weakly-supervised）公式探索方法，用于提升神经符号（neuro-symbolic）数学推理系统的性能。该方法通过从问题输入和最终输出中自主探索中间标签（intermediate labels），克服了现有技术的局限性，如对预训练模型（如 Large Language Models, LLMs）内在知识的依赖和在巨大搜索空间中的低效性。实验结果在 Mathematics 数据集上从多个方面验证了该方法的有效性，展示了其在抽象、逻辑和定量推理方面的精确性和可控性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00629v1",
      "published_date": "2025-02-02 02:34:36 UTC",
      "updated_date": "2025-02-02 02:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:02:59.991863"
    },
    {
      "arxiv_id": "2502.01677v2",
      "title": "Position: AI Scaling: From Up to Down and Out",
      "title_zh": "翻译失败",
      "authors": [
        "Yunke Wang",
        "Yanxi Li",
        "Chang Xu"
      ],
      "abstract": "AI Scaling has traditionally been synonymous with Scaling Up, which builds\nlarger and more powerful models. However, the growing demand for efficiency,\nadaptability, and collaboration across diverse applications necessitates a\nbroader perspective. This position paper presents a holistic framework for AI\nscaling, encompassing Scaling Up, Scaling Down, and Scaling Out. It argues that\nwhile Scaling Up of models faces inherent bottlenecks, the future trajectory of\nAI scaling lies in Scaling Down and Scaling Out. These paradigms address\ncritical technical and societal challenges, such as reducing carbon footprint,\nensuring equitable access, and enhancing cross-domain collaboration. We explore\ntransformative applications in healthcare, smart manufacturing, and content\ncreation, demonstrating how AI Scaling can enable breakthroughs in efficiency,\npersonalization, and global connectivity. Additionally, we highlight key\nchallenges, including balancing model complexity with interpretability,\nmanaging resource constraints, and fostering ethical development. By\nsynthesizing these approaches, we propose a unified roadmap that redefines the\nfuture of AI research and application, paving the way for advancements toward\nArtificial General Intelligence (AGI).",
      "tldr_zh": "这篇论文提出一个整体的 AI Scaling 框架，包括 Scaling Up、Scaling Down 和 Scaling Out，认为未来 AI 发展应转向 Scaling Down 和 Scaling Out，以克服 Scaling Up 的固有瓶颈并解决技术和社会挑战，如减少碳足迹、确保公平访问和增强跨领域合作。该框架在医疗、智能制造和内容创建等领域展示出显著潜力，可实现效率提升、个性化以及全球连接的突破。论文还讨论了关键挑战，包括平衡模型复杂性与可解释性、管理资源约束和促进道德发展，并为 AI 研究和应用提供一个统一的路线图，推动向 Artificial General Intelligence (AGI) 的进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.01677v2",
      "published_date": "2025-02-02 02:14:00 UTC",
      "updated_date": "2025-05-13 04:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:03:12.914803"
    },
    {
      "arxiv_id": "2502.00620v2",
      "title": "Representations Shape Weak-to-Strong Generalization: Theoretical Insights and Empirical Predictions",
      "title_zh": "表示塑造弱到强泛化：理论洞见与经验预测",
      "authors": [
        "Yihao Xue",
        "Jiping Li",
        "Baharan Mirzasoleiman"
      ],
      "abstract": "Weak-to-Strong Generalization (W2SG), where a weak model supervises a\nstronger one, serves as an important analogy for understanding how humans might\nguide superhuman intelligence in the future. Promising empirical results\nrevealed that a strong model can surpass its weak supervisor. While recent work\nhas offered theoretical insights into this phenomenon, a clear understanding of\nthe interactions between weak and strong models that drive W2SG remains\nelusive. We investigate W2SG through a theoretical lens and show that it can be\ncharacterized using kernels derived from the principal components of weak and\nstrong models' internal representations. These kernels can be used to define a\nspace that, at a high level, captures what the weak model is unable to learn\nbut is learnable by the strong model. The projection of labels onto this space\nquantifies how much the strong model falls short of its full potential due to\nweak supervision. This characterization also provides insights into how certain\nerrors in weak supervision can be corrected by the strong model, regardless of\noverfitting. Our theory has significant practical implications, providing a\nrepresentation-based metric that predicts W2SG performance trends without\nrequiring labels, as shown in experiments on molecular predictions with\ntransformers and 5 NLP tasks involving 52 LLMs.",
      "tldr_zh": "本文研究了 Weak-to-Strong Generalization (W2SG)，即弱模型监督强模型的现象，通过理论分析弱模型和强模型内部表示的 principal components 派生核来刻画其机制。该方法定义了一个空间，捕捉弱模型无法学习但强模型可学习的内容，并量化标签在该空间的投影，以评估强模型因弱监督而未达潜力的程度，同时解释了强模型如何纠正弱监督错误而不受过拟合影响。实验结果显示，这一理论提供了一个基于表示的指标，能在分子预测（使用 transformers）和 5 个 NLP 任务（涉及 52 个 LLMs）上准确预测 W2SG 性能趋势，而无需标签。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00620v2",
      "published_date": "2025-02-02 01:11:51 UTC",
      "updated_date": "2025-02-05 00:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:03:25.001620"
    },
    {
      "arxiv_id": "2502.00619v1",
      "title": "Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Yujin Oh",
        "Pengfei Jin",
        "Sangjoon Park",
        "Sekeun Kim",
        "Siyeop Yoon",
        "Kyungsang Kim",
        "Jin Sung Kim",
        "Xiang Li",
        "Quanzheng Li"
      ],
      "abstract": "Ensuring fairness in medical image segmentation is critical due to biases in\nimbalanced clinical data acquisition caused by demographic attributes (e.g.,\nage, sex, race) and clinical factors (e.g., disease severity). To address these\nchallenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired\nby optimal control theory. We provide a comprehensive analysis of its\nunderlying mechanisms and clarify dMoE's role in adapting to heterogeneous\ndistributions in medical image segmentation. Furthermore, we integrate dMoE\ninto multiple network architectures, demonstrating its broad applicability\nacross diverse medical image analysis tasks. By incorporating demographic and\nclinical factors, dMoE achieves state-of-the-art performance on two 2D\nbenchmark datasets and a 3D in-house dataset. Our results highlight the\neffectiveness of dMoE in mitigating biases from imbalanced distributions,\noffering a promising approach to bridging control theory and medical image\nsegmentation within fairness learning paradigms. The source code will be made\navailable.",
      "tldr_zh": "该研究针对医疗图像分割中由人口统计属性（如年龄、性别、种族）和临床因素（如疾病严重程度）导致的数据不平衡问题，提出了一种基于最优控制理论的 Distribution-aware Mixture of Experts (dMoE) 方法。dMoE 通过分析其底层机制并适应异质分布，将公平性学习整合到多种网络架构中，适用于多样化的医疗图像分析任务。在两个 2D 基准数据集和一个 3D 内部数据集上，dMoE 实现了最先进性能，有效缓解了偏差问题，并桥接了控制理论与公平性学习范式。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "12 pages, 3 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.00619v1",
      "published_date": "2025-02-02 01:10:31 UTC",
      "updated_date": "2025-02-02 01:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:03:37.031558"
    },
    {
      "arxiv_id": "2502.00618v1",
      "title": "DesCLIP: Robust Continual Adaptation via General Attribute Descriptions for Pretrained Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chiyuan He",
        "Zihuan Qiu",
        "Fanman Meng",
        "Linfeng Xu",
        "Qingbo Wu",
        "Hongliang Li"
      ],
      "abstract": "Continual adaptation of vision-language models (VLMs) focuses on leveraging\ncross-modal pretrained knowledge to incrementally adapt for expanding\ndownstream tasks and datasets, while tackling the challenge of knowledge\nforgetting. Existing research often focuses on connecting visual features with\nspecific class text in downstream tasks, overlooking the latent relationships\nbetween general and specialized knowledge. Our findings reveal that forcing\nmodels to optimize inappropriate visual-text matches exacerbates forgetting of\nVLMs. To tackle this issue, we propose DesCLIP, which leverages general\nattribute (GA) descriptions to guide the understanding of specific class\nobjects, enabling VLMs to establish robust \\textit{vision-GA-class} trilateral\nassociations rather than relying solely on \\textit{vision-class} connections.\nSpecifically, we introduce a language assistant to generate concrete GA\ndescription candidates via proper request prompts. Then, an anchor-based\nembedding filter is designed to obtain highly relevant GA description\nembeddings, which are leveraged as the paired text embeddings for\nvisual-textual instance matching, thereby tuning the visual encoder.\nCorrespondingly, the class text embeddings are gradually calibrated to align\nwith these shared GA description embeddings. Extensive experiments demonstrate\nthe advancements and efficacy of our proposed method, with comprehensive\nempirical evaluations highlighting its superior performance compared to\nexisting pretrained and VLM-based continual learning methods.",
      "tldr_zh": "该论文探讨了视觉语言模型 (VLMs) 的持续适应 (Continual Adaptation)，旨在利用预训练知识逐步适应新任务，同时解决知识遗忘问题。DesCLIP 方法通过引入一般属性 (General Attribute, GA) 描述来指导模型理解特定类对象，建立稳健的 vision-GA-class 三边关联，而非仅依赖 vision-class 连接；具体包括使用语言助手生成 GA 描述候选，并设计基于锚点的嵌入过滤器来优化视觉编码器和校准类文本嵌入。实验结果表明，DesCLIP 在各种下游任务上显著优于现有预训练和 VLM-based 持续学习方法，证明了其有效性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00618v1",
      "published_date": "2025-02-02 01:06:02 UTC",
      "updated_date": "2025-02-02 01:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:03:49.773707"
    },
    {
      "arxiv_id": "2502.00611v1",
      "title": "Enhancing Code Consistency in AI Research with Large Language Models and Retrieval-Augmented Generation",
      "title_zh": "使用大语言模型和检索增强生成提升人工智能研究中的代码一致性",
      "authors": [
        "Rajat Keshri",
        "Arun George Zachariah",
        "Michael Boone"
      ],
      "abstract": "Ensuring that code accurately reflects the algorithms and methods described\nin research papers is critical for maintaining credibility and fostering trust\nin AI research. This paper presents a novel system designed to verify code\nimplementations against the algorithms and methodologies outlined in\ncorresponding research papers. Our system employs Retrieval-Augmented\nGeneration to extract relevant details from both the research papers and code\nbases, followed by a structured comparison using Large Language Models. This\napproach improves the accuracy and comprehensiveness of code implementation\nverification while contributing to the transparency, explainability, and\nreproducibility of AI research. By automating the verification process, our\nsystem reduces manual effort, enhances research credibility, and ultimately\nadvances the state of the art in code verification.",
      "tldr_zh": "这篇论文提出了一种新系统，用于验证 AI 研究论文中的代码实现是否与算法和方法一致，从而提升研究的可信度和透明性。系统采用 Retrieval-Augmented Generation 从论文和代码库中提取相关细节，随后利用 Large Language Models 进行结构化比较，以提高验证的准确性和全面性。通过自动化流程，该系统减少了手动努力，促进了 AI 研究的解释性、可重复性，并推动了代码验证领域的进步。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00611v1",
      "published_date": "2025-02-02 00:35:42 UTC",
      "updated_date": "2025-02-02 00:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:04:00.061778"
    },
    {
      "arxiv_id": "2502.00604v1",
      "title": "Gradient Alignment in Physics-informed Neural Networks: A Second-Order Optimization Perspective",
      "title_zh": "物理信息神经网络中的梯度对齐：二阶优化视角",
      "authors": [
        "Sifan Wang",
        "Ananyae Kumar Bhartari",
        "Bowen Li",
        "Paris Perdikaris"
      ],
      "abstract": "Multi-task learning through composite loss functions is fundamental to modern\ndeep learning, yet optimizing competing objectives remains challenging. We\npresent new theoretical and practical approaches for addressing directional\nconflicts between loss terms, demonstrating their effectiveness in\nphysics-informed neural networks (PINNs) where such conflicts are particularly\nchallenging to resolve. Through theoretical analysis, we demonstrate how these\nconflicts limit first-order methods and show that second-order optimization\nnaturally resolves them through implicit gradient alignment. We prove that\nSOAP, a recently proposed quasi-Newton method, efficiently approximates the\nHessian preconditioner, enabling breakthrough performance in PINNs:\nstate-of-the-art results on 10 challenging PDE benchmarks, including the first\nsuccessful application to turbulent flows with Reynolds numbers up to 10,000,\nwith 2-10x accuracy improvements over existing methods. We also introduce a\nnovel gradient alignment score that generalizes cosine similarity to multiple\ngradients, providing a practical tool for analyzing optimization dynamics. Our\nfindings establish frameworks for understanding and resolving gradient\nconflicts, with broad implications for optimization beyond scientific\ncomputing.",
      "tldr_zh": "本研究从第二阶优化视角探讨了物理信息神经网络 (PINNs) 中梯度对齐问题，针对多任务学习中复合损失函数的方向冲突提出新理论和实践方法。论文证明，第一阶优化方法受这些冲突限制，而第二阶优化通过隐式梯度对齐自然解决，并展示了 SOAP（一种准牛顿方法）能高效近似 Hessian 预处理程序，从而在 PINNs 上实现突破性性能。实验结果显示，该方法在 10 个挑战性 PDE 基准上达到最先进水平，包括首次成功应用于 Reynolds 数高达 10,000 的湍流流动，准确率较现有方法提高 2-10 倍。该研究还引入了新的梯度对齐分数，以泛化余弦相似度用于分析优化动态，并为解决梯度冲突提供更广泛的框架，适用于科学计算以外领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "39 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00604v1",
      "published_date": "2025-02-02 00:21:45 UTC",
      "updated_date": "2025-02-02 00:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:04:12.575782"
    },
    {
      "arxiv_id": "2502.06803v1",
      "title": "Emotion Recognition and Generation: A Comprehensive Review of Face, Speech, and Text Modalities",
      "title_zh": "情感识别和生成：面部、语音和文本模态的全面综述",
      "authors": [
        "Rebecca Mobbs",
        "Dimitrios Makris",
        "Vasileios Argyriou"
      ],
      "abstract": "Emotion recognition and generation have emerged as crucial topics in\nArtificial Intelligence research, playing a significant role in enhancing\nhuman-computer interaction within healthcare, customer service, and other\nfields. Although several reviews have been conducted on emotion recognition and\ngeneration as separate entities, many of these works are either fragmented or\nlimited to specific methodologies, lacking a comprehensive overview of recent\ndevelopments and trends across different modalities. In this survey, we provide\na holistic review aimed at researchers beginning their exploration in emotion\nrecognition and generation. We introduce the fundamental principles underlying\nemotion recognition and generation across facial, vocal, and textual\nmodalities. This work categorises recent state-of-the-art research into\ndistinct technical approaches and explains the theoretical foundations and\nmotivations behind these methodologies, offering a clearer understanding of\ntheir application. Moreover, we discuss evaluation metrics, comparative\nanalyses, and current limitations, shedding light on the challenges faced by\nresearchers in the field. Finally, we propose future research directions to\naddress these challenges and encourage further exploration into developing\nrobust, effective, and ethically responsible emotion recognition and generation\nsystems.",
      "tldr_zh": "这篇综述论文全面审视了Emotion Recognition and Generation在人工智能中的关键作用，特别是提升人机交互在医疗和客服等领域的应用。与现有研究不同，本文提供了一个整合性概述，涵盖面部、语音和文本模态的基本原理、最新技术方法及其理论基础。论文分类了State-of-the-Art研究，讨论了评估指标、比较分析以及当前面临的挑战，如方法碎片化和局限性。最后，它提出未来研究方向，旨在解决这些问题并推动开发更鲁棒、有效且符合伦理的系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to ACM Computing Surveys",
      "pdf_url": "http://arxiv.org/pdf/2502.06803v1",
      "published_date": "2025-02-02 00:11:19 UTC",
      "updated_date": "2025-02-02 00:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:04:23.976918"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 76,
  "processed_papers_count": 76,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T06:04:41.350364"
}