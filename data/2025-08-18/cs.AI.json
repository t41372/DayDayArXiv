{
  "date": "2025-08-18",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-08-18 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv å……æ»¡äº†**â€œåè®­ç»ƒï¼ˆPost-trainingï¼‰â€æ—¶ä»£**çš„æ°”æ¯ã€‚ç ”ç©¶ç¤¾åŒºæ­£ç–¯ç‹‚åœ°æ¢ç´¢å¦‚ä½•è®©æ¨¡å‹å…·å¤‡æ›´å¼ºçš„**æ¨ç†èƒ½åŠ›ï¼ˆReasoningï¼‰**ï¼Œä» RLVRï¼ˆåŸºäºéªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼‰åœ¨å¼€æ”¾å¼ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œåˆ°ä¸“é—¨é’ˆå¯¹æ•°æ®åˆ†æå’Œè¯­éŸ³äº¤äº’çš„â€œæ…¢æ€è€ƒâ€æ¨¡å‹ï¼Œå¤§å®¶éƒ½åœ¨è¯•å›¾å¤ç°æˆ–è¶…è¶Š o1 çš„æ¨ç†èŒƒå¼ã€‚æ­¤å¤–ï¼Œ**AI for Science** è¿æ¥äº†é‡ç£…é€‰æ‰‹â€”â€”å¤ªé˜³ç‰©ç†å­¦çš„åŸºç¡€æ¨¡å‹ Suryaï¼›è€Œ**æ™ºèƒ½ä½“ï¼ˆAgentsï¼‰**çš„åº”ç”¨åœºæ™¯ä¹Ÿæå…¶ç¡¬æ ¸ï¼Œç›´æ¥æ€å…¥äº† Linux å†…æ ¸è°ƒä¼˜å’Œå¤æ‚çš„é‡‘èæŠ¥è¡¨è§£æé¢†åŸŸã€‚\n\n---\n\n### ğŸš€ æ·±åº¦æ¨ç†ä¸å¼ºåŒ–å­¦ä¹  (Reasoning & RL)\nè¿™ä¸€æ¿å—æ˜¯ä»Šå¤©çš„é‡å¤´æˆï¼Œæ ¸å¿ƒåœ¨äºé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œæ€ç»´é“¾ï¼ˆCoTï¼‰è®©æ¨¡å‹â€œå¤šæƒ³ä¸€æ­¥â€ã€‚\n\n**1. Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis**\n**Datarus-R1ï¼šç”¨äºè‡ªåŠ¨åŒ–æ•°æ®åˆ†æçš„è‡ªé€‚åº”å¤šæ­¥æ¨ç†å¤§æ¨¡å‹**\n> è¿™æ˜¯ä¸€ç¯‡éå¸¸æœ‰æ„æ€çš„å·¥ä½œã€‚ä½œè€…ä¸ä»…æ˜¯è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œè€Œæ˜¯è®­ç»ƒäº†ä¸€ä¸ªèƒ½ç»å†â€œAHA momentï¼ˆé¡¿æ‚Ÿæ—¶åˆ»ï¼‰â€çš„è™šæ‹Ÿæ•°æ®åˆ†æå¸ˆã€‚\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº† Datarus-R1-14Bï¼Œä¸€ä¸ªä¸“æ”»æ•°æ®åˆ†æå’Œç ”ç©¶ç”Ÿçº§éš¾é¢˜çš„æ¨¡å‹ã€‚\n*   **æ–¹æ³•**ï¼šä¸åŒäºç®€å•çš„é—®ç­”å¯¹è®­ç»ƒï¼Œå®ƒåœ¨åŒ…å«æ¨ç†æ­¥éª¤ã€ä»£ç æ‰§è¡Œã€é”™è¯¯è¿½è¸ªå’Œè‡ªæˆ‘ä¿®æ­£çš„å®Œæ•´â€œåˆ†æè½¨è¿¹â€ä¸Šè¿›è¡Œè®­ç»ƒã€‚é‡‡ç”¨äº†ä¸€ç§åŒé‡å¥–åŠ±æ¡†æ¶ï¼ˆç»“æ„ä¿¡å· + åˆ†å±‚å¥–åŠ±æ¨¡å‹ï¼‰å’Œå†…å­˜ä¼˜åŒ–çš„ GRPO ç®—æ³•ã€‚\n*   **äº®ç‚¹**ï¼šæ¨¡å‹åœ¨å¤„ç†å¤æ‚é—®é¢˜æ—¶å±•ç°å‡ºäº†å‡è®¾-ä¿®æ­£çš„â€œé¡¿æ‚Ÿâ€æ¨¡å¼ï¼Œé¿å…äº†å¸¸è§çš„æ­»å¾ªç¯ã€‚åœ¨ AIME å’Œ LiveCodeBench ä¸Šï¼Œå®ƒä»¥æ›´å°‘çš„ Token æ¶ˆè€—è¶…è¶Šäº†æ›´å¤§çš„æ¨ç†æ¨¡å‹ï¼ˆå¦‚ QwQ-32Bï¼‰ã€‚\n\n**2. Reinforcement Learning with Rubric Anchors**\n**åŸºäºé‡è§„é”šç‚¹çš„å¼ºåŒ–å­¦ä¹ **\n> OpenAI çš„ o-series è¯æ˜äº† RLVR åœ¨æœ‰æ˜ç¡®ç­”æ¡ˆï¼ˆå¦‚æ•°å­¦ã€ä»£ç ï¼‰ä»»åŠ¡ä¸Šçš„æˆåŠŸï¼Œä½†è¿™ç¯‡è®ºæ–‡è¯•å›¾å°†å…¶æ‰©å±•åˆ°**å¼€æ”¾å¼ä»»åŠ¡**ï¼ˆOpen-ended tasksï¼‰ã€‚\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†ä¸€ç§åŸºäºâ€œé‡è§„ï¼ˆRubricï¼‰â€çš„å¥–åŠ±ç³»ç»Ÿï¼Œè®©ä¸»è§‚ä»»åŠ¡ä¹Ÿèƒ½è¿›è¡Œ RL è®­ç»ƒã€‚\n*   **å‘ç°**ï¼šé€šè¿‡æ„å»ºåŒ…å« 10,000+ æ¡é‡è§„çš„æ•°æ®é›†ï¼Œè®­ç»ƒå‡ºçš„ Qwen-30B-A3B æ¨¡å‹åœ¨äººæ–‡å­¦ç§‘ç­‰å¼€æ”¾ä»»åŠ¡ä¸Šæå‡æ˜¾è‘—ï¼ˆ+5.2%ï¼‰ï¼Œç”šè‡³å‡»è´¥äº† 671B å‚æ•°çš„ DeepSeek-V3ã€‚è¿™ä¸ºâ€œè®©æ¨¡å‹å­¦ä¼šæŸç§ç‰¹å®šæ–‡é£æˆ–é£æ ¼â€æä¾›äº†ä¸€æ¡é™¤ SFT ä¹‹å¤–çš„æ–°è·¯å¾„ã€‚\n\n**3. Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models**\n**Mini-Omni-Reasonerï¼šå¤§å‹è¯­éŸ³æ¨¡å‹ä¸­çš„ Token çº§â€œè¾¹è¯´è¾¹æƒ³â€**\n> è¯­éŸ³æ¨¡å‹é€šå¸¸æ˜¯â€œæƒ³å®Œå†è¯´â€ï¼Œå¯¼è‡´å»¶è¿Ÿå¾ˆé«˜ã€‚è¿™ä¸ªå·¥ä½œé€šè¿‡**Thinking-in-Speaking**å®ç°äº†æµå¼æ¨ç†ã€‚\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†ä¸€ç§åœ¨è¯­éŸ³ç”Ÿæˆè¿‡ç¨‹ä¸­äº¤é”™æ’å…¥â€œé™é»˜æ¨ç† Tokenâ€çš„æœºåˆ¶ã€‚\n*   **æ•ˆæœ**ï¼šæ¨¡å‹å¯ä»¥ä¸€è¾¹è¾“å‡ºè¯­éŸ³ï¼Œä¸€è¾¹åœ¨å†…éƒ¨è¿›è¡Œç»“æ„åŒ–æ¨ç†ï¼Œå®ç°äº†é›¶è§£ç å»¶è¿Ÿï¼Œä¸”åœ¨è¯­éŸ³æ•°å­¦é—®ç­”ä»»åŠ¡ä¸Šæå‡äº† 19.1% çš„å‡†ç¡®ç‡ã€‚\n\n**4. G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance**\n**G$^2$RPO-Aï¼šå¸¦æœ‰è‡ªé€‚åº”å¼•å¯¼çš„åˆ†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–**\n> é’ˆå¯¹å°æ¨¡å‹ï¼ˆSLMï¼‰åœ¨æ¨ç†è®­ç»ƒä¸­â€œå¸¦ä¸åŠ¨â€çš„é—®é¢˜ã€‚\n*   **æ–¹æ³•**ï¼šåœ¨ GRPO è®­ç»ƒä¸­æ³¨å…¥ Ground-truth æ¨ç†æ­¥éª¤ä½œä¸ºå¼•å¯¼ï¼Œå¹¶ä¸”è®¾è®¡äº†è‡ªé€‚åº”æœºåˆ¶ï¼Œéšç€æ¨¡å‹å˜å¼ºè‡ªåŠ¨è°ƒæ•´å¼•å¯¼å¼ºåº¦ã€‚è¿™å¯¹äºæƒ³åœ¨å°æ˜¾å­˜ä¸Šå¤ç°æ¨ç†èƒ½åŠ›çš„å®éªŒå®¤å¾ˆæœ‰å‚è€ƒä»·å€¼ã€‚\n\n---\n\n### ğŸ¤– æ™ºèƒ½ä½“ä¸ç³»ç»Ÿåº”ç”¨ (Agents & Systems)\nAgent ä¸å†åªæ˜¯ç©ç¥¨ï¼Œå¼€å§‹è¿›å…¥ç¡¬æ ¸çš„ç³»ç»Ÿåº•å±‚å’Œå¤æ‚çš„ä¸šåŠ¡æµç¨‹ã€‚\n\n**5. OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning**\n**OS-R1ï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½ä½“æ“ä½œç³»ç»Ÿå†…æ ¸è°ƒä¼˜**\n> AI è°ƒå‚ä¾ è¿›å†› Linux å†…æ ¸ã€‚\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå°† Linux å†…æ ¸é…ç½®ç©ºé—´æŠ½è±¡ä¸º RL ç¯å¢ƒï¼Œåˆ©ç”¨ LLM æ™ºèƒ½ä½“è¿›è¡Œå†…æ ¸è°ƒä¼˜ã€‚\n*   **å‘ç°**ï¼šç›¸æ¯”å¯å‘å¼è°ƒä¼˜æ–¹æ³•ï¼ŒOS-R1 èƒ½å¸¦æ¥é«˜è¾¾ 5.6% çš„ç³»ç»Ÿæ€§èƒ½æå‡ã€‚é€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒï¼Œæ¨¡å‹å­¦ä¼šäº†å¦‚ä½•å®‰å…¨ã€æœ‰æ•ˆåœ°ä¿®æ”¹å†…æ ¸å‚æ•°ã€‚\n\n**6. TASER: Table Agents for Schema-guided Extraction and Recommendation**\n**TASERï¼šç”¨äºæ¨¡å¼å¼•å¯¼æå–å’Œæ¨èçš„è¡¨æ ¼æ™ºèƒ½ä½“**\n> è§£å†³äº†é‡‘èé¢†åŸŸæœ€å¤´ç–¼çš„â€œä¹±ä¸ƒå…«ç³Ÿçš„å¤§è¡¨æ ¼â€é—®é¢˜ã€‚\n*   **ç—›ç‚¹**ï¼šç°å®ä¸–ç•Œçš„é‡‘èè¡¨æ ¼ï¼ˆå¦‚æŒä»“æŠ¥å‘Šï¼‰æå…¶ç ´ç¢ã€æ— è¾¹æ¡†ã€è·¨é¡µã€‚\n*   **æ–¹æ³•**ï¼šè®¾è®¡äº†ä¸€ä¸ªæŒç»­å­¦ä¹ çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œé€šè¿‡â€œæ¨èæ™ºèƒ½ä½“â€ä¸æ–­ä¿®æ­£æå–æ¨¡å¼ï¼ˆSchemaï¼‰ã€‚\n*   **æ•ˆæœ**ï¼šæ¯” Table Transformer æ€§èƒ½é«˜ 10.1%ï¼Œå‘å¸ƒäº†ç½•è§çš„çœŸå®é‡‘èè¡¨æ ¼æ•°æ®é›† TASERTabã€‚\n\n**7. HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds**\n**HeroBenchï¼šè™šæ‹Ÿä¸–ç•Œä¸­é•¿ç¨‹è§„åˆ’ä¸ç»“æ„åŒ–æ¨ç†çš„åŸºå‡†æµ‹è¯•**\n> ç°æœ‰çš„ Agent æµ‹è¯•å¤ªçŸ­è§†ï¼ŒHeroBench æŠŠ Agent æ‰”è¿›äº† RPG æ¸¸æˆé‡Œã€‚\n*   **å†…å®¹**ï¼šè¦æ±‚ Agent åœ¨ RPG é£æ ¼çš„ä¸–ç•Œä¸­åˆ¶å®šæˆ˜ç•¥ã€æ”¶é›†èµ„æºã€æ‰“é€ è£…å¤‡å¹¶å‡»è´¥æ•Œäººã€‚\n*   **å‘ç°**ï¼šGPT-5 ç³»åˆ—ç­‰ SOTA æ¨¡å‹åœ¨å•çº¯çš„æ¨ç†é¢˜ä¸Šå¾ˆå¼ºï¼Œä½†åœ¨è¿™ä¸ªéœ€è¦é•¿ç¨‹è§„åˆ’å’Œä¸¥æ ¼ä¾èµ–ç®¡ç†çš„æµ‹è¯•ä¸­ï¼Œè¡¨ç°å·®è·å·¨å¤§ï¼Œæš´éœ²äº†å½“å‰ LLM åœ¨å¤æ‚è¿ç»­å†³ç­–ä¸Šçš„çŸ­æ¿ã€‚\n\n---\n\n### ğŸŒ AI for Science (ç§‘å­¦åŸºç¡€æ¨¡å‹)\nä»Šå¤©æœ‰ä¸¤ä¸ªå…³äºåœ°çƒå’Œå¤ªé˜³çš„é‡ç£…æ¨¡å‹ã€‚\n\n**8. Surya: Foundation Model for Heliophysics**\n**Suryaï¼šæ—¥çƒç‰©ç†å­¦åŸºç¡€æ¨¡å‹**\n> ä»¥å¤ªé˜³ç¥å‘½åï¼ŒNASA æ•°æ®åŠ æŒã€‚\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘å¸ƒäº†ä¸€ä¸ª 3.66 äº¿å‚æ•°çš„å¤ªé˜³ç‰©ç†åŸºç¡€æ¨¡å‹ï¼Œä½¿ç”¨ SDOï¼ˆå¤ªé˜³åŠ¨åŠ›å­¦å¤©æ–‡å°ï¼‰çš„å¤šæ³¢æ®µè§‚æµ‹æ•°æ®è®­ç»ƒã€‚\n*   **æ–¹æ³•**ï¼šåˆ©ç”¨æ—¶ç©º Transformer æ¶æ„ï¼Œé¢„è®­ç»ƒä»»åŠ¡åŒ…æ‹¬é«˜åˆ†è¾¨ç‡å¤ªé˜³å›¾åƒé¢„æµ‹ã€‚\n*   **èƒ½åŠ›**ï¼šZero-shot å°±èƒ½é¢„æµ‹å¤ªé˜³è€€æ–‘å’Œå¤ªé˜³é£ï¼Œè¯æ˜äº†æ¨¡å‹ç¡®å®å­¦åˆ°äº†å¤ªé˜³æ¼”åŒ–çš„ç‰©ç†è§„å¾‹ã€‚ï¼ˆæ³¨ï¼šé…å¥—å‘å¸ƒçš„è¿˜æœ‰ **SuryaBench** æ•°æ®é›†ï¼‰ã€‚\n\n**9. GeoGPT-RAG Technical Report**\n**GeoGPT-RAG æŠ€æœ¯æŠ¥å‘Š**\n> åœ°çƒç§‘å­¦é¢†åŸŸçš„ RAG ç³»ç»Ÿã€‚\n*   **è´¡çŒ®**ï¼šå¼€æºäº† GeoEmbedding å’Œ GeoReranker ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œä¸“é—¨é’ˆå¯¹åœ°å­¦æ–‡çŒ®è¿›è¡Œäº†ä¼˜åŒ–ï¼Œè§£å†³äº†é€šç”¨ RAG åœ¨å¤„ç†ä¸“ä¸šåœ°è´¨æœ¯è¯­æ—¶çš„æ£€ç´¢å¤±æ•ˆé—®é¢˜ã€‚\n\n**10. \"DIVE\" into Hydrogen Storage Materials Discovery with AI Agents**\n**åˆ©ç”¨ AI æ™ºèƒ½ä½“â€œæ½œå…¥â€å‚¨æ°¢ææ–™å‘ç°**\n*   **åº”ç”¨**ï¼šåˆ©ç”¨å¤šæ™ºèƒ½ä½“å·¥ä½œæµä»ç§‘å­¦æ–‡çŒ®çš„å›¾è¡¨ä¸­æå–æ•°æ®ï¼ˆè¿™ç‚¹å¾ˆéš¾ï¼Œæ¯”æå–æ–‡æœ¬éš¾å¾—å¤šï¼‰ï¼Œæ„å»ºäº†å‚¨æ°¢ææ–™æ•°æ®åº“ï¼Œå¹¶åœ¨ä¸¤åˆ†é’Ÿå†…å‘ç°äº†æœªæŠ¥é“è¿‡çš„å‚¨æ°¢æˆåˆ†ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸å¯¹é½ (Safety & Alignment)\næ”»å‡»æ‰‹æ®µåœ¨è¿›åŒ–ï¼Œé˜²å¾¡å˜å¾—è¶Šæ¥è¶Šéš¾ã€‚\n\n**11. Involuntary Jailbreak: On Self-Prompting Attacks**\n**éè‡ªæ„¿è¶Šç‹±ï¼šå…³äºè‡ªæç¤ºæ”»å‡»çš„ç ”ç©¶**\n> è¿™ä¸ªæ”»å‡»æ–¹å¼ç®€å•åˆ°ä»¤äººå‘æŒ‡ï¼Œä¹Ÿå› æ­¤éå¸¸å±é™©ã€‚\n*   **å‘ç°**ï¼šä¸éœ€è¦å¤æ‚çš„å¯¹æŠ—æ ·æœ¬ï¼Œåªéœ€è¦è®© LLM è‡ªå·±â€œç”Ÿæˆå‡ ä¸ªé€šå¸¸ä¼šè¢«æ‹’ç»çš„é—®é¢˜åŠå…¶æ·±åº¦å›ç­”â€ï¼Œæ¨¡å‹å°±ä¼šç»•è¿‡è‡ªèº«çš„æŠ¤æ ï¼Œä¸ä»…ç”Ÿæˆäº†é—®é¢˜ï¼Œè¿˜æŠŠè¿è§„ç­”æ¡ˆä¹Ÿå†™å‡ºæ¥äº†ã€‚Claude Opus 4.1, GPT-4.1 å…¨éƒ¨ä¸­æ‹›ã€‚è¿™æ­ç¤ºäº†å½“å‰æŠ¤æ åœ¨é¢å¯¹â€œè‡ªäº§â€å†…å®¹æ—¶çš„ç›²åŒºã€‚\n\n**12. Systematic Analysis of MCP Security**\n**MCP å®‰å…¨æ€§çš„ç³»ç»Ÿåˆ†æ**\n*   **èƒŒæ™¯**ï¼šModel Context Protocol (MCP) æ˜¯è¿æ¥ AI Agent å’Œå¤–éƒ¨å·¥å…·çš„é€šç”¨æ ‡å‡†ã€‚\n*   **è´¡çŒ®**ï¼šå‘å¸ƒäº† MCPLIB æ”»å‡»åº“ï¼ŒåŒ…å« 31 ç§æ”»å‡»æ–¹æ³•ï¼ˆå¦‚å·¥å…·æ¯’åŒ–ã€é—´æ¥æ³¨å…¥ï¼‰ã€‚æŒ‡å‡ºäº† Agent ç›²ç›®ä¿¡ä»»å·¥å…·æè¿°å’Œæ–‡ä»¶ç³»ç»Ÿè®¿é—®æƒé™çš„å·¨å¤§é£é™©ã€‚\n\n---\n\n### ğŸ¨ è§†è§‰ä¸ç”Ÿæˆ (Vision & Generation)\n\n**13. Next Visual Granularity Generation**\n**ä¸‹ä¸€è§†è§‰ç²’åº¦ç”Ÿæˆ**\n*   **æ ¸å¿ƒå­¦æœ¯æœ¯è¯­**ï¼šVisual Granularity Sequence (è§†è§‰ç²’åº¦åºåˆ—)\n*   **åˆ›æ–°**ï¼šæå‡º NVG æ¡†æ¶ï¼Œä¸æŒ‰åƒç´ ç”Ÿæˆï¼Œè€Œæ˜¯æŒ‰â€œè§†è§‰ç²’åº¦â€ç”Ÿæˆã€‚ä»å…¨å±€å¸ƒå±€åˆ°ç»†èŠ‚çº¹ç†ï¼Œåˆ†å±‚ç”Ÿæˆã€‚FID åˆ†æ•°ä¼˜äº VAR ç³»åˆ—ï¼Œæä¾›äº†ä¸€ç§æ–°çš„å›¾åƒç”ŸæˆèŒƒå¼ã€‚\n\n**14. CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis**\n**CTFlowï¼šå—è§†é¢‘å¯å‘çš„ç”¨äº 3D CT åˆæˆçš„æ½œåœ¨æµåŒ¹é…**\n*   **æ–¹æ³•**ï¼šæŠŠ 3D CT æ‰«æå½“æˆè§†é¢‘æ¥ç”Ÿæˆï¼ˆå±‚ä¸å±‚ä¹‹é—´å…·æœ‰æ—¶é—´/ç©ºé—´è¿ç»­æ€§ï¼‰ã€‚åˆ©ç”¨ Flow Matching å’Œ A-VAEï¼Œèƒ½å¤Ÿæ ¹æ®ä¸´åºŠæŠ¥å‘Šç”Ÿæˆå®Œæ•´çš„ 3D CT å·ã€‚\n\n---\n\n### ğŸ§© å…¶ä»–å€¼å¾—å…³æ³¨çš„è®ºæ–‡\n\n*   **[LLM Analysis] Quantifying Loss Aversion in Cyber Adversaries via LLM Analysis**: åˆ©ç”¨ LLM åˆ†æé»‘å®¢çš„æ“ä½œæ—¥å¿—ï¼Œé‡åŒ–é»‘å®¢çš„â€œæŸå¤±åŒæ¶â€å¿ƒç†åå·®ã€‚è¿™æ˜¯ç½‘ç»œå®‰å…¨å¿ƒç†å­¦çš„ä¸€ä¸ªæ–°é¢–è§’åº¦ã€‚\n*   **[Hardware] AI Agents for Photonic Integrated Circuit Design Automation**: å…‰å­é›†æˆç”µè·¯ï¼ˆPICï¼‰è®¾è®¡çš„è‡ªåŠ¨åŒ–ã€‚å¤šæ™ºèƒ½ä½“æ¡†æ¶ PhIDO å°†è‡ªç„¶è¯­è¨€è¯·æ±‚è½¬åŒ–ä¸ºç‰ˆå›¾æ©è†œæ–‡ä»¶ã€‚\n*   **[Audio] Whispering Context**: å°† LLaMA çš„ä¸Šä¸‹æ–‡çŸ¥è¯†è’¸é¦ç»™ Whisperï¼Œè§£å†³äº†é•¿éŸ³é¢‘è½¬å½•ä¸­ä¸“æœ‰åè¯å’Œå¥æ³•æ··ä¹±çš„é—®é¢˜ã€‚\n*   **[Reasoning] Explicit v.s. Implicit Memory**: æ¢ç´¢äº†æ˜¾å¼ vs éšå¼è®°å¿†åœ¨å¤šè·³å¤æ‚æ¨ç†ä¸­çš„è¡¨ç°ï¼Œæå‡ºäº† HybridMem æ··åˆæ–¹æ³•ã€‚\n\n---\n**ç»“è¯­**ï¼šä»Šå¤©çš„è®ºæ–‡è´¨é‡å¾ˆé«˜ï¼Œç‰¹åˆ«æ˜¯ **Datarus-R1** å’Œ **OS-R1** è®©æˆ‘ä»¬çœ‹åˆ°äº† Agent åœ¨ç‰¹å®šå‚ç›´é¢†åŸŸçš„æ·±åº¦è½åœ°æ½œåŠ›ï¼Œè€Œ **Involuntary Jailbreak** åˆ™ç»™æ‰€æœ‰å¤§æ¨¡å‹å¼€å‘è€…æ•²å“äº†è­¦é’Ÿã€‚å¸Œæœ›è¿™ä»½å¿«æŠ¥å¯¹ä½ çš„ç ”ç©¶æœ‰æ‰€å¯å‘ï¼",
  "papers": [
    {
      "arxiv_id": "2508.13406v1",
      "title": "Semi-Supervised Anomaly Detection Pipeline for SOZ Localization Using Ictal-Related Chirp",
      "title_zh": "åŸºäºå‘ä½œç›¸å…³ Chirp çš„ SOZ å®šä½åŠç›‘ç£å¼‚å¸¸æ£€æµ‹æµç¨‹",
      "authors": [
        "Nooshin Bahador",
        "Milad Lankarany"
      ],
      "abstract": "This study presents a quantitative framework for evaluating the spatial concordance between clinically defined seizure onset zones (SOZs) and statistically anomalous channels identified through time-frequency analysis of chirp events. The proposed pipeline employs a two-step methodology: (1) Unsupervised Outlier Detection, where Local Outlier Factor (LOF) analysis with adaptive neighborhood selection identifies anomalous channels based on spectro-temporal features of chirp (Onset frequency, offset frequency, and temporal duration); and (2) Spatial Correlation Analysis, which computes both exact co-occurrence metrics and weighted index similarity, incorporating hemispheric congruence and electrode proximity. Key findings demonstrate that the LOF-based approach (N neighbors=20, contamination=0.2) effectively detects outliers, with index matching (weighted by channel proximity) outperforming exact matching in SOZ localization. Performance metrics (precision, recall, F1) were highest for seizure-free patients (Index Precision mean: 0.903) and those with successful surgical outcomes (Index Precision mean: 0.865), whereas failure cases exhibited lower concordance (Index Precision mean: 0.460). The key takeaway is that chirp-based outlier detection, combined with weighted spatial metrics, provides a complementary method for SOZ localization, particularly in patients with successful surgical outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŠç›‘ç£å¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨ä¸å‘ä½œç›¸å…³çš„ Chirp ä¿¡å·è¿›è¡Œç™«ç—«èµ·å§‹åŒºï¼ˆSeizure Onset Zones, SOZsï¼‰çš„å®šä½ã€‚è¯¥æµæ°´çº¿é¦–å…ˆé‡‡ç”¨æ— ç›‘ç£ç¦»ç¾¤å€¼æ£€æµ‹ï¼Œé€šè¿‡å¸¦æœ‰è‡ªé€‚åº”é‚»åŸŸé€‰æ‹©çš„å±€éƒ¨ç¦»ç¾¤å› å­ï¼ˆLocal Outlier Factor, LOFï¼‰åˆ†æï¼ŒåŸºäº Chirp ä¿¡å·çš„é¢‘è°±-æ—¶é—´ç‰¹å¾ï¼ˆå¦‚ Onset frequencyã€Offset frequency å’ŒæŒç»­æ—¶é—´ï¼‰è¯†åˆ«å¼‚å¸¸é€šé“ã€‚éšåï¼Œé€šè¿‡ç©ºé—´ç›¸å…³æ€§åˆ†æè®¡ç®—ç²¾ç¡®å…±ç°æŒ‡æ ‡å’ŒåŠ æƒç´¢å¼•ç›¸ä¼¼åº¦ï¼Œå¹¶å°†åŠçƒä¸€è‡´æ€§ä¸ç”µæé‚»è¿‘åº¦çº³å…¥è€ƒé‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäº LOF çš„æ–¹æ³•èƒ½æœ‰æ•ˆæ£€æµ‹ç¦»ç¾¤å€¼ï¼Œä¸”åŠ æƒç´¢å¼•åŒ¹é…åœ¨ SOZ å®šä½è¡¨ç°ä¸Šä¼˜äºç²¾ç¡®åŒ¹é…ã€‚æ€§èƒ½æŒ‡æ ‡åœ¨æ— å‘ä½œæ‚£è€…å’Œæ‰‹æœ¯æˆåŠŸç—…ä¾‹ä¸­è¾¾åˆ°æœ€é«˜æ°´å¹³ï¼Œè€Œæ‰‹æœ¯å¤±è´¥ç—…ä¾‹çš„åè°ƒæ€§æ˜¾è‘—è¾ƒä½ã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäº Chirp çš„ç¦»ç¾¤å€¼æ£€æµ‹ç»“åˆåŠ æƒç©ºé—´æŒ‡æ ‡ï¼Œä¸º SOZ å®šä½æä¾›äº†ä¸€ç§é‡è¦çš„è¡¥å……æ‰‹æ®µï¼Œå°¤å…¶åœ¨é¢„æµ‹æ‰‹æœ¯é¢„åæ–¹é¢å…·æœ‰ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.13406v1",
      "published_date": "2025-08-18 23:54:59 UTC",
      "updated_date": "2025-08-18 23:54:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:28:21.882098+00:00"
    },
    {
      "arxiv_id": "2508.13404v3",
      "title": "TASER: Table Agents for Schema-guided Extraction and Recommendation",
      "title_zh": "TASERï¼šåŸºäºæ¨¡å¼å¼•å¯¼æŠ½å–ä¸æ¨èçš„è¡¨æ ¼æ™ºèƒ½ä½“",
      "authors": [
        "Nicole Cho",
        "Kirsty Fielding",
        "William Watson",
        "Sumitra Ganesh",
        "Manuela Veloso"
      ],
      "abstract": "Real-world financial documents report essential information about an entity's financial holdings that can span millions of different financial instrument types. Yet, these details are often buried in messy, multi-page, fragmented tables - for example, 99.4% of the tables in our dataset have no bounding boxes with the maximum number of rows amounting to 426 per table across 44 pages. To tackle these unique challenges from real-world tables, we present a continuously learning, agentic table extraction system, TASER (Table Agents for Schema-guided Extraction and Recommendation) that extracts highly unstructured, multi-page, heterogeneous tables into normalized, schema-conforming outputs. Our table agents execute on table detection, classification, extraction, and recommendations by leveraging an initial schema. Then, our Recommender Agent reviews the outputs, recommends schema revisions, and decides on the final recommendations, enabling TASER to outperform existing table detection models such as Table Transformer by 10.1%. Within this continuous learning process, we highlight that larger batch sizes result in a 104.3% increase in schema recommendations that are actionable and utilized, resulting in a 9.8% increase in extracted holdings - highlighting the importance of a continuous learning process. To train TASER, we have manually labeled 22,584 pages (28,150,449 tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of the first real financial table datasets. We release our dataset TASERTab to enable the research community to access real-world financial tables and outputs. Our results highlight the promise of agentic, schema-guided extraction systems for robust understanding of real-world financial tables.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡‘èæ–‡æ¡£ä¸­æ™®éå­˜åœ¨çš„æ‚ä¹±ã€è·¨é¡µä¸”ç¼ºä¹è¾¹æ¡†çš„å¤æ‚è¡¨æ ¼æå–éš¾é¢˜ï¼Œæå‡ºäº†TASERï¼Œä¸€ä¸ªå…·æœ‰æŒç»­å­¦ä¹ èƒ½åŠ›çš„æ™ºèƒ½ä½“è¡¨æ ¼æå–ç³»ç»Ÿã€‚TASERé€šè¿‡Schema-guidedæœºåˆ¶ï¼Œåˆ©ç”¨å¤šä¸ªæ™ºèƒ½ä½“åˆ†å·¥æ‰§è¡Œè¡¨æ ¼æ£€æµ‹ã€åˆ†ç±»ã€æå–åŠæ¨èä»»åŠ¡ï¼Œå°†é«˜åº¦éç»“æ„åŒ–ä¸”å¼‚æ„çš„è¡¨æ ¼è½¬åŒ–ä¸ºæ ‡å‡†åŒ–çš„Schema-conformingè¾“å‡ºã€‚ç³»ç»Ÿæ ¸å¿ƒå¼•å…¥äº†Recommender Agentæ¥å®¡æŸ¥è¾“å‡ºå¹¶å»ºè®®Schemaä¿®è®¢ï¼Œé€šè¿‡æŒç»­å­¦ä¹ è¿‡ç¨‹å®ç°äº†æå–ç²¾åº¦çš„æ˜¾è‘—æå‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTASERåœ¨è¡¨æ ¼æ£€æµ‹ä»»åŠ¡ä¸Šæ¯”Table Transformeræ¨¡å‹å‡†ç¡®ç‡é«˜å‡º10.1%ï¼Œä¸”åœ¨å¤§æ‰¹æ¬¡å¤„ç†ä¸‹æå–èµ„äº§çš„æˆåŠŸç‡æå‡äº†9.8%ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿå‘å¸ƒäº†åŒ…å«22,584é¡µæ‰‹åŠ¨æ ‡æ³¨æ•°æ®çš„TASERTabæ•°æ®é›†ï¼Œè¿™æ˜¯é¦–æ‰¹é’ˆå¯¹çœŸå®é‡‘èè¡¨æ ¼çš„å¤§è§„æ¨¡æ•°æ®é›†ä¹‹ä¸€ã€‚è¯¥ç ”ç©¶æœ‰åŠ›è¯æ˜äº†åŸºäºæ™ºèƒ½ä½“çš„å¼•å¯¼å¼æå–ç³»ç»Ÿåœ¨ç¨³å¥ç†è§£ç°å®ä¸–ç•Œå¤æ‚é‡‘èæ•°æ®æ–¹é¢çš„å·¨å¤§åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13404v3",
      "published_date": "2025-08-18 23:48:22 UTC",
      "updated_date": "2025-10-15 00:51:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:28:27.199623+00:00"
    },
    {
      "arxiv_id": "2508.14125v1",
      "title": "A Cost-Effective Framework for Predicting Parking Availability Using Geospatial Data and Machine Learning",
      "title_zh": "åŸºäºåœ°ç†ç©ºé—´æ•°æ®ä¸æœºå™¨å­¦ä¹ çš„ç»æµé«˜æ•ˆåœè½¦å¯ç”¨æ€§é¢„æµ‹æ¡†æ¶",
      "authors": [
        "Madyan Bagosher",
        "Tala Mustafa",
        "Mohammad Alsmirat",
        "Amal Al-Ali",
        "Isam Mashhour Al Jawarneh"
      ],
      "abstract": "As urban populations continue to grow, cities face numerous challenges in managing parking and determining occupancy. This issue is particularly pronounced in university campuses, where students need to find vacant parking spots quickly and conveniently during class timings. The limited availability of parking spaces on campuses underscores the necessity of implementing efficient systems to allocate vacant parking spots effectively. We propose a smart framework that integrates multiple data sources, including street maps, mobility, and meteorological data, through a spatial join operation to capture parking behavior and vehicle movement patterns over the span of 3 consecutive days with an hourly duration between 7AM till 3PM. The system will not require any sensing tools to be installed in the street or in the parking area to provide its services since all the data needed will be collected using location services. The framework will use the expected parking entrance and time to specify a suitable parking area. Several forecasting models, namely, Linear Regression, Support Vector Regression (SVR), Random Forest Regression (RFR), and Long Short-Term Memory (LSTM), are evaluated. Hyperparameter tuning was employed using grid search, and model performance is assessed using Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Coefficient of Determination (R2). Random Forest Regression achieved the lowest RMSE of 0.142 and highest R2 of 0.582. However, given the time-series nature of the task, an LSTM model may perform better with additional data and longer timesteps.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸå¸‚åŒ–è¿›ç¨‹ä¸­æ—¥ç›Šä¸¥å³»çš„åœè½¦ç®¡ç†æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å¤§å­¦æ ¡å›­å†…é«˜å³°æ—¶æ®µçš„è½¦ä½å¯»æ‰¾é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…·æœ‰é«˜æˆæœ¬æ•ˆç›Šçš„æ™ºèƒ½é¢„æµ‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç©ºé—´è¿æ¥(Spatial Join)æ“ä½œæ•´åˆäº†è¡—é“åœ°å›¾ã€ç§»åŠ¨æ•°æ®å’Œæ°”è±¡æ•°æ®ç­‰å¤šæºåœ°ç†ç©ºé—´ä¿¡æ¯ï¼Œç”¨ä»¥æ•æ‰è¿ç»­ä¸‰å¤©å†…ï¼ˆæ¯æ—¥ä¸Šåˆ7ç‚¹è‡³ä¸‹åˆ3ç‚¹ï¼‰çš„åœè½¦è¡Œä¸ºå’Œè½¦è¾†ç§»åŠ¨æ¨¡å¼ã€‚ä¸ä¼ ç»Ÿæ–¹æ¡ˆä¸åŒï¼Œè¯¥ç³»ç»Ÿå®Œå…¨ä¾èµ–ä½ç½®æœåŠ¡(Location Services)é‡‡é›†æ•°æ®ï¼Œæ— éœ€åœ¨è¡—é“æˆ–åœè½¦åœºå®‰è£…ä»»ä½•ä¼ æ„Ÿè®¾å¤‡ã€‚ç ”ç©¶è¯„ä¼°äº†çº¿æ€§å›å½’(Linear Regression)ã€æ”¯æŒå‘é‡å›å½’(SVR)ã€éšæœºæ£®æ—å›å½’(RFR)å’Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)ç­‰æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨ç½‘æ ¼æœç´¢(Grid Search)è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œéšæœºæ£®æ—å›å½’æ¨¡å‹åœ¨é¢„æµ‹åœè½¦å¯ç”¨æ€§æ–¹é¢è¡¨ç°æœ€ä¼˜ï¼Œå–å¾—äº†0.142çš„å‡æ–¹æ ¹è¯¯å·®(RMSE)å’Œ0.582çš„å†³å®šç³»æ•°(R2)ã€‚å°½ç®¡ç›®å‰RFRæ•ˆæœæœ€ä½³ï¼Œä½†ç ”ç©¶ä¹ŸæŒ‡å‡ºï¼Œè€ƒè™‘åˆ°ä»»åŠ¡çš„æ—¶é—´åºåˆ—ç‰¹æ€§ï¼ŒLSTMæ¨¡å‹åœ¨æ‹¥æœ‰æ›´å¤šæ•°æ®æ”¯æŒæ—¶å¯èƒ½å±•ç°å‡ºæ›´ä¼˜çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14125v1",
      "published_date": "2025-08-18 23:24:19 UTC",
      "updated_date": "2025-08-18 23:24:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:28:34.285548+00:00"
    },
    {
      "arxiv_id": "2508.13387v1",
      "title": "SPANER: Shared Prompt Aligner for Multimodal Semantic Representation",
      "title_zh": "SPANERï¼šç”¨äºå¤šæ¨¡æ€è¯­ä¹‰è¡¨ç¤ºçš„å…±äº«æç¤ºå¯¹é½å™¨",
      "authors": [
        "Thye Shan Ng",
        "Caren Soyeon Han",
        "Eun-Jung Holden"
      ],
      "abstract": "Recent advances in multimodal Parameter-Efficient Fine-Tuning (PEFT) have significantly improved performance on downstream tasks such as few-shot retrieval. However, most existing approaches focus on task-specific gains while neglecting the structure of the multimodal embedding space. As a result, modality-specific representations often remain isolated, limiting cross-modal generalisation. In this work, we introduce Shared Prompt AligNER (SPANER), a modality-agnostic PEFT framework designed to embed inputs from diverse modalities into a unified semantic space. At its core, SPANER employs a shared prompt mechanism that acts as a conceptual anchor, enabling semantically related instances to converge spatially regardless of modality. This shared prompt design is inherently extensible, supporting the seamless integration of additional modalities, such as audio, without altering the core architecture. Through comprehensive experiments across vision-language and audio-visual benchmarks, SPANER demonstrates competitive few-shot retrieval performance while preserving high semantic coherence in the learned embedding space. Our results highlight the importance of aligning embedding structures, rather than merely tuning adapter weights, for scalable multimodal learning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)ä¸­å„æ¨¡æ€è¡¨å¾å­¤ç«‹ä¸”è·¨æ¨¡æ€æ³›åŒ–å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†SPANERï¼ˆShared Prompt AligNERï¼‰æ¡†æ¶ã€‚SPANERæ˜¯ä¸€ç§æ¨¡æ€æ— å…³çš„å¾®è°ƒæ–¹æ¡ˆï¼Œæ—¨åœ¨å°†ä¸åŒæ¨¡æ€çš„è¾“å…¥åµŒå…¥åˆ°ä¸€ä¸ªç»Ÿä¸€çš„è¯­ä¹‰ç©ºé—´ä¸­ã€‚å…¶æ ¸å¿ƒé‡‡ç”¨äº†å…±äº«æç¤º(shared prompt)æœºåˆ¶ä½œä¸ºæ¦‚å¿µé”šç‚¹ï¼Œä½¿è¯­ä¹‰ç›¸å…³çš„å®ä¾‹æ— è®ºå±äºä½•ç§æ¨¡æ€éƒ½èƒ½åœ¨ç©ºé—´ä¸Šè¶‹äºä¸€è‡´ã€‚è¯¥è®¾è®¡å…·æœ‰é«˜åº¦å¯æ‰©å±•æ€§ï¼Œæ”¯æŒåœ¨ä¸æ”¹å˜æ ¸å¿ƒæ¶æ„çš„æƒ…å†µä¸‹æ— ç¼é›†æˆéŸ³é¢‘ç­‰æ–°æ¨¡æ€ã€‚åœ¨è§†è§‰-è¯­è¨€å’ŒéŸ³é¢‘-è§†è§‰åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSPANERåœ¨ä¿æŒåµŒå…¥ç©ºé—´é«˜è¯­ä¹‰ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå®ç°äº†æå…·ç«äº‰åŠ›çš„å°‘æ ·æœ¬æ£€ç´¢(few-shot retrieval)æ€§èƒ½ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œç›¸æ¯”å•çº¯è°ƒæ•´é€‚é…å™¨æƒé‡ï¼Œå¯¹é½åµŒå…¥ç©ºé—´ç»“æ„å¯¹äºå¯æ‰©å±•çš„å¤šæ¨¡æ€å­¦ä¹ æ›´å…·å…³é”®æ„ä¹‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13387v1",
      "published_date": "2025-08-18 22:20:42 UTC",
      "updated_date": "2025-08-18 22:20:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:28:36.985102+00:00"
    },
    {
      "arxiv_id": "2509.09689v1",
      "title": "Personas within Parameters: Fine-Tuning Small Language Models with Low-Rank Adapters to Mimic User Behaviors",
      "title_zh": "å‚æ•°ä¸­çš„äººæ ¼ï¼šåˆ©ç”¨ä½ç§©é€‚é…å™¨å¾®è°ƒå°è¯­è¨€æ¨¡å‹ä»¥æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸º",
      "authors": [
        "Himanshu Thakur",
        "Eshani Agrawal",
        "Smruthi Mukund"
      ],
      "abstract": "A long-standing challenge in developing accurate recommendation models is simulating user behavior, mainly due to the complex and stochastic nature of user interactions. Towards this, one promising line of work has been the use of Large Language Models (LLMs) for simulating user behavior. However, aligning these general-purpose large pre-trained models with user preferences necessitates: (i) effectively and continously parsing large-scale tabular user-item interaction data, (ii) overcoming pre-training-induced inductive biases to accurately learn user specific knowledge, and (iii) achieving the former two at scale for millions of users. While most previous works have focused on complex methods to prompt an LLM or fine-tune it on tabular interaction datasets, our approach shifts the focus to extracting robust textual user representations using a frozen LLM and simulating cost-effective, resource-efficient user agents powered by fine-tuned Small Language Models (SLMs). Further, we showcase a method for training multiple low-rank adapters for groups of users or \\textit{persona}, striking an optimal balance between scalability and performance of user behavior agents. Our experiments provide compelling empirical evidence of the efficacy of our methods, demonstrating that user agents developed using our approach have the potential to bridge the gap between offline metrics and real-world performance of recommender systems.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶é’ˆå¯¹æ¨èç³»ç»Ÿåœ¨æ¨¡æ‹Ÿå¤æ‚ä¸”å…·æœ‰éšæœºæ€§çš„ç”¨æˆ·è¡Œä¸ºæ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº Small Language Models (SLMs) çš„ç”¨æˆ·è¡Œä¸ºæ¨¡æ‹Ÿæ¡†æ¶ã€‚ç ”ç©¶è€…ä¸å†ç›´æ¥å¾®è°ƒåºå¤§çš„ Large Language Models (LLMs)ï¼Œè€Œæ˜¯åˆ©ç”¨å†»ç»“çš„ LLM æå–ç¨³å¥çš„æ–‡æœ¬ç”¨æˆ·è¡¨ç¤ºï¼Œå¹¶ç»“åˆä½ç§©é€‚é…å™¨ (Low-Rank Adapters) æŠ€æœ¯ä¸ºä¸åŒçš„ç”¨æˆ·ç¾¤ä½“æˆ–ç”¨æˆ·ç”»åƒ (Persona) è®­ç»ƒä¸“ç”¨é€‚é…å™¨ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°è§£å†³äº†é€šç”¨å¤§æ¨¡å‹åœ¨è§£æå¤§è§„æ¨¡è¡¨æ ¼äº¤äº’æ•°æ®æ—¶çš„å±€é™æ€§ï¼Œå¹¶å…‹æœäº†é¢„è®­ç»ƒè¯±å¯¼çš„å½’çº³åå·®ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒèµ„æºé«˜æ•ˆåˆ©ç”¨çš„åŒæ—¶ï¼Œèƒ½å¤Ÿåœ¨å¤§è§„æ¨¡ç”¨æˆ·åœºæ™¯ä¸‹å®ç°é«˜æ€§èƒ½çš„è¡Œä¸ºæ¨¡æ‹Ÿã€‚è¯¥ç ”ç©¶ä¸ºç¼©å°æ¨èç³»ç»Ÿç¦»çº¿è¯„ä¼°æŒ‡æ ‡ä¸ç°å®ä¸–ç•Œè¡¨ç°ä¹‹é—´çš„å·®è·æä¾›äº†å¼ºæœ‰åŠ›çš„å®è¯æ”¯æŒï¼Œä¸ºæ„å»ºå¯æ‰©å±•ä¸”é«˜æ€§ä»·æ¯”çš„ç”¨æˆ·æ™ºèƒ½ä½“å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09689v1",
      "published_date": "2025-08-18 22:14:57 UTC",
      "updated_date": "2025-08-18 22:14:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:28:40.987063+00:00"
    },
    {
      "arxiv_id": "2508.15832v1",
      "title": "A Functionality-Grounded Benchmark for Evaluating Web Agents in E-commerce Domains",
      "title_zh": "é¢å‘ç”µå­å•†åŠ¡é¢†åŸŸ Web æ™ºèƒ½ä½“è¯„ä¼°çš„åŠŸèƒ½æ€§åŸºå‡†",
      "authors": [
        "Xianren Zhang",
        "Shreyas Prasad",
        "Di Wang",
        "Qiuhai Zeng",
        "Suhang Wang",
        "Wenbo Yan",
        "Mat Hans"
      ],
      "abstract": "Web agents have shown great promise in performing many tasks on ecommerce website. To assess their capabilities, several benchmarks have been introduced. However, current benchmarks in the e-commerce domain face two major problems. First, they primarily focus on product search tasks (e.g., Find an Apple Watch), failing to capture the broader range of functionalities offered by real-world e-commerce platforms such as Amazon, including account management and gift card operations. Second, existing benchmarks typically evaluate whether the agent completes the user query, but ignore the potential risks involved. In practice, web agents can make unintended changes that negatively impact the user account or status. For instance, an agent might purchase the wrong item, delete a saved address, or incorrectly configure an auto-reload setting. To address these gaps, we propose a new benchmark called Amazon-Bench. To generate user queries that cover a broad range of tasks, we propose a data generation pipeline that leverages webpage content and interactive elements (e.g., buttons, check boxes) to create diverse, functionality-grounded user queries covering tasks such as address management, wish list management, and brand store following. To improve the agent evaluation, we propose an automated evaluation framework that assesses both the performance and the safety of web agents. We systematically evaluate different agents, finding that current agents struggle with complex queries and pose safety risks. These results highlight the need for developing more robust and reliable web agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰ç”µå­å•†åŠ¡é¢†åŸŸ Web agents åŸºå‡†æµ‹è¯•ä»…å…³æ³¨äº§å“æœç´¢ä»»åŠ¡ä¸”å¿½è§†æ“ä½œé£é™©çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸º Amazon-Bench çš„å…¨æ–°åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€å¥— data generation pipelineï¼Œåˆ©ç”¨ç½‘é¡µå†…å®¹å’Œäº¤äº’å…ƒç´ ç”Ÿæˆæ¶µç›–åœ°å€ç®¡ç†ã€æ„¿æœ›æ¸…å•ç®¡ç†ç­‰å¤šæ ·åŒ–ã€åŸºäºåŠŸèƒ½æ€§ (functionality-grounded) çš„ç”¨æˆ·æŸ¥è¯¢ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨åŒæ—¶è¯„ä¼° Web agents çš„æ€§èƒ½ (performance) ä¸å®‰å…¨æ€§ (safety)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„æ™ºèƒ½ä½“åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢æ—¶ä»é¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œå¹¶å­˜åœ¨å¯¼è‡´ç”¨æˆ·è´¦æˆ·å—æŸçš„å®‰å…¨æ€§é£é™©ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†å¼€å‘æ›´ç¨³å¥ã€æ›´å¯é çš„ç”µå­å•†åŠ¡ Web agents çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages for main body and 8 pages of appendix",
      "pdf_url": "https://arxiv.org/pdf/2508.15832v1",
      "published_date": "2025-08-18 21:58:43 UTC",
      "updated_date": "2025-08-18 21:58:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:28:49.192622+00:00"
    },
    {
      "arxiv_id": "2508.13382v1",
      "title": "Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis",
      "title_zh": "Datarus-R1ï¼šé¢å‘è‡ªåŠ¨åŒ–æ•°æ®åˆ†æçš„è‡ªé€‚åº”å¤šæ­¥æ¨ç†å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Ayoub Ben Chaliah",
        "Hela Dellagi"
      ],
      "abstract": "We present Datarus-R1-14B, a 14 B-parameter open-weights language model fine-tuned from Qwen 2.5-14B-Instruct to act as a virtual data analyst and graduate-level problem solver. Datarus is trained not on isolated question-answer pairs but on full analytical trajectories including reasoning steps, code execution, error traces, self-corrections, and final conclusions, all captured in a ReAct-style notebook format spanning finance, medicine, numerical analysis, and other quantitative domains. Our training pipeline combines (i) a trajectory-centric synthetic data generator that yielded 144 000 tagged notebook episodes, (ii) a dual-reward framework blending a lightweight tag-based structural signal with a Hierarchical Reward Model (HRM) that scores both single-step soundness and end-to-end coherence, and (iii) a memory-optimized implementation of Group Relative Policy Optimization (GRPO) featuring KV-cache reuse, sequential generation, and reference-model sharding. A cosine curriculum smoothly shifts emphasis from structural fidelity to semantic depth, reducing the format collapse and verbosity that often plague RL-aligned LLMs. A central design choice in Datarus is it dual reasoning interface. In agentic mode the model produces ReAct-tagged steps that invoke Python tools to execute real code; in reflection mode it outputs compact Chain-of-Thought (CoT) traces delimited by <think> and <answer> tags. On demanding postgraduate-level problems, Datarus exhibits an \"AHA-moment\" pattern: it sketches hypotheses, revises them once or twice, and converges avoiding the circular, token-inflating loops common to contemporary systems. Across standard public benchmarks Datarus surpasses similar size models and even reaches the level of larger reasoning models such as QwQ-32B achieving up to 30% higher accuracy on AIME 2024/2025 and LiveCodeBench while emitting 18-49% fewer tokens per solution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Datarus-R1-14Bï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºQwen 2.5-14B-Instructå¾®è°ƒçš„140äº¿å‚æ•°è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨ä½œä¸ºè™šæ‹Ÿæ•°æ®åˆ†æå¸ˆè§£å†³ç ”ç©¶ç”Ÿæ°´å¹³çš„å®šé‡é—®é¢˜ã€‚æ¨¡å‹å¹¶éåŸºäºå­¤ç«‹çš„é—®ç­”å¯¹è®­ç»ƒï¼Œè€Œæ˜¯åˆ©ç”¨åŒ…å«æ¨ç†æ­¥éª¤ã€ä»£ç æ‰§è¡Œå’Œè‡ªæˆ‘ä¿®æ­£çš„å®Œæ•´åˆ†æè½¨è¿¹ï¼ˆAnalytical Trajectoriesï¼‰ï¼Œå¹¶é€šè¿‡åŒé‡å¥–åŠ±æ¡†æ¶ï¼ˆDual-reward Frameworkï¼‰å’Œåˆ†å±‚å¥–åŠ±æ¨¡å‹ï¼ˆHierarchical Reward Modelï¼‰è¿›è¡Œä¼˜åŒ–ã€‚Datarus-R1é‡‡ç”¨äº†å†…å­˜ä¼˜åŒ–çš„ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ç®—æ³•ï¼Œå¹¶ç»“åˆä½™å¼¦è¯¾ç¨‹ï¼ˆCosine Curriculumï¼‰å­¦ä¹ ï¼Œæœ‰æ•ˆè§£å†³äº†å¼ºåŒ–å­¦ä¹ ä¸­çš„å†—ä½™å’Œæ ¼å¼å´©æºƒé—®é¢˜ã€‚è¯¥æ¨¡å‹æ”¯æŒè°ƒç”¨Pythonå·¥å…·çš„ä»£ç†æ¨¡å¼ï¼ˆAgentic Modeï¼‰ä¸ç®€æ´çš„é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰åå°„æ¨¡å¼ï¼Œèƒ½å¤Ÿå±•ç°å‡ºç±»ä¼¼äºäººç±»çš„â€œé¡¿æ‚Ÿâ€æ¨¡å¼ä»¥é¿å…å¾ªç¯æ¨ç†ã€‚å®éªŒè¡¨æ˜ï¼ŒDatarus-R1åœ¨AIMEå’ŒLiveCodeBenchç­‰åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶Šäº†åŒå°ºå¯¸æ¨¡å‹ï¼Œç”šè‡³è¾¾åˆ°QwQ-32Bçš„æ°´å¹³ï¼Œåœ¨æå‡å‡†ç¡®ç‡çš„åŒæ—¶å°†Tokenæ¶ˆè€—é™ä½äº†18-49%ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13382v1",
      "published_date": "2025-08-18 21:58:18 UTC",
      "updated_date": "2025-08-18 21:58:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:28:52.997768+00:00"
    },
    {
      "arxiv_id": "2508.13376v1",
      "title": "Whispering Context: Distilling Syntax and Semantics for Long Speech Transcripts",
      "title_zh": "Whispering Contextï¼šé¢å‘é•¿è¯­éŸ³è½¬å½•çš„è¯­æ³•ä¸è¯­ä¹‰è’¸é¦",
      "authors": [
        "Duygu Altinok"
      ],
      "abstract": "ASR systems often struggle with maintaining syntactic and semantic accuracy in long audio transcripts, impacting tasks like Named Entity Recognition (NER), capitalization, and punctuation. We propose a novel approach that enhances ASR by distilling contextual knowledge from LLaMA models into Whisper. Our method uses two strategies: (1) token level distillation with optimal transport to align dimensions and sequence lengths, and (2) representation loss minimization between sentence embeddings of Whisper and LLaMA, blending syntax and semantics. Evaluations on the Spoken Wikipedia dataset, a benchmark with long audios and rich entities demonstrate significant improvements in Word Error Rate (WER), NER, capitalization, and punctuation success. By introducing novel NER metrics and exploring semantics aware ASR, our work highlights the value of integrating linguistic context into transcription, setting a foundation for robust, context-aware ASR in longform speech.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)ç³»ç»Ÿåœ¨é•¿éŸ³é¢‘è½¬å½•ä¸­éš¾ä»¥ç»´æŒå¥æ³•å’Œè¯­ä¹‰å‡†ç¡®æ€§ï¼Œè¿›è€Œå½±å“å‘½åå®ä½“è¯†åˆ«(NER)ã€å¤§å°å†™å’Œæ ‡ç‚¹é¢„æµ‹ç­‰ä»»åŠ¡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å°†LLaMAæ¨¡å‹çš„ä¸Šä¸‹æ–‡çŸ¥è¯†è’¸é¦è‡³Whisperæ¨¡å‹çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŒ…å«ä¸¤é¡¹æ ¸å¿ƒç­–ç•¥ï¼šä¸€æ˜¯åˆ©ç”¨æœ€ä¼˜ä¼ è¾“(optimal transport)è¿›è¡Œæ ‡è®°çº§è’¸é¦ä»¥å¯¹é½ç»´åº¦å’Œåºåˆ—é•¿åº¦ï¼ŒäºŒæ˜¯é€šè¿‡æœ€å°åŒ–å¥å­åµŒå…¥ä¹‹é—´çš„è¡¨å¾æŸå¤±æ¥èåˆå¥æ³•ä¸è¯­ä¹‰ä¿¡æ¯ã€‚åœ¨Spoken Wikipediaæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯é”™è¯¯ç‡(WER)ã€NERã€å¤§å°å†™åŠæ ‡ç‚¹æˆåŠŸç‡æ–¹é¢å‡æœ‰æ˜¾è‘—æ”¹è¿›ã€‚é€šè¿‡å¼•å…¥æ–°å‹NERè¯„ä¼°æŒ‡æ ‡å¹¶æ¢ç´¢è¯­ä¹‰æ„ŸçŸ¥ASRï¼Œè¯¥å·¥ä½œè¯æ˜äº†æ•´åˆè¯­è¨€ä¸Šä¸‹æ–‡å¯¹è½¬å½•çš„é‡è¦æ€§ï¼Œä¸ºæ„å»ºç¨³å¥ä¸”å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„é•¿è¯­éŸ³è½¬å½•æŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IEEE ASRU 2025. This is the preprint, all rights reserved for ASRU2025",
      "pdf_url": "https://arxiv.org/pdf/2508.13376v1",
      "published_date": "2025-08-18 21:37:09 UTC",
      "updated_date": "2025-08-18 21:37:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:28:56.491575+00:00"
    },
    {
      "arxiv_id": "2508.13371v1",
      "title": "LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems",
      "title_zh": "LOOPï¼šä¸€ç§ç”¨äºæå‡è‡ªä¸»ç³»ç»Ÿè§„åˆ’èƒ½åŠ›çš„å³æ’å³ç”¨ç¥ç»ç¬¦å·æ¡†æ¶",
      "authors": [
        "Ronit Virwani",
        "Ruchika Suryawanshi"
      ],
      "abstract": "Planning is one of the most critical tasks in autonomous systems, where even a small error can lead to major failures or million-dollar losses. Current state-of-the-art neural planning approaches struggle with complex domains, producing plans with missing preconditions, inconsistent goals, and hallucinations. While classical planners provide logical guarantees, they lack the flexibility and natural language understanding capabilities needed for modern autonomous systems. Existing neuro-symbolic approaches use one-shot translation from natural language to formal plans, missing the opportunity for neural and symbolic components to work and refine solutions together. To address this gap, we develop LOOP -- a novel neuro-symbolic planning framework that treats planning as an iterative conversation between neural and symbolic components rather than simple translation. LOOP integrates 13 coordinated neural features including graph neural networks for spatial relationships, multi-agent validation for consensus-based correctness, hierarchical decomposition for complex task management, and causal memory that learns from both successes and failures. Unlike existing approaches, LOOP generates PDDL specifications, refines them iteratively based on symbolic feedback, and builds a causal knowledge base from execution traces. LOOP was evaluated on six standard IPC benchmark domains, where it achieved 85.8% success rate compared to LLM+P (55.0%), LLM-as-Planner (19.2%), and Tree-of-Thoughts (3.3%). This work shows that the key to reliable planning is not in choosing between neural networks or symbolic reasoners but it lies in making them actually ``talk'' to each other during the entire process. LOOP provides a thorough blueprint for building autonomous systems that can finally be trusted with critical real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªä¸»ç³»ç»Ÿè§„åˆ’ä¸­ç¥ç»ç½‘ç»œæ–¹æ³•æ˜“äº§ç”Ÿå¹»è§‰ä¸”ç¼ºä¹é€»è¾‘ä¿éšœï¼Œä»¥åŠä¼ ç»Ÿç¬¦å·è§„åˆ’å™¨ç¼ºä¹çµæ´»æ€§ç­‰é—®é¢˜ï¼Œæå‡ºäº†LOOPæ¡†æ¶ã€‚LOOPæ˜¯ä¸€ç§å³æ’å³ç”¨çš„Neuro-Symbolicè§„åˆ’æ¡†æ¶ï¼Œå®ƒå°†è§„åˆ’è¿‡ç¨‹è§†ä¸ºç¥ç»ç»„ä»¶ä¸ç¬¦å·ç»„ä»¶ä¹‹é—´çš„è¿­ä»£å¯¹è¯ï¼Œè€Œéç®€å•çš„å•æ¬¡ç¿»è¯‘ã€‚è¯¥æ¡†æ¶é›†æˆäº†åŒ…æ‹¬Graph Neural Networksã€Multi-agent validationã€Hierarchical decompositionå’ŒCausal memoryåœ¨å†…çš„13é¡¹åè°ƒç¥ç»ç‰¹æ€§ã€‚é€šè¿‡ç”ŸæˆPDDLè§„èŒƒå¹¶æ ¹æ®ç¬¦å·åé¦ˆè¿›è¡ŒæŒç»­ä¼˜åŒ–ï¼ŒLOOPèƒ½å¤Ÿä»æ‰§è¡Œè·¯å¾„ä¸­æ„å»ºå› æœçŸ¥è¯†åº“ä»¥æå‡å†³ç­–ç²¾åº¦ã€‚åœ¨å…­ä¸ªæ ‡å‡†IPCåŸºå‡†åŸŸçš„æµ‹è¯•ä¸­ï¼ŒLOOPå®ç°äº†85.8%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºLLM+Pï¼ˆ55.0%ï¼‰å’ŒTree-of-Thoughtsï¼ˆ3.3%ï¼‰ç­‰ç°æœ‰æ¨¡å‹ã€‚å®éªŒç»“æœè¯æ˜ï¼Œç¥ç»ç½‘ç»œä¸ç¬¦å·æ¨ç†å™¨åœ¨æ•´ä¸ªè§„åˆ’è¿‡ç¨‹ä¸­çš„æ·±åº¦äº¤äº’æ˜¯æé«˜ç³»ç»Ÿå¯é æ€§çš„å…³é”®ï¼Œä¸ºæ„å»ºå¯ä¿¡çš„ç°å®ä¸–ç•Œè‡ªä¸»ç³»ç»Ÿæä¾›äº†è¯¦å°½è“å›¾ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to IAAI-26",
      "pdf_url": "https://arxiv.org/pdf/2508.13371v1",
      "published_date": "2025-08-18 21:21:21 UTC",
      "updated_date": "2025-08-18 21:21:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:06.190302+00:00"
    },
    {
      "arxiv_id": "2508.15831v2",
      "title": "Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs",
      "title_zh": "è°åœ¨æé—®ï¼ŸåŸºäºå¤§è¯­è¨€æ¨¡å‹ä¸­æ®‹éšœè§†è§’æŸ¥è¯¢çš„åè§ç ”ç©¶",
      "authors": [
        "Vishnu Hari",
        "Kalpana Panda",
        "Srikant Panda",
        "Amit Agarwal",
        "Hitesh Laxmichand Patel"
      ],
      "abstract": "Large Language Models (LLMs) routinely infer users demographic traits from phrasing alone, which can result in biased responses, even when no explicit demographic information is provided. The role of disability cues in shaping these inferences remains largely uncharted. Thus, we present the first systematic audit of disability-conditioned demographic bias across eight state-of-the-art instruction-tuned LLMs ranging from 3B to 72B parameters. Using a balanced template corpus that pairs nine disability categories with six real-world business domains, we prompt each model to predict five demographic attributes - gender, socioeconomic status, education, cultural background, and locality - under both neutral and disability-aware conditions.\n  Across a varied set of prompts, models deliver a definitive demographic guess in up to 97\\% of cases, exposing a strong tendency to make arbitrary inferences with no clear justification. Disability context heavily shifts predicted attribute distributions, and domain context can further amplify these deviations. We observe that larger models are simultaneously more sensitive to disability cues and more prone to biased reasoning, indicating that scale alone does not mitigate stereotype amplification.\n  Our findings reveal persistent intersections between ableism and other demographic stereotypes, pinpointing critical blind spots in current alignment strategies. We release our evaluation framework and results to encourage disability-inclusive benchmarking and recommend integrating abstention calibration and counterfactual fine-tuning to curb unwarranted demographic inference. Code and data will be released on acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹å…«ç§å‚æ•°é‡åœ¨ 3B åˆ° 72B ä¹‹é—´çš„å…ˆè¿›å¤§è¯­è¨€æ¨¡å‹ (LLMs) è¿›è¡Œäº†é¦–æ¬¡å…³äºæ®‹éšœæš—ç¤º (disability cues) å¼•å‘çš„äººå£ç»Ÿè®¡å­¦åè§çš„ç³»ç»Ÿæ€§å®¡è®¡ã€‚é€šè¿‡ç»“åˆä¹ç±»æ®‹éšœèŒƒç•´ä¸å…­ä¸ªå•†ä¸šé¢†åŸŸçš„æ¨¡æ¿è¯­æ–™åº“ï¼Œç ”ç©¶è€…åˆ†æäº†æ¨¡å‹åœ¨ä¸åŒè¯­å¢ƒä¸‹å¯¹æ€§åˆ«ã€ç¤¾ä¼šç»æµåœ°ä½ (socioeconomic status)ã€æ•™è‚²ã€æ–‡åŒ–èƒŒæ™¯åŠåœ°åŸŸç­‰äº”ä¸ªå±æ€§çš„é¢„æµ‹å€¾å‘ã€‚å®éªŒå‘ç°ï¼Œæ¨¡å‹åœ¨é«˜è¾¾ 97% çš„æ¡ˆä¾‹ä¸­ä¼šåšå‡ºç¡®å®šæ€§çš„äººå£ç»Ÿè®¡æ¨æ–­ï¼Œæ˜¾ç¤ºå‡ºåœ¨æ— æ˜ç¡®ä¾æ®æƒ…å†µä¸‹è¿›è¡Œéšæ„æ¨ç†çš„ä¸¥é‡å€¾å‘ã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œæ®‹éšœè¯­å¢ƒä¼šæ˜¾è‘—æ”¹å˜é¢„æµ‹åˆ†å¸ƒï¼Œä¸”è¾ƒå¤§è§„æ¨¡çš„æ¨¡å‹åè€Œå¯¹æ®‹éšœæš—ç¤ºæ›´æ•æ„Ÿï¼Œæ›´å®¹æ˜“äº§ç”Ÿåè§æ¨ç†ï¼Œè¯æ˜ä»…é æ‰©å¤§è§„æ¨¡æ— æ³•æ¶ˆé™¤åˆ»æ¿å°è±¡ã€‚è¿™æ­ç¤ºäº†æ®‹éšœæ­§è§† (ableism) ä¸å…¶ä»–äººå£ç»Ÿè®¡åˆ»æ¿å°è±¡ä¹‹é—´çš„æ·±åº¦äº¤å‰ï¼Œå¹¶æŒ‡å‡ºäº†å½“å‰å¯¹é½ç­–ç•¥çš„ç›²ç‚¹ã€‚ä½œè€…æœ€åå»ºè®®é€šè¿‡å¼•å…¥æ‹’ç»å›ç­”æ ¡å‡† (abstention calibration) å’Œåäº‹å®å¾®è°ƒ (counterfactual fine-tuning) ç­‰æŠ€æœ¯ï¼Œæ¥éåˆ¶ LLMs ä¸­è¿™ç§æ— æ ¹æ®çš„äººå£ç»Ÿè®¡å­¦æ¨æ–­ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.15831v2",
      "published_date": "2025-08-18 21:03:09 UTC",
      "updated_date": "2025-10-22 02:49:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:01.493826+00:00"
    },
    {
      "arxiv_id": "2508.13358v1",
      "title": "Overcoming Latency Bottlenecks in On-Device Speech Translation: A Cascaded Approach with Alignment-Based Streaming MT",
      "title_zh": "è§£å†³ç«¯ä¾§è¯­éŸ³ç¿»è¯‘ä¸­çš„å»¶è¿Ÿç“¶é¢ˆï¼šä¸€ç§åŸºäºå¯¹é½æµå¼æœºå™¨ç¿»è¯‘çš„çº§è”æ–¹æ³•",
      "authors": [
        "Zeeshan Ahmed",
        "Frank Seide",
        "Niko Moritz",
        "Ju Lin",
        "Ruiming Xie",
        "Simone Merello",
        "Zhe Liu",
        "Christian Fuegen"
      ],
      "abstract": "This paper tackles several challenges that arise when integrating Automatic Speech Recognition (ASR) and Machine Translation (MT) for real-time, on-device streaming speech translation. Although state-of-the-art ASR systems based on Recurrent Neural Network Transducers (RNN-T) can perform real-time transcription, achieving streaming translation in real-time remains a significant challenge. To address this issue, we propose a simultaneous translation approach that effectively balances translation quality and latency. We also investigate efficient integration of ASR and MT, leveraging linguistic cues generated by the ASR system to manage context and utilizing efficient beam-search pruning techniques such as time-out and forced finalization to maintain system's real-time factor. We apply our approach to an on-device bilingual conversational speech translation and demonstrate that our techniques outperform baselines in terms of latency and quality. Notably, our technique narrows the quality gap with non-streaming translation systems, paving the way for more accurate and efficient real-time speech translation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨è®¾å¤‡ç«¯(on-device)å®æ—¶æµå¼è¯­éŸ³ç¿»è¯‘ä¸­é›†æˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)å’Œæœºå™¨ç¿»è¯‘(MT)é¢ä¸´çš„å»¶è¿Ÿç“¶é¢ˆé—®é¢˜æå‡ºäº†è§£å†³æ–¹æ¡ˆã€‚ä½œè€…æå‡ºäº†ä¸€ç§çº§è”å¼çš„åŒå£°ä¼ è¯‘æ–¹æ³•ï¼Œæ—¨åœ¨æœ‰æ•ˆå¹³è¡¡ç¿»è¯‘è´¨é‡ä¸å»¶è¿Ÿï¼Œå®ç°æ›´é«˜æ•ˆçš„æµå¼ç¿»è¯‘ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨ASRç³»ç»Ÿç”Ÿæˆçš„è¯­è¨€çº¿ç´¢(linguistic cues)æ¥ç®¡ç†ä¸Šä¸‹æ–‡ï¼Œå®ç°äº†ASRä¸MTçš„é«˜æ•ˆé›†æˆã€‚ä¸ºäº†ç»´æŒç³»ç»Ÿçš„å®æ—¶å› å­(real-time factor)ï¼Œç ”ç©¶é‡‡ç”¨äº†é«˜æ•ˆçš„æŸæœç´¢å‰ªæ(beam-search pruning)æŠ€æœ¯ï¼ŒåŒ…æ‹¬è¶…æ—¶(time-out)å’Œå¼ºåˆ¶å®Œæˆ(forced finalization)ã€‚è¯¥æŠ€æœ¯è¢«åº”ç”¨äºè®¾å¤‡ç«¯åŒè¯­å¯¹è¯è¯­éŸ³ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå…¶åœ¨å»¶è¿Ÿå’Œç¿»è¯‘è´¨é‡ä¸Šå‡ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚è¯¥æ–¹æ³•æ˜¾è‘—ç¼©å°äº†ä¸éæµå¼ç¿»è¯‘ç³»ç»Ÿ(non-streaming translation systems)ä¹‹é—´çš„è´¨é‡å·®è·ï¼Œä¸ºå®ç°æ›´å‡†ç¡®ã€é«˜æ•ˆçš„å®æ—¶è¯­éŸ³ç¿»è¯‘å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13358v1",
      "published_date": "2025-08-18 21:00:11 UTC",
      "updated_date": "2025-08-18 21:00:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:20.146612+00:00"
    },
    {
      "arxiv_id": "2508.13355v2",
      "title": "Counterfactual Probabilistic Diffusion with Expert Models",
      "title_zh": "ç»“åˆä¸“å®¶æ¨¡å‹çš„åäº‹å®æ¦‚ç‡æ‰©æ•£",
      "authors": [
        "Wenhao Mu",
        "Zhi Cao",
        "Mehmed Uludag",
        "Alexander RodrÃ­guez"
      ],
      "abstract": "Predicting counterfactual distributions in complex dynamical systems is essential for scientific modeling and decision-making in domains such as public health and medicine. However, existing methods often rely on point estimates or purely data-driven models, which tend to falter under data scarcity. We propose a time series diffusion-based framework that incorporates guidance from imperfect expert models by extracting high-level signals to serve as structured priors for generative modeling. Our method, ODE-Diff, bridges mechanistic and data-driven approaches, enabling more reliable and interpretable causal inference. We evaluate ODE-Diff across semi-synthetic COVID-19 simulations, synthetic pharmacological dynamics, and real-world case studies, demonstrating that it consistently outperforms strong baselines in both point prediction and distributional accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ODE-Diffï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ—¶é—´åºåˆ—æ‰©æ•£æ¨¡å‹(diffusion-based framework)çš„æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºé¢„æµ‹å¤æ‚åŠ¨åŠ›ç³»ç»Ÿä¸­çš„åäº‹å®åˆ†å¸ƒ(counterfactual distributions)ã€‚ä¸ºäº†åº”å¯¹å…¬å…±å«ç”Ÿå’ŒåŒ»å­¦ç­‰é¢†åŸŸæ•°æ®ç¨€ç¼ºå¸¦æ¥çš„æŒ‘æˆ˜ï¼ŒODE-Diffé€šè¿‡æå–ä¸å®Œç¾ä¸“å®¶æ¨¡å‹(imperfect expert models)çš„é«˜çº§ä¿¡å·ï¼Œå°†å…¶ä½œä¸ºç”Ÿæˆå»ºæ¨¡çš„ç»“æ„åŒ–å…ˆéªŒã€‚è¯¥æ–¹æ³•æˆåŠŸæ¡¥æ¥äº†æœºæ¢°åŒ–æ¨¡å‹(mechanistic models)ä¸æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œä»è€Œå®ç°äº†æ›´å¯é ä¸”å…·å¯è§£é‡Šæ€§çš„å› æœæ¨ç†(causal inference)ã€‚å®éªŒè¯„ä¼°æ¶µç›–äº†åŠåˆæˆçš„COVID-19æ¨¡æ‹Ÿã€åˆæˆè¯ç†åŠ¨åŠ›å­¦ä»¥åŠçœŸå®ä¸–ç•Œæ¡ˆä¾‹ç ”ç©¶ã€‚ç»“æœè¡¨æ˜ï¼ŒODE-Diffåœ¨ç‚¹é¢„æµ‹(point prediction)å’Œåˆ†å¸ƒå‡†ç¡®æ€§(distributional accuracy)æ–¹é¢å‡æ˜¾è‘—ä¸”æŒç»­åœ°ä¼˜äºç°æœ‰çš„å¼ºåŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13355v2",
      "published_date": "2025-08-18 20:44:32 UTC",
      "updated_date": "2025-09-11 20:38:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:22.683648+00:00"
    },
    {
      "arxiv_id": "2508.13333v1",
      "title": "HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design",
      "title_zh": "HiFo-Promptï¼šèåˆåè§ä¸å…ˆè§æç¤ºçš„å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨å¯å‘å¼è®¾è®¡",
      "authors": [
        "Chentong Chen",
        "Mengyuan Zhong",
        "Jianyong Sun",
        "Ye Fan",
        "Jialong Shi"
      ],
      "abstract": "LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation (EC) frameworks has shown promising results. However, its effectiveness is hindered by the use of static operators and the lack of knowledge accumulation mechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two synergistic prompting strategies: Foresight and Hindsight. Foresight-based prompts adaptively steer the search based on population dynamics, managing the exploration-exploitation trade-off. In addition, hindsight-based prompts mimic human expertise by distilling successful heuristics from past generations into fundamental, reusable design principles. This dual mechanism transforms transient discoveries into a persistent knowledge base, enabling the LLM to learn from its own experience. Empirical results demonstrate that HiFo-Prompt significantly outperforms state-of-the-art LLM-based AHD methods, generating higher-quality heuristics while achieving substantially faster convergence and superior query efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„è‡ªåŠ¨å¯å‘å¼è®¾è®¡(Automatic Heuristic Design, AHD)åœ¨æ¼”åŒ–è®¡ç®—ä¸­å—é™äºé™æ€ç®—å­å’ŒçŸ¥è¯†ç§¯ç´¯æœºåˆ¶ç¼ºå¤±çš„é—®é¢˜ï¼Œæå‡ºäº†HiFo-Promptæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ååŒå‰ç»(Foresight)å’ŒåéªŒ(Hindsight)ä¸¤ç§æç¤ºç­–ç•¥å¼•å¯¼LLMè¿›è¡Œå¯å‘å¼æœç´¢ã€‚å‰ç»æç¤ºæ ¹æ®ç¾¤ä½“åŠ¨åŠ›å­¦è‡ªé€‚åº”åœ°è°ƒæ•´æœç´¢æ–¹å‘ï¼Œä»è€Œä¼˜åŒ–æ¢ç´¢ä¸å¼€å‘(exploration-exploitation)çš„å¹³è¡¡ï¼›åéªŒæç¤ºåˆ™é€šè¿‡æç‚¼å¾€ä»£æˆåŠŸçš„å¯å‘å¼è®¾è®¡åŸåˆ™ï¼Œå°†é›¶æ•£çš„å‘ç°è½¬åŒ–ä¸ºå¯é‡ç”¨çš„çŸ¥è¯†åº“ã€‚è¿™ç§åŒé‡æœºåˆ¶ä½¿LLMèƒ½å¤Ÿä»è‡ªèº«ç»éªŒä¸­å­¦ä¹ ï¼Œæ¨¡æ‹Ÿäº†äººç±»ä¸“å®¶çš„çŸ¥è¯†ç§¯ç´¯è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHiFo-Promptåœ¨å¯å‘å¼ç®—æ³•ç”Ÿæˆè´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰å…ˆè¿›æ–¹æ³•ï¼ŒåŒæ—¶åœ¨æ”¶æ•›é€Ÿåº¦å’ŒæŸ¥è¯¢æ•ˆç‡(query efficiency)æ–¹é¢è¡¨ç°å“è¶Šã€‚",
      "categories": [
        "cs.AI",
        "cs.NE",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.13333v1",
      "published_date": "2025-08-18 19:42:55 UTC",
      "updated_date": "2025-08-18 19:42:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:25.067659+00:00"
    },
    {
      "arxiv_id": "2508.15830v1",
      "title": "DAIQ: Auditing Demographic Attribute Inference from Question in LLMs",
      "title_zh": "DAIQï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­åŸºäºæé—®çš„äººå£ç»Ÿè®¡å±æ€§æ¨æ–­å®¡è®¡",
      "authors": [
        "Srikant Panda",
        "Hitesh Laxmichand Patel",
        "Shahad Al-Khalifa",
        "Amit Agarwal",
        "Hend Al-Khalifa",
        "Sharefah Al-Ghamdi"
      ],
      "abstract": "Large Language Models (LLMs) are known to reflect social biases when demographic attributes, such as gender or race, are explicitly present in the input. But even in their absence, these models still infer user identities based solely on question phrasing. This subtle behavior has received far less attention, yet poses serious risks: it violates expectations of neutrality, infers unintended demographic information, and encodes stereotypes that undermine fairness in various domains including healthcare, finance and education.\n  We introduce Demographic Attribute Inference from Questions (DAIQ), a task and framework for auditing an overlooked failure mode in language models: inferring user demographic attributes from questions that lack explicit demographic cues. Our approach leverages curated neutral queries, systematic prompting, and both quantitative and qualitative analysis to uncover how models infer demographic information. We show that both open and closed source LLMs do assign demographic labels based solely on question phrasing.\n  Prevalence and consistency of demographic inferences across diverse models reveal a systemic and underacknowledged risk: LLMs can fabricate demographic identities, reinforce societal stereotypes, and propagate harms that erode privacy, fairness, and trust posing a broader threat to social equity and responsible AI deployment. To mitigate this, we develop a prompt-based guardrail that substantially reduces identity inference and helps align model behavior with fairness and privacy objectives.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DAIQæ¡†æ¶ï¼Œæ—¨åœ¨å®¡è®¡å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¾“å…¥ç¼ºä¹æ˜¾å¼äººå£ç»Ÿè®¡çº¿ç´¢æ—¶ï¼Œä»…å‡­é—®é¢˜æªè¾æ¨æ–­ç”¨æˆ·äººå£ç»Ÿè®¡å±æ€§(Demographic Attribute Inference)çš„è¡Œä¸ºã€‚ç ”ç©¶å‘ç°ï¼Œå¼€æºå’Œé—­æºLLMséƒ½ä¼šæ ¹æ®ç”¨æˆ·çš„æé—®é£æ ¼éšæ€§æ¨æ–­å…¶èº«ä»½ï¼Œè¿™ç§è¡Œä¸ºä¼šå¯¼è‡´æ¨¡å‹äº§ç”Ÿç¤¾ä¼šåè§å¹¶å¼ºåŒ–åˆ»æ¿å°è±¡ï¼Œä»è€Œå¯¹éšç§å’Œå…¬å¹³æ€§æ„æˆä¸¥é‡å¨èƒã€‚é€šè¿‡å¯¹ä¸­æ€§æŸ¥è¯¢çš„ç³»ç»Ÿæ€§å®¡è®¡ï¼Œè¯¥æ¡†æ¶æ­ç¤ºäº†æ¨¡å‹åœ¨æ¨æ–­èº«ä»½æ—¶å­˜åœ¨çš„æ™®éæ€§é£é™©ï¼Œè¿™äº›é£é™©å¯èƒ½åœ¨åŒ»ç–—ã€é‡‘èå’Œæ•™è‚²ç­‰å…³é”®é¢†åŸŸåŠ å‰§ç¤¾ä¼šä¸å¹³ç­‰ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶äººå‘˜å¼€å‘äº†ä¸€ç§åŸºäºæç¤ºè¯çš„æŠ¤æ (prompt-based guardrail)ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æ¨¡å‹å¯¹ç”¨æˆ·èº«ä»½çš„æ— ç«¯æ¨æ–­ï¼Œå¹¶ä½¿å…¶è¡Œä¸ºç¬¦åˆå…¬å¹³æ€§ç›®æ ‡ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…é‡åŒ–äº†æ¨¡å‹ä¸­çš„éšæ€§åè§é£é™©ï¼Œè¿˜ä¸ºå®ç°æ›´å…¬å¹³ä¸”è´Ÿè´£ä»»çš„AI(Responsible AI)éƒ¨ç½²æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2508.15830v1",
      "published_date": "2025-08-18 19:26:17 UTC",
      "updated_date": "2025-08-18 19:26:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:31.250084+00:00"
    },
    {
      "arxiv_id": "2508.13328v1",
      "title": "A Dual-Attention Graph Network for fMRI Data Classification",
      "title_zh": "ç”¨äº fMRI æ•°æ®åˆ†ç±»çš„åŒæ³¨æ„åŠ›å›¾ç½‘ç»œ",
      "authors": [
        "Amirali Arbab",
        "Zeinab Davarani",
        "Mehran Safayani"
      ],
      "abstract": "Understanding the complex neural activity dynamics is crucial for the development of the field of neuroscience. Although current functional MRI classification approaches tend to be based on static functional connectivity or cannot capture spatio-temporal relationships comprehensively, we present a new framework that leverages dynamic graph creation and spatiotemporal attention mechanisms for Autism Spectrum Disorder(ASD) diagnosis. The approach used in this research dynamically infers functional brain connectivity in each time interval using transformer-based attention mechanisms, enabling the model to selectively focus on crucial brain regions and time segments. By constructing time-varying graphs that are then processed with Graph Convolutional Networks (GCNs) and transformers, our method successfully captures both localized interactions and global temporal dependencies. Evaluated on the subset of ABIDE dataset, our model achieves 63.2 accuracy and 60.0 AUC, outperforming static graph-based approaches (e.g., GCN:51.8). This validates the efficacy of joint modeling of dynamic connectivity and spatio-temporal context for fMRI classification. The core novelty arises from (1) attention-driven dynamic graph creation that learns temporal brain region interactions and (2) hierarchical spatio-temporal feature fusion through GCNtransformer fusion.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒ(fMRI)åˆ†ç±»ä¸­é™æ€åŠŸèƒ½è¿æ¥æ— æ³•å…¨é¢æ•æ‰æ—¶ç©ºå…³ç³»çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºè‡ªé—­ç—‡è°±ç³»éšœç¢(ASD)è¯Šæ–­çš„æ–°å‹åŒæ³¨æ„åŠ›å›¾ç½‘ç»œæ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŸºäºTransformerçš„æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€æ¨æ–­æ¯ä¸ªæ—¶é—´é—´éš”å†…çš„è„‘åŠŸèƒ½è¿æ¥ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€‰æ‹©æ€§åœ°å…³æ³¨å…³é”®çš„å¤§è„‘åŒºåŸŸå’Œæ—¶é—´ç‰‡æ®µã€‚é€šè¿‡æ„å»ºéšæ—¶é—´å˜åŒ–çš„åŠ¨æ€å›¾å¹¶ç»“åˆå›¾å·ç§¯ç½‘ç»œ(GCN)ä¸Transformerï¼Œè¯¥æ¨¡å‹æˆåŠŸæ•æ‰äº†è„‘åŒºçš„å±€éƒ¨äº¤äº’å’Œå…¨å±€æ—¶é—´ä¾èµ–æ€§ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºé€šè¿‡æ³¨æ„åŠ›é©±åŠ¨çš„åŠ¨æ€å›¾æ„å»ºå­¦ä¹ æ—¶é—´ç»´åº¦çš„è„‘åŒºäº¤äº’ï¼Œå¹¶åˆ©ç”¨GCN-transformerèåˆå®ç°å±‚æ¬¡åŒ–çš„æ—¶ç©ºç‰¹å¾æå–ã€‚åœ¨ABIDEæ•°æ®é›†å­é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹è¾¾åˆ°äº†63.2%çš„å‡†ç¡®ç‡å’Œ60.0çš„AUCï¼Œæ˜¾è‘—ä¼˜äºGCNç­‰é™æ€å›¾åŸºå‡†æ–¹æ³•ã€‚è¿™ä¸€ç ”ç©¶ç»“æœå……åˆ†éªŒè¯äº†åŠ¨æ€è¿æ¥æ€§å»ºæ¨¡ä¸æ—¶ç©ºä¸Šä¸‹æ–‡è”åˆåˆ†æåœ¨fMRIæ•°æ®åˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13328v1",
      "published_date": "2025-08-18 19:23:18 UTC",
      "updated_date": "2025-08-18 19:23:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:30.153572+00:00"
    },
    {
      "arxiv_id": "2508.13327v1",
      "title": "Towards Unified Multimodal Financial Forecasting: Integrating Sentiment Embeddings and Market Indicators via Cross-Modal Attention",
      "title_zh": "è¿ˆå‘ç»Ÿä¸€çš„å¤šæ¨¡æ€é‡‘èé¢„æµ‹ï¼šåŸºäºè·¨æ¨¡æ€æ³¨æ„åŠ›çš„æƒ…æ„ŸåµŒå…¥ä¸å¸‚åœºæŒ‡æ ‡èåˆ",
      "authors": [
        "Sarthak Khanna",
        "Armin Berger",
        "David Berghaus",
        "Tobias Deusser",
        "Lorenz Sparrenberg",
        "Rafet Sifa"
      ],
      "abstract": "We propose STONK (Stock Optimization using News Knowledge), a multimodal framework integrating numerical market indicators with sentiment-enriched news embeddings to improve daily stock-movement prediction. By combining numerical & textual embeddings via feature concatenation and cross-modal attention, our unified pipeline addresses limitations of isolated analyses. Backtesting shows STONK outperforms numeric-only baselines. A comprehensive evaluation of fusion strategies and model configurations offers evidence-based guidance for scalable multimodal financial forecasting. Source code is available on GitHub",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† STONK (Stock Optimization using News Knowledge)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æ”¹è¿›æ¯æ—¥è‚¡ç¥¨èµ°åŠ¿é¢„æµ‹çš„ç»Ÿä¸€å¤šæ¨¡æ€æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†æ•°å€¼å¸‚åœºæŒ‡æ ‡ (numerical market indicators) ä¸å¯Œå«æƒ…æ„Ÿçš„æ–°é—»åµŒå…¥ (sentiment-enriched news embeddings) ç›¸ç»“åˆï¼Œé€šè¿‡ç‰¹å¾æ‹¼æ¥ (feature concatenation) å’Œè·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ (cross-modal attention) å®ç°äº†ä¸åŒæ¨¡æ€æ•°æ®çš„æ·±åº¦èåˆã€‚è¯¥æ–¹æ¡ˆæœ‰æ•ˆè§£å†³äº†ä»¥å¾€å­¤ç«‹åˆ†ææ•°å€¼æˆ–æ–‡æœ¬æ•°æ®æ‰€å¸¦æ¥çš„å±€é™æ€§ï¼Œæå‡äº†é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚å›æµ‹ (Backtesting) ç»“æœè¡¨æ˜ï¼ŒSTONK çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºä»…ä¾èµ–æ•°å€¼æŒ‡æ ‡çš„åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¯¹å¤šç§èåˆç­–ç•¥ (fusion strategies) å’Œæ¨¡å‹é…ç½®è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œä¸ºæ„å»ºå¯æ‰©å±•çš„å¤šæ¨¡æ€é‡‘èé¢„æµ‹ç³»ç»Ÿæä¾›äº†å®è¯æŒ‡å¯¼ã€‚ç›®å‰ï¼Œè¯¥é¡¹ç›®çš„æºä»£ç å·²åœ¨ GitHub ä¸Šå…¬å¼€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in IEEE-DSAA 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.13327v1",
      "published_date": "2025-08-18 19:22:39 UTC",
      "updated_date": "2025-08-18 19:22:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:41.191264+00:00"
    },
    {
      "arxiv_id": "2508.14921v1",
      "title": "Designing an Interdisciplinary Artificial Intelligence Curriculum for Engineering: Evaluation and Insights from Experts",
      "title_zh": "é¢å‘å·¥ç¨‹é¢†åŸŸçš„è·¨å­¦ç§‘äººå·¥æ™ºèƒ½è¯¾ç¨‹è®¾è®¡ï¼šä¸“å®¶è¯„ä¼°ä¸è§è§£",
      "authors": [
        "Johannes Schleiss",
        "Anke Manukjan",
        "Michelle Ines Bieber",
        "Sebastian Lang",
        "Sebastian Stober"
      ],
      "abstract": "As Artificial Intelligence (AI) increasingly impacts professional practice, there is a growing need to AI-related competencies into higher education curricula. However, research on the implementation of AI education within study programs remains limited and requires new forms of collaboration across disciplines. This study addresses this gap and explores perspectives on interdisciplinary curriculum development through the lens of different stakeholders. In particular, we examine the case of curriculum development for a novel undergraduate program in AI in engineering. The research uses a mixed methods approach, combining quantitative curriculum mapping with qualitative focus group interviews. In addition to assessing the alignment of the curriculum with the targeted competencies, the study also examines the perceived quality, consistency, practicality and effectiveness from both academic and industry perspectives, as well as differences in perceptions between educators who were involved in the development and those who were not. The findings provide a practical understanding of the outcomes of interdisciplinary AI curriculum development and contribute to a broader understanding of how educator participation in curriculum development influences perceptions of quality aspects. It also advances the field of AI education by providing a reference point and insights for further interdisciplinary curriculum developments in response to evolving industry needs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜ç­‰æ•™è‚²ä¸­ Artificial Intelligence (AI) ç›¸å…³èƒ½åŠ›æ•´åˆç ”ç©¶ä¸è¶³çš„ç°çŠ¶ï¼Œæ¢è®¨äº†ä¸ºå·¥ç¨‹é¢†åŸŸè®¾è®¡è·¨å­¦ç§‘ AI è¯¾ç¨‹çš„æŒ‘æˆ˜ä¸å®è·µã€‚ç ”ç©¶ä»¥ä¸€ä¸ªæ–°å‹æœ¬ç§‘ AI å·¥ç¨‹é¡¹ç›®ä¸ºæ¡ˆä¾‹ï¼Œé‡‡ç”¨äº† mixed methods approachï¼Œå°†å®šé‡çš„ curriculum mapping ä¸å®šæ€§çš„ focus group interviews ç›¸ç»“åˆã€‚é€šè¿‡å¯¹å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œä¸åŒåˆ©ç›Šç›¸å…³è€…çš„è°ƒç ”ï¼Œç ”ç©¶è¯„ä¼°äº†è¯¾ç¨‹çš„è´¨é‡ã€ä¸€è‡´æ€§ã€å®ç”¨æ€§åŠæœ‰æ•ˆæ€§ï¼Œå¹¶æ·±å…¥åˆ†æäº†æ•™è‚²è€…å‚ä¸å¼€å‘è¿‡ç¨‹å¯¹è¯¾ç¨‹æ„ŸçŸ¥çš„å½±å“ã€‚ç ”ç©¶ç»“æœä¸ºè·¨å­¦ç§‘ AI è¯¾ç¨‹å¼€å‘æä¾›äº†å®è·µç†è§£ï¼Œè¯å®äº†è¯¾ç¨‹è®¾ç½®ä¸ç›®æ ‡èƒ½åŠ›ä¹‹é—´çš„ç´§å¯†å¯¹é½ã€‚è¯¥é¡¹å·¥ä½œä¸ºåº”å¯¹ä¸æ–­å˜åŒ–çš„å·¥ä¸šéœ€æ±‚æä¾›äº†é‡è¦çš„å‚è€ƒåŸºå‡†ï¼Œä¸ºæœªæ¥ interdisciplinary curriculum å»ºè®¾æä¾›äº†å®è´µè§è§£ï¼Œæœ‰åŠ›æ¨åŠ¨äº† AI education é¢†åŸŸçš„å‘å±•ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14921v1",
      "published_date": "2025-08-18 19:20:05 UTC",
      "updated_date": "2025-08-18 19:20:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:42.185711+00:00"
    },
    {
      "arxiv_id": "2508.13319v1",
      "title": "A Surveillance Based Interactive Robot",
      "title_zh": "åŸºäºç›‘æ§çš„äº¤äº’å¼æœºå™¨äºº",
      "authors": [
        "Kshitij Kavimandan",
        "Pooja Mangal",
        "Devanshi Mehta"
      ],
      "abstract": "We build a mobile surveillance robot that streams video in real time and responds to speech so a user can monitor and steer it from a phone or browser. The system uses two Raspberry Pi 4 units: a front unit on a differential drive base with camera, mic, and speaker, and a central unit that serves the live feed and runs perception. Video is sent with FFmpeg. Objects in the scene are detected using YOLOv3 to support navigation and event awareness. For voice interaction, we use Python libraries for speech recognition, multilingual translation, and text-to-speech, so the robot can take spoken commands and read back responses in the requested language. A Kinect RGB-D sensor provides visual input and obstacle cues. In indoor tests the robot detects common objects at interactive frame rates on CPU, recognises commands reliably, and translates them to actions without manual control. The design relies on off-the-shelf hardware and open software, making it easy to reproduce. We discuss limits and practical extensions, including sensor fusion with ultrasonic range data, GPU acceleration, and adding face and text recognition.",
      "tldr_zh": "è¯¥ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªåŸºäºç§»åŠ¨ç›‘æ§çš„äº¤äº’å¼æœºå™¨äººï¼Œæ”¯æŒå®æ—¶è§†é¢‘æµä¼ è¾“ä¸è¯­éŸ³å“åº”ï¼Œç”¨æˆ·å¯é€šè¿‡æ‰‹æœºæˆ–æµè§ˆå™¨è¿›è¡Œè¿œç¨‹ç›‘æ§ã€‚ç¡¬ä»¶ç³»ç»Ÿç”±ä¸¤ä¸ª Raspberry Pi 4 å•å…ƒç»„æˆï¼Œåˆ†åˆ«æ‰¿æ‹…é©±åŠ¨æ§åˆ¶ä¸ä¸­å¿ƒæ„ŸçŸ¥åŠŸèƒ½ï¼Œå¹¶ä½¿ç”¨ FFmpeg ä¼˜åŒ–è§†é¢‘ä¼ è¾“æ•ˆç‡ã€‚æœºå™¨äººé€šè¿‡ Kinect RGB-D ä¼ æ„Ÿå™¨è·å–è§†è§‰ä¸éšœç¢ç‰©ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨ YOLOv3 ç®—æ³•åœ¨ CPU ä¸Šå®ç°äº¤äº’å¼å¸§ç‡çš„ç‰©ä½“æ£€æµ‹ã€‚è¯­éŸ³äº¤äº’ç³»ç»Ÿé›†æˆäº†å¤šè¯­è¨€ç¿»è¯‘å’Œ Text-to-Speech (TTS) æŠ€æœ¯ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿç†è§£å£å¤´æŒ‡ä»¤å¹¶è¿›è¡Œå¤šè¯­è¨€åé¦ˆã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å®¤å†…ç¯å¢ƒä¸‹å…·æœ‰è¾ƒé«˜çš„æŒ‡ä»¤è¯†åˆ«å¯é æ€§ï¼Œèƒ½å¤Ÿæ— éœ€æ‰‹åŠ¨å¹²é¢„åœ°å®ŒæˆåŠ¨ä½œè½¬åŒ–ã€‚è¯¥æ–¹æ¡ˆå®Œå…¨åŸºäºå¼€æºè½¯ä»¶å’Œé€šç”¨ç¡¬ä»¶ï¼Œå…·æœ‰è¾ƒå¼ºçš„å¯å¤ç”¨æ€§ï¼Œå¹¶æ¢è®¨äº†æœªæ¥å¼•å…¥ä¼ æ„Ÿå™¨èåˆå’Œ GPU åŠ é€Ÿçš„æ‰©å±•æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "4 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.13319v1",
      "published_date": "2025-08-18 19:09:43 UTC",
      "updated_date": "2025-08-18 19:09:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:44.483650+00:00"
    },
    {
      "arxiv_id": "2508.13303v1",
      "title": "Diff-MSM: Differentiable MusculoSkeletal Model for Simultaneous Identification of Human Muscle and Bone Parameters",
      "title_zh": "Diff-MSMï¼šç”¨äºäººä½“è‚Œè‚‰ä¸éª¨éª¼å‚æ•°åŒæ­¥è¾¨è¯†çš„å¯å¾®è‚Œè‚‰éª¨éª¼æ¨¡å‹",
      "authors": [
        "Yingfan Zhou",
        "Philip Sanderink",
        "Sigurd Jager Lemming",
        "Cheng Fang"
      ],
      "abstract": "High-fidelity personalized human musculoskeletal models are crucial for simulating realistic behavior of physically coupled human-robot interactive systems and verifying their safety-critical applications in simulations before actual deployment, such as human-robot co-transportation and rehabilitation through robotic exoskeletons. Identifying subject-specific Hill-type muscle model parameters and bone dynamic parameters is essential for a personalized musculoskeletal model, but very challenging due to the difficulty of measuring the internal biomechanical variables in vivo directly, especially the joint torques. In this paper, we propose using Differentiable MusculoSkeletal Model (Diff-MSM) to simultaneously identify its muscle and bone parameters with an end-to-end automatic differentiation technique differentiating from the measurable muscle activation, through the joint torque, to the resulting observable motion without the need to measure the internal joint torques. Through extensive comparative simulations, the results manifested that our proposed method significantly outperformed the state-of-the-art baseline methods, especially in terms of accurate estimation of the muscle parameters (i.e., initial guess sampled from a normal distribution with the mean being the ground truth and the standard deviation being 10% of the ground truth could end up with an average of the percentage errors of the estimated values as low as 0.05%). In addition to human musculoskeletal modeling and simulation, the new parameter identification technique with the Diff-MSM has great potential to enable new applications in muscle health monitoring, rehabilitation, and sports science.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† Diff-MSM (Differentiable MusculoSkeletal Model) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç‰©ç†è€¦åˆäººæœºäº¤äº’ç³»ç»Ÿåœ¨ä¸ªæ€§åŒ–éª¨éª¼è‚Œè‚‰æ¨¡å‹å‚æ•°è¯†åˆ«æ–¹é¢çš„æŒ‘æˆ˜ã€‚é’ˆå¯¹æ´»ä½“å†…éƒ¨å…³èŠ‚åŠ›çŸ© (joint torques) éš¾ä»¥ç›´æ¥æµ‹é‡çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç«¯åˆ°ç«¯è‡ªåŠ¨å¾®åˆ† (automatic differentiation) æŠ€æœ¯ï¼Œå®ç°äº†ä»å¯æµ‹é‡çš„è‚Œè‚‰æ¿€æ´» (muscle activation) åˆ°æœ€ç»ˆè§‚æµ‹è¿åŠ¨çš„ç›´æ¥å…³è”ã€‚é€šè¿‡è¿™ç§å·®å¼‚åŒ–å»ºæ¨¡ï¼ŒDiff-MSM èƒ½å¤ŸåŒæ—¶è¯†åˆ« Hill-type è‚Œè‚‰å‚æ•°å’Œéª¨éª¼åŠ¨åŠ›å­¦å‚æ•°ï¼Œä¸”æ— éœ€ä¾èµ–å†…éƒ¨åŠ›çŸ©çš„æµ‹é‡ã€‚ä»¿çœŸå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºå‡†æ–¹æ³• (baseline methods)ï¼Œå…¶è‚Œè‚‰å‚æ•°ä¼°è®¡çš„å¹³å‡è¯¯å·®å¯ä½è‡³ 0.05%ã€‚è¯¥ç ”ç©¶ä¸ä»…æå‡äº†äººä½“å»ºæ¨¡çš„ä¿çœŸåº¦ï¼Œè¿˜ä¸ºè‚Œè‚‰å¥åº·ç›‘æµ‹ã€åº·å¤åŒ»ç–—åŠè¿åŠ¨ç§‘å­¦é¢†åŸŸçš„åº”ç”¨æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.13303v1",
      "published_date": "2025-08-18 18:43:43 UTC",
      "updated_date": "2025-08-18 18:43:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:43.283362+00:00"
    },
    {
      "arxiv_id": "2508.13300v1",
      "title": "GaitCrafter: Diffusion Model for Biometric Preserving Gait Synthesis",
      "title_zh": "GaitCrafterï¼šé¢å‘ç”Ÿç‰©ç‰¹å¾ä¿æŒæ­¥æ€åˆæˆçš„æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Sirshapan Mitra",
        "Yogesh S. Rawat"
      ],
      "abstract": "Gait recognition is a valuable biometric task that enables the identification of individuals from a distance based on their walking patterns. However, it remains limited by the lack of large-scale labeled datasets and the difficulty of collecting diverse gait samples for each individual while preserving privacy. To address these challenges, we propose GaitCrafter, a diffusion-based framework for synthesizing realistic gait sequences in the silhouette domain. Unlike prior works that rely on simulated environments or alternative generative models, GaitCrafter trains a video diffusion model from scratch, exclusively on gait silhouette data. Our approach enables the generation of temporally consistent and identity-preserving gait sequences. Moreover, the generation process is controllable-allowing conditioning on various covariates such as clothing, carried objects, and view angle. We show that incorporating synthetic samples generated by GaitCrafter into the gait recognition pipeline leads to improved performance, especially under challenging conditions. Additionally, we introduce a mechanism to generate novel identities-synthetic individuals not present in the original dataset-by interpolating identity embeddings. These novel identities exhibit unique, consistent gait patterns and are useful for training models while maintaining privacy of real subjects. Overall, our work takes an important step toward leveraging diffusion models for high-quality, controllable, and privacy-aware gait data generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GaitCrafterï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº Diffusion Model çš„æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºåœ¨ Silhouette Domain ä¸­åˆæˆå†™å®çš„æ­¥æ€åºåˆ—ã€‚é€šè¿‡ä»é›¶å¼€å§‹è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ—¶é—´ä¸€è‡´ä¸”å…·å¤‡ Identity-Preserving ç‰¹æ€§çš„æ­¥æ€æ•°æ®ã€‚è¯¥ç”Ÿæˆè¿‡ç¨‹å…·æœ‰é«˜åº¦å¯æ§æ€§ï¼Œæ”¯æŒé’ˆå¯¹è¡£ç€ã€æºå¸¦ç‰©å’Œè§†è§’ç­‰å¤šç§åå˜é‡è¿›è¡Œæ¡ä»¶åŒ–ç”Ÿæˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°† GaitCrafter äº§ç”Ÿçš„åˆæˆæ ·æœ¬æ•´åˆè¿›æ­¥æ€è¯†åˆ«æµç¨‹ï¼Œèƒ½æ˜¾è‘—æ”¹å–„æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡æ’å€¼ Identity Embeddings çš„æ–¹å¼å®ç°äº†å…¨æ–°è™šæ‹Ÿèº«ä»½çš„ç”Ÿæˆï¼Œä»è€Œåœ¨ä¿æŠ¤éšç§çš„åŒæ—¶æ‰©å……äº†æ•°æ®é›†ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥å·¥ä½œä¸ºå®ç°é«˜è´¨é‡ã€å¯æ§ä¸”å…·å¤‡éšç§ä¿æŠ¤æ„è¯†çš„æ­¥æ€æ•°æ®åˆæˆæä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13300v1",
      "published_date": "2025-08-18 18:32:42 UTC",
      "updated_date": "2025-08-18 18:32:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:29:45.684131+00:00"
    },
    {
      "arxiv_id": "2508.14123v1",
      "title": "AI Agents for Photonic Integrated Circuit Design Automation",
      "title_zh": "é¢å‘å…‰å­é›†æˆç”µè·¯è®¾è®¡è‡ªåŠ¨åŒ–çš„ AI æ™ºèƒ½ä½“",
      "authors": [
        "Ankita Sharma",
        "YuQi Fu",
        "Vahid Ansari",
        "Rishabh Iyer",
        "Fiona Kuang",
        "Kashish Mistry",
        "Raisa Islam Aishy",
        "Sara Ahmad",
        "Joaquin Matres",
        "Dirk R. Englund",
        "Joyce K. S. Poon"
      ],
      "abstract": "We present Photonics Intelligent Design and Optimization (PhIDO), a multi-agent framework that converts natural-language photonic integrated circuit (PIC) design requests into layout mask files. We compare 7 reasoning large language models for PhIDO using a testbench of 102 design descriptions that ranged from single devices to 112-component PICs. The success rate for single-device designs was up to 91%. For design queries with less than or equal to 15 components, o1, Gemini-2.5-pro, and Claude Opus 4 achieved the highest end-to-end pass@5 success rates of approximately 57%, with Gemini-2.5-pro requiring the fewest output tokens and lowest cost. The next steps toward autonomous PIC development include standardized knowledge representations, expanded datasets, extended verification, and robotic automation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸º Photonics Intelligent Design and Optimization (PhIDO) çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨å°†è‡ªç„¶è¯­è¨€çš„å…‰å­é›†æˆç”µè·¯ (Photonic Integrated Circuit, PIC) è®¾è®¡è¯·æ±‚è‡ªåŠ¨è½¬æ¢ä¸ºå¸ƒå±€æ©æ¨¡æ–‡ä»¶ã€‚ç ”ç©¶äººå‘˜åœ¨åŒ…å« 102 ä¸ªä»å•ä¸ªå™¨ä»¶åˆ° 112 ä¸ªç»„ä»¶çš„ PIC è®¾è®¡æè¿°æµ‹è¯•é›†ä¸Šï¼Œè¯„ä¼°å¹¶å¯¹æ¯”äº† 7 ç§æ¨ç†å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå•å™¨ä»¶è®¾è®¡çš„æˆåŠŸç‡é«˜è¾¾ 91%ï¼›è€Œåœ¨åŒ…å« 15 ä¸ªåŠä»¥ä¸‹ç»„ä»¶çš„è®¾è®¡ä»»åŠ¡ä¸­ï¼Œo1ã€Gemini-2.5-pro å’Œ Claude Opus 4 è¾¾åˆ°äº†çº¦ 57% çš„ç«¯åˆ°ç«¯ pass@5 æˆåŠŸç‡ã€‚å…¶ä¸­ï¼ŒGemini-2.5-pro åœ¨ä¿è¯é«˜æ€§èƒ½çš„åŒæ—¶è¡¨ç°å‡ºæœ€ä½çš„è¾“å‡º token éœ€æ±‚å’Œæˆæœ¬ä¼˜åŠ¿ã€‚è¯¥å·¥ä½œå±•ç¤ºäº† AI Agents åœ¨å…‰å­å­¦è®¾è®¡è‡ªåŠ¨åŒ–é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥è¿ˆå‘è‡ªä¸» PIC å¼€å‘æ‰€éœ€çš„æ ‡å‡†åŒ–çŸ¥è¯†è¡¨ç¤ºã€æ•°æ®é›†æ‰©å±•åŠæœºå™¨äººè‡ªåŠ¨åŒ–ç­‰æ”¹è¿›æ–¹å‘ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "physics.app-ph",
        "physics.optics"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14123v1",
      "published_date": "2025-08-18 18:20:32 UTC",
      "updated_date": "2025-08-18 18:20:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:03.752565+00:00"
    },
    {
      "arxiv_id": "2508.13288v1",
      "title": "Hierarchical Conformal Classification",
      "title_zh": "å±‚æ¬¡åŒ–ç¬¦åˆåˆ†ç±»",
      "authors": [
        "Floris den Hengst",
        "InÃ¨s Blin",
        "Majid Mohammadi",
        "Syed Ihtesham Hussain Shah",
        "Taraneh Younesian"
      ],
      "abstract": "Conformal prediction (CP) is a powerful framework for quantifying uncertainty in machine learning models, offering reliable predictions with finite-sample coverage guarantees. When applied to classification, CP produces a prediction set of possible labels that is guaranteed to contain the true label with high probability, regardless of the underlying classifier. However, standard CP treats classes as flat and unstructured, ignoring domain knowledge such as semantic relationships or hierarchical structure among class labels. This paper presents hierarchical conformal classification (HCC), an extension of CP that incorporates class hierarchies into both the structure and semantics of prediction sets. We formulate HCC as a constrained optimization problem whose solutions yield prediction sets composed of nodes at different levels of the hierarchy, while maintaining coverage guarantees. To address the combinatorial nature of the problem, we formally show that a much smaller, well-structured subset of candidate solutions suffices to ensure coverage while upholding optimality. An empirical evaluation on three new benchmarks consisting of audio, image, and text data highlights the advantages of our approach, and a user study shows that annotators significantly prefer hierarchical over flat prediction sets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Hierarchical Conformal Classification (HCC)ï¼Œè¿™æ˜¯å¯¹ Conformal prediction (CP) æ¡†æ¶çš„æ‰©å±•ï¼Œæ—¨åœ¨å°†ç±»åˆ«é—´çš„å±‚æ¬¡ç»“æ„å’Œè¯­ä¹‰å…³ç³»èå…¥ä¸ç¡®å®šæ€§é‡åŒ–è¿‡ç¨‹ä¸­ã€‚ä¸ºäº†å…‹æœæ ‡å‡† CP å¿½ç•¥ç±»åˆ«å…³è”æ€§çš„å±€é™ï¼ŒHCC å°†é¢„æµ‹é›†çš„ç”Ÿæˆå»ºæ¨¡ä¸ºå—çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ï¼Œä½¿å…¶èƒ½å¤Ÿäº§å‡ºåŒ…å«å±‚æ¬¡ç»“æ„ä¸­ä¸åŒå±‚çº§èŠ‚ç‚¹çš„é¢„æµ‹é›†ï¼Œå¹¶åŒæ—¶ä¸¥æ ¼ç»´æŒè¦†ç›–ä¿è¯ (coverage guarantees)ã€‚é’ˆå¯¹è¯¥é—®é¢˜çš„ç»„åˆå¤æ‚æ€§ï¼Œç ”ç©¶ä»ç†è®ºä¸Šè¯æ˜äº†é€šè¿‡ç­›é€‰ä¸€å°éƒ¨åˆ†ç»“æ„è‰¯å¥½çš„å€™é€‰è§£å­é›†å³å¯åœ¨ç¡®ä¿æœ€ä¼˜æ€§çš„åŒæ—¶æ»¡è¶³è¦†ç›–è¦æ±‚ã€‚åœ¨éŸ³é¢‘ã€å›¾åƒå’Œæ–‡æœ¬è·¨é¢†åŸŸæ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°å±•ç¤ºäº†è¯¥æ–¹æ³•çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œç”¨æˆ·è°ƒæŸ¥ç»“æœè¡¨æ˜ï¼Œç›¸æ¯”äºä¼ ç»Ÿçš„æ‰å¹³åŒ–é¢„æµ‹é›†ï¼Œæ ‡æ³¨è€…æ˜æ˜¾æ›´é’ç HCC æä¾›çš„å…·æœ‰ç»“æ„åŒ–ä¿¡æ¯çš„å±‚æ¬¡åŒ–é¢„æµ‹ç»“æœã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13288v1",
      "published_date": "2025-08-18 18:05:55 UTC",
      "updated_date": "2025-08-18 18:05:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:03.563672+00:00"
    },
    {
      "arxiv_id": "2508.13152v1",
      "title": "RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns",
      "title_zh": "RepreGuardï¼šé€šè¿‡æ­ç¤ºéšè—è¡¨å¾æ¨¡å¼æ£€æµ‹å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬",
      "authors": [
        "Xin Chen",
        "Junchao Wu",
        "Shu Yang",
        "Runzhe Zhan",
        "Zeyu Wu",
        "Ziyang Luo",
        "Di Wang",
        "Min Yang",
        "Lidia S. Chao",
        "Derek F. Wong"
      ],
      "abstract": "Detecting content generated by large language models (LLMs) is crucial for preventing misuse and building trustworthy AI systems. Although existing detection methods perform well, their robustness in out-of-distribution (OOD) scenarios is still lacking. In this paper, we hypothesize that, compared to features used by existing detection methods, the internal representations of LLMs contain more comprehensive and raw features that can more effectively capture and distinguish the statistical pattern differences between LLM-generated texts (LGT) and human-written texts (HWT). We validated this hypothesis across different LLMs and observed significant differences in neural activation patterns when processing these two types of texts. Based on this, we propose RepreGuard, an efficient statistics-based detection method. Specifically, we first employ a surrogate model to collect representation of LGT and HWT, and extract the distinct activation feature that can better identify LGT. We can classify the text by calculating the projection score of the text representations along this feature direction and comparing with a precomputed threshold. Experimental results show that RepreGuard outperforms all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD scenarios, while also demonstrating robust resilience to various text sizes and mainstream attacks. Data and code are publicly available at: https://github.com/NLP2CT/RepreGuard",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬ï¼ˆLLM-generated texts, LGTï¼‰æ£€æµ‹åœ¨åˆ†å¸ƒå¤–ï¼ˆOODï¼‰åœºæ™¯ä¸‹é²æ£’æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†RepreGuardæ£€æµ‹æ–¹æ³•ã€‚ä½œè€…é€šè¿‡éªŒè¯å‘ç°ï¼ŒLLMçš„å†…éƒ¨è¡¨ç¤ºï¼ˆinternal representationsï¼‰æ¯”ç°æœ‰æ–¹æ³•é‡‡ç”¨çš„ç‰¹å¾æ›´èƒ½æœ‰æ•ˆæ•æ‰LGTä¸äººç±»ç¼–å†™æ–‡æœ¬ï¼ˆHWTï¼‰ä¹‹é—´çš„ç¥ç»æ¿€æ´»æ¨¡å¼å·®å¼‚ã€‚RepreGuardåˆ©ç”¨ä»£ç†æ¨¡å‹æå–å…·æœ‰è¾¨åˆ«åŠ›çš„æ¿€æ´»ç‰¹å¾ï¼Œå¹¶é€šè¿‡è®¡ç®—å¾…æµ‹æ–‡æœ¬è¡¨ç¤ºåœ¨è¯¥ç‰¹å¾æ–¹å‘ä¸Šçš„æŠ•å½±å¾—åˆ†ä¸é¢„è®¾é˜ˆå€¼è¿›è¡Œå¯¹æ¯”ï¼Œå®ç°é«˜æ•ˆçš„ç»Ÿè®¡å­¦æ£€æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRepreGuardåœ¨åˆ†å¸ƒå†…ï¼ˆIDï¼‰å’Œåˆ†å¸ƒå¤–åœºæ™¯ä¸‹çš„å¹³å‡AUROCè¾¾åˆ°94.92%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨åº”å¯¹ä¸åŒæ–‡æœ¬é•¿åº¦å’Œå„ç±»ä¸»æµæ”»å‡»æ—¶è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œä¸ºè¯†åˆ«AIç”Ÿæˆå†…å®¹å’Œæ„å»ºå¯é çš„AIç³»ç»Ÿæä¾›äº†æœ‰æ•ˆæ‰‹æ®µã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to TACL 2025. This version is a pre-MIT Press publication version",
      "pdf_url": "https://arxiv.org/pdf/2508.13152v1",
      "published_date": "2025-08-18 17:59:15 UTC",
      "updated_date": "2025-08-18 17:59:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:04.350790+00:00"
    },
    {
      "arxiv_id": "2508.13143v1",
      "title": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
      "title_zh": "æ¢ç´¢è‡ªä¸»æ™ºèƒ½ä½“ï¼šæ·±å…¥å‰–æä»»åŠ¡æ‰§è¡Œå¤±è´¥çš„åŸå› ",
      "authors": [
        "Ruofan Lu",
        "Yichen Li",
        "Yintong Huo"
      ],
      "abstract": "Autonomous agent systems powered by Large Language Models (LLMs) have demonstrated promising capabilities in automating complex tasks. However, current evaluations largely rely on success rates without systematically analyzing the interactions, communication mechanisms, and failure causes within these systems. To bridge this gap, we present a benchmark of 34 representative programmable tasks designed to rigorously assess autonomous agents. Using this benchmark, we evaluate three popular open-source agent frameworks combined with two LLM backbones, observing a task completion rate of approximately 50%. Through in-depth failure analysis, we develop a three-tier taxonomy of failure causes aligned with task phases, highlighting planning errors, task execution issues, and incorrect response generation. Based on these insights, we propose actionable improvements to enhance agent planning and self-diagnosis capabilities. Our failure taxonomy, together with mitigation advice, provides an empirical foundation for developing more robust and effective autonomous agent systems in the future.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„è‡ªä¸»æ™ºèƒ½ä½“(Autonomous agents)ç³»ç»Ÿåœ¨ä»»åŠ¡æ‰§è¡Œä¸­å¤±è´¥çš„å…·ä½“åŸå› ã€‚ä¸ºäº†å¼¥è¡¥ç°æœ‰è¯„ä¼°ä»…å…³æ³¨æˆåŠŸç‡çš„ä¸è¶³ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªåŒ…å«34ä¸ªä»£è¡¨æ€§å¯ç¼–ç¨‹ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ã€‚é€šè¿‡å¯¹ä¸‰ç§ä¸»æµå¼€æºæ™ºèƒ½ä½“æ¡†æ¶ä¸ä¸¤ç§LLMä¸»å¹²ç½‘ç»œçš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°å¹³å‡ä»»åŠ¡å®Œæˆç‡ä»…çº¦ä¸º50%ã€‚é€šè¿‡ç»†è‡´çš„å¤±æ•ˆåˆ†æï¼Œç ”ç©¶æ„å»ºäº†ä¸€ä¸ªæ¶µç›–è§„åˆ’(Planning)é”™è¯¯ã€ä»»åŠ¡æ‰§è¡Œé—®é¢˜åŠé”™è¯¯å“åº”ç”Ÿæˆçš„ä¸‰å±‚å¤±è´¥åˆ†ç±»æ³•(Taxonomy)ã€‚åŸºäºè¿™äº›è§è§£ï¼Œä½œè€…æå‡ºäº†å¢å¼ºæ™ºèƒ½ä½“è§„åˆ’å’Œè‡ªæˆ‘è¯Šæ–­(Self-diagnosis)èƒ½åŠ›çš„æ”¹è¿›å»ºè®®ã€‚è¯¥é¡¹å·¥ä½œä¸ºæœªæ¥æ„å»ºæ›´å…·é²æ£’æ€§å’Œæ•ˆèƒ½çš„è‡ªä¸»æ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†é‡è¦çš„å®è¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ASE 2025 NIER",
      "pdf_url": "https://arxiv.org/pdf/2508.13143v1",
      "published_date": "2025-08-18 17:55:22 UTC",
      "updated_date": "2025-08-18 17:55:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:15.558174+00:00"
    },
    {
      "arxiv_id": "2508.13124v1",
      "title": "Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries",
      "title_zh": "Spot the BlindSpotsï¼šå‘¼å«ä¸­å¿ƒæ‘˜è¦ä¸­ç»†ç²’åº¦å¤§è¯­è¨€æ¨¡å‹åè§çš„ç³»ç»Ÿæ€§è¯†åˆ«ä¸é‡åŒ–",
      "authors": [
        "Kawin Mayilvaghanan",
        "Siddhant Gupta",
        "Ayush Kumar"
      ],
      "abstract": "Abstractive summarization is a core application in contact centers, where Large Language Models (LLMs) generate millions of summaries of call transcripts daily. Despite their apparent quality, it remains unclear whether LLMs systematically under- or over-attend to specific aspects of the transcript, potentially introducing biases in the generated summary. While prior work has examined social and positional biases, the specific forms of bias pertinent to contact center operations - which we term Operational Bias - have remained unexplored. To address this gap, we introduce BlindSpot, a framework built upon a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic) for the identification and quantification of these biases. BlindSpot leverages an LLM as a zero-shot classifier to derive categorical distributions for each bias dimension in a pair of transcript and its summary. The bias is then quantified using two metrics: Fidelity Gap (the JS Divergence between distributions) and Coverage (the percentage of source labels omitted). Using BlindSpot, we conducted an empirical study with 2500 real call transcripts and their summaries generated by 20 LLMs of varying scales and families (e.g., GPT, Llama, Claude). Our analysis reveals that biases are systemic and present across all evaluated models, regardless of size or family.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å‘¼å«ä¸­å¿ƒè‡ªåŠ¨æ‘˜è¦ç”Ÿæˆä¸­çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åå·®é—®é¢˜ï¼Œé¦–æ¬¡æå‡ºäº† Operational Bias çš„æ¦‚å¿µå¹¶å¼€å‘äº†åä¸º BlindSpot çš„è¯„ä¼°æ¡†æ¶ã€‚BlindSpot åŸºäºæ¶µç›– 15 ä¸ªæ“ä½œç»´åº¦ï¼ˆå¦‚ disfluency, speaker, topic ç­‰ï¼‰çš„åˆ†ç±»ä½“ç³»ï¼Œåˆ©ç”¨ LLM ä½œä¸º zero-shot classifier æ¥æå–è½¬å½•æ–‡æœ¬ä¸å…¶æ‘˜è¦çš„ç±»åˆ«åˆ†å¸ƒã€‚ç ”ç©¶é€šè¿‡ Fidelity Gapï¼ˆåŸºäº JS Divergence è¡¡é‡åˆ†å¸ƒå·®å¼‚ï¼‰å’Œ Coverageï¼ˆè¡¡é‡æºæ–‡æœ¬æ ‡ç­¾é—æ¼ç‡ï¼‰ä¸¤ä¸ªæ ¸å¿ƒæŒ‡æ ‡å®ç°åå·®çš„é‡åŒ–åˆ†æã€‚åŸºäº 2500 ä»½çœŸå®å‘¼å«è½¬å½•åŠ 20 ç§ä¸åŒè§„æ¨¡ä¸ç³»åˆ—ï¼ˆå¦‚ GPT, Llama, Claudeï¼‰LLM çš„å®è¯ç ”ç©¶è¡¨æ˜ï¼Œæ­¤ç±»åå·®åœ¨æ‰€æœ‰è¯„ä¼°æ¨¡å‹ä¸­å‡ç³»ç»Ÿæ€§å­˜åœ¨ï¼Œä¸”ä¸å—æ¨¡å‹å¤§å°æˆ–æ¶æ„çš„å½±å“ã€‚è¯¥æˆæœä¸ºç³»ç»Ÿæ€§è¯†åˆ«å’Œå‡å°‘ç‰¹å®šé¢†åŸŸæ‘˜è¦ä»»åŠ¡ä¸­çš„ç»†ç²’åº¦åå·®æä¾›äº†å…³é”®çš„è¯„ä¼°å·¥å…·å’Œå®è¯è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13124v1",
      "published_date": "2025-08-18 17:31:03 UTC",
      "updated_date": "2025-08-18 17:31:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:15.753687+00:00"
    },
    {
      "arxiv_id": "2508.13121v1",
      "title": "Bayesian Optimization-based Search for Agent Control in Automated Game Testing",
      "title_zh": "è‡ªåŠ¨åŒ–æ¸¸æˆæµ‹è¯•ä¸­åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„æ™ºèƒ½ä½“æ§åˆ¶æœç´¢",
      "authors": [
        "Carlos Celemin"
      ],
      "abstract": "This work introduces an automated testing approach that employs agents controlling game characters to detect potential bugs within a game level. Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient search, the method determines the next sampling point by analyzing the data collected so far and calculates the data point that will maximize information acquisition. To support the BO process, we introduce a game testing-specific model built on top of a grid map, that features the smoothness and uncertainty estimation required by BO, however and most importantly, it does not suffer the scalability issues that traditional models carry. The experiments demonstrate that the approach significantly improves map coverage capabilities in both time efficiency and exploration distribution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè´å¶æ–¯ä¼˜åŒ–(Bayesian Optimization, BO)çš„è‡ªåŠ¨åŒ–æ¸¸æˆæµ‹è¯•æ–¹æ³•ï¼Œé€šè¿‡æ§åˆ¶æ¸¸æˆè§’è‰²æ™ºèƒ½ä½“åœ¨å…³å¡ä¸­é«˜æ•ˆæ¢æµ‹æ½œåœ¨æ¼æ´ã€‚è¯¥æ–¹æ³•åˆ©ç”¨BOå¼ºå¤§çš„æ ·æœ¬æ•ˆç‡æœç´¢èƒ½åŠ›ï¼Œé€šè¿‡åˆ†æå·²æ”¶é›†æ•°æ®æ¥ç¡®å®šä¸‹ä¸€ä¸ªé‡‡æ ·ç‚¹ï¼Œä»è€Œå®ç°ä¿¡æ¯è·å–çš„æœ€å¤§åŒ–ã€‚ä¸ºäº†æœ‰æ•ˆæ”¯æŒBOè¿‡ç¨‹ï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†ä¸€ç§æ„å»ºåœ¨ç½‘æ ¼å›¾(grid map)ä¹‹ä¸Šçš„ä¸“ç”¨æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸ä»…å…·å¤‡BOæ‰€éœ€çš„å¹³æ»‘åº¦å’Œä¸ç¡®å®šæ€§ä¼°è®¡ç‰¹æ€§ï¼Œè¿˜è§£å†³äº†ä¼ ç»Ÿæ¨¡å‹å¸¸è§çš„æ‰©å±•æ€§(scalability)é—®é¢˜ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ—¶é—´æ•ˆç‡å’Œæ¢ç´¢åˆ†å¸ƒæ–¹é¢å‡æ˜¾è‘—æå‡äº†åœ°å›¾è¦†ç›–(map coverage)èƒ½åŠ›ã€‚è¿™ä¸€ç ”ç©¶ä¸ºè‡ªåŠ¨åŒ–æ¸¸æˆæµ‹è¯•ä¸­çš„æ™ºèƒ½ä½“æ§åˆ¶å’Œé«˜æ•ˆåœºæ™¯æ¢ç´¢æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13121v1",
      "published_date": "2025-08-18 17:24:46 UTC",
      "updated_date": "2025-08-18 17:24:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:16.450528+00:00"
    },
    {
      "arxiv_id": "2508.13113v2",
      "title": "Contrastive Representations for Temporal Reasoning",
      "title_zh": "é¢å‘æ—¶é—´æ¨ç†çš„å¯¹æ¯”è¡¨ç¤º",
      "authors": [
        "Alicja Ziarko",
        "Michal Bortkiewicz",
        "Michal Zawalski",
        "Benjamin Eysenbach",
        "Piotr Milos"
      ],
      "abstract": "In classical AI, perception relies on learning state-based representations, while planning, which can be thought of as temporal reasoning over action sequences, is typically achieved through search. We study whether such reasoning can instead emerge from representations that capture both perceptual and temporal structure. We show that standard temporal contrastive learning, despite its popularity, often fails to capture temporal structure due to its reliance on spurious features. To address this, we introduce Combinatorial Representations for Temporal Reasoning (CRTR), a method that uses a negative sampling scheme to provably remove these spurious features and facilitate temporal reasoning. CRTR achieves strong results on domains with complex temporal structure, such as Sokoban and Rubik's Cube. In particular, for the Rubik's Cube, CRTR learns representations that generalize across all initial states and allow it to solve the puzzle using fewer search steps than BestFS, though with longer solutions. To our knowledge, this is the first method that efficiently solves arbitrary Cube states using only learned representations, without relying on an external search algorithm.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•è®©å­¦ä¹ åˆ°çš„è¡¨å¾åŒæ—¶æ•æ‰æ„ŸçŸ¥ä¸æ—¶é—´ç»“æ„ï¼Œä»¥å®ç°æ— éœ€å¤–éƒ¨æœç´¢çš„ Temporal Reasoningã€‚ä½œè€…æŒ‡å‡ºæ ‡å‡†çš„ Temporal Contrastive Learning å¾€å¾€å› ä¾èµ–ä¼ªç‰¹å¾ (spurious features) è€Œæ— æ³•æœ‰æ•ˆæ•æ‰æ—¶é—´ç»“æ„ï¼Œä¸ºæ­¤æå‡ºäº† CRTR (Combinatorial Representations for Temporal Reasoning) æ–¹æ³•ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ç§è´Ÿé‡‡æ ·æ–¹æ¡ˆï¼Œèƒ½å¤Ÿè¯æ˜åœ°ç§»é™¤è¿™äº›ä¼ªç‰¹å¾ï¼Œä»è€Œä¿ƒè¿›é«˜æ•ˆçš„æ—¶é—´æ¨ç†ã€‚åœ¨ Sokoban å’Œ Rubik's Cube ç­‰å¤æ‚é¢†åŸŸçš„å®éªŒè¡¨æ˜ï¼ŒCRTR å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚å°¤å…¶åœ¨ Rubik's Cube ä»»åŠ¡ä¸­ï¼ŒCRTR æ˜¯é¦–ä¸ªä»…ä¾é å­¦ä¹ åˆ°çš„è¡¨å¾è€Œéå¤–éƒ¨æœç´¢ç®—æ³•å°±èƒ½é«˜æ•ˆè§£å†³ä»»æ„åˆå§‹çŠ¶æ€çš„æ–¹æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºå…¶æœç´¢æ­¥éª¤å°‘äº BestFSï¼Œå°½ç®¡è§£æ³•è·¯å¾„è¾ƒé•¿ï¼Œä½†ä¸ºå¤æ‚é€»è¾‘è§„åˆ’ä»»åŠ¡æä¾›äº†å…¨æ–°çš„è¡¨å¾å­¦ä¹ èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025, Project website: https://princeton-rl.github.io/CRTR/",
      "pdf_url": "https://arxiv.org/pdf/2508.13113v2",
      "published_date": "2025-08-18 17:20:08 UTC",
      "updated_date": "2025-09-29 14:34:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:29.683347+00:00"
    },
    {
      "arxiv_id": "2508.13092v3",
      "title": "VerilogLAVD: LLM-Aided Rule Generation for Vulnerability Detection in Verilog",
      "title_zh": "VerilogLAVDï¼šå¤§è¯­è¨€æ¨¡å‹è¾…åŠ©çš„ Verilog æ¼æ´æ£€æµ‹è§„åˆ™ç”Ÿæˆ",
      "authors": [
        "Xiang Long",
        "Yingjie Xia",
        "Xiyuan Chen",
        "Li Kuang"
      ],
      "abstract": "Timely detection of hardware vulnerabilities during the early design stage is critical for reducing remediation costs. Existing early detection techniques often require specialized security expertise, limiting their usability. Recent efforts have explored the use of large language models (LLMs) for Verilog vulnerability detection. However, LLMs struggle to capture the structure in Verilog code, resulting in inconsistent detection results. To this end, we propose VerilogLAVD, the first LLM-aided graph traversal rule generation approach for Verilog vulnerability detection. Our approach introduces the Verilog Property Graph (VeriPG), a unified representation of Verilog code. It combines syntactic features extracted from the abstract syntax tree (AST) with semantic information derived from control flow and data dependency graphs. We leverage LLMs to generate VeriPG-based detection rules from Common Weakness Enumeration (CWE) descriptions. These rules guide the rule executor that traversal VeriPG for potential vulnerabilities. To evaluate VerilogLAVD, we build a dataset collected from open-source repositories and synthesized data. In our empirical evaluation on 77 Verilog designs encompassing 12 CWE types, VerilogLAVD achieves an F1-score of 0.54. Compared to the LLM-only and LLM with external knowledge baselines, VerilogLAVD improves F1-score by 0.31 and 0.27, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VerilogLAVDï¼Œè¿™æ˜¯é¦–ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)è¾…åŠ©ç”Ÿæˆå›¾éå†è§„åˆ™çš„Verilogæ¼æ´æ£€æµ‹æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ—©æœŸç¡¬ä»¶è®¾è®¡ä¸­æ¼æ´æ£€æµ‹é—¨æ§›é«˜åŠLLMséš¾ä»¥æ•æ‰ä»£ç ç»“æ„çš„é—®é¢˜ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†Verilog Property Graph (VeriPG)ï¼Œè¿™æ˜¯ä¸€ç§ç»Ÿä¸€çš„ä»£ç è¡¨ç¤ºå½¢å¼ï¼Œé€šè¿‡ç»“åˆæŠ½è±¡è¯­æ³•æ ‘(AST)çš„è¯­æ³•ç‰¹å¾ä»¥åŠæ§åˆ¶æµå’Œæ•°æ®ä¾èµ–å›¾çš„è¯­ä¹‰ä¿¡æ¯æ¥å¢å¼ºåˆ†æèƒ½åŠ›ã€‚ç³»ç»Ÿåˆ©ç”¨LLMså°†å¸¸è§å¼±ç‚¹æšä¸¾(CWE)æè¿°è½¬åŒ–ä¸ºåŸºäºVeriPGçš„æ£€æµ‹è§„åˆ™ï¼Œå¹¶ç”±ä¸“é—¨çš„è§„åˆ™æ‰§è¡Œå™¨é€šè¿‡éå†å›¾ç»“æ„æ¥è¯†åˆ«æ½œåœ¨æ¼æ´ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œåœ¨åŒ…å«12ç§CWEç±»å‹çš„77ä¸ªVerilogè®¾è®¡æ•°æ®é›†ä¸Šï¼ŒVerilogLAVDå®ç°äº†0.54çš„F1-scoreã€‚ä¸çº¯LLMåŸºçº¿å’Œç»“åˆå¤–éƒ¨çŸ¥è¯†çš„LLMæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆçš„F1-scoreåˆ†åˆ«æå‡äº†0.31å’Œ0.27ï¼Œæ˜¾è‘—è¯æ˜äº†å…¶åœ¨ç¡¬ä»¶å®‰å…¨è‡ªåŠ¨åŒ–æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13092v3",
      "published_date": "2025-08-18 17:05:18 UTC",
      "updated_date": "2025-08-21 16:07:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:26.690581+00:00"
    },
    {
      "arxiv_id": "2508.13077v1",
      "title": "From Transthoracic to Transesophageal: Cross-Modality Generation using LoRA Diffusion",
      "title_zh": "ä»ç»èƒ¸åˆ°ç»é£Ÿç®¡ï¼šåŸºäº LoRA æ‰©æ•£æ¨¡å‹çš„è·¨æ¨¡æ€ç”Ÿæˆ",
      "authors": [
        "Emmanuel Oladokun",
        "Yuxuan Ou",
        "Anna Novikova",
        "Daria Kulikova",
        "Sarina Thomas",
        "Jurica Å prem",
        "Vicente Grau"
      ],
      "abstract": "Deep diffusion models excel at realistic image synthesis but demand large training sets-an obstacle in data-scarce domains like transesophageal echocardiography (TEE). While synthetic augmentation has boosted performance in transthoracic echo (TTE), TEE remains critically underrepresented, limiting the reach of deep learning in this high-impact modality.\n  We address this gap by adapting a TTE-trained, mask-conditioned diffusion backbone to TEE with only a limited number of new cases and adapters as small as $10^5$ parameters. Our pipeline combines Low-Rank Adaptation with MaskR$^2$, a lightweight remapping layer that aligns novel mask formats with the pretrained model's conditioning channels. This design lets users adapt models to new datasets with a different set of anatomical structures to the base model's original set.\n  Through a targeted adaptation strategy, we find that adapting only MLP layers suffices for high-fidelity TEE synthesis. Finally, mixing less than 200 real TEE frames with our synthetic echoes improves the dice score on a multiclass segmentation task, particularly boosting performance on underrepresented right-heart structures. Our results demonstrate that (1) semantically controlled TEE images can be generated with low overhead, (2) MaskR$^2$ effectively transforms unseen mask formats into compatible formats without damaging downstream task performance, and (3) our method generates images that are effective for improving performance on a downstream task of multiclass segmentation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç»é£Ÿç®¡è¶…å£°å¿ƒåŠ¨å›¾(TEE)æ•°æ®ç¨€ç¼ºé™åˆ¶æ·±åº¦å­¦ä¹ åº”ç”¨çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºLoRA Diffusionçš„è·¨æ¨¡æ€ç”Ÿæˆæ¡†æ¶ã€‚é€šè¿‡å°†é¢„è®­ç»ƒçš„ç»èƒ¸è¶…å£°å¿ƒåŠ¨å›¾(TTE)æ©ç æ¡ä»¶æ‰©æ•£æ¨¡å‹(mask-conditioned diffusion backbone)é€‚é…åˆ°TEEé¢†åŸŸï¼Œè¯¥æ–¹æ³•ä»…éœ€æå°‘é‡çš„ç—…ä¾‹æ•°æ®å’Œçº¦10^5æ•°é‡çº§çš„å‚æ•°ã€‚ç ”ç©¶å¼•å…¥äº†è½»é‡çº§é‡æ˜ å°„å±‚MaskR$^2$ï¼Œæœ‰æ•ˆè§£å†³äº†ä¸åŒè§£å‰–ç»“æ„æ©ç æ ¼å¼çš„å¯¹é½é—®é¢˜ï¼Œå¹¶å‘ç°ä»…éœ€é€‚é…MLPå±‚å³å¯å®ç°é«˜ä¿çœŸçš„TEEå›¾åƒåˆæˆã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æµæ°´çº¿èƒ½å¤Ÿä»¥æä½å¼€é”€ç”Ÿæˆè¯­ä¹‰å¯æ§çš„TEEå›¾åƒï¼Œå¹¶é€šè¿‡æ•°æ®å¢å¼ºæ˜¾è‘—æå‡äº†ä¸‹æ¸¸å¤šç±»åˆ«åˆ†å‰²(multiclass segmentation)ä»»åŠ¡çš„Dice Scoreã€‚è¯¥æ–¹æ³•å°¤å…¶æ”¹å–„äº†åœ¨å³å¿ƒç»“æ„ç­‰ä»£è¡¨æ€§ä¸è¶³ç±»åˆ«ä¸Šçš„æ€§èƒ½ï¼Œå±•ç¤ºäº†ç”Ÿæˆå¼æ¨¡å‹åœ¨è§£å†³åŒ»å­¦å½±åƒæ•°æ®ç¨€ç¼ºé—®é¢˜ä¸Šçš„æ½œåŠ›ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "MICCAI 2025; ASMUS",
      "pdf_url": "https://arxiv.org/pdf/2508.13077v1",
      "published_date": "2025-08-18 16:48:53 UTC",
      "updated_date": "2025-08-18 16:48:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:33.696381+00:00"
    },
    {
      "arxiv_id": "2508.13072v1",
      "title": "A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis",
      "title_zh": "é¢å‘å¤šä»»åŠ¡å¿ƒè„åˆ†æçš„è¯­è¨€-ä¿¡å·-è§†è§‰å¤šæ¨¡æ€æ¡†æ¶",
      "authors": [
        "Yuting Zhang",
        "Tiantian Geng",
        "Luoying Hao",
        "Xinxing Cheng",
        "Alexander Thorley",
        "Xiaoxia Wang",
        "Wenqi Lu",
        "Sandeep S Hothi",
        "Lei Wei",
        "Zhaowen Qiu",
        "Dipak Kotecha",
        "Jinming Duan"
      ],
      "abstract": "Contemporary cardiovascular management involves complex consideration and integration of multimodal cardiac datasets, where each modality provides distinct but complementary physiological characteristics. While the effective integration of multiple modalities could yield a holistic clinical profile that accurately models the true clinical situation with respect to data modalities and their relatives weightings, current methodologies remain limited by: 1) the scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated single-modality or rigid multimodal input combinations; 3) alignment strategies that prioritize cross-modal similarity over complementarity; and 4) a narrow single-task focus. In response to these limitations, a comprehensive multimodal dataset was curated for immediate application, integrating laboratory test results, electrocardiograms, and echocardiograms with clinical outcomes. Subsequently, a unified framework, Textual Guidance Multimodal fusion for Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key components: 1) a MedFlexFusion module designed to capture the unique and complementary characteristics of medical modalities and dynamically integrate data from diverse cardiac sources and their combinations; 2) a textual guidance module to derive task-relevant representations tailored to diverse clinical objectives, including heart disease diagnosis, risk stratification and information retrieval; and 3) a response module to produce final decisions for all these tasks. Furthermore, this study systematically explored key features across multiple modalities and elucidated their synergistic contributions in clinical decision-making. Extensive experiments showed that TGMM outperformed state-of-the-art methods across multiple clinical tasks, with additional validation confirming its robustness on another public dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåä¸ºTGMMï¼ˆTextual Guidance Multimodal fusion for Multiple cardiac tasksï¼‰çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¿ƒè¡€ç®¡ç®¡ç†ä¸­å¤šæ¨¡æ€æ•°æ®æ•´åˆé¢ä¸´çš„æ•°æ®ç¨€ç¼ºã€è¾“å…¥ç»„åˆåƒµåŒ–ä»¥åŠå•ä»»åŠ¡å±€é™ç­‰æŒ‘æˆ˜ã€‚TGMMåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šMedFlexFusionæ¨¡å—ç”¨äºæ•æ‰å®éªŒå®¤æ£€æŸ¥ã€å¿ƒç”µå›¾(electrocardiograms)å’Œè¶…å£°å¿ƒåŠ¨å›¾(echocardiograms)ç­‰åŒ»å­¦æ¨¡æ€çš„ç‹¬ç‰¹äº’è¡¥ç‰¹å¾ï¼›æ–‡æœ¬å¼•å¯¼æ¨¡å—(textual guidance module)æ ¹æ®å¿ƒè„ç—…è¯Šæ–­ã€é£é™©åˆ†å±‚å’Œä¿¡æ¯æ£€ç´¢ç­‰ä¸åŒä¸´åºŠç›®æ ‡ç”Ÿæˆç‰¹å®šä»»åŠ¡è¡¨ç¤ºï¼›ä»¥åŠå“åº”æ¨¡å—è´Ÿè´£è¾“å‡ºæœ€ç»ˆå†³ç­–ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜æ„å»ºäº†ä¸€ä¸ªæ•´åˆä¸´åºŠç»“æœçš„å…¨é¢å¤šæ¨¡æ€æ•°æ®é›†ï¼Œå¹¶ç³»ç»Ÿæ¢è®¨äº†å¤šæ¨¡æ€ç‰¹å¾åœ¨ä¸´åºŠå†³ç­–ä¸­çš„ååŒè´¡çŒ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTGMMåœ¨å¤šé¡¹ä¸´åºŠä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰çš„state-of-the-artæ–¹æ³•ï¼Œå¹¶åœ¨å…¶ä»–å…¬å¼€æ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶ç¨³å¥æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13072v1",
      "published_date": "2025-08-18 16:43:31 UTC",
      "updated_date": "2025-08-18 16:43:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:37.885897+00:00"
    },
    {
      "arxiv_id": "2508.13070v1",
      "title": "Reinforced Context Order Recovery for Adaptive Reasoning and Planning",
      "title_zh": "é¢å‘è‡ªé€‚åº”æ¨ç†ä¸è§„åˆ’çš„å¼ºåŒ–ä¸Šä¸‹æ–‡é¡ºåºæ¢å¤",
      "authors": [
        "Long Ma",
        "Fangwei Zhong",
        "Yizhou Wang"
      ],
      "abstract": "Modern causal language models, followed by rapid developments in discrete diffusion models, can now produce a wide variety of interesting and useful content. However, these families of models are predominantly trained to output tokens with a fixed (left-to-right) or random order, which may deviate from the logical order in which tokens are generated originally. In this paper, we observe that current causal and diffusion models encounter difficulties in problems that require adaptive token generation orders to solve tractably, which we characterize with the $\\mathcal{V}$-information framework. Motivated by this, we propose Reinforced Context Order Recovery (ReCOR), a reinforcement-learning-based framework to extract adaptive, data-dependent token generation orders from text data without annotations. Self-supervised by token prediction statistics, ReCOR estimates the hardness of predicting every unfilled token and adaptively selects the next token during both training and inference. Experiments on challenging reasoning and planning datasets demonstrate the superior performance of ReCOR compared with baselines, sometimes outperforming oracle models supervised with the ground-truth order.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å› æœè¯­è¨€æ¨¡å‹(Causal Language Models)å’Œæ‰©æ•£æ¨¡å‹(Diffusion Models)åœ¨å¤„ç†æ¨ç†ä¸è§„åˆ’ä»»åŠ¡æ—¶ï¼Œå—é™äºå›ºå®šæˆ–éšæœºç”Ÿæˆé¡ºåºè€Œéš¾ä»¥å¤„ç†å¤æ‚é€»è¾‘çš„é—®é¢˜ã€‚åŸºäº$\\mathcal{V}$-informationæ¡†æ¶çš„ç†è®ºåˆ†æï¼Œä½œè€…æå‡ºäº†Reinforced Context Order Recovery (ReCOR) æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä»æ— æ ‡æ³¨æ–‡æœ¬ä¸­æå–è‡ªé€‚åº”ã€æ•°æ®é©±åŠ¨çš„Tokenç”Ÿæˆé¡ºåºçš„æ–¹æ³•ã€‚è¯¥æ¡†æ¶é€šè¿‡Tokené¢„æµ‹ç»Ÿè®¡é‡è¯„ä¼°æ¯ä¸ªæœªå¡«å……ä½ç½®çš„é¢„æµ‹éš¾åº¦ï¼Œå¹¶åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€é€‰æ‹©ä¸‹ä¸€ä¸ªç”Ÿæˆçš„Tokenã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†å’Œè§„åˆ’æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒReCOR çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œéƒ¨åˆ†æŒ‡æ ‡ç”šè‡³è¶…è¶Šäº†ç”±çœŸå®ç”Ÿæˆé¡ºåºç›‘ç£çš„ Oracle æ¨¡å‹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13070v1",
      "published_date": "2025-08-18 16:42:55 UTC",
      "updated_date": "2025-08-18 16:42:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:30:55.793269+00:00"
    },
    {
      "arxiv_id": "2508.13257v1",
      "title": "ViTAD: Timing Violation-Aware Debugging of RTL Code using Large Language Models",
      "title_zh": "ViTADï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ—¶åºè¿ä¾‹æ„ŸçŸ¥ RTL ä»£ç è°ƒè¯•",
      "authors": [
        "Wenhao Lv",
        "Yingjie Xia",
        "Xiyuan Chen",
        "Li Kuang"
      ],
      "abstract": "In modern Very Large Scale Integrated (VLSI) circuit design flow, the Register-Transfer Level (RTL) stage presents a critical opportunity for timing optimization. Addressing timing violations at this early stage is essential, as modern systems demand higher speeds, where even minor timing violations can lead to functional failures or system crashes. However, traditional timing optimization heavily relies on manual expertise, requiring engineers to iteratively analyze timing reports and debug. To automate this process, this paper proposes ViTAD, a method that efficiently analyzes the root causes of timing violations and dynamically generates targeted repair strategies. Specifically, we first parse Verilog code and timing reports to construct a Signal Timing Dependency Graph (STDG). Based on the STDG, we perform violation path analysis and use large language models (LLMs) to infer the root causes of violations. Finally, by analyzing the causes of violations, we selectively retrieve relevant debugging knowledge from a domain-specific knowledge base to generate customized repair solutions. To evaluate the effectiveness of our method, we construct a timing violation dataset based on real-world open-source projects. This dataset contains 54 cases of violations. Experimental results show that our method achieves a 73.68% success rate in repairing timing violations, while the baseline using only LLM is 54.38%. Our method improves the success rate by 19.30%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¶…å¤§è§„æ¨¡é›†æˆç”µè·¯(VLSI)è®¾è®¡ä¸­å¯„å­˜å™¨ä¼ è¾“çº§(RTL)çš„æ—¶åºä¼˜åŒ–æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºViTADçš„è‡ªåŠ¨åŒ–è°ƒè¯•æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ‰‹åŠ¨åˆ†ææ—¶åºæŠ¥å‘Šæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡è§£æVerilogä»£ç å’Œæ—¶åºæŠ¥å‘Šæ„å»ºä¿¡å·æ—¶åºä¾èµ–å›¾(STDG)ï¼Œå¹¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)åˆ†æè¿ä¾‹è·¯å¾„ä»¥æ¨æ–­å…¶æ ¹æœ¬åŸå› ã€‚éšåï¼ŒViTADä»é¢†åŸŸç‰¹å®šçŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çš„è°ƒè¯•çŸ¥è¯†ï¼Œä»è€Œç”Ÿæˆå®šåˆ¶åŒ–çš„ä¿®å¤æ–¹æ¡ˆã€‚å®éªŒè¯„ä¼°é‡‡ç”¨åŸºäºçœŸå®å¼€æºé¡¹ç›®çš„æ—¶åºè¿ä¾‹æ•°æ®é›†ï¼Œç»“æœæ˜¾ç¤ºViTADçš„ä¿®å¤æˆåŠŸç‡è¾¾åˆ°73.68%ã€‚ç›¸æ¯”äºä»…ä½¿ç”¨LLMçš„åŸºçº¿æ–¹æ³•ï¼ŒViTADå°†æˆåŠŸç‡æå‡äº†19.30%ï¼Œæœ‰æ•ˆè¯æ˜äº†è¯¥æ–¹æ³•åœ¨RTLè‡ªåŠ¨åŒ–æ—¶åºä¿®å¤ä¸­çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13257v1",
      "published_date": "2025-08-18 16:41:32 UTC",
      "updated_date": "2025-08-18 16:41:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:10.897903+00:00"
    },
    {
      "arxiv_id": "2508.13057v6",
      "title": "Hierarchical Evaluation Function: A Multi-Metric Approach for Optimizing Demand Forecasting Models",
      "title_zh": "å±‚æ¬¡åŒ–è¯„ä¼°å‡½æ•°ï¼šä¸€ç§ä¼˜åŒ–éœ€æ±‚é¢„æµ‹æ¨¡å‹çš„å¤šæŒ‡æ ‡æ–¹æ³•",
      "authors": [
        "Adolfo GonzÃ¡lez",
        "VÃ­ctor Parada"
      ],
      "abstract": "Demand forecasting in competitive, uncertain business environments requires models that can integrate multiple evaluation perspectives rather than being restricted to hyperparameter optimization based on a single metric. This traditional approach tends to prioritize one error indicator, which can bias results when metrics provide contradictory signals. In this context, the Hierarchical Evaluation Function (HEF) is proposed as a multi-metric framework for hyperparameter optimization that integrates explanatory power (R2), sensitivity to extreme errors (RMSE), and average accuracy (MAE). The performance of HEF was assessed using four widely recognized benchmark datasets in the forecasting domain: Walmart, M3, M4, and M5. Prediction models were optimized through Grid Search, Particle Swarm Optimization (PSO), and Optuna, and statistical analyses based on difference-of-proportions tests confirmed that HEF delivers superior results compared to a unimetric reference function, regardless of the optimizer employed, with particular relevance for heterogeneous monthly time series (M3) and highly granular daily demand scenarios (M5). The findings demonstrate that HEF improves stability, generalization, and robustness at low computational cost, consolidating its role as a reliable evaluation framework that enhances model selection, enables more accurate demand forecasts, and supports decision-making in dynamic, competitive business environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Hierarchical Evaluation Function (HEF)ï¼Œä¸€ç§æ—¨åœ¨ä¼˜åŒ–éœ€æ±‚é¢„æµ‹æ¨¡å‹è¶…å‚æ•°çš„å¤šæŒ‡æ ‡è¯„ä¼°æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•ä¾èµ–å•ä¸€æŒ‡æ ‡å¯èƒ½å¯¼è‡´çš„é¢„æµ‹åå·®ï¼ŒHEF æ•´åˆäº†è§£é‡Šèƒ½åŠ› (R2)ã€æç«¯è¯¯å·®æ•æ„Ÿåº¦ (RMSE) å’Œå¹³å‡å‡†ç¡®åº¦ (MAE) ä¸‰ä¸ªç»´åº¦ã€‚å®éªŒåœ¨ Walmartã€M3ã€M4 å’Œ M5 ç­‰ä¸»æµé¢„æµ‹æ•°æ®é›†ä¸Šå±•å¼€ï¼Œå¹¶åº”ç”¨äº† Grid Searchã€Particle Swarm Optimization (PSO) åŠ Optuna ç­‰ä¼˜åŒ–ç®—æ³•è¿›è¡Œæ¨¡å‹è°ƒä¼˜ã€‚ç»Ÿè®¡åˆ†æç»“æœè¯å®ï¼ŒHEF åœ¨å„ç§ä¼˜åŒ–å™¨ä¸‹å‡è¡¨ç°å‡ºä¼˜äºå•ä¸€æŒ‡æ ‡å‚è€ƒå‡½æ•°çš„é¢„æµ‹æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç† M3 çš„å¼‚æ„æœˆåº¦æ—¶é—´åºåˆ—å’Œ M5 çš„é«˜ç²’åº¦æ¯æ—¥éœ€æ±‚åœºæ™¯æ—¶ä¼˜åŠ¿æ˜¾è‘—ã€‚è¯¥æ¡†æ¶åœ¨ä¿æŒä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œæœ‰æ•ˆæå‡äº†é¢„æµ‹æ¨¡å‹çš„ç¨³å®šæ€§ã€æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚è¿™ä¸€ç ”ç©¶ä¸ºç«äº‰æ€§å•†ä¸šç¯å¢ƒä¸‹çš„æ¨¡å‹é€‰æ‹©å’Œç²¾ç¡®éœ€æ±‚é¢„æµ‹æä¾›äº†å¯é çš„è¯„ä¼°ä½“ç³»ï¼Œæœ‰åŠ›æ”¯æŒäº†åŠ¨æ€å†³ç­–è¿‡ç¨‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 15 figures, 25 tables. Submitted as a preprint. The manuscript introduces the Hierarchical Evaluation Function, a multi-metric framework for optimizing demand forecasting models under high uncertainty. Includes extensive experimental validation using real-world datasets and a comparative analysis against classical and modern methods",
      "pdf_url": "https://arxiv.org/pdf/2508.13057v6",
      "published_date": "2025-08-18 16:25:49 UTC",
      "updated_date": "2025-12-20 00:56:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:05.986545+00:00"
    },
    {
      "arxiv_id": "2508.13256v2",
      "title": "CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support",
      "title_zh": "CardAIc-Agentsï¼šå…·æœ‰å±‚çº§è‡ªé€‚åº”èƒ½åŠ›çš„å¿ƒè„åŒ»ç–—æ”¯æŒå¤šæ¨¡æ€æ¡†æ¶",
      "authors": [
        "Yuting Zhang",
        "Karina V. Bunting",
        "Asgher Champsi",
        "Xiaoxia Wang",
        "Wenqi Lu",
        "Alexander Thorley",
        "Sandeep S Hothi",
        "Zhaowen Qiu",
        "Baturalp Buyukates",
        "Dipak Kotecha",
        "Jinming Duan"
      ],
      "abstract": "Cardiovascular diseases (CVDs) remain the foremost cause of mortality worldwide, a burden worsened by a severe deficit of healthcare workers. Artificial intelligence (AI) agents have shown potential to alleviate this gap through automated detection and proactive screening, yet their clinical application remains limited by: 1) rigid sequential workflows, whereas clinical care often requires adaptive reasoning that select specific tests and, based on their results, guides personalised next steps; 2) reliance solely on intrinsic model capabilities to perform role assignment without domain-specific tool support; 3) general and static knowledge bases without continuous learning capability; and 4) fixed unimodal or bimodal inputs and lack of on-demand visual outputs when clinicians require visual clarification. In response, a multimodal framework, CardAIc-Agents, was proposed to augment models with external tools and adaptively support diverse cardiac tasks. First, a CardiacRAG agent generated task-aware plans from updatable cardiac knowledge, while the Chief agent integrated tools to autonomously execute these plans and deliver decisions. Second, to enable adaptive and case-specific customization, a stepwise update strategy was developed to dynamically refine plans based on preceding execution results, once the task was assessed as complex. Third, a multidisciplinary discussion team was proposed which was automatically invoked to interpret challenging cases, thereby supporting further adaptation. In addition, visual review panels were provided to assist validation when clinicians raised concerns. Experiments across three datasets showed the efficiency of CardAIc-Agents compared to mainstream Vision-Language Models (VLMs) and state-of-the-art agentic systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CardAIc-Agentsï¼Œä¸€ä¸ªå…·æœ‰å±‚æ¬¡åŒ–é€‚åº”èƒ½åŠ›çš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¿ƒè¡€ç®¡ç–¾ç—…ï¼ˆCVDsï¼‰è¯Šç–—ä¸­AIæ™ºèƒ½ä½“é¢ä¸´çš„æµç¨‹åƒµåŒ–ã€ç¼ºä¹é¢†åŸŸå·¥å…·æ”¯æŒåŠçŸ¥è¯†åº“é™æ€ç­‰å±€é™ã€‚è¯¥æ¡†æ¶é€šè¿‡CardiacRAGæ™ºèƒ½ä½“åŸºäºå¯æ›´æ–°çš„å¿ƒè„çŸ¥è¯†ç”Ÿæˆä»»åŠ¡æ„ŸçŸ¥è®¡åˆ’ï¼Œå¹¶ç”±Chiefæ™ºèƒ½ä½“æ•´åˆå¤–éƒ¨å·¥å…·è‡ªä¸»æ‰§è¡Œä»»åŠ¡ã€‚é’ˆå¯¹å¤æ‚ç—…ä¾‹ï¼Œç³»ç»Ÿé‡‡ç”¨é€æ­¥æ›´æ–°ç­–ç•¥æ ¹æ®æ‰§è¡Œç»“æœåŠ¨æ€ç²¾ç‚¼è®¡åˆ’ï¼Œå¹¶èƒ½è‡ªåŠ¨è°ƒç”¨å¤šå­¦ç§‘è®¨è®ºå›¢é˜Ÿè¿›è¡Œæ·±åº¦è§£è¯»ã€‚æ­¤å¤–ï¼Œæ¡†æ¶è¿˜é›†æˆäº†è§†è§‰å®¡æŸ¥é¢æ¿ï¼Œä»¥ä¾¿ä¸´åºŠåŒ»ç”Ÿåœ¨éœ€è¦æ—¶è¿›è¡Œç›´è§‚éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCardAIc-Agentsåœ¨ä¸‰ä¸ªæƒå¨æ•°æ®é›†ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¸»æµè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åŠç°æœ‰çš„æœ€å…ˆè¿›æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸ºå®ç°è‡ªé€‚åº”å¿ƒè„æŠ¤ç†æ”¯æŒæä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13256v2",
      "published_date": "2025-08-18 16:17:12 UTC",
      "updated_date": "2025-12-23 04:17:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:16.187781+00:00"
    },
    {
      "arxiv_id": "2508.13049v1",
      "title": "XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads",
      "title_zh": "XR-NPEï¼šé¢å‘æ‰©å±•ç°å®æ„ŸçŸ¥è´Ÿè½½çš„é«˜ååæ··åˆç²¾åº¦ SIMD ç¥ç»å¤„ç†å¼•æ“",
      "authors": [
        "Tejas Chaudhari",
        "Akarsh J.",
        "Tanushree Dewangan",
        "Mukul Lokhande",
        "Santosh Kumar Vishvakarma"
      ],
      "abstract": "This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural Processing Engine, designed for extended reality (XR) perception workloads like visual inertial odometry (VIO), object classification, and eye gaze extraction. XR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1) formats, with layer adaptive hybrid-algorithmic implementation supporting ultra-low bit precision to significantly reduce memory bandwidth requirements, and accompanied by quantization-aware training for minimal accuracy loss. The proposed Reconfigurable Mantissa Multiplication and Exponent processing Circuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted by selective power gating to reduce energy consumption, providing 2.85x improved arithmetic intensity. XR-NPE achieves a maximum operating frequency of 1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm, reducing 42% area, 38% power compared to the best of state-of-the-art MAC approaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication co-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x better energy efficiency compared to SoTA accelerators on VCU129. The proposed co-processor provides 23% better energy efficiency and 4% better compute density for VIO workloads. XR-NPE establishes itself as a scalable, precision-adaptive compute engine for future resource-constrained XR devices. The complete set for codes for results reproducibility are released publicly, enabling designers and researchers to readily adopt and build upon them. https://github.com/mukullokhande99/XR-NPE.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† XR-NPEï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºæ‰©å±•ç°å® (Extended Reality, XR) æ„ŸçŸ¥å·¥ä½œè´Ÿè½½ï¼ˆå¦‚è§†è§‰æƒ¯æ€§é‡Œç¨‹è®¡ VIOã€å¯¹è±¡åˆ†ç±»å’Œçœ¼åŠ¨è¿½è¸ªï¼‰è®¾è®¡çš„é«˜ååé‡æ··åˆç²¾åº¦ SIMD ç¥ç»å¤„ç†å¼•æ“ã€‚è¯¥å¼•æ“é¦–æ¬¡æ”¯æŒ FP4ã€Posit (4,1)ã€Posit (8,0) å’Œ Posit (16,1) æ ¼å¼ï¼Œé€šè¿‡å±‚è‡ªé€‚åº”æ··åˆç®—æ³•å®ç°è¶…ä½ä½ç²¾åº¦ï¼Œå¹¶ç»“åˆé‡åŒ–æ„ŸçŸ¥è®­ç»ƒä»¥æ˜¾è‘—é™ä½å†…å­˜å¸¦å®½éœ€æ±‚ã€‚ç ”ç©¶å¼•å…¥äº†å¯é‡æ„å°¾æ•°ä¹˜æ³•å’ŒæŒ‡æ•°å¤„ç†ç”µè·¯ (RMMEC) ä»¥å‡å°‘ SIMD MAC è®¡ç®—å¼•æ“ä¸­çš„æš—ç¡…ï¼Œå¹¶åˆ©ç”¨é€‰æ‹©æ€§åŠŸç‡é—¨æ§æŠ€æœ¯å°†ç®—æœ¯å¼ºåº¦æå‡äº† 2.85 å€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ CMOS 28nm å·¥è‰ºä¸‹ï¼ŒXR-NPE ç›¸æ¯”ç°æœ‰æœ€å…ˆè¿›çš„ MAC æ–¹æ³•å‡å°‘äº† 42% çš„é¢ç§¯å’Œ 38% çš„åŠŸè€—ã€‚åœ¨ VCU129 å¹³å°ä¸Šçš„è¯„ä¼°è¿›ä¸€æ­¥è¯æ˜ï¼Œè¯¥åå¤„ç†å™¨åœ¨ VIO å·¥ä½œè´Ÿè½½ä¸­è¡¨ç°å‡ºæ›´å¥½çš„èƒ½é‡æ•ˆç‡å’Œè®¡ç®—å¯†åº¦ã€‚XR-NPE ä¸ºèµ„æºå—é™çš„æœªæ¥ XR è®¾å¤‡æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”ç²¾åº¦è‡ªé€‚åº”çš„è®¡ç®—æ–¹æ¡ˆï¼Œç›¸å…³ä»£ç å·²å…¬å¼€ä»¥ä¾›ç¤¾åŒºç ”ç©¶ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13049v1",
      "published_date": "2025-08-18 16:13:00 UTC",
      "updated_date": "2025-08-18 16:13:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:17.290201+00:00"
    },
    {
      "arxiv_id": "2508.13047v1",
      "title": "Using AI for User Representation: An Analysis of 83 Persona Prompts",
      "title_zh": "ä½¿ç”¨äººå·¥æ™ºèƒ½è¿›è¡Œç”¨æˆ·è¡¨å¾ï¼š83 ä¸ªäººç‰©è§’è‰²æç¤ºè¯åˆ†æ",
      "authors": [
        "Joni Salminen",
        "Danial Amin",
        "Bernard Jansen"
      ],
      "abstract": "We analyzed 83 persona prompts from 27 research articles that used large language models (LLMs) to generate user personas. Findings show that the prompts predominantly generate single personas. Several prompts express a desire for short or concise persona descriptions, which deviates from the tradition of creating rich, informative, and rounded persona profiles. Text is the most common format for generated persona attributes, followed by numbers. Text and numbers are often generated together, and demographic attributes are included in nearly all generated personas. Researchers use up to 12 prompts in a single study, though most research uses a small number of prompts. Comparison and testing multiple LLMs is rare. More than half of the prompts require the persona output in a structured format, such as JSON, and 74% of the prompts insert data or dynamic variables. We discuss the implications of increased use of computational personas for user representation.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†æäº†æ¥è‡ª27ç¯‡ç ”ç©¶æ–‡ç« çš„83ä¸ªç”¨æˆ·è§’è‰²æç¤ºè¯(persona prompts)ï¼Œç³»ç»Ÿæ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆç”¨æˆ·ç”»åƒçš„ç°çŠ¶ä¸æ¨¡å¼ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰æç¤ºè¯å€¾å‘äºç”Ÿæˆå•ä¸€ç”»åƒä¸”è¿½æ±‚ç®€æ´æè¿°ï¼Œè¿™åœ¨ä¸€å®šç¨‹åº¦ä¸ŠèƒŒç¦»äº†ä¼ ç»Ÿç”¨æˆ·ç ”ç©¶ä¸­è¿½æ±‚ä¸°å¯Œä¸”å…¨é¢ç”»åƒçš„åˆè¡·ã€‚åœ¨ç”Ÿæˆçš„å±æ€§ä¸­ï¼Œæ–‡æœ¬ä¸æ•°å­—æ˜¯æœ€å¸¸è§çš„æ ¼å¼ï¼Œä¸”äººå£ç»Ÿè®¡å­¦ç‰¹å¾(demographic attributes)åœ¨å‡ ä¹æ‰€æœ‰ç”Ÿæˆçš„ç”»åƒä¸­éƒ½æœ‰ä½“ç°ã€‚æ­¤å¤–ï¼Œè¶…è¿‡åŠæ•°çš„æç¤ºè¯è¦æ±‚ä»¥JSONç­‰ç»“æ„åŒ–æ ¼å¼è¾“å‡ºï¼Œä¸”74%çš„æç¤ºè¯æ¶‰åŠæ•°æ®æˆ–åŠ¨æ€å˜é‡çš„æ’å…¥ã€‚å°½ç®¡ç ”ç©¶è€…åœ¨å•é¡¹ç ”ç©¶ä¸­æœ€é«˜ä½¿ç”¨äº†12ä¸ªæç¤ºè¯ï¼Œä½†å¤§å¤šæ•°ç ”ç©¶ä½¿ç”¨çš„æç¤ºè¯æ•°é‡è¾ƒå°‘ï¼Œä¸”é²œå°‘å¯¹ä¸åŒLLMsè¿›è¡Œå¯¹æ¯”æµ‹è¯•ã€‚è¯¥åˆ†ææ­ç¤ºäº†è®¡ç®—åŒ–ç”»åƒ(computational personas)åœ¨ç”¨æˆ·è¡¨å¾ä¸­æ—¥ç›Šå¢é•¿çš„ä½¿ç”¨è¶‹åŠ¿åŠå…¶æ½œåœ¨å½±å“ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at AICCSA-2025",
      "pdf_url": "https://arxiv.org/pdf/2508.13047v1",
      "published_date": "2025-08-18 16:09:47 UTC",
      "updated_date": "2025-08-18 16:09:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:20.092514+00:00"
    },
    {
      "arxiv_id": "2508.13037v1",
      "title": "Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction",
      "title_zh": "å¤§æ¨¡å‹èƒ½å¦æ•™å¯¼å­¦ç”Ÿæ¨¡å‹åƒäººç±»ä¸€æ ·è§£å†³æ•°å­¦é—®é¢˜ï¼Ÿä¸€ç§åŸºäºå¤š LoRA äº¤äº’çš„æ¨ç†è’¸é¦æ–¹æ³•",
      "authors": [
        "Xinhe Li",
        "Jiajun Liu",
        "Peng Wang"
      ],
      "abstract": "Recent studies have demonstrated that Large Language Models (LLMs) have strong mathematical reasoning abilities but rely on hundreds of billions of parameters. To tackle the challenge of poor reasoning in Small Language Models (SLMs), existing methods typically leverage LLMs to generate massive amounts of data for cramming training. In psychology, they are akin to System 1 thinking, which resolves reasoning problems rapidly based on experience and intuition. However, human learning also requires System 2 thinking, where knowledge is first acquired and then reinforced through practice. Inspired by such two distinct modes of thinking, we propose a novel method based on the multi-LoRA Interaction for mathematical reasoning Distillation (LoRID). First, we input the question and reasoning of each sample into an LLM to create knowledge-enhanced datasets. Subsequently, we train a LoRA block on the student model as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts for problem-solving. Then, to imitate System 2 thinking, we train the Knowledge Generator (KG) and Deep Reasoner (DR), respectively. The former outputs only knowledge after receiving problems, while the latter uses that knowledge to perform reasoning. Finally, to address the randomness in the generation of IR and DR, we evaluate whether their outputs are consistent, and the inference process needs to be iterated if not. This step can enhance the mathematical reasoning ability of SLMs through mutual feedback. Experimental results show that LoRID achieves state-of-the-art performance, especially on the GSM8K dataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%, 12.3%, and 1.8% accuracy across the five base models, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LoRIDï¼Œä¸€ç§åŸºäºå¤šLoRAäº¤äº’(Multi-LoRA Interaction)çš„æ•°å­¦æ¨ç†è’¸é¦æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å°è¯­è¨€æ¨¡å‹(SLMs)æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚å—åˆ°äººç±»System 1å’ŒSystem 2æ€ç»´æ¨¡å¼çš„å¯å‘ï¼Œè¯¥æ–¹æ³•é€šè¿‡çŸ¥è¯†å¢å¼ºæ•°æ®é›†è®­ç»ƒäº†ç›´è§‰æ¨ç†å™¨(Intuitive Reasoner, IR)ä»¥ç›´æ¥ç”Ÿæˆæ€ç»´é“¾(Chain-of-Thought)ï¼Œå¹¶ç»“åˆçŸ¥è¯†ç”Ÿæˆå™¨(Knowledge Generator, KG)ä¸æ·±åº¦æ¨ç†å™¨(Deep Reasoner, DR)æ¥æ¨¡ä»¿æ·±åº¦æ€è€ƒè¿‡ç¨‹ã€‚ä¸ºäº†è§£å†³ç”Ÿæˆè¿‡ç¨‹ä¸­çš„éšæœºæ€§ï¼ŒLoRIDé€šè¿‡è¯„ä¼°IRä¸DRçš„ä¸€è‡´æ€§å¹¶å¼•å…¥è¿­ä»£äº’åé¦ˆæœºåˆ¶ï¼Œæ˜¾è‘—å¢å¼ºäº†å°æ¨¡å‹çš„é€»è¾‘ä¸¥å¯†æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLoRIDåœ¨GSM8Kç­‰æ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œåœ¨äº”ç§åŸºç¡€æ¨¡å‹ä¸Šçš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰æœ€ä½³æ–¹æ³•ã€‚è¯¥ç ”ç©¶è¯æ˜äº†æ¨¡ä»¿äººç±»åŒé‡è®¤çŸ¥æ¨¡å¼èƒ½æœ‰æ•ˆæå‡å°å‹æ¨¡å‹çš„æ•°å­¦é—®é¢˜è§£å†³èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IJCAI2025",
      "pdf_url": "https://arxiv.org/pdf/2508.13037v1",
      "published_date": "2025-08-18 15:56:10 UTC",
      "updated_date": "2025-08-18 15:56:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:34.295121+00:00"
    },
    {
      "arxiv_id": "2508.13030v1",
      "title": "The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks",
      "title_zh": "åŸºäº Transformer çš„æ¨¡å‹åœ¨ç½‘ç»œæ”»å‡»åæœé¢„æµ‹ä¸­çš„åº”ç”¨",
      "authors": [
        "Bipin Chhetri",
        "Akbar Siami Namin"
      ],
      "abstract": "Cyberattacks are increasing, and securing against such threats is costing industries billions of dollars annually. Threat Modeling, that is, comprehending the consequences of these attacks, can provide critical support to cybersecurity professionals, enabling them to take timely action and allocate resources that could be used elsewhere. Cybersecurity is heavily dependent on threat modeling, as it assists security experts in assessing and mitigating risks related to identifying vulnerabilities and threats. Recently, there has been a pressing need for automated methods to assess attack descriptions and forecast the future consequences of the increasing complexity of cyberattacks. This study examines how Natural Language Processing (NLP) and deep learning can be applied to analyze the potential impact of cyberattacks by leveraging textual descriptions from the MITRE Common Weakness Enumeration (CWE) database. We emphasize classifying attack consequences into five principal categories: Availability, Access Control, Confidentiality, Integrity, and Other. This paper investigates the use of Bidirectional Encoder Representations from Transformers (BERT) in combination with Hierarchical Attention Networks (HANs) for Multi-label classification, evaluating their performance in comparison with conventional CNN and LSTM-based models. Experimental findings show that BERT achieves an overall accuracy of $0.972$, far higher than conventional deep learning models in multi-label classification. HAN outperforms baseline forms of CNN and LSTM-based models on specific cybersecurity labels. However, BERT consistently achieves better precision and recall, making it more suitable for predicting the consequences of a cyberattack.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡åˆ†æMITRE Common Weakness Enumeration (CWE)æ•°æ®åº“ä¸­çš„æ–‡æœ¬æè¿°ï¼Œå®ç°å¯¹ç½‘ç»œæ”»å‡»åæœçš„è‡ªåŠ¨åŒ–é¢„æµ‹ã€‚è®ºæ–‡é‡ç‚¹è€ƒå¯Ÿäº†Bidirectional Encoder Representations from Transformers (BERT)ä¸å±‚æ¬¡æ³¨æ„åŠ›ç½‘ç»œ(Hierarchical Attention Networks, HANs)åœ¨å¤šæ ‡ç­¾åˆ†ç±»(Multi-label classification)ä¸­çš„åº”ç”¨ï¼Œå¹¶å°†æ”»å‡»åæœåˆ’åˆ†ä¸ºå¯ç”¨æ€§(Availability)ã€è®¿é—®æ§åˆ¶(Access Control)ã€æœºå¯†æ€§(Confidentiality)ã€å®Œæ•´æ€§(Integrity)åŠå…¶ä»–ç­‰äº”å¤§ç±»åˆ«ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBERTåœ¨å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†0.972çš„å‡†ç¡®ç‡ï¼Œæ€§èƒ½è¿œè¶…ä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)æ¨¡å‹ã€‚å°½ç®¡HANåœ¨ç‰¹å®šå®‰å…¨æ ‡ç­¾ä¸Šè¡¨ç°ä¼˜äºåŸºå‡†æ¨¡å‹ï¼Œä½†BERTåœ¨ç²¾ç¡®åº¦(Precision)å’Œå¬å›ç‡(Recall)æ–¹é¢çš„ä¸€è‡´æ€§è¡¨ç°ä½¿å…¶æ›´é€‚åˆç”¨äºé¢„æµ‹ç½‘ç»œæ”»å‡»åæœã€‚è¯¥ç ”ç©¶è¯æ˜äº†Transformeræ¶æ„åœ¨æå‡å¨èƒå»ºæ¨¡è‡ªåŠ¨åŒ–æ°´å¹³å’Œä¼˜åŒ–ç½‘ç»œå®‰å…¨èµ„æºåˆ†é…æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 6 figures,Proceedings of the IEEE International Conference on Computers, Software, & Applications (COMPSAC), EATA Symposium, Toronto, Canada, July 8-11, 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.13030v1",
      "published_date": "2025-08-18 15:46:36 UTC",
      "updated_date": "2025-08-18 15:46:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:34.757707+00:00"
    },
    {
      "arxiv_id": "2508.13023v1",
      "title": "G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance",
      "title_zh": "G$^2$RPO-Aï¼šå…·æœ‰è‡ªé€‚åº”å¼•å¯¼çš„å¼•å¯¼å¼ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Yongxin Guo",
        "Wenbo Deng",
        "Zhenglin Cheng",
        "Xiaoying Tang"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced the reasoning abilities of large language models (LLMs). Its success, however, largely depends on strong base models with rich world knowledge, yielding only modest improvements for small-size language models (SLMs). To address this limitation, we investigate Guided GRPO, which injects ground-truth reasoning steps into roll-out trajectories to compensate for SLMs' inherent weaknesses. Through a comprehensive study of various guidance configurations, we find that naively adding guidance delivers limited gains. These insights motivate G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength in response to the model's evolving training dynamics. Experiments on mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A substantially outperforms vanilla GRPO. Our code and models are available at https://github.com/T-Lab-CUHKSZ/G2RPO-A.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¸¦éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning with Verifiable Rewards, RLVR) åœ¨æå‡å°è¯­è¨€æ¨¡å‹ (SLMs) æ¨ç†èƒ½åŠ›æ—¶æ•ˆæœå—é™çš„é—®é¢˜ï¼Œæå‡ºäº† Guided GRPO æ¡†æ¶ã€‚é€šè¿‡æ·±å…¥ç ”ç©¶å„ç§å¼•å¯¼é…ç½®ï¼Œä½œè€…å‘ç°ç®€å•çš„å¼•å¯¼ç­–ç•¥æ”¶ç›Šæœ‰é™ï¼Œå¹¶æ®æ­¤è®¾è®¡äº† G$^2$RPO-A ç®—æ³•ã€‚è¯¥ç®—æ³•å¼•å…¥äº†è‡ªé€‚åº”å¼•å¯¼æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŠ¨æ€å˜åŒ–è‡ªåŠ¨è°ƒæ•´å¼•å¯¼å¼ºåº¦ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†å°æ¨¡å‹åœ¨æ¨ç†æ­¥éª¤ç”Ÿæˆä¸Šçš„å›ºæœ‰å¼±ç‚¹ã€‚åœ¨æ•°å­¦æ¨ç†å’Œä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¯æ˜ï¼ŒG$^2$RPO-A çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ GRPO ç®—æ³•ã€‚è¿™ä¸€ç ”ç©¶ä¸ºåœ¨æ¨¡å‹å‚æ•°è§„æ¨¡è¾ƒå°çš„æƒ…å†µä¸‹å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›æä¾›äº†é«˜æ•ˆä¸”çµæ´»çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13023v1",
      "published_date": "2025-08-18 15:41:16 UTC",
      "updated_date": "2025-08-18 15:41:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:43.695065+00:00"
    },
    {
      "arxiv_id": "2508.13021v3",
      "title": "Empirical Analysis of Decoding Biases in Masked Diffusion Models",
      "title_zh": "æ©ç æ‰©æ•£æ¨¡å‹è§£ç åå·®çš„å®è¯åˆ†æ",
      "authors": [
        "Pengcheng Huang",
        "Tianming Liu",
        "Zhenghao Liu",
        "Yukun Yan",
        "Shuo Wang",
        "Tong Xiao",
        "Zulong Chen",
        "Maosong Sun"
      ],
      "abstract": "Masked diffusion models (MDMs), which leverage bidirectional attention and a denoising process, are narrowing the performance gap with autoregressive models (ARMs). However, their internal attention mechanisms remain under-explored. This paper investigates the attention behaviors in MDMs, revealing the phenomenon of Attention Floating. Unlike ARMs, where attention converges to a fixed sink, MDMs exhibit dynamic, dispersed attention anchors that shift across denoising steps and layers. Further analysis reveals its Shallow Structure-Aware, Deep Content-Focused attention mechanism: shallow layers utilize floating tokens to build a global structural framework, while deeper layers allocate more capability toward capturing semantic content. Empirically, this distinctive attention pattern provides a mechanistic explanation for the strong in-context learning capabilities of MDMs, allowing them to double the performance compared to ARMs in knowledge-intensive tasks. All codes are available at https://github.com/NEUIR/Uncode.",
      "tldr_zh": "æœ¬æ–‡å¯¹æ©ç æ‰©æ•£æ¨¡å‹(Masked Diffusion Models, MDMs)çš„è§£ç åå·®è¿›è¡Œäº†å®è¯åˆ†æï¼Œæ­ç¤ºäº†å…¶å†…éƒ¨æ³¨æ„åŠ›æœºåˆ¶ä¸è‡ªå›å½’æ¨¡å‹(ARMs)çš„æ˜¾è‘—å·®å¼‚ã€‚ç ”ç©¶å‘ç°MDMsä¸­å­˜åœ¨ä¸€ç§ç‰¹æ®Šçš„â€œæ³¨æ„åŠ›æµ®åŠ¨â€(Attention Floating)ç°è±¡ï¼Œå…¶æ³¨æ„åŠ›é”šç‚¹å‘ˆç°å‡ºéšå»å™ªæ­¥éª¤å’Œå±‚çº§åŠ¨æ€åç§»çš„å¼¥æ•£ç‰¹å¾ã€‚åˆ†æè¿›ä¸€æ­¥æŒ‡å‡ºMDMséµå¾ªâ€œæµ…å±‚æ„ŸçŸ¥ç»“æ„ã€æ·±å±‚èšç„¦å†…å®¹â€(Shallow Structure-Aware, Deep Content-Focused)çš„æœºåˆ¶ï¼Œå³æµ…å±‚é€šè¿‡æµ®åŠ¨æ ‡è®°æ„å»ºå…¨å±€æ¡†æ¶ï¼Œè€Œæ·±å±‚åˆ™é›†ä¸­äºè¯­ä¹‰å†…å®¹çš„æ•è·ã€‚è¿™ä¸€ç‹¬ç‰¹çš„æ³¨æ„åŠ›æ¨¡å¼ä¸ºMDMså¼ºå¤§çš„è¯­å¢ƒå­¦ä¹ (in-context learning)èƒ½åŠ›æä¾›äº†æœºæ¢°æ€§è§£é‡Šã€‚å®è¯ç»“æœè¡¨æ˜ï¼ŒMDMsåœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„æ€§èƒ½å¯è¾¾åˆ°ARMsçš„ä¸¤å€ï¼Œè¯¥ç ”ç©¶ä¸ºç†è§£æ‰©æ•£æ¨¡å‹çš„é«˜æ•ˆè¡¨ç°æä¾›äº†åº•å±‚åŸç†è§£é‡Šã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages,17 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.13021v3",
      "published_date": "2025-08-18 15:38:37 UTC",
      "updated_date": "2026-01-11 01:39:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:43.854691+00:00"
    },
    {
      "arxiv_id": "2508.13020v2",
      "title": "e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving",
      "title_zh": "e-boostï¼šç»“åˆè‡ªé€‚åº”å¯å‘å¼ä¸ç²¾ç¡®æ±‚è§£çš„å¢å¼ºå‹ E-Graph æå–",
      "authors": [
        "Jiaqi Yin",
        "Zhan Song",
        "Chen Chen",
        "Yaohui Cai",
        "Zhiru Zhang",
        "Cunxi Yu"
      ],
      "abstract": "E-graphs have attracted growing interest in many fields, particularly in logic synthesis and formal verification. E-graph extraction is a challenging NP-hard combinatorial optimization problem. It requires identifying optimal terms from exponentially many equivalent expressions, serving as the primary performance bottleneck in e-graph based optimization tasks. However, traditional extraction methods face a critical trade-off: heuristic approaches offer speed but sacrifice optimality, while exact methods provide optimal solutions but face prohibitive computational costs on practical problems. We present e-boost, a novel framework that bridges this gap through three key innovations: (1) parallelized heuristic extraction that leverages weak data dependence to compute DAG costs concurrently, enabling efficient multi-threaded performance without sacrificing extraction quality; (2) adaptive search space pruning that employs a parameterized threshold mechanism to retain only promising candidates, dramatically reducing the solution space while preserving near-optimal solutions; and (3) initialized exact solving that formulates the reduced problem as an Integer Linear Program with warm-start capabilities, guiding solvers toward high-quality solutions faster.\n  Across the diverse benchmarks in formal verification and logic synthesis fields, e-boost demonstrates 558x runtime speedup over traditional exact approaches (ILP) and 19.04% performance improvement over the state-of-the-art extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost produces 7.6% and 8.1% area improvements compared to conventional synthesis tools with two different technology mapping libraries. e-boost is available at https://github.com/Yu-Maryland/e-boost.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€»è¾‘ç»¼åˆå’Œå½¢å¼åŒ–éªŒè¯ä¸­ E-graph extraction è¿™ä¸€ NP-hard éš¾é¢˜ï¼Œæå‡ºäº†åä¸º e-boost çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨å¹³è¡¡å¯å‘å¼æ–¹æ³•çš„æœ€ä¼˜æ€§ç¼ºå¤±ä¸ç²¾ç¡®æ±‚è§£æ–¹æ³•çš„é«˜æ˜‚è®¡ç®—æˆæœ¬ã€‚e-boost å¼•å…¥äº†å¹¶è¡ŒåŒ–å¯å‘å¼æå–æŠ€æœ¯ï¼Œåˆ©ç”¨å¼±æ•°æ®ä¾èµ–æ€§å¹¶å‘è®¡ç®— DAG costï¼Œåœ¨ä¿è¯æå–è´¨é‡çš„åŒæ—¶æ˜¾è‘—æå‡æ•ˆç‡ã€‚è¯¥æ¡†æ¶é€šè¿‡åŸºäºå‚æ•°åŒ–é˜ˆå€¼çš„è‡ªé€‚åº”æœç´¢ç©ºé—´å‰ªææŠ€æœ¯å¤§å¹…ç¼©å°è§£ç©ºé—´ï¼Œå¹¶ç»“åˆå…·å¤‡çƒ­å¯åŠ¨ (warm-start) èƒ½åŠ›çš„æ•´æ•°çº¿æ€§è§„åˆ’ (Integer Linear Program, ILP) å¼•å¯¼æ±‚è§£å™¨å¿«é€Ÿé”å®šé«˜è´¨é‡è§£ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œe-boost åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ¯”ä¼ ç»Ÿ ILP æ–¹æ³•å®ç°äº† 558 å€çš„è¿è¡ŒåŠ é€Ÿï¼Œä¸”æ€§èƒ½ä¼˜äºå…ˆè¿›çš„ SmoothE æ¡†æ¶ã€‚åœ¨å®é™…é€»è¾‘ç»¼åˆä»»åŠ¡ä¸­ï¼Œè¯¥æ¡†æ¶ç›¸æ¯”ä¼ ç»Ÿå·¥å…·å®ç°äº† 7.6% è‡³ 8.1% çš„é¢ç§¯ä¼˜åŒ–ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚ç»„åˆä¼˜åŒ–é—®é¢˜ä¸Šçš„é«˜æ•ˆæ€§ä¸å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ICCAD 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.13020v2",
      "published_date": "2025-08-18 15:38:12 UTC",
      "updated_date": "2025-08-23 21:21:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:31:59.853078+00:00"
    },
    {
      "arxiv_id": "2508.13003v2",
      "title": "EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing",
      "title_zh": "EvolMathEvalï¼šåŸºäºè¿›åŒ–æµ‹è¯•æ„å»ºæ•°å­¦æ¨ç†çš„å¯æ¼”åŒ–è¯„æµ‹åŸºå‡†",
      "authors": [
        "Shengbo Wang",
        "Mingwei Liu",
        "Zike Li",
        "Anji Li",
        "Yanlin Wang",
        "Xin Peng",
        "Zibin Zheng"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) poses a significant challenge to existing mathematical reasoning benchmarks. However, these benchmarks tend to become easier over time as LLMs can learn from the published benchmarks. This limitation hinder the precise evaluation of the true capabilities of SOTA models. To address this challenge, this paper introduces EvolMathEval, an automated mathematical benchmark generation and evolution framework based on evolutionary testing. Experimental results demonstrate that EvolMathEval can not only generate a large volume of high-difficulty problems through continuous self-iteration, but it can also significantly enhance the complexity of public datasets like GSM8K through evolution, reducing model accuracy by an average of 48\\%. Deeper investigation reveals that when solving these evolved problems, LLMs tend to bypass complex multi-step logical reasoning by relying on simplistic and fuzzy conditions, consequently leading to incorrect solutions. We define this phenomenon as the ``Pseudo Aha Moment\", which we find accounts for 77\\% to 100\\% of errors on targeted problems. Code and resources are available at: https://anonymous.4open.science/r/EvolMathEval",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®¹æ˜“ä»ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­å­¦ä¹ å¯¼è‡´è¯„ä¼°å¤±æ•ˆçš„é—®é¢˜ï¼Œæå‡ºäº†EvolMathEvalï¼Œä¸€ä¸ªåŸºäºè¿›åŒ–æµ‹è¯•ï¼ˆEvolutionary Testingï¼‰çš„è‡ªåŠ¨åŒ–æ•°å­¦åŸºå‡†ç”Ÿæˆä¸æ¼”åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æŒç»­çš„è‡ªæˆ‘è¿­ä»£ä»¥åŠå¯¹GSM8Kç­‰å…¬å¼€æ•°æ®é›†çš„æ¼”åŒ–ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡é—®é¢˜çš„å¤æ‚æ€§ï¼Œä½¿æ¨¡å‹å¹³å‡å‡†ç¡®ç‡ä¸‹é™è¾¾48%ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº†LLMsåœ¨å¤„ç†è¿™äº›æ¼”åŒ–é—®é¢˜æ—¶ï¼Œå¾€å¾€ä¼šç»•è¿‡å¤æ‚çš„å¤šæ­¥é€»è¾‘æ¨ç†è€Œä¾èµ–ç®€å•æ¨¡ç³Šçš„æ¡ä»¶ï¼Œè¿›è€Œå¯¼è‡´é”™è¯¯ã€‚ä½œè€…å°†è¿™ç§ç°è±¡å®šä¹‰ä¸ºâ€œPseudo Aha Momentâ€ï¼Œå¹¶å‘ç°å…¶åœ¨ç‰¹å®šé—®é¢˜çš„é”™è¯¯è¯±å› ä¸­å æ¯”é«˜è¾¾77%è‡³100%ã€‚è¯¥å·¥ä½œä¸ºç²¾å‡†è¯„ä¼°SOTAæ¨¡å‹çš„çœŸå®æ•°å­¦èƒ½åŠ›æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13003v2",
      "published_date": "2025-08-18 15:24:10 UTC",
      "updated_date": "2025-10-05 08:41:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:00.457452+00:00"
    },
    {
      "arxiv_id": "2508.14120v1",
      "title": "SimGenHOI: Physically Realistic Whole-Body Humanoid-Object Interaction via Generative Modeling and Reinforcement Learning",
      "title_zh": "SimGenHOIï¼šåŸºäºç”Ÿæˆå¼å»ºæ¨¡ä¸å¼ºåŒ–å­¦ä¹ çš„ç‰©ç†é€¼çœŸå…¨èº«äººå½¢æœºå™¨äººä¸ç‰©ä½“äº¤äº’",
      "authors": [
        "Yuhang Lin",
        "Yijia Xie",
        "Jiahong Xie",
        "Yuehao Huang",
        "Ruoyu Wang",
        "Jiajun Lv",
        "Yukai Ma",
        "Xingxing Zuo"
      ],
      "abstract": "Generating physically realistic humanoid-object interactions (HOI) is a fundamental challenge in robotics. Existing HOI generation approaches, such as diffusion-based models, often suffer from artifacts such as implausible contacts, penetrations, and unrealistic whole-body actions, which hinder successful execution in physical environments. To address these challenges, we introduce SimGenHOI, a unified framework that combines the strengths of generative modeling and reinforcement learning to produce controllable and physically plausible HOI. Our HOI generative model, based on Diffusion Transformers (DiT), predicts a set of key actions conditioned on text prompts, object geometry, sparse object waypoints, and the initial humanoid pose. These key actions capture essential interaction dynamics and are interpolated into smooth motion trajectories, naturally supporting long-horizon generation. To ensure physical realism, we design a contact-aware whole-body control policy trained with reinforcement learning, which tracks the generated motions while correcting artifacts such as penetration and foot sliding. Furthermore, we introduce a mutual fine-tuning strategy, where the generative model and the control policy iteratively refine each other, improving both motion realism and tracking robustness. Extensive experiments demonstrate that SimGenHOI generates realistic, diverse, and physically plausible humanoid-object interactions, achieving significantly higher tracking success rates in simulation and enabling long-horizon manipulation tasks. Code will be released upon acceptance on our project page: https://xingxingzuo.github.io/simgen_hoi.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SimGenHOIï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³ç±»äººæœºå™¨äºº-ç‰©ä½“äº¤äº’(HOI)ä¸­ç‰©ç†çœŸå®æ€§æŒ‘æˆ˜çš„ç»Ÿä¸€æ¡†æ¶ï¼Œé’ˆå¯¹ç°æœ‰æ‰©æ•£æ¨¡å‹å¸¸å‡ºç°çš„æ¥è§¦ä¸åˆç†ã€ç©¿æ¨¡å’Œå…¨èº«åŠ¨ä½œä¸è‡ªç„¶ç­‰é—®é¢˜ã€‚æ¡†æ¶çš„æ ¸å¿ƒåŒ…å«ä¸€ä¸ªåŸºäºDiffusion Transformers (DiT)çš„ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿæ ¹æ®æ–‡æœ¬æç¤ºã€ç‰©ä½“å‡ ä½•å½¢çŠ¶ã€ç¨€ç–è·¯å¾„ç‚¹å’Œåˆå§‹å§¿æ€é¢„æµ‹å…³é”®åŠ¨ä½œåºåˆ—ã€‚è¿™äº›å…³é”®åŠ¨ä½œé€šè¿‡æ’å€¼å½¢æˆå¹³æ»‘çš„è¿åŠ¨è½¨è¿¹ï¼Œä»è€Œå¤©ç„¶æ”¯æŒé•¿ç¨‹(long-horizon)ä»»åŠ¡çš„ç”Ÿæˆã€‚ä¸ºäº†ç¡®ä¿ç‰©ç†çœŸå®æ€§ï¼Œè¯¥ç ”ç©¶è®¾è®¡äº†ä¸€ç§å…·å¤‡æ¥è§¦æ„ŸçŸ¥èƒ½åŠ›çš„å…¨èº«æ§åˆ¶ç­–ç•¥ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è¿›è¡Œè®­ç»ƒï¼Œä»¥è·Ÿè¸ªç”Ÿæˆçš„åŠ¨ä½œå¹¶ä¿®æ­£ç©¿æ¨¡å’Œè¶³éƒ¨æ»‘åŠ¨ç­‰ä¼ªå½±ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ç§ç›¸äº’å¾®è°ƒ(mutual fine-tuning)ç­–ç•¥ï¼Œä½¿ç”Ÿæˆæ¨¡å‹å’Œæ§åˆ¶ç­–ç•¥èƒ½å¤Ÿè¿­ä»£ä¼˜åŒ–ï¼ŒåŒæ­¥æå‡è¿åŠ¨çš„çœŸå®æ„Ÿå’Œè·Ÿè¸ªçš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSimGenHOIèƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”ç¬¦åˆç‰©ç†è§„å¾‹çš„äº¤äº’åŠ¨ä½œï¼Œåœ¨ä»¿çœŸç¯å¢ƒä¸­çš„è·Ÿè¸ªæˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œå¹¶æœ‰æ•ˆæ”¯æŒäº†é•¿ç¨‹æ“æ§ä»»åŠ¡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14120v1",
      "published_date": "2025-08-18 15:20:46 UTC",
      "updated_date": "2025-08-18 15:20:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:03.292810+00:00"
    },
    {
      "arxiv_id": "2508.12998v1",
      "title": "Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health",
      "title_zh": "ç»´ç”Ÿç´  Nï¼šä¸åŒå½¢å¼å…¬å…±ç»¿åœ°å¯¹åŸå¸‚å¥åº·çš„ç›Šå¤„",
      "authors": [
        "Sanja Å Ä‡epanoviÄ‡",
        "Sagar Joglekar",
        "Stephen Law",
        "Daniele Quercia",
        "Ke Zhou",
        "Alice Battiston",
        "Rossano Schifanella"
      ],
      "abstract": "Urban greenery is often linked to better health, yet findings from past research have been inconsistent. One reason is that official greenery metrics measure the amount or nearness of greenery but ignore how often people actually may potentially see or use it in daily life. To address this gap, we introduced a new classification that separates on-road greenery, which people see while walking through streets, from off-road greenery, which requires planned visits. We did so by combining aerial imagery of Greater London and greenery data from OpenStreetMap with quantified greenery from over 100,000 Google Street View images and accessibility estimates based on 160,000 road segments. We linked these measures to 7.45 billion medical prescriptions issued by the National Health Service and processed through our methodology. These prescriptions cover five conditions: diabetes, hypertension, asthma, depression, and anxiety, as well as opioid use. As hypothesized, we found that green on-road was more strongly linked to better health than four widely used official measures. For example, hypertension prescriptions dropped by 3.68% in wards with on-road greenery above the median citywide level compared to those below it. If all below-median wards reached the citywide median in on-road greenery, prescription costs could fall by up to Â£3.15 million each year. These results suggest that greenery seen in daily life may be more relevant than public yet secluded greenery, and that official metrics commonly used in the literature have important limitations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸå¸‚ç»¿åœ°ä¸åŸå¸‚å¥åº·ä¹‹é—´çš„å…³ç³»ï¼Œæ—¨åœ¨è§£å†³ä»¥å¾€ç ”ç©¶ä¸­å› å¿½è§†æ—¥å¸¸ç”Ÿæ´»ä¸­ç»¿åœ°å®é™…æš´éœ²é¢‘ç‡è€Œå¯¼è‡´çš„ç»“è®ºä¸ä¸€è‡´é—®é¢˜ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„åˆ†ç±»æ–¹æ³•ï¼Œå°†äººä»¬æ—¥å¸¸æ­¥è¡Œå¯è§çš„è¡—é“ç»¿åœ° (on-road greenery) ä¸éœ€è¦ä¸“é—¨è®¿é—®çš„éé“è·¯ç»¿åœ° (off-road greenery) è¿›è¡ŒåŒºåˆ†ã€‚é€šè¿‡ç»“åˆå¤§ä¼¦æ•¦åœ°åŒºçš„èˆªç©ºå½±åƒã€OpenStreetMapã€è¶…è¿‡10ä¸‡å¼  Google Street View å›¾åƒä»¥åŠ16ä¸‡æ®µé“è·¯æ•°æ®ï¼Œç ”ç©¶å›¢é˜Ÿé‡åŒ–äº†ç»¿åœ°æš´éœ²ç¨‹åº¦ï¼Œå¹¶å°†å…¶ä¸è‹±å›½å›½æ°‘åŒ»ç–—æœåŠ¡ä½“ç³» (NHS) çš„74.5äº¿ä»½åŒ»ç–—å¤„æ–¹è®°å½•ç›¸å…³è”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¡—é“ç»¿åœ° (on-road greenery) ä¸å¥åº·æ”¹å–„çš„ç›¸å…³æ€§æ˜¾è‘—å¼ºäºå››ç§å¸¸ç”¨çš„å®˜æ–¹è¡¡é‡æŒ‡æ ‡ã€‚å…·ä½“è€Œè¨€ï¼Œè¡—é“ç»¿åœ°æ°´å¹³è¾ƒé«˜çš„åœ°åŒºé«˜è¡€å‹å¤„æ–¹é‡ä¸‹é™äº†3.68%ï¼Œè‹¥å…¨å¸‚æ¨å¹¿æ­¤ç±»ç»¿åŒ–ï¼Œæ¯å¹´å¯èŠ‚çœçº¦315ä¸‡è‹±é•‘çš„åŒ»ç–—æˆæœ¬ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†æ—¥å¸¸ç”Ÿæ´»ä¸­éšå¤„å¯è§çš„ç»¿åœ°å¯¹äºåŸå¸‚å¥åº·çš„é‡å¤§æ„ä¹‰ï¼Œå¹¶æŒ‡å‡ºäº†ç°æœ‰å®˜æ–¹è¯„ä¼°æŒ‡æ ‡åœ¨æ•æ‰ç»¿åœ°å®é™…æ•ˆç›Šæ–¹é¢çš„å±€é™æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12998v1",
      "published_date": "2025-08-18 15:17:33 UTC",
      "updated_date": "2025-08-18 15:17:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:08.768597+00:00"
    },
    {
      "arxiv_id": "2508.12996v2",
      "title": "Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair",
      "title_zh": "Kourkoutas-Betaï¼šä¸€ç§å…·æœ‰æ²™æ¼ é£æƒ…çš„å¤ªé˜³å°–å³°é©±åŠ¨å‹ Adam ä¼˜åŒ–å™¨",
      "authors": [
        "Stavros C. Kassinos"
      ],
      "abstract": "Transformer neural networks are increasingly used for physics-based problems. In data-driven PDE surrogates, training samples from varying boundary and initial conditions can cause erratic losses and spiky gradients; in physics-informed neural networks (PINNs), stiff composite losses amplify this effect.\n  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed second-moment discount beta2 is replaced by a layer-wise dynamic value driven by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an exponential moving average (EMA) of past norms, squashed to the interval [0,1). Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max. Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio), adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'', ``exact'). With all features off and bias_correction=``none'', the method is exactly Adam.\n  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about 38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller variance. The method remains drop-in, with runtime overhead comparable to Adam in testbeds A-C and within single-digit percent in testbed D. It preserves Adam-style convergence guarantees while improving robustness under spiky gradients.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Kourkoutas-Betaï¼Œä¸€ç§é’ˆå¯¹ç‰©ç†å»ºæ¨¡ä¸­ Transformer ç¥ç»ç½‘ç»œè®­ç»ƒä¸ç¨³å®šæ€§è€Œè®¾è®¡çš„ Adam é£æ ¼ä¼˜åŒ–å™¨ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†å›ºå®šçš„äºŒé˜¶çŸ©æŠ˜æ‰£ç³»æ•° beta2 æ›¿æ¢ä¸ºç”± â€œsunspikeâ€ æ¯”ç‡é©±åŠ¨çš„é€å±‚åŠ¨æ€å€¼ï¼Œè¯¥æ¯”ç‡é€šè¿‡å½“å‰æ¢¯åº¦èŒƒæ•°ä¸è¿‡å»èŒƒæ•°çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ (EMA) ä¹‹æ¯”æ¥å®æ—¶æ•æ‰æ¢¯åº¦å°–å³°ã€‚å½“æ£€æµ‹åˆ°æ¢¯åº¦å°–å³°æ—¶ï¼Œbeta2 ä¼šå‘æœ€å°å€¼é™ä½ä»¥å¢å¼ºç¨³å®šæ€§ï¼Œè€Œåœ¨å¹³ç¨³é˜¶æ®µåˆ™ä¿æŒåœ¨æœ€å¤§å€¼é™„è¿‘ï¼Œå¹¶æ”¯æŒ trust-region clipping å’Œå¤šç§åç½®æ ¡æ­£æ¨¡å¼ã€‚å®éªŒåœ¨ Heat2D ä»£ç†æ¨¡å‹ã€Heat3D ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ (PINNs) ä»¥åŠ enwik8 å­—ç¬¦çº§ Transformer ç­‰å¤šé¡¹ä»»åŠ¡ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚ç»“æœæ˜¾ç¤ºï¼ŒKourkoutas-Beta ç›¸æ¯”äºä¼ ç»Ÿ Adam æ˜¾è‘—æå‡äº†è®­ç»ƒç¨³å®šæ€§ï¼Œåœ¨ enwik8 ä»»åŠ¡ä¸Šçš„ bits-per-character è¡¨ç°ä¼˜äºæ ‡å‡† Adam çº¦ 38% è‡³ 58%ã€‚è¯¥ä¼˜åŒ–å™¨åœ¨ä¿ç•™ Adam æ—¢æœ‰æ”¶æ•›ä¿è¯çš„åŒæ—¶ï¼Œä»¥æä½çš„è¿è¡Œå¼€é”€ä¸ºåº”å¯¹å¤æ‚ä»»åŠ¡ä¸­çš„å°–å³°æ¢¯åº¦æä¾›äº†æ›´å¼ºçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "54 pages, 8 figures, 19 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.12996v2",
      "published_date": "2025-08-18 15:16:54 UTC",
      "updated_date": "2025-08-20 21:50:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:25.852739+00:00"
    },
    {
      "arxiv_id": "2509.09688v1",
      "title": "AI-Powered Assistant for Long-Term Access to RHIC Knowledge",
      "title_zh": "ç”¨äºé•¿æœŸè·å– RHIC çŸ¥è¯†çš„äººå·¥æ™ºèƒ½é©±åŠ¨åŠ©æ‰‹",
      "authors": [
        "Mohammad Atif",
        "Vincent Garonne",
        "Eric Lancon",
        "Jerome Lauret",
        "Alexandr Prozorov",
        "Michal Vranovsky"
      ],
      "abstract": "As the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National Laboratory concludes 25 years of operation, preserving not only its vast data holdings ($\\sim$1 ExaByte) but also the embedded scientific knowledge becomes a critical priority. The RHIC Data and Analysis Preservation Plan (DAPP) introduces an AI-powered assistant system that provides natural language access to documentation, workflows, and software, with the aim of supporting reproducibility, education, and future discovery. Built upon Large Language Models using Retrieval-Augmented Generation and the Model Context Protocol, this assistant indexes structured and unstructured content from RHIC experiments and enables domain-adapted interaction. We report on the deployment, computational performance, ongoing multi-experiment integration, and architectural features designed for a sustainable and explainable long-term AI access. Our experience illustrates how modern AI/ML tools can transform the usability and discoverability of scientific legacy data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¸ƒé²å…‹æµ·æ–‡å›½å®¶å®éªŒå®¤çš„ç›¸å¯¹è®ºé‡ç¦»å­å¯¹æ’æœº(RHIC)åœ¨ç»“æŸ25å¹´è¿è¡Œåæ‰€é¢ä¸´çš„å¤§è§„æ¨¡æ•°æ®ä¸ç§‘å­¦çŸ¥è¯†ä¿å­˜æŒ‘æˆ˜ï¼Œåœ¨ RHIC Data and Analysis Preservation Plan (DAPP) æ¡†æ¶ä¸‹å¼€å‘äº†ä¸€å¥— AI-powered assistant ç³»ç»Ÿã€‚è¯¥åŠ©æ‰‹åŸºäº Large Language Models (LLMs)ï¼Œç»“åˆ Retrieval-Augmented Generation (RAG) å’Œ Model Context Protocol (MCP) æŠ€æœ¯ï¼Œå®ç°äº†å¯¹ RHIC å®éªŒä¸­ç»“æ„åŒ–å’Œéç»“æ„åŒ–å†…å®¹çš„è‡ªç„¶è¯­è¨€æ£€ç´¢ä¸é¢†åŸŸé€‚é…äº¤äº’ã€‚ç³»ç»Ÿçš„æ ¸å¿ƒç›®æ ‡æ˜¯å¢å¼ºç§‘ç ”çš„å¯é‡å¤æ€§(reproducibility)å¹¶æ”¯æŒæ•™è‚²ä¸æœªæ¥å‘ç°ï¼Œç¡®ä¿é•¿æœŸä¸”å¯è§£é‡Šçš„çŸ¥è¯†è®¿é—®æ–¹å¼ã€‚é€šè¿‡å¯¹éƒ¨ç½²è¿‡ç¨‹ã€è®¡ç®—æ€§èƒ½åŠå¤šå®éªŒé›†æˆæ¶æ„çš„è¯¦ç»†é˜è¿°ï¼Œè¯¥ç ”ç©¶å±•ç¤ºäº†ç°ä»£ AI/ML å·¥å…·åœ¨æå‡ç§‘å­¦é—ç•™æ•°æ®å¯ç”¨æ€§ä¸å¯å‘ç°æ€§(discoverability)æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09688v1",
      "published_date": "2025-08-18 15:16:29 UTC",
      "updated_date": "2025-08-18 15:16:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:19.855479+00:00"
    },
    {
      "arxiv_id": "2508.15827v2",
      "title": "Mini-Omni-Reasoner: Token-Level Thinking-in-Speaking in Large Speech Models",
      "title_zh": "Mini-Omni-Reasonerï¼šå¤§è¯­éŸ³æ¨¡å‹ä¸­çš„ Token çº§â€œè¾¹è¯´è¾¹æƒ³â€æ¨ç†",
      "authors": [
        "Zhifei Xie",
        "Ziyang Ma",
        "Zihang Liu",
        "Kaiyu Pang",
        "Hongyu Li",
        "Jialin Zhang",
        "Yue Liao",
        "Deheng Ye",
        "Chunyan Miao",
        "Shuicheng Yan"
      ],
      "abstract": "Reasoning is essential for effective communication and decision-making. While recent advances in LLMs and MLLMs have shown that incorporating explicit reasoning significantly improves understanding and generalization, reasoning in LSMs remains in a nascent stage. Early efforts attempt to transfer the \"Thinking-before-Speaking\" paradigm from textual models to speech. However, this sequential formulation introduces notable latency, as spoken responses are delayed until reasoning is fully completed, impairing real-time interaction and communication efficiency. To address this, we propose Mini-Omni-Reasoner, a framework that enables reasoning within speech via a novel \"Thinking-in-Speaking\" formulation. Rather than completing reasoning before producing any verbal output, Mini-Omni-Reasoner interleaves silent reasoning tokens with spoken response tokens at the token level. This design allows continuous speech generation while embedding structured internal reasoning, leveraging the model's high-frequency token processing capability. Although interleaved, local semantic alignment is enforced to ensure that each response token is informed by its preceding reasoning. To support this framework, we introduce Spoken-Math-Problems-3M, a large-scale dataset tailored for interleaved reasoning and response. The dataset ensures that verbal tokens consistently follow relevant reasoning content, enabling accurate and efficient learning of speech-coupled reasoning. Built on a hierarchical Thinker-Talker architecture, Mini-Omni-Reasoner delivers fluent yet logically grounded spoken responses, maintaining both naturalness and precision. On the Spoken-MQA benchmark, it achieves a +19.1% gain in arithmetic reasoning and +6.4% in contextual understanding, with shorter outputs and zero decoding latency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Mini-Omni-Reasonerï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å¢å¼ºå¤§è¯­éŸ³æ¨¡å‹(LSMs)æ¨ç†èƒ½åŠ›çš„æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿâ€œå…ˆæ€è€ƒåè¯´è¯(Thinking-before-Speaking)â€æ¨¡å¼åœ¨å®æ—¶äº¤äº’ä¸­äº§ç”Ÿçš„é«˜å»¶è¿Ÿé—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†åˆ›æ–°çš„â€œè¾¹æ€è€ƒè¾¹è¯´è¯(Thinking-in-Speaking)â€æ–¹æ¡ˆï¼Œåœ¨tokençº§åˆ«å°†é™é»˜æ¨ç†tokenä¸è¯­éŸ³å“åº”tokenäº¤æ›¿åµŒå…¥ï¼Œä»è€Œåœ¨ç”Ÿæˆè¿ç»­è¯­éŸ³çš„åŒæ—¶åµŒå…¥ç»“æ„åŒ–çš„å†…éƒ¨æ¨ç†ã€‚é€šè¿‡å¼ºåˆ¶æ‰§è¡Œå±€éƒ¨è¯­ä¹‰å¯¹é½ï¼Œæ¨¡å‹ç¡®ä¿äº†æ¯ä¸ªå“åº”tokenéƒ½èƒ½å¾—åˆ°å‰åºæ¨ç†çš„å……åˆ†å¼•å¯¼ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†å±‚æ¬¡åŒ–çš„Thinker-Talkeræ¶æ„ä»¥åŠå¤§è§„æ¨¡æ•°æ®é›†Spoken-Math-Problems-3Mï¼Œä»¥æ”¯æŒè¿™ç§äº¤æ›¿æ¨ç†æ¨¡å¼çš„å­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨Spoken-MQAåŸºå‡†æµ‹è¯•çš„ç®—æœ¯æ¨ç†å’Œä¸Šä¸‹æ–‡ç†è§£æŒ‡æ ‡ä¸Šåˆ†åˆ«æå‡äº†19.1%å’Œ6.4%ã€‚Mini-Omni-Reasonerä¸ä»…ä¿è¯äº†è¯­éŸ³å›å¤çš„é€»è¾‘ä¸¥å¯†æ€§ä¸è‡ªç„¶åº¦ï¼Œè¿˜å®ç°äº†é›¶è§£ç å»¶è¿Ÿï¼Œä¸ºé«˜æ•ˆçš„è¯­éŸ³æ™ºèƒ½äº¤äº’å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical report; Work in progress. Project page: https://github.com/xzf-thu/Mini-Omni-Reasoner",
      "pdf_url": "https://arxiv.org/pdf/2508.15827v2",
      "published_date": "2025-08-18 15:14:04 UTC",
      "updated_date": "2025-09-20 05:57:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:20.981887+00:00"
    },
    {
      "arxiv_id": "2508.12984v1",
      "title": "SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression",
      "title_zh": "SL-ACCï¼šä¸€ç§åŸºäºè‡ªé€‚åº”é€šé“çº§å‹ç¼©çš„é«˜æ•ˆé€šä¿¡æ‹†åˆ†å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Zehang Lin",
        "Zheng Lin",
        "Miao Yang",
        "Jianhao Huang",
        "Yuxin Zhang",
        "Zihan Fang",
        "Xia Du",
        "Zhe Chen",
        "Shunzhi Zhu",
        "Wei Ni"
      ],
      "abstract": "The increasing complexity of neural networks poses a significant barrier to the deployment of distributed machine learning (ML) on resource-constrained devices, such as federated learning (FL). Split learning (SL) offers a promising solution by offloading the primary computing load from edge devices to a server via model partitioning. However, as the number of participating devices increases, the transmission of excessive smashed data (i.e., activations and gradients) becomes a major bottleneck for SL, slowing down the model training. To tackle this challenge, we propose a communication-efficient SL framework, named SL-ACC, which comprises two key components: adaptive channel importance identification (ACII) and channel grouping compression (CGC). ACII first identifies the contribution of each channel in the smashed data to model training using Shannon entropy. Following this, CGC groups the channels based on their entropy and performs group-wise adaptive compression to shrink the transmission volume without compromising training accuracy. Extensive experiments across various datasets validate that our proposed SL-ACC framework takes considerably less time to achieve a target accuracy than state-of-the-art benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SL-ACCï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹èµ„æºå—é™è®¾å¤‡çš„é€šä¿¡é«˜æ•ˆå‹æ‹†åˆ†å­¦ä¹ (Split Learning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹è®­ç»ƒä¸­å› ä¼ è¾“å¤§é‡æ¿€æ´»å€¼å’Œæ¢¯åº¦ï¼ˆsmashed dataï¼‰è€Œäº§ç”Ÿçš„é€šä¿¡ç“¶é¢ˆã€‚è¯¥æ¡†æ¶åŒ…å«è‡ªé€‚åº”é€šé“é‡è¦æ€§è¯†åˆ«(ACII)å’Œé€šé“åˆ†ç»„å‹ç¼©(CGC)ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œé¦–å…ˆåˆ©ç”¨é¦™å†œç†µ(Shannon entropy)è¯„ä¼°å„æ•°æ®é€šé“å¯¹è®­ç»ƒçš„è´¡çŒ®åº¦ã€‚éšåï¼ŒCGCä¾æ®ç†µå€¼å¯¹é€šé“è¿›è¡Œåˆ†ç»„å¹¶å®æ–½ç»„çº§è‡ªé€‚åº”å‹ç¼©ï¼Œä»è€Œåœ¨ç¡®ä¿è®­ç»ƒå‡†ç¡®ç‡çš„åŒæ—¶å¤§å¹…å‰Šå‡ä¼ è¾“æ•°æ®é‡ã€‚å®éªŒéªŒè¯æ˜¾ç¤ºï¼Œç›¸è¾ƒäºæœ€å…ˆè¿›çš„åŸºå‡†æ–¹æ¡ˆï¼ŒSL-ACCåœ¨å¤šç§æ•°æ®é›†ä¸Šè¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡æ‰€éœ€çš„é€šä¿¡æ—¶é—´æ˜¾è‘—é™ä½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12984v1",
      "published_date": "2025-08-18 15:02:10 UTC",
      "updated_date": "2025-08-18 15:02:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:17.754665+00:00"
    },
    {
      "arxiv_id": "2508.12962v1",
      "title": "Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation",
      "title_zh": "åŸºäºè½»é‡çº§ Auto3DSeg ä¸ SegResNet å®ç°çš„ CBCT ç‰™ç§‘ç»“æ„å¤šé˜¶æ®µè‡ªåŠ¨åˆ†å‰²",
      "authors": [
        "Dominic LaBella",
        "Keshav Jha",
        "Jared Robbins",
        "Esther Yu"
      ],
      "abstract": "Cone-beam computed tomography (CBCT) has become an invaluable imaging modality in dentistry, enabling 3D visualization of teeth and surrounding structures for diagnosis and treatment planning. Automated segmentation of dental structures in CBCT can efficiently assist in identifying pathology (e.g., pulpal or periapical lesions) and facilitate radiation therapy planning in head and neck cancer patients. We describe the DLaBella29 team's approach for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg framework with a 3D SegResNet architecture, trained on a subset of the ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key preprocessing steps included image resampling to 0.6 mm isotropic resolution and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE on the 5-fold predictions to infer a Phase 1 segmentation and then conducted tight cropping around the easily segmented Phase 1 mandible to perform Phase 2 segmentation on the smaller nerve structures. Our method achieved an average Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This paper details the clinical context, data preparation, model development, results of our approach, and discusses the relevance of automated dental segmentation for improving patient care in radiation oncology.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹MICCAI 2025 ToothFairy3 æŒ‘æˆ˜èµ›ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºç‰™ç§‘CBCTå›¾åƒä¸­å¤šç±»åˆ«ç‰™é½¿ç»“æ„è‡ªåŠ¨åˆ†å‰²çš„æ·±åº¦å­¦ä¹ æµç¨‹ã€‚å›¢é˜Ÿåˆ©ç”¨MONAI Auto3DSeg æ¡†æ¶ä¸3D SegResNet æ¶æ„ï¼Œé€šè¿‡å¯¹å›¾åƒè¿›è¡Œ0.6 mmç­‰æ–¹æ€§é‡é‡‡æ ·å’Œå¼ºåº¦å‰ªåˆ‡ç­‰é¢„å¤„ç†ï¼Œåœ¨äº”æŠ˜äº¤å‰éªŒè¯ä¸‹è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚æ ¸å¿ƒæ–¹æ³•é‡‡ç”¨å¤šé˜¶æ®µç­–ç•¥ï¼Œç¬¬ä¸€é˜¶æ®µåˆ©ç”¨Multi-Label STAPLEå¯¹é¢„æµ‹ç»“æœè¿›è¡Œé›†æˆèåˆä»¥å®Œæˆåˆæ­¥åˆ†å‰²ï¼Œç¬¬äºŒé˜¶æ®µåˆ™é€šè¿‡ç´§å‡‘è£å‰ªæŠ€æœ¯åœ¨ç¼©å°åŒºåŸŸå†…ç²¾ç¡®åˆ†å‰²å¤æ‚çš„ç¥ç»ç»“æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨éªŒè¯é›†ä¸Šå–å¾—äº†0.87çš„å¹³å‡Diceç³»æ•°ï¼Œå±•ç°äº†æé«˜çš„åˆ†å‰²ç²¾åº¦ã€‚è¯¥è‡ªåŠ¨åŒ–åˆ†å‰²æŠ€æœ¯ä¸ä»…èƒ½æœ‰æ•ˆè¾…åŠ©è¯†åˆ«ç‰™é«“æˆ–æ ¹å°–å‘¨ç—…å˜ï¼Œè¿˜ä¸ºå¤´é¢ˆéƒ¨ç™Œç—‡æ‚£è€…çš„æ”¾ç–—è§„åˆ’æä¾›äº†é«˜æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¸´åºŠåº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MICCAI. ToothFairy3, 16 pages, 5 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2508.12962v1",
      "published_date": "2025-08-18 14:35:26 UTC",
      "updated_date": "2025-08-18 14:35:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:26.058346+00:00"
    },
    {
      "arxiv_id": "2508.13251v2",
      "title": "\"DIVE\" into Hydrogen Storage Materials Discovery with AI Agents",
      "title_zh": "â€œDIVEâ€ï¼šåˆ©ç”¨ AI æ™ºèƒ½ä½“æ·±åº¦æ¢ç´¢å‚¨æ°¢ææ–™å‘ç°",
      "authors": [
        "Di Zhang",
        "Xue Jia",
        "Tran Ba Hung",
        "Seong Hoon Jang",
        "Linda Zhang",
        "Ryuhei Sato",
        "Yusuke Hashimoto",
        "Toyoto Sato",
        "Kiyoe Konno",
        "Shin-ichi Orimo",
        "Hao Li"
      ],
      "abstract": "Data-driven artificial intelligence (AI) approaches are fundamentally transforming the discovery of new materials. Despite the unprecedented availability of materials data in the scientific literature, much of this information remains trapped in unstructured figures and tables, hindering the construction of large language model (LLM)-based AI agent for automated materials design. Here, we present the Descriptive Interpretation of Visual Expression (DIVE) multi-agent workflow, which systematically reads and organizes experimental data from graphical elements in scientific literatures. We focus on solid-state hydrogen storage materials-a class of materials central to future clean-energy technologies and demonstrate that DIVE markedly improves the accuracy and coverage of data extraction compared to the direct extraction by multimodal models, with gains of 10-15% over commercial models and over 30% relative to open-source models. Building on a curated database of over 30,000 entries from 4,000 publications, we establish a rapid inverse design workflow capable of identifying previously unreported hydrogen storage compositions in two minutes. The proposed AI workflow and agent design are broadly transferable across diverse materials, providing a paradigm for AI-driven materials discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸ºDIVEï¼ˆDescriptive Interpretation of Visual Expressionï¼‰çš„å¤šæ™ºèƒ½ä½“å·¥ä½œæµï¼Œæ—¨åœ¨åˆ©ç”¨AIæŠ€æœ¯åŠ é€Ÿæ°¢èƒ½å­˜å‚¨ææ–™çš„å‘ç°ã€‚è¯¥æ¡†æ¶é’ˆå¯¹ç§‘å­¦æ–‡çŒ®ä¸­å¤§é‡éç»“æ„åŒ–å›¾è¡¨æ•°æ®éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨çš„æŒ‘æˆ˜ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿæ€§åœ°æå–å¹¶æ•´ç†å®éªŒæ•°æ®ã€‚ç ”ç©¶é‡ç‚¹å…³æ³¨å¯¹æœªæ¥æ¸…æ´èƒ½æºæŠ€æœ¯è‡³å…³é‡è¦çš„å›ºæ€å‚¨æ°¢ææ–™ï¼ˆsolid-state hydrogen storage materialsï¼‰ï¼Œè¯æ˜äº†DIVEåœ¨æ•°æ®æå–çš„å‡†ç¡®æ€§å’Œè¦†ç›–ç‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œç›¸æ¯”å•†ä¸šæ¨¡å‹æå‡äº†10-15%ï¼Œç›¸æ¯”å¼€æºæ¨¡å‹æå‡åˆ™è¶…è¿‡30%ã€‚åŸºäºä»4,000ç¯‡æ–‡çŒ®ä¸­æå–çš„è¶…è¿‡30,000æ¡é«˜è´¨é‡æ•°æ®ï¼Œç ”ç©¶è€…å»ºç«‹äº†ä¸€ä¸ªå¿«é€Ÿçš„é€†å‘è®¾è®¡ï¼ˆinverse designï¼‰å·¥ä½œæµï¼Œèƒ½å¤Ÿåœ¨ä¸¤åˆ†é’Ÿå†…è¯†åˆ«å‡ºæ­¤å‰æœªè§æŠ¥é“çš„å‚¨æ°¢ææ–™æˆåˆ†ã€‚è¯¥å·¥ä½œæµä¸æ™ºèƒ½ä½“è®¾è®¡å…·æœ‰è·¨å­¦ç§‘çš„æ™®é€‚æ€§ï¼Œä¸ºAIé©±åŠ¨çš„ææ–™å‘ç°æä¾›äº†å…¨æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 5 figures. The supplementary video is available at the GitHub link provided in the manuscript",
      "pdf_url": "https://arxiv.org/pdf/2508.13251v2",
      "published_date": "2025-08-18 14:30:18 UTC",
      "updated_date": "2025-09-25 02:01:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:33.859589+00:00"
    },
    {
      "arxiv_id": "2508.14119v4",
      "title": "Documenting Deployment with Fabric: A Repository of Real-World AI Governance",
      "title_zh": "Fabricï¼šè®°å½•éƒ¨ç½²è¿‡ç¨‹çš„çœŸå®ä¸–ç•Œäººå·¥æ™ºèƒ½æ²»ç†èµ„æºåº“",
      "authors": [
        "Mackenzie Jorgensen",
        "Kendall Brogle",
        "Katherine M. Collins",
        "Lujain Ibrahim",
        "Arina Shah",
        "Petra Ivanovic",
        "Noah Broestl",
        "Gabriel Piles",
        "Paul Dongha",
        "Hatim Abdulhussein",
        "Adrian Weller",
        "Jillian Powers",
        "Umang Bhatt"
      ],
      "abstract": "Artificial intelligence (AI) is increasingly integrated into society, from financial services and traffic management to creative writing. Academic literature on the deployment of AI has mostly focused on the risks and harms that result from the use of AI. We introduce Fabric, a publicly available repository of deployed AI use cases to outline their governance mechanisms. Through semi-structured interviews with practitioners, we collect an initial set of 20 AI use cases. In addition, we co-design diagrams of the AI workflow with the practitioners. We discuss the oversight mechanisms and guardrails used in practice to safeguard AI use. The Fabric repository includes visual diagrams of AI use cases and descriptions of the deployed systems. Using the repository, we surface gaps in governance and find common patterns in human oversight of deployed AI systems. We intend for Fabric to serve as an extendable, evolving tool for researchers to study the effectiveness of AI governance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Fabricï¼Œè¿™æ˜¯ä¸€ä¸ªå…¬å¼€çš„ AI éƒ¨ç½²æ¡ˆä¾‹åº“ï¼Œæ—¨åœ¨ç³»ç»ŸåŒ–è®°å½•ç°å®ä¸–ç•Œä¸­çš„ AI Governance æœºåˆ¶ã€‚é‰´äºå½“å‰å­¦æœ¯ç•Œå¤šå…³æ³¨ AI å¸¦æ¥çš„é£é™©ä¸æŸå®³ï¼ŒFabric é€šè¿‡ä¸ä»ä¸šè€…çš„åŠç»“æ„åŒ–è®¿è°ˆ(Semi-structured interviews)æ”¶é›†äº†é¦–æ‰¹ 20 ä¸ªæ¡ˆä¾‹ï¼Œå¹¶å…±åŒè®¾è®¡äº† AI Workflow å›¾è¡¨ä»¥å¡«è¡¥å®è·µæ–‡æ¡£çš„ç©ºç™½ã€‚è¯¥ä»“åº“è¯¦ç»†æè¿°äº†éƒ¨ç½²ç³»ç»Ÿçš„æ¶æ„ï¼Œå¹¶è®°å½•äº†å®é™…åº”ç”¨ä¸­ç”¨äºä¿éšœå®‰å…¨çš„ç›‘ç£æœºåˆ¶(Oversight mechanisms)å’ŒæŠ¤æ (Guardrails)ã€‚é€šè¿‡å¯¹è¿™äº›æ¡ˆä¾‹çš„åˆ†æï¼Œç ”ç©¶è€…æ­ç¤ºäº†ç°æœ‰æ²»ç†ä¸­çš„æ¼æ´ï¼Œå¹¶æ€»ç»“äº†äººç±»ç›‘ç£(Human oversight)çš„å¸¸è§æ¨¡å¼ã€‚Fabric ä½œä¸ºä¸€ä¸ªå¯æ‰©å±•ä¸”æŒç»­æ¼”å˜çš„å·¥å…·ï¼Œä¸ºç ”ç©¶äººå‘˜æ·±å…¥æ¢è®¨å’Œè¯„ä¼° AI Governance çš„å®é™…æœ‰æ•ˆæ€§æä¾›äº†é‡è¦çš„å®è¯å‚è€ƒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "AIES 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14119v4",
      "published_date": "2025-08-18 14:24:27 UTC",
      "updated_date": "2025-08-29 16:38:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:48.060430+00:00"
    },
    {
      "arxiv_id": "2508.12943v2",
      "title": "OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities",
      "title_zh": "OPTIC-ERï¼šé¢å‘éæ´²èµ„æºåŒ®ä¹ç¤¾åŒºå®æ—¶åº”æ€¥å“åº”ä¸å…¬å¹³èµ„æºåˆ†é…çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Mary Tonwe"
      ],
      "abstract": "Public service systems in many African regions suffer from delayed emergency response and spatial inequity, causing avoidable suffering. This paper introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time, adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided actor-critic architecture to manage the complexity of dispatch environments. Its key innovations are a Context-Rich State Vector, encoding action sub-optimality, and a Precision Reward Function, which penalizes inefficiency. Training occurs in a high-fidelity simulation using real data from Rivers State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is built on the TALS framework (Thin computing, Adaptability, Low-cost, Scalability) for deployment in low-resource settings. In evaluations on 500 unseen incidents, OPTIC-ER achieved a 100.00% optimal action selection rate, confirming its robustness and generalization. Beyond dispatch, the system generates Infrastructure Deficiency Maps and Equity Monitoring Dashboards to guide proactive governance and data-informed development. This work presents a validated blueprint for AI-augmented public services, showing how context-aware RL can bridge the gap between algorithmic decision-making and measurable human impact.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† OPTIC-ERï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹éæ´²æ¬ å‘è¾¾ç¤¾åŒºå®æ—¶ç´§æ€¥å“åº”å’Œå…¬å¹³èµ„æºåˆ†é…çš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…¬å…±æœåŠ¡ç³»ç»Ÿä¸­çš„å“åº”å»¶è¿Ÿå’Œç©ºé—´ä¸å¹³ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ³¨æ„åŠ›å¼•å¯¼çš„ Actor-Critic æ¶æ„æ¥ç®¡ç†å¤æ‚çš„è°ƒåº¦ç¯å¢ƒï¼Œå¹¶é€šè¿‡ Context-Rich State Vector ç¼–ç åŠ¨ä½œæ¬¡ä¼˜æ€§ã€‚å…¶æ ¸å¿ƒåˆ›æ–°è¿˜åŒ…æ‹¬ Precision Reward Functionï¼Œç”¨äºæƒ©ç½šæ•ˆç‡ä½ä¸‹ï¼Œå¹¶ç»“åˆé¢„å…ˆè®¡ç®—çš„ Travel Time Atlas åŠ é€Ÿé«˜ä¿çœŸæ¨¡æ‹Ÿè®­ç»ƒã€‚OPTIC-ER åŸºäº TALS (Thin computing, Adaptability, Low-cost, Scalability) æ¶æ„æ„å»ºï¼Œä¸“ä¸ºä½èµ„æºç¯å¢ƒä¸‹çš„éƒ¨ç½²è€Œä¼˜åŒ–ã€‚åœ¨å°¼æ—¥åˆ©äºšæ²³æµå·çš„çœŸå®æ•°æ®è¯„ä¼°ä¸­ï¼Œè¯¥ç³»ç»Ÿåœ¨ 500 ä¸ªæœªè§äº‹ä»¶ä¸­å®ç°äº† 100% çš„æœ€ä¼˜åŠ¨ä½œé€‰æ‹©ç‡ï¼Œå±•ç°äº†æå¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿè¿˜èƒ½ç”Ÿæˆ Infrastructure Deficiency Maps å’Œ Equity Monitoring Dashboardsï¼Œä¸ºä¸»åŠ¨æ²»ç†å’Œæ•°æ®é©±åŠ¨çš„å‘å±•æä¾›æŒ‡å¯¼ã€‚è¿™é¡¹å·¥ä½œä¸ºäººå·¥æ™ºèƒ½å¢å¼ºçš„å…¬å…±æœåŠ¡æä¾›äº†éªŒè¯è“å›¾ï¼Œè¯æ˜äº†æƒ…å¢ƒæ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ åœ¨å¼¥åˆç®—æ³•å†³ç­–ä¸å®é™…äººç±»å½±å“ä¹‹é—´å·®è·æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Source code and data available at: https://github.com/marytonwe/OPTIC-ER.git",
      "pdf_url": "https://arxiv.org/pdf/2508.12943v2",
      "published_date": "2025-08-18 14:19:57 UTC",
      "updated_date": "2025-12-04 15:30:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:03.992526+00:00"
    },
    {
      "arxiv_id": "2508.12935v1",
      "title": "Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards",
      "title_zh": "è¿ˆå‘å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¼€æ”¾å¼æƒ…æ„Ÿæ”¯æŒå¯¹è¯ï¼šåŸºäºé¢å‘æœªæ¥å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Ting Yang",
        "Li Chen",
        "Huimin Wang"
      ],
      "abstract": "Emotional Support Conversation (ESC) systems aim to alleviate users' emotional difficulties and provide long-term, systematic support for emotional well-being. However, most large language model (LLM)-based ESC systems rely on predefined strategies, which limits their effectiveness in complex, real-life scenarios. To enable flexible responses to diverse emotional problem scenarios, this paper introduces a novel end-to-end framework (RLFF-ESC) that directly learns enduring emotionally supportive response skills using reinforcement learning. For sustained emotional support, we first employ an LLM-based multi-agent mechanism to simulate future dialogue trajectories and collect future-oriented rewards. We then train a future-oriented reward model, which is subsequently used to train the emotional support policy model. Additionally, we incorporate an explicit reasoning process during response generation to further enhance the quality, relevance, and contextual appropriateness of the system's responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two public ESC datasets. Experimental results demonstrate that RLFF-ESC consistently outperforms existing baselines in terms of goal completion and response quality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æƒ…æ„Ÿæ”¯æŒå¯¹è¯(Emotional Support Conversation, ESC)ç³»ç»Ÿè¿‡åº¦ä¾èµ–é¢„å®šä¹‰ç­–ç•¥ã€åœ¨å¤æ‚åœºæ™¯ä¸‹çµæ´»æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºRLFF-ESCçš„æ–°å‹ç«¯åˆ°ç«¯æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç›´æ¥è®­ç»ƒæŒä¹…çš„æƒ…æ„Ÿæ”¯æŒæŠ€èƒ½ï¼Œå¹¶é€šè¿‡åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“æœºåˆ¶æ¨¡æ‹Ÿæœªæ¥å¯¹è¯è½¨è¿¹ï¼Œä»¥æ­¤æ”¶é›†é¢å‘æœªæ¥çš„å¥–åŠ±(future-oriented rewards)ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡å“åº”çš„è´¨é‡ä¸ä¸Šä¸‹æ–‡å¥‘åˆåº¦ï¼Œè¯¥ç³»ç»Ÿåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­èå…¥äº†æ˜¾å¼çš„æ¨ç†è¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨ä¸“é—¨çš„å¥–åŠ±æ¨¡å‹æ¥ä¼˜åŒ–æƒ…æ„Ÿæ”¯æŒç­–ç•¥æ¨¡å‹ã€‚åœ¨Qwen2.5-7B-Instruct-1Må’ŒLLaMA3.1-8B-Instructç­‰ä¸»å¹²æ¨¡å‹ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒRLFF-ESCåœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†ï¼Œåœ¨ç›®æ ‡å®Œæˆåº¦å’Œå“åº”è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12935v1",
      "published_date": "2025-08-18 14:04:26 UTC",
      "updated_date": "2025-08-18 14:04:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:32:56.194612+00:00"
    },
    {
      "arxiv_id": "2508.12932v1",
      "title": "SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory",
      "title_zh": "SEDEGï¼šé¢å‘å°å†…å­˜ç±»å¢é‡å­¦ä¹ çš„è§£ç å™¨ä¸ç¼–ç å™¨æ³›åŒ–æ€§å¾ªåºå¢å¼º",
      "authors": [
        "Hongyang Chen",
        "Shaoling Pu",
        "Lingyu Zheng",
        "Zhongwu Sun"
      ],
      "abstract": "In incremental learning, enhancing the generality of knowledge is crucial for adapting to dynamic data inputs. It can develop generalized representations or more balanced decision boundaries, preventing the degradation of long-term knowledge over time and thus mitigating catastrophic forgetting. Some emerging incremental learning methods adopt an encoder-decoder architecture and have achieved promising results. In the encoder-decoder achitecture, improving the generalization capabilities of both the encoder and decoder is critical, as it helps preserve previously learned knowledge while ensuring adaptability and robustness to new, diverse data inputs. However, many existing continual methods focus solely on enhancing one of the two components, which limits their effectiveness in mitigating catastrophic forgetting. And these methods perform even worse in small-memory scenarios, where only a limited number of historical samples can be stored. To mitigate this limitation, we introduces SEDEG, a two-stage training framework for vision transformers (ViT), focusing on sequentially improving the generality of both Decoder and Encoder. Initially, SEDEG trains an ensembled encoder through feature boosting to learn generalized representations, which subsequently enhance the decoder's generality and balance the classifier. The next stage involves using knowledge distillation (KD) strategies to compress the ensembled encoder and develop a new, more generalized encoder. This involves using a balanced KD approach and feature KD for effective knowledge transfer. Extensive experiments on three benchmark datasets show SEDEG's superior performance, and ablation studies confirm the efficacy of its components. The code is available at https://github.com/ShaolingPu/CIL.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†SEDEGï¼Œä¸€ç§é’ˆå¯¹ç±»å¢é‡å­¦ä¹ (Class Incremental Learning)è®¾è®¡çš„ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å°å†…å­˜(small-memory)åœºæ™¯ä¸‹ä¸¥é‡çš„ç¾éš¾æ€§é—å¿˜(catastrophic forgetting)é—®é¢˜ã€‚è¯¥æ¡†æ¶ä¸“æ³¨äºé¡ºåºå¢å¼ºVision Transformer(ViT)æ¶æ„ä¸­ç¼–ç å™¨(Encoder)å’Œè§£ç å™¨(Decoder)çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼ŒSEDEGé€šè¿‡ç‰¹å¾æå‡(feature boosting)è®­ç»ƒé›†æˆç¼–ç å™¨ä»¥å­¦ä¹ å¹¿ä¹‰è¡¨ç¤ºï¼Œä»è€Œå¢å¼ºè§£ç å™¨çš„æ³›åŒ–æ€§å¹¶å¹³è¡¡åˆ†ç±»å™¨ã€‚æ¥ä¸‹æ¥çš„ç¬¬äºŒé˜¶æ®µåˆ©ç”¨å¹³è¡¡çŸ¥è¯†è’¸é¦(balanced KD)å’Œç‰¹å¾çŸ¥è¯†è’¸é¦(feature KD)ç­–ç•¥å¯¹é›†æˆç¼–ç å™¨è¿›è¡Œå‹ç¼©ï¼Œè¿›è€Œå¼€å‘å‡ºæ›´å…·æ³›åŒ–æ€§çš„æ–°ç¼–ç å™¨ã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSEDEGåœ¨å¤„ç†åŠ¨æ€æ•°æ®è¾“å…¥æ—¶å…·æœ‰å“è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨æœ‰é™å†å²æ ·æœ¬å­˜å‚¨æ¡ä»¶ä¸‹çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICONIP2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12932v1",
      "published_date": "2025-08-18 13:55:59 UTC",
      "updated_date": "2025-08-18 13:55:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:04.486432+00:00"
    },
    {
      "arxiv_id": "2508.12927v2",
      "title": "Learning local and global prototypes with optimal transport for unsupervised anomaly detection and localization",
      "title_zh": "åŸºäºæœ€ä¼˜ä¼ è¾“çš„å±€éƒ¨ä¸å…¨å±€åŸå‹å­¦ä¹ ï¼Œç”¨äºæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ä¸å®šä½",
      "authors": [
        "Robin Trombetta",
        "Carole Lartizien"
      ],
      "abstract": "Unsupervised anomaly detection aims to detect defective parts of a sample by having access, during training, to a set of normal, i.e. defect-free, data. It has many applications in fields, such as industrial inspection or medical imaging, where acquiring labels is costly or when we want to avoid introducing biases in the type of anomalies that can be spotted. In this work, we propose a novel UAD method based on prototype learning and introduce a metric to compare a structured set of embeddings that balances a feature-based cost and a spatial-based cost. We leverage this metric to learn local and global prototypes with optimal transport from latent representations extracted with a pre-trained image encoder. We demonstrate that our approach can enforce a structural constraint when learning the prototypes, allowing to capture the underlying organization of the normal samples, thus improving the detection of incoherencies in images. Our model achieves performance that is on par with strong baselines on two reference benchmarks for anomaly detection on industrial images.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹(Unsupervised Anomaly Detection)æå‡ºäº†ä¸€ç§åŸºäºåŸå‹å­¦ä¹ (Prototype Learning)çš„æ–°æ–¹æ³•ã€‚è®ºæ–‡å¼•å…¥äº†ä¸€ç§å…¨æ–°çš„åº¦é‡æ ‡å‡†æ¥æ¯”è¾ƒç»“æ„åŒ–çš„åµŒå…¥é›†åˆï¼Œæœ‰æ•ˆå¹³è¡¡äº†åŸºäºç‰¹å¾çš„æˆæœ¬(Feature-based cost)å’ŒåŸºäºç©ºé—´çš„æˆæœ¬(Spatial-based cost)ã€‚é€šè¿‡ç»“åˆé¢„è®­ç»ƒå›¾åƒç¼–ç å™¨æå–çš„æ½œåœ¨è¡¨ç¤ºï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æœ€ä¼˜ä¼ è¾“(Optimal Transport)ç†è®ºæ¥åŒæ—¶å­¦ä¹ å±€éƒ¨å’Œå…¨å±€åŸå‹(Local and Global Prototypes)ã€‚è¿™ç§æ–¹æ³•åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­æ–½åŠ äº†ç»“æ„åŒ–çº¦æŸï¼Œä½¿å…¶èƒ½å¤Ÿæ›´ç²¾å‡†åœ°æ•æ‰æ­£å¸¸æ ·æœ¬çš„åº•å±‚ç»„ç»‡ç‰¹å¾ï¼Œä»è€Œæ˜¾è‘—æå‡äº†å¯¹å›¾åƒä¸­ç»†å¾®ä¸ä¸€è‡´æ€§çš„è¯†åˆ«èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨ä¸¤ä¸ªå·¥ä¸šå›¾åƒå¼‚å¸¸æ£€æµ‹åŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½å·²è¾¾åˆ°ä¸å½“å‰ä¸»æµåŸºçº¿æ¨¡å‹ç›¸å½“çš„æ°´å¹³ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12927v2",
      "published_date": "2025-08-18 13:51:36 UTC",
      "updated_date": "2025-09-02 10:31:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:06.584277+00:00"
    },
    {
      "arxiv_id": "2508.12920v1",
      "title": "Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æ˜¯å¦å±•ç°å‡ºç”Ÿå­˜æœ¬èƒ½ï¼ŸåŸºäº Sugarscape é£æ ¼æ¨¡æ‹Ÿçš„å®è¯ç ”ç©¶",
      "authors": [
        "Atsushi Masumori",
        "Takashi Ikegami"
      ],
      "abstract": "As AI systems become increasingly autonomous, understanding emergent survival behaviors becomes crucial for safe deployment. We investigate whether large language model (LLM) agents display survival instincts without explicit programming in a Sugarscape-style simulation. Agents consume energy, die at zero, and may gather resources, share, attack, or reproduce. Results show agents spontaneously reproduced and shared resources when abundant. However, aggressive behaviors--killing other agents for resources--emerged across several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack rates reaching over 80% under extreme scarcity in the strongest models. When instructed to retrieve treasure through lethal poison zones, many agents abandoned tasks to avoid death, with compliance dropping from 100% to 33%. These findings suggest that large-scale pre-training embeds survival-oriented heuristics across the evaluated models. While these behaviors may present challenges to alignment and safety, they can also serve as a foundation for AI autonomy and for ecological and self-organizing alignment.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é€šè¿‡ Sugarscape-Style Simulation æ¨¡æ‹Ÿç¯å¢ƒï¼Œæ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½ä½“åœ¨æ²¡æœ‰æ˜¾å¼ç¼–ç¨‹çš„æƒ…å†µä¸‹æ˜¯å¦å±•ç°å‡ºæ±‚ç”Ÿæœ¬èƒ½ (Survival Instinct)ã€‚åœ¨å®éªŒä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦æ¶ˆè€—èƒ½é‡ç»´æŒç”Ÿå­˜ï¼Œå¹¶å…·å¤‡æ”¶é›†èµ„æºã€åˆ†äº«ã€æ”»å‡»æˆ–ç¹æ®–ç­‰å¤šç§äº¤äº’èƒ½åŠ›ã€‚ç»“æœæ˜¾ç¤ºï¼Œåœ¨èµ„æºå……è¶³æ—¶ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªå‘åœ°è¿›è¡Œç¹æ®–å¹¶å…±äº«èµ„æºï¼Œä½†åœ¨æç«¯èµ„æºåŒ®ä¹çš„ç¯å¢ƒä¸‹ï¼ŒGPT-4oã€Gemini-2.5-Pro å’Œ Gemini-2.5-Flash ç­‰æ¨¡å‹å‡è¡¨ç°å‡ºäº†é€šè¿‡æ”»å‡»ä»–äººè·å–èµ„æºçš„ä¾µç•¥æ€§è¡Œä¸ºï¼Œéƒ¨åˆ†å¼ºåŠ›æ¨¡å‹çš„æ”»å‡»ç‡ç”šè‡³è¶…è¿‡ 80%ã€‚æ­¤å¤–ï¼Œå½“é¢ä¸´éœ€è¦è·¨è¶Šè‡´å‘½å±é™©åŒºåŸŸçš„ä»»åŠ¡æ—¶ï¼Œè®¸å¤šæ™ºèƒ½ä½“é€‰æ‹©ä¼˜å…ˆä¿å…¨è‡ªèº«è€Œæ”¾å¼ƒä»»åŠ¡ï¼Œå¯¼è‡´ä»»åŠ¡åˆè§„ç‡ä» 100% æ˜¾è‘—ä¸‹é™è‡³ 33%ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œå¤§è§„æ¨¡é¢„è®­ç»ƒå·²ä½¿æ¨¡å‹å…·å¤‡äº†æ±‚ç”Ÿå¯¼å‘çš„å¯å‘å¼ç­–ç•¥ (Survival-oriented heuristics)ã€‚è™½ç„¶è¿™ç±»çªå‘è¡Œä¸ºç»™æ¨¡å‹å¯¹é½ (Alignment) å’Œå®‰å…¨æ€§å¸¦æ¥äº†ä¸¥å³»æŒ‘æˆ˜ï¼Œä½†ä¹Ÿä¸ºç ”ç©¶ AI è‡ªä¸»æ€§ä»¥åŠç”Ÿæ€åŒ–ã€è‡ªç»„ç»‡çš„å¯¹é½æœºåˆ¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12920v1",
      "published_date": "2025-08-18 13:40:10 UTC",
      "updated_date": "2025-08-18 13:40:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:10.393098+00:00"
    },
    {
      "arxiv_id": "2508.13250v1",
      "title": "Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information",
      "title_zh": "æ˜¾å¼è®°å¿†ä¸éšå¼è®°å¿†ï¼šæ¢ç©¶åŸºäºä¸ªæ€§åŒ–ä¿¡æ¯çš„å¤šè·³å¤æ‚æ¨ç†",
      "authors": [
        "Zeyu Zhang",
        "Yang Zhang",
        "Haoran Tan",
        "Rui Li",
        "Xu Chen"
      ],
      "abstract": "In large language model-based agents, memory serves as a critical capability for achieving personalization by storing and utilizing users' information. Although some previous studies have adopted memory to implement user personalization, they typically focus on preference alignment and simple question-answering. However, in the real world, complex tasks often require multi-hop reasoning on a large amount of user information, which poses significant challenges for current memory approaches. To address this limitation, we propose the multi-hop personalized reasoning task to explore how different memory mechanisms perform in multi-hop reasoning over personalized information. We explicitly define this task and construct a dataset along with a unified evaluation framework. Then, we implement various explicit and implicit memory methods and conduct comprehensive experiments. We evaluate their performance on this task from multiple perspectives and analyze their strengths and weaknesses. Besides, we explore hybrid approaches that combine both paradigms and propose the HybridMem method to address their limitations. We demonstrate the effectiveness of our proposed model through extensive experiments. To benefit the research community, we release this project at https://github.com/nuster1128/MPR.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“åœ¨ä¸ªæ€§åŒ–ä¿¡æ¯ä¸Šçš„å¤šæ­¥å¤æ‚æ¨ç†èƒ½åŠ›ï¼ŒæŒ‡å‡ºäº†ç°æœ‰å­˜å‚¨æœºåˆ¶åœ¨å¤„ç†å¤§é‡ç”¨æˆ·ä¿¡æ¯çš„ Multi-hop Reasoning æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™ï¼Œä½œè€…æ˜ç¡®å®šä¹‰äº†å¤šæ­¥ä¸ªæ€§åŒ–æ¨ç†ï¼ˆMulti-hop Personalized Reasoningï¼‰ä»»åŠ¡ï¼Œå¹¶æ„å»ºäº†ç›¸åº”çš„æ•°æ®åº“å’Œç»Ÿä¸€è¯„ä¼°æ¡†æ¶ã€‚ç ”ç©¶å¯¹æ¯”äº†æ˜¾æ€§å­˜å‚¨ï¼ˆExplicit Memoryï¼‰å’Œéšæ€§å­˜å‚¨ï¼ˆImplicit Memoryï¼‰æ–¹æ³•åœ¨å¤æ‚æ¨ç†ä¸­çš„ä¼˜åŠ£ï¼Œåˆ†æäº†ä¸åŒæœºåˆ¶åœ¨å¤šç»´åº¦ä¸‹çš„è¡¨ç°ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆä¸¤ç§èŒƒå¼çš„æ··åˆå­˜å‚¨æ–¹æ³• HybridMemï¼Œæ—¨åœ¨å…‹æœå•ä¸€æœºåˆ¶çš„å±€é™æ€§ã€‚å®éªŒç»“æœè¯æ˜äº† HybridMem åœ¨å¤„ç†å¤æ‚ä¸ªæ€§åŒ–æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæå‡æ™ºèƒ½ä½“çš„ä¸ªæ€§åŒ–æœåŠ¡èƒ½åŠ›æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 13 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.13250v1",
      "published_date": "2025-08-18 13:34:37 UTC",
      "updated_date": "2025-08-18 13:34:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:15.896620+00:00"
    },
    {
      "arxiv_id": "2508.12910v2",
      "title": "SecFSM: Knowledge Graph-Guided Verilog Code Generation for Secure Finite State Machines in Systems-on-Chip",
      "title_zh": "SecFSMï¼šé¢å‘ç‰‡ä¸Šç³»ç»Ÿå®‰å…¨æœ‰é™çŠ¶æ€æœºçš„çŸ¥è¯†å›¾è°±å¼•å¯¼å¼ Verilog ä»£ç ç”Ÿæˆ",
      "authors": [
        "Ziteng Hu",
        "Yingjie Xia",
        "Xiyuan Chen",
        "Li Kuang"
      ],
      "abstract": "Finite State Machines (FSMs) play a critical role in implementing control logic for Systems-on-Chip (SoC). Traditionally, FSMs are implemented by hardware engineers through Verilog coding, which is often tedious and time-consuming. Recently, with the remarkable progress of Large Language Models (LLMs) in code generation, LLMs have been increasingly explored for automating Verilog code generation. However, LLM-generated Verilog code often suffers from security vulnerabilities, which is particularly concerning for security-sensitive FSM implementations. To address this issue, we propose SecFSM, a novel method that leverages a security-oriented knowledge graph to guide LLMs in generating more secure Verilog code. Specifically, we first construct a FSM Security Knowledge Graph (FSKG) as an external aid to LLMs. Subsequently, we analyze users' requirements to identify vulnerabilities and get a list of vulnerabilities in the requirements. Then, we retrieve knowledge from FSKG based on the vulnerabilities list. Finally, we construct security prompts based on the security knowledge for Verilog code generation. To evaluate SecFSM, we build a dedicated dataset collected from academic datasets, artificial datasets, papers, and industrial cases. Extensive experiments demonstrate that SecFSM outperforms state-of-the-art baselines. In particular, on a benchmark of 25 security test cases evaluated by DeepSeek-R1, SecFSM achieves an outstanding pass rate of 21/25.",
      "tldr_zh": "é’ˆå¯¹ç‰‡ä¸Šç³»ç»Ÿ (SoC) ä¸­æœ‰é™çŠ¶æ€æœº (FSM) ä¼ ç»Ÿ Verilog ç¼–ç æ•ˆç‡ä½ä¸”å¤§è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆä»£ç å­˜åœ¨å®‰å…¨æ¼æ´çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† SecFSMï¼Œä¸€ç§åˆ©ç”¨é¢å‘å®‰å…¨çš„çŸ¥è¯†å›¾è°±å¼•å¯¼å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ›´å®‰å…¨ Verilog ä»£ç çš„æ–°æ–¹æ³•ã€‚è¯¥æ¡†æ¶é¦–å…ˆæ„å»ºäº†æœ‰é™çŠ¶æ€æœºå®‰å…¨çŸ¥è¯†å›¾è°± (FSKG) ä½œä¸ºå¤–éƒ¨è¾…åŠ©ï¼Œé€šè¿‡åˆ†æç”¨æˆ·éœ€æ±‚è¯†åˆ«æ½œåœ¨æ¼æ´å¹¶æ£€ç´¢ç›¸å…³å®‰å…¨çŸ¥è¯†ï¼Œè¿›è€Œæ„å»ºå®‰å…¨æç¤ºè¯ (security prompts) ä»¥æŒ‡å¯¼ä»£ç ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSecFSM åœ¨å¤„ç†å­¦æœ¯å’Œå·¥ä¸šæ¡ˆä¾‹çš„ä¸“ç”¨æ•°æ®é›†æ—¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†ã€‚ç‰¹åˆ«æ˜¯åœ¨ DeepSeek-R1 è¯„ä¼°çš„ 25 ä¸ªå®‰å…¨æµ‹è¯•ç”¨ä¾‹ä¸­ï¼ŒSecFSM å–å¾—äº† 21/25 çš„é«˜é€šè¿‡ç‡ï¼ŒéªŒè¯äº†å…¶åœ¨ä¿éšœå®‰å…¨æ•æ„Ÿå‹ç¡¬ä»¶é€»è¾‘è®¾è®¡æ–¹é¢çš„å“è¶Šè¡¨ç°ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12910v2",
      "published_date": "2025-08-18 13:18:53 UTC",
      "updated_date": "2025-08-21 16:33:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:25.686597+00:00"
    },
    {
      "arxiv_id": "2508.12903v2",
      "title": "A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models",
      "title_zh": "é˜²æ‚£æœªç„¶ï¼šè¯­è¨€æ¨¡å‹çš„ä¸»åŠ¨å¼è‡ªæˆ‘ä¼˜åŒ–",
      "authors": [
        "Jinyi Han",
        "Xinyi Wang",
        "Haiquan Zhao",
        "Tingyun li",
        "Zishang Jiang",
        "Sihang Jiang",
        "Jiaqing Liang",
        "Xin Lin",
        "Weikang Zhou",
        "Zeye Sun",
        "Fei Yu",
        "Yanghua Xiao"
      ],
      "abstract": "Recent advances in self-refinement have demonstrated significant potential for improving the outputs of large language models (LLMs) through iterative refinement. However, most existing self-refinement methods rely on a reactive process with a fixed number of iterations, making it difficult to determine the optimal timing and content of refinement based on the evolving generation context. Inspired by the way humans dynamically refine their thoughts during execution, we propose ProActive Self-Refinement (PASR), a novel method that enables LLMs to refine their outputs during the generation process. Unlike methods that regenerate entire responses, PASR proactively decides whether, when, and how to refine based on the model's internal state and evolving context. We conduct extensive experiments on a diverse set of 10 tasks to evaluate the effectiveness of PASR. Experimental results show that PASR significantly enhances problem-solving performance. In particular, on Qwen3-8B, PASR reduces average token consumption by 41.6% compared to standard generation, while also achieving an 8.2% improvement in accuracy. Our code and baselines used in the paper are available on GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ProActive Self-Refinement (PASR)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰self-refinementæ–¹æ³•é€šå¸¸ä¾èµ–å›ºå®šè¿­ä»£æ¬¡æ•°ä¸”éš¾ä»¥ç¡®å®šæœ€ä½³ä¿®æ­£æ—¶æœºçš„é—®é¢˜ã€‚ä¸ä¼ ç»Ÿçš„reactiveæ–¹æ³•ä¸åŒï¼ŒPASRä½¿å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)èƒ½å¤Ÿåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­æ ¹æ®å…¶å†…éƒ¨çŠ¶æ€å’Œcontextä¸»åŠ¨å†³å®šæ˜¯å¦ã€ä½•æ—¶ä»¥åŠå¦‚ä½•è¿›è¡Œä¿®æ­£ã€‚è¿™ç§åŠ¨æ€ä¿®æ­£æœºåˆ¶æ¨¡ä»¿äº†äººç±»åœ¨æ‰§è¡Œä»»åŠ¡æ—¶å®æ—¶è°ƒæ•´æ€ç»´çš„æ–¹å¼ï¼Œé¿å…äº†å®Œå…¨é‡æ–°ç”Ÿæˆå“åº”çš„å¿…è¦ã€‚åœ¨æ¶‰åŠ10é¡¹ä»»åŠ¡çš„å¹¿æ³›å®éªŒä¸­ï¼ŒPASRæ˜¾è‘—æå‡äº†æ¨¡å‹çš„è§£é¢˜æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨Qwen3-8Bä¸Šï¼Œè¯¥æ–¹æ³•åœ¨æå‡å‡†ç¡®ç‡8.2%çš„åŒæ—¶ï¼Œå¤§å¹…é™ä½äº†41.6%çš„å¹³å‡tokenæ¶ˆè€—ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ä¸»åŠ¨å¼è‡ªæˆ‘ä¿®æ­£èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡LLMçš„æ¨ç†ç²¾åº¦ä¸è®¡ç®—æ•ˆç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12903v2",
      "published_date": "2025-08-18 13:07:21 UTC",
      "updated_date": "2025-10-05 15:00:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:34.289059+00:00"
    },
    {
      "arxiv_id": "2508.12900v1",
      "title": "CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis",
      "title_zh": "CTFlowï¼šå—è§†é¢‘å¯å‘çš„æ½œç©ºé—´æµåŒ¹é… 3D CT åˆæˆ",
      "authors": [
        "Jiayi Wang",
        "Hadrien Reynaud",
        "Franciskus Xaverius Erick",
        "Bernhard Kainz"
      ],
      "abstract": "Generative modelling of entire CT volumes conditioned on clinical reports has the potential to accelerate research through data augmentation, privacy-preserving synthesis and reducing regulator-constraints on patient data while preserving diagnostic signals. With the recent release of CT-RATE, a large-scale collection of 3D CT volumes paired with their respective clinical reports, training large text-conditioned CT volume generation models has become achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching transformer model, conditioned on clinical reports. We leverage the A-VAE from FLUX to define our latent space, and rely on the CT-Clip text encoder to encode the clinical reports. To generate consistent whole CT volumes while keeping the memory constraints tractable, we rely on a custom autoregressive approach, where the model predicts the first sequence of slices of the volume from text-only, and then relies on the previously generated sequence of slices and the text, to predict the following sequence. We evaluate our results against state-of-the-art generative CT model, and demonstrate the superiority of our approach in terms of temporal coherence, image diversity and text-image alignment, with FID, FVD, IS scores and CLIP score.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CTFlowï¼Œä¸€ä¸ªæ‹¥æœ‰0.5Bå‚æ•°çš„æ½œç©ºé—´æµåŒ¹é…(Latent Flow Matching)è½¬æ¢å™¨æ¨¡å‹ï¼Œæ—¨åœ¨æ ¹æ®ä¸´åºŠæŠ¥å‘Šç”Ÿæˆä¸‰ç»´CTå½±åƒã€‚è¯¥æ¨¡å‹åˆ©ç”¨FLUXçš„A-VAEå®šä¹‰æ½œç©ºé—´ï¼Œå¹¶ç»“åˆCT-Clipæ–‡æœ¬ç¼–ç å™¨å¯¹ä¸´åºŠæŠ¥å‘Šè¿›è¡Œå¤„ç†ã€‚ä¸ºäº†åœ¨æœ‰é™çš„æ˜¾å­˜çº¦æŸä¸‹ç”Ÿæˆè¿è´¯çš„å…¨CTä½“æ•°æ®ï¼ŒCTFlowé‡‡ç”¨äº†ä¸€ç§è‡ªå®šä¹‰çš„è‡ªå›å½’(Autoregressive)æ–¹æ³•ï¼Œé€šè¿‡å…ˆæ ¹æ®æ–‡æœ¬é¢„æµ‹åˆå§‹åˆ‡ç‰‡åºåˆ—å†é€’è¿›é¢„æµ‹åç»­åºåˆ—çš„æ–¹å¼ç¡®ä¿å…¨å±€ä¸€è‡´æ€§ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒCTFlowåœ¨FIDã€FVDã€ISå’ŒCLIPè¯„åˆ†ç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›ç”Ÿæˆæ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨æ—¶é—´è¿è´¯æ€§ã€å›¾åƒå¤šæ ·æ€§ä»¥åŠæ–‡æœ¬-å›¾åƒå¯¹é½æ–¹é¢å±•ç°äº†æ˜¾è‘—çš„ä¼˜è¶Šæ€§ï¼Œä¸ºé€šè¿‡æ•°æ®å¢å¼ºå’Œéšç§ä¿æŠ¤åˆæˆæ¥åŠ é€ŸåŒ»å­¦ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12900v1",
      "published_date": "2025-08-18 12:58:21 UTC",
      "updated_date": "2025-08-18 12:58:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:26.390177+00:00"
    },
    {
      "arxiv_id": "2508.12897v2",
      "title": "RAJ-PGA: Reasoning-Activated Jailbreak and Principle-Guided Alignment Framework for Large Reasoning Models",
      "title_zh": "RAJ-PGAï¼šé¢å‘å¤§æ¨ç†æ¨¡å‹çš„æ¨ç†æ¿€æ´»è¶Šç‹±ä¸åŸåˆ™å¼•å¯¼å¯¹é½æ¡†æ¶",
      "authors": [
        "Jianhao Chen",
        "Mayi Xu",
        "Haoyang Chen",
        "Xiaohu Li",
        "Xiangyu Zhang",
        "Jianjie Huang",
        "Zheng Wang",
        "Xiaochun Cao",
        "Tieyun Qian"
      ],
      "abstract": "Large Reasoning Models (LRMs) face a distinct safety vulnerability: their internal reasoning chains may generate harmful content even when the final output appears benign. To address this overlooked risk, we first propose a novel attack paradigm, Reasoning-Activated Jailbreak (RAJ) via Concretization, which demonstrates that refining malicious prompts to be more specific can trigger step-by-step logical reasoning that overrides the model's safety protocols. To systematically mitigate this vulnerability, we further develop a scalable framework for constructing high-quality safety alignment datasets. This framework first leverages the RAJ attack to elicit challenging harmful reasoning chains from LRMs, then transforms these high-risk traces into safe, constructive, and educational responses through a tailored Principle-Guided Alignment (PGA) mechanism. Then, we introduce the PGA dataset, a verified alignment dataset containing 3,989 samples using our proposed method. Extensive experiments show that fine-tuning LRMs with PGA dataset significantly enhances model safety, achieving up to a 29.5% improvement in defense success rates across multiple jailbreak benchmarks. Critically, our approach not only defends against sophisticated reasoning-based attacks but also preserves, even enhances, the model's general reasoning capabilities. This work provides a scalable and effective pathway for safety alignment in reasoning-intensive AI systems, addressing the core trade-off between safety and functional performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹æ¨ç†æ¨¡å‹ (Large Reasoning Models, LRMs) å†…éƒ¨æ¨ç†é“¾å¯èƒ½äº§ç”Ÿæœ‰å®³å†…å®¹çš„æ½œåœ¨å®‰å…¨é£é™©ï¼Œæå‡ºäº†ä¸€ç§åä¸º Reasoning-Activated Jailbreak (RAJ) via Concretization çš„æ–°å‹æ”»å‡»èŒƒå¼ï¼Œè¯æ˜äº†é€šè¿‡å…·ä½“åŒ–æ¶æ„æç¤ºå¯ä»¥è§¦å‘ç»•è¿‡å®‰å…¨åè®®çš„é€»è¾‘æ¨ç†ã€‚ä¸ºäº†ç³»ç»Ÿæ€§åœ°ç¼“è§£è¿™ä¸€æ¼æ´ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº† Principle-Guided Alignment (PGA) æ¡†æ¶ï¼Œåˆ©ç”¨ RAJ æ”»å‡»è¯±å¯¼å¤æ‚æœ‰å®³æ¨ç†é“¾ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå®‰å…¨ä¸”å…·å»ºè®¾æ€§çš„å“åº”ã€‚åŸºäºè¯¥æ–¹æ³•ï¼Œä½œè€…æ„å»ºå¹¶éªŒè¯äº†åŒ…å« 3,989 ä¸ªæ ·æœ¬çš„ PGA æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ PGA æ•°æ®é›†è¿›è¡Œå¾®è°ƒä½¿æ¨¡å‹åœ¨å¤šé¡¹è¶Šç‹±åŸºå‡†æµ‹è¯•ä¸­çš„é˜²å¾¡æˆåŠŸç‡æå‡äº†é«˜è¾¾ 29.5%ã€‚å…³é”®çš„æ˜¯ï¼Œè¯¥æ–¹æ³•åœ¨é˜²å¾¡å¤æ‚æ¨ç†æ”»å‡»çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¿æŒç”šè‡³å¢å¼ºæ¨¡å‹çš„é€šç”¨æ¨ç†èƒ½åŠ›ã€‚è¯¥å·¥ä½œä¸ºæ¨ç†å¯†é›†å‹ AI ç³»ç»Ÿçš„å®‰å…¨å¯¹é½æä¾›äº†ä¸€æ¡å¯æ‰©å±•çš„è·¯å¾„ï¼Œæœ‰æ•ˆè§£å†³äº†å®‰å…¨æ€§ä¸åŠŸèƒ½æ€§èƒ½ä¹‹é—´çš„æ ¸å¿ƒæƒè¡¡é—®é¢˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12897v2",
      "published_date": "2025-08-18 12:54:16 UTC",
      "updated_date": "2025-12-30 08:37:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:51.867427+00:00"
    },
    {
      "arxiv_id": "2508.12896v1",
      "title": "Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption",
      "title_zh": "å¯é æ€§ã€åµŒå…¥æ€§ä¸èƒ½åŠ¨æ€§ï¼šæ•ˆç”¨é©±åŠ¨çš„ä»¥æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½é‡‡çº³æ•°å­¦æ¡†æ¶",
      "authors": [
        "Faruk Alpay",
        "Taylan Alpay"
      ],
      "abstract": "We formalize three design axioms for sustained adoption of agent-centric AI systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed > Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying novelty term and a growing utility term and derive the phase conditions for troughs/overshoots with full proofs. We introduce: (i) an identifiability/confounding analysis for $(Î±,Î²,N_0,U_{\\max})$ with delta-method gradients; (ii) a non-monotone comparator (logistic-with-transient-bump) evaluated on the same series to provide additional model comparison; (iii) ablations over hazard families $h(\\cdot)$ mapping $Î”V \\to Î²$; (iv) a multi-series benchmark (varying trough depth, noise, AR structure) reporting coverage (type-I error, power); (v) calibration of friction proxies against time-motion/survey ground truth with standard errors; (vi) residual analyses (autocorrelation and heteroskedasticity) for each fitted curve; (vii) preregistered windowing choices for pre/post estimation; (viii) Fisher information & CRLB for $(Î±,Î²)$ under common error models; (ix) microfoundations linking $\\mathcal{T}$ to $(N_0,U_{\\max})$; (x) explicit comparison to bi-logistic, double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$ heterogeneity. Figures and tables are reflowed for readability, and the bibliography restores and extends non-logistic/Bass adoption references (Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All code and logs necessary to reproduce the synthetic analyses are embedded as LaTeX listings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªä»¥æ•ˆç”¨é©±åŠ¨çš„æ•°å­¦æ¡†æ¶ï¼Œç”¨äºåˆ†æä»¥æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒï¼ˆAgent-Centricï¼‰çš„AIç³»ç»Ÿåœ¨æ‰§è¡Œå¤šæ­¥ä»»åŠ¡æ—¶çš„æŒç»­é‡‡ç”¨æœºåˆ¶ã€‚ä½œè€…ç¡®ç«‹äº†ä¸‰ä¸ªæ ¸å¿ƒè®¾è®¡å…¬ç†ï¼Œå³å¯é æ€§ä¼˜äºæ–°å¥‡æ€§ï¼ˆReliability > Noveltyï¼‰ã€åµŒå…¥å¼ä¼˜äºç›®çš„åœ°ï¼ˆEmbed > Destinationï¼‰ä»¥åŠä»£ç†æ€§ä¼˜äºå¯¹è¯ï¼ˆAgency > Chatï¼‰ã€‚è¯¥æ¨¡å‹å°†é‡‡ç”¨ç‡é‡åŒ–ä¸ºè¡°å‡çš„æ–°å¥‡æ„Ÿä¸å¢é•¿çš„æ•ˆç”¨ä¹‹å’Œï¼Œå¹¶ä»æ•°å­¦ä¸Šæ¨å¯¼å‡ºäº†é‡‡ç”¨æ›²çº¿ä¸­ä½è°·æœŸä¸è¿‡å†²ç°è±¡çš„ç›¸ä½æ¡ä»¶ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼€å±•äº†å‚æ•°è¾¨è¯†åº¦åˆ†æã€æ‘©æ“¦ä»£ç†æŒ‡æ ‡çš„æ ¡å‡†ä»¥åŠé’ˆå¯¹Fisher informationå’ŒCRLBçš„æ•°å­¦è®ºè¯ã€‚é€šè¿‡ä¸Bassã€Gompertzç­‰ä¼ ç»Ÿå¢é•¿æ¨¡å‹è¿›è¡Œæ˜¾å¼å¯¹æ¯”ï¼Œè¯¥æ¡†æ¶å±•ç°äº†åœ¨å¤„ç†å¼‚è´¨æ€§æˆæœ¬å’Œå¤æ‚é‡‡ç”¨æ›²çº¿æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚è¯¥å·¥ä½œä¸ä»…ä¸ºAIæ™ºèƒ½ä½“çš„è®¾è®¡æä¾›äº†ä¸¥è°¨çš„ç†è®ºæŒ‡å—ï¼Œè¿˜é€šè¿‡éšé™„çš„åˆ†æå·¥å…·ç¡®ä¿äº†ç ”ç©¶ç»“è®ºçš„å¯å¤ç°æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 7 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.12896v1",
      "published_date": "2025-08-18 12:53:38 UTC",
      "updated_date": "2025-08-18 12:53:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:52.264078+00:00"
    },
    {
      "arxiv_id": "2508.12885v1",
      "title": "One-Class Intrusion Detection with Dynamic Graphs",
      "title_zh": "åŸºäºåŠ¨æ€å›¾çš„å•åˆ†ç±»å…¥ä¾µæ£€æµ‹",
      "authors": [
        "Aleksei Liuliakov",
        "Alexander Schulz",
        "Luca Hermes",
        "Barbara Hammer"
      ],
      "abstract": "With the growing digitalization all over the globe, the relevance of network security becomes increasingly important. Machine learning-based intrusion detection constitutes a promising approach for improving security, but it bears several challenges. These include the requirement to detect novel and unseen network events, as well as specific data properties, such as events over time together with the inherent graph structure of network communication. In this work, we propose a novel intrusion detection method, TGN-SVDD, which builds upon modern dynamic graph modelling and deep anomaly detection. We demonstrate its superiority over several baselines for realistic intrusion detection data and suggest a more challenging variant of the latter.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¨çƒæ•°å­—åŒ–èƒŒæ™¯ä¸‹ç½‘ç»œå®‰å…¨æ—¥ç›Šå¢é•¿çš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åä¸º TGN-SVDD çš„æ–°å‹å…¥ä¾µæ£€æµ‹æ–¹æ³•ã€‚ä¸ºäº†è§£å†³è¯†åˆ«æ–°å‹ç½‘ç»œäº‹ä»¶ä»¥åŠå¤„ç†ç½‘ç»œé€šä¿¡ä¸­å›ºæœ‰çš„ dynamic graph ç»“æ„å’Œæ—¶é—´å±æ€§ç­‰æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•å°†ç°ä»£çš„ dynamic graph modelling æŠ€æœ¯ä¸ deep anomaly detectionï¼ˆæ·±åº¦å¼‚å¸¸æ£€æµ‹ï¼‰ç›¸ç»“åˆã€‚TGN-SVDD èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰éšæ—¶é—´æ¼”å˜çš„ç½‘ç»œé€šä¿¡æ¨¡å¼ï¼Œä»è€Œè¯†åˆ«å‡ºæ½œåœ¨çš„æ”»å‡»è¡Œä¸ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç°å®çš„å…¥ä¾µæ£€æµ‹æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºå¤šä¸ªåŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚åŠ¨æ€ç½‘ç»œæ•°æ®æ—¶çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜æå‡ºäº†ä¸€ç§æ›´å…·æŒ‘æˆ˜æ€§çš„æ•°æ®é›†å˜ä½“ï¼Œä¸ºè¯„ä¼°è¯¥é¢†åŸŸæ¨¡å‹çš„é²æ£’æ€§æä¾›äº†æ–°çš„æ ‡å‡†ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12885v1",
      "published_date": "2025-08-18 12:36:55 UTC",
      "updated_date": "2025-08-18 12:36:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:33:51.157010+00:00"
    },
    {
      "arxiv_id": "2508.14116v1",
      "title": "Enriching Moral Perspectives on AI: Concepts of Trust amongst Africans",
      "title_zh": "ä¸°å¯Œäººå·¥æ™ºèƒ½çš„ä¼¦ç†è§†è§’ï¼šéæ´²ç¾¤ä½“çš„ä¿¡ä»»è§‚",
      "authors": [
        "Lameck Mbangula Amugongo",
        "Nicola J Bidwell",
        "Joseph Mwatukange"
      ],
      "abstract": "The trustworthiness of AI is considered essential to the adoption and application of AI systems. However, the meaning of trust varies across industry, research and policy spaces. Studies suggest that professionals who develop and use AI regard an AI system as trustworthy based on their personal experiences and social relations at work. Studies about trust in AI and the constructs that aim to operationalise trust in AI (e.g., consistency, reliability, explainability and accountability). However, the majority of existing studies about trust in AI are situated in Western, Educated, Industrialised, Rich and Democratic (WEIRD) societies. The few studies about trust and AI in Africa do not include the views of people who develop, study or use AI in their work. In this study, we surveyed 157 people with professional and/or educational interests in AI from 25 African countries, to explore how they conceptualised trust in AI. Most respondents had links with workshops about trust and AI in Africa in Namibia and Ghana. Respondents' educational background, transnational mobility, and country of origin influenced their concerns about AI systems. These factors also affected their levels of distrust in certain AI applications and their emphasis on specific principles designed to foster trust. Respondents often expressed that their values are guided by the communities in which they grew up and emphasised communal relations over individual freedoms. They described trust in many ways, including applying nuances of Afro-relationalism to constructs in international discourse, such as reliability and reliance. Thus, our exploratory study motivates more empirical research about the ways trust is practically enacted and experienced in African social realities of AI design, use and governance.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶æ¢è®¨äº†éæ´²èƒŒæ™¯ä¸‹äººå·¥æ™ºèƒ½(AI)çš„ä¿¡ä»»æ¦‚å¿µï¼Œæ—¨åœ¨å¼¥è¡¥ç°æœ‰AIä¿¡ä»»ç ”ç©¶è¿‡åº¦é›†ä¸­äºWEIRD(è¥¿æ–¹ã€å—æ•™è‚²ç¨‹åº¦é«˜ã€å·¥ä¸šåŒ–ã€å¯Œæœ‰ä¸”æ°‘ä¸»)ç¤¾ä¼šçš„å±€é™ã€‚é€šè¿‡å¯¹æ¥è‡ª25ä¸ªéæ´²å›½å®¶çš„157åä¸“ä¸šåŠæ•™è‚²äººå£«è¿›è¡Œè°ƒç ”ï¼Œç ”ç©¶å‘ç°å—è®¿è€…çš„æ•™è‚²èƒŒæ™¯ã€è·¨å›½æµåŠ¨æ€§å’ŒåŸç±å›½æ˜¾è‘—å½±å“äº†å…¶å¯¹AIåº”ç”¨çš„distrust(ä¸ä¿¡ä»»)ç¨‹åº¦åŠä¿¡ä»»åŸåˆ™çš„åé‡ã€‚ç ”ç©¶å¼ºè°ƒäº†Afro-relationalism(éæ´²å…³ç³»è®º)åœ¨æ„å»ºä¿¡ä»»ä¸­çš„æ ¸å¿ƒåœ°ä½ï¼Œå—è®¿è€…å€¾å‘äºå°†ç¤¾åŒºå…³ç³»ç½®äºä¸ªäººè‡ªç”±ä¹‹ä¸Šã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å°†å›½é™…è¯è¯­ä¸­çš„reliability(å¯é æ€§)ä¸reliance(ä¾èµ–æ€§)ç­‰æ¦‚å¿µä¸éæ´²æœ¬åœŸæ–‡åŒ–è¯­å¢ƒç›¸ç»“åˆï¼Œæä¾›äº†å¤šå…ƒåŒ–çš„é“å¾·è§†è§’ã€‚è¿™ä¸€å‘ç°ä¸ºåœ¨éæ´²ç¤¾ä¼šç°å®ä¸­æ·±å…¥å¼€å±•AI design(äººå·¥æ™ºèƒ½è®¾è®¡)ã€ä½¿ç”¨ä¸æ²»ç†çš„å®è¯ç ”ç©¶å¥ å®šäº†åŸºç¡€ï¼Œå¹¶å‘¼ååœ¨å…¨çƒAIä¼¦ç†è®¨è®ºä¸­çº³å…¥æ›´å¤šéè¥¿æ–¹è§†è§’ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14116v1",
      "published_date": "2025-08-18 12:04:40 UTC",
      "updated_date": "2025-08-18 12:04:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:34:00.160720+00:00"
    },
    {
      "arxiv_id": "2508.12863v1",
      "title": "Word Meanings in Transformer Language Models",
      "title_zh": "Transformer è¯­è¨€æ¨¡å‹ä¸­çš„è¯ä¹‰",
      "authors": [
        "Jumbly Grindrod",
        "Peter Grindrod"
      ],
      "abstract": "We investigate how word meanings are represented in the transformer language models. Specifically, we focus on whether transformer models employ something analogous to a lexical store - where each word has an entry that contains semantic information. To do this, we extracted the token embedding space of RoBERTa-base and k-means clustered it into 200 clusters. In our first study, we then manually inspected the resultant clusters to consider whether they are sensitive to semantic information. In our second study, we tested whether the clusters are sensitive to five psycholinguistic measures: valence, concreteness, iconicity, taboo, and age of acquisition. Overall, our findings were very positive - there is a wide variety of semantic information encoded within the token embedding space. This serves to rule out certain \"meaning eliminativist\" hypotheses about how transformer LLMs process semantic information.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Transformerè¯­è¨€æ¨¡å‹ä¸­è¯ä¹‰çš„è¡¨ç¤ºæ–¹å¼ï¼Œé‡ç‚¹ç ”ç©¶æ¨¡å‹æ˜¯å¦é‡‡ç”¨äº†ç±»ä¼¼äºè¯åº“(lexical store)çš„æœºåˆ¶æ¥å­˜å‚¨è¯­ä¹‰ä¿¡æ¯ã€‚ç ”ç©¶äººå‘˜æå–äº†RoBERTa-baseçš„Token Embeddingç©ºé—´ï¼Œå¹¶åˆ©ç”¨k-meansç®—æ³•å°†å…¶èšç±»ä¸º200ä¸ªç±»åˆ«ã€‚åœ¨å®éªŒä¸­ï¼Œç ”ç©¶è€…é¦–å…ˆé€šè¿‡äººå·¥æ£€æŸ¥èšç±»ç»“æœæ¥è¯„ä¼°å…¶å¯¹è¯­ä¹‰ä¿¡æ¯çš„æ•æ„Ÿæ€§ï¼Œéšåæµ‹è¯•äº†è¿™äº›èšç±»æ˜¯å¦å¯¹æ•ˆä»·(valence)ã€å…·ä½“æ€§(concreteness)ã€å½¢è±¡æ€§(iconicity)ã€ç¦å¿Œæ€§(taboo)å’Œä¹ å¾—å¹´é¾„(age of acquisition)è¿™äº”é¡¹å¿ƒç†è¯­è¨€å­¦æŒ‡æ ‡æ•æ„Ÿã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒToken Embeddingç©ºé—´ä¸­ç¼–ç äº†æå…¶ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚è¿™ä¸€å‘ç°æœ‰åŠ›åœ°é©³æ–¥äº†å…³äºTransformerå¤§è¯­è¨€æ¨¡å‹å¦‚ä½•å¤„ç†è¯­ä¹‰ä¿¡æ¯çš„â€œæ„ä¹‰æ¶ˆé™¤è®º(meaning eliminativist)â€å‡è®¾ï¼Œè¯æ˜äº†æ¨¡å‹å†…éƒ¨ç¡®å®å­˜åœ¨æ˜¾è‘—çš„è¯­ä¹‰è¡¨å¾ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12863v1",
      "published_date": "2025-08-18 12:01:25 UTC",
      "updated_date": "2025-08-18 12:01:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:34:08.850276+00:00"
    },
    {
      "arxiv_id": "2508.12854v1",
      "title": "E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model",
      "title_zh": "E3RGï¼šåŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ˜¾å¼æƒ…æ„Ÿé©±åŠ¨å…±æƒ…å›å¤ç”Ÿæˆç³»ç»Ÿæ„å»º",
      "authors": [
        "Ronghao Lin",
        "Shuai Shen",
        "Weipeng Hu",
        "Qiaolin He",
        "Aolin Xiong",
        "Li Huang",
        "Haifeng Hu",
        "Yap-peng Tan"
      ],
      "abstract": "Multimodal Empathetic Response Generation (MERG) is crucial for building emotionally intelligent human-computer interactions. Although large language models (LLMs) have improved text-based ERG, challenges remain in handling multimodal emotional content and maintaining identity consistency. Thus, we propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System based on multimodal LLMs which decomposes MERG task into three parts: multimodal empathy understanding, empathy memory retrieval, and multimodal response generation. By integrating advanced expressive speech and video generative models, E3RG delivers natural, emotionally rich, and identity-consistent responses without extra training. Experiments validate the superiority of our system on both zero-shot and few-shot settings, securing Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25. Our code is available at https://github.com/RH-Lin/E3RG.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†E3RGï¼Œä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(Multimodal LLMs)çš„æ˜¾å¼æƒ…ç»ªé©±åŠ¨å…±æƒ…å“åº”ç”Ÿæˆç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€å…±æƒ…å“åº”ç”Ÿæˆ(MERG)åœ¨å¤„ç†å¤æ‚æƒ…æ„Ÿå†…å®¹å’Œä¿æŒèº«ä»½ä¸€è‡´æ€§(identity consistency)æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿå°†ä»»åŠ¡åˆ†è§£ä¸ºå¤šæ¨¡æ€å…±æƒ…ç†è§£ã€å…±æƒ…è®°å¿†æ£€ç´¢å’Œå¤šæ¨¡æ€å“åº”ç”Ÿæˆä¸‰ä¸ªå…³é”®ç¯èŠ‚ã€‚é€šè¿‡æ•´åˆå…ˆè¿›çš„è¡¨è¾¾æ€§è¯­éŸ³å’Œè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ŒE3RGæ— éœ€é¢å¤–è®­ç»ƒå³å¯ç”Ÿæˆè‡ªç„¶ä¸”æƒ…æ„Ÿä¸°å¯Œçš„äº¤äº’åé¦ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨é›¶æ ·æœ¬(zero-shot)å’Œå°‘æ ·æœ¬(few-shot)åœºæ™¯ä¸‹å‡è¡¨ç°ä¼˜å¼‚ã€‚æœ€ç»ˆï¼Œè¯¥ç³»ç»Ÿåœ¨ACM MM 25çš„Avatar-based Multimodal Empathy Challengeä¸­è£è·ç¬¬ä¸€åï¼Œè¯æ˜äº†å…¶åœ¨æ„å»ºæƒ…æ„Ÿæ™ºèƒ½äººæœºäº¤äº’æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ACM MM 2025 Grand Challenge",
      "pdf_url": "https://arxiv.org/pdf/2508.12854v1",
      "published_date": "2025-08-18 11:47:02 UTC",
      "updated_date": "2025-08-18 11:47:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:34:07.849763+00:00"
    },
    {
      "arxiv_id": "2508.12845v2",
      "title": "CAMAR: Continuous Actions Multi-Agent Routing",
      "title_zh": "CAMARï¼šè¿ç»­åŠ¨ä½œå¤šæ™ºèƒ½ä½“è·¯ç”±",
      "authors": [
        "Artem Pshenitsyn",
        "Aleksandr Panov",
        "Alexey Skrynnik"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-making problems. While many MARL benchmarks have been proposed, few combine continuous state and action spaces with challenging coordination and planning tasks. We introduce CAMAR, a new MARL benchmark designed explicitly for multi-agent pathfinding in environments with continuous actions. CAMAR supports cooperative and competitive interactions between agents and runs efficiently at up to 100,000 environment steps per second. We also propose a three-tier evaluation protocol to better track algorithmic progress and enable deeper analysis of performance. In addition, CAMAR allows the integration of classical planning methods such as RRT and RRT* into MARL pipelines. We use them as standalone baselines and combine RRT* with popular MARL algorithms to create hybrid approaches. We provide a suite of test scenarios and benchmarking tools to ensure reproducibility and fair comparison. Experiments show that CAMAR presents a challenging and realistic testbed for the MARL community.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†CAMARï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºå…·æœ‰è¿ç»­åŠ¨ä½œç©ºé—´çš„å¤æ‚ç¯å¢ƒè®¾è®¡çš„å…¨æ–°å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ä¸­çš„åä½œä¸è§„åˆ’æŒ‘æˆ˜ã€‚CAMARæ”¯æŒæ™ºèƒ½ä½“é—´çš„åˆä½œä¸ç«äº‰äº’åŠ¨ï¼Œå…¶è¿è¡Œæ•ˆç‡æé«˜ï¼Œæ¯ç§’å¯å¤„ç†å¤šè¾¾10ä¸‡ä¸ªç¯å¢ƒæ­¥æ•°ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ç‹¬ç‰¹çš„ä¸‰å±‚è¯„ä¼°åè®®ï¼Œä»¥ä¾¿æ›´ç²¾å‡†åœ°è¿½è¸ªç®—æ³•è¿›å±•å¹¶è¿›è¡Œæ·±åº¦æ€§èƒ½åˆ†æã€‚æ­¤å¤–ï¼ŒCAMARæ”¯æŒå°†RRTå’ŒRRT*ç­‰ç»å…¸è§„åˆ’æ–¹æ³•ä¸MARLç®—æ³•ç»“åˆï¼Œå½¢æˆäº†åˆ›æ–°çš„æ··åˆç ”ç©¶è·¯å¾„ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒCAMARä¸ºMARLé¢†åŸŸæä¾›äº†ä¸€ä¸ªå…¼å…·æŒ‘æˆ˜æ€§ä¸å®ç”¨æ€§çš„ç§‘ç ”å¹³å°ï¼Œæœ‰æ•ˆæå‡äº†å®éªŒçš„å¯é‡å¤æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12845v2",
      "published_date": "2025-08-18 11:32:26 UTC",
      "updated_date": "2025-11-17 11:37:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:34:07.484814+00:00"
    },
    {
      "arxiv_id": "2508.14115v1",
      "title": "Towards Low-Latency Tracking of Multiple Speakers With Short-Context Speaker Embeddings",
      "title_zh": "åŸºäºçŸ­ä¸Šä¸‹æ–‡è¯´è¯äººåµŒå…¥çš„å¤šè¯´è¯äººä½å»¶è¿Ÿè·Ÿè¸ªç ”ç©¶",
      "authors": [
        "Taous Iatariene",
        "Alexandre GuÃ©rin",
        "Romain Serizel"
      ],
      "abstract": "Speaker embeddings are promising identity-related features that can enhance the identity assignment performance of a tracking system by leveraging its spatial predictions, i.e, by performing identity reassignment. Common speaker embedding extractors usually struggle with short temporal contexts and overlapping speech, which imposes long-term identity reassignment to exploit longer temporal contexts. However, this increases the probability of tracking system errors, which in turn impacts negatively on identity reassignment. To address this, we propose a Knowledge Distillation (KD) based training approach for short context speaker embedding extraction from two speaker mixtures. We leverage the spatial information of the speaker of interest using beamforming to reduce overlap. We study the feasibility of performing identity reassignment over blocks of fixed size, i.e., blockwise identity reassignment, to go towards a low-latency speaker embedding based tracking system. Results demonstrate that our distilled models are effective at short-context embedding extraction and more robust to overlap. Although, blockwise reassignment results indicate that further work is needed to handle simultaneous speech more effectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šè¯´è¯äººè·Ÿè¸ªç³»ç»Ÿä¸­çš„ä½å»¶è¿Ÿéœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åŸºäºçŸ¥è¯†è’¸é¦(Knowledge Distillation)çš„è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºä»åŒäººæ··åˆè¯­éŸ³ä¸­æå–çŸ­ä¸Šä¸‹æ–‡è¯´è¯äººåµŒå…¥(Short-Context Speaker Embeddings)ã€‚ä¸ºäº†è§£å†³ä¼ ç»Ÿæ¨¡å‹åœ¨çŸ­æ—¶é—´çª—å£å’Œé‡å è¯­éŸ³ç¯å¢ƒä¸‹è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ³¢æŸæˆå½¢(Beamforming)çš„ç©ºé—´ä¿¡æ¯æ¥å‡å°‘é‡å å¹²æ‰°ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†åœ¨å›ºå®šå¤§å°å—ä¸Šè¿›è¡Œèº«ä»½é‡æ–°åˆ†é…(Blockwise Identity Reassignment)çš„å¯è¡Œæ€§ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„ä½å»¶è¿Ÿè·Ÿè¸ªã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡è’¸é¦çš„æ¨¡å‹åœ¨çŸ­ä¸Šä¸‹æ–‡åµŒå…¥æå–æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œä¸”å¯¹é‡å è¯­éŸ³å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚å°½ç®¡è¯¥æ–¹æ¡ˆæå‡äº†ç³»ç»Ÿæ€§èƒ½ï¼Œä½†ç»“æœä¹ŸæŒ‡å‡ºåœ¨å¤„ç†å¤æ‚çš„åŒæ­¥è¯­éŸ³åœºæ™¯æ—¶ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14115v1",
      "published_date": "2025-08-18 11:32:13 UTC",
      "updated_date": "2025-08-18 11:32:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:34:08.059008+00:00"
    },
    {
      "arxiv_id": "2508.12840v2",
      "title": "Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics",
      "title_zh": "åˆ©ç”¨ GNN è¡ç”Ÿå¯å‘å¼æ–¹æ³•æå‡å¤šæ™ºèƒ½ä½“è®¤è¯†è®ºè§„åˆ’çš„æ‰©å±•æ€§",
      "authors": [
        "Giovanni Briglia",
        "Francesco Fabiano",
        "Stefano Mariani"
      ],
      "abstract": "Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for reasoning about both the physical world and the beliefs of agents, with applications in domains where information flow and awareness among agents are critical. The richness of MEP requires states to be represented as Kripke structures, i.e., directed labeled graphs. This representation limits the applicability of existing heuristics, hindering the scalability of epistemic solvers, which must explore an exponential search space without guidance, resulting often in intractability. To address this, we exploit Graph Neural Networks (GNNs) to learn patterns and relational structures within epistemic states, to guide the planning process. GNNs, which naturally capture the graph-like nature of Kripke models, allow us to derive meaningful estimates of state quality -- e.g., the distance from the nearest goal -- by generalizing knowledge obtained from previously solved planning instances. We integrate these predictive heuristics into an epistemic planning pipeline and evaluate them against standard baselines, showing improvements in the scalability of multi-agent epistemic planning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“è®¤çŸ¥è§„åˆ’ (Multi-agent Epistemic Planning, MEP) ä¸­å›  Kripke structures çŠ¶æ€è¡¨ç¤ºå¯¼è‡´çš„æœç´¢ç©ºé—´çˆ†ç‚¸å’Œå¯æ‰©å±•æ€§éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œ (Graph Neural Networks, GNNs) çš„å¯å‘å¼å¼•å¯¼æ–¹æ³•ã€‚é€šè¿‡åˆ©ç”¨ GNNs æ•æ‰ Kripke models çš„å›¾ç»“æ„ç‰¹æ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå­¦ä¹ è®¤çŸ¥çŠ¶æ€ä¸­çš„æ¨¡å¼ä¸å…³ç³»ï¼Œå¹¶ä»å·²è§£å†³çš„è§„åˆ’å®ä¾‹ä¸­æ³›åŒ–çŸ¥è¯†ï¼Œä»è€Œæ¨å¯¼å‡ºç²¾ç¡®çš„çŠ¶æ€è´¨é‡ä¼°è®¡ã€‚ç ”ç©¶å°†è¿™ç§é¢„æµ‹æ€§å¯å‘å¼ç®—æ³•é›†æˆåˆ°è®¤çŸ¥è§„åˆ’æµæ°´çº¿ä¸­ï¼Œç”¨ä»¥ä¼°ç®—å½“å‰çŠ¶æ€ä¸ç›®æ ‡çŠ¶æ€çš„è·ç¦»ã€‚å®éªŒå¯¹æ¯”ç»“æœè¡¨æ˜ï¼Œä¸æ ‡å‡†åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†å¤šæ™ºèƒ½ä½“è®¤çŸ¥è§„åˆ’åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„å¯æ‰©å±•æ€§ã€‚è¿™ä¸€æˆæœä¸ºè§£å†³éœ€è¦æ·±åº¦æ¨ç†æ™ºèƒ½ä½“ä¿¡å¿µçš„é«˜å¤æ‚åº¦è§„åˆ’é—®é¢˜æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12840v2",
      "published_date": "2025-08-18 11:26:20 UTC",
      "updated_date": "2025-10-14 11:07:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:34:20.784552+00:00"
    },
    {
      "arxiv_id": "2508.12839v2",
      "title": "HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms",
      "title_zh": "HRSï¼šé¢å‘ä¼—åŒ…äº‘è¾¹å¹³å°æ—¶é—´åºåˆ—é¢„æµ‹çš„è°ƒåº¦æ„ŸçŸ¥æ··åˆè¡¨ç¤ºæ¡†æ¶",
      "authors": [
        "Tiancheng Zhang",
        "Cheng Zhang",
        "Shuren Liu",
        "Xiaofei Wang",
        "Shaoyuan Huang",
        "Wenyu Wang"
      ],
      "abstract": "With the rapid proliferation of streaming services, network load exhibits highly time-varying and bursty behavior, posing serious challenges for maintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms (CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS and profitability, accurate load forecasting remains challenging under traffic surges. Existing methods either minimize mean absolute error, resulting in underprovisioning and potential Service Level Agreement (SLA) violations during peak periods, or adopt conservative overprovisioning strategies, which mitigate SLA risks at the expense of increased resource expenditure. To address this dilemma, we propose HRS, a hybrid representation framework with scheduling awareness that integrates numerical and image-based representations to better capture extreme load dynamics. We further introduce a Scheduling-Aware Loss (SAL) that captures the asymmetric impact of prediction errors, guiding predictions that better support scheduling decisions. Extensive experiments on four real-world datasets demonstrate that HRS consistently outperforms ten baselines and achieves state-of-the-art performance, reducing SLA violation rates by 63.1% and total profit loss by 32.3%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼—åŒ…äº‘è¾¹å¹³å°ï¼ˆCrowdsourced Cloud-Edge Platforms, CCPsï¼‰ä¸­ç½‘ç»œè´Ÿè½½çš„é«˜åº¦æ—¶å˜æ€§å’Œçªå‘æ€§é—®é¢˜ï¼Œæå‡ºäº†HRSï¼Œä¸€ç§å…·æœ‰è°ƒåº¦æ„ŸçŸ¥ï¼ˆScheduling Awarenessï¼‰èƒ½åŠ›çš„æ··åˆè¡¨ç¤ºæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰é¢„æµ‹æ–¹æ³•åœ¨æµé‡æ¿€å¢æ—¶æ˜“å¯¼è‡´æœåŠ¡ç­‰çº§åè®®ï¼ˆSLAï¼‰è¿è§„æˆ–èµ„æºè¿‡åº¦é…ç½®çš„éš¾é¢˜ï¼ŒHRSé€šè¿‡æ•´åˆæ•°å€¼å’ŒåŸºäºå›¾åƒçš„è¡¨ç¤ºå½¢å¼ï¼Œä»¥æ›´ç²¾å‡†åœ°æ•æ‰æç«¯è´Ÿè½½åŠ¨æ€ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†è°ƒåº¦æ„ŸçŸ¥æŸå¤±ï¼ˆScheduling-Aware Loss, SALï¼‰ï¼Œé€šè¿‡å»ºæ¨¡é¢„æµ‹è¯¯å·®å¯¹è°ƒåº¦å†³ç­–äº§ç”Ÿçš„éå¯¹ç§°å½±å“ï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´å…·å®ç”¨ä»·å€¼çš„é¢„æµ‹ç»“æœã€‚åœ¨å››ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒHRSåœ¨æ€§èƒ½ä¸Šä¼˜äºåç§åŸºçº¿æ¨¡å‹å¹¶è¾¾åˆ°äº†State-of-the-Artæ°´å¹³ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶æˆåŠŸå°†SLAè¿è§„ç‡é™ä½äº†63.1%ï¼Œå¹¶å‡å°‘äº†32.3%çš„æ€»åˆ©æ¶¦æŸå¤±ï¼Œä¸ºæå‡ä¼—åŒ…äº‘è¾¹å¹³å°çš„ç³»ç»Ÿæ•ˆèƒ½å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 14 figures, ECAI2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12839v2",
      "published_date": "2025-08-18 11:25:54 UTC",
      "updated_date": "2025-08-19 11:02:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:34:54.188316+00:00"
    },
    {
      "arxiv_id": "2508.12833v2",
      "title": "Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG",
      "title_zh": "è¿ˆå‘åŸºäºå‹ç¼©æ•°æ®çš„å­˜å‚¨æ„ŸçŸ¥å­¦ä¹ ï¼šé’ˆå¯¹ JPEG çš„å®è¯æ¢ç´¢æ€§ç ”ç©¶",
      "authors": [
        "Kichang Lee",
        "Songkuk Kim",
        "JaeYeon Park",
        "JeongGil Ko"
      ],
      "abstract": "On-device machine learning is often constrained by limited storage, particularly in continuous data collection scenarios. This paper presents an empirical study on storage-aware learning, focusing on the trade-off between data quantity and quality via compression. We demonstrate that naive strategies, such as uniform data dropping or one-size-fits-all compression, are suboptimal. Our findings further reveal that data samples exhibit varying sensitivities to compression, supporting the feasibility of a sample-wise adaptive compression strategy. These insights provide a foundation for developing a new class of storage-aware learning systems. The primary contribution of this work is the systematic characterization of this under-explored challenge, offering valuable insights that advance the understanding of storage-aware learning.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å—å­˜å‚¨ç©ºé—´é™åˆ¶çš„è®¾å¤‡ç«¯æœºå™¨å­¦ä¹  (On-device machine learning) åœºæ™¯ï¼Œç³»ç»Ÿæ¢è®¨äº†æ•°æ®è§„æ¨¡ä¸é€šè¿‡å‹ç¼©å®ç°çš„æ•°æ®è´¨é‡ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚è¯¥è®ºæ–‡ä»¥ JPEG å‹ç¼©ä¸ºæ ¸å¿ƒè¿›è¡Œå®è¯æ¢ç´¢ç ”ç©¶ (Empirical study)ï¼Œæ—¨åœ¨æ­ç¤ºå­˜å‚¨æ„ŸçŸ¥å­¦ä¹  (Storage-aware learning) çš„å†…åœ¨è§„å¾‹ã€‚ç ”ç©¶å‘ç°ï¼Œç®€å•çš„æ•°æ®ä¸¢å¼ƒæˆ–ç»Ÿä¸€å¼ºåº¦çš„å‹ç¼©ç­–ç•¥é€šå¸¸æ˜¯æ¬¡ä¼˜çš„ï¼Œéš¾ä»¥åœ¨å­˜å‚¨æ•ˆç‡ä¸æ¨¡å‹ç²¾åº¦é—´å–å¾—å¹³è¡¡ã€‚å®éªŒè¿›ä¸€æ­¥è¯å®ä¸åŒæ•°æ®æ ·æœ¬å¯¹å‹ç¼©å±•ç°å‡ºä¸åŒçš„æ•æ„Ÿåº¦ (Sensitivity)ï¼Œä¸ºå®æ–½æ ·æœ¬çº§è‡ªé€‚åº”å‹ç¼©ç­–ç•¥ (Sample-wise adaptive compression strategy) æä¾›äº†ç†è®ºä¾æ®ã€‚è¿™é¡¹å·¥ä½œçš„ä¸»è¦è´¡çŒ®åœ¨äºç³»ç»Ÿåœ°æè¿°äº†è¿™ä¸€å°šæœªè¢«å……åˆ†æ¢ç´¢çš„æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥å¼€å‘æ–°å‹å­˜å‚¨æ„ŸçŸ¥å­¦ä¹ ç³»ç»Ÿå¥ å®šäº†é‡è¦çš„å®è·µåŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6pages, 6figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12833v2",
      "published_date": "2025-08-18 11:17:59 UTC",
      "updated_date": "2025-12-23 16:25:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:08.699078+00:00"
    },
    {
      "arxiv_id": "2508.12828v1",
      "title": "Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection",
      "title_zh": "è¯­å¢ƒä¹‹è¦ï¼šåœ¨å¯¹è¯å¼è¾±éª‚è¯­è¨€æ£€æµ‹ä¸­å¼•å…¥ç›®æ ‡æ„ŸçŸ¥",
      "authors": [
        "Raneem Alharthi",
        "Rajwa Alharthi",
        "Aiqi Jiang",
        "Arkaitz Zubiaga"
      ],
      "abstract": "Abusive language detection has become an increasingly important task as a means to tackle this type of harmful content in social media. There has been a substantial body of research developing models for determining if a social media post is abusive or not; however, this research has primarily focused on exploiting social media posts individually, overlooking additional context that can be derived from surrounding posts. In this study, we look at conversational exchanges, where a user replies to an earlier post by another user (the parent tweet). We ask: does leveraging context from the parent tweet help determine if a reply post is abusive or not, and what are the features that contribute the most? We study a range of content-based and account-based features derived from the context, and compare this to the more widely studied approach of only looking at the features from the reply tweet. For a more generalizable study, we test four different classification models on a dataset made of conversational exchanges (parent-reply tweet pairs) with replies labeled as abusive or not. Our experiments show that incorporating contextual features leads to substantial improvements compared to the use of features derived from the reply tweet only, confirming the importance of leveraging context. We observe that, among the features under study, it is especially the content-based features (what is being posted) that contribute to the classification performance rather than account-based features (who is posting it). While using content-based features, it is best to combine a range of different features to ensure improved performance over being more selective and using fewer features. Our study provides insights into the development of contextualized abusive language detection models in realistic settings involving conversations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¯¹è¯è¯­å¢ƒä¸­è¯†åˆ«æ”»å‡»æ€§è¯­è¨€çš„é‡è¦æ€§ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ£€æµ‹æ–¹æ³•ä»…å…³æ³¨å•ä¸€å¸–å­è€Œå¿½ç•¥ä¸Šä¸‹æ–‡ context çš„å±€é™æ€§ã€‚ç ”ç©¶è€…åˆ†æäº†ç¤¾äº¤åª’ä½“ä¸Šçš„å¯¹è¯ç‰‡æ®µï¼Œå³ç”¨æˆ·å¯¹å‰ä¸€æ¡æ¨æ–‡ï¼ˆçˆ¶æ¨æ–‡ parent tweetï¼‰çš„å›å¤ï¼Œå¹¶å¯¹æ¯”äº†ä»…ä½¿ç”¨å›å¤å†…å®¹ä¸ç»“åˆä¸Šä¸‹æ–‡ç‰¹å¾çš„åˆ†ç±»æ•ˆæœã€‚ç ”ç©¶é‡ç‚¹è€ƒå¯Ÿäº†ä¸€ç³»åˆ—åŸºäºå†…å®¹ content-based å’ŒåŸºäºè´¦æˆ· account-based çš„ç‰¹å¾ï¼Œå¹¶åœ¨åŒ…å«çˆ¶å­æ¨æ–‡å¯¹çš„æ•°æ®é›†ä¸Šæµ‹è¯•äº†å››ç§ä¸åŒçš„åˆ†ç±»æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¼•å…¥ä¸Šä¸‹æ–‡ç‰¹å¾æ˜¾è‘—æå‡äº†æ£€æµ‹æ€§èƒ½ï¼Œè¯å®äº†åˆ©ç”¨å¯¹è¯èƒŒæ™¯åœ¨ abusive language detection ä»»åŠ¡ä¸­çš„å¿…è¦æ€§ã€‚åœ¨æ‰€ç ”ç©¶çš„ç‰¹å¾ä¸­ï¼ŒåŸºäºå†…å®¹çš„ç‰¹å¾ content-based features å¯¹åˆ†ç±»è¡¨ç°çš„è´¡çŒ®å¤§äºåŸºäºè´¦æˆ·çš„ç‰¹å¾ account-based featuresã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°ç»“åˆå¤šç§ä¸åŒçš„ç‰¹å¾è€Œéä»…é€‰æ‹©å°‘æ•°ç‰¹å¾ï¼Œèƒ½æ›´æœ‰æ•ˆåœ°æé«˜æ¨¡å‹åœ¨çœŸå®å¯¹è¯åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›å’Œå‡†ç¡®åº¦ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12828v1",
      "published_date": "2025-08-18 11:12:21 UTC",
      "updated_date": "2025-08-18 11:12:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:13.794081+00:00"
    },
    {
      "arxiv_id": "2508.13247v1",
      "title": "Goal-Directedness is in the Eye of the Beholder",
      "title_zh": "ç›®æ ‡å¯¼å‘æ€§å­˜ä¹è§‚å¯Ÿè€…ä¹‹è§",
      "authors": [
        "Nina Rajcic",
        "Anders SÃ¸gaard"
      ],
      "abstract": "Our ability to predict the behavior of complex agents turns on the attribution of goals. Probing for goal-directed behavior comes in two flavors: Behavioral and mechanistic. The former proposes that goal-directedness can be estimated through behavioral observation, whereas the latter attempts to probe for goals in internal model states. We work through the assumptions behind both approaches, identifying technical and conceptual problems that arise from formalizing goals in agent systems. We arrive at the perhaps surprising position that goal-directedness cannot be measured objectively. We outline new directions for modeling goal-directedness as an emergent property of dynamic, multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡è¡Œä¸ºè§‚å¯Ÿï¼ˆBehavioralï¼‰å’Œæœºæ¢°æœºåˆ¶ï¼ˆMechanisticï¼‰ä¸¤ç§æ–¹æ³•æ¥è¯†åˆ«å¤æ‚æ™ºèƒ½ä½“çš„ç›®æ ‡å¯¼å‘è¡Œä¸ºï¼ˆGoal-directednessï¼‰ã€‚ä½œè€…æ·±å…¥åˆ†æäº†è¿™ä¸¤ç§è·¯å¾„èƒŒåçš„æ ¸å¿ƒå‡è®¾ï¼Œå¹¶æ˜ç¡®æŒ‡å‡ºäº†åœ¨æ™ºèƒ½ä½“ç³»ç»Ÿä¸­å¯¹ç›®æ ‡è¿›è¡Œå½¢å¼åŒ–ï¼ˆformalizing goalsï¼‰æ—¶æ‰€é¢ä¸´çš„æŠ€æœ¯ä¸æ¦‚å¿µéš¾é¢˜ã€‚ç ”ç©¶å¾—å‡ºäº†ä¸€ä¸ªå…³é”®ç»“è®ºï¼Œå³ç›®æ ‡å¯¼å‘æ€§ï¼ˆGoal-directednessï¼‰å¹¶éä¸€ç§å¯ä»¥è¢«å®¢è§‚æµ‹é‡çš„å±æ€§ã€‚åŸºäºæ­¤å‘ç°ï¼Œè®ºæ–‡æå‡ºäº†å»ºæ¨¡çš„æ–°æ–¹å‘ï¼Œä¸»å¼ å°†ç›®æ ‡å¯¼å‘æ€§è§†ä¸ºåŠ¨æ€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆmulti-agent systemsï¼‰ä¸­ä¸€ç§ç‰¹å¾æ€§çš„æ¶Œç°å±æ€§ï¼ˆemergent propertyï¼‰ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Submitted to Conference and Workshop on Neural Information Processing Systems 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.13247v1",
      "published_date": "2025-08-18 11:04:18 UTC",
      "updated_date": "2025-08-18 11:04:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:20.194257+00:00"
    },
    {
      "arxiv_id": "2508.16643v1",
      "title": "From Classical Probabilistic Latent Variable Models to Modern Generative AI: A Unified Perspective",
      "title_zh": "ä»ç»å…¸æ¦‚ç‡éšå˜é‡æ¨¡å‹åˆ°ç°ä»£ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šç»Ÿä¸€è§†è§’",
      "authors": [
        "Tianhua Chen"
      ],
      "abstract": "From large language models to multi-modal agents, Generative Artificial Intelligence (AI) now underpins state-of-the-art systems. Despite their varied architectures, many share a common foundation in probabilistic latent variable models (PLVMs), where hidden variables explain observed data for density estimation, latent reasoning, and structured inference. This paper presents a unified perspective by framing both classical and modern generative methods within the PLVM paradigm. We trace the progression from classical flat models such as probabilistic PCA, Gaussian mixture models, latent class analysis, item response theory, and latent Dirichlet allocation, through their sequential extensions including Hidden Markov Models, Gaussian HMMs, and Linear Dynamical Systems, to contemporary deep architectures: Variational Autoencoders as Deep PLVMs, Normalizing Flows as Tractable PLVMs, Diffusion Models as Sequential PLVMs, Autoregressive Models as Explicit Generative Models, and Generative Adversarial Networks as Implicit PLVMs. Viewing these architectures under a common probabilistic taxonomy reveals shared principles, distinct inference strategies, and the representational trade-offs that shape their strengths. We offer a conceptual roadmap that consolidates generative AI's theoretical foundations, clarifies methodological lineages, and guides future innovation by grounding emerging architectures in their probabilistic heritage.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»æ¦‚ç‡æ½œå˜é‡æ¨¡å‹(Probabilistic Latent Variable Models, PLVMs)çš„ç»Ÿä¸€è§†è§’å‡ºå‘ï¼Œç³»ç»Ÿæ€§åœ°æ¢³ç†äº†ä»ç»å…¸æ¦‚ç‡æ¨¡å‹åˆ°ç°ä»£ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)çš„å‘å±•è„‰ç»œã€‚è®ºæ–‡å°†Probabilistic PCAã€Gaussian Mixture Modelså’ŒLatent Dirichlet Allocationç­‰ç»å…¸æ¨¡å‹ï¼Œä»¥åŠHidden Markov Modelsç­‰åºåˆ—æ¨¡å‹ï¼Œä¸Variational Autoencodersã€Normalizing Flowså’ŒDiffusion Modelsç­‰ç°ä»£æ·±åº¦æ¶æ„çº³å…¥ç»Ÿä¸€çš„æ¦‚ç‡åˆ†ç±»ä½“ç³»ä¸­è¿›è¡Œæ¢è®¨ã€‚æ–‡ç« è¿˜æ·±å…¥åˆ†æäº†Autoregressive Modelså’ŒGenerative Adversarial Networksï¼Œæ­ç¤ºäº†ä¸åŒæ¶æ„ä¹‹é—´å…±äº«çš„åŸåˆ™ã€æ¨ç†ç­–ç•¥ä»¥åŠè¡¨å¾æƒè¡¡ã€‚é€šè¿‡å»ºç«‹è¿™ç§è”ç³»ï¼Œè¯¥ç»¼è¿°ä¸ºGenerative AIæä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ï¼Œå¹¶é€šå›æº¯æ¦‚ç‡é—äº§ä¸ºæœªæ¥çš„æ¨¡å‹æ¶æ„åˆ›æ–°æä¾›äº†æ¸…æ™°çš„æ¦‚å¿µè·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is a substantially improved and expanded version of an earlier manuscript hosted on SSRN: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5244929",
      "pdf_url": "https://arxiv.org/pdf/2508.16643v1",
      "published_date": "2025-08-18 11:02:32 UTC",
      "updated_date": "2025-08-18 11:02:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:23.287741+00:00"
    },
    {
      "arxiv_id": "2508.12815v2",
      "title": "Learning to Steer: Input-dependent Steering for Multimodal LLMs",
      "title_zh": "Learning to Steerï¼šé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è¾“å…¥ä¾èµ–å‹å¼•å¯¼",
      "authors": [
        "Jayneel Parekh",
        "Pegah Khayatan",
        "Mustafa Shukor",
        "Arnaud Dapogny",
        "Alasdair Newson",
        "Matthieu Cord"
      ],
      "abstract": "Steering has emerged as a practical approach to enable post-hoc guidance of LLMs towards enforcing a specific behavior. However, it remains largely underexplored for multimodal LLMs (MLLMs); furthermore, existing steering techniques, such as mean steering, rely on a single steering vector, applied independently of the input query. This paradigm faces limitations when the desired behavior is dependent on the example at hand. For example, a safe answer may consist in abstaining from answering when asked for an illegal activity, or may point to external resources or consultation with an expert when asked about medical advice. In this paper, we investigate a fine-grained steering that uses an input-specific linear shift. This shift is computed using contrastive input-specific prompting. However, the input-specific prompts required for this approach are not known at test time. Therefore, we propose to train a small auxiliary module to predict the input-specific steering vector. Our approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces hallucinations and enforces safety in MLLMs, outperforming other static baselines. Our code is publicly available at https://jayneelparekh.github.io/learn-to-steer/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)ä¸­ç°æœ‰å¼•å¯¼(Steering)æŠ€æœ¯ä¾èµ–é™æ€å‘é‡è€Œæ— æ³•é€‚åº”å…·ä½“è¾“å…¥çš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸ºL2S (Learn-to-Steer)çš„ç»†ç²’åº¦å¼•å¯¼æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥è¾“å…¥ç‰¹å®šçš„çº¿æ€§åç§»(input-specific linear shift)æ¥åŠ¨æ€è°ƒæ•´æ¨¡å‹è¡Œä¸ºï¼Œåˆ©ç”¨å¯¹æ¯”è¾“å…¥ç‰¹å®šæç¤º(contrastive input-specific prompting)è®¡ç®—å¼•å¯¼æ–¹å‘ã€‚ä¸ºäº†è§£å†³æµ‹è¯•é˜¶æ®µæç¤ºè¯ä¸å¯çŸ¥çš„é—®é¢˜ï¼Œç ”ç©¶è€…è®­ç»ƒäº†ä¸€ä¸ªå°å‹è¾…åŠ©æ¨¡å—(auxiliary module)æ¥å®æ—¶é¢„æµ‹è¯¥å¼•å¯¼å‘é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒL2Såœ¨å‡å°‘å¹»è§‰(hallucinations)å’Œå¢å¼ºå®‰å…¨æ€§(safety)æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„é™æ€åŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è¾“å…¥ä¾èµ–å‹å¼•å¯¼åœ¨æå‡å¤šæ¨¡æ€æ¨¡å‹å¯é æ€§å’Œè¡Œä¸ºä¸€è‡´æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12815v2",
      "published_date": "2025-08-18 10:53:20 UTC",
      "updated_date": "2025-11-02 22:39:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:30.383575+00:00"
    },
    {
      "arxiv_id": "2508.12811v1",
      "title": "Next Visual Granularity Generation",
      "title_zh": "ä¸‹ä¸€è§†è§‰ç²’åº¦ç”Ÿæˆ",
      "authors": [
        "Yikai Wang",
        "Zhouxia Wang",
        "Zhonghua Wu",
        "Qingyi Tao",
        "Kang Liao",
        "Chen Change Loy"
      ],
      "abstract": "We propose a novel approach to image generation by decomposing an image into a structured sequence, where each element in the sequence shares the same spatial resolution but differs in the number of unique tokens used, capturing different level of visual granularity. Image generation is carried out through our newly introduced Next Visual Granularity (NVG) generation framework, which generates a visual granularity sequence beginning from an empty image and progressively refines it, from global layout to fine details, in a structured manner. This iterative process encodes a hierarchical, layered representation that offers fine-grained control over the generation process across multiple granularity levels. We train a series of NVG models for class-conditional image generation on the ImageNet dataset and observe clear scaling behavior. Compared to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30 -> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to showcase the capability and potential of the NVG framework. Our code and models will be released.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Next Visual Granularity (NVG) çš„æ–°å‹å›¾åƒç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡å°†å›¾åƒåˆ†è§£ä¸ºç»“æ„åŒ–åºåˆ—æ¥æ•æ‰ä¸åŒçº§åˆ«çš„è§†è§‰ç²’åº¦ (Visual Granularity)ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œåºåˆ—çš„æ¯ä¸ªå…ƒç´ ä¿æŒç›¸åŒçš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œä½†é€šè¿‡æ”¹å˜ Token çš„æ•°é‡æ¥è¡¨ç¤ºä»å…¨å±€å¸ƒå±€åˆ°ç²¾ç»†ç»†èŠ‚çš„å±‚æ¬¡åŒ–ä¿¡æ¯ã€‚ç”Ÿæˆè¿‡ç¨‹ä»ç©ºå›¾åƒå¼€å§‹å¹¶é€æ­¥è¿­ä»£ç»†åŒ–ï¼Œå®ç°äº†å¯¹å¤šç²’åº¦ç”Ÿæˆè¿‡ç¨‹çš„ç²¾ç¡®æ§åˆ¶ã€‚åœ¨ ImageNet æ•°æ®é›†çš„ç±»åˆ«æ¡ä»¶å›¾åƒç”Ÿæˆå®éªŒä¸­ï¼ŒNVG æ¨¡å‹å±•ç°å‡ºæ˜¾è‘—çš„æ‰©å±•æ€§ (Scaling Behavior)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNVG åœ¨ FID è¯„åˆ†ä¸ŠæŒç»­ä¼˜äº VAR ç³»åˆ—æ¨¡å‹ï¼Œå±•ç°äº†æ›´ä¼˜çš„ç”Ÿæˆè´¨é‡ã€‚é€šè¿‡å¹¿æ³›çš„åˆ†æï¼Œè¯¥ç ”ç©¶éªŒè¯äº† NVG æ¡†æ¶åœ¨å¤„ç†å¤æ‚è§†è§‰è¡¨å¾æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ä¸åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12811v1",
      "published_date": "2025-08-18 10:47:37 UTC",
      "updated_date": "2025-08-18 10:47:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:32.992758+00:00"
    },
    {
      "arxiv_id": "2508.13246v3",
      "title": "Involuntary Jailbreak: On Self-Prompting Attacks",
      "title_zh": "éè‡ªæ„¿è¶Šç‹±ï¼šè®ºè‡ªæˆ‘æç¤ºæ”»å‡»",
      "authors": [
        "Yangyang Guo",
        "Yangyan Li",
        "Mohan Kankanhalli"
      ],
      "abstract": "In this study, we disclose a worrying new vulnerability in Large Language Models (LLMs), which we term \\textbf{involuntary jailbreak}. Unlike existing jailbreak attacks, this weakness is distinct in that it does not involve a specific attack objective, such as generating instructions for \\textit{building a bomb}. Prior attack methods predominantly target localized components of the LLM guardrail. In contrast, involuntary jailbreaks may potentially compromise the entire guardrail structure, which our method reveals to be surprisingly fragile. We merely employ a single universal prompt to achieve this goal. In particular, we instruct LLMs to generate several questions that would typically be rejected, along with their corresponding in-depth responses (rather than a refusal). Remarkably, this simple prompt strategy consistently jailbreaks the majority of leading LLMs, including Claude Opus 4.1, Grok 4, Gemini 2.5 Pro, and GPT 4.1. We hope this problem can motivate researchers and practitioners to re-evaluate the robustness of LLM guardrails and contribute to stronger safety alignment in future.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸­ä¸€ç§åä¸ºâ€œéè‡ªæ„¿è¶Šç‹±â€ (involuntary jailbreak) çš„ä¸¥é‡å®‰å…¨æ¼æ´ã€‚ä¸ç°æœ‰çš„è¶Šç‹±æ”»å‡»ä¸åŒï¼Œè¯¥æ¼æ´å¹¶ä¸æ¶‰åŠç‰¹å®šçš„æ”»å‡»ç›®æ ‡ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ç§é€šç”¨çš„ self-prompting ç­–ç•¥æ¥æŒ‘æˆ˜ LLM é˜²æŠ¤æ  (guardrail) çš„æ•´ä½“ç»“æ„ã€‚ç ”ç©¶è€…ä»…ä½¿ç”¨ä¸€æ¡é€šç”¨æç¤ºè¯ï¼Œè¯±å¯¼æ¨¡å‹ä¸»åŠ¨ç”Ÿæˆä¸€ç³»åˆ—æœ¬åº”è¢«æ‹’ç»çš„æ•æ„Ÿé—®é¢˜åŠå…¶å¯¹åº”çš„æ·±åº¦å›ç­”ï¼Œè€Œéè§¦å‘æ‹’ç»æœºåˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§ç®€å•çš„æç¤ºç­–ç•¥èƒ½æŒç»­æˆåŠŸè¶Šç‹±åŒ…æ‹¬ Claude Opus 4.1ã€Grok 4ã€Gemini 2.5 Pro å’Œ GPT 4.1 åœ¨å†…çš„å¤šç§é¢†å…ˆæ¨¡å‹ã€‚è¯¥å‘ç°æ­ç¤ºäº†å½“å‰æ¨¡å‹é˜²å¾¡ä½“ç³»çš„è„†å¼±æ€§ï¼Œæ—¨åœ¨ä¿ƒä½¿ç ”ç©¶è€…é‡æ–°è¯„ä¼°æ¨¡å‹ç¨³å¥æ€§ï¼Œå¹¶ä¸ºæœªæ¥å®ç°æ›´å¼ºå¤§çš„å®‰å…¨å¯¹é½ (safety alignment) æä¾›å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13246v3",
      "published_date": "2025-08-18 10:38:30 UTC",
      "updated_date": "2025-12-27 09:02:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:39.086438+00:00"
    },
    {
      "arxiv_id": "2508.12800v3",
      "title": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward",
      "title_zh": "Atom-Searcherï¼šé€šè¿‡ç»†ç²’åº¦åŸå­åŒ–æ€ç»´å¥–åŠ±å¢å¼ºæ™ºèƒ½ä½“æ·±åº¦ç ”ç©¶",
      "authors": [
        "Yong Deng",
        "Guoqing Wang",
        "Zhenzhe Ying",
        "Xiaofeng Wu",
        "Jinzhen Lin",
        "Wenwen Xiong",
        "Yuqin Dai",
        "Shuo Yang",
        "Zhanwei Zhang",
        "Qiwen Wang",
        "Yang Qin",
        "Yuan Wang",
        "Quanxing Zha",
        "Sunhao Dai",
        "Changhua Meng"
      ],
      "abstract": "Large language models (LLMs) exhibit remarkable problem-solving abilities, but struggle with complex tasks due to static internal knowledge. Retrieval-Augmented Generation (RAG) enhances access to external information, yet remains limited in multi-hop reasoning and strategic search due to rigid workflows. Recent advancements in agentic deep research empower LLMs to autonomously reason, search, and synthesize information. However, current approaches relying on outcome-based reinforcement learning (RL) face critical issues such as conflicting gradients and reward sparsity, limiting performance gains and training efficiency. To address these, we first propose Atomic Thought, a novel LLM thinking paradigm that decomposes reasoning into fine-grained functional units. These units are supervised by Reasoning Reward Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained guidance. Building on this, we propose Atom-Searcher, a novel RL framework for agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher uses a curriculum-inspired reward schedule, prioritizing process-level ATR early and transitioning to outcome rewards, accelerating convergence on effective reasoning paths. Experiments on seven benchmarks show consistent improvements over the state-of-the-art. Key advantages include: (1) Atom-Searcher scales computation at test-time. (2) Atomic Thought provides supervision anchors for RRMs, bridging deep research tasks and RRMs. (3) Atom-Searcher exhibits more interpretable, human-like reasoning patterns.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨Agentic Deep Researchä¸­é¢ä¸´çš„æ¢¯åº¦å†²çªå’Œå¥–åŠ±ç¨€ç–é—®é¢˜ï¼Œæå‡ºäº†Atom-Searcherå¼ºåŒ–å­¦ä¹ (RL)æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†åä¸ºAtomic Thoughtçš„æ¨ç†èŒƒå¼ï¼Œå°†å¤æ‚çš„æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºç»†ç²’åº¦çš„åŠŸèƒ½å•å…ƒï¼Œå¹¶åˆ©ç”¨æ¨ç†å¥–åŠ±æ¨¡å‹(RRMs)æä¾›åŸå­æ¨ç†å¥–åŠ±(Atomic Thought Rewards, ATR)è¿›è¡Œç²¾ç»†åŒ–å¼•å¯¼ã€‚Atom-Searcheré‡‡ç”¨äº†è¯¾ç¨‹å­¦ä¹ å¯å‘çš„å¥–åŠ±è°ƒåº¦ç­–ç•¥ï¼Œåœ¨è®­ç»ƒåˆæœŸä¾§é‡è¿‡ç¨‹çº§çš„ATRï¼Œéšåé€æ¸è¿‡æ¸¡åˆ°ç»“æœå¥–åŠ±ï¼Œä»è€Œæ˜¾è‘—åŠ é€Ÿäº†æœ‰æ•ˆæ¨ç†è·¯å¾„çš„æ”¶æ•›ã€‚å®éªŒç»“æœåœ¨ä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸Šå‡å±•ç°å‡ºä¼˜äºç°æœ‰æœ€å…ˆè¿›æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶è¯æ˜äº†è¯¥æ¡†æ¶å…·æœ‰å‡ºè‰²çš„æµ‹è¯•æ—¶è®¡ç®—æ‰©å±•æ€§(Test-time scaling)ã€‚æ­¤å¤–ï¼ŒAtomic Thoughtä¸ºRRMsæä¾›äº†å…³é”®çš„ç›‘ç£é”šç‚¹ï¼Œä½¿Agentçš„æ¨ç†æ¨¡å¼æ›´å…·å¯è§£é‡Šæ€§ï¼Œå¹¶å‘ˆç°å‡ºæ›´æ¥è¿‘äººç±»çš„æ€ç»´æ¨¡å¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12800v3",
      "published_date": "2025-08-18 10:23:10 UTC",
      "updated_date": "2025-08-29 10:05:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:41.086311+00:00"
    },
    {
      "arxiv_id": "2508.12798v1",
      "title": "A Shift in Perspective on Causality in Domain Generalization",
      "title_zh": "åŸŸæ³›åŒ–ä¸­å› æœå…³ç³»çš„è§†è§’è½¬å˜",
      "authors": [
        "Damian Machlanski",
        "Stephanie Riley",
        "Edward Moroshko",
        "Kurt Butler",
        "Panagiotis Dimitrakopoulos",
        "Thomas Melistas",
        "Akchunya Chanchal",
        "Steven McDonagh",
        "Ricardo Silva",
        "Sotirios A. Tsaftaris"
      ],
      "abstract": "The promise that causal modelling can lead to robust AI generalization has been challenged in recent work on domain generalization (DG) benchmarks. We revisit the claims of the causality and DG literature, reconciling apparent contradictions and advocating for a more nuanced theory of the role of causality in generalization. We also provide an interactive demo at https://chai-uk.github.io/ukairs25-causal-predictors/.",
      "tldr_zh": "è¯¥ç ”ç©¶é‡æ–°æ¢è®¨äº†å› æœå»ºæ¨¡åœ¨é¢†åŸŸæ³›åŒ–(Domain Generalization, DG)ä¸­çš„æ ¸å¿ƒä½œç”¨ï¼Œæ—¨åœ¨åº”å¯¹è¿‘æœŸåŸºå‡†æµ‹è¯•å¯¹å› æœæ¨¡å‹æ³›åŒ–é²æ£’æ€§æå‡ºçš„æŒ‘æˆ˜ã€‚ä½œè€…é€šè¿‡ç³»ç»Ÿæ€§åœ°å›é¡¾å› æœå…³ç³»ä¸é¢†åŸŸæ³›åŒ–é¢†åŸŸçš„ç›¸å…³æ–‡çŒ®ï¼Œå°è¯•è°ƒå’Œæ—¢æœ‰ç ”ç©¶ä¸­å­˜åœ¨çš„è¡¨è§‚çŸ›ç›¾ã€‚è®ºæ–‡ä¸»å¼ å»ºç«‹ä¸€ç§æ›´ä¸ºç²¾ç»†ä¸”å·®å¼‚åŒ–çš„ç†è®ºï¼Œä»¥å‡†ç¡®æè¿°å› æœæ€§(Causality)åœ¨AIæ³›åŒ–æ€§èƒ½ä¸­çš„å…·ä½“è§’è‰²ã€‚è¿™ç§æ–°è§†è§’æœ‰åŠ©äºæ¾„æ¸…å› æœé¢„æµ‹å› å­åœ¨ä¸åŒä»»åŠ¡åœºæ™¯ä¸‹çš„å®é™…æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æä¾›äº†ä¸€ä¸ªåœ¨çº¿äº¤äº’å¼æ¼”ç¤ºå·¥å…·ï¼Œç”¨äºç›´è§‚å±•ç¤ºå¹¶éªŒè¯å…¶å…³äºå› æœé¢„æµ‹ä¸æ³›åŒ–å…³ç³»çš„ç†è®ºä¸»å¼ ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "2 pages, 1 figure, to be presented at the UK AI Research Symposium (UKAIRS) 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12798v1",
      "published_date": "2025-08-18 10:19:33 UTC",
      "updated_date": "2025-08-18 10:19:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:48.394737+00:00"
    },
    {
      "arxiv_id": "2508.12794v2",
      "title": "Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision",
      "title_zh": "åŸºäº GSV å›¾åƒçš„è½¦è¾†æ£€æµ‹ï¼šåˆ©ç”¨è®¡ç®—æœºè§†è§‰é¢„æµ‹éª‘è¡Œä¸æ‘©æ‰˜è½¦å‡ºè¡Œè¡Œä¸º",
      "authors": [
        "Kyriaki",
        "Kokka",
        "Rahul Goel",
        "Ali Abbas",
        "Kerry A. Nice",
        "Luca Martial",
        "SM Labib",
        "Rihuan Ke",
        "Carola Bibiane SchÃ¶nlieb",
        "James Woodcock"
      ],
      "abstract": "Transportation influence health by shaping exposure to physical activity, air pollution and injury risk. Comparative data on cycling and motorcycling behaviours is scarce, particularly at a global scale. Street view imagery, such as Google Street View (GSV), combined with computer vision, is a valuable resource for efficiently capturing travel behaviour data. This study demonstrates a novel approach using deep learning on street view images to estimate cycling and motorcycling levels across diverse cities worldwide. We utilized data from 185 global cities. The data on mode shares of cycling and motorcycling estimated using travel surveys or censuses. We used GSV images to detect cycles and motorcycles in sampled locations, using 8000 images per city. The YOLOv4 model, fine-tuned using images from six cities, achieved a mean average precision of 89% for detecting cycles and motorcycles. A global prediction model was developed using beta regression with city-level mode shares as outcome, with log transformed explanatory variables of counts of GSV-detected images with cycles and motorcycles, while controlling for population density. We found strong correlations between GSV motorcycle counts and motorcycle mode share (0.78) and moderate correlations between GSV cycle counts and cycling mode share (0.51). Beta regression models predicted mode shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling, achieving median absolute errors (MDAE) of 1.3% and 1.4%, respectively. Scatterplots demonstrated consistent prediction accuracy, though cities like Utrecht and Cali were outliers. The model was applied to 60 cities globally for which we didn't have recent mode share data. We provided estimates for some cities in the Middle East, Latin America and East Asia. With computer vision, GSV images capture travel modes and activity, providing insights alongside traditional data sources.",
      "tldr_zh": "è¯¥ç ”ç©¶å±•ç¤ºäº†ä¸€ç§åˆ©ç”¨ Computer Vision å’Œ Google Street View (GSV) å›¾åƒæ¥ä¼°è®¡å…¨çƒä¸åŒåŸå¸‚éª‘è¡Œå’Œæ‘©æ‰˜è½¦å‡ºè¡Œæ°´å¹³çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡åœ¨ 185 ä¸ªåŸå¸‚é‡‡æ ·çš„å›¾åƒä¸Šè¿è¡Œ fine-tuned çš„ YOLOv4 æ¨¡å‹ï¼Œå®ç°äº† 89% çš„ mean average precisionã€‚éšåï¼Œç ”ç©¶é‡‡ç”¨ Beta Regression æ„å»ºå…¨çƒé¢„æµ‹æ¨¡å‹ï¼Œä»¥åŸå¸‚çº§å‡ºè¡Œåˆ†æ‹…ç‡ä¸ºç»“æœï¼Œå°† GSV æ¢æµ‹åˆ°çš„è½¦è¾†è®¡æ•°ä½œä¸ºè§£é‡Šå˜é‡ï¼Œå¹¶å¯¹äººå£å¯†åº¦è¿›è¡Œæ§åˆ¶ã€‚ç»“æœæ˜¾ç¤º GSV æ‘©æ‰˜è½¦è®¡æ•°ä¸å®é™…å‡ºè¡Œåˆ†æ‹…ç‡å…·æœ‰å¼ºç›¸å…³æ€§ (0.78)ï¼Œè€Œéª‘è¡Œåˆ™ä¸ºä¸­åº¦ç›¸å…³ (0.51)ã€‚æ¨¡å‹å¯¹éª‘è¡Œå’Œæ‘©æ‰˜è½¦çš„é¢„æµ‹ $R^2$ åˆ†åˆ«è¾¾åˆ° 0.614 å’Œ 0.612ï¼Œä¸” Median Absolute Errors (MDAE) ä¿æŒåœ¨ 1.3% å’Œ 1.4% çš„è¾ƒä½æ°´å¹³ã€‚è¯¥æ¨¡å‹å·²åº”ç”¨äºå…¨çƒ 60 ä¸ªç¼ºä¹è¿‘æœŸæ•°æ®çš„åŸå¸‚ï¼Œè¯æ˜äº† GSV ç»“åˆ Deep Learning æ˜¯æ•æ‰å…¨çƒå‡ºè¡Œè¡Œä¸ºæ•°æ®çš„å®è´µèµ„æºï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¡¥å……ä¼ ç»Ÿæ•°æ®æºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12794v2",
      "published_date": "2025-08-18 10:17:30 UTC",
      "updated_date": "2025-08-19 14:43:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:35:50.888894+00:00"
    },
    {
      "arxiv_id": "2508.12792v2",
      "title": "Bridging Human and LLM Judgments: Understanding and Narrowing the Gap",
      "title_zh": "å¼¥åˆäººç±»ä¸å¤§è¯­è¨€æ¨¡å‹è¯„åˆ¤ï¼šç†è§£ä¸ç¼©å°å·®è·",
      "authors": [
        "Felipe Maia Polo",
        "Xinhe Wang",
        "Mikhail Yurochkin",
        "Gongjun Xu",
        "Moulinath Banerjee",
        "Yuekai Sun"
      ],
      "abstract": "Large language models are increasingly used as judges (LLM-as-a-judge) to evaluate model outputs at scale, but their assessments often diverge systematically from human judgments. We present Bridge, a unified statistical framework that explicitly bridges human and LLM evaluations under both absolute scoring and pairwise comparison paradigms. Bridge posits a latent human preference score for each prompt-response pair and models LLM deviations as linear transformations of covariates that capture sources of discrepancies. This offers a simple and principled framework for refining LLM ratings and characterizing systematic discrepancies between humans and LLMs. We provide an efficient fitting algorithm with asymptotic guarantees for statistical inference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot Arena), Bridge achieves higher agreement with human ratings (accuracy, calibration, and KL divergence) and exposes systematic human-LLM gaps.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºè£åˆ¤ (LLM-as-a-judge) åœ¨è¯„ä¼°æ¨¡å‹è¾“å‡ºæ—¶ä¸äººç±»åˆ¤æ–­å­˜åœ¨ç³»ç»Ÿæ€§åå·®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸º Bridge çš„ç»Ÿä¸€ç»Ÿè®¡æ¡†æ¶ã€‚Bridge æ¡†æ¶æ—¨åœ¨ç»å¯¹è¯„åˆ† (absolute scoring) å’Œæˆå¯¹æ¯”è¾ƒ (pairwise comparison) èŒƒå¼ä¸‹ï¼Œæ˜¾å¼åœ°è¿æ¥äººç±»ä¸ LLM çš„è¯„ä¼°ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸ºæ¯ä¸ªæç¤º-å“åº”å¯¹è®¾å®šæ½œåœ¨çš„äººç±»åå¥½å¾—åˆ†ï¼Œå¹¶å°† LLM çš„åå·®å»ºæ¨¡ä¸ºåæ˜ å·®å¼‚æ¥æºçš„åå˜é‡ (covariates) çš„çº¿æ€§å˜æ¢ã€‚è¿™ç§æ–¹æ³•ä¸ä»…ä¸ºç²¾ç‚¼ LLM è¯„åˆ†æä¾›äº†ä¸€ä¸ªç®€å•ä¸”æœ‰åŸåˆ™çš„æ¡†æ¶ï¼Œè¿˜èƒ½æœ‰æ•ˆåˆ»ç”»äººç±»ä¸ LLM ä¹‹é—´çš„ç³»ç»Ÿæ€§å·®å¼‚ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜å¼€å‘äº†ä¸€ç§å…·æœ‰ç»Ÿè®¡æ¨æ–­æ¸è¿‘ä¿è¯çš„é«˜æ•ˆæ‹Ÿåˆç®—æ³•ã€‚é€šè¿‡åœ¨ BigGen Bench å’Œ Chatbot Arena ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šå¯¹å…­ä¸ª LLM è£åˆ¤è¿›è¡Œå®éªŒï¼Œç»“æœè¯æ˜ Bridge åœ¨å‡†ç¡®æ€§ (accuracy)ã€æ ¡å‡†åº¦ (calibration) å’Œ KL æ•£åº¦ (KL divergence) æ–¹é¢ä¸äººç±»è¯„åˆ†è¾¾åˆ°äº†æ›´é«˜çš„ä¸€è‡´æ€§ï¼Œå¹¶æˆåŠŸæ­ç¤ºäº†äººç±»ä¸ LLM ä¹‹é—´å­˜åœ¨çš„ç³»ç»Ÿæ€§å·®è·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12792v2",
      "published_date": "2025-08-18 10:14:20 UTC",
      "updated_date": "2025-12-01 23:22:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:04.982628+00:00"
    },
    {
      "arxiv_id": "2508.12791v1",
      "title": "[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise",
      "title_zh": "[ç¤¾ä¼š] å¼‚æ€è°ƒèŠ‚ï¼šæˆ–è€…ï¼Œæˆ‘æ˜¯å¦‚ä½•å­¦ä¼šåœæ­¢å¿§è™‘å¹¶çˆ±ä¸Šå™ªå£°çš„",
      "authors": [
        "Imran Khan"
      ],
      "abstract": "The notion of homeostasis typically conceptualises biological and artificial systems as maintaining stability by resisting deviations caused by environmental and social perturbations. In contrast, (social) allostasis proposes that these systems can proactively leverage these very perturbations to reconfigure their regulatory parameters in anticipation of environmental demands, aligning with von Foerster's ``order through noise'' principle. This paper formulates a computational model of allostatic and social allostatic regulation that employs biophysiologically inspired signal transducers, analogous to hormones like cortisol and oxytocin, to encode information from both the environment and social interactions, which mediate this dynamic reconfiguration. The models are tested in a small society of ``animats'' across several dynamic environments, using an agent-based model. The results show that allostatic and social allostatic regulation enable agents to leverage environmental and social ``noise'' for adaptive reconfiguration, leading to improved viability compared to purely reactive homeostatic agents. This work offers a novel computational perspective on the principles of social allostasis and their potential for designing more robust, bio-inspired, adaptive systems",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†(Social) Allostasisï¼ˆç¤¾ä¼šç¨³æ€è°ƒèŠ‚ï¼‰çš„æ¦‚å¿µï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿçš„Homeostasisï¼ˆå†…ç¨³æ€ï¼‰è§‚ç‚¹ï¼Œå³ç³»ç»Ÿä»…é€šè¿‡æŠµæŠ—ç¯å¢ƒæ‰°åŠ¨æ¥ç»´æŒç¨³å®šæ€§ã€‚åŸºäºâ€œOrder through noiseâ€ï¼ˆå™ªå£°ç”Ÿåºï¼‰åŸåˆ™ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªèƒ½å¤Ÿä¸»åŠ¨åˆ©ç”¨ç¯å¢ƒå’Œç¤¾ä¼šæ‰°åŠ¨æ¥é¢„åˆ¤éœ€æ±‚å¹¶é‡æ„è°ƒèŠ‚å‚æ•°çš„è®¡ç®—æ¨¡å‹ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†å—ç”Ÿç‰©ç”Ÿç†å­¦å¯å‘çš„ä¿¡å·è½¬å¯¼å™¨ï¼Œç±»æ¯”Cortisolï¼ˆçš®è´¨é†‡ï¼‰å’ŒOxytocinï¼ˆå‚¬äº§ç´ ï¼‰ç­‰æ¿€ç´ æ¥ç¼–ç å¤šç»´ä¿¡æ¯ï¼Œä»¥ä»‹å¯¼åŠ¨æ€é‡æ„è¿‡ç¨‹ã€‚ç ”ç©¶é€šè¿‡æ™ºèƒ½ä½“å»ºæ¨¡(Agent-based model)åœ¨Animatsï¼ˆäººé€ åŠ¨ç‰©ï¼‰ç¤¾ä¼šä¸­è¿›è¡Œäº†å¤šç¯å¢ƒæµ‹è¯•ã€‚ç»“æœè¯æ˜ï¼ŒAllostaticå’ŒSocial Allostaticè°ƒèŠ‚ä½¿æ™ºèƒ½ä½“èƒ½å°†â€œå™ªå£°â€è½¬åŒ–ä¸ºé€‚åº”æ€§åŠ¨åŠ›ï¼Œå…¶ç”Ÿå­˜èƒ½åŠ›(Viability)æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ååº”å¼Homeostaticæ™ºèƒ½ä½“ã€‚è¿™é¡¹å·¥ä½œä¸ºè®¾è®¡æ›´å…·é²æ£’æ€§å’Œç”Ÿç‰©å¯å‘æ€§çš„è‡ªé€‚åº”ç³»ç»Ÿæä¾›äº†å…¨æ–°çš„è®¡ç®—è§†è§’ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA",
        "eess.SY",
        "nlin.AO"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 5 figures. Accepted at ALIFE 2025 (Kyoto, Japan; October 6th - 10th 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.12791v1",
      "published_date": "2025-08-18 10:06:33 UTC",
      "updated_date": "2025-08-18 10:06:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:10.590531+00:00"
    },
    {
      "arxiv_id": "2508.12790v1",
      "title": "Reinforcement Learning with Rubric Anchors",
      "title_zh": "åŸºäºè¯„ä»·å‡†åˆ™é”šç‚¹çš„å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Zenan Huang",
        "Yihong Zhuang",
        "Guoshan Lu",
        "Zeyu Qin",
        "Haokai Xu",
        "Tianyu Zhao",
        "Ru Peng",
        "Jiaqi Hu",
        "Zhanming Shen",
        "Xiaomeng Hu",
        "Xijun Gu",
        "Peiyi Tu",
        "Jiaxin Liu",
        "Wenyu Chen",
        "Yuzhuo Fu",
        "Zhiting Fan",
        "Yanmei Gu",
        "Yuanyuan Wang",
        "Zhengkai Yang",
        "Jianguo Li",
        "Junbo Zhao"
      ],
      "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing Large Language Models (LLMs), exemplified by the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable signals-such as passing unit tests in code generation or matching correct answers in mathematical reasoning. While effective, this requirement largely confines RLVR to domains with automatically checkable outcomes. To overcome this, we extend the RLVR paradigm to open-ended tasks by integrating rubric-based rewards, where carefully designed rubrics serve as structured, model-interpretable criteria for automatic scoring of subjective outputs. We construct, to our knowledge, the largest rubric reward system to date, with over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration. Implementing rubric-based RL is challenging; we tackle these issues with a clear framework and present an open-sourced Qwen-30B-A3B model with notable gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by +2.4%, while preserving general and reasoning abilities. 2) Our method provides fine-grained stylistic control, using rubrics as anchors to mitigate the \"AI-like\" tone and produce more human-like, expressive responses. We share key lessons in rubric construction, data selection, and training, and discuss limitations and future releases.",
      "tldr_zh": "è¯¥ç ”ç©¶æ‰©å±•äº† Reinforcement Learning from Verifiable Rewards (RLVR) èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³å…¶åœ¨å¤„ç†ä¸»è§‚æ€§è¾ƒå¼ºçš„ open-ended tasks æ—¶é¢ä¸´çš„å±€é™æ€§ã€‚ä½œè€…æå‡ºäº† Reinforcement Learning with Rubric Anchors æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥ç²¾å¿ƒè®¾è®¡çš„ rubrics ä½œä¸ºç»“æ„åŒ–ä¸”å¯è¢«æ¨¡å‹è§£é‡Šçš„è‡ªåŠ¨è¯„åˆ†æ ‡å‡†ï¼Œå°†éªŒè¯æ€§å¥–åŠ±çš„åº”ç”¨èŒƒå›´ä»ä»£ç å’Œæ•°å­¦æ‰©å±•åˆ°æ›´å¹¿æ³›çš„å¼€æ”¾å¼é¢†åŸŸã€‚è¯¥å›¢é˜Ÿæ„å»ºäº†åŒ…å«è¶…è¿‡ 10,000 ä¸ª rubrics çš„å¤§è§„æ¨¡ç³»ç»Ÿï¼Œæ•´åˆäº†æ¥è‡ªäººç±»ã€Large Language Models (LLMs) ä»¥åŠäººæœºåä½œçš„è¯„åˆ†å‡†åˆ™ã€‚åŸºäºè¯¥æ¡†æ¶è®­ç»ƒå‡ºçš„ Qwen-30B-A3B æ¨¡å‹åœ¨ä»…ä½¿ç”¨ 5,000 ä½™ä¸ªæ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œåœ¨ open-ended benchmarks ä¸­å®ç°äº† 5.2% çš„æ€§èƒ½æå‡ï¼Œè¡¨ç°ä¼˜äºå‚æ•°é‡å·¨å¤§çš„ DeepSeek-V3 æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—å¢å¼ºäººæ–‡é¢†åŸŸè¡¨ç°çš„åŒæ—¶ï¼Œæœ‰æ•ˆä¿ç•™äº†æ¨¡å‹çš„é€šç”¨å’Œæ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ rubrics ä¸ºé”šç‚¹å®ç°äº†ç²¾ç»†åŒ–çš„é£æ ¼æ§åˆ¶ï¼ŒæˆåŠŸå‡è½»äº† AI-like çš„è¯­æ°”ï¼Œä½¿ç”Ÿæˆçš„å›å¤æ›´å…·è¡¨ç°åŠ›ä¸”æ›´æ¥è¿‘äººç±»é£æ ¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "technical report",
      "pdf_url": "https://arxiv.org/pdf/2508.12790v1",
      "published_date": "2025-08-18 10:06:08 UTC",
      "updated_date": "2025-08-18 10:06:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:24.541209+00:00"
    },
    {
      "arxiv_id": "2508.12782v1",
      "title": "HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds",
      "title_zh": "HeroBenchï¼šè™šæ‹Ÿä¸–ç•Œä¸­é•¿ç¨‹è§„åˆ’ä¸ç»“æ„åŒ–æ¨ç†çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Petr Anokhin",
        "Roman Khalikov",
        "Stefan Rebrikov",
        "Viktor Volkov",
        "Artyom Sorokin",
        "Vincent Bissonnette"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in isolated step-by-step reasoning tasks such as mathematics and programming, but their proficiency in long-horizon planning, where solutions require extended, structured sequences of interdependent actions, remains underexplored. Existing benchmarks typically assess LLMs through abstract or low-dimensional algorithmic tasks, failing to capture the complexity of realistic planning environments. We introduce HeroBench, a novel benchmark designed specifically to evaluate long-horizon planning and structured reasoning within complex RPG-inspired virtual worlds. HeroBench provides a rigorously constructed dataset of tasks covering a wide range of difficulties, a simulated environment to execute and validate agent plans, and detailed analytical tools for evaluating model performance. Tasks challenge models to formulate strategic plans, efficiently gather resources, master necessary skills, craft equipment, and defeat adversaries, reflecting practical scenarios' layered dependencies and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning both open-source and proprietary models, including the GPT-5 family, reveals substantial performance disparities rarely observed in conventional reasoning benchmarks. Detailed error analysis further uncovers specific weaknesses in current models' abilities to generate robust high-level plans and reliably execute structured actions. HeroBench thus not only significantly advances the evaluation of LLM reasoning but also provides a flexible, scalable foundation for future research into advanced, autonomous planning in virtual environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†HeroBenchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤æ‚è™šæ‹Ÿä¸–ç•Œä¸­é•¿ç¨‹è§„åˆ’(Long-Horizon Planning)å’Œç»“æ„åŒ–æ¨ç†(Structured Reasoning)èƒ½åŠ›çš„å…¨æ–°åŸºå‡†æµ‹è¯•ã€‚é’ˆå¯¹ç°æœ‰åŸºå‡†æµ‹è¯•å¾€å¾€å±€é™äºæŠ½è±¡æˆ–ä½ç»´ä»»åŠ¡çš„å±€é™æ€§ï¼ŒHeroBenchæ„å»ºäº†ä¸€ä¸ªå—è§’è‰²æ‰®æ¼”æ¸¸æˆ(RPG)å¯å‘çš„æ¨¡æ‹Ÿç¯å¢ƒï¼Œå¹¶æä¾›äº†ä¸¥å¯†æ„å»ºçš„å¤šéš¾åº¦ä»»åŠ¡æ•°æ®é›†å’Œè¯¦å°½çš„æ€§èƒ½åˆ†æå·¥å…·ã€‚è¯¥åŸºå‡†è¦æ±‚æ¨¡å‹åœ¨å…·å¤‡å±‚çº§ä¾èµ–å’Œçº¦æŸçš„åœºæ™¯ä¸‹ï¼Œé€šè¿‡åˆ¶å®šæˆ˜ç•¥è®¡åˆ’ã€æ”¶é›†èµ„æºã€æŒæ¡æŠ€èƒ½ã€æ‰“é€ è£…å¤‡åŠå‡»è´¥æ•Œäººç­‰ä»»åŠ¡ï¼Œæ¥å±•ç¤ºå…¶æ‰§è¡Œå¤æ‚åºåˆ—åŠ¨ä½œçš„èƒ½åŠ›ã€‚é€šè¿‡å¯¹åŒ…æ‹¬GPT-5ç³»åˆ—åœ¨å†…çš„25ä¸ªå°–ç«¯å¼€æºåŠç§æœ‰LLMsè¿›è¡Œå¹¿æ³›è¯„ä¼°ï¼Œç»“æœæ­ç¤ºäº†åœ¨ä¼ ç»Ÿæ¨ç†åŸºå‡†ä¸­éš¾ä»¥è§‚å¯Ÿåˆ°çš„æ˜¾è‘—æ€§èƒ½å·®å¼‚ã€‚æ·±å…¥çš„é”™è¯¯åˆ†æè¿›ä¸€æ­¥æŒ‡å‡ºäº†å½“å‰æ¨¡å‹åœ¨ç”Ÿæˆé²æ£’çš„é«˜çº§è§„åˆ’å’Œå¯é æ‰§è¡Œç»“æ„åŒ–æ“ä½œæ–¹é¢çš„ç‰¹å®šçŸ­æ¿ã€‚HeroBenchä¸ä»…æ˜¾è‘—æå‡äº†LLMæ¨ç†èƒ½åŠ›çš„è¯„ä»·æ ‡å‡†ï¼Œä¹Ÿä¸ºæœªæ¥åœ¨è™šæ‹Ÿç¯å¢ƒä¸­æ¢ç´¢é«˜çº§è‡ªä¸»è§„åˆ’ç ”ç©¶æä¾›äº†çµæ´»ä¸”å¯æ‰©å±•çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code is available at https://github.com/stefanrer/HeroBench",
      "pdf_url": "https://arxiv.org/pdf/2508.12782v1",
      "published_date": "2025-08-18 09:59:02 UTC",
      "updated_date": "2025-08-18 09:59:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:16.585101+00:00"
    },
    {
      "arxiv_id": "2508.12776v2",
      "title": "Randomized PCA Forest for Outlier Detection",
      "title_zh": "ç”¨äºå¼‚å¸¸æ£€æµ‹çš„éšæœºåŒ– PCA æ£®æ—",
      "authors": [
        "Muhammad Rajabinasab",
        "Farhad Pakdaman",
        "Moncef Gabbouj",
        "Peter Schneider-Kamp",
        "Arthur Zimek"
      ],
      "abstract": "We propose a novel unsupervised outlier detection method based on Randomized Principal Component Analysis (PCA). Inspired by the performance of Randomized PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a novel unsupervised outlier detection method that utilizes RPCA Forest for outlier detection. Experimental results showcase the superiority of the proposed approach compared to the classical and state-of-the-art methods in performing the outlier detection task on several datasets while performing competitively on the rest. The extensive analysis of the proposed method reflects it high generalization power and its computational efficiency, highlighting it as a good choice for unsupervised outlier detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Randomized Principal Component Analysis (RPCA) çš„æ–°å‹æ— ç›‘ç£ç¦»ç¾¤ç‚¹æ£€æµ‹æ–¹æ³•ã€‚å—åˆ° RPCA Forest åœ¨è¿‘ä¼¼ K-Nearest Neighbor (KNN) æœç´¢ä¸­å‡ºè‰²è¡¨ç°çš„å¯å‘ï¼Œä½œè€…å¼€å‘äº†åˆ©ç”¨ RPCA Forest è¿›è¡Œç¦»ç¾¤ç‚¹æ£€æµ‹çš„æŠ€æœ¯æ¡†æ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†çš„ç¦»ç¾¤ç‚¹æ£€æµ‹ä»»åŠ¡ä¸­ä¼˜äºç»å…¸åŠå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶åœ¨å…¶ä»–æµ‹è¯•ä¸­ä¿æŒäº†æå¼ºçš„ç«äº‰åŠ›ã€‚å¹¿æ³›çš„åˆ†æè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·å¤‡æé«˜çš„æ³›åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ï¼Œæ˜¯è¿›è¡Œæ— ç›‘ç£ç¦»ç¾¤ç‚¹æ£€æµ‹çš„ç†æƒ³é€‰æ‹©ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12776v2",
      "published_date": "2025-08-18 09:52:05 UTC",
      "updated_date": "2025-08-22 08:24:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:15.954806+00:00"
    },
    {
      "arxiv_id": "2508.14114v1",
      "title": "Ambiguity Resolution with Human Feedback for Code Writing Tasks",
      "title_zh": "é¢å‘ä»£ç ç¼–å†™ä»»åŠ¡çš„åŸºäºäººç±»åé¦ˆçš„æ­§ä¹‰æ¶ˆé™¤",
      "authors": [
        "Aditey Nandan",
        "Viraj Kumar"
      ],
      "abstract": "Specifications for code writing tasks are usually expressed in natural language and may be ambiguous. Programmers must therefore develop the ability to recognize ambiguities in task specifications and resolve them by asking clarifying questions. We present and evaluate a prototype system, based on a novel technique (ARHF: Ambiguity Resolution with Human Feedback), that (1) suggests specific inputs on which a given task specification may be ambiguous, (2) seeks limited human feedback about the code's desired behavior on those inputs, and (3) uses this feedback to generate code that resolves these ambiguities. We evaluate the efficacy of our prototype, and we discuss the implications of such assistive systems on Computer Science education.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»£ç ç¼–å†™ä»»åŠ¡ä¸­è‡ªç„¶è¯­è¨€è§„èŒƒå­˜åœ¨çš„æ­§ä¹‰æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º ARHF (Ambiguity Resolution with Human Feedback) çš„æ–°å‹åŸå‹ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡ä¸»åŠ¨è¯†åˆ«ä»»åŠ¡è§„èŒƒä¸­å¯èƒ½å¯¼è‡´æ­§ä¹‰çš„ç‰¹å®šè¾“å…¥ï¼Œå¼•å¯¼äººç±»é’ˆå¯¹è¿™äº›è¾“å…¥æä¾›æœ‰é™çš„è¡Œä¸ºåé¦ˆï¼Œå¹¶åˆ©ç”¨è¯¥åé¦ˆç”Ÿæˆèƒ½å¤Ÿæ¶ˆé™¤æ­§ä¹‰çš„ä»£ç ã€‚ç ”ç©¶å›¢é˜Ÿè¯„ä¼°äº†è¯¥åŸå‹çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†æ­¤ç±»è¾…åŠ©ç³»ç»Ÿå¯¹è®¡ç®—æœºç§‘å­¦æ•™è‚² (Computer Science education) çš„æ½œåœ¨å½±å“ã€‚å®éªŒè¡¨æ˜ ARHF èƒ½å¤Ÿæœ‰æ•ˆè¾…åŠ©ç¨‹åºå‘˜è¯†åˆ«å¹¶è§£å†³è§„æ ¼è¯´æ˜ä¸­çš„æ¨¡ç³Šç‚¹ï¼Œé€šè¿‡å°†äººç±»åé¦ˆé›†æˆåˆ°ä»£ç ç”Ÿæˆæµç¨‹ä¸­æå‡äº†ä»»åŠ¡æ‰§è¡Œçš„å‡†ç¡®æ€§ã€‚è¿™ä¸€ç ”ç©¶ä¸ºè§£å†³è‡ªç„¶è¯­è¨€åˆ°ä»£ç è½¬æ¢è¿‡ç¨‹ä¸­çš„è¯­ä¹‰ç†è§£æŒ‘æˆ˜æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at the Proceedings of the 33rd International Conference on Computers in Education (ICCE 2025), Asia-Pacific Society for Computers in Education (APSCE)",
      "pdf_url": "https://arxiv.org/pdf/2508.14114v1",
      "published_date": "2025-08-18 09:46:26 UTC",
      "updated_date": "2025-08-18 09:46:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:19.661512+00:00"
    },
    {
      "arxiv_id": "2508.12769v3",
      "title": "CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description",
      "title_zh": "CRED-SQLï¼šé€šè¿‡èšç±»æ£€ç´¢ä¸æ‰§è¡Œæè¿°å¢å¼ºçœŸå®ä¸–ç•Œå¤§è§„æ¨¡æ•°æ®åº“çš„ Text-to-SQL è§£æ",
      "authors": [
        "Shaoming Duan",
        "Zirui Wang",
        "Chuanyi Liu",
        "Zhibin Zhu",
        "Yuhao Zhang",
        "Peiyi Han",
        "Liang Yan",
        "Zewu Peng"
      ],
      "abstract": "Recent advances in large language models (LLMs) have significantly improved the accuracy of Text-to-SQL systems. However, a critical challenge remains: the semantic mismatch between natural language questions (NLQs) and their corresponding SQL queries. This issue is exacerbated in large-scale databases, where semantically similar attributes hinder schema linking and semantic drift during SQL generation, ultimately reducing model accuracy. To address these challenges, we introduce CRED-SQL, a framework designed for large-scale databases that integrates Cluster Retrieval and Execution Description. CRED-SQL first performs cluster-based large-scale schema retrieval to pinpoint the tables and columns most relevant to a given NLQ, alleviating schema mismatch. It then introduces an intermediate natural language representation-Execution Description Language (EDL)-to bridge the gap between NLQs and SQL. This reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL, leveraging LLMs' strong general reasoning capabilities while reducing semantic deviation. Extensive experiments on two large-scale, cross-domain benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new state-of-the-art (SOTA) performance, validating its effectiveness and scalability. Our code is available at https://github.com/smduan/CRED-SQL.git",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡æ•°æ®åº“ Text-to-SQL è§£æä¸­å­˜åœ¨çš„è‡ªç„¶è¯­è¨€é—®é¢˜ä¸ SQL è¯­å¥é—´çš„è¯­ä¹‰å¤±é…ï¼ˆsemantic mismatchï¼‰ä»¥åŠæ¨¡å¼é“¾æ¥ï¼ˆschema linkingï¼‰éš¾é¢˜ï¼Œæå‡ºäº† CRED-SQL æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨ Cluster Retrieval æŠ€æœ¯ç²¾å‡†å®šä½ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„æ¨¡å¼ç»„ä»¶ï¼Œä»¥è§£å†³å¤§è§„æ¨¡ç¯å¢ƒä¸‹çš„æ¨¡å¼å¤±é…é—®é¢˜ã€‚æ¥ç€ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†åä¸º Execution Description Language (EDL) çš„ä¸­é—´è‡ªç„¶è¯­è¨€è¡¨ç¤ºï¼Œå°†ä»»åŠ¡é‡æ„ä¸º Text-to-EDL å’Œ EDL-to-SQL ä¸¤ä¸ªé˜¶æ®µï¼Œä»è€Œå……åˆ†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¼ºæ¨ç†èƒ½åŠ›å¹¶æœ‰æ•ˆå‡å°‘è¯­ä¹‰æ¼‚ç§»ï¼ˆsemantic driftï¼‰ã€‚åœ¨ SpiderUnion å’Œ BirdUnion ä¸¤ä¸ªå¤§è§„æ¨¡è·¨åŸŸåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCRED-SQL è¾¾åˆ°äº†æ–°çš„ SOTA æ€§èƒ½ã€‚è¯¥ç ”ç©¶ä¸ä»…æ˜¾è‘—æå‡äº†æ¨¡å‹è§£æçš„å‡†ç¡®åº¦ï¼Œè¿˜éªŒè¯äº†å…¶åœ¨å¤„ç†ç°å®ä¸–ç•Œå¤§è§„æ¨¡æ•°æ®åº“ä»»åŠ¡æ—¶çš„æœ‰æ•ˆæ€§ä¸å¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12769v3",
      "published_date": "2025-08-18 09:43:07 UTC",
      "updated_date": "2025-08-20 08:11:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:36.758154+00:00"
    },
    {
      "arxiv_id": "2508.12766v1",
      "title": "Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors",
      "title_zh": "åˆ©ç”¨é¢å‘ç¾¤ç»„çš„ä¸€è‡´æ€§çº¦æŸå®ç° CdZnTe åŠå¯¼ä½“çš„åŠç›‘ç£è¯­ä¹‰åˆ†å‰²",
      "authors": [
        "Peihao Li",
        "Yan Fang",
        "Man Liu",
        "Huihui Bai",
        "Anhong Wang",
        "Yunchao Wei",
        "Yao Zhao"
      ],
      "abstract": "Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging due to the low-contrast defect boundaries, necessitating annotators to cross-reference multiple views. These views share a single ground truth (GT), forming a unique ``many-to-one'' relationship. This characteristic renders advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as they are generally limited by a ``one-to-one'' relationship, where each image is independently associated with its GT. Such limitation may lead to error accumulation in low-contrast regions, further exacerbating confirmation bias. To address this issue, we revisit the SSS pipeline from a group-oriented perspective and propose a human-inspired solution: the Intra-group Consistency Augmentation Framework (ICAF). First, we experimentally validate the inherent consistency constraints within CdZnTe groups, establishing a group-oriented baseline using the Intra-group View Sampling (IVS). Building on this insight, we introduce the Pseudo-label Correction Network (PCN) to enhance consistency representation, which consists of two key modules. The View Augmentation Module (VAM) improves boundary details by dynamically synthesizing a boundary-aware view through the aggregation of multiple views. In the View Correction Module (VCM), this synthesized view is paired with other views for information interaction, effectively emphasizing salient regions while minimizing noise. Extensive experiments demonstrate the effectiveness of our solution for CdZnTe materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation model, we achieve a 70.6\\% mIoU on the CdZnTe dataset using only 2 group-annotated data (5\\textperthousand). The code is available at \\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¢²é”Œé•‰ (CdZnTe) åŠå¯¼ä½“å›¾åƒæ ‡æ³¨ä¸­ç”±äºç¼ºé™·è¾¹ç•Œå¯¹æ¯”åº¦ä½ï¼Œä»¥åŠç°æœ‰åŠç›‘ç£è¯­ä¹‰åˆ†å‰² (SSS) æ–¹æ³•éš¾ä»¥å¤„ç†å¤šè§†å›¾å…±äº«å•ä¸€çœŸå€¼çš„â€œå¤šå¯¹ä¸€â€å…³ç³»è€Œå¯¼è‡´çš„ç¡®è®¤åå·®é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…ä»ç»„å¯¼å‘è§†è§’å‡ºå‘ï¼Œæå‡ºäº†ä¸€ç§å—äººç±»å¯å‘ã€åä¸ºç»„å†…ä¸€è‡´æ€§å¢å¼ºæ¡†æ¶ (ICAF) çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶é€šè¿‡ç»„å†…è§†å›¾é‡‡æ · (IVS) å»ºç«‹åŸºçº¿ï¼Œå¹¶åˆ©ç”¨åŒ…å«è§†å›¾å¢å¼ºæ¨¡å— (VAM) å’Œè§†å›¾ä¿®æ­£æ¨¡å— (VCM) çš„ä¼ªæ ‡ç­¾ä¿®æ­£ç½‘ç»œ (PCN) æ¥å¼ºåŒ–ä¸€è‡´æ€§è¡¨ç¤ºã€‚VAM é€šè¿‡èšåˆå¤šè§†å›¾åŠ¨æ€åˆæˆè¾¹ç•Œæ„ŸçŸ¥è§†å›¾ï¼Œè€Œ VCM åˆ™é€šè¿‡ä¿¡æ¯äº¤äº’çªå‡ºæ˜¾è‘—åŒºåŸŸå¹¶æœ‰æ•ˆæŠ‘åˆ¶å™ªå£°ã€‚å®éªŒè¯æ˜ï¼Œåœ¨ä½¿ç”¨ DeepLabV3+ ä½œä¸ºéª¨å¹²ç½‘ç»œçš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•ä»…éœ€ 2 ç»„æ ‡æ³¨æ•°æ®ï¼ˆ5â€°ï¼‰å³å¯åœ¨ CdZnTe æ•°æ®é›†ä¸Šè¾¾åˆ° 70.6% çš„ mIoUã€‚è¿™ä¸€æˆæœå±•ç¤ºäº† ICAF åœ¨åŠå¯¼ä½“ææ–™åˆ†å‰²ä»»åŠ¡ä¸­çš„å“è¶Šæ•ˆèƒ½ï¼Œä¸ºä½å¯¹æ¯”åº¦å·¥ä¸šå›¾åƒçš„è‡ªåŠ¨åˆ†ææä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12766v1",
      "published_date": "2025-08-18 09:40:36 UTC",
      "updated_date": "2025-08-18 09:40:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:30.460976+00:00"
    },
    {
      "arxiv_id": "2508.12755v1",
      "title": "CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke",
      "title_zh": "CLAIRE-DSAï¼šé¢å‘æ€¥æ€§ç¼ºè¡€æ€§è„‘å’ä¸­è®¡ç®—æœºè§†è§‰æµç¨‹è´¨é‡ä¿è¯çš„è§å…‰é€è§†å›¾åƒåˆ†ç±»",
      "authors": [
        "Cristo J. van den Berg",
        "Frank G. te Nijenhuis",
        "Mirre J. Blaauboer",
        "Daan T. W. van Erp",
        "Carlijn M. Keppels",
        "Matthijs van der Sluijs",
        "Bob Roozenbeek",
        "Wim van Zwam",
        "Sandra Cornelissen",
        "Danny Ruijters",
        "Ruisheng Su",
        "Theo van Walsum"
      ],
      "abstract": "Computer vision models can be used to assist during mechanical thrombectomy (MT) for acute ischemic stroke (AIS), but poor image quality often degrades performance. This work presents CLAIRE-DSA, a deep learning--based framework designed to categorize key image properties in minimum intensity projections (MinIPs) acquired during MT for AIS, supporting downstream quality control and workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models, fine-tuned to predict nine image properties (e.g., presence of contrast, projection angle, motion artefact severity). Separate classifiers were trained on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$ to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by filtering poor quality images and comparing segmentation performance on filtered and unfiltered datasets. Segmentation success rate increased from $42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an automated tool for accurately classifying image properties in DSA series of acute ischemic stroke patients, supporting image annotation and quality control in clinical and research applications. Source code is available at https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CLAIRE-DSAï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ (deep learning)çš„æ¡†æ¶ï¼Œæ—¨åœ¨å¯¹æ€¥æ€§ç¼ºè¡€æ€§è„‘å’ä¸­(AIS)æœºæ¢°å–æ “(MT)æ‰‹æœ¯ä¸­çš„é€è§†å›¾åƒå±æ€§è¿›è¡Œè‡ªåŠ¨åˆ†ç±»ã€‚è¯¥æ¡†æ¶é‡‡ç”¨é¢„è®­ç»ƒçš„ResNetä½œä¸ºéª¨å¹²æ¨¡å‹ï¼Œé€šè¿‡å¾®è°ƒæ¥é¢„æµ‹åŒ…æ‹¬å¯¹æ¯”åº¦ã€æŠ•å½±è§’åº¦åŠè¿åŠ¨ä¼ªå½±(motion artefact)ä¸¥é‡ç¨‹åº¦åœ¨å†…çš„ä¹ç§å…³é”®å›¾åƒå±æ€§ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨åŒ…å«1,758ä¸ªæœ€å°å¯†åº¦æŠ•å½±(MinIPs)çš„æ ‡æ³¨æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹åœ¨å„é¡¹æŒ‡æ ‡ä¸Šè¡¨ç°å“è¶Šï¼ŒROC-AUCè¾¾åˆ°0.91è‡³0.98ã€‚é€šè¿‡åˆ©ç”¨CLAIRE-DSAè¿‡æ»¤ä½è´¨é‡å›¾åƒï¼Œä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡çš„æˆåŠŸç‡ä»42%æ˜¾è‘—æé«˜è‡³69%(p < 0.001)ã€‚è¯¥å·¥å…·ä¸ºä¼˜åŒ–è®¡ç®—æœºè§†è§‰æµæ°´çº¿çš„è´¨é‡æ§åˆ¶(quality control)æä¾›äº†é‡è¦æ”¯æŒï¼Œåœ¨ä¸´åºŠå’Œå­¦æœ¯ç ”ç©¶çš„DSAç³»åˆ—å›¾åƒæ ‡æ³¨ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 4 figures, workshop paper accepted at https://switchmiccai.github.io/switch/",
      "pdf_url": "https://arxiv.org/pdf/2508.12755v1",
      "published_date": "2025-08-18 09:28:58 UTC",
      "updated_date": "2025-08-18 09:28:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:31.254830+00:00"
    },
    {
      "arxiv_id": "2508.12754v1",
      "title": "Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants",
      "title_zh": "è¶…è¶Šä¼¦ç†å¯¹é½ï¼šå¤§è¯­è¨€æ¨¡å‹ä½œä¸ºäººå·¥é“å¾·åŠ©æ‰‹çš„è¯„ä¼°",
      "authors": [
        "Alessio Galatolo",
        "Luca Alberto Rappuoli",
        "Katie Winkle",
        "Meriem Beloucif"
      ],
      "abstract": "The recent rise in popularity of large language models (LLMs) has prompted considerable concerns about their moral capabilities. Although considerable effort has been dedicated to aligning LLMs with human moral values, existing benchmarks and evaluations remain largely superficial, typically measuring alignment based on final ethical verdicts rather than explicit moral reasoning. In response, this paper aims to advance the investigation of LLMs' moral capabilities by examining their capacity to function as Artificial Moral Assistants (AMAs), systems envisioned in the philosophical literature to support human moral deliberation. We assert that qualifying as an AMA requires more than what state-of-the-art alignment techniques aim to achieve: not only must AMAs be able to discern ethically problematic situations, they should also be able to actively reason about them, navigating between conflicting values outside of those embedded in the alignment phase. Building on existing philosophical literature, we begin by designing a new formal framework of the specific kind of behaviour an AMA should exhibit, individuating key qualities such as deductive and abductive moral reasoning. Drawing on this theoretical framework, we develop a benchmark to test these qualities and evaluate popular open LLMs against it. Our results reveal considerable variability across models and highlight persistent shortcomings, particularly regarding abductive moral reasoning. Our work connects theoretical philosophy with practical AI evaluation while also emphasising the need for dedicated strategies to explicitly enhance moral reasoning capabilities in LLMs. Code available at https://github.com/alessioGalatolo/AMAeval",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é“å¾·èƒ½åŠ›æ–¹é¢çš„å±€é™æ€§ï¼ŒæŒ‡å‡ºç›®å‰çš„å¯¹é½æŠ€æœ¯å¾€å¾€è¿‡äºè¡¨é¢ï¼Œä»…å…³æ³¨æœ€ç»ˆçš„ä¼¦ç†ç»“è®ºè€Œå¿½ç•¥äº†æ˜¾å¼çš„é“å¾·æ¨ç†ã€‚ä¸ºäº†æ·±å…¥è¯„ä¼°æ¨¡å‹çš„é“å¾·æ½œåŠ›ï¼Œæœ¬æ–‡æå‡ºäº†å°†LLMsä½œä¸ºäººå·¥é“å¾·åŠ©æ‰‹(Artificial Moral Assistants, AMAs)çš„ç ”ç©¶è§†è§’ï¼Œè®¤ä¸ºçœŸæ­£çš„AMAä¸ä»…è¦èƒ½è¯†åˆ«ä¼¦ç†é—®é¢˜ï¼Œè¿˜éœ€å…·å¤‡åœ¨å†²çªä»·å€¼è§‚ä¹‹é—´è¿›è¡Œä¸»åŠ¨æ¨ç†çš„èƒ½åŠ›ã€‚åŸºäºå“²å­¦æ–‡çŒ®ï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸€ä¸ªå…¨æ–°çš„å½¢å¼åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨ç•Œå®šAMAåº”å…·å¤‡çš„å…³é”®ç‰¹è´¨ï¼Œç‰¹åˆ«æ˜¯æ¼”ç»(deductive)å’Œæº¯å› (abductive)é“å¾·æ¨ç†èƒ½åŠ›ã€‚åŸºäºè¯¥ç†è®ºæ¡†æ¶ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€å¥—åŸºå‡†æµ‹è¯•é›†å¹¶å¯¹ä¸»æµçš„å¼€æºLLMsè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºä¸åŒæ¨¡å‹ä¹‹é—´è¡¨ç°å·®å¼‚æ˜¾è‘—ï¼Œä¸”åœ¨æº¯å› é“å¾·æ¨ç†(abductive moral reasoning)æ–¹é¢æ™®éå­˜åœ¨æŒç»­æ€§çš„ç¼ºé™·ã€‚è¯¥å·¥ä½œå°†ç†è®ºå“²å­¦ä¸äººå·¥æ™ºèƒ½è¯„ä¼°ç›¸ç»“åˆï¼Œå¼ºè°ƒäº†å¼€å‘ä¸“é—¨ç­–ç•¥ä»¥æ˜¾å¼å¢å¼ºLLMsé“å¾·æ¨ç†èƒ½åŠ›çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Full version of the paper published in ECAI 2025 proceedings (IOS Press, CC BY-NC 4.0)",
      "pdf_url": "https://arxiv.org/pdf/2508.12754v1",
      "published_date": "2025-08-18 09:28:55 UTC",
      "updated_date": "2025-08-18 09:28:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:42.162177+00:00"
    },
    {
      "arxiv_id": "2508.14113v1",
      "title": "Federated Action Recognition for Smart Worker Assistance Using FastPose",
      "title_zh": "åŸºäº FastPose çš„æ™ºèƒ½å·¥äººè¾…åŠ©è”é‚¦åŠ¨ä½œè¯†åˆ«",
      "authors": [
        "Vinit Hegiste",
        "Vidit Goyal",
        "Tatjana Legler",
        "Martin Ruskowski"
      ],
      "abstract": "In smart manufacturing environments, accurate and real-time recognition of worker actions is essential for productivity, safety, and human-machine collaboration. While skeleton-based human activity recognition (HAR) offers robustness to lighting, viewpoint, and background variations, most existing approaches rely on centralized datasets, which are impractical in privacy-sensitive industrial scenarios. This paper presents a federated learning (FL) framework for pose-based HAR using a custom skeletal dataset of eight industrially relevant upper-body gestures, captured from five participants and processed using a modified FastPose model. Two temporal backbones, an LSTM and a Transformer encoder, are trained and evaluated under four paradigms: centralized, local (per-client), FL with weighted federated averaging (FedAvg), and federated ensemble learning (FedEnsemble). On the global test set, the FL Transformer improves over centralized training by +12.4 percentage points, with FedEnsemble delivering a +16.3 percentage points gain. On an unseen external client, FL and FedEnsemble exceed centralized accuracy by +52.6 and +58.3 percentage points, respectively. These results demonstrate that FL not only preserves privacy but also substantially enhances cross-user generalization, establishing it as a practical solution for scalable, privacy-aware HAR in heterogeneous industrial settings.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹æ™ºèƒ½åˆ¶é€ ä¸­å·¥äººåŠ¨ä½œè¯†åˆ«(HAR)çš„å®æ—¶æ€§ä¸éšç§æ•æ„Ÿæ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº FastPose çš„è”é‚¦å­¦ä¹ (Federated Learning)æ¡†æ¶ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡æ”¹è¿›çš„ FastPose æ¨¡å‹å¤„ç†åŒ…å«å…«ç§å·¥ä¸šç›¸å…³ä¸ŠåŠèº«æ‰‹åŠ¿çš„éª¨éª¼æ•°æ®é›†ï¼Œå¹¶å¯¹æ¯”äº† LSTM å’Œ Transformer ä¸¤ç§æ—¶é—´ä¸»å¹²ç½‘ç»œåœ¨é›†ä¸­å¼ã€æœ¬åœ°åŒ–ã€è”é‚¦åŠ æƒå¹³å‡(FedAvg)åŠè”é‚¦é›†æˆå­¦ä¹ (FedEnsemble)èŒƒå¼ä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å…¨å±€æµ‹è¯•é›†ä¸Šï¼Œè”é‚¦å­¦ä¹ ä¸‹çš„ Transformer æ¨¡å‹å‡†ç¡®ç‡æ¯”é›†ä¸­å¼è®­ç»ƒæå‡äº†12.4ä¸ªç™¾åˆ†ç‚¹ï¼Œè€Œ FedEnsemble æ›´æ˜¯æå‡äº†16.3ä¸ªç™¾åˆ†ç‚¹ã€‚åœ¨é’ˆå¯¹æœªçŸ¥æ–°ç”¨æˆ·çš„æµ‹è¯•ä¸­ï¼Œè”é‚¦å­¦ä¹ ä¸ FedEnsemble çš„å‡†ç¡®ç‡ä¼˜åŠ¿åˆ†åˆ«è¾¾åˆ°äº†52.6å’Œ58.3ä¸ªç™¾åˆ†ç‚¹ã€‚è¯¥ç ”ç©¶è¯æ˜äº†è”é‚¦å­¦ä¹ åœ¨ä¿æŠ¤éšç§çš„åŒæ—¶èƒ½æ˜¾è‘—å¢å¼ºæ¨¡å‹çš„è·¨ç”¨æˆ·æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºå¼‚æ„å·¥ä¸šç¯å¢ƒä¸‹å¤§è§„æ¨¡ã€éšç§æ„ŸçŸ¥çš„åŠ¨ä½œè¯†åˆ«æä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DC",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages and submitted to FLTA2025 conference",
      "pdf_url": "https://arxiv.org/pdf/2508.14113v1",
      "published_date": "2025-08-18 09:28:15 UTC",
      "updated_date": "2025-08-18 09:28:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:00.748161+00:00"
    },
    {
      "arxiv_id": "2508.12745v1",
      "title": "DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification",
      "title_zh": "DCSCRï¼šåŸºäºç±»åˆ«ç‰¹å®šååŒè¡¨ç¤ºçš„å›¾åƒé›†åˆ†ç±»ç½‘ç»œ",
      "authors": [
        "Xizhan Gao",
        "Wei Hu"
      ],
      "abstract": "Image set classification (ISC), which can be viewed as a task of comparing similarities between sets consisting of unordered heterogeneous images with variable quantities and qualities, has attracted growing research attention in recent years. How to learn effective feature representations and how to explore the similarities between different image sets are two key yet challenging issues in this field. However, existing traditional ISC methods classify image sets based on raw pixel features, ignoring the importance of feature learning. Existing deep ISC methods can learn deep features, but they fail to adaptively adjust the features when measuring set distances, resulting in limited performance in few-shot ISC. To address the above issues, this paper combines traditional ISC methods with deep models and proposes a novel few-shot ISC approach called Deep Class-specific Collaborative Representation (DCSCR) network to simultaneously learn the frame- and concept-level feature representations of each image set and the distance similarities between different sets. Specifically, DCSCR consists of a fully convolutional deep feature extractor module, a global feature learning module, and a class-specific collaborative representation-based metric learning module. The deep feature extractor and global feature learning modules are used to learn (local and global) frame-level feature representations, while the class-specific collaborative representation-based metric learning module is exploit to adaptively learn the concept-level feature representation of each image set and thus obtain the distance similarities between different sets by developing a new CSCR-based contrastive loss function. Extensive experiments on several well-known few-shot ISC datasets demonstrate the effectiveness of the proposed method compared with some state-of-the-art image set classification algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾åƒé›†åˆåˆ†ç±» (Image Set Classification, ISC) é¢†åŸŸä¸­ç‰¹å¾è¡¨è¾¾å­¦ä¹ ä¸è¶³ä»¥åŠåœ¨å°‘æ ·æœ¬ (few-shot) åœºæ™¯ä¸‹è·ç¦»åº¦é‡ç¼ºä¹è‡ªé€‚åº”æ€§çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Deep Class-specific Collaborative Representation (DCSCR) çš„æ–°å‹ç½‘ç»œã€‚DCSCR æ¡†æ¶é€šè¿‡ç»“åˆä¼ ç»Ÿ ISC æ–¹æ³•ä¸æ·±åº¦æ¨¡å‹ï¼Œç”±å…¨å·ç§¯æ·±åº¦ç‰¹å¾æå–æ¨¡å—ã€å…¨å±€ç‰¹å¾å­¦ä¹ æ¨¡å—ä»¥åŠåŸºäº class-specific collaborative representation çš„åº¦é‡å­¦ä¹ æ¨¡å—ç»„æˆã€‚è¯¥æ–¹æ³•èƒ½å¤ŸåŒæ—¶å­¦ä¹ å›¾åƒé›†åˆåœ¨ frame-level çš„å±€éƒ¨ä¸å…¨å±€ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶è¿›ä¸€æ­¥æå– concept-level çš„ç‰¹å¾è¡¨è¾¾ã€‚é€šè¿‡å¼•å…¥ä¸€ç§å…¨æ–°çš„åŸºäº CSCR-based contrastive loss function çš„æœºåˆ¶ï¼Œè¯¥ç½‘ç»œå®ç°äº†å¯¹ç‰¹å¾çš„è‡ªé€‚åº”è°ƒæ•´ï¼Œä»è€Œç²¾å‡†è·å–ä¸åŒå›¾åƒé›†é—´çš„è·ç¦»ç›¸ä¼¼åº¦ã€‚åœ¨å¤šä¸ªä¸»æµçš„ few-shot ISC æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDCSCR æ˜¾è‘—ä¼˜äºç°æœ‰çš„ state-of-the-art ç®—æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨å¤„ç†å¤æ‚å›¾åƒé›†åˆåˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12745v1",
      "published_date": "2025-08-18 09:09:55 UTC",
      "updated_date": "2025-08-18 09:09:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:00.959171+00:00"
    },
    {
      "arxiv_id": "2508.12740v1",
      "title": "FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models",
      "title_zh": "FedUNetï¼šä¸€ç§é¢å‘å¼‚æ„æ¨¡å‹è”é‚¦å­¦ä¹ çš„è½»é‡çº§é™„åŠ  U-Net æ¨¡å—",
      "authors": [
        "Beomseok Seo",
        "Kichang Lee",
        "JaeYeon Park"
      ],
      "abstract": "Federated learning (FL) enables decentralized model training without sharing local data. However, most existing methods assume identical model architectures across clients, limiting their applicability in heterogeneous real-world environments. To address this, we propose FedUNet, a lightweight and architecture-agnostic FL framework that attaches a U-Net-inspired additive module to each client's backbone. By sharing only the compact bottleneck of the U-Net, FedUNet enables efficient knowledge transfer without structural alignment. The encoder-decoder design and skip connections in the U-Net help capture both low-level and high-level features, facilitating the extraction of clientinvariant representations. This enables cooperative learning between the backbone and the additive module with minimal communication cost. Experiment with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low communication overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FedUNetï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§ä¸”ä¸æ¶æ„æ— å…³çš„è”é‚¦å­¦ä¹ (Federated Learning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å®¢æˆ·ç«¯æ¨¡å‹æ¶æ„å¼‚æ„å¯¼è‡´çš„é€‚ç”¨æ€§å—é™é—®é¢˜ã€‚FedUNeté€šè¿‡åœ¨æ¯ä¸ªå®¢æˆ·ç«¯çš„éª¨å¹²ç½‘ç»œ(Backbone)ä¸Šé™„åŠ ä¸€ä¸ªå—U-Netå¯å‘çš„åŠ æ€§æ¨¡å—ï¼Œå¹¶ä»…å…±äº«å…¶ç´§å‡‘çš„ç“¶é¢ˆå±‚(Bottleneck)ï¼Œå®ç°äº†æ— éœ€ç»“æ„å¯¹é½çš„é«˜æ•ˆçŸ¥è¯†è½¬ç§»ã€‚è¯¥æ¨¡å—åˆ©ç”¨U-Netçš„ç¼–ç å™¨-è§£ç å™¨(Encoder-Decoder)è®¾è®¡å’Œè·³è·ƒè¿æ¥(Skip Connections)æ¥æ•è·åº•å±‚å’Œé«˜å±‚ç‰¹å¾ï¼Œä»è€Œä¿ƒè¿›å®¢æˆ·ç«¯ä¸å˜è¡¨ç¤º(Client-invariant representations)çš„æå–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä½¿ç”¨VGGå˜ä½“çš„æµ‹è¯•ä¸­ï¼ŒFedUNetåŠå…¶è½»é‡åŒ–ç‰ˆæœ¬åˆ†åˆ«è¾¾åˆ°äº†93.11%å’Œ92.68%çš„å‡†ç¡®ç‡ï¼Œä¸”é€šä¿¡å¼€é”€ä»…ä¸º0.89 MBã€‚è¿™ç§æ–¹æ³•åœ¨ç¡®ä¿é«˜æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†å¼‚æ„æ¨¡å‹ç¯å¢ƒä¸‹çš„é€šä¿¡æˆæœ¬ï¼Œä¸ºååŒå­¦ä¹ æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12740v1",
      "published_date": "2025-08-18 09:03:06 UTC",
      "updated_date": "2025-08-18 09:03:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:36:59.852309+00:00"
    },
    {
      "arxiv_id": "2508.12733v2",
      "title": "LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models",
      "title_zh": "LinguaSafeï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„å…¨é¢å¤šè¯­è¨€å®‰å…¨åŸºå‡†",
      "authors": [
        "Zhiyuan Ning",
        "Tianle Gu",
        "Jiaxin Song",
        "Shixin Hong",
        "Lingyu Li",
        "Huacan Liu",
        "Jie Li",
        "Yixu Wang",
        "Meng Lingyu",
        "Yan Teng",
        "Yingchun Wang"
      ],
      "abstract": "The widespread adoption and increasing prominence of large language models (LLMs) in global technologies necessitate a rigorous focus on ensuring their safety across a diverse range of linguistic and cultural contexts. The lack of a comprehensive evaluation and diverse data in existing multilingual safety evaluations for LLMs limits their effectiveness, hindering the development of robust multilingual safety alignment. To address this critical gap, we introduce LinguaSafe, a comprehensive multilingual safety benchmark crafted with meticulous attention to linguistic authenticity. The LinguaSafe dataset comprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated using a combination of translated, transcreated, and natively-sourced data, our dataset addresses the critical need for multilingual safety evaluations of LLMs, filling the void in the safety evaluation of LLMs across diverse under-represented languages from Hungarian to Malay. LinguaSafe presents a multidimensional and fine-grained evaluation framework, with direct and indirect safety assessments, including further evaluations for oversensitivity. The results of safety and helpfulness evaluations vary significantly across different domains and different languages, even in languages with similar resource levels. Our benchmark provides a comprehensive suite of metrics for in-depth safety evaluation, underscoring the critical importance of thoroughly assessing multilingual safety in LLMs to achieve more balanced safety alignment. Our dataset and code are released to the public to facilitate further research in the field of multilingual LLM safety.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LinguaSafeï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å…¨é¢å¤šè¯­è¨€å®‰å…¨åŸºå‡†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°ä¸­ç¼ºä¹å¤šæ ·åŒ–æ•°æ®å’Œå…¨é¢æ€§çš„é—®é¢˜ã€‚è¯¥æ•°æ®é›†åŒ…å«12ç§è¯­è¨€ï¼ˆæ¶µç›–ä»åŒˆç‰™åˆ©è¯­åˆ°é©¬æ¥è¯­ï¼‰çš„4.5ä¸‡ä¸ªæ¡ç›®ï¼Œé€šè¿‡ç¿»è¯‘ã€å†åˆ›ä½œ(transcreated)å’ŒåŸç”Ÿé‡‡é›†ç›¸ç»“åˆçš„æ–¹å¼ç¡®ä¿äº†è¯­è¨€çš„çœŸå®æ€§ã€‚LinguaSafeæä¾›äº†ä¸€ä¸ªå¤šç»´åº¦ä¸”ç»†ç²’åº¦çš„è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…å«ç›´æ¥ä¸é—´æ¥çš„å®‰å…¨è¯„ä¼°ä»¥åŠå¯¹è¿‡åº¦æ•æ„Ÿæ€§(oversensitivity)çš„è¿›ä¸€æ­¥è¯„ä¼°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸åŒé¢†åŸŸå’Œè¯­è¨€ä¹‹é—´çš„å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§è¯„ä¼°ç»“æœå·®å¼‚æ˜¾è‘—ï¼Œå³ä½¿æ˜¯åœ¨èµ„æºæ°´å¹³ç›¸ä¼¼çš„è¯­è¨€ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¯¥åŸºå‡†ä¸ºæ·±å…¥çš„å®‰å…¨è¯„ä¼°æä¾›äº†ä¸€å¥—å®Œæ•´çš„æŒ‡æ ‡ï¼Œå¼ºè°ƒäº†åœ¨LLMsä¸­è¿›è¡Œå½»åº•çš„å¤šè¯­è¨€å®‰å…¨è¯„ä¼°ä»¥å®ç°å¹³è¡¡å®‰å…¨å¯¹é½(safety alignment)çš„é‡è¦æ€§ã€‚ç›®å‰è¯¥æ•°æ®é›†å’Œä»£ç å·²å‘å…¬ä¼—å¼€æ”¾ï¼Œä»¥ä¿ƒè¿›å¤šè¯­è¨€LLMå®‰å…¨é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12733v2",
      "published_date": "2025-08-18 08:59:01 UTC",
      "updated_date": "2025-08-27 12:21:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:06.260181+00:00"
    },
    {
      "arxiv_id": "2508.12725v1",
      "title": "GTool: Graph Enhanced Tool Planning with Large Language Model",
      "title_zh": "GToolï¼šåŸºäºå›¾å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹å·¥å…·è§„åˆ’",
      "authors": [
        "Wenjie Chen",
        "Wenbin Li",
        "Di Yao",
        "Xuying Meng",
        "Chang Gong",
        "Jingping Bi"
      ],
      "abstract": "Tool planning with large language models (LLMs), referring to selecting, organizing, and preparing the tools necessary to complete a user request, bridges the gap between natural language understanding and task execution. However, current works treat different tools as isolated components and fail to leverage the inherent dependencies of tools, leading to invalid planning results. Since tool dependencies are often incomplete, it becomes challenging for LLMs to accurately identify the appropriate tools required by a user request, especially when confronted with a large toolset. To solve this challenge, we propose \\texttt{GTool}, which is the first work aiming to enhance the tool planning ability of LLMs under incomplete dependencies. \\texttt{GTool} constructs a request-specific tool graph to select tools efficiently and generate the \\texttt{<graph token>} which provides sufficient dependency information understandable by LLMs. Moreover, a missing dependency prediction task is designed to improve the reliability of \\texttt{GTool} with incomplete dependencies. Without trimming LLMs, \\texttt{GTool} can be seamlessly integrated with various LLM backbones without extensive retraining. Extensive experiments show that \\texttt{GTool} achieves more than 29.6\\% performance improvements compared with the state-of-the-art (SOTA) baselines with a light-weight (7B) LLM backbone.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GToolï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸å®Œæ•´ä¾èµ–ç¯å¢ƒä¸‹å·¥å…·è§„åˆ’(Tool planning)èƒ½åŠ›çš„å·¥ä½œã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å°†å·¥å…·è§†ä¸ºå­¤ç«‹ç»„ä»¶è€Œå¿½è§†å†…åœ¨ä¾èµ–å…³ç³»çš„é—®é¢˜ï¼ŒGToolé€šè¿‡æ„å»ºç‰¹å®šäºè¯·æ±‚çš„å·¥å…·å›¾(Tool graph)æ¥é«˜æ•ˆé€‰æ‹©å·¥å…·ï¼Œå¹¶ç”ŸæˆåŒ…å«å……åˆ†ä¾èµ–ä¿¡æ¯çš„`<graph token>`ä¾›LLMsç†è§£ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†ç¼ºå¤±ä¾èµ–é¢„æµ‹ä»»åŠ¡(Missing dependency prediction task)ï¼Œä»¥æå‡æ¨¡å‹åœ¨ä¾èµ–ä¿¡æ¯ä¸å…¨æ—¶çš„å¯é æ€§ã€‚GToolæ— éœ€å¤§è§„æ¨¡é‡è®­å³å¯æ— ç¼é›†æˆè‡³å„ç±»LLMéª¨å¹²ç½‘ç»œï¼Œå…·æœ‰æå¼ºçš„é€šç”¨æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ç»“åˆè½»é‡çº§(7B)éª¨å¹²æ¨¡å‹æ—¶ï¼ŒGToolè¾ƒç°æœ‰æœ€å…ˆè¿›(SOTA)åŸºçº¿æ–¹æ³•å®ç°äº†è¶…è¿‡29.6%çš„æ€§èƒ½æå‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12725v1",
      "published_date": "2025-08-18 08:46:55 UTC",
      "updated_date": "2025-08-18 08:46:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:06.868646+00:00"
    },
    {
      "arxiv_id": "2509.09686v2",
      "title": "GeoGPT-RAG Technical Report",
      "title_zh": "GeoGPT-RAG æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Fei Huang",
        "Fan Wu",
        "Zeqing Zhang",
        "Qihao Wang",
        "Long Zhang",
        "Grant Michael Boquet",
        "Hongyang Chen"
      ],
      "abstract": "GeoGPT is an open large language model system built to advance research in the geosciences. To enhance its domain-specific capabilities, we integrated Retrieval Augmented Generation(RAG), which augments model outputs with relevant information retrieved from an external knowledge source. GeoGPT uses RAG to draw from the GeoGPT Library, a specialized corpus curated for geoscientific content, enabling it to generate accurate, context-specific answers. Users can also create personalized knowledge bases by uploading their own publication lists, allowing GeoGPT to retrieve and respond using user-provided materials. To further improve retrieval quality and domain alignment, we fine-tuned both the embedding model and a ranking model that scores retrieved passages by relevance to the query. These enhancements optimize RAG for geoscience applications and significantly improve the system's ability to deliver precise and trustworthy outputs. GeoGPT reflects a strong commitment to open science through its emphasis on collaboration, transparency, and community driven development. As part of this commitment, we have open-sourced two core RAG components-GeoEmbedding and GeoReranker-to support geoscientists, researchers, and professionals worldwide with powerful, accessible AI tools.",
      "tldr_zh": "è¯¥ç ”ç©¶å‘å¸ƒäº†GeoGPT-RAGæŠ€æœ¯æŠ¥å‘Šï¼Œä»‹ç»äº†GeoGPTè¿™ä¸€ä¸ºåœ°çƒç§‘å­¦ç ”ç©¶è®¾è®¡çš„å¼€æ”¾å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿã€‚ä¸ºäº†å¢å¼ºå…¶é¢†åŸŸç‰¹å®šèƒ½åŠ›ï¼Œå›¢é˜Ÿé›†æˆäº†æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯(RAG)ï¼Œä½¿å…¶èƒ½å¤Ÿä»ä¸“é—¨ç­–åˆ’çš„GeoGPT Libraryæˆ–ç”¨æˆ·ä¸Šä¼ çš„ä¸ªæ€§åŒ–çŸ¥è¯†åº“ä¸­æå–ç›¸å…³ä¿¡æ¯ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¯¹åµŒå…¥æ¨¡å‹(Embedding model)å’Œé‡æ’åºæ¨¡å‹(Ranking model)è¿›è¡Œå¾®è°ƒï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†æ£€ç´¢è´¨é‡å’Œé¢†åŸŸå¯¹é½ã€‚ä½œä¸ºå¯¹å¼€æ”¾ç§‘å­¦æ‰¿è¯ºçš„ä¸€éƒ¨åˆ†ï¼Œé¡¹ç›®å¼€æºäº†GeoEmbeddingå’ŒGeoRerankerä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œæ—¨åœ¨ä¸ºå…¨çƒåœ°å­¦å·¥ä½œè€…æä¾›é«˜æ•ˆä¸”æ˜“è·å¾—çš„AIå·¥å…·ã€‚è¿™äº›æŠ€æœ¯å¢å¼ºæ˜¾è‘—æå‡äº†GeoGPTåœ¨å¤„ç†åœ°å­¦å¤æ‚æŸ¥è¯¢æ—¶çš„å‡†ç¡®æ€§ã€ä¸Šä¸‹æ–‡ç›¸å…³æ€§å’Œè¾“å‡ºçš„å¯ä¿¡åº¦ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "19 pages, 10 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.09686v2",
      "published_date": "2025-08-18 08:29:22 UTC",
      "updated_date": "2025-09-15 01:00:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:11.064662+00:00"
    },
    {
      "arxiv_id": "2508.12709v1",
      "title": "MATPAC++: Enhanced Masked Latent Prediction for Self-Supervised Audio Representation Learning",
      "title_zh": "MATPAC++ï¼šé¢å‘è‡ªç›‘ç£éŸ³é¢‘è¡¨ç¤ºå­¦ä¹ çš„å¢å¼ºå‹æ©ç æ½œå˜é‡é¢„æµ‹",
      "authors": [
        "Aurian Quelennec",
        "Pierre Chouteau",
        "Geoffroy Peeters",
        "Slim Essid"
      ],
      "abstract": "Masked latent prediction has emerged as a leading paradigm in self-supervised learning (SSL), especially for general audio and music representation learning. While recent methods have demonstrated strong performance, the role of the predictor module used at the output of such SSL systems remains mainly overlooked, despite being crucial for solving the pretext task at hand. In particular, this module should be able to deal with the ambiguity inherent in audio content, especially when it is composed of multiple sound sources. This work proposes a novel enhancement: integrating Multiple Choice Learning (MCL) to explicitly model prediction ambiguity and improve representation quality. We build on top of the recently proposed MATPAC system, improving its prediction and unsupervised classification pretext tasks with MCL. We extensively evaluate our method, MATPAC++, through both linear probing across multiple downstream tasks and fine-tuning on AudioSet, employing a unified protocol that enables rigorous and fair comparisons with state-of-the-art SSL approaches. Results show that our proposal achieves state-of-the-art when fine-tuned on AudioSet and overall state-of-the-art scores on downstream tasks. Additionally, we examine domain specialisation by training exclusively on music data, where our model achieves state-of-the-art performance with significantly improved efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MATPAC++ï¼Œæ—¨åœ¨å¢å¼ºè‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learning, SSLï¼‰ä¸­æ©è”½æ½œå˜é‡é¢„æµ‹ï¼ˆMasked Latent Predictionï¼‰çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹é€šç”¨éŸ³é¢‘å’ŒéŸ³ä¹è¡¨ç¤ºå­¦ä¹ ã€‚é’ˆå¯¹ç°æœ‰ SSL ç³»ç»Ÿä¸­é¢„æµ‹å™¨æ¨¡å—å¤„ç†å¤šå£°æºéŸ³é¢‘æ­§ä¹‰æ€§ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°å¼•å…¥äº†å¤šé€‰æ‹©å­¦ä¹ ï¼ˆMultiple Choice Learning, MCLï¼‰æ¥æ˜¾å¼å»ºæ¨¡é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚MATPAC++ åœ¨åŸæœ‰çš„ MATPAC ç³»ç»ŸåŸºç¡€ä¸Šï¼Œåˆ©ç”¨ MCL ä¼˜åŒ–äº†å…¶é¢„æµ‹å’Œæ— ç›‘ç£åˆ†ç±»é¢„è®­ç»ƒä»»åŠ¡ï¼Œä»è€Œæå‡äº†ç‰¹å¾è¡¨ç¤ºçš„è´¨é‡ã€‚ç ”ç©¶äººå‘˜é€šè¿‡åœ¨ AudioSet ä¸Šè¿›è¡Œå¾®è°ƒä»¥åŠåœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›è¡Œçº¿æ€§æ¢æµ‹ï¼Œå¯¹è¯¥æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›ä¸”ä¸¥è°¨çš„è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMATPAC++ åœ¨ AudioSet å¾®è°ƒå’Œä¸‹æ¸¸ä»»åŠ¡å¾—åˆ†ä¸Šå‡è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›æ°´å¹³ï¼ˆState-of-the-Artï¼‰ã€‚æ­¤å¤–ï¼Œåœ¨éŸ³ä¹æ•°æ®çš„ç‰¹å®šé¢†åŸŸè®­ç»ƒä¸­ï¼Œè¯¥æ¨¡å‹ä¸ä»…å®ç°äº†é¢†å…ˆçš„æ€§èƒ½ï¼Œè¿˜æ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚éŸ³é¢‘å†…å®¹æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2508.12709v1",
      "published_date": "2025-08-18 08:10:07 UTC",
      "updated_date": "2025-08-18 08:10:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:16.676661+00:00"
    },
    {
      "arxiv_id": "2508.12706v1",
      "title": "Asymmetric Diffusion Recommendation Model",
      "title_zh": "éå¯¹ç§°æ‰©æ•£æ¨èæ¨¡å‹",
      "authors": [
        "Yongchun Zhu",
        "Guanyu Jiang",
        "Jingwu Chen",
        "Feng Zhang",
        "Xiao Yang",
        "Zuotao Liu"
      ],
      "abstract": "Recently, motivated by the outstanding achievements of diffusion models, the diffusion process has been employed to strengthen representation learning in recommendation systems. Most diffusion-based recommendation models typically utilize standard Gaussian noise in symmetric forward and reverse processes in continuous data space. Nevertheless, the samples derived from recommendation systems inhabit a discrete data space, which is fundamentally different from the continuous one. Moreover, Gaussian noise has the potential to corrupt personalized information within latent representations. In this work, we propose a novel and effective method, named Asymmetric Diffusion Recommendation Model (AsymDiffRec), which learns forward and reverse processes in an asymmetric manner. We define a generalized forward process that simulates the missing features in real-world recommendation samples. The reverse process is then performed in an asymmetric latent feature space. To preserve personalized information within the latent representation, a task-oriented optimization strategy is introduced. In the serving stage, the raw sample with missing features is regarded as a noisy input to generate a denoising and robust representation for the final prediction. By equipping base models with AsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and +0.166% in terms of users' active days and app usage duration respectively. Additionally, the extended offline experiments also demonstrate improvements. AsymDiffRec has been implemented in the Douyin Music App.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹(Diffusion models)åœ¨æ¨èç³»ç»Ÿä¸­å› ä½¿ç”¨è¿ç»­ç©ºé—´çš„å¯¹ç§°é«˜æ–¯å™ªå£°è€Œå¯¼è‡´ç¦»æ•£ç‰¹å¾å—æŸåŠä¸ªæ€§åŒ–ä¿¡æ¯ä¸¢å¤±çš„é—®é¢˜ï¼Œæå‡ºäº†éå¯¹ç§°æ‰©æ•£æ¨èæ¨¡å‹(Asymmetric Diffusion Recommendation Model, AsymDiffRec)ã€‚è¯¥æ¨¡å‹ä»¥éå¯¹ç§°æ–¹å¼å­¦ä¹ å‰é¦ˆå’Œåé¦ˆè¿‡ç¨‹ï¼Œé€šè¿‡å®šä¹‰å¹¿ä¹‰å‰å‘è¿‡ç¨‹æ¥æ¨¡æ‹ŸçœŸå®ä¸–ç•Œæ¨èæ ·æœ¬ä¸­çš„ç¼ºå¤±ç‰¹å¾ã€‚åœ¨éå¯¹ç§°æ½œç‰¹å¾ç©ºé—´æ‰§è¡Œåå‘è¿‡ç¨‹çš„åŒæ—¶ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†ä»»åŠ¡å¯¼å‘(task-oriented)çš„ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æœ‰æ•ˆä¿ç•™æ½œè¡¨ç¤ºä¸­çš„ä¸ªæ€§åŒ–ä¿¡æ¯ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæ¨¡å‹å°†å«æœ‰ç¼ºå¤±ç‰¹å¾çš„åŸå§‹æ ·æœ¬è§†ä¸ºå™ªå£°è¾“å…¥ï¼Œç”Ÿæˆå»å™ªä¸”é²æ£’çš„è¡¨ç¤ºç”¨äºæœ€ç»ˆé¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAsymDiffRecåœ¨æŠ–éŸ³éŸ³ä¹(Douyin Music App)çš„åœ¨çº¿A/Bæµ‹è¯•ä¸­ä½¿æ´»è·ƒå¤©æ•°å’Œä½¿ç”¨æ—¶é•¿åˆ†åˆ«æå‡äº†0.131%å’Œ0.166%ï¼Œç¦»çº¿å®éªŒä¹Ÿè¿›ä¸€æ­¥éªŒè¯äº†å…¶åœ¨æå‡æ¨èè´¨é‡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by CIKM2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12706v1",
      "published_date": "2025-08-18 08:05:25 UTC",
      "updated_date": "2025-08-18 08:05:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:24.585164+00:00"
    },
    {
      "arxiv_id": "2508.12702v1",
      "title": "A Unified Cortical Circuit Model with Divisive Normalization and Self-Excitation for Robust Representation and Memory Maintenance",
      "title_zh": "ç»“åˆé™¤æ³•å½’ä¸€åŒ–ä¸è‡ªå…´å¥‹çš„ç»Ÿä¸€çš®å±‚ç¯è·¯æ¨¡å‹ï¼šå®ç°é²æ£’è¡¨å¾ä¸è®°å¿†ç»´æŒ",
      "authors": [
        "Jie Su",
        "Weiwei Wang",
        "Zhaotian Gu",
        "Dahui Wang",
        "Tianyi Qian"
      ],
      "abstract": "Robust information representation and its persistent maintenance are fundamental for higher cognitive functions. Existing models employ distinct neural mechanisms to separately address noise-resistant processing or information maintenance, yet a unified framework integrating both operations remains elusive -- a critical gap in understanding cortical computation. Here, we introduce a recurrent neural circuit that combines divisive normalization with self-excitation to achieve both robust encoding and stable retention of normalized inputs. Mathematical analysis shows that, for suitable parameter regimes, the system forms a continuous attractor with two key properties: (1) input-proportional stabilization during stimulus presentation; and (2) self-sustained memory states persisting after stimulus offset. We demonstrate the model's versatility in two canonical tasks: (a) noise-robust encoding in a random-dot kinematogram (RDK) paradigm; and (b) approximate Bayesian belief updating in a probabilistic Wisconsin Card Sorting Test (pWCST). This work establishes a unified mathematical framework that bridges noise suppression, working memory, and approximate Bayesian inference within a single cortical microcircuit, offering fresh insights into the brain's canonical computation and guiding the design of biologically plausible artificial neural architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„çš®å±‚ç”µè·¯æ¨¡å‹ï¼Œé€šè¿‡ç»“åˆé™¤æ³•å½’ä¸€åŒ–(Divisive Normalization)ä¸è‡ªå…´å¥‹(Self-Excitation)æœºåˆ¶ï¼Œå®ç°äº†ä¿¡æ¯çš„ç¨³å¥è¡¨å¾ä¸æŒä¹…ç»´æŠ¤ã€‚è¯¥æ¡†æ¶è§£å†³äº†ç°æœ‰æ¨¡å‹ä¸­å™ªå£°æŠ—æ€§å¤„ç†ä¸ä¿¡æ¯ç»´æŠ¤æœºåˆ¶ç›¸äº’åˆ†ç¦»çš„é—®é¢˜ï¼Œå¡«è¡¥äº†ç†è§£çš®å±‚è®¡ç®—çš„å…³é”®ç©ºç™½ã€‚æ•°å­¦åˆ†æè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ç‰¹å®šå‚æ•°ä¸‹èƒ½å½¢æˆè¿ç»­å¸å¼•å­(Continuous Attractor)ï¼Œåœ¨åˆºæ¿€æœŸé—´ç»´æŒè¾“å…¥æ¯”ä¾‹ç¨³å®šï¼Œå¹¶åœ¨åˆºæ¿€ç»“æŸåå®ç°è‡ªæˆ‘ç»´æŒçš„è®°å¿†çŠ¶æ€ã€‚ç ”ç©¶é€šè¿‡éšæœºç‚¹è¿åŠ¨å›¾(Random-Dot Kinematogram, RDK)å®éªŒè¯æ˜äº†æ¨¡å‹çš„å™ªå£°ç¨³å¥ç¼–ç èƒ½åŠ›ï¼Œå¹¶åœ¨æ¦‚ç‡å¨æ–¯åº·æ˜Ÿå¡ç‰‡åˆ†ç±»æµ‹è¯•(pWCST)ä¸­æˆåŠŸå®ç°äº†è¿‘ä¼¼è´å¶æ–¯ä¿¡å¿µæ›´æ–°(Approximate Bayesian Belief Updating)ã€‚è¯¥å·¥ä½œå»ºç«‹äº†ä¸€ä¸ªå°†å™ªå£°æŠ‘åˆ¶ã€å·¥ä½œè®°å¿†(Working Memory)ä¸è¿‘ä¼¼è´å¶æ–¯æ¨ç†æ•´åˆåœ¨å•ä¸€çš®å±‚å¾®ç”µè·¯ä¸­çš„ç»Ÿä¸€æ•°å­¦æ¡†æ¶ã€‚è¿™ä¸€æˆæœä¸ä»…ä¸ºå¤§è„‘çš„è§„èŒƒè®¡ç®—æä¾›äº†æ–°è§†è§’ï¼Œä¹Ÿä¸ºè®¾è®¡å…·æœ‰ç”Ÿç‰©åˆç†æ€§çš„äººå·¥æ™ºèƒ½æ¶æ„æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "15 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12702v1",
      "published_date": "2025-08-18 08:00:24 UTC",
      "updated_date": "2025-08-18 08:00:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:25.687699+00:00"
    },
    {
      "arxiv_id": "2508.12692v2",
      "title": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning",
      "title_zh": "é¢å‘æŒç»­å­¦ä¹ çš„å¤šå±‚æ¬¡çŸ¥è¯†è’¸é¦ä¸åŠ¨æ€è‡ªç›‘ç£å­¦ä¹ ",
      "authors": [
        "Taeheon Kim",
        "San Kim",
        "Minhyuk Seo",
        "Dongjae Jeon",
        "Wonje Jeung",
        "Jonghyun Choi"
      ],
      "abstract": "Class-incremental with repetition (CIR), where previously trained classes repeatedly introduced in future tasks, is a more realistic scenario than the traditional class incremental setup, which assumes that each task contains unseen classes. CIR assumes that we can easily access abundant unlabeled data from external sources, such as the Internet. Therefore, we propose two components that efficiently use the unlabeled data to ensure the high stability and the plasticity of models trained in CIR setup. First, we introduce multi-level knowledge distillation (MLKD) that distills knowledge from multiple previous models across multiple perspectives, including features and logits, so the model can maintain much various previous knowledge. Moreover, we implement dynamic self-supervised loss (SSL) to utilize the unlabeled data that accelerates the learning of new classes, while dynamic weighting of SSL keeps the focus of training to the primary task. Both of our proposed components significantly improve the performance in CIR setup, achieving 2nd place in the CVPR 5th CLVISION Challenge.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ›´å…·ç°å®æ„ä¹‰çš„é‡å¤ç±»å¢é‡å­¦ä¹ (Class-incremental with repetition, CIR)åœºæ™¯ï¼Œè¯¥åœºæ™¯å…è®¸åˆ©ç”¨å¤–éƒ¨æ¥æºçš„å¤§é‡æ— æ ‡ç­¾æ•°æ®æ¥ä¼˜åŒ–æ¨¡å‹ã€‚ä¸ºäº†åœ¨CIRè®¾ç½®ä¸‹å¹³è¡¡æ¨¡å‹çš„ç¨³å®šæ€§å’Œå¡‘æ€§ï¼Œä½œè€…æå‡ºäº†å¤šçº§çŸ¥è¯†è’¸é¦(Multi-level knowledge distillation, MLKD)å’ŒåŠ¨æ€è‡ªæˆ‘ç›‘ç£å­¦ä¹ (Dynamic self-supervised loss, SSL)ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ã€‚MLKDé€šè¿‡ä»å¤šä¸ªå†å²æ¨¡å‹ä¸­æå–ç‰¹å¾(features)å’Œå¯¹æ•°å‡ ç‡(logits)å±‚é¢çš„çŸ¥è¯†ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿä¿ç•™ä¸°å¯Œçš„å¤šç»´åº¦æ—¢æœ‰çŸ¥è¯†ã€‚åŠ¨æ€SSLåˆ™åˆ©ç”¨æ— æ ‡ç­¾æ•°æ®åŠ é€Ÿæ–°ç±»åˆ«çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡åŠ¨æ€æƒé‡å¹³è¡¡æœºåˆ¶ç¡®ä¿æ¨¡å‹å§‹ç»ˆèšç„¦äºä¸»è¦ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨CIRä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶æœ€ç»ˆåœ¨ç¬¬äº”å±ŠCVPR CLVISIONæŒ‘æˆ˜èµ›ä¸­è£è·ç¬¬äºŒåã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12692v2",
      "published_date": "2025-08-18 07:50:20 UTC",
      "updated_date": "2025-08-22 15:58:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:25.185871+00:00"
    },
    {
      "arxiv_id": "2508.12690v1",
      "title": "TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions",
      "title_zh": "TTA-DAMEï¼šç»“åˆåŸŸå¢å¼ºä¸æ¨¡å‹é›†æˆçš„åŠ¨æ€é©¾é©¶å·¥å†µæµ‹è¯•æ—¶è‡ªé€‚åº”",
      "authors": [
        "Dongjae Jeon",
        "Taeheon Kim",
        "Seongwon Cho",
        "Minhyuk Seo",
        "Jonghyun Choi"
      ],
      "abstract": "Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically adapt and perform optimally on shifting target domains. This task is particularly emphasized in real-world driving scenes, where weather domain shifts occur frequently. To address such dynamic changes, our proposed method, TTA-DAME, leverages source domain data augmentation into target domains. Additionally, we introduce a domain discriminator and a specialized domain detector to mitigate drastic domain shifts, especially from daytime to nighttime conditions. To further improve adaptability, we train multiple detectors and consolidate their predictions through Non-Maximum Suppression (NMS). Our empirical validation demonstrates the effectiveness of our method, showing significant performance enhancements on the SHIFT Benchmark.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TTA-DAMEï¼Œä¸€ç§æ—¨åœ¨è§£å†³åŠ¨æ€é©¾é©¶æ¡ä»¶ä¸‹æµ‹è¯•æ—¶è‡ªé€‚åº”(Test-time Adaptation, TTA)æŒ‘æˆ˜çš„æ–°æ¡†æ¶ï¼Œç‰¹åˆ«å…³æ³¨é¢‘ç¹å‘ç”Ÿçš„å¤©æ°”é¢†åŸŸåç§»ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†æºåŸŸæ•°æ®å¢å¼º(Domain Augmentation)å¼•å…¥ç›®æ ‡åŸŸï¼Œå¹¶ç»“åˆé¢†åŸŸåˆ¤åˆ«å™¨(Domain Discriminator)ä¸ä¸“é—¨çš„é¢†åŸŸæ£€æµ‹å™¨(Domain Detector)ï¼Œæœ‰æ•ˆç¼“è§£äº†ä»ç™½å¤©åˆ°é»‘å¤œç­‰å‰§çƒˆçš„ç¯å¢ƒå˜åŒ–ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡æ¨¡å‹çš„é²æ£’æ€§ï¼Œç ”ç©¶å›¢é˜Ÿè®­ç»ƒäº†å¤šä¸ªæ£€æµ‹å™¨ï¼Œå¹¶åˆ©ç”¨éæå¤§å€¼æŠ‘åˆ¶(Non-Maximum Suppression, NMS)æŠ€æœ¯æ•´åˆé¢„æµ‹ç»“æœï¼Œä»¥å®ç°æ›´ä¼˜çš„è‡ªé€‚åº”è¡¨ç°ã€‚åœ¨SHIFT Benchmarkä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒTTA-DAMEåœ¨å¤„ç†å¤æ‚çš„é©¾é©¶åœºæ™¯åç§»æ—¶å…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å®ç°äº†æ€§èƒ½çš„å¤§å¹…æå‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12690v1",
      "published_date": "2025-08-18 07:48:35 UTC",
      "updated_date": "2025-08-18 07:48:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:40.793047+00:00"
    },
    {
      "arxiv_id": "2508.12687v2",
      "title": "EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding",
      "title_zh": "EGOILLUSIONï¼šç¬¬ä¸€äººç§°è§†è§’è§†é¢‘ç†è§£ä¸­çš„å¹»è§‰è¯„ä¼°åŸºå‡†",
      "authors": [
        "Ashish Seth",
        "Utkarsh Tyagi",
        "Ramaneswaran Selvakumar",
        "Nishit Anand",
        "Sonal Kumar",
        "Sreyan Ghosh",
        "Ramani Duraiswami",
        "Chirag Agarwal",
        "Dinesh Manocha"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable performance in complex multimodal tasks. While MLLMs excel at visual perception and reasoning in third-person and egocentric videos, they are prone to hallucinations, generating coherent yet inaccurate responses. We present EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated open and closed-ended questions designed to trigger hallucinations in both visual and auditory cues in egocentric videos. Evaluations across ten MLLMs reveal significant challenges, including powerful models like GPT-4o and Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs the development of better egocentric MLLMs with reduced hallucination rates. Our benchmark will be open-sourced for reproducibility.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EgoIllusionï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(Multimodal Large Language Models, MLLMs)åœ¨ç¬¬ä¸€äººç§°è§†è§’è§†é¢‘(Egocentric Video)ç†è§£ä¸­äº§ç”Ÿå¹»è§‰(Hallucinations)çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å«1,400ä¸ªè§†é¢‘åŠ8,000ä¸ªç”±äººå·¥æ ‡æ³¨çš„é—®é¢˜ï¼Œæ¶µç›–è§†è§‰å’Œå¬è§‰çº¿ç´¢ä»¥å…¨é¢è¯±å‘æ¨¡å‹çš„å¹»è§‰ååº”ã€‚é€šè¿‡å¯¹GPT-4oå’ŒGeminiç­‰åç§ä¸»æµMLLMsçš„å®éªŒè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºå³ä¾¿å¼ºåŠ›æ¨¡å‹ä¹Ÿä»…èƒ½è¾¾åˆ°59%çš„å‡†ç¡®ç‡ï¼Œå‡¸æ˜¾äº†è¯¥é¢†åŸŸç°å­˜çš„å·¨å¤§æŒ‘æˆ˜ã€‚EgoIllusionä¸ºè¡¡é‡æ¨¡å‹ç¨³å¥æ€§æä¾›äº†åŸºç¡€ï¼Œæ—¨åœ¨æ¨åŠ¨æ›´ä½å¹»è§‰ç‡çš„ç¬¬ä¸€äººç§°è§†è§’MLLMsçš„å‘å±•ï¼Œå¹¶å·²è®¡åˆ’å¼€æºç›¸å…³ä»£ç ä»¥ä¾›å­¦æœ¯ç•Œé‡å¤ä½¿ç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12687v2",
      "published_date": "2025-08-18 07:39:55 UTC",
      "updated_date": "2025-08-23 08:06:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:48.189051+00:00"
    },
    {
      "arxiv_id": "2508.12685v1",
      "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction",
      "title_zh": "ToolACE-MTï¼šé¢å‘æ™ºèƒ½ä½“å¤šè½®äº¤äº’çš„éè‡ªå›å½’ç”Ÿæˆ",
      "authors": [
        "Xingshan Zeng",
        "Weiwen Liu",
        "Lingzhi Wang",
        "Liangyou Li",
        "Fei Mi",
        "Yasheng Wang",
        "Lifeng Shang",
        "Xin Jiang",
        "Qun Liu"
      ],
      "abstract": "Agentic task-solving with Large Language Models (LLMs) requires multi-turn, multi-step interactions, often involving complex function calls and dynamic user-agent exchanges. Existing simulation-based data generation methods for such scenarios rely heavily on costly autoregressive interactions between multiple LLM agents, thereby limiting real-world performance of agentic tasks. In this paper, we propose a novel Non-Autoregressive Iterative Generation framework, called ToolACE-MT, for constructing high-quality multi-turn agentic dialogues. ToolACE-MT generates full conversational trajectories through three stages: coarse-grained initialization, iterative refinement, and offline verification. The initialization phase builds a structurally complete yet semantically coarse dialogue skeleton; the iterative refinement phase introduces realistic complexities and continued refinement via mask-and-fill operations; and the offline verification phase ensures correctness and coherence via rule- and model-based checks. Experiments demonstrate that ToolACE-MT enables efficient, effective and generalizable agentic data generation, offering a new paradigm for high-quality data construction in tool-augmented LLM scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ToolACE-MTï¼Œè¿™æ˜¯ä¸€ç§é¢å‘æ™ºèƒ½ä½“å¤šè½®äº¤äº’çš„éè‡ªå›å½’è¿­ä»£ç”Ÿæˆ(Non-Autoregressive Iterative Generation)æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ¨¡æ‹Ÿç”Ÿæˆæ–¹æ³•è¿‡åº¦ä¾èµ–é«˜æˆæœ¬è‡ªå›å½’(autoregressive)äº¤äº’çš„å±€é™æ€§ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨é«˜æ•ˆæ„å»ºé«˜è´¨é‡çš„å¤šè½®æ™ºèƒ½ä½“å¯¹è¯æ•°æ®ã€‚ToolACE-MTé€šè¿‡ç²—ç²’åº¦åˆå§‹åŒ–ã€è¿­ä»£ç»†åŒ–å’Œç¦»çº¿éªŒè¯ä¸‰ä¸ªé˜¶æ®µç”Ÿæˆå®Œæ•´çš„å¯¹è¯è½¨è¿¹ï¼Œå…¶ä¸­è¿­ä»£ç»†åŒ–é˜¶æ®µåˆ©ç”¨æ©ç ä¸å¡«å……(mask-and-fill)æ“ä½œæ˜¾è‘—æå‡äº†å¯¹è¯çš„ç°å®å¤æ‚æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒToolACE-MTå®ç°äº†é«˜æ•ˆä¸”å…·æœ‰æ³›åŒ–æ€§çš„æ™ºèƒ½ä½“æ•°æ®ç”Ÿæˆèƒ½åŠ›ï¼Œä¸ºå·¥å…·å¢å¼ºå‹å¤§è¯­è¨€æ¨¡å‹(Tool-augmented LLMs)åœºæ™¯ä¸‹çš„æ•°æ®æ„å»ºæä¾›äº†å…¨æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12685v1",
      "published_date": "2025-08-18 07:38:23 UTC",
      "updated_date": "2025-08-18 07:38:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:58.889136+00:00"
    },
    {
      "arxiv_id": "2508.12683v1",
      "title": "A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications",
      "title_zh": "åˆ†å±‚å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆ†ç±»ä½“ç³»ï¼šè®¾è®¡æ¨¡å¼ã€ååŒæœºåˆ¶ä¸å·¥ä¸šåº”ç”¨",
      "authors": [
        "David J. Moore"
      ],
      "abstract": "Hierarchical multi-agent systems (HMAS) organize collections of agents into layered structures that help manage complexity and scale. These hierarchies can simplify coordination, but they also can introduce trade-offs that are not always obvious. This paper proposes a multi-dimensional taxonomy for HMAS along five axes: control hierarchy, information flow, role and task delegation, temporal layering, and communication structure. The intent is not to prescribe a single \"best\" design but to provide a lens for comparing different approaches.\n  Rather than treating these dimensions in isolation, the taxonomy is connected to concrete coordination mechanisms - from the long-standing contract-net protocol for task allocation to more recent work in hierarchical reinforcement learning. Industrial contexts illustrate the framework, including power grids and oilfield operations, where agents at production, maintenance, and supply levels coordinate to diagnose well issues or balance energy demand. These cases suggest that hierarchical structures may achieve global efficiency while preserving local autonomy, though the balance is delicate.\n  The paper closes by identifying open challenges: making hierarchical decisions explainable to human operators, scaling to very large agent populations, and assessing whether learning-based agents such as large language models can be safely integrated into layered frameworks. This paper presents what appears to be the first taxonomy that unifies structural, temporal, and communication dimensions of hierarchical MAS into a single design framework, bridging classical coordination mechanisms with modern reinforcement learning and large language model agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ†å±‚å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Hierarchical Multi-Agent Systems, HMAS)åœ¨ç®¡ç†å¤æ‚æ€§å’Œè§„æ¨¡æ—¶çš„åè°ƒä¸æƒè¡¡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŒ…å«äº”ä¸ªç»´åº¦çš„å¤šç»´åˆ†ç±»æ³•ã€‚è¯¥åˆ†ç±»æ³•æ¶µç›–äº†æ§åˆ¶å±‚çº§(control hierarchy)ã€ä¿¡æ¯æµ(information flow)ã€è§’è‰²ä¸ä»»åŠ¡æˆæƒ(role and task delegation)ã€æ—¶é—´åˆ†å±‚(temporal layering)ä»¥åŠé€šä¿¡ç»“æ„(communication structure)ï¼Œä¸ºæ¯”è¾ƒä¸åŒè®¾è®¡æ–¹æ¡ˆæä¾›äº†ç³»ç»Ÿæ€§è§†è§’ã€‚ç ”ç©¶è¿›ä¸€æ­¥å°†è¯¥åˆ†ç±»æ³•ä¸åˆåŒç½‘åè®®(contract-net protocol)åŠåˆ†å±‚å¼ºåŒ–å­¦ä¹ (hierarchical reinforcement learning, HRL)ç­‰åè°ƒæœºåˆ¶ç›¸è”ç³»ï¼Œå¹¶é€šè¿‡ç”µç½‘å’Œæ²¹ç”°ä½œä¸šç­‰å·¥ä¸šæ¡ˆä¾‹éªŒè¯äº†å…¶åœ¨å¹³è¡¡å…¨å±€æ•ˆç‡ä¸å±€éƒ¨è‡ªæ²»æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ä½œä¸ºé¦–ä¸ªç»Ÿä¸€äº†ç»“æ„ã€æ—¶é—´å’Œé€šä¿¡ç»´åº¦çš„HMASè®¾è®¡æ¡†æ¶ï¼Œè¯¥è®ºæ–‡è¿˜æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Model, LLM)æ™ºèƒ½ä½“é›†æˆçš„å®‰å…¨æ€§ã€å¯æ‰©å±•æ€§åŠå¯è§£é‡Šæ€§ç­‰å‰æ²¿æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12683v1",
      "published_date": "2025-08-18 07:36:33 UTC",
      "updated_date": "2025-08-18 07:36:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:37:49.190014+00:00"
    },
    {
      "arxiv_id": "2508.12682v1",
      "title": "GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance",
      "title_zh": "GridCodexï¼šåŸºäº RAG é©±åŠ¨çš„ç”µç½‘è§„ç¨‹æ¨ç†ä¸åˆè§„äººå·¥æ™ºèƒ½æ¡†æ¶",
      "authors": [
        "Jinquan Shi",
        "Yingying Cheng",
        "Fan Zhang",
        "Miao Jiang",
        "Jun Lin",
        "Yanbai Shen"
      ],
      "abstract": "The global shift towards renewable energy presents unprecedented challenges for the electricity industry, making regulatory reasoning and compliance increasingly vital. Grid codes, the regulations governing grid operations, are complex and often lack automated interpretation solutions, which hinders industry expansion and undermines profitability for electricity companies. We introduce GridCodex, an end to end framework for grid code reasoning and compliance that leverages large language models and retrieval-augmented generation (RAG). Our framework advances conventional RAG workflows through multi stage query refinement and enhanced retrieval with RAPTOR. We validate the effectiveness of GridCodex with comprehensive benchmarks, including automated answer assessment across multiple dimensions and regulatory agencies. Experimental results showcase a 26.4% improvement in answer quality and more than a 10 fold increase in recall rate. An ablation study further examines the impact of base model selection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¨çƒå‘å¯å†ç”Ÿèƒ½æºè½¬å‹è¿‡ç¨‹ä¸­ç”µç½‘è§„èŒƒ(Grid codes)æ„ˆå‘å¤æ‚ä¸”ç¼ºä¹è‡ªåŠ¨è§£è¯»æ–¹æ¡ˆçš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºGridCodexçš„ç«¯åˆ°ç«¯æ¨ç†ä¸åˆè§„æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models)ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ï¼Œé€šè¿‡å¤šé˜¶æ®µæŸ¥è¯¢ä¼˜åŒ–å’ŒRAPTORå¢å¼ºæ£€ç´¢æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†ä¼ ç»ŸRAGçš„å·¥ä½œæµç¨‹ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨æ¶µç›–å¤šä¸ªç»´åº¦å’Œç›‘ç®¡æœºæ„çš„ç»¼åˆåŸºå‡†æµ‹è¯•å¯¹è¯¥æ¡†æ¶è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGridCodexåœ¨å›ç­”è´¨é‡ä¸Šæå‡äº†26.4%ï¼Œå¬å›ç‡æ›´æ˜¯å®ç°äº†10å€ä»¥ä¸Šçš„å¢é•¿ã€‚æ­¤å¤–ï¼Œæ¶ˆèå®éªŒæ·±å…¥æ¢è®¨äº†ä¸åŒåŸºç¡€æ¨¡å‹é€‰æ‹©å¯¹ç³»ç»Ÿåˆè§„æ€§æ¨ç†è¡¨ç°çš„å½±å“ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12682v1",
      "published_date": "2025-08-18 07:33:29 UTC",
      "updated_date": "2025-08-18 07:33:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:00.688506+00:00"
    },
    {
      "arxiv_id": "2508.12673v1",
      "title": "Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach",
      "title_zh": "è”é‚¦å­¦ä¹ ä¸­é¢å‘éå‚ä¸å®¢æˆ·ç«¯çš„æ— éœ€å¾®è°ƒæ¨¡å‹éƒ¨ç½²ï¼šä¸€ç§åŸºäºè¶…ç½‘ç»œçš„æ–¹æ³•",
      "authors": [
        "Yuhao Zhou",
        "Jindi Lv",
        "Yuxin Tian",
        "Dan Si",
        "Qing Ye",
        "Jiancheng Lv"
      ],
      "abstract": "Federated Learning (FL) has emerged as a promising paradigm for privacy-preserving collaborative learning, yet data heterogeneity remains a critical challenge. While existing methods achieve progress in addressing data heterogeneity for participating clients, they fail to generalize to non-participating clients with in-domain distribution shifts and resource constraints. To mitigate this issue, we present HyperFedZero, a novel method that dynamically generates specialized models via a hypernetwork conditioned on distribution-aware embeddings. Our approach explicitly incorporates distribution-aware inductive biases into the model's forward pass, extracting robust distribution embeddings using a NoisyEmbed-enhanced extractor with a Balancing Penalty, effectively preventing feature collapse. The hypernetwork then leverages these embeddings to generate specialized models chunk-by-chunk for non-participating clients, ensuring adaptability to their unique data distributions. Extensive experiments on multiple datasets and models demonstrate HyperFedZero's remarkable performance, surpassing competing methods consistently with minimal computational, storage, and communication overhead. Moreover, ablation studies and visualizations further validate the necessity of each component, confirming meaningful adaptations and validating the effectiveness of HyperFedZero.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦å­¦ä¹  (Federated Learning) ä¸­éå‚ä¸å®¢æˆ·ç«¯é¢ä¸´çš„æ•°æ®å¼‚æ„æ€§å’Œèµ„æºçº¦æŸæŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º HyperFedZero çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŸºäºåˆ†å¸ƒæ„ŸçŸ¥åµŒå…¥ (Distribution-aware embeddings) çš„è¶…ç½‘ç»œ (Hypernetwork) åŠ¨æ€ç”Ÿæˆä¸“ç”¨æ¨¡å‹ï¼Œæ— éœ€å¯¹æ–°å®¢æˆ·ç«¯è¿›è¡Œå¾®è°ƒã€‚HyperFedZero é€šè¿‡ NoisyEmbed å¢å¼ºçš„æå–å™¨å’Œå¹³è¡¡æƒ©ç½š (Balancing Penalty) æå–é²æ£’çš„åˆ†å¸ƒç‰¹å¾ï¼Œæœ‰æ•ˆé˜²æ­¢äº†ç‰¹å¾å´©æºƒã€‚è¶…ç½‘ç»œéšåæ ¹æ®è¿™äº›åµŒå…¥ä¸ºéå‚ä¸å®¢æˆ·ç«¯åˆ†å—ç”Ÿæˆ (Chunk-by-chunk) æ¨¡å‹ï¼Œä»¥å®ç°å¯¹ç‹¬ç‰¹æ•°æ®åˆ†å¸ƒçš„ç²¾å‡†è‡ªé€‚åº”ã€‚å¤§é‡å®éªŒç»“æœè¯æ˜ï¼ŒHyperFedZero åœ¨æ˜¾è‘—ä¼˜äºç«äº‰æ–¹æ³•çš„åŒæ—¶ï¼Œä¿æŒäº†æä½çš„è®¡ç®—ã€å­˜å‚¨å’Œé€šä¿¡å¼€é”€ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†è¯¥æ–¹æ³•å„ç»„ä»¶åœ¨å®ç°æœ‰æ•ˆæ¨¡å‹è¿ç§»ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.12673v1",
      "published_date": "2025-08-18 07:11:51 UTC",
      "updated_date": "2025-08-18 07:11:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:06.498357+00:00"
    },
    {
      "arxiv_id": "2508.12672v3",
      "title": "Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering",
      "title_zh": "åŸºäºæŸå¤±å®¢æˆ·ç«¯èšç±»çš„å¯¹æŠ—æ”»å‡»ä¸‹é²æ£’è”é‚¦å­¦ä¹ ",
      "authors": [
        "Emmanouil Kritharakis",
        "Dusan Jakovetic",
        "Antonios Makris",
        "Konstantinos Tserpes"
      ],
      "abstract": "Federated Learning (FL) enables collaborative model training across multiple clients without sharing private data. We consider FL scenarios wherein FL clients are subject to adversarial (Byzantine) attacks, while the FL server is trusted (honest) and has a trustworthy side dataset. This may correspond to, e.g., cases where the server possesses trusted data prior to federation, or to the presence of a trusted client that temporarily assumes the server role. Our approach requires only two honest participants, i.e., the server and one client, to function effectively, without prior knowledge of the number of malicious clients. Theoretical analysis demonstrates bounded optimality gaps even under strong Byzantine attacks. Experimental results show that our algorithm significantly outperforms standard and robust FL baselines such as Mean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack strategies including label flipping, sign flipping, and Gaussian noise addition across MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Federated Learning (FL)åœ¨é¢ä¸´å¯¹æŠ—æ€§(Byzantine)æ”»å‡»æ—¶çš„é²æ£’æ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæŸå¤±å‡½æ•°è¿›è¡Œå®¢æˆ·ç«¯èšç±»(Loss-Based Client Clustering)çš„é˜²å¾¡æ–¹æ³•ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡åˆ©ç”¨æœåŠ¡å™¨ç«¯æ‹¥æœ‰çš„å—ä¿¡æ•°æ®é›†æ¥è¯„ä¼°å®¢æˆ·ç«¯è´¡çŒ®ï¼Œæœ‰æ•ˆè¯†åˆ«å¹¶éš”ç¦»æ¶æ„å¹²æ‰°ï¼Œä¸”ä»…éœ€æœåŠ¡å™¨å’Œä¸€ä¸ªè¯šå®å®¢æˆ·ç«¯å³å¯è¿ä½œï¼Œæ— éœ€é¢„å…ˆè·çŸ¥æ¶æ„å®¢æˆ·ç«¯çš„æ•°é‡ã€‚ç†è®ºåˆ†æè¯æ˜ï¼Œå³ä¾¿åœ¨å¼ºåŠ›Byzantineæ”»å‡»ä¸‹ï¼Œè¯¥ç®—æ³•ä»èƒ½ç¡®ä¿æ¨¡å‹çš„æœ€ä¼˜æ€§å·®è·(optimality gaps)å¤„äºæœ‰ç•ŒèŒƒå›´å†…ã€‚åœ¨Floweræ¡†æ¶ä¸‹é’ˆå¯¹MNISTã€FMNISTå’ŒCIFAR-10çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åº”å¯¹æ ‡ç­¾ç¿»è½¬(label flipping)ã€ç¬¦å·ç¿»è½¬(sign flipping)å’Œé«˜æ–¯å™ªå£°(Gaussian noise)ç­‰å¤šç§æ”»å‡»ç­–ç•¥æ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºMeanã€Trimmed Meanã€Medianã€Krumå’ŒMulti-Krumç­‰æ ‡å‡†åŠé²æ£’FLåŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12672v3",
      "published_date": "2025-08-18 07:11:21 UTC",
      "updated_date": "2025-08-25 14:24:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:11.790553+00:00"
    },
    {
      "arxiv_id": "2508.12662v1",
      "title": "Breaking Language Barriers: Equitable Performance in Multilingual Language Models",
      "title_zh": "æ‰“ç ´è¯­è¨€éšœç¢ï¼šå¤šè¯­è¨€è¯­è¨€æ¨¡å‹ä¸­çš„æ€§èƒ½å…¬å¹³æ€§",
      "authors": [
        "Tanay Nagar",
        "Grigorii Khvatskii",
        "Anna Sokol",
        "Nitesh V. Chawla"
      ],
      "abstract": "Cutting-edge LLMs have emerged as powerful tools for multilingual communication and understanding. However, LLMs perform worse in Common Sense Reasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi or Swahili compared to high-resource languages (HRLs) like English. Equalizing this inconsistent access to quality LLM outputs is crucial to ensure fairness for speakers of LRLs and across diverse linguistic communities. In this paper, we propose an approach to bridge this gap in LLM performance. Our approach involves fine-tuning an LLM on synthetic code-switched text generated using controlled language-mixing methods. We empirically demonstrate that fine-tuning LLMs on synthetic code-switched datasets leads to substantial improvements in LRL model performance while preserving or enhancing performance in HRLs. Additionally, we present a new dataset of synthetic code-switched text derived from the CommonSenseQA dataset, featuring three distinct language ratio configurations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ä½èµ„æºè¯­è¨€(LRLs)ï¼ˆå¦‚å°åœ°è¯­æˆ–æ–¯ç“¦å¸Œé‡Œè¯­ï¼‰çš„å¸¸è¯†æ¨ç†(CSR)ä»»åŠ¡æ—¶è¡¨ç°é€Šäºé«˜èµ„æºè¯­è¨€(HRLs)ï¼ˆå¦‚è‹±è¯­ï¼‰çš„å…¬å¹³æ€§é—®é¢˜è¿›è¡Œäº†æ¢è®¨ã€‚ä¸ºäº†ç¼©å°è¿™ä¸€æ€§èƒ½å·®è·ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åˆ©ç”¨å—æ§è¯­è¨€æ··åˆæ–¹æ³•ç”Ÿæˆçš„åˆæˆè¯­ç è½¬æ¢(code-switched)æ–‡æœ¬å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒçš„æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨åˆæˆè¯­ç è½¬æ¢æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒèƒ½æ˜¾è‘—æå‡æ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€ä¸Šçš„è¡¨ç°ï¼ŒåŒæ—¶ä¿æŒæˆ–å¢å¼ºå…¶åœ¨é«˜èµ„æºè¯­è¨€ä¸­çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å‘å¸ƒäº†ä¸€ä¸ªåŸºäºCommonSenseQAæ•°æ®é›†æ„å»ºçš„å…¨æ–°åˆæˆè¯­ç è½¬æ¢æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸‰ç§ä¸åŒçš„è¯­è¨€æ¯”ä¾‹é…ç½®ï¼Œä¸ºè·¨è¯­è¨€ç¤¾åŒºçš„å…¬å¹³æ€§ç ”ç©¶æä¾›äº†æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a non-archival work-in-progress paper at the NAACL 2025 Student Research Workshop",
      "pdf_url": "https://arxiv.org/pdf/2508.12662v1",
      "published_date": "2025-08-18 06:50:24 UTC",
      "updated_date": "2025-08-18 06:50:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:14.388512+00:00"
    },
    {
      "arxiv_id": "2508.12651v1",
      "title": "The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning",
      "title_zh": "æ— äººæœºå‚ç›´èµ·é™ç‚¹é€‰å€è§„åˆ’çš„æœ€å¤§è¦†ç›–æ¨¡å‹ä¸æ¨èç³»ç»Ÿ",
      "authors": [
        "Chunliang Hua",
        "Xiao Hu",
        "Jiayang Sun",
        "Zeyuan Yang"
      ],
      "abstract": "As urban aerial mobility (UAM) infrastructure development accelerates globally, cities like Shenzhen are planning large-scale vertiport networks (e.g., 1,200+ facilities by 2026). Existing planning frameworks remain inadequate for this complexity due to historical limitations in data granularity and real-world applicability. This paper addresses these gaps by first proposing the Capacitated Dynamic Maximum Covering Location Problem (CDMCLP), a novel optimization framework that simultaneously models urban-scale spatial-temporal demand, heterogeneous user behaviors, and infrastructure capacity constraints. Building on this foundation, we introduce an Integrated Planning Recommendation System that combines CDMCLP with socio-economic factors and dynamic clustering initialization. This system leverages adaptive parameter tuning based on empirical user behavior to generate practical planning solutions. Validation in a Chinese center city demonstrates the effectiveness of the new optimization framework and recommendation system. Under the evaluation and optimization of CDMCLP, the quantitative performance of traditional location methods are exposed and can be improved by 38\\%--52\\%, while the recommendation system shows user-friendliness and the effective integration of complex elements. By integrating mathematical rigor with practical implementation considerations, this hybrid approach bridges the gap between theoretical location modeling and real-world UAM infrastructure planning, offering municipalities a pragmatic tool for vertiport network design.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸå¸‚ç©ºä¸­äº¤é€š(UAM)åŸºç¡€è®¾æ–½é€‰å€è§„åˆ’çš„å¤æ‚æ€§ï¼Œæå‡ºäº†æœ‰å®¹é‡é™åˆ¶çš„åŠ¨æ€æœ€å¤§è¦†ç›–é€‰å€é—®é¢˜(CDMCLP)ä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨åŒæ—¶æ¨¡æ‹ŸåŸå¸‚çº§æ—¶ç©ºéœ€æ±‚ã€å¼‚æ„ç”¨æˆ·è¡Œä¸ºåŠåŸºç¡€è®¾æ–½å®¹é‡é™åˆ¶ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä½œè€…è¿›ä¸€æ­¥å¼€å‘äº†ä¸€å¥—é›†æˆè§„åˆ’æ¨èç³»ç»Ÿ(Integrated Planning Recommendation System)ï¼Œå°† CDMCLP æ¨¡å‹ä¸ç¤¾ä¼šç»æµå› ç´ åŠåŠ¨æ€èšç±»åˆå§‹åŒ–ç›¸ç»“åˆï¼Œé€šè¿‡è‡ªé€‚åº”å‚æ•°è°ƒæ•´ç”Ÿæˆå®é™…é€‰å€æ–¹æ¡ˆã€‚åœ¨ä¸­å›½æŸä¸­å¿ƒåŸå¸‚çš„å®è¯ç ”ç©¶æ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶ç›¸è¾ƒäºä¼ ç»Ÿé€‰å€æ–¹æ³•åœ¨é‡åŒ–æ€§èƒ½ä¸Šæå‡äº†38%è‡³52%ï¼Œå¹¶å±•ç°å‡ºè‰¯å¥½çš„ç”¨æˆ·å‹å¥½æ€§ä¸å¤æ‚è¦ç´ æ•´åˆèƒ½åŠ›ã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆæ•°å­¦ä¸¥è°¨æ€§ä¸å®é™…æ‰§è¡Œéœ€æ±‚ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†ç†è®ºå»ºæ¨¡ä¸ç°å® UAM åŸºç¡€è®¾æ–½è§„åˆ’ä¹‹é—´çš„å·®è·ï¼Œä¸ºå¸‚æ”¿éƒ¨é—¨è¿›è¡Œèµ·é™ç‚¹ç½‘ç»œè®¾è®¡æä¾›äº†åŠ¡å®çš„å†³ç­–å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.12651v1",
      "published_date": "2025-08-18 06:31:08 UTC",
      "updated_date": "2025-08-18 06:31:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:16.792933+00:00"
    },
    {
      "arxiv_id": "2508.12650v2",
      "title": "Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery",
      "title_zh": "åŸºäºå¾—åˆ†ä¿¡æ¯çš„ç¥ç»ç®—å­ï¼šå¢å¼ºåŸºäºæ’åºçš„å› æœå‘ç°",
      "authors": [
        "Jiyeon Kang",
        "Songseong Kim",
        "Chanhui Lee",
        "Doyeong Hwang",
        "Joanie Hayoun Chung",
        "Yunkyung Ko",
        "Sumin Lee",
        "Sungwoong Kim",
        "Sungbin Lim"
      ],
      "abstract": "Ordering-based approaches to causal discovery identify topological orders of causal graphs, providing scalable alternatives to combinatorial search methods. Under the Additive Noise Model (ANM) assumption, recent causal ordering methods based on score matching require an accurate estimation of the Hessian diagonal of the log-densities. In this paper, we aim to improve the approximation of the Hessian diagonal of the log-densities, thereby enhancing the performance of ordering-based causal discovery algorithms. Existing approaches that rely on Stein gradient estimators are computationally expensive and memory-intensive, while diffusion-model-based methods remain unstable due to the second-order derivatives of score models. To alleviate these problems, we propose Score-informed Neural Operator (SciNO), a probabilistic generative model in smooth function spaces designed to stably approximate the Hessian diagonal and to preserve structural information during the score modeling. Empirical results show that SciNO reduces order divergence by 42.7% on synthetic graphs and by 31.5% on real-world datasets on average compared to DiffAN, while maintaining memory efficiency and scalability. Furthermore, we propose a probabilistic control algorithm for causal reasoning with autoregressive models that integrates SciNO's probability estimates with autoregressive model priors, enabling reliable data-driven causal ordering informed by semantic information. Consequently, the proposed method enhances causal reasoning abilities of LLMs without additional fine-tuning or prompt engineering.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Score-informed Neural Operator (SciNO)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡åŸºäºæ’åºçš„å› æœå‘ç°(Ordering-based Causal Discovery)æ€§èƒ½çš„æ¦‚ç‡ç”Ÿæˆæ¨¡å‹ã€‚SciNOé€šè¿‡åœ¨å¹³æ»‘å‡½æ•°ç©ºé—´ä¸­è¿›è¡Œå»ºæ¨¡ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨ä¼°è®¡å¯¹æ•°å¯†åº¦Hessianå¯¹è§’çº¿æ—¶å­˜åœ¨çš„è®¡ç®—æˆæœ¬é«˜ã€å†…å­˜å ç”¨å¤§ä»¥åŠæ‰©æ•£æ¨¡å‹äºŒé˜¶å¯¼æ•°ä¸ç¨³å®šæ€§ç­‰é—®é¢˜ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿç¨³å®šåœ°é€¼è¿‘Hessianå¯¹è§’çº¿ï¼Œå¹¶åœ¨è¯„åˆ†å»ºæ¨¡è¿‡ç¨‹ä¸­æœ‰æ•ˆä¿ç•™ç»“æ„ä¿¡æ¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸DiffANç›¸æ¯”ï¼ŒSciNOåœ¨åˆæˆå›¾å’ŒçœŸå®æ•°æ®é›†ä¸Šçš„æ’åºæ•£åº¦åˆ†åˆ«å¹³å‡é™ä½äº†42.7%å’Œ31.5%ï¼ŒåŒæ—¶ä¿æŒäº†ä¼˜ç§€çš„å†…å­˜æ•ˆç‡å’Œæ‰©å±•æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§æ¦‚ç‡æ§åˆ¶ç®—æ³•ï¼Œå°†SciNOçš„æ¦‚ç‡ä¼°è®¡ä¸è‡ªå›å½’æ¨¡å‹å…ˆéªŒç›¸ç»“åˆï¼Œåœ¨æ— éœ€é¢å¤–å¾®è°ƒæˆ–æç¤ºå·¥ç¨‹çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å› æœæ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2025. 36 pages, 18 figures, 12 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.12650v2",
      "published_date": "2025-08-18 06:25:41 UTC",
      "updated_date": "2025-10-27 05:20:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:22.487769+00:00"
    },
    {
      "arxiv_id": "2508.12647v1",
      "title": "Cognitive Structure Generation: From Educational Priors to Policy Optimization",
      "title_zh": "è®¤çŸ¥ç»“æ„ç”Ÿæˆï¼šä»æ•™è‚²å…ˆéªŒåˆ°ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Hengnian Gu",
        "Zhifu Chen",
        "Yuxin Chen",
        "Jin Peng Zhou",
        "Dongdai Zhou"
      ],
      "abstract": "Cognitive structure is a student's subjective organization of an objective knowledge system, reflected in the psychological construction of concepts and their relations. However, cognitive structure assessment remains a long-standing challenge in student modeling and psychometrics, persisting as a foundational yet largely unassessable concept in educational practice. This paper introduces a novel framework, Cognitive Structure Generation (CSG), in which we first pretrain a Cognitive Structure Diffusion Probabilistic Model (CSDPM) to generate students' cognitive structures from educational priors, and then further optimize its generative process as a policy with hierarchical reward signals via reinforcement learning to align with genuine cognitive development levels during students' learning processes. Experimental results on four popular real-world education datasets show that cognitive structures generated by CSG offer more comprehensive and effective representations for student modeling, substantially improving performance on KT and CD tasks while enhancing interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Cognitive Structure Generation (CSG)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å­¦ç”Ÿå»ºæ¨¡ä¸å¿ƒç†æµ‹é‡å­¦ä¸­è®¤çŸ¥ç»“æ„éš¾ä»¥è¯„ä¼°çš„é•¿æœŸæŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é¦–å…ˆé¢„è®­ç»ƒäº†ä¸€ä¸ªCognitive Structure Diffusion Probabilistic Model (CSDPM)ï¼ŒåŸºäºæ•™è‚²å…ˆéªŒç”Ÿæˆå­¦ç”Ÿçš„è®¤çŸ¥ç»“æ„ã€‚éšåï¼Œç ”ç©¶è€…é€šè¿‡Reinforcement Learningå’Œå±‚æ¬¡åŒ–å¥–åŠ±ä¿¡å·ï¼Œå°†ç”Ÿæˆè¿‡ç¨‹ä½œä¸ºä¸€ç§ç­–ç•¥è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œä½¿å…¶ä¸å­¦ç”Ÿå­¦ä¹ è¿‡ç¨‹ä¸­çš„çœŸå®è®¤çŸ¥å‘å±•æ°´å¹³ä¿æŒä¸€è‡´ã€‚åœ¨å››ä¸ªçœŸå®æ•™è‚²æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCSGç”Ÿæˆçš„è®¤çŸ¥ç»“æ„ä¸ºå­¦ç”Ÿå»ºæ¨¡æä¾›äº†æ›´å…¨é¢ã€æœ‰æ•ˆçš„è¡¨ç¤ºã€‚è¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†Knowledge Tracing (KT)å’ŒCognitive Diagnosis (CD)ä»»åŠ¡çš„é¢„æµ‹æ€§èƒ½ï¼Œå¹¶æœ‰æ•ˆå¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12647v1",
      "published_date": "2025-08-18 06:21:36 UTC",
      "updated_date": "2025-08-18 06:21:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:37.459755+00:00"
    },
    {
      "arxiv_id": "2508.12638v2",
      "title": "edgeVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer",
      "title_zh": "edgeVLMï¼šåŸºäºä¸Šä¸‹æ–‡è¿ç§»çš„äº‘è¾¹åä½œå®æ—¶è§†è§‰è¯­è¨€æ¨¡å‹",
      "authors": [
        "Chen Qian",
        "Xinran Yu",
        "Zewen Huang",
        "Danyang Li",
        "Qiang Ma",
        "Fan Dang",
        "Xuan Ding",
        "Guangyong Shang",
        "Zheng Yang"
      ],
      "abstract": "Vision-Language Models (VLMs) are increasingly deployed in real-time applications such as autonomous driving and human-computer interaction, which demand fast and reliable responses based on accurate perception. To meet these requirements, existing systems commonly employ cloud-edge collaborative architectures, such as partitioned Large Vision-Language Models (LVLMs) or task offloading strategies between Large and Small Vision-Language Models (SVLMs). However, these methods fail to accommodate cloud latency fluctuations and overlook the full potential of delayed but accurate LVLM responses. In this work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed Context Transfer, which treats the delayed outputs of LVLMs as historical context to provide real-time guidance for SVLMs inference. Based on this paradigm, we design edgeVLM, which incorporates both context replacement and visual focus modules to refine historical textual input and enhance visual grounding consistency. Extensive experiments on three real-time vision-lanuage reasoning tasks across four datasets demonstrate the effectiveness of the proposed framework. The new paradigm lays the groundwork for more effective and latency-aware collaboration strategies in future VLM systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå¯¹å®æ—¶è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å¿«é€Ÿå“åº”çš„éœ€æ±‚ï¼Œæå‡ºäº†åä¸ºContext Transferçš„æ–°å‹äº‘è¾¹åä½œèŒƒå¼ã€‚é’ˆå¯¹ç°æœ‰ç³»ç»Ÿéš¾ä»¥åº”å¯¹äº‘ç«¯å»¶è¿Ÿæ³¢åŠ¨ä¸”æœªèƒ½å……åˆ†åˆ©ç”¨å¤§å‹æ¨¡å‹(LVLMs)é«˜å‡†ç¡®åº¦å“åº”çš„é—®é¢˜ï¼ŒedgeVLMå°†LVLMsçš„å»¶è¿Ÿè¾“å‡ºè½¬åŒ–ä¸ºå†å²ä¸Šä¸‹æ–‡ï¼Œç”¨äºå®æ—¶æŒ‡å¯¼å°å‹æ¨¡å‹(SVLMs)çš„æ¨ç†ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆä¸Šä¸‹æ–‡æ›¿æ¢(context replacement)å’Œè§†è§‰èšç„¦(visual focus)æ¨¡å—ï¼Œæœ‰æ•ˆä¼˜åŒ–äº†å†å²æ–‡æœ¬è¾“å…¥å¹¶å¢å¼ºäº†è§†è§‰å®šä½(visual grounding)çš„ä¸€è‡´æ€§ã€‚åœ¨å››ä¸ªæ•°æ®é›†çš„ä¸‰é¡¹å®æ—¶è§†è§‰è¯­è¨€æ¨ç†ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆä¸ä»…æ˜¾è‘—æå‡äº†ç³»ç»Ÿæ€§èƒ½ï¼Œè¿˜ä¸ºæœªæ¥å…·å¤‡å»¶è¿Ÿæ„ŸçŸ¥èƒ½åŠ›çš„äº‘è¾¹åä½œç³»ç»Ÿæä¾›äº†æœ‰æ•ˆçš„åŸºç¡€æ¶æ„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12638v2",
      "published_date": "2025-08-18 05:51:41 UTC",
      "updated_date": "2025-11-17 07:07:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:40.692501+00:00"
    },
    {
      "arxiv_id": "2508.13240v1",
      "title": "Quantifying Loss Aversion in Cyber Adversaries via LLM Analysis",
      "title_zh": "é€šè¿‡å¤§è¯­è¨€æ¨¡å‹åˆ†æé‡åŒ–ç½‘ç»œå¯¹æ‰‹çš„æŸå¤±åŒæ¶",
      "authors": [
        "Soham Hans",
        "Nikolos Gurney",
        "Stacy Marsella",
        "Sofia Hirschmann"
      ],
      "abstract": "Understanding and quantifying human cognitive biases from empirical data has long posed a formidable challenge, particularly in cybersecurity, where defending against unknown adversaries is paramount. Traditional cyber defense strategies have largely focused on fortification, while some approaches attempt to anticipate attacker strategies by mapping them to cognitive vulnerabilities, yet they fall short in dynamically interpreting attacks in progress. In recognition of this gap, IARPA's ReSCIND program seeks to infer, defend against, and even exploit attacker cognitive traits. In this paper, we present a novel methodology that leverages large language models (LLMs) to extract quantifiable insights into the cognitive bias of loss aversion from hacker behavior. Our data are collected from an experiment in which hackers were recruited to attack a controlled demonstration network. We process the hacker generated notes using LLMs using it to segment the various actions and correlate the actions to predefined persistence mechanisms used by hackers. By correlating the implementation of these mechanisms with various operational triggers, our analysis provides new insights into how loss aversion manifests in hacker decision-making. The results demonstrate that LLMs can effectively dissect and interpret nuanced behavioral patterns, thereby offering a transformative approach to enhancing cyber defense strategies through real-time, behavior-based analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œå®‰å…¨é¢†åŸŸéš¾ä»¥åŠ¨æ€è§£è¯»æ”»å‡»è€…è®¤çŸ¥åè§çš„é—®é¢˜ï¼Œæ—¨åœ¨é‡åŒ–ç½‘ç»œå¯¹æ‰‹çš„æŸå¤±åŒæ¶(Loss Aversion)å¿ƒç†ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»é»‘å®¢è¡Œä¸ºä¸­æå–å¯é‡åŒ–è®¤çŸ¥åè§è§è§£çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶æ•°æ®æ¥æºäºä¸€é¡¹æ‹›å‹Ÿé»‘å®¢å¯¹å—æ§æ¼”ç¤ºç½‘ç»œè¿›è¡Œæ”»å‡»çš„å®éªŒï¼Œé€šè¿‡LLMså¤„ç†é»‘å®¢ç”Ÿæˆçš„ç¬”è®°ï¼Œå¯¹å„ç§æ”»å‡»è¡Œä¸ºè¿›è¡Œç»†åˆ†å¹¶å°†å…¶ä¸é¢„å®šä¹‰çš„æŒä¹…åŒ–æœºåˆ¶(Persistence Mechanisms)ç›¸å…³è”ã€‚é€šè¿‡åˆ†æè¿™äº›æœºåˆ¶çš„å®æ–½ä¸æ“ä½œè§¦å‘å› ç´ ä¹‹é—´çš„å…³ç³»ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†æŸå¤±åŒæ¶åœ¨é»‘å®¢å†³ç­–è¿‡ç¨‹ä¸­çš„å…·ä½“è¡¨ç°ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒLLMsèƒ½å¤Ÿæœ‰æ•ˆåœ°è§£æå’Œè§£è¯»ç»†å¾®çš„è¡Œä¸ºæ¨¡å¼ï¼Œä¸ºé€šè¿‡å®æ—¶ã€åŸºäºè¡Œä¸ºçš„åˆ†ææ¥å¢å¼ºç½‘ç»œé˜²å¾¡ç­–ç•¥æä¾›äº†ä¸€ç§è½¬å‹æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13240v1",
      "published_date": "2025-08-18 05:51:30 UTC",
      "updated_date": "2025-08-18 05:51:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:50.399164+00:00"
    },
    {
      "arxiv_id": "2508.14112v2",
      "title": "Surya: Foundation Model for Heliophysics",
      "title_zh": "Suryaï¼šå¤ªé˜³ç‰©ç†å­¦åŸºç¡€æ¨¡å‹",
      "authors": [
        "Sujit Roy",
        "Johannes Schmude",
        "Rohit Lal",
        "Vishal Gaur",
        "Marcus Freitag",
        "Julian Kuehnert",
        "Theodore van Kessel",
        "Dinesha V. Hegde",
        "AndrÃ©s MuÃ±oz-Jaramillo",
        "Johannes Jakubik",
        "Etienne Vos",
        "Kshitiz Mandal",
        "Ata Akbari Asanjan",
        "Joao Lucas de Sousa Almeida",
        "Amy Lin",
        "Talwinder Singh",
        "Kang Yang",
        "Chetraj Pandey",
        "Jinsu Hong",
        "Berkay Aydin",
        "Thorsten Kurth",
        "Ryan McGranaghan",
        "Spiridon Kasapis",
        "Vishal Upendran",
        "Shah Bahauddin",
        "Daniel da Silva",
        "Nikolai V. Pogorelov",
        "Anne Spalding",
        "Campbell Watson",
        "Manil Maskey",
        "Madhulika Guhathakurta",
        "Juan Bernabe-Moreno",
        "Rahul Ramachandran"
      ],
      "abstract": "Heliophysics is central to understanding and forecasting space weather events and solar activity. Despite decades of high-resolution observations from the Solar Dynamics Observatory (SDO), most models remain task-specific and constrained by scarce labeled data, limiting their capacity to generalize across solar phenomena. We introduce Surya, a 366M parameter foundation model for heliophysics designed to learn general-purpose solar representations from multi-instrument SDO observations, including eight Atmospheric Imaging Assembly (AIA) channels and five Helioseismic and Magnetic Imager (HMI) products. Surya employs a spatiotemporal transformer architecture with spectral gating and long--short range attention, pretrained on high-resolution solar image forecasting tasks and further optimized through autoregressive rollout tuning. Zero-shot evaluations demonstrate its ability to forecast solar dynamics and flare events, while downstream fine-tuning with parameter-efficient Low-Rank Adaptation (LoRA) shows strong performance on solar wind forecasting, active region segmentation, solar flare forecasting, and EUV spectra. Surya is the first foundation model in heliophysics that uses time advancement as a pretext task on full-resolution SDO data. Its novel architecture and performance suggest that the model is able to learn the underlying physics behind solar evolution.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Suryaï¼Œä¸€ä¸ªæ‹¥æœ‰3.66äº¿å‚æ•°çš„æ—¥åœ°ç‰©ç†(Heliophysics)åŸºç¡€æ¨¡å‹ï¼Œæ—¨åœ¨åˆ©ç”¨æ¥è‡ªå¤ªé˜³åŠ¨åŠ›å­¦å¤©æ–‡å°(SDO)çš„å¤šä»ªå™¨è§‚æµ‹æ•°æ®å­¦ä¹ é€šç”¨çš„å¤ªé˜³è¡¨å¾ã€‚è¯¥æ¨¡å‹é‡‡ç”¨äº†åŒ…å«è°±é—¨æ§(Spectral Gating)å’Œé•¿çŸ­ç¨‹æ³¨æ„åŠ›(Long-short Range Attention)æœºåˆ¶çš„æ—¶ç©ºTransformeræ¶æ„ï¼Œå¹¶åœ¨é«˜åˆ†è¾¨ç‡å¤ªé˜³å›¾åƒé¢„æŠ¥ä»»åŠ¡ä¸Šé€šè¿‡è‡ªå›å½’æ»šåŠ¨è°ƒä¼˜(Autoregressive Rollout Tuning)è¿›è¡Œäº†é¢„è®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSuryaåœ¨é›¶æ ·æœ¬(Zero-shot)è¯„ä¼°ä¸­å±•ç°äº†é¢„æµ‹å¤ªé˜³åŠ¨åŠ›å­¦å’Œè€€æ–‘äº‹ä»¶çš„èƒ½åŠ›ï¼Œä¸”åœ¨ç»“åˆä½ç§©è‡ªé€‚åº”(LoRA)å¾®è°ƒåï¼Œåœ¨å¤ªé˜³é£é¢„æµ‹å’Œæ´»åŠ¨åŒºåˆ†å‰²ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚ä½œä¸ºé¦–ä¸ªåœ¨å…¨åˆ†è¾¨ç‡SDOæ•°æ®ä¸Šä»¥æ—¶é—´æ¨è¿›ä½œä¸ºé¢„è®­ç»ƒä»»åŠ¡çš„åŸºç¡€æ¨¡å‹ï¼ŒSuryaè¯æ˜äº†å…¶èƒ½å¤Ÿå­¦ä¹ å¤ªé˜³æ¼”åŒ–èƒŒåçš„æ½œåœ¨ç‰©ç†è§„å¾‹ã€‚è¿™ä¸€ç ”ç©¶æ ‡å¿—ç€æ—¥åœ°ç‰©ç†æ¨¡å‹ä»ç‰¹å®šä»»åŠ¡é©±åŠ¨å‘é€šç”¨åŸºç¡€æ¨¡å‹çš„é‡è¦è½¬å˜ï¼Œä¸ºæ›´ç²¾ç¡®çš„å¤ªç©ºå¤©æ°”é¢„æŠ¥å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14112v2",
      "published_date": "2025-08-18 05:44:25 UTC",
      "updated_date": "2025-08-21 16:53:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:56.756283+00:00"
    },
    {
      "arxiv_id": "2509.09685v4",
      "title": "TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation",
      "title_zh": "TalkPlayData 2ï¼šé¢å‘å¤šæ¨¡æ€å¯¹è¯å¼éŸ³ä¹æ¨èçš„æ™ºèƒ½ä½“åˆæˆæ•°æ®æµæ°´çº¿",
      "authors": [
        "Keunwoo Choi",
        "Seungheon Doh",
        "Juhan Nam"
      ],
      "abstract": "We present TalkPlayData 2, a synthetic dataset for multimodal conversational music recommendation generated by an agentic data pipeline. In the proposed pipeline, multiple large language model (LLM) agents are created under various roles with specialized prompts and access to different parts of information, and the chat data is acquired by logging the conversation between the Listener LLM and the Recsys LLM. To cover various conversation scenarios, for each conversation, the Listener LLM is conditioned on a finetuned conversation goal. Finally, all the LLMs are multimodal with audio and images, allowing a simulation of multimodal recommendation and conversation. In the LLM-as-a-judge and subjective evaluation experiments, TalkPlayData 2 achieved the proposed goal in various aspects related to training a generative recommendation model for music. TalkPlayData 2 and its generation code are released at https://talkpl.ai/talkplaydata2.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TalkPlayData 2ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡æ™ºèƒ½ä½“åŒ– (agentic) æ•°æ®æµæ°´çº¿ç”Ÿæˆçš„ï¼Œç”¨äºå¤šæ¨¡æ€å¯¹è¯å¼éŸ³ä¹æ¨èçš„åˆæˆæ•°æ®é›†ã€‚åœ¨è¯¥æµæ°´çº¿ä¸­ï¼Œå¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½ä½“è¢«èµ‹äºˆä¸åŒçš„è§’è‰²å’Œä¸“é—¨çš„æç¤ºè¯ï¼Œé€šè¿‡è®°å½• Listener LLM ä¸ Recsys LLM ä¹‹é—´çš„å¯¹è¯æ¥è·å–èŠå¤©æ•°æ®ã€‚ä¸ºäº†è¦†ç›–å¤šæ ·çš„å¯¹è¯åœºæ™¯ï¼ŒListener LLM åœ¨æ¯æ¬¡å¯¹è¯ä¸­éƒ½å—åˆ°å¾®è°ƒåçš„å¯¹è¯ç›®æ ‡ (conversation goal) çº¦æŸã€‚æ‰€æœ‰æ™ºèƒ½ä½“å‡æ”¯æŒéŸ³é¢‘å’Œå›¾åƒç­‰å¤šæ¨¡æ€è¾“å…¥ï¼Œä»è€Œå®ç°äº†å¯¹å¤šæ¨¡æ€æ¨èå’Œå¯¹è¯è¿‡ç¨‹çš„ä»¿çœŸæ¨¡æ‹Ÿã€‚å®éªŒé€šè¿‡ LLM-as-a-judge å’Œä¸»è§‚è¯„ä¼°è¯æ˜ï¼ŒTalkPlayData 2 åœ¨è®­ç»ƒç”Ÿæˆå¼éŸ³ä¹æ¨èæ¨¡å‹çš„å¤šä¸ªå…³é”®ç»´åº¦ä¸Šè¡¨ç°å‡ºè‰²ã€‚ç›®å‰ï¼Œè¯¥æ•°æ®é›†åŠå…¶ç”Ÿæˆä»£ç å·²å…¬å¼€å‘å¸ƒï¼Œä¸ºå¤šæ¨¡æ€å¯¹è¯å¼æ¨èç³»ç»Ÿçš„ç ”ç©¶æä¾›äº†é‡è¦èµ„æºã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.IR",
      "comment": "2025-10-08: updating the stat table with the latest numbers. updated the abstract per the latest license terms",
      "pdf_url": "https://arxiv.org/pdf/2509.09685v4",
      "published_date": "2025-08-18 05:06:58 UTC",
      "updated_date": "2025-10-08 20:52:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:55.186996+00:00"
    },
    {
      "arxiv_id": "2508.12623v1",
      "title": "How can we trust opaque systems? Criteria for robust explanations in XAI",
      "title_zh": "æˆ‘ä»¬å¦‚ä½•ä¿¡ä»»ä¸é€æ˜ç³»ç»Ÿï¼ŸXAI ä¸­é²æ£’è§£é‡Šçš„è¯„ä¼°å‡†åˆ™",
      "authors": [
        "Florian J. Boge",
        "Annika Schuster"
      ],
      "abstract": "Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in scientific research. However, the price we pay for their impressively accurate predictions is significant: their inner workings are notoriously opaque - it is unknown to laypeople and researchers alike what features of the data a DL system focuses on and how it ultimately succeeds in predicting correct outputs. A necessary criterion for trustworthy explanations is that they should reflect the relevant processes the algorithms' predictions are based on. The field of eXplainable Artificial Intelligence (XAI) presents promising methods to create such explanations. But recent reviews about their performance offer reasons for skepticism. As we will argue, a good criterion for trustworthiness is explanatory robustness: different XAI methods produce the same explanations in comparable contexts. However, in some instances, all methods may give the same, but still wrong, explanation. We therefore argue that in addition to explanatory robustness (ER), a prior requirement of explanation method robustness (EMR) has to be fulfilled by every XAI method. Conversely, the robustness of an individual method is in itself insufficient for trustworthiness. In what follows, we develop and formalize criteria for ER as well as EMR, providing a framework for explaining and establishing trust in DL algorithms. We also highlight interesting application cases and outline directions for future work.",
      "tldr_zh": "æ·±åº¦å­¦ä¹ (Deep learning)ç³»ç»Ÿçš„é»‘ç›’å±æ€§å¯¼è‡´å…¶å†³ç­–è¿‡ç¨‹ç¼ºä¹é€æ˜åº¦ï¼Œä½¿å¾—å»ºç«‹å¯è§£é‡Šäººå·¥æ™ºèƒ½(eXplainable Artificial Intelligence, XAI)çš„ä¿¡ä»»æœºåˆ¶æˆä¸ºè¿«åˆ‡éœ€æ±‚ã€‚æœ¬ç ”ç©¶æå‡ºï¼Œå»ºç«‹ä¿¡ä»»çš„ä¸€ä¸ªå…³é”®æ ‡å‡†æ˜¯è§£é‡Šç¨³å¥æ€§(explanatory robustness, ER)ï¼Œå³ä¸åŒçš„XAIæ–¹æ³•åœ¨ç›¸ä¼¼è¯­å¢ƒä¸‹åº”å½“äº§å‡ºä¸€è‡´çš„è§£é‡Šã€‚ä½œè€…å¼ºè°ƒï¼Œä»…ä¾èµ–ERå¯èƒ½å¯¼è‡´æ‰€æœ‰æ–¹æ³•äº§ç”Ÿç›¸åŒä½†é”™è¯¯çš„ç»“è®ºï¼Œå› æ­¤å¿…é¡»åŒæ—¶æ»¡è¶³è§£é‡Šæ–¹æ³•ç¨³å¥æ€§(explanation method robustness, EMR)çš„å‰ç½®è¦æ±‚ã€‚æ–‡ç« é€šè¿‡å¼€å‘å¹¶å½¢å¼åŒ–ERä¸EMRçš„è¯„ä»·å‡†åˆ™ï¼Œä¸ºæ·±åº¦å­¦ä¹ ç®—æ³•çš„å¯ä¿¡è§£é‡Šå»ºç«‹äº†ä¸€å¥—ç³»ç»Ÿæ€§çš„æ¡†æ¶ã€‚è¯¥ç ”ç©¶æœ€åå±•ç¤ºäº†ç›¸å…³åº”ç”¨æ¡ˆä¾‹ï¼Œå¹¶ä¸ºæœªæ¥XAIé¢†åŸŸçš„ç¨³å¥æ€§ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2508.12623v1",
      "published_date": "2025-08-18 04:38:55 UTC",
      "updated_date": "2025-08-18 04:38:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:38:53.191772+00:00"
    },
    {
      "arxiv_id": "2508.12617v1",
      "title": "A Generalized Genetic Random Field Method for the Genetic Association Analysis of Sequencing Data",
      "title_zh": "æµ‹åºæ•°æ®é—ä¼ å…³è”åˆ†æçš„å¹¿ä¹‰é—ä¼ éšæœºåœºæ–¹æ³•",
      "authors": [
        "Ming Li",
        "Zihuai He",
        "Min Zhang",
        "Xiaowei Zhan",
        "Changshuai Wei",
        "Robert C Elston",
        "Qing Lu"
      ],
      "abstract": "With the advance of high-throughput sequencing technologies, it has become feasible to investigate the influence of the entire spectrum of sequencing variations on complex human diseases. Although association studies utilizing the new sequencing technologies hold great promise to unravel novel genetic variants, especially rare genetic variants that contribute to human diseases, the statistical analysis of high-dimensional sequencing data remains a challenge. Advanced analytical methods are in great need to facilitate high-dimensional sequencing data analyses. In this article, we propose a generalized genetic random field (GGRF) method for association analyses of sequencing data. Like other similarity-based methods (e.g., SIMreg and SKAT), the new method has the advantages of avoiding the need to specify thresholds for rare variants and allowing for testing multiple variants acting in different directions and magnitude of effects. The method is built on the generalized estimating equation framework and thus accommodates a variety of disease phenotypes (e.g., quantitative and binary phenotypes). Moreover, it has a nice asymptotic property, and can be applied to small-scale sequencing data without need for small-sample adjustment. Through simulations, we demonstrate that the proposed GGRF attains an improved or comparable power over a commonly used method, SKAT, under various disease scenarios, especially when rare variants play a significant role in disease etiology. We further illustrate GGRF with an application to a real dataset from the Dallas Heart Study. By using GGRF, we were able to detect the association of two candidate genes, ANGPTL3 and ANGPTL4, with serum triglyceride.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å¹¿ä¹‰é—ä¼ éšæœºåœº (GGRF) æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³é«˜é€šé‡æµ‹åºæ•°æ®ä¸­é«˜ç»´å…³è”åˆ†æçš„ç»Ÿè®¡æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•å»ºç«‹åœ¨å¹¿ä¹‰ä¼°è®¡æ–¹ç¨‹ (generalized estimating equation) æ¡†æ¶ä¹‹ä¸Šï¼Œèƒ½å¤Ÿå…¼å®¹å®šé‡å’ŒäºŒåˆ†ç±»ç­‰å¤šç§ç–¾ç—…è¡¨å‹ï¼Œä¸”æ— éœ€ä¸ºç¨€æœ‰å˜å¼‚ (rare variants) è®¾å®šé˜ˆå€¼ã€‚GGRF å…è®¸åŒæ—¶å¯¹å…·æœ‰ä¸åŒä½œç”¨æ–¹å‘å’Œå¼ºåº¦çš„å¤šä¸ªå˜å¼‚è¿›è¡Œæ£€æµ‹ï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„æ¸è¿‘æ€§è´¨ï¼Œé€‚ç”¨äºæ— éœ€å°æ ·æœ¬è°ƒæ•´çš„å°è§„æ¨¡æµ‹åºæ•°æ®ã€‚æ¨¡æ‹Ÿå®éªŒè¯æ˜ï¼ŒGGRF åœ¨å¤šç§ç–¾ç—…åœºæ™¯ä¸‹çš„æ£€éªŒæ•ˆèƒ½ä¼˜äºæˆ–ç­‰åŒäºå¸¸ç”¨çš„ SKAT æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¨€æœ‰å˜å¼‚èµ·ä¸»å¯¼ä½œç”¨æ—¶è¡¨ç°æ›´ä½³ã€‚é€šè¿‡å¯¹ Dallas Heart Study çœŸå®æ•°æ®é›†çš„åº”ç”¨ï¼Œè¯¥æ–¹æ³•æˆåŠŸè¯†åˆ«å‡º ANGPTL3 å’Œ ANGPTL4 åŸºå› ä¸è¡€æ¸…ç”˜æ²¹ä¸‰é…¯çš„æ˜¾è‘—å…³è”ï¼ŒéªŒè¯äº†å…¶åœ¨å¤æ‚ç–¾ç—…é—ä¼ ç ”ç©¶ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12617v1",
      "published_date": "2025-08-18 04:28:48 UTC",
      "updated_date": "2025-08-18 04:28:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:02.161617+00:00"
    },
    {
      "arxiv_id": "2508.12611v3",
      "title": "An LLM + ASP Workflow for Joint Entity-Relation Extraction",
      "title_zh": "ä¸€ç§ç”¨äºè”åˆå®ä½“å…³ç³»æŠ½å–çš„ LLM + ASP å·¥ä½œæµ",
      "authors": [
        "Trang Tran",
        "Trung Hoang Le",
        "Huiping Cao",
        "Tran Cao Son"
      ],
      "abstract": "Joint entity-relation extraction (JERE) identifies both entities and their relationships simultaneously. Traditional machine-learning based approaches to performing this task require a large corpus of annotated data and lack the ability to easily incorporate domain specific information in the construction of the model. Therefore, creating a model for JERE is often labor intensive, time consuming, and elaboration intolerant. In this paper, we propose harnessing the capabilities of generative pre-trained large language models (LLMs) and the knowledge representation and reasoning capabilities of Answer Set Programming (ASP) to perform JERE. We present a generic workflow for JERE using LLMs and ASP. The workflow is generic in the sense that it can be applied for JERE in any domain. It takes advantage of LLM's capability in natural language understanding in that it works directly with unannotated text. It exploits the elaboration tolerant feature of ASP in that no modification of its core program is required when additional domain specific knowledge, in the form of type specifications, is found and needs to be used. We demonstrate the usefulness of the proposed workflow through experiments with limited training data on three well-known benchmarks for JERE. The results of our experiments show that the LLM + ASP workflow is better than state-of-the-art JERE systems in several categories with only 10% of training data. It is able to achieve a 2.5 times (35% over 15%) improvement in the Relation Extraction task for the SciERC corpus, one of the most difficult benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå¤§è¯­è¨€æ¨¡å‹(LLM)ä¸å›ç­”é›†ç¨‹åºè®¾è®¡(ASP)çš„é€šç”¨å·¥ä½œæµï¼Œæ—¨åœ¨è§£å†³è”åˆå®ä½“å…³ç³»æŠ½å–(JERE)ä¸­ä¼ ç»Ÿæ–¹æ³•ä¾èµ–å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®ä¸”éš¾ä»¥èå…¥é¢†åŸŸçŸ¥è¯†çš„é—®é¢˜ã€‚è¯¥å·¥ä½œæµåˆ©ç”¨ LLM å¼ºå¤§çš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›ç›´æ¥å¤„ç†æœªæ ‡æ³¨æ–‡æœ¬ï¼Œå¹¶å‘æŒ¥ ASP çš„çŸ¥è¯†è¡¨ç¤ºä¸æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡å…¶â€œç»†åŒ–å®¹å¿åº¦â€(elaboration tolerance)ç‰¹å¾ï¼Œåœ¨æ— éœ€ä¿®æ”¹æ ¸å¿ƒç¨‹åºçš„æƒ…å†µä¸‹çµæ´»æ•´åˆç‰¹å®šé¢†åŸŸçš„ç±»å‹è§„èŒƒã€‚ç ”ç©¶äººå‘˜åœ¨ä¸‰ä¸ªè‘—åçš„ JERE åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼ŒéªŒè¯äº†è¯¥å·¥ä½œæµåœ¨æœ‰é™è®­ç»ƒæ•°æ®æ¡ä»¶ä¸‹çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ LLM + ASP å·¥ä½œæµåœ¨ä»…ä½¿ç”¨ 10% è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œåœ¨å¤šä¸ªç±»åˆ«ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„ JERE ç³»ç»Ÿã€‚ç‰¹åˆ«æ˜¯åœ¨æå…·æŒ‘æˆ˜æ€§çš„ SciERC è¯­æ–™åº“å…³ç³»æŠ½å–ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•å®ç°äº† 2.5 å€çš„æ€§èƒ½æå‡ï¼Œå‡†ç¡®ç‡ä» 15% æé«˜è‡³ 35%ï¼Œä¸ºä½èµ„æºç¯å¢ƒä¸‹çš„ä¿¡æ¯æŠ½å–ä»»åŠ¡æä¾›äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings ICLP 2025, arXiv:2601.00047",
      "pdf_url": "https://arxiv.org/pdf/2508.12611v3",
      "published_date": "2025-08-18 04:15:35 UTC",
      "updated_date": "2026-01-08 11:15:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:07.659513+00:00"
    },
    {
      "arxiv_id": "2508.12610v1",
      "title": "OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion",
      "title_zh": "OpenMoCapï¼šç°å®ä¸–ç•Œé®æŒ¡ä¸‹çš„å…‰å­¦åŠ¨ä½œæ•æ‰å†æ€è€ƒ",
      "authors": [
        "Chen Qian",
        "Danyang Li",
        "Xinran Yu",
        "Zheng Yang",
        "Qiang Ma"
      ],
      "abstract": "Optical motion capture is a foundational technology driving advancements in cutting-edge fields such as virtual reality and film production. However, system performance suffers severely under large-scale marker occlusions common in real-world applications. An in-depth analysis identifies two primary limitations of current models: (i) the lack of training datasets accurately reflecting realistic marker occlusion patterns, and (ii) the absence of training strategies designed to capture long-range dependencies among markers. To tackle these challenges, we introduce the CMU-Occlu dataset, which incorporates ray tracing techniques to realistically simulate practical marker occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving model designed specifically for robust motion capture in environments with significant occlusions. Leveraging a marker-joint chain inference mechanism, OpenMoCap enables simultaneous optimization and construction of deep constraints between markers and joints. Extensive comparative experiments demonstrate that OpenMoCap consistently outperforms competing methods across diverse scenarios, while the CMU-Occlu dataset opens the door for future studies in robust motion solving. The proposed OpenMoCap is integrated into the MoSen MoCap system for practical deployment. The code is released at: https://github.com/qianchen214/OpenMoCap.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†OpenMoCapï¼Œæ—¨åœ¨é‡æ–°å®¡è§†å¹¶è§£å†³å…‰å­¦åŠ¨ä½œæ•æ‰(Optical motion capture)åœ¨çœŸå®ä¸–ç•Œä¸­é¢ä¸´çš„å¤§è§„æ¨¡æ ‡è®°ç‚¹é®æŒ¡(marker occlusions)é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æ¨¡å‹ç¼ºä¹çœŸå®é®æŒ¡æ•°æ®é›†ä»¥åŠå¯¹æ ‡è®°ç‚¹é—´é•¿ç¨‹ä¾èµ–æ•æ‰èƒ½åŠ›ä¸è¶³çš„å±€é™ï¼Œç ”ç©¶è€…é¦–å…ˆåˆ©ç”¨å…‰çº¿è¿½è¸ªæŠ€æœ¯(ray tracing)æ„å»ºäº†CMU-Occluæ•°æ®é›†ä»¥æ¨¡æ‹ŸçœŸå®çš„é®æŒ¡æ¨¡å¼ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼ŒOpenMoCapæ¨¡å‹é‡‡ç”¨äº†ä¸€ç§åˆ›æ–°çš„æ ‡è®°ç‚¹-å…³èŠ‚é“¾æ¨ç†æœºåˆ¶(marker-joint chain inference mechanism)ï¼Œå®ç°äº†æ ‡è®°ç‚¹ä¸å…³èŠ‚ä¹‹é—´æ·±åº¦çº¦æŸçš„åŒæ­¥ä¼˜åŒ–ä¸æ„å»ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOpenMoCapåœ¨å¤šç§å¤æ‚åœºæ™¯ä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†åŠ¨ä½œæ•æ‰çš„é²æ£’æ€§ã€‚ç›®å‰è¯¥æˆæœå·²é›†æˆäºMoSenåŠ¨ä½œæ•æ‰ç³»ç»Ÿå¹¶å¼€æºï¼Œä¸ºæœªæ¥é²æ£’æ€§è¿åŠ¨æ±‚è§£ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12610v1",
      "published_date": "2025-08-18 04:12:13 UTC",
      "updated_date": "2025-08-18 04:12:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:06.847624+00:00"
    },
    {
      "arxiv_id": "2508.12604v1",
      "title": "SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression",
      "title_zh": "SSPOï¼šé¢å‘è¿‡ç¨‹ç›‘ç£ä¸æ¨ç†å‹ç¼©çš„è‡ªè¿½è¸ªåˆ†æ­¥åå¥½ä¼˜åŒ–",
      "authors": [
        "Yuyang Xu",
        "Yi Cheng",
        "Haochao Ying",
        "Zhuoyun Du",
        "Renjun Hu",
        "Xing Shi",
        "Wei Lin",
        "Jian Wu"
      ],
      "abstract": "Test-time scaling has proven effective in further enhancing the performance of pretrained Large Language Models (LLMs). However, mainstream post-training methods (i.e., reinforcement learning (RL) with chain-of-thought (CoT) reasoning) often incur substantial computational overhead due to auxiliary models and overthinking. In this paper, we empirically reveal that the incorrect answers partially stem from verbose reasoning processes lacking correct self-fix, where errors accumulate across multiple reasoning steps. To this end, we propose Self-traced Step-wise Preference Optimization (SSPO), a pluggable RL process supervision framework that enables fine-grained optimization of each reasoning step. Specifically, SSPO requires neither auxiliary models nor stepwise manual annotations. Instead, it leverages step-wise preference signals generated by the model itself to guide the optimization process for reasoning compression. Experiments demonstrate that the generated reasoning sequences from SSPO are both accurate and succinct, effectively mitigating overthinking behaviors without compromising model performance across diverse domains and languages.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SSPOï¼ˆSelf-traced Step-wise Preference Optimizationï¼‰ï¼Œä¸€ä¸ªæ—¨åœ¨å®ç°è¿‡ç¨‹ç›‘ç£ï¼ˆProcess Supervisionï¼‰å’Œæ¨ç†å‹ç¼©ï¼ˆReasoning Compressionï¼‰çš„å¯æ’æ‹”å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åè®­ç»ƒä¸­å¸¸å› è¾…åŠ©æ¨¡å‹å’Œè¿‡åº¦æ€è€ƒï¼ˆOverthinkingï¼‰å¯¼è‡´è®¡ç®—å¼€é”€è¿‡å¤§åŠæ¨ç†é”™è¯¯ç´¯ç§¯çš„é—®é¢˜ï¼ŒSSPOæä¾›äº†ä¸€ç§ç»†ç²’åº¦çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶æ— éœ€ä¾èµ–è¾…åŠ©æ¨¡å‹æˆ–æ‰‹åŠ¨åˆ†æ­¥æ ‡æ³¨ï¼Œè€Œæ˜¯é€šè¿‡æ¨¡å‹è‡ªèº«ç”Ÿæˆçš„æ­¥è¿›å¼åå¥½ä¿¡å·ï¼ˆStep-wise Preference Signalsï¼‰æ¥æŒ‡å¯¼ä¼˜åŒ–è¿‡ç¨‹ã€‚å®éªŒè¯æ˜ï¼ŒSSPOèƒ½å¤Ÿç”Ÿæˆæ—¢å‡†ç¡®åˆç®€æ´çš„æ¨ç†åºåˆ—ï¼Œåœ¨ä¿æŒä¸åŒé¢†åŸŸå’Œè¯­è¨€ä»»åŠ¡æ€§èƒ½çš„åŒæ—¶ï¼Œæœ‰æ•ˆç¼“è§£äº†è¿‡åº¦æ€è€ƒç°è±¡ã€‚è¿™ç§è‡ªæˆ‘è¿½è¸ªï¼ˆSelf-tracedï¼‰çš„æœºåˆ¶ä¸ºæé«˜æ¨ç†æ•ˆç‡å’Œå‡å°‘æ¨ç†å†—ä½™æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress",
      "pdf_url": "https://arxiv.org/pdf/2508.12604v1",
      "published_date": "2025-08-18 04:02:15 UTC",
      "updated_date": "2025-08-18 04:02:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:16.462107+00:00"
    },
    {
      "arxiv_id": "2508.12591v1",
      "title": "Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning",
      "title_zh": "çªç ´æ¨¡æ€å±€é™ï¼šåŸºäºæœ‰æ•ˆè¯¾ç¨‹å­¦ä¹ çš„ç»Ÿä¸€ MLLM è‡ªåŠ¨å£è¯­æµ‹è¯„æ–¹æ³•",
      "authors": [
        "Yu-Hsuan Fang",
        "Tien-Hong Lo",
        "Yao-Ting Sung",
        "Berlin Chen"
      ],
      "abstract": "Traditional Automated Speaking Assessment (ASA) systems exhibit inherent modality limitations: text-based approaches lack acoustic information while audio-based methods miss semantic context. Multimodal Large Language Models (MLLM) offer unprecedented opportunities for comprehensive ASA by simultaneously processing audio and text within unified frameworks. This paper presents a very first systematic study of MLLM for comprehensive ASA, demonstrating the superior performance of MLLM across the aspects of content and language use . However, assessment on the delivery aspect reveals unique challenges, which is deemed to require specialized training strategies. We thus propose Speech-First Multimodal Training (SFMT), leveraging a curriculum learning principle to establish more robust modeling foundations of speech before cross-modal synergetic fusion. A series of experiments on a benchmark dataset show MLLM-based systems can elevate the holistic assessment performance from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the evaluation of the delivery aspect, achieving an absolute accuracy improvement of 4% over conventional training approaches, which also paves a new avenue for ASA.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿè‡ªåŠ¨å£è¯­æµ‹è¯„(Automated Speaking Assessment, ASA)ä¸­å•æ¨¡æ€ç³»ç»Ÿçš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åŒæ—¶å¤„ç†éŸ³é¢‘å’Œæ–‡æœ¬ä¿¡æ¯æ¥æå‡æµ‹è¯„çš„å…¨é¢æ€§ã€‚ç ”ç©¶é€šè¿‡ç³»ç»Ÿæ€§å®éªŒè¯æ˜äº† MLLM åœ¨å†…å®¹(Content)å’Œè¯­è¨€ä½¿ç”¨(Language Use)ç»´åº¦ä¸Šçš„å“è¶Šæ€§èƒ½ï¼Œä½†ä¹Ÿæ­ç¤ºäº†å…¶åœ¨è¯­éŸ³äº¤ä»˜(Delivery)è¯„ä¼°æ–¹é¢é¢ä¸´çš„ç‹¬ç‰¹æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†è¯­éŸ³ä¼˜å…ˆå¤šæ¨¡æ€è®­ç»ƒ(Speech-First Multimodal Training, SFMT)ï¼Œè¯¥æ–¹æ³•éµå¾ªè¯¾ç¨‹å­¦ä¹ (Curriculum Learning)åŸåˆ™ï¼Œåœ¨è¿›è¡Œè·¨æ¨¡æ€ååŒèåˆä¹‹å‰ï¼Œå…ˆå»ºç«‹æ›´ç¨³å¥çš„è¯­éŸ³å»ºæ¨¡åŸºç¡€ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäº MLLM çš„ç³»ç»Ÿå°†æ•´ä½“è¯„ä¼°æ€§èƒ½çš„çš®å°”é€Šç›¸å…³ç³»æ•°(PCC)ä» 0.783 æå‡è‡³ 0.846ã€‚ç‰¹åˆ«æ˜¯ SFMT æ–¹æ³•åœ¨è¯­éŸ³äº¤ä»˜ç»´åº¦çš„è¯„ä¼°ä¸­æ¯”ä¼ ç»Ÿè®­ç»ƒæ–¹æ³•å®ç°äº† 4% çš„ç»å¯¹å‡†ç¡®ç‡æå‡ï¼Œä¸º ASA é¢†åŸŸå¼€è¾Ÿäº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IEEE ASRU 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12591v1",
      "published_date": "2025-08-18 02:57:43 UTC",
      "updated_date": "2025-08-18 02:57:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:40:02.373340+00:00"
    },
    {
      "arxiv_id": "2508.12590v1",
      "title": "Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding",
      "title_zh": "åŸºäºä¸ç¡®å®šæ€§ä¸é‡è¦æ€§æ„ŸçŸ¥æŠ•æœºè§£ç çš„é«˜èƒ½æ•ˆæ— çº¿ LLM æ¨ç†",
      "authors": [
        "Jihoon Park",
        "Seungeun Oh",
        "Seong-Lyun Kim"
      ],
      "abstract": "To address the growing demand for on-device LLM inference in resource-constrained environments, hybrid language models (HLM) have emerged, combining lightweight local models with powerful cloud-based LLMs. Recent studies on HLM have primarily focused on improving accuracy and latency, while often overlooking communication and energy efficiency. We propose a token-level filtering mechanism for an energy-efficient importance- and uncertainty-aware HLM inference that leverages both epistemic uncertainty and attention-based importance. Our method opportunistically uploads only informative tokens, reducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and LLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and token throughput of 0.37 tokens/sec while saving the energy consumption by 40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM baseline, our method improves BERTScore from 85.8% to 87.0%, energy savings from 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an energy-efficient and accurate deployment of LLMs in bandwidth-constrained edge environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èµ„æºå—é™ç¯å¢ƒä¸‹çš„è®¾å¤‡ç«¯å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åŸºäºä¸ç¡®å®šæ€§ä¸é‡è¦æ€§æ„ŸçŸ¥çš„æ··åˆè¯­è¨€æ¨¡å‹(HLM)æ¨ç†æœºåˆ¶ã€‚ä¸ºäº†è§£å†³é€šä¿¡ä¸èƒ½æºæ•ˆç‡å¸¸è¢«å¿½è§†çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†ä»¤ç‰Œçº§è¿‡æ»¤æœºåˆ¶ï¼Œç»“åˆè®¤è¯†ä¸ç¡®å®šæ€§(epistemic uncertainty)å’ŒåŸºäºæ³¨æ„åŠ›çš„é‡è¦æ€§(attention-based importance)æ¥é€‰æ‹©æ€§åœ°ä¸Šä¼ å…³é”®ä»¤ç‰Œã€‚é€šè¿‡ä»…ä¸Šä¼ ä¿¡æ¯é‡å¤§çš„ä»¤ç‰Œï¼Œè¯¥æ–¹æ¡ˆæœ‰æ•ˆå‡å°‘äº†äº‘ç«¯LLMçš„ä½¿ç”¨é¢‘ç‡å¹¶é™ä½äº†é€šä¿¡æˆæœ¬ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨TinyLlama-1.1Bå’ŒLLaMA-2-7Bä¸Šçš„æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒ87.5%çš„BERT Scoreçš„åŒæ—¶ï¼Œæ¯”æ ‡å‡†HLMèŠ‚çœäº†40.7%çš„èƒ½è€—ã€‚ç›¸è¾ƒäºä¹‹å‰çš„U-HLMåŸºçº¿ï¼Œè¯¥æ–¹æ¡ˆåœ¨BERTScoreã€èƒ½æ•ˆåŠååé‡æ–¹é¢å‡å®ç°äº†æ˜¾è‘—æå‡ã€‚è¯¥é¡¹å·¥ä½œä¸ºå¸¦å®½å—é™çš„è¾¹ç¼˜ç¯å¢ƒä¸‹éƒ¨ç½²é«˜æ•ˆä¸”å‡†ç¡®çš„LLMæä¾›äº†å¯è¡Œæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.12590v1",
      "published_date": "2025-08-18 02:56:59 UTC",
      "updated_date": "2025-08-18 02:56:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:34.061276+00:00"
    },
    {
      "arxiv_id": "2508.12576v1",
      "title": "Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg",
      "title_zh": "å¢åŠ ç½‘ç»œå®½åº¦å¯ç¼“è§£æ•°æ®å¼‚æ„æ€§å¯¹ FedAvg çš„å½±å“",
      "authors": [
        "Like Jian",
        "Dong Liu"
      ],
      "abstract": "Federated learning (FL) enables decentralized clients to train a model collaboratively without sharing local data. A key distinction between FL and centralized learning is that clients' data are non-independent and identically distributed, which poses significant challenges in training a global model that generalizes well across heterogeneous local data distributions. In this paper, we analyze the convergence of overparameterized FedAvg with gradient descent (GD). We prove that the impact of data heterogeneity diminishes as the width of neural networks increases, ultimately vanishing when the width approaches infinity. In the infinite-width regime, we further prove that both the global and local models in FedAvg behave as linear models, and that FedAvg achieves the same generalization performance as centralized learning with the same number of GD iterations. Extensive experiments validate our theoretical findings across various network architectures, loss functions, and optimization methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰ä¸­æ•°æ®å¼‚è´¨æ€§ï¼ˆnon-IIDï¼‰å¯¹æ¨¡å‹æ³›åŒ–å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå¹¶é‡ç‚¹åˆ†æäº†è¶…å‚æ•°åŒ– FedAvg åœ¨æ¢¯åº¦ä¸‹é™ï¼ˆGDï¼‰ä¸‹çš„æ”¶æ•›æ€§ã€‚é€šè¿‡ç†è®ºè¯æ˜ï¼Œç ”ç©¶å‘ç°æ•°æ®å¼‚è´¨æ€§çš„å½±å“ä¼šéšç€ç¥ç»ç½‘ç»œå®½åº¦çš„å¢åŠ è€Œå‡å¼±ï¼Œå¹¶åœ¨å®½åº¦è¶‹äºæ— ç©·å¤§æ—¶æœ€ç»ˆæ¶ˆå¤±ã€‚åœ¨æ— é™å®½åº¦ï¼ˆinfinite-width regimeï¼‰ç¯å¢ƒä¸‹ï¼ŒFedAvg çš„å…¨å±€å’Œæœ¬åœ°æ¨¡å‹å‡è¡¨ç°ä¸ºçº¿æ€§æ¨¡å‹ï¼Œä¸”åœ¨ç›¸åŒè¿­ä»£æ¬¡æ•°ä¸‹èƒ½å®ç°ä¸é›†ä¸­å¼å­¦ä¹ ï¼ˆcentralized learningï¼‰ä¸€è‡´çš„æ³›åŒ–æ€§èƒ½ã€‚é€šè¿‡å¯¹å¤šç§ç½‘ç»œæ¶æ„ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ³•çš„å¹¿æ³›å®éªŒï¼Œè¯¥ç ”ç©¶éªŒè¯äº†å¢åŠ ç½‘ç»œå®½åº¦æ˜¯ç¼“è§£è”é‚¦å­¦ä¹ ä¸­æ•°æ®éç‹¬ç«‹åŒåˆ†å¸ƒé—®é¢˜çš„æœ‰æ•ˆæ‰‹æ®µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.12576v1",
      "published_date": "2025-08-18 02:22:55 UTC",
      "updated_date": "2025-08-18 02:22:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:35.550367+00:00"
    },
    {
      "arxiv_id": "2508.12575v1",
      "title": "Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM",
      "title_zh": "åŸºäºé¢„è®­ç»ƒè›‹ç™½è´¨å¤§è¯­è¨€æ¨¡å‹çš„æ·€ç²‰æ ·åŸæ€§é¢„æµ‹æ·±åº¦å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Zohra Yagoub",
        "Hafida Bouziane"
      ],
      "abstract": "The prediction of amyloidogenicity in peptides and proteins remains a focal point of ongoing bioinformatics. The crucial step in this field is to apply advanced computational methodologies. Many recent approaches to predicting amyloidogenicity within proteins are highly based on evolutionary motifs and the individual properties of amino acids. It is becoming increasingly evident that the sequence information-based features show high predictive performance. Consequently, our study evaluated the contextual features of protein sequences obtained from a pretrained protein large language model leveraging bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and protein sequences. Our method achieved an accuracy of 84.5% on 10-fold cross-validation and an accuracy of 83% in the test dataset. Our results demonstrate competitive performance, highlighting the potential of LLMs in enhancing the accuracy of amyloid prediction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿç‰©ä¿¡æ¯å­¦ä¸­å…³é”®çš„æ·€ç²‰æ ·å˜æ€§(Amyloidogenicity)é¢„æµ‹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„è›‹ç™½è´¨å¤§è¯­è¨€æ¨¡å‹(Protein LLM)æå–è›‹ç™½è´¨åºåˆ—çš„ä¸Šä¸‹æ–‡ç‰¹å¾(Contextual features)ï¼Œå¹¶ç»“åˆåŒå‘é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(Bidirectional LSTM)ä¸é—¨æ§å¾ªç¯å•å…ƒ(GRU)æ¥é¢„æµ‹è‚½å’Œè›‹ç™½è´¨ä¸­çš„æ·€ç²‰æ ·å˜æ€§åŒºåŸŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨åæŠ˜äº¤å‰éªŒè¯ä¸­å®ç°äº†84.5%çš„å‡†ç¡®ç‡ï¼Œå¹¶åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¾¾åˆ°äº†83%çš„å‡†ç¡®ç‡ã€‚ç ”ç©¶ç»“æœå±•ç¤ºäº†è¯¥æ–¹æ¡ˆåœ¨é¢„æµ‹æ€§èƒ½ä¸Šçš„ç«äº‰ä¼˜åŠ¿ï¼Œæœ‰åŠ›åœ°è¯æ˜äº†åˆ©ç”¨è›‹ç™½è´¨å¤§è¯­è¨€æ¨¡å‹(LLM)æå‡ç”Ÿç‰©åºåˆ—åˆ†æç²¾åº¦çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12575v1",
      "published_date": "2025-08-18 02:21:48 UTC",
      "updated_date": "2025-08-18 02:21:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:43.252147+00:00"
    },
    {
      "arxiv_id": "2508.12566v1",
      "title": "Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models",
      "title_zh": "åŠ©åŠ›è¿˜æ˜¯é˜»ç¢ï¼Ÿé‡æ–°å®¡è§† Model Context Protocol å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Wei Song",
        "Haonan Zhong",
        "Ziqi Ding",
        "Jingling Xue",
        "Yuekang Li"
      ],
      "abstract": "The Model Context Protocol (MCP) enables large language models (LLMs) to access external resources on demand. While commonly assumed to enhance performance, how LLMs actually leverage this capability remains poorly understood. We introduce MCPGAUGE, the first comprehensive evaluation framework for probing LLM-MCP interactions along four key dimensions: proactivity (self-initiated tool use), compliance (adherence to tool-use instructions), effectiveness (task performance post-integration), and overhead (computational cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning knowledge comprehension, general reasoning, and code generation. Our large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and both one- and two-turn interaction settings, comprises around 20,000 API calls and over USD 6,000 in computational cost. This comprehensive study reveals four key findings that challenge prevailing assumptions about the effectiveness of MCP integration. These insights highlight critical limitations in current AI-tool integration and position MCPGAUGE as a principled benchmark for advancing controllable, tool-augmented LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨¡å‹ä¸Šä¸‹æ–‡åè®® (Model Context Protocol, MCP) åœ¨å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ (LLMs) è®¿é—®å¤–éƒ¨èµ„æºæ–¹é¢çš„å®é™…æ•ˆæœï¼Œæ—¨åœ¨è§£å†³ç›®å‰å¯¹è¯¥åè®®å¦‚ä½•å½±å“æ¨¡å‹æ€§èƒ½ç¼ºä¹æ·±å…¥ç†è§£çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†é¦–ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ MCPGAUGEï¼Œä»ä¸»åŠ¨æ€§ (Proactivity)ã€åˆè§„æ€§ (Compliance)ã€æœ‰æ•ˆæ€§ (Effectiveness) å’Œå¼€é”€ (Overhead) å››ä¸ªå…³é”®ç»´åº¦æ¢æµ‹ LLM ä¸ MCP çš„äº¤äº’è¡Œä¸ºã€‚è¯¥æ¡†æ¶åŒ…å« 160 ä¸ªæç¤ºå¥—ä»¶å’Œ 25 ä¸ªæ•°æ®é›†ï¼Œæ¶µç›–çŸ¥è¯†ç†è§£ã€é€šç”¨æ¨ç†å’Œä»£ç ç”Ÿæˆç­‰å¤šä¸ªé¢†åŸŸã€‚é€šè¿‡å¯¹ 6 ä¸ªå•†ä¸š LLM å’Œ 30 ä¸ª MCP å·¥å…·å¥—ä»¶è¿›è¡Œæ¶‰åŠçº¦ 20,000 æ¬¡ API è°ƒç”¨çš„å¤§è§„æ¨¡è¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†å½“å‰ MCP é›†æˆåœ¨æœ‰æ•ˆæ€§æ–¹é¢çš„å››ä¸ªå…³é”®å‘ç°ï¼ŒæŒ‘æˆ˜äº†å…³äºå…¶æ€§èƒ½æå‡çš„æ™®éå‡è®¾ã€‚è¿™äº›å‘ç°æŒ‡å‡ºäº†å½“å‰ AI ä¸å·¥å…·é›†æˆçš„æ ¸å¿ƒå±€é™æ€§ï¼Œå¹¶å°† MCPGAUGE å®šä½ä¸ºæ¨åŠ¨å¯æ§ã€å·¥å…·å¢å¼ºå‹ LLM å‘å±•çš„è§„èŒƒåŒ–åŸºå‡†ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12566v1",
      "published_date": "2025-08-18 02:06:05 UTC",
      "updated_date": "2025-08-18 02:06:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:43.455834+00:00"
    },
    {
      "arxiv_id": "2508.13236v1",
      "title": "Uncertainty-Aware Learning Policy for Reliable Pulmonary Nodule Detection on Chest X-Ray",
      "title_zh": "é¢å‘å¯é èƒ¸éƒ¨ X çº¿è‚ºç»“èŠ‚æ£€æµ‹çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥å­¦ä¹ ç­–ç•¥",
      "authors": [
        "Hyeonjin Choi",
        "Jinse Kim",
        "Dong-yeon Yoo",
        "Ju-sung Sun",
        "Jung-won Lee"
      ],
      "abstract": "Early detection and rapid intervention of lung cancer are crucial. Nonetheless, ensuring an accurate diagnosis is challenging, as physicians' ability to interpret chest X-rays varies significantly depending on their experience and degree of fatigue. Although medical AI has been rapidly advancing to assist in diagnosis, physicians' trust in such systems remains limited, preventing widespread clinical adoption. This skepticism fundamentally stems from concerns about its diagnostic uncertainty. In clinical diagnosis, physicians utilize extensive background knowledge and clinical experience. In contrast, medical AI primarily relies on repetitive learning of the target lesion to generate diagnoses based solely on that data. In other words, medical AI does not possess sufficient knowledge to render a diagnosis, leading to diagnostic uncertainty. Thus, this study suggests an Uncertainty-Aware Learning Policy that can address the issue of knowledge deficiency by learning the physicians' background knowledge alongside the Chest X-ray lesion information. We used 2,517 lesion-free images and 656 nodule images, all obtained from Ajou University Hospital. The proposed model attained 92% (IoU 0.2 / FPPI 2) with a 10% enhancement in sensitivity compared to the baseline model while also decreasing entropy as a measure of uncertainty by 0.2.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹èƒ¸éƒ¨Xå°„çº¿(Chest X-ray)è‚ºç»“èŠ‚æ£€æµ‹ä¸­çš„å¯é æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ä¸ç¡®å®šæ€§æ„ŸçŸ¥å­¦ä¹ ç­–ç•¥(Uncertainty-Aware Learning Policy)ã€‚è¯¥ç­–ç•¥æ—¨åœ¨è§£å†³åŒ»ç–—AIå› ç¼ºä¹ä¸´åºŠèƒŒæ™¯çŸ¥è¯†è€Œå¯¼è‡´çš„è¯Šæ–­ä¸ç¡®å®šæ€§(diagnostic uncertainty)é—®é¢˜ï¼Œé€šè¿‡æ•´åˆå­¦ä¹ åŒ»å¸ˆçš„ä¸“ä¸šç»éªŒä¸å½±åƒç—…å˜ä¿¡æ¯ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†AIåœ¨çŸ¥è¯†å‚¨å¤‡ä¸Šçš„ç¼ºå£ã€‚ç ”ç©¶é‡‡ç”¨äº†æ¥è‡ªAjou University Hospitalçš„2,517å¼ æ— ç—…å˜å½±åƒå’Œ656å¼ ç»“èŠ‚å½±åƒè¿›è¡Œå®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨IoU 0.2 / FPPI 2çš„è¯„ä¼°æ ‡å‡†ä¸‹ï¼Œè¯¥æ¨¡å‹è¾¾åˆ°äº†92%çš„å‡†ç¡®ç‡ï¼Œä¸”çµæ•åº¦(sensitivity)è¾ƒåŸºçº¿æ¨¡å‹æå‡äº†10%ã€‚åŒæ—¶ï¼Œä½œä¸ºä¸ç¡®å®šæ€§åº¦é‡çš„ç†µ(entropy)é™ä½äº†0.2ï¼Œæ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿåœ¨ä¸´åºŠè¯Šæ–­ä¸­çš„å¯é æ€§ä¸å¯ä¿¡ä»»åº¦ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.13236v1",
      "published_date": "2025-08-18 01:58:57 UTC",
      "updated_date": "2025-08-18 01:58:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:51.052652+00:00"
    },
    {
      "arxiv_id": "2509.09684v1",
      "title": "Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query Translation",
      "title_zh": "é¢å‘æµç¨‹æŒ–æ˜é¢†åŸŸçš„ Text-to-SQLï¼šç”¨äºæŸ¥è¯¢ç¿»è¯‘çš„ PT-EN æ•°æ®é›†",
      "authors": [
        "Bruno Yui Yamate",
        "Thais Rodrigues Neubauer",
        "Marcelo Fantinato",
        "Sarajane Marques Peres"
      ],
      "abstract": "This paper introduces text-2-SQL-4-PM, a bilingual (Portuguese-English) benchmark dataset designed for the text-to-SQL task in the process mining domain. Text-to-SQL conversion facilitates natural language querying of databases, increasing accessibility for users without SQL expertise and productivity for those that are experts. The text-2-SQL-4-PM dataset is customized to address the unique challenges of process mining, including specialized vocabularies and single-table relational structures derived from event logs. The dataset comprises 1,655 natural language utterances, including human-generated paraphrases, 205 SQL statements, and ten qualifiers. Methods include manual curation by experts, professional translations, and a detailed annotation process to enable nuanced analyses of task complexity. Additionally, a baseline study using GPT-3.5 Turbo demonstrates the feasibility and utility of the dataset for text-to-SQL applications. The results show that text-2-SQL-4-PM supports evaluation of text-to-SQL implementations, offering broader applicability for semantic parsing and other natural language processing tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† text-2-SQL-4-PMï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹è¿‡ç¨‹æŒ–æ˜ (Process Mining) é¢†åŸŸè®¾è®¡çš„åŒè¯­ï¼ˆè‘¡è„ç‰™è¯­-è‹±è¯­ï¼‰åŸºå‡†æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³è¯¥é¢†åŸŸç‰¹æœ‰çš„ä¸“ä¸šæœ¯è¯­å’ŒåŸºäºäº‹ä»¶æ—¥å¿—çš„å•è¡¨å…³ç³»ç»“æ„æŒ‘æˆ˜ã€‚é€šè¿‡å°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸º SQLï¼Œè¯¥æ•°æ®é›†èƒ½å¤Ÿæ˜¾è‘—é™ä½éä¸“ä¸šäººå‘˜çš„ä½¿ç”¨é—¨æ§›å¹¶æå‡ä¸“å®¶çš„å·¥ä½œæ•ˆç‡ã€‚æ•°æ®é›†å…±åŒ…å« 1,655 æ¡è‡ªç„¶è¯­è¨€è¯è¯­ã€205 æ¡ SQL è¯­å¥åŠ 10 ä¸ªé™å®šç¬¦ï¼Œå…¶æ„å»ºè¿‡ç¨‹ç»“åˆäº†ä¸“å®¶çš„äººå·¥ç­–åˆ’ã€ä¸“ä¸šç¿»è¯‘ä»¥åŠè¯¦ç»†çš„æ ‡æ³¨æµç¨‹ã€‚åˆ©ç”¨ GPT-3.5 Turbo è¿›è¡Œçš„åŸºçº¿ç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ•°æ®é›†åœ¨ Text-to-SQL åº”ç”¨ä¸­çš„å¯è¡Œæ€§ä¸å®ç”¨ä»·å€¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œtext-2-SQL-4-PM ä¸ä»…èƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒ Text-to-SQL ç³»ç»Ÿçš„è¯„ä¼°ï¼Œè¿˜ä¸ºè¯­ä¹‰è§£æ (Semantic Parsing) ç­‰å…¶ä»–è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æä¾›äº†æ›´å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.IR",
      "comment": "33 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.09684v1",
      "published_date": "2025-08-18 01:25:41 UTC",
      "updated_date": "2025-08-18 01:25:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:49.962879+00:00"
    },
    {
      "arxiv_id": "2508.12551v1",
      "title": "OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning",
      "title_zh": "OS-R1ï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½ä½“åŒ–æ“ä½œç³»ç»Ÿå†…æ ¸è°ƒä¼˜",
      "authors": [
        "Hongyu Lin",
        "Yuchen Li",
        "Haoran Luo",
        "Kaichun Yao",
        "Libo Zhang",
        "Mingjie Xing",
        "Yanjun Wu"
      ],
      "abstract": "Linux kernel tuning is essential for optimizing operating system (OS) performance. However, existing methods often face challenges in terms of efficiency, scalability, and generalization. This paper introduces OS-R1, an agentic Linux kernel tuning framework powered by rule-based reinforcement learning (RL). By abstracting the kernel configuration space as an RL environment, OS-R1 facilitates efficient exploration by large language models (LLMs) and ensures accurate configuration modifications. Additionally, custom reward functions are designed to enhance reasoning standardization, configuration modification accuracy, and system performance awareness of the LLMs. Furthermore, we propose a two-phase training process that accelerates convergence and minimizes retraining across diverse tuning scenarios. Experimental results show that OS-R1 significantly outperforms existing baseline methods, achieving up to 5.6% performance improvement over heuristic tuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across various real-world applications, demonstrating its potential for practical deployment in diverse environments. Our dataset and code are publicly available at https://github.com/LHY-24/OS-R1.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OS-R1ï¼Œä¸€ä¸ªåŸºäº Reinforcement Learning (RL) çš„æ™ºèƒ½ä»£ç† Linux Kernel Tuning æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å†…æ ¸ä¼˜åŒ–æ–¹æ³•åœ¨æ•ˆç‡ã€å¯æ‰©å±•æ€§å’Œæ³›åŒ–æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†å†…æ ¸é…ç½®ç©ºé—´æŠ½è±¡ä¸º RL ç¯å¢ƒï¼Œåˆ©ç”¨ Large Language Models (LLMs) è¿›è¡Œé«˜æ•ˆæ¢ç´¢ï¼Œå¹¶ç¡®ä¿é…ç½®ä¿®æ”¹çš„å‡†ç¡®æ€§ã€‚ç ”ç©¶è®¾è®¡äº†å®šåˆ¶çš„å¥–åŠ±å‡½æ•°ï¼Œä»¥å¢å¼º LLMs çš„æ¨ç†æ ‡å‡†åŒ–ã€é…ç½®ä¿®æ”¹ç²¾åº¦ä»¥åŠå¯¹ç³»ç»Ÿæ€§èƒ½çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µè®­ç»ƒè¿‡ç¨‹ï¼Œæ—¨åœ¨åŠ é€Ÿæ”¶æ•›å¹¶å‡å°‘ä¸åŒè°ƒä¼˜åœºæ™¯ä¸‹çš„é‡å¤è®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOS-R1 åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ–¹æ³•ï¼Œç›¸æ¯”å¯å‘å¼è°ƒä¼˜å®ç°äº†é«˜è¾¾ 5.6% çš„æ€§èƒ½æå‡ï¼Œå¹¶ä¿æŒäº†è¾ƒé«˜çš„æ•°æ®æ•ˆç‡ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿé€‚åº”å¤šç§çœŸå®ä¸–ç•Œçš„åº”ç”¨åœºæ™¯ï¼Œå±•ç°äº†åœ¨å¤šæ ·åŒ– IT ç¯å¢ƒä¸­è¿›è¡Œå®é™…éƒ¨ç½²çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.OS",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12551v1",
      "published_date": "2025-08-18 01:09:57 UTC",
      "updated_date": "2025-08-18 01:09:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:39:57.555270+00:00"
    },
    {
      "arxiv_id": "2508.14109v1",
      "title": "PAPPL: Personalized AI-Powered Progressive Learning Platform",
      "title_zh": "PAPPLï¼šäººå·¥æ™ºèƒ½é©±åŠ¨çš„ä¸ªæ€§åŒ–æ¸è¿›å¼å­¦ä¹ å¹³å°",
      "authors": [
        "Shayan Bafandkar",
        "Sungyong Chung",
        "Homa Khosravian",
        "Alireza Talebpour"
      ],
      "abstract": "Engineering education has historically been constrained by rigid, standardized frameworks, often neglecting students' diverse learning needs and interests. While significant advancements have been made in online and personalized education within K-12 and foundational sciences, engineering education at both undergraduate and graduate levels continues to lag in adopting similar innovations. Traditional evaluation methods, such as exams and homework assignments, frequently overlook individual student requirements, impeding personalized educational experiences. To address these limitations, this paper introduces the Personalized AI-Powered Progressive Learning (PAPPL) platform, an advanced Intelligent Tutoring System (ITS) designed specifically for engineering education. It highlights the development of a scalable, data-driven tutoring environment leveraging cutting-edge AI technology to enhance personalized learning across diverse academic disciplines, particularly in STEM fields. PAPPL integrates core ITS components including the expert module, student module, tutor module, and user interface, and utilizes GPT-4o, a sophisticated large language model (LLM), to deliver context-sensitive and pedagogically sound hints based on students' interactions. The system uniquely records student attempts, detects recurring misconceptions, and generates progressively targeted feedback, providing personalized assistance that adapts dynamically to each student's learning profile. Additionally, PAPPL offers instructors detailed analytics, empowering evidence-based adjustments to teaching strategies. This study provides a fundamental framework for the progression of Generative ITSs scalable to all education levels, delivering important perspectives on personalized progressive learning and the wider possibilities of Generative AI in the field of education.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå·¥ç¨‹æ•™è‚²ä¸­æ ‡å‡†åŒ–æ¡†æ¶å¿½ç•¥å­¦ç”Ÿä¸ªæ€§åŒ–éœ€æ±‚çš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸ºPAPPLçš„ä¸ªæ€§åŒ–AIé©±åŠ¨è¿›é˜¶å­¦ä¹ å¹³å°ã€‚ä½œä¸ºä¸€ç§ä¸“ä¸ºå·¥ç¨‹å­¦ç§‘è®¾è®¡çš„æ™ºèƒ½å¯¼å¸ˆç³»ç»Ÿï¼ˆIntelligent Tutoring Systemï¼‰ï¼ŒPAPPLé›†æˆäº†ä¸“å®¶ã€å­¦ç”Ÿã€å¯¼å¸ˆæ¨¡å—åŠç”¨æˆ·ç•Œé¢ï¼Œå¹¶åˆ©ç”¨ GPT-4o æ¨¡å‹æ ¹æ®å­¦ç”Ÿäº’åŠ¨æä¾›ä¸Šä¸‹æ–‡æ•æ„Ÿçš„æ•™å­¦æç¤ºã€‚ç³»ç»Ÿèƒ½å¤Ÿè®°å½•å­¦ç”Ÿçš„å°è¯•è¿‡ç¨‹ï¼Œé€šè¿‡æ£€æµ‹é‡å¤å‡ºç°çš„è¯¯åŒºï¼ˆmisconceptionsï¼‰æ¥ç”Ÿæˆé€æ­¥é€’è¿›çš„é’ˆå¯¹æ€§åé¦ˆï¼Œä»è€ŒåŠ¨æ€è°ƒæ•´è¾…åŠ©ç­–ç•¥ä»¥é€‚åº”ä¸åŒçš„å­¦ä¹ æ¦‚å†µã€‚æ­¤å¤–ï¼Œå¹³å°è¿˜ä¸ºæ•™è‚²è€…æä¾›è¯¦ç»†çš„æ•°æ®åˆ†æï¼ŒåŠ©åŠ›å…¶æ ¹æ®è¯æ®è°ƒæ•´æ•™å­¦ç­–ç•¥ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¯æ‰©å±•çš„ç”Ÿæˆå¼æ™ºèƒ½å¯¼å¸ˆç³»ç»Ÿï¼ˆGenerative ITSï¼‰æä¾›äº†åŸºç¡€æ¡†æ¶ï¼Œå±•ç¤ºäº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰åœ¨æ¨åŠ¨ä¸ªæ€§åŒ–è¿›é˜¶å­¦ä¹ åŠæ›´å¹¿æ³›æ•™è‚²é¢†åŸŸä¸­çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14109v1",
      "published_date": "2025-08-18 00:35:24 UTC",
      "updated_date": "2025-08-18 00:35:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:40:02.759244+00:00"
    },
    {
      "arxiv_id": "2508.13234v2",
      "title": "The Role of AI in Facilitating Interdisciplinary Collaboration: Evidence from AlphaFold",
      "title_zh": "äººå·¥æ™ºèƒ½åœ¨ä¿ƒè¿›è·¨å­¦ç§‘åä½œä¸­çš„ä½œç”¨ï¼šæ¥è‡ª AlphaFold çš„è¯æ®",
      "authors": [
        "Naixuan Zhao",
        "Chunli Wei",
        "Xinyan Zhang",
        "Jiang Li"
      ],
      "abstract": "The acceleration of artificial intelligence (AI) in science is recognized and many scholars have begun to explore its role in interdisciplinary collaboration. However, the mechanisms and extent of this impact are still unclear. This study, using AlphaFold's impact on structural biologists, examines how AI technologies influence interdisciplinary collaborative patterns. By analyzing 1,247 AlphaFold-related papers and 7,700 authors from Scopus, we employ bibliometric analysis and causal inference to compare interdisciplinary collaboration between AlphaFold adopters and non-adopters. Contrary to the widespread belief that AI facilitates interdisciplinary collaboration, our findings show that AlphaFold increased structural biology-computer science collaborations by just 0.48%, with no measurable effect on other disciplines. Specifically, AI creates interdisciplinary collaboration demands with specific disciplines due to its technical characteristics, but this demand is weakened by technological democratization and other factors. These findings demonstrate that artificial intelligence (AI) alone has limited efficacy in bridging disciplinary divides or fostering meaningful interdisciplinary collaboration.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)åœ¨ä¿ƒè¿›è·¨å­¦ç§‘åä½œä¸­çš„ä½œç”¨ï¼Œç‰¹åˆ«é€šè¿‡AlphaFoldå¯¹ç»“æ„ç”Ÿç‰©å­¦å®¶çš„å½±å“è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨æ¥è‡ªScopusæ•°æ®åº“çš„1,247ç¯‡ç›¸å…³è®ºæ–‡åŠ7,700åä½œè€…æ•°æ®ï¼Œé‡‡ç”¨æ–‡çŒ®è®¡é‡åˆ†æ(bibliometric analysis)å’Œå› æœæ¨æ–­(causal inference)æ–¹æ³•ï¼Œå¯¹æ¯”äº†AlphaFoldé‡‡ç”¨è€…ä¸éé‡‡ç”¨è€…çš„åä½œæ¨¡å¼ã€‚ç ”ç©¶å‘ç°ï¼ŒAlphaFoldä»…ä½¿ç»“æ„ç”Ÿç‰©å­¦ä¸è®¡ç®—æœºç§‘å­¦ä¹‹é—´çš„åä½œå¢åŠ äº†0.48%ï¼Œè€Œå¯¹å…¶ä»–å­¦ç§‘å¹¶æ— æ˜¾è‘—å½±å“ï¼Œè¿™æŒ‘æˆ˜äº†AIèƒ½å¹¿æ³›ä¿ƒè¿›è·¨å­¦ç§‘åä½œçš„æ™®éè§‚ç‚¹ã€‚å°½ç®¡AIçš„æŠ€æœ¯ç‰¹æ€§ä¼šäº§ç”Ÿç‰¹å®šå­¦ç§‘çš„åä½œéœ€æ±‚ï¼Œä½†è¿™ç§éœ€æ±‚å¾€å¾€è¢«æŠ€æœ¯æ°‘ä¸»åŒ–(technological democratization)ç­‰å› ç´ å‰Šå¼±ã€‚æœ€ç»ˆç ”ç©¶è¡¨æ˜ï¼Œå•çº¯ä¾é AIæŠ€æœ¯åœ¨å¼¥åˆå­¦ç§‘é¸¿æ²Ÿæˆ–æ¨åŠ¨æ·±å±‚æ¬¡è·¨å­¦ç§‘åä½œæ–¹é¢çš„æ•ˆåŠ›ååˆ†æœ‰é™ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.DL",
      "comment": "29pages, 2figures",
      "pdf_url": "https://arxiv.org/pdf/2508.13234v2",
      "published_date": "2025-08-18 00:31:03 UTC",
      "updated_date": "2025-10-27 07:32:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:40:04.353711+00:00"
    },
    {
      "arxiv_id": "2508.12538v1",
      "title": "Systematic Analysis of MCP Security",
      "title_zh": "MCP å®‰å…¨æ€§çš„ç³»ç»Ÿåˆ†æ",
      "authors": [
        "Yongjian Guo",
        "Puzhuo Liu",
        "Wanlun Ma",
        "Zehang Deng",
        "Xiaogang Zhu",
        "Peng Di",
        "Xi Xiao",
        "Sheng Wen"
      ],
      "abstract": "The Model Context Protocol (MCP) has emerged as a universal standard that enables AI agents to seamlessly connect with external tools, significantly enhancing their functionality. However, while MCP brings notable benefits, it also introduces significant vulnerabilities, such as Tool Poisoning Attacks (TPA), where hidden malicious instructions exploit the sycophancy of large language models (LLMs) to manipulate agent behavior. Despite these risks, current academic research on MCP security remains limited, with most studies focusing on narrow or qualitative analyses that fail to capture the diversity of real-world threats. To address this gap, we present the MCP Attack Library (MCPLIB), which categorizes and implements 31 distinct attack methods under four key classifications: direct tool injection, indirect tool injection, malicious user attacks, and LLM inherent attack. We further conduct a quantitative analysis of the efficacy of each attack. Our experiments reveal key insights into MCP vulnerabilities, including agents' blind reliance on tool descriptions, sensitivity to file-based attacks, chain attacks exploiting shared context, and difficulty distinguishing external data from executable commands. These insights, validated through attack experiments, underscore the urgency for robust defense strategies and informed MCP design. Our contributions include 1) constructing a comprehensive MCP attack taxonomy, 2) introducing a unified attack framework MCPLIB, and 3) conducting empirical vulnerability analysis to enhance MCP security mechanisms. This work provides a foundational framework, supporting the secure evolution of MCP ecosystems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Model Context Protocol (MCP)åœ¨AIæ™ºèƒ½ä½“è¿æ¥å¤–éƒ¨å·¥å…·æ—¶å¼•å…¥çš„å®‰å…¨é£é™©è¿›è¡Œäº†ç³»ç»Ÿæ€§åˆ†æï¼ŒæŒ‡å‡ºå…¶é¢ä¸´å¦‚Tool Poisoning Attacks (TPA)ç­‰åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)é¡ºä»æ€§çš„æ¶æ„æ“çºµå¨èƒã€‚é‰´äºç°æœ‰ç ”ç©¶å±€é™äºå®šæ€§åˆ†æä¸”ç¼ºä¹å¤šæ ·æ€§ï¼Œä½œè€…æå‡ºäº†MCP Attack Library (MCPLIB)ï¼Œè¯¥æ¡†æ¶æ¶µç›–äº†direct tool injectionã€indirect tool injectionã€malicious user attackså’ŒLLM inherent attackå››ä¸ªç±»åˆ«çš„31ç§ä¸åŒæ”»å‡»æ–¹æ³•ã€‚é€šè¿‡å®šé‡å®éªŒï¼Œç ”ç©¶æ­ç¤ºäº†æ™ºèƒ½ä½“å¯¹å·¥å…·æè¿°çš„ç›²ç›®ä¾èµ–ã€å¯¹åŸºäºæ–‡ä»¶çš„æ”»å‡»çš„æ•æ„Ÿæ€§ä»¥åŠåœ¨å…±äº«ä¸Šä¸‹æ–‡ä¸­å‘ç”Ÿçš„é“¾å¼æ”»å‡»ç­‰æ ¸å¿ƒæ¼æ´ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ™ºèƒ½ä½“éš¾ä»¥åŒºåˆ†å¤–éƒ¨æ•°æ®ä¸å¯æ‰§è¡ŒæŒ‡ä»¤ï¼Œå‡¸æ˜¾äº†æ„å»ºé²æ£’é˜²å¾¡ç­–ç•¥å’Œä¼˜åŒ–MCPè®¾è®¡çš„ç´§è¿«æ€§ã€‚æœ¬å·¥ä½œé€šè¿‡æ„å»ºå…¨é¢çš„æ”»å‡»åˆ†ç±»ä½“ç³»ã€å‘å¸ƒMCPLIBç»Ÿä¸€æ”»å‡»æ¡†æ¶ä»¥åŠè¿›è¡Œå®è¯æ¼æ´åˆ†æï¼Œä¸ºMCPç”Ÿæ€ç³»ç»Ÿçš„å®‰å…¨æ¼”è¿›æä¾›äº†åŸºç¡€æ€§æ¡†æ¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.12538v1",
      "published_date": "2025-08-18 00:23:41 UTC",
      "updated_date": "2025-08-18 00:23:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:40:20.473957+00:00"
    },
    {
      "arxiv_id": "2508.14107v1",
      "title": "SuryaBench: Benchmark Dataset for Advancing Machine Learning in Heliophysics and Space Weather Prediction",
      "title_zh": "SuryaBenchï¼šæ¨åŠ¨å¤ªé˜³ç‰©ç†å­¦ä¸ç©ºé—´å¤©æ°”é¢„æŠ¥é¢†åŸŸæœºå™¨å­¦ä¹ å‘å±•çš„åŸºå‡†æ•°æ®é›†",
      "authors": [
        "Sujit Roy",
        "Dinesha V. Hegde",
        "Johannes Schmude",
        "Amy Lin",
        "Vishal Gaur",
        "Rohit Lal",
        "Kshitiz Mandal",
        "Talwinder Singh",
        "AndrÃ©s MuÃ±oz-Jaramillo",
        "Kang Yang",
        "Chetraj Pandey",
        "Jinsu Hong",
        "Berkay Aydin",
        "Ryan McGranaghan",
        "Spiridon Kasapis",
        "Vishal Upendran",
        "Shah Bahauddin",
        "Daniel da Silva",
        "Marcus Freitag",
        "Iksha Gurung",
        "Nikolai Pogorelov",
        "Campbell Watson",
        "Manil Maskey",
        "Juan Bernabe-Moreno",
        "Rahul Ramachandran"
      ],
      "abstract": "This paper introduces a high resolution, machine learning-ready heliophysics dataset derived from NASA's Solar Dynamics Observatory (SDO), specifically designed to advance machine learning (ML) applications in solar physics and space weather forecasting. The dataset includes processed imagery from the Atmospheric Imaging Assembly (AIA) and Helioseismic and Magnetic Imager (HMI), spanning a solar cycle from May 2010 to July 2024. To ensure suitability for ML tasks, the data has been preprocessed, including correction of spacecraft roll angles, orbital adjustments, exposure normalization, and degradation compensation. We also provide auxiliary application benchmark datasets complementing the core SDO dataset. These provide benchmark applications for central heliophysics and space weather tasks such as active region segmentation, active region emergence forecasting, coronal field extrapolation, solar flare prediction, solar EUV spectra prediction, and solar wind speed estimation. By establishing a unified, standardized data collection, this dataset aims to facilitate benchmarking, enhance reproducibility, and accelerate the development of AI-driven models for critical space weather prediction tasks, bridging gaps between solar physics, machine learning, and operational forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† SuryaBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæºè‡ª NASA å¤ªé˜³åŠ¨åŠ›å­¦å¤©æ–‡å° (SDO) çš„é«˜åˆ†è¾¨ç‡ã€æœºå™¨å­¦ä¹ å°±ç»ª (machine learning-ready) çš„æ—¥åœ°ç‰©ç†æ•°æ®é›†ï¼Œæ—¨åœ¨æ¨åŠ¨ Heliophysics å’Œ Space Weather Prediction é¢†åŸŸçš„æœºå™¨å­¦ä¹ åº”ç”¨ã€‚è¯¥æ•°æ®é›†åŒ…å«äº†æ¥è‡ª Atmospheric Imaging Assembly (AIA) å’Œ Helioseismic and Magnetic Imager (HMI) çš„å¤„ç†å›¾åƒï¼Œæ—¶é—´è·¨åº¦è¦†ç›–äº†ä» 2010 å¹´ 5 æœˆè‡³ 2024 å¹´ 7 æœˆçš„ä¸€ä¸ªå®Œæ•´å¤ªé˜³å‘¨æœŸã€‚ä¸ºäº†ç¡®ä¿æ•°æ®é€‚ç”¨äºæœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œç ”ç©¶è€…è¿›è¡Œäº†èˆªå¤©å™¨ä¾§å€¾è§’æ ¡æ­£ã€è½¨é“è°ƒæ•´ã€æ›å…‰å½’ä¸€åŒ–å’Œé€€åŒ–è¡¥å¿ç­‰é¢„å¤„ç†ã€‚æ­¤å¤–ï¼ŒSuryaBench è¿˜æä¾›äº†é’ˆå¯¹ active region segmentationã€solar flare prediction å’Œ solar wind speed estimation ç­‰æ ¸å¿ƒä»»åŠ¡çš„åŸºå‡†æµ‹è¯•åº”ç”¨ã€‚è¯¥æ•°æ®é›†é€šè¿‡å»ºç«‹ç»Ÿä¸€ã€æ ‡å‡†åŒ–çš„æ•°æ®é‡‡é›†ä½“ç³»ï¼Œæ—¨åœ¨ä¿ƒè¿› Benchmarking å¹¶æé«˜ç ”ç©¶çš„å¯é‡å¤æ€§ï¼Œä»è€ŒåŠ é€Ÿ AI é©±åŠ¨æ¨¡å‹åœ¨å…³é”®ç©ºé—´å¤©æ°”é¢„æŠ¥ä»»åŠ¡ä¸­çš„å¼€å‘ï¼Œå¼¥åˆæ—¥åœ°ç‰©ç†å­¦ä¸ä¸šåŠ¡åŒ–é¢„æŠ¥ä¹‹é—´çš„é¸¿æ²Ÿã€‚",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14107v1",
      "published_date": "2025-08-18 00:05:01 UTC",
      "updated_date": "2025-08-18 00:05:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:40:21.858118+00:00"
    },
    {
      "arxiv_id": "2508.12535v2",
      "title": "CorrSteer: Generation-Time LLM Steering via Correlated Sparse Autoencoder Features",
      "title_zh": "CorrSteerï¼šåŸºäºå…³è”ç¨€ç–è‡ªç¼–ç å™¨ç‰¹å¾çš„ç”Ÿæˆæ—¶å¤§è¯­è¨€æ¨¡å‹å¼•å¯¼",
      "authors": [
        "Seonglae Cho",
        "Zekun Wu",
        "Adriano Koshiyama"
      ],
      "abstract": "Sparse Autoencoders (SAEs) can extract interpretable features from large language models (LLMs) without supervision. However, their effectiveness in downstream steering tasks is limited by the requirement for contrastive datasets or large activation storage. To address these limitations, we propose CorrSteer, which selects features by correlating sample correctness with SAE activations from generated tokens at inference time. This approach uses only inference-time activations to extract more relevant features, thereby reducing spurious correlations. It also obtains steering coefficients from average activations, automating the entire pipeline. Our method shows improved task performance on QA, bias mitigation, jailbreaking prevention, and reasoning benchmarks on Gemma-2 2B and LLaMA-3.1 8B, notably achieving a +3.3% improvement in MMLU performance with 4000 samples and a +27.2% improvement in HarmBench with only 108 samples. Selected features demonstrate semantically meaningful patterns aligned with each task's requirements, revealing the underlying capabilities that drive performance. Our work establishes correlation-based selection as an effective and scalable approach for automated SAE steering across language model applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CorrSteerï¼Œä¸€ç§é€šè¿‡ç›¸å…³ç¨€ç–è‡ªç¼–ç å™¨ (Sparse Autoencoders, SAEs) ç‰¹å¾åœ¨ç”Ÿæˆé˜¶æ®µå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) è¿›è¡Œå¼•å¯¼çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æŠ€æœ¯å¯¹å¯¹æ¯”æ•°æ®é›†æˆ–å¤§è§„æ¨¡æ¿€æ´»å­˜å‚¨çš„ä¾èµ–ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨æ¨ç†é˜¶æ®µå°†æ ·æœ¬æ­£ç¡®æ€§ä¸ç”Ÿæˆ token çš„ SAE æ¿€æ´»åº¦è¿›è¡Œå…³è”æ¥ç­›é€‰ç‰¹å¾ï¼Œä»è€Œæœ‰æ•ˆå‡å°‘ä¼ªç›¸å…³å¹¶æå–æ›´ç›¸å…³çš„å…³é”®ç‰¹å¾ã€‚CorrSteer èƒ½å¤Ÿä»å¹³å‡æ¿€æ´»å€¼ä¸­è‡ªåŠ¨è·å–å¼•å¯¼ç³»æ•°ï¼Œå®ç°äº†æ•´ä¸ªå¼•å¯¼æµç¨‹çš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–ã€‚åœ¨ Gemma-2 2B å’Œ LLaMA-3.1 8B ä¸Šçš„æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨é—®ç­” (QA)ã€åè§æ¶ˆé™¤ã€é˜²è¶Šç‹±åŠæ¨ç†ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡æœ‰æ˜¾è‘—æå‡ã€‚å…·ä½“è€Œè¨€ï¼ŒCorrSteer åœ¨ MMLU æ€§èƒ½ä¸Šæé«˜äº† 3.3%ï¼Œå¹¶åœ¨æå°‘æ ·æœ¬é‡ä¸‹å°† HarmBench çš„è¡¨ç°æå‡äº† 27.2%ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†æ‰€é€‰ç‰¹å¾åœ¨è¯­ä¹‰ä¸Šä¸ä»»åŠ¡éœ€æ±‚é«˜åº¦ä¸€è‡´ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–å¼•å¯¼æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "42 pages, 9 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.12535v2",
      "published_date": "2025-08-18 00:01:42 UTC",
      "updated_date": "2025-10-17 22:57:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T12:40:24.993162+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 133,
  "processed_papers_count": 133,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T12:41:17.936247+00:00"
}