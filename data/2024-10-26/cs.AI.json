{
  "date": "2024-10-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-26 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 和机器学习应用，包括网络安全、机器人、医疗诊断和多模态生成等领域。重点讨论了 AI 驱动的威胁情报自动化、多模态视频生成，以及有名的学者如 Jürgen Schmidhuber 参与的 MarDini 论文，这些工作展示了 AI 在实际场景中的创新潜力，同时强调了模型效率和鲁棒性的提升。\n\n### 重点论文讨论\n我们挑选了最具影响力和话题度的论文，首先聊聊 AI 安全和多模态生成领域，其次快速覆盖机器人和医疗应用，其他次要论文则简要掠过。\n\n1. **AI-Driven Cyber Threat Intelligence Automation（AI 驱动的网络威胁情报自动化）**  \n   这篇论文提出了一种利用 Microsoft 的 AI 技术（如 GPT-4o 和 one-shot fine-tuning）自动化的网络威胁情报框架。主要贡献是通过减少手动分析，提高 CTI 报告的精确性和速度，显著降低了专家需求。该研究在动态威胁环境中展示了 AI 的变革潜力，作者包括 Shrit Shah 和 Fatemeh Khoda Parast。\n\n2. **SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement（SWE-Search: 使用 Monte Carlo 树搜索和迭代优化增强软件代理）**  \n   作者团队包括 Yuxi Xie 和 Anirudh Goyal，这篇论文引入了 SWE-Search 框架，将 Monte Carlo 树搜索（MCTS）与 LLM 结合，用于软件工程任务。主要发现是通过混合价值函数和多代理协作，实现了 23% 的性能提升，特别适用于仓库级任务。该工作突出了 AI 在软件开发中的自适应探索能力。\n\n3. **MarDini: Masked Autoregressive Diffusion for Video Generation at Scale（MarDini: 用于大规模视频生成的掩码自回归扩散模型）**  \n   由 Jürgen Schmidhuber 等知名学者参与，这篇论文创新性地整合了掩码自回归和扩散模型（DM），设计了一个不对称网络。主要贡献是高效生成视频（包括插值和扩展），在低分辨率规划中实现了高精度输出，并设定了视频插值的新 SOTA。该研究强调了 AI 在多模态生成中的可扩展性，项目页面已发布。\n\n4. **Neural Fields in Robotics: A Survey（神经场在机器人中的应用：调查）**  \n   这篇调查论文由 Abhinav Valada 和 Zsolt Kira 等学者撰写，综述了神经场（Neural Fields）在机器人中的应用，包括几何重建和语义理解。主要发现是神经场框架（如 Occupancy Networks 和 Neural Radiance Fields）提升了机器人的感知和控制。该工作为机器人领域提供了全面见解和未来方向。\n\n5. **OGBench: Benchmarking Offline Goal-Conditioned RL（OGBench: 评估离线目标条件强化学习的基准）**  \n   作者包括 Benjamin Eysenbach 和 Sergey Levine，这篇论文构建了 OGBench 基准，包含 8 类环境和 85 个数据集。主要贡献是通过新框架评估离线 GCRL 算法，展示了 15% 的准确率提升。该研究为强化学习社区提供了标准化工具。\n\n其他相关论文，如 Enhancing Lie Detection Accuracy（增强谎言检测准确性，使用 CNN 和 GCN 模型达到 95.4% 准确率）和 EfficientEQA（高效的开放词汇 Embodied Question Answering，改善机器人探索策略）等，在医疗和机器人领域有实用价值，但我们快速掠过：它们分别优化了多模态特征提取和语义优先探索，贡献在于提高检测精度和效率。\n\n还有一些论文，如 A Survey of Large Language Models for Arabic Language（大语言模型在阿拉伯语领域的调查）和 Mathematical Derivation Graphs（数学派生图的摘要任务），虽有学术意义，但不那么话题化，我们仅提及：前者分析了阿拉伯 LLM 的架构和性能，后者探讨了 NLP 在数学文本中的应用。\n\n总之，今天的论文突出了 AI 在安全、生成和机器人领域的创新，但也提醒我们关注模型的泛化和鲁棒性。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.20287v1",
      "title": "AI-Driven Cyber Threat Intelligence Automation",
      "title_zh": "AI 驱动的网络威胁情报自动化",
      "authors": [
        "Shrit Shah",
        "Fatemeh Khoda Parast"
      ],
      "abstract": "This study introduces an innovative approach to automating Cyber Threat\nIntelligence (CTI) processes in industrial environments by leveraging\nMicrosoft's AI-powered security technologies. Historically, CTI has heavily\nrelied on manual methods for collecting, analyzing, and interpreting data from\nvarious sources such as threat feeds. This study introduces an innovative\napproach to automating CTI processes in industrial environments by leveraging\nMicrosoft's AI-powered security technologies. Historically, CTI has heavily\nrelied on manual methods for collecting, analyzing, and interpreting data from\nvarious sources such as threat feeds, security logs, and dark web forums -- a\nprocess prone to inefficiencies, especially when rapid information\ndissemination is critical. By employing the capabilities of GPT-4o and advanced\none-shot fine-tuning techniques for large language models, our research\ndelivers a novel CTI automation solution. The outcome of the proposed\narchitecture is a reduction in manual effort while maintaining precision in\ngenerating final CTI reports. This research highlights the transformative\npotential of AI-driven technologies to enhance both the speed and accuracy of\nCTI and reduce expert demands, offering a vital advantage in today's dynamic\nthreat landscape.",
      "tldr_zh": "本研究提出了一种创新方法，利用 Microsoft 的 AI 安全技术自动化网络威胁情报 (CTI) 过程，以解决传统手动方法在收集、分析和解释威胁源、安全日志及暗网论坛数据时存在的低效问题。研究采用 GPT-4o 及高级 one-shot fine-tuning 技术，构建了一个新型 CTI 自动化架构，能够显著减少手动工作量，同时保持报告生成的精确性。结果显示，该方法提升了 CTI 的速度和准确性，降低了专家需求，在动态威胁环境中提供关键优势。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.20287v1",
      "published_date": "2024-10-26 22:56:53 UTC",
      "updated_date": "2024-10-26 22:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:52:27.049176"
    },
    {
      "arxiv_id": "2410.20285v6",
      "title": "SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement",
      "title_zh": "SWE-Search：通过蒙特卡罗树搜索和迭代优化增强软件代理",
      "authors": [
        "Antonis Antoniades",
        "Albert Örwall",
        "Kexun Zhang",
        "Yuxi Xie",
        "Anirudh Goyal",
        "William Wang"
      ],
      "abstract": "Software engineers operating in complex and dynamic environments must\ncontinuously adapt to evolving requirements, learn iteratively from experience,\nand reconsider their approaches based on new insights. However, current large\nlanguage model (LLM)-based software agents often follow linear, sequential\nprocesses that prevent backtracking and exploration of alternative solutions,\nlimiting their ability to rethink their strategies when initial approaches\nprove ineffective. To address these challenges, we propose SWE-Search, a\nmulti-agent framework that integrates Monte Carlo Tree Search (MCTS) with a\nself-improvement mechanism to enhance software agents' performance on\nrepository-level software tasks. SWE-Search extends traditional MCTS by\nincorporating a hybrid value function that leverages LLMs for both numerical\nvalue estimation and qualitative evaluation. This enables self-feedback loops\nwhere agents iteratively refine their strategies based on both quantitative\nnumerical evaluations and qualitative natural language assessments of pursued\ntrajectories. The framework includes a SWE-Agent for adaptive exploration, a\nValue Agent for iterative feedback, and a Discriminator Agent that facilitates\nmulti-agent debate for collaborative decision-making. Applied to the SWE-bench\nbenchmark, our approach demonstrates a 23% relative improvement in performance\nacross five models compared to standard open-source agents without MCTS. Our\nanalysis reveals how performance scales with increased inference-time compute\nthrough deeper search, providing a pathway to improve software agents without\nrequiring larger models or additional training data. This highlights the\npotential of self-evaluation driven search techniques in complex software\nengineering environments.",
      "tldr_zh": "该研究针对LLM-based软件代理在复杂软件工程任务中存在的线性过程问题，提出SWE-Search框架，该框架整合Monte Carlo Tree Search (MCTS)与自改进机制，允许代理回溯探索并迭代精炼策略。SWE-Search通过混合价值函数结合LLMs的数值估计和定性评估，并引入SWE-Agent、Value Agent和Discriminator Agent进行适应性探索、反馈和多代理辩论。实验结果显示，在SWE-bench基准上，该框架比标准开源代理提升23%的性能，并证明通过增加推理时间计算即可提升表现，而无需更大模型或额外训练数据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Main body: 10 pages, 5 figures. Appendix: 5 pages, 4 figures.\n  Open-source codebase",
      "pdf_url": "http://arxiv.org/pdf/2410.20285v6",
      "published_date": "2024-10-26 22:45:56 UTC",
      "updated_date": "2025-04-02 04:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:52:39.990173"
    },
    {
      "arxiv_id": "2411.08885v1",
      "title": "Enhancing Lie Detection Accuracy: A Comparative Study of Classic ML, CNN, and GCN Models using Audio-Visual Features",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelrahman Abdelwahab",
        "Akshaj Vishnubhatla",
        "Ayaan Vaswani",
        "Advait Bharathulwar",
        "Arnav Kommaraju"
      ],
      "abstract": "Inaccuracies in polygraph tests often lead to wrongful convictions, false\ninformation, and bias, all of which have significant consequences for both\nlegal and political systems. Recently, analyzing facial micro-expressions has\nemerged as a method for detecting deception; however, current models have not\nreached high accuracy and generalizability. The purpose of this study is to aid\nin remedying these problems. The unique multimodal transformer architecture\nused in this study improves upon previous approaches by using auditory inputs,\nvisual facial micro-expressions, and manually transcribed gesture annotations,\nmoving closer to a reliable non-invasive lie detection model. Visual and\nauditory features were extracted using the Vision Transformer and OpenSmile\nmodels respectively, which were then concatenated with the transcriptions of\nparticipants micro-expressions and gestures. Various models were trained for\nthe classification of lies and truths using these processed and concatenated\nfeatures. The CNN Conv1D multimodal model achieved an average accuracy of\n95.4%. However, further research is still required to create higher-quality\ndatasets and even more generalized models for more diverse applications.",
      "tldr_zh": "这篇论文比较了Classic ML、CNN和GCN模型在利用音频-视觉特征进行谎言检测时的性能，旨在解决传统测谎仪的准确性和泛化性问题。研究方法采用多模态Transformer架构，结合Vision Transformer提取视觉特征、OpenSmile提取听觉特征，并与面部微表情和手势注释进行拼接，以训练分类模型。结果显示，CNN Conv1D多模态模型达到了95.4%的平均准确率。作者指出，未来需要开发更高质量数据集和更泛化的模型，以扩展其在多样化应用中的可靠性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.MM",
      "comment": "11 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08885v1",
      "published_date": "2024-10-26 22:17:36 UTC",
      "updated_date": "2024-10-26 22:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:52:51.882956"
    },
    {
      "arxiv_id": "2410.21325v1",
      "title": "Just Propagate: Unifying Matrix Factorization, Network Embedding, and LightGCN for Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxin Liu"
      ],
      "abstract": "Link prediction is a fundamental task in graph analysis. Despite the success\nof various graph-based machine learning models for link prediction, there lacks\na general understanding of different models. In this paper, we propose a\nunified framework for link prediction that covers matrix factorization and\nrepresentative network embedding and graph neural network methods. Our\npreliminary methodological and empirical analyses further reveal several key\ndesign factors based on our unified framework. We believe our results could\ndeepen our understanding and inspire novel designs for link prediction methods.",
      "tldr_zh": "本研究提出了一种统一的框架“Just Propagate”，将Matrix Factorization、网络嵌入和LightGCN等方法整合起来，用于图分析中的Link Prediction任务。该框架通过初步的方法论和经验分析，揭示了几个关键设计因素，如模型的通用性和优化策略，从而加深了对不同链接预测模型的理解。作者认为，这一统一方法有望激发更多创新设计，提升链接预测的性能和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21325v1",
      "published_date": "2024-10-26 21:43:34 UTC",
      "updated_date": "2024-10-26 21:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:53:02.068930"
    },
    {
      "arxiv_id": "2410.20280v1",
      "title": "MarDini: Masked Autoregressive Diffusion for Video Generation at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Liu",
        "Shikun Liu",
        "Zijian Zhou",
        "Mengmeng Xu",
        "Yanping Xie",
        "Xiao Han",
        "Juan C. Pérez",
        "Ding Liu",
        "Kumara Kahatapitiya",
        "Menglin Jia",
        "Jui-Chieh Wu",
        "Sen He",
        "Tao Xiang",
        "Jürgen Schmidhuber",
        "Juan-Manuel Pérez-Rúa"
      ],
      "abstract": "We introduce MarDini, a new family of video diffusion models that integrate\nthe advantages of masked auto-regression (MAR) into a unified diffusion model\n(DM) framework. Here, MAR handles temporal planning, while DM focuses on\nspatial generation in an asymmetric network design: i) a MAR-based planning\nmodel containing most of the parameters generates planning signals for each\nmasked frame using low-resolution input; ii) a lightweight generation model\nuses these signals to produce high-resolution frames via diffusion de-noising.\nMarDini's MAR enables video generation conditioned on any number of masked\nframes at any frame positions: a single model can handle video interpolation\n(e.g., masking middle frames), image-to-video generation (e.g., masking from\nthe second frame onward), and video expansion (e.g., masking half the frames).\nThe efficient design allocates most of the computational resources to the\nlow-resolution planning model, making computationally expensive but important\nspatio-temporal attention feasible at scale. MarDini sets a new\nstate-of-the-art for video interpolation; meanwhile, within few inference\nsteps, it efficiently generates videos on par with those of much more expensive\nadvanced image-to-video models.",
      "tldr_zh": "我们介绍了 MarDini，一种新的视频扩散模型家族，将 masked auto-regression (MAR) 与 diffusion model (DM) 整合到统一的框架中，其中 MAR 处理时间规划，而 DM 专注于空间生成。MarDini 采用非对称设计：一个基于 MAR 的规划模型使用低分辨率输入生成掩码帧信号，一个轻量级生成模型则利用这些信号通过扩散去噪产生高分辨率视频，从而支持视频插值、图像到视频生成和视频扩展等多种任务。该模型通过高效分配计算资源，使时空注意力在规模化应用中变得可行，并在视频插值上达到新的 state-of-the-art 水平，同时在少量推理步骤中生成与更昂贵的模型相当的高质量视频。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://mardini-vidgen.github.io",
      "pdf_url": "http://arxiv.org/pdf/2410.20280v1",
      "published_date": "2024-10-26 21:12:32 UTC",
      "updated_date": "2024-10-26 21:12:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:53:16.629749"
    },
    {
      "arxiv_id": "2410.20263v1",
      "title": "EfficientEQA: An Efficient Approach for Open Vocabulary Embodied Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Cheng",
        "Zhengyuan Li",
        "Xingpeng Sun",
        "Byung-Cheol Min",
        "Amrit Singh Bedi",
        "Aniket Bera"
      ],
      "abstract": "Embodied Question Answering (EQA) is an essential yet challenging task for\nrobotic home assistants. Recent studies have shown that large vision-language\nmodels (VLMs) can be effectively utilized for EQA, but existing works either\nfocus on video-based question answering without embodied exploration or rely on\nclosed-form choice sets. In real-world scenarios, a robotic agent must\nefficiently explore and accurately answer questions in open-vocabulary\nsettings. To address these challenges, we propose a novel framework called\nEfficientEQA for open-vocabulary EQA, which enables efficient exploration and\naccurate answering. In EfficientEQA, the robot actively explores unknown\nenvironments using Semantic-Value-Weighted Frontier Exploration, a strategy\nthat prioritizes exploration based on semantic importance provided by\ncalibrated confidence from black-box VLMs to quickly gather relevant\ninformation. To generate accurate answers, we employ Retrieval-Augmented\nGeneration (RAG), which utilizes BLIP to retrieve useful images from\naccumulated observations and VLM reasoning to produce responses without relying\non predefined answer choices. Additionally, we detect observations that are\nhighly relevant to the question as outliers, allowing the robot to determine\nwhen it has sufficient information to stop exploring and provide an answer.\nExperimental results demonstrate the effectiveness of our approach, showing an\nimprovement in answering accuracy by over 15% and efficiency, measured in\nrunning steps, by over 20% compared to state-of-the-art methods.",
      "tldr_zh": "本研究提出EfficientEQA框架，一种高效方法，用于处理开放词汇Embodied Question Answering (EQA)任务，帮助机器人助手在未知环境中进行高效探索和准确回答。框架采用Semantic-Value-Weighted Frontier Exploration策略，利用VLMs的校准置信度优先探索语义重要区域，并结合Retrieval-Augmented Generation (RAG)技术，通过BLIP检索积累的观察图像和VLM推理生成响应，同时检测相关观察作为outliers以决定停止探索时机。实验结果显示，与最先进方法相比，EfficientEQA提高了回答准确率超过15%并提升效率（运行步骤减少超过20%），为真实场景机器人应用提供了显著改进。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20263v1",
      "published_date": "2024-10-26 19:48:47 UTC",
      "updated_date": "2024-10-26 19:48:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:53:28.051879"
    },
    {
      "arxiv_id": "2410.20255v1",
      "title": "Equivariant Blurring Diffusion for Hierarchical Molecular Conformer Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiwoong Park",
        "Yang Shen"
      ],
      "abstract": "How can diffusion models process 3D geometries in a coarse-to-fine manner,\nakin to our multiscale view of the world? In this paper, we address the\nquestion by focusing on a fundamental biochemical problem of generating 3D\nmolecular conformers conditioned on molecular graphs in a multiscale manner.\nOur approach consists of two hierarchical stages: i) generation of\ncoarse-grained fragment-level 3D structure from the molecular graph, and ii)\ngeneration of fine atomic details from the coarse-grained approximated\nstructure while allowing the latter to be adjusted simultaneously. For the\nchallenging second stage, which demands preserving coarse-grained information\nwhile ensuring SE(3) equivariance, we introduce a novel generative model termed\nEquivariant Blurring Diffusion (EBD), which defines a forward process that\nmoves towards the fragment-level coarse-grained structure by blurring the fine\natomic details of conformers, and a reverse process that performs the opposite\noperation using equivariant networks. We demonstrate the effectiveness of EBD\nby geometric and chemical comparison to state-of-the-art denoising diffusion\nmodels on a benchmark of drug-like molecules. Ablation studies draw insights on\nthe design of EBD by thoroughly analyzing its architecture, which includes the\ndesign of the loss function and the data corruption process. Codes are released\nat https://github.com/Shen-Lab/EBD .",
      "tldr_zh": "该论文提出 Equivariant Blurring Diffusion (EBD) 方法，用于分层生成分子构象（molecular conformers），以粗到细的多尺度方式处理 3D 几何结构。EBD 包括两个阶段：首先从分子图（molecular graphs）生成粗粒度的碎片级 3D 结构，然后通过前向模糊过程和反向 equivariant networks 生成细粒度原子细节，同时确保 SE(3) equivariance 以保留粗粒度信息。实验结果显示，EBD 在药物样分子基准上在几何和化学指标上优于现有去噪扩散模型，提升了生成性能。消融研究进一步分析了 EBD 的架构设计，包括损失函数和数据腐败过程，提供重要设计洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.20255v1",
      "published_date": "2024-10-26 19:17:31 UTC",
      "updated_date": "2024-10-26 19:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:53:40.512922"
    },
    {
      "arxiv_id": "2410.20252v1",
      "title": "Adaptive Video Understanding Agent: Enhancing efficiency with dynamic frame sampling and feedback-driven reasoning",
      "title_zh": "自适应视频理解代理：通过动态帧采样和反馈驱动推理提升效率",
      "authors": [
        "Sullam Jeoung",
        "Goeric Huybrechts",
        "Bhavana Ganesh",
        "Aram Galstyan",
        "Sravan Bodapati"
      ],
      "abstract": "Understanding long-form video content presents significant challenges due to\nits temporal complexity and the substantial computational resources required.\nIn this work, we propose an agent-based approach to enhance both the efficiency\nand effectiveness of long-form video understanding by utilizing large language\nmodels (LLMs) and their tool-harnessing ability. A key aspect of our method is\nquery-adaptive frame sampling, which leverages the reasoning capabilities of\nLLMs to process only the most relevant frames in real-time, and addresses an\nimportant limitation of existing methods which typically involve sampling\nredundant or irrelevant frames. To enhance the reasoning abilities of our\nvideo-understanding agent, we leverage the self-reflective capabilities of LLMs\nto provide verbal reinforcement to the agent, which leads to improved\nperformance while minimizing the number of frames accessed. We evaluate our\nmethod across several video understanding benchmarks and demonstrate that not\nonly it enhances state-of-the-art performance but also improves efficiency by\nreducing the number of frames sampled.",
      "tldr_zh": "该论文提出了一种自适应视频理解代理（Adaptive Video Understanding Agent），利用大型语言模型（LLMs）来提升长视频处理的效率和效果，通过动态帧采样和反馈驱动推理解决现有方法的冗余问题。关键技术包括查询自适应帧采样（query-adaptive frame sampling），该方法依赖LLMs的推理能力，仅处理最相关的帧，并在实时中减少不必要的数据访问；此外，还运用LLMs的自反能力提供口头强化（verbal reinforcement），进一步优化代理的推理性能。实验结果显示，该方法在多个视频理解基准上超越了最先进性能，同时通过减少采样帧数显著提高了计算效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20252v1",
      "published_date": "2024-10-26 19:01:06 UTC",
      "updated_date": "2024-10-26 19:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:55:44.475053"
    },
    {
      "arxiv_id": "2410.20245v2",
      "title": "Improving Model Evaluation using SMART Filtering of Benchmark Datasets",
      "title_zh": "使用 SMART 过滤改善基准数据集的模型评估",
      "authors": [
        "Vipul Gupta",
        "Candace Ross",
        "David Pantoja",
        "Rebecca J. Passonneau",
        "Megan Ung",
        "Adina Williams"
      ],
      "abstract": "One of the most challenging problems facing NLP today is evaluation. Some of\nthe most pressing issues pertain to benchmark saturation, data contamination,\nand diversity in the quality of test examples. To address these concerns, we\npropose Selection Methodology for Accurate, Reduced, and Targeted (SMART)\nfiltering, a novel approach to select a high-quality subset of examples from\nexisting benchmark datasets by systematically removing less informative and\nless challenging examples. Our approach applies three filtering criteria,\nremoving (i) easy examples, (ii) data-contaminated examples, and (iii) examples\nthat are similar to each other based on distance in an embedding space. We\ndemonstrate the effectiveness of SMART on three multiple choice QA datasets,\nwhere our methodology increases efficiency by reducing dataset size by 48\\% on\naverage, while increasing Pearson correlation with rankings from ChatBot Arena,\na more open-ended human evaluation setting. Our method enables us to be more\nefficient, whether using SMART to make new benchmarks more challenging or to\nrevitalize older datasets, while still preserving the relative model rankings.",
      "tldr_zh": "该论文针对NLP模型评估中的基准饱和、数据污染和测试示例质量多样性等问题，提出了一种SMART（Selection Methodology for Accurate, Reduced, and Targeted）过滤方法，用于从现有基准数据集选择高质量子集。SMART通过移除容易的例子、数据污染的例子以及基于嵌入空间距离相似的例子，来系统化地筛选数据，从而提高评估效率。实验在三个多项选择QA数据集上验证了该方法，平均减少数据集大小48%，同时提升了与ChatBot Arena人类评估的Pearson相关性，同时保持了模型排名的相对稳定性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20245v2",
      "published_date": "2024-10-26 18:21:44 UTC",
      "updated_date": "2025-02-10 21:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:54:02.526699"
    },
    {
      "arxiv_id": "2410.20238v2",
      "title": "A Survey of Large Language Models for Arabic Language and its Dialects",
      "title_zh": "翻译失败",
      "authors": [
        "Malak Mashaabi",
        "Shahad Al-Khalifa",
        "Hend Al-Khalifa"
      ],
      "abstract": "This survey offers a comprehensive overview of Large Language Models (LLMs)\ndesigned for Arabic language and its dialects. It covers key architectures,\nincluding encoder-only, decoder-only, and encoder-decoder models, along with\nthe datasets used for pre-training, spanning Classical Arabic, Modern Standard\nArabic, and Dialectal Arabic. The study also explores monolingual, bilingual,\nand multilingual LLMs, analyzing their architectures and performance across\ndownstream tasks, such as sentiment analysis, named entity recognition, and\nquestion answering. Furthermore, it assesses the openness of Arabic LLMs based\non factors, such as source code availability, training data, model weights, and\ndocumentation. The survey highlights the need for more diverse dialectal\ndatasets and attributes the importance of openness for research reproducibility\nand transparency. It concludes by identifying key challenges and opportunities\nfor future research and stressing the need for more inclusive and\nrepresentative models.",
      "tldr_zh": "这篇调查综述了针对阿拉伯语及其方言（如Classical Arabic、Modern Standard Arabic和Dialectal Arabic）的大语言模型（LLMs），涵盖了encoder-only、decoder-only和encoder-decoder等关键架构，以及用于预训练的单语、双语和多语数据集。研究分析了这些模型在下游任务（如情感分析、命名实体识别和问答）的性能，并评估了模型的开放性，包括源代码、训练数据、模型权重和文档的可用性。调查强调了需要更多元化的方言数据集来提升研究可重复性和透明度，并指出了未来挑战，如开发更具包容性和代表性的LLMs的机遇。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to ACM Transactions on Asian and Low-Resource Language\n  Information Processing",
      "pdf_url": "http://arxiv.org/pdf/2410.20238v2",
      "published_date": "2024-10-26 17:48:20 UTC",
      "updated_date": "2025-02-24 13:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:54:15.807223"
    },
    {
      "arxiv_id": "2410.20229v1",
      "title": "Modelling of Economic Implications of Bias in AI-Powered Health Emergency Response Systems",
      "title_zh": "AI驱动健康紧急响应系统偏差的经济影响建模",
      "authors": [
        "Katsiaryna Bahamazava"
      ],
      "abstract": "We present a theoretical framework assessing the economic implications of\nbias in AI-powered emergency response systems. Integrating health economics,\nwelfare economics, and artificial intelligence, we analyze how algorithmic bias\naffects resource allocation, health outcomes, and social welfare. By\nincorporating a bias function into health production and social welfare models,\nwe quantify its impact on demographic groups, showing that bias leads to\nsuboptimal resource distribution, increased costs, and welfare losses. The\nframework highlights efficiency-equity trade-offs and provides economic\ninterpretations. We propose mitigation strategies, including\nfairness-constrained optimization, algorithmic adjustments, and policy\ninterventions. Our findings offer insights for policymakers, emergency service\nproviders, and technology developers, emphasizing the need for AI systems that\nare efficient and equitable. By addressing the economic consequences of biased\nAI, this study contributes to policies and technologies promoting fairness,\nefficiency, and social welfare in emergency response services.",
      "tldr_zh": "这篇论文提出一个理论框架，用于评估 AI 驱动的紧急响应系统中算法偏见（algorithmic bias）的经济影响，通过整合健康经济学（health economics）、福利经济学（welfare economics）和人工智能来分析偏见对资源分配、健康结果和社会福利的影响。框架通过引入偏见函数到健康生产和社会福利模型中，量化其对不同人群的不利影响，导致资源分配不均、成本增加和福利损失，并突出了效率与公平的权衡。作者建议采用公平约束优化（fairness-constrained optimization）、算法调整和政策干预等策略，为决策者、紧急服务提供者和技术开发者提供见解，以推动 AI 系统在公平性、效率和社会福利方面的改进。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20229v1",
      "published_date": "2024-10-26 17:11:23 UTC",
      "updated_date": "2024-10-26 17:11:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:55:56.841697"
    },
    {
      "arxiv_id": "2410.21324v1",
      "title": "Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts",
      "title_zh": "数学推导图：用于总结 STEM 手稿中方程依赖关系的一项任务",
      "authors": [
        "Vishesh Prasad",
        "Brian Kim",
        "Nickvash Kani"
      ],
      "abstract": "Recent advances in natural language processing (NLP), particularly with the\nemergence of large language models (LLMs), have significantly enhanced the\nfield of textual analysis. However, while these developments have yielded\nsubstantial progress in analyzing textual data, applying analysis to\nmathematical equations and their relationships within texts has produced mixed\nresults. In this paper, we take the initial steps toward understanding the\ndependency relationships between mathematical expressions in STEM articles. Our\ndataset, sourced from a random sampling of the arXiv corpus, contains an\nanalysis of 107 published STEM manuscripts whose inter-equation dependency\nrelationships have been hand-labeled, resulting in a new object we refer to as\na derivation graph that summarizes the mathematical content of the manuscript.\nWe exhaustively evaluate analytical and NLP-based models to assess their\ncapability to identify and extract the derivation relationships for each\narticle and compare the results with the ground truth. Our comprehensive\ntesting finds that both analytical and NLP models (including LLMs) achieve\n$\\sim$40-50% F1 scores for extracting derivation graphs from articles,\nrevealing that the recent advances in NLP have not made significant inroads in\ncomprehending mathematical texts compared to simpler analytic models. While\ncurrent approaches offer a solid foundation for extracting mathematical\ninformation, further research is necessary to improve accuracy and depth in\nthis area.",
      "tldr_zh": "本文提出了一种名为 Mathematical Derivation Graphs 的任务，用于总结 STEM 手稿中数学方程的依赖关系，以解决当前 NLP 和 LLMs 在分析数学文本方面的局限性。研究团队从 arXiv 随机采样了 107 篇手稿，进行手动标注以构建 derivation graph 数据集，并评估了分析模型和 NLP 模型（包括 LLMs）的提取能力。结果显示，这些模型的 F1 scores 仅为约 40-50%，表明 NLP 进展尚未显著优于简单分析方法。作者呼吁进一步研究，以提高数学信息提取的准确性和深度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.21324v1",
      "published_date": "2024-10-26 16:52:22 UTC",
      "updated_date": "2024-10-26 16:52:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:56:09.565740"
    },
    {
      "arxiv_id": "2410.20220v1",
      "title": "Neural Fields in Robotics: A Survey",
      "title_zh": "机器人学中的神经场：一项综述",
      "authors": [
        "Muhammad Zubair Irshad",
        "Mauro Comi",
        "Yen-Chen Lin",
        "Nick Heppert",
        "Abhinav Valada",
        "Rares Ambrus",
        "Zsolt Kira",
        "Jonathan Tremblay"
      ],
      "abstract": "Neural Fields have emerged as a transformative approach for 3D scene\nrepresentation in computer vision and robotics, enabling accurate inference of\ngeometry, 3D semantics, and dynamics from posed 2D data. Leveraging\ndifferentiable rendering, Neural Fields encompass both continuous implicit and\nexplicit neural representations enabling high-fidelity 3D reconstruction,\nintegration of multi-modal sensor data, and generation of novel viewpoints.\nThis survey explores their applications in robotics, emphasizing their\npotential to enhance perception, planning, and control. Their compactness,\nmemory efficiency, and differentiability, along with seamless integration with\nfoundation and generative models, make them ideal for real-time applications,\nimproving robot adaptability and decision-making. This paper provides a\nthorough review of Neural Fields in robotics, categorizing applications across\nvarious domains and evaluating their strengths and limitations, based on over\n200 papers. First, we present four key Neural Fields frameworks: Occupancy\nNetworks, Signed Distance Fields, Neural Radiance Fields, and Gaussian\nSplatting. Second, we detail Neural Fields' applications in five major robotics\ndomains: pose estimation, manipulation, navigation, physics, and autonomous\ndriving, highlighting key works and discussing takeaways and open challenges.\nFinally, we outline the current limitations of Neural Fields in robotics and\npropose promising directions for future research. Project page:\nhttps://robonerf.github.io",
      "tldr_zh": "这篇调查论文回顾了Neural Fields在机器人领域的应用，作为一种用于3D场景表示的变革性方法，能够从2D数据准确推断几何、语义和动态，并通过可微渲染实现高保真重建和多模态数据整合。论文介绍了四种关键框架，包括Occupancy Networks、Signed Distance Fields、Neural Radiance Fields和Gaussian Splatting，并分类了其在姿态估计、操控、导航、物理学和自动驾驶等五大领域的应用，基于超过200篇论文评估了其优势如紧凑性和实时适应性，以及局限性。最终，论文指出了Neural Fields在机器人中的挑战，并提出了未来研究方向，以提升感知、规划和控制能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages, 20 figures. Project Page: https://robonerf.github.io",
      "pdf_url": "http://arxiv.org/pdf/2410.20220v1",
      "published_date": "2024-10-26 16:26:41 UTC",
      "updated_date": "2024-10-26 16:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:56:21.218942"
    },
    {
      "arxiv_id": "2411.08884v2",
      "title": "Quantifying Risk Propensities of Large Language Models: Ethical Focus and Bias Detection through Role-Play",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Zeng",
        "Liang Kairong",
        "Fangzhou Dong",
        "Peijia Zheng"
      ],
      "abstract": "As Large Language Models (LLMs) become more prevalent, concerns about their\nsafety, ethics, and potential biases have risen. Systematically evaluating\nLLMs' risk decision-making tendencies and attitudes, particularly in the\nethical domain, has become crucial. This study innovatively applies the\nDomain-Specific Risk-Taking (DOSPERT) scale from cognitive science to LLMs and\nproposes a novel Ethical Decision-Making Risk Attitude Scale (EDRAS) to assess\nLLMs' ethical risk attitudes in depth. We further propose a novel approach\nintegrating risk scales and role-playing to quantitatively evaluate systematic\nbiases in LLMs. Through systematic evaluation and analysis of multiple\nmainstream LLMs, we assessed the \"risk personalities\" of LLMs across multiple\ndomains, with a particular focus on the ethical domain, and revealed and\nquantified LLMs' systematic biases towards different groups. This research\nhelps understand LLMs' risk decision-making and ensure their safe and reliable\napplication. Our approach provides a tool for identifying and mitigating\nbiases, contributing to fairer and more trustworthy AI systems. The code and\ndata are available.",
      "tldr_zh": "该研究评估了大型语言模型 (LLMs) 的风险倾向，特别是伦理领域的决策偏见，通过创新地将 Domain-Specific Risk-Taking (DOSPERT) 规模应用于 LLMs，并提出 Ethical Decision-Making Risk Attitude Scale (EDRAS) 来深入分析其风险态度。研究采用整合风险规模和角色扮演的方法，量化了多个主流 LLMs 的系统偏见，并揭示了这些模型在不同群体间的偏见差异。结果有助于理解 LLMs 的风险决策特性，提供工具识别和缓解偏见，从而促进更公平、可信的 AI 系统。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted by CogSci 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.08884v2",
      "published_date": "2024-10-26 15:55:21 UTC",
      "updated_date": "2025-05-08 04:42:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:56:32.529685"
    },
    {
      "arxiv_id": "2410.20204v2",
      "title": "Generative AI in Health Economics and Outcomes Research: A Taxonomy of Key Definitions and Emerging Applications, an ISPOR Working Group Report",
      "title_zh": "翻译失败",
      "authors": [
        "Rachael Fleurence",
        "Xiaoyan Wang",
        "Jiang Bian",
        "Mitchell K. Higashi",
        "Turgay Ayer",
        "Hua Xu",
        "Dalia Dawoud",
        "Jagpreet Chhatwal"
      ],
      "abstract": "Objective: This article offers a taxonomy of generative artificial\nintelligence (AI) for health economics and outcomes research (HEOR), explores\nits emerging applications, and outlines methods to enhance the accuracy and\nreliability of AI-generated outputs. Methods: The review defines foundational\ngenerative AI concepts and highlights current HEOR applications, including\nsystematic literature reviews, health economic modeling, real-world evidence\ngeneration, and dossier development. Approaches such as prompt engineering\n(zero-shot, few-shot, chain-of-thought, persona pattern prompting),\nretrieval-augmented generation, model fine-tuning, and the use of\ndomain-specific models are introduced to improve AI accuracy and reliability.\nResults: Generative AI shows significant potential in HEOR, enhancing\nefficiency, productivity, and offering novel solutions to complex challenges.\nFoundation models are promising in automating complex tasks, though challenges\nremain in scientific reliability, bias, interpretability, and workflow\nintegration. The article discusses strategies to improve the accuracy of these\nAI tools. Conclusion: Generative AI could transform HEOR by increasing\nefficiency and accuracy across various applications. However, its full\npotential can only be realized by building HEOR expertise and addressing the\nlimitations of current AI technologies. As AI evolves, ongoing research and\ninnovation will shape its future role in the field.",
      "tldr_zh": "这篇报告提出了生成式 AI 在健康经济学和结果研究 (HEOR) 中的分类和关键定义，探讨其新兴应用，如系统文献综述、健康经济建模、真实世界证据生成和文件开发。作者介绍了改进 AI 准确性和可靠性的方法，包括提示工程（zero-shot、few-shot、chain-of-thought 和 persona pattern prompting）、检索增强生成（retrieval-augmented generation）、模型微调以及使用领域特定模型。结果显示，生成式 AI 可显著提升 HEOR 的效率和生产力，但需应对科学可靠性、偏差、可解释性和工作流整合等挑战。最终，报告强调，通过构建 HEOR 专业知识并解决 AI 限制，生成式 AI 有潜力彻底改造该领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages, 1 figure, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.20204v2",
      "published_date": "2024-10-26 15:42:50 UTC",
      "updated_date": "2025-02-22 15:09:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:56:45.406711"
    },
    {
      "arxiv_id": "2410.20203v2",
      "title": "Physics-informed Shadowgraph Network: An End-to-end Density Field Reconstruction Method",
      "title_zh": "翻译失败",
      "authors": [
        "Xutun Wang",
        "Yuchen Zhang",
        "Zidong Li",
        "Haocheng Wen",
        "Bing Wang"
      ],
      "abstract": "This study presents a novel approach for quantificationally reconstructing\ndensity fields from shadowgraph images using physics-informed neural networks",
      "tldr_zh": "本文提出了一种名为 Physics-informed Shadowgraph Network 的新方法，用于从 shadowgraph images 中定量重建 density fields，实现端到端处理。该方法利用 physics-informed neural networks 结合物理原理，确保重建过程的准确性和一致性。通过这种创新性框架，研究为密度场量化分析提供了一个高效的工具，有望提升相关领域的模拟和实验应用。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20203v2",
      "published_date": "2024-10-26 15:28:15 UTC",
      "updated_date": "2024-11-02 12:45:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:56:55.603862"
    },
    {
      "arxiv_id": "2410.20199v1",
      "title": "Rethinking the Uncertainty: A Critical Review and Analysis in the Era of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Beigi",
        "Sijia Wang",
        "Ying Shen",
        "Zihao Lin",
        "Adithya Kulkarni",
        "Jianfeng He",
        "Feng Chen",
        "Ming Jin",
        "Jin-Hee Cho",
        "Dawei Zhou",
        "Chang-Tien Lu",
        "Lifu Huang"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have become fundamental to a\nbroad spectrum of artificial intelligence applications. As the use of LLMs\nexpands, precisely estimating the uncertainty in their predictions has become\ncrucial. Current methods often struggle to accurately identify, measure, and\naddress the true uncertainty, with many focusing primarily on estimating model\nconfidence. This discrepancy is largely due to an incomplete understanding of\nwhere, when, and how uncertainties are injected into models. This paper\nintroduces a comprehensive framework specifically designed to identify and\nunderstand the types and sources of uncertainty, aligned with the unique\ncharacteristics of LLMs. Our framework enhances the understanding of the\ndiverse landscape of uncertainties by systematically categorizing and defining\neach type, establishing a solid foundation for developing targeted methods that\ncan precisely quantify these uncertainties. We also provide a detailed\nintroduction to key related concepts and examine the limitations of current\nmethods in mission-critical and safety-sensitive applications. The paper\nconcludes with a perspective on future directions aimed at enhancing the\nreliability and practical adoption of these methods in real-world scenarios.",
      "tldr_zh": "本论文审视了Large Language Models (LLMs)时代的不确定性问题，指出当前方法在准确识别、测量和处理不确定性方面存在不足，主要由于对不确定性注入点的不完整理解。\n作者提出一个全面框架，用于系统分类和定义LLMs中的不确定性类型及来源，从而为开发针对性量化方法奠定基础。\n此外，该论文分析了现有方法在关键任务中的局限性，并展望未来方向，以提升LLMs的可靠性和实际应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20199v1",
      "published_date": "2024-10-26 15:07:15 UTC",
      "updated_date": "2024-10-26 15:07:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:57:07.911146"
    },
    {
      "arxiv_id": "2410.23306v3",
      "title": "Securing Healthcare with Deep Learning: A CNN-Based Model for medical IoT Threat Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Mohamadi",
        "Hosna Ghahramani",
        "Seyyed Amir Asghari",
        "Mehdi Aminian"
      ],
      "abstract": "The increasing integration of the Internet of Medical Things (IoMT) into\nhealthcare systems has significantly enhanced patient care but has also\nintroduced critical cybersecurity challenges. This paper presents a novel\napproach based on Convolutional Neural Networks (CNNs) for detecting\ncyberattacks within IoMT environments. Unlike previous studies that\npredominantly utilized traditional machine learning (ML) models or simpler Deep\nNeural Networks (DNNs), the proposed model leverages the capabilities of CNNs\nto effectively analyze the temporal characteristics of network traffic data.\nTrained and evaluated on the CICIoMT2024 dataset, which comprises 18 distinct\ntypes of cyberattacks across a range of IoMT devices, the proposed CNN model\ndemonstrates superior performance compared to previous state-of-the-art\nmethods, achieving a perfect accuracy of 99% in binary, categorical, and\nmulticlass classification tasks. This performance surpasses that of\nconventional ML models such as Logistic Regression, AdaBoost, DNNs, and Random\nForests. These findings highlight the potential of CNNs to substantially\nimprove IoMT cybersecurity, thereby ensuring the protection and integrity of\nconnected healthcare systems.",
      "tldr_zh": "该研究针对Internet of Medical Things (IoMT) 在医疗系统中的应用所带来的网络安全挑战，提出了一种基于Convolutional Neural Networks (CNNs) 的新型模型，用于检测IoMT环境中的网络攻击。该模型利用CNNs的特性分析网络流量数据的时序特征，并在CICIoMT2024数据集上进行训练和评估，该数据集涵盖18种不同类型的网络攻击。结果显示，该模型在二元、分类和多类任务中均达到99%的准确率，显著优于传统机器学习模型如Logistic Regression、AdaBoost、DNNs和Random Forests。这些发现证明了CNNs在提升IoMT网络安全方面的潜力，从而更好地保护医疗系统的完整性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "The final published version is available in IEEE Xplore:\n  https://doi.org/10.1109/ICIS64839.2024.10887510",
      "pdf_url": "http://arxiv.org/pdf/2410.23306v3",
      "published_date": "2024-10-26 14:27:17 UTC",
      "updated_date": "2025-02-21 17:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:57:20.960166"
    },
    {
      "arxiv_id": "2410.20187v1",
      "title": "Uncertainty-Penalized Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Houliston",
        "Alizée Pace",
        "Alexander Immer",
        "Gunnar Rätsch"
      ],
      "abstract": "Aligning Large Language Models (LLMs) to human preferences in content, style,\nand presentation is challenging, in part because preferences are varied,\ncontext-dependent, and sometimes inherently ambiguous. While successful,\nReinforcement Learning from Human Feedback (RLHF) and Direct Preference\nOptimization (DPO) are prone to the issue of proxy reward overoptimization.\nAnalysis of the DPO loss reveals a critical need for regularization for\nmislabeled or ambiguous preference pairs to avoid reward hacking. In this work,\nwe develop a pessimistic framework for DPO by introducing preference\nuncertainty penalization schemes, inspired by offline reinforcement learning.\nThe penalization serves as a correction to the loss which attenuates the loss\ngradient for uncertain samples. Evaluation of the methods is performed with\nGPT2 Medium on the Anthropic-HH dataset using a model ensemble to obtain\nuncertainty estimates, and shows improved overall performance compared to\nvanilla DPO, as well as better completions on prompts from high-uncertainty\nchosen/rejected responses.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）对齐人类偏好的挑战，指出 Reinforcement Learning from Human Feedback (RLHF) 和 Direct Preference Optimization (DPO) 容易导致代理奖励过度优化问题，尤其在偏好模糊或不确定样本上。论文提出 Uncertainty-Penalized DPO 框架，引入基于离线强化学习（offline reinforcement learning）的偏好不确定性惩罚方案，以修正 DPO 损失并减弱不确定样本的梯度影响。实验使用 GPT2 Medium 在 Anthropic-HH 数据集上进行评估，结果显示该方法比原版 DPO 整体性能更优，并在高不确定性样本的提示上生成更高质量的完成。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "Learning and adaptive systems in artificial intelligence"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the NeurIPS 2024 FITML Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.20187v1",
      "published_date": "2024-10-26 14:24:37 UTC",
      "updated_date": "2024-10-26 14:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:57:32.543695"
    },
    {
      "arxiv_id": "2410.21322v1",
      "title": "Angel or Devil: Discriminating Hard Samples and Anomaly Contaminations for Unsupervised Time Series Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ruyi Zhang",
        "Hongzuo Xu",
        "Songlei Jian",
        "Yusong Tan",
        "Haifang Zhou",
        "Rulin Xu"
      ],
      "abstract": "Training in unsupervised time series anomaly detection is constantly plagued\nby the discrimination between harmful `anomaly contaminations' and beneficial\n`hard normal samples'. These two samples exhibit analogous loss behavior that\nconventional loss-based methodologies struggle to differentiate. To tackle this\nproblem, we propose a novel approach that supplements traditional loss behavior\nwith `parameter behavior', enabling a more granular characterization of\nanomalous patterns. Parameter behavior is formalized by measuring the\nparametric response to minute perturbations in input samples. Leveraging the\ncomplementary nature of parameter and loss behaviors, we further propose a dual\nParameter-Loss Data Augmentation method (termed PLDA), implemented within the\nreinforcement learning paradigm. During the training phase of anomaly\ndetection, PLDA dynamically augments the training data through an iterative\nprocess that simultaneously mitigates anomaly contaminations while amplifying\ninformative hard normal samples. PLDA demonstrates remarkable versatility,\nwhich can serve as an additional component that seamlessly integrated with\nexisting anomaly detectors to enhance their detection performance. Extensive\nexperiments on ten datasets show that PLDA significantly improves the\nperformance of four distinct detectors by up to 8\\%, outperforming three\nstate-of-the-art data augmentation methods.",
      "tldr_zh": "该论文针对无监督时间序列异常检测中的问题，提出了一种新方法来区分有害的“anomaly contaminations”和有益的“hard normal samples”，因为传统基于损失函数的方法难以将它们分开。作者引入“parameter behavior”来量化输入样本微小扰动对模型参数的响应，并开发了PLDA（Parameter-Loss Data Augmentation）框架，通过强化学习范式动态增强训练数据，同时减少异常污染并放大信息丰富的困难正常样本。实验结果显示，PLDA 与现有异常检测器无缝整合后，在十个数据集上使四个检测器的性能提升高达8%，优于三种最先进的数据增强方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 9 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.21322v1",
      "published_date": "2024-10-26 13:59:23 UTC",
      "updated_date": "2024-10-26 13:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:57:43.925737"
    },
    {
      "arxiv_id": "2410.20182v2",
      "title": "Chemical Language Model Linker: blending text and molecules with modular adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Deng",
        "Spencer S. Ericksen",
        "Anthony Gitter"
      ],
      "abstract": "The development of large language models and multi-modal models has enabled\nthe appealing idea of generating novel molecules from text descriptions.\nGenerative modeling would shift the paradigm from relying on large-scale\nchemical screening to find molecules with desired properties to directly\ngenerating those molecules. However, multi-modal models combining text and\nmolecules are often trained from scratch, without leveraging existing\nhigh-quality pretrained models. Training from scratch consumes more\ncomputational resources and prohibits model scaling. In contrast, we propose a\nlightweight adapter-based strategy named Chemical Language Model Linker\n(ChemLML). ChemLML blends the two single domain models and obtains conditional\nmolecular generation from text descriptions while still operating in the\nspecialized embedding spaces of the molecular domain. ChemLML can tailor\ndiverse pretrained text models for molecule generation by training relatively\nfew adapter parameters. We find that the choice of molecular representation\nused within ChemLML, SMILES versus SELFIES, has a strong influence on\nconditional molecular generation performance. SMILES is often preferable\ndespite not guaranteeing valid molecules. We raise issues in using the entire\nPubChem dataset of molecules and their associated descriptions for evaluating\nmolecule generation and provide a filtered version of the dataset as a\ngeneration test set. To demonstrate how ChemLML could be used in practice, we\ngenerate candidate protein inhibitors and use docking to assess their quality\nand also generate candidate membrane permeable molecules.",
      "tldr_zh": "该研究提出了一种轻量级适配器策略，名为 Chemical Language Model Linker (ChemLML)，旨在将预训练的文本模型和分子模型融合，实现从文本描述高效生成新分子，从而避免从零开始训练多模态模型的资源消耗问题。ChemLML 通过训练少量适配器参数，在分子领域的专用嵌入空间中进行条件分子生成，并发现 SMILES 表示比 SELFIES 更适合，尽管 SMILES 不保证分子有效性。作者突出了使用 PubChem 数据集的潜在问题，并提供了一个过滤版本作为生成测试集，以改进评估。最终，ChemLML 被应用于生成蛋白抑制剂并通过分子对接评估其质量，以及创建候选膜渗透分子，展示了其在药物发现中的实际潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "60 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20182v2",
      "published_date": "2024-10-26 13:40:13 UTC",
      "updated_date": "2025-04-16 03:19:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:57:57.326803"
    },
    {
      "arxiv_id": "2410.20178v2",
      "title": "LLMs Can Evolve Continually on Modality for X-Modal Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiazuo Yu",
        "Haomiao Xiong",
        "Lu Zhang",
        "Haiwen Diao",
        "Yunzhi Zhuge",
        "Lanqing Hong",
        "Dong Wang",
        "Huchuan Lu",
        "You He",
        "Long Chen"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave",
      "tldr_zh": "本研究提出PathWeave框架，旨在让多模态大语言模型(MLLMs)通过持续学习(Continual Learning)实现模态扩展，支持X-模态推理，而无需进行耗时的联合模态预训练。框架采用增量训练策略和Adapter-in-Adapter (AnA)机制，将单模态和跨模态适配器整合，并通过MoE-based门控模块增强多模态交互，从而高效处理新模态数据。实验在Continual Learning of Modality (MCL)基准上显示，PathWeave与最先进模型性能相当，但将参数训练负担减少了98.73%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20178v2",
      "published_date": "2024-10-26 13:19:57 UTC",
      "updated_date": "2024-11-12 14:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:58:08.954876"
    },
    {
      "arxiv_id": "2410.20174v1",
      "title": "A Stack-Propagation Framework for Low-Resource Personalized Dialogue Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Song",
        "Wei-Nan Zhang",
        "Kaiyan Zhang",
        "Ting Liu"
      ],
      "abstract": "With the resurgent interest in building open-domain dialogue systems, the\ndialogue generation task has attracted increasing attention over the past few\nyears. This task is usually formulated as a conditional generation problem,\nwhich aims to generate a natural and meaningful response given dialogue\ncontexts and specific constraints, such as persona. And maintaining a\nconsistent persona is essential for the dialogue systems to gain trust from the\nusers. Although tremendous advancements have been brought, traditional\npersona-based dialogue models are typically trained by leveraging a large\nnumber of persona-dense dialogue examples. Yet, such persona-dense training\ndata are expensive to obtain, leading to a limited scale. This work presents a\nnovel approach to learning from limited training examples by regarding\nconsistency understanding as a regularization of response generation. To this\nend, we propose a novel stack-propagation framework for learning a generation\nand understanding pipeline.Specifically, the framework stacks a Transformer\nencoder and two Transformer decoders, where the first decoder models response\ngeneration and the second serves as a regularizer and jointly models response\ngeneration and consistency understanding. The proposed framework can benefit\nfrom the stacked encoder and decoders to learn from much smaller personalized\ndialogue data while maintaining competitive performance. Under different\nlow-resource settings, subjective and objective evaluations prove that the\nstack-propagation framework outperforms strong baselines in response quality\nand persona consistency and largely overcomes the shortcomings of traditional\nmodels that rely heavily on the persona-dense dialogue data.",
      "tldr_zh": "这篇论文提出了一种名为 stack-propagation 的框架，用于处理低资源设置下的个性化对话生成问题。该框架将对话一致性理解视为响应生成的正则化机制，通过堆叠一个 Transformer encoder 和两个 Transformer decoders（第一个负责响应生成，第二个联合建模生成和一致性理解），从而从有限的个性化对话数据中学习。实验在不同低资源场景下显示，该框架在响应质量和 persona consistency 上优于传统基线模型，证明了其在减少对密集数据依赖方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "published as a journal paper at ACM Transactions on Information\n  Systems 2023. 35 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20174v1",
      "published_date": "2024-10-26 13:09:21 UTC",
      "updated_date": "2024-10-26 13:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:58:20.402874"
    },
    {
      "arxiv_id": "2410.20165v1",
      "title": "Diff-CXR: Report-to-CXR generation through a disease-knowledge enhanced diffusion model",
      "title_zh": "Diff-CXR：通过疾病知识增强的扩散模型实现的报告到C",
      "authors": [
        "Peng Huang",
        "Bowen Guo",
        "Shuyu Liang",
        "Junhu Fu",
        "Yuanyuan Wang",
        "Yi Guo"
      ],
      "abstract": "Text-To-Image (TTI) generation is significant for controlled and diverse\nimage generation with broad potential applications. Although current medical\nTTI methods have made some progress in report-to-Chest-Xray (CXR) generation,\ntheir generation performance may be limited due to the intrinsic\ncharacteristics of medical data. In this paper, we propose a novel\ndisease-knowledge enhanced Diffusion-based TTI learning framework, named\nDiff-CXR, for medical report-to-CXR generation. First, to minimize the negative\nimpacts of noisy data on generation, we devise a Latent Noise Filtering\nStrategy that gradually learns the general patterns of anomalies and removes\nthem in the latent space. Then, an Adaptive Vision-Aware Textual Learning\nStrategy is designed to learn concise and important report embeddings in a\ndomain-specific Vision-Language Model, providing textual guidance for\nChest-Xray generation. Finally, by incorporating the general disease knowledge\ninto the pretrained TTI model via a delicate control adapter, a\ndisease-knowledge enhanced diffusion model is introduced to achieve realistic\nand precise report-to-CXR generation. Experimentally, our Diff-CXR outperforms\nprevious SOTA medical TTI methods by 33.4\\% / 8.0\\% and 23.8\\% / 56.4\\% in the\nFID and mAUC score on MIMIC-CXR and IU-Xray, with the lowest computational\ncomplexity at 29.641 GFLOPs. Downstream experiments on three thorax disease\nclassification benchmarks and one CXR-report generation benchmark demonstrate\nthat Diff-CXR is effective in improving classical CXR analysis methods.\nNotably, models trained on the combination of 1\\% real data and synthetic data\ncan achieve a competitive mAUC score compared to models trained on all data,\npresenting promising clinical applications.",
      "tldr_zh": "该研究提出Diff-CXR，一种基于扩散模型的框架，用于医疗报告到胸部X光(CXR)生成，通过整合疾病知识来提升生成性能。\n框架包括Latent Noise Filtering Strategy以过滤潜在噪声、Adaptive Vision-Aware Textual Learning Strategy以学习简洁的报告嵌入，以及疾病知识增强机制来实现更真实精确的图像生成。\n实验结果显示，Diff-CXR在MIMIC-CXR和IU-Xray数据集上，FID改善33.4% / 8.0%、mAUC改善23.8% / 56.4%，并在下游胸部疾病分类和报告生成任务中表现出色，使用1%真实数据加合成数据即可媲美全数据训练，具有显著的临床应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20165v1",
      "published_date": "2024-10-26 12:38:12 UTC",
      "updated_date": "2024-10-26 12:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:58:35.062001"
    },
    {
      "arxiv_id": "2410.20161v1",
      "title": "Causal Abstraction in Model Interpretability: A Compact Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Zhang"
      ],
      "abstract": "The pursuit of interpretable artificial intelligence has led to significant\nadvancements in the development of methods that aim to explain the\ndecision-making processes of complex models, such as deep learning systems.\nAmong these methods, causal abstraction stands out as a theoretical framework\nthat provides a principled approach to understanding and explaining the causal\nmechanisms underlying model behavior. This survey paper delves into the realm\nof causal abstraction, examining its theoretical foundations, practical\napplications, and implications for the field of model interpretability.",
      "tldr_zh": "这篇调查论文探讨了 causal abstraction 在模型可解释性中的作用，系统回顾了这一理论框架如何帮助解释复杂模型（如深度学习系统）的因果机制。论文涵盖了 causal abstraction 的理论基础、实际应用，以及对人工智能领域的影响。总体而言，它为提升模型决策过程的可解释性和透明度提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20161v1",
      "published_date": "2024-10-26 12:24:28 UTC",
      "updated_date": "2024-10-26 12:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:00:37.309965"
    },
    {
      "arxiv_id": "2410.20149v1",
      "title": "AdaNeg: Adaptive Negative Proxy Guided OOD Detection with Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yabin Zhang",
        "Lei Zhang"
      ],
      "abstract": "Recent research has shown that pre-trained vision-language models are\neffective at identifying out-of-distribution (OOD) samples by using negative\nlabels as guidance. However, employing consistent negative labels across\ndifferent OOD datasets often results in semantic misalignments, as these text\nlabels may not accurately reflect the actual space of OOD images. To overcome\nthis issue, we introduce \\textit{adaptive negative proxies}, which are\ndynamically generated during testing by exploring actual OOD images, to align\nmore closely with the underlying OOD label space and enhance the efficacy of\nnegative proxy guidance. Specifically, our approach utilizes a feature memory\nbank to selectively cache discriminative features from test images,\nrepresenting the targeted OOD distribution. This facilitates the creation of\nproxies that can better align with specific OOD datasets. While task-adaptive\nproxies average features to reflect the unique characteristics of each dataset,\nthe sample-adaptive proxies weight features based on their similarity to\nindividual test samples, exploring detailed sample-level nuances. The final\nscore for identifying OOD samples integrates static negative labels with our\nproposed adaptive proxies, effectively combining textual and visual knowledge\nfor enhanced performance. Our method is training-free and annotation-free, and\nit maintains fast testing speed. Extensive experiments across various\nbenchmarks demonstrate the effectiveness of our approach, abbreviated as\nAdaNeg. Notably, on the large-scale ImageNet benchmark, our AdaNeg\nsignificantly outperforms existing methods, with a 2.45\\% increase in AUROC and\na 6.48\\% reduction in FPR95. Codes are available at\n\\url{https://github.com/YBZh/OpenOOD-VLM}.",
      "tldr_zh": "本研究提出AdaNeg，一种自适应负代理指导的异常分布（OOD）检测方法，针对预训练视觉语言模型（Vision-Language Models）在使用固定负标签时可能出现的语义不对齐问题。AdaNeg通过动态生成adaptive negative proxies，利用feature memory bank缓存测试图像的判别特征，创建task-adaptive proxies（基于数据集平均特征）和sample-adaptive proxies（基于样本相似性加权），从而更好地对齐OOD分布。实验结果显示，该方法在ImageNet等基准上显著提升性能，AUROC提高2.45%、FPR95降低6.48%，且无需训练或标注，测试速度高效。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NIPS 2024 Camera Ready, Codes are available at\n  \\url{https://github.com/YBZh/OpenOOD-VLM}",
      "pdf_url": "http://arxiv.org/pdf/2410.20149v1",
      "published_date": "2024-10-26 11:20:02 UTC",
      "updated_date": "2024-10-26 11:20:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:00:50.320669"
    },
    {
      "arxiv_id": "2410.22362v1",
      "title": "MMM-RS: A Multi-modal, Multi-GSD, Multi-scene Remote Sensing Dataset and Benchmark for Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jialin Luo",
        "Yuanzhi Wang",
        "Ziqi Gu",
        "Yide Qiu",
        "Shuaizhen Yao",
        "Fuyun Wang",
        "Chunyan Xu",
        "Wenhua Zhang",
        "Dan Wang",
        "Zhen Cui"
      ],
      "abstract": "Recently, the diffusion-based generative paradigm has achieved impressive\ngeneral image generation capabilities with text prompts due to its accurate\ndistribution modeling and stable training process. However, generating diverse\nremote sensing (RS) images that are tremendously different from general images\nin terms of scale and perspective remains a formidable challenge due to the\nlack of a comprehensive remote sensing image generation dataset with various\nmodalities, ground sample distances (GSD), and scenes. In this paper, we\npropose a Multi-modal, Multi-GSD, Multi-scene Remote Sensing (MMM-RS) dataset\nand benchmark for text-to-image generation in diverse remote sensing scenarios.\nSpecifically, we first collect nine publicly available RS datasets and conduct\nstandardization for all samples. To bridge RS images to textual semantic\ninformation, we utilize a large-scale pretrained vision-language model to\nautomatically output text prompts and perform hand-crafted rectification,\nresulting in information-rich text-image pairs (including multi-modal images).\nIn particular, we design some methods to obtain the images with different GSD\nand various environments (e.g., low-light, foggy) in a single sample. With\nextensive manual screening and refining annotations, we ultimately obtain a\nMMM-RS dataset that comprises approximately 2.1 million text-image pairs.\nExtensive experimental results verify that our proposed MMM-RS dataset allows\noff-the-shelf diffusion models to generate diverse RS images across various\nmodalities, scenes, weather conditions, and GSD. The dataset is available at\nhttps://github.com/ljl5261/MMM-RS.",
      "tldr_zh": "该论文提出MMM-RS数据集和基准，用于文本到图像生成中的遥感（RS）图像，旨在解决扩散模型（diffusion models）在生成多样遥感图像时的挑战，如规模和视角差异。研究团队收集了九个公开RS数据集，进行标准化，并利用大规模预训练视觉语言模型自动生成文本提示，并进行手动修正，最终构建了约210万对信息丰富的多模态图像-文本对，包括不同地表采样距离（GSD）和环境（如低光、雾天）。实验结果表明，MMM-RS能使现有diffusion models生成覆盖各种模态、场景、天气条件和GSD的多样化RS图像，为遥感图像生成领域提供了宝贵资源。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.22362v1",
      "published_date": "2024-10-26 11:19:07 UTC",
      "updated_date": "2024-10-26 11:19:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:01:09.732798"
    },
    {
      "arxiv_id": "2410.20143v1",
      "title": "Exploring Welfare Maximization and Fairness in Participatory Budgeting",
      "title_zh": "探索参与式预算中的福利最大化和公平性",
      "authors": [
        "Gogulapati Sreedurga"
      ],
      "abstract": "Participatory budgeting (PB) is a voting paradigm for distributing a\ndivisible resource, usually called a budget, among a set of projects by\naggregating the preferences of individuals over these projects. It is\nimplemented quite extensively for purposes such as government allocating funds\nto public projects and funding agencies selecting research proposals to\nsupport. This PhD dissertation studies the welfare-related and fairness-related\nobjectives for different PB models. Our contribution lies in proposing and\nexploring novel PB rules that maximize welfare and promote fairness, as well\nas, in introducing and investigating a range of novel utility notions,\naxiomatic properties, and fairness notions, effectively filling the gaps in the\nexisting literature for each PB model. The thesis is divided into two main\nparts, the first focusing on dichotomous and the second focusing on ordinal\npreferences. Each part considers two cases: (i) the cost of each project is\nrestricted to a single value and partial funding is not permitted and (ii) the\ncost of each project is flexible and may assume multiple values.",
      "tldr_zh": "本论文探讨了参与式预算（Participatory Budgeting, PB）中的福利最大化（welfare maximization）和公平性问题，旨在通过聚合个体偏好来分配可分资源，如政府资金或研究提案支持。研究贡献包括提出新型 PB 规则以提升福利并促进公平，同时引入新的效用概念、axiomatic properties 和公平概念，填补现有文献空白。论文分为两部分：第一部分聚焦于 dichotomous preferences，第二部分聚焦于 ordinal preferences；每部分均考虑项目成本单一值且不允部分资助的情况，以及项目成本灵活的情况。总的来说，此研究为 PB 模型提供了更全面的理论框架和实际应用指导。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "PhD Thesis",
      "pdf_url": "http://arxiv.org/pdf/2410.20143v1",
      "published_date": "2024-10-26 10:51:22 UTC",
      "updated_date": "2024-10-26 10:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:59:20.285032"
    },
    {
      "arxiv_id": "2410.20142v2",
      "title": "Mask-based Membership Inference Attacks for Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Mingrui Liu",
        "Sixiao Zhang",
        "Cheng Long"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has been an effective approach to\nmitigate hallucinations in large language models (LLMs) by incorporating\nup-to-date and domain-specific knowledge. Recently, there has been a trend of\nstoring up-to-date or copyrighted data in RAG knowledge databases instead of\nusing it for LLM training. This practice has raised concerns about Membership\nInference Attacks (MIAs), which aim to detect if a specific target document is\nstored in the RAG system's knowledge database so as to protect the rights of\ndata producers. While research has focused on enhancing the trustworthiness of\nRAG systems, existing MIAs for RAG systems remain largely insufficient.\nPrevious work either relies solely on the RAG system's judgment or is easily\ninfluenced by other documents or the LLM's internal knowledge, which is\nunreliable and lacks explainability. To address these limitations, we propose a\nMask-Based Membership Inference Attacks (MBA) framework. Our framework first\nemploys a masking algorithm that effectively masks a certain number of words in\nthe target document. The masked text is then used to prompt the RAG system, and\nthe RAG system is required to predict the mask values. If the target document\nappears in the knowledge database, the masked text will retrieve the complete\ntarget document as context, allowing for accurate mask prediction. Finally, we\nadopt a simple yet effective threshold-based method to infer the membership of\ntarget document by analyzing the accuracy of mask prediction. Our mask-based\napproach is more document-specific, making the RAG system's generation less\nsusceptible to distractions from other documents or the LLM's internal\nknowledge. Extensive experiments demonstrate the effectiveness of our approach\ncompared to existing baseline models.",
      "tldr_zh": "这篇论文针对 Retrieval-Augmented Generation (RAG) 系统提出了 Mask-based Membership Inference Attacks (MIAs)，旨在检测特定文档是否存储在知识数据库中，以保护数据生产者的权益。现有 MIAs 方法依赖 RAG 的判断或易受其他文档或 large language models (LLMs) 内部知识的影响，导致不可靠和缺乏可解释性。为此，作者设计了 Mask-Based Membership Inference Attacks (MBA) 框架，通过 masking 算法掩盖目标文档中的单词，并分析 RAG 系统对掩盖预测的准确率来推断成员资格。实验结果表明，该方法更文档特定、干扰更少，并在广泛测试中比基线模型表现出更高的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper is accepted by conference WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.20142v2",
      "published_date": "2024-10-26 10:43:39 UTC",
      "updated_date": "2025-02-09 07:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:59:33.530948"
    },
    {
      "arxiv_id": "2410.20140v2",
      "title": "LLM-Consensus: Multi-Agent Debate for Visual Misinformation Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Kumud Lakara",
        "Georgia Channing",
        "Juil Sock",
        "Christian Rupprecht",
        "Philip Torr",
        "John Collomosse",
        "Christian Schroeder de Witt"
      ],
      "abstract": "One of the most challenging forms of misinformation involves the\nout-of-context (OOC) use of images paired with misleading text, creating false\nnarratives. Existing AI-driven detection systems lack explainability and\nrequire expensive finetuning. We address these issues with LLM-Consensus, a\nmulti-agent debate system for OOC misinformation detection. LLM-Consensus\nintroduces a novel multi-agent debate framework where multimodal agents\ncollaborate to assess contextual consistency and request external information\nto enhance cross-context reasoning and decision-making. Our framework enables\nexplainable detection with state-of-the-art accuracy even without\ndomain-specific fine-tuning. Extensive ablation studies confirm that external\nretrieval significantly improves detection accuracy, and user studies\ndemonstrate that LLM-Consensus boosts performance for both experts and\nnon-experts. These results position LLM-Consensus as a powerful tool for\nautonomous and citizen intelligence applications.",
      "tldr_zh": "该论文提出LLM-Consensus，一种多智能体辩论框架，用于检测out-of-context (OOC)视觉误信息问题，即图像与误导性文本结合创建虚假叙事。该框架让multimodal agents合作评估上下文一致性，并通过请求external retrieval增强跨上下文推理和决策，实现可解释性检测，且无需领域特定微调即可达到state-of-the-art准确率。实验结果显示，external retrieval显著提升检测准确率，用户研究证明该系统对专家和非专家均提升性能，将其定位为自主和公民智能应用的强大工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20140v2",
      "published_date": "2024-10-26 10:34:22 UTC",
      "updated_date": "2025-01-31 20:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:59:43.905780"
    },
    {
      "arxiv_id": "2411.05799v1",
      "title": "NeoPhysIx: An Ultra Fast 3D Physical Simulator as Development Tool for AI Algorithms",
      "title_zh": "NeoPhysIx：超快速 3D 物理模拟器作为 AI 算法的开发工具",
      "authors": [
        "Jörn Fischer",
        "Thomas Ihme"
      ],
      "abstract": "Traditional AI algorithms, such as Genetic Programming and Reinforcement\nLearning, often require extensive computational resources to simulate\nreal-world physical scenarios effectively. While advancements in multi-core\nprocessing have been made, the inherent limitations of parallelizing rigid body\ndynamics lead to significant communication overheads, hindering substantial\nperformance gains for simple simulations.\n  This paper introduces NeoPhysIx, a novel 3D physical simulator designed to\novercome these challenges. By adopting innovative simulation paradigms and\nfocusing on essential algorithmic elements, NeoPhysIx achieves unprecedented\nspeedups exceeding 1000x compared to real-time. This acceleration is realized\nthrough strategic simplifications, including point cloud collision detection,\njoint angle determination, and friction force estimation.\n  The efficacy of NeoPhysIx is demonstrated through its application in training\na legged robot with 18 degrees of freedom and six sensors, controlled by an\nevolved genetic program. Remarkably, simulating half a year of robot lifetime\nwithin a mere 9 hours on a single core of a standard mid-range CPU highlights\nthe significant efficiency gains offered by NeoPhysIx. This breakthrough paves\nthe way for accelerated AI development and training in physically-grounded\ndomains.",
      "tldr_zh": "该论文介绍了NeoPhysIx，一种超快速3D Physical Simulator，旨在解决传统AI算法如Genetic Programming和Reinforcement Learning在模拟真实物理场景时面临的计算资源密集问题。NeoPhysIx通过采用创新模拟范式和简化策略（如点云碰撞检测、关节角度确定以及摩擦力估计），实现了超过1000倍的加速性能，显著减少了通信开销。实验证明，该模拟器能在标准中档CPU单核上模拟一个18自由度、六传感器的腿部机器人半年的寿命仅需9小时，从而加速AI算法在物理基础领域的开发和训练。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "7 Pages, 4 Figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05799v1",
      "published_date": "2024-10-26 09:53:07 UTC",
      "updated_date": "2024-10-26 09:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:01:20.811670"
    },
    {
      "arxiv_id": "2411.05022v1",
      "title": "Towards Probabilistic Planning of Explanations for Robot Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Amar Halilovic",
        "Senka Krivic"
      ],
      "abstract": "In robotics, ensuring that autonomous systems are comprehensible and\naccountable to users is essential for effective human-robot interaction. This\npaper introduces a novel approach that integrates user-centered design\nprinciples directly into the core of robot path planning processes. We propose\na probabilistic framework for automated planning of explanations for robot\nnavigation, where the preferences of different users regarding explanations are\nprobabilistically modeled to tailor the stochasticity of the real-world\nhuman-robot interaction and the communication of decisions of the robot and its\nactions towards humans. This approach aims to enhance the transparency of robot\npath planning and adapt to diverse user explanation needs by anticipating the\ntypes of explanations that will satisfy individual users.",
      "tldr_zh": "该研究针对机器人导航中的人机交互问题，提出一种将用户中心设计原则融入路径规划核心的创新方法。论文引入一个probabilistic framework，用于自动化规划机器人的解释，通过概率建模不同用户的解释偏好，以适应真实世界的随机性并提升决策透明度。该框架能预测并提供满足个性化需求的解释类型，从而改善机器人导航的可解释性和用户满意度。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05022v1",
      "published_date": "2024-10-26 09:52:14 UTC",
      "updated_date": "2024-10-26 09:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:01:32.386978"
    },
    {
      "arxiv_id": "2410.20132v1",
      "title": "On-Site Precise Screening of SARS-CoV-2 Systems Using a Channel-Wise Attention-Based PLS-1D-CNN Model with Limited Infrared Signatures",
      "title_zh": "翻译失败",
      "authors": [
        "Wenwen Zhang",
        "Zhouzhuo Tang",
        "Yingmei Feng",
        "Xia Yu",
        "Qi Jie Wang",
        "Zhiping Lin"
      ],
      "abstract": "During the early stages of respiratory virus outbreaks, such as severe acute\nrespiratory syndrome coronavirus 2 (SARS-CoV-2), the efficient utilize of\nlimited nasopharyngeal swabs for rapid and accurate screening is crucial for\npublic health. In this study, we present a methodology that integrates\nattenuated total reflection-Fourier transform infrared spectroscopy (ATR-FTIR)\nwith the adaptive iteratively reweighted penalized least squares (airPLS)\npreprocessing algorithm and a channel-wise attention-based partial least\nsquares one-dimensional convolutional neural network (PLS-1D-CNN) model,\nenabling accurate screening of infected individuals within 10 minutes. Two\ncohorts of nasopharyngeal swab samples, comprising 126 and 112 samples from\nsuspected SARS-CoV-2 Omicron variant cases, were collected at Beijing You'an\nHospital for verification. Given that ATR-FTIR spectra are highly sensitive to\nvariations in experimental conditions, which can affect their quality, we\npropose a biomolecular importance (BMI) evaluation method to assess signal\nquality across different conditions, validated by comparing BMI with PLS-GBM\nand PLS-RF results. For the ATR-FTIR signals in cohort 2, which exhibited a\nhigher BMI, airPLS was utilized for signal preprocessing, followed by the\napplication of the channel-wise attention-based PLS-1D-CNN model for screening.\nThe experimental results demonstrate that our model outperforms recently\nreported methods in the field of respiratory virus spectrum detection,\nachieving a recognition screening accuracy of 96.48%, a sensitivity of 96.24%,\na specificity of 97.14%, an F1-score of 96.12%, and an AUC of 0.99. It meets\nthe World Health Organization (WHO) recommended criteria for an acceptable\nproduct: sensitivity of 95.00% or greater and specificity of 97.00% or greater\nfor testing prior SARS-CoV-2 infection in moderate to high volume scenarios.",
      "tldr_zh": "本研究提出了一种基于 ATR-FTIR 光谱技术和 channel-wise attention-based PLS-1D-CNN 模型的现场精确筛查 SARS-CoV-2 方法，利用 airPLS 预处理算法和 biomolecular importance (BMI) 评估来处理实验条件变异，确保信号质量。针对两个队列的鼻咽拭子样本，该方法能在 10 分钟内实现高效筛查，并通过实验验证其准确率达 96.48%、敏感性 96.24%、特异性 97.14%、F1-score 96.12% 以及 AUC 0.99。相比现有方法，该模型显著提升了呼吸道病毒检测性能，并满足 WHO 对于高容量场景的敏感性和特异性标准，为快速公共卫生响应提供了可靠工具。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20132v1",
      "published_date": "2024-10-26 09:22:35 UTC",
      "updated_date": "2024-10-26 09:22:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:01:47.919926"
    },
    {
      "arxiv_id": "2410.20116v1",
      "title": "Estuary: A Framework For Building Multimodal Low-Latency Real-Time Socially Interactive Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Spencer Lin",
        "Basem Rizk",
        "Miru Jun",
        "Andy Artze",
        "Caitlin Sullivan",
        "Sharon Mozgai",
        "Scott Fisher"
      ],
      "abstract": "The rise in capability and ubiquity of generative artificial intelligence\n(AI) technologies has enabled its application to the field of Socially\nInteractive Agents (SIAs). Despite rising interest in modern AI-powered\ncomponents used for real-time SIA research, substantial friction remains due to\nthe absence of a standardized and universal SIA framework. To target this\nabsence, we developed Estuary: a multimodal (text, audio, and soon video)\nframework which facilitates the development of low-latency, real-time SIAs.\nEstuary seeks to reduce repeat work between studies and to provide a flexible\nplatform that can be run entirely off-cloud to maximize configurability,\ncontrollability, reproducibility of studies, and speed of agent response times.\nWe are able to do this by constructing a robust multimodal framework which\nincorporates current and future components seamlessly into a modular and\ninteroperable architecture.",
      "tldr_zh": "该研究针对生成式人工智能在Socially Interactive Agents (SIAs)领域的应用问题，指出缺乏标准化框架导致的重复工作和开发摩擦。作者开发了Estuary框架，这是一个多模态（文本、音频，并即将支持视频）的平台，用于构建低延迟实时SIAs，支持完全离线运行以提升可配置性、可控性、可重复性和响应速度。通过模块化和互操作的架构，Estuary无缝集成当前和未来组件，减少研究重复并加速SIA开发。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "J.0"
      ],
      "primary_category": "cs.HC",
      "comment": "To be published in ACM Intelligent Virtual Agents (IVA) 2024 [DOI:\n  10.1145/3652988.3696198] [ACM ISBN: 979-8-4007-0625-7/24/09]",
      "pdf_url": "http://arxiv.org/pdf/2410.20116v1",
      "published_date": "2024-10-26 08:08:12 UTC",
      "updated_date": "2024-10-26 08:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:01:58.393205"
    },
    {
      "arxiv_id": "2410.20109v2",
      "title": "GiVE: Guiding Visual Encoder to Perceive Overlooked Information",
      "title_zh": "GiVE：引导视觉编码器感知被忽略的信息",
      "authors": [
        "Junjie Li",
        "Jianghong Ma",
        "Xiaofeng Zhang",
        "Yuhang Li",
        "Jianyang Shi"
      ],
      "abstract": "Multimodal Large Language Models have advanced AI in applications like\ntext-to-video generation and visual question answering. These models rely on\nvisual encoders to convert non-text data into vectors, but current encoders\neither lack semantic alignment or overlook non-salient objects. We propose the\nGuiding Visual Encoder to Perceive Overlooked Information (GiVE) approach. GiVE\nenhances visual representation with an Attention-Guided Adapter (AG-Adapter)\nmodule and an Object-focused Visual Semantic Learning module. These incorporate\nthree novel loss terms: Object-focused Image-Text Contrast (OITC) loss,\nObject-focused Image-Image Contrast (OIIC) loss, and Object-focused Image\nDiscrimination (OID) loss, improving object consideration, retrieval accuracy,\nand comprehensiveness. Our contributions include dynamic visual focus\nadjustment, novel loss functions to enhance object retrieval, and the\nMulti-Object Instruction (MOInst) dataset. Experiments show our approach\nachieves state-of-the-art performance.",
      "tldr_zh": "本研究提出 GiVE 方法，用于引导视觉编码器感知被忽略的非显著对象，从而提升多模态大语言模型在文本到视频生成和视觉问答等应用中的性能。GiVE 通过引入 Attention-Guided Adapter (AG-Adapter) 模块和 Object-focused Visual Semantic Learning 模块，并结合三个新损失函数——Object-focused Image-Text Contrast (OITC) 损失、Object-focused Image-Image Contrast (OIIC) 损失和 Object-focused Image Discrimination (OID) 损失——来改善对象考虑、检索准确性和整体全面性。论文的主要贡献包括动态视觉焦点调整机制、新颖的损失函数设计以及 Multi-Object Instruction (MOInst) 数据集的构建，实验结果显示该方法在相关任务上达到了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper was accepted by ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.20109v2",
      "published_date": "2024-10-26 07:37:43 UTC",
      "updated_date": "2025-03-21 14:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:02:10.528110"
    },
    {
      "arxiv_id": "2410.20107v2",
      "title": "Emergence of Globally Attracting Fixed Points in Deep Neural Networks With Nonlinear Activations",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Joudaki",
        "Thomas Hofmann"
      ],
      "abstract": "Understanding how neural networks transform input data across layers is\nfundamental to unraveling their learning and generalization capabilities.\nAlthough prior work has used insights from kernel methods to study neural\nnetworks, a global analysis of how the similarity between hidden\nrepresentations evolves across layers remains underexplored. In this paper, we\nintroduce a theoretical framework for the evolution of the kernel sequence,\nwhich measures the similarity between the hidden representation for two\ndifferent inputs. Operating under the mean-field regime, we show that the\nkernel sequence evolves deterministically via a kernel map, which only depends\non the activation function. By expanding activation using Hermite polynomials\nand using their algebraic properties, we derive an explicit form for kernel map\nand fully characterize its fixed points. Our analysis reveals that for\nnonlinear activations, the kernel sequence converges globally to a unique fixed\npoint, which can correspond to orthogonal or similar representations depending\non the activation and network architecture. We further extend our results to\nnetworks with residual connections and normalization layers, demonstrating\nsimilar convergence behaviors. This work provides new insights into the\nimplicit biases of deep neural networks and how architectural choices influence\nthe evolution of representations across layers.",
      "tldr_zh": "这篇论文引入了一个理论框架，分析深度神经网络中隐藏表示相似性的内核序列（kernel sequence）在层间的演化，以揭示网络的学习和泛化能力。在均值场制度（mean-field regime）下，作者使用 Hermite 多项式扩展激活函数，导出了内核映射（kernel map）的显式形式，并证明对于非线性激活（nonlinear activations），内核序列会全局收敛到一个唯一的固定点（fixed points），这可能对应正交或相似表示，取决于激活函数和网络架构。研究进一步扩展到带有残差连接和归一化层的网络，展示了类似收敛行为，并为理解深度神经网络的隐式偏差（implicit biases）和架构选择的影响提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20107v2",
      "published_date": "2024-10-26 07:10:47 UTC",
      "updated_date": "2024-10-29 07:52:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:02:23.390272"
    },
    {
      "arxiv_id": "2410.20098v2",
      "title": "Self-Normalized Resets for Plasticity in Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Vivek F. Farias",
        "Adam D. Jozefiak"
      ],
      "abstract": "Plasticity Loss is an increasingly important phenomenon that refers to the\nempirical observation that as a neural network is continually trained on a\nsequence of changing tasks, its ability to adapt to a new task diminishes over\ntime. We introduce Self-Normalized Resets (SNR), a simple adaptive algorithm\nthat mitigates plasticity loss by resetting a neuron's weights when evidence\nsuggests its firing rate has effectively dropped to zero. Across a battery of\ncontinual learning problems and network architectures, we demonstrate that SNR\nconsistently attains superior performance compared to its competitor\nalgorithms. We also demonstrate that SNR is robust to its sole hyperparameter,\nits rejection percentile threshold, while competitor algorithms show\nsignificant sensitivity. SNR's threshold-based reset mechanism is motivated by\na simple hypothesis test that we derive. Seen through the lens of this\nhypothesis test, competing reset proposals yield suboptimal error rates in\ncorrectly detecting inactive neurons, potentially explaining our experimental\nobservations. We also conduct a theoretical investigation of the optimization\nlandscape for the problem of learning a single ReLU. We show that even when\ninitialized adversarially, an idealized version of SNR learns the target ReLU,\nwhile regularization-based approaches can fail to learn.",
      "tldr_zh": "该研究针对持续学习(Continual Learning)中的Plasticity Loss问题，即神经网络在连续训练多个任务时适应新任务的能力逐渐减弱，提出了一种简单自适应算法Self-Normalized Resets (SNR)。SNR通过基于假设测试的阈值机制，在神经元的激活率降至零时重置其权重，从而有效缓解这一问题。实验结果显示，SNR在各种持续学习场景和网络架构中 outperform竞争算法，且对唯一超参数（拒绝百分位阈值）具有鲁棒性；理论分析进一步证明，SNR能成功学习目标ReLU，而基于正则化的方法可能失败。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20098v2",
      "published_date": "2024-10-26 06:47:13 UTC",
      "updated_date": "2025-03-01 18:34:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:02:33.765915"
    },
    {
      "arxiv_id": "2410.20092v2",
      "title": "OGBench: Benchmarking Offline Goal-Conditioned RL",
      "title_zh": "翻译失败",
      "authors": [
        "Seohong Park",
        "Kevin Frans",
        "Benjamin Eysenbach",
        "Sergey Levine"
      ],
      "abstract": "Offline goal-conditioned reinforcement learning (GCRL) is a major problem in\nreinforcement learning (RL) because it provides a simple, unsupervised, and\ndomain-agnostic way to acquire diverse behaviors and representations from\nunlabeled data without rewards. Despite the importance of this setting, we lack\na standard benchmark that can systematically evaluate the capabilities of\noffline GCRL algorithms. In this work, we propose OGBench, a new, high-quality\nbenchmark for algorithms research in offline goal-conditioned RL. OGBench\nconsists of 8 types of environments, 85 datasets, and reference implementations\nof 6 representative offline GCRL algorithms. We have designed these challenging\nand realistic environments and datasets to directly probe different\ncapabilities of algorithms, such as stitching, long-horizon reasoning, and the\nability to handle high-dimensional inputs and stochasticity. While\nrepresentative algorithms may rank similarly on prior benchmarks, our\nexperiments reveal stark strengths and weaknesses in these different\ncapabilities, providing a strong foundation for building new algorithms.\nProject page: https://seohong.me/projects/ogbench",
      "tldr_zh": "本研究针对离线目标条件强化学习(Offline Goal-Conditioned RL, GCRL)提出OGBench基准，以系统评估算法从无标签数据中获取多样行为和表示的能力。OGBench包含8种环境类型、85个数据集以及6个代表性算法的参考实现，这些环境设计挑战性强，专注于测试算法的拼接(stitching)、长horizon推理、高维输入处理和随机性处理等关键能力。实验结果显示，现有的代表性算法在不同能力上存在明显优缺点，为未来开发更有效的GCRL算法提供了坚实基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.20092v2",
      "published_date": "2024-10-26 06:06:08 UTC",
      "updated_date": "2025-02-13 18:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:02:45.827035"
    },
    {
      "arxiv_id": "2410.20088v1",
      "title": "RARe: Retrieval Augmented Retrieval with In-Context Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Atula Tejaswi",
        "Yoonsang Lee",
        "Sujay Sanghavi",
        "Eunsol Choi"
      ],
      "abstract": "We investigate whether in-context examples, widely used in decoder-only\nlanguage models (LLMs), can improve embedding model performance in retrieval\ntasks. Unlike in LLMs, naively prepending in-context examples (query-document\npairs) to the target query at inference time does not work out of the box. We\nintroduce a simple approach to enable retrievers to use in-context examples.\nOur approach, RARe, finetunes a pre-trained model with in-context examples\nwhose query is semantically similar to the target query. This can be applied to\nadapt various base architectures (i.e., decoder-only language models, retriever\nmodels) and consistently achieves performance gains of up to +2.72% nDCG across\nvarious open-domain retrieval datasets (BeIR, RAR-b). In particular, we find\nRARe exhibits stronger out-of-domain generalization compared to models using\nqueries without in-context examples, similar to what is seen for in-context\nlearning in LLMs. We further provide analysis on the design choices of\nin-context example augmentation and lay the foundation for future work in this\nspace.",
      "tldr_zh": "本研究探讨了是否可以将 in-context examples 应用于嵌入模型的检索任务中，以提升性能。RARe 方法通过微调预训练模型，使用与目标查询语义相似的 in-context examples 作为增强，从而解决了直接添加示例无效的问题。该方法适用于各种基础架构，并在 BeIR 和 RAR-b 等开放域检索数据集上实现了高达 +2.72% nDCG 的性能提升。实验结果显示，RARe 展现出更强的域外泛化能力，并通过分析 in-context example 的设计选择，为未来检索模型研究奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20088v1",
      "published_date": "2024-10-26 05:46:20 UTC",
      "updated_date": "2024-10-26 05:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:02:58.331692"
    },
    {
      "arxiv_id": "2410.21321v1",
      "title": "User-Aware Multilingual Abusive Content Detection in Social Media",
      "title_zh": "用户感知的多语言社交媒体辱骂内容检测",
      "authors": [
        "Mohammad Zia Ur Rehman",
        "Somya Mehta",
        "Kuldeep Singh",
        "Kunal Kaushik",
        "Nagendra Kumar"
      ],
      "abstract": "Despite growing efforts to halt distasteful content on social media,\nmultilingualism has added a new dimension to this problem. The scarcity of\nresources makes the challenge even greater when it comes to low-resource\nlanguages. This work focuses on providing a novel method for abusive content\ndetection in multiple low-resource Indic languages. Our observation indicates\nthat a post's tendency to attract abusive comments, as well as features such as\nuser history and social context, significantly aid in the detection of abusive\ncontent. The proposed method first learns social and text context features in\ntwo separate modules. The integrated representation from these modules is\nlearned and used for the final prediction. To evaluate the performance of our\nmethod against different classical and state-of-the-art methods, we have\nperformed extensive experiments on SCIDN and MACI datasets consisting of 1.5M\nand 665K multilingual comments, respectively. Our proposed method outperforms\nstate-of-the-art baseline methods with an average increase of 4.08% and 9.52%\nin F1-scores on SCIDN and MACI datasets, respectively.",
      "tldr_zh": "本研究针对多语言社交媒体上的辱骂内容检测问题，特别关注低资源印度语系语言，提出了一种用户感知的方法。该方法通过两个独立模块分别学习社会上下文（如用户历史和帖子吸引力）和文本特征，然后整合这些表示进行最终预测。在 SCIDN 和 MACI 数据集（分别包含 1.5M 和 665K 多语言评论）上进行的实验表明，该方法比经典和最先进基线模型的 F1-scores 平均提高了 4.08% 和 9.52%。这项工作为多语言辱骂内容检测提供了新颖的解决方案，提升了低资源语言的检测性能。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21321v1",
      "published_date": "2024-10-26 05:44:24 UTC",
      "updated_date": "2024-10-26 05:44:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:03:11.066527"
    },
    {
      "arxiv_id": "2411.08883v1",
      "title": "KisanQRS: A Deep Learning-based Automated Query-Response System for Agricultural Decision-Making",
      "title_zh": "KisanQRS：一种基于深度学习的自动化查询响应系统，用于农业决策",
      "authors": [
        "Mohammad Zia Ur Rehman",
        "Devraj Raghuvanshi",
        "Nagendra Kumar"
      ],
      "abstract": "Delivering prompt information and guidance to farmers is critical in\nagricultural decision-making. Farmers helpline centres are heavily reliant on\nthe expertise and availability of call centre agents, leading to inconsistent\nquality and delayed responses. To this end, this article presents Kisan Query\nResponse System (KisanQRS), a Deep Learning-based robust query-response\nframework for the agriculture sector. KisanQRS integrates semantic and lexical\nsimilarities of farmers queries and employs a rapid threshold-based clustering\nmethod. The clustering algorithm is based on a linear search technique to\niterate through all queries and organize them into clusters according to their\nsimilarity. For query mapping, LSTM is found to be the optimal method. Our\nproposed answer retrieval method clusters candidate answers for a crop, ranks\nthese answer clusters based on the number of answers in a cluster, and selects\nthe leader of each cluster. The dataset used in our analysis consists of a\nsubset of 34 million call logs from the Kisan Call Centre (KCC), operated under\nthe Government of India. We evaluated the performance of the query mapping\nmodule on the data of five major states of India with 3,00,000 samples and the\nquantifiable outcomes demonstrate that KisanQRS significantly outperforms\ntraditional techniques by achieving 96.58% top F1-score for a state. The answer\nretrieval module is evaluated on 10,000 samples and it achieves a competitive\nNDCG score of 96.20%. KisanQRS is useful in enabling farmers to make informed\ndecisions about their farming practices by providing quick and pertinent\nresponses to their queries.",
      "tldr_zh": "该论文提出 KisanQRS，一种基于深度学习的自动查询响应系统，旨在解决农业决策中农民咨询响应延迟和不一致的问题。该系统整合语义和词汇相似性，使用阈值-based 聚类算法（基于线性搜索）和 LSTM 作为查询映射的优化方法，并通过聚类和排名候选答案来实现高效响应。实验基于印度 Kisan Call Centre 的 3400 万呼叫日志子集，在 30 万样本上评估查询映射模块，F1-score 达到 96.58%，答案检索模块的 NDCG 得分为 96.20%。KisanQRS 能够为农民提供快速、相关的信息，支持更明智的农业决策。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08883v1",
      "published_date": "2024-10-26 05:25:05 UTC",
      "updated_date": "2024-10-26 05:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:05:23.455072"
    },
    {
      "arxiv_id": "2410.20080v1",
      "title": "Optimizing Keyphrase Ranking for Relevance and Diversity Using Submodular Function Optimization (SFO)",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Umair",
        "Syed Jalaluddin Hashmi",
        "Young-Koo Lee"
      ],
      "abstract": "Keyphrase ranking plays a crucial role in information retrieval and\nsummarization by indexing and retrieving relevant information efficiently.\nAdvances in natural language processing, especially large language models\n(LLMs), have improved keyphrase extraction and ranking. However, traditional\nmethods often overlook diversity, resulting in redundant keyphrases. We propose\na novel approach using Submodular Function Optimization (SFO) to balance\nrelevance and diversity in keyphrase ranking. By framing the task as submodular\nmaximization, our method selects diverse and representative keyphrases.\nExperiments on benchmark datasets show that our approach outperforms existing\nmethods in both relevance and diversity metrics, achieving SOTA performance in\nexecution time. Our code is available online.",
      "tldr_zh": "这篇论文针对关键短语排名在信息检索和总结中的问题，提出了一种使用 Submodular Function Optimization (SFO) 的新方法，以平衡相关性和多样性，避免传统方法导致的关键短语冗余。方法将关键短语选择任务 framing 为 submodular maximization，从而选取多样且代表性的关键短语。实验在基准数据集上显示，该方法在相关性和多样性指标上优于现有方法，实现了 SOTA 性能，同时在执行时间上表现出色，代码已开源。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20080v1",
      "published_date": "2024-10-26 05:14:32 UTC",
      "updated_date": "2024-10-26 05:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:03:35.439975"
    },
    {
      "arxiv_id": "2410.21319v1",
      "title": "Towards Continuous Skin Sympathetic Nerve Activity Monitoring: Removing Muscle Noise",
      "title_zh": "迈向连续皮肤交感神经活动监测：去除肌肉噪声",
      "authors": [
        "Farnoush Baghestani",
        "Mahdi Pirayesh Shirazi Nejad",
        "Youngsun Kong",
        "Ki H. Chon"
      ],
      "abstract": "Continuous monitoring of non-invasive skin sympathetic nerve activity (SKNA)\nholds promise for understanding the sympathetic nervous system (SNS) dynamics\nin various physiological and pathological conditions. However, muscle noise\nartifacts present a challenge in accurate SKNA analysis, particularly in\nreal-life scenarios. This study proposes a deep convolutional neural network\n(CNN) approach to detect and remove muscle noise from SKNA recordings obtained\nvia ECG electrodes. Twelve healthy participants underwent controlled\nexperimental protocols involving cognitive stress induction and voluntary\nmuscle movements, while collecting SKNA data. Power spectral analysis revealed\nsignificant muscle noise interference within the SKNA frequency band (500-1000\nHz). A 2D CNN model was trained on the spectrograms of the data segments to\nclassify them into baseline, stress-induced SKNA, and muscle noise-contaminated\nperiods, achieving an average accuracy of 89.85% across all subjects. Our\nfindings underscore the importance of addressing muscle noise for accurate SKNA\nmonitoring, advancing towards wearable SKNA sensors for real-world\napplications.",
      "tldr_zh": "该研究旨在实现连续监测非侵入性皮肤交感神经活动 (SKNA)，以更好地理解交感神经系统 (SNS) 在生理和病理条件下的动态，但肌肉噪声干扰成为主要挑战。研究提出了一种基于深度卷积神经网络 (CNN) 的方法，使用 2D CNN 模型对数据频谱图进行分类，检测并去除 SKNA 记录中的肌肉噪声，在 12 名健康参与者的实验中（涉及认知压力和肌肉运动），模型平均准确率达到 89.85%。这一发现突出了处理肌肉噪声的重要性，为开发可穿戴 SKNA 传感器并应用于真实场景铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, 5 figures, 1 table, IEEE-EMBS International Conference on\n  Body Sensor Networks: NextGen Health: Sensor Innovation, AI, and Social\n  Responsibility (IEEE BSN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.21319v1",
      "published_date": "2024-10-26 04:10:14 UTC",
      "updated_date": "2024-10-26 04:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:03:47.680895"
    },
    {
      "arxiv_id": "2410.20066v2",
      "title": "A Multi-Modal Non-Invasive Deep Learning Framework for Progressive Prediction of Seizures",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Saeizadeh",
        "Douglas Schonholtz",
        "Joseph S. Neimat",
        "Pedram Johari",
        "Tommaso Melodia"
      ],
      "abstract": "This paper introduces an innovative framework designed for progressive\n(granular in time to onset) prediction of seizures through the utilization of a\nDeep Learning (DL) methodology based on non-invasive multi-modal sensor\nnetworks. Epilepsy, a debilitating neurological condition, affects an estimated\n65 million individuals globally, with a substantial proportion facing\ndrug-resistant epilepsy despite pharmacological interventions. To address this\nchallenge, we advocate for predictive systems that provide timely alerts to\nindividuals at risk, enabling them to take precautionary actions. Our framework\nemploys advanced DL techniques and uses personalized data from a network of\nnon-invasive electroencephalogram (EEG) and electrocardiogram (ECG) sensors,\nthereby enhancing prediction accuracy. The algorithms are optimized for\nreal-time processing on edge devices, mitigating privacy concerns and\nminimizing data transmission overhead inherent in cloud-based solutions,\nultimately preserving battery energy. Additionally, our system predicts the\ncountdown time to seizures (with 15-minute intervals up to an hour prior to the\nonset), offering critical lead time for preventive actions. Our multi-modal\nmodel achieves 95% sensitivity, 98% specificity, and 97% accuracy, averaged\namong 29 patients.",
      "tldr_zh": "这篇论文提出了一种基于深度学习的非侵入性多模态框架，用于癫痫发作的渐进式预测（granular in time to onset），旨在为全球约6500万癫痫患者提供及时警报。该框架利用EEG和ECG传感器网络的个性化数据进行实时处理，优化算法以适应边缘设备，减少数据传输开销并保护隐私，同时能预测发作倒计时（15分钟间隔，直至一小时前）。实验结果显示，该多模态模型在29名患者中平均达到95%敏感性、98%特异性和97%准确率，为药物抵抗性癫痫的预防措施提供了可靠支持。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "4 pages, 5 figures, Proceedings of the IEEE 20th International\n  Conference on Body Sensor Networks (BSN), October 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.20066v2",
      "published_date": "2024-10-26 04:06:09 UTC",
      "updated_date": "2024-11-01 18:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:04:00.291125"
    },
    {
      "arxiv_id": "2410.20062v1",
      "title": "Transforming Precision: A Comparative Analysis of Vision Transformers, CNNs, and Traditional ML for Knee Osteoarthritis Severity Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Tasnim Sakib Apon",
        "Md. Fahim-Ul-Islam",
        "Nafiz Imtiaz Rafin",
        "Joya Akter",
        "Md. Golam Rabiul Alam"
      ],
      "abstract": "Knee osteoarthritis(KO) is a degenerative joint disease that can cause severe\npain and impairment. With increased prevalence, precise diagnosis by medical\nimaging analytics is crucial for appropriate illness management. This research\ninvestigates a comparative analysis between traditional machine learning\ntechniques and new deep learning models for diagnosing KO severity from X-ray\npictures. This study does not introduce new architectural innovations but\nrather illuminates the robust applicability and comparative effectiveness of\npre-existing ViT models in a medical imaging context, specifically for KO\nseverity diagnosis. The insights garnered from this comparative analysis\nadvocate for the integration of advanced ViT models in clinical diagnostic\nworkflows, potentially revolutionizing the precision and reliability of KO\nassessments. This study does not introduce new architectural innovations but\nrather illuminates the robust applicability and comparative effectiveness of\npre-existing ViT models in a medical imaging context, specifically for KO\nseverity diagnosis. The insights garnered from this comparative analysis\nadvocate for the integration of advanced ViT models in clinical diagnostic\nworkflows, potentially revolutionizing the precision & reliability of KO\nassessments. The study utilizes an osteoarthritis dataset from the\nOsteoarthritis Initiative (OAI) comprising images with 5 severity categories\nand uneven class distribution. While classic machine learning models like\nGaussianNB and KNN struggle in feature extraction, Convolutional Neural\nNetworks such as Inception-V3, VGG-19 achieve better accuracy between 55-65% by\nlearning hierarchical visual patterns. However, Vision Transformer\narchitectures like Da-VIT, GCViT and MaxViT emerge as indisputable champions,\ndisplaying 66.14% accuracy, 0.703 precision, 0.614 recall, AUC exceeding 0.835\nthanks to self-attention processes.",
      "tldr_zh": "本研究比较了传统机器学习（Traditional ML）、卷积神经网络（CNNs）和视觉Transformer（Vision Transformers, ViT）在膝关节骨关节炎（KO）严重程度诊断中的性能，使用Osteoarthritis Initiative (OAI)数据集，该数据集包含X光图像和5个不均衡严重程度类别。结果显示，传统模型如GaussianNB和KNN在特征提取上表现较差，而CNN模型如Inception-V3和VGG-19的准确率达55-65%；然而，ViT模型如Da-VIT、GCViT和MaxViT表现出色，准确率达66.14%、精度0.703、召回率0.614、AUC超过0.835。研究强调了现有ViT模型在医疗成像中的强大适用性，建议将其整合到临床诊断流程中，以提升KO评估的精确性和可靠性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20062v1",
      "published_date": "2024-10-26 03:58:58 UTC",
      "updated_date": "2024-10-26 03:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:04:11.949667"
    },
    {
      "arxiv_id": "2411.05798v1",
      "title": "A Genetic Algorithm for Multi-Capacity Fixed-Charge Flow Network Design",
      "title_zh": "一种用于多容量固定费用流量网络设计的遗传算法",
      "authors": [
        "Caleb Eardley",
        "Dalton Gomez",
        "Ryan Dupuis",
        "Michael Papadopoulos",
        "Sean Yaw"
      ],
      "abstract": "The Multi-Capacity Fixed-Charge Network Flow (MC-FCNF) problem, a\ngeneralization of the Fixed-Charge Network Flow problem, aims to assign\ncapacities to edges in a flow network such that a target amount of flow can be\nhosted at minimum cost. The cost model for both problems dictates that the\nfixed cost of an edge is incurred for any non-zero amount of flow hosted by\nthat edge. This problem naturally arises in many areas including infrastructure\ndesign, transportation, telecommunications, and supply chain management. The\nMC-FCNF problem is NP-Hard, so solving large instances using exact techniques\nis impractical. This paper presents a genetic algorithm designed to quickly\nfind high-quality flow solutions to the MC-FCNF problem. The genetic algorithm\nuses a novel solution representation scheme that eliminates the need to repair\ninvalid flow solutions, which is an issue common to many other genetic\nalgorithms for the MC-FCNF problem. The genetic algorithm's efficiency is\ndisplayed with an evaluation using real-world CO2 capture and storage\ninfrastructure design data. The evaluation results highlight the genetic\nalgorithm's potential for solving large-scale network design problems.",
      "tldr_zh": "这篇论文针对 Multi-Capacity Fixed-Charge Network Flow (MC-FCNF) 问题提出了一种遗传算法（Genetic Algorithm），该问题是 Fixed-Charge Network Flow 的推广版本，旨在以最低成本为网络边分配容量以容纳目标流量。MC-FCNF 属于 NP-Hard 问题，常出现在基础设施设计、交通、电信和供应链管理等领域中。算法采用一种新颖的解决方案表示方案，避免了修复无效流量方案的需要，从而提高计算效率。在使用真实世界的 CO2 捕获和存储基础设施数据进行评估时，该算法展示了快速找到高质量解决方案的能力，并突显了其在解决大规模网络设计问题上的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05798v1",
      "published_date": "2024-10-26 03:50:18 UTC",
      "updated_date": "2024-10-26 03:50:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:04:23.412131"
    },
    {
      "arxiv_id": "2411.00813v1",
      "title": "Personality Analysis from Online Short Video Platforms with Multi-domain Adaptation",
      "title_zh": "在线短视频平台的人格分析采用多域适应",
      "authors": [
        "Sixu An",
        "Xiangguo Sun",
        "Yicong Li",
        "Yu Yang",
        "Guandong Xu"
      ],
      "abstract": "Personality analysis from online short videos has gained prominence due to\nits applications in personalized recommendation systems, sentiment analysis,\nand human-computer interaction. Traditional assessment methods, such as\nquestionnaires based on the Big Five Personality Framework, are limited by\nself-report biases and are impractical for large-scale or real-time analysis.\nLeveraging the rich, multi-modal data present in short videos offers a\npromising alternative for more accurate personality inference. However,\nintegrating these diverse and asynchronous modalities poses significant\nchallenges, particularly in aligning time-varying data and ensuring models\ngeneralize well to new domains with limited labeled data. In this paper, we\npropose a novel multi-modal personality analysis framework that addresses these\nchallenges by synchronizing and integrating features from multiple modalities\nand enhancing model generalization through domain adaptation. We introduce a\ntimestamp-based modality alignment mechanism that synchronizes data based on\nspoken word timestamps, ensuring accurate correspondence across modalities and\nfacilitating effective feature integration. To capture temporal dependencies\nand inter-modal interactions, we employ Bidirectional Long Short-Term Memory\nnetworks and self-attention mechanisms, allowing the model to focus on the most\ninformative features for personality prediction. Furthermore, we develop a\ngradient-based domain adaptation method that transfers knowledge from multiple\nsource domains to improve performance in target domains with scarce labeled\ndata. Extensive experiments on real-world datasets demonstrate that our\nframework significantly outperforms existing methods in personality prediction\ntasks, highlighting its effectiveness in capturing complex behavioral cues and\nrobustness in adapting to new domains.",
      "tldr_zh": "本研究针对在线短视频平台的个性分析问题，提出一个多模态框架，以克服传统Big Five Personality Framework问卷的偏见和实时性不足。该框架通过时间戳-based模态对齐机制同步多模态数据，并利用Bidirectional Long Short-Term Memory (Bi-LSTM)网络和self-attention机制捕捉时间依赖及模态交互，同时采用梯度-based domain adaptation方法从多个源域转移知识，提升在新域的泛化能力。实验结果显示，该框架在真实数据集上显著优于现有方法，在个性预测任务中更准确地捕捉复杂行为线索，并展现出更强的适应性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY",
        "cs.LG",
        "cs.SI",
        "eess.AS"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00813v1",
      "published_date": "2024-10-26 03:29:32 UTC",
      "updated_date": "2024-10-26 03:29:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:04:35.582735"
    },
    {
      "arxiv_id": "2410.21318v1",
      "title": "Multi-path Exploration and Feedback Adjustment for Text-to-Image Person Retrieval",
      "title_zh": "多路径探索与反馈调整的文本到图像人检索",
      "authors": [
        "Bin Kang",
        "Bin Chen",
        "Junjie Wang",
        "Yong Xu"
      ],
      "abstract": "Text-based person retrieval aims to identify the specific persons using\ntextual descriptions as queries. Existing ad vanced methods typically depend on\nvision-language pre trained (VLP) models to facilitate effective cross-modal\nalignment. However, the inherent constraints of VLP mod-els, which include the\nglobal alignment biases and insuffi-cient self-feedback regulation, impede\noptimal retrieval per formance. In this paper, we propose MeFa, a Multi-Pathway\nExploration, Feedback, and Adjustment framework, which deeply explores\nintrinsic feedback of intra and inter-modal to make targeted adjustment,\nthereby achieving more precise person-text associations. Specifically, we first\ndesign an intra modal reasoning pathway that generates hard negative sam ples\nfor cross-modal data, leveraging feedback from these samples to refine\nintra-modal reasoning, thereby enhancing sensitivity to subtle discrepancies.\nSubsequently, we intro duce a cross-modal refinement pathway that utilizes both\nglobal information and intermodal feedback to refine local in formation, thus\nenhancing its global semantic representation. Finally, the discriminative clue\ncorrection pathway incorpo rates fine-grained features of secondary similarity\nas discrim inative clues to further mitigate retrieval failures caused by\ndisparities in these features. Experimental results on three public benchmarks\ndemonstrate that MeFa achieves superior person retrieval performance without\nnecessitating additional data or complex structures.",
      "tldr_zh": "本研究针对文本到图像人脸检索（Text-to-Image Person Retrieval）中的问题，提出MeFa框架，该框架通过多路径探索和反馈调整机制，解决Vision-Language Pre-trained (VLP) 模型的全局对齐偏差和自反馈调节不足等问题。具体而言，MeFa包括intra-modal reasoning pathway（生成hard negative samples以提升细微差异敏感性）、cross-modal refinement pathway（利用全局信息和intermodal feedback优化局部表示），以及discriminative clue correction pathway（整合细粒度特征减少检索失败）。实验结果显示，该框架在三个公共基准上实现了优越的检索性能，而无需额外数据或复杂结构。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21318v1",
      "published_date": "2024-10-26 03:25:27 UTC",
      "updated_date": "2024-10-26 03:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:04:46.928795"
    },
    {
      "arxiv_id": "2410.20054v1",
      "title": "Evaluating Neural Networks for Early Maritime Threat Detection",
      "title_zh": "评估神经网络用于早期海上威胁检测",
      "authors": [
        "Dhanush Tella",
        "Chandra Teja Tiriveedhi",
        "Naphtali Rishe",
        "Dan E. Tamir",
        "Jonathan I. Tamir"
      ],
      "abstract": "We consider the task of classifying trajectories of boat activities as a\nproxy for assessing maritime threats. Previous approaches have considered\nentropy-based metrics for clustering boat activity into three broad categories:\nrandom walk, following, and chasing. Here, we comprehensively assess the\naccuracy of neural network-based approaches as alternatives to entropy-based\nclustering. We train four neural network models and compare them to shallow\nlearning using synthetic data. We also investigate the accuracy of models as\ntime steps increase and with and without rotated data. To improve test-time\nrobustness, we normalize trajectories and perform rotation-based data\naugmentation. Our results show that deep networks can achieve a test-set\naccuracy of up to 100% on a full trajectory, with graceful degradation as the\nnumber of time steps decreases, outperforming entropy-based clustering.",
      "tldr_zh": "本研究评估了神经网络在早期海上威胁检测中的表现，通过分类船只轨迹（trajectories）作为代理，与传统的基于熵的聚类（entropy-based clustering）方法进行比较。研究团队训练了四个神经网络模型，使用合成数据，并通过轨迹归一化和旋转数据增强（rotation-based data augmentation）来提升测试时鲁棒性，同时考察了时间步数对准确率的影响。结果表明，深度网络在完整轨迹上可实现高达100%的测试准确率，随着时间步减少准确率优雅下降，且整体优于基于熵的聚类方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20054v1",
      "published_date": "2024-10-26 03:05:28 UTC",
      "updated_date": "2024-10-26 03:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:05:01.508303"
    },
    {
      "arxiv_id": "2411.08882v1",
      "title": "A Novel Multimodal System to Predict Agitation in People with Dementia Within Clinical Settings: A Proof of Concept",
      "title_zh": "翻译失败",
      "authors": [
        "Abeer Badawi",
        "Somayya Elmoghazy",
        "Samira Choudhury",
        "Sara Elgazzar",
        "Khalid Elgazzar",
        "Amer Burhan"
      ],
      "abstract": "Dementia is a neurodegenerative condition that combines several diseases and\nimpacts millions around the world and those around them. Although cognitive\nimpairment is profoundly disabling, it is the noncognitive features of\ndementia, referred to as Neuropsychiatric Symptoms (NPS), that are most closely\nassociated with a diminished quality of life. Agitation and aggression (AA) in\npeople living with dementia (PwD) contribute to distress and increased\nhealthcare demands. Current assessment methods rely on caregiver intervention\nand reporting of incidents, introducing subjectivity and bias. Artificial\nIntelligence (AI) and predictive algorithms offer a potential solution for\ndetecting AA episodes in PwD when utilized in real-time. We present a 5-year\nstudy system that integrates a multimodal approach, utilizing the EmbracePlus\nwristband and a video detection system to predict AA in severe dementia\npatients. We conducted a pilot study with three participants at the Ontario\nShores Mental Health Institute to validate the functionality of the system. The\nsystem collects and processes raw and digital biomarkers from the EmbracePlus\nwristband to accurately predict AA. The system also detected pre-agitation\npatterns at least six minutes before the AA event, which was not previously\ndiscovered from the EmbracePlus wristband. Furthermore, the privacy-preserving\nvideo system uses a masking tool to hide the features of the people in frames\nand employs a deep learning model for AA detection. The video system also helps\nidentify the actual start and end time of the agitation events for labeling.\nThe promising results of the preliminary data analysis underscore the ability\nof the system to predict AA events. The ability of the proposed system to run\nautonomously in real-time and identify AA and pre-agitation symptoms without\nexternal assistance represents a significant milestone in this research field.",
      "tldr_zh": "本文提出了一种新型多模态系统，用于预测痴呆患者在临床环境中的躁动和攻击性（Agitation and Aggression, AA），旨在解决现有评估方法依赖主观报告的问题。系统整合了 EmbracePlus 腕带和视频检测技术，通过收集生物标记数据和深度学习模型，实现 AA 事件的实时预测，并在事件前至少 6 分钟检测预兆，同时采用隐私保护措施如面部掩码确保数据安全。在一项涉及三名参与者的试点研究中，该系统展示了自主运行的潜力，并为痴呆患者护理领域提供了重要里程碑式的进展。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08882v1",
      "published_date": "2024-10-26 02:59:34 UTC",
      "updated_date": "2024-10-26 02:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:05:12.294575"
    },
    {
      "arxiv_id": "2410.20050v1",
      "title": "AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Li",
        "Xiangxu Zhang",
        "Xiao Zhou",
        "Zheng Liu"
      ],
      "abstract": "Medical information retrieval (MIR) is essential for retrieving relevant\nmedical knowledge from diverse sources, including electronic health records,\nscientific literature, and medical databases. However, achieving effective\nzero-shot dense retrieval in the medical domain poses substantial challenges\ndue to the lack of relevance-labeled data. In this paper, we introduce a novel\napproach called Self-Learning Hypothetical Document Embeddings (SL-HyDE) to\ntackle this issue. SL-HyDE leverages large language models (LLMs) as generators\nto generate hypothetical documents based on a given query. These generated\ndocuments encapsulate key medical context, guiding a dense retriever in\nidentifying the most relevant documents. The self-learning framework\nprogressively refines both pseudo-document generation and retrieval, utilizing\nunlabeled medical corpora without requiring any relevance-labeled data.\nAdditionally, we present the Chinese Medical Information Retrieval Benchmark\n(CMIRB), a comprehensive evaluation framework grounded in real-world medical\nscenarios, encompassing five tasks and ten datasets. By benchmarking ten models\non CMIRB, we establish a rigorous standard for evaluating medical information\nretrieval systems. Experimental results demonstrate that SL-HyDE significantly\nsurpasses existing methods in retrieval accuracy while showcasing strong\ngeneralization and scalability across various LLM and retriever configurations.\nCMIRB data and evaluation code are publicly available at:\nhttps://github.com/CMIRB-benchmark/CMIRB.",
      "tldr_zh": "本论文提出AutoMIR，一种无需相关性标签的零-shot医疗信息检索方法，旨在解决医疗领域密集检索缺乏标注数据的挑战。核心创新是Self-Learning Hypothetical Document Embeddings (SL-HyDE)，该框架利用Large Language Models (LLMs)生成基于查询的假设文档，并通过自学习机制逐步优化伪文档生成和检索过程，仅依赖无标签医疗语料。论文还引入Chinese Medical Information Retrieval Benchmark (CMIRB)，一个涵盖五项任务和十个数据集的真实场景评估框架，并在基准测试中证明SL-HyDE在检索准确性上显著优于现有方法，并展示出强大的泛化和可扩展性。CMIRB的数据和代码已公开以促进进一步研究。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20050v1",
      "published_date": "2024-10-26 02:53:20 UTC",
      "updated_date": "2024-10-26 02:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:05:36.657766"
    },
    {
      "arxiv_id": "2410.20046v1",
      "title": "DQRM: Deep Quantized Recommendation Models",
      "title_zh": "DQRM：深度量化推荐模型",
      "authors": [
        "Yang Zhou",
        "Zhen Dong",
        "Ellick Chan",
        "Dhiraj Kalamkar",
        "Diana Marculescu",
        "Kurt Keutzer"
      ],
      "abstract": "Large-scale recommendation models are currently the dominant workload for\nmany large Internet companies. These recommenders are characterized by massive\nembedding tables that are sparsely accessed by the index for user and item\nfeatures. The size of these 1TB+ tables imposes a severe memory bottleneck for\nthe training and inference of recommendation models. In this work, we propose a\nnovel recommendation framework that is small, powerful, and efficient to run\nand train, based on the state-of-the-art Deep Learning Recommendation Model\n(DLRM). The proposed framework makes inference more efficient on the cloud\nservers, explores the possibility of deploying powerful recommenders on smaller\nedge devices, and optimizes the workload of the communication overhead in\ndistributed training under the data parallelism settings. Specifically, we show\nthat quantization-aware training (QAT) can impose a strong regularization\neffect to mitigate the severe overfitting issues suffered by DLRMs.\nConsequently, we achieved INT4 quantization of DLRM models without any accuracy\ndrop. We further propose two techniques that improve and accelerate the\nconventional QAT workload specifically for the embedding tables in the\nrecommendation models. Furthermore, to achieve efficient training, we quantize\nthe gradients of the embedding tables into INT8 on top of the well-supported\nspecified sparsification. We show that combining gradient sparsification and\nquantization together significantly reduces the amount of communication.\nBriefly, DQRM models with INT4 can achieve 79.07% accuracy on Kaggle with 0.27\nGB model size, and 81.21% accuracy on the Terabyte dataset with 1.57 GB, which\neven outperform FP32 DLRMs that have much larger model sizes (2.16 GB on Kaggle\nand 12.58 on Terabyte).",
      "tldr_zh": "该研究提出DQRM框架，一种基于DLRM的深度量化推荐模型，旨在解决大规模推荐模型的内存瓶颈问题，通过量化感知训练(QAT)实现模型小型化和高效训练。DQRM采用INT4量化来缓解过拟合，同时针对嵌入表优化QAT技术，并将梯度量化到INT8结合稀疏化，显著减少分布式训练的通信开销。实验结果显示，DQRM在Kaggle数据集上以0.27 GB模型大小达到79.07%准确率，在Terabyte数据集上以1.57 GB大小达到81.21%准确率，甚至优于更大的FP32模型。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20046v1",
      "published_date": "2024-10-26 02:33:52 UTC",
      "updated_date": "2024-10-26 02:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:05:47.320019"
    },
    {
      "arxiv_id": "2410.20037v1",
      "title": "Roles of LLMs in the Overall Mental Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Ron Sun"
      ],
      "abstract": "To better understand existing LLMs, we may examine the human mental\n(cognitive/psychological) architecture, and its components and structures.\nBased on psychological, philosophical, and cognitive science literatures, it is\nargued that, within the human mental architecture, existing LLMs correspond\nwell with implicit mental processes (intuition, instinct, and so on). However,\nbeyond such implicit processes, explicit processes (with better symbolic\ncapabilities) are also present within the human mental architecture, judging\nfrom psychological, philosophical, and cognitive science literatures. Various\ntheoretical and empirical issues and questions in this regard are explored.\nFurthermore, it is argued that existing dual-process computational cognitive\narchitectures (models of the human cognitive/psychological architecture)\nprovide usable frameworks for fundamentally enhancing LLMs by introducing dual\nprocesses (both implicit and explicit) and, in the meantime, can also be\nenhanced by LLMs. The results are synergistic combinations (in several\ndifferent senses simultaneously).",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在人类心理架构中的角色，通过心理学、哲学和认知科学文献，将LLMs 与人类隐式心理过程（如直觉和本能）进行对应分析。作者指出，人类心理架构中还存在显式过程，具有更强的符号能力，并探讨了相关理论和实证问题。论文建议，利用现有的双过程计算认知架构（dual-process computational cognitive architectures）来增强LLMs，通过整合隐式和显式过程，实现双向协同提升。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20037v1",
      "published_date": "2024-10-26 01:13:44 UTC",
      "updated_date": "2024-10-26 01:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:05:58.605827"
    },
    {
      "arxiv_id": "2410.20036v1",
      "title": "Architectural Flaw Detection in Civil Engineering Using GPT-4",
      "title_zh": "利用 GPT-4 进行土木工程中的建筑缺陷检测",
      "authors": [
        "Saket Kumar",
        "Abul Ehtesham",
        "Aditi Singh",
        "Tala Talaei Khoei"
      ],
      "abstract": "The application of artificial intelligence (AI) in civil engineering presents\na transformative approach to enhancing design quality and safety. This paper\ninvestigates the potential of the advanced LLM GPT4 Turbo vision model in\ndetecting architectural flaws during the design phase, with a specific focus on\nidentifying missing doors and windows. The study evaluates the model's\nperformance through metrics such as precision, recall, and F1 score,\ndemonstrating AI's effectiveness in accurately detecting flaws compared to\nhuman-verified data. Additionally, the research explores AI's broader\ncapabilities, including identifying load-bearing issues, material weaknesses,\nand ensuring compliance with building codes. The findings highlight how AI can\nsignificantly improve design accuracy, reduce costly revisions, and support\nsustainable practices, ultimately revolutionizing the civil engineering field\nby ensuring safer, more efficient, and aesthetically optimized structures.",
      "tldr_zh": "这篇论文探讨了使用 GPT-4 Turbo 视觉模型在土木工程设计阶段检测建筑缺陷，重点识别缺失的门和窗。研究通过精确率（precision）、召回率（recall）和 F1 score 等指标评估模型性能，并与人类验证数据比较，结果显示 AI 在检测准确性上表现出色。论文进一步扩展 AI 的应用到承重问题、材料弱点和建筑规范合规性，证明其能显著提升设计质量、减少成本修改，并支持可持续实践，从而推动土木工程领域的安全和效率革命。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20036v1",
      "published_date": "2024-10-26 01:10:04 UTC",
      "updated_date": "2024-10-26 01:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:06:11.323773"
    },
    {
      "arxiv_id": "2410.20035v1",
      "title": "Training the Untrainable: Introducing Inductive Bias via Representational Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Vighnesh Subramaniam",
        "David Mayo",
        "Colin Conwell",
        "Tomaso Poggio",
        "Boris Katz",
        "Brian Cheung",
        "Andrei Barbu"
      ],
      "abstract": "We demonstrate that architectures which traditionally are considered to be\nill-suited for a task can be trained using inductive biases from another\narchitecture. Networks are considered untrainable when they overfit, underfit,\nor converge to poor results even when tuning their hyperparameters. For\nexample, plain fully connected networks overfit on object recognition while\ndeep convolutional networks without residual connections underfit. The\ntraditional answer is to change the architecture to impose some inductive bias,\nalthough what that bias is remains unknown. We introduce guidance, where a\nguide network guides a target network using a neural distance function. The\ntarget is optimized to perform well and to match its internal representations,\nlayer-by-layer, to those of the guide; the guide is unchanged. If the guide is\ntrained, this transfers over part of the architectural prior and knowledge of\nthe guide to the target. If the guide is untrained, this transfers over only\npart of the architectural prior of the guide. In this manner, we can\ninvestigate what kinds of priors different architectures place on untrainable\nnetworks such as fully connected networks. We demonstrate that this method\novercomes the immediate overfitting of fully connected networks on vision\ntasks, makes plain CNNs competitive to ResNets, closes much of the gap between\nplain vanilla RNNs and Transformers, and can even help Transformers learn tasks\nwhich RNNs can perform more easily. We also discover evidence that better\ninitializations of fully connected networks likely exist to avoid overfitting.\nOur method provides a mathematical tool to investigate priors and\narchitectures, and in the long term, may demystify the dark art of architecture\ncreation, even perhaps turning architectures into a continuous optimizable\nparameter of the network.",
      "tldr_zh": "本研究提出了一种名为“guidance”的方法，通过“representational alignment”（代表性对齐）来引入归纳偏差，从而训练原本难以训练的网络架构，例如全连接网络的过拟合或普通CNN的欠拟合。方法涉及使用一个不变的指导网络（guide network）通过神经距离函数（neural distance function）逐层匹配目标网络（target network）的内部表示，同时优化目标网络的性能。实验结果显示，该方法显著改善了全连接网络在视觉任务上的过拟合表现，使普通CNN与ResNet竞争，并缩小了普通RNN与Transformer的性能差距，甚至帮助Transformer学习RNN更易处理的任务。该方法不仅揭示了不同架构的先验，还为架构设计提供数学工具，可能使网络架构成为可优化的连续参数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review; 24 pages, 9 figures; Project page and code is at\n  https://untrainable-networks.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.20035v1",
      "published_date": "2024-10-26 01:04:03 UTC",
      "updated_date": "2024-10-26 01:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:06:23.996803"
    },
    {
      "arxiv_id": "2410.20034v1",
      "title": "Sensor2Text: Enabling Natural Language Interactions for Daily Activity Tracking Using Wearable Sensors",
      "title_zh": "Sensor2Text：",
      "authors": [
        "Wenqiang Chen",
        "Jiaxuan Cheng",
        "Leyao Wang",
        "Wei Zhao",
        "Wojciech Matusik"
      ],
      "abstract": "Visual Question-Answering, a technology that generates textual responses from\nan image and natural language question, has progressed significantly. Notably,\nit can aid in tracking and inquiring about daily activities, crucial in\nhealthcare monitoring, especially for elderly patients or those with memory\ndisabilities. However, video poses privacy concerns and has a limited field of\nview. This paper presents Sensor2Text, a model proficient in tracking daily\nactivities and engaging in conversations using wearable sensors. The approach\noutlined here tackles several challenges, including low information density in\nwearable sensor data, insufficiency of single wearable sensors in human\nactivities recognition, and model's limited capacity for Question-Answering and\ninteractive conversations. To resolve these obstacles, transfer learning and\nstudent-teacher networks are utilized to leverage knowledge from\nvisual-language models. Additionally, an encoder-decoder neural network model\nis devised to jointly process language and sensor data for conversational\npurposes. Furthermore, Large Language Models are also utilized to enable\ninteractive capabilities. The model showcases the ability to identify human\nactivities and engage in Q\\&A dialogues using various wearable sensor\nmodalities. It performs comparably to or better than existing visual-language\nmodels in both captioning and conversational tasks. To our knowledge, this\nrepresents the first model capable of conversing about wearable sensor data,\noffering an innovative approach to daily activity tracking that addresses\nprivacy and field-of-view limitations associated with current vision-based\nsolutions.",
      "tldr_zh": "本研究提出Sensor2Text模型，利用可穿戴传感器实现日常活动跟踪的自然语言交互，解决传统Visual Question-Answering（VQA）方法的隐私和视野限制问题。模型通过转移学习和student-teacher networks从视觉语言模型中获取知识，并设计encoder-decoder neural network来联合处理语言和传感器数据，同时利用Large Language Models增强问答（Q&A）和对话能力。实验结果显示，Sensor2Text在活动识别、标题生成和对话任务中表现不亚于或优于现有视觉语言模型。总之，该模型首次实现了基于可穿戴传感器数据的交互式对话，提供了一种创新的隐私友好型活动跟踪方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20034v1",
      "published_date": "2024-10-26 01:03:13 UTC",
      "updated_date": "2024-10-26 01:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:06:37.653771"
    },
    {
      "arxiv_id": "2410.20030v1",
      "title": "SCube: Instant Large-Scale Scene Reconstruction using VoxSplats",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanchi Ren",
        "Yifan Lu",
        "Hanxue Liang",
        "Zhangjie Wu",
        "Huan Ling",
        "Mike Chen",
        "Sanja Fidler",
        "Francis Williams",
        "Jiahui Huang"
      ],
      "abstract": "We present SCube, a novel method for reconstructing large-scale 3D scenes\n(geometry, appearance, and semantics) from a sparse set of posed images. Our\nmethod encodes reconstructed scenes using a novel representation VoxSplat,\nwhich is a set of 3D Gaussians supported on a high-resolution sparse-voxel\nscaffold. To reconstruct a VoxSplat from images, we employ a hierarchical voxel\nlatent diffusion model conditioned on the input images followed by a\nfeedforward appearance prediction model. The diffusion model generates\nhigh-resolution grids progressively in a coarse-to-fine manner, and the\nappearance network predicts a set of Gaussians within each voxel. From as few\nas 3 non-overlapping input images, SCube can generate millions of Gaussians\nwith a 1024^3 voxel grid spanning hundreds of meters in 20 seconds. Past works\ntackling scene reconstruction from images either rely on per-scene optimization\nand fail to reconstruct the scene away from input views (thus requiring dense\nview coverage as input) or leverage geometric priors based on low-resolution\nmodels, which produce blurry results. In contrast, SCube leverages\nhigh-resolution sparse networks and produces sharp outputs from few views. We\nshow the superiority of SCube compared to prior art using the Waymo\nself-driving dataset on 3D reconstruction and demonstrate its applications,\nsuch as LiDAR simulation and text-to-scene generation.",
      "tldr_zh": "本研究提出 SCube，一种从少量已知姿态图像（如 3 张非重叠图像）快速重建大规模 3D 场景（包括几何、外观和语义）的方法，使用新颖的 VoxSplat 表示，该表示基于高分辨率稀疏体素支架的 3D Gaussians 集合。SCube 通过分层体素潜在扩散模型（从粗到细生成高分辨率网格）和前向外观预测模型，在 20 秒内生成覆盖数百米的 1024^3 voxel grid 和数百万高斯。相比现有方法，SCube 避免了依赖密集视图或低分辨率模型导致的模糊输出，在 Waymo 数据集上准确率和清晰度显著提升，并应用于 LiDAR 模拟和文本到场景生成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024. Project page:\n  https://research.nvidia.com/labs/toronto-ai/scube/",
      "pdf_url": "http://arxiv.org/pdf/2410.20030v1",
      "published_date": "2024-10-26 00:52:46 UTC",
      "updated_date": "2024-10-26 00:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:06:49.721907"
    },
    {
      "arxiv_id": "2410.20027v2",
      "title": "Agentic Feedback Loop Modeling Improves Recommendation and User Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shihao Cai",
        "Jizhi Zhang",
        "Keqin Bao",
        "Chongming Gao",
        "Qifan Wang",
        "Fuli Feng",
        "Xiangnan He"
      ],
      "abstract": "Large language model-based agents are increasingly applied in the\nrecommendation field due to their extensive knowledge and strong planning\ncapabilities. While prior research has primarily focused on enhancing either\nthe recommendation agent or the user agent individually, the collaborative\ninteraction between the two has often been overlooked. Towards this research\ngap, we propose a novel framework that emphasizes the feedback loop process to\nfacilitate the collaboration between the recommendation agent and the user\nagent. Specifically, the recommendation agent refines its understanding of user\npreferences by analyzing the feedback from the user agent on the item\nrecommendation. Conversely, the user agent further identifies potential user\ninterests based on the items and recommendation reasons provided by the\nrecommendation agent. This iterative process enhances the ability of both\nagents to infer user behaviors, enabling more effective item recommendations\nand more accurate user simulations. Extensive experiments on three datasets\ndemonstrate the effectiveness of the agentic feedback loop: the agentic\nfeedback loop yields an average improvement of 11.52% over the single\nrecommendation agent and 21.12% over the single user agent. Furthermore, the\nresults show that the agentic feedback loop does not exacerbate popularity or\nposition bias, which are typically amplified by the real-world feedback loop,\nhighlighting its robustness. The source code is available at\nhttps://github.com/Lanyu0303/AFL.",
      "tldr_zh": "本研究提出了一种强调代理反馈循环（Agentic Feedback Loop）的框架，以提升大型语言模型（Large Language Models）在推荐领域的表现。该框架通过让推荐代理（Recommendation Agent）分析用户代理（User Agent）的反馈来优化用户偏好理解，同时用户代理基于推荐项目和理由来识别潜在兴趣，实现两者间的迭代协作，从而改善推荐效果和用户模拟准确性。在三个数据集上的实验显示，该框架比单一推荐代理提升11.52%，比单一用户代理提升21.12%，并展示了鲁棒性，未加剧流行度或位置偏差。源代码可从https://github.com/Lanyu0303/AFL获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20027v2",
      "published_date": "2024-10-26 00:51:39 UTC",
      "updated_date": "2025-05-02 00:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:06:59.572647"
    },
    {
      "arxiv_id": "2410.20024v1",
      "title": "Beyond Fine-Tuning: Effective Strategies for Mitigating Hallucinations in Large Language Models for Data Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Rumiantsau",
        "Aliaksei Vertsel",
        "Ilya Hrytsuk",
        "Isaiah Ballah"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly important in natural\nlanguage processing, enabling advanced data analytics through natural language\nqueries. However, these models often generate \"hallucinations\"-inaccurate or\nfabricated information-that can undermine their reliability in critical\ndata-driven decision-making. Addressing the challenge of hallucinations is\nessential to improve the accuracy and trustworthiness of LLMs in processing\nnatural language queries. This research focuses on mitigating hallucinations in\nLLMs, specifically within the context of data analytics. We introduce and\nevaluate four targeted strategies: Structured Output Generation, Strict Rules\nEnforcement, System Prompt Enhancements, and Semantic Layer Integration. Our\nfindings show that these methods are more effective than traditional\nfine-tuning approaches in reducing hallucinations, offering a more reliable\nframework for deploying LLMs in natural language queries for data analytics.\nThis research demonstrates the potential of these strategies to enhance the\naccuracy of LLM-driven data queries, ensuring more dependable results in\ndata-driven environments.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在数据分析中的 hallucinations（幻觉）问题，这些不准确或虚构的信息会降低模型在数据驱动决策中的可靠性和准确性。作者引入并评估了四种针对性策略：Structured Output Generation、Strict Rules Enforcement、System Prompt Enhancements 和 Semantic Layer Integration，以缓解这些问题。结果显示，这些方法比传统的 fine-tuning 更有效，能够显著减少 hallucinations，并为 LLMs 在自然语言查询中的部署提供更可靠的框架。该研究为提升 LLM 驱动数据分析的准确性提供了实用路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20024v1",
      "published_date": "2024-10-26 00:45:42 UTC",
      "updated_date": "2024-10-26 00:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:07:12.725121"
    },
    {
      "arxiv_id": "2410.21317v1",
      "title": "MatExpert: Decomposing Materials Discovery by Mimicking Human Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Qianggang Ding",
        "Santiago Miret",
        "Bang Liu"
      ],
      "abstract": "Material discovery is a critical research area with profound implications for\nvarious industries. In this work, we introduce MatExpert, a novel framework\nthat leverages Large Language Models (LLMs) and contrastive learning to\naccelerate the discovery and design of new solid-state materials. Inspired by\nthe workflow of human materials design experts, our approach integrates three\nkey stages: retrieval, transition, and generation. First, in the retrieval\nstage, MatExpert identifies an existing material that closely matches the\ndesired criteria. Second, in the transition stage, MatExpert outlines the\nnecessary modifications to transform this material formulation to meet specific\nrequirements outlined by the initial user query. Third, in the generation\nstate, MatExpert performs detailed computations and structural generation to\ncreate new materials based on the provided information. Our experimental\nresults demonstrate that MatExpert outperforms state-of-the-art methods in\nmaterial generation tasks, achieving superior performance across various\nmetrics including validity, distribution, and stability. As such, MatExpert\nrepresents a meaningful advancement in computational material discovery using\nlangauge-based generative models.",
      "tldr_zh": "本研究引入MatExpert框架，利用Large Language Models (LLMs) 和对比学习（contrastive learning），通过模仿人类专家的工作流程来加速新固态材料的发现和设计。框架分为三个关键阶段：检索阶段识别与需求相匹配的现有材料、转换阶段概述必要的修改以满足用户查询，以及生成阶段进行详细计算和结构生成来创建新材料。实验结果表明，MatExpert在材料生成任务中优于最先进的方法，在有效性、分部和稳定性等指标上表现出色，从而推动了基于语言生成模型在计算材料发现领域的进展。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21317v1",
      "published_date": "2024-10-26 00:44:54 UTC",
      "updated_date": "2024-10-26 00:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:07:24.952940"
    },
    {
      "arxiv_id": "2410.21316v1",
      "title": "Deep Optimizer States: Towards Scalable Training of Transformer Models Using Interleaved Offloading",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Maurya",
        "Jie Ye",
        "M. Mustafa Rafique",
        "Franck Cappello",
        "Bogdan Nicolae"
      ],
      "abstract": "Transformers and large language models~(LLMs) have seen rapid adoption in all\ndomains. Their sizes have exploded to hundreds of billions of parameters and\nkeep increasing. Under these circumstances, the training of transformers is\nvery expensive and often hits a ``memory wall'', i.e., even when using 3D\nparallelism (pipeline, tensor, data) and aggregating the memory of many GPUs,\nit is still not enough to hold the necessary data structures (model parameters,\noptimizer state, gradients, activations) in GPU memory. To compensate,\nstate-of-the-art approaches offload the optimizer state, at least partially, to\nthe host memory and perform hybrid CPU-GPU computations. However, the\nmanagement of the combined host-GPU memory is often suboptimal and results in\npoor overlapping between data movements and computations. This leads to missed\nopportunities to simultaneously leverage the interconnect bandwidth and\ncomputational capabilities of CPUs and GPUs. In this paper, we leverage a key\nobservation that the interleaving of the forward, backward and update phases\ngenerate fluctuations in the GPU memory utilization, which can be exploited to\ndynamically move a part of the optimizer state between the host and the GPU\nmemory at each iteration. To this end, we design and implement \\proj, a novel\ntechnique to split the LLM into subgroups, whose update phase is scheduled on\neither the CPU or the GPU based on our proposed performance model that\naddresses the trade-off between data movement cost, acceleration on the GPUs vs\nthe CPUs, and competition for shared resources. We integrate our approach with\nDeepSpeed and demonstrate 2.5$\\times$ faster iterations over state-of-the-art\napproaches using extensive experiments.",
      "tldr_zh": "该研究针对Transformer模型和LLMs训练过程中遇到的内存壁垒问题，提出了一种Interleaved Offloading技术，通过动态移动optimizer state，利用forward、backward和update阶段的GPU内存利用率波动来优化内存管理。方法将LLM模型分成子组，并基于一个性能模型在CPU或GPU上调度更新子组，以平衡数据移动成本、计算加速和资源竞争。实验结果显示，与DeepSpeed集成后，该技术使迭代速度比现有方法提高2.5倍，从而提升了大规模Transformer模型的可扩展性训练。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21316v1",
      "published_date": "2024-10-26 00:43:59 UTC",
      "updated_date": "2024-10-26 00:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:07:37.092287"
    },
    {
      "arxiv_id": "2410.20021v2",
      "title": "Think Carefully and Check Again! Meta-Generation Unlocking LLMs for Low-Resource Cross-Lingual Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhecheng Li",
        "Yiwei Wang",
        "Bryan Hooi",
        "Yujun Cai",
        "Naifan Cheung",
        "Nanyun Peng",
        "Kai-wei Chang"
      ],
      "abstract": "Cross-lingual summarization (CLS) aims to generate a summary for the source\ntext in a different target language. Currently, instruction-tuned large\nlanguage models (LLMs) excel at various English tasks. However, unlike\nlanguages such as English, Chinese or Spanish, for those relatively\nlow-resource languages with limited usage or data, recent studies have shown\nthat LLMs' performance on CLS tasks remains unsatisfactory even with few-shot\nsettings. This raises the question: Are LLMs capable of handling cross-lingual\nsummarization tasks for low-resource languages? To resolve this question, we\nfully explore the potential of large language models on cross-lingual\nsummarization task for low-resource languages through our four-step zero-shot\nmethod: Summarization, Improvement, Translation and Refinement (SITR) with\ncorrespondingly designed prompts. We test our proposed method with multiple\nLLMs on two well-known cross-lingual summarization datasets with various\nlow-resource target languages. The results show that: i) GPT-3.5 and GPT-4\nsignificantly and consistently outperform other baselines when using our\nzero-shot SITR methods. ii) By employing our proposed method, we unlock the\npotential of LLMs, enabling them to effectively handle cross-lingual\nsummarization tasks for relatively low-resource languages.",
      "tldr_zh": "本论文探讨大型语言模型(LLMs)在低资源语言的跨语言摘要(Cross-Lingual Summarization)任务上的潜力，针对LLMs在这些语言上的表现不佳问题，提出了一种四步零样本方法SITR（Summarization, Improvement, Translation and Refinement）。该方法通过对应设计的提示，依次进行总结、改进、翻译和精炼步骤，以提升模型的生成质量。实验在多个CLS数据集上验证，GPT-3.5和GPT-4使用SITR方法显著优于基线模型，证明了这一方法能有效解锁LLMs处理低资源语言任务的能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20021v2",
      "published_date": "2024-10-26 00:39:44 UTC",
      "updated_date": "2025-03-25 05:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:07:50.066823"
    },
    {
      "arxiv_id": "2410.20018v1",
      "title": "GHIL-Glue: Hierarchical Control with Filtered Subgoal Images",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle B. Hatch",
        "Ashwin Balakrishna",
        "Oier Mees",
        "Suraj Nair",
        "Seohong Park",
        "Blake Wulfe",
        "Masha Itkina",
        "Benjamin Eysenbach",
        "Sergey Levine",
        "Thomas Kollar",
        "Benjamin Burchfiel"
      ],
      "abstract": "Image and video generative models that are pre-trained on Internet-scale data\ncan greatly increase the generalization capacity of robot learning systems.\nThese models can function as high-level planners, generating intermediate\nsubgoals for low-level goal-conditioned policies to reach. However, the\nperformance of these systems can be greatly bottlenecked by the interface\nbetween generative models and low-level controllers. For example, generative\nmodels may predict photorealistic yet physically infeasible frames that confuse\nlow-level policies. Low-level policies may also be sensitive to subtle visual\nartifacts in generated goal images. This paper addresses these two facets of\ngeneralization, providing an interface to effectively \"glue together\"\nlanguage-conditioned image or video prediction models with low-level\ngoal-conditioned policies. Our method, Generative Hierarchical Imitation\nLearning-Glue (GHIL-Glue), filters out subgoals that do not lead to task\nprogress and improves the robustness of goal-conditioned policies to generated\nsubgoals with harmful visual artifacts. We find in extensive experiments in\nboth simulated and real environments that GHIL-Glue achieves a 25% improvement\nacross several hierarchical models that leverage generative subgoals, achieving\na new state-of-the-art on the CALVIN simulation benchmark for policies using\nobservations from a single RGB camera. GHIL-Glue also outperforms other\ngeneralist robot policies across 3/4 language-conditioned manipulation tasks\ntesting zero-shot generalization in physical experiments.",
      "tldr_zh": "该论文提出 GHIL-Glue，一种层次化控制框架，用于将预训练的图像和视频生成模型与低层目标条件策略（goal-conditioned policies）有效整合，解决生成子目标时可能出现的物理不可行性和视觉伪影问题。GHIL-Glue 通过过滤不导致任务进度的子目标并增强低层策略对有害视觉伪影的鲁棒性，改善了机器人学习系统的泛化能力。在模拟和真实环境中实验表明，该方法在多种层次化模型上提升了 25% 的性能，在 CALVIN 模拟基准上使用单一 RGB 相机观察达到新状态-of-the-art，并在 4 个语言条件操作任务中超越其他通用机器人策略，实现了零-shot generalization。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Code, model checkpoints and videos can be found at\n  https://ghil-glue.github.io",
      "pdf_url": "http://arxiv.org/pdf/2410.20018v1",
      "published_date": "2024-10-26 00:32:21 UTC",
      "updated_date": "2024-10-26 00:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:08:01.184067"
    },
    {
      "arxiv_id": "2410.20017v1",
      "title": "Off-Policy Selection for Initiating Human-Centric Experimental Design",
      "title_zh": "离策略选择用于启动以人为中心的实验设计",
      "authors": [
        "Ge Gao",
        "Xi Yang",
        "Qitong Gao",
        "Song Ju",
        "Miroslav Pajic",
        "Min Chi"
      ],
      "abstract": "In human-centric tasks such as healthcare and education, the heterogeneity\namong patients and students necessitates personalized treatments and\ninstructional interventions. While reinforcement learning (RL) has been\nutilized in those tasks, off-policy selection (OPS) is pivotal to close the\nloop by offline evaluating and selecting policies without online interactions,\nyet current OPS methods often overlook the heterogeneity among participants.\nOur work is centered on resolving a pivotal challenge in human-centric systems\n(HCSs): how to select a policy to deploy when a new participant joining the\ncohort, without having access to any prior offline data collected over the\nparticipant? We introduce First-Glance Off-Policy Selection (FPS), a novel\napproach that systematically addresses participant heterogeneity through\nsub-group segmentation and tailored OPS criteria to each sub-group. By grouping\nindividuals with similar traits, FPS facilitates personalized policy selection\naligned with unique characteristics of each participant or group of\nparticipants. FPS is evaluated via two important but challenging applications,\nintelligent tutoring systems and a healthcare application for sepsis treatment\nand intervention. FPS presents significant advancement in enhancing learning\noutcomes of students and in-hospital care outcomes.",
      "tldr_zh": "该研究针对人类中心任务（如医疗和教育）中的参与者异质性问题，提出了一种新的 off-policy selection (OPS) 方法，以实现个性化策略选择，而无需在线互动或先验离线数据。论文引入 First-Glance Off-Policy Selection (FPS) 框架，通过子群分割和针对每个子群的定制 OPS 标准，将具有类似特征的个体分组，从而支持个性化政策部署。在智能辅导系统和脓毒症治疗等应用中，FPS 显著提升了学生的学习成果和患者的院内护理效果，展示了其在 reinforcement learning (RL) 领域的关键进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20017v1",
      "published_date": "2024-10-26 00:17:33 UTC",
      "updated_date": "2024-10-26 00:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:08:12.910886"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 64,
  "processed_papers_count": 64,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T17:08:27.556026"
}