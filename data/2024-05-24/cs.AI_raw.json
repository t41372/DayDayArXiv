[
  {
    "arxiv_id": "2405.15985v1",
    "title": "The Impact and Opportunities of Generative AI in Fact-Checking",
    "authors": [
      "Robert Wolfe",
      "Tanushree Mitra"
    ],
    "abstract": "Generative AI appears poised to transform white collar professions, with more\nthan 90% of Fortune 500 companies using OpenAI's flagship GPT models, which\nhave been characterized as \"general purpose technologies\" capable of effecting\nepochal changes in the economy. But how will such technologies impact\norganizations whose job is to verify and report factual information, and to\nensure the health of the information ecosystem? To investigate this question,\nwe conducted 30 interviews with N=38 participants working at 29 fact-checking\norganizations across six continents, asking about how they use generative AI\nand the opportunities and challenges they see in the technology. We found that\nuses of generative AI envisioned by fact-checkers differ based on\norganizational infrastructure, with applications for quality assurance in\nEditing, for trend analysis in Investigation, and for information literacy in\nAdvocacy. We used the TOE framework to describe participant concerns ranging\nfrom the Technological (lack of transparency), to the Organizational (resource\nconstraints), to the Environmental (uncertain and evolving policy). Building on\nthe insights of our participants, we describe value tensions between\nfact-checking and generative AI, and propose a novel Verification dimension to\nthe design space of generative models for information verification work.\nFinally, we outline an agenda for fairness, accountability, and transparency\nresearch to support the responsible use of generative AI in fact-checking.\nThroughout, we highlight the importance of human infrastructure and labor in\nproducing verified information in collaboration with AI. We expect that this\nwork will inform not only the scientific literature on fact-checking, but also\ncontribute to understanding of organizational adaptation to a powerful but\nunreliable new technology.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "To be published at the ACM Conference on Fairness, Accountability,\n  and Transparency (FAccT) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15985v1",
    "published_date": "2024-05-24 23:58:01 UTC",
    "updated_date": "2024-05-24 23:58:01 UTC"
  },
  {
    "arxiv_id": "2405.15984v4",
    "title": "Evaluating and Safeguarding the Adversarial Robustness of Retrieval-Based In-Context Learning",
    "authors": [
      "Simon Yu",
      "Jie He",
      "Pasquale Minervini",
      "Jeff Z. Pan"
    ],
    "abstract": "With the emergence of large language models, such as LLaMA and OpenAI GPT-3,\nIn-Context Learning (ICL) gained significant attention due to its effectiveness\nand efficiency. However, ICL is very sensitive to the choice, order, and\nverbaliser used to encode the demonstrations in the prompt. Retrieval-Augmented\nICL methods try to address this problem by leveraging retrievers to extract\nsemantically related examples as demonstrations. While this approach yields\nmore accurate results, its robustness against various types of adversarial\nattacks, including perturbations on test samples, demonstrations, and retrieved\ndata, remains under-explored. Our study reveals that retrieval-augmented models\ncan enhance robustness against test sample attacks, outperforming vanilla ICL\nwith a 4.87% reduction in Attack Success Rate (ASR); however, they exhibit\noverconfidence in the demonstrations, leading to a 2% increase in ASR for\ndemonstration attacks. Adversarial training can help improve the robustness of\nICL methods to adversarial attacks; however, such a training scheme can be too\ncostly in the context of LLMs. As an alternative, we introduce an effective\ntraining-free adversarial defence method, DARD, which enriches the example pool\nwith those attacked samples. We show that DARD yields improvements in\nperformance and robustness, achieving a 15% reduction in ASR over the\nbaselines. Code and data are released to encourage further research:\nhttps://github.com/simonucl/adv-retreival-icl",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024, 31 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15984v4",
    "published_date": "2024-05-24 23:56:36 UTC",
    "updated_date": "2024-10-08 18:08:40 UTC"
  },
  {
    "arxiv_id": "2405.15973v4",
    "title": "Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement",
    "authors": [
      "Xiyao Wang",
      "Jiuhai Chen",
      "Zhaoyang Wang",
      "Yuhang Zhou",
      "Yiyang Zhou",
      "Huaxiu Yao",
      "Tianyi Zhou",
      "Tom Goldstein",
      "Parminder Bhatia",
      "Furong Huang",
      "Cao Xiao"
    ],
    "abstract": "Large vision-language models (LVLMs) have achieved impressive results in\nvisual question-answering and reasoning tasks through vision instruction tuning\non specific datasets. However, there remains significant room for improvement\nin aligning visual and language modalities. Existing methods often depend on\nexternal models or data, leading to uncontrollable and unstable alignment\nresults. In this paper, we propose SIMA, a self-improvement framework that\nenhances visual and language modality alignment without external dependencies.\nSIMA leverages existing vision instruction tuning datasets to self-generate\nresponses, incorporating an in-context self-critic mechanism that constructs\npreference pairs for tuning. Crucially, our approach allows LVLMs to act as\ncritics by designing effective critic prompts, eliminating the need for\nadditional fine-tuning with external instruction data. We introduce three novel\nvisual metrics within the self-critic process to guide judgment, significantly\nimproving the accuracy of self-critic. Through extensive experiments across 14\nhallucination and comprehensive benchmarks, we demonstrate that SIMA\nsignificantly improves LVLM's performance and outperforms previous approaches,\nachieving superior modality alignment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2405.15973v4",
    "published_date": "2024-05-24 23:09:27 UTC",
    "updated_date": "2025-02-08 21:50:41 UTC"
  },
  {
    "arxiv_id": "2405.15960v1",
    "title": "Human-Centered Automation",
    "authors": [
      "Carlos Toxtli"
    ],
    "abstract": "The rapid advancement of Generative Artificial Intelligence (AI), such as\nLarge Language Models (LLMs) and Multimodal Large Language Models (MLLM), has\nthe potential to revolutionize the way we work and interact with digital\nsystems across various industries. However, the current state of software\nautomation, such as Robotic Process Automation (RPA) frameworks, often requires\ndomain expertise and lacks visibility and intuitive interfaces, making it\nchallenging for users to fully leverage these technologies. This position paper\nargues for the emerging area of Human-Centered Automation (HCA), which\nprioritizes user needs and preferences in the design and development of\nautomation systems. Drawing on empirical evidence from human-computer\ninteraction research and case studies, we highlight the importance of\nconsidering user perspectives in automation and propose a framework for\ndesigning human-centric automation solutions. The paper discusses the\nlimitations of existing automation approaches, the challenges in integrating AI\nand RPA, and the benefits of human-centered automation for productivity,\ninnovation, and democratizing access to these technologies. We emphasize the\nimportance of open-source solutions and provide examples of how HCA can empower\nindividuals and organizations in the era of rapidly progressing AI, helping\nthem remain competitive. The paper also explores pathways to achieve more\nadvanced and context-aware automation solutions. We conclude with a call to\naction for researchers and practitioners to focus on developing automation\ntechnologies that adapt to user needs, provide intuitive interfaces, and\nleverage the capabilities of high-end AI to create a more accessible and\nuser-friendly future of automation.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "12 pages, 0 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15960v1",
    "published_date": "2024-05-24 22:12:28 UTC",
    "updated_date": "2024-05-24 22:12:28 UTC"
  },
  {
    "arxiv_id": "2405.15956v1",
    "title": "CFGs: Causality Constrained Counterfactual Explanations using goal-directed ASP",
    "authors": [
      "Sopam Dasgupta",
      "Joaqu√≠n Arias",
      "Elmer Salazar",
      "Gopal Gupta"
    ],
    "abstract": "Machine learning models that automate decision-making are increasingly used\nin consequential areas such as loan approvals, pretrial bail approval, and\nhiring. Unfortunately, most of these models are black boxes, i.e., they are\nunable to reveal how they reach these prediction decisions. A need for\ntransparency demands justification for such predictions. An affected individual\nmight also desire explanations to understand why a decision was made. Ethical\nand legal considerations require informing the individual of changes in the\ninput attribute (s) that could be made to produce a desirable outcome. Our work\nfocuses on the latter problem of generating counterfactual explanations by\nconsidering the causal dependencies between features. In this paper, we present\nthe framework CFGs, CounterFactual Generation with s(CASP), which utilizes the\ngoal-directed Answer Set Programming (ASP) system s(CASP) to automatically\ngenerate counterfactual explanations from models generated by rule-based\nmachine learning algorithms in particular. We benchmark CFGs with the FOLD-SE\nmodel. Reaching the counterfactual state from the initial state is planned and\nachieved using a series of interventions. To validate our proposal, we show how\ncounterfactual explanations are computed and justified by imagining worlds\nwhere some or all factual assumptions are altered/changed. More importantly, we\nshow how CFGs navigates between these worlds, namely, go from our initial state\nwhere we obtain an undesired outcome to the imagined goal state where we obtain\nthe desired decision, taking into account the causal relationships among\nfeatures.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.04382",
    "pdf_url": "http://arxiv.org/pdf/2405.15956v1",
    "published_date": "2024-05-24 21:47:58 UTC",
    "updated_date": "2024-05-24 21:47:58 UTC"
  },
  {
    "arxiv_id": "2405.15936v1",
    "title": "Zero-Shot Spam Email Classification Using Pre-trained Large Language Models",
    "authors": [
      "Sergio Rojas-Galeano"
    ],
    "abstract": "This paper investigates the application of pre-trained large language models\n(LLMs) for spam email classification using zero-shot prompting. We evaluate the\nperformance of both open-source (Flan-T5) and proprietary LLMs (ChatGPT, GPT-4)\non the well-known SpamAssassin dataset. Two classification approaches are\nexplored: (1) truncated raw content from email subject and body, and (2)\nclassification based on summaries generated by ChatGPT. Our empirical analysis,\nleveraging the entire dataset for evaluation without further training, reveals\npromising results. Flan-T5 achieves a 90% F1-score on the truncated content\napproach, while GPT-4 reaches a 95% F1-score using summaries. While these\ninitial findings on a single dataset suggest the potential for classification\npipelines of LLM-based subtasks (e.g., summarisation and classification),\nfurther validation on diverse datasets is necessary. The high operational costs\nof proprietary models, coupled with the general inference costs of LLMs, could\nsignificantly hinder real-world deployment for spam filtering.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15936v1",
    "published_date": "2024-05-24 20:55:49 UTC",
    "updated_date": "2024-05-24 20:55:49 UTC"
  },
  {
    "arxiv_id": "2405.15928v1",
    "title": "PatchProt: Hydrophobic patch prediction using protein foundation models",
    "authors": [
      "Dea Gogishvili",
      "Emmanuel Minois-Genin",
      "Jan van Eck",
      "Sanne Abeln"
    ],
    "abstract": "Hydrophobic patches on protein surfaces play important functional roles in\nprotein-protein and protein-ligand interactions. Large hydrophobic surfaces are\nalso involved in the progression of aggregation diseases. Predicting exposed\nhydrophobic patches from a protein sequence has been shown to be a difficult\ntask. Fine-tuning foundation models allows for adapting a model to the specific\nnuances of a new task using a much smaller dataset. Additionally, multi-task\ndeep learning offers a promising solution for addressing data gaps,\nsimultaneously outperforming single-task methods. In this study, we harnessed a\nrecently released leading large language model ESM-2. Efficient fine-tuning of\nESM-2 was achieved by leveraging a recently developed parameter-efficient\nfine-tuning method. This approach enabled comprehensive training of model\nlayers without excessive parameters and without the need to include a\ncomputationally expensive multiple sequence analysis. We explored several\nrelated tasks, at local (residue) and global (protein) levels, to improve the\nrepresentation of the model. As a result, our fine-tuned ESM-2 model,\nPatchProt, cannot only predict hydrophobic patch areas but also outperforms\nexisting methods at predicting primary tasks, including secondary structure and\nsurface accessibility predictions. Importantly, our analysis shows that\nincluding related local tasks can improve predictions on more difficult global\ntasks. This research sets a new standard for sequence-based protein property\nprediction and highlights the remarkable potential of fine-tuning foundation\nmodels enriching the model representation by training over related tasks.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15928v1",
    "published_date": "2024-05-24 20:37:02 UTC",
    "updated_date": "2024-05-24 20:37:02 UTC"
  },
  {
    "arxiv_id": "2405.15908v1",
    "title": "Knowledge-Informed Auto-Penetration Testing Based on Reinforcement Learning with Reward Machine",
    "authors": [
      "Yuanliang Li",
      "Hanzheng Dai",
      "Jun Yan"
    ],
    "abstract": "Automated penetration testing (AutoPT) based on reinforcement learning (RL)\nhas proven its ability to improve the efficiency of vulnerability\nidentification in information systems. However, RL-based PT encounters several\nchallenges, including poor sampling efficiency, intricate reward specification,\nand limited interpretability. To address these issues, we propose a\nknowledge-informed AutoPT framework called DRLRM-PT, which leverages reward\nmachines (RMs) to encode domain knowledge as guidelines for training a PT\npolicy. In our study, we specifically focus on lateral movement as a PT case\nstudy and formulate it as a partially observable Markov decision process\n(POMDP) guided by RMs. We design two RMs based on the MITRE ATT\\&CK knowledge\nbase for lateral movement. To solve the POMDP and optimize the PT policy, we\nemploy the deep Q-learning algorithm with RM (DQRM). The experimental results\ndemonstrate that the DQRM agent exhibits higher training efficiency in PT\ncompared to agents without knowledge embedding. Moreover, RMs encoding more\ndetailed domain knowledge demonstrated better PT performance compared to RMs\nwith simpler knowledge.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15908v1",
    "published_date": "2024-05-24 20:05:12 UTC",
    "updated_date": "2024-05-24 20:05:12 UTC"
  },
  {
    "arxiv_id": "2405.15907v2",
    "title": "Belief-State Query Policies for User-Aligned POMDPs",
    "authors": [
      "Daniel Bramblett",
      "Siddharth Srivastava"
    ],
    "abstract": "Planning in real-world settings often entails addressing partial\nobservability while aligning with users' requirements. We present a novel\nframework for expressing users' constraints and preferences about agent\nbehavior in a partially observable setting using parameterized belief-state\nquery (BSQ) policies in the setting of goal-oriented partially observable\nMarkov decision processes (gPOMDPs). We present the first formal analysis of\nsuch constraints and prove that while the expected cost function of a\nparameterized BSQ policy w.r.t its parameters is not convex, it is piecewise\nconstant and yields an implicit discrete parameter search space that is finite\nfor finite horizons. This theoretical result leads to novel algorithms that\noptimize gPOMDP agent behavior with guaranteed user alignment. Analysis proves\nthat our algorithms converge to the optimal user-aligned behavior in the limit.\nEmpirical results show that parameterized BSQ policies provide a\ncomputationally feasible approach for user-aligned planning in partially\nobservable settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15907v2",
    "published_date": "2024-05-24 20:04:51 UTC",
    "updated_date": "2025-04-15 17:47:28 UTC"
  },
  {
    "arxiv_id": "2405.15902v1",
    "title": "Hacc-Man: An Arcade Game for Jailbreaking LLMs",
    "authors": [
      "Matheus Valentim",
      "Jeanette Falk",
      "Nanna Inie"
    ],
    "abstract": "The recent leaps in complexity and fluency of Large Language Models (LLMs)\nmean that, for the first time in human history, people can interact with\ncomputers using natural language alone. This creates monumental possibilities\nof automation and accessibility of computing, but also raises severe security\nand safety threats: When everyone can interact with LLMs, everyone can\npotentially break into the systems running LLMs. All it takes is creative use\nof language. This paper presents Hacc-Man, a game which challenges its players\nto \"jailbreak\" an LLM: subvert the LLM to output something that it is not\nintended to. Jailbreaking is at the intersection between creative problem\nsolving and LLM security. The purpose of the game is threefold: 1. To heighten\nawareness of the risks of deploying fragile LLMs in everyday systems, 2. To\nheighten people's self-efficacy in interacting with LLMs, and 3. To discover\nthe creative problem solving strategies, people deploy in this novel context.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15902v1",
    "published_date": "2024-05-24 19:55:20 UTC",
    "updated_date": "2024-05-24 19:55:20 UTC"
  },
  {
    "arxiv_id": "2405.15882v1",
    "title": "Risk Factor Identification In Osteoporosis Using Unsupervised Machine Learning Techniques",
    "authors": [
      "Mikayla Calitis"
    ],
    "abstract": "In this study, the reliability of identified risk factors associated with\nosteoporosis is investigated using a new clustering-based method on electronic\nmedical records. This study proposes utilizing a new CLustering Iterations\nFramework (CLIF) that includes an iterative clustering framework that can adapt\nany of the following three components: clustering, feature selection, and\nprincipal feature identification. The study proposes using Wasserstein distance\nto identify principal features, borrowing concepts from the optimal transport\ntheory. The study also suggests using a combination of ANOVA and ablation tests\nto select influential features from a data set. Some risk factors presented in\nexisting works are endorsed by our identified significant clusters, while the\nreliability of some other risk factors is weakened.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 10 figures, 4 algorithms",
    "pdf_url": "http://arxiv.org/pdf/2405.15882v1",
    "published_date": "2024-05-24 18:53:28 UTC",
    "updated_date": "2024-05-24 18:53:28 UTC"
  },
  {
    "arxiv_id": "2405.15881v1",
    "title": "Scaling Diffusion Mamba with Bidirectional SSMs for Efficient Image and Video Generation",
    "authors": [
      "Shentong Mo",
      "Yapeng Tian"
    ],
    "abstract": "In recent developments, the Mamba architecture, known for its selective state\nspace approach, has shown potential in the efficient modeling of long\nsequences. However, its application in image generation remains underexplored.\nTraditional diffusion transformers (DiT), which utilize self-attention blocks,\nare effective but their computational complexity scales quadratically with the\ninput length, limiting their use for high-resolution images. To address this\nchallenge, we introduce a novel diffusion architecture, Diffusion Mamba (DiM),\nwhich foregoes traditional attention mechanisms in favor of a scalable\nalternative. By harnessing the inherent efficiency of the Mamba architecture,\nDiM achieves rapid inference times and reduced computational load, maintaining\nlinear complexity with respect to sequence length. Our architecture not only\nscales effectively but also outperforms existing diffusion transformers in both\nimage and video generation tasks. The results affirm the scalability and\nefficiency of DiM, establishing a new benchmark for image and video generation\ntechniques. This work advances the field of generative models and paves the way\nfor further applications of scalable architectures.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15881v1",
    "published_date": "2024-05-24 18:50:27 UTC",
    "updated_date": "2024-05-24 18:50:27 UTC"
  },
  {
    "arxiv_id": "2405.15880v2",
    "title": "HYSYNTH: Context-Free LLM Approximation for Guiding Program Synthesis",
    "authors": [
      "Shraddha Barke",
      "Emmanuel Anaya Gonzalez",
      "Saketh Ram Kasibatla",
      "Taylor Berg-Kirkpatrick",
      "Nadia Polikarpova"
    ],
    "abstract": "Many structured prediction and reasoning tasks can be framed as program\nsynthesis problems, where the goal is to generate a program in a\ndomain-specific language (DSL) that transforms input data into the desired\noutput. Unfortunately, purely neural approaches, such as large language models\n(LLMs), often fail to produce fully correct programs in unfamiliar DSLs, while\npurely symbolic methods based on combinatorial search scale poorly to complex\nproblems. Motivated by these limitations, we introduce a hybrid approach, where\nLLM completions for a given task are used to learn a task-specific,\ncontext-free surrogate model, which is then used to guide program synthesis. We\nevaluate this hybrid approach on three domains, and show that it outperforms\nboth unguided search and direct sampling from LLMs, as well as existing program\nsynthesizers.",
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "primary_category": "cs.PL",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15880v2",
    "published_date": "2024-05-24 18:45:51 UTC",
    "updated_date": "2024-11-01 02:46:03 UTC"
  },
  {
    "arxiv_id": "2405.17485v2",
    "title": "Comet: A Communication-efficient and Performant Approximation for Private Transformer Inference",
    "authors": [
      "Xiangrui Xu",
      "Qiao Zhang",
      "Rui Ning",
      "Chunsheng Xin",
      "Hongyi Wu"
    ],
    "abstract": "The prevalent use of Transformer-like models, exemplified by ChatGPT in\nmodern language processing applications, underscores the critical need for\nenabling private inference essential for many cloud-based services reliant on\nsuch models. However, current privacy-preserving frameworks impose significant\ncommunication burden, especially for non-linear computation in Transformer\nmodel. In this paper, we introduce a novel plug-in method Comet to effectively\nreduce the communication cost without compromising the inference performance.\nWe second introduce an efficient approximation method to eliminate the heavy\ncommunication in finding good initial approximation. We evaluate our Comet on\nBert and RoBERTa models with GLUE benchmark datasets, showing up to 3.9$\\times$\nless communication and 3.5$\\times$ speedups while keep competitive model\nperformance compared to the prior art.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17485v2",
    "published_date": "2024-05-24 18:43:00 UTC",
    "updated_date": "2024-09-07 13:07:44 UTC"
  },
  {
    "arxiv_id": "2405.15871v1",
    "title": "CausalConceptTS: Causal Attributions for Time Series Classification using High Fidelity Diffusion Models",
    "authors": [
      "Juan Miguel Lopez Alcaraz",
      "Nils Strodthoff"
    ],
    "abstract": "Despite the excelling performance of machine learning models, understanding\nthe decisions of machine learning models remains a long-standing goal. While\ncommonly used attribution methods in explainable AI attempt to address this\nissue, they typically rely on associational rather than causal relationships.\nIn this study, within the context of time series classification, we introduce a\nnovel framework to assess the causal effect of concepts, i.e., predefined\nsegments within a time series, on specific classification outcomes. To achieve\nthis, we leverage state-of-the-art diffusion-based generative models to\nestimate counterfactual outcomes. Our approach compares these causal\nattributions with closely related associational attributions, both\ntheoretically and empirically. We demonstrate the insights gained by our\napproach for a diverse set of qualitatively different time series\nclassification tasks. Although causal and associational attributions might\noften share some similarities, in all cases they differ in important details,\nunderscoring the risks associated with drawing causal conclusions from\nassociational data alone. We believe that the proposed approach is widely\napplicable also in other domains, particularly where predefined segmentations\nare available, to shed some light on the limits of associational attributions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures. Source code under\n  https://github.com/AI4HealthUOL/CausalConceptTS",
    "pdf_url": "http://arxiv.org/pdf/2405.15871v1",
    "published_date": "2024-05-24 18:33:18 UTC",
    "updated_date": "2024-05-24 18:33:18 UTC"
  },
  {
    "arxiv_id": "2405.15868v2",
    "title": "LLS: Local Learning Rule for Deep Neural Networks Inspired by Neural Activity Synchronization",
    "authors": [
      "Marco Paul E. Apolinario",
      "Arani Roy",
      "Kaushik Roy"
    ],
    "abstract": "Training deep neural networks (DNNs) using traditional backpropagation (BP)\npresents challenges in terms of computational complexity and energy\nconsumption, particularly for on-device learning where computational resources\nare limited. Various alternatives to BP, including random feedback alignment,\nforward-forward, and local classifiers, have been explored to address these\nchallenges. These methods have their advantages, but they can encounter\ndifficulties when dealing with intricate visual tasks or demand considerable\ncomputational resources. In this paper, we propose a novel Local Learning rule\ninspired by neural activity Synchronization phenomena (LLS) observed in the\nbrain. LLS utilizes fixed periodic basis vectors to synchronize neuron activity\nwithin each layer, enabling efficient training without the need for additional\ntrainable parameters. We demonstrate the effectiveness of LLS and its\nvariations, LLS-M and LLS-MxM, on multiple image classification datasets,\nachieving accuracy comparable to BP with reduced computational complexity and\nminimal additional parameters. Specifically, LLS achieves comparable\nperformance with up to $300 \\times$ fewer multiply-accumulate (MAC) operations\nand half the memory requirements of BP. Furthermore, the performance of LLS on\nthe Visual Wake Word (VWW) dataset highlights its suitability for on-device\nlearning tasks, making it a promising candidate for edge hardware\nimplementations.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15868v2",
    "published_date": "2024-05-24 18:24:24 UTC",
    "updated_date": "2024-10-29 16:35:59 UTC"
  },
  {
    "arxiv_id": "2406.00030v1",
    "title": "Large Language Model Pruning",
    "authors": [
      "Hanjuan Huang",
      "Hao-Jia Song",
      "Hsing-Kuo Pao"
    ],
    "abstract": "We surely enjoy the larger the better models for their superior performance\nin the last couple of years when both the hardware and software support the\nbirth of such extremely huge models. The applied fields include text mining and\nothers. In particular, the success of LLMs on text understanding and text\ngeneration draws attention from researchers who have worked on NLP and related\nareas for years or even decades. On the side, LLMs may suffer from problems\nlike model overfitting, hallucination, and device limitation to name a few. In\nthis work, we suggest a model pruning technique specifically focused on LLMs.\nThe proposed methodology emphasizes the explainability of deep learning models.\nBy having the theoretical foundation, we obtain a trustworthy deep model so\nthat huge models with a massive number of model parameters become not quite\nnecessary. A mutual information-based estimation is adopted to find neurons\nwith redundancy to eliminate. Moreover, an estimator with well-tuned parameters\nhelps to find precise estimation to guide the pruning procedure. At the same\ntime, we also explore the difference between pruning on large-scale models vs.\npruning on small-scale models. The choice of pruning criteria is sensitive in\nsmall models but not for large-scale models. It is a novel finding through this\nwork. Overall, we demonstrate the superiority of the proposed model to the\nstate-of-the-art models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.00030v1",
    "published_date": "2024-05-24 18:22:15 UTC",
    "updated_date": "2024-05-24 18:22:15 UTC"
  },
  {
    "arxiv_id": "2405.15863v3",
    "title": "QA-MDT: Quality-aware Masked Diffusion Transformer for Enhanced Music Generation",
    "authors": [
      "Chang Li",
      "Ruoyu Wang",
      "Lijuan Liu",
      "Jun Du",
      "Yixuan Sun",
      "Zilu Guo",
      "Zhenrong Zhang",
      "Yuan Jiang",
      "Jianqing Gao",
      "Feng Ma"
    ],
    "abstract": "Text-to-music (TTM) generation, which converts textual descriptions into\naudio, opens up innovative avenues for multimedia creation. Achieving high\nquality and diversity in this process demands extensive, high-quality data,\nwhich are often scarce in available datasets. Most open-source datasets\nfrequently suffer from issues like low-quality waveforms and low text-audio\nconsistency, hindering the advancement of music generation models. To address\nthese challenges, we propose a novel quality-aware training paradigm for\ngenerating high-quality, high-musicality music from large-scale,\nquality-imbalanced datasets. Additionally, by leveraging unique properties in\nthe latent space of musical signals, we adapt and implement a masked diffusion\ntransformer (MDT) model for the TTM task, showcasing its capacity for quality\ncontrol and enhanced musicality. Furthermore, we introduce a three-stage\ncaption refinement approach to address low-quality captions' issue. Experiments\nshow state-of-the-art (SOTA) performance on benchmark datasets including\nMusicCaps and the Song-Describer Dataset with both objective and subjective\nmetrics. Demo audio samples are available at https://qa-mdt.github.io/, code\nand pretrained checkpoints are open-sourced at\nhttps://github.com/ivcylc/OpenMusic.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "2025 International Joint Conference on Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2405.15863v3",
    "published_date": "2024-05-24 18:09:27 UTC",
    "updated_date": "2025-04-29 04:06:46 UTC"
  },
  {
    "arxiv_id": "2405.15860v1",
    "title": "Free Performance Gain from Mixing Multiple Partially Labeled Samples in Multi-label Image Classification",
    "authors": [
      "Chak Fong Chong",
      "Jielong Guo",
      "Xu Yang",
      "Wei Ke",
      "Yapeng Wang"
    ],
    "abstract": "Multi-label image classification datasets are often partially labeled where\nmany labels are missing, posing a significant challenge to training accurate\ndeep classifiers. However, the powerful Mixup sample-mixing data augmentation\ncannot be well utilized to address this challenge, as it cannot perform linear\ninterpolation on the unknown labels to construct augmented samples. In this\npaper, we propose LogicMix, a Mixup variant designed for such partially labeled\ndatasets. LogicMix mixes the sample labels by logical OR so that the unknown\nlabels can be correctly mixed by utilizing OR's logical equivalences, including\nthe domination and identity laws. Unlike Mixup, which mixes exactly two\nsamples, LogicMix can mix multiple ($\\geq2$) partially labeled samples,\nconstructing visually more confused augmented samples to regularize training.\nLogicMix is more general and effective than other compared Mixup variants in\nthe experiments on various partially labeled dataset scenarios. Moreover, it is\nplug-and-play and only requires minimal computation, hence it can be easily\ninserted into existing frameworks to collaborate with other methods to improve\nmodel performance with a negligible impact on training time, as demonstrated\nthrough extensive experiments. In particular, through the collaboration of\nLogicMix, RandAugment, Curriculum Labeling, and Category-wise Fine-Tuning, we\nattain state-of-the-art performance on MS-COCO, VG-200, and Pascal VOC 2007\nbenchmarking datasets. The remarkable generality, effectiveness, collaboration,\nand simplicity suggest that LogicMix promises to be a popular and vital data\naugmentation method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15860v1",
    "published_date": "2024-05-24 18:05:09 UTC",
    "updated_date": "2024-05-24 18:05:09 UTC"
  },
  {
    "arxiv_id": "2405.15768v1",
    "title": "Canonical Variates in Wasserstein Metric Space",
    "authors": [
      "Jia Li",
      "Lin Lin"
    ],
    "abstract": "In this paper, we address the classification of instances each characterized\nnot by a singular point, but by a distribution on a vector space. We employ the\nWasserstein metric to measure distances between distributions, which are then\nused by distance-based classification algorithms such as k-nearest neighbors,\nk-means, and pseudo-mixture modeling. Central to our investigation is dimension\nreduction within the Wasserstein metric space to enhance classification\naccuracy. We introduce a novel approach grounded in the principle of maximizing\nFisher's ratio, defined as the quotient of between-class variation to\nwithin-class variation. The directions in which this ratio is maximized are\ntermed discriminant coordinates or canonical variates axes. In practice, we\ndefine both between-class and within-class variations as the average squared\ndistances between pairs of instances, with the pairs either belonging to the\nsame class or to different classes. This ratio optimization is achieved through\nan iterative algorithm, which alternates between optimal transport and\nmaximization steps within the vector space. We conduct empirical studies to\nassess the algorithm's convergence and, through experimental validation,\ndemonstrate that our dimension reduction technique substantially enhances\nclassification performance. Moreover, our method outperforms well-established\nalgorithms that operate on vector representations derived from distributional\ndata. It also exhibits robustness against variations in the distributional\nrepresentations of data clouds.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "double space 37 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15768v1",
    "published_date": "2024-05-24 17:59:21 UTC",
    "updated_date": "2024-05-24 17:59:21 UTC"
  },
  {
    "arxiv_id": "2405.15766v2",
    "title": "Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development",
    "authors": [
      "Pranab Sahoo",
      "Ayush Kumar Singh",
      "Sriparna Saha",
      "Aman Chadha",
      "Samrat Mondal"
    ],
    "abstract": "The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance,\nenhancing patient safety by identifying potential risks associated with\nmedications, facilitating early detection of adverse events, and guiding\nregulatory decision-making. Traditional ADE detection methods are reliable but\nslow, not easily adaptable to large-scale operations, and offer limited\ninformation. With the exponential increase in data sources like social media\ncontent, biomedical literature, and Electronic Medical Records (EMR),\nextracting relevant ADE-related information from these unstructured texts is\nimperative. Previous ADE mining studies have focused on text-based\nmethodologies, overlooking visual cues, limiting contextual comprehension, and\nhindering accurate interpretation. To address this gap, we present a MultiModal\nAdverse Drug Event (MMADE) detection dataset, merging ADE-related textual\ninformation with visual aids. Additionally, we introduce a framework that\nleverages the capabilities of LLMs and VLMs for ADE detection by generating\ndetailed descriptions of medical images depicting ADEs, aiding healthcare\nprofessionals in visually identifying adverse events. Using our MMADE dataset,\nwe showcase the significance of integrating visual cues from images to enhance\noverall performance. This approach holds promise for patient safety, ADE\nawareness, and healthcare accessibility, paving the way for further exploration\nin personalized healthcare.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "ACL Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15766v2",
    "published_date": "2024-05-24 17:58:42 UTC",
    "updated_date": "2024-05-27 02:55:45 UTC"
  },
  {
    "arxiv_id": "2405.15758v1",
    "title": "InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation",
    "authors": [
      "Yuchi Wang",
      "Junliang Guo",
      "Jianhong Bai",
      "Runyi Yu",
      "Tianyu He",
      "Xu Tan",
      "Xu Sun",
      "Jiang Bian"
    ],
    "abstract": "Recent talking avatar generation models have made strides in achieving\nrealistic and accurate lip synchronization with the audio, but often fall short\nin controlling and conveying detailed expressions and emotions of the avatar,\nmaking the generated video less vivid and controllable. In this paper, we\npropose a novel text-guided approach for generating emotionally expressive 2D\navatars, offering fine-grained control, improved interactivity, and\ngeneralizability to the resulting video. Our framework, named InstructAvatar,\nleverages a natural language interface to control the emotion as well as the\nfacial motion of avatars. Technically, we design an automatic annotation\npipeline to construct an instruction-video paired training dataset, equipped\nwith a novel two-branch diffusion-based generator to predict avatars with audio\nand text instructions at the same time. Experimental results demonstrate that\nInstructAvatar produces results that align well with both conditions, and\noutperforms existing methods in fine-grained emotion control, lip-sync quality,\nand naturalness. Our project page is\nhttps://wangyuchi369.github.io/InstructAvatar/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://wangyuchi369.github.io/InstructAvatar/",
    "pdf_url": "http://arxiv.org/pdf/2405.15758v1",
    "published_date": "2024-05-24 17:53:54 UTC",
    "updated_date": "2024-05-24 17:53:54 UTC"
  },
  {
    "arxiv_id": "2405.15756v4",
    "title": "Wasserstein Distances, Neuronal Entanglement, and Sparsity",
    "authors": [
      "Shashata Sawmya",
      "Linghao Kong",
      "Ilia Markov",
      "Dan Alistarh",
      "Nir Shavit"
    ],
    "abstract": "Disentangling polysemantic neurons is at the core of many current approaches\nto interpretability of large language models. Here we attempt to study how\ndisentanglement can be used to understand performance, particularly under\nweight sparsity, a leading post-training optimization technique. We suggest a\nnovel measure for estimating neuronal entanglement: the Wasserstein distance of\na neuron's output distribution to a Gaussian. Moreover, we show the existence\nof a small number of highly entangled \"Wasserstein Neurons\" in each linear\nlayer of an LLM, characterized by their highly non-Gaussian output\ndistributions, their role in mapping similar inputs to dissimilar outputs, and\ntheir significant impact on model accuracy. To study these phenomena, we\npropose a new experimental framework for disentangling polysemantic neurons.\nOur framework separates each layer's inputs to create a mixture of experts\nwhere each neuron's output is computed by a mixture of neurons of lower\nWasserstein distance, each better at maintaining accuracy when sparsified\nwithout retraining. We provide strong evidence that this is because the mixture\nof sparse experts is effectively disentangling the input-output relationship of\nindividual neurons, in particular the difficult Wasserstein neurons.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15756v4",
    "published_date": "2024-05-24 17:51:39 UTC",
    "updated_date": "2025-02-26 17:32:10 UTC"
  },
  {
    "arxiv_id": "2405.15750v2",
    "title": "Filtered Corpus Training (FiCT) Shows that Language Models can Generalize from Indirect Evidence",
    "authors": [
      "Abhinav Patil",
      "Jaap Jumelet",
      "Yu Ying Chiu",
      "Andy Lapastora",
      "Peter Shen",
      "Lexie Wang",
      "Clevis Willrich",
      "Shane Steinert-Threlkeld"
    ],
    "abstract": "This paper introduces Filtered Corpus Training, a method that trains language\nmodels (LMs) on corpora with certain linguistic constructions filtered out from\nthe training data, and uses it to measure the ability of LMs to perform\nlinguistic generalization on the basis of indirect evidence. We apply the\nmethod to both LSTM and Transformer LMs (of roughly comparable size),\ndeveloping filtered corpora that target a wide range of linguistic phenomena.\nOur results show that while transformers are better qua LMs (as measured by\nperplexity), both models perform equally and surprisingly well on linguistic\ngeneralization measures, suggesting that they are capable of generalizing from\nindirect evidence.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Forthcoming in Transactions of the Association for Computational\n  Linguistics (TACL). This is a pre-MIT Press publication version. For code and\n  trained models, see http://github.com/CLMBRs/corpus-filtering",
    "pdf_url": "http://arxiv.org/pdf/2405.15750v2",
    "published_date": "2024-05-24 17:47:20 UTC",
    "updated_date": "2024-08-06 22:29:11 UTC"
  },
  {
    "arxiv_id": "2405.15739v3",
    "title": "Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias",
    "authors": [
      "Andres Algaba",
      "Carmen Mazijn",
      "Vincent Holst",
      "Floriano Tori",
      "Sylvia Wenmackers",
      "Vincent Ginis"
    ],
    "abstract": "Citation practices are crucial in shaping the structure of scientific\nknowledge, yet they are often influenced by contemporary norms and biases. The\nemergence of Large Language Models (LLMs) introduces a new dynamic to these\npractices. Interestingly, the characteristics and potential biases of\nreferences recommended by LLMs that entirely rely on their parametric\nknowledge, and not on search or retrieval-augmented generation, remain\nunexplored. Here, we analyze these characteristics in an experiment using a\ndataset from AAAI, NeurIPS, ICML, and ICLR, published after GPT-4's knowledge\ncut-off date. In our experiment, LLMs are tasked with suggesting scholarly\nreferences for the anonymized in-text citations within these papers. Our\nfindings reveal a remarkable similarity between human and LLM citation\npatterns, but with a more pronounced high citation bias, which persists even\nafter controlling for publication year, title length, number of authors, and\nvenue. The results hold for both GPT-4, and the more capable models GPT-4o and\nClaude 3.5 where the papers are part of the training data. Additionally, we\nobserve a large consistency between the characteristics of LLM's existing and\nnon-existent generated references, indicating the model's internalization of\ncitation patterns. By analyzing citation graphs, we show that the references\nrecommended are embedded in the relevant citation context, suggesting an even\ndeeper conceptual internalization of the citation networks. While LLMs can aid\nin citation generation, they may also amplify existing biases, such as the\nMatthew effect, and introduce new ones, potentially skewing scientific\nknowledge dissemination.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.DL",
    "comment": "30 pages, 13 figures, 4 tables. Added GPT-4o and Claude 3.5 results",
    "pdf_url": "http://arxiv.org/pdf/2405.15739v3",
    "published_date": "2024-05-24 17:34:32 UTC",
    "updated_date": "2024-08-24 12:04:48 UTC"
  },
  {
    "arxiv_id": "2405.15843v1",
    "title": "SpotNet: An Image Centric, Lidar Anchored Approach To Long Range Perception",
    "authors": [
      "Louis Foucard",
      "Samar Khanna",
      "Yi Shi",
      "Chi-Kuei Liu",
      "Quinn Z Shen",
      "Thuyen Ngo",
      "Zi-Xiang Xia"
    ],
    "abstract": "In this paper, we propose SpotNet: a fast, single stage, image-centric but\nLiDAR anchored approach for long range 3D object detection. We demonstrate that\nour approach to LiDAR/image sensor fusion, combined with the joint learning of\n2D and 3D detection tasks, can lead to accurate 3D object detection with very\nsparse LiDAR support. Unlike more recent bird's-eye-view (BEV) sensor-fusion\nmethods which scale with range $r$ as $O(r^2)$, SpotNet scales as $O(1)$ with\nrange. We argue that such an architecture is ideally suited to leverage each\nsensor's strength, i.e. semantic understanding from images and accurate range\nfinding from LiDAR data. Finally we show that anchoring detections on LiDAR\npoints removes the need to regress distances, and so the architecture is able\nto transfer from 2MP to 8MP resolution images without re-training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15843v1",
    "published_date": "2024-05-24 17:25:48 UTC",
    "updated_date": "2024-05-24 17:25:48 UTC"
  },
  {
    "arxiv_id": "2405.15731v3",
    "title": "Understanding the differences in Foundation Models: Attention, State Space Models, and Recurrent Neural Networks",
    "authors": [
      "Jerome Sieber",
      "Carmen Amo Alonso",
      "Alexandre Didier",
      "Melanie N. Zeilinger",
      "Antonio Orvieto"
    ],
    "abstract": "Softmax attention is the principle backbone of foundation models for various\nartificial intelligence applications, yet its quadratic complexity in sequence\nlength can limit its inference throughput in long-context settings. To address\nthis challenge, alternative architectures such as linear attention, State Space\nModels (SSMs), and Recurrent Neural Networks (RNNs) have been considered as\nmore efficient alternatives. While connections between these approaches exist,\nsuch models are commonly developed in isolation and there is a lack of\ntheoretical understanding of the shared principles underpinning these\narchitectures and their subtle differences, greatly influencing performance and\nscalability. In this paper, we introduce the Dynamical Systems Framework (DSF),\nwhich allows a principled investigation of all these architectures in a common\nrepresentation. Our framework facilitates rigorous comparisons, providing new\ninsights on the distinctive characteristics of each model class. For instance,\nwe compare linear attention and selective SSMs, detailing their differences and\nconditions under which both are equivalent. We also provide principled\ncomparisons between softmax attention and other model classes, discussing the\ntheoretical conditions under which softmax attention can be approximated.\nAdditionally, we substantiate these new insights with empirical validations and\nmathematical arguments. This shows the DSF's potential to guide the systematic\ndevelopment of future more efficient and scalable foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15731v3",
    "published_date": "2024-05-24 17:19:57 UTC",
    "updated_date": "2024-12-08 05:25:05 UTC"
  },
  {
    "arxiv_id": "2405.19363v2",
    "title": "Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification",
    "authors": [
      "Yihe Wang",
      "Nan Huang",
      "Taida Li",
      "Yujun Yan",
      "Xiang Zhang"
    ],
    "abstract": "Medical time series (MedTS) data, such as Electroencephalography (EEG) and\nElectrocardiography (ECG), play a crucial role in healthcare, such as\ndiagnosing brain and heart diseases. Existing methods for MedTS classification\nprimarily rely on handcrafted biomarkers extraction and CNN-based models, with\nlimited exploration of transformer-based models. In this paper, we introduce\nMedformer, a multi-granularity patching transformer tailored specifically for\nMedTS classification. Our method incorporates three novel mechanisms to\nleverage the unique characteristics of MedTS: cross-channel patching to\nleverage inter-channel correlations, multi-granularity embedding for capturing\nfeatures at different scales, and two-stage (intra- and inter-granularity)\nmulti-granularity self-attention for learning features and correlations within\nand among granularities. We conduct extensive experiments on five public\ndatasets under both subject-dependent and challenging subject-independent\nsetups. Results demonstrate Medformer's superiority over 10 baselines,\nachieving top averaged ranking across five datasets on all six evaluation\nmetrics. These findings underscore the significant impact of our method on\nhealthcare applications, such as diagnosing Myocardial Infarction, Alzheimer's,\nand Parkinson's disease. We release the source code at\nhttps://github.com/DL4mHealth/Medformer.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "21 pages (15 pages main paper + 6 pages supplementary materials)",
    "pdf_url": "http://arxiv.org/pdf/2405.19363v2",
    "published_date": "2024-05-24 16:51:10 UTC",
    "updated_date": "2024-10-19 06:47:33 UTC"
  },
  {
    "arxiv_id": "2406.00029v1",
    "title": "Clustered Retrieved Augmented Generation (CRAG)",
    "authors": [
      "Simon Akesson",
      "Frances A. Santos"
    ],
    "abstract": "Providing external knowledge to Large Language Models (LLMs) is a key point\nfor using these models in real-world applications for several reasons, such as\nincorporating up-to-date content in a real-time manner, providing access to\ndomain-specific knowledge, and contributing to hallucination prevention. The\nvector database-based Retrieval Augmented Generation (RAG) approach has been\nwidely adopted to this end. Thus, any part of external knowledge can be\nretrieved and provided to some LLM as the input context. Despite RAG approach's\nsuccess, it still might be unfeasible for some applications, because the\ncontext retrieved can demand a longer context window than the size supported by\nLLM. Even when the context retrieved fits into the context window size, the\nnumber of tokens might be expressive and, consequently, impact costs and\nprocessing time, becoming impractical for most applications. To address these,\nwe propose CRAG, a novel approach able to effectively reduce the number of\nprompting tokens without degrading the quality of the response generated\ncompared to a solution using RAG. Through our experiments, we show that CRAG\ncan reduce the number of tokens by at least 46\\%, achieving more than 90\\% in\nsome cases, compared to RAG. Moreover, the number of tokens with CRAG does not\nincrease considerably when the number of reviews analyzed is higher, unlike\nRAG, where the number of tokens is almost 9x higher when there are 75 reviews\ncompared to 4 reviews.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00029v1",
    "published_date": "2024-05-24 16:36:47 UTC",
    "updated_date": "2024-05-24 16:36:47 UTC"
  },
  {
    "arxiv_id": "2405.15684v1",
    "title": "Prompt-Aware Adapter: Towards Learning Adaptive Visual Tokens for Multimodal Large Language Models",
    "authors": [
      "Yue Zhang",
      "Hehe Fan",
      "Yi Yang"
    ],
    "abstract": "To bridge the gap between vision and language modalities, Multimodal Large\nLanguage Models (MLLMs) usually learn an adapter that converts visual inputs to\nunderstandable tokens for Large Language Models (LLMs). However, most adapters\ngenerate consistent visual tokens, regardless of the specific objects of\ninterest mentioned in the prompt. Since these adapters distribute equal\nattention to every detail in the image and focus on the entire scene, they may\nincrease the cognitive load for LLMs, particularly when processing complex\nscenes. To alleviate this problem, we propose prompt-aware adapters. These\nadapters are designed with the capability to dynamically embed visual inputs\nbased on the specific focus of the prompt. Specifically, prompt-aware adapters\nutilize both global and local textual features to capture the most relevant\nvisual clues from the prompt at both coarse and fine granularity levels. This\napproach significantly enhances the ability of LLMs to understand and interpret\nvisual content. Experiments on various visual question answering tasks, such as\ncounting and position reasoning, demonstrate the effectiveness of prompt-aware\nadapters.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15684v1",
    "published_date": "2024-05-24 16:24:10 UTC",
    "updated_date": "2024-05-24 16:24:10 UTC"
  },
  {
    "arxiv_id": "2405.15683v3",
    "title": "Visual Description Grounding Reduces Hallucinations and Boosts Reasoning in LVLMs",
    "authors": [
      "Sreyan Ghosh",
      "Chandra Kiran Reddy Evuru",
      "Sonal Kumar",
      "Utkarsh Tyagi",
      "Oriol Nieto",
      "Zeyu Jin",
      "Dinesh Manocha"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) often produce responses that misalign\nwith factual information, a phenomenon known as hallucinations. While\nhallucinations are well-studied, the exact causes behind them remain\nunderexplored. In this paper, we first investigate the root causes of\nhallucinations in LVLMs. Our findings reveal that existing mitigation\ntechniques primarily reduce hallucinations for visual recognition prompts-those\nthat require simple descriptions of visual elements-but fail for cognitive\nprompts that demand deliberate reasoning. We identify the core issue as a lack\nof true visual perception in LVLMs: although they can accurately recognize\nvisual elements, they struggle to fully interpret these elements in the context\nof the input prompt and effectively link this recognition to their internal\nknowledge, which is critical for reasoning. To address this gap, we introduce\nVisual Description Grounded Decoding (VDGD), a simple, robust, and\ntraining-free method designed to enhance visual perception and improve\nreasoning capabilities in LVLMs. VDGD works by first generating a detailed\ndescription of the image and appending it as a prefix to the instruction.\nDuring response generation, tokens are sampled based on their KL divergence to\nthe description, favoring candidates with lower divergence. Experimental\nresults on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD\nconsistently outperforms existing baselines 2% - 33%. Finally, we introduce\nVaLLu, a benchmark designed for comprehensive evaluation of the cognitive\ncapabilities of LVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICLR 2025. Project: https://sreyan88.github.io/VDGD/",
    "pdf_url": "http://arxiv.org/pdf/2405.15683v3",
    "published_date": "2024-05-24 16:21:59 UTC",
    "updated_date": "2025-03-06 03:59:59 UTC"
  },
  {
    "arxiv_id": "2405.15682v4",
    "title": "The Road Less Scheduled",
    "authors": [
      "Aaron Defazio",
      "Xingyu Alice Yang",
      "Harsh Mehta",
      "Konstantin Mishchenko",
      "Ahmed Khaled",
      "Ashok Cutkosky"
    ],
    "abstract": "Existing learning rate schedules that do not require specification of the\noptimization stopping step T are greatly out-performed by learning rate\nschedules that depend on T. We propose an approach that avoids the need for\nthis stopping time by eschewing the use of schedules entirely, while exhibiting\nstate-of-the-art performance compared to schedules across a wide family of\nproblems ranging from convex problems to large-scale deep learning problems.\nOur Schedule-Free approach introduces no additional hyper-parameters over\nstandard optimizers with momentum. Our method is a direct consequence of a new\ntheory we develop that unifies scheduling and iterate averaging. An open source\nimplementation of our method is available at\nhttps://github.com/facebookresearch/schedule_free. Schedule-Free AdamW is the\ncore algorithm behind our winning entry to the MLCommons 2024 AlgoPerf\nAlgorithmic Efficiency Challenge Self-Tuning track.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15682v4",
    "published_date": "2024-05-24 16:20:46 UTC",
    "updated_date": "2024-10-29 22:40:23 UTC"
  },
  {
    "arxiv_id": "2405.15673v2",
    "title": "Consistency of Neural Causal Partial Identification",
    "authors": [
      "Jiyuan Tan",
      "Jose Blanchet",
      "Vasilis Syrgkanis"
    ],
    "abstract": "Recent progress in Neural Causal Models (NCMs) showcased how identification\nand partial identification of causal effects can be automatically carried out\nvia training of neural generative models that respect the constraints encoded\nin a given causal graph [Xia et al. 2022, Balazadeh et al. 2022]. However,\nformal consistency of these methods has only been proven for the case of\ndiscrete variables or only for linear causal models. In this work, we prove the\nconsistency of partial identification via NCMs in a general setting with both\ncontinuous and categorical variables. Further, our results highlight the impact\nof the design of the underlying neural network architecture in terms of depth\nand connectivity as well as the importance of applying Lipschitz regularization\nin the training phase. In particular, we provide a counterexample showing that\nwithout Lipschitz regularization this method may not be asymptotically\nconsistent. Our results are enabled by new results on the approximability of\nStructural Causal Models (SCMs) via neural generative models, together with an\nanalysis of the sample complexity of the resulting architectures and how that\ntranslates into an error in the constrained optimization problem that defines\nthe partial identification bounds.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "61 pages, 8 figures, accepted by Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15673v2",
    "published_date": "2024-05-24 16:12:39 UTC",
    "updated_date": "2024-11-08 04:12:13 UTC"
  },
  {
    "arxiv_id": "2405.15661v2",
    "title": "Exposing Image Classifier Shortcuts with Counterfactual Frequency (CoF) Tables",
    "authors": [
      "James Hinns",
      "David Martens"
    ],
    "abstract": "The rise of deep learning in image classification has brought unprecedented\naccuracy but also highlighted a key issue: the use of 'shortcuts' by models.\nSuch shortcuts are easy-to-learn patterns from the training data that fail to\ngeneralise to new data. Examples include the use of a copyright watermark to\nrecognise horses, snowy background to recognise huskies, or ink markings to\ndetect malignant skin lesions. The explainable AI (XAI) community has suggested\nusing instance-level explanations to detect shortcuts without external data,\nbut this requires the examination of many explanations to confirm the presence\nof such shortcuts, making it a labour-intensive process. To address these\nchallenges, we introduce Counterfactual Frequency (CoF) tables, a novel\napproach that aggregates instance-based explanations into global insights, and\nexposes shortcuts. The aggregation implies the need for some semantic concepts\nto be used in the explanations, which we solve by labelling the segments of an\nimage. We demonstrate the utility of CoF tables across several datasets,\nrevealing the shortcuts learned from them.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15661v2",
    "published_date": "2024-05-24 15:58:02 UTC",
    "updated_date": "2025-01-29 11:33:40 UTC"
  },
  {
    "arxiv_id": "2405.15658v2",
    "title": "CoHD: A Counting-Aware Hierarchical Decoding Framework for Generalized Referring Expression Segmentation",
    "authors": [
      "Zhuoyan Luo",
      "Yinghao Wu",
      "Tianheng Cheng",
      "Yong Liu",
      "Yicheng Xiao",
      "Hongfa Wang",
      "Xiao-Ping Zhang",
      "Yujiu Yang"
    ],
    "abstract": "The newly proposed Generalized Referring Expression Segmentation (GRES)\namplifies the formulation of classic RES by involving complex\nmultiple/non-target scenarios. Recent approaches address GRES by directly\nextending the well-adopted RES frameworks with object-existence identification.\nHowever, these approaches tend to encode multi-granularity object information\ninto a single representation, which makes it difficult to precisely represent\ncomprehensive objects of different granularity. Moreover, the simple binary\nobject-existence identification across all referent scenarios fails to specify\ntheir inherent differences, incurring ambiguity in object understanding. To\ntackle the above issues, we propose a \\textbf{Co}unting-Aware\n\\textbf{H}ierarchical \\textbf{D}ecoding framework (CoHD) for GRES. By\ndecoupling the intricate referring semantics into different granularity with a\nvisual-linguistic hierarchy, and dynamic aggregating it with intra- and\ninter-selection, CoHD boosts multi-granularity comprehension with the\nreciprocal benefit of the hierarchical nature. Furthermore, we incorporate the\ncounting ability by embodying multiple/single/non-target scenarios into count-\nand category-level supervision, facilitating comprehensive object perception.\nExperimental results on gRefCOCO, Ref-ZOM, R-RefCOCO, and RefCOCO benchmarks\ndemonstrate the effectiveness and rationality of CoHD which outperforms\nstate-of-the-art GRES methods by a remarkable margin. Code is available at\n\\href{https://github.com/RobertLuo1/CoHD}{here}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15658v2",
    "published_date": "2024-05-24 15:53:59 UTC",
    "updated_date": "2024-11-25 17:14:20 UTC"
  },
  {
    "arxiv_id": "2405.15642v1",
    "title": "Effective Confidence Region Prediction Using Probability Forecasters",
    "authors": [
      "David Lindsay",
      "Sian Lindsay"
    ],
    "abstract": "Confidence region prediction is a practically useful extension to the\ncommonly studied pattern recognition problem. Instead of predicting a single\nlabel, the constraint is relaxed to allow prediction of a subset of labels\ngiven a desired confidence level 1-delta. Ideally, effective region predictions\nshould be (1) well calibrated - predictive regions at confidence level 1-delta\nshould err with relative frequency at most delta and (2) be as narrow (or\ncertain) as possible. We present a simple technique to generate confidence\nregion predictions from conditional probability estimates (probability\nforecasts). We use this 'conversion' technique to generate confidence region\npredictions from probability forecasts output by standard machine learning\nalgorithms when tested on 15 multi-class datasets. Our results show that\napproximately 44% of experiments demonstrate well-calibrated confidence region\npredictions, with the K-Nearest Neighbour algorithm tending to perform\nconsistently well across all data. Our results illustrate the practical\nbenefits of effective confidence region prediction with respect to medical\ndiagnostics, where guarantees of capturing the true disease label can be given.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, originally posted in 2005",
    "pdf_url": "http://arxiv.org/pdf/2405.15642v1",
    "published_date": "2024-05-24 15:33:08 UTC",
    "updated_date": "2024-05-24 15:33:08 UTC"
  },
  {
    "arxiv_id": "2405.15640v1",
    "title": "GECKO: Generative Language Model for English, Code and Korean",
    "authors": [
      "Sungwoo Oh",
      "Donggyu Kim"
    ],
    "abstract": "We introduce GECKO, a bilingual large language model (LLM) optimized for\nKorean and English, along with programming languages. GECKO is pretrained on\nthe balanced, high-quality corpus of Korean and English employing LLaMA\narchitecture. In this report, we share the experiences of several efforts to\nbuild a better data pipeline for the corpus and to train our model. GECKO shows\ngreat efficiency in token generations for both Korean and English, despite its\nsmall size of vocabulary. We measure the performance on the representative\nbenchmarks in terms of Korean, English and Code, and it exhibits great\nperformance on KMMLU (Korean MMLU) and modest performance in English and Code,\neven with its smaller number of trained tokens compared to English-focused\nLLMs. GECKO is available to the open-source community under a permissive\nlicense. We hope our work offers a research baseline and practical insights for\nKorean LLM research. The model can be found at:\nhttps://huggingface.co/kifai/GECKO-7B",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15640v1",
    "published_date": "2024-05-24 15:30:41 UTC",
    "updated_date": "2024-05-24 15:30:41 UTC"
  },
  {
    "arxiv_id": "2406.15430v1",
    "title": "Automated Parking Planning with Vision-Based BEV Approach",
    "authors": [
      "Yuxuan Zhao"
    ],
    "abstract": "Automated Valet Parking (AVP) is a crucial component of advanced autonomous\ndriving systems, focusing on the endpoint task within the \"human-vehicle\ninteraction\" process to tackle the challenges of the \"last mile\".The perception\nmodule of the automated parking algorithm has evolved from local perception\nusing ultrasonic radar and global scenario precise map matching for\nlocalization to a high-level map-free Birds Eye View (BEV) perception\nsolution.The BEV scene places higher demands on the real-time performance and\nsafety of automated parking planning tasks. This paper proposes an improved\nautomated parking algorithm based on the A* algorithm, integrating vehicle\nkinematic models, heuristic function optimization, bidirectional search, and\nBezier curve optimization to enhance the computational speed and real-time\ncapabilities of the planning algorithm.Numerical optimization methods are\nemployed to generate the final parking trajectory, ensuring the safety of the\nparking path. The proposed approach is experimentally validated in the commonly\nused industrial CARLA-ROS joint simulation environment. Compared to traditional\nalgorithms, this approach demonstrates reduced computation time with more\nchallenging collision-risk test cases and improved performance in comfort\nmetrics.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.15430v1",
    "published_date": "2024-05-24 15:26:09 UTC",
    "updated_date": "2024-05-24 15:26:09 UTC"
  },
  {
    "arxiv_id": "2406.15429v1",
    "title": "Automatic parking planning control method based on improved A* algorithm",
    "authors": [
      "Yuxuan Zhao"
    ],
    "abstract": "As the trend of moving away from high-precision maps gradually emerges in the\nautonomous driving industry,traditional planning algorithms are gradually\nexposing some problems. To address the high real-time, high precision, and high\ntrajectory quality requirements posed by the automatic parking task under\nreal-time perceived local maps,this paper proposes an improved automatic\nparking planning algorithm based on the A* algorithm, and uses Model Predictive\nControl (MPC) as the control module for automatic parking.The algorithm\nenhances the planning real-time performance by optimizing heuristic functions,\nbinary heap optimization, and bidirectional search; it calculates the\npassability of narrow areas by dynamically loading obstacles and introduces the\nvehicle's own volume during planning; it improves trajectory quality by using\nneighborhood expansion and Bezier curve optimization methods to meet the high\ntrajectory quality requirements of the parking task. After obtaining the output\nresults of the planning algorithm, a loss function is designed according to the\ncharacteristics of the automatic parking task under local maps, and the MPC\nalgorithm is used to output control commands to drive the car along the planned\ntrajectory. This paper uses the perception results of real driving environments\nconverted into maps as planning inputs to conduct simulation tests and ablation\nexperiments on the algorithm. Experimental results show that the improved\nalgorithm proposed in this paper can effectively meet the special requirements\nof automatic parking under local maps and complete the automatic parking\nplanning and control tasks.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.15429v1",
    "published_date": "2024-05-24 15:26:07 UTC",
    "updated_date": "2024-05-24 15:26:07 UTC"
  },
  {
    "arxiv_id": "2405.15633v1",
    "title": "Less is more: Summarizing Patch Tokens for efficient Multi-Label Class-Incremental Learning",
    "authors": [
      "Thomas De Min",
      "Massimiliano Mancini",
      "St√©phane Lathuili√®re",
      "Subhankar Roy",
      "Elisa Ricci"
    ],
    "abstract": "Prompt tuning has emerged as an effective rehearsal-free technique for\nclass-incremental learning (CIL) that learns a tiny set of task-specific\nparameters (or prompts) to instruct a pre-trained transformer to learn on a\nsequence of tasks. Albeit effective, prompt tuning methods do not lend well in\nthe multi-label class incremental learning (MLCIL) scenario (where an image\ncontains multiple foreground classes) due to the ambiguity in selecting the\ncorrect prompt(s) corresponding to different foreground objects belonging to\nmultiple tasks. To circumvent this issue we propose to eliminate the prompt\nselection mechanism by maintaining task-specific pathways, which allow us to\nlearn representations that do not interact with the ones from the other tasks.\nSince independent pathways in truly incremental scenarios will result in an\nexplosion of computation due to the quadratically complex multi-head\nself-attention (MSA) operation in prompt tuning, we propose to reduce the\noriginal patch token embeddings into summarized tokens. Prompt tuning is then\napplied to these fewer summarized tokens to compute the final representation.\nOur proposed method Multi-Label class incremental learning via summarising\npAtch tokeN Embeddings (MULTI-LANE) enables learning disentangled task-specific\nrepresentations in MLCIL while ensuring fast inference. We conduct experiments\nin common benchmarks and demonstrate that our MULTI-LANE achieves a new\nstate-of-the-art in MLCIL. Additionally, we show that MULTI-LANE is also\ncompetitive in the CIL setting. Source code available at\nhttps://github.com/tdemin16/multi-lane",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at 3rd Conference on Lifelong Learning Agents (CoLLAs),\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15633v1",
    "published_date": "2024-05-24 15:18:27 UTC",
    "updated_date": "2024-05-24 15:18:27 UTC"
  },
  {
    "arxiv_id": "2405.15624v2",
    "title": "Inverse-RLignment: Large Language Model Alignment from Demonstrations through Inverse Reinforcement Learning",
    "authors": [
      "Hao Sun",
      "Mihaela van der Schaar"
    ],
    "abstract": "Aligning Large Language Models (LLMs) is crucial for enhancing their safety\nand utility. However, existing methods, primarily based on preference datasets,\nface challenges such as noisy labels, high annotation costs, and privacy\nconcerns. In this work, we introduce Alignment from Demonstrations (AfD), a\nnovel approach leveraging high-quality demonstration data to overcome these\nchallenges. We formalize AfD within a sequential decision-making framework,\nhighlighting its unique challenge of missing reward signals. Drawing insights\nfrom forward and inverse reinforcement learning, we introduce divergence\nminimization objectives for AfD. Analytically, we elucidate the mass-covering\nand mode-seeking behaviors of various approaches, explaining when and why\ncertain methods are superior. Practically, we propose a computationally\nefficient algorithm that extrapolates over a tailored reward model for AfD. We\nvalidate our key insights through experiments on the Harmless and Helpful\ntasks, demonstrating their strong empirical performance while maintaining\nsimplicity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15624v2",
    "published_date": "2024-05-24 15:13:53 UTC",
    "updated_date": "2025-01-25 11:10:39 UTC"
  },
  {
    "arxiv_id": "2405.15616v1",
    "title": "Neuromorphic dreaming: A pathway to efficient learning in artificial agents",
    "authors": [
      "Ingo Blakowski",
      "Dmitrii Zendrikov",
      "Cristiano Capone",
      "Giacomo Indiveri"
    ],
    "abstract": "Achieving energy efficiency in learning is a key challenge for artificial\nintelligence (AI) computing platforms. Biological systems demonstrate\nremarkable abilities to learn complex skills quickly and efficiently. Inspired\nby this, we present a hardware implementation of model-based reinforcement\nlearning (MBRL) using spiking neural networks (SNNs) on mixed-signal\nanalog/digital neuromorphic hardware. This approach leverages the energy\nefficiency of mixed-signal neuromorphic chips while achieving high sample\nefficiency through an alternation of online learning, referred to as the\n\"awake\" phase, and offline learning, known as the \"dreaming\" phase. The model\nproposed includes two symbiotic networks: an agent network that learns by\ncombining real and simulated experiences, and a learned world model network\nthat generates the simulated experiences. We validate the model by training the\nhardware implementation to play the Atari game Pong. We start from a baseline\nconsisting of an agent network learning without a world model and dreaming,\nwhich successfully learns to play the game. By incorporating dreaming, the\nnumber of required real game experiences are reduced significantly compared to\nthe baseline. The networks are implemented using a mixed-signal neuromorphic\nprocessor, with the readout layers trained using a computer in-the-loop, while\nthe other layers remain fixed. These results pave the way toward\nenergy-efficient neuromorphic learning systems capable of rapid learning in\nreal world applications and use-cases.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15616v1",
    "published_date": "2024-05-24 15:03:56 UTC",
    "updated_date": "2024-05-24 15:03:56 UTC"
  },
  {
    "arxiv_id": "2405.15614v1",
    "title": "Harnessing Large Language Models for Software Vulnerability Detection: A Comprehensive Benchmarking Study",
    "authors": [
      "Karl Tamberg",
      "Hayretdin Bahsi"
    ],
    "abstract": "Despite various approaches being employed to detect vulnerabilities, the\nnumber of reported vulnerabilities shows an upward trend over the years. This\nsuggests the problems are not caught before the code is released, which could\nbe caused by many factors, like lack of awareness, limited efficacy of the\nexisting vulnerability detection tools or the tools not being user-friendly. To\nhelp combat some issues with traditional vulnerability detection tools, we\npropose using large language models (LLMs) to assist in finding vulnerabilities\nin source code. LLMs have shown a remarkable ability to understand and generate\ncode, underlining their potential in code-related tasks. The aim is to test\nmultiple state-of-the-art LLMs and identify the best prompting strategies,\nallowing extraction of the best value from the LLMs. We provide an overview of\nthe strengths and weaknesses of the LLM-based approach and compare the results\nto those of traditional static analysis tools. We find that LLMs can pinpoint\nmany more issues than traditional static analysis tools, outperforming\ntraditional tools in terms of recall and F1 scores. The results should benefit\nsoftware developers and security analysts responsible for ensuring that the\ncode is free of vulnerabilities.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15614v1",
    "published_date": "2024-05-24 14:59:19 UTC",
    "updated_date": "2024-05-24 14:59:19 UTC"
  },
  {
    "arxiv_id": "2405.15613v2",
    "title": "Automatic Data Curation for Self-Supervised Learning: A Clustering-Based Approach",
    "authors": [
      "Huy V. Vo",
      "Vasil Khalidov",
      "Timoth√©e Darcet",
      "Th√©o Moutakanni",
      "Nikita Smetanin",
      "Marc Szafraniec",
      "Hugo Touvron",
      "Camille Couprie",
      "Maxime Oquab",
      "Armand Joulin",
      "Herv√© J√©gou",
      "Patrick Labatut",
      "Piotr Bojanowski"
    ],
    "abstract": "Self-supervised features are the cornerstone of modern machine learning\nsystems. They are typically pre-trained on data collections whose construction\nand curation typically require extensive human effort. This manual process has\nsome limitations similar to those encountered in supervised learning, e.g., the\ncrowd-sourced selection of data is costly and time-consuming, preventing\nscaling the dataset size. In this work, we consider the problem of automatic\ncuration of high-quality datasets for self-supervised pre-training. We posit\nthat such datasets should be large, diverse and balanced, and propose a\nclustering-based approach for building ones satisfying all these criteria. Our\nmethod involves successive and hierarchical applications of $k$-means on a\nlarge and diverse data repository to obtain clusters that distribute uniformly\namong data concepts, followed by a hierarchical, balanced sampling step from\nthese clusters. Extensive experiments on three different data domains including\nweb-based images, satellite images and text show that features trained on our\nautomatically curated datasets outperform those trained on uncurated data while\nbeing on par or better than ones trained on manually curated data. Code is\navailable at https://github.com/facebookresearch/ssl-data-curation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15613v2",
    "published_date": "2024-05-24 14:58:51 UTC",
    "updated_date": "2024-06-28 09:22:38 UTC"
  },
  {
    "arxiv_id": "2405.15598v5",
    "title": "MCDFN: Supply Chain Demand Forecasting via an Explainable Multi-Channel Data Fusion Network Model",
    "authors": [
      "Md Abrar Jahin",
      "Asef Shahriar",
      "Md Al Amin"
    ],
    "abstract": "Accurate demand forecasting is crucial for optimizing supply chain\nmanagement. Traditional methods often fail to capture complex patterns from\nseasonal variability and special events. Despite advancements in deep learning,\ninterpretable forecasting models remain a challenge. To address this, we\nintroduce the Multi-Channel Data Fusion Network (MCDFN), a hybrid architecture\nthat integrates Convolutional Neural Networks (CNN), Long Short-Term Memory\nnetworks (LSTM), and Gated Recurrent Units (GRU) to enhance predictive\nperformance by extracting spatial and temporal features from time series data.\nOur comparative benchmarking demonstrates that MCDFN outperforms seven other\ndeep-learning models, achieving superior metrics: MSE (23.5738), RMSE (4.8553),\nMAE (3.9991), and MAPE (20.1575%). Theil's U statistic of 0.1181 (U<1) of MCDFN\nindicates its superiority over the naive forecasting approach, and a 10-fold\ncross-validated statistical paired t-test with a p-value of 5% indicated no\nsignificant difference between MCDFN's predictions and actual values. We apply\nexplainable AI techniques like ShapTime and Permutation Feature Importance to\nenhance interpretability. This research advances demand forecasting\nmethodologies and offers practical guidelines for integrating MCDFN into supply\nchain systems, highlighting future research directions for scalability and\nuser-friendly deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15598v5",
    "published_date": "2024-05-24 14:30:00 UTC",
    "updated_date": "2025-03-01 19:43:45 UTC"
  },
  {
    "arxiv_id": "2405.15579v1",
    "title": "Generating density nowcasts for U.S. GDP growth with deep learning: Bayes by Backprop and Monte Carlo dropout",
    "authors": [
      "Krist√≥f N√©meth",
      "D√°niel Hadh√°zi"
    ],
    "abstract": "Recent results in the literature indicate that artificial neural networks\n(ANNs) can outperform the dynamic factor model (DFM) in terms of the accuracy\nof GDP nowcasts. Compared to the DFM, the performance advantage of these highly\nflexible, nonlinear estimators is particularly evident in periods of recessions\nand structural breaks. From the perspective of policy-makers, however, nowcasts\nare the most useful when they are conveyed with uncertainty attached to them.\nWhile the DFM and other classical time series approaches analytically derive\nthe predictive (conditional) distribution for GDP growth, ANNs can only produce\npoint nowcasts based on their default training procedure (backpropagation). To\nfill this gap, first in the literature, we adapt two different deep learning\nalgorithms that enable ANNs to generate density nowcasts for U.S. GDP growth:\nBayes by Backprop and Monte Carlo dropout. The accuracy of point nowcasts,\ndefined as the mean of the empirical predictive distribution, is evaluated\nrelative to a naive constant growth model for GDP and a benchmark DFM\nspecification. Using a 1D CNN as the underlying ANN architecture, both\nalgorithms outperform those benchmarks during the evaluation period (2012:Q1 --\n2022:Q4). Furthermore, both algorithms are able to dynamically adjust the\nlocation (mean), scale (variance), and shape (skew) of the empirical predictive\ndistribution. The results indicate that both Bayes by Backprop and Monte Carlo\ndropout can effectively augment the scope and functionality of ANNs, rendering\nthem a fully compatible and competitive alternative for classical time series\napproaches.",
    "categories": [
      "econ.EM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "econ.EM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15579v1",
    "published_date": "2024-05-24 14:06:08 UTC",
    "updated_date": "2024-05-24 14:06:08 UTC"
  },
  {
    "arxiv_id": "2405.15569v1",
    "title": "Randomized heuristic repair for large-scale multidimensional knapsack problem",
    "authors": [
      "Jean P. Martins"
    ],
    "abstract": "The multidimensional knapsack problem (MKP) is an NP-hard combinatorial\noptimization problem whose solution is determining a subset of maximum total\nprofit items that do not violate capacity constraints. Due to its hardness,\nlarge-scale MKP instances are usually a target for metaheuristics, a context in\nwhich effective feasibility maintenance strategies are crucial. In 1998, Chu\nand Beasley proposed an effective heuristic repair that is still relevant for\nrecent metaheuristics. However, due to its deterministic nature, the diversity\nof solutions such heuristic provides is insufficient for long runs. As a\nresult, the search for new solutions ceases after a while. This paper proposes\nan efficiency-based randomization strategy for the heuristic repair that\nincreases the variability of the repaired solutions without deteriorating\nquality and improves the overall results.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15569v1",
    "published_date": "2024-05-24 14:01:05 UTC",
    "updated_date": "2024-05-24 14:01:05 UTC"
  },
  {
    "arxiv_id": "2405.15568v3",
    "title": "OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code",
    "authors": [
      "Maxence Faldor",
      "Jenny Zhang",
      "Antoine Cully",
      "Jeff Clune"
    ],
    "abstract": "Open-ended and AI-generating algorithms aim to continuously generate and\nsolve increasingly complex tasks indefinitely, offering a promising path toward\nmore general intelligence. To accomplish this grand vision, learning must occur\nwithin a vast array of potential tasks. Existing approaches to automatically\ngenerating environments are constrained within manually predefined, often\nnarrow distributions of environment, limiting their ability to create any\nlearning environment. To address this limitation, we introduce a novel\nframework, OMNI-EPIC, that augments previous work in Open-endedness via Models\nof human Notions of Interestingness (OMNI) with Environments Programmed in Code\n(EPIC). OMNI-EPIC leverages foundation models to autonomously generate code\nspecifying the next learnable (i.e., not too easy or difficult for the agent's\ncurrent skill set) and interesting (e.g., worthwhile and novel) tasks.\nOMNI-EPIC generates both environments (e.g., an obstacle course) and reward\nfunctions (e.g., progress through the obstacle course quickly without touching\nred objects), enabling it, in principle, to create any simulatable learning\ntask. We showcase the explosive creativity of OMNI-EPIC, which continuously\ninnovates to suggest new, interesting learning challenges. We also highlight\nhow OMNI-EPIC can adapt to reinforcement learning agents' learning progress,\ngenerating tasks that are of suitable difficulty. Overall, OMNI-EPIC can\nendlessly create learnable and interesting environments, further propelling the\ndevelopment of self-improving AI systems and AI-Generating Algorithms. Project\nwebsite with videos: https://dub.sh/omniepic",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15568v3",
    "published_date": "2024-05-24 13:57:32 UTC",
    "updated_date": "2025-02-14 14:24:59 UTC"
  },
  {
    "arxiv_id": "2405.15564v2",
    "title": "Rethinking Independent Cross-Entropy Loss For Graph-Structured Data",
    "authors": [
      "Rui Miao",
      "Kaixiong Zhou",
      "Yili Wang",
      "Ninghao Liu",
      "Ying Wang",
      "Xin Wang"
    ],
    "abstract": "Graph neural networks (GNNs) have exhibited prominent performance in learning\ngraph-structured data. Considering node classification task, based on the i.i.d\nassumption among node labels, the traditional supervised learning simply sums\nup cross-entropy losses of the independent training nodes and applies the\naverage loss to optimize GNNs' weights. But different from other data formats,\nthe nodes are naturally connected. It is found that the independent\ndistribution modeling of node labels restricts GNNs' capability to generalize\nover the entire graph and defend adversarial attacks. In this work, we propose\na new framework, termed joint-cluster supervised learning, to model the joint\ndistribution of each node with its corresponding cluster. We learn the joint\ndistribution of node and cluster labels conditioned on their representations,\nand train GNNs with the obtained joint loss. In this way, the data-label\nreference signals extracted from the local cluster explicitly strengthen the\ndiscrimination ability on the target node. The extensive experiments\ndemonstrate that our joint-cluster supervised learning can effectively bolster\nGNNs' node classification accuracy. Furthermore, being benefited from the\nreference signals which may be free from spiteful interference, our learning\nparadigm significantly protects the node classification from being affected by\nthe adversarial attack.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15564v2",
    "published_date": "2024-05-24 13:52:41 UTC",
    "updated_date": "2024-05-27 01:42:32 UTC"
  },
  {
    "arxiv_id": "2405.15561v1",
    "title": "When Generative AI Meets Workplace Learning: Creating A Realistic & Motivating Learning Experience With A Generative PCA",
    "authors": [
      "Andreas Bucher",
      "Birgit Schenk",
      "Mateusz Dolata",
      "Gerhard Schwabe"
    ],
    "abstract": "Workplace learning is used to train employees systematically, e.g., via\ne-learning or in 1:1 training. However, this is often deemed ineffective and\ncostly. Whereas pure e-learning lacks the possibility of conversational\nexercise and personal contact, 1:1 training with human instructors involves a\nhigh level of personnel and organizational costs. Hence, pedagogical\nconversational agents (PCAs), based on generative AI, seem to compensate for\nthe disadvantages of both forms. Following Action Design Research, this paper\ndescribes an organizational communication training with a Generative PCA\n(GenPCA). The evaluation shows promising results: the agent was perceived\npositively among employees and contributed to an improvement in self-determined\nlearning. However, the integration of such agent comes not without limitations.\nWe conclude with suggestions concerning the didactical methods, which are\nsupported by a GenPCA, and possible improvements of such an agent for workplace\nlearning.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15561v1",
    "published_date": "2024-05-24 13:49:18 UTC",
    "updated_date": "2024-05-24 13:49:18 UTC"
  },
  {
    "arxiv_id": "2405.17483v1",
    "title": "Concept-based Explainable Malignancy Scoring on Pulmonary Nodules in CT Images",
    "authors": [
      "Rinat I. Dumaev",
      "Sergei A. Molodyakov",
      "Lev V. Utkin"
    ],
    "abstract": "To increase the transparency of modern computer-aided diagnosis (CAD) systems\nfor assessing the malignancy of lung nodules, an interpretable model based on\napplying the generalized additive models and the concept-based learning is\nproposed. The model detects a set of clinically significant attributes in\naddition to the final malignancy regression score and learns the association\nbetween the lung nodule attributes and a final diagnosis decision as well as\ntheir contributions into the decision. The proposed concept-based learning\nframework provides human-readable explanations in terms of different concepts\n(numerical and categorical), their values, and their contribution to the final\nprediction. Numerical experiments with the LIDC-IDRI dataset demonstrate that\nthe diagnosis results obtained using the proposed model, which explicitly\nexplores internal relationships, are in line with similar patterns observed in\nclinical practice. Additionally, the proposed model shows the competitive\nclassification and the nodule attribute scoring performance, highlighting its\npotential for effective decision-making in the lung nodule diagnosis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17483v1",
    "published_date": "2024-05-24 13:36:44 UTC",
    "updated_date": "2024-05-24 13:36:44 UTC"
  },
  {
    "arxiv_id": "2406.03199v4",
    "title": "Bayesian WeakS-to-Strong from Text Classification to Generation",
    "authors": [
      "Ziyun Cui",
      "Ziyang Zhang",
      "Guangzhi Sun",
      "Wen Wu",
      "Chao Zhang"
    ],
    "abstract": "Advances in large language models raise the question of how alignment\ntechniques will adapt as models become increasingly complex and humans will\nonly be able to supervise them weakly. Weak-to-Strong mimics such a scenario\nwhere weak model supervision attempts to harness the full capabilities of a\nmuch stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by\nexploring an ensemble of weak models which simulate the variability in human\nopinions. Confidence scores are estimated using a Bayesian approach to guide\nthe WeakS-to-Strong generalization. Furthermore, we extend the application of\nWeakS-to-Strong from text classification tasks to text generation tasks where\nmore advanced strategies are investigated for supervision. Moreover, direct\npreference optimization is applied to advance the student model's preference\nlearning, beyond the basic learning framework of teacher forcing. Results\ndemonstrate the effectiveness of the proposed approach for the reliability of a\nstrong student model, showing potential for superalignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2406.03199v4",
    "published_date": "2024-05-24 13:33:11 UTC",
    "updated_date": "2025-03-12 07:57:44 UTC"
  },
  {
    "arxiv_id": "2405.15544v1",
    "title": "Knowledge-enhanced Relation Graph and Task Sampling for Few-shot Molecular Property Prediction",
    "authors": [
      "Zeyu Wang",
      "Tianyi Jiang",
      "Yao Lu",
      "Xiaoze Bao",
      "Shanqing Yu",
      "Bin Wei",
      "Qi Xuan"
    ],
    "abstract": "Recently, few-shot molecular property prediction (FSMPP) has garnered\nincreasing attention. Despite impressive breakthroughs achieved by existing\nmethods, they often overlook the inherent many-to-many relationships between\nmolecules and properties, which limits their performance. For instance, similar\nsubstructures of molecules can inspire the exploration of new compounds.\nAdditionally, the relationships between properties can be quantified, with\nhigh-related properties providing more information in exploring the target\nproperty than those low-related. To this end, this paper proposes a novel\nmeta-learning FSMPP framework (KRGTS), which comprises the Knowledge-enhanced\nRelation Graph module and the Task Sampling module. The knowledge-enhanced\nrelation graph module constructs the molecule-property multi-relation graph\n(MPMRG) to capture the many-to-many relationships between molecules and\nproperties. The task sampling module includes a meta-training task sampler and\nan auxiliary task sampler, responsible for scheduling the meta-training process\nand sampling high-related auxiliary tasks, respectively, thereby achieving\nefficient meta-knowledge learning and reducing noise introduction. Empirically,\nextensive experiments on five datasets demonstrate the superiority of KRGTS\nover a variety of state-of-the-art methods. The code is available in\nhttps://github.com/Vencent-Won/KRGTS-public.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15544v1",
    "published_date": "2024-05-24 13:31:19 UTC",
    "updated_date": "2024-05-24 13:31:19 UTC"
  },
  {
    "arxiv_id": "2405.15521v1",
    "title": "A Preference-oriented Diversity Model Based on Mutual-information in Re-ranking for E-commerce Search",
    "authors": [
      "Huimu Wang",
      "Mingming Li",
      "Dadong Miao",
      "Songlin Wang",
      "Guoyu Tang",
      "Lin Liu",
      "Sulong Xu",
      "Jinghe Hu"
    ],
    "abstract": "Re-ranking is a process of rearranging ranking list to more effectively meet\nuser demands by accounting for the interrelationships between items. Existing\nmethods predominantly enhance the precision of search results, often at the\nexpense of diversity, leading to outcomes that may not fulfill the varied needs\nof users. Conversely, methods designed to promote diversity might compromise\nthe precision of the results, failing to satisfy the users' requirements for\naccuracy. To alleviate the above problems, this paper proposes a\nPreference-oriented Diversity Model Based on Mutual-information (PODM-MI),\nwhich consider both accuracy and diversity in the re-ranking process.\nSpecifically, PODM-MI adopts Multidimensional Gaussian distributions based on\nvariational inference to capture users' diversity preferences with uncertainty.\nThen we maximize the mutual information between the diversity preferences of\nthe users and the candidate items using the maximum variational inference lower\nbound to enhance their correlations. Subsequently, we derive a utility matrix\nbased on the correlations, enabling the adaptive ranking of items in line with\nuser preferences and establishing a balance between the aforementioned\nobjectives. Experimental results on real-world online e-commerce systems\ndemonstrate the significant improvements of PODM-MI, and we have successfully\ndeployed PODM-MI on an e-commerce search platform.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15521v1",
    "published_date": "2024-05-24 13:03:34 UTC",
    "updated_date": "2024-05-24 13:03:34 UTC"
  },
  {
    "arxiv_id": "2405.15514v1",
    "title": "On the Convexity and Reliability of the Bethe Free Energy Approximation",
    "authors": [
      "Harald Leisenberger",
      "Christian Knoll",
      "Franz Pernkopf"
    ],
    "abstract": "The Bethe free energy approximation provides an effective way for relaxing\nNP-hard problems of probabilistic inference. However, its accuracy depends on\nthe model parameters and particularly degrades if a phase transition in the\nmodel occurs. In this work, we analyze when the Bethe approximation is reliable\nand how this can be verified. We argue and show by experiment that it is mostly\naccurate if it is convex on a submanifold of its domain, the 'Bethe box'. For\nverifying its convexity, we derive two sufficient conditions that are based on\nthe definiteness properties of the Bethe Hessian matrix: the first uses the\nconcept of diagonal dominance, and the second decomposes the Bethe Hessian\nmatrix into a sum of sparse matrices and characterizes the definiteness\nproperties of the individual matrices in that sum. These theoretical results\nprovide a simple way to estimate the critical phase transition temperature of a\nmodel. As a practical contribution we propose $\\texttt{BETHE-MIN}$, a projected\nquasi-Newton method to efficiently find a minimum of the Bethe free energy.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "This work has been submitted to the Journal of Machine Learning\n  Research (JMLR) for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2405.15514v1",
    "published_date": "2024-05-24 12:57:40 UTC",
    "updated_date": "2024-05-24 12:57:40 UTC"
  },
  {
    "arxiv_id": "2405.15512v2",
    "title": "ChatGPT Code Detection: Techniques for Uncovering the Source of Code",
    "authors": [
      "Marc Oedingen",
      "Raphael C. Engelhardt",
      "Robin Denz",
      "Maximilian Hammer",
      "Wolfgang Konen"
    ],
    "abstract": "In recent times, large language models (LLMs) have made significant strides\nin generating computer code, blurring the lines between code created by humans\nand code produced by artificial intelligence (AI). As these technologies evolve\nrapidly, it is crucial to explore how they influence code generation,\nespecially given the risk of misuse in areas like higher education. This paper\nexplores this issue by using advanced classification techniques to\ndifferentiate between code written by humans and that generated by ChatGPT, a\ntype of LLM. We employ a new approach that combines powerful embedding features\n(black-box) with supervised learning algorithms - including Deep Neural\nNetworks, Random Forests, and Extreme Gradient Boosting - to achieve this\ndifferentiation with an impressive accuracy of 98%. For the successful\ncombinations, we also examine their model calibration, showing that some of the\nmodels are extremely well calibrated. Additionally, we present white-box\nfeatures and an interpretable Bayes classifier to elucidate critical\ndifferences between the code sources, enhancing the explainability and\ntransparency of our approach. Both approaches work well but provide at most\n85-88% accuracy. We also show that untrained humans solve the same task not\nbetter than random guessing. This study is crucial in understanding and\nmitigating the potential risks associated with using AI in code generation,\nparticularly in the context of higher education, software development, and\ncompetitive programming.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication in MDPI AI Journal",
    "pdf_url": "http://arxiv.org/pdf/2405.15512v2",
    "published_date": "2024-05-24 12:56:18 UTC",
    "updated_date": "2024-07-03 10:23:01 UTC"
  },
  {
    "arxiv_id": "2405.15505v1",
    "title": "Revisiting Counterfactual Regression through the Lens of Gromov-Wasserstein Information Bottleneck",
    "authors": [
      "Hao Yang",
      "Zexu Sun",
      "Hongteng Xu",
      "Xu Chen"
    ],
    "abstract": "As a promising individualized treatment effect (ITE) estimation method,\ncounterfactual regression (CFR) maps individuals' covariates to a latent space\nand predicts their counterfactual outcomes. However, the selection bias between\ncontrol and treatment groups often imbalances the two groups' latent\ndistributions and negatively impacts this method's performance. In this study,\nwe revisit counterfactual regression through the lens of information bottleneck\nand propose a novel learning paradigm called Gromov-Wasserstein information\nbottleneck (GWIB). In this paradigm, we learn CFR by maximizing the mutual\ninformation between covariates' latent representations and outcomes while\npenalizing the kernelized mutual information between the latent representations\nand the covariates. We demonstrate that the upper bound of the penalty term can\nbe implemented as a new regularizer consisting of $i)$ the fused\nGromov-Wasserstein distance between the latent representations of different\ngroups and $ii)$ the gap between the transport cost generated by the model and\nthe cross-group Gromov-Wasserstein distance between the latent representations\nand the covariates. GWIB effectively learns the CFR model through alternating\noptimization, suppressing selection bias while avoiding trivial latent\ndistributions. Experiments on ITE estimation tasks show that GWIB consistently\noutperforms state-of-the-art CFR methods. To promote the research community, we\nrelease our project at https://github.com/peteryang1031/Causal-GWIB.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.15505v1",
    "published_date": "2024-05-24 12:48:24 UTC",
    "updated_date": "2024-05-24 12:48:24 UTC"
  },
  {
    "arxiv_id": "2405.15485v1",
    "title": "Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs",
    "authors": [
      "Siyuan Guo",
      "Aniket Didolkar",
      "Nan Rosemary Ke",
      "Anirudh Goyal",
      "Ferenc Husz√°r",
      "Bernhard Sch√∂lkopf"
    ],
    "abstract": "We are beginning to see progress in language model assisted scientific\ndiscovery. Motivated by the use of LLMs as a general scientific assistant, this\npaper assesses the domain knowledge of LLMs through its understanding of\ndifferent mathematical skills required to solve problems. In particular, we\nlook at not just what the pre-trained model already knows, but how it learned\nto learn from information during in-context learning or instruction-tuning\nthrough exploiting the complex knowledge structure within mathematics.\nMotivated by the Neural Tangent Kernel (NTK), we propose \\textit{NTKEval} to\nassess changes in LLM's probability distribution via training on different\nkinds of math data. Our systematic analysis finds evidence of domain\nunderstanding during in-context learning. By contrast, certain\ninstruction-tuning leads to similar performance changes irrespective of\ntraining on different data, suggesting a lack of domain understanding across\ndifferent skills.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15485v1",
    "published_date": "2024-05-24 12:04:54 UTC",
    "updated_date": "2024-05-24 12:04:54 UTC"
  },
  {
    "arxiv_id": "2405.15476v3",
    "title": "Editable Concept Bottleneck Models",
    "authors": [
      "Lijie Hu",
      "Chenyang Ren",
      "Zhengyu Hu",
      "Hongbin Lin",
      "Cheng-Long Wang",
      "Hui Xiong",
      "Jingfeng Zhang",
      "Di Wang"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) have garnered much attention for their\nability to elucidate the prediction process through a humanunderstandable\nconcept layer. However, most previous studies focused on cases where the data,\nincluding concepts, are clean. In many scenarios, we often need to\nremove/insert some training data or new concepts from trained CBMs for reasons\nsuch as privacy concerns, data mislabelling, spurious concepts, and concept\nannotation errors. Thus, deriving efficient editable CBMs without retraining\nfrom scratch remains a challenge, particularly in large-scale applications. To\naddress these challenges, we propose Editable Concept Bottleneck Models\n(ECBMs). Specifically, ECBMs support three different levels of data removal:\nconcept-label-level, concept-level, and data-level. ECBMs enjoy mathematically\nrigorous closed-form approximations derived from influence functions that\nobviate the need for retraining. Experimental results demonstrate the\nefficiency and adaptability of our ECBMs, affirming their practical value in\nCBMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "49 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.15476v3",
    "published_date": "2024-05-24 11:55:46 UTC",
    "updated_date": "2025-02-01 12:03:52 UTC"
  },
  {
    "arxiv_id": "2405.15453v2",
    "title": "Benchmarking the Performance of Pre-trained LLMs across Urdu NLP Tasks",
    "authors": [
      "Munief Hassan Tahir",
      "Sana Shams",
      "Layba Fiaz",
      "Farah Adeeba",
      "Sarmad Hussain"
    ],
    "abstract": "Large Language Models (LLMs) pre-trained on multilingual data have\nrevolutionized natural language processing research, by transitioning from\nlanguages and task specific model pipelines to a single model adapted on a\nvariety of tasks. However majority of existing multilingual NLP benchmarks for\nLLMs provide evaluation data in only few languages with little linguistic\ndiversity. In addition these benchmarks lack quality assessment against the\nrespective state-of the art models. This study presents an in-depth examination\nof 7 prominent LLMs: GPT-3.5-turbo, Llama 2-7B-Chat, Llama 3.1-8B, Bloomz 3B,\nBloomz 7B1, Ministral-8B and Whisper (Large, medium and small variant) across\n17 tasks using 22 datasets, 13.8 hours of speech, in a zero-shot setting, and\ntheir performance against state-of-the-art (SOTA) models, has been compared and\nanalyzed. Our experiments show that SOTA models currently outperform\nencoder-decoder models in majority of Urdu NLP tasks under zero-shot settings.\nHowever, comparing Llama 3.1-8B over prior version Llama 2-7B-Chat, we can\ndeduce that with improved language coverage, LLMs can surpass these SOTA\nmodels. Our results emphasize that models with fewer parameters but richer\nlanguage-specific data, like Llama 3.1-8B, often outperform larger models with\nlower language diversity, such as GPT-3.5, in several tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15453v2",
    "published_date": "2024-05-24 11:30:37 UTC",
    "updated_date": "2024-12-31 09:13:06 UTC"
  },
  {
    "arxiv_id": "2405.15452v2",
    "title": "Leveraging Logical Rules in Knowledge Editing: A Cherry on the Top",
    "authors": [
      "Keyuan Cheng",
      "Muhammad Asif Ali",
      "Shu Yang",
      "Gang Lin",
      "Yuxuan Zhai",
      "Haoyang Fei",
      "Ke Xu",
      "Lu Yu",
      "Lijie Hu",
      "Di Wang"
    ],
    "abstract": "Multi-hop Question Answering (MQA) under knowledge editing (KE) is a key\nchallenge in Large Language Models (LLMs). While best-performing solutions in\nthis domain use a plan and solve paradigm to split a question into\nsub-questions followed by response generation, we claim that this approach is\nsub-optimal as it fails for hard to decompose questions, and it does not\nexplicitly cater to correlated knowledge updates resulting as a consequence of\nknowledge edits. This has a detrimental impact on the overall consistency of\nthe updated knowledge. To address these issues, in this paper, we propose a\nnovel framework named RULE-KE, i.e., RULE based Knowledge Editing, which is a\ncherry on the top for augmenting the performance of all existing MQA methods\nunder KE. Specifically, RULE-KE leverages rule discovery to discover a set of\nlogical rules. Then, it uses these discovered rules to update knowledge about\nfacts highly correlated with the edit. Experimental evaluation using existing\nand newly curated datasets (i.e., RKE-EVAL) shows that RULE-KE helps augment\nboth performances of parameter-based and memory-based solutions up to 92% and\n112.9%, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.15452v2",
    "published_date": "2024-05-24 11:30:00 UTC",
    "updated_date": "2024-05-27 11:24:59 UTC"
  },
  {
    "arxiv_id": "2405.15446v1",
    "title": "Mind the Gap: A Causal Perspective on Bias Amplification in Prediction & Decision-Making",
    "authors": [
      "Drago Plecko",
      "Elias Bareinboim"
    ],
    "abstract": "Investigating fairness and equity of automated systems has become a critical\nfield of inquiry. Most of the literature in fair machine learning focuses on\ndefining and achieving fairness criteria in the context of prediction, while\nnot explicitly focusing on how these predictions may be used later on in the\npipeline. For instance, if commonly used criteria, such as independence or\nsufficiency, are satisfied for a prediction score $S$ used for binary\nclassification, they need not be satisfied after an application of a simple\nthresholding operation on $S$ (as commonly used in practice). In this paper, we\ntake an important step to address this issue in numerous statistical and causal\nnotions of fairness. We introduce the notion of a margin complement, which\nmeasures how much a prediction score $S$ changes due to a thresholding\noperation. We then demonstrate that the marginal difference in the optimal 0/1\npredictor $\\widehat Y$ between groups, written $P(\\hat y \\mid x_1) - P(\\hat y\n\\mid x_0)$, can be causally decomposed into the influences of $X$ on the\n$L_2$-optimal prediction score $S$ and the influences of $X$ on the margin\ncomplement $M$, along different causal pathways (direct, indirect, spurious).\nWe then show that under suitable causal assumptions, the influences of $X$ on\nthe prediction score $S$ are equal to the influences of $X$ on the true outcome\n$Y$. This yields a new decomposition of the disparity in the predictor\n$\\widehat Y$ that allows us to disentangle causal differences inherited from\nthe true outcome $Y$ that exists in the real world vs. those coming from the\noptimization procedure itself. This observation highlights the need for more\nregulatory oversight due to the potential for bias amplification, and to\naddress this issue we introduce new notions of weak and strong business\nnecessity, together with an algorithm for assessing whether these notions are\nsatisfied.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15446v1",
    "published_date": "2024-05-24 11:22:19 UTC",
    "updated_date": "2024-05-24 11:22:19 UTC"
  },
  {
    "arxiv_id": "2405.15444v4",
    "title": "HINT: Hypernetwork Approach to Training Weight Interval Regions in Continual Learning",
    "authors": [
      "Patryk Krukowski",
      "Anna Bielawska",
      "Kamil KsiƒÖ≈ºek",
      "Pawe≈Ç Wawrzy≈Ñski",
      "Pawe≈Ç Batorski",
      "Przemys≈Çaw Spurek"
    ],
    "abstract": "Recently, a new Continual Learning (CL) paradigm was presented to control\ncatastrophic forgetting, called Interval Continual Learning (InterContiNet),\nwhich relies on enforcing interval constraints on the neural network parameter\nspace. Unfortunately, InterContiNet training is challenging due to the high\ndimensionality of the weight space, making intervals difficult to manage. To\naddress this issue, we introduce HINT, a technique that employs interval\narithmetic within the embedding space and utilizes a hypernetwork to map these\nintervals to the target network parameter space. We train interval embeddings\nfor consecutive tasks and train a hypernetwork to transform these embeddings\ninto weights of the target network. An embedding for a given task is trained\nalong with the hypernetwork, preserving the response of the target network for\nthe previous task embeddings. Interval arithmetic works with a more manageable,\nlower-dimensional embedding space rather than directly preparing intervals in a\nhigh-dimensional weight space. Our model allows faster and more efficient\ntraining. Furthermore, HINT maintains the guarantee of not forgetting. At the\nend of training, we can choose one universal embedding to produce a single\nnetwork dedicated to all tasks. In such a framework, hypernetwork is used only\nfor training and, finally, we can utilize one set of weights. HINT obtains\nsignificantly better results than InterContiNet and gives SOTA results on\nseveral benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15444v4",
    "published_date": "2024-05-24 11:20:41 UTC",
    "updated_date": "2025-05-06 11:52:21 UTC"
  },
  {
    "arxiv_id": "2405.15443v2",
    "title": "Fairness-Accuracy Trade-Offs: A Causal Perspective",
    "authors": [
      "Drago Plecko",
      "Elias Bareinboim"
    ],
    "abstract": "Systems based on machine learning may exhibit discriminatory behavior based\non sensitive characteristics such as gender, sex, religion, or race. In light\nof this, various notions of fairness and methods to quantify discrimination\nwere proposed, leading to the development of numerous approaches for\nconstructing fair predictors. At the same time, imposing fairness constraints\nmay decrease the utility of the decision-maker, highlighting a tension between\nfairness and utility. This tension is also recognized in legal frameworks, for\ninstance in the disparate impact doctrine of Title VII of the Civil Rights Act\nof 1964 -- in which specific attention is given to considerations of business\nnecessity -- possibly allowing the usage of proxy variables associated with the\nsensitive attribute in case a high-enough utility cannot be achieved without\nthem. In this work, we analyze the tension between fairness and accuracy from a\ncausal lens for the first time. We introduce the notion of a path-specific\nexcess loss (PSEL) that captures how much the predictor's loss increases when a\ncausal fairness constraint is enforced. We then show that the total excess loss\n(TEL), defined as the difference between the loss of predictor fair along all\ncausal pathways vs. an unconstrained predictor, can be decomposed into a sum of\nmore local PSELs. At the same time, enforcing a causal constraint often reduces\nthe disparity between demographic groups. Thus, we introduce a quantity that\nsummarizes the fairness-utility trade-off, called the causal fairness/utility\nratio, defined as the ratio of the reduction in discrimination vs. the excess\nloss from constraining a causal pathway. This quantity is suitable for\ncomparing the fairness-utility trade-off across causal pathways. Finally, as\nour approach requires causally-constrained fair predictors, we introduce a new\nneural approach for causally-constrained fair learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15443v2",
    "published_date": "2024-05-24 11:19:52 UTC",
    "updated_date": "2024-12-20 09:47:48 UTC"
  },
  {
    "arxiv_id": "2405.15439v1",
    "title": "Text-guided 3D Human Motion Generation with Keyframe-based Parallel Skip Transformer",
    "authors": [
      "Zichen Geng",
      "Caren Han",
      "Zeeshan Hayder",
      "Jian Liu",
      "Mubarak Shah",
      "Ajmal Mian"
    ],
    "abstract": "Text-driven human motion generation is an emerging task in animation and\nhumanoid robot design. Existing algorithms directly generate the full sequence\nwhich is computationally expensive and prone to errors as it does not pay\nspecial attention to key poses, a process that has been the cornerstone of\nanimation for decades. We propose KeyMotion, that generates plausible human\nmotion sequences corresponding to input text by first generating keyframes\nfollowed by in-filling. We use a Variational Autoencoder (VAE) with\nKullback-Leibler regularization to project the keyframes into a latent space to\nreduce dimensionality and further accelerate the subsequent diffusion process.\nFor the reverse diffusion, we propose a novel Parallel Skip Transformer that\nperforms cross-modal attention between the keyframe latents and text condition.\nTo complete the motion sequence, we propose a text-guided Transformer designed\nto perform motion-in-filling, ensuring the preservation of both fidelity and\nadherence to the physical constraints of human motion. Experiments show that\nour method achieves state-of-theart results on the HumanML3D dataset\noutperforming others on all R-precision metrics and MultiModal Distance.\nKeyMotion also achieves competitive performance on the KIT dataset, achieving\nthe best results on Top3 R-precision, FID, and Diversity metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15439v1",
    "published_date": "2024-05-24 11:12:37 UTC",
    "updated_date": "2024-05-24 11:12:37 UTC"
  },
  {
    "arxiv_id": "2405.15436v1",
    "title": "Hybrid Context Retrieval Augmented Generation Pipeline: LLM-Augmented Knowledge Graphs and Vector Database for Accreditation Reporting Assistance",
    "authors": [
      "Candace Edwards"
    ],
    "abstract": "In higher education, accreditation is a quality assurance process, where an\ninstitution demonstrates a commitment to delivering high quality programs and\nservices to their students. For business schools nationally and internationally\nthe Association to Advance Collegiate Schools of Business (AACSB) accreditation\nis the gold standard. For a business school to receive and subsequently\nmaintain accreditation, the school must undertake a rigorous, time consuming\nreporting and peer review process, to demonstrate alignment with the AACSB\nStandards. For this project we create a hybrid context retrieval augmented\ngeneration pipeline that can assist in the documentation alignment and\nreporting process necessary for accreditation. We implement both a vector\ndatabase and knowledge graph, as knowledge stores containing both institutional\ndata and AACSB Standard data. The output of the pipeline can be used by\ninstitution stakeholders to build their accreditation report, dually grounded\nby the context from the knowledge stores. To develop our knowledge graphs we\nutilized both a manual construction process as well as an LLM Augmented\nKnowledge Graph approach. We evaluated the pipeline using the RAGAs framework\nand observed optimal performance on answer relevancy and answer correctness\nmetrics.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "17 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15436v1",
    "published_date": "2024-05-24 11:05:45 UTC",
    "updated_date": "2024-05-24 11:05:45 UTC"
  },
  {
    "arxiv_id": "2405.15414v1",
    "title": "Luban: Building Open-Ended Creative Agents via Autonomous Embodied Verification",
    "authors": [
      "Yuxuan Guo",
      "Shaohui Peng",
      "Jiaming Guo",
      "Di Huang",
      "Xishan Zhang",
      "Rui Zhang",
      "Yifan Hao",
      "Ling Li",
      "Zikang Tian",
      "Mingju Gao",
      "Yutai Li",
      "Yiming Gan",
      "Shuai Liang",
      "Zihao Zhang",
      "Zidong Du",
      "Qi Guo",
      "Xing Hu",
      "Yunji Chen"
    ],
    "abstract": "Building open agents has always been the ultimate goal in AI research, and\ncreative agents are the more enticing. Existing LLM agents excel at\nlong-horizon tasks with well-defined goals (e.g., `mine diamonds' in\nMinecraft). However, they encounter difficulties on creative tasks with open\ngoals and abstract criteria due to the inability to bridge the gap between\nthem, thus lacking feedback for self-improvement in solving the task. In this\nwork, we introduce autonomous embodied verification techniques for agents to\nfill the gap, laying the groundwork for creative tasks. Specifically, we\npropose the Luban agent target creative building tasks in Minecraft, which\nequips with two-level autonomous embodied verification inspired by human design\npractices: (1) visual verification of 3D structural speculates, which comes\nfrom agent synthesized CAD modeling programs; (2) pragmatic verification of the\ncreation by generating and verifying environment-relevant functionality\nprograms based on the abstract criteria. Extensive multi-dimensional human\nstudies and Elo ratings show that the Luban completes diverse creative building\ntasks in our proposed benchmark and outperforms other baselines ($33\\%$ to\n$100\\%$) in both visualization and pragmatism. Additional demos on the\nreal-world robotic arm show the creation potential of the Luban in the physical\nworld.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15414v1",
    "published_date": "2024-05-24 10:25:59 UTC",
    "updated_date": "2024-05-24 10:25:59 UTC"
  },
  {
    "arxiv_id": "2405.15412v2",
    "title": "Data-driven Global Ocean Modeling for Seasonal to Decadal Prediction",
    "authors": [
      "Zijie Guo",
      "Pumeng Lyu",
      "Fenghua Ling",
      "Lei Bai",
      "Jing-Jia Luo",
      "Niklas Boers",
      "Toshio Yamagata",
      "Takeshi Izumo",
      "Sophie Cravatte",
      "Antonietta Capotondi",
      "Wanli Ouyang"
    ],
    "abstract": "Accurate ocean dynamics modeling is crucial for enhancing understanding of\nocean circulation, predicting climate variability, and tackling challenges\nposed by climate change. Despite improvements in traditional numerical models,\npredicting global ocean variability over multi-year scales remains challenging.\nHere, we propose ORCA-DL (Oceanic Reliable foreCAst via Deep Learning), the\nfirst data-driven 3D ocean model for seasonal to decadal prediction of global\nocean circulation. ORCA-DL accurately simulates three-dimensional ocean\ndynamics and outperforms state-of-the-art dynamical models in capturing extreme\nevents, including El Ni\\~no-Southern Oscillation and upper ocean heatwaves.\nThis demonstrates the high potential of data-driven models for efficient and\naccurate global ocean forecasting. Moreover, ORCA-DL stably emulates ocean\ndynamics at decadal timescales, demonstrating its potential even for skillful\ndecadal predictions and climate projections.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15412v2",
    "published_date": "2024-05-24 10:23:17 UTC",
    "updated_date": "2024-10-29 06:06:10 UTC"
  },
  {
    "arxiv_id": "2407.13053v1",
    "title": "E2Vec: Feature Embedding with Temporal Information for Analyzing Student Actions in E-Book Systems",
    "authors": [
      "Yuma Miyazaki",
      "Valdemar ≈†v√°bensk√Ω",
      "Yuta Taniguchi",
      "Fumiya Okubo",
      "Tsubasa Minematsu",
      "Atsushi Shimada"
    ],
    "abstract": "Digital textbook (e-book) systems record student interactions with textbooks\nas a sequence of events called EventStream data. In the past, researchers\nextracted meaningful features from EventStream, and utilized them as inputs for\ndownstream tasks such as grade prediction and modeling of student behavior.\nPrevious research evaluated models that mainly used statistical-based features\nderived from EventStream logs, such as the number of operation types or access\nfrequencies. While these features are useful for providing certain insights,\nthey lack temporal information that captures fine-grained differences in\nlearning behaviors among different students. This study proposes E2Vec, a novel\nfeature representation method based on word embeddings. The proposed method\nregards operation logs and their time intervals for each student as a string\nsequence of characters and generates a student vector of learning activity\nfeatures that incorporates time information. We applied fastText to generate an\nembedding vector for each of 305 students in a dataset from two years of\ncomputer science courses. Then, we investigated the effectiveness of E2Vec in\nan at-risk detection task, demonstrating potential for generalizability and\nperformance.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Published in proceedings of the 17th Educational Data Mining\n  Conference (EDM 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.13053v1",
    "published_date": "2024-05-24 10:17:43 UTC",
    "updated_date": "2024-05-24 10:17:43 UTC"
  },
  {
    "arxiv_id": "2405.15398v1",
    "title": "PriCE: Privacy-Preserving and Cost-Effective Scheduling for Parallelizing the Large Medical Image Processing Workflow over Hybrid Clouds",
    "authors": [
      "Yuandou Wang",
      "Neel Kanwal",
      "Kjersti Engan",
      "Chunming Rong",
      "Paola Grosso",
      "Zhiming Zhao"
    ],
    "abstract": "Running deep neural networks for large medical images is a resource-hungry\nand time-consuming task with centralized computing. Outsourcing such medical\nimage processing tasks to hybrid clouds has benefits, such as a significant\nreduction of execution time and monetary cost. However, due to privacy\nconcerns, it is still challenging to process sensitive medical images over\nclouds, which would hinder their deployment in many real-world applications. To\novercome this, we first formulate the overall optimization objectives of the\nprivacy-preserving distributed system model, i.e., minimizing the amount of\ninformation about the private data learned by the adversaries throughout the\nprocess, reducing the maximum execution time and cost under the user budget\nconstraint. We propose a novel privacy-preserving and cost-effective method\ncalled PriCE to solve this multi-objective optimization problem. We performed\nextensive simulation experiments for artifact detection tasks on medical images\nusing an ensemble of five deep convolutional neural network inferences as the\nworkflow task. Experimental results show that PriCE successfully splits a wide\nrange of input gigapixel medical images with graph-coloring-based strategies,\nyielding desired output utility and lowering the privacy risk, makespan, and\nmonetary cost under user's budget.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.ET"
    ],
    "primary_category": "cs.CE",
    "comment": "Acccepted at Europar 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15398v1",
    "published_date": "2024-05-24 09:52:00 UTC",
    "updated_date": "2024-05-24 09:52:00 UTC"
  },
  {
    "arxiv_id": "2405.15388v1",
    "title": "Language-Driven Interactive Traffic Trajectory Generation",
    "authors": [
      "Junkai Xia",
      "Chenxin Xu",
      "Qingyao Xu",
      "Chen Xie",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "abstract": "Realistic trajectory generation with natural language control is pivotal for\nadvancing autonomous vehicle technology. However, previous methods focus on\nindividual traffic participant trajectory generation, thus failing to account\nfor the complexity of interactive traffic dynamics. In this work, we propose\nInteractTraj, the first language-driven traffic trajectory generator that can\ngenerate interactive traffic trajectories. InteractTraj interprets abstract\ntrajectory descriptions into concrete formatted interaction-aware numerical\ncodes and learns a mapping between these formatted codes and the final\ninteractive trajectories. To interpret language descriptions, we propose a\nlanguage-to-code encoder with a novel interaction-aware encoding strategy. To\nproduce interactive traffic trajectories, we propose a code-to-trajectory\ndecoder with interaction-aware feature aggregation that synergizes vehicle\ninteractions with the environmental map and the vehicle moves. Extensive\nexperiments show our method demonstrates superior performance over previous\nSoTA methods, offering a more realistic generation of interactive traffic\ntrajectories with high controllability via diverse natural language commands.\nOur code is available at https://github.com/X1a-jk/InteractTraj.git",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15388v1",
    "published_date": "2024-05-24 09:38:36 UTC",
    "updated_date": "2024-05-24 09:38:36 UTC"
  },
  {
    "arxiv_id": "2405.15383v2",
    "title": "Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search",
    "authors": [
      "Nicola Dainese",
      "Matteo Merler",
      "Minttu Alakuijala",
      "Pekka Marttinen"
    ],
    "abstract": "In this work we consider Code World Models, world models generated by a Large\nLanguage Model (LLM) in the form of Python code for model-based Reinforcement\nLearning (RL). Calling code instead of LLMs for planning has potential to be\nmore precise, reliable, interpretable, and extremely efficient. However,\nwriting appropriate Code World Models requires the ability to understand\ncomplex instructions, to generate exact code with non-trivial logic and to\nself-debug a long program with feedback from unit tests and environment\ntrajectories. To address these challenges, we propose Generate, Improve and Fix\nwith Monte Carlo Tree Search (GIF-MCTS), a new code generation strategy for\nLLMs. To test our approach in an offline RL setting, we introduce the Code\nWorld Models Benchmark (CWMB), a suite of program synthesis and planning tasks\ncomprised of 18 diverse RL environments paired with corresponding textual\ndescriptions and curated trajectories. GIF-MCTS surpasses all baselines on the\nCWMB and two other benchmarks, and we show that the Code World Models\nsynthesized with it can be successfully used for planning, resulting in\nmodel-based RL agents with greatly improved sample efficiency and inference\nspeed.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at NeurIPS 2024, Main Track. 11 pages in main text, 40 pages\n  including references and supplementary materials. 2 figures and 3 tables in\n  the main text, 9 figures and 12 tables when including the supplementary\n  materials. Website at https://sites.google.com/view/code-world-models/home",
    "pdf_url": "http://arxiv.org/pdf/2405.15383v2",
    "published_date": "2024-05-24 09:31:26 UTC",
    "updated_date": "2024-10-30 14:19:57 UTC"
  },
  {
    "arxiv_id": "2407.00033v1",
    "title": "Uncovering cognitive taskonomy through transfer learning in masked autoencoder-based fMRI reconstruction",
    "authors": [
      "Youzhi Qu",
      "Junfeng Xia",
      "Xinyao Jian",
      "Wendu Li",
      "Kaining Peng",
      "Zhichao Liang",
      "Haiyan Wu",
      "Quanying Liu"
    ],
    "abstract": "Data reconstruction is a widely used pre-training task to learn the\ngeneralized features for many downstream tasks. Although reconstruction tasks\nhave been applied to neural signal completion and denoising, neural signal\nreconstruction is less studied. Here, we employ the masked autoencoder (MAE)\nmodel to reconstruct functional magnetic resonance imaging (fMRI) data, and\nutilize a transfer learning framework to obtain the cognitive taskonomy, a\nmatrix to quantify the similarity between cognitive tasks. Our experimental\nresults demonstrate that the MAE model effectively captures the temporal\ndynamics patterns and interactions within the brain regions, enabling robust\ncross-subject fMRI signal reconstruction. The cognitive taskonomy derived from\nthe transfer learning framework reveals the relationships among cognitive\ntasks, highlighting subtask correlations within motor tasks and similarities\nbetween emotion, social, and gambling tasks. Our study suggests that the fMRI\nreconstruction with MAE model can uncover the latent representation and the\nobtained taskonomy offers guidance for selecting source tasks in neural\ndecoding tasks for improving the decoding performance on target tasks.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00033v1",
    "published_date": "2024-05-24 09:29:16 UTC",
    "updated_date": "2024-05-24 09:29:16 UTC"
  },
  {
    "arxiv_id": "2405.15380v1",
    "title": "Full-stack evaluation of Machine Learning inference workloads for RISC-V systems",
    "authors": [
      "Debjyoti Bhattacharjee",
      "Anmol",
      "Tommaso Marinelli",
      "Karan Pathak",
      "Peter Kourzanov"
    ],
    "abstract": "Architectural simulators hold a vital role in RISC-V research, providing a\ncrucial platform for workload evaluation without the need for costly physical\nprototypes. They serve as a dynamic environment for exploring innovative\narchitectural concepts, enabling swift iteration and thorough analysis of\nperformance metrics. As deep learning algorithms become increasingly pervasive,\nit is essential to benchmark new architectures with machine learning workloads.\nThe diverse computational kernels used in deep learning algorithms highlight\nthe necessity for a comprehensive compilation toolchain to map to target\nhardware platforms. This study evaluates the performance of a wide array of\nmachine learning workloads on RISC-V architectures using gem5, an open-source\narchitectural simulator. Leveraging an open-source compilation toolchain based\non Multi-Level Intermediate Representation (MLIR), the research presents\nbenchmarking results specifically focused on deep learning inference workloads.\nAdditionally, the study sheds light on current limitations of gem5 when\nsimulating RISC-V architectures, offering insights for future development and\nrefinement.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "RISC-V Summit Europe 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15380v1",
    "published_date": "2024-05-24 09:24:46 UTC",
    "updated_date": "2024-05-24 09:24:46 UTC"
  },
  {
    "arxiv_id": "2405.15375v1",
    "title": "A Planet Scale Spatial-Temporal Knowledge Graph Based On OpenStreetMap And H3 Grid",
    "authors": [
      "Martin B√∂ckling",
      "Heiko Paulheim",
      "Sarah Detzler"
    ],
    "abstract": "Geospatial data plays a central role in modeling our world, for which\nOpenStreetMap (OSM) provides a rich source of such data. While often spatial\ndata is represented in a tabular format, a graph based representation provides\nthe possibility to interconnect entities which would have been separated in a\ntabular representation. We propose in our paper a framework which supports a\nplanet scale transformation of OpenStreetMap data into a Spatial Temporal\nKnowledge Graph. In addition to OpenStreetMap data, we align the different\nOpenStreetMap geometries on individual h3 grid cells. We compare our\nconstructed spatial knowledge graph to other spatial knowledge graphs and\noutline our contribution in this paper. As a basis for our computation, we use\nApache Sedona as a computational framework for our Spatial Temporal Knowledge\nGraph construction",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 2 figures, GeoLD2024: 6th Geospatial Linked Data Workshop,\n  May 26, 2024, Hersonissos, Greece",
    "pdf_url": "http://arxiv.org/pdf/2405.15375v1",
    "published_date": "2024-05-24 09:22:20 UTC",
    "updated_date": "2024-05-24 09:22:20 UTC"
  },
  {
    "arxiv_id": "2405.15374v1",
    "title": "Leveraging Large Language Models for Semantic Query Processing in a Scholarly Knowledge Graph",
    "authors": [
      "Runsong Jia",
      "Bowen Zhang",
      "Sergio J. Rodr√≠guez M√©ndez",
      "Pouya G. Omran"
    ],
    "abstract": "The proposed research aims to develop an innovative semantic query processing\nsystem that enables users to obtain comprehensive information about research\nworks produced by Computer Science (CS) researchers at the Australian National\nUniversity (ANU). The system integrates Large Language Models (LLMs) with the\nANU Scholarly Knowledge Graph (ASKG), a structured repository of all\nresearch-related artifacts produced at ANU in the CS field. Each artifact and\nits parts are represented as textual nodes stored in a Knowledge Graph (KG).\n  To address the limitations of traditional scholarly KG construction and\nutilization methods, which often fail to capture fine-grained details, we\npropose a novel framework that integrates the Deep Document Model (DDM) for\ncomprehensive document representation and the KG-enhanced Query Processing\n(KGQP) for optimized complex query handling. DDM enables a fine-grained\nrepresentation of the hierarchical structure and semantic relationships within\nacademic papers, while KGQP leverages the KG structure to improve query\naccuracy and efficiency with LLMs.\n  By combining the ASKG with LLMs, our approach enhances knowledge utilization\nand natural language understanding capabilities. The proposed system employs an\nautomatic LLM-SPARQL fusion to retrieve relevant facts and textual nodes from\nthe ASKG. Initial experiments demonstrate that our framework is superior to\nbaseline methods in terms of accuracy retrieval and query efficiency.\n  We showcase the practical application of our framework in academic research\nscenarios, highlighting its potential to revolutionize scholarly knowledge\nmanagement and discovery. This work empowers researchers to acquire and utilize\nknowledge from documents more effectively and provides a foundation for\ndeveloping precise and reliable interactions with LLMs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "H.3.3; I.2.4; I.7.5; I.2.7"
    ],
    "primary_category": "cs.IR",
    "comment": "for the associated repository, see http://w3id.org/kgcp/KGQP",
    "pdf_url": "http://arxiv.org/pdf/2405.15374v1",
    "published_date": "2024-05-24 09:19:45 UTC",
    "updated_date": "2024-05-24 09:19:45 UTC"
  },
  {
    "arxiv_id": "2405.15835v1",
    "title": "Analyzing the Impact of Climate Change With Major Emphasis on Pollution: A Comparative Study of ML and Statistical Models in Time Series Data",
    "authors": [
      "Anurag Mishra",
      "Ronen Gold",
      "Sanjeev Vijayakumar"
    ],
    "abstract": "Industrial operations have grown exponentially over the last century, driving\nadvancements in energy utilization through vehicles and machinery.This growth\nhas significant environmental implications, necessitating the use of\nsophisticated technology to monitor and analyze climate data.The surge in\nindustrial activities presents a complex challenge in forecasting its diverse\nenvironmental impacts, which vary greatly across different regions.Aim to\nunderstand these dynamics more deeply to predict and mitigate the environmental\nimpacts of industrial activities.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "stat.AP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15835v1",
    "published_date": "2024-05-24 09:18:17 UTC",
    "updated_date": "2024-05-24 09:18:17 UTC"
  },
  {
    "arxiv_id": "2405.15373v1",
    "title": "Autonomous Quilt Spreading for Caregiving Robots",
    "authors": [
      "Yuchun Guo",
      "Zhiqing Lu",
      "Yanling Zhou",
      "Xin Jiang"
    ],
    "abstract": "In this work, we propose a novel strategy to ensure infants, who\ninadvertently displace their quilts during sleep, are promptly and accurately\nre-covered. Our approach is formulated into two subsequent steps: interference\nresolution and quilt spreading. By leveraging the DWPose human skeletal\ndetection and the Segment Anything instance segmentation models, the proposed\nmethod can accurately recognize the states of the infant and the quilt over\nher, which involves addressing the interferences resulted from an infant's\nlimbs laid on part of the quilt. Building upon prior research, the EM*D deep\nlearning model is employed to forecast quilt state transitions before and after\nquilt spreading actions. To improve the sensitivity of the network in\ndistinguishing state variation of the handled quilt, we introduce an enhanced\nloss function that translates the voxelized quilt state into a more\nrepresentative one. Both simulation and real-world experiments validate the\nefficacy of our method, in spreading and recover a quilt over an infant.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15373v1",
    "published_date": "2024-05-24 09:11:29 UTC",
    "updated_date": "2024-05-24 09:11:29 UTC"
  },
  {
    "arxiv_id": "2405.15369v1",
    "title": "Cross-Domain Policy Adaptation by Capturing Representation Mismatch",
    "authors": [
      "Jiafei Lyu",
      "Chenjia Bai",
      "Jingwen Yang",
      "Zongqing Lu",
      "Xiu Li"
    ],
    "abstract": "It is vital to learn effective policies that can be transferred to different\ndomains with dynamics discrepancies in reinforcement learning (RL). In this\npaper, we consider dynamics adaptation settings where there exists dynamics\nmismatch between the source domain and the target domain, and one can get\naccess to sufficient source domain data, while can only have limited\ninteractions with the target domain. Existing methods address this problem by\nlearning domain classifiers, performing data filtering from a value discrepancy\nperspective, etc. Instead, we tackle this challenge from a decoupled\nrepresentation learning perspective. We perform representation learning only in\nthe target domain and measure the representation deviations on the transitions\nfrom the source domain, which we show can be a signal of dynamics mismatch. We\nalso show that representation deviation upper bounds performance difference of\na given policy in the source domain and target domain, which motivates us to\nadopt representation deviation as a reward penalty. The produced\nrepresentations are not involved in either policy or value function, but only\nserve as a reward penalizer. We conduct extensive experiments on environments\nwith kinematic and morphology mismatch, and the results show that our method\nexhibits strong performance on many tasks. Our code is publicly available at\nhttps://github.com/dmksjfl/PAR.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15369v1",
    "published_date": "2024-05-24 09:06:12 UTC",
    "updated_date": "2024-05-24 09:06:12 UTC"
  },
  {
    "arxiv_id": "2405.15346v1",
    "title": "BiSup: Bidirectional Quantization Error Suppression for Large Language Models",
    "authors": [
      "Minghui Zou",
      "Ronghui Guo",
      "Sai Zhang",
      "Xiaowang Zhang",
      "Zhiyong Feng"
    ],
    "abstract": "As the size and context length of Large Language Models (LLMs) grow,\nweight-activation quantization has emerged as a crucial technique for efficient\ndeployment of LLMs. Compared to weight-only quantization, weight-activation\nquantization presents greater challenges due to the presence of outliers in\nactivations. Existing methods have made significant progress by exploring\nmixed-precision quantization and outlier suppression. However, these methods\nprimarily focus on optimizing the results of single matrix multiplication,\nneglecting the bidirectional propagation of quantization errors in LLMs.\nSpecifically, errors accumulate vertically within the same token through\nlayers, and diffuse horizontally across different tokens due to self-attention\nmechanisms. To address this issue, we introduce BiSup, a Bidirectional\nquantization error Suppression method. By constructing appropriate optimizable\nparameter spaces, BiSup utilizes a small amount of data for quantization-aware\nparameter-efficient fine-tuning to suppress the error vertical accumulation.\nBesides, BiSup employs prompt mixed-precision quantization strategy, which\npreserves high precision for the key-value cache of system prompts, to mitigate\nthe error horizontal diffusion. Extensive experiments on Llama and Qwen\nfamilies demonstrate that BiSup can improve performance over two\nstate-of-the-art methods (the average WikiText2 perplexity decreases from 13.26\nto 9.41 for Atom and from 14.33 to 7.85 for QuaRot under the W3A3-g128\nconfiguration), further facilitating the practical applications of low-bit\nweight-activation quantization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15346v1",
    "published_date": "2024-05-24 08:39:27 UTC",
    "updated_date": "2024-05-24 08:39:27 UTC"
  },
  {
    "arxiv_id": "2405.15832v1",
    "title": "DETECTA 2.0: Research into non-intrusive methodologies supported by Industry 4.0 enabling technologies for predictive and cyber-secure maintenance in SMEs",
    "authors": [
      "√Ålvaro Huertas-Garc√≠a",
      "Javier Mu√±oz",
      "Enrique De Miguel Ambite",
      "Marcos Avil√©s Camarmas",
      "Jos√© F√©lix Ovejero"
    ],
    "abstract": "The integration of predictive maintenance and cybersecurity represents a\ntransformative advancement for small and medium-sized enterprises (SMEs)\noperating within the Industry 4.0 paradigm. Despite their economic importance,\nSMEs often face significant challenges in adopting advanced technologies due to\nresource constraints and knowledge gaps. The DETECTA 2.0 project addresses\nthese hurdles by developing an innovative system that harmonizes real-time\nanomaly detection, sophisticated analytics, and predictive forecasting\ncapabilities.\n  The system employs a semi-supervised methodology, combining unsupervised\nanomaly detection with supervised learning techniques. This approach enables\nmore agile and cost-effective development of AI detection systems,\nsignificantly reducing the time required for manual case review.\n  At the core lies a Digital Twin interface, providing intuitive real-time\nvisualizations of machine states and detected anomalies. Leveraging\ncutting-edge AI engines, the system intelligently categorizes anomalies based\non observed patterns, differentiating between technical errors and potential\ncybersecurity incidents. This discernment is fortified by detailed analytics,\nincluding certainty levels that enhance alert reliability and minimize false\npositives.\n  The predictive engine uses advanced time series algorithms like N-HiTS to\nforecast future machine utilization trends. This proactive approach optimizes\nmaintenance planning, enhances cybersecurity measures, and minimizes unplanned\ndowntimes despite variable production processes.\n  With its modular architecture enabling seamless integration across industrial\nsetups and low implementation costs, DETECTA 2.0 presents an attractive\nsolution for SMEs to strengthen their predictive maintenance and cybersecurity\nstrategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15832v1",
    "published_date": "2024-05-24 08:38:38 UTC",
    "updated_date": "2024-05-24 08:38:38 UTC"
  },
  {
    "arxiv_id": "2405.15341v2",
    "title": "V-Zen: Efficient GUI Understanding and Precise Grounding With A Novel Multimodal LLM",
    "authors": [
      "Abdur Rahman",
      "Rajat Chawla",
      "Muskaan Kumar",
      "Arkajit Datta",
      "Adarsh Jha",
      "Mukunda NS",
      "Ishaan Bhola"
    ],
    "abstract": "In the rapidly evolving landscape of AI research and application, Multimodal\nLarge Language Models (MLLMs) have emerged as a transformative force, adept at\ninterpreting and integrating information from diverse modalities such as text,\nimages, and Graphical User Interfaces (GUIs). Despite these advancements, the\nnuanced interaction and understanding of GUIs pose a significant challenge,\nlimiting the potential of existing models to enhance automation levels. To\nbridge this gap, this paper presents V-Zen, an innovative Multimodal Large\nLanguage Model (MLLM) meticulously crafted to revolutionise the domain of GUI\nunderstanding and grounding. Equipped with dual-resolution image encoders,\nV-Zen establishes new benchmarks in efficient grounding and next-action\nprediction, thereby laying the groundwork for self-operating computer systems.\nComplementing V-Zen is the GUIDE dataset, an extensive collection of real-world\nGUI elements and task-based sequences, serving as a catalyst for specialised\nfine-tuning. The successful integration of V-Zen and GUIDE marks the dawn of a\nnew era in multimodal AI research, opening the door to intelligent, autonomous\ncomputing experiences. This paper extends an invitation to the research\ncommunity to join this exciting journey, shaping the future of GUI automation.\nIn the spirit of open science, our code, data, and model will be made publicly\navailable, paving the way for multimodal dialogue scenarios with intricate and\nprecise interactions.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.15341v2",
    "published_date": "2024-05-24 08:21:45 UTC",
    "updated_date": "2024-07-21 07:34:44 UTC"
  },
  {
    "arxiv_id": "2405.15831v1",
    "title": "Transmission Interface Power Flow Adjustment: A Deep Reinforcement Learning Approach based on Multi-task Attribution Map",
    "authors": [
      "Shunyu Liu",
      "Wei Luo",
      "Yanzhen Zhou",
      "Kaixuan Chen",
      "Quan Zhang",
      "Huating Xu",
      "Qinglai Guo",
      "Mingli Song"
    ],
    "abstract": "Transmission interface power flow adjustment is a critical measure to ensure\nthe security and economy operation of power systems. However, conventional\nmodel-based adjustment schemes are limited by the increasing variations and\nuncertainties occur in power systems, where the adjustment problems of\ndifferent transmission interfaces are often treated as several independent\ntasks, ignoring their coupling relationship and even leading to conflict\ndecisions. In this paper, we introduce a novel data-driven deep reinforcement\nlearning (DRL) approach, to handle multiple power flow adjustment tasks jointly\ninstead of learning each task from scratch. At the heart of the proposed method\nis a multi-task attribution map (MAM), which enables the DRL agent to\nexplicitly attribute each transmission interface task to different power system\nnodes with task-adaptive attention weights. Based on this MAM, the agent can\nfurther provide effective strategies to solve the multi-task adjustment problem\nwith a near-optimal operation cost. Simulation results on the IEEE 118-bus\nsystem, a realistic 300-bus system in China, and a very large European system\nwith 9241 buses demonstrate that the proposed method significantly improves the\nperformance compared with several baseline methods, and exhibits high\ninterpretability with the learnable MAM.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted by IEEE Transactions on Power Systems",
    "pdf_url": "http://arxiv.org/pdf/2405.15831v1",
    "published_date": "2024-05-24 08:20:53 UTC",
    "updated_date": "2024-05-24 08:20:53 UTC"
  },
  {
    "arxiv_id": "2406.00025v1",
    "title": "SCALM: Towards Semantic Caching for Automated Chat Services with Large Language Models",
    "authors": [
      "Jiaxing Li",
      "Chi Xu",
      "Feng Wang",
      "Isaac M von Riedemann",
      "Cong Zhang",
      "Jiangchuan Liu"
    ],
    "abstract": "Large Language Models (LLMs) have become increasingly popular, transforming a\nwide range of applications across various domains. However, the real-world\neffectiveness of their query cache systems has not been thoroughly\ninvestigated. In this work, we for the first time conducted an analysis on\nreal-world human-to-LLM interaction data, identifying key challenges in\nexisting caching solutions for LLM-based chat services. Our findings reveal\nthat current caching methods fail to leverage semantic connections, leading to\ninefficient cache performance and extra token costs. To address these issues,\nwe propose SCALM, a new cache architecture that emphasizes semantic analysis\nand identifies significant cache entries and patterns. We also detail the\nimplementations of the corresponding cache storage and eviction strategies. Our\nevaluations show that SCALM increases cache hit ratios and reduces operational\ncosts for LLMChat services. Compared with other state-of-the-art solutions in\nGPTCache, SCALM shows, on average, a relative increase of 63% in cache hit\nratio and a relative improvement of 77% in tokens savings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00025v1",
    "published_date": "2024-05-24 08:16:22 UTC",
    "updated_date": "2024-05-24 08:16:22 UTC"
  },
  {
    "arxiv_id": "2407.03133v3",
    "title": "Quantifying the Cross-sectoral Intersecting Discrepancies within Multiple Groups Using Latent Class Analysis Towards Fairness",
    "authors": [
      "Yingfang Yuan",
      "Kefan Chen",
      "Mehdi Rizvi",
      "Lynne Baillie",
      "Wei Pang"
    ],
    "abstract": "The growing interest in fair AI development is evident. The ''Leave No One\nBehind'' initiative urges us to address multiple and intersecting forms of\ninequality in accessing services, resources, and opportunities, emphasising the\nsignificance of fairness in AI. This is particularly relevant as an increasing\nnumber of AI tools are applied to decision-making processes, such as resource\nallocation and service scheme development, across various sectors such as\nhealth, energy, and housing. Therefore, exploring joint inequalities in these\nsectors is significant and valuable for thoroughly understanding overall\ninequality and unfairness. This research introduces an innovative approach to\nquantify cross-sectoral intersecting discrepancies among user-defined groups\nusing latent class analysis. These discrepancies can be used to approximate\ninequality and provide valuable insights to fairness issues. We validate our\napproach using both proprietary and public datasets, including both EVENS and\nCensus 2021 (England & Wales) datasets, to examine cross-sectoral intersecting\ndiscrepancies among different ethnic groups. We also verify the reliability of\nthe quantified discrepancy by conducting a correlation analysis with a\ngovernment public metric. Our findings reveal significant discrepancies both\namong minority ethnic groups and between minority ethnic groups and\nnon-minority ethnic groups, emphasising the need for targeted interventions in\npolicy-making processes. Furthermore, we demonstrate how the proposed approach\ncan provide valuable insights into ensuring fairness in machine learning\nsystems.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03133v3",
    "published_date": "2024-05-24 08:10:31 UTC",
    "updated_date": "2025-02-08 19:28:05 UTC"
  },
  {
    "arxiv_id": "2405.15324v2",
    "title": "Continuously Learning, Adapting, and Improving: A Dual-Process Approach to Autonomous Driving",
    "authors": [
      "Jianbiao Mei",
      "Yukai Ma",
      "Xuemeng Yang",
      "Licheng Wen",
      "Xinyu Cai",
      "Xin Li",
      "Daocheng Fu",
      "Bo Zhang",
      "Pinlong Cai",
      "Min Dou",
      "Botian Shi",
      "Liang He",
      "Yong Liu",
      "Yu Qiao"
    ],
    "abstract": "Autonomous driving has advanced significantly due to sensors, machine\nlearning, and artificial intelligence improvements. However, prevailing methods\nstruggle with intricate scenarios and causal relationships, hindering\nadaptability and interpretability in varied environments. To address the above\nproblems, we introduce LeapAD, a novel paradigm for autonomous driving inspired\nby the human cognitive process. Specifically, LeapAD emulates human attention\nby selecting critical objects relevant to driving decisions, simplifying\nenvironmental interpretation, and mitigating decision-making complexities.\nAdditionally, LeapAD incorporates an innovative dual-process decision-making\nmodule, which consists of an Analytic Process (System-II) for thorough analysis\nand reasoning, along with a Heuristic Process (System-I) for swift and\nempirical processing. The Analytic Process leverages its logical reasoning to\naccumulate linguistic driving experience, which is then transferred to the\nHeuristic Process by supervised fine-tuning. Through reflection mechanisms and\na growing memory bank, LeapAD continuously improves itself from past mistakes\nin a closed-loop environment. Closed-loop testing in CARLA shows that LeapAD\noutperforms all methods relying solely on camera input, requiring 1-2 orders of\nmagnitude less labeled data. Experiments also demonstrate that as the memory\nbank expands, the Heuristic Process with only 1.8B parameters can inherit the\nknowledge from a GPT-4 powered Analytic Process and achieve continuous\nperformance improvement. Project page: https://pjlab-adg.github.io/LeapAD.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15324v2",
    "published_date": "2024-05-24 08:07:28 UTC",
    "updated_date": "2024-10-25 16:00:54 UTC"
  },
  {
    "arxiv_id": "2405.15320v1",
    "title": "Organic Data-Driven Approach for Turkish Grammatical Error Correction and LLMs",
    "authors": [
      "Asƒ±m Ersoy",
      "Olcay Taner Yƒ±ldƒ±z"
    ],
    "abstract": "Grammatical Error Correction has seen significant progress with the recent\nadvancements in deep learning. As those methods require huge amounts of data,\nsynthetic datasets are being built to fill this gap. Unfortunately, synthetic\ndatasets are not organic enough in some cases and even require clean data to\nstart with. Furthermore, most of the work that has been done is focused mostly\non English. In this work, we introduce a new organic data-driven approach,\nclean insertions, to build parallel Turkish Grammatical Error Correction\ndatasets from any organic data, and to clean the data used for training Large\nLanguage Models. We achieve state-of-the-art results on two Turkish Grammatical\nError Correction test sets out of the three publicly available ones. We also\nshow the effectiveness of our method on the training losses of training\nlanguage models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15320v1",
    "published_date": "2024-05-24 08:00:24 UTC",
    "updated_date": "2024-05-24 08:00:24 UTC"
  },
  {
    "arxiv_id": "2405.15319v2",
    "title": "Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training",
    "authors": [
      "Wenyu Du",
      "Tongxu Luo",
      "Zihan Qiu",
      "Zeyu Huang",
      "Yikang Shen",
      "Reynold Cheng",
      "Yike Guo",
      "Jie Fu"
    ],
    "abstract": "LLMs are computationally expensive to pre-train due to their large scale.\nModel growth emerges as a promising approach by leveraging smaller models to\naccelerate the training of larger ones. However, the viability of these model\ngrowth methods in efficient LLM pre-training remains underexplored. This work\nidentifies three critical $\\underline{\\textit{O}}$bstacles: ($\\textit{O}$1)\nlack of comprehensive evaluation, ($\\textit{O}$2) untested viability for\nscaling, and ($\\textit{O}$3) lack of empirical guidelines. To tackle\n$\\textit{O}$1, we summarize existing approaches into four atomic growth\noperators and systematically evaluate them in a standardized LLM pre-training\nsetting. Our findings reveal that a depthwise stacking operator, called\n$G_{\\text{stack}}$, exhibits remarkable acceleration in training, leading to\ndecreased loss and improved overall performance on eight standard NLP\nbenchmarks compared to strong baselines. Motivated by these promising results,\nwe conduct extensive experiments to delve deeper into $G_{\\text{stack}}$ to\naddress $\\textit{O}$2 and $\\textit{O}$3. For $\\textit{O}$2 (untested\nscalability), our study shows that $G_{\\text{stack}}$ is scalable and\nconsistently performs well, with experiments up to 7B LLMs after growth and\npre-training LLMs with 750B tokens. For example, compared to a conventionally\ntrained 7B model using 300B tokens, our $G_{\\text{stack}}$ model converges to\nthe same loss with 194B tokens, resulting in a 54.6\\% speedup. We further\naddress $\\textit{O}$3 (lack of empirical guidelines) by formalizing guidelines\nto determine growth timing and growth factor for $G_{\\text{stack}}$, making it\npractical in general LLM pre-training. We also provide in-depth discussions and\ncomprehensive ablation studies of $G_{\\text{stack}}$. Our code and pre-trained\nmodel are available at https://llm-stacking.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2405.15319v2",
    "published_date": "2024-05-24 08:00:00 UTC",
    "updated_date": "2024-10-22 10:31:59 UTC"
  },
  {
    "arxiv_id": "2405.15318v1",
    "title": "Are Long-LLMs A Necessity For Long-Context Tasks?",
    "authors": [
      "Hongjin Qian",
      "Zheng Liu",
      "Peitian Zhang",
      "Kelong Mao",
      "Yujia Zhou",
      "Xu Chen",
      "Zhicheng Dou"
    ],
    "abstract": "The learning and deployment of long-LLMs remains a challenging problem\ndespite recent progresses. In this work, we argue that the long-LLMs are not a\nnecessity to solve long-context tasks, as common long-context tasks are\nshort-context solvable, i.e. they can be solved by purely working with oracle\nshort-contexts within the long-context tasks' inputs. On top of this argument,\nwe propose a framework called LC-Boost (Long-Context Bootstrapper), which\nenables a short-LLM to address the long-context tasks in a bootstrapping\nmanner. In our framework, the short-LLM prompts itself to reason for two\ncritical decisions: 1) how to access to the appropriate part of context within\nthe input, 2) how to make effective use of the accessed context. By adaptively\naccessing and utilizing the context based on the presented tasks, LC-Boost can\nserve as a general framework to handle diversified long-context processing\nproblems. We comprehensively evaluate different types of tasks from popular\nlong-context benchmarks, where LC-Boost is able to achieve a substantially\nimproved performance with a much smaller consumption of resource.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.15318v1",
    "published_date": "2024-05-24 07:59:30 UTC",
    "updated_date": "2024-05-24 07:59:30 UTC"
  },
  {
    "arxiv_id": "2405.15317v3",
    "title": "NuwaTS: a Foundation Model Mending Every Incomplete Time Series",
    "authors": [
      "Jinguo Cheng",
      "Chunwei Yang",
      "Wanlin Cai",
      "Yuxuan Liang",
      "Qingsong Wen",
      "Yuankai Wu"
    ],
    "abstract": "Time series imputation is critical for many real-world applications and has\nbeen widely studied. However, existing models often require specialized designs\ntailored to specific missing patterns, variables, or domains which limits their\ngeneralizability. In addition, current evaluation frameworks primarily focus on\ndomain-specific tasks and often rely on time-wise train/validation/test data\nsplits, which fail to rigorously assess a model's ability to generalize across\nunseen variables or domains. In this paper, we present \\textbf{NuwaTS}, a novel\nframework that repurposes Pre-trained Language Models (PLMs) for general time\nseries imputation. Once trained, NuwaTS can be applied to impute missing data\nacross any domain. We introduce specialized embeddings for each sub-series\npatch, capturing information about the patch, its missing data patterns, and\nits statistical characteristics. By combining contrastive learning with the\nimputation task, we train PLMs to create a versatile, one-for-all imputation\nmodel. Additionally, we employ a plug-and-play fine-tuning approach, enabling\nefficient adaptation to domain-specific tasks with minimal adjustments. To\nevaluate cross-variable and cross-domain generalization, we propose a new\nbenchmarking protocol that partitions the datasets along the variable\ndimension. Experimental results on over seventeen million time series samples\nfrom diverse domains demonstrate that NuwaTS outperforms state-of-the-art\ndomain-specific models across various datasets under the proposed benchmarking\nprotocol. Furthermore, we show that NuwaTS generalizes to other time series\ntasks, such as forecasting. Our codes are available at\nhttps://github.com/Chengyui/NuwaTS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15317v3",
    "published_date": "2024-05-24 07:59:02 UTC",
    "updated_date": "2024-10-02 14:34:08 UTC"
  },
  {
    "arxiv_id": "2405.15311v3",
    "title": "Retro: Reusing teacher projection head for efficient embedding distillation on Lightweight Models via Self-supervised Learning",
    "authors": [
      "Khanh-Binh Nguyen",
      "Chae Jung Park"
    ],
    "abstract": "Self-supervised learning (SSL) is gaining attention for its ability to learn\neffective representations with large amounts of unlabeled data. Lightweight\nmodels can be distilled from larger self-supervised pre-trained models using\ncontrastive and consistency constraints. Still, the different sizes of the\nprojection heads make it challenging for students to mimic the teacher's\nembedding accurately. We propose \\textsc{Retro}, which reuses the teacher's\nprojection head for students, and our experimental results demonstrate\nsignificant improvements over the state-of-the-art on all lightweight models.\nFor instance, when training EfficientNet-B0 using ResNet-50/101/152 as\nteachers, our approach improves the linear result on ImageNet to $66.9\\%$,\n$69.3\\%$, and $69.8\\%$, respectively, with significantly fewer parameters.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at BMVC 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15311v3",
    "published_date": "2024-05-24 07:53:09 UTC",
    "updated_date": "2024-08-24 13:23:40 UTC"
  },
  {
    "arxiv_id": "2405.19360v3",
    "title": "ART: Automatic Red-teaming for Text-to-Image Models to Protect Benign Users",
    "authors": [
      "Guanlin Li",
      "Kangjie Chen",
      "Shudong Zhang",
      "Jie Zhang",
      "Tianwei Zhang"
    ],
    "abstract": "Large-scale pre-trained generative models are taking the world by storm, due\nto their abilities in generating creative content. Meanwhile, safeguards for\nthese generative models are developed, to protect users' rights and safety,\nmost of which are designed for large language models. Existing methods\nprimarily focus on jailbreak and adversarial attacks, which mainly evaluate the\nmodel's safety under malicious prompts. Recent work found that manually crafted\nsafe prompts can unintentionally trigger unsafe generations. To further\nsystematically evaluate the safety risks of text-to-image models, we propose a\nnovel Automatic Red-Teaming framework, ART. Our method leverages both vision\nlanguage model and large language model to establish a connection between\nunsafe generations and their prompts, thereby more efficiently identifying the\nmodel's vulnerabilities. With our comprehensive experiments, we reveal the\ntoxicity of the popular open-source text-to-image models. The experiments also\nvalidate the effectiveness, adaptability, and great diversity of ART.\nAdditionally, we introduce three large-scale red-teaming datasets for studying\nthe safety risks associated with text-to-image models. Datasets and models can\nbe found in https://github.com/GuanlinLee/ART.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19360v3",
    "published_date": "2024-05-24 07:44:27 UTC",
    "updated_date": "2024-10-11 06:52:18 UTC"
  },
  {
    "arxiv_id": "2405.15302v2",
    "title": "The Buffer Mechanism for Multi-Step Information Reasoning in Language Models",
    "authors": [
      "Zhiwei Wang",
      "Yunji Wang",
      "Zhongwang Zhang",
      "Zhangchen Zhou",
      "Hui Jin",
      "Tianyang Hu",
      "Jiacheng Sun",
      "Zhenguo Li",
      "Yaoyu Zhang",
      "Zhi-Qin John Xu"
    ],
    "abstract": "Large language models have consistently struggled with complex reasoning\ntasks, such as mathematical problem-solving. Investigating the internal\nreasoning mechanisms of these models can help us design better model\narchitectures and training strategies, ultimately enhancing their reasoning\ncapability. In this study, we constructed a symbolic dataset to investigate the\nmechanisms by which Transformer models employ vertical thinking strategy based\non their inherent structure and horizontal thinking strategy based on Chain of\nThought to achieve multi-step reasoning. We introduced the concept of buffer\nmechanism: the model stores various information in distinct buffers and\nselectively extracts them through the query-key matrix. We proposed a random\nmatrix-based algorithm to enhance the model's reasoning ability, resulting in a\n75% reduction in the training time required for the GPT-2 model to achieve\ngeneralization capability on the PrOntoQA dataset. These findings provide new\ninsights into understanding the mechanisms of large language models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15302v2",
    "published_date": "2024-05-24 07:41:26 UTC",
    "updated_date": "2024-10-15 07:26:33 UTC"
  },
  {
    "arxiv_id": "2405.15294v2",
    "title": "Semi-Supervised Learning guided by the Generalized Bayes Rule under Soft Revision",
    "authors": [
      "Stefan Dietrich",
      "Julian Rodemann",
      "Christoph Jansen"
    ],
    "abstract": "We provide a theoretical and computational investigation of the Gamma-Maximin\nmethod with soft revision, which was recently proposed as a robust criterion\nfor pseudo-label selection (PLS) in semi-supervised learning. Opposed to\ntraditional methods for PLS we use credal sets of priors (\"generalized Bayes\")\nto represent the epistemic modeling uncertainty. These latter are then updated\nby the Gamma-Maximin method with soft revision. We eventually select\npseudo-labeled data that are most likely in light of the least favorable\ndistribution from the so updated credal set. We formalize the task of finding\noptimal pseudo-labeled data w.r.t. the Gamma-Maximin method with soft revision\nas an optimization problem. A concrete implementation for the class of logistic\nmodels then allows us to compare the predictive power of the method with\ncompeting approaches. It is observed that the Gamma-Maximin method with soft\nrevision can achieve very promising results, especially when the proportion of\nlabeled data is low.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.TH",
      "62C12 62C10",
      "I.2.6; G.3"
    ],
    "primary_category": "stat.ML",
    "comment": "Accepted at the 11th International Conference on Soft Methods in\n  Probability and Statistics (SMPS) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15294v2",
    "published_date": "2024-05-24 07:30:45 UTC",
    "updated_date": "2024-06-04 15:28:34 UTC"
  },
  {
    "arxiv_id": "2405.15292v1",
    "title": "Towards a Probabilistic Fusion Approach for Robust Battery Prognostics",
    "authors": [
      "Jokin Alcibar",
      "Jose I. Aizpurua",
      "Ekhi Zugasti"
    ],
    "abstract": "Batteries are a key enabling technology for the decarbonization of transport\nand energy sectors. The safe and reliable operation of batteries is crucial for\nbattery-powered systems. In this direction, the development of accurate and\nrobust battery state-of-health prognostics models can unlock the potential of\nautonomous systems for complex, remote and reliable operations. The combination\nof Neural Networks, Bayesian modelling concepts and ensemble learning\nstrategies, form a valuable prognostics framework to combine uncertainty in a\nrobust and accurate manner. Accordingly, this paper introduces a Bayesian\nensemble learning approach to predict the capacity depletion of lithium-ion\nbatteries. The approach accurately predicts the capacity fade and quantifies\nthe uncertainty associated with battery design and degradation processes. The\nproposed Bayesian ensemble methodology employs a stacking technique,\nintegrating multiple Bayesian neural networks (BNNs) as base learners, which\nhave been trained on data diversity. The proposed method has been validated\nusing a battery aging dataset collected by the NASA Ames Prognostics Center of\nExcellence. Obtained results demonstrate the improved accuracy and robustness\nof the proposed probabilistic fusion approach with respect to (i) a single BNN\nmodel and (ii) a classical stacking strategy based on different BNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15292v1",
    "published_date": "2024-05-24 07:26:36 UTC",
    "updated_date": "2024-05-24 07:26:36 UTC"
  },
  {
    "arxiv_id": "2405.20770v4",
    "title": "Large Language Model Sentinel: LLM Agent for Adversarial Purification",
    "authors": [
      "Guang Lin",
      "Toshihisa Tanaka",
      "Qibin Zhao"
    ],
    "abstract": "Over the past two years, the use of large language models (LLMs) has advanced\nrapidly. While these LLMs offer considerable convenience, they also raise\nsecurity concerns, as LLMs are vulnerable to adversarial attacks by some\nwell-designed textual perturbations. In this paper, we introduce a novel\ndefense technique named Large LAnguage MOdel Sentinel (LLAMOS), which is\ndesigned to enhance the adversarial robustness of LLMs by purifying the\nadversarial textual examples before feeding them into the target LLM. Our\nmethod comprises two main components: a) Agent instruction, which can simulate\na new agent for adversarial defense, altering minimal characters to maintain\nthe original meaning of the sentence while defending against attacks; b)\nDefense guidance, which provides strategies for modifying clean or adversarial\nexamples to ensure effective defense and accurate outputs from the target LLMs.\nRemarkably, the defense agent demonstrates robust defensive capabilities even\nwithout learning from adversarial examples. Additionally, we conduct an\nintriguing adversarial experiment where we develop two agents, one for defense\nand one for attack, and engage them in mutual confrontation. During the\nadversarial interactions, neither agent completely beat the other. Extensive\nexperiments on both open-source and closed-source LLMs demonstrate that our\nmethod effectively defends against adversarial attacks, thereby enhancing\nadversarial robustness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.20770v4",
    "published_date": "2024-05-24 07:23:56 UTC",
    "updated_date": "2025-04-23 05:12:45 UTC"
  },
  {
    "arxiv_id": "2405.15282v2",
    "title": "Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation",
    "authors": [
      "Abhinav Jain",
      "Swarat Chaudhuri",
      "Thomas Reps",
      "Chris Jermaine"
    ],
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has become the standard for\ncustomising Foundation Models (FMs) to user-specific downstream tasks. However,\ntypical PEFT methods require storing multiple task-specific adapters, creating\nscalability issues as these adapters must be housed and run at the FM server.\nTraditional prompt tuning offers a potential solution by customising them\nthrough task-specific input prefixes, but it under-performs compared to other\nPEFT methods like LoRA. To address this gap, we propose Low-Rank Prompt\nAdaptation (LoPA), a prompt-tuning-based approach that performs on par with\nstate-of-the-art PEFT methods and full fine-tuning while being more\nparameter-efficient and not requiring a server-based adapter. LoPA generates\nsoft prompts by balancing between sharing task-specific information across\ninstances and customization for each instance. It uses a low-rank decomposition\nof the soft-prompt component encoded for each instance to achieve parameter\nefficiency. We provide a comprehensive evaluation on multiple natural language\nunderstanding and code generation and understanding tasks across a wide range\nof foundation models with varying sizes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.15282v2",
    "published_date": "2024-05-24 07:11:42 UTC",
    "updated_date": "2024-10-31 22:29:59 UTC"
  },
  {
    "arxiv_id": "2405.15280v1",
    "title": "DFGNN: Dual-frequency Graph Neural Network for Sign-aware Feedback",
    "authors": [
      "Yiqing Wu",
      "Ruobing Xie",
      "Zhao Zhang",
      "Xu Zhang",
      "Fuzhen Zhuang",
      "Leyu Lin",
      "Zhanhui Kang",
      "Yongjun Xu"
    ],
    "abstract": "The graph-based recommendation has achieved great success in recent years.\nHowever, most existing graph-based recommendations focus on capturing user\npreference based on positive edges/feedback, while ignoring negative\nedges/feedback (e.g., dislike, low rating) that widely exist in real-world\nrecommender systems. How to utilize negative feedback in graph-based\nrecommendations still remains underexplored. In this study, we first conducted\na comprehensive experimental analysis and found that (1) existing graph neural\nnetworks are not well-suited for modeling negative feedback, which acts as a\nhigh-frequency signal in a user-item graph. (2) The graph-based recommendation\nsuffers from the representation degeneration problem. Based on the two\nobservations, we propose a novel model that models positive and negative\nfeedback from a frequency filter perspective called Dual-frequency Graph Neural\nNetwork for Sign-aware Recommendation (DFGNN). Specifically, in DFGNN, the\ndesigned dual-frequency graph filter (DGF) captures both low-frequency and\nhigh-frequency signals that contain positive and negative feedback.\nFurthermore, the proposed signed graph regularization is applied to maintain\nthe user/item embedding uniform in the embedding space to alleviate the\nrepresentation degeneration problem. Additionally, we conduct extensive\nexperiments on real-world datasets and demonstrate the effectiveness of the\nproposed model. Codes of our model will be released upon acceptance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by KDD 2024 Research Track",
    "pdf_url": "http://arxiv.org/pdf/2405.15280v1",
    "published_date": "2024-05-24 07:07:41 UTC",
    "updated_date": "2024-05-24 07:07:41 UTC"
  },
  {
    "arxiv_id": "2405.15264v1",
    "title": "Self-Contrastive Weakly Supervised Learning Framework for Prognostic Prediction Using Whole Slide Images",
    "authors": [
      "Saul Fuster",
      "Farbod Khoraminia",
      "Julio Silva-Rodr√≠guez",
      "Umay Kiraz",
      "Geert J. L. H. van Leenders",
      "Trygve Eftest√∏l",
      "Valery Naranjo",
      "Emiel A. M. Janssen",
      "Tahlita C. M. Zuiverloon",
      "Kjersti Engan"
    ],
    "abstract": "We present a pioneering investigation into the application of deep learning\ntechniques to analyze histopathological images for addressing the substantial\nchallenge of automated prognostic prediction. Prognostic prediction poses a\nunique challenge as the ground truth labels are inherently weak, and the model\nmust anticipate future events that are not directly observable in the image. To\naddress this challenge, we propose a novel three-part framework comprising of a\nconvolutional network based tissue segmentation algorithm for region of\ninterest delineation, a contrastive learning module for feature extraction, and\na nested multiple instance learning classification module. Our study explores\nthe significance of various regions of interest within the histopathological\nslides and exploits diverse learning scenarios. The pipeline is initially\nvalidated on artificially generated data and a simpler diagnostic task.\nTransitioning to prognostic prediction, tasks become more challenging.\nEmploying bladder cancer as use case, our best models yield an AUC of 0.721 and\n0.678 for recurrence and treatment outcome prediction respectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "https://github.com/Biomedical-Data-Analysis-Laboratory/HistoPrognostics",
    "pdf_url": "http://arxiv.org/pdf/2405.15264v1",
    "published_date": "2024-05-24 06:45:36 UTC",
    "updated_date": "2024-05-24 06:45:36 UTC"
  },
  {
    "arxiv_id": "2405.15254v1",
    "title": "Novel Kernel Models and Exact Representor Theory for Neural Networks Beyond the Over-Parameterized Regime",
    "authors": [
      "Alistair Shilton",
      "Sunil Gupta",
      "Santu Rana",
      "Svetha Venkatesh"
    ],
    "abstract": "This paper presents two models of neural-networks and their training\napplicable to neural networks of arbitrary width, depth and topology, assuming\nonly finite-energy neural activations; and a novel representor theory for\nneural networks in terms of a matrix-valued kernel. The first model is exact\n(un-approximated) and global, casting the neural network as an elements in a\nreproducing kernel Banach space (RKBS); we use this model to provide tight\nbounds on Rademacher complexity. The second model is exact and local, casting\nthe change in neural network function resulting from a bounded change in\nweights and biases (ie. a training step) in reproducing kernel Hilbert space\n(RKHS) in terms of a local-intrinsic neural kernel (LiNK). This local model\nprovides insight into model adaptation through tight bounds on Rademacher\ncomplexity of network adaptation. We also prove that the neural tangent kernel\n(NTK) is a first-order approximation of the LiNK kernel. Finally, and noting\nthat the LiNK does not provide a representor theory for technical reasons, we\npresent an exact novel representor theory for layer-wise neural network\ntraining with unregularized gradient descent in terms of a local-extrinsic\nneural kernel (LeNK). This representor theory gives insight into the role of\nhigher-order statistics in neural network training and the effect of kernel\nevolution in neural-network kernel models. Throughout the paper (a) feedforward\nReLU networks and (b) residual networks (ResNet) are used as illustrative\nexamples.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15254v1",
    "published_date": "2024-05-24 06:30:36 UTC",
    "updated_date": "2024-05-24 06:30:36 UTC"
  },
  {
    "arxiv_id": "2405.15250v1",
    "title": "Coaching Copilot: Blended Form of an LLM-Powered Chatbot and a Human Coach to Effectively Support Self-Reflection for Leadership Growth",
    "authors": [
      "Riku Arakawa",
      "Hiromu Yakura"
    ],
    "abstract": "Chatbots' role in fostering self-reflection is now widely recognized,\nespecially in inducing users' behavior change. While the benefits of 24/7\navailability, scalability, and consistent responses have been demonstrated in\ncontexts such as healthcare and tutoring to help one form a new habit, their\nutilization in coaching necessitating deeper introspective dialogue to induce\nleadership growth remains unexplored. This paper explores the potential of such\na chatbot powered by recent Large Language Models (LLMs) in collaboration with\nprofessional coaches in the field of executive coaching. Through a design\nworkshop with them and two weeks of user study involving ten coach-client\npairs, we explored the feasibility and nuances of integrating chatbots to\ncomplement human coaches. Our findings highlight the benefits of chatbots'\nubiquity and reasoning capabilities enabled by LLMs while identifying their\nlimitations and design necessities for effective collaboration between human\ncoaches and chatbots. By doing so, this work contributes to the foundation for\naugmenting one's self-reflective process with prevalent conversational agents\nthrough the human-in-the-loop approach.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by the International ACM Conversational User Interfaces\n  Conference (CUI '24)",
    "pdf_url": "http://arxiv.org/pdf/2405.15250v1",
    "published_date": "2024-05-24 06:20:56 UTC",
    "updated_date": "2024-05-24 06:20:56 UTC"
  },
  {
    "arxiv_id": "2405.15245v1",
    "title": "Cooperative Backdoor Attack in Decentralized Reinforcement Learning with Theoretical Guarantee",
    "authors": [
      "Mengtong Gao",
      "Yifei Zou",
      "Zuyuan Zhang",
      "Xiuzhen Cheng",
      "Dongxiao Yu"
    ],
    "abstract": "The safety of decentralized reinforcement learning (RL) is a challenging\nproblem since malicious agents can share their poisoned policies with benign\nagents. The paper investigates a cooperative backdoor attack in a decentralized\nreinforcement learning scenario. Differing from the existing methods that hide\na whole backdoor attack behind their shared policies, our method decomposes the\nbackdoor behavior into multiple components according to the state space of RL.\nEach malicious agent hides one component in its policy and shares its policy\nwith the benign agents. When a benign agent learns all the poisoned policies,\nthe backdoor attack is assembled in its policy. The theoretical proof is given\nto show that our cooperative method can successfully inject the backdoor into\nthe RL policies of benign agents. Compared with the existing backdoor attacks,\nour cooperative method is more covert since the policy from each attacker only\ncontains a component of the backdoor attack and is harder to detect. Extensive\nsimulations are conducted based on Atari environments to demonstrate the\nefficiency and covertness of our method. To the best of our knowledge, this is\nthe first paper presenting a provable cooperative backdoor attack in\ndecentralized reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15245v1",
    "published_date": "2024-05-24 06:13:31 UTC",
    "updated_date": "2024-05-24 06:13:31 UTC"
  },
  {
    "arxiv_id": "2406.00024v2",
    "title": "Embedding-Aligned Language Models",
    "authors": [
      "Guy Tennenholtz",
      "Yinlam Chow",
      "Chih-Wei Hsu",
      "Lior Shani",
      "Ethan Liang",
      "Craig Boutilier"
    ],
    "abstract": "We propose a novel approach for training large language models (LLMs) to\nadhere to objectives defined within a latent embedding space. Our method\nleverages reinforcement learning (RL), treating a pre-trained LLM as an\nenvironment. Our embedding-aligned guided language (EAGLE) agent is trained to\niteratively steer the LLM's generation towards optimal regions of the latent\nembedding space, w.r.t. some predefined criterion. We demonstrate the\neffectiveness of the EAGLE agent using the MovieLens 25M and Amazon Review\ndatasets to surface content gaps that satisfy latent user demand. We also\ndemonstrate the benefit of using an optimal design of a state-dependent action\nset to improve EAGLE's efficiency. Our work paves the way for controlled and\ngrounded text generation using LLMs, ensuring consistency with domain-specific\nknowledge and data representations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00024v2",
    "published_date": "2024-05-24 06:11:17 UTC",
    "updated_date": "2024-10-28 06:30:42 UTC"
  },
  {
    "arxiv_id": "2405.15230v2",
    "title": "$i$REPO: $i$mplicit Reward Pairwise Difference based Empirical Preference Optimization",
    "authors": [
      "Long Tan Le",
      "Han Shu",
      "Tung-Anh Nguyen",
      "Choong Seon Hong",
      "Nguyen H. Tran"
    ],
    "abstract": "While astonishingly capable, large Language Models (LLM) can sometimes\nproduce outputs that deviate from human expectations. Such deviations\nnecessitate an alignment phase to prevent disseminating untruthful, toxic, or\nbiased information. Traditional alignment methods based on reinforcement\nlearning often struggle with the identified instability, whereas preference\noptimization methods are limited by their overfitting to pre-collected\nhard-label datasets. In this paper, we propose a novel LLM alignment framework\nnamed $i$REPO, which utilizes implicit Reward pairwise difference regression\nfor Empirical Preference Optimization. Particularly, $i$REPO employs\nself-generated datasets labeled by empirical human (or AI annotator) preference\nto iteratively refine the aligned policy through a novel regression-based loss\nfunction. Furthermore, we introduce an innovative algorithm backed by\ntheoretical guarantees for achieving optimal results under ideal assumptions\nand providing a practical performance-gap result without such assumptions.\nExperimental results with Phi-2 and Mistral-7B demonstrate that $i$REPO\neffectively achieves self-alignment using soft-label, self-generated responses\nand the logit of empirical AI annotators. Furthermore, our approach surpasses\npreference optimization baselines in evaluations using the Language Model\nEvaluation Harness and Multi-turn benchmarks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2405.15230v2",
    "published_date": "2024-05-24 05:42:11 UTC",
    "updated_date": "2024-10-29 00:19:13 UTC"
  },
  {
    "arxiv_id": "2405.15222v2",
    "title": "Leveraging Unknown Objects to Construct Labeled-Unlabeled Meta-Relationships for Zero-Shot Object Navigation",
    "authors": [
      "Yanwei Zheng",
      "Changrui Li",
      "Chuanlin Lan",
      "Yaling Li",
      "Xiao Zhang",
      "Yifei Zou",
      "Dongxiao Yu",
      "Zhipeng Cai"
    ],
    "abstract": "Zero-shot object navigation (ZSON) addresses situation where an agent\nnavigates to an unseen object that does not present in the training set.\nPrevious works mainly train agent using seen objects with known labels, and\nignore the seen objects without labels. In this paper, we introduce seen\nobjects without labels, herein termed as ``unknown objects'', into training\nprocedure to enrich the agent's knowledge base with distinguishable but\npreviously overlooked information. Furthermore, we propose the label-wise\nmeta-correlation module (LWMCM) to harness relationships among objects with and\nwithout labels, and obtain enhanced objects information. Specially, we propose\ntarget feature generator (TFG) to generate the features representation of the\nunlabeled target objects. Subsequently, the unlabeled object identifier (UOI)\nmodule assesses whether the unlabeled target object appears in the current\nobservation frame captured by the camera and produces an adapted target\nfeatures representation specific to the observed context. In meta contrastive\nfeature modifier (MCFM), the target features is modified via approaching the\nfeatures of objects within the observation frame while distancing itself from\nfeatures of unobserved objects. Finally, the meta object-graph learner (MOGL)\nmodule is utilized to calculate the relationships among objects based on the\nfeatures. Experiments conducted on AI2THOR and RoboTHOR platforms demonstrate\nthe effectiveness of our proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15222v2",
    "published_date": "2024-05-24 05:26:18 UTC",
    "updated_date": "2024-05-27 02:39:39 UTC"
  },
  {
    "arxiv_id": "2406.06549v1",
    "title": "Large Language Model (LLM) for Standard Cell Layout Design Optimization",
    "authors": [
      "Chia-Tung Ho",
      "Haoxing Ren"
    ],
    "abstract": "Standard cells are essential components of modern digital circuit designs.\nWith process technologies advancing toward 2nm, more routability issues have\narisen due to the decreasing number of routing tracks, increasing number and\ncomplexity of design rules, and strict patterning rules. The state-of-the-art\nstandard cell design automation framework is able to automatically design\nstandard cell layouts in advanced nodes, but it is still struggling to generate\nhighly competitive Performance-Power-Area (PPA) and routable cell layouts for\ncomplex sequential cell designs. Consequently, a novel and efficient\nmethodology incorporating the expertise of experienced human designers to\nincrementally optimize the PPA of cell layouts is highly necessary and\nessential. High-quality device clustering, with consideration of netlist\ntopology, diffusion sharing/break and routability in the layouts, can reduce\ncomplexity and assist in finding highly competitive PPA, and routable layouts\nfaster. In this paper, we leverage the natural language and reasoning ability\nof Large Language Model (LLM) to generate high-quality cluster constraints\nincrementally to optimize the cell layout PPA and debug the routability with\nReAct prompting. On a benchmark of sequential standard cells in 2nm, we\ndemonstrate that the proposed method not only achieves up to 19.4% smaller cell\narea, but also generates 23.5% more LVS/DRC clean cell layouts than previous\nwork. In summary, the proposed method not only successfully reduces cell area\nby 4.65% on average, but also is able to fix routability in the cell layout\ndesigns.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "6 pages, 8 figures, IEEE International Workshop on LLM-Aided Design\n  (LAD'24)",
    "pdf_url": "http://arxiv.org/pdf/2406.06549v1",
    "published_date": "2024-05-24 04:59:58 UTC",
    "updated_date": "2024-05-24 04:59:58 UTC"
  },
  {
    "arxiv_id": "2405.17477v3",
    "title": "OLLIE: Imitation Learning from Offline Pretraining to Online Finetuning",
    "authors": [
      "Sheng Yue",
      "Xingyuan Hua",
      "Ju Ren",
      "Sen Lin",
      "Junshan Zhang",
      "Yaoxue Zhang"
    ],
    "abstract": "In this paper, we study offline-to-online Imitation Learning (IL) that\npretrains an imitation policy from static demonstration data, followed by fast\nfinetuning with minimal environmental interaction. We find the na\\\"ive\ncombination of existing offline IL and online IL methods tends to behave poorly\nin this context, because the initial discriminator (often used in online IL)\noperates randomly and discordantly against the policy initialization, leading\nto misguided policy optimization and $\\textit{unlearning}$ of pretraining\nknowledge. To overcome this challenge, we propose a principled\noffline-to-online IL method, named $\\texttt{OLLIE}$, that simultaneously learns\na near-expert policy initialization along with an $\\textit{aligned\ndiscriminator initialization}$, which can be seamlessly integrated into online\nIL, achieving smooth and fast finetuning. Empirically, $\\texttt{OLLIE}$\nconsistently and significantly outperforms the baseline methods in\n$\\textbf{20}$ challenging tasks, from continuous control to vision-based\ndomains, in terms of performance, demonstration efficiency, and convergence\nspeed. This work may serve as a foundation for further exploration of\npretraining and finetuning in the context of IL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Machine Learning (ICML)",
    "pdf_url": "http://arxiv.org/pdf/2405.17477v3",
    "published_date": "2024-05-24 04:57:25 UTC",
    "updated_date": "2024-05-30 17:11:46 UTC"
  },
  {
    "arxiv_id": "2405.17476v3",
    "title": "How to Leverage Diverse Demonstrations in Offline Imitation Learning",
    "authors": [
      "Sheng Yue",
      "Jiani Liu",
      "Xingyuan Hua",
      "Ju Ren",
      "Sen Lin",
      "Junshan Zhang",
      "Yaoxue Zhang"
    ],
    "abstract": "Offline Imitation Learning (IL) with imperfect demonstrations has garnered\nincreasing attention owing to the scarcity of expert data in many real-world\ndomains. A fundamental problem in this scenario is how to extract positive\nbehaviors from noisy data. In general, current approaches to the problem select\ndata building on state-action similarity to given expert demonstrations,\nneglecting precious information in (potentially abundant) $\\textit{diverse}$\nstate-actions that deviate from expert ones. In this paper, we introduce a\nsimple yet effective data selection method that identifies positive behaviors\nbased on their resultant states -- a more informative criterion enabling\nexplicit utilization of dynamics information and effective extraction of both\nexpert and beneficial diverse behaviors. Further, we devise a lightweight\nbehavior cloning algorithm capable of leveraging the expert and selected data\ncorrectly. In the experiments, we evaluate our method on a suite of complex and\nhigh-dimensional offline IL benchmarks, including continuous-control and\nvision-based tasks. The results demonstrate that our method achieves\nstate-of-the-art performance, outperforming existing methods on\n$\\textbf{20/21}$ benchmarks, typically by $\\textbf{2-5x}$, while maintaining a\ncomparable runtime to Behavior Cloning ($\\texttt{BC}$).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Machine Learning (ICML)",
    "pdf_url": "http://arxiv.org/pdf/2405.17476v3",
    "published_date": "2024-05-24 04:56:39 UTC",
    "updated_date": "2024-05-30 17:15:09 UTC"
  },
  {
    "arxiv_id": "2405.19358v2",
    "title": "Robustifying Safety-Aligned Large Language Models through Clean Data Curation",
    "authors": [
      "Xiaoqun Liu",
      "Jiacheng Liang",
      "Muchao Ye",
      "Zhaohan Xi"
    ],
    "abstract": "Large language models (LLMs) are vulnerable when trained on datasets\ncontaining harmful content, which leads to potential jailbreaking attacks in\ntwo scenarios: the integration of harmful texts within crowdsourced data used\nfor pre-training and direct tampering with LLMs through fine-tuning. In both\nscenarios, adversaries can compromise the safety alignment of LLMs,\nexacerbating malfunctions. Motivated by the need to mitigate these adversarial\ninfluences, our research aims to enhance safety alignment by either\nneutralizing the impact of malicious texts in pre-training datasets or\nincreasing the difficulty of jailbreaking during downstream fine-tuning. In\nthis paper, we propose a data curation framework designed to counter\nadversarial impacts in both scenarios. Our method operates under the assumption\nthat we have no prior knowledge of attack details, focusing solely on curating\nclean texts. We introduce an iterative process aimed at revising texts to\nreduce their perplexity as perceived by LLMs, while simultaneously preserving\ntheir text quality. By pre-training or fine-tuning LLMs with curated clean\ntexts, we observe a notable improvement in LLM robustness regarding safety\nalignment against harmful queries. For instance, when pre-training LLMs using a\ncrowdsourced dataset containing 5\\% harmful instances, adding an equivalent\namount of curated texts significantly mitigates the likelihood of providing\nharmful responses in LLMs and reduces the attack success rate by 71\\%. Our\nstudy represents a significant step towards mitigating the risks associated\nwith training-based jailbreaking and fortifying the secure utilization of LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19358v2",
    "published_date": "2024-05-24 04:50:38 UTC",
    "updated_date": "2024-05-31 02:09:51 UTC"
  },
  {
    "arxiv_id": "2405.17475v2",
    "title": "How Culturally Aware are Vision-Language Models?",
    "authors": [
      "Olena Burda-Lassen",
      "Aman Chadha",
      "Shashank Goswami",
      "Vinija Jain"
    ],
    "abstract": "An image is often considered worth a thousand words, and certain images can\ntell rich and insightful stories. Can these stories be told via image\ncaptioning? Images from folklore genres, such as mythology, folk dance,\ncultural signs, and symbols, are vital to every culture. Our research compares\nthe performance of four popular vision-language models (GPT-4V, Gemini Pro\nVision, LLaVA, and OpenFlamingo) in identifying culturally specific information\nin such images and creating accurate and culturally sensitive image captions.\nWe also propose a new evaluation metric, the Cultural Awareness Score (CAS),\nwhich measures the degree of cultural awareness in image captions. We provide a\ndataset MOSAIC-1.5k labeled with ground truth for images containing cultural\nbackground and context and a labeled dataset with assigned Cultural Awareness\nScores that can be used with unseen data. Creating culturally appropriate image\ncaptions is valuable for scientific research and can be beneficial for many\npractical applications. We envision our work will promote a deeper integration\nof cultural sensitivity in AI applications worldwide. By making the dataset and\nCultural Awareness Score available to the public, we aim to facilitate further\nresearch in this area, encouraging the development of more culturally aware AI\nsystems that respect and celebrate global diversity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17475v2",
    "published_date": "2024-05-24 04:45:14 UTC",
    "updated_date": "2025-02-08 18:49:00 UTC"
  },
  {
    "arxiv_id": "2405.15208v1",
    "title": "Decoding at the Speed of Thought: Harnessing Parallel Decoding of Lexical Units for LLMs",
    "authors": [
      "Chenxi Sun",
      "Hongzhi Zhang",
      "Zijia Lin",
      "Jingyuan Zhang",
      "Fuzheng Zhang",
      "Zhongyuan Wang",
      "Bin Chen",
      "Chengru Song",
      "Di Zhang",
      "Kun Gai",
      "Deyi Xiong"
    ],
    "abstract": "Large language models have demonstrated exceptional capability in natural\nlanguage understanding and generation. However, their generation speed is\nlimited by the inherently sequential nature of their decoding process, posing\nchallenges for real-time applications. This paper introduces Lexical Unit\nDecoding (LUD), a novel decoding methodology implemented in a data-driven\nmanner, accelerating the decoding process without sacrificing output quality.\nThe core of our approach is the observation that a pre-trained language model\ncan confidently predict multiple contiguous tokens, forming the basis for a\n\\textit{lexical unit}, in which these contiguous tokens could be decoded in\nparallel. Extensive experiments validate that our method substantially reduces\ndecoding time while maintaining generation quality, i.e., 33\\% speed up on\nnatural language generation with no quality loss, and 30\\% speed up on code\ngeneration with a negligible quality loss of 3\\%. Distinctively, LUD requires\nno auxiliary models and does not require changes to existing architectures. It\ncan also be integrated with other decoding acceleration methods, thus achieving\nan even more pronounced inference efficiency boost. We posit that the\nfoundational principles of LUD could define a new decoding paradigm for future\nlanguage models, enhancing their applicability for a broader spectrum of\napplications. All codes are be publicly available at\nhttps://github.com/tjunlp-lab/Lexical-Unit-Decoding-LUD-. Keywords: Parallel\nDecoding, Lexical Unit Decoding, Large Language Model",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15208v1",
    "published_date": "2024-05-24 04:35:13 UTC",
    "updated_date": "2024-05-24 04:35:13 UTC"
  },
  {
    "arxiv_id": "2405.17474v2",
    "title": "Federated Offline Policy Optimization with Dual Regularization",
    "authors": [
      "Sheng Yue",
      "Zerui Qin",
      "Xingyuan Hua",
      "Yongheng Deng",
      "Ju Ren"
    ],
    "abstract": "Federated Reinforcement Learning (FRL) has been deemed as a promising\nsolution for intelligent decision-making in the era of Artificial Internet of\nThings. However, existing FRL approaches often entail repeated interactions\nwith the environment during local updating, which can be prohibitively\nexpensive or even infeasible in many real-world domains. To overcome this\nchallenge, this paper proposes a novel offline federated policy optimization\nalgorithm, named $\\texttt{DRPO}$, which enables distributed agents to\ncollaboratively learn a decision policy only from private and static data\nwithout further environmental interactions. $\\texttt{DRPO}$ leverages dual\nregularization, incorporating both the local behavioral policy and the global\naggregated policy, to judiciously cope with the intrinsic two-tier\ndistributional shifts in offline FRL. Theoretical analysis characterizes the\nimpact of the dual regularization on performance, demonstrating that by\nachieving the right balance thereof, $\\texttt{DRPO}$ can effectively counteract\ndistributional shifts and ensure strict policy improvement in each federative\nlearning round. Extensive experiments validate the significant performance\ngains of $\\texttt{DRPO}$ over baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE International Conference on Computer Communications (INFOCOM)",
    "pdf_url": "http://arxiv.org/pdf/2405.17474v2",
    "published_date": "2024-05-24 04:24:03 UTC",
    "updated_date": "2024-05-29 01:38:59 UTC"
  },
  {
    "arxiv_id": "2405.15194v2",
    "title": "Extracting Heuristics from Large Language Models for Reward Shaping in Reinforcement Learning",
    "authors": [
      "Siddhant Bhambri",
      "Amrita Bhattacharjee",
      "Durgesh Kalwar",
      "Lin Guan",
      "Huan Liu",
      "Subbarao Kambhampati"
    ],
    "abstract": "Reinforcement Learning (RL) suffers from sample inefficiency in sparse reward\ndomains, and the problem is further pronounced in case of stochastic\ntransitions. To improve the sample efficiency, reward shaping is a well-studied\napproach to introduce intrinsic rewards that can help the RL agent converge to\nan optimal policy faster. However, designing a useful reward shaping function\nfor all desirable states in the Markov Decision Process (MDP) is challenging,\neven for domain experts. Given that Large Language Models (LLMs) have\ndemonstrated impressive performance across a magnitude of natural language\ntasks, we aim to answer the following question: `Can we obtain heuristics using\nLLMs for constructing a reward shaping function that can boost an RL agent's\nsample efficiency?' To this end, we aim to leverage off-the-shelf LLMs to\ngenerate a plan for an abstraction of the underlying MDP. We further use this\nLLM-generated plan as a heuristic to construct the reward shaping signal for\nthe downstream RL agent. By characterizing the type of abstraction based on the\nMDP horizon length, we analyze the quality of heuristics when generated using\nan LLM, with and without a verifier in the loop. Our experiments across\nmultiple domains with varying horizon length and number of sub-goals from the\nBabyAI environment suite, Household, Mario, and, Minecraft domain, show 1) the\nadvantages and limitations of querying LLMs with and without a verifier to\ngenerate a reward shaping heuristic, and, 2) a significant improvement in the\nsample efficiency of PPO, A2C, and Q-learning when guided by the LLM-generated\nheuristics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15194v2",
    "published_date": "2024-05-24 03:53:57 UTC",
    "updated_date": "2024-10-07 19:33:34 UTC"
  },
  {
    "arxiv_id": "2405.15185v1",
    "title": "An Evaluation of Estimative Uncertainty in Large Language Models",
    "authors": [
      "Zhisheng Tang",
      "Ke Shen",
      "Mayank Kejriwal"
    ],
    "abstract": "Words of estimative probability (WEPs), such as ''maybe'' or ''probably not''\nare ubiquitous in natural language for communicating estimative uncertainty,\ncompared with direct statements involving numerical probability. Human\nestimative uncertainty, and its calibration with numerical estimates, has long\nbeen an area of study -- including by intelligence agencies like the CIA. This\nstudy compares estimative uncertainty in commonly used large language models\n(LLMs) like GPT-4 and ERNIE-4 to that of humans, and to each other. Here we\nshow that LLMs like GPT-3.5 and GPT-4 align with human estimates for some, but\nnot all, WEPs presented in English. Divergence is also observed when the LLM is\npresented with gendered roles and Chinese contexts. Further study shows that an\nadvanced LLM like GPT-4 can consistently map between statistical and estimative\nuncertainty, but a significant performance gap remains. The results contribute\nto a growing body of research on human-LLM alignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15185v1",
    "published_date": "2024-05-24 03:39:31 UTC",
    "updated_date": "2024-05-24 03:39:31 UTC"
  },
  {
    "arxiv_id": "2405.15182v2",
    "title": "RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation",
    "authors": [
      "Peihua Mai",
      "Ran Yan",
      "Yan Pang"
    ],
    "abstract": "Federated learning (FL) allows multiple devices to train a model\ncollaboratively without sharing their data. Despite its benefits, FL is\nvulnerable to privacy leakage and poisoning attacks. To address the privacy\nconcern, secure aggregation (SecAgg) is often used to obtain the aggregation of\ngradients on sever without inspecting individual user updates. Unfortunately,\nexisting defense strategies against poisoning attacks rely on the analysis of\nlocal updates in plaintext, making them incompatible with SecAgg. To reconcile\nthe conflicts, we propose a robust federated learning framework against\npoisoning attacks (RFLPA) based on SecAgg protocol. Our framework computes the\ncosine similarity between local updates and server updates to conduct robust\naggregation. Furthermore, we leverage verifiable packed Shamir secret sharing\nto achieve reduced communication cost of $O(M+N)$ per user, and design a novel\ndot product aggregation algorithm to resolve the issue of increased information\nleakage. Our experimental results show that RFLPA significantly reduces\ncommunication and computation overhead by over $75\\%$ compared to the\nstate-of-the-art secret sharing method, BREA, while maintaining competitive\naccuracy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "E.4"
    ],
    "primary_category": "cs.CR",
    "comment": "accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15182v2",
    "published_date": "2024-05-24 03:31:10 UTC",
    "updated_date": "2024-10-26 03:42:27 UTC"
  },
  {
    "arxiv_id": "2405.17473v2",
    "title": "Repeat-Aware Neighbor Sampling for Dynamic Graph Learning",
    "authors": [
      "Tao Zou",
      "Yuhao Mao",
      "Junchen Ye",
      "Bowen Du"
    ],
    "abstract": "Dynamic graph learning equips the edges with time attributes and allows\nmultiple links between two nodes, which is a crucial technology for\nunderstanding evolving data scenarios like traffic prediction and\nrecommendation systems. Existing works obtain the evolving patterns mainly\ndepending on the most recent neighbor sequences. However, we argue that whether\ntwo nodes will have interaction with each other in the future is highly\ncorrelated with the same interaction that happened in the past. Only\nconsidering the recent neighbors overlooks the phenomenon of repeat behavior\nand fails to accurately capture the temporal evolution of interactions. To fill\nthis gap, this paper presents RepeatMixer, which considers evolving patterns of\nfirst and high-order repeat behavior in the neighbor sampling strategy and\ntemporal information learning. Firstly, we define the first-order repeat-aware\nnodes of the source node as the destination nodes that have interacted\nhistorically and extend this concept to high orders as nodes in the destination\nnode's high-order neighbors. Then, we extract neighbors of the source node that\ninteracted before the appearance of repeat-aware nodes with a slide window\nstrategy as its neighbor sequence. Next, we leverage both the first and\nhigh-order neighbor sequences of source and destination nodes to learn temporal\npatterns of interactions via an MLP-based encoder. Furthermore, considering the\nvarying temporal patterns on different orders, we introduce a time-aware\naggregation mechanism that adaptively aggregates the temporal representations\nfrom different orders based on the significance of their interaction time\nsequences. Experimental results demonstrate the superiority of RepeatMixer over\nstate-of-the-art models in link prediction tasks, underscoring the\neffectiveness of the proposed repeat-aware neighbor sampling strategy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2024, Research Track",
    "pdf_url": "http://arxiv.org/pdf/2405.17473v2",
    "published_date": "2024-05-24 03:24:29 UTC",
    "updated_date": "2024-06-20 05:23:57 UTC"
  },
  {
    "arxiv_id": "2405.17472v2",
    "title": "FreezeAsGuard: Mitigating Illegal Adaptation of Diffusion Models via Selective Tensor Freezing",
    "authors": [
      "Kai Huang",
      "Haoming Wang",
      "Wei Gao"
    ],
    "abstract": "Text-to-image diffusion models can be fine-tuned in custom domains to adapt\nto specific user preferences, but such adaptability has also been utilized for\nillegal purposes, such as forging public figures' portraits, duplicating\ncopyrighted artworks and generating explicit contents. Existing work focused on\ndetecting the illegally generated contents, but cannot prevent or mitigate\nillegal adaptations of diffusion models. Other schemes of model unlearning and\nreinitialization, similarly, cannot prevent users from relearning the knowledge\nof illegal model adaptation with custom data. In this paper, we present\nFreezeAsGuard, a new technique that addresses these limitations and enables\nirreversible mitigation of illegal adaptations of diffusion models. Our\napproach is that the model publisher selectively freezes tensors in pre-trained\ndiffusion models that are critical to illegal model adaptations, to mitigate\nthe fine-tuned model's representation power in illegal adaptations, but\nminimize the impact on other legal adaptations. Experiment results in multiple\ntext-to-image application domains show that FreezeAsGuard provides 37% stronger\npower in mitigating illegal model adaptations compared to competitive\nbaselines, while incurring less than 5% impact on legal model adaptations. The\nsource code is available at: https://github.com/pittisl/FreezeAsGuard.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.17472v2",
    "published_date": "2024-05-24 03:23:51 UTC",
    "updated_date": "2024-11-27 04:43:01 UTC"
  },
  {
    "arxiv_id": "2405.17471v2",
    "title": "Momentum-Based Federated Reinforcement Learning with Interaction and Communication Efficiency",
    "authors": [
      "Sheng Yue",
      "Xingyuan Hua",
      "Lili Chen",
      "Ju Ren"
    ],
    "abstract": "Federated Reinforcement Learning (FRL) has garnered increasing attention\nrecently. However, due to the intrinsic spatio-temporal non-stationarity of\ndata distributions, the current approaches typically suffer from high\ninteraction and communication costs. In this paper, we introduce a new FRL\nalgorithm, named $\\texttt{MFPO}$, that utilizes momentum, importance sampling,\nand additional server-side adjustment to control the shift of stochastic policy\ngradients and enhance the efficiency of data utilization. We prove that by\nproper selection of momentum parameters and interaction frequency,\n$\\texttt{MFPO}$ can achieve $\\tilde{\\mathcal{O}}(H N^{-1}\\epsilon^{-3/2})$ and\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ interaction and communication complexities\n($N$ represents the number of agents), where the interaction complexity\nachieves linear speedup with the number of agents, and the communication\ncomplexity aligns the best achievable of existing first-order FL algorithms.\nExtensive experiments corroborate the substantial performance gains of\n$\\texttt{MFPO}$ over existing methods on a suite of complex and\nhigh-dimensional benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE International Conference on Computer Communications (INFOCOM)",
    "pdf_url": "http://arxiv.org/pdf/2405.17471v2",
    "published_date": "2024-05-24 03:23:37 UTC",
    "updated_date": "2024-05-29 01:36:56 UTC"
  },
  {
    "arxiv_id": "2405.15177v5",
    "title": "Diffusion Actor-Critic with Entropy Regulator",
    "authors": [
      "Yinuo Wang",
      "Likun Wang",
      "Yuxuan Jiang",
      "Wenjun Zou",
      "Tong Liu",
      "Xujie Song",
      "Wenxuan Wang",
      "Liming Xiao",
      "Jiang Wu",
      "Jingliang Duan",
      "Shengbo Eben Li"
    ],
    "abstract": "Reinforcement learning (RL) has proven highly effective in addressing complex\ndecision-making and control tasks. However, in most traditional RL algorithms,\nthe policy is typically parameterized as a diagonal Gaussian distribution with\nlearned mean and variance, which constrains their capability to acquire complex\npolicies. In response to this problem, we propose an online RL algorithm termed\ndiffusion actor-critic with entropy regulator (DACER). This algorithm\nconceptualizes the reverse process of the diffusion model as a novel policy\nfunction and leverages the capability of the diffusion model to fit multimodal\ndistributions, thereby enhancing the representational capacity of the policy.\nSince the distribution of the diffusion policy lacks an analytical expression,\nits entropy cannot be determined analytically. To mitigate this, we propose a\nmethod to estimate the entropy of the diffusion policy utilizing Gaussian\nmixture model. Building on the estimated entropy, we can learn a parameter\n$\\alpha$ that modulates the degree of exploration and exploitation. Parameter\n$\\alpha$ will be employed to adaptively regulate the variance of the added\nnoise, which is applied to the action output by the diffusion model.\nExperimental trials on MuJoCo benchmarks and a multimodal task demonstrate that\nthe DACER algorithm achieves state-of-the-art (SOTA) performance in most MuJoCo\ncontrol tasks while exhibiting a stronger representational capacity of the\ndiffusion policy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS2024 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2405.15177v5",
    "published_date": "2024-05-24 03:23:27 UTC",
    "updated_date": "2024-12-21 02:23:41 UTC"
  },
  {
    "arxiv_id": "2405.17470v1",
    "title": "Athena: Efficient Block-Wise Post-Training Quantization for Large Language Models Using Second-Order Matrix Derivative Information",
    "authors": [
      "Yanshu Wang",
      "Wenyang He",
      "Tong Yang"
    ],
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing tasks such as machine translation, text generation, and sentiment\nanalysis. However, their large size, often consisting of billions of\nparameters, poses challenges for storage, computation, and deployment,\nparticularly in resource-constrained environments like mobile devices and edge\ncomputing platforms. Effective compression and quantization techniques are\ncrucial for addressing these issues, reducing memory footprint and\ncomputational requirements without significantly compromising performance.\nTraditional methods that uniformly map parameters to compressed spaces fail to\naccount for the uneven distribution of parameters, leading to substantial\naccuracy loss. In this work, we propose Athena, a novel algorithm for efficient\nblock-wise post-training quantization of LLMs. Athena leverages Second-Order\nMatrix Derivative Information to guide the quantization process using the\ncurvature information of the loss landscape. By grouping parameters by columns\nor rows and iteratively optimizing the quantization process, Athena updates the\nmodel parameters and Hessian matrix to achieve significant compression while\nmaintaining high accuracy. This makes Athena a practical solution for deploying\nLLMs in various settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17470v1",
    "published_date": "2024-05-24 03:14:29 UTC",
    "updated_date": "2024-05-24 03:14:29 UTC"
  },
  {
    "arxiv_id": "2407.11974v1",
    "title": "Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone",
    "authors": [
      "Catalina Gomez",
      "Ruolin Wang",
      "Katharina Breininger",
      "Corinne Casey",
      "Chris Bradley",
      "Mitchell Pavlak",
      "Alex Pham",
      "Jithin Yohannan",
      "Mathias Unberath"
    ],
    "abstract": "Primary care providers are vital for initial triage and referrals to\nspecialty care. In glaucoma, asymptomatic and fast progression can lead to\nvision loss, necessitating timely referrals to specialists. However, primary\neye care providers may not identify urgent cases, potentially delaying care.\nArtificial Intelligence (AI) offering explanations could enhance their referral\ndecisions. We investigate how various AI explanations help providers\ndistinguish between patients needing immediate or non-urgent specialist\nreferrals. We built explainable AI algorithms to predict glaucoma surgery needs\nfrom routine eyecare data as a proxy for identifying high-risk patients. We\nincorporated intrinsic and post-hoc explainability and conducted an online\nstudy with optometrists to assess human-AI team performance, measuring referral\naccuracy and analyzing interactions with AI, including agreement rates, task\ntime, and user experience perceptions. AI support enhanced referral accuracy\namong 87 participants (59.9%/50.8% with/without AI), though Human-AI teams\nunderperformed compared to AI alone. Participants believed they included AI\nadvice more when using the intrinsic model, and perceived it more useful and\npromising. Without explanations, deviations from AI recommendations increased.\nAI support did not increase workload, confidence, and trust, but reduced\nchallenges. On a separate test set, our black-box and intrinsic models achieved\nan accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We\nidentify opportunities of human-AI teaming for glaucoma management in primary\neye care, noting that while AI enhances referral accuracy, it also shows a\nperformance gap compared to AI alone, even with explanations. Human involvement\nremains essential in medical decision making, underscoring the need for future\nresearch to optimize collaboration, ensuring positive experiences and safe AI\nuse.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.11974v1",
    "published_date": "2024-05-24 03:01:20 UTC",
    "updated_date": "2024-05-24 03:01:20 UTC"
  },
  {
    "arxiv_id": "2405.17469v1",
    "title": "A Dataset for Research on Water Sustainability",
    "authors": [
      "Pranjol Sen Gupta",
      "Md Rajib Hossen",
      "Pengfei Li",
      "Shaolei Ren",
      "Mohammad A. Islam"
    ],
    "abstract": "Freshwater scarcity is a global problem that requires collective efforts\nacross all industry sectors. Nevertheless, a lack of access to operational\nwater footprint data bars many applications from exploring optimization\nopportunities hidden within the temporal and spatial variations. To break this\nbarrier into research in water sustainability, we build a dataset for operation\ndirect water usage in the cooling systems and indirect water embedded in\nelectricity generation. Our dataset consists of the hourly water efficiency of\nmajor U.S. cities and states from 2019 to 2023. We also offer cooling system\nmodels that capture the impact of weather on water efficiency. We present a\npreliminary analysis of our dataset and discuss three potential applications\nthat can benefit from it. Our dataset is publicly available at Open Science\nFramework (OSF)",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ACM e-Energy 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.17469v1",
    "published_date": "2024-05-24 02:59:52 UTC",
    "updated_date": "2024-05-24 02:59:52 UTC"
  },
  {
    "arxiv_id": "2405.15165v1",
    "title": "A Solution-based LLM API-using Methodology for Academic Information Seeking",
    "authors": [
      "Yuanchun Wang",
      "Jifan Yu",
      "Zijun Yao",
      "Jing Zhang",
      "Yuyang Xie",
      "Shangqing Tu",
      "Yiyang Fu",
      "Youhe Feng",
      "Jinkai Zhang",
      "Jingyao Zhang",
      "Bowen Huang",
      "Yuanyao Li",
      "Huihui Yuan",
      "Lei Hou",
      "Juanzi Li",
      "Jie Tang"
    ],
    "abstract": "Applying large language models (LLMs) for academic API usage shows promise in\nreducing researchers' academic information seeking efforts. However, current\nLLM API-using methods struggle with complex API coupling commonly encountered\nin academic queries. To address this, we introduce SoAy, a solution-based LLM\nAPI-using methodology for academic information seeking. It uses code with a\nsolution as the reasoning method, where a solution is a pre-constructed API\ncalling sequence. The addition of the solution reduces the difficulty for the\nmodel to understand the complex relationships between APIs. Code improves the\nefficiency of reasoning.\n  To evaluate SoAy, we introduce SoAyBench, an evaluation benchmark accompanied\nby SoAyEval, built upon a cloned environment of APIs from AMiner. Experimental\nresults demonstrate a 34.58-75.99\\% performance improvement compared to\nstate-of-the-art LLM API-based baselines. All datasets, codes, tuned models,\nand deployed online services are publicly accessible at\nhttps://github.com/RUCKBReasoning/SoAy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15165v1",
    "published_date": "2024-05-24 02:44:14 UTC",
    "updated_date": "2024-05-24 02:44:14 UTC"
  },
  {
    "arxiv_id": "2405.15164v1",
    "title": "From Frege to chatGPT: Compositionality in language, cognition, and deep neural networks",
    "authors": [
      "Jacob Russin",
      "Sam Whitman McGrath",
      "Danielle J. Williams",
      "Lotem Elber-Dorozko"
    ],
    "abstract": "Compositionality has long been considered a key explanatory property\nunderlying human intelligence: arbitrary concepts can be composed into novel\ncomplex combinations, permitting the acquisition of an open ended, potentially\ninfinite expressive capacity from finite learning experiences. Influential\narguments have held that neural networks fail to explain this aspect of\nbehavior, leading many to dismiss them as viable models of human cognition.\nOver the last decade, however, modern deep neural networks (DNNs), which share\nthe same fundamental design principles as their predecessors, have come to\ndominate artificial intelligence, exhibiting the most advanced cognitive\nbehaviors ever demonstrated in machines. In particular, large language models\n(LLMs), DNNs trained to predict the next word on a large corpus of text, have\nproven capable of sophisticated behaviors such as writing syntactically complex\nsentences without grammatical errors, producing cogent chains of reasoning, and\neven writing original computer programs -- all behaviors thought to require\ncompositional processing. In this chapter, we survey recent empirical work from\nmachine learning for a broad audience in philosophy, cognitive science, and\nneuroscience, situating recent breakthroughs within the broader context of\nphilosophical arguments about compositionality. In particular, our review\nemphasizes two approaches to endowing neural networks with compositional\ngeneralization capabilities: (1) architectural inductive biases, and (2)\nmetalearning, or learning to learn. We also present findings suggesting that\nLLM pretraining can be understood as a kind of metalearning, and can thereby\nequip DNNs with compositional generalization abilities in a similar way. We\nconclude by discussing the implications that these findings may have for the\nstudy of compositionality in human cognition and by suggesting avenues for\nfuture research.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "32 pages (50 pages including references), 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15164v1",
    "published_date": "2024-05-24 02:36:07 UTC",
    "updated_date": "2024-05-24 02:36:07 UTC"
  },
  {
    "arxiv_id": "2405.15829v1",
    "title": "Spatio-temporal Value Semantics-based Abstraction for Dense Deep Reinforcement Learning",
    "authors": [
      "Jihui Nie",
      "Dehui Du",
      "Jiangnan Zhao"
    ],
    "abstract": "Intelligent Cyber-Physical Systems (ICPS) represent a specialized form of\nCyber-Physical System (CPS) that incorporates intelligent components, notably\nConvolutional Neural Networks (CNNs) and Deep Reinforcement Learning (DRL), to\nundertake multifaceted tasks encompassing perception, decision-making, and\ncontrol. The utilization of DRL for decision-making facilitates dynamic\ninteraction with the environment, generating control actions aimed at\nmaximizing cumulative rewards. Nevertheless, the inherent uncertainty of the\noperational environment and the intricate nature of ICPS necessitate\nexploration within complex and dynamic state spaces during the learning phase.\nDRL confronts challenges in terms of efficiency, generalization capabilities,\nand data scarcity during decision-making process. In response to these\nchallenges, we propose an innovative abstract modeling approach grounded in\nspatial-temporal value semantics, capturing the evolution in the distribution\nof semantic value across time and space. A semantics-based abstraction is\nintroduced to construct an abstract Markov Decision Process (MDP) for the DRL\nlearning process. Furthermore, optimization techniques for abstraction are\ndelineated, aiming to refine the abstract model and mitigate semantic gaps\nbetween abstract and concrete states. The efficacy of the abstract modeling is\nassessed through the evaluation and analysis of the abstract MDP model using\nPRISM. A series of experiments are conducted, involving diverse scenarios such\nas lane-keeping, adaptive cruise control, and intersection crossroad\nassistance, to demonstrate the effectiveness of our abstracting approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68N30",
      "D.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 7 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2405.15829v1",
    "published_date": "2024-05-24 02:21:10 UTC",
    "updated_date": "2024-05-24 02:21:10 UTC"
  },
  {
    "arxiv_id": "2405.15154v2",
    "title": "Online Prompt Pricing based on Combinatorial Multi-Armed Bandit and Hierarchical Stackelberg Game",
    "authors": [
      "Meiling Li",
      "Hongrun Ren",
      "Haixu Xiong",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "abstract": "Generation models have shown promising performance in various tasks, making\ntrading around machine learning models possible. In this paper, we aim at a\nnovel prompt trading scenario, prompt bundle trading (PBT) system, and propose\nan online pricing mechanism. Based on the combinatorial multi-armed bandit\n(CMAB) and three-stage hierarchical Stackelburg (HS) game, our pricing\nmechanism considers the profits of the consumer, platform, and seller,\nsimultaneously achieving the profit satisfaction of these three participants.\nWe break down the pricing issue into two steps, namely unknown category\nselection and incentive strategy optimization. The former step is to select a\nset of categories with the highest qualities, and the latter is to derive the\noptimal strategy for each participant based on the chosen categories. Unlike\nthe existing fixed pricing mode, the PBT pricing mechanism we propose is more\nflexible and diverse, which is more in accord with the transaction needs of\nreal-world scenarios. We test our method on a simulated text-to-image dataset.\nThe experimental results demonstrate the effectiveness of our algorithm, which\nprovides a feasible price-setting standard for the prompt marketplaces.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15154v2",
    "published_date": "2024-05-24 02:13:46 UTC",
    "updated_date": "2024-05-31 14:01:32 UTC"
  },
  {
    "arxiv_id": "2405.15152v1",
    "title": "Machine Unlearning in Large Language Models",
    "authors": [
      "Saaketh Koundinya Gundavarapu",
      "Shreya Agarwal",
      "Arushi Arora",
      "Chandana Thimmalapura Jagadeeshaiah"
    ],
    "abstract": "Machine unlearning, a novel area within artificial intelligence, focuses on\naddressing the challenge of selectively forgetting or reducing undesirable\nknowledge or behaviors in machine learning models, particularly in the context\nof large language models (LLMs). This paper introduces a methodology to align\nLLMs, such as Open Pre-trained Transformer Language Models, with ethical,\nprivacy, and safety standards by leveraging the gradient ascent algorithm for\nknowledge unlearning. Our approach aims to selectively erase or modify learned\ninformation in LLMs, targeting harmful responses and copyrighted content. This\npaper presents a dual-pronged approach to enhance the ethical and safe behavior\nof large language models (LLMs) by addressing the issues of harmful responses\nand copyrighted content. To mitigate harmful responses, we applied gradient\nascent on the PKU dataset, achieving a 75\\% reduction in harmful responses for\nOpen Pre-trained Transformer Language Models (OPT1.3b and OPT2.7b)\n\\citet{zhang2022opt} while retaining previous knowledge using the TruthfulQA\ndataset \\citet{DBLP:journals/corr/abs-2109-07958}. For handling copyrighted\ncontent, we constructed a custom dataset based on the Lord of the Rings corpus\nand aligned LLMs (OPT1.3b and OPT2.7b) \\citet{zhang2022opt} through LoRA:\nLow-Rank Adaptation of Large Language Models\n\\citet{DBLP:journals/corr/abs-2106-09685} finetuning. Subsequently, we employed\ngradient ascent to unlearn the Lord of the Rings content, resulting in a\nremarkable reduction in the presence of copyrighted material. To maintain a\ndiverse knowledge base, we utilized the Book Corpus dataset. Additionally, we\npropose a new evaluation technique for assessing the effectiveness of harmful\nunlearning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.15152v1",
    "published_date": "2024-05-24 02:12:51 UTC",
    "updated_date": "2024-05-24 02:12:51 UTC"
  },
  {
    "arxiv_id": "2405.17468v2",
    "title": "Deep Activity Model: A Generative Approach for Human Mobility Pattern Synthesis",
    "authors": [
      "Xishun Liao",
      "Qinhua Jiang",
      "Brian Yueshuai He",
      "Yifan Liu",
      "Chenchen Kuai",
      "Jiaqi Ma"
    ],
    "abstract": "Human mobility plays a crucial role in transportation, urban planning, and\npublic health. Advances in deep learning and the availability of diverse\nmobility data have transformed mobility modeling. However, existing deep\nlearning models often focus on spatio-temporal patterns and struggle to capture\nthe semantic interdependencies among activities, while also being limited by\nspecific data sources. These challenges reduce their realism and adaptability.\nTraditional activity-based models (ABMs) face issues as well, relying on rigid\nassumptions and requiring extensive data, making them costly and difficult to\nadapt to new regions, especially those with limited conventional travel data.\nTo address these limitations, we develop a novel generative deep learning\napproach for human mobility modeling and synthesis that incorporates both\nactivity patterns and location trajectories using open-source data. The model\ncan be fine-tuned with local data, allowing it to adapt to and accurately\nrepresent mobility patterns across diverse regions. The model is evaluated on a\nnationwide dataset of the United States, where it demonstrates superior\nperformance in generating activity-location chains that closely follow ground\ntruth distributions. Further tests using state- or city-specific datasets from\nCalifornia, Washington, and Mexico City confirm its transferability. This\ninnovative approach offers substantial potential to advance mobility modeling\nresearch, particularly in generating synthetic human mobility data. This can\nprovide urban planners and policymakers with enhanced tools for simulating\nmobility in diverse regions and better informing decisions related to\ntransportation, urban development, and public health.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17468v2",
    "published_date": "2024-05-24 02:04:10 UTC",
    "updated_date": "2024-11-03 06:38:52 UTC"
  },
  {
    "arxiv_id": "2405.15145v3",
    "title": "CulturePark: Boosting Cross-cultural Understanding in Large Language Models",
    "authors": [
      "Cheng Li",
      "Damien Teney",
      "Linyi Yang",
      "Qingsong Wen",
      "Xing Xie",
      "Jindong Wang"
    ],
    "abstract": "Cultural bias is pervasive in many large language models (LLMs), largely due\nto the deficiency of data representative of different cultures. Typically,\ncultural datasets and benchmarks are constructed either by extracting subsets\nof existing datasets or by aggregating from platforms such as Wikipedia and\nsocial media. However, these approaches are highly dependent on real-world data\nand human annotations, making them costly and difficult to scale. Inspired by\ncognitive theories on social communication, this paper introduces CulturePark,\nan LLM-powered multi-agent communication framework for cultural data\ncollection. CulturePark simulates cross-cultural human communication with\nLLM-based agents playing roles in different cultures. It generates high-quality\ncross-cultural dialogues encapsulating human beliefs, norms, and customs. Using\nCulturePark, we generated 41,000 cultural samples to fine-tune eight\nculture-specific LLMs. We evaluated these models across three downstream tasks:\ncontent moderation, cultural alignment, and cultural education. Results show\nthat for content moderation, our GPT-3.5-based models either match or\noutperform GPT-4 on datasets. Regarding cultural alignment, our models surpass\nGPT-4 on Hofstede's VSM 13 framework. Furthermore, for cultural education of\nhuman participants, our models demonstrate superior outcomes in both learning\nefficacy and user experience compared to GPT-4. CulturePark proves an important\nstep in addressing cultural bias and advancing the democratization of AI,\nhighlighting the critical role of culturally inclusive data in model training.\nCode is released at https://github.com/Scarelette/CulturePark.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024; Code is released at\n  https://github.com/Scarelette/CulturePark. arXiv admin note: substantial text\n  overlap with arXiv:2402.10946",
    "pdf_url": "http://arxiv.org/pdf/2405.15145v3",
    "published_date": "2024-05-24 01:49:02 UTC",
    "updated_date": "2024-11-21 10:52:29 UTC"
  },
  {
    "arxiv_id": "2405.15143v4",
    "title": "Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models",
    "authors": [
      "Cong Lu",
      "Shengran Hu",
      "Jeff Clune"
    ],
    "abstract": "Go-Explore is a powerful family of algorithms designed to solve\nhard-exploration problems built on the principle of archiving discovered\nstates, and iteratively returning to and exploring from the most promising\nstates. This approach has led to superhuman performance across a wide variety\nof challenging problems including Atari games and robotic control, but requires\nmanually designing heuristics to guide exploration (i.e., determine which\nstates to save and explore from, and what actions to consider next), which is\ntime-consuming and infeasible in general. To resolve this, we propose\nIntelligent Go-Explore (IGE) which greatly extends the scope of the original\nGo-Explore by replacing these handcrafted heuristics with the intelligence and\ninternalized human notions of interestingness captured by giant pretrained\nfoundation models (FMs). This provides IGE with a human-like ability to\ninstinctively identify how interesting or promising any new state is (e.g.,\ndiscovering new objects, locations, or behaviors), even in complex environments\nwhere heuristics are hard to define. Moreover, IGE offers the exciting\nopportunity to recognize and capitalize on serendipitous discoveries -- states\nencountered during exploration that are valuable in terms of exploration, yet\nwhere what makes them interesting was not anticipated by the human user. We\nevaluate our algorithm on a diverse range of language and vision-based tasks\nthat require search and exploration. Across these tasks, IGE strongly exceeds\nclassic reinforcement learning and graph search baselines, and also succeeds\nwhere prior state-of-the-art FM agents like Reflexion completely fail. Overall,\nIntelligent Go-Explore combines the tremendous strengths of FMs and the\npowerful Go-Explore algorithm, opening up a new frontier of research into\ncreating more generally capable agents with impressive exploration\ncapabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.15143v4",
    "published_date": "2024-05-24 01:45:27 UTC",
    "updated_date": "2025-02-07 11:10:39 UTC"
  },
  {
    "arxiv_id": "2405.15137v1",
    "title": "An Approximate Dynamic Programming Framework for Occlusion-Robust Multi-Object Tracking",
    "authors": [
      "Pratyusha Musunuru",
      "Yuchao Li",
      "Jamison Weber",
      "Dimitri Bertsekas"
    ],
    "abstract": "In this work, we consider data association problems involving multi-object\ntracking (MOT). In particular, we address the challenges arising from object\nocclusions. We propose a framework called approximate dynamic programming track\n(ADPTrack), which applies dynamic programming principles to improve an existing\nmethod called the base heuristic. Given a set of tracks and the next target\nframe, the base heuristic extends the tracks by matching them to the objects of\nthis target frame directly. In contrast, ADPTrack first processes a few\nsubsequent frames and applies the base heuristic starting from the next target\nframe to obtain tentative tracks. It then leverages the tentative tracks to\nmatch the objects of the target frame. This tends to reduce the occlusion-based\nerrors and leads to an improvement over the base heuristic. When tested on the\nMOT17 video dataset, the proposed method demonstrates a 0.7% improvement in the\nassociation accuracy (IDF1 metric) over a state-of-the-art method that is used\nas the base heuristic. It also obtains improvements with respect to all the\nother standard metrics. Empirically, we found that the improvements are\nparticularly pronounced in scenarios where the video data is obtained by\nfixed-position cameras.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15137v1",
    "published_date": "2024-05-24 01:27:14 UTC",
    "updated_date": "2024-05-24 01:27:14 UTC"
  },
  {
    "arxiv_id": "2405.15127v1",
    "title": "Benchmarking Hierarchical Image Pyramid Transformer for the classification of colon biopsies and polyps in histopathology images",
    "authors": [
      "Nohemi Sofia Leon Contreras",
      "Marina D'Amato",
      "Francesco Ciompi",
      "Clement Grisi",
      "Witali Aswolinskiy",
      "Simona Vatrano",
      "Filippo Fraggetta",
      "Iris Nagtegaal"
    ],
    "abstract": "Training neural networks with high-quality pixel-level annotation in\nhistopathology whole-slide images (WSI) is an expensive process due to\ngigapixel resolution of WSIs. However, recent advances in self-supervised\nlearning have shown that highly descriptive image representations can be\nlearned without the need for annotations. We investigate the application of the\nrecent Hierarchical Image Pyramid Transformer (HIPT) model for the specific\ntask of classification of colorectal biopsies and polyps. After evaluating the\neffectiveness of TCGA-learned features in the original HIPT model, we\nincorporate colon biopsy image information into HIPT's pretraining using two\ndistinct strategies: (1) fine-tuning HIPT from the existing TCGA weights and\n(2) pretraining HIPT from random weight initialization. We compare the\nperformance of these pretraining regimes on two colorectal biopsy\nclassification tasks: binary and multiclass classification.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "4 pages, 3 figures, to be published in the 2024 IEEE International\n  Symposium on Biomedical Imaging (ISBI) proceedings",
    "pdf_url": "http://arxiv.org/pdf/2405.15127v1",
    "published_date": "2024-05-24 00:59:30 UTC",
    "updated_date": "2024-05-24 00:59:30 UTC"
  },
  {
    "arxiv_id": "2405.15124v4",
    "title": "Scaling Law for Time Series Forecasting",
    "authors": [
      "Jingzhe Shi",
      "Qinwei Ma",
      "Huan Ma",
      "Lei Li"
    ],
    "abstract": "Scaling law that rewards large datasets, complex models and enhanced data\ngranularity has been observed in various fields of deep learning. Yet, studies\non time series forecasting have cast doubt on scaling behaviors of deep\nlearning methods for time series forecasting: while more training data improves\nperformance, more capable models do not always outperform less capable models,\nand longer input horizons may hurt performance for some models. We propose a\ntheory for scaling law for time series forecasting that can explain these\nseemingly abnormal behaviors. We take into account the impact of dataset size\nand model complexity, as well as time series data granularity, particularly\nfocusing on the look-back horizon, an aspect that has been unexplored in\nprevious theories. Furthermore, we empirically evaluate various models using a\ndiverse set of time series forecasting datasets, which (1) verifies the\nvalidity of scaling law on dataset size and model complexity within the realm\nof time series forecasting, and (2) validates our theoretical framework,\nparticularly regarding the influence of look back horizon. We hope our findings\nmay inspire new models targeting time series forecasting datasets of limited\nsize, as well as large foundational datasets and models for time series\nforecasting in future work. Code for our experiments has been made public at\nhttps://github.com/JingzheShi/ScalingLawForTimeSeriesForecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15124v4",
    "published_date": "2024-05-24 00:46:27 UTC",
    "updated_date": "2024-11-09 19:21:17 UTC"
  },
  {
    "arxiv_id": "2405.15828v1",
    "title": "Oil & Water? Diffusion of AI Within and Across Scientific Fields",
    "authors": [
      "Eamon Duede",
      "William Dolan",
      "Andr√© Bauer",
      "Ian Foster",
      "Karim Lakhani"
    ],
    "abstract": "This study empirically investigates claims of the increasing ubiquity of\nartificial intelligence (AI) within roughly 80 million research publications\nacross 20 diverse scientific fields, by examining the change in scholarly\nengagement with AI from 1985 through 2022. We observe exponential growth, with\nAI-engaged publications increasing approximately thirteenfold (13x) across all\nfields, suggesting a dramatic shift from niche to mainstream. Moreover, we\nprovide the first empirical examination of the distribution of AI-engaged\npublications across publication venues within individual fields, with results\nthat reveal a broadening of AI engagement within disciplines. While this\nbroadening engagement suggests a move toward greater disciplinary integration\nin every field, increased ubiquity is associated with a semantic tension\nbetween AI-engaged research and more traditional disciplinary research. Through\nan analysis of tens of millions of document embeddings, we observe a complex\ninterplay between AI-engaged and non-AI-engaged research within and across\nfields, suggesting that increasing ubiquity is something of an oil-and-water\nphenomenon -- AI-engaged work is spreading out over fields, but not mixing well\nwith non-AI-engaged work.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15828v1",
    "published_date": "2024-05-24 00:39:32 UTC",
    "updated_date": "2024-05-24 00:39:32 UTC"
  },
  {
    "arxiv_id": "2405.15116v2",
    "title": "Quantifying the Gain in Weak-to-Strong Generalization",
    "authors": [
      "Moses Charikar",
      "Chirag Pabbaraju",
      "Kirankumar Shiragur"
    ],
    "abstract": "Recent advances in large language models have shown capabilities that are\nextraordinary and near-superhuman. These models operate with such complexity\nthat reliably evaluating and aligning them proves challenging for humans. This\nleads to the natural question: can guidance from weak models (like humans)\nadequately direct the capabilities of strong models? In a recent and somewhat\nsurprising work, Burns et al. (2023) empirically demonstrated that when strong\nmodels (like GPT-4) are finetuned using labels generated by weak supervisors\n(like GPT-2), the strong models outperform their weaker counterparts -- a\nphenomenon they term weak-to-strong generalization.\n  In this work, we present a theoretical framework for understanding\nweak-to-strong generalization. Specifically, we show that the improvement in\nperformance achieved by strong models over their weaker counterparts is\nquantified by the misfit error incurred by the strong model on labels generated\nby the weaker model. Our theory reveals several curious algorithmic insights.\nFor instance, we can predict the amount by which the strong model will improve\nover the weak model, and also choose among different weak models to train the\nstrong model, based on its misfit error. We validate our theoretical findings\nthrough various empirical assessments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages; NeurIPS 2024 camera-ready version with additional\n  experiments, references and discussion",
    "pdf_url": "http://arxiv.org/pdf/2405.15116v2",
    "published_date": "2024-05-24 00:14:16 UTC",
    "updated_date": "2024-10-23 03:55:34 UTC"
  }
]