[
  {
    "arxiv_id": "2509.03771v3",
    "title": "Co-Evolving Complexity: An Adversarial Framework for Automatic MARL Curricula",
    "authors": [
      "Brennen Hill"
    ],
    "abstract": "The advancement of general-purpose intelligent agents is intrinsically linked to the environments in which they are trained. While scaling models and datasets has yielded remarkable capabilities, scaling the complexity, diversity, and interactivity of environments remains a crucial bottleneck. Hand-crafted environments are finite and often contain implicit biases, limiting the potential for agents to develop truly generalizable and robust skills. In this work, we propose a paradigm for generating a boundless and adaptive curriculum of challenges by framing the environment generation process as an adversarial game. We introduce a system where a team of cooperative multi-agent defenders learns to survive against a procedurally generative attacker. The attacker agent learns to produce increasingly challenging configurations of enemy units, dynamically creating novel worlds tailored to exploit the defenders' current weaknesses. Concurrently, the defender team learns cooperative strategies to overcome these generated threats. This co-evolutionary dynamic creates a self-scaling environment where complexity arises organically from the adversarial interaction, providing an effectively infinite stream of novel and relevant training data. We demonstrate that with minimal training, this approach leads to the emergence of complex, intelligent behaviors, such as flanking and shielding by the attacker, and focus-fire and spreading by the defenders. Our findings suggest that adversarial co-evolution is a powerful mechanism for automatically scaling environmental complexity, driving agents towards greater robustness and strategic depth.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Scaling Environments for Agents (SEA)",
    "pdf_url": "https://arxiv.org/pdf/2509.03771v3",
    "published_date": "2025-09-03 23:32:39 UTC",
    "updated_date": "2025-11-04 06:38:29 UTC"
  },
  {
    "arxiv_id": "2509.03768v1",
    "title": "RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs",
    "authors": [
      "Connor Walker",
      "Koorosh Aslansefat",
      "Mohammad Naveed Akram",
      "Yiannis Papadopoulos"
    ],
    "abstract": "Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet conventional Large Language Models (LLMs) often fail when confronted with highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced Retrieval-Augmented Generation (RAG) framework that explicitly integrates safety-critical documents alongside technical manuals.By issuing parallel queries to two indices and allocating separate retrieval budgets for knowledge and safety, RAGuard guarantees both technical depth and safety coverage. We further develop a SafetyClamp extension that fetches a larger candidate pool, \"hard-clamping\" exact slot guarantees to safety. We evaluate across sparse (BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms, measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of RAG show an increase in Safety Recall@K from almost 0\\% in RAG to more than 50\\% in RAGuard, while maintaining Technical Recall above 60\\%. These results demonstrate that RAGuard and SafetyClamp have the potential to establish a new standard for integrating safety assurance into LLM-powered decision support in critical maintenance contexts.",
    "categories": [
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03768v1",
    "published_date": "2025-09-03 23:24:17 UTC",
    "updated_date": "2025-09-03 23:24:17 UTC"
  },
  {
    "arxiv_id": "2509.03757v1",
    "title": "ARDO: A Weak Formulation Deep Neural Network Method for Elliptic and Parabolic PDEs Based on Random Differences of Test Functions",
    "authors": [
      "Wei Cai",
      "Andrew Qing He"
    ],
    "abstract": "We propose ARDO method for solving PDEs and PDE-related problems with deep learning techniques. This method uses a weak adversarial formulation but transfers the random difference operator onto the test function. The main advantage of this framework is that it is fully derivative-free with respect to the solution neural network. This framework is particularly suitable for Fokker-Planck type second-order elliptic and parabolic PDEs.",
    "categories": [
      "math.NA",
      "cs.AI"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03757v1",
    "published_date": "2025-09-03 22:54:12 UTC",
    "updated_date": "2025-09-03 22:54:12 UTC"
  },
  {
    "arxiv_id": "2509.03754v1",
    "title": "STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification",
    "authors": [
      "Zongsen Qiu"
    ],
    "abstract": "Responding to rising global food security needs, precision agriculture and deep learning-based plant disease diagnosis have become crucial. Yet, deploying high-precision models on edge devices is challenging. Most lightweight networks use attention mechanisms designed for generic object recognition, which poorly capture subtle pathological features like irregular lesion shapes and complex textures. To overcome this, we propose a twofold solution: first, using a training-free neural architecture search method (DeepMAD) to create an efficient network backbone for edge devices; second, introducing the Shape-Texture Attention Module (STAM). STAM splits attention into two branches -- one using deformable convolutions (DCNv4) for shape awareness and the other using a Gabor filter bank for texture awareness. On the public CCMT plant disease dataset, our STA-Net model (with 401K parameters and 51.1M FLOPs) reached 89.00% accuracy and an F1 score of 88.96%. Ablation studies confirm STAM significantly improves performance over baseline and standard attention models. Integrating domain knowledge via decoupled attention thus presents a promising path for edge-deployed precision agriculture AI. The source code is available at https://github.com/RzMY/STA-Net.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03754v1",
    "published_date": "2025-09-03 22:46:20 UTC",
    "updated_date": "2025-09-03 22:46:20 UTC"
  },
  {
    "arxiv_id": "2509.03741v1",
    "title": "Designing Gaze Analytics for ELA Instruction: A User-Centered Dashboard with Conversational AI Support",
    "authors": [
      "Eduardo Davalos",
      "Yike Zhang",
      "Shruti Jain",
      "Namrata Srivastava",
      "Trieu Truong",
      "Nafees-ul Haque",
      "Tristan Van",
      "Jorge Salas",
      "Sara McFadden",
      "Sun-Joo Cho",
      "Gautam Biswas",
      "Amanda Goodwin"
    ],
    "abstract": "Eye-tracking offers rich insights into student cognition and engagement, but remains underutilized in classroom-facing educational technology due to challenges in data interpretation and accessibility. In this paper, we present the iterative design and evaluation of a gaze-based learning analytics dashboard for English Language Arts (ELA), developed through five studies involving teachers and students. Guided by user-centered design and data storytelling principles, we explored how gaze data can support reflection, formative assessment, and instructional decision-making. Our findings demonstrate that gaze analytics can be approachable and pedagogically valuable when supported by familiar visualizations, layered explanations, and narrative scaffolds. We further show how a conversational agent, powered by a large language model (LLM), can lower cognitive barriers to interpreting gaze data by enabling natural language interactions with multimodal learning analytics. We conclude with design implications for future EdTech systems that aim to integrate novel data modalities in classroom contexts.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "22 pages, 9 figures, 3 tables, submitted to IUI2026",
    "pdf_url": "https://arxiv.org/pdf/2509.03741v1",
    "published_date": "2025-09-03 22:01:14 UTC",
    "updated_date": "2025-09-03 22:01:14 UTC"
  },
  {
    "arxiv_id": "2509.03738v2",
    "title": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces",
    "authors": [
      "Bahareh Tolooshams",
      "Ailsa Shen",
      "Anima Anandkumar"
    ],
    "abstract": "We frame the problem of unifying representations in neural models as one of sparse model recovery and introduce a framework that extends sparse autoencoders (SAEs) to lifted spaces and infinite-dimensional function spaces, enabling mechanistic interpretability of large neural operators (NO). While the Platonic Representation Hypothesis suggests that neural networks converge to similar representations across architectures, the representational properties of neural operators remain underexplored despite their growing importance in scientific computing. We compare the inference and training dynamics of SAEs, lifted-SAE, and SAE neural operators. We highlight how lifting and operator modules introduce beneficial inductive biases, enabling faster recovery, improved recovery of smooth concepts, and robust inference across varying resolutions, a property unique to neural operators.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Tolooshams and Shen has equal contribution. Extended Abstract at the Workshop on Unifying Representations in Neural Models (UniReps 2025) at NeurIPS",
    "pdf_url": "https://arxiv.org/pdf/2509.03738v2",
    "published_date": "2025-09-03 21:57:03 UTC",
    "updated_date": "2025-10-23 01:32:48 UTC"
  },
  {
    "arxiv_id": "2509.03736v1",
    "title": "Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation",
    "authors": [
      "James Mooney",
      "Josef Woldense",
      "Zheng Robert Jia",
      "Shirley Anugrah Hayati",
      "My Ha Nguyen",
      "Vipul Raheja",
      "Dongyeop Kang"
    ],
    "abstract": "The impressive capabilities of Large Language Models (LLMs) have fueled the notion that synthetic agents can serve as substitutes for real participants in human-subject research. In an effort to evaluate the merits of this claim, social science researchers have largely focused on whether LLM-generated survey data corresponds to that of a human counterpart whom the LLM is prompted to represent. In contrast, we address a more fundamental question: Do agents maintain internal consistency, retaining similar behaviors when examined under different experimental settings? To this end, we develop a study designed to (a) reveal the agent's internal state and (b) examine agent behavior in a basic dialogue setting. This design enables us to explore a set of behavioral hypotheses to assess whether an agent's conversation behavior is consistent with what we would expect from their revealed internal state. Our findings on these hypotheses show significant internal inconsistencies in LLMs across model families and at differing model sizes. Most importantly, we find that, although agents may generate responses matching those of their human counterparts, they fail to be internally consistent, representing a critical gap in their capabilities to accurately substitute for real participants in human-subject research. Our simulation code and data are publicly accessible.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 9 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.03736v1",
    "published_date": "2025-09-03 21:55:29 UTC",
    "updated_date": "2025-09-03 21:55:29 UTC"
  },
  {
    "arxiv_id": "2509.03733v2",
    "title": "Differentiable Entropy Regularization: A Complexity-Aware Approach for Neural Optimization",
    "authors": [
      "Ibne Farabi Shihab",
      "Sanjeda Akter",
      "Anuj Sharma"
    ],
    "abstract": "We introduce the first differentiable approximation of range-partition entropy, a complexity measure from computational geometry that directly bounds algorithmic runtime. Unlike architectural modifications, our method is a complementary regularizer that provides orthogonal efficiency gains when combined with existing optimizations. We establish theoretical guarantees in computational geometry, achieving 4--5$\\times$ provable speedups on convex hull and triangulation with $<$0.2\\% error. On ImageNet-1K with ViT-Base, entropy regularization achieves 80.1\\% top-1 accuracy at 80\\% sparsity (1.60$\\times$ standalone speedup), and when combined with FlashAttention yields 2.07$\\times$ speedup versus 1.63$\\times$ for FlashAttention alone. On large language models (LLaMA-2 7B, Mistral-7B, Phi-2), we achieve 1.48--1.60$\\times$ inference speedups at 70--75\\% sparsity with minimal quality degradation (ROUGE-L drops of 0.3--0.4 points, perplexity increase of 0.9). Unlike prior regularization methods that target output distributions, we directly minimize representation complexity, yielding both efficiency gains and improved robustness through semantically structured sparsity patterns (IoU 0.73 vs 0.41 for magnitude pruning, CIFAR-100-C mCE 48.7 vs 55.4). Benefits are strongest for geometry and vision transformers, with more modest but measurable gains on LLMs, demonstrating that complexity regularization offers a principled pathway to joint efficiency-robustness optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03733v2",
    "published_date": "2025-09-03 21:38:22 UTC",
    "updated_date": "2025-11-19 04:56:47 UTC"
  },
  {
    "arxiv_id": "2509.03730v2",
    "title": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs",
    "authors": [
      "Pengrui Han",
      "Rafal Kocielnik",
      "Peiyang Song",
      "Ramit Debnath",
      "Dean Mobbs",
      "Anima Anandkumar",
      "R. Michael Alvarez"
    ],
    "abstract": "Personality traits have long been studied as predictors of human behavior. Recent advances in Large Language Models (LLMs) suggest similar patterns may emerge in artificial systems, with advanced LLMs displaying consistent behavioral tendencies resembling human traits like agreeableness and self-regulation. Understanding these patterns is crucial, yet prior work primarily relied on simplified self-reports and heuristic prompting, with little behavioral validation. In this study, we systematically characterize LLM personality across three dimensions: (1) the dynamic emergence and evolution of trait profiles throughout training stages; (2) the predictive validity of self-reported traits in behavioral tasks; and (3) the impact of targeted interventions, such as persona injection, on both self-reports and behavior. Our findings reveal that instructional alignment (e.g., RLHF, instruction tuning) significantly stabilizes trait expression and strengthens trait correlations in ways that mirror human data. However, these self-reported traits do not reliably predict behavior, and observed associations often diverge from human patterns. While persona injection successfully steers self-reports in the intended direction, it exerts little or inconsistent effect on actual behavior. By distinguishing surface-level trait expression from behavioral consistency, our findings challenge assumptions about LLM personality and underscore the need for deeper evaluation in alignment and interpretability.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "We make public all code and source data at https://github.com/psychology-of-AI/Personality-Illusion for full reproducibility",
    "pdf_url": "https://arxiv.org/pdf/2509.03730v2",
    "published_date": "2025-09-03 21:27:10 UTC",
    "updated_date": "2025-09-05 01:39:01 UTC"
  },
  {
    "arxiv_id": "2509.03728v3",
    "title": "PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming",
    "authors": [
      "Wesley Hanwen Deng",
      "Sunnie S. Y. Kim",
      "Akshita Jha",
      "Ken Holstein",
      "Motahhare Eslami",
      "Lauren Wilcox",
      "Leon A Gatys"
    ],
    "abstract": "Recent developments in AI governance and safety research have called for red-teaming methods that can effectively surface potential risks posed by AI models. Many of these calls have emphasized how the identities and backgrounds of red-teamers can shape their red-teaming strategies, and thus the kinds of risks they are likely to uncover. While automated red-teaming approaches promise to complement human red-teaming by enabling larger-scale exploration of model behavior, current approaches do not consider the role of identity. As an initial step towards incorporating people's background and identities in automated red-teaming, we develop and evaluate a novel method, PersonaTeaming, that introduces personas in the adversarial prompt generation process to explore a wider spectrum of adversarial strategies. In particular, we first introduce a methodology for mutating prompts based on either \"red-teaming expert\" personas or \"regular AI user\" personas. We then develop a dynamic persona-generating algorithm that automatically generates various persona types adaptive to different seed prompts. In addition, we develop a set of new metrics to explicitly measure the \"mutation distance\" to complement existing diversity measurements of adversarial prompts. Our experiments show promising improvements (up to 144.1%) in the attack success rates of adversarial prompts through persona mutation, while maintaining prompt diversity, compared to RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the strengths and limitations of different persona types and mutation methods, shedding light on future opportunities to explore complementarities between automated and human red-teaming approaches.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03728v3",
    "published_date": "2025-09-03 21:20:38 UTC",
    "updated_date": "2025-10-27 04:01:19 UTC"
  },
  {
    "arxiv_id": "2509.03725v1",
    "title": "MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection",
    "authors": [
      "Parush Gera",
      "Tempestt Neal"
    ],
    "abstract": "We present the novel approach for stance detection across domains and targets, Metric Learning-Based Few-Shot Learning for Cross-Target and Cross-Domain Stance Detection (MLSD). MLSD utilizes metric learning with triplet loss to capture semantic similarities and differences between stance targets, enhancing domain adaptation. By constructing a discriminative embedding space, MLSD allows a cross-target or cross-domain stance detection model to acquire useful examples from new target domains. We evaluate MLSD in multiple cross-target and cross-domain scenarios across two datasets, showing statistically significant improvement in stance detection performance across six widely used stance detection models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03725v1",
    "published_date": "2025-09-03 21:12:07 UTC",
    "updated_date": "2025-09-03 21:12:07 UTC"
  },
  {
    "arxiv_id": "2509.03709v3",
    "title": "From Federated Learning to X-Learning: Breaking the Barriers of Decentrality Through Random Walks",
    "authors": [
      "Allan Salihovic",
      "Payam Abdisarabshali",
      "Michael Langberg",
      "Seyyedali Hosseinalipour"
    ],
    "abstract": "We provide our perspective on X-Learning (XL), a novel distributed learning architecture that generalizes and extends the concept of decentralization. Our goal is to present a vision for XL, introducing its unexplored design considerations and degrees of freedom. To this end, we shed light on the intuitive yet non-trivial connections between XL, graph theory, and Markov chains. We also present a series of open research directions to stimulate further research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.03709v3",
    "published_date": "2025-09-03 20:48:41 UTC",
    "updated_date": "2025-10-09 21:10:54 UTC"
  },
  {
    "arxiv_id": "2509.03695v1",
    "title": "Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures",
    "authors": [
      "Payam Abdisarabshali",
      "Fardis Nadimi",
      "Kasra Borazjani",
      "Naji Khosravan",
      "Minghui Liwang",
      "Wei Ni",
      "Dusit Niyato",
      "Michael Langberg",
      "Seyyedali Hosseinalipour"
    ],
    "abstract": "The rise of foundation models (FMs) has reshaped the landscape of machine learning. As these models continued to grow, leveraging geo-distributed data from wireless devices has become increasingly critical, giving rise to federated foundation models (FFMs). More recently, FMs have evolved into multi-modal multi-task (M3T) FMs (e.g., GPT-4) capable of processing diverse modalities across multiple tasks, which motivates a new underexplored paradigm: M3T FFMs. In this paper, we unveil an unexplored variation of M3T FFMs by proposing hierarchical federated foundation models (HF-FMs), which in turn expose two overlooked heterogeneity dimensions to fog/edge networks that have a direct impact on these emerging models: (i) heterogeneity in collected modalities and (ii) heterogeneity in executed tasks across fog/edge nodes. HF-FMs strategically align the modular structure of M3T FMs, comprising modality encoders, prompts, mixture-of-experts (MoEs), adapters, and task heads, with the hierarchical nature of fog/edge infrastructures. Moreover, HF-FMs enable the optional usage of device-to-device (D2D) communications, enabling horizontal module relaying and localized cooperative training among nodes when feasible. Through delving into the architectural design of HF-FMs, we highlight their unique capabilities along with a series of tailored future research directions. Finally, to demonstrate their potential, we prototype HF-FMs in a wireless network setting and release the open-source code for the development of HF-FMs with the goal of fostering exploration in this untapped field (GitHub: https://github.com/payamsiabd/M3T-FFM).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2509.03695v1",
    "published_date": "2025-09-03 20:23:19 UTC",
    "updated_date": "2025-09-03 20:23:19 UTC"
  },
  {
    "arxiv_id": "2509.03680v1",
    "title": "LuxDiT: Lighting Estimation with Video Diffusion Transformer",
    "authors": [
      "Ruofan Liang",
      "Kai He",
      "Zan Gojcic",
      "Igor Gilitschenski",
      "Sanja Fidler",
      "Nandita Vijaykumar",
      "Zian Wang"
    ],
    "abstract": "Estimating scene lighting from a single image or video remains a longstanding challenge in computer vision and graphics. Learning-based approaches are constrained by the scarcity of ground-truth HDR environment maps, which are expensive to capture and limited in diversity. While recent generative models offer strong priors for image synthesis, lighting estimation remains difficult due to its reliance on indirect visual cues, the need to infer global (non-local) context, and the recovery of high-dynamic-range outputs. We propose LuxDiT, a novel data-driven approach that fine-tunes a video diffusion transformer to generate HDR environment maps conditioned on visual input. Trained on a large synthetic dataset with diverse lighting conditions, our model learns to infer illumination from indirect visual cues and generalizes effectively to real-world scenes. To improve semantic alignment between the input and the predicted environment map, we introduce a low-rank adaptation finetuning strategy using a collected dataset of HDR panoramas. Our method produces accurate lighting predictions with realistic angular high-frequency details, outperforming existing state-of-the-art techniques in both quantitative and qualitative evaluations.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "Project page: https://research.nvidia.com/labs/toronto-ai/LuxDiT/",
    "pdf_url": "https://arxiv.org/pdf/2509.03680v1",
    "published_date": "2025-09-03 19:59:20 UTC",
    "updated_date": "2025-09-03 19:59:20 UTC"
  },
  {
    "arxiv_id": "2509.03677v2",
    "title": "Insights from Gradient Dynamics: Gradient Autoscaled Normalization",
    "authors": [
      "Vincent-Daniel Yun"
    ],
    "abstract": "Gradient dynamics play a central role in determining the stability and generalization of deep neural networks. In this work, we provide an empirical analysis of how variance and standard deviation of gradients evolve during training, showing consistent changes across layers and at the global scale in convolutional networks. Motivated by these observations, we propose a hyperparameter-free gradient normalization method that aligns gradient scaling with their natural evolution. This approach prevents unintended amplification, stabilizes optimization, and preserves convergence guarantees. Experiments on the challenging CIFAR-100 benchmark with ResNet-20, ResNet-56, and VGG-16-BN demonstrate that our method maintains or improves test accuracy even under strong generalization. Beyond practical performance, our study highlights the importance of directly tracking gradient dynamics, aiming to bridge the gap between theoretical expectations and empirical behaviors, and to provide insights for future optimization research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03677v2",
    "published_date": "2025-09-03 19:54:23 UTC",
    "updated_date": "2025-09-08 06:17:26 UTC"
  },
  {
    "arxiv_id": "2509.03658v2",
    "title": "Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning",
    "authors": [
      "Antonio Guillen-Perez"
    ],
    "abstract": "The ability to generate a diverse and plausible distribution of future trajectories is a critical capability for autonomous vehicle planning systems. While recent generative models have shown promise, achieving high fidelity, computational efficiency, and precise control remains a significant challenge. In this paper, we present the Efficient Virtuoso, a conditional latent diffusion model for goal-conditioned trajectory planning. Our approach introduces a novel two-stage normalization pipeline that first scales trajectories to preserve their geometric aspect ratio and then normalizes the resulting PCA latent space to ensure a stable training target. The denoising process is performed efficiently in this low-dimensional latent space by a simple MLP denoiser, which is conditioned on a rich scene context fused by a powerful Transformer-based StateEncoder. We demonstrate that our method achieves state-of-the-art performance on the Waymo Open Motion Dataset, achieving a minimum Average Displacement Error (minADE) of 0.25. Furthermore, through a rigorous ablation study on goal representation, we provide a key insight: while a single endpoint goal can resolve strategic ambiguity, a richer, multi-step sparse route is essential for enabling the precise, high-fidelity tactical execution that mirrors nuanced human driving behavior.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03658v2",
    "published_date": "2025-09-03 19:18:02 UTC",
    "updated_date": "2025-09-06 15:10:15 UTC"
  },
  {
    "arxiv_id": "2509.05361v2",
    "title": "Constitutional Law and AI Governance: Constraints on Model Licensing and Research Classification",
    "authors": [
      "Alex Mark",
      "Aaron Scher"
    ],
    "abstract": "Transformative AI systems may pose unprecedented catastrophic risks, but the U.S. Constitution places significant constraints on the government's ability to govern this technology. This paper examines how the First Amendment, administrative law, and the Fourteenth Amendment shape the legal vulnerability of two regulatory proposals: model licensing and AI research classification. While the First Amendment may provide some degree of protection for model algorithms or outputs, this protection does not foreclose regulation. Policymakers must also consider administrative legal requirements, due to both agency review and authority. Finally, while substantive due process and equal protection pose minimal obstacles, procedural due process requires the government to clearly define when developers vest a legal interest in their models. Given this analysis, effective AI governance requires careful implementation to avoid these legal challenges.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05361v2",
    "published_date": "2025-09-03 19:09:06 UTC",
    "updated_date": "2025-12-18 17:36:48 UTC"
  },
  {
    "arxiv_id": "2509.03652v1",
    "title": "Nonnegative matrix factorization and the principle of the common cause",
    "authors": [
      "E. Khalafyan",
      "A. E. Allahverdyan",
      "A. Hovhannisyan"
    ],
    "abstract": "Nonnegative matrix factorization (NMF) is a known unsupervised data-reduction method. The principle of the common cause (PCC) is a basic methodological approach in probabilistic causality, which seeks an independent mixture model for the joint probability of two dependent random variables. It turns out that these two concepts are closely related. This relationship is explored reciprocally for several datasets of gray-scale images, which are conveniently mapped into probability models. On one hand, PCC provides a predictability tool that leads to a robust estimation of the effective rank of NMF. Unlike other estimates (e.g., those based on the Bayesian Information Criteria), our estimate of the rank is stable against weak noise. We show that NMF implemented around this rank produces features (basis images) that are also stable against noise and against seeds of local optimization, thereby effectively resolving the NMF nonidentifiability problem. On the other hand, NMF provides an interesting possibility of implementing PCC in an approximate way, where larger and positively correlated joint probabilities tend to be explained better via the independent mixture model. We work out a clustering method, where data points with the same common cause are grouped into the same cluster. We also show how NMF can be employed for data denoising.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03652v1",
    "published_date": "2025-09-03 19:02:39 UTC",
    "updated_date": "2025-09-03 19:02:39 UTC"
  },
  {
    "arxiv_id": "2509.03649v1",
    "title": "An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification",
    "authors": [
      "Davide Italo Serramazza",
      "Nikos Papadeas",
      "Zahraa Abdallah",
      "Georgiana Ifrim"
    ],
    "abstract": "Explainable AI (XAI) has become an increasingly important topic for understanding and attributing the predictions made by complex Time Series Classification (TSC) models. Among attribution methods, SHapley Additive exPlanations (SHAP) is widely regarded as an excellent attribution method; but its computational complexity, which scales exponentially with the number of features, limits its practicality for long time series. To address this, recent studies have shown that aggregating features via segmentation, to compute a single attribution value for a group of consecutive time points, drastically reduces SHAP running time. However, the choice of the optimal segmentation strategy remains an open question. In this work, we investigated eight different Time Series Segmentation algorithms to understand how segment compositions affect the explanation quality. We evaluate these approaches using two established XAI evaluation methodologies: InterpretTime and AUC Difference. Through experiments on both Multivariate (MTS) and Univariate Time Series (UTS), we find that the number of segments has a greater impact on explanation quality than the specific segmentation method. Notably, equal-length segmentation consistently outperforms most of the custom time series segmentation algorithms. Furthermore, we introduce a novel attribution normalisation technique that weights segments by their length and we show that it consistently improves attribution quality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03649v1",
    "published_date": "2025-09-03 18:55:23 UTC",
    "updated_date": "2025-09-03 18:55:23 UTC"
  },
  {
    "arxiv_id": "2509.03647v1",
    "title": "Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators",
    "authors": [
      "Dani Roytburg",
      "Matthew Bozoukov",
      "Matthew Nguyen",
      "Jou Barzdukas",
      "Simon Fu",
      "Narmeen Oozeer"
    ],
    "abstract": "Large language models (LLMs) increasingly serve as automated evaluators, yet they suffer from \"self-preference bias\": a tendency to favor their own outputs over those of other models. This bias undermines fairness and reliability in evaluation pipelines, particularly for tasks like preference tuning and model routing. We investigate whether lightweight steering vectors can mitigate this problem at inference time without retraining. We introduce a curated dataset that distinguishes self-preference bias into justified examples of self-preference and unjustified examples of self-preference, and we construct steering vectors using two methods: Contrastive Activation Addition (CAA) and an optimization-based approach. Our results show that steering vectors can reduce unjustified self-preference bias by up to 97\\%, substantially outperforming prompting and direct preference optimization baselines. Yet steering vectors are unstable on legitimate self-preference and unbiased agreement, implying self-preference spans multiple or nonlinear directions. This underscores both their promise and limits as safeguards for LLM-as-judges and motivates more robust interventions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03647v1",
    "published_date": "2025-09-03 18:52:55 UTC",
    "updated_date": "2025-09-03 18:52:55 UTC"
  },
  {
    "arxiv_id": "2509.03646v3",
    "title": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning",
    "authors": [
      "Haozhe Wang",
      "Qixin Xu",
      "Che Liu",
      "Junhong Wu",
      "Fangzhen Lin",
      "Wenhu Chen"
    ],
    "abstract": "Reinforcement Learning (RL) has proven highly effective at enhancing the complex reasoning abilities of Large Language Models (LLMs), yet underlying mechanisms driving this success remain largely opaque. Our analysis reveals that puzzling phenomena like ``aha moments\", ``length-scaling'' and entropy dynamics are not disparate occurrences but hallmarks of an emergent reasoning hierarchy, akin to the separation of high-level strategic planning from low-level procedural execution in human cognition. We uncover a compelling two-phase dynamic: initially, a model is constrained by procedural correctness and must improve its low-level skills. The learning bottleneck then decisively shifts, with performance gains being driven by the exploration and mastery of high-level strategic planning. This insight exposes a core inefficiency in prevailing RL algorithms like GRPO, which apply optimization pressure agnostically and dilute the learning signal across all tokens. To address this, we propose Hierarchy-Aware Credit Assignment (HICRA), an algorithm that concentrates optimization efforts on high-impact planning tokens. Our extensive experiments validate that HICRA significantly outperforms strong baselines, and offer deep insights into how reasoning advances through the lens of strategic exploration.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2509.03646v3",
    "published_date": "2025-09-03 18:52:49 UTC",
    "updated_date": "2025-09-27 17:07:24 UTC"
  },
  {
    "arxiv_id": "2509.03644v1",
    "title": "Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations",
    "authors": [
      "François Olivier",
      "Zied Bouraoui"
    ],
    "abstract": "Despite significant progress in natural language understanding, Large Language Models (LLMs) remain error-prone when performing logical reasoning, often lacking the robust mental representations that enable human-like comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that grounds understanding and logical reasoning in schematic representations based on image schemas-recurring patterns derived from sensorimotor experience that structure human cognition. Our system operationalizes the spatial foundations of these cognitive structures using declarative spatial reasoning within Answer Set Programming. Through evaluation on logical deduction problems, we demonstrate that LLMs can be guided to interpret scenarios through embodied cognitive structures, that these structures can be formalized as executable programs, and that the resulting representations support effective logical reasoning with enhanced interpretability. While our current implementation focuses on spatial primitives, it establishes the computational foundation for incorporating more complex and dynamic representations.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in Proceedings of Machine Learning Research, 19th Conference on Neurosymbolic Learning and Reasoning, 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.03644v1",
    "published_date": "2025-09-03 18:50:18 UTC",
    "updated_date": "2025-09-03 18:50:18 UTC"
  },
  {
    "arxiv_id": "2509.03643v2",
    "title": "CEHR-XGPT: A Scalable Multi-Task Foundation Model for Electronic Health Records",
    "authors": [
      "Chao Pang",
      "Jiheum Park",
      "Xinzhuo Jiang",
      "Nishanth Parameshwar Pavinkurve",
      "Krishna S. Kalluri",
      "Shalmali Joshi",
      "Noémie Elhadad",
      "Karthik Natarajan"
    ],
    "abstract": "Electronic Health Records (EHRs) provide a rich, longitudinal view of patient health and hold significant potential for advancing clinical decision support, risk prediction, and data-driven healthcare research. However, most artificial intelligence (AI) models for EHRs are designed for narrow, single-purpose tasks, limiting their generalizability and utility in real-world settings. Here, we present CEHR-XGPT, a general-purpose foundation model for EHR data that unifies three essential capabilities - feature representation, zero-shot prediction, and synthetic data generation - within a single architecture. To support temporal reasoning over clinical sequences, CEHR-XGPT incorporates a novel time-token-based learning framework that explicitly encodes patients' dynamic timelines into the model structure. CEHR-XGPT demonstrates strong performance across all three tasks and generalizes effectively to external datasets through vocabulary expansion and fine-tuning. Its versatility enables rapid model development, cohort discovery, and patient outcome forecasting without the need for task-specific retraining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03643v2",
    "published_date": "2025-09-03 18:50:03 UTC",
    "updated_date": "2025-09-05 12:40:38 UTC"
  },
  {
    "arxiv_id": "2509.03636v2",
    "title": "CausalARC: Abstract Reasoning with Causal World Models",
    "authors": [
      "Jacqueline Maasch",
      "John Kalantari",
      "Kia Khezeli"
    ],
    "abstract": "On-the-fly reasoning often requires adaptation to novel problems under limited data and distribution shift. This work introduces CausalARC: an experimental testbed for AI reasoning in low-data and out-of-distribution regimes, modeled after the Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is sampled from a fully specified causal world model, formally expressed as a structural causal model. Principled data augmentations provide observational, interventional, and counterfactual feedback about the world model in the form of few-shot, in-context learning demonstrations. As a proof-of-concept, we illustrate the use of CausalARC for four language model evaluation settings: (1) abstract reasoning with test-time training, (2) counterfactual reasoning with in-context learning, (3) program synthesis, and (4) causal discovery with logical reasoning. Within- and between-model performance varied heavily across tasks, indicating room for significant improvement in language model reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Peer-reviewed workshop paper",
    "pdf_url": "https://arxiv.org/pdf/2509.03636v2",
    "published_date": "2025-09-03 18:37:36 UTC",
    "updated_date": "2025-11-01 23:22:34 UTC"
  },
  {
    "arxiv_id": "2509.03633v1",
    "title": "treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds",
    "authors": [
      "Josafat-Mattias Burmeister",
      "Andreas Tockner",
      "Stefan Reder",
      "Markus Engel",
      "Rico Richter",
      "Jan-Peter Mund",
      "Jürgen Döllner"
    ],
    "abstract": "Close-range laser scanning provides detailed 3D captures of forest stands but requires efficient software for processing 3D point cloud data and extracting individual trees. Although recent studies have introduced deep learning methods for tree instance segmentation, these approaches require large annotated datasets and substantial computational resources. As a resource-efficient alternative, we present a revised version of the treeX algorithm, an unsupervised method that combines clustering-based stem detection with region growing for crown delineation. While the original treeX algorithm was developed for personal laser scanning (PLS) data, we provide two parameter presets, one for ground-based laser scanning (stationary terrestrial - TLS and PLS), and one for UAV-borne laser scanning (ULS). We evaluated the method on six public datasets (FOR-instance, ForestSemantic, LAUTx, NIBIO MLS, TreeLearn, Wytham Woods) and compared it to six open-source methods (original treeX, treeiso, RayCloudTools, ForAINet, SegmentAnyTree, TreeLearn). Compared to the original treeX algorithm, our revision reduces runtime and improves accuracy, with instance detection F$_1$-score gains of +0.11 to +0.49 for ground-based data. For ULS data, our preset achieves an F$_1$-score of 0.58, whereas the original algorithm fails to segment any correct instances. For TLS and PLS data, our algorithm achieves accuracy similar to recent open-source methods, including deep learning. Given its algorithmic design, we see two main applications for our method: (1) as a resource-efficient alternative to deep learning approaches in scenarios where the data characteristics align with the method design (sufficient stem visibility and point density), and (2) for the semi-automatic generation of labels for deep learning models. To enable broader adoption, we provide an open-source Python implementation in the pointtree package.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03633v1",
    "published_date": "2025-09-03 18:35:20 UTC",
    "updated_date": "2025-09-03 18:35:20 UTC"
  },
  {
    "arxiv_id": "2509.03626v1",
    "title": "Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE",
    "authors": [
      "Zahra Zehtabi Sabeti Moghaddam",
      "Zeinab Dehghani",
      "Maneeha Rani",
      "Koorosh Aslansefat",
      "Bhupesh Kumar Mishra",
      "Rameez Raja Kureshi",
      "Dhavalkumar Thakker"
    ],
    "abstract": "Generative AI, such as Large Language Models (LLMs), has achieved impressive progress but still produces hallucinations and unverifiable claims, limiting reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves accuracy by grounding outputs in external knowledge, especially in domains like healthcare, where precision is vital. However, RAG remains opaque and essentially a black box, heavily dependent on data quality. We developed a method-agnostic, perturbation-based framework that provides token and component-level interoperability for Graph RAG using SMILE and named it as Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing similarities, and training weighted linear surrogates, KG-SMILE identifies the graph entities and relations most influential to generated outputs, thereby making RAG more transparent. We evaluate KG-SMILE using comprehensive attribution metrics, including fidelity, faithfulness, consistency, stability, and accuracy. Our findings show that KG-SMILE produces stable, human-aligned explanations, demonstrating its capacity to balance model effectiveness with interpretability and thereby fostering greater transparency and trust in machine learning technologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03626v1",
    "published_date": "2025-09-03 18:29:30 UTC",
    "updated_date": "2025-09-03 18:29:30 UTC"
  },
  {
    "arxiv_id": "2509.05359v1",
    "title": "An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training",
    "authors": [
      "Yanis Labrak",
      "Richard Dufour",
      "Mickaël Rouvier"
    ],
    "abstract": "This paper investigates discrete unit representations in Speech Language Models (SLMs), focusing on optimizing speech modeling during continual pre-training. In this paper, we systematically examine how model architecture, data representation, and training robustness influence the pre-training stage in which we adapt existing pre-trained language models to the speech modality. Our experiments highlight the role of speech encoders and clustering granularity across different model scales, showing how optimal discretization strategies vary with model capacity. By examining cluster distribution and phonemic alignments, we investigate the effective use of discrete vocabulary, uncovering both linguistic and paralinguistic patterns. Additionally, we explore the impact of clustering data selection on model robustness, highlighting the importance of domain matching between discretization training and target applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in International Conference on Text, Speech, and Dialogue, 13-24",
    "pdf_url": "https://arxiv.org/pdf/2509.05359v1",
    "published_date": "2025-09-03 18:11:53 UTC",
    "updated_date": "2025-09-03 18:11:53 UTC"
  },
  {
    "arxiv_id": "2509.03615v1",
    "title": "E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition",
    "authors": [
      "Aryan Gupta",
      "Anupam Purwar"
    ],
    "abstract": "Optical Character Recognition (OCR) in multilingual, noisy, and diverse real-world images remains a significant challenge for optical character recognition systems. With the rise of Large Vision-Language Models (LVLMs), there is growing interest in their ability to generalize and reason beyond fixed OCR pipelines. In this work, we introduce Sprinklr-Edge-OCR, a novel OCR system built specifically optimized for edge deployment in resource-constrained environments. We present a large-scale comparative evaluation of five state-of-the-art LVLMs (InternVL, Qwen, GOT OCR, LLaMA, MiniCPM) and two traditional OCR systems (Sprinklr-Edge-OCR, SuryaOCR) on a proprietary, doubly hand annotated dataset of multilingual (54 languages) images. Our benchmark covers a broad range of metrics including accuracy, semantic consistency, language coverage, computational efficiency (latency, memory, GPU usage), and deployment cost. To better reflect real-world applicability, we also conducted edge case deployment analysis, evaluating model performance on CPU only environments. Among the results, Qwen achieved the highest precision (0.54), while Sprinklr-Edge-OCR delivered the best overall F1 score (0.46) and outperformed others in efficiency, processing images 35 faster (0.17 seconds per image on average) and at less than 0.01 of the cost (0.006 USD per 1,000 images) compared to LVLM. Our findings demonstrate that the most optimal OCR systems for edge deployment are the traditional ones even in the era of LLMs due to their low compute requirements, low latency, and very high affordability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Sprinklr OCR provides a fast and compute light way of performing OCR",
    "pdf_url": "https://arxiv.org/pdf/2509.03615v1",
    "published_date": "2025-09-03 18:08:41 UTC",
    "updated_date": "2025-09-03 18:08:41 UTC"
  },
  {
    "arxiv_id": "2509.03614v1",
    "title": "Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge",
    "authors": [
      "Seungho Choe",
      "Xiaoli Qin",
      "Abubakr Shafique",
      "Amanda Dy",
      "Susan Done",
      "Dimitrios Androutsos",
      "April Khademi"
    ],
    "abstract": "Counting mitotic figures is time-intensive for pathologists and leads to inter-observer variability. Artificial intelligence (AI) promises a solution by automatically detecting mitotic figures while maintaining decision consistency. However, AI tools are susceptible to domain shift, where a significant drop in performance can occur due to differences in the training and testing sets, including morphological diversity between organs, species, and variations in staining protocols. Furthermore, the number of mitoses is much less than the count of normal nuclei, which introduces severely imbalanced data for the detection task. In this work, we formulate mitosis detection as a pixel-level segmentation and propose a teacher-student model that simultaneously addresses mitosis detection (Track 1) and atypical mitosis classification (Track 2). Our method is based on a UNet segmentation backbone that integrates domain generalization modules, namely contrastive representation learning and domain-adversarial training. A teacher-student strategy is employed to generate pixel-level pseudo-masks not only for annotated mitoses and hard negatives but also for normal nuclei, thereby enhancing feature discrimination and improving robustness against domain shift. For the classification task, we introduce a multi-scale CNN classifier that leverages feature maps from the segmentation model within a multi-task learning paradigm. On the preliminary test set, the algorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of 0.8414 in Track 2, demonstrating the effectiveness of integrating segmentation-based detection and classification into a unified framework for robust mitosis analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 1 figures, final submission for MIDOG 2025 challenge",
    "pdf_url": "https://arxiv.org/pdf/2509.03614v1",
    "published_date": "2025-09-03 18:08:11 UTC",
    "updated_date": "2025-09-03 18:08:11 UTC"
  },
  {
    "arxiv_id": "2509.03594v1",
    "title": "The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric",
    "authors": [
      "Thomas R. Harvey"
    ],
    "abstract": "We present a class of novel optimisers for training neural networks that makes use of the Riemannian metric naturally induced when the loss landscape is embedded in higher-dimensional space. This is the same metric that underlies common visualisations of loss landscapes. By taking this geometric perspective literally and using the induced metric, we develop a new optimiser and compare it to existing methods, namely: SGD, Adam, AdamW, and Muon, across a range of tasks and architectures. Empirically, we conclude that this new class of optimisers is highly effective in low dimensional examples, and provides slight improvement over state-of-the-art methods for training neural networks. These new optimisers have theoretically desirable properties. In particular, the effective learning rate is automatically decreased in regions of high curvature acting as a smoothed out form of gradient clipping. Similarly, one variant of these optimisers can also be viewed as inducing an effective scheduled learning rate and decoupled weight decay is the natural choice from our geometric perspective. The basic method can be used to modify any existing preconditioning method. The new optimiser has a computational complexity comparable to that of Adam.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/harveyThomas4692/Induced-Metric-Optimiser",
    "pdf_url": "https://arxiv.org/pdf/2509.03594v1",
    "published_date": "2025-09-03 18:00:33 UTC",
    "updated_date": "2025-09-03 18:00:33 UTC"
  },
  {
    "arxiv_id": "2509.03581v2",
    "title": "Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents",
    "authors": [
      "Davide Paglieri",
      "Bartłomiej Cupiał",
      "Jonathan Cook",
      "Ulyana Piterbarg",
      "Jens Tuyls",
      "Edward Grefenstette",
      "Jakob Nicolaus Foerster",
      "Jack Parker-Holder",
      "Tim Rocktäschel"
    ],
    "abstract": "Training large language models (LLMs) to reason via reinforcement learning (RL) significantly improves their problem-solving capabilities. In agentic settings, existing methods like ReAct prompt LLMs to explicitly plan before every action; however, we demonstrate that always planning is computationally expensive and degrades performance on long-horizon tasks, while never planning further limits performance. To address this, we introduce a conceptual framework formalizing dynamic planning for LLM agents, enabling them to flexibly decide when to allocate test-time compute for planning. We propose a simple two-stage training pipeline: (1) supervised fine-tuning on diverse synthetic data to prime models for dynamic planning, and (2) RL to refine this capability in long-horizon environments. Experiments on the Crafter environment show that dynamic planning agents trained with this approach are more sample-efficient and consistently achieve more complex objectives. Additionally, we demonstrate that these agents can be effectively steered by human-written plans, surpassing their independent capabilities. To our knowledge, this work is the first to explore training LLM agents for dynamic test-time compute allocation in sequential decision-making tasks, paving the way for more efficient, adaptive, and controllable agentic systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03581v2",
    "published_date": "2025-09-03 18:00:13 UTC",
    "updated_date": "2025-09-30 09:12:45 UTC"
  },
  {
    "arxiv_id": "2509.03515v2",
    "title": "Can the Waymo Open Motion Dataset Support Realistic Behavioral Modeling? A Validation Study with Naturalistic Trajectories",
    "authors": [
      "Yanlin Zhang",
      "Sungyong Chung",
      "Nachuan Li",
      "Dana Monzer",
      "Hani S. Mahmassani",
      "Samer H. Hamdar",
      "Alireza Talebpour"
    ],
    "abstract": "The Waymo Open Motion Dataset (WOMD) has become a popular resource for data-driven modeling of autonomous vehicles (AVs) behavior. However, its validity for behavioral analysis remains uncertain due to proprietary post-processing, the absence of error quantification, and the segmentation of trajectories into 20-second clips. This study examines whether WOMD accurately captures the dynamics and interactions observed in real-world AV operations. Leveraging an independently collected naturalistic dataset from Level 4 AV operations in Phoenix, Arizona (PHX), we perform comparative analyses across three representative urban driving scenarios: discharging at signalized intersections, car-following, and lane-changing behaviors. For the discharging analysis, headways are manually extracted from aerial video to ensure negligible measurement error. For the car-following and lane-changing cases, we apply the Simulation-Extrapolation (SIMEX) method to account for empirically estimated error in the PHX data and use Dynamic Time Warping (DTW) distances to quantify behavioral differences. Results across all scenarios consistently show that behavior in PHX falls outside the behavioral envelope of WOMD. Notably, WOMD underrepresents short headways and abrupt decelerations. These findings suggest that behavioral models calibrated solely on WOMD may systematically underestimate the variability, risk, and complexity of naturalistic driving. Caution is therefore warranted when using WOMD for behavior modeling without proper validation against independently collected data.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "eess.SY",
      "stat.AP"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03515v2",
    "published_date": "2025-09-03 17:56:46 UTC",
    "updated_date": "2026-01-19 23:50:26 UTC"
  },
  {
    "arxiv_id": "2509.03505v2",
    "title": "LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence",
    "authors": [
      "Xingxuan Zhang",
      "Gang Ren",
      "Han Yu",
      "Hao Yuan",
      "Hui Wang",
      "Jiansheng Li",
      "Jiayun Wu",
      "Lang Mo",
      "Li Mao",
      "Mingchao Hao",
      "Ningbo Dai",
      "Renzhe Xu",
      "Shuyang Li",
      "Tianyang Zhang",
      "Yue He",
      "Yuanrui Wang",
      "Yunjia Zhang",
      "Zijing Xu",
      "Dongzhe Li",
      "Fang Gao",
      "Hao Zou",
      "Jiandong Liu",
      "Jiashuo Liu",
      "Jiawei Xu",
      "Kaijie Cheng",
      "Kehan Li",
      "Linjun Zhou",
      "Qing Li",
      "Shaohua Fan",
      "Xiaoyu Lin",
      "Xinyan Han",
      "Xuanyue Li",
      "Yan Lu",
      "Yuan Xue",
      "Yuanyuan Jiang",
      "Zimu Wang",
      "Zhenlei Wang",
      "Peng Cui"
    ],
    "abstract": "We argue that progress toward general intelligence requires complementary foundation models grounded in language, the physical world, and structured data. This report presents LimiX-16M and LimiX-2M, two instantiations of our large structured-data models (LDMs). Both models treat structured data as a joint distribution over variables and missingness, thus capable of addressing a wide range of tabular tasks through query-based conditional prediction via a single model. They are pretrained using masked joint-distribution modeling with an episodic, context-conditional objective, supporting rapid, training-free adaptation at inference. We evaluate LimiX models across 11 large structured-data benchmarks with broad regimes of sample size, feature dimensionality, class number, categorical-to-numerical feature ratio, missingness, and sample-to-feature ratios. LimiX-16M consistently surpasses strong baselines, as shown in Figure 1 and Figure 2. The superiority holds across a wide range of tasks, such as classification, regression, missing value imputation, and data generation, often by substantial margins, while avoiding task-specific architectures or bespoke training per task. Notably, LimiX-2M delivers strong results under tight compute and memory budgets. We also present the first scaling law study for LDMs, revealing how data and model scaling jointly influence downstream performance and offering quantitative guidance for tabular foundation modeling. All LimiX models are publicly accessible under Apache 2.0.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "61 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.03505v2",
    "published_date": "2025-09-03 17:39:08 UTC",
    "updated_date": "2025-11-07 16:49:47 UTC"
  },
  {
    "arxiv_id": "2509.03503v1",
    "title": "Warming Up for Zeroth-Order Federated Pre-Training with Low Resource Clients",
    "authors": [
      "Gwen Legate",
      "Irina Rish",
      "Eugene Belilovsky"
    ],
    "abstract": "Federated learning enables collaborative model training across numerous edge devices without requiring participants to share data; however, memory and communication constraints on these edge devices may preclude their participation in training. We consider a setting in which a subset of edge devices are below a critical memory or communication threshold required to conduct model updates. Under typical federated optimization algorithms, these devices are excluded from training which renders their data inaccessible and increases system induced bias. We are inspired by MeZO, a zeroth-order method used for memory-efficient fine-tuning. The increased variance inherent to zeroth-order gradient approximations has relegated previous zeroth-order optimizers exclusively to the domain of fine tuning; a limitation we seek to correct. We devise a federated, memory-efficient zeroth-order optimizer, ZOWarmUp that permits zeroth-order training from a random initialization. ZOWarmUp leverages differing client capabilities and careful variance reduction techniques to facilitate participation of under-represented, low-resource clients in model training. Like other federated zeroth-order methods, ZOWarmUp eliminates the need for edge devices to transmit their full gradients to the server and instead relies on only a small set of random seeds, rendering the up-link communication cost negligible. We present experiments using various datasets and model architectures to show that ZOWarmUp is a robust algorithm that can can be applied under a wide variety of circumstances. For systems with a high proportion of edge devices that would otherwise be excluded from training, this algorithm provides access to a greater volume and diversity of data, thus improving training outcomes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03503v1",
    "published_date": "2025-09-03 17:35:51 UTC",
    "updated_date": "2025-09-03 17:35:51 UTC"
  },
  {
    "arxiv_id": "2509.03501v1",
    "title": "Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data",
    "authors": [
      "Honglu Zhou",
      "Xiangyu Peng",
      "Shrikant Kendre",
      "Michael S. Ryoo",
      "Silvio Savarese",
      "Caiming Xiong",
      "Juan Carlos Niebles"
    ],
    "abstract": "Next-generation AI companions must go beyond general video understanding to resolve spatial and temporal references in dynamic, real-world environments. Existing Video Large Language Models (Video LLMs), while capable of coarse-level comprehension, struggle with fine-grained, spatiotemporal reasoning, especially when user queries rely on time-based event references for temporal anchoring, or gestural cues for spatial anchoring to clarify object references and positions. To bridge this critical gap, we introduce Strefer, a synthetic instruction data generation framework designed to equip Video LLMs with spatiotemporal referring and reasoning capabilities. Strefer produces diverse instruction-tuning data using a data engine that pseudo-annotates temporally dense, fine-grained video metadata, capturing rich spatial and temporal information in a structured manner, including subjects, objects, their locations as masklets, and their action descriptions and timelines. Our approach enhances the ability of Video LLMs to interpret spatial and temporal references, fostering more versatile, space-time-aware reasoning essential for real-world AI companions. Without using proprietary models, costly human annotation, or the need to annotate large volumes of new videos, experimental evaluations show that models trained with data produced by Strefer outperform baselines on tasks requiring spatial and temporal disambiguation. Additionally, these models exhibit enhanced space-time-aware reasoning, establishing a new foundation for perceptually grounded, instruction-tuned Video LLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This technical report serves as the archival version of our paper accepted at the ICCV 2025 Workshop. For more information, please visit our project website: https://strefer.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2509.03501v1",
    "published_date": "2025-09-03 17:33:20 UTC",
    "updated_date": "2025-09-03 17:33:20 UTC"
  },
  {
    "arxiv_id": "2509.03500v1",
    "title": "Real-Time Instrument Planning and Perception for Novel Measurements of Dynamic Phenomena",
    "authors": [
      "Itai Zilberstein",
      "Alberto Candela",
      "Steve Chien"
    ],
    "abstract": "Advancements in onboard computing mean remote sensing agents can employ state-of-the-art computer vision and machine learning at the edge. These capabilities can be leveraged to unlock new rare, transient, and pinpoint measurements of dynamic science phenomena. In this paper, we present an automated workflow that synthesizes the detection of these dynamic events in look-ahead satellite imagery with autonomous trajectory planning for a follow-up high-resolution sensor to obtain pinpoint measurements. We apply this workflow to the use case of observing volcanic plumes. We analyze classification approaches including traditional machine learning algorithms and convolutional neural networks. We present several trajectory planning algorithms that track the morphological features of a plume and integrate these algorithms with the classifiers. We show through simulation an order of magnitude increase in the utility return of the high-resolution instrument compared to baselines while maintaining efficient runtimes.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Appears in Proceedings of 18th Symposium on Advanced Space Technologies in Robotics and Automation",
    "pdf_url": "https://arxiv.org/pdf/2509.03500v1",
    "published_date": "2025-09-03 17:32:15 UTC",
    "updated_date": "2025-09-03 17:32:15 UTC"
  },
  {
    "arxiv_id": "2509.03493v2",
    "title": "On Entropy Control in LLM-RL Algorithms",
    "authors": [
      "Han Shen"
    ],
    "abstract": "For RL algorithms, appropriate entropy control is crucial to their effectiveness. To control the policy entropy, a commonly used method is entropy regularization, which is adopted in various popular RL algorithms including PPO, SAC and A3C. Although entropy regularization proves effective in robotic and games RL conventionally, studies found that it gives weak to no gains in LLM-RL training. In this work, we study the issues of entropy bonus in LLM-RL setting. Specifically, we first argue that the conventional entropy regularization suffers from the LLM's extremely large response space and the sparsity of the optimal outputs. As a remedy, we propose AEnt, an entropy control method that utilizes a new clamped entropy bonus with an automatically adjusted coefficient. The clamped entropy is evaluated with the re-normalized policy defined on certain smaller token space, which encourages exploration within a more compact response set. In addition, the algorithm automatically adjusts entropy coefficient according to the clamped entropy value, effectively controlling the entropy-induced bias while leveraging the entropy's benefits. AEnt is tested in math-reasoning tasks under different base models and datasets, and it is observed that AEnt outperforms the baselines consistently across multiple benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03493v2",
    "published_date": "2025-09-03 17:23:19 UTC",
    "updated_date": "2025-09-25 09:05:58 UTC"
  },
  {
    "arxiv_id": "2509.03487v2",
    "title": "SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models",
    "authors": [
      "Jigang Fan",
      "Zhenghong Zhou",
      "Ruofan Jin",
      "Le Cong",
      "Mengdi Wang",
      "Zaixi Zhang"
    ],
    "abstract": "Proteins play crucial roles in almost all biological processes. The advancement of deep learning has greatly accelerated the development of protein foundation models, leading to significant successes in protein understanding and design. However, the lack of systematic red-teaming for these models has raised serious concerns about their potential misuse, such as generating proteins with biological safety risks. This paper introduces SafeProtein, the first red-teaming framework designed for protein foundation models to the best of our knowledge. SafeProtein combines multimodal prompt engineering and heuristic beam search to systematically design red-teaming methods and conduct tests on protein foundation models. We also curated SafeProtein-Bench, which includes a manually constructed red-teaming benchmark dataset and a comprehensive evaluation protocol. SafeProtein achieved continuous jailbreaks on state-of-the-art protein foundation models (up to 70% attack success rate for ESM3), revealing potential biological safety risks in current protein foundation models and providing insights for the development of robust security protection technologies for frontier models. The codes will be made publicly available at https://github.com/jigang-fan/SafeProtein.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03487v2",
    "published_date": "2025-09-03 17:13:56 UTC",
    "updated_date": "2025-10-08 17:47:56 UTC"
  },
  {
    "arxiv_id": "2509.03477v1",
    "title": "Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning",
    "authors": [
      "Duy A. Nguyen",
      "Abhi Kamboj",
      "Minh N. Do"
    ],
    "abstract": "Addressing missing modalities and limited labeled data is crucial for advancing robust multimodal learning. We propose Robult, a scalable framework designed to mitigate these challenges by preserving modality-specific information and leveraging redundancy through a novel information-theoretic approach. Robult optimizes two core objectives: (1) a soft Positive-Unlabeled (PU) contrastive loss that maximizes task-relevant feature alignment while effectively utilizing limited labeled data in semi-supervised settings, and (2) a latent reconstruction loss that ensures unique modality-specific information is retained. These strategies, embedded within a modular design, enhance performance across various downstream tasks and ensure resilience to incomplete modalities during inference. Experimental results across diverse datasets validate that Robult achieves superior performance over existing approaches in both semi-supervised learning and missing modality contexts. Furthermore, its lightweight design promotes scalability and seamless integration with existing architectures, making it suitable for real-world multimodal applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted and presented at IJCAI 2025 in Montreal, Canada",
    "pdf_url": "https://arxiv.org/pdf/2509.03477v1",
    "published_date": "2025-09-03 16:56:27 UTC",
    "updated_date": "2025-09-03 16:56:27 UTC"
  },
  {
    "arxiv_id": "2509.03472v1",
    "title": "DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling",
    "authors": [
      "Yubo Gao",
      "Renbo Tu",
      "Gennady Pekhimenko",
      "Nandita Vijaykumar"
    ],
    "abstract": "Differentially-Private SGD (DP-SGD) is a powerful technique to protect user privacy when using sensitive data to train neural networks. During training, converting model weights and activations into low-precision formats, i.e., quantization, can drastically reduce training times, energy consumption, and cost, and is thus a widely used technique. In this work, we demonstrate that quantization causes significantly higher accuracy degradation in DP-SGD compared to regular SGD. We observe that this is caused by noise injection in DP-SGD, which amplifies quantization variance, leading to disproportionately large accuracy degradation. To address this challenge, we present QPQuant, a dynamic quantization framework that adaptively selects a changing subset of layers to quantize at each epoch. Our method combines two key ideas that effectively reduce quantization variance: (i) probabilistic sampling of the layers that rotates which layers are quantized every epoch, and (ii) loss-aware layer prioritization, which uses a differentially private loss sensitivity estimator to identify layers that can be quantized with minimal impact on model quality. This estimator consumes a negligible fraction of the overall privacy budget, preserving DP guarantees. Empirical evaluations on ResNet18, ResNet50, and DenseNet121 across a range of datasets demonstrate that DPQuant consistently outperforms static quantization baselines, achieving near Pareto-optimal accuracy-compute trade-offs and up to 2.21x theoretical throughput improvements on low-precision hardware, with less than 2% drop in validation accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03472v1",
    "published_date": "2025-09-03 16:51:26 UTC",
    "updated_date": "2025-09-03 16:51:26 UTC"
  },
  {
    "arxiv_id": "2509.03467v1",
    "title": "Continuous Saudi Sign Language Recognition: A Vision Transformer Approach",
    "authors": [
      "Soukeina Elhassen",
      "Lama Al Khuzayem",
      "Areej Alhothali",
      "Ohoud Alzamzami",
      "Nahed Alowaidi"
    ],
    "abstract": "Sign language (SL) is an essential communication form for hearing-impaired and deaf people, enabling engagement within the broader society. Despite its significance, limited public awareness of SL often leads to inequitable access to educational and professional opportunities, thereby contributing to social exclusion, particularly in Saudi Arabia, where over 84,000 individuals depend on Saudi Sign Language (SSL) as their primary form of communication. Although certain technological approaches have helped to improve communication for individuals with hearing impairments, there continues to be an urgent requirement for more precise and dependable translation techniques, especially for Arabic sign language variants like SSL. Most state-of-the-art solutions have primarily focused on non-Arabic sign languages, resulting in a considerable absence of resources dedicated to Arabic sign language, specifically SSL. The complexity of the Arabic language and the prevalence of isolated sign language datasets that concentrate on individual words instead of continuous speech contribute to this issue. To address this gap, our research represents an important step in developing SSL resources. To address this, we introduce the first continuous Saudi Sign Language dataset called KAU-CSSL, focusing on complete sentences to facilitate further research and enable sophisticated recognition systems for SSL recognition and translation. Additionally, we propose a transformer-based model, utilizing a pretrained ResNet-18 for spatial feature extraction and a Transformer Encoder with Bidirectional LSTM for temporal dependencies, achieving 99.02\\% accuracy at signer dependent mode and 77.71\\% accuracy at signer independent mode. This development leads the way to not only improving communication tools for the SSL community but also making a substantial contribution to the wider field of sign language.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 13 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.03467v1",
    "published_date": "2025-09-03 16:44:08 UTC",
    "updated_date": "2025-09-03 16:44:08 UTC"
  },
  {
    "arxiv_id": "2509.03462v1",
    "title": "sam-llm: interpretable lane change trajectoryprediction via parametric finetuning",
    "authors": [
      "Zhuo Cao",
      "Yunxiao Shi",
      "Min Xu"
    ],
    "abstract": "This work introduces SAM-LLM, a novel hybrid architecture that bridges the gap between the contextual reasoning of Large Language Models (LLMs) and the physical precision of kinematic lane change models for autonomous driving. The system is designed for interpretable lane change trajectory prediction by finetuning an LLM to output the core physical parameters of a trajectory model instead of raw coordinates. For lane-keeping scenarios, the model predicts discrete coordinates, but for lane change maneuvers, it generates the parameters for an enhanced Sinusoidal Acceleration Model (SAM), including lateral displacement, maneuver duration, initial lateral velocity, and longitudinal velocity change. This parametric approach yields a complete, continuous, and physically plausible trajectory model that is inherently interpretable and computationally efficient, achieving an 80% reduction in output size compared to coordinate-based methods. The SAM-LLM achieves a state-of-the-art overall intention prediction accuracy of 98.73%, demonstrating performance equivalent to traditional LLM predictors while offering significant advantages in explainability and resource efficiency.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.03462v1",
    "published_date": "2025-09-03 16:37:49 UTC",
    "updated_date": "2025-09-03 16:37:49 UTC"
  },
  {
    "arxiv_id": "2509.03409v1",
    "title": "Multi-level SSL Feature Gating for Audio Deepfake Detection",
    "authors": [
      "Hoan My Tran",
      "Damien Lolive",
      "Aghilas Sini",
      "Arnaud Delhay",
      "Pierre-François Marteau",
      "David Guennec"
    ],
    "abstract": "Recent advancements in generative AI, particularly in speech synthesis, have enabled the generation of highly natural-sounding synthetic speech that closely mimics human voices. While these innovations hold promise for applications like assistive technologies, they also pose significant risks, including misuse for fraudulent activities, identity theft, and security threats. Current research on spoofing detection countermeasures remains limited by generalization to unseen deepfake attacks and languages. To address this, we propose a gating mechanism extracting relevant feature from the speech foundation XLS-R model as a front-end feature extractor. For downstream back-end classifier, we employ Multi-kernel gated Convolution (MultiConv) to capture both local and global speech artifacts. Additionally, we introduce Centered Kernel Alignment (CKA) as a similarity metric to enforce diversity in learned features across different MultiConv layers. By integrating CKA with our gating mechanism, we hypothesize that each component helps improving the learning of distinct synthetic speech patterns. Experimental results demonstrate that our approach achieves state-of-the-art performance on in-domain benchmarks while generalizing robustly to out-of-domain datasets, including multilingual speech samples. This underscores its potential as a versatile solution for detecting evolving speech deepfake threats.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.SD",
    "comment": "This paper has been accepted by ACM MM 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.03409v1",
    "published_date": "2025-09-03 15:37:52 UTC",
    "updated_date": "2025-09-03 15:37:52 UTC"
  },
  {
    "arxiv_id": "2509.03403v1",
    "title": "Beyond Correctness: Harmonizing Process and Outcome Rewards through RL Training",
    "authors": [
      "Chenlu Ye",
      "Zhou Yu",
      "Ziji Zhang",
      "Hao Chen",
      "Narayanan Sadagopan",
      "Jing Huang",
      "Tong Zhang",
      "Anurag Beniwal"
    ],
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged to be a predominant paradigm for mathematical reasoning tasks, offering stable improvements in reasoning ability. However, Outcome Reward Models (ORMs) in RLVR are too coarse-grained to distinguish flawed reasoning within correct answers or valid reasoning within incorrect answers. This lack of granularity introduces noisy and misleading gradients significantly and hinders further progress in reasoning process quality. While Process Reward Models (PRMs) offer fine-grained guidance for intermediate steps, they frequently suffer from inaccuracies and are susceptible to reward hacking.\n  To resolve this dilemma, we introduce PRocess cOnsistency Filter (PROF), an effective data process curation method that harmonizes noisy, fine-grained process rewards with accurate, coarse-grained outcome rewards. Rather than naively blending PRM and ORM in the objective function (arXiv:archive/2506.18896), PROF leverages their complementary strengths through consistency-driven sample selection. Our approach retains correct responses with higher averaged process values and incorrect responses with lower averaged process values, while maintaining positive/negative training sample balance. Extensive experiments demonstrate that our method not only consistently improves the final accuracy over $4\\%$ compared to the blending approaches, but also strengthens the quality of intermediate reasoning steps. Codes and training recipes are available at https://github.com/Chenluye99/PROF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03403v1",
    "published_date": "2025-09-03 15:28:51 UTC",
    "updated_date": "2025-09-03 15:28:51 UTC"
  },
  {
    "arxiv_id": "2509.03383v1",
    "title": "ANNIE: Be Careful of Your Robots",
    "authors": [
      "Yiyang Huang",
      "Zixuan Wang",
      "Zishen Wan",
      "Yapeng Tian",
      "Haobo Xu",
      "Yinhe Han",
      "Yiming Gan"
    ],
    "abstract": "The integration of vision-language-action (VLA) models into embodied AI (EAI) robots is rapidly advancing their ability to perform complex, long-horizon tasks in humancentric environments. However, EAI systems introduce critical security risks: a compromised VLA model can directly translate adversarial perturbations on sensory input into unsafe physical actions. Traditional safety definitions and methodologies from the machine learning community are no longer sufficient. EAI systems raise new questions, such as what constitutes safety, how to measure it, and how to design effective attack and defense mechanisms in physically grounded, interactive settings. In this work, we present the first systematic study of adversarial safety attacks on embodied AI systems, grounded in ISO standards for human-robot interactions. We (1) formalize a principled taxonomy of safety violations (critical, dangerous, risky) based on physical constraints such as separation distance, velocity, and collision boundaries; (2) introduce ANNIEBench, a benchmark of nine safety-critical scenarios with 2,400 video-action sequences for evaluating embodied safety; and (3) ANNIE-Attack, a task-aware adversarial framework with an attack leader model that decomposes long-horizon goals into frame-level perturbations. Our evaluation across representative EAI models shows attack success rates exceeding 50% across all safety categories. We further demonstrate sparse and adaptive attack strategies and validate the real-world impact through physical robot experiments. These results expose a previously underexplored but highly consequential attack surface in embodied AI systems, highlighting the urgent need for security-driven defenses in the physical AI era. Code is available at https://github.com/RLCLab/Annie.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03383v1",
    "published_date": "2025-09-03 15:00:28 UTC",
    "updated_date": "2025-09-03 15:00:28 UTC"
  },
  {
    "arxiv_id": "2509.03380v1",
    "title": "Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems",
    "authors": [
      "Peter J. Bentley",
      "Soo Ling Lim",
      "Fuyuki Ishikawa"
    ],
    "abstract": "Agentic LLM AI agents are often little more than autonomous chatbots: actors following scripts, often controlled by an unreliable director. This work introduces a bottom-up framework that situates AI agents in their environment, with all behaviors triggered by changes in their environments. It introduces the notion of aspects, similar to the idea of umwelt, where sets of agents perceive their environment differently to each other, enabling clearer control of information. We provide an illustrative implementation and show that compared to a typical architecture, which leaks up to 83% of the time, aspective agentic AI enables zero information leakage. We anticipate that this concept of specialist agents working efficiently in their own information niches can provide improvements to both security and efficiency.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.03380v1",
    "published_date": "2025-09-03 14:57:04 UTC",
    "updated_date": "2025-09-03 14:57:04 UTC"
  },
  {
    "arxiv_id": "2509.03379v1",
    "title": "TinyDrop: Tiny Model Guided Token Dropping for Vision Transformers",
    "authors": [
      "Guoxin Wang",
      "Qingyuan Wang",
      "Binhua Huang",
      "Shaowu Chen",
      "Deepu John"
    ],
    "abstract": "Vision Transformers (ViTs) achieve strong performance in image classification but incur high computational costs from processing all image tokens. To reduce inference costs in large ViTs without compromising accuracy, we propose TinyDrop, a training-free token dropping framework guided by a lightweight vision model. The guidance model estimates the importance of tokens while performing inference, thereby selectively discarding low-importance tokens if large vit models need to perform attention calculations. The framework operates plug-and-play, requires no architectural modifications, and is compatible with diverse ViT architectures. Evaluations on standard image classification benchmarks demonstrate that our framework reduces FLOPs by up to 80% for ViTs with minimal accuracy degradation, highlighting its generalization capability and practical utility for efficient ViT-based classification.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03379v1",
    "published_date": "2025-09-03 14:55:49 UTC",
    "updated_date": "2025-09-03 14:55:49 UTC"
  },
  {
    "arxiv_id": "2509.03351v1",
    "title": "epiGPTope: A machine learning-based epitope generator and classifier",
    "authors": [
      "Natalia Flechas Manrique",
      "Alberto Martínez",
      "Elena López-Martínez",
      "Luc Andrea",
      "Román Orus",
      "Aitor Manteca",
      "Aitziber L. Cortajarena",
      "Llorenç Espinosa-Portalés"
    ],
    "abstract": "Epitopes are short antigenic peptide sequences which are recognized by antibodies or immune cell receptors. These are central to the development of immunotherapies, vaccines, and diagnostics. However, the rational design of synthetic epitope libraries is challenging due to the large combinatorial sequence space, $20^n$ combinations for linear epitopes of n amino acids, making screening and testing unfeasible, even with high throughput experimental techniques. In this study, we present a large language model, epiGPTope, pre-trained on protein data and specifically fine-tuned on linear epitopes, which for the first time can directly generate novel epitope-like sequences, which are found to possess statistical properties analogous to the ones of known epitopes. This generative approach can be used to prepare libraries of epitope candidate sequences. We further train statistical classifiers to predict whether an epitope sequence is of bacterial or viral origin, thus narrowing the candidate library and increasing the likelihood of identifying specific epitopes. We propose that such combination of generative and predictive models can be of assistance in epitope discovery. The approach uses only primary amino acid sequences of linear epitopes, bypassing the need for a geometric framework or hand-crafted features of the sequences. By developing a method to create biologically feasible sequences, we anticipate faster and more cost-effective generation and screening of synthetic epitopes, with relevant applications in the development of new biotechnologies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 4 figures. Supplementary Information with 5 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.03351v1",
    "published_date": "2025-09-03 14:36:06 UTC",
    "updated_date": "2025-09-03 14:36:06 UTC"
  },
  {
    "arxiv_id": "2509.03345v1",
    "title": "Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning",
    "authors": [
      "Yunxin Sun",
      "Abulhair Saparov"
    ],
    "abstract": "Reasoning is a core capability in artificial intelligence systems, for which large language models (LLMs) have recently shown remarkable progress. However, most work focuses exclusively on deductive reasoning, which is problematic since other types of reasoning are also essential in solving real-world problems, and they are less explored. This work focuses on evaluating LLMs' inductive and abductive reasoning capabilities. We introduce a programmable and synthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example consists of an incomplete world model and a set of observations. The task for the intelligent agent is to produce hypotheses to explain observations under the incomplete world model to solve each reasoning example. We propose a new metric to evaluate the quality of hypotheses based on Occam's Razor. We evaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs can perform inductive and abductive reasoning in simple scenarios, but struggle with complex world models and producing high-quality hypotheses, even with popular reasoning-enhancing techniques such as in-context learning and RLVR.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03345v1",
    "published_date": "2025-09-03 14:22:42 UTC",
    "updated_date": "2025-09-03 14:22:42 UTC"
  },
  {
    "arxiv_id": "2509.03341v1",
    "title": "On the MIA Vulnerability Gap Between Private GANs and Diffusion Models",
    "authors": [
      "Ilana Sebag",
      "Jean-Yves Franceschi",
      "Alain Rakotomamonjy",
      "Alexandre Allauzen",
      "Jamal Atif"
    ],
    "abstract": "Generative Adversarial Networks (GANs) and diffusion models have emerged as leading approaches for high-quality image synthesis. While both can be trained under differential privacy (DP) to protect sensitive data, their sensitivity to membership inference attacks (MIAs), a key threat to data confidentiality, remains poorly understood. In this work, we present the first unified theoretical and empirical analysis of the privacy risks faced by differentially private generative models. We begin by showing, through a stability-based analysis, that GANs exhibit fundamentally lower sensitivity to data perturbations than diffusion models, suggesting a structural advantage in resisting MIAs. We then validate this insight with a comprehensive empirical study using a standardized MIA pipeline to evaluate privacy leakage across datasets and privacy budgets. Our results consistently reveal a marked privacy robustness gap in favor of GANs, even in strong DP regimes, highlighting that model type alone can critically shape privacy leakage.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03341v1",
    "published_date": "2025-09-03 14:18:22 UTC",
    "updated_date": "2025-09-03 14:18:22 UTC"
  },
  {
    "arxiv_id": "2509.03340v2",
    "title": "Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems",
    "authors": [
      "Fleur Hendriks",
      "Ondřej Rokoš",
      "Martin Doškář",
      "Marc G. D. Geers",
      "Vlado Menkovski"
    ],
    "abstract": "Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models struggle to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we propose a generative framework based on flow matching to model the full probability distribution over bifurcation outcomes. Our method enables direct sampling of multiple valid solutions while preserving system symmetries through equivariant modeling. We introduce a symmetric matching strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from toy models to complex physical problems such as buckling beams and the Allen-Cahn equation. Our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods in capturing multimodal distributions and symmetry-breaking bifurcations, offering a principled and scalable solution for modeling multistability in high-dimensional systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 7 figures including appendices. Accepted to Machine Learning and the Physical Sciences Workshop, NeurIPS 2025 (https://ml4physicalsciences.github.io/2025/). Repository with corresponding code: https://github.com/FHendriks11/bifurcationML/. Video explanation: https://www.youtube.com/watch?v=wsL3h17KtjY",
    "pdf_url": "https://arxiv.org/pdf/2509.03340v2",
    "published_date": "2025-09-03 14:18:05 UTC",
    "updated_date": "2025-11-26 14:19:09 UTC"
  },
  {
    "arxiv_id": "2509.03323v1",
    "title": "Heatmap Guided Query Transformers for Robust Astrocyte Detection across Immunostains and Resolutions",
    "authors": [
      "Xizhe Zhang",
      "Jiayang Zhu"
    ],
    "abstract": "Astrocytes are critical glial cells whose altered morphology and density are hallmarks of many neurological disorders. However, their intricate branching and stain dependent variability make automated detection of histological images a highly challenging task. To address these challenges, we propose a hybrid CNN Transformer detector that combines local feature extraction with global contextual reasoning. A heatmap guided query mechanism generates spatially grounded anchors for small and faint astrocytes, while a lightweight Transformer module improves discrimination in dense clusters. Evaluated on ALDH1L1 and GFAP stained astrocyte datasets, the model consistently outperformed Faster R-CNN, YOLOv11 and DETR, achieving higher sensitivity with fewer false positives, as confirmed by FROC analysis. These results highlight the potential of hybrid CNN Transformer architectures for robust astrocyte detection and provide a foundation for advanced computational pathology tools.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03323v1",
    "published_date": "2025-09-03 14:01:04 UTC",
    "updated_date": "2025-09-03 14:01:04 UTC"
  },
  {
    "arxiv_id": "2509.03310v2",
    "title": "app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding",
    "authors": [
      "Evgenii Kniazev",
      "Arseny Kravchenko",
      "Igor Rekun",
      "James Broadhead",
      "Nikita Shamgunov",
      "Pranav Sah",
      "Pratik Nichite",
      "Ivan Yamshchikov"
    ],
    "abstract": "We present app.build (https://github.com/neondatabase/appdotbuild-agent), an open-source framework that improves LLM-based application generation through systematic validation and structured environments. Our approach combines multi-layered validation pipelines, stack-specific orchestration, and model-agnostic architecture, implemented across three reference stacks. Through evaluation on 30 generation tasks, we demonstrate that comprehensive validation achieves 73.3% viability rate with 30% reaching perfect quality scores, while open-weights models achieve 80.8% of closed-model performance when provided structured environments. The open-source framework has been adopted by the community, with over 3,000 applications generated to date. This work demonstrates that scaling reliable AI agents requires scaling environments, not just models -- providing empirical insights and complete reference implementations for production-oriented agent systems.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03310v2",
    "published_date": "2025-09-03 13:41:45 UTC",
    "updated_date": "2026-01-09 20:59:39 UTC"
  },
  {
    "arxiv_id": "2509.03303v2",
    "title": "Automatic Differentiation of Agent-Based Models",
    "authors": [
      "Arnau Quera-Bofarull",
      "Nicholas Bishop",
      "Joel Dyer",
      "Daniel Jarne Ornia",
      "Anisoara Calinescu",
      "Doyne Farmer",
      "Michael Wooldridge"
    ],
    "abstract": "Agent-based models (ABMs) simulate complex systems by capturing the bottom-up interactions of individual agents comprising the system. Many complex systems of interest, such as epidemics or financial markets, involve thousands or even millions of agents. Consequently, ABMs often become computationally demanding and rely on the calibration of numerous free parameters, which has significantly hindered their widespread adoption. In this paper, we demonstrate that automatic differentiation (AD) techniques can effectively alleviate these computational burdens. By applying AD to ABMs, the gradients of the simulator become readily available, greatly facilitating essential tasks such as calibration and sensitivity analysis. Specifically, we show how AD enables variational inference (VI) techniques for efficient parameter calibration. Our experiments demonstrate substantial performance improvements and computational savings using VI on three prominent ABMs: Axtell's model of firms; Sugarscape; and the SIR epidemiological model. Our approach thus significantly enhances the practicality and scalability of ABMs for studying complex systems.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "Rev. 1: Updated references and code availability",
    "pdf_url": "https://arxiv.org/pdf/2509.03303v2",
    "published_date": "2025-09-03 13:28:33 UTC",
    "updated_date": "2025-11-18 15:04:10 UTC"
  },
  {
    "arxiv_id": "2509.03294v2",
    "title": "A Comprehensive Guide to Differential Privacy: From Theory to User Expectations",
    "authors": [
      "Napsu Karmitsa",
      "Antti Airola",
      "Tapio Pahikkala",
      "Tinja Pitkämäki"
    ],
    "abstract": "The increasing availability of personal data has enabled significant advances in fields such as machine learning, healthcare, and cybersecurity. However, this data abundance also raises serious privacy concerns, especially in light of powerful re-identification attacks and growing legal and ethical demands for responsible data use. Differential privacy (DP) has emerged as a principled, mathematically grounded framework for mitigating these risks. This review provides a comprehensive survey of DP, covering its theoretical foundations, practical mechanisms, and real-world applications. It explores key algorithmic tools and domain-specific challenges - particularly in privacy-preserving machine learning and synthetic data generation. The report also highlights usability issues and the need for improved communication and transparency in DP systems. Overall, the goal is to support informed adoption of DP by researchers and practitioners navigating the evolving landscape of data privacy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03294v2",
    "published_date": "2025-09-03 13:23:10 UTC",
    "updated_date": "2025-09-11 13:12:37 UTC"
  },
  {
    "arxiv_id": "2509.03286v1",
    "title": "Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making",
    "authors": [
      "Prachi Bagave",
      "Marcus Westberg",
      "Marijn Janssen",
      "Aaron Yi Ding"
    ],
    "abstract": "AI is transforming the healthcare domain and is increasingly helping practitioners to make health-related decisions. Therefore, accountability becomes a crucial concern for critical AI-driven decisions. Although regulatory bodies, such as the EU commission, provide guidelines, they are highlevel and focus on the ''what'' that should be done and less on the ''how'', creating a knowledge gap for actors. Through an extensive analysis, we found that the term accountability is perceived and dealt with in many different ways, depending on the actor's expertise and domain of work. With increasing concerns about AI accountability issues and the ambiguity around this term, this paper bridges the gap between the ''what'' and ''how'' of AI accountability, specifically for AI systems in healthcare. We do this by analysing the concept of accountability, formulating an accountability framework, and providing a three-tier structure for handling various accountability mechanisms. Our accountability framework positions the regulations of healthcare AI systems and the mechanisms adopted by the actors under a consistent accountability regime. Moreover, the three-tier structure guides the actors of the healthcare AI system to categorise the mechanisms based on their conduct. Through our framework, we advocate that decision-making in healthcare AI holds shared dependencies, where accountability should be dealt with jointly and should foster collaborations. We highlight the role of explainability in instigating communication and information sharing between the actors to further facilitate the collaborative process.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in AAAI AIES 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.03286v1",
    "published_date": "2025-09-03 13:05:29 UTC",
    "updated_date": "2025-09-03 13:05:29 UTC"
  },
  {
    "arxiv_id": "2509.03263v1",
    "title": "Estudio de la eficiencia en la escalabilidad de GPUs para el entrenamiento de Inteligencia Artificial",
    "authors": [
      "David Cortes",
      "Carlos Juiz",
      "Belen Bermejo"
    ],
    "abstract": "Training large-scale deep learning models has become a key challenge for the scientific community and industry. While the massive use of GPUs can significantly speed up training times, this approach has a negative impact on efficiency. In this article, we present a detailed analysis of the times reported by MLPerf Training v4.1 on four workloads: BERT, Llama2 LoRA, RetinaNet, and Stable Diffusion, showing that there are configurations that optimise the relationship between performance, GPU usage, and efficiency. The results point to a break-even point that allows training times to be reduced while maximising efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, in Spanish language, 8 figures, Conference at SARTECO 2025, Spain",
    "pdf_url": "https://arxiv.org/pdf/2509.03263v1",
    "published_date": "2025-09-03 12:24:42 UTC",
    "updated_date": "2025-09-03 12:24:42 UTC"
  },
  {
    "arxiv_id": "2509.03260v1",
    "title": "HyPV-LEAD: Proactive Early-Warning of Cryptocurrency Anomalies through Data-Driven Structural-Temporal Modeling",
    "authors": [
      "Minjung Park",
      "Gyuyeon Na",
      "Soyoun Kim",
      "Sunyoung Moon",
      "HyeonJeong Cha",
      "Sangmi Chai"
    ],
    "abstract": "Abnormal cryptocurrency transactions - such as mixing services, fraudulent transfers, and pump-and-dump operations -- pose escalating risks to financial integrity but remain notoriously difficult to detect due to class imbalance, temporal volatility, and complex network dependencies. Existing approaches are predominantly model-centric and post hoc, flagging anomalies only after they occur and thus offering limited preventive value. This paper introduces HyPV-LEAD (Hyperbolic Peak-Valley Lead-time Enabled Anomaly Detection), a data-driven early-warning framework that explicitly incorporates lead time into anomaly detection. Unlike prior methods, HyPV-LEAD integrates three innovations: (1) window-horizon modeling to guarantee actionable lead-time alerts, (2) Peak-Valley (PV) sampling to mitigate class imbalance while preserving temporal continuity, and (3) hyperbolic embedding to capture the hierarchical and scale-free properties of blockchain transaction networks. Empirical evaluation on large-scale Bitcoin transaction data demonstrates that HyPV-LEAD consistently outperforms state-of-the-art baselines, achieving a PR-AUC of 0.9624 with significant gains in precision and recall. Ablation studies further confirm that each component - PV sampling, hyperbolic embedding, and structural-temporal modeling - provides complementary benefits, with the full framework delivering the highest performance. By shifting anomaly detection from reactive classification to proactive early-warning, HyPV-LEAD establishes a robust foundation for real-time risk management, anti-money laundering (AML) compliance, and financial security in dynamic blockchain environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.RM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03260v1",
    "published_date": "2025-09-03 12:23:38 UTC",
    "updated_date": "2025-09-03 12:23:38 UTC"
  },
  {
    "arxiv_id": "2509.03561v1",
    "title": "Quantum-Assisted Correlation Clustering",
    "authors": [
      "Antonio Macaluso",
      "Supreeth Mysore Venkatesh",
      "Diego Arenas",
      "Matthias Klusch",
      "Andreas Dengel"
    ],
    "abstract": "This work introduces a hybrid quantum-classical method to correlation clustering, a graph-based unsupervised learning task that seeks to partition the nodes in a graph based on pairwise agreement and disagreement. In particular, we adapt GCS-Q, a quantum-assisted solver originally designed for coalition structure generation, to maximize intra-cluster agreement in signed graphs through recursive divisive partitioning. The proposed method encodes each bipartitioning step as a quadratic unconstrained binary optimization problem, solved via quantum annealing. This integration of quantum optimization within a hierarchical clustering framework enables handling of graphs with arbitrary correlation structures, including negative edges, without relying on metric assumptions or a predefined number of clusters. Empirical evaluations on synthetic signed graphs and real-world hyperspectral imaging data demonstrate that, when adapted for correlation clustering, GCS-Q outperforms classical algorithms in robustness and clustering quality on real-world data and in scenarios with cluster size imbalance. Our results highlight the promise of hybrid quantum-classical optimization for advancing scalable and structurally-aware clustering techniques in graph-based unsupervised learning.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "To be published in IEEE QAI 2025 conference",
    "pdf_url": "https://arxiv.org/pdf/2509.03561v1",
    "published_date": "2025-09-03 12:14:35 UTC",
    "updated_date": "2025-09-03 12:14:35 UTC"
  },
  {
    "arxiv_id": "2509.03249v2",
    "title": "Structure Transfer: an Inference-Based Calculus for the Transformation of Representations",
    "authors": [
      "Daniel Raggi",
      "Gem Stapleton",
      "Mateja Jamnik",
      "Aaron Stockdill",
      "Grecia Garcia Garcia",
      "Peter C-H. Cheng"
    ],
    "abstract": "Representation choice is of fundamental importance to our ability to communicate and reason effectively. A major unsolved problem, addressed in this paper, is how to devise representational-system (RS) agnostic techniques that drive representation transformation and choice. We present a novel calculus, called structure transfer, that enables representation transformation across diverse RSs. Specifically, given a source representation drawn from a source RS, the rules of structure transfer allow us to generate a target representation for a target RS. The generality of structure transfer comes in part from its ability to ensure that the source representation and the generated target representation satisfy any specified relation (such as semantic equivalence). This is done by exploiting schemas, which encode knowledge about RSs. Specifically, schemas can express preservation of information across relations between any pair of RSs, and this knowledge is used by structure transfer to derive a structure for the target representation which ensures that the desired relation holds. We formalise this using Representational Systems Theory, building on the key concept of a construction space. The abstract nature of construction spaces grants them the generality to model RSs of diverse kinds, including formal languages, geometric figures and diagrams, as well as informal notations. Consequently, structure transfer is a system-agnostic calculus that can be used to identify alternative representations in a wide range of practical settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03249v2",
    "published_date": "2025-09-03 12:07:23 UTC",
    "updated_date": "2025-09-04 08:55:32 UTC"
  },
  {
    "arxiv_id": "2509.05356v2",
    "title": "Spiking Neural Networks for Continuous Control via End-to-End Model-Based Learning",
    "authors": [
      "Justus Huebotter",
      "Pablo Lanillos",
      "Marcel van Gerven",
      "Serge Thill"
    ],
    "abstract": "Despite recent progress in training spiking neural networks (SNNs) for classification, their application to continuous motor control remains limited. Here, we demonstrate that fully spiking architectures can be trained end-to-end to control robotic arms with multiple degrees of freedom in continuous environments. Our predictive-control framework combines Leaky Integrate-and-Fire dynamics with surrogate gradients, jointly optimizing a forward model for dynamics prediction and a policy network for goal-directed action. We evaluate this approach on both a planar 2D reaching task and a simulated 6-DOF Franka Emika Panda robot. Results show that SNNs can achieve stable training and accurate torque control, establishing their viability for high-dimensional motor tasks. An extensive ablation study highlights the role of initialization, learnable time constants, and regularization in shaping training dynamics. We conclude that while stable and effective control can be achieved, recurrent spiking networks remain highly sensitive to hyperparameter settings, underscoring the importance of principled design choices.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05356v2",
    "published_date": "2025-09-03 12:05:58 UTC",
    "updated_date": "2025-09-16 11:40:33 UTC"
  },
  {
    "arxiv_id": "2509.03244v1",
    "title": "FoMEMO: Towards Foundation Models for Expensive Multi-objective Optimization",
    "authors": [
      "Yiming Yao",
      "Fei Liu",
      "Liang Zhao",
      "Xi Lin",
      "Qingfu Zhang"
    ],
    "abstract": "Expensive multi-objective optimization is a prevalent and crucial concern in many real-world scenarios, where sample-efficiency is vital due to the limited evaluations to recover the true Pareto front for decision making. Existing works either involve rebuilding Gaussian process surrogates from scratch for each objective in each new problem encountered, or rely on extensive past domain experiments for pre-training deep learning models, making them hard to generalize and impractical to cope with various emerging applications in the real world. To address this issue, we propose a new paradigm named FoMEMO (Foundation Models for Expensive Multi-objective Optimization), which enables the establishment of a foundation model conditioned on any domain trajectory and user preference, and facilitates fast in-context optimization based on the predicted preference-wise aggregation posteriors. Rather than accessing extensive domain experiments in the real world, we demonstrate that pre-training the foundation model with a diverse set of hundreds of millions of synthetic data can lead to superior adaptability to unknown problems, without necessitating any subsequent model training or updates in the optimization process. We evaluate our method across a variety of synthetic benchmarks and real-word applications, and demonstrate its superior generality and competitive performance compared to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03244v1",
    "published_date": "2025-09-03 12:00:24 UTC",
    "updated_date": "2025-09-03 12:00:24 UTC"
  },
  {
    "arxiv_id": "2509.03240v1",
    "title": "Evaluation of Stress Detection as Time Series Events -- A Novel Window-Based F1-Metric",
    "authors": [
      "Harald Vilhelm Skat-Rørdam",
      "Sneha Das",
      "Kathrine Sofie Rasmussen",
      "Nicole Nadine Lønfeldt",
      "Line Clemmensen"
    ],
    "abstract": "Accurate evaluation of event detection in time series is essential for applications such as stress monitoring with wearable devices, where ground truth is typically annotated as single-point events, even though the underlying phenomena are gradual and temporally diffused. Standard metrics like F1 and point-adjusted F1 (F1$_{pa}$) often misrepresent model performance in such real-world, imbalanced datasets. We introduce a window-based F1 metric (F1$_w$) that incorporates temporal tolerance, enabling a more robust assessment of event detection when exact alignment is unrealistic. Empirical analysis in three physiological datasets, two in-the-wild (ADARP, Wrist Angel) and one experimental (ROAD), indicates that F1$_w$ reveals meaningful model performance patterns invisible to conventional metrics, while its window size can be adapted to domain knowledge to avoid overestimation. We show that the choice of evaluation metric strongly influences the interpretation of model performance: using predictions from TimesFM, only our temporally tolerant metrics reveal statistically significant improvements over random and null baselines in the two in-the-wild use cases. This work addresses key gaps in time series evaluation and provides practical guidance for healthcare applications where requirements for temporal precision vary by context.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.03240v1",
    "published_date": "2025-09-03 11:55:28 UTC",
    "updated_date": "2025-09-03 11:55:28 UTC"
  },
  {
    "arxiv_id": "2509.10517v2",
    "title": "A Comparative Benchmark of Federated Learning Strategies for Mortality Prediction on Heterogeneous and Imbalanced Clinical Data",
    "authors": [
      "Rodrigo Tertulino"
    ],
    "abstract": "Machine learning models hold significant potential for predicting in-hospital mortality, yet data privacy constraints and the statistical heterogeneity of real-world clinical data often hamper their development. Federated Learning (FL) offers a privacy-preserving solution, but its performance under non-Independent and Identically Distributed (non-IID) and imbalanced conditions requires rigorous investigation. The study presents a comparative benchmark of five federated learning strategies: FedAvg, FedProx, FedAdagrad, FedAdam, and FedCluster for mortality prediction. Using the large-scale MIMIC-IV dataset, we simulate a realistic non-IID environment by partitioning data by clinical care unit. To address the inherent class imbalance of the task, the SMOTE-Tomek technique is applied to each client's local training data. Our experiments, conducted over 50 communication rounds, reveal that the regularization-based strategy, FedProx, consistently outperformed other methods, achieving the highest F1-Score of 0.8831 while maintaining stable convergence. While the baseline FedAvg was the most computationally efficient, its predictive performance was substantially lower. Our findings indicate that regularization-based FL algorithms like FedProx offer a more robust and effective solution for heterogeneous and imbalanced clinical prediction tasks than standard or server-side adaptive aggregation methods. The work provides a crucial empirical benchmark for selecting appropriate FL strategies for real-world healthcare applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "The author requests withdrawal due to errors in the results section regarding model performance metrics. These errors compromise the interpretability of the benchmark and the validity of the conclusions. The author prefers to withdraw the paper to prevent the dissemination of flawed results",
    "pdf_url": "https://arxiv.org/pdf/2509.10517v2",
    "published_date": "2025-09-03 11:32:57 UTC",
    "updated_date": "2025-11-15 13:24:35 UTC"
  },
  {
    "arxiv_id": "2509.10516v3",
    "title": "Privacy-Preserving Personalization in Education: A Federated Recommender System for Student Performance Prediction",
    "authors": [
      "Rodrigo Tertulino",
      "Ricardo Almeida"
    ],
    "abstract": "The increasing digitalization of education presents unprecedented opportunities for data-driven personalization, but it also introduces significant challenges to student data privacy. Conventional recommender systems rely on centralized data, a paradigm often incompatible with modern data protection regulations. A novel privacy-preserving recommender system is proposed and evaluated to address this critical issue using Federated Learning (FL). The approach utilizes a Deep Neural Network (DNN) with rich, engineered features from the large-scale ASSISTments educational dataset. A rigorous comparative analysis of federated aggregation strategies was conducted, identifying FedProx as a significantly more stable and effective method for handling heterogeneous student data than the standard FedAvg baseline. The optimized federated model achieves a high-performance F1-Score of 76.28%, corresponding to 92% of the performance of a powerful, centralized XGBoost model. These findings validate that a federated approach can provide highly effective content recommendations without centralizing sensitive student data. Consequently, our work presents a viable and robust solution to the personalization-privacy dilemma in modern educational platforms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.10516v3",
    "published_date": "2025-09-03 11:28:57 UTC",
    "updated_date": "2025-11-10 14:44:47 UTC"
  },
  {
    "arxiv_id": "2510.13811v1",
    "title": "Generative AI in Heritage Practice: Improving the Accessibility of Heritage Guidance",
    "authors": [
      "Jessica Witte",
      "Edmund Lee",
      "Lisa Brausem",
      "Verity Shillabeer",
      "Chiara Bonacchi"
    ],
    "abstract": "This paper discusses the potential for integrating Generative Artificial Intelligence (GenAI) into professional heritage practice with the aim of enhancing the accessibility of public-facing guidance documents. We developed HAZEL, a GenAI chatbot fine-tuned to assist with revising written guidance relating to heritage conservation and interpretation. Using quantitative assessments, we compare HAZEL's performance to that of ChatGPT (GPT-4) in a series of tasks related to the guidance writing process. The results of this comparison indicate a slightly better performance of HAZEL over ChatGPT, suggesting that the GenAI chatbot is more effective once the underlying large language model (LLM) has been fine-tuned. However, we also note significant limitations, particularly in areas requiring cultural sensitivity and more advanced technical expertise. These findings suggest that, while GenAI cannot replace human heritage professionals in technical authoring tasks, its potential to automate and expedite certain aspects of guidance writing could offer valuable benefits to heritage organisations, especially in resource-constrained contexts.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages",
    "pdf_url": "https://arxiv.org/pdf/2510.13811v1",
    "published_date": "2025-09-03 11:28:39 UTC",
    "updated_date": "2025-09-03 11:28:39 UTC"
  },
  {
    "arxiv_id": "2509.03221v1",
    "title": "LGBP-OrgaNet: Learnable Gaussian Band Pass Fusion of CNN and Transformer Features for Robust Organoid Segmentation and Tracking",
    "authors": [
      "Jing Zhang",
      "Siying Tao",
      "Jiao Li",
      "Tianhe Wang",
      "Junchen Wu",
      "Ruqian Hao",
      "Xiaohui Du",
      "Ruirong Tan",
      "Rui Li"
    ],
    "abstract": "Organoids replicate organ structure and function, playing a crucial role in fields such as tumor treatment and drug screening. Their shape and size can indicate their developmental status, but traditional fluorescence labeling methods risk compromising their structure. Therefore, this paper proposes an automated, non-destructive approach to organoid segmentation and tracking. We introduced the LGBP-OrgaNet, a deep learning-based system proficient in accurately segmenting, tracking, and quantifying organoids. The model leverages complementary information extracted from CNN and Transformer modules and introduces the innovative feature fusion module, Learnable Gaussian Band Pass Fusion, to merge data from two branches. Additionally, in the decoder, the model proposes a Bidirectional Cross Fusion Block to fuse multi-scale features, and finally completes the decoding through progressive concatenation and upsampling. SROrga demonstrates satisfactory segmentation accuracy and robustness on organoids segmentation datasets, providing a potent tool for organoid research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03221v1",
    "published_date": "2025-09-03 11:24:23 UTC",
    "updated_date": "2025-09-03 11:24:23 UTC"
  },
  {
    "arxiv_id": "2509.03219v3",
    "title": "Uncertainty-driven Adaptive Exploration",
    "authors": [
      "Leonidas Bakopoulos",
      "Georgios Chalkiadakis"
    ],
    "abstract": "Adaptive exploration methods propose ways to learn complex policies via alternating between exploration and exploitation. An important question for such methods is to determine the appropriate moment to switch between exploration and exploitation and vice versa. This is critical in domains that require the learning of long and complex sequences of actions. In this work, we present a generic adaptive exploration framework that employs uncertainty to address this important issue in a principled manner. Our framework includes previous adaptive exploration approaches as special cases. Moreover, we can incorporate in our framework any uncertainty-measuring mechanism of choice, for instance mechanisms used in intrinsic motivation or epistemic uncertainty-based exploration methods. We experimentally demonstrate that our framework gives rise to adaptive exploration strategies that outperform standard ones across several environments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "This is an extended version of the paper titled \"A Novel Framework for Uncertainty-Driven Adaptive Exploration\" accepted as a full paper at AAMAS 2026. The accepted paper can be found in https://openreview.net/forum?id=j5awxzdsU9",
    "pdf_url": "https://arxiv.org/pdf/2509.03219v3",
    "published_date": "2025-09-03 11:13:23 UTC",
    "updated_date": "2026-01-06 14:18:41 UTC"
  },
  {
    "arxiv_id": "2509.03206v1",
    "title": "Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback",
    "authors": [
      "Zeqiang Zhang",
      "Fabian Wurzberger",
      "Gerrit Schmid",
      "Sebastian Gottwald",
      "Daniel A. Braun"
    ],
    "abstract": "Reinforcement learning faces significant challenges when applied to tasks characterized by sparse reward structures. Although imitation learning, within the domain of supervised learning, offers faster convergence, it relies heavily on human-generated demonstrations. Recently, Goal-Conditioned Supervised Learning (GCSL) has emerged as a potential solution by enabling self-imitation learning for autonomous systems. By strategically relabelling goals, agents can derive policy insights from their own experiences. Despite the successes of this framework, it presents two notable limitations: (1) Learning exclusively from self-generated experiences can exacerbate the agents' inherent biases; (2) The relabelling strategy allows agents to focus solely on successful outcomes, precluding them from learning from their mistakes. To address these issues, we propose a novel model that integrates contrastive learning principles into the GCSL framework to learn from both success and failure. Through empirical evaluations, we demonstrate that our algorithm overcomes limitations imposed by agents' initial biases and thereby enables more exploratory behavior. This facilitates the identification and adoption of effective policies, leading to superior performance across a variety of challenging environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03206v1",
    "published_date": "2025-09-03 10:50:48 UTC",
    "updated_date": "2025-09-03 10:50:48 UTC"
  },
  {
    "arxiv_id": "2509.03179v1",
    "title": "AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain",
    "authors": [
      "Alma M. Liezenga",
      "Stefan Wijnja",
      "Puck de Haan",
      "Niels W. T. Brink",
      "Jip J. van Stijn",
      "Yori Kamphuis",
      "Klamer Schutte"
    ],
    "abstract": "Poisoning attacks pose an increasing threat to the security and robustness of Artificial Intelligence systems in the military domain. The widespread use of open-source datasets and pretrained models exacerbates this risk. Despite the severity of this threat, there is limited research on the application and detection of poisoning attacks on object detection systems. This is especially problematic in the military domain, where attacks can have grave consequences. In this work, we both investigate the effect of poisoning attacks on military object detectors in practice, and the best approach to detect these attacks. To support this research, we create a small, custom dataset featuring military vehicles: MilCivVeh. We explore the vulnerability of military object detectors for poisoning attacks by implementing a modified version of the BadDet attack: a patch-based poisoning attack. We then assess its impact, finding that while a positive attack success rate is achievable, it requires a substantial portion of the data to be poisoned -- raising questions about its practical applicability. To address the detection challenge, we test both specialized poisoning detection methods and anomaly detection methods from the visual industrial inspection domain. Since our research shows that both classes of methods are lacking, we introduce our own patch detection method: AutoDetect, a simple, fast, and lightweight autoencoder-based method. Our method shows promising results in separating clean from poisoned samples using the reconstruction error of image slices, outperforming existing methods, while being less time- and memory-intensive. We urge that the availability of large, representative datasets in the military domain is a prerequisite to further evaluate risks of poisoning attacks and opportunities patch detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "To be presented at SPIE: Sensors + Imaging, Artificial Intelligence for Security and Defence Applications II",
    "pdf_url": "https://arxiv.org/pdf/2509.03179v1",
    "published_date": "2025-09-03 10:05:02 UTC",
    "updated_date": "2025-09-03 10:05:02 UTC"
  },
  {
    "arxiv_id": "2509.03169v1",
    "title": "Rashomon in the Streets: Explanation Ambiguity in Scene Understanding",
    "authors": [
      "Helge Spieker",
      "Jørn Eirik Betten",
      "Arnaud Gotlieb",
      "Nadjib Lazaar",
      "Nassim Belmecheri"
    ],
    "abstract": "Explainable AI (XAI) is essential for validating and trusting models in safety-critical applications like autonomous driving. However, the reliability of XAI is challenged by the Rashomon effect, where multiple, equally accurate models can offer divergent explanations for the same prediction. This paper provides the first empirical quantification of this effect for the task of action prediction in real-world driving scenes. Using Qualitative Explainable Graphs (QXGs) as a symbolic scene representation, we train Rashomon sets of two distinct model classes: interpretable, pair-based gradient boosting models and complex, graph-based Graph Neural Networks (GNNs). Using feature attribution methods, we measure the agreement of explanations both within and between these classes. Our results reveal significant explanation disagreement. Our findings suggest that explanation ambiguity is an inherent property of the problem, not just a modeling artifact.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025 Fall Symposium: AI Trustworthiness and Risk Assessment for Challenged Contexts (ATRACC)",
    "pdf_url": "https://arxiv.org/pdf/2509.03169v1",
    "published_date": "2025-09-03 09:36:18 UTC",
    "updated_date": "2025-09-03 09:36:18 UTC"
  },
  {
    "arxiv_id": "2509.03161v1",
    "title": "Domain Adaptation of LLMs for Process Data",
    "authors": [
      "Rafael Seidi Oyamada",
      "Jari Peeperkorn",
      "Jochen De Weerdt",
      "Johannes De Smedt"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have emerged as a prominent area of interest across various research domains, including Process Mining (PM). Current applications in PM have predominantly centered on prompt engineering strategies or the transformation of event logs into narrative-style datasets, thereby exploiting the semantic capabilities of LLMs to address diverse tasks. In contrast, this study investigates the direct adaptation of pretrained LLMs to process data without natural language reformulation, motivated by the fact that these models excel in generating sequences of tokens, similar to the objective in PM. More specifically, we focus on parameter-efficient fine-tuning techniques to mitigate the computational overhead typically associated with such models. Our experimental setup focuses on Predictive Process Monitoring (PPM), and considers both single- and multi-task predictions. The results demonstrate a potential improvement in predictive performance over state-of-the-art recurrent neural network (RNN) approaches and recent narrative-style-based solutions, particularly in the multi-task setting. Additionally, our fine-tuned models exhibit faster convergence and require significantly less hyperparameter optimization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03161v1",
    "published_date": "2025-09-03 09:21:35 UTC",
    "updated_date": "2025-09-03 09:21:35 UTC"
  },
  {
    "arxiv_id": "2509.03140v1",
    "title": "Decentralised self-organisation of pivoting cube ensembles using geometric deep learning",
    "authors": [
      "Nadezhda Dobreva",
      "Emmanuel Blazquez",
      "Jai Grover",
      "Dario Izzo",
      "Yuzhen Qin",
      "Dominik Dold"
    ],
    "abstract": "We present a decentralized model for autonomous reconfiguration of homogeneous pivoting cube modular robots in two dimensions. Each cube in the ensemble is controlled by a neural network that only gains information from other cubes in its local neighborhood, trained using reinforcement learning. Furthermore, using geometric deep learning, we include the grid symmetries of the cube ensemble in the neural network architecture. We find that even the most localized versions succeed in reconfiguring to the target shape, although reconfiguration happens faster the more information about the whole ensemble is available to individual cubes. Near-optimal reconfiguration is achieved with only nearest neighbor interactions by using multiple information passing between cubes, allowing them to accumulate more global information about the ensemble. Compared to standard neural network architectures, using geometric deep learning approaches provided only minor benefits. Overall, we successfully demonstrate mostly local control of a modular self-assembling system, which is transferable to other space-relevant systems with different action spaces, such as sliding cube modular robots and CubeSat swarms.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03140v1",
    "published_date": "2025-09-03 08:50:41 UTC",
    "updated_date": "2025-09-03 08:50:41 UTC"
  },
  {
    "arxiv_id": "2509.03137v1",
    "title": "A Neural Network Approach to Multi-radionuclide TDCR Beta Spectroscopy",
    "authors": [
      "Li Yi",
      "Qian Yang"
    ],
    "abstract": "Liquid scintillation triple-to-doubly coincident ratio (TDCR) spectroscopy is widely adopted as a standard method for radionuclide quantification because of its inherent advantages such as high precision, self-calibrating capability, and independence from radioactive reference sources. However, multiradionuclide analysis via TDCR faces the challenges of limited automation and reliance on mixture-specific standards, which may not be easily available. Here, we present an Artificial Intelligence (AI) framework that combines numerical spectral simulation and deep learning for standard-free automated analysis. $β$ spectra for model training were generated using Geant4 simulations coupled with statistically modeled detector response sampling. A tailored neural network architecture, trained on this dataset covering various nuclei mix ratio and quenching scenarios, enables autonomous resolution of individual radionuclide activities and detecting efficiency through end-to-end learning paradigms. The model delivers consistent high accuracy across tasks: activity proportions (mean absolute error = 0.009), detection efficiencies (mean absolute error = 0.002), and spectral reconstruction (Structural Similarity Index = 0.9998), validating its physical plausibility for quenched $β$ spectroscopy. This AI-driven methodology exhibits significant potential for automated safety-compliant multiradionuclide analysis with robust generalization, real-time processing capabilities, and engineering feasibility, particularly in scenarios where reference materials are unavailable or rapid field analysis is required.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "nucl-ex",
      "physics.comp-ph",
      "physics.ins-det"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.03137v1",
    "published_date": "2025-09-03 08:40:02 UTC",
    "updated_date": "2025-09-03 08:40:02 UTC"
  },
  {
    "arxiv_id": "2509.03136v1",
    "title": "Adaptive KV-Cache Compression without Manually Setting Budget",
    "authors": [
      "Chenxia Tang",
      "Jianchun Liu",
      "Hongli Xu",
      "Liusheng Huang"
    ],
    "abstract": "Large language models (LLMs) inference relies heavily on KV-caches to accelerate autoregressive decoding, but the resulting memory footprint grows rapidly with sequence length, posing significant efficiency challenges. Current KV-cache compression methods suffer from a Procrustes' bed problem: they force diverse workloads into fixed compression ratios, leading to suboptimal resource allocation and inference performance. To this end, we present GVote, an adaptive KV-cache compression scheme that eliminates manual budget specification while achieving superior accuracy-efficiency trade-offs. GVote operates on the principle that the important keys are the aggregation of keys required by future queries. The method predicts future query attention demands by Monte-Carlo style sampling potential queries and aggregating selected keys to determine the optimal cache budget without manual specification. Experimental evaluation demonstrates GVote's effectiveness across multiple benchmarks, including GSM8K, RULER and Longbench. Compared to baselines, GVote exhibits 2$\\times$ memory reduction while the accuracy maintains higher or comparable.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03136v1",
    "published_date": "2025-09-03 08:38:40 UTC",
    "updated_date": "2025-09-03 08:38:40 UTC"
  },
  {
    "arxiv_id": "2509.03122v3",
    "title": "From Construction to Injection: Edit-Based Fingerprints for Large Language Models",
    "authors": [
      "Yue Li",
      "Xin Yi",
      "Dongsheng Shi",
      "Yongyi Cui",
      "Gerard de Melo",
      "Linlin Wang"
    ],
    "abstract": "Establishing reliable and verifiable fingerprinting mechanisms is fundamental to controlling the unauthorized redistribution of large language models (LLMs). However, existing approaches face two major challenges: (a) ensuring imperceptibility, including resistance to statistical identification and avoidance of accidental activation during fingerprint construction, and (b) preserving both model utility and fingerprint detectability under subsequent model modifications. To address these challenges, we propose an end-to-end fingerprinting framework with two components. First, we design a rule-based code-mixing fingerprint (CF) that maps natural-query-like prompts to multi-candidate targets, reducing accidental triggering via high-complexity code-mixing formulations. Second, we introduce Multi-Candidate Editing (MCEdit), which jointly optimizes multi-candidate targets and enforces margins between target and non-target outputs to improve post-modification detectability. Extensive experiments demonstrate that our framework provides a robust and practical solution for fingerprinting LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "https://arxiv.org/pdf/2509.03122v3",
    "published_date": "2025-09-03 08:22:04 UTC",
    "updated_date": "2026-01-21 17:56:42 UTC"
  },
  {
    "arxiv_id": "2509.03118v1",
    "title": "A Hierarchical Deep Reinforcement Learning Framework for Traffic Signal Control with Predictable Cycle Planning",
    "authors": [
      "Hankang Gu",
      "Yuli Zhang",
      "Chengming Wang",
      "Ruiyuan Jiang",
      "Ziheng Qiao",
      "Pengfei Fan",
      "Dongyao Jia"
    ],
    "abstract": "Deep reinforcement learning (DRL) has become a popular approach in traffic signal control (TSC) due to its ability to learn adaptive policies from complex traffic environments. Within DRL-based TSC methods, two primary control paradigms are ``choose phase\" and ``switch\" strategies. Although the agent in the choose phase paradigm selects the next active phase adaptively, this paradigm may result in unexpected phase sequences for drivers, disrupting their anticipation and potentially compromising safety at intersections. Meanwhile, the switch paradigm allows the agent to decide whether to switch to the next predefined phase or extend the current phase. While this structure maintains a more predictable order, it can lead to unfair and inefficient phase allocations, as certain movements may be extended disproportionately while others are neglected. In this paper, we propose a DRL model, named Deep Hierarchical Cycle Planner (DHCP), to allocate the traffic signal cycle duration hierarchically. A high-level agent first determines the split of the total cycle time between the North-South (NS) and East-West (EW) directions based on the overall traffic state. Then, a low-level agent further divides the allocated duration within each major direction between straight and left-turn movements, enabling more flexible durations for the two movements. We test our model on both real and synthetic road networks, along with multiple sets of real and synthetic traffic flows. Empirical results show our model achieves the best performance over all datasets against baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03118v1",
    "published_date": "2025-09-03 08:20:06 UTC",
    "updated_date": "2025-09-03 08:20:06 UTC"
  },
  {
    "arxiv_id": "2509.03112v1",
    "title": "Information transmission: Inferring change area from change moment in time series remote sensing images",
    "authors": [
      "Jialu Li",
      "Chen Wu",
      "Meiqi Hu"
    ],
    "abstract": "Time series change detection is a critical task for exploring ecosystem dynamics using time series remote sensing images, because it can simultaneously indicate where and when change occur. While deep learning has shown excellent performance in this domain, it continues to approach change area detection and change moment identification as distinct tasks. Given that change area can be inferred from change moment, we propose a time series change detection network, named CAIM-Net (Change Area Inference from Moment Network), to ensure consistency between change area and change moment results. CAIM-Net infers change area from change moment based on the intrinsic relationship between time series analysis and spatial change detection. The CAIM-Net comprises three key steps: Difference Extraction and Enhancement, Coarse Change Moment Extraction, and Fine Change Moment Extraction and Change Area Inference. In the Difference Extraction and Enhancement, a lightweight encoder with batch dimension stacking is designed to rapidly extract difference features. Subsequently, boundary enhancement convolution is applied to amplify these difference features. In the Coarse Change Moment Extraction, the enhanced difference features from the first step are used to spatiotemporal correlation analysis, and then two distinct methods are employed to determine coarse change moments. In the Fine Change Moment Extraction and Change Area Inference, a multiscale temporal Class Activation Mapping (CAM) module first increases the weight of the change-occurring moment from coarse change moments. Then the weighted change moment is used to infer change area based on the fact that pixels with the change moment must have undergone a change.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03112v1",
    "published_date": "2025-09-03 08:10:30 UTC",
    "updated_date": "2025-09-03 08:10:30 UTC"
  },
  {
    "arxiv_id": "2509.03093v1",
    "title": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
    "authors": [
      "Fatih Pehlivan",
      "Arçin Ülkü Ergüzen",
      "Sahand Moslemi Yengejeh",
      "Mayasah Lami",
      "Anil Koyuncu"
    ],
    "abstract": "Traditional static analysis methods struggle to detect semantic design flaws, such as violations of the SOLID principles, which require a strong understanding of object-oriented design patterns and principles. Existing solutions typically focus on individual SOLID principles or specific programming languages, leaving a gap in the ability to detect violations across all five principles in multi-language codebases. This paper presents a new approach: a methodology that leverages tailored prompt engineering to assess LLMs on their ability to detect SOLID violations across multiple languages. We present a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder, and GPT-4o Mini-on their ability to detect violations of all five SOLID principles. For this evaluation, we construct a new benchmark dataset of 240 manually validated code examples. Using this dataset, we test four distinct prompt strategies inspired by established zero-shot, few-shot, and chain-of-thought techniques to systematically measure their impact on detection accuracy. Our emerging results reveal a stark hierarchy among models, with GPT-4o Mini decisively outperforming others, yet even struggles with challenging principles like DIP. Crucially, we show that prompt strategy has a dramatic impact, but no single strategy is universally best; for instance, a deliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE prompt is superior for DIP violations. Across all experiments, detection accuracy is heavily influenced by language characteristics and degrades sharply with increasing code complexity. These initial findings demonstrate that effective, AI-driven design analysis requires not a single best model, but a tailored approach that matches the right model and prompt to the specific design context, highlighting the potential of LLMs to support maintainability through AI-assisted code analysis.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to ASE2025",
    "pdf_url": "https://arxiv.org/pdf/2509.03093v1",
    "published_date": "2025-09-03 07:48:38 UTC",
    "updated_date": "2025-09-03 07:48:38 UTC"
  },
  {
    "arxiv_id": "2509.06995v1",
    "title": "The Protocol Genome A Self Supervised Learning Framework from DICOM Headers",
    "authors": [
      "Jimmy Joseph"
    ],
    "abstract": "In this paper, we introduce the Protocol Genome, a self-supervised learning system that learns correlations from DICOM headers and achieves AUROC 0.901 (vs 0.847 baseline) and ECE 0.036 (vs 0.058) on fully held-out external validation. Our method also improves calibration and robustness across modalities (CT, MRI, CXR) and vendors. Clinical imaging is funneled through PACS/DICOM, where procedure choices (scanner make/model, sequence, kernel, kVp, TR/TE, and slice thickness) have consequences for contrast, noise, and artifact. These latent confounders impede the generalization of image-only networks across sites. We consider structured DICOM headers as a label and learn protocol-aware but clinically robust image representations. Protocol Genome obtains tokenized embeddings of de-identified header fields and models them along with image features using: (1) protocol-image contrastive learning, (2) masked protocol prediction, and (3) protocol-protocol translation. With 1.26M studies (7 health systems, 31 scanners, 3 vendors; CT, MR, CR/DR), we experiment on: (A) chest CT triage for PE, (B) brain MRI glioma grading, and (C) chest radiograph cardiomegaly detection. Relative to strong SSL baselines (SimCLR, MAE) as well as ImageNet transfer, Protocol Genome (+0.046: PE, +0.058: glioma, +0.041: cardiomegaly) is associated with higher external AUROC; 25-37% calibration improvements are obtained (p < 0.01, DeLong tests). While the gains may be task-dependent, they are preserved with 10-20% of labeled data. From a clinical point of view, the technique reduces false positives at protocol borders and is applicable in a PACS (DICOM C-FIND/C-MOVE, DICOMweb QIDO/WADO). We publish a model card and deployment guide, complete with both de-identification and bias audits.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06995v1",
    "published_date": "2025-09-03 07:38:32 UTC",
    "updated_date": "2025-09-03 07:38:32 UTC"
  },
  {
    "arxiv_id": "2509.03070v2",
    "title": "YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform",
    "authors": [
      "Po-Heng Chou",
      "Wei-Lung Mao",
      "Ru-Ping Lin"
    ],
    "abstract": "This letter proposes a YOLO-based framework for spatial bearing fault diagnosis using time-frequency spectrograms derived from continuous wavelet transform (CWT). One-dimensional vibration signals are first transformed into time-frequency spectrograms using Morlet wavelets to capture transient fault signatures. These spectrograms are then processed by YOLOv9, v10, and v11 models to classify fault types. Evaluated on three benchmark datasets, including Case Western Reserve University (CWRU), Paderborn University (PU), and Intelligent Maintenance System (IMS), the proposed CWT-YOLO pipeline achieves significantly higher accuracy and generalizability than the baseline MCNN-LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8% (PU), and 99.5% (IMS). In addition, its region-aware detection mechanism enables direct visualization of fault locations in spectrograms, offering a practical solution for condition monitoring in rotating machinery.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "eess.SP",
    "comment": "5 pages, 2 figures, 2 tables, submitted to IEEE Sensors Letters",
    "pdf_url": "https://arxiv.org/pdf/2509.03070v2",
    "published_date": "2025-09-03 07:08:44 UTC",
    "updated_date": "2025-09-08 14:37:04 UTC"
  },
  {
    "arxiv_id": "2509.03066v1",
    "title": "S2M2ECG: Spatio-temporal bi-directional State Space Model Enabled Multi-branch Mamba for ECG",
    "authors": [
      "Huaicheng Zhang",
      "Ruoxin Wang",
      "Chenlian Zhou",
      "Jiguang Shi",
      "Yue Ge",
      "Zhoutong Li",
      "Sheng Chang",
      "Hao Wang",
      "Jin He",
      "Qijun Huang"
    ],
    "abstract": "As one of the most effective methods for cardiovascular disease (CVD) diagnosis, multi-lead Electrocardiogram (ECG) signals present a characteristic multi-sensor information fusion challenge that has been continuously researched in deep learning domains. Despite the numerous algorithms proposed with different DL architectures, maintaining a balance among performance, computational complexity, and multi-source ECG feature fusion remains challenging. Recently, state space models (SSMs), particularly Mamba, have demonstrated remarkable effectiveness across various fields. Their inherent design for high-efficiency computation and linear complexity makes them particularly suitable for low-dimensional data like ECGs. This work proposes S2M2ECG, an SSM architecture featuring three-level fusion mechanisms: (1) Spatio-temporal bi-directional SSMs with segment tokenization for low-level signal fusion, (2) Intra-lead temporal information fusion with bi-directional scanning to enhance recognition accuracy in both forward and backward directions, (3) Cross-lead feature interaction modules for spatial information fusion. To fully leverage the ECG-specific multi-lead mechanisms inherent in ECG signals, a multi-branch design and lead fusion modules are incorporated, enabling individual analysis of each lead while ensuring seamless integration with others. Experimental results reveal that S2M2ECG achieves superior performance in the rhythmic, morphological, and clinical scenarios. Moreover, its lightweight architecture ensures it has nearly the fewest parameters among existing models, making it highly suitable for efficient inference and convenient deployment. Collectively, S2M2ECG offers a promising alternative that strikes an excellent balance among performance, computational complexity, and ECG-specific characteristics, paving the way for high-performance, lightweight computations in CVD diagnosis.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03066v1",
    "published_date": "2025-09-03 06:52:50 UTC",
    "updated_date": "2025-09-03 06:52:50 UTC"
  },
  {
    "arxiv_id": "2509.03059v1",
    "title": "Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers",
    "authors": [
      "Xingyue Huang",
      "Rishabh",
      "Gregor Franke",
      "Ziyi Yang",
      "Jiamu Bai",
      "Weijie Bai",
      "Jinhe Bi",
      "Zifeng Ding",
      "Yiqun Duan",
      "Chengyu Fan",
      "Wendong Fan",
      "Xin Gao",
      "Ruohao Guo",
      "Yuan He",
      "Zhuangzhuang He",
      "Xianglong Hu",
      "Neil Johnson",
      "Bowen Li",
      "Fangru Lin",
      "Siyu Lin",
      "Tong Liu",
      "Yunpu Ma",
      "Hao Shen",
      "Hao Sun",
      "Beibei Wang",
      "Fangyijie Wang",
      "Hao Wang",
      "Haoran Wang",
      "Yang Wang",
      "Yifeng Wang",
      "Zhaowei Wang",
      "Ziyang Wang",
      "Yifan Wu",
      "Zikai Xiao",
      "Chengxing Xie",
      "Fan Yang",
      "Junxiao Yang",
      "Qianshuo Ye",
      "Ziyu Ye",
      "Guangtao Zeng",
      "Yuwen Ebony Zhang",
      "Zeyu Zhang",
      "Zihao Zhu",
      "Bernard Ghanem",
      "Philip Torr",
      "Guohao Li"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03059v1",
    "published_date": "2025-09-03 06:42:40 UTC",
    "updated_date": "2025-09-03 06:42:40 UTC"
  },
  {
    "arxiv_id": "2509.03054v2",
    "title": "Binary Quantization For LLMs Through Dynamic Grouping",
    "authors": [
      "Xinzhe Zheng",
      "Zhen-Qun Yang",
      "Haoran Xie",
      "S. Joe Qin",
      "Arlene Chen",
      "Fangzhen Lin"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of Natural Language Processing (NLP) tasks, but require substantial memory and computational resources. Binary quantization, which compresses model weights from 16-bit Brain Float to 1-bit representations in {-1, 1}, offers significant reductions in storage and inference costs. However, such aggressive quantization often leads to notable performance degradation compared to more conservative 4-bit quantization methods. In this research, we propose a novel optimization objective tailored for binary quantization, along with three algorithms designed to realize it effectively. Our method enhances blocked quantization by dynamically identifying optimal unstructured sub-matrices through adaptive grouping strategies. Experimental results demonstrate that our approach achieves an average bit length of just 1.007 bits, while maintaining high model quality. Specifically, our quantized LLaMA 3.2 3B model attains a perplexity of 8.23, remarkably close to the original 7.81, and surpasses previous SOTA BiLLM with a perplexity of only 123.90. Furthermore, our method is competitive with SOTA 4-bit approaches such as GPTQ in both performance and efficiency. The compression process is highly efficient, requiring only 14 seconds to quantize the full LLaMA 3.2 3B weights on a single CPU core, with the entire process completing in under 100 minutes and exhibiting embarrassingly parallel properties.\n  Code - https://github.com/johnnyzheng0636/WGM_bi_quan",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "An error was identified in the quantization bit width; it is not binary",
    "pdf_url": "https://arxiv.org/pdf/2509.03054v2",
    "published_date": "2025-09-03 06:36:21 UTC",
    "updated_date": "2025-09-15 05:32:08 UTC"
  },
  {
    "arxiv_id": "2509.03047v1",
    "title": "FlashRecovery: Fast and Low-Cost Recovery from Failures for Large-Scale Training of LLMs",
    "authors": [
      "Haijun Zhang",
      "Jinxiang Wang",
      "Zhenhua Yu",
      "Yanyong Zhang",
      "Xuejie Ji",
      "Kaining Mao",
      "Jun Zhang",
      "Yaqing Zhang",
      "Ting Wu",
      "Fei Jie",
      "Xiemin Huang",
      "Zhifang Cai",
      "Junhua Cheng",
      "Shuwei Wang",
      "Wei Li",
      "Xiaoming Bao",
      "Hua Xu",
      "Shixiong Zhao",
      "Jun Li",
      "Hongwei Sun",
      "Ziyang Zhang",
      "Yi Xiong",
      "Chunsheng Li"
    ],
    "abstract": "Large language models (LLMs) have made a profound impact across various fields due to their advanced capabilities. However, training these models at unprecedented scales requires extensive AI accelerator clusters and sophisticated parallelism strategies, which pose significant challenges in maintaining system reliability over prolonged training periods. A major concern is the substantial loss of training time caused by inevitable hardware and software failures. To address these challenges, we present FlashRecovery, a fast and low-cost failure recovery system comprising three core modules: (1) Active and real-time failure detection. This module performs continuous training state monitoring, enabling immediate identification of hardware and software failures within seconds, thus ensuring rapid incident response; (2) Scale-independent task restart. By employing different recovery strategies for normal and faulty nodes, combined with an optimized communication group reconstruction protocol, our approach ensures that the recovery time remains nearly constant, regardless of cluster scale; (3) Checkpoint-free recovery within one step. Our novel recovery mechanism enables single-step restoration, completely eliminating dependence on traditional checkpointing methods and their associated overhead. Collectively, these innovations enable FlashRecovery to achieve optimal Recovery Time Objective (RTO) and Recovery Point Objective (RPO), substantially improving the reliability and efficiency of long-duration LLM training. Experimental results demonstrate that FlashRecovery system can achieve training restoration on training cluster with 4, 800 devices in 150 seconds. We also verify that the time required for failure recovery is nearly consistent for different scales of training tasks.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03047v1",
    "published_date": "2025-09-03 06:19:59 UTC",
    "updated_date": "2025-09-03 06:19:59 UTC"
  },
  {
    "arxiv_id": "2509.03041v1",
    "title": "MedLiteNet: Lightweight Hybrid Medical Image Segmentation Model",
    "authors": [
      "Pengyang Yu",
      "Haoquan Wang",
      "Gerard Marks",
      "Tahar Kechadi",
      "Laurence T. Yang",
      "Sahraoui Dhelim",
      "Nyothiri Aung"
    ],
    "abstract": "Accurate skin-lesion segmentation remains a key technical challenge for computer-aided diagnosis of skin cancer. Convolutional neural networks, while effective, are constrained by limited receptive fields and thus struggle to model long-range dependencies. Vision Transformers capture global context, yet their quadratic complexity and large parameter budgets hinder use on the small-sample medical datasets common in dermatology. We introduce the MedLiteNet, a lightweight CNN Transformer hybrid tailored for dermoscopic segmentation that achieves high precision through hierarchical feature extraction and multi-scale context aggregation. The encoder stacks depth-wise Mobile Inverted Bottleneck blocks to curb computation, inserts a bottleneck-level cross-scale token-mixing unit to exchange information between resolutions, and embeds a boundary-aware self-attention module to sharpen lesion contours.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03041v1",
    "published_date": "2025-09-03 05:59:13 UTC",
    "updated_date": "2025-09-03 05:59:13 UTC"
  },
  {
    "arxiv_id": "2509.03036v1",
    "title": "Knowledge Integration for Physics-informed Symbolic Regression Using Pre-trained Large Language Models",
    "authors": [
      "Bilge Taskin",
      "Wenxiong Xie",
      "Teddy Lazebnik"
    ],
    "abstract": "Symbolic regression (SR) has emerged as a powerful tool for automated scientific discovery, enabling the derivation of governing equations from experimental data. A growing body of work illustrates the promise of integrating domain knowledge into the SR to improve the discovered equation's generality and usefulness. Physics-informed SR (PiSR) addresses this by incorporating domain knowledge, but current methods often require specialized formulations and manual feature engineering, limiting their adaptability only to domain experts. In this study, we leverage pre-trained Large Language Models (LLMs) to facilitate knowledge integration in PiSR. By harnessing the contextual understanding of LLMs trained on vast scientific literature, we aim to automate the incorporation of domain knowledge, reducing the need for manual intervention and making the process more accessible to a broader range of scientific problems. Namely, the LLM is integrated into the SR's loss function, adding a term of the LLM's evaluation of the SR's produced equation. We extensively evaluate our method using three SR algorithms (DEAP, gplearn, and PySR) and three pre-trained LLMs (Falcon, Mistral, and LLama 2) across three physical dynamics (dropping ball, simple harmonic motion, and electromagnetic wave). The results demonstrate that LLM integration consistently improves the reconstruction of physical dynamics from data, enhancing the robustness of SR models to noise and complexity. We further explore the impact of prompt engineering, finding that more informative prompts significantly improve performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.03036v1",
    "published_date": "2025-09-03 05:53:40 UTC",
    "updated_date": "2025-09-03 05:53:40 UTC"
  },
  {
    "arxiv_id": "2509.03025v2",
    "title": "Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens",
    "authors": [
      "Sohee Kim",
      "Soohyun Ryu",
      "Joonhyung Park",
      "Eunho Yang"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) generate contextually relevant responses by jointly interpreting visual and textual inputs. However, our finding reveals they often mistakenly perceive text inputs lacking visual evidence as being part of the image, leading to erroneous responses. In light of this finding, we probe whether LVLMs possess an internal capability to determine if textual concepts are grounded in the image, and discover a specific subset of Feed-Forward Network (FFN) neurons, termed Visual Absence-aware (VA) neurons, that consistently signal the visual absence through a distinctive activation pattern. Leveraging these patterns, we develop a detection module that systematically classifies whether an input token is visually grounded. Guided by its prediction, we propose a method to refine the outputs by reinterpreting question prompts or replacing the detected absent tokens during generation. Extensive experiments show that our method effectively mitigates the models' tendency to falsely presume the visual presence of text input and its generality across various LVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted to EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.03025v2",
    "published_date": "2025-09-03 05:17:25 UTC",
    "updated_date": "2025-09-05 07:49:47 UTC"
  },
  {
    "arxiv_id": "2509.03024v1",
    "title": "Efficient Privacy-Preserving Recommendation on Sparse Data using Fully Homomorphic Encryption",
    "authors": [
      "Moontaha Nishat Chowdhury",
      "André Bauer",
      "Minxuan Zhou"
    ],
    "abstract": "In today's data-driven world, recommendation systems personalize user experiences across industries but rely on sensitive data, raising privacy concerns. Fully homomorphic encryption (FHE) can secure these systems, but a significant challenge in applying FHE to recommendation systems is efficiently handling the inherently large and sparse user-item rating matrices. FHE operations are computationally intensive, and naively processing various sparse matrices in recommendation systems would be prohibitively expensive. Additionally, the communication overhead between parties remains a critical concern in encrypted domains. We propose a novel approach combining Compressed Sparse Row (CSR) representation with FHE-based matrix factorization that efficiently handles matrix sparsity in the encrypted domain while minimizing communication costs. Our experimental results demonstrate high recommendation accuracy with encrypted data while achieving the lowest communication costs, effectively preserving user privacy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "The paper is accepted at the 21st IEEE International eScience Conference (eScience'25) and will be published soon. Link: https://www.escience-conference.org/2025/papers",
    "pdf_url": "https://arxiv.org/pdf/2509.03024v1",
    "published_date": "2025-09-03 05:15:45 UTC",
    "updated_date": "2025-09-03 05:15:45 UTC"
  },
  {
    "arxiv_id": "2509.03011v1",
    "title": "Lesion-Aware Visual-Language Fusion for Automated Image Captioning of Ulcerative Colitis Endoscopic Examinations",
    "authors": [
      "Alexis Ivan Lopez Escamilla",
      "Gilberto Ochoa",
      "Sharib Al"
    ],
    "abstract": "We present a lesion-aware image captioning framework for ulcerative colitis (UC). The model integrates ResNet embeddings, Grad-CAM heatmaps, and CBAM-enhanced attention with a T5 decoder. Clinical metadata (MES score 0-3, vascular pattern, bleeding, erythema, friability, ulceration) is injected as natural-language prompts to guide caption generation. The system produces structured, interpretable descriptions aligned with clinical practice and provides MES classification and lesion tags. Compared with baselines, our approach improves caption quality and MES classification accuracy, supporting reliable endoscopic reporting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Miccai Demi Conference 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.03011v1",
    "published_date": "2025-09-03 04:41:18 UTC",
    "updated_date": "2025-09-03 04:41:18 UTC"
  },
  {
    "arxiv_id": "2509.02982v1",
    "title": "StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails",
    "authors": [
      "Hritik Arasu",
      "Faisal R Jahangiri"
    ],
    "abstract": "Sleep staging models often degrade when deployed on patients with unseen physiology or recording conditions. We propose a streaming, source-free test-time adaptation (TTA) recipe that combines entropy minimization (Tent) with Batch-Norm statistic refresh and two safety rails: an entropy gate to pause adaptation on uncertain windows and an EMA-based reset to reel back drift. On Sleep-EDF Expanded, using single-lead EEG (Fpz-Cz, 100 Hz, 30s epochs; R&K to AASM mapping), we show consistent gains over a frozen baseline at seconds-level latency and minimal memory, reporting per-stage metrics and Cohen's k. The method is model-agnostic, requires no source data or patient calibration, and is practical for on-device or bedside use.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "5 page paper, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.02982v1",
    "published_date": "2025-09-03 03:42:31 UTC",
    "updated_date": "2025-09-03 03:42:31 UTC"
  },
  {
    "arxiv_id": "2509.02967v2",
    "title": "AR-KAN: Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network for Time Series Forecasting",
    "authors": [
      "Chen Zeng",
      "Tiehang Xu",
      "Qiao Wang"
    ],
    "abstract": "Traditional neural networks struggle to capture the spectral structure of complex signals. Fourier neural networks (FNNs) attempt to address this by embedding Fourier series components, yet many real-world signals are almost-periodic with non-commensurate frequencies, posing additional challenges. Building on prior work showing that ARIMA outperforms large language models (LLMs) for forecasting, we extend the comparison to neural predictors and find ARIMA still superior. We therefore propose the Autoregressive-Weight-Enhanced Kolmogorov-Arnold Network (AR-KAN), which integrates a pre-trained AR module for temporal memory with a KAN for nonlinear representation. The AR module preserves essential temporal features while reducing redundancy. Experiments demonstrate that AR-KAN matches ARIMA on almost-periodic functions and achieves the best results on $72\\%$ of Rdatasets series, with a clear advantage on data with periodic structure. These results highlight AR-KAN as a robust and effective framework for time series forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02967v2",
    "published_date": "2025-09-03 03:11:26 UTC",
    "updated_date": "2025-09-18 01:57:01 UTC"
  },
  {
    "arxiv_id": "2509.02966v2",
    "title": "KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models",
    "authors": [
      "Yujin Wang",
      "Tianyi Wang",
      "Quanfeng Liu",
      "Wenxian Fan",
      "Junfeng Jiao",
      "Christian Claudel",
      "Yunbing Yan",
      "Bingzhao Gao",
      "Jianqiang Wang",
      "Hong Chen"
    ],
    "abstract": "Accurate short-horizon trajectory prediction is crucial for safe and reliable autonomous driving. However, existing vision-language models (VLMs) often fail to accurately understand driving scenes and generate trustworthy trajectories. To address this challenge, this paper introduces KEPT, a knowledge-enhanced VLM framework that predicts ego trajectories directly from consecutive front-view driving frames. KEPT integrates a temporal frequency-spatial fusion (TFSF) video encoder, which is trained via self-supervised learning with hard-negative mining, with a k-means & HNSW retrieval-augmented generation (RAG) pipeline. Retrieved prior knowledge is added into chain-of-thought (CoT) prompts with explicit planning constraints, while a triple-stage fine-tuning paradigm aligns the VLM backbone to enhance spatial perception and trajectory prediction capabilities. Evaluated on nuScenes dataset, KEPT achieves the best open-loop performance compared with baseline methods. Ablation studies on fine-tuning stages, Top-K value of RAG, different retrieval strategies, vision encoders, and VLM backbones are conducted to demonstrate the effectiveness of KEPT. These results indicate that KEPT offers a promising, data-efficient way toward trustworthy trajectory prediction in autonomous driving.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02966v2",
    "published_date": "2025-09-03 03:10:42 UTC",
    "updated_date": "2025-11-25 06:38:17 UTC"
  },
  {
    "arxiv_id": "2509.05352v1",
    "title": "Unsupervised Instance Segmentation with Superpixels",
    "authors": [
      "Cuong Manh Hoang"
    ],
    "abstract": "Instance segmentation is essential for numerous computer vision applications, including robotics, human-computer interaction, and autonomous driving. Currently, popular models bring impressive performance in instance segmentation by training with a large number of human annotations, which are costly to collect. For this reason, we present a new framework that efficiently and effectively segments objects without the need for human annotations. Firstly, a MultiCut algorithm is applied to self-supervised features for coarse mask segmentation. Then, a mask filter is employed to obtain high-quality coarse masks. To train the segmentation network, we compute a novel superpixel-guided mask loss, comprising hard loss and soft loss, with high-quality coarse masks and superpixels segmented from low-level image features. Lastly, a self-training process with a new adaptive loss is proposed to improve the quality of predicted masks. We conduct experiments on public datasets in instance segmentation and object detection to demonstrate the effectiveness of the proposed framework. The results show that the proposed framework outperforms previous state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05352v1",
    "published_date": "2025-09-03 02:46:48 UTC",
    "updated_date": "2025-09-03 02:46:48 UTC"
  },
  {
    "arxiv_id": "2509.02958v1",
    "title": "Lattice Annotated Temporal (LAT) Logic for Non-Markovian Reasoning",
    "authors": [
      "Kaustuv Mukherji",
      "Jaikrishna Manojkumar Patil",
      "Dyuman Aditya",
      "Paulo Shakarian",
      "Devendra Parkar",
      "Lahari Pokala",
      "Clark Dorman",
      "Gerardo I. Simari"
    ],
    "abstract": "We introduce Lattice Annotated Temporal (LAT) Logic, an extension of Generalized Annotated Logic Programs (GAPs) that incorporates temporal reasoning and supports open-world semantics through the use of a lower lattice structure. This logic combines an efficient deduction process with temporal logic programming to support non-Markovian relationships and open-world reasoning capabilities. The open-world aspect, a by-product of the use of the lower-lattice annotation structure, allows for efficient grounding through a Skolemization process, even in domains with infinite or highly diverse constants.\n  We provide a suite of theoretical results that bound the computational complexity of the grounding process, in addition to showing that many of the results on GAPs (using an upper lattice) still hold with the lower lattice and temporal extensions (though different proof techniques are required). Our open-source implementation, PyReason, features modular design, machine-level optimizations, and direct integration with reinforcement learning environments. Empirical evaluations across multi-agent simulations and knowledge graph tasks demonstrate up to three orders of magnitude speedup and up to five orders of magnitude memory reduction while maintaining or improving task performance. Additionally, we evaluate LAT Logic's value in reinforcement learning environments as a non-Markovian simulator, achieving up to three orders of magnitude faster simulation with improved agent performance, including a 26% increase in win rate due to capturing richer temporal dependencies. These results highlight LAT Logic's potential as a unified, extensible framework for open-world temporal reasoning in dynamic and uncertain environments. Our implementation is available at: pyreason.syracuse.edu.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02958v1",
    "published_date": "2025-09-03 02:45:34 UTC",
    "updated_date": "2025-09-03 02:45:34 UTC"
  },
  {
    "arxiv_id": "2509.02930v2",
    "title": "VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills",
    "authors": [
      "Erik M. Lintunen"
    ],
    "abstract": "In self-supervised reinforcement learning (RL), one of the key challenges is learning a diverse set of skills to prepare agents for unknown future tasks. Despite impressive advances, scalability and evaluation remain prevalent issues. Regarding scalability, the search for meaningful skills can be obscured by high-dimensional feature spaces, where relevant features may vary across downstream task domains. For evaluating skill diversity, defining what constitutes \"diversity\" typically requires a hard commitment to a specific notion of what it means for skills to be diverse, potentially leading to inconsistencies in how skill diversity is understood, making results across different approaches hard to compare, and leaving many forms of diversity unexplored. To address these issues, we adopt a measure of sample diversity that translates ideas from ecology to machine learning -- the Vendi Score -- allowing the user to specify and evaluate any desired form of diversity. We demonstrate how this metric facilitates skill evaluation and introduce VendiRL, a unified framework for learning diversely diverse sets of skills. Given distinct similarity functions, VendiRL motivates distinct forms of diversity, which could support skill-diversity pretraining in new and richly interactive environments where optimising for various forms of diversity may be desirable.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages including appendices, full paper at the Scaling Environments for Agents workshop at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02930v2",
    "published_date": "2025-09-03 01:53:29 UTC",
    "updated_date": "2025-10-12 18:35:39 UTC"
  },
  {
    "arxiv_id": "2509.02924v1",
    "title": "Simulacra Naturae: Generative Ecosystem driven by Agent-Based Simulations and Brain Organoid Collective Intelligence",
    "authors": [
      "Nefeli Manoudaki",
      "Mert Toka",
      "Iason Paterakis",
      "Diarmid Flatley"
    ],
    "abstract": "Simulacra Naturae is a data-driven media installation that explores collective care through the entanglement of biological computation, material ecologies, and generative systems. The work translates pre-recorded neural activity from brain organoids, lab-grown three-dimensional clusters of neurons, into a multi-sensory environment composed of generative visuals, spatial audio, living plants, and fabricated clay artifacts. These biosignals, streamed through a real-time system, modulate emergent agent behaviors inspired by natural systems such as termite colonies and slime molds. Rather than using biosignals as direct control inputs, Simulacra Naturae treats organoid activity as a co-creative force, allowing neural rhythms to guide the growth, form, and atmosphere of a generative ecosystem. The installation features computationally fabricated clay prints embedded with solenoids, adding physical sound resonances to the generative surround composition. The spatial environment, filled with live tropical plants and a floor-level projection layer featuring real-time generative AI visuals, invites participants into a sensory field shaped by nonhuman cognition. By grounding abstract data in living materials and embodied experience, Simulacra Naturae reimagines visualization as a practice of care, one that decentralizes human agency and opens new spaces for ethics, empathy, and ecological attunement within hybrid computational systems.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.MM",
    "comment": "to be published in IEEE VISAP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02924v1",
    "published_date": "2025-09-03 01:26:39 UTC",
    "updated_date": "2025-09-03 01:26:39 UTC"
  },
  {
    "arxiv_id": "2509.02918v1",
    "title": "Single Domain Generalization in Diabetic Retinopathy: A Neuro-Symbolic Learning Approach",
    "authors": [
      "Midhat Urooj",
      "Ayan Banerjee",
      "Farhat Shaikh",
      "Kuntal Thakur",
      "Sandeep Gupta"
    ],
    "abstract": "Domain generalization remains a critical challenge in medical imaging, where models trained on single sources often fail under real-world distribution shifts. We propose KG-DG, a neuro-symbolic framework for diabetic retinopathy (DR) classification that integrates vision transformers with expert-guided symbolic reasoning to enable robust generalization across unseen domains. Our approach leverages clinical lesion ontologies through structured, rule-based features and retinal vessel segmentation, fusing them with deep visual representations via a confidence-weighted integration strategy. The framework addresses both single-domain generalization (SDG) and multi-domain generalization (MDG) by minimizing the KL divergence between domain embeddings, thereby enforcing alignment of high-level clinical semantics. Extensive experiments across four public datasets (APTOS, EyePACS, Messidor-1, Messidor-2) demonstrate significant improvements: up to a 5.2% accuracy gain in cross-domain settings and a 6% improvement over baseline ViT models. Notably, our symbolic-only model achieves a 63.67% average accuracy in MDG, while the complete neuro-symbolic integration achieves the highest accuracy compared to existing published baselines and benchmarks in challenging SDG scenarios. Ablation studies reveal that lesion-based features (84.65% accuracy) substantially outperform purely neural approaches, confirming that symbolic components act as effective regularizers beyond merely enhancing interpretability. Our findings establish neuro-symbolic integration as a promising paradigm for building clinically robust, and domain-invariant medical AI systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in ANSyA 2025: 1st International Workshop on Advanced Neuro-Symbolic Applications",
    "pdf_url": "https://arxiv.org/pdf/2509.02918v1",
    "published_date": "2025-09-03 01:07:49 UTC",
    "updated_date": "2025-09-03 01:07:49 UTC"
  },
  {
    "arxiv_id": "2509.02910v1",
    "title": "The Basic B*** Effect: The Use of LLM-based Agents Reduces the Distinctiveness and Diversity of People's Choices",
    "authors": [
      "Sandra C. Matz",
      "C. Blaine Horton",
      "Sofie Goethals"
    ],
    "abstract": "Large language models (LLMs) increasingly act on people's behalf: they write emails, buy groceries, and book restaurants. While the outsourcing of human decision-making to AI can be both efficient and effective, it raises a fundamental question: how does delegating identity-defining choices to AI reshape who people become? We study the impact of agentic LLMs on two identity-relevant outcomes: interpersonal distinctiveness - how unique a person's choices are relative to others - and intrapersonal diversity - the breadth of a single person's choices over time. Using real choices drawn from social-media behavior of 1,000 U.S. users (110,000 choices in total), we compare a generic and personalized agent to a human baseline. Both agents shift people's choices toward more popular options, reducing the distinctiveness of their behaviors and preferences. While the use of personalized agents tempers this homogenization (compared to the generic AI), it also more strongly compresses the diversity of people's preference portfolios by narrowing what they explore across topics and psychological affinities. Understanding how AI agents might flatten human experience, and how using generic versus personalized agents involves distinctiveness-diversity trade-offs, is critical for designing systems that augment rather than constrain human agency, and for safeguarding diversity in thought, taste, and expression.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02910v1",
    "published_date": "2025-09-03 00:33:49 UTC",
    "updated_date": "2025-09-03 00:33:49 UTC"
  },
  {
    "arxiv_id": "2509.04515v1",
    "title": "Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations",
    "authors": [
      "Martha O. Dimgba",
      "Sharon Oba",
      "Ameeta Agrawal",
      "Philippe J. Giabbanelli"
    ],
    "abstract": "Language models have been shown to propagate social bias through their output, particularly in the representation of gender and ethnicity. This paper investigates gender and ethnicity biases in AI-generated occupational stories. Representation biases are measured before and after applying our proposed mitigation strategy, Bias Analysis and Mitigation through Explanation (BAME), revealing improvements in demographic representation ranging from 2% to 20%. BAME leverages model-generated explanations to inform targeted prompt engineering, effectively reducing biases without modifying model parameters. By analyzing stories generated across 25 occupational groups, three large language models (Claude 3.5 Sonnet, Llama 3.1 70B Instruct, and GPT-4 Turbo), and multiple demographic dimensions, we identify persistent patterns of overrepresentation and underrepresentation linked to training data stereotypes. Our findings demonstrate that guiding models with their own internal reasoning mechanisms can significantly enhance demographic parity, thereby contributing to the development of more transparent generative AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.04515v1",
    "published_date": "2025-09-03 00:25:25 UTC",
    "updated_date": "2025-09-03 00:25:25 UTC"
  }
]