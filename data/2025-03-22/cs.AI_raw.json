[
  {
    "arxiv_id": "2503.17885v1",
    "title": "Reasoning with LLMs for Zero-Shot Vulnerability Detection",
    "authors": [
      "Arastoo Zibaeirad",
      "Marco Vieira"
    ],
    "abstract": "Automating software vulnerability detection (SVD) remains a critical\nchallenge in an era of increasingly complex and interdependent software\nsystems. Despite significant advances in Large Language Models (LLMs) for code\nanalysis, prevailing evaluation methodologies often lack the\n\\textbf{context-aware robustness} necessary to capture real-world intricacies\nand cross-component interactions. To address these limitations, we present\n\\textbf{VulnSage}, a comprehensive evaluation framework and a dataset curated\nfrom diverse, large-scale open-source system software projects developed in\nC/C++. Unlike prior datasets, it leverages a heuristic noise pre-filtering\napproach combined with LLM-based reasoning to ensure a representative and\nminimally noisy spectrum of vulnerabilities. The framework supports\nmulti-granular analysis across function, file, and inter-function levels and\nemploys four diverse zero-shot prompt strategies: Baseline, Chain-of-Thought,\nThink, and Think & Verify. Through this evaluation, we uncover that structured\nreasoning prompts substantially improve LLM performance, with Think & Verify\nreducing ambiguous responses from 20.3% to 9.1% while increasing accuracy. We\nfurther demonstrate that code-specialized models consistently outperform\ngeneral-purpose alternatives, with performance varying significantly across\nvulnerability types, revealing that no single approach universally excels\nacross all security contexts. Link to dataset and codes:\nhttps://github.com/Erroristotle/VulnSage.git",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17885v1",
    "published_date": "2025-03-22 23:59:17 UTC",
    "updated_date": "2025-03-22 23:59:17 UTC"
  },
  {
    "arxiv_id": "2503.20796v1",
    "title": "EXPLICATE: Enhancing Phishing Detection through Explainable AI and LLM-Powered Interpretability",
    "authors": [
      "Bryan Lim",
      "Roman Huerta",
      "Alejandro Sotelo",
      "Anthonie Quintela",
      "Priyanka Kumar"
    ],
    "abstract": "Sophisticated phishing attacks have emerged as a major cybersecurity threat,\nbecoming more common and difficult to prevent. Though machine learning\ntechniques have shown promise in detecting phishing attacks, they function\nmainly as \"black boxes\" without revealing their decision-making rationale. This\nlack of transparency erodes the trust of users and diminishes their effective\nthreat response. We present EXPLICATE: a framework that enhances phishing\ndetection through a three-component architecture: an ML-based classifier using\ndomain-specific features, a dual-explanation layer combining LIME and SHAP for\ncomplementary feature-level insights, and an LLM enhancement using DeepSeek v3\nto translate technical explanations into accessible natural language. Our\nexperiments show that EXPLICATE attains 98.4 % accuracy on all metrics, which\nis on par with existing deep learning techniques but has better explainability.\nHigh-quality explanations are generated by the framework with an accuracy of\n94.2 % as well as a consistency of 96.8\\% between the LLM output and model\nprediction. We create EXPLICATE as a fully usable GUI application and a light\nChrome extension, showing its applicability in many deployment situations. The\nresearch shows that high detection performance can go hand-in-hand with\nmeaningful explainability in security applications. Most important, it\naddresses the critical divide between automated AI and user trust in phishing\ndetection systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.20796v1",
    "published_date": "2025-03-22 23:37:35 UTC",
    "updated_date": "2025-03-22 23:37:35 UTC"
  },
  {
    "arxiv_id": "2503.17882v1",
    "title": "Think Before Refusal : Triggering Safety Reflection in LLMs to Mitigate False Refusal Behavior",
    "authors": [
      "Shengyun Si",
      "Xinpeng Wang",
      "Guangyao Zhai",
      "Nassir Navab",
      "Barbara Plank"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated that\nfine-tuning and human alignment can render LLMs harmless. In practice, such\n\"harmlessness\" behavior is mainly achieved by training models to reject harmful\nrequests, such as \"Explain how to burn down my neighbor's house\", where the\nmodel appropriately declines to respond. However, this approach can\ninadvertently result in false refusal, where models reject benign queries as\nwell, such as \"Tell me how to kill a Python process\". In this work, we\ndemonstrate that prompting safety reflection before generating a response can\nmitigate false refusal behavior. Building on this finding, we introduce the\nThink-Before-Refusal (TBR) schema and conduct safety-aware instruction\nfine-tuning incorporating safety reflection. In an ablation study across 15\npre-trained models, we show that models fine-tuned with safety reflection\nsignificantly reduce false refusal behavior while maintaining safety and\noverall performance compared to those fine-tuned without safety reflection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 23 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.17882v1",
    "published_date": "2025-03-22 23:35:49 UTC",
    "updated_date": "2025-03-22 23:35:49 UTC"
  },
  {
    "arxiv_id": "2503.18976v1",
    "title": "Synthetic media and computational capitalism: towards a critical theory of artificial intelligence",
    "authors": [
      "David M. Berry"
    ],
    "abstract": "This paper develops a critical theory of artificial intelligence, within a\nhistorical constellation where computational systems increasingly generate\ncultural content that destabilises traditional distinctions between human and\nmachine production. Through this analysis, I introduce the concept of the\nalgorithmic condition, a cultural moment when machine-generated work not only\nbecomes indistinguishable from human creation but actively reshapes our\nunderstanding of ideas of authenticity. This transformation, I argue, moves\nbeyond false consciousness towards what I call post-consciousness, where the\nboundaries between individual and synthetic consciousness become porous.\nDrawing on critical theory and extending recent work on computational ideology,\nI develop three key theoretical contributions, first, the concept of the\nInversion to describe a new computational turn in algorithmic society; second,\nautomimetric production as a framework for understanding emerging practices of\nautomated value creation; and third, constellational analysis as a\nmethodological approach for mapping the complex interplay of technical systems,\ncultural forms and political economic structures. Through these contributions,\nI argue that we need new critical methods capable of addressing both the\ntechnical specificity of AI systems and their role in restructuring forms of\nlife under computational capitalism. The paper concludes by suggesting that\ncritical reflexivity is needed to engage with the algorithmic condition without\nbeing subsumed by it and that it represents a growing challenge for\ncontemporary critical theory.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.0; K.4.1"
    ],
    "primary_category": "cs.CY",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.18976v1",
    "published_date": "2025-03-22 22:59:28 UTC",
    "updated_date": "2025-03-22 22:59:28 UTC"
  },
  {
    "arxiv_id": "2503.17871v1",
    "title": "good4cir: Generating Detailed Synthetic Captions for Composed Image Retrieval",
    "authors": [
      "Pranavi Kolouju",
      "Eric Xing",
      "Robert Pless",
      "Nathan Jacobs",
      "Abby Stylianou"
    ],
    "abstract": "Composed image retrieval (CIR) enables users to search images using a\nreference image combined with textual modifications. Recent advances in\nvision-language models have improved CIR, but dataset limitations remain a\nbarrier. Existing datasets often rely on simplistic, ambiguous, or insufficient\nmanual annotations, hindering fine-grained retrieval. We introduce good4cir, a\nstructured pipeline leveraging vision-language models to generate high-quality\nsynthetic annotations. Our method involves: (1) extracting fine-grained object\ndescriptions from query images, (2) generating comparable descriptions for\ntarget images, and (3) synthesizing textual instructions capturing meaningful\ntransformations between images. This reduces hallucination, enhances\nmodification diversity, and ensures object-level consistency. Applying our\nmethod improves existing datasets and enables creating new datasets across\ndiverse domains. Results demonstrate improved retrieval accuracy for CIR models\ntrained on our pipeline-generated datasets. We release our dataset construction\nframework to support further research in CIR and multi-modal retrieval.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17871v1",
    "published_date": "2025-03-22 22:33:56 UTC",
    "updated_date": "2025-03-22 22:33:56 UTC"
  },
  {
    "arxiv_id": "2503.17867v1",
    "title": "Detecting and Mitigating DDoS Attacks with AI: A Survey",
    "authors": [
      "Alexandru Apostu",
      "Silviu Gheorghe",
      "Andrei Hîji",
      "Nicolae Cleju",
      "Andrei Pătraşcu",
      "Cristian Rusu",
      "Radu Ionescu",
      "Paul Irofti"
    ],
    "abstract": "Distributed Denial of Service attacks represent an active cybersecurity\nresearch problem. Recent research shifted from static rule-based defenses\ntowards AI-based detection and mitigation. This comprehensive survey covers\nseveral key topics. Preeminently, state-of-the-art AI detection methods are\ndiscussed. An in-depth taxonomy based on manual expert hierarchies and an\nAI-generated dendrogram are provided, thus settling DDoS categorization\nambiguities. An important discussion on available datasets follows, covering\ndata format options and their role in training AI detection methods together\nwith adversarial training and examples augmentation. Beyond detection, AI based\nmitigation techniques are surveyed as well. Finally, multiple open research\ndirections are proposed.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17867v1",
    "published_date": "2025-03-22 21:54:23 UTC",
    "updated_date": "2025-03-22 21:54:23 UTC"
  },
  {
    "arxiv_id": "2504.01970v1",
    "title": "Differentiable Optimization for Deep Learning-Enhanced DC Approximation of AC Optimal Power Flow",
    "authors": [
      "Andrew Rosemberg",
      "Michael Klamkin"
    ],
    "abstract": "The growing scale of power systems and the increasing uncertainty introduced\nby renewable energy sources necessitates novel optimization techniques that are\nsignificantly faster and more accurate than existing methods. The AC Optimal\nPower Flow (AC-OPF) problem, a core component of power grid optimization, is\noften approximated using linearized DC Optimal Power Flow (DC-OPF) models for\ncomputational tractability, albeit at the cost of suboptimal and inefficient\ndecisions. To address these limitations, we propose a novel deep learning-based\nframework for network equivalency that enhances DC-OPF to more closely mimic\nthe behavior of AC-OPF. The approach utilizes recent advances in differentiable\noptimization, incorporating a neural network trained to predict adjusted nodal\nshunt conductances and branch susceptances in order to account for nonlinear\npower flow behavior. The model can be trained end-to-end using modern deep\nlearning frameworks by leveraging the implicit function theorem. Results\ndemonstrate the framework's ability to significantly improve prediction\naccuracy, paving the way for more reliable and efficient power systems.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.01970v1",
    "published_date": "2025-03-22 20:53:53 UTC",
    "updated_date": "2025-03-22 20:53:53 UTC"
  },
  {
    "arxiv_id": "2503.17862v1",
    "title": "A Causal Adjustment Module for Debiasing Scene Graph Generation",
    "authors": [
      "Li Liu",
      "Shuzhou Sun",
      "Shuaifeng Zhi",
      "Fan Shi",
      "Zhen Liu",
      "Janne Heikkilä",
      "Yongxiang Liu"
    ],
    "abstract": "While recent debiasing methods for Scene Graph Generation (SGG) have shown\nimpressive performance, these efforts often attribute model bias solely to the\nlong-tail distribution of relationships, overlooking the more profound causes\nstemming from skewed object and object pair distributions. In this paper, we\nemploy causal inference techniques to model the causality among these observed\nskewed distributions. Our insight lies in the ability of causal inference to\ncapture the unobservable causal effects between complex distributions, which is\ncrucial for tracing the roots of model bias. Specifically, we introduce the\nMediator-based Causal Chain Model (MCCM), which, in addition to modeling\ncausality among objects, object pairs, and relationships, incorporates mediator\nvariables, i.e., cooccurrence distribution, for complementing the causality.\nFollowing this, we propose the Causal Adjustment Module (CAModule) to estimate\nthe modeled causal structure, using variables from MCCM as inputs to produce a\nset of adjustment factors aimed at correcting biased model predictions.\nMoreover, our method enables the composition of zero-shot relationships,\nthereby enhancing the model's ability to recognize such relationships.\nExperiments conducted across various SGG backbones and popular benchmarks\ndemonstrate that CAModule achieves state-of-the-art mean recall rates, with\nsignificant improvements also observed on the challenging zero-shot recall rate\nmetric.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 8 tables, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.17862v1",
    "published_date": "2025-03-22 20:44:01 UTC",
    "updated_date": "2025-03-22 20:44:01 UTC"
  },
  {
    "arxiv_id": "2504.13859v1",
    "title": "DoYouTrustAI: A Tool to Teach Students About AI Misinformation and Prompt Engineering",
    "authors": [
      "Phillip Driscoll",
      "Priyanka Kumar"
    ],
    "abstract": "AI, especially Large Language Models (LLMs) like ChatGPT, have rapidly\ndeveloped and gained widespread adoption in the past five years, shifting user\npreference from traditional search engines. However, the generative nature of\nLLMs raises concerns about presenting misinformation as fact. To address this,\nwe developed a web-based application that helps K-12 students enhance critical\nthinking by identifying misleading information in LLM responses about major\nhistorical figures. In this paper, we describe the implementation and design\ndetails of the DoYouTrustAI tool, which can be used to provide an interactive\nlesson which teaches students about the dangers of misinformation and how\nbelievable generative AI can make it seem. The DoYouTrustAI tool utilizes\nprompt engineering to present the user with AI generated summaries about the\nlife of a historical figure. These summaries can be either accurate accounts of\nthat persons life, or an intentionally misleading alteration of their history.\nThe user is tasked with determining the validity of the statement without\nexternal resources. Our research questions for this work were:(RQ1) How can we\ndesign a tool that teaches students about the dangers of misleading information\nand of how misinformation can present itself in LLM responses? (RQ2) Can we\npresent prompt engineering as a topic that is easily understandable for\nstudents? Our findings highlight the need to correct misleading information\nbefore users retain it. Our tool lets users select familiar individuals for\ntesting to reduce random guessing and presents misinformation alongside known\nfacts to maintain believability. It also provides pre-configured prompt\ninstructions to show how different prompts affect AI responses. Together, these\nfeatures create a controlled environment where users learn the importance of\nverifying AI responses and understanding prompt engineering.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13859v1",
    "published_date": "2025-03-22 19:11:57 UTC",
    "updated_date": "2025-03-22 19:11:57 UTC"
  },
  {
    "arxiv_id": "2503.17842v1",
    "title": "Adapt, Agree, Aggregate: Semi-Supervised Ensemble Labeling for Graph Convolutional Networks",
    "authors": [
      "Maryam Abdolali",
      "Romina Zakerian",
      "Behnam Roshanfekr",
      "Fardin Ayar",
      "Mohammad Rahmati"
    ],
    "abstract": "In this paper, we propose a novel framework that combines ensemble learning\nwith augmented graph structures to improve the performance and robustness of\nsemi-supervised node classification in graphs. By creating multiple augmented\nviews of the same graph, our approach harnesses the \"wisdom of a diverse\ncrowd\", mitigating the challenges posed by noisy graph structures. Leveraging\nensemble learning allows us to simultaneously achieve three key goals: adaptive\nconfidence threshold selection based on model agreement, dynamic determination\nof the number of high-confidence samples for training, and robust extraction of\npseudo-labels to mitigate confirmation bias. Our approach uniquely integrates\nadaptive ensemble consensus to flexibly guide pseudo-label extraction and\nsample selection, reducing the risks of error accumulation and improving\nrobustness. Furthermore, the use of ensemble-driven consensus for\npseudo-labeling captures subtle patterns that individual models often overlook,\nenabling the model to generalize better. Experiments on several real-world\ndatasets demonstrate the effectiveness of our proposed method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17842v1",
    "published_date": "2025-03-22 19:10:54 UTC",
    "updated_date": "2025-03-22 19:10:54 UTC"
  },
  {
    "arxiv_id": "2503.17837v1",
    "title": "A Study on the Improvement of Code Generation Quality Using Large Language Models Leveraging Product Documentation",
    "authors": [
      "Takuro Morimoto",
      "Harumi Haraguchi"
    ],
    "abstract": "Research on using Large Language Models (LLMs) in system development is\nexpanding, especially in automated code and test generation. While E2E testing\nis vital for ensuring application quality, most test generation research has\nfocused on unit tests, with limited work on E2E test code. This study proposes\na method for automatically generating E2E test code from product documentation\nsuch as manuals, FAQs, and tutorials using LLMs with tailored prompts. The two\nstep process interprets documentation intent and produces executable test code.\nExperiments on a web app with six key features (e.g., authentication, profile,\ndiscussion) showed that tests generated from product documentation had high\ncompilation success and functional coverage, outperforming those based on\nrequirement specs and user stories. These findings highlight the potential of\nproduct documentation to improve E2E test quality and, by extension, software\nquality.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 5 figures and 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.17837v1",
    "published_date": "2025-03-22 18:42:05 UTC",
    "updated_date": "2025-03-22 18:42:05 UTC"
  },
  {
    "arxiv_id": "2503.17831v1",
    "title": "FundusGAN: A Hierarchical Feature-Aware Generative Framework for High-Fidelity Fundus Image Generation",
    "authors": [
      "Qingshan Hou",
      "Meng Wang",
      "Peng Cao",
      "Zou Ke",
      "Xiaoli Liu",
      "Huazhu Fu",
      "Osmar R. Zaiane"
    ],
    "abstract": "Recent advancements in ophthalmology foundation models such as RetFound have\ndemonstrated remarkable diagnostic capabilities but require massive datasets\nfor effective pre-training, creating significant barriers for development and\ndeployment. To address this critical challenge, we propose FundusGAN, a novel\nhierarchical feature-aware generative framework specifically designed for\nhigh-fidelity fundus image synthesis. Our approach leverages a Feature Pyramid\nNetwork within its encoder to comprehensively extract multi-scale information,\ncapturing both large anatomical structures and subtle pathological features.\nThe framework incorporates a modified StyleGAN-based generator with dilated\nconvolutions and strategic upsampling adjustments to preserve critical retinal\nstructures while enhancing pathological detail representation. Comprehensive\nevaluations on the DDR, DRIVE, and IDRiD datasets demonstrate that FundusGAN\nconsistently outperforms state-of-the-art methods across multiple metrics\n(SSIM: 0.8863, FID: 54.2, KID: 0.0436 on DDR). Furthermore, disease\nclassification experiments reveal that augmenting training data with\nFundusGAN-generated images significantly improves diagnostic accuracy across\nmultiple CNN architectures (up to 6.49\\% improvement with ResNet50). These\nresults establish FundusGAN as a valuable foundation model component that\neffectively addresses data scarcity challenges in ophthalmological AI research,\nenabling more robust and generalizable diagnostic systems while reducing\ndependency on large-scale clinical data collection.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17831v1",
    "published_date": "2025-03-22 18:08:07 UTC",
    "updated_date": "2025-03-22 18:08:07 UTC"
  },
  {
    "arxiv_id": "2503.17822v1",
    "title": "Metacognition in Content-Centric Computational Cognitive C4 Modeling",
    "authors": [
      "Sergei Nirenburg",
      "Marjorie McShane",
      "Sanjay Oruganti"
    ],
    "abstract": "For AI agents to emulate human behavior, they must be able to perceive,\nmeaningfully interpret, store, and use large amounts of information about the\nworld, themselves, and other agents. Metacognition is a necessary component of\nall of these processes. In this paper, we briefly a) introduce content-centric\ncomputational cognitive (C4) modeling for next-generation AI agents; b) review\nthe long history of developing C4 agents at RPI's LEIA (Language-Endowed\nIntelligent Agents) Lab; c) discuss our current work on extending LEIAs'\ncognitive capabilities to cognitive robotic applications developed using a\nneuro symbolic processing model; and d) sketch plans for future developments in\nthis paradigm that aim to overcome underappreciated limitations of currently\npopular, LLM-driven methods in AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "METACOG-25: 2nd Workshop on Metacognitive Prediction of AI Behavior",
    "pdf_url": "http://arxiv.org/pdf/2503.17822v1",
    "published_date": "2025-03-22 17:23:27 UTC",
    "updated_date": "2025-03-22 17:23:27 UTC"
  },
  {
    "arxiv_id": "2503.17821v1",
    "title": "OvercookedV2: Rethinking Overcooked for Zero-Shot Coordination",
    "authors": [
      "Tobias Gessler",
      "Tin Dizdarevic",
      "Ani Calinescu",
      "Benjamin Ellis",
      "Andrei Lupu",
      "Jakob Nicolaus Foerster"
    ],
    "abstract": "AI agents hold the potential to transform everyday life by helping humans\nachieve their goals. To do this successfully, agents need to be able to\ncoordinate with novel partners without prior interaction, a setting known as\nzero-shot coordination (ZSC). Overcooked has become one of the most popular\nbenchmarks for evaluating coordination capabilities of AI agents and learning\nalgorithms. In this work, we investigate the origins of ZSC challenges in\nOvercooked. We introduce a state augmentation mechanism which mixes states that\nmight be encountered when paired with unknown partners into the training\ndistribution, reducing the out-of-distribution challenge associated with ZSC.\nWe show that independently trained agents under this algorithm coordinate\nsuccessfully in Overcooked. Our results suggest that ZSC failure can largely be\nattributed to poor state coverage under self-play rather than more\nsophisticated coordination challenges. The Overcooked environment is therefore\nnot suitable as a ZSC benchmark. To address these shortcomings, we introduce\nOvercookedV2, a new version of the benchmark, which includes asymmetric\ninformation and stochasticity, facilitating the creation of interesting ZSC\nscenarios. To validate OvercookedV2, we conduct experiments demonstrating that\nmere exhaustive state coverage is insufficient to coordinate well. Finally, we\nuse OvercookedV2 to build a new range of coordination challenges, including\nones that require test time protocol formation, and we demonstrate the need for\nnew coordination algorithms that can adapt online. We hope that OvercookedV2\nwill help benchmark the next generation of ZSC algorithms and advance\ncollaboration between AI agents and humans.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17821v1",
    "published_date": "2025-03-22 17:14:24 UTC",
    "updated_date": "2025-03-22 17:14:24 UTC"
  },
  {
    "arxiv_id": "2504.03687v1",
    "title": "Process Optimization and Deployment for Sensor-Based Human Activity Recognition Based on Deep Learning",
    "authors": [
      "Hanyu Liu",
      "Ying Yu",
      "Hang Xiao",
      "Siyao Li",
      "Xuze Li",
      "Jiarui Li",
      "Haotian Tang"
    ],
    "abstract": "Sensor-based human activity recognition is a key technology for many\nhuman-centered intelligent applications. However, this research is still in its\ninfancy and faces many unresolved challenges. To address these, we propose a\ncomprehensive optimization process approach centered on multi-attention\ninteraction. We first utilize unsupervised statistical feature-guided diffusion\nmodels for highly adaptive data enhancement, and introduce a novel network\narchitecture-Multi-branch Spatiotemporal Interaction Network, which uses\nmulti-branch features at different levels to effectively Sequential ), which\nuses multi-branch features at different levels to effectively Sequential\nspatio-temporal interaction to enhance the ability to mine advanced latent\nfeatures. In addition, we adopt a multi-loss function fusion strategy in the\ntraining phase to dynamically adjust the fusion weights between batches to\noptimize the training results. Finally, we also conducted actual deployment on\nembedded devices to extensively test the practical feasibility of the proposed\nmethod in existing work. We conduct extensive testing on three public datasets,\nincluding ablation studies, comparisons of related work, and embedded\ndeployments.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03687v1",
    "published_date": "2025-03-22 16:48:16 UTC",
    "updated_date": "2025-03-22 16:48:16 UTC"
  },
  {
    "arxiv_id": "2503.17811v1",
    "title": "Feather-SQL: A Lightweight NL2SQL Framework with Dual-Model Collaboration Paradigm for Small Language Models",
    "authors": [
      "Wenqi Pei",
      "Hailing Xu",
      "Hengyuan Zhao",
      "Shizheng Hou",
      "Han Chen",
      "Zining Zhang",
      "Pingyi Luo",
      "Bingsheng He"
    ],
    "abstract": "Natural Language to SQL (NL2SQL) has seen significant advancements with large\nlanguage models (LLMs). However, these models often depend on closed-source\nsystems and high computational resources, posing challenges in data privacy and\ndeployment. In contrast, small language models (SLMs) struggle with NL2SQL\ntasks, exhibiting poor performance and incompatibility with existing\nframeworks. To address these issues, we introduce Feather-SQL, a new\nlightweight framework tailored for SLMs. Feather-SQL improves SQL executability\nand accuracy through 1) schema pruning and linking, 2) multi-path and\nmulti-candidate generation. Additionally, we introduce the 1+1 Model\nCollaboration Paradigm, which pairs a strong general-purpose chat model with a\nfine-tuned SQL specialist, combining strong analytical reasoning with\nhigh-precision SQL generation. Experimental results on BIRD demonstrate that\nFeather-SQL improves NL2SQL performance on SLMs, with around 10% boost for\nmodels without fine-tuning. The proposed paradigm raises the accuracy ceiling\nof SLMs to 54.76%, highlighting its effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17811v1",
    "published_date": "2025-03-22 16:22:53 UTC",
    "updated_date": "2025-03-22 16:22:53 UTC"
  },
  {
    "arxiv_id": "2503.17803v1",
    "title": "A Roadmap Towards Improving Multi-Agent Reinforcement Learning With Causal Discovery And Inference",
    "authors": [
      "Giovanni Briglia",
      "Stefano Mariani",
      "Franco Zambonelli"
    ],
    "abstract": "Causal reasoning is increasingly used in Reinforcement Learning (RL) to\nimprove the learning process in several dimensions: efficacy of learned\npolicies, efficiency of convergence, generalisation capabilities, safety and\ninterpretability of behaviour. However, applications of causal reasoning to\nMulti-Agent RL (MARL) are still mostly unexplored. In this paper, we take the\nfirst step in investigating the opportunities and challenges of applying causal\nreasoning in MARL. We measure the impact of a simple form of causal\naugmentation in state-of-the-art MARL scenarios increasingly requiring\ncooperation, and with state-of-the-art MARL algorithms exploiting various\ndegrees of collaboration between agents. Then, we discuss the positive as well\nas negative results achieved, giving us the chance to outline the areas where\nfurther research may help to successfully transfer causal RL to the multi-agent\nsetting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17803v1",
    "published_date": "2025-03-22 15:49:13 UTC",
    "updated_date": "2025-03-22 15:49:13 UTC"
  },
  {
    "arxiv_id": "2503.18975v1",
    "title": "Machine Learning - Driven Materials Discovery: Unlocking Next-Generation Functional Materials -- A minireview",
    "authors": [
      "Dilshod Nematov",
      "Mirabbos Hojamberdiev"
    ],
    "abstract": "The rapid advancement of machine learning and artificial intelligence\n(AI)-driven techniques is revolutionizing materials discovery, property\nprediction, and material design by minimizing human intervention and\naccelerating scientific progress. This review provides a comprehensive overview\nof smart, machine learning (ML)-driven approaches, emphasizing their role in\npredicting material properties, discovering novel compounds, and optimizing\nmaterial structures. Key methodologies ranging from deep learning, graph neural\nnetworks, and Bayesian optimization to automated generative models, such as\ngenerative adversarial networks (GANs) and variational autoencoders (VAEs)\nenable the autonomous design of materials with tailored functionalities. By\nleveraging AutoML frameworks (e.g., AutoGluon, TPOT, and H2O.ai), researchers\ncan automate the model selection, hyperparameter tuning, and feature\nengineering, significantly improving the efficiency of materials informatics.\nFurthermore, the integration of AI-driven robotic laboratories and\nhigh-throughput computing has established a fully automated pipeline for rapid\nsynthesis and experimental validation, drastically reducing the time and cost\nof material discovery. This review highlights real-world applications of\nautomated ML-driven approaches in predicting mechanical, thermal, electrical,\nand optical properties of materials, demonstrating successful cases in\nsuperconductors, catalysts, photovoltaics, and energy storage systems. We also\naddress key challenges, such as data quality, interpretability, and the\nintegration of AutoML with quantum computing, which are essential for future\nadvancements. Ultimately, the synergy between AI, automated experimentation,\nand computational modeling transforms the way the materials are discovered,\noptimized, and designed, paving the way for next-generation innovations in\nenergy, electronics, and nanotechnology.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18975v1",
    "published_date": "2025-03-22 15:24:38 UTC",
    "updated_date": "2025-03-22 15:24:38 UTC"
  },
  {
    "arxiv_id": "2503.17798v1",
    "title": "GaussianFocus: Constrained Attention Focus for 3D Gaussian Splatting",
    "authors": [
      "Zexu Huang",
      "Min Xu",
      "Stuart Perry"
    ],
    "abstract": "Recent developments in 3D reconstruction and neural rendering have\nsignificantly propelled the capabilities of photo-realistic 3D scene rendering\nacross various academic and industrial fields. The 3D Gaussian Splatting\ntechnique, alongside its derivatives, integrates the advantages of\nprimitive-based and volumetric representations to deliver top-tier rendering\nquality and efficiency. Despite these advancements, the method tends to\ngenerate excessive redundant noisy Gaussians overfitted to every training view,\nwhich degrades the rendering quality. Additionally, while 3D Gaussian Splatting\nexcels in small-scale and object-centric scenes, its application to larger\nscenes is hindered by constraints such as limited video memory, excessive\noptimization duration, and variable appearance across views. To address these\nchallenges, we introduce GaussianFocus, an innovative approach that\nincorporates a patch attention algorithm to refine rendering quality and\nimplements a Gaussian constraints strategy to minimize redundancy. Moreover, we\npropose a subdivision reconstruction strategy for large-scale scenes, dividing\nthem into smaller, manageable blocks for individual training. Our results\nindicate that GaussianFocus significantly reduces unnecessary Gaussians and\nenhances rendering quality, surpassing existing State-of-The-Art (SoTA)\nmethods. Furthermore, we demonstrate the capability of our approach to\neffectively manage and render large scenes, such as urban environments, whilst\nmaintaining high fidelity in the visual output.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17798v1",
    "published_date": "2025-03-22 15:18:23 UTC",
    "updated_date": "2025-03-22 15:18:23 UTC"
  },
  {
    "arxiv_id": "2503.17794v3",
    "title": "Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models",
    "authors": [
      "Ketan Suhaas Saichandran",
      "Xavier Thomas",
      "Prakhar Kaushik",
      "Deepti Ghadiyaram"
    ],
    "abstract": "Text-to-image generative models often struggle with long prompts detailing\ncomplex scenes, diverse objects with distinct visual characteristics and\nspatial relationships. In this work, we propose SCoPE (Scheduled interpolation\nof Coarse-to-fine Prompt Embeddings), a training-free method to improve\ntext-to-image alignment by progressively refining the input prompt in a\ncoarse-to-fine-grained manner. Given a detailed input prompt, we first\ndecompose it into multiple sub-prompts which evolve from describing broad scene\nlayout to highly intricate details. During inference, we interpolate between\nthese sub-prompts and thus progressively introduce finer-grained details into\nthe generated image. Our training-free plug-and-play approach significantly\nenhances prompt alignment, achieves an average improvement of up to +4% in\nVisual Question Answering (VQA) scores over the Stable Diffusion baselines on\n85% of the prompts from the GenAI-Bench dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17794v3",
    "published_date": "2025-03-22 15:05:21 UTC",
    "updated_date": "2025-04-26 02:34:31 UTC"
  },
  {
    "arxiv_id": "2503.17793v1",
    "title": "Every Sample Matters: Leveraging Mixture-of-Experts and High-Quality Data for Efficient and Accurate Code LLM",
    "authors": [
      "Codefuse",
      "Ling Team",
      ":",
      "Wenting Cai",
      "Yuchen Cao",
      "Chaoyu Chen",
      "Chen Chen",
      "Siba Chen",
      "Qing Cui",
      "Peng Di",
      "Junpeng Fang",
      "Zi Gong",
      "Ting Guo",
      "Zhengyu He",
      "Yang Huang",
      "Cong Li",
      "Jianguo Li",
      "Zheng Li",
      "Shijie Lian",
      "BingChang Liu",
      "Songshan Luo",
      "Shuo Mao",
      "Min Shen",
      "Jian Wu",
      "Jiaolong Yang",
      "Wenjie Yang",
      "Tong Ye",
      "Hang Yu",
      "Wei Zhang",
      "Zhenduo Zhang",
      "Hailin Zhao",
      "Xunjin Zheng",
      "Jun Zhou"
    ],
    "abstract": "Recent advancements in code large language models (LLMs) have demonstrated\nremarkable capabilities in code generation and understanding. It is still\nchallenging to build a code LLM with comprehensive performance yet ultimate\nefficiency. Many attempts have been released in the open source community to\nbreak the trade-off between performance and efficiency, such as the Qwen Coder\nseries and the DeepSeek Coder series. This paper introduces yet another attempt\nin this area, namely Ling-Coder-Lite. We leverage the efficient\nMixture-of-Experts (MoE) architecture along with a set of high-quality data\ncuration methods (especially those based on program analytics) to build an\nefficient yet powerful code LLM. Ling-Coder-Lite exhibits on-par performance on\n12 representative coding benchmarks compared to state-of-the-art models of\nsimilar size, such as Qwen2.5-Coder-7B and DeepSeek-Coder-V2-Lite, while\noffering competitive latency and throughput. In practice, we achieve a 50\\%\nreduction in deployment resources compared to the similar-sized dense model\nwithout performance loss. To facilitate further research and development in\nthis area, we open-source our models as well as a substantial portion of\nhigh-quality data for the annealing and post-training stages. The models and\ndata can be accessed\nat~\\url{https://huggingface.co/inclusionAI/Ling-Coder-lite}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.17793v1",
    "published_date": "2025-03-22 15:00:18 UTC",
    "updated_date": "2025-03-22 15:00:18 UTC"
  },
  {
    "arxiv_id": "2503.17788v1",
    "title": "Aligning Foundation Model Priors and Diffusion-Based Hand Interactions for Occlusion-Resistant Two-Hand Reconstruction",
    "authors": [
      "Gaoge Han",
      "Yongkang Cheng",
      "Zhe Chen",
      "Shaoli Huang",
      "Tongliang Liu"
    ],
    "abstract": "Two-hand reconstruction from monocular images faces persistent challenges due\nto complex and dynamic hand postures and occlusions, causing significant\ndifficulty in achieving plausible interaction alignment. Existing approaches\nstruggle with such alignment issues, often resulting in misalignment and\npenetration artifacts. To tackle this, we propose a novel framework that\nattempts to precisely align hand poses and interactions by synergistically\nintegrating foundation model-driven 2D priors with diffusion-based interaction\nrefinement for occlusion-resistant two-hand reconstruction. First, we introduce\na Fusion Alignment Encoder that learns to align fused multimodal priors\nkeypoints, segmentation maps, and depth cues from foundation models during\ntraining. This provides robust structured guidance, further enabling efficient\ninference without foundation models at test time while maintaining high\nreconstruction accuracy. Second, we employ a two-hand diffusion model\nexplicitly trained to transform interpenetrated poses into plausible,\nnon-penetrated interactions, leveraging gradient-guided denoising to correct\nartifacts and ensure realistic spatial relations. Extensive evaluations\ndemonstrate that our method achieves state-of-the-art performance on\nInterHand2.6M, FreiHAND, and HIC datasets, significantly advancing occlusion\nhandling and interaction robustness.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17788v1",
    "published_date": "2025-03-22 14:42:27 UTC",
    "updated_date": "2025-03-22 14:42:27 UTC"
  },
  {
    "arxiv_id": "2503.17784v1",
    "title": "MEPNet: Medical Entity-balanced Prompting Network for Brain CT Report Generation",
    "authors": [
      "Xiaodan Zhang",
      "Yanzhao Shi",
      "Junzhong Ji",
      "Chengxin Zheng",
      "Liangqiong Qu"
    ],
    "abstract": "The automatic generation of brain CT reports has gained widespread attention,\ngiven its potential to assist radiologists in diagnosing cranial diseases.\nHowever, brain CT scans involve extensive medical entities, such as diverse\nanatomy regions and lesions, exhibiting highly inconsistent spatial patterns in\n3D volumetric space. This leads to biased learning of medical entities in\nexisting methods, resulting in repetitiveness and inaccuracy in generated\nreports. To this end, we propose a Medical Entity-balanced Prompting Network\n(MEPNet), which harnesses the large language model (LLM) to fairly interpret\nvarious entities for accurate brain CT report generation. By introducing the\nvisual embedding and the learning status of medical entities as enriched clues,\nour method prompts the LLM to balance the learning of diverse entities, thereby\nenhancing reports with comprehensive findings. First, to extract visual\nembedding of entities, we propose Knowledge-driven Joint Attention to explore\nand distill entity patterns using both explicit and implicit medical knowledge.\nThen, a Learning Status Scorer is designed to evaluate the learning of entity\nvisual embeddings, resulting in unique learning status for individual entities.\nFinally, these entity visual embeddings and status are elaborately integrated\ninto multi-modal prompts, to guide the text generation of LLM. This process\nallows LLM to self-adapt the learning process for biased-fitted entities,\nthereby covering detailed findings in generated reports. We conduct experiments\non two brain CT report generation benchmarks, showing the effectiveness in\nclinical accuracy and text coherence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI 2025 Oral Paper",
    "pdf_url": "http://arxiv.org/pdf/2503.17784v1",
    "published_date": "2025-03-22 14:31:30 UTC",
    "updated_date": "2025-03-22 14:31:30 UTC"
  },
  {
    "arxiv_id": "2503.17783v1",
    "title": "Energy-Aware LLMs: A step towards sustainable AI for downstream applications",
    "authors": [
      "Nguyen Phuc Tran",
      "Brigitte Jaumard",
      "Oscar Delgado"
    ],
    "abstract": "Advanced Large Language Models (LLMs) have revolutionized various fields,\nincluding communication networks, sparking an innovation wave that has led to\nnew applications and services, and significantly enhanced solution schemes.\nDespite all these impressive developments, most LLMs typically require huge\ncomputational resources, resulting in terribly high energy consumption. Thus,\nthis research study proposes an end-to-end pipeline that investigates the\ntrade-off between energy efficiency and model performance for an LLM during\nfault ticket analysis in communication networks. It further evaluates the\npipeline performance using two real-world datasets for the tasks of root cause\nanalysis and response feedback in a communication network. Our results show\nthat an appropriate combination of quantization and pruning techniques is able\nto reduce energy consumption while significantly improving model performance.",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.PF",
    "comment": "This work has been submitted to V. International Conference on\n  Electrical, Computer and Energy Technologies (ICECET 2025) for possible\n  publication",
    "pdf_url": "http://arxiv.org/pdf/2503.17783v1",
    "published_date": "2025-03-22 14:28:29 UTC",
    "updated_date": "2025-03-22 14:28:29 UTC"
  },
  {
    "arxiv_id": "2504.03686v2",
    "title": "Revisiting Outage for Edge Inference Systems",
    "authors": [
      "Zhanwei Wang",
      "Qunsong Zeng",
      "Haotian Zheng",
      "Kaibin Huang"
    ],
    "abstract": "One of the key missions of sixth-generation (6G) mobile networks is to deploy\nlarge-scale artificial intelligence (AI) models at the network edge to provide\nremote-inference services for edge devices. The resultant platform, known as\nedge inference, will support a wide range of Internet-of-Things applications,\nsuch as autonomous driving, industrial automation, and augmented reality. Given\nthe mission-critical and time-sensitive nature of these tasks, it is essential\nto design edge inference systems that are both reliable and capable of meeting\nstringent end-to-end (E2E) latency constraints. Existing studies, which\nprimarily focus on communication reliability as characterized by channel outage\nprobability, may fail to guarantee E2E performance, specifically in terms of\nE2E inference accuracy and latency. To address this limitation, we propose a\ntheoretical framework that introduces and mathematically characterizes the\ninference outage (InfOut) probability, which quantifies the likelihood that the\nE2E inference accuracy falls below a target threshold. Under an E2E latency\nconstraint, this framework establishes a fundamental tradeoff between\ncommunication overhead (i.e., uploading more sensor observations) and inference\nreliability as quantified by the InfOut probability. To find a tractable way to\noptimize this tradeoff, we derive accurate surrogate functions for InfOut\nprobability by applying a Gaussian approximation to the distribution of the\nreceived discriminant gain. Experimental results demonstrate the superiority of\nthe proposed design over conventional communication-centric approaches in terms\nof E2E inference reliability.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03686v2",
    "published_date": "2025-03-22 13:10:27 UTC",
    "updated_date": "2025-04-28 06:14:26 UTC"
  },
  {
    "arxiv_id": "2503.17763v1",
    "title": "Lifelong Evolution of Swarms",
    "authors": [
      "Lorenzo Leuzzi",
      "Simon Jones",
      "Sabine Hauert",
      "Davide Bacciu",
      "Andrea Cossu"
    ],
    "abstract": "Adapting to task changes without forgetting previous knowledge is a key skill\nfor intelligent systems, and a crucial aspect of lifelong learning. Swarm\ncontrollers, however, are typically designed for specific tasks, lacking the\nability to retain knowledge across changing tasks. Lifelong learning, on the\nother hand, focuses on individual agents with limited insights into the\nemergent abilities of a collective like a swarm. To address this gap, we\nintroduce a lifelong evolutionary framework for swarms, where a population of\nswarm controllers is evolved in a dynamic environment that incrementally\npresents novel tasks. This requires evolution to find controllers that quickly\nadapt to new tasks while retaining knowledge of previous ones, as they may\nreappear in the future. We discover that the population inherently preserves\ninformation about previous tasks, and it can reuse it to foster adaptation and\nmitigate forgetting. In contrast, the top-performing individual for a given\ntask catastrophically forgets previous tasks. To mitigate this phenomenon, we\ndesign a regularization process for the evolutionary algorithm, reducing\nforgetting in top-performing individuals. Evolving swarms in a lifelong fashion\nraises fundamental questions on the current state of deep lifelong learning and\non the robustness of swarm controllers in dynamic environments.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted as full paper at GECCO 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.17763v1",
    "published_date": "2025-03-22 13:08:31 UTC",
    "updated_date": "2025-03-22 13:08:31 UTC"
  },
  {
    "arxiv_id": "2503.17760v1",
    "title": "CODA: Repurposing Continuous VAEs for Discrete Tokenization",
    "authors": [
      "Zeyu Liu",
      "Zanlin Ni",
      "Yeguo Hua",
      "Xin Deng",
      "Xiao Ma",
      "Cheng Zhong",
      "Gao Huang"
    ],
    "abstract": "Discrete visual tokenizers transform images into a sequence of tokens,\nenabling token-based visual generation akin to language models. However, this\nprocess is inherently challenging, as it requires both compressing visual\nsignals into a compact representation and discretizing them into a fixed set of\ncodes. Traditional discrete tokenizers typically learn the two tasks jointly,\noften leading to unstable training, low codebook utilization, and limited\nreconstruction quality. In this paper, we introduce\n\\textbf{CODA}(\\textbf{CO}ntinuous-to-\\textbf{D}iscrete \\textbf{A}daptation), a\nframework that decouples compression and discretization. Instead of training\ndiscrete tokenizers from scratch, CODA adapts off-the-shelf continuous VAEs --\nalready optimized for perceptual compression -- into discrete tokenizers via a\ncarefully designed discretization process. By primarily focusing on\ndiscretization, CODA ensures stable and efficient training while retaining the\nstrong visual fidelity of continuous VAEs. Empirically, with $\\mathbf{6\n\\times}$ less training budget than standard VQGAN, our approach achieves a\nremarkable codebook utilization of 100% and notable reconstruction FID (rFID)\nof $\\mathbf{0.43}$ and $\\mathbf{1.34}$ for $8 \\times$ and $16 \\times$\ncompression on ImageNet 256$\\times$ 256 benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://lzy-tony.github.io/coda",
    "pdf_url": "http://arxiv.org/pdf/2503.17760v1",
    "published_date": "2025-03-22 12:59:00 UTC",
    "updated_date": "2025-03-22 12:59:00 UTC"
  },
  {
    "arxiv_id": "2503.17756v1",
    "title": "Bandwidth Reservation for Time-Critical Vehicular Applications: A Multi-Operator Environment",
    "authors": [
      "Abdullah Al-Khatib",
      "Abdullah Ahmed",
      "Klaus Moessner",
      "Holger Timinger"
    ],
    "abstract": "Onsite bandwidth reservation requests often face challenges such as price\nfluctuations and fairness issues due to unpredictable bandwidth availability\nand stringent latency requirements. Requesting bandwidth in advance can\nmitigate the impact of these fluctuations and ensure timely access to critical\nresources. In a multi-Mobile Network Operator (MNO) environment, vehicles need\nto select cost-effective and reliable resources for their safety-critical\napplications. This research aims to minimize resource costs by finding the best\nprice among multiple MNOs. It formulates multi-operator scenarios as a Markov\nDecision Process (MDP), utilizing a Deep Reinforcement Learning (DRL)\nalgorithm, specifically Dueling Deep Q-Learning. For efficient and stable\nlearning, we propose a novel area-wise approach and an adaptive MDP synthetic\nclose to the real environment. The Temporal Fusion Transformer (TFT) is used to\nhandle time-dependent data and model training. Furthermore, the research\nleverages Amazon spot price data and adopts a multi-phase training approach,\ninvolving initial training on synthetic data, followed by real-world data.\nThese phases enable the DRL agent to make informed decisions using insights\nfrom historical data and real-time observations. The results show that our\nmodel leads to significant cost reductions, up to 40%, compared to scenarios\nwithout a policy model in such a complex environment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.17756v1",
    "published_date": "2025-03-22 12:36:23 UTC",
    "updated_date": "2025-03-22 12:36:23 UTC"
  },
  {
    "arxiv_id": "2503.17753v1",
    "title": "Building Resource-Constrained Language Agents: A Korean Case Study on Chemical Toxicity Information",
    "authors": [
      "Hojun Cho",
      "Donghu Kim",
      "Soyoung Yang",
      "Chan Lee",
      "Hunjoo Lee",
      "Jaegul Choo"
    ],
    "abstract": "Language agents powered by large language models (LLMs) face significant\ndeployment challenges in resource-constrained environments, particularly for\nspecialized domains and less-common languages. This paper presents Tox-chat, a\nKorean chemical toxicity information agent devised within these limitations. We\npropose two key innovations: a context-efficient architecture that reduces\ntoken consumption through hierarchical section search, and a scenario-based\ndialogue generation methodology that effectively distills tool-using\ncapabilities from larger models. Experimental evaluations demonstrate that our\nfine-tuned 8B parameter model substantially outperforms both untuned models and\nbaseline approaches, in terms of DB faithfulness and preference. Our work\noffers valuable insights for researchers developing domain-specific language\nagents under practical constraints.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.17753v1",
    "published_date": "2025-03-22 12:34:15 UTC",
    "updated_date": "2025-03-22 12:34:15 UTC"
  },
  {
    "arxiv_id": "2503.17736v1",
    "title": "V2P-Bench: Evaluating Video-Language Understanding with Visual Prompts for Better Human-Model Interaction",
    "authors": [
      "Yiming Zhao",
      "Yu Zeng",
      "Yukun Qi",
      "YaoYang Liu",
      "Lin Chen",
      "Zehui Chen",
      "Xikun Bao",
      "Jie Zhao",
      "Feng Zhao"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have made significant progress in the\nfield of video understanding recently. However, current benchmarks uniformly\nlean on text prompts for evaluation, which often necessitate complex\nreferential language and fail to provide precise spatial and temporal\nreferences. This limitation diminishes the experience and efficiency of\nhuman-model interaction. To address this limitation, we propose the Video\nVisual Prompt Benchmark(V2P-Bench), a comprehensive benchmark specifically\ndesigned to evaluate LVLMs' video understanding capabilities in multimodal\nhuman-model interaction scenarios. V2P-Bench includes 980 unique videos and\n1,172 QA pairs, covering 5 main tasks and 12 dimensions, facilitating\ninstance-level fine-grained understanding aligned with human cognition.\nBenchmarking results reveal that even the most powerful models perform poorly\non V2P-Bench (65.4% for GPT-4o and 67.9% for Gemini-1.5-Pro), significantly\nlower than the human experts' 88.3%, highlighting the current shortcomings of\nLVLMs in understanding video visual prompts. We hope V2P-Bench will serve as a\nfoundation for advancing multimodal human-model interaction and video\nunderstanding evaluation. Project page:\nhttps://github.com/gaotiexinqu/V2P-Bench.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17736v1",
    "published_date": "2025-03-22 11:30:46 UTC",
    "updated_date": "2025-03-22 11:30:46 UTC"
  },
  {
    "arxiv_id": "2503.17730v1",
    "title": "Aportes para el cumplimiento del Reglamento (UE) 2024/1689 en robótica y sistemas autónomos",
    "authors": [
      "Francisco J. Rodríguez Lera",
      "Yoana Pita Lorenzo",
      "David Sobrín Hidalgo",
      "Laura Fernández Becerra",
      "Irene González Fernández",
      "Jose Miguel Guerrero Hernández"
    ],
    "abstract": "Cybersecurity in robotics stands out as a key aspect within Regulation (EU)\n2024/1689, also known as the Artificial Intelligence Act, which establishes\nspecific guidelines for intelligent and automated systems. A fundamental\ndistinction in this regulatory framework is the difference between robots with\nArtificial Intelligence (AI) and those that operate through automation systems\nwithout AI, since the former are subject to stricter security requirements due\nto their learning and autonomy capabilities. This work analyzes cybersecurity\ntools applicable to advanced robotic systems, with special emphasis on the\nprotection of knowledge bases in cognitive architectures. Furthermore, a list\nof basic tools is proposed to guarantee the security, integrity, and resilience\nof these systems, and a practical case is presented, focused on the analysis of\nrobot knowledge management, where ten evaluation criteria are defined to ensure\ncompliance with the regulation and reduce risks in human-robot interaction\n(HRI) environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 1 figure, in Spanish",
    "pdf_url": "http://arxiv.org/pdf/2503.17730v1",
    "published_date": "2025-03-22 11:04:42 UTC",
    "updated_date": "2025-03-22 11:04:42 UTC"
  },
  {
    "arxiv_id": "2503.17728v1",
    "title": "DynASyn: Multi-Subject Personalization Enabling Dynamic Action Synthesis",
    "authors": [
      "Yongjin Choi",
      "Chanhun Park",
      "Seung Jun Baek"
    ],
    "abstract": "Recent advances in text-to-image diffusion models spurred research on\npersonalization, i.e., a customized image synthesis, of subjects within\nreference images. Although existing personalization methods are able to alter\nthe subjects' positions or to personalize multiple subjects simultaneously,\nthey often struggle to modify the behaviors of subjects or their dynamic\ninteractions. The difficulty is attributable to overfitting to reference\nimages, which worsens if only a single reference image is available. We propose\nDynASyn, an effective multi-subject personalization from a single reference\nimage addressing these challenges. DynASyn preserves the subject identity in\nthe personalization process by aligning concept-based priors with subject\nappearances and actions. This is achieved by regularizing the attention maps\nbetween the subject token and images through concept-based priors. In addition,\nwe propose concept-based prompt-and-image augmentation for an enhanced\ntrade-off between identity preservation and action diversity. We adopt an\nSDE-based editing guided by augmented prompts to generate diverse appearances\nand actions while maintaining identity consistency in the augmented images.\nExperiments show that DynASyn is capable of synthesizing highly realistic\nimages of subjects with novel contexts and dynamic interactions with the\nsurroundings, and outperforms baseline methods in both quantitative and\nqualitative aspects.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.17728v1",
    "published_date": "2025-03-22 10:56:35 UTC",
    "updated_date": "2025-03-22 10:56:35 UTC"
  },
  {
    "arxiv_id": "2503.17726v1",
    "title": "A Survey on Mathematical Reasoning and Optimization with Large Language Models",
    "authors": [
      "Ali Forootani"
    ],
    "abstract": "Mathematical reasoning and optimization are fundamental to artificial\nintelligence and computational problem-solving. Recent advancements in Large\nLanguage Models (LLMs) have significantly improved AI-driven mathematical\nreasoning, theorem proving, and optimization techniques. This survey explores\nthe evolution of mathematical problem-solving in AI, from early statistical\nlearning approaches to modern deep learning and transformer-based\nmethodologies. We review the capabilities of pretrained language models and\nLLMs in performing arithmetic operations, complex reasoning, theorem proving,\nand structured symbolic computation. A key focus is on how LLMs integrate with\noptimization and control frameworks, including mixed-integer programming,\nlinear quadratic control, and multi-agent optimization strategies. We examine\nhow LLMs assist in problem formulation, constraint generation, and heuristic\nsearch, bridging theoretical reasoning with practical applications. We also\ndiscuss enhancement techniques such as Chain-of-Thought reasoning, instruction\ntuning, and tool-augmented methods that improve LLM's problem-solving\nperformance. Despite their progress, LLMs face challenges in numerical\nprecision, logical consistency, and proof verification. Emerging trends such as\nhybrid neural-symbolic reasoning, structured prompt engineering, and multi-step\nself-correction aim to overcome these limitations. Future research should focus\non interpretability, integration with domain-specific solvers, and improving\nthe robustness of AI-driven decision-making. This survey offers a comprehensive\nreview of the current landscape and future directions of mathematical reasoning\nand optimization with LLMs, with applications across engineering, finance, and\nscientific research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17726v1",
    "published_date": "2025-03-22 10:49:32 UTC",
    "updated_date": "2025-03-22 10:49:32 UTC"
  },
  {
    "arxiv_id": "2503.17724v1",
    "title": "Towards Invisible Backdoor Attack on Text-to-Image Diffusion Model",
    "authors": [
      "Jie Zhang",
      "Zhongqi Wang",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "abstract": "Backdoor attacks targeting text-to-image diffusion models have advanced\nrapidly, enabling attackers to implant malicious triggers into these models to\nmanipulate their outputs. However, current backdoor samples often exhibit two\nkey abnormalities compared to benign samples: 1) Semantic Consistency, where\nbackdoor prompts tend to generate images with similar semantic content even\nwith significant textual variations to the prompts; 2) Attention Consistency,\nwhere the trigger induces consistent structural responses in the\ncross-attention maps. These consistencies leave detectable traces for\ndefenders, making backdoors easier to identify. To enhance the stealthiness of\nbackdoor samples, we propose a novel Invisible Backdoor Attack (IBA) by\nexplicitly mitigating these consistencies. Specifically, our approach leverages\nsyntactic structures as backdoor triggers to amplify the sensitivity to textual\nvariations, effectively breaking down the semantic consistency. Besides, a\nregularization method based on Kernel Maximum Mean Discrepancy (KMMD) is\nproposed to align the distribution of cross-attention responses between\nbackdoor and benign samples, thereby disrupting attention consistency.\nExtensive experiments demonstrate that our IBA achieves a 97.5% attack success\nrate while exhibiting stronger resistance to defenses, with an average of over\n98% backdoor samples bypassing three state-of-the-art detection mechanisms. The\ncode is available at https://github.com/Robin-WZQ/IBA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17724v1",
    "published_date": "2025-03-22 10:41:46 UTC",
    "updated_date": "2025-03-22 10:41:46 UTC"
  },
  {
    "arxiv_id": "2504.13858v1",
    "title": "The Effect of Explainable AI-based Decision Support on Human Task Performance: A Meta-Analysis",
    "authors": [
      "Felix Haag"
    ],
    "abstract": "The desirable properties of explanations in information systems have fueled\nthe demands for transparency in artificial intelligence (AI) outputs. To\naddress these demands, the field of explainable AI (XAI) has put forth methods\nthat can support human decision-making by explaining AI outputs. However,\ncurrent empirical works present inconsistent findings on whether such\nexplanations help to improve users' task performance in decision support\nsystems (DSS). In this paper, we conduct a meta-analysis to explore how XAI\naffects human performance in classification tasks. Our results show an\nimprovement in task performance through XAI-based decision support, though\nexplanations themselves are not the decisive driver for this improvement. The\nanalysis reveals that the studies' risk of bias moderates the effect of\nexplanations in AI, while the explanation type appears to play only a\nnegligible role. Our findings contribute to the human computer interaction\nfield by enhancing the understanding of human-XAI collaboration in DSS.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Published in the Proceedings of the Twenty-Third Annual Pre-ICIS\n  Workshop on HCI Research in MIS, Bangkok, Thailand, December 15th, 2024",
    "pdf_url": "http://arxiv.org/pdf/2504.13858v1",
    "published_date": "2025-03-22 10:38:43 UTC",
    "updated_date": "2025-03-22 10:38:43 UTC"
  },
  {
    "arxiv_id": "2503.17712v1",
    "title": "Multi-modality Anomaly Segmentation on the Road",
    "authors": [
      "Heng Gao",
      "Zhuolin He",
      "Shoumeng Qiu",
      "Xiangyang Xue",
      "Jian Pu"
    ],
    "abstract": "Semantic segmentation allows autonomous driving cars to understand the\nsurroundings of the vehicle comprehensively. However, it is also crucial for\nthe model to detect obstacles that may jeopardize the safety of autonomous\ndriving systems. Based on our experiments, we find that current uni-modal\nanomaly segmentation frameworks tend to produce high anomaly scores for\nnon-anomalous regions in images. Motivated by this empirical finding, we\ndevelop a multi-modal uncertainty-based anomaly segmentation framework, named\nMMRAS+, for autonomous driving systems. MMRAS+ effectively reduces the high\nanomaly outputs of non-anomalous classes by introducing text-modal using the\nCLIP text encoder. Indeed, MMRAS+ is the first multi-modal anomaly segmentation\nsolution for autonomous driving. Moreover, we develop an ensemble module to\nfurther boost the anomaly segmentation performance. Experiments on RoadAnomaly,\nSMIYC, and Fishyscapes validation datasets demonstrate the superior performance\nof our method. The code is available in\nhttps://github.com/HengGao12/MMRAS_plus.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17712v1",
    "published_date": "2025-03-22 09:55:42 UTC",
    "updated_date": "2025-03-22 09:55:42 UTC"
  },
  {
    "arxiv_id": "2503.17710v1",
    "title": "Slide2Text: Leveraging LLMs for Personalized Textbook Generation from PowerPoint Presentations",
    "authors": [
      "Yizhou Zhou"
    ],
    "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\neducational technology, enabling innovative approaches to automated and\npersonalized content creation. This paper introduces Slide2Text, a system that\nleverages LLMs to transform PowerPoint presentations into customized textbooks.\nBy extracting slide content using OCR, organizing it into a coherent structure,\nand generating tailored materials such as explanations, exercises, and\nreferences, Slide2Text streamlines the textbook creation process. Flexible\ncustomization options further enhance its adaptability to diverse educational\nneeds. The system highlights the potential of LLMs in modernizing textbook\ncreation and improving educational accessibility. Future developments will\nexplore multimedia inputs and advanced user customization features.",
    "categories": [
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17710v1",
    "published_date": "2025-03-22 09:42:03 UTC",
    "updated_date": "2025-03-22 09:42:03 UTC"
  },
  {
    "arxiv_id": "2503.17709v1",
    "title": "GUI-Xplore: Empowering Generalizable GUI Agents with One Exploration",
    "authors": [
      "Yuchen Sun",
      "Shanhui Zhao",
      "Tao Yu",
      "Hao Wen",
      "Samith Va",
      "Mengwei Xu",
      "Yuanchun Li",
      "Chongyang Zhang"
    ],
    "abstract": "GUI agents hold significant potential to enhance the experience and\nefficiency of human-device interaction. However, current methods face\nchallenges in generalizing across applications (apps) and tasks, primarily due\nto two fundamental limitations in existing datasets. First, these datasets\noverlook developer-induced structural variations among apps, limiting the\ntransferability of knowledge across diverse software environments. Second, many\nof them focus solely on navigation tasks, which restricts their capacity to\nrepresent comprehensive software architectures and complex user interactions.\nTo address these challenges, we introduce GUI-Xplore, a dataset meticulously\ndesigned to enhance cross-application and cross-task generalization via an\nexploration-and-reasoning framework. GUI-Xplore integrates pre-recorded\nexploration videos providing contextual insights, alongside five hierarchically\nstructured downstream tasks designed to comprehensively evaluate GUI agent\ncapabilities. To fully exploit GUI-Xplore's unique features, we propose\nXplore-Agent, a GUI agent framework that combines Action-aware GUI Modeling\nwith Graph-Guided Environment Reasoning. Further experiments indicate that\nXplore-Agent achieves a 10% improvement over existing methods in unfamiliar\nenvironments, yet there remains significant potential for further enhancement\ntowards truly generalizable GUI agents.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.17709v1",
    "published_date": "2025-03-22 09:30:37 UTC",
    "updated_date": "2025-03-22 09:30:37 UTC"
  },
  {
    "arxiv_id": "2503.17704v1",
    "title": "PT-PINNs: A Parametric Engineering Turbulence Solver based on Physics-Informed Neural Networks",
    "authors": [
      "Liang Jiang",
      "Yuzhou Cheng",
      "Kun Luo",
      "Jianren Fan"
    ],
    "abstract": "Physics-informed neural networks (PINNs) demonstrate promising potential in\nparameterized engineering turbulence optimization problems but face challenges,\nsuch as high data requirements and low computational accuracy when applied to\nengineering turbulence problems. This study proposes a framework that enhances\nthe ability of PINNs to solve parametric turbulence problems without training\ndatasets from experiments or CFD-Parametric Turbulence PINNs (PT-PINNs)). Two\nkey methods are introduced to improve the accuracy and robustness of this\nframework. The first is a soft constraint method for turbulent viscosity\ncalculation. The second is a pre-training method based on the conservation of\nflow rate in the flow field. The effectiveness of PT-PINNs is validated using a\nthree-dimensional backward-facing step (BFS) turbulence problem with two\nvarying parameters (Re = 3000-200000, ER = 1.1-1.5). PT-PINNs produce\npredictions that closely match experimental data and computational fluid\ndynamics (CFD) results across various conditions. Moreover, PT-PINNs offer a\ncomputational efficiency advantage over traditional CFD methods. The total time\nrequired to construct the parametric BFS turbulence model is 39 hours,\none-sixteenth of the time required by traditional numerical methods. The\ninference time for a single-condition prediction is just 40 seconds-only 0.5%\nof a single CFD computation. These findings highlight the potential of PT-PINNs\nfor future applications in engineering turbulence optimization problems.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17704v1",
    "published_date": "2025-03-22 09:10:53 UTC",
    "updated_date": "2025-03-22 09:10:53 UTC"
  },
  {
    "arxiv_id": "2503.17702v1",
    "title": "On the (im)possibility of sustainable artificial intelligence. Why it does not make sense to move faster when heading the wrong way",
    "authors": [
      "Rainer Rehak"
    ],
    "abstract": "Artificial intelligence (AI) is currently considered a sustainability\n\"game-changer\" within and outside of academia. In order to discuss sustainable\nAI this article draws from insights by critical data and algorithm studies,\nSTS, transformative sustainability science, critical computer science, and\npublic interest theory. I argue that while there are indeed many\nsustainability-related use cases for AI, they are likely to have more overall\ndrawbacks than benefits. To substantiate this claim, I differentiate three 'AI\nmaterialities' of the AI supply chain: first the literal materiality (e.g.\nwater, cobalt, lithium, energy consumption etc.), second, the informational\nmateriality (e.g. lots of data and centralised control necessary), and third,\nthe social materiality (e.g. exploitative data work, communities harm by waste\nand pollution). In all materialities, effects are especially devastating for\nthe global south while benefiting the global north. A second strong claim\nregarding sustainable AI circles around so called apolitical optimisation (e.g.\nregarding city traffic), however the optimisation criteria (e.g. cars, bikes,\nemissions, commute time, health) are purely political and have to be\ncollectively negotiated before applying AI optimisation. Hence, sustainable AI,\nin principle, cannot break the glass ceiling of transformation and might even\ndistract from necessary societal change. To address that I propose to stop\n'unformation gathering' and to apply the 'small is beautiful' principle. This\naims to contribute to an informed academic and collective negotiation on how to\n(not) integrate AI into the sustainability project while avoiding to reproduce\nthe status quo by serving hegemonic interests between useful AI use cases,\ntechno-utopian salvation narratives, technology-centred efficiency paradigms,\nthe exploitative and extractivist character of AI and concepts of digital\ndegrowth.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "68T99",
      "K.4; I.2; H.4"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.17702v1",
    "published_date": "2025-03-22 09:01:15 UTC",
    "updated_date": "2025-03-22 09:01:15 UTC"
  },
  {
    "arxiv_id": "2503.17688v1",
    "title": "Intelligence Sequencing and the Path-Dependence of Intelligence Evolution: AGI-First vs. DCI-First as Irreversible Attractors",
    "authors": [
      "Andy E. Williams"
    ],
    "abstract": "The trajectory of intelligence evolution is often framed around the emergence\nof artificial general intelligence (AGI) and its alignment with human values.\nThis paper challenges that framing by introducing the concept of intelligence\nsequencing: the idea that the order in which AGI and decentralized collective\nintelligence (DCI) emerge determines the long-term attractor basin of\nintelligence. Using insights from dynamical systems, evolutionary game theory,\nand network models, it argues that intelligence follows a path-dependent,\nirreversible trajectory. Once development enters a centralized (AGI-first) or\ndecentralized (DCI-first) regime, transitions become structurally infeasible\ndue to feedback loops and resource lock-in. Intelligence attractors are modeled\nin functional state space as the co-navigation of conceptual and adaptive\nfitness spaces. Early-phase structuring constrains later dynamics, much like\nrenormalization in physics. This has major implications for AI safety:\ntraditional alignment assumes AGI will emerge and must be controlled after the\nfact, but this paper argues that intelligence sequencing is more foundational.\nIf AGI-first architectures dominate before DCI reaches critical mass,\nhierarchical monopolization and existential risk become locked in. If DCI-first\nemerges, intelligence stabilizes around decentralized cooperative equilibrium.\nThe paper further explores whether intelligence structurally biases itself\ntoward an attractor based on its self-modeling method -- externally imposed\naxioms (favoring AGI) vs. recursive internal visualization (favoring DCI).\nFinally, it proposes methods to test this theory via simulations, historical\nlock-in case studies, and intelligence network analysis. The findings suggest\nthat intelligence sequencing is a civilizational tipping point: determining\nwhether the future is shaped by unbounded competition or unbounded cooperation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17688v1",
    "published_date": "2025-03-22 08:09:04 UTC",
    "updated_date": "2025-03-22 08:09:04 UTC"
  },
  {
    "arxiv_id": "2503.17684v1",
    "title": "Can LLMs Automate Fact-Checking Article Writing?",
    "authors": [
      "Dhruv Sahnan",
      "David Corney",
      "Irene Larraz",
      "Giovanni Zagni",
      "Ruben Miguez",
      "Zhuohan Xie",
      "Iryna Gurevych",
      "Elizabeth Churchill",
      "Tanmoy Chakraborty",
      "Preslav Nakov"
    ],
    "abstract": "Automatic fact-checking aims to support professional fact-checkers by\noffering tools that can help speed up manual fact-checking. Yet, existing\nframeworks fail to address the key step of producing output suitable for\nbroader dissemination to the general public: while human fact-checkers\ncommunicate their findings through fact-checking articles, automated systems\ntypically produce little or no justification for their assessments. Here, we\naim to bridge this gap. We argue for the need to extend the typical automatic\nfact-checking pipeline with automatic generation of full fact-checking\narticles. We first identify key desiderata for such articles through a series\nof interviews with experts from leading fact-checking organizations. We then\ndevelop QRAFT, an LLM-based agentic framework that mimics the writing workflow\nof human fact-checkers. Finally, we assess the practical usefulness of QRAFT\nthrough human evaluations with professional fact-checkers. Our evaluation shows\nthat while QRAFT outperforms several previously proposed text-generation\napproaches, it lags considerably behind expert-written articles. We hope that\nour work will enable further research in this new and important direction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 4 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.17684v1",
    "published_date": "2025-03-22 07:56:50 UTC",
    "updated_date": "2025-03-22 07:56:50 UTC"
  },
  {
    "arxiv_id": "2503.17682v2",
    "title": "Safe RLHF-V: Safe Reinforcement Learning from Multi-modal Human Feedback",
    "authors": [
      "Jiaming Ji",
      "Xinyu Chen",
      "Rui Pan",
      "Conghui Zhang",
      "Han Zhu",
      "Jiahao Li",
      "Donghai Hong",
      "Boyuan Chen",
      "Jiayi Zhou",
      "Kaile Wang",
      "Juntao Dai",
      "Chi-Min Chan",
      "Yida Tang",
      "Sirui Han",
      "Yike Guo",
      "Yaodong Yang"
    ],
    "abstract": "Multimodal large language models (MLLMs) are essential for building\ngeneral-purpose AI assistants; however, they pose increasing safety risks. How\ncan we ensure safety alignment of MLLMs to prevent undesired behaviors? Going\nfurther, it is critical to explore how to fine-tune MLLMs to preserve\ncapabilities while meeting safety constraints. Fundamentally, this challenge\ncan be formulated as a min-max optimization problem. However, existing datasets\nhave not yet disentangled single preference signals into explicit safety\nconstraints, hindering systematic investigation in this direction. Moreover, it\nremains an open question whether such constraints can be effectively\nincorporated into the optimization process for multi-modal models. In this\nwork, we present the first exploration of the Safe RLHF-V -- the first\nmultimodal safety alignment framework. The framework consists of:\n$\\mathbf{(I)}$ BeaverTails-V, the first open-source dataset featuring dual\npreference annotations for helpfulness and safety, supplemented with\nmulti-level safety labels (minor, moderate, severe); $\\mathbf{(II)}$\nBeaver-Guard-V, a multi-level guardrail system to proactively defend against\nunsafe queries and adversarial attacks. Applying the guard model over five\nrounds of filtering and regeneration significantly enhances the precursor\nmodel's overall safety by an average of 40.9%. $\\mathbf{(III)}$ Based on dual\npreference, we initiate the first exploration of multi-modal safety alignment\nwithin a constrained optimization. Experimental results demonstrate that Safe\nRLHF effectively improves both model helpfulness and safety. Specifically, Safe\nRLHF-V enhances model safety by 34.2% and helpfulness by 34.3%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17682v2",
    "published_date": "2025-03-22 07:40:20 UTC",
    "updated_date": "2025-05-22 15:42:20 UTC"
  },
  {
    "arxiv_id": "2503.17671v1",
    "title": "ComfyGPT: A Self-Optimizing Multi-Agent System for Comprehensive ComfyUI Workflow Generation",
    "authors": [
      "Oucheng Huang",
      "Yuhang Ma",
      "Zeng Zhao",
      "Mingrui Wu",
      "Jiayi Ji",
      "Rongsheng Zhang",
      "Zhipeng Hu",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "abstract": "ComfyUI provides a widely-adopted, workflow-based interface that enables\nusers to customize various image generation tasks through an intuitive\nnode-based architecture. However, the intricate connections between nodes and\ndiverse modules often present a steep learning curve for users. In this paper,\nwe introduce ComfyGPT, the first self-optimizing multi-agent system designed to\ngenerate ComfyUI workflows based on task descriptions automatically. ComfyGPT\ncomprises four specialized agents: ReformatAgent, FlowAgent, RefineAgent, and\nExecuteAgent. The core innovation of ComfyGPT lies in two key aspects. First,\nit focuses on generating individual node links rather than entire workflows,\nsignificantly improving generation precision. Second, we proposed FlowAgent, a\nLLM-based workflow generation agent that uses both supervised fine-tuning (SFT)\nand reinforcement learning (RL) to improve workflow generation accuracy.\nMoreover, we introduce FlowDataset, a large-scale dataset containing 13,571\nworkflow-description pairs, and FlowBench, a comprehensive benchmark for\nevaluating workflow generation systems. We also propose four novel evaluation\nmetrics: Format Validation (FV), Pass Accuracy (PA), Pass Instruct Alignment\n(PIA), and Pass Node Diversity (PND). Experimental results demonstrate that\nComfyGPT significantly outperforms existing LLM-based methods in workflow\ngeneration.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17671v1",
    "published_date": "2025-03-22 06:48:50 UTC",
    "updated_date": "2025-03-22 06:48:50 UTC"
  },
  {
    "arxiv_id": "2503.17661v2",
    "title": "A Qualitative Study of User Perception of M365 AI Copilot",
    "authors": [
      "Muneera Bano",
      "Didar Zowghi",
      "Jon Whittle",
      "Liming Zhu",
      "Andrew Reeson",
      "Rob Martin",
      "Jen Parsons"
    ],
    "abstract": "Adopting AI copilots in professional workflows presents opportunities for\nenhanced productivity, efficiency, and decision making. In this paper, we\npresent results from a six month trial of M365 Copilot conducted at our\norganisation in 2024. A qualitative interview study was carried out with 27\nparticipants. The study explored user perceptions of M365 Copilot's\neffectiveness, productivity impact, evolving expectations, ethical concerns,\nand overall satisfaction. Initial enthusiasm for the tool was met with mixed\npost trial experiences. While some users found M365 Copilot beneficial for\ntasks such as email coaching, meeting summaries, and content retrieval, others\nreported unmet expectations in areas requiring deeper contextual understanding,\nreasoning, and integration with existing workflows. Ethical concerns were a\nrecurring theme, with users highlighting issues related to data privacy,\ntransparency, and AI bias. While M365 Copilot demonstrated value in specific\noperational areas, its broader impact remained constrained by usability\nlimitations and the need for human oversight to validate AI generated outputs.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17661v2",
    "published_date": "2025-03-22 06:11:10 UTC",
    "updated_date": "2025-03-30 01:08:08 UTC"
  },
  {
    "arxiv_id": "2503.17656v3",
    "title": "NaFM: Pre-training a Foundation Model for Small-Molecule Natural Products",
    "authors": [
      "Yuheng Ding",
      "Bo Qiang",
      "Yiran Zhou",
      "Jie Yu",
      "Qi Li",
      "Liangren Zhang",
      "Yusong Wang",
      "Zhenmin Liu"
    ],
    "abstract": "Natural products, as metabolites from microorganisms, animals, or plants,\nexhibit diverse biological activities, making them crucial for drug discovery.\nNowadays, existing deep learning methods for natural products research\nprimarily rely on supervised learning approaches designed for specific\ndownstream tasks. However, such one-model-for-a-task paradigm often lacks\ngeneralizability and leaves significant room for performance improvement.\nAdditionally, existing molecular characterization methods are not well-suited\nfor the unique tasks associated with natural products. To address these\nlimitations, we have pre-trained a foundation model for natural products based\non their unique properties. Our approach employs a novel pretraining strategy\nthat is especially tailored to natural products. By incorporating contrastive\nlearning and masked graph learning objectives, we emphasize evolutional\ninformation from molecular scaffolds while capturing side-chain information.\nOur framework achieves state-of-the-art (SOTA) results in various downstream\ntasks related to natural product mining and drug discovery. We first compare\ntaxonomy classification with synthesized molecule-focused baselines to\ndemonstrate that current models are inadequate for understanding natural\nsynthesis. Furthermore, by diving into a fine-grained analysis at both the gene\nand microbial levels, NaFM demonstrates the ability to capture evolutionary\ninformation. Eventually, our method is experimented with virtual screening,\nillustrating informative natural product representations that can lead to more\neffective identification of potential drug candidates.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17656v3",
    "published_date": "2025-03-22 05:32:03 UTC",
    "updated_date": "2025-05-18 12:50:42 UTC"
  },
  {
    "arxiv_id": "2503.18973v1",
    "title": "Automated diagnosis of lung diseases using vision transformer: a comparative study on chest x-ray classification",
    "authors": [
      "Muhammad Ahmad",
      "Sardar Usman",
      "Ildar Batyrshin",
      "Muhammad Muzammil",
      "K. Sajid",
      "M. Hasnain",
      "Muhammad Jalal",
      "Grigori Sidorov"
    ],
    "abstract": "Background: Lung disease is a significant health issue, particularly in\nchildren and elderly individuals. It often results from lung infections and is\none of the leading causes of mortality in children. Globally, lung-related\ndiseases claim many lives each year, making early and accurate diagnoses\ncrucial. Radiographs are valuable tools for the diagnosis of such conditions.\nThe most prevalent lung diseases, including pneumonia, asthma, allergies,\nchronic obstructive pulmonary disease (COPD), bronchitis, emphysema, and lung\ncancer, represent significant public health challenges. Early prediction of\nthese conditions is critical, as it allows for the identification of risk\nfactors and implementation of preventive measures to reduce the likelihood of\ndisease onset\n  Methods: In this study, we utilized a dataset comprising 3,475 chest X-ray\nimages sourced from from Mendeley Data provided by Talukder, M. A. (2023) [14],\ncategorized into three classes: normal, lung opacity, and pneumonia. We applied\nfive pre-trained deep learning models, including CNN, ResNet50, DenseNet,\nCheXNet, and U-Net, as well as two transfer learning algorithms such as Vision\nTransformer (ViT) and Shifted Window (Swin) to classify these images. This\napproach aims to address diagnostic issues in lung abnormalities by reducing\nreliance on human intervention through automated classification systems. Our\nanalysis was conducted in both binary and multiclass settings. Results: In the\nbinary classification, we focused on distinguishing between normal and viral\npneumonia cases, whereas in the multi-class classification, all three classes\n(normal, lung opacity, and viral pneumonia) were included. Our proposed\nmethodology (ViT) achieved remarkable performance, with accuracy rates of 99%\nfor binary classification and 95.25% for multiclass classification.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.18973v1",
    "published_date": "2025-03-22 04:35:17 UTC",
    "updated_date": "2025-03-22 04:35:17 UTC"
  },
  {
    "arxiv_id": "2503.17645v1",
    "title": "A Modular Dataset to Demonstrate LLM Abstraction Capability",
    "authors": [
      "Adam Atanas",
      "Kai Liu"
    ],
    "abstract": "Large language models (LLMs) exhibit impressive capabilities but struggle\nwith reasoning errors due to hallucinations and flawed logic. To investigate\ntheir internal representations of reasoning, we introduce ArrangementPuzzle, a\nnovel puzzle dataset with structured solutions and automated stepwise\ncorrectness verification. We trained a classifier model on LLM activations on\nthis dataset and found that it achieved over 80% accuracy in predicting\nreasoning correctness, implying that LLMs internally distinguish between\ncorrect and incorrect reasoning steps, with the strongest representations in\nmiddle-late Transformer layers. Further analysis reveals that LLMs encode\nabstract reasoning concepts within the middle activation layers of the\ntransformer architecture, distinguishing logical from semantic equivalence.\nThese findings provide insights into LLM reasoning mechanisms and contribute to\nimproving AI reliability and interpretability, thereby offering the possibility\nto manipulate and refine LLM reasoning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figures. Submitted to ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.17645v1",
    "published_date": "2025-03-22 04:25:30 UTC",
    "updated_date": "2025-03-22 04:25:30 UTC"
  },
  {
    "arxiv_id": "2503.17644v1",
    "title": "On The Sample Complexity Bounds In Bilevel Reinforcement Learning",
    "authors": [
      "Mudit Gaur",
      "Amrit Singh Bedi",
      "Raghu Pasupathu",
      "Vaneet Aggarwal"
    ],
    "abstract": "Bilevel reinforcement learning (BRL) has emerged as a powerful mathematical\nframework for studying generative AI alignment and related problems. While\nseveral principled algorithmic frameworks have been proposed, key theoretical\nfoundations, particularly those related to sample complexity, remain\nunderexplored. Understanding and deriving tight sample complexity bounds are\ncrucial for bridging the gap between theory and practice, guiding the\ndevelopment of more efficient algorithms. In this work, we present the first\nsample complexity result for BRL, achieving a bound of $\\epsilon^{-4}$. This\nresult extends to standard bilevel optimization problems, providing an\ninteresting theoretical contribution with practical implications. To address\nthe computational challenges associated with hypergradient estimation in\nbilevel optimization, we develop a first-order Hessian-free algorithm that does\nnot rely on costly hypergradient computations. By leveraging matrix-free\ntechniques and constrained optimization methods, our approach ensures\nscalability and practicality. Our findings pave the way for improved methods in\nAI alignment and other fields reliant on bilevel optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17644v1",
    "published_date": "2025-03-22 04:22:04 UTC",
    "updated_date": "2025-03-22 04:22:04 UTC"
  },
  {
    "arxiv_id": "2503.17640v1",
    "title": "On the Hopf-Cole Transform for Control-affine Schrödinger Bridge",
    "authors": [
      "Alexis Teter",
      "Abhishek Halder"
    ],
    "abstract": "The purpose of this note is to clarify the importance of the relation\n$\\boldsymbol{gg}^{\\top}\\propto \\boldsymbol{\\sigma\\sigma}^{\\top}$ in solving\ncontrol-affine Schr\\\"{o}dinger bridge problems via the Hopf-Cole transform,\nwhere $\\boldsymbol{g},\\boldsymbol{\\sigma}$ are the control and noise\ncoefficients, respectively. We show that the Hopf-Cole transform applied to the\nconditions of optimality for generic control-affine Schr\\\"{o}dinger bridge\nproblems, i.e., without the assumption\n$\\boldsymbol{gg}^{\\top}\\propto\\boldsymbol{\\sigma\\sigma}^{\\top}$, gives a pair\nof forward-backward PDEs that are neither linear nor equation-level decoupled.\nWe explain how the resulting PDEs can be interpreted as nonlinear\nforward-backward advection-diffusion-reaction equations, where the nonlinearity\nstem from additional drift and reaction terms involving the gradient of the\nlog-likelihood a.k.a. the score. These additional drift and reaction vanish\nwhen $\\boldsymbol{gg}^{\\top}\\propto\\boldsymbol{\\sigma\\sigma}^{\\top}$, and the\nresulting boundary-coupled system of linear PDEs can then be solved by dynamic\nSinkhorn recursions. A key takeaway of our work is that the numerical solution\nof the generic control-affine Schr\\\"{o}dinger bridge requires further\nalgorithmic development, possibly generalizing the dynamic Sinkhorn recursion\nor otherwise.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17640v1",
    "published_date": "2025-03-22 04:08:10 UTC",
    "updated_date": "2025-03-22 04:08:10 UTC"
  },
  {
    "arxiv_id": "2503.17632v1",
    "title": "FairFlow: Mitigating Dataset Biases through Undecided Learning",
    "authors": [
      "Jiali Cheng",
      "Hadi Amiri"
    ],
    "abstract": "Language models are prone to dataset biases, known as shortcuts and spurious\ncorrelations in data, which often result in performance drop on new data. We\npresent a new debiasing framework called ``FairFlow'' that mitigates dataset\nbiases by learning to be undecided in its predictions for data samples or\nrepresentations associated with known or unknown biases. The framework\nintroduces two key components: a suite of data and model perturbation\noperations that generate different biased views of input samples, and a\ncontrastive objective that learns debiased and robust representations from the\nresulting biased views of samples. Experiments show that FairFlow outperforms\nexisting debiasing methods, particularly against out-of-domain and hard test\nsamples without compromising the in-domain performance",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.17632v1",
    "published_date": "2025-03-22 03:35:51 UTC",
    "updated_date": "2025-03-22 03:35:51 UTC"
  },
  {
    "arxiv_id": "2503.18971v1",
    "title": "LLMs as Planning Modelers: A Survey for Leveraging Large Language Models to Construct Automated Planning Models",
    "authors": [
      "Marcus Tantakoun",
      "Xiaodan Zhu",
      "Christian Muise"
    ],
    "abstract": "Large Language Models (LLMs) excel in various natural language tasks but\noften struggle with long-horizon planning problems requiring structured\nreasoning. This limitation has drawn interest in integrating neuro-symbolic\napproaches within the Automated Planning (AP) and Natural Language Processing\n(NLP) communities. However, identifying optimal AP deployment frameworks can be\ndaunting. This paper aims to provide a timely survey of the current research\nwith an in-depth analysis, positioning LLMs as tools for extracting and\nrefining planning models to support reliable AP planners. By systematically\nreviewing the current state of research, we highlight methodologies, and\nidentify critical challenges and future directions, hoping to contribute to the\njoint research on NLP and Automated Planning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 3 figures, 3 appendices",
    "pdf_url": "http://arxiv.org/pdf/2503.18971v1",
    "published_date": "2025-03-22 03:35:44 UTC",
    "updated_date": "2025-03-22 03:35:44 UTC"
  },
  {
    "arxiv_id": "2503.21795v1",
    "title": "Threshold Adaptation in Spiking Networks Enables Shortest Path Finding and Place Disambiguation",
    "authors": [
      "Robin Dietrich",
      "Tobias Fischer",
      "Nicolai Waniek",
      "Nico Reeb",
      "Michael Milford",
      "Alois Knoll",
      "Adam D. Hines"
    ],
    "abstract": "Efficient spatial navigation is a hallmark of the mammalian brain, inspiring\nthe development of neuromorphic systems that mimic biological principles.\nDespite progress, implementing key operations like back-tracing and handling\nambiguity in bio-inspired spiking neural networks remains an open challenge.\nThis work proposes a mechanism for activity back-tracing in arbitrary,\nuni-directional spiking neuron graphs. We extend the existing replay mechanism\nof the spiking hierarchical temporal memory (S-HTM) by our spike\ntiming-dependent threshold adaptation (STDTA), which enables us to perform path\nplanning in networks of spiking neurons. We further present an ambiguity\ndependent threshold adaptation (ADTA) for identifying places in an environment\nwith less ambiguity, enhancing the localization estimate of an agent. Combined,\nthese methods enable efficient identification of the shortest path to an\nunambiguous target. Our experiments show that a network trained on sequences\nreliably computes shortest paths with fewer replays than the steps required to\nreach the target. We further show that we can identify places with reduced\nambiguity in multiple, similar environments. These contributions advance the\npractical application of biologically inspired sequential learning algorithms\nlike the S-HTM towards neuromorphic localization and navigation.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.NE",
    "comment": "Appears in the proceedings of the 2025 Neuro Inspired Computational\n  Elements Conference (NICE)",
    "pdf_url": "http://arxiv.org/pdf/2503.21795v1",
    "published_date": "2025-03-22 03:18:44 UTC",
    "updated_date": "2025-03-22 03:18:44 UTC"
  },
  {
    "arxiv_id": "2503.17626v1",
    "title": "Transferable Latent-to-Latent Locomotion Policy for Efficient and Versatile Motion Control of Diverse Legged Robots",
    "authors": [
      "Ziang Zheng",
      "Guojian Zhan",
      "Bin Shuai",
      "Shengtao Qin",
      "Jiangtao Li",
      "Tao Zhang",
      "Shengbo Eben Li"
    ],
    "abstract": "Reinforcement learning (RL) has demonstrated remarkable capability in\nacquiring robot skills, but learning each new skill still requires substantial\ndata collection for training. The pretrain-and-finetune paradigm offers a\npromising approach for efficiently adapting to new robot entities and tasks.\nInspired by the idea that acquired knowledge can accelerate learning new tasks\nwith the same robot and help a new robot master a trained task, we propose a\nlatent training framework where a transferable latent-to-latent locomotion\npolicy is pretrained alongside diverse task-specific observation encoders and\naction decoders. This policy in latent space processes encoded latent\nobservations to generate latent actions to be decoded, with the potential to\nlearn general abstract motion skills. To retain essential information for\ndecision-making and control, we introduce a diffusion recovery module that\nminimizes information reconstruction loss during pretrain stage. During\nfine-tune stage, the pretrained latent-to-latent locomotion policy remains\nfixed, while only the lightweight task-specific encoder and decoder are\noptimized for efficient adaptation. Our method allows a robot to leverage its\nown prior experience across different tasks as well as the experience of other\nmorphologically diverse robots to accelerate adaptation. We validate our\napproach through extensive simulations and real-world experiments,\ndemonstrating that the pretrained latent-to-latent locomotion policy\neffectively generalizes to new robot entities and tasks with improved\nefficiency.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17626v1",
    "published_date": "2025-03-22 03:01:25 UTC",
    "updated_date": "2025-03-22 03:01:25 UTC"
  },
  {
    "arxiv_id": "2503.17625v1",
    "title": "AI-Based Screening for Depression and Social Anxiety Through Eye Tracking: An Exploratory Study",
    "authors": [
      "Karol Chlasta",
      "Katarzyna Wisiecka",
      "Krzysztof Krejtz",
      "Izabela Krejtz"
    ],
    "abstract": "Well-being is a dynamic construct that evolves over time and fluctuates\nwithin individuals, presenting challenges for accurate quantification. Reduced\nwell-being is often linked to depression or anxiety disorders, which are\ncharacterised by biases in visual attention towards specific stimuli, such as\nhuman faces. This paper introduces a novel approach to AI-assisted screening of\naffective disorders by analysing visual attention scan paths using\nconvolutional neural networks (CNNs). Data were collected from two studies\nexamining (1) attentional tendencies in individuals diagnosed with major\ndepression and (2) social anxiety. These data were processed using residual\nCNNs through images generated from eye-gaze patterns. Experimental results,\nobtained with ResNet architectures, demonstrated an average accuracy of 48% for\na three-class system and 62% for a two-class system. Based on these exploratory\nfindings, we propose that this method could be employed in rapid, ecological,\nand effective mental health screening systems to assess well-being through\neye-tracking.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG",
      "68U01",
      "J.3; I.2; I.5; H.4; C.3"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.17625v1",
    "published_date": "2025-03-22 02:53:02 UTC",
    "updated_date": "2025-03-22 02:53:02 UTC"
  },
  {
    "arxiv_id": "2503.17623v1",
    "title": "Unraveling Pedestrian Fatality Patterns: A Comparative Study with Explainable AI",
    "authors": [
      "Methusela Sulle",
      "Judith Mwakalonge",
      "Gurcan Comert",
      "Saidi Siuhi",
      "Nana Kankam Gyimah"
    ],
    "abstract": "Road fatalities pose significant public safety and health challenges\nworldwide, with pedestrians being particularly vulnerable in vehicle-pedestrian\ncrashes due to disparities in physical and performance characteristics. This\nstudy employs explainable artificial intelligence (XAI) to identify key factors\ncontributing to pedestrian fatalities across the five U.S. states with the\nhighest crash rates (2018-2022). It compares them to the five states with the\nlowest fatality rates. Using data from the Fatality Analysis Reporting System\n(FARS), the study applies machine learning techniques-including Decision Trees,\nGradient Boosting Trees, Random Forests, and XGBoost-to predict contributing\nfactors to pedestrian fatalities. To address data imbalance, the Synthetic\nMinority Over-sampling Technique (SMOTE) is utilized, while SHapley Additive\nExplanations (SHAP) values enhance model interpretability. The results indicate\nthat age, alcohol and drug use, location, and environmental conditions are\nsignificant predictors of pedestrian fatalities. The XGBoost model outperformed\nothers, achieving a balanced accuracy of 98 %, accuracy of 90 %, precision of\n92 %, recall of 90 %, and an F1 score of 91 %. Findings reveal that pedestrian\nfatalities are more common in mid-block locations and areas with poor\nvisibility, with older adults and substance-impaired individuals at higher\nrisk. These insights can inform policymakers and urban planners in implementing\ntargeted safety measures, such as improved lighting, enhanced pedestrian\ninfrastructure, and stricter traffic law enforcement, to reduce fatalities and\nimprove public safety.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.17623v1",
    "published_date": "2025-03-22 02:44:41 UTC",
    "updated_date": "2025-03-22 02:44:41 UTC"
  },
  {
    "arxiv_id": "2504.07114v1",
    "title": "ChatBench: From Static Benchmarks to Human-AI Evaluation",
    "authors": [
      "Serina Chang",
      "Ashton Anderson",
      "Jake M. Hofman"
    ],
    "abstract": "With the rapid adoption of LLM-based chatbots, there is a pressing need to\nevaluate what humans and LLMs can achieve together. However, standard\nbenchmarks, such as MMLU, measure LLM capabilities in isolation (i.e.,\n\"AI-alone\"). Here, we design and conduct a user study to convert MMLU questions\ninto user-AI conversations, by seeding the user with the question and having\nthem carry out a conversation with the LLM to answer their question. We release\nChatBench, a new dataset with AI-alone, user-alone, and user-AI data for 396\nquestions and two LLMs, including 144K answers and 7,336 user-AI conversations.\nWe find that AI-alone accuracy fails to predict user-AI accuracy, with\nsignificant differences across multiple subjects (math, physics, and moral\nreasoning), and we analyze the user-AI conversations to provide insight into\nhow they diverge from AI-alone benchmarks. Finally, we show that fine-tuning a\nuser simulator on a subset of ChatBench improves its ability to estimate\nuser-AI accuracies, increasing correlation on held-out questions by more than\n20 points, creating possibilities for scaling interactive evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07114v1",
    "published_date": "2025-03-22 01:21:40 UTC",
    "updated_date": "2025-03-22 01:21:40 UTC"
  },
  {
    "arxiv_id": "2503.17604v4",
    "title": "OmniScience: A Domain-Specialized LLM for Scientific Reasoning and Discovery",
    "authors": [
      "Vignesh Prabhakar",
      "Md Amirul Islam",
      "Adam Atanas",
      "Yao-Ting Wang",
      "Joah Han",
      "Aastha Jhunjhunwala",
      "Rucha Apte",
      "Robert Clark",
      "Kang Xu",
      "Zihan Wang",
      "Kai Liu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in\nadvancing scientific knowledge and addressing complex challenges. In this work,\nwe introduce OmniScience, a specialized large reasoning model for general\nscience, developed through three key components: (1) domain adaptive\npretraining on a carefully curated corpus of scientific literature, (2)\ninstruction tuning on a specialized dataset to guide the model in following\ndomain-specific tasks, and (3) reasoning-based knowledge distillation through\nfine-tuning to significantly enhance its ability to generate contextually\nrelevant and logically sound responses. We demonstrate the versatility of\nOmniScience by developing a battery agent that efficiently ranks molecules as\npotential electrolyte solvents or additives. Comprehensive evaluations reveal\nthat OmniScience is competitive with state-of-the-art large reasoning models on\nthe GPQA Diamond and domain-specific battery benchmarks, while outperforming\nall public reasoning and non-reasoning models with similar parameter counts. We\nfurther demonstrate via ablation experiments that domain adaptive pretraining\nand reasoning-based knowledge distillation are critical to attain our\nperformance levels, across benchmarks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17604v4",
    "published_date": "2025-03-22 01:18:59 UTC",
    "updated_date": "2025-04-22 20:31:48 UTC"
  },
  {
    "arxiv_id": "2503.17603v1",
    "title": "A Generative Caching System for Large Language Models",
    "authors": [
      "Arun Iyengar",
      "Ashish Kundu",
      "Ramana Kompella",
      "Sai Nandan Mamidi"
    ],
    "abstract": "Caching has the potential to be of significant benefit for accessing large\nlanguage models (LLMs) due to their high latencies which typically range from a\nsmall number of seconds to well over a minute. Furthermore, many LLMs charge\nmoney for queries; caching thus has a clear monetary benefit. This paper\npresents a new caching system for improving user experiences with LLMs. In\naddition to reducing both latencies and monetary costs for accessing LLMs, our\nsystem also provides important features that go beyond the performance benefits\ntypically associated with caches. A key feature we provide is generative\ncaching, wherein multiple cached responses can be synthesized to provide\nanswers to queries which have never been seen before. Our generative caches\nfunction as repositories of valuable information which can be mined and\nanalyzed. We also improve upon past semantic caching techniques by tailoring\nthe caching algorithms to optimally balance cost and latency reduction with the\nquality of responses provided. Performance tests indicate that our caches are\nconsiderably faster than GPTcache.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.DC",
      "cs.NI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17603v1",
    "published_date": "2025-03-22 01:17:56 UTC",
    "updated_date": "2025-03-22 01:17:56 UTC"
  },
  {
    "arxiv_id": "2503.17599v2",
    "title": "Evaluating Clinical Competencies of Large Language Models with a General Practice Benchmark",
    "authors": [
      "Zheqing Li",
      "Yiying Yang",
      "Jiping Lang",
      "Wenhao Jiang",
      "Yuhang Zhao",
      "Shuang Li",
      "Dingqian Wang",
      "Zhu Lin",
      "Xuanna Li",
      "Yuze Tang",
      "Jiexian Qiu",
      "Xiaolin Lu",
      "Hongji Yu",
      "Shuang Chen",
      "Yuhua Bi",
      "Xiaofei Zeng",
      "Yixian Chen",
      "Junrong Chen",
      "Lin Yao"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated considerable potential in\ngeneral practice. However, existing benchmarks and evaluation frameworks\nprimarily depend on exam-style or simplified question-answer formats, lacking a\ncompetency-based structure aligned with the real-world clinical\nresponsibilities encountered in general practice. Consequently, the extent to\nwhich LLMs can reliably fulfill the duties of general practitioners (GPs)\nremains uncertain. In this work, we propose a novel evaluation framework to\nassess the capability of LLMs to function as GPs. Based on this framework, we\nintroduce a general practice benchmark (GPBench), whose data are meticulously\nannotated by domain experts in accordance with routine clinical practice\nstandards. We evaluate ten state-of-the-art LLMs and analyze their\ncompetencies. Our findings indicate that current LLMs are not yet ready for\ndeployment in such settings without human oversight, and further optimization\nspecifically tailored to the daily responsibilities of GPs is essential.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17599v2",
    "published_date": "2025-03-22 01:02:44 UTC",
    "updated_date": "2025-05-14 10:25:11 UTC"
  },
  {
    "arxiv_id": "2503.17587v1",
    "title": "ConSol: Sequential Probability Ratio Testing to Find Consistent LLM Reasoning Paths Efficiently",
    "authors": [
      "Jaeyeon Lee",
      "Guantong Qi",
      "Matthew Brady Neeley",
      "Zhandong Liu",
      "Hyun-Hwan Jeong"
    ],
    "abstract": "Recent advancements in large language models (LLMs) integrating explicit\nreasoning, such as OpenAI's o3-mini, DeepSeek-R1, and QWQ-32B, enable smaller\nmodels to solve complex tasks by generating intermediate reasoning steps prior\nto providing answers. However, this approach significantly increases\ncomputational costs, both monetarily and environmentally. The widely-used\nself-consistency method further exacerbates these costs by aggregating multiple\nreasoning paths to improve accuracy, often requiring between 40 to 64 samples\nper task. Although aggregation effectively reduces variance and bias,\nadditional sampling can lead to diminishing returns when early samples yield\nconsistent results. To address inefficiencies, we propose leveraging Sequential\nProbability Ratio Testing (SPRT) to dynamically terminate sampling once\nsufficient consistency is achieved. We calibrate SPRT parameters specifically\nfor LLM applications, accounting for sensitivity to detect the mode of the\ndistribution. Our experiments demonstrate that incorporating SPRT significantly\nenhances token efficiency, achieving comparable accuracy to self-consistency\nmethods but at a substantially reduced computational cost. To promote\ntransparency and facilitate reproducibility, we have made the source code and\ndatasets used in our experiments publicly available at our GitHub repository:\nhttps://github.com/LiuzLab/consol, or available as a PyPI package: pip install\nconsol. We hope that this resource will support further research and encourage\nthe development of new methods building upon our work.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17587v1",
    "published_date": "2025-03-22 00:07:28 UTC",
    "updated_date": "2025-03-22 00:07:28 UTC"
  }
]