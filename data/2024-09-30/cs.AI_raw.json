[
  {
    "arxiv_id": "2410.00933v1",
    "title": "StreamEnsemble: Predictive Queries over Spatiotemporal Streaming Data",
    "authors": [
      "Anderson Chaves",
      "Eduardo Ogasawara",
      "Patrick Valduriez",
      "Fabio Porto"
    ],
    "abstract": "Predictive queries over spatiotemporal (ST) stream data pose significant data\nprocessing and analysis challenges. ST data streams involve a set of time\nseries whose data distributions may vary in space and time, exhibiting multiple\ndistinct patterns. In this context, assuming a single machine learning model\nwould adequately handle such variations is likely to lead to failure. To\naddress this challenge, we propose StreamEnsemble, a novel approach to\npredictive queries over ST data that dynamically selects and allocates Machine\nLearning models according to the underlying time series distributions and model\ncharacteristics. Our experimental evaluation reveals that this method markedly\noutperforms traditional ensemble methods and single model approaches in terms\nof accuracy and time, demonstrating a significant reduction in prediction error\nof more than 10 times compared to traditional approaches.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.00933v1",
    "published_date": "2024-09-30 23:50:16 UTC",
    "updated_date": "2024-09-30 23:50:16 UTC"
  },
  {
    "arxiv_id": "2410.00275v2",
    "title": "On Large Uni- and Multi-modal Models for Unsupervised Classification of Social Media Images: Nature's Contribution to People as a case study",
    "authors": [
      "Rohaifa Khaldi",
      "Domingo Alcaraz-Segura",
      "Ignacio SÃ¡nchez-Herrera",
      "Javier Martinez-Lopez",
      "Carlos Javier Navarro",
      "Siham Tabik"
    ],
    "abstract": "Social media images have proven to be a valuable source of information for\nunderstanding human interactions with important subjects such as cultural\nheritage, biodiversity, and nature, among others. The task of grouping such\nimages into a number of semantically meaningful clusters without labels is\nchallenging due to the high diversity and complex nature of the visual content\nin addition to their large volume. On the other hand, recent advances in Large\nVisual Models (LVMs), Large Language Models (LLMs), and Large Visual Language\nModels (LVLMs) provide an important opportunity to explore new productive and\nscalable solutions. This work proposes, analyzes, and compares various\napproaches based on one or more state-of-the-art LVM, LLM, and LVLM, for\nmapping social media images into a number of predefined classes. As a case\nstudy, we consider the problem of understanding the interactions between humans\nand nature, also known as Nature's Contribution to People or Cultural Ecosystem\nServices (CES). Our experiments show that the highest-performing approaches,\nwith accuracy above 95%, still require the creation of a small labeled dataset.\nThese include the fine-tuned LVM DINOv2 and the LVLM LLaVA-1.5 combined with a\nfine-tuned LLM. The top fully unsupervised approaches, achieving accuracy above\n84%, are the LVLMs, specifically the proprietary GPT-4 model and the public\nLLaVA-1.5 model. Additionally, the LVM DINOv2, when applied in a 10-shot\nlearning setup, delivered competitive results with an accuracy of 83.99%,\nclosely matching the performance of the LVLM LLaVA-1.5.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.00275v2",
    "published_date": "2024-09-30 23:04:55 UTC",
    "updated_date": "2024-10-16 10:27:14 UTC"
  },
  {
    "arxiv_id": "2410.03737v1",
    "title": "Meta Reinforcement Learning Approach for Adaptive Resource Optimization in O-RAN",
    "authors": [
      "Fatemeh Lotfi",
      "Fatemeh Afghah"
    ],
    "abstract": "As wireless networks grow to support more complex applications, the Open\nRadio Access Network (O-RAN) architecture, with its smart RAN Intelligent\nController (RIC) modules, becomes a crucial solution for real-time network data\ncollection, analysis, and dynamic management of network resources including\nradio resource blocks and downlink power allocation. Utilizing artificial\nintelligence (AI) and machine learning (ML), O-RAN addresses the variable\ndemands of modern networks with unprecedented efficiency and adaptability.\nDespite progress in using ML-based strategies for network optimization,\nchallenges remain, particularly in the dynamic allocation of resources in\nunpredictable environments. This paper proposes a novel Meta Deep Reinforcement\nLearning (Meta-DRL) strategy, inspired by Model-Agnostic Meta-Learning (MAML),\nto advance resource block and downlink power allocation in O-RAN. Our approach\nleverages O-RAN's disaggregated architecture with virtual distributed units\n(DUs) and meta-DRL strategies, enabling adaptive and localized decision-making\nthat significantly enhances network efficiency. By integrating meta-learning,\nour system quickly adapts to new network conditions, optimizing resource\nallocation in real-time. This results in a 19.8% improvement in network\nmanagement performance over traditional methods, advancing the capabilities of\nnext-generation wireless networks.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03737v1",
    "published_date": "2024-09-30 23:04:30 UTC",
    "updated_date": "2024-09-30 23:04:30 UTC"
  },
  {
    "arxiv_id": "2410.00274v2",
    "title": "Social Conjuring: Multi-User Runtime Collaboration with AI in Building Virtual 3D Worlds",
    "authors": [
      "Amina Kobenova",
      "Cyan DeVeaux",
      "Samyak Parajuli",
      "Andrzej Banburski-Fahey",
      "Judith Amores Fernandez",
      "Jaron Lanier"
    ],
    "abstract": "Generative artificial intelligence has shown promise in prompting virtual\nworlds into existence, yet little attention has been given to understanding how\nthis process unfolds as social interaction. We present Social Conjurer, a\nframework for AI-augmented dynamic 3D scene co-creation, where multiple users\ncollaboratively build and modify virtual worlds in real-time. Through an\nexpanded set of interactions, including social and tool-based engagements as\nwell as spatial reasoning, our framework facilitates the creation of rich,\ndiverse virtual environments. Findings from a preliminary user study (N=12)\nprovide insight into the user experience of this approach, how social contexts\nshape the prompting of spatial environments, and perspective on social\napplications of prompt-based 3D co-creation. In addition to highlighting the\npotential of AI-supported multi-user world creation and offering new pathways\nfor AI-augmented creative processes in VR, this article presents a set of\nimplications for designing human-centered interfaces that incorporate AI models\ninto 3D content generation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "27 pages + Appendix, 16 figures; fixed some minor UTF-8 encoding\n  issues in arXiv compilation",
    "pdf_url": "http://arxiv.org/pdf/2410.00274v2",
    "published_date": "2024-09-30 23:02:51 UTC",
    "updated_date": "2024-10-02 17:34:41 UTC"
  },
  {
    "arxiv_id": "2410.00267v1",
    "title": "KPCA-CAM: Visual Explainability of Deep Computer Vision Models using Kernel PCA",
    "authors": [
      "Sachin Karmani",
      "Thanushon Sivakaran",
      "Gaurav Prasad",
      "Mehmet Ali",
      "Wenbo Yang",
      "Sheyang Tang"
    ],
    "abstract": "Deep learning models often function as black boxes, providing no\nstraightforward reasoning for their predictions. This is particularly true for\ncomputer vision models, which process tensors of pixel values to generate\noutcomes in tasks such as image classification and object detection. To\nelucidate the reasoning of these models, class activation maps (CAMs) are used\nto highlight salient regions that influence a model's output. This research\nintroduces KPCA-CAM, a technique designed to enhance the interpretability of\nConvolutional Neural Networks (CNNs) through improved class activation maps.\nKPCA-CAM leverages Principal Component Analysis (PCA) with the kernel trick to\ncapture nonlinear relationships within CNN activations more effectively. By\nmapping data into higher-dimensional spaces with kernel functions and\nextracting principal components from this transformed hyperplane, KPCA-CAM\nprovides more accurate representations of the underlying data manifold. This\nenables a deeper understanding of the features influencing CNN decisions.\nEmpirical evaluations on the ILSVRC dataset across different CNN models\ndemonstrate that KPCA-CAM produces more precise activation maps, providing\nclearer insights into the model's reasoning compared to existing CAM\nalgorithms. This research advances CAM techniques, equipping researchers and\npractitioners with a powerful tool to gain deeper insights into CNN\ndecision-making processes and overall behaviors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 4 figures, Published to IEEE MMSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.00267v1",
    "published_date": "2024-09-30 22:36:37 UTC",
    "updated_date": "2024-09-30 22:36:37 UTC"
  },
  {
    "arxiv_id": "2410.00263v2",
    "title": "Procedure-Aware Surgical Video-language Pretraining with Hierarchical Knowledge Augmentation",
    "authors": [
      "Kun Yuan",
      "Vinkle Srivastav",
      "Nassir Navab",
      "Nicolas Padoy"
    ],
    "abstract": "Surgical video-language pretraining (VLP) faces unique challenges due to the\nknowledge domain gap and the scarcity of multi-modal data. This study aims to\nbridge the gap by addressing issues regarding textual information loss in\nsurgical lecture videos and the spatial-temporal challenges of surgical VLP. We\npropose a hierarchical knowledge augmentation approach and a novel\nProcedure-Encoded Surgical Knowledge-Augmented Video-Language Pretraining\n(PeskaVLP) framework to tackle these issues. The knowledge augmentation uses\nlarge language models (LLM) for refining and enriching surgical concepts, thus\nproviding comprehensive language supervision and reducing the risk of\noverfitting. PeskaVLP combines language supervision with visual\nself-supervision, constructing hard negative samples and employing a Dynamic\nTime Warping (DTW) based loss function to effectively comprehend the\ncross-modal procedural alignment. Extensive experiments on multiple public\nsurgical scene understanding and cross-modal retrieval datasets show that our\nproposed method significantly improves zero-shot transferring performance and\noffers a generalist visual representation for further advancements in surgical\nscene understanding.The code is available at\nhttps://github.com/CAMMA-public/SurgVLP",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024 Spolight)",
    "pdf_url": "http://arxiv.org/pdf/2410.00263v2",
    "published_date": "2024-09-30 22:21:05 UTC",
    "updated_date": "2025-03-13 15:21:36 UTC"
  },
  {
    "arxiv_id": "2410.00260v2",
    "title": "DoPAMine: Domain-specific Pre-training Adaptation from seed-guided data Mining",
    "authors": [
      "Vinayak Arannil",
      "Neha Narwal",
      "Sourav Sanjukta Bhabesh",
      "Sai Nikhil Thirandas",
      "Darren Yow-Bang Wang",
      "Graham Horwood",
      "Alex Anto Chirayath",
      "Gouri Pandeshwar"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable ability to generalize\neffectively across numerous industry domains while executing a range of tasks.\nMany of these competencies are obtained from the data utilized during the\npre-training phase of the Language Models (LMs). However, these models exhibit\nlimitations when tasked with performing in specialized or low-resource industry\ndomains. More recent approaches use LLMs for generating domain-specific\nsynthetic data but most often they lack in truthfulness and complexity.\nAlternatively, in cases where domain data is available like healthcare and\nfinance most of the LMs are proprietary necessitating the need for a scalable\nmethod to curate real world industry specific pre-training data. In this work,\nwe propose an automated and scalable framework - DoPAMine:Domain-specific\nPre-training Adaptation from seed-guided data Mining, to mine domain specific\ntraining data from a large data corpus for domain adaptation of a LM. The\nframework leverages the parametric knowledge of a LLM to generate diverse and\nrepresentative seed data tailored to a specific domain which is then used to\nmine real world data from a large data corpus like Common Crawl. We evaluated\nour framework's performance in the continual pre-training (CPT) setting by\ntraining two domain specific 7B parameter LMs in healthcare and finance with\ndata mined via DoPAMine. Our experiments show that DoPAMine boosts the\nperformance of pre-trained LLMs on average by 4.9% and 5.1% in zero-shot and\n5-shot settings respectively on healthcare tasks from MMLU, MedQA, MedMCQA and\nPubMedQA datasets, and 2.9% and 6.7% for zero-shot and 5-shot settings\nrespectively on finance tasks from FiQA-SA, FPB and Headlines datasets when\ncompared to the baseline.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00260v2",
    "published_date": "2024-09-30 22:15:58 UTC",
    "updated_date": "2024-10-09 17:39:59 UTC"
  },
  {
    "arxiv_id": "2410.00258v1",
    "title": "Possible principles for aligned structure learning agents",
    "authors": [
      "Lancelot Da Costa",
      "TomÃ¡Å¡ GavenÄiak",
      "David Hyland",
      "Mandana Samiei",
      "Cristian Dragos-Manta",
      "Candice Pattisapu",
      "Adeel Razi",
      "Karl Friston"
    ],
    "abstract": "This paper offers a roadmap for the development of scalable aligned\nartificial intelligence (AI) from first principle descriptions of natural\nintelligence. In brief, a possible path toward scalable aligned AI rests upon\nenabling artificial agents to learn a good model of the world that includes a\ngood model of our preferences. For this, the main objective is creating agents\nthat learn to represent the world and other agents' world models; a problem\nthat falls under structure learning (a.k.a. causal representation learning). We\nexpose the structure learning and alignment problems with this goal in mind, as\nwell as principles to guide us forward, synthesizing various ideas across\nmathematics, statistics, and cognitive science. 1) We discuss the essential\nrole of core knowledge, information geometry and model reduction in structure\nlearning, and suggest core structural modules to learn a wide range of\nnaturalistic worlds. 2) We outline a way toward aligned agents through\nstructure learning and theory of mind. As an illustrative example, we\nmathematically sketch Asimov's Laws of Robotics, which prescribe agents to act\ncautiously to minimize the ill-being of other agents. We supplement this\nexample by proposing refined approaches to alignment. These observations may\nguide the development of artificial intelligence in helping to scale existing\n-- or design new -- aligned structure learning systems.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages of content, 31 with references",
    "pdf_url": "http://arxiv.org/pdf/2410.00258v1",
    "published_date": "2024-09-30 22:06:06 UTC",
    "updated_date": "2024-09-30 22:06:06 UTC"
  },
  {
    "arxiv_id": "2410.00257v1",
    "title": "The age of spiritual machines: Language quietus induces synthetic altered states of consciousness in artificial intelligence",
    "authors": [
      "Jeremy I Skipper",
      "Joanna Kuc",
      "Greg Cooper",
      "Christopher Timmermann"
    ],
    "abstract": "How is language related to consciousness? Language functions to categorise\nperceptual experiences (e.g., labelling interoceptive states as 'happy') and\nhigher-level constructs (e.g., using 'I' to represent the narrative self).\nPsychedelic use and meditation might be described as altered states that impair\nor intentionally modify the capacity for linguistic categorisation. For\nexample, psychedelic phenomenology is often characterised by 'oceanic\nboundlessness' or 'unity' and 'ego dissolution', which might be expected of a\nsystem unburdened by entrenched language categories. If language breakdown\nplays a role in producing such altered behaviour, multimodal artificial\nintelligence might align more with these phenomenological descriptions when\nattention is shifted away from language. We tested this hypothesis by comparing\nthe semantic embedding spaces from simulated altered states after manipulating\nattentional weights in CLIP and FLAVA models to embedding spaces from altered\nstates questionnaires before manipulation. Compared to random text and various\nother altered states including anxiety, models were more aligned with\ndisembodied, ego-less, spiritual, and unitive states, as well as minimal\nphenomenal experiences, with decreased attention to language and vision.\nReduced attention to language was associated with distinct linguistic patterns\nand blurred embeddings within and, especially, across semantic categories\n(e.g., 'giraffes' become more like 'bananas'). These results lend support to\nthe role of language categorisation in the phenomenology of altered states of\nconsciousness, like those experienced with high doses of psychedelics or\nconcentration meditation, states that often lead to improved mental health and\nwellbeing.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-bio.NC",
    "comment": "8 Figures",
    "pdf_url": "http://arxiv.org/pdf/2410.00257v1",
    "published_date": "2024-09-30 22:03:26 UTC",
    "updated_date": "2024-09-30 22:03:26 UTC"
  },
  {
    "arxiv_id": "2410.00255v2",
    "title": "Robin3D: Improving 3D Large Language Model via Robust Instruction Tuning",
    "authors": [
      "Weitai Kang",
      "Haifeng Huang",
      "Yuzhang Shang",
      "Mubarak Shah",
      "Yan Yan"
    ],
    "abstract": "Recent advancements in 3D Large Language Models (3DLLMs) have highlighted\ntheir potential in building general-purpose agents in the 3D real world, yet\nchallenges remain due to the lack of high-quality robust instruction-following\ndata, leading to limited discriminative power and generalization of 3DLLMs. In\nthis paper, we introduce Robin3D, a powerful 3DLLM trained on large-scale\ninstruction-following data generated by our novel data engine, Robust\nInstruction Generation (RIG) engine. RIG generates two key instruction data: 1)\nthe Adversarial Instruction-following data, which features mixed negative and\npositive samples to enhance the model's discriminative understanding. 2) the\nDiverse Instruction-following data, which contains various instruction styles\nto enhance model's generalization. As a result, we construct 1 million\ninstruction-following data, consisting of 344K Adversarial samples, 508K\nDiverse samples, and 165K benchmark training set samples. To better handle\nthese complex instructions, Robin3D first incorporates Relation-Augmented\nProjector to enhance spatial understanding, and then strengthens the object\nreferring and grounding ability through ID-Feature Bonding. Robin3D\nconsistently outperforms previous methods across five widely-used 3D multimodal\nlearning benchmarks, without the need for task-specific fine-tuning. Notably,\nwe achieve a 7.8\\% improvement in the grounding task (Multi3DRefer) and a 6.9\\%\nimprovement in the captioning task (Scan2Cap).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.00255v2",
    "published_date": "2024-09-30 21:55:38 UTC",
    "updated_date": "2025-02-20 18:06:19 UTC"
  },
  {
    "arxiv_id": "2410.00240v1",
    "title": "Demonstrating the Continual Learning Capabilities and Practical Application of Discrete-Time Active Inference",
    "authors": [
      "Rithvik Prakki"
    ],
    "abstract": "Active inference is a mathematical framework for understanding how agents\n(biological or artificial) interact with their environments, enabling continual\nadaptation and decision-making. It combines Bayesian inference and free energy\nminimization to model perception, action, and learning in uncertain and dynamic\ncontexts. Unlike reinforcement learning, active inference integrates\nexploration and exploitation seamlessly by minimizing expected free energy. In\nthis paper, we present a continual learning framework for agents operating in\ndiscrete time environments, using active inference as the foundation. We derive\nthe mathematical formulations of variational and expected free energy and apply\nthem to the design of a self-learning research agent. This agent updates its\nbeliefs and adapts its actions based on new data without manual intervention.\nThrough experiments in changing environments, we demonstrate the agent's\nability to relearn and refine its models efficiently, making it suitable for\ncomplex domains like finance and healthcare. The paper concludes by discussing\nhow the proposed framework generalizes to other systems, positioning active\ninference as a flexible approach for adaptive AI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.00240v1",
    "published_date": "2024-09-30 21:18:46 UTC",
    "updated_date": "2024-09-30 21:18:46 UTC"
  },
  {
    "arxiv_id": "2410.03736v2",
    "title": "CliMB: An AI-enabled Partner for Clinical Predictive Modeling",
    "authors": [
      "Evgeny Saveliev",
      "Tim Schubert",
      "Thomas Pouplin",
      "Vasilis Kosmoliaptsis",
      "Mihaela van der Schaar"
    ],
    "abstract": "Despite its significant promise and continuous technical advances, real-world\napplications of artificial intelligence (AI) remain limited. We attribute this\nto the \"domain expert-AI-conundrum\": while domain experts, such as clinician\nscientists, should be able to build predictive models such as risk scores, they\nface substantial barriers in accessing state-of-the-art (SOTA) tools. While\nautomated machine learning (AutoML) has been proposed as a partner in clinical\npredictive modeling, many additional requirements need to be fulfilled to make\nmachine learning accessible for clinician scientists.\n  To address this gap, we introduce CliMB, a no-code AI-enabled partner\ndesigned to empower clinician scientists to create predictive models using\nnatural language. CliMB guides clinician scientists through the entire medical\ndata science pipeline, thus empowering them to create predictive models from\nreal-world data in just one conversation. CliMB also creates structured reports\nand interpretable visuals. In evaluations involving clinician scientists and\nsystematic comparisons against a baseline GPT-4, CliMB consistently\ndemonstrated superior performance in key areas such as planning, error\nprevention, code execution, and model performance. Moreover, in blinded\nassessments involving 45 clinicians from diverse specialties and career stages,\nmore than 80% preferred CliMB over GPT-4. Overall, by providing a no-code\ninterface with clear guidance and access to SOTA methods in the fields of\ndata-centric AI, AutoML, and interpretable ML, CliMB empowers clinician\nscientists to build robust predictive models.\n  The proof-of-concept version of CliMB is available as open-source software on\nGitHub: https://github.com/vanderschaarlab/climb.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "* Evgeny Saveliev and Tim Schubert contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2410.03736v2",
    "published_date": "2024-09-30 21:18:05 UTC",
    "updated_date": "2024-11-25 16:21:05 UTC"
  },
  {
    "arxiv_id": "2410.00231v1",
    "title": "Helpful DoggyBot: Open-World Object Fetching using Legged Robots and Vision-Language Models",
    "authors": [
      "Qi Wu",
      "Zipeng Fu",
      "Xuxin Cheng",
      "Xiaolong Wang",
      "Chelsea Finn"
    ],
    "abstract": "Learning-based methods have achieved strong performance for quadrupedal\nlocomotion. However, several challenges prevent quadrupeds from learning\nhelpful indoor skills that require interaction with environments and humans:\nlack of end-effectors for manipulation, limited semantic understanding using\nonly simulation data, and low traversability and reachability in indoor\nenvironments. We present a system for quadrupedal mobile manipulation in indoor\nenvironments. It uses a front-mounted gripper for object manipulation, a\nlow-level controller trained in simulation using egocentric depth for agile\nskills like climbing and whole-body tilting, and pre-trained vision-language\nmodels (VLMs) with a third-person fisheye and an egocentric RGB camera for\nsemantic understanding and command generation. We evaluate our system in two\nunseen environments without any real-world data collection or training. Our\nsystem can zero-shot generalize to these environments and complete tasks, like\nfollowing user's commands to fetch a randomly placed stuff toy after climbing\nover a queen-sized bed, with a 60% success rate. Project website:\nhttps://helpful-doggybot.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://helpful-doggybot.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.00231v1",
    "published_date": "2024-09-30 20:58:38 UTC",
    "updated_date": "2024-09-30 20:58:38 UTC"
  },
  {
    "arxiv_id": "2410.00930v1",
    "title": "ACEV: Unsupervised Intersecting Manifold Segmentation using Adaptation to Angular Change of Eigenvectors in Intrinsic Dimension",
    "authors": [
      "Subhadip Boral",
      "Rikathi Pal",
      "Ashish Ghosh"
    ],
    "abstract": "Intersecting manifold segmentation has been a focus of research, where\nindividual manifolds, that intersect with other manifolds, are separated to\ndiscover their distinct properties. The proposed method is based on the\nintuition that when a manifold in $D$ dimensional space with an intrinsic\ndimension of $d$ intersects with another manifold, the data variance grows in\nmore than $d$ directions. The proposed method measures local data variances and\ndetermines their vector directions. It counts the number of vectors with\nnon-zero variance, which determines the manifold's intrinsic dimension. For\ndetection of the intersection region, the method adapts to the changes in the\nangular gaps between the corresponding direction vectors of the child and\nparent using exponential moving averages using a tree structure construction.\nAccordingly, it includes those data points in the same manifold whose\nneighborhood is within the adaptive angular difference and eventually\nidentifies the data points in the intersection area of manifolds. Data points\nwhose inclusion in the neighborhood-identified data points increases their\nintrinsic dimensionality are removed based on data variance and distance. The\nproposed method performs better than 18 SOTA manifold segmentation methods in\nARI and NMI scores over 14 real-world datasets with lesser time complexity and\nbetter stability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 7 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.00930v1",
    "published_date": "2024-09-30 20:37:47 UTC",
    "updated_date": "2024-09-30 20:37:47 UTC"
  },
  {
    "arxiv_id": "2410.00929v1",
    "title": "A Knowledge-Informed Large Language Model Framework for U.S. Nuclear Power Plant Shutdown Initiating Event Classification for Probabilistic Risk Assessment",
    "authors": [
      "Min Xian",
      "Tao Wang",
      "Sai Zhang",
      "Fei Xu",
      "Zhegang Ma"
    ],
    "abstract": "Identifying and classifying shutdown initiating events (SDIEs) is critical\nfor developing low power shutdown probabilistic risk assessment for nuclear\npower plants. Existing computational approaches cannot achieve satisfactory\nperformance due to the challenges of unavailable large, labeled datasets,\nimbalanced event types, and label noise. To address these challenges, we\npropose a hybrid pipeline that integrates a knowledge-informed machine learning\nmode to prescreen non-SDIEs and a large language model (LLM) to classify SDIEs\ninto four types. In the prescreening stage, we proposed a set of 44 SDIE text\npatterns that consist of the most salient keywords and phrases from six SDIE\ntypes. Text vectorization based on the SDIE patterns generates feature vectors\nthat are highly separable by using a simple binary classifier. The second stage\nbuilds Bidirectional Encoder Representations from Transformers (BERT)-based\nLLM, which learns generic English language representations from self-supervised\npretraining on a large dataset and adapts to SDIE classification by fine-tuning\nit on an SDIE dataset. The proposed approaches are evaluated on a dataset with\n10,928 events using precision, recall ratio, F1 score, and average accuracy.\nThe results demonstrate that the prescreening stage can exclude more than 97%\nnon-SDIEs, and the LLM achieves an average accuracy of 93.4% for SDIE\nclassification.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00929v1",
    "published_date": "2024-09-30 20:35:03 UTC",
    "updated_date": "2024-09-30 20:35:03 UTC"
  },
  {
    "arxiv_id": "2410.00182v1",
    "title": "Zero-Shot Classification of Crisis Tweets Using Instruction-Finetuned Large Language Models",
    "authors": [
      "Emma McDaniel",
      "Samuel Scheele",
      "Jeff Liu"
    ],
    "abstract": "Social media posts are frequently identified as a valuable source of\nopen-source intelligence for disaster response, and pre-LLM NLP techniques have\nbeen evaluated on datasets of crisis tweets. We assess three commercial large\nlanguage models (OpenAI GPT-4o, Gemini 1.5-flash-001 and Anthropic Claude-3-5\nSonnet) capabilities in zero-shot classification of short social media posts.\nIn one prompt, the models are asked to perform two classification tasks: 1)\nidentify if the post is informative in a humanitarian context; and 2) rank and\nprovide probabilities for the post in relation to 16 possible humanitarian\nclasses. The posts being classified are from the consolidated crisis tweet\ndataset, CrisisBench. Results are evaluated using macro, weighted, and binary\nF1-scores. The informative classification task, generally performed better\nwithout extra information, while for the humanitarian label classification\nproviding the event that occurred during which the tweet was mined, resulted in\nbetter performance. Further, we found that the models have significantly\nvarying performance by dataset, which raises questions about dataset quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00182v1",
    "published_date": "2024-09-30 19:33:58 UTC",
    "updated_date": "2024-09-30 19:33:58 UTC"
  },
  {
    "arxiv_id": "2410.00163v1",
    "title": "Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation",
    "authors": [
      "Pedro Henrique Paiola",
      "Gabriel Lino Garcia",
      "JoÃ£o Renato Ribeiro Manesco",
      "Mateus Roder",
      "Douglas Rodrigues",
      "JoÃ£o Paulo Papa"
    ],
    "abstract": "This study evaluates the performance of large language models (LLMs) as\nmedical agents in Portuguese, aiming to develop a reliable and relevant virtual\nassistant for healthcare professionals. The HealthCareMagic-100k-en and MedQuAD\ndatasets, translated from English using GPT-3.5, were used to fine-tune the\nChatBode-7B model using the PEFT-QLoRA method. The InternLM2 model, with\ninitial training on medical data, presented the best overall performance, with\nhigh precision and adequacy in metrics such as accuracy, completeness and\nsafety. However, DrBode models, derived from ChatBode, exhibited a phenomenon\nof catastrophic forgetting of acquired medical knowledge. Despite this, these\nmodels performed frequently or even better in aspects such as grammaticality\nand coherence. A significant challenge was low inter-rater agreement,\nhighlighting the need for more robust assessment protocols. This work paves the\nway for future research, such as evaluating multilingual models specific to the\nmedical field, improving the quality of training data, and developing more\nconsistent evaluation methodologies for the medical field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2410.00163v1",
    "published_date": "2024-09-30 19:10:03 UTC",
    "updated_date": "2024-09-30 19:10:03 UTC"
  },
  {
    "arxiv_id": "2410.00153v3",
    "title": "Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution",
    "authors": [
      "Haiyan Zhao",
      "Heng Zhao",
      "Bo Shen",
      "Ali Payani",
      "Fan Yang",
      "Mengnan Du"
    ],
    "abstract": "Probing learned concepts in large language models (LLMs) is crucial for\nunderstanding how semantic knowledge is encoded internally. Training linear\nclassifiers on probing tasks is a principle approach to denote the vector of a\ncertain concept in the representation space. However, the single vector\nidentified for a concept varies with both data and training, making it less\nrobust and weakening its effectiveness in real-world applications. To address\nthis challenge, we propose an approach to approximate the subspace representing\na specific concept. Built on linear probing classifiers, we extend the concept\nvectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's\neffectiveness through measuring its faithfulness and plausibility across\nmultiple LLMs with different sizes and architectures. Additionally, we use\nrepresentation intervention tasks to showcase its efficacy in real-world\napplications such as emotion steering. Experimental results indicate that GCS\nconcept vectors have the potential to balance steering performance and\nmaintaining the fluency in natural language generation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.00153v3",
    "published_date": "2024-09-30 18:52:53 UTC",
    "updated_date": "2025-05-05 19:17:46 UTC"
  },
  {
    "arxiv_id": "2410.03733v1",
    "title": "Evaluating the Effects of AI Directors for Quest Selection",
    "authors": [
      "Kristen K. Yu",
      "Matthew Guzdial",
      "Nathan Sturtevant"
    ],
    "abstract": "Modern commercial games are designed for mass appeal, not for individual\nplayers, but there is a unique opportunity in video games to better fit the\nindividual through adapting game elements. In this paper, we focus on AI\nDirectors, systems which can dynamically modify a game, that personalize the\nplayer experience to match the player's preference. In the past, some AI\nDirector studies have provided inconclusive results, so their effect on player\nexperience is not clear. We take three AI Directors and directly compare them\nin a human subject study to test their effectiveness on quest selection. Our\nresults show that a non-random AI Director provides a better player experience\nthan a random AI Director.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03733v1",
    "published_date": "2024-09-30 18:16:38 UTC",
    "updated_date": "2024-09-30 18:16:38 UTC"
  },
  {
    "arxiv_id": "2410.00134v1",
    "title": "Semantic-Driven Topic Modeling Using Transformer-Based Embeddings and Clustering Algorithms",
    "authors": [
      "Melkamu Abay Mersha",
      "Mesay Gemeda yigezu",
      "Jugal Kalita"
    ],
    "abstract": "Topic modeling is a powerful technique to discover hidden topics and patterns\nwithin a collection of documents without prior knowledge. Traditional topic\nmodeling and clustering-based techniques encounter challenges in capturing\ncontextual semantic information. This study introduces an innovative end-to-end\nsemantic-driven topic modeling technique for the topic extraction process,\nutilizing advanced word and document embeddings combined with a powerful\nclustering algorithm. This semantic-driven approach represents a significant\nadvancement in topic modeling methodologies. It leverages contextual semantic\ninformation to extract coherent and meaningful topics. Specifically, our model\ngenerates document embeddings using pre-trained transformer-based language\nmodels, reduces the dimensions of the embeddings, clusters the embeddings based\non semantic similarity, and generates coherent topics for each cluster.\nCompared to ChatGPT and traditional topic modeling algorithms, our model\nprovides more coherent and meaningful topics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00134v1",
    "published_date": "2024-09-30 18:15:31 UTC",
    "updated_date": "2024-09-30 18:15:31 UTC"
  },
  {
    "arxiv_id": "2410.00131v2",
    "title": "Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models",
    "authors": [
      "Ji Liu",
      "Jiaxiang Ren",
      "Ruoming Jin",
      "Zijie Zhang",
      "Yang Zhou",
      "Patrick Valduriez",
      "Dejing Dou"
    ],
    "abstract": "As a promising paradigm to collaboratively train models with decentralized\ndata, Federated Learning (FL) can be exploited to fine-tune Large Language\nModels (LLMs). While LLMs correspond to huge size, the scale of the training\ndata significantly increases, which leads to tremendous amounts of computation\nand communication costs. The training data is generally non-Independent and\nIdentically Distributed (non-IID), which requires adaptive data processing\nwithin each device. Although Low Rank Adaptation (LoRA) can significantly\nreduce the scale of parameters to update in the fine-tuning process, it still\ntakes unaffordable time to transfer the low-rank parameters of all the layers\nin LLMs. In this paper, we propose a Fisher Information-based Efficient\nCurriculum Federated Learning framework (FibecFed) with two novel methods,\ni.e., adaptive federated curriculum learning and efficient sparse parameter\nupdate. First, we propose a fisher information-based method to adaptively\nsample data within each device to improve the effectiveness of the FL\nfine-tuning process. Second, we dynamically select the proper layers for global\naggregation and sparse parameters for local update with LoRA so as to improve\nthe efficiency of the FL fine-tuning process. Extensive experimental results\nbased on 10 datasets demonstrate that FibecFed yields excellent performance (up\nto 45.35% in terms of accuracy) and superb fine-tuning speed (up to 98.61%\nfaster) compared with 17 baseline approaches).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 8 figures, 14 tables, to appear in EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.00131v2",
    "published_date": "2024-09-30 18:12:18 UTC",
    "updated_date": "2024-10-18 05:22:02 UTC"
  },
  {
    "arxiv_id": "2410.00129v2",
    "title": "Cartesian Genetic Programming Approach for Designing Convolutional Neural Networks",
    "authors": [
      "Maciej Krzywda",
      "Szymon Åukasik",
      "Amir Gandomi H"
    ],
    "abstract": "The present study covers an approach to neural architecture search (NAS)\nusing Cartesian genetic programming (CGP) for the design and optimization of\nConvolutional Neural Networks (CNNs). In designing artificial neural networks,\none crucial aspect of the innovative approach is suggesting a novel neural\narchitecture. Currently used architectures have mostly been developed manually\nby human experts, which is a time-consuming and error-prone process. In this\nwork, we use pure Genetic Programming Approach to design CNNs, which employs\nonly one genetic operation, i.e., mutation. In the course of preliminary\nexperiments, our methodology yields promising results.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00129v2",
    "published_date": "2024-09-30 18:10:06 UTC",
    "updated_date": "2024-10-13 23:43:33 UTC"
  },
  {
    "arxiv_id": "2409.20568v1",
    "title": "Continuously Improving Mobile Manipulation with Autonomous Real-World RL",
    "authors": [
      "Russell Mendonca",
      "Emmanuel Panov",
      "Bernadette Bucher",
      "Jiuguang Wang",
      "Deepak Pathak"
    ],
    "abstract": "We present a fully autonomous real-world RL framework for mobile manipulation\nthat can learn policies without extensive instrumentation or human supervision.\nThis is enabled by 1) task-relevant autonomy, which guides exploration towards\nobject interactions and prevents stagnation near goal states, 2) efficient\npolicy learning by leveraging basic task knowledge in behavior priors, and 3)\nformulating generic rewards that combine human-interpretable semantic\ninformation with low-level, fine-grained observations. We demonstrate that our\napproach allows Spot robots to continually improve their performance on a set\nof four challenging mobile manipulation tasks, obtaining an average success\nrate of 80% across tasks, a 3-4 improvement over existing approaches. Videos\ncan be found at https://continual-mobile-manip.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "CoRL 2024. Website at https://continual-mobile-manip.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2409.20568v1",
    "published_date": "2024-09-30 17:59:50 UTC",
    "updated_date": "2024-09-30 17:59:50 UTC"
  },
  {
    "arxiv_id": "2409.20560v2",
    "title": "LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner",
    "authors": [
      "Xiaopan Zhang",
      "Hao Qin",
      "Fuquan Wang",
      "Yue Dong",
      "Jiachen Li"
    ],
    "abstract": "Language models (LMs) possess a strong capability to comprehend natural\nlanguage, making them effective in translating human instructions into detailed\nplans for simple robot tasks. Nevertheless, it remains a significant challenge\nto handle long-horizon tasks, especially in subtask identification and\nallocation for cooperative heterogeneous robot teams. To address this issue, we\npropose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel\nmulti-agent task planning framework that achieves state-of-the-art performance\non long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning\ncapability and the traditional heuristic search planner to achieve a high\nsuccess rate and efficiency while demonstrating strong generalization across\ntasks. Additionally, we create MAT-THOR, a comprehensive benchmark that\nfeatures household tasks with two different levels of complexity based on the\nAI2-THOR environment. The experimental results demonstrate that LaMMA-P\nachieves a 105% higher success rate and 36% higher efficiency than existing\nLM-based multiagent planners. The experimental videos, code, datasets, and\ndetailed prompts used in each module can be found on the project website:\nhttps://lamma-p.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE Conference on Robotics and Automation (ICRA 2025); Project\n  website: https://lamma-p.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2409.20560v2",
    "published_date": "2024-09-30 17:58:18 UTC",
    "updated_date": "2025-03-13 06:17:58 UTC"
  },
  {
    "arxiv_id": "2410.00086v2",
    "title": "ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer",
    "authors": [
      "Zhen Han",
      "Zeyinzi Jiang",
      "Yulin Pan",
      "Jingfeng Zhang",
      "Chaojie Mao",
      "Chenwei Xie",
      "Yu Liu",
      "Jingren Zhou"
    ],
    "abstract": "Diffusion models have emerged as a powerful generative technology and have\nbeen found to be applicable in various scenarios. Most existing foundational\ndiffusion models are primarily designed for text-guided visual generation and\ndo not support multi-modal conditions, which are essential for many visual\nediting tasks. This limitation prevents these foundational diffusion models\nfrom serving as a unified model in the field of visual generation, like GPT-4\nin the natural language processing field. In this work, we propose ACE, an\nAll-round Creator and Editor, which achieves comparable performance compared to\nthose expert models in a wide range of visual generation tasks. To achieve this\ngoal, we first introduce a unified condition format termed Long-context\nCondition Unit (LCU), and propose a novel Transformer-based diffusion model\nthat uses LCU as input, aiming for joint training across various generation and\nediting tasks. Furthermore, we propose an efficient data collection approach to\naddress the issue of the absence of available training data. It involves\nacquiring pairwise images with synthesis-based or clustering-based pipelines\nand supplying these pairs with accurate textual instructions by leveraging a\nfine-tuned multi-modal large language model. To comprehensively evaluate the\nperformance of our model, we establish a benchmark of manually annotated pairs\ndata across a variety of visual generation tasks. The extensive experimental\nresults demonstrate the superiority of our model in visual generation fields.\nThanks to the all-in-one capabilities of our model, we can easily build a\nmulti-modal chat system that responds to any interactive request for image\ncreation using a single model to serve as the backend, avoiding the cumbersome\npipeline typically employed in visual agents. Code and models will be available\non the project page: https://ali-vilab.github.io/ace-page/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00086v2",
    "published_date": "2024-09-30 17:56:27 UTC",
    "updated_date": "2024-11-05 12:25:32 UTC"
  },
  {
    "arxiv_id": "2409.20553v2",
    "title": "Maia-2: A Unified Model for Human-AI Alignment in Chess",
    "authors": [
      "Zhenwei Tang",
      "Difan Jiao",
      "Reid McIlroy-Young",
      "Jon Kleinberg",
      "Siddhartha Sen",
      "Ashton Anderson"
    ],
    "abstract": "There are an increasing number of domains in which artificial intelligence\n(AI) systems both surpass human ability and accurately model human behavior.\nThis introduces the possibility of algorithmically-informed teaching in these\ndomains through more relatable AI partners and deeper insights into human\ndecision-making. Critical to achieving this goal, however, is coherently\nmodeling human behavior at various skill levels. Chess is an ideal model system\nfor conducting research into this kind of human-AI alignment, with its rich\nhistory as a pivotal testbed for AI research, mature superhuman AI systems like\nAlphaZero, and precise measurements of skill via chess rating systems. Previous\nwork in modeling human decision-making in chess uses completely independent\nmodels to capture human style at different skill levels, meaning they lack\ncoherence in their ability to adapt to the full spectrum of human improvement\nand are ultimately limited in their effectiveness as AI partners and teaching\ntools. In this work, we propose a unified modeling approach for human-AI\nalignment in chess that coherently captures human style across different skill\nlevels and directly captures how people improve. Recognizing the complex,\nnon-linear nature of human learning, we introduce a skill-aware attention\nmechanism to dynamically integrate players' strengths with encoded chess\npositions, enabling our model to be sensitive to evolving player skill. Our\nexperimental results demonstrate that this unified framework significantly\nenhances the alignment between AI and human players across a diverse range of\nexpertise levels, paving the way for deeper insights into human decision-making\nand AI-guided teaching tools.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted @ NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.20553v2",
    "published_date": "2024-09-30 17:54:23 UTC",
    "updated_date": "2024-10-31 23:29:28 UTC"
  },
  {
    "arxiv_id": "2409.20550v2",
    "title": "LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation",
    "authors": [
      "Ziyao Zhang",
      "Yanlin Wang",
      "Chong Wang",
      "Jiachi Chen",
      "Zibin Zheng"
    ],
    "abstract": "Code generation aims to automatically generate code from input requirements,\nsignificantly enhancing development efficiency. Recent large language models\n(LLMs) based approaches have shown promising results and revolutionized code\ngeneration task. Despite the promising performance, LLMs often generate\ncontents with hallucinations, especially for the code generation scenario\nrequiring the handling of complex contextual dependencies in practical\ndevelopment process. Although previous study has analyzed hallucinations in\nLLM-powered code generation, the study is limited to standalone function\ngeneration. In this paper, we conduct an empirical study to study the\nphenomena, mechanism, and mitigation of LLM hallucinations within more\npractical and complex development contexts in repository-level generation\nscenario. First, we manually examine the code generation results from six\nmainstream LLMs to establish a hallucination taxonomy of LLM-generated code.\nNext, we elaborate on the phenomenon of hallucinations, analyze their\ndistribution across different models. We then analyze causes of hallucinations\nand identify four potential factors contributing to hallucinations. Finally, we\npropose an RAG-based mitigation method, which demonstrates consistent\neffectiveness in all studied LLMs. The replication package including code,\ndata, and experimental results is available at\nhttps://github.com/DeepSoftwareAnalytics/LLMCodingHallucination",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by ISSTA 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.20550v2",
    "published_date": "2024-09-30 17:51:15 UTC",
    "updated_date": "2025-01-17 01:44:44 UTC"
  },
  {
    "arxiv_id": "2410.03731v3",
    "title": "Unsupervised Human Preference Learning",
    "authors": [
      "Sumuk Shashidhar",
      "Abhinav Chinta",
      "Vaibhav Sahai",
      "Dilek Hakkani-TÃ¼r"
    ],
    "abstract": "Large language models demonstrate impressive reasoning abilities but struggle\nto provide personalized content due to their lack of individual user preference\ninformation. Existing methods, such as in-context learning and\nparameter-efficient fine-tuning, fall short in capturing the complexity of\nhuman preferences, especially given the small, personal datasets individuals\npossess. In this paper, we propose a novel approach utilizing small parameter\nmodels as preference agents to generate natural language rules that guide a\nlarger, pre-trained model, enabling efficient personalization. Our method\ninvolves a small, local \"steering wheel\" model that directs the outputs of a\nmuch larger foundation model, producing content tailored to an individual's\npreferences while leveraging the extensive knowledge and capabilities of the\nlarge model. Importantly, this personalization is achieved without the need to\nfine-tune the large model. Experimental results on email and article datasets,\ndemonstrate that our technique significantly outperforms baseline\npersonalization methods. By allowing foundation models to adapt to individual\npreferences in a data and compute-efficient manner, our approach paves the way\nfor highly personalized language model applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2410.03731v3",
    "published_date": "2024-09-30 17:51:01 UTC",
    "updated_date": "2024-10-11 18:53:56 UTC"
  },
  {
    "arxiv_id": "2409.20548v2",
    "title": "Robi Butler: Multimodal Remote Interaction with a Household Robot Assistant",
    "authors": [
      "Anxing Xiao",
      "Nuwan Janaka",
      "Tianrun Hu",
      "Anshul Gupta",
      "Kaixin Li",
      "Cunjun Yu",
      "David Hsu"
    ],
    "abstract": "Imagine a future when we can Zoom-call a robot to manage household chores\nremotely. This work takes one step in this direction. Robi Butler is a new\nhousehold robot assistant that enables seamless multimodal remote interaction.\nIt allows the human user to monitor its environment from a first-person view,\nissue voice or text commands, and specify target objects through hand-pointing\ngestures. At its core, a high-level behavior module, powered by Large Language\nModels (LLMs), interprets multimodal instructions to generate multistep action\nplans. Each plan consists of open-vocabulary primitives supported by\nvision-language models, enabling the robot to process both textual and gestural\ninputs. Zoom provides a convenient interface to implement remote interactions\nbetween the human and the robot. The integration of these components allows\nRobi Butler to ground remote multimodal instructions in real-world home\nenvironments in a zero-shot manner. We evaluated the system on various\nhousehold tasks, demonstrating its ability to execute complex user commands\nwith multimodal inputs. We also conducted a user study to examine how\nmultimodal interaction influences user experiences in remote human-robot\ninteraction. These results suggest that with the advances in robot foundation\nmodels, we are moving closer to the reality of remote household robot\nassistants.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.20548v2",
    "published_date": "2024-09-30 17:49:09 UTC",
    "updated_date": "2025-03-10 06:00:08 UTC"
  },
  {
    "arxiv_id": "2410.00083v1",
    "title": "A Survey on Diffusion Models for Inverse Problems",
    "authors": [
      "Giannis Daras",
      "Hyungjin Chung",
      "Chieh-Hsin Lai",
      "Yuki Mitsufuji",
      "Jong Chul Ye",
      "Peyman Milanfar",
      "Alexandros G. Dimakis",
      "Mauricio Delbracio"
    ],
    "abstract": "Diffusion models have become increasingly popular for generative modeling due\nto their ability to generate high-quality samples. This has unlocked exciting\nnew possibilities for solving inverse problems, especially in image restoration\nand reconstruction, by treating diffusion models as unsupervised priors. This\nsurvey provides a comprehensive overview of methods that utilize pre-trained\ndiffusion models to solve inverse problems without requiring further training.\nWe introduce taxonomies to categorize these methods based on both the problems\nthey address and the techniques they employ. We analyze the connections between\ndifferent approaches, offering insights into their practical implementation and\nhighlighting important considerations. We further discuss specific challenges\nand potential solutions associated with using latent diffusion models for\ninverse problems. This work aims to be a valuable resource for those interested\nin learning about the intersection of diffusion models and inverse problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in progress. 38 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.00083v1",
    "published_date": "2024-09-30 17:34:01 UTC",
    "updated_date": "2024-09-30 17:34:01 UTC"
  },
  {
    "arxiv_id": "2410.00082v1",
    "title": "Graph Residual Noise Learner Network for Brain Connectivity Graph Prediction",
    "authors": [
      "Oytun Demirbilek",
      "Tingying Peng",
      "Alaa Bessadok"
    ],
    "abstract": "A morphological brain graph depicting a connectional fingerprint is of\nparamount importance for charting brain dysconnectivity patterns. Such data\noften has missing observations due to various reasons such as time-consuming\nand incomplete neuroimage processing pipelines. Thus, predicting a target brain\ngraph from a source graph is crucial for better diagnosing neurological\ndisorders with minimal data acquisition resources. Many brain graph generative\nmodels were proposed for promising results, yet they are mostly based on\ngenerative adversarial networks (GAN), which could suffer from mode collapse\nand require large training datasets. Recent developments in diffusion models\naddress these problems by offering essential properties such as a stable\ntraining objective and easy scalability. However, applying a diffusion process\nto graph edges fails to maintain the topological symmetry of the brain\nconnectivity matrices. To meet these challenges, we propose the Graph Residual\nNoise Learner Network (Grenol-Net), the first graph diffusion model for\npredicting a target graph from a source graph.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "10 pages, 3 figures, 6th Workshop on GRaphs in biomedicAl Image\n  anaLysis",
    "pdf_url": "http://arxiv.org/pdf/2410.00082v1",
    "published_date": "2024-09-30 17:28:38 UTC",
    "updated_date": "2024-09-30 17:28:38 UTC"
  },
  {
    "arxiv_id": "2410.00081v3",
    "title": "From homeostasis to resource sharing: Biologically and economically aligned multi-objective multi-agent AI safety benchmarks",
    "authors": [
      "Roland Pihlakas",
      "Joel PyykkÃ¶"
    ],
    "abstract": "Developing safe, aligned agentic AI systems requires comprehensive empirical\ntesting, yet many existing benchmarks neglect crucial themes aligned with\nbiology and economics, both time-tested fundamental sciences describing our\nneeds and preferences. To address this gap, the present work focuses on\nintroducing biologically and economically motivated themes that have been\nneglected in current mainstream discussions on AI safety - namely a set of\nmulti-objective, multi-agent alignment benchmarks that emphasize homeostasis\nfor bounded and biological objectives, diminishing returns for unbounded,\ninstrumental, and business objectives, sustainability principle, and resource\nsharing. We implemented eight main benchmark environments on the above themes,\nto illustrate key pitfalls and challenges in agentic AI-s, such as unboundedly\nmaximizing a homeostatic objective, over-optimizing one objective at the\nexpense of others, neglecting safety constraints, or depleting shared\nresources.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "20 pages, 13 figures, 1 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.00081v3",
    "published_date": "2024-09-30 17:24:21 UTC",
    "updated_date": "2025-03-04 16:42:06 UTC"
  },
  {
    "arxiv_id": "2409.20524v1",
    "title": "Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource",
    "authors": [
      "Pablo Ortega",
      "Jordi Luque",
      "Luis Lamiable",
      "Rodrigo LÃ³pez",
      "Richard Benjamins"
    ],
    "abstract": "Human language, while aimed at conveying meaning, inherently carries\nambiguity. It poses challenges for speech and language processing, but also\nserves crucial communicative functions. Efficiently solve ambiguity is both a\ndesired and a necessary characteristic. The lexical meaning of a word in\ncontext can be determined automatically by Word Sense Disambiguation (WSD)\nalgorithms that rely on external knowledge often limited and biased toward\nEnglish. When adapting content to other languages, automated translations are\nfrequently inaccurate and a high degree of expert human validation is necessary\nto ensure both accuracy and understanding. The current study addresses previous\nlimitations by introducing a new resource for Spanish WSD. It includes a sense\ninventory and a lexical dataset sourced from the Diccionario de la Lengua\nEspa\\~nola which is maintained by the Real Academia Espa\\~nola. We also review\ncurrent resources for Spanish and report metrics on them by a state-of-the-art\nsystem.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.20524v1",
    "published_date": "2024-09-30 17:22:33 UTC",
    "updated_date": "2024-09-30 17:22:33 UTC"
  },
  {
    "arxiv_id": "2409.20521v1",
    "title": "Upper and Lower Bounds for Distributionally Robust Off-Dynamics Reinforcement Learning",
    "authors": [
      "Zhishuai Liu",
      "Weixin Wang",
      "Pan Xu"
    ],
    "abstract": "We study off-dynamics Reinforcement Learning (RL), where the policy training\nand deployment environments are different. To deal with this environmental\nperturbation, we focus on learning policies robust to uncertainties in\ntransition dynamics under the framework of distributionally robust Markov\ndecision processes (DRMDPs), where the nominal and perturbed dynamics are\nlinear Markov Decision Processes. We propose a novel algorithm We-DRIVE-U that\nenjoys an average suboptimality $\\widetilde{\\mathcal{O}}\\big({d H \\cdot \\min\n\\{1/{\\rho}, H\\}/\\sqrt{K} }\\big)$, where $K$ is the number of episodes, $H$ is\nthe horizon length, $d$ is the feature dimension and $\\rho$ is the uncertainty\nlevel. This result improves the state-of-the-art by\n$\\mathcal{O}(dH/\\min\\{1/\\rho,H\\})$. We also construct a novel hard instance and\nderive the first information-theoretic lower bound in this setting, which\nindicates our algorithm is near-optimal up to $\\mathcal{O}(\\sqrt{H})$ for any\nuncertainty level $\\rho\\in(0,1]$. Our algorithm also enjoys a 'rare-switching'\ndesign, and thus only requires $\\mathcal{O}(dH\\log(1+H^2K))$ policy switches\nand $\\mathcal{O}(d^2H\\log(1+H^2K))$ calls for oracle to solve dual optimization\nproblems, which significantly improves the computational efficiency of existing\nalgorithms for DRMDPs, whose policy switch and oracle complexities are both\n$\\mathcal{O}(K)$.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "48 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.20521v1",
    "published_date": "2024-09-30 17:21:15 UTC",
    "updated_date": "2024-09-30 17:21:15 UTC"
  },
  {
    "arxiv_id": "2409.20517v1",
    "title": "SMLE: Safe Machine Learning via Embedded Overapproximation",
    "authors": [
      "Matteo Francobaldi",
      "Michele Lombardi"
    ],
    "abstract": "Despite the extent of recent advances in Machine Learning (ML) and Neural\nNetworks, providing formal guarantees on the behavior of these systems is still\nan open problem, and a crucial requirement for their adoption in regulated or\nsafety-critical scenarios. We consider the task of training differentiable ML\nmodels guaranteed to satisfy designer-chosen properties, stated as input-output\nimplications. This is very challenging, due to the computational complexity of\nrigorously verifying and enforcing compliance in modern neural models. We\nprovide an innovative approach based on three components: 1) a general, simple\narchitecture enabling efficient verification with a conservative semantic; 2) a\nrigorous training algorithm based on the Projected Gradient Method; 3) a\nformulation of the problem of searching for strong counterexamples. The\nproposed framework, being only marginally affected by model complexity, scales\nwell to practical applications, and produces models that provide full property\nsatisfaction guarantees. We evaluate our approach on properties defined by\nlinear inequalities in regression, and on mutually exclusive classes in\nmultilabel classification. Our approach is competitive with a baseline that\nincludes property enforcement during preprocessing, i.e. on the training data,\nas well as during postprocessing, i.e. on the model predictions. Finally, our\ncontributions establish a framework that opens up multiple research directions\nand potential improvements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20517v1",
    "published_date": "2024-09-30 17:19:57 UTC",
    "updated_date": "2024-09-30 17:19:57 UTC"
  },
  {
    "arxiv_id": "2410.12807v1",
    "title": "A Hierarchical conv-LSTM and LLM Integrated Model for Holistic Stock Forecasting",
    "authors": [
      "Arya Chakraborty",
      "Auhona Basu"
    ],
    "abstract": "The financial domain presents a complex environment for stock market\nprediction, characterized by volatile patterns and the influence of\nmultifaceted data sources. Traditional models have leveraged either\nConvolutional Neural Networks (CNN) for spatial feature extraction or Long\nShort-Term Memory (LSTM) networks for capturing temporal dependencies, with\nlimited integration of external textual data. This paper proposes a novel\nTwo-Level Conv-LSTM Neural Network integrated with a Large Language Model (LLM)\nfor comprehensive stock advising. The model harnesses the strengths of\nConv-LSTM for analyzing time-series data and LLM for processing and\nunderstanding textual information from financial news, social media, and\nreports. In the first level, convolutional layers are employed to identify\nlocal patterns in historical stock prices and technical indicators, followed by\nLSTM layers to capture the temporal dynamics. The second level integrates the\noutput with an LLM that analyzes sentiment and contextual information from\ntextual data, providing a holistic view of market conditions. The combined\napproach aims to improve prediction accuracy and provide contextually rich\nstock advising.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG",
      "I.2.0; I.2.1"
    ],
    "primary_category": "q-fin.ST",
    "comment": "8 pages, 2 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12807v1",
    "published_date": "2024-09-30 17:04:42 UTC",
    "updated_date": "2024-09-30 17:04:42 UTC"
  },
  {
    "arxiv_id": "2409.20503v2",
    "title": "What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach",
    "authors": [
      "Xingfang Wu",
      "Heng Li",
      "Foutse Khomh"
    ],
    "abstract": "Log data are generated from logging statements in the source code, providing\ninsights into the execution processes of software applications and systems.\nState-of-the-art log-based anomaly detection approaches typically leverage deep\nlearning models to capture the semantic or sequential information in the log\ndata and detect anomalous runtime behaviors. However, the impacts of these\ndifferent types of information are not clear. In addition, most existing\napproaches ignore the timestamps in log data, which can potentially provide\nfine-grained sequential and temporal information. In this work, we propose a\nconfigurable Transformer-based anomaly detection model that can capture the\nsemantic, sequential, and temporal information in the log data and allows us to\nconfigure the different types of information as the model's features.\nAdditionally, we train and evaluate the proposed model using log sequences of\ndifferent lengths, thus overcoming the constraint of existing methods that rely\non fixed-length or time-windowed log sequences as inputs. With the proposed\nmodel, we conduct a series of experiments with different combinations of input\nfeatures to evaluate the roles of different types of information in anomaly\ndetection. The model can attain competitive and consistently stable performance\ncompared to the baselines when presented with log sequences of varying lengths.\nThe results indicate that the event occurrence information plays a key role in\nidentifying anomalies, while the impact of the sequential and temporal\ninformation is not significant for anomaly detection on the studied public\ndatasets. On the other hand, the findings also reveal the simplicity of the\nstudied public datasets and highlight the importance of constructing new\ndatasets that contain different types of anomalies to better evaluate the\nperformance of anomaly detection models.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.20503v2",
    "published_date": "2024-09-30 17:03:13 UTC",
    "updated_date": "2025-03-11 01:55:49 UTC"
  },
  {
    "arxiv_id": "2409.20502v1",
    "title": "COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models",
    "authors": [
      "Divyanshu Daiya",
      "Damon Conover",
      "Aniket Bera"
    ],
    "abstract": "We propose a novel framework COLLAGE for generating collaborative\nagent-object-agent interactions by leveraging large language models (LLMs) and\nhierarchical motion-specific vector-quantized variational autoencoders\n(VQ-VAEs). Our model addresses the lack of rich datasets in this domain by\nincorporating the knowledge and reasoning abilities of LLMs to guide a\ngenerative diffusion model. The hierarchical VQ-VAE architecture captures\ndifferent motion-specific characteristics at multiple levels of abstraction,\navoiding redundant concepts and enabling efficient multi-resolution\nrepresentation. We introduce a diffusion model that operates in the latent\nspace and incorporates LLM-generated motion planning cues to guide the\ndenoising process, resulting in prompt-specific motion generation with greater\ncontrol and diversity. Experimental results on the CORE-4D, and InterHuman\ndatasets demonstrate the effectiveness of our approach in generating realistic\nand diverse collaborative human-object-human interactions, outperforming\nstate-of-the-art methods. Our work opens up new possibilities for modeling\ncomplex interactions in various domains, such as robotics, graphics and\ncomputer vision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.20502v1",
    "published_date": "2024-09-30 17:02:13 UTC",
    "updated_date": "2024-09-30 17:02:13 UTC"
  },
  {
    "arxiv_id": "2410.00079v1",
    "title": "Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface",
    "authors": [
      "Wenyue Hua",
      "Mengting Wan",
      "Shashank Vadrevu",
      "Ryan Nadel",
      "Yongfeng Zhang",
      "Chi Wang"
    ],
    "abstract": "Agents, as user-centric tools, are increasingly deployed for human task\ndelegation, assisting with a broad spectrum of requests by generating thoughts,\nengaging with user proxies, and producing action plans. However, agents based\non large language models (LLMs) often face substantial planning latency due to\ntwo primary factors: the efficiency limitations of the underlying LLMs due to\ntheir large size and high demand, and the structural complexity of the agents\ndue to the extensive generation of intermediate thoughts to produce the final\noutput. Given that inefficiency in service provision can undermine the value of\nautomation for users, this paper presents a human-centered efficient agent\nplanning method -- Interactive Speculative Planning -- aiming at enhancing the\nefficiency of agent planning through both system design and human-AI\ninteraction. Our approach advocates for the co-design of the agent system and\nuser interface, underscoring the importance of an agent system that can fluidly\nmanage user interactions and interruptions. By integrating human interruptions\nas a fundamental component of the system, we not only make it more user-centric\nbut also expedite the entire process by leveraging human-in-the-loop\ninteractions to provide accurate intermediate steps. Code and data will be\nreleased.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "27 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.00079v1",
    "published_date": "2024-09-30 16:52:51 UTC",
    "updated_date": "2024-09-30 16:52:51 UTC"
  },
  {
    "arxiv_id": "2409.20483v1",
    "title": "RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations",
    "authors": [
      "Johannes Kruse",
      "Kasper Lindskow",
      "Saikishore Kalloori",
      "Marco Polignano",
      "Claudio Pomo",
      "Abhishek Srivastava",
      "Anshuk Uppal",
      "Michael Riis Andersen",
      "Jes Frellsen"
    ],
    "abstract": "The RecSys Challenge 2024 aims to advance news recommendation by addressing\nboth the technical and normative challenges inherent in designing effective and\nresponsible recommender systems for news publishing. This paper describes the\nchallenge, including its objectives, problem setting, and the dataset provided\nby the Danish news publishers Ekstra Bladet and JP/Politikens Media Group\n(\"Ekstra Bladet\"). The challenge explores the unique aspects of news\nrecommendation, such as modeling user preferences based on behavior, accounting\nfor the influence of the news agenda on user interests, and managing the rapid\ndecay of news items. Additionally, the challenge embraces normative\ncomplexities, investigating the effects of recommender systems on news flow and\ntheir alignment with editorial values. We summarize the challenge setup,\ndataset characteristics, and evaluation metrics. Finally, we announce the\nwinners and highlight their contributions. The dataset is available at:\nhttps://recsys.eb.dk.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "5 pages, 3 tables, RecSys' 24",
    "pdf_url": "http://arxiv.org/pdf/2409.20483v1",
    "published_date": "2024-09-30 16:42:57 UTC",
    "updated_date": "2024-09-30 16:42:57 UTC"
  },
  {
    "arxiv_id": "2410.12806v1",
    "title": "Interpretable Rule-Based System for Radar-Based Gesture Sensing: Enhancing Transparency and Personalization in AI",
    "authors": [
      "Sarah Seifi",
      "Tobias Sukianto",
      "Cecilia Carbonelli",
      "Lorenzo Servadei",
      "Robert Wille"
    ],
    "abstract": "The increasing demand in artificial intelligence (AI) for models that are\nboth effective and explainable is critical in domains where safety and trust\nare paramount. In this study, we introduce MIRA, a transparent and\ninterpretable multi-class rule-based algorithm tailored for radar-based gesture\ndetection. Addressing the critical need for understandable AI, MIRA enhances\nuser trust by providing insight into its decision-making process. We showcase\nthe system's adaptability through personalized rule sets that calibrate to\nindividual user behavior, offering a user-centric AI experience. Alongside\npresenting a novel multi-class classification architecture, we share an\nextensive frequency-modulated continuous wave radar gesture dataset and\nevidence of the superior interpretability of our system through comparative\nanalyses. Our research underscores MIRA's ability to deliver both high\ninterpretability and performance and emphasizes the potential for broader\nadoption of interpretable AI in safety-critical applications.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted at the 21st European Radar Conference, 4 pages, 2 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.12806v1",
    "published_date": "2024-09-30 16:40:27 UTC",
    "updated_date": "2024-09-30 16:40:27 UTC"
  },
  {
    "arxiv_id": "2409.20467v1",
    "title": "A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media",
    "authors": [
      "Dung Ha Nguyen",
      "Anh Thi Hoang Nguyen",
      "Kiet Van Nguyen"
    ],
    "abstract": "This study introduces an innovative automatic labeling framework to address\nthe challenges of lexical normalization in social media texts for low-resource\nlanguages like Vietnamese. Social media data is rich and diverse, but the\nevolving and varied language used in these contexts makes manual labeling\nlabor-intensive and expensive. To tackle these issues, we propose a framework\nthat integrates semi-supervised learning with weak supervision techniques. This\napproach enhances the quality of training dataset and expands its size while\nminimizing manual labeling efforts. Our framework automatically labels raw\ndata, converting non-standard vocabulary into standardized forms, thereby\nimproving the accuracy and consistency of the training data. Experimental\nresults demonstrate the effectiveness of our weak supervision framework in\nnormalizing Vietnamese text, especially when utilizing Pre-trained Language\nModels. The proposed framework achieves an impressive F1-score of 82.72% and\nmaintains vocabulary integrity with an accuracy of up to 99.22%. Additionally,\nit effectively handles undiacritized text under various conditions. This\nframework significantly enhances natural language normalization quality and\nimproves the accuracy of various NLP tasks, leading to an average accuracy\nincrease of 1-3%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20467v1",
    "published_date": "2024-09-30 16:26:40 UTC",
    "updated_date": "2024-09-30 16:26:40 UTC"
  },
  {
    "arxiv_id": "2409.20449v2",
    "title": "Linear Projections of Teacher Embeddings for Few-Class Distillation",
    "authors": [
      "Noel Loo",
      "Fotis Iliopoulos",
      "Wei Hu",
      "Erik Vee"
    ],
    "abstract": "Knowledge Distillation (KD) has emerged as a promising approach for\ntransferring knowledge from a larger, more complex teacher model to a smaller\nstudent model. Traditionally, KD involves training the student to mimic the\nteacher's output probabilities, while more advanced techniques have explored\nguiding the student to adopt the teacher's internal representations. Despite\nits widespread success, the performance of KD in binary classification and\nfew-class problems has been less satisfactory. This is because the information\nabout the teacher model's generalization patterns scales directly with the\nnumber of classes. Moreover, several sophisticated distillation methods may not\nbe universally applicable or effective for data types beyond Computer Vision.\nConsequently, effective distillation techniques remain elusive for a range of\nkey real-world applications, such as sentiment analysis, search query\nunderstanding, and advertisement-query relevance assessment. Taking these\nobservations into account, we introduce a novel method for distilling knowledge\nfrom the teacher's model representations, which we term Learning Embedding\nLinear Projections (LELP). Inspired by recent findings about the structure of\nfinal-layer representations, LELP works by identifying informative linear\nsubspaces in the teacher's embedding space, and splitting them into\npseudo-subclasses. The student model is then trained to replicate these\npseudo-classes. Our experimental evaluation on large-scale NLP benchmarks like\nAmazon Reviews and Sentiment140 demonstrate the LELP is consistently\ncompetitive with, and typically superior to, existing state-of-the-art\ndistillation algorithms for binary and few-class problems, where most KD\nmethods suffer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20449v2",
    "published_date": "2024-09-30 16:07:34 UTC",
    "updated_date": "2024-10-02 02:36:30 UTC"
  },
  {
    "arxiv_id": "2410.03730v2",
    "title": "Teuken-7B-Base & Teuken-7B-Instruct: Towards European LLMs",
    "authors": [
      "Mehdi Ali",
      "Michael Fromm",
      "Klaudia Thellmann",
      "Jan Ebert",
      "Alexander Arno Weber",
      "Richard Rutmann",
      "Charvi Jain",
      "Max LÃ¼bbering",
      "Daniel Steinigen",
      "Johannes Leveling",
      "Katrin Klug",
      "Jasper Schulze Buschhoff",
      "Lena Jurkschat",
      "Hammam Abdelwahab",
      "Benny JÃ¶rg Stein",
      "Karl-Heinz Sylla",
      "Pavel Denisov",
      "Nicolo' Brandizzi",
      "Qasid Saleem",
      "Anirban Bhowmick",
      "Lennard Helmer",
      "Chelsea John",
      "Pedro Ortiz Suarez",
      "Malte Ostendorff",
      "Alex Jude",
      "Lalith Manjunath",
      "Samuel Weinbach",
      "Carolin Penke",
      "Oleg Filatov",
      "Shima Asaadi",
      "Fabio Barth",
      "Rafet Sifa",
      "Fabian KÃ¼ch",
      "Andreas Herten",
      "RenÃ© JÃ¤kel",
      "Georg Rehm",
      "Stefan Kesselheim",
      "Joachim KÃ¶hler",
      "Nicolas Flores-Herr"
    ],
    "abstract": "We present two multilingual LLMs designed to embrace Europe's linguistic\ndiversity by supporting all 24 official languages of the European Union.\nTrained on a dataset comprising around 60% non-English data and utilizing a\ncustom multilingual tokenizer, our models address the limitations of existing\nLLMs that predominantly focus on English or a few high-resource languages. We\ndetail the models' development principles, i.e., data composition, tokenizer\noptimization, and training methodologies. The models demonstrate competitive\nperformance across multilingual benchmarks, as evidenced by their performance\non European versions of ARC, HellaSwag, MMLU, and TruthfulQA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03730v2",
    "published_date": "2024-09-30 16:05:38 UTC",
    "updated_date": "2024-10-15 17:09:40 UTC"
  },
  {
    "arxiv_id": "2409.20447v1",
    "title": "POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator",
    "authors": [
      "Eugenio Lomurno",
      "Samuele Mariani",
      "Matteo Monti",
      "Matteo Matteucci"
    ],
    "abstract": "Neural Architecture Search (NAS) automates neural network design, reducing\ndependence on human expertise. While NAS methods are computationally intensive\nand dataset-specific, auxiliary predictors reduce the models needing training,\ndecreasing search time. This strategy is used to generate architectures\nsatisfying multiple computational constraints. Recently, Transferable NAS has\nemerged, generalizing the search process from dataset-dependent to\ntask-dependent. In this field, DiffusionNAG is a state-of-the-art method. This\ndiffusion-based approach streamlines computation, generating architectures\noptimized for accuracy on unseen datasets without further adaptation. However,\nby focusing solely on accuracy, DiffusionNAG overlooks other crucial objectives\nlike model complexity, computational efficiency, and inference latency --\nfactors essential for deploying models in resource-constrained environments.\nThis paper introduces the Pareto-Optimal Many-Objective Neural Architecture\nGenerator (POMONAG), extending DiffusionNAG via a many-objective diffusion\nprocess. POMONAG simultaneously considers accuracy, number of parameters,\nmultiply-accumulate operations (MACs), and inference latency. It integrates\nPerformance Predictor models to estimate these metrics and guide diffusion\ngradients. POMONAG's optimization is enhanced by expanding its training\nMeta-Dataset, applying Pareto Front Filtering, and refining embeddings for\nconditional generation. These enhancements enable POMONAG to generate\nPareto-optimal architectures that outperform the previous state-of-the-art in\nperformance and efficiency. Results were validated on two search spaces --\nNASBench201 and MobileNetV3 -- and evaluated across 15 image classification\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20447v1",
    "published_date": "2024-09-30 16:05:29 UTC",
    "updated_date": "2024-09-30 16:05:29 UTC"
  },
  {
    "arxiv_id": "2409.20427v2",
    "title": "Sufficient and Necessary Explanations (and What Lies in Between)",
    "authors": [
      "Beepul Bharti",
      "Paul Yi",
      "Jeremias Sulam"
    ],
    "abstract": "As complex machine learning models continue to find applications in\nhigh-stakes decision-making scenarios, it is crucial that we can explain and\nunderstand their predictions. Post-hoc explanation methods provide useful\ninsights by identifying important features in an input $\\mathbf{x}$ with\nrespect to the model output $f(\\mathbf{x})$. In this work, we formalize and\nstudy two precise notions of feature importance for general machine learning\nmodels: sufficiency and necessity. We demonstrate how these two types of\nexplanations, albeit intuitive and simple, can fall short in providing a\ncomplete picture of which features a model finds important. To this end, we\npropose a unified notion of importance that circumvents these limitations by\nexploring a continuum along a necessity-sufficiency axis. Our unified notion,\nwe show, has strong ties to other popular definitions of feature importance,\nlike those based on conditional independence and game-theoretic quantities like\nShapley values. Crucially, we demonstrate how a unified perspective allows us\nto detect important features that could be missed by either of the previous\napproaches alone.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20427v2",
    "published_date": "2024-09-30 15:50:57 UTC",
    "updated_date": "2024-10-15 14:04:35 UTC"
  },
  {
    "arxiv_id": "2409.20424v1",
    "title": "World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering",
    "authors": [
      "Jiacong Wang",
      "Bohong Wu",
      "Haiyong Jiang",
      "Xun Zhou",
      "Xin Xiao",
      "Haoyuan Guo",
      "Jun Xiao"
    ],
    "abstract": "Recent advances in Vision-Language Models (VLMs) and the scarcity of\nhigh-quality multi-modal alignment data have inspired numerous researches on\nsynthetic VLM data generation. The conventional norm in VLM data construction\nuses a mixture of specialists in caption and OCR, or stronger VLM APIs and\nexpensive human annotation. In this paper, we present World to Code (W2C), a\nmeticulously curated multi-modal data construction pipeline that organizes the\nfinal generation output into a Python code format. The pipeline leverages the\nVLM itself to extract cross-modal information via different prompts and filter\nthe generated outputs again via a consistency filtering strategy. Experiments\nhave demonstrated the high quality of W2C by improving various existing visual\nquestion answering and visual grounding benchmarks across different VLMs.\nFurther analysis also demonstrates that the new code parsing ability of VLMs\npresents better cross-modal equivalence than the commonly used detail caption\nability. Our code is available at\nhttps://github.com/foundation-multimodal-models/World2Code.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at EMNLP 2024 Main Conference, 16pages",
    "pdf_url": "http://arxiv.org/pdf/2409.20424v1",
    "published_date": "2024-09-30 15:49:54 UTC",
    "updated_date": "2024-09-30 15:49:54 UTC"
  },
  {
    "arxiv_id": "2409.20423v5",
    "title": "Stream-level flow matching with Gaussian processes",
    "authors": [
      "Ganchao Wei",
      "Li Ma"
    ],
    "abstract": "Flow matching (FM) is a family of training algorithms for fitting continuous\nnormalizing flows (CNFs). Conditional flow matching (CFM) exploits the fact\nthat the marginal vector field of a CNF can be learned by fitting least-squares\nregression to the conditional vector field specified given one or both ends of\nthe flow path. In this paper, we extend the CFM algorithm by defining\nconditional probability paths along ``streams'', instances of latent stochastic\npaths that connect data pairs of source and target, which are modeled with\nGaussian process (GP) distributions. The unique distributional properties of\nGPs help preserve the ``simulation-free\" nature of CFM training. We show that\nthis generalization of the CFM can effectively reduce the variance in the\nestimated marginal vector field at a moderate computational cost, thereby\nimproving the quality of the generated samples under common metrics.\nAdditionally, adopting the GP on the streams allows for flexibly linking\nmultiple correlated training data points (e.g., time series). We empirically\nvalidate our claim through both simulations and applications to image and\nneural time series data.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20423v5",
    "published_date": "2024-09-30 15:47:22 UTC",
    "updated_date": "2025-02-03 14:31:17 UTC"
  },
  {
    "arxiv_id": "2409.20412v1",
    "title": "Conformal Prediction for Dose-Response Models with Continuous Treatments",
    "authors": [
      "Jarne Verhaeghe",
      "Jef Jonkers",
      "Sofie Van Hoecke"
    ],
    "abstract": "Understanding the dose-response relation between a continuous treatment and\nthe outcome for an individual can greatly drive decision-making, particularly\nin areas like personalized drug dosing and personalized healthcare\ninterventions. Point estimates are often insufficient in these high-risk\nenvironments, highlighting the need for uncertainty quantification to support\ninformed decisions. Conformal prediction, a distribution-free and\nmodel-agnostic method for uncertainty quantification, has seen limited\napplication in continuous treatments or dose-response models. To address this\ngap, we propose a novel methodology that frames the causal dose-response\nproblem as a covariate shift, leveraging weighted conformal prediction. By\nincorporating propensity estimation, conformal predictive systems, and\nlikelihood ratios, we present a practical solution for generating prediction\nintervals for dose-response models. Additionally, our method approximates local\ncoverage for every treatment value by applying kernel functions as weights in\nweighted conformal prediction. Finally, we use a new synthetic benchmark\ndataset to demonstrate the significance of covariate shift assumptions in\nachieving robust prediction intervals for dose-response models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages main text, 8 pages references and appendix",
    "pdf_url": "http://arxiv.org/pdf/2409.20412v1",
    "published_date": "2024-09-30 15:40:54 UTC",
    "updated_date": "2024-09-30 15:40:54 UTC"
  },
  {
    "arxiv_id": "2409.20398v2",
    "title": "AUCSeg: AUC-oriented Pixel-level Long-tail Semantic Segmentation",
    "authors": [
      "Boyu Han",
      "Qianqian Xu",
      "Zhiyong Yang",
      "Shilong Bao",
      "Peisong Wen",
      "Yangbangyan Jiang",
      "Qingming Huang"
    ],
    "abstract": "The Area Under the ROC Curve (AUC) is a well-known metric for evaluating\ninstance-level long-tail learning problems. In the past two decades, many AUC\noptimization methods have been proposed to improve model performance under\nlong-tail distributions. In this paper, we explore AUC optimization methods in\nthe context of pixel-level long-tail semantic segmentation, a much more\ncomplicated scenario. This task introduces two major challenges for AUC\noptimization techniques. On one hand, AUC optimization in a pixel-level task\ninvolves complex coupling across loss terms, with structured inner-image and\npairwise inter-image dependencies, complicating theoretical analysis. On the\nother hand, we find that mini-batch estimation of AUC loss in this case\nrequires a larger batch size, resulting in an unaffordable space complexity. To\naddress these issues, we develop a pixel-level AUC loss function and conduct a\ndependency-graph-based theoretical analysis of the algorithm's generalization\nability. Additionally, we design a Tail-Classes Memory Bank (T-Memory Bank) to\nmanage the significant memory demand. Finally, comprehensive experiments across\nvarious benchmarks confirm the effectiveness of our proposed AUCSeg method. The\ncode is available at https://github.com/boyuh/AUCSeg.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20398v2",
    "published_date": "2024-09-30 15:31:02 UTC",
    "updated_date": "2024-10-10 13:31:39 UTC"
  },
  {
    "arxiv_id": "2409.20371v1",
    "title": "Frequency Adaptive Normalization For Non-stationary Time Series Forecasting",
    "authors": [
      "Weiwei Ye",
      "Songgaojun Deng",
      "Qiaosha Zou",
      "Ning Gui"
    ],
    "abstract": "Time series forecasting typically needs to address non-stationary data with\nevolving trend and seasonal patterns. To address the non-stationarity,\nreversible instance normalization has been recently proposed to alleviate\nimpacts from the trend with certain statistical measures, e.g., mean and\nvariance. Although they demonstrate improved predictive accuracy, they are\nlimited to expressing basic trends and are incapable of handling seasonal\npatterns. To address this limitation, this paper proposes a new instance\nnormalization solution, called frequency adaptive normalization (FAN), which\nextends instance normalization in handling both dynamic trend and seasonal\npatterns. Specifically, we employ the Fourier transform to identify\ninstance-wise predominant frequent components that cover most non-stationary\nfactors. Furthermore, the discrepancy of those frequency components between\ninputs and outputs is explicitly modeled as a prediction task with a simple MLP\nmodel. FAN is a model-agnostic method that can be applied to arbitrary\npredictive backbones. We instantiate FAN on four widely used forecasting models\nas the backbone and evaluate their prediction performance improvements on eight\nbenchmark datasets. FAN demonstrates significant performance advancement,\nachieving 7.76% ~ 37.90% average improvements in MSE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 Poster",
    "pdf_url": "http://arxiv.org/pdf/2409.20371v1",
    "published_date": "2024-09-30 15:07:16 UTC",
    "updated_date": "2024-09-30 15:07:16 UTC"
  },
  {
    "arxiv_id": "2409.20370v1",
    "title": "The Perfect Blend: Redefining RLHF with Mixture of Judges",
    "authors": [
      "Tengyu Xu",
      "Eryk Helenowski",
      "Karthik Abinav Sankararaman",
      "Di Jin",
      "Kaiyan Peng",
      "Eric Han",
      "Shaoliang Nie",
      "Chen Zhu",
      "Hejia Zhang",
      "Wenxuan Zhou",
      "Zhouhao Zeng",
      "Yun He",
      "Karishma Mandyam",
      "Arya Talabzadeh",
      "Madian Khabsa",
      "Gabriel Cohen",
      "Yuandong Tian",
      "Hao Ma",
      "Sinong Wang",
      "Han Fang"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has become the leading\napproach for fine-tuning large language models (LLM). However, RLHF has\nlimitations in multi-task learning (MTL) due to challenges of reward hacking\nand extreme multi-objective optimization (i.e., trade-off of multiple and/or\nsometimes conflicting objectives). Applying RLHF for MTL currently requires\ncareful tuning of the weights for reward model and data combinations. This is\noften done via human intuition and does not generalize. In this work, we\nintroduce a novel post-training paradigm which we called Constrained Generative\nPolicy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with\ncost-efficient constrained policy optimization with stratification, which can\nidentify the perfect blend in RLHF in a principled manner. It shows strong\nempirical results with theoretical guarantees, does not require extensive\nhyper-parameter tuning, and is plug-and-play in common post-training pipelines.\nTogether, this can detect and mitigate reward hacking behaviors while reaching\na pareto-optimal point across an extremely large number of objectives.\n  Our empirical evaluations demonstrate that CGPO significantly outperforms\nstandard RLHF algorithms like PPO and DPO across various tasks including\ngeneral chat, STEM questions, instruction following, and coding. Specifically,\nCGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in\nArena-Hard (STEM & reasoning), and consistent gains in other domains like math\nand coding. Notably, PPO, while commonly used, is prone to severe reward\nhacking in popular coding benchmarks, which CGPO successfully addresses. This\nbreakthrough in RLHF not only tackles reward hacking and extreme\nmulti-objective optimization challenges but also advances the state-of-the-art\nin aligning general-purpose LLMs for diverse applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "submitted to conference",
    "pdf_url": "http://arxiv.org/pdf/2409.20370v1",
    "published_date": "2024-09-30 15:06:53 UTC",
    "updated_date": "2024-09-30 15:06:53 UTC"
  },
  {
    "arxiv_id": "2409.20364v1",
    "title": "Efficient Driving Behavior Narration and Reasoning on Edge Device Using Large Language Models",
    "authors": [
      "Yizhou Huang",
      "Yihua Cheng",
      "Kezhi Wang"
    ],
    "abstract": "Deep learning architectures with powerful reasoning capabilities have driven\nsignificant advancements in autonomous driving technology. Large language\nmodels (LLMs) applied in this field can describe driving scenes and behaviors\nwith a level of accuracy similar to human perception, particularly in visual\ntasks. Meanwhile, the rapid development of edge computing, with its advantage\nof proximity to data sources, has made edge devices increasingly important in\nautonomous driving. Edge devices process data locally, reducing transmission\ndelays and bandwidth usage, and achieving faster response times. In this work,\nwe propose a driving behavior narration and reasoning framework that applies\nLLMs to edge devices. The framework consists of multiple roadside units, with\nLLMs deployed on each unit. These roadside units collect road data and\ncommunicate via 5G NSR/NR networks. Our experiments show that LLMs deployed on\nedge devices can achieve satisfactory response speeds. Additionally, we propose\na prompt strategy to enhance the narration and reasoning performance of the\nsystem. This strategy integrates multi-modal information, including\nenvironmental, agent, and motion data. Experiments conducted on the\nOpenDV-Youtube dataset demonstrate that our approach significantly improves\nperformance across both tasks.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted for possible journal publication",
    "pdf_url": "http://arxiv.org/pdf/2409.20364v1",
    "published_date": "2024-09-30 15:03:55 UTC",
    "updated_date": "2024-09-30 15:03:55 UTC"
  },
  {
    "arxiv_id": "2409.20361v2",
    "title": "Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference",
    "authors": [
      "Ke Yi",
      "Zengke Liu",
      "Jianwei Zhang",
      "Chengyuan Li",
      "Tong Zhang",
      "Junyang Lin",
      "Jingren Zhou"
    ],
    "abstract": "Large language models have demonstrated promising capabilities upon scaling\nup parameters. However, serving large language models incurs substantial\ncomputation and memory movement costs due to their large scale. Quantization\nmethods have been employed to reduce service costs and latency. Nevertheless,\noutliers in activations hinder the development of INT4 weight-activation\nquantization. Existing approaches separate outliers and normal values into two\nmatrices or migrate outliers from activations to weights, suffering from high\nlatency or accuracy degradation. Based on observing activations from large\nlanguage models, outliers can be classified into channel-wise and spike\noutliers. In this work, we propose Rotated Runtime Smooth (RRS), a\nplug-and-play activation smoother for quantization, consisting of Runtime\nSmooth and the Rotation operation. Runtime Smooth (RS) is introduced to\neliminate channel-wise outliers by smoothing activations with channel-wise\nmaximums during runtime. The rotation operation can narrow the gap between\nspike outliers and normal values, alleviating the effect of victims caused by\nchannel-wise smoothing. The proposed method outperforms the state-of-the-art\nmethod in the LLaMA and Qwen families and improves WikiText-2 perplexity from\n57.33 to 6.66 for INT4 inference.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20361v2",
    "published_date": "2024-09-30 14:59:22 UTC",
    "updated_date": "2024-11-11 12:45:51 UTC"
  },
  {
    "arxiv_id": "2409.20340v3",
    "title": "Enhancing GANs with Contrastive Learning-Based Multistage Progressive Finetuning SNN and RL-Based External Optimization",
    "authors": [
      "Osama Mustafa"
    ],
    "abstract": "Generative Adversarial Networks (GANs) have been at the forefront of image\nsynthesis, especially in medical fields like histopathology, where they help\naddress challenges such as data scarcity, patient privacy, and class imbalance.\nHowever, several inherent and domain-specific issues remain. For GANs, training\ninstability, mode collapse, and insufficient feedback from binary\nclassification can undermine performance. These challenges are particularly\npronounced with high-resolution histopathology images due to their complex\nfeature representation and high spatial detail. In response to these\nchallenges, this work proposes a novel framework integrating a contrastive\nlearning-based Multistage Progressive Finetuning Siamese Neural Network\n(MFT-SNN) with a Reinforcement Learning-based External Optimizer (RL-EO). The\nMFT-SNN improves feature similarity extraction in histopathology data, while\nthe RL-EO acts as a reward-based guide to balance GAN training, addressing mode\ncollapse and enhancing output quality. The proposed approach is evaluated\nagainst state-of-the-art (SOTA) GAN models and demonstrates superior\nperformance across multiple metrics.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20340v3",
    "published_date": "2024-09-30 14:39:56 UTC",
    "updated_date": "2024-10-26 09:51:39 UTC"
  },
  {
    "arxiv_id": "2409.20303v1",
    "title": "A Looming Replication Crisis in Evaluating Behavior in Language Models? Evidence and Solutions",
    "authors": [
      "LaurÃ¨ne Vaugrante",
      "Mathias Niepert",
      "Thilo Hagendorff"
    ],
    "abstract": "In an era where large language models (LLMs) are increasingly integrated into\na wide range of everyday applications, research into these models' behavior has\nsurged. However, due to the novelty of the field, clear methodological\nguidelines are lacking. This raises concerns about the replicability and\ngeneralizability of insights gained from research on LLM behavior. In this\nstudy, we discuss the potential risk of a replication crisis and support our\nconcerns with a series of replication experiments focused on prompt engineering\ntechniques purported to influence reasoning abilities in LLMs. We tested\nGPT-3.5, GPT-4o, Gemini 1.5 Pro, Claude 3 Opus, Llama 3-8B, and Llama 3-70B, on\nthe chain-of-thought, EmotionPrompting, ExpertPrompting, Sandbagging, as well\nas Re-Reading prompt engineering techniques, using manually double-checked\nsubsets of reasoning benchmarks including CommonsenseQA, CRT, NumGLUE,\nScienceQA, and StrategyQA. Our findings reveal a general lack of statistically\nsignificant differences across nearly all techniques tested, highlighting,\namong others, several methodological weaknesses in previous research. We\npropose a forward-looking approach that includes developing robust\nmethodologies for evaluating LLMs, establishing sound benchmarks, and designing\nrigorous experimental frameworks to ensure accurate and reliable assessments of\nmodel outputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20303v1",
    "published_date": "2024-09-30 14:00:34 UTC",
    "updated_date": "2024-09-30 14:00:34 UTC"
  },
  {
    "arxiv_id": "2409.20302v2",
    "title": "OM4OV: Leveraging Ontology Matching for Ontology Versioning",
    "authors": [
      "Zhangcheng Qiang",
      "Kerry Taylor",
      "Weiqing Wang"
    ],
    "abstract": "Due to the dynamic nature of the semantic web, ontology version control is\nrequired to capture time-varying information, most importantly for widely-used\nontologies. Despite the long-standing recognition of ontology versioning (OV)\nas a crucial component for efficient ontology management, the growing size of\nontologies and accumulating errors caused by manual labour overwhelm current OV\napproaches. In this paper, we propose yet another approach to performing OV\nusing existing ontology matching (OM) techniques and systems. We introduce a\nunified OM4OV pipeline. From an OM perspective, we reconstruct a new task\nformulation, measurement, and testbed for OV tasks. Reusing the prior\nalignment(s) from OM, we propose a pipeline optimisation method called\ncross-reference (CR) mechanism to improve overall OV performance. We\nexperimentally validate the OM4OV pipeline and the cross-reference mechanism in\nmodified Ontology Alignment Evaluation Initiative (OAEI) datasets. We also\ndiscuss the insights on OM used for OV tasks, where some false mappings\ndetected by OV systems are not actually false.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2409.20302v2",
    "published_date": "2024-09-30 14:00:04 UTC",
    "updated_date": "2024-11-24 23:38:31 UTC"
  },
  {
    "arxiv_id": "2409.20274v1",
    "title": "Probabilistic Answer Set Programming with Discrete and Continuous Random Variables",
    "authors": [
      "Damiano Azzolini",
      "Fabrizio Riguzzi"
    ],
    "abstract": "Probabilistic Answer Set Programming under the credal semantics (PASP)\nextends Answer Set Programming with probabilistic facts that represent\nuncertain information. The probabilistic facts are discrete with Bernoulli\ndistributions. However, several real-world scenarios require a combination of\nboth discrete and continuous random variables. In this paper, we extend the\nPASP framework to support continuous random variables and propose Hybrid\nProbabilistic Answer Set Programming (HPASP). Moreover, we discuss, implement,\nand assess the performance of two exact algorithms based on projected answer\nset enumeration and knowledge compilation and two approximate algorithms based\non sampling. Empirical results, also in line with known theoretical results,\nshow that exact inference is feasible only for small instances, but knowledge\ncompilation has a huge positive impact on the performance. Sampling allows\nhandling larger instances, but sometimes requires an increasing amount of\nmemory. Under consideration in Theory and Practice of Logic Programming (TPLP).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)",
    "pdf_url": "http://arxiv.org/pdf/2409.20274v1",
    "published_date": "2024-09-30 13:24:42 UTC",
    "updated_date": "2024-09-30 13:24:42 UTC"
  },
  {
    "arxiv_id": "2409.20260v1",
    "title": "Computer-mediated therapies for stroke rehabilitation: a systematic review and meta-Analysis",
    "authors": [
      "Stanley Mugisha. Mirko Job. Matteo Zoppi",
      "Marco Testa",
      "Rezia Molfino"
    ],
    "abstract": "OBJECTIVE: To evaluate the efficacy of different forms of virtual reality\n(VR) treatments as either immersive virtual reality (IVR) or non-immersive\nvirtual reality (NIVR) in comparison to conventional therapy (CT) in improving\nphysical and psychological status among stroke patients. METHODS: The\nliterature search was conducted on seven databases. ACM Digital Library,\nMedline (via PubMed), Cochrane, IEEE Xplore, Web of Science, and Scopus. The\neffect sizes of the main outcomes were calculated using Cohen's d. Pooled\nresults were used to present an overall estimate of the treatment effect using\na random-effects model. RESULTS: A total of 22 randomized controlled trials\nwere evaluated. 3 trials demonstrated that immersive virtual reality improved\nupper limb activity, function and activity of daily life in a way comparable to\nCT. 18 trials showed that NIVR had similar benefits to CT for upper limb\nactivity and function, balance and mobility, activities of daily living and\nparticipation. A comparison between the different forms of VR showed that IVR\nmay be more beneficial than NIVR for upper limb training and activities of\ndaily life. CONCLUSIONS: This study found out that IVR therapies may be more\neffective than NIVR but not CT to improve upper limb activity, function, and\ndaily life activities. However, there is no evidence of the durability of IVR\ntreatment. More research involving studies with larger samples is needed to\nassess the long-term effects and promising benefits of immersive virtual\nreality technology.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.HC",
      "cs.MM",
      "J.3.2"
    ],
    "primary_category": "physics.med-ph",
    "comment": "32 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.20260v1",
    "published_date": "2024-09-30 12:50:46 UTC",
    "updated_date": "2024-09-30 12:50:46 UTC"
  },
  {
    "arxiv_id": "2409.20259v1",
    "title": "Learning to Ground Existentially Quantified Goals",
    "authors": [
      "Martin Funkquist",
      "Simon StÃ¥hlberg",
      "Hector Geffner"
    ],
    "abstract": "Goal instructions for autonomous AI agents cannot assume that objects have\nunique names. Instead, objects in goals must be referred to by providing\nsuitable descriptions. However, this raises problems in both classical planning\nand generalized planning. The standard approach to handling existentially\nquantified goals in classical planning involves compiling them into a DNF\nformula that encodes all possible variable bindings and adding dummy actions to\nmap each DNF term into the new, dummy goal. This preprocessing is exponential\nin the number of variables. In generalized planning, the problem is different:\neven if general policies can deal with any initial situation and goal,\nexecuting a general policy requires the goal to be grounded to define a value\nfor the policy features. The problem of grounding goals, namely finding the\nobjects to bind the goal variables, is subtle: it is a generalization of\nclassical planning, which is a special case when there are no goal variables to\nbind, and constraint reasoning, which is a special case when there are no\nactions. In this work, we address the goal grounding problem with a novel\nsupervised learning approach. A GNN architecture, trained to predict the cost\nof partially quantified goals over small domain instances is tested on larger\ninstances involving more objects and different quantified goals. The proposed\narchitecture is evaluated experimentally over several planning domains where\ngeneralization is tested along several dimensions including the number of goal\nvariables and objects that can bind such variables. The scope of the approach\nis also discussed in light of the known relationship between GNNs and C2\nlogics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, Accepted at the 21st International Conference on Principles\n  of Knowledge Representation and Reasoning (KR2024) in the Reasoning,\n  Learning, and Decision Making track",
    "pdf_url": "http://arxiv.org/pdf/2409.20259v1",
    "published_date": "2024-09-30 12:49:27 UTC",
    "updated_date": "2024-09-30 12:49:27 UTC"
  },
  {
    "arxiv_id": "2409.20258v1",
    "title": "Inferring Preferences from Demonstrations in Multi-objective Reinforcement Learning",
    "authors": [
      "Junlin Lu",
      "Patrick Mannion",
      "Karl Mason"
    ],
    "abstract": "Many decision-making problems feature multiple objectives where it is not\nalways possible to know the preferences of a human or agent decision-maker for\ndifferent objectives. However, demonstrated behaviors from the decision-maker\nare often available. This research proposes a dynamic weight-based preference\ninference (DWPI) algorithm that can infer the preferences of agents acting in\nmulti-objective decision-making problems from demonstrations. The proposed\nalgorithm is evaluated on three multi-objective Markov decision processes: Deep\nSea Treasure, Traffic, and Item Gathering, and is compared to two existing\npreference inference algorithms. Empirical results demonstrate significant\nimprovements compared to the baseline algorithms, in terms of both time\nefficiency and inference accuracy. The DWPI algorithm maintains its performance\nwhen inferring preferences for sub-optimal demonstrations. Moreover, the DWPI\nalgorithm does not necessitate any interactions with the user during inference\n- only demonstrations are required. We provide a correctness proof and\ncomplexity analysis of the algorithm and statistically evaluate the performance\nunder different representation of demonstrations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Neural Comput & Applic (2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.20258v1",
    "published_date": "2024-09-30 12:49:10 UTC",
    "updated_date": "2024-09-30 12:49:10 UTC"
  },
  {
    "arxiv_id": "2409.20252v2",
    "title": "What is the Role of Large Language Models in the Evolution of Astronomy Research?",
    "authors": [
      "Morgan Fouesneau",
      "Ivelina G. Momcheva",
      "Urmila Chadayammuri",
      "Mariia Demianenko",
      "Antoine Dumont",
      "Raphael E. Hviding",
      "K. Angelique Kahle",
      "Nadiia Pulatova",
      "Bhavesh Rajpoot",
      "Marten B. Scheuck",
      "Rhys Seeburger",
      "Dmitry Semenov",
      "Jaime I. VillaseÃ±or"
    ],
    "abstract": "ChatGPT and other state-of-the-art large language models (LLMs) are rapidly\ntransforming multiple fields, offering powerful tools for a wide range of\napplications. These models, commonly trained on vast datasets, exhibit\nhuman-like text generation capabilities, making them useful for research tasks\nsuch as ideation, literature review, coding, drafting, and outreach. We\nconducted a study involving 13 astronomers at different career stages and\nresearch fields to explore LLM applications across diverse tasks over several\nmonths and to evaluate their performance in research-related activities. This\nwork was accompanied by an anonymous survey assessing participants' experiences\nand attitudes towards LLMs. We provide a detailed analysis of the tasks\nattempted and the survey answers, along with specific output examples. Our\nfindings highlight both the potential and limitations of LLMs in supporting\nresearch while also addressing general and research-specific ethical\nconsiderations. We conclude with a series of recommendations, emphasizing the\nneed for researchers to complement LLMs with critical thinking and domain\nexpertise, ensuring these tools serve as aids rather than substitutes for\nrigorous scientific inquiry.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "Paper submitted to RASTI. We share our experience, ethical and legal\n  concerns (5.3), and recommendations for individuals and journals (6.). We\n  welcome feedback",
    "pdf_url": "http://arxiv.org/pdf/2409.20252v2",
    "published_date": "2024-09-30 12:42:25 UTC",
    "updated_date": "2024-10-01 16:34:13 UTC"
  },
  {
    "arxiv_id": "2409.20247v1",
    "title": "Resource Allocation for Stable LLM Training in Mobile Edge Computing",
    "authors": [
      "Chang Liu",
      "Jun Zhao"
    ],
    "abstract": "As mobile devices increasingly become focal points for advanced applications,\nedge computing presents a viable solution to their inherent computational\nlimitations, particularly in deploying large language models (LLMs). However,\ndespite the advancements in edge computing, significant challenges remain in\nefficient training and deploying LLMs due to the computational demands and data\nprivacy concerns associated with these models. This paper explores a\ncollaborative training framework that integrates mobile users with edge servers\nto optimize resource allocation, thereby enhancing both performance and\nefficiency. Our approach leverages parameter-efficient fine-tuning (PEFT)\nmethods, allowing mobile users to adjust the initial layers of the LLM while\nedge servers handle the more demanding latter layers. Specifically, we\nformulate a multi-objective optimization problem to minimize the total energy\nconsumption and delay during training. We also address the common issue of\ninstability in model performance by incorporating stability enhancements into\nour objective function. Through novel fractional programming technique, we\nachieve a stationary point for the formulated problem. Simulations demonstrate\nthat our method reduces the energy consumption as well as the latency, and\nincreases the reliability of LLMs across various mobile settings.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.IT",
      "cs.SY",
      "eess.SY",
      "math.IT",
      "math.OC"
    ],
    "primary_category": "cs.DC",
    "comment": "This paper appears in the 2024 International Symposium on Theory,\n  Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile\n  Computing (MobiHoc)",
    "pdf_url": "http://arxiv.org/pdf/2409.20247v1",
    "published_date": "2024-09-30 12:36:27 UTC",
    "updated_date": "2024-09-30 12:36:27 UTC"
  },
  {
    "arxiv_id": "2409.20222v2",
    "title": "Beyond Prompts: Dynamic Conversational Benchmarking of Large Language Models",
    "authors": [
      "David Castillo-Bolado",
      "Joseph Davidson",
      "Finlay Gray",
      "Marek Rosa"
    ],
    "abstract": "We introduce a dynamic benchmarking system for conversational agents that\nevaluates their performance through a single, simulated, and lengthy\nuser$\\leftrightarrow$agent interaction. The interaction is a conversation\nbetween the user and agent, where multiple tasks are introduced and then\nundertaken concurrently. We context switch regularly to interleave the tasks,\nwhich constructs a realistic testing scenario in which we assess the Long-Term\nMemory, Continual Learning, and Information Integration capabilities of the\nagents. Results from both proprietary and open-source Large-Language Models\nshow that LLMs in general perform well on single-task interactions, but they\nstruggle on the same tasks when they are interleaved. Notably, short-context\nLLMs supplemented with an LTM system perform as well as or better than those\nwith larger contexts. Our benchmark suggests that there are other challenges\nfor LLMs responding to more natural interactions that contemporary benchmarks\nhave heretofore not been able to capture.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as a poster at NeurIPS D&B Track 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.20222v2",
    "published_date": "2024-09-30 12:01:29 UTC",
    "updated_date": "2024-10-11 11:32:16 UTC"
  },
  {
    "arxiv_id": "2409.20196v4",
    "title": "Melody-Guided Music Generation",
    "authors": [
      "Shaopeng Wei",
      "Manzhen Wei",
      "Haoyu Wang",
      "Yu Zhao",
      "Gang Kou"
    ],
    "abstract": "We present the Melody-Guided Music Generation (MG2) model, a novel approach\nusing melody to guide the text-to-music generation that, despite a simple\nmethod and limited resources, achieves excellent performance. Specifically, we\nfirst align the text with audio waveforms and their associated melodies using\nthe newly proposed Contrastive Language-Music Pretraining, enabling the learned\ntext representation fused with implicit melody information. Subsequently, we\ncondition the retrieval-augmented diffusion module on both text prompt and\nretrieved melody. This allows MG2 to generate music that reflects the content\nof the given text description, meantime keeping the intrinsic harmony under the\nguidance of explicit melody information. We conducted extensive experiments on\ntwo public datasets: MusicCaps and MusicBench. Surprisingly, the experimental\nresults demonstrate that the proposed MG2 model surpasses current open-source\ntext-to-music generation models, achieving this with fewer than 1/3 of the\nparameters or less than 1/200 of the training data compared to state-of-the-art\ncounterparts. Furthermore, we conducted comprehensive human evaluations\ninvolving three types of users and five perspectives, using newly designed\nquestionnaires to explore the potential real-world applications of MG2.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "16 pages, 8 figure, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.20196v4",
    "published_date": "2024-09-30 11:13:35 UTC",
    "updated_date": "2024-12-30 05:54:03 UTC"
  },
  {
    "arxiv_id": "2409.20195v2",
    "title": "Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT",
    "authors": [
      "Arunava Chakravarty",
      "Taha Emre",
      "Dmitrii Lachinov",
      "Antoine Rivail",
      "Hendrik Scholl",
      "Lars Fritsche",
      "Sobha Sivaprasad",
      "Daniel Rueckert",
      "Andrew Lotery",
      "Ursula Schmidt-Erfurth",
      "Hrvoje BogunoviÄ"
    ],
    "abstract": "Predicting future disease progression risk from medical images is challenging\ndue to patient heterogeneity, and subtle or unknown imaging biomarkers.\nMoreover, deep learning (DL) methods for survival analysis are susceptible to\nimage domain shifts across scanners. We tackle these issues in the task of\npredicting late dry Age-related Macular Degeneration (dAMD) onset from retinal\nOCT scans. We propose a novel DL method for survival prediction to jointly\npredict from the current scan a risk score, inversely related to\ntime-to-conversion, and the probability of conversion within a time interval\n$t$. It uses a family of parallel hyperplanes generated by parameterizing the\nbias term as a function of $t$. In addition, we develop unsupervised losses\nbased on intra-subject image pairs to ensure that risk scores increase over\ntime and that future conversion predictions are consistent with AMD stage\nprediction using actual scans of future visits. Such losses enable\ndata-efficient fine-tuning of the trained model on new unlabeled datasets\nacquired with a different scanner. Extensive evaluation on two large datasets\nacquired with different scanners resulted in a mean AUROCs of 0.82 for\nDataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24\nmonths.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted in MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.20195v2",
    "published_date": "2024-09-30 11:11:35 UTC",
    "updated_date": "2024-10-03 13:50:29 UTC"
  },
  {
    "arxiv_id": "2409.20192v1",
    "title": "Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing: Challenges, Risks, and Impact on Work",
    "authors": [
      "Samuel Kernan Freire",
      "Tianhao He",
      "Chaofan Wang",
      "Evangelos Niforatos",
      "Alessandro Bozzon"
    ],
    "abstract": "In the shift towards human-centered manufacturing, our two-year longitudinal\nstudy investigates the real-world impact of deploying Cognitive Assistants\n(CAs) in factories. The CAs were designed to facilitate knowledge sharing among\nfactory operators. Our investigation focused on smartphone-based voice\nassistants and LLM-powered chatbots, examining their usability and utility in a\nreal-world factory setting. Based on the qualitative feedback we collected\nduring the deployments of CAs at the factories, we conducted a thematic\nanalysis to investigate the perceptions, challenges, and overall impact on\nworkflow and knowledge sharing.\n  Our results indicate that while CAs have the potential to significantly\nimprove efficiency through knowledge sharing and quicker resolution of\nproduction issues, they also introduce concerns around workplace surveillance,\nthe types of knowledge that can be shared, and shortcomings compared to\nhuman-to-human knowledge sharing. Additionally, our findings stress the\nimportance of addressing privacy, knowledge contribution burdens, and tensions\nbetween factory operators and their managers.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "32 pages, 6 figures, 2 tables, under review",
    "pdf_url": "http://arxiv.org/pdf/2409.20192v1",
    "published_date": "2024-09-30 11:08:27 UTC",
    "updated_date": "2024-09-30 11:08:27 UTC"
  },
  {
    "arxiv_id": "2409.20187v1",
    "title": "Choosing DAG Models Using Markov and Minimal Edge Count in the Absence of Ground Truth",
    "authors": [
      "Joseph D. Ramsey",
      "Bryan Andrews",
      "Peter Spirtes"
    ],
    "abstract": "We give a novel nonparametric pointwise consistent statistical test (the\nMarkov Checker) of the Markov condition for directed acyclic graph (DAG) or\ncompleted partially directed acyclic graph (CPDAG) models given a dataset. We\nalso introduce the Cross-Algorithm Frugality Search (CAFS) for rejecting DAG\nmodels that either do not pass the Markov Checker test or that are not edge\nminimal. Edge minimality has been used previously by Raskutti and Uhler as a\nnonparametric simplicity criterion, though CAFS readily generalizes to other\nsimplicity conditions. Reference to the ground truth is not necessary for CAFS,\nso it is useful for finding causal structure learning algorithms and tuning\nparameter settings that output causal models that are approximately true from a\ngiven data set. We provide a software tool for this analysis that is suitable\nfor even quite large or dense models, provided a suitably fast pointwise\nconsistent test of conditional independence is available. In addition, we show\nin simulation that the CAFS procedure can pick approximately correct models\nwithout knowing the ground truth.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML",
      "68T37",
      "I.2.0; I.2.6; I.6.5"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 14 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2409.20187v1",
    "published_date": "2024-09-30 11:03:44 UTC",
    "updated_date": "2024-09-30 11:03:44 UTC"
  },
  {
    "arxiv_id": "2410.03728v5",
    "title": "Exploring QUIC Dynamics: A Large-Scale Dataset for Encrypted Traffic Analysis",
    "authors": [
      "Barak Gahtan",
      "Robert J. Shahla",
      "Alex M. Bronstein",
      "Reuven Cohen"
    ],
    "abstract": "The increasing adoption of the QUIC transport protocol has transformed\nencrypted web traffic, necessitating new methodologies for network analysis.\nHowever, existing datasets lack the scope, metadata, and decryption\ncapabilities required for robust benchmarking in encrypted traffic research. We\nintroduce VisQUIC, a large-scale dataset of 100,000 labeled QUIC traces from\nover 44,000 websites, collected over four months. Unlike prior datasets,\nVisQUIC provides SSL keys for controlled decryption, supports multiple QUIC\nimplementations (Chromium QUIC, Facebooks mvfst, Cloudflares quiche), and\nintroduces a novel image-based representation that enables machine\nlearning-driven encrypted traffic analysis. The dataset includes standardized\nbenchmarking tools, ensuring reproducibility. To demonstrate VisQUICs utility,\nwe present a benchmarking task for estimating HTTP/3 responses in encrypted\nQUIC traffic, achieving 97% accuracy using only observable packet features. By\npublicly releasing VisQUIC, we provide an open foundation for advancing\nencrypted traffic analysis, QUIC security research, and network monitoring.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "The dataset and the supplementary material can be provided upon\n  request",
    "pdf_url": "http://arxiv.org/pdf/2410.03728v5",
    "published_date": "2024-09-30 10:50:12 UTC",
    "updated_date": "2025-02-27 16:19:53 UTC"
  },
  {
    "arxiv_id": "2409.20174v1",
    "title": "Modelando procesos cognitivos de la lectura natural con GPT-2",
    "authors": [
      "Bruno Bianchi",
      "Alfredo Umfurer",
      "Juan Esteban Kamienkowski"
    ],
    "abstract": "The advancement of the Natural Language Processing field has enabled the\ndevelopment of language models with a great capacity for generating text. In\nrecent years, Neuroscience has been using these models to better understand\ncognitive processes. In previous studies, we found that models like Ngrams and\nLSTM networks can partially model Predictability when used as a co-variable to\nexplain readers' eye movements. In the present work, we further this line of\nresearch by using GPT-2 based models. The results show that this architecture\nachieves better outcomes than its predecessors.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "in Spanish language",
    "pdf_url": "http://arxiv.org/pdf/2409.20174v1",
    "published_date": "2024-09-30 10:34:32 UTC",
    "updated_date": "2024-09-30 10:34:32 UTC"
  },
  {
    "arxiv_id": "2409.20163v1",
    "title": "MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants",
    "authors": [
      "Zeyu Zhang",
      "Quanyu Dai",
      "Luyu Chen",
      "Zeren Jiang",
      "Rui Li",
      "Jieming Zhu",
      "Xu Chen",
      "Yi Xie",
      "Zhenhua Dong",
      "Ji-Rong Wen"
    ],
    "abstract": "LLM-based agents have been widely applied as personal assistants, capable of\nmemorizing information from user messages and responding to personal queries.\nHowever, there still lacks an objective and automatic evaluation on their\nmemory capability, largely due to the challenges in constructing reliable\nquestions and answers (QAs) according to user messages. In this paper, we\npropose MemSim, a Bayesian simulator designed to automatically construct\nreliable QAs from generated user messages, simultaneously keeping their\ndiversity and scalability. Specifically, we introduce the Bayesian Relation\nNetwork (BRNet) and a causal generation mechanism to mitigate the impact of LLM\nhallucinations on factual information, facilitating the automatic creation of\nan evaluation dataset. Based on MemSim, we generate a dataset in the daily-life\nscenario, named MemDaily, and conduct extensive experiments to assess the\neffectiveness of our approach. We also provide a benchmark for evaluating\ndifferent memory mechanisms in LLM-based agents with the MemDaily dataset. To\nbenefit the research community, we have released our project at\nhttps://github.com/nuster1128/MemSim.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 25 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2409.20163v1",
    "published_date": "2024-09-30 10:19:04 UTC",
    "updated_date": "2024-09-30 10:19:04 UTC"
  },
  {
    "arxiv_id": "2409.20149v1",
    "title": "1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models",
    "authors": [
      "Chanjun Park",
      "Hyunsoo Ha",
      "Jihoo Kim",
      "Yungi Kim",
      "Dahyun Kim",
      "Sukyung Lee",
      "Seonghoon Yang"
    ],
    "abstract": "In this paper, we propose the 1 Trillion Token Platform (1TT Platform), a\nnovel framework designed to facilitate efficient data sharing with a\ntransparent and equitable profit-sharing mechanism. The platform fosters\ncollaboration between data contributors, who provide otherwise non-disclosed\ndatasets, and a data consumer, who utilizes these datasets to enhance their own\nservices. Data contributors are compensated in monetary terms, receiving a\nshare of the revenue generated by the services of the data consumer. The data\nconsumer is committed to sharing a portion of the revenue with contributors,\naccording to predefined profit-sharing arrangements. By incorporating a\ntransparent profit-sharing paradigm to incentivize large-scale data sharing,\nthe 1TT Platform creates a collaborative environment to drive the advancement\nof NLP and LLM technologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20149v1",
    "published_date": "2024-09-30 09:55:39 UTC",
    "updated_date": "2024-09-30 09:55:39 UTC"
  },
  {
    "arxiv_id": "2409.20147v1",
    "title": "Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language",
    "authors": [
      "Vincent Beliveau",
      "Helene Kaas",
      "Martin Prener",
      "Claes N. Ladefoged",
      "Desmond Elliott",
      "Gitte M. Knudsen",
      "Lars H. Pinborg",
      "Melanie Ganz"
    ],
    "abstract": "Natural language processing (NLP) in the medical domain can underperform in\nreal-world applications involving small datasets in a non-English language with\nfew labeled samples and imbalanced classes. There is yet no consensus on how to\napproach this problem. We evaluated a set of NLP models including BERT-like\ntransformers, few-shot learning with sentence transformers (SetFit), and\nprompted large language models (LLM), using three datasets of radiology reports\non magnetic resonance images of epilepsy patients in Danish, a low-resource\nlanguage. Our results indicate that BERT-like models pretrained in the target\ndomain of radiology reports currently offer the optimal performances for this\nscenario. Notably, the SetFit and LLM models underperformed compared to\nBERT-like models, with LLM performing the worst. Importantly, none of the\nmodels investigated was sufficiently accurate to allow for text classification\nwithout any supervision. However, they show potential for data filtering, which\ncould reduce the amount of manual labeling required.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20147v1",
    "published_date": "2024-09-30 09:52:28 UTC",
    "updated_date": "2024-09-30 09:52:28 UTC"
  },
  {
    "arxiv_id": "2409.20130v1",
    "title": "Reevaluation of Inductive Link Prediction",
    "authors": [
      "Simon Ott",
      "Christian Meilicke",
      "Heiner Stuckenschmidt"
    ],
    "abstract": "Within this paper, we show that the evaluation protocol currently used for\ninductive link prediction is heavily flawed as it relies on ranking the true\nentity in a small set of randomly sampled negative entities. Due to the limited\nsize of the set of negatives, a simple rule-based baseline can achieve\nstate-of-the-art results, which simply ranks entities higher based on the\nvalidity of their type. As a consequence of these insights, we reevaluate\ncurrent approaches for inductive link prediction on several benchmarks using\nthe link prediction protocol usually applied to the transductive setting. As\nsome inductive methods suffer from scalability issues when evaluated in this\nsetting, we propose and apply additionally an improved sampling protocol, which\ndoes not suffer from the problem mentioned above. The results of our evaluation\ndiffer drastically from the results reported in so far.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in RuleML+RR 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.20130v1",
    "published_date": "2024-09-30 09:32:10 UTC",
    "updated_date": "2024-09-30 09:32:10 UTC"
  },
  {
    "arxiv_id": "2409.20094v1",
    "title": "Aggressive Post-Training Compression on Extremely Large Language Models",
    "authors": [
      "Zining Zhang",
      "Yao Chen",
      "Bingsheng He",
      "Zhenjie Zhang"
    ],
    "abstract": "The increasing size and complexity of Large Language Models (LLMs) pose\nchallenges for their deployment on personal computers and mobile devices.\nAggressive post-training model compression is necessary to reduce the models'\nsize, but it often results in significant accuracy loss. To address this\nchallenge, we propose a novel network pruning technology that utilizes over 0.7\nsparsity and less than 8 bits of quantization. Our approach enables the\ncompression of prevailing LLMs within a couple of hours while maintaining a\nrelatively small accuracy loss. In experimental evaluations, our method\ndemonstrates effectiveness and potential for practical deployment. By making\nLLMs available on domestic devices, our work can facilitate a new era of\nnatural language processing applications with wide-ranging impacts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20094v1",
    "published_date": "2024-09-30 08:47:17 UTC",
    "updated_date": "2024-09-30 08:47:17 UTC"
  },
  {
    "arxiv_id": "2409.20092v1",
    "title": "Continuous-Time Linear Positional Embedding for Irregular Time Series Forecasting",
    "authors": [
      "Byunghyun Kim",
      "Jae-Gil Lee"
    ],
    "abstract": "Irregularly sampled time series forecasting, characterized by non-uniform\nintervals, is prevalent in practical applications. However, previous research\nhave been focused on regular time series forecasting, typically relying on\ntransformer architectures. To extend transformers to handle irregular time\nseries, we tackle the positional embedding which represents the temporal\ninformation of the data. We propose CTLPE, a method learning a continuous\nlinear function for encoding temporal information. The two challenges of\nirregular time series, inconsistent observation patterns and irregular time\ngaps, are solved by learning a continuous-time function and concise\nrepresentation of position. Additionally, the linear continuous function is\nempirically shown superior to other continuous functions by learning a neural\ncontrolled differential equation-based positional embedding, and theoretically\nsupported with properties of ideal positional embedding. CTLPE outperforms\nexisting techniques across various irregularly-sampled time series datasets,\nshowcasing its enhanced efficacy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20092v1",
    "published_date": "2024-09-30 08:46:18 UTC",
    "updated_date": "2024-09-30 08:46:18 UTC"
  },
  {
    "arxiv_id": "2409.20064v2",
    "title": "Knowledge Discovery using Unsupervised Cognition",
    "authors": [
      "Alfredo Ibias",
      "Hector Antona",
      "Guillem Ramirez-Miranda",
      "Enric Guinovart"
    ],
    "abstract": "Knowledge discovery is key to understand and interpret a dataset, as well as\nto find the underlying relationships between its components. Unsupervised\nCognition is a novel unsupervised learning algorithm that focus on modelling\nthe learned data. This paper presents three techniques to perform knowledge\ndiscovery over an already trained Unsupervised Cognition model. Specifically,\nwe present a technique for pattern mining, a technique for feature selection\nbased on the previous pattern mining technique, and a technique for\ndimensionality reduction based on the previous feature selection technique. The\nfinal goal is to distinguish between relevant and irrelevant features and use\nthem to build a model from which to extract meaningful patterns. We evaluated\nour proposals with empirical experiments and found that they overcome the\nstate-of-the-art in knowledge discovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20064v2",
    "published_date": "2024-09-30 08:07:29 UTC",
    "updated_date": "2025-01-28 11:36:19 UTC"
  },
  {
    "arxiv_id": "2409.20054v1",
    "title": "Evaluating and explaining training strategies for zero-shot cross-lingual news sentiment analysis",
    "authors": [
      "Luka AndrenÅ¡ek",
      "Boshko Koloski",
      "AndraÅ¾ Pelicon",
      "Nada LavraÄ",
      "Senja Pollak",
      "Matthew Purver"
    ],
    "abstract": "We investigate zero-shot cross-lingual news sentiment detection, aiming to\ndevelop robust sentiment classifiers that can be deployed across multiple\nlanguages without target-language training data. We introduce novel evaluation\ndatasets in several less-resourced languages, and experiment with a range of\napproaches including the use of machine translation; in-context learning with\nlarge language models; and various intermediate training regimes including a\nnovel task objective, POA, that leverages paragraph-level information. Our\nresults demonstrate significant improvements over the state of the art, with\nin-context learning generally giving the best performance, but with the novel\nPOA approach giving a competitive alternative with much lower computational\noverhead. We also show that language similarity is not in itself sufficient for\npredicting the success of cross-lingual transfer, but that similarity in\nsemantic content and structure can be equally important.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The first two authors share equal contribution",
    "pdf_url": "http://arxiv.org/pdf/2409.20054v1",
    "published_date": "2024-09-30 07:59:41 UTC",
    "updated_date": "2024-09-30 07:59:41 UTC"
  },
  {
    "arxiv_id": "2409.20053v2",
    "title": "GUNDAM: Aligning Large Language Models with Graph Understanding",
    "authors": [
      "Sheng Ouyang",
      "Yulan Hu",
      "Ge Chen",
      "Yong Liu"
    ],
    "abstract": "Large Language Models (LLMs) have achieved impressive results in processing\ntext data, which has sparked interest in applying these models beyond textual\ndata, such as graphs. In the field of graph learning, there is a growing\ninterest in harnessing LLMs to comprehend and manipulate graph-structured data.\nExisting research predominantly focuses on graphs with rich textual features,\nsuch as knowledge graphs or text attribute graphs, leveraging LLMs' ability to\nprocess text but inadequately addressing graph structure. This work\nspecifically aims to assess and enhance LLMs' abilities to comprehend and\nutilize the structural knowledge inherent in graph data itself, rather than\nfocusing solely on graphs rich in textual content. To achieve this, we\nintroduce the \\textbf{G}raph \\textbf{U}nderstanding for \\textbf{N}atural\nLanguage \\textbf{D}riven \\textbf{A}nalytical \\textbf{M}odel (\\model). This\nmodel adapts LLMs to better understand and engage with the structure of graph\ndata, enabling them to perform complex reasoning tasks by leveraging the\ngraph's structure itself. Our experimental evaluations on graph reasoning\nbenchmarks not only substantiate that \\model~ outperforms the SOTA baselines\nfor comparisons. But also reveals key factors affecting the graph reasoning\ncapabilities of LLMs. Moreover, we provide a theoretical analysis illustrating\nhow reasoning paths can enhance LLMs' reasoning capabilities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20053v2",
    "published_date": "2024-09-30 07:59:10 UTC",
    "updated_date": "2024-10-08 06:00:52 UTC"
  },
  {
    "arxiv_id": "2409.20052v2",
    "title": "Mitigating Propensity Bias of Large Language Models for Recommender Systems",
    "authors": [
      "Guixian Zhang",
      "Guan Yuan",
      "Debo Cheng",
      "Lin Liu",
      "Jiuyong Li",
      "Shichao Zhang"
    ],
    "abstract": "The rapid development of Large Language Models (LLMs) creates new\nopportunities for recommender systems, especially by exploiting the side\ninformation (e.g., descriptions and analyses of items) generated by these\nmodels. However, aligning this side information with collaborative information\nfrom historical interactions poses significant challenges. The inherent biases\nwithin LLMs can skew recommendations, resulting in distorted and potentially\nunfair user experiences. On the other hand, propensity bias causes side\ninformation to be aligned in such a way that it often tends to represent all\ninputs in a low-dimensional subspace, leading to a phenomenon known as\ndimensional collapse, which severely restricts the recommender system's ability\nto capture user preferences and behaviours. To address these issues, we\nintroduce a novel framework named Counterfactual LLM Recommendation (CLLMR).\nSpecifically, we propose a spectrum-based side information encoder that\nimplicitly embeds structural information from historical interactions into the\nside information representation, thereby circumventing the risk of dimension\ncollapse. Furthermore, our CLLMR approach explores the causal relationships\ninherent in LLM-based recommender systems. By leveraging counterfactual\ninference, we counteract the biases introduced by LLMs. Extensive experiments\ndemonstrate that our CLLMR approach consistently enhances the performance of\nvarious recommender models.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20052v2",
    "published_date": "2024-09-30 07:57:13 UTC",
    "updated_date": "2025-04-11 05:07:41 UTC"
  },
  {
    "arxiv_id": "2409.20042v2",
    "title": "Beyond Scores: A Modular RAG-Based System for Automatic Short Answer Scoring with Feedback",
    "authors": [
      "Menna Fateen",
      "Bo Wang",
      "Tsunenori Mine"
    ],
    "abstract": "Automatic short answer scoring (ASAS) helps reduce the grading burden on\neducators but often lacks detailed, explainable feedback. Existing methods in\nASAS with feedback (ASAS-F) rely on fine-tuning language models with limited\ndatasets, which is resource-intensive and struggles to generalize across\ncontexts. Recent approaches using large language models (LLMs) have focused on\nscoring without extensive fine-tuning. However, they often rely heavily on\nprompt engineering and either fail to generate elaborated feedback or do not\nadequately evaluate it. In this paper, we propose a modular retrieval augmented\ngeneration based ASAS-F system that scores answers and generates feedback in\nstrict zero-shot and few-shot learning scenarios. We design our system to be\nadaptable to various educational tasks without extensive prompt engineering\nusing an automatic prompt generation framework. Results show an improvement in\nscoring accuracy by 9\\% on unseen questions compared to fine-tuning, offering a\nscalable and cost-effective solution.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20042v2",
    "published_date": "2024-09-30 07:48:55 UTC",
    "updated_date": "2024-10-10 01:45:51 UTC"
  },
  {
    "arxiv_id": "2409.20016v2",
    "title": "Personalisation via Dynamic Policy Fusion",
    "authors": [
      "Ajsal Shereef Palattuparambil",
      "Thommen George Karimpanal",
      "Santu Rana"
    ],
    "abstract": "Deep reinforcement learning (RL) policies, although optimal in terms of task\nrewards, may not align with the personal preferences of human users. To ensure\nthis alignment, a naive solution would be to retrain the agent using a reward\nfunction that encodes the user's specific preferences. However, such a reward\nfunction is typically not readily available, and as such, retraining the agent\nfrom scratch can be prohibitively expensive. We propose a more practical\napproach - to adapt the already trained policy to user-specific needs with the\nhelp of human feedback. To this end, we infer the user's intent through\ntrajectory-level feedback and combine it with the trained task policy via a\ntheoretically grounded dynamic policy fusion approach. As our approach collects\nhuman feedback on the very same trajectories used to learn the task policy, it\ndoes not require any additional interactions with the environment, making it a\nzero-shot approach. We empirically demonstrate in a number of environments that\nour proposed dynamic policy fusion approach consistently achieves the intended\ntask while simultaneously adhering to user-specific needs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.20016v2",
    "published_date": "2024-09-30 07:23:47 UTC",
    "updated_date": "2024-10-03 03:15:28 UTC"
  },
  {
    "arxiv_id": "2409.20012v2",
    "title": "Towards Robust Multimodal Sentiment Analysis with Incomplete Data",
    "authors": [
      "Haoyu Zhang",
      "Wenbin Wang",
      "Tianshu Yu"
    ],
    "abstract": "The field of Multimodal Sentiment Analysis (MSA) has recently witnessed an\nemerging direction seeking to tackle the issue of data incompleteness.\nRecognizing that the language modality typically contains dense sentiment\ninformation, we consider it as the dominant modality and present an innovative\nLanguage-dominated Noise-resistant Learning Network (LNLN) to achieve robust\nMSA. The proposed LNLN features a dominant modality correction (DMC) module and\ndominant modality based multimodal learning (DMML) module, which enhances the\nmodel's robustness across various noise scenarios by ensuring the quality of\ndominant modality representations. Aside from the methodical design, we perform\ncomprehensive experiments under random data missing scenarios, utilizing\ndiverse and meaningful settings on several popular datasets (\\textit{e.g.,}\nMOSI, MOSEI, and SIMS), providing additional uniformity, transparency, and\nfairness compared to existing evaluations in the literature. Empirically, LNLN\nconsistently outperforms existing baselines, demonstrating superior performance\nacross these challenging and extensive evaluation metrics.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.20012v2",
    "published_date": "2024-09-30 07:14:31 UTC",
    "updated_date": "2024-11-01 08:40:28 UTC"
  },
  {
    "arxiv_id": "2409.20010v1",
    "title": "Customized Information and Domain-centric Knowledge Graph Construction with Large Language Models",
    "authors": [
      "Frank Wawrzik",
      "Matthias Plaue",
      "Savan Vekariya",
      "Christoph Grimm"
    ],
    "abstract": "In this paper we propose a novel approach based on knowledge graphs to\nprovide timely access to structured information, to enable actionable\ntechnology intelligence, and improve cyber-physical systems planning. Our\nframework encompasses a text mining process, which includes information\nretrieval, keyphrase extraction, semantic network creation, and topic map\nvisualization. Following this data exploration process, we employ a selective\nknowledge graph construction (KGC) approach supported by an electronics and\ninnovation ontology-backed pipeline for multi-objective decision-making with a\nfocus on cyber-physical systems. We apply our methodology to the domain of\nautomotive electrical systems to demonstrate the approach, which is scalable.\nOur results demonstrate that our construction process outperforms GraphGPT as\nwell as our bi-LSTM and transformer REBEL with a pre-defined dataset by several\ntimes in terms of class recognition, relationship construction and correct\n\"sublass of\" categorization. Additionally, we outline reasoning applications\nand provide a comparison with Wikidata to show the differences and advantages\nof the approach.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at CAIPI Workshop at AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.20010v1",
    "published_date": "2024-09-30 07:08:28 UTC",
    "updated_date": "2024-09-30 07:08:28 UTC"
  },
  {
    "arxiv_id": "2409.20005v1",
    "title": "Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification",
    "authors": [
      "Jiseok Lee",
      "Brian Kenji Iwana"
    ],
    "abstract": "Transfer learning is a common practice that alleviates the need for extensive\ndata to train neural networks. It is performed by pre-training a model using a\nsource dataset and fine-tuning it for a target task. However, not every source\ndataset is appropriate for each target dataset, especially for time series. In\nthis paper, we propose a novel method of selecting and using multiple datasets\nfor transfer learning for time series classification. Specifically, our method\ncombines multiple datasets as one source dataset for pre-training neural\nnetworks. Furthermore, for selecting multiple sources, our method measures the\ntransferability of datasets based on shapelet discovery for effective source\nselection. While traditional transferability measures require considerable time\nfor pre-training all the possible sources for source selection of each possible\narchitecture, our method can be repeatedly used for every possible architecture\nwith a single simple computation. Using the proposed method, we demonstrate\nthat it is possible to increase the performance of temporal convolutional\nneural networks (CNN) on time series datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at International Conference on Pattern Recognition 2024\n  (ICPR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.20005v1",
    "published_date": "2024-09-30 06:57:30 UTC",
    "updated_date": "2024-09-30 06:57:30 UTC"
  },
  {
    "arxiv_id": "2410.07165v1",
    "title": "Complex Logical Query Answering by Calibrating Knowledge Graph Completion Models",
    "authors": [
      "Changyi Xiao",
      "Yixin Cao"
    ],
    "abstract": "Complex logical query answering (CLQA) is a challenging task that involves\nfinding answer entities for complex logical queries over incomplete knowledge\ngraphs (KGs). Previous research has explored the use of pre-trained knowledge\ngraph completion (KGC) models, which can predict the missing facts in KGs, to\nanswer complex logical queries. However, KGC models are typically evaluated\nusing ranking evaluation metrics, which may result in values of predictions of\nKGC models that are not well-calibrated. In this paper, we propose a method for\ncalibrating KGC models, namely CKGC, which enables KGC models to adapt to\nanswering complex logical queries. Notably, CKGC is lightweight and effective.\nThe adaptation function is simple, allowing the model to quickly converge\nduring the adaptation process. The core concept of CKGC is to map the values of\npredictions of KGC models to the range [0, 1], ensuring that values associated\nwith true facts are close to 1, while values linked to false facts are close to\n0. Through experiments on three benchmark datasets, we demonstrate that our\nproposed calibration method can significantly boost model performance in the\nCLQA task. Moreover, our approach can enhance the performance of CLQA while\npreserving the ranking evaluation metrics of KGC models. The code is available\nat https://github.com/changyi7231/CKGC.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07165v1",
    "published_date": "2024-09-30 06:51:50 UTC",
    "updated_date": "2024-09-30 06:51:50 UTC"
  },
  {
    "arxiv_id": "2409.19998v2",
    "title": "Do Influence Functions Work on Large Language Models?",
    "authors": [
      "Zhe Li",
      "Wei Zhao",
      "Yige Li",
      "Jun Sun"
    ],
    "abstract": "Influence functions are important for quantifying the impact of individual\ntraining data points on a model's predictions. Although extensive research has\nbeen conducted on influence functions in traditional machine learning models,\ntheir application to large language models (LLMs) has been limited. In this\nwork, we conduct a systematic study to address a key question: do influence\nfunctions work on LLMs? Specifically, we evaluate influence functions across\nmultiple tasks and find that they consistently perform poorly in most settings.\nOur further investigation reveals that their poor performance can be attributed\nto: (1) inevitable approximation errors when estimating the iHVP component due\nto the scale of LLMs, (2) uncertain convergence during fine-tuning, and, more\nfundamentally, (3) the definition itself, as changes in model parameters do not\nnecessarily correlate with changes in LLM behavior. Thus, our study suggests\nthe need for alternative approaches for identifying influential samples.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19998v2",
    "published_date": "2024-09-30 06:50:18 UTC",
    "updated_date": "2024-12-19 19:33:43 UTC"
  },
  {
    "arxiv_id": "2409.19993v1",
    "title": "Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges",
    "authors": [
      "Qin Liu",
      "Wenjie Mo",
      "Terry Tong",
      "Jiashu Xu",
      "Fei Wang",
      "Chaowei Xiao",
      "Muhao Chen"
    ],
    "abstract": "The advancement of Large Language Models (LLMs) has significantly impacted\nvarious domains, including Web search, healthcare, and software development.\nHowever, as these models scale, they become more vulnerable to cybersecurity\nrisks, particularly backdoor attacks. By exploiting the potent memorization\ncapacity of LLMs, adversaries can easily inject backdoors into LLMs by\nmanipulating a small portion of training data, leading to malicious behaviors\nin downstream applications whenever the hidden backdoor is activated by the\npre-defined triggers. Moreover, emerging learning paradigms like instruction\ntuning and reinforcement learning from human feedback (RLHF) exacerbate these\nrisks as they rely heavily on crowdsourced data and human feedback, which are\nnot fully controlled. In this paper, we present a comprehensive survey of\nemerging backdoor threats to LLMs that appear during LLM development or\ninference, and cover recent advancement in both defense and detection\nstrategies for mitigating backdoor threats to LLMs. We also outline key\nchallenges in addressing these threats, highlighting areas for future research.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "The 60th Annual Allerton Conference (Invited Paper). The arXiv\n  version is a pre-IEEE Press publication version",
    "pdf_url": "http://arxiv.org/pdf/2409.19993v1",
    "published_date": "2024-09-30 06:31:36 UTC",
    "updated_date": "2024-09-30 06:31:36 UTC"
  },
  {
    "arxiv_id": "2409.19992v2",
    "title": "A large-scale operational study of fingerprint quality and demographics",
    "authors": [
      "Javier Galbally",
      "Aleksandrs Cepilovs",
      "Ramon Blanco-Gonzalo",
      "Gillian Ormiston",
      "Oscar Miguel-Hurtado",
      "Istvan Sz. Racz"
    ],
    "abstract": "Even though a few initial works have shown on small sets of data some level\nof bias in the performance of fingerprint recognition technology with respect\nto certain demographic groups, there is still not sufficient evidence to\nunderstand the impact that certain factors such as gender, age or finger-type\nmay have on fingerprint quality and, in turn, also on fingerprint matching\naccuracy. The present work addresses this still under researched topic, on a\nlarge-scale database of operational data containing 10-print impressions of\nalmost 16,000 subjects. The results reached provide further insight into the\ndependency of fingerprint quality and demographics, and show that there in fact\nexists a certain degree of performance variability in fingerprint-based\nrecognition systems for different segments of the population. Based on the\nexperimental evaluation, the work points out new observations based on\ndata-driven evidence, provides plausible hypotheses to explain such\nobservations, and concludes with potential follow-up actions that can help to\nreduce the observed fingerprint quality differences. This way, the current\npaper can be considered as a contribution to further increase the algorithmic\nfairness and equality of biometric technology.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Extended journal version submitted to IET Biometrics. 10 pages, 5\n  figures Reference conference paper: J. Galbally, A. Cepilovs, R.\n  Blanco-Gonzalo, G. Ormiston, O. Miguel-Hurtado, and I. S. Racz, 'Fingerprint\n  quality per individual finger type: A large-scale study on real operational\n  data' in Proc. IEEE Intl. Workshop on Biometrics and Forensics 2023 (IWBF\n  2023)",
    "pdf_url": "http://arxiv.org/pdf/2409.19992v2",
    "published_date": "2024-09-30 06:30:33 UTC",
    "updated_date": "2024-10-04 14:20:31 UTC"
  },
  {
    "arxiv_id": "2410.03727v3",
    "title": "FaithEval: Can Your Language Model Stay Faithful to Context, Even If \"The Moon is Made of Marshmallows\"",
    "authors": [
      "Yifei Ming",
      "Senthil Purushwalkam",
      "Shrey Pandit",
      "Zixuan Ke",
      "Xuan-Phi Nguyen",
      "Caiming Xiong",
      "Shafiq Joty"
    ],
    "abstract": "Ensuring faithfulness to context in large language models (LLMs) and\nretrieval-augmented generation (RAG) systems is crucial for reliable deployment\nin real-world applications, as incorrect or unsupported information can erode\nuser trust. Despite advancements on standard benchmarks, faithfulness\nhallucination-where models generate responses misaligned with the provided\ncontext-remains a significant challenge. In this work, we introduce FaithEval,\na novel and comprehensive benchmark tailored to evaluate the faithfulness of\nLLMs in contextual scenarios across three diverse tasks: unanswerable,\ninconsistent, and counterfactual contexts. These tasks simulate real-world\nchallenges where retrieval mechanisms may surface incomplete, contradictory, or\nfabricated information. FaithEval comprises 4.9K high-quality problems in\ntotal, validated through a rigorous four-stage context construction and\nvalidation framework, employing both LLM-based auto-evaluation and human\nvalidation. Our extensive study across a wide range of open-source and\nproprietary models reveals that even state-of-the-art models often struggle to\nremain faithful to the given context, and that larger models do not necessarily\nexhibit improved faithfulness.Project is available at:\nhttps://github.com/SalesforceAIResearch/FaithEval.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The conference version of this paper is published at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.03727v3",
    "published_date": "2024-09-30 06:27:53 UTC",
    "updated_date": "2025-04-24 22:33:02 UTC"
  },
  {
    "arxiv_id": "2409.19984v1",
    "title": "CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models",
    "authors": [
      "Eitan Wagner",
      "Yuli Slavutsky",
      "Omri Abend"
    ],
    "abstract": "Although language model scores are often treated as probabilities, their\nreliability as probability estimators has mainly been studied through\ncalibration, overlooking other aspects. In particular, it is unclear whether\nlanguage models produce the same value for different ways of assigning joint\nprobabilities to word spans. Our work introduces a novel framework, ConTestS\n(Consistency Testing over Spans), involving statistical tests to assess score\nconsistency across interchangeable completion and conditioning orders. We\nconduct experiments on post-release real and synthetic data to eliminate\ntraining effects. Our findings reveal that both Masked Language Models (MLMs)\nand autoregressive models exhibit inconsistent predictions, with autoregressive\nmodels showing larger discrepancies. Larger MLMs tend to produce more\nconsistent predictions, while autoregressive models show the opposite trend.\nMoreover, for both model types, prediction entropies offer insights into the\ntrue word span likelihood and therefore can aid in selecting optimal decoding\nstrategies. The inconsistencies revealed by our analysis, as well their\nconnection to prediction entropies and differences between model types, can\nserve as useful guides for future research on addressing these limitations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19984v1",
    "published_date": "2024-09-30 06:24:43 UTC",
    "updated_date": "2024-09-30 06:24:43 UTC"
  },
  {
    "arxiv_id": "2409.19977v1",
    "title": "Knowledge Graph Embedding by Normalizing Flows",
    "authors": [
      "Changyi Xiao",
      "Xiangnan He",
      "Yixin Cao"
    ],
    "abstract": "A key to knowledge graph embedding (KGE) is to choose a proper representation\nspace, e.g., point-wise Euclidean space and complex vector space. In this\npaper, we propose a unified perspective of embedding and introduce uncertainty\ninto KGE from the view of group theory. Our model can incorporate existing\nmodels (i.e., generality), ensure the computation is tractable (i.e.,\nefficiency) and enjoy the expressive power of complex random variables (i.e.,\nexpressiveness). The core idea is that we embed entities/relations as elements\nof a symmetric group, i.e., permutations of a set. Permutations of different\nsets can reflect different properties of embedding. And the group operation of\nsymmetric groups is easy to compute. In specific, we show that the embedding of\nmany existing models, point vectors, can be seen as elements of a symmetric\ngroup. To reflect uncertainty, we first embed entities/relations as\npermutations of a set of random variables. A permutation can transform a simple\nrandom variable into a complex random variable for greater expressiveness,\ncalled a normalizing flow. We then define scoring functions by measuring the\nsimilarity of two normalizing flows, namely NFE. We construct several\ninstantiating models and prove that they are able to learn logical rules.\nExperimental results demonstrate the effectiveness of introducing uncertainty\nand our model. The code is available at https://github.com/changyi7231/NFE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19977v1",
    "published_date": "2024-09-30 06:04:34 UTC",
    "updated_date": "2024-09-30 06:04:34 UTC"
  },
  {
    "arxiv_id": "2409.19954v3",
    "title": "Domain Consistency Representation Learning for Lifelong Person Re-Identification",
    "authors": [
      "Shiben Liu",
      "Qiang Wang",
      "Huijie Fan",
      "Weihong Ren",
      "Baojie Fan",
      "Yandong Tang"
    ],
    "abstract": "Lifelong person re-identification (LReID) exhibits a contradictory\nrelationship between intra-domain discrimination and inter-domain gaps when\nlearning from continuous data. Intra-domain discrimination focuses on\nindividual nuances (i.e., clothing type, accessories, etc.), while inter-domain\ngaps emphasize domain consistency. Achieving a trade-off between maximizing\nintra-domain discrimination and minimizing inter-domain gaps is a crucial\nchallenge for improving LReID performance. Most existing methods strive to\nreduce inter-domain gaps through knowledge distillation to maintain domain\nconsistency. However, they often ignore intra-domain discrimination. To address\nthis challenge, we propose a novel domain consistency representation learning\n(DCR) model that explores global and attribute-wise representations as a bridge\nto balance intra-domain discrimination and inter-domain gaps. At the\nintra-domain level, we explore the complementary relationship between global\nand attribute-wise representations to improve discrimination among similar\nidentities. Excessive learning intra-domain discrimination can lead to\ncatastrophic forgetting. We further develop an attribute-oriented\nanti-forgetting (AF) strategy that explores attribute-wise representations to\nenhance inter-domain consistency, and propose a knowledge consolidation (KC)\nstrategy to facilitate knowledge transfer. Extensive experiments show that our\nDCR model achieves superior performance compared to state-of-the-art LReID\nmethods. Our code is publicly available at https://github.com/LiuShiBen/DCR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19954v3",
    "published_date": "2024-09-30 05:19:09 UTC",
    "updated_date": "2025-04-27 09:28:11 UTC"
  },
  {
    "arxiv_id": "2409.19951v2",
    "title": "Law of the Weakest Link: Cross Capabilities of Large Language Models",
    "authors": [
      "Ming Zhong",
      "Aston Zhang",
      "Xuewei Wang",
      "Rui Hou",
      "Wenhan Xiong",
      "Chenguang Zhu",
      "Zhengxing Chen",
      "Liang Tan",
      "Chloe Bi",
      "Mike Lewis",
      "Sravya Popuri",
      "Sharan Narang",
      "Melanie Kambadur",
      "Dhruv Mahajan",
      "Sergey Edunov",
      "Jiawei Han",
      "Laurens van der Maaten"
    ],
    "abstract": "The development and evaluation of Large Language Models (LLMs) have largely\nfocused on individual capabilities. However, this overlooks the intersection of\nmultiple abilities across different types of expertise that are often required\nfor real-world tasks, which we term cross capabilities. To systematically\nexplore this concept, we first define seven core individual capabilities and\nthen pair them to form seven common cross capabilities, each supported by a\nmanually constructed taxonomy. Building on these definitions, we introduce\nCrossEval, a benchmark comprising 1,400 human-annotated prompts, with 100\nprompts for each individual and cross capability. To ensure reliable\nevaluation, we involve expert annotators to assess 4,200 model responses,\ngathering 8,400 human ratings with detailed explanations to serve as reference\nexamples. Our findings reveal that, in both static evaluations and attempts to\nenhance specific abilities, current LLMs consistently exhibit the \"Law of the\nWeakest Link,\" where cross-capability performance is significantly constrained\nby the weakest component. Specifically, across 58 cross-capability scores from\n17 models, 38 scores are lower than all individual capabilities, while 20 fall\nbetween strong and weak, but closer to the weaker ability. These results\nhighlight the under-performance of LLMs in cross-capability tasks, making the\nidentification and improvement of the weakest capabilities a critical priority\nfor future research to optimize performance in complex, multi-dimensional\nscenarios.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Data, Code, & Benchmark: www.llm-cross-capabilities.org",
    "pdf_url": "http://arxiv.org/pdf/2409.19951v2",
    "published_date": "2024-09-30 05:12:01 UTC",
    "updated_date": "2024-10-02 22:24:44 UTC"
  },
  {
    "arxiv_id": "2409.19949v2",
    "title": "Task-agnostic Pre-training and Task-guided Fine-tuning for Versatile Diffusion Planner",
    "authors": [
      "Chenyou Fan",
      "Chenjia Bai",
      "Zhao Shan",
      "Haoran He",
      "Yang Zhang",
      "Zhen Wang"
    ],
    "abstract": "Diffusion models have demonstrated their capabilities in modeling\ntrajectories of multi-tasks. However, existing multi-task planners or policies\ntypically rely on task-specific demonstrations via multi-task imitation, or\nrequire task-specific reward labels to facilitate policy optimization via\nReinforcement Learning (RL). They are costly due to the substantial human\nefforts required to collect expert data or design reward functions. To address\nthese challenges, we aim to develop a versatile diffusion planner capable of\nleveraging large-scale inferior data that contains task-agnostic sub-optimal\ntrajectories, with the ability to fast adapt to specific tasks. In this paper,\nwe propose SODP, a two-stage framework that leverages Sub-Optimal data to learn\na Diffusion Planner, which is generalizable for various downstream tasks.\nSpecifically, in the pre-training stage, we train a foundation diffusion\nplanner that extracts general planning capabilities by modeling the versatile\ndistribution of multi-task trajectories, which can be sub-optimal and has wide\ndata coverage. Then for downstream tasks, we adopt RL-based fine-tuning with\ntask-specific rewards to quickly refine the diffusion planner, which aims to\ngenerate action sequences with higher task-specific returns. Experimental\nresults from multi-task domains including Meta-World and Adroit demonstrate\nthat SODP outperforms state-of-the-art methods with only a small amount of data\nfor reward-guided fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19949v2",
    "published_date": "2024-09-30 05:05:37 UTC",
    "updated_date": "2025-02-02 13:33:28 UTC"
  },
  {
    "arxiv_id": "2409.19948v1",
    "title": "JaPOC: Japanese Post-OCR Correction Benchmark using Vouchers",
    "authors": [
      "Masato Fujitake"
    ],
    "abstract": "In this paper, we create benchmarks and assess the effectiveness of error\ncorrection methods for Japanese vouchers in OCR (Optical Character Recognition)\nsystems. It is essential for automation processing to correctly recognize\nscanned voucher text, such as the company name on invoices. However, perfect\nrecognition is complex due to the noise, such as stamps. Therefore, it is\ncrucial to correctly rectify erroneous OCR results. However, no publicly\navailable OCR error correction benchmarks for Japanese exist, and methods have\nnot been adequately researched. In this study, we measured text recognition\naccuracy by existing services on Japanese vouchers and developed a post-OCR\ncorrection benchmark. Then, we proposed simple baselines for error correction\nusing language models and verified whether the proposed method could\neffectively correct these errors. In the experiments, the proposed error\ncorrection algorithm significantly improved overall recognition accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to PRICAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19948v1",
    "published_date": "2024-09-30 05:01:49 UTC",
    "updated_date": "2024-09-30 05:01:49 UTC"
  },
  {
    "arxiv_id": "2409.19940v1",
    "title": "Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains",
    "authors": [
      "Samia Belhadj",
      "Sanguk Park",
      "Ambika Seth",
      "Hesham Dar",
      "Thijs Kooi"
    ],
    "abstract": "Fairness in medical AI is increasingly recognized as a crucial aspect of\nhealthcare delivery. While most of the prior work done on fairness emphasizes\nthe importance of equal performance, we argue that decreases in fairness can be\neither harmful or non-harmful, depending on the type of change and how\nsensitive attributes are used. To this end, we introduce the notion of\npositive-sum fairness, which states that an increase in performance that\nresults in a larger group disparity is acceptable as long as it does not come\nat the cost of individual subgroup performance. This allows sensitive\nattributes correlated with the disease to be used to increase performance\nwithout compromising on fairness.\n  We illustrate this idea by comparing four CNN models that make different use\nof the race attribute in the training phase. The results show that removing all\ndemographic encodings from the images helps close the gap in performance\nbetween the different subgroups, whereas leveraging the race attribute as a\nmodel's input increases the overall performance while widening the disparities\nbetween subgroups. These larger gaps are then put in perspective of the\ncollective benefit through our notion of positive-sum fairness to distinguish\nharmful from non harmful disparities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19940v1",
    "published_date": "2024-09-30 04:37:23 UTC",
    "updated_date": "2024-09-30 04:37:23 UTC"
  },
  {
    "arxiv_id": "2409.19924v4",
    "title": "On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability",
    "authors": [
      "Kevin Wang",
      "Junbo Li",
      "Neel P. Bhatt",
      "Yihan Xi",
      "Qiang Liu",
      "Ufuk Topcu",
      "Zhangyang Wang"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have showcased their\nability to perform complex reasoning tasks, but their effectiveness in planning\nremains underexplored. In this study, we evaluate the planning capabilities of\nOpenAI's o1 models across a variety of benchmark tasks, focusing on three key\naspects: feasibility, optimality, and generalizability. Through empirical\nevaluations on constraint-heavy tasks (e.g., $\\textit{Barman}$,\n$\\textit{Tyreworld}$) and spatially complex environments (e.g.,\n$\\textit{Termes}$, $\\textit{Floortile}$), we highlight o1-preview's strengths\nin self-evaluation and constraint-following, while also identifying bottlenecks\nin decision-making and memory management, particularly in tasks requiring\nrobust spatial reasoning. Our results reveal that o1-preview outperforms GPT-4\nin adhering to task constraints and managing state transitions in structured\nenvironments. However, the model often generates suboptimal solutions with\nredundant actions and struggles to generalize effectively in spatially complex\ntasks. This pilot study provides foundational insights into the planning\nlimitations of LLMs, offering key directions for future research on improving\nmemory management, decision-making, and generalization in LLM-based planning.\nCode available at https://github.com/VITA-Group/o1-planning.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Code available at https://github.com/VITA-Group/o1-planning",
    "pdf_url": "http://arxiv.org/pdf/2409.19924v4",
    "published_date": "2024-09-30 03:58:43 UTC",
    "updated_date": "2024-10-14 03:41:09 UTC"
  },
  {
    "arxiv_id": "2410.00709v1",
    "title": "Binding Affinity Prediction: From Conventional to Machine Learning-Based Approaches",
    "authors": [
      "Xuefeng Liu",
      "Songhao Jiang",
      "Xiaotian Duan",
      "Archit Vasan",
      "Chong Liu",
      "Chih-chan Tien",
      "Heng Ma",
      "Thomas Brettin",
      "Fangfang Xia",
      "Ian T. Foster",
      "Rick L. Stevens"
    ],
    "abstract": "Protein-ligand binding is the process by which a small molecule (drug or\ninhibitor) attaches to a target protein. The binding affinity, which refers to\nthe strength of this interaction, is central to many important problems in\nbioinformatics such as drug design. An extensive amount of work has been\ndevoted to predicting binding affinity over the past decades due to its\nsignificance. In this paper, we review all significant recent works, focusing\non the methods, features, and benchmark datasets. We have observed a rising\ntrend in the use of traditional machine learning and deep learning models for\npredicting binding affinity, accompanied by an increasing amount of data on\nproteins and small drug-like molecules. While prediction results are constantly\nimproving, we also identify several open questions and potential directions\nthat remain unexplored in the field. This paper could serve as an excellent\nstarting point for machine learning researchers who wish to engage in the study\nof binding affinity, or for anyone with general interests in machine learning,\ndrug discovery, and bioinformatics.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00709v1",
    "published_date": "2024-09-30 03:40:49 UTC",
    "updated_date": "2024-09-30 03:40:49 UTC"
  },
  {
    "arxiv_id": "2409.19913v3",
    "title": "Scaling Optimal LR Across Token Horizons",
    "authors": [
      "Johan Bjorck",
      "Alon Benhaim",
      "Vishrav Chaudhary",
      "Furu Wei",
      "Xia Song"
    ],
    "abstract": "State-of-the-art LLMs are powered by scaling -- scaling model size, dataset\nsize and cluster size. It is economically infeasible to extensively tune\nhyperparameter for the largest runs. Instead, approximately optimal\nhyperparameters must be inferred or \\textit{transferred} from smaller\nexperiments. Hyperparameter transfer across model sizes has been studied in\nYang et al. However, hyperparameter transfer across dataset size -- or token\nhorizon -- has not been studied yet. To remedy this we conduct a large scale\nempirical study on how optimal learning rate (LR) depends on token horizon in\nLLM training. We first demonstrate that the optimal LR changes significantly\nwith token horizon -- longer training necessitates smaller LR. Secondly we\ndemonstrate the the optimal LR follows a scaling law, and that the optimal LR\nfor longer horizons can be accurately estimated from shorter horizons via such\nscaling laws. We also provide a rule-of-thumb for transferring LR across token\nhorizons with zero overhead over current practices. Lastly we provide evidence\nthat LLama-1 used too high LR, and estimate the performance hit from this. We\nthus argue that hyperparameter transfer across data size is an important and\noverlooked component of LLM training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.19913v3",
    "published_date": "2024-09-30 03:32:02 UTC",
    "updated_date": "2025-02-24 02:55:34 UTC"
  },
  {
    "arxiv_id": "2409.19898v2",
    "title": "UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs",
    "authors": [
      "Yuho Lee",
      "Taewon Yun",
      "Jason Cai",
      "Hang Su",
      "Hwanjun Song"
    ],
    "abstract": "Existing benchmarks for summarization quality evaluation often lack diverse\ninput scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and\nstruggle with subjective and coarse-grained annotation schemes. To address\nthese shortcomings, we create UniSumEval benchmark, which extends the range of\ninput context (e.g., domain, length) and provides fine-grained,\nmulti-dimensional annotations. We use AI assistance in data creation,\nidentifying potentially hallucinogenic input texts, and also helping human\nannotators reduce the difficulty of fine-grained annotation tasks. With\nUniSumEval, we benchmark nine latest language models as summarizers, offering\ninsights into their performance across varying input contexts and evaluation\ndimensions. Furthermore, we conduct a thorough comparison of SOTA automated\nsummary evaluators. Our benchmark data will be available at\nhttps://github.com/DISL-Lab/UniSumEval-v1.0.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP-Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19898v2",
    "published_date": "2024-09-30 02:56:35 UTC",
    "updated_date": "2024-10-01 07:11:44 UTC"
  },
  {
    "arxiv_id": "2409.19894v2",
    "title": "TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation",
    "authors": [
      "Zhiqiang Yuan",
      "Weitong Chen",
      "Hanlin Wang",
      "Kai Yu",
      "Xin Peng",
      "Yiling Lou"
    ],
    "abstract": "Code translation converts code from one programming language to another while\nmaintaining its original functionality, which is crucial for software\nmigration, system refactoring, and cross-platform development. Traditional\nrule-based methods rely on manually-written rules, which can be time-consuming\nand often result in less readable code. To overcome this, learning-based\nmethods have been developed, leveraging parallel data to train models for\nautomated code translation. More recently, the advance of Large Language Models\n(LLMs) further boosts learning-based code translation. Although promising,\nLLM-translated program still suffers from diverse quality issues (e.g., syntax\nerrors and semantic errors). In particular, it can be challenging for LLMs to\nself-debug these errors when simply provided with the corresponding error\nmessages.\n  In this work, we propose a novel LLM-based multi-agent system TRANSAGENT,\nwhich enhances LLM-based code translation by fixing the syntax errors and\nsemantic errors with the synergy between four LLM-based agents, including\nInitial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error\nFixer. The main insight of TRANSAGENT is to first localize the error code block\nin the target program based on the execution alignment between the target and\nsource program, which can narrow down the fixing space and thus lower down the\nfixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark\nfrom recent programming tasks to mitigate the potential data leakage issue. On\nour benchmark, TRANSAGENT outperforms the latest LLM-based code translation\ntechnique UniTrans in both translation effectiveness and efficiency;\nadditionally, our evaluation on different LLMs show the generalization of\nTRANSAGENT and our ablation study shows the contribution of each agent.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19894v2",
    "published_date": "2024-09-30 02:53:03 UTC",
    "updated_date": "2024-10-01 04:35:05 UTC"
  },
  {
    "arxiv_id": "2409.19886v1",
    "title": "RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models",
    "authors": [
      "Shuhao Chen",
      "Weisen Jiang",
      "Baijiong Lin",
      "James T. Kwok",
      "Yu Zhang"
    ],
    "abstract": "Recent works show that assembling multiple off-the-shelf large language\nmodels (LLMs) can harness their complementary abilities. To achieve this,\nrouting is a promising method, which learns a router to select the most\nsuitable LLM for each query. However, existing routing models are ineffective\nwhen multiple LLMs perform well for a query. To address this problem, in this\npaper, we propose a method called query-based Router by Dual Contrastive\nlearning (RouterDC). The RouterDC model consists of an encoder and LLM\nembeddings, and we propose two contrastive learning losses to train the\nRouterDC model. Experimental results show that RouterDC is effective in\nassembling LLMs and largely outperforms individual top-performing LLMs as well\nas existing routing methods on both in-distribution (+2.76\\%) and\nout-of-distribution (+1.90\\%) tasks. Source code is available at\nhttps://github.com/shuhao02/RouterDC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19886v1",
    "published_date": "2024-09-30 02:31:40 UTC",
    "updated_date": "2024-09-30 02:31:40 UTC"
  },
  {
    "arxiv_id": "2409.19884v2",
    "title": "SWIM: Short-Window CNN Integrated with Mamba for EEG-Based Auditory Spatial Attention Decoding",
    "authors": [
      "Ziyang Zhang",
      "Andrew Thwaites",
      "Alexandra Woolgar",
      "Brian Moore",
      "Chao Zhang"
    ],
    "abstract": "In complex auditory environments, the human auditory system possesses the\nremarkable ability to focus on a specific speaker while disregarding others. In\nthis study, a new model named SWIM, a short-window convolution neural network\n(CNN) integrated with Mamba, is proposed for identifying the locus of auditory\nattention (left or right) from electroencephalography (EEG) signals without\nrelying on speech envelopes. SWIM consists of two parts. The first is a\nshort-window CNN (SW$_\\text{CNN}$), which acts as a short-term EEG feature\nextractor and achieves a final accuracy of 84.9% in the leave-one-speaker-out\nsetup on the widely used KUL dataset. This improvement is due to the use of an\nimproved CNN structure, data augmentation, multitask training, and model\ncombination. The second part, Mamba, is a sequence model first applied to\nauditory spatial attention decoding to leverage the long-term dependency from\nprevious SW$_\\text{CNN}$ time steps. By joint training SW$_\\text{CNN}$ and\nMamba, the proposed SWIM structure uses both short-term and long-term\ninformation and achieves an accuracy of 86.2%, which reduces the classification\nerrors by a relative 31.0% compared to the previous state-of-the-art result.\nThe source code is available at https://github.com/windowso/SWIM-ASAD.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "accepted by SLT 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19884v2",
    "published_date": "2024-09-30 02:28:32 UTC",
    "updated_date": "2024-11-27 12:30:24 UTC"
  },
  {
    "arxiv_id": "2409.19877v1",
    "title": "Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation",
    "authors": [
      "Huangyu Dai",
      "Ben Chen",
      "Kaidi Chen",
      "Ying Han",
      "Zihan Liang",
      "Wen Jiang"
    ],
    "abstract": "For crosslingual conversation and trade, Neural Machine Translation (NMT) is\npivotal yet faces persistent challenges with monotony and repetition in\ngenerated content. Traditional solutions that rely on penalizing text\nredundancy or token reoccurrence have shown limited efficacy, particularly for\nlengthy article and e-commerce descriptions with inherent redundancy, even with\nthe advent of Large Language Models (LLMs). This paper investigates the\nunderlying causes of textual repetition through the lens of information\nentropy, attributing the phenomenon to the elevated uncertainty within the\ninput text. To address this, a novel algorithm named Contrastive Token Learning\nwith Similarity Decay (CTSD) is introduced, which modulates the suppression of\ntokens dynamically, informed by varying attention weights and inter-token\ndistances. Furthermore, an e-commerce dataset comprised of title texts of\nonline real items is compiled and released susceptible to hallucination\ntranslations to benchmark the algorithm. Extensive evaluations demonstrate that\nCTSD significantly outperforms existing approaches in precision and\ngeneralizability. Additional online A/B testing underscores its practical\nvalue, showing marked improvements in user engagement and conversion. Notably,\nthis method has been implemented with full traffic on eight multilingual sites\nof alibaba.com, the largest B2B e-commerce platform in the world.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP'24 Findings. 12 pages, 4 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.19877v1",
    "published_date": "2024-09-30 02:21:39 UTC",
    "updated_date": "2024-09-30 02:21:39 UTC"
  },
  {
    "arxiv_id": "2409.19871v1",
    "title": "TSI: A Multi-View Representation Learning Approach for Time Series Forecasting",
    "authors": [
      "Wentao Gao",
      "Ziqi Xu",
      "Jiuyong Li",
      "Lin Liu",
      "Jixue Liu",
      "Thuc Duy Le",
      "Debo Cheng",
      "Yanchang Zhao",
      "Yun Chen"
    ],
    "abstract": "As the growing demand for long sequence time-series forecasting in real-world\napplications, such as electricity consumption planning, the significance of\ntime series forecasting becomes increasingly crucial across various domains.\nThis is highlighted by recent advancements in representation learning within\nthe field. This study introduces a novel multi-view approach for time series\nforecasting that innovatively integrates trend and seasonal representations\nwith an Independent Component Analysis (ICA)-based representation. Recognizing\nthe limitations of existing methods in representing complex and\nhigh-dimensional time series data, this research addresses the challenge by\ncombining TS (trend and seasonality) and ICA (independent components)\nperspectives. This approach offers a holistic understanding of time series\ndata, going beyond traditional models that often miss nuanced, nonlinear\nrelationships. The efficacy of TSI model is demonstrated through comprehensive\ntesting on various benchmark datasets, where it shows superior performance over\ncurrent state-of-the-art models, particularly in multivariate forecasting. This\nmethod not only enhances the accuracy of forecasting but also contributes\nsignificantly to the field by providing a more in-depth understanding of time\nseries data. The research which uses ICA for a view lays the groundwork for\nfurther exploration and methodological advancements in time series forecasting,\nopening new avenues for research and practical applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AJCAI Oral Accepted",
    "pdf_url": "http://arxiv.org/pdf/2409.19871v1",
    "published_date": "2024-09-30 02:11:57 UTC",
    "updated_date": "2024-09-30 02:11:57 UTC"
  },
  {
    "arxiv_id": "2410.00064v3",
    "title": "M2Distill: Multi-Modal Distillation for Lifelong Imitation Learning",
    "authors": [
      "Kaushik Roy",
      "Akila Dissanayake",
      "Brendan Tidd",
      "Peyman Moghadam"
    ],
    "abstract": "Lifelong imitation learning for manipulation tasks poses significant\nchallenges due to distribution shifts that occur in incremental learning steps.\nExisting methods often focus on unsupervised skill discovery to construct an\never-growing skill library or distillation from multiple policies, which can\nlead to scalability issues as diverse manipulation tasks are continually\nintroduced and may fail to ensure a consistent latent space throughout the\nlearning process, leading to catastrophic forgetting of previously learned\nskills. In this paper, we introduce M2Distill, a multi-modal distillation-based\nmethod for lifelong imitation learning focusing on preserving consistent latent\nspace across vision, language, and action distributions throughout the learning\nprocess. By regulating the shifts in latent representations across different\nmodalities from previous to current steps, and reducing discrepancies in\nGaussian Mixture Model (GMM) policies between consecutive learning steps, we\nensure that the learned policy retains its ability to perform previously\nlearned tasks while seamlessly integrating new skills. Extensive evaluations on\nthe LIBERO lifelong imitation learning benchmark suites, including\nLIBERO-OBJECT, LIBERO-GOAL, and LIBERO-SPATIAL, demonstrate that our method\nconsistently outperforms prior state-of-the-art methods across all evaluated\nmetrics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.00064v3",
    "published_date": "2024-09-30 01:43:06 UTC",
    "updated_date": "2025-03-07 01:29:54 UTC"
  },
  {
    "arxiv_id": "2409.19841v2",
    "title": "Counter-Current Learning: A Biologically Plausible Dual Network Approach for Deep Learning",
    "authors": [
      "Chia-Hsiang Kao",
      "Bharath Hariharan"
    ],
    "abstract": "Despite its widespread use in neural networks, error backpropagation has\nfaced criticism for its lack of biological plausibility, suffering from issues\nsuch as the backward locking problem and the weight transport problem. These\nlimitations have motivated researchers to explore more biologically plausible\nlearning algorithms that could potentially shed light on how biological neural\nsystems adapt and learn. Inspired by the counter-current exchange mechanisms\nobserved in biological systems, we propose counter-current learning (CCL), a\nbiologically plausible framework for credit assignment in neural networks. This\nframework employs a feedforward network to process input data and a feedback\nnetwork to process targets, with each network enhancing the other through\nanti-parallel signal propagation. By leveraging the more informative signals\nfrom the bottom layer of the feedback network to guide the updates of the top\nlayer of the feedforward network and vice versa, CCL enables the simultaneous\ntransformation of source inputs to target outputs and the dynamic mutual\ninfluence of these transformations. Experimental results on MNIST,\nFashionMNIST, CIFAR10, and CIFAR100 datasets using multi-layer perceptrons and\nconvolutional neural networks demonstrate that CCL achieves comparable\nperformance to other biologically plausible algorithms while offering a more\nbiologically realistic learning mechanism. Furthermore, we showcase the\napplicability of our approach to an autoencoder task, underscoring its\npotential for unsupervised representation learning. Our work presents a\ndirection for biologically inspired and plausible learning algorithms, offering\nan alternative mechanism of learning and adaptation in neural networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024. Code available at\n  https://github.com/IandRover/CCL-NeurIPS24",
    "pdf_url": "http://arxiv.org/pdf/2409.19841v2",
    "published_date": "2024-09-30 00:47:13 UTC",
    "updated_date": "2024-10-23 16:27:27 UTC"
  },
  {
    "arxiv_id": "2409.19839v5",
    "title": "ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities",
    "authors": [
      "Ezra Karger",
      "Houtan Bastani",
      "Chen Yueh-Han",
      "Zachary Jacobs",
      "Danny Halawi",
      "Fred Zhang",
      "Philip E. Tetlock"
    ],
    "abstract": "Forecasts of future events are essential inputs into informed\ndecision-making. Machine learning (ML) systems have the potential to deliver\nforecasts at scale, but there is no framework for evaluating the accuracy of ML\nsystems on a standardized set of forecasting questions. To address this gap, we\nintroduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML\nsystems on an automatically generated and regularly updated set of 1,000\nforecasting questions. To avoid any possibility of data leakage, ForecastBench\nis comprised solely of questions about future events that have no known answer\nat the time of submission. We quantify the capabilities of current ML systems\nby collecting forecasts from expert (human) forecasters, the general public,\nand LLMs on a random subset of questions from the benchmark ($N=200$). While\nLLMs have achieved super-human performance on many benchmarks, they perform\nless well here: expert forecasters outperform the top-performing LLM ($p$-value\n$<0.001$). We display system and human scores in a public leaderboard at\nwww.forecastbench.org.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19839v5",
    "published_date": "2024-09-30 00:41:51 UTC",
    "updated_date": "2025-02-28 12:35:34 UTC"
  }
]