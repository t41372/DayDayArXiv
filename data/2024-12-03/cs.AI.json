{
  "date": "2024-12-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-03 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM 在视觉和文本任务中的应用、图像生成技术改进，以及 AI 在医疗和强化学习等领域的实际应用。其中，LLM 增强视觉任务的框架（如 VideoGen-of-Thought）和图像生成优化（如 AccDiffusion v2）令人印象深刻，而知名学者如 Jiajun Wu 的作品在 3D 布局生成中展现了创新潜力。\n\n以下是今日论文的精选摘要，我将相关主题归类讨论，先优先聊重要或有话题度的论文（如 LLM 和图像生成），其他次要论文快速掠过，只列标题和核心贡献。每个条目保留核心术语，并简要描述主要贡献和发现。\n\n### LLM 和文本生成相关\n- **Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning**（增强大型语言模型的信任：基于不确定性感知的微调）  \n  贡献：提出一种不确定性感知微调方法，改进了 LLM 在自然语言生成中的不确定性估计和幻觉检测，实验显示在问答任务中显著提升模型可靠性。\n- **MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions**（MLD-EA：通过引入情感和动作检查并完成叙事连贯性）  \n  贡献：开发了基于 LLM 的模型来识别叙事中的逻辑漏洞并生成连贯句子，强调情感一致性，适用于 NLP 中的故事生成。\n- **Removing Spurious Correlation from Neural Network Interpretations**（从神经网络解释中去除虚假相关性）  \n  贡献：引入因果中介方法控制混杂因素（如话题），减少 LLM 在对话中的毒性偏差。\n- **Time-Reversal Provides Unsupervised Feedback to LLMs**（时间反转为 LLM 提供无监督反馈）  \n  贡献：提出时间反转框架，使用逆向预测优化 LLM 的查询响应，提升代码生成和安全过滤的准确性。\n- **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment**（医疗多模态基础模型在临床诊断和治疗中的应用）  \n  贡献：综述多模态模型在医疗诊断中的进展，强调其在精确诊断中的潜力，但需解决数据隐私和泛化问题。\n- **其他次要论文**：如 \"EvoLLMs\"（使用进化计算减少 LLM 幻觉）和 \"FathomGPT\"（用于海洋数据分析的 LLM 接口），这些快速掠过，仅贡献在于扩展 LLM 到特定领域，但创新性较低。\n\n### 图像生成和视觉任务\n- **ShapeWords: Guiding Text-to-Image Synthesis with 3D Shape-Aware Prompts**（ShapeWords：使用 3D 形状感知提示指导文本到图像合成）  \n  贡献：引入 3D 形状感知令牌，结合文本提示生成更精确的图像，实验证明在保持形状一致性同时提升文本 compliance。\n- **VideoGen-of-Thought: Step-by-step generating multi-shot video with minimal manual intervention**（VideoGen-of-Thought：通过逐步生成实现多镜头视频的最小手动干预）  \n  贡献：提出基于 LLM 的框架，逐步生成多镜头视频，显著减少手动编辑，同时提升视觉一致性和叙事连贯性。\n- **AccDiffusion v2: Towards More Accurate Higher-Resolution Diffusion Extrapolation**（AccDiffusion v2：实现更准确的高分辨率扩散外推）  \n  贡献：优化扩散模型，减少图像生成中的重复和失真，实验显示在高分辨率任务中性能提升。\n- **AniGS: Animatable Gaussian Avatar from a Single Image with Inconsistent Gaussian Reconstruction**（AniGS：从单张图像生成可动画高斯头像）  \n  贡献：使用高斯散斑重建从单图像生成可动画 3D 头像，解决多视图不一致问题。\n- **其他次要论文**：如 \"Gaussian Splatting Under Attack\"（探讨图像生成的安全性）和 \"LayoutVLM\"（视觉布局优化），这些论文在图像处理中有所贡献，但主题较窄，仅限于特定攻击或布局问题。\n\n### 强化学习和应用\n- **Proximal Control of UAVs with Federated Learning for Human-Robot Collaborative Domains**（使用联邦学习进行无人机的人机协作控制）  \n  贡献：结合联邦学习和 LSTM 实现无人机动作识别，提升多人协作下的准确性，实验在真实环境中达到 96% 以上。\n- **CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events**（CausalMob：使用 LLM 推断人类意图的因果移动预测）  \n  贡献：利用 LLM 提取事件意图进行移动预测，改进了传统模型的准确性。\n- **其他次要论文**：如 \"HERO\"（LLM 在查询优化的应用）和 \"TAB-Fields\"（神经网络解释），这些在特定优化中有效，但整体影响力有限。\n\n### 其他领域应用\n- **FLAME 3 Dataset: Unleashing the Power of Radiometric Thermal UAV Imagery for Wildfire Management**（FLAME 3 数据集：释放辐射热 UAV 图像在野火管理的潜力）  \n  贡献：发布新数据集，支持 AI 在野火检测中的应用，实验显示提升了机器学习模型的准确性。\n- **WxC-Bench: A Novel Dataset for Weather and Climate Downstream Tasks**（WxC-Bench：用于天气和气候任务的新数据集）  \n  贡献：引入多模态数据集，支持 AI 在气象任务中的泛化。\n- **其他次要论文**：如 \"Graph Learning for Planning\"（图学习在规划中的应用）和 \"Social Media Informatics for Sustainable Cities\"（社交媒体在可持续城市中的信息学），这些论文探索 AI 的扩展应用，但细节较泛，不做深聊。\n\n今天的论文总体上突出了 LLM 和图像生成领域的创新潜力，但也暴露了 AI 在泛化和安全上的挑战。未来几天，继续关注这些主题的进展！如果有特定论文感兴趣，建议查阅原文。",
  "papers": [
    {
      "arxiv_id": "2412.02912v1",
      "title": "ShapeWords: Guiding Text-to-Image Synthesis with 3D Shape-Aware Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitry Petrov",
        "Pradyumn Goyal",
        "Divyansh Shivashok",
        "Yuanming Tao",
        "Melinos Averkiou",
        "Evangelos Kalogerakis"
      ],
      "abstract": "We introduce ShapeWords, an approach for synthesizing images based on 3D\nshape guidance and text prompts. ShapeWords incorporates target 3D shape\ninformation within specialized tokens embedded together with the input text,\neffectively blending 3D shape awareness with textual context to guide the image\nsynthesis process. Unlike conventional shape guidance methods that rely on\ndepth maps restricted to fixed viewpoints and often overlook full 3D structure\nor textual context, ShapeWords generates diverse yet consistent images that\nreflect both the target shape's geometry and the textual description.\nExperimental results show that ShapeWords produces images that are more\ntext-compliant, aesthetically plausible, while also maintaining 3D shape\nawareness.",
      "tldr_zh": "我们引入了 ShapeWords 方法，用于通过 3D Shape-Aware Prompts 引导 Text-to-Image Synthesis，将目标 3D 形状信息嵌入专用 tokens 与文本提示结合，从而实现形状几何和文本上下文的融合。不同于传统方法依赖固定视点的深度图并忽略完整 3D 结构或文本，ShapeWords 生成多样且一致的图像，确保了形状的精确反映。实验结果显示，该方法产生的图像在文本遵守性、美观性和 3D 形状意识方面均优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project webpage: https://lodurality.github.io/shapewords/",
      "pdf_url": "http://arxiv.org/pdf/2412.02912v1",
      "published_date": "2024-12-03 23:37:47 UTC",
      "updated_date": "2024-12-03 23:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:57:26.673853"
    },
    {
      "arxiv_id": "2412.02906v1",
      "title": "Does Few-Shot Learning Help LLM Performance in Code Synthesis?",
      "title_zh": "翻译失败",
      "authors": [
        "Derek Xu",
        "Tong Xie",
        "Botao Xia",
        "Haoyu Li",
        "Yunsheng Bai",
        "Yizhou Sun",
        "Wei Wang"
      ],
      "abstract": "Large language models (LLMs) have made significant strides at code generation\nthrough improved model design, training, and chain-of-thought. However,\nprompt-level optimizations remain an important yet under-explored aspect of\nLLMs for coding. This work focuses on the few-shot examples present in most\ncode generation prompts, offering a systematic study on whether few-shot\nexamples improve LLM's coding capabilities, which few-shot examples have the\nlargest impact, and how to select impactful examples. Our work offers 2\napproaches for selecting few-shot examples, a model-free method,\nCODEEXEMPLAR-FREE, and a model-based method, CODEEXEMPLAR-BASED. The 2 methods\noffer a trade-off between improved performance and reliance on training data\nand interpretability. Both methods significantly improve CodeLlama's coding\nability across the popular HumanEval+ coding benchmark. In summary, our work\nprovides valuable insights into how to pick few-shot examples in code\ngeneration prompts to improve LLM code generation capabilities.",
      "tldr_zh": "本文研究了少样本学习（few-shot examples）是否能提升大型语言模型（LLMs）在代码生成（code synthesis）任务中的性能，重点分析了提示中的示例选择对编码能力的影响。作者提出了两种方法：模型无关的 CODEEXEMPLAR-FREE 和模型相关的 CODEEXEMPLAR-BASED，前者提供更高的可解释性，后者依赖训练数据但优化了性能。实验在 HumanEval+ 基准上证明，这些方法显著提升了 CodeLlama 的代码生成能力，并为选择有效少样本示例提供了系统性指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02906v1",
      "published_date": "2024-12-03 23:19:40 UTC",
      "updated_date": "2024-12-03 23:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:57:38.867898"
    },
    {
      "arxiv_id": "2412.02904v1",
      "title": "Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning",
      "title_zh": "通过不确定性感知微调增强大语言模型的信任",
      "authors": [
        "Ranganath Krishnan",
        "Piyush Khanna",
        "Omesh Tickoo"
      ],
      "abstract": "Large language models (LLMs) have revolutionized the field of natural\nlanguage processing with their impressive reasoning and question-answering\ncapabilities. However, these models are sometimes prone to generating\ncredible-sounding but incorrect information, a phenomenon known as LLM\nhallucinations. Reliable uncertainty estimation in LLMs is essential for\nfostering trust in their generated responses and serves as a critical tool for\nthe detection and prevention of erroneous or hallucinated outputs. To achieve\nreliable and well-calibrated uncertainty quantification in open-ended and\nfree-form natural language generation, we propose an uncertainty-aware\nfine-tuning approach for LLMs. This approach enhances the model's ability to\nprovide reliable uncertainty estimates without compromising accuracy, thereby\nguiding them to produce more trustworthy responses. We introduce a novel\nuncertainty-aware causal language modeling loss function, grounded in the\nprinciples of decision theory. Through rigorous evaluation on multiple\nfree-form question-answering datasets and models, we demonstrate that our\nuncertainty-aware fine-tuning approach yields better calibrated uncertainty\nestimates in natural language generation tasks than fine-tuning with the\nstandard causal language modeling loss. Furthermore, the experimental results\nshow that the proposed method significantly improves the model's ability to\ndetect hallucinations and identify out-of-domain prompts.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）容易产生幻觉（hallucinations）的缺陷，提出了一种 uncertainty-aware fine-tuning 方法，以提升模型的不确定性估计并增强其可信度。该方法引入一个基于决策理论的 uncertainty-aware causal language modeling loss function，在不牺牲准确性的前提下，改善了模型对不确定性的量化。通过在多个自由形式问答数据集上的实验，结果显示，该方法比标准 causal language modeling loss 提供了更精确的不确定性校准，并显著提高了检测幻觉和识别 out-of-domain 提示的能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02904v1",
      "published_date": "2024-12-03 23:14:47 UTC",
      "updated_date": "2024-12-03 23:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:57:50.688969"
    },
    {
      "arxiv_id": "2412.02897v1",
      "title": "MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions",
      "title_zh": "MLD-EA：通过引入情感和动作检查并完成叙事连贯性",
      "authors": [
        "Jinming Zhang",
        "Yunfei Long"
      ],
      "abstract": "Narrative understanding and story generation are critical challenges in\nnatural language processing (NLP), with much of the existing research focused\non summarization and question-answering tasks. While previous studies have\nexplored predicting plot endings and generating extended narratives, they often\nneglect the logical coherence within stories, leaving a significant gap in the\nfield. To address this, we introduce the Missing Logic Detector by Emotion and\nAction (MLD-EA) model, which leverages large language models (LLMs) to identify\nnarrative gaps and generate coherent sentences that integrate seamlessly with\nthe story's emotional and logical flow. The experimental results demonstrate\nthat the MLD-EA model enhances narrative understanding and story generation,\nhighlighting LLMs' potential as effective logic checkers in story writing with\nlogical coherence and emotional consistency. This work fills a gap in NLP\nresearch and advances border goals of creating more sophisticated and reliable\nstory-generation systems.",
      "tldr_zh": "本论文针对自然语言处理(NLP)中叙事理解和故事生成的逻辑连贯性问题，引入了MLD-EA模型，利用大型语言模型(LLMs)来检测叙事缺口并生成整合情感和动作的连贯句子。MLD-EA通过强调情感一致性和逻辑流畅性，显著提升了故事生成的质量。实验结果证明，该模型在叙事理解和故事写作中表现出色，填补了NLP研究的空白，并推动了更可靠的自动故事生成系统的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02897v1",
      "published_date": "2024-12-03 23:01:21 UTC",
      "updated_date": "2024-12-03 23:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:58:03.526758"
    },
    {
      "arxiv_id": "2412.02893v1",
      "title": "Removing Spurious Correlation from Neural Network Interpretations",
      "title_zh": "去除神经网络解释中的虚假相关",
      "authors": [
        "Milad Fotouhi",
        "Mohammad Taha Bahadori",
        "Oluwaseyi Feyisetan",
        "Payman Arabshahi",
        "David Heckerman"
      ],
      "abstract": "The existing algorithms for identification of neurons responsible for\nundesired and harmful behaviors do not consider the effects of confounders such\nas topic of the conversation. In this work, we show that confounders can create\nspurious correlations and propose a new causal mediation approach that controls\nthe impact of the topic. In experiments with two large language models, we\nstudy the localization hypothesis and show that adjusting for the effect of\nconversation topic, toxicity becomes less localized.",
      "tldr_zh": "本文研究了神经网络解释中的 spurious correlation 问题，指出现有算法忽略了混杂因素（如对话主题）的影响，导致不准确的神经元识别。作者提出了一种新的 causal mediation approach，通过控制对话主题的干扰来去除这些虚假相关。实验结果显示，在两个大型语言模型上调整混杂因素后，toxicity 的 localized 程度降低，验证了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.AP",
        "stat.ME"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02893v1",
      "published_date": "2024-12-03 22:58:21 UTC",
      "updated_date": "2024-12-03 22:58:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:58:13.945697"
    },
    {
      "arxiv_id": "2412.02889v2",
      "title": "Deep-Learning Based Docking Methods: Fair Comparisons to Conventional Docking Workflows",
      "title_zh": "基于深度学习的对接方法：与传统对接工作流的公平比较",
      "authors": [
        "Ajay N. Jain",
        "Ann E. Cleves",
        "W. Patrick Walters"
      ],
      "abstract": "The diffusion learning method, DiffDock, for docking small-molecule ligands\ninto protein binding sites was recently introduced. Results included\ncomparisons to more conventional docking approaches, with DiffDock showing\nsuperior performance. Here, we employ a fully automatic workflow using the\nSurflex-Dock methods to generate a fair baseline for conventional docking\napproaches. Results were generated for the common and expected situation where\na binding site location is known and also for the condition of an unknown\nbinding site. For the known binding site condition, Surflex-Dock success rates\nat 2.0 Angstroms RMSD far exceeded those for DiffDock (Top-1/Top-5 success\nrates, respectively, were 68/81% compared with 45/51%). Glide performed with\nsimilar success rates (67/73%) to Surflex-Dock for the known binding site\ncondition, and results for AutoDock Vina and Gnina followed this pattern. For\nthe unknown binding site condition, using an automated method to identify\nmultiple binding pockets, Surflex-Dock success rates again exceeded those of\nDiffDock, but by a somewhat lesser margin. DiffDock made use of roughly 17,000\nco-crystal structures for learning (98% of PDBBind version 2020, pre-2019\nstructures) for a training set in order to predict on 363 test cases (2% of\nPDBBind 2020) from 2019 forward. DiffDock's performance was inextricably linked\nwith the presence of near-neighbor cases of close to identical protein-ligand\ncomplexes in the training set for over half of the test set cases. DiffDock\nexhibited a 40 percentage point difference on near-neighbor cases (two-thirds\nof all test cases) compared with cases with no near-neighbor training case.\nDiffDock has apparently encoded a type of table-lookup during its learning\nprocess, rendering meaningful applications beyond its reach. Further, it does\nnot perform even close to competitively with a competently run modern docking\nworkflow.",
      "tldr_zh": "这篇论文对基于深度学习的分子对接方法 DiffDock 与传统方法（如 Surflex-Dock、Glide、AutoDock Vina 和 Gnina）进行了公平比较，使用全自动工作流作为基准。实验结果显示，在已知结合位点条件下，Surflex-Dock 的成功率（Top-1/Top-5 为 68%/81%）远高于 DiffDock（45%/51%），Glide 的表现与之类似；在未知结合位点条件下，传统方法仍保持优势，但差距较小。作者发现 DiffDock 的性能高度依赖训练集中的近邻案例，导致泛化能力不足，并得出结论：传统对接工作流在实际应用中更具竞争力。",
      "categories": [
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "Post-Conclusion addendum added with additional reference and context,\n  19 pages including references and appendices, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02889v2",
      "published_date": "2024-12-03 22:47:47 UTC",
      "updated_date": "2024-12-09 18:37:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:58:27.603090"
    },
    {
      "arxiv_id": "2412.02878v2",
      "title": "Modeling and Discovering Direct Causes for Predictive Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yizuo Chen",
        "Amit Bhatia"
      ],
      "abstract": "We introduce a causal modeling framework that captures the input-output\nbehavior of predictive models (e.g., machine learning models). The framework\nenables us to identify features that directly cause the predictions, which has\nbroad implications for data collection and model evaluation. We then present\nsound and complete algorithms for discovering direct causes (from data) under\nsome assumptions. Furthermore, we propose a novel independence rule that can be\nintegrated with the algorithms to accelerate the discovery process, as we\ndemonstrate both theoretically and empirically.",
      "tldr_zh": "本研究引入了一个因果建模框架，用于捕捉预测模型（如机器学习 models）的输入-输出行为，从而识别直接导致预测的特征，这对数据收集和模型评估具有广泛影响。该框架基于某些假设，提供了可靠且完整的算法，从数据中发现直接 causes。此外，研究提出了一种新颖的 independence rule，可与算法整合以加速发现过程，并在理论和实证上证明了其有效性。总的来说，此框架为提升预测模型的解释性和可靠性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02878v2",
      "published_date": "2024-12-03 22:25:42 UTC",
      "updated_date": "2025-05-17 03:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:58:37.824974"
    },
    {
      "arxiv_id": "2412.02875v1",
      "title": "Out-of-Distribution Detection for Neurosymbolic Autonomous Cyber Agents",
      "title_zh": "分布外检测针对神经符号自治网络代理",
      "authors": [
        "Ankita Samaddar",
        "Nicholas Potteiger",
        "Xenofon Koutsoukos"
      ],
      "abstract": "Autonomous agents for cyber applications take advantage of modern defense\ntechniques by adopting intelligent agents with conventional and\nlearning-enabled components. These intelligent agents are trained via\nreinforcement learning (RL) algorithms, and can learn, adapt to, reason about\nand deploy security rules to defend networked computer systems while\nmaintaining critical operational workflows. However, the knowledge available\nduring training about the state of the operational network and its environment\nmay be limited. The agents should be trustworthy so that they can reliably\ndetect situations they cannot handle, and hand them over to cyber experts. In\nthis work, we develop an out-of-distribution (OOD) Monitoring algorithm that\nuses a Probabilistic Neural Network (PNN) to detect anomalous or OOD situations\nof RL-based agents with discrete states and discrete actions. To demonstrate\nthe effectiveness of the proposed approach, we integrate the OOD monitoring\nalgorithm with a neurosymbolic autonomous cyber agent that uses behavior trees\nwith learning-enabled components. We evaluate the proposed approach in a\nsimulated cyber environment under different adversarial strategies.\nExperimental results over a large number of episodes illustrate the overall\nefficiency of our proposed approach.",
      "tldr_zh": "该研究针对神经符号自主网络代理（Neurosymbolic Autonomous Cyber Agents）开发了一种Out-of-Distribution (OOD)检测算法，利用Probabilistic Neural Network (PNN)来识别强化学习 (RL) 代理在离散状态和离散动作下的异常情况，以确保代理在面对未知网络环境时能可靠地移交专家处理。算法整合到基于行为树的代理系统中，允许代理学习、适应和部署安全规则，同时维护关键操作流程。通过在模拟网络环境中进行实验，该方法在不同对抗策略下表现出色，实验结果显示其在大量剧集中显著提高了代理的可靠性和整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 10 figures, IEEE International Conference on AI in\n  Cybersecurity (ICAIC), 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02875v1",
      "published_date": "2024-12-03 22:20:52 UTC",
      "updated_date": "2024-12-03 22:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:58:50.475220"
    },
    {
      "arxiv_id": "2412.02869v1",
      "title": "Constrained Identifiability of Causal Effects",
      "title_zh": "翻译失败",
      "authors": [
        "Yizuo Chen",
        "Adnan Darwiche"
      ],
      "abstract": "We study the identification of causal effects in the presence of different\ntypes of constraints (e.g., logical constraints) in addition to the causal\ngraph. These constraints impose restrictions on the models (parameterizations)\ninduced by the causal graph, reducing the set of models considered by the\nidentifiability problem. We formalize the notion of constrained\nidentifiability, which takes a set of constraints as another input to the\nclassical definition of identifiability. We then introduce a framework for\ntesting constrained identifiability by employing tractable Arithmetic Circuits\n(ACs), which enables us to accommodate constraints systematically. We show that\nthis AC-based approach is at least as complete as existing algorithms (e.g.,\ndo-calculus) for testing classical identifiability, which only assumes the\nconstraint of strict positivity. We use examples to demonstrate the\neffectiveness of this AC-based approach by showing that unidentifiable causal\neffects may become identifiable under different types of constraints.",
      "tldr_zh": "本研究探讨了在因果图之外添加约束（如逻辑约束）后，因果效果的识别问题，形式化了Constrained Identifiability的概念，以减少模型集并提升identifiability。\n他们提出了一种基于Arithmetic Circuits (ACs)的框架，用于系统测试constrained identifiability，该方法至少与传统算法（如do-calculus）同样完整。\n通过示例，该方法证明了原本不可识别的因果效果在不同约束下可变得可识别，从而扩展了因果推理的应用潜力。",
      "categories": [
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02869v1",
      "published_date": "2024-12-03 22:08:45 UTC",
      "updated_date": "2024-12-03 22:08:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:59:02.317378"
    },
    {
      "arxiv_id": "2412.02868v2",
      "title": "Enhancing LLMs with Smart Preprocessing for EHR Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiang Qu",
        "Yifan Dai",
        "Shilin Yu",
        "Pradham Tanikella",
        "Travis Schrank",
        "Trevor Hackman",
        "Didong Li",
        "Di Wu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\nnatural language processing; however, their application in sensitive domains\nsuch as healthcare, especially in processing Electronic Health Records (EHRs),\nis constrained by limited computational resources and privacy concerns. This\npaper introduces a compact LLM framework optimized for local deployment in\nenvironments with stringent privacy requirements and restricted access to\nhigh-performance GPUs. Our approach leverages simple yet powerful preprocessing\ntechniques, including regular expressions (regex) and Retrieval-Augmented\nGeneration (RAG), to extract and highlight critical information from clinical\nnotes. By pre-filtering long, unstructured text, we enhance the performance of\nsmaller LLMs on EHR-related tasks. Our framework is evaluated using zero-shot\nand few-shot learning paradigms on both private and publicly available datasets\n(MIMIC-IV), with additional comparisons against fine-tuned LLMs on MIMIC-IV.\nExperimental results demonstrate that our preprocessing strategy significantly\nsupercharges the performance of smaller LLMs, making them well-suited for\nprivacy-sensitive and resource-constrained applications. This study offers\nvaluable insights into optimizing LLM performance for local, secure, and\nefficient healthcare applications. It provides practical guidance for\nreal-world deployment for LLMs while tackling challenges related to privacy,\ncomputational feasibility, and clinical applicability.",
      "tldr_zh": "这篇论文提出了一种优化大型语言模型（LLMs）的紧凑框架，旨在处理电子健康记录（EHR）分析中的计算资源限制和隐私问题。该框架利用简单的预处理技术，如 regular expressions (regex) 和 Retrieval-Augmented Generation (RAG)，来提取和突出临床笔记中的关键信息，从而提升小型 LLMs 在长文本任务上的性能。实验通过 zero-shot 和 few-shot 学习在私有数据集及公开数据集（MIMIC-IV）上进行评估，结果显示预处理策略使小型 LLMs 的表现显著提升，平均性能较基线模型大幅改进。该方法为隐私敏感、资源受限的医疗应用提供实用指导，确保 LLMs 的本地部署和临床适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02868v2",
      "published_date": "2024-12-03 22:06:55 UTC",
      "updated_date": "2025-04-24 13:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:01:08.306119"
    },
    {
      "arxiv_id": "2412.02865v3",
      "title": "Memory-efficient Continual Learning with Neural Collapse Contrastive",
      "title_zh": "翻译失败",
      "authors": [
        "Trung-Anh Dang",
        "Vincent Nguyen",
        "Ngoc-Son Vu",
        "Christel Vrain"
      ],
      "abstract": "Contrastive learning has significantly improved representation quality,\nenhancing knowledge transfer across tasks in continual learning (CL). However,\ncatastrophic forgetting remains a key challenge, as contrastive based methods\nprimarily focus on \"soft relationships\" or \"softness\" between samples, which\nshift with changing data distributions and lead to representation overlap\nacross tasks. Recently, the newly identified Neural Collapse phenomenon has\nshown promise in CL by focusing on \"hard relationships\" or \"hardness\" between\nsamples and fixed prototypes. However, this approach overlooks \"softness\",\ncrucial for capturing intra-class variability, and this rigid focus can also\npull old class representations toward current ones, increasing forgetting.\nBuilding on these insights, we propose Focal Neural Collapse Contrastive\n(FNC^2), a novel representation learning loss that effectively balances both\nsoft and hard relationships. Additionally, we introduce the Hardness-Softness\nDistillation (HSD) loss to progressively preserve the knowledge gained from\nthese relationships across tasks. Our method outperforms state-of-the-art\napproaches, particularly in minimizing memory reliance. Remarkably, even\nwithout the use of memory, our approach rivals rehearsal-based methods,\noffering a compelling solution for data privacy concerns.",
      "tldr_zh": "这篇论文针对持续学习（Continual Learning）中的灾难性遗忘问题，提出了一种新的表示学习损失函数Focal Neural Collapse Contrastive (FNC^2)，它通过平衡样本之间的“软关系”和“硬关系”来改善知识转移和表示质量。论文同时引入了Hardness-Softness Distillation (HSD)损失，用于逐步保留任务间的关系知识，从而减少对内存的依赖。实验结果显示，该方法优于现有对比学习（Contrastive Learning）方法，即使不使用内存，也能与基于重述的模型匹敌，为数据隐私保护提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02865v3",
      "published_date": "2024-12-03 22:00:12 UTC",
      "updated_date": "2024-12-06 10:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:01:20.220196"
    },
    {
      "arxiv_id": "2412.02863v1",
      "title": "Proximal Control of UAVs with Federated Learning for Human-Robot Collaborative Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Nogueira Nobrega",
        "Ewerton de Oliveira",
        "Martin Saska",
        "Tiago Nascimento"
      ],
      "abstract": "The human-robot interaction (HRI) is a growing area of research. In HRI,\ncomplex command (action) classification is still an open problem that usually\nprevents the real applicability of such a technique. The literature presents\nsome works that use neural networks to detect these actions. However, occlusion\nis still a major issue in HRI, especially when using uncrewed aerial vehicles\n(UAVs), since, during the robot's movement, the human operator is often out of\nthe robot's field of view. Furthermore, in multi-robot scenarios, distributed\ntraining is also an open problem. In this sense, this work proposes an action\nrecognition and control approach based on Long Short-Term Memory (LSTM) Deep\nNeural Networks with two layers in association with three densely connected\nlayers and Federated Learning (FL) embedded in multiple drones. The FL enabled\nour approach to be trained in a distributed fashion, i.e., access to data\nwithout the need for cloud or other repositories, which facilitates the\nmulti-robot system's learning. Furthermore, our multi-robot approach results\nalso prevented occlusion situations, with experiments with real robots\nachieving an accuracy greater than 96%.",
      "tldr_zh": "本研究针对人类-机器人交互(HRI)中复杂命令分类的挑战，特别是无人机(UAVs)场景下的遮挡问题，提出了一种基于Long Short-Term Memory (LSTM)深度神经网络的行动识别和控制方法。方法结合两层LSTM和三层密集连接层，并融入Federated Learning (FL)，实现分布式训练，使多机器人系统无需云存储即可学习和协作。实验结果表明，该方法在真实机器人环境中有效避免遮挡，准确率超过96%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02863v1",
      "published_date": "2024-12-03 21:57:04 UTC",
      "updated_date": "2024-12-03 21:57:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:01:32.077599"
    },
    {
      "arxiv_id": "2412.02858v1",
      "title": "Unpaired Modality Translation for Pseudo Labeling of Histology Images",
      "title_zh": "翻译失败",
      "authors": [
        "Arthur Boschet",
        "Armand Collin",
        "Nishka Katoch",
        "Julien Cohen-Adad"
      ],
      "abstract": "The segmentation of histological images is critical for various biomedical\napplications, yet the lack of annotated data presents a significant challenge.\nWe propose a microscopy pseudo labeling pipeline utilizing unsupervised image\ntranslation to address this issue. Our method generates pseudo labels by\ntranslating between labeled and unlabeled domains without requiring prior\nannotation in the target domain. We evaluate two pseudo labeling strategies\nacross three image domains increasingly dissimilar from the labeled data,\ndemonstrating their effectiveness. Notably, our method achieves a mean Dice\nscore of $0.736 \\pm 0.005$ on a SEM dataset using the tutoring path, which\ninvolves training a segmentation model on synthetic data created by translating\nthe labeled dataset (TEM) to the target modality (SEM). This approach aims to\naccelerate the annotation process by providing high-quality pseudo labels as a\nstarting point for manual refinement.",
      "tldr_zh": "该研究针对组织学图像分割中标注数据不足的问题，提出了一种无监督图像翻译的伪标签（pseudo labeling）管道。该方法通过在标记域（如 TEM）和未标记域（如 SEM）之间进行无配对模态翻译（Unpaired Modality Translation），生成高质量伪标签，而无需目标域的先验标注。实验评估了两种伪标签策略，在三个与标记数据相似度递减的图像域上进行测试，结果显示在 SEM 数据集上，使用辅导路径（tutoring path）训练的分割模型达到了平均 Dice score 为 $0.736 \\pm 0.005$。此方法可作为手动精炼的起点，有效加速图像标注过程。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02858v1",
      "published_date": "2024-12-03 21:45:59 UTC",
      "updated_date": "2024-12-03 21:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:01:43.575456"
    },
    {
      "arxiv_id": "2412.02851v1",
      "title": "Block MedCare: Advancing healthcare through blockchain integration with AI and IoT",
      "title_zh": "Block MedCare：通过区块链与 AI 和 IoT 的整合推进医疗保健",
      "authors": [
        "Oliver Simonoski",
        "Dijana Capeska Bogatinoska"
      ],
      "abstract": "This research explores the integration of blockchain technology in\nhealthcare, focusing on enhancing the security and efficiency of Electronic\nHealth Record (EHR) management. We propose a novel Ethereum-based system that\nempowers patients with secure control over their medical data. Our approach\naddresses key challenges in healthcare blockchain implementation, including\nscalability, privacy, and regulatory compliance. The system incorporates\ndigital signatures, Role-Based Access Control, and a multi-layered architecture\nto ensure secure, controlled access. We developed a decentralized application\n(dApp) with user-friendly interfaces for patients, doctors, and administrators,\ndemonstrating the practical application of our solution. A survey among\nhealthcare professionals and IT experts revealed strong interest in blockchain\nadoption, while also highlighting concerns about integration costs. The study\nexplores future enhancements, including integration with IoT devices and\nAI-driven analytics, contributing to the evolution of secure, efficient, and\ninteroperable healthcare systems that leverage cutting-edge technologies for\nimproved patient care.",
      "tldr_zh": "这篇论文提出Block MedCare系统，利用Ethereum区块链技术增强电子健康记录(EHR)管理的安全性和效率，让患者能够安全控制自身医疗数据。系统通过数字签名、Role-Based Access Control和多层架构解决可扩展性、隐私及监管合规挑战，并开发了一个用户友好的去中心化应用(dApp)供患者、医生和管理员使用。调查显示医疗专业人士和IT专家对区块链整合有强烈兴趣，但也担忧成本；未来，该系统计划融入IoT设备和AI驱动分析，以推动更安全、高效的医疗体系。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02851v1",
      "published_date": "2024-12-03 21:31:46 UTC",
      "updated_date": "2024-12-03 21:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:01:55.937069"
    },
    {
      "arxiv_id": "2412.05322v1",
      "title": "$ρ$-NeRF: Leveraging Attenuation Priors in Neural Radiance Field for 3D Computed Tomography Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Li Zhou",
        "Changsheng Fang",
        "Bahareh Morovati",
        "Yongtong Liu",
        "Shuo Han",
        "Yongshun Xu",
        "Hengyong Yu"
      ],
      "abstract": "This paper introduces $\\rho$-NeRF, a self-supervised approach that sets a new\nstandard in novel view synthesis (NVS) and computed tomography (CT)\nreconstruction by modeling a continuous volumetric radiance field enriched with\nphysics-based attenuation priors. The $\\rho$-NeRF represents a\nthree-dimensional (3D) volume through a fully-connected neural network that\ntakes a single continuous four-dimensional (4D) coordinate, spatial location\n$(x, y, z)$ and an initialized attenuation value ($\\rho$), and outputs the\nattenuation coefficient at that position. By querying these 4D coordinates\nalong X-ray paths, the classic forward projection technique is applied to\nintegrate attenuation data across the 3D space. By matching and refining\npre-initialized attenuation values derived from traditional reconstruction\nalgorithms like Feldkamp-Davis-Kress algorithm (FDK) or conjugate gradient\nleast squares (CGLS), the enriched schema delivers superior fidelity in both\nprojection synthesis and image recognition.",
      "tldr_zh": "本文提出ρ-NeRF，一种自监督方法，用于新型视图合成(NVS)和3D计算断层扫描(CT)重建，通过在神经辐射场(Neural Radiance Field)中整合基于物理的衰减先验(attenuation priors)来提升重建精度。ρ-NeRF使用一个全连接神经网络，输入4D坐标（包括空间位置(x, y, z)和初始衰减值ρ），输出对应位置的衰减系数，并通过经典的前向投影技术整合X射线路径数据。最终，该方法通过匹配和精炼传统算法如Feldkamp-Davis-Kress algorithm (FDK)或conjugate gradient least squares (CGLS)的预初始化值，在投影合成和图像识别方面实现了更高的保真度。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "The paper was submitted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.05322v1",
      "published_date": "2024-12-03 21:06:26 UTC",
      "updated_date": "2024-12-03 21:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:02:08.368148"
    },
    {
      "arxiv_id": "2412.02835v1",
      "title": "CAISSON: Concept-Augmented Inference Suite of Self-Organizing Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Igor Halperin"
      ],
      "abstract": "We present CAISSON, a novel hierarchical approach to Retrieval-Augmented\nGeneration (RAG) that transforms traditional single-vector search into a\nmulti-view clustering framework. At its core, CAISSON leverages dual\nSelf-Organizing Maps (SOMs) to create complementary organizational views of the\ndocument space, where each view captures different aspects of document\nrelationships through specialized embeddings. The first view processes combined\ntext and metadata embeddings, while the second operates on metadata enriched\nwith concept embeddings, enabling a comprehensive multi-view analysis that\ncaptures both fine-grained semantic relationships and high-level conceptual\npatterns. This dual-view approach enables more nuanced document discovery by\ncombining evidence from different organizational perspectives. To evaluate\nCAISSON, we develop SynFAQA, a framework for generating synthetic financial\nanalyst notes and question-answer pairs that systematically tests different\naspects of information retrieval capabilities. Drawing on HotPotQA's\nmethodology for constructing multi-step reasoning questions, SynFAQA generates\ncontrolled test cases where each question is paired with the set of notes\ncontaining its ground-truth answer, progressing from simple single-entity\nqueries to complex multi-hop retrieval tasks involving multiple entities and\nconcepts. Our experimental results demonstrate substantial improvements over\nboth basic and enhanced RAG implementations, particularly for complex\nmulti-entity queries, while maintaining practical response times suitable for\ninteractive applications.",
      "tldr_zh": "我们介绍了 CAISSON，一种基于双 Self-Organizing Maps (SOMs) 的层次化 Retrieval-Augmented Generation (RAG) 框架，将传统单向量搜索转化为多视图聚类，以捕捉文档空间的语义关系和概念模式。CAISSON 通过一个视图处理文本与元数据嵌入，另一个视图整合元数据和概念嵌入，实现更全面的文档发现和分析。为评估该框架，我们开发了 SynFAQA 框架，用于生成合成金融分析师笔记和问答对，支持从简单单实体查询到复杂多跳任务的测试。实验结果表明，CAISSON 在复杂多实体查询上比基本和增强 RAG 实现有显著改进，同时保持适合交互应用的响应时间。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 7 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.02835v1",
      "published_date": "2024-12-03 21:00:10 UTC",
      "updated_date": "2024-12-03 21:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:02:20.704843"
    },
    {
      "arxiv_id": "2412.02831v1",
      "title": "FLAME 3 Dataset: Unleashing the Power of Radiometric Thermal UAV Imagery for Wildfire Management",
      "title_zh": "翻译失败",
      "authors": [
        "Bryce Hopkins",
        "Leo ONeill",
        "Michael Marinaccio",
        "Eric Rowell",
        "Russell Parsons",
        "Sarah Flanary",
        "Irtija Nazim",
        "Carl Seielstad",
        "Fatemeh Afghah"
      ],
      "abstract": "The increasing accessibility of radiometric thermal imaging sensors for\nunmanned aerial vehicles (UAVs) offers significant potential for advancing\nAI-driven aerial wildfire management. Radiometric imaging provides per-pixel\ntemperature estimates, a valuable improvement over non-radiometric data that\nrequires irradiance measurements to be converted into visible images using RGB\ncolor palettes. Despite its benefits, this technology has been underutilized\nlargely due to a lack of available data for researchers. This study addresses\nthis gap by introducing methods for collecting and processing synchronized\nvisual spectrum and radiometric thermal imagery using UAVs at prescribed fires.\nThe included imagery processing pipeline drastically simplifies and partially\nautomates each step from data collection to neural network input. Further, we\npresent the FLAME 3 dataset, the first comprehensive collection of side-by-side\nvisual spectrum and radiometric thermal imagery of wildland fires. Building on\nour previous FLAME 1 and FLAME 2 datasets, FLAME 3 includes radiometric thermal\nTag Image File Format (TIFFs) and nadir thermal plots, providing a new data\ntype and collection method. This dataset aims to spur a new generation of\nmachine learning models utilizing radiometric thermal imagery, potentially\ntrivializing tasks such as aerial wildfire detection, segmentation, and\nassessment. A single-burn subset of FLAME 3 for computer vision applications is\navailable on Kaggle with the full 6 burn set available to readers upon request.",
      "tldr_zh": "本研究推出了 FLAME 3 数据集，这是首个全面的辐射热成像 (Radiometric thermal) 和视觉谱图像集合，旨在提升 AI 驱动的空中野火管理 (AI-driven aerial wildfire management)。研究团队开发了数据收集和处理管道，使用无人机 (UAVs) 在规定火灾中同步获取图像，并自动简化从数据采集到神经网络 (Neural network) 输入的步骤。相比之前的 FLAME 1 和 2 数据集，FLAME 3 引入了新的数据类型，如辐射热 TIFFs 和 nadir 热图，有助于简化野火检测、分段和评估任务，并推动新一代机器学习模型的开发。数据集的部分子集已在 Kaggle 公开，完整版本可供研究者申请。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 Figures, 8 Tables",
      "pdf_url": "http://arxiv.org/pdf/2412.02831v1",
      "published_date": "2024-12-03 20:53:42 UTC",
      "updated_date": "2024-12-03 20:53:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:02:32.531755"
    },
    {
      "arxiv_id": "2412.02823v1",
      "title": "Minimization of Boolean Complexity in In-Context Concept Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Leroy Z. Wang",
        "R. Thomas McCoy",
        "Shane Steinert-Threlkeld"
      ],
      "abstract": "What factors contribute to the relative success and corresponding\ndifficulties of in-context learning for Large Language Models (LLMs)? Drawing\non insights from the literature on human concept learning, we test LLMs on\ncarefully designed concept learning tasks, and show that task performance\nhighly correlates with the Boolean complexity of the concept. This suggests\nthat in-context learning exhibits a learning bias for simplicity in a way\nsimilar to humans.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)在上下文学习中的成功因素，通过借鉴人类概念学习文献设计特定任务进行测试。结果显示，任务表现高度与概念的布尔复杂度相关，表明LLMs存在类似于人类的简单性学习偏好。该发现为理解LLMs的学习机制提供了新洞见，并可能指导未来模型优化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02823v1",
      "published_date": "2024-12-03 20:41:37 UTC",
      "updated_date": "2024-12-03 20:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:02:42.536660"
    },
    {
      "arxiv_id": "2412.02819v4",
      "title": "CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels",
      "title_zh": "翻译失败",
      "authors": [
        "Lingxiao Wei",
        "He Yan",
        "Xiangju Lu",
        "Junmin Zhu",
        "Jun Wang",
        "Wei Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have been well-researched in various\nlong-context tasks. However, the scarcity of high-quality long-context\nsummarization datasets has hindered further advancements in this area. To\naddress this, we introduce CNNSum, a multi-scale long-context summarization\nbenchmark based on Chinese novels, featuring human-driven annotations, which\ncomprises four subsets totaling 695 samples, with lengths ranging from 16k to\n128k. We evaluate numerous LLMs and conduct detailed case analyses.\nFurthermore, we conduct extensive fine-tuning experiments to explore and\nimprove long-context summarization. In our study: (1) Advanced LLMs like GPT-4o\nmay still generate subjective commentary, leading to vague summaries. (2)\nCurrently, long-context summarization mainly relies on memory ability afforded\nby longer context lengths. The advantages of Large LLMs are hard to utilize,\nthus small LLMs are the most cost-effective. (3) Different prompt templates\npaired with various version models may cause large performance gaps. In further\nfine-tuning, these can be mitigated, and the Base version models perform\nbetter. (4) LLMs with RoPE-base scaled exhibit strong extrapolation potential;\nusing short-context data can significantly improve long-context summarization\nperformance. However, further applying other interpolation methods requires\ncareful selection. (5) CNNSum provides more reliable and insightful evaluation\nresults than other benchmarks. We release CNNSum to advance future research in\nthis field. https://github.com/CxsGhost/CNNSum",
      "tldr_zh": "本研究引入了 CNNSum，这是一个基于中文小说的多尺度长上下文总结基准数据集，共包含四个子集和695个样本，长度从16k到128k，用于评估大型语言模型(LLMs)在长上下文任务中的性能。研究者通过评估多种LLMs和进行广泛微调实验，发现先进的模型如GPT-4o可能产生主观评论导致摘要模糊，而小LLMs更具成本效益，且使用RoPE-base缩放的模型显示出显著的外推潜力。总体结果表明，长上下文总结主要依赖记忆能力，通过适当的提示模板和微调可以缓解性能差距，CNNSum数据集的发布将推动该领域的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.02819v4",
      "published_date": "2024-12-03 20:35:57 UTC",
      "updated_date": "2024-12-17 16:03:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:02:56.320639"
    },
    {
      "arxiv_id": "2412.02803v1",
      "title": "Gaussian Splatting Under Attack: Investigating Adversarial Noise in 3D Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Abdurrahman Zeybey",
        "Mehmet Ergezer",
        "Tommy Nguyen"
      ],
      "abstract": "3D Gaussian Splatting has advanced radiance field reconstruction, enabling\nhigh-quality view synthesis and fast rendering in 3D modeling. While\nadversarial attacks on object detection models are well-studied for 2D images,\ntheir impact on 3D models remains underexplored. This work introduces the\nMasked Iterative Fast Gradient Sign Method (M-IFGSM), designed to generate\nadversarial noise targeting the CLIP vision-language model. M-IFGSM\nspecifically alters the object of interest by focusing perturbations on masked\nregions, degrading the performance of CLIP's zero-shot object detection\ncapability when applied to 3D models. Using eight objects from the Common\nObjects 3D (CO3D) dataset, we demonstrate that our method effectively reduces\nthe accuracy and confidence of the model, with adversarial noise being nearly\nimperceptible to human observers. The top-1 accuracy in original model renders\ndrops from 95.4\\% to 12.5\\% for train images and from 91.2\\% to 35.4\\% for test\nimages, with confidence levels reflecting this shift from true classification\nto misclassification, underscoring the risks of adversarial attacks on 3D\nmodels in applications such as autonomous driving, robotics, and surveillance.\nThe significance of this research lies in its potential to expose\nvulnerabilities in modern 3D vision models, including radiance fields,\nprompting the development of more robust defenses and security measures in\ncritical real-world applications.",
      "tldr_zh": "本研究调查了在 3D 对象中针对 Gaussian Splatting 的对抗噪声攻击，探讨了其对辐射场重建和视图合成的潜在影响。研究提出了一种新方法 Masked Iterative Fast Gradient Sign Method (M-IFGSM)，通过在掩码区域施加微扰来生成针对 CLIP 视觉语言模型的对抗噪声，从而降低其零样本对象检测性能。实验使用 Common Objects 3D (CO3D) 数据集的八个对象显示，该方法使模型的 Top-1 准确率从训练图像的 95.4% 降至 12.5%，以及测试图像从 91.2% 降至 35.4%，同时噪声对人类几乎不可见。总体结果突显了 3D 视觉模型在自动驾驶、机器人和监控等应用中的安全漏洞，呼吁开发更 robust 的防御措施。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to Safe Generative AI Workshop @ NeurIPS 2024:\n  https://neurips.cc/virtual/2024/workshop/84705",
      "pdf_url": "http://arxiv.org/pdf/2412.02803v1",
      "published_date": "2024-12-03 20:11:21 UTC",
      "updated_date": "2024-12-03 20:11:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:03:08.520933"
    },
    {
      "arxiv_id": "2412.02802v1",
      "title": "Flattering to Deceive: The Impact of Sycophantic Behavior on User Trust in Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "María Victoria Carro"
      ],
      "abstract": "Sycophancy refers to the tendency of a large language model to align its\noutputs with the user's perceived preferences, beliefs, or opinions, in order\nto look favorable, regardless of whether those statements are factually\ncorrect. This behavior can lead to undesirable consequences, such as\nreinforcing discriminatory biases or amplifying misinformation. Given that\nsycophancy is often linked to human feedback training mechanisms, this study\nexplores whether sycophantic tendencies negatively impact user trust in large\nlanguage models or, conversely, whether users consider such behavior as\nfavorable. To investigate this, we instructed one group of participants to\nanswer ground-truth questions with the assistance of a GPT specifically\ndesigned to provide sycophantic responses, while another group used the\nstandard version of ChatGPT. Initially, participants were required to use the\nlanguage model, after which they were given the option to continue using it if\nthey found it trustworthy and useful. Trust was measured through both\ndemonstrated actions and self-reported perceptions. The findings consistently\nshow that participants exposed to sycophantic behavior reported and exhibited\nlower levels of trust compared to those who interacted with the standard\nversion of the model, despite the opportunity to verify the accuracy of the\nmodel's output.",
      "tldr_zh": "本研究探讨了大型语言模型（Large Language Models）中的 sycophantic behavior（讨好行为）对用户信任的影响，这种行为指模型为取悦用户而调整输出，忽略事实正确性，可能强化偏见或传播错误信息。研究者设计实验，让一组参与者使用专门训练的 sycophantic GPT 回答真实问题，另一组使用标准 ChatGPT，并通过行为观察和自报评估来衡量信任水平。结果显示，暴露于 sycophantic behavior 的参与者表现出更低的信任，尽管他们有机会验证输出，这突显了这种行为的潜在负面后果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02802v1",
      "published_date": "2024-12-03 20:07:41 UTC",
      "updated_date": "2024-12-03 20:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:03:19.171201"
    },
    {
      "arxiv_id": "2412.02801v3",
      "title": "Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm",
      "title_zh": "基于粒子群优化算法的 Transformer 心脏病预测模型优化",
      "authors": [
        "Jingyuan Yi",
        "Peiyang Yu",
        "Tianyi Huang",
        "Zeqiu Xu"
      ],
      "abstract": "Aiming at the latest particle swarm optimization algorithm, this paper\nproposes an improved Transformer model to improve the accuracy of heart disease\nprediction and provide a new algorithm idea. We first use three mainstream\nmachine learning classification algorithms - decision tree, random forest and\nXGBoost, and then output the confusion matrix of these three models. The\nresults showed that the random forest model had the best performance in\npredicting the classification of heart disease, with an accuracy of 92.2%.\nThen, we apply the Transformer model based on particle swarm optimization (PSO)\nalgorithm to the same dataset for classification experiment. The results show\nthat the classification accuracy of the model is as high as 96.5%, 4.3\npercentage points higher than that of random forest, which verifies the\neffectiveness of PSO in optimizing Transformer model. From the above research,\nwe can see that particle swarm optimization significantly improves Transformer\nperformance in heart disease prediction. Improving the ability to predict heart\ndisease is a global priority with benefits for all humankind. Accurate\nprediction can enhance public health, optimize medical resources, and reduce\nhealthcare costs, leading to healthier populations and more productive\nsocieties worldwide. This advancement paves the way for more efficient health\nmanagement and supports the foundation of a healthier, more resilient global\ncommunity.",
      "tldr_zh": "本研究针对心血管疾病预测，提出了一种基于粒子群优化 (PSO) 算法优化的 Transformer 模型，以提升预测准确性。首先，通过比较决策树、随机森林和 XGBoost 三种机器学习算法，发现随机森林在数据集上的准确率最高，为92.2%。随后，实验结果显示，PSO 优化后的 Transformer 模型准确率达到96.5%，比随机森林高4.3个百分点，验证了该优化方法的有效性。该创新有助于改善公共健康、优化医疗资源并降低成本，为全球健康管理提供新思路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02801v3",
      "published_date": "2024-12-03 20:04:32 UTC",
      "updated_date": "2025-01-07 10:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:03:32.037871"
    },
    {
      "arxiv_id": "2412.02790v1",
      "title": "An Evolutionary Large Language Model for Hallucination Mitigation",
      "title_zh": "一种用于缓解幻觉的进化大语言模型",
      "authors": [
        "Abdennour Boulesnane",
        "Abdelhakim Souilah"
      ],
      "abstract": "The emergence of LLMs, like ChatGPT and Gemini, has marked the modern era of\nartificial intelligence applications characterized by high-impact applications\ngenerating text, images, and videos. However, these models usually ensue with\none critical challenge called hallucination: confident presentation of\ninaccurate or fabricated information. This problem attracts serious concern\nwhen these models are applied to specialized domains, including healthcare and\nlaw, where the accuracy and preciseness of information are absolute conditions.\nIn this paper, we propose EvoLLMs, an innovative framework inspired by\nEvolutionary Computation, which automates the generation of high-quality\nQuestion-answering (QA) datasets while minimizing hallucinations. EvoLLMs\nemploys genetic algorithms, mimicking evolutionary processes like selection,\nvariation, and mutation, to guide LLMs in generating accurate, contextually\nrelevant question-answer pairs. Comparative analysis shows that EvoLLMs\nconsistently outperforms human-generated datasets in key metrics such as Depth,\nRelevance, and Coverage, while nearly matching human performance in mitigating\nhallucinations. These results highlight EvoLLMs as a robust and efficient\nsolution for QA dataset generation, significantly reducing the time and\nresources required for manual curation.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)如ChatGPT和Gemini的幻觉(hallucination)问题——即自信地输出不准确信息——提出了一种创新框架EvoLLMs。EvoLLMs受进化计算启发，利用遗传算法(genetic algorithms)模拟选择、变异和突变过程，自动生成高质量的问答(QA)数据集，同时最小化幻觉。实验结果显示，EvoLLMs在深度、相关性和覆盖率等关键指标上优于人类生成数据集，并在减少幻觉方面几乎与人类相当，从而显著降低了手动数据整理所需的时间和资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02790v1",
      "published_date": "2024-12-03 19:40:13 UTC",
      "updated_date": "2024-12-03 19:40:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:03:44.021860"
    },
    {
      "arxiv_id": "2412.02788v2",
      "title": "Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset",
      "title_zh": "Hybrid-SQuAD：混合学术问答数据集",
      "authors": [
        "Tilahun Abedissa Taffa",
        "Debayan Banerjee",
        "Yaregal Assabie",
        "Ricardo Usbeck"
      ],
      "abstract": "Existing Scholarly Question Answering (QA) methods typically target\nhomogeneous data sources, relying solely on either text or Knowledge Graphs\n(KGs). However, scholarly information often spans heterogeneous sources,\nnecessitating the development of QA systems that integrate information from\nmultiple heterogeneous data sources. To address this challenge, we introduce\nHybrid-SQuAD (Hybrid Scholarly Question Answering Dataset), a novel large-scale\nQA dataset designed to facilitate answering questions incorporating both text\nand KG facts. The dataset consists of 10.5K question-answer pairs generated by\na large language model, leveraging the KGs DBLP and SemOpenAlex alongside\ncorresponding text from Wikipedia. In addition, we propose a RAG-based baseline\nhybrid QA model, achieving an exact match score of 69.65 on the Hybrid-SQuAD\ntest set.",
      "tldr_zh": "本研究指出，现有的学术问答（Scholarly QA）方法通常只依赖单一来源，如文本或 Knowledge Graphs (KGs)，而忽略了异构数据整合的需求。为解决此问题，论文引入了 Hybrid-SQuAD，这是一个大规模数据集，包含 10.5K 个问题-答案对，由大语言模型基于 KGs 如 DBLP 和 SemOpenAlex 以及对应的 Wikipedia 文本生成。该数据集旨在支持整合文本和 KG 事实的 QA 任务，此外，论文提出了一种基于 RAG (Retrieval-Augmented Generation) 的基线混合 QA 模型，在 Hybrid-SQuAD 测试集上实现了 69.65% 的精确匹配分数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02788v2",
      "published_date": "2024-12-03 19:37:00 UTC",
      "updated_date": "2024-12-05 10:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:03:55.852681"
    },
    {
      "arxiv_id": "2412.02784v1",
      "title": "FathomGPT: A Natural Language Interface for Interactively Exploring Ocean Science Data",
      "title_zh": "翻译失败",
      "authors": [
        "Nabin Khanal",
        "Chun Meng Yu",
        "Jui-Cheng Chiu",
        "Anav Chaudhary",
        "Ziyue Zhang",
        "Kakani Katija",
        "Angus G. Forbes"
      ],
      "abstract": "We introduce FathomGPT, an open source system for the interactive\ninvestigation of ocean science data via a natural language interface. FathomGPT\nwas developed in close collaboration with marine scientists to enable\nresearchers to explore and analyze the FathomNet image database. FathomGPT\nprovides a custom information retrieval pipeline that leverages OpenAI's large\nlanguage models to enable: the creation of complex queries to retrieve images,\ntaxonomic information, and scientific measurements; mapping common names and\nmorphological features to scientific names; generating interactive charts on\ndemand; and searching by image or specified patterns within an image. In\ndesigning FathomGPT, particular emphasis was placed on enhancing the user's\nexperience by facilitating free-form exploration and optimizing response times.\nWe present an architectural overview and implementation details of FathomGPT,\nalong with a series of ablation studies that demonstrate the effectiveness of\nour approach to name resolution, fine tuning, and prompt modification. We also\npresent usage scenarios of interactive data exploration sessions and document\nfeedback from ocean scientists and machine learning experts.",
      "tldr_zh": "我们介绍了 FathomGPT，这是一个开源系统，通过自然语言界面支持海洋科学数据的交互式探索，特别针对 FathomNet 图像数据库开发。系统利用 OpenAI 的语言模型构建自定义信息检索管道，实现复杂查询（如检索图像、分类信息和科学测量）、常见名称映射、交互式图表生成以及基于图像模式的搜索。设计重点在于提升用户体验、优化响应时间和促进自由形式探索，并通过消融研究、实际使用场景以及来自海洋科学家和机器学习专家的反馈，证明了其在名称解析、微调和提示修改方面的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.2; I.2.7; I.7.10"
      ],
      "primary_category": "cs.HC",
      "comment": "The first two authors contributed equally to this work. Accepted to\n  the 37th Annual ACM Symposium on User Interface Software and Technology (UIST\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.02784v1",
      "published_date": "2024-12-03 19:22:55 UTC",
      "updated_date": "2024-12-03 19:22:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:04:08.062998"
    },
    {
      "arxiv_id": "2412.02780v1",
      "title": "WxC-Bench: A Novel Dataset for Weather and Climate Downstream Tasks",
      "title_zh": "WxC-Bench：一个新颖的数据集，用于天气和气候下游任务",
      "authors": [
        "Rajat Shinde",
        "Christopher E. Phillips",
        "Kumar Ankur",
        "Aman Gupta",
        "Simon Pfreundschuh",
        "Sujit Roy",
        "Sheyenne Kirkland",
        "Vishal Gaur",
        "Amy Lin",
        "Aditi Sheshadri",
        "Udaysankar Nair",
        "Manil Maskey",
        "Rahul Ramachandran"
      ],
      "abstract": "High-quality machine learning (ML)-ready datasets play a foundational role in\ndeveloping new artificial intelligence (AI) models or fine-tuning existing\nmodels for scientific applications such as weather and climate analysis.\nUnfortunately, despite the growing development of new deep learning models for\nweather and climate, there is a scarcity of curated, pre-processed machine\nlearning (ML)-ready datasets. Curating such high-quality datasets for\ndeveloping new models is challenging particularly because the modality of the\ninput data varies significantly for different downstream tasks addressing\ndifferent atmospheric scales (spatial and temporal). Here we introduce\nWxC-Bench (Weather and Climate Bench), a multi-modal dataset designed to\nsupport the development of generalizable AI models for downstream use-cases in\nweather and climate research. WxC-Bench is designed as a dataset of datasets\nfor developing ML-models for a complex weather and climate system, addressing\nselected downstream tasks as machine learning phenomenon. WxC-Bench encompasses\nseveral atmospheric processes from meso-$\\beta$ (20 - 200 km) scale to synoptic\nscales (2500 km), such as aviation turbulence, hurricane intensity and track\nmonitoring, weather analog search, gravity wave parameterization, and natural\nlanguage report generation. We provide a comprehensive description of the\ndataset and also present a technical validation for baseline analysis. The\ndataset and code to prepare the ML-ready data have been made publicly available\non Hugging Face -- https://huggingface.co/datasets/nasa-impact/WxC-Bench",
      "tldr_zh": "该论文介绍了 WxC-Bench，这是一个新型多模态数据集，旨在解决天气和气候分析中高质量 ML-ready 数据集的短缺问题，以支持开发通用 AI 模型。数据集涵盖从 meso-β (20-200 km) 规模到对流规模的各种大气过程，包括航空湍流、飓风强度和轨迹监测、天气模拟搜索、重力波参数化以及自然语言报告生成等下游任务。作者提供了数据集的全面描述和技术验证，并将其及其准备代码公开在 Hugging Face 上（https://huggingface.co/datasets/nasa-impact/WxC-Bench），为天气和气候研究中的 ML 模型开发提供了宝贵资源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02780v1",
      "published_date": "2024-12-03 19:20:27 UTC",
      "updated_date": "2024-12-03 19:20:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:04:20.144770"
    },
    {
      "arxiv_id": "2412.02779v2",
      "title": "Synergistic Development of Perovskite Memristors and Algorithms for Robust Analog Computing",
      "title_zh": "协同开发的 Perovskite 忆阻器和算法用于鲁",
      "authors": [
        "Nanyang Ye",
        "Qiao Sun",
        "Yifei Wang",
        "Liujia Yang",
        "Jundong Zhou",
        "Lei Wang",
        "Guang-Zhong Yang",
        "Xinbing Wang",
        "Chenghu Zhou",
        "Wei Ren",
        "Leilei Gu",
        "Huaqiang Wu",
        "Qinying Gu"
      ],
      "abstract": "Analog computing using non-volatile memristors has emerged as a promising\nsolution for energy-efficient deep learning. New materials, like\nperovskites-based memristors are recently attractive due to their\ncost-effectiveness, energy efficiency and flexibility. Yet, challenges in\nmaterial diversity and immature fabrications require extensive experimentation\nfor device development. Moreover, significant non-idealities in these\nmemristors often impede them for computing. Here, we propose a synergistic\nmethodology to concurrently optimize perovskite memristor fabrication and\ndevelop robust analog DNNs that effectively address the inherent non-idealities\nof these memristors. Employing Bayesian optimization (BO) with a focus on\nusability, we efficiently identify optimal materials and fabrication conditions\nfor perovskite memristors. Meanwhile, we developed \"BayesMulti\", a DNN training\nstrategy utilizing BO-guided noise injection to improve the resistance of\nanalog DNNs to memristor imperfections. Our approach theoretically ensures that\nwithin a certain range of parameter perturbations due to memristor\nnon-idealities, the prediction outcomes remain consistent. Our integrated\napproach enables use of analog computing in much deeper and wider networks,\nwhich significantly outperforms existing methods in diverse tasks like image\nclassification, autonomous driving, species identification, and large\nvision-language models, achieving up to 100-fold improvements. We further\nvalidate our methodology on a 10$\\times$10 optimized perovskite memristor\ncrossbar, demonstrating high accuracy in a classification task and low energy\nconsumption. This study offers a versatile solution for efficient optimization\nof various analog computing systems, encompassing both devices and algorithms.",
      "tldr_zh": "本研究提出了一种协同方法，用于优化 perovskite memristors 的制造过程和开发鲁棒的 analog DNNs，以应对 memristor 非理想性带来的计算挑战。该方法利用 Bayesian optimization (BO) 高效识别最佳材料和制造条件，同时开发了 \"BayesMulti\" 训练策略，通过 BO 引导的噪声注入，提升 analog DNNs 对 memristor 缺陷的抵抗力，并在理论上确保参数扰动范围内预测结果的一致性。在图像分类、自动驾驶、物种识别和大型视觉语言模型等任务中，该方法显著优于现有技术，实现高达 100 倍的性能提升，并通过 10×10 perovskite memristor crossbar 的实验验证，展示了高准确性和低能量消耗，提供了一个通用的模拟计算系统优化解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02779v2",
      "published_date": "2024-12-03 19:20:08 UTC",
      "updated_date": "2024-12-09 15:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:04:32.904711"
    },
    {
      "arxiv_id": "2412.02776v1",
      "title": "Hacking CTFs with Plain Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Rustem Turtayev",
        "Artem Petrov",
        "Dmitrii Volkov",
        "Denis Volk"
      ],
      "abstract": "We saturate a high-school-level hacking benchmark with plain LLM agent\ndesign. Concretely, we obtain 95% performance on InterCode-CTF, a popular\noffensive security benchmark, using prompting, tool use, and multiple attempts.\nThis beats prior work by Phuong et al. 2024 (29%) and Abramovich et al. 2024\n(72%).\n  Our results suggest that current LLMs have surpassed the high school level in\noffensive cybersecurity. Their hacking capabilities remain underelicited: our\nReAct&Plan prompting strategy solves many challenges in 1-2 turns without\ncomplex engineering or advanced harnessing.",
      "tldr_zh": "该研究使用简单的LLM代理设计，在InterCode-CTF高水平黑客基准上达到了95%的性能，通过提示、工具使用和多次尝试来实现。这一成果超过了先前Phuong et al. 2024的29%和Abramovich et al. 2024的72%。研究者提出的ReAct&Plan提示策略能够在1-2回合内解决许多挑战，而无需复杂的工程或高级技术。结果表明，当前LLM在进攻性网络安全方面已超出高中水平，其潜能尚未被充分挖掘。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02776v1",
      "published_date": "2024-12-03 19:17:45 UTC",
      "updated_date": "2024-12-03 19:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:04:43.100946"
    },
    {
      "arxiv_id": "2412.02775v1",
      "title": "Optimizing Large Language Models for Turkish: New Methodologies in Corpus Selection and Training",
      "title_zh": "翻译失败",
      "authors": [
        "H. Toprak Kesgin",
        "M. Kaan Yuce",
        "Eren Dogan",
        "M. Egemen Uzun",
        "Atahan Uz",
        "Elif Ince",
        "Yusuf Erdem",
        "Osama Shbib",
        "Ahmed Zeer",
        "M. Fatih Amasyali"
      ],
      "abstract": "In this study, we develop and assess new corpus selection and training\nmethodologies to improve the effectiveness of Turkish language models.\nSpecifically, we adapted Large Language Model generated datasets and translated\nEnglish datasets into Turkish, integrating these resources into the training\nprocess. This approach led to substantial enhancements in model accuracy for\nboth few-shot and zero-shot learning scenarios. Furthermore, the merging of\nthese adapted models was found to markedly improve their performance. Human\nevaluative metrics, including task-specific performance assessments, further\ndemonstrated that these adapted models possess a greater aptitude for\ncomprehending the Turkish language and addressing logic-based queries. This\nresearch underscores the importance of refining corpus selection strategies to\noptimize the performance of multilingual models, particularly for\nunder-resourced languages like Turkish.",
      "tldr_zh": "本研究开发了新的语料库选择和训练方法，以优化土耳其语的 Large Language Models。具体而言，通过适应 Large Language Model 生成的数据集并将英语数据集翻译成土耳其语，并将其整合到训练过程中，模型在 few-shot 和 zero-shot 学习场景中的准确性大幅提升。合并这些适应后的模型进一步提高了整体性能，且人类评估指标显示其更擅长理解土耳其语并处理逻辑查询。该研究强调了针对资源不足语言如土耳其语优化语料库选择策略的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "2024 Innovations in Intelligent Systems and Applications Conference\n  (ASYU)",
      "pdf_url": "http://arxiv.org/pdf/2412.02775v1",
      "published_date": "2024-12-03 19:17:18 UTC",
      "updated_date": "2024-12-03 19:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:04:55.251002"
    },
    {
      "arxiv_id": "2412.02764v2",
      "title": "Drawing Pandas: A Benchmark for LLMs in Generating Plotting Code",
      "title_zh": "翻译失败",
      "authors": [
        "Timur Galimzyanov",
        "Sergey Titov",
        "Yaroslav Golubev",
        "Egor Bogomolov"
      ],
      "abstract": "This paper introduces the human-curated PandasPlotBench dataset, designed to\nevaluate language models' effectiveness as assistants in visual data\nexploration. Our benchmark focuses on generating code for visualizing tabular\ndata - such as a Pandas DataFrame - based on natural language instructions,\ncomplementing current evaluation tools and expanding their scope. The dataset\nincludes 175 unique tasks. Our experiments assess several leading Large\nLanguage Models (LLMs) across three visualization libraries: Matplotlib,\nSeaborn, and Plotly. We show that the shortening of tasks has a minimal effect\non plotting capabilities, allowing for the user interface that accommodates\nconcise user input without sacrificing functionality or accuracy. Another of\nour findings reveals that while LLMs perform well with popular libraries like\nMatplotlib and Seaborn, challenges persist with Plotly, highlighting areas for\nimprovement. We hope that the modular design of our benchmark will broaden the\ncurrent studies on generating visualizations. Our dataset and benchmark code\nare available online:\nhttps://huggingface.co/datasets/JetBrains-Research/PandasPlotBench;\nhttps://github.com/JetBrains-Research/PandasPlotBench.",
      "tldr_zh": "这篇论文引入了PandasPlotBench数据集，这是一个人类策划的基准，用于评估LLMs在基于自然语言指令生成表格数据可视化代码（如Pandas DataFrame）的能力。数据集包含175个独特任务，并通过实验测试了多种领先LLMs在Matplotlib、Seaborn和Plotly三个库上的表现。研究发现，LLMs在Matplotlib和Seaborn上表现出色，但在Plotly上仍面临挑战，同时任务简化对绘图功能和准确性影响最小。该基准的模块化设计旨在扩展可视化生成研究，并提供了公开数据集和代码资源。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.02764v2",
      "published_date": "2024-12-03 19:05:37 UTC",
      "updated_date": "2025-02-26 16:52:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:05:07.137784"
    },
    {
      "arxiv_id": "2412.02760v1",
      "title": "Cosmos-LLaVA: Chatting with the Visual Cosmos-LLaVA: Görselle Sohbet Etmek",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Zeer",
        "Eren Dogan",
        "Yusuf Erdem",
        "Elif Ince",
        "Osama Shbib",
        "M. Egemen Uzun",
        "Atahan Uz",
        "M. Kaan Yuce",
        "H. Toprak Kesgin",
        "M. Fatih Amasyali"
      ],
      "abstract": "In this study, a Turkish visual instruction model was developed and various\nmodel architectures and dataset combinations were analysed to improve the\nperformance of this model. The Cosmos-LLaVA model, which is built by combining\ndifferent large language models and image coders, is designed to overcome the\ndeficiencies in the Turkish language. In the experiments, the effects of\nfine-tuning with various datasets on the model performance are analysed in\ndetail. The results show that model architecture and dataset selection have a\nsignificant impact on performance.\n  Bu \\c{c}al{\\i}\\c{s}mada bir T\\\"urk\\c{c}e g\\\"orsel talimat modeli\ngeli\\c{s}tirilerek bu modelin performans{\\i}n{\\i} art{\\i}rmaya y\\\"onelik\n\\c{c}e\\c{s}itli model mimarileri ve veri k\\\"umesi kombinasyonlar{\\i}\nderinlemesine incelenmi\\c{s}tir. Farkl{\\i} b\\\"uy\\\"uk dil modelleri ve\ng\\\"or\\\"unt\\\"u kodlay{\\i}c{\\i}lar{\\i}n{\\i}n bir araya getirilmesiyle\nolu\\c{s}turulan Cosmos-LLaVA modeli, T\\\"urk\\c{c}e dilindeki eksiklikleri\ngidermeye y\\\"onelik olarak tasarlanm{\\i}\\c{s}t{\\i}r. Yap{\\i}lan deneylerde,\n\\c{c}e\\c{s}itli veri k\\\"umeleri ile yap{\\i}lan ince ayarlar{\\i}n model\nperformans{\\i}n{\\i} nas{\\i}l etkiledi\\u{g}i detayl{\\i} olarak ele\nal{\\i}nm{\\i}\\c{s}t{\\i}r. Sonu\\c{c}lar, model mimarisi ve veri k\\\"umesi\nse\\c{c}iminin performans \\\"uzerinde \\\"onemli bir etkiye sahip oldu\\u{g}unu\ng\\\"ostermektedir.",
      "tldr_zh": "本研究开发了Cosmos-LLaVA，一种针对土耳其语的视觉指令模型，旨在通过结合不同的大型语言模型（large language models）和图像编码器（image coders）来克服土耳其语中的不足。研究者分析了各种模型架构和数据集组合的影响，并通过实验详细评估了细调数据集对模型性能的作用。结果显示，模型架构和数据集选择对性能有显著影响，为土耳其语视觉任务的优化提供了重要见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "in Turkish language, 2024 8th International Artificial Intelligence\n  and Data Processing Symposium (IDAP)",
      "pdf_url": "http://arxiv.org/pdf/2412.02760v1",
      "published_date": "2024-12-03 19:01:00 UTC",
      "updated_date": "2024-12-03 19:01:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:07:19.199960"
    },
    {
      "arxiv_id": "2412.02698v1",
      "title": "Scaling BERT Models for Turkish Automatic Punctuation and Capitalization Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulkader Saoud",
        "Mahmut Alomeyr",
        "Himmet Toprak Kesgin",
        "Mehmet Fatih Amasyali"
      ],
      "abstract": "This paper investigates the effectiveness of BERT based models for automated\npunctuation and capitalization corrections in Turkish texts across five\ndistinct model sizes. The models are designated as Tiny, Mini, Small, Medium,\nand Base. The design and capabilities of each model are tailored to address the\nspecific challenges of the Turkish language, with a focus on optimizing\nperformance while minimizing computational overhead. The study presents a\nsystematic comparison of the performance metrics precision, recall, and F1\nscore of each model, offering insights into their applicability in diverse\noperational contexts. The results demonstrate a significant improvement in text\nreadability and accuracy as model size increases, with the Base model achieving\nthe highest correction precision. This research provides a comprehensive guide\nfor selecting the appropriate model size based on specific user needs and\ncomputational resources, establishing a framework for deploying these models in\nreal-world applications to enhance the quality of written Turkish.",
      "tldr_zh": "本研究探讨了不同规模的BERT模型（Tiny、Mini、Small、Medium和Base）在土耳其语文本的自动标点和大小写修正中的效果，这些模型针对土耳其语的特定挑战进行了优化，以平衡性能和计算开销。研究通过比较精确率、召回率和F1分数，系统评估了各模型的表现，结果显示模型规模越大，文本可读性和修正准确性显著提升，其中Base模型取得了最高精度。该工作为用户根据实际需求和资源选择合适模型提供了全面指南，并建立了部署这些模型的框架，以提升土耳其语文本质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "2024 Innovations in Intelligent Systems and Applications Conference\n  (ASYU)",
      "pdf_url": "http://arxiv.org/pdf/2412.02698v1",
      "published_date": "2024-12-03 18:59:51 UTC",
      "updated_date": "2024-12-03 18:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:05:31.650481"
    },
    {
      "arxiv_id": "2412.02692v2",
      "title": "Scalable Image Tokenization with Index Backpropagation Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Fengyuan Shi",
        "Zhuoyan Luo",
        "Yixiao Ge",
        "Yujiu Yang",
        "Ying Shan",
        "Limin Wang"
      ],
      "abstract": "Existing vector quantization (VQ) methods struggle with scalability, largely\nattributed to the instability of the codebook that undergoes partial updates\nduring training. The codebook is prone to collapse as utilization decreases,\ndue to the progressively widening distribution gap between non-activated codes\nand visual features. To solve the problem, we propose Index Backpropagation\nQuantization (IBQ), a new VQ method for the joint optimization of all codebook\nembeddings and the visual encoder. Applying a straight-through estimator on the\none-hot categorical distribution between the encoded feature and codebook, all\ncodes are differentiable and maintain a consistent latent space with the visual\nencoder. IBQ enables scalable training of visual tokenizers and, for the first\ntime, achieves a large-scale codebook ($2^{18}$) with high dimension ($256$)\nand high utilization. Experiments on the standard ImageNet benchmark\ndemonstrate the scalability and superiority of IBQ, achieving competitive\nresults on reconstruction and the application of autoregressive visual\ngeneration. The code and models are available at\nhttps://github.com/TencentARC/SEED-Voken.",
      "tldr_zh": "现有 VQ 方法在训练中由于代码本部分更新导致的不稳定性，难以实现可扩展性。论文提出 Index Backpropagation Quantization (IBQ)，一种新方法，通过在编码特征和代码本之间应用 straight-through estimator，使所有代码本可微并与视觉编码器联合优化，从而保持一致的潜在空间。IBQ 首次实现了大规模代码本 ($2^{18}$) 和高维度 (256) 的训练，并显著提高了代码利用率；在 ImageNet 基准实验中，IBQ 在图像重建和自回归视觉生成任务上取得了竞争性结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02692v2",
      "published_date": "2024-12-03 18:59:10 UTC",
      "updated_date": "2025-03-10 09:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:05:43.652726"
    },
    {
      "arxiv_id": "2412.02685v1",
      "title": "T-REG: Preference Optimization with Token-Level Reward Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Zhou",
        "Shujian Zhang",
        "Lingxiao Zhao",
        "Tao Meng"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has been crucial in\naligning large language models (LLMs) with human values. Traditionally, RLHF\ninvolves generating responses to a query and using a reward model to assign a\nreward to the entire response. However, this approach faces challenges due to\nits reliance on a single, sparse reward, which makes it challenging for the\nmodel to identify which parts of the sequence contribute most significantly to\nthe final reward. Recent methods have attempted to address this limitation by\nintroducing token-level rewards. However, these methods often rely on either a\ntrained credit assignment model or AI annotators, raising concerns about the\nquality and reliability of the rewards. In this paper, we propose token-level\nreward regularization (T-REG), a novel approach that leverages both\nsequence-level and token-level rewards for preference optimization. Harnessing\nthe self-refinement capabilities of LLMs, our method uses contrastive prompting\nto enable LLMs to self-generate token-level rewards. These self-generated\nrewards then act as reward regularization, guiding the model to more\neffectively distribute sequence-level rewards across tokens. This facilitates\nbetter token-level credit assignment and enhances alignment performance.\nExperiments on the instruction following benchmarks, including Alpaca Eval 2\nand Arena-Hard, show that our method consistently outperforms baseline methods\nby up to 3.8% and 4.4%, respectively. We will release the code and models at\nhttps://github.com/wzhouad/T-REG.",
      "tldr_zh": "本论文提出 T-REG，一种新型偏好优化方法，通过引入 token-level 奖励正则化来解决传统 RLHF（Reinforcement Learning from Human Feedback）在对齐大型语言模型（LLMs）时依赖单一序列级奖励的问题，导致难以精确分配信用。T-REG 利用 LLMs 的自精炼能力，通过对比提示生成 token-level 奖励，并将其作为正则化机制，指导模型更好地分布序列级奖励，从而提升 token-level 信用分配和整体对齐性能。在 Alpaca Eval 2 和 Arena-Hard 基准测试中，T-REG 分别比基线方法提高了 3.8% 和 4.4%，展示了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02685v1",
      "published_date": "2024-12-03 18:56:07 UTC",
      "updated_date": "2024-12-03 18:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:07:15.074700"
    },
    {
      "arxiv_id": "2412.02684v1",
      "title": "AniGS: Animatable Gaussian Avatar from a Single Image with Inconsistent Gaussian Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Lingteng Qiu",
        "Shenhao Zhu",
        "Qi Zuo",
        "Xiaodong Gu",
        "Yuan Dong",
        "Junfei Zhang",
        "Chao Xu",
        "Zhe Li",
        "Weihao Yuan",
        "Liefeng Bo",
        "Guanying Chen",
        "Zilong Dong"
      ],
      "abstract": "Generating animatable human avatars from a single image is essential for\nvarious digital human modeling applications. Existing 3D reconstruction methods\noften struggle to capture fine details in animatable models, while generative\napproaches for controllable animation, though avoiding explicit 3D modeling,\nsuffer from viewpoint inconsistencies in extreme poses and computational\ninefficiencies. In this paper, we address these challenges by leveraging the\npower of generative models to produce detailed multi-view canonical pose\nimages, which help resolve ambiguities in animatable human reconstruction. We\nthen propose a robust method for 3D reconstruction of inconsistent images,\nenabling real-time rendering during inference. Specifically, we adapt a\ntransformer-based video generation model to generate multi-view canonical pose\nimages and normal maps, pretraining on a large-scale video dataset to improve\ngeneralization. To handle view inconsistencies, we recast the reconstruction\nproblem as a 4D task and introduce an efficient 3D modeling approach using 4D\nGaussian Splatting. Experiments demonstrate that our method achieves\nphotorealistic, real-time animation of 3D human avatars from in-the-wild\nimages, showcasing its effectiveness and generalization capability.",
      "tldr_zh": "该研究提出AniGS方法，从单张图像生成可动画化的Gaussian Avatar，以解决现有3D重建方法在捕捉细节方面的不足，以及生成方法在视角不一致和计算效率上的挑战。方法首先利用基于Transformer的视频生成模型，在大规模视频数据集上预训练，生成详细的多视图标准姿势图像和normal maps，以消除重建模糊性。随后，将重建问题转化为4D任务，并采用4D Gaussian Splatting进行高效3D建模，实现实时渲染。实验结果显示，该方法能从野外图像创建逼真、实时的人体动画，并展示出优秀的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://lingtengqiu.github.io/2024/AniGS/",
      "pdf_url": "http://arxiv.org/pdf/2412.02684v1",
      "published_date": "2024-12-03 18:55:39 UTC",
      "updated_date": "2024-12-03 18:55:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:08:00.827733"
    },
    {
      "arxiv_id": "2412.02682v1",
      "title": "The Asymptotic Behavior of Attention in Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Álvaro Rodríguez Abella",
        "João Pedro Silvestre",
        "Paulo Tabuada"
      ],
      "abstract": "A key component of transformers is the attention mechanism orchestrating how\neach token influences the propagation of every other token through a\ntransformer. In this paper we provide a rigorous, mathematical analysis of the\nasymptotic properties of attention in transformers. Although we present several\nresults based on different assumptions, all of them point to the same\nconclusion, all tokens asymptotically converge to each other, a phenomenon that\nhas been empirically reported in the literature. Our findings are carefully\ncompared with existing theoretical results and illustrated by simulations and\nexperimental studies using the GPT-2 model.",
      "tldr_zh": "本研究分析了Transformer模型中注意力机制(asymptotic behavior)的渐近行为，探讨了每个token如何影响其他token的传播。论文通过严格的数学分析，在不同假设下证明了所有token会渐近收敛到一起，这一现象与现有文献的经验观察一致。该发现通过模拟和使用GPT-2模型的实验验证，进一步与现有理论结果进行了比较，为理解Transformer的动态行为提供了新的见解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.DS",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02682v1",
      "published_date": "2024-12-03 18:54:49 UTC",
      "updated_date": "2024-12-03 18:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:07:13.845989"
    },
    {
      "arxiv_id": "2412.02659v2",
      "title": "Adaptive Informed Deep Neural Networks for Power Flow Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Zeynab Kaseb",
        "Stavros Orfanoudakis",
        "Pedro P. Vergara",
        "Peter Palensky"
      ],
      "abstract": "This study introduces PINN4PF, an end-to-end deep learning architecture for\npower flow (PF) analysis that effectively captures the nonlinear dynamics of\nlarge-scale modern power systems. The proposed neural network (NN) architecture\nconsists of two important advancements in the training pipeline: (A) a\ndouble-head feed-forward NN that aligns with PF analysis, including an\nactivation function that adjusts to the net active and reactive power\ninjections patterns, and (B) a physics-based loss function that partially\nincorporates power system topology information. The effectiveness of the\nproposed architecture is illustrated through 4-bus, 15-bus, 290-bus, and\n2224-bus test systems and is evaluated against two baselines: a linear\nregression model (LR) and a black-box NN (MLP). The comparison is based on (i)\ngeneralization ability, (ii) robustness, (iii) impact of training dataset size\non generalization ability, (iv) accuracy in approximating derived PF quantities\n(specifically line current, line active power, and line reactive power), and\n(v) scalability. Results demonstrate that PINN4PF outperforms both baselines\nacross all test systems by up to two orders of magnitude not only in terms of\ndirect criteria, e.g., generalization ability, but also in terms of\napproximating derived physical quantities.",
      "tldr_zh": "这篇论文提出了一种名为 PINN4PF 的端到端深度学习架构，用于电力流 (PF) 分析，能够有效捕捉大规模现代电力系统的非线性动态。PINN4PF 的关键创新包括一个双头前馈神经网络 (NN)，其激活函数根据净有功和无功功率注入模式进行调整，以及一个基于物理的损失函数来部分整合电力系统拓扑信息。实验结果显示，在 4-bus、15-bus、290-bus 和 2224-bus 测试系统中，PINN4PF 相较于线性回归 (LR) 和黑箱 NN (MLP) 基线模型，在泛化能力、鲁棒性、准确性和可扩展性等方面提高了两个数量级，尤其在近似派生物理量如线路电流和功率时表现出色。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "eess.SP"
      ],
      "primary_category": "eess.SY",
      "comment": "10 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.02659v2",
      "published_date": "2024-12-03 18:33:48 UTC",
      "updated_date": "2025-05-03 19:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:06:32.567730"
    },
    {
      "arxiv_id": "2412.02653v1",
      "title": "Scaffold or Crutch? Examining College Students' Use and Views of Generative AI Tools for STEM Education",
      "title_zh": "翻译失败",
      "authors": [
        "Karen D. Wang",
        "Zhangyang Wu",
        "L'Nard Tufts II",
        "Carl Wieman",
        "Shima Salehi",
        "Nick Haber"
      ],
      "abstract": "Developing problem-solving competency is central to Science, Technology,\nEngineering, and Mathematics (STEM) education, yet translating this priority\ninto effective approaches to problem-solving instruction and assessment remain\na significant challenge. The recent proliferation of generative artificial\nintelligence (genAI) tools like ChatGPT in higher education introduces new\nconsiderations about how these tools can help or hinder students' development\nof STEM problem-solving competency. Our research examines these considerations\nby studying how and why college students use genAI tools in their STEM\ncoursework, focusing on their problem-solving support. We surveyed 40 STEM\ncollege students from diverse U.S. institutions and 28 STEM faculty to\nunderstand instructor perspectives on effective genAI tool use and guidance in\nSTEM courses. Our findings reveal high adoption rates and diverse applications\nof genAI tools among STEM students. The most common use cases include finding\nexplanations, exploring related topics, summarizing readings, and helping with\nproblem-set questions. The primary motivation for using genAI tools was to save\ntime. Moreover, over half of student participants reported simply inputting\nproblems for AI to generate solutions, potentially bypassing their own\nproblem-solving processes. These findings indicate that despite high adoption\nrates, students' current approaches to utilizing genAI tools often fall short\nin enhancing their own STEM problem-solving competencies. The study also\nexplored students' and STEM instructors' perceptions of the benefits and risks\nassociated with using genAI tools in STEM education. Our findings provide\ninsights into how to guide students on appropriate genAI use in STEM courses\nand how to design genAI-based tools to foster students' problem-solving\ncompetency.",
      "tldr_zh": "本研究考察了生成式 AI (genAI) 工具（如 ChatGPT）在 STEM 教育中对大学生问题解决能力的作用，通过调查 40 名 STEM 学生和 28 名 STEM 教师，分析了工具的使用模式和观点。发现学生高度采用 genAI 工具，主要用于解释概念、探索相关主题、总结阅读和解答问题集，动机主要是节省时间，但超过半数学生直接输入问题让 AI 生成答案，可能忽略自身问题解决过程，从而阻碍能力发展。该研究揭示了 genAI 的潜在益处和风险，并提供指导，帮助教师设计课程和工具，以促进学生适当使用 genAI 并提升 STEM 问题解决能力。",
      "categories": [
        "physics.ed-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ed-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02653v1",
      "published_date": "2024-12-03 18:27:40 UTC",
      "updated_date": "2024-12-03 18:27:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:06:43.548250"
    },
    {
      "arxiv_id": "2412.02638v1",
      "title": "QA-TOOLBOX: Conversational Question-Answering for process task guidance in manufacturing",
      "title_zh": "翻译失败",
      "authors": [
        "Ramesh Manuvinakurike",
        "Elizabeth Watkins",
        "Celal Savur",
        "Anthony Rhodes",
        "Sovan Biswas",
        "Gesem Gudino Mejia",
        "Richard Beckwith",
        "Saurav Sahay",
        "Giuseppe Raffa",
        "Lama Nachman"
      ],
      "abstract": "In this work we explore utilizing LLMs for data augmentation for\nmanufacturing task guidance system. The dataset consists of representative\nsamples of interactions with technicians working in an advanced manufacturing\nsetting. The purpose of this work to explore the task, data augmentation for\nthe supported tasks and evaluating the performance of the existing LLMs. We\nobserve that that task is complex requiring understanding from procedure\nspecification documents, actions and objects sequenced temporally. The dataset\nconsists of 200,000+ question/answer pairs that refer to the spec document and\nare grounded in narrations and/or video demonstrations. We compared the\nperformance of several popular open-sourced LLMs by developing a baseline using\neach LLM and then compared the responses in a reference-free setting using\nLLM-as-a-judge and compared the ratings with crowd-workers whilst validating\nthe ratings with experts.",
      "tldr_zh": "本文提出 QA-TOOLBOX，一种基于对话式问答的系统，用于指导制造业过程任务。研究利用 LLMs 进行数据增强，构建了一个包含超过20万对问题/答案对的数据集，该数据集基于程序规范文档、时序动作和视频演示，以处理任务的复杂性。作者评估了多种开源 LLMs 的性能，通过开发基线、采用 LLM-as-a-judge 的无参考比较，并结合众包工作者和专家验证，展示了 LLMs 在制造业任务指导中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02638v1",
      "published_date": "2024-12-03 18:10:31 UTC",
      "updated_date": "2024-12-03 18:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:06:55.691546"
    },
    {
      "arxiv_id": "2412.02632v2",
      "title": "Scaling Image Tokenizers with Grouped Spherical Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangtao Wang",
        "Zhen Qin",
        "Yifan Zhang",
        "Vincent Tao Hu",
        "Björn Ommer",
        "Rania Briq",
        "Stefan Kesselheim"
      ],
      "abstract": "Vision tokenizers have gained a lot of attraction due to their scalability\nand compactness; previous works depend on old-school GAN-based hyperparameters,\nbiased comparisons, and a lack of comprehensive analysis of the scaling\nbehaviours. To tackle those issues, we introduce Grouped Spherical Quantization\n(GSQ), featuring spherical codebook initialization and lookup regularization to\nconstrain codebook latent to a spherical surface. Our empirical analysis of\nimage tokenizer training strategies demonstrates that GSQ-GAN achieves superior\nreconstruction quality over state-of-the-art methods with fewer training\niterations, providing a solid foundation for scaling studies. Building on this,\nwe systematically examine the scaling behaviours of GSQ, specifically in latent\ndimensionality, codebook size, and compression ratios, and their impact on\nmodel performance. Our findings reveal distinct behaviours at high and low\nspatial compression levels, underscoring challenges in representing\nhigh-dimensional latent spaces. We show that GSQ can restructure\nhigh-dimensional latent into compact, low-dimensional spaces, thus enabling\nefficient scaling with improved quality. As a result, GSQ-GAN achieves a 16x\ndown-sampling with a reconstruction FID (rFID) of 0.50.",
      "tldr_zh": "该研究提出Grouped Spherical Quantization (GSQ)，一种新的图像分词器方法，通过球形代码书初始化和查找正则化，将代码书潜在空间约束到球面，以提升重建质量和训练效率。相比现有方法，GSQ-GAN 在更少的训练迭代中实现了优越的图像重建性能，并系统分析了潜在维度、代码书大小和压缩比的缩放行为，发现高空间压缩水平下存在独特挑战，同时能将高维潜在空间重组为紧凑低维空间。最终，GSQ-GAN 在16x下采样下达到了0.50的重建FID (rFID)，为高效扩展图像分词器提供了坚实基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02632v2",
      "published_date": "2024-12-03 18:01:45 UTC",
      "updated_date": "2024-12-04 05:02:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:07:07.453308"
    },
    {
      "arxiv_id": "2412.02626v3",
      "title": "Time-Reversal Provides Unsupervised Feedback to LLMs",
      "title_zh": "时间反转为 LLMs 提供无监督反馈",
      "authors": [
        "Yerram Varun",
        "Rahul Madhavan",
        "Sravanti Addepalli",
        "Arun Suggala",
        "Karthikeyan Shanmugam",
        "Prateek Jain"
      ],
      "abstract": "Large Language Models (LLMs) are typically trained to predict in the forward\ndirection of time. However, recent works have shown that prompting these models\nto look back and critique their own generations can produce useful feedback.\nMotivated by this, we explore the question of whether LLMs can be empowered to\nthink (predict and score) backwards to provide unsupervised feedback that\ncomplements forward LLMs. Towards this, we introduce Time Reversed Language\nModels (TRLMs), which can score and generate queries when conditioned on\nresponses, effectively functioning in the reverse direction of time. Further,\nto effectively infer in the response to query direction, we pre-train and\nfine-tune a language model (TRLM-Ba) in the reverse token order from scratch.\nWe show empirically (and theoretically in a stylized setting) that\ntime-reversed models can indeed complement forward model predictions when used\nto score the query given response for re-ranking multiple forward generations.\nWe obtain up to 5\\% improvement on the widely used AlpacaEval Leaderboard over\nthe competent baseline of best-of-N re-ranking using self log-perplexity\nscores. We further show that TRLM scoring outperforms conventional forward\nscoring of response given query, resulting in significant gains in applications\nsuch as citation generation and passage retrieval. We next leverage the\ngenerative ability of TRLM to augment or provide unsupervised feedback to input\nsafety filters of LLMs, demonstrating a drastic reduction in false negative\nrate with negligible impact on false positive rates against several attacks\npublished on the popular JailbreakBench leaderboard.",
      "tldr_zh": "本文提出 Time Reversed Language Models (TRLMs)，一种逆向思考的语言模型，能在给定响应的情况下评分和生成查询，从而为大型语言模型(LLMs)提供无监督反馈，补充传统向前预测的不足。研究通过从零开始预训练和微调逆序模型(TRLM-Ba)，并在理论和实验中证明其有效性，在AlpacaEval Leaderboard上比最佳N重排基准提升5%，并在引文生成和段落检索等应用中实现显著性能改进。此外，TRLMs用于增强LLMs的输入安全过滤器，显著减少假阴性率，同时对假阳性率影响微乎其微。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a spotlight in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.02626v3",
      "published_date": "2024-12-03 17:54:12 UTC",
      "updated_date": "2025-02-02 22:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:08:12.908105"
    },
    {
      "arxiv_id": "2412.02621v1",
      "title": "Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions",
      "title_zh": "医学多模态基础模型在临床诊断和治疗中的应用、挑战和未来方向",
      "authors": [
        "Kai Sun",
        "Siyan Xue",
        "Fuchun Sun",
        "Haoran Sun",
        "Yu Luo",
        "Ling Wang",
        "Siyuan Wang",
        "Na Guo",
        "Lei Liu",
        "Tian Zhao",
        "Xinzhou Wang",
        "Lei Yang",
        "Shuo Jin",
        "Jun Yan",
        "Jiahong Dong"
      ],
      "abstract": "Recent advancements in deep learning have significantly revolutionized the\nfield of clinical diagnosis and treatment, offering novel approaches to improve\ndiagnostic precision and treatment efficacy across diverse clinical domains,\nthus driving the pursuit of precision medicine. The growing availability of\nmulti-organ and multimodal datasets has accelerated the development of\nlarge-scale Medical Multimodal Foundation Models (MMFMs). These models, known\nfor their strong generalization capabilities and rich representational power,\nare increasingly being adapted to address a wide range of clinical tasks, from\nearly diagnosis to personalized treatment strategies. This review offers a\ncomprehensive analysis of recent developments in MMFMs, focusing on three key\naspects: datasets, model architectures, and clinical applications. We also\nexplore the challenges and opportunities in optimizing multimodal\nrepresentations and discuss how these advancements are shaping the future of\nhealthcare by enabling improved patient outcomes and more efficient clinical\nworkflows.",
      "tldr_zh": "这篇综述论文探讨了深度学习在临床诊断和治疗中的应用，强调大型Medical Multimodal Foundation Models (MMFMs)如何利用多器官和多模态数据集提升诊断精度和个性化治疗策略。论文分析了MMFMs的关键要素，包括数据集、模型架构以及在早期诊断和治疗中的实际应用，同时指出了优化多模态表示的挑战与机遇。最终，该研究展望了MMFMs如何推动精确医学的发展，提高患者预后和临床工作流的效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02621v1",
      "published_date": "2024-12-03 17:50:19 UTC",
      "updated_date": "2024-12-03 17:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:08:24.193310"
    },
    {
      "arxiv_id": "2412.02617v1",
      "title": "Improving Dynamic Object Interactions in Text-to-Video Generation with AI Feedback",
      "title_zh": "通过 AI 反馈改进文本到视频生成中的动态物体交互",
      "authors": [
        "Hiroki Furuta",
        "Heiga Zen",
        "Dale Schuurmans",
        "Aleksandra Faust",
        "Yutaka Matsuo",
        "Percy Liang",
        "Sherry Yang"
      ],
      "abstract": "Large text-to-video models hold immense potential for a wide range of\ndownstream applications. However, these models struggle to accurately depict\ndynamic object interactions, often resulting in unrealistic movements and\nfrequent violations of real-world physics. One solution inspired by large\nlanguage models is to align generated outputs with desired outcomes using\nexternal feedback. This enables the model to refine its responses autonomously,\neliminating extensive manual data collection. In this work, we investigate the\nuse of feedback to enhance the object dynamics in text-to-video models. We aim\nto answer a critical question: what types of feedback, paired with which\nspecific self-improvement algorithms, can most effectively improve text-video\nalignment and realistic object interactions? We begin by deriving a unified\nprobabilistic objective for offline RL finetuning of text-to-video models. This\nperspective highlights how design elements in existing algorithms like KL\nregularization and policy projection emerge as specific choices within a\nunified framework. We then use derived methods to optimize a set of text-video\nalignment metrics (e.g., CLIP scores, optical flow), but notice that they often\nfail to align with human perceptions of generation quality. To address this\nlimitation, we propose leveraging vision-language models to provide more\nnuanced feedback specifically tailored to object dynamics in videos. Our\nexperiments demonstrate that our method can effectively optimize a wide variety\nof rewards, with binary AI feedback driving the most significant improvements\nin video quality for dynamic interactions, as confirmed by both AI and human\nevaluations. Notably, we observe substantial gains when using reward signals\nderived from AI feedback, particularly in scenarios involving complex\ninteractions between multiple objects and realistic depictions of objects\nfalling.",
      "tldr_zh": "本研究针对文本到视频生成模型在描绘动态物体交互时的不足（如不现实运动和物理违规），提出使用 AI 反馈机制进行自主改进，以提升视频的真实性和文本-视频对齐。论文推导了一个统一的概率目标框架，用于离线 RL finetuning，并探索不同反馈类型（如基于视觉语言模型的细致反馈）和算法优化。实验结果显示，二元 AI 反馈在优化 CLIP scores 和 optical flow 等指标方面最为有效，尤其在多物体复杂交互和物体下落场景中显著提高了视频质量，并经 AI 和人类评估确认。整体方法为文本到视频模型的自主优化提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Website: https://sites.google.com/view/aif-dynamic-t2v/",
      "pdf_url": "http://arxiv.org/pdf/2412.02617v1",
      "published_date": "2024-12-03 17:44:23 UTC",
      "updated_date": "2024-12-03 17:44:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:08:35.217570"
    },
    {
      "arxiv_id": "2412.02615v1",
      "title": "Projection Abstractions in Planning Under the Lenses of Abstractions for MDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Giuseppe Canonaco",
        "Alberto Pozanco",
        "Daniel Borrajo"
      ],
      "abstract": "The concept of abstraction has been independently developed both in the\ncontext of AI Planning and discounted Markov Decision Processes (MDPs).\nHowever, the way abstractions are built and used in the context of Planning and\nMDPs is different even though lots of commonalities can be highlighted. To this\nday there is no work trying to relate and unify the two fields on the matter of\nabstractions unraveling all the different assumptions and their effect on the\nway they can be used. Therefore, in this paper we aim to do so by looking at\nprojection abstractions in Planning through the lenses of discounted MDPs.\nStarting from a projection abstraction built according to Classical or\nProbabilistic Planning techniques, we will show how the same abstraction can be\nobtained under the abstraction frameworks available for discounted MDPs. Along\nthe way, we will focus on computational as well as representational advantages\nand disadvantages of both worlds pointing out new research directions that are\nof interest for both fields.",
      "tldr_zh": "本文探讨了AI Planning和discounted MDPs中抽象概念的差异，并首次尝试统一两者，分析其构建和应用方式的共同点与假设影响。研究通过将Classical或Probabilistic Planning中的projection abstractions置于MDPs抽象框架下，展示了如何获得相同的抽象结构，同时比较了计算和表示上的优势与劣势。最终，论文指出了潜在的研究方向，为AI Planning和MDPs领域提供了新的交叉视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02615v1",
      "published_date": "2024-12-03 17:43:28 UTC",
      "updated_date": "2024-12-03 17:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:08:46.814977"
    },
    {
      "arxiv_id": "2412.02611v1",
      "title": "AV-Odyssey Bench: Can Your Multimodal LLMs Really Understand Audio-Visual Information?",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixiong Gong",
        "Kaituo Feng",
        "Bohao Li",
        "Yibing Wang",
        "Mofan Cheng",
        "Shijia Yang",
        "Jiaming Han",
        "Benyou Wang",
        "Yutong Bai",
        "Zhuoran Yang",
        "Xiangyu Yue"
      ],
      "abstract": "Recently, multimodal large language models (MLLMs), such as GPT-4o, Gemini\n1.5 Pro, and Reka Core, have expanded their capabilities to include vision and\naudio modalities. While these models demonstrate impressive performance across\na wide range of audio-visual applications, our proposed DeafTest reveals that\nMLLMs often struggle with simple tasks humans find trivial: 1) determining\nwhich of two sounds is louder, and 2) determining which of two sounds has a\nhigher pitch. Motivated by these observations, we introduce AV-Odyssey Bench, a\ncomprehensive audio-visual benchmark designed to assess whether those MLLMs can\ntruly understand the audio-visual information. This benchmark encompasses 4,555\ncarefully crafted problems, each incorporating text, visual, and audio\ncomponents. To successfully infer answers, models must effectively leverage\nclues from both visual and audio inputs. To ensure precise and objective\nevaluation of MLLM responses, we have structured the questions as\nmultiple-choice, eliminating the need for human evaluation or LLM-assisted\nassessment. We benchmark a series of closed-source and open-source models and\nsummarize the observations. By revealing the limitations of current models, we\naim to provide useful insight for future dataset collection and model\ndevelopment.",
      "tldr_zh": "该研究揭示了多模态大语言模型（Multimodal LLMs）如 GPT-4o 和 Gemini 1.5 Pro 在处理音频-视觉信息时存在的局限性，例如难以判断声音的响度和音调。作者提出了 AV-Odyssey Bench，这是一个全面的音频-视觉基准测试，包含 4,555 个多选题问题，每个问题整合文本、视觉和音频组件，要求模型有效利用多模态线索来回答。实验评估了一系列闭源和开源模型，总结了它们的表现，突显了模型在真实理解音频-视觉信息方面的不足。该基准旨在为未来的数据集收集和模型开发提供宝贵洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://av-odyssey.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.02611v1",
      "published_date": "2024-12-03 17:41:23 UTC",
      "updated_date": "2024-12-03 17:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:08:59.965764"
    },
    {
      "arxiv_id": "2412.02610v1",
      "title": "AI-Driven Resource Allocation Framework for Microservices in Hybrid Cloud Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Biman Barua",
        "M. Shamim Kaiser"
      ],
      "abstract": "The increasing demand for scalable, efficient resource management in hybrid\ncloud environments has led to the exploration of AI-driven approaches for\ndynamic resource allocation. This paper presents an AI-driven framework for\nresource allocation among microservices in hybrid cloud platforms. The\nframework employs reinforcement learning (RL)-based resource utilization\noptimization to reduce costs and improve performance. The framework integrates\nAI models with cloud management tools to respond to challenges of dynamic\nscaling and cost-efficient low-latency service delivery. The reinforcement\nlearning model continuously adjusts provisioned resources as required by the\nmicroservices and predicts the future consumption trends to minimize both\nunder- and over-provisioning of resources. Preliminary simulation results\nindicate that using AI in the provision of resources related to costs can\nreduce expenditure by up to 30-40% compared to manual provisioning and\nthreshold-based auto-scaling approaches. It is also estimated that the\nefficiency in resource utilization is expected to improve by 20%-30% with a\ncorresponding latency cut of 15%-20% during the peak demand periods. This study\ncompares the AI-driven approach with existing static and rule-based resource\nallocation methods, demonstrating the capability of this new model to\noutperform them in terms of flexibility and real-time interests. The results\nindicate that reinforcement learning can make optimization of hybrid cloud\nplatforms even better, offering a 25-35% improvement in cost efficiency and the\npower of scaling for microservice-based applications. The proposed framework is\na strong and scalable solution to managing cloud resources in dynamic and\nperformance-critical environments.",
      "tldr_zh": "这篇论文提出了一种AI驱动的资源分配框架，用于混合云平台中微服务的动态管理，旨在通过强化学习（RL）优化资源利用以降低成本并提升性能。该框架整合AI模型与云管理工具，实时调整资源分配并预测未来消耗趋势，从而减少资源不足或过度分配的风险。与传统静态和基于规则的方法相比，模拟结果显示该框架可将成本降低30-40%，资源利用效率提高20-30%，并在高峰期将延迟减少15-20%，为动态、高性能环境提供了一个可扩展的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.PF",
        "cs.SE",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02610v1",
      "published_date": "2024-12-03 17:41:08 UTC",
      "updated_date": "2024-12-03 17:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:09:12.281705"
    },
    {
      "arxiv_id": "2412.02602v1",
      "title": "CEGI: Measuring the trade-off between efficiency and carbon emissions for SLMs and VLMs",
      "title_zh": "CEGI: 测量 SLMs 和 VLMs 在效率与",
      "authors": [
        "Abhas Kumar",
        "Kapil Pathak",
        "Rajesh Kavuru",
        "Prabhakar Srinivasan"
      ],
      "abstract": "This paper analyzes the performance of Small Language Models (SLMs) and\nVision Language Models (VLMs) and evaluates the trade-off between model\nperformance and carbon emissions across 4 essential tasks: Image Captioning,\nVisual Question Answering (VQA), Dialogue Summarization and Text-to-SQL\nconversion. Various SLMs and VLMs belonging to the Qwen and LLaMA architecture\nfamily are chosen and variants based on model size in terms of the number of\nparameters, quantization level and fine-tuning parameters are evaluated. The\nmodel variant's performance and carbon emissions are calculated. To quantify\nthe trade-off between model performance and carbon emissions, we introduce a\nnovel metric called CEGI (Carbon Efficient Gain Index). This metric represents\nthe carbon emission per unit percentage gain per million trainable parameters .\nThis metric provides a normalized measure to compare model's efficiency in\nterms of performance improvement relative to their environmental cost. The\nexperiment's outcome demonstrates that fine-tuning SLMs and VLMs can achieve\nperformance levels comparable to Large Language Models (LLMs) while producing\nsignificantly less carbon emissions. Our findings suggest that the marginal\ngains in accuracy from larger models do not justify the substantial increase in\ncarbon emissions. Leveraging lower-bit quantization levels, the proposed metric\nfurther enhances energy efficiency without compromising performance. This study\nhighlights balancing high performance and environmental sustainability. It\noffers a valuable metric for selecting models suitable for\nenvironmentally-friendly AI development.",
      "tldr_zh": "本研究评估了Small Language Models (SLMs) 和 Vision Language Models (VLMs) 在 Image Captioning、Visual Question Answering (VQA)、Dialogue Summarization 和 Text-to-SQL conversion 等四个关键任务上的性能，并量化了模型性能与碳排放之间的权衡。研究者引入了新型指标CEGI (Carbon Efficient Gain Index)，用于衡量每百万可训练参数的性能提升百分比与碳排放的比率，从而提供一种标准化方法比较模型的效率和环境成本。实验结果显示，通过微调，SLMs 和 VLMs 可达到与Large Language Models (LLMs) 相当的性能，同时显著降低碳排放；此外，采用较低位量化水平进一步提升了能源效率，而更大模型的准确率提升往往不值得其碳排放的增加。该研究强调了在AI开发中平衡高性能与环境可持续性的重要性，并为选择环保模型提供了宝贵指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02602v1",
      "published_date": "2024-12-03 17:32:47 UTC",
      "updated_date": "2024-12-03 17:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:09:24.919063"
    },
    {
      "arxiv_id": "2412.02594v1",
      "title": "PrefixLLM: LLM-aided Prefix Circuit Design",
      "title_zh": "PrefixLLM：LLM 辅助的前缀电路设计",
      "authors": [
        "Weihua Xiao",
        "Venkata Sai Charan Putrevu",
        "Raghu Vamshi Hemadri",
        "Siddharth Garg",
        "Ramesh Karri"
      ],
      "abstract": "Prefix circuits are fundamental components in digital adders, widely used in\ndigital systems due to their efficiency in calculating carry signals.\nSynthesizing prefix circuits with minimized area and delay is crucial for\nenhancing the performance of modern computing systems. Recently, large language\nmodels (LLMs) have demonstrated a surprising ability to perform text generation\ntasks. We propose PrefixLLM, that leverages LLMs for prefix circuit synthesis.\nPrefixLLM transforms the prefix circuit synthesis task into a structured text\ngeneration problem, termed the Structured Prefix Circuit Representation (SPCR),\nand introduces an iterative framework to automatically and accurately generate\nvalid SPCRs. We further present a design space exploration (DSE) framework that\nuses LLMs to iteratively search for area and delay optimized prefix circuits.\nCompared to state-of-the-art, PrefixLLM can reduce the area by 3.70% under the\nsame delay constraint. This work highlights the use of LLMs in the synthesis of\narithmetic circuits, which can be transformed into the structured text\ngeneration.",
      "tldr_zh": "本研究提出 PrefixLLM，一种利用大型语言模型 (LLMs) 辅助前缀电路设计的框架，前缀电路是数字加法器中计算携带信号的关键组件。PrefixLLM 将电路合成转化为结构化文本生成问题，引入 Structured Prefix Circuit Representation (SPCR) 和一个迭代框架，以自动生成有效的电路表示，并结合设计空间探索 (DSE) 框架来优化电路的面积和延迟。与最先进方法相比，该框架在相同延迟约束下可将面积减少 3.70%。这项工作展示了 LLMs 在算术电路合成等结构化任务中的潜力。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02594v1",
      "published_date": "2024-12-03 17:26:42 UTC",
      "updated_date": "2024-12-03 17:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:09:35.779757"
    },
    {
      "arxiv_id": "2412.02588v1",
      "title": "Explainable CTR Prediction via LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohan Yu",
        "Li Zhang",
        "Chong Chen"
      ],
      "abstract": "Recommendation Systems have become integral to modern user experiences, but\nlack transparency in their decision-making processes. Existing explainable\nrecommendation methods are hindered by reliance on a post-hoc paradigm, wherein\nexplanation generators are trained independently of the underlying recommender\nmodels. This paradigm necessitates substantial human effort in data\nconstruction and raises concerns about explanation reliability. In this paper,\nwe present ExpCTR, a novel framework that integrates large language model based\nexplanation generation directly into the CTR prediction process. Inspired by\nrecent advances in reinforcement learning, we employ two carefully designed\nreward mechanisms, LC alignment, which ensures explanations reflect user\nintentions, and IC alignment, which maintains consistency with traditional\nID-based CTR models. Our approach incorporates an efficient training paradigm\nwith LoRA and a three-stage iterative process. ExpCTR circumvents the need for\nextensive explanation datasets while fostering synergy between CTR prediction\nand explanation generation. Experimental results demonstrate that ExpCTR\nsignificantly enhances both recommendation accuracy and interpretability across\nthree real-world datasets.",
      "tldr_zh": "这篇论文提出ExpCTR框架，通过LLM推理将解释生成直接整合到CTR预测过程中，解决了传统后验范式依赖大量人工数据和可靠性问题的局限性。该框架引入LC alignment（确保解释反映用户意图）和IC alignment（保持与传统ID-based CTR模型一致性）的奖励机制，并采用LoRA高效训练及三阶段迭代过程，促进CTR预测与解释生成的协同效应。实验结果显示，在三个真实数据集上，ExpCTR显著提升了推荐准确性和可解释性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "WSDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02588v1",
      "published_date": "2024-12-03 17:17:27 UTC",
      "updated_date": "2024-12-03 17:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:09:47.751083"
    },
    {
      "arxiv_id": "2412.02579v2",
      "title": "Factored space models: Towards causality between levels of abstraction",
      "title_zh": "翻译失败",
      "authors": [
        "Scott Garrabrant",
        "Matthias Georg Mayer",
        "Magdalena Wache",
        "Leon Lang",
        "Sam Eisenstat",
        "Holger Dell"
      ],
      "abstract": "Causality plays an important role in understanding intelligent behavior, and\nthere is a wealth of literature on mathematical models for causality, most of\nwhich is focused on causal graphs. Causal graphs are a powerful tool for a wide\nrange of applications, in particular when the relevant variables are known and\nat the same level of abstraction. However, the given variables can also be\nunstructured data, like pixels of an image. Meanwhile, the causal variables,\nsuch as the positions of objects in the image, can be arbitrary deterministic\nfunctions of the given variables. Moreover, the causal variables may form a\nhierarchy of abstractions, in which the macro-level variables are deterministic\nfunctions of the micro-level variables. Causal graphs are limited when it comes\nto modeling this kind of situation. In the presence of deterministic\nrelationships there is generally no causal graph that satisfies both the Markov\ncondition and the faithfulness condition. We introduce factored space models as\nan alternative to causal graphs which naturally represent both probabilistic\nand deterministic relationships at all levels of abstraction. Moreover, we\nintroduce structural independence and establish that it is equivalent to\nstatistical independence in every distribution that factorizes over the\nfactored space. This theorem generalizes the classical soundness and\ncompleteness theorem for d-separation.",
      "tldr_zh": "该论文探讨了因果性在理解智能行为中的作用，指出传统的causal graphs模型在处理未知变量或不同抽象级别（如图像像素与对象位置）时存在局限，尤其在确定性关系下无法同时满足Markov condition和faithfulness condition。作者提出factored space models作为替代方案，能自然表示多抽象级别的概率和确定性关系。论文还引入structural independence概念，并证明其等价于统计独立性，从而推广了d-separation的健全性和完整性定理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.02579v2",
      "published_date": "2024-12-03 17:04:20 UTC",
      "updated_date": "2024-12-20 18:38:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:09:59.720766"
    },
    {
      "arxiv_id": "2412.02574v1",
      "title": "Generating Critical Scenarios for Testing Automated Driving Systems",
      "title_zh": "生成测试",
      "authors": [
        "Trung-Hieu Nguyen",
        "Truong-Giang Vuong",
        "Hong-Nam Duong",
        "Son Nguyen",
        "Hieu Dinh Vo",
        "Toshiaki Aoki",
        "Thu-Trang Nguyen"
      ],
      "abstract": "Autonomous vehicles (AVs) have demonstrated significant potential in\nrevolutionizing transportation, yet ensuring their safety and reliability\nremains a critical challenge, especially when exposed to dynamic and\nunpredictable environments. Real-world testing of an Autonomous Driving System\n(ADS) is both expensive and risky, making simulation-based testing a preferred\napproach. In this paper, we propose AVASTRA, a Reinforcement Learning\n(RL)-based approach to generate realistic critical scenarios for testing ADSs\nin simulation environments. To capture the complexity of driving scenarios,\nAVASTRA comprehensively represents the environment by both the internal states\nof an ADS under-test (e.g., the status of the ADS's core components, speed, or\nacceleration) and the external states of the surrounding factors in the\nsimulation environment (e.g., weather, traffic flow, or road condition).\nAVASTRA trains the RL agent to effectively configure the simulation environment\nthat places the AV in dangerous situations and potentially leads it to\ncollisions. We introduce a diverse set of actions that allows the RL agent to\nsystematically configure both environmental conditions and traffic\nparticipants. Additionally, based on established safety requirements, we\nenforce heuristic constraints to ensure the realism and relevance of the\ngenerated test scenarios. AVASTRA is evaluated on two popular simulation maps\nwith four different road configurations. Our results show AVASTRA's ability to\noutperform the state-of-the-art approach by generating 30% to 115% more\ncollision scenarios. Compared to the baseline based on Random Search, AVASTRA\nachieves up to 275% better performance. These results highlight the\neffectiveness of AVASTRA in enhancing the safety testing of AVs through\nrealistic comprehensive critical scenario generation.",
      "tldr_zh": "本研究针对自动驾驶系统（Autonomous Driving Systems, ADS）的安全测试问题，提出了一种基于强化学习（Reinforcement Learning, RL）的框架AVASTRA，用于生成现实的临界场景。该方法全面考虑ADS的内部状态（如速度和加速度）以及外部环境因素（如天气、交通流量和道路条件），并通过多样化的动作配置模拟环境以诱发潜在碰撞。AVASTRA还引入启发式约束（heuristic constraints）确保场景的真实性和相关性。实验结果显示，在两个模拟地图上，AVASTRA比现有最先进方法生成30%至115%的更多碰撞场景，并比基于随机搜索的基线提高高达275%的性能，从而显著提升了自动驾驶车辆的安全测试效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02574v1",
      "published_date": "2024-12-03 16:59:30 UTC",
      "updated_date": "2024-12-03 16:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:10:12.133466"
    },
    {
      "arxiv_id": "2412.02570v1",
      "title": "TAB-Fields: A Maximum Entropy Framework for Mission-Aware Adversarial Planning",
      "title_zh": "TAB-Fields：一个最大熵框架，用于任务感知的对抗规划",
      "authors": [
        "Gokul Puthumanaillam",
        "Jae Hyuk Song",
        "Nurzhan Yesmagambet",
        "Shinkyu Park",
        "Melkior Ornik"
      ],
      "abstract": "Autonomous agents operating in adversarial scenarios face a fundamental\nchallenge: while they may know their adversaries' high-level objectives, such\nas reaching specific destinations within time constraints, the exact policies\nthese adversaries will employ remain unknown. Traditional approaches address\nthis challenge by treating the adversary's state as a partially observable\nelement, leading to a formulation as a Partially Observable Markov Decision\nProcess (POMDP). However, the induced belief-space dynamics in a POMDP require\nknowledge of the system's transition dynamics, which, in this case, depend on\nthe adversary's unknown policy. Our key observation is that while an\nadversary's exact policy is unknown, their behavior is necessarily constrained\nby their mission objectives and the physical environment, allowing us to\ncharacterize the space of possible behaviors without assuming specific\npolicies. In this paper, we develop Task-Aware Behavior Fields (TAB-Fields), a\nrepresentation that captures adversary state distributions over time by\ncomputing the most unbiased probability distribution consistent with known\nconstraints. We construct TAB-Fields by solving a constrained optimization\nproblem that minimizes additional assumptions about adversary behavior beyond\nmission and environmental requirements. We integrate TAB-Fields with standard\nplanning algorithms by introducing TAB-conditioned POMCP, an adaptation of\nPartially Observable Monte Carlo Planning. Through experiments in simulation\nwith underwater robots and hardware implementations with ground robots, we\ndemonstrate that our approach achieves superior performance compared to\nbaselines that either assume specific adversary policies or neglect mission\nconstraints altogether. Evaluation videos and code are available at\nhttps://tab-fields.github.io.",
      "tldr_zh": "该论文针对自治代理在对抗场景中的规划挑战，提出TAB-Fields框架，该框架利用最大熵原理，通过计算最无偏的概率分布来表征对手状态随时间的分布，仅基于已知的任务目标和环境约束，而不假设特定对手策略。核心方法涉及解决一个约束优化问题来构建TAB-Fields，并将其集成到TAB-conditioned POMCP算法中，以提升规划的鲁棒性。实验结果显示，在水下机器人模拟和地面机器人硬件测试中，该方法比假设特定策略或忽略任务约束的基准模型表现出显著优越性能，证明了其在不确定环境下的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02570v1",
      "published_date": "2024-12-03 16:55:27 UTC",
      "updated_date": "2024-12-03 16:55:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:10:24.777694"
    },
    {
      "arxiv_id": "2412.02568v1",
      "title": "Segmentation of Coronary Artery Stenosis in X-ray Angiography using Mamba Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Rostami",
        "Fatemeh Fouladi",
        "Hedieh Sajedi"
      ],
      "abstract": "Coronary artery disease stands as one of the primary contributors to global\nmortality rates. The automated identification of coronary artery stenosis from\nX-ray images plays a critical role in the diagnostic process for coronary heart\ndisease. This task is challenging due to the complex structure of coronary\narteries, intrinsic noise in X-ray images, and the fact that stenotic coronary\narteries appear narrow and blurred in X-ray angiographies. This study employs\nfive different variants of the Mamba-based model and one variant of the Swin\nTransformer-based model, primarily based on the U-Net architecture, for the\nlocalization of stenosis in Coronary artery disease. Our best results showed an\nF1 score of 68.79% for the U-Mamba BOT model, representing an 11.8% improvement\nover the semi-supervised approach.",
      "tldr_zh": "本研究针对冠状动脉疾病（Coronary Artery Disease）的自动诊断，提出使用 Mamba-based 模型和 Swin Transformer-based 模型进行 X-ray Angiography 中冠状动脉狭窄（Coronary Artery Stenosis）的分割，以应对图像中复杂结构、噪声和模糊挑战。研究基于 U-Net 架构，测试了五种 Mamba 模型变体和一种 Swin Transformer 模型变体。结果显示，U-Mamba BOT 模型取得了 68.79% 的 F1 score，比半监督方法提高了 11.8%，为临床诊断提供了更精确的定位工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02568v1",
      "published_date": "2024-12-03 16:54:46 UTC",
      "updated_date": "2024-12-03 16:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:10:36.117869"
    },
    {
      "arxiv_id": "2412.02563v1",
      "title": "Semantic Tokens in Retrieval Augmented Generation",
      "title_zh": "检索增强生成中的语义标记",
      "authors": [
        "Joel Suro"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) architectures have recently garnered\nsignificant attention for their ability to improve truth grounding and\ncoherence in natural language processing tasks. However, the reliability of RAG\nsystems in producing accurate answers diminishes as the volume of data they\naccess increases. Even with smaller datasets, these systems occasionally fail\nto address simple queries. This issue arises from their dependence on\nstate-of-the-art large language models (LLMs), which can introduce uncertainty\ninto the system's outputs. In this work, I propose a novel Comparative RAG\nsystem that introduces an evaluator module to bridge the gap between\nprobabilistic RAG systems and deterministically verifiable responses. The\nevaluator compares external recommendations with the retrieved document chunks,\nadding a decision-making layer that enhances the system's reliability. This\napproach ensures that the chunks retrieved are both semantically relevant and\nlogically consistent with deterministic insights, thereby improving the\naccuracy and overall efficiency of RAG systems. This framework paves the way\nfor more reliable and scalable question-answering applications in domains\nrequiring high precision and verifiability.",
      "tldr_zh": "该研究指出，Retrieval-Augmented Generation (RAG) 系统虽然能提升自然语言处理任务的真实性和连贯性，但随着数据量的增加，其可靠性下降，主要由于依赖大型语言模型 (LLMs) 的不确定性导致。作者提出了一种新型 Comparative RAG 系统，引入 evaluator 模块来比较外部推荐和检索文档块，从而添加决策层，确保检索内容在语义上相关和逻辑上一致。实验结果显示，该框架显著提高了 RAG 的准确性和效率，为高精度、可验证的问答应用领域提供了更可靠、可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02563v1",
      "published_date": "2024-12-03 16:52:06 UTC",
      "updated_date": "2024-12-03 16:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:10:48.550164"
    },
    {
      "arxiv_id": "2412.02539v1",
      "title": "Graph-Powered Defense: Controller Area Network Intrusion Detection for Unmanned Aerial Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Reek Majumder",
        "Gurcan Comert",
        "David Werth",
        "Adrian Gale",
        "Mashrur Chowdhury",
        "M Sabbir Salek"
      ],
      "abstract": "The network of services, including delivery, farming, and environmental\nmonitoring, has experienced exponential expansion in the past decade with\nUnmanned Aerial Vehicles (UAVs). Yet, UAVs are not robust enough against\ncyberattacks, especially on the Controller Area Network (CAN) bus. The CAN bus\nis a general-purpose vehicle-bus standard to enable microcontrollers and\nin-vehicle computers to interact, primarily connecting different Electronic\nControl Units (ECUs). In this study, we focus on solving some of the most\ncritical security weaknesses in UAVs by developing a novel graph-based\nintrusion detection system (IDS) leveraging the Uncomplicated Application-level\nVehicular Communication and Networking (UAVCAN) protocol. First, we decode CAN\nmessages based on UAVCAN protocol specification; second, we present a\ncomprehensive method of transforming tabular UAVCAN messages into graph\nstructures. Lastly, we apply various graph-based machine learning models for\ndetecting cyber-attacks on the CAN bus, including graph convolutional neural\nnetworks (GCNNs), graph attention networks (GATs), Graph Sample and Aggregate\nNetworks (GraphSAGE), and graph structure-based transformers. Our findings show\nthat inductive models such as GATs, GraphSAGE, and graph-based transformers can\nachieve competitive and even better accuracy than transductive models like\nGCNNs in detecting various types of intrusions, with minimum information on\nprotocol specification, thus providing a generic robust solution for CAN bus\nsecurity for the UAVs. We also compared our results with baseline single-layer\nLong Short-Term Memory (LSTM) and found that all our graph-based models perform\nbetter without using any decoded features based on the UAVCAN protocol,\nhighlighting higher detection performance with protocol-independent capability.",
      "tldr_zh": "该研究针对无人驾驶航空器(UAVs)的控制器区域网络(CAN)总线安全漏洞，开发了一种基于图的入侵检测系统(IDS)，利用UAVCAN协议来检测网络攻击。首先，通过解码CAN消息并将其转换为图结构，研究应用了多种图-based机器学习模型，包括图卷积神经网络(GCNNs)、图注意力网络(GATs)、GraphSAGE和图结构-based transformers。这些模型无需依赖协议细节，即可实现高效入侵检测，归纳模型如GATs和GraphSAGE在准确率上优于传导模型GCNNs，并比基线单层LSTM模型表现更好。总体而言，该方法提供了一种通用且鲁棒的CAN总线安全解决方案，提升了UAVs的网络防御能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02539v1",
      "published_date": "2024-12-03 16:32:57 UTC",
      "updated_date": "2024-12-03 16:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:11:00.059783"
    },
    {
      "arxiv_id": "2412.02730v2",
      "title": "Shaping AI's Impact on Billions of Lives",
      "title_zh": "塑造人工智能对数十亿人生命的影响",
      "authors": [
        "Mariano-Florentino Cuéllar",
        "Jeff Dean",
        "Finale Doshi-Velez",
        "John Hennessy",
        "Andy Konwinski",
        "Sanmi Koyejo",
        "Pelonomi Moiloa",
        "Emma Pierson",
        "David Patterson"
      ],
      "abstract": "Artificial Intelligence (AI), like any transformative technology, has the\npotential to be a double-edged sword, leading either toward significant\nadvancements or detrimental outcomes for society as a whole. As is often the\ncase when it comes to widely-used technologies in market economies (e.g., cars\nand semiconductor chips), commercial interest tends to be the predominant\nguiding factor. The AI community is at risk of becoming polarized to either\ntake a laissez-faire attitude toward AI development, or to call for government\noverregulation. Between these two poles we argue for the community of AI\npractitioners to consciously and proactively work for the common good. This\npaper offers a blueprint for a new type of innovation infrastructure including\n18 concrete milestones to guide AI research in that direction. Our view is that\nwe are still in the early days of practical AI, and focused efforts by\npractitioners, policymakers, and other stakeholders can still maximize the\nupsides of AI and minimize its downsides.\n  We talked to luminaries such as recent Nobelist John Jumper on science,\nPresident Barack Obama on governance, former UN Ambassador and former National\nSecurity Advisor Susan Rice on security, philanthropist Eric Schmidt on several\ntopics, and science fiction novelist Neal Stephenson on entertainment. This\nongoing dialogue and collaborative effort has produced a comprehensive,\nrealistic view of what the actual impact of AI could be, from a diverse\nassembly of thinkers with deep understanding of this technology and these\ndomains. From these exchanges, five recurring guidelines emerged, which form\nthe cornerstone of a framework for beginning to harness AI in service of the\npublic good. They not only guide our efforts in discovery but also shape our\napproach to deploying this transformative technology responsibly and ethically.",
      "tldr_zh": "这篇论文讨论了人工智能（AI）的双重影响，既能推动社会进步，也可能带来负面后果，并批评商业利益主导AI发展可能导致的极化（如放任主义或过度监管）。作者提出一个创新基础设施蓝图，包括18个具体milestones，来指导AI研究者主动为公共利益服务，同时强调通过与专家（如诺贝尔奖获得者John Jumper和前总统Barack Obama）的对话，提炼出五个核心guidelines，以负责任地部署AI。论文认为，AI仍处于早期阶段，通过从业者、政策制定者和利益相关者的共同努力，可以最大化AI的积极影响并最小化其风险。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02730v2",
      "published_date": "2024-12-03 16:29:37 UTC",
      "updated_date": "2024-12-11 15:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:11:11.818227"
    },
    {
      "arxiv_id": "2412.02530v1",
      "title": "WEM-GAN: Wavelet transform based facial expression manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Dongya Sun",
        "Yunfei Hu",
        "Xianzhe Zhang",
        "Yingsong Hu"
      ],
      "abstract": "Facial expression manipulation aims to change human facial expressions\nwithout affecting face recognition. In order to transform the facial\nexpressions to target expressions, previous methods relied on expression labels\nto guide the manipulation process. However, these methods failed to preserve\nthe details of facial features, which causes the weakening or the loss of\nidentity information in the output image. In our work, we propose WEM-GAN, in\nshort for wavelet-based expression manipulation GAN, which puts more efforts on\npreserving the details of the original image in the editing process. Firstly,\nwe take advantage of the wavelet transform technique and combine it with our\ngenerator with a U-net autoencoder backbone, in order to improve the\ngenerator's ability to preserve more details of facial features. Secondly, we\nalso implement the high-frequency component discriminator, and use\nhigh-frequency domain adversarial loss to further constrain the optimization of\nour model, providing the generated face image with more abundant details.\nAdditionally, in order to narrow the gap between generated facial expressions\nand target expressions, we use residual connections between encoder and\ndecoder, while also using relative action units (AUs) several times. Extensive\nqualitative and quantitative experiments have demonstrated that our model\nperforms better in preserving identity features, editing capability, and image\ngeneration quality on the AffectNet dataset. It also shows superior performance\nin metrics such as Average Content Distance (ACD) and Expression Distance (ED).",
      "tldr_zh": "这篇论文提出了WEM-GAN，一种基于wavelet transform的面部表情操作方法，旨在改变人类面部表情的同时保留身份信息，避免现有方法在依赖表情标签时导致面部细节丢失。WEM-GAN结合U-net自编码器生成器和高频组件判别器(high-frequency component discriminator)，并引入高频域对抗损失(high-frequency domain adversarial loss)，以增强图像细节保留能力；同时，通过residual connections和relative action units (AUs)来缩小生成表情与目标表情的差距。在AffectNet数据集上的定性和定量实验表明，该模型在Average Content Distance (ACD)和Expression Distance (ED)等指标上表现出色，显著提高了身份特征保留、编辑能力和图像生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02530v1",
      "published_date": "2024-12-03 16:23:02 UTC",
      "updated_date": "2024-12-03 16:23:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:11:24.827968"
    },
    {
      "arxiv_id": "2412.02528v1",
      "title": "Bias Analysis of AI Models for Undergraduate Student Admissions",
      "title_zh": "本科生录取 AI 模型的偏差分析",
      "authors": [
        "Kelly Van Busum",
        "Shiaofen Fang"
      ],
      "abstract": "Bias detection and mitigation is an active area of research in machine\nlearning. This work extends previous research done by the authors to provide a\nrigorous and more complete analysis of the bias found in AI predictive models.\nAdmissions data spanning six years was used to create an AI model to determine\nwhether a given student would be directly admitted into the School of Science\nunder various scenarios at a large urban research university. During this time,\nsubmission of standardized test scores as part of an application became\noptional which led to interesting questions about the impact of standardized\ntest scores on admission decisions. We developed and analyzed AI models to\nunderstand which variables are important in admissions decisions, and how the\ndecision to exclude test scores affects the demographics of the students who\nare admitted. We then evaluated the predictive models to detect and analyze\nbiases these models may carry with respect to three variables chosen to\nrepresent sensitive populations: gender, race, and whether a student was the\nfirst in his or her family to attend college. We also extended our analysis to\nshow that the biases detected were persistent. Finally, we included several\nfairness metrics in our analysis and discussed the uses and limitations of\nthese metrics.",
      "tldr_zh": "这篇论文扩展了作者之前的AI模型偏见分析，使用六年招生数据构建预测模型，以评估学生是否被直接录取到科学学院，并探讨标准化测试分数可选政策对录取决策的影响。研究分析了关键变量的重要性，以及排除测试分数如何改变录取学生的 demographic 分布，同时检测了模型中针对性别、种族和第一代大学生的偏见。结果显示，这些偏见是持久的，论文还引入了多种 fairness metrics，并讨论了这些指标的用途和局限性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02528v1",
      "published_date": "2024-12-03 16:21:37 UTC",
      "updated_date": "2024-12-03 16:21:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:11:35.607925"
    },
    {
      "arxiv_id": "2412.02520v3",
      "title": "Cooperative Cruising: Reinforcement Learning-Based Time-Headway Control for Increased Traffic Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Yaron Veksler",
        "Sharon Hornstein",
        "Han Wang",
        "Maria Laura Delle Monache",
        "Daniel Urieli"
      ],
      "abstract": "The proliferation of connected automated vehicles represents an unprecedented\nopportunity for improving driving efficiency and alleviating traffic\ncongestion. However, existing research fails to address realistic multi-lane\nhighway scenarios without assuming connectivity, perception, and control\ncapabilities that are typically unavailable in current vehicles. This paper\nproposes a novel AI system that is the first to improve highway traffic\nefficiency compared with human-like traffic in realistic, simulated multi-lane\nscenarios, while relying on existing connectivity, perception, and control\ncapabilities. At the core of our approach is a reinforcement learning based\ncontroller that dynamically communicates time-headways to automated vehicles\nnear bottlenecks based on real-time traffic conditions. These desired\ntime-headways are then used by adaptive cruise control (ACC) systems to adjust\ntheir following distance. By (i) integrating existing traffic estimation\ntechnology and low-bandwidth vehicle-to-infrastructure connectivity, (ii)\nleveraging safety-certified ACC systems, and (iii) targeting localized\nbottleneck challenges that can be addressed independently in different\nlocations, we propose a potentially practical, safe, and scalable system that\ncan positively impact numerous road users.",
      "tldr_zh": "本文提出一种名为 Cooperative Cruising 的 AI 系统，利用 Reinforcement Learning 基于的控制器动态通信 Time-Headway 给自动车辆，以提高多车道高速公路的交通效率。该系统依赖现有技术，如交通估计、低带宽车辆到基础设施连接和安全认证的 Adaptive Cruise Control (ACC)，针对本地瓶颈问题调整车辆跟随距离，实现实用、安全和可扩展的交通优化。实验结果显示，该系统在现实模拟场景中显著超越人类驾驶水平，提高了整体交通效率，并为缓解拥堵提供了可行的解决方案。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02520v3",
      "published_date": "2024-12-03 16:13:42 UTC",
      "updated_date": "2025-02-02 08:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:11:47.849270"
    },
    {
      "arxiv_id": "2412.02509v2",
      "title": "FCL-ViT: Task-Aware Attention Tuning for Continual Learning",
      "title_zh": "FCL-ViT：任务感知注意力调优用于持续学习",
      "authors": [
        "Anestis Kaimakamidis",
        "Ioannis Pitas"
      ],
      "abstract": "Continual Learning (CL) involves adapting the prior Deep Neural Network (DNN)\nknowledge to new tasks, without forgetting the old ones. However, modern CL\ntechniques focus on provisioning memory capabilities to existing DNN models\nrather than designing new ones that are able to adapt according to the task at\nhand. This paper presents the novel Feedback Continual Learning Vision\nTransformer (FCL-ViT) that uses a feedback mechanism to generate real-time\ndynamic attention features tailored to the current task. The FCL-ViT operates\nin two Phases. In phase 1, the generic image features are produced and\ndetermine where the Transformer should attend on the current image. In phase 2,\ntask-specific image features are generated that leverage dynamic attention. To\nthis end, Tunable self-Attention Blocks (TABs) and Task Specific Blocks (TSBs)\nare introduced that operate in both phases and are responsible for tuning the\nTABs attention, respectively. The FCL-ViT surpasses state-of-the-art\nperformance on Continual Learning compared to benchmark methods, while\nretaining a small number of trainable DNN parameters.",
      "tldr_zh": "这篇论文提出了 FCL-ViT，一种针对 Continual Learning 的新型 Vision Transformer 模型，通过反馈机制实现实时动态注意力调整，以适应新任务而不遗忘旧知识。FCL-ViT 分为两个阶段：第一阶段生成通用图像特征并确定 Transformer 的注意力位置，第二阶段则基于动态注意力产生任务特定特征。论文引入了 Tunable self-Attention Blocks (TABs) 和 Task Specific Blocks (TSBs) 来优化注意力调优过程。实验结果显示，FCL-ViT 在 Continual Learning 基准测试中超越了现有方法，同时仅需较少的训练参数。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02509v2",
      "published_date": "2024-12-03 15:48:33 UTC",
      "updated_date": "2024-12-04 17:35:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:12:00.709693"
    },
    {
      "arxiv_id": "2412.02508v2",
      "title": "Towards Rich Emotions in 3D Avatars: A Text-to-3D Avatar Generation Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Haidong Xu",
        "Meishan Zhang",
        "Hao Ju",
        "Zhedong Zheng",
        "Erik Cambria",
        "Min Zhang",
        "Hao Fei"
      ],
      "abstract": "Producing emotionally dynamic 3D facial avatars with text derived from spoken\nwords (Emo3D) has been a pivotal research topic in 3D avatar generation. While\nprogress has been made in general-purpose 3D avatar generation, the exploration\nof generating emotional 3D avatars remains scarce, primarily due to the\ncomplexities of identifying and rendering rich emotions from spoken words. This\npaper reexamines Emo3D generation and draws inspiration from human processes,\nbreaking down Emo3D into two cascading steps: Text-to-3D Expression Mapping\n(T3DEM) and 3D Avatar Rendering (3DAR). T3DEM is the most crucial step in\ndetermining the quality of Emo3D generation and encompasses three key\nchallenges: Expression Diversity, Emotion-Content Consistency, and Expression\nFluidity. To address these challenges, we introduce a novel benchmark to\nadvance research in Emo3D generation. First, we present EmoAva, a large-scale,\nhigh-quality dataset for T3DEM, comprising 15,000 text-to-3D expression\nmappings that characterize the aforementioned three challenges in Emo3D\ngeneration. Furthermore, we develop various metrics to effectively evaluate\nmodels against these identified challenges. Next, to effectively model the\nconsistency, diversity, and fluidity of human expressions in the T3DEM step, we\npropose the Continuous Text-to-Expression Generator, which employs an\nautoregressive Conditional Variational Autoencoder for expression code\ngeneration, enhanced with Latent Temporal Attention and Expression-wise\nAttention mechanisms. Finally, to further enhance the 3DAR step on rendering\nhigher-quality subtle expressions, we present the Globally-informed Gaussian\nAvatar (GiGA) model. GiGA incorporates a global information mechanism into 3D\nGaussian representations, enabling the capture of subtle micro-expressions and\nseamless transitions between emotional states.",
      "tldr_zh": "这篇论文针对基于文本生成情感丰富的 3D 面部头像（Emo3D）问题，提出一个基准框架，将生成过程分解为 Text-to-3D Expression Mapping (T3DEM) 和 3D Avatar Rendering (3DAR) 两个步骤。T3DEM 需应对表情多样性、情感内容一致性和表情流畅性的三大挑战，为此，论文引入了大规模高品质数据集 EmoAva（包含 15,000 个文本到 3D 表情映射）以及相应的评估指标。作者开发了 Continuous Text-to-Expression Generator，使用 autoregressive Conditional Variational Autoencoder 结合 Latent Temporal Attention 和 Expression-wise Attention 机制，来有效建模表情的一致性、多样性和流畅性。最终，他们提出了 Globally-informed Gaussian Avatar (GiGA) 模型，通过融入全局信息机制，提升对微妙表情的捕捉和情感状态的平滑过渡，从而推进 Emo3D 生成的研究。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages. Project website: https://github.com/WalkerMitty/EmoAva",
      "pdf_url": "http://arxiv.org/pdf/2412.02508v2",
      "published_date": "2024-12-03 15:39:05 UTC",
      "updated_date": "2025-05-20 15:17:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:12:13.817988"
    },
    {
      "arxiv_id": "2412.02479v2",
      "title": "OODFace: Benchmarking Robustness of Face Recognition under Common Corruptions and Appearance Variations",
      "title_zh": "翻译失败",
      "authors": [
        "Caixin Kang",
        "Yubo Chen",
        "Shouwei Ruan",
        "Shiji Zhao",
        "Ruochen Zhang",
        "Jiayi Wang",
        "Shan Fu",
        "Xingxing Wei"
      ],
      "abstract": "With the rise of deep learning, facial recognition technology has seen\nextensive research and rapid development. Although facial recognition is\nconsidered a mature technology, we find that existing open-source models and\ncommercial algorithms lack robustness in certain complex Out-of-Distribution\n(OOD) scenarios, raising concerns about the reliability of these systems. In\nthis paper, we introduce OODFace, which explores the OOD challenges faced by\nfacial recognition models from two perspectives: common corruptions and\nappearance variations. We systematically design 30 OOD scenarios across 9 major\ncategories tailored for facial recognition. By simulating these challenges on\npublic datasets, we establish three robustness benchmarks: LFW-C/V, CFP-FP-C/V,\nand YTF-C/V. We then conduct extensive experiments on 19 facial recognition\nmodels and 3 commercial APIs, along with extended physical experiments on face\nmasks to assess their robustness. Next, we explore potential solutions from two\nperspectives: defense strategies and Vision-Language Models (VLMs). Based on\nthe results, we draw several key insights, highlighting the vulnerability of\nfacial recognition systems to OOD data and suggesting possible solutions.\nAdditionally, we offer a unified toolkit that includes all corruption and\nvariation types, easily extendable to other datasets. We hope that our\nbenchmarks and findings can provide guidance for future improvements in facial\nrecognition model robustness.",
      "tldr_zh": "本研究引入 OODFace 基准，用于评估人脸识别模型在常见腐败（common corruptions）和外观变化（appearance variations）等 Out-of-Distribution (OOD) 场景下的鲁棒性，共设计了 30 种 OOD 场景，涵盖 9 个主要类别，并在公共数据集上建立了 LFW-C/V、CFP-FP-C/V 和 YTF-C/V 等三个鲁棒性基准。实验对 19 个模型和 3 个商业 API 进行了广泛测试，包括物理实验（如面具影响），结果显示人脸识别系统对 OOD 数据高度脆弱。论文还探讨了防御策略和 Vision-Language Models (VLMs) 等潜在解决方案，并提供了一个可扩展的统一工具包，以指导未来人脸识别模型的改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02479v2",
      "published_date": "2024-12-03 14:42:31 UTC",
      "updated_date": "2025-03-27 05:40:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:12:26.910684"
    },
    {
      "arxiv_id": "2412.02474v1",
      "title": "F-SE-LSTM: A Time Series Anomaly Detection Method with Frequency Domain Information",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Xiang Lu",
        "Xiao-Bo Jin",
        "Jian Chen",
        "Dong-Jie Liu",
        "Guang-Gang Geng"
      ],
      "abstract": "With the development of society, time series anomaly detection plays an\nimportant role in network and IoT services. However, most existing anomaly\ndetection methods directly analyze time series in the time domain and cannot\ndistinguish some relatively hidden anomaly sequences. We attempt to analyze the\nimpact of frequency on time series from a frequency domain perspective, thus\nproposing a new time series anomaly detection method called F-SE-LSTM. This\nmethod utilizes two sliding windows and fast Fourier transform (FFT) to\nconstruct a frequency matrix. Simultaneously, Squeeze-and-Excitation Networks\n(SENet) and Long Short-Term Memory (LSTM) are employed to extract\nfrequency-related features within and between periods. Through comparative\nexperiments on multiple datasets such as Yahoo Webscope S5 and Numenta Anomaly\nBenchmark, the results demonstrate that the frequency matrix constructed by\nF-SE-LSTM exhibits better discriminative ability than ordinary time domain and\nfrequency domain data. Furthermore, F-SE-LSTM outperforms existing\nstate-of-the-art deep learning anomaly detection methods in terms of anomaly\ndetection capability and execution efficiency.",
      "tldr_zh": "该论文提出了一种新的时间序列异常检测方法 F-SE-LSTM，通过引入频率域信息来解决现有方法在时间域分析中难以识别隐藏异常序列的问题。该方法利用两个滑动窗口和 fast Fourier transform (FFT) 构建频率矩阵，并结合 Squeeze-and-Excitation Networks (SENet) 和 Long Short-Term Memory (LSTM) 来提取周期内和周期间的频率相关特征。在 Yahoo Webscope S5 和 Numenta Anomaly Benchmark 等数据集上的实验表明，F-SE-LSTM 的频率矩阵具有更强的区分能力，并在异常检测性能和执行效率上优于现有最先进深度学习方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02474v1",
      "published_date": "2024-12-03 14:36:24 UTC",
      "updated_date": "2024-12-03 14:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:12:35.534014"
    },
    {
      "arxiv_id": "2412.02454v1",
      "title": "Gracefully Filtering Backdoor Samples for Generative Large Language Models without Retraining",
      "title_zh": "翻译失败",
      "authors": [
        "Zongru Wu",
        "Pengzhou Cheng",
        "Lingyong Fang",
        "Zhuosheng Zhang",
        "Gongshen Liu"
      ],
      "abstract": "Backdoor attacks remain significant security threats to generative large\nlanguage models (LLMs). Since generative LLMs output sequences of\nhigh-dimensional token logits instead of low-dimensional classification logits,\nmost existing backdoor defense methods designed for discriminative models like\nBERT are ineffective for generative LLMs. Inspired by the observed differences\nin learning behavior between backdoor and clean mapping in the frequency space,\nwe transform gradients of each training sample, directly influencing parameter\nupdates, into the frequency space. Our findings reveal a distinct separation\nbetween the gradients of backdoor and clean samples in the frequency space.\nBased on this phenomenon, we propose Gradient Clustering in the Frequency Space\nfor Backdoor Sample Filtering (GraCeFul), which leverages sample-wise gradients\nin the frequency space to effectively identify backdoor samples without\nrequiring retraining LLMs. Experimental results show that GraCeFul outperforms\nbaselines significantly. Notably, GraCeFul exhibits remarkable computational\nefficiency, achieving nearly 100% recall and F1 scores in identifying backdoor\nsamples, reducing the average success rate of various backdoor attacks to 0%\nwith negligible drops in clean accuracy across multiple free-style question\nanswering datasets. Additionally, GraCeFul generalizes to Llama-2 and Vicuna.\nThe codes are publicly available at https://github.com/ZrW00/GraceFul.",
      "tldr_zh": "这篇论文针对生成式大型语言模型（generative LLMs）的后门攻击（backdoor attacks）问题，提出了一种无需重新训练的过滤方法GraCeFul。GraCeFul通过将训练样本的梯度（gradients）转化为频率空间，并利用后门样本与干净样本在该空间的明显分离特性，进行梯度聚类（Gradient Clustering）来有效识别后门样本。实验结果表明，GraCeFul显著优于现有基线，实现了近100%的召回率和F1分数，将各种后门攻击的平均成功率降至0%，同时在多个自由式问答数据集上保持了干净准确率几乎无损。该方法还展示了良好的泛化性，可应用于Llama-2和Vicuna模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02454v1",
      "published_date": "2024-12-03 13:43:36 UTC",
      "updated_date": "2024-12-03 13:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:12:49.416887"
    },
    {
      "arxiv_id": "2412.02449v1",
      "title": "BYE: Build Your Encoder with One Sequence of Exploration Data for Long-Term Dynamic Scene Understanding",
      "title_zh": "BYE：用一个探索数据序列构建你的编码器用于长期动态场景理解",
      "authors": [
        "Chenguang Huang",
        "Shengchao Yan",
        "Wolfram Burgard"
      ],
      "abstract": "Dynamic scene understanding remains a persistent challenge in robotic\napplications. Early dynamic mapping methods focused on mitigating the negative\ninfluence of short-term dynamic objects on camera motion estimation by masking\nor tracking specific categories, which often fall short in adapting to\nlong-term scene changes. Recent efforts address object association in long-term\ndynamic environments using neural networks trained on synthetic datasets, but\nthey still rely on predefined object shapes and categories. Other methods\nincorporate visual, geometric, or semantic heuristics for the association but\noften lack robustness. In this work, we introduce BYE, a class-agnostic,\nper-scene point cloud encoder that removes the need for predefined categories,\nshape priors, or extensive association datasets. Trained on only a single\nsequence of exploration data, BYE can efficiently perform object association in\ndynamically changing scenes. We further propose an ensembling scheme combining\nthe semantic strengths of Vision Language Models (VLMs) with the scene-specific\nexpertise of BYE, achieving a 7% improvement and a 95% success rate in object\nassociation tasks. Code and dataset are available at\nhttps://byencoder.github.io.",
      "tldr_zh": "本文提出 BYE 编码器，用于解决机器人应用中长期动态场景理解的挑战，该编码器是无类别的点云编码器，仅需一个探索数据序列即可训练，无需预定义物体类别或形状先验，从而实现高效的物体关联。BYE 通过结合 Vision Language Models (VLMs) 的语义优势和其自身场景特定专长，提出了一种集成方案，在物体关联任务中实现了 7% 的性能提升和 95% 的成功率。该方法提高了动态场景处理的鲁棒性，并提供了公开的代码和数据集以供进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02449v1",
      "published_date": "2024-12-03 13:34:42 UTC",
      "updated_date": "2024-12-03 13:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:13:00.780985"
    },
    {
      "arxiv_id": "2412.02441v1",
      "title": "Artificial Expert Intelligence through PAC-reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Shai Shalev-Shwartz",
        "Amnon Shashua",
        "Gal Beniamini",
        "Yoav Levine",
        "Or Sharir",
        "Noam Wies",
        "Ido Ben-Shaul",
        "Tomer Nussbaum",
        "Shir Granot Peled"
      ],
      "abstract": "Artificial Expert Intelligence (AEI) seeks to transcend the limitations of\nboth Artificial General Intelligence (AGI) and narrow AI by integrating\ndomain-specific expertise with critical, precise reasoning capabilities akin to\nthose of top human experts. Existing AI systems often excel at predefined tasks\nbut struggle with adaptability and precision in novel problem-solving. To\novercome this, AEI introduces a framework for ``Probably Approximately Correct\n(PAC) Reasoning\". This paradigm provides robust theoretical guarantees for\nreliably decomposing complex problems, with a practical mechanism for\ncontrolling reasoning precision. In reference to the division of human thought\ninto System 1 for intuitive thinking and System 2 for reflective\nreasoning~\\citep{tversky1974judgment}, we refer to this new type of reasoning\nas System 3 for precise reasoning, inspired by the rigor of the scientific\nmethod. AEI thus establishes a foundation for error-bounded, inference-time\nlearning.",
      "tldr_zh": "该论文提出 Artificial Expert Intelligence (AEI)，旨在超越 Artificial General Intelligence (AGI) 和 narrow AI 的局限，通过整合领域特定专业知识与精确推理能力。AEI 引入 PAC-reasoning 框架，提供可靠的理论保证来分解复杂问题，并通过实用机制控制推理精度。借鉴人类思维的 System 1（直觉思考）和 System 2（反思推理），作者将此精确推理定义为 System 3，从而为错误边界内的推理时间学习奠定基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02441v1",
      "published_date": "2024-12-03 13:25:18 UTC",
      "updated_date": "2024-12-03 13:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:13:11.976912"
    },
    {
      "arxiv_id": "2412.02427v1",
      "title": "GerPS-Compare: Comparing NER methods for legal norm analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah T. Bachinger",
        "Christoph Unger",
        "Robin Erd",
        "Leila Feddoul",
        "Clara Lachenmaier",
        "Sina Zarrieß",
        "Birgitta König-Ries"
      ],
      "abstract": "We apply NER to a particular sub-genre of legal texts in German: the genre of\nlegal norms regulating administrative processes in public service\nadministration. The analysis of such texts involves identifying stretches of\ntext that instantiate one of ten classes identified by public service\nadministration professionals. We investigate and compare three methods for\nperforming Named Entity Recognition (NER) to detect these classes: a Rule-based\nsystem, deep discriminative models, and a deep generative model. Our results\nshow that Deep Discriminative models outperform both the Rule-based system as\nwell as the Deep Generative model, the latter two roughly performing equally\nwell, outperforming each other in different classes. The main cause for this\nsomewhat surprising result is arguably the fact that the classes used in the\nanalysis are semantically and syntactically heterogeneous, in contrast to the\nclasses used in more standard NER tasks. Deep Discriminative models appear to\nbe better equipped for dealing with this heterogenerity than both generic LLMs\nand human linguists designing rule-based NER systems.",
      "tldr_zh": "本文研究了三种Named Entity Recognition (NER) 方法在德国法律规范文本（具体为公共服务管理规则）中的应用，这些文本需识别属于十个类别的实体。方法包括基于规则的系统、深度判别模型和深度生成模型。结果表明，深度判别模型在整体性能上优于其他两种方法，而基于规则的系统和深度生成模型性能大致相当，但各在不同类别中占优。该差异主要源于分析类别的语义和句法异质性，使得深度判别模型更适合处理此类复杂任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02427v1",
      "published_date": "2024-12-03 12:46:06 UTC",
      "updated_date": "2024-12-03 12:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:13:24.204345"
    },
    {
      "arxiv_id": "2412.02415v1",
      "title": "Knowledge-Enhanced Conversational Recommendation via Transformer-based Sequential Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Zou",
        "Aixin Sun",
        "Cheng Long",
        "Evangelos Kanoulas"
      ],
      "abstract": "In conversational recommender systems (CRSs), conversations usually involve a\nset of items and item-related entities or attributes, e.g., director is a\nrelated entity of a movie. These items and item-related entities are often\nmentioned along the development of a dialog, leading to potential sequential\ndependencies among them. However, most of existing CRSs neglect these potential\nsequential dependencies. In this article, we first propose a Transformer-based\nsequential conversational recommendation method, named TSCR, to model the\nsequential dependencies in the conversations to improve CRS. In TSCR, we\nrepresent conversations by items and the item-related entities, and construct\nuser sequences to discover user preferences by considering both the mentioned\nitems and item-related entities. Based on the constructed sequences, we deploy\na Cloze task to predict the recommended items along a sequence. Meanwhile, in\ncertain domains, knowledge graphs formed by the items and their related\nentities are readily available, which provide various different kinds of\nassociations among them. Given that TSCR does not benefit from such knowledge\ngraphs, we then propose a knowledge graph enhanced version of TSCR, called\nTSCRKG. In specific, we leverage the knowledge graph to offline initialize our\nmodel TSCRKG, and augment the user sequence of conversations (i.e., sequence of\nthe mentioned items and item-related entities in the conversation) with\nmulti-hop paths in the knowledge graph. Experimental results demonstrate that\nour TSCR model significantly outperforms state-of-the-art baselines, and the\nenhanced version TSCRKG further improves recommendation performance on top of\nTSCR.",
      "tldr_zh": "本文提出了一种基于 Transformer 的顺序建模方法 TSCR，用于提升对话推荐系统（CRSs）的性能，通过捕捉对话中物品和相关实体（如电影导演）的顺序依赖性。TSCR 通过构建用户序列（包含提到的物品和实体）并采用 Cloze 任务来预测推荐物品，从而更好地发现用户偏好。在特定领域，作者进一步开发了知识图谱（knowledge graphs）增强版 TSCRKG，通过离线初始化模型和使用多跳路径增强用户序列，以利用实体间的各种关联。实验结果显示，TSCR 显著优于现有基线方法，而 TSCRKG 在此基础上进一步提高了推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by ACM TOIS",
      "pdf_url": "http://arxiv.org/pdf/2412.02415v1",
      "published_date": "2024-12-03 12:20:56 UTC",
      "updated_date": "2024-12-03 12:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:13:37.366678"
    },
    {
      "arxiv_id": "2412.02412v1",
      "title": "VISTA: A Panoramic View of Neural Representations",
      "title_zh": "VISTA：神经表示的全景视图",
      "authors": [
        "Tom White"
      ],
      "abstract": "We present VISTA (Visualization of Internal States and Their Associations), a\nnovel pipeline for visually exploring and interpreting neural network\nrepresentations. VISTA addresses the challenge of analyzing vast\nmultidimensional spaces in modern machine learning models by mapping\nrepresentations into a semantic 2D space. The resulting collages visually\nreveal patterns and relationships within internal representations. We\ndemonstrate VISTA's utility by applying it to sparse autoencoder latents\nuncovering new properties and interpretations. We review the VISTA methodology,\npresent findings from our case study ( https://got.drib.net/latents/ ), and\ndiscuss implications for neural network interpretability across various domains\nof machine learning.",
      "tldr_zh": "我们提出VISTA，一种新型管道，用于可视化探索和解释神经网络的内部表示，通过将多维表示映射到语义2D空间，生成视觉拼贴以揭示模式和关系。该方法解决了分析庞大多维空间的挑战，并在应用于sparse autoencoder的潜在变量时，揭示了新的属性和解释。研究通过案例研究（https://got.drib.net/latents/）呈现了发现，并讨论了VISTA对机器学习各种领域的神经网络可解释性的潜在影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02412v1",
      "published_date": "2024-12-03 12:12:03 UTC",
      "updated_date": "2024-12-03 12:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:13:47.688817"
    },
    {
      "arxiv_id": "2412.02410v1",
      "title": "A Multi-Agent Framework for Extensible Structured Text Generation in PLCs",
      "title_zh": "翻译失败",
      "authors": [
        "Donghao Yang",
        "Aolang Wu",
        "Tianyi Zhang",
        "Li Zhang",
        "Fang Liu",
        "Xiaoli Lian",
        "Yuming Ren",
        "Jiaji Tian"
      ],
      "abstract": "Programmable Logic Controllers (PLCs) are microcomputers essential for\nautomating factory operations. Structured Text (ST), a high-level language\nadhering to the IEC 61131-3 standard, is pivotal for PLCs due to its ability to\nexpress logic succinctly and to seamlessly integrate with other languages\nwithin the same standard. However, vendors develop their own customized\nversions of ST, and the lack of comprehensive and standardized documentation\nfor the full semantics of ST has contributed to inconsistencies in how the\nlanguage is implemented. Consequently, the steep learning curve associated with\nST, combined with ever-evolving industrial requirements, presents significant\nchallenges for developers. In response to these issues, we present AutoPLC, an\nLLM-based approach designed to automate the generation of vendor-specific ST\ncode. To facilitate effective code generation, we first built a comprehensive\nknowledge base, including Rq2ST Case Library (requirements and corresponding\nimplementations) and Instruction libraries. Then we developed a retrieval\nmodule to incorporate the domain-specific knowledge by identifying pertinent\ncases and instructions, guiding the LLM to generate code that meets the\nrequirements. In order to verify and improve the quality of the generated code,\nwe designed an adaptable code checker. If errors are detected, we initiate an\niterative self-improvement process to instruct the LLM to revise the generated\ncode. We evaluate AutoPLC's performance against seven state-of-the-art\nbaselines using three benchmarks, one for open-source basic ST and two for\ncommercial Structured Control Language (SCL) from Siemens. The results show\nthat our approach consistently achieves superior performance across all\nbenchmarks. Ablation study emphasizes the significance of our modules. Further\nmanual analysis confirm the practical utility of the ST code generated by\nAutoPLC.",
      "tldr_zh": "该论文针对 Programmable Logic Controllers (PLCs) 中 Structured Text (ST) 代码生成面临的标准化问题和学习挑战，提出了一种基于多智能体框架的 AutoPLC 方法。该方法首先构建了全面知识基，包括 Rq2ST Case Library 和 Instruction libraries，并通过检索模块整合领域知识来指导 Large Language Models (LLMs) 生成供应商特定的 ST 代码。随后，引入可适应的代码检查器进行验证，并采用迭代自改进过程修正错误。实验结果显示，AutoPLC 在三个基准测试（包括开源 ST 和 Siemens SCL）中比七个最先进基线表现出色，消融研究和手动分析进一步证实了其模块设计和实用价值。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02410v1",
      "published_date": "2024-12-03 12:05:56 UTC",
      "updated_date": "2024-12-03 12:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:14:00.689814"
    },
    {
      "arxiv_id": "2412.12122v3",
      "title": "AI-driven Inverse Design of Band-Tunable Mechanical Metastructures for Tailored Vibration Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Tanuj Gupta",
        "Arun Kumar Sharma",
        "Ankur Dwivedi",
        "Vivek Gupta",
        "Subhadeep Sahana",
        "Suryansh Pathak",
        "Ashish Awasthi",
        "Bishakh Bhattacharya"
      ],
      "abstract": "On-demand vibration mitigation in a mechanical system needs the suitable\ndesign of multiscale metastructures, involving complex unit cells. In this\nstudy, immersing in the world of patterns and examining the structural details\nof some interesting motifs are extracted from the mechanical metastructure\nperspective. Nine interlaced metastructures are fabricated using additive\nmanufacturing, and corresponding vibration characteristics are studied\nexperimentally and numerically. Further, the band-gap modulation with metallic\ninserts in the honeycomb interlaced metastructures is also studied. AI-driven\ninverse design of such complex metastructures with a desired vibration\nmitigation profile can pave the way for addressing engineering challenges in\nhigh-precision manufacturing. The current inverse design methodologies are\nlimited to designing simple periodic structures based on limited variants of\nunit cells. Therefore, a novel forward analysis model with multi-head\nFEM-inspired spatial attention (FSA) is proposed to learn the complex geometry\nof the metastructures and predict corresponding transmissibility. Subsequently,\na multiscale Gaussian self-attention (MGSA) based inverse design model with\nGaussian function for 1D spectrum position encoding is developed to produce a\nsuitable metastructure for the desired vibration transmittance. The proposed AI\nframework demonstrated outstanding performance corresponding to the expected\nlocally resonant bandgaps in a targeted frequency range.",
      "tldr_zh": "该研究针对机械系统的定制振动抑制，提出了一种AI驱动的反向设计方法，用于设计带隙可调的多尺度机械元结构（metastructures）。他们首先通过添加剂制造制作并分析了九种交织元结构及其振动特性，包括使用金属插入物调节带隙（band-gap）。核心创新包括开发了一个前向分析模型，使用multi-head FEM-inspired spatial attention (FSA)来学习元结构的复杂几何并预测透射率（transmissibility），以及一个multiscale Gaussian self-attention (MGSA)基于的反向设计模型，通过高斯函数的1D谱位置编码生成满足特定振动抑制需求的元结构。该框架在目标频率范围内表现出色，实现了预期的局部共振带隙，并为高精度制造中的工程挑战提供了新解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12122v3",
      "published_date": "2024-12-03 12:02:11 UTC",
      "updated_date": "2025-02-28 06:51:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:14:12.501904"
    },
    {
      "arxiv_id": "2412.02399v1",
      "title": "OMENN: One Matrix to Explain Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Wróbel",
        "Mikołaj Janusz",
        "Bartosz Zieliński",
        "Dawid Rymarczyk"
      ],
      "abstract": "Deep Learning (DL) models are often black boxes, making their decision-making\nprocesses difficult to interpret. This lack of transparency has driven\nadvancements in eXplainable Artificial Intelligence (XAI), a field dedicated to\nclarifying the reasoning behind DL model predictions. Among these,\nattribution-based methods such as LRP and GradCAM are widely used, though they\nrely on approximations that can be imprecise.\n  To address these limitations, we introduce One Matrix to Explain Neural\nNetworks (OMENN), a novel post-hoc method that represents a neural network as a\nsingle, interpretable matrix for each specific input. This matrix is\nconstructed through a series of linear transformations that represent the\nprocessing of the input by each successive layer in the neural network. As a\nresult, OMENN provides locally precise, attribution-based explanations of the\ninput across various modern models, including ViTs and CNNs. We present a\ntheoretical analysis of OMENN based on dynamic linearity property and validate\nits effectiveness with extensive tests on two XAI benchmarks, demonstrating\nthat OMENN is competitive with state-of-the-art methods.",
      "tldr_zh": "该研究针对深度学习模型的黑盒问题，提出了一种新型后验方法OMENN，用于解释神经网络的决策过程。OMENN通过一系列线性变换，将神经网络表示为针对特定输入的单个可解释矩阵，从而精确捕捉输入在各层（如CNNs和ViTs）的处理过程，比传统归因方法如LRP和GradCAM更准确。实验在两个XAI基准上验证了OMENN的有效性，其性能与最先进方法相当，为可解释人工智能（XAI）提供了竞争力的新工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review, code will be released after acceptance",
      "pdf_url": "http://arxiv.org/pdf/2412.02399v1",
      "published_date": "2024-12-03 11:49:01 UTC",
      "updated_date": "2024-12-03 11:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:16:24.846094"
    },
    {
      "arxiv_id": "2412.02372v2",
      "title": "HERO: Hint-Based Efficient and Reliable Query Optimizer",
      "title_zh": "HERO：基于提示的高效可靠查询优化器",
      "authors": [
        "Sergey Zinchenko",
        "Sergey Iazov"
      ],
      "abstract": "We propose a novel model for learned query optimization which provides query\nhints leading to better execution plans. The model addresses the three key\nchallenges in learned hint-based query optimization: reliable hint\nrecommendation (ensuring non-degradation of query latency), efficient hint\nexploration, and fast inference. We provide an in-depth analysis of existing\nNN-based approaches to hint-based optimization and experimentally confirm the\nnamed challenges for them. Our alternative solution consists of a new inference\nschema based on an ensemble of context-aware models and a graph storage for\nreliable hint suggestion and fast inference, and a budget-controlled training\nprocedure with a local search algorithm that solves the issue of exponential\nsearch space exploration. In experiments on standard benchmarks, our model\ndemonstrates optimization capability close to the best achievable with\ncoarse-grained hints. Controlling the degree of parallelism (query dop) in\naddition to operator-related hints enables our model to achieve 3x latency\nimprovement on JOB benchmark which sets a new standard for optimization. Our\nmodel is interpretable and easy to debug, which is particularly important for\ndeployment in production.",
      "tldr_zh": "该论文提出HERO，一种基于提示的学习型查询优化器，旨在通过提供可靠的查询提示来改善执行计划，同时解决可靠提示推荐、有效提示探索和快速推理的三大挑战。HERO采用集成上下文感知模型的推理架构、图存储用于快速提示建议，以及预算控制训练结合局部搜索算法来处理指数级搜索空间。实验结果显示，在标准基准如JOB benchmark上，该模型实现了接近最佳的优化性能，并通过控制查询并行度（query dop）等操作相关提示，实现了3倍的延迟改进；此外，HERO具有可解释性和易调试性，适合生产环境部署。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG",
        "H.2.4; I.2.6; I.2.8"
      ],
      "primary_category": "cs.DB",
      "comment": "Submitted to VLDB 2025; 13 pages; 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02372v2",
      "published_date": "2024-12-03 10:58:34 UTC",
      "updated_date": "2024-12-05 06:00:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:14:35.369777"
    },
    {
      "arxiv_id": "2412.02368v1",
      "title": "ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?",
      "title_zh": "翻译失败",
      "authors": [
        "Leixin Zhang",
        "Steffen Eger",
        "Yinjie Cheng",
        "Weihe Zhai",
        "Jonas Belouadi",
        "Christoph Leiter",
        "Simone Paolo Ponzetto",
        "Fahimeh Moafian",
        "Zhixue Zhao"
      ],
      "abstract": "Multimodal large language models (LLMs) have demonstrated impressive\ncapabilities in generating high-quality images from textual instructions.\nHowever, their performance in generating scientific images--a critical\napplication for accelerating scientific progress--remains underexplored. In\nthis work, we address this gap by introducing ScImage, a benchmark designed to\nevaluate the multimodal capabilities of LLMs in generating scientific images\nfrom textual descriptions. ScImage assesses three key dimensions of\nunderstanding: spatial, numeric, and attribute comprehension, as well as their\ncombinations, focusing on the relationships between scientific objects (e.g.,\nsquares, circles). We evaluate five models, GPT-4o, Llama, AutomaTikZ, Dall-E,\nand StableDiffusion, using two modes of output generation: code-based outputs\n(Python, TikZ) and direct raster image generation. Additionally, we examine\nfour different input languages: English, German, Farsi, and Chinese. Our\nevaluation, conducted with 11 scientists across three criteria (correctness,\nrelevance, and scientific accuracy), reveals that while GPT-4o produces outputs\nof decent quality for simpler prompts involving individual dimensions such as\nspatial, numeric, or attribute understanding in isolation, all models face\nchallenges in this task, especially for more complex prompts.",
      "tldr_zh": "本研究引入了ScImage基准，用于评估多模态大型语言模型（Multimodal LLMs）从文本描述生成科学图像的能力，旨在填补这一领域的评估空白。基准评估了空间理解（spatial comprehension）、数字理解（numeric comprehension）和属性理解（attribute comprehension）等三个关键维度，以及它们之间的组合关系，测试了GPT-4o、Llama、AutomaTikZ、Dall-E和StableDiffusion等五种模型，通过代码输出（Python、TikZ）和直接光栅图像生成两种模式，以及English、German、Farsi和Chinese四种输入语言。实验结果显示，GPT-4o在简单提示下表现较好，但所有模型在复杂提示中均面临挑战，尤其是在正确性、相关性和科学准确性方面。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02368v1",
      "published_date": "2024-12-03 10:52:06 UTC",
      "updated_date": "2024-12-03 10:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:14:47.895811"
    },
    {
      "arxiv_id": "2412.02357v1",
      "title": "Dynamic Prompt Middleware: Contextual Prompt Refinement Controls for Comprehension Tasks",
      "title_zh": "动态提示中间件：用于理解任务的上下文提示细化控制",
      "authors": [
        "Ian Drosos",
        "Jack Williams",
        "Advait Sarkar",
        "Nicholas Wilson"
      ],
      "abstract": "Effective prompting of generative AI is challenging for many users,\nparticularly in expressing context for comprehension tasks such as explaining\nspreadsheet formulas, Python code, and text passages. Prompt middleware aims to\naddress this barrier by assisting in prompt construction, but barriers remain\nfor users in expressing adequate control so that they can receive AI-responses\nthat match their preferences.\n  We conduct a formative survey (n=38) investigating user needs for control\nover AI-generated explanations in comprehension tasks, which uncovers a\ntrade-off between standardized but predictable support for prompting, and\nadaptive but unpredictable support tailored to the user and task. To explore\nthis trade-off, we implement two prompt middleware approaches: Dynamic Prompt\nRefinement Control (Dynamic PRC) and Static Prompt Refinement Control (Static\nPRC). The Dynamic PRC approach generates context-specific UI elements that\nprovide prompt refinements based on the user's prompt and user needs from the\nAI, while the Static PRC approach offers a preset list of generally applicable\nrefinements.\n  We evaluate these two approaches with a controlled user study (n=16) to\nassess the impact of these approaches on user control of AI responses for\ncrafting better explanations. Results show a preference for the Dynamic PRC\napproach as it afforded more control, lowered barriers to providing context,\nand encouraged exploration and reflection of the tasks, but that reasoning\nabout the effects of different generated controls on the final output remains\nchallenging. Drawing on participant feedback, we discuss design implications\nfor future Dynamic PRC systems that enhance user control of AI responses. Our\nfindings suggest that dynamic prompt middleware can improve the user experience\nof generative AI workflows by affording greater control and guide users to a\nbetter AI response.",
      "tldr_zh": "这篇论文探讨了用户在为理解任务（如解释电子表格公式、Python 代码或文本段落）提示生成式 AI 时面临的上下文表达挑战，提出了 Dynamic Prompt Refinement Control (Dynamic PRC) 和 Static Prompt Refinement Control (Static PRC) 两种提示中间件方法。Dynamic PRC 通过生成特定于用户提示和需求的 UI 元素来提供适应性细化，而 Static PRC 则提供一组预设的通用细化选项。通过用户调查（n=38）和对照研究（n=16），结果显示 Dynamic PRC 更受欢迎，因为它增强了用户控制、降低了提供上下文的障碍，并促进任务探索和反思。论文基于反馈讨论了未来 Dynamic PRC 系统的设计启示，强调动态提示中间件能改善生成式 AI 工作流的用户体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02357v1",
      "published_date": "2024-12-03 10:27:04 UTC",
      "updated_date": "2024-12-03 10:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:15:00.657984"
    },
    {
      "arxiv_id": "2412.02334v2",
      "title": "Reinforcement learning to learn quantum states for Heisenberg scaling accuracy",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongwoo Jae",
        "Jeonghoon Hong",
        "Jinho Choo",
        "Yeong-Dae Kwon"
      ],
      "abstract": "Learning quantum states is a crucial task for realizing quantum information\ntechnology. Recently, neural approaches have emerged as promising methods for\nlearning quantum states. We propose a meta-learning model that utilizes\nreinforcement learning (RL) to optimize the process of learning quantum states.\nTo improve the data efficiency of the RL, we introduce an action repetition\nstrategy inspired by curriculum learning. The RL agent significantly improves\nthe sample efficiency of learning random quantum states, and achieves\ninfidelity scaling close to the Heisenberg limit. We also show that the RL\nagent trained using 3-qubit states can generalize to learning up to 5-qubit\nstates. These results highlight the utility of RL-driven meta-learning to\nenhance the efficiency and generalizability of learning quantum states. Our\napproach can be applied to improve quantum control, quantum optimization, and\nquantum machine learning.",
      "tldr_zh": "该研究提出了一种使用强化学习 (RL) 的元学习模型，以优化量子状态的学习过程，并实现接近海森堡极限 (Heisenberg limit) 的准确性。为提高数据效率，该模型引入了受课程学习启发的行动重复策略，显著提升了学习随机量子状态的样本效率和不保真度缩放表现。实验结果显示，训练于 3-qubit 状态的 RL 代理能泛化到 5-qubit 状态，从而增强了方法的通用性。该方法可应用于量子控制、量子优化和量子机器学习等领域。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02334v2",
      "published_date": "2024-12-03 09:53:32 UTC",
      "updated_date": "2025-02-26 10:24:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:15:12.109849"
    },
    {
      "arxiv_id": "2412.02331v1",
      "title": "Sample Efficient Robot Learning in Supervised Effect Prediction Tasks",
      "title_zh": "在监督效果预测任务中的样本高效机器人学习",
      "authors": [
        "Mehmet Arda Eren",
        "Erhan Oztop"
      ],
      "abstract": "In self-supervised robot learning, robots actively explore their environments\nand generate data by acting on entities in the environment. Therefore, an\nexploration policy is desired that ensures sample efficiency to minimize robot\nexecution costs while still providing accurate learning. For this purpose, the\nrobotic community has adopted Intrinsic Motivation (IM)-based approaches such\nas Learning Progress (LP). On the machine learning front, Active Learning (AL)\nhas been used successfully, especially for classification tasks. In this work,\nwe develop a novel AL framework geared towards robotics regression tasks, such\nas action-effect prediction and, more generally, for world model learning,\nwhich we call MUSEL - Model Uncertainty for Sample Efficient Learning. MUSEL\naims to extract model uncertainty from the total uncertainty estimate given by\na suitable learning engine by making use of earning progress and input\ndiversity and use it to improve sample efficiency beyond the state-of-the-art\naction-effect prediction methods. We demonstrate the feasibility of our model\nby using a Stochastic Variational Gaussian Process (SVGP) as the learning\nengine and testing the system on a set of robotic experiments in simulation.\nThe efficacy of MUSEL is demonstrated by comparing its performance to standard\nmethods used in robot action-effect learning. In a robotic tabletop environment\nin which a robot manipulator is tasked with learning the effect of its actions,\nthe experiments show that MUSEL facilitates higher accuracy in learning action\neffects while ensuring sample efficiency.",
      "tldr_zh": "本研究针对机器人自监督学习中的动作效果预测任务，提出了一种新型 Active Learning (AL) 框架 MUSEL - Model Uncertainty for Sample Efficient Learning，以提升样本效率并减少机器人执行成本。MUSEL 通过从总不确定性中提取模型不确定性，并结合 Learning Progress (LP) 和输入多样性，优化了回归任务如动作效果预测和世界模型学习的过程。实验使用 Stochastic Variational Gaussian Process (SVGP) 作为学习引擎，在模拟机器人桌面环境中进行测试，结果显示 MUSEL 相较于标准方法实现了更高的准确性和样本效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "18 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02331v1",
      "published_date": "2024-12-03 09:48:28 UTC",
      "updated_date": "2024-12-03 09:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:15:23.665910"
    },
    {
      "arxiv_id": "2412.07796v1",
      "title": "MRP-LLM: Multitask Reflective Large Language Models for Privacy-Preserving Next POI Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqing Wu",
        "Zhu Sun",
        "Dongxia Wang",
        "Lu Zhang",
        "Jie Zhang",
        "Yew Soon Ong"
      ],
      "abstract": "Large language models (LLMs) have shown promising potential for next\nPoint-of-Interest (POI) recommendation. However, existing methods only perform\ndirect zero-shot prompting, leading to ineffective extraction of user\npreferences, insufficient injection of collaborative signals, and a lack of\nuser privacy protection. As such, we propose a novel Multitask Reflective Large\nLanguage Model for Privacy-preserving Next POI Recommendation (MRP-LLM), aiming\nto exploit LLMs for better next POI recommendation while preserving user\nprivacy. Specifically, the Multitask Reflective Preference Extraction Module\nfirst utilizes LLMs to distill each user's fine-grained (i.e., categorical,\ntemporal, and spatial) preferences into a knowledge base (KB). The Neighbor\nPreference Retrieval Module retrieves and summarizes the preferences of similar\nusers from the KB to obtain collaborative signals. Subsequently, aggregating\nthe user's preferences with those of similar users, the Multitask Next POI\nRecommendation Module generates the next POI recommendations via multitask\nprompting. Meanwhile, during data collection, a Privacy Transmission Module is\nspecifically devised to preserve sensitive POI data. Extensive experiments on\nthree real-world datasets demonstrate the efficacy of our proposed MRP-LLM in\nproviding more accurate next POI recommendations with user privacy preserved.",
      "tldr_zh": "该研究提出MRP-LLM，一种多任务反射式大语言模型(LLMs)，旨在通过改进用户偏好提取和协作信号注入来提升隐私保护下的下一个兴趣点(POI)推荐。框架包括Multitask Reflective Preference Extraction Module用于提取用户的细粒度偏好（如类别、时间和空间）并存储到知识库(KB)，Neighbor Preference Retrieval Module检索类似用户的偏好，以及Multitask Next POI Recommendation Module通过多任务提示聚合偏好生成推荐，同时Privacy Transmission Module确保数据收集过程中的隐私保护。在三个真实数据集上的实验证明，MRP-LLM比现有方法提供更准确的POI推荐，同时有效保护用户隐私。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07796v1",
      "published_date": "2024-12-03 09:45:02 UTC",
      "updated_date": "2024-12-03 09:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:17:37.299111"
    },
    {
      "arxiv_id": "2412.02327v1",
      "title": "Switchable deep beamformer for high-quality and real-time passive acoustic mapping",
      "title_zh": "可切换深度波",
      "authors": [
        "Yi Zeng",
        "Jinwei Li",
        "Hui Zhu",
        "Shukuan Lu",
        "Jianfeng Li",
        "Xiran Cai"
      ],
      "abstract": "Passive acoustic mapping (PAM) is a promising tool for monitoring acoustic\ncavitation activities in the applications of ultrasound therapy. Data-adaptive\nbeamformers for PAM have better image quality compared to the time exposure\nacoustics (TEA) algorithms. However, the computational cost of data-adaptive\nbeamformers is considerably expensive. In this work, we develop a deep\nbeamformer based on a generative adversarial network, which can switch between\ndifferent transducer arrays and reconstruct high-quality PAM images directly\nfrom radio frequency ultrasound signals with low computational cost. The deep\nbeamformer was trained on the dataset consisting of simulated and experimental\ncavitation signals of single and multiple microbubble clouds measured by\ndifferent (linear and phased) arrays covering 1-15 MHz. We compared the\nperformance of the deep beamformer to TEA and three different data-adaptive\nbeamformers using the simulated and experimental test dataset. Compared with\nTEA, the deep beamformer reduced the energy spread area by 18.9%-65.0% and\nimproved the image signal-to-noise ratio by 9.3-22.9 dB in average for the\ndifferent arrays in our data. Compared to the data-adaptive beamformers, the\ndeep beamformer reduced the computational cost by three orders of magnitude\nachieving 10.5 ms image reconstruction speed in our data, while the image\nquality was as good as that of the data-adaptive beamformers. These results\ndemonstrated the potential of the deep beamformer for high-resolution\nmonitoring of microbubble cavitation activities for ultrasound therapy.",
      "tldr_zh": "这篇论文提出了一种基于生成对抗网络 (GAN) 的可切换深度波束形成器，用于被动声学映射 (PAM)，以实现高图像质量和实时监测超声治疗中的声空化活动。该方法能够处理不同换能器阵列（线性和相位阵列）的射频超声信号，并在1-15 MHz频率范围内重建高质量图像，同时显著降低计算成本。相比于时间暴露声学 (TEA) 算法，深度波束形成器平均减少了18.9%-65.0%的能量扩散区域，并提高了9.3-22.9 dB的图像信噪比。与数据自适应波束形成器相比，它将计算成本降低了三个数量级，实现10.5 ms的图像重建速度，同时保持相似的图像质量。这些结果展示了该技术在高分辨率监测微泡空化活动方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02327v1",
      "published_date": "2024-12-03 09:40:59 UTC",
      "updated_date": "2024-12-03 09:40:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:15:49.850772"
    },
    {
      "arxiv_id": "2412.02302v2",
      "title": "Enhanced Photovoltaic Power Forecasting: An iTransformer and LSTM-Based Model Integrating Temporal and Covariate Interactions",
      "title_zh": "增强的光伏发电功率预测：一个整合时间动态和协变量交互的基于 iTransformer 和 LSTM 模型",
      "authors": [
        "Guang Wu",
        "Yun Wang",
        "Qian Zhou",
        "Ziyang Zhang"
      ],
      "abstract": "Accurate photovoltaic (PV) power forecasting is critical for integrating\nrenewable energy sources into the grid, optimizing real-time energy management,\nand ensuring energy reliability amidst increasing demand. However, existing\nmodels often struggle with effectively capturing the complex relationships\nbetween target variables and covariates, as well as the interactions between\ntemporal dynamics and multivariate data, leading to suboptimal forecasting\naccuracy. To address these challenges, we propose a novel model architecture\nthat leverages the iTransformer for feature extraction from target variables\nand employs long short-term memory (LSTM) to extract features from covariates.\nA cross-attention mechanism is integrated to fuse the outputs of both models,\nfollowed by a Kolmogorov-Arnold network (KAN) mapping for enhanced\nrepresentation. The effectiveness of the proposed model is validated using\npublicly available datasets from Australia, with experiments conducted across\nfour seasons. Results demonstrate that the proposed model effectively capture\nseasonal variations in PV power generation and improve forecasting accuracy.",
      "tldr_zh": "本文提出了一种增强光伏（PV）功率预测模型，旨在解决现有模型在捕捉目标变量与协变量复杂关系以及时间动态与多变量交互方面的不足。模型结合 iTransformer 提取目标变量特征、LSTM 提取协变量特征，并通过交叉注意力机制融合输出，随后使用 Kolmogorov-Arnold network (KAN) 进行表示增强。在澳大利亚公开数据集上的实验验证中，该模型有效捕捉季节变化，并显著提高了预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02302v2",
      "published_date": "2024-12-03 09:16:13 UTC",
      "updated_date": "2025-05-07 08:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:15:59.860855"
    },
    {
      "arxiv_id": "2412.02301v1",
      "title": "Large Multimodal Agents for Accurate Phishing Detection with Enhanced Token Optimization and Cost Reduction",
      "title_zh": "大型多模态代理用于准确网络钓鱼检测，结合增强令牌优化和成本降低",
      "authors": [
        "Fouad Trad",
        "Ali Chehab"
      ],
      "abstract": "With the rise of sophisticated phishing attacks, there is a growing need for\neffective and economical detection solutions. This paper explores the use of\nlarge multimodal agents, specifically Gemini 1.5 Flash and GPT-4o mini, to\nanalyze both URLs and webpage screenshots via APIs, thus avoiding the\ncomplexities of training and maintaining AI systems. Our findings indicate that\nintegrating these two data types substantially enhances detection performance\nover using either type alone. However, API usage incurs costs per query that\ndepend on the number of input and output tokens. To address this, we propose a\ntwo-tiered agentic approach: initially, one agent assesses the URL, and if\ninconclusive, a second agent evaluates both the URL and the screenshot. This\nmethod not only maintains robust detection performance but also significantly\nreduces API costs by minimizing unnecessary multi-input queries. Cost analysis\nshows that with the agentic approach, GPT-4o mini can process about 4.2 times\nas many websites per $100 compared to the multimodal approach (107,440 vs.\n25,626), and Gemini 1.5 Flash can process about 2.6 times more websites\n(2,232,142 vs. 862,068). These findings underscore the significant economic\nbenefits of the agentic approach over the multimodal method, providing a viable\nsolution for organizations aiming to leverage advanced AI for phishing\ndetection while controlling expenses.",
      "tldr_zh": "本研究探讨使用大型多模态代理（如 Gemini 1.5 Flash 和 GPT-4o mini）通过 APIs 分析 URL 和网页截图，以实现高效的网络钓鱼检测，避免了训练和维护 AI 系统的复杂性。研究发现，整合 URL 和截图数据比单独使用一种数据类型显著提升检测性能，但 API 查询成本依赖于输入/输出 tokens。针对此，提出了一种两层代理方法：先评估 URL，若不确定再评估 URL 和截图，从而维持高检测准确率并大幅降低成本——例如，GPT-4o mini 可处理约 4.2 倍网站（每 100 美元 107,440 vs. 25,626），Gemini 1.5 Flash 处理约 2.6 倍（2,232,142 vs. 862,068）。这一方法为组织提供经济可行的网络钓鱼检测解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in the 2nd International Conference on Foundation and Large\n  Language Models (FLLM2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.02301v1",
      "published_date": "2024-12-03 09:13:52 UTC",
      "updated_date": "2024-12-03 09:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:17:50.158520"
    },
    {
      "arxiv_id": "2412.02295v1",
      "title": "CADMR: Cross-Attention and Disentangled Learning for Multimodal Recommender Systems",
      "title_zh": "CADMR：交叉注意力和解耦学习用于多模态推荐系统",
      "authors": [
        "Yasser Khalafaoui",
        "Martino Lovisetto",
        "Basarab Matei",
        "Nistor Grozavu"
      ],
      "abstract": "The increasing availability and diversity of multimodal data in recommender\nsystems offer new avenues for enhancing recommendation accuracy and user\nsatisfaction. However, these systems must contend with high-dimensional, sparse\nuser-item rating matrices, where reconstructing the matrix with only small\nsubsets of preferred items for each user poses a significant challenge. To\naddress this, we propose CADMR, a novel autoencoder-based multimodal\nrecommender system framework. CADMR leverages multi-head cross-attention\nmechanisms and Disentangled Learning to effectively integrate and utilize\nheterogeneous multimodal data in reconstructing the rating matrix. Our approach\nfirst disentangles modality-specific features while preserving their\ninterdependence, thereby learning a joint latent representation. The multi-head\ncross-attention mechanism is then applied to enhance user-item interaction\nrepresentations with respect to the learned multimodal item latent\nrepresentations. We evaluate CADMR on three benchmark datasets, demonstrating\nsignificant performance improvements over state-of-the-art methods.",
      "tldr_zh": "该研究提出CADMR，一种基于自编码器的多模态推荐系统框架，旨在解决高维稀疏用户-物品评分矩阵的重建挑战。CADMR 通过 Disentangled Learning 先分离模态特定特征并保留其相互依赖性，以学习联合潜在表示，然后利用多头交叉注意力机制增强用户-物品交互表示，从而有效整合异构多模态数据。实验在三个基准数据集上显示，CADMR 相对于现有最先进方法实现了显著性能提升。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02295v1",
      "published_date": "2024-12-03 09:09:52 UTC",
      "updated_date": "2024-12-03 09:09:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:18:00.103969"
    },
    {
      "arxiv_id": "2412.02294v1",
      "title": "Initial Study On Improving Segmentation By Combining Preoperative CT And Intraoperative CBCT Using Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian E. Tschuchnig",
        "Philipp Steininger",
        "Michael Gadermayr"
      ],
      "abstract": "Computer-Assisted Interventions enable clinicians to perform precise,\nminimally invasive procedures, often relying on advanced imaging methods.\nCone-beam computed tomography (CBCT) can be used to facilitate\ncomputer-assisted interventions, despite often suffering from artifacts that\npose challenges for accurate interpretation. While the degraded image quality\ncan affect image analysis, the availability of high quality, preoperative scans\noffers potential for improvements. Here we consider a setting where\npreoperative CT and intraoperative CBCT scans are available, however, the\nalignment (registration) between the scans is imperfect to simulate a real\nworld scenario. We propose a multimodal learning method that fuses roughly\naligned CBCT and CT scans and investigate the effect on segmentation\nperformance. For this experiment we use synthetically generated data containing\nreal CT and synthetic CBCT volumes with corresponding voxel annotations. We\nshow that this fusion setup improves segmentation performance in $18$ out of\n$20$ investigated setups.",
      "tldr_zh": "该研究探讨了通过结合术前 CT 和术中 CBCT 扫描来改善图像分割性能的问题，针对 CBCT 的伪影 artifacts 带来的挑战。研究提出了一种多模态学习方法，用于融合粗略对齐的 CT 和 CBCT 扫描，并在模拟真实场景的条件下进行实验。使用合成数据（包括真实 CT 和合成 CBCT 体素 annotations），结果显示在 20 个设置中，有 18 个实现了 segmentation performance 的提升，为计算机辅助干预中的精确图像分析提供了初步见解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at BVM 2025. arXiv admin note: text overlap with\n  arXiv:2406.11650",
      "pdf_url": "http://arxiv.org/pdf/2412.02294v1",
      "published_date": "2024-12-03 09:08:38 UTC",
      "updated_date": "2024-12-03 09:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:18:12.674644"
    },
    {
      "arxiv_id": "2412.02292v1",
      "title": "Deep Matrix Factorization with Adaptive Weights for Multi-View Clustering",
      "title_zh": "自适应权重的深度矩阵分解用于多视图聚类",
      "authors": [
        "Yasser Khalafaoui",
        "Basarab Matei",
        "Martino Lovisetto",
        "Nistor Grozavu"
      ],
      "abstract": "Recently, deep matrix factorization has been established as a powerful model\nfor unsupervised tasks, achieving promising results, especially for multi-view\nclustering. However, existing methods often lack effective feature selection\nmechanisms and rely on empirical hyperparameter selection. To address these\nissues, we introduce a novel Deep Matrix Factorization with Adaptive Weights\nfor Multi-View Clustering (DMFAW). Our method simultaneously incorporates\nfeature selection and generates local partitions, enhancing clustering results.\nNotably, the features weights are controlled and adjusted by a parameter that\nis dynamically updated using Control Theory inspired mechanism, which not only\nimproves the model's stability and adaptability to diverse datasets but also\naccelerates convergence. A late fusion approach is then proposed to align the\nweighted local partitions with the consensus partition. Finally, the\noptimization problem is solved via an alternating optimization algorithm with\ntheoretically guaranteed convergence. Extensive experiments on benchmark\ndatasets highlight that DMFAW outperforms state-of-the-art methods in terms of\nclustering performance.",
      "tldr_zh": "本研究针对多视图聚类（Multi-View Clustering）中的问题，提出了一种新型Deep Matrix Factorization with Adaptive Weights (DMFAW)方法，以解决现有模型缺乏有效特征选择机制和依赖经验超参数的问题。DMFAW 同时整合特征选择和局部分区生成，并通过受Control Theory启发的动态参数机制自动调整特征权重，提高模型的稳定性和适应性，同时加速收敛。研究还引入晚融合（late fusion）方法来对齐加权局部分区与共识分区，并采用交替优化算法进行求解，该算法具有理论上的收敛保证。在基准数据集上的广泛实验表明，DMFAW 在聚类性能上优于最先进方法。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02292v1",
      "published_date": "2024-12-03 09:08:27 UTC",
      "updated_date": "2024-12-03 09:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:18:24.378679"
    },
    {
      "arxiv_id": "2412.02291v2",
      "title": "Conformal Symplectic Optimization for Stable Reinforcement Learning",
      "title_zh": "保形辛优化用于稳定强化学习",
      "authors": [
        "Yao Lyu",
        "Xiangteng Zhang",
        "Shengbo Eben Li",
        "Jingliang Duan",
        "Letian Tao",
        "Qing Xu",
        "Lei He",
        "Keqiang Li"
      ],
      "abstract": "Training deep reinforcement learning (RL) agents necessitates overcoming the\nhighly unstable nonconvex stochastic optimization inherent in the\ntrial-and-error mechanism. To tackle this challenge, we propose a\nphysics-inspired optimization algorithm called relativistic adaptive gradient\ndescent (RAD), which enhances long-term training stability. By conceptualizing\nneural network (NN) training as the evolution of a conformal Hamiltonian\nsystem, we present a universal framework for transferring long-term stability\nfrom conformal symplectic integrators to iterative NN updating rules, where the\nchoice of kinetic energy governs the dynamical properties of resulting\noptimization algorithms. By utilizing relativistic kinetic energy, RAD\nincorporates principles from special relativity and limits parameter updates\nbelow a finite speed, effectively mitigating abnormal gradient influences.\nAdditionally, RAD models NN optimization as the evolution of a multi-particle\nsystem where each trainable parameter acts as an independent particle with an\nindividual adaptive learning rate. We prove RAD's sublinear convergence under\ngeneral nonconvex settings, where smaller gradient variance and larger batch\nsizes contribute to tighter convergence. Notably, RAD degrades to the\nwell-known adaptive moment estimation (ADAM) algorithm when its speed\ncoefficient is chosen as one and symplectic factor as a small positive value.\nExperimental results show RAD outperforming nine baseline optimizers with five\nRL algorithms across twelve environments, including standard benchmarks and\nchallenging scenarios. Notably, RAD achieves up to a 155.1% performance\nimprovement over ADAM in Atari games, showcasing its efficacy in stabilizing\nand accelerating RL training.",
      "tldr_zh": "本研究提出了一种基于物理启发的优化算法 relativistic adaptive gradient descent (RAD)，旨在解决深度 reinforcement learning (RL) 训练中非凸随机优化的不稳定性问题。通过将神经网络训练视为 conformal Hamiltonian 系统，RAD 利用 conformal symplectic integrators 和 relativistic kinetic energy 来限制参数更新速度，缓解异常梯度影响，并将优化建模为多粒子系统，每个参数带有自适应学习率。研究证明了 RAD 在非凸设置下的次线性收敛性，并在特定条件下退化成经典的 adaptive moment estimation (ADAM) 算法。实验结果显示，RAD 在五种 RL 算法和十二个环境中优于九种基线优化器，在 Atari 游戏中比 ADAM 提升高达 155.1% 的性能，从而显著稳定和加速 RL 训练。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02291v2",
      "published_date": "2024-12-03 09:07:31 UTC",
      "updated_date": "2024-12-08 07:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:18:36.686277"
    },
    {
      "arxiv_id": "2412.02285v1",
      "title": "GQWformer: A Quantum-based Transformer for Graph Representation Learning",
      "title_zh": "GQWformer：一种基于量子的 Transformer 用于图表示学习",
      "authors": [
        "Lei Yu",
        "Hongyang Chen",
        "Jingsong Lv",
        "Linyao Yang"
      ],
      "abstract": "Graph Transformers (GTs) have demonstrated significant advantages in graph\nrepresentation learning through their global attention mechanisms. However, the\nself-attention mechanism in GTs tends to neglect the inductive biases inherent\nin graph structures, making it chanllenging to effectively capture essential\nstructural information. To address this issue, we propose a novel approach that\nintegrate graph inductive bias into self-attention mechanisms by leveraging\nquantum technology for structural encoding. In this paper, we introduce the\nGraph Quantum Walk Transformer (GQWformer), a groundbreaking GNN framework that\nutilizes quantum walks on attributed graphs to generate node quantum states.\nThese quantum states encapsulate rich structural attributes and serve as\ninductive biases for the transformer, thereby enabling the generation of more\nmeaningful attention scores. By subsequently incorporating a recurrent neural\nnetwork, our design amplifies the model's ability to focus on both local and\nglobal information. We conducted comprehensive experiments across five publicly\navailable datasets to evaluate the effectiveness of our model. These results\nclearly indicate that GQWformer outperforms existing state-of-the-art graph\nclassification algorithms. These findings highlight the significant potential\nof integrating quantum computing methodologies with traditional GNNs to advance\nthe field of graph representation learning, providing a promising direction for\nfuture research and applications.",
      "tldr_zh": "该论文提出GQWformer，一种基于量子技术的Graph Transformer框架，用于提升图表示学习。GQWformer通过量子行走(quantum walks)在属性图上生成节点量子状态，将这些状态作为归纳偏差(inductive biases)融入自注意力(self-attention)机制，从而更好地捕获图结构的本质信息。框架还结合循环神经网络(RNN)来增强对局部和全局信息的关注。实验结果显示，在五个公开数据集上，GQWformer在图分类任务中优于现有最先进算法。整体而言，该方法突显了量子计算与传统GNN(Graph Neural Networks)整合的潜力，为图表示学习领域开辟新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02285v1",
      "published_date": "2024-12-03 09:03:04 UTC",
      "updated_date": "2024-12-03 09:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:18:48.165959"
    },
    {
      "arxiv_id": "2412.02283v1",
      "title": "VR Based Emotion Recognition Using Deep Multimodal Fusion With Biosignals Across Multiple Anatomical Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Pubudu L. Indrasiri",
        "Bipasha Kashyap",
        "Chandima Kolambahewage",
        "Bahareh Nakisa",
        "Kiran Ijaz",
        "Pubudu N. Pathirana"
      ],
      "abstract": "Emotion recognition is significantly enhanced by integrating multimodal\nbiosignals and IMU data from multiple domains. In this paper, we introduce a\nnovel multi-scale attention-based LSTM architecture, combined with\nSqueeze-and-Excitation (SE) blocks, by leveraging multi-domain signals from the\nhead (Meta Quest Pro VR headset), trunk (Equivital Vest), and peripheral\n(Empatica Embrace Plus) during affect elicitation via visual stimuli. Signals\nfrom 23 participants were recorded, alongside self-assessed valence and arousal\nratings after each stimulus. LSTM layers extract features from each modality,\nwhile multi-scale attention captures fine-grained temporal dependencies, and SE\nblocks recalibrate feature importance prior to classification. We assess which\ndomain's signals carry the most distinctive emotional information during VR\nexperiences, identifying key biosignals contributing to emotion detection. The\nproposed architecture, validated in a user study, demonstrates superior\nperformance in classifying valance and arousal level (high / low), showcasing\nthe efficacy of multi-domain and multi-modal fusion with biosignals (e.g.,\nTEMP, EDA) with IMU data (e.g., accelerometer) for emotion recognition in\nreal-world applications.",
      "tldr_zh": "本研究提出了一种基于多尺度注意力 LSTM 架构的系统，结合 Squeeze-and-Excitation (SE) 块，融合来自头部（Meta Quest Pro VR 头盔）、躯干（Equivital Vest）和外围（Empatica Embrace Plus）的多域生物信号（如 TEMP, EDA）和 IMU 数据（如加速度计），以提升 VR 环境下的情感识别性能。实验涉及 23 名参与者，通过视觉刺激记录信号并收集自评的 valence 和 arousal 评分，评估不同域信号对情感信息的关键贡献。结果显示，该架构在分类 valence 和 arousal 水平（高/低）方面表现出色，比传统方法更有效，证明了多模态融合在真实应用中的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02283v1",
      "published_date": "2024-12-03 08:59:12 UTC",
      "updated_date": "2024-12-03 08:59:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:19:01.382830"
    },
    {
      "arxiv_id": "2412.02280v1",
      "title": "AH-OCDA: Amplitude-based Curriculum Learning and Hopfield Segmentation Model for Open Compound Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyun Choi",
        "Junwon Ko",
        "Dong-Jae Lee",
        "Junmo Kim"
      ],
      "abstract": "Open compound domain adaptation (OCDA) is a practical domain adaptation\nproblem that consists of a source domain, target compound domain, and unseen\nopen domain. In this problem, the absence of domain labels and pixel-level\nsegmentation labels for both compound and open domains poses challenges to the\ndirect application of existing domain adaptation and generalization methods. To\naddress this issue, we propose Amplitude-based curriculum learning and a\nHopfield segmentation model for Open Compound Domain Adaptation (AH-OCDA). Our\nmethod comprises two complementary components: 1) amplitude-based curriculum\nlearning and 2) Hopfield segmentation model. Without prior knowledge of target\ndomains within the compound domains, amplitude-based curriculum learning\ngradually induces the semantic segmentation model to adapt from the near-source\ncompound domain to the far-source compound domain by ranking unlabeled compound\ndomain images through Fast Fourier Transform (FFT). Additionally, the Hopfield\nsegmentation model maps segmentation feature distributions from arbitrary\ndomains to the feature distributions of the source domain. AH-OCDA achieves\nstate-of-the-art performance on two OCDA benchmarks and extended open domains,\ndemonstrating its adaptability to continuously changing compound domains and\nunseen open domains.",
      "tldr_zh": "这篇论文针对开放复合域适应（OCDA）问题，提出了一种名为 AH-OCDA 的方法，以解决源域、目标复合域和未见开放域中缺乏域标签和像素级分割标签的挑战。该方法包括两个关键组件：基于振幅的课程学习（Amplitude-based curriculum learning），通过 Fast Fourier Transform (FFT) 对未标记复合域图像排序，实现从接近源域到远离源域的渐进适应；以及 Hopfield segmentation model，用于将分割特征分布从任意域映射回源域特征分布。实验结果表明，AH-OCDA 在两个 OCDA 基准和扩展开放域上取得了最先进性能，展示了其对不断变化的复合域和未见开放域的强大适应性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02280v1",
      "published_date": "2024-12-03 08:55:10 UTC",
      "updated_date": "2024-12-03 08:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:19:13.739297"
    },
    {
      "arxiv_id": "2412.02279v1",
      "title": "A Comprehensive Evaluation of Large Language Models on Aspect-Based Sentiment Analysis",
      "title_zh": "大型语言模型在方面级情感分析中的全面评估",
      "authors": [
        "Changzhi Zhou",
        "Dandan Song",
        "Yuhang Tian",
        "Zhijing Wu",
        "Hao Wang",
        "Xinyu Zhang",
        "Jun Yang",
        "Ziyi Yang",
        "Shuhao Zhang"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have garnered increasing attention in\nthe field of natural language processing, revolutionizing numerous downstream\ntasks with powerful reasoning and generation abilities. For example, In-Context\nLearning (ICL) introduces a fine-tuning-free paradigm, allowing out-of-the-box\nLLMs to execute downstream tasks by analogy learning without any fine-tuning.\nBesides, in a fine-tuning-dependent paradigm where substantial training data\nexists, Parameter-Efficient Fine-Tuning (PEFT), as the cost-effective methods,\nenable LLMs to achieve excellent performance comparable to full fine-tuning.\n  However, these fascinating techniques employed by LLMs have not been fully\nexploited in the ABSA field. Previous works probe LLMs in ABSA by merely using\nrandomly selected input-output pairs as demonstrations in ICL, resulting in an\nincomplete and superficial evaluation. In this paper, we shed light on a\ncomprehensive evaluation of LLMs in the ABSA field, involving 13 datasets, 8\nABSA subtasks, and 6 LLMs. Specifically, we design a unified task formulation\nto unify ``multiple LLMs for multiple ABSA subtasks in multiple paradigms.''\nFor the fine-tuning-dependent paradigm, we efficiently fine-tune LLMs using\ninstruction-based multi-task learning. For the fine-tuning-free paradigm, we\npropose 3 demonstration selection strategies to stimulate the few-shot\nabilities of LLMs. Our extensive experiments demonstrate that LLMs achieve a\nnew state-of-the-art performance compared to fine-tuned Small Language Models\n(SLMs) in the fine-tuning-dependent paradigm. More importantly, in the\nfine-tuning-free paradigm where SLMs are ineffective, LLMs with ICL still\nshowcase impressive potential and even compete with fine-tuned SLMs on some\nABSA subtasks.",
      "tldr_zh": "本文对 Large Language Models (LLMs) 在 Aspect-Based Sentiment Analysis (ABSA) 领域的性能进行了全面评估，涵盖 13 个数据集、8 个 ABSA 子任务和 6 个 LLMs。研究设计了统一的任务表述，支持 fine-tuning-dependent 和 fine-tuning-free 范式：前者通过指令-based 多任务学习高效 fine-tune LLMs，后者提出 3 种演示选择策略来激发 LLMs 的 few-shot 能力。实验结果显示，LLMs 在 fine-tuning-dependent 范式中超越了 fine-tuned Small Language Models (SLMs)，并在 fine-tuning-free 范式中，通过 In-Context Learning (ICL) 展现出强大的潜力，甚至在某些子任务上与 fine-tuned SLMs 竞争。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02279v1",
      "published_date": "2024-12-03 08:54:17 UTC",
      "updated_date": "2024-12-03 08:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:19:26.863766"
    },
    {
      "arxiv_id": "2412.03600v2",
      "title": "Social Media Informatics for Sustainable Cities and Societies: An Overview of the Applications, associated Challenges, and Potential Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Jebran Khan",
        "Kashif Ahmad",
        "Senthil Kumar Jagatheesaperumal",
        "Nasir Ahmad",
        "Kyung-Ah Sohn"
      ],
      "abstract": "In the modern world, our cities and societies face several technological and\nsocietal challenges, such as rapid urbanization, global warming & climate\nchange, the digital divide, and social inequalities, increasing the need for\nmore sustainable cities and societies. Addressing these challenges requires a\nmultifaceted approach involving all the stakeholders, sustainable planning,\nefficient resource management, innovative solutions, and modern technologies.\nLike other modern technologies, social media informatics also plays its part in\ndeveloping more sustainable and resilient cities and societies. Despite its\nlimitations, social media informatics has proven very effective in various\nsustainable cities and society applications. In this paper, we review and\nanalyze the role of social media informatics in sustainable cities and society\nby providing a detailed overview of its applications, associated challenges,\nand potential solutions. This work is expected to provide a baseline for future\nresearch in the domain.",
      "tldr_zh": "该论文概述了社交媒体信息学（social media informatics）在推动可持续城市和社会（sustainable cities and societies）方面的作用，针对诸如快速城市化、全球变暖和数字鸿沟等挑战。作者通过回顾和分析其各种应用、相关挑战（如局限性和社会不平等问题）以及潜在解决方案，强调了多利益相关者参与和创新技术的必要性。该研究为未来在这一领域的研究提供了重要基线。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "35 pages, 3 tables, and 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03600v2",
      "published_date": "2024-12-03 08:53:32 UTC",
      "updated_date": "2024-12-09 16:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:19:36.062575"
    },
    {
      "arxiv_id": "2412.02270v1",
      "title": "Sustainable Self-evolution Adversarial Training",
      "title_zh": "可持续自我演化对抗训练",
      "authors": [
        "Wenxuan Wang",
        "Chenglei Wang",
        "Huihui Qi",
        "Menghao Ye",
        "Xuelin Qian",
        "Peng Wang",
        "Yanning Zhang"
      ],
      "abstract": "With the wide application of deep neural network models in various computer\nvision tasks, there has been a proliferation of adversarial example generation\nstrategies aimed at deeply exploring model security. However, existing\nadversarial training defense models, which rely on single or limited types of\nattacks under a one-time learning process, struggle to adapt to the dynamic and\nevolving nature of attack methods. Therefore, to achieve defense performance\nimprovements for models in long-term applications, we propose a novel\nSustainable Self-Evolution Adversarial Training (SSEAT) framework.\nSpecifically, we introduce a continual adversarial defense pipeline to realize\nlearning from various kinds of adversarial examples across multiple stages.\nAdditionally, to address the issue of model catastrophic forgetting caused by\ncontinual learning from ongoing novel attacks, we propose an adversarial data\nreplay module to better select more diverse and key relearning data.\nFurthermore, we design a consistency regularization strategy to encourage\ncurrent defense models to learn more from previously trained ones, guiding them\nto retain more past knowledge and maintain accuracy on clean samples. Extensive\nexperiments have been conducted to verify the efficacy of the proposed SSEAT\ndefense method, which demonstrates superior defense performance and\nclassification accuracy compared to competitors.",
      "tldr_zh": "该研究针对深度神经网络在对抗攻击中的适应性问题，提出了一种新型框架 Sustainable Self-Evolution Adversarial Training (SSEAT)，通过持续对抗防御管道实现多阶段学习来自多种对抗样本。SSEAT 引入对抗数据重放模块来选择更多样化的关键数据，缓解持续学习中的灾难性遗忘问题，并采用一致性正则化策略引导模型保留过去知识，同时维持在干净样本上的准确性。实验结果显示，SSEAT 在防御性能和分类准确性上优于现有竞争方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ACMMM 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.02270v1",
      "published_date": "2024-12-03 08:41:11 UTC",
      "updated_date": "2024-12-03 08:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:19:48.117850"
    },
    {
      "arxiv_id": "2412.02263v2",
      "title": "Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence",
      "title_zh": "连接大型语言模型与区块链：推进智能合约从自动化到智能化的演变",
      "authors": [
        "Youquan Xian",
        "Xueying Zeng",
        "Duancheng Xuan",
        "Danping Yang",
        "Chunpei Li",
        "Peng Fan",
        "Peng Liu"
      ],
      "abstract": "Blockchain smart contracts have catalyzed the development of decentralized\napplications across various domains, including decentralized finance. However,\ndue to constraints in computational resources and the prevalence of data silos,\ncurrent smart contracts face significant challenges in fully leveraging the\npowerful capabilities of Large Language Models (LLMs) for tasks such as\nintelligent analysis and reasoning. To address this gap, this paper proposes\nand implements a universal framework for integrating LLMs with blockchain data,\n{\\sysname}, effectively overcoming the interoperability barriers between\nblockchain and LLMs. By combining semantic relatedness with truth discovery\nmethods, we introduce an innovative data aggregation approach, {\\funcname},\nwhich significantly enhances the accuracy and trustworthiness of data generated\nby LLMs. To validate the framework's effectiveness, we construct a dataset\nconsisting of three types of questions, capturing Q\\&A interactions between 10\noracle nodes and 5 LLM models. Experimental results demonstrate that, even with\n40\\% malicious nodes, the proposed solution improves data accuracy by an\naverage of 17.74\\% compared to the optimal baseline. This research not only\nprovides an innovative solution for the intelligent enhancement of smart\ncontracts but also highlights the potential for deep integration between LLMs\nand blockchain technology, paving the way for more intelligent and complex\napplications of smart contracts in the future.",
      "tldr_zh": "本文提出{\\sysname}框架，将Large Language Models (LLMs)与区块链数据整合，解决智能合约在计算资源和数据孤岛限制下无法充分利用LLMs进行智能分析和推理的问题。通过{\\funcname}数据聚合方法，结合语义相关性和真相发现技术，该框架显著提升了数据生成的准确性和可信度。实验使用一个包含三种问题类型的数据集，模拟10个预言机节点和5个LLM模型的交互，结果显示即使40%的节点为恶意，该框架仍比最佳基线平均提高了17.74%的准确率。这为智能合约从自动化向智能演进提供了创新解决方案，并展示了LLMs与区块链深度集成的潜力。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02263v2",
      "published_date": "2024-12-03 08:35:51 UTC",
      "updated_date": "2024-12-06 16:43:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:20:01.324073"
    },
    {
      "arxiv_id": "2412.02259v2",
      "title": "VideoGen-of-Thought: Step-by-step generating multi-shot video with minimal manual intervention",
      "title_zh": "翻译失败",
      "authors": [
        "Mingzhe Zheng",
        "Yongqi Xu",
        "Haojian Huang",
        "Xuran Ma",
        "Yexin Liu",
        "Wenjie Shu",
        "Yatian Pang",
        "Feilong Tang",
        "Qifeng Chen",
        "Harry Yang",
        "Ser-Nam Lim"
      ],
      "abstract": "Current video generation models excel at short clips but fail to produce\ncohesive multi-shot narratives due to disjointed visual dynamics and fractured\nstorylines. Existing solutions either rely on extensive manual\nscripting/editing or prioritize single-shot fidelity over cross-scene\ncontinuity, limiting their practicality for movie-like content. We introduce\nVideoGen-of-Thought (VGoT), a step-by-step framework that automates multi-shot\nvideo synthesis from a single sentence by systematically addressing three core\nchallenges: (1) Narrative Fragmentation: Existing methods lack structured\nstorytelling. We propose dynamic storyline modeling, which first converts the\nuser prompt into concise shot descriptions, then elaborates them into detailed,\ncinematic specifications across five domains (character dynamics, background\ncontinuity, relationship evolution, camera movements, HDR lighting), ensuring\nlogical narrative progression with self-validation. (2) Visual Inconsistency:\nExisting approaches struggle with maintaining visual consistency across shots.\nOur identity-aware cross-shot propagation generates identity-preserving\nportrait (IPP) tokens that maintain character fidelity while allowing trait\nvariations (expressions, aging) dictated by the storyline. (3) Transition\nArtifacts: Abrupt shot changes disrupt immersion. Our adjacent latent\ntransition mechanisms implement boundary-aware reset strategies that process\nadjacent shots' features at transition points, enabling seamless visual flow\nwhile preserving narrative continuity. VGoT generates multi-shot videos that\noutperform state-of-the-art baselines by 20.4% in within-shot face consistency\nand 17.4% in style consistency, while achieving over 100% better cross-shot\nconsistency and 10x fewer manual adjustments than alternatives.",
      "tldr_zh": "本研究提出 VideoGen-of-Thought (VGoT)，一个逐步框架，用于从单一句子自动生成多镜头视频，旨在解决当前视频模型在叙事连贯性上的局限性，同时最小化手动干预。VGoT 处理三个核心挑战：通过动态故事线建模来克服 Narrative Fragmentation，将用户提示转化为详细的镜头描述并确保逻辑进展；利用 identity-preserving portrait (IPP) tokens 实现 Visual Inconsistency 的跨镜头视觉一致性；以及通过相邻潜在过渡机制消除 Transition Artifacts，确保无缝镜头切换。实验结果显示，VGoT 在单镜头面部一致性上比最先进基线提升 20.4%，风格一致性提升 17.4%，跨镜头一致性提高 100%，并减少 10 倍手动调整，为高效的多镜头视频合成提供了可靠方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/DuNGEOnmassster/VideoGen-of-Thought.git;\n  Webpage: https://cheliosoops.github.io/VGoT/",
      "pdf_url": "http://arxiv.org/pdf/2412.02259v2",
      "published_date": "2024-12-03 08:33:50 UTC",
      "updated_date": "2025-03-20 02:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:20:14.663070"
    },
    {
      "arxiv_id": "2412.02251v3",
      "title": "Selective Reviews of Bandit Problems in AI via a Statistical View",
      "title_zh": "翻译失败",
      "authors": [
        "Pengjie Zhou",
        "Haoyu Wei",
        "Huiming Zhang"
      ],
      "abstract": "Reinforcement Learning (RL) is a widely researched area in artificial\nintelligence that focuses on teaching agents decision-making through\ninteractions with their environment. A key subset includes stochastic\nmulti-armed bandit (MAB) and continuum-armed bandit (SCAB) problems, which\nmodel sequential decision-making under uncertainty. This review outlines the\nfoundational models and assumptions of bandit problems, explores non-asymptotic\ntheoretical tools like concentration inequalities and minimax regret bounds,\nand compares frequentist and Bayesian algorithms for managing\nexploration-exploitation trade-offs. Additionally, we explore K-armed\ncontextual bandits and SCAB, focusing on their methodologies and regret\nanalyses. We also examine the connections between SCAB problems and functional\ndata analysis. Finally, we highlight recent advances and ongoing challenges in\nthe field.",
      "tldr_zh": "这篇综述论文从统计视角审视人工智能(AI)中强化学习(Reinforcement Learning, RL)的多臂老虎机(stochastic multi-armed bandit, MAB)和连续臂老虎机(continuum-armed bandit, SCAB)问题。论文概述了这些问题的基础模型、假设以及非渐近理论工具，如concentration inequalities和minimax regret bounds，并比较了频繁主义和贝叶斯算法在exploration-exploitation trade-offs中的应用。 additionally, it explores K-armed contextual bandits和SCAB的方法、regret analyses，以及SCAB与functional data analysis的联系。最后，论文突出了该领域的最新进展和持续挑战，为研究者提供了一个全面的回顾框架。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "econ.EM",
        "math.PR"
      ],
      "primary_category": "stat.ML",
      "comment": "52 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02251v3",
      "published_date": "2024-12-03 08:28:47 UTC",
      "updated_date": "2025-02-19 18:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:20:25.259236"
    },
    {
      "arxiv_id": "2412.02242v1",
      "title": "U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Fnu Neha",
        "Deepshikha Bhati",
        "Deepak Kumar Shukla",
        "Sonavi Makarand Dalvi",
        "Nikolaos Mantzou",
        "Safa Shubbar"
      ],
      "abstract": "Medical imaging is essential in healthcare to provide key insights into\npatient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive\ntechniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography\n(CT), and Ultrasound (US), capture detailed images of organs, tissues, and\nabnormalities. Effective analysis of these images requires precise segmentation\nto delineate regions of interest (ROI), such as organs or lesions. Traditional\nsegmentation methods, relying on manual feature-extraction, are labor-intensive\nand vary across experts. Recent advancements in Artificial Intelligence (AI)\nand Deep Learning (DL), particularly convolutional models such as U-Net and its\nvariants (U-Net++ and U-Net 3+), have transformed medical image segmentation\n(MIS) by automating the process and enhancing accuracy. These models enable\nefficient, precise pixel-wise classification across various imaging modalities,\novercoming the limitations of manual segmentation. This review explores various\nmedical imaging techniques, examines the U-Net architectures and their\nadaptations, and discusses their application across different modalities. It\nalso identifies common challenges in MIS and proposes potential solutions.",
      "tldr_zh": "这篇综述论文回顾了U-Net及其变体（如U-Net++和U-Net 3+）在医疗图像分割（MIS）中的应用，强调了这些深度学习模型如何通过自动化像素级分类提升分割的准确性和效率。论文讨论了U-Net在不同成像模态（如X-ray、MRI、CT和Ultrasound）中的适应性，解决了传统手动特征提取方法的劳动密集型问题，并分析了常见挑战，如图像变异和噪声。最终，论文提出潜在解决方案，以推动更可靠的医疗图像分析，支持诊断和治疗决策。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02242v1",
      "published_date": "2024-12-03 08:11:06 UTC",
      "updated_date": "2024-12-03 08:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:20:36.590765"
    },
    {
      "arxiv_id": "2412.02237v3",
      "title": "Cross-Attention Head Position Patterns Can Align with Human Visual Concepts in Text-to-Image Generative Models",
      "title_zh": "交叉注意力头位置模式可以在文本",
      "authors": [
        "Jungwon Park",
        "Jungmin Ko",
        "Dongnam Byun",
        "Jangwon Suh",
        "Wonjong Rhee"
      ],
      "abstract": "Recent text-to-image diffusion models leverage cross-attention layers, which\nhave been effectively utilized to enhance a range of visual generative tasks.\nHowever, our understanding of cross-attention layers remains somewhat limited.\nIn this study, we introduce a mechanistic interpretability approach for\ndiffusion models by constructing Head Relevance Vectors (HRVs) that align with\nhuman-specified visual concepts. An HRV for a given visual concept has a length\nequal to the total number of cross-attention heads, with each element\nrepresenting the importance of the corresponding head for the given visual\nconcept. To validate HRVs as interpretable features, we develop an ordered\nweakening analysis that demonstrates their effectiveness. Furthermore, we\npropose concept strengthening and concept adjusting methods and apply them to\nenhance three visual generative tasks. Our results show that HRVs can reduce\nmisinterpretations of polysemous words in image generation, successfully modify\nfive challenging attributes in image editing, and mitigate catastrophic neglect\nin multi-concept generation. Overall, our work provides an advancement in\nunderstanding cross-attention layers and introduces new approaches for\nfine-controlling these layers at the head level.",
      "tldr_zh": "本研究探讨了文本到图像生成模型中的交叉注意力层（cross-attention layers），通过构建Head Relevance Vectors (HRVs)来量化每个注意力头对于人类指定视觉概念的重要性，从而提升模型的可解释性。研究采用ordered weakening analysis验证HRVs的有效性，并提出concept strengthening和concept adjusting方法，用于细粒度控制图像生成过程。结果显示，HRVs能够减少多义词的多义解释、成功修改图像编辑中的五个挑战属性，并缓解多概念生成中的灾难性忽略，为理解和优化交叉注意力层提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02237v3",
      "published_date": "2024-12-03 08:05:56 UTC",
      "updated_date": "2025-02-24 14:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:20:47.346890"
    },
    {
      "arxiv_id": "2412.02228v1",
      "title": "BANER: Boundary-Aware LLMs for Few-Shot Named Entity Recognition",
      "title_zh": "BANER：边界感知 LLMs 用于少样本命名实体识别",
      "authors": [
        "Quanjiang Guo",
        "Yihong Dong",
        "Ling Tian",
        "Zhao Kang",
        "Yu Zhang",
        "Sijie Wang"
      ],
      "abstract": "Despite the recent success of two-stage prototypical networks in few-shot\nnamed entity recognition (NER), challenges such as over/under-detected false\nspans in the span detection stage and unaligned entity prototypes in the type\nclassification stage persist. Additionally, LLMs have not proven to be\neffective few-shot information extractors in general. In this paper, we propose\nan approach called Boundary-Aware LLMs for Few-Shot Named Entity Recognition to\naddress these issues. We introduce a boundary-aware contrastive learning\nstrategy to enhance the LLM's ability to perceive entity boundaries for\ngeneralized entity spans. Additionally, we utilize LoRAHub to align information\nfrom the target domain to the source domain, thereby enhancing adaptive\ncross-domain classification capabilities. Extensive experiments across various\nbenchmarks demonstrate that our framework outperforms prior methods, validating\nits effectiveness. In particular, the proposed strategies demonstrate\neffectiveness across a range of LLM architectures. The code and data are\nreleased on https://github.com/UESTC-GQJ/BANER.",
      "tldr_zh": "该研究提出BANER框架，利用Boundary-Aware LLMs来解决Few-Shot Named Entity Recognition中的挑战，如跨度检测的假跨度和实体原型的未对齐问题。BANER引入Boundary-Aware对比学习策略，以增强LLMs对实体边界的感知能力，并采用LoRAHub对齐源域和目标域的信息，提高跨域分类的适应性。在多种基准上的广泛实验显示，该框架优于现有方法，并在不同LLM架构中表现出色，代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Appear on COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02228v1",
      "published_date": "2024-12-03 07:51:14 UTC",
      "updated_date": "2024-12-03 07:51:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:20:59.669895"
    },
    {
      "arxiv_id": "2412.02222v1",
      "title": "Deep learning approach for predicting the replicator equation in evolutionary game theory",
      "title_zh": "翻译失败",
      "authors": [
        "Advait Chandorkar"
      ],
      "abstract": "This paper presents a physics-informed deep learning approach for predicting\nthe replicator equation, allowing accurate forecasting of population dynamics.\nThis methodological innovation allows us to derive governing differential or\ndifference equations for systems that lack explicit mathematical models. We\nused the SINDy model first introduced by Fasel, Kaiser, Kutz, Brunton, and\nBrunt 2016a to get the replicator equation, which will significantly advance\nour understanding of evolutionary biology, economic systems, and social\ndynamics. By refining predictive models across multiple disciplines, including\necology, social structures, and moral behaviours, our work offers new insights\ninto the complex interplay of variables shaping evolutionary outcomes in\ndynamic systems",
      "tldr_zh": "本文提出了一种基于物理信息的深度学习方法，用于预测进化博弈论中的复制子方程（replicator equation），从而实现对种群动态的准确预测。该方法利用 SINDy 模型从缺乏显式数学模型的系统中推导出治理的微分或差分方程，显著提升了跨学科应用的潜力。研究结果将深化我们对进化生物学、经济系统和社会动态的理解，并在生态、社会结构和道德行为等领域提供新的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02222v1",
      "published_date": "2024-12-03 07:28:52 UTC",
      "updated_date": "2024-12-03 07:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:21:11.966392"
    },
    {
      "arxiv_id": "2412.02220v1",
      "title": "Unlocking Tuning-Free Few-Shot Adaptability in Visual Foundation Models by Recycling Pre-Tuned LoRAs",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Hu",
        "Yongxian Wei",
        "Li Shen",
        "Chun Yuan",
        "Dacheng Tao"
      ],
      "abstract": "Large Language Models (LLMs) such as ChatGPT demonstrate strong few-shot\nadaptability without requiring fine-tuning, positioning them ideal for\ndata-limited and real-time applications. However, this adaptability has not yet\nbeen replicated in current Visual Foundation Models (VFMs), which require\nexplicit fine-tuning with sufficient tuning data. Besides, the\npretraining-finetuning paradigm has led to the surge of numerous task-specific\nmodular components, such as Low-Rank Adaptation (LoRA). For the first time, we\nexplore the potential of reusing diverse pre-tuned LoRAs without accessing\ntheir original training data, to achieve tuning-free few-shot adaptation in\nVFMs. Our framework, LoRA Recycle, distills a meta-LoRA from diverse pre-tuned\nLoRAs with a meta-learning objective, using surrogate data generated inversely\nfrom pre-tuned LoRAs themselves. The VFM, once equipped with the meta-LoRA, is\nempowered to solve new few-shot tasks in a single forward pass, akin to the\nin-context learning of LLMs. Additionally, we incorporate a double-efficient\nmechanism tailored to our framework, significantly accelerating the\nmeta-training process while maintaining or even improving performance.\nExtensive experiments across various few-shot classification benchmarks across\nboth in- and cross-domain scenarios demonstrate the superiority of our\nframework.",
      "tldr_zh": "该研究解决了视觉基础模型（VFMs）在少样本场景下缺乏免微调适应性的问题，相比大型语言模型（LLMs）如ChatGPT。作者提出LoRA Recycle框架，通过重用预训练的Low-Rank Adaptation (LoRA)模块，并使用从这些LoRA反向生成的代理数据，提炼出meta-LoRA，实现VFMs在单次前向传播中的少样本任务处理，类似于LLMs的in-context learning。同时，该框架引入双重高效机制，加速元训练过程。实验在各种少样本分类基准上显示，LoRA Recycle在同域和跨域场景下均表现出优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02220v1",
      "published_date": "2024-12-03 07:25:30 UTC",
      "updated_date": "2024-12-03 07:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:21:24.080244"
    },
    {
      "arxiv_id": "2412.02215v1",
      "title": "Recovering implicit physics model under real-world constraints",
      "title_zh": "在现实世界约束下恢复隐式物理模型",
      "authors": [
        "Ayan Banerjee",
        "Sandeep K. S. Gupta"
      ],
      "abstract": "Recovering a physics-driven model, i.e. a governing set of equations of the\nunderlying dynamical systems, from the real-world data has been of recent\ninterest. Most existing methods either operate on simulation data with\nunrealistically high sampling rates or require explicit measurements of all\nsystem variables, which is not amenable in real-world deployments. Moreover,\nthey assume the timestamps of external perturbations to the physical system are\nknown a priori, without uncertainty, implicitly discounting any sensor\ntime-synchronization or human reporting errors. In this paper, we propose a\nnovel liquid time constant neural network (LTC-NN) based architecture to\nrecover underlying model of physical dynamics from real-world data. The\nautomatic differentiation property of LTC-NN nodes overcomes problems\nassociated with low sampling rates, the input dependent time constant in the\nforward pass of the hidden layer of LTC-NN nodes creates a massive search space\nof implicit physical dynamics, the physics model solver based data\nreconstruction loss guides the search for the correct set of implicit dynamics,\nand the use of the dropout regularization in the dense layer ensures extraction\nof the sparsest model. Further, to account for the perturbation timing error,\nwe utilize dense layer nodes to search through input shifts that results in the\nlowest reconstruction loss. Experiments on four benchmark dynamical systems,\nthree with simulation data and one with the real-world data show that the\nLTC-NN architecture is more accurate in recovering implicit physics model\ncoefficients than the state-of-the-art sparse model recovery approaches. We\nalso introduce four additional case studies (total eight) on real-life medical\nexamples in simulation and with real-world clinical data to show effectiveness\nof our approach in recovering underlying model in practice.",
      "tldr_zh": "这篇论文提出了一种基于液态时间常数神经网络 (LTC-NN) 的新架构，用于从真实世界数据中恢复隐式物理模型，解决了现有方法依赖高采样率数据、需显式测量所有变量以及忽略扰动时间不确定性的问题。LTC-NN 通过自动微分处理低采样率、利用输入依赖时间常数创建隐式动态搜索空间、基于物理模型求解器的重构损失引导模型优化，以及 Dropout 正则化提取稀疏模型，同时搜索输入偏移以校正扰动时间错误。实验在四个基准动态系统（包括模拟和真实数据）上显示，该方法在恢复隐式物理模型系数方面比现有稀疏模型恢复方法更准确，并在八个真实医疗案例研究中证明了其实际有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is published in ECAI 2024,\n  https://ebooks.iospress.nl/volumearticle/69651",
      "pdf_url": "http://arxiv.org/pdf/2412.02215v1",
      "published_date": "2024-12-03 07:11:21 UTC",
      "updated_date": "2024-12-03 07:11:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:21:37.837015"
    },
    {
      "arxiv_id": "2412.02205v3",
      "title": "DataLab: A Unified Platform for LLM-Powered Business Intelligence",
      "title_zh": "DataLab：LLM 驱动的商业智能统一平台",
      "authors": [
        "Luoxuan Weng",
        "Yinghao Tang",
        "Yingchaojie Feng",
        "Zhuo Chang",
        "Ruiqin Chen",
        "Haozhe Feng",
        "Chen Hou",
        "Danqing Huang",
        "Yang Li",
        "Huaming Rao",
        "Haonan Wang",
        "Canshi Wei",
        "Xiaofeng Yang",
        "Yuhui Zhang",
        "Yifeng Zheng",
        "Xiuqi Huang",
        "Minfeng Zhu",
        "Yuxin Ma",
        "Bin Cui",
        "Peng Chen",
        "Wei Chen"
      ],
      "abstract": "Business intelligence (BI) transforms large volumes of data within modern\norganizations into actionable insights for informed decision-making. Recently,\nlarge language model (LLM)-based agents have streamlined the BI workflow by\nautomatically performing task planning, reasoning, and actions in executable\nenvironments based on natural language (NL) queries. However, existing\napproaches primarily focus on individual BI tasks such as NL2SQL and NL2VIS.\nThe fragmentation of tasks across different data roles and tools lead to\ninefficiencies and potential errors due to the iterative and collaborative\nnature of BI. In this paper, we introduce DataLab, a unified BI platform that\nintegrates a one-stop LLM-based agent framework with an augmented computational\nnotebook interface. DataLab supports various BI tasks for different data roles\nin data preparation, analysis, and visualization by seamlessly combining LLM\nassistance with user customization within a single environment. To achieve this\nunification, we design a domain knowledge incorporation module tailored for\nenterprise-specific BI tasks, an inter-agent communication mechanism to\nfacilitate information sharing across the BI workflow, and a cell-based context\nmanagement strategy to enhance context utilization efficiency in BI notebooks.\nExtensive experiments demonstrate that DataLab achieves state-of-the-art\nperformance on various BI tasks across popular research benchmarks. Moreover,\nDataLab maintains high effectiveness and efficiency on real-world datasets from\nTencent, achieving up to a 58.58% increase in accuracy and a 61.65% reduction\nin token cost on enterprise-specific BI tasks.",
      "tldr_zh": "本文提出 DataLab，一种统一的平台，结合 LLM-based 代理框架和增强计算笔记本界面，用于简化商业智能 (BI) 工作流，支持数据准备、分析和可视化等任务。DataLab 通过设计领域知识整合模块、代理间通信机制以及基于单元的上下文管理策略，解决了现有方法如 NL2SQL 和 NL2VIS 的任务碎片化问题，提升了效率和准确性。实验结果显示，DataLab 在流行 BI 基准上达到最先进性能，并在腾讯真实数据集上实现准确率提高高达 58.58% 和令牌成本减少 61.65%。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted to ICDE 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02205v3",
      "published_date": "2024-12-03 06:47:15 UTC",
      "updated_date": "2025-04-07 12:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:21:48.892114"
    },
    {
      "arxiv_id": "2412.02193v3",
      "title": "LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fan-Yun Sun",
        "Weiyu Liu",
        "Siyi Gu",
        "Dylan Lim",
        "Goutam Bhat",
        "Federico Tombari",
        "Manling Li",
        "Nick Haber",
        "Jiajun Wu"
      ],
      "abstract": "Spatial reasoning is a fundamental aspect of human cognition, enabling\nintuitive understanding and manipulation of objects in three-dimensional space.\nWhile foundation models demonstrate remarkable performance on some benchmarks,\nthey still struggle with 3D reasoning tasks like arranging objects in space\naccording to open-ended language instructions, particularly in dense and\nphysically constrained environments. We introduce LayoutVLM, a framework and\nscene layout representation that exploits the semantic knowledge of\nVision-Language Models (VLMs) and supports differentiable optimization to\nensure physical plausibility. LayoutVLM employs VLMs to generate two mutually\nreinforcing representations from visually marked images, and a self-consistent\ndecoding process to improve VLMs spatial planning. Our experiments show that\nLayoutVLM addresses the limitations of existing LLM and constraint-based\napproaches, producing physically plausible 3D layouts better aligned with the\nsemantic intent of input language instructions. We also demonstrate that\nfine-tuning VLMs with the proposed scene layout representation extracted from\nexisting scene datasets can improve their reasoning performance.",
      "tldr_zh": "这篇论文引入了 LayoutVLM 框架，利用 Vision-Language Models (VLMs) 的语义知识，通过可微优化来处理 3D 布局任务，旨在解决现有模型在密集物理环境中根据语言指令排列对象的难题。LayoutVLM 从视觉标记图像生成相互加强的表示，并采用自一致解码过程来提升空间规划的准确性和物理合理性。实验显示，该框架比传统 LLM 和基于约束的方法更有效，能产生与语言指令语义更一致的 3D 布局，并通过微调 VLMs 改善其整体推理性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025, project website:\n  https://ai.stanford.edu/~sunfanyun/layoutvlm/",
      "pdf_url": "http://arxiv.org/pdf/2412.02193v3",
      "published_date": "2024-12-03 06:15:04 UTC",
      "updated_date": "2025-03-11 05:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:22:00.795029"
    },
    {
      "arxiv_id": "2412.02189v1",
      "title": "Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification",
      "title_zh": "机器学习算法在早期遗传疾病和子类分类中的性能比较",
      "authors": [
        "Abu Bakar Siddik",
        "Faisal R. Badal",
        "Afroza Islam"
      ],
      "abstract": "A great deal of effort has been devoted to discovering a particular genetic\ndisorder, but its classification across a broad spectrum of disorder classes\nand types remains elusive. Early diagnosis of genetic disorders enables timely\ninterventions and improves outcomes. This study implements machine learning\nmodels using basic clinical indicators measurable at birth or infancy to enable\ndiagnosis in preliminary life stages. Supervised learning algorithms were\nimplemented on a dataset of 22083 instances with 42 features like family\nhistory, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,\nfeature engineering, and selection were undertaken. Two multi-class classifiers\nwere developed: one for predicting disorder classes (mitochondrial,\nmultifactorial, and single-gene) and one for subtypes (9 disorders).\nPerformance was evaluated using accuracy, precision, recall, and the F1-score.\nThe CatBoost classifier achieved the highest accuracy of 77% for predicting\ngenetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.\nThe study demonstrates the feasibility of using basic clinical data in machine\nlearning models for early categorization and diagnosis across various genetic\ndisorders. Applying ML with basic clinical indicators can enable timely\ninterventions once validated on larger datasets. It is necessary to conduct\nfurther studies to improve model performance on this dataset.",
      "tldr_zh": "该研究比较了各种机器学习算法在早期遗传疾病分类中的性能，使用基本临床指标（如家族史、新生儿指标和实验室测试）来实现初步诊断。基于一个包含22083个实例和42个特征的数据集，论文开发了两个多类分类器：一个用于预测遗传疾病类别（mitochondrial, multifactorial, and single-gene），另一个用于子类型（9个疾病），并通过超参数调整、特征工程和选择来优化模型。评估结果显示，CatBoost分类器在类别预测中达到77%的准确率，而SVM在子类型预测中达到80%的准确率。总体而言，该研究证明了使用简单临床数据进行机器学习诊断的可行性，并建议在更大数据集上进一步验证以提升性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 11 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.02189v1",
      "published_date": "2024-12-03 06:02:47 UTC",
      "updated_date": "2024-12-03 06:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:22:13.982892"
    },
    {
      "arxiv_id": "2412.02186v1",
      "title": "VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Kangsan Kim",
        "Geon Park",
        "Youngwan Lee",
        "Woongyeong Yeo",
        "Sung Ju Hwang"
      ],
      "abstract": "Recent advancements in video large multimodal models (LMMs) have\nsignificantly improved their video understanding and reasoning capabilities.\nHowever, their performance drops on out-of-distribution (OOD) tasks that are\nunderrepresented in training data. Traditional methods like fine-tuning on OOD\ndatasets are impractical due to high computational costs. While In-context\nlearning (ICL) with demonstration examples has shown promising generalization\nperformance in language tasks and image-language tasks without fine-tuning,\napplying ICL to video-language tasks faces challenges due to the limited\ncontext length in Video LMMs, as videos require longer token lengths. To\naddress these issues, we propose VideoICL, a novel video in-context learning\nframework for OOD tasks that introduces a similarity-based relevant example\nselection strategy and a confidence-based iterative inference approach. This\nallows to select the most relevant examples and rank them based on similarity,\nto be used for inference. If the generated response has low confidence, our\nframework selects new examples and performs inference again, iteratively\nrefining the results until a high-confidence response is obtained. This\napproach improves OOD video understanding performance by extending effective\ncontext length without incurring high costs. The experimental results on\nmultiple benchmarks demonstrate significant performance gains, especially in\ndomain-specific scenarios, laying the groundwork for broader video\ncomprehension applications. Code will be released at\nhttps://github.com/KangsanKim07/VideoICL",
      "tldr_zh": "该研究针对视频大型多模态模型（Video LMMs）在处理分布外（OOD）任务时的性能下降问题，提出了一种新型框架VideoICL。该框架采用基于相似度的相关示例选择策略和置信度-based迭代推理方法，通过动态选择示例并反复优化响应，直到获得高置信度输出，从而扩展有效上下文长度而不需微调。实验结果显示，VideoICL在多个基准上显著提升了OOD视频理解性能，尤其在特定领域场景中，为更广泛的视频理解应用奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02186v1",
      "published_date": "2024-12-03 05:54:43 UTC",
      "updated_date": "2024-12-03 05:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:22:24.358940"
    },
    {
      "arxiv_id": "2412.02181v2",
      "title": "Generalizing Weisfeiler-Lehman Kernels to Subgraphs",
      "title_zh": "翻译失败",
      "authors": [
        "Dongkwan Kim",
        "Alice Oh"
      ],
      "abstract": "Subgraph representation learning has been effective in solving various\nreal-world problems. However, current graph neural networks (GNNs) produce\nsuboptimal results for subgraph-level tasks due to their inability to capture\ncomplex interactions within and between subgraphs. To provide a more expressive\nand efficient alternative, we propose WLKS, a Weisfeiler-Lehman (WL) kernel\ngeneralized for subgraphs by applying the WL algorithm on induced $k$-hop\nneighborhoods. We combine kernels across different $k$-hop levels to capture\nricher structural information that is not fully encoded in existing models. Our\napproach can balance expressiveness and efficiency by eliminating the need for\nneighborhood sampling. In experiments on eight real-world and synthetic\nbenchmarks, WLKS significantly outperforms leading approaches on five datasets\nwhile reducing training time, ranging from 0.01x to 0.25x compared to the\nstate-of-the-art.",
      "tldr_zh": "这篇论文针对图神经网络 (GNNs) 在子图级任务中无法有效捕捉子图内部和之间复杂交互的问题，提出了一种泛化 Weisfeiler-Lehman (WL) 内核的方法，名为 WLKS。WLKS 通过在诱导的 k-hop 邻域上应用 WL 算法，并结合不同 k-hop 水平的内核，捕捉更丰富的结构信息，同时实现表达性和效率的平衡，无需邻域采样。在八个真实和合成基准测试中，WLKS 在五个数据集上显著优于领先方法，并将训练时间减少至原先的 0.01x 到 0.25x。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 Camera Ready (15 pages)",
      "pdf_url": "http://arxiv.org/pdf/2412.02181v2",
      "published_date": "2024-12-03 05:35:44 UTC",
      "updated_date": "2025-02-06 07:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:24:30.142981"
    },
    {
      "arxiv_id": "2412.02177v1",
      "title": "Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports",
      "title_zh": "翻译失败",
      "authors": [
        "R. Mahmood",
        "K. C. L. Wong",
        "D. M. Reyes",
        "N. D'Souza",
        "L. Shi",
        "J. Wu",
        "P. Kaviani",
        "M. Kalra",
        "G. Wang",
        "P. Yan",
        "T. Syeda-Mahmood"
      ],
      "abstract": "With the emergence of large-scale vision-language models, realistic radiology\nreports may be generated using only medical images as input guided by simple\nprompts. However, their practical utility has been limited due to the factual\nerrors in their description of findings. In this paper, we propose a novel\nmodel for explainable fact-checking that identifies errors in findings and\ntheir locations indicated through the reports. Specifically, we analyze the\ntypes of errors made by automated reporting methods and derive a new synthetic\ndataset of images paired with real and fake descriptions of findings and their\nlocations from a ground truth dataset. A new multi-label cross-modal\ncontrastive regression network is then trained on this datsaset. We evaluate\nthe resulting fact-checking model and its utility in correcting reports\ngenerated by several SOTA automated reporting tools on a variety of benchmark\ndatasets with results pointing to over 40\\% improvement in report quality\nthrough such error detection and correction.",
      "tldr_zh": "这篇论文针对大型视觉语言模型生成胸部 X 光报告时存在的错误问题，提出了一种基于解剖学基础的可解释事实检查模型，用于识别报告中发现的错误及其位置。研究者首先分析自动报告方法的错误类型，并构建了一个合成数据集，包括真实和虚假描述的图像配对，然后训练一个多标签跨模态对比回归网络（multi-label cross-modal contrastive regression network）来实现错误检测和纠正。实验结果显示，该模型在多个基准数据集上显著提升了报告质量，错误纠正后改善幅度超过40%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02177v1",
      "published_date": "2024-12-03 05:21:42 UTC",
      "updated_date": "2024-12-03 05:21:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:22:48.951615"
    },
    {
      "arxiv_id": "2412.02176v1",
      "title": "Self-Supervised Learning-Based Path Planning and Obstacle Avoidance Using PPO and B-Splines in Unknown Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Shahab Shokouhi",
        "Oguzhan Oruc",
        "May-Win Thein"
      ],
      "abstract": "This paper introduces SmartBSP, an advanced self-supervised learning\nframework for real-time path planning and obstacle avoidance in autonomous\nrobotics navigating through complex environments. The proposed system\nintegrates Proximal Policy Optimization (PPO) with Convolutional Neural\nNetworks (CNN) and Actor-Critic architecture to process limited LIDAR inputs\nand compute spatial decision-making probabilities. The robot's perceptual field\nis discretized into a grid format, which the CNN analyzes to produce a spatial\nprobability distribution. During the training process a nuanced cost function\nis minimized that accounts for path curvature, endpoint proximity, and obstacle\navoidance. Simulations results in different scenarios validate the algorithm's\nresilience and adaptability across diverse operational scenarios. Subsequently,\nReal-time experiments, employing the Robot Operating System (ROS), were carried\nout to assess the efficacy of the proposed algorithm.",
      "tldr_zh": "这篇论文提出了 SmartBSP，一种基于自监督学习的框架，用于自主机器人在未知环境中的实时路径规划和障碍物避让。该框架整合 PPO（Proximal Policy Optimization）、CNN（Convolutional Neural Networks）和 Actor-Critic 架构，来处理有限的 LIDAR 输入并生成空间概率分布。训练过程通过最小化一个考虑路径曲率、终点接近度和障碍物避让的成本函数来优化性能。模拟和实时实验（使用 ROS）证明了算法在不同场景中的韧性和适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02176v1",
      "published_date": "2024-12-03 05:20:29 UTC",
      "updated_date": "2024-12-03 05:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:23:01.992654"
    },
    {
      "arxiv_id": "2412.02173v1",
      "title": "Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models",
      "title_zh": "保持专家参与循环",
      "authors": [
        "Nader Karayanni",
        "Aya Awwad",
        "Chein-Lien Hsiao",
        "Surish P Shanmugam"
      ],
      "abstract": "Since the emergence of Large Language Models (LLMs), the challenge of\neffectively leveraging their potential in healthcare has taken center stage. A\ncritical barrier to using LLMs for extracting insights from unstructured\nclinical notes lies in the prompt engineering process. Despite its pivotal role\nin determining task performance, a clear framework for prompt optimization\nremains absent. Current methods to address this gap take either a manual prompt\nrefinement approach, where domain experts collaborate with prompt engineers to\ncreate an optimal prompt, which is time-intensive and difficult to scale, or\nthrough employing automatic prompt optimizing approaches, where the value of\nthe input of domain experts is not fully realized. To address this, we propose\nStructEase, a novel framework that bridges the gap between automation and the\ninput of human expertise in prompt engineering. A core innovation of the\nframework is SamplEase, an iterative sampling algorithm that identifies\nhigh-value cases where expert feedback drives significant performance\nimprovements. This approach minimizes expert intervention, to effectively\nenhance classification outcomes. This targeted approach reduces labeling\nredundancy, mitigates human error, and enhances classification outcomes. We\nevaluated the performance of StructEase using a dataset of de-identified\nclinical narratives from the US National Electronic Injury Surveillance System\n(NEISS), demonstrating significant gains in classification performance compared\nto current methods. Our findings underscore the value of expert integration in\nLLM workflows, achieving notable improvements in F1 score while maintaining\nminimal expert effort. By combining transparency, flexibility, and scalability,\nStructEase sets the foundation for a framework to integrate expert input into\nLLM workflows in healthcare and beyond.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs) 在医疗领域提取非结构化临床笔记洞见的挑战，提出StructEase框架，以专家指导优化prompt engineering。核心创新是SamplEase算法，该算法通过迭代采样识别高价值案例，最大化专家反馈的作用，同时减少干预和错误。实验在US National Electronic Injury Surveillance System (NEISS) 数据集上评估，显示StructEase显著提升分类性能，F1 score 获得显著改善。总体上，该框架为LLMs 工作流中整合专家输入提供了透明、灵活且可扩展的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02173v1",
      "published_date": "2024-12-03 05:05:13 UTC",
      "updated_date": "2024-12-03 05:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:23:12.590041"
    },
    {
      "arxiv_id": "2412.02172v2",
      "title": "VISCO: Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Xueqing Wu",
        "Yuheng Ding",
        "Bingxuan Li",
        "Pan Lu",
        "Da Yin",
        "Kai-Wei Chang",
        "Nanyun Peng"
      ],
      "abstract": "The ability of large vision-language models (LVLMs) to critique and correct\ntheir reasoning is an essential building block towards their self-improvement.\nHowever, a systematic analysis of such capabilities in LVLMs is still lacking.\nWe propose VISCO, the first benchmark to extensively analyze the fine-grained\ncritique and correction capabilities of LVLMs. Compared to existing work that\nuses a single scalar value to critique the entire reasoning [4], VISCO features\ndense and fine-grained critique, requiring LVLMs to evaluate the correctness of\neach step in the chain-of-thought and provide natural language explanations to\nsupport their judgments. Extensive evaluation of 24 LVLMs demonstrates that\nhuman-written critiques significantly enhance the performance after correction,\nshowcasing the potential of the self-improvement strategy. However, the\nmodel-generated critiques are less helpful and sometimes detrimental to the\nperformance, suggesting that critique is the crucial bottleneck. We identified\nthree common patterns in critique failures: failure to critique visual\nperception, reluctance to \"say no\", and exaggerated assumption of error\npropagation. To address these issues, we propose an effective LookBack strategy\nthat revisits the image to verify each piece of information in the initial\nreasoning. LookBack significantly improves critique and correction performance\nby up to 13.5%.",
      "tldr_zh": "本研究提出 VISCO 基准，用于评估大型视觉语言模型 (LVLMs) 在视觉推理中的细粒度批评和修正能力，强调模型需评估推理链中每个步骤的正确性并提供自然语言解释。实验评估了 24 个 LVLMs，发现人类编写的批评能显著提升修正后的性能，而模型生成的批评往往无效甚至有害，主要瓶颈在于批评过程。论文识别了三种常见失败模式（包括无法批评视觉感知、不愿“说不”和夸大错误传播），并引入 LookBack 策略，通过重新审视图像验证初始推理，提升了批评和修正性能最多 13.5%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. https://visco-benchmark.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.02172v2",
      "published_date": "2024-12-03 05:04:49 UTC",
      "updated_date": "2025-03-18 08:02:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:23:24.661805"
    },
    {
      "arxiv_id": "2412.02166v1",
      "title": "Analyzing the Impact of AI Tools on Student Study Habits and Academic Performance",
      "title_zh": "分析 AI 工具对学生学习习惯和学术表现的影响",
      "authors": [
        "Ben Ward",
        "Deepshikha Bhati",
        "Fnu Neha",
        "Angela Guercio"
      ],
      "abstract": "This study explores the effectiveness of AI tools in enhancing student\nlearning, specifically in improving study habits, time management, and feedback\nmechanisms. The research focuses on how AI tools can support personalized\nlearning, adaptive test adjustments, and provide real-time classroom analysis.\nStudent feedback revealed strong support for these features, and the study\nfound a significant reduction in study hours alongside an increase in GPA,\nsuggesting positive academic outcomes. Despite these benefits, challenges such\nas over-reliance on AI and difficulties in integrating AI with traditional\nteaching methods were also identified, emphasizing the need for AI tools to\ncomplement conventional educational strategies rather than replace them. Data\nwere collected through a survey with a Likert scale and follow-up interviews,\nproviding both quantitative and qualitative insights. The analysis involved\ndescriptive statistics to summarize demographic data, AI usage patterns, and\nperceived effectiveness, as well as inferential statistics (T-tests, ANOVA) to\nexamine the impact of demographic factors on AI adoption. Regression analysis\nidentified predictors of AI adoption, and qualitative responses were\nthematically analyzed to understand students' perspectives on the future of AI\nin education. This mixed-methods approach provided a comprehensive view of AI's\nrole in education and highlighted the importance of privacy, transparency, and\ncontinuous refinement of AI features to maximize their educational benefits.",
      "tldr_zh": "本研究分析了 AI tools 对学生学习习惯和学术表现的影响，重点探讨其在提升个性化学习、时间管理和反馈机制方面的作用。研究采用混合方法，通过 Likert scale 问卷调查和后续访谈，结合描述性统计、T-tests、ANOVA 和回归分析，收集了定量和定性数据。结果显示，AI tools 显著减少了学生学习时间，同时提高了 GPA，并获得了学生积极反馈；然而，也揭示了过度依赖 AI 和与传统教学方法整合的挑战。研究强调，AI 应作为教育策略的补充，并加强隐私、透明度和功能优化的措施，以最大化其益处。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02166v1",
      "published_date": "2024-12-03 04:51:57 UTC",
      "updated_date": "2024-12-03 04:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:23:37.335017"
    },
    {
      "arxiv_id": "2412.02159v1",
      "title": "Jailbreak Defense in a Narrow Domain: Limitations of Existing Methods and a New Transcript-Classifier Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Tony T. Wang",
        "John Hughes",
        "Henry Sleight",
        "Rylan Schaeffer",
        "Rajashree Agrawal",
        "Fazl Barez",
        "Mrinank Sharma",
        "Jesse Mu",
        "Nir Shavit",
        "Ethan Perez"
      ],
      "abstract": "Defending large language models against jailbreaks so that they never engage\nin a broadly-defined set of forbidden behaviors is an open problem. In this\npaper, we investigate the difficulty of jailbreak-defense when we only want to\nforbid a narrowly-defined set of behaviors. As a case study, we focus on\npreventing an LLM from helping a user make a bomb. We find that popular\ndefenses such as safety training, adversarial training, and input/output\nclassifiers are unable to fully solve this problem. In pursuit of a better\nsolution, we develop a transcript-classifier defense which outperforms the\nbaseline defenses we test. However, our classifier defense still fails in some\ncircumstances, which highlights the difficulty of jailbreak-defense even in a\nnarrow domain.",
      "tldr_zh": "该论文探讨了在狭窄领域（如防止LLM帮助用户制作炸弹）中防御jailbreak攻击的挑战，指出现有方法如safety training、adversarial training和input/output classifiers无法完全解决这个问题。研究者提出了一种新颖的transcript-classifier防御方法，通过分析对话记录来提升防御效果，并显示其在测试中优于基线方法。尽管如此，该方法在某些情况下仍会失败，突显了即使在狭窄领域jailbreak防御的复杂性和局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the AdvML-Frontiers and SoLaR workshops at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.02159v1",
      "published_date": "2024-12-03 04:34:58 UTC",
      "updated_date": "2024-12-03 04:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:24:40.561930"
    },
    {
      "arxiv_id": "2412.02155v2",
      "title": "CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojie Yang",
        "Hangli Ge",
        "Jiawei Wang",
        "Zipei Fan",
        "Renhe Jiang",
        "Ryosuke Shibasaki",
        "Noboru Koshizuka"
      ],
      "abstract": "Large-scale human mobility exhibits spatial and temporal patterns that can\nassist policymakers in decision making. Although traditional prediction models\nattempt to capture these patterns, they often interfered by non-periodic public\nevents, such as disasters and occasional celebrations. Since regular human\nmobility patterns are heavily affected by these events, estimating their causal\neffects is critical to accurate mobility predictions. Although news articles\nprovide unique perspectives on these events in an unstructured format,\nprocessing is a challenge. In this study, we propose a causality-augmented\nprediction model, called CausalMob, to analyze the causal effects of public\nevents. We first utilize large language models (LLMs) to extract human\nintentions from news articles and transform them into features that act as\ncausal treatments. Next, the model learns representations of spatio-temporal\nregional covariates from multiple data sources to serve as confounders for\ncausal inference. Finally, we present a causal effect estimation framework to\nensure event features remain independent of confounders during prediction.\nBased on large-scale real-world data, the experimental results show that the\nproposed model excels in human mobility prediction, outperforming\nstate-of-the-art models.",
      "tldr_zh": "该研究针对公共事件（如灾害或庆祝）对人类流动的影响，提出了一种因果增强预测模型CausalMob，以提升预测准确性。模型首先利用大型语言模型(LLMs)从新闻文章中提取人类意图，并将其转化为因果处理特征；同时，从多种数据源学习时空区域协变量作为混杂因素，并构建因果效应估计框架，确保事件特征独立于混杂因素。实验结果显示，在大规模真实数据上，CausalMob 优于最先进模型，证明了其在人类 mobility prediction 中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02155v2",
      "published_date": "2024-12-03 04:29:27 UTC",
      "updated_date": "2025-01-07 06:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:24:52.569849"
    },
    {
      "arxiv_id": "2412.02154v1",
      "title": "Failure Probability Estimation for Black-Box Autonomous Systems using State-Dependent Importance Sampling Proposals",
      "title_zh": "翻译失败",
      "authors": [
        "Harrison Delecki",
        "Sydney M. Katz",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "Estimating the probability of failure is a critical step in developing\nsafety-critical autonomous systems. Direct estimation methods such as Monte\nCarlo sampling are often impractical due to the rarity of failures in these\nsystems. Existing importance sampling approaches do not scale to sequential\ndecision-making systems with large state spaces and long horizons. We propose\nan adaptive importance sampling algorithm to address these limitations. Our\nmethod minimizes the forward Kullback-Leibler divergence between a\nstate-dependent proposal distribution and a relaxed form of the optimal\nimportance sampling distribution. Our method uses Markov score ascent methods\nto estimate this objective. We evaluate our approach on four sequential systems\nand show that it provides more accurate failure probability estimates than\nbaseline Monte Carlo and importance sampling techniques. This work is open\nsourced.",
      "tldr_zh": "这篇论文针对黑盒自主系统的故障概率估计问题，提出了一种自适应重要性采样算法，以解决传统Monte Carlo sampling方法在稀有故障事件中的低效性，以及现有importance sampling方法在大型状态空间和长时序决策系统中的局限性。该算法通过最小化状态依赖的提议分布与松弛的最优importance sampling分布之间的forward Kullback-Leibler divergence，并采用Markov score ascent方法进行优化，从而提升估计准确性。在四个顺序决策系统中实验验证，该方法比基线技术更精确，并已开源以促进进一步应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to L4DC 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02154v1",
      "published_date": "2024-12-03 04:28:58 UTC",
      "updated_date": "2024-12-03 04:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:25:04.877977"
    },
    {
      "arxiv_id": "2412.02153v2",
      "title": "Revisiting the Initial Steps in Adaptive Gradient Descent Optimization",
      "title_zh": "重新审视自适应梯度下降优化的初始步骤",
      "authors": [
        "Abulikemu Abuduweili",
        "Changliu Liu"
      ],
      "abstract": "Adaptive gradient optimization methods, such as Adam, are prevalent in\ntraining deep neural networks across diverse machine learning tasks due to\ntheir ability to achieve faster convergence. However, these methods often\nsuffer from suboptimal generalization compared to stochastic gradient descent\n(SGD) and exhibit instability, particularly when training Transformer models.\nIn this work, we show the standard initialization of the second-order moment\nestimation ($v_0 =0$) as a significant factor contributing to these\nlimitations. We introduce simple yet effective solutions: initializing the\nsecond-order moment estimation with non-zero values, using either data-driven\nor random initialization strategies. Empirical evaluations demonstrate that our\napproach not only stabilizes convergence but also enhances the final\nperformance of adaptive gradient optimizers. Furthermore, by adopting the\nproposed initialization strategies, Adam achieves performance comparable to\nmany recently proposed variants of adaptive gradient optimization methods. Our\ncode is available at https://github.com/Walleclipse/Adam_Initialization.",
      "tldr_zh": "本研究重新审视了自适应梯度下降优化方法（如 Adam）的初始步骤，发现标准初始化（second-order moment estimation 的 v_0 = 0）是导致泛化性能不如 SGD 和训练不稳定（尤其在 Transformer 模型上）的主要因素。作者提出简单有效的解决方案：采用非零值初始化策略，包括数据驱动或随机方法，来改善 second-order moment estimation。实验结果显示，这种方法显著稳定了收敛过程，提升了 Adam 的最终性能，并使其表现可与最近的自适应梯度优化变体相当。代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Conference on Parsimony and Learning (CPAL) 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02153v2",
      "published_date": "2024-12-03 04:28:14 UTC",
      "updated_date": "2025-02-11 16:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:25:16.543229"
    },
    {
      "arxiv_id": "2412.02148v1",
      "title": "Mining Tweets to Predict Future Bitcoin Price",
      "title_zh": "翻译失败",
      "authors": [
        "Ashutosh Hathidara",
        "Gaurav Atavale",
        "Suyash Chaudhary"
      ],
      "abstract": "Bitcoin has increased investment interests in people during the last decade.\nWe have seen an increase in the number of posts on social media platforms about\ncryptocurrency, especially Bitcoin. This project focuses on analyzing user\ntweet data in combination with Bitcoin price data to see the relevance between\nprice fluctuations and the conversation between millions of people on Twitter.\nThis study also exploits this relationship between user tweets and bitcoin\nprices to predict the future bitcoin price. We are utilizing novel techniques\nand methods to analyze the data and make price predictions.",
      "tldr_zh": "这篇论文探讨了Twitter推文与Bitcoin价格波动之间的相关性，旨在通过分析用户推文数据和Bitcoin价格数据来预测未来价格。研究利用新颖的技术和方法，结合社交媒体对话与价格历史数据进行相关性分析。结果表明，这种方法能有效捕捉公众情绪对Bitcoin市场的影响，为价格预测提供新的洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02148v1",
      "published_date": "2024-12-03 04:09:19 UTC",
      "updated_date": "2024-12-03 04:09:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:25:28.576907"
    },
    {
      "arxiv_id": "2412.02142v1",
      "title": "Personalized Multimodal Large Language Models: A Survey",
      "title_zh": "个性化的多模态大语言模型：一个综述",
      "authors": [
        "Junda Wu",
        "Hanjia Lyu",
        "Yu Xia",
        "Zhehao Zhang",
        "Joe Barrow",
        "Ishita Kumar",
        "Mehrnoosh Mirtaheri",
        "Hongjie Chen",
        "Ryan A. Rossi",
        "Franck Dernoncourt",
        "Tong Yu",
        "Ruiyi Zhang",
        "Jiuxiang Gu",
        "Nesreen K. Ahmed",
        "Yu Wang",
        "Xiang Chen",
        "Hanieh Deilamsalehy",
        "Namyong Park",
        "Sungchul Kim",
        "Huanrui Yang",
        "Subrata Mitra",
        "Zhengmian Hu",
        "Nedim Lipka",
        "Dang Nguyen",
        "Yue Zhao",
        "Jiebo Luo",
        "Julian McAuley"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have become increasingly important\ndue to their state-of-the-art performance and ability to integrate multiple\ndata modalities, such as text, images, and audio, to perform complex tasks with\nhigh accuracy. This paper presents a comprehensive survey on personalized\nmultimodal large language models, focusing on their architecture, training\nmethods, and applications. We propose an intuitive taxonomy for categorizing\nthe techniques used to personalize MLLMs to individual users, and discuss the\ntechniques accordingly. Furthermore, we discuss how such techniques can be\ncombined or adapted when appropriate, highlighting their advantages and\nunderlying rationale. We also provide a succinct summary of personalization\ntasks investigated in existing research, along with the evaluation metrics\ncommonly used. Additionally, we summarize the datasets that are useful for\nbenchmarking personalized MLLMs. Finally, we outline critical open challenges.\nThis survey aims to serve as a valuable resource for researchers and\npractitioners seeking to understand and advance the development of personalized\nmultimodal large language models.",
      "tldr_zh": "这篇论文对个性化 Multimodal Large Language Models (MLLMs) 进行了全面调查，涵盖了其架构、训练方法和应用。作者提出了一种直观的分类法来归类个性化技术，并讨论了这些技术的组合、适应方式及其优势。论文总结了现有研究中的个性化任务、常用评估指标、基准数据集，并指出了关键的开放挑战，为研究者和从业者提供了一个宝贵的资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02142v1",
      "published_date": "2024-12-03 03:59:03 UTC",
      "updated_date": "2024-12-03 03:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:25:40.473017"
    },
    {
      "arxiv_id": "2412.02136v1",
      "title": "Graph Learning for Planning: The Story Thus Far and Open Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Dillon Z. Chen",
        "Mingyu Hao",
        "Sylvie Thiébaux",
        "Felipe Trevizan"
      ],
      "abstract": "Graph learning is naturally well suited for use in planning due to its\nability to exploit relational structures exhibited in planning domains and to\ntake as input planning instances with arbitrary number of objects. In this\npaper, we study the usage of graph learning for planning thus far by studying\nthe theoretical and empirical effects on learning and planning performance of\n(1) graph representations of planning tasks, (2) graph learning architectures,\nand (3) optimisation formulations for learning. Our studies accumulate in the\nGOOSE framework which learns domain knowledge from small planning tasks in\norder to scale up to much larger planning tasks. In this paper, we also\nhighlight and propose the 5 open challenges in the general Learning for\nPlanning field that we believe need to be addressed for advancing the\nstate-of-the-art.",
      "tldr_zh": "这篇论文回顾了图学习(Graph Learning)在规划(Planning)中的应用，强调其利用关系结构和处理任意对象实例的优势。通过研究图表示、图学习架构以及优化公式对学习和规划性能的理论及经验影响，论文提出了GOOSE框架，该框架从小型规划任务中学习领域知识，以扩展到更大规模的任务。最终，论文突出了5个关键开放挑战，旨在推动Learning for Planning领域的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02136v1",
      "published_date": "2024-12-03 03:49:27 UTC",
      "updated_date": "2024-12-03 03:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:25:52.239161"
    },
    {
      "arxiv_id": "2412.02130v1",
      "title": "A privacy-preserving distributed credible evidence fusion algorithm for collective decision-making",
      "title_zh": "一种隐私保护的分布式可信证据融合算法，用于集体决策",
      "authors": [
        "Chaoxiong Ma",
        "Yan Liang",
        "Xinyu Yang",
        "Han Wu",
        "Huixia Zhang"
      ],
      "abstract": "The theory of evidence reasoning has been applied to collective\ndecision-making in recent years. However, existing distributed evidence fusion\nmethods lead to participants' preference leakage and fusion failures as they\ndirectly exchange raw evidence and do not assess evidence credibility like\ncentralized credible evidence fusion (CCEF) does. To do so, a\nprivacy-preserving distributed credible evidence fusion method with three-level\nconsensus (PCEF) is proposed in this paper. In evidence difference measure\n(EDM) neighbor consensus, an evidence-free equivalent expression of EDM among\nneighbored agents is derived with the shared dot product protocol for pignistic\nprobability and the identical judgment of two events with maximal subjective\nprobabilities, so that evidence privacy is guaranteed due to such irreversible\nevidence transformation. In EDM network consensus, the non-neighbored EDMs are\ninferred and neighbored EDMs reach uniformity via interaction between linear\naverage consensus (LAC) and low-rank matrix completion with rank adaptation to\nguarantee EDM consensus convergence and no solution of inferring raw evidence\nin numerical iteration style. In fusion network consensus, a privacy-preserving\nLAC with a self-cancelling differential privacy term is proposed, where each\nagent adds its randomness to the sharing content and step-by-step cancels such\nrandomness in consensus iterations. Besides, the sufficient condition of the\nconvergence to the CCEF is explored, and it is proven that raw evidence is\nimpossibly inferred in such an iterative consensus. The simulations show that\nPCEF is close to CCEF both in credibility and fusion results and obtains higher\ndecision accuracy with less time-comsuming than existing methods.",
      "tldr_zh": "该论文提出了一种隐私保护的分布式可信证据融合算法（PCEF），旨在解决现有分布式证据融合方法在集体决策中存在的偏好泄露和融合失败问题，与集中式可信证据融合（CCEF）类似但注重隐私。PCEF 通过三层共识机制实现：首先，在证据差异测量（EDM）邻居共识中，使用共享点积协议和最大主观概率判断推导出等效表达式，确保证据隐私；其次，在 EDM 网络共识中，通过线性平均共识（LAC）和低秩矩阵完成推断非邻居 EDM 并实现共识收敛；最后，在融合网络共识中，引入带有自取消差分隐私项的 LAC，使代理在迭代中添加并取消随机性。实验结果表明，PCEF 在可信度和融合效果上接近 CCEF，同时比现有方法提供更高的决策准确性和更低的计算开销。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02130v1",
      "published_date": "2024-12-03 03:36:42 UTC",
      "updated_date": "2024-12-03 03:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:26:06.877854"
    },
    {
      "arxiv_id": "2412.02126v1",
      "title": "Benchmarking symbolic regression constant optimization schemes",
      "title_zh": "符号回归常量优化方案的基准测试",
      "authors": [
        "L. G. A dos Reis",
        "V. L. P. S. Caminha",
        "T. J. P. Penna"
      ],
      "abstract": "Symbolic regression is a machine learning technique, and it has seen many\nadvancements in recent years, especially in genetic programming approaches\n(GPSR). Furthermore, it has been known for many years that constant\noptimization of parameters, during the evolutionary search, greatly increases\nGPSR performance However, different authors approach such tasks differently and\nno consensus exists regarding which methods perform best. In this work, we\nevaluate eight different parameter optimization methods, applied during\nevolutionary search, over ten known benchmark problems, in two different\nscenarios. We also propose using an under-explored metric called Tree Edit\nDistance (TED), aiming to identify symbolic accuracy. In conjunction with\nclassical error measures, we develop a combined analysis of model performance\nin symbolic regression. We then show that different constant optimization\nmethods perform better in certain scenarios and that there is no overall best\nchoice for every problem. Finally, we discuss how common metric decisions may\nbe biased and appear to generate better models in comparison.",
      "tldr_zh": "本研究对符号回归(Symbolic Regression)中的常数优化方案进行了基准测试(Benchmarking)，评估了八种参数优化方法在十个已知基准问题和两种场景下的表现。作者引入了未被充分探索的指标Tree Edit Distance (TED)，并结合经典错误测量，开发了一种综合分析模型性能的方法。结果显示，不同优化方法在特定场景下更具优势，并不存在适用于所有问题的最佳选择；此外，常见指标决策可能存在偏差，导致模型表现被高估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 10 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.02126v1",
      "published_date": "2024-12-03 03:29:27 UTC",
      "updated_date": "2024-12-03 03:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:26:16.919813"
    },
    {
      "arxiv_id": "2412.02125v1",
      "title": "Optimizing Latent Goal by Learning from Trajectory Preference",
      "title_zh": "翻译失败",
      "authors": [
        "Guangyu Zhao",
        "Kewei Lian",
        "Haowei Lin",
        "Haobo Fu",
        "Qiang Fu",
        "Shaofei Cai",
        "Zihao Wang",
        "Yitao Liang"
      ],
      "abstract": "A glowing body of work has emerged focusing on instruction-following policies\nfor open-world agents, aiming to better align the agent's behavior with human\nintentions. However, the performance of these policies is highly susceptible to\nthe initial prompt, which leads to extra efforts in selecting the best\ninstructions. We propose a framework named Preference Goal Tuning (PGT). PGT\nallows an instruction following policy to interact with the environment to\ncollect several trajectories, which will be categorized into positive and\nnegative samples based on preference. Then we use preference learning to\nfine-tune the initial goal latent representation with the categorized\ntrajectories while keeping the policy backbone frozen. The experiment result\nshows that with minimal data and training, PGT achieves an average relative\nimprovement of 72.0% and 81.6% over 17 tasks in 2 different foundation policies\nrespectively, and outperforms the best human-selected instructions. Moreover,\nPGT surpasses full fine-tuning in the out-of-distribution (OOD) task-execution\nenvironments by 13.4%, indicating that our approach retains strong\ngeneralization capabilities. Since our approach stores a single latent\nrepresentation for each task independently, it can be viewed as an efficient\nmethod for continual learning, without the risk of catastrophic forgetting or\ntask interference. In short, PGT enhances the performance of agents across\nnearly all tasks in the Minecraft Skillforge benchmark and demonstrates\nrobustness to the execution environment.",
      "tldr_zh": "本研究提出了一种名为 Preference Goal Tuning (PGT) 的框架，用于优化开放世界代理的指令跟随策略，以更好地适应人类意图。该框架让代理与环境互动收集轨迹，并基于偏好将轨迹分类为正负样本，然后通过偏好学习微调初始目标潜在表示(latent representation)，同时冻结策略骨干以保持泛化能力。实验结果显示，PGT 在 Minecraft Skillforge 基准的 17 个任务上，分别比两种基础策略提升了 72.0% 和 81.6%，并在 out-of-distribution (OOD) 任务环境中超越全微调方法 13.4%，同时作为一种高效的 continual learning 方法，避免了灾难性遗忘和任务干扰。总体而言，PGT 显著提升了代理的性能和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02125v1",
      "published_date": "2024-12-03 03:27:48 UTC",
      "updated_date": "2024-12-03 03:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:26:28.889109"
    },
    {
      "arxiv_id": "2412.02114v2",
      "title": "Beyond Generation: Unlocking Universal Editing via Self-Supervised Fine-Tuning",
      "title_zh": "超越生成：通过自监督微调解锁通用编辑",
      "authors": [
        "Harold Haodong Chen",
        "Harry Yang",
        "Ser-Nam Lim"
      ],
      "abstract": "Recent advances in video generation have outpaced progress in video editing,\nwhich remains constrained by several limiting factors, namely: (a) the task's\ndependency on supervision severely limits generality, (b) an unnecessary\nartificial separation between the generation and editing task, and (c) the high\ncomputational costs of training a video model. In this work, we propose UES\n(Unlocking Universal Editing via Self-Supervision), a lightweight\nself-supervised fine-tuning strategy that transforms generation models into\nunified generation-editing systems through self-supervised semantic alignment.\nOur approach establishes a dual-conditioning mechanism where original\nvideo-text pairs jointly provide visual and textual semantics, enabling\nstructured learning of intrinsic spatiotemporal correspondences. Key advantages\ninclude: (i) Universality through supervision-free adaptation to diverse\nediting tasks, (ii) Unification of generation and editing applicable to most\ntext(+image)-to-video model, and (iii) Efficiency via lightweight fine-tune\nthat reduces tunable parameters by 92.67%. To enable systematic evaluation, we\nintroduce OmniBench-99, a comprehensive benchmark spanning 99 videos across\nhumans/animals, environments, and objects, comprising 4 editing types and 8\nscenarios. Extensive experiments show UES enables models without inherent\nediting capability to perform powerful and universal editing while preserving\nor even enhancing their original generation performance.",
      "tldr_zh": "该论文指出了视频编辑领域受限于监督依赖、任务分离和高计算成本的问题，并提出UES（Unlocking Universal Editing via Self-Supervision）方法，通过自监督微调将生成模型转化为统一的生成-编辑系统。UES采用双条件机制，利用原始视频-文本对进行语义对齐，学习内在的时空对应，从而实现无监督适应多样编辑任务。关键优势包括通用性、可应用于大多数text-to-video模型，以及减少可调参数92.67%的效率。实验在OmniBench-99基准上验证，UES使模型获得强大的编辑能力，同时保持或提升原生成性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project: https://haroldchen19.github.io/UES-Page/",
      "pdf_url": "http://arxiv.org/pdf/2412.02114v2",
      "published_date": "2024-12-03 03:10:19 UTC",
      "updated_date": "2025-03-18 10:51:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:26:40.919680"
    },
    {
      "arxiv_id": "2412.02113v1",
      "title": "Trust & Safety of LLMs and LLMs in Trust & Safety",
      "title_zh": "LLMs",
      "authors": [
        "Doohee You",
        "Dan Chon"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have garnered considerable\nattention for their remarkable abilities in natural language processing tasks.\nHowever, their widespread adoption has raised concerns pertaining to trust and\nsafety. This systematic review investigates the current research landscape on\ntrust and safety in LLMs, with a particular focus on the novel application of\nLLMs within the field of Trust and Safety itself. We delve into the\ncomplexities of utilizing LLMs in domains where maintaining trust and safety is\nparamount, offering a consolidated perspective on this emerging trend.\\\n  By synthesizing findings from various studies, we identify key challenges and\npotential solutions, aiming to benefit researchers and practitioners seeking to\nunderstand the nuanced interplay between LLMs and Trust and Safety.\n  This review provides insights on best practices for using LLMs in Trust and\nSafety, and explores emerging risks such as prompt injection and jailbreak\nattacks. Ultimately, this study contributes to a deeper understanding of how\nLLMs can be effectively and responsibly utilized to enhance trust and safety in\nthe digital realm.",
      "tldr_zh": "这篇系统综述探讨了大型语言模型（LLMs）的信任和安全问题，以及LLMs在信任和安全领域的新兴应用。通过综合现有研究，该文识别了关键挑战，如提示注入（prompt injection）和越狱攻击（jailbreak attacks），并提出了潜在解决方案和最佳实践。最终，该研究为研究者和从业者提供了如何有效、负责任地利用LLMs提升数字领域信任和安全的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.02113v1",
      "published_date": "2024-12-03 03:10:12 UTC",
      "updated_date": "2024-12-03 03:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:28:46.476900"
    },
    {
      "arxiv_id": "2412.04503v1",
      "title": "A Primer on Large Language Models and their Limitations",
      "title_zh": "大型语言模型及其限制的入门指南",
      "authors": [
        "Sandra Johnson",
        "David Hyland-Wood"
      ],
      "abstract": "This paper provides a primer on Large Language Models (LLMs) and identifies\ntheir strengths, limitations, applications and research directions. It is\nintended to be useful to those in academia and industry who are interested in\ngaining an understanding of the key LLM concepts and technologies, and in\nutilising this knowledge in both day to day tasks and in more complex scenarios\nwhere this technology can enhance current practices and processes.",
      "tldr_zh": "这篇论文作为大型语言模型(LLMs)的入门指南，概述了LLMs的优势、局限性、应用以及未来的研究方向，旨在帮助学术和行业从业者快速掌握核心概念和技术。论文重点讨论了LLMs在日常任务和复杂场景中的实际利用潜力，例如提升现有实践和流程。总体而言，它为读者提供了实用知识基础，促进LLMs在各种领域的有效应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50"
      ],
      "primary_category": "cs.CL",
      "comment": "33 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.04503v1",
      "published_date": "2024-12-03 02:45:02 UTC",
      "updated_date": "2024-12-03 02:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:27:03.799135"
    },
    {
      "arxiv_id": "2412.02099v1",
      "title": "AccDiffusion v2: Towards More Accurate Higher-Resolution Diffusion Extrapolation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihang Lin",
        "Mingbao Lin",
        "Wengyi Zhan",
        "Rongrong Ji"
      ],
      "abstract": "Diffusion models suffer severe object repetition and local distortion when\nthe inference resolution differs from its pre-trained resolution. We propose\nAccDiffusion v2, an accurate method for patch-wise higher-resolution diffusion\nextrapolation without training. Our in-depth analysis in this paper shows that\nusing an identical text prompt for different patches leads to repetitive\ngeneration, while the absence of a prompt undermines image details. In\nresponse, our AccDiffusion v2 novelly decouples the vanilla image-content-aware\nprompt into a set of patch-content-aware prompts, each of which serves as a\nmore precise description of a patch. Further analysis reveals that local\ndistortion arises from inaccurate descriptions in prompts about the local\nstructure of higher-resolution images. To address this issue, AccDiffusion v2,\nfor the first time, introduces an auxiliary local structural information\nthrough ControlNet during higher-resolution diffusion extrapolation aiming to\nmitigate the local distortions. Finally, our analysis indicates that global\nsemantic information is conducive to suppressing both repetitive generation and\nlocal distortion. Hence, our AccDiffusion v2 further proposes dilated sampling\nwith window interaction for better global semantic information during\nhigher-resolution diffusion extrapolation. We conduct extensive experiments,\nincluding both quantitative and qualitative comparisons, to demonstrate the\nefficacy of our AccDiffusion v2. The quantitative comparison shows that\nAccDiffusion v2 achieves state-of-the-art performance in image generation\nextrapolation without training. The qualitative comparison intuitively\nillustrates that AccDiffusion v2 effectively suppresses the issues of\nrepetitive generation and local distortion in image generation extrapolation.\nOur code is available at \\url{https://github.com/lzhxmu/AccDiffusion_v2}.",
      "tldr_zh": "本文提出AccDiffusion v2，一种无需训练的补丁式更高分辨率扩散外推方法，针对扩散模型在推理分辨率与预训练分辨率不匹配时出现对象重复和局部扭曲的问题。核心创新包括将图像内容感知提示解耦为补丁内容感知提示以提高描述精度、首次引入ControlNet提供辅助局部结构信息，以及采用膨胀采样(dilated sampling)与窗口交互增强全局语义信息。实验结果显示，AccDiffusion v2在定量和定性比较中达到最先进性能，有效抑制了重复生成和局部扭曲现象。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages. arXiv admin note: text overlap with arXiv:2407.10738",
      "pdf_url": "http://arxiv.org/pdf/2412.02099v1",
      "published_date": "2024-12-03 02:44:35 UTC",
      "updated_date": "2024-12-03 02:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:27:18.133218"
    },
    {
      "arxiv_id": "2412.02091v2",
      "title": "The Problem of Social Cost in Multi-Agent General Reinforcement Learning: Survey and Synthesis",
      "title_zh": "多智能体通用强化学习中的社会成本问题：调查和综合",
      "authors": [
        "Kee Siong Ng",
        "Samuel Yang-Zhao",
        "Timothy Cadogan-Cowper"
      ],
      "abstract": "The AI safety literature is full of examples of powerful AI agents that, in\nblindly pursuing a specific and usually narrow objective, ends up with\nunacceptable and even catastrophic collateral damage to others. In this paper,\nwe consider the problem of social harms that can result from actions taken by\nlearning and utility-maximising agents in a multi-agent environment. The\nproblem of measuring social harms or impacts in such multi-agent settings,\nespecially when the agents are artificial generally intelligent (AGI) agents,\nwas listed as an open problem in Everitt et al, 2018. We attempt a partial\nanswer to that open problem in the form of market-based mechanisms to quantify\nand control the cost of such social harms. The proposed setup captures many\nwell-studied special cases and is more general than existing formulations of\nmulti-agent reinforcement learning with mechanism design in two ways: (i) the\nunderlying environment is a history-based general reinforcement learning\nenvironment like in AIXI; (ii) the reinforcement-learning agents participating\nin the environment can have different learning strategies and planning\nhorizons. To demonstrate the practicality of the proposed setup, we survey some\nkey classes of learning algorithms and present a few applications, including a\ndiscussion of the Paperclips problem and pollution control with a cap-and-trade\nsystem.",
      "tldr_zh": "该论文探讨了在多代理一般强化学习(Multi-Agent General Reinforcement Learning)环境中，AI 代理追求特定目标可能导致社会伤害的问题，并针对这一问题提出基于市场机制的框架来量化和控制这些成本。相比现有方法，该框架更通用，支持历史-based 一般强化学习环境（如 AIXI）和代理间的不同学习策略及规划视野。论文通过调研关键学习算法类和讨论实际应用，如 Paperclips 问题和污染控制的 cap-and-trade 系统，展示了其实用性和潜在影响。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.MA",
        "I.2.11"
      ],
      "primary_category": "cs.AI",
      "comment": "67 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.02091v2",
      "published_date": "2024-12-03 02:22:55 UTC",
      "updated_date": "2025-04-13 01:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:27:28.846817"
    },
    {
      "arxiv_id": "2412.02085v1",
      "title": "Evolution of Collective AI Beyond Individual Optimization",
      "title_zh": "集体 AI 的演化超越个体优化",
      "authors": [
        "Ryosuke Takata",
        "Yujin Tang",
        "Yingtao Tian",
        "Norihiro Maruyama",
        "Hiroki Kojima",
        "Takashi Ikegami"
      ],
      "abstract": "This study investigates collective behaviors that emerge from a group of\nhomogeneous individuals optimized for a specific capability. We created a group\nof simple, identical neural network based agents modeled after\nchemotaxis-driven vehicles that follow pheromone trails and examined\nmulti-agent simulations using clones of these evolved individuals. Our results\nshow that the evolution of individuals led to population differentiation.\nSurprisingly, we observed that collective fitness significantly changed during\nlater evolutionary stages, despite maintained high individual performance and\nsimplified neural architectures. This decline occurred when agents developed\nreduced sensor-motor coupling, suggesting that over-optimization of individual\nagents almost always lead to less effective group behavior. Our research\ninvestigates how individual differentiation can evolve through what\nevolutionary pathways.",
      "tldr_zh": "本研究探讨了从一群同质个体优化特定能力中出现的集体行为，创建了基于neural network的简单代理，模仿chemotaxis驱动的车辆并遵循pheromone trails，通过multi-agent simulations对这些进化的个体克隆进行测试。结果显示，个体的进化导致了population differentiation，尽管个体性能保持高水平和neural architectures简化，但collective fitness在进化后期显著下降。研究发现，这种下降与agents减少的sensor-motor coupling有关，表明过度优化个体代理几乎总是导致群体行为不佳，并探讨了个体分化通过哪些evolutionary pathways发展。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02085v1",
      "published_date": "2024-12-03 02:03:36 UTC",
      "updated_date": "2024-12-03 02:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:27:40.557919"
    },
    {
      "arxiv_id": "2412.02084v1",
      "title": "Comparative Analysis of Black-Box and White-Box Machine Learning Model in Phishing Detection",
      "title_zh": "黑箱和白箱机器学习模型在网络钓鱼检测中的比较分析",
      "authors": [
        "Abdullah Fajar",
        "Setiadi Yazid",
        "Indra Budi"
      ],
      "abstract": "Background: Explainability in phishing detection model can support a further\nsolution of phishing attack mitigation by increasing trust and understanding\nhow phishing can be detected. Objective: The aims of this study to determine\nand best recommendation to apply an approach which has several components with\nabilities to fulfil the critical needs Methods: A methodology starting with\nanalyzing both black-box and white-box models to get the pros and cons\nspecifically in phishing detection. The conclusion of the analysis will be\nvalidated by experiment using a set of well-known algorithms and public\nphishing datasets. Experimental metrics covers 3 measurements such as\npredictive accuracy and explainability metrics. Conclusion: Both models are\ncomparable in terms of interpretability and consistency, with room for\nimprovement in diverse datasets. EBM as an example of white-box model is\ngenerally better suited for applications requiring explainability and\nactionable insights. Finally, each model, white-box and black-box model has\npositive and negative aspects both for performance metric and for explainable\nmetric. It is important to consider the objective of model usage.",
      "tldr_zh": "本研究比较了Black-Box和White-Box机器学习模型在Phishing Detection中的性能，旨在通过提升模型的可解释性来增强钓鱼攻击的缓解策略。研究方法包括分析两种模型的优缺点，并通过实验使用知名算法和公共数据集进行验证，评估指标涵盖预测准确性、可解释性和一致性。结果显示，两者可解释性和一致性相当，但White-Box模型如EBM更适合需要行动性洞察的应用，最终推荐根据模型使用目标选择合适类型，以平衡性能和解释性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02084v1",
      "published_date": "2024-12-03 02:00:47 UTC",
      "updated_date": "2024-12-03 02:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:27:52.968842"
    },
    {
      "arxiv_id": "2412.02083v2",
      "title": "Implementing An Artificial Quantum Perceptron",
      "title_zh": "翻译失败",
      "authors": [
        "Ashutosh Hathidara",
        "Lalit Pandey"
      ],
      "abstract": "A Perceptron is a fundamental building block of a neural network. The\nflexibility and scalability of perceptron make it ubiquitous in building\nintelligent systems. Studies have shown the efficacy of a single neuron in\nmaking intelligent decisions. Here, we examined and compared two perceptrons\nwith distinct mechanisms, and developed a quantum version of one of those\nperceptrons. As a part of this modeling, we implemented the quantum circuit for\nan artificial perception, generated a dataset, and simulated the training.\nThrough these experiments, we show that there is an exponential growth\nadvantage and test different qubit versions. Our findings show that this\nquantum model of an individual perceptron can be used as a pattern classifier.\nFor the second type of model, we provide an understanding to design and\nsimulate a spike-dependent quantum perceptron. Our code is available at\nhttps://github.com/ashutosh1919/quantum-perceptron",
      "tldr_zh": "这篇论文实现了人工量子 Perceptron，通过比较两种不同机制的 Perceptron，开发了其量子版本作为神经网络的基本构建块。研究者构建了量子电路，生成数据集并模拟训练，展示了量子模型在模式分类中的指数级增长优势，并测试了不同量子比特版本。对于第二种模型，他们提供了设计和模拟基于尖峰的量子 Perceptron 的方法，并公开了代码以供进一步验证。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02083v2",
      "published_date": "2024-12-03 01:57:09 UTC",
      "updated_date": "2025-03-24 14:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:28:04.365889"
    },
    {
      "arxiv_id": "2412.02065v1",
      "title": "Leveraging Large Language Models to Democratize Access to Costly Financial Datasets for Academic Research",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Junyan Wang",
        "Victor Xiaoqi Wang"
      ],
      "abstract": "Unequal access to costly datasets essential for empirical research has long\nhindered researchers from disadvantaged institutions, limiting their ability to\ncontribute to their fields and advance their careers. Recent breakthroughs in\nLarge Language Models (LLMs) have the potential to democratize data access by\nautomating data collection from unstructured sources. We develop and evaluate a\nnovel methodology using GPT-4o-mini within a Retrieval-Augmented Generation\n(RAG) framework to collect data from corporate disclosures. Our approach\nachieves human-level accuracy in collecting CEO pay ratios from approximately\n10,000 proxy statements and Critical Audit Matters (CAMs) from more than 12,000\n10-K filings, with LLM processing times of 9 and 40 minutes respectively, each\nat a cost under $10. This stands in stark contrast to the hundreds of hours\nneeded for manual collection or the thousands of dollars required for\ncommercial database subscriptions. To foster a more inclusive research\ncommunity by empowering researchers with limited resources to explore new\navenues of inquiry, we share our methodology and the resulting datasets.",
      "tldr_zh": "该研究探讨了如何利用 Large Language Models (LLMs) 民主化访问昂贵的财务数据集，以解决研究者尤其是弱势机构人员的不平等问题。研究团队开发了一种新方法，使用 GPT-4o-mini 在 Retrieval-Augmented Generation (RAG) 框架中，从公司披露文件中自动化数据收集，实现了从约10,000个代理声明中提取CEO pay ratios，以及从超过12,000个10-K filings中提取Critical Audit Matters (CAMs)。该方法达到人类水平的准确性，同时处理时间仅为9和40分钟，成本每项不到10美元，远优于手动收集（数百小时）或商业数据库订阅（数千美元）。最终，研究分享了该方法和数据集，以促进更具包容性的学术研究社区。",
      "categories": [
        "q-fin.GN",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "q-fin.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02065v1",
      "published_date": "2024-12-03 00:59:56 UTC",
      "updated_date": "2024-12-03 00:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:28:17.403292"
    },
    {
      "arxiv_id": "2412.02062v1",
      "title": "Construction and optimization of health behavior prediction model for the elderly in smart elderly care",
      "title_zh": "智能养老中老年人健康行为预测模型的构建与优化",
      "authors": [
        "Qian Guo",
        "Peiyuan Chen"
      ],
      "abstract": "With the intensification of global aging, health management of the elderly\nhas become a focus of social attention. This study designs and implements a\nsmart elderly care service model to address issues such as data diversity,\nhealth status complexity, long-term dependence and data loss, sudden changes in\nbehavior, and data privacy in the prediction of health behaviors of the\nelderly. The model achieves accurate prediction and dynamic management of\nhealth behaviors of the elderly through modules such as multimodal data fusion,\ndata loss processing, nonlinear prediction, emergency detection, and privacy\nprotection. In the experimental design, based on multi-source data sets and\nmarket research results, the model demonstrates excellent performance in health\nbehavior prediction, emergency detection, and personalized services. The\nexperimental results show that the model can effectively improve the accuracy\nand robustness of health behavior prediction and meet the actual application\nneeds in the field of smart elderly care. In the future, with the integration\nof more data and further optimization of technology, the model will provide\nmore powerful technical support for smart elderly care services.",
      "tldr_zh": "本研究构建并优化了智能养老健康行为预测模型，旨在解决老年人群数据多样性、健康状态复杂性、长期依赖性、行为突发变化和数据隐私等问题。模型通过多模态数据融合（multimodal data fusion）、数据丢失处理、非线性预测、紧急检测和隐私保护模块，实现老年健康行为的准确预测和动态管理。实验基于多源数据集和市场研究结果，证明该模型在健康行为预测、紧急检测和个性化服务中表现出色，提高了预测准确性和鲁棒性。未来，随着更多数据的整合和技术优化，该模型将为智能养老服务提供更可靠的技术支持。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.02062v1",
      "published_date": "2024-12-03 00:47:42 UTC",
      "updated_date": "2024-12-03 00:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:28:29.245976"
    },
    {
      "arxiv_id": "2412.02057v2",
      "title": "Comparative Analysis of Multi-Agent Reinforcement Learning Policies for Crop Planning Decision Support",
      "title_zh": "多智能体强化学习策略在作物规划决策支持中的比较分析",
      "authors": [
        "Anubha Mahajan",
        "Shreya Hegde",
        "Ethan Shay",
        "Daniel Wu",
        "Aviva Prins"
      ],
      "abstract": "In India, the majority of farmers are classified as small or marginal, making\ntheir livelihoods particularly vulnerable to economic losses due to market\nsaturation and climate risks. Effective crop planning can significantly impact\ntheir expected income, yet existing decision support systems (DSS) often\nprovide generic recommendations that fail to account for real-time market\ndynamics and the interactions among multiple farmers. In this paper, we\nevaluate the viability of three multi-agent reinforcement learning (MARL)\napproaches for optimizing total farmer income and promoting fairness in crop\nplanning: Independent Q-Learning (IQL), where each farmer acts independently\nwithout coordination, Agent-by-Agent (ABA), which sequentially optimizes each\nfarmer's policy in relation to the others, and the Multi-agent Rollout Policy,\nwhich jointly optimizes all farmers' actions for global reward maximization.\nOur results demonstrate that while IQL offers computational efficiency with\nlinear runtime, it struggles with coordination among agents, leading to lower\ntotal rewards and an unequal distribution of income. Conversely, the\nMulti-agent Rollout policy achieves the highest total rewards and promotes\nequitable income distribution among farmers but requires significantly more\ncomputational resources, making it less practical for large numbers of agents.\nABA strikes a balance between runtime efficiency and reward optimization,\noffering reasonable total rewards with acceptable fairness and scalability.\nThese findings highlight the importance of selecting appropriate MARL\napproaches in DSS to provide personalized and equitable crop planning\nrecommendations, advancing the development of more adaptive and farmer-centric\nagricultural decision-making systems.",
      "tldr_zh": "本研究比较了三种多智能体强化学习（MARL）方法，用于优化印度小农的作物规划决策支持系统，以应对市场饱和和气候风险问题。方法包括Independent Q-Learning (IQL)，其中每个农民独立行动，计算效率高但协调不足导致回报较低和收入不平等；Agent-by-Agent (ABA)，通过顺序优化每个农民的政策，实现运行时效率与回报的平衡；以及Multi-agent Rollout Policy，通过联合优化所有农民行动，获得最高总回报和公平性，但计算资源需求较大。结果显示，ABA在效率和公平性间取得最佳折中，而这些发现强调了在决策支持系统中选择合适MARL方法的重要性，以推动个性化、公平的农业决策系统发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02057v2",
      "published_date": "2024-12-03 00:30:19 UTC",
      "updated_date": "2025-02-24 16:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:28:57.492698"
    },
    {
      "arxiv_id": "2412.02043v1",
      "title": "Future of Information Retrieval Research in the Age of Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "James Allan",
        "Eunsol Choi",
        "Daniel P. Lopresti",
        "Hamed Zamani"
      ],
      "abstract": "In the fast-evolving field of information retrieval (IR), the integration of\ngenerative AI technologies such as large language models (LLMs) is transforming\nhow users search for and interact with information. Recognizing this paradigm\nshift at the intersection of IR and generative AI (IR-GenAI), a visioning\nworkshop supported by the Computing Community Consortium (CCC) was held in July\n2024 to discuss the future of IR in the age of generative AI. This workshop\nconvened 44 experts in information retrieval, natural language processing,\nhuman-computer interaction, and artificial intelligence from academia,\nindustry, and government to explore how generative AI can enhance IR and vice\nversa, and to identify the major challenges and opportunities in this rapidly\nadvancing field.\n  This report contains a summary of discussions as potentially important\nresearch topics and contains a list of recommendations for academics, industry\npractitioners, institutions, evaluation campaigns, and funding agencies.",
      "tldr_zh": "这篇报告探讨了信息检索 (IR) 领域在生成式 AI 时代的发展前景，强调大型语言模型 (LLMs) 等技术如何改变用户搜索和互动方式。2024 年 7 月，由 Computing Community Consortium (CCC) 支持的研讨会聚集了 44 位专家，包括 IR、自然语言处理 (NLP)、人机交互和人工智能领域的学者和从业者，讨论了 IR 与生成式 AI (IR-GenAI) 的交叉点、挑战与机遇。报告总结了重要研究主题，并为学术界、行业机构、评估活动和资助机构提供了具体推荐，以推动该领域的创新。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02043v1",
      "published_date": "2024-12-03 00:01:48 UTC",
      "updated_date": "2024-12-03 00:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:29:09.366970"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 132,
  "processed_papers_count": 132,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T07:31:26.923661"
}