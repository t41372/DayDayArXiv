[
  {
    "arxiv_id": "2412.02912v1",
    "title": "ShapeWords: Guiding Text-to-Image Synthesis with 3D Shape-Aware Prompts",
    "authors": [
      "Dmitry Petrov",
      "Pradyumn Goyal",
      "Divyansh Shivashok",
      "Yuanming Tao",
      "Melinos Averkiou",
      "Evangelos Kalogerakis"
    ],
    "abstract": "We introduce ShapeWords, an approach for synthesizing images based on 3D\nshape guidance and text prompts. ShapeWords incorporates target 3D shape\ninformation within specialized tokens embedded together with the input text,\neffectively blending 3D shape awareness with textual context to guide the image\nsynthesis process. Unlike conventional shape guidance methods that rely on\ndepth maps restricted to fixed viewpoints and often overlook full 3D structure\nor textual context, ShapeWords generates diverse yet consistent images that\nreflect both the target shape's geometry and the textual description.\nExperimental results show that ShapeWords produces images that are more\ntext-compliant, aesthetically plausible, while also maintaining 3D shape\nawareness.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project webpage: https://lodurality.github.io/shapewords/",
    "pdf_url": "http://arxiv.org/pdf/2412.02912v1",
    "published_date": "2024-12-03 23:37:47 UTC",
    "updated_date": "2024-12-03 23:37:47 UTC"
  },
  {
    "arxiv_id": "2412.02906v1",
    "title": "Does Few-Shot Learning Help LLM Performance in Code Synthesis?",
    "authors": [
      "Derek Xu",
      "Tong Xie",
      "Botao Xia",
      "Haoyu Li",
      "Yunsheng Bai",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "abstract": "Large language models (LLMs) have made significant strides at code generation\nthrough improved model design, training, and chain-of-thought. However,\nprompt-level optimizations remain an important yet under-explored aspect of\nLLMs for coding. This work focuses on the few-shot examples present in most\ncode generation prompts, offering a systematic study on whether few-shot\nexamples improve LLM's coding capabilities, which few-shot examples have the\nlargest impact, and how to select impactful examples. Our work offers 2\napproaches for selecting few-shot examples, a model-free method,\nCODEEXEMPLAR-FREE, and a model-based method, CODEEXEMPLAR-BASED. The 2 methods\noffer a trade-off between improved performance and reliance on training data\nand interpretability. Both methods significantly improve CodeLlama's coding\nability across the popular HumanEval+ coding benchmark. In summary, our work\nprovides valuable insights into how to pick few-shot examples in code\ngeneration prompts to improve LLM code generation capabilities.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02906v1",
    "published_date": "2024-12-03 23:19:40 UTC",
    "updated_date": "2024-12-03 23:19:40 UTC"
  },
  {
    "arxiv_id": "2412.02904v1",
    "title": "Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning",
    "authors": [
      "Ranganath Krishnan",
      "Piyush Khanna",
      "Omesh Tickoo"
    ],
    "abstract": "Large language models (LLMs) have revolutionized the field of natural\nlanguage processing with their impressive reasoning and question-answering\ncapabilities. However, these models are sometimes prone to generating\ncredible-sounding but incorrect information, a phenomenon known as LLM\nhallucinations. Reliable uncertainty estimation in LLMs is essential for\nfostering trust in their generated responses and serves as a critical tool for\nthe detection and prevention of erroneous or hallucinated outputs. To achieve\nreliable and well-calibrated uncertainty quantification in open-ended and\nfree-form natural language generation, we propose an uncertainty-aware\nfine-tuning approach for LLMs. This approach enhances the model's ability to\nprovide reliable uncertainty estimates without compromising accuracy, thereby\nguiding them to produce more trustworthy responses. We introduce a novel\nuncertainty-aware causal language modeling loss function, grounded in the\nprinciples of decision theory. Through rigorous evaluation on multiple\nfree-form question-answering datasets and models, we demonstrate that our\nuncertainty-aware fine-tuning approach yields better calibrated uncertainty\nestimates in natural language generation tasks than fine-tuning with the\nstandard causal language modeling loss. Furthermore, the experimental results\nshow that the proposed method significantly improves the model's ability to\ndetect hallucinations and identify out-of-domain prompts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02904v1",
    "published_date": "2024-12-03 23:14:47 UTC",
    "updated_date": "2024-12-03 23:14:47 UTC"
  },
  {
    "arxiv_id": "2412.02897v1",
    "title": "MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions",
    "authors": [
      "Jinming Zhang",
      "Yunfei Long"
    ],
    "abstract": "Narrative understanding and story generation are critical challenges in\nnatural language processing (NLP), with much of the existing research focused\non summarization and question-answering tasks. While previous studies have\nexplored predicting plot endings and generating extended narratives, they often\nneglect the logical coherence within stories, leaving a significant gap in the\nfield. To address this, we introduce the Missing Logic Detector by Emotion and\nAction (MLD-EA) model, which leverages large language models (LLMs) to identify\nnarrative gaps and generate coherent sentences that integrate seamlessly with\nthe story's emotional and logical flow. The experimental results demonstrate\nthat the MLD-EA model enhances narrative understanding and story generation,\nhighlighting LLMs' potential as effective logic checkers in story writing with\nlogical coherence and emotional consistency. This work fills a gap in NLP\nresearch and advances border goals of creating more sophisticated and reliable\nstory-generation systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02897v1",
    "published_date": "2024-12-03 23:01:21 UTC",
    "updated_date": "2024-12-03 23:01:21 UTC"
  },
  {
    "arxiv_id": "2412.02893v1",
    "title": "Removing Spurious Correlation from Neural Network Interpretations",
    "authors": [
      "Milad Fotouhi",
      "Mohammad Taha Bahadori",
      "Oluwaseyi Feyisetan",
      "Payman Arabshahi",
      "David Heckerman"
    ],
    "abstract": "The existing algorithms for identification of neurons responsible for\nundesired and harmful behaviors do not consider the effects of confounders such\nas topic of the conversation. In this work, we show that confounders can create\nspurious correlations and propose a new causal mediation approach that controls\nthe impact of the topic. In experiments with two large language models, we\nstudy the localization hypothesis and show that adjusting for the effect of\nconversation topic, toxicity becomes less localized.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02893v1",
    "published_date": "2024-12-03 22:58:21 UTC",
    "updated_date": "2024-12-03 22:58:21 UTC"
  },
  {
    "arxiv_id": "2412.02889v2",
    "title": "Deep-Learning Based Docking Methods: Fair Comparisons to Conventional Docking Workflows",
    "authors": [
      "Ajay N. Jain",
      "Ann E. Cleves",
      "W. Patrick Walters"
    ],
    "abstract": "The diffusion learning method, DiffDock, for docking small-molecule ligands\ninto protein binding sites was recently introduced. Results included\ncomparisons to more conventional docking approaches, with DiffDock showing\nsuperior performance. Here, we employ a fully automatic workflow using the\nSurflex-Dock methods to generate a fair baseline for conventional docking\napproaches. Results were generated for the common and expected situation where\na binding site location is known and also for the condition of an unknown\nbinding site. For the known binding site condition, Surflex-Dock success rates\nat 2.0 Angstroms RMSD far exceeded those for DiffDock (Top-1/Top-5 success\nrates, respectively, were 68/81% compared with 45/51%). Glide performed with\nsimilar success rates (67/73%) to Surflex-Dock for the known binding site\ncondition, and results for AutoDock Vina and Gnina followed this pattern. For\nthe unknown binding site condition, using an automated method to identify\nmultiple binding pockets, Surflex-Dock success rates again exceeded those of\nDiffDock, but by a somewhat lesser margin. DiffDock made use of roughly 17,000\nco-crystal structures for learning (98% of PDBBind version 2020, pre-2019\nstructures) for a training set in order to predict on 363 test cases (2% of\nPDBBind 2020) from 2019 forward. DiffDock's performance was inextricably linked\nwith the presence of near-neighbor cases of close to identical protein-ligand\ncomplexes in the training set for over half of the test set cases. DiffDock\nexhibited a 40 percentage point difference on near-neighbor cases (two-thirds\nof all test cases) compared with cases with no near-neighbor training case.\nDiffDock has apparently encoded a type of table-lookup during its learning\nprocess, rendering meaningful applications beyond its reach. Further, it does\nnot perform even close to competitively with a competently run modern docking\nworkflow.",
    "categories": [
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.AI",
    "comment": "Post-Conclusion addendum added with additional reference and context,\n  19 pages including references and appendices, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02889v2",
    "published_date": "2024-12-03 22:47:47 UTC",
    "updated_date": "2024-12-09 18:37:17 UTC"
  },
  {
    "arxiv_id": "2412.02878v2",
    "title": "Modeling and Discovering Direct Causes for Predictive Models",
    "authors": [
      "Yizuo Chen",
      "Amit Bhatia"
    ],
    "abstract": "We introduce a causal modeling framework that captures the input-output\nbehavior of predictive models (e.g., machine learning models). The framework\nenables us to identify features that directly cause the predictions, which has\nbroad implications for data collection and model evaluation. We then present\nsound and complete algorithms for discovering direct causes (from data) under\nsome assumptions. Furthermore, we propose a novel independence rule that can be\nintegrated with the algorithms to accelerate the discovery process, as we\ndemonstrate both theoretically and empirically.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02878v2",
    "published_date": "2024-12-03 22:25:42 UTC",
    "updated_date": "2025-05-17 03:06:10 UTC"
  },
  {
    "arxiv_id": "2412.02875v1",
    "title": "Out-of-Distribution Detection for Neurosymbolic Autonomous Cyber Agents",
    "authors": [
      "Ankita Samaddar",
      "Nicholas Potteiger",
      "Xenofon Koutsoukos"
    ],
    "abstract": "Autonomous agents for cyber applications take advantage of modern defense\ntechniques by adopting intelligent agents with conventional and\nlearning-enabled components. These intelligent agents are trained via\nreinforcement learning (RL) algorithms, and can learn, adapt to, reason about\nand deploy security rules to defend networked computer systems while\nmaintaining critical operational workflows. However, the knowledge available\nduring training about the state of the operational network and its environment\nmay be limited. The agents should be trustworthy so that they can reliably\ndetect situations they cannot handle, and hand them over to cyber experts. In\nthis work, we develop an out-of-distribution (OOD) Monitoring algorithm that\nuses a Probabilistic Neural Network (PNN) to detect anomalous or OOD situations\nof RL-based agents with discrete states and discrete actions. To demonstrate\nthe effectiveness of the proposed approach, we integrate the OOD monitoring\nalgorithm with a neurosymbolic autonomous cyber agent that uses behavior trees\nwith learning-enabled components. We evaluate the proposed approach in a\nsimulated cyber environment under different adversarial strategies.\nExperimental results over a large number of episodes illustrate the overall\nefficiency of our proposed approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 10 figures, IEEE International Conference on AI in\n  Cybersecurity (ICAIC), 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02875v1",
    "published_date": "2024-12-03 22:20:52 UTC",
    "updated_date": "2024-12-03 22:20:52 UTC"
  },
  {
    "arxiv_id": "2412.02869v1",
    "title": "Constrained Identifiability of Causal Effects",
    "authors": [
      "Yizuo Chen",
      "Adnan Darwiche"
    ],
    "abstract": "We study the identification of causal effects in the presence of different\ntypes of constraints (e.g., logical constraints) in addition to the causal\ngraph. These constraints impose restrictions on the models (parameterizations)\ninduced by the causal graph, reducing the set of models considered by the\nidentifiability problem. We formalize the notion of constrained\nidentifiability, which takes a set of constraints as another input to the\nclassical definition of identifiability. We then introduce a framework for\ntesting constrained identifiability by employing tractable Arithmetic Circuits\n(ACs), which enables us to accommodate constraints systematically. We show that\nthis AC-based approach is at least as complete as existing algorithms (e.g.,\ndo-calculus) for testing classical identifiability, which only assumes the\nconstraint of strict positivity. We use examples to demonstrate the\neffectiveness of this AC-based approach by showing that unidentifiable causal\neffects may become identifiable under different types of constraints.",
    "categories": [
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02869v1",
    "published_date": "2024-12-03 22:08:45 UTC",
    "updated_date": "2024-12-03 22:08:45 UTC"
  },
  {
    "arxiv_id": "2412.02868v2",
    "title": "Enhancing LLMs with Smart Preprocessing for EHR Analysis",
    "authors": [
      "Yixiang Qu",
      "Yifan Dai",
      "Shilin Yu",
      "Pradham Tanikella",
      "Travis Schrank",
      "Trevor Hackman",
      "Didong Li",
      "Di Wu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\nnatural language processing; however, their application in sensitive domains\nsuch as healthcare, especially in processing Electronic Health Records (EHRs),\nis constrained by limited computational resources and privacy concerns. This\npaper introduces a compact LLM framework optimized for local deployment in\nenvironments with stringent privacy requirements and restricted access to\nhigh-performance GPUs. Our approach leverages simple yet powerful preprocessing\ntechniques, including regular expressions (regex) and Retrieval-Augmented\nGeneration (RAG), to extract and highlight critical information from clinical\nnotes. By pre-filtering long, unstructured text, we enhance the performance of\nsmaller LLMs on EHR-related tasks. Our framework is evaluated using zero-shot\nand few-shot learning paradigms on both private and publicly available datasets\n(MIMIC-IV), with additional comparisons against fine-tuned LLMs on MIMIC-IV.\nExperimental results demonstrate that our preprocessing strategy significantly\nsupercharges the performance of smaller LLMs, making them well-suited for\nprivacy-sensitive and resource-constrained applications. This study offers\nvaluable insights into optimizing LLM performance for local, secure, and\nefficient healthcare applications. It provides practical guidance for\nreal-world deployment for LLMs while tackling challenges related to privacy,\ncomputational feasibility, and clinical applicability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02868v2",
    "published_date": "2024-12-03 22:06:55 UTC",
    "updated_date": "2025-04-24 13:07:21 UTC"
  },
  {
    "arxiv_id": "2412.02865v3",
    "title": "Memory-efficient Continual Learning with Neural Collapse Contrastive",
    "authors": [
      "Trung-Anh Dang",
      "Vincent Nguyen",
      "Ngoc-Son Vu",
      "Christel Vrain"
    ],
    "abstract": "Contrastive learning has significantly improved representation quality,\nenhancing knowledge transfer across tasks in continual learning (CL). However,\ncatastrophic forgetting remains a key challenge, as contrastive based methods\nprimarily focus on \"soft relationships\" or \"softness\" between samples, which\nshift with changing data distributions and lead to representation overlap\nacross tasks. Recently, the newly identified Neural Collapse phenomenon has\nshown promise in CL by focusing on \"hard relationships\" or \"hardness\" between\nsamples and fixed prototypes. However, this approach overlooks \"softness\",\ncrucial for capturing intra-class variability, and this rigid focus can also\npull old class representations toward current ones, increasing forgetting.\nBuilding on these insights, we propose Focal Neural Collapse Contrastive\n(FNC^2), a novel representation learning loss that effectively balances both\nsoft and hard relationships. Additionally, we introduce the Hardness-Softness\nDistillation (HSD) loss to progressively preserve the knowledge gained from\nthese relationships across tasks. Our method outperforms state-of-the-art\napproaches, particularly in minimizing memory reliance. Remarkably, even\nwithout the use of memory, our approach rivals rehearsal-based methods,\noffering a compelling solution for data privacy concerns.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02865v3",
    "published_date": "2024-12-03 22:00:12 UTC",
    "updated_date": "2024-12-06 10:38:02 UTC"
  },
  {
    "arxiv_id": "2412.02863v1",
    "title": "Proximal Control of UAVs with Federated Learning for Human-Robot Collaborative Domains",
    "authors": [
      "Lucas Nogueira Nobrega",
      "Ewerton de Oliveira",
      "Martin Saska",
      "Tiago Nascimento"
    ],
    "abstract": "The human-robot interaction (HRI) is a growing area of research. In HRI,\ncomplex command (action) classification is still an open problem that usually\nprevents the real applicability of such a technique. The literature presents\nsome works that use neural networks to detect these actions. However, occlusion\nis still a major issue in HRI, especially when using uncrewed aerial vehicles\n(UAVs), since, during the robot's movement, the human operator is often out of\nthe robot's field of view. Furthermore, in multi-robot scenarios, distributed\ntraining is also an open problem. In this sense, this work proposes an action\nrecognition and control approach based on Long Short-Term Memory (LSTM) Deep\nNeural Networks with two layers in association with three densely connected\nlayers and Federated Learning (FL) embedded in multiple drones. The FL enabled\nour approach to be trained in a distributed fashion, i.e., access to data\nwithout the need for cloud or other repositories, which facilitates the\nmulti-robot system's learning. Furthermore, our multi-robot approach results\nalso prevented occlusion situations, with experiments with real robots\nachieving an accuracy greater than 96%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02863v1",
    "published_date": "2024-12-03 21:57:04 UTC",
    "updated_date": "2024-12-03 21:57:04 UTC"
  },
  {
    "arxiv_id": "2412.02858v1",
    "title": "Unpaired Modality Translation for Pseudo Labeling of Histology Images",
    "authors": [
      "Arthur Boschet",
      "Armand Collin",
      "Nishka Katoch",
      "Julien Cohen-Adad"
    ],
    "abstract": "The segmentation of histological images is critical for various biomedical\napplications, yet the lack of annotated data presents a significant challenge.\nWe propose a microscopy pseudo labeling pipeline utilizing unsupervised image\ntranslation to address this issue. Our method generates pseudo labels by\ntranslating between labeled and unlabeled domains without requiring prior\nannotation in the target domain. We evaluate two pseudo labeling strategies\nacross three image domains increasingly dissimilar from the labeled data,\ndemonstrating their effectiveness. Notably, our method achieves a mean Dice\nscore of $0.736 \\pm 0.005$ on a SEM dataset using the tutoring path, which\ninvolves training a segmentation model on synthetic data created by translating\nthe labeled dataset (TEM) to the target modality (SEM). This approach aims to\naccelerate the annotation process by providing high-quality pseudo labels as a\nstarting point for manual refinement.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02858v1",
    "published_date": "2024-12-03 21:45:59 UTC",
    "updated_date": "2024-12-03 21:45:59 UTC"
  },
  {
    "arxiv_id": "2412.02851v1",
    "title": "Block MedCare: Advancing healthcare through blockchain integration with AI and IoT",
    "authors": [
      "Oliver Simonoski",
      "Dijana Capeska Bogatinoska"
    ],
    "abstract": "This research explores the integration of blockchain technology in\nhealthcare, focusing on enhancing the security and efficiency of Electronic\nHealth Record (EHR) management. We propose a novel Ethereum-based system that\nempowers patients with secure control over their medical data. Our approach\naddresses key challenges in healthcare blockchain implementation, including\nscalability, privacy, and regulatory compliance. The system incorporates\ndigital signatures, Role-Based Access Control, and a multi-layered architecture\nto ensure secure, controlled access. We developed a decentralized application\n(dApp) with user-friendly interfaces for patients, doctors, and administrators,\ndemonstrating the practical application of our solution. A survey among\nhealthcare professionals and IT experts revealed strong interest in blockchain\nadoption, while also highlighting concerns about integration costs. The study\nexplores future enhancements, including integration with IoT devices and\nAI-driven analytics, contributing to the evolution of secure, efficient, and\ninteroperable healthcare systems that leverage cutting-edge technologies for\nimproved patient care.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02851v1",
    "published_date": "2024-12-03 21:31:46 UTC",
    "updated_date": "2024-12-03 21:31:46 UTC"
  },
  {
    "arxiv_id": "2412.05322v1",
    "title": "$ρ$-NeRF: Leveraging Attenuation Priors in Neural Radiance Field for 3D Computed Tomography Reconstruction",
    "authors": [
      "Li Zhou",
      "Changsheng Fang",
      "Bahareh Morovati",
      "Yongtong Liu",
      "Shuo Han",
      "Yongshun Xu",
      "Hengyong Yu"
    ],
    "abstract": "This paper introduces $\\rho$-NeRF, a self-supervised approach that sets a new\nstandard in novel view synthesis (NVS) and computed tomography (CT)\nreconstruction by modeling a continuous volumetric radiance field enriched with\nphysics-based attenuation priors. The $\\rho$-NeRF represents a\nthree-dimensional (3D) volume through a fully-connected neural network that\ntakes a single continuous four-dimensional (4D) coordinate, spatial location\n$(x, y, z)$ and an initialized attenuation value ($\\rho$), and outputs the\nattenuation coefficient at that position. By querying these 4D coordinates\nalong X-ray paths, the classic forward projection technique is applied to\nintegrate attenuation data across the 3D space. By matching and refining\npre-initialized attenuation values derived from traditional reconstruction\nalgorithms like Feldkamp-Davis-Kress algorithm (FDK) or conjugate gradient\nleast squares (CGLS), the enriched schema delivers superior fidelity in both\nprojection synthesis and image recognition.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "The paper was submitted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.05322v1",
    "published_date": "2024-12-03 21:06:26 UTC",
    "updated_date": "2024-12-03 21:06:26 UTC"
  },
  {
    "arxiv_id": "2412.02835v1",
    "title": "CAISSON: Concept-Augmented Inference Suite of Self-Organizing Neural Networks",
    "authors": [
      "Igor Halperin"
    ],
    "abstract": "We present CAISSON, a novel hierarchical approach to Retrieval-Augmented\nGeneration (RAG) that transforms traditional single-vector search into a\nmulti-view clustering framework. At its core, CAISSON leverages dual\nSelf-Organizing Maps (SOMs) to create complementary organizational views of the\ndocument space, where each view captures different aspects of document\nrelationships through specialized embeddings. The first view processes combined\ntext and metadata embeddings, while the second operates on metadata enriched\nwith concept embeddings, enabling a comprehensive multi-view analysis that\ncaptures both fine-grained semantic relationships and high-level conceptual\npatterns. This dual-view approach enables more nuanced document discovery by\ncombining evidence from different organizational perspectives. To evaluate\nCAISSON, we develop SynFAQA, a framework for generating synthetic financial\nanalyst notes and question-answer pairs that systematically tests different\naspects of information retrieval capabilities. Drawing on HotPotQA's\nmethodology for constructing multi-step reasoning questions, SynFAQA generates\ncontrolled test cases where each question is paired with the set of notes\ncontaining its ground-truth answer, progressing from simple single-entity\nqueries to complex multi-hop retrieval tasks involving multiple entities and\nconcepts. Our experimental results demonstrate substantial improvements over\nboth basic and enhanced RAG implementations, particularly for complex\nmulti-entity queries, while maintaining practical response times suitable for\ninteractive applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 7 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.02835v1",
    "published_date": "2024-12-03 21:00:10 UTC",
    "updated_date": "2024-12-03 21:00:10 UTC"
  },
  {
    "arxiv_id": "2412.02831v1",
    "title": "FLAME 3 Dataset: Unleashing the Power of Radiometric Thermal UAV Imagery for Wildfire Management",
    "authors": [
      "Bryce Hopkins",
      "Leo ONeill",
      "Michael Marinaccio",
      "Eric Rowell",
      "Russell Parsons",
      "Sarah Flanary",
      "Irtija Nazim",
      "Carl Seielstad",
      "Fatemeh Afghah"
    ],
    "abstract": "The increasing accessibility of radiometric thermal imaging sensors for\nunmanned aerial vehicles (UAVs) offers significant potential for advancing\nAI-driven aerial wildfire management. Radiometric imaging provides per-pixel\ntemperature estimates, a valuable improvement over non-radiometric data that\nrequires irradiance measurements to be converted into visible images using RGB\ncolor palettes. Despite its benefits, this technology has been underutilized\nlargely due to a lack of available data for researchers. This study addresses\nthis gap by introducing methods for collecting and processing synchronized\nvisual spectrum and radiometric thermal imagery using UAVs at prescribed fires.\nThe included imagery processing pipeline drastically simplifies and partially\nautomates each step from data collection to neural network input. Further, we\npresent the FLAME 3 dataset, the first comprehensive collection of side-by-side\nvisual spectrum and radiometric thermal imagery of wildland fires. Building on\nour previous FLAME 1 and FLAME 2 datasets, FLAME 3 includes radiometric thermal\nTag Image File Format (TIFFs) and nadir thermal plots, providing a new data\ntype and collection method. This dataset aims to spur a new generation of\nmachine learning models utilizing radiometric thermal imagery, potentially\ntrivializing tasks such as aerial wildfire detection, segmentation, and\nassessment. A single-burn subset of FLAME 3 for computer vision applications is\navailable on Kaggle with the full 6 burn set available to readers upon request.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 8 Figures, 8 Tables",
    "pdf_url": "http://arxiv.org/pdf/2412.02831v1",
    "published_date": "2024-12-03 20:53:42 UTC",
    "updated_date": "2024-12-03 20:53:42 UTC"
  },
  {
    "arxiv_id": "2412.02823v1",
    "title": "Minimization of Boolean Complexity in In-Context Concept Learning",
    "authors": [
      "Leroy Z. Wang",
      "R. Thomas McCoy",
      "Shane Steinert-Threlkeld"
    ],
    "abstract": "What factors contribute to the relative success and corresponding\ndifficulties of in-context learning for Large Language Models (LLMs)? Drawing\non insights from the literature on human concept learning, we test LLMs on\ncarefully designed concept learning tasks, and show that task performance\nhighly correlates with the Boolean complexity of the concept. This suggests\nthat in-context learning exhibits a learning bias for simplicity in a way\nsimilar to humans.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02823v1",
    "published_date": "2024-12-03 20:41:37 UTC",
    "updated_date": "2024-12-03 20:41:37 UTC"
  },
  {
    "arxiv_id": "2412.02819v4",
    "title": "CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels",
    "authors": [
      "Lingxiao Wei",
      "He Yan",
      "Xiangju Lu",
      "Junmin Zhu",
      "Jun Wang",
      "Wei Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have been well-researched in various\nlong-context tasks. However, the scarcity of high-quality long-context\nsummarization datasets has hindered further advancements in this area. To\naddress this, we introduce CNNSum, a multi-scale long-context summarization\nbenchmark based on Chinese novels, featuring human-driven annotations, which\ncomprises four subsets totaling 695 samples, with lengths ranging from 16k to\n128k. We evaluate numerous LLMs and conduct detailed case analyses.\nFurthermore, we conduct extensive fine-tuning experiments to explore and\nimprove long-context summarization. In our study: (1) Advanced LLMs like GPT-4o\nmay still generate subjective commentary, leading to vague summaries. (2)\nCurrently, long-context summarization mainly relies on memory ability afforded\nby longer context lengths. The advantages of Large LLMs are hard to utilize,\nthus small LLMs are the most cost-effective. (3) Different prompt templates\npaired with various version models may cause large performance gaps. In further\nfine-tuning, these can be mitigated, and the Base version models perform\nbetter. (4) LLMs with RoPE-base scaled exhibit strong extrapolation potential;\nusing short-context data can significantly improve long-context summarization\nperformance. However, further applying other interpolation methods requires\ncareful selection. (5) CNNSum provides more reliable and insightful evaluation\nresults than other benchmarks. We release CNNSum to advance future research in\nthis field. https://github.com/CxsGhost/CNNSum",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.02819v4",
    "published_date": "2024-12-03 20:35:57 UTC",
    "updated_date": "2024-12-17 16:03:43 UTC"
  },
  {
    "arxiv_id": "2412.02803v1",
    "title": "Gaussian Splatting Under Attack: Investigating Adversarial Noise in 3D Objects",
    "authors": [
      "Abdurrahman Zeybey",
      "Mehmet Ergezer",
      "Tommy Nguyen"
    ],
    "abstract": "3D Gaussian Splatting has advanced radiance field reconstruction, enabling\nhigh-quality view synthesis and fast rendering in 3D modeling. While\nadversarial attacks on object detection models are well-studied for 2D images,\ntheir impact on 3D models remains underexplored. This work introduces the\nMasked Iterative Fast Gradient Sign Method (M-IFGSM), designed to generate\nadversarial noise targeting the CLIP vision-language model. M-IFGSM\nspecifically alters the object of interest by focusing perturbations on masked\nregions, degrading the performance of CLIP's zero-shot object detection\ncapability when applied to 3D models. Using eight objects from the Common\nObjects 3D (CO3D) dataset, we demonstrate that our method effectively reduces\nthe accuracy and confidence of the model, with adversarial noise being nearly\nimperceptible to human observers. The top-1 accuracy in original model renders\ndrops from 95.4\\% to 12.5\\% for train images and from 91.2\\% to 35.4\\% for test\nimages, with confidence levels reflecting this shift from true classification\nto misclassification, underscoring the risks of adversarial attacks on 3D\nmodels in applications such as autonomous driving, robotics, and surveillance.\nThe significance of this research lies in its potential to expose\nvulnerabilities in modern 3D vision models, including radiance fields,\nprompting the development of more robust defenses and security measures in\ncritical real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to Safe Generative AI Workshop @ NeurIPS 2024:\n  https://neurips.cc/virtual/2024/workshop/84705",
    "pdf_url": "http://arxiv.org/pdf/2412.02803v1",
    "published_date": "2024-12-03 20:11:21 UTC",
    "updated_date": "2024-12-03 20:11:21 UTC"
  },
  {
    "arxiv_id": "2412.02802v1",
    "title": "Flattering to Deceive: The Impact of Sycophantic Behavior on User Trust in Large Language Model",
    "authors": [
      "María Victoria Carro"
    ],
    "abstract": "Sycophancy refers to the tendency of a large language model to align its\noutputs with the user's perceived preferences, beliefs, or opinions, in order\nto look favorable, regardless of whether those statements are factually\ncorrect. This behavior can lead to undesirable consequences, such as\nreinforcing discriminatory biases or amplifying misinformation. Given that\nsycophancy is often linked to human feedback training mechanisms, this study\nexplores whether sycophantic tendencies negatively impact user trust in large\nlanguage models or, conversely, whether users consider such behavior as\nfavorable. To investigate this, we instructed one group of participants to\nanswer ground-truth questions with the assistance of a GPT specifically\ndesigned to provide sycophantic responses, while another group used the\nstandard version of ChatGPT. Initially, participants were required to use the\nlanguage model, after which they were given the option to continue using it if\nthey found it trustworthy and useful. Trust was measured through both\ndemonstrated actions and self-reported perceptions. The findings consistently\nshow that participants exposed to sycophantic behavior reported and exhibited\nlower levels of trust compared to those who interacted with the standard\nversion of the model, despite the opportunity to verify the accuracy of the\nmodel's output.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02802v1",
    "published_date": "2024-12-03 20:07:41 UTC",
    "updated_date": "2024-12-03 20:07:41 UTC"
  },
  {
    "arxiv_id": "2412.02801v3",
    "title": "Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm",
    "authors": [
      "Jingyuan Yi",
      "Peiyang Yu",
      "Tianyi Huang",
      "Zeqiu Xu"
    ],
    "abstract": "Aiming at the latest particle swarm optimization algorithm, this paper\nproposes an improved Transformer model to improve the accuracy of heart disease\nprediction and provide a new algorithm idea. We first use three mainstream\nmachine learning classification algorithms - decision tree, random forest and\nXGBoost, and then output the confusion matrix of these three models. The\nresults showed that the random forest model had the best performance in\npredicting the classification of heart disease, with an accuracy of 92.2%.\nThen, we apply the Transformer model based on particle swarm optimization (PSO)\nalgorithm to the same dataset for classification experiment. The results show\nthat the classification accuracy of the model is as high as 96.5%, 4.3\npercentage points higher than that of random forest, which verifies the\neffectiveness of PSO in optimizing Transformer model. From the above research,\nwe can see that particle swarm optimization significantly improves Transformer\nperformance in heart disease prediction. Improving the ability to predict heart\ndisease is a global priority with benefits for all humankind. Accurate\nprediction can enhance public health, optimize medical resources, and reduce\nhealthcare costs, leading to healthier populations and more productive\nsocieties worldwide. This advancement paves the way for more efficient health\nmanagement and supports the foundation of a healthier, more resilient global\ncommunity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02801v3",
    "published_date": "2024-12-03 20:04:32 UTC",
    "updated_date": "2025-01-07 10:09:18 UTC"
  },
  {
    "arxiv_id": "2412.02790v1",
    "title": "An Evolutionary Large Language Model for Hallucination Mitigation",
    "authors": [
      "Abdennour Boulesnane",
      "Abdelhakim Souilah"
    ],
    "abstract": "The emergence of LLMs, like ChatGPT and Gemini, has marked the modern era of\nartificial intelligence applications characterized by high-impact applications\ngenerating text, images, and videos. However, these models usually ensue with\none critical challenge called hallucination: confident presentation of\ninaccurate or fabricated information. This problem attracts serious concern\nwhen these models are applied to specialized domains, including healthcare and\nlaw, where the accuracy and preciseness of information are absolute conditions.\nIn this paper, we propose EvoLLMs, an innovative framework inspired by\nEvolutionary Computation, which automates the generation of high-quality\nQuestion-answering (QA) datasets while minimizing hallucinations. EvoLLMs\nemploys genetic algorithms, mimicking evolutionary processes like selection,\nvariation, and mutation, to guide LLMs in generating accurate, contextually\nrelevant question-answer pairs. Comparative analysis shows that EvoLLMs\nconsistently outperforms human-generated datasets in key metrics such as Depth,\nRelevance, and Coverage, while nearly matching human performance in mitigating\nhallucinations. These results highlight EvoLLMs as a robust and efficient\nsolution for QA dataset generation, significantly reducing the time and\nresources required for manual curation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02790v1",
    "published_date": "2024-12-03 19:40:13 UTC",
    "updated_date": "2024-12-03 19:40:13 UTC"
  },
  {
    "arxiv_id": "2412.02788v2",
    "title": "Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset",
    "authors": [
      "Tilahun Abedissa Taffa",
      "Debayan Banerjee",
      "Yaregal Assabie",
      "Ricardo Usbeck"
    ],
    "abstract": "Existing Scholarly Question Answering (QA) methods typically target\nhomogeneous data sources, relying solely on either text or Knowledge Graphs\n(KGs). However, scholarly information often spans heterogeneous sources,\nnecessitating the development of QA systems that integrate information from\nmultiple heterogeneous data sources. To address this challenge, we introduce\nHybrid-SQuAD (Hybrid Scholarly Question Answering Dataset), a novel large-scale\nQA dataset designed to facilitate answering questions incorporating both text\nand KG facts. The dataset consists of 10.5K question-answer pairs generated by\na large language model, leveraging the KGs DBLP and SemOpenAlex alongside\ncorresponding text from Wikipedia. In addition, we propose a RAG-based baseline\nhybrid QA model, achieving an exact match score of 69.65 on the Hybrid-SQuAD\ntest set.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02788v2",
    "published_date": "2024-12-03 19:37:00 UTC",
    "updated_date": "2024-12-05 10:30:56 UTC"
  },
  {
    "arxiv_id": "2412.02784v1",
    "title": "FathomGPT: A Natural Language Interface for Interactively Exploring Ocean Science Data",
    "authors": [
      "Nabin Khanal",
      "Chun Meng Yu",
      "Jui-Cheng Chiu",
      "Anav Chaudhary",
      "Ziyue Zhang",
      "Kakani Katija",
      "Angus G. Forbes"
    ],
    "abstract": "We introduce FathomGPT, an open source system for the interactive\ninvestigation of ocean science data via a natural language interface. FathomGPT\nwas developed in close collaboration with marine scientists to enable\nresearchers to explore and analyze the FathomNet image database. FathomGPT\nprovides a custom information retrieval pipeline that leverages OpenAI's large\nlanguage models to enable: the creation of complex queries to retrieve images,\ntaxonomic information, and scientific measurements; mapping common names and\nmorphological features to scientific names; generating interactive charts on\ndemand; and searching by image or specified patterns within an image. In\ndesigning FathomGPT, particular emphasis was placed on enhancing the user's\nexperience by facilitating free-form exploration and optimizing response times.\nWe present an architectural overview and implementation details of FathomGPT,\nalong with a series of ablation studies that demonstrate the effectiveness of\nour approach to name resolution, fine tuning, and prompt modification. We also\npresent usage scenarios of interactive data exploration sessions and document\nfeedback from ocean scientists and machine learning experts.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.2; I.2.7; I.7.10"
    ],
    "primary_category": "cs.HC",
    "comment": "The first two authors contributed equally to this work. Accepted to\n  the 37th Annual ACM Symposium on User Interface Software and Technology (UIST\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.02784v1",
    "published_date": "2024-12-03 19:22:55 UTC",
    "updated_date": "2024-12-03 19:22:55 UTC"
  },
  {
    "arxiv_id": "2412.02780v1",
    "title": "WxC-Bench: A Novel Dataset for Weather and Climate Downstream Tasks",
    "authors": [
      "Rajat Shinde",
      "Christopher E. Phillips",
      "Kumar Ankur",
      "Aman Gupta",
      "Simon Pfreundschuh",
      "Sujit Roy",
      "Sheyenne Kirkland",
      "Vishal Gaur",
      "Amy Lin",
      "Aditi Sheshadri",
      "Udaysankar Nair",
      "Manil Maskey",
      "Rahul Ramachandran"
    ],
    "abstract": "High-quality machine learning (ML)-ready datasets play a foundational role in\ndeveloping new artificial intelligence (AI) models or fine-tuning existing\nmodels for scientific applications such as weather and climate analysis.\nUnfortunately, despite the growing development of new deep learning models for\nweather and climate, there is a scarcity of curated, pre-processed machine\nlearning (ML)-ready datasets. Curating such high-quality datasets for\ndeveloping new models is challenging particularly because the modality of the\ninput data varies significantly for different downstream tasks addressing\ndifferent atmospheric scales (spatial and temporal). Here we introduce\nWxC-Bench (Weather and Climate Bench), a multi-modal dataset designed to\nsupport the development of generalizable AI models for downstream use-cases in\nweather and climate research. WxC-Bench is designed as a dataset of datasets\nfor developing ML-models for a complex weather and climate system, addressing\nselected downstream tasks as machine learning phenomenon. WxC-Bench encompasses\nseveral atmospheric processes from meso-$\\beta$ (20 - 200 km) scale to synoptic\nscales (2500 km), such as aviation turbulence, hurricane intensity and track\nmonitoring, weather analog search, gravity wave parameterization, and natural\nlanguage report generation. We provide a comprehensive description of the\ndataset and also present a technical validation for baseline analysis. The\ndataset and code to prepare the ML-ready data have been made publicly available\non Hugging Face -- https://huggingface.co/datasets/nasa-impact/WxC-Bench",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02780v1",
    "published_date": "2024-12-03 19:20:27 UTC",
    "updated_date": "2024-12-03 19:20:27 UTC"
  },
  {
    "arxiv_id": "2412.02779v2",
    "title": "Synergistic Development of Perovskite Memristors and Algorithms for Robust Analog Computing",
    "authors": [
      "Nanyang Ye",
      "Qiao Sun",
      "Yifei Wang",
      "Liujia Yang",
      "Jundong Zhou",
      "Lei Wang",
      "Guang-Zhong Yang",
      "Xinbing Wang",
      "Chenghu Zhou",
      "Wei Ren",
      "Leilei Gu",
      "Huaqiang Wu",
      "Qinying Gu"
    ],
    "abstract": "Analog computing using non-volatile memristors has emerged as a promising\nsolution for energy-efficient deep learning. New materials, like\nperovskites-based memristors are recently attractive due to their\ncost-effectiveness, energy efficiency and flexibility. Yet, challenges in\nmaterial diversity and immature fabrications require extensive experimentation\nfor device development. Moreover, significant non-idealities in these\nmemristors often impede them for computing. Here, we propose a synergistic\nmethodology to concurrently optimize perovskite memristor fabrication and\ndevelop robust analog DNNs that effectively address the inherent non-idealities\nof these memristors. Employing Bayesian optimization (BO) with a focus on\nusability, we efficiently identify optimal materials and fabrication conditions\nfor perovskite memristors. Meanwhile, we developed \"BayesMulti\", a DNN training\nstrategy utilizing BO-guided noise injection to improve the resistance of\nanalog DNNs to memristor imperfections. Our approach theoretically ensures that\nwithin a certain range of parameter perturbations due to memristor\nnon-idealities, the prediction outcomes remain consistent. Our integrated\napproach enables use of analog computing in much deeper and wider networks,\nwhich significantly outperforms existing methods in diverse tasks like image\nclassification, autonomous driving, species identification, and large\nvision-language models, achieving up to 100-fold improvements. We further\nvalidate our methodology on a 10$\\times$10 optimized perovskite memristor\ncrossbar, demonstrating high accuracy in a classification task and low energy\nconsumption. This study offers a versatile solution for efficient optimization\nof various analog computing systems, encompassing both devices and algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02779v2",
    "published_date": "2024-12-03 19:20:08 UTC",
    "updated_date": "2024-12-09 15:56:08 UTC"
  },
  {
    "arxiv_id": "2412.02776v1",
    "title": "Hacking CTFs with Plain Agents",
    "authors": [
      "Rustem Turtayev",
      "Artem Petrov",
      "Dmitrii Volkov",
      "Denis Volk"
    ],
    "abstract": "We saturate a high-school-level hacking benchmark with plain LLM agent\ndesign. Concretely, we obtain 95% performance on InterCode-CTF, a popular\noffensive security benchmark, using prompting, tool use, and multiple attempts.\nThis beats prior work by Phuong et al. 2024 (29%) and Abramovich et al. 2024\n(72%).\n  Our results suggest that current LLMs have surpassed the high school level in\noffensive cybersecurity. Their hacking capabilities remain underelicited: our\nReAct&Plan prompting strategy solves many challenges in 1-2 turns without\ncomplex engineering or advanced harnessing.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02776v1",
    "published_date": "2024-12-03 19:17:45 UTC",
    "updated_date": "2024-12-03 19:17:45 UTC"
  },
  {
    "arxiv_id": "2412.02775v1",
    "title": "Optimizing Large Language Models for Turkish: New Methodologies in Corpus Selection and Training",
    "authors": [
      "H. Toprak Kesgin",
      "M. Kaan Yuce",
      "Eren Dogan",
      "M. Egemen Uzun",
      "Atahan Uz",
      "Elif Ince",
      "Yusuf Erdem",
      "Osama Shbib",
      "Ahmed Zeer",
      "M. Fatih Amasyali"
    ],
    "abstract": "In this study, we develop and assess new corpus selection and training\nmethodologies to improve the effectiveness of Turkish language models.\nSpecifically, we adapted Large Language Model generated datasets and translated\nEnglish datasets into Turkish, integrating these resources into the training\nprocess. This approach led to substantial enhancements in model accuracy for\nboth few-shot and zero-shot learning scenarios. Furthermore, the merging of\nthese adapted models was found to markedly improve their performance. Human\nevaluative metrics, including task-specific performance assessments, further\ndemonstrated that these adapted models possess a greater aptitude for\ncomprehending the Turkish language and addressing logic-based queries. This\nresearch underscores the importance of refining corpus selection strategies to\noptimize the performance of multilingual models, particularly for\nunder-resourced languages like Turkish.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "2024 Innovations in Intelligent Systems and Applications Conference\n  (ASYU)",
    "pdf_url": "http://arxiv.org/pdf/2412.02775v1",
    "published_date": "2024-12-03 19:17:18 UTC",
    "updated_date": "2024-12-03 19:17:18 UTC"
  },
  {
    "arxiv_id": "2412.02764v2",
    "title": "Drawing Pandas: A Benchmark for LLMs in Generating Plotting Code",
    "authors": [
      "Timur Galimzyanov",
      "Sergey Titov",
      "Yaroslav Golubev",
      "Egor Bogomolov"
    ],
    "abstract": "This paper introduces the human-curated PandasPlotBench dataset, designed to\nevaluate language models' effectiveness as assistants in visual data\nexploration. Our benchmark focuses on generating code for visualizing tabular\ndata - such as a Pandas DataFrame - based on natural language instructions,\ncomplementing current evaluation tools and expanding their scope. The dataset\nincludes 175 unique tasks. Our experiments assess several leading Large\nLanguage Models (LLMs) across three visualization libraries: Matplotlib,\nSeaborn, and Plotly. We show that the shortening of tasks has a minimal effect\non plotting capabilities, allowing for the user interface that accommodates\nconcise user input without sacrificing functionality or accuracy. Another of\nour findings reveals that while LLMs perform well with popular libraries like\nMatplotlib and Seaborn, challenges persist with Plotly, highlighting areas for\nimprovement. We hope that the modular design of our benchmark will broaden the\ncurrent studies on generating visualizations. Our dataset and benchmark code\nare available online:\nhttps://huggingface.co/datasets/JetBrains-Research/PandasPlotBench;\nhttps://github.com/JetBrains-Research/PandasPlotBench.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.02764v2",
    "published_date": "2024-12-03 19:05:37 UTC",
    "updated_date": "2025-02-26 16:52:21 UTC"
  },
  {
    "arxiv_id": "2412.02760v1",
    "title": "Cosmos-LLaVA: Chatting with the Visual Cosmos-LLaVA: Görselle Sohbet Etmek",
    "authors": [
      "Ahmed Zeer",
      "Eren Dogan",
      "Yusuf Erdem",
      "Elif Ince",
      "Osama Shbib",
      "M. Egemen Uzun",
      "Atahan Uz",
      "M. Kaan Yuce",
      "H. Toprak Kesgin",
      "M. Fatih Amasyali"
    ],
    "abstract": "In this study, a Turkish visual instruction model was developed and various\nmodel architectures and dataset combinations were analysed to improve the\nperformance of this model. The Cosmos-LLaVA model, which is built by combining\ndifferent large language models and image coders, is designed to overcome the\ndeficiencies in the Turkish language. In the experiments, the effects of\nfine-tuning with various datasets on the model performance are analysed in\ndetail. The results show that model architecture and dataset selection have a\nsignificant impact on performance.\n  Bu \\c{c}al{\\i}\\c{s}mada bir T\\\"urk\\c{c}e g\\\"orsel talimat modeli\ngeli\\c{s}tirilerek bu modelin performans{\\i}n{\\i} art{\\i}rmaya y\\\"onelik\n\\c{c}e\\c{s}itli model mimarileri ve veri k\\\"umesi kombinasyonlar{\\i}\nderinlemesine incelenmi\\c{s}tir. Farkl{\\i} b\\\"uy\\\"uk dil modelleri ve\ng\\\"or\\\"unt\\\"u kodlay{\\i}c{\\i}lar{\\i}n{\\i}n bir araya getirilmesiyle\nolu\\c{s}turulan Cosmos-LLaVA modeli, T\\\"urk\\c{c}e dilindeki eksiklikleri\ngidermeye y\\\"onelik olarak tasarlanm{\\i}\\c{s}t{\\i}r. Yap{\\i}lan deneylerde,\n\\c{c}e\\c{s}itli veri k\\\"umeleri ile yap{\\i}lan ince ayarlar{\\i}n model\nperformans{\\i}n{\\i} nas{\\i}l etkiledi\\u{g}i detayl{\\i} olarak ele\nal{\\i}nm{\\i}\\c{s}t{\\i}r. Sonu\\c{c}lar, model mimarisi ve veri k\\\"umesi\nse\\c{c}iminin performans \\\"uzerinde \\\"onemli bir etkiye sahip oldu\\u{g}unu\ng\\\"ostermektedir.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "in Turkish language, 2024 8th International Artificial Intelligence\n  and Data Processing Symposium (IDAP)",
    "pdf_url": "http://arxiv.org/pdf/2412.02760v1",
    "published_date": "2024-12-03 19:01:00 UTC",
    "updated_date": "2024-12-03 19:01:00 UTC"
  },
  {
    "arxiv_id": "2412.02698v1",
    "title": "Scaling BERT Models for Turkish Automatic Punctuation and Capitalization Correction",
    "authors": [
      "Abdulkader Saoud",
      "Mahmut Alomeyr",
      "Himmet Toprak Kesgin",
      "Mehmet Fatih Amasyali"
    ],
    "abstract": "This paper investigates the effectiveness of BERT based models for automated\npunctuation and capitalization corrections in Turkish texts across five\ndistinct model sizes. The models are designated as Tiny, Mini, Small, Medium,\nand Base. The design and capabilities of each model are tailored to address the\nspecific challenges of the Turkish language, with a focus on optimizing\nperformance while minimizing computational overhead. The study presents a\nsystematic comparison of the performance metrics precision, recall, and F1\nscore of each model, offering insights into their applicability in diverse\noperational contexts. The results demonstrate a significant improvement in text\nreadability and accuracy as model size increases, with the Base model achieving\nthe highest correction precision. This research provides a comprehensive guide\nfor selecting the appropriate model size based on specific user needs and\ncomputational resources, establishing a framework for deploying these models in\nreal-world applications to enhance the quality of written Turkish.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "2024 Innovations in Intelligent Systems and Applications Conference\n  (ASYU)",
    "pdf_url": "http://arxiv.org/pdf/2412.02698v1",
    "published_date": "2024-12-03 18:59:51 UTC",
    "updated_date": "2024-12-03 18:59:51 UTC"
  },
  {
    "arxiv_id": "2412.02692v2",
    "title": "Scalable Image Tokenization with Index Backpropagation Quantization",
    "authors": [
      "Fengyuan Shi",
      "Zhuoyan Luo",
      "Yixiao Ge",
      "Yujiu Yang",
      "Ying Shan",
      "Limin Wang"
    ],
    "abstract": "Existing vector quantization (VQ) methods struggle with scalability, largely\nattributed to the instability of the codebook that undergoes partial updates\nduring training. The codebook is prone to collapse as utilization decreases,\ndue to the progressively widening distribution gap between non-activated codes\nand visual features. To solve the problem, we propose Index Backpropagation\nQuantization (IBQ), a new VQ method for the joint optimization of all codebook\nembeddings and the visual encoder. Applying a straight-through estimator on the\none-hot categorical distribution between the encoded feature and codebook, all\ncodes are differentiable and maintain a consistent latent space with the visual\nencoder. IBQ enables scalable training of visual tokenizers and, for the first\ntime, achieves a large-scale codebook ($2^{18}$) with high dimension ($256$)\nand high utilization. Experiments on the standard ImageNet benchmark\ndemonstrate the scalability and superiority of IBQ, achieving competitive\nresults on reconstruction and the application of autoregressive visual\ngeneration. The code and models are available at\nhttps://github.com/TencentARC/SEED-Voken.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02692v2",
    "published_date": "2024-12-03 18:59:10 UTC",
    "updated_date": "2025-03-10 09:01:48 UTC"
  },
  {
    "arxiv_id": "2412.02685v1",
    "title": "T-REG: Preference Optimization with Token-Level Reward Regularization",
    "authors": [
      "Wenxuan Zhou",
      "Shujian Zhang",
      "Lingxiao Zhao",
      "Tao Meng"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has been crucial in\naligning large language models (LLMs) with human values. Traditionally, RLHF\ninvolves generating responses to a query and using a reward model to assign a\nreward to the entire response. However, this approach faces challenges due to\nits reliance on a single, sparse reward, which makes it challenging for the\nmodel to identify which parts of the sequence contribute most significantly to\nthe final reward. Recent methods have attempted to address this limitation by\nintroducing token-level rewards. However, these methods often rely on either a\ntrained credit assignment model or AI annotators, raising concerns about the\nquality and reliability of the rewards. In this paper, we propose token-level\nreward regularization (T-REG), a novel approach that leverages both\nsequence-level and token-level rewards for preference optimization. Harnessing\nthe self-refinement capabilities of LLMs, our method uses contrastive prompting\nto enable LLMs to self-generate token-level rewards. These self-generated\nrewards then act as reward regularization, guiding the model to more\neffectively distribute sequence-level rewards across tokens. This facilitates\nbetter token-level credit assignment and enhances alignment performance.\nExperiments on the instruction following benchmarks, including Alpaca Eval 2\nand Arena-Hard, show that our method consistently outperforms baseline methods\nby up to 3.8% and 4.4%, respectively. We will release the code and models at\nhttps://github.com/wzhouad/T-REG.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02685v1",
    "published_date": "2024-12-03 18:56:07 UTC",
    "updated_date": "2024-12-03 18:56:07 UTC"
  },
  {
    "arxiv_id": "2412.02684v1",
    "title": "AniGS: Animatable Gaussian Avatar from a Single Image with Inconsistent Gaussian Reconstruction",
    "authors": [
      "Lingteng Qiu",
      "Shenhao Zhu",
      "Qi Zuo",
      "Xiaodong Gu",
      "Yuan Dong",
      "Junfei Zhang",
      "Chao Xu",
      "Zhe Li",
      "Weihao Yuan",
      "Liefeng Bo",
      "Guanying Chen",
      "Zilong Dong"
    ],
    "abstract": "Generating animatable human avatars from a single image is essential for\nvarious digital human modeling applications. Existing 3D reconstruction methods\noften struggle to capture fine details in animatable models, while generative\napproaches for controllable animation, though avoiding explicit 3D modeling,\nsuffer from viewpoint inconsistencies in extreme poses and computational\ninefficiencies. In this paper, we address these challenges by leveraging the\npower of generative models to produce detailed multi-view canonical pose\nimages, which help resolve ambiguities in animatable human reconstruction. We\nthen propose a robust method for 3D reconstruction of inconsistent images,\nenabling real-time rendering during inference. Specifically, we adapt a\ntransformer-based video generation model to generate multi-view canonical pose\nimages and normal maps, pretraining on a large-scale video dataset to improve\ngeneralization. To handle view inconsistencies, we recast the reconstruction\nproblem as a 4D task and introduce an efficient 3D modeling approach using 4D\nGaussian Splatting. Experiments demonstrate that our method achieves\nphotorealistic, real-time animation of 3D human avatars from in-the-wild\nimages, showcasing its effectiveness and generalization capability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://lingtengqiu.github.io/2024/AniGS/",
    "pdf_url": "http://arxiv.org/pdf/2412.02684v1",
    "published_date": "2024-12-03 18:55:39 UTC",
    "updated_date": "2024-12-03 18:55:39 UTC"
  },
  {
    "arxiv_id": "2412.02682v1",
    "title": "The Asymptotic Behavior of Attention in Transformers",
    "authors": [
      "Álvaro Rodríguez Abella",
      "João Pedro Silvestre",
      "Paulo Tabuada"
    ],
    "abstract": "A key component of transformers is the attention mechanism orchestrating how\neach token influences the propagation of every other token through a\ntransformer. In this paper we provide a rigorous, mathematical analysis of the\nasymptotic properties of attention in transformers. Although we present several\nresults based on different assumptions, all of them point to the same\nconclusion, all tokens asymptotically converge to each other, a phenomenon that\nhas been empirically reported in the literature. Our findings are carefully\ncompared with existing theoretical results and illustrated by simulations and\nexperimental studies using the GPT-2 model.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "math.DS",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02682v1",
    "published_date": "2024-12-03 18:54:49 UTC",
    "updated_date": "2024-12-03 18:54:49 UTC"
  },
  {
    "arxiv_id": "2412.02659v2",
    "title": "Adaptive Informed Deep Neural Networks for Power Flow Analysis",
    "authors": [
      "Zeynab Kaseb",
      "Stavros Orfanoudakis",
      "Pedro P. Vergara",
      "Peter Palensky"
    ],
    "abstract": "This study introduces PINN4PF, an end-to-end deep learning architecture for\npower flow (PF) analysis that effectively captures the nonlinear dynamics of\nlarge-scale modern power systems. The proposed neural network (NN) architecture\nconsists of two important advancements in the training pipeline: (A) a\ndouble-head feed-forward NN that aligns with PF analysis, including an\nactivation function that adjusts to the net active and reactive power\ninjections patterns, and (B) a physics-based loss function that partially\nincorporates power system topology information. The effectiveness of the\nproposed architecture is illustrated through 4-bus, 15-bus, 290-bus, and\n2224-bus test systems and is evaluated against two baselines: a linear\nregression model (LR) and a black-box NN (MLP). The comparison is based on (i)\ngeneralization ability, (ii) robustness, (iii) impact of training dataset size\non generalization ability, (iv) accuracy in approximating derived PF quantities\n(specifically line current, line active power, and line reactive power), and\n(v) scalability. Results demonstrate that PINN4PF outperforms both baselines\nacross all test systems by up to two orders of magnitude not only in terms of\ndirect criteria, e.g., generalization ability, but also in terms of\napproximating derived physical quantities.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "eess.SP"
    ],
    "primary_category": "eess.SY",
    "comment": "10 pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.02659v2",
    "published_date": "2024-12-03 18:33:48 UTC",
    "updated_date": "2025-05-03 19:28:39 UTC"
  },
  {
    "arxiv_id": "2412.02653v1",
    "title": "Scaffold or Crutch? Examining College Students' Use and Views of Generative AI Tools for STEM Education",
    "authors": [
      "Karen D. Wang",
      "Zhangyang Wu",
      "L'Nard Tufts II",
      "Carl Wieman",
      "Shima Salehi",
      "Nick Haber"
    ],
    "abstract": "Developing problem-solving competency is central to Science, Technology,\nEngineering, and Mathematics (STEM) education, yet translating this priority\ninto effective approaches to problem-solving instruction and assessment remain\na significant challenge. The recent proliferation of generative artificial\nintelligence (genAI) tools like ChatGPT in higher education introduces new\nconsiderations about how these tools can help or hinder students' development\nof STEM problem-solving competency. Our research examines these considerations\nby studying how and why college students use genAI tools in their STEM\ncoursework, focusing on their problem-solving support. We surveyed 40 STEM\ncollege students from diverse U.S. institutions and 28 STEM faculty to\nunderstand instructor perspectives on effective genAI tool use and guidance in\nSTEM courses. Our findings reveal high adoption rates and diverse applications\nof genAI tools among STEM students. The most common use cases include finding\nexplanations, exploring related topics, summarizing readings, and helping with\nproblem-set questions. The primary motivation for using genAI tools was to save\ntime. Moreover, over half of student participants reported simply inputting\nproblems for AI to generate solutions, potentially bypassing their own\nproblem-solving processes. These findings indicate that despite high adoption\nrates, students' current approaches to utilizing genAI tools often fall short\nin enhancing their own STEM problem-solving competencies. The study also\nexplored students' and STEM instructors' perceptions of the benefits and risks\nassociated with using genAI tools in STEM education. Our findings provide\ninsights into how to guide students on appropriate genAI use in STEM courses\nand how to design genAI-based tools to foster students' problem-solving\ncompetency.",
    "categories": [
      "physics.ed-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ed-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02653v1",
    "published_date": "2024-12-03 18:27:40 UTC",
    "updated_date": "2024-12-03 18:27:40 UTC"
  },
  {
    "arxiv_id": "2412.02638v1",
    "title": "QA-TOOLBOX: Conversational Question-Answering for process task guidance in manufacturing",
    "authors": [
      "Ramesh Manuvinakurike",
      "Elizabeth Watkins",
      "Celal Savur",
      "Anthony Rhodes",
      "Sovan Biswas",
      "Gesem Gudino Mejia",
      "Richard Beckwith",
      "Saurav Sahay",
      "Giuseppe Raffa",
      "Lama Nachman"
    ],
    "abstract": "In this work we explore utilizing LLMs for data augmentation for\nmanufacturing task guidance system. The dataset consists of representative\nsamples of interactions with technicians working in an advanced manufacturing\nsetting. The purpose of this work to explore the task, data augmentation for\nthe supported tasks and evaluating the performance of the existing LLMs. We\nobserve that that task is complex requiring understanding from procedure\nspecification documents, actions and objects sequenced temporally. The dataset\nconsists of 200,000+ question/answer pairs that refer to the spec document and\nare grounded in narrations and/or video demonstrations. We compared the\nperformance of several popular open-sourced LLMs by developing a baseline using\neach LLM and then compared the responses in a reference-free setting using\nLLM-as-a-judge and compared the ratings with crowd-workers whilst validating\nthe ratings with experts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02638v1",
    "published_date": "2024-12-03 18:10:31 UTC",
    "updated_date": "2024-12-03 18:10:31 UTC"
  },
  {
    "arxiv_id": "2412.02632v2",
    "title": "Scaling Image Tokenizers with Grouped Spherical Quantization",
    "authors": [
      "Jiangtao Wang",
      "Zhen Qin",
      "Yifan Zhang",
      "Vincent Tao Hu",
      "Björn Ommer",
      "Rania Briq",
      "Stefan Kesselheim"
    ],
    "abstract": "Vision tokenizers have gained a lot of attraction due to their scalability\nand compactness; previous works depend on old-school GAN-based hyperparameters,\nbiased comparisons, and a lack of comprehensive analysis of the scaling\nbehaviours. To tackle those issues, we introduce Grouped Spherical Quantization\n(GSQ), featuring spherical codebook initialization and lookup regularization to\nconstrain codebook latent to a spherical surface. Our empirical analysis of\nimage tokenizer training strategies demonstrates that GSQ-GAN achieves superior\nreconstruction quality over state-of-the-art methods with fewer training\niterations, providing a solid foundation for scaling studies. Building on this,\nwe systematically examine the scaling behaviours of GSQ, specifically in latent\ndimensionality, codebook size, and compression ratios, and their impact on\nmodel performance. Our findings reveal distinct behaviours at high and low\nspatial compression levels, underscoring challenges in representing\nhigh-dimensional latent spaces. We show that GSQ can restructure\nhigh-dimensional latent into compact, low-dimensional spaces, thus enabling\nefficient scaling with improved quality. As a result, GSQ-GAN achieves a 16x\ndown-sampling with a reconstruction FID (rFID) of 0.50.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02632v2",
    "published_date": "2024-12-03 18:01:45 UTC",
    "updated_date": "2024-12-04 05:02:45 UTC"
  },
  {
    "arxiv_id": "2412.02626v3",
    "title": "Time-Reversal Provides Unsupervised Feedback to LLMs",
    "authors": [
      "Yerram Varun",
      "Rahul Madhavan",
      "Sravanti Addepalli",
      "Arun Suggala",
      "Karthikeyan Shanmugam",
      "Prateek Jain"
    ],
    "abstract": "Large Language Models (LLMs) are typically trained to predict in the forward\ndirection of time. However, recent works have shown that prompting these models\nto look back and critique their own generations can produce useful feedback.\nMotivated by this, we explore the question of whether LLMs can be empowered to\nthink (predict and score) backwards to provide unsupervised feedback that\ncomplements forward LLMs. Towards this, we introduce Time Reversed Language\nModels (TRLMs), which can score and generate queries when conditioned on\nresponses, effectively functioning in the reverse direction of time. Further,\nto effectively infer in the response to query direction, we pre-train and\nfine-tune a language model (TRLM-Ba) in the reverse token order from scratch.\nWe show empirically (and theoretically in a stylized setting) that\ntime-reversed models can indeed complement forward model predictions when used\nto score the query given response for re-ranking multiple forward generations.\nWe obtain up to 5\\% improvement on the widely used AlpacaEval Leaderboard over\nthe competent baseline of best-of-N re-ranking using self log-perplexity\nscores. We further show that TRLM scoring outperforms conventional forward\nscoring of response given query, resulting in significant gains in applications\nsuch as citation generation and passage retrieval. We next leverage the\ngenerative ability of TRLM to augment or provide unsupervised feedback to input\nsafety filters of LLMs, demonstrating a drastic reduction in false negative\nrate with negligible impact on false positive rates against several attacks\npublished on the popular JailbreakBench leaderboard.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as a spotlight in NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.02626v3",
    "published_date": "2024-12-03 17:54:12 UTC",
    "updated_date": "2025-02-02 22:13:29 UTC"
  },
  {
    "arxiv_id": "2412.02621v1",
    "title": "Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions",
    "authors": [
      "Kai Sun",
      "Siyan Xue",
      "Fuchun Sun",
      "Haoran Sun",
      "Yu Luo",
      "Ling Wang",
      "Siyuan Wang",
      "Na Guo",
      "Lei Liu",
      "Tian Zhao",
      "Xinzhou Wang",
      "Lei Yang",
      "Shuo Jin",
      "Jun Yan",
      "Jiahong Dong"
    ],
    "abstract": "Recent advancements in deep learning have significantly revolutionized the\nfield of clinical diagnosis and treatment, offering novel approaches to improve\ndiagnostic precision and treatment efficacy across diverse clinical domains,\nthus driving the pursuit of precision medicine. The growing availability of\nmulti-organ and multimodal datasets has accelerated the development of\nlarge-scale Medical Multimodal Foundation Models (MMFMs). These models, known\nfor their strong generalization capabilities and rich representational power,\nare increasingly being adapted to address a wide range of clinical tasks, from\nearly diagnosis to personalized treatment strategies. This review offers a\ncomprehensive analysis of recent developments in MMFMs, focusing on three key\naspects: datasets, model architectures, and clinical applications. We also\nexplore the challenges and opportunities in optimizing multimodal\nrepresentations and discuss how these advancements are shaping the future of\nhealthcare by enabling improved patient outcomes and more efficient clinical\nworkflows.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02621v1",
    "published_date": "2024-12-03 17:50:19 UTC",
    "updated_date": "2024-12-03 17:50:19 UTC"
  },
  {
    "arxiv_id": "2412.02617v1",
    "title": "Improving Dynamic Object Interactions in Text-to-Video Generation with AI Feedback",
    "authors": [
      "Hiroki Furuta",
      "Heiga Zen",
      "Dale Schuurmans",
      "Aleksandra Faust",
      "Yutaka Matsuo",
      "Percy Liang",
      "Sherry Yang"
    ],
    "abstract": "Large text-to-video models hold immense potential for a wide range of\ndownstream applications. However, these models struggle to accurately depict\ndynamic object interactions, often resulting in unrealistic movements and\nfrequent violations of real-world physics. One solution inspired by large\nlanguage models is to align generated outputs with desired outcomes using\nexternal feedback. This enables the model to refine its responses autonomously,\neliminating extensive manual data collection. In this work, we investigate the\nuse of feedback to enhance the object dynamics in text-to-video models. We aim\nto answer a critical question: what types of feedback, paired with which\nspecific self-improvement algorithms, can most effectively improve text-video\nalignment and realistic object interactions? We begin by deriving a unified\nprobabilistic objective for offline RL finetuning of text-to-video models. This\nperspective highlights how design elements in existing algorithms like KL\nregularization and policy projection emerge as specific choices within a\nunified framework. We then use derived methods to optimize a set of text-video\nalignment metrics (e.g., CLIP scores, optical flow), but notice that they often\nfail to align with human perceptions of generation quality. To address this\nlimitation, we propose leveraging vision-language models to provide more\nnuanced feedback specifically tailored to object dynamics in videos. Our\nexperiments demonstrate that our method can effectively optimize a wide variety\nof rewards, with binary AI feedback driving the most significant improvements\nin video quality for dynamic interactions, as confirmed by both AI and human\nevaluations. Notably, we observe substantial gains when using reward signals\nderived from AI feedback, particularly in scenarios involving complex\ninteractions between multiple objects and realistic depictions of objects\nfalling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Website: https://sites.google.com/view/aif-dynamic-t2v/",
    "pdf_url": "http://arxiv.org/pdf/2412.02617v1",
    "published_date": "2024-12-03 17:44:23 UTC",
    "updated_date": "2024-12-03 17:44:23 UTC"
  },
  {
    "arxiv_id": "2412.02615v1",
    "title": "Projection Abstractions in Planning Under the Lenses of Abstractions for MDPs",
    "authors": [
      "Giuseppe Canonaco",
      "Alberto Pozanco",
      "Daniel Borrajo"
    ],
    "abstract": "The concept of abstraction has been independently developed both in the\ncontext of AI Planning and discounted Markov Decision Processes (MDPs).\nHowever, the way abstractions are built and used in the context of Planning and\nMDPs is different even though lots of commonalities can be highlighted. To this\nday there is no work trying to relate and unify the two fields on the matter of\nabstractions unraveling all the different assumptions and their effect on the\nway they can be used. Therefore, in this paper we aim to do so by looking at\nprojection abstractions in Planning through the lenses of discounted MDPs.\nStarting from a projection abstraction built according to Classical or\nProbabilistic Planning techniques, we will show how the same abstraction can be\nobtained under the abstraction frameworks available for discounted MDPs. Along\nthe way, we will focus on computational as well as representational advantages\nand disadvantages of both worlds pointing out new research directions that are\nof interest for both fields.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02615v1",
    "published_date": "2024-12-03 17:43:28 UTC",
    "updated_date": "2024-12-03 17:43:28 UTC"
  },
  {
    "arxiv_id": "2412.02611v1",
    "title": "AV-Odyssey Bench: Can Your Multimodal LLMs Really Understand Audio-Visual Information?",
    "authors": [
      "Kaixiong Gong",
      "Kaituo Feng",
      "Bohao Li",
      "Yibing Wang",
      "Mofan Cheng",
      "Shijia Yang",
      "Jiaming Han",
      "Benyou Wang",
      "Yutong Bai",
      "Zhuoran Yang",
      "Xiangyu Yue"
    ],
    "abstract": "Recently, multimodal large language models (MLLMs), such as GPT-4o, Gemini\n1.5 Pro, and Reka Core, have expanded their capabilities to include vision and\naudio modalities. While these models demonstrate impressive performance across\na wide range of audio-visual applications, our proposed DeafTest reveals that\nMLLMs often struggle with simple tasks humans find trivial: 1) determining\nwhich of two sounds is louder, and 2) determining which of two sounds has a\nhigher pitch. Motivated by these observations, we introduce AV-Odyssey Bench, a\ncomprehensive audio-visual benchmark designed to assess whether those MLLMs can\ntruly understand the audio-visual information. This benchmark encompasses 4,555\ncarefully crafted problems, each incorporating text, visual, and audio\ncomponents. To successfully infer answers, models must effectively leverage\nclues from both visual and audio inputs. To ensure precise and objective\nevaluation of MLLM responses, we have structured the questions as\nmultiple-choice, eliminating the need for human evaluation or LLM-assisted\nassessment. We benchmark a series of closed-source and open-source models and\nsummarize the observations. By revealing the limitations of current models, we\naim to provide useful insight for future dataset collection and model\ndevelopment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://av-odyssey.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.02611v1",
    "published_date": "2024-12-03 17:41:23 UTC",
    "updated_date": "2024-12-03 17:41:23 UTC"
  },
  {
    "arxiv_id": "2412.02610v1",
    "title": "AI-Driven Resource Allocation Framework for Microservices in Hybrid Cloud Platforms",
    "authors": [
      "Biman Barua",
      "M. Shamim Kaiser"
    ],
    "abstract": "The increasing demand for scalable, efficient resource management in hybrid\ncloud environments has led to the exploration of AI-driven approaches for\ndynamic resource allocation. This paper presents an AI-driven framework for\nresource allocation among microservices in hybrid cloud platforms. The\nframework employs reinforcement learning (RL)-based resource utilization\noptimization to reduce costs and improve performance. The framework integrates\nAI models with cloud management tools to respond to challenges of dynamic\nscaling and cost-efficient low-latency service delivery. The reinforcement\nlearning model continuously adjusts provisioned resources as required by the\nmicroservices and predicts the future consumption trends to minimize both\nunder- and over-provisioning of resources. Preliminary simulation results\nindicate that using AI in the provision of resources related to costs can\nreduce expenditure by up to 30-40% compared to manual provisioning and\nthreshold-based auto-scaling approaches. It is also estimated that the\nefficiency in resource utilization is expected to improve by 20%-30% with a\ncorresponding latency cut of 15%-20% during the peak demand periods. This study\ncompares the AI-driven approach with existing static and rule-based resource\nallocation methods, demonstrating the capability of this new model to\noutperform them in terms of flexibility and real-time interests. The results\nindicate that reinforcement learning can make optimization of hybrid cloud\nplatforms even better, offering a 25-35% improvement in cost efficiency and the\npower of scaling for microservice-based applications. The proposed framework is\na strong and scalable solution to managing cloud resources in dynamic and\nperformance-critical environments.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.PF",
      "cs.SE",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02610v1",
    "published_date": "2024-12-03 17:41:08 UTC",
    "updated_date": "2024-12-03 17:41:08 UTC"
  },
  {
    "arxiv_id": "2412.02602v1",
    "title": "CEGI: Measuring the trade-off between efficiency and carbon emissions for SLMs and VLMs",
    "authors": [
      "Abhas Kumar",
      "Kapil Pathak",
      "Rajesh Kavuru",
      "Prabhakar Srinivasan"
    ],
    "abstract": "This paper analyzes the performance of Small Language Models (SLMs) and\nVision Language Models (VLMs) and evaluates the trade-off between model\nperformance and carbon emissions across 4 essential tasks: Image Captioning,\nVisual Question Answering (VQA), Dialogue Summarization and Text-to-SQL\nconversion. Various SLMs and VLMs belonging to the Qwen and LLaMA architecture\nfamily are chosen and variants based on model size in terms of the number of\nparameters, quantization level and fine-tuning parameters are evaluated. The\nmodel variant's performance and carbon emissions are calculated. To quantify\nthe trade-off between model performance and carbon emissions, we introduce a\nnovel metric called CEGI (Carbon Efficient Gain Index). This metric represents\nthe carbon emission per unit percentage gain per million trainable parameters .\nThis metric provides a normalized measure to compare model's efficiency in\nterms of performance improvement relative to their environmental cost. The\nexperiment's outcome demonstrates that fine-tuning SLMs and VLMs can achieve\nperformance levels comparable to Large Language Models (LLMs) while producing\nsignificantly less carbon emissions. Our findings suggest that the marginal\ngains in accuracy from larger models do not justify the substantial increase in\ncarbon emissions. Leveraging lower-bit quantization levels, the proposed metric\nfurther enhances energy efficiency without compromising performance. This study\nhighlights balancing high performance and environmental sustainability. It\noffers a valuable metric for selecting models suitable for\nenvironmentally-friendly AI development.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02602v1",
    "published_date": "2024-12-03 17:32:47 UTC",
    "updated_date": "2024-12-03 17:32:47 UTC"
  },
  {
    "arxiv_id": "2412.02594v1",
    "title": "PrefixLLM: LLM-aided Prefix Circuit Design",
    "authors": [
      "Weihua Xiao",
      "Venkata Sai Charan Putrevu",
      "Raghu Vamshi Hemadri",
      "Siddharth Garg",
      "Ramesh Karri"
    ],
    "abstract": "Prefix circuits are fundamental components in digital adders, widely used in\ndigital systems due to their efficiency in calculating carry signals.\nSynthesizing prefix circuits with minimized area and delay is crucial for\nenhancing the performance of modern computing systems. Recently, large language\nmodels (LLMs) have demonstrated a surprising ability to perform text generation\ntasks. We propose PrefixLLM, that leverages LLMs for prefix circuit synthesis.\nPrefixLLM transforms the prefix circuit synthesis task into a structured text\ngeneration problem, termed the Structured Prefix Circuit Representation (SPCR),\nand introduces an iterative framework to automatically and accurately generate\nvalid SPCRs. We further present a design space exploration (DSE) framework that\nuses LLMs to iteratively search for area and delay optimized prefix circuits.\nCompared to state-of-the-art, PrefixLLM can reduce the area by 3.70% under the\nsame delay constraint. This work highlights the use of LLMs in the synthesis of\narithmetic circuits, which can be transformed into the structured text\ngeneration.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02594v1",
    "published_date": "2024-12-03 17:26:42 UTC",
    "updated_date": "2024-12-03 17:26:42 UTC"
  },
  {
    "arxiv_id": "2412.02588v1",
    "title": "Explainable CTR Prediction via LLM Reasoning",
    "authors": [
      "Xiaohan Yu",
      "Li Zhang",
      "Chong Chen"
    ],
    "abstract": "Recommendation Systems have become integral to modern user experiences, but\nlack transparency in their decision-making processes. Existing explainable\nrecommendation methods are hindered by reliance on a post-hoc paradigm, wherein\nexplanation generators are trained independently of the underlying recommender\nmodels. This paradigm necessitates substantial human effort in data\nconstruction and raises concerns about explanation reliability. In this paper,\nwe present ExpCTR, a novel framework that integrates large language model based\nexplanation generation directly into the CTR prediction process. Inspired by\nrecent advances in reinforcement learning, we employ two carefully designed\nreward mechanisms, LC alignment, which ensures explanations reflect user\nintentions, and IC alignment, which maintains consistency with traditional\nID-based CTR models. Our approach incorporates an efficient training paradigm\nwith LoRA and a three-stage iterative process. ExpCTR circumvents the need for\nextensive explanation datasets while fostering synergy between CTR prediction\nand explanation generation. Experimental results demonstrate that ExpCTR\nsignificantly enhances both recommendation accuracy and interpretability across\nthree real-world datasets.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "WSDM 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02588v1",
    "published_date": "2024-12-03 17:17:27 UTC",
    "updated_date": "2024-12-03 17:17:27 UTC"
  },
  {
    "arxiv_id": "2412.02579v2",
    "title": "Factored space models: Towards causality between levels of abstraction",
    "authors": [
      "Scott Garrabrant",
      "Matthias Georg Mayer",
      "Magdalena Wache",
      "Leon Lang",
      "Sam Eisenstat",
      "Holger Dell"
    ],
    "abstract": "Causality plays an important role in understanding intelligent behavior, and\nthere is a wealth of literature on mathematical models for causality, most of\nwhich is focused on causal graphs. Causal graphs are a powerful tool for a wide\nrange of applications, in particular when the relevant variables are known and\nat the same level of abstraction. However, the given variables can also be\nunstructured data, like pixels of an image. Meanwhile, the causal variables,\nsuch as the positions of objects in the image, can be arbitrary deterministic\nfunctions of the given variables. Moreover, the causal variables may form a\nhierarchy of abstractions, in which the macro-level variables are deterministic\nfunctions of the micro-level variables. Causal graphs are limited when it comes\nto modeling this kind of situation. In the presence of deterministic\nrelationships there is generally no causal graph that satisfies both the Markov\ncondition and the faithfulness condition. We introduce factored space models as\nan alternative to causal graphs which naturally represent both probabilistic\nand deterministic relationships at all levels of abstraction. Moreover, we\nintroduce structural independence and establish that it is equivalent to\nstatistical independence in every distribution that factorizes over the\nfactored space. This theorem generalizes the classical soundness and\ncompleteness theorem for d-separation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.02579v2",
    "published_date": "2024-12-03 17:04:20 UTC",
    "updated_date": "2024-12-20 18:38:53 UTC"
  },
  {
    "arxiv_id": "2412.02574v1",
    "title": "Generating Critical Scenarios for Testing Automated Driving Systems",
    "authors": [
      "Trung-Hieu Nguyen",
      "Truong-Giang Vuong",
      "Hong-Nam Duong",
      "Son Nguyen",
      "Hieu Dinh Vo",
      "Toshiaki Aoki",
      "Thu-Trang Nguyen"
    ],
    "abstract": "Autonomous vehicles (AVs) have demonstrated significant potential in\nrevolutionizing transportation, yet ensuring their safety and reliability\nremains a critical challenge, especially when exposed to dynamic and\nunpredictable environments. Real-world testing of an Autonomous Driving System\n(ADS) is both expensive and risky, making simulation-based testing a preferred\napproach. In this paper, we propose AVASTRA, a Reinforcement Learning\n(RL)-based approach to generate realistic critical scenarios for testing ADSs\nin simulation environments. To capture the complexity of driving scenarios,\nAVASTRA comprehensively represents the environment by both the internal states\nof an ADS under-test (e.g., the status of the ADS's core components, speed, or\nacceleration) and the external states of the surrounding factors in the\nsimulation environment (e.g., weather, traffic flow, or road condition).\nAVASTRA trains the RL agent to effectively configure the simulation environment\nthat places the AV in dangerous situations and potentially leads it to\ncollisions. We introduce a diverse set of actions that allows the RL agent to\nsystematically configure both environmental conditions and traffic\nparticipants. Additionally, based on established safety requirements, we\nenforce heuristic constraints to ensure the realism and relevance of the\ngenerated test scenarios. AVASTRA is evaluated on two popular simulation maps\nwith four different road configurations. Our results show AVASTRA's ability to\noutperform the state-of-the-art approach by generating 30% to 115% more\ncollision scenarios. Compared to the baseline based on Random Search, AVASTRA\nachieves up to 275% better performance. These results highlight the\neffectiveness of AVASTRA in enhancing the safety testing of AVs through\nrealistic comprehensive critical scenario generation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02574v1",
    "published_date": "2024-12-03 16:59:30 UTC",
    "updated_date": "2024-12-03 16:59:30 UTC"
  },
  {
    "arxiv_id": "2412.02570v1",
    "title": "TAB-Fields: A Maximum Entropy Framework for Mission-Aware Adversarial Planning",
    "authors": [
      "Gokul Puthumanaillam",
      "Jae Hyuk Song",
      "Nurzhan Yesmagambet",
      "Shinkyu Park",
      "Melkior Ornik"
    ],
    "abstract": "Autonomous agents operating in adversarial scenarios face a fundamental\nchallenge: while they may know their adversaries' high-level objectives, such\nas reaching specific destinations within time constraints, the exact policies\nthese adversaries will employ remain unknown. Traditional approaches address\nthis challenge by treating the adversary's state as a partially observable\nelement, leading to a formulation as a Partially Observable Markov Decision\nProcess (POMDP). However, the induced belief-space dynamics in a POMDP require\nknowledge of the system's transition dynamics, which, in this case, depend on\nthe adversary's unknown policy. Our key observation is that while an\nadversary's exact policy is unknown, their behavior is necessarily constrained\nby their mission objectives and the physical environment, allowing us to\ncharacterize the space of possible behaviors without assuming specific\npolicies. In this paper, we develop Task-Aware Behavior Fields (TAB-Fields), a\nrepresentation that captures adversary state distributions over time by\ncomputing the most unbiased probability distribution consistent with known\nconstraints. We construct TAB-Fields by solving a constrained optimization\nproblem that minimizes additional assumptions about adversary behavior beyond\nmission and environmental requirements. We integrate TAB-Fields with standard\nplanning algorithms by introducing TAB-conditioned POMCP, an adaptation of\nPartially Observable Monte Carlo Planning. Through experiments in simulation\nwith underwater robots and hardware implementations with ground robots, we\ndemonstrate that our approach achieves superior performance compared to\nbaselines that either assume specific adversary policies or neglect mission\nconstraints altogether. Evaluation videos and code are available at\nhttps://tab-fields.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02570v1",
    "published_date": "2024-12-03 16:55:27 UTC",
    "updated_date": "2024-12-03 16:55:27 UTC"
  },
  {
    "arxiv_id": "2412.02568v1",
    "title": "Segmentation of Coronary Artery Stenosis in X-ray Angiography using Mamba Models",
    "authors": [
      "Ali Rostami",
      "Fatemeh Fouladi",
      "Hedieh Sajedi"
    ],
    "abstract": "Coronary artery disease stands as one of the primary contributors to global\nmortality rates. The automated identification of coronary artery stenosis from\nX-ray images plays a critical role in the diagnostic process for coronary heart\ndisease. This task is challenging due to the complex structure of coronary\narteries, intrinsic noise in X-ray images, and the fact that stenotic coronary\narteries appear narrow and blurred in X-ray angiographies. This study employs\nfive different variants of the Mamba-based model and one variant of the Swin\nTransformer-based model, primarily based on the U-Net architecture, for the\nlocalization of stenosis in Coronary artery disease. Our best results showed an\nF1 score of 68.79% for the U-Mamba BOT model, representing an 11.8% improvement\nover the semi-supervised approach.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02568v1",
    "published_date": "2024-12-03 16:54:46 UTC",
    "updated_date": "2024-12-03 16:54:46 UTC"
  },
  {
    "arxiv_id": "2412.02563v1",
    "title": "Semantic Tokens in Retrieval Augmented Generation",
    "authors": [
      "Joel Suro"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) architectures have recently garnered\nsignificant attention for their ability to improve truth grounding and\ncoherence in natural language processing tasks. However, the reliability of RAG\nsystems in producing accurate answers diminishes as the volume of data they\naccess increases. Even with smaller datasets, these systems occasionally fail\nto address simple queries. This issue arises from their dependence on\nstate-of-the-art large language models (LLMs), which can introduce uncertainty\ninto the system's outputs. In this work, I propose a novel Comparative RAG\nsystem that introduces an evaluator module to bridge the gap between\nprobabilistic RAG systems and deterministically verifiable responses. The\nevaluator compares external recommendations with the retrieved document chunks,\nadding a decision-making layer that enhances the system's reliability. This\napproach ensures that the chunks retrieved are both semantically relevant and\nlogically consistent with deterministic insights, thereby improving the\naccuracy and overall efficiency of RAG systems. This framework paves the way\nfor more reliable and scalable question-answering applications in domains\nrequiring high precision and verifiability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02563v1",
    "published_date": "2024-12-03 16:52:06 UTC",
    "updated_date": "2024-12-03 16:52:06 UTC"
  },
  {
    "arxiv_id": "2412.02539v1",
    "title": "Graph-Powered Defense: Controller Area Network Intrusion Detection for Unmanned Aerial Vehicles",
    "authors": [
      "Reek Majumder",
      "Gurcan Comert",
      "David Werth",
      "Adrian Gale",
      "Mashrur Chowdhury",
      "M Sabbir Salek"
    ],
    "abstract": "The network of services, including delivery, farming, and environmental\nmonitoring, has experienced exponential expansion in the past decade with\nUnmanned Aerial Vehicles (UAVs). Yet, UAVs are not robust enough against\ncyberattacks, especially on the Controller Area Network (CAN) bus. The CAN bus\nis a general-purpose vehicle-bus standard to enable microcontrollers and\nin-vehicle computers to interact, primarily connecting different Electronic\nControl Units (ECUs). In this study, we focus on solving some of the most\ncritical security weaknesses in UAVs by developing a novel graph-based\nintrusion detection system (IDS) leveraging the Uncomplicated Application-level\nVehicular Communication and Networking (UAVCAN) protocol. First, we decode CAN\nmessages based on UAVCAN protocol specification; second, we present a\ncomprehensive method of transforming tabular UAVCAN messages into graph\nstructures. Lastly, we apply various graph-based machine learning models for\ndetecting cyber-attacks on the CAN bus, including graph convolutional neural\nnetworks (GCNNs), graph attention networks (GATs), Graph Sample and Aggregate\nNetworks (GraphSAGE), and graph structure-based transformers. Our findings show\nthat inductive models such as GATs, GraphSAGE, and graph-based transformers can\nachieve competitive and even better accuracy than transductive models like\nGCNNs in detecting various types of intrusions, with minimum information on\nprotocol specification, thus providing a generic robust solution for CAN bus\nsecurity for the UAVs. We also compared our results with baseline single-layer\nLong Short-Term Memory (LSTM) and found that all our graph-based models perform\nbetter without using any decoded features based on the UAVCAN protocol,\nhighlighting higher detection performance with protocol-independent capability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02539v1",
    "published_date": "2024-12-03 16:32:57 UTC",
    "updated_date": "2024-12-03 16:32:57 UTC"
  },
  {
    "arxiv_id": "2412.02730v2",
    "title": "Shaping AI's Impact on Billions of Lives",
    "authors": [
      "Mariano-Florentino Cuéllar",
      "Jeff Dean",
      "Finale Doshi-Velez",
      "John Hennessy",
      "Andy Konwinski",
      "Sanmi Koyejo",
      "Pelonomi Moiloa",
      "Emma Pierson",
      "David Patterson"
    ],
    "abstract": "Artificial Intelligence (AI), like any transformative technology, has the\npotential to be a double-edged sword, leading either toward significant\nadvancements or detrimental outcomes for society as a whole. As is often the\ncase when it comes to widely-used technologies in market economies (e.g., cars\nand semiconductor chips), commercial interest tends to be the predominant\nguiding factor. The AI community is at risk of becoming polarized to either\ntake a laissez-faire attitude toward AI development, or to call for government\noverregulation. Between these two poles we argue for the community of AI\npractitioners to consciously and proactively work for the common good. This\npaper offers a blueprint for a new type of innovation infrastructure including\n18 concrete milestones to guide AI research in that direction. Our view is that\nwe are still in the early days of practical AI, and focused efforts by\npractitioners, policymakers, and other stakeholders can still maximize the\nupsides of AI and minimize its downsides.\n  We talked to luminaries such as recent Nobelist John Jumper on science,\nPresident Barack Obama on governance, former UN Ambassador and former National\nSecurity Advisor Susan Rice on security, philanthropist Eric Schmidt on several\ntopics, and science fiction novelist Neal Stephenson on entertainment. This\nongoing dialogue and collaborative effort has produced a comprehensive,\nrealistic view of what the actual impact of AI could be, from a diverse\nassembly of thinkers with deep understanding of this technology and these\ndomains. From these exchanges, five recurring guidelines emerged, which form\nthe cornerstone of a framework for beginning to harness AI in service of the\npublic good. They not only guide our efforts in discovery but also shape our\napproach to deploying this transformative technology responsibly and ethically.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02730v2",
    "published_date": "2024-12-03 16:29:37 UTC",
    "updated_date": "2024-12-11 15:22:32 UTC"
  },
  {
    "arxiv_id": "2412.02530v1",
    "title": "WEM-GAN: Wavelet transform based facial expression manipulation",
    "authors": [
      "Dongya Sun",
      "Yunfei Hu",
      "Xianzhe Zhang",
      "Yingsong Hu"
    ],
    "abstract": "Facial expression manipulation aims to change human facial expressions\nwithout affecting face recognition. In order to transform the facial\nexpressions to target expressions, previous methods relied on expression labels\nto guide the manipulation process. However, these methods failed to preserve\nthe details of facial features, which causes the weakening or the loss of\nidentity information in the output image. In our work, we propose WEM-GAN, in\nshort for wavelet-based expression manipulation GAN, which puts more efforts on\npreserving the details of the original image in the editing process. Firstly,\nwe take advantage of the wavelet transform technique and combine it with our\ngenerator with a U-net autoencoder backbone, in order to improve the\ngenerator's ability to preserve more details of facial features. Secondly, we\nalso implement the high-frequency component discriminator, and use\nhigh-frequency domain adversarial loss to further constrain the optimization of\nour model, providing the generated face image with more abundant details.\nAdditionally, in order to narrow the gap between generated facial expressions\nand target expressions, we use residual connections between encoder and\ndecoder, while also using relative action units (AUs) several times. Extensive\nqualitative and quantitative experiments have demonstrated that our model\nperforms better in preserving identity features, editing capability, and image\ngeneration quality on the AffectNet dataset. It also shows superior performance\nin metrics such as Average Content Distance (ACD) and Expression Distance (ED).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02530v1",
    "published_date": "2024-12-03 16:23:02 UTC",
    "updated_date": "2024-12-03 16:23:02 UTC"
  },
  {
    "arxiv_id": "2412.02528v1",
    "title": "Bias Analysis of AI Models for Undergraduate Student Admissions",
    "authors": [
      "Kelly Van Busum",
      "Shiaofen Fang"
    ],
    "abstract": "Bias detection and mitigation is an active area of research in machine\nlearning. This work extends previous research done by the authors to provide a\nrigorous and more complete analysis of the bias found in AI predictive models.\nAdmissions data spanning six years was used to create an AI model to determine\nwhether a given student would be directly admitted into the School of Science\nunder various scenarios at a large urban research university. During this time,\nsubmission of standardized test scores as part of an application became\noptional which led to interesting questions about the impact of standardized\ntest scores on admission decisions. We developed and analyzed AI models to\nunderstand which variables are important in admissions decisions, and how the\ndecision to exclude test scores affects the demographics of the students who\nare admitted. We then evaluated the predictive models to detect and analyze\nbiases these models may carry with respect to three variables chosen to\nrepresent sensitive populations: gender, race, and whether a student was the\nfirst in his or her family to attend college. We also extended our analysis to\nshow that the biases detected were persistent. Finally, we included several\nfairness metrics in our analysis and discussed the uses and limitations of\nthese metrics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02528v1",
    "published_date": "2024-12-03 16:21:37 UTC",
    "updated_date": "2024-12-03 16:21:37 UTC"
  },
  {
    "arxiv_id": "2412.02520v3",
    "title": "Cooperative Cruising: Reinforcement Learning-Based Time-Headway Control for Increased Traffic Efficiency",
    "authors": [
      "Yaron Veksler",
      "Sharon Hornstein",
      "Han Wang",
      "Maria Laura Delle Monache",
      "Daniel Urieli"
    ],
    "abstract": "The proliferation of connected automated vehicles represents an unprecedented\nopportunity for improving driving efficiency and alleviating traffic\ncongestion. However, existing research fails to address realistic multi-lane\nhighway scenarios without assuming connectivity, perception, and control\ncapabilities that are typically unavailable in current vehicles. This paper\nproposes a novel AI system that is the first to improve highway traffic\nefficiency compared with human-like traffic in realistic, simulated multi-lane\nscenarios, while relying on existing connectivity, perception, and control\ncapabilities. At the core of our approach is a reinforcement learning based\ncontroller that dynamically communicates time-headways to automated vehicles\nnear bottlenecks based on real-time traffic conditions. These desired\ntime-headways are then used by adaptive cruise control (ACC) systems to adjust\ntheir following distance. By (i) integrating existing traffic estimation\ntechnology and low-bandwidth vehicle-to-infrastructure connectivity, (ii)\nleveraging safety-certified ACC systems, and (iii) targeting localized\nbottleneck challenges that can be addressed independently in different\nlocations, we propose a potentially practical, safe, and scalable system that\ncan positively impact numerous road users.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02520v3",
    "published_date": "2024-12-03 16:13:42 UTC",
    "updated_date": "2025-02-02 08:49:21 UTC"
  },
  {
    "arxiv_id": "2412.02509v2",
    "title": "FCL-ViT: Task-Aware Attention Tuning for Continual Learning",
    "authors": [
      "Anestis Kaimakamidis",
      "Ioannis Pitas"
    ],
    "abstract": "Continual Learning (CL) involves adapting the prior Deep Neural Network (DNN)\nknowledge to new tasks, without forgetting the old ones. However, modern CL\ntechniques focus on provisioning memory capabilities to existing DNN models\nrather than designing new ones that are able to adapt according to the task at\nhand. This paper presents the novel Feedback Continual Learning Vision\nTransformer (FCL-ViT) that uses a feedback mechanism to generate real-time\ndynamic attention features tailored to the current task. The FCL-ViT operates\nin two Phases. In phase 1, the generic image features are produced and\ndetermine where the Transformer should attend on the current image. In phase 2,\ntask-specific image features are generated that leverage dynamic attention. To\nthis end, Tunable self-Attention Blocks (TABs) and Task Specific Blocks (TSBs)\nare introduced that operate in both phases and are responsible for tuning the\nTABs attention, respectively. The FCL-ViT surpasses state-of-the-art\nperformance on Continual Learning compared to benchmark methods, while\nretaining a small number of trainable DNN parameters.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02509v2",
    "published_date": "2024-12-03 15:48:33 UTC",
    "updated_date": "2024-12-04 17:35:48 UTC"
  },
  {
    "arxiv_id": "2412.02508v2",
    "title": "Towards Rich Emotions in 3D Avatars: A Text-to-3D Avatar Generation Benchmark",
    "authors": [
      "Haidong Xu",
      "Meishan Zhang",
      "Hao Ju",
      "Zhedong Zheng",
      "Erik Cambria",
      "Min Zhang",
      "Hao Fei"
    ],
    "abstract": "Producing emotionally dynamic 3D facial avatars with text derived from spoken\nwords (Emo3D) has been a pivotal research topic in 3D avatar generation. While\nprogress has been made in general-purpose 3D avatar generation, the exploration\nof generating emotional 3D avatars remains scarce, primarily due to the\ncomplexities of identifying and rendering rich emotions from spoken words. This\npaper reexamines Emo3D generation and draws inspiration from human processes,\nbreaking down Emo3D into two cascading steps: Text-to-3D Expression Mapping\n(T3DEM) and 3D Avatar Rendering (3DAR). T3DEM is the most crucial step in\ndetermining the quality of Emo3D generation and encompasses three key\nchallenges: Expression Diversity, Emotion-Content Consistency, and Expression\nFluidity. To address these challenges, we introduce a novel benchmark to\nadvance research in Emo3D generation. First, we present EmoAva, a large-scale,\nhigh-quality dataset for T3DEM, comprising 15,000 text-to-3D expression\nmappings that characterize the aforementioned three challenges in Emo3D\ngeneration. Furthermore, we develop various metrics to effectively evaluate\nmodels against these identified challenges. Next, to effectively model the\nconsistency, diversity, and fluidity of human expressions in the T3DEM step, we\npropose the Continuous Text-to-Expression Generator, which employs an\nautoregressive Conditional Variational Autoencoder for expression code\ngeneration, enhanced with Latent Temporal Attention and Expression-wise\nAttention mechanisms. Finally, to further enhance the 3DAR step on rendering\nhigher-quality subtle expressions, we present the Globally-informed Gaussian\nAvatar (GiGA) model. GiGA incorporates a global information mechanism into 3D\nGaussian representations, enabling the capture of subtle micro-expressions and\nseamless transitions between emotional states.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages. Project website: https://github.com/WalkerMitty/EmoAva",
    "pdf_url": "http://arxiv.org/pdf/2412.02508v2",
    "published_date": "2024-12-03 15:39:05 UTC",
    "updated_date": "2025-05-20 15:17:39 UTC"
  },
  {
    "arxiv_id": "2412.02479v2",
    "title": "OODFace: Benchmarking Robustness of Face Recognition under Common Corruptions and Appearance Variations",
    "authors": [
      "Caixin Kang",
      "Yubo Chen",
      "Shouwei Ruan",
      "Shiji Zhao",
      "Ruochen Zhang",
      "Jiayi Wang",
      "Shan Fu",
      "Xingxing Wei"
    ],
    "abstract": "With the rise of deep learning, facial recognition technology has seen\nextensive research and rapid development. Although facial recognition is\nconsidered a mature technology, we find that existing open-source models and\ncommercial algorithms lack robustness in certain complex Out-of-Distribution\n(OOD) scenarios, raising concerns about the reliability of these systems. In\nthis paper, we introduce OODFace, which explores the OOD challenges faced by\nfacial recognition models from two perspectives: common corruptions and\nappearance variations. We systematically design 30 OOD scenarios across 9 major\ncategories tailored for facial recognition. By simulating these challenges on\npublic datasets, we establish three robustness benchmarks: LFW-C/V, CFP-FP-C/V,\nand YTF-C/V. We then conduct extensive experiments on 19 facial recognition\nmodels and 3 commercial APIs, along with extended physical experiments on face\nmasks to assess their robustness. Next, we explore potential solutions from two\nperspectives: defense strategies and Vision-Language Models (VLMs). Based on\nthe results, we draw several key insights, highlighting the vulnerability of\nfacial recognition systems to OOD data and suggesting possible solutions.\nAdditionally, we offer a unified toolkit that includes all corruption and\nvariation types, easily extendable to other datasets. We hope that our\nbenchmarks and findings can provide guidance for future improvements in facial\nrecognition model robustness.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02479v2",
    "published_date": "2024-12-03 14:42:31 UTC",
    "updated_date": "2025-03-27 05:40:57 UTC"
  },
  {
    "arxiv_id": "2412.02474v1",
    "title": "F-SE-LSTM: A Time Series Anomaly Detection Method with Frequency Domain Information",
    "authors": [
      "Yi-Xiang Lu",
      "Xiao-Bo Jin",
      "Jian Chen",
      "Dong-Jie Liu",
      "Guang-Gang Geng"
    ],
    "abstract": "With the development of society, time series anomaly detection plays an\nimportant role in network and IoT services. However, most existing anomaly\ndetection methods directly analyze time series in the time domain and cannot\ndistinguish some relatively hidden anomaly sequences. We attempt to analyze the\nimpact of frequency on time series from a frequency domain perspective, thus\nproposing a new time series anomaly detection method called F-SE-LSTM. This\nmethod utilizes two sliding windows and fast Fourier transform (FFT) to\nconstruct a frequency matrix. Simultaneously, Squeeze-and-Excitation Networks\n(SENet) and Long Short-Term Memory (LSTM) are employed to extract\nfrequency-related features within and between periods. Through comparative\nexperiments on multiple datasets such as Yahoo Webscope S5 and Numenta Anomaly\nBenchmark, the results demonstrate that the frequency matrix constructed by\nF-SE-LSTM exhibits better discriminative ability than ordinary time domain and\nfrequency domain data. Furthermore, F-SE-LSTM outperforms existing\nstate-of-the-art deep learning anomaly detection methods in terms of anomaly\ndetection capability and execution efficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02474v1",
    "published_date": "2024-12-03 14:36:24 UTC",
    "updated_date": "2024-12-03 14:36:24 UTC"
  },
  {
    "arxiv_id": "2412.02454v1",
    "title": "Gracefully Filtering Backdoor Samples for Generative Large Language Models without Retraining",
    "authors": [
      "Zongru Wu",
      "Pengzhou Cheng",
      "Lingyong Fang",
      "Zhuosheng Zhang",
      "Gongshen Liu"
    ],
    "abstract": "Backdoor attacks remain significant security threats to generative large\nlanguage models (LLMs). Since generative LLMs output sequences of\nhigh-dimensional token logits instead of low-dimensional classification logits,\nmost existing backdoor defense methods designed for discriminative models like\nBERT are ineffective for generative LLMs. Inspired by the observed differences\nin learning behavior between backdoor and clean mapping in the frequency space,\nwe transform gradients of each training sample, directly influencing parameter\nupdates, into the frequency space. Our findings reveal a distinct separation\nbetween the gradients of backdoor and clean samples in the frequency space.\nBased on this phenomenon, we propose Gradient Clustering in the Frequency Space\nfor Backdoor Sample Filtering (GraCeFul), which leverages sample-wise gradients\nin the frequency space to effectively identify backdoor samples without\nrequiring retraining LLMs. Experimental results show that GraCeFul outperforms\nbaselines significantly. Notably, GraCeFul exhibits remarkable computational\nefficiency, achieving nearly 100% recall and F1 scores in identifying backdoor\nsamples, reducing the average success rate of various backdoor attacks to 0%\nwith negligible drops in clean accuracy across multiple free-style question\nanswering datasets. Additionally, GraCeFul generalizes to Llama-2 and Vicuna.\nThe codes are publicly available at https://github.com/ZrW00/GraceFul.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02454v1",
    "published_date": "2024-12-03 13:43:36 UTC",
    "updated_date": "2024-12-03 13:43:36 UTC"
  },
  {
    "arxiv_id": "2412.02449v1",
    "title": "BYE: Build Your Encoder with One Sequence of Exploration Data for Long-Term Dynamic Scene Understanding",
    "authors": [
      "Chenguang Huang",
      "Shengchao Yan",
      "Wolfram Burgard"
    ],
    "abstract": "Dynamic scene understanding remains a persistent challenge in robotic\napplications. Early dynamic mapping methods focused on mitigating the negative\ninfluence of short-term dynamic objects on camera motion estimation by masking\nor tracking specific categories, which often fall short in adapting to\nlong-term scene changes. Recent efforts address object association in long-term\ndynamic environments using neural networks trained on synthetic datasets, but\nthey still rely on predefined object shapes and categories. Other methods\nincorporate visual, geometric, or semantic heuristics for the association but\noften lack robustness. In this work, we introduce BYE, a class-agnostic,\nper-scene point cloud encoder that removes the need for predefined categories,\nshape priors, or extensive association datasets. Trained on only a single\nsequence of exploration data, BYE can efficiently perform object association in\ndynamically changing scenes. We further propose an ensembling scheme combining\nthe semantic strengths of Vision Language Models (VLMs) with the scene-specific\nexpertise of BYE, achieving a 7% improvement and a 95% success rate in object\nassociation tasks. Code and dataset are available at\nhttps://byencoder.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02449v1",
    "published_date": "2024-12-03 13:34:42 UTC",
    "updated_date": "2024-12-03 13:34:42 UTC"
  },
  {
    "arxiv_id": "2412.02441v1",
    "title": "Artificial Expert Intelligence through PAC-reasoning",
    "authors": [
      "Shai Shalev-Shwartz",
      "Amnon Shashua",
      "Gal Beniamini",
      "Yoav Levine",
      "Or Sharir",
      "Noam Wies",
      "Ido Ben-Shaul",
      "Tomer Nussbaum",
      "Shir Granot Peled"
    ],
    "abstract": "Artificial Expert Intelligence (AEI) seeks to transcend the limitations of\nboth Artificial General Intelligence (AGI) and narrow AI by integrating\ndomain-specific expertise with critical, precise reasoning capabilities akin to\nthose of top human experts. Existing AI systems often excel at predefined tasks\nbut struggle with adaptability and precision in novel problem-solving. To\novercome this, AEI introduces a framework for ``Probably Approximately Correct\n(PAC) Reasoning\". This paradigm provides robust theoretical guarantees for\nreliably decomposing complex problems, with a practical mechanism for\ncontrolling reasoning precision. In reference to the division of human thought\ninto System 1 for intuitive thinking and System 2 for reflective\nreasoning~\\citep{tversky1974judgment}, we refer to this new type of reasoning\nas System 3 for precise reasoning, inspired by the rigor of the scientific\nmethod. AEI thus establishes a foundation for error-bounded, inference-time\nlearning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02441v1",
    "published_date": "2024-12-03 13:25:18 UTC",
    "updated_date": "2024-12-03 13:25:18 UTC"
  },
  {
    "arxiv_id": "2412.02427v1",
    "title": "GerPS-Compare: Comparing NER methods for legal norm analysis",
    "authors": [
      "Sarah T. Bachinger",
      "Christoph Unger",
      "Robin Erd",
      "Leila Feddoul",
      "Clara Lachenmaier",
      "Sina Zarrieß",
      "Birgitta König-Ries"
    ],
    "abstract": "We apply NER to a particular sub-genre of legal texts in German: the genre of\nlegal norms regulating administrative processes in public service\nadministration. The analysis of such texts involves identifying stretches of\ntext that instantiate one of ten classes identified by public service\nadministration professionals. We investigate and compare three methods for\nperforming Named Entity Recognition (NER) to detect these classes: a Rule-based\nsystem, deep discriminative models, and a deep generative model. Our results\nshow that Deep Discriminative models outperform both the Rule-based system as\nwell as the Deep Generative model, the latter two roughly performing equally\nwell, outperforming each other in different classes. The main cause for this\nsomewhat surprising result is arguably the fact that the classes used in the\nanalysis are semantically and syntactically heterogeneous, in contrast to the\nclasses used in more standard NER tasks. Deep Discriminative models appear to\nbe better equipped for dealing with this heterogenerity than both generic LLMs\nand human linguists designing rule-based NER systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02427v1",
    "published_date": "2024-12-03 12:46:06 UTC",
    "updated_date": "2024-12-03 12:46:06 UTC"
  },
  {
    "arxiv_id": "2412.02415v1",
    "title": "Knowledge-Enhanced Conversational Recommendation via Transformer-based Sequential Modelling",
    "authors": [
      "Jie Zou",
      "Aixin Sun",
      "Cheng Long",
      "Evangelos Kanoulas"
    ],
    "abstract": "In conversational recommender systems (CRSs), conversations usually involve a\nset of items and item-related entities or attributes, e.g., director is a\nrelated entity of a movie. These items and item-related entities are often\nmentioned along the development of a dialog, leading to potential sequential\ndependencies among them. However, most of existing CRSs neglect these potential\nsequential dependencies. In this article, we first propose a Transformer-based\nsequential conversational recommendation method, named TSCR, to model the\nsequential dependencies in the conversations to improve CRS. In TSCR, we\nrepresent conversations by items and the item-related entities, and construct\nuser sequences to discover user preferences by considering both the mentioned\nitems and item-related entities. Based on the constructed sequences, we deploy\na Cloze task to predict the recommended items along a sequence. Meanwhile, in\ncertain domains, knowledge graphs formed by the items and their related\nentities are readily available, which provide various different kinds of\nassociations among them. Given that TSCR does not benefit from such knowledge\ngraphs, we then propose a knowledge graph enhanced version of TSCR, called\nTSCRKG. In specific, we leverage the knowledge graph to offline initialize our\nmodel TSCRKG, and augment the user sequence of conversations (i.e., sequence of\nthe mentioned items and item-related entities in the conversation) with\nmulti-hop paths in the knowledge graph. Experimental results demonstrate that\nour TSCR model significantly outperforms state-of-the-art baselines, and the\nenhanced version TSCRKG further improves recommendation performance on top of\nTSCR.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by ACM TOIS",
    "pdf_url": "http://arxiv.org/pdf/2412.02415v1",
    "published_date": "2024-12-03 12:20:56 UTC",
    "updated_date": "2024-12-03 12:20:56 UTC"
  },
  {
    "arxiv_id": "2412.02412v1",
    "title": "VISTA: A Panoramic View of Neural Representations",
    "authors": [
      "Tom White"
    ],
    "abstract": "We present VISTA (Visualization of Internal States and Their Associations), a\nnovel pipeline for visually exploring and interpreting neural network\nrepresentations. VISTA addresses the challenge of analyzing vast\nmultidimensional spaces in modern machine learning models by mapping\nrepresentations into a semantic 2D space. The resulting collages visually\nreveal patterns and relationships within internal representations. We\ndemonstrate VISTA's utility by applying it to sparse autoencoder latents\nuncovering new properties and interpretations. We review the VISTA methodology,\npresent findings from our case study ( https://got.drib.net/latents/ ), and\ndiscuss implications for neural network interpretability across various domains\nof machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02412v1",
    "published_date": "2024-12-03 12:12:03 UTC",
    "updated_date": "2024-12-03 12:12:03 UTC"
  },
  {
    "arxiv_id": "2412.02410v1",
    "title": "A Multi-Agent Framework for Extensible Structured Text Generation in PLCs",
    "authors": [
      "Donghao Yang",
      "Aolang Wu",
      "Tianyi Zhang",
      "Li Zhang",
      "Fang Liu",
      "Xiaoli Lian",
      "Yuming Ren",
      "Jiaji Tian"
    ],
    "abstract": "Programmable Logic Controllers (PLCs) are microcomputers essential for\nautomating factory operations. Structured Text (ST), a high-level language\nadhering to the IEC 61131-3 standard, is pivotal for PLCs due to its ability to\nexpress logic succinctly and to seamlessly integrate with other languages\nwithin the same standard. However, vendors develop their own customized\nversions of ST, and the lack of comprehensive and standardized documentation\nfor the full semantics of ST has contributed to inconsistencies in how the\nlanguage is implemented. Consequently, the steep learning curve associated with\nST, combined with ever-evolving industrial requirements, presents significant\nchallenges for developers. In response to these issues, we present AutoPLC, an\nLLM-based approach designed to automate the generation of vendor-specific ST\ncode. To facilitate effective code generation, we first built a comprehensive\nknowledge base, including Rq2ST Case Library (requirements and corresponding\nimplementations) and Instruction libraries. Then we developed a retrieval\nmodule to incorporate the domain-specific knowledge by identifying pertinent\ncases and instructions, guiding the LLM to generate code that meets the\nrequirements. In order to verify and improve the quality of the generated code,\nwe designed an adaptable code checker. If errors are detected, we initiate an\niterative self-improvement process to instruct the LLM to revise the generated\ncode. We evaluate AutoPLC's performance against seven state-of-the-art\nbaselines using three benchmarks, one for open-source basic ST and two for\ncommercial Structured Control Language (SCL) from Siemens. The results show\nthat our approach consistently achieves superior performance across all\nbenchmarks. Ablation study emphasizes the significance of our modules. Further\nmanual analysis confirm the practical utility of the ST code generated by\nAutoPLC.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02410v1",
    "published_date": "2024-12-03 12:05:56 UTC",
    "updated_date": "2024-12-03 12:05:56 UTC"
  },
  {
    "arxiv_id": "2412.12122v3",
    "title": "AI-driven Inverse Design of Band-Tunable Mechanical Metastructures for Tailored Vibration Mitigation",
    "authors": [
      "Tanuj Gupta",
      "Arun Kumar Sharma",
      "Ankur Dwivedi",
      "Vivek Gupta",
      "Subhadeep Sahana",
      "Suryansh Pathak",
      "Ashish Awasthi",
      "Bishakh Bhattacharya"
    ],
    "abstract": "On-demand vibration mitigation in a mechanical system needs the suitable\ndesign of multiscale metastructures, involving complex unit cells. In this\nstudy, immersing in the world of patterns and examining the structural details\nof some interesting motifs are extracted from the mechanical metastructure\nperspective. Nine interlaced metastructures are fabricated using additive\nmanufacturing, and corresponding vibration characteristics are studied\nexperimentally and numerically. Further, the band-gap modulation with metallic\ninserts in the honeycomb interlaced metastructures is also studied. AI-driven\ninverse design of such complex metastructures with a desired vibration\nmitigation profile can pave the way for addressing engineering challenges in\nhigh-precision manufacturing. The current inverse design methodologies are\nlimited to designing simple periodic structures based on limited variants of\nunit cells. Therefore, a novel forward analysis model with multi-head\nFEM-inspired spatial attention (FSA) is proposed to learn the complex geometry\nof the metastructures and predict corresponding transmissibility. Subsequently,\na multiscale Gaussian self-attention (MGSA) based inverse design model with\nGaussian function for 1D spectrum position encoding is developed to produce a\nsuitable metastructure for the desired vibration transmittance. The proposed AI\nframework demonstrated outstanding performance corresponding to the expected\nlocally resonant bandgaps in a targeted frequency range.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12122v3",
    "published_date": "2024-12-03 12:02:11 UTC",
    "updated_date": "2025-02-28 06:51:15 UTC"
  },
  {
    "arxiv_id": "2412.02399v1",
    "title": "OMENN: One Matrix to Explain Neural Networks",
    "authors": [
      "Adam Wróbel",
      "Mikołaj Janusz",
      "Bartosz Zieliński",
      "Dawid Rymarczyk"
    ],
    "abstract": "Deep Learning (DL) models are often black boxes, making their decision-making\nprocesses difficult to interpret. This lack of transparency has driven\nadvancements in eXplainable Artificial Intelligence (XAI), a field dedicated to\nclarifying the reasoning behind DL model predictions. Among these,\nattribution-based methods such as LRP and GradCAM are widely used, though they\nrely on approximations that can be imprecise.\n  To address these limitations, we introduce One Matrix to Explain Neural\nNetworks (OMENN), a novel post-hoc method that represents a neural network as a\nsingle, interpretable matrix for each specific input. This matrix is\nconstructed through a series of linear transformations that represent the\nprocessing of the input by each successive layer in the neural network. As a\nresult, OMENN provides locally precise, attribution-based explanations of the\ninput across various modern models, including ViTs and CNNs. We present a\ntheoretical analysis of OMENN based on dynamic linearity property and validate\nits effectiveness with extensive tests on two XAI benchmarks, demonstrating\nthat OMENN is competitive with state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review, code will be released after acceptance",
    "pdf_url": "http://arxiv.org/pdf/2412.02399v1",
    "published_date": "2024-12-03 11:49:01 UTC",
    "updated_date": "2024-12-03 11:49:01 UTC"
  },
  {
    "arxiv_id": "2412.02372v2",
    "title": "HERO: Hint-Based Efficient and Reliable Query Optimizer",
    "authors": [
      "Sergey Zinchenko",
      "Sergey Iazov"
    ],
    "abstract": "We propose a novel model for learned query optimization which provides query\nhints leading to better execution plans. The model addresses the three key\nchallenges in learned hint-based query optimization: reliable hint\nrecommendation (ensuring non-degradation of query latency), efficient hint\nexploration, and fast inference. We provide an in-depth analysis of existing\nNN-based approaches to hint-based optimization and experimentally confirm the\nnamed challenges for them. Our alternative solution consists of a new inference\nschema based on an ensemble of context-aware models and a graph storage for\nreliable hint suggestion and fast inference, and a budget-controlled training\nprocedure with a local search algorithm that solves the issue of exponential\nsearch space exploration. In experiments on standard benchmarks, our model\ndemonstrates optimization capability close to the best achievable with\ncoarse-grained hints. Controlling the degree of parallelism (query dop) in\naddition to operator-related hints enables our model to achieve 3x latency\nimprovement on JOB benchmark which sets a new standard for optimization. Our\nmodel is interpretable and easy to debug, which is particularly important for\ndeployment in production.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG",
      "H.2.4; I.2.6; I.2.8"
    ],
    "primary_category": "cs.DB",
    "comment": "Submitted to VLDB 2025; 13 pages; 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02372v2",
    "published_date": "2024-12-03 10:58:34 UTC",
    "updated_date": "2024-12-05 06:00:34 UTC"
  },
  {
    "arxiv_id": "2412.02368v1",
    "title": "ScImage: How Good Are Multimodal Large Language Models at Scientific Text-to-Image Generation?",
    "authors": [
      "Leixin Zhang",
      "Steffen Eger",
      "Yinjie Cheng",
      "Weihe Zhai",
      "Jonas Belouadi",
      "Christoph Leiter",
      "Simone Paolo Ponzetto",
      "Fahimeh Moafian",
      "Zhixue Zhao"
    ],
    "abstract": "Multimodal large language models (LLMs) have demonstrated impressive\ncapabilities in generating high-quality images from textual instructions.\nHowever, their performance in generating scientific images--a critical\napplication for accelerating scientific progress--remains underexplored. In\nthis work, we address this gap by introducing ScImage, a benchmark designed to\nevaluate the multimodal capabilities of LLMs in generating scientific images\nfrom textual descriptions. ScImage assesses three key dimensions of\nunderstanding: spatial, numeric, and attribute comprehension, as well as their\ncombinations, focusing on the relationships between scientific objects (e.g.,\nsquares, circles). We evaluate five models, GPT-4o, Llama, AutomaTikZ, Dall-E,\nand StableDiffusion, using two modes of output generation: code-based outputs\n(Python, TikZ) and direct raster image generation. Additionally, we examine\nfour different input languages: English, German, Farsi, and Chinese. Our\nevaluation, conducted with 11 scientists across three criteria (correctness,\nrelevance, and scientific accuracy), reveals that while GPT-4o produces outputs\nof decent quality for simpler prompts involving individual dimensions such as\nspatial, numeric, or attribute understanding in isolation, all models face\nchallenges in this task, especially for more complex prompts.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02368v1",
    "published_date": "2024-12-03 10:52:06 UTC",
    "updated_date": "2024-12-03 10:52:06 UTC"
  },
  {
    "arxiv_id": "2412.02357v1",
    "title": "Dynamic Prompt Middleware: Contextual Prompt Refinement Controls for Comprehension Tasks",
    "authors": [
      "Ian Drosos",
      "Jack Williams",
      "Advait Sarkar",
      "Nicholas Wilson"
    ],
    "abstract": "Effective prompting of generative AI is challenging for many users,\nparticularly in expressing context for comprehension tasks such as explaining\nspreadsheet formulas, Python code, and text passages. Prompt middleware aims to\naddress this barrier by assisting in prompt construction, but barriers remain\nfor users in expressing adequate control so that they can receive AI-responses\nthat match their preferences.\n  We conduct a formative survey (n=38) investigating user needs for control\nover AI-generated explanations in comprehension tasks, which uncovers a\ntrade-off between standardized but predictable support for prompting, and\nadaptive but unpredictable support tailored to the user and task. To explore\nthis trade-off, we implement two prompt middleware approaches: Dynamic Prompt\nRefinement Control (Dynamic PRC) and Static Prompt Refinement Control (Static\nPRC). The Dynamic PRC approach generates context-specific UI elements that\nprovide prompt refinements based on the user's prompt and user needs from the\nAI, while the Static PRC approach offers a preset list of generally applicable\nrefinements.\n  We evaluate these two approaches with a controlled user study (n=16) to\nassess the impact of these approaches on user control of AI responses for\ncrafting better explanations. Results show a preference for the Dynamic PRC\napproach as it afforded more control, lowered barriers to providing context,\nand encouraged exploration and reflection of the tasks, but that reasoning\nabout the effects of different generated controls on the final output remains\nchallenging. Drawing on participant feedback, we discuss design implications\nfor future Dynamic PRC systems that enhance user control of AI responses. Our\nfindings suggest that dynamic prompt middleware can improve the user experience\nof generative AI workflows by affording greater control and guide users to a\nbetter AI response.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02357v1",
    "published_date": "2024-12-03 10:27:04 UTC",
    "updated_date": "2024-12-03 10:27:04 UTC"
  },
  {
    "arxiv_id": "2412.02334v2",
    "title": "Reinforcement learning to learn quantum states for Heisenberg scaling accuracy",
    "authors": [
      "Jeongwoo Jae",
      "Jeonghoon Hong",
      "Jinho Choo",
      "Yeong-Dae Kwon"
    ],
    "abstract": "Learning quantum states is a crucial task for realizing quantum information\ntechnology. Recently, neural approaches have emerged as promising methods for\nlearning quantum states. We propose a meta-learning model that utilizes\nreinforcement learning (RL) to optimize the process of learning quantum states.\nTo improve the data efficiency of the RL, we introduce an action repetition\nstrategy inspired by curriculum learning. The RL agent significantly improves\nthe sample efficiency of learning random quantum states, and achieves\ninfidelity scaling close to the Heisenberg limit. We also show that the RL\nagent trained using 3-qubit states can generalize to learning up to 5-qubit\nstates. These results highlight the utility of RL-driven meta-learning to\nenhance the efficiency and generalizability of learning quantum states. Our\napproach can be applied to improve quantum control, quantum optimization, and\nquantum machine learning.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "15 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02334v2",
    "published_date": "2024-12-03 09:53:32 UTC",
    "updated_date": "2025-02-26 10:24:09 UTC"
  },
  {
    "arxiv_id": "2412.02331v1",
    "title": "Sample Efficient Robot Learning in Supervised Effect Prediction Tasks",
    "authors": [
      "Mehmet Arda Eren",
      "Erhan Oztop"
    ],
    "abstract": "In self-supervised robot learning, robots actively explore their environments\nand generate data by acting on entities in the environment. Therefore, an\nexploration policy is desired that ensures sample efficiency to minimize robot\nexecution costs while still providing accurate learning. For this purpose, the\nrobotic community has adopted Intrinsic Motivation (IM)-based approaches such\nas Learning Progress (LP). On the machine learning front, Active Learning (AL)\nhas been used successfully, especially for classification tasks. In this work,\nwe develop a novel AL framework geared towards robotics regression tasks, such\nas action-effect prediction and, more generally, for world model learning,\nwhich we call MUSEL - Model Uncertainty for Sample Efficient Learning. MUSEL\naims to extract model uncertainty from the total uncertainty estimate given by\na suitable learning engine by making use of earning progress and input\ndiversity and use it to improve sample efficiency beyond the state-of-the-art\naction-effect prediction methods. We demonstrate the feasibility of our model\nby using a Stochastic Variational Gaussian Process (SVGP) as the learning\nengine and testing the system on a set of robotic experiments in simulation.\nThe efficacy of MUSEL is demonstrated by comparing its performance to standard\nmethods used in robot action-effect learning. In a robotic tabletop environment\nin which a robot manipulator is tasked with learning the effect of its actions,\nthe experiments show that MUSEL facilitates higher accuracy in learning action\neffects while ensuring sample efficiency.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "18 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02331v1",
    "published_date": "2024-12-03 09:48:28 UTC",
    "updated_date": "2024-12-03 09:48:28 UTC"
  },
  {
    "arxiv_id": "2412.07796v1",
    "title": "MRP-LLM: Multitask Reflective Large Language Models for Privacy-Preserving Next POI Recommendation",
    "authors": [
      "Ziqing Wu",
      "Zhu Sun",
      "Dongxia Wang",
      "Lu Zhang",
      "Jie Zhang",
      "Yew Soon Ong"
    ],
    "abstract": "Large language models (LLMs) have shown promising potential for next\nPoint-of-Interest (POI) recommendation. However, existing methods only perform\ndirect zero-shot prompting, leading to ineffective extraction of user\npreferences, insufficient injection of collaborative signals, and a lack of\nuser privacy protection. As such, we propose a novel Multitask Reflective Large\nLanguage Model for Privacy-preserving Next POI Recommendation (MRP-LLM), aiming\nto exploit LLMs for better next POI recommendation while preserving user\nprivacy. Specifically, the Multitask Reflective Preference Extraction Module\nfirst utilizes LLMs to distill each user's fine-grained (i.e., categorical,\ntemporal, and spatial) preferences into a knowledge base (KB). The Neighbor\nPreference Retrieval Module retrieves and summarizes the preferences of similar\nusers from the KB to obtain collaborative signals. Subsequently, aggregating\nthe user's preferences with those of similar users, the Multitask Next POI\nRecommendation Module generates the next POI recommendations via multitask\nprompting. Meanwhile, during data collection, a Privacy Transmission Module is\nspecifically devised to preserve sensitive POI data. Extensive experiments on\nthree real-world datasets demonstrate the efficacy of our proposed MRP-LLM in\nproviding more accurate next POI recommendations with user privacy preserved.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.07796v1",
    "published_date": "2024-12-03 09:45:02 UTC",
    "updated_date": "2024-12-03 09:45:02 UTC"
  },
  {
    "arxiv_id": "2412.02327v1",
    "title": "Switchable deep beamformer for high-quality and real-time passive acoustic mapping",
    "authors": [
      "Yi Zeng",
      "Jinwei Li",
      "Hui Zhu",
      "Shukuan Lu",
      "Jianfeng Li",
      "Xiran Cai"
    ],
    "abstract": "Passive acoustic mapping (PAM) is a promising tool for monitoring acoustic\ncavitation activities in the applications of ultrasound therapy. Data-adaptive\nbeamformers for PAM have better image quality compared to the time exposure\nacoustics (TEA) algorithms. However, the computational cost of data-adaptive\nbeamformers is considerably expensive. In this work, we develop a deep\nbeamformer based on a generative adversarial network, which can switch between\ndifferent transducer arrays and reconstruct high-quality PAM images directly\nfrom radio frequency ultrasound signals with low computational cost. The deep\nbeamformer was trained on the dataset consisting of simulated and experimental\ncavitation signals of single and multiple microbubble clouds measured by\ndifferent (linear and phased) arrays covering 1-15 MHz. We compared the\nperformance of the deep beamformer to TEA and three different data-adaptive\nbeamformers using the simulated and experimental test dataset. Compared with\nTEA, the deep beamformer reduced the energy spread area by 18.9%-65.0% and\nimproved the image signal-to-noise ratio by 9.3-22.9 dB in average for the\ndifferent arrays in our data. Compared to the data-adaptive beamformers, the\ndeep beamformer reduced the computational cost by three orders of magnitude\nachieving 10.5 ms image reconstruction speed in our data, while the image\nquality was as good as that of the data-adaptive beamformers. These results\ndemonstrated the potential of the deep beamformer for high-resolution\nmonitoring of microbubble cavitation activities for ultrasound therapy.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02327v1",
    "published_date": "2024-12-03 09:40:59 UTC",
    "updated_date": "2024-12-03 09:40:59 UTC"
  },
  {
    "arxiv_id": "2412.02302v2",
    "title": "Enhanced Photovoltaic Power Forecasting: An iTransformer and LSTM-Based Model Integrating Temporal and Covariate Interactions",
    "authors": [
      "Guang Wu",
      "Yun Wang",
      "Qian Zhou",
      "Ziyang Zhang"
    ],
    "abstract": "Accurate photovoltaic (PV) power forecasting is critical for integrating\nrenewable energy sources into the grid, optimizing real-time energy management,\nand ensuring energy reliability amidst increasing demand. However, existing\nmodels often struggle with effectively capturing the complex relationships\nbetween target variables and covariates, as well as the interactions between\ntemporal dynamics and multivariate data, leading to suboptimal forecasting\naccuracy. To address these challenges, we propose a novel model architecture\nthat leverages the iTransformer for feature extraction from target variables\nand employs long short-term memory (LSTM) to extract features from covariates.\nA cross-attention mechanism is integrated to fuse the outputs of both models,\nfollowed by a Kolmogorov-Arnold network (KAN) mapping for enhanced\nrepresentation. The effectiveness of the proposed model is validated using\npublicly available datasets from Australia, with experiments conducted across\nfour seasons. Results demonstrate that the proposed model effectively capture\nseasonal variations in PV power generation and improve forecasting accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02302v2",
    "published_date": "2024-12-03 09:16:13 UTC",
    "updated_date": "2025-05-07 08:16:09 UTC"
  },
  {
    "arxiv_id": "2412.02301v1",
    "title": "Large Multimodal Agents for Accurate Phishing Detection with Enhanced Token Optimization and Cost Reduction",
    "authors": [
      "Fouad Trad",
      "Ali Chehab"
    ],
    "abstract": "With the rise of sophisticated phishing attacks, there is a growing need for\neffective and economical detection solutions. This paper explores the use of\nlarge multimodal agents, specifically Gemini 1.5 Flash and GPT-4o mini, to\nanalyze both URLs and webpage screenshots via APIs, thus avoiding the\ncomplexities of training and maintaining AI systems. Our findings indicate that\nintegrating these two data types substantially enhances detection performance\nover using either type alone. However, API usage incurs costs per query that\ndepend on the number of input and output tokens. To address this, we propose a\ntwo-tiered agentic approach: initially, one agent assesses the URL, and if\ninconclusive, a second agent evaluates both the URL and the screenshot. This\nmethod not only maintains robust detection performance but also significantly\nreduces API costs by minimizing unnecessary multi-input queries. Cost analysis\nshows that with the agentic approach, GPT-4o mini can process about 4.2 times\nas many websites per $100 compared to the multimodal approach (107,440 vs.\n25,626), and Gemini 1.5 Flash can process about 2.6 times more websites\n(2,232,142 vs. 862,068). These findings underscore the significant economic\nbenefits of the agentic approach over the multimodal method, providing a viable\nsolution for organizations aiming to leverage advanced AI for phishing\ndetection while controlling expenses.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in the 2nd International Conference on Foundation and Large\n  Language Models (FLLM2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.02301v1",
    "published_date": "2024-12-03 09:13:52 UTC",
    "updated_date": "2024-12-03 09:13:52 UTC"
  },
  {
    "arxiv_id": "2412.02295v1",
    "title": "CADMR: Cross-Attention and Disentangled Learning for Multimodal Recommender Systems",
    "authors": [
      "Yasser Khalafaoui",
      "Martino Lovisetto",
      "Basarab Matei",
      "Nistor Grozavu"
    ],
    "abstract": "The increasing availability and diversity of multimodal data in recommender\nsystems offer new avenues for enhancing recommendation accuracy and user\nsatisfaction. However, these systems must contend with high-dimensional, sparse\nuser-item rating matrices, where reconstructing the matrix with only small\nsubsets of preferred items for each user poses a significant challenge. To\naddress this, we propose CADMR, a novel autoencoder-based multimodal\nrecommender system framework. CADMR leverages multi-head cross-attention\nmechanisms and Disentangled Learning to effectively integrate and utilize\nheterogeneous multimodal data in reconstructing the rating matrix. Our approach\nfirst disentangles modality-specific features while preserving their\ninterdependence, thereby learning a joint latent representation. The multi-head\ncross-attention mechanism is then applied to enhance user-item interaction\nrepresentations with respect to the learned multimodal item latent\nrepresentations. We evaluate CADMR on three benchmark datasets, demonstrating\nsignificant performance improvements over state-of-the-art methods.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02295v1",
    "published_date": "2024-12-03 09:09:52 UTC",
    "updated_date": "2024-12-03 09:09:52 UTC"
  },
  {
    "arxiv_id": "2412.02294v1",
    "title": "Initial Study On Improving Segmentation By Combining Preoperative CT And Intraoperative CBCT Using Synthetic Data",
    "authors": [
      "Maximilian E. Tschuchnig",
      "Philipp Steininger",
      "Michael Gadermayr"
    ],
    "abstract": "Computer-Assisted Interventions enable clinicians to perform precise,\nminimally invasive procedures, often relying on advanced imaging methods.\nCone-beam computed tomography (CBCT) can be used to facilitate\ncomputer-assisted interventions, despite often suffering from artifacts that\npose challenges for accurate interpretation. While the degraded image quality\ncan affect image analysis, the availability of high quality, preoperative scans\noffers potential for improvements. Here we consider a setting where\npreoperative CT and intraoperative CBCT scans are available, however, the\nalignment (registration) between the scans is imperfect to simulate a real\nworld scenario. We propose a multimodal learning method that fuses roughly\naligned CBCT and CT scans and investigate the effect on segmentation\nperformance. For this experiment we use synthetically generated data containing\nreal CT and synthetic CBCT volumes with corresponding voxel annotations. We\nshow that this fusion setup improves segmentation performance in $18$ out of\n$20$ investigated setups.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at BVM 2025. arXiv admin note: text overlap with\n  arXiv:2406.11650",
    "pdf_url": "http://arxiv.org/pdf/2412.02294v1",
    "published_date": "2024-12-03 09:08:38 UTC",
    "updated_date": "2024-12-03 09:08:38 UTC"
  },
  {
    "arxiv_id": "2412.02292v1",
    "title": "Deep Matrix Factorization with Adaptive Weights for Multi-View Clustering",
    "authors": [
      "Yasser Khalafaoui",
      "Basarab Matei",
      "Martino Lovisetto",
      "Nistor Grozavu"
    ],
    "abstract": "Recently, deep matrix factorization has been established as a powerful model\nfor unsupervised tasks, achieving promising results, especially for multi-view\nclustering. However, existing methods often lack effective feature selection\nmechanisms and rely on empirical hyperparameter selection. To address these\nissues, we introduce a novel Deep Matrix Factorization with Adaptive Weights\nfor Multi-View Clustering (DMFAW). Our method simultaneously incorporates\nfeature selection and generates local partitions, enhancing clustering results.\nNotably, the features weights are controlled and adjusted by a parameter that\nis dynamically updated using Control Theory inspired mechanism, which not only\nimproves the model's stability and adaptability to diverse datasets but also\naccelerates convergence. A late fusion approach is then proposed to align the\nweighted local partitions with the consensus partition. Finally, the\noptimization problem is solved via an alternating optimization algorithm with\ntheoretically guaranteed convergence. Extensive experiments on benchmark\ndatasets highlight that DMFAW outperforms state-of-the-art methods in terms of\nclustering performance.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02292v1",
    "published_date": "2024-12-03 09:08:27 UTC",
    "updated_date": "2024-12-03 09:08:27 UTC"
  },
  {
    "arxiv_id": "2412.02291v2",
    "title": "Conformal Symplectic Optimization for Stable Reinforcement Learning",
    "authors": [
      "Yao Lyu",
      "Xiangteng Zhang",
      "Shengbo Eben Li",
      "Jingliang Duan",
      "Letian Tao",
      "Qing Xu",
      "Lei He",
      "Keqiang Li"
    ],
    "abstract": "Training deep reinforcement learning (RL) agents necessitates overcoming the\nhighly unstable nonconvex stochastic optimization inherent in the\ntrial-and-error mechanism. To tackle this challenge, we propose a\nphysics-inspired optimization algorithm called relativistic adaptive gradient\ndescent (RAD), which enhances long-term training stability. By conceptualizing\nneural network (NN) training as the evolution of a conformal Hamiltonian\nsystem, we present a universal framework for transferring long-term stability\nfrom conformal symplectic integrators to iterative NN updating rules, where the\nchoice of kinetic energy governs the dynamical properties of resulting\noptimization algorithms. By utilizing relativistic kinetic energy, RAD\nincorporates principles from special relativity and limits parameter updates\nbelow a finite speed, effectively mitigating abnormal gradient influences.\nAdditionally, RAD models NN optimization as the evolution of a multi-particle\nsystem where each trainable parameter acts as an independent particle with an\nindividual adaptive learning rate. We prove RAD's sublinear convergence under\ngeneral nonconvex settings, where smaller gradient variance and larger batch\nsizes contribute to tighter convergence. Notably, RAD degrades to the\nwell-known adaptive moment estimation (ADAM) algorithm when its speed\ncoefficient is chosen as one and symplectic factor as a small positive value.\nExperimental results show RAD outperforming nine baseline optimizers with five\nRL algorithms across twelve environments, including standard benchmarks and\nchallenging scenarios. Notably, RAD achieves up to a 155.1% performance\nimprovement over ADAM in Atari games, showcasing its efficacy in stabilizing\nand accelerating RL training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02291v2",
    "published_date": "2024-12-03 09:07:31 UTC",
    "updated_date": "2024-12-08 07:07:57 UTC"
  },
  {
    "arxiv_id": "2412.02285v1",
    "title": "GQWformer: A Quantum-based Transformer for Graph Representation Learning",
    "authors": [
      "Lei Yu",
      "Hongyang Chen",
      "Jingsong Lv",
      "Linyao Yang"
    ],
    "abstract": "Graph Transformers (GTs) have demonstrated significant advantages in graph\nrepresentation learning through their global attention mechanisms. However, the\nself-attention mechanism in GTs tends to neglect the inductive biases inherent\nin graph structures, making it chanllenging to effectively capture essential\nstructural information. To address this issue, we propose a novel approach that\nintegrate graph inductive bias into self-attention mechanisms by leveraging\nquantum technology for structural encoding. In this paper, we introduce the\nGraph Quantum Walk Transformer (GQWformer), a groundbreaking GNN framework that\nutilizes quantum walks on attributed graphs to generate node quantum states.\nThese quantum states encapsulate rich structural attributes and serve as\ninductive biases for the transformer, thereby enabling the generation of more\nmeaningful attention scores. By subsequently incorporating a recurrent neural\nnetwork, our design amplifies the model's ability to focus on both local and\nglobal information. We conducted comprehensive experiments across five publicly\navailable datasets to evaluate the effectiveness of our model. These results\nclearly indicate that GQWformer outperforms existing state-of-the-art graph\nclassification algorithms. These findings highlight the significant potential\nof integrating quantum computing methodologies with traditional GNNs to advance\nthe field of graph representation learning, providing a promising direction for\nfuture research and applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02285v1",
    "published_date": "2024-12-03 09:03:04 UTC",
    "updated_date": "2024-12-03 09:03:04 UTC"
  },
  {
    "arxiv_id": "2412.02283v1",
    "title": "VR Based Emotion Recognition Using Deep Multimodal Fusion With Biosignals Across Multiple Anatomical Domains",
    "authors": [
      "Pubudu L. Indrasiri",
      "Bipasha Kashyap",
      "Chandima Kolambahewage",
      "Bahareh Nakisa",
      "Kiran Ijaz",
      "Pubudu N. Pathirana"
    ],
    "abstract": "Emotion recognition is significantly enhanced by integrating multimodal\nbiosignals and IMU data from multiple domains. In this paper, we introduce a\nnovel multi-scale attention-based LSTM architecture, combined with\nSqueeze-and-Excitation (SE) blocks, by leveraging multi-domain signals from the\nhead (Meta Quest Pro VR headset), trunk (Equivital Vest), and peripheral\n(Empatica Embrace Plus) during affect elicitation via visual stimuli. Signals\nfrom 23 participants were recorded, alongside self-assessed valence and arousal\nratings after each stimulus. LSTM layers extract features from each modality,\nwhile multi-scale attention captures fine-grained temporal dependencies, and SE\nblocks recalibrate feature importance prior to classification. We assess which\ndomain's signals carry the most distinctive emotional information during VR\nexperiences, identifying key biosignals contributing to emotion detection. The\nproposed architecture, validated in a user study, demonstrates superior\nperformance in classifying valance and arousal level (high / low), showcasing\nthe efficacy of multi-domain and multi-modal fusion with biosignals (e.g.,\nTEMP, EDA) with IMU data (e.g., accelerometer) for emotion recognition in\nreal-world applications.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02283v1",
    "published_date": "2024-12-03 08:59:12 UTC",
    "updated_date": "2024-12-03 08:59:12 UTC"
  },
  {
    "arxiv_id": "2412.02280v1",
    "title": "AH-OCDA: Amplitude-based Curriculum Learning and Hopfield Segmentation Model for Open Compound Domain Adaptation",
    "authors": [
      "Jaehyun Choi",
      "Junwon Ko",
      "Dong-Jae Lee",
      "Junmo Kim"
    ],
    "abstract": "Open compound domain adaptation (OCDA) is a practical domain adaptation\nproblem that consists of a source domain, target compound domain, and unseen\nopen domain. In this problem, the absence of domain labels and pixel-level\nsegmentation labels for both compound and open domains poses challenges to the\ndirect application of existing domain adaptation and generalization methods. To\naddress this issue, we propose Amplitude-based curriculum learning and a\nHopfield segmentation model for Open Compound Domain Adaptation (AH-OCDA). Our\nmethod comprises two complementary components: 1) amplitude-based curriculum\nlearning and 2) Hopfield segmentation model. Without prior knowledge of target\ndomains within the compound domains, amplitude-based curriculum learning\ngradually induces the semantic segmentation model to adapt from the near-source\ncompound domain to the far-source compound domain by ranking unlabeled compound\ndomain images through Fast Fourier Transform (FFT). Additionally, the Hopfield\nsegmentation model maps segmentation feature distributions from arbitrary\ndomains to the feature distributions of the source domain. AH-OCDA achieves\nstate-of-the-art performance on two OCDA benchmarks and extended open domains,\ndemonstrating its adaptability to continuously changing compound domains and\nunseen open domains.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02280v1",
    "published_date": "2024-12-03 08:55:10 UTC",
    "updated_date": "2024-12-03 08:55:10 UTC"
  },
  {
    "arxiv_id": "2412.02279v1",
    "title": "A Comprehensive Evaluation of Large Language Models on Aspect-Based Sentiment Analysis",
    "authors": [
      "Changzhi Zhou",
      "Dandan Song",
      "Yuhang Tian",
      "Zhijing Wu",
      "Hao Wang",
      "Xinyu Zhang",
      "Jun Yang",
      "Ziyi Yang",
      "Shuhao Zhang"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have garnered increasing attention in\nthe field of natural language processing, revolutionizing numerous downstream\ntasks with powerful reasoning and generation abilities. For example, In-Context\nLearning (ICL) introduces a fine-tuning-free paradigm, allowing out-of-the-box\nLLMs to execute downstream tasks by analogy learning without any fine-tuning.\nBesides, in a fine-tuning-dependent paradigm where substantial training data\nexists, Parameter-Efficient Fine-Tuning (PEFT), as the cost-effective methods,\nenable LLMs to achieve excellent performance comparable to full fine-tuning.\n  However, these fascinating techniques employed by LLMs have not been fully\nexploited in the ABSA field. Previous works probe LLMs in ABSA by merely using\nrandomly selected input-output pairs as demonstrations in ICL, resulting in an\nincomplete and superficial evaluation. In this paper, we shed light on a\ncomprehensive evaluation of LLMs in the ABSA field, involving 13 datasets, 8\nABSA subtasks, and 6 LLMs. Specifically, we design a unified task formulation\nto unify ``multiple LLMs for multiple ABSA subtasks in multiple paradigms.''\nFor the fine-tuning-dependent paradigm, we efficiently fine-tune LLMs using\ninstruction-based multi-task learning. For the fine-tuning-free paradigm, we\npropose 3 demonstration selection strategies to stimulate the few-shot\nabilities of LLMs. Our extensive experiments demonstrate that LLMs achieve a\nnew state-of-the-art performance compared to fine-tuned Small Language Models\n(SLMs) in the fine-tuning-dependent paradigm. More importantly, in the\nfine-tuning-free paradigm where SLMs are ineffective, LLMs with ICL still\nshowcase impressive potential and even compete with fine-tuned SLMs on some\nABSA subtasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02279v1",
    "published_date": "2024-12-03 08:54:17 UTC",
    "updated_date": "2024-12-03 08:54:17 UTC"
  },
  {
    "arxiv_id": "2412.03600v2",
    "title": "Social Media Informatics for Sustainable Cities and Societies: An Overview of the Applications, associated Challenges, and Potential Solutions",
    "authors": [
      "Jebran Khan",
      "Kashif Ahmad",
      "Senthil Kumar Jagatheesaperumal",
      "Nasir Ahmad",
      "Kyung-Ah Sohn"
    ],
    "abstract": "In the modern world, our cities and societies face several technological and\nsocietal challenges, such as rapid urbanization, global warming & climate\nchange, the digital divide, and social inequalities, increasing the need for\nmore sustainable cities and societies. Addressing these challenges requires a\nmultifaceted approach involving all the stakeholders, sustainable planning,\nefficient resource management, innovative solutions, and modern technologies.\nLike other modern technologies, social media informatics also plays its part in\ndeveloping more sustainable and resilient cities and societies. Despite its\nlimitations, social media informatics has proven very effective in various\nsustainable cities and society applications. In this paper, we review and\nanalyze the role of social media informatics in sustainable cities and society\nby providing a detailed overview of its applications, associated challenges,\nand potential solutions. This work is expected to provide a baseline for future\nresearch in the domain.",
    "categories": [
      "physics.soc-ph",
      "cs.AI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "35 pages, 3 tables, and 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03600v2",
    "published_date": "2024-12-03 08:53:32 UTC",
    "updated_date": "2024-12-09 16:06:08 UTC"
  },
  {
    "arxiv_id": "2412.02270v1",
    "title": "Sustainable Self-evolution Adversarial Training",
    "authors": [
      "Wenxuan Wang",
      "Chenglei Wang",
      "Huihui Qi",
      "Menghao Ye",
      "Xuelin Qian",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "abstract": "With the wide application of deep neural network models in various computer\nvision tasks, there has been a proliferation of adversarial example generation\nstrategies aimed at deeply exploring model security. However, existing\nadversarial training defense models, which rely on single or limited types of\nattacks under a one-time learning process, struggle to adapt to the dynamic and\nevolving nature of attack methods. Therefore, to achieve defense performance\nimprovements for models in long-term applications, we propose a novel\nSustainable Self-Evolution Adversarial Training (SSEAT) framework.\nSpecifically, we introduce a continual adversarial defense pipeline to realize\nlearning from various kinds of adversarial examples across multiple stages.\nAdditionally, to address the issue of model catastrophic forgetting caused by\ncontinual learning from ongoing novel attacks, we propose an adversarial data\nreplay module to better select more diverse and key relearning data.\nFurthermore, we design a consistency regularization strategy to encourage\ncurrent defense models to learn more from previously trained ones, guiding them\nto retain more past knowledge and maintain accuracy on clean samples. Extensive\nexperiments have been conducted to verify the efficacy of the proposed SSEAT\ndefense method, which demonstrates superior defense performance and\nclassification accuracy compared to competitors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ACMMM 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.02270v1",
    "published_date": "2024-12-03 08:41:11 UTC",
    "updated_date": "2024-12-03 08:41:11 UTC"
  },
  {
    "arxiv_id": "2412.02263v2",
    "title": "Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence",
    "authors": [
      "Youquan Xian",
      "Xueying Zeng",
      "Duancheng Xuan",
      "Danping Yang",
      "Chunpei Li",
      "Peng Fan",
      "Peng Liu"
    ],
    "abstract": "Blockchain smart contracts have catalyzed the development of decentralized\napplications across various domains, including decentralized finance. However,\ndue to constraints in computational resources and the prevalence of data silos,\ncurrent smart contracts face significant challenges in fully leveraging the\npowerful capabilities of Large Language Models (LLMs) for tasks such as\nintelligent analysis and reasoning. To address this gap, this paper proposes\nand implements a universal framework for integrating LLMs with blockchain data,\n{\\sysname}, effectively overcoming the interoperability barriers between\nblockchain and LLMs. By combining semantic relatedness with truth discovery\nmethods, we introduce an innovative data aggregation approach, {\\funcname},\nwhich significantly enhances the accuracy and trustworthiness of data generated\nby LLMs. To validate the framework's effectiveness, we construct a dataset\nconsisting of three types of questions, capturing Q\\&A interactions between 10\noracle nodes and 5 LLM models. Experimental results demonstrate that, even with\n40\\% malicious nodes, the proposed solution improves data accuracy by an\naverage of 17.74\\% compared to the optimal baseline. This research not only\nprovides an innovative solution for the intelligent enhancement of smart\ncontracts but also highlights the potential for deep integration between LLMs\nand blockchain technology, paving the way for more intelligent and complex\napplications of smart contracts in the future.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02263v2",
    "published_date": "2024-12-03 08:35:51 UTC",
    "updated_date": "2024-12-06 16:43:58 UTC"
  },
  {
    "arxiv_id": "2412.02259v2",
    "title": "VideoGen-of-Thought: Step-by-step generating multi-shot video with minimal manual intervention",
    "authors": [
      "Mingzhe Zheng",
      "Yongqi Xu",
      "Haojian Huang",
      "Xuran Ma",
      "Yexin Liu",
      "Wenjie Shu",
      "Yatian Pang",
      "Feilong Tang",
      "Qifeng Chen",
      "Harry Yang",
      "Ser-Nam Lim"
    ],
    "abstract": "Current video generation models excel at short clips but fail to produce\ncohesive multi-shot narratives due to disjointed visual dynamics and fractured\nstorylines. Existing solutions either rely on extensive manual\nscripting/editing or prioritize single-shot fidelity over cross-scene\ncontinuity, limiting their practicality for movie-like content. We introduce\nVideoGen-of-Thought (VGoT), a step-by-step framework that automates multi-shot\nvideo synthesis from a single sentence by systematically addressing three core\nchallenges: (1) Narrative Fragmentation: Existing methods lack structured\nstorytelling. We propose dynamic storyline modeling, which first converts the\nuser prompt into concise shot descriptions, then elaborates them into detailed,\ncinematic specifications across five domains (character dynamics, background\ncontinuity, relationship evolution, camera movements, HDR lighting), ensuring\nlogical narrative progression with self-validation. (2) Visual Inconsistency:\nExisting approaches struggle with maintaining visual consistency across shots.\nOur identity-aware cross-shot propagation generates identity-preserving\nportrait (IPP) tokens that maintain character fidelity while allowing trait\nvariations (expressions, aging) dictated by the storyline. (3) Transition\nArtifacts: Abrupt shot changes disrupt immersion. Our adjacent latent\ntransition mechanisms implement boundary-aware reset strategies that process\nadjacent shots' features at transition points, enabling seamless visual flow\nwhile preserving narrative continuity. VGoT generates multi-shot videos that\noutperform state-of-the-art baselines by 20.4% in within-shot face consistency\nand 17.4% in style consistency, while achieving over 100% better cross-shot\nconsistency and 10x fewer manual adjustments than alternatives.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code: https://github.com/DuNGEOnmassster/VideoGen-of-Thought.git;\n  Webpage: https://cheliosoops.github.io/VGoT/",
    "pdf_url": "http://arxiv.org/pdf/2412.02259v2",
    "published_date": "2024-12-03 08:33:50 UTC",
    "updated_date": "2025-03-20 02:25:43 UTC"
  },
  {
    "arxiv_id": "2412.02251v3",
    "title": "Selective Reviews of Bandit Problems in AI via a Statistical View",
    "authors": [
      "Pengjie Zhou",
      "Haoyu Wei",
      "Huiming Zhang"
    ],
    "abstract": "Reinforcement Learning (RL) is a widely researched area in artificial\nintelligence that focuses on teaching agents decision-making through\ninteractions with their environment. A key subset includes stochastic\nmulti-armed bandit (MAB) and continuum-armed bandit (SCAB) problems, which\nmodel sequential decision-making under uncertainty. This review outlines the\nfoundational models and assumptions of bandit problems, explores non-asymptotic\ntheoretical tools like concentration inequalities and minimax regret bounds,\nand compares frequentist and Bayesian algorithms for managing\nexploration-exploitation trade-offs. Additionally, we explore K-armed\ncontextual bandits and SCAB, focusing on their methodologies and regret\nanalyses. We also examine the connections between SCAB problems and functional\ndata analysis. Finally, we highlight recent advances and ongoing challenges in\nthe field.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "econ.EM",
      "math.PR"
    ],
    "primary_category": "stat.ML",
    "comment": "52 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02251v3",
    "published_date": "2024-12-03 08:28:47 UTC",
    "updated_date": "2025-02-19 18:48:18 UTC"
  },
  {
    "arxiv_id": "2412.02242v1",
    "title": "U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities",
    "authors": [
      "Fnu Neha",
      "Deepshikha Bhati",
      "Deepak Kumar Shukla",
      "Sonavi Makarand Dalvi",
      "Nikolaos Mantzou",
      "Safa Shubbar"
    ],
    "abstract": "Medical imaging is essential in healthcare to provide key insights into\npatient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive\ntechniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography\n(CT), and Ultrasound (US), capture detailed images of organs, tissues, and\nabnormalities. Effective analysis of these images requires precise segmentation\nto delineate regions of interest (ROI), such as organs or lesions. Traditional\nsegmentation methods, relying on manual feature-extraction, are labor-intensive\nand vary across experts. Recent advancements in Artificial Intelligence (AI)\nand Deep Learning (DL), particularly convolutional models such as U-Net and its\nvariants (U-Net++ and U-Net 3+), have transformed medical image segmentation\n(MIS) by automating the process and enhancing accuracy. These models enable\nefficient, precise pixel-wise classification across various imaging modalities,\novercoming the limitations of manual segmentation. This review explores various\nmedical imaging techniques, examines the U-Net architectures and their\nadaptations, and discusses their application across different modalities. It\nalso identifies common challenges in MIS and proposes potential solutions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02242v1",
    "published_date": "2024-12-03 08:11:06 UTC",
    "updated_date": "2024-12-03 08:11:06 UTC"
  },
  {
    "arxiv_id": "2412.02237v3",
    "title": "Cross-Attention Head Position Patterns Can Align with Human Visual Concepts in Text-to-Image Generative Models",
    "authors": [
      "Jungwon Park",
      "Jungmin Ko",
      "Dongnam Byun",
      "Jangwon Suh",
      "Wonjong Rhee"
    ],
    "abstract": "Recent text-to-image diffusion models leverage cross-attention layers, which\nhave been effectively utilized to enhance a range of visual generative tasks.\nHowever, our understanding of cross-attention layers remains somewhat limited.\nIn this study, we introduce a mechanistic interpretability approach for\ndiffusion models by constructing Head Relevance Vectors (HRVs) that align with\nhuman-specified visual concepts. An HRV for a given visual concept has a length\nequal to the total number of cross-attention heads, with each element\nrepresenting the importance of the corresponding head for the given visual\nconcept. To validate HRVs as interpretable features, we develop an ordered\nweakening analysis that demonstrates their effectiveness. Furthermore, we\npropose concept strengthening and concept adjusting methods and apply them to\nenhance three visual generative tasks. Our results show that HRVs can reduce\nmisinterpretations of polysemous words in image generation, successfully modify\nfive challenging attributes in image editing, and mitigate catastrophic neglect\nin multi-concept generation. Overall, our work provides an advancement in\nunderstanding cross-attention layers and introduces new approaches for\nfine-controlling these layers at the head level.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02237v3",
    "published_date": "2024-12-03 08:05:56 UTC",
    "updated_date": "2025-02-24 14:59:37 UTC"
  },
  {
    "arxiv_id": "2412.02228v1",
    "title": "BANER: Boundary-Aware LLMs for Few-Shot Named Entity Recognition",
    "authors": [
      "Quanjiang Guo",
      "Yihong Dong",
      "Ling Tian",
      "Zhao Kang",
      "Yu Zhang",
      "Sijie Wang"
    ],
    "abstract": "Despite the recent success of two-stage prototypical networks in few-shot\nnamed entity recognition (NER), challenges such as over/under-detected false\nspans in the span detection stage and unaligned entity prototypes in the type\nclassification stage persist. Additionally, LLMs have not proven to be\neffective few-shot information extractors in general. In this paper, we propose\nan approach called Boundary-Aware LLMs for Few-Shot Named Entity Recognition to\naddress these issues. We introduce a boundary-aware contrastive learning\nstrategy to enhance the LLM's ability to perceive entity boundaries for\ngeneralized entity spans. Additionally, we utilize LoRAHub to align information\nfrom the target domain to the source domain, thereby enhancing adaptive\ncross-domain classification capabilities. Extensive experiments across various\nbenchmarks demonstrate that our framework outperforms prior methods, validating\nits effectiveness. In particular, the proposed strategies demonstrate\neffectiveness across a range of LLM architectures. The code and data are\nreleased on https://github.com/UESTC-GQJ/BANER.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Appear on COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02228v1",
    "published_date": "2024-12-03 07:51:14 UTC",
    "updated_date": "2024-12-03 07:51:14 UTC"
  },
  {
    "arxiv_id": "2412.02222v1",
    "title": "Deep learning approach for predicting the replicator equation in evolutionary game theory",
    "authors": [
      "Advait Chandorkar"
    ],
    "abstract": "This paper presents a physics-informed deep learning approach for predicting\nthe replicator equation, allowing accurate forecasting of population dynamics.\nThis methodological innovation allows us to derive governing differential or\ndifference equations for systems that lack explicit mathematical models. We\nused the SINDy model first introduced by Fasel, Kaiser, Kutz, Brunton, and\nBrunt 2016a to get the replicator equation, which will significantly advance\nour understanding of evolutionary biology, economic systems, and social\ndynamics. By refining predictive models across multiple disciplines, including\necology, social structures, and moral behaviours, our work offers new insights\ninto the complex interplay of variables shaping evolutionary outcomes in\ndynamic systems",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02222v1",
    "published_date": "2024-12-03 07:28:52 UTC",
    "updated_date": "2024-12-03 07:28:52 UTC"
  },
  {
    "arxiv_id": "2412.02220v1",
    "title": "Unlocking Tuning-Free Few-Shot Adaptability in Visual Foundation Models by Recycling Pre-Tuned LoRAs",
    "authors": [
      "Zixuan Hu",
      "Yongxian Wei",
      "Li Shen",
      "Chun Yuan",
      "Dacheng Tao"
    ],
    "abstract": "Large Language Models (LLMs) such as ChatGPT demonstrate strong few-shot\nadaptability without requiring fine-tuning, positioning them ideal for\ndata-limited and real-time applications. However, this adaptability has not yet\nbeen replicated in current Visual Foundation Models (VFMs), which require\nexplicit fine-tuning with sufficient tuning data. Besides, the\npretraining-finetuning paradigm has led to the surge of numerous task-specific\nmodular components, such as Low-Rank Adaptation (LoRA). For the first time, we\nexplore the potential of reusing diverse pre-tuned LoRAs without accessing\ntheir original training data, to achieve tuning-free few-shot adaptation in\nVFMs. Our framework, LoRA Recycle, distills a meta-LoRA from diverse pre-tuned\nLoRAs with a meta-learning objective, using surrogate data generated inversely\nfrom pre-tuned LoRAs themselves. The VFM, once equipped with the meta-LoRA, is\nempowered to solve new few-shot tasks in a single forward pass, akin to the\nin-context learning of LLMs. Additionally, we incorporate a double-efficient\nmechanism tailored to our framework, significantly accelerating the\nmeta-training process while maintaining or even improving performance.\nExtensive experiments across various few-shot classification benchmarks across\nboth in- and cross-domain scenarios demonstrate the superiority of our\nframework.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02220v1",
    "published_date": "2024-12-03 07:25:30 UTC",
    "updated_date": "2024-12-03 07:25:30 UTC"
  },
  {
    "arxiv_id": "2412.02215v1",
    "title": "Recovering implicit physics model under real-world constraints",
    "authors": [
      "Ayan Banerjee",
      "Sandeep K. S. Gupta"
    ],
    "abstract": "Recovering a physics-driven model, i.e. a governing set of equations of the\nunderlying dynamical systems, from the real-world data has been of recent\ninterest. Most existing methods either operate on simulation data with\nunrealistically high sampling rates or require explicit measurements of all\nsystem variables, which is not amenable in real-world deployments. Moreover,\nthey assume the timestamps of external perturbations to the physical system are\nknown a priori, without uncertainty, implicitly discounting any sensor\ntime-synchronization or human reporting errors. In this paper, we propose a\nnovel liquid time constant neural network (LTC-NN) based architecture to\nrecover underlying model of physical dynamics from real-world data. The\nautomatic differentiation property of LTC-NN nodes overcomes problems\nassociated with low sampling rates, the input dependent time constant in the\nforward pass of the hidden layer of LTC-NN nodes creates a massive search space\nof implicit physical dynamics, the physics model solver based data\nreconstruction loss guides the search for the correct set of implicit dynamics,\nand the use of the dropout regularization in the dense layer ensures extraction\nof the sparsest model. Further, to account for the perturbation timing error,\nwe utilize dense layer nodes to search through input shifts that results in the\nlowest reconstruction loss. Experiments on four benchmark dynamical systems,\nthree with simulation data and one with the real-world data show that the\nLTC-NN architecture is more accurate in recovering implicit physics model\ncoefficients than the state-of-the-art sparse model recovery approaches. We\nalso introduce four additional case studies (total eight) on real-life medical\nexamples in simulation and with real-world clinical data to show effectiveness\nof our approach in recovering underlying model in practice.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is published in ECAI 2024,\n  https://ebooks.iospress.nl/volumearticle/69651",
    "pdf_url": "http://arxiv.org/pdf/2412.02215v1",
    "published_date": "2024-12-03 07:11:21 UTC",
    "updated_date": "2024-12-03 07:11:21 UTC"
  },
  {
    "arxiv_id": "2412.02205v3",
    "title": "DataLab: A Unified Platform for LLM-Powered Business Intelligence",
    "authors": [
      "Luoxuan Weng",
      "Yinghao Tang",
      "Yingchaojie Feng",
      "Zhuo Chang",
      "Ruiqin Chen",
      "Haozhe Feng",
      "Chen Hou",
      "Danqing Huang",
      "Yang Li",
      "Huaming Rao",
      "Haonan Wang",
      "Canshi Wei",
      "Xiaofeng Yang",
      "Yuhui Zhang",
      "Yifeng Zheng",
      "Xiuqi Huang",
      "Minfeng Zhu",
      "Yuxin Ma",
      "Bin Cui",
      "Peng Chen",
      "Wei Chen"
    ],
    "abstract": "Business intelligence (BI) transforms large volumes of data within modern\norganizations into actionable insights for informed decision-making. Recently,\nlarge language model (LLM)-based agents have streamlined the BI workflow by\nautomatically performing task planning, reasoning, and actions in executable\nenvironments based on natural language (NL) queries. However, existing\napproaches primarily focus on individual BI tasks such as NL2SQL and NL2VIS.\nThe fragmentation of tasks across different data roles and tools lead to\ninefficiencies and potential errors due to the iterative and collaborative\nnature of BI. In this paper, we introduce DataLab, a unified BI platform that\nintegrates a one-stop LLM-based agent framework with an augmented computational\nnotebook interface. DataLab supports various BI tasks for different data roles\nin data preparation, analysis, and visualization by seamlessly combining LLM\nassistance with user customization within a single environment. To achieve this\nunification, we design a domain knowledge incorporation module tailored for\nenterprise-specific BI tasks, an inter-agent communication mechanism to\nfacilitate information sharing across the BI workflow, and a cell-based context\nmanagement strategy to enhance context utilization efficiency in BI notebooks.\nExtensive experiments demonstrate that DataLab achieves state-of-the-art\nperformance on various BI tasks across popular research benchmarks. Moreover,\nDataLab maintains high effectiveness and efficiency on real-world datasets from\nTencent, achieving up to a 58.58% increase in accuracy and a 61.65% reduction\nin token cost on enterprise-specific BI tasks.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted to ICDE 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02205v3",
    "published_date": "2024-12-03 06:47:15 UTC",
    "updated_date": "2025-04-07 12:01:15 UTC"
  },
  {
    "arxiv_id": "2412.02193v3",
    "title": "LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models",
    "authors": [
      "Fan-Yun Sun",
      "Weiyu Liu",
      "Siyi Gu",
      "Dylan Lim",
      "Goutam Bhat",
      "Federico Tombari",
      "Manling Li",
      "Nick Haber",
      "Jiajun Wu"
    ],
    "abstract": "Spatial reasoning is a fundamental aspect of human cognition, enabling\nintuitive understanding and manipulation of objects in three-dimensional space.\nWhile foundation models demonstrate remarkable performance on some benchmarks,\nthey still struggle with 3D reasoning tasks like arranging objects in space\naccording to open-ended language instructions, particularly in dense and\nphysically constrained environments. We introduce LayoutVLM, a framework and\nscene layout representation that exploits the semantic knowledge of\nVision-Language Models (VLMs) and supports differentiable optimization to\nensure physical plausibility. LayoutVLM employs VLMs to generate two mutually\nreinforcing representations from visually marked images, and a self-consistent\ndecoding process to improve VLMs spatial planning. Our experiments show that\nLayoutVLM addresses the limitations of existing LLM and constraint-based\napproaches, producing physically plausible 3D layouts better aligned with the\nsemantic intent of input language instructions. We also demonstrate that\nfine-tuning VLMs with the proposed scene layout representation extracted from\nexisting scene datasets can improve their reasoning performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025, project website:\n  https://ai.stanford.edu/~sunfanyun/layoutvlm/",
    "pdf_url": "http://arxiv.org/pdf/2412.02193v3",
    "published_date": "2024-12-03 06:15:04 UTC",
    "updated_date": "2025-03-11 05:58:39 UTC"
  },
  {
    "arxiv_id": "2412.02189v1",
    "title": "Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification",
    "authors": [
      "Abu Bakar Siddik",
      "Faisal R. Badal",
      "Afroza Islam"
    ],
    "abstract": "A great deal of effort has been devoted to discovering a particular genetic\ndisorder, but its classification across a broad spectrum of disorder classes\nand types remains elusive. Early diagnosis of genetic disorders enables timely\ninterventions and improves outcomes. This study implements machine learning\nmodels using basic clinical indicators measurable at birth or infancy to enable\ndiagnosis in preliminary life stages. Supervised learning algorithms were\nimplemented on a dataset of 22083 instances with 42 features like family\nhistory, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,\nfeature engineering, and selection were undertaken. Two multi-class classifiers\nwere developed: one for predicting disorder classes (mitochondrial,\nmultifactorial, and single-gene) and one for subtypes (9 disorders).\nPerformance was evaluated using accuracy, precision, recall, and the F1-score.\nThe CatBoost classifier achieved the highest accuracy of 77% for predicting\ngenetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.\nThe study demonstrates the feasibility of using basic clinical data in machine\nlearning models for early categorization and diagnosis across various genetic\ndisorders. Applying ML with basic clinical indicators can enable timely\ninterventions once validated on larger datasets. It is necessary to conduct\nfurther studies to improve model performance on this dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 11 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.02189v1",
    "published_date": "2024-12-03 06:02:47 UTC",
    "updated_date": "2024-12-03 06:02:47 UTC"
  },
  {
    "arxiv_id": "2412.02186v1",
    "title": "VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding",
    "authors": [
      "Kangsan Kim",
      "Geon Park",
      "Youngwan Lee",
      "Woongyeong Yeo",
      "Sung Ju Hwang"
    ],
    "abstract": "Recent advancements in video large multimodal models (LMMs) have\nsignificantly improved their video understanding and reasoning capabilities.\nHowever, their performance drops on out-of-distribution (OOD) tasks that are\nunderrepresented in training data. Traditional methods like fine-tuning on OOD\ndatasets are impractical due to high computational costs. While In-context\nlearning (ICL) with demonstration examples has shown promising generalization\nperformance in language tasks and image-language tasks without fine-tuning,\napplying ICL to video-language tasks faces challenges due to the limited\ncontext length in Video LMMs, as videos require longer token lengths. To\naddress these issues, we propose VideoICL, a novel video in-context learning\nframework for OOD tasks that introduces a similarity-based relevant example\nselection strategy and a confidence-based iterative inference approach. This\nallows to select the most relevant examples and rank them based on similarity,\nto be used for inference. If the generated response has low confidence, our\nframework selects new examples and performs inference again, iteratively\nrefining the results until a high-confidence response is obtained. This\napproach improves OOD video understanding performance by extending effective\ncontext length without incurring high costs. The experimental results on\nmultiple benchmarks demonstrate significant performance gains, especially in\ndomain-specific scenarios, laying the groundwork for broader video\ncomprehension applications. Code will be released at\nhttps://github.com/KangsanKim07/VideoICL",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02186v1",
    "published_date": "2024-12-03 05:54:43 UTC",
    "updated_date": "2024-12-03 05:54:43 UTC"
  },
  {
    "arxiv_id": "2412.02181v2",
    "title": "Generalizing Weisfeiler-Lehman Kernels to Subgraphs",
    "authors": [
      "Dongkwan Kim",
      "Alice Oh"
    ],
    "abstract": "Subgraph representation learning has been effective in solving various\nreal-world problems. However, current graph neural networks (GNNs) produce\nsuboptimal results for subgraph-level tasks due to their inability to capture\ncomplex interactions within and between subgraphs. To provide a more expressive\nand efficient alternative, we propose WLKS, a Weisfeiler-Lehman (WL) kernel\ngeneralized for subgraphs by applying the WL algorithm on induced $k$-hop\nneighborhoods. We combine kernels across different $k$-hop levels to capture\nricher structural information that is not fully encoded in existing models. Our\napproach can balance expressiveness and efficiency by eliminating the need for\nneighborhood sampling. In experiments on eight real-world and synthetic\nbenchmarks, WLKS significantly outperforms leading approaches on five datasets\nwhile reducing training time, ranging from 0.01x to 0.25x compared to the\nstate-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 Camera Ready (15 pages)",
    "pdf_url": "http://arxiv.org/pdf/2412.02181v2",
    "published_date": "2024-12-03 05:35:44 UTC",
    "updated_date": "2025-02-06 07:51:42 UTC"
  },
  {
    "arxiv_id": "2412.02177v1",
    "title": "Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports",
    "authors": [
      "R. Mahmood",
      "K. C. L. Wong",
      "D. M. Reyes",
      "N. D'Souza",
      "L. Shi",
      "J. Wu",
      "P. Kaviani",
      "M. Kalra",
      "G. Wang",
      "P. Yan",
      "T. Syeda-Mahmood"
    ],
    "abstract": "With the emergence of large-scale vision-language models, realistic radiology\nreports may be generated using only medical images as input guided by simple\nprompts. However, their practical utility has been limited due to the factual\nerrors in their description of findings. In this paper, we propose a novel\nmodel for explainable fact-checking that identifies errors in findings and\ntheir locations indicated through the reports. Specifically, we analyze the\ntypes of errors made by automated reporting methods and derive a new synthetic\ndataset of images paired with real and fake descriptions of findings and their\nlocations from a ground truth dataset. A new multi-label cross-modal\ncontrastive regression network is then trained on this datsaset. We evaluate\nthe resulting fact-checking model and its utility in correcting reports\ngenerated by several SOTA automated reporting tools on a variety of benchmark\ndatasets with results pointing to over 40\\% improvement in report quality\nthrough such error detection and correction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02177v1",
    "published_date": "2024-12-03 05:21:42 UTC",
    "updated_date": "2024-12-03 05:21:42 UTC"
  },
  {
    "arxiv_id": "2412.02176v1",
    "title": "Self-Supervised Learning-Based Path Planning and Obstacle Avoidance Using PPO and B-Splines in Unknown Environments",
    "authors": [
      "Shahab Shokouhi",
      "Oguzhan Oruc",
      "May-Win Thein"
    ],
    "abstract": "This paper introduces SmartBSP, an advanced self-supervised learning\nframework for real-time path planning and obstacle avoidance in autonomous\nrobotics navigating through complex environments. The proposed system\nintegrates Proximal Policy Optimization (PPO) with Convolutional Neural\nNetworks (CNN) and Actor-Critic architecture to process limited LIDAR inputs\nand compute spatial decision-making probabilities. The robot's perceptual field\nis discretized into a grid format, which the CNN analyzes to produce a spatial\nprobability distribution. During the training process a nuanced cost function\nis minimized that accounts for path curvature, endpoint proximity, and obstacle\navoidance. Simulations results in different scenarios validate the algorithm's\nresilience and adaptability across diverse operational scenarios. Subsequently,\nReal-time experiments, employing the Robot Operating System (ROS), were carried\nout to assess the efficacy of the proposed algorithm.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02176v1",
    "published_date": "2024-12-03 05:20:29 UTC",
    "updated_date": "2024-12-03 05:20:29 UTC"
  },
  {
    "arxiv_id": "2412.02173v1",
    "title": "Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models",
    "authors": [
      "Nader Karayanni",
      "Aya Awwad",
      "Chein-Lien Hsiao",
      "Surish P Shanmugam"
    ],
    "abstract": "Since the emergence of Large Language Models (LLMs), the challenge of\neffectively leveraging their potential in healthcare has taken center stage. A\ncritical barrier to using LLMs for extracting insights from unstructured\nclinical notes lies in the prompt engineering process. Despite its pivotal role\nin determining task performance, a clear framework for prompt optimization\nremains absent. Current methods to address this gap take either a manual prompt\nrefinement approach, where domain experts collaborate with prompt engineers to\ncreate an optimal prompt, which is time-intensive and difficult to scale, or\nthrough employing automatic prompt optimizing approaches, where the value of\nthe input of domain experts is not fully realized. To address this, we propose\nStructEase, a novel framework that bridges the gap between automation and the\ninput of human expertise in prompt engineering. A core innovation of the\nframework is SamplEase, an iterative sampling algorithm that identifies\nhigh-value cases where expert feedback drives significant performance\nimprovements. This approach minimizes expert intervention, to effectively\nenhance classification outcomes. This targeted approach reduces labeling\nredundancy, mitigates human error, and enhances classification outcomes. We\nevaluated the performance of StructEase using a dataset of de-identified\nclinical narratives from the US National Electronic Injury Surveillance System\n(NEISS), demonstrating significant gains in classification performance compared\nto current methods. Our findings underscore the value of expert integration in\nLLM workflows, achieving notable improvements in F1 score while maintaining\nminimal expert effort. By combining transparency, flexibility, and scalability,\nStructEase sets the foundation for a framework to integrate expert input into\nLLM workflows in healthcare and beyond.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02173v1",
    "published_date": "2024-12-03 05:05:13 UTC",
    "updated_date": "2024-12-03 05:05:13 UTC"
  },
  {
    "arxiv_id": "2412.02172v2",
    "title": "VISCO: Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning",
    "authors": [
      "Xueqing Wu",
      "Yuheng Ding",
      "Bingxuan Li",
      "Pan Lu",
      "Da Yin",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "abstract": "The ability of large vision-language models (LVLMs) to critique and correct\ntheir reasoning is an essential building block towards their self-improvement.\nHowever, a systematic analysis of such capabilities in LVLMs is still lacking.\nWe propose VISCO, the first benchmark to extensively analyze the fine-grained\ncritique and correction capabilities of LVLMs. Compared to existing work that\nuses a single scalar value to critique the entire reasoning [4], VISCO features\ndense and fine-grained critique, requiring LVLMs to evaluate the correctness of\neach step in the chain-of-thought and provide natural language explanations to\nsupport their judgments. Extensive evaluation of 24 LVLMs demonstrates that\nhuman-written critiques significantly enhance the performance after correction,\nshowcasing the potential of the self-improvement strategy. However, the\nmodel-generated critiques are less helpful and sometimes detrimental to the\nperformance, suggesting that critique is the crucial bottleneck. We identified\nthree common patterns in critique failures: failure to critique visual\nperception, reluctance to \"say no\", and exaggerated assumption of error\npropagation. To address these issues, we propose an effective LookBack strategy\nthat revisits the image to verify each piece of information in the initial\nreasoning. LookBack significantly improves critique and correction performance\nby up to 13.5%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. https://visco-benchmark.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.02172v2",
    "published_date": "2024-12-03 05:04:49 UTC",
    "updated_date": "2025-03-18 08:02:22 UTC"
  },
  {
    "arxiv_id": "2412.02166v1",
    "title": "Analyzing the Impact of AI Tools on Student Study Habits and Academic Performance",
    "authors": [
      "Ben Ward",
      "Deepshikha Bhati",
      "Fnu Neha",
      "Angela Guercio"
    ],
    "abstract": "This study explores the effectiveness of AI tools in enhancing student\nlearning, specifically in improving study habits, time management, and feedback\nmechanisms. The research focuses on how AI tools can support personalized\nlearning, adaptive test adjustments, and provide real-time classroom analysis.\nStudent feedback revealed strong support for these features, and the study\nfound a significant reduction in study hours alongside an increase in GPA,\nsuggesting positive academic outcomes. Despite these benefits, challenges such\nas over-reliance on AI and difficulties in integrating AI with traditional\nteaching methods were also identified, emphasizing the need for AI tools to\ncomplement conventional educational strategies rather than replace them. Data\nwere collected through a survey with a Likert scale and follow-up interviews,\nproviding both quantitative and qualitative insights. The analysis involved\ndescriptive statistics to summarize demographic data, AI usage patterns, and\nperceived effectiveness, as well as inferential statistics (T-tests, ANOVA) to\nexamine the impact of demographic factors on AI adoption. Regression analysis\nidentified predictors of AI adoption, and qualitative responses were\nthematically analyzed to understand students' perspectives on the future of AI\nin education. This mixed-methods approach provided a comprehensive view of AI's\nrole in education and highlighted the importance of privacy, transparency, and\ncontinuous refinement of AI features to maximize their educational benefits.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02166v1",
    "published_date": "2024-12-03 04:51:57 UTC",
    "updated_date": "2024-12-03 04:51:57 UTC"
  },
  {
    "arxiv_id": "2412.02159v1",
    "title": "Jailbreak Defense in a Narrow Domain: Limitations of Existing Methods and a New Transcript-Classifier Approach",
    "authors": [
      "Tony T. Wang",
      "John Hughes",
      "Henry Sleight",
      "Rylan Schaeffer",
      "Rajashree Agrawal",
      "Fazl Barez",
      "Mrinank Sharma",
      "Jesse Mu",
      "Nir Shavit",
      "Ethan Perez"
    ],
    "abstract": "Defending large language models against jailbreaks so that they never engage\nin a broadly-defined set of forbidden behaviors is an open problem. In this\npaper, we investigate the difficulty of jailbreak-defense when we only want to\nforbid a narrowly-defined set of behaviors. As a case study, we focus on\npreventing an LLM from helping a user make a bomb. We find that popular\ndefenses such as safety training, adversarial training, and input/output\nclassifiers are unable to fully solve this problem. In pursuit of a better\nsolution, we develop a transcript-classifier defense which outperforms the\nbaseline defenses we test. However, our classifier defense still fails in some\ncircumstances, which highlights the difficulty of jailbreak-defense even in a\nnarrow domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the AdvML-Frontiers and SoLaR workshops at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.02159v1",
    "published_date": "2024-12-03 04:34:58 UTC",
    "updated_date": "2024-12-03 04:34:58 UTC"
  },
  {
    "arxiv_id": "2412.02155v2",
    "title": "CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events",
    "authors": [
      "Xiaojie Yang",
      "Hangli Ge",
      "Jiawei Wang",
      "Zipei Fan",
      "Renhe Jiang",
      "Ryosuke Shibasaki",
      "Noboru Koshizuka"
    ],
    "abstract": "Large-scale human mobility exhibits spatial and temporal patterns that can\nassist policymakers in decision making. Although traditional prediction models\nattempt to capture these patterns, they often interfered by non-periodic public\nevents, such as disasters and occasional celebrations. Since regular human\nmobility patterns are heavily affected by these events, estimating their causal\neffects is critical to accurate mobility predictions. Although news articles\nprovide unique perspectives on these events in an unstructured format,\nprocessing is a challenge. In this study, we propose a causality-augmented\nprediction model, called CausalMob, to analyze the causal effects of public\nevents. We first utilize large language models (LLMs) to extract human\nintentions from news articles and transform them into features that act as\ncausal treatments. Next, the model learns representations of spatio-temporal\nregional covariates from multiple data sources to serve as confounders for\ncausal inference. Finally, we present a causal effect estimation framework to\nensure event features remain independent of confounders during prediction.\nBased on large-scale real-world data, the experimental results show that the\nproposed model excels in human mobility prediction, outperforming\nstate-of-the-art models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02155v2",
    "published_date": "2024-12-03 04:29:27 UTC",
    "updated_date": "2025-01-07 06:30:24 UTC"
  },
  {
    "arxiv_id": "2412.02154v1",
    "title": "Failure Probability Estimation for Black-Box Autonomous Systems using State-Dependent Importance Sampling Proposals",
    "authors": [
      "Harrison Delecki",
      "Sydney M. Katz",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "Estimating the probability of failure is a critical step in developing\nsafety-critical autonomous systems. Direct estimation methods such as Monte\nCarlo sampling are often impractical due to the rarity of failures in these\nsystems. Existing importance sampling approaches do not scale to sequential\ndecision-making systems with large state spaces and long horizons. We propose\nan adaptive importance sampling algorithm to address these limitations. Our\nmethod minimizes the forward Kullback-Leibler divergence between a\nstate-dependent proposal distribution and a relaxed form of the optimal\nimportance sampling distribution. Our method uses Markov score ascent methods\nto estimate this objective. We evaluate our approach on four sequential systems\nand show that it provides more accurate failure probability estimates than\nbaseline Monte Carlo and importance sampling techniques. This work is open\nsourced.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to L4DC 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02154v1",
    "published_date": "2024-12-03 04:28:58 UTC",
    "updated_date": "2024-12-03 04:28:58 UTC"
  },
  {
    "arxiv_id": "2412.02153v2",
    "title": "Revisiting the Initial Steps in Adaptive Gradient Descent Optimization",
    "authors": [
      "Abulikemu Abuduweili",
      "Changliu Liu"
    ],
    "abstract": "Adaptive gradient optimization methods, such as Adam, are prevalent in\ntraining deep neural networks across diverse machine learning tasks due to\ntheir ability to achieve faster convergence. However, these methods often\nsuffer from suboptimal generalization compared to stochastic gradient descent\n(SGD) and exhibit instability, particularly when training Transformer models.\nIn this work, we show the standard initialization of the second-order moment\nestimation ($v_0 =0$) as a significant factor contributing to these\nlimitations. We introduce simple yet effective solutions: initializing the\nsecond-order moment estimation with non-zero values, using either data-driven\nor random initialization strategies. Empirical evaluations demonstrate that our\napproach not only stabilizes convergence but also enhances the final\nperformance of adaptive gradient optimizers. Furthermore, by adopting the\nproposed initialization strategies, Adam achieves performance comparable to\nmany recently proposed variants of adaptive gradient optimization methods. Our\ncode is available at https://github.com/Walleclipse/Adam_Initialization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Conference on Parsimony and Learning (CPAL) 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02153v2",
    "published_date": "2024-12-03 04:28:14 UTC",
    "updated_date": "2025-02-11 16:23:39 UTC"
  },
  {
    "arxiv_id": "2412.02148v1",
    "title": "Mining Tweets to Predict Future Bitcoin Price",
    "authors": [
      "Ashutosh Hathidara",
      "Gaurav Atavale",
      "Suyash Chaudhary"
    ],
    "abstract": "Bitcoin has increased investment interests in people during the last decade.\nWe have seen an increase in the number of posts on social media platforms about\ncryptocurrency, especially Bitcoin. This project focuses on analyzing user\ntweet data in combination with Bitcoin price data to see the relevance between\nprice fluctuations and the conversation between millions of people on Twitter.\nThis study also exploits this relationship between user tweets and bitcoin\nprices to predict the future bitcoin price. We are utilizing novel techniques\nand methods to analyze the data and make price predictions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02148v1",
    "published_date": "2024-12-03 04:09:19 UTC",
    "updated_date": "2024-12-03 04:09:19 UTC"
  },
  {
    "arxiv_id": "2412.02142v1",
    "title": "Personalized Multimodal Large Language Models: A Survey",
    "authors": [
      "Junda Wu",
      "Hanjia Lyu",
      "Yu Xia",
      "Zhehao Zhang",
      "Joe Barrow",
      "Ishita Kumar",
      "Mehrnoosh Mirtaheri",
      "Hongjie Chen",
      "Ryan A. Rossi",
      "Franck Dernoncourt",
      "Tong Yu",
      "Ruiyi Zhang",
      "Jiuxiang Gu",
      "Nesreen K. Ahmed",
      "Yu Wang",
      "Xiang Chen",
      "Hanieh Deilamsalehy",
      "Namyong Park",
      "Sungchul Kim",
      "Huanrui Yang",
      "Subrata Mitra",
      "Zhengmian Hu",
      "Nedim Lipka",
      "Dang Nguyen",
      "Yue Zhao",
      "Jiebo Luo",
      "Julian McAuley"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have become increasingly important\ndue to their state-of-the-art performance and ability to integrate multiple\ndata modalities, such as text, images, and audio, to perform complex tasks with\nhigh accuracy. This paper presents a comprehensive survey on personalized\nmultimodal large language models, focusing on their architecture, training\nmethods, and applications. We propose an intuitive taxonomy for categorizing\nthe techniques used to personalize MLLMs to individual users, and discuss the\ntechniques accordingly. Furthermore, we discuss how such techniques can be\ncombined or adapted when appropriate, highlighting their advantages and\nunderlying rationale. We also provide a succinct summary of personalization\ntasks investigated in existing research, along with the evaluation metrics\ncommonly used. Additionally, we summarize the datasets that are useful for\nbenchmarking personalized MLLMs. Finally, we outline critical open challenges.\nThis survey aims to serve as a valuable resource for researchers and\npractitioners seeking to understand and advance the development of personalized\nmultimodal large language models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02142v1",
    "published_date": "2024-12-03 03:59:03 UTC",
    "updated_date": "2024-12-03 03:59:03 UTC"
  },
  {
    "arxiv_id": "2412.02136v1",
    "title": "Graph Learning for Planning: The Story Thus Far and Open Challenges",
    "authors": [
      "Dillon Z. Chen",
      "Mingyu Hao",
      "Sylvie Thiébaux",
      "Felipe Trevizan"
    ],
    "abstract": "Graph learning is naturally well suited for use in planning due to its\nability to exploit relational structures exhibited in planning domains and to\ntake as input planning instances with arbitrary number of objects. In this\npaper, we study the usage of graph learning for planning thus far by studying\nthe theoretical and empirical effects on learning and planning performance of\n(1) graph representations of planning tasks, (2) graph learning architectures,\nand (3) optimisation formulations for learning. Our studies accumulate in the\nGOOSE framework which learns domain knowledge from small planning tasks in\norder to scale up to much larger planning tasks. In this paper, we also\nhighlight and propose the 5 open challenges in the general Learning for\nPlanning field that we believe need to be addressed for advancing the\nstate-of-the-art.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02136v1",
    "published_date": "2024-12-03 03:49:27 UTC",
    "updated_date": "2024-12-03 03:49:27 UTC"
  },
  {
    "arxiv_id": "2412.02130v1",
    "title": "A privacy-preserving distributed credible evidence fusion algorithm for collective decision-making",
    "authors": [
      "Chaoxiong Ma",
      "Yan Liang",
      "Xinyu Yang",
      "Han Wu",
      "Huixia Zhang"
    ],
    "abstract": "The theory of evidence reasoning has been applied to collective\ndecision-making in recent years. However, existing distributed evidence fusion\nmethods lead to participants' preference leakage and fusion failures as they\ndirectly exchange raw evidence and do not assess evidence credibility like\ncentralized credible evidence fusion (CCEF) does. To do so, a\nprivacy-preserving distributed credible evidence fusion method with three-level\nconsensus (PCEF) is proposed in this paper. In evidence difference measure\n(EDM) neighbor consensus, an evidence-free equivalent expression of EDM among\nneighbored agents is derived with the shared dot product protocol for pignistic\nprobability and the identical judgment of two events with maximal subjective\nprobabilities, so that evidence privacy is guaranteed due to such irreversible\nevidence transformation. In EDM network consensus, the non-neighbored EDMs are\ninferred and neighbored EDMs reach uniformity via interaction between linear\naverage consensus (LAC) and low-rank matrix completion with rank adaptation to\nguarantee EDM consensus convergence and no solution of inferring raw evidence\nin numerical iteration style. In fusion network consensus, a privacy-preserving\nLAC with a self-cancelling differential privacy term is proposed, where each\nagent adds its randomness to the sharing content and step-by-step cancels such\nrandomness in consensus iterations. Besides, the sufficient condition of the\nconvergence to the CCEF is explored, and it is proven that raw evidence is\nimpossibly inferred in such an iterative consensus. The simulations show that\nPCEF is close to CCEF both in credibility and fusion results and obtains higher\ndecision accuracy with less time-comsuming than existing methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02130v1",
    "published_date": "2024-12-03 03:36:42 UTC",
    "updated_date": "2024-12-03 03:36:42 UTC"
  },
  {
    "arxiv_id": "2412.02126v1",
    "title": "Benchmarking symbolic regression constant optimization schemes",
    "authors": [
      "L. G. A dos Reis",
      "V. L. P. S. Caminha",
      "T. J. P. Penna"
    ],
    "abstract": "Symbolic regression is a machine learning technique, and it has seen many\nadvancements in recent years, especially in genetic programming approaches\n(GPSR). Furthermore, it has been known for many years that constant\noptimization of parameters, during the evolutionary search, greatly increases\nGPSR performance However, different authors approach such tasks differently and\nno consensus exists regarding which methods perform best. In this work, we\nevaluate eight different parameter optimization methods, applied during\nevolutionary search, over ten known benchmark problems, in two different\nscenarios. We also propose using an under-explored metric called Tree Edit\nDistance (TED), aiming to identify symbolic accuracy. In conjunction with\nclassical error measures, we develop a combined analysis of model performance\nin symbolic regression. We then show that different constant optimization\nmethods perform better in certain scenarios and that there is no overall best\nchoice for every problem. Finally, we discuss how common metric decisions may\nbe biased and appear to generate better models in comparison.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 10 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.02126v1",
    "published_date": "2024-12-03 03:29:27 UTC",
    "updated_date": "2024-12-03 03:29:27 UTC"
  },
  {
    "arxiv_id": "2412.02125v1",
    "title": "Optimizing Latent Goal by Learning from Trajectory Preference",
    "authors": [
      "Guangyu Zhao",
      "Kewei Lian",
      "Haowei Lin",
      "Haobo Fu",
      "Qiang Fu",
      "Shaofei Cai",
      "Zihao Wang",
      "Yitao Liang"
    ],
    "abstract": "A glowing body of work has emerged focusing on instruction-following policies\nfor open-world agents, aiming to better align the agent's behavior with human\nintentions. However, the performance of these policies is highly susceptible to\nthe initial prompt, which leads to extra efforts in selecting the best\ninstructions. We propose a framework named Preference Goal Tuning (PGT). PGT\nallows an instruction following policy to interact with the environment to\ncollect several trajectories, which will be categorized into positive and\nnegative samples based on preference. Then we use preference learning to\nfine-tune the initial goal latent representation with the categorized\ntrajectories while keeping the policy backbone frozen. The experiment result\nshows that with minimal data and training, PGT achieves an average relative\nimprovement of 72.0% and 81.6% over 17 tasks in 2 different foundation policies\nrespectively, and outperforms the best human-selected instructions. Moreover,\nPGT surpasses full fine-tuning in the out-of-distribution (OOD) task-execution\nenvironments by 13.4%, indicating that our approach retains strong\ngeneralization capabilities. Since our approach stores a single latent\nrepresentation for each task independently, it can be viewed as an efficient\nmethod for continual learning, without the risk of catastrophic forgetting or\ntask interference. In short, PGT enhances the performance of agents across\nnearly all tasks in the Minecraft Skillforge benchmark and demonstrates\nrobustness to the execution environment.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02125v1",
    "published_date": "2024-12-03 03:27:48 UTC",
    "updated_date": "2024-12-03 03:27:48 UTC"
  },
  {
    "arxiv_id": "2412.02114v2",
    "title": "Beyond Generation: Unlocking Universal Editing via Self-Supervised Fine-Tuning",
    "authors": [
      "Harold Haodong Chen",
      "Harry Yang",
      "Ser-Nam Lim"
    ],
    "abstract": "Recent advances in video generation have outpaced progress in video editing,\nwhich remains constrained by several limiting factors, namely: (a) the task's\ndependency on supervision severely limits generality, (b) an unnecessary\nartificial separation between the generation and editing task, and (c) the high\ncomputational costs of training a video model. In this work, we propose UES\n(Unlocking Universal Editing via Self-Supervision), a lightweight\nself-supervised fine-tuning strategy that transforms generation models into\nunified generation-editing systems through self-supervised semantic alignment.\nOur approach establishes a dual-conditioning mechanism where original\nvideo-text pairs jointly provide visual and textual semantics, enabling\nstructured learning of intrinsic spatiotemporal correspondences. Key advantages\ninclude: (i) Universality through supervision-free adaptation to diverse\nediting tasks, (ii) Unification of generation and editing applicable to most\ntext(+image)-to-video model, and (iii) Efficiency via lightweight fine-tune\nthat reduces tunable parameters by 92.67%. To enable systematic evaluation, we\nintroduce OmniBench-99, a comprehensive benchmark spanning 99 videos across\nhumans/animals, environments, and objects, comprising 4 editing types and 8\nscenarios. Extensive experiments show UES enables models without inherent\nediting capability to perform powerful and universal editing while preserving\nor even enhancing their original generation performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project: https://haroldchen19.github.io/UES-Page/",
    "pdf_url": "http://arxiv.org/pdf/2412.02114v2",
    "published_date": "2024-12-03 03:10:19 UTC",
    "updated_date": "2025-03-18 10:51:59 UTC"
  },
  {
    "arxiv_id": "2412.02113v1",
    "title": "Trust & Safety of LLMs and LLMs in Trust & Safety",
    "authors": [
      "Doohee You",
      "Dan Chon"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have garnered considerable\nattention for their remarkable abilities in natural language processing tasks.\nHowever, their widespread adoption has raised concerns pertaining to trust and\nsafety. This systematic review investigates the current research landscape on\ntrust and safety in LLMs, with a particular focus on the novel application of\nLLMs within the field of Trust and Safety itself. We delve into the\ncomplexities of utilizing LLMs in domains where maintaining trust and safety is\nparamount, offering a consolidated perspective on this emerging trend.\\\n  By synthesizing findings from various studies, we identify key challenges and\npotential solutions, aiming to benefit researchers and practitioners seeking to\nunderstand the nuanced interplay between LLMs and Trust and Safety.\n  This review provides insights on best practices for using LLMs in Trust and\nSafety, and explores emerging risks such as prompt injection and jailbreak\nattacks. Ultimately, this study contributes to a deeper understanding of how\nLLMs can be effectively and responsibly utilized to enhance trust and safety in\nthe digital realm.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.02113v1",
    "published_date": "2024-12-03 03:10:12 UTC",
    "updated_date": "2024-12-03 03:10:12 UTC"
  },
  {
    "arxiv_id": "2412.04503v1",
    "title": "A Primer on Large Language Models and their Limitations",
    "authors": [
      "Sandra Johnson",
      "David Hyland-Wood"
    ],
    "abstract": "This paper provides a primer on Large Language Models (LLMs) and identifies\ntheir strengths, limitations, applications and research directions. It is\nintended to be useful to those in academia and industry who are interested in\ngaining an understanding of the key LLM concepts and technologies, and in\nutilising this knowledge in both day to day tasks and in more complex scenarios\nwhere this technology can enhance current practices and processes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.CL",
    "comment": "33 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.04503v1",
    "published_date": "2024-12-03 02:45:02 UTC",
    "updated_date": "2024-12-03 02:45:02 UTC"
  },
  {
    "arxiv_id": "2412.02099v1",
    "title": "AccDiffusion v2: Towards More Accurate Higher-Resolution Diffusion Extrapolation",
    "authors": [
      "Zhihang Lin",
      "Mingbao Lin",
      "Wengyi Zhan",
      "Rongrong Ji"
    ],
    "abstract": "Diffusion models suffer severe object repetition and local distortion when\nthe inference resolution differs from its pre-trained resolution. We propose\nAccDiffusion v2, an accurate method for patch-wise higher-resolution diffusion\nextrapolation without training. Our in-depth analysis in this paper shows that\nusing an identical text prompt for different patches leads to repetitive\ngeneration, while the absence of a prompt undermines image details. In\nresponse, our AccDiffusion v2 novelly decouples the vanilla image-content-aware\nprompt into a set of patch-content-aware prompts, each of which serves as a\nmore precise description of a patch. Further analysis reveals that local\ndistortion arises from inaccurate descriptions in prompts about the local\nstructure of higher-resolution images. To address this issue, AccDiffusion v2,\nfor the first time, introduces an auxiliary local structural information\nthrough ControlNet during higher-resolution diffusion extrapolation aiming to\nmitigate the local distortions. Finally, our analysis indicates that global\nsemantic information is conducive to suppressing both repetitive generation and\nlocal distortion. Hence, our AccDiffusion v2 further proposes dilated sampling\nwith window interaction for better global semantic information during\nhigher-resolution diffusion extrapolation. We conduct extensive experiments,\nincluding both quantitative and qualitative comparisons, to demonstrate the\nefficacy of our AccDiffusion v2. The quantitative comparison shows that\nAccDiffusion v2 achieves state-of-the-art performance in image generation\nextrapolation without training. The qualitative comparison intuitively\nillustrates that AccDiffusion v2 effectively suppresses the issues of\nrepetitive generation and local distortion in image generation extrapolation.\nOur code is available at \\url{https://github.com/lzhxmu/AccDiffusion_v2}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages. arXiv admin note: text overlap with arXiv:2407.10738",
    "pdf_url": "http://arxiv.org/pdf/2412.02099v1",
    "published_date": "2024-12-03 02:44:35 UTC",
    "updated_date": "2024-12-03 02:44:35 UTC"
  },
  {
    "arxiv_id": "2412.02091v2",
    "title": "The Problem of Social Cost in Multi-Agent General Reinforcement Learning: Survey and Synthesis",
    "authors": [
      "Kee Siong Ng",
      "Samuel Yang-Zhao",
      "Timothy Cadogan-Cowper"
    ],
    "abstract": "The AI safety literature is full of examples of powerful AI agents that, in\nblindly pursuing a specific and usually narrow objective, ends up with\nunacceptable and even catastrophic collateral damage to others. In this paper,\nwe consider the problem of social harms that can result from actions taken by\nlearning and utility-maximising agents in a multi-agent environment. The\nproblem of measuring social harms or impacts in such multi-agent settings,\nespecially when the agents are artificial generally intelligent (AGI) agents,\nwas listed as an open problem in Everitt et al, 2018. We attempt a partial\nanswer to that open problem in the form of market-based mechanisms to quantify\nand control the cost of such social harms. The proposed setup captures many\nwell-studied special cases and is more general than existing formulations of\nmulti-agent reinforcement learning with mechanism design in two ways: (i) the\nunderlying environment is a history-based general reinforcement learning\nenvironment like in AIXI; (ii) the reinforcement-learning agents participating\nin the environment can have different learning strategies and planning\nhorizons. To demonstrate the practicality of the proposed setup, we survey some\nkey classes of learning algorithms and present a few applications, including a\ndiscussion of the Paperclips problem and pollution control with a cap-and-trade\nsystem.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.MA",
      "I.2.11"
    ],
    "primary_category": "cs.AI",
    "comment": "67 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.02091v2",
    "published_date": "2024-12-03 02:22:55 UTC",
    "updated_date": "2025-04-13 01:25:54 UTC"
  },
  {
    "arxiv_id": "2412.02085v1",
    "title": "Evolution of Collective AI Beyond Individual Optimization",
    "authors": [
      "Ryosuke Takata",
      "Yujin Tang",
      "Yingtao Tian",
      "Norihiro Maruyama",
      "Hiroki Kojima",
      "Takashi Ikegami"
    ],
    "abstract": "This study investigates collective behaviors that emerge from a group of\nhomogeneous individuals optimized for a specific capability. We created a group\nof simple, identical neural network based agents modeled after\nchemotaxis-driven vehicles that follow pheromone trails and examined\nmulti-agent simulations using clones of these evolved individuals. Our results\nshow that the evolution of individuals led to population differentiation.\nSurprisingly, we observed that collective fitness significantly changed during\nlater evolutionary stages, despite maintained high individual performance and\nsimplified neural architectures. This decline occurred when agents developed\nreduced sensor-motor coupling, suggesting that over-optimization of individual\nagents almost always lead to less effective group behavior. Our research\ninvestigates how individual differentiation can evolve through what\nevolutionary pathways.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02085v1",
    "published_date": "2024-12-03 02:03:36 UTC",
    "updated_date": "2024-12-03 02:03:36 UTC"
  },
  {
    "arxiv_id": "2412.02084v1",
    "title": "Comparative Analysis of Black-Box and White-Box Machine Learning Model in Phishing Detection",
    "authors": [
      "Abdullah Fajar",
      "Setiadi Yazid",
      "Indra Budi"
    ],
    "abstract": "Background: Explainability in phishing detection model can support a further\nsolution of phishing attack mitigation by increasing trust and understanding\nhow phishing can be detected. Objective: The aims of this study to determine\nand best recommendation to apply an approach which has several components with\nabilities to fulfil the critical needs Methods: A methodology starting with\nanalyzing both black-box and white-box models to get the pros and cons\nspecifically in phishing detection. The conclusion of the analysis will be\nvalidated by experiment using a set of well-known algorithms and public\nphishing datasets. Experimental metrics covers 3 measurements such as\npredictive accuracy and explainability metrics. Conclusion: Both models are\ncomparable in terms of interpretability and consistency, with room for\nimprovement in diverse datasets. EBM as an example of white-box model is\ngenerally better suited for applications requiring explainability and\nactionable insights. Finally, each model, white-box and black-box model has\npositive and negative aspects both for performance metric and for explainable\nmetric. It is important to consider the objective of model usage.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02084v1",
    "published_date": "2024-12-03 02:00:47 UTC",
    "updated_date": "2024-12-03 02:00:47 UTC"
  },
  {
    "arxiv_id": "2412.02083v2",
    "title": "Implementing An Artificial Quantum Perceptron",
    "authors": [
      "Ashutosh Hathidara",
      "Lalit Pandey"
    ],
    "abstract": "A Perceptron is a fundamental building block of a neural network. The\nflexibility and scalability of perceptron make it ubiquitous in building\nintelligent systems. Studies have shown the efficacy of a single neuron in\nmaking intelligent decisions. Here, we examined and compared two perceptrons\nwith distinct mechanisms, and developed a quantum version of one of those\nperceptrons. As a part of this modeling, we implemented the quantum circuit for\nan artificial perception, generated a dataset, and simulated the training.\nThrough these experiments, we show that there is an exponential growth\nadvantage and test different qubit versions. Our findings show that this\nquantum model of an individual perceptron can be used as a pattern classifier.\nFor the second type of model, we provide an understanding to design and\nsimulate a spike-dependent quantum perceptron. Our code is available at\nhttps://github.com/ashutosh1919/quantum-perceptron",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02083v2",
    "published_date": "2024-12-03 01:57:09 UTC",
    "updated_date": "2025-03-24 14:54:27 UTC"
  },
  {
    "arxiv_id": "2412.02065v1",
    "title": "Leveraging Large Language Models to Democratize Access to Costly Financial Datasets for Academic Research",
    "authors": [
      "Julian Junyan Wang",
      "Victor Xiaoqi Wang"
    ],
    "abstract": "Unequal access to costly datasets essential for empirical research has long\nhindered researchers from disadvantaged institutions, limiting their ability to\ncontribute to their fields and advance their careers. Recent breakthroughs in\nLarge Language Models (LLMs) have the potential to democratize data access by\nautomating data collection from unstructured sources. We develop and evaluate a\nnovel methodology using GPT-4o-mini within a Retrieval-Augmented Generation\n(RAG) framework to collect data from corporate disclosures. Our approach\nachieves human-level accuracy in collecting CEO pay ratios from approximately\n10,000 proxy statements and Critical Audit Matters (CAMs) from more than 12,000\n10-K filings, with LLM processing times of 9 and 40 minutes respectively, each\nat a cost under $10. This stands in stark contrast to the hundreds of hours\nneeded for manual collection or the thousands of dollars required for\ncommercial database subscriptions. To foster a more inclusive research\ncommunity by empowering researchers with limited resources to explore new\navenues of inquiry, we share our methodology and the resulting datasets.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "q-fin.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02065v1",
    "published_date": "2024-12-03 00:59:56 UTC",
    "updated_date": "2024-12-03 00:59:56 UTC"
  },
  {
    "arxiv_id": "2412.02062v1",
    "title": "Construction and optimization of health behavior prediction model for the elderly in smart elderly care",
    "authors": [
      "Qian Guo",
      "Peiyuan Chen"
    ],
    "abstract": "With the intensification of global aging, health management of the elderly\nhas become a focus of social attention. This study designs and implements a\nsmart elderly care service model to address issues such as data diversity,\nhealth status complexity, long-term dependence and data loss, sudden changes in\nbehavior, and data privacy in the prediction of health behaviors of the\nelderly. The model achieves accurate prediction and dynamic management of\nhealth behaviors of the elderly through modules such as multimodal data fusion,\ndata loss processing, nonlinear prediction, emergency detection, and privacy\nprotection. In the experimental design, based on multi-source data sets and\nmarket research results, the model demonstrates excellent performance in health\nbehavior prediction, emergency detection, and personalized services. The\nexperimental results show that the model can effectively improve the accuracy\nand robustness of health behavior prediction and meet the actual application\nneeds in the field of smart elderly care. In the future, with the integration\nof more data and further optimization of technology, the model will provide\nmore powerful technical support for smart elderly care services.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.02062v1",
    "published_date": "2024-12-03 00:47:42 UTC",
    "updated_date": "2024-12-03 00:47:42 UTC"
  },
  {
    "arxiv_id": "2412.02057v2",
    "title": "Comparative Analysis of Multi-Agent Reinforcement Learning Policies for Crop Planning Decision Support",
    "authors": [
      "Anubha Mahajan",
      "Shreya Hegde",
      "Ethan Shay",
      "Daniel Wu",
      "Aviva Prins"
    ],
    "abstract": "In India, the majority of farmers are classified as small or marginal, making\ntheir livelihoods particularly vulnerable to economic losses due to market\nsaturation and climate risks. Effective crop planning can significantly impact\ntheir expected income, yet existing decision support systems (DSS) often\nprovide generic recommendations that fail to account for real-time market\ndynamics and the interactions among multiple farmers. In this paper, we\nevaluate the viability of three multi-agent reinforcement learning (MARL)\napproaches for optimizing total farmer income and promoting fairness in crop\nplanning: Independent Q-Learning (IQL), where each farmer acts independently\nwithout coordination, Agent-by-Agent (ABA), which sequentially optimizes each\nfarmer's policy in relation to the others, and the Multi-agent Rollout Policy,\nwhich jointly optimizes all farmers' actions for global reward maximization.\nOur results demonstrate that while IQL offers computational efficiency with\nlinear runtime, it struggles with coordination among agents, leading to lower\ntotal rewards and an unequal distribution of income. Conversely, the\nMulti-agent Rollout policy achieves the highest total rewards and promotes\nequitable income distribution among farmers but requires significantly more\ncomputational resources, making it less practical for large numbers of agents.\nABA strikes a balance between runtime efficiency and reward optimization,\noffering reasonable total rewards with acceptable fairness and scalability.\nThese findings highlight the importance of selecting appropriate MARL\napproaches in DSS to provide personalized and equitable crop planning\nrecommendations, advancing the development of more adaptive and farmer-centric\nagricultural decision-making systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02057v2",
    "published_date": "2024-12-03 00:30:19 UTC",
    "updated_date": "2025-02-24 16:57:07 UTC"
  },
  {
    "arxiv_id": "2412.02043v1",
    "title": "Future of Information Retrieval Research in the Age of Generative AI",
    "authors": [
      "James Allan",
      "Eunsol Choi",
      "Daniel P. Lopresti",
      "Hamed Zamani"
    ],
    "abstract": "In the fast-evolving field of information retrieval (IR), the integration of\ngenerative AI technologies such as large language models (LLMs) is transforming\nhow users search for and interact with information. Recognizing this paradigm\nshift at the intersection of IR and generative AI (IR-GenAI), a visioning\nworkshop supported by the Computing Community Consortium (CCC) was held in July\n2024 to discuss the future of IR in the age of generative AI. This workshop\nconvened 44 experts in information retrieval, natural language processing,\nhuman-computer interaction, and artificial intelligence from academia,\nindustry, and government to explore how generative AI can enhance IR and vice\nversa, and to identify the major challenges and opportunities in this rapidly\nadvancing field.\n  This report contains a summary of discussions as potentially important\nresearch topics and contains a list of recommendations for academics, industry\npractitioners, institutions, evaluation campaigns, and funding agencies.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02043v1",
    "published_date": "2024-12-03 00:01:48 UTC",
    "updated_date": "2024-12-03 00:01:48 UTC"
  }
]