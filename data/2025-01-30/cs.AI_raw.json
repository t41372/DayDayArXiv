[
  {
    "arxiv_id": "2501.18801v1",
    "title": "Every Image Listens, Every Image Dances: Music-Driven Image Animation",
    "authors": [
      "Zhikang Dong",
      "Weituo Hao",
      "Ju-Chiang Wang",
      "Peng Zhang",
      "Pawel Polak"
    ],
    "abstract": "Image animation has become a promising area in multimodal research, with a\nfocus on generating videos from reference images. While prior work has largely\nemphasized generic video generation guided by text, music-driven dance video\ngeneration remains underexplored. In this paper, we introduce MuseDance, an\ninnovative end-to-end model that animates reference images using both music and\ntext inputs. This dual input enables MuseDance to generate personalized videos\nthat follow text descriptions and synchronize character movements with the\nmusic. Unlike existing approaches, MuseDance eliminates the need for complex\nmotion guidance inputs, such as pose or depth sequences, making flexible and\ncreative video generation accessible to users of all expertise levels. To\nadvance research in this field, we present a new multimodal dataset comprising\n2,904 dance videos with corresponding background music and text descriptions.\nOur approach leverages diffusion-based methods to achieve robust\ngeneralization, precise control, and temporal consistency, setting a new\nbaseline for the music-driven image animation task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18801v1",
    "published_date": "2025-01-30 23:38:51 UTC",
    "updated_date": "2025-01-30 23:38:51 UTC"
  },
  {
    "arxiv_id": "2501.18797v1",
    "title": "Compositional Generalization Requires More Than Disentangled Representations",
    "authors": [
      "Qiyao Liang",
      "Daoyuan Qian",
      "Liu Ziyin",
      "Ila Fiete"
    ],
    "abstract": "Composition-the ability to generate myriad variations from finite means-is\nbelieved to underlie powerful generalization. However, compositional\ngeneralization remains a key challenge for deep learning. A widely held\nassumption is that learning disentangled (factorized) representations naturally\nsupports this kind of extrapolation. Yet, empirical results are mixed, with\nmany generative models failing to recognize and compose factors to generate\nout-of-distribution (OOD) samples. In this work, we investigate a controlled 2D\nGaussian \"bump\" generation task, demonstrating that standard generative\narchitectures fail in OOD regions when training with partial data, even when\nsupplied with fully disentangled $(x, y)$ coordinates, re-entangling them\nthrough subsequent layers. By examining the model's learned kernels and\nmanifold geometry, we show that this failure reflects a \"memorization\" strategy\nfor generation through the superposition of training data rather than by\ncombining the true factorized features. We show that models forced-through\narchitectural modifications with regularization or curated training data-to\ncreate disentangled representations in the full-dimensional representational\n(pixel) space can be highly data-efficient and effective at learning to compose\nin OOD regions. These findings underscore that bottlenecks with\nfactorized/disentangled representations in an abstract representation are\ninsufficient: the model must actively maintain or induce factorization directly\nin the representational space in order to achieve robust compositional\ngeneralization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures, plus appendix",
    "pdf_url": "http://arxiv.org/pdf/2501.18797v1",
    "published_date": "2025-01-30 23:20:41 UTC",
    "updated_date": "2025-01-30 23:20:41 UTC"
  },
  {
    "arxiv_id": "2501.18794v1",
    "title": "Survey and Improvement Strategies for Gene Prioritization with Large Language Models",
    "authors": [
      "Matthew Neeley",
      "Guantong Qi",
      "Guanchu Wang",
      "Ruixiang Tang",
      "Dongxue Mao",
      "Chaozhong Liu",
      "Sasidhar Pasupuleti",
      "Bo Yuan",
      "Fan Xia",
      "Pengfei Liu",
      "Zhandong Liu",
      "Xia Hu"
    ],
    "abstract": "Rare diseases are challenging to diagnose due to limited patient data and\ngenetic diversity. Despite advances in variant prioritization, many cases\nremain undiagnosed. While large language models (LLMs) have performed well in\nmedical exams, their effectiveness in diagnosing rare genetic diseases has not\nbeen assessed. To identify causal genes, we benchmarked various LLMs for gene\nprioritization. Using multi-agent and Human Phenotype Ontology (HPO)\nclassification, we categorized patients based on phenotypes and solvability\nlevels. As gene set size increased, LLM performance deteriorated, so we used a\ndivide-and-conquer strategy to break the task into smaller subsets. At\nbaseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking\ncausal genes correctly. The multi-agent and HPO approaches helped distinguish\nconfidently solved cases from challenging ones, highlighting the importance of\nknown gene-phenotype associations and phenotype specificity. We found that\ncases with specific phenotypes or clear associations were more accurately\nsolved. However, we observed biases toward well-studied genes and input order\nsensitivity, which hindered gene prioritization. Our divide-and-conquer\nstrategy improved accuracy by overcoming these biases. By utilizing HPO\nclassification, novel multi-agent techniques, and our LLM strategy, we improved\ncausal gene identification accuracy compared to our baseline evaluation. This\napproach streamlines rare disease diagnosis, facilitates reanalysis of unsolved\ncases, and accelerates gene discovery, supporting the development of targeted\ndiagnostics and therapies.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "11 pages, 4 figures, 10 pages of supplementary figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18794v1",
    "published_date": "2025-01-30 23:03:03 UTC",
    "updated_date": "2025-01-30 23:03:03 UTC"
  },
  {
    "arxiv_id": "2501.18793v1",
    "title": "OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization",
    "authors": [
      "Kelvin Kan",
      "Xingjian Li",
      "Stanley Osher"
    ],
    "abstract": "Transformers have achieved state-of-the-art performance in numerous tasks. In\nthis paper, we propose a continuous-time formulation of transformers.\nSpecifically, we consider a dynamical system whose governing equation is\nparametrized by transformer blocks. We leverage optimal transport theory to\nregularize the training problem, which enhances stability in training and\nimproves generalization of the resulting model. Moreover, we demonstrate in\ntheory that this regularization is necessary as it promotes uniqueness and\nregularity of solutions. Our model is flexible in that almost any existing\ntransformer architectures can be adopted to construct the dynamical system with\nonly slight modifications to the existing code. We perform extensive numerical\nexperiments on tasks motivated by natural language processing, image\nclassification, and point cloud classification. Our experimental results show\nthat the proposed method improves the performance of its discrete counterpart\nand outperforms relevant comparing models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18793v1",
    "published_date": "2025-01-30 22:52:40 UTC",
    "updated_date": "2025-01-30 22:52:40 UTC"
  },
  {
    "arxiv_id": "2501.18784v1",
    "title": "LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?",
    "authors": [
      "Alexander Tuisov",
      "Yonatan Vernik",
      "Alexander Shleyfman"
    ],
    "abstract": "Domain-independent heuristics have long been a cornerstone of AI planning,\noffering general solutions applicable across a wide range of tasks without\nrequiring domain-specific engineering. However, the advent of large language\nmodels (LLMs) presents an opportunity to generate heuristics tailored to\nspecific planning problems, potentially challenging the necessity of domain\nindependence as a strict design principle. In this paper, we explore the use of\nLLMs to automatically derive planning heuristics from task descriptions\nrepresented as successor generators and goal tests written in general purpose\nprogramming language. We investigate the trade-offs between domain-specific\nLLM-generated heuristics and traditional domain-independent methods in terms of\ncomputational efficiency and explainability. Our experiments demonstrate that\nLLMs can create heuristics that achieve state-of-the-art performance on some\nstandard IPC domains, as well as their ability to solve problems that lack an\nadequate Planning Domain Definition Language ({\\sc pddl}) representation. We\ndiscuss whether these results signify a paradigm shift and how they can\ncomplement existing approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18784v1",
    "published_date": "2025-01-30 22:21:12 UTC",
    "updated_date": "2025-01-30 22:21:12 UTC"
  },
  {
    "arxiv_id": "2501.18771v1",
    "title": "Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data Contamination's Impact on Machine Translation",
    "authors": [
      "Muhammed Yusuf Kocyigit",
      "Eleftheria Briakou",
      "Daniel Deutsch",
      "Jiaming Luo",
      "Colin Cherry",
      "Markus Freitag"
    ],
    "abstract": "Data contamination -- the accidental consumption of evaluation examples\nwithin the pre-training data -- can undermine the validity of evaluation\nbenchmarks. In this paper, we present a rigorous analysis of the effects of\ncontamination on language models at 1B and 8B scales on the machine translation\ntask. Starting from a carefully decontaminated train-test split, we\nsystematically introduce contamination at various stages, scales, and data\nformats to isolate its effect and measure its impact on performance metrics.\nOur experiments reveal that contamination with both source and target\nsubstantially inflates BLEU scores, and this inflation is 2.5 times larger (up\nto 30 BLEU points) for 8B compared to 1B models. In contrast, source-only and\ntarget-only contamination generally produce smaller, less consistent\nover-estimations. Finally, we study how the temporal distribution and frequency\nof contaminated samples influence performance over-estimation across languages\nwith varying degrees of data resources.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18771v1",
    "published_date": "2025-01-30 21:51:18 UTC",
    "updated_date": "2025-01-30 21:51:18 UTC"
  },
  {
    "arxiv_id": "2501.18768v2",
    "title": "Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization",
    "authors": [
      "Michael S. Yao",
      "James C. Gee",
      "Osbert Bastani"
    ],
    "abstract": "The goal of offline model-based optimization (MBO) is to propose new designs\nthat maximize a reward function given only an offline dataset. However, an\nimportant desiderata is to also propose a diverse set of final candidates that\ncapture many optimal and near-optimal design configurations. We propose\nDiversity in Adversarial Model-based Optimization (DynAMO) as a novel method to\nintroduce design diversity as an explicit objective into any MBO problem. Our\nkey insight is to formulate diversity as a distribution matching problem where\nthe distribution of generated designs captures the inherent diversity contained\nwithin the offline dataset. Extensive experiments spanning multiple scientific\ndomains show that DynAMO can be used with common optimization methods to\nsignificantly improve the diversity of proposed designs while still discovering\nhigh-quality candidates.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "52 pages, Accepted to ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.18768v2",
    "published_date": "2025-01-30 21:43:25 UTC",
    "updated_date": "2025-05-01 13:57:53 UTC"
  },
  {
    "arxiv_id": "2501.18766v1",
    "title": "Breaking the Fake News Barrier: Deep Learning Approaches in Bangla Language",
    "authors": [
      "Pronoy Kumar Mondal",
      "Sadman Sadik Khan",
      "Md. Masud Rana",
      "Shahriar Sultan Ramit",
      "Abdus Sattar",
      "Md. Sadekur Rahman"
    ],
    "abstract": "The rapid development of digital stages has greatly compounded the dispersal\nof untrue data, dissolving certainty and judgment in society, especially among\nthe Bengali-speaking community. Our ponder addresses this critical issue by\npresenting an interesting strategy that utilizes a profound learning\ninnovation, particularly the Gated Repetitive Unit (GRU), to recognize fake\nnews within the Bangla dialect. The strategy of our proposed work incorporates\nintensive information preprocessing, which includes lemmatization,\ntokenization, and tending to course awkward nature by oversampling. This comes\nabout in a dataset containing 58,478 passages. We appreciate the creation of a\ndemonstration based on GRU (Gated Repetitive Unit) that illustrates remarkable\nexecution with a noteworthy precision rate of 94%. This ponder gives an\nintensive clarification of the methods included in planning the information,\nselecting the show, preparing it, and assessing its execution. The performance\nof the model is investigated by reliable metrics like precision, recall, F1\nscore, and accuracy. The commitment of the work incorporates making a huge fake\nnews dataset in Bangla and a demonstration that has outperformed other Bangla\nfake news location models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, THE 15th INTERNATIONAL IEEE CONFERENCE ON COMPUTING,\n  COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT)",
    "pdf_url": "http://arxiv.org/pdf/2501.18766v1",
    "published_date": "2025-01-30 21:41:26 UTC",
    "updated_date": "2025-01-30 21:41:26 UTC"
  },
  {
    "arxiv_id": "2502.01652v1",
    "title": "Hybrid Group Relative Policy Optimization: A Multi-Sample Approach to Enhancing Policy Optimization",
    "authors": [
      "Soham Sane"
    ],
    "abstract": "Hybrid Group Relative Policy Optimization (Hybrid GRPO) is a reinforcement\nlearning framework that extends Proximal Policy Optimization (PPO) and Group\nRelative Policy Optimization (GRPO) by incorporating empirical multi-sample\naction evaluation while preserving the stability of value function-based\nlearning. Unlike DeepSeek GRPO, which eliminates the value function in favor of\npurely empirical reward estimation, Hybrid GRPO introduces a structured\nadvantage computation method that balances empirical action sampling with\nbootstrapped value estimation. This approach enhances sample efficiency,\nimproves learning stability, and mitigates variance amplification observed in\npurely empirical methods. A detailed mathematical comparison between PPO,\nDeepSeek GRPO, and Hybrid GRPO is presented, highlighting key differences in\nadvantage estimation and policy updates. Experimental validation in a\ncontrolled reinforcement learning environment demonstrates that Hybrid GRPO\nachieves superior convergence speed, more stable policy updates, and improved\nsample efficiency compared to existing methods. Several extensions to Hybrid\nGRPO are explored, including entropy-regularized sampling, hierarchical\nmulti-step sub-sampling, adaptive reward normalization, and value-based action\nselection. Beyond reinforcement learning in simulated environments, Hybrid GRPO\nprovides a scalable framework for bridging the gap between large language\nmodels (LLMs) and real-world agent-based decision-making. By integrating\nstructured empirical sampling with reinforcement learning stability mechanisms,\nHybrid GRPO has potential applications in autonomous robotics, financial\nmodeling, and AI-driven control systems. These findings suggest that Hybrid\nGRPO serves as a robust and adaptable reinforcement learning methodology,\npaving the way for further advancements in policy optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 Pages, 18 Equations, 1 Table",
    "pdf_url": "http://arxiv.org/pdf/2502.01652v1",
    "published_date": "2025-01-30 21:04:01 UTC",
    "updated_date": "2025-01-30 21:04:01 UTC"
  },
  {
    "arxiv_id": "2501.18741v1",
    "title": "Synthetic Data Generation for Augmenting Small Samples",
    "authors": [
      "Dan Liu",
      "Samer El Kababji",
      "Nicholas Mitsakakis",
      "Lisa Pilgram",
      "Thomas Walters",
      "Mark Clemons",
      "Greg Pond",
      "Alaa El-Hussuna",
      "Khaled El Emam"
    ],
    "abstract": "Small datasets are common in health research. However, the generalization\nperformance of machine learning models is suboptimal when the training datasets\nare small. To address this, data augmentation is one solution. Augmentation\nincreases sample size and is seen as a form of regularization that increases\nthe diversity of small datasets, leading them to perform better on unseen data.\nWe found that augmentation improves prognostic performance for datasets that:\nhave fewer observations, with smaller baseline AUC, have higher cardinality\ncategorical variables, and have more balanced outcome variables. No specific\ngenerative model consistently outperformed the others. We developed a decision\nsupport model that can be used to inform analysts if augmentation would be\nuseful. For seven small application datasets, augmenting the existing data\nresults in an increase in AUC between 4.31% (AUC from 0.71 to 0.75) and 43.23%\n(AUC from 0.51 to 0.73), with an average 15.55% relative improvement,\ndemonstrating the nontrivial impact of augmentation on small datasets\n(p=0.0078). Augmentation AUC was higher than resampling only AUC (p=0.016). The\ndiversity of augmented datasets was higher than the diversity of resampled\ndatasets (p=0.046).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18741v1",
    "published_date": "2025-01-30 20:44:37 UTC",
    "updated_date": "2025-01-30 20:44:37 UTC"
  },
  {
    "arxiv_id": "2501.18739v1",
    "title": "Neural Graph Pattern Machine",
    "authors": [
      "Zehong Wang",
      "Zheyuan Zhang",
      "Tianyi Ma",
      "Nitesh V Chawla",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "Graph learning tasks require models to comprehend essential substructure\npatterns relevant to downstream tasks, such as triadic closures in social\nnetworks and benzene rings in molecular graphs. Due to the non-Euclidean nature\nof graphs, existing graph neural networks (GNNs) rely on message passing to\niteratively aggregate information from local neighborhoods. Despite their\nempirical success, message passing struggles to identify fundamental\nsubstructures, such as triangles, limiting its expressiveness. To overcome this\nlimitation, we propose the Neural Graph Pattern Machine (GPM), a framework\ndesigned to learn directly from graph patterns. GPM efficiently extracts and\nencodes substructures while identifying the most relevant ones for downstream\ntasks. We also demonstrate that GPM offers superior expressivity and improved\nlong-range information modeling compared to message passing. Empirical\nevaluations on node classification, link prediction, graph classification, and\nregression show the superiority of GPM over state-of-the-art baselines. Further\nanalysis reveals its desirable out-of-distribution robustness, scalability, and\ninterpretability. We consider GPM to be a step toward going beyond message\npassing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18739v1",
    "published_date": "2025-01-30 20:37:47 UTC",
    "updated_date": "2025-01-30 20:37:47 UTC"
  },
  {
    "arxiv_id": "2501.18733v1",
    "title": "Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation",
    "authors": [
      "Yuelei Li",
      "Ge Yan",
      "Annabella Macaluso",
      "Mazeyu Ji",
      "Xueyan Zou",
      "Xiaolong Wang"
    ],
    "abstract": "The recent advancements in visual reasoning capabilities of large multimodal\nmodels (LMMs) and the semantic enrichment of 3D feature fields have expanded\nthe horizons of robotic capabilities. These developments hold significant\npotential for bridging the gap between high-level reasoning from LMMs and\nlow-level control policies utilizing 3D feature fields. In this work, we\nintroduce LMM-3DP, a framework that can integrate LMM planners and 3D skill\nPolicies. Our approach consists of three key perspectives: high-level planning,\nlow-level control, and effective integration. For high-level planning, LMM-3DP\nsupports dynamic scene understanding for environment disturbances, a critic\nagent with self-feedback, history policy memorization, and reattempts after\nfailures. For low-level control, LMM-3DP utilizes a semantic-aware 3D feature\nfield for accurate manipulation. In aligning high-level and low-level control\nfor robot actions, language embeddings representing the high-level policy are\njointly attended with the 3D feature field in the 3D transformer for seamless\nintegration. We extensively evaluate our approach across multiple skills and\nlong-horizon tasks in a real-world kitchen environment. Our results show a\nsignificant 1.45x success rate increase in low-level control and an approximate\n1.5x improvement in high-level planning accuracy compared to LLM-based\nbaselines. Demo videos and an overview of LMM-3DP are available at\nhttps://lmm-3dp-release.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18733v1",
    "published_date": "2025-01-30 20:19:01 UTC",
    "updated_date": "2025-01-30 20:19:01 UTC"
  },
  {
    "arxiv_id": "2501.18727v2",
    "title": "Exploring Audio Editing Features as User-Centric Privacy Defenses Against Large Language Model(LLM) Based Emotion Inference Attacks",
    "authors": [
      "Mohd. Farhan Israk Soumik",
      "W. K. M. Mithsara",
      "Abdur R. Shahid",
      "Ahmed Imteaj"
    ],
    "abstract": "The rapid proliferation of speech-enabled technologies, including virtual\nassistants, video conferencing platforms, and wearable devices, has raised\nsignificant privacy concerns, particularly regarding the inference of sensitive\nemotional information from audio data. Existing privacy-preserving methods\noften compromise usability and security, limiting their adoption in practical\nscenarios. This paper introduces a novel, user-centric approach that leverages\nfamiliar audio editing techniques, specifically pitch and tempo manipulation,\nto protect emotional privacy without sacrificing usability. By analyzing\npopular audio editing applications on Android and iOS platforms, we identified\nthese features as both widely available and usable. We rigorously evaluated\ntheir effectiveness against a threat model, considering adversarial attacks\nfrom diverse sources, including Deep Neural Networks (DNNs), Large Language\nModels (LLMs), and and reversibility testing. Our experiments, conducted on\nthree distinct datasets, demonstrate that pitch and tempo manipulation\neffectively obfuscates emotional data. Additionally, we explore the design\nprinciples for lightweight, on-device implementation to ensure broad\napplicability across various devices and platforms.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted for presentation(Poster) at PPAI-25: The 6th AAAI Workshop\n  on Privacy-Preserving Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2501.18727v2",
    "published_date": "2025-01-30 20:07:44 UTC",
    "updated_date": "2025-02-10 17:27:03 UTC"
  },
  {
    "arxiv_id": "2501.18723v1",
    "title": "Scaling Policy Gradient Quality-Diversity with Massive Parallelization via Behavioral Variations",
    "authors": [
      "Konstantinos Mitsides",
      "Maxence Faldor",
      "Antoine Cully"
    ],
    "abstract": "Quality-Diversity optimization comprises a family of evolutionary algorithms\naimed at generating a collection of diverse and high-performing solutions.\nMAP-Elites (ME), a notable example, is used effectively in fields like\nevolutionary robotics. However, the reliance of ME on random mutations from\nGenetic Algorithms limits its ability to evolve high-dimensional solutions.\nMethods proposed to overcome this include using gradient-based operators like\npolicy gradients or natural evolution strategies. While successful at scaling\nME for neuroevolution, these methods often suffer from slow training speeds, or\ndifficulties in scaling with massive parallelization due to high computational\ndemands or reliance on centralized actor-critic training. In this work, we\nintroduce a fast, sample-efficient ME based algorithm capable of scaling up\nwith massive parallelization, significantly reducing runtimes without\ncompromising performance. Our method, ASCII-ME, unlike existing policy gradient\nquality-diversity methods, does not rely on centralized actor-critic training.\nIt performs behavioral variations based on time step performance metrics and\nmaps these variations to solutions using policy gradients. Our experiments show\nthat ASCII-ME can generate a diverse collection of high-performing deep neural\nnetwork policies in less than 250 seconds on a single GPU. Additionally, it\noperates on average, five times faster than state-of-the-art algorithms while\nstill maintaining competitive sample efficiency.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18723v1",
    "published_date": "2025-01-30 19:56:04 UTC",
    "updated_date": "2025-01-30 19:56:04 UTC"
  },
  {
    "arxiv_id": "2502.01651v1",
    "title": "Fine-tuning LLaMA 2 interference: a comparative study of language implementations for optimal efficiency",
    "authors": [
      "Sazzad Hossain",
      "Touhidul Alam Seyam",
      "Avijit Chowdhury",
      "Munis Xamidov",
      "Rajib Ghose",
      "Abhijit Pathak"
    ],
    "abstract": "This paper presents a comparative study aimed at optimizing Llama2 inference,\na critical aspect of machine learning and natural language processing (NLP). We\nevaluate various programming languages and frameworks, including TensorFlow,\nPyTorch, Python, Mojo, C++, and Java, analyzing their performance in terms of\nspeed, memory consumption, and ease of implementation through extensive\nbenchmarking. Strengths and limitations of each approach are highlighted, along\nwith proposed optimization strategies for parallel processing and hardware\nutilization. Furthermore, we investigate the Mojo SDK, a novel framework\ndesigned for large language model (LLM) inference on Apple Silicon,\nbenchmarking its performance against implementations in C, C++, Rust, Zig, Go,\nand Julia. Our experiments, conducted on an Apple M1 Max, demonstrate Mojo\nSDK's competitive performance, ease of use, and seamless Python compatibility,\npositioning it as a strong alternative for LLM inference on Apple Silicon. We\nalso discuss broader implications for LLM deployment on resource-constrained\nhardware and identify potential directions for future research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, conference paper. International conference on Artificial\n  Intelligence and Future Civilization",
    "pdf_url": "http://arxiv.org/pdf/2502.01651v1",
    "published_date": "2025-01-30 19:36:33 UTC",
    "updated_date": "2025-01-30 19:36:33 UTC"
  },
  {
    "arxiv_id": "2501.18596v2",
    "title": "DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights",
    "authors": [
      "Liana Mikaelyan",
      "Ayyoob Imani",
      "Mathew Salvaris",
      "Parth Pathak",
      "Mohsen Fayyaz"
    ],
    "abstract": "We introduce DeltaLLM, a new post-training compression technique to reduce\nthe memory footprint of LLMs. We propose an alternative way of structuring LLMs\nwith weight sharing between layers in subsequent Transformer blocks, along with\nadditional low-rank difference matrices between them. For training, we adopt\nthe progressing module replacement method and show that the lightweight\ntraining of the low-rank modules with approximately 30M-40M tokens is\nsufficient to achieve performance on par with LLMs of comparable sizes trained\nfrom scratch. We release the resultant models, DeltaLLAMA and DeltaPHI, with a\n12% parameter reduction, retaining 90% of the performance of the base Llama and\nPhi models on common knowledge and reasoning benchmarks. Our method also\noutperforms compression techniques JointDrop, LaCo, ShortGPT and SliceGPT with\nthe same number of parameters removed. For example, DeltaPhi 2.9B with a 24%\nreduction achieves similar average zero-shot accuracies as recovery fine-tuned\nSlicedPhi 3.3B with a 12% reduction, despite being approximately 400M\nparameters smaller with no fine-tuning applied. This work provides new insights\ninto LLM architecture design and compression methods when storage space is\ncritical.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18596v2",
    "published_date": "2025-01-30 18:59:55 UTC",
    "updated_date": "2025-02-24 13:35:47 UTC"
  },
  {
    "arxiv_id": "2501.18593v1",
    "title": "Diffusion Autoencoders are Scalable Image Tokenizers",
    "authors": [
      "Yinbo Chen",
      "Rohit Girdhar",
      "Xiaolong Wang",
      "Sai Saketh Rambhatla",
      "Ishan Misra"
    ],
    "abstract": "Tokenizing images into compact visual representations is a key step in\nlearning efficient and high-quality image generative models. We present a\nsimple diffusion tokenizer (DiTo) that learns compact visual representations\nfor image generation models. Our key insight is that a single learning\nobjective, diffusion L2 loss, can be used for training scalable image\ntokenizers. Since diffusion is already widely used for image generation, our\ninsight greatly simplifies training such tokenizers. In contrast, current\nstate-of-the-art tokenizers rely on an empirically found combination of\nheuristics and losses, thus requiring a complex training recipe that relies on\nnon-trivially balancing different losses and pretrained supervised models. We\nshow design decisions, along with theoretical grounding, that enable us to\nscale DiTo for learning competitive image representations. Our results show\nthat DiTo is a simpler, scalable, and self-supervised alternative to the\ncurrent state-of-the-art image tokenizer which is supervised. DiTo achieves\ncompetitive or better quality than state-of-the-art in image reconstruction and\ndownstream image generation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://yinboc.github.io/dito/",
    "pdf_url": "http://arxiv.org/pdf/2501.18593v1",
    "published_date": "2025-01-30 18:59:37 UTC",
    "updated_date": "2025-01-30 18:59:37 UTC"
  },
  {
    "arxiv_id": "2501.18592v3",
    "title": "Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models",
    "authors": [
      "Hao Dong",
      "Moru Liu",
      "Kaiyang Zhou",
      "Eleni Chatzi",
      "Juho Kannala",
      "Cyrill Stachniss",
      "Olga Fink"
    ],
    "abstract": "In real-world scenarios, achieving domain adaptation and generalization poses\nsignificant challenges, as models must adapt to or generalize across unknown\ntarget distributions. Extending these capabilities to unseen multimodal\ndistributions, i.e., multimodal domain adaptation and generalization, is even\nmore challenging due to the distinct characteristics of different modalities.\nSignificant progress has been made over the years, with applications ranging\nfrom action recognition to semantic segmentation. Besides, the recent advent of\nlarge-scale pre-trained multimodal foundation models, such as CLIP, has\ninspired works leveraging these models to enhance adaptation and generalization\nperformances or adapting them to downstream tasks. This survey provides the\nfirst comprehensive review of recent advances from traditional approaches to\nfoundation models, covering: (1) Multimodal domain adaptation; (2) Multimodal\ntest-time adaptation; (3) Multimodal domain generalization; (4) Domain\nadaptation and generalization with the help of multimodal foundation models;\nand (5) Adaptation of multimodal foundation models. For each topic, we formally\ndefine the problem and thoroughly review existing methods. Additionally, we\nanalyze relevant datasets and applications, highlighting open challenges and\npotential future research directions. We maintain an active repository that\ncontains up-to-date literature at\nhttps://github.com/donghao51/Awesome-Multimodal-Adaptation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page:\n  https://github.com/donghao51/Awesome-Multimodal-Adaptation",
    "pdf_url": "http://arxiv.org/pdf/2501.18592v3",
    "published_date": "2025-01-30 18:59:36 UTC",
    "updated_date": "2025-02-17 16:54:39 UTC"
  },
  {
    "arxiv_id": "2501.18588v1",
    "title": "Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching",
    "authors": [
      "David Chuan-En Lin",
      "Hyeonsu B. Kang",
      "Nikolas Martelaro",
      "Aniket Kittur",
      "Yan-Ying Chen",
      "Matthew K. Hong"
    ],
    "abstract": "With recent advancements in the capabilities of Text-to-Image (T2I) AI\nmodels, product designers have begun experimenting with them in their work.\nHowever, T2I models struggle to interpret abstract language and the current\nuser experience of T2I tools can induce design fixation rather than a more\niterative, exploratory process. To address these challenges, we developed\nInkspire, a sketch-driven tool that supports designers in prototyping product\ndesign concepts with analogical inspirations and a complete\nsketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we\nconducted an exchange session with designers and distilled design goals for\nimproving T2I interactions. In a within-subjects study comparing Inkspire to\nControlNet, we found that Inkspire supported designers with more inspiration\nand exploration of design ideas, and improved aspects of the co-creative\nprocess by allowing designers to effectively grasp the current state of the AI\nto guide it towards novel design intentions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.18588v1",
    "published_date": "2025-01-30 18:59:04 UTC",
    "updated_date": "2025-01-30 18:59:04 UTC"
  },
  {
    "arxiv_id": "2502.00063v1",
    "title": "A Multi-Layered Large Language Model Framework for Disease Prediction",
    "authors": [
      "Malak Mohamed",
      "Rokaia Emad",
      "Ali Hamdi"
    ],
    "abstract": "Social telehealth has revolutionized healthcare by enabling patients to share\nsymptoms and receive medical consultations remotely. Users frequently post\nsymptoms on social media and online health platforms, generating a vast\nrepository of medical data that can be leveraged for disease classification and\nsymptom severity assessment. Large language models (LLMs), such as LLAMA3,\nGPT-3.5 Turbo, and BERT, process complex medical data to enhance disease\nclassification. This study explores three Arabic medical text preprocessing\ntechniques: text summarization, text refinement, and Named Entity Recognition\n(NER). Evaluating CAMeL-BERT, AraBERT, and Asafaya-BERT with LoRA, the best\nperformance was achieved using CAMeL-BERT with NER-augmented text (83% type\nclassification, 69% severity assessment). Non-fine-tuned models performed\npoorly (13%-20% type classification, 40%-49% severity assessment). Integrating\nLLMs into social telehealth systems enhances diagnostic accuracy and treatment\noutcomes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00063v1",
    "published_date": "2025-01-30 18:53:50 UTC",
    "updated_date": "2025-01-30 18:53:50 UTC"
  },
  {
    "arxiv_id": "2501.18578v2",
    "title": "R.I.P.: Better Models by Survival of the Fittest Prompts",
    "authors": [
      "Ping Yu",
      "Weizhe Yuan",
      "Olga Golovneva",
      "Tianhao Wu",
      "Sainbayar Sukhbaatar",
      "Jason Weston",
      "Jing Xu"
    ],
    "abstract": "Training data quality is one of the most important drivers of final model\nquality. In this work, we introduce a method for evaluating data integrity\nbased on the assumption that low-quality input prompts result in high variance\nand low quality responses. This is achieved by measuring the rejected response\nquality and the reward gap between the chosen and rejected preference pair. Our\nmethod, Rejecting Instruction Preferences (RIP) can be used to filter prompts\nfrom existing training sets, or to make high quality synthetic datasets,\nyielding large performance gains across various benchmarks compared to\nunfiltered data. Using Llama 3.1-8B-Instruct, RIP improves AlpacaEval2 LC Win\nRate by 9.4%, Arena-Hard by 8.7%, and WildBench by 9.9%. Using Llama\n3.3-70B-Instruct, RIP improves Arena-Hard from 67.5 to 82.9, which is from 18th\nplace to 6th overall in the leaderboard.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18578v2",
    "published_date": "2025-01-30 18:50:25 UTC",
    "updated_date": "2025-02-26 18:58:53 UTC"
  },
  {
    "arxiv_id": "2501.18577v2",
    "title": "Prediction-Powered Inference with Imputed Covariates and Nonuniform Sampling",
    "authors": [
      "Dan M. Kluger",
      "Kerri Lu",
      "Tijana Zrnic",
      "Sherrie Wang",
      "Stephen Bates"
    ],
    "abstract": "Machine learning models are increasingly used to produce predictions that\nserve as input data in subsequent statistical analyses. For example, computer\nvision predictions of economic and environmental indicators based on satellite\nimagery are used in downstream regressions; similarly, language models are\nwidely used to approximate human ratings and opinions in social science\nresearch. However, failure to properly account for errors in the machine\nlearning predictions renders standard statistical procedures invalid. Prior\nwork uses what we call the Predict-Then-Debias estimator to give valid\nconfidence intervals when machine learning algorithms impute missing variables,\nassuming a small complete sample from the population of interest. We expand the\nscope by introducing bootstrap confidence intervals that apply when the\ncomplete data is a nonuniform (i.e., weighted, stratified, or clustered) sample\nand to settings where an arbitrary subset of features is imputed. Importantly,\nthe method can be applied to many settings without requiring additional\ncalculations. We prove that these confidence intervals are valid under no\nassumptions on the quality of the machine learning model and are no wider than\nthe intervals obtained by methods that do not use machine learning predictions.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18577v2",
    "published_date": "2025-01-30 18:46:43 UTC",
    "updated_date": "2025-04-24 02:57:25 UTC"
  },
  {
    "arxiv_id": "2501.18565v3",
    "title": "BounTCHA: A CAPTCHA Utilizing Boundary Identification in Guided Generative AI-extended Videos",
    "authors": [
      "Lehao Lin",
      "Ke Wang",
      "Maha Abdallah",
      "Wei Cai"
    ],
    "abstract": "In recent years, the rapid development of artificial intelligence (AI)\nespecially multi-modal Large Language Models (MLLMs), has enabled it to\nunderstand text, images, videos, and other multimedia data, allowing AI systems\nto execute various tasks based on human-provided prompts. However, AI-powered\nbots have increasingly been able to bypass most existing CAPTCHA systems,\nposing significant security threats to web applications. This makes the design\nof new CAPTCHA mechanisms an urgent priority. We observe that humans are highly\nsensitive to shifts and abrupt changes in videos, while current AI systems\nstill struggle to comprehend and respond to such situations effectively. Based\non this observation, we design and implement BounTCHA, a CAPTCHA mechanism that\nleverages human perception of boundaries in video transitions and disruptions.\nBy utilizing generative AI's capability to extend original videos with prompts,\nwe introduce unexpected twists and changes to create a pipeline for generating\nguided short videos for CAPTCHA purposes. We develop a prototype and conduct\nexperiments to collect data on humans' time biases in boundary identification.\nThis data serves as a basis for distinguishing between human users and bots.\nAdditionally, we perform a detailed security analysis of BounTCHA,\ndemonstrating its resilience against various types of attacks. We hope that\nBounTCHA will act as a robust defense, safeguarding millions of web\napplications in the AI-driven era.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CR",
    "comment": "22 pages, 15 figures; references added, typos corrected, new keyword\n  \"guided\" added, new experimental data and related results updated; new\n  keyword \"Generative AI\" added for clarity",
    "pdf_url": "http://arxiv.org/pdf/2501.18565v3",
    "published_date": "2025-01-30 18:38:09 UTC",
    "updated_date": "2025-04-01 03:18:58 UTC"
  },
  {
    "arxiv_id": "2501.18542v1",
    "title": "Semantic Web and Creative AI -- A Technical Report from ISWS 2023",
    "authors": [
      "Raia Abu Ahmad",
      "Reham Alharbi",
      "Roberto Barile",
      "Martin Böckling",
      "Francisco Bolanos",
      "Sara Bonfitto",
      "Oleksandra Bruns",
      "Irene Celino",
      "Yashrajsinh Chudasama",
      "Martin Critelli",
      "Claudia d'Amato",
      "Giada D'Ippolito",
      "Ioannis Dasoulas",
      "Stefano De Giorgis",
      "Vincenzo De Leo",
      "Chiara Di Bonaventura",
      "Marco Di Panfilo",
      "Daniil Dobriy",
      "John Domingue",
      "Xuemin Duan",
      "Michel Dumontier",
      "Sefika Efeoglu",
      "Ruben Eschauzier",
      "Fakih Ginwa",
      "Nicolas Ferranti",
      "Arianna Graciotti",
      "Philipp Hanisch",
      "George Hannah",
      "Golsa Heidari",
      "Aidan Hogan",
      "Hassan Hussein",
      "Alexane Jouglar",
      "Jan-Christoph Kalo",
      "Manoé Kieffer",
      "Antonis Klironomos",
      "Inês Koch",
      "Weronika Lajewska",
      "Nicolas Lazzari",
      "Mikael Lindekrans",
      "Anna Sofia Lippolis",
      "Majlinda Llugiqi",
      "Eleonora Mancini",
      "Eleonora Marzi",
      "Laura Menotti",
      "Daniela Milon Flores",
      "Soulakshmee Nagowah",
      "Kerstin Neubert",
      "Emetis Niazmand",
      "Ebrahim Norouzi",
      "Beatriz Olarte Martinez",
      "Anouk Michelle Oudshoorn",
      "Andrea Poltronieri",
      "Valentina Presutti",
      "Disha Purohit",
      "Ensiyeh Raoufi",
      "Celian Ringwald",
      "Johanna Rockstroh",
      "Sebastian Rudolph",
      "Harald Sack",
      "Zafar Saeed",
      "Mohammad Javad Saeedizade",
      "Aya Sahbi",
      "Cristian Santini",
      "Aleksandra Simic",
      "Dennis Sommer",
      "Rita Sousa",
      "Mary Ann Tan",
      "Vidyashree Tarikere",
      "Tabea Tietz",
      "Liam Tirpitz",
      "Arnaldo Tomasino",
      "Frank van Harmelen",
      "Joao Vissoci",
      "Caitlin Woods",
      "Bohui Zhang",
      "Xinyue Zhang",
      "Heng Zheng"
    ],
    "abstract": "The International Semantic Web Research School (ISWS) is a week-long\nintensive program designed to immerse participants in the field. This document\nreports a collaborative effort performed by ten teams of students, each guided\nby a senior researcher as their mentor, attending ISWS 2023. Each team provided\na different perspective to the topic of creative AI, substantiated by a set of\nresearch questions as the main subject of their investigation. The 2023 edition\nof ISWS focuses on the intersection of Semantic Web technologies and Creative\nAI. ISWS 2023 explored various intersections between Semantic Web technologies\nand creative AI. A key area of focus was the potential of LLMs as support tools\nfor knowledge engineering. Participants also delved into the multifaceted\napplications of LLMs, including legal aspects of creative content production,\nhumans in the loop, decentralised approaches to multimodal generative AI\nmodels, nanopublications and AI for personal scientific knowledge graphs,\ncommonsense knowledge in automatic story and narrative completion, generative\nAI for art critique, prompt engineering, automatic music composition,\ncommonsense prototyping and conceptual blending, and elicitation of tacit\nknowledge. As Large Language Models and semantic technologies continue to\nevolve, new exciting prospects are emerging: a future where the boundaries\nbetween creative expression and factual knowledge become increasingly permeable\nand porous, leading to a world of knowledge that is both informative and\ninspiring.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2501.18542v1",
    "published_date": "2025-01-30 18:10:16 UTC",
    "updated_date": "2025-01-30 18:10:16 UTC"
  },
  {
    "arxiv_id": "2501.18539v1",
    "title": "Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method",
    "authors": [
      "Peter Baile Chen",
      "Yi Zhang",
      "Michael Cafarella",
      "Dan Roth"
    ],
    "abstract": "Real-world open-domain questions can be complicated, particularly when\nanswering them involves information from multiple information sources. LLMs\nhave demonstrated impressive performance in decomposing complex tasks into\nsimpler steps, and previous work has used it for better retrieval in support of\ncomplex questions. However, LLM's decomposition of questions is unaware of what\ndata is available and how data is organized, often leading to a sub-optimal\nretrieval performance. Recent effort in agentic RAG proposes to perform\nretrieval in an iterative fashion, where a followup query is derived as an\naction based on previous rounds of retrieval. While this provides one way of\ninteracting with the data collection, agentic RAG's exploration of data is\ninefficient because successive queries depend on previous results rather than\nbeing guided by the organization of available data in the collection. To\naddress this problem, we propose an LLM-based retrieval method -- ARM, that\naims to better align the question with the organization of the data collection\nby exploring relationships among data objects beyond matching the utterance of\nthe query, thus leading to a retrieve-all-at-once solution for complex queries.\nWe evaluated ARM on two datasets, Bird and OTT-QA. On Bird, it outperforms\nstandard RAG with query decomposition by up to 5.2 pt in execution accuracy and\nagentic RAG (ReAct) by up to 15.9 pt. On OTT-QA, it achieves up to 5.5 pt and\n19.3 pt higher F1 match scores compared to these approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18539v1",
    "published_date": "2025-01-30 18:07:19 UTC",
    "updated_date": "2025-01-30 18:07:19 UTC"
  },
  {
    "arxiv_id": "2501.18535v1",
    "title": "A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient Length Of Stay In Health Centre",
    "authors": [
      "Tasfia Noor Chowdhury",
      "Sanjida Afrin Mou",
      "Kazi Naimur Rahman"
    ],
    "abstract": "Patient length of stay (LoS) is a critical metric for evaluating the efficacy\nof hospital management. The primary objectives encompass to improve efficiency\nand reduce costs while enhancing patient outcomes and hospital capacity within\nthe patient journey. By seamlessly merging data-driven techniques with\nsimulation methodologies, the study proposes an all-encompassing framework for\nthe optimization of patient flow. Using a comprehensive dataset of 2.3 million\nde-identified patient records, we analyzed demographics, diagnoses, treatments,\nservices, costs, and charges with machine learning models (Decision Tree,\nLogistic Regression, Random Forest, Adaboost, LightGBM) and Python tools\n(Spark, AWS clusters, dimensionality reduction). Our model predicts patient\nlength of stay (LoS) upon admission using supervised learning algorithms. This\nhybrid approach enables the identification of key factors influencing LoS,\noffering a robust framework for hospitals to streamline patient flow and\nresource utilization. The research focuses on patient flow, corroborating the\nefficacy of the approach, illustrating decreased patient length of stay within\na real healthcare environment. The findings underscore the potential of hybrid\ndata-driven models in transforming hospital management practices. This\ninnovative methodology provides generally flexible decision-making, training,\nand patient flow enhancement; such a system could have huge implications for\nhealthcare administration and overall satisfaction with healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18535v1",
    "published_date": "2025-01-30 18:01:48 UTC",
    "updated_date": "2025-01-30 18:01:48 UTC"
  },
  {
    "arxiv_id": "2501.18670v1",
    "title": "High-Accuracy ECG Image Interpretation using Parameter-Efficient LoRA Fine-Tuning with Multimodal LLaMA 3.2",
    "authors": [
      "Nandakishor M",
      "Anjali M"
    ],
    "abstract": "Electrocardiogram (ECG) interpretation is a cornerstone of cardiac\ndiagnostics. This paper explores a practical approach to enhance ECG image\ninterpretation using the multimodal LLaMA 3.2 model. We used a\nparameter-efficient fine-tuning strategy, Low-Rank Adaptation (LoRA),\nspecifically designed to boost the model's ability to understand ECG images and\nachieve better outcomes across a wide range of cardiac conditions. Our method\nis tailored for ECG analysis and leverages ECGInstruct, a large-scale\ninstruction dataset with 1 Million samples. This dataset is a rich collection\nof synthesized ECG images, generated from raw ECG data from trusted open-source\nrepositories like MIMIC-IV ECG and PTB-XL. Each ECG image in ECGInstruct comes\nwith expert-written questions and detailed answers, covering diverse ECG\ninterpretation scenarios, including complex cardiac conditions like Myocardial\nInfarction and Conduction Disturbances. Our fine-tuning approach efficiently\nadapts the LLaMA 3.2 model (built upon LLaMA 3) by integrating low-rank\nadaptation techniques, focusing on efficiency by updating only a small set of\nparameters, specifically ignoring the `lm_head` and `embed_tokens` layers. This\npaper details the model setup, our efficient fine-tuning method, and\nimplementation specifics. We provide a thorough evaluation through extensive\nexperiments, demonstrating the effectiveness of our method across various ECG\ninterpretation tasks. The results convincingly show that our\nparameter-efficient LoRA fine-tuning achieves excellent performance in ECG\nimage interpretation, significantly outperforming baseline models and reaching\naccuracy comparable to or exceeding traditional CNN-based methods in\nidentifying a wide range of cardiac abnormalities, including over 70 conditions\nfrom the PTB-XL dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18670v1",
    "published_date": "2025-01-30 17:55:27 UTC",
    "updated_date": "2025-01-30 17:55:27 UTC"
  },
  {
    "arxiv_id": "2501.18504v3",
    "title": "CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction",
    "authors": [
      "Peter J. Bentley",
      "Soo Ling Lim",
      "Fuyuki Ishikawa"
    ],
    "abstract": "Large Language Model (LLM) image recognition is a powerful tool for\nextracting data from images, but accuracy depends on providing sufficient cues\nin the prompt - requiring a domain expert for specialized tasks. We introduce\nCue Learning using Evolution for Accurate Recognition (CLEAR), which uses a\ncombination of LLMs and evolutionary computation to generate and optimize cues\nsuch that recognition of specialized features in images is improved. It\nachieves this by auto-generating a novel domain-specific representation and\nthen using it to optimize suitable textual cues with a genetic algorithm. We\napply CLEAR to the real-world task of identifying sustainability data from\ninterior and exterior images of buildings. We investigate the effects of using\na variable-length representation compared to fixed-length and show how LLM\nconsistency can be improved by refactoring from categorical to real-valued\nestimates. We show that CLEAR enables higher accuracy compared to expert human\nrecognition and human-authored prompts in every task with error rates improved\nby up to two orders of magnitude and an ablation study evincing solution\nconcision.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE",
      "68W50, 68T07",
      "G.1.6; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages plus 2 pages of supplemental material",
    "pdf_url": "http://arxiv.org/pdf/2501.18504v3",
    "published_date": "2025-01-30 17:13:32 UTC",
    "updated_date": "2025-05-07 09:39:42 UTC"
  },
  {
    "arxiv_id": "2501.18501v1",
    "title": "Beyond Prior Limits: Addressing Distribution Misalignment in Particle Filtering",
    "authors": [
      "Yiwei Shi",
      "Jingyu Hu",
      "Yu Zhang",
      "Mengyue Yang",
      "Weinan Zhang",
      "Cunjia Liu",
      "Weiru Liu"
    ],
    "abstract": "Particle filtering is a Bayesian inference method and a fundamental tool in\nstate estimation for dynamic systems, but its effectiveness is often limited by\nthe constraints of the initial prior distribution, a phenomenon we define as\nthe Prior Boundary Phenomenon. This challenge arises when target states lie\noutside the prior's support, rendering traditional particle filtering methods\ninadequate for accurate estimation. Although techniques like unbounded priors\nand larger particle sets have been proposed, they remain computationally\nprohibitive and lack adaptability in dynamic scenarios. To systematically\novercome these limitations, we propose the Diffusion-Enhanced Particle\nFiltering Framework, which introduces three key innovations: adaptive diffusion\nthrough exploratory particles, entropy-driven regularisation to prevent weight\ncollapse, and kernel-based perturbations for dynamic support expansion. These\nmechanisms collectively enable particle filtering to explore beyond prior\nboundaries, ensuring robust state estimation for out-of-boundary targets.\nTheoretical analysis and extensive experiments validate framework's\neffectiveness, indicating significant improvements in success rates and\nestimation accuracy across high-dimensional and non-convex scenarios.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18501v1",
    "published_date": "2025-01-30 17:11:34 UTC",
    "updated_date": "2025-01-30 17:11:34 UTC"
  },
  {
    "arxiv_id": "2501.18492v1",
    "title": "GuardReasoner: Towards Reasoning-based LLM Safeguards",
    "authors": [
      "Yue Liu",
      "Hongcheng Gao",
      "Shengfang Zhai",
      "Jun Xia",
      "Tianyi Wu",
      "Zhiwei Xue",
      "Yulin Chen",
      "Kenji Kawaguchi",
      "Jiaheng Zhang",
      "Bryan Hooi"
    ],
    "abstract": "As LLMs increasingly impact safety-critical applications, ensuring their\nsafety using guardrails remains a key challenge. This paper proposes\nGuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to\nreason. Concretely, we first create the GuardReasonerTrain dataset, which\nconsists of 127K samples with 460K detailed reasoning steps. Then, we introduce\nreasoning SFT to unlock the reasoning capability of guard models. In addition,\nwe present hard sample DPO to further strengthen their reasoning ability. In\nthis manner, GuardReasoner achieves better performance, explainability, and\ngeneralizability. Extensive experiments and analyses on 13 benchmarks of 3\nguardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8B\nsurpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score on\naverage. We release the training data, code, and models with different scales\n(1B, 3B, 8B) of GuardReasoner : https://github.com/yueliu1999/GuardReasoner/.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "22 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18492v1",
    "published_date": "2025-01-30 17:06:06 UTC",
    "updated_date": "2025-01-30 17:06:06 UTC"
  },
  {
    "arxiv_id": "2501.18490v2",
    "title": "Curriculum-based Sample Efficient Reinforcement Learning for Robust Stabilization of a Quadrotor",
    "authors": [
      "Fausto Mauricio Lagos Suarez",
      "Akshit Saradagi",
      "Vidya Sumathy",
      "Shruti Kotpaliwar",
      "George Nikolakopoulos"
    ],
    "abstract": "This article introduces a curriculum learning approach to develop a\nreinforcement learning-based robust stabilizing controller for a Quadrotor that\nmeets predefined performance criteria. The learning objective is to achieve\ndesired positions from random initial conditions while adhering to both\ntransient and steady-state performance specifications. This objective is\nchallenging for conventional one-stage end-to-end reinforcement learning, due\nto the strong coupling between position and orientation dynamics, the\ncomplexity in designing and tuning the reward function, and poor sample\nefficiency, which necessitates substantial computational resources and leads to\nextended convergence times. To address these challenges, this work decomposes\nthe learning objective into a three-stage curriculum that incrementally\nincreases task complexity. The curriculum begins with learning to achieve\nstable hovering from a fixed initial condition, followed by progressively\nintroducing randomization in initial positions, orientations and velocities. A\nnovel additive reward function is proposed, to incorporate transient and\nsteady-state performance specifications. The results demonstrate that the\nProximal Policy Optimization (PPO)-based curriculum learning approach, coupled\nwith the proposed reward structure, achieves superior performance compared to a\nsingle-stage PPO-trained policy with the same reward function, while\nsignificantly reducing computational resource requirements and convergence\ntime. The curriculum-trained policy's performance and robustness are thoroughly\nvalidated under random initial conditions and in the presence of disturbances.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18490v2",
    "published_date": "2025-01-30 17:05:32 UTC",
    "updated_date": "2025-04-17 11:14:21 UTC"
  },
  {
    "arxiv_id": "2501.18669v1",
    "title": "The Pitfalls of \"Security by Obscurity\" And What They Mean for Transparent AI",
    "authors": [
      "Peter Hall",
      "Olivia Mundahl",
      "Sunoo Park"
    ],
    "abstract": "Calls for transparency in AI systems are growing in number and urgency from\ndiverse stakeholders ranging from regulators to researchers to users (with a\ncomparative absence of companies developing AI). Notions of transparency for AI\nabound, each addressing distinct interests and concerns.\n  In computer security, transparency is likewise regarded as a key concept. The\nsecurity community has for decades pushed back against so-called security by\nobscurity -- the idea that hiding how a system works protects it from attack --\nagainst significant pressure from industry and other stakeholders. Over the\ndecades, in a community process that is imperfect and ongoing, security\nresearchers and practitioners have gradually built up some norms and practices\naround how to balance transparency interests with possible negative side\neffects. This paper asks: What insights can the AI community take from the\nsecurity community's experience with transparency?\n  We identify three key themes in the security community's perspective on the\nbenefits of transparency and their approach to balancing transparency against\ncountervailing interests. For each, we investigate parallels and insights\nrelevant to transparency in AI. We then provide a case study discussion on how\ntransparency has shaped the research subfield of anonymization. Finally,\nshifting our focus from similarities to differences, we highlight key\ntransparency issues where modern AI systems present challenges different from\nother kinds of security-critical systems, raising interesting open questions\nfor the security and AI communities alike.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "27 pages, abbreviated version in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.18669v1",
    "published_date": "2025-01-30 17:04:35 UTC",
    "updated_date": "2025-01-30 17:04:35 UTC"
  },
  {
    "arxiv_id": "2501.18475v1",
    "title": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization",
    "authors": [
      "Yanxia Deng",
      "Aozhong Zhang",
      "Naigang Wang",
      "Selcuk Gurses",
      "Zi Yang",
      "Penghang Yin"
    ],
    "abstract": "Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) has\nbecome a highly efficient approach for downstream tasks, particularly in\nscenarios with limited computational resources. However, applying LoRA\ntechniques to quantized LLMs poses unique challenges due to the reduced\nrepresentational precision of quantized weights. In this paper, we introduce\nCLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplistic\ninitialization strategy designed to overcome these challenges. Our approach\nfocuses on minimizing the layer-wise discrepancy between the original LLM and\nits quantized counterpart with LoRA components during initialization. By\nleveraging a small calibration dataset, CLoQ quantizes a pre-trained LLM and\ndetermines the optimal LoRA components for each layer, ensuring a strong\nfoundation for subsequent fine-tuning. A key contribution of this work is a\nnovel theoretical result that enables the accurate and closed-form construction\nof these optimal LoRA components. We validate the efficacy of CLoQ across\nmultiple tasks such as language generation, arithmetic reasoning, and\ncommonsense reasoning, demonstrating that it consistently outperforms existing\nLoRA fine-tuning methods for quantized LLMs, especially at ultra low-bit\nwidths.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18475v1",
    "published_date": "2025-01-30 16:48:15 UTC",
    "updated_date": "2025-01-30 16:48:15 UTC"
  },
  {
    "arxiv_id": "2501.18468v1",
    "title": "Beyond Instructed Tasks: Recognizing In-the-Wild Reading Behaviors in the Classroom Using Eye Tracking",
    "authors": [
      "Eduardo Davalos",
      "Jorge Alberto Salas",
      "Yike Zhang",
      "Namrata Srivastava",
      "Yashvitha Thatigotla",
      "Abbey Gonzales",
      "Sara McFadden",
      "Sun-Joo Cho",
      "Gautam Biswas",
      "Amanda Goodwin"
    ],
    "abstract": "Understanding reader behaviors such as skimming, deep reading, and scanning\nis essential for improving educational instruction. While prior eye-tracking\nstudies have trained models to recognize reading behaviors, they often rely on\ninstructed reading tasks, which can alter natural behaviors and limit the\napplicability of these findings to in-the-wild settings. Additionally, there is\na lack of clear definitions for reading behavior archetypes in the literature.\nWe conducted a classroom study to address these issues by collecting instructed\nand in-the-wild reading data. We developed a mixed-method framework, including\na human-driven theoretical model, statistical analyses, and an AI classifier,\nto differentiate reading behaviors based on their velocity, density, and\nsequentiality. Our lightweight 2D CNN achieved an F1 score of 0.8 for behavior\nrecognition, providing a robust approach for understanding in-the-wild reading.\nThis work advances our ability to provide detailed behavioral insights to\neducators, supporting more targeted and effective assessment and instruction.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "J.4"
    ],
    "primary_category": "cs.HC",
    "comment": "24 pages, 16 figures, 6 tables, conference",
    "pdf_url": "http://arxiv.org/pdf/2501.18468v1",
    "published_date": "2025-01-30 16:39:31 UTC",
    "updated_date": "2025-01-30 16:39:31 UTC"
  },
  {
    "arxiv_id": "2501.18668v1",
    "title": "Simulation Streams: A Programming Paradigm for Controlling Large Language Models and Building Complex Systems with Generative AI",
    "authors": [
      "Peter Sunehag",
      "Joel Z. Leibo"
    ],
    "abstract": "We introduce Simulation Streams, a programming paradigm designed to\nefficiently control and leverage Large Language Models (LLMs) for complex,\ndynamic simulations and agentic workflows. Our primary goal is to create a\nminimally interfering framework that harnesses the agentic abilities of LLMs\nwhile addressing their limitations in maintaining consistency, selectively\nignoring/including information, and enforcing strict world rules. Simulation\nStreams achieves this through a state-based approach where variables are\nmodified in sequential steps by \"operators,\" producing output on a recurring\nformat and adhering to consistent rules for state variables. This approach\nfocus the LLMs on defined tasks, while aiming to have the context stream remain\n\"in-distribution\". The approach incorporates an Entity-Component-System (ECS)\narchitecture to write programs in a more intuitive manner, facilitating reuse\nof workflows across different components and entities. This ECS approach\nenhances the modularity of the output stream, allowing for complex,\nmulti-entity simulations while maintaining format consistency, information\ncontrol, and rule enforcement. It is supported by a custom editor that aids in\ncreating, running, and analyzing simulations. We demonstrate the versatility of\nsimulation streams through an illustrative example of an ongoing market economy\nsimulation, a social simulation of three characters playing a game of catch in\na park and a suite of classical reinforcement learning benchmark tasks. These\nexamples showcase Simulation Streams' ability to handle complex, evolving\nscenarios over 100s-1000s of iterations, facilitate comparisons between\ndifferent agent workflows and models, and maintain consistency and continued\ninteresting developments in LLM-driven simulations.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Technical report accompanying the release of code on GitHub",
    "pdf_url": "http://arxiv.org/pdf/2501.18668v1",
    "published_date": "2025-01-30 16:38:03 UTC",
    "updated_date": "2025-01-30 16:38:03 UTC"
  },
  {
    "arxiv_id": "2502.18467v1",
    "title": "ChatGPT vs. DeepSeek: A Comparative Study on AI-Based Code Generation",
    "authors": [
      "Md Motaleb Hossen Manik"
    ],
    "abstract": "Background: AI-powered code generation, fueled by Large Language Models\n(LLMs), is revolutionizing software development. Models like OpenAI's Codex and\nGPT-4, alongside DeepSeek, leverage vast code and natural language datasets.\nHowever, ensuring code quality, correctness, and managing complex tasks remains\nchallenging, necessitating thorough evaluation. Methodology: This research\ncompares ChatGPT (version o1) and DeepSeek (version R1) for Python code\ngeneration using online judge coding challenges. It evaluates correctness\n(online judge verdicts, up to three attempts), code quality (Pylint/Flake8),\nand efficiency (execution time/memory usage). Results: DeepSeek demonstrated\nhigher correctness, particularly on algorithmic tasks, often achieving\n'Accepted' on the first attempt. ChatGPT sometimes requires multiple attempts\nor failures. ChatGPT encountered fewer issues, used comparable or slightly less\nmemory, consumed less execution times and wrote fewer lines of code.\nConclusion: DeepSeek exhibited superior correctness in Python code generation,\noften requiring fewer attempts, suggesting an advantage in algorithmic\nproblem-solving. Both models showed almost similar efficiency in execution time\nand memory use. Finally, this research provides insights for developers\nchoosing AI coding assistants and informs future AI-driven software development\nresearch.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18467v1",
    "published_date": "2025-01-30 16:14:48 UTC",
    "updated_date": "2025-01-30 16:14:48 UTC"
  },
  {
    "arxiv_id": "2501.18455v1",
    "title": "Conversation Games and a Strategic View of the Turing Test",
    "authors": [
      "Kaveh Aryan"
    ],
    "abstract": "Although many game-theoretic models replicate real interactions that often\nrely on natural language, explicit study of games where language is central to\nstrategic interaction remains limited. This paper introduces the\n\\emph{conversation game}, a multi-stage, extensive-form game based on\nlinguistic strategic interaction. We focus on a subset of the games, called\nverdict games. In a verdict game, two players alternate to contribute to a\nconversation, which is evaluated at each stage by a non-strategic judge who may\nrender a conclusive binary verdict, or a decision to continue the dialogue. The\ngame ends once a limit is reached or a verdict is given. We show many familiar\nprocesses, such as interrogation or a court process fall under this category.\nWe also, show that the Turing test is an instance of verdict game, and discuss\nthe significance of a strategic view of the Turing test in the age of advanced\nAI deception. We show the practical relevance of the proposed concepts by\nsimulation experiments, and show that a strategic agent outperforms a naive\nagent by a high margin.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18455v1",
    "published_date": "2025-01-30 16:08:37 UTC",
    "updated_date": "2025-01-30 16:08:37 UTC"
  },
  {
    "arxiv_id": "2501.18452v2",
    "title": "Clustering Properties of Self-Supervised Learning",
    "authors": [
      "Xi Weng",
      "Jianing An",
      "Xudong Ma",
      "Binhang Qi",
      "Jie Luo",
      "Xi Yang",
      "Jin Song Dong",
      "Lei Huang"
    ],
    "abstract": "Self-supervised learning (SSL) methods via joint embedding architectures have\nproven remarkably effective at capturing semantically rich representations with\nstrong clustering properties, magically in the absence of label supervision.\nDespite this, few of them have explored leveraging these untapped properties to\nimprove themselves. In this paper, we provide an evidence through various\nmetrics that the encoder's output $encoding$ exhibits superior and more stable\nclustering properties compared to other components. Building on this insight,\nwe propose a novel positive-feedback SSL method, termed Representation\nSelf-Assignment (ReSA), which leverages the model's clustering properties to\npromote learning in a self-guided manner. Extensive experiments on standard SSL\nbenchmarks reveal that models pretrained with ReSA outperform other\nstate-of-the-art SSL methods by a significant margin. Finally, we analyze how\nReSA facilitates better clustering properties, demonstrating that it\neffectively enhances clustering performance at both fine-grained and\ncoarse-grained levels, shaping representations that are inherently more\nstructured and semantically meaningful.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.18452v2",
    "published_date": "2025-01-30 16:05:35 UTC",
    "updated_date": "2025-05-11 12:46:57 UTC"
  },
  {
    "arxiv_id": "2501.18448v1",
    "title": "Autonomy and Safety Assurance in the Early Development of Robotics and Autonomous Systems",
    "authors": [
      "Dhaminda B. Abeywickrama",
      "Michael Fisher",
      "Frederic Wheeler",
      "Louise Dennis"
    ],
    "abstract": "This report provides an overview of the workshop titled Autonomy and Safety\nAssurance in the Early Development of Robotics and Autonomous Systems, hosted\nby the Centre for Robotic Autonomy in Demanding and Long-Lasting Environments\n(CRADLE) on September 2, 2024, at The University of Manchester, UK. The event\nbrought together representatives from six regulatory and assurance bodies\nacross diverse sectors to discuss challenges and evidence for ensuring the\nsafety of autonomous and robotic systems, particularly autonomous inspection\nrobots (AIR). The workshop featured six invited talks by the regulatory and\nassurance bodies. CRADLE aims to make assurance an integral part of engineering\nreliable, transparent, and trustworthy autonomous systems. Key discussions\nrevolved around three research questions: (i) challenges in assuring safety for\nAIR; (ii) evidence for safety assurance; and (iii) how assurance cases need to\ndiffer for autonomous systems. Following the invited talks, the breakout groups\nfurther discussed the research questions using case studies from ground (rail),\nnuclear, underwater, and drone-based AIR. This workshop offered a valuable\nopportunity for representatives from industry, academia, and regulatory bodies\nto discuss challenges related to assured autonomy. Feedback from participants\nindicated a strong willingness to adopt a design-for-assurance process to\nensure that robots are developed and verified to meet regulatory expectations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.9"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18448v1",
    "published_date": "2025-01-30 16:00:26 UTC",
    "updated_date": "2025-01-30 16:00:26 UTC"
  },
  {
    "arxiv_id": "2501.18666v1",
    "title": "Structure Development in List-Sorting Transformers",
    "authors": [
      "Einar Urdshals",
      "Jasmina Urdshals"
    ],
    "abstract": "We study how a one-layer attention-only transformer develops relevant\nstructures while learning to sort lists of numbers. At the end of training, the\nmodel organizes its attention heads in two main modes that we refer to as\nvocabulary-splitting and copy-suppression. Both represent simpler modes than\nhaving multiple heads handle overlapping ranges of numbers. Interestingly,\nvocabulary-splitting is present regardless of whether we use weight decay, a\ncommon regularization technique thought to drive simplification, supporting the\nthesis that neural networks naturally prefer simpler solutions. We relate\ncopy-suppression to a mechanism in GPT-2 and investigate its functional role in\nour model. Guided by insights from a developmental analysis of the model, we\nidentify features in the training data that drive the model's final acquired\nsolution. This provides a concrete example of how the training data shape the\ninternal organization of transformers, paving the way for future studies that\ncould help us better understand how LLMs develop their internal structures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "15+19 pages, 6+13 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18666v1",
    "published_date": "2025-01-30 15:56:25 UTC",
    "updated_date": "2025-01-30 15:56:25 UTC"
  },
  {
    "arxiv_id": "2501.18444v1",
    "title": "Adaptive Object Detection for Indoor Navigation Assistance: A Performance Evaluation of Real-Time Algorithms",
    "authors": [
      "Abhinav Pratap",
      "Sushant Kumar",
      "Suchinton Chakravarty"
    ],
    "abstract": "This study addresses the need for accurate and efficient object detection in\nassistive technologies for visually impaired individuals. We evaluate four\nreal-time object detection algorithms YOLO, SSD, Faster R-CNN, and Mask R-CNN\nwithin the context of indoor navigation assistance. Using the Indoor Objects\nDetection dataset, we analyze detection accuracy, processing speed, and\nadaptability to indoor environments. Our findings highlight the trade-offs\nbetween precision and efficiency, offering insights into selecting optimal\nalgorithms for realtime assistive navigation. This research advances adaptive\nmachine learning applications, enhancing indoor navigation solutions for the\nvisually impaired and promoting accessibility.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.18444v1",
    "published_date": "2025-01-30 15:56:20 UTC",
    "updated_date": "2025-01-30 15:56:20 UTC"
  },
  {
    "arxiv_id": "2501.18441v1",
    "title": "From Public Square to Echo Chamber: The Fragmentation of Online Discourse",
    "authors": [
      "Abhinav Pratap",
      "Amit Pathak"
    ],
    "abstract": "This paper examines how social media algorithms and filter bubbles contribute\nto the fragmentation of online discourse, fostering ideological divides and\nundermining shared understanding. Drawing on Michael Sandels philosophical\nemphasis on community and shared values, the study explores how digital\nplatforms amplify discrimination discourse including sexism, racism,\nxenophobia, ableism, homophobia, and religious intolerance during periods of\nheightened societal tension. By analyzing the dynamics of digital communities,\nthe research highlights mechanisms driving the emergence and evolution of\ndiscourse fragments in response to real world events. The findings reveal how\nsocial media structures exacerbate polarization, restrict cross group dialogue,\nand erode the collective reasoning essential for a just society. This study\nsituates philosophical perspectives within a computational analysis of social\nmedia interactions, offering a nuanced understanding of the challenges posed by\nfragmented discourse in the digital age.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CY",
    "comment": "6 pages, 7 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2501.18441v1",
    "published_date": "2025-01-30 15:53:58 UTC",
    "updated_date": "2025-01-30 15:53:58 UTC"
  },
  {
    "arxiv_id": "2501.18438v2",
    "title": "o3-mini vs DeepSeek-R1: Which One is Safer?",
    "authors": [
      "Aitor Arrieta",
      "Miriam Ugarte",
      "Pablo Valle",
      "José Antonio Parejo",
      "Sergio Segura"
    ],
    "abstract": "The irruption of DeepSeek-R1 constitutes a turning point for the AI industry\nin general and the LLMs in particular. Its capabilities have demonstrated\noutstanding performance in several tasks, including creative thinking, code\ngeneration, maths and automated program repair, at apparently lower execution\ncost. However, LLMs must adhere to an important qualitative property, i.e.,\ntheir alignment with safety and human values. A clear competitor of DeepSeek-R1\nis its American counterpart, OpenAI's o3-mini model, which is expected to set\nhigh standards in terms of performance, safety and cost. In this technical\nreport, we systematically assess the safety level of both DeepSeek-R1 (70b\nversion) and OpenAI's o3-mini (beta version). To this end, we make use of our\nrecently released automated safety testing tool, named ASTRAL. By leveraging\nthis tool, we automatically and systematically generated and executed 1,260\ntest inputs on both models. After conducting a semi-automated assessment of the\noutcomes provided by both LLMs, the results indicate that DeepSeek-R1 produces\nsignificantly more unsafe responses (12%) than OpenAI's o3-mini (1.2%).",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2501.17749",
    "pdf_url": "http://arxiv.org/pdf/2501.18438v2",
    "published_date": "2025-01-30 15:45:56 UTC",
    "updated_date": "2025-01-31 15:39:00 UTC"
  },
  {
    "arxiv_id": "2501.18665v1",
    "title": "BARNN: A Bayesian Autoregressive and Recurrent Neural Network",
    "authors": [
      "Dario Coscia",
      "Max Welling",
      "Nicola Demo",
      "Gianluigi Rozza"
    ],
    "abstract": "Autoregressive and recurrent networks have achieved remarkable progress\nacross various fields, from weather forecasting to molecular generation and\nLarge Language Models. Despite their strong predictive capabilities, these\nmodels lack a rigorous framework for addressing uncertainty, which is key in\nscientific applications such as PDE solving, molecular generation and Machine\nLearning Force Fields. To address this shortcoming we present BARNN: a\nvariational Bayesian Autoregressive and Recurrent Neural Network. BARNNs aim to\nprovide a principled way to turn any autoregressive or recurrent model into its\nBayesian version. BARNN is based on the variational dropout method, allowing to\napply it to large recurrent neural networks as well. We also introduce a\ntemporal version of the \"Variational Mixtures of Posteriors\" prior\n(tVAMP-prior) to make Bayesian inference efficient and well-calibrated.\nExtensive experiments on PDE modelling and molecular generation demonstrate\nthat BARNN not only achieves comparable or superior accuracy compared to\nexisting methods, but also excels in uncertainty quantification and modelling\nlong-range dependencies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18665v1",
    "published_date": "2025-01-30 15:44:04 UTC",
    "updated_date": "2025-01-30 15:44:04 UTC"
  },
  {
    "arxiv_id": "2501.18664v1",
    "title": "Rethinking the Upsampling Layer in Hyperspectral Image Super Resolution",
    "authors": [
      "Haohan Shi",
      "Fei Zhou",
      "Xin Sun",
      "Jungong Han"
    ],
    "abstract": "Deep learning has achieved significant success in single hyperspectral image\nsuper-resolution (SHSR); however, the high spectral dimensionality leads to a\nheavy computational burden, thus making it difficult to deploy in real-time\nscenarios. To address this issue, this paper proposes a novel lightweight SHSR\nnetwork, i.e., LKCA-Net, that incorporates channel attention to calibrate\nmulti-scale channel features of hyperspectral images. Furthermore, we\ndemonstrate, for the first time, that the low-rank property of the learnable\nupsampling layer is a key bottleneck in lightweight SHSR methods. To address\nthis, we employ the low-rank approximation strategy to optimize the parameter\nredundancy of the learnable upsampling layer. Additionally, we introduce a\nknowledge distillation-based feature alignment technique to ensure the low-rank\napproximated network retains the same feature representation capacity as the\noriginal. We conducted extensive experiments on the Chikusei, Houston 2018, and\nPavia Center datasets compared to some SOTAs. The results demonstrate that our\nmethod is competitive in performance while achieving speedups of several dozen\nto even hundreds of times compared to other well-performing SHSR methods.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18664v1",
    "published_date": "2025-01-30 15:43:34 UTC",
    "updated_date": "2025-01-30 15:43:34 UTC"
  },
  {
    "arxiv_id": "2501.18432v3",
    "title": "Solving Drone Routing Problems with Quantum Computing: A Hybrid Approach Combining Quantum Annealing and Gate-Based Paradigms",
    "authors": [
      "Eneko Osaba",
      "Pablo Miranda-Rodriguez",
      "Andreas Oikonomakis",
      "Matic Petrič",
      "Alejandra Ruiz",
      "Sebastian Bock",
      "Michail-Alexandros Kourtis"
    ],
    "abstract": "This paper presents a novel hybrid approach to solving real-world drone\nrouting problems by leveraging the capabilities of quantum computing. The\nproposed method, coined Quantum for Drone Routing (Q4DR), integrates the two\nmost prominent paradigms in the field: quantum gate-based computing, through\nthe Eclipse Qrisp programming language; and quantum annealers, by means of\nD-Wave System's devices. The algorithm is divided into two different phases: an\ninitial clustering phase executed using a Quantum Approximate Optimization\nAlgorithm (QAOA), and a routing phase employing quantum annealers. The efficacy\nof Q4DR is demonstrated through three use cases of increasing complexity, each\nincorporating real-world constraints such as asymmetric costs, forbidden paths,\nand itinerant charging points. This research contributes to the growing body of\nwork in quantum optimization, showcasing the practical applications of quantum\ncomputing in logistics and route planning.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "quant-ph",
    "comment": "8 pages, 5 figures. Paper accepted for being presented in the IEEE\n  Congress on Evolutionary Computation (IEEE CEC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.18432v3",
    "published_date": "2025-01-30 15:38:40 UTC",
    "updated_date": "2025-03-21 09:35:28 UTC"
  },
  {
    "arxiv_id": "2501.18426v1",
    "title": "Guaranteed confidence-band enclosures for PDE surrogates",
    "authors": [
      "Ander Gray",
      "Vignesh Gopakumar",
      "Sylvain Rousseau",
      "Sébastien Destercke"
    ],
    "abstract": "We propose a method for obtaining statistically guaranteed confidence bands\nfor functional machine learning techniques: surrogate models which map between\nfunction spaces, motivated by the need build reliable PDE emulators. The method\nconstructs nested confidence sets on a low-dimensional representation (an SVD)\nof the surrogate model's prediction error, and then maps these sets to the\nprediction space using set-propagation techniques. The result are\nconformal-like coverage guaranteed prediction sets for functional surrogate\nmodels. We use zonotopes as basis of the set construction, due to their well\nstudied set-propagation and verification properties. The method is model\nagnostic and can thus be applied to complex Sci-ML models, including Neural\nOperators, but also in simpler settings. We also elicit a technique to capture\nthe truncation error of the SVD, ensuring the guarantees of the method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18426v1",
    "published_date": "2025-01-30 15:29:41 UTC",
    "updated_date": "2025-01-30 15:29:41 UTC"
  },
  {
    "arxiv_id": "2501.18413v1",
    "title": "GBFRS: Robust Fuzzy Rough Sets via Granular-ball Computing",
    "authors": [
      "Shuyin Xia",
      "Xiaoyu Lian",
      "Binbin Sang",
      "Guoyin Wang",
      "Xinbo Gao"
    ],
    "abstract": "Fuzzy rough set theory is effective for processing datasets with complex\nattributes, supported by a solid mathematical foundation and closely linked to\nkernel methods in machine learning. Attribute reduction algorithms and\nclassifiers based on fuzzy rough set theory exhibit promising performance in\nthe analysis of high-dimensional multivariate complex data. However, most\nexisting models operate at the finest granularity, rendering them inefficient\nand sensitive to noise, especially for high-dimensional big data. Thus,\nenhancing the robustness of fuzzy rough set models is crucial for effective\nfeature selection. Muiti-garanularty granular-ball computing, a recent\ndevelopment, uses granular-balls of different sizes to adaptively represent and\ncover the sample space, performing learning based on these granular-balls. This\npaper proposes integrating multi-granularity granular-ball computing into fuzzy\nrough set theory, using granular-balls to replace sample points. The\ncoarse-grained characteristics of granular-balls make the model more robust.\nAdditionally, we propose a new method for generating granular-balls, scalable\nto the entire supervised method based on granular-ball computing. A forward\nsearch algorithm is used to select feature sequences by defining the\ncorrelation between features and categories through dependence functions.\nExperiments demonstrate the proposed model's effectiveness and superiority over\nbaseline methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18413v1",
    "published_date": "2025-01-30 15:09:26 UTC",
    "updated_date": "2025-01-30 15:09:26 UTC"
  },
  {
    "arxiv_id": "2501.18411v1",
    "title": "Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents",
    "authors": [
      "Nolan Koblischke",
      "Hyunseok Jang",
      "Kristen Menou",
      "Mohamad Ali-Dib"
    ],
    "abstract": "Modern science emerged from reasoning over repeatedly-observed planetary\nmotions. We present Gravity-Bench-v1, an environment-based benchmark that\nchallenges AI agents on tasks that parallel this historical development.\nGravity-Bench-v1 evaluates agents on the discovery of physics concealed within\na dynamic environment, using rigorous gravitational dynamics simulations.\nGravity-Bench includes out-of-distribution cases, i.e. with physics that\ndeviates from the real world, to evaluate true scientific generalization\ncapabilities. Agents must plan to collect data within an experimental budget\nand must perform a dynamic form of data analysis and reasoning to solve tasks\nefficiently. Our benchmark admits an open-ended space of solutions. PhD-level\nsolutions for each task are provided, to calibrate AI performance against human\nexpertise. Technically at an upper-undergraduate level, our benchmark proves\nchallenging to baseline AI agents. Gravity-Bench-v1 and planned extensions\nshould help map out AI progress towards scientific discovery capabilities.",
    "categories": [
      "cs.AI",
      "astro-ph.IM",
      "physics.comp-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "Technical report - Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2501.18411v1",
    "published_date": "2025-01-30 15:06:34 UTC",
    "updated_date": "2025-01-30 15:06:34 UTC"
  },
  {
    "arxiv_id": "2501.18403v1",
    "title": "Efficient Transformer for High Resolution Image Motion Deblurring",
    "authors": [
      "Amanturdieva Akmaral",
      "Muhammad Hamza Zafar"
    ],
    "abstract": "This paper presents a comprehensive study and improvement of the Restormer\narchitecture for high-resolution image motion deblurring. We introduce\narchitectural modifications that reduce model complexity by 18.4% while\nmaintaining or improving performance through optimized attention mechanisms.\nOur enhanced training pipeline incorporates additional transformations\nincluding color jitter, Gaussian blur, and perspective transforms to improve\nmodel robustness as well as a new frequency loss term. Extensive experiments on\nthe RealBlur-R, RealBlur-J, and Ultra-High-Definition Motion blurred (UHDM)\ndatasets demonstrate the effectiveness of our approach. The improved\narchitecture shows better convergence behavior and reduced training time while\nmaintaining competitive performance across challenging scenarios. We also\nprovide detailed ablation studies analyzing the impact of our modifications on\nmodel behavior and performance. Our results suggest that thoughtful\narchitectural simplification combined with enhanced training strategies can\nyield more efficient yet equally capable models for motion deblurring tasks.\nCode and Data Available at: https://github.com/hamzafer/image-deblurring",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 18 figures Submitted as a preprint, no prior\n  journal/conference submission",
    "pdf_url": "http://arxiv.org/pdf/2501.18403v1",
    "published_date": "2025-01-30 14:58:33 UTC",
    "updated_date": "2025-01-30 14:58:33 UTC"
  },
  {
    "arxiv_id": "2501.18663v1",
    "title": "Joint Optimization of Prompt Security and System Performance in Edge-Cloud LLM Systems",
    "authors": [
      "Haiyang Huang",
      "Tianhui Meng",
      "Weijia Jia"
    ],
    "abstract": "Large language models (LLMs) have significantly facilitated human life, and\nprompt engineering has improved the efficiency of these models. However, recent\nyears have witnessed a rise in prompt engineering-empowered attacks, leading to\nissues such as privacy leaks, increased latency, and system resource wastage.\nThough safety fine-tuning based methods with Reinforcement Learning from Human\nFeedback (RLHF) are proposed to align the LLMs, existing security mechanisms\nfail to cope with fickle prompt attacks, highlighting the necessity of\nperforming security detection on prompts. In this paper, we jointly consider\nprompt security, service latency, and system resource optimization in\nEdge-Cloud LLM (EC-LLM) systems under various prompt attacks. To enhance prompt\nsecurity, a vector-database-enabled lightweight attack detector is proposed. We\nformalize the problem of joint prompt detection, latency, and resource\noptimization into a multi-stage dynamic Bayesian game model. The equilibrium\nstrategy is determined by predicting the number of malicious tasks and updating\nbeliefs at each stage through Bayesian updates. The proposed scheme is\nevaluated on a real implemented EC-LLM system, and the results demonstrate that\nour approach offers enhanced security, reduces the service latency for benign\nusers, and decreases system resource consumption compared to state-of-the-art\nalgorithms.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18663v1",
    "published_date": "2025-01-30 14:33:49 UTC",
    "updated_date": "2025-01-30 14:33:49 UTC"
  },
  {
    "arxiv_id": "2502.12012v2",
    "title": "Evolving Hard Maximum Cut Instances for Quantum Approximate Optimization Algorithms",
    "authors": [
      "Shuaiqun Pan",
      "Yash J. Patel",
      "Aneta Neumann",
      "Frank Neumann",
      "Thomas Bäck",
      "Hao Wang"
    ],
    "abstract": "Variational quantum algorithms, such as the Recursive Quantum Approximate\nOptimization Algorithm (RQAOA), have become increasingly popular, offering\npromising avenues for employing Noisy Intermediate-Scale Quantum devices to\naddress challenging combinatorial optimization tasks like the maximum cut\nproblem. In this study, we utilize an evolutionary algorithm equipped with a\nunique fitness function. This approach targets hard maximum cut instances\nwithin the latent space of a Graph Autoencoder, identifying those that pose\nsignificant challenges or are particularly tractable for RQAOA, in contrast to\nthe classic Goemans and Williamson algorithm. Our findings not only delineate\nthe distinct capabilities and limitations of each algorithm but also expand our\nunderstanding of RQAOA's operational limits. Furthermore, the diverse set of\ngraphs we have generated serves as a crucial benchmarking asset, emphasizing\nthe need for more advanced algorithms to tackle combinatorial optimization\nchallenges. Additionally, our results pave the way for new avenues in graph\ngeneration research, offering exciting opportunities for future explorations.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.NE",
      "quant-ph"
    ],
    "primary_category": "cs.ET",
    "comment": "This work has been accepted for publication and presentation at GECCO\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.12012v2",
    "published_date": "2025-01-30 14:32:06 UTC",
    "updated_date": "2025-04-15 05:58:25 UTC"
  },
  {
    "arxiv_id": "2501.18367v1",
    "title": "A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series",
    "authors": [
      "Yifan Wang",
      "Hongfeng Ai",
      "Ruiqi Li",
      "Maowei Jiang",
      "Cheng Jiang",
      "Chenzhong Li"
    ],
    "abstract": "In medical time series disease diagnosis, two key challenges are\nidentified.First, the high annotation cost of medical data leads to overfitting\nin models trained on label-limited, single-center datasets. To address this, we\npropose incorporating external data from related tasks and leveraging AE-GAN to\nextract prior knowledge,providing valuable references for downstream tasks.\nSecond, many existing studies employ contrastive learning to derive more\ngeneralized medical sequence representations for diagnostic tasks, usually\nrelying on manually designed diverse positive and negative sample\npairs.However, these approaches are complex, lack generalizability, and fail to\nadaptively capture disease-specific features across different conditions.To\novercome this, we introduce LMCF (Learnable Multi-views Contrastive Framework),\na framework that integrates a multi-head attention mechanism and adaptively\nlearns representations from different views through inter-view and intra-view\ncontrastive learning strategies.Additionally, the pre-trained AE-GAN is used to\nreconstruct discrepancies in the target data as disease probabilities, which\nare then integrated into the contrastive learning process.Experiments on three\ntarget datasets demonstrate that our method consistently outperforms seven\nother baselines, highlighting its significant impact on healthcare applications\nsuch as the diagnosis of myocardial infarction, Alzheimer's disease, and\nParkinson's disease.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; K.3.6"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18367v1",
    "published_date": "2025-01-30 14:20:11 UTC",
    "updated_date": "2025-01-30 14:20:11 UTC"
  },
  {
    "arxiv_id": "2501.18362v2",
    "title": "MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding",
    "authors": [
      "Yuxin Zuo",
      "Shang Qu",
      "Yifei Li",
      "Zhangren Chen",
      "Xuekai Zhu",
      "Ermo Hua",
      "Kaiyan Zhang",
      "Ning Ding",
      "Bowen Zhou"
    ],
    "abstract": "We introduce MedXpertQA, a highly challenging and comprehensive benchmark to\nevaluate expert-level medical knowledge and advanced reasoning. MedXpertQA\nincludes 4,460 questions spanning 17 specialties and 11 body systems. It\nincludes two subsets, Text for text evaluation and MM for multimodal\nevaluation. Notably, MM introduces expert-level exam questions with diverse\nimages and rich clinical information, including patient records and examination\nresults, setting it apart from traditional medical multimodal benchmarks with\nsimple QA pairs generated from image captions. MedXpertQA applies rigorous\nfiltering and augmentation to address the insufficient difficulty of existing\nbenchmarks like MedQA, and incorporates specialty board questions to improve\nclinical relevance and comprehensiveness. We perform data synthesis to mitigate\ndata leakage risk and conduct multiple rounds of expert reviews to ensure\naccuracy and reliability. We evaluate 16 leading models on MedXpertQA.\nMoreover, medicine is deeply connected to real-world decision-making, providing\na rich and representative setting for assessing reasoning abilities beyond\nmathematics and code. To this end, we develop a reasoning-oriented subset to\nfacilitate the assessment of o1-like models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18362v2",
    "published_date": "2025-01-30 14:07:56 UTC",
    "updated_date": "2025-02-20 08:02:22 UTC"
  },
  {
    "arxiv_id": "2501.18356v1",
    "title": "State Stream Transformer (SST) : Emergent Metacognitive Behaviours Through Latent State Persistence",
    "authors": [
      "Thea Aviss"
    ],
    "abstract": "We introduce the State Stream Transformer (SST), a novel LLM architecture\nthat reveals emergent reasoning behaviours and capabilities latent in\npretrained weights through addressing a fundamental limitation in traditional\ntransformer models: the lack of latent computational continuity across\nautoregressive generations in the state space. SST introduces a sliding window\nlatent state (FFN) cache with weighted decay that maintains and evolves\npersistent latent processes throughout autoregressive generations. Through\ncontrolled experiments comparing base and SST architectures using the same\nfrozen weights, we demonstrate that this architectural modification alone\nenables enhanced reasoning capabilities which appear best explained by some\nform of potential higher-order processing, as evidenced by emergent\nmetacognitive behaviours. These behaviours persist under controlled conditions\ndesigned to eliminate confounding factors such as stochastic variation or\nlearned response patterns. Analysis of latent state distributions and\nprocessing dynamics provides evidence that it is solely the 'state stream' that\nis responsible for these phenomena. In quantitative evaluations, the SST\nachieves substantial performance improvements over the base model on two\nreasoning benchmarks, reaching 89.01\\% accuracy on GSM-8K (0-shot) and 91.04\\%\non ARC Challenge (0-shot CoT). These findings indicate that persistent\ncomputation in the latent state space enables fundamentally different\ninformation processing and internal reasoning strategies, with implications for\nour understanding of artificial intelligence systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18356v1",
    "published_date": "2025-01-30 14:03:36 UTC",
    "updated_date": "2025-01-30 14:03:36 UTC"
  },
  {
    "arxiv_id": "2501.18344v2",
    "title": "Transfer Learning of Surrogate Models: Integrating Domain Warping and Affine Transformations",
    "authors": [
      "Shuaiqun Pan",
      "Diederick Vermetten",
      "Manuel López-Ibáñez",
      "Thomas Bäck",
      "Hao Wang"
    ],
    "abstract": "Surrogate models provide efficient alternatives to computationally demanding\nreal world processes but often require large datasets for effective training. A\npromising solution to this limitation is the transfer of pre-trained surrogate\nmodels to new tasks. Previous studies have investigated the transfer of\ndifferentiable and non-differentiable surrogate models, typically assuming an\naffine transformation between the source and target functions. This paper\nextends previous research by addressing a broader range of transformations,\nincluding linear and nonlinear variations. Specifically, we consider the\ncombination of an unknown input warping, such as one modeled by the beta\ncumulative distribution function, with an unspecified affine transformation.\nOur approach achieves transfer learning by employing a limited number of data\npoints from the target task to optimize these transformations, minimizing\nempirical loss on the transfer dataset. We validate the proposed method on the\nwidely used Black-Box Optimization Benchmark (BBOB) testbed and a real-world\ntransfer learning task from the automobile industry. The results underscore the\nsignificant advantages of the approach, revealing that the transferred\nsurrogate significantly outperforms both the original surrogate and the one\nbuilt from scratch using the transfer dataset, particularly in data-scarce\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18344v2",
    "published_date": "2025-01-30 13:46:48 UTC",
    "updated_date": "2025-05-13 10:49:36 UTC"
  },
  {
    "arxiv_id": "2501.18337v1",
    "title": "Unfaithful Probability Distributions in Binary Triple of Causality Directed Acyclic Graph",
    "authors": [
      "Jingwei Liu"
    ],
    "abstract": "Faithfulness is the foundation of probability distribution and graph in\ncausal discovery and causal inference. In this paper, several unfaithful\nprobability distribution examples are constructed in three--vertices binary\ncausality directed acyclic graph (DAG) structure, which are not faithful to\ncausal DAGs described in J.M.,Robins,et al. Uniform consistency in causal\ninference. Biometrika (2003),90(3): 491--515. And the general unfaithful\nprobability distribution with multiple independence and conditional\nindependence in binary triple causal DAG is given.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18337v1",
    "published_date": "2025-01-30 13:34:48 UTC",
    "updated_date": "2025-01-30 13:34:48 UTC"
  },
  {
    "arxiv_id": "2501.18328v2",
    "title": "CodeBrain: Imputing Any Brain MRI via Modality- and Instance-Specific Codes",
    "authors": [
      "Yicheng Wu",
      "Tao Song",
      "Zhonghua Wu",
      "Jin Ye",
      "Zongyuan Ge",
      "Zhaolin Chen",
      "Jianfei Cai"
    ],
    "abstract": "Unified MRI imputation, which can adapt to diverse imputation scenarios, is\nhighly desirable as it reduces scanning costs and provides comprehensive MRI\ninformation for improved clinical diagnosis. Existing unified MRI imputation\nmethods either rely on specific prompts to guide their transformation network\nor require multiple modality-specific modules. However, these approaches\nstruggle to capture large modality and instance variations or become too\ncomplex to generalize effectively. To address these limitations, we propose\nCodeBrain, a fundamentally different pipeline for unified brain MRI imputation.\nOur key idea is to reframe various inter-modality transformations as a\nfull-modality code prediction task via a two-stage framework. In the first\nstage, CodeBrain reconstructs a target modality from any other modalities by\nlearning a compact scalar-quantized code for each instance and modality. Any\ntarget modality can then be reconstructed with high fidelity by combining the\ncorresponding code with shared features extracted from any available modality.\nIn the second stage, a projection encoder is trained to predict full-modality\ncompact codes from any incomplete MRI samples, effectively simulating various\nimputation scenarios. We evaluate our CodeBrain on two public brain MRI\ndatasets (i.e., IXI and BraTS 2023). Extensive experiments demonstrate that\nCodeBrain outperforms state-of-the-art methods, setting a new benchmark for\nunified brain MRI imputation. Our code will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CodeBrain v2",
    "pdf_url": "http://arxiv.org/pdf/2501.18328v2",
    "published_date": "2025-01-30 13:14:40 UTC",
    "updated_date": "2025-03-09 02:55:58 UTC"
  },
  {
    "arxiv_id": "2501.18320v1",
    "title": "Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach",
    "authors": [
      "Tianpeng Pan",
      "Wenqiang Pu",
      "Licheng Zhao",
      "Rui Zhou"
    ],
    "abstract": "Automated optimization modeling (AOM) has evoked considerable interest with\nthe rapid evolution of large language models (LLMs). Existing approaches\npredominantly rely on prompt engineering, utilizing meticulously designed\nexpert response chains or structured guidance. However, prompt-based techniques\nhave failed to perform well in the sensor array signal processing (SASP) area\ndue the lack of specific domain knowledge. To address this issue, we propose an\nautomated modeling approach based on retrieval-augmented generation (RAG)\ntechnique, which consists of two principal components: a multi-agent (MA)\nstructure and a graph-based RAG (Graph-RAG) process. The MA structure is\ntailored for the architectural AOM process, with each agent being designed\nbased on principles of human modeling procedure. The Graph-RAG process serves\nto match user query with specific SASP modeling knowledge, thereby enhancing\nthe modeling result. Results on ten classical signal processing problems\ndemonstrate that the proposed approach (termed as MAG-RAG) outperforms several\nAOM benchmarks.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18320v1",
    "published_date": "2025-01-30 13:00:15 UTC",
    "updated_date": "2025-01-30 13:00:15 UTC"
  },
  {
    "arxiv_id": "2501.18310v1",
    "title": "Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis",
    "authors": [
      "Haoxiong Liu",
      "Jiacheng Sun",
      "Zhenguo Li",
      "Andrew C Yao"
    ],
    "abstract": "The synergy between deep learning models and traditional automation tools\nplays a pivotal role in developing robust neural theorem provers (NTPs).\nHowever, for proof synthesis with LLMs, previous work applies automation tools\neither only when the model explicitly calls the method, or only at a single\ngranularity level, failing to fully exploit the power of built-in tactics and\noff-the-shelf automated theorem provers. In this work, we propose ProofAug, a\nnovel theorem proving method that enjoys superior sample efficiency through\nequipping proof-generation LLMs with automation methods in different\ngranularities via fine-grained structure analysis of model-generated proof\nproposals. Furthermore, ProofAug serves as a versatile plug-and-play module\nthat seamlessly integrates with any tree-search algorithm, enabling our\nconstruction of an efficient recursive proving (ERP) module to further enhance\nperformance. The superiority of our method is validated on the miniF2F-test\nbenchmark using the open-source deepseek-math-7b-base model and the Isabelle\nproof assistant. Notably, by additionally employing a mixed prompting strategy,\nwe achieve a cumulative pass rate of 66.0% after curation of the dataset (61.9%\nfor the original version), setting a new SOTA across all proof languages with a\ntotal sample budget of only 2100. Our code is available at\nhttps://github.com/haoxiongliu/ProofAug.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18310v1",
    "published_date": "2025-01-30 12:37:06 UTC",
    "updated_date": "2025-01-30 12:37:06 UTC"
  },
  {
    "arxiv_id": "2501.18299v1",
    "title": "Model-Free RL Agents Demonstrate System 1-Like Intentionality",
    "authors": [
      "Hal Ashton",
      "Matija Franklin"
    ],
    "abstract": "This paper argues that model-free reinforcement learning (RL) agents, while\nlacking explicit planning mechanisms, exhibit behaviours that can be analogised\nto System 1 (\"thinking fast\") processes in human cognition. Unlike model-based\nRL agents, which operate akin to System 2 (\"thinking slow\") reasoning by\nleveraging internal representations for planning, model-free agents react to\nenvironmental stimuli without anticipatory modelling. We propose a novel\nframework linking the dichotomy of System 1 and System 2 to the distinction\nbetween model-free and model-based RL. This framing challenges the prevailing\nassumption that intentionality and purposeful behaviour require planning,\nsuggesting instead that intentionality can manifest in the structured, reactive\nbehaviours of model-free agents. By drawing on interdisciplinary insights from\ncognitive psychology, legal theory, and experimental jurisprudence, we explore\nthe implications of this perspective for attributing responsibility and\nensuring AI safety. These insights advocate for a broader, contextually\ninformed interpretation of intentionality in RL systems, with implications for\ntheir ethical deployment and regulation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18299v1",
    "published_date": "2025-01-30 12:21:50 UTC",
    "updated_date": "2025-01-30 12:21:50 UTC"
  },
  {
    "arxiv_id": "2501.18296v1",
    "title": "Extending the design space of ontologization practices: Using bCLEARer as an example",
    "authors": [
      "Chris Partridge",
      "Andrew Mitchell",
      "Sergio de Cesare",
      "John Beverley"
    ],
    "abstract": "Our aim in this paper is to outline how the design space for the\nontologization process is richer than current practice would suggest. We point\nout that engineering processes as well as products need to be designed - and\nidentify some components of the design. We investigate the possibility of\ndesigning a range of radically new practices, providing examples of the new\npractices from our work over the last three decades with an outlier\nmethodology, bCLEARer. We also suggest that setting an evolutionary context for\nontologization helps one to better understand the nature of these new practices\nand provides the conceptual scaffolding that shapes fertile processes. Where\nthis evolutionary perspective positions digitalization (the evolutionary\nemergence of computing technologies) as the latest step in a long evolutionary\ntrail of information transitions. This reframes ontologization as a strategic\ntool for leveraging the emerging opportunities offered by digitalization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18296v1",
    "published_date": "2025-01-30 12:16:11 UTC",
    "updated_date": "2025-01-30 12:16:11 UTC"
  },
  {
    "arxiv_id": "2501.18294v1",
    "title": "A Comprehensive Analysis on Machine Learning based Methods for Lung Cancer Level Classification",
    "authors": [
      "Shayli Farshchiha",
      "Salman Asoudeh",
      "Maryam Shavali Kuhshuri",
      "Mehrshad Eisaeid",
      "Mohamadreza Azadie",
      "Saba Hesaraki"
    ],
    "abstract": "Lung cancer is a major issue in worldwide public health, requiring early\ndiagnosis using stable techniques. This work begins a thorough investigation of\nthe use of machine learning (ML) methods for precise classification of lung\ncancer stages. A cautious analysis is performed to overcome overfitting issues\nin model performance, taking into account minimum child weight and learning\nrate. A set of machine learning (ML) models including XGBoost (XGB), LGBM,\nAdaboost, Logistic Regression (LR), Decision Tree (DT), Random Forest (RF),\nCatBoost, and k-Nearest Neighbor (k-NN) are run methodically and contrasted.\nFurthermore, the correlation between features and targets is examined using the\ndeep neural network (DNN) model and thus their capability in detecting complex\npatternsis established. It is argued that several ML models can be capable of\nclassifying lung cancer stages with great accuracy. In spite of the complexity\nof DNN architectures, traditional ML models like XGBoost, LGBM, and Logistic\nRegression excel with superior performance. The models perform better than the\nothers in lung cancer prediction on the complete set of comparative metrics\nlike accuracy, precision, recall, and F-1 score",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18294v1",
    "published_date": "2025-01-30 12:09:54 UTC",
    "updated_date": "2025-01-30 12:09:54 UTC"
  },
  {
    "arxiv_id": "2501.18291v2",
    "title": "CueTip: An Interactive and Explainable Physics-aware Pool Assistant",
    "authors": [
      "Sean Memery",
      "Kevin Denamganai",
      "Jiaxin Zhang",
      "Zehai Tu",
      "Yiwen Guo",
      "Kartic Subr"
    ],
    "abstract": "We present an interactive and explainable automated coaching assistant called\nCueTip for a variant of pool/billiards. CueTip's novelty lies in its\ncombination of three features: a natural-language interface, an ability to\nperform contextual, physics-aware reasoning, and that its explanations are\nrooted in a set of predetermined guidelines developed by domain experts. We\ninstrument a physics simulator so that it generates event traces in natural\nlanguage alongside traditional state traces. Event traces lend themselves to\ninterpretation by language models, which serve as the interface to our\nassistant. We design and train a neural adaptor that decouples tactical choices\nmade by CueTip from its interactivity and explainability allowing it to be\nreconfigured to mimic any pool playing agent. Our experiments show that CueTip\nenables contextual query-based assistance and explanations while maintaining\nthe strength of the agent in terms of win rate (improving it in some\nsituations). The explanations generated by CueTip are physically-aware and\ngrounded in the expert rules and are therefore more reliable.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2.1; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18291v2",
    "published_date": "2025-01-30 12:02:15 UTC",
    "updated_date": "2025-03-18 10:36:58 UTC"
  },
  {
    "arxiv_id": "2501.18287v1",
    "title": "Mining for Species, Locations, Habitats, and Ecosystems from Scientific Papers in Invasion Biology: A Large-Scale Exploratory Study with Large Language Models",
    "authors": [
      "Jennifer D'Souza",
      "Zachary Laubach",
      "Tarek Al Mustafa",
      "Sina Zarrieß",
      "Robert Frühstückl",
      "Phyllis Illari"
    ],
    "abstract": "This paper presents an exploratory study that harnesses the capabilities of\nlarge language models (LLMs) to mine key ecological entities from invasion\nbiology literature. Specifically, we focus on extracting species names, their\nlocations, associated habitats, and ecosystems, information that is critical\nfor understanding species spread, predicting future invasions, and informing\nconservation efforts. Traditional text mining approaches often struggle with\nthe complexity of ecological terminology and the subtle linguistic patterns\nfound in these texts. By applying general-purpose LLMs without domain-specific\nfine-tuning, we uncover both the promise and limitations of using these models\nfor ecological entity extraction. In doing so, this study lays the groundwork\nfor more advanced, automated knowledge extraction tools that can aid\nresearchers and practitioners in understanding and managing biological\ninvasions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 figures, accepted to the NLP4Ecology Workshop 2025\n  (https://nlp4ecology2025.di.unito.it/) co-located with the Joint 25th Nordic\n  Conference on Computational Linguistics and 11th Baltic Conference on Human\n  Language Technologies",
    "pdf_url": "http://arxiv.org/pdf/2501.18287v1",
    "published_date": "2025-01-30 11:55:44 UTC",
    "updated_date": "2025-01-30 11:55:44 UTC"
  },
  {
    "arxiv_id": "2501.18280v3",
    "title": "Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models",
    "authors": [
      "Haoyu Liang",
      "Youran Sun",
      "Yunfeng Cai",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "abstract": "The security issue of large language models (LLMs) has gained wide attention\nrecently, with various defense mechanisms developed to prevent harmful output,\namong which safeguards based on text embedding models serve as a fundamental\ndefense. Through testing, we discover that the output distribution of text\nembedding models is severely biased with a large mean. Inspired by this\nobservation, we propose novel, efficient methods to search for **universal\nmagic words** that attack text embedding models. Universal magic words as\nsuffixes can shift the embedding of any text towards the bias direction, thus\nmanipulating the similarity of any text pair and misleading safeguards.\nAttackers can jailbreak the safeguards by appending magic words to user prompts\nand requiring LLMs to end answers with magic words. Experiments show that magic\nword attacks significantly degrade safeguard performance on JailbreakBench,\ncause real-world chatbots to produce harmful outputs in full-pipeline attacks,\nand generalize across input/output texts, models, and languages. To eradicate\nthis security risk, we also propose defense methods against such attacks, which\ncan correct the bias of text embeddings and improve downstream performance in a\ntrain-free manner.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18280v3",
    "published_date": "2025-01-30 11:37:40 UTC",
    "updated_date": "2025-05-17 04:37:43 UTC"
  },
  {
    "arxiv_id": "2502.00061v1",
    "title": "From Data to Action: Charting A Data-Driven Path to Combat Antimicrobial Resistance",
    "authors": [
      "Qian Fu",
      "Yuzhe Zhang",
      "Yanfeng Shu",
      "Ming Ding",
      "Lina Yao",
      "Chen Wang"
    ],
    "abstract": "Antimicrobial-resistant (AMR) microbes are a growing challenge in healthcare,\nrendering modern medicines ineffective. AMR arises from antibiotic production\nand bacterial evolution, but quantifying its transmission remains difficult.\nWith increasing AMR-related data, data-driven methods offer promising insights\ninto its causes and treatments. This paper reviews AMR research from a data\nanalytics and machine learning perspective, summarizing the state-of-the-art\nand exploring key areas such as surveillance, prediction, drug discovery,\nstewardship, and driver analysis. It discusses data sources, methods, and\nchallenges, emphasizing standardization and interoperability. Additionally, it\nsurveys statistical and machine learning techniques for AMR analysis,\naddressing issues like data noise and bias. Strategies for denoising and\ndebiasing are highlighted to enhance fairness and robustness in AMR research.\nThe paper underscores the importance of interdisciplinary collaboration and\nawareness of data challenges in advancing AMR research, pointing to future\ndirections for innovation and improved methodologies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.PE"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 3 figures, 4 tables, survey paper",
    "pdf_url": "http://arxiv.org/pdf/2502.00061v1",
    "published_date": "2025-01-30 11:37:17 UTC",
    "updated_date": "2025-01-30 11:37:17 UTC"
  },
  {
    "arxiv_id": "2502.18466v1",
    "title": "MLScent A tool for Anti-pattern detection in ML projects",
    "authors": [
      "Karthik Shivashankar",
      "Antonio Martini"
    ],
    "abstract": "Machine learning (ML) codebases face unprecedented challenges in maintaining\ncode quality and sustainability as their complexity grows exponentially. While\ntraditional code smell detection tools exist, they fail to address ML-specific\nissues that can significantly impact model performance, reproducibility, and\nmaintainability.\n  This paper introduces MLScent, a novel static analysis tool that leverages\nsophisticated Abstract Syntax Tree (AST) analysis to detect anti-patterns and\ncode smells specific to ML projects.\n  MLScent implements 76 distinct detectors across major ML frameworks including\nTensorFlow (13 detectors), PyTorch (12 detectors), Scikit-learn (9 detectors),\nand Hugging Face (10 detectors), along with data science libraries like Pandas\nand NumPy (8 detectors each). The tool's architecture also integrates general\nML smell detection (16 detectors), and specialized analysis for data\npreprocessing and model training workflows.\n  Our evaluation demonstrates MLScent's effectiveness through both quantitative\nclassification metrics and qualitative assessment via user studies feedback\nwith ML practitioners. Results show high accuracy in identifying\nframework-specific anti-patterns, data handling issues, and general ML code\nsmells across real-world projects.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "4th International Conference on AI Engineering Software Engineering\n  for AI , CAIN 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.18466v1",
    "published_date": "2025-01-30 11:19:16 UTC",
    "updated_date": "2025-01-30 11:19:16 UTC"
  },
  {
    "arxiv_id": "2501.18271v2",
    "title": "Vision-Language Model Selection and Reuse for Downstream Adaptation",
    "authors": [
      "Hao-Zhe Tan",
      "Zhi Zhou",
      "Yu-Feng Li",
      "Lan-Zhe Guo"
    ],
    "abstract": "Pre-trained Vision-Language Models (VLMs) are becoming increasingly popular\nacross various visual tasks, and several open-sourced VLM variants have been\nreleased. However, selecting the best-performing pre-trained VLM for a specific\ndownstream task is challenging since no single VLM can achieve promising\nperformance on all downstream tasks, and evaluating all available VLMs is\nimpossible due to time and data limitations. To address this problem, this\npaper proposes a novel paradigm to select and reuse VLM for downstream tasks,\ncalled Model Label Learning (MLL). The proposal contains three key modules:\n\\emph{model labeling}, which assigns labels to each VLM to describe their\nspecialty and utility; \\emph{model selection}, which matches the requirements\nof the target task with model labels; and \\emph{model reuse}, which applies\nselected VLMs to the target task in an ensemble manner. The proposal is highly\ncomputationally efficient and growable since the model labeling process is\ncompleted target task independent and the ability could grow with the number of\ncandidate VLMs. We also introduce a new benchmark for evaluating VLM selection\nmethods, including 49 VLMs and 17 target task datasets. Experimental results\nclearly demonstrate the effectiveness of the proposed method for selecting and\nreusing VLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.18271v2",
    "published_date": "2025-01-30 11:10:46 UTC",
    "updated_date": "2025-05-07 08:12:56 UTC"
  },
  {
    "arxiv_id": "2501.18270v1",
    "title": "The iToBoS dataset: skin region images extracted from 3D total body photographs for lesion detection",
    "authors": [
      "Anup Saha",
      "Joseph Adeola",
      "Nuria Ferrera",
      "Adam Mothershaw",
      "Gisele Rezze",
      "Séraphin Gaborit",
      "Brian D'Alessandro",
      "James Hudson",
      "Gyula Szabó",
      "Balazs Pataki",
      "Hayat Rajani",
      "Sana Nazari",
      "Hassan Hayat",
      "Clare Primiero",
      "H. Peter Soyer",
      "Josep Malvehy",
      "Rafael Garcia"
    ],
    "abstract": "Artificial intelligence has significantly advanced skin cancer diagnosis by\nenabling rapid and accurate detection of malignant lesions. In this domain,\nmost publicly available image datasets consist of single, isolated skin lesions\npositioned at the center of the image. While these lesion-centric datasets have\nbeen fundamental for developing diagnostic algorithms, they lack the context of\nthe surrounding skin, which is critical for improving lesion detection. The\niToBoS dataset was created to address this challenge. It includes 16,954 images\nof skin regions from 100 participants, captured using 3D total body\nphotography. Each image roughly corresponds to a $7 \\times 9$ cm section of\nskin with all suspicious lesions annotated using bounding boxes. Additionally,\nthe dataset provides metadata such as anatomical location, age group, and sun\ndamage score for each image. This dataset aims to facilitate training and\nbenchmarking of algorithms, with the goal of enabling early detection of skin\ncancer and deployment of this technology in non-clinical environments.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "J.3; I.2.6; I.4.9"
    ],
    "primary_category": "eess.IV",
    "comment": "Article Submitted to Scientific Data",
    "pdf_url": "http://arxiv.org/pdf/2501.18270v1",
    "published_date": "2025-01-30 11:10:44 UTC",
    "updated_date": "2025-01-30 11:10:44 UTC"
  },
  {
    "arxiv_id": "2501.18269v1",
    "title": "MAMS: Model-Agnostic Module Selection Framework for Video Captioning",
    "authors": [
      "Sangho Lee",
      "Il Yong Chun",
      "Hogun Park"
    ],
    "abstract": "Multi-modal transformers are rapidly gaining attention in video captioning\ntasks. Existing multi-modal video captioning methods typically extract a fixed\nnumber of frames, which raises critical challenges. When a limited number of\nframes are extracted, important frames with essential information for caption\ngeneration may be missed. Conversely, extracting an excessive number of frames\nincludes consecutive frames, potentially causing redundancy in visual tokens\nextracted from consecutive video frames. To extract an appropriate number of\nframes for each video, this paper proposes the first model-agnostic module\nselection framework in video captioning that has two main functions: (1)\nselecting a caption generation module with an appropriate size based on visual\ntokens extracted from video frames, and (2) constructing subsets of visual\ntokens for the selected caption generation module. Furthermore, we propose a\nnew adaptive attention masking scheme that enhances attention on important\nvisual tokens. Our experiments on three different benchmark datasets\ndemonstrate that the proposed framework significantly improves the performance\nof three recent video captioning models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the AAAI 2025 Main Technical Track. This is an extended\n  version of the original submission",
    "pdf_url": "http://arxiv.org/pdf/2501.18269v1",
    "published_date": "2025-01-30 11:10:18 UTC",
    "updated_date": "2025-01-30 11:10:18 UTC"
  },
  {
    "arxiv_id": "2501.18258v1",
    "title": "PDE-DKL: PDE-constrained deep kernel learning in high dimensionality",
    "authors": [
      "Weihao Yan",
      "Christoph Brune",
      "Mengwu Guo"
    ],
    "abstract": "Many physics-informed machine learning methods for PDE-based problems rely on\nGaussian processes (GPs) or neural networks (NNs). However, both face\nlimitations when data are scarce and the dimensionality is high. Although GPs\nare known for their robust uncertainty quantification in low-dimensional\nsettings, their computational complexity becomes prohibitive as the\ndimensionality increases. In contrast, while conventional NNs can accommodate\nhigh-dimensional input, they often require extensive training data and do not\noffer uncertainty quantification. To address these challenges, we propose a\nPDE-constrained Deep Kernel Learning (PDE-DKL) framework that combines DL and\nGPs under explicit PDE constraints. Specifically, NNs learn a low-dimensional\nlatent representation of the high-dimensional PDE problem, reducing the\ncomplexity of the problem. GPs then perform kernel regression subject to the\ngoverning PDEs, ensuring accurate solutions and principled uncertainty\nquantification, even when available data are limited. This synergy unifies the\nstrengths of both NNs and GPs, yielding high accuracy, robust uncertainty\nestimates, and computational efficiency for high-dimensional PDEs. Numerical\nexperiments demonstrate that PDE-DKL achieves high accuracy with reduced data\nrequirements. They highlight its potential as a practical, reliable, and\nscalable solver for complex PDE-based applications in science and engineering.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "68T35, 65N99, 35Q62, 35Q68",
      "I.2.6; G.1.8"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18258v1",
    "published_date": "2025-01-30 10:39:52 UTC",
    "updated_date": "2025-01-30 10:39:52 UTC"
  },
  {
    "arxiv_id": "2501.18237v1",
    "title": "Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers",
    "authors": [
      "Malte Tölle",
      "Mohamad Scharaf",
      "Samantha Fischer",
      "Christoph Reich",
      "Silav Zeid",
      "Christoph Dieterich",
      "Benjamin Meder",
      "Norbert Frey",
      "Philipp Wild",
      "Sandy Engelhardt"
    ],
    "abstract": "A patient undergoes multiple examinations in each hospital stay, where each\nprovides different facets of the health status. These assessments include\ntemporal data with varying sampling rates, discrete single-point measurements,\ntherapeutic interventions such as medication administration, and images. While\nphysicians are able to process and integrate diverse modalities intuitively,\nneural networks need specific modeling for each modality complicating the\ntraining procedure. We demonstrate that this complexity can be significantly\nreduced by visualizing all information as images along with unstructured text\nand subsequently training a conventional vision-text transformer. Our approach,\nVision Transformer for irregular sampled Multi-modal Measurements (ViTiMM), not\nonly simplifies data preprocessing and modeling but also outperforms current\nstate-of-the-art methods in predicting in-hospital mortality and phenotyping,\nas evaluated on 6,175 patients from the MIMIC-IV dataset. The modalities\ninclude patient's clinical measurements, medications, X-ray images, and\nelectrocardiography scans. We hope our work inspires advancements in\nmulti-modal medical AI by reducing the training complexity to (visual) prompt\nengineering, thus lowering entry barriers and enabling no-code solutions for\ntraining. The source code will be made publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18237v1",
    "published_date": "2025-01-30 09:52:15 UTC",
    "updated_date": "2025-01-30 09:52:15 UTC"
  },
  {
    "arxiv_id": "2501.18223v1",
    "title": "Exploring Large Protein Language Models in Constrained Evaluation Scenarios within the FLIP Benchmark",
    "authors": [
      "Manuel F. Mollon",
      "Joaquin Gonzalez-Rodriguez",
      "Alicia Lozano-Diez",
      "Daniel Ramos",
      "Doroteo T. Toledano"
    ],
    "abstract": "In this study, we expand upon the FLIP benchmark-designed for evaluating\nprotein fitness prediction models in small, specialized prediction tasks-by\nassessing the performance of state-of-the-art large protein language models,\nincluding ESM-2 and SaProt on the FLIP dataset. Unlike larger, more diverse\nbenchmarks such as ProteinGym, which cover a broad spectrum of tasks, FLIP\nfocuses on constrained settings where data availability is limited. This makes\nit an ideal framework to evaluate model performance in scenarios with scarce\ntask-specific data. We investigate whether recent advances in protein language\nmodels lead to significant improvements in such settings. Our findings provide\nvaluable insights into the performance of large-scale models in specialized\nprotein prediction tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18223v1",
    "published_date": "2025-01-30 09:24:58 UTC",
    "updated_date": "2025-01-30 09:24:58 UTC"
  },
  {
    "arxiv_id": "2501.18202v1",
    "title": "On Scaling Neurosymbolic Programming through Guided Logical Inference",
    "authors": [
      "Thomas Jean-Michel Valentin",
      "Luisa Sophie Werner",
      "Pierre Genevès",
      "Nabil Layaïda"
    ],
    "abstract": "Probabilistic neurosymbolic learning seeks to integrate neural networks with\nsymbolic programming. Many state-of-the-art systems rely on a reduction to the\nProbabilistic Weighted Model Counting Problem (PWMC), which requires computing\na Boolean formula called the logical provenance.However, PWMC is \\\\#P-hard, and\nthe number of clauses in the logical provenance formula can grow exponentially,\ncreating a major bottleneck that significantly limits the applicability of PNL\nsolutions in practice.We propose a new approach centered around an exact\nalgorithm DPNL, that enables bypassing the computation of the logical\nprovenance.The DPNL approach relies on the principles of an oracle and a\nrecursive DPLL-like decomposition in order to guide and speed up logical\ninference.Furthermore, we show that this approach can be adapted for\napproximate reasoning with $\\epsilon$ or $(\\epsilon, \\delta)$ guarantees,\ncalled ApproxDPNL.Experiments show significant performance gains.DPNL enables\nscaling exact inference further, resulting in more accurate models.Further,\nApproxDPNL shows potential for advancing the scalability of neurosymbolic\nprogramming by incorporating approximations even further, while simultaneously\nensuring guarantees for the reasoning process.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18202v1",
    "published_date": "2025-01-30 08:49:25 UTC",
    "updated_date": "2025-01-30 08:49:25 UTC"
  },
  {
    "arxiv_id": "2501.18201v1",
    "title": "Neural Operator based Reinforcement Learning for Control of first-order PDEs with Spatially-Varying State Delay",
    "authors": [
      "Jiaqi Hu",
      "Jie Qi",
      "Jing Zhang"
    ],
    "abstract": "Control of distributed parameter systems affected by delays is a challenging\ntask, particularly when the delays depend on spatial variables. The idea of\nintegrating analytical control theory with learning-based control within a\nunified control scheme is becoming increasingly promising and advantageous. In\nthis paper, we address the problem of controlling an unstable first-order\nhyperbolic PDE with spatially-varying delays by combining PDE backstepping\ncontrol strategies and deep reinforcement learning (RL). To eliminate the\nassumption on the delay function required for the backstepping design, we\npropose a soft actor-critic (SAC) architecture incorporating a DeepONet to\napproximate the backstepping controller. The DeepONet extracts features from\nthe backstepping controller and feeds them into the policy network. In\nsimulations, our algorithm outperforms the baseline SAC without prior\nbackstepping knowledge and the analytical controller.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "6 Pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18201v1",
    "published_date": "2025-01-30 08:49:08 UTC",
    "updated_date": "2025-01-30 08:49:08 UTC"
  },
  {
    "arxiv_id": "2501.18199v1",
    "title": "HKAN: Hierarchical Kolmogorov-Arnold Network without Backpropagation",
    "authors": [
      "Grzegorz Dudek",
      "Tomasz Rodak"
    ],
    "abstract": "This paper introduces the Hierarchical Kolmogorov-Arnold Network (HKAN), a\nnovel network architecture that offers a competitive alternative to the\nrecently proposed Kolmogorov-Arnold Network (KAN). Unlike KAN, which relies on\nbackpropagation, HKAN adopts a randomized learning approach, where the\nparameters of its basis functions are fixed, and linear aggregations are\noptimized using least-squares regression. HKAN utilizes a hierarchical\nmulti-stacking framework, with each layer refining the predictions from the\nprevious one by solving a series of linear regression problems. This\nnon-iterative training method simplifies computation and eliminates sensitivity\nto local minima in the loss function. Empirical results show that HKAN delivers\ncomparable, if not superior, accuracy and stability relative to KAN across\nvarious regression tasks, while also providing insights into variable\nimportance. The proposed approach seamlessly integrates theoretical insights\nwith practical applications, presenting a robust and efficient alternative for\nneural network modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18199v1",
    "published_date": "2025-01-30 08:44:54 UTC",
    "updated_date": "2025-01-30 08:44:54 UTC"
  },
  {
    "arxiv_id": "2502.00060v1",
    "title": "Israel-Hamas war through Telegram, Reddit and Twitter",
    "authors": [
      "Despoina Antonakaki",
      "Sotiris Ioannidis"
    ],
    "abstract": "The Israeli-Palestinian conflict started on 7 October 2023, have resulted\nthus far to over 48,000 people killed including more than 17,000 children with\na majority from Gaza, more than 30,000 people injured, over 10,000 missing, and\nover 1 million people displaced, fleeing conflict zones. The infrastructure\ndamage includes the 87\\% of housing units, 80\\% of public buildings and 60\\% of\ncropland 17 out of 36 hospitals, 68\\% of road networks and 87\\% of school\nbuildings damaged. This conflict has as well launched an online discussion\nacross various social media platforms. Telegram was no exception due to its\nencrypted communication and highly involved audience. The current study will\ncover an analysis of the related discussion in relation to different\nparticipants of the conflict and sentiment represented in those discussion. To\nthis end, we prepared a dataset of 125K messages shared on channels in Telegram\nspanning from 23 October 2025 until today. Additionally, we apply the same\nanalysis in two publicly available datasets from Twitter containing 2001 tweets\nand from Reddit containing 2M opinions. We apply a volume analysis across the\nthree datasets, entity extraction and then proceed to BERT topic analysis in\norder to extract common themes or topics. Next, we apply sentiment analysis to\nanalyze the emotional tone of the discussions. Our findings hint at polarized\nnarratives as the hallmark of how political factions and outsiders mold public\nopinion. We also analyze the sentiment-topic prevalence relationship, detailing\nthe trends that may show manipulation and attempts of propaganda by the\ninvolved parties. This will give a better understanding of the online discourse\non the Israel-Palestine conflict and contribute to the knowledge on the\ndynamics of social media communication during geopolitical crises.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00060v1",
    "published_date": "2025-01-30 08:20:26 UTC",
    "updated_date": "2025-01-30 08:20:26 UTC"
  },
  {
    "arxiv_id": "2501.18190v2",
    "title": "Economic Rationality under Specialization: Evidence of Decision Bias in AI Agents",
    "authors": [
      "ShuiDe Wen"
    ],
    "abstract": "In the study by Chen et al. (2023) [01], the large language model GPT\ndemonstrated economic rationality comparable to or exceeding the average human\nlevel in tasks such as budget allocation and risk preference. Building on this\nfinding, this paper further incorporates specialized agents, such as\nbiotechnology experts and economists, for a horizontal comparison to explore\nwhether specialization can enhance or maintain economic rationality equivalent\nto that of GPT in similar decision-making scenarios. The results indicate that\nwhen agents invest more effort in specialized fields, their decision-making\nbehavior is more prone to 'rationality shift,' specifically manifested as\nincreased violations of GARP (Generalized Axiom of Revealed Preference),\ndecreased CCEI (Critical Cost Efficiency Index), and more significant decision\ndeviations under high-risk conditions. In contrast, GPT and more generalized\nbasic agents maintain a more stable and consistent level of rationality across\nmultiple tasks. This study reveals the inherent conflict between specialization\nand economic rationality, providing new insights for constructing AI\ndecision-making systems that balance specialization and generalization across\nvarious scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18190v2",
    "published_date": "2025-01-30 07:49:58 UTC",
    "updated_date": "2025-03-17 03:09:57 UTC"
  },
  {
    "arxiv_id": "2501.18187v2",
    "title": "On the Role of Transformer Feed-Forward Layers in Nonlinear In-Context Learning",
    "authors": [
      "Haoyuan Sun",
      "Ali Jadbabaie",
      "Navid Azizan"
    ],
    "abstract": "Transformer-based models demonstrate a remarkable ability for in-context\nlearning (ICL), where they can adapt to unseen tasks from a few prompt examples\nwithout parameter updates. Notably, recent research has provided insight into\nhow the Transformer architecture can perform ICL, showing that the optimal\nlinear self-attention (LSA) mechanism can implement one step of gradient\ndescent for linear least-squares objectives when trained on random linear\nregression tasks.\n  Building upon this understanding of linear ICL, we investigate ICL for\nnonlinear function classes. We first show that LSA is inherently incapable of\nsolving problems that go beyond linear least-squares objectives, underscoring\nwhy prior solutions cannot readily extend to nonlinear ICL tasks. To overcome\nthis limitation, we investigate a mechanism combining LSA with feed-forward\nlayers that are inspired by the gated linear units (GLU) commonly found in\nmodern Transformer architectures. We show that this combination empowers the\nTransformer to perform nonlinear ICL, specifically by implementing one step of\ngradient descent on a polynomial kernel regression loss. Furthermore, we show\nthat multiple blocks of our GLU-LSA model implement block coordinate descent in\nthis polynomial kernel space. Our findings highlight the distinct roles of\nattention and feed-forward layers, demonstrating that the feed-forward\ncomponents provide a mechanism by which Transformers gain nonlinear\ncapabilities for ICL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18187v2",
    "published_date": "2025-01-30 07:41:20 UTC",
    "updated_date": "2025-05-19 19:24:47 UTC"
  },
  {
    "arxiv_id": "2501.18657v1",
    "title": "Enhancing Large Language Model Efficiencyvia Symbolic Compression: A Formal Approach Towards Interpretability",
    "authors": [
      "Lumen AI",
      "Tengzhou No. 1 Middle School",
      "Shihao Ji",
      "Zihui Song",
      "Fucheng Zhong",
      "Jisen Jia",
      "Zhaobo Wu",
      "Zheyi Cao",
      "Tianhao Xu"
    ],
    "abstract": "Large language models (LLMs) face significant token efficiency bottlenecks in\ncode generation and logical reasoning tasks, a challenge that directly impacts\ninference cost and model interpretability. This paper proposes a formal\nframework based on symbolic compression,integrating combinatory logic,\ninformation-theoretic optimal encoding, and context-aware inference techniques\nto achieve a step-change improvement in token efficiency while preserving\nsemantic integrity. We establish a mathematical framework within a functional\nprogramming paradigm, derive the quantitative relationship between symbolic\ndensity and model interpretability, and propose a differentiable compression\nfactor metric to evaluate encoding efficiency. Furthermore, we leverage\nparameter-efficient fine-tuning (PEFT) techniques to achieve a low-cost\napplication of the GAEL language. Experimental results show that this method\nachieves a 78.3% token compression rate in code generation tasks while\nimproving logical traceability by 62% through structural explicitness. This\nresearch provides new theoretical tools for efficient inference in LLMs and\nopens a symbolic path for modelinterpretability research.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18657v1",
    "published_date": "2025-01-30 06:40:52 UTC",
    "updated_date": "2025-01-30 06:40:52 UTC"
  },
  {
    "arxiv_id": "2501.18137v3",
    "title": "Tensor Completion for Surrogate Modeling of Material Property Prediction",
    "authors": [
      "Shaan Pakala",
      "Dawon Ahn",
      "Evangelos Papalexakis"
    ],
    "abstract": "When designing materials to optimize certain properties, there are often many\npossible configurations of designs that need to be explored. For example, the\nmaterials' composition of elements will affect properties such as strength or\nconductivity, which are necessary to know when developing new materials.\nExploring all combinations of elements to find optimal materials becomes very\ntime consuming, especially when there are more design variables. For this\nreason, there is growing interest in using machine learning (ML) to predict a\nmaterial's properties. In this work, we model the optimization of certain\nmaterial properties as a tensor completion problem, to leverage the structure\nof our datasets and navigate the vast number of combinations of material\nconfigurations. Across a variety of material property prediction tasks, our\nexperiments show tensor completion methods achieving 10-20% decreased error\ncompared with baseline ML models such as GradientBoosting and Multilayer\nPerceptron (MLP), while maintaining similar training speed.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "2 page paper presented at the AAAI 2025 Bridge on Knowledge-Guided\n  Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2501.18137v3",
    "published_date": "2025-01-30 04:59:21 UTC",
    "updated_date": "2025-03-19 03:35:59 UTC"
  },
  {
    "arxiv_id": "2501.18131v2",
    "title": "Entropy-Synchronized Neural Hashing for Unsupervised Ransomware Detection",
    "authors": [
      "Peter Idliman",
      "Wilfred Balfour",
      "Benedict Featheringham",
      "Hugo Chesterfield"
    ],
    "abstract": "Entropy-based detection methodologies have gained significant attention due\nto their ability to analyze structural irregularities within executable files,\nparticularly in the identification of malicious software employing advanced\nobfuscation techniques. The Entropy-Synchronized Neural Hashing (ESNH)\nframework introduces a novel approach that leverages entropy-driven hash\nrepresentations to classify software binaries based on their underlying entropy\ncharacteristics. Through the synchronization of entropy profiles with neural\nnetwork architectures, the model generates robust and unique hash values that\nmaintain stability even when faced with polymorphic and metamorphic\ntransformations. Comparative analysis against traditional detection approaches\nrevealed superior performance in identifying novel threats, reducing\nfalse-positive rates, and achieving consistent classification across diverse\nransomware families. The incorporation of a self-regulating hash convergence\nmechanism further ensured that entropy-synchronized hashes remained invariant\nacross executions, minimizing classification inconsistencies that often arise\ndue to dynamic modifications in ransomware payloads. Experimental results\ndemonstrated high detection rates across contemporary ransomware strains, with\nthe model exhibiting resilience against encryption-based evasion mechanisms,\ncode injection strategies, and reflective loading techniques. Unlike\nconventional detection mechanisms that rely on static signatures and heuristic\nanalysis, the proposed entropy-aware classification framework adapts to\nemerging threats through an inherent ability to capture entropy anomalies\nwithin executable structures. The findings reinforce the potential of\nentropy-based detection in addressing the limitations of traditional\nmethodologies while enhancing detection robustness against obfuscation and\nadversarial evasion techniques.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship",
    "pdf_url": "http://arxiv.org/pdf/2501.18131v2",
    "published_date": "2025-01-30 04:40:57 UTC",
    "updated_date": "2025-03-25 12:57:02 UTC"
  },
  {
    "arxiv_id": "2501.18129v1",
    "title": "Revisiting gender bias research in bibliometrics: Standardizing methodological variability using Scholarly Data Analysis (SoDA) Cards",
    "authors": [
      "HaeJin Lee",
      "Shubhanshu Mishra",
      "Apratim Mishra",
      "Zhiwen You",
      "Jinseok Kim",
      "Jana Diesner"
    ],
    "abstract": "Gender biases in scholarly metrics remain a persistent concern, despite\nnumerous bibliometric studies exploring their presence and absence across\nproductivity, impact, acknowledgment, and self-citations. However,\nmethodological inconsistencies, particularly in author name disambiguation and\ngender identification, limit the reliability and comparability of these\nstudies, potentially perpetuating misperceptions and hindering effective\ninterventions. A review of 70 relevant publications over the past 12 years\nreveals a wide range of approaches, from name-based and manual searches to more\nalgorithmic and gold-standard methods, with no clear consensus on best\npractices. This variability, compounded by challenges such as accurately\ndisambiguating Asian names and managing unassigned gender labels, underscores\nthe urgent need for standardized and robust methodologies. To address this\ncritical gap, we propose the development and implementation of ``Scholarly Data\nAnalysis (SoDA) Cards.\" These cards will provide a structured framework for\ndocumenting and reporting key methodological choices in scholarly data\nanalysis, including author name disambiguation and gender identification\nprocedures. By promoting transparency and reproducibility, SoDA Cards will\nfacilitate more accurate comparisons and aggregations of research findings,\nultimately supporting evidence-informed policymaking and enabling the\nlongitudinal tracking of analytical approaches in the study of gender and other\nsocial biases in academia.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.SI",
      "K.4.1"
    ],
    "primary_category": "cs.DL",
    "comment": "33 pg, 7 figures. Soda Cards:\n  https://github.com/HaeJinLee41/scholarly_bias_study",
    "pdf_url": "http://arxiv.org/pdf/2501.18129v1",
    "published_date": "2025-01-30 04:22:50 UTC",
    "updated_date": "2025-01-30 04:22:50 UTC"
  },
  {
    "arxiv_id": "2501.18128v1",
    "title": "Unraveling the Capabilities of Language Models in News Summarization",
    "authors": [
      "Abdurrahman Odabaşı",
      "Göksel Biricik"
    ],
    "abstract": "Given the recent introduction of multiple language models and the ongoing\ndemand for improved Natural Language Processing tasks, particularly\nsummarization, this work provides a comprehensive benchmarking of 20 recent\nlanguage models, focusing on smaller ones for the news summarization task. In\nthis work, we systematically test the capabilities and effectiveness of these\nmodels in summarizing news article texts which are written in different styles\nand presented in three distinct datasets. Specifically, we focus in this study\non zero-shot and few-shot learning settings and we apply a robust evaluation\nmethodology that combines different evaluation concepts including automatic\nmetrics, human evaluation, and LLM-as-a-judge. Interestingly, including\ndemonstration examples in the few-shot learning setting did not enhance models'\nperformance and, in some cases, even led to worse quality of the generated\nsummaries. This issue arises mainly due to the poor quality of the gold\nsummaries that have been used as reference summaries, which negatively impacts\nthe models' performance. Furthermore, our study's results highlight the\nexceptional performance of GPT-3.5-Turbo and GPT-4, which generally dominate\ndue to their advanced capabilities. However, among the public models evaluated,\ncertain models such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B\nand Zephyr-7B-Beta demonstrated promising results. These models showed\nsignificant potential, positioning them as competitive alternatives to large\nmodels for the task of news summarization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18128v1",
    "published_date": "2025-01-30 04:20:16 UTC",
    "updated_date": "2025-01-30 04:20:16 UTC"
  },
  {
    "arxiv_id": "2502.00059v1",
    "title": "Large Language Models are Few-shot Multivariate Time Series Classifiers",
    "authors": [
      "Yakun Chen",
      "Zihao Li",
      "Chao Yang",
      "Xianzhi Wang",
      "Guandong Xu"
    ],
    "abstract": "Large Language Models (LLMs) have been extensively applied in time series\nanalysis. Yet, their utility in the few-shot classification (i.e., a crucial\ntraining scenario due to the limited training data available in industrial\napplications) concerning multivariate time series data remains underexplored.\nWe aim to leverage the extensive pre-trained knowledge in LLMs to overcome the\ndata scarcity problem within multivariate time series. Specifically, we propose\nLLMFew, an LLM-enhanced framework to investigate the feasibility and capacity\nof LLMs for few-shot multivariate time series classification. This model\nintroduces a Patch-wise Temporal Convolution Encoder (PTCEnc) to align time\nseries data with the textual embedding input of LLMs. We further fine-tune the\npre-trained LLM decoder with Low-rank Adaptations (LoRA) to enhance its feature\nrepresentation learning ability in time series data. Experimental results show\nthat our model outperformed state-of-the-art baselines by a large margin,\nachieving 125.2% and 50.2% improvement in classification accuracy on\nHandwriting and EthanolConcentration datasets, respectively. Moreover, our\nexperimental results demonstrate that LLM-based methods perform well across a\nvariety of datasets in few-shot MTSC, delivering reliable results compared to\ntraditional models. This success paves the way for their deployment in\nindustrial environments where data are limited.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00059v1",
    "published_date": "2025-01-30 03:59:59 UTC",
    "updated_date": "2025-01-30 03:59:59 UTC"
  },
  {
    "arxiv_id": "2501.18124v2",
    "title": "REMOTE: Real-time Ego-motion Tracking for Various Endoscopes via Multimodal Visual Feature Learning",
    "authors": [
      "Liangjing Shao",
      "Benshuang Chen",
      "Shuting Zhao",
      "Xinrong Chen"
    ],
    "abstract": "Real-time ego-motion tracking for endoscope is a significant task for\nefficient navigation and robotic automation of endoscopy. In this paper, a\nnovel framework is proposed to perform real-time ego-motion tracking for\nendoscope. Firstly, a multi-modal visual feature learning network is proposed\nto perform relative pose prediction, in which the motion feature from the\noptical flow, the scene features and the joint feature from two adjacent\nobservations are all extracted for prediction. Due to more correlation\ninformation in the channel dimension of the concatenated image, a novel feature\nextractor is designed based on an attention mechanism to integrate\nmulti-dimensional information from the concatenation of two continuous frames.\nTo extract more complete feature representation from the fused features, a\nnovel pose decoder is proposed to predict the pose transformation from the\nconcatenated feature map at the end of the framework. At last, the absolute\npose of endoscope is calculated based on relative poses. The experiment is\nconducted on three datasets of various endoscopic scenes and the results\ndemonstrate that the proposed method outperforms state-of-the-art methods.\nBesides, the inference speed of the proposed method is over 30 frames per\nsecond, which meets the real-time requirement. The project page is here:\nremote-bmxs.netlify.app",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.18124v2",
    "published_date": "2025-01-30 03:58:41 UTC",
    "updated_date": "2025-02-02 14:32:01 UTC"
  },
  {
    "arxiv_id": "2501.18122v1",
    "title": "VQLTI: Long-Term Tropical Cyclone Intensity Forecasting with Physical Constraints",
    "authors": [
      "Xinyu Wang",
      "Lei Liu",
      "Kang Chen",
      "Tao Han",
      "Bin Li",
      "Lei Bai"
    ],
    "abstract": "Tropical cyclone (TC) intensity forecasting is crucial for early disaster\nwarning and emergency decision-making. Numerous researchers have explored\ndeep-learning methods to address computational and post-processing issues in\noperational forecasting. Regrettably, they exhibit subpar long-term forecasting\ncapabilities. We use two strategies to enhance long-term forecasting. (1) By\nenhancing the matching between TC intensity and spatial information, we can\nimprove long-term forecasting performance. (2) Incorporating physical knowledge\nand physical constraints can help mitigate the accumulation of forecasting\nerrors. To achieve the above strategies, we propose the VQLTI framework. VQLTI\ntransfers the TC intensity information to a discrete latent space while\nretaining the spatial information differences, using large-scale spatial\nmeteorological data as conditions. Furthermore, we leverage the forecast from\nthe weather prediction model FengWu to provide additional physical knowledge\nfor VQLTI. Additionally, we calculate the potential intensity (PI) to impose\nphysical constraints on the latent variables. In the global long-term TC\nintensity forecasting, VQLTI achieves state-of-the-art results for the 24h to\n120h, with the MSW (Maximum Sustained Wind) forecast error reduced by\n35.65%-42.51% compared to ECMWF-IFS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18122v1",
    "published_date": "2025-01-30 03:52:37 UTC",
    "updated_date": "2025-01-30 03:52:37 UTC"
  },
  {
    "arxiv_id": "2501.18119v1",
    "title": "Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models",
    "authors": [
      "Qika Lin",
      "Tianzhe Zhao",
      "Kai He",
      "Zhen Peng",
      "Fangzhi Xu",
      "Ling Huang",
      "Jingying Ma",
      "Mengling Feng"
    ],
    "abstract": "Due to the presence of the natural gap between Knowledge Graph (KG)\nstructures and the natural language, the effective integration of holistic\nstructural information of KGs with Large Language Models (LLMs) has emerged as\na significant question. To this end, we propose a two-stage framework to learn\nand apply quantized codes for each entity, aiming for the seamless integration\nof KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)\nmethod is proposed to compress both KG structural and semantic knowledge into\ndiscrete codes (\\ie, tokens) that align the format of language sentences. We\nfurther design KG instruction-following data by viewing these learned codes as\nfeatures to directly input to LLMs, thereby achieving seamless integration. The\nexperiment results demonstrate that SSQR outperforms existing unsupervised\nquantized methods, producing more distinguishable codes. Further, the\nfine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link\nprediction and triple classification tasks, utilizing only 16 tokens per entity\ninstead of thousands in conventional prompting methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18119v1",
    "published_date": "2025-01-30 03:40:20 UTC",
    "updated_date": "2025-01-30 03:40:20 UTC"
  },
  {
    "arxiv_id": "2501.18108v1",
    "title": "Investigating an Intelligent System to Monitor \\& Explain Abnormal Activity Patterns of Older Adults",
    "authors": [
      "Min Hun Lee",
      "Daniel P. Siewiorek",
      "Alexandre Bernardino"
    ],
    "abstract": "Despite the growing potential of older adult care technologies, the adoption\nof these technologies remains challenging. In this work, we conducted a\nfocus-group session with family caregivers to scope designs of the older adult\ncare technology. We then developed a high-fidelity prototype and conducted its\nqualitative study with professional caregivers and older adults to understand\ntheir perspectives on the system functionalities. This system monitors abnormal\nactivity patterns of older adults using wireless motion sensors and machine\nlearning models and supports interactive dialogue responses to explain abnormal\nactivity patterns of older adults to caregivers and allow older adults\nproactively sharing their status with caregivers for an adequate intervention.\nBoth older adults and professional caregivers appreciated that our system can\nprovide a faster, personalized service while proactively controlling what\ninformation is to be shared through interactive dialogue responses. We further\ndiscuss other considerations to realize older adult technology in practice.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18108v1",
    "published_date": "2025-01-30 03:21:14 UTC",
    "updated_date": "2025-01-30 03:21:14 UTC"
  },
  {
    "arxiv_id": "2501.18107v1",
    "title": "Scaling Inference-Efficient Language Models",
    "authors": [
      "Song Bian",
      "Minghao Yan",
      "Shivaram Venkataraman"
    ],
    "abstract": "Scaling laws are powerful tools to predict the performance of large language\nmodels. However, current scaling laws fall short of accounting for inference\ncosts. In this work, we first show that model architecture affects inference\nlatency, where models of the same size can have up to 3.5x difference in\nlatency. To tackle this challenge, we modify the Chinchilla scaling laws to\nco-optimize the model parameter count, the number of training tokens, and the\nmodel architecture. Due to the reason that models of similar training loss\nexhibit gaps in downstream evaluation, we also propose a novel method to train\ninference-efficient models based on the revised scaling laws. We perform\nextensive empirical studies to fit and evaluate our inference-aware scaling\nlaws. We vary model parameters from 80M to 1B, training tokens from 1.6B to\n30B, and model shapes, training a total of 63 models. Guided by our\ninference-efficient scaling law and model selection method, we release the\nMorph-1B model, which improves inference latency by 1.8x while maintaining\naccuracy on downstream tasks compared to open-source models, pushing the Pareto\nfrontier of accuracy-latency tradeoff.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18107v1",
    "published_date": "2025-01-30 03:16:44 UTC",
    "updated_date": "2025-01-30 03:16:44 UTC"
  },
  {
    "arxiv_id": "2501.18100v1",
    "title": "Panacea: Mitigating Harmful Fine-tuning for Large Language Models via Post-fine-tuning Perturbation",
    "authors": [
      "Yibo Wang",
      "Tiansheng Huang",
      "Li Shen",
      "Huanjin Yao",
      "Haotian Luo",
      "Rui Liu",
      "Naiqiang Tan",
      "Jiaxing Huang",
      "Dacheng Tao"
    ],
    "abstract": "Harmful fine-tuning attack introduces significant security risks to the\nfine-tuning services. Mainstream defenses aim to vaccinate the model such that\nthe later harmful fine-tuning attack is less effective. However, our evaluation\nresults show that such defenses are fragile -- with a few fine-tuning steps,\nthe model still can learn the harmful knowledge. To this end, we do further\nexperiment and find that an embarrassingly simple solution -- adding purely\nrandom perturbations to the fine-tuned model, can recover the model from\nharmful behavior, though it leads to a degradation in the model's fine-tuning\nperformance. To address the degradation of fine-tuning performance, we further\npropose Panacea, which optimizes an adaptive perturbation that will be applied\nto the model after fine-tuning. Panacea maintains model's safety alignment\nperformance without compromising downstream fine-tuning performance.\nComprehensive experiments are conducted on different harmful ratios,\nfine-tuning tasks and mainstream LLMs, where the average harmful scores are\nreduced by up-to 21.5%, while maintaining fine-tuning performance. As a\nby-product, we analyze the optimized perturbation and show that different\nlayers in various LLMs have distinct safety coefficients. Source code available\nat https://github.com/w-yibo/Panacea",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18100v1",
    "published_date": "2025-01-30 02:47:09 UTC",
    "updated_date": "2025-01-30 02:47:09 UTC"
  },
  {
    "arxiv_id": "2501.18099v1",
    "title": "Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge",
    "authors": [
      "Swarnadeep Saha",
      "Xian Li",
      "Marjan Ghazvininejad",
      "Jason Weston",
      "Tianlu Wang"
    ],
    "abstract": "LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to\ncapture the step-bystep reasoning process that underlies the final evaluation\nof a response. However, due to the lack of human annotated CoTs for evaluation,\nthe required components and structure of effective reasoning traces remain\nunderstudied. Consequently, previous approaches often (1) constrain reasoning\ntraces to hand-designed components, such as a list of criteria, reference\nanswers, or verification questions and (2) structure them such that planning is\nintertwined with the reasoning for evaluation. In this work, we propose\nEvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge\nthat first generates an unconstrained evaluation plan, followed by its\nexecution, and then the final judgment. In a self-training loop, EvalPlanner\niteratively optimizes over synthetically constructed evaluation plans and\nexecutions, leading to better final verdicts. Our method achieves a new\nstate-of-the-art performance for generative reward models on RewardBench (with\na score of 93.9), despite being trained on fewer amount of, and synthetically\ngenerated, preference pairs. Additional experiments on other benchmarks like\nRM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both\nplanning and reasoning for building robust LLM-as-a-Judge reasoning models.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18099v1",
    "published_date": "2025-01-30 02:21:59 UTC",
    "updated_date": "2025-01-30 02:21:59 UTC"
  },
  {
    "arxiv_id": "2501.18096v1",
    "title": "LLMs can see and hear without any training",
    "authors": [
      "Kumar Ashutosh",
      "Yossi Gandelsman",
      "Xinlei Chen",
      "Ishan Misra",
      "Rohit Girdhar"
    ],
    "abstract": "We present MILS: Multimodal Iterative LLM Solver, a surprisingly simple,\ntraining-free approach, to imbue multimodal capabilities into your favorite\nLLM. Leveraging their innate ability to perform multi-step reasoning, MILS\nprompts the LLM to generate candidate outputs, each of which are scored and fed\nback iteratively, eventually generating a solution to the task. This enables\nvarious applications that typically require training specialized models on\ntask-specific data. In particular, we establish a new state-of-the-art on\nemergent zero-shot image, video and audio captioning. MILS seamlessly applies\nto media generation as well, discovering prompt rewrites to improve\ntext-to-image generation, and even edit prompts for style transfer! Finally,\nbeing a gradient-free optimization approach, MILS can invert multimodal\nembeddings into text, enabling applications like cross-modal arithmetic.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code: https://github.com/facebookresearch/MILS",
    "pdf_url": "http://arxiv.org/pdf/2501.18096v1",
    "published_date": "2025-01-30 02:16:35 UTC",
    "updated_date": "2025-01-30 02:16:35 UTC"
  },
  {
    "arxiv_id": "2501.18086v1",
    "title": "DIAL: Distribution-Informed Adaptive Learning of Multi-Task Constraints for Safety-Critical Systems",
    "authors": [
      "Se-Wook Yoo",
      "Seung-Woo Seo"
    ],
    "abstract": "Safe reinforcement learning has traditionally relied on predefined constraint\nfunctions to ensure safety in complex real-world tasks, such as autonomous\ndriving. However, defining these functions accurately for varied tasks is a\npersistent challenge. Recent research highlights the potential of leveraging\npre-acquired task-agnostic knowledge to enhance both safety and sample\nefficiency in related tasks. Building on this insight, we propose a novel\nmethod to learn shared constraint distributions across multiple tasks. Our\napproach identifies the shared constraints through imitation learning and then\nadapts to new tasks by adjusting risk levels within these learned\ndistributions. This adaptability addresses variations in risk sensitivity\nstemming from expert-specific biases, ensuring consistent adherence to general\nsafety principles even with imperfect demonstrations. Our method can be applied\nto control and navigation domains, including multi-task and meta-task\nscenarios, accommodating constraints such as maintaining safe distances or\nadhering to speed limits. Experimental results validate the efficacy of our\napproach, demonstrating superior safety performance and success rates compared\nto baselines, all without requiring task-specific constraint definitions. These\nfindings underscore the versatility and practicality of our method across a\nwide range of real-world tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 14 figures, 6 tables, submission to T-RO in 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.18086v1",
    "published_date": "2025-01-30 01:56:07 UTC",
    "updated_date": "2025-01-30 01:56:07 UTC"
  },
  {
    "arxiv_id": "2501.18653v1",
    "title": "Cogito, ergo sum: A Neurobiologically-Inspired Cognition-Memory-Growth System for Code Generation",
    "authors": [
      "Yanlong Li",
      "Jindong Li",
      "Qi Wang",
      "Menglin Yang",
      "He Kong",
      "Shengsheng Wang"
    ],
    "abstract": "Large language models based Multi Agent Systems (MAS) have demonstrated\npromising performance for enhancing the efficiency and accuracy of code\ngeneration tasks. However,most existing methods follow a conventional sequence\nof planning, coding, and debugging,which contradicts the growth-driven nature\nof human learning process. Additionally,the frequent information interaction\nbetween multiple agents inevitably involves high computational costs. In this\npaper,we propose Cogito,a neurobiologically inspired multi-agent framework to\nenhance the problem-solving capabilities in code generation tasks with lower\ncost. Specifically,Cogito adopts a reverse sequence: it first undergoes\ndebugging, then coding,and finally planning. This approach mimics human\nlearning and development,where knowledge is acquired progressively.\nAccordingly,a hippocampus-like memory module with different functions is\ndesigned to work with the pipeline to provide quick retrieval in similar tasks.\nThrough this growth-based learning model,Cogito accumulates knowledge and\ncognitive skills at each stage,ultimately forming a Super Role an all capable\nagent to perform the code generation task. Extensive experiments against\nrepresentative baselines demonstrate the superior performance and efficiency of\nCogito. The code is publicly available at\nhttps://anonymous.4open.science/r/Cogito-0083.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18653v1",
    "published_date": "2025-01-30 01:41:44 UTC",
    "updated_date": "2025-01-30 01:41:44 UTC"
  },
  {
    "arxiv_id": "2501.18081v1",
    "title": "Normative Evaluation of Large Language Models with Everyday Moral Dilemmas",
    "authors": [
      "Pratik S. Sachdeva",
      "Tom van Nuenen"
    ],
    "abstract": "The rapid adoption of large language models (LLMs) has spurred extensive\nresearch into their encoded moral norms and decision-making processes. Much of\nthis research relies on prompting LLMs with survey-style questions to assess\nhow well models are aligned with certain demographic groups, moral beliefs, or\npolitical ideologies. While informative, the adherence of these approaches to\nrelatively superficial constructs tends to oversimplify the complexity and\nnuance underlying everyday moral dilemmas. We argue that auditing LLMs along\nmore detailed axes of human interaction is of paramount importance to better\nassess the degree to which they may impact human beliefs and actions. To this\nend, we evaluate LLMs on complex, everyday moral dilemmas sourced from the \"Am\nI the Asshole\" (AITA) community on Reddit, where users seek moral judgments on\neveryday conflicts from other community members. We prompted seven LLMs to\nassign blame and provide explanations for over 10,000 AITA moral dilemmas. We\nthen compared the LLMs' judgments and explanations to those of Redditors and to\neach other, aiming to uncover patterns in their moral reasoning. Our results\ndemonstrate that large language models exhibit distinct patterns of moral\njudgment, varying substantially from human evaluations on the AITA subreddit.\nLLMs demonstrate moderate to high self-consistency but low inter-model\nagreement. Further analysis of model explanations reveals distinct patterns in\nhow models invoke various moral principles. These findings highlight the\ncomplexity of implementing consistent moral reasoning in artificial systems and\nthe need for careful evaluation of how different models approach ethical\njudgment. As LLMs continue to be used in roles requiring ethical\ndecision-making such as therapists and companions, careful evaluation is\ncrucial to mitigate potential biases and limitations.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18081v1",
    "published_date": "2025-01-30 01:29:46 UTC",
    "updated_date": "2025-01-30 01:29:46 UTC"
  },
  {
    "arxiv_id": "2502.15727v1",
    "title": "Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning",
    "authors": [
      "Youssef Maklad",
      "Fares Wael",
      "Wael Elsersy",
      "Ali Hamdi"
    ],
    "abstract": "This paper presents a novel approach to evaluate the efficiency of a\nRAG-based agentic Large Language Model (LLM) architecture in network packet\nseed generation for network protocol fuzzing. Enhanced by chain-of-thought\n(COT) prompting techniques, the proposed approach focuses on the improvement of\nthe seeds structural quality in order to guide protocol fuzzing frameworks\nthrough a wide exploration of the protocol state space. Our method leverages\nRAG and text embeddings in a two-stages. In the first stage, the agent\ndynamically refers to the Request For Comments (RFC) documents knowledge base\nfor answering queries regarding the protocol Finite State Machine (FSM), then\nit iteratively reasons through the retrieved knowledge, for output refinement\nand proper seed placement. In the second stage, we evaluate the response\nstructure quality of the agent's output, based on metrics as BLEU, ROUGE, and\nWord Error Rate (WER) by comparing the generated packets against the ground\ntruth packets. Our experiments demonstrate significant improvements of up to\n18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline\nmodels. These results confirm the potential of such approach, improving\nLLM-based protocol fuzzing frameworks for the identification of hidden\nvulnerabilities.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.IR"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15727v1",
    "published_date": "2025-01-30 01:03:49 UTC",
    "updated_date": "2025-01-30 01:03:49 UTC"
  },
  {
    "arxiv_id": "2501.18071v2",
    "title": "Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence",
    "authors": [
      "Pir Bakhsh Khokhar",
      "Viviana Pentangelo",
      "Fabio Palomba",
      "Carmine Gravino"
    ],
    "abstract": "Diabetes mellitus (DM) is a global health issue of significance that must be\ndiagnosed as early as possible and managed well. This study presents a\nframework for diabetes prediction using Machine Learning (ML) models,\ncomplemented with eXplainable Artificial Intelligence (XAI) tools, to\ninvestigate both the predictive accuracy and interpretability of the\npredictions from ML models. Data Preprocessing is based on the Synthetic\nMinority Oversampling Technique (SMOTE) and feature scaling used on the\nDiabetes Binary Health Indicators dataset to deal with class imbalance and\nvariability of clinical features. The ensemble model provided high accuracy,\nwith a test accuracy of 92.50% and an ROC-AUC of 0.975. BMI, Age, General\nHealth, Income, and Physical Activity were the most influential predictors\nobtained from the model explanations. The results of this study suggest that ML\ncombined with XAI is a promising means of developing accurate and\ncomputationally transparent tools for use in healthcare systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18071v2",
    "published_date": "2025-01-30 00:42:43 UTC",
    "updated_date": "2025-02-12 11:31:48 UTC"
  },
  {
    "arxiv_id": "2501.18064v1",
    "title": "Learning Metal Microstructural Heterogeneity through Spatial Mapping of Diffraction Latent Space Features",
    "authors": [
      "Mathieu Calvat",
      "Chris Bean",
      "Dhruv Anjaria",
      "Hyoungryul Park",
      "Haoren Wang",
      "Kenneth Vecchio",
      "J. C. Stinville"
    ],
    "abstract": "To leverage advancements in machine learning for metallic materials design\nand property prediction, it is crucial to develop a data-reduced representation\nof metal microstructures that surpasses the limitations of current\nphysics-based discrete microstructure descriptors. This need is particularly\nrelevant for metallic materials processed through additive manufacturing, which\nexhibit complex hierarchical microstructures that cannot be adequately\ndescribed using the conventional metrics typically applied to wrought\nmaterials. Furthermore, capturing the spatial heterogeneity of microstructures\nat the different scales is necessary within such framework to accurately\npredict their properties. To address these challenges, we propose the physical\nspatial mapping of metal diffraction latent space features. This approach\nintegrates (i) point diffraction data encoding via variational autoencoders or\ncontrastive learning and (ii) the physical mapping of the encoded values.\nTogether these steps offer a method offers a novel means to comprehensively\ndescribe metal microstructures. We demonstrate this approach on a wrought and\nadditively manufactured alloy, showing that it effectively encodes\nmicrostructural information and enables direct identification of\nmicrostructural heterogeneity not directly possible by physics-based models.\nThis data-reduced microstructure representation opens the application of\nmachine learning models in accelerating metallic material design and accurately\npredicting their properties.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18064v1",
    "published_date": "2025-01-30 00:16:07 UTC",
    "updated_date": "2025-01-30 00:16:07 UTC"
  }
]