[
  {
    "arxiv_id": "2402.14601v3",
    "title": "Bringing Generative AI to Adaptive Learning in Education",
    "authors": [
      "Hang Li",
      "Tianlong Xu",
      "Chaoli Zhang",
      "Eason Chen",
      "Jing Liang",
      "Xing Fan",
      "Haoyang Li",
      "Jiliang Tang",
      "Qingsong Wen"
    ],
    "abstract": "The recent surge in generative AI technologies, such as large language models\nand diffusion models, has boosted the development of AI applications in various\ndomains, including science, finance, and education. Concurrently, adaptive\nlearning, a concept that has gained substantial interest in the educational\nsphere, has proven its efficacy in enhancing students' learning efficiency. In\nthis position paper, we aim to shed light on the intersectional studies of\nthese two methods, which combine generative AI with adaptive learning concepts.\nBy presenting discussions about the benefits, challenges, and potentials in\nthis field, we argue that this union will contribute significantly to the\ndevelopment of the next-stage learning format in education.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14601v3",
    "published_date": "2024-02-02 23:54:51 UTC",
    "updated_date": "2024-06-28 23:43:07 UTC"
  },
  {
    "arxiv_id": "2402.01955v1",
    "title": "OPSurv: Orthogonal Polynomials Quadrature Algorithm for Survival Analysis",
    "authors": [
      "Lilian W. Bialokozowicz",
      "Hoang M. Le",
      "Tristan Sylvain",
      "Peter A. I. Forsyth",
      "Vineel Nagisetty",
      "Greg Mori"
    ],
    "abstract": "This paper introduces the Orthogonal Polynomials Quadrature Algorithm for\nSurvival Analysis (OPSurv), a new method providing time-continuous functional\noutputs for both single and competing risks scenarios in survival analysis.\nOPSurv utilizes the initial zero condition of the Cumulative Incidence function\nand a unique decomposition of probability densities using orthogonal\npolynomials, allowing it to learn functional approximation coefficients for\neach risk event and construct Cumulative Incidence Function estimates via\nGauss--Legendre quadrature. This approach effectively counters overfitting,\nparticularly in competing risks scenarios, enhancing model expressiveness and\ncontrol. The paper further details empirical validations and theoretical\njustifications of OPSurv, highlighting its robust performance as an advancement\nin survival analysis with competing risks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.FA",
      "68W25 (Primary), 65Z05 (Secondary)",
      "I.2.0; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01955v1",
    "published_date": "2024-02-02 23:26:09 UTC",
    "updated_date": "2024-02-02 23:26:09 UTC"
  },
  {
    "arxiv_id": "2402.01928v1",
    "title": "Robust Counterfactual Explanations in Machine Learning: A Survey",
    "authors": [
      "Junqi Jiang",
      "Francesco Leofante",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "abstract": "Counterfactual explanations (CEs) are advocated as being ideally suited to\nproviding algorithmic recourse for subjects affected by the predictions of\nmachine learning models. While CEs can be beneficial to affected individuals,\nrecent work has exposed severe issues related to the robustness of\nstate-of-the-art methods for obtaining CEs. Since a lack of robustness may\ncompromise the validity of CEs, techniques to mitigate this risk are in order.\nIn this survey, we review works in the rapidly growing area of robust CEs and\nperform an in-depth analysis of the forms of robustness they consider. We also\ndiscuss existing solutions and their limitations, providing a solid foundation\nfor future developments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01928v1",
    "published_date": "2024-02-02 21:56:58 UTC",
    "updated_date": "2024-02-02 21:56:58 UTC"
  },
  {
    "arxiv_id": "2402.01922v3",
    "title": "A General Framework for Learning from Weak Supervision",
    "authors": [
      "Hao Chen",
      "Jindong Wang",
      "Lei Feng",
      "Xiang Li",
      "Yidong Wang",
      "Xing Xie",
      "Masashi Sugiyama",
      "Rita Singh",
      "Bhiksha Raj"
    ],
    "abstract": "Weakly supervised learning generally faces challenges in applicability to\nvarious scenarios with diverse weak supervision and in scalability due to the\ncomplexity of existing algorithms, thereby hindering the practical deployment.\nThis paper introduces a general framework for learning from weak supervision\n(GLWS) with a novel algorithm. Central to GLWS is an Expectation-Maximization\n(EM) formulation, adeptly accommodating various weak supervision sources,\nincluding instance partial labels, aggregate statistics, pairwise observations,\nand unlabeled data. We further present an advanced algorithm that significantly\nsimplifies the EM computational demands using a Non-deterministic Finite\nAutomaton (NFA) along with a forward-backward algorithm, which effectively\nreduces time complexity from quadratic or factorial often required in existing\nsolutions to linear scale. The problem of learning from arbitrary weak\nsupervision is therefore converted to the NFA modeling of them. GLWS not only\nenhances the scalability of machine learning models but also demonstrates\nsuperior performance and versatility across 11 weak supervision scenarios. We\nhope our work paves the way for further advancements and practical deployment\nin this field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 20 tables, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01922v3",
    "published_date": "2024-02-02 21:48:50 UTC",
    "updated_date": "2024-06-05 16:03:55 UTC"
  },
  {
    "arxiv_id": "2402.01920v2",
    "title": "Preference Poisoning Attacks on Reward Model Learning",
    "authors": [
      "Junlin Wu",
      "Jiongxiao Wang",
      "Chaowei Xiao",
      "Chenguang Wang",
      "Ning Zhang",
      "Yevgeniy Vorobeychik"
    ],
    "abstract": "Learning reward models from pairwise comparisons is a fundamental component\nin a number of domains, including autonomous control, conversational agents,\nand recommendation systems, as part of a broad goal of aligning automated\ndecisions with user preferences. These approaches entail collecting preference\ninformation from people, with feedback often provided anonymously. Since\npreferences are subjective, there is no gold standard to compare against; yet,\nreliance of high-impact systems on preference learning creates a strong\nmotivation for malicious actors to skew data collected in this fashion to their\nends. We investigate the nature and extent of this vulnerability by considering\nan attacker who can flip a small subset of preference comparisons to either\npromote or demote a target outcome. We propose two classes of algorithmic\napproaches for these attacks: a gradient-based framework, and several variants\nof rank-by-distance methods. Next, we evaluate the efficacy of best attacks in\nboth these classes in successfully achieving malicious goals on datasets from\nthree domains: autonomous control, recommendation system, and textual\nprompt-response preference learning. We find that the best attacks are often\nhighly successful, achieving in the most extreme case 100\\% success rate with\nonly 0.3\\% of the data poisoned. However, \\emph{which} attack is best can vary\nsignificantly across domains. In addition, we observe that the simpler and more\nscalable rank-by-distance approaches are often competitive with, and on\noccasion significantly outperform, gradient-based methods. Finally, we show\nthat state-of-the-art defenses against other classes of poisoning attacks\nexhibit limited efficacy in our setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01920v2",
    "published_date": "2024-02-02 21:45:24 UTC",
    "updated_date": "2024-10-08 20:32:15 UTC"
  },
  {
    "arxiv_id": "2402.01909v2",
    "title": "On Catastrophic Inheritance of Large Foundation Models",
    "authors": [
      "Hao Chen",
      "Bhiksha Raj",
      "Xing Xie",
      "Jindong Wang"
    ],
    "abstract": "Large foundation models (LFMs) are claiming incredible performances. Yet\ngreat concerns have been raised about their mythic and uninterpreted potentials\nnot only in machine learning, but also in various other disciplines. In this\nposition paper, we propose to identify a neglected issue deeply rooted in LFMs:\nCatastrophic Inheritance, describing the weaknesses and limitations inherited\nfrom biased large-scale pre-training data to behaviors of LFMs on the\ndownstream tasks, including samples that are corrupted, long-tailed, noisy,\nout-of-distributed, to name a few. Such inheritance can potentially cause\ncatastrophes to downstream applications, such as bias, lack of generalization,\ndeteriorated performance, security vulnerability, privacy leakage, and value\nmisalignment. We discuss the challenges behind this issue and propose UIM, a\nframework to Understand the catastrophic inheritance of LFMs from both\npre-training and downstream adaptation, Interpret the implications of\ncatastrophic inheritance on downstream tasks, and how to Mitigate it. UIM aims\nto unite both the machine learning and social sciences communities for more\nresponsible and promising AI development and deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by DMLR",
    "pdf_url": "http://arxiv.org/pdf/2402.01909v2",
    "published_date": "2024-02-02 21:21:55 UTC",
    "updated_date": "2024-10-23 00:40:23 UTC"
  },
  {
    "arxiv_id": "2402.05943v1",
    "title": "A hybrid IndRNNLSTM approach for real-time anomaly detection in software-defined networks",
    "authors": [
      "Sajjad Salem",
      "Salman Asoudeh"
    ],
    "abstract": "Anomaly detection in SDN using data flow prediction is a difficult task. This\nproblem is included in the category of time series and regression problems.\nMachine learning approaches are challenging in this field due to the manual\nselection of features. On the other hand, deep learning approaches have\nimportant features due to the automatic selection of features. Meanwhile,\nRNN-based approaches have been used the most. The LSTM and GRU approaches learn\ndependent entities well; on the other hand, the IndRNN approach learns\nnon-dependent entities in time series. The proposed approach tried to use a\ncombination of IndRNN and LSTM approaches to learn dependent and non-dependent\nfeatures. Feature selection approaches also provide a suitable view of features\nfor the models; for this purpose, four feature selection models, Filter,\nWrapper, Embedded, and Autoencoder were used. The proposed IndRNNLSTM\nalgorithm, in combination with Embedded, was able to achieve MAE=1.22 and\nRMSE=9.92 on NSL-KDD data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05943v1",
    "published_date": "2024-02-02 20:41:55 UTC",
    "updated_date": "2024-02-02 20:41:55 UTC"
  },
  {
    "arxiv_id": "2403.07890v2",
    "title": "$\\widetilde{O}(T^{-1})$ Convergence to (Coarse) Correlated Equilibria in Full-Information General-Sum Markov Games",
    "authors": [
      "Weichao Mao",
      "Haoran Qiu",
      "Chen Wang",
      "Hubertus Franke",
      "Zbigniew Kalbarczyk",
      "Tamer Başar"
    ],
    "abstract": "No-regret learning has a long history of being closely connected to game\ntheory. Recent works have devised uncoupled no-regret learning dynamics that,\nwhen adopted by all the players in normal-form games, converge to various\nequilibrium solutions at a near-optimal rate of $\\widetilde{O}(T^{-1})$, a\nsignificant improvement over the $O(1/\\sqrt{T})$ rate of classic no-regret\nlearners. However, analogous convergence results are scarce in Markov games, a\nmore generic setting that lays the foundation for multi-agent reinforcement\nlearning. In this work, we close this gap by showing that the\noptimistic-follow-the-regularized-leader (OFTRL) algorithm, together with\nappropriate value update procedures, can find\n$\\widetilde{O}(T^{-1})$-approximate (coarse) correlated equilibria in\nfull-information general-sum Markov games within $T$ iterations. Numerical\nresults are also included to corroborate our theoretical findings.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07890v2",
    "published_date": "2024-02-02 20:40:27 UTC",
    "updated_date": "2024-04-23 05:40:37 UTC"
  },
  {
    "arxiv_id": "2402.01889v1",
    "title": "The Role of Foundation Models in Neuro-Symbolic Learning and Reasoning",
    "authors": [
      "Daniel Cunnington",
      "Mark Law",
      "Jorge Lobo",
      "Alessandra Russo"
    ],
    "abstract": "Neuro-Symbolic AI (NeSy) holds promise to ensure the safe deployment of AI\nsystems, as interpretable symbolic techniques provide formal behaviour\nguarantees. The challenge is how to effectively integrate neural and symbolic\ncomputation, to enable learning and reasoning from raw data. Existing pipelines\nthat train the neural and symbolic components sequentially require extensive\nlabelling, whereas end-to-end approaches are limited in terms of scalability,\ndue to the combinatorial explosion in the symbol grounding problem. In this\npaper, we leverage the implicit knowledge within foundation models to enhance\nthe performance in NeSy tasks, whilst reducing the amount of data labelling and\nmanual engineering. We introduce a new architecture, called NeSyGPT, which\nfine-tunes a vision-language foundation model to extract symbolic features from\nraw data, before learning a highly expressive answer set program to solve a\ndownstream task. Our comprehensive evaluation demonstrates that NeSyGPT has\nsuperior accuracy over various baselines, and can scale to complex NeSy tasks.\nFinally, we highlight the effective use of a large language model to generate\nthe programmatic interface between the neural and symbolic components,\nsignificantly reducing the amount of manual engineering required.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Pre-print",
    "pdf_url": "http://arxiv.org/pdf/2402.01889v1",
    "published_date": "2024-02-02 20:33:14 UTC",
    "updated_date": "2024-02-02 20:33:14 UTC"
  },
  {
    "arxiv_id": "2402.01886v2",
    "title": "Inverse Reinforcement Learning by Estimating Expertise of Demonstrators",
    "authors": [
      "Mark Beliaev",
      "Ramtin Pedarsani"
    ],
    "abstract": "In Imitation Learning (IL), utilizing suboptimal and heterogeneous\ndemonstrations presents a substantial challenge due to the varied nature of\nreal-world data. However, standard IL algorithms consider these datasets as\nhomogeneous, thereby inheriting the deficiencies of suboptimal demonstrators.\nPrevious approaches to this issue rely on impractical assumptions like\nhigh-quality data subsets, confidence rankings, or explicit environmental\nknowledge. This paper introduces IRLEED, Inverse Reinforcement Learning by\nEstimating Expertise of Demonstrators, a novel framework that overcomes these\nhurdles without prior knowledge of demonstrator expertise. IRLEED enhances\nexisting Inverse Reinforcement Learning (IRL) algorithms by combining a general\nmodel for demonstrator suboptimality to address reward bias and action\nvariance, with a Maximum Entropy IRL framework to efficiently derive the\noptimal policy from diverse, suboptimal demonstrations. Experiments in both\nonline and offline IL settings, with simulated and human-generated data,\ndemonstrate IRLEED's adaptability and effectiveness, making it a versatile\nsolution for learning from suboptimal demonstrations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 4 figures, extended version of AAAI publication",
    "pdf_url": "http://arxiv.org/pdf/2402.01886v2",
    "published_date": "2024-02-02 20:21:09 UTC",
    "updated_date": "2024-12-13 18:59:14 UTC"
  },
  {
    "arxiv_id": "2402.01881v3",
    "title": "Large Language Model Agent for Hyper-Parameter Optimization",
    "authors": [
      "Siyi Liu",
      "Chen Gao",
      "Yong Li"
    ],
    "abstract": "Hyperparameter optimization is critical in modern machine learning, requiring\nexpert knowledge, numerous trials, and high computational and human resources.\nDespite the advancements in Automated Machine Learning (AutoML), challenges in\nterms of trial efficiency, setup complexity, and interoperability still\npersist. To address these issues, we introduce a novel paradigm leveraging\nLarge Language Models (LLMs) to automate hyperparameter optimization across\ndiverse machine learning tasks, which is named AgentHPO (short for LLM\nAgent-based Hyperparameter Optimization). Specifically, AgentHPO processes the\ntask information autonomously, conducts experiments with specific\nhyperparameters (HPs), and iteratively optimizes them based on historical\ntrials. This human-like optimization process largely reduces the number of\nrequired trials, simplifies the setup process, and enhances interpretability\nand user trust, compared to traditional AutoML methods. Extensive empirical\nexperiments conducted on 12 representative machine-learning tasks indicate that\nAgentHPO not only matches but also often surpasses the best human trials in\nterms of performance while simultaneously providing explainable results.\nFurther analysis sheds light on the strategies employed by the LLM in\noptimizing these tasks, highlighting its effectiveness and adaptability in\nvarious scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01881v3",
    "published_date": "2024-02-02 20:12:05 UTC",
    "updated_date": "2025-02-26 13:57:13 UTC"
  },
  {
    "arxiv_id": "2402.01877v1",
    "title": "Mobile Fitting Room: On-device Virtual Try-on via Diffusion Models",
    "authors": [
      "Justin Blalock",
      "David Munechika",
      "Harsha Karanth",
      "Alec Helbling",
      "Pratham Mehta",
      "Seongmin Lee",
      "Duen Horng Chau"
    ],
    "abstract": "The growing digital landscape of fashion e-commerce calls for interactive and\nuser-friendly interfaces for virtually trying on clothes. Traditional try-on\nmethods grapple with challenges in adapting to diverse backgrounds, poses, and\nsubjects. While newer methods, utilizing the recent advances of diffusion\nmodels, have achieved higher-quality image generation, the human-centered\ndimensions of mobile interface delivery and privacy concerns remain largely\nunexplored. We present Mobile Fitting Room, the first on-device diffusion-based\nvirtual try-on system. To address multiple inter-related technical challenges\nsuch as high-quality garment placement and model compression for mobile\ndevices, we present a novel technical pipeline and an interface design that\nenables privacy preservation and user customization. A usage scenario\nhighlights how our tool can provide a seamless, interactive virtual try-on\nexperience for customers and provide a valuable service for fashion e-commerce\nbusinesses.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01877v1",
    "published_date": "2024-02-02 20:05:45 UTC",
    "updated_date": "2024-02-02 20:05:45 UTC"
  },
  {
    "arxiv_id": "2402.01874v1",
    "title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models",
    "authors": [
      "Moschoula Pternea",
      "Prerna Singh",
      "Abir Chakraborty",
      "Yagna Oruganti",
      "Mirco Milletari",
      "Sayli Bapat",
      "Kebei Jiang"
    ],
    "abstract": "In this work, we review research studies that combine Reinforcement Learning\n(RL) and Large Language Models (LLMs), two areas that owe their momentum to the\ndevelopment of deep neural networks. We propose a novel taxonomy of three main\nclasses based on the way that the two model types interact with each other. The\nfirst class, RL4LLM, includes studies where RL is leveraged to improve the\nperformance of LLMs on tasks related to Natural Language Processing. L4LLM is\ndivided into two sub-categories depending on whether RL is used to directly\nfine-tune an existing LLM or to improve the prompt of the LLM. In the second\nclass, LLM4RL, an LLM assists the training of an RL model that performs a task\nthat is not inherently related to natural language. We further break down\nLLM4RL based on the component of the RL training framework that the LLM assists\nor replaces, namely reward shaping, goal generation, and policy function.\nFinally, in the third class, RL+LLM, an LLM and an RL agent are embedded in a\ncommon planning framework without either of them contributing to training or\nfine-tuning of the other. We further branch this class to distinguish between\nstudies with and without natural language feedback. We use this taxonomy to\nexplore the motivations behind the synergy of LLMs and RL and explain the\nreasons for its success, while pinpointing potential shortcomings and areas\nwhere further research is needed, as well as alternative methodologies that\nserve the same goal.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages (including bibliography), 1 figure, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.01874v1",
    "published_date": "2024-02-02 20:01:15 UTC",
    "updated_date": "2024-02-02 20:01:15 UTC"
  },
  {
    "arxiv_id": "2402.01864v2",
    "title": "(A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible LLM Policies for Legal Advice",
    "authors": [
      "Inyoung Cheong",
      "King Xia",
      "K. J. Kevin Feng",
      "Quan Ze Chen",
      "Amy X. Zhang"
    ],
    "abstract": "Large language models (LLMs) are increasingly capable of providing users with\nadvice in a wide range of professional domains, including legal advice.\nHowever, relying on LLMs for legal queries raises concerns due to the\nsignificant expertise required and the potential real-world consequences of the\nadvice. To explore \\textit{when} and \\textit{why} LLMs should or should not\nprovide advice to users, we conducted workshops with 20 legal experts using\nmethods inspired by case-based reasoning. The provided realistic queries\n(\"cases\") allowed experts to examine granular, situation-specific concerns and\noverarching technical and legal constraints, producing a concrete set of\ncontextual considerations for LLM developers. By synthesizing the factors that\nimpacted LLM response appropriateness, we present a 4-dimension framework: (1)\nUser attributes and behaviors, (2) Nature of queries, (3) AI capabilities, and\n(4) Social impacts. We share experts' recommendations for LLM response\nstrategies, which center around helping users identify `right questions to ask'\nand relevant information rather than providing definitive legal judgments. Our\nfindings reveal novel legal considerations, such as unauthorized practice of\nlaw, confidentiality, and liability for inaccurate advice, that have been\noverlooked in the literature. The case-based deliberation method enabled us to\nelicit fine-grained, practice-informed insights that surpass those from\nde-contextualized surveys or speculative principles. These findings underscore\nthe applicability of our method for translating domain-specific professional\nknowledge and practices into policies that can guide LLM behavior in a more\nresponsible direction.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01864v2",
    "published_date": "2024-02-02 19:35:34 UTC",
    "updated_date": "2024-05-03 07:32:34 UTC"
  },
  {
    "arxiv_id": "2402.01863v2",
    "title": "DFML: Decentralized Federated Mutual Learning",
    "authors": [
      "Yasser H. Khalil",
      "Amir H. Estiri",
      "Mahdi Beitollahi",
      "Nader Asadi",
      "Sobhan Hemati",
      "Xu Li",
      "Guojun Zhang",
      "Xi Chen"
    ],
    "abstract": "In the realm of real-world devices, centralized servers in Federated Learning\n(FL) present challenges including communication bottlenecks and susceptibility\nto a single point of failure. Additionally, contemporary devices inherently\nexhibit model and data heterogeneity. Existing work lacks a Decentralized FL\n(DFL) framework capable of accommodating such heterogeneity without imposing\narchitectural restrictions or assuming the availability of public data. To\naddress these issues, we propose a Decentralized Federated Mutual Learning\n(DFML) framework that is serverless, supports nonrestrictive heterogeneous\nmodels, and avoids reliance on public data. DFML effectively handles model and\ndata heterogeneity through mutual learning, which distills knowledge between\nclients, and cyclically varying the amount of supervision and distillation\nsignals. Extensive experimental results demonstrate consistent effectiveness of\nDFML in both convergence speed and global accuracy, outperforming prevalent\nbaselines under various conditions. For example, with the CIFAR-100 dataset and\n50 clients, DFML achieves a substantial increase of +17.20% and +19.95% in\nglobal accuracy under Independent and Identically Distributed (IID) and non-IID\ndata shifts, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01863v2",
    "published_date": "2024-02-02 19:35:05 UTC",
    "updated_date": "2024-08-13 22:07:03 UTC"
  },
  {
    "arxiv_id": "2402.01862v1",
    "title": "Parametric Feature Transfer: One-shot Federated Learning with Foundation Models",
    "authors": [
      "Mahdi Beitollahi",
      "Alex Bie",
      "Sobhan Hemati",
      "Leo Maxime Brunswic",
      "Xu Li",
      "Xi Chen",
      "Guojun Zhang"
    ],
    "abstract": "In one-shot federated learning (FL), clients collaboratively train a global\nmodel in a single round of communication. Existing approaches for one-shot FL\nenhance communication efficiency at the expense of diminished accuracy. This\npaper introduces FedPFT (Federated Learning with Parametric Feature Transfer),\na methodology that harnesses the transferability of foundation models to\nenhance both accuracy and communication efficiency in one-shot FL. The approach\ninvolves transferring per-client parametric models (specifically, Gaussian\nmixtures) of features extracted from foundation models. Subsequently, each\nparametric model is employed to generate synthetic features for training a\nclassifier head. Experimental results on eight datasets demonstrate that FedPFT\nenhances the communication-accuracy frontier in both centralized and\ndecentralized FL scenarios, as well as across diverse data-heterogeneity\nsettings such as covariate shift and task shift, with improvements of up to\n20.6%. Additionally, FedPFT adheres to the data minimization principle of FL,\nas clients do not send real features. We demonstrate that sending real features\nis vulnerable to potent reconstruction attacks. Moreover, we show that FedPFT\nis amenable to formal privacy guarantees via differential privacy,\ndemonstrating favourable privacy-accuracy tradeoffs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01862v1",
    "published_date": "2024-02-02 19:34:46 UTC",
    "updated_date": "2024-02-02 19:34:46 UTC"
  },
  {
    "arxiv_id": "2402.01858v3",
    "title": "Explaining latent representations of generative models with large multimodal models",
    "authors": [
      "Mengdan Zhu",
      "Zhenke Liu",
      "Bo Pan",
      "Abhinav Angirekula",
      "Liang Zhao"
    ],
    "abstract": "Learning interpretable representations of data generative latent factors is\nan important topic for the development of artificial intelligence. With the\nrise of the large multimodal model, it can align images with text to generate\nanswers. In this work, we propose a framework to comprehensively explain each\nlatent variable in the generative models using a large multimodal model. We\nfurther measure the uncertainty of our generated explanations, quantitatively\nevaluate the performance of explanation generation among multiple large\nmultimodal models, and qualitatively visualize the variations of each latent\nvariable to learn the disentanglement effects of different generative models on\nexplanations. Finally, we discuss the explanatory capabilities and limitations\nof state-of-the-art large multimodal models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024 Workshop on Reliable and Responsible Foundation Models",
    "pdf_url": "http://arxiv.org/pdf/2402.01858v3",
    "published_date": "2024-02-02 19:28:33 UTC",
    "updated_date": "2024-04-18 03:54:39 UTC"
  },
  {
    "arxiv_id": "2402.01849v1",
    "title": "Capturing waste collection planning expert knowledge in a fitness function through preference learning",
    "authors": [
      "Laura Fernández Díaz",
      "Miriam Fernández Díaz",
      "José Ramón Quevedo",
      "Elena Montañés"
    ],
    "abstract": "This paper copes with the COGERSA waste collection process. Up to now,\nexperts have been manually designed the process using a trial and error\nmechanism. This process is not globally optimized, since it has been\nprogressively and locally built as council demands appear. Planning\noptimization algorithms usually solve it, but they need a fitness function to\nevaluate a route planning quality. The drawback is that even experts are not\nable to propose one in a straightforward way due to the complexity of the\nprocess. Hence, the goal of this paper is to build a fitness function though a\npreference framework, taking advantage of the available expert knowledge and\nexpertise. Several key performance indicators together with preference\njudgments are carefully established according to the experts for learning a\npromising fitness function. Particularly, the additivity property of them makes\nthe task be much more affordable, since it allows to work with routes rather\nthan with route plannings. Besides, a feature selection analysis is performed\nover such indicators, since the experts suspect of a potential existing (but\nunknown) redundancy among them. The experiment results confirm this hypothesis,\nsince the best $C-$index ($98\\%$ against around $94\\%$) is reached when 6 or 8\nout of 21 indicators are taken. Particularly, truck load seems to be a highly\npromising key performance indicator, together to the travelled distance along\nnon-main roads. A comparison with other existing approaches shows that the\nproposed method clearly outperforms them, since the $C-$index goes from $72\\%$\nor $90\\%$ to $98\\%$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01849v1",
    "published_date": "2024-02-02 19:04:53 UTC",
    "updated_date": "2024-02-02 19:04:53 UTC"
  },
  {
    "arxiv_id": "2402.01841v1",
    "title": "COMET: Generating Commit Messages using Delta Graph Context Representation",
    "authors": [
      "Abhinav Reddy Mandli",
      "Saurabhsingh Rajput",
      "Tushar Sharma"
    ],
    "abstract": "Commit messages explain code changes in a commit and facilitate collaboration\namong developers. Several commit message generation approaches have been\nproposed; however, they exhibit limited success in capturing the context of\ncode changes. We propose Comet (Context-Aware Commit Message Generation), a\nnovel approach that captures context of code changes using a graph-based\nrepresentation and leverages a transformer-based model to generate high-quality\ncommit messages. Our proposed method utilizes delta graph that we developed to\neffectively represent code differences. We also introduce a customizable\nquality assurance module to identify optimal messages, mitigating subjectivity\nin commit messages. Experiments show that Comet outperforms state-of-the-art\ntechniques in terms of bleu-norm and meteor metrics while being comparable in\nterms of rogue-l. Additionally, we compare the proposed approach with the\npopular gpt-3.5-turbo model, along with gpt-4-turbo; the most capable GPT\nmodel, over zero-shot, one-shot, and multi-shot settings. We found Comet\noutperforming the GPT models, on five and four metrics respectively and provide\ncompetitive results with the two other metrics. The study has implications for\nresearchers, tool developers, and software developers. Software developers may\nutilize Comet to generate context-aware commit messages. Researchers and tool\ndevelopers can apply the proposed delta graph technique in similar contexts,\nlike code review summarization.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "22 Pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01841v1",
    "published_date": "2024-02-02 19:01:52 UTC",
    "updated_date": "2024-02-02 19:01:52 UTC"
  },
  {
    "arxiv_id": "2402.01832v2",
    "title": "SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training?",
    "authors": [
      "Hasan Abed Al Kader Hammoud",
      "Hani Itani",
      "Fabio Pizzati",
      "Philip Torr",
      "Adel Bibi",
      "Bernard Ghanem"
    ],
    "abstract": "We present SynthCLIP, a CLIP model trained on entirely synthetic text-image\npairs. Leveraging recent text-to-image (TTI) networks and large language models\n(LLM), we generate synthetic datasets of images and corresponding captions at\nscale, with no human intervention. In this work, we provide an analysis on CLIP\nmodels trained on synthetic data. We provide insights on the data generation\nstrategy, number of samples required, scaling trends, and resulting properties.\nWe also introduce SynthCI-30M, a purely synthetic dataset comprising 30 million\ncaptioned images. Our code, trained models, and data, are released as open\nsource at https://github.com/hammoudhasan/SynthCLIP",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2402.01832v2",
    "published_date": "2024-02-02 18:59:58 UTC",
    "updated_date": "2024-07-18 10:21:29 UTC"
  },
  {
    "arxiv_id": "2403.07888v2",
    "title": "Cross-modality debiasing: using language to mitigate sub-population shifts in imaging",
    "authors": [
      "Yijiang Pang",
      "Bao Hoang",
      "Jiayu Zhou"
    ],
    "abstract": "Sub-population shift is a specific type of domain shift that highlights\nchanges in data distribution within specific sub-groups or populations between\ntraining and testing. Sub-population shift accounts for a significant source of\nalgorithmic bias and calls for distributional robustness. Recent studies found\ninherent distributional robustness in multi-modality foundation models, such as\nthe vision-language model CLIP, yet this robustness is vulnerable through\nparameter fine-tuning. In this paper, we propose leveraging the connection of\nrobustness among different modalities and reshaping the distributional\nrobustness of one modality with another. Specifically, in the context of the\ndistributional robustness of CLIP, we propose to leverage natural language\ninputs to debias the image feature representations, to improve worst-case\nperformance on sub-populations. Our extensive empirical studies show that image\nrepresentations debiased by natural language can achieve significant\nperformance improvement and reduction of performance instability under\nsub-population shifts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07888v2",
    "published_date": "2024-02-02 18:54:48 UTC",
    "updated_date": "2024-04-02 14:47:23 UTC"
  },
  {
    "arxiv_id": "2402.01830v3",
    "title": "PiCO: Peer Review in LLMs based on the Consistency Optimization",
    "authors": [
      "Kun-Peng Ning",
      "Shuo Yang",
      "Yu-Yang Liu",
      "Jia-Yu Yao",
      "Zhen-Hui Liu",
      "Yong-Hong Tian",
      "Yibing Song",
      "Li Yuan"
    ],
    "abstract": "Existing large language models (LLMs) evaluation methods typically focus on\ntesting the performance on some closed-environment and domain-specific\nbenchmarks with human annotations. In this paper, we explore a novel\nunsupervised evaluation direction, utilizing peer-review mechanisms to measure\nLLMs automatically. In this setting, both open-source and closed-source LLMs\nlie in the same environment, capable of answering unlabeled questions and\nevaluating each other, where each LLM's response score is jointly determined by\nother anonymous ones. To obtain the ability hierarchy among these models, we\nassign each LLM a learnable capability parameter to adjust the final ranking.\nWe formalize it as a constrained optimization problem, intending to maximize\nthe consistency of each LLM's capabilities and scores. The key assumption\nbehind is that high-level LLM can evaluate others' answers more accurately than\nlow-level ones, while higher-level LLM can also achieve higher response scores.\nMoreover, we propose three metrics called PEN, CIN, and LIS to evaluate the gap\nin aligning human rankings. We perform experiments on multiple datasets with\nthese metrics, validating the effectiveness of the proposed approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01830v3",
    "published_date": "2024-02-02 18:49:26 UTC",
    "updated_date": "2025-02-21 06:33:26 UTC"
  },
  {
    "arxiv_id": "2402.01614v1",
    "title": "L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders",
    "authors": [
      "Ruikang Ouyang",
      "Andrew Elliott",
      "Stratis Limnios",
      "Mihai Cucuringu",
      "Gesine Reinert"
    ],
    "abstract": "For analysing real-world networks, graph representation learning is a popular\ntool. These methods, such as a graph autoencoder (GAE), typically rely on\nlow-dimensional representations, also called embeddings, which are obtained\nthrough minimising a loss function; these embeddings are used with a decoder\nfor downstream tasks such as node classification and edge prediction. While\nGAEs tend to be fairly accurate, they suffer from scalability issues. For\nimproved speed, a Local2Global approach, which combines graph patch embeddings\nbased on eigenvector synchronisation, was shown to be fast and achieve good\naccuracy. Here we propose L2G2G, a Local2Global method which improves GAE\naccuracy without sacrificing scalability. This improvement is achieved by\ndynamically synchronising the latent node representations, while training the\nGAEs. It also benefits from the decoder computing an only local patch loss.\nHence, aligning the local embeddings in each epoch utilises more information\nfrom the graph than a single post-training alignment does, while maintaining\nscalability. We illustrate on synthetic benchmarks, as well as real-world\nexamples, that L2G2G achieves higher accuracy than the standard Local2Global\napproach and scales efficiently on the larger data sets. We find that for large\nand dense networks, it even outperforms the slow, but assumed more accurate,\nGAEs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 4 figures, Complex Networks 2023, Volume I, SCI 1141",
    "pdf_url": "http://arxiv.org/pdf/2402.01614v1",
    "published_date": "2024-02-02 18:24:37 UTC",
    "updated_date": "2024-02-02 18:24:37 UTC"
  },
  {
    "arxiv_id": "2402.01613v2",
    "title": "Nomic Embed: Training a Reproducible Long Context Text Embedder",
    "authors": [
      "Zach Nussbaum",
      "John X. Morris",
      "Brandon Duderstadt",
      "Andriy Mulyar"
    ],
    "abstract": "This technical report describes the training of nomic-embed-text-v1, the\nfirst fully reproducible, open-source, open-weights, open-data, 8192 context\nlength English text embedding model that outperforms both OpenAI Ada-002 and\nOpenAI text-embedding-3-small on the short-context MTEB benchmark and the long\ncontext LoCo benchmark. We release the training code and model weights under an\nApache 2.0 license. In contrast with other open-source models, we release the\nfull curated training data and code that allows for full replication of\nnomic-embed-text-v1. You can find code and data to replicate the model at\nhttps://github.com/nomic-ai/contrastors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to TMLR https://openreview.net/forum?id=IPmzyQSiQE",
    "pdf_url": "http://arxiv.org/pdf/2402.01613v2",
    "published_date": "2024-02-02 18:23:18 UTC",
    "updated_date": "2025-02-03 22:26:56 UTC"
  },
  {
    "arxiv_id": "2402.01828v1",
    "title": "Retrieval Augmented End-to-End Spoken Dialog Models",
    "authors": [
      "Mingqiu Wang",
      "Izhak Shafran",
      "Hagen Soltau",
      "Wei Han",
      "Yuan Cao",
      "Dian Yu",
      "Laurent El Shafey"
    ],
    "abstract": "We recently developed SLM, a joint speech and language model, which fuses a\npretrained foundational speech model and a large language model (LLM), while\npreserving the in-context learning capability intrinsic to the pretrained LLM.\nIn this paper, we apply SLM to speech dialog applications where the dialog\nstates are inferred directly from the audio signal.\n  Task-oriented dialogs often contain domain-specific entities, i.e.,\nrestaurants, hotels, train stations, and city names, which are difficult to\nrecognize, however, critical for the downstream applications. Inspired by the\nRAG (retrieval-augmented generation) paradigm, we propose a retrieval augmented\nSLM (ReSLM) that overcomes this weakness. We first train a speech retriever to\nretrieve text entities mentioned in the audio. The retrieved entities are then\nadded as text inputs to the underlying SLM to bias model predictions. We\nevaluated ReSLM on speech MultiWoz task (DSTC-11 challenge), and found that\nthis retrieval augmentation boosts model performance, achieving joint goal\naccuracy (38.6% vs 32.7%), slot error rate (20.6% vs 24.8%) and ASR word error\nrate (5.5% vs 6.7%). While demonstrated on dialog state tracking, our approach\nis broadly applicable to other speech tasks requiring contextual information or\ndomain-specific entities, such as contextual ASR with biasing capability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01828v1",
    "published_date": "2024-02-02 18:23:09 UTC",
    "updated_date": "2024-02-02 18:23:09 UTC"
  },
  {
    "arxiv_id": "2402.01826v1",
    "title": "Leveraging Large Language Models for Analyzing Blood Pressure Variations Across Biological Sex from Scientific Literature",
    "authors": [
      "Yuting Guo",
      "Seyedeh Somayyeh Mousavi",
      "Reza Sameni",
      "Abeed Sarker"
    ],
    "abstract": "Hypertension, defined as blood pressure (BP) that is above normal, holds\nparamount significance in the realm of public health, as it serves as a\ncritical precursor to various cardiovascular diseases (CVDs) and significantly\ncontributes to elevated mortality rates worldwide. However, many existing BP\nmeasurement technologies and standards might be biased because they do not\nconsider clinical outcomes, comorbidities, or demographic factors, making them\ninconclusive for diagnostic purposes. There is limited data-driven research\nfocused on studying the variance in BP measurements across these variables. In\nthis work, we employed GPT-35-turbo, a large language model (LLM), to\nautomatically extract the mean and standard deviation values of BP for both\nmales and females from a dataset comprising 25 million abstracts sourced from\nPubMed. 993 article abstracts met our predefined inclusion criteria (i.e.,\npresence of references to blood pressure, units of blood pressure such as mmHg,\nand mention of biological sex). Based on the automatically-extracted\ninformation from these articles, we conducted an analysis of the variations of\nBP values across biological sex. Our results showed the viability of utilizing\nLLMs to study the BP variations across different demographic factors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01826v1",
    "published_date": "2024-02-02 18:15:51 UTC",
    "updated_date": "2024-02-02 18:15:51 UTC"
  },
  {
    "arxiv_id": "2402.01607v3",
    "title": "Natural Counterfactuals With Necessary Backtracking",
    "authors": [
      "Guang-Yuan Hao",
      "Jiji Zhang",
      "Biwei Huang",
      "Hao Wang",
      "Kun Zhang"
    ],
    "abstract": "Counterfactual reasoning is pivotal in human cognition and especially\nimportant for providing explanations and making decisions. While Judea Pearl's\ninfluential approach is theoretically elegant, its generation of a\ncounterfactual scenario often requires too much deviation from the observed\nscenarios to be feasible, as we show using simple examples. To mitigate this\ndifficulty, we propose a framework of \\emph{natural counterfactuals} and a\nmethod for generating counterfactuals that are more feasible with respect to\nthe actual data distribution. Our methodology incorporates a certain amount of\nbacktracking when needed, allowing changes in causally preceding variables to\nminimize deviations from realistic scenarios. Specifically, we introduce a\nnovel optimization framework that permits but also controls the extent of\nbacktracking with a naturalness criterion. Empirical experiments demonstrate\nthe effectiveness of our method. The code is available at\nhttps://github.com/GuangyuanHao/natural_counterfactuals.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.NE",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01607v3",
    "published_date": "2024-02-02 18:11:43 UTC",
    "updated_date": "2024-10-30 23:53:11 UTC"
  },
  {
    "arxiv_id": "2402.01602v1",
    "title": "Foundation Model Sherpas: Guiding Foundation Models through Knowledge and Reasoning",
    "authors": [
      "Debarun Bhattacharjya",
      "Junkyu Lee",
      "Don Joven Agravante",
      "Balaji Ganesan",
      "Radu Marinescu"
    ],
    "abstract": "Foundation models (FMs) such as large language models have revolutionized the\nfield of AI by showing remarkable performance in various tasks. However, they\nexhibit numerous limitations that prevent their broader adoption in many\nreal-world systems, which often require a higher bar for trustworthiness and\nusability. Since FMs are trained using loss functions aimed at reconstructing\nthe training corpus in a self-supervised manner, there is no guarantee that the\nmodel's output aligns with users' preferences for a specific task at hand. In\nthis survey paper, we propose a conceptual framework that encapsulates\ndifferent modes by which agents could interact with FMs and guide them suitably\nfor a set of tasks, particularly through knowledge augmentation and reasoning.\nOur framework elucidates agent role categories such as updating the underlying\nFM, assisting with prompting the FM, and evaluating the FM output. We also\ncategorize several state-of-the-art approaches into agent interaction\nprotocols, highlighting the nature and extent of involvement of the various\nagent roles. The proposed framework provides guidance for future directions to\nfurther realize the power of FMs in practical AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01602v1",
    "published_date": "2024-02-02 18:00:35 UTC",
    "updated_date": "2024-02-02 18:00:35 UTC"
  },
  {
    "arxiv_id": "2402.01591v2",
    "title": "BAT: Learning to Reason about Spatial Sounds with Large Language Models",
    "authors": [
      "Zhisheng Zheng",
      "Puyuan Peng",
      "Ziyang Ma",
      "Xie Chen",
      "Eunsol Choi",
      "David Harwath"
    ],
    "abstract": "Spatial sound reasoning is a fundamental human skill, enabling us to navigate\nand interpret our surroundings based on sound. In this paper we present BAT,\nwhich combines the spatial sound perception ability of a binaural acoustic\nscene analysis model with the natural language reasoning capabilities of a\nlarge language model (LLM) to replicate this innate ability. To address the\nlack of existing datasets of in-the-wild spatial sounds, we synthesized a\nbinaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developed\nSpatialSoundQA, a spatial sound-based question-answering dataset, offering a\nrange of QA tasks that train BAT in various aspects of spatial sound perception\nand reasoning. The acoustic front end encoder of BAT is a novel spatial audio\nencoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which by\nitself achieves strong performance across sound event detection, spatial\nlocalization, and distance estimation. By integrating Spatial-AST with LLaMA-2\n7B model, BAT transcends standard Sound Event Localization and Detection (SELD)\ntasks, enabling the model to reason about the relationships between the sounds\nin its environment. Our experiments demonstrate BAT's superior performance on\nboth spatial sound perception and reasoning, showcasing the immense potential\nof LLMs in navigating and interpreting complex spatial audio environments.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to ICML 2024. Our demo, dataset, code and model weights are\n  available at: https://zhishengzheng.com/BAT",
    "pdf_url": "http://arxiv.org/pdf/2402.01591v2",
    "published_date": "2024-02-02 17:34:53 UTC",
    "updated_date": "2024-05-25 17:05:11 UTC"
  },
  {
    "arxiv_id": "2402.05942v1",
    "title": "Cooperative Knowledge Distillation: A Learner Agnostic Approach",
    "authors": [
      "Michael Livanos",
      "Ian Davidson",
      "Stephen Wong"
    ],
    "abstract": "Knowledge distillation is a simple but powerful way to transfer knowledge\nbetween a teacher model to a student model. Existing work suffers from at least\none of the following key limitations in terms of direction and scope of\ntransfer which restrict its use: all knowledge is transferred from teacher to\nstudent regardless of whether or not that knowledge is useful, the student is\nthe only one learning in this exchange, and typically distillation transfers\nknowledge only from a single teacher to a single student. We formulate a novel\nform of knowledge distillation in which many models can act as both students\nand teachers which we call cooperative distillation. The models cooperate as\nfollows: a model (the student) identifies specific deficiencies in it's\nperformance and searches for another model (the teacher) who encodes learned\nknowledge into instructional virtual instances via counterfactual instance\ngeneration. Because different models may have different strengths and\nweaknesses, all models can act as either students or teachers (cooperation)\nwhen appropriate and only distill knowledge in areas specific to their\nstrengths (focus). Since counterfactuals as a paradigm are not tied to any\nspecific algorithm, we can use this method to distill knowledge between\nlearners of different architectures, algorithms, and even feature spaces. We\ndemonstrate that our approach not only outperforms baselines such as transfer\nlearning, self-supervised learning, and multiple knowledge distillation\nalgorithms on several datasets, but it can also be used in settings where the\naforementioned techniques cannot.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 7 figures, AAAI24",
    "pdf_url": "http://arxiv.org/pdf/2402.05942v1",
    "published_date": "2024-02-02 17:31:50 UTC",
    "updated_date": "2024-02-02 17:31:50 UTC"
  },
  {
    "arxiv_id": "2402.01586v4",
    "title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents",
    "authors": [
      "Wenyue Hua",
      "Xianjun Yang",
      "Mingyu Jin",
      "Zelong Li",
      "Wei Cheng",
      "Ruixiang Tang",
      "Yongfeng Zhang"
    ],
    "abstract": "The rise of LLM-based agents shows great potential to revolutionize task\nplanning, capturing significant attention. Given that these agents will be\nintegrated into high-stake domains, ensuring their reliability and safety is\ncrucial. This paper presents an Agent-Constitution-based agent framework,\nTrustAgent, with a particular focus on improving the LLM-based agent safety.\nThe proposed framework ensures strict adherence to the Agent Constitution\nthrough three strategic components: pre-planning strategy which injects safety\nknowledge to the model before plan generation, in-planning strategy which\nenhances safety during plan generation, and post-planning strategy which\nensures safety by post-planning inspection. Our experimental results\ndemonstrate that the proposed framework can effectively enhance an LLM agent's\nsafety across multiple domains by identifying and mitigating potential dangers\nduring the planning. Further analysis reveals that the framework not only\nimproves safety but also enhances the helpfulness of the agent. Additionally,\nwe highlight the importance of the LLM reasoning ability in adhering to the\nConstitution. This paper sheds light on how to ensure the safe integration of\nLLM-based agents into human-centric environments. Data and code are available\nat https://github.com/agiresearch/TrustAgent.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "In EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01586v4",
    "published_date": "2024-02-02 17:26:23 UTC",
    "updated_date": "2024-10-03 22:12:05 UTC"
  },
  {
    "arxiv_id": "2402.01580v2",
    "title": "Generative AI for Education (GAIED): Advances, Opportunities, and Challenges",
    "authors": [
      "Paul Denny",
      "Sumit Gulwani",
      "Neil T. Heffernan",
      "Tanja Käser",
      "Steven Moore",
      "Anna N. Rafferty",
      "Adish Singla"
    ],
    "abstract": "This survey article has grown out of the GAIED (pronounced \"guide\") workshop\norganized by the authors at the NeurIPS 2023 conference. We organized the GAIED\nworkshop as part of a community-building effort to bring together researchers,\neducators, and practitioners to explore the potential of generative AI for\nenhancing education. This article aims to provide an overview of the workshop\nactivities and highlight several future research directions in the area of\nGAIED.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01580v2",
    "published_date": "2024-02-02 17:19:20 UTC",
    "updated_date": "2024-02-07 01:11:10 UTC"
  },
  {
    "arxiv_id": "2402.01825v2",
    "title": "Fractal Patterns May Illuminate the Success of Next-Token Prediction",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Vinh Q. Tran",
      "Mostafa Dehghani"
    ],
    "abstract": "We study the fractal structure of language, aiming to provide a precise\nformalism for quantifying properties that may have been previously suspected\nbut not formally shown. We establish that language is: (1) self-similar,\nexhibiting complexities at all levels of granularity, with no particular\ncharacteristic context length, and (2) long-range dependent (LRD), with a Hurst\nparameter of approximately H=0.7. Based on these findings, we argue that\nshort-term patterns/dependencies in language, such as in paragraphs, mirror the\npatterns/dependencies over larger scopes, like entire documents. This may shed\nsome light on how next-token prediction can capture the structure of text\nacross multiple levels of granularity, from words and clauses to broader\ncontexts and intents. In addition, we carry out an extensive analysis across\ndifferent domains and architectures, showing that fractal parameters are\nrobust. Finally, we demonstrate that the tiny variations in fractal parameters\nseen across LLMs improve upon perplexity-based bits-per-byte (BPB) in\npredicting their downstream performance. We hope these findings offer a fresh\nperspective on language and the mechanisms underlying the success of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 10 tables, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01825v2",
    "published_date": "2024-02-02 17:09:33 UTC",
    "updated_date": "2024-05-22 16:19:13 UTC"
  },
  {
    "arxiv_id": "2402.01566v1",
    "title": "Boximator: Generating Rich and Controllable Motions for Video Synthesis",
    "authors": [
      "Jiawei Wang",
      "Yuchen Zhang",
      "Jiaxin Zou",
      "Yan Zeng",
      "Guoqiang Wei",
      "Liping Yuan",
      "Hang Li"
    ],
    "abstract": "Generating rich and controllable motion is a pivotal challenge in video\nsynthesis. We propose Boximator, a new approach for fine-grained motion\ncontrol. Boximator introduces two constraint types: hard box and soft box.\nUsers select objects in the conditional frame using hard boxes and then use\neither type of boxes to roughly or rigorously define the object's position,\nshape, or motion path in future frames. Boximator functions as a plug-in for\nexisting video diffusion models. Its training process preserves the base\nmodel's knowledge by freezing the original weights and training only the\ncontrol module. To address training challenges, we introduce a novel\nself-tracking technique that greatly simplifies the learning of box-object\ncorrelations. Empirically, Boximator achieves state-of-the-art video quality\n(FVD) scores, improving on two base models, and further enhanced after\nincorporating box constraints. Its robust motion controllability is validated\nby drastic increases in the bounding box alignment metric. Human evaluation\nalso shows that users favor Boximator generation results over the base model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01566v1",
    "published_date": "2024-02-02 16:59:48 UTC",
    "updated_date": "2024-02-02 16:59:48 UTC"
  },
  {
    "arxiv_id": "2402.01546v1",
    "title": "Privacy-Preserving Distributed Learning for Residential Short-Term Load Forecasting",
    "authors": [
      "Yi Dong",
      "Yingjie Wang",
      "Mariana Gama",
      "Mustafa A. Mustafa",
      "Geert Deconinck",
      "Xiaowei Huang"
    ],
    "abstract": "In the realm of power systems, the increasing involvement of residential\nusers in load forecasting applications has heightened concerns about data\nprivacy. Specifically, the load data can inadvertently reveal the daily\nroutines of residential users, thereby posing a risk to their property\nsecurity. While federated learning (FL) has been employed to safeguard user\nprivacy by enabling model training without the exchange of raw data, these FL\nmodels have shown vulnerabilities to emerging attack techniques, such as Deep\nLeakage from Gradients and poisoning attacks. To counteract these, we initially\nemploy a Secure-Aggregation (SecAgg) algorithm that leverages multiparty\ncomputation cryptographic techniques to mitigate the risk of gradient leakage.\nHowever, the introduction of SecAgg necessitates the deployment of additional\nsub-center servers for executing the multiparty computation protocol, thereby\nescalating computational complexity and reducing system robustness, especially\nin scenarios where one or more sub-centers are unavailable. To address these\nchallenges, we introduce a Markovian Switching-based distributed training\nframework, the convergence of which is substantiated through rigorous\ntheoretical analysis. The Distributed Markovian Switching (DMS) topology shows\nstrong robustness towards the poisoning attacks as well. Case studies employing\nreal-world power system load data validate the efficacy of our proposed\nalgorithm. It not only significantly minimizes communication complexity but\nalso maintains accuracy levels comparable to traditional FL methods, thereby\nenhancing the scalability of our load forecasting algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01546v1",
    "published_date": "2024-02-02 16:39:08 UTC",
    "updated_date": "2024-02-02 16:39:08 UTC"
  },
  {
    "arxiv_id": "2402.01822v2",
    "title": "Building Guardrails for Large Language Models",
    "authors": [
      "Yi Dong",
      "Ronghui Mu",
      "Gaojie Jin",
      "Yi Qi",
      "Jinwei Hu",
      "Xingyu Zhao",
      "Jie Meng",
      "Wenjie Ruan",
      "Xiaowei Huang"
    ],
    "abstract": "As Large Language Models (LLMs) become more integrated into our daily lives,\nit is crucial to identify and mitigate their risks, especially when the risks\ncan have profound impacts on human users and societies. Guardrails, which\nfilter the inputs or outputs of LLMs, have emerged as a core safeguarding\ntechnology. This position paper takes a deep look at current open-source\nsolutions (Llama Guard, Nvidia NeMo, Guardrails AI), and discusses the\nchallenges and the road towards building more complete solutions. Drawing on\nrobust evidence from previous research, we advocate for a systematic approach\nto construct guardrails for LLMs, based on comprehensive consideration of\ndiverse contexts across various LLMs applications. We propose employing\nsocio-technical methods through collaboration with a multi-disciplinary team to\npinpoint precise technical requirements, exploring advanced neural-symbolic\nimplementations to embrace the complexity of the requirements, and developing\nverification and testing to ensure the utmost quality of the final product.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Proceedings of the 41st International Conference on Machine Learning,\n  Vienna, Austria. PMLR 235, 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01822v2",
    "published_date": "2024-02-02 16:35:00 UTC",
    "updated_date": "2024-05-29 12:57:01 UTC"
  },
  {
    "arxiv_id": "2402.01821v2",
    "title": "Human-like Category Learning by Injecting Ecological Priors from Large Language Models into Neural Networks",
    "authors": [
      "Akshay K. Jagadish",
      "Julian Coda-Forno",
      "Mirko Thalmann",
      "Eric Schulz",
      "Marcel Binz"
    ],
    "abstract": "Ecological rationality refers to the notion that humans are rational agents\nadapted to their environment. However, testing this theory remains challenging\ndue to two reasons: the difficulty in defining what tasks are ecologically\nvalid and building rational models for these tasks. In this work, we\ndemonstrate that large language models can generate cognitive tasks,\nspecifically category learning tasks, that match the statistics of real-world\ntasks, thereby addressing the first challenge. We tackle the second challenge\nby deriving rational agents adapted to these tasks using the framework of\nmeta-learning, leading to a class of models called ecologically rational\nmeta-learned inference (ERMI). ERMI quantitatively explains human data better\nthan seven other cognitive models in two different experiments. It additionally\nmatches human behavior on a qualitative level: (1) it finds the same tasks\ndifficult that humans find difficult, (2) it becomes more reliant on an\nexemplar-based strategy for assigning categories with learning, and (3) it\ngeneralizes to unseen stimuli in a human-like way. Furthermore, we show that\nERMI's ecologically valid priors allow it to achieve state-of-the-art\nperformance on the OpenML-CC18 classification benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages (9 pages of main text, 4 pages of references, and 14 pages\n  of appendix), 13 figures, and 7 Tables",
    "pdf_url": "http://arxiv.org/pdf/2402.01821v2",
    "published_date": "2024-02-02 16:32:04 UTC",
    "updated_date": "2024-05-28 07:40:53 UTC"
  },
  {
    "arxiv_id": "2402.01537v1",
    "title": "Closing the Gap in Human Behavior Analysis: A Pipeline for Synthesizing Trimodal Data",
    "authors": [
      "Christian Stippel",
      "Thomas Heitzinger",
      "Rafael Sterzinger",
      "Martin Kampel"
    ],
    "abstract": "In pervasive machine learning, especially in Human Behavior Analysis (HBA),\nRGB has been the primary modality due to its accessibility and richness of\ninformation. However, linked with its benefits are challenges, including\nsensitivity to lighting conditions and privacy concerns. One possibility to\novercome these vulnerabilities is to resort to different modalities. For\ninstance, thermal is particularly adept at accentuating human forms, while\ndepth adds crucial contextual layers. Despite their known benefits, only a few\nHBA-specific datasets that integrate these modalities exist. To address this\nshortage, our research introduces a novel generative technique for creating\ntrimodal, i.e., RGB, thermal, and depth, human-focused datasets. This technique\ncapitalizes on human segmentation masks derived from RGB images, combined with\nthermal and depth backgrounds that are sourced automatically. With these two\ningredients, we synthesize depth and thermal counterparts from existing RGB\ndata utilizing conditional image-to-image translation. By employing this\napproach, we generate trimodal data that can be leveraged to train models for\nsettings with limited data, bad lightning conditions, or privacy-sensitive\nareas.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01537v1",
    "published_date": "2024-02-02 16:27:45 UTC",
    "updated_date": "2024-02-02 16:27:45 UTC"
  },
  {
    "arxiv_id": "2402.01536v2",
    "title": "Homogenization Effects of Large Language Models on Human Creative Ideation",
    "authors": [
      "Barrett R. Anderson",
      "Jash Hemant Shah",
      "Max Kreminski"
    ],
    "abstract": "Large language models (LLMs) are now being used in a wide variety of\ncontexts, including as creativity support tools (CSTs) intended to help their\nusers come up with new ideas. But do LLMs actually support user creativity? We\nhypothesized that the use of an LLM as a CST might make the LLM's users feel\nmore creative, and even broaden the range of ideas suggested by each individual\nuser, but also homogenize the ideas suggested by different users. We conducted\na 36-participant comparative user study and found, in accordance with the\nhomogenization hypothesis, that different users tended to produce less\nsemantically distinct ideas with ChatGPT than with an alternative CST.\nAdditionally, ChatGPT users generated a greater number of more detailed ideas,\nbut felt less responsible for the ideas they generated. We discuss potential\nimplications of these findings for users, designers, and developers of\nLLM-based CSTs.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to C&C 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01536v2",
    "published_date": "2024-02-02 16:27:11 UTC",
    "updated_date": "2024-05-10 20:10:22 UTC"
  },
  {
    "arxiv_id": "2402.01535v2",
    "title": "An Empirical Analysis of Diversity in Argument Summarization",
    "authors": [
      "Michiel van der Meer",
      "Piek Vossen",
      "Catholijn M. Jonker",
      "Pradeep K. Murukannaiah"
    ],
    "abstract": "Presenting high-level arguments is a crucial task for fostering participation\nin online societal discussions. Current argument summarization approaches miss\nan important facet of this task -- capturing diversity -- which is important\nfor accommodating multiple perspectives. We introduce three aspects of\ndiversity: those of opinions, annotators, and sources. We evaluate approaches\nto a popular argument summarization task called Key Point Analysis, which shows\nhow these approaches struggle to (1) represent arguments shared by few people,\n(2) deal with data from various sources, and (3) align with subjectivity in\nhuman-provided annotations. We find that both general-purpose LLMs and\ndedicated KPA models exhibit this behavior, but have complementary strengths.\nFurther, we observe that diversification of training data may ameliorate\ngeneralization. Addressing diversity in argument summarization requires a mix\nof strategies to deal with subjectivity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EACL2024 (main proceedings)",
    "pdf_url": "http://arxiv.org/pdf/2402.01535v2",
    "published_date": "2024-02-02 16:26:52 UTC",
    "updated_date": "2024-02-14 10:51:08 UTC"
  },
  {
    "arxiv_id": "2402.01521v2",
    "title": "K-Level Reasoning: Establishing Higher Order Beliefs in Large Language Models for Strategic Reasoning",
    "authors": [
      "Yadong Zhang",
      "Shaoguang Mao",
      "Tao Ge",
      "Xun Wang",
      "Yan Xia",
      "Man Lan",
      "Furu Wei"
    ],
    "abstract": "Strategic reasoning is a complex yet essential capability for intelligent\nagents. It requires Large Language Model (LLM) agents to adapt their strategies\ndynamically in multi-agent environments. Unlike static reasoning tasks, success\nin these contexts depends on anticipating other agents' beliefs and actions\nwhile continuously adjusting strategies to achieve individual goals. LLMs and\nLLM agents often struggle with strategic reasoning due to the absence of a\nreasoning framework that enables them to dynamically infer others' perspectives\nand adapt to changing environments. Inspired by the Level-K framework from game\ntheory and behavioral economics, which extends reasoning from simple reactions\nto structured strategic depth, we propose a novel framework: \"K-Level Reasoning\nwith Large Language Models (K-R).\" This framework employs recursive mechanisms\nto enable LLMs to achieve varying levels of strategic depth, allowing agents to\nform higher order beliefs - beliefs about others' beliefs. We validate this\nframework through rigorous testing on four testbeds: two classical game theory\nproblems and two social intelligence tasks. The results demonstrate the\nadvantages of K-R in strategic reasoning. Our work presents the first recursive\nimplementation of strategic depth in large language models (LLMs). It\nestablishes a foundation for future research into theory of mind and strategic\nreasoning in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01521v2",
    "published_date": "2024-02-02 16:07:05 UTC",
    "updated_date": "2024-10-17 16:08:15 UTC"
  },
  {
    "arxiv_id": "2402.01515v1",
    "title": "Enhancing Stochastic Gradient Descent: A Unified Framework and Novel Acceleration Methods for Faster Convergence",
    "authors": [
      "Yichuan Deng",
      "Zhao Song",
      "Chiwun Yang"
    ],
    "abstract": "Based on SGD, previous works have proposed many algorithms that have improved\nconvergence speed and generalization in stochastic optimization, such as SGDm,\nAdaGrad, Adam, etc. However, their convergence analysis under non-convex\nconditions is challenging. In this work, we propose a unified framework to\naddress this issue. For any first-order methods, we interpret the updated\ndirection $g_t$ as the sum of the stochastic subgradient $\\nabla f_t(x_t)$ and\nan additional acceleration term $\\frac{2|\\langle v_t, \\nabla f_t(x_t)\n\\rangle|}{\\|v_t\\|_2^2} v_t$, thus we can discuss the convergence by analyzing\n$\\langle v_t, \\nabla f_t(x_t) \\rangle$. Through our framework, we have\ndiscovered two plug-and-play acceleration methods: \\textbf{Reject Accelerating}\nand \\textbf{Random Vector Accelerating}, we theoretically demonstrate that\nthese two methods can directly lead to an improvement in convergence rate.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01515v1",
    "published_date": "2024-02-02 15:55:25 UTC",
    "updated_date": "2024-02-02 15:55:25 UTC"
  },
  {
    "arxiv_id": "2402.01499v3",
    "title": "Developing and Evaluating a Design Method for Positive Artificial Intelligence",
    "authors": [
      "Willem van der Maden",
      "Derek Lomas",
      "Paul Hekkert"
    ],
    "abstract": "As artificial intelligence (AI) continues advancing, ensuring positive\nsocietal impacts becomes critical, especially as AI systems become increasingly\nubiquitous in various aspects of life. However, developing \"AI for good\" poses\nsubstantial challenges around aligning systems with complex human values.\nPresently, we lack mature methods for addressing these challenges. This article\npresents and evaluates the Positive AI design method aimed at addressing this\ngap. The method provides a human-centered process to translate wellbeing\naspirations into concrete practices. First, we explain the method's four key\nsteps: contextualizing, operationalizing, optimizing, and implementing\nwellbeing supported by continuous measurement for feedback cycles. We then\npresent a multiple case study where novice designers applied the method,\nrevealing strengths and weaknesses related to efficacy and usability. Next, an\nexpert evaluation study assessed the quality of the resulting concepts, rating\nthem moderately high for feasibility, desirability, and plausibility of\nachieving intended wellbeing benefits. Together, these studies provide\npreliminary validation of the method's ability to improve AI design, while\nsurfacing areas needing refinement like developing support for complex steps.\nProposed adaptations such as examples and evaluation heuristics could address\nweaknesses. Further research should examine sustained application over multiple\nprojects. This human-centered approach shows promise for realizing the vision\nof 'AI for Wellbeing' that does not just avoid harm, but actively benefits\nhumanity.",
    "categories": [
      "cs.AI",
      "68T01",
      "H.5.2; I.2.9; J.3"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01499v3",
    "published_date": "2024-02-02 15:31:08 UTC",
    "updated_date": "2024-12-19 09:58:47 UTC"
  },
  {
    "arxiv_id": "2402.01481v4",
    "title": "Pre-Training Protein Bi-level Representation Through Span Mask Strategy On 3D Protein Chains",
    "authors": [
      "Jiale Zhao",
      "Wanru Zhuang",
      "Jia Song",
      "Yaqi Li",
      "Shuqi Lu"
    ],
    "abstract": "In recent years, there has been a surge in the development of 3D\nstructure-based pre-trained protein models, representing a significant\nadvancement over pre-trained protein language models in various downstream\ntasks. However, most existing structure-based pre-trained models primarily\nfocus on the residue level, i.e., alpha carbon atoms, while ignoring other\natoms like side chain atoms. We argue that modeling proteins at both residue\nand atom levels is important since the side chain atoms can also be crucial for\nnumerous downstream tasks, for example, molecular docking. Nevertheless, we\nfind that naively combining residue and atom information during pre-training\ntypically fails. We identify a key reason is the information leakage caused by\nthe inclusion of atom structure in the input, which renders residue-level\npre-training tasks trivial and results in insufficiently expressive residue\nrepresentations. To address this issue, we introduce a span mask pre-training\nstrategy on 3D protein chains to learn meaningful representations of both\nresidues and atoms. This leads to a simple yet effective approach to learning\nprotein representation suitable for diverse downstream tasks. Extensive\nexperimental results on binding site prediction and function prediction tasks\ndemonstrate our proposed pre-training approach significantly outperforms other\nmethods. Our code will be made public.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01481v4",
    "published_date": "2024-02-02 15:07:09 UTC",
    "updated_date": "2024-06-02 23:17:38 UTC"
  },
  {
    "arxiv_id": "2402.01476v2",
    "title": "Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes",
    "authors": [
      "Yingyi Chen",
      "Qinghua Tao",
      "Francesco Tonin",
      "Johan A. K. Suykens"
    ],
    "abstract": "While the great capability of Transformers significantly boosts prediction\naccuracy, it could also yield overconfident predictions and require calibrated\nuncertainty estimation, which can be commonly tackled by Gaussian processes\n(GPs). Existing works apply GPs with symmetric kernels under variational\ninference to the attention kernel; however, omitting the fact that attention\nkernels are in essence asymmetric. Moreover, the complexity of deriving the GP\nposteriors remains high for large-scale data. In this work, we propose\nKernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for building\nuncertainty-aware self-attention where the asymmetry of attention kernels is\ntackled by Kernel SVD (KSVD) and a reduced complexity is acquired. Through\nKEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors from\nKSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) using\nonly a small set of adjoint eigenfunctions from KSVD, the derivation of SVGP\nposteriors can be based on the inversion of a diagonal matrix containing\nsingular values, contributing to a reduction in time complexity; iii) an\nevidence lower bound is derived so that variational parameters and network\nweights can be optimized with it. Experiments verify our excellent performances\nand efficiency on in-distribution, distribution-shift and out-of-distribution\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "We propose Kernel-Eigen Pair Sparse Variational Gaussian Processes\n  (KEP-SVGP) for building uncertainty-aware self-attention where the asymmetry\n  of attention kernel is tackled by KSVD and a reduced time complexity is\n  acquired",
    "pdf_url": "http://arxiv.org/pdf/2402.01476v2",
    "published_date": "2024-02-02 15:05:13 UTC",
    "updated_date": "2024-05-28 09:13:19 UTC"
  },
  {
    "arxiv_id": "2402.01467v2",
    "title": "Brain-Like Replay Naturally Emerges in Reinforcement Learning Agents",
    "authors": [
      "Jiyi Wang",
      "Likai Tang",
      "Huimiao Chen",
      "Marcelo G Mattar",
      "Sen Song"
    ],
    "abstract": "Replay is a powerful strategy to promote learning in artificial intelligence\nand the brain. However, the conditions to generate it and its functional\nadvantages have not been fully recognized. In this study, we develop a modular\nreinforcement learning model that could generate replay. We prove that replay\ngenerated in this way helps complete the task. We also analyze the information\ncontained in the representation and provide a mechanism for how replay makes a\ndifference. Our design avoids complex assumptions and enables replay to emerge\nnaturally within a task-optimized paradigm. Our model also reproduces key\nphenomena observed in biological agents. This research explores the structural\nbiases in modular ANN to generate replay and its potential utility in\ndeveloping efficient RL.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.CE",
      "cs.NE",
      "cs.SY",
      "q-bio.NC"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01467v2",
    "published_date": "2024-02-02 14:55:51 UTC",
    "updated_date": "2024-10-06 21:37:54 UTC"
  },
  {
    "arxiv_id": "2402.01454v5",
    "title": "Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach",
    "authors": [
      "Masayuki Takayama",
      "Tadahisa Okuda",
      "Thong Pham",
      "Tatsuyoshi Ikenoue",
      "Shingo Fukuma",
      "Shohei Shimizu",
      "Akiyoshi Sannai"
    ],
    "abstract": "In practical statistical causal discovery (SCD), embedding domain expert\nknowledge as constraints into the algorithm is important for reasonable causal\nmodels reflecting the broad knowledge of domain experts, despite the challenges\nin the systematic acquisition of background knowledge. To overcome these\nchallenges, this paper proposes a novel method for causal inference, in which\nSCD and knowledge-based causal inference (KBCI) with a large language model\n(LLM) are synthesized through ``statistical causal prompting (SCP)'' for LLMs\nand prior knowledge augmentation for SCD. The experiments in this work have\nrevealed that the results of LLM-KBCI and SCD augmented with LLM-KBCI approach\nthe ground truths, more than the SCD result without prior knowledge. These\nexperiments have also revealed that the SCD result can be further improved if\nthe LLM undergoes SCP. Furthermore, with an unpublished real-world dataset, we\nhave demonstrated that the background knowledge provided by the LLM can improve\nthe SCD on this dataset, even if this dataset has never been included in the\ntraining data of the LLM. For future practical application of this proposed\nmethod across important domains such as healthcare, we also thoroughly discuss\nthe limitations, risks of critical errors, expected improvement of techniques\naround LLMs, and realistic integration of expert checks of the results into\nthis automatic process, with SCP simulations under various conditions both in\nsuccessful and failure scenarios. The careful and appropriate application of\nthe proposed approach in this work, with improvement and customization for each\ndomain, can thus address challenges such as dataset biases and limitations,\nillustrating the potential of LLMs to improve data-driven causal inference\nacross diverse scientific domains.\n  The code used in this work is publicly available at:\nwww.github.com/mas-takayama/LLM-and-SCD",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01454v5",
    "published_date": "2024-02-02 14:43:19 UTC",
    "updated_date": "2025-05-11 11:11:03 UTC"
  },
  {
    "arxiv_id": "2402.01817v3",
    "title": "LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks",
    "authors": [
      "Subbarao Kambhampati",
      "Karthik Valmeekam",
      "Lin Guan",
      "Mudit Verma",
      "Kaya Stechly",
      "Siddhant Bhambri",
      "Lucas Saldyt",
      "Anil Murthy"
    ],
    "abstract": "There is considerable confusion about the role of Large Language Models\n(LLMs) in planning and reasoning tasks. On one side are over-optimistic claims\nthat LLMs can indeed do these tasks with just the right prompting or\nself-verification strategies. On the other side are perhaps over-pessimistic\nclaims that all that LLMs are good for in planning/reasoning tasks are as mere\ntranslators of the problem specification from one syntactic format to another,\nand ship the problem off to external symbolic solvers. In this position paper,\nwe take the view that both these extremes are misguided. We argue that\nauto-regressive LLMs cannot, by themselves, do planning or self-verification\n(which is after all a form of reasoning), and shed some light on the reasons\nfor misunderstandings in the literature. We will also argue that LLMs should be\nviewed as universal approximate knowledge sources that have much more\nmeaningful roles to play in planning/reasoning tasks beyond simple\nfront-end/back-end format translators. We present a vision of {\\bf LLM-Modulo\nFrameworks} that combine the strengths of LLMs with external model-based\nverifiers in a tighter bi-directional interaction regime. We will show how the\nmodels driving the external verifiers themselves can be acquired with the help\nof LLMs. We will also argue that rather than simply pipelining LLMs and\nsymbolic components, this LLM-Modulo Framework provides a better neuro-symbolic\napproach that offers tighter integration between LLMs and symbolic components,\nand allows extending the scope of model-based planning/reasoning regimes\ntowards more flexible knowledge, problem and preference specifications.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01817v3",
    "published_date": "2024-02-02 14:43:18 UTC",
    "updated_date": "2024-06-12 01:13:11 UTC"
  },
  {
    "arxiv_id": "2402.01446v2",
    "title": "Guidance Graph Optimization for Lifelong Multi-Agent Path Finding",
    "authors": [
      "Yulun Zhang",
      "He Jiang",
      "Varun Bhatt",
      "Stefanos Nikolaidis",
      "Jiaoyang Li"
    ],
    "abstract": "We study how to use guidance to improve the throughput of lifelong\nMulti-Agent Path Finding (MAPF). Previous studies have demonstrated that, while\nincorporating guidance, such as highways, can accelerate MAPF algorithms, this\noften results in a trade-off with solution quality. In addition, how to\ngenerate good guidance automatically remains largely unexplored, with current\nmethods falling short of surpassing manually designed ones. In this work, we\nintroduce the guidance graph as a versatile representation of guidance for\nlifelong MAPF, framing Guidance Graph Optimization as the task of optimizing\nits edge weights. We present two GGO algorithms to automatically generate\nguidance for arbitrary lifelong MAPF algorithms and maps. The first method\ndirectly optimizes edge weights, while the second method optimizes an update\nmodel capable of generating edge weights. Empirically, we show that (1) our\nguidance graphs improve the throughput of three representative lifelong MAPF\nalgorithms in eight benchmark maps, and (2) our update model can generate\nguidance graphs for as large as $93 \\times 91$ maps and as many as 3,000\nagents. We include the source code at:\n\\url{https://github.com/lunjohnzhang/ggo_public}. All optimized guidance graphs\nare available online at: \\url{https://yulunzhang.net/publication/zhang2024ggo}.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCAI), 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01446v2",
    "published_date": "2024-02-02 14:38:04 UTC",
    "updated_date": "2024-05-09 19:14:12 UTC"
  },
  {
    "arxiv_id": "2402.01444v1",
    "title": "Mission Critical -- Satellite Data is a Distinct Modality in Machine Learning",
    "authors": [
      "Esther Rolf",
      "Konstantin Klemmer",
      "Caleb Robinson",
      "Hannah Kerner"
    ],
    "abstract": "Satellite data has the potential to inspire a seismic shift for machine\nlearning -- one in which we rethink existing practices designed for traditional\ndata modalities. As machine learning for satellite data (SatML) gains traction\nfor its real-world impact, our field is at a crossroads. We can either continue\napplying ill-suited approaches, or we can initiate a new research agenda that\ncenters around the unique characteristics and challenges of satellite data.\nThis position paper argues that satellite data constitutes a distinct modality\nfor machine learning research and that we must recognize it as such to advance\nthe quality and impact of SatML research across theory, methods, and\ndeployment. We outline critical discussion questions and actionable suggestions\nto transform SatML from merely an intriguing application area to a dedicated\nresearch discipline that helps move the needle on big challenges for machine\nlearning and society.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01444v1",
    "published_date": "2024-02-02 14:36:50 UTC",
    "updated_date": "2024-02-02 14:36:50 UTC"
  },
  {
    "arxiv_id": "2402.01440v4",
    "title": "A Survey of Few-Shot Learning on Graphs: from Meta-Learning to Pre-Training and Prompt Learning",
    "authors": [
      "Xingtong Yu",
      "Yuan Fang",
      "Zemin Liu",
      "Yuxia Wu",
      "Zhihao Wen",
      "Jianyuan Bo",
      "Xinming Zhang",
      "Steven C. H. Hoi"
    ],
    "abstract": "Graph representation learning, a critical step in graph-centric tasks, has\nseen significant advancements. Earlier techniques often operate in an\nend-to-end setting, which heavily rely on the availability of ample labeled\ndata. This constraint has spurred the emergence of few-shot learning on graphs,\nwhere only a few labels are available for each task. Given the extensive\nliterature in this field, this survey endeavors to synthesize recent\ndevelopments, provide comparative insights, and identify future directions. We\nsystematically categorize existing studies based on two major taxonomies: (1)\nProblem taxonomy, which explores different types of data scarcity problems and\ntheir applications, and (2) Technique taxonomy, which details key strategies\nfor addressing these data-scarce few-shot problems. The techniques can be\nbroadly categorized into meta-learning, pre-training, and hybrid approaches,\nwith a finer-grained classification in each category to aid readers in their\nmethod selection process. Within each category, we analyze the relationships\namong these methods and compare their strengths and limitations. Finally, we\noutline prospective directions for few-shot learning on graphs to catalyze\ncontinued innovation in this field. The website for this survey can be accessed\nby \\url{https://github.com/smufang/fewshotgraph}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01440v4",
    "published_date": "2024-02-02 14:32:42 UTC",
    "updated_date": "2024-09-20 05:27:29 UTC"
  },
  {
    "arxiv_id": "2402.01439v1",
    "title": "From Words to Molecules: A Survey of Large Language Models in Chemistry",
    "authors": [
      "Chang Liao",
      "Yemin Yu",
      "Yu Mei",
      "Ying Wei"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have achieved significant\nsuccess in natural language processing (NLP) and various interdisciplinary\nareas. However, applying LLMs to chemistry is a complex task that requires\nspecialized domain knowledge. This paper provides a thorough exploration of the\nnuanced methodologies employed in integrating LLMs into the field of chemistry,\ndelving into the complexities and innovations at this interdisciplinary\njuncture. Specifically, our analysis begins with examining how molecular\ninformation is fed into LLMs through various representation and tokenization\nmethods. We then categorize chemical LLMs into three distinct groups based on\nthe domain and modality of their input data, and discuss approaches for\nintegrating these inputs for LLMs. Furthermore, this paper delves into the\npretraining objectives with adaptations to chemical LLMs. After that, we\nexplore the diverse applications of LLMs in chemistry, including novel\nparadigms for their application in chemistry tasks. Finally, we identify\npromising research directions, including further integration with chemical\nknowledge, advancements in continual learning, and improvements in model\ninterpretability, paving the way for groundbreaking developments in the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to IJCAI 2024 survey track",
    "pdf_url": "http://arxiv.org/pdf/2402.01439v1",
    "published_date": "2024-02-02 14:30:48 UTC",
    "updated_date": "2024-02-02 14:30:48 UTC"
  },
  {
    "arxiv_id": "2402.01416v1",
    "title": "Sequence Shortening for Context-Aware Machine Translation",
    "authors": [
      "Paweł Mąka",
      "Yusuf Can Semerci",
      "Jan Scholtes",
      "Gerasimos Spanakis"
    ],
    "abstract": "Context-aware Machine Translation aims to improve translations of sentences\nby incorporating surrounding sentences as context. Towards this task, two main\narchitectures have been applied, namely single-encoder (based on concatenation)\nand multi-encoder models. In this study, we show that a special case of\nmulti-encoder architecture, where the latent representation of the source\nsentence is cached and reused as the context in the next step, achieves higher\naccuracy on the contrastive datasets (where the models have to rank the correct\ntranslation among the provided sentences) and comparable BLEU and COMET scores\nas the single- and multi-encoder approaches. Furthermore, we investigate the\napplication of Sequence Shortening to the cached representations. We test three\npooling-based shortening techniques and introduce two novel methods - Latent\nGrouping and Latent Selecting, where the network learns to group tokens or\nselects the tokens to be cached as context. Our experiments show that the two\nmethods achieve competitive BLEU and COMET scores and accuracies on the\ncontrastive datasets to the other tested methods while potentially allowing for\nhigher interpretability and reducing the growth of memory requirements with\nincreased context size.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of the ACL: EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01416v1",
    "published_date": "2024-02-02 13:55:37 UTC",
    "updated_date": "2024-02-02 13:55:37 UTC"
  },
  {
    "arxiv_id": "2402.01415v1",
    "title": "SMLP: Symbolic Machine Learning Prover",
    "authors": [
      "Franz Brauße",
      "Zurab Khasidashvili",
      "Konstantin Korovin"
    ],
    "abstract": "Symbolic Machine Learning Prover (SMLP) is a tool and a library for system\nexploration based on data samples obtained by simulating or executing the\nsystem on a number of input vectors. SMLP aims at exploring the system based on\nthis data by taking a grey-box approach: SMLP combines statistical methods of\ndata exploration with building and exploring machine learning models in close\nfeedback loop with the system's response, and exploring these models by\ncombining probabilistic and formal methods. SMLP has been applied in industrial\nsetting at Intel for analyzing and optimizing hardware designs at the analog\nlevel. SMLP is a general purpose tool and can be applied to systems that can be\nsampled and modeled by machine learning models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SC",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 4 figures. (submitted)",
    "pdf_url": "http://arxiv.org/pdf/2402.01415v1",
    "published_date": "2024-02-02 13:53:29 UTC",
    "updated_date": "2024-02-02 13:53:29 UTC"
  },
  {
    "arxiv_id": "2402.01410v1",
    "title": "XAI for Skin Cancer Detection with Prototypes and Non-Expert Supervision",
    "authors": [
      "Miguel Correia",
      "Alceu Bissoto",
      "Carlos Santiago",
      "Catarina Barata"
    ],
    "abstract": "Skin cancer detection through dermoscopy image analysis is a critical task.\nHowever, existing models used for this purpose often lack interpretability and\nreliability, raising the concern of physicians due to their black-box nature.\nIn this paper, we propose a novel approach for the diagnosis of melanoma using\nan interpretable prototypical-part model. We introduce a guided supervision\nbased on non-expert feedback through the incorporation of: 1) binary masks,\nobtained automatically using a segmentation network; and 2) user-refined\nprototypes. These two distinct information pathways aim to ensure that the\nlearned prototypes correspond to relevant areas within the skin lesion,\nexcluding confounding factors beyond its boundaries. Experimental results\ndemonstrate that, even without expert supervision, our approach achieves\nsuperior performance and generalization compared to non-interpretable models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in the iMIMIC Workshop @ MICCAI 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.01410v1",
    "published_date": "2024-02-02 13:42:45 UTC",
    "updated_date": "2024-02-02 13:42:45 UTC"
  },
  {
    "arxiv_id": "2402.01408v3",
    "title": "Counterfactual Concept Bottleneck Models",
    "authors": [
      "Gabriele Dominici",
      "Pietro Barbiero",
      "Francesco Giannini",
      "Martin Gjoreski",
      "Giuseppe Marra",
      "Marc Langheinrich"
    ],
    "abstract": "Current deep learning models are not designed to simultaneously address three\nfundamental questions: predict class labels to solve a given classification\ntask (the \"What?\"), simulate changes in the situation to evaluate how this\nimpacts class predictions (the \"How?\"), and imagine how the scenario should\nchange to result in different class predictions (the \"Why not?\"). The inability\nto answer these questions represents a crucial gap in deploying reliable AI\nagents, calibrating human trust, and improving human-machine interaction. To\nbridge this gap, we introduce CounterFactual Concept Bottleneck Models\n(CF-CBMs), a class of models designed to efficiently address the above queries\nall at once without the need to run post-hoc searches. Our experimental results\ndemonstrate that CF-CBMs: achieve classification accuracy comparable to\nblack-box models and existing CBMs (\"What?\"), rely on fewer important concepts\nleading to simpler explanations (\"How?\"), and produce interpretable,\nconcept-based counterfactuals (\"Why not?\"). Additionally, we show that training\nthe counterfactual generator jointly with the CBM leads to two key\nimprovements: (i) it alters the model's decision-making process, making the\nmodel rely on fewer important concepts (leading to simpler explanations), and\n(ii) it significantly increases the causal effect of concept interventions on\nclass predictions, making the model more responsive to these changes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01408v3",
    "published_date": "2024-02-02 13:42:12 UTC",
    "updated_date": "2025-02-20 12:07:41 UTC"
  },
  {
    "arxiv_id": "2402.01401v4",
    "title": "An Information Theoretic Approach to Machine Unlearning",
    "authors": [
      "Jack Foster",
      "Kyle Fogarty",
      "Stefan Schoepf",
      "Zack Dugue",
      "Cengiz Öztireli",
      "Alexandra Brintrup"
    ],
    "abstract": "To comply with AI and data regulations, the need to forget private or\ncopyrighted information from trained machine learning models is increasingly\nimportant. The key challenge in unlearning is forgetting the necessary data in\na timely manner, while preserving model performance. In this work, we address\nthe zero-shot unlearning scenario, whereby an unlearning algorithm must be able\nto remove data given only a trained model and the data to be forgotten. We\nexplore unlearning from an information theoretic perspective, connecting the\ninfluence of a sample to the information gain a model receives by observing it.\nFrom this, we derive a simple but principled zero-shot unlearning method based\non the geometry of the model. Our approach takes the form of minimising the\ngradient of a learned function with respect to a small neighbourhood around a\ntarget forget point. This induces a smoothing effect, causing forgetting by\nmoving the boundary of the classifier. We explore the intuition behind why this\napproach can jointly unlearn forget samples while preserving general model\nperformance through a series of low-dimensional experiments. We perform\nextensive empirical evaluation of our method over a range of contemporary\nbenchmarks, verifying that our method is competitive with state-of-the-art\nperformance under the strict constraints of zero-shot unlearning. Code for the\nproject can be found at\nhttps://github.com/jwf40/Information-Theoretic-Unlearning",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Updated, new low-dimensional experiments and updated perspective on\n  unlearning from an information theoretic view",
    "pdf_url": "http://arxiv.org/pdf/2402.01401v4",
    "published_date": "2024-02-02 13:33:30 UTC",
    "updated_date": "2024-12-02 00:03:53 UTC"
  },
  {
    "arxiv_id": "2402.01399v3",
    "title": "A Probabilistic Model Behind Self-Supervised Learning",
    "authors": [
      "Alice Bizeul",
      "Bernhard Schölkopf",
      "Carl Allen"
    ],
    "abstract": "In self-supervised learning (SSL), representations are learned via an\nauxiliary task without annotated labels. A common task is to classify\naugmentations or different modalities of the data, which share semantic content\n(e.g. an object in an image) but differ in style (e.g. the object's location).\nMany approaches to self-supervised learning have been proposed, e.g. SimCLR,\nCLIP, and DINO, which have recently gained much attention for their\nrepresentations achieving downstream performance comparable to supervised\nlearning. However, a theoretical understanding of self-supervised methods\neludes. Addressing this, we present a generative latent variable model for\nself-supervised learning and show that several families of discriminative SSL,\nincluding contrastive methods, induce a comparable distribution over\nrepresentations, providing a unifying theoretical framework for these methods.\nThe proposed model also justifies connections drawn to mutual information and\nthe use of a ''projection head''. Learning representations by fitting the model\ngeneratively (termed SimVAE) improves performance over discriminative and other\nVAE-based methods on simple image benchmarks and significantly narrows the gap\nbetween generative and discriminative representation learning in more complex\nsettings. Importantly, as our analysis predicts, SimVAE outperforms\nself-supervised learning where style information is required, taking an\nimportant step toward understanding self-supervised methods and achieving\ntask-agnostic representations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01399v3",
    "published_date": "2024-02-02 13:31:17 UTC",
    "updated_date": "2024-10-15 13:16:13 UTC"
  },
  {
    "arxiv_id": "2402.01812v1",
    "title": "Distilling LLMs' Decomposition Abilities into Compact Language Models",
    "authors": [
      "Denis Tarasov",
      "Kumar Shridhar"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated proficiency in their reasoning\nabilities, yet their large size presents scalability challenges and limits any\nfurther customization. In contrast, compact models offer customized training\nbut often fall short in solving complex reasoning tasks. This study focuses on\ndistilling the LLMs' decomposition skills into compact models using offline\nreinforcement learning. We leverage the advancements in the LLM`s capabilities\nto provide feedback and generate a specialized task-specific dataset for\ntraining compact models. The development of an AI-generated dataset and the\nestablishment of baselines constitute the primary contributions of our work,\nunderscoring the potential of compact models in replicating complex\nproblem-solving skills.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "https://github.com/DT6A/GSM8K-AI-SubQ",
    "pdf_url": "http://arxiv.org/pdf/2402.01812v1",
    "published_date": "2024-02-02 13:23:15 UTC",
    "updated_date": "2024-02-02 13:23:15 UTC"
  },
  {
    "arxiv_id": "2402.01376v2",
    "title": "LoTR: Low Tensor Rank Weight Adaptation",
    "authors": [
      "Daniel Bershatsky",
      "Daria Cherniuk",
      "Talgat Daulbaev",
      "Aleksandr Mikhalev",
      "Ivan Oseledets"
    ],
    "abstract": "In this paper we generalize and extend an idea of low-rank adaptation (LoRA)\nof large language models (LLMs) based on Transformer architecture. Widely used\nLoRA-like methods of fine-tuning LLMs are based on matrix factorization of\ngradient update. We introduce LoTR, a novel approach for parameter-efficient\nfine-tuning of LLMs which represents a gradient update to parameters in a form\nof tensor decomposition. Low-rank adapter for each layer is constructed as a\nproduct of three matrices, and tensor structure arises from sharing left and\nright multipliers of this product among layers. Simultaneous compression of a\nsequence of layers with low-rank tensor representation allows LoTR to archive\neven better parameter efficiency then LoRA especially for deep models.\nMoreover, the core tensor does not depend on original weight dimension and can\nbe made arbitrary small, which allows for extremely cheap and fast downstream\nfine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted; missing author and sections were added;",
    "pdf_url": "http://arxiv.org/pdf/2402.01376v2",
    "published_date": "2024-02-02 13:00:38 UTC",
    "updated_date": "2024-02-05 12:42:52 UTC"
  },
  {
    "arxiv_id": "2403.07887v4",
    "title": "Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations",
    "authors": [
      "Bhishma Dedhia",
      "Niraj K. Jha"
    ],
    "abstract": "Several accounts of human cognition posit that our intelligence is rooted in\nour ability to form abstract composable concepts, ground them in our\nenvironment, and reason over these grounded entities. This trifecta of human\nthought has remained elusive in modern intelligent machines. In this work, we\ninvestigate whether slot representations extracted from visual scenes serve as\nappropriate compositional abstractions for grounding and reasoning. We present\nthe Neural Slot Interpreter (NSI), which learns to ground object semantics in\nslots. At the core of NSI is a nested schema that uses simple syntax rules to\norganize the object semantics of a scene into object-centric schema primitives.\nThen, the NSI metric learns to ground primitives into slots through a\nstructured contrastive learning objective that reasons over the intermodal\nalignment. Experiments with a bi-modal object-property and scene retrieval task\ndemonstrate the grounding efficacy and interpretability of correspondences\nlearned by NSI. From a scene representation standpoint, we find that emergent\nNSI slots that move beyond the image grid by binding to spatial objects\nfacilitate improved visual grounding compared to conventional\nbounding-box-based approaches. From a data efficiency standpoint, we\nempirically validate that NSI learns more generalizable representations from a\nfixed amount of annotation data than the traditional approach. We also show\nthat the grounded slots surpass unsupervised slots in real-world object\ndiscovery and scale with scene complexity. Finally, we investigate the\ndownstream efficacy of the grounded slots. Vision Transformers trained on\ngrounding-aware NSI tokenizers using as few as ten tokens outperform\npatch-based tokens on challenging few-shot classification tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07887v4",
    "published_date": "2024-02-02 12:37:23 UTC",
    "updated_date": "2025-05-09 00:19:39 UTC"
  },
  {
    "arxiv_id": "2402.01355v2",
    "title": "FindingEmo: An Image Dataset for Emotion Recognition in the Wild",
    "authors": [
      "Laurent Mertens",
      "Elahe' Yargholi",
      "Hans Op de Beeck",
      "Jan Van den Stock",
      "Joost Vennekens"
    ],
    "abstract": "We introduce FindingEmo, a new image dataset containing annotations for 25k\nimages, specifically tailored to Emotion Recognition. Contrary to existing\ndatasets, it focuses on complex scenes depicting multiple people in various\nnaturalistic, social settings, with images being annotated as a whole, thereby\ngoing beyond the traditional focus on faces or single individuals. Annotated\ndimensions include Valence, Arousal and Emotion label, with annotations\ngathered using Prolific. Together with the annotations, we release the list of\nURLs pointing to the original images, as well as all associated source code.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "33 pages, 21 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.01355v2",
    "published_date": "2024-02-02 12:22:41 UTC",
    "updated_date": "2024-06-05 13:42:25 UTC"
  },
  {
    "arxiv_id": "2402.06647v1",
    "title": "A Survey on Large Language Model Hallucination via a Creativity Perspective",
    "authors": [
      "Xuhui Jiang",
      "Yuxing Tian",
      "Fengrui Hua",
      "Chengjin Xu",
      "Yuanzhuo Wang",
      "Jian Guo"
    ],
    "abstract": "Hallucinations in large language models (LLMs) are always seen as\nlimitations. However, could they also be a source of creativity? This survey\nexplores this possibility, suggesting that hallucinations may contribute to LLM\napplication by fostering creativity. This survey begins with a review of the\ntaxonomy of hallucinations and their negative impact on LLM reliability in\ncritical applications. Then, through historical examples and recent relevant\ntheories, the survey explores the potential creative benefits of hallucinations\nin LLMs. To elucidate the value and evaluation criteria of this connection, we\ndelve into the definitions and assessment methods of creativity. Following the\nframework of divergent and convergent thinking phases, the survey\nsystematically reviews the literature on transforming and harnessing\nhallucinations for creativity in LLMs. Finally, the survey discusses future\nresearch directions, emphasizing the need to further explore and refine the\napplication of hallucinations in creative processes within LLMs.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.06647v1",
    "published_date": "2024-02-02 12:21:04 UTC",
    "updated_date": "2024-02-02 12:21:04 UTC"
  },
  {
    "arxiv_id": "2402.01352v1",
    "title": "Describing Images $\\textit{Fast and Slow}$: Quantifying and Predicting the Variation in Human Signals during Visuo-Linguistic Processes",
    "authors": [
      "Ece Takmaz",
      "Sandro Pezzelle",
      "Raquel Fernández"
    ],
    "abstract": "There is an intricate relation between the properties of an image and how\nhumans behave while describing the image. This behavior shows ample variation,\nas manifested in human signals such as eye movements and when humans start to\ndescribe the image. Despite the value of such signals of visuo-linguistic\nvariation, they are virtually disregarded in the training of current pretrained\nmodels, which motivates further investigation. Using a corpus of Dutch image\ndescriptions with concurrently collected eye-tracking data, we explore the\nnature of the variation in visuo-linguistic signals, and find that they\ncorrelate with each other. Given this result, we hypothesize that variation\nstems partly from the properties of the images, and explore whether image\nrepresentations encoded by pretrained vision encoders can capture such\nvariation. Our results indicate that pretrained models do so to a\nweak-to-moderate degree, suggesting that the models lack biases about what\nmakes a stimulus complex for humans and what leads to variations in human\noutputs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01352v1",
    "published_date": "2024-02-02 12:11:16 UTC",
    "updated_date": "2024-02-02 12:11:16 UTC"
  },
  {
    "arxiv_id": "2402.01349v3",
    "title": "LLMs May Perform MCQA by Selecting the Least Incorrect Option",
    "authors": [
      "Haochun Wang",
      "Sendong Zhao",
      "Zewen Qiang",
      "Nuwa Xi",
      "Bing Qin",
      "Ting Liu"
    ],
    "abstract": "In the field of NLP, Large Language Models (LLMs) have markedly enhanced\nperformance across a variety of tasks. However, the comprehensive evaluation of\nLLMs remains an inevitable challenge for the community. Recently, the adoption\nof Multiple Choice Question Answering (MCQA) as a benchmark for assessing LLMs\nhas gained considerable traction. However, concerns regarding the robustness of\nthis evaluative method persist. Building upon previous discussions on the issue\nof \\textit{variability}, we reveal an additional dimension of concern: LLMs may\nperform MCQA by selecting the least incorrect option rather than distinctly\ncorrect. This observation suggests that LLMs might regard multiple options as\ncorrect, which could undermine the reliability of MCQA as a metric for\nevaluating LLMs. To address this challenge, we introduce an enhanced dataset\naugmentation method for MCQA, termed MCQA+, to provide a more accurate\nreflection of the model performance, thereby highlighting the necessity for\nmore sophisticated evaluation mechanisms in the assessment of LLM capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.01349v3",
    "published_date": "2024-02-02 12:07:00 UTC",
    "updated_date": "2024-12-06 11:54:40 UTC"
  },
  {
    "arxiv_id": "2402.01348v2",
    "title": "CORE: Mitigating Catastrophic Forgetting in Continual Learning through Cognitive Replay",
    "authors": [
      "Jianshu Zhang",
      "Yankai Fu",
      "Ziheng Peng",
      "Dongyu Yao",
      "Kun He"
    ],
    "abstract": "This paper introduces a novel perspective to significantly mitigate\ncatastrophic forgetting in continuous learning (CL), which emphasizes models'\ncapacity to preserve existing knowledge and assimilate new information. Current\nreplay-based methods treat every task and data sample equally and thus can not\nfully exploit the potential of the replay buffer. In response, we propose\nCOgnitive REplay (CORE), which draws inspiration from human cognitive review\nprocesses. CORE includes two key strategies: Adaptive Quantity Allocation and\nQuality-Focused Data Selection. The former adaptively modulates the replay\nbuffer allocation for each task based on its forgetting rate, while the latter\nguarantees the inclusion of representative data that best encapsulates the\ncharacteristics of each task within the buffer. Our approach achieves an\naverage accuracy of 37.95% on split-CIFAR10, surpassing the best baseline\nmethod by 6.52%. Additionally, it significantly enhances the accuracy of the\npoorest-performing task by 6.30% compared to the top baseline. Code is\navailable at https://github.com/sterzhang/CORE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CogSci24 as oral presentation",
    "pdf_url": "http://arxiv.org/pdf/2402.01348v2",
    "published_date": "2024-02-02 12:04:44 UTC",
    "updated_date": "2024-04-09 08:33:22 UTC"
  },
  {
    "arxiv_id": "2402.01345v6",
    "title": "Skip \\n: A Simple Method to Reduce Hallucination in Large Vision-Language Models",
    "authors": [
      "Zongbo Han",
      "Zechen Bai",
      "Haiyang Mei",
      "Qianli Xu",
      "Changqing Zhang",
      "Mike Zheng Shou"
    ],
    "abstract": "Recent advancements in large vision-language models (LVLMs) have demonstrated\nimpressive capability in visual information understanding with human language.\nDespite these advances, LVLMs still face challenges with multimodal\nhallucination, such as generating text descriptions of objects that are not\npresent in the visual information. However, the underlying fundamental reasons\nof multimodal hallucinations remain poorly explored. In this paper, we propose\na new perspective, suggesting that the inherent biases in LVLMs might be a key\nfactor in hallucinations. Specifically, we systematically identify a semantic\nshift bias related to paragraph breaks (\\n\\n), where the content before and\nafter '\\n\\n' in the training data frequently exhibit significant semantic\nchanges. This pattern leads the model to infer that the contents following\n'\\n\\n' should be obviously different from the preceding contents with less\nhallucinatory descriptions, thereby increasing the probability of hallucinatory\ndescriptions subsequent to the '\\n\\n'. We have validated this hypothesis on\nmultiple publicly available LVLMs. Besides, we find that deliberately inserting\n'\\n\\n' at the generated description can induce more hallucinations. A simple\nmethod is proposed to effectively mitigate the hallucination of LVLMs by\nskipping the output of '\\n'.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01345v6",
    "published_date": "2024-02-02 12:02:46 UTC",
    "updated_date": "2024-05-08 02:15:45 UTC"
  },
  {
    "arxiv_id": "2402.03469v3",
    "title": "Rethinking the Role of Proxy Rewards in Language Model Alignment",
    "authors": [
      "Sungdong Kim",
      "Minjoon Seo"
    ],
    "abstract": "Learning from human feedback via proxy reward modeling has been studied to\nalign Large Language Models (LLMs) with human values. However, achieving\nreliable training through that proxy reward model (RM) is not a trivial\nproblem, and its behavior remained as a black-box. In this paper, we study the\nrole of proxy rewards in the LLM alignment via `reverse reward engineering' by\ncomposing interpretable features as a white-box reward function. We aim to\nreplicate the ground truth (gold) reward signal by achieving a monotonic\nrelationship between the proxy and gold reward signals after training the model\nusing the proxy reward in reinforcement learning (RL). Our findings indicate\nthat successfully emulating the gold reward requires generating responses that\nare relevant with enough length to open-ended questions, while also ensuring\nresponse consistency in closed-ended questions. Furthermore, resulting models\noptimizing our devised white-box reward show competitive performances with\nstrong open-source RMs in alignment benchmarks. We highlight its potential\nusage as a simple but strong reward baseline for the LLM alignment, not\nrequiring explicit human feedback dataset and RM training. Our code is\navailable at https://github.com/naver-ai/rethinking-proxy-reward.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to EMNLP 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2402.03469v3",
    "published_date": "2024-02-02 11:58:08 UTC",
    "updated_date": "2024-10-06 13:21:32 UTC"
  },
  {
    "arxiv_id": "2402.01335v3",
    "title": "BehAVE: Behaviour Alignment of Video Game Encodings",
    "authors": [
      "Nemanja Rašajski",
      "Chintan Trivedi",
      "Konstantinos Makantasis",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "abstract": "Domain randomisation enhances the transferability of vision models across\nvisually distinct domains with similar content. However, current methods\nheavily depend on intricate simulation engines, hampering feasibility and\nscalability. This paper introduces BehAVE, a video understanding framework that\nutilises existing commercial video games for domain randomisation without\naccessing their simulation engines. BehAVE taps into the visual diversity of\nvideo games for randomisation and uses textual descriptions of player actions\nto align videos with similar content. We evaluate BehAVE across 25 first-person\nshooter (FPS) games using various video and text foundation models,\ndemonstrating its robustness in domain randomisation. BehAVE effectively aligns\nplayer behavioural patterns and achieves zero-shot transfer to multiple unseen\nFPS games when trained on just one game. In a more challenging scenario, BehAVE\nenhances the zero-shot transferability of foundation models to unseen FPS\ngames, even when trained on a game of a different genre, with improvements of\nup to 22%. BehAVE is available online at https://github.com/nrasajski/BehAVE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01335v3",
    "published_date": "2024-02-02 11:40:27 UTC",
    "updated_date": "2024-11-01 16:51:01 UTC"
  },
  {
    "arxiv_id": "2402.01327v3",
    "title": "Supervised Algorithmic Fairness in Distribution Shifts: A Survey",
    "authors": [
      "Minglai Shao",
      "Dong Li",
      "Chen Zhao",
      "Xintao Wu",
      "Yujie Lin",
      "Qin Tian"
    ],
    "abstract": "Supervised fairness-aware machine learning under distribution shifts is an\nemerging field that addresses the challenge of maintaining equitable and\nunbiased predictions when faced with changes in data distributions from source\nto target domains. In real-world applications, machine learning models are\noften trained on a specific dataset but deployed in environments where the data\ndistribution may shift over time due to various factors. This shift can lead to\nunfair predictions, disproportionately affecting certain groups characterized\nby sensitive attributes, such as race and gender. In this survey, we provide a\nsummary of various types of distribution shifts and comprehensively investigate\nexisting methods based on these shifts, highlighting six commonly used\napproaches in the literature. Additionally, this survey lists publicly\navailable datasets and evaluation metrics for empirical studies. We further\nexplore the interconnection with related research fields, discuss the\nsignificant challenges, and identify potential directions for future studies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01327v3",
    "published_date": "2024-02-02 11:26:18 UTC",
    "updated_date": "2024-05-05 01:01:03 UTC"
  },
  {
    "arxiv_id": "2402.01306v4",
    "title": "KTO: Model Alignment as Prospect Theoretic Optimization",
    "authors": [
      "Kawin Ethayarajh",
      "Winnie Xu",
      "Niklas Muennighoff",
      "Dan Jurafsky",
      "Douwe Kiela"
    ],
    "abstract": "Kahneman & Tversky's $\\textit{prospect theory}$ tells us that humans perceive\nrandom variables in a biased but well-defined manner (1992); for example,\nhumans are famously loss-averse. We show that objectives for aligning LLMs with\nhuman feedback implicitly incorporate many of these biases -- the success of\nthese objectives (e.g., DPO) over cross-entropy minimization can partly be\nascribed to them belonging to a family of loss functions that we call\n$\\textit{human-aware losses}$ (HALOs). However, the utility functions these\nmethods attribute to humans still differ from those in the prospect theory\nliterature. Using a Kahneman-Tversky model of human utility, we propose a HALO\nthat directly maximizes the utility of generations instead of maximizing the\nlog-likelihood of preferences, as current methods do. We call this approach\nKTO, and it matches or exceeds the performance of preference-based methods at\nscales from 1B to 30B, despite only learning from a binary signal of whether an\noutput is desirable. More broadly, our work suggests that there is no one HALO\nthat is universally superior; the best loss depends on the inductive biases\nmost appropriate for a given setting, an oft-overlooked consideration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01306v4",
    "published_date": "2024-02-02 10:53:36 UTC",
    "updated_date": "2024-11-19 18:12:45 UTC"
  },
  {
    "arxiv_id": "2402.01298v1",
    "title": "Learning Semantic Information from Raw Audio Signal Using Both Contextual and Phonetic Representations",
    "authors": [
      "Jaeyeon Kim",
      "Injune Hwang",
      "Kyogu Lee"
    ],
    "abstract": "We propose a framework to learn semantics from raw audio signals using two\ntypes of representations, encoding contextual and phonetic information\nrespectively. Specifically, we introduce a speech-to-unit processing pipeline\nthat captures two types of representations with different time resolutions. For\nthe language model, we adopt a dual-channel architecture to incorporate both\ntypes of representation. We also present new training objectives, masked\ncontext reconstruction and masked context prediction, that push models to learn\nsemantics effectively. Experiments on the sSIMI metric of Zero Resource Speech\nBenchmark 2021 and Fluent Speech Command dataset show our framework learns\nsemantics better than models trained with only one type of representation.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01298v1",
    "published_date": "2024-02-02 10:39:58 UTC",
    "updated_date": "2024-02-02 10:39:58 UTC"
  },
  {
    "arxiv_id": "2402.01295v4",
    "title": "ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast",
    "authors": [
      "Wanghan Xu",
      "Kang Chen",
      "Tao Han",
      "Hao Chen",
      "Wanli Ouyang",
      "Lei Bai"
    ],
    "abstract": "Data-driven weather forecast based on machine learning (ML) has experienced\nrapid development and demonstrated superior performance in the global\nmedium-range forecast compared to traditional physics-based dynamical models.\nHowever, most of these ML models struggle with accurately predicting extreme\nweather, which is related to training loss and the uncertainty of weather\nsystems. Through mathematical analysis, we prove that the use of symmetric\nlosses, such as the Mean Squared Error (MSE), leads to biased predictions and\nunderestimation of extreme values. To address this issue, we introduce Exloss,\na novel loss function that performs asymmetric optimization and highlights\nextreme values to obtain accurate extreme weather forecast. Beyond the\nevolution in training loss, we introduce a training-free extreme value\nenhancement module named ExBooster, which captures the uncertainty in\nprediction outcomes by employing multiple random samples, thereby increasing\nthe hit rate of low-probability extreme events. Combined with an advanced\nglobal weather forecast model, extensive experiments show that our solution can\nachieve state-of-the-art performance in extreme weather prediction, while\nmaintaining the overall forecast accuracy comparable to the top medium-range\nforecast models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01295v4",
    "published_date": "2024-02-02 10:34:13 UTC",
    "updated_date": "2024-08-16 09:26:37 UTC"
  },
  {
    "arxiv_id": "2402.01292v3",
    "title": "Towards the New XAI: A Hypothesis-Driven Approach to Decision Support Using Evidence",
    "authors": [
      "Thao Le",
      "Tim Miller",
      "Liz Sonenberg",
      "Ronal Singh"
    ],
    "abstract": "Prior research on AI-assisted human decision-making has explored several\ndifferent explainable AI (XAI) approaches. A recent paper has proposed a\nparadigm shift calling for hypothesis-driven XAI through a conceptual framework\ncalled evaluative AI that gives people evidence that supports or refutes\nhypotheses without necessarily giving a decision-aid recommendation. In this\npaper, we describe and evaluate an approach for hypothesis-driven XAI based on\nthe Weight of Evidence (WoE) framework, which generates both positive and\nnegative evidence for a given hypothesis. Through human behavioural\nexperiments, we show that our hypothesis-driven approach increases decision\naccuracy and reduces reliance compared to a recommendation-driven approach and\nan AI-explanation-only baseline, but with a small increase in under-reliance\ncompared to the recommendation-driven approach. Further, we show that\nparticipants used our hypothesis-driven approach in a materially different way\nto the two baselines.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "ECAI 2024 Main Track. The full paper version, including the\n  supplementary material",
    "pdf_url": "http://arxiv.org/pdf/2402.01292v3",
    "published_date": "2024-02-02 10:28:24 UTC",
    "updated_date": "2024-08-26 04:45:02 UTC"
  },
  {
    "arxiv_id": "2402.07919v1",
    "title": "How Can Generative AI Enhance the Well-being of Blind?",
    "authors": [
      "Oliver Bendel"
    ],
    "abstract": "This paper examines the question of how generative AI can improve the\nwell-being of blind or visually impaired people. It refers to a current\nexample, the Be My Eyes app, in which the Be My AI feature was integrated in\n2023, which is based on GPT-4 from OpenAI. The author's tests are described and\nevaluated. There is also an ethical and social discussion. The power of the\ntool, which can analyze still images in an amazing way, is demonstrated. Those\naffected gain a new independence and a new perception of their environment. At\nthe same time, they are dependent on the world view and morality of the\nprovider or developer, who prescribe or deny them certain descriptions. An\noutlook makes it clear that the analysis of moving images will mean a further\nleap forward. It is fair to say that generative AI can fundamentally improve\nthe well-being of blind and visually impaired people and will change it in\nvarious ways.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2; K.3"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.07919v1",
    "published_date": "2024-02-02 10:26:39 UTC",
    "updated_date": "2024-02-02 10:26:39 UTC"
  },
  {
    "arxiv_id": "2402.04275v1",
    "title": "Motion Mapping Cognition: A Nondecomposable Primary Process in Human Vision",
    "authors": [
      "Zhenping Xie"
    ],
    "abstract": "Human intelligence seems so mysterious that we have not successfully\nunderstood its foundation until now. Here, I want to present a basic cognitive\nprocess, motion mapping cognition (MMC), which should be a nondecomposable\nprimary function in human vision. Wherein, I point out that, MMC process can be\nused to explain most of human visual functions in fundamental, but can not be\neffectively modelled by traditional visual processing ways including image\nsegmentation, object recognition, object tracking etc. Furthermore, I state\nthat MMC may be looked as an extension of Chen's theory of topological\nperception on human vision, and seems to be unsolvable using existing\nintelligent algorithm skills. Finally, along with the requirements of MMC\nproblem, an interesting computational model, quantized topological matching\nprinciple can be derived by developing the idea of optimal transport theory.\nAbove results may give us huge inspiration to develop more robust and\ninterpretable machine vision models.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.NC",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.04275v1",
    "published_date": "2024-02-02 10:11:25 UTC",
    "updated_date": "2024-02-02 10:11:25 UTC"
  },
  {
    "arxiv_id": "2402.01806v1",
    "title": "HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on Text",
    "authors": [
      "Han Liu",
      "Zhi Xu",
      "Xiaotong Zhang",
      "Feng Zhang",
      "Fenglong Ma",
      "Hongyang Chen",
      "Hong Yu",
      "Xianchao Zhang"
    ],
    "abstract": "Black-box hard-label adversarial attack on text is a practical and\nchallenging task, as the text data space is inherently discrete and\nnon-differentiable, and only the predicted label is accessible. Research on\nthis problem is still in the embryonic stage and only a few methods are\navailable. Nevertheless, existing methods rely on the complex heuristic\nalgorithm or unreliable gradient estimation strategy, which probably fall into\nthe local optimum and inevitably consume numerous queries, thus are difficult\nto craft satisfactory adversarial examples with high semantic similarity and\nlow perturbation rate in a limited query budget. To alleviate above issues, we\npropose a simple yet effective framework to generate high quality textual\nadversarial examples under the black-box hard-label attack scenarios, named\nHQA-Attack. Specifically, after initializing an adversarial example randomly,\nHQA-attack first constantly substitutes original words back as many as\npossible, thus shrinking the perturbation rate. Then it leverages the synonym\nset of the remaining changed words to further optimize the adversarial example\nwith the direction which can improve the semantic similarity and satisfy the\nadversarial condition simultaneously. In addition, during the optimizing\nprocedure, it searches a transition synonym word for each changed word, thus\navoiding traversing the whole synonym set and reducing the query number to some\nextent. Extensive experimental results on five text classification datasets,\nthree natural language inference datasets and two real-world APIs have shown\nthat the proposed HQA-Attack method outperforms other strong baselines\nsignificantly.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01806v1",
    "published_date": "2024-02-02 10:06:43 UTC",
    "updated_date": "2024-02-02 10:06:43 UTC"
  },
  {
    "arxiv_id": "2402.01276v4",
    "title": "Federated Unlearning: a Perspective of Stability and Fairness",
    "authors": [
      "Jiaqi Shao",
      "Tao Lin",
      "Xuanyu Cao",
      "Bing Luo"
    ],
    "abstract": "This paper explores the multifaceted consequences of federated unlearning\n(FU) with data heterogeneity. We introduce key metrics for FU assessment,\nconcentrating on verification, global stability, and local fairness, and\ninvestigate the inherent trade-offs. Furthermore, we formulate the unlearning\nprocess with data heterogeneity through an optimization framework. Our key\ncontribution lies in a comprehensive theoretical analysis of the trade-offs in\nFU and provides insights into data heterogeneity's impacts on FU. Leveraging\nthese insights, we propose FU mechanisms to manage the trade-offs, guiding\nfurther development for FU mechanisms. We empirically validate that our FU\nmechanisms effectively balance trade-offs, confirming insights derived from our\ntheoretical analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01276v4",
    "published_date": "2024-02-02 10:05:25 UTC",
    "updated_date": "2024-06-01 15:18:50 UTC"
  },
  {
    "arxiv_id": "2402.09450v3",
    "title": "Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram",
    "authors": [
      "Yeongyeon Na",
      "Minje Park",
      "Yunwon Tae",
      "Sunghoon Joo"
    ],
    "abstract": "Electrocardiograms (ECG) are widely employed as a diagnostic tool for\nmonitoring electrical signals originating from a heart. Recent machine learning\nresearch efforts have focused on the application of screening various diseases\nusing ECG signals. However, adapting to the application of screening disease is\nchallenging in that labeled ECG data are limited. Achieving general\nrepresentation through self-supervised learning (SSL) is a well-known approach\nto overcome the scarcity of labeled data; however, a naive application of SSL\nto ECG data, without considering the spatial-temporal relationships inherent in\nECG signals, may yield suboptimal results. In this paper, we introduce ST-MEM\n(Spatio-Temporal Masked Electrocardiogram Modeling), designed to learn\nspatio-temporal features by reconstructing masked 12-lead ECG data. ST-MEM\noutperforms other SSL baseline methods in various experimental settings for\narrhythmia classification tasks. Moreover, we demonstrate that ST-MEM is\nadaptable to various lead combinations. Through quantitative and qualitative\nanalysis, we show a spatio-temporal relationship within ECG data. Our code is\navailable at https://github.com/bakqui/ST-MEM.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "ICLR 2024. The first three authors contribute equally",
    "pdf_url": "http://arxiv.org/pdf/2402.09450v3",
    "published_date": "2024-02-02 10:04:13 UTC",
    "updated_date": "2024-03-19 16:17:00 UTC"
  },
  {
    "arxiv_id": "2402.01805v4",
    "title": "Can LLMs perform structured graph reasoning?",
    "authors": [
      "Palaash Agrawal",
      "Shavak Vasania",
      "Cheston Tan"
    ],
    "abstract": "Pretrained Large Language Models (LLMs) have demonstrated various reasoning\ncapabilities through language-based prompts alone, particularly in unstructured\ntask settings (tasks purely based on language semantics). However, LLMs often\nstruggle with structured tasks, because of the inherent incompatibility of\ninput representation. Reducing structured tasks to uni-dimensional language\nsemantics often renders the problem trivial. Keeping the trade-off between LLM\ncompatibility and structure complexity in mind, we design various graph\nreasoning tasks as a proxy to semi-structured tasks in this paper, in order to\ntest the ability to navigate through representations beyond plain text in\nvarious LLMs. Particularly, we design 10 distinct problems of graph traversal,\neach representing increasing levels of complexity, and benchmark 5 different\ninstruct-finetuned LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2 and Palm-2) on the\naforementioned tasks. Further, we analyse the performance of models across\nvarious settings such as varying sizes of graphs as well as different forms of\nk-shot prompting. We highlight various limitations, biases and properties of\nLLMs through this benchmarking process, such as an inverse relation to the\naverage degrees of freedom of traversal per node in graphs, the overall\nnegative impact of k-shot prompting on graph reasoning tasks, and a positive\nresponse bias which prevents LLMs from identifying the absence of a valid\nsolution. Finally, we introduce a new prompting technique specially designed\nfor graph traversal tasks (PathCompare), which demonstrates a notable increase\nin the performance of LLMs in comparison to standard prompting techniques such\nas Chain-of-Thought (CoT).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "International Conference on Pattern Recognition (ICPR), 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01805v4",
    "published_date": "2024-02-02 09:45:33 UTC",
    "updated_date": "2024-08-29 14:05:44 UTC"
  },
  {
    "arxiv_id": "2402.01267v1",
    "title": "The Human and the Mechanical: logos, truthfulness, and ChatGPT",
    "authors": [
      "Anastasia Giannakidou",
      "Alda Mari"
    ],
    "abstract": "The paper addresses the question of whether it is appropriate to talk about\n`mechanical minds' at all, and whether ChatGPT models can indeed be thought of\nas realizations of that. Our paper adds a semantic argument to the current\ndebate. The act of human assertion requires the formation of a veridicality\njudgment. Modification of assertions with modals (John must be at home) and the\nuse of subjective elements (John is obviously at home) indicate that the\nspeaker is manipulating her judgments and, in a cooperative context, intends\nher epistemic state to be transparent to the addressee. Veridicality judgments\nare formed on the basis of two components: (i) evidence that relates to reality\n(exogenous evidence) and (ii) endogenous evidence, such as preferences and\nprivate beliefs. `Mechanical minds' lack these two components: (i) they do not\nrelate to reality and (ii) do not have endogenous evidence. Therefore they lack\nthe ability to form a belief about the world and a veridicality judgments\naltogether. They can only mimic that judgment, but the output is not ground in\nthe very foundations for it.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under submission",
    "pdf_url": "http://arxiv.org/pdf/2402.01267v1",
    "published_date": "2024-02-02 09:41:51 UTC",
    "updated_date": "2024-02-02 09:41:51 UTC"
  },
  {
    "arxiv_id": "2402.01261v3",
    "title": "TEDDY: Trimming Edges with Degree-based Discrimination strategY",
    "authors": [
      "Hyunjin Seo",
      "Jihun Yun",
      "Eunho Yang"
    ],
    "abstract": "Since the pioneering work on the lottery ticket hypothesis for graph neural\nnetworks (GNNs) was proposed in Chen et al. (2021), the study on finding graph\nlottery tickets (GLT) has become one of the pivotal focus in the GNN community,\ninspiring researchers to discover sparser GLT while achieving comparable\nperformance to original dense networks. In parallel, the graph structure has\ngained substantial attention as a crucial factor in GNN training dynamics, also\nelucidated by several recent studies. Despite this, contemporary studies on\nGLT, in general, have not fully exploited inherent pathways in the graph\nstructure and identified tickets in an iterative manner, which is\ntime-consuming and inefficient. To address these limitations, we introduce\nTEDDY, a one-shot edge sparsification framework that leverages structural\ninformation by incorporating edge-degree information. Following edge\nsparsification, we encourage the parameter sparsity during training via simple\nprojected gradient descent on the $\\ell_0$ ball. Given the target sparsity\nlevels for both the graph structure and the model parameters, our TEDDY\nfacilitates efficient and rapid realization of GLT within a single training.\nRemarkably, our experimental results demonstrate that TEDDY significantly\nsurpasses conventional iterative approaches in generalization, even when\nconducting one-shot sparsification that solely utilizes graph structures,\nwithout taking feature information into account.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01261v3",
    "published_date": "2024-02-02 09:32:03 UTC",
    "updated_date": "2024-03-15 14:12:18 UTC"
  },
  {
    "arxiv_id": "2402.01259v1",
    "title": "Position Aware 60 GHz mmWave Beamforming for V2V Communications Utilizing Deep Learning",
    "authors": [
      "Muhammad Baqer Mollah",
      "Honggang Wang",
      "Hua Fang"
    ],
    "abstract": "Beamforming techniques are considered as essential parts to compensate the\nsevere path loss in millimeter-wave (mmWave) communications by adopting large\nantenna arrays and formulating narrow beams to obtain satisfactory received\npowers. However, performing accurate beam alignment over such narrow beams for\nefficient link configuration by traditional beam selection approaches, mainly\nrelied on channel state information, typically impose significant latency and\ncomputing overheads, which is often infeasible in vehicle-to-vehicle (V2V)\ncommunications like highly dynamic scenarios. In contrast, utilizing\nout-of-band contextual information, such as vehicular position information, is\na potential alternative to reduce such overheads. In this context, this paper\npresents a deep learning-based solution on utilizing the vehicular position\ninformation for predicting the optimal beams having sufficient mmWave received\npowers so that the best V2V line-of-sight links can be ensured proactively.\nAfter experimental evaluation of the proposed solution on real-world measured\nmmWave sensing and communications datasets, the results show that the solution\ncan achieve up to 84.58% of received power of link status on average, which\nconfirm a promising solution for beamforming in mmWave at 60 GHz enabled V2V\ncommunications.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "cs.SI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI",
    "comment": "2024 IEEE International Conference on Communications (ICC), Denver,\n  CO, USA",
    "pdf_url": "http://arxiv.org/pdf/2402.01259v1",
    "published_date": "2024-02-02 09:30:27 UTC",
    "updated_date": "2024-02-02 09:30:27 UTC"
  },
  {
    "arxiv_id": "2402.01241v1",
    "title": "Can Shape-Infused Joint Embeddings Improve Image-Conditioned 3D Diffusion?",
    "authors": [
      "Cristian Sbrolli",
      "Paolo Cudrano",
      "Matteo Matteucci"
    ],
    "abstract": "Recent advancements in deep generative models, particularly with the\napplication of CLIP (Contrastive Language Image Pretraining) to Denoising\nDiffusion Probabilistic Models (DDPMs), have demonstrated remarkable\neffectiveness in text to image generation. The well structured embedding space\nof CLIP has also been extended to image to shape generation with DDPMs,\nyielding notable results. Despite these successes, some fundamental questions\narise: Does CLIP ensure the best results in shape generation from images? Can\nwe leverage conditioning to bring explicit 3D knowledge into the generative\nprocess and obtain better quality? This study introduces CISP (Contrastive\nImage Shape Pre training), designed to enhance 3D shape synthesis guided by 2D\nimages. CISP aims to enrich the CLIP framework by aligning 2D images with 3D\nshapes in a shared embedding space, specifically capturing 3D characteristics\npotentially overlooked by CLIP's text image focus. Our comprehensive analysis\nassesses CISP's guidance performance against CLIP guided models, focusing on\ngeneration quality, diversity, and coherence of the produced shapes with the\nconditioning image. We find that, while matching CLIP in generation quality and\ndiversity, CISP substantially improves coherence with input images,\nunderscoring the value of incorporating 3D knowledge into generative models.\nThese findings suggest a promising direction for advancing the synthesis of 3D\nvisual content by integrating multimodal systems with 3D representations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01241v1",
    "published_date": "2024-02-02 09:09:23 UTC",
    "updated_date": "2024-02-02 09:09:23 UTC"
  },
  {
    "arxiv_id": "2402.01240v3",
    "title": "Beyond the Request: Harnessing HTTP Response Headers for Cross-Browser Web Tracker Classification in an Imbalanced Setting",
    "authors": [
      "Wolf Rieder",
      "Philip Raschke",
      "Thomas Cory"
    ],
    "abstract": "The World Wide Web's connectivity is greatly attributed to the HTTP protocol,\nwith HTTP messages offering informative header fields that appeal to\ndisciplines like web security and privacy, especially concerning web tracking.\nDespite existing research employing HTTP request messages to identify web\ntrackers, HTTP response headers are often overlooked. This study endeavors to\ndesign effective machine learning classifiers for web tracker detection using\nbinarized HTTP response headers. Data from the Chrome, Firefox, and Brave\nbrowsers, obtained through the traffic monitoring browser extension T.EX,\nserves as our dataset. Ten supervised models were trained on Chrome data and\ntested across all browsers, including a Chrome dataset from a year later. The\nresults demonstrated high accuracy, F1-score, precision, recall, and minimal\nlog-loss error for Chrome and Firefox, but subpar performance on Brave,\npotentially due to its distinct data distribution and feature set. The research\nsuggests that these classifiers are viable for web tracker detection. However,\nreal-world application testing remains pending, and the distinction between\ntracker types and broader label sources could be explored in future studies.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01240v3",
    "published_date": "2024-02-02 09:07:09 UTC",
    "updated_date": "2024-09-23 11:33:15 UTC"
  },
  {
    "arxiv_id": "2402.01239v1",
    "title": "PRIME: Protect Your Videos From Malicious Editing",
    "authors": [
      "Guanlin Li",
      "Shuai Yang",
      "Jie Zhang",
      "Tianwei Zhang"
    ],
    "abstract": "With the development of generative models, the quality of generated content\nkeeps increasing. Recently, open-source models have made it surprisingly easy\nto manipulate and edit photos and videos, with just a few simple prompts. While\nthese cutting-edge technologies have gained popularity, they have also given\nrise to concerns regarding the privacy and portrait rights of individuals.\nMalicious users can exploit these tools for deceptive or illegal purposes.\nAlthough some previous works focus on protecting photos against generative\nmodels, we find there are still gaps between protecting videos and images in\nthe aspects of efficiency and effectiveness. Therefore, we introduce our\nprotection method, PRIME, to significantly reduce the time cost and improve the\nprotection performance. Moreover, to evaluate our proposed protection method,\nwe consider both objective metrics and human subjective metrics. Our evaluation\nresults indicate that PRIME only costs 8.3% GPU hours of the cost of the\nprevious state-of-the-art method and achieves better protection results on both\nhuman evaluation and objective metrics. Code can be found in\nhttps://github.com/GuanlinLee/prime.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01239v1",
    "published_date": "2024-02-02 09:07:00 UTC",
    "updated_date": "2024-02-02 09:07:00 UTC"
  },
  {
    "arxiv_id": "2402.01238v1",
    "title": "Flexible Variational Information Bottleneck: Achieving Diverse Compression with a Single Training",
    "authors": [
      "Sota Kudo",
      "Naoaki Ono",
      "Shigehiko Kanaya",
      "Ming Huang"
    ],
    "abstract": "Information Bottleneck (IB) is a widely used framework that enables the\nextraction of information related to a target random variable from a source\nrandom variable. In the objective function, IB controls the trade-off between\ndata compression and predictiveness through the Lagrange multiplier $\\beta$.\nTraditionally, to find the trade-off to be learned, IB requires a search for\n$\\beta$ through multiple training cycles, which is computationally expensive.\nIn this study, we introduce Flexible Variational Information Bottleneck (FVIB),\nan innovative framework for classification task that can obtain optimal models\nfor all values of $\\beta$ with single, computationally efficient training. We\ntheoretically demonstrate that across all values of reasonable $\\beta$, FVIB\ncan simultaneously maximize an approximation of the objective function for\nVariational Information Bottleneck (VIB), the conventional IB method. Then we\nempirically show that FVIB can learn the VIB objective as effectively as VIB.\nFurthermore, in terms of calibration performance, FVIB outperforms other IB and\ncalibration methods by enabling continuous optimization of $\\beta$. Our codes\nare available at https://github.com/sotakudo/fvib.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01238v1",
    "published_date": "2024-02-02 09:03:38 UTC",
    "updated_date": "2024-02-02 09:03:38 UTC"
  },
  {
    "arxiv_id": "2402.01227v1",
    "title": "STAA-Net: A Sparse and Transferable Adversarial Attack for Speech Emotion Recognition",
    "authors": [
      "Yi Chang",
      "Zhao Ren",
      "Zixing Zhang",
      "Xin Jing",
      "Kun Qian",
      "Xi Shao",
      "Bin Hu",
      "Tanja Schultz",
      "Björn W. Schuller"
    ],
    "abstract": "Speech contains rich information on the emotions of humans, and Speech\nEmotion Recognition (SER) has been an important topic in the area of\nhuman-computer interaction. The robustness of SER models is crucial,\nparticularly in privacy-sensitive and reliability-demanding domains like\nprivate healthcare. Recently, the vulnerability of deep neural networks in the\naudio domain to adversarial attacks has become a popular area of research.\nHowever, prior works on adversarial attacks in the audio domain primarily rely\non iterative gradient-based techniques, which are time-consuming and prone to\noverfitting the specific threat model. Furthermore, the exploration of sparse\nperturbations, which have the potential for better stealthiness, remains\nlimited in the audio domain. To address these challenges, we propose a\ngenerator-based attack method to generate sparse and transferable adversarial\nexamples to deceive SER models in an end-to-end and efficient manner. We\nevaluate our method on two widely-used SER datasets, Database of Elicited Mood\nin Speech (DEMoS) and Interactive Emotional dyadic MOtion CAPture (IEMOCAP),\nand demonstrate its ability to generate successful sparse adversarial examples\nin an efficient manner. Moreover, our generated adversarial examples exhibit\nmodel-agnostic transferability, enabling effective adversarial attacks on\nadvanced victim models.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01227v1",
    "published_date": "2024-02-02 08:46:57 UTC",
    "updated_date": "2024-02-02 08:46:57 UTC"
  },
  {
    "arxiv_id": "2402.01219v1",
    "title": "AI Code Generators for Security: Friend or Foe?",
    "authors": [
      "Roberto Natella",
      "Pietro Liguori",
      "Cristina Improta",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "abstract": "Recent advances of artificial intelligence (AI) code generators are opening\nnew opportunities in software security research, including misuse by malicious\nactors. We review use cases for AI code generators for security and introduce\nan evaluation benchmark.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "Dataset available at: https://github.com/dessertlab/violent-python",
    "pdf_url": "http://arxiv.org/pdf/2402.01219v1",
    "published_date": "2024-02-02 08:41:15 UTC",
    "updated_date": "2024-02-02 08:41:15 UTC"
  },
  {
    "arxiv_id": "2402.01804v4",
    "title": "Analysis of Internet of Things Implementation Barriers in the Cold Supply Chain: An Integrated ISM-MICMAC and DEMATEL Approach",
    "authors": [
      "Kazrin Ahmad",
      "Md. Saiful Islam",
      "Md Abrar Jahin",
      "M. F. Mridha"
    ],
    "abstract": "Integrating Internet of Things (IoT) technology inside the cold supply chain\ncan enhance transparency, efficiency, and quality, optimizing operating\nprocedures and increasing productivity. The integration of IoT in this\ncomplicated setting is hindered by specific barriers that need a thorough\nexamination. Prominent barriers to IoT implementation in the cold supply chain\nare identified using a two-stage model. After reviewing the available\nliterature on the topic of IoT implementation, a total of 13 barriers were\nfound. The survey data was cross-validated for quality, and Cronbach's alpha\ntest was employed to ensure validity. This research applies the interpretative\nstructural modeling technique in the first phase to identify the main barriers.\nAmong those barriers, \"regularity compliance\" and \"cold chain networks\" are key\ndrivers for IoT adoption strategies. MICMAC's driving and dependence power\nelement categorization helps evaluate the barrier interactions. In the second\nphase of this research, a decision-making trial and evaluation laboratory\nmethodology was employed to identify causal relationships between barriers and\nevaluate them according to their relative importance. Each cause is a potential\ndrive, and if its efficiency can be enhanced, the system as a whole benefits.\nThe research findings provide industry stakeholders, governments, and\norganizations with significant drivers of IoT adoption to overcome these\nbarriers and optimize the utilization of IoT technology to improve the\neffectiveness and reliability of the cold supply chain.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01804v4",
    "published_date": "2024-02-02 08:37:06 UTC",
    "updated_date": "2024-11-05 13:23:16 UTC"
  },
  {
    "arxiv_id": "2402.01208v1",
    "title": "Location Agnostic Adaptive Rain Precipitation Prediction using Deep Learning",
    "authors": [
      "Md Shazid Islam",
      "Md Saydur Rahman",
      "Md Saad Ul Haque",
      "Farhana Akter Tumpa",
      "Md Sanzid Bin Hossain",
      "Abul Al Arabi"
    ],
    "abstract": "Rain precipitation prediction is a challenging task as it depends on weather\nand meteorological features which vary from location to location. As a result,\na prediction model that performs well at one location does not perform well at\nother locations due to the distribution shifts. In addition, due to global\nwarming, the weather patterns are changing very rapidly year by year which\ncreates the possibility of ineffectiveness of those models even at the same\nlocation as time passes. In our work, we have proposed an adaptive deep\nlearning-based framework in order to provide a solution to the aforementioned\nchallenges. Our method can generalize the model for the prediction of\nprecipitation for any location where the methods without adaptation fail. Our\nmethod has shown 43.51%, 5.09%, and 38.62% improvement after adaptation using a\ndeep neural network for predicting the precipitation of Paris, Los Angeles, and\nTokyo, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01208v1",
    "published_date": "2024-02-02 08:26:42 UTC",
    "updated_date": "2024-02-02 08:26:42 UTC"
  },
  {
    "arxiv_id": "2402.01207v4",
    "title": "Efficient Causal Graph Discovery Using Large Language Models",
    "authors": [
      "Thomas Jiralerspong",
      "Xiaoyin Chen",
      "Yash More",
      "Vedant Shah",
      "Yoshua Bengio"
    ],
    "abstract": "We propose a novel framework that leverages LLMs for full causal graph\ndiscovery. While previous LLM-based methods have used a pairwise query\napproach, this requires a quadratic number of queries which quickly becomes\nimpractical for larger causal graphs. In contrast, the proposed framework uses\na breadth-first search (BFS) approach which allows it to use only a linear\nnumber of queries. We also show that the proposed method can easily incorporate\nobservational data when available, to improve performance. In addition to being\nmore time and data-efficient, the proposed framework achieves state-of-the-art\nresults on real-world causal graphs of varying sizes. The results demonstrate\nthe effectiveness and efficiency of the proposed method in discovering causal\nrelationships, showcasing its potential for broad applicability in causal graph\ndiscovery tasks across different domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01207v4",
    "published_date": "2024-02-02 08:25:32 UTC",
    "updated_date": "2024-07-20 18:51:58 UTC"
  },
  {
    "arxiv_id": "2402.01204v4",
    "title": "A Survey on Self-Supervised Learning for Non-Sequential Tabular Data",
    "authors": [
      "Wei-Yao Wang",
      "Wei-Wei Du",
      "Derek Xu",
      "Wei Wang",
      "Wen-Chih Peng"
    ],
    "abstract": "Self-supervised learning (SSL) has been incorporated into many\nstate-of-the-art models in various domains, where SSL defines pretext tasks\nbased on unlabeled datasets to learn contextualized and robust representations.\nRecently, SSL has become a new trend in exploring the representation learning\ncapability in the realm of tabular data, which is more challenging due to not\nhaving explicit relations for learning descriptive representations. This survey\naims to systematically review and summarize the recent progress and challenges\nof SSL for non-sequential tabular data (SSL4NS-TD). We first present a formal\ndefinition of NS-TD and clarify its correlation to related studies. Then, these\napproaches are categorized into three groups - predictive learning, contrastive\nlearning, and hybrid learning, with their motivations and strengths of\nrepresentative methods in each direction. Moreover, application issues of\nSSL4NS-TD are presented, including automatic data engineering, cross-table\ntransferability, and domain knowledge integration. In addition, we elaborate on\nexisting benchmarks and datasets for NS-TD applications to analyze the\nperformance of existing tabular models. Finally, we discuss the challenges of\nSSL4NS-TD and provide potential directions for future research. We expect our\nwork to be useful in terms of encouraging more research on lowering the barrier\nto entry SSL for the tabular domain, and of improving the foundations for\nimplicit tabular data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ACML-24 Journal Track. The paper list can be found at\n  https://github.com/wwweiwei/awesome-self-supervised-learning-for-tabular-data",
    "pdf_url": "http://arxiv.org/pdf/2402.01204v4",
    "published_date": "2024-02-02 08:17:41 UTC",
    "updated_date": "2024-09-10 07:02:47 UTC"
  },
  {
    "arxiv_id": "2402.03370v1",
    "title": "Detection of tortured phrases in scientific literature",
    "authors": [
      "Eléna Martel",
      "Martin Lentschat",
      "Cyril Labbé"
    ],
    "abstract": "This paper presents various automatic detection methods to extract so called\ntortured phrases from scientific papers. These tortured phrases, e.g. flag to\nclamor instead of signal to noise, are the results of paraphrasing tools used\nto escape plagiarism detection. We built a dataset and evaluated several\nstrategies to flag previously undocumented tortured phrases. The proposed and\ntested methods are based on language models and either on embeddings\nsimilarities or on predictions of masked token. We found that an approach using\ntoken prediction and that propagates the scores to the chunk level gives the\nbest results. With a recall value of .87 and a precision value of .61, it could\nretrieve new tortured phrases to be submitted to domain experts for validation.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.DL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03370v1",
    "published_date": "2024-02-02 08:15:43 UTC",
    "updated_date": "2024-02-02 08:15:43 UTC"
  },
  {
    "arxiv_id": "2402.01201v1",
    "title": "Few-Shot Class-Incremental Learning with Prior Knowledge",
    "authors": [
      "Wenhao Jiang",
      "Duo Li",
      "Menghan Hu",
      "Guangtao Zhai",
      "Xiaokang Yang",
      "Xiao-Ping Zhang"
    ],
    "abstract": "To tackle the issues of catastrophic forgetting and overfitting in few-shot\nclass-incremental learning (FSCIL), previous work has primarily concentrated on\npreserving the memory of old knowledge during the incremental phase. The role\nof pre-trained model in shaping the effectiveness of incremental learning is\nfrequently underestimated in these studies. Therefore, to enhance the\ngeneralization ability of the pre-trained model, we propose Learning with Prior\nKnowledge (LwPK) by introducing nearly free prior knowledge from a few\nunlabeled data of subsequent incremental classes. We cluster unlabeled\nincremental class samples to produce pseudo-labels, then jointly train these\nwith labeled base class samples, effectively allocating embedding space for\nboth old and new class data. Experimental results indicate that LwPK\neffectively enhances the model resilience against catastrophic forgetting, with\ntheoretical analysis based on empirical risk minimization and class distance\nmeasurement corroborating its operational principles. The source code of LwPK\nis publicly available at: \\url{https://github.com/StevenJ308/LwPK}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01201v1",
    "published_date": "2024-02-02 08:05:35 UTC",
    "updated_date": "2024-02-02 08:05:35 UTC"
  },
  {
    "arxiv_id": "2402.01195v2",
    "title": "Conditional Normalizing Flows for Active Learning of Coarse-Grained Molecular Representations",
    "authors": [
      "Henrik Schopmans",
      "Pascal Friederich"
    ],
    "abstract": "Efficient sampling of the Boltzmann distribution of molecular systems is a\nlong-standing challenge. Recently, instead of generating long molecular\ndynamics simulations, generative machine learning methods such as normalizing\nflows have been used to learn the Boltzmann distribution directly, without\nsamples. However, this approach is susceptible to mode collapse and thus often\ndoes not explore the full configurational space. In this work, we address this\nchallenge by separating the problem into two levels, the fine-grained and\ncoarse-grained degrees of freedom. A normalizing flow conditioned on the\ncoarse-grained space yields a probabilistic connection between the two levels.\nTo explore the configurational space, we employ coarse-grained simulations with\nactive learning which allows us to update the flow and make all-atom potential\nenergy evaluations only when necessary. Using alanine dipeptide as an example,\nwe show that our methods obtain a speedup to molecular dynamics simulations of\napproximately 15.9 to 216.2 compared to the speedup of 4.5 of the current\nstate-of-the-art machine learning approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01195v2",
    "published_date": "2024-02-02 07:44:26 UTC",
    "updated_date": "2024-05-24 12:13:33 UTC"
  },
  {
    "arxiv_id": "2402.01802v1",
    "title": "An Auction-based Marketplace for Model Trading in Federated Learning",
    "authors": [
      "Yue Cui",
      "Liuyi Yao",
      "Yaliang Li",
      "Ziqian Chen",
      "Bolin Ding",
      "Xiaofang Zhou"
    ],
    "abstract": "Federated learning (FL) is increasingly recognized for its efficacy in\ntraining models using locally distributed data. However, the proper valuation\nof shared data in this collaborative process remains insufficiently addressed.\nIn this work, we frame FL as a marketplace of models, where clients act as both\nbuyers and sellers, engaging in model trading. This FL market allows clients to\ngain monetary reward by selling their own models and improve local model\nperformance through the purchase of others' models. We propose an auction-based\nsolution to ensure proper pricing based on performance gain. Incentive\nmechanisms are designed to encourage clients to truthfully reveal their model\nvaluations. Furthermore, we introduce a reinforcement learning (RL) framework\nfor marketing operations, aiming to achieve maximum trading volumes under the\ndynamic and evolving market status. Experimental results on four datasets\ndemonstrate that the proposed FL market can achieve high trading revenue and\nfair downstream task accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01802v1",
    "published_date": "2024-02-02 07:25:53 UTC",
    "updated_date": "2024-02-02 07:25:53 UTC"
  },
  {
    "arxiv_id": "2402.01801v3",
    "title": "Large Language Models for Time Series: A Survey",
    "authors": [
      "Xiyuan Zhang",
      "Ranak Roy Chowdhury",
      "Rajesh K. Gupta",
      "Jingbo Shang"
    ],
    "abstract": "Large Language Models (LLMs) have seen significant use in domains such as\nnatural language processing and computer vision. Going beyond text, image and\ngraphics, LLMs present a significant potential for analysis of time series\ndata, benefiting domains such as climate, IoT, healthcare, traffic, audio and\nfinance. This survey paper provides an in-depth exploration and a detailed\ntaxonomy of the various methodologies employed to harness the power of LLMs for\ntime series analysis. We address the inherent challenge of bridging the gap\nbetween LLMs' original text data training and the numerical nature of time\nseries data, and explore strategies for transferring and distilling knowledge\nfrom LLMs to numerical time series analysis. We detail various methodologies,\nincluding (1) direct prompting of LLMs, (2) time series quantization, (3)\naligning techniques, (4) utilization of the vision modality as a bridging\nmechanism, and (5) the combination of LLMs with tools. Additionally, this\nsurvey offers a comprehensive overview of the existing multimodal time series\nand text datasets and delves into the challenges and future opportunities of\nthis emerging field. We maintain an up-to-date Github repository which includes\nall the papers and datasets discussed in the survey.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "GitHub repository:\n  https://github.com/xiyuanzh/awesome-llm-time-series",
    "pdf_url": "http://arxiv.org/pdf/2402.01801v3",
    "published_date": "2024-02-02 07:24:35 UTC",
    "updated_date": "2024-05-06 20:48:41 UTC"
  },
  {
    "arxiv_id": "2402.01183v1",
    "title": "LINGO-Space: Language-Conditioned Incremental Grounding for Space",
    "authors": [
      "Dohyun Kim",
      "Nayoung Oh",
      "Deokmin Hwang",
      "Daehyung Park"
    ],
    "abstract": "We aim to solve the problem of spatially localizing composite instructions\nreferring to space: space grounding. Compared to current instance grounding,\nspace grounding is challenging due to the ill-posedness of identifying\nlocations referred to by discrete expressions and the compositional ambiguity\nof referring expressions. Therefore, we propose a novel probabilistic\nspace-grounding methodology (LINGO-Space) that accurately identifies a\nprobabilistic distribution of space being referred to and incrementally updates\nit, given subsequent referring expressions leveraging configurable polar\ndistributions. Our evaluations show that the estimation using polar\ndistributions enables a robot to ground locations successfully through $20$\ntable-top manipulation benchmark tests. We also show that updating the\ndistribution helps the grounding method accurately narrow the referring space.\nWe finally demonstrate the robustness of the space grounding with simulated\nmanipulation and real quadruped robot navigation tasks. Code and videos are\navailable at https://lingo-space.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01183v1",
    "published_date": "2024-02-02 06:58:39 UTC",
    "updated_date": "2024-02-02 06:58:39 UTC"
  },
  {
    "arxiv_id": "2402.01799v2",
    "title": "Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward",
    "authors": [
      "Arnav Chavan",
      "Raghav Magazine",
      "Shubham Kushwaha",
      "Mérouane Debbah",
      "Deepak Gupta"
    ],
    "abstract": "Despite the impressive performance of LLMs, their widespread adoption faces\nchallenges due to substantial computational and memory requirements during\ninference. Recent advancements in model compression and system-level\noptimization methods aim to enhance LLM inference. This survey offers an\noverview of these methods, emphasizing recent developments. Through experiments\non LLaMA(/2)-7B, we evaluate various compression techniques, providing\npractical insights for efficient LLM deployment in a unified setting. The\nempirical analysis on LLaMA(/2)-7B highlights the effectiveness of these\nmethods. Drawing from survey insights, we identify current limitations and\ndiscuss potential future directions to improve LLM inference efficiency. We\nrelease the codebase to reproduce the results presented in this paper at\nhttps://github.com/nyunAI/Faster-LLM-Survey",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IJCAI '24 (Survey Track), Updated TGI results",
    "pdf_url": "http://arxiv.org/pdf/2402.01799v2",
    "published_date": "2024-02-02 06:29:34 UTC",
    "updated_date": "2024-04-24 04:58:46 UTC"
  },
  {
    "arxiv_id": "2402.18587v1",
    "title": "At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence",
    "authors": [
      "Abdulkadir Celik",
      "Ahmed M. Eltawil"
    ],
    "abstract": "The majority of data-driven wireless research leans heavily on discriminative\nAI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI\n(GenAI) pertains to generative models (GMs) capable of discerning the\nunderlying data distribution, patterns, and features of the input data. This\nmakes GenAI a crucial asset in wireless domain wherein real-world data is often\nscarce, incomplete, costly to acquire, and hard to model or comprehend. With\nthese appealing attributes, GenAI can replace or supplement DAI methods in\nvarious capacities. Accordingly, this combined tutorial-survey paper commences\nwith preliminaries of 6G and wireless intelligence by outlining candidate 6G\napplications and services, presenting a taxonomy of state-of-the-art DAI\nmodels, exemplifying prominent DAI use cases, and elucidating the multifaceted\nways through which GenAI enhances DAI. Subsequently, we present a tutorial on\nGMs by spotlighting seminal examples such as generative adversarial networks,\nvariational autoencoders, flow-based GMs, diffusion-based GMs, generative\ntransformers, large language models, to name a few. Contrary to the prevailing\nbelief that GenAI is a nascent trend, our exhaustive review of approximately\n120 technical papers demonstrates the scope of research across core wireless\nresearch areas, including physical layer design; network optimization,\norganization, and management; network traffic analytics; cross-layer network\nsecurity; and localization & positioning. Furthermore, we outline the central\nrole of GMs in pioneering areas of 6G network research, including\nsemantic/THz/near-field communications, ISAC, extremely large antenna arrays,\ndigital twins, AI-generated content services, mobile edge computing and edge\nAI, adversarial ML, and trustworthy AI. Lastly, we shed light on the\nmultifarious challenges ahead, suggesting potential strategies and promising\nremedies.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18587v1",
    "published_date": "2024-02-02 06:23:25 UTC",
    "updated_date": "2024-02-02 06:23:25 UTC"
  },
  {
    "arxiv_id": "2402.01169v1",
    "title": "Faster Inference of Integer SWIN Transformer by Removing the GELU Activation",
    "authors": [
      "Mohammadreza Tayaranian",
      "Seyyed Hasan Mozafari",
      "James J. Clark",
      "Brett Meyer",
      "Warren Gross"
    ],
    "abstract": "SWIN transformer is a prominent vision transformer model that has\nstate-of-the-art accuracy in image classification tasks. Despite this success,\nits unique architecture causes slower inference compared with similar deep\nneural networks. Integer quantization of the model is one of the methods used\nto improve its inference latency. However, state-of-the-art has not been able\nto fully quantize the model. In this work, we improve upon the inference\nlatency of the state-of-the-art methods by removing the floating-point\noperations, which are associated with the GELU activation in Swin Transformer.\nWhile previous work proposed to replace the non-integer operations with linear\napproximation functions, we propose to replace GELU with ReLU activation. The\nadvantage of ReLU over previous methods is its low memory and computation\ncomplexity. We use iterative knowledge distillation to compensate for the lost\naccuracy due to replacing GELU with ReLU. We quantize our GELU-less SWIN\ntransformer and show that on an RTX 4090 NVIDIA GPU we can improve the\ninference latency of the quantized SWIN transformer by at least $11\\%$ while\nmaintaining an accuracy drop of under $0.5\\%$ on the ImageNet evaluation\ndataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 1 figure. Submitted to Edge Intelligence Workshop III, an\n  AAAI 2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2402.01169v1",
    "published_date": "2024-02-02 06:23:00 UTC",
    "updated_date": "2024-02-02 06:23:00 UTC"
  },
  {
    "arxiv_id": "2402.01166v2",
    "title": "A Comprehensive Survey on 3D Content Generation",
    "authors": [
      "Jian Liu",
      "Xiaoshui Huang",
      "Tianyu Huang",
      "Lu Chen",
      "Yuenan Hou",
      "Shixiang Tang",
      "Ziwei Liu",
      "Wanli Ouyang",
      "Wangmeng Zuo",
      "Junjun Jiang",
      "Xianming Liu"
    ],
    "abstract": "Recent years have witnessed remarkable advances in artificial intelligence\ngenerated content(AIGC), with diverse input modalities, e.g., text, image,\nvideo, audio and 3D. The 3D is the most close visual modality to real-world 3D\nenvironment and carries enormous knowledge. The 3D content generation shows\nboth academic and practical values while also presenting formidable technical\nchallenges. This review aims to consolidate developments within the burgeoning\ndomain of 3D content generation. Specifically, a new taxonomy is proposed that\ncategorizes existing approaches into three types: 3D native generative methods,\n2D prior-based 3D generative methods, and hybrid 3D generative methods. The\nsurvey covers approximately 60 papers spanning the major techniques. Besides,\nwe discuss limitations of current 3D content generation techniques, and point\nout open challenges as well as promising directions for future work.\nAccompanied with this survey, we have established a project website where the\nresources on 3D content generation research are provided. The project page is\navailable at https://github.com/hitcslj/Awesome-AIGC-3D.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2402.01166v2",
    "published_date": "2024-02-02 06:20:44 UTC",
    "updated_date": "2024-03-19 08:22:42 UTC"
  },
  {
    "arxiv_id": "2403.17942v1",
    "title": "A Note On Lookahead In Real Life And Computing",
    "authors": [
      "Burle Sharma",
      "Rakesh Mohanty",
      "Sucheta Panda"
    ],
    "abstract": "Past, Present and Future are considered to be three temporal and logical\nconcepts which are well defined by human beings for their existence and growth.\nWe, as human beings, have the privilege of using our intelligence to mentally\nexecute an activity before physical occurrence of the same in the real world.\nKnowledge of the past, aplomb of present and visualisation for the future\ncorrespond to three concepts such as look-back, look-at and look-ahead\nrespectively in real life as well as in diversified domains of computing.\nLook-Ahead(LA) deals with the future prediction of information and processing\nof input to produce the output in advance. In this article, our main objective\nis to learn, understand and explore the concept of LA and design novel models\nas solution for real world problems. We present three well known algorithmic\nframeworks used in practice based on availability of input information such as\noffline, online and semi-online. We introduce interesting real life\napplications and well known computing problems where LA plays a significant\nrole for making a process, system or algorithm efficient. We define new types\nof LA and propose a taxonomy for LA based on literature review for designing\nnovel LA models in future. Using the concept of LA, We identify and present\nmany interesting and non-trivial research challenges as future potential\nresearch directions. Intuitively, we observe that LA can be used as a powerful\ntool and framework for future researchers in design of efficient computational\nmodels and algorithms for solving non-trivial and challenging optimization\nproblems.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17942v1",
    "published_date": "2024-02-02 06:17:49 UTC",
    "updated_date": "2024-02-02 06:17:49 UTC"
  },
  {
    "arxiv_id": "2402.01162v1",
    "title": "2AFC Prompting of Large Multimodal Models for Image Quality Assessment",
    "authors": [
      "Hanwei Zhu",
      "Xiangjie Sui",
      "Baoliang Chen",
      "Xuelin Liu",
      "Peilin Chen",
      "Yuming Fang",
      "Shiqi Wang"
    ],
    "abstract": "While abundant research has been conducted on improving high-level visual\nunderstanding and reasoning capabilities of large multimodal models~(LMMs),\ntheir visual quality assessment~(IQA) ability has been relatively\nunder-explored. Here we take initial steps towards this goal by employing the\ntwo-alternative forced choice~(2AFC) prompting, as 2AFC is widely regarded as\nthe most reliable way of collecting human opinions of visual quality.\nSubsequently, the global quality score of each image estimated by a particular\nLMM can be efficiently aggregated using the maximum a posterior estimation.\nMeanwhile, we introduce three evaluation criteria: consistency, accuracy, and\ncorrelation, to provide comprehensive quantifications and deeper insights into\nthe IQA capability of five LMMs. Extensive experiments show that existing LMMs\nexhibit remarkable IQA ability on coarse-grained quality comparison, but there\nis room for improvement on fine-grained quality discrimination. The proposed\ndataset sheds light on the future development of IQA models based on LMMs. The\ncodes will be made publicly available at https://github.com/h4nwei/2AFC-LMMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01162v1",
    "published_date": "2024-02-02 06:05:18 UTC",
    "updated_date": "2024-02-02 06:05:18 UTC"
  },
  {
    "arxiv_id": "2402.01145v3",
    "title": "ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution",
    "authors": [
      "Haoran Ye",
      "Jiarui Wang",
      "Zhiguang Cao",
      "Federico Berto",
      "Chuanbo Hua",
      "Haeyeon Kim",
      "Jinkyoo Park",
      "Guojie Song"
    ],
    "abstract": "The omnipresence of NP-hard combinatorial optimization problems (COPs)\ncompels domain experts to engage in trial-and-error heuristic design. The\nlong-standing endeavor of design automation has gained new momentum with the\nrise of large language models (LLMs). This paper introduces Language\nHyper-Heuristics (LHHs), an emerging variant of Hyper-Heuristics that leverages\nLLMs for heuristic generation, featuring minimal manual intervention and\nopen-ended heuristic spaces. To empower LHHs, we present Reflective Evolution\n(ReEvo), a novel integration of evolutionary search for efficiently exploring\nthe heuristic space, and LLM reflections to provide verbal gradients within the\nspace. Across five heterogeneous algorithmic types, six different COPs, and\nboth white-box and black-box views of COPs, ReEvo yields state-of-the-art and\ncompetitive meta-heuristics, evolutionary algorithms, heuristics, and neural\nsolvers, while being more sample-efficient than prior LHHs.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01145v3",
    "published_date": "2024-02-02 05:04:51 UTC",
    "updated_date": "2024-10-14 13:50:46 UTC"
  },
  {
    "arxiv_id": "2402.01143v2",
    "title": "Learning Network Representations with Disentangled Graph Auto-Encoder",
    "authors": [
      "Di Fan",
      "Chuanhou Gao"
    ],
    "abstract": "The (variational) graph auto-encoder is widely used to learn representations\nfor graph-structured data. However, the formation of real-world graphs is a\ncomplicated and heterogeneous process influenced by latent factors. Existing\nencoders are fundamentally holistic, neglecting the entanglement of latent\nfactors. This reduces the effectiveness of graph analysis tasks, while also\nmaking it more difficult to explain the learned representations. As a result,\nlearning disentangled graph representations with the (variational) graph\nauto-encoder poses significant challenges and remains largely unexplored in the\ncurrent research. In this paper, we introduce the Disentangled Graph\nAuto-Encoder (DGA) and the Disentangled Variational Graph Auto-Encoder (DVGA)\nto learn disentangled representations. Specifically, we first design a\ndisentangled graph convolutional network with multi-channel message-passing\nlayers to serve as the encoder. This allows each channel to aggregate\ninformation about each latent factor. The disentangled variational graph\nauto-encoder's expressive capability is then enhanced by applying a\ncomponent-wise flow to each channel. In addition, we construct a factor-wise\ndecoder that takes into account the characteristics of disentangled\nrepresentations. We improve the independence of representations by imposing\nindependence constraints on the mapping channels for distinct latent factors.\nEmpirical experiments on both synthetic and real-world datasets demonstrate the\nsuperiority of our proposed method compared to several state-of-the-art\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01143v2",
    "published_date": "2024-02-02 04:52:52 UTC",
    "updated_date": "2024-07-16 16:07:44 UTC"
  },
  {
    "arxiv_id": "2402.01140v1",
    "title": "Root Cause Analysis In Microservice Using Neural Granger Causal Discovery",
    "authors": [
      "Cheng-Ming Lin",
      "Ching Chang",
      "Wei-Yao Wang",
      "Kuang-Da Wang",
      "Wen-Chih Peng"
    ],
    "abstract": "In recent years, microservices have gained widespread adoption in IT\noperations due to their scalability, maintenance, and flexibility. However, it\nbecomes challenging for site reliability engineers (SREs) to pinpoint the root\ncause due to the complex relationships in microservices when facing system\nmalfunctions. Previous research employed structured learning methods (e.g.,\nPC-algorithm) to establish causal relationships and derive root causes from\ncausal graphs. Nevertheless, they ignored the temporal order of time series\ndata and failed to leverage the rich information inherent in the temporal\nrelationships. For instance, in cases where there is a sudden spike in CPU\nutilization, it can lead to an increase in latency for other microservices.\nHowever, in this scenario, the anomaly in CPU utilization occurs before the\nlatency increase, rather than simultaneously. As a result, the PC-algorithm\nfails to capture such characteristics. To address these challenges, we propose\nRUN, a novel approach for root cause analysis using neural Granger causal\ndiscovery with contrastive learning. RUN enhances the backbone encoder by\nintegrating contextual information from time series, and leverages a time\nseries forecasting model to conduct neural Granger causal discovery. In\naddition, RUN incorporates Pagerank with a personalization vector to\nefficiently recommend the top-k root causes. Extensive experiments conducted on\nthe synthetic and real-world microservice-based datasets demonstrate that RUN\nnoticeably outperforms the state-of-the-art root cause analysis methods.\nMoreover, we provide an analysis scenario for the sock-shop case to showcase\nthe practicality and efficacy of RUN in microservice-based applications. Our\ncode is publicly available at https://github.com/zmlin1998/RUN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2024 Main Track",
    "pdf_url": "http://arxiv.org/pdf/2402.01140v1",
    "published_date": "2024-02-02 04:43:06 UTC",
    "updated_date": "2024-02-02 04:43:06 UTC"
  },
  {
    "arxiv_id": "2402.01134v2",
    "title": "DeepAAT: Deep Automated Aerial Triangulation for Fast UAV-based Mapping",
    "authors": [
      "Zequan Chen",
      "Jianping Li",
      "Qusheng Li",
      "Bisheng Yang",
      "Zhen Dong"
    ],
    "abstract": "Automated Aerial Triangulation (AAT), aiming to restore image pose and\nreconstruct sparse points simultaneously, plays a pivotal role in earth\nobservation. With its rich research heritage spanning several decades in\nphotogrammetry, AAT has evolved into a fundamental process widely applied in\nlarge-scale Unmanned Aerial Vehicle (UAV) based mapping. Despite its\nadvancements, classic AAT methods still face challenges like low efficiency and\nlimited robustness. This paper introduces DeepAAT, a deep learning network\ndesigned specifically for AAT of UAV imagery. DeepAAT considers both spatial\nand spectral characteristics of imagery, enhancing its capability to resolve\nerroneous matching pairs and accurately predict image poses. DeepAAT marks a\nsignificant leap in AAT's efficiency, ensuring thorough scene coverage and\nprecision. Its processing speed outpaces incremental AAT methods by hundreds of\ntimes and global AAT methods by tens of times while maintaining a comparable\nlevel of reconstruction accuracy. Additionally, DeepAAT's scene clustering and\nmerging strategy facilitate rapid localization and pose determination for\nlarge-scale UAV images, even under constrained computing resources. The\nexperimental results demonstrate DeepAAT's substantial improvements over\nconventional AAT methods, highlighting its potential in the efficiency and\naccuracy of UAV-based 3D reconstruction tasks. To benefit the photogrammetry\nsociety, the code of DeepAAT will be released at:\nhttps://github.com/WHU-USI3DV/DeepAAT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01134v2",
    "published_date": "2024-02-02 04:17:02 UTC",
    "updated_date": "2024-04-07 06:30:39 UTC"
  },
  {
    "arxiv_id": "2402.01791v1",
    "title": "Variational Quantum Circuits Enhanced Generative Adversarial Network",
    "authors": [
      "Runqiu Shu",
      "Xusheng Xu",
      "Man-Hong Yung",
      "Wei Cui"
    ],
    "abstract": "Generative adversarial network (GAN) is one of the widely-adopted\nmachine-learning frameworks for a wide range of applications such as generating\nhigh-quality images, video, and audio contents. However, training a GAN could\nbecome computationally expensive for large neural networks. In this work, we\npropose a hybrid quantum-classical architecture for improving GAN (denoted as\nQC-GAN). The performance was examed numerically by benchmarking with a\nclassical GAN using MindSpore Quantum on the task of hand-written image\ngeneration. The generator of the QC-GAN consists of a quantum variational\ncircuit together with a one-layer neural network, and the discriminator\nconsists of a traditional neural network. Leveraging the entangling and\nexpressive power of quantum circuits, our hybrid architecture achieved better\nperformance (Frechet Inception Distance) than the classical GAN, with much\nfewer training parameters and number of iterations for convergence. We have\nalso demonstrated the superiority of QC-GAN over an alternative quantum GAN,\nnamely pathGAN, which could hardly generate 16$\\times$16 or larger images. This\nwork demonstrates the value of combining ideas from quantum computing with\nmachine learning for both areas of Quantum-for-AI and AI-for-Quantum.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01791v1",
    "published_date": "2024-02-02 03:59:35 UTC",
    "updated_date": "2024-02-02 03:59:35 UTC"
  },
  {
    "arxiv_id": "2402.01118v3",
    "title": "PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language Models",
    "authors": [
      "Sihao Hu",
      "Tiansheng Huang",
      "Ling Liu"
    ],
    "abstract": "We introduce PokeLLMon, the first LLM-embodied agent that achieves\nhuman-parity performance in tactical battle games, as demonstrated in Pokemon\nbattles. The design of PokeLLMon incorporates three key strategies: (i)\nIn-context reinforcement learning that instantly consumes text-based feedback\nderived from battles to iteratively refine the policy; (ii) Knowledge-augmented\ngeneration that retrieves external knowledge to counteract hallucination and\nenables the agent to act timely and properly; (iii) Consistent action\ngeneration to mitigate the panic switching phenomenon when the agent faces a\npowerful opponent and wants to elude the battle. We show that online battles\nagainst human demonstrates PokeLLMon's human-like battle strategies and\njust-in-time decision making, achieving 49% of win rate in the Ladder\ncompetitions and 56% of win rate in the invited battles. Our implementation and\nplayable battle logs are available at: https://github.com/git-disl/PokeLLMon.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01118v3",
    "published_date": "2024-02-02 03:22:12 UTC",
    "updated_date": "2024-04-02 15:46:35 UTC"
  },
  {
    "arxiv_id": "2402.01114v1",
    "title": "Double-Dip: Thwarting Label-Only Membership Inference Attacks with Transfer Learning and Randomization",
    "authors": [
      "Arezoo Rajabi",
      "Reeya Pimple",
      "Aiswarya Janardhanan",
      "Surudhi Asokraj",
      "Bhaskar Ramasubramanian",
      "Radha Poovendran"
    ],
    "abstract": "Transfer learning (TL) has been demonstrated to improve DNN model performance\nwhen faced with a scarcity of training samples. However, the suitability of TL\nas a solution to reduce vulnerability of overfitted DNNs to privacy attacks is\nunexplored. A class of privacy attacks called membership inference attacks\n(MIAs) aim to determine whether a given sample belongs to the training dataset\n(member) or not (nonmember). We introduce Double-Dip, a systematic empirical\nstudy investigating the use of TL (Stage-1) combined with randomization\n(Stage-2) to thwart MIAs on overfitted DNNs without degrading classification\naccuracy. Our study examines the roles of shared feature space and parameter\nvalues between source and target models, number of frozen layers, and\ncomplexity of pretrained models. We evaluate Double-Dip on three (Target,\nSource) dataset paris: (i) (CIFAR-10, ImageNet), (ii) (GTSRB, ImageNet), (iii)\n(CelebA, VGGFace2). We consider four publicly available pretrained DNNs: (a)\nVGG-19, (b) ResNet-18, (c) Swin-T, and (d) FaceNet. Our experiments demonstrate\nthat Stage-1 reduces adversary success while also significantly increasing\nclassification accuracy of nonmembers against an adversary with either\nwhite-box or black-box DNN model access, attempting to carry out SOTA\nlabel-only MIAs. After Stage-2, success of an adversary carrying out a\nlabel-only MIA is further reduced to near 50%, bringing it closer to a random\nguess and showing the effectiveness of Double-Dip. Stage-2 of Double-Dip also\nachieves lower ASR and higher classification accuracy than regularization and\ndifferential privacy-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01114v1",
    "published_date": "2024-02-02 03:14:37 UTC",
    "updated_date": "2024-02-02 03:14:37 UTC"
  },
  {
    "arxiv_id": "2402.01111v1",
    "title": "Near-Optimal Reinforcement Learning with Self-Play under Adaptivity Constraints",
    "authors": [
      "Dan Qiao",
      "Yu-Xiang Wang"
    ],
    "abstract": "We study the problem of multi-agent reinforcement learning (MARL) with\nadaptivity constraints -- a new problem motivated by real-world applications\nwhere deployments of new policies are costly and the number of policy updates\nmust be minimized. For two-player zero-sum Markov Games, we design a (policy)\nelimination based algorithm that achieves a regret of $\\widetilde{O}(\\sqrt{H^3\nS^2 ABK})$, while the batch complexity is only $O(H+\\log\\log K)$. In the above,\n$S$ denotes the number of states, $A,B$ are the number of actions for the two\nplayers respectively, $H$ is the horizon and $K$ is the number of episodes.\nFurthermore, we prove a batch complexity lower bound\n$\\Omega(\\frac{H}{\\log_{A}K}+\\log\\log K)$ for all algorithms with\n$\\widetilde{O}(\\sqrt{K})$ regret bound, which matches our upper bound up to\nlogarithmic factors. As a byproduct, our techniques naturally extend to\nlearning bandit games and reward-free MARL within near optimal batch\ncomplexity. To the best of our knowledge, these are the first line of results\ntowards understanding MARL with low adaptivity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01111v1",
    "published_date": "2024-02-02 03:00:40 UTC",
    "updated_date": "2024-02-02 03:00:40 UTC"
  },
  {
    "arxiv_id": "2402.01790v1",
    "title": "An introduction to graphical tensor notation for mechanistic interpretability",
    "authors": [
      "Jordan K. Taylor"
    ],
    "abstract": "Graphical tensor notation is a simple way of denoting linear operations on\ntensors, originating from physics. Modern deep learning consists almost\nentirely of operations on or between tensors, so easily understanding tensor\noperations is quite important for understanding these systems. This is\nespecially true when attempting to reverse-engineer the algorithms learned by a\nneural network in order to understand its behavior: a field known as\nmechanistic interpretability. It's often easy to get confused about which\noperations are happening between tensors and lose sight of the overall\nstructure, but graphical tensor notation makes it easier to parse things at a\nglance and see interesting equivalences. The first half of this document\nintroduces the notation and applies it to some decompositions (SVD, CP, Tucker,\nand tensor network decompositions), while the second half applies it to some\nexisting some foundational approaches for mechanistically understanding\nlanguage models, loosely following ``A Mathematical Framework for Transformer\nCircuits'', then constructing an example ``induction head'' circuit in\ngraphical tensor notation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 75 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01790v1",
    "published_date": "2024-02-02 02:56:01 UTC",
    "updated_date": "2024-02-02 02:56:01 UTC"
  },
  {
    "arxiv_id": "2402.01107v3",
    "title": "Simulation of Graph Algorithms with Looped Transformers",
    "authors": [
      "Artur Back de Luca",
      "Kimon Fountoulakis"
    ],
    "abstract": "The execution of graph algorithms using neural networks has recently\nattracted significant interest due to promising empirical progress. This\nmotivates further understanding of how neural networks can replicate reasoning\nsteps with relational data. In this work, we study the ability of transformer\nnetworks to simulate algorithms on graphs from a theoretical perspective. The\narchitecture we use is a looped transformer with extra attention heads that\ninteract with the graph. We prove by construction that this architecture can\nsimulate individual algorithms such as Dijkstra's shortest path, Breadth- and\nDepth-First Search, and Kosaraju's strongly connected components, as well as\nmultiple algorithms simultaneously. The number of parameters in the networks\ndoes not increase with the input graph size, which implies that the networks\ncan simulate the above algorithms for any graph. Despite this property, we show\na limit to simulation in our solution due to finite precision. Finally, we show\na Turing Completeness result with constant width when the extra attention heads\nare utilized.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "55 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01107v3",
    "published_date": "2024-02-02 02:48:03 UTC",
    "updated_date": "2024-10-01 20:30:37 UTC"
  },
  {
    "arxiv_id": "2402.01789v2",
    "title": "The Political Preferences of LLMs",
    "authors": [
      "David Rozado"
    ],
    "abstract": "I report here a comprehensive analysis about the political preferences\nembedded in Large Language Models (LLMs). Namely, I administer 11 political\norientation tests, designed to identify the political preferences of the test\ntaker, to 24 state-of-the-art conversational LLMs, both closed and open source.\nWhen probed with questions/statements with political connotations, most\nconversational LLMs tend to generate responses that are diagnosed by most\npolitical test instruments as manifesting preferences for left-of-center\nviewpoints. This does not appear to be the case for five additional base (i.e.\nfoundation) models upon which LLMs optimized for conversation with humans are\nbuilt. However, the weak performance of the base models at coherently answering\nthe tests' questions makes this subset of results inconclusive. Finally, I\ndemonstrate that LLMs can be steered towards specific locations in the\npolitical spectrum through Supervised Fine-Tuning (SFT) with only modest\namounts of politically aligned data, suggesting SFT's potential to embed\npolitical orientation in LLMs. With LLMs beginning to partially displace\ntraditional information sources like search engines and Wikipedia, the societal\nimplications of political biases embedded in LLMs are substantial.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01789v2",
    "published_date": "2024-02-02 02:43:10 UTC",
    "updated_date": "2024-06-02 04:48:36 UTC"
  },
  {
    "arxiv_id": "2402.01788v2",
    "title": "LitLLM: A Toolkit for Scientific Literature Review",
    "authors": [
      "Shubham Agarwal",
      "Gaurav Sahu",
      "Abhay Puri",
      "Issam H. Laradji",
      "Krishnamurthy DJ Dvijotham",
      "Jason Stanley",
      "Laurent Charlin",
      "Christopher Pal"
    ],
    "abstract": "Conducting literature reviews for scientific papers is essential for\nunderstanding research, its limitations, and building on existing work. It is a\ntedious task which makes an automatic literature review generator appealing.\nUnfortunately, many existing works that generate such reviews using Large\nLanguage Models (LLMs) have significant limitations. They tend to\nhallucinate-generate non-factual information-and ignore the latest research\nthey have not been trained on. To address these limitations, we propose a\ntoolkit that operates on Retrieval Augmented Generation (RAG) principles,\nspecialized prompting and instructing techniques with the help of LLMs. Our\nsystem first initiates a web search to retrieve relevant papers by summarizing\nuser-provided abstracts into keywords using an off-the-shelf LLM. Authors can\nenhance the search by supplementing it with relevant papers or keywords,\ncontributing to a tailored retrieval process. Second, the system re-ranks the\nretrieved papers based on the user-provided abstract. Finally, the related work\nsection is generated based on the re-ranked results and the abstract. There is\na substantial reduction in time and effort for literature review compared to\ntraditional methods, establishing our toolkit as an efficient alternative. Our\nproject page including the demo and toolkit can be accessed here:\nhttps://litllm.github.io",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01788v2",
    "published_date": "2024-02-02 02:41:28 UTC",
    "updated_date": "2025-03-21 14:49:10 UTC"
  },
  {
    "arxiv_id": "2402.01103v3",
    "title": "Compositional Generative Modeling: A Single Model is Not All You Need",
    "authors": [
      "Yilun Du",
      "Leslie Kaelbling"
    ],
    "abstract": "Large monolithic generative models trained on massive amounts of data have\nbecome an increasingly dominant approach in AI research. In this paper, we\nargue that we should instead construct large generative systems by composing\nsmaller generative models together. We show how such a compositional generative\napproach enables us to learn distributions in a more data-efficient manner,\nenabling generalization to parts of the data distribution unseen at training\ntime. We further show how this enables us to program and construct new\ngenerative models for tasks completely unseen at training. Finally, we show\nthat in many cases, we can discover separate compositional components from\ndata.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024 (Position Track)",
    "pdf_url": "http://arxiv.org/pdf/2402.01103v3",
    "published_date": "2024-02-02 02:40:51 UTC",
    "updated_date": "2024-06-03 23:30:33 UTC"
  },
  {
    "arxiv_id": "2402.05941v1",
    "title": "Character-based Outfit Generation with Vision-augmented Style Extraction via LLMs",
    "authors": [
      "Najmeh Forouzandehmehr",
      "Yijie Cao",
      "Nikhil Thakurdesai",
      "Ramin Giahi",
      "Luyi Ma",
      "Nima Farrokhsiar",
      "Jianpeng Xu",
      "Evren Korpeoglu",
      "Kannan Achan"
    ],
    "abstract": "The outfit generation problem involves recommending a complete outfit to a\nuser based on their interests. Existing approaches focus on recommending items\nbased on anchor items or specific query styles but do not consider customer\ninterests in famous characters from movie, social media, etc. In this paper, we\ndefine a new Character-based Outfit Generation (COG) problem, designed to\naccurately interpret character information and generate complete outfit sets\naccording to customer specifications such as age and gender. To tackle this\nproblem, we propose a novel framework LVA-COG that leverages Large Language\nModels (LLMs) to extract insights from customer interests (e.g., character\ninformation) and employ prompt engineering techniques for accurate\nunderstanding of customer preferences. Additionally, we incorporate\ntext-to-image models to enhance the visual understanding and generation\n(factual or counterfactual) of cohesive outfits. Our framework integrates LLMs\nwith text-to-image models and improves the customer's approach to fashion by\ngenerating personalized recommendations. With experiments and case studies, we\ndemonstrate the effectiveness of our solution from multiple dimensions.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "7 pages, 4 figures, IEEE Big Data 2023 3rd Workshop on Multimodal AI\n  (MMAI 2023), IEEE BigData 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.05941v1",
    "published_date": "2024-02-02 02:11:31 UTC",
    "updated_date": "2024-02-02 02:11:31 UTC"
  },
  {
    "arxiv_id": "2402.01096v1",
    "title": "Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance",
    "authors": [
      "Wenqi Wei",
      "Ling Liu"
    ],
    "abstract": "Emerging Distributed AI systems are revolutionizing big data computing and\ndata processing capabilities with growing economic and societal impact.\nHowever, recent studies have identified new attack surfaces and risks caused by\nsecurity, privacy, and fairness issues in AI systems. In this paper, we review\nrepresentative techniques, algorithms, and theoretical foundations for\ntrustworthy distributed AI through robustness guarantee, privacy protection,\nand fairness awareness in distributed learning. We first provide a brief\noverview of alternative architectures for distributed learning, discuss\ninherent vulnerabilities for security, privacy, and fairness of AI algorithms\nin distributed learning, and analyze why these problems are present in\ndistributed learning regardless of specific architectures. Then we provide a\nunique taxonomy of countermeasures for trustworthy distributed AI, covering (1)\nrobustness to evasion attacks and irregular queries at inference, and\nrobustness to poisoning attacks, Byzantine attacks, and irregular data\ndistribution during training; (2) privacy protection during distributed\nlearning and model inference at deployment; and (3) AI fairness and governance\nwith respect to both data and models. We conclude with a discussion on open\nchallenges and future research directions toward trustworthy distributed AI,\nsuch as the need for trustworthy AI policy guidelines, the AI\nresponsibility-utility co-design, and incentives and compliance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Manuscript accepted to ACM Computing Surveys",
    "pdf_url": "http://arxiv.org/pdf/2402.01096v1",
    "published_date": "2024-02-02 01:58:58 UTC",
    "updated_date": "2024-02-02 01:58:58 UTC"
  },
  {
    "arxiv_id": "2402.01095v1",
    "title": "How many views does your deep neural network use for prediction?",
    "authors": [
      "Keisuke Kawano",
      "Takuro Kutsuna",
      "Keisuke Sano"
    ],
    "abstract": "The generalization ability of Deep Neural Networks (DNNs) is still not fully\nunderstood, despite numerous theoretical and empirical analyses. Recently,\nAllen-Zhu & Li (2023) introduced the concept of multi-views to explain the\ngeneralization ability of DNNs, but their main target is ensemble or distilled\nmodels, and no method for estimating multi-views used in a prediction of a\nspecific input is discussed. In this paper, we propose Minimal Sufficient Views\n(MSVs), which is similar to multi-views but can be efficiently computed for\nreal images. MSVs is a set of minimal and distinct features in an input, each\nof which preserves a model's prediction for the input. We empirically show that\nthere is a clear relationship between the number of MSVs and prediction\naccuracy across models, including convolutional and transformer models,\nsuggesting that a multi-view like perspective is also important for\nunderstanding the generalization ability of (non-ensemble or non-distilled)\nDNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01095v1",
    "published_date": "2024-02-02 01:58:16 UTC",
    "updated_date": "2024-02-02 01:58:16 UTC"
  },
  {
    "arxiv_id": "2402.01077v2",
    "title": "Recent Advances in Predictive Modeling with Electronic Health Records",
    "authors": [
      "Jiaqi Wang",
      "Junyu Luo",
      "Muchao Ye",
      "Xiaochen Wang",
      "Yuan Zhong",
      "Aofei Chang",
      "Guanjie Huang",
      "Ziyi Yin",
      "Cao Xiao",
      "Jimeng Sun",
      "Fenglong Ma"
    ],
    "abstract": "The development of electronic health records (EHR) systems has enabled the\ncollection of a vast amount of digitized patient data. However, utilizing EHR\ndata for predictive modeling presents several challenges due to its unique\ncharacteristics. With the advancements in machine learning techniques, deep\nlearning has demonstrated its superiority in various applications, including\nhealthcare. This survey systematically reviews recent advances in deep\nlearning-based predictive models using EHR data. Specifically, we begin by\nintroducing the background of EHR data and providing a mathematical definition\nof the predictive modeling task. We then categorize and summarize predictive\ndeep models from multiple perspectives. Furthermore, we present benchmarks and\ntoolkits relevant to predictive modeling in healthcare. Finally, we conclude\nthis survey by discussing open challenges and suggesting promising directions\nfor future research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by IJCAI 24 Survey Track",
    "pdf_url": "http://arxiv.org/pdf/2402.01077v2",
    "published_date": "2024-02-02 00:31:01 UTC",
    "updated_date": "2024-08-13 05:35:57 UTC"
  },
  {
    "arxiv_id": "2405.01540v1",
    "title": "Universal Imitation Games",
    "authors": [
      "Sridhar Mahadevan"
    ],
    "abstract": "Alan Turing proposed in 1950 a framework called an imitation game to decide\nif a machine could think. Using mathematics developed largely after Turing --\ncategory theory -- we analyze a broader class of universal imitation games\n(UIGs), which includes static, dynamic, and evolutionary games. In static\ngames, the participants are in a steady state. In dynamic UIGs, \"learner\"\nparticipants are trying to imitate \"teacher\" participants over the long run. In\nevolutionary UIGs, the participants are competing against each other in an\nevolutionary game, and participants can go extinct and be replaced by others\nwith higher fitness. We use the framework of category theory -- in particular,\ntwo influential results by Yoneda -- to characterize each type of imitation\ngame. Universal properties in categories are defined by initial and final\nobjects. We characterize dynamic UIGs where participants are learning by\ninductive inference as initial algebras over well-founded sets, and contrast\nthem with participants learning by conductive inference over the final\ncoalgebra of non-well-founded sets. We briefly discuss the extension of our\ncategorical framework for UIGs to imitation games on quantum computers.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "98 pages. arXiv admin note: substantial text overlap with\n  arXiv:2402.18732",
    "pdf_url": "http://arxiv.org/pdf/2405.01540v1",
    "published_date": "2024-02-02 00:07:15 UTC",
    "updated_date": "2024-02-02 00:07:15 UTC"
  }
]