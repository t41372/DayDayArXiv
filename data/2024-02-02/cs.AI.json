{
  "date": "2024-02-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-02 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLM）的应用、生成模型的创新、强化学习和因果推理等话题。重点在于 LLM 在教育、决策和生成内容中的潜力，令人印象深刻的文章包括 Yoshua Bengio 参与的因果发现框架，以及生成 AI 在教育和视频合成中的新进展。接下来，我将挑选并简要讨论部分重要论文，先聊 LLM 相关的高话题度文章，再聊生成模型和强化学习，最后快速掠过其他领域。\n\n### LLM 和决策相关\n- **Bringing Generative AI to Adaptive Learning in Education (教育中的生成 AI)**  \n  这篇论文讨论了生成 AI（如 LLM）与自适应学习的结合，强调其在提升学习效率中的益处。主要贡献是提出一个位置论文，分析了益处、挑战和潜力，指出这种整合可能推动教育领域的下一阶段发展。\n\n- **KTO: Model Alignment as Prospect Theoretic Optimization (模型对齐作为前景理论优化)**  \n  作者使用前景理论优化 LLM 与人类反馈的模型对齐，提出一种新损失函数。主要发现是，该方法在多个数据集上匹配或超过传统偏好学习方法，展示了 LLM 在决策中的高效性。\n\n- **The Political Preferences of LLMs (LLM 的政治偏好)**  \n  这篇调查了 24 个 LLM 的政治倾向，通过测试发现大多数 LLM 倾向于左倾观点，并探讨了微调的影响。主要贡献是揭示 LLM 偏见的社会影响，并证明通过少量数据微调可以调整偏好。\n\n- **TrustAgent: Towards Safe and Trustworthy LLM-based Agents (LLM 代理的安全性)**  \n  论文提出一个基于代理宪章的框架，用于 LLM 代理的安全防护。主要发现是通过预规划、规划中和后规划策略，显著减少 LLM 代理的安全风险。\n\n- **PiCO: Peer Review in LLMs based on the Consistency Optimization (LLM 中的同行评审)**  \n  作者设计了一个优化框架，让 LLM 模拟同行评审过程。主要贡献是使用一致性优化来评估 LLM 能力层次，实验显示其在多数据集上有效。\n\n- **On Catastrophic Inheritance of Large Foundation Models (大型基础模型的灾难性继承)**  \n  这篇位置论文分析了基础模型从预训练数据继承的弱点，如偏差和泛化问题。主要发现是提出 UIM 框架来理解和缓解这些问题。\n\n### 生成模型和图像处理\n- **Boximator: Generating Rich and Controllable Motions for Video Synthesis (生成丰富的可控运动用于视频合成)**  \n  论文引入 Boximator 框架，用于生成可控视频运动。主要贡献是通过硬盒和软盒约束提升视频扩散模型的质量，实验显示其在视频生成中超越基线。\n\n- **SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training? (全合成 CLIP 训练的准备度)**  \n  作者使用合成数据训练 CLIP 模型，主要发现是合成数据能提升图像生成性能，并公开了代码和数据集。\n\n- **Mobile Fitting Room: On-device Virtual Try-on via Diffusion Models (基于扩散模型的移动虚拟试衣)**  \n  这篇提出一个设备端虚拟试衣系统，使用扩散模型处理图像。主要贡献是解决背景和姿势适应问题，提供隐私保护和交互体验。\n\n- **Explaining latent representations of generative models with large multimodal models (使用多模态模型解释生成模型的潜在表示)**  \n  论文开发了 NeSyGPT 框架，用于解释生成模型的潜在变量。主要发现是通过多模态模型减少标注需求，提升解释可扩展性。\n\n### 强化学习和因果推理\n- **Efficient Causal Graph Discovery Using Large Language Models (使用 LLM 的高效因果图发现)**  \n  Yoshua Bengio 参与的这篇论文提出一个 LLM 框架，用于因果图发现。主要贡献是结合检索增强和主动学习，显著提高效率和准确性。\n\n- **Inverse Reinforcement Learning by Estimating Expertise of Demonstrators (通过估计演示者专业性进行逆强化学习)**  \n  作者引入 IRLEED 框架，处理次优演示数据。主要发现是无需先验知识即可从多样演示中学习最优策略。\n\n- **BAT: Learning to Reason about Spatial Sounds with Large Language Models (使用 LLM 学习空间声音推理)**  \n  论文提出 BAT 模型，用于空间音频推理。主要贡献是结合 LLM 和音频编码器，提升声音事件检测和定位性能。\n\n其他论文涉及领域如医疗 AI、隐私保护和图学习等，但相对不那么核心，我快速掠过：\n- **OPSurv: Orthogonal Polynomials Quadrature Algorithm for Survival Analysis (正交多项式求积算法用于生存分析)**：提出新算法处理生存分析中的过拟合问题。\n- **A General Framework for Learning from Weak Supervision (弱监督学习的通用框架)**：开发 GLWS 框架，提升弱监督场景下的可扩展性。\n- **Preference Poisoning Attacks on Reward Model Learning (奖励模型学习的偏好攻击)**：分析攻击方法及其防御。\n- **A Survey on Few-Shot Learning on Graphs (图上的少样本学习调查)**：综述图少样本学习方法。\n- **From Words to Molecules: A Survey on Large Language Models in Chemistry (从单词到分子：LLM 在化学中的调查)**：综述 LLM 在化学领域的应用。\n\n总之，今天的论文突显了 LLM 在决策和生成中的潜力，但也暴露了偏见和安全挑战。未来研究可聚焦于 LLM 的鲁棒性和多模态整合。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2402.14601v3",
      "title": "Bringing Generative AI to Adaptive Learning in Education",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Li",
        "Tianlong Xu",
        "Chaoli Zhang",
        "Eason Chen",
        "Jing Liang",
        "Xing Fan",
        "Haoyang Li",
        "Jiliang Tang",
        "Qingsong Wen"
      ],
      "abstract": "The recent surge in generative AI technologies, such as large language models\nand diffusion models, has boosted the development of AI applications in various\ndomains, including science, finance, and education. Concurrently, adaptive\nlearning, a concept that has gained substantial interest in the educational\nsphere, has proven its efficacy in enhancing students' learning efficiency. In\nthis position paper, we aim to shed light on the intersectional studies of\nthese two methods, which combine generative AI with adaptive learning concepts.\nBy presenting discussions about the benefits, challenges, and potentials in\nthis field, we argue that this union will contribute significantly to the\ndevelopment of the next-stage learning format in education.",
      "tldr_zh": "这篇立场论文探讨了生成式 AI（如 large language models 和 diffusion models）与自适应学习在教育领域的结合，旨在提升学生的学习效率。论文讨论了这种整合的好处（如个性化教育体验）、潜在挑战（如技术限制和伦理问题），以及未来的发展潜力。作者认为，这种交叉应用将为教育的下一阶段学习格式带来重大贡献。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14601v3",
      "published_date": "2024-02-02 23:54:51 UTC",
      "updated_date": "2024-06-28 23:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:21:15.214143"
    },
    {
      "arxiv_id": "2402.01955v1",
      "title": "OPSurv: Orthogonal Polynomials Quadrature Algorithm for Survival Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Lilian W. Bialokozowicz",
        "Hoang M. Le",
        "Tristan Sylvain",
        "Peter A. I. Forsyth",
        "Vineel Nagisetty",
        "Greg Mori"
      ],
      "abstract": "This paper introduces the Orthogonal Polynomials Quadrature Algorithm for\nSurvival Analysis (OPSurv), a new method providing time-continuous functional\noutputs for both single and competing risks scenarios in survival analysis.\nOPSurv utilizes the initial zero condition of the Cumulative Incidence function\nand a unique decomposition of probability densities using orthogonal\npolynomials, allowing it to learn functional approximation coefficients for\neach risk event and construct Cumulative Incidence Function estimates via\nGauss--Legendre quadrature. This approach effectively counters overfitting,\nparticularly in competing risks scenarios, enhancing model expressiveness and\ncontrol. The paper further details empirical validations and theoretical\njustifications of OPSurv, highlighting its robust performance as an advancement\nin survival analysis with competing risks.",
      "tldr_zh": "本研究提出了一种新的生存分析算法OPSurv（Orthogonal Polynomials Quadrature Algorithm for Survival Analysis），它提供时间连续的功能输出，适用于单风险和竞争风险场景。OPSurv利用Cumulative Incidence Function的初始零条件以及正交多项式对概率密度的独特分解，通过学习功能逼近系数并采用Gauss-Legendre quadrature来构建Cumulative Incidence Function估计，从而有效防止过拟合并提升模型的表现力和控制力。该方法经经验验证和理论证明，在竞争风险生存分析中表现出色，代表了该领域的显著进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.FA",
        "68W25 (Primary), 65Z05 (Secondary)",
        "I.2.0; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01955v1",
      "published_date": "2024-02-02 23:26:09 UTC",
      "updated_date": "2024-02-02 23:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:21:28.558057"
    },
    {
      "arxiv_id": "2402.01928v1",
      "title": "Robust Counterfactual Explanations in Machine Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Junqi Jiang",
        "Francesco Leofante",
        "Antonio Rago",
        "Francesca Toni"
      ],
      "abstract": "Counterfactual explanations (CEs) are advocated as being ideally suited to\nproviding algorithmic recourse for subjects affected by the predictions of\nmachine learning models. While CEs can be beneficial to affected individuals,\nrecent work has exposed severe issues related to the robustness of\nstate-of-the-art methods for obtaining CEs. Since a lack of robustness may\ncompromise the validity of CEs, techniques to mitigate this risk are in order.\nIn this survey, we review works in the rapidly growing area of robust CEs and\nperform an in-depth analysis of the forms of robustness they consider. We also\ndiscuss existing solutions and their limitations, providing a solid foundation\nfor future developments.",
      "tldr_zh": "该论文对机器学习中的鲁棒反事实解释（Counterfactual Explanations, CEs）进行了全面调查，强调CEs在提供算法补救（algorithmic recourse）方面的潜力，但指出现有方法存在严重鲁棒性问题，可能影响解释的有效性。作者分析了各种形式的robustness，包括对模型扰动和数据变化的抵抗力，并审视了现有解决方案及其局限性。最终，该调查为开发更可靠的CEs技术奠定了基础，促进未来机器学习解释的可信度提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01928v1",
      "published_date": "2024-02-02 21:56:58 UTC",
      "updated_date": "2024-02-02 21:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:21:41.144569"
    },
    {
      "arxiv_id": "2402.01922v3",
      "title": "A General Framework for Learning from Weak Supervision",
      "title_zh": "弱监督学习的通用框架",
      "authors": [
        "Hao Chen",
        "Jindong Wang",
        "Lei Feng",
        "Xiang Li",
        "Yidong Wang",
        "Xing Xie",
        "Masashi Sugiyama",
        "Rita Singh",
        "Bhiksha Raj"
      ],
      "abstract": "Weakly supervised learning generally faces challenges in applicability to\nvarious scenarios with diverse weak supervision and in scalability due to the\ncomplexity of existing algorithms, thereby hindering the practical deployment.\nThis paper introduces a general framework for learning from weak supervision\n(GLWS) with a novel algorithm. Central to GLWS is an Expectation-Maximization\n(EM) formulation, adeptly accommodating various weak supervision sources,\nincluding instance partial labels, aggregate statistics, pairwise observations,\nand unlabeled data. We further present an advanced algorithm that significantly\nsimplifies the EM computational demands using a Non-deterministic Finite\nAutomaton (NFA) along with a forward-backward algorithm, which effectively\nreduces time complexity from quadratic or factorial often required in existing\nsolutions to linear scale. The problem of learning from arbitrary weak\nsupervision is therefore converted to the NFA modeling of them. GLWS not only\nenhances the scalability of machine learning models but also demonstrates\nsuperior performance and versatility across 11 weak supervision scenarios. We\nhope our work paves the way for further advancements and practical deployment\nin this field.",
      "tldr_zh": "本论文提出一个通用框架 GLWS，用于从弱监督中学习，以解决弱监督学习在各种场景中的适用性和可扩展性挑战。GLWS 的核心是 Expectation-Maximization (EM) 公式，能够处理多种弱监督来源，如实例部分标签、聚合统计、成对观察和无标签数据。该框架引入一个高级算法，利用 Non-deterministic Finite Automaton (NFA) 和前向-后向算法，将计算复杂度从二次或阶乘级降至线性级，从而将弱监督问题转化为 NFA 建模。实验结果显示，GLWS 在 11 个弱监督场景中表现出色，提高了机器学习模型的可扩展性和性能，为该领域的实际部署铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 20 tables, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01922v3",
      "published_date": "2024-02-02 21:48:50 UTC",
      "updated_date": "2024-06-05 16:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:21:53.569636"
    },
    {
      "arxiv_id": "2402.01920v2",
      "title": "Preference Poisoning Attacks on Reward Model Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junlin Wu",
        "Jiongxiao Wang",
        "Chaowei Xiao",
        "Chenguang Wang",
        "Ning Zhang",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "Learning reward models from pairwise comparisons is a fundamental component\nin a number of domains, including autonomous control, conversational agents,\nand recommendation systems, as part of a broad goal of aligning automated\ndecisions with user preferences. These approaches entail collecting preference\ninformation from people, with feedback often provided anonymously. Since\npreferences are subjective, there is no gold standard to compare against; yet,\nreliance of high-impact systems on preference learning creates a strong\nmotivation for malicious actors to skew data collected in this fashion to their\nends. We investigate the nature and extent of this vulnerability by considering\nan attacker who can flip a small subset of preference comparisons to either\npromote or demote a target outcome. We propose two classes of algorithmic\napproaches for these attacks: a gradient-based framework, and several variants\nof rank-by-distance methods. Next, we evaluate the efficacy of best attacks in\nboth these classes in successfully achieving malicious goals on datasets from\nthree domains: autonomous control, recommendation system, and textual\nprompt-response preference learning. We find that the best attacks are often\nhighly successful, achieving in the most extreme case 100\\% success rate with\nonly 0.3\\% of the data poisoned. However, \\emph{which} attack is best can vary\nsignificantly across domains. In addition, we observe that the simpler and more\nscalable rank-by-distance approaches are often competitive with, and on\noccasion significantly outperform, gradient-based methods. Finally, we show\nthat state-of-the-art defenses against other classes of poisoning attacks\nexhibit limited efficacy in our setting.",
      "tldr_zh": "这篇论文探讨了在reward model learning中，偏好投毒攻击（preference poisoning attacks）的风险，攻击者通过翻转少量成对偏好比较来操纵系统决策，影响自动控制、对话代理和推荐系统等领域。研究者提出了两种攻击算法：gradient-based framework和几种rank-by-distance methods，以推广或降级目标结果。实验在自动控制、推荐系统及文本提示-响应偏好学习数据集上评估，发现最佳攻击高度有效，例如仅投毒0.3%的数据即可实现100%的成功率。论文还指出，最佳攻击因领域而异，简单可扩展的rank-by-distance方法有时优于gradient-based方法，且现有投毒攻击防御措施在这一场景下效果有限。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01920v2",
      "published_date": "2024-02-02 21:45:24 UTC",
      "updated_date": "2024-10-08 20:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:22:08.151264"
    },
    {
      "arxiv_id": "2402.01909v2",
      "title": "On Catastrophic Inheritance of Large Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Chen",
        "Bhiksha Raj",
        "Xing Xie",
        "Jindong Wang"
      ],
      "abstract": "Large foundation models (LFMs) are claiming incredible performances. Yet\ngreat concerns have been raised about their mythic and uninterpreted potentials\nnot only in machine learning, but also in various other disciplines. In this\nposition paper, we propose to identify a neglected issue deeply rooted in LFMs:\nCatastrophic Inheritance, describing the weaknesses and limitations inherited\nfrom biased large-scale pre-training data to behaviors of LFMs on the\ndownstream tasks, including samples that are corrupted, long-tailed, noisy,\nout-of-distributed, to name a few. Such inheritance can potentially cause\ncatastrophes to downstream applications, such as bias, lack of generalization,\ndeteriorated performance, security vulnerability, privacy leakage, and value\nmisalignment. We discuss the challenges behind this issue and propose UIM, a\nframework to Understand the catastrophic inheritance of LFMs from both\npre-training and downstream adaptation, Interpret the implications of\ncatastrophic inheritance on downstream tasks, and how to Mitigate it. UIM aims\nto unite both the machine learning and social sciences communities for more\nresponsible and promising AI development and deployment.",
      "tldr_zh": "这篇论文讨论了大型基础模型（LFMs）从偏置预训练数据中继承的弱点，即Catastrophic Inheritance，这种问题可能导致下游任务出现偏差、泛化能力不足、性能下降、安全漏洞、隐私泄露和价值不一致等灾难性后果。作者识别出这些继承问题源于数据问题，如损坏、长尾分布和噪声，并分析了其挑战。论文提出UIM框架，包括Understand（理解继承机制）、Interpret（解释下游影响）和Mitigate（缓解策略），旨在促进机器学习和社会科学社区的合作，实现更负责任的AI开发和部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by DMLR",
      "pdf_url": "http://arxiv.org/pdf/2402.01909v2",
      "published_date": "2024-02-02 21:21:55 UTC",
      "updated_date": "2024-10-23 00:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:22:17.586715"
    },
    {
      "arxiv_id": "2402.05943v1",
      "title": "A hybrid IndRNNLSTM approach for real-time anomaly detection in software-defined networks",
      "title_zh": "一种混合 IndRNNLSTM 方法用于软件定义网络中的实时异常检测",
      "authors": [
        "Sajjad Salem",
        "Salman Asoudeh"
      ],
      "abstract": "Anomaly detection in SDN using data flow prediction is a difficult task. This\nproblem is included in the category of time series and regression problems.\nMachine learning approaches are challenging in this field due to the manual\nselection of features. On the other hand, deep learning approaches have\nimportant features due to the automatic selection of features. Meanwhile,\nRNN-based approaches have been used the most. The LSTM and GRU approaches learn\ndependent entities well; on the other hand, the IndRNN approach learns\nnon-dependent entities in time series. The proposed approach tried to use a\ncombination of IndRNN and LSTM approaches to learn dependent and non-dependent\nfeatures. Feature selection approaches also provide a suitable view of features\nfor the models; for this purpose, four feature selection models, Filter,\nWrapper, Embedded, and Autoencoder were used. The proposed IndRNNLSTM\nalgorithm, in combination with Embedded, was able to achieve MAE=1.22 and\nRMSE=9.92 on NSL-KDD data.",
      "tldr_zh": "这篇论文提出了一种混合 IndRNNLSTM 方法，用于在软件定义网络(SDN)中进行实时异常检测，以解决时间序列预测中的特征学习挑战。方法结合 IndRNN（擅长非依赖实体）和 LSTM（擅长依赖实体）的优势，并使用 Filter、Wrapper、Embedded 和 Autoencoder 等特征选择技术来优化模型输入。该方法在 NSL-KDD 数据集上实现了 MAE=1.22 和 RMSE=9.92 的性能，展示了其在自动特征选择和异常检测准确性方面的显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05943v1",
      "published_date": "2024-02-02 20:41:55 UTC",
      "updated_date": "2024-02-02 20:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:22:28.557765"
    },
    {
      "arxiv_id": "2403.07890v2",
      "title": "$\\widetilde{O}(T^{-1})$ Convergence to (Coarse) Correlated Equilibria in Full-Information General-Sum Markov Games",
      "title_zh": "翻译失败",
      "authors": [
        "Weichao Mao",
        "Haoran Qiu",
        "Chen Wang",
        "Hubertus Franke",
        "Zbigniew Kalbarczyk",
        "Tamer Başar"
      ],
      "abstract": "No-regret learning has a long history of being closely connected to game\ntheory. Recent works have devised uncoupled no-regret learning dynamics that,\nwhen adopted by all the players in normal-form games, converge to various\nequilibrium solutions at a near-optimal rate of $\\widetilde{O}(T^{-1})$, a\nsignificant improvement over the $O(1/\\sqrt{T})$ rate of classic no-regret\nlearners. However, analogous convergence results are scarce in Markov games, a\nmore generic setting that lays the foundation for multi-agent reinforcement\nlearning. In this work, we close this gap by showing that the\noptimistic-follow-the-regularized-leader (OFTRL) algorithm, together with\nappropriate value update procedures, can find\n$\\widetilde{O}(T^{-1})$-approximate (coarse) correlated equilibria in\nfull-information general-sum Markov games within $T$ iterations. Numerical\nresults are also included to corroborate our theoretical findings.",
      "tldr_zh": "本文研究了无悔学习（no-regret learning）在全信息一般和Markov游戏中的应用，填补了现有工作在Markov游戏（多代理强化学习的基础）中缺乏$\\widetilde{O}(T^{-1})$收敛率的空白。作者证明了optimistic-follow-the-regularized-leader (OFTRL)算法结合适当的价值更新过程，能够在T迭代内实现$\\widetilde{O}(T^{-1})$近似（粗糙）相关均衡（(coarse) correlated equilibria）。实验结果验证了这一理论发现，与经典无悔学习器的$O(1/\\sqrt{T})$速率相比，取得了显著改善。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07890v2",
      "published_date": "2024-02-02 20:40:27 UTC",
      "updated_date": "2024-04-23 05:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:22:42.591601"
    },
    {
      "arxiv_id": "2402.01889v1",
      "title": "The Role of Foundation Models in Neuro-Symbolic Learning and Reasoning",
      "title_zh": "基础模型在神经符号学习和推理中的作用",
      "authors": [
        "Daniel Cunnington",
        "Mark Law",
        "Jorge Lobo",
        "Alessandra Russo"
      ],
      "abstract": "Neuro-Symbolic AI (NeSy) holds promise to ensure the safe deployment of AI\nsystems, as interpretable symbolic techniques provide formal behaviour\nguarantees. The challenge is how to effectively integrate neural and symbolic\ncomputation, to enable learning and reasoning from raw data. Existing pipelines\nthat train the neural and symbolic components sequentially require extensive\nlabelling, whereas end-to-end approaches are limited in terms of scalability,\ndue to the combinatorial explosion in the symbol grounding problem. In this\npaper, we leverage the implicit knowledge within foundation models to enhance\nthe performance in NeSy tasks, whilst reducing the amount of data labelling and\nmanual engineering. We introduce a new architecture, called NeSyGPT, which\nfine-tunes a vision-language foundation model to extract symbolic features from\nraw data, before learning a highly expressive answer set program to solve a\ndownstream task. Our comprehensive evaluation demonstrates that NeSyGPT has\nsuperior accuracy over various baselines, and can scale to complex NeSy tasks.\nFinally, we highlight the effective use of a large language model to generate\nthe programmatic interface between the neural and symbolic components,\nsignificantly reducing the amount of manual engineering required.",
      "tldr_zh": "这篇论文探讨了 Foundation Models 在 Neuro-Symbolic Learning and Reasoning 中的作用，旨在解决 Neuro-Symbolic AI (NeSy) 系统中神经和符号计算整合的挑战，例如顺序训练需要大量标注和端到端方法的扩展性问题。作者提出 NeSyGPT 架构，通过 fine-tune 视觉语言 Foundation Model 从原始数据提取符号特征，并结合 Answer Set Program 学习下游任务，从而减少数据标注和手动工程需求。实验评估表明，NeSyGPT 比各种基线模型具有更高的准确性和可扩展性，并利用 Large Language Model 生成神经与符号组件的程序接口，进一步降低了手动工程工作量。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2402.01889v1",
      "published_date": "2024-02-02 20:33:14 UTC",
      "updated_date": "2024-02-02 20:33:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:22:53.721936"
    },
    {
      "arxiv_id": "2402.01886v2",
      "title": "Inverse Reinforcement Learning by Estimating Expertise of Demonstrators",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Beliaev",
        "Ramtin Pedarsani"
      ],
      "abstract": "In Imitation Learning (IL), utilizing suboptimal and heterogeneous\ndemonstrations presents a substantial challenge due to the varied nature of\nreal-world data. However, standard IL algorithms consider these datasets as\nhomogeneous, thereby inheriting the deficiencies of suboptimal demonstrators.\nPrevious approaches to this issue rely on impractical assumptions like\nhigh-quality data subsets, confidence rankings, or explicit environmental\nknowledge. This paper introduces IRLEED, Inverse Reinforcement Learning by\nEstimating Expertise of Demonstrators, a novel framework that overcomes these\nhurdles without prior knowledge of demonstrator expertise. IRLEED enhances\nexisting Inverse Reinforcement Learning (IRL) algorithms by combining a general\nmodel for demonstrator suboptimality to address reward bias and action\nvariance, with a Maximum Entropy IRL framework to efficiently derive the\noptimal policy from diverse, suboptimal demonstrations. Experiments in both\nonline and offline IL settings, with simulated and human-generated data,\ndemonstrate IRLEED's adaptability and effectiveness, making it a versatile\nsolution for learning from suboptimal demonstrations.",
      "tldr_zh": "这篇论文解决了模仿学习(Imitation Learning, IL)中处理次优和异构演示数据的挑战，传统方法往往依赖不切实际的假设，如高质量数据子集或环境知识。作者提出IRLEED（Inverse Reinforcement Learning by Estimating Expertise of Demonstrators）框架，通过估计演示者专业知识来增强逆强化学习(Inverse Reinforcement Learning, IRL)算法，结合演示者次优性模型和Maximum Entropy IRL框架，以高效从多样化演示中推导最优策略。实验在在线和离线IL设置中使用模拟及人类生成数据，证明了IRLEED的适应性和有效性，使其成为从次优演示中学习的通用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures, extended version of AAAI publication",
      "pdf_url": "http://arxiv.org/pdf/2402.01886v2",
      "published_date": "2024-02-02 20:21:09 UTC",
      "updated_date": "2024-12-13 18:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:23:05.803821"
    },
    {
      "arxiv_id": "2402.01881v3",
      "title": "Large Language Model Agent for Hyper-Parameter Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Siyi Liu",
        "Chen Gao",
        "Yong Li"
      ],
      "abstract": "Hyperparameter optimization is critical in modern machine learning, requiring\nexpert knowledge, numerous trials, and high computational and human resources.\nDespite the advancements in Automated Machine Learning (AutoML), challenges in\nterms of trial efficiency, setup complexity, and interoperability still\npersist. To address these issues, we introduce a novel paradigm leveraging\nLarge Language Models (LLMs) to automate hyperparameter optimization across\ndiverse machine learning tasks, which is named AgentHPO (short for LLM\nAgent-based Hyperparameter Optimization). Specifically, AgentHPO processes the\ntask information autonomously, conducts experiments with specific\nhyperparameters (HPs), and iteratively optimizes them based on historical\ntrials. This human-like optimization process largely reduces the number of\nrequired trials, simplifies the setup process, and enhances interpretability\nand user trust, compared to traditional AutoML methods. Extensive empirical\nexperiments conducted on 12 representative machine-learning tasks indicate that\nAgentHPO not only matches but also often surpasses the best human trials in\nterms of performance while simultaneously providing explainable results.\nFurther analysis sheds light on the strategies employed by the LLM in\noptimizing these tasks, highlighting its effectiveness and adaptability in\nvarious scenarios.",
      "tldr_zh": "这篇论文提出 AgentHPO，一种基于 Large Language Models (LLMs) 的代理系统，用于自动化超参数优化 (HPO)，以解决传统 Automated Machine Learning (AutoML) 在试验效率、设置复杂性和互操作性方面的挑战。AgentHPO 通过自主处理任务信息、进行实验并基于历史试验迭代优化超参数，显著减少了试验次数并提升了可解释性和用户信任。在 12 个代表性机器学习任务上的实验显示，AgentHPO 不仅匹配或超过最佳人类试验性能，还提供了详细的优化策略分析，证明了其有效性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01881v3",
      "published_date": "2024-02-02 20:12:05 UTC",
      "updated_date": "2025-02-26 13:57:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:23:20.570138"
    },
    {
      "arxiv_id": "2402.01877v1",
      "title": "Mobile Fitting Room: On-device Virtual Try-on via Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Blalock",
        "David Munechika",
        "Harsha Karanth",
        "Alec Helbling",
        "Pratham Mehta",
        "Seongmin Lee",
        "Duen Horng Chau"
      ],
      "abstract": "The growing digital landscape of fashion e-commerce calls for interactive and\nuser-friendly interfaces for virtually trying on clothes. Traditional try-on\nmethods grapple with challenges in adapting to diverse backgrounds, poses, and\nsubjects. While newer methods, utilizing the recent advances of diffusion\nmodels, have achieved higher-quality image generation, the human-centered\ndimensions of mobile interface delivery and privacy concerns remain largely\nunexplored. We present Mobile Fitting Room, the first on-device diffusion-based\nvirtual try-on system. To address multiple inter-related technical challenges\nsuch as high-quality garment placement and model compression for mobile\ndevices, we present a novel technical pipeline and an interface design that\nenables privacy preservation and user customization. A usage scenario\nhighlights how our tool can provide a seamless, interactive virtual try-on\nexperience for customers and provide a valuable service for fashion e-commerce\nbusinesses.",
      "tldr_zh": "该研究针对时尚电商的虚拟试衣需求，提出 Mobile Fitting Room，这是一个基于 diffusion models 的首创设备端（on-device）系统，解决了传统方法在适应多样背景、姿势和主体时的挑战，同时注重隐私保护和用户定制。系统采用新型技术管道，包括高质量服装放置和模型压缩机制，以实现高效图像生成和交互界面设计。在实际使用场景中，该工具为用户提供无缝虚拟试衣体验，并为电商业务带来显著价值。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01877v1",
      "published_date": "2024-02-02 20:05:45 UTC",
      "updated_date": "2024-02-02 20:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:23:30.613702"
    },
    {
      "arxiv_id": "2402.01874v1",
      "title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Moschoula Pternea",
        "Prerna Singh",
        "Abir Chakraborty",
        "Yagna Oruganti",
        "Mirco Milletari",
        "Sayli Bapat",
        "Kebei Jiang"
      ],
      "abstract": "In this work, we review research studies that combine Reinforcement Learning\n(RL) and Large Language Models (LLMs), two areas that owe their momentum to the\ndevelopment of deep neural networks. We propose a novel taxonomy of three main\nclasses based on the way that the two model types interact with each other. The\nfirst class, RL4LLM, includes studies where RL is leveraged to improve the\nperformance of LLMs on tasks related to Natural Language Processing. L4LLM is\ndivided into two sub-categories depending on whether RL is used to directly\nfine-tune an existing LLM or to improve the prompt of the LLM. In the second\nclass, LLM4RL, an LLM assists the training of an RL model that performs a task\nthat is not inherently related to natural language. We further break down\nLLM4RL based on the component of the RL training framework that the LLM assists\nor replaces, namely reward shaping, goal generation, and policy function.\nFinally, in the third class, RL+LLM, an LLM and an RL agent are embedded in a\ncommon planning framework without either of them contributing to training or\nfine-tuning of the other. We further branch this class to distinguish between\nstudies with and without natural language feedback. We use this taxonomy to\nexplore the motivations behind the synergy of LLMs and RL and explain the\nreasons for its success, while pinpointing potential shortcomings and areas\nwhere further research is needed, as well as alternative methodologies that\nserve the same goal.",
      "tldr_zh": "本论文审阅了强化学习 (RL) 和大型语言模型 (LLM) 之间的协同研究，并提出一个新颖的分类法 (taxonomy) 来组织这些互动。分类法分为三个主要类别：RL4LLM（使用 RL 改进 LLM 的性能，包括直接微调或提示优化）、LLM4RL（LLM 辅助 RL 模型训练，如奖励塑造、目标生成或策略函数）、以及 RL+LLM（二者在共同规划框架中嵌入，而不相互训练）。通过此分类，论文探讨了这些协同的动机、成功原因、潜在缺点，并指出了需要进一步研究的领域以及替代方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages (including bibliography), 1 figure, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.01874v1",
      "published_date": "2024-02-02 20:01:15 UTC",
      "updated_date": "2024-02-02 20:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:23:42.665671"
    },
    {
      "arxiv_id": "2402.01864v2",
      "title": "(A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible LLM Policies for Legal Advice",
      "title_zh": "翻译失败",
      "authors": [
        "Inyoung Cheong",
        "King Xia",
        "K. J. Kevin Feng",
        "Quan Ze Chen",
        "Amy X. Zhang"
      ],
      "abstract": "Large language models (LLMs) are increasingly capable of providing users with\nadvice in a wide range of professional domains, including legal advice.\nHowever, relying on LLMs for legal queries raises concerns due to the\nsignificant expertise required and the potential real-world consequences of the\nadvice. To explore \\textit{when} and \\textit{why} LLMs should or should not\nprovide advice to users, we conducted workshops with 20 legal experts using\nmethods inspired by case-based reasoning. The provided realistic queries\n(\"cases\") allowed experts to examine granular, situation-specific concerns and\noverarching technical and legal constraints, producing a concrete set of\ncontextual considerations for LLM developers. By synthesizing the factors that\nimpacted LLM response appropriateness, we present a 4-dimension framework: (1)\nUser attributes and behaviors, (2) Nature of queries, (3) AI capabilities, and\n(4) Social impacts. We share experts' recommendations for LLM response\nstrategies, which center around helping users identify `right questions to ask'\nand relevant information rather than providing definitive legal judgments. Our\nfindings reveal novel legal considerations, such as unauthorized practice of\nlaw, confidentiality, and liability for inaccurate advice, that have been\noverlooked in the literature. The case-based deliberation method enabled us to\nelicit fine-grained, practice-informed insights that surpass those from\nde-contextualized surveys or speculative principles. These findings underscore\nthe applicability of our method for translating domain-specific professional\nknowledge and practices into policies that can guide LLM behavior in a more\nresponsible direction.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 在提供法律建议时的责任问题，通过与 20 名法律专家进行的研讨会，使用案例推理方法分析现实查询。研究提出一个 4-dimension framework，包括用户属性和行为、查询性质、AI 能力以及社会影响，以评估 LLM 响应的适宜性。专家们推荐 LLM 应专注于帮助用户识别“正确的问题”和相关信息，而不是给出最终判断，并强调了如 unauthorized practice of law、confidentiality 和 liability for inaccurate advice 等法律考虑。总体上，这种方法为将专业知识转化为更负责的 LLM 政策提供了细粒度的实践指导。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01864v2",
      "published_date": "2024-02-02 19:35:34 UTC",
      "updated_date": "2024-05-03 07:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:23:56.230095"
    },
    {
      "arxiv_id": "2402.01863v2",
      "title": "DFML: Decentralized Federated Mutual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yasser H. Khalil",
        "Amir H. Estiri",
        "Mahdi Beitollahi",
        "Nader Asadi",
        "Sobhan Hemati",
        "Xu Li",
        "Guojun Zhang",
        "Xi Chen"
      ],
      "abstract": "In the realm of real-world devices, centralized servers in Federated Learning\n(FL) present challenges including communication bottlenecks and susceptibility\nto a single point of failure. Additionally, contemporary devices inherently\nexhibit model and data heterogeneity. Existing work lacks a Decentralized FL\n(DFL) framework capable of accommodating such heterogeneity without imposing\narchitectural restrictions or assuming the availability of public data. To\naddress these issues, we propose a Decentralized Federated Mutual Learning\n(DFML) framework that is serverless, supports nonrestrictive heterogeneous\nmodels, and avoids reliance on public data. DFML effectively handles model and\ndata heterogeneity through mutual learning, which distills knowledge between\nclients, and cyclically varying the amount of supervision and distillation\nsignals. Extensive experimental results demonstrate consistent effectiveness of\nDFML in both convergence speed and global accuracy, outperforming prevalent\nbaselines under various conditions. For example, with the CIFAR-100 dataset and\n50 clients, DFML achieves a substantial increase of +17.20% and +19.95% in\nglobal accuracy under Independent and Identically Distributed (IID) and non-IID\ndata shifts, respectively.",
      "tldr_zh": "这篇论文提出了DFML框架，一种无服务器的Decentralized Federated Learning (DFL)方法，旨在解决传统Federated Learning (FL)中的通信瓶颈、单点故障以及模型和数据异质性问题，而无需架构限制或依赖公共数据。DFML通过mutual learning机制实现客户端间的知识蒸馏，并通过循环变化监督和蒸馏信号来有效处理异质性。实验结果显示，DFML在CIFAR-100数据集和50个客户端场景下，相比基线模型在IID和non-IID数据分布下分别提升了17.20%和19.95%的全局准确率，并在收敛速度上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01863v2",
      "published_date": "2024-02-02 19:35:05 UTC",
      "updated_date": "2024-08-13 22:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:24:06.960735"
    },
    {
      "arxiv_id": "2402.01862v1",
      "title": "Parametric Feature Transfer: One-shot Federated Learning with Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Beitollahi",
        "Alex Bie",
        "Sobhan Hemati",
        "Leo Maxime Brunswic",
        "Xu Li",
        "Xi Chen",
        "Guojun Zhang"
      ],
      "abstract": "In one-shot federated learning (FL), clients collaboratively train a global\nmodel in a single round of communication. Existing approaches for one-shot FL\nenhance communication efficiency at the expense of diminished accuracy. This\npaper introduces FedPFT (Federated Learning with Parametric Feature Transfer),\na methodology that harnesses the transferability of foundation models to\nenhance both accuracy and communication efficiency in one-shot FL. The approach\ninvolves transferring per-client parametric models (specifically, Gaussian\nmixtures) of features extracted from foundation models. Subsequently, each\nparametric model is employed to generate synthetic features for training a\nclassifier head. Experimental results on eight datasets demonstrate that FedPFT\nenhances the communication-accuracy frontier in both centralized and\ndecentralized FL scenarios, as well as across diverse data-heterogeneity\nsettings such as covariate shift and task shift, with improvements of up to\n20.6%. Additionally, FedPFT adheres to the data minimization principle of FL,\nas clients do not send real features. We demonstrate that sending real features\nis vulnerable to potent reconstruction attacks. Moreover, we show that FedPFT\nis amenable to formal privacy guarantees via differential privacy,\ndemonstrating favourable privacy-accuracy tradeoffs.",
      "tldr_zh": "这篇论文提出 FedPFT（Federated Learning with Parametric Feature Transfer）方法，用于 one-shot federated learning，通过利用 foundation models 的转移能力，同时提升准确性和通信效率。方法涉及转移每个客户端的 Gaussian mixtures 参数化模型，这些模型基于基础模型提取的特征，然后生成合成特征来训练分类器头。实验结果显示，在八个数据集上，FedPFT 在集中式和去中心式 FL 场景中，以及 covariate shift 和 task shift 等数据异质性设置下，准确性改善高达 20.6%。此外，该方法遵守 federated learning 的数据最小化原则，避免发送真实特征从而防范重建攻击，并支持 differential privacy，提供良好的隐私-准确性权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01862v1",
      "published_date": "2024-02-02 19:34:46 UTC",
      "updated_date": "2024-02-02 19:34:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:24:19.885848"
    },
    {
      "arxiv_id": "2402.01858v3",
      "title": "Explaining latent representations of generative models with large multimodal models",
      "title_zh": "使用大型多模态模型解释生成模型的潜在表示",
      "authors": [
        "Mengdan Zhu",
        "Zhenke Liu",
        "Bo Pan",
        "Abhinav Angirekula",
        "Liang Zhao"
      ],
      "abstract": "Learning interpretable representations of data generative latent factors is\nan important topic for the development of artificial intelligence. With the\nrise of the large multimodal model, it can align images with text to generate\nanswers. In this work, we propose a framework to comprehensively explain each\nlatent variable in the generative models using a large multimodal model. We\nfurther measure the uncertainty of our generated explanations, quantitatively\nevaluate the performance of explanation generation among multiple large\nmultimodal models, and qualitatively visualize the variations of each latent\nvariable to learn the disentanglement effects of different generative models on\nexplanations. Finally, we discuss the explanatory capabilities and limitations\nof state-of-the-art large multimodal models.",
      "tldr_zh": "该论文提出一个框架，使用大型多模态模型（large multimodal models）来全面解释生成模型（generative models）中的潜在表示（latent representations），以提升人工智能中数据的可解释性。该框架不仅生成针对每个潜在变量的解释，还通过测量不确定性、定量评估多个大型多模态模型的性能以及定性可视化潜在变量变化，来评估不同生成模型的解耦效果。最终，研究讨论了这些先进模型的解释能力和局限性，为可解释AI表示提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 Workshop on Reliable and Responsible Foundation Models",
      "pdf_url": "http://arxiv.org/pdf/2402.01858v3",
      "published_date": "2024-02-02 19:28:33 UTC",
      "updated_date": "2024-04-18 03:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:24:30.776988"
    },
    {
      "arxiv_id": "2402.01849v1",
      "title": "Capturing waste collection planning expert knowledge in a fitness function through preference learning",
      "title_zh": "通过偏",
      "authors": [
        "Laura Fernández Díaz",
        "Miriam Fernández Díaz",
        "José Ramón Quevedo",
        "Elena Montañés"
      ],
      "abstract": "This paper copes with the COGERSA waste collection process. Up to now,\nexperts have been manually designed the process using a trial and error\nmechanism. This process is not globally optimized, since it has been\nprogressively and locally built as council demands appear. Planning\noptimization algorithms usually solve it, but they need a fitness function to\nevaluate a route planning quality. The drawback is that even experts are not\nable to propose one in a straightforward way due to the complexity of the\nprocess. Hence, the goal of this paper is to build a fitness function though a\npreference framework, taking advantage of the available expert knowledge and\nexpertise. Several key performance indicators together with preference\njudgments are carefully established according to the experts for learning a\npromising fitness function. Particularly, the additivity property of them makes\nthe task be much more affordable, since it allows to work with routes rather\nthan with route plannings. Besides, a feature selection analysis is performed\nover such indicators, since the experts suspect of a potential existing (but\nunknown) redundancy among them. The experiment results confirm this hypothesis,\nsince the best $C-$index ($98\\%$ against around $94\\%$) is reached when 6 or 8\nout of 21 indicators are taken. Particularly, truck load seems to be a highly\npromising key performance indicator, together to the travelled distance along\nnon-main roads. A comparison with other existing approaches shows that the\nproposed method clearly outperforms them, since the $C-$index goes from $72\\%$\nor $90\\%$ to $98\\%$.",
      "tldr_zh": "这篇论文针对 COGERSA 废物收集过程，通过 preference learning 捕获专家知识来构建一个评估路线规划质量的 fitness function，以解决手动试错机制的全局优化不足问题。该方法结合关键绩效指标（KPIs）和专家偏好判断，进行特征选择分析，发现 21 个指标中仅需 6 或 8 个即可实现最佳效果。实验结果显示，C-index 提升至 98%，卡车负载和非主干道行驶距离等指标尤为关键，并显著优于现有方法的 72% 或 90%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01849v1",
      "published_date": "2024-02-02 19:04:53 UTC",
      "updated_date": "2024-02-02 19:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:24:44.739881"
    },
    {
      "arxiv_id": "2402.01841v1",
      "title": "COMET: Generating Commit Messages using Delta Graph Context Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Reddy Mandli",
        "Saurabhsingh Rajput",
        "Tushar Sharma"
      ],
      "abstract": "Commit messages explain code changes in a commit and facilitate collaboration\namong developers. Several commit message generation approaches have been\nproposed; however, they exhibit limited success in capturing the context of\ncode changes. We propose Comet (Context-Aware Commit Message Generation), a\nnovel approach that captures context of code changes using a graph-based\nrepresentation and leverages a transformer-based model to generate high-quality\ncommit messages. Our proposed method utilizes delta graph that we developed to\neffectively represent code differences. We also introduce a customizable\nquality assurance module to identify optimal messages, mitigating subjectivity\nin commit messages. Experiments show that Comet outperforms state-of-the-art\ntechniques in terms of bleu-norm and meteor metrics while being comparable in\nterms of rogue-l. Additionally, we compare the proposed approach with the\npopular gpt-3.5-turbo model, along with gpt-4-turbo; the most capable GPT\nmodel, over zero-shot, one-shot, and multi-shot settings. We found Comet\noutperforming the GPT models, on five and four metrics respectively and provide\ncompetitive results with the two other metrics. The study has implications for\nresearchers, tool developers, and software developers. Software developers may\nutilize Comet to generate context-aware commit messages. Researchers and tool\ndevelopers can apply the proposed delta graph technique in similar contexts,\nlike code review summarization.",
      "tldr_zh": "本文提出 COMET，一种上下文感知的提交消息生成方法，使用 delta graph 表示代码差异，并结合 Transformer 模型来捕捉代码变化的上下文，从而生成高质量的提交消息。该方法还引入一个可定制的质量保证模块，以减少消息的主观性。实验结果显示，COMET 在 bleu-norm 和 meteor 指标上优于现有技术，在 rogue-L 上与它们相当；与 GPT-3.5-turbo 和 GPT-4-turbo 模型比较，COMET 在零样本、一样本和多样本设置下表现出色，优于 GPT 模型的五个指标，并与其他两个指标竞争。该研究为软件开发者提供生成上下文感知提交消息的工具，并为研究者和工具开发者在类似领域（如代码审查总结）应用 delta graph 技术提供启发。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "22 Pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01841v1",
      "published_date": "2024-02-02 19:01:52 UTC",
      "updated_date": "2024-02-02 19:01:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:24:56.108777"
    },
    {
      "arxiv_id": "2402.01832v2",
      "title": "SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training?",
      "title_zh": "SynthCLIP：我们准备好进行完全合成的 CLIP 训练了吗？",
      "authors": [
        "Hasan Abed Al Kader Hammoud",
        "Hani Itani",
        "Fabio Pizzati",
        "Philip Torr",
        "Adel Bibi",
        "Bernard Ghanem"
      ],
      "abstract": "We present SynthCLIP, a CLIP model trained on entirely synthetic text-image\npairs. Leveraging recent text-to-image (TTI) networks and large language models\n(LLM), we generate synthetic datasets of images and corresponding captions at\nscale, with no human intervention. In this work, we provide an analysis on CLIP\nmodels trained on synthetic data. We provide insights on the data generation\nstrategy, number of samples required, scaling trends, and resulting properties.\nWe also introduce SynthCI-30M, a purely synthetic dataset comprising 30 million\ncaptioned images. Our code, trained models, and data, are released as open\nsource at https://github.com/hammoudhasan/SynthCLIP",
      "tldr_zh": "本研究提出 SynthCLIP，一种完全基于合成文本-图像对训练的 CLIP 模型，利用文本到图像 (TTI) 网络和大语言模型 (LLM) 生成大规模数据集，无需人为干预。论文分析了合成数据训练策略、所需样本数量、缩放趋势以及模型性能特性，并发布了 SynthCI-30M 数据集，包含 3000 万张带描述的纯合成图像。SynthCLIP 的开源实现为评估合成数据在视觉语言模型训练中的潜力提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2402.01832v2",
      "published_date": "2024-02-02 18:59:58 UTC",
      "updated_date": "2024-07-18 10:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:25:06.034557"
    },
    {
      "arxiv_id": "2403.07888v2",
      "title": "Cross-modality debiasing: using language to mitigate sub-population shifts in imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Yijiang Pang",
        "Bao Hoang",
        "Jiayu Zhou"
      ],
      "abstract": "Sub-population shift is a specific type of domain shift that highlights\nchanges in data distribution within specific sub-groups or populations between\ntraining and testing. Sub-population shift accounts for a significant source of\nalgorithmic bias and calls for distributional robustness. Recent studies found\ninherent distributional robustness in multi-modality foundation models, such as\nthe vision-language model CLIP, yet this robustness is vulnerable through\nparameter fine-tuning. In this paper, we propose leveraging the connection of\nrobustness among different modalities and reshaping the distributional\nrobustness of one modality with another. Specifically, in the context of the\ndistributional robustness of CLIP, we propose to leverage natural language\ninputs to debias the image feature representations, to improve worst-case\nperformance on sub-populations. Our extensive empirical studies show that image\nrepresentations debiased by natural language can achieve significant\nperformance improvement and reduction of performance instability under\nsub-population shifts.",
      "tldr_zh": "该论文探讨了 sub-population shifts（子群体分布变化）在图像处理中导致的算法偏见问题，并强调了分布鲁棒性的重要性。作者提出一种 cross-modality debiasing 方法，利用自然语言输入来调整 CLIP 等多模态基础模型的图像特征表示，从而提升模型在子群体上的最坏情况性能。该方法通过利用不同模态之间的鲁棒性连接，显著提高了图像表示的鲁棒性，并在广泛实验中实现了性能的显著提升和不稳定性减少。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07888v2",
      "published_date": "2024-02-02 18:54:48 UTC",
      "updated_date": "2024-04-02 14:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:25:17.936170"
    },
    {
      "arxiv_id": "2402.01830v3",
      "title": "PiCO: Peer Review in LLMs based on the Consistency Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Kun-Peng Ning",
        "Shuo Yang",
        "Yu-Yang Liu",
        "Jia-Yu Yao",
        "Zhen-Hui Liu",
        "Yong-Hong Tian",
        "Yibing Song",
        "Li Yuan"
      ],
      "abstract": "Existing large language models (LLMs) evaluation methods typically focus on\ntesting the performance on some closed-environment and domain-specific\nbenchmarks with human annotations. In this paper, we explore a novel\nunsupervised evaluation direction, utilizing peer-review mechanisms to measure\nLLMs automatically. In this setting, both open-source and closed-source LLMs\nlie in the same environment, capable of answering unlabeled questions and\nevaluating each other, where each LLM's response score is jointly determined by\nother anonymous ones. To obtain the ability hierarchy among these models, we\nassign each LLM a learnable capability parameter to adjust the final ranking.\nWe formalize it as a constrained optimization problem, intending to maximize\nthe consistency of each LLM's capabilities and scores. The key assumption\nbehind is that high-level LLM can evaluate others' answers more accurately than\nlow-level ones, while higher-level LLM can also achieve higher response scores.\nMoreover, we propose three metrics called PEN, CIN, and LIS to evaluate the gap\nin aligning human rankings. We perform experiments on multiple datasets with\nthese metrics, validating the effectiveness of the proposed approach.",
      "tldr_zh": "本论文提出 PiCO 方法，利用同行评审机制对大型语言模型 (LLMs) 进行无监督评估，旨在解决现有方法依赖封闭环境和人工标注的局限性。该方法让 LLMs 在同一环境中回答未标注问题并相互匿名评估，每个模型的响应分数由其他模型共同决定，并通过为每个 LLM 分配可学习的 capability parameter 来形式化为一致性优化问题，以最大化能力的层次一致性。实验结果显示，该方法在多个数据集上有效，提出的 PEN, CIN 和 LIS 指标成功评估了与人类排名的对齐差距。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01830v3",
      "published_date": "2024-02-02 18:49:26 UTC",
      "updated_date": "2025-02-21 06:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:25:31.456090"
    },
    {
      "arxiv_id": "2402.01614v1",
      "title": "L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Ruikang Ouyang",
        "Andrew Elliott",
        "Stratis Limnios",
        "Mihai Cucuringu",
        "Gesine Reinert"
      ],
      "abstract": "For analysing real-world networks, graph representation learning is a popular\ntool. These methods, such as a graph autoencoder (GAE), typically rely on\nlow-dimensional representations, also called embeddings, which are obtained\nthrough minimising a loss function; these embeddings are used with a decoder\nfor downstream tasks such as node classification and edge prediction. While\nGAEs tend to be fairly accurate, they suffer from scalability issues. For\nimproved speed, a Local2Global approach, which combines graph patch embeddings\nbased on eigenvector synchronisation, was shown to be fast and achieve good\naccuracy. Here we propose L2G2G, a Local2Global method which improves GAE\naccuracy without sacrificing scalability. This improvement is achieved by\ndynamically synchronising the latent node representations, while training the\nGAEs. It also benefits from the decoder computing an only local patch loss.\nHence, aligning the local embeddings in each epoch utilises more information\nfrom the graph than a single post-training alignment does, while maintaining\nscalability. We illustrate on synthetic benchmarks, as well as real-world\nexamples, that L2G2G achieves higher accuracy than the standard Local2Global\napproach and scales efficiently on the larger data sets. We find that for large\nand dense networks, it even outperforms the slow, but assumed more accurate,\nGAEs.",
      "tldr_zh": "这篇论文提出 L2G2G，一种可扩展的 Local-to-Global 网络嵌入方法，旨在提升 Graph Autoencoders (GAE) 的准确性，同时解决其可扩展性问题。L2G2G 通过在训练过程中动态同步潜在节点表示并仅计算局部补丁损失，利用更多图信息来优化嵌入过程。实验结果显示，在合成基准和真实世界网络上，L2G2G 比标准 Local2Global 方法准确性更高，并在大型密集网络中甚至超过了传统 GAE 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 4 figures, Complex Networks 2023, Volume I, SCI 1141",
      "pdf_url": "http://arxiv.org/pdf/2402.01614v1",
      "published_date": "2024-02-02 18:24:37 UTC",
      "updated_date": "2024-02-02 18:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:25:43.194919"
    },
    {
      "arxiv_id": "2402.01613v2",
      "title": "Nomic Embed: Training a Reproducible Long Context Text Embedder",
      "title_zh": "翻译失败",
      "authors": [
        "Zach Nussbaum",
        "John X. Morris",
        "Brandon Duderstadt",
        "Andriy Mulyar"
      ],
      "abstract": "This technical report describes the training of nomic-embed-text-v1, the\nfirst fully reproducible, open-source, open-weights, open-data, 8192 context\nlength English text embedding model that outperforms both OpenAI Ada-002 and\nOpenAI text-embedding-3-small on the short-context MTEB benchmark and the long\ncontext LoCo benchmark. We release the training code and model weights under an\nApache 2.0 license. In contrast with other open-source models, we release the\nfull curated training data and code that allows for full replication of\nnomic-embed-text-v1. You can find code and data to replicate the model at\nhttps://github.com/nomic-ai/contrastors.",
      "tldr_zh": "该研究介绍了 nomic-embed-text-v1，一种完全可重现的开源英文文本嵌入模型，支持 8192 上下文长度，并开源了模型权重、训练代码和数据。模型在短上下文 MTEB benchmark 和长上下文 LoCo benchmark 上，超过了 OpenAI Ada-002 和 OpenAI text-embedding-3-small 的性能。作者在 Apache 2.0 许可下发布了所有资源，包括用于完全复制模型的代码和数据，可在 https://github.com/nomic-ai/contrastors 获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to TMLR https://openreview.net/forum?id=IPmzyQSiQE",
      "pdf_url": "http://arxiv.org/pdf/2402.01613v2",
      "published_date": "2024-02-02 18:23:18 UTC",
      "updated_date": "2025-02-03 22:26:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:25:54.356199"
    },
    {
      "arxiv_id": "2402.01828v1",
      "title": "Retrieval Augmented End-to-End Spoken Dialog Models",
      "title_zh": "检索增强端到端口语对话模型",
      "authors": [
        "Mingqiu Wang",
        "Izhak Shafran",
        "Hagen Soltau",
        "Wei Han",
        "Yuan Cao",
        "Dian Yu",
        "Laurent El Shafey"
      ],
      "abstract": "We recently developed SLM, a joint speech and language model, which fuses a\npretrained foundational speech model and a large language model (LLM), while\npreserving the in-context learning capability intrinsic to the pretrained LLM.\nIn this paper, we apply SLM to speech dialog applications where the dialog\nstates are inferred directly from the audio signal.\n  Task-oriented dialogs often contain domain-specific entities, i.e.,\nrestaurants, hotels, train stations, and city names, which are difficult to\nrecognize, however, critical for the downstream applications. Inspired by the\nRAG (retrieval-augmented generation) paradigm, we propose a retrieval augmented\nSLM (ReSLM) that overcomes this weakness. We first train a speech retriever to\nretrieve text entities mentioned in the audio. The retrieved entities are then\nadded as text inputs to the underlying SLM to bias model predictions. We\nevaluated ReSLM on speech MultiWoz task (DSTC-11 challenge), and found that\nthis retrieval augmentation boosts model performance, achieving joint goal\naccuracy (38.6% vs 32.7%), slot error rate (20.6% vs 24.8%) and ASR word error\nrate (5.5% vs 6.7%). While demonstrated on dialog state tracking, our approach\nis broadly applicable to other speech tasks requiring contextual information or\ndomain-specific entities, such as contextual ASR with biasing capability.",
      "tldr_zh": "本研究提出了一种检索增强的端到端语音对话模型 ReSLM（Retrieval Augmented SLM），基于现有的 SLM（Speech and Language Model）框架，该框架融合了预训练语音模型和大型语言模型（LLM），以直接从音频信号中推断对话状态。针对任务导向对话中特定实体（如餐厅或酒店名称）的识别难题，ReSLM 采用 RAG（Retrieval-Augmented Generation）范式，训练一个语音检索器来提取音频中提到的文本实体，并将其作为输入偏置 SLM 的预测。实验在 speech MultiWoz 任务（DSTC-11 挑战）上显示，ReSLM 显著提升了性能，包括 joint goal accuracy 从 32.7% 提高到 38.6%、slot error rate 从 24.8% 降到 20.6%，以及 ASR word error rate 从 6.7% 降到 5.5%。这种方法可扩展到其他需要上下文信息或特定实体的语音任务，如 contextual ASR with biasing capability。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01828v1",
      "published_date": "2024-02-02 18:23:09 UTC",
      "updated_date": "2024-02-02 18:23:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:26:08.443665"
    },
    {
      "arxiv_id": "2402.01826v1",
      "title": "Leveraging Large Language Models for Analyzing Blood Pressure Variations Across Biological Sex from Scientific Literature",
      "title_zh": "翻译失败",
      "authors": [
        "Yuting Guo",
        "Seyedeh Somayyeh Mousavi",
        "Reza Sameni",
        "Abeed Sarker"
      ],
      "abstract": "Hypertension, defined as blood pressure (BP) that is above normal, holds\nparamount significance in the realm of public health, as it serves as a\ncritical precursor to various cardiovascular diseases (CVDs) and significantly\ncontributes to elevated mortality rates worldwide. However, many existing BP\nmeasurement technologies and standards might be biased because they do not\nconsider clinical outcomes, comorbidities, or demographic factors, making them\ninconclusive for diagnostic purposes. There is limited data-driven research\nfocused on studying the variance in BP measurements across these variables. In\nthis work, we employed GPT-35-turbo, a large language model (LLM), to\nautomatically extract the mean and standard deviation values of BP for both\nmales and females from a dataset comprising 25 million abstracts sourced from\nPubMed. 993 article abstracts met our predefined inclusion criteria (i.e.,\npresence of references to blood pressure, units of blood pressure such as mmHg,\nand mention of biological sex). Based on the automatically-extracted\ninformation from these articles, we conducted an analysis of the variations of\nBP values across biological sex. Our results showed the viability of utilizing\nLLMs to study the BP variations across different demographic factors.",
      "tldr_zh": "本研究探讨了高血压（Hypertension）在不同生物性别间的血压（BP）变化，利用大型语言模型（Large Language Models, LLMs）分析科学文献中的数据。作者使用 GPT-3.5-turbo 从 PubMed 的 2500 万篇摘要中筛选出 993 篇符合标准的文章，自动提取男性和女性的血压均值和标准差。结果显示，血压值在生物性别间存在显著差异，并证明了 LLMs 在数据驱动研究中分析人口统计因素的可行性，为改进血压测量技术和标准提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01826v1",
      "published_date": "2024-02-02 18:15:51 UTC",
      "updated_date": "2024-02-02 18:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:26:18.777612"
    },
    {
      "arxiv_id": "2402.01607v3",
      "title": "Natural Counterfactuals With Necessary Backtracking",
      "title_zh": "翻译失败",
      "authors": [
        "Guang-Yuan Hao",
        "Jiji Zhang",
        "Biwei Huang",
        "Hao Wang",
        "Kun Zhang"
      ],
      "abstract": "Counterfactual reasoning is pivotal in human cognition and especially\nimportant for providing explanations and making decisions. While Judea Pearl's\ninfluential approach is theoretically elegant, its generation of a\ncounterfactual scenario often requires too much deviation from the observed\nscenarios to be feasible, as we show using simple examples. To mitigate this\ndifficulty, we propose a framework of \\emph{natural counterfactuals} and a\nmethod for generating counterfactuals that are more feasible with respect to\nthe actual data distribution. Our methodology incorporates a certain amount of\nbacktracking when needed, allowing changes in causally preceding variables to\nminimize deviations from realistic scenarios. Specifically, we introduce a\nnovel optimization framework that permits but also controls the extent of\nbacktracking with a naturalness criterion. Empirical experiments demonstrate\nthe effectiveness of our method. The code is available at\nhttps://github.com/GuangyuanHao/natural_counterfactuals.",
      "tldr_zh": "该论文探讨了反事实推理（Counterfactual reasoning）在人类认知、解释和决策中的关键作用，但指出Judea Pearl的经典方法往往生成偏离实际数据分布的反事实场景，缺乏可行性。为解决这一问题，作者提出自然反事实（natural counterfactuals）框架，并开发了一种生成方法，通过必要回溯（backtracking）来调整因果前置变量，从而最小化偏差。研究引入一个新颖的优化框架，使用自然性标准（naturalness criterion）控制回溯程度，实验结果证明了该方法的有效性，并提供了开源代码。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.NE",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01607v3",
      "published_date": "2024-02-02 18:11:43 UTC",
      "updated_date": "2024-10-30 23:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:26:30.326836"
    },
    {
      "arxiv_id": "2402.01602v1",
      "title": "Foundation Model Sherpas: Guiding Foundation Models through Knowledge and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Debarun Bhattacharjya",
        "Junkyu Lee",
        "Don Joven Agravante",
        "Balaji Ganesan",
        "Radu Marinescu"
      ],
      "abstract": "Foundation models (FMs) such as large language models have revolutionized the\nfield of AI by showing remarkable performance in various tasks. However, they\nexhibit numerous limitations that prevent their broader adoption in many\nreal-world systems, which often require a higher bar for trustworthiness and\nusability. Since FMs are trained using loss functions aimed at reconstructing\nthe training corpus in a self-supervised manner, there is no guarantee that the\nmodel's output aligns with users' preferences for a specific task at hand. In\nthis survey paper, we propose a conceptual framework that encapsulates\ndifferent modes by which agents could interact with FMs and guide them suitably\nfor a set of tasks, particularly through knowledge augmentation and reasoning.\nOur framework elucidates agent role categories such as updating the underlying\nFM, assisting with prompting the FM, and evaluating the FM output. We also\ncategorize several state-of-the-art approaches into agent interaction\nprotocols, highlighting the nature and extent of involvement of the various\nagent roles. The proposed framework provides guidance for future directions to\nfurther realize the power of FMs in practical AI systems.",
      "tldr_zh": "这篇论文讨论了基础模型（Foundation Models, FMs）如大型语言模型在实际应用中的局限性，包括输出可能不符合用户偏好，导致可信度和可用性不足。作者提出一个概念框架，描述代理（agents）如何通过知识增强和推理与 FMs 互动，包括代理角色如更新底层 FM、辅助提示和评估输出。框架还分类了现有先进方法，并为未来 AI 系统实现 FMs 的潜力提供指导方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01602v1",
      "published_date": "2024-02-02 18:00:35 UTC",
      "updated_date": "2024-02-02 18:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:26:42.118629"
    },
    {
      "arxiv_id": "2402.01591v2",
      "title": "BAT: Learning to Reason about Spatial Sounds with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhisheng Zheng",
        "Puyuan Peng",
        "Ziyang Ma",
        "Xie Chen",
        "Eunsol Choi",
        "David Harwath"
      ],
      "abstract": "Spatial sound reasoning is a fundamental human skill, enabling us to navigate\nand interpret our surroundings based on sound. In this paper we present BAT,\nwhich combines the spatial sound perception ability of a binaural acoustic\nscene analysis model with the natural language reasoning capabilities of a\nlarge language model (LLM) to replicate this innate ability. To address the\nlack of existing datasets of in-the-wild spatial sounds, we synthesized a\nbinaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developed\nSpatialSoundQA, a spatial sound-based question-answering dataset, offering a\nrange of QA tasks that train BAT in various aspects of spatial sound perception\nand reasoning. The acoustic front end encoder of BAT is a novel spatial audio\nencoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which by\nitself achieves strong performance across sound event detection, spatial\nlocalization, and distance estimation. By integrating Spatial-AST with LLaMA-2\n7B model, BAT transcends standard Sound Event Localization and Detection (SELD)\ntasks, enabling the model to reason about the relationships between the sounds\nin its environment. Our experiments demonstrate BAT's superior performance on\nboth spatial sound perception and reasoning, showcasing the immense potential\nof LLMs in navigating and interpreting complex spatial audio environments.",
      "tldr_zh": "该论文提出 BAT 系统，将双耳声学场景分析模型与大型语言模型 (LLM) 相结合，实现对空间声音的感知和推理，模拟人类基于声音导航和解释环境的能力。为解决野外空间声音数据集缺乏的问题，作者使用 AudioSet 和 SoundSpaces 2.0 合成了一个双耳音频数据集，并开发了 SpatialSoundQA 数据集，用于训练各种空间声音问答任务。BAT 的核心组件是新型空间音频编码器 Spatial Audio Spectrogram Transformer (Spatial-AST)，其与 LLaMA-2 7B 模型集成，超越了标准 Sound Event Localization and Detection (SELD) 任务，能够推理环境中的声音关系。实验结果显示，BAT 在空间声音感知和推理任务上表现出色，展示了 LLM 在复杂音频环境中的巨大潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICML 2024. Our demo, dataset, code and model weights are\n  available at: https://zhishengzheng.com/BAT",
      "pdf_url": "http://arxiv.org/pdf/2402.01591v2",
      "published_date": "2024-02-02 17:34:53 UTC",
      "updated_date": "2024-05-25 17:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:26:56.289919"
    },
    {
      "arxiv_id": "2402.05942v1",
      "title": "Cooperative Knowledge Distillation: A Learner Agnostic Approach",
      "title_zh": "合作知识蒸馏：一种学习器无关的方法",
      "authors": [
        "Michael Livanos",
        "Ian Davidson",
        "Stephen Wong"
      ],
      "abstract": "Knowledge distillation is a simple but powerful way to transfer knowledge\nbetween a teacher model to a student model. Existing work suffers from at least\none of the following key limitations in terms of direction and scope of\ntransfer which restrict its use: all knowledge is transferred from teacher to\nstudent regardless of whether or not that knowledge is useful, the student is\nthe only one learning in this exchange, and typically distillation transfers\nknowledge only from a single teacher to a single student. We formulate a novel\nform of knowledge distillation in which many models can act as both students\nand teachers which we call cooperative distillation. The models cooperate as\nfollows: a model (the student) identifies specific deficiencies in it's\nperformance and searches for another model (the teacher) who encodes learned\nknowledge into instructional virtual instances via counterfactual instance\ngeneration. Because different models may have different strengths and\nweaknesses, all models can act as either students or teachers (cooperation)\nwhen appropriate and only distill knowledge in areas specific to their\nstrengths (focus). Since counterfactuals as a paradigm are not tied to any\nspecific algorithm, we can use this method to distill knowledge between\nlearners of different architectures, algorithms, and even feature spaces. We\ndemonstrate that our approach not only outperforms baselines such as transfer\nlearning, self-supervised learning, and multiple knowledge distillation\nalgorithms on several datasets, but it can also be used in settings where the\naforementioned techniques cannot.",
      "tldr_zh": "该论文提出了一种名为“Cooperative Knowledge Distillation”的新方法，允许多个模型相互充当学生和老师，以针对性转移知识，克服传统知识蒸馏的局限，如无差别知识转移和单向学习。通过反事实实例生成（Counterfactual Instance Generation），学生模型识别自身缺陷，并从教师模型获取特定领域的专长知识。实验结果显示，该方法在多个数据集上优于基线技术，包括Transfer Learning、自监督学习和其他知识蒸馏算法，且适用于不同架构和特征空间的模型设置。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures, AAAI24",
      "pdf_url": "http://arxiv.org/pdf/2402.05942v1",
      "published_date": "2024-02-02 17:31:50 UTC",
      "updated_date": "2024-02-02 17:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:27:06.057131"
    },
    {
      "arxiv_id": "2402.01586v4",
      "title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyue Hua",
        "Xianjun Yang",
        "Mingyu Jin",
        "Zelong Li",
        "Wei Cheng",
        "Ruixiang Tang",
        "Yongfeng Zhang"
      ],
      "abstract": "The rise of LLM-based agents shows great potential to revolutionize task\nplanning, capturing significant attention. Given that these agents will be\nintegrated into high-stake domains, ensuring their reliability and safety is\ncrucial. This paper presents an Agent-Constitution-based agent framework,\nTrustAgent, with a particular focus on improving the LLM-based agent safety.\nThe proposed framework ensures strict adherence to the Agent Constitution\nthrough three strategic components: pre-planning strategy which injects safety\nknowledge to the model before plan generation, in-planning strategy which\nenhances safety during plan generation, and post-planning strategy which\nensures safety by post-planning inspection. Our experimental results\ndemonstrate that the proposed framework can effectively enhance an LLM agent's\nsafety across multiple domains by identifying and mitigating potential dangers\nduring the planning. Further analysis reveals that the framework not only\nimproves safety but also enhances the helpfulness of the agent. Additionally,\nwe highlight the importance of the LLM reasoning ability in adhering to the\nConstitution. This paper sheds light on how to ensure the safe integration of\nLLM-based agents into human-centric environments. Data and code are available\nat https://github.com/agiresearch/TrustAgent.",
      "tldr_zh": "这篇论文提出了 TrustAgent 框架，一种基于 Agent-Constitution 的方法，旨在提升 LLM-based agents 的安全性和可靠性。该框架通过三个关键策略——pre-planning strategy（注入安全知识）、in-planning strategy（生成计划时增强安全）和 post-planning strategy（事后检查）——确保代理严格遵守安全准则。实验结果显示，TrustAgent 在多个领域有效识别和缓解潜在风险，不仅提高了代理的安全性，还增强了其帮助性。论文强调了 LLM 推理能力对遵守 Agent Constitution 的重要性，并为 LLM-based agents 在高风险人类环境中的安全集成提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "In EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01586v4",
      "published_date": "2024-02-02 17:26:23 UTC",
      "updated_date": "2024-10-03 22:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:27:19.281518"
    },
    {
      "arxiv_id": "2402.01580v2",
      "title": "Generative AI for Education (GAIED): Advances, Opportunities, and Challenges",
      "title_zh": "生成式人工智能用于教育",
      "authors": [
        "Paul Denny",
        "Sumit Gulwani",
        "Neil T. Heffernan",
        "Tanja Käser",
        "Steven Moore",
        "Anna N. Rafferty",
        "Adish Singla"
      ],
      "abstract": "This survey article has grown out of the GAIED (pronounced \"guide\") workshop\norganized by the authors at the NeurIPS 2023 conference. We organized the GAIED\nworkshop as part of a community-building effort to bring together researchers,\neducators, and practitioners to explore the potential of generative AI for\nenhancing education. This article aims to provide an overview of the workshop\nactivities and highlight several future research directions in the area of\nGAIED.",
      "tldr_zh": "这篇文章基于作者在 NeurIPS 2023 会议上组织的 GAIED 研讨会，提供了一个对生成式 AI 在教育领域的进展、机会和挑战的全面概述。研讨会旨在将研究者、教育者和从业者聚集在一起，探讨生成式 AI 如何提升教育实践。文章强调了未来研究方向，以推动 GAIED 社区的建设和创新。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01580v2",
      "published_date": "2024-02-02 17:19:20 UTC",
      "updated_date": "2024-02-07 01:11:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:27:30.478222"
    },
    {
      "arxiv_id": "2402.01825v2",
      "title": "Fractal Patterns May Illuminate the Success of Next-Token Prediction",
      "title_zh": "分形模式可能阐明下一标记预测的成功",
      "authors": [
        "Ibrahim Alabdulmohsin",
        "Vinh Q. Tran",
        "Mostafa Dehghani"
      ],
      "abstract": "We study the fractal structure of language, aiming to provide a precise\nformalism for quantifying properties that may have been previously suspected\nbut not formally shown. We establish that language is: (1) self-similar,\nexhibiting complexities at all levels of granularity, with no particular\ncharacteristic context length, and (2) long-range dependent (LRD), with a Hurst\nparameter of approximately H=0.7. Based on these findings, we argue that\nshort-term patterns/dependencies in language, such as in paragraphs, mirror the\npatterns/dependencies over larger scopes, like entire documents. This may shed\nsome light on how next-token prediction can capture the structure of text\nacross multiple levels of granularity, from words and clauses to broader\ncontexts and intents. In addition, we carry out an extensive analysis across\ndifferent domains and architectures, showing that fractal parameters are\nrobust. Finally, we demonstrate that the tiny variations in fractal parameters\nseen across LLMs improve upon perplexity-based bits-per-byte (BPB) in\npredicting their downstream performance. We hope these findings offer a fresh\nperspective on language and the mechanisms underlying the success of LLMs.",
      "tldr_zh": "本研究探讨了语言的分形结构，通过精确形式主义量化其属性，发现语言是 self-similar 的，在所有粒度级别显示复杂性，且无特定上下文长度；同时，语言具有 long-range dependent (LRD) 特性，Hurst parameter 约为 H=0.7。研究表明，短期的语言模式（如段落）镜像长期模式（如整个文档），这有助于解释 next-token prediction 如何捕捉多级别文本结构。跨不同领域和架构的分析显示，分形参数稳健且可靠，其微小变化比 perplexity-based bits-per-byte (BPB) 更能预测 LLMs 的下游性能，提供了一个新视角来理解语言和大型语言模型的成功机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 10 tables, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01825v2",
      "published_date": "2024-02-02 17:09:33 UTC",
      "updated_date": "2024-05-22 16:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:27:44.875809"
    },
    {
      "arxiv_id": "2402.01566v1",
      "title": "Boximator: Generating Rich and Controllable Motions for Video Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Wang",
        "Yuchen Zhang",
        "Jiaxin Zou",
        "Yan Zeng",
        "Guoqiang Wei",
        "Liping Yuan",
        "Hang Li"
      ],
      "abstract": "Generating rich and controllable motion is a pivotal challenge in video\nsynthesis. We propose Boximator, a new approach for fine-grained motion\ncontrol. Boximator introduces two constraint types: hard box and soft box.\nUsers select objects in the conditional frame using hard boxes and then use\neither type of boxes to roughly or rigorously define the object's position,\nshape, or motion path in future frames. Boximator functions as a plug-in for\nexisting video diffusion models. Its training process preserves the base\nmodel's knowledge by freezing the original weights and training only the\ncontrol module. To address training challenges, we introduce a novel\nself-tracking technique that greatly simplifies the learning of box-object\ncorrelations. Empirically, Boximator achieves state-of-the-art video quality\n(FVD) scores, improving on two base models, and further enhanced after\nincorporating box constraints. Its robust motion controllability is validated\nby drastic increases in the bounding box alignment metric. Human evaluation\nalso shows that users favor Boximator generation results over the base model.",
      "tldr_zh": "该论文提出Boximator，一种用于视频合成的细粒度运动控制方法，通过引入hard box和soft box约束，让用户定义对象在未来帧中的位置、形状或运动路径。Boximator作为现有视频扩散模型的插件，仅训练控制模块并冻结原权重，同时采用新型自跟踪技术简化box-object相关性学习。实验结果显示，Boximator在FVD视频质量指标上超越基线模型，并在bounding box alignment指标上大幅提升，人为评估也表明用户更偏好其生成结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01566v1",
      "published_date": "2024-02-02 16:59:48 UTC",
      "updated_date": "2024-02-02 16:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:27:55.333817"
    },
    {
      "arxiv_id": "2402.01546v1",
      "title": "Privacy-Preserving Distributed Learning for Residential Short-Term Load Forecasting",
      "title_zh": "用于住宅短期负荷预测的隐私保护分布式学习",
      "authors": [
        "Yi Dong",
        "Yingjie Wang",
        "Mariana Gama",
        "Mustafa A. Mustafa",
        "Geert Deconinck",
        "Xiaowei Huang"
      ],
      "abstract": "In the realm of power systems, the increasing involvement of residential\nusers in load forecasting applications has heightened concerns about data\nprivacy. Specifically, the load data can inadvertently reveal the daily\nroutines of residential users, thereby posing a risk to their property\nsecurity. While federated learning (FL) has been employed to safeguard user\nprivacy by enabling model training without the exchange of raw data, these FL\nmodels have shown vulnerabilities to emerging attack techniques, such as Deep\nLeakage from Gradients and poisoning attacks. To counteract these, we initially\nemploy a Secure-Aggregation (SecAgg) algorithm that leverages multiparty\ncomputation cryptographic techniques to mitigate the risk of gradient leakage.\nHowever, the introduction of SecAgg necessitates the deployment of additional\nsub-center servers for executing the multiparty computation protocol, thereby\nescalating computational complexity and reducing system robustness, especially\nin scenarios where one or more sub-centers are unavailable. To address these\nchallenges, we introduce a Markovian Switching-based distributed training\nframework, the convergence of which is substantiated through rigorous\ntheoretical analysis. The Distributed Markovian Switching (DMS) topology shows\nstrong robustness towards the poisoning attacks as well. Case studies employing\nreal-world power system load data validate the efficacy of our proposed\nalgorithm. It not only significantly minimizes communication complexity but\nalso maintains accuracy levels comparable to traditional FL methods, thereby\nenhancing the scalability of our load forecasting algorithm.",
      "tldr_zh": "本论文针对住宅短期负载预测中的隐私风险（如负载数据泄露用户日常routine），探讨了Federated Learning (FL) 的局限性，包括对Deep Leakage from Gradients和poisoning attacks的易感性。作者首先采用Secure-Aggregation (SecAgg)算法，通过多方计算加密技术减少梯度泄漏，但这增加了计算复杂性和系统脆弱性。为此，提出Distributed Markovian Switching (DMS)框架，并通过理论分析证明其收敛性，同时提升了对poisoning attacks的鲁棒性。实验结果显示，使用真实电力负载数据，该算法显著降低通信复杂性，保持与传统FL方法相当的准确性，并提高了整体可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01546v1",
      "published_date": "2024-02-02 16:39:08 UTC",
      "updated_date": "2024-02-02 16:39:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:28:07.144011"
    },
    {
      "arxiv_id": "2402.01822v2",
      "title": "Building Guardrails for Large Language Models",
      "title_zh": "为大型语言模型构建护栏",
      "authors": [
        "Yi Dong",
        "Ronghui Mu",
        "Gaojie Jin",
        "Yi Qi",
        "Jinwei Hu",
        "Xingyu Zhao",
        "Jie Meng",
        "Wenjie Ruan",
        "Xiaowei Huang"
      ],
      "abstract": "As Large Language Models (LLMs) become more integrated into our daily lives,\nit is crucial to identify and mitigate their risks, especially when the risks\ncan have profound impacts on human users and societies. Guardrails, which\nfilter the inputs or outputs of LLMs, have emerged as a core safeguarding\ntechnology. This position paper takes a deep look at current open-source\nsolutions (Llama Guard, Nvidia NeMo, Guardrails AI), and discusses the\nchallenges and the road towards building more complete solutions. Drawing on\nrobust evidence from previous research, we advocate for a systematic approach\nto construct guardrails for LLMs, based on comprehensive consideration of\ndiverse contexts across various LLMs applications. We propose employing\nsocio-technical methods through collaboration with a multi-disciplinary team to\npinpoint precise technical requirements, exploring advanced neural-symbolic\nimplementations to embrace the complexity of the requirements, and developing\nverification and testing to ensure the utmost quality of the final product.",
      "tldr_zh": "这篇论文讨论了为 Large Language Models (LLMs) 构建 Guardrails 的重要性，以识别和缓解其潜在风险，特别是对人类用户和社会的影响。作者审视了当前开源解决方案，如 Llama Guard、Nvidia NeMo 和 Guardrails AI，并分析了面临的挑战和构建更完整系统的路径。论文提倡采用系统方法，通过多学科团队合作来定义技术要求，探索高级神经符号实现以处理复杂性，并强调验证和测试以确保最终产品的质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 41st International Conference on Machine Learning,\n  Vienna, Austria. PMLR 235, 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01822v2",
      "published_date": "2024-02-02 16:35:00 UTC",
      "updated_date": "2024-05-29 12:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:28:20.008861"
    },
    {
      "arxiv_id": "2402.01821v2",
      "title": "Human-like Category Learning by Injecting Ecological Priors from Large Language Models into Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Akshay K. Jagadish",
        "Julian Coda-Forno",
        "Mirko Thalmann",
        "Eric Schulz",
        "Marcel Binz"
      ],
      "abstract": "Ecological rationality refers to the notion that humans are rational agents\nadapted to their environment. However, testing this theory remains challenging\ndue to two reasons: the difficulty in defining what tasks are ecologically\nvalid and building rational models for these tasks. In this work, we\ndemonstrate that large language models can generate cognitive tasks,\nspecifically category learning tasks, that match the statistics of real-world\ntasks, thereby addressing the first challenge. We tackle the second challenge\nby deriving rational agents adapted to these tasks using the framework of\nmeta-learning, leading to a class of models called ecologically rational\nmeta-learned inference (ERMI). ERMI quantitatively explains human data better\nthan seven other cognitive models in two different experiments. It additionally\nmatches human behavior on a qualitative level: (1) it finds the same tasks\ndifficult that humans find difficult, (2) it becomes more reliant on an\nexemplar-based strategy for assigning categories with learning, and (3) it\ngeneralizes to unseen stimuli in a human-like way. Furthermore, we show that\nERMI's ecologically valid priors allow it to achieve state-of-the-art\nperformance on the OpenML-CC18 classification benchmark.",
      "tldr_zh": "该研究探讨了生态理性(Ecological rationality)，通过利用大型语言模型(Large Language Models)生成与真实世界统计相匹配的类别学习任务，解决了定义生态有效任务的挑战。研究提出生态理性元学习推理(ERMI)模型，该模型基于元学习(meta-learning)框架注入生态先验，使其在两个实验中定量优于其他七个认知模型，并定性匹配人类行为，如识别难任务、依赖示例-based策略和人类-like泛化。此外，ERMI 在 OpenML-CC18 分类基准上实现了最先进性能，展示了其在模拟人类认知方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages (9 pages of main text, 4 pages of references, and 14 pages\n  of appendix), 13 figures, and 7 Tables",
      "pdf_url": "http://arxiv.org/pdf/2402.01821v2",
      "published_date": "2024-02-02 16:32:04 UTC",
      "updated_date": "2024-05-28 07:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:28:30.946156"
    },
    {
      "arxiv_id": "2402.01537v1",
      "title": "Closing the Gap in Human Behavior Analysis: A Pipeline for Synthesizing Trimodal Data",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Stippel",
        "Thomas Heitzinger",
        "Rafael Sterzinger",
        "Martin Kampel"
      ],
      "abstract": "In pervasive machine learning, especially in Human Behavior Analysis (HBA),\nRGB has been the primary modality due to its accessibility and richness of\ninformation. However, linked with its benefits are challenges, including\nsensitivity to lighting conditions and privacy concerns. One possibility to\novercome these vulnerabilities is to resort to different modalities. For\ninstance, thermal is particularly adept at accentuating human forms, while\ndepth adds crucial contextual layers. Despite their known benefits, only a few\nHBA-specific datasets that integrate these modalities exist. To address this\nshortage, our research introduces a novel generative technique for creating\ntrimodal, i.e., RGB, thermal, and depth, human-focused datasets. This technique\ncapitalizes on human segmentation masks derived from RGB images, combined with\nthermal and depth backgrounds that are sourced automatically. With these two\ningredients, we synthesize depth and thermal counterparts from existing RGB\ndata utilizing conditional image-to-image translation. By employing this\napproach, we generate trimodal data that can be leveraged to train models for\nsettings with limited data, bad lightning conditions, or privacy-sensitive\nareas.",
      "tldr_zh": "在人类行为分析(HBA)中，RGB 模态虽信息丰富，但易受光照条件和隐私问题影响，因此研究提出了一种新型管道，用于合成三模态(RGB、thermal 和 depth)数据集。 该方法利用从 RGB 图像中提取的人体分割掩码(human segmentation masks)，结合自动获取的 thermal 和 depth 背景，通过条件图像到图像翻译(conditional image-to-image translation)生成对应的 thermal 和 depth 数据。 这种合成技术能弥合多模态数据集的短缺，支持在数据有限、光照不良或隐私敏感场景下训练更鲁棒的 HBA 模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01537v1",
      "published_date": "2024-02-02 16:27:45 UTC",
      "updated_date": "2024-02-02 16:27:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:28:44.105494"
    },
    {
      "arxiv_id": "2402.01536v2",
      "title": "Homogenization Effects of Large Language Models on Human Creative Ideation",
      "title_zh": "翻译失败",
      "authors": [
        "Barrett R. Anderson",
        "Jash Hemant Shah",
        "Max Kreminski"
      ],
      "abstract": "Large language models (LLMs) are now being used in a wide variety of\ncontexts, including as creativity support tools (CSTs) intended to help their\nusers come up with new ideas. But do LLMs actually support user creativity? We\nhypothesized that the use of an LLM as a CST might make the LLM's users feel\nmore creative, and even broaden the range of ideas suggested by each individual\nuser, but also homogenize the ideas suggested by different users. We conducted\na 36-participant comparative user study and found, in accordance with the\nhomogenization hypothesis, that different users tended to produce less\nsemantically distinct ideas with ChatGPT than with an alternative CST.\nAdditionally, ChatGPT users generated a greater number of more detailed ideas,\nbut felt less responsible for the ideas they generated. We discuss potential\nimplications of these findings for users, designers, and developers of\nLLM-based CSTs.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 作为创意支持工具 (CSTs) 对人类创意构思的影响，假设其使用可能提升用户创意感知和个人想法范围，但会使不同用户的想法趋于同质化。研究通过一项36名参与者的比较用户研究发现，与其他CST相比，使用ChatGPT的用户生成更少的语义Distinct想法，尽管产生了更多详细的想法，但对这些想法的责任感更低。论文讨论了这些发现对LLM-based CST的用户、设计师和开发者的潜在影响，包括如何平衡创意支持与多样性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to C&C 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01536v2",
      "published_date": "2024-02-02 16:27:11 UTC",
      "updated_date": "2024-05-10 20:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:28:54.925312"
    },
    {
      "arxiv_id": "2402.01535v2",
      "title": "An Empirical Analysis of Diversity in Argument Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Michiel van der Meer",
        "Piek Vossen",
        "Catholijn M. Jonker",
        "Pradeep K. Murukannaiah"
      ],
      "abstract": "Presenting high-level arguments is a crucial task for fostering participation\nin online societal discussions. Current argument summarization approaches miss\nan important facet of this task -- capturing diversity -- which is important\nfor accommodating multiple perspectives. We introduce three aspects of\ndiversity: those of opinions, annotators, and sources. We evaluate approaches\nto a popular argument summarization task called Key Point Analysis, which shows\nhow these approaches struggle to (1) represent arguments shared by few people,\n(2) deal with data from various sources, and (3) align with subjectivity in\nhuman-provided annotations. We find that both general-purpose LLMs and\ndedicated KPA models exhibit this behavior, but have complementary strengths.\nFurther, we observe that diversification of training data may ameliorate\ngeneralization. Addressing diversity in argument summarization requires a mix\nof strategies to deal with subjectivity.",
      "tldr_zh": "本论文通过实证分析探讨了论点总结中的多样性问题，强调其在在线社会讨论中容纳多种视角的重要性。研究引入了opinions（意见）、annotators（标注者）和sources（来源）三种多样性方面，并评估了Key Point Analysis（KPA）任务中现有方法的表现，发现这些方法难以代表少数人共享的论点、处理多来源数据，以及与人类标注的主观性对齐。结果显示，通用LLMs和专用的KPA模型都存在这些局限，但二者具有互补优势，而训练数据的多样化可改善模型的泛化能力。总之，处理多样性需要结合多种策略来应对主观性挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EACL2024 (main proceedings)",
      "pdf_url": "http://arxiv.org/pdf/2402.01535v2",
      "published_date": "2024-02-02 16:26:52 UTC",
      "updated_date": "2024-02-14 10:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:29:08.196972"
    },
    {
      "arxiv_id": "2402.01521v2",
      "title": "K-Level Reasoning: Establishing Higher Order Beliefs in Large Language Models for Strategic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yadong Zhang",
        "Shaoguang Mao",
        "Tao Ge",
        "Xun Wang",
        "Yan Xia",
        "Man Lan",
        "Furu Wei"
      ],
      "abstract": "Strategic reasoning is a complex yet essential capability for intelligent\nagents. It requires Large Language Model (LLM) agents to adapt their strategies\ndynamically in multi-agent environments. Unlike static reasoning tasks, success\nin these contexts depends on anticipating other agents' beliefs and actions\nwhile continuously adjusting strategies to achieve individual goals. LLMs and\nLLM agents often struggle with strategic reasoning due to the absence of a\nreasoning framework that enables them to dynamically infer others' perspectives\nand adapt to changing environments. Inspired by the Level-K framework from game\ntheory and behavioral economics, which extends reasoning from simple reactions\nto structured strategic depth, we propose a novel framework: \"K-Level Reasoning\nwith Large Language Models (K-R).\" This framework employs recursive mechanisms\nto enable LLMs to achieve varying levels of strategic depth, allowing agents to\nform higher order beliefs - beliefs about others' beliefs. We validate this\nframework through rigorous testing on four testbeds: two classical game theory\nproblems and two social intelligence tasks. The results demonstrate the\nadvantages of K-R in strategic reasoning. Our work presents the first recursive\nimplementation of strategic depth in large language models (LLMs). It\nestablishes a foundation for future research into theory of mind and strategic\nreasoning in LLMs.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在多代理环境中的战略推理难题，提出了一种名为 K-Level Reasoning (K-R) 的新框架，以帮助 LLMs 动态推断其他代理的信念并适应变化。K-R 框架借鉴游戏理论的 Level-K 模型，通过递归机制实现不同级别的战略深度，形成更高阶信念（beliefs about others' beliefs）。实验在四个测试平台（包括经典游戏理论问题和社会智能任务）上验证了 K-R 的优势，这是 LLM 中战略深度的首次递归实现，为理论 of mind 和未来战略推理研究奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01521v2",
      "published_date": "2024-02-02 16:07:05 UTC",
      "updated_date": "2024-10-17 16:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:29:21.264089"
    },
    {
      "arxiv_id": "2402.01515v1",
      "title": "Enhancing Stochastic Gradient Descent: A Unified Framework and Novel Acceleration Methods for Faster Convergence",
      "title_zh": "增强随机梯度下降：一个统一的框架和新颖的加速方法以实现更快收敛",
      "authors": [
        "Yichuan Deng",
        "Zhao Song",
        "Chiwun Yang"
      ],
      "abstract": "Based on SGD, previous works have proposed many algorithms that have improved\nconvergence speed and generalization in stochastic optimization, such as SGDm,\nAdaGrad, Adam, etc. However, their convergence analysis under non-convex\nconditions is challenging. In this work, we propose a unified framework to\naddress this issue. For any first-order methods, we interpret the updated\ndirection $g_t$ as the sum of the stochastic subgradient $\\nabla f_t(x_t)$ and\nan additional acceleration term $\\frac{2|\\langle v_t, \\nabla f_t(x_t)\n\\rangle|}{\\|v_t\\|_2^2} v_t$, thus we can discuss the convergence by analyzing\n$\\langle v_t, \\nabla f_t(x_t) \\rangle$. Through our framework, we have\ndiscovered two plug-and-play acceleration methods: \\textbf{Reject Accelerating}\nand \\textbf{Random Vector Accelerating}, we theoretically demonstrate that\nthese two methods can directly lead to an improvement in convergence rate.",
      "tldr_zh": "本论文提出一个统一框架，用于增强随机梯度下降（SGD）算法在非凸条件下的收敛分析，将更新方向分解为随机子梯度（∇f_t(x_t)）和一个加速项（\\frac{2|\\langle v_t, \\nabla f_t(x_t) \\rangle|}{\\|v_t\\|_2^2} v_t），从而通过分析内积\\langle v_t, \\nabla f_t(x_t) \\rangle来评估收敛性能。该框架解决了现有算法如SGDm、AdaGrad和Adam等在非凸优化中的挑战。论文进一步引入了两种即插即用加速方法：Reject Accelerating和Random Vector Accelerating，并理论证明这些方法能直接改善收敛率，为随机优化提供更高效的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01515v1",
      "published_date": "2024-02-02 15:55:25 UTC",
      "updated_date": "2024-02-02 15:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:29:34.395826"
    },
    {
      "arxiv_id": "2402.01499v3",
      "title": "Developing and Evaluating a Design Method for Positive Artificial Intelligence",
      "title_zh": "开发和评估一种针对积极人工智能的设计方法",
      "authors": [
        "Willem van der Maden",
        "Derek Lomas",
        "Paul Hekkert"
      ],
      "abstract": "As artificial intelligence (AI) continues advancing, ensuring positive\nsocietal impacts becomes critical, especially as AI systems become increasingly\nubiquitous in various aspects of life. However, developing \"AI for good\" poses\nsubstantial challenges around aligning systems with complex human values.\nPresently, we lack mature methods for addressing these challenges. This article\npresents and evaluates the Positive AI design method aimed at addressing this\ngap. The method provides a human-centered process to translate wellbeing\naspirations into concrete practices. First, we explain the method's four key\nsteps: contextualizing, operationalizing, optimizing, and implementing\nwellbeing supported by continuous measurement for feedback cycles. We then\npresent a multiple case study where novice designers applied the method,\nrevealing strengths and weaknesses related to efficacy and usability. Next, an\nexpert evaluation study assessed the quality of the resulting concepts, rating\nthem moderately high for feasibility, desirability, and plausibility of\nachieving intended wellbeing benefits. Together, these studies provide\npreliminary validation of the method's ability to improve AI design, while\nsurfacing areas needing refinement like developing support for complex steps.\nProposed adaptations such as examples and evaluation heuristics could address\nweaknesses. Further research should examine sustained application over multiple\nprojects. This human-centered approach shows promise for realizing the vision\nof 'AI for Wellbeing' that does not just avoid harm, but actively benefits\nhumanity.",
      "tldr_zh": "这篇论文提出了一种名为 Positive AI 的设计方法，旨在通过人类中心的方法确保人工智能（AI）系统与复杂人类价值观一致，实现积极的社会影响。该方法包括四个关键步骤：contextualizing（情境化）、operationalizing（操作化）、optimizing（优化）和 implementing（实施）福祉，并通过持续测量提供反馈循环。研究通过多案例研究评估了初学者设计师的应用，发现方法在功效和可用性方面存在优势和弱点，同时专家评估显示生成的概念在可行性、吸引力及福祉益处方面得分较高。尽管初步验证表明 Positive AI 方法能提升 AI 设计，但论文指出需改进复杂步骤，如提供示例和评估启发式，并建议未来研究探索其在多个项目中的持续应用，以推动“AI for Wellbeing”的愿景。",
      "categories": [
        "cs.AI",
        "68T01",
        "H.5.2; I.2.9; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01499v3",
      "published_date": "2024-02-02 15:31:08 UTC",
      "updated_date": "2024-12-19 09:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:29:44.858844"
    },
    {
      "arxiv_id": "2402.01481v4",
      "title": "Pre-Training Protein Bi-level Representation Through Span Mask Strategy On 3D Protein Chains",
      "title_zh": "翻译失败",
      "authors": [
        "Jiale Zhao",
        "Wanru Zhuang",
        "Jia Song",
        "Yaqi Li",
        "Shuqi Lu"
      ],
      "abstract": "In recent years, there has been a surge in the development of 3D\nstructure-based pre-trained protein models, representing a significant\nadvancement over pre-trained protein language models in various downstream\ntasks. However, most existing structure-based pre-trained models primarily\nfocus on the residue level, i.e., alpha carbon atoms, while ignoring other\natoms like side chain atoms. We argue that modeling proteins at both residue\nand atom levels is important since the side chain atoms can also be crucial for\nnumerous downstream tasks, for example, molecular docking. Nevertheless, we\nfind that naively combining residue and atom information during pre-training\ntypically fails. We identify a key reason is the information leakage caused by\nthe inclusion of atom structure in the input, which renders residue-level\npre-training tasks trivial and results in insufficiently expressive residue\nrepresentations. To address this issue, we introduce a span mask pre-training\nstrategy on 3D protein chains to learn meaningful representations of both\nresidues and atoms. This leads to a simple yet effective approach to learning\nprotein representation suitable for diverse downstream tasks. Extensive\nexperimental results on binding site prediction and function prediction tasks\ndemonstrate our proposed pre-training approach significantly outperforms other\nmethods. Our code will be made public.",
      "tldr_zh": "本论文指出，现有的3D结构基于蛋白质预训练模型主要关注residue level（如alpha carbon atoms），而忽略了atom levels（如side chain atoms），这在molecular docking等下游任务中可能导致关键信息缺失。作者发现，直接结合residue和atom信息会导致information leakage，使residue-level预训练任务变得简单，并影响表示表达性。为解决此问题，提出了一种span mask pre-training strategy，在3D protein chains上学习残基和原子的双水平表示，从而实现简单有效的蛋白质表示。实验结果显示，该方法在binding site prediction和function prediction任务上显著优于其他方法，代码将公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01481v4",
      "published_date": "2024-02-02 15:07:09 UTC",
      "updated_date": "2024-06-02 23:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:29:59.605365"
    },
    {
      "arxiv_id": "2402.01476v2",
      "title": "Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes",
      "title_zh": "通过核",
      "authors": [
        "Yingyi Chen",
        "Qinghua Tao",
        "Francesco Tonin",
        "Johan A. K. Suykens"
      ],
      "abstract": "While the great capability of Transformers significantly boosts prediction\naccuracy, it could also yield overconfident predictions and require calibrated\nuncertainty estimation, which can be commonly tackled by Gaussian processes\n(GPs). Existing works apply GPs with symmetric kernels under variational\ninference to the attention kernel; however, omitting the fact that attention\nkernels are in essence asymmetric. Moreover, the complexity of deriving the GP\nposteriors remains high for large-scale data. In this work, we propose\nKernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for building\nuncertainty-aware self-attention where the asymmetry of attention kernels is\ntackled by Kernel SVD (KSVD) and a reduced complexity is acquired. Through\nKEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors from\nKSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) using\nonly a small set of adjoint eigenfunctions from KSVD, the derivation of SVGP\nposteriors can be based on the inversion of a diagonal matrix containing\nsingular values, contributing to a reduction in time complexity; iii) an\nevidence lower bound is derived so that variational parameters and network\nweights can be optimized with it. Experiments verify our excellent performances\nand efficiency on in-distribution, distribution-shift and out-of-distribution\nbenchmarks.",
      "tldr_zh": "本研究提出了一种名为 Kernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) 的方法，用于构建不确定性感知的自注意力机制，以解决 Transformers 模型的过度自信预测问题。KEP-SVGP 通过 Kernel SVD (KSVD) 处理注意力核的本质不对称性，并利用 KSVD 的奇异向量集和伴随特征函数来简化 SVGP 后验推导，从而降低计算复杂度并基于证据下界优化变分参数和网络权重。实验结果显示，该方法在分布内、分布偏移和分布外基准上表现出色，提高了预测性能和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "We propose Kernel-Eigen Pair Sparse Variational Gaussian Processes\n  (KEP-SVGP) for building uncertainty-aware self-attention where the asymmetry\n  of attention kernel is tackled by KSVD and a reduced time complexity is\n  acquired",
      "pdf_url": "http://arxiv.org/pdf/2402.01476v2",
      "published_date": "2024-02-02 15:05:13 UTC",
      "updated_date": "2024-05-28 09:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:30:12.240413"
    },
    {
      "arxiv_id": "2402.01467v2",
      "title": "Brain-Like Replay Naturally Emerges in Reinforcement Learning Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyi Wang",
        "Likai Tang",
        "Huimiao Chen",
        "Marcelo G Mattar",
        "Sen Song"
      ],
      "abstract": "Replay is a powerful strategy to promote learning in artificial intelligence\nand the brain. However, the conditions to generate it and its functional\nadvantages have not been fully recognized. In this study, we develop a modular\nreinforcement learning model that could generate replay. We prove that replay\ngenerated in this way helps complete the task. We also analyze the information\ncontained in the representation and provide a mechanism for how replay makes a\ndifference. Our design avoids complex assumptions and enables replay to emerge\nnaturally within a task-optimized paradigm. Our model also reproduces key\nphenomena observed in biological agents. This research explores the structural\nbiases in modular ANN to generate replay and its potential utility in\ndeveloping efficient RL.",
      "tldr_zh": "本研究开发了一个模块化强化学习（Reinforcement Learning）模型，能够自然生成类似于大脑的Replay策略，以促进学习。该模型证明了Replay有助于任务完成，并通过分析表示中的信息，揭示了其影响机制。该设计避免复杂假设，使Replay在任务优化范式中自然出现，并成功复制了生物代理的关键现象，为开发高效RL提供潜在效用。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.CE",
        "cs.NE",
        "cs.SY",
        "q-bio.NC"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01467v2",
      "published_date": "2024-02-02 14:55:51 UTC",
      "updated_date": "2024-10-06 21:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:30:21.022718"
    },
    {
      "arxiv_id": "2402.01454v5",
      "title": "Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Masayuki Takayama",
        "Tadahisa Okuda",
        "Thong Pham",
        "Tatsuyoshi Ikenoue",
        "Shingo Fukuma",
        "Shohei Shimizu",
        "Akiyoshi Sannai"
      ],
      "abstract": "In practical statistical causal discovery (SCD), embedding domain expert\nknowledge as constraints into the algorithm is important for reasonable causal\nmodels reflecting the broad knowledge of domain experts, despite the challenges\nin the systematic acquisition of background knowledge. To overcome these\nchallenges, this paper proposes a novel method for causal inference, in which\nSCD and knowledge-based causal inference (KBCI) with a large language model\n(LLM) are synthesized through ``statistical causal prompting (SCP)'' for LLMs\nand prior knowledge augmentation for SCD. The experiments in this work have\nrevealed that the results of LLM-KBCI and SCD augmented with LLM-KBCI approach\nthe ground truths, more than the SCD result without prior knowledge. These\nexperiments have also revealed that the SCD result can be further improved if\nthe LLM undergoes SCP. Furthermore, with an unpublished real-world dataset, we\nhave demonstrated that the background knowledge provided by the LLM can improve\nthe SCD on this dataset, even if this dataset has never been included in the\ntraining data of the LLM. For future practical application of this proposed\nmethod across important domains such as healthcare, we also thoroughly discuss\nthe limitations, risks of critical errors, expected improvement of techniques\naround LLMs, and realistic integration of expert checks of the results into\nthis automatic process, with SCP simulations under various conditions both in\nsuccessful and failure scenarios. The careful and appropriate application of\nthe proposed approach in this work, with improvement and customization for each\ndomain, can thus address challenges such as dataset biases and limitations,\nillustrating the potential of LLMs to improve data-driven causal inference\nacross diverse scientific domains.\n  The code used in this work is publicly available at:\nwww.github.com/mas-takayama/LLM-and-SCD",
      "tldr_zh": "本文提出了一种整合大型语言模型 (LLMs) 与统计因果发现 (SCD) 的新方法，通过“statistical causal prompting (SCP)”为 LLMs 提供提示，并对 SCD 进行先验知识增强，从而克服背景知识获取的挑战。实验结果显示，该方法使 SCD 结果更接近真实值，并在未见过的真实数据集上显著提升性能。作者还讨论了该方法的局限性、潜在风险以及在医疗等领域的实际应用前景，以缓解数据集偏差等问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01454v5",
      "published_date": "2024-02-02 14:43:19 UTC",
      "updated_date": "2025-05-11 11:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:30:35.227233"
    },
    {
      "arxiv_id": "2402.01817v3",
      "title": "LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks",
      "title_zh": "LLMs 无法规划，但能在 LLM-Modulo 框架中帮助规划",
      "authors": [
        "Subbarao Kambhampati",
        "Karthik Valmeekam",
        "Lin Guan",
        "Mudit Verma",
        "Kaya Stechly",
        "Siddhant Bhambri",
        "Lucas Saldyt",
        "Anil Murthy"
      ],
      "abstract": "There is considerable confusion about the role of Large Language Models\n(LLMs) in planning and reasoning tasks. On one side are over-optimistic claims\nthat LLMs can indeed do these tasks with just the right prompting or\nself-verification strategies. On the other side are perhaps over-pessimistic\nclaims that all that LLMs are good for in planning/reasoning tasks are as mere\ntranslators of the problem specification from one syntactic format to another,\nand ship the problem off to external symbolic solvers. In this position paper,\nwe take the view that both these extremes are misguided. We argue that\nauto-regressive LLMs cannot, by themselves, do planning or self-verification\n(which is after all a form of reasoning), and shed some light on the reasons\nfor misunderstandings in the literature. We will also argue that LLMs should be\nviewed as universal approximate knowledge sources that have much more\nmeaningful roles to play in planning/reasoning tasks beyond simple\nfront-end/back-end format translators. We present a vision of {\\bf LLM-Modulo\nFrameworks} that combine the strengths of LLMs with external model-based\nverifiers in a tighter bi-directional interaction regime. We will show how the\nmodels driving the external verifiers themselves can be acquired with the help\nof LLMs. We will also argue that rather than simply pipelining LLMs and\nsymbolic components, this LLM-Modulo Framework provides a better neuro-symbolic\napproach that offers tighter integration between LLMs and symbolic components,\nand allows extending the scope of model-based planning/reasoning regimes\ntowards more flexible knowledge, problem and preference specifications.",
      "tldr_zh": "这篇论文讨论了大型语言模型（LLMs）在规划和推理任务中的角色，驳斥了过度乐观（LLMs 通过提示即可独立完成任务）和过度悲观（LLMs 仅作为格式翻译工具）的极端观点。作者认为 auto-regressive LLMs 本身无法进行规划或自验证，但可作为通用近似知识来源，与外部符号验证器紧密结合。论文提出 LLM-Modulo Frameworks 的愿景，这种框架通过双向互动整合 LLMs 和模型验证器，并利用 LLMs 来获取验证器模型，实现更紧密的神经符号（neuro-symbolic）方法。最终，这有助于扩展基于模型的规划/推理系统，使其适应更灵活的知识、问题和偏好规格。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01817v3",
      "published_date": "2024-02-02 14:43:18 UTC",
      "updated_date": "2024-06-12 01:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:30:44.969827"
    },
    {
      "arxiv_id": "2402.01446v2",
      "title": "Guidance Graph Optimization for Lifelong Multi-Agent Path Finding",
      "title_zh": "翻译失败",
      "authors": [
        "Yulun Zhang",
        "He Jiang",
        "Varun Bhatt",
        "Stefanos Nikolaidis",
        "Jiaoyang Li"
      ],
      "abstract": "We study how to use guidance to improve the throughput of lifelong\nMulti-Agent Path Finding (MAPF). Previous studies have demonstrated that, while\nincorporating guidance, such as highways, can accelerate MAPF algorithms, this\noften results in a trade-off with solution quality. In addition, how to\ngenerate good guidance automatically remains largely unexplored, with current\nmethods falling short of surpassing manually designed ones. In this work, we\nintroduce the guidance graph as a versatile representation of guidance for\nlifelong MAPF, framing Guidance Graph Optimization as the task of optimizing\nits edge weights. We present two GGO algorithms to automatically generate\nguidance for arbitrary lifelong MAPF algorithms and maps. The first method\ndirectly optimizes edge weights, while the second method optimizes an update\nmodel capable of generating edge weights. Empirically, we show that (1) our\nguidance graphs improve the throughput of three representative lifelong MAPF\nalgorithms in eight benchmark maps, and (2) our update model can generate\nguidance graphs for as large as $93 \\times 91$ maps and as many as 3,000\nagents. We include the source code at:\n\\url{https://github.com/lunjohnzhang/ggo_public}. All optimized guidance graphs\nare available online at: \\url{https://yulunzhang.net/publication/zhang2024ggo}.",
      "tldr_zh": "这篇论文针对终身多智能体路径寻找（lifelong Multi-Agent Path Finding, MAPF）提出了一种Guidance Graph Optimization (GGO)方法，以提升算法的吞吐量，同时缓解以往指导机制对解决方案质量的权衡问题。研究引入指导图作为指导的通用表示，并开发了两个GGO算法：一个直接优化边权重，另一个优化更新模型以自动生成边权重。实验结果显示，该方法在八个基准地图上改善了三个代表性终身MAPF算法的性能，并能处理高达93×91的地图和多达3,000个代理，为自动生成高效指导提供了实用框架。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted to International Joint Conference on Artificial Intelligence\n  (IJCAI), 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01446v2",
      "published_date": "2024-02-02 14:38:04 UTC",
      "updated_date": "2024-05-09 19:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:30:59.600611"
    },
    {
      "arxiv_id": "2402.01444v1",
      "title": "Mission Critical -- Satellite Data is a Distinct Modality in Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Esther Rolf",
        "Konstantin Klemmer",
        "Caleb Robinson",
        "Hannah Kerner"
      ],
      "abstract": "Satellite data has the potential to inspire a seismic shift for machine\nlearning -- one in which we rethink existing practices designed for traditional\ndata modalities. As machine learning for satellite data (SatML) gains traction\nfor its real-world impact, our field is at a crossroads. We can either continue\napplying ill-suited approaches, or we can initiate a new research agenda that\ncenters around the unique characteristics and challenges of satellite data.\nThis position paper argues that satellite data constitutes a distinct modality\nfor machine learning research and that we must recognize it as such to advance\nthe quality and impact of SatML research across theory, methods, and\ndeployment. We outline critical discussion questions and actionable suggestions\nto transform SatML from merely an intriguing application area to a dedicated\nresearch discipline that helps move the needle on big challenges for machine\nlearning and society.",
      "tldr_zh": "这篇立场论文主张，satellite data 应被视为 machine learning 的一个独特模态，因为其独特特性和挑战（如数据获取和处理方式）与传统模态不同。论文批评当前机器学习实践不适合 satellite data，并呼吁建立一个新的研究议程，聚焦理论、方法和部署方面的创新，以提升 SatML 的质量和实际影响。作者提出了关键讨论问题和可行动建议，旨在将 SatML 从一个应用领域转变为独立的学科，从而推动 machine learning 在社会重大挑战上的进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01444v1",
      "published_date": "2024-02-02 14:36:50 UTC",
      "updated_date": "2024-02-02 14:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:31:08.827304"
    },
    {
      "arxiv_id": "2402.01440v4",
      "title": "A Survey of Few-Shot Learning on Graphs: from Meta-Learning to Pre-Training and Prompt Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xingtong Yu",
        "Yuan Fang",
        "Zemin Liu",
        "Yuxia Wu",
        "Zhihao Wen",
        "Jianyuan Bo",
        "Xinming Zhang",
        "Steven C. H. Hoi"
      ],
      "abstract": "Graph representation learning, a critical step in graph-centric tasks, has\nseen significant advancements. Earlier techniques often operate in an\nend-to-end setting, which heavily rely on the availability of ample labeled\ndata. This constraint has spurred the emergence of few-shot learning on graphs,\nwhere only a few labels are available for each task. Given the extensive\nliterature in this field, this survey endeavors to synthesize recent\ndevelopments, provide comparative insights, and identify future directions. We\nsystematically categorize existing studies based on two major taxonomies: (1)\nProblem taxonomy, which explores different types of data scarcity problems and\ntheir applications, and (2) Technique taxonomy, which details key strategies\nfor addressing these data-scarce few-shot problems. The techniques can be\nbroadly categorized into meta-learning, pre-training, and hybrid approaches,\nwith a finer-grained classification in each category to aid readers in their\nmethod selection process. Within each category, we analyze the relationships\namong these methods and compare their strengths and limitations. Finally, we\noutline prospective directions for few-shot learning on graphs to catalyze\ncontinued innovation in this field. The website for this survey can be accessed\nby \\url{https://github.com/smufang/fewshotgraph}.",
      "tldr_zh": "这篇调查综述了图表示学习(Graph representation learning)中的Few-Shot Learning发展，强调了在数据稀缺条件下（如仅有少量标签）如何处理图相关任务。论文基于问题分类(Problem taxonomy)探讨了不同数据稀缺类型及其应用，并从技术分类(Technique taxonomy)角度细化了解决策略，主要包括Meta-Learning、Pre-Training和混合方法(Hybrid approaches)，并比较了这些方法的优缺点及关系。最后，它指出了Few-Shot Learning在图领域的未来方向，以推动创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01440v4",
      "published_date": "2024-02-02 14:32:42 UTC",
      "updated_date": "2024-09-20 05:27:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:31:22.373882"
    },
    {
      "arxiv_id": "2402.01439v1",
      "title": "From Words to Molecules: A Survey of Large Language Models in Chemistry",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Liao",
        "Yemin Yu",
        "Yu Mei",
        "Ying Wei"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have achieved significant\nsuccess in natural language processing (NLP) and various interdisciplinary\nareas. However, applying LLMs to chemistry is a complex task that requires\nspecialized domain knowledge. This paper provides a thorough exploration of the\nnuanced methodologies employed in integrating LLMs into the field of chemistry,\ndelving into the complexities and innovations at this interdisciplinary\njuncture. Specifically, our analysis begins with examining how molecular\ninformation is fed into LLMs through various representation and tokenization\nmethods. We then categorize chemical LLMs into three distinct groups based on\nthe domain and modality of their input data, and discuss approaches for\nintegrating these inputs for LLMs. Furthermore, this paper delves into the\npretraining objectives with adaptations to chemical LLMs. After that, we\nexplore the diverse applications of LLMs in chemistry, including novel\nparadigms for their application in chemistry tasks. Finally, we identify\npromising research directions, including further integration with chemical\nknowledge, advancements in continual learning, and improvements in model\ninterpretability, paving the way for groundbreaking developments in the field.",
      "tldr_zh": "这篇论文对Large Language Models (LLMs) 在化学领域的应用进行全面调查，探讨了将LLMs 整合到化学中的复杂方法，包括分子信息的表示、tokenization 和输入数据分类。论文将化学LLMs 分为三种类型（基于输入数据的领域和模态），并分析了预训练目标的适应以及在化学任务中的多样应用，如新范式创新。最终，它指出了未来研究方向，包括与化学知识的进一步整合、持续学习（continual learning）的进展，以及模型可解释性（model interpretability）的提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IJCAI 2024 survey track",
      "pdf_url": "http://arxiv.org/pdf/2402.01439v1",
      "published_date": "2024-02-02 14:30:48 UTC",
      "updated_date": "2024-02-02 14:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:31:35.291741"
    },
    {
      "arxiv_id": "2402.01416v1",
      "title": "Sequence Shortening for Context-Aware Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Paweł Mąka",
        "Yusuf Can Semerci",
        "Jan Scholtes",
        "Gerasimos Spanakis"
      ],
      "abstract": "Context-aware Machine Translation aims to improve translations of sentences\nby incorporating surrounding sentences as context. Towards this task, two main\narchitectures have been applied, namely single-encoder (based on concatenation)\nand multi-encoder models. In this study, we show that a special case of\nmulti-encoder architecture, where the latent representation of the source\nsentence is cached and reused as the context in the next step, achieves higher\naccuracy on the contrastive datasets (where the models have to rank the correct\ntranslation among the provided sentences) and comparable BLEU and COMET scores\nas the single- and multi-encoder approaches. Furthermore, we investigate the\napplication of Sequence Shortening to the cached representations. We test three\npooling-based shortening techniques and introduce two novel methods - Latent\nGrouping and Latent Selecting, where the network learns to group tokens or\nselects the tokens to be cached as context. Our experiments show that the two\nmethods achieve competitive BLEU and COMET scores and accuracies on the\ncontrastive datasets to the other tested methods while potentially allowing for\nhigher interpretability and reducing the growth of memory requirements with\nincreased context size.",
      "tldr_zh": "本研究探讨了Context-Aware Machine Translation，通过整合周围句子作为上下文来提升句子翻译质量。研究者发现，一种特殊的multi-encoder架构（缓存源句子的潜在表示并在下一步重用）在对比数据集上比single-encoder和multi-encoder方法表现出更高的准确率，同时在BLEU和COMET分数上保持相当水平。进一步，他们引入了Sequence Shortening技术，包括三种池化-based缩短方法以及两种新方法Latent Grouping和Latent Selecting，这些允许网络学习分组或选择要缓存的标记。新方法不仅在BLEU、COMET分数和对比数据集准确率上与现有方法竞争，还提高了模型的可解释性和内存效率，减少了上下文大小增长带来的需求。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of the ACL: EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01416v1",
      "published_date": "2024-02-02 13:55:37 UTC",
      "updated_date": "2024-02-02 13:55:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:31:47.212802"
    },
    {
      "arxiv_id": "2402.01415v1",
      "title": "SMLP: Symbolic Machine Learning Prover",
      "title_zh": "翻译失败",
      "authors": [
        "Franz Brauße",
        "Zurab Khasidashvili",
        "Konstantin Korovin"
      ],
      "abstract": "Symbolic Machine Learning Prover (SMLP) is a tool and a library for system\nexploration based on data samples obtained by simulating or executing the\nsystem on a number of input vectors. SMLP aims at exploring the system based on\nthis data by taking a grey-box approach: SMLP combines statistical methods of\ndata exploration with building and exploring machine learning models in close\nfeedback loop with the system's response, and exploring these models by\ncombining probabilistic and formal methods. SMLP has been applied in industrial\nsetting at Intel for analyzing and optimizing hardware designs at the analog\nlevel. SMLP is a general purpose tool and can be applied to systems that can be\nsampled and modeled by machine learning models.",
      "tldr_zh": "SMLP 是一种符号机器学习证明器（Symbolic Machine Learning Prover），它是一个工具和库，用于基于系统模拟或执行产生的数据样本进行系统探索。SMLP 采用灰盒方法（grey-box approach），将统计数据探索与机器学习模型的构建相结合，并在与系统响应的反馈循环中应用概率和形式方法（probabilistic and formal methods）。该工具已在 Intel 的工业环境中用于分析和优化硬件设计，尤其在模拟级别，并作为一个通用工具适用于任何可通过机器学习模型（machine learning models）采样的系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "cs.SC",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures. (submitted)",
      "pdf_url": "http://arxiv.org/pdf/2402.01415v1",
      "published_date": "2024-02-02 13:53:29 UTC",
      "updated_date": "2024-02-02 13:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:31:56.717841"
    },
    {
      "arxiv_id": "2402.01410v1",
      "title": "XAI for Skin Cancer Detection with Prototypes and Non-Expert Supervision",
      "title_zh": "XAI 用于皮肤癌检测的原型和非专家监督",
      "authors": [
        "Miguel Correia",
        "Alceu Bissoto",
        "Carlos Santiago",
        "Catarina Barata"
      ],
      "abstract": "Skin cancer detection through dermoscopy image analysis is a critical task.\nHowever, existing models used for this purpose often lack interpretability and\nreliability, raising the concern of physicians due to their black-box nature.\nIn this paper, we propose a novel approach for the diagnosis of melanoma using\nan interpretable prototypical-part model. We introduce a guided supervision\nbased on non-expert feedback through the incorporation of: 1) binary masks,\nobtained automatically using a segmentation network; and 2) user-refined\nprototypes. These two distinct information pathways aim to ensure that the\nlearned prototypes correspond to relevant areas within the skin lesion,\nexcluding confounding factors beyond its boundaries. Experimental results\ndemonstrate that, even without expert supervision, our approach achieves\nsuperior performance and generalization compared to non-interpretable models.",
      "tldr_zh": "该论文针对皮肤癌检测中的可解释性问题，提出了一种基于 XAI 的可解释原型部分模型（interpretable prototypical-part model），利用非专家监督来提升模型可靠性。具体方法包括使用自动分割网络生成的二进制掩码（binary masks）和用户精炼的原型（user-refined prototypes），以确保原型聚焦于皮肤病变的相关区域并排除干扰因素。实验结果显示，即使没有专家监督，该方法在性能和泛化能力上均优于非可解释模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in the iMIMIC Workshop @ MICCAI 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.01410v1",
      "published_date": "2024-02-02 13:42:45 UTC",
      "updated_date": "2024-02-02 13:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:32:09.940148"
    },
    {
      "arxiv_id": "2402.01408v3",
      "title": "Counterfactual Concept Bottleneck Models",
      "title_zh": "反事实概念瓶颈模型",
      "authors": [
        "Gabriele Dominici",
        "Pietro Barbiero",
        "Francesco Giannini",
        "Martin Gjoreski",
        "Giuseppe Marra",
        "Marc Langheinrich"
      ],
      "abstract": "Current deep learning models are not designed to simultaneously address three\nfundamental questions: predict class labels to solve a given classification\ntask (the \"What?\"), simulate changes in the situation to evaluate how this\nimpacts class predictions (the \"How?\"), and imagine how the scenario should\nchange to result in different class predictions (the \"Why not?\"). The inability\nto answer these questions represents a crucial gap in deploying reliable AI\nagents, calibrating human trust, and improving human-machine interaction. To\nbridge this gap, we introduce CounterFactual Concept Bottleneck Models\n(CF-CBMs), a class of models designed to efficiently address the above queries\nall at once without the need to run post-hoc searches. Our experimental results\ndemonstrate that CF-CBMs: achieve classification accuracy comparable to\nblack-box models and existing CBMs (\"What?\"), rely on fewer important concepts\nleading to simpler explanations (\"How?\"), and produce interpretable,\nconcept-based counterfactuals (\"Why not?\"). Additionally, we show that training\nthe counterfactual generator jointly with the CBM leads to two key\nimprovements: (i) it alters the model's decision-making process, making the\nmodel rely on fewer important concepts (leading to simpler explanations), and\n(ii) it significantly increases the causal effect of concept interventions on\nclass predictions, making the model more responsive to these changes.",
      "tldr_zh": "这篇论文提出了 CounterFactual Concept Bottleneck Models (CF-CBMs)，一种新型模型，旨在同时解决深度学习模型在分类任务中的三个核心问题：\"What?\"（预测类标签）、\"How?\"（模拟情况变化对预测的影响）和\"Why not?\"（想象场景变化以改变预测）。CF-CBMs 通过整合概念瓶颈模型 (CBMs) 和 counterfactual 生成器，实现高效的查询响应，而无需后处理搜索。实验结果表明，该模型的分类准确率与黑盒模型和现有 CBMs 相当，同时依赖更少的概念，提供更简单的解释，并生成可解释的概念-based counterfactuals。此外，联合训练 counterfactual 生成器能优化决策过程，提高概念干预的因果效应，使模型更响应变化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01408v3",
      "published_date": "2024-02-02 13:42:12 UTC",
      "updated_date": "2025-02-20 12:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:32:23.598021"
    },
    {
      "arxiv_id": "2402.01401v4",
      "title": "An Information Theoretic Approach to Machine Unlearning",
      "title_zh": "基于信息理论的机器学习遗忘方法",
      "authors": [
        "Jack Foster",
        "Kyle Fogarty",
        "Stefan Schoepf",
        "Zack Dugue",
        "Cengiz Öztireli",
        "Alexandra Brintrup"
      ],
      "abstract": "To comply with AI and data regulations, the need to forget private or\ncopyrighted information from trained machine learning models is increasingly\nimportant. The key challenge in unlearning is forgetting the necessary data in\na timely manner, while preserving model performance. In this work, we address\nthe zero-shot unlearning scenario, whereby an unlearning algorithm must be able\nto remove data given only a trained model and the data to be forgotten. We\nexplore unlearning from an information theoretic perspective, connecting the\ninfluence of a sample to the information gain a model receives by observing it.\nFrom this, we derive a simple but principled zero-shot unlearning method based\non the geometry of the model. Our approach takes the form of minimising the\ngradient of a learned function with respect to a small neighbourhood around a\ntarget forget point. This induces a smoothing effect, causing forgetting by\nmoving the boundary of the classifier. We explore the intuition behind why this\napproach can jointly unlearn forget samples while preserving general model\nperformance through a series of low-dimensional experiments. We perform\nextensive empirical evaluation of our method over a range of contemporary\nbenchmarks, verifying that our method is competitive with state-of-the-art\nperformance under the strict constraints of zero-shot unlearning. Code for the\nproject can be found at\nhttps://github.com/jwf40/Information-Theoretic-Unlearning",
      "tldr_zh": "该研究从信息论视角探讨了机器取消学习（Machine Unlearning），旨在帮助模型忘记私有或版权数据，同时保持整体性能。作者提出了一种零-shot unlearning 方法，通过计算样本的信息增益并最小化学习函数相对于目标忘记点的梯度邻域，实现分类器边界的平滑调整，从而有效移除指定数据。实验结果显示，该方法在多种基准测试中表现出色，与最先进技术竞争，并在低维实验中验证了其在忘记样本的同时保留模型性能的优势。代码可从 https://github.com/jwf40/Information-Theoretic-Unlearning 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Updated, new low-dimensional experiments and updated perspective on\n  unlearning from an information theoretic view",
      "pdf_url": "http://arxiv.org/pdf/2402.01401v4",
      "published_date": "2024-02-02 13:33:30 UTC",
      "updated_date": "2024-12-02 00:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:32:35.553706"
    },
    {
      "arxiv_id": "2402.01399v3",
      "title": "A Probabilistic Model Behind Self-Supervised Learning",
      "title_zh": "自监督学习背后的概率模型",
      "authors": [
        "Alice Bizeul",
        "Bernhard Schölkopf",
        "Carl Allen"
      ],
      "abstract": "In self-supervised learning (SSL), representations are learned via an\nauxiliary task without annotated labels. A common task is to classify\naugmentations or different modalities of the data, which share semantic content\n(e.g. an object in an image) but differ in style (e.g. the object's location).\nMany approaches to self-supervised learning have been proposed, e.g. SimCLR,\nCLIP, and DINO, which have recently gained much attention for their\nrepresentations achieving downstream performance comparable to supervised\nlearning. However, a theoretical understanding of self-supervised methods\neludes. Addressing this, we present a generative latent variable model for\nself-supervised learning and show that several families of discriminative SSL,\nincluding contrastive methods, induce a comparable distribution over\nrepresentations, providing a unifying theoretical framework for these methods.\nThe proposed model also justifies connections drawn to mutual information and\nthe use of a ''projection head''. Learning representations by fitting the model\ngeneratively (termed SimVAE) improves performance over discriminative and other\nVAE-based methods on simple image benchmarks and significantly narrows the gap\nbetween generative and discriminative representation learning in more complex\nsettings. Importantly, as our analysis predicts, SimVAE outperforms\nself-supervised learning where style information is required, taking an\nimportant step toward understanding self-supervised methods and achieving\ntask-agnostic representations.",
      "tldr_zh": "本论文提出一个生成式潜在变量模型来解释自监督学习 (SSL)，其中 SSL 通过辅助任务（如分类数据增强）学习表示，而无需标注标签。该模型证明了多种判别式 SSL 方法（如 SimCLR、CLIP 和 DINO）会诱导相似的表示分布，从而提供了一个统一的理论框架，并解释了这些方法与互信息以及“projection head”的联系。作者引入了 SimVAE，通过生成式拟合模型来学习表示，在简单图像基准上优于判别式和其它 VAE 方法，并在复杂任务中显著缩小生成式与判别式表示学习的性能差距；此外，SimVAE 在需要风格信息的任务上表现出色，推动了任务无关表示的实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01399v3",
      "published_date": "2024-02-02 13:31:17 UTC",
      "updated_date": "2024-10-15 13:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:32:47.707899"
    },
    {
      "arxiv_id": "2402.01812v1",
      "title": "Distilling LLMs' Decomposition Abilities into Compact Language Models",
      "title_zh": "将 LLMs 的分解能力蒸馏到紧凑语言模型中",
      "authors": [
        "Denis Tarasov",
        "Kumar Shridhar"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated proficiency in their reasoning\nabilities, yet their large size presents scalability challenges and limits any\nfurther customization. In contrast, compact models offer customized training\nbut often fall short in solving complex reasoning tasks. This study focuses on\ndistilling the LLMs' decomposition skills into compact models using offline\nreinforcement learning. We leverage the advancements in the LLM`s capabilities\nto provide feedback and generate a specialized task-specific dataset for\ntraining compact models. The development of an AI-generated dataset and the\nestablishment of baselines constitute the primary contributions of our work,\nunderscoring the potential of compact models in replicating complex\nproblem-solving skills.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)强大的推理能力与尺寸大带来的可扩展性和自定义挑战，提出一种方法，通过离线强化学习将LLMs的分解技能蒸馏到紧凑语言模型中。研究利用LLMs提供反馈并生成特定任务数据集，用于训练紧凑模型，从而提升其在复杂推理任务上的表现。主要贡献包括开发AI生成数据集、建立性能基线，并证明紧凑模型具有复制复杂问题解决技能的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "https://github.com/DT6A/GSM8K-AI-SubQ",
      "pdf_url": "http://arxiv.org/pdf/2402.01812v1",
      "published_date": "2024-02-02 13:23:15 UTC",
      "updated_date": "2024-02-02 13:23:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:33:00.234781"
    },
    {
      "arxiv_id": "2402.01376v2",
      "title": "LoTR: Low Tensor Rank Weight Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Bershatsky",
        "Daria Cherniuk",
        "Talgat Daulbaev",
        "Aleksandr Mikhalev",
        "Ivan Oseledets"
      ],
      "abstract": "In this paper we generalize and extend an idea of low-rank adaptation (LoRA)\nof large language models (LLMs) based on Transformer architecture. Widely used\nLoRA-like methods of fine-tuning LLMs are based on matrix factorization of\ngradient update. We introduce LoTR, a novel approach for parameter-efficient\nfine-tuning of LLMs which represents a gradient update to parameters in a form\nof tensor decomposition. Low-rank adapter for each layer is constructed as a\nproduct of three matrices, and tensor structure arises from sharing left and\nright multipliers of this product among layers. Simultaneous compression of a\nsequence of layers with low-rank tensor representation allows LoTR to archive\neven better parameter efficiency then LoRA especially for deep models.\nMoreover, the core tensor does not depend on original weight dimension and can\nbe made arbitrary small, which allows for extremely cheap and fast downstream\nfine-tuning.",
      "tldr_zh": "本研究提出了 LoTR，一种基于张量分解的低秩权重适配方法，用于高效微调大型语言模型 (LLMs)。LoTR 通过将梯度更新表示为三个矩阵的乘积，并在层间共享左和右乘子，形成低秩张量结构，从而比传统 LoRA 的矩阵分解方法更参数高效，尤其适用于深度模型。实验结果表明，LoTR 能显著压缩参数，同时使下游微调更快速和廉价，提供了一种改进的 Transformer 架构微调策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted; missing author and sections were added;",
      "pdf_url": "http://arxiv.org/pdf/2402.01376v2",
      "published_date": "2024-02-02 13:00:38 UTC",
      "updated_date": "2024-02-05 12:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:33:08.891956"
    },
    {
      "arxiv_id": "2403.07887v4",
      "title": "Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Bhishma Dedhia",
        "Niraj K. Jha"
      ],
      "abstract": "Several accounts of human cognition posit that our intelligence is rooted in\nour ability to form abstract composable concepts, ground them in our\nenvironment, and reason over these grounded entities. This trifecta of human\nthought has remained elusive in modern intelligent machines. In this work, we\ninvestigate whether slot representations extracted from visual scenes serve as\nappropriate compositional abstractions for grounding and reasoning. We present\nthe Neural Slot Interpreter (NSI), which learns to ground object semantics in\nslots. At the core of NSI is a nested schema that uses simple syntax rules to\norganize the object semantics of a scene into object-centric schema primitives.\nThen, the NSI metric learns to ground primitives into slots through a\nstructured contrastive learning objective that reasons over the intermodal\nalignment. Experiments with a bi-modal object-property and scene retrieval task\ndemonstrate the grounding efficacy and interpretability of correspondences\nlearned by NSI. From a scene representation standpoint, we find that emergent\nNSI slots that move beyond the image grid by binding to spatial objects\nfacilitate improved visual grounding compared to conventional\nbounding-box-based approaches. From a data efficiency standpoint, we\nempirically validate that NSI learns more generalizable representations from a\nfixed amount of annotation data than the traditional approach. We also show\nthat the grounded slots surpass unsupervised slots in real-world object\ndiscovery and scale with scene complexity. Finally, we investigate the\ndownstream efficacy of the grounded slots. Vision Transformers trained on\ngrounding-aware NSI tokenizers using as few as ten tokens outperform\npatch-based tokens on challenging few-shot classification tasks.",
      "tldr_zh": "本论文探讨了在 emergent slot representations 中 grounding 对象语义，以模拟人类认知的抽象概念形成、环境接地和推理过程。研究提出 Neural Slot Interpreter (NSI)，它通过嵌套 schema 和简单语法规则组织场景对象语义为 object-centric schema primitives，并利用结构化的 contrastive learning 目标实现 intermodal alignment，将这些 primitives grounding 到 slots 中。实验结果显示，NSI 比传统的 bounding-box-based 方法在视觉 grounding 和双模态检索任务中表现出色，并从固定标注数据中学习更可泛化的表示。最终，基于 grounding-aware NSI tokenizers 训练的 Vision Transformers 在少样本分类任务中，使用少量 tokens 时超越了传统的 patch-based 方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07887v4",
      "published_date": "2024-02-02 12:37:23 UTC",
      "updated_date": "2025-05-09 00:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:33:23.603914"
    },
    {
      "arxiv_id": "2402.01355v2",
      "title": "FindingEmo: An Image Dataset for Emotion Recognition in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Laurent Mertens",
        "Elahe' Yargholi",
        "Hans Op de Beeck",
        "Jan Van den Stock",
        "Joost Vennekens"
      ],
      "abstract": "We introduce FindingEmo, a new image dataset containing annotations for 25k\nimages, specifically tailored to Emotion Recognition. Contrary to existing\ndatasets, it focuses on complex scenes depicting multiple people in various\nnaturalistic, social settings, with images being annotated as a whole, thereby\ngoing beyond the traditional focus on faces or single individuals. Annotated\ndimensions include Valence, Arousal and Emotion label, with annotations\ngathered using Prolific. Together with the annotations, we release the list of\nURLs pointing to the original images, as well as all associated source code.",
      "tldr_zh": "该研究引入了FindingEmo数据集，一个包含25k张图像的资源，专门用于野外情感识别。与现有数据集不同，它关注复杂社会场景中的多个人物，并对整个图像进行整体标注。标注维度包括Valence、Arousal和Emotion label，使用Prolific平台收集数据。数据集还附带图像URL列表和相关源代码，以支持进一步的研究和应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "33 pages, 21 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.01355v2",
      "published_date": "2024-02-02 12:22:41 UTC",
      "updated_date": "2024-06-05 13:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:33:33.416303"
    },
    {
      "arxiv_id": "2402.06647v1",
      "title": "A Survey on Large Language Model Hallucination via a Creativity Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Xuhui Jiang",
        "Yuxing Tian",
        "Fengrui Hua",
        "Chengjin Xu",
        "Yuanzhuo Wang",
        "Jian Guo"
      ],
      "abstract": "Hallucinations in large language models (LLMs) are always seen as\nlimitations. However, could they also be a source of creativity? This survey\nexplores this possibility, suggesting that hallucinations may contribute to LLM\napplication by fostering creativity. This survey begins with a review of the\ntaxonomy of hallucinations and their negative impact on LLM reliability in\ncritical applications. Then, through historical examples and recent relevant\ntheories, the survey explores the potential creative benefits of hallucinations\nin LLMs. To elucidate the value and evaluation criteria of this connection, we\ndelve into the definitions and assessment methods of creativity. Following the\nframework of divergent and convergent thinking phases, the survey\nsystematically reviews the literature on transforming and harnessing\nhallucinations for creativity in LLMs. Finally, the survey discusses future\nresearch directions, emphasizing the need to further explore and refine the\napplication of hallucinations in creative processes within LLMs.",
      "tldr_zh": "这篇调查论文从创意的角度审视大型语言模型（LLMs）中的幻觉（hallucinations），提出幻觉不仅仅是局限性，还可能作为促进创意的来源。论文首先回顾了幻觉的分类及其在关键应用中的负面影响，然后通过历史例子和相关理论探讨其潜在益处，并定义了创意的评估标准。接着，它系统回顾了文献，聚焦于如何通过发散性（divergent）和收敛性（convergent）思考阶段，将幻觉转化为LLMs的创意应用，最后讨论了未来研究方向，强调进一步探索幻觉在创意过程中的作用。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.06647v1",
      "published_date": "2024-02-02 12:21:04 UTC",
      "updated_date": "2024-02-02 12:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:33:45.628576"
    },
    {
      "arxiv_id": "2402.01352v1",
      "title": "Describing Images $\\textit{Fast and Slow}$: Quantifying and Predicting the Variation in Human Signals during Visuo-Linguistic Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Ece Takmaz",
        "Sandro Pezzelle",
        "Raquel Fernández"
      ],
      "abstract": "There is an intricate relation between the properties of an image and how\nhumans behave while describing the image. This behavior shows ample variation,\nas manifested in human signals such as eye movements and when humans start to\ndescribe the image. Despite the value of such signals of visuo-linguistic\nvariation, they are virtually disregarded in the training of current pretrained\nmodels, which motivates further investigation. Using a corpus of Dutch image\ndescriptions with concurrently collected eye-tracking data, we explore the\nnature of the variation in visuo-linguistic signals, and find that they\ncorrelate with each other. Given this result, we hypothesize that variation\nstems partly from the properties of the images, and explore whether image\nrepresentations encoded by pretrained vision encoders can capture such\nvariation. Our results indicate that pretrained models do so to a\nweak-to-moderate degree, suggesting that the models lack biases about what\nmakes a stimulus complex for humans and what leads to variations in human\noutputs.",
      "tldr_zh": "该研究探讨了图像属性与人类描述行为（如眼动和描述起始时间）之间的复杂关系，量化了这些visuo-linguistic processes中的信号变异。使用一个包含荷兰语图像描述和eye-tracking data的语料库，研究者发现这些信号相互相关，并假设变异部分源于图像属性。实验结果显示，pretrained vision encoders只能弱到中度地捕捉这种变异，表明这些模型缺乏对人类刺激复杂性和输出变异的内在偏置。总的来说，这为改进视觉语言模型提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01352v1",
      "published_date": "2024-02-02 12:11:16 UTC",
      "updated_date": "2024-02-02 12:11:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:33:58.162688"
    },
    {
      "arxiv_id": "2402.01349v3",
      "title": "LLMs May Perform MCQA by Selecting the Least Incorrect Option",
      "title_zh": "翻译失败",
      "authors": [
        "Haochun Wang",
        "Sendong Zhao",
        "Zewen Qiang",
        "Nuwa Xi",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "In the field of NLP, Large Language Models (LLMs) have markedly enhanced\nperformance across a variety of tasks. However, the comprehensive evaluation of\nLLMs remains an inevitable challenge for the community. Recently, the adoption\nof Multiple Choice Question Answering (MCQA) as a benchmark for assessing LLMs\nhas gained considerable traction. However, concerns regarding the robustness of\nthis evaluative method persist. Building upon previous discussions on the issue\nof \\textit{variability}, we reveal an additional dimension of concern: LLMs may\nperform MCQA by selecting the least incorrect option rather than distinctly\ncorrect. This observation suggests that LLMs might regard multiple options as\ncorrect, which could undermine the reliability of MCQA as a metric for\nevaluating LLMs. To address this challenge, we introduce an enhanced dataset\naugmentation method for MCQA, termed MCQA+, to provide a more accurate\nreflection of the model performance, thereby highlighting the necessity for\nmore sophisticated evaluation mechanisms in the assessment of LLM capabilities.",
      "tldr_zh": "该研究揭示了Large Language Models (LLMs)在Multiple Choice Question Answering (MCQA)任务中可能通过选择“最不错误的”选项来回答，而不是真正正确的选项，这表明LLMs可能将多个选项视为正确，从而质疑MCQA作为评估基准的可靠性。论文分析了这一问题如何影响LLMs的全面评估，并引入了MCQA+，一种增强的数据集扩充方法，以更准确地反映模型性能。最终，这强调了需要更复杂的评估机制来评估LLMs的能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.01349v3",
      "published_date": "2024-02-02 12:07:00 UTC",
      "updated_date": "2024-12-06 11:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:34:09.620757"
    },
    {
      "arxiv_id": "2402.01348v2",
      "title": "CORE: Mitigating Catastrophic Forgetting in Continual Learning through Cognitive Replay",
      "title_zh": "翻译失败",
      "authors": [
        "Jianshu Zhang",
        "Yankai Fu",
        "Ziheng Peng",
        "Dongyu Yao",
        "Kun He"
      ],
      "abstract": "This paper introduces a novel perspective to significantly mitigate\ncatastrophic forgetting in continuous learning (CL), which emphasizes models'\ncapacity to preserve existing knowledge and assimilate new information. Current\nreplay-based methods treat every task and data sample equally and thus can not\nfully exploit the potential of the replay buffer. In response, we propose\nCOgnitive REplay (CORE), which draws inspiration from human cognitive review\nprocesses. CORE includes two key strategies: Adaptive Quantity Allocation and\nQuality-Focused Data Selection. The former adaptively modulates the replay\nbuffer allocation for each task based on its forgetting rate, while the latter\nguarantees the inclusion of representative data that best encapsulates the\ncharacteristics of each task within the buffer. Our approach achieves an\naverage accuracy of 37.95% on split-CIFAR10, surpassing the best baseline\nmethod by 6.52%. Additionally, it significantly enhances the accuracy of the\npoorest-performing task by 6.30% compared to the top baseline. Code is\navailable at https://github.com/sterzhang/CORE.",
      "tldr_zh": "本论文提出了一种名为 CORE 的新方法，用于缓解持续学习（Continual Learning）中的灾难性遗忘（Catastrophic Forgetting），通过模拟人类认知复习过程来帮助模型保留既有知识并吸收新信息。CORE 包括两个关键策略：Adaptive Quantity Allocation，根据任务的遗忘率动态分配回放缓冲区，以及 Quality-Focused Data Selection，选择最能代表任务特征的高质量数据，以优化缓冲区利用。实验结果显示，在 split-CIFAR10 数据集上，CORE 的平均准确率达到 37.95%，比最佳基线方法高出 6.52%，并将表现最差任务的准确率提高了 6.30%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CogSci24 as oral presentation",
      "pdf_url": "http://arxiv.org/pdf/2402.01348v2",
      "published_date": "2024-02-02 12:04:44 UTC",
      "updated_date": "2024-04-09 08:33:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:34:22.290021"
    },
    {
      "arxiv_id": "2402.01345v6",
      "title": "Skip \\n: A Simple Method to Reduce Hallucination in Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zongbo Han",
        "Zechen Bai",
        "Haiyang Mei",
        "Qianli Xu",
        "Changqing Zhang",
        "Mike Zheng Shou"
      ],
      "abstract": "Recent advancements in large vision-language models (LVLMs) have demonstrated\nimpressive capability in visual information understanding with human language.\nDespite these advances, LVLMs still face challenges with multimodal\nhallucination, such as generating text descriptions of objects that are not\npresent in the visual information. However, the underlying fundamental reasons\nof multimodal hallucinations remain poorly explored. In this paper, we propose\na new perspective, suggesting that the inherent biases in LVLMs might be a key\nfactor in hallucinations. Specifically, we systematically identify a semantic\nshift bias related to paragraph breaks (\\n\\n), where the content before and\nafter '\\n\\n' in the training data frequently exhibit significant semantic\nchanges. This pattern leads the model to infer that the contents following\n'\\n\\n' should be obviously different from the preceding contents with less\nhallucinatory descriptions, thereby increasing the probability of hallucinatory\ndescriptions subsequent to the '\\n\\n'. We have validated this hypothesis on\nmultiple publicly available LVLMs. Besides, we find that deliberately inserting\n'\\n\\n' at the generated description can induce more hallucinations. A simple\nmethod is proposed to effectively mitigate the hallucination of LVLMs by\nskipping the output of '\\n'.",
      "tldr_zh": "该论文探讨了大型视觉语言模型(LVLMs)中多模态幻觉的原因，提出一种新视角：模型的内在偏差，尤其是与段落换行符(\\n\\n)相关的语义偏移偏差，导致\\n\\n后内容更易产生幻觉描述。研究者通过实验验证了这一假设，并在多个公开LVLMs上确认， deliberately inserting '\\n\\n' 会增加幻觉发生。最终，他们提出一个简单方法——跳过输出中的'\\n'，有效缓解了LVLMs的幻觉问题。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01345v6",
      "published_date": "2024-02-02 12:02:46 UTC",
      "updated_date": "2024-05-08 02:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:34:34.018781"
    },
    {
      "arxiv_id": "2402.03469v3",
      "title": "Rethinking the Role of Proxy Rewards in Language Model Alignment",
      "title_zh": "重新思考代理奖励在语言模型对齐中的作用",
      "authors": [
        "Sungdong Kim",
        "Minjoon Seo"
      ],
      "abstract": "Learning from human feedback via proxy reward modeling has been studied to\nalign Large Language Models (LLMs) with human values. However, achieving\nreliable training through that proxy reward model (RM) is not a trivial\nproblem, and its behavior remained as a black-box. In this paper, we study the\nrole of proxy rewards in the LLM alignment via `reverse reward engineering' by\ncomposing interpretable features as a white-box reward function. We aim to\nreplicate the ground truth (gold) reward signal by achieving a monotonic\nrelationship between the proxy and gold reward signals after training the model\nusing the proxy reward in reinforcement learning (RL). Our findings indicate\nthat successfully emulating the gold reward requires generating responses that\nare relevant with enough length to open-ended questions, while also ensuring\nresponse consistency in closed-ended questions. Furthermore, resulting models\noptimizing our devised white-box reward show competitive performances with\nstrong open-source RMs in alignment benchmarks. We highlight its potential\nusage as a simple but strong reward baseline for the LLM alignment, not\nrequiring explicit human feedback dataset and RM training. Our code is\navailable at https://github.com/naver-ai/rethinking-proxy-reward.",
      "tldr_zh": "这篇论文重新审视了代理奖励模型（proxy reward modeling）在大型语言模型（LLMs）对齐中的作用，通过逆向奖励工程（reverse reward engineering）方法构建一个可解释的白盒奖励函数，以模拟真实（gold）奖励信号。研究发现，成功模拟需要生成与开放式问题相关的足够长响应，以及对封闭式问题的一致响应，从而在强化学习（RL）中实现代理和真实奖励的单调关系。结果显示，使用这种白盒奖励优化的模型在对齐基准上与强开源奖励模型（RMs）性能相当，且无需依赖显式人类反馈数据集，提供了一个简单有效的备选方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to EMNLP 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2402.03469v3",
      "published_date": "2024-02-02 11:58:08 UTC",
      "updated_date": "2024-10-06 13:21:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:34:46.946206"
    },
    {
      "arxiv_id": "2402.01335v3",
      "title": "BehAVE: Behaviour Alignment of Video Game Encodings",
      "title_zh": "翻译失败",
      "authors": [
        "Nemanja Rašajski",
        "Chintan Trivedi",
        "Konstantinos Makantasis",
        "Antonios Liapis",
        "Georgios N. Yannakakis"
      ],
      "abstract": "Domain randomisation enhances the transferability of vision models across\nvisually distinct domains with similar content. However, current methods\nheavily depend on intricate simulation engines, hampering feasibility and\nscalability. This paper introduces BehAVE, a video understanding framework that\nutilises existing commercial video games for domain randomisation without\naccessing their simulation engines. BehAVE taps into the visual diversity of\nvideo games for randomisation and uses textual descriptions of player actions\nto align videos with similar content. We evaluate BehAVE across 25 first-person\nshooter (FPS) games using various video and text foundation models,\ndemonstrating its robustness in domain randomisation. BehAVE effectively aligns\nplayer behavioural patterns and achieves zero-shot transfer to multiple unseen\nFPS games when trained on just one game. In a more challenging scenario, BehAVE\nenhances the zero-shot transferability of foundation models to unseen FPS\ngames, even when trained on a game of a different genre, with improvements of\nup to 22%. BehAVE is available online at https://github.com/nrasajski/BehAVE.",
      "tldr_zh": "该论文提出 BehAVE 框架，一种无需访问模拟引擎的视频理解方法，利用现有商业视频游戏的视觉多样性进行 domain randomisation，并通过玩家动作的文本描述实现视频内容对齐，以提升视觉模型在类似领域间的可转移性。BehAVE 在 25 个第一人称射击 (FPS) 游戏上进行评估，展示了其鲁棒性，能够有效对齐玩家行为模式，并在仅在一个游戏上训练的情况下实现零-shot transfer 到多个未见 FPS 游戏。实验结果显示，即使在不同游戏类型上训练，该框架也能提升基础模型对未见 FPS 游戏的零-shot 转移性能，高达 22% 的改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01335v3",
      "published_date": "2024-02-02 11:40:27 UTC",
      "updated_date": "2024-11-01 16:51:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:34:59.104739"
    },
    {
      "arxiv_id": "2402.01327v3",
      "title": "Supervised Algorithmic Fairness in Distribution Shifts: A Survey",
      "title_zh": "分布偏移中的监督算法公平性：综述",
      "authors": [
        "Minglai Shao",
        "Dong Li",
        "Chen Zhao",
        "Xintao Wu",
        "Yujie Lin",
        "Qin Tian"
      ],
      "abstract": "Supervised fairness-aware machine learning under distribution shifts is an\nemerging field that addresses the challenge of maintaining equitable and\nunbiased predictions when faced with changes in data distributions from source\nto target domains. In real-world applications, machine learning models are\noften trained on a specific dataset but deployed in environments where the data\ndistribution may shift over time due to various factors. This shift can lead to\nunfair predictions, disproportionately affecting certain groups characterized\nby sensitive attributes, such as race and gender. In this survey, we provide a\nsummary of various types of distribution shifts and comprehensively investigate\nexisting methods based on these shifts, highlighting six commonly used\napproaches in the literature. Additionally, this survey lists publicly\navailable datasets and evaluation metrics for empirical studies. We further\nexplore the interconnection with related research fields, discuss the\nsignificant challenges, and identify potential directions for future studies.",
      "tldr_zh": "这篇调查论文探讨了在分布 shifts（分布偏移）下监督算法公平性的挑战，强调了数据分布从源域到目标域的变化可能导致不公平预测，对特定群体（如基于种族或性别的敏感属性）产生不利影响。论文总结了各种分布 shifts 类型，并系统调查了六种常用方法，包括基于这些偏移的公平感知技术，同时列出了公开数据集和评估指标。最终，它讨论了与相关研究领域的关联、关键挑战（如模型鲁棒性），并指出了未来研究的潜在方向，例如更先进的适应性策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01327v3",
      "published_date": "2024-02-02 11:26:18 UTC",
      "updated_date": "2024-05-05 01:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:35:10.719594"
    },
    {
      "arxiv_id": "2402.01306v4",
      "title": "KTO: Model Alignment as Prospect Theoretic Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Kawin Ethayarajh",
        "Winnie Xu",
        "Niklas Muennighoff",
        "Dan Jurafsky",
        "Douwe Kiela"
      ],
      "abstract": "Kahneman & Tversky's $\\textit{prospect theory}$ tells us that humans perceive\nrandom variables in a biased but well-defined manner (1992); for example,\nhumans are famously loss-averse. We show that objectives for aligning LLMs with\nhuman feedback implicitly incorporate many of these biases -- the success of\nthese objectives (e.g., DPO) over cross-entropy minimization can partly be\nascribed to them belonging to a family of loss functions that we call\n$\\textit{human-aware losses}$ (HALOs). However, the utility functions these\nmethods attribute to humans still differ from those in the prospect theory\nliterature. Using a Kahneman-Tversky model of human utility, we propose a HALO\nthat directly maximizes the utility of generations instead of maximizing the\nlog-likelihood of preferences, as current methods do. We call this approach\nKTO, and it matches or exceeds the performance of preference-based methods at\nscales from 1B to 30B, despite only learning from a binary signal of whether an\noutput is desirable. More broadly, our work suggests that there is no one HALO\nthat is universally superior; the best loss depends on the inductive biases\nmost appropriate for a given setting, an oft-overlooked consideration.",
      "tldr_zh": "这篇论文基于Kahneman和Tversky的前景理论（prospect theory），探讨了大型语言模型（LLMs）校准的优化问题，指出现有目标（如DPO）隐含了人类的认知偏见，并将其归类为“人类感知损失”（HALOs）。作者提出KTO方法，使用Kahneman-Tversky效用模型直接最大化生成输出的效用，而非最大化偏好日志似然，从而仅需二元信号（输出是否可取）即可实现模型对齐。实验结果显示，KTO在1B到30B参数规模下，性能匹配或超过基于偏好的方法。该工作强调，没有一个通用的HALO是最优的，最佳损失取决于特定场景的归纳偏差。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01306v4",
      "published_date": "2024-02-02 10:53:36 UTC",
      "updated_date": "2024-11-19 18:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:35:26.385911"
    },
    {
      "arxiv_id": "2402.01298v1",
      "title": "Learning Semantic Information from Raw Audio Signal Using Both Contextual and Phonetic Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeyeon Kim",
        "Injune Hwang",
        "Kyogu Lee"
      ],
      "abstract": "We propose a framework to learn semantics from raw audio signals using two\ntypes of representations, encoding contextual and phonetic information\nrespectively. Specifically, we introduce a speech-to-unit processing pipeline\nthat captures two types of representations with different time resolutions. For\nthe language model, we adopt a dual-channel architecture to incorporate both\ntypes of representation. We also present new training objectives, masked\ncontext reconstruction and masked context prediction, that push models to learn\nsemantics effectively. Experiments on the sSIMI metric of Zero Resource Speech\nBenchmark 2021 and Fluent Speech Command dataset show our framework learns\nsemantics better than models trained with only one type of representation.",
      "tldr_zh": "本论文提出一个框架，用于从原始音频信号中学习语义信息，通过结合contextual representations和phonetic representations两种表示。框架包括一个语音到单元的处理管道，以捕获不同时间分辨率的表示，并采用双通道架构的语言模型，同时引入新的训练目标masked context reconstruction和masked context prediction，以有效提升语义学习。实验结果显示，该框架在Zero Resource Speech Benchmark 2021的sSIMI指标和Fluent Speech Command数据集上，比仅使用一种表示的模型表现出更好的语义学习性能。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01298v1",
      "published_date": "2024-02-02 10:39:58 UTC",
      "updated_date": "2024-02-02 10:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:35:36.416090"
    },
    {
      "arxiv_id": "2402.01295v4",
      "title": "ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast",
      "title_zh": "ExtremeCast: 提升全球天气预报的极值预测",
      "authors": [
        "Wanghan Xu",
        "Kang Chen",
        "Tao Han",
        "Hao Chen",
        "Wanli Ouyang",
        "Lei Bai"
      ],
      "abstract": "Data-driven weather forecast based on machine learning (ML) has experienced\nrapid development and demonstrated superior performance in the global\nmedium-range forecast compared to traditional physics-based dynamical models.\nHowever, most of these ML models struggle with accurately predicting extreme\nweather, which is related to training loss and the uncertainty of weather\nsystems. Through mathematical analysis, we prove that the use of symmetric\nlosses, such as the Mean Squared Error (MSE), leads to biased predictions and\nunderestimation of extreme values. To address this issue, we introduce Exloss,\na novel loss function that performs asymmetric optimization and highlights\nextreme values to obtain accurate extreme weather forecast. Beyond the\nevolution in training loss, we introduce a training-free extreme value\nenhancement module named ExBooster, which captures the uncertainty in\nprediction outcomes by employing multiple random samples, thereby increasing\nthe hit rate of low-probability extreme events. Combined with an advanced\nglobal weather forecast model, extensive experiments show that our solution can\nachieve state-of-the-art performance in extreme weather prediction, while\nmaintaining the overall forecast accuracy comparable to the top medium-range\nforecast models.",
      "tldr_zh": "该研究针对机器学习（ML）驱动的全球天气预报模型在极端天气预测上的不足（如训练损失和不确定性），通过数学分析证明使用对称损失函数如 Mean Squared Error (MSE) 会导致预测偏差和极端值低估。作者提出了一种新损失函数 Exloss，进行不对称优化并强调极端值，以提升极端天气预测的准确性。同时，引入了无需训练的极端值增强模块 ExBooster，通过多个随机样本捕捉预测不确定性，提高低概率极端事件的命中率。实验结果显示，与先进的全球天气预报模型结合后，该方法在极端天气预测中达到最先进性能，同时保持整体预报准确性与顶级模型相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01295v4",
      "published_date": "2024-02-02 10:34:13 UTC",
      "updated_date": "2024-08-16 09:26:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:35:47.818160"
    },
    {
      "arxiv_id": "2402.01292v3",
      "title": "Towards the New XAI: A Hypothesis-Driven Approach to Decision Support Using Evidence",
      "title_zh": "翻译失败",
      "authors": [
        "Thao Le",
        "Tim Miller",
        "Liz Sonenberg",
        "Ronal Singh"
      ],
      "abstract": "Prior research on AI-assisted human decision-making has explored several\ndifferent explainable AI (XAI) approaches. A recent paper has proposed a\nparadigm shift calling for hypothesis-driven XAI through a conceptual framework\ncalled evaluative AI that gives people evidence that supports or refutes\nhypotheses without necessarily giving a decision-aid recommendation. In this\npaper, we describe and evaluate an approach for hypothesis-driven XAI based on\nthe Weight of Evidence (WoE) framework, which generates both positive and\nnegative evidence for a given hypothesis. Through human behavioural\nexperiments, we show that our hypothesis-driven approach increases decision\naccuracy and reduces reliance compared to a recommendation-driven approach and\nan AI-explanation-only baseline, but with a small increase in under-reliance\ncompared to the recommendation-driven approach. Further, we show that\nparticipants used our hypothesis-driven approach in a materially different way\nto the two baselines.",
      "tldr_zh": "该论文提出了一种新的假设驱动 XAI（Explainable AI）方法，基于 Weight of Evidence (WoE) 框架，通过提供支持或反驳假设的正负证据，帮助人类决策，而非直接给出推荐。实验结果显示，与推荐驱动方法和 AI 解释基线相比，这种方法提高了决策准确性，减少了对 AI 的依赖，但略微增加了轻信问题。进一步分析表明，参与者对该方法的运用方式与基线方法存在显著差异，为 evaluative AI 范式转变提供了实证支持。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "ECAI 2024 Main Track. The full paper version, including the\n  supplementary material",
      "pdf_url": "http://arxiv.org/pdf/2402.01292v3",
      "published_date": "2024-02-02 10:28:24 UTC",
      "updated_date": "2024-08-26 04:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:36:01.555730"
    },
    {
      "arxiv_id": "2402.07919v1",
      "title": "How Can Generative AI Enhance the Well-being of Blind?",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Bendel"
      ],
      "abstract": "This paper examines the question of how generative AI can improve the\nwell-being of blind or visually impaired people. It refers to a current\nexample, the Be My Eyes app, in which the Be My AI feature was integrated in\n2023, which is based on GPT-4 from OpenAI. The author's tests are described and\nevaluated. There is also an ethical and social discussion. The power of the\ntool, which can analyze still images in an amazing way, is demonstrated. Those\naffected gain a new independence and a new perception of their environment. At\nthe same time, they are dependent on the world view and morality of the\nprovider or developer, who prescribe or deny them certain descriptions. An\noutlook makes it clear that the analysis of moving images will mean a further\nleap forward. It is fair to say that generative AI can fundamentally improve\nthe well-being of blind and visually impaired people and will change it in\nvarious ways.",
      "tldr_zh": "这篇论文探讨了生成式 AI 如何提升盲人或视力受损者的福祉，以 Be My Eyes 应用及其基于 GPT-4 的 Be My AI 功能为例。作者通过测试和评估，展示了该工具在分析静态图像方面的强大能力，帮助用户获得新的独立性和环境感知，同时强调了用户对开发者的世界观和道德标准的依赖。论文还进行了道德和社会讨论，并展望动态图像分析将带来进一步的进步，总体认为生成式 AI 可从根本上改善盲人的福祉并带来多方面改变。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2; K.3"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.07919v1",
      "published_date": "2024-02-02 10:26:39 UTC",
      "updated_date": "2024-02-02 10:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:36:12.337282"
    },
    {
      "arxiv_id": "2402.04275v1",
      "title": "Motion Mapping Cognition: A Nondecomposable Primary Process in Human Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenping Xie"
      ],
      "abstract": "Human intelligence seems so mysterious that we have not successfully\nunderstood its foundation until now. Here, I want to present a basic cognitive\nprocess, motion mapping cognition (MMC), which should be a nondecomposable\nprimary function in human vision. Wherein, I point out that, MMC process can be\nused to explain most of human visual functions in fundamental, but can not be\neffectively modelled by traditional visual processing ways including image\nsegmentation, object recognition, object tracking etc. Furthermore, I state\nthat MMC may be looked as an extension of Chen's theory of topological\nperception on human vision, and seems to be unsolvable using existing\nintelligent algorithm skills. Finally, along with the requirements of MMC\nproblem, an interesting computational model, quantized topological matching\nprinciple can be derived by developing the idea of optimal transport theory.\nAbove results may give us huge inspiration to develop more robust and\ninterpretable machine vision models.",
      "tldr_zh": "本文提出 motion mapping cognition (MMC) 作为人类视觉中不可分解的初级认知过程，用于根本上解释大多数视觉功能，但传统方法如图像分割、物体识别和物体跟踪无法有效建模它。作者指出，MMC 可以视为对 Chen's theory of topological perception 的扩展，且当前智能算法难以解决这一问题。基于 MMC 的要求，作者推导出了一个计算模型：quantized topological matching principle，通过发展 optimal transport theory 的想法。总体而言，这些结果为开发更鲁棒和可解释的机器视觉模型提供了重要启发。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.04275v1",
      "published_date": "2024-02-02 10:11:25 UTC",
      "updated_date": "2024-02-02 10:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:36:23.789204"
    },
    {
      "arxiv_id": "2402.01806v1",
      "title": "HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on Text",
      "title_zh": "翻译失败",
      "authors": [
        "Han Liu",
        "Zhi Xu",
        "Xiaotong Zhang",
        "Feng Zhang",
        "Fenglong Ma",
        "Hongyang Chen",
        "Hong Yu",
        "Xianchao Zhang"
      ],
      "abstract": "Black-box hard-label adversarial attack on text is a practical and\nchallenging task, as the text data space is inherently discrete and\nnon-differentiable, and only the predicted label is accessible. Research on\nthis problem is still in the embryonic stage and only a few methods are\navailable. Nevertheless, existing methods rely on the complex heuristic\nalgorithm or unreliable gradient estimation strategy, which probably fall into\nthe local optimum and inevitably consume numerous queries, thus are difficult\nto craft satisfactory adversarial examples with high semantic similarity and\nlow perturbation rate in a limited query budget. To alleviate above issues, we\npropose a simple yet effective framework to generate high quality textual\nadversarial examples under the black-box hard-label attack scenarios, named\nHQA-Attack. Specifically, after initializing an adversarial example randomly,\nHQA-attack first constantly substitutes original words back as many as\npossible, thus shrinking the perturbation rate. Then it leverages the synonym\nset of the remaining changed words to further optimize the adversarial example\nwith the direction which can improve the semantic similarity and satisfy the\nadversarial condition simultaneously. In addition, during the optimizing\nprocedure, it searches a transition synonym word for each changed word, thus\navoiding traversing the whole synonym set and reducing the query number to some\nextent. Extensive experimental results on five text classification datasets,\nthree natural language inference datasets and two real-world APIs have shown\nthat the proposed HQA-Attack method outperforms other strong baselines\nsignificantly.",
      "tldr_zh": "这篇论文针对文本的黑盒硬-label adversarial attack 的挑战，提出了一种简单有效的框架 HQA-Attack，以生成高质量对抗样本。HQA-Attack 通过随机初始化样本、优先恢复原始单词以降低扰动率，并利用同义词集优化语义相似度，同时搜索过渡同义词来减少查询次数。实验结果表明，该方法在五个文本分类数据集、三个自然语言推理数据集和两个真实世界 API 上显著优于现有基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01806v1",
      "published_date": "2024-02-02 10:06:43 UTC",
      "updated_date": "2024-02-02 10:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:36:36.539913"
    },
    {
      "arxiv_id": "2402.01276v4",
      "title": "Federated Unlearning: a Perspective of Stability and Fairness",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Shao",
        "Tao Lin",
        "Xuanyu Cao",
        "Bing Luo"
      ],
      "abstract": "This paper explores the multifaceted consequences of federated unlearning\n(FU) with data heterogeneity. We introduce key metrics for FU assessment,\nconcentrating on verification, global stability, and local fairness, and\ninvestigate the inherent trade-offs. Furthermore, we formulate the unlearning\nprocess with data heterogeneity through an optimization framework. Our key\ncontribution lies in a comprehensive theoretical analysis of the trade-offs in\nFU and provides insights into data heterogeneity's impacts on FU. Leveraging\nthese insights, we propose FU mechanisms to manage the trade-offs, guiding\nfurther development for FU mechanisms. We empirically validate that our FU\nmechanisms effectively balance trade-offs, confirming insights derived from our\ntheoretical analysis.",
      "tldr_zh": "这篇论文从稳定性(stability)和公平性(fairness)的角度探讨了Federated Unlearning (FU)在数据异质性下的多方面影响，引入了验证、全球稳定性(global stability)和本地公平性(local fairness)的关键指标，并分析了这些指标之间的固有权衡。作者通过优化框架对数据异质性下的无学习过程进行理论分析，揭示了FU的权衡关系及其对数据异质性的影响，并据此提出机制来管理这些权衡。实验结果验证了这些机制在平衡权衡方面的有效性，确认了理论分析的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01276v4",
      "published_date": "2024-02-02 10:05:25 UTC",
      "updated_date": "2024-06-01 15:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:36:48.732874"
    },
    {
      "arxiv_id": "2402.09450v3",
      "title": "Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram",
      "title_zh": "翻译失败",
      "authors": [
        "Yeongyeon Na",
        "Minje Park",
        "Yunwon Tae",
        "Sunghoon Joo"
      ],
      "abstract": "Electrocardiograms (ECG) are widely employed as a diagnostic tool for\nmonitoring electrical signals originating from a heart. Recent machine learning\nresearch efforts have focused on the application of screening various diseases\nusing ECG signals. However, adapting to the application of screening disease is\nchallenging in that labeled ECG data are limited. Achieving general\nrepresentation through self-supervised learning (SSL) is a well-known approach\nto overcome the scarcity of labeled data; however, a naive application of SSL\nto ECG data, without considering the spatial-temporal relationships inherent in\nECG signals, may yield suboptimal results. In this paper, we introduce ST-MEM\n(Spatio-Temporal Masked Electrocardiogram Modeling), designed to learn\nspatio-temporal features by reconstructing masked 12-lead ECG data. ST-MEM\noutperforms other SSL baseline methods in various experimental settings for\narrhythmia classification tasks. Moreover, we demonstrate that ST-MEM is\nadaptable to various lead combinations. Through quantitative and qualitative\nanalysis, we show a spatio-temporal relationship within ECG data. Our code is\navailable at https://github.com/bakqui/ST-MEM.",
      "tldr_zh": "这篇论文针对心电图(ECG)数据标注不足的问题，提出了一种自监督学习(SSL)方法 ST-MEM（Spatio-Temporal Masked Electrocardiogram Modeling），旨在通过重建masked的12-lead ECG数据来捕获其固有的时空关系。ST-MEM在心律失常(arrhythmia)分类任务中表现优于其他SSL基线方法，并在各种导联组合中显示出良好的适应性。通过定量和定性分析，该方法成功展示了ECG数据中的时空关系，为ECG疾病筛查提供了更有效的表示学习框架。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "ICLR 2024. The first three authors contribute equally",
      "pdf_url": "http://arxiv.org/pdf/2402.09450v3",
      "published_date": "2024-02-02 10:04:13 UTC",
      "updated_date": "2024-03-19 16:17:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:37:00.249776"
    },
    {
      "arxiv_id": "2402.01805v4",
      "title": "Can LLMs perform structured graph reasoning?",
      "title_zh": "翻译失败",
      "authors": [
        "Palaash Agrawal",
        "Shavak Vasania",
        "Cheston Tan"
      ],
      "abstract": "Pretrained Large Language Models (LLMs) have demonstrated various reasoning\ncapabilities through language-based prompts alone, particularly in unstructured\ntask settings (tasks purely based on language semantics). However, LLMs often\nstruggle with structured tasks, because of the inherent incompatibility of\ninput representation. Reducing structured tasks to uni-dimensional language\nsemantics often renders the problem trivial. Keeping the trade-off between LLM\ncompatibility and structure complexity in mind, we design various graph\nreasoning tasks as a proxy to semi-structured tasks in this paper, in order to\ntest the ability to navigate through representations beyond plain text in\nvarious LLMs. Particularly, we design 10 distinct problems of graph traversal,\neach representing increasing levels of complexity, and benchmark 5 different\ninstruct-finetuned LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2 and Palm-2) on the\naforementioned tasks. Further, we analyse the performance of models across\nvarious settings such as varying sizes of graphs as well as different forms of\nk-shot prompting. We highlight various limitations, biases and properties of\nLLMs through this benchmarking process, such as an inverse relation to the\naverage degrees of freedom of traversal per node in graphs, the overall\nnegative impact of k-shot prompting on graph reasoning tasks, and a positive\nresponse bias which prevents LLMs from identifying the absence of a valid\nsolution. Finally, we introduce a new prompting technique specially designed\nfor graph traversal tasks (PathCompare), which demonstrates a notable increase\nin the performance of LLMs in comparison to standard prompting techniques such\nas Chain-of-Thought (CoT).",
      "tldr_zh": "这篇论文探讨了大语言模型（LLMs）在结构化图推理任务中的性能，设计了10个不同复杂度的图遍历问题作为代理任务，以测试LLMs处理非纯文本表示的能力。研究基准测试了GPT-4、GPT-3.5、Claude-2、Llama-2和Palm-2等5个指令微调模型，分析了它们在不同图大小和k-shot prompting设置下的表现，发现LLMs存在与节点自由度反比的局限性、k-shot prompting的负面影响，以及积极响应偏差。最终，论文引入了新的提示技术PathCompare，与Chain-of-Thought (CoT)相比，它显著提升了LLMs在图遍历任务中的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "International Conference on Pattern Recognition (ICPR), 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01805v4",
      "published_date": "2024-02-02 09:45:33 UTC",
      "updated_date": "2024-08-29 14:05:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:37:13.122872"
    },
    {
      "arxiv_id": "2402.01267v1",
      "title": "The Human and the Mechanical: logos, truthfulness, and ChatGPT",
      "title_zh": "人类",
      "authors": [
        "Anastasia Giannakidou",
        "Alda Mari"
      ],
      "abstract": "The paper addresses the question of whether it is appropriate to talk about\n`mechanical minds' at all, and whether ChatGPT models can indeed be thought of\nas realizations of that. Our paper adds a semantic argument to the current\ndebate. The act of human assertion requires the formation of a veridicality\njudgment. Modification of assertions with modals (John must be at home) and the\nuse of subjective elements (John is obviously at home) indicate that the\nspeaker is manipulating her judgments and, in a cooperative context, intends\nher epistemic state to be transparent to the addressee. Veridicality judgments\nare formed on the basis of two components: (i) evidence that relates to reality\n(exogenous evidence) and (ii) endogenous evidence, such as preferences and\nprivate beliefs. `Mechanical minds' lack these two components: (i) they do not\nrelate to reality and (ii) do not have endogenous evidence. Therefore they lack\nthe ability to form a belief about the world and a veridicality judgments\naltogether. They can only mimic that judgment, but the output is not ground in\nthe very foundations for it.",
      "tldr_zh": "这篇论文探讨了是否适合谈论“mechanical minds”以及ChatGPT是否可视为其实现，并从语义角度添加新论点。作者分析了人类断言的真实性判断（veridicality judgment），强调它依赖于外生证据（exogenous evidence，如与现实相关的证据）和内生证据（endogenous evidence，如偏好和私人信念）。结论是，“mechanical minds”缺乏这些组件，无法真正形成世界信念，只能模仿真实性判断。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under submission",
      "pdf_url": "http://arxiv.org/pdf/2402.01267v1",
      "published_date": "2024-02-02 09:41:51 UTC",
      "updated_date": "2024-02-02 09:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:37:25.731683"
    },
    {
      "arxiv_id": "2402.01261v3",
      "title": "TEDDY: Trimming Edges with Degree-based Discrimination strategY",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunjin Seo",
        "Jihun Yun",
        "Eunho Yang"
      ],
      "abstract": "Since the pioneering work on the lottery ticket hypothesis for graph neural\nnetworks (GNNs) was proposed in Chen et al. (2021), the study on finding graph\nlottery tickets (GLT) has become one of the pivotal focus in the GNN community,\ninspiring researchers to discover sparser GLT while achieving comparable\nperformance to original dense networks. In parallel, the graph structure has\ngained substantial attention as a crucial factor in GNN training dynamics, also\nelucidated by several recent studies. Despite this, contemporary studies on\nGLT, in general, have not fully exploited inherent pathways in the graph\nstructure and identified tickets in an iterative manner, which is\ntime-consuming and inefficient. To address these limitations, we introduce\nTEDDY, a one-shot edge sparsification framework that leverages structural\ninformation by incorporating edge-degree information. Following edge\nsparsification, we encourage the parameter sparsity during training via simple\nprojected gradient descent on the $\\ell_0$ ball. Given the target sparsity\nlevels for both the graph structure and the model parameters, our TEDDY\nfacilitates efficient and rapid realization of GLT within a single training.\nRemarkably, our experimental results demonstrate that TEDDY significantly\nsurpasses conventional iterative approaches in generalization, even when\nconducting one-shot sparsification that solely utilizes graph structures,\nwithout taking feature information into account.",
      "tldr_zh": "本研究针对图神经网络(GNNs)的彩票票假设(lottery ticket hypothesis)，提出TEDDY框架，这是一种one-shot边稀疏化方法，利用边度信息(edge-degree information)来高效发现图彩票票(GLT)。TEDDY首先基于结构信息进行边稀疏化，然后通过投影梯度下降(projected gradient descent)在ℓ0球上鼓励参数稀疏，从而在单次训练中实现高效的稀疏模型。实验结果显示，TEDDY在泛化性能上显著优于传统迭代方法，即使仅使用图结构信息而不考虑特征信息。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01261v3",
      "published_date": "2024-02-02 09:32:03 UTC",
      "updated_date": "2024-03-15 14:12:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:37:38.557756"
    },
    {
      "arxiv_id": "2402.01259v1",
      "title": "Position Aware 60 GHz mmWave Beamforming for V2V Communications Utilizing Deep Learning",
      "title_zh": "位置感知的 60 GHz mmWave 波束形成技术，用于 V2V 通信并利用深度学习",
      "authors": [
        "Muhammad Baqer Mollah",
        "Honggang Wang",
        "Hua Fang"
      ],
      "abstract": "Beamforming techniques are considered as essential parts to compensate the\nsevere path loss in millimeter-wave (mmWave) communications by adopting large\nantenna arrays and formulating narrow beams to obtain satisfactory received\npowers. However, performing accurate beam alignment over such narrow beams for\nefficient link configuration by traditional beam selection approaches, mainly\nrelied on channel state information, typically impose significant latency and\ncomputing overheads, which is often infeasible in vehicle-to-vehicle (V2V)\ncommunications like highly dynamic scenarios. In contrast, utilizing\nout-of-band contextual information, such as vehicular position information, is\na potential alternative to reduce such overheads. In this context, this paper\npresents a deep learning-based solution on utilizing the vehicular position\ninformation for predicting the optimal beams having sufficient mmWave received\npowers so that the best V2V line-of-sight links can be ensured proactively.\nAfter experimental evaluation of the proposed solution on real-world measured\nmmWave sensing and communications datasets, the results show that the solution\ncan achieve up to 84.58% of received power of link status on average, which\nconfirm a promising solution for beamforming in mmWave at 60 GHz enabled V2V\ncommunications.",
      "tldr_zh": "本研究针对毫米波（mmWave）通信中严重的路径损失问题，提出了一种基于深度学习的波束形成解决方案，利用车辆位置信息来预测最佳波束，确保车辆间（V2V）通信中的高效视线链路。方法通过整合外部上下文信息（如车辆位置）来避免传统beamforming依赖信道状态信息带来的高延迟和计算开销，并在60 GHz频段进行优化。实验结果显示，该方案在真实数据集上平均实现了84.58%的接收功率，证明了其在动态V2V通信场景中的潜在应用价值。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.SI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "2024 IEEE International Conference on Communications (ICC), Denver,\n  CO, USA",
      "pdf_url": "http://arxiv.org/pdf/2402.01259v1",
      "published_date": "2024-02-02 09:30:27 UTC",
      "updated_date": "2024-02-02 09:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:37:49.566287"
    },
    {
      "arxiv_id": "2402.01241v1",
      "title": "Can Shape-Infused Joint Embeddings Improve Image-Conditioned 3D Diffusion?",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian Sbrolli",
        "Paolo Cudrano",
        "Matteo Matteucci"
      ],
      "abstract": "Recent advancements in deep generative models, particularly with the\napplication of CLIP (Contrastive Language Image Pretraining) to Denoising\nDiffusion Probabilistic Models (DDPMs), have demonstrated remarkable\neffectiveness in text to image generation. The well structured embedding space\nof CLIP has also been extended to image to shape generation with DDPMs,\nyielding notable results. Despite these successes, some fundamental questions\narise: Does CLIP ensure the best results in shape generation from images? Can\nwe leverage conditioning to bring explicit 3D knowledge into the generative\nprocess and obtain better quality? This study introduces CISP (Contrastive\nImage Shape Pre training), designed to enhance 3D shape synthesis guided by 2D\nimages. CISP aims to enrich the CLIP framework by aligning 2D images with 3D\nshapes in a shared embedding space, specifically capturing 3D characteristics\npotentially overlooked by CLIP's text image focus. Our comprehensive analysis\nassesses CISP's guidance performance against CLIP guided models, focusing on\ngeneration quality, diversity, and coherence of the produced shapes with the\nconditioning image. We find that, while matching CLIP in generation quality and\ndiversity, CISP substantially improves coherence with input images,\nunderscoring the value of incorporating 3D knowledge into generative models.\nThese findings suggest a promising direction for advancing the synthesis of 3D\nvisual content by integrating multimodal systems with 3D representations.",
      "tldr_zh": "本研究探讨了是否通过注入形状信息到联合嵌入中，能提升基于图像的 3D 扩散模型（Image-Conditioned 3D Diffusion）的性能。论文引入 CISP（Contrastive Image Shape Pretraining）方法，该框架扩展 CLIP（Contrastive Language Image Pretraining），通过在共享嵌入空间中对齐 2D 图像和 3D 形状，捕捉 CLIP 可能忽略的 3D 特性。实验结果显示，CISP 在生成质量和多样性上与 CLIP 相当，但显著提高了形状与输入图像的 coherence（一致性）。这些发现为整合多模态系统和 3D 表示推进 3D 视觉内容合成提供了有前景的方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01241v1",
      "published_date": "2024-02-02 09:09:23 UTC",
      "updated_date": "2024-02-02 09:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:38:05.009157"
    },
    {
      "arxiv_id": "2402.01240v3",
      "title": "Beyond the Request: Harnessing HTTP Response Headers for Cross-Browser Web Tracker Classification in an Imbalanced Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Wolf Rieder",
        "Philip Raschke",
        "Thomas Cory"
      ],
      "abstract": "The World Wide Web's connectivity is greatly attributed to the HTTP protocol,\nwith HTTP messages offering informative header fields that appeal to\ndisciplines like web security and privacy, especially concerning web tracking.\nDespite existing research employing HTTP request messages to identify web\ntrackers, HTTP response headers are often overlooked. This study endeavors to\ndesign effective machine learning classifiers for web tracker detection using\nbinarized HTTP response headers. Data from the Chrome, Firefox, and Brave\nbrowsers, obtained through the traffic monitoring browser extension T.EX,\nserves as our dataset. Ten supervised models were trained on Chrome data and\ntested across all browsers, including a Chrome dataset from a year later. The\nresults demonstrated high accuracy, F1-score, precision, recall, and minimal\nlog-loss error for Chrome and Firefox, but subpar performance on Brave,\npotentially due to its distinct data distribution and feature set. The research\nsuggests that these classifiers are viable for web tracker detection. However,\nreal-world application testing remains pending, and the distinction between\ntracker types and broader label sources could be explored in future studies.",
      "tldr_zh": "该研究旨在利用 HTTP response headers 设计机器学习分类器，以在不平衡数据集下检测跨浏览器网络跟踪器。研究者使用 T.EX 浏览器扩展从 Chrome、Firefox 和 Brave 浏览器收集数据，训练了 10 个监督模型，并在 Chrome 数据上训练后跨浏览器测试。结果显示，模型在 Chrome 和 Firefox 上表现出高准确率、F1-score、precision、recall 和低 log-loss error，但在 Brave 上性能较差，可能因数据分布差异所致。该方法证明了 HTTP response headers 在 web tracker detection 中的潜力，但需进一步进行真实世界应用测试和探索跟踪器类型分类。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01240v3",
      "published_date": "2024-02-02 09:07:09 UTC",
      "updated_date": "2024-09-23 11:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:38:13.547593"
    },
    {
      "arxiv_id": "2402.01239v1",
      "title": "PRIME: Protect Your Videos From Malicious Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Guanlin Li",
        "Shuai Yang",
        "Jie Zhang",
        "Tianwei Zhang"
      ],
      "abstract": "With the development of generative models, the quality of generated content\nkeeps increasing. Recently, open-source models have made it surprisingly easy\nto manipulate and edit photos and videos, with just a few simple prompts. While\nthese cutting-edge technologies have gained popularity, they have also given\nrise to concerns regarding the privacy and portrait rights of individuals.\nMalicious users can exploit these tools for deceptive or illegal purposes.\nAlthough some previous works focus on protecting photos against generative\nmodels, we find there are still gaps between protecting videos and images in\nthe aspects of efficiency and effectiveness. Therefore, we introduce our\nprotection method, PRIME, to significantly reduce the time cost and improve the\nprotection performance. Moreover, to evaluate our proposed protection method,\nwe consider both objective metrics and human subjective metrics. Our evaluation\nresults indicate that PRIME only costs 8.3% GPU hours of the cost of the\nprevious state-of-the-art method and achieves better protection results on both\nhuman evaluation and objective metrics. Code can be found in\nhttps://github.com/GuanlinLee/prime.",
      "tldr_zh": "本文研究了生成模型(generative models)的发展导致的视频编辑易用性问题，强调了恶意用户可能侵犯隐私和肖像权的风险。作者提出PRIME方法，通过优化保护机制显著降低时间成本（仅需之前最先进方法8.3%的GPU hours），并在效率和效果上超越现有图像保护技术。实验评估显示，PRIME在人类主观评估和客观指标上均取得更好结果，为视频隐私保护提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01239v1",
      "published_date": "2024-02-02 09:07:00 UTC",
      "updated_date": "2024-02-02 09:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:38:25.279821"
    },
    {
      "arxiv_id": "2402.01238v1",
      "title": "Flexible Variational Information Bottleneck: Achieving Diverse Compression with a Single Training",
      "title_zh": "灵活变分信息瓶颈：通过单次训练实现多样压缩",
      "authors": [
        "Sota Kudo",
        "Naoaki Ono",
        "Shigehiko Kanaya",
        "Ming Huang"
      ],
      "abstract": "Information Bottleneck (IB) is a widely used framework that enables the\nextraction of information related to a target random variable from a source\nrandom variable. In the objective function, IB controls the trade-off between\ndata compression and predictiveness through the Lagrange multiplier $\\beta$.\nTraditionally, to find the trade-off to be learned, IB requires a search for\n$\\beta$ through multiple training cycles, which is computationally expensive.\nIn this study, we introduce Flexible Variational Information Bottleneck (FVIB),\nan innovative framework for classification task that can obtain optimal models\nfor all values of $\\beta$ with single, computationally efficient training. We\ntheoretically demonstrate that across all values of reasonable $\\beta$, FVIB\ncan simultaneously maximize an approximation of the objective function for\nVariational Information Bottleneck (VIB), the conventional IB method. Then we\nempirically show that FVIB can learn the VIB objective as effectively as VIB.\nFurthermore, in terms of calibration performance, FVIB outperforms other IB and\ncalibration methods by enabling continuous optimization of $\\beta$. Our codes\nare available at https://github.com/sotakudo/fvib.",
      "tldr_zh": "Information Bottleneck (IB) 是一种框架，用于从源随机变量中提取与目标变量相关的信息，通过 Lagrange multiplier β 平衡数据压缩和预测性，但传统方法需多次训练来搜索 β，这耗费计算资源。本研究提出 Flexible Variational Information Bottleneck (FVIB)，一个创新框架，能通过单次高效训练同时获得所有 β 值的模型，并理论证明 FVIB 可最大化 Variational Information Bottleneck (VIB) 的目标函数。实验结果显示，FVIB 的学习效果与 VIB 相当，并在校准性能上优于其他 IB 和校准方法，代码已在 GitHub 开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01238v1",
      "published_date": "2024-02-02 09:03:38 UTC",
      "updated_date": "2024-02-02 09:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:38:38.258957"
    },
    {
      "arxiv_id": "2402.01227v1",
      "title": "STAA-Net: A Sparse and Transferable Adversarial Attack for Speech Emotion Recognition",
      "title_zh": "STAA-Net：针对语音情感识别的稀疏且可转移对抗攻击",
      "authors": [
        "Yi Chang",
        "Zhao Ren",
        "Zixing Zhang",
        "Xin Jing",
        "Kun Qian",
        "Xi Shao",
        "Bin Hu",
        "Tanja Schultz",
        "Björn W. Schuller"
      ],
      "abstract": "Speech contains rich information on the emotions of humans, and Speech\nEmotion Recognition (SER) has been an important topic in the area of\nhuman-computer interaction. The robustness of SER models is crucial,\nparticularly in privacy-sensitive and reliability-demanding domains like\nprivate healthcare. Recently, the vulnerability of deep neural networks in the\naudio domain to adversarial attacks has become a popular area of research.\nHowever, prior works on adversarial attacks in the audio domain primarily rely\non iterative gradient-based techniques, which are time-consuming and prone to\noverfitting the specific threat model. Furthermore, the exploration of sparse\nperturbations, which have the potential for better stealthiness, remains\nlimited in the audio domain. To address these challenges, we propose a\ngenerator-based attack method to generate sparse and transferable adversarial\nexamples to deceive SER models in an end-to-end and efficient manner. We\nevaluate our method on two widely-used SER datasets, Database of Elicited Mood\nin Speech (DEMoS) and Interactive Emotional dyadic MOtion CAPture (IEMOCAP),\nand demonstrate its ability to generate successful sparse adversarial examples\nin an efficient manner. Moreover, our generated adversarial examples exhibit\nmodel-agnostic transferability, enabling effective adversarial attacks on\nadvanced victim models.",
      "tldr_zh": "这篇论文提出了STAA-Net，一种基于生成器的稀疏且可转移的对抗攻击方法，针对语音情感识别(SER)模型的漏洞进行高效攻击，以解决传统迭代梯度方法的耗时和过拟合问题。STAA-Net通过端到端的生成机制创建隐蔽的对抗样本，这些样本在DEMoS和IEMOCAP数据集上表现出色，能够有效欺骗SER模型。实验结果显示，该方法生成的对抗样本具有模型无关的转移性，可成功攻击高级受害者模型，从而提升了SER系统的鲁棒性评估。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.HC",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01227v1",
      "published_date": "2024-02-02 08:46:57 UTC",
      "updated_date": "2024-02-02 08:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:38:50.181822"
    },
    {
      "arxiv_id": "2402.01219v1",
      "title": "AI Code Generators for Security: Friend or Foe?",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Natella",
        "Pietro Liguori",
        "Cristina Improta",
        "Bojan Cukic",
        "Domenico Cotroneo"
      ],
      "abstract": "Recent advances of artificial intelligence (AI) code generators are opening\nnew opportunities in software security research, including misuse by malicious\nactors. We review use cases for AI code generators for security and introduce\nan evaluation benchmark.",
      "tldr_zh": "该论文探讨了AI code generators在软件安全研究中的双重角色：一方面它们开启了新机会，如提升安全应用；另一方面可能被恶意actors滥用。作者审视了AI code generators的安全用例，包括潜在的误用场景。最终，论文引入了一个evaluation benchmark，以评估这些工具的利弊。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Dataset available at: https://github.com/dessertlab/violent-python",
      "pdf_url": "http://arxiv.org/pdf/2402.01219v1",
      "published_date": "2024-02-02 08:41:15 UTC",
      "updated_date": "2024-02-02 08:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:39:00.389751"
    },
    {
      "arxiv_id": "2402.01804v4",
      "title": "Analysis of Internet of Things Implementation Barriers in the Cold Supply Chain: An Integrated ISM-MICMAC and DEMATEL Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Kazrin Ahmad",
        "Md. Saiful Islam",
        "Md Abrar Jahin",
        "M. F. Mridha"
      ],
      "abstract": "Integrating Internet of Things (IoT) technology inside the cold supply chain\ncan enhance transparency, efficiency, and quality, optimizing operating\nprocedures and increasing productivity. The integration of IoT in this\ncomplicated setting is hindered by specific barriers that need a thorough\nexamination. Prominent barriers to IoT implementation in the cold supply chain\nare identified using a two-stage model. After reviewing the available\nliterature on the topic of IoT implementation, a total of 13 barriers were\nfound. The survey data was cross-validated for quality, and Cronbach's alpha\ntest was employed to ensure validity. This research applies the interpretative\nstructural modeling technique in the first phase to identify the main barriers.\nAmong those barriers, \"regularity compliance\" and \"cold chain networks\" are key\ndrivers for IoT adoption strategies. MICMAC's driving and dependence power\nelement categorization helps evaluate the barrier interactions. In the second\nphase of this research, a decision-making trial and evaluation laboratory\nmethodology was employed to identify causal relationships between barriers and\nevaluate them according to their relative importance. Each cause is a potential\ndrive, and if its efficiency can be enhanced, the system as a whole benefits.\nThe research findings provide industry stakeholders, governments, and\norganizations with significant drivers of IoT adoption to overcome these\nbarriers and optimize the utilization of IoT technology to improve the\neffectiveness and reliability of the cold supply chain.",
      "tldr_zh": "本研究分析了在冷供应链中实施Internet of Things (IoT)技术的障碍，通过文献回顾识别出13个主要障碍。研究采用两阶段方法：第一阶段使用Interpretive Structural Modeling (ISM)和MICMAC分析来识别关键障碍及其互动关系，发现“regularity compliance”和“cold chain networks”是IoT采用的核心驱动因素。第二阶段应用Decision-Making Trial and Evaluation Laboratory (DEMATEL)方法，探讨障碍间的因果关系和相对重要性，以提供优化策略。研究结果为行业利益相关者、政府和组织提供指导，帮助克服这些障碍，提升冷供应链的有效性和可靠性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01804v4",
      "published_date": "2024-02-02 08:37:06 UTC",
      "updated_date": "2024-11-05 13:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:39:13.907018"
    },
    {
      "arxiv_id": "2402.01208v1",
      "title": "Location Agnostic Adaptive Rain Precipitation Prediction using Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Md Shazid Islam",
        "Md Saydur Rahman",
        "Md Saad Ul Haque",
        "Farhana Akter Tumpa",
        "Md Sanzid Bin Hossain",
        "Abul Al Arabi"
      ],
      "abstract": "Rain precipitation prediction is a challenging task as it depends on weather\nand meteorological features which vary from location to location. As a result,\na prediction model that performs well at one location does not perform well at\nother locations due to the distribution shifts. In addition, due to global\nwarming, the weather patterns are changing very rapidly year by year which\ncreates the possibility of ineffectiveness of those models even at the same\nlocation as time passes. In our work, we have proposed an adaptive deep\nlearning-based framework in order to provide a solution to the aforementioned\nchallenges. Our method can generalize the model for the prediction of\nprecipitation for any location where the methods without adaptation fail. Our\nmethod has shown 43.51%, 5.09%, and 38.62% improvement after adaptation using a\ndeep neural network for predicting the precipitation of Paris, Los Angeles, and\nTokyo, respectively.",
      "tldr_zh": "该研究针对雨量预测的挑战提出了一种位置无关的自适应深度学习框架，以应对不同地点的气象特征分布偏移和全球变暖导致的天气模式变化。该框架通过自适应机制，使模型能够泛化到任何位置，避免传统方法在位置转移时的失效。实验结果显示，使用深度神经网络后，该方法对巴黎、洛杉矶和东京的雨量预测准确率分别提高了43.51%、5.09%和38.62%。这项工作为更可靠的动态天气预测提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01208v1",
      "published_date": "2024-02-02 08:26:42 UTC",
      "updated_date": "2024-02-02 08:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:39:25.979798"
    },
    {
      "arxiv_id": "2402.01207v4",
      "title": "Efficient Causal Graph Discovery Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Jiralerspong",
        "Xiaoyin Chen",
        "Yash More",
        "Vedant Shah",
        "Yoshua Bengio"
      ],
      "abstract": "We propose a novel framework that leverages LLMs for full causal graph\ndiscovery. While previous LLM-based methods have used a pairwise query\napproach, this requires a quadratic number of queries which quickly becomes\nimpractical for larger causal graphs. In contrast, the proposed framework uses\na breadth-first search (BFS) approach which allows it to use only a linear\nnumber of queries. We also show that the proposed method can easily incorporate\nobservational data when available, to improve performance. In addition to being\nmore time and data-efficient, the proposed framework achieves state-of-the-art\nresults on real-world causal graphs of varying sizes. The results demonstrate\nthe effectiveness and efficiency of the proposed method in discovering causal\nrelationships, showcasing its potential for broad applicability in causal graph\ndiscovery tasks across different domains.",
      "tldr_zh": "该研究提出了一种高效框架，利用大型语言模型(LLMs)进行完整的因果图发现，与以往的成对查询方法相比，该框架采用广度优先搜索(BFS)策略，仅需线性数量的查询，从而显著降低计算开销。框架还可轻松整合观测数据以提升性能，在各种大小的真实世界因果图上实现了最先进的结果。总体而言，这种方法不仅提高了时间和数据效率，还展示了在不同领域发现因果关系的广阔潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01207v4",
      "published_date": "2024-02-02 08:25:32 UTC",
      "updated_date": "2024-07-20 18:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:39:38.578723"
    },
    {
      "arxiv_id": "2402.01204v4",
      "title": "A Survey on Self-Supervised Learning for Non-Sequential Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Wei-Yao Wang",
        "Wei-Wei Du",
        "Derek Xu",
        "Wei Wang",
        "Wen-Chih Peng"
      ],
      "abstract": "Self-supervised learning (SSL) has been incorporated into many\nstate-of-the-art models in various domains, where SSL defines pretext tasks\nbased on unlabeled datasets to learn contextualized and robust representations.\nRecently, SSL has become a new trend in exploring the representation learning\ncapability in the realm of tabular data, which is more challenging due to not\nhaving explicit relations for learning descriptive representations. This survey\naims to systematically review and summarize the recent progress and challenges\nof SSL for non-sequential tabular data (SSL4NS-TD). We first present a formal\ndefinition of NS-TD and clarify its correlation to related studies. Then, these\napproaches are categorized into three groups - predictive learning, contrastive\nlearning, and hybrid learning, with their motivations and strengths of\nrepresentative methods in each direction. Moreover, application issues of\nSSL4NS-TD are presented, including automatic data engineering, cross-table\ntransferability, and domain knowledge integration. In addition, we elaborate on\nexisting benchmarks and datasets for NS-TD applications to analyze the\nperformance of existing tabular models. Finally, we discuss the challenges of\nSSL4NS-TD and provide potential directions for future research. We expect our\nwork to be useful in terms of encouraging more research on lowering the barrier\nto entry SSL for the tabular domain, and of improving the foundations for\nimplicit tabular data.",
      "tldr_zh": "本调查论文系统回顾了自监督学习 (SSL) 在非序列表格数据 (Non-Sequential Tabular Data, NS-TD) 中的应用进展，强调了 SSL 通过定义预文本任务来学习鲁棒表示的挑战和潜力。论文将 SSL 方法分为预测学习、对比学习和混合学习三类，并分析了每类方法的动机、优势以及代表性技术。讨论了实际应用问题，包括自动数据工程、跨表可转移性和领域知识整合，并评估了现有基准和数据集以分析表格模型性能。最后，论文指出了 SSL4NS-TD 的关键挑战，并提出未来研究方向，以降低 SSL 在表格领域的进入门槛并改进隐式数据基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACML-24 Journal Track. The paper list can be found at\n  https://github.com/wwweiwei/awesome-self-supervised-learning-for-tabular-data",
      "pdf_url": "http://arxiv.org/pdf/2402.01204v4",
      "published_date": "2024-02-02 08:17:41 UTC",
      "updated_date": "2024-09-10 07:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:39:52.111895"
    },
    {
      "arxiv_id": "2402.03370v1",
      "title": "Detection of tortured phrases in scientific literature",
      "title_zh": "翻译失败",
      "authors": [
        "Eléna Martel",
        "Martin Lentschat",
        "Cyril Labbé"
      ],
      "abstract": "This paper presents various automatic detection methods to extract so called\ntortured phrases from scientific papers. These tortured phrases, e.g. flag to\nclamor instead of signal to noise, are the results of paraphrasing tools used\nto escape plagiarism detection. We built a dataset and evaluated several\nstrategies to flag previously undocumented tortured phrases. The proposed and\ntested methods are based on language models and either on embeddings\nsimilarities or on predictions of masked token. We found that an approach using\ntoken prediction and that propagates the scores to the chunk level gives the\nbest results. With a recall value of .87 and a precision value of .61, it could\nretrieve new tortured phrases to be submitted to domain experts for validation.",
      "tldr_zh": "本研究探讨了科学文献中tortured phrases的自动检测方法，这些短语（如“flag to clamor”代替“signal to noise”）是使用改写工具逃避抄袭检测的产物。作者构建了一个数据集，并评估了基于language models的多种策略，包括embeddings similarities和masked token预测。结果显示，使用token prediction并将分数传播到chunk级别的方案效果最佳，实现了0.87的recall和0.61的precision，能够有效识别新tortured phrases并提交给领域专家验证。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.DL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03370v1",
      "published_date": "2024-02-02 08:15:43 UTC",
      "updated_date": "2024-02-02 08:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:40:03.451978"
    },
    {
      "arxiv_id": "2402.01201v1",
      "title": "Few-Shot Class-Incremental Learning with Prior Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Jiang",
        "Duo Li",
        "Menghan Hu",
        "Guangtao Zhai",
        "Xiaokang Yang",
        "Xiao-Ping Zhang"
      ],
      "abstract": "To tackle the issues of catastrophic forgetting and overfitting in few-shot\nclass-incremental learning (FSCIL), previous work has primarily concentrated on\npreserving the memory of old knowledge during the incremental phase. The role\nof pre-trained model in shaping the effectiveness of incremental learning is\nfrequently underestimated in these studies. Therefore, to enhance the\ngeneralization ability of the pre-trained model, we propose Learning with Prior\nKnowledge (LwPK) by introducing nearly free prior knowledge from a few\nunlabeled data of subsequent incremental classes. We cluster unlabeled\nincremental class samples to produce pseudo-labels, then jointly train these\nwith labeled base class samples, effectively allocating embedding space for\nboth old and new class data. Experimental results indicate that LwPK\neffectively enhances the model resilience against catastrophic forgetting, with\ntheoretical analysis based on empirical risk minimization and class distance\nmeasurement corroborating its operational principles. The source code of LwPK\nis publicly available at: \\url{https://github.com/StevenJ308/LwPK}.",
      "tldr_zh": "该研究针对少样本类增量学习（Few-Shot Class-Incremental Learning, FSCIL）中的灾难性遗忘（catastrophic forgetting）和过拟合问题，提出了一种名为 Learning with Prior Knowledge (LwPK) 的方法，通过引入后续增量类的少量无标签数据作为先验知识来提升预训练模型的泛化能力。\nLwPK 的核心机制是先对无标签增量类样本进行聚类生成伪标签，然后与带标签的基类样本联合训练，从而为旧和新类数据分配合适的嵌入空间。\n实验结果表明，该方法有效增强了模型对灾难性遗忘的抵抗力，并通过经验风险最小化（empirical risk minimization）和类距离测量（class distance measurement）的理论分析支持了其原理。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01201v1",
      "published_date": "2024-02-02 08:05:35 UTC",
      "updated_date": "2024-02-02 08:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:40:16.542863"
    },
    {
      "arxiv_id": "2402.01195v2",
      "title": "Conditional Normalizing Flows for Active Learning of Coarse-Grained Molecular Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Henrik Schopmans",
        "Pascal Friederich"
      ],
      "abstract": "Efficient sampling of the Boltzmann distribution of molecular systems is a\nlong-standing challenge. Recently, instead of generating long molecular\ndynamics simulations, generative machine learning methods such as normalizing\nflows have been used to learn the Boltzmann distribution directly, without\nsamples. However, this approach is susceptible to mode collapse and thus often\ndoes not explore the full configurational space. In this work, we address this\nchallenge by separating the problem into two levels, the fine-grained and\ncoarse-grained degrees of freedom. A normalizing flow conditioned on the\ncoarse-grained space yields a probabilistic connection between the two levels.\nTo explore the configurational space, we employ coarse-grained simulations with\nactive learning which allows us to update the flow and make all-atom potential\nenergy evaluations only when necessary. Using alanine dipeptide as an example,\nwe show that our methods obtain a speedup to molecular dynamics simulations of\napproximately 15.9 to 216.2 compared to the speedup of 4.5 of the current\nstate-of-the-art machine learning approach.",
      "tldr_zh": "本研究针对分子系统Boltzmann分布的采样挑战，提出使用条件Normalizing Flows结合Active Learning的方法，以提高粗粒度(Coarse-Grained)分子表示的学习效率。方法将分子自由度分为细粒度(Fine-Grained)和粗粒度空间，通过条件Normalizing Flows建立两者之间的概率连接，并在粗粒度模拟中应用Active Learning，仅在必要时进行全原子势能评估，从而探索完整的配置空间。以丙氨酸二肽(Alanine Dipeptide)为例，实验结果显示，该方法相对于当前最先进机器学习方法的4.5倍加速，实现了15.9至216.2倍的模拟速度提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01195v2",
      "published_date": "2024-02-02 07:44:26 UTC",
      "updated_date": "2024-05-24 12:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:40:26.288927"
    },
    {
      "arxiv_id": "2402.01802v1",
      "title": "An Auction-based Marketplace for Model Trading in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Cui",
        "Liuyi Yao",
        "Yaliang Li",
        "Ziqian Chen",
        "Bolin Ding",
        "Xiaofang Zhou"
      ],
      "abstract": "Federated learning (FL) is increasingly recognized for its efficacy in\ntraining models using locally distributed data. However, the proper valuation\nof shared data in this collaborative process remains insufficiently addressed.\nIn this work, we frame FL as a marketplace of models, where clients act as both\nbuyers and sellers, engaging in model trading. This FL market allows clients to\ngain monetary reward by selling their own models and improve local model\nperformance through the purchase of others' models. We propose an auction-based\nsolution to ensure proper pricing based on performance gain. Incentive\nmechanisms are designed to encourage clients to truthfully reveal their model\nvaluations. Furthermore, we introduce a reinforcement learning (RL) framework\nfor marketing operations, aiming to achieve maximum trading volumes under the\ndynamic and evolving market status. Experimental results on four datasets\ndemonstrate that the proposed FL market can achieve high trading revenue and\nfair downstream task accuracy.",
      "tldr_zh": "这篇论文提出了一种基于拍卖的模型交易市场框架，用于 Federated Learning (FL)，允许客户端作为买家和卖家买卖模型，从而通过出售模型获得货币奖励并通过购买他模型提升本地性能。作者设计了拍卖机制和激励机制，确保定价基于性能提升，并鼓励客户端真实揭示模型估值。同时，引入了 reinforcement learning (RL) 框架来动态优化市场操作，实现最大交易量。实验结果在四个数据集上显示，该框架实现了高交易收入和公平的下游任务准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01802v1",
      "published_date": "2024-02-02 07:25:53 UTC",
      "updated_date": "2024-02-02 07:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:40:38.518045"
    },
    {
      "arxiv_id": "2402.01801v3",
      "title": "Large Language Models for Time Series: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Xiyuan Zhang",
        "Ranak Roy Chowdhury",
        "Rajesh K. Gupta",
        "Jingbo Shang"
      ],
      "abstract": "Large Language Models (LLMs) have seen significant use in domains such as\nnatural language processing and computer vision. Going beyond text, image and\ngraphics, LLMs present a significant potential for analysis of time series\ndata, benefiting domains such as climate, IoT, healthcare, traffic, audio and\nfinance. This survey paper provides an in-depth exploration and a detailed\ntaxonomy of the various methodologies employed to harness the power of LLMs for\ntime series analysis. We address the inherent challenge of bridging the gap\nbetween LLMs' original text data training and the numerical nature of time\nseries data, and explore strategies for transferring and distilling knowledge\nfrom LLMs to numerical time series analysis. We detail various methodologies,\nincluding (1) direct prompting of LLMs, (2) time series quantization, (3)\naligning techniques, (4) utilization of the vision modality as a bridging\nmechanism, and (5) the combination of LLMs with tools. Additionally, this\nsurvey offers a comprehensive overview of the existing multimodal time series\nand text datasets and delves into the challenges and future opportunities of\nthis emerging field. We maintain an up-to-date Github repository which includes\nall the papers and datasets discussed in the survey.",
      "tldr_zh": "这篇调查论文探讨了Large Language Models (LLMs)在时间序列分析中的应用潜力，涵盖气候、IoT、医疗、交通、音频和金融等领域，并提供了一个详细的分类法来桥接LLMs的文本训练背景与数值时间序列数据的挑战。论文概述了多种方法，包括直接prompting、时间序列量化、对齐技术、利用视觉模式作为桥梁，以及与工具的结合，以实现知识转移和蒸馏。最终，它总结了现有多模态时间序列和文本数据集、面临的挑战、未来机会，并维护一个GitHub仓库以追踪相关资源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "GitHub repository:\n  https://github.com/xiyuanzh/awesome-llm-time-series",
      "pdf_url": "http://arxiv.org/pdf/2402.01801v3",
      "published_date": "2024-02-02 07:24:35 UTC",
      "updated_date": "2024-05-06 20:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:40:50.882563"
    },
    {
      "arxiv_id": "2402.01183v1",
      "title": "LINGO-Space: Language-Conditioned Incremental Grounding for Space",
      "title_zh": "LINGO-Space：基于语言的增量空间接地",
      "authors": [
        "Dohyun Kim",
        "Nayoung Oh",
        "Deokmin Hwang",
        "Daehyung Park"
      ],
      "abstract": "We aim to solve the problem of spatially localizing composite instructions\nreferring to space: space grounding. Compared to current instance grounding,\nspace grounding is challenging due to the ill-posedness of identifying\nlocations referred to by discrete expressions and the compositional ambiguity\nof referring expressions. Therefore, we propose a novel probabilistic\nspace-grounding methodology (LINGO-Space) that accurately identifies a\nprobabilistic distribution of space being referred to and incrementally updates\nit, given subsequent referring expressions leveraging configurable polar\ndistributions. Our evaluations show that the estimation using polar\ndistributions enables a robot to ground locations successfully through $20$\ntable-top manipulation benchmark tests. We also show that updating the\ndistribution helps the grounding method accurately narrow the referring space.\nWe finally demonstrate the robustness of the space grounding with simulated\nmanipulation and real quadruped robot navigation tasks. Code and videos are\navailable at https://lingo-space.github.io.",
      "tldr_zh": "本研究针对空间 grounding 的挑战，提出了一种基于语言条件的增量 grounding 方法，名为 LINGO-Space，用于精确定位复合指令中提到的空间位置。该方法采用概率分布和可配置的 polar distributions 来识别初始空间概率，并通过后续引用表达逐步更新分布，以解决定位不确定性和组合模糊性问题。实验结果显示，LINGO-Space 在 20 个 table-top manipulation benchmark tests 中成功地帮助机器人定位空间，并通过分布更新精确缩小引用区域，最终在模拟操作和真实四足机器人导航任务中证明了其鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01183v1",
      "published_date": "2024-02-02 06:58:39 UTC",
      "updated_date": "2024-02-02 06:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:41:04.146027"
    },
    {
      "arxiv_id": "2402.01799v2",
      "title": "Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward",
      "title_zh": "翻译失败",
      "authors": [
        "Arnav Chavan",
        "Raghav Magazine",
        "Shubham Kushwaha",
        "Mérouane Debbah",
        "Deepak Gupta"
      ],
      "abstract": "Despite the impressive performance of LLMs, their widespread adoption faces\nchallenges due to substantial computational and memory requirements during\ninference. Recent advancements in model compression and system-level\noptimization methods aim to enhance LLM inference. This survey offers an\noverview of these methods, emphasizing recent developments. Through experiments\non LLaMA(/2)-7B, we evaluate various compression techniques, providing\npractical insights for efficient LLM deployment in a unified setting. The\nempirical analysis on LLaMA(/2)-7B highlights the effectiveness of these\nmethods. Drawing from survey insights, we identify current limitations and\ndiscuss potential future directions to improve LLM inference efficiency. We\nrelease the codebase to reproduce the results presented in this paper at\nhttps://github.com/nyunAI/Faster-LLM-Survey",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）的当前挑战，包括推理过程中的高计算和内存需求，并概述了模型压缩和系统级优化方法，以实现更快速、更轻量的LLMs。作者通过在LLaMA(/2)-7B模型上的实验，评估了各种压缩技术，提供统一的实用见解，证明这些方法能有效提升LLMs的部署效率。论文还指出了现有限制，并提出未来方向，如进一步优化和创新，同时公开了代码库（https://github.com/nyunAI/Faster-LLM-Survey）以便重现结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IJCAI '24 (Survey Track), Updated TGI results",
      "pdf_url": "http://arxiv.org/pdf/2402.01799v2",
      "published_date": "2024-02-02 06:29:34 UTC",
      "updated_date": "2024-04-24 04:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:41:13.908653"
    },
    {
      "arxiv_id": "2402.18587v1",
      "title": "At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulkadir Celik",
        "Ahmed M. Eltawil"
      ],
      "abstract": "The majority of data-driven wireless research leans heavily on discriminative\nAI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI\n(GenAI) pertains to generative models (GMs) capable of discerning the\nunderlying data distribution, patterns, and features of the input data. This\nmakes GenAI a crucial asset in wireless domain wherein real-world data is often\nscarce, incomplete, costly to acquire, and hard to model or comprehend. With\nthese appealing attributes, GenAI can replace or supplement DAI methods in\nvarious capacities. Accordingly, this combined tutorial-survey paper commences\nwith preliminaries of 6G and wireless intelligence by outlining candidate 6G\napplications and services, presenting a taxonomy of state-of-the-art DAI\nmodels, exemplifying prominent DAI use cases, and elucidating the multifaceted\nways through which GenAI enhances DAI. Subsequently, we present a tutorial on\nGMs by spotlighting seminal examples such as generative adversarial networks,\nvariational autoencoders, flow-based GMs, diffusion-based GMs, generative\ntransformers, large language models, to name a few. Contrary to the prevailing\nbelief that GenAI is a nascent trend, our exhaustive review of approximately\n120 technical papers demonstrates the scope of research across core wireless\nresearch areas, including physical layer design; network optimization,\norganization, and management; network traffic analytics; cross-layer network\nsecurity; and localization & positioning. Furthermore, we outline the central\nrole of GMs in pioneering areas of 6G network research, including\nsemantic/THz/near-field communications, ISAC, extremely large antenna arrays,\ndigital twins, AI-generated content services, mobile edge computing and edge\nAI, adversarial ML, and trustworthy AI. Lastly, we shed light on the\nmultifarious challenges ahead, suggesting potential strategies and promising\nremedies.",
      "tldr_zh": "这篇论文以教程和调查形式探讨了 Generative AI (GenAI) 在 6G 无线智能中的新前沿，强调 GenAI 通过理解数据分布和模式，能够解决数据稀缺问题并补充或取代 Discriminative AI (DAI)。论文首先概述了 6G 应用、DAI 模型分类和 GenAI 的增强作用，然后提供 GenAI 模型教程，包括 Generative Adversarial Networks (GANs)、Variational Autoencoders (VAEs) 等，并回顾约 120 篇文献，涵盖物理层设计、网络优化和语义通信等领域。最终，它突出了 GenAI 在 6G 创新如数字孪生和可信赖 AI 中的核心作用，同时指出了面临的挑战并提出潜在策略。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.18587v1",
      "published_date": "2024-02-02 06:23:25 UTC",
      "updated_date": "2024-02-02 06:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:41:28.958054"
    },
    {
      "arxiv_id": "2402.01169v1",
      "title": "Faster Inference of Integer SWIN Transformer by Removing the GELU Activation",
      "title_zh": "通过移除 GELU 激活函数加速整数 Swin Transformer 的推理",
      "authors": [
        "Mohammadreza Tayaranian",
        "Seyyed Hasan Mozafari",
        "James J. Clark",
        "Brett Meyer",
        "Warren Gross"
      ],
      "abstract": "SWIN transformer is a prominent vision transformer model that has\nstate-of-the-art accuracy in image classification tasks. Despite this success,\nits unique architecture causes slower inference compared with similar deep\nneural networks. Integer quantization of the model is one of the methods used\nto improve its inference latency. However, state-of-the-art has not been able\nto fully quantize the model. In this work, we improve upon the inference\nlatency of the state-of-the-art methods by removing the floating-point\noperations, which are associated with the GELU activation in Swin Transformer.\nWhile previous work proposed to replace the non-integer operations with linear\napproximation functions, we propose to replace GELU with ReLU activation. The\nadvantage of ReLU over previous methods is its low memory and computation\ncomplexity. We use iterative knowledge distillation to compensate for the lost\naccuracy due to replacing GELU with ReLU. We quantize our GELU-less SWIN\ntransformer and show that on an RTX 4090 NVIDIA GPU we can improve the\ninference latency of the quantized SWIN transformer by at least $11\\%$ while\nmaintaining an accuracy drop of under $0.5\\%$ on the ImageNet evaluation\ndataset.",
      "tldr_zh": "本文提出了一种优化整数量化 SWIN Transformer 的方法，通过移除 GELU 激活函数并用 ReLU 激活函数替换，以降低内存和计算复杂度。作者采用迭代知识蒸馏（iterative knowledge distillation）技术来补偿替换带来的准确率损失。实验结果显示，在 RTX 4090 NVIDIA GPU 上，该方法使量化 SWIN Transformer 的推理延迟至少改善 11%，同时在 ImageNet 数据集上的准确率仅下降不到 0.5%。这为提升视觉Transformer模型的推理效率提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 1 figure. Submitted to Edge Intelligence Workshop III, an\n  AAAI 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2402.01169v1",
      "published_date": "2024-02-02 06:23:00 UTC",
      "updated_date": "2024-02-02 06:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:41:38.603040"
    },
    {
      "arxiv_id": "2402.01166v2",
      "title": "A Comprehensive Survey on 3D Content Generation",
      "title_zh": "3D内容生成的全面综述",
      "authors": [
        "Jian Liu",
        "Xiaoshui Huang",
        "Tianyu Huang",
        "Lu Chen",
        "Yuenan Hou",
        "Shixiang Tang",
        "Ziwei Liu",
        "Wanli Ouyang",
        "Wangmeng Zuo",
        "Junjun Jiang",
        "Xianming Liu"
      ],
      "abstract": "Recent years have witnessed remarkable advances in artificial intelligence\ngenerated content(AIGC), with diverse input modalities, e.g., text, image,\nvideo, audio and 3D. The 3D is the most close visual modality to real-world 3D\nenvironment and carries enormous knowledge. The 3D content generation shows\nboth academic and practical values while also presenting formidable technical\nchallenges. This review aims to consolidate developments within the burgeoning\ndomain of 3D content generation. Specifically, a new taxonomy is proposed that\ncategorizes existing approaches into three types: 3D native generative methods,\n2D prior-based 3D generative methods, and hybrid 3D generative methods. The\nsurvey covers approximately 60 papers spanning the major techniques. Besides,\nwe discuss limitations of current 3D content generation techniques, and point\nout open challenges as well as promising directions for future work.\nAccompanied with this survey, we have established a project website where the\nresources on 3D content generation research are provided. The project page is\navailable at https://github.com/hitcslj/Awesome-AIGC-3D.",
      "tldr_zh": "这篇综述总结了人工智能生成内容（AIGC）在 3D 内容生成领域的最新进展，强调 3D 作为接近真实世界环境的视觉模式，其学术和实际价值，同时讨论了面临的重大技术挑战。作者提出一个新的分类法，将现有方法分为三类：3D native generative methods、2D prior-based 3D generative methods 和 hybrid 3D generative methods，并涵盖了约 60 篇相关论文。综述还分析了当前技术的局限性、开放挑战以及未来研究方向，并提供了一个资源网站（https://github.com/hitcslj/Awesome-AIGC-3D）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2402.01166v2",
      "published_date": "2024-02-02 06:20:44 UTC",
      "updated_date": "2024-03-19 08:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:41:51.720531"
    },
    {
      "arxiv_id": "2403.17942v1",
      "title": "A Note On Lookahead In Real Life And Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Burle Sharma",
        "Rakesh Mohanty",
        "Sucheta Panda"
      ],
      "abstract": "Past, Present and Future are considered to be three temporal and logical\nconcepts which are well defined by human beings for their existence and growth.\nWe, as human beings, have the privilege of using our intelligence to mentally\nexecute an activity before physical occurrence of the same in the real world.\nKnowledge of the past, aplomb of present and visualisation for the future\ncorrespond to three concepts such as look-back, look-at and look-ahead\nrespectively in real life as well as in diversified domains of computing.\nLook-Ahead(LA) deals with the future prediction of information and processing\nof input to produce the output in advance. In this article, our main objective\nis to learn, understand and explore the concept of LA and design novel models\nas solution for real world problems. We present three well known algorithmic\nframeworks used in practice based on availability of input information such as\noffline, online and semi-online. We introduce interesting real life\napplications and well known computing problems where LA plays a significant\nrole for making a process, system or algorithm efficient. We define new types\nof LA and propose a taxonomy for LA based on literature review for designing\nnovel LA models in future. Using the concept of LA, We identify and present\nmany interesting and non-trivial research challenges as future potential\nresearch directions. Intuitively, we observe that LA can be used as a powerful\ntool and framework for future researchers in design of efficient computational\nmodels and algorithms for solving non-trivial and challenging optimization\nproblems.",
      "tldr_zh": "这篇论文探讨了 Look-Ahead (LA) 概念，将其与人类对过去、现在和未来的认知相联系，强调 LA 在现实生活和计算领域的预测性作用。作者介绍了三种基于输入信息可用性的算法框架：offline、online 和 semi-online，并通过文献回顾分析了 LA 在实际应用和计算问题中的效率提升。论文定义了新 LA 类型，提出 taxonomy 分类法，并指出 LA 可作为设计高效算法和解决优化问题的强大工具，为未来研究提供潜在方向。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17942v1",
      "published_date": "2024-02-02 06:17:49 UTC",
      "updated_date": "2024-02-02 06:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:42:04.053685"
    },
    {
      "arxiv_id": "2402.01162v1",
      "title": "2AFC Prompting of Large Multimodal Models for Image Quality Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Hanwei Zhu",
        "Xiangjie Sui",
        "Baoliang Chen",
        "Xuelin Liu",
        "Peilin Chen",
        "Yuming Fang",
        "Shiqi Wang"
      ],
      "abstract": "While abundant research has been conducted on improving high-level visual\nunderstanding and reasoning capabilities of large multimodal models~(LMMs),\ntheir visual quality assessment~(IQA) ability has been relatively\nunder-explored. Here we take initial steps towards this goal by employing the\ntwo-alternative forced choice~(2AFC) prompting, as 2AFC is widely regarded as\nthe most reliable way of collecting human opinions of visual quality.\nSubsequently, the global quality score of each image estimated by a particular\nLMM can be efficiently aggregated using the maximum a posterior estimation.\nMeanwhile, we introduce three evaluation criteria: consistency, accuracy, and\ncorrelation, to provide comprehensive quantifications and deeper insights into\nthe IQA capability of five LMMs. Extensive experiments show that existing LMMs\nexhibit remarkable IQA ability on coarse-grained quality comparison, but there\nis room for improvement on fine-grained quality discrimination. The proposed\ndataset sheds light on the future development of IQA models based on LMMs. The\ncodes will be made publicly available at https://github.com/h4nwei/2AFC-LMMs.",
      "tldr_zh": "本研究探讨了大型多模态模型 (LMMs) 在图像质量评估 (IQA) 方面的能力，通过引入两选一强迫选择 (2AFC) 提示方法来模拟人类视觉质量意见的可靠收集方式。研究利用最大后验估计高效聚合 LMMs 对图像的全局质量分数，并提出一致性、准确性和相关性三个评估标准，对五种 LMMs 进行全面量化。实验结果显示，现有的 LMMs 在粗粒度质量比较上表现出色，但细粒度质量区分仍有改进空间；此外，该研究提供了一个新数据集，以推动基于 LMMs 的 IQA 模型未来发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01162v1",
      "published_date": "2024-02-02 06:05:18 UTC",
      "updated_date": "2024-02-02 06:05:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:42:16.245732"
    },
    {
      "arxiv_id": "2402.01145v3",
      "title": "ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Ye",
        "Jiarui Wang",
        "Zhiguang Cao",
        "Federico Berto",
        "Chuanbo Hua",
        "Haeyeon Kim",
        "Jinkyoo Park",
        "Guojie Song"
      ],
      "abstract": "The omnipresence of NP-hard combinatorial optimization problems (COPs)\ncompels domain experts to engage in trial-and-error heuristic design. The\nlong-standing endeavor of design automation has gained new momentum with the\nrise of large language models (LLMs). This paper introduces Language\nHyper-Heuristics (LHHs), an emerging variant of Hyper-Heuristics that leverages\nLLMs for heuristic generation, featuring minimal manual intervention and\nopen-ended heuristic spaces. To empower LHHs, we present Reflective Evolution\n(ReEvo), a novel integration of evolutionary search for efficiently exploring\nthe heuristic space, and LLM reflections to provide verbal gradients within the\nspace. Across five heterogeneous algorithmic types, six different COPs, and\nboth white-box and black-box views of COPs, ReEvo yields state-of-the-art and\ncompetitive meta-heuristics, evolutionary algorithms, heuristics, and neural\nsolvers, while being more sample-efficient than prior LHHs.",
      "tldr_zh": "该研究提出 Language Hyper-Heuristics (LHHs)，一种利用 Large Language Models (LLMs) 生成启发式算法的方法，以最小化手动干预并扩展启发式空间。作者引入 Reflective Evolution (ReEvo) 框架，将进化搜索与 LLM 的反思机制相结合，提供 verbal gradients 来高效探索启发式空间。在五种算法类型、六种 NP-hard combinatorial optimization problems (COPs) 以及白盒和黑盒视图下，ReEvo 生成了最先进的元启发式算法、进化算法、启发式和神经求解器，且比现有 LHHs 更具样本效率。总的来说，这一方法为自动化设计优化算法提供了新途径，提升了解决复杂 COPs 的性能。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01145v3",
      "published_date": "2024-02-02 05:04:51 UTC",
      "updated_date": "2024-10-14 13:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:42:27.462158"
    },
    {
      "arxiv_id": "2402.01143v2",
      "title": "Learning Network Representations with Disentangled Graph Auto-Encoder",
      "title_zh": "翻译失败",
      "authors": [
        "Di Fan",
        "Chuanhou Gao"
      ],
      "abstract": "The (variational) graph auto-encoder is widely used to learn representations\nfor graph-structured data. However, the formation of real-world graphs is a\ncomplicated and heterogeneous process influenced by latent factors. Existing\nencoders are fundamentally holistic, neglecting the entanglement of latent\nfactors. This reduces the effectiveness of graph analysis tasks, while also\nmaking it more difficult to explain the learned representations. As a result,\nlearning disentangled graph representations with the (variational) graph\nauto-encoder poses significant challenges and remains largely unexplored in the\ncurrent research. In this paper, we introduce the Disentangled Graph\nAuto-Encoder (DGA) and the Disentangled Variational Graph Auto-Encoder (DVGA)\nto learn disentangled representations. Specifically, we first design a\ndisentangled graph convolutional network with multi-channel message-passing\nlayers to serve as the encoder. This allows each channel to aggregate\ninformation about each latent factor. The disentangled variational graph\nauto-encoder's expressive capability is then enhanced by applying a\ncomponent-wise flow to each channel. In addition, we construct a factor-wise\ndecoder that takes into account the characteristics of disentangled\nrepresentations. We improve the independence of representations by imposing\nindependence constraints on the mapping channels for distinct latent factors.\nEmpirical experiments on both synthetic and real-world datasets demonstrate the\nsuperiority of our proposed method compared to several state-of-the-art\nbaselines.",
      "tldr_zh": "本研究针对传统图自动编码器（graph auto-encoder）在处理真实图数据时忽略潜在因素纠缠的问题，提出Disentangled Graph Auto-Encoder (DGA)和Disentangled Variational Graph Auto-Encoder (DVGA)模型，以学习解缠的图表示。具体而言，该方法设计了多通道消息传递层（multi-channel message-passing layers）的解缠图卷积网络作为编码器，并通过组件-wise flow增强变分模型的表达能力，同时引入因子-wise解码器和独立性约束（independence constraints）来提升表示的独立性。实验结果显示，该方法在合成和真实数据集上显著优于现有基线模型，提高了图分析任务的效能和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01143v2",
      "published_date": "2024-02-02 04:52:52 UTC",
      "updated_date": "2024-07-16 16:07:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:42:40.045996"
    },
    {
      "arxiv_id": "2402.01140v1",
      "title": "Root Cause Analysis In Microservice Using Neural Granger Causal Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng-Ming Lin",
        "Ching Chang",
        "Wei-Yao Wang",
        "Kuang-Da Wang",
        "Wen-Chih Peng"
      ],
      "abstract": "In recent years, microservices have gained widespread adoption in IT\noperations due to their scalability, maintenance, and flexibility. However, it\nbecomes challenging for site reliability engineers (SREs) to pinpoint the root\ncause due to the complex relationships in microservices when facing system\nmalfunctions. Previous research employed structured learning methods (e.g.,\nPC-algorithm) to establish causal relationships and derive root causes from\ncausal graphs. Nevertheless, they ignored the temporal order of time series\ndata and failed to leverage the rich information inherent in the temporal\nrelationships. For instance, in cases where there is a sudden spike in CPU\nutilization, it can lead to an increase in latency for other microservices.\nHowever, in this scenario, the anomaly in CPU utilization occurs before the\nlatency increase, rather than simultaneously. As a result, the PC-algorithm\nfails to capture such characteristics. To address these challenges, we propose\nRUN, a novel approach for root cause analysis using neural Granger causal\ndiscovery with contrastive learning. RUN enhances the backbone encoder by\nintegrating contextual information from time series, and leverages a time\nseries forecasting model to conduct neural Granger causal discovery. In\naddition, RUN incorporates Pagerank with a personalization vector to\nefficiently recommend the top-k root causes. Extensive experiments conducted on\nthe synthetic and real-world microservice-based datasets demonstrate that RUN\nnoticeably outperforms the state-of-the-art root cause analysis methods.\nMoreover, we provide an analysis scenario for the sock-shop case to showcase\nthe practicality and efficacy of RUN in microservice-based applications. Our\ncode is publicly available at https://github.com/zmlin1998/RUN.",
      "tldr_zh": "这篇论文针对微服务架构中系统故障的根因分析问题，提出了一种名为RUN的新方法，利用神经Granger causal discovery和对比学习来捕捉时间序列数据的时序关系。RUN通过增强骨干编码器整合上下文信息，并结合时间序列预测模型和Pagerank个性化向量来高效识别和推荐top-k根因。实验结果显示，RUN在合成和真实微服务数据集上显著优于现有方法，如PC-algorithm，并通过sock-shop案例验证了其实际应用价值；代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2024 Main Track",
      "pdf_url": "http://arxiv.org/pdf/2402.01140v1",
      "published_date": "2024-02-02 04:43:06 UTC",
      "updated_date": "2024-02-02 04:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:42:51.067709"
    },
    {
      "arxiv_id": "2402.01134v2",
      "title": "DeepAAT: Deep Automated Aerial Triangulation for Fast UAV-based Mapping",
      "title_zh": "DeepAAT：深度自动航空三角测量用于快速基于 UAV 的映射",
      "authors": [
        "Zequan Chen",
        "Jianping Li",
        "Qusheng Li",
        "Bisheng Yang",
        "Zhen Dong"
      ],
      "abstract": "Automated Aerial Triangulation (AAT), aiming to restore image pose and\nreconstruct sparse points simultaneously, plays a pivotal role in earth\nobservation. With its rich research heritage spanning several decades in\nphotogrammetry, AAT has evolved into a fundamental process widely applied in\nlarge-scale Unmanned Aerial Vehicle (UAV) based mapping. Despite its\nadvancements, classic AAT methods still face challenges like low efficiency and\nlimited robustness. This paper introduces DeepAAT, a deep learning network\ndesigned specifically for AAT of UAV imagery. DeepAAT considers both spatial\nand spectral characteristics of imagery, enhancing its capability to resolve\nerroneous matching pairs and accurately predict image poses. DeepAAT marks a\nsignificant leap in AAT's efficiency, ensuring thorough scene coverage and\nprecision. Its processing speed outpaces incremental AAT methods by hundreds of\ntimes and global AAT methods by tens of times while maintaining a comparable\nlevel of reconstruction accuracy. Additionally, DeepAAT's scene clustering and\nmerging strategy facilitate rapid localization and pose determination for\nlarge-scale UAV images, even under constrained computing resources. The\nexperimental results demonstrate DeepAAT's substantial improvements over\nconventional AAT methods, highlighting its potential in the efficiency and\naccuracy of UAV-based 3D reconstruction tasks. To benefit the photogrammetry\nsociety, the code of DeepAAT will be released at:\nhttps://github.com/WHU-USI3DV/DeepAAT.",
      "tldr_zh": "本文提出DeepAAT，一种基于深度学习的Automated Aerial Triangulation (AAT) 方法，旨在提升UAV-based映射的效率和鲁棒性。该方法通过整合图像的空间和光谱特性，解决匹配错误问题并准确预测图像姿态，同时采用场景聚类和合并策略，便于大规模UAV图像的快速定位。实验结果显示，DeepAAT的处理速度比增量AAT方法快数百倍，比全局AAT方法快数十倍，同时保持可比的3D重建精度。作者开源了代码（https://github.com/WHU-USI3DV/DeepAAT），为摄影测量领域带来显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01134v2",
      "published_date": "2024-02-02 04:17:02 UTC",
      "updated_date": "2024-04-07 06:30:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:43:04.008731"
    },
    {
      "arxiv_id": "2402.01791v1",
      "title": "Variational Quantum Circuits Enhanced Generative Adversarial Network",
      "title_zh": "翻译失败",
      "authors": [
        "Runqiu Shu",
        "Xusheng Xu",
        "Man-Hong Yung",
        "Wei Cui"
      ],
      "abstract": "Generative adversarial network (GAN) is one of the widely-adopted\nmachine-learning frameworks for a wide range of applications such as generating\nhigh-quality images, video, and audio contents. However, training a GAN could\nbecome computationally expensive for large neural networks. In this work, we\npropose a hybrid quantum-classical architecture for improving GAN (denoted as\nQC-GAN). The performance was examed numerically by benchmarking with a\nclassical GAN using MindSpore Quantum on the task of hand-written image\ngeneration. The generator of the QC-GAN consists of a quantum variational\ncircuit together with a one-layer neural network, and the discriminator\nconsists of a traditional neural network. Leveraging the entangling and\nexpressive power of quantum circuits, our hybrid architecture achieved better\nperformance (Frechet Inception Distance) than the classical GAN, with much\nfewer training parameters and number of iterations for convergence. We have\nalso demonstrated the superiority of QC-GAN over an alternative quantum GAN,\nnamely pathGAN, which could hardly generate 16$\\times$16 or larger images. This\nwork demonstrates the value of combining ideas from quantum computing with\nmachine learning for both areas of Quantum-for-AI and AI-for-Quantum.",
      "tldr_zh": "这篇论文提出了一种增强生成对抗网络（Generative Adversarial Network, GAN）的混合量子-经典架构，名为 QC-GAN，利用变分量子电路（Variational Quantum Circuits）来提升图像生成性能，同时减少计算开销。QC-GAN 的生成器结合量子电路和一层神经网络，判别器则采用传统神经网络，通过 MindSpore Quantum 在手写图像生成任务上进行基准测试，结果显示其比经典 GAN 取得了更好的 Frechet Inception Distance（FID）分数，并显著降低了训练参数和迭代次数。与另一种量子 GAN（pathGAN）相比，QC-GAN 能够生成更大的图像（如 16×16 或以上），证明了其优越性。该工作展示了量子计算与机器学习的融合在 Quantum-for-AI 和 AI-for-Quantum 领域中的潜在价值。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01791v1",
      "published_date": "2024-02-02 03:59:35 UTC",
      "updated_date": "2024-02-02 03:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:43:16.966625"
    },
    {
      "arxiv_id": "2402.01118v3",
      "title": "PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sihao Hu",
        "Tiansheng Huang",
        "Ling Liu"
      ],
      "abstract": "We introduce PokeLLMon, the first LLM-embodied agent that achieves\nhuman-parity performance in tactical battle games, as demonstrated in Pokemon\nbattles. The design of PokeLLMon incorporates three key strategies: (i)\nIn-context reinforcement learning that instantly consumes text-based feedback\nderived from battles to iteratively refine the policy; (ii) Knowledge-augmented\ngeneration that retrieves external knowledge to counteract hallucination and\nenables the agent to act timely and properly; (iii) Consistent action\ngeneration to mitigate the panic switching phenomenon when the agent faces a\npowerful opponent and wants to elude the battle. We show that online battles\nagainst human demonstrates PokeLLMon's human-like battle strategies and\njust-in-time decision making, achieving 49% of win rate in the Ladder\ncompetitions and 56% of win rate in the invited battles. Our implementation and\nplayable battle logs are available at: https://github.com/git-disl/PokeLLMon.",
      "tldr_zh": "该研究介绍了PokeLLMon，一种基于Large Language Models (LLMs)的代理，首次在Pokemon战斗游戏中实现了与人类相当的性能水平。PokeLLMon采用三项关键策略：(i) In-context reinforcement learning，通过即时文本反馈迭代优化策略；(ii) Knowledge-augmented generation，检索外部知识以减少幻觉并确保及时决策；(iii) Consistent action generation，缓解面对强大对手时的恐慌切换现象。实验结果显示，在在线对战中，PokeLLMon在Ladder比赛中胜率达49%，在邀请赛中达56%，展示了其人类般的策略和决策能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01118v3",
      "published_date": "2024-02-02 03:22:12 UTC",
      "updated_date": "2024-04-02 15:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:43:29.256276"
    },
    {
      "arxiv_id": "2402.01114v1",
      "title": "Double-Dip: Thwarting Label-Only Membership Inference Attacks with Transfer Learning and Randomization",
      "title_zh": "翻译失败",
      "authors": [
        "Arezoo Rajabi",
        "Reeya Pimple",
        "Aiswarya Janardhanan",
        "Surudhi Asokraj",
        "Bhaskar Ramasubramanian",
        "Radha Poovendran"
      ],
      "abstract": "Transfer learning (TL) has been demonstrated to improve DNN model performance\nwhen faced with a scarcity of training samples. However, the suitability of TL\nas a solution to reduce vulnerability of overfitted DNNs to privacy attacks is\nunexplored. A class of privacy attacks called membership inference attacks\n(MIAs) aim to determine whether a given sample belongs to the training dataset\n(member) or not (nonmember). We introduce Double-Dip, a systematic empirical\nstudy investigating the use of TL (Stage-1) combined with randomization\n(Stage-2) to thwart MIAs on overfitted DNNs without degrading classification\naccuracy. Our study examines the roles of shared feature space and parameter\nvalues between source and target models, number of frozen layers, and\ncomplexity of pretrained models. We evaluate Double-Dip on three (Target,\nSource) dataset paris: (i) (CIFAR-10, ImageNet), (ii) (GTSRB, ImageNet), (iii)\n(CelebA, VGGFace2). We consider four publicly available pretrained DNNs: (a)\nVGG-19, (b) ResNet-18, (c) Swin-T, and (d) FaceNet. Our experiments demonstrate\nthat Stage-1 reduces adversary success while also significantly increasing\nclassification accuracy of nonmembers against an adversary with either\nwhite-box or black-box DNN model access, attempting to carry out SOTA\nlabel-only MIAs. After Stage-2, success of an adversary carrying out a\nlabel-only MIA is further reduced to near 50%, bringing it closer to a random\nguess and showing the effectiveness of Double-Dip. Stage-2 of Double-Dip also\nachieves lower ASR and higher classification accuracy than regularization and\ndifferential privacy-based methods.",
      "tldr_zh": "该论文提出Double-Dip方法，利用Transfer Learning（Stage-1）和随机化（Stage-2）来对抗Label-Only Membership Inference Attacks（MIAs），旨在减少过拟合DNN模型的隐私漏洞，同时保持分类准确性。研究通过分析源模型和目标模型的共享特征空间、冻结层数量以及预训练模型的复杂性（如VGG-19、ResNet-18），在数据集对（如CIFAR-10与ImageNet）上进行实验。结果显示，Stage-1显著降低了攻击成功率（ASR）并提升了非成员样本的分类准确性；Stage-2进一步将攻击成功率降至接近50%，优于正则化和差分隐私方法。总的来说，Double-Dip为保护DNN模型隐私提供了有效且高效的策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01114v1",
      "published_date": "2024-02-02 03:14:37 UTC",
      "updated_date": "2024-02-02 03:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:43:42.891451"
    },
    {
      "arxiv_id": "2402.01111v1",
      "title": "Near-Optimal Reinforcement Learning with Self-Play under Adaptivity Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Qiao",
        "Yu-Xiang Wang"
      ],
      "abstract": "We study the problem of multi-agent reinforcement learning (MARL) with\nadaptivity constraints -- a new problem motivated by real-world applications\nwhere deployments of new policies are costly and the number of policy updates\nmust be minimized. For two-player zero-sum Markov Games, we design a (policy)\nelimination based algorithm that achieves a regret of $\\widetilde{O}(\\sqrt{H^3\nS^2 ABK})$, while the batch complexity is only $O(H+\\log\\log K)$. In the above,\n$S$ denotes the number of states, $A,B$ are the number of actions for the two\nplayers respectively, $H$ is the horizon and $K$ is the number of episodes.\nFurthermore, we prove a batch complexity lower bound\n$\\Omega(\\frac{H}{\\log_{A}K}+\\log\\log K)$ for all algorithms with\n$\\widetilde{O}(\\sqrt{K})$ regret bound, which matches our upper bound up to\nlogarithmic factors. As a byproduct, our techniques naturally extend to\nlearning bandit games and reward-free MARL within near optimal batch\ncomplexity. To the best of our knowledge, these are the first line of results\ntowards understanding MARL with low adaptivity.",
      "tldr_zh": "这篇论文研究了多智能体强化学习(MARL) 在适应性约束下的问题，旨在最小化政策更新次数以降低实际部署成本。对于两玩家零和 Markov Games，他们设计了一个基于政策消除的算法，实现 regret 为 \\(\\widetilde{O}(\\sqrt{H^3 S^2 A B K})\\)，而 batch complexity 仅为 \\(O(H + \\log \\log K)\\)。论文证明了 batch complexity 的下界 \\(\\Omega(\\frac{H}{\\log_A K} + \\log \\log K)\\)，与上界匹配到对数因子，并将技术扩展到 bandit games 和 reward-free MARL，实现了近优的 batch complexity。这些结果首次探讨了低适应性的 MARL 问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01111v1",
      "published_date": "2024-02-02 03:00:40 UTC",
      "updated_date": "2024-02-02 03:00:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:43:55.499958"
    },
    {
      "arxiv_id": "2402.01790v1",
      "title": "An introduction to graphical tensor notation for mechanistic interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan K. Taylor"
      ],
      "abstract": "Graphical tensor notation is a simple way of denoting linear operations on\ntensors, originating from physics. Modern deep learning consists almost\nentirely of operations on or between tensors, so easily understanding tensor\noperations is quite important for understanding these systems. This is\nespecially true when attempting to reverse-engineer the algorithms learned by a\nneural network in order to understand its behavior: a field known as\nmechanistic interpretability. It's often easy to get confused about which\noperations are happening between tensors and lose sight of the overall\nstructure, but graphical tensor notation makes it easier to parse things at a\nglance and see interesting equivalences. The first half of this document\nintroduces the notation and applies it to some decompositions (SVD, CP, Tucker,\nand tensor network decompositions), while the second half applies it to some\nexisting some foundational approaches for mechanistically understanding\nlanguage models, loosely following ``A Mathematical Framework for Transformer\nCircuits'', then constructing an example ``induction head'' circuit in\ngraphical tensor notation.",
      "tldr_zh": "这篇论文介绍了 graphical tensor notation，一种源自物理学的简单方法，用于表示张量线性操作，以帮助理解深度学习系统中的复杂计算。作者强调该符号在 mechanistic interpretability 中的重要性，能快速解析张量间的操作、识别等价性和整体结构。论文第一部分应用该符号于常见分解如 SVD、CP、Tucker 和张量网络分解；第二部分则将其用于分析语言模型的机制，基于“A Mathematical Framework for Transformer Circuits”构建一个 induction head 电路示例，从而提升对神经网络行为的逆向工程能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 75 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01790v1",
      "published_date": "2024-02-02 02:56:01 UTC",
      "updated_date": "2024-02-02 02:56:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:44:06.015257"
    },
    {
      "arxiv_id": "2402.01107v3",
      "title": "Simulation of Graph Algorithms with Looped Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Artur Back de Luca",
        "Kimon Fountoulakis"
      ],
      "abstract": "The execution of graph algorithms using neural networks has recently\nattracted significant interest due to promising empirical progress. This\nmotivates further understanding of how neural networks can replicate reasoning\nsteps with relational data. In this work, we study the ability of transformer\nnetworks to simulate algorithms on graphs from a theoretical perspective. The\narchitecture we use is a looped transformer with extra attention heads that\ninteract with the graph. We prove by construction that this architecture can\nsimulate individual algorithms such as Dijkstra's shortest path, Breadth- and\nDepth-First Search, and Kosaraju's strongly connected components, as well as\nmultiple algorithms simultaneously. The number of parameters in the networks\ndoes not increase with the input graph size, which implies that the networks\ncan simulate the above algorithms for any graph. Despite this property, we show\na limit to simulation in our solution due to finite precision. Finally, we show\na Turing Completeness result with constant width when the extra attention heads\nare utilized.",
      "tldr_zh": "本研究从理论角度探讨循环Transformer网络如何模拟图算法，采用带有额外注意力头的架构来处理关系数据。研究证明，该模型能够通过构造方式模拟单个算法如Dijkstra's shortest path、Breadth-First Search、Depth-First Search和Kosaraju's strongly connected components，以及同时模拟多个算法，且网络参数不随输入图大小增加。尽管存在有限精度限制，但利用额外注意力头，该架构实现了Turing Completeness，具有恒定宽度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "55 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01107v3",
      "published_date": "2024-02-02 02:48:03 UTC",
      "updated_date": "2024-10-01 20:30:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:44:17.441670"
    },
    {
      "arxiv_id": "2402.01789v2",
      "title": "The Political Preferences of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "David Rozado"
      ],
      "abstract": "I report here a comprehensive analysis about the political preferences\nembedded in Large Language Models (LLMs). Namely, I administer 11 political\norientation tests, designed to identify the political preferences of the test\ntaker, to 24 state-of-the-art conversational LLMs, both closed and open source.\nWhen probed with questions/statements with political connotations, most\nconversational LLMs tend to generate responses that are diagnosed by most\npolitical test instruments as manifesting preferences for left-of-center\nviewpoints. This does not appear to be the case for five additional base (i.e.\nfoundation) models upon which LLMs optimized for conversation with humans are\nbuilt. However, the weak performance of the base models at coherently answering\nthe tests' questions makes this subset of results inconclusive. Finally, I\ndemonstrate that LLMs can be steered towards specific locations in the\npolitical spectrum through Supervised Fine-Tuning (SFT) with only modest\namounts of politically aligned data, suggesting SFT's potential to embed\npolitical orientation in LLMs. With LLMs beginning to partially displace\ntraditional information sources like search engines and Wikipedia, the societal\nimplications of political biases embedded in LLMs are substantial.",
      "tldr_zh": "本研究对24个最先进的对话式Large Language Models (LLMs)进行了11个政治倾向测试，发现大多数LLMs在回答带有政治含义的问题时，倾向于表现为左翼观点。基础模型（base models）则未显示类似偏好，但由于其在回答问题时的连贯性较差，该结果不确定。通过Supervised Fine-Tuning (SFT)使用少量政治相关数据，作者证明可以轻松引导LLMs朝特定政治光谱方向发展。这种嵌入的政治偏见可能对社会产生重大影响，因为LLMs正逐步取代传统信息来源，如搜索引擎和Wikipedia。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01789v2",
      "published_date": "2024-02-02 02:43:10 UTC",
      "updated_date": "2024-06-02 04:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:44:31.154630"
    },
    {
      "arxiv_id": "2402.01788v2",
      "title": "LitLLM: A Toolkit for Scientific Literature Review",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Agarwal",
        "Gaurav Sahu",
        "Abhay Puri",
        "Issam H. Laradji",
        "Krishnamurthy DJ Dvijotham",
        "Jason Stanley",
        "Laurent Charlin",
        "Christopher Pal"
      ],
      "abstract": "Conducting literature reviews for scientific papers is essential for\nunderstanding research, its limitations, and building on existing work. It is a\ntedious task which makes an automatic literature review generator appealing.\nUnfortunately, many existing works that generate such reviews using Large\nLanguage Models (LLMs) have significant limitations. They tend to\nhallucinate-generate non-factual information-and ignore the latest research\nthey have not been trained on. To address these limitations, we propose a\ntoolkit that operates on Retrieval Augmented Generation (RAG) principles,\nspecialized prompting and instructing techniques with the help of LLMs. Our\nsystem first initiates a web search to retrieve relevant papers by summarizing\nuser-provided abstracts into keywords using an off-the-shelf LLM. Authors can\nenhance the search by supplementing it with relevant papers or keywords,\ncontributing to a tailored retrieval process. Second, the system re-ranks the\nretrieved papers based on the user-provided abstract. Finally, the related work\nsection is generated based on the re-ranked results and the abstract. There is\na substantial reduction in time and effort for literature review compared to\ntraditional methods, establishing our toolkit as an efficient alternative. Our\nproject page including the demo and toolkit can be accessed here:\nhttps://litllm.github.io",
      "tldr_zh": "这篇论文介绍了 LitLLM，一种基于 Retrieval Augmented Generation (RAG) 原则和大型语言模型 (LLMs) 的工具包，旨在自动化科学文献综述过程。工具包通过使用专门的提示技术，先将用户提供的摘要转化为关键词进行网络搜索，然后允许用户补充相关论文或关键词以优化检索，并基于重新排序的结果生成相关工作部分。与传统方法相比，LitLLM 大大减少了文献综述的时间和精力，提供了一个高效的替代方案。项目页面包括演示和工具包，可访问 https://litllm.github.io。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01788v2",
      "published_date": "2024-02-02 02:41:28 UTC",
      "updated_date": "2025-03-21 14:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:44:41.616701"
    },
    {
      "arxiv_id": "2402.01103v3",
      "title": "Compositional Generative Modeling: A Single Model is Not All You Need",
      "title_zh": "翻译失败",
      "authors": [
        "Yilun Du",
        "Leslie Kaelbling"
      ],
      "abstract": "Large monolithic generative models trained on massive amounts of data have\nbecome an increasingly dominant approach in AI research. In this paper, we\nargue that we should instead construct large generative systems by composing\nsmaller generative models together. We show how such a compositional generative\napproach enables us to learn distributions in a more data-efficient manner,\nenabling generalization to parts of the data distribution unseen at training\ntime. We further show how this enables us to program and construct new\ngenerative models for tasks completely unseen at training. Finally, we show\nthat in many cases, we can discover separate compositional components from\ndata.",
      "tldr_zh": "本论文主张，构建大型生成系统应通过组合较小的生成模型，而非依赖单一大型模型，这种方法称为 compositional generative modeling，能更高效地学习数据分布，实现对训练时未见部分的泛化。该方法还允许编程和构建新模型，用于处理完全未见任务，并在许多情况下从数据中自动发现独立的组合组件。总体上，这为提高生成模型的灵活性和数据效率提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024 (Position Track)",
      "pdf_url": "http://arxiv.org/pdf/2402.01103v3",
      "published_date": "2024-02-02 02:40:51 UTC",
      "updated_date": "2024-06-03 23:30:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:44:53.175010"
    },
    {
      "arxiv_id": "2402.05941v1",
      "title": "Character-based Outfit Generation with Vision-augmented Style Extraction via LLMs",
      "title_zh": "基于角色的服装生成：通过视觉",
      "authors": [
        "Najmeh Forouzandehmehr",
        "Yijie Cao",
        "Nikhil Thakurdesai",
        "Ramin Giahi",
        "Luyi Ma",
        "Nima Farrokhsiar",
        "Jianpeng Xu",
        "Evren Korpeoglu",
        "Kannan Achan"
      ],
      "abstract": "The outfit generation problem involves recommending a complete outfit to a\nuser based on their interests. Existing approaches focus on recommending items\nbased on anchor items or specific query styles but do not consider customer\ninterests in famous characters from movie, social media, etc. In this paper, we\ndefine a new Character-based Outfit Generation (COG) problem, designed to\naccurately interpret character information and generate complete outfit sets\naccording to customer specifications such as age and gender. To tackle this\nproblem, we propose a novel framework LVA-COG that leverages Large Language\nModels (LLMs) to extract insights from customer interests (e.g., character\ninformation) and employ prompt engineering techniques for accurate\nunderstanding of customer preferences. Additionally, we incorporate\ntext-to-image models to enhance the visual understanding and generation\n(factual or counterfactual) of cohesive outfits. Our framework integrates LLMs\nwith text-to-image models and improves the customer's approach to fashion by\ngenerating personalized recommendations. With experiments and case studies, we\ndemonstrate the effectiveness of our solution from multiple dimensions.",
      "tldr_zh": "该论文定义了新的Character-based Outfit Generation (COG)问题，旨在基于用户对电影或社交媒体著名角色的兴趣，结合年龄和性别等因素生成完整的个性化服装套装。研究提出LVA-COG框架，利用Large Language Models (LLMs)和prompt engineering技术提取用户偏好，并整合text-to-image模型增强视觉理解和连贯服装生成。实验和案例研究从多个维度证明了该框架的有效性，提高了服装推荐的准确性和个性化水平。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "7 pages, 4 figures, IEEE Big Data 2023 3rd Workshop on Multimodal AI\n  (MMAI 2023), IEEE BigData 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.05941v1",
      "published_date": "2024-02-02 02:11:31 UTC",
      "updated_date": "2024-02-02 02:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:45:07.099751"
    },
    {
      "arxiv_id": "2402.01096v1",
      "title": "Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqi Wei",
        "Ling Liu"
      ],
      "abstract": "Emerging Distributed AI systems are revolutionizing big data computing and\ndata processing capabilities with growing economic and societal impact.\nHowever, recent studies have identified new attack surfaces and risks caused by\nsecurity, privacy, and fairness issues in AI systems. In this paper, we review\nrepresentative techniques, algorithms, and theoretical foundations for\ntrustworthy distributed AI through robustness guarantee, privacy protection,\nand fairness awareness in distributed learning. We first provide a brief\noverview of alternative architectures for distributed learning, discuss\ninherent vulnerabilities for security, privacy, and fairness of AI algorithms\nin distributed learning, and analyze why these problems are present in\ndistributed learning regardless of specific architectures. Then we provide a\nunique taxonomy of countermeasures for trustworthy distributed AI, covering (1)\nrobustness to evasion attacks and irregular queries at inference, and\nrobustness to poisoning attacks, Byzantine attacks, and irregular data\ndistribution during training; (2) privacy protection during distributed\nlearning and model inference at deployment; and (3) AI fairness and governance\nwith respect to both data and models. We conclude with a discussion on open\nchallenges and future research directions toward trustworthy distributed AI,\nsuch as the need for trustworthy AI policy guidelines, the AI\nresponsibility-utility co-design, and incentives and compliance.",
      "tldr_zh": "这篇论文回顾了可信分布式 AI 系统在鲁棒性、隐私保护和公平性方面的技术、算法及理论基础，旨在解决分布式学习中存在的安全风险和漏洞。作者首先概述了分布式学习架构及其固有问题，如对逃避攻击、投毒攻击、Byzantine attacks 和不规则数据分布的易感性，然后提出一个独特分类，包括提升鲁棒性、实现隐私保护以及确保AI公平性和治理。论文最后讨论了开放挑战和未来方向，例如制定可信AI政策指导、责任与实用性共同设计，以及激励和合规机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Manuscript accepted to ACM Computing Surveys",
      "pdf_url": "http://arxiv.org/pdf/2402.01096v1",
      "published_date": "2024-02-02 01:58:58 UTC",
      "updated_date": "2024-02-02 01:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:45:17.702589"
    },
    {
      "arxiv_id": "2402.01095v1",
      "title": "How many views does your deep neural network use for prediction?",
      "title_zh": "翻译失败",
      "authors": [
        "Keisuke Kawano",
        "Takuro Kutsuna",
        "Keisuke Sano"
      ],
      "abstract": "The generalization ability of Deep Neural Networks (DNNs) is still not fully\nunderstood, despite numerous theoretical and empirical analyses. Recently,\nAllen-Zhu & Li (2023) introduced the concept of multi-views to explain the\ngeneralization ability of DNNs, but their main target is ensemble or distilled\nmodels, and no method for estimating multi-views used in a prediction of a\nspecific input is discussed. In this paper, we propose Minimal Sufficient Views\n(MSVs), which is similar to multi-views but can be efficiently computed for\nreal images. MSVs is a set of minimal and distinct features in an input, each\nof which preserves a model's prediction for the input. We empirically show that\nthere is a clear relationship between the number of MSVs and prediction\naccuracy across models, including convolutional and transformer models,\nsuggesting that a multi-view like perspective is also important for\nunderstanding the generalization ability of (non-ensemble or non-distilled)\nDNNs.",
      "tldr_zh": "该研究探讨了 Deep Neural Networks (DNNs) 的泛化能力，针对现有 multi-views 概念的局限性，提出 Minimal Sufficient Views (MSVs) 方法，该方法通过提取输入图像中最小且独特的特征集合来高效计算并保留模型的预测。实验结果显示，MSVs 的数量与预测准确率之间存在显著相关性，适用于卷积和 Transformer 模型。总之，这扩展了 multi-views 视角，有助于更好地理解非集成或非蒸馏 DNNs 的泛化机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01095v1",
      "published_date": "2024-02-02 01:58:16 UTC",
      "updated_date": "2024-02-02 01:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:45:30.662971"
    },
    {
      "arxiv_id": "2402.01077v2",
      "title": "Recent Advances in Predictive Modeling with Electronic Health Records",
      "title_zh": "电子健康记录在预测建模中的最新进展",
      "authors": [
        "Jiaqi Wang",
        "Junyu Luo",
        "Muchao Ye",
        "Xiaochen Wang",
        "Yuan Zhong",
        "Aofei Chang",
        "Guanjie Huang",
        "Ziyi Yin",
        "Cao Xiao",
        "Jimeng Sun",
        "Fenglong Ma"
      ],
      "abstract": "The development of electronic health records (EHR) systems has enabled the\ncollection of a vast amount of digitized patient data. However, utilizing EHR\ndata for predictive modeling presents several challenges due to its unique\ncharacteristics. With the advancements in machine learning techniques, deep\nlearning has demonstrated its superiority in various applications, including\nhealthcare. This survey systematically reviews recent advances in deep\nlearning-based predictive models using EHR data. Specifically, we begin by\nintroducing the background of EHR data and providing a mathematical definition\nof the predictive modeling task. We then categorize and summarize predictive\ndeep models from multiple perspectives. Furthermore, we present benchmarks and\ntoolkits relevant to predictive modeling in healthcare. Finally, we conclude\nthis survey by discussing open challenges and suggesting promising directions\nfor future research.",
      "tldr_zh": "这篇综述论文探讨了使用电子健康记录 (EHR) 数据进行预测建模的最新进展，强调了深度学习在医疗领域的优越性。论文首先介绍了 EHR 数据的背景及其数学定义，然后从多个视角分类总结了基于深度学习的预测模型，并呈现了相关的基准和工具包。最终，它讨论了当前面临的开放挑战，并提出未来研究的有前景方向，以推动 EHR 在预测建模中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by IJCAI 24 Survey Track",
      "pdf_url": "http://arxiv.org/pdf/2402.01077v2",
      "published_date": "2024-02-02 00:31:01 UTC",
      "updated_date": "2024-08-13 05:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:45:41.661109"
    },
    {
      "arxiv_id": "2405.01540v1",
      "title": "Universal Imitation Games",
      "title_zh": "通用模仿游戏",
      "authors": [
        "Sridhar Mahadevan"
      ],
      "abstract": "Alan Turing proposed in 1950 a framework called an imitation game to decide\nif a machine could think. Using mathematics developed largely after Turing --\ncategory theory -- we analyze a broader class of universal imitation games\n(UIGs), which includes static, dynamic, and evolutionary games. In static\ngames, the participants are in a steady state. In dynamic UIGs, \"learner\"\nparticipants are trying to imitate \"teacher\" participants over the long run. In\nevolutionary UIGs, the participants are competing against each other in an\nevolutionary game, and participants can go extinct and be replaced by others\nwith higher fitness. We use the framework of category theory -- in particular,\ntwo influential results by Yoneda -- to characterize each type of imitation\ngame. Universal properties in categories are defined by initial and final\nobjects. We characterize dynamic UIGs where participants are learning by\ninductive inference as initial algebras over well-founded sets, and contrast\nthem with participants learning by conductive inference over the final\ncoalgebra of non-well-founded sets. We briefly discuss the extension of our\ncategorical framework for UIGs to imitation games on quantum computers.",
      "tldr_zh": "这篇论文扩展了 Alan Turing 提出的 imitation game 框架，使用 category theory 分析了更广泛的 universal imitation games (UIGs)，包括静态、动态和进化类型。作者运用 Yoneda 的结果表征这些游戏，其中动态 UIGs 通过 inductive inference 建模为 initial algebras，而 conductive inference 与 final coalgebra 相关联，以区分学习过程。最终，该框架为理解机器智能提供了数学基础，并简要探讨了扩展到 quantum computers 的可能性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "98 pages. arXiv admin note: substantial text overlap with\n  arXiv:2402.18732",
      "pdf_url": "http://arxiv.org/pdf/2405.01540v1",
      "published_date": "2024-02-02 00:07:15 UTC",
      "updated_date": "2024-02-02 00:07:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:45:54.770691"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 123,
  "processed_papers_count": 123,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T02:46:41.695024"
}