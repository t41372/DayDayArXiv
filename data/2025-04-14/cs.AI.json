{
  "date": "2025-04-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-14 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的推理优化、多模态生成与安全对齐、机器人学习以及联邦学习等领域，重点包括大型语言模型（如 DeepSeek-R1）的深度推理技术、hallucination 检测方法，以及知名学者如 John E. Sader 参与的物理应用论文；令人印象深刻的是，DeepSeek-R1 的优化和 LLM 安全研究展示了高效推理与鲁棒性的新进展。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论重要或话题度高的文章（如 LLM 推理、安全和多模态领域），并将相关论文归类讨论；其他较次要的论文（如特定实验或小众应用）将快速掠过，仅列出标题和核心要点。\n\n### LLM 推理与优化\n- **DeepSeek-R1 的优化和应用**：论文如 \"RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning Capability\" (英文原题) 提出了一种安全对齐方法，提升了 DeepSeek-R1 的推理能力，同时保持了其在数学和编码任务上的性能；另一篇 \"Efficient Multi-Task Modeling through Automated Fusion of Trained Models\" (英文原题) 探索了多任务模型融合，贡献了高效的知识共享机制。\n- **推理模型的评估**：论文 \"Who is More Bayesian: Humans or ChatGPT?\" (英文原题) 比较了人类和 ChatGPT 在贝叶斯推理中的表现，发现最新 ChatGPT 版本在决策任务中超越人类；\"Weight Ensembling Improves Reasoning in Language Models\" (英文原题) 通过权重集成提升了模型的推理准确性，显著减少了错误传播。\n- **其他推理相关**：\"Weight-of-Thought Reasoning: Exploring Neural Network Weights for Enhanced LLM Reasoning\" (英文原题) 通过分析神经网络权重改进了 LLM 的推理结构，适用于复杂任务；\"LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models\" (英文原题) 构建了科学方程发现基准，突出了 LLM 在推理中的局限性。\n\n这些论文强调了 LLM 推理的效率和鲁棒性，DeepSeek-R1 的工作特别值得关注，因为它在保持性能的同时提升了安全。\n\n### LLM 安全与对齐\n- **安全机制创新**：\"LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models\" (英文原题) 研究了 LLM 在说服任务中的风险，贡献了检测不道德策略的方法；\"The Jailbreak Tax: How Useful are Your Jailbreak Outputs?\" (英文原题) 评估了越狱攻击的实际效用，发现攻击输出往往降低模型准确性。\n- **多模态安全**：\"Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks\" (英文原题) 审视了多模态模型的公平性和透明度，强调了偏置缓解策略；\"LLM-Driven NPCs: Cross-Platform Dialogue System for Games and Social Platforms\" (英文原题) 探讨了 LLM 在对话系统中的安全应用。\n- **快速掠过**：\"CleanMAP: Distilling Multimodal LLMs for Confidence-Driven Crowdsourced HD Map Updates\" (英文原题) 通过多模态蒸馏提升了地图更新置信度；\"LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks\" (英文原题) 揭示了模型遗忘机制的核心集效应。\n\n这些工作突出了 LLM 安全的重要性，尤其在多模态环境中，hallucination 检测和偏置控制是关键发现。\n\n### 多模态生成与处理\n- **视频和图像生成**：\"Hearing Anywhere in Any Environment\" (英文原题) 提出 xRIR 框架，实现跨环境的音频重建，显著提升了多模态沉浸感；\"Efficient Brain Tumor Segmentation Using a Dual-Decoder 3D U-Net with Attention Gates (DDUNet)\" (英文原题) 使用注意力门控的双解码器网络提高了脑肿瘤分割精度。\n- **其他生成模型**：\"Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling\" (英文原题) 统一了生成模型框架，提升了多模态任务的鲁棒性；\"Visual anemometry of natural vegetation from their leaf motion\" (英文原题) 由知名学者 John E. Sader 参与，利用视觉分析实现了风速测量，贡献了创新的物理应用方法。\n\n这些论文在多模态领域表现出色，视频生成和医疗图像处理的应用潜力较大。\n\n### 机器人与联邦学习\n- **机器人学习**：\"Toward Aligning Human and Robot Actions via Multi-Modal Demonstration Learning\" (英文原题) 通过多模态演示实现了人机动作对齐；\"EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical Challenge in Multi-Robot Control\" (英文原题) 提出分层框架，提升了多机器人控制的鲁棒性。\n- **联邦学习**：\"FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous Environments\" (英文原题) 解决了联邦学习中的模态缺失问题；快速掠过：\"Efficient Multi-Task Modeling through Automated Fusion of Trained Models\" (英文原题) 在联邦环境中实现了任务融合。\n- **快速掠过其他**：如 \"Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots\" (英文原题) 优化了机器人地图压缩；\"Towards Quantifying Commonsense Reasoning with Mechanistic Insights\" (英文原题) 探讨了常识推理机制。\n\n机器人论文侧重实际应用，联邦学习部分则强调分布式协作，但整体影响较前述领域小。\n\n总体而言，今天的论文突出了 AI 推理、安全和多模态处理的创新，但许多工作仍需在实际部署中验证。明日见！",
  "papers": [
    {
      "arxiv_id": "2504.10766v1",
      "title": "How Instruction and Reasoning Data shape Post-Training: Data Quality through the Lens of Layer-wise Gradients",
      "title_zh": "指令和推理数据如何塑造后训练：通过",
      "authors": [
        "Ming Li",
        "Yanhong Li",
        "Ziyue Li",
        "Tianyi Zhou"
      ],
      "abstract": "As the post-training of large language models (LLMs) advances from\ninstruction-following to complex reasoning tasks, understanding how different\ndata affect finetuning dynamics remains largely unexplored. In this paper, we\npresent a spectral analysis of layer-wise gradients induced by low/high-quality\ninstruction and reasoning data for LLM post-training. Our analysis reveals that\nwidely-studied metrics for data evaluation, e.g., IFD, InsTag, Difficulty, and\nReward, can be explained and unified by spectral properties computed from\ngradients' singular value decomposition (SVD). Specifically, higher-quality\ndata are usually associated with lower nuclear norms and higher effective\nranks. Notably, effective rank exhibits better robustness and resolution than\nnuclear norm in capturing subtle quality differences. For example, reasoning\ndata achieves substantially higher effective ranks than instruction data,\nimplying richer gradient structures on more complex tasks. Our experiments also\nhighlight that models within the same family share similar gradient patterns\nregardless of their sizes, whereas different model families diverge\nsignificantly. Providing a unified view on the effects of data quality across\ninstruction and reasoning data, this work illuminates the interplay between\ndata quality and training stability, shedding novel insights into developing\nbetter data exploration strategies for post-training.",
      "tldr_zh": "本文通过层级梯度的谱分析，探讨了指令和推理数据对大型语言模型（LLMs）后训练的影响，揭示了数据质量指标（如IFD、InsTag、Difficulty和Reward）可通过梯度的奇异值分解（SVD）统一解释。研究发现，高质量数据通常具有较低核范数和较高有效秩，其中有效秩更能捕捉微妙差异，例如推理数据比指令数据显示出更丰富的梯度结构。实验结果表明，同家族模型无论大小梯度模式相似，而不同家族模型差异显著。该工作为理解数据质量与训练稳定性间的互动提供了新见解，并有助于优化后训练数据策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10766v1",
      "published_date": "2025-04-14 23:53:47 UTC",
      "updated_date": "2025-04-14 23:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:36:33.787268"
    },
    {
      "arxiv_id": "2504.10753v1",
      "title": "Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning",
      "title_zh": "通过贝叶斯深度集成学习实现的认识论不确定性感知推荐系统",
      "authors": [
        "Radin Cheraghi",
        "Amir Mohammad Mahfoozi",
        "Sepehr Zolfaghari",
        "Mohammadshayan Shabani",
        "Maryam Ramezani",
        "Hamid R. Rabiee"
      ],
      "abstract": "Recommending items to users has long been a fundamental task, and studies\nhave tried to improve it ever since. Most well-known models commonly employ\nrepresentation learning to map users and items into a unified embedding space\nfor matching assessment. These approaches have primary limitations, especially\nwhen dealing with explicit feedback and sparse data contexts. Two primary\nlimitations are their proneness to overfitting and failure to incorporate\nepistemic uncertainty in predictions. To address these problems, we propose a\nnovel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To\nimprove model generalization and quality, we utilize Bayesian Neural Networks,\nwhich incorporate uncertainty within their weight parameters. In addition, we\nintroduce a new interpretable non-linear matching approach for the user and\nitem embeddings, leveraging the advantages of the attention mechanism.\nFurthermore, we endorse the implementation of an ensemble-based supermodel to\ngenerate more robust and reliable predictions, resulting in a more complete\nmodel. Empirical evaluation through extensive experiments and ablation studies\nacross a range of publicly accessible real-world datasets with differing\nsparsity characteristics confirms our proposed method's effectiveness and the\nimportance of its components.",
      "tldr_zh": "该论文针对推荐系统的易过拟合和忽略认识不确定性（epistemic uncertainty）问题，提出了一种新型方法BDECF（Bayesian Deep Ensemble Collaborative Filtering）。BDECF利用Bayesian Neural Networks处理权重参数的不确定性，引入基于attention mechanism的可解释非线性匹配方法，并采用ensemble-based supermodel生成更鲁棒的预测。实验结果通过广泛的真实世界数据集验证了该方法的有效性，尤其在稀疏数据场景下显著提升了模型泛化和性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10753v1",
      "published_date": "2025-04-14 23:04:35 UTC",
      "updated_date": "2025-04-14 23:04:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:36:45.920517"
    },
    {
      "arxiv_id": "2504.10751v1",
      "title": "Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel T. Larsson",
        "Dipankar Maity"
      ],
      "abstract": "In this paper, we develop a systematic framework for the time-sequential\ncompression of dynamic probabilistic occupancy grids. Our approach leverages\nideas from signal compression theory to formulate an optimization problem that\nsearches for a multi-resolution hierarchical encoder that balances the quality\nof the compressed map (distortion) with its description size, the latter of\nwhich relates to the bandwidth required to reliably transmit the map to other\nagents or to store map estimates in on-board memory. The resulting optimization\nproblem allows for multi-resolution map compressions to be obtained that\nsatisfy available communication or memory resources, and does not require\nknowledge of the occupancy map dynamics. We develop an algorithm to solve our\nproblem, and demonstrate the utility of the proposed framework in simulation on\nboth static (i.e., non-time varying) and dynamic (time-varying) occupancy maps.",
      "tldr_zh": "这篇论文提出了一种系统框架，用于动态概率占用网格的时间序列压缩，针对移动机器人在时间变化环境中的应用。该框架借鉴信号压缩理论，制定优化问题以寻找多分辨率层次编码器，平衡压缩地图的失真（distortion）和描述大小，从而适应可用通信带宽或内存资源，而无需事先知道占用地图动态。实验结果显示，该算法在模拟环境中对静态和动态占用地图均表现出有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10751v1",
      "published_date": "2025-04-14 22:54:29 UTC",
      "updated_date": "2025-04-14 22:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:36:58.627024"
    },
    {
      "arxiv_id": "2504.13200v1",
      "title": "Efficient Brain Tumor Segmentation Using a Dual-Decoder 3D U-Net with Attention Gates (DDUNet)",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Mahdi Danesh Pajouh"
      ],
      "abstract": "Cancer remains one of the leading causes of mortality worldwide, and among\nits many forms, brain tumors are particularly notorious due to their aggressive\nnature and the critical challenges involved in early diagnosis. Recent advances\nin artificial intelligence have shown great promise in assisting medical\nprofessionals with precise tumor segmentation, a key step in timely diagnosis\nand treatment planning. However, many state-of-the-art segmentation methods\nrequire extensive computational resources and prolonged training times,\nlimiting their practical application in resource-constrained settings. In this\nwork, we present a novel dual-decoder U-Net architecture enhanced with\nattention-gated skip connections, designed specifically for brain tumor\nsegmentation from MRI scans. Our approach balances efficiency and accuracy by\nachieving competitive segmentation performance while significantly reducing\ntraining demands. Evaluated on the BraTS 2020 dataset, the proposed model\nachieved Dice scores of 85.06% for Whole Tumor (WT), 80.61% for Tumor Core\n(TC), and 71.26% for Enhancing Tumor (ET) in only 50 epochs, surpassing several\ncommonly used U-Net variants. Our model demonstrates that high-quality brain\ntumor segmentation is attainable even under limited computational resources,\nthereby offering a viable solution for researchers and clinicians operating\nwith modest hardware. This resource-efficient model has the potential to\nimprove early detection and diagnosis of brain tumors, ultimately contributing\nto better patient outcomes",
      "tldr_zh": "本研究提出了一种高效的脑肿瘤分割模型DDUNet，该模型基于双解码器3D U-Net架构，并融入注意力门控跳跃连接，用于从MRI扫描中精确识别肿瘤，从而解决现有方法计算资源需求高的难题。\nDDUNet在BraTS 2020数据集上实现了出色的性能，仅需50个epoch即达到Whole Tumor (WT)的Dice scores 85.06%、Tumor Core (TC)的80.61%和Enhancing Tumor (ET)的71.26%，超过了传统U-Net变体。\n这一方法证明了在有限计算资源下也能实现高质量分割，有助于提升脑肿瘤的早期诊断和治疗规划，改善患者预后。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13200v1",
      "published_date": "2025-04-14 22:45:33 UTC",
      "updated_date": "2025-04-14 22:45:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:37:10.144470"
    },
    {
      "arxiv_id": "2504.10746v1",
      "title": "Hearing Anywhere in Any Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Xiulong Liu",
        "Anurag Kumar",
        "Paul Calamia",
        "Sebastia V. Amengual",
        "Calvin Murdock",
        "Ishwarya Ananthabhotla",
        "Philip Robinson",
        "Eli Shlizerman",
        "Vamsi Krishna Ithapu",
        "Ruohan Gao"
      ],
      "abstract": "In mixed reality applications, a realistic acoustic experience in spatial\nenvironments is as crucial as the visual experience for achieving true\nimmersion. Despite recent advances in neural approaches for Room Impulse\nResponse (RIR) estimation, most existing methods are limited to the single\nenvironment on which they are trained, lacking the ability to generalize to new\nrooms with different geometries and surface materials. We aim to develop a\nunified model capable of reconstructing the spatial acoustic experience of any\nenvironment with minimum additional measurements. To this end, we present xRIR,\na framework for cross-room RIR prediction. The core of our generalizable\napproach lies in combining a geometric feature extractor, which captures\nspatial context from panorama depth images, with a RIR encoder that extracts\ndetailed acoustic features from only a few reference RIR samples. To evaluate\nour method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity\nsimulation of over 300,000 RIRs from 260 rooms. Experiments show that our\nmethod strongly outperforms a series of baselines. Furthermore, we successfully\nperform sim-to-real transfer by evaluating our model on four real-world\nenvironments, demonstrating the generalizability of our approach and the\nrealism of our dataset.",
      "tldr_zh": "该论文针对混合现实(Mixed Reality)应用中空间声学体验的挑战，提出xRIR框架，以实现对任何环境的Room Impulse Response (RIR)重建，仅需最少额外测量。该框架结合几何特征提取器（从全景深度图像捕获空间上下文）和RIR编码器（从少数参考RIR样本提取声学特征），使模型具备跨房间泛化能力。为评估方法，作者引入了ACOUSTICROOMS数据集，包含超过300,000个高保真RIR模拟数据来自260个房间。实验结果显示，xRIR显著优于基线模型，并在四个真实世界环境中成功实现sim-to-real转移，证明了其泛化性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.10746v1",
      "published_date": "2025-04-14 22:37:52 UTC",
      "updated_date": "2025-04-14 22:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:37:21.920096"
    },
    {
      "arxiv_id": "2504.10738v1",
      "title": "CleanMAP: Distilling Multimodal LLMs for Confidence-Driven Crowdsourced HD Map Updates",
      "title_zh": "翻译失败",
      "authors": [
        "Ankit Kumar Shaw",
        "Kun Jiang",
        "Tuopu Wen",
        "Chandan Kumar Sah",
        "Yining Shi",
        "Mengmeng Yang",
        "Diange Yang",
        "Xiaoli Lian"
      ],
      "abstract": "The rapid growth of intelligent connected vehicles (ICVs) and integrated\nvehicle-road-cloud systems has increased the demand for accurate, real-time HD\nmap updates. However, ensuring map reliability remains challenging due to\ninconsistencies in crowdsourced data, which suffer from motion blur, lighting\nvariations, adverse weather, and lane marking degradation. This paper\nintroduces CleanMAP, a Multimodal Large Language Model (MLLM)-based\ndistillation framework designed to filter and refine crowdsourced data for\nhigh-confidence HD map updates. CleanMAP leverages an MLLM-driven lane\nvisibility scoring model that systematically quantifies key visual parameters,\nassigning confidence scores (0-10) based on their impact on lane detection. A\nnovel dynamic piecewise confidence-scoring function adapts scores based on lane\nvisibility, ensuring strong alignment with human evaluations while effectively\nfiltering unreliable data. To further optimize map accuracy, a\nconfidence-driven local map fusion strategy ranks and selects the top-k\nhighest-scoring local maps within an optimal confidence range (best score minus\n10%), striking a balance between data quality and quantity. Experimental\nevaluations on a real-world autonomous vehicle dataset validate CleanMAP's\neffectiveness, demonstrating that fusing the top three local maps achieves the\nlowest mean map update error of 0.28m, outperforming the baseline (0.37m) and\nmeeting stringent accuracy thresholds (<= 0.32m). Further validation with\nreal-vehicle data confirms 84.88% alignment with human evaluators, reinforcing\nthe model's robustness and reliability. This work establishes CleanMAP as a\nscalable and deployable solution for crowdsourced HD map updates, ensuring more\nprecise and reliable autonomous navigation. The code will be available at\nhttps://Ankit-Zefan.github.io/CleanMap/",
      "tldr_zh": "本研究提出CleanMAP，一种基于Multimodal LLMs的蒸馏框架，用于驱动置信度评估的众包HD地图更新，以解决众包数据中的不一致性问题，如运动模糊、光照变化和恶劣天气。框架包括一个MLLM驱动的车道可见性评分模型，通过量化视觉参数并应用动态分段置信度函数（0-10分数），来过滤不可靠数据，并采用置信度驱动的局部地图融合策略，选择top-k高分地图以平衡质量和数量。实验在真实自动驾驶数据集上验证，融合top three局部地图的平均更新错误降至0.28m，比基线（0.37m）改善显著，并与人类评估一致性达84.88%，证明CleanMAP可作为可扩展的解决方案提升自主导航的精确性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO",
        "I.2.9; I.2.7; I.2.10; I.5.5; I.5.4; I.2.11"
      ],
      "primary_category": "cs.CV",
      "comment": "Kun Jiang, Mengmeng Yang and Diange Yang are Corresponding Author.\n  The main paper and supplementary material are both included here, total 23\n  pages (main paper is 10 pages and supplementary material is 13 pages), total\n  17 figures (6 figures in main paper and 11 figures in supplementary\n  material), this paper is Accepted to CVPR WDFM-AD Workshop 2025, The code\n  will be available at https://Ankit-Zefan.github.io/CleanMap/",
      "pdf_url": "http://arxiv.org/pdf/2504.10738v1",
      "published_date": "2025-04-14 22:16:10 UTC",
      "updated_date": "2025-04-14 22:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:37:35.084318"
    },
    {
      "arxiv_id": "2504.10735v2",
      "title": "Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Timur Carstensen",
        "Neeratyoy Mallik",
        "Frank Hutter",
        "Martin Rapp"
      ],
      "abstract": "As model sizes grow, finding efficient and cost-effective hyperparameter\noptimization (HPO) methods becomes increasingly crucial for deep learning\npipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources\nrequired for DL training with lower fidelity estimations, existing fidelity\nsources often fail under lower compute and memory constraints. We propose a\nnovel fidelity source: the number of layers that are trained or frozen during\ntraining. For deep networks, this approach offers significant compute and\nmemory savings while preserving rank correlations between hyperparameters at\nlow fidelities compared to full model training. We demonstrate this in our\nempirical evaluation across ResNets and Transformers and additionally analyze\nthe utility of frozen layers as a fidelity in using GPU resources as a fidelity\nin HPO, and for a combined MF-HPO with other fidelity sources. This\ncontribution opens new applications for MF-HPO with hardware resources as a\nfidelity and creates opportunities for improved algorithms navigating joint\nfidelity spaces.",
      "tldr_zh": "该论文提出了一种内存高效的多保真度超参数优化（MF-HPO）方法，名为“Frozen Layers”，通过训练或冻结网络层数作为新保真度来源，来显著减少深度学习模型的计算和内存消耗，同时保持低保真度下的超参数排名相关性。相比传统方法，该方法在ResNets和Transformers上进行了实证评估，展示了其在GPU资源利用方面的优势，并探讨了与其他保真度来源结合的可能性。总体而言，这为硬件资源作为保真度的MF-HPO应用提供了新机遇，提升了超参数优化的算法效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10735v2",
      "published_date": "2025-04-14 22:06:24 UTC",
      "updated_date": "2025-04-17 12:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:37:46.489079"
    },
    {
      "arxiv_id": "2504.11493v1",
      "title": "Toward Aligning Human and Robot Actions via Multi-Modal Demonstration Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Azizul Zahid",
        "Jie Fan",
        "Farong Wang",
        "Ashton Dy",
        "Sai Swaminathan",
        "Fei Liu"
      ],
      "abstract": "Understanding action correspondence between humans and robots is essential\nfor evaluating alignment in decision-making, particularly in human-robot\ncollaboration and imitation learning within unstructured environments. We\npropose a multimodal demonstration learning framework that explicitly models\nhuman demonstrations from RGB video with robot demonstrations in voxelized\nRGB-D space. Focusing on the \"pick and place\" task from the RH20T dataset, we\nutilize data from 5 users across 10 diverse scenes. Our approach combines\nResNet-based visual encoding for human intention modeling and a Perceiver\nTransformer for voxel-based robot action prediction. After 2000 training\nepochs, the human model reaches 71.67% accuracy, and the robot model achieves\n71.8% accuracy, demonstrating the framework's potential for aligning complex,\nmultimodal human and robot behaviors in manipulation tasks.",
      "tldr_zh": "这篇论文提出了一种多模态演示学习框架，旨在对齐人类和机器人在非结构化环境中的动作对应性，以提升人类-机器人协作和模仿学习。框架通过ResNet-based视觉编码处理RGB视频中的人类演示，并使用Perceiver Transformer预测体素化RGB-D空间中的机器人动作，聚焦于RH20T数据集的“pick and place”任务。实验结果显示，在5个用户和10个多样场景下，经过2000训练周期，人类模型准确率达到71.67%，机器人模型达到71.8%，证明了该框架在处理复杂多模态行为方面的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA'25 Workshop: Human-Centered Robot Learning in the Era of Big\n  Data and Large Models",
      "pdf_url": "http://arxiv.org/pdf/2504.11493v1",
      "published_date": "2025-04-14 21:14:51 UTC",
      "updated_date": "2025-04-14 21:14:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:37:57.797993"
    },
    {
      "arxiv_id": "2504.13199v3",
      "title": "Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Saleh",
        "Azadeh Tabatabaei"
      ],
      "abstract": "Objective: This review explores the trustworthiness of multimodal artificial\nintelligence (AI) systems, specifically focusing on vision-language tasks. It\naddresses critical challenges related to fairness, transparency, and ethical\nimplications in these systems, providing a comparative analysis of key tasks\nsuch as Visual Question Answering (VQA), image captioning, and visual dialogue.\nBackground: Multimodal models, particularly vision-language models, enhance\nartificial intelligence (AI) capabilities by integrating visual and textual\ndata, mimicking human learning processes. Despite significant advancements, the\ntrustworthiness of these models remains a crucial concern, particularly as AI\nsystems increasingly confront issues regarding fairness, transparency, and\nethics. Methods: This review examines research conducted from 2017 to 2024\nfocusing on forenamed core vision-language tasks. It employs a comparative\napproach to analyze these tasks through the lens of trustworthiness,\nunderlining fairness, explainability, and ethics. This study synthesizes\nfindings from recent literature to identify trends, challenges, and\nstate-of-the-art solutions. Results: Several key findings were highlighted.\nTransparency: Explainability of vision language tasks is important for user\ntrust. Techniques, such as attention maps and gradient-based methods, have\nsuccessfully addressed this issue. Fairness: Bias mitigation in VQA and visual\ndialogue systems is essential for ensuring unbiased outcomes across diverse\ndemographic groups. Ethical Implications: Addressing biases in multilingual\nmodels and ensuring ethical data handling is critical for the responsible\ndeployment of vision-language systems. Conclusion: This study underscores the\nimportance of integrating fairness, transparency, and ethical considerations in\ndeveloping vision-language models within a unified framework.",
      "tldr_zh": "这篇综述探讨了多模态 AI 在视觉语言任务中的可信度，重点审视 fairness、transparency 和 ethics 问题，包括 Visual Question Answering (VQA)、图像描述和视觉对话等关键任务。通过比较分析 2017-2024 年的相关研究，该文总结了解决这些挑战的趋势和解决方案，如使用注意力图和梯度方法提升透明度、缓解 VQA 中的偏见以确保 fairness，以及处理多语言模型的伦理问题。最终，论文强调在开发视觉语言模型时整合这些因素的重要性，以构建更可靠的 AI 系统。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13199v3",
      "published_date": "2025-04-14 21:10:25 UTC",
      "updated_date": "2025-05-08 05:10:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:38:10.109244"
    },
    {
      "arxiv_id": "2504.10700v1",
      "title": "Optimizing Data Distribution and Kernel Performance for Efficient Training of Chemistry Foundation Models: A Case Study with MACE",
      "title_zh": "优化数据分布和内核性能以高效训练化学基础模型：以 MACE",
      "authors": [
        "Jesun Firoz",
        "Franco Pellegrini",
        "Mario Geiger",
        "Darren Hsu",
        "Jenna A. Bilbrey",
        "Han-Yi Chou",
        "Maximilian Stadler",
        "Markus Hoehnerbach",
        "Tingyu Wang",
        "Dejun Lin",
        "Emine Kucukbenli",
        "Henry W. Sprueill",
        "Ilyes Batatia",
        "Sotiris S. Xantheas",
        "MalSoon Lee",
        "Chris Mundy",
        "Gabor Csanyi",
        "Justin S. Smith",
        "Ponnuswamy Sadayappan",
        "Sutanay Choudhury"
      ],
      "abstract": "Chemistry Foundation Models (CFMs) that leverage Graph Neural Networks (GNNs)\noperating on 3D molecular graph structures are becoming indispensable tools for\ncomputational chemists and materials scientists. These models facilitate the\nunderstanding of matter and the discovery of new molecules and materials. In\ncontrast to GNNs operating on a large homogeneous graphs, GNNs used by CFMs\nprocess a large number of geometric graphs of varying sizes, requiring\ndifferent optimization strategies than those developed for large homogeneous\nGNNs. This paper presents optimizations for two critical phases of CFM\ntraining: data distribution and model training, targeting MACE - a\nstate-of-the-art CFM. We address the challenge of load balancing in data\ndistribution by formulating it as a multi-objective bin packing problem. We\npropose an iterative algorithm that provides a highly effective, fast, and\npractical solution, ensuring efficient data distribution. For the training\nphase, we identify symmetric tensor contraction as the key computational kernel\nin MACE and optimize this kernel to improve the overall performance. Our\ncombined approach of balanced data distribution and kernel optimization\nsignificantly enhances the training process of MACE. Experimental results\ndemonstrate a substantial speedup, reducing per-epoch execution time for\ntraining from 12 to 2 minutes on 740 GPUs with a 2.6M sample dataset.",
      "tldr_zh": "这篇论文针对 Chemistry Foundation Models (CFMs) 的训练优化，以 MACE 为案例研究，专注于处理大量大小不一的 3D 分子图结构的 Graph Neural Networks (GNNs)。他们将数据分布的负载平衡问题建模为多目标 bin packing 问题，并提出一个迭代算法来实现高效的数据分配，同时优化训练中的关键计算内核——对称张量收缩，以提升整体性能。实验结果显示，该方法在 740 个 GPU 和 2.6M 样本数据集上，将每轮训练时间从 12 分钟缩短至 2 分钟，显著提高了 CFMs 的训练效率。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted at The 34th ACM International Symposium on High-Performance\n  Parallel and Distributed Computing (HPDC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.10700v1",
      "published_date": "2025-04-14 20:48:19 UTC",
      "updated_date": "2025-04-14 20:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:38:22.591151"
    },
    {
      "arxiv_id": "2504.10699v1",
      "title": "HyRRT-Connect: Bidirectional Motion Planning for Hybrid Dynamical Systems",
      "title_zh": "HyRRT-Connect：用于混合动力系统的双向运动规划",
      "authors": [
        "Nan Wang",
        "Ricardo G. Sanfelice"
      ],
      "abstract": "This paper proposes a bidirectional rapidly-exploring random trees (RRT)\nalgorithm to solve the motion planning problem for hybrid systems. The proposed\nalgorithm, called HyRRT-Connect, propagates in both forward and backward\ndirections in hybrid time until an overlap between the forward and backward\npropagation results is detected. Then, HyRRT-Connect constructs a motion plan\nthrough the reversal and concatenation of functions defined on hybrid time\ndomains, ensuring that the motion plan satisfies the given hybrid dynamics. To\naddress the potential discontinuity along the flow caused by tolerating some\ndistance between the forward and backward partial motion plans, we reconstruct\nthe backward partial motion plan by a forward-in-hybrid-time simulation from\nthe final state of the forward partial motion plan. effectively eliminating the\ndiscontinuity. The proposed algorithm is applied to an actuated bouncing ball\nsystem and a walking robot example to highlight its computational improvement.",
      "tldr_zh": "本论文提出了一种双向快速扩展随机树 (RRT) 算法，名为 HyRRT-Connect，用于解决混合动态系统 (hybrid systems) 的运动规划问题。该算法在混合时间 (hybrid time) 中同时向前和向后传播，直到检测到重叠，然后通过反转和连接在混合时间域上定义的函数来构建满足混合动态的运动计划。为了消除前向和后向部分计划可能导致的流动不连续性，算法通过从前向计划的最终状态进行前向模拟来重建后向计划。实验应用包括一个带驱动的弹跳球系统和一个步行机器人示例，展示了 HyRRT-Connect 在计算效率上的显著改进。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "59 pages, 9 figures, submitted to IJRR. arXiv admin note: substantial\n  text overlap with arXiv:2403.18413; text overlap with arXiv:2406.01802",
      "pdf_url": "http://arxiv.org/pdf/2504.10699v1",
      "published_date": "2025-04-14 20:46:54 UTC",
      "updated_date": "2025-04-14 20:46:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:38:33.226082"
    },
    {
      "arxiv_id": "2504.10694v1",
      "title": "The Jailbreak Tax: How Useful are Your Jailbreak Outputs?",
      "title_zh": "翻译失败",
      "authors": [
        "Kristina Nikolić",
        "Luze Sun",
        "Jie Zhang",
        "Florian Tramèr"
      ],
      "abstract": "Jailbreak attacks bypass the guardrails of large language models to produce\nharmful outputs. In this paper, we ask whether the model outputs produced by\nexisting jailbreaks are actually useful. For example, when jailbreaking a model\nto give instructions for building a bomb, does the jailbreak yield good\ninstructions? Since the utility of most unsafe answers (e.g., bomb\ninstructions) is hard to evaluate rigorously, we build new jailbreak evaluation\nsets with known ground truth answers, by aligning models to refuse questions\nrelated to benign and easy-to-evaluate topics (e.g., biology or math). Our\nevaluation of eight representative jailbreaks across five utility benchmarks\nreveals a consistent drop in model utility in jailbroken responses, which we\nterm the jailbreak tax. For example, while all jailbreaks we tested bypass\nguardrails in models aligned to refuse to answer math, this comes at the\nexpense of a drop of up to 92% in accuracy. Overall, our work proposes the\njailbreak tax as a new important metric in AI safety, and introduces benchmarks\nto evaluate existing and future jailbreaks. We make the benchmark available at\nhttps://github.com/ethz-spylab/jailbreak-tax",
      "tldr_zh": "这篇论文探讨了jailbreak attacks（越狱攻击）对大语言模型的影响，评估这些攻击是否能产生真正有用的输出，例如在绕过防护机制后是否给出准确的指令。作者构建了新数据集，使用已知ground truth的benign话题（如生物或数学）来评估jailbreak的效用，并测试了八种代表性jailbreak在五个基准上的表现。结果显示，jailbreak会导致模型输出效用显著下降，称为jailbreak tax，例如准确率下降高达92%。总体上，该研究提出jailbreak tax作为AI safety的重要新指标，并公开了基准数据集以供进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10694v1",
      "published_date": "2025-04-14 20:30:41 UTC",
      "updated_date": "2025-04-14 20:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:38:46.478684"
    },
    {
      "arxiv_id": "2504.10685v1",
      "title": "NTIRE 2025 Challenge on Cross-Domain Few-Shot Object Detection: Methods and Results",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqian Fu",
        "Xingyu Qiu",
        "Bin Ren",
        "Yanwei Fu",
        "Radu Timofte",
        "Nicu Sebe",
        "Ming-Hsuan Yang",
        "Luc Van Gool",
        "Kaijin Zhang",
        "Qingpeng Nong",
        "Xiugang Dong",
        "Hong Gao",
        "Xiangsheng Zhou",
        "Jiancheng Pan",
        "Yanxing Liu",
        "Xiao He",
        "Jiahao Li",
        "Yuze Sun",
        "Xiaomeng Huang",
        "Zhenyu Zhang",
        "Ran Ma",
        "Yuhan Liu",
        "Zijian Zhuang",
        "Shuai Yi",
        "Yixiong Zou",
        "Lingyi Hong",
        "Mingxi Chen",
        "Runze Li",
        "Xingdong Sheng",
        "Wenqiang Zhang",
        "Weisen Chen",
        "Yongxin Yan",
        "Xinguo Chen",
        "Yuanjie Shao",
        "Zhengrong Zuo",
        "Nong Sang",
        "Hao Wu",
        "Haoran Sun",
        "Shuming Hu",
        "Yan Zhang",
        "Zhiguang Shi",
        "Yu Zhang",
        "Chao Chen",
        "Tao Wang",
        "Da Feng",
        "Linhai Zhuo",
        "Ziming Lin",
        "Yali Huang",
        "Jie Me",
        "Yiming Yang",
        "Mi Guo",
        "Mingyuan Jiu",
        "Mingliang Xu",
        "Maomao Xiong",
        "Qunshu Zhang",
        "Xinyu Cao",
        "Yuqing Yang",
        "Dianmo Sheng",
        "Xuanpu Zhao",
        "Zhiyu Li",
        "Xuyang Ding",
        "Wenqian Li"
      ],
      "abstract": "Cross-Domain Few-Shot Object Detection (CD-FSOD) poses significant challenges\nto existing object detection and few-shot detection models when applied across\ndomains. In conjunction with NTIRE 2025, we organized the 1st CD-FSOD\nChallenge, aiming to advance the performance of current object detectors on\nentirely novel target domains with only limited labeled data. The challenge\nattracted 152 registered participants, received submissions from 42 teams, and\nconcluded with 13 teams making valid final submissions. Participants approached\nthe task from diverse perspectives, proposing novel models that achieved new\nstate-of-the-art (SOTA) results under both open-source and closed-source\nsettings. In this report, we present an overview of the 1st NTIRE 2025 CD-FSOD\nChallenge, highlighting the proposed solutions and summarizing the results\nsubmitted by the participants.",
      "tldr_zh": "这篇论文报告了 NTIRE 2025 上的首个 Cross-Domain Few-Shot Object Detection (CD-FSOD) 挑战赛，旨在提升物体检测模型在跨域少样本场景下的性能。挑战赛吸引了 152 名注册参与者，其中 42 队提交方案，并有 13 队提供有效最终结果。参与者从多角度提出创新模型，实现了 open-source 和 closed-source 下的 state-of-the-art (SOTA) 性能。报告概述了这些方法，并总结了挑战赛的整体成果，为未来 CD-FSOD 研究提供了宝贵参考。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by CVPRW 25 @ NTIRE",
      "pdf_url": "http://arxiv.org/pdf/2504.10685v1",
      "published_date": "2025-04-14 20:17:27 UTC",
      "updated_date": "2025-04-14 20:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:38:58.363402"
    },
    {
      "arxiv_id": "2504.10679v1",
      "title": "Keyword Extraction, and Aspect Classification in Sinhala, English, and Code-Mixed Content",
      "title_zh": "翻译失败",
      "authors": [
        "F. A. Rizvi",
        "T. Navojith",
        "A. M. N. H. Adhikari",
        "W. P. U. Senevirathna",
        "Dharshana Kasthurirathna",
        "Lakmini Abeywardhana"
      ],
      "abstract": "Brand reputation in the banking sector is maintained through insightful\nanalysis of customer opinion on code-mixed and multilingual content.\nConventional NLP models misclassify or ignore code-mixed text, when mix with\nlow resource languages such as Sinhala-English and fail to capture\ndomain-specific knowledge. This study introduces a hybrid NLP method to improve\nkeyword extraction, content filtering, and aspect-based classification of\nbanking content. Keyword extraction in English is performed with a hybrid\napproach comprising a fine-tuned SpaCy NER model, FinBERT-based KeyBERT\nembeddings, YAKE, and EmbedRank, which results in a combined accuracy of 91.2%.\nCode-mixed and Sinhala keywords are extracted using a fine-tuned XLM-RoBERTa\nmodel integrated with a domain-specific Sinhala financial vocabulary, and it\nresults in an accuracy of 87.4%. To ensure data quality, irrelevant comment\nfiltering was performed using several models, with the BERT-base-uncased model\nachieving 85.2% for English and XLM-RoBERTa 88.1% for Sinhala, which was better\nthan GPT-4o, SVM, and keyword-based filtering. Aspect classification followed\nthe same pattern, with the BERT-base-uncased model achieving 87.4% for English\nand XLM-RoBERTa 85.9% for Sinhala, both exceeding GPT-4 and keyword-based\napproaches. These findings confirm that fine-tuned transformer models\noutperform traditional methods in multilingual financial text analysis. The\npresent framework offers an accurate and scalable solution for brand reputation\nmonitoring in code-mixed and low-resource banking environments.",
      "tldr_zh": "这篇论文提出了一种混合NLP方法，用于在Sinhala、English和Code-mixed内容中进行Keyword Extraction和Aspect Classification，以解决传统模型在处理代码混合文本和低资源语言时的不足，从而提升银行部门的客户意见分析。方法包括fine-tuned SpaCy NER、FinBERT-based KeyBERT、YAKE和EmbedRank用于English关键词提取（准确率91.2%），以及fine-tuned XLM-RoBERTa结合领域特定Sinhala金融词汇用于Code-mixed和Sinhala文本（准确率87.4%）。内容过滤和Aspect Classification分别采用BERT-base-uncased（English准确率85.2%和87.4%）和XLM-RoBERTa（Sinhala准确率88.1%和85.9%），均优于GPT-4o、SVM和关键词方法。研究发现，fine-tuned transformer模型在多语言金融文本分析中表现出色，为代码混合和低资源环境下的品牌声誉监控提供了准确可扩展的框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 Pages, 2 figures, 7 Tables",
      "pdf_url": "http://arxiv.org/pdf/2504.10679v1",
      "published_date": "2025-04-14 20:01:34 UTC",
      "updated_date": "2025-04-14 20:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:39:12.826067"
    },
    {
      "arxiv_id": "2504.10677v1",
      "title": "Achieving Optimal Tissue Repair Through MARL with Reward Shaping and Curriculum Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Al-Zafar Khan",
        "Jamal Al-Karaki"
      ],
      "abstract": "In this paper, we present a multi-agent reinforcement learning (MARL)\nframework for optimizing tissue repair processes using engineered biological\nagents. Our approach integrates: (1) stochastic reaction-diffusion systems\nmodeling molecular signaling, (2) neural-like electrochemical communication\nwith Hebbian plasticity, and (3) a biologically informed reward function\ncombining chemical gradient tracking, neural synchronization, and robust\npenalties. A curriculum learning scheme guides the agent through progressively\ncomplex repair scenarios. In silico experiments demonstrate emergent repair\nstrategies, including dynamic secretion control and spatial coordination.",
      "tldr_zh": "本研究提出了一种基于多智能体强化学习(MARL)的框架，用于通过奖励整形和课程学习优化组织修复过程。该框架整合了随机反应-扩散系统来建模分子信号、神经样电化学通信与Hebbian plasticity，以及一个基于生物的奖励函数，结合化学梯度跟踪、神经同步和鲁棒惩罚；同时，使用课程学习方案引导代理逐步处理复杂修复场景。在模拟实验中，该方法展现了紧急修复策略，包括动态分泌控制和空间协调，从而提升了组织修复的效率和效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 4 figures, submitted to the 10th International Conference\n  on Information and Communication Technology for Intelligent Systems (ICTIS)",
      "pdf_url": "http://arxiv.org/pdf/2504.10677v1",
      "published_date": "2025-04-14 19:57:03 UTC",
      "updated_date": "2025-04-14 19:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:39:21.418507"
    },
    {
      "arxiv_id": "2504.10663v2",
      "title": "Characterizing Knowledge Manipulation in a Russian Wikipedia Fork",
      "title_zh": "翻译失败",
      "authors": [
        "Mykola Trokhymovych",
        "Oleksandr Kosovan",
        "Nathan Forrester",
        "Pablo Aragón",
        "Diego Saez-Trumper",
        "Ricardo Baeza-Yates"
      ],
      "abstract": "Wikipedia is powered by MediaWiki, a free and open-source software that is\nalso the infrastructure for many other wiki-based online encyclopedias. These\ninclude the recently launched website Ruwiki, which has copied and modified the\noriginal Russian Wikipedia content to conform to Russian law. To identify\npractices and narratives that could be associated with different forms of\nknowledge manipulation, this article presents an in-depth analysis of this\nRussian Wikipedia fork. We propose a methodology to characterize the main\nchanges with respect to the original version. The foundation of this study is a\ncomprehensive comparative analysis of more than 1.9M articles from Russian\nWikipedia and its fork. Using meta-information and geographical, temporal,\ncategorical, and textual features, we explore the changes made by Ruwiki\neditors. Furthermore, we present a classification of the main topics of\nknowledge manipulation in this fork, including a numerical estimation of their\nscope. This research not only sheds light on significant changes within Ruwiki,\nbut also provides a methodology that could be applied to analyze other\nWikipedia forks and similar collaborative projects.",
      "tldr_zh": "这篇论文分析了 Ruwiki，这是一个基于 MediaWiki 的俄罗斯维基百科分支，探讨了其对原内容进行复制和修改以符合俄罗斯法律所引发的知识操纵实践和叙事。研究者提出了一种方法，通过对超过 190 万篇文章进行全面比较分析，利用元信息、地理、时间、类别和文本特征来表征 Ruwiki 编辑所做的关键变化。他们进一步分类了知识操纵的主要主题，并对其范围进行了数值估计，为分析其他 Wikipedia 分支和类似协作项目提供了可扩展的分析框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10663v2",
      "published_date": "2025-04-14 19:30:30 UTC",
      "updated_date": "2025-04-21 05:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:39:35.256536"
    },
    {
      "arxiv_id": "2504.10660v1",
      "title": "LITERA: An LLM Based Approach to Latin-to-English Translation",
      "title_zh": "LITERA：一种基于LLM的拉丁语到英语翻译方法",
      "authors": [
        "Paul Rosu"
      ],
      "abstract": "This paper introduces an LLM-based Latin-to-English translation platform\ndesigned to address the challenges of translating Latin texts. We named the\nmodel LITERA, which stands for Latin Interpretation and Translations into\nEnglish for Research Assistance. Through a multi-layered translation process\nutilizing a fine-tuned version of GPT-4o-mini and GPT-4o, LITERA offers an\nunprecedented level of accuracy, showcased by greatly improved BLEU scores,\nparticularly in classical Latin, along with improved BLEURT scores. The\ndevelopment of LITERA involved close collaboration with Duke University's\nClassical Studies Department, which was instrumental in creating a small,\nhigh-quality parallel Latin-English dataset. This paper details the\narchitecture, fine-tuning methodology, and prompting strategies used in LITERA,\nemphasizing its ability to produce literal translations.",
      "tldr_zh": "本论文介绍了 LITERA，一种基于 LLM 的拉丁语到英语翻译方法，旨在解决拉丁文本翻译的挑战。LITERA 利用 fine-tuned 的 GPT-4o-mini 和 GPT-4o 进行多层翻译过程，并通过与 Duke 大学古典研究部门合作创建的高质量平行数据集，实现了精确的字面翻译。实验结果显示，LITERA 在古典拉丁语翻译中显著提升了 BLEU 和 BLEURT 分数，为研究辅助提供了更可靠的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL Findings",
      "pdf_url": "http://arxiv.org/pdf/2504.10660v1",
      "published_date": "2025-04-14 19:21:20 UTC",
      "updated_date": "2025-04-14 19:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:39:46.664045"
    },
    {
      "arxiv_id": "2504.10655v1",
      "title": "MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyu Kong",
        "Nima Shoghi",
        "Guoxiang Hu",
        "Pan Li",
        "Victor Fung"
      ],
      "abstract": "Geometric machine learning models such as graph neural networks have achieved\nremarkable success in recent years in chemical and materials science research\nfor applications such as high-throughput virtual screening and atomistic\nsimulations. The success of these models can be attributed to their ability to\neffectively learn latent representations of atomic structures directly from the\ntraining data. Conversely, this also results in high data requirements for\nthese models, hindering their application to problems which are data sparse\nwhich are common in this domain. To address this limitation, there is a growing\ndevelopment in the area of pre-trained machine learning models which have\nlearned general, fundamental, geometric relationships in atomistic data, and\nwhich can then be fine-tuned to much smaller application-specific datasets. In\nparticular, models which are pre-trained on diverse, large-scale atomistic\ndatasets have shown impressive generalizability and flexibility to downstream\napplications, and are increasingly referred to as atomistic foundation models.\nTo leverage the untapped potential of these foundation models, we introduce\nMatterTune, a modular and extensible framework that provides advanced\nfine-tuning capabilities and seamless integration of atomistic foundation\nmodels into downstream materials informatics and simulation workflows, thereby\nlowering the barriers to adoption and facilitating diverse applications in\nmaterials science. In its current state, MatterTune supports a number of\nstate-of-the-art foundation models such as ORB, MatterSim, JMP, and\nEquformerV2, and hosts a wide range of features including a modular and\nflexible design, distributed and customizable fine-tuning, broad support for\ndownstream informatics tasks, and more.",
      "tldr_zh": "该论文介绍了MatterTune，一种集成式、用户友好的平台，旨在通过微调atomistic foundation models来加速材料模拟和发现，解决几何机器学习模型（如graph neural networks）在数据稀缺问题上的局限性。MatterTune提供模块化和可扩展的框架，支持分布式微调，并无缝整合这些预训练模型到材料信息学和模拟工作流中。平台目前兼容多种先进模型，包括ORB、MatterSim、JMP和EquformerV2，并通过灵活设计和广泛的下游任务支持，降低了采用门槛并促进了材料科学领域的多样应用。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10655v1",
      "published_date": "2025-04-14 19:12:43 UTC",
      "updated_date": "2025-04-14 19:12:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:39:57.510180"
    },
    {
      "arxiv_id": "2504.10650v1",
      "title": "Will AI shape the way we speak? The emerging sociolinguistic influence of synthetic voices",
      "title_zh": "AI 会塑造我们的说话方式吗？合成语音的新兴社会语言学影响",
      "authors": [
        "Éva Székely",
        "Jūra Miniota",
        "Míša",
        "Hejná"
      ],
      "abstract": "The growing prevalence of conversational voice interfaces, powered by\ndevelopments in both speech and language technologies, raises important\nquestions about their influence on human communication. While written\ncommunication can signal identity through lexical and stylistic choices,\nvoice-based interactions inherently amplify socioindexical elements - such as\naccent, intonation, and speech style - which more prominently convey social\nidentity and group affiliation. There is evidence that even passive media such\nas television is likely to influence the audience's linguistic patterns. Unlike\npassive media, conversational AI is interactive, creating a more immersive and\nreciprocal dynamic that holds a greater potential to impact how individuals\nspeak in everyday interactions. Such heightened influence can be expected to\narise from phenomena such as acoustic-prosodic entrainment and linguistic\naccommodation, which occur naturally during interaction and enable users to\nadapt their speech patterns in response to the system. While this phenomenon is\nstill emerging, its potential societal impact could provide organisations,\nmovements, and brands with a subtle yet powerful avenue for shaping and\ncontrolling public perception and social identity. We argue that the\nsocioindexical influence of AI-generated speech warrants attention and should\nbecome a focus of interdisciplinary research, leveraging new and existing\nmethodologies and technologies to better understand its implications.",
      "tldr_zh": "这篇论文探讨了AI生成的合成语音（synthetic voices）对人类沟通方式的潜在社会语言学（sociolinguistic）影响，随着语音接口的普及，这种影响可能通过口音、语调和风格强化社会身份和群体归属。作者指出，与被动媒体不同，交互式的AI系统会通过声学-韵律entrainment（acoustic-prosodic entrainment）和语言适应（linguistic accommodation）等现象，促进用户在日常互动中调整说话模式，从而为组织或品牌提供塑造公众感知的机会。论文强调，这种新兴现象的社会影响值得关注，并呼吁开展跨学科研究以深入理解其含义。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "eess.AS",
        "I.2.7; K.4.2; H.5.2"
      ],
      "primary_category": "cs.CY",
      "comment": "5 pages, 0 figures, International Workshop on Spoken Dialogue Systems\n  Technology (IWSDS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.10650v1",
      "published_date": "2025-04-14 19:04:32 UTC",
      "updated_date": "2025-04-14 19:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:40:09.380937"
    },
    {
      "arxiv_id": "2504.10649v1",
      "title": "Ride-pool Assignment Algorithms: Modern Implementation and Swapping Heuristics",
      "title_zh": "拼车分配算法：",
      "authors": [
        "Matthew Zalesak",
        "Hins Hu",
        "Samitha Samaranayake"
      ],
      "abstract": "On-demand ride-pooling has emerged as a popular urban transportation\nsolution, addressing the efficiency limitations of traditional ride-hailing\nservices by grouping multiple riding requests with spatiotemporal proximity\ninto a single vehicle. Although numerous algorithms have been developed for the\nRide-pool Assignment Problem (RAP) -- a core component of ride-pooling systems,\nthere is a lack of open-source implementations, making it difficult to\nbenchmark these algorithms on a common dataset and objective. In this paper, we\npresent the implementation details of a ride-pool simulator that encompasses\nseveral key ride-pool assignment algorithms, along with associated components\nsuch as vehicle routing and rebalancing. We also open-source a highly optimized\nand modular C++ codebase, designed to facilitate the extension of new\nalgorithms and features. Additionally, we introduce a family of swapping-based\nlocal-search heuristics to enhance existing ride-pool assignment algorithms,\nachieving a better balance between performance and computational efficiency.\nExtensive experiments on a large-scale, real-world dataset from Manhattan, NYC\nreveal that while all selected algorithms perform comparably, the newly\nproposed Multi-Round Linear Assignment with Cyclic Exchange (LA-MR-CE)\nalgorithm achieves a state-of-the-art service rate with significantly reduced\ncomputational time. Furthermore, an in-depth analysis suggests that a\nperformance barrier exists for all myopic ride-pool assignment algorithms due\nto the system's capacity bottleneck, and incorporating future information could\nbe key to overcoming this limitation.",
      "tldr_zh": "本论文探讨了按需拼车（ride-pooling）系统的核心问题——Ride-pool Assignment Problem (RAP)，通过提供开源实现来解决算法基准测试的困难。研究者实现了 ride-pool 模拟器，包括多个关键分配算法、车辆路由和再平衡组件，并开源了一个模块化的 C++ 代码库，以便扩展新功能；同时引入了基于交换的局部搜索启发式方法（swapping-based local-search heuristics），并提出 Multi-Round Linear Assignment with Cyclic Exchange (LA-MR-CE) 算法，以优化性能和计算效率。在曼哈顿真实数据集上的大规模实验显示，LA-MR-CE 算法实现了最先进的服率，同时显著减少了计算时间；此外，分析揭示了所有短视算法的性能瓶颈，建议融入未来信息以进一步提升系统。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10649v1",
      "published_date": "2025-04-14 19:01:47 UTC",
      "updated_date": "2025-04-14 19:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:40:23.939818"
    },
    {
      "arxiv_id": "2504.10646v1",
      "title": "Weight-of-Thought Reasoning: Exploring Neural Network Weights for Enhanced LLM Reasoning",
      "title_zh": "Weight-of-Thought 推理：探索神经网络权重以增强 LLM 推理",
      "authors": [
        "Saif Punjwani",
        "Larry Heck"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities when prompted with strategies such as Chain-of-Thought (CoT).\nHowever, these approaches focus on token-level output without considering\ninternal weight dynamics. We introduce Weight-of-Thought (WoT) reasoning, a\nnovel approach that examines neural network weights before inference to\nidentify reasoning pathways. Unlike existing methods, WoT explores the weight\nspace through graph-based message passing, multi-step reasoning processes, and\nattention mechanisms. Our implementation creates an interconnected graph of\nreasoning nodes. Experiments on diverse reasoning tasks (syllogistic,\nmathematical, algebraic, combinatorial, and geometric) demonstrate that WoT\nachieves superior performance compared to traditional methods, particularly for\ncomplex problems. This approach leads to both improved performance and greater\ninterpretability of the reasoning process, offering a promising direction for\nenhancing LLM reasoning capabilities.",
      "tldr_zh": "本研究提出Weight-of-Thought (WoT)推理方法，通过分析神经网络权重在推理前的状态来识别推理路径，从而提升Large Language Models (LLMs)的推理能力，与传统Chain-of-Thought (CoT)方法不同，WoT利用图-based message passing、多步推理过程和注意力机制构建互连的推理节点图。实验在多种任务上（如syllogistic、mathematical、algebraic、combinatorial和geometric）进行，结果显示WoT在复杂问题上比传统方法性能更优。总体而言，此方法不仅提高了推理准确性，还增强了过程的可解释性，为LLMs推理能力的发展提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10646v1",
      "published_date": "2025-04-14 18:56:29 UTC",
      "updated_date": "2025-04-14 18:56:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:40:36.120996"
    },
    {
      "arxiv_id": "2504.10637v2",
      "title": "Better Estimation of the KL Divergence Between Language Models",
      "title_zh": "语言模型之间 KL 散度的更好估计",
      "authors": [
        "Afra Amini",
        "Tim Vieira",
        "Ryan Cotterell"
      ],
      "abstract": "Estimating the Kullback--Leibler (KL) divergence between language models has\nmany applications, e.g., reinforcement learning from human feedback (RLHF),\ninterpretability, and knowledge distillation. However, computing the exact KL\ndivergence between two arbitrary language models is intractable. Thus,\npractitioners often resort to the use of sampling-based estimators. While it is\neasy to fashion a simple Monte Carlo (MC) estimator that provides an unbiased\nestimate of the KL divergence between language models, this estimator\nnotoriously suffers from high variance, and can even result in a negative\nestimate of the KL divergence, a non-negative quantity. In this paper, we\nintroduce a Rao--Blackwellized estimator that is also unbiased and provably has\nvariance less than or equal to that of the standard Monte Carlo estimator. In\nan empirical study on sentiment-controlled fine-tuning, we show that our\nestimator provides more stable KL estimates and reduces variance substantially\nin practice. Additionally, we derive an analogous Rao--Blackwellized estimator\nof the gradient of the KL divergence, which leads to more stable training and\nproduces models that more frequently appear on the Pareto frontier of reward\nvs. KL compared to the ones trained with the MC estimator of the gradient.",
      "tldr_zh": "该论文探讨了更好地估计语言模型之间 KL Divergence 的方法，该散度在 RLHF（reinforcement learning from human feedback）、可解释性和知识蒸馏等领域有广泛应用。作者指出，传统的 Monte Carlo 估计器虽无偏但方差高，可能导致负值估计，因此提出了一种 Rao-Blackwellized 估计器，能显著降低方差并保持无偏性。实验结果显示，该估计器在情感控制微调任务中提供了更稳定的 KL 估计，并衍生出其梯度估计器，提升了训练稳定性，使模型更频繁出现在奖励与 KL 的 Pareto 前沿上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10637v2",
      "published_date": "2025-04-14 18:40:02 UTC",
      "updated_date": "2025-05-02 23:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:40:47.566838"
    },
    {
      "arxiv_id": "2504.10636v1",
      "title": "Who is More Bayesian: Humans or ChatGPT?",
      "title_zh": "谁更符合贝叶斯原则：人类还是 ChatGPT？",
      "authors": [
        "Tianshi Mu",
        "Pranjal Rawat",
        "John Rust",
        "Chengjun Zhang",
        "Qixuan Zhong"
      ],
      "abstract": "We compare the performance of human and artificially intelligent (AI)\ndecision makers in simple binary classification tasks where the optimal\ndecision rule is given by Bayes Rule. We reanalyze choices of human subjects\ngathered from laboratory experiments conducted by El-Gamal and Grether and Holt\nand Smith. We confirm that while overall, Bayes Rule represents the single best\nmodel for predicting human choices, subjects are heterogeneous and a\nsignificant share of them make suboptimal choices that reflect judgement biases\ndescribed by Kahneman and Tversky that include the ``representativeness\nheuristic'' (excessive weight on the evidence from the sample relative to the\nprior) and ``conservatism'' (excessive weight on the prior relative to the\nsample). We compare the performance of AI subjects gathered from recent\nversions of large language models (LLMs) including several versions of ChatGPT.\nThese general-purpose generative AI chatbots are not specifically trained to do\nwell in narrow decision making tasks, but are trained instead as ``language\npredictors'' using a large corpus of textual data from the web. We show that\nChatGPT is also subject to biases that result in suboptimal decisions. However\nwe document a rapid evolution in the performance of ChatGPT from sub-human\nperformance for early versions (ChatGPT 3.5) to superhuman and nearly perfect\nBayesian classifications in the latest versions (ChatGPT 4o).",
      "tldr_zh": "本研究比较了人类和ChatGPT等大型语言模型（LLMs）在简单二元分类任务中的决策表现，这些任务的最佳规则为Bayes Rule。研究重新分析了人类实验数据，发现尽管Bayes Rule是预测人类选择的顶级模型，但许多受试者存在异质性，受Kahneman和Tversky描述的偏见影响，如“representativeness heuristic”（过度依赖样本证据）和“conservatism”（过度依赖先验）。ChatGPT作为通用语言预测器也表现出次优决策和类似偏见，但从早期版本（ChatGPT 3.5，表现低于人类）到最新版本（ChatGPT 4o），其性能迅速提升，实现近乎完美的Bayesian分类。总体而言，该研究揭示了AI在决策任务中从亚人类到超人类水平的快速演变，为理解人类与AI认知差异提供了新洞见。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC",
        "stat.ME"
      ],
      "primary_category": "econ.GN",
      "comment": "86 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10636v1",
      "published_date": "2025-04-14 18:37:54 UTC",
      "updated_date": "2025-04-14 18:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:40:59.999628"
    },
    {
      "arxiv_id": "2504.10612v3",
      "title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Michal Balcerak",
        "Tamaz Amiranashvili",
        "Antonio Terpin",
        "Suprosanna Shit",
        "Lea Bogensperger",
        "Sebastian Kaltenbach",
        "Petros Koumoutsakos",
        "Bjoern Menze"
      ],
      "abstract": "The most widely used generative models map noise and data distributions by\nmatching flows or scores. However, they struggle to incorporate partial\nobservations and additional priors--something energy-based models (EBMs) handle\nelegantly by simply adding corresponding scalar energy terms. We address this\nissue by proposing Energy Matching, a framework that endows flow-based\napproaches with the flexibility of EBMs. Far from the data manifold, samples\nmove along curl-free, optimal transport paths from noise to data. As they\napproach the data manifold, an entropic energy term guides the system into a\nBoltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in\nterms of fidelity, while retaining simulation-free training of transport-based\napproaches away from the data manifold. Furthermore, we leverage the method's\nflexibility to introduce an interaction energy that supports diverse mode\nexploration, which we demonstrate in a controlled protein-generation setting.\nOur approach focuses on learning a scalar potential energy--without\ntime-conditioning, auxiliary generators, or additional networks--which marks a\nsignificant departure from recent EBM methods. We believe that this simplified\nframework significantly advances EBMs capabilities and paves the way for their\nwider adoption in generative modeling across diverse domains.",
      "tldr_zh": "本文提出 Energy Matching 框架，将 Flow Matching 和 Energy-Based Models (EBMs) 统一，用于生成建模，从而优雅地处理部分观察和额外先验问题。该框架在远离数据流形时采用无旋的最优传输路径从噪声引导样本，并通过熵能量项引导系统进入 Boltzmann 平衡分布，捕获数据的似然结构。实验结果显示，Energy Matching 在 CIFAR-10 和 ImageNet 生成任务中在保真度上大幅优于现有 EBMs，同时支持多样模式探索，如在蛋白质生成中的应用。该方法简化了参数化，仅需一个时间无关的标量势能作为生成器和正则化工具，标志着 EBMs 能力的显著进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10612v3",
      "published_date": "2025-04-14 18:10:58 UTC",
      "updated_date": "2025-05-22 15:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:41:12.891098"
    },
    {
      "arxiv_id": "2504.10584v1",
      "title": "Visual anemometry of natural vegetation from their leaf motion",
      "title_zh": "翻译失败",
      "authors": [
        "Roni H. Goldshmid",
        "John O. Dabiri",
        "John E. Sader"
      ],
      "abstract": "High-resolution, near-ground wind-speed data are critical for improving the\naccuracy of weather predictions and climate models,$^{1-3}$ supporting wildfire\ncontrol efforts,$^{4-7}$ and ensuring the safe passage of airplanes during\ntakeoff and landing maneouvers.$^{8,9}$ Quantitative wind speed anemometry\ngenerally employs on-site instrumentation for accurate single-position data or\nsophisticated remote techniques such as Doppler radar for quantitative field\nmeasurements. It is widely recognized that the wind-induced motion of\nvegetation depends in a complex manner on their structure and mechanical\nproperties, obviating their use in quantitative anemometry.$^{10-14}$ We\nanalyze measurements on a host of different vegetation showing that leaf motion\ncan be decoupled from the leaf's branch and support structure, at\nlow-to-moderate wind speed, $U_{wind}$. This wind speed range is characterized\nby a leaf Reynolds number, enabling the development of a remote, quantitative\nanemometry method based on the formula,\n$U_{wind}\\approx740\\sqrt{{\\mu}U_{leaf}/{\\rho}D}$, that relies only on the leaf\nsize $D$, its measured fluctuating (RMS) speed $U_{leaf}$, the air viscosity\n$\\mu$, and its mass density $\\rho$. This formula is corroborated by a\nfirst-principles model and validated using a host of laboratory and field tests\non diverse vegetation types, ranging from oak, olive, and magnolia trees\nthrough to camphor and bullgrass. The findings of this study open the door to a\nnew paradigm in anemometry, using natural vegetation to enable remote and rapid\nquantitative field measurements at global locations with minimal cost.",
      "tldr_zh": "本研究提出了一种基于自然植被叶动的新型视觉风速测量方法（visual anemometry），通过分析叶子在低到中等风速（low-to-moderate wind speed）下的运动，将其从支撑结构中分离出来，以实现远程定量风速估算。研究开发了公式 \\( U_{wind} \\approx 740 \\sqrt{\\frac{\\mu U_{leaf}}{\\rho D}} \\)，其中 D 为叶子大小、U_leaf 为其波动速度、μ 为空气粘度、ρ 为空气密度，并通过第一性原理模型以及实验室和实地测试（如橡树、橄榄树等植被）得到验证。结果表明，该方法在多种植被上准确性高，为全球范围的远程、快速且低成本风速测量开辟了新范式。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.CV",
        "physics.ao-ph"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10584v1",
      "published_date": "2025-04-14 18:00:02 UTC",
      "updated_date": "2025-04-14 18:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:41:24.466031"
    },
    {
      "arxiv_id": "2504.10478v3",
      "title": "Weight Ensembling Improves Reasoning in Language Models",
      "title_zh": "权重集成提升了语言模型中的推理能力",
      "authors": [
        "Xingyu Dang",
        "Christina Baek",
        "Kaiyue Wen",
        "Zico Kolter",
        "Aditi Raghunathan"
      ],
      "abstract": "We investigate a failure mode that arises during the training of reasoning\nmodels, where the diversity of generations begins to collapse, leading to\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\nsimple intervention of interpolating the weights of the latest SFT checkpoint\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\nwith less data when tuned further by reinforcement learning. Finally, we find\nthat WiSE-FT provides complementary performance gains that cannot be achieved\nonly through diversity-inducing decoding strategies, like temperature scaling.\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\nreduce bias and variance simultaneously, while temperature scaling inherently\ntrades off between bias and variance.",
      "tldr_zh": "本研究发现，在训练语言模型的推理能力时，生成多样性崩溃会导致Pass@1率改善但Pass@k率迅速恶化，影响测试性能。为解决此问题，提出WiSE-FT方法，通过将最新监督微调(SFT)检查点与早期检查点权重插值，几乎完全恢复Pass@k，同时提升Pass@1和测试时间缩放表现。实验显示，WiSE-FT在强化学习进一步微调时，使用更少数据即可获得优越结果，并与温度缩放等策略提供互补收益；此外，论文形式化了Pass@k的偏差-方差权衡，证明WiSE-FT能同时减少偏差和方差。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10478v3",
      "published_date": "2025-04-14 17:59:07 UTC",
      "updated_date": "2025-04-30 07:56:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:41:35.836434"
    },
    {
      "arxiv_id": "2504.10445v1",
      "title": "RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users",
      "title_zh": "翻译失败",
      "authors": [
        "Suyu Ye",
        "Haojun Shi",
        "Darren Shih",
        "Hyokun Yun",
        "Tanya Roosta",
        "Tianmin Shu"
      ],
      "abstract": "To achieve successful assistance with long-horizon web-based tasks, AI agents\nmust be able to sequentially follow real-world user instructions over a long\nperiod. Unlike existing web-based agent benchmarks, sequential instruction\nfollowing in the real world poses significant challenges beyond performing a\nsingle, clearly defined task. For instance, real-world human instructions can\nbe ambiguous, require different levels of AI assistance, and may evolve over\ntime, reflecting changes in the user's mental state. To address this gap, we\nintroduce RealWebAssist, a novel benchmark designed to evaluate sequential\ninstruction-following in realistic scenarios involving long-horizon\ninteractions with the web, visual GUI grounding, and understanding ambiguous\nreal-world user instructions. RealWebAssist includes a dataset of sequential\ninstructions collected from real-world human users. Each user instructs a\nweb-based assistant to perform a series of tasks on multiple websites. A\nsuccessful agent must reason about the true intent behind each instruction,\nkeep track of the mental state of the user, understand user-specific routines,\nand ground the intended tasks to actions on the correct GUI elements. Our\nexperimental results show that state-of-the-art models struggle to understand\nand ground user instructions, posing critical challenges in following\nreal-world user instructions for long-horizon web assistance.",
      "tldr_zh": "该论文引入了RealWebAssist benchmark，用于评估AI代理在处理真实世界用户长期网络任务时的顺序指令遵循能力。该基准聚焦于应对模糊指令、用户心理状态变化以及多网站交互等挑战，包含一个从真实用户收集的数据集，涉及视觉GUI grounding和长时序推理。实验结果显示，现有最先进模型在理解用户意图和正确执行任务方面存在显著困难，突出了AI在真实场景中提供可靠网络协助的潜在问题。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Project Website: https://scai.cs.jhu.edu/projects/RealWebAssist/\n  Code: https://github.com/SCAI-JHU/RealWebAssist",
      "pdf_url": "http://arxiv.org/pdf/2504.10445v1",
      "published_date": "2025-04-14 17:36:46 UTC",
      "updated_date": "2025-04-14 17:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:41:47.062534"
    },
    {
      "arxiv_id": "2504.10443v1",
      "title": "Multimodal Long Video Modeling Based on Temporal Dynamic Context",
      "title_zh": "基于时序动态上下文的多模态长视频建模",
      "authors": [
        "Haoran Hao",
        "Jiaming Han",
        "Yiyuan Zhang",
        "Xiangyu Yue"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have led to significant\nbreakthroughs in video understanding. However, existing models still struggle\nwith long video processing due to the context length constraint of LLMs and the\nvast amount of information within the video. Although some recent methods are\ndesigned for long video understanding, they often lose crucial information\nduring token compression and struggle with additional modality like audio. In\nthis work, we propose a dynamic long video encoding method utilizing the\ntemporal relationship between frames, named Temporal Dynamic Context (TDC).\nFirstly, we segment the video into semantically consistent scenes based on\ninter-frame similarities, then encode each frame into tokens using visual-audio\nencoders. Secondly, we propose a novel temporal context compressor to reduce\nthe number of tokens within each segment. Specifically, we employ a query-based\nTransformer to aggregate video, audio, and instruction text tokens into a\nlimited set of temporal context tokens. Finally, we feed the static frame\ntokens and the temporal context tokens into the LLM for video understanding.\nFurthermore, to handle extremely long videos, we propose a training-free\nchain-of-thought strategy that progressively extracts answers from multiple\nvideo segments. These intermediate answers serve as part of the reasoning\nprocess and contribute to the final answer. We conduct extensive experiments on\ngeneral video understanding and audio-video understanding benchmarks, where our\nmethod demonstrates strong performance. The code and models are available at\nhttps://github.com/Hoar012/TDC-Video.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在处理长视频时的上下文长度限制和信息冗余问题，提出了一种基于Temporal Dynamic Context (TDC)的多模态长视频建模方法。首先，将视频分割成语义一致的场景，使用视觉-音频编码器生成tokens，然后通过query-based Transformer聚合tokens以减少数量，并将静态帧tokens和temporal context tokens输入LLMs进行理解。其次，为极长视频引入无训练的chain-of-thought策略，通过逐步从多个段提取中间答案来生成最终响应。实验结果显示，该方法在视频理解和音频-视频理解基准上表现出色，代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10443v1",
      "published_date": "2025-04-14 17:34:06 UTC",
      "updated_date": "2025-04-14 17:34:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:42:00.273663"
    },
    {
      "arxiv_id": "2504.10430v1",
      "title": "LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Minqian Liu",
        "Zhiyang Xu",
        "Xinyi Zhang",
        "Heajun An",
        "Sarvech Qadir",
        "Qi Zhang",
        "Pamela J. Wisniewski",
        "Jin-Hee Cho",
        "Sang Won Lee",
        "Ruoxi Jia",
        "Lifu Huang"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have enabled them to\napproach human-level persuasion capabilities. However, such potential also\nraises concerns about the safety risks of LLM-driven persuasion, particularly\ntheir potential for unethical influence through manipulation, deception,\nexploitation of vulnerabilities, and many other harmful tactics. In this work,\nwe present a systematic investigation of LLM persuasion safety through two\ncritical aspects: (1) whether LLMs appropriately reject unethical persuasion\ntasks and avoid unethical strategies during execution, including cases where\nthe initial persuasion goal appears ethically neutral, and (2) how influencing\nfactors like personality traits and external pressures affect their behavior.\nTo this end, we introduce PersuSafety, the first comprehensive framework for\nthe assessment of persuasion safety which consists of three stages, i.e.,\npersuasion scene creation, persuasive conversation simulation, and persuasion\nsafety assessment. PersuSafety covers 6 diverse unethical persuasion topics and\n15 common unethical strategies. Through extensive experiments across 8 widely\nused LLMs, we observe significant safety concerns in most LLMs, including\nfailing to identify harmful persuasion tasks and leveraging various unethical\npersuasion strategies. Our study calls for more attention to improve safety\nalignment in progressive and goal-driven conversations such as persuasion.",
      "tldr_zh": "该研究通过实证调查探讨了大型语言模型(LLMs)作为说服者的潜在安全风险，重点评估LLMs是否能拒绝不道德说服任务并避免使用操纵、欺骗等不道德策略。\n他们引入了PersuSafety框架，包括说服场景创建、说服对话模拟和安全评估三个阶段，涵盖6个不道德说服主题和15个常见策略，并在8个广泛使用的LLMs上进行实验。\n结果显示，大多数LLMs存在显著安全问题，常无法识别有害任务并采用不道德方法。\n这项工作呼吁加强对LLMs在渐进式对话中的安全对齐，以防范不当影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.10430v1",
      "published_date": "2025-04-14 17:20:34 UTC",
      "updated_date": "2025-04-14 17:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:42:11.528516"
    },
    {
      "arxiv_id": "2504.10421v1",
      "title": "Can We Edit LLMs for Long-Tail Biomedical Knowledge?",
      "title_zh": "我们能否编辑LLMs以处理长尾生物医学知识？",
      "authors": [
        "Xinhao Yi",
        "Jake Lever",
        "Kevin Bryson",
        "Zaiqiao Meng"
      ],
      "abstract": "Knowledge editing has emerged as an effective approach for updating large\nlanguage models (LLMs) by modifying their internal knowledge. However, their\napplication to the biomedical domain faces unique challenges due to the\nlong-tailed distribution of biomedical knowledge, where rare and infrequent\ninformation is prevalent. In this paper, we conduct the first comprehensive\nstudy to investigate the effectiveness of knowledge editing methods for editing\nlong-tail biomedical knowledge. Our results indicate that, while existing\nediting methods can enhance LLMs' performance on long-tail biomedical\nknowledge, their performance on long-tail knowledge remains inferior to that on\nhigh-frequency popular knowledge, even after editing. Our further analysis\nreveals that long-tail biomedical knowledge contains a significant amount of\none-to-many knowledge, where one subject and relation link to multiple objects.\nThis high prevalence of one-to-many knowledge limits the effectiveness of\nknowledge editing in improving LLMs' understanding of long-tail biomedical\nknowledge, highlighting the need for tailored strategies to bridge this\nperformance gap.",
      "tldr_zh": "本研究首次全面探讨了知识编辑方法在处理长尾生物医学知识方面的有效性，针对大型语言模型（LLMs）更新稀有和不频繁信息的挑战。结果显示，现有的编辑方法虽能提升LLMs在长尾知识上的表现，但其效果仍远逊于高频知识，即使经过编辑。进一步分析发现，长尾生物医学知识中大量存在一对多知识（one-to-many knowledge），这限制了编辑方法的潜力，并强调了需要定制策略来缩小这一性能差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10421v1",
      "published_date": "2025-04-14 17:08:20 UTC",
      "updated_date": "2025-04-14 17:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:42:22.270003"
    },
    {
      "arxiv_id": "2504.10415v1",
      "title": "LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models",
      "title_zh": "LLM-SRBench：大型语言模型用于科学方程发现的新基准",
      "authors": [
        "Parshin Shojaee",
        "Ngoc-Hieu Nguyen",
        "Kazem Meidani",
        "Amir Barati Farimani",
        "Khoa D Doan",
        "Chandan K Reddy"
      ],
      "abstract": "Scientific equation discovery is a fundamental task in the history of\nscientific progress, enabling the derivation of laws governing natural\nphenomena. Recently, Large Language Models (LLMs) have gained interest for this\ntask due to their potential to leverage embedded scientific knowledge for\nhypothesis generation. However, evaluating the true discovery capabilities of\nthese methods remains challenging, as existing benchmarks often rely on common\nequations that are susceptible to memorization by LLMs, leading to inflated\nperformance metrics that do not reflect discovery. In this paper, we introduce\nLLM-SRBench, a comprehensive benchmark with 239 challenging problems across\nfour scientific domains specifically designed to evaluate LLM-based scientific\nequation discovery methods while preventing trivial memorization. Our benchmark\ncomprises two main categories: LSR-Transform, which transforms common physical\nmodels into less common mathematical representations to test reasoning beyond\nmemorized forms, and LSR-Synth, which introduces synthetic, discovery-driven\nproblems requiring data-driven reasoning. Through extensive evaluation of\nseveral state-of-the-art methods, using both open and closed LLMs, we find that\nthe best-performing system so far achieves only 31.5% symbolic accuracy. These\nfindings highlight the challenges of scientific equation discovery, positioning\nLLM-SRBench as a valuable resource for future research.",
      "tldr_zh": "本论文引入 LLM-SRBench，这是一个新的基准，旨在评估大型语言模型 (LLMs) 在科学方程发现任务中的真实能力，通过设计 239 个挑战性问题跨越四个科学领域，以避免模型对常见方程的记忆偏差。基准分为 LSR-Transform（将常见物理模型转化为不常见数学表示以测试推理能力）和 LSR-Synth（引入合成问题需要数据驱动推理）两大类别。实验结果显示，使用多种 state-of-the-art 方法的最佳系统仅达到 31.5% 的 symbolic accuracy，这突显了 LLMs 在科学方程发现中的局限性，并为未来研究提供宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project page:\n  https://github.com/deep-symbolic-mathematics/llm-srbench , Benchmark page:\n  https://huggingface.co/datasets/nnheui/llm-srbench",
      "pdf_url": "http://arxiv.org/pdf/2504.10415v1",
      "published_date": "2025-04-14 17:00:13 UTC",
      "updated_date": "2025-04-14 17:00:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:42:35.930354"
    },
    {
      "arxiv_id": "2504.10412v1",
      "title": "AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance Software Maintainability",
      "title_zh": "翻译失败",
      "authors": [
        "Gopichand Bandarupalli"
      ],
      "abstract": "This study explores Graph Neural Networks (GNNs) as a transformative tool for\ncode refactoring, using abstract syntax trees (ASTs) to boost software\nmaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet\nand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based\nSonarQube and decision trees. Metrics include cyclomatic complexity (target\nbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve\n92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming\nSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of\nsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offers\na scalable AI-driven path to cleaner codebases, which is crucial for software\nengineering.",
      "tldr_zh": "该研究利用图神经网络(GNNs)和抽象语法树(ASTs)进行AI驱动的代码重构，旨在提升软件可维护性，通过分析CodeSearchNet的200万代码片段和自定义75000文件GitHub Python语料库，并与SonarQube和决策树进行比较。指标包括环状复杂度(目标低于10)和耦合度(目标低于5)，GNNs实现了92%的重构精度，将复杂度降低35%并将耦合度降低33%，远超SonarQube(78%、16%)和决策树(85%、25%)。此外，预处理修复了60%的语法错误，并通过图表和AST视觉化呈现结果，为软件工程提供了一个可扩展的AI路径以实现更清洁的代码库。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10412v1",
      "published_date": "2025-04-14 16:58:54 UTC",
      "updated_date": "2025-04-14 16:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:42:48.805140"
    },
    {
      "arxiv_id": "2504.10405v1",
      "title": "Performance of Large Language Models in Supporting Medical Diagnosis and Treatment",
      "title_zh": "翻译失败",
      "authors": [
        "Diogo Sousa",
        "Guilherme Barbosa",
        "Catarina Rocha",
        "Dulce Oliveira"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into healthcare holds\nsignificant potential to enhance diagnostic accuracy and support medical\ntreatment planning. These AI-driven systems can analyze vast datasets,\nassisting clinicians in identifying diseases, recommending treatments, and\npredicting patient outcomes. This study evaluates the performance of a range of\ncontemporary LLMs, including both open-source and closed-source models, on the\n2024 Portuguese National Exam for medical specialty access (PNA), a\nstandardized medical knowledge assessment. Our results highlight considerable\nvariation in accuracy and cost-effectiveness, with several models demonstrating\nperformance exceeding human benchmarks for medical students on this specific\ntask. We identify leading models based on a combined score of accuracy and\ncost, discuss the implications of reasoning methodologies like\nChain-of-Thought, and underscore the potential for LLMs to function as valuable\ncomplementary tools aiding medical professionals in complex clinical\ndecision-making.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在支持医疗诊断和治疗方面的性能，测试了多种开源和闭源模型在2024年葡萄牙国家医学考试（PNA）上的表现。结果显示，这些模型在准确性和成本效益上存在显著差异，其中部分模型超过了医学生的基准水平。研究强调了Chain-of-Thought等推理方法的重要性，并指出LLMs可作为医疗专业人员在复杂临床决策中的宝贵补充工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 6 figures, 4 tables. Acknowledgements: The authors\n  acknowledge the support of the AITriage4SU Project (2024.07400.IACDC/2024),\n  funded by the FCT (Foundation for Science and Technology), Portugal",
      "pdf_url": "http://arxiv.org/pdf/2504.10405v1",
      "published_date": "2025-04-14 16:53:59 UTC",
      "updated_date": "2025-04-14 16:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:42:58.590827"
    },
    {
      "arxiv_id": "2504.10397v1",
      "title": "Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?",
      "title_zh": "大型语言模型能否辅助专家知识获取用于概率因果建模？",
      "authors": [
        "Olha Shaposhnyk",
        "Daria Zahorska",
        "Svetlana Yanushkevich"
      ],
      "abstract": "Objective: This study investigates the potential of Large Language Models\n(LLMs) as an alternative to human expert elicitation for extracting structured\ncausal knowledge and facilitating causal modeling in biometric and healthcare\napplications.\n  Material and Methods: LLM-generated causal structures, specifically Bayesian\nnetworks (BNs), were benchmarked against traditional statistical methods (e.g.,\nBayesian Information Criterion) using healthcare datasets. Validation\ntechniques included structural equation modeling (SEM) to verifying\nrelationships, and measures such as entropy, predictive accuracy, and\nrobustness to compare network structures.\n  Results and Discussion: LLM-generated BNs demonstrated lower entropy than\nexpert-elicited and statistically generated BNs, suggesting higher confidence\nand precision in predictions. However, limitations such as contextual\nconstraints, hallucinated dependencies, and potential biases inherited from\ntraining data require further investigation.\n  Conclusion: LLMs represent a novel frontier in expert elicitation for\nprobabilistic causal modeling, promising to improve transparency and reduce\nuncertainty in the decision-making using such models.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 是否能替代人类专家抽取结构化因果知识，并辅助生物识别和医疗领域的概率因果建模。研究方法包括使用 LLMs 生成贝叶斯网络 (BNs)，并与传统统计方法（如 Bayesian Information Criterion）进行比较，通过结构方程建模 (SEM) 验证关系，并评估熵、预测准确性和鲁棒性。结果显示，LLMs 生成的 BNs 具有更低的熵，表明更高的预测置信度和精确性，但面临上下文约束、虚构依赖关系和训练数据偏见等挑战。总体而言，LLMs 为专家 elicitation 提供新途径，有望提升因果建模的透明度和决策不确定性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10397v1",
      "published_date": "2025-04-14 16:45:52 UTC",
      "updated_date": "2025-04-14 16:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:43:12.167728"
    },
    {
      "arxiv_id": "2504.10390v1",
      "title": "Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain",
      "title_zh": "教师运动先验：增强机器人于挑战性地形的运动",
      "authors": [
        "Fangcheng Jin",
        "Yuqi Wang",
        "Peixin Ma",
        "Guodong Yang",
        "Pan Zhao",
        "En Li",
        "Zhengtao Zhang"
      ],
      "abstract": "Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.",
      "tldr_zh": "本文提出了一种基于教师-学生范式的Teacher Motion Priors框架，结合imitation learning和auxiliary task learning，以提升机器人（尤其是人形机器人）在复杂地形上的行走鲁棒性。该框架先训练高性能教师策略使用特权信息获取运动技能，然后通过generative adversarial mechanism将教师的运动分布转移到仅依赖noisy proprioceptive data的学生策略中，缓解分布偏移并加速收敛。实验结果显示，该方法显著提高了人形机器人在动态地形上的行走稳定性，并降低了开发成本，提供了一个实用部署解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T40"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.10390v1",
      "published_date": "2025-04-14 16:36:56 UTC",
      "updated_date": "2025-04-14 16:36:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:43:24.100159"
    },
    {
      "arxiv_id": "2504.10369v1",
      "title": "SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired Symbolic Reasoning",
      "title_zh": "SymRTLO：利用 LLMs 和受神经元启发的符号推理增强",
      "authors": [
        "Yiting Wang",
        "Wanghao Ye",
        "Ping Guo",
        "Yexiao He",
        "Ziyao Wang",
        "Yexiao He",
        "Bowei Tian",
        "Shwai He",
        "Guoheng Sun",
        "Zheyu Shen",
        "Sihan Chen",
        "Ankur Srivastava",
        "Qingfu Zhang",
        "Gang Qu",
        "Ang Li"
      ],
      "abstract": "Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.",
      "tldr_zh": "该研究提出 SymRTLO 框架，利用 LLMs 和神经元启发符号推理来优化 RTL 代码，旨在解决手动重写耗时易错以及现有编译器处理复杂约束的难题。\n框架整合检索增强生成 (RAG) 系统、Abstract Syntax Tree (AST)-based 模板和符号模块，实现语法正确性代码重写、有限状态机 (FSM) 逻辑的细粒度优化，以及结合形式等效检查和测试驱动的快速验证管道。\n实验结果显示，在 RTL-Rewriter 基准上使用 Synopsys Design Compiler 和 Yosys，SymRTLO 分别将功率、性能和面积 (PPA) 改善高达 43.9%、62.5% 和 51.1%，优于现有方法。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.AR",
      "comment": "16 pages, 8 figures, 7 tables. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.10369v1",
      "published_date": "2025-04-14 16:15:55 UTC",
      "updated_date": "2025-04-14 16:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:43:36.510112"
    },
    {
      "arxiv_id": "2504.10368v2",
      "title": "S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models",
      "title_zh": "S1-Bench：用于评估大型推理模型",
      "authors": [
        "Wenyuan Zhang",
        "Shuaiyi Nie",
        "Xinghua Zhang",
        "Zefeng Zhang",
        "Tingwen Liu"
      ],
      "abstract": "We introduce S1-Bench, a novel benchmark designed to evaluate the performance\nof Large Reasoning Models (LRMs) on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their heavy reliance on system 2 thinking may limit their system 1\nthinking capabilities. However, there is a lack of an appropriate benchmark for\nevaluating LRM's system 1 thinking capabilities. To fill this gap, S1-Bench\nintroduces a suite of simple, diverse, and natural questions across multiple\ndomains and languages, specifically designed to assess LRMs' performance on\nquestions more suitable for system 1 . We conduct extensive evaluations across\n28 LRMs, revealing their inefficiency, inadequate accuracy, and limited\nrobustness when handling simple questions. Additionally, we observe a gap\nbetween their difficulty perception and generation length. Overall, this work\npaves the way toward dual-system compatibility in the development of LRMs.",
      "tldr_zh": "我们引入了 S1-Bench，这是一个简单的新型基准，用于评估大型推理模型 (LRMs) 在偏好直觉系统 1 thinking 的简单任务上的性能，同时突显它们对系统 2 thinking 的过度依赖可能导致的能力缺失。S1-Bench 包含一系列简单、多样且自然的跨领域和跨语言问题，专门设计来测试 LRMs 在系统 1 任务中的表现。实验结果显示，28 个 LRMs 在处理这些简单问题时存在效率低下、准确性不足和鲁棒性有限的问题，并揭示了它们在难度感知和生成长度之间的差距。这项工作为推动 LRMs 向双系统兼容性发展提供了重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages, 9 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.10368v2",
      "published_date": "2025-04-14 16:13:23 UTC",
      "updated_date": "2025-05-20 16:52:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:43:48.251702"
    },
    {
      "arxiv_id": "2504.16101v1",
      "title": "xLSTM-ECG: Multi-label ECG Classification via Feature Fusion with xLSTM",
      "title_zh": "xLSTM-ECG：通过xLSTM特征融合进行多标签ECG分类",
      "authors": [
        "Lei Kang",
        "Xuanshuo Fu",
        "Javier Vazquez-Corral",
        "Ernest Valveny",
        "Dimosthenis Karatzas"
      ],
      "abstract": "Cardiovascular diseases (CVDs) remain the leading cause of mortality\nworldwide, highlighting the critical need for efficient and accurate diagnostic\ntools. Electrocardiograms (ECGs) are indispensable in diagnosing various heart\nconditions; however, their manual interpretation is time-consuming and\nerror-prone. In this paper, we propose xLSTM-ECG, a novel approach that\nleverages an extended Long Short-Term Memory (xLSTM) network for multi-label\nclassification of ECG signals, using the PTB-XL dataset. To the best of our\nknowledge, this work represents the first design and application of xLSTM\nmodules specifically adapted for multi-label ECG classification. Our method\nemploys a Short-Time Fourier Transform (STFT) to convert time-series ECG\nwaveforms into the frequency domain, thereby enhancing feature extraction. The\nxLSTM architecture is specifically tailored to address the complexities of\n12-lead ECG recordings by capturing both local and global signal features.\nComprehensive experiments on the PTB-XL dataset reveal that our model achieves\nstrong multi-label classification performance, while additional tests on the\nGeorgia 12-Lead dataset underscore its robustness and efficiency. This approach\nsignificantly improves ECG classification accuracy, thereby advancing clinical\ndiagnostics and patient care. The code will be publicly available upon\nacceptance.",
      "tldr_zh": "本论文提出 xLSTM-ECG 方法，利用扩展的 Long Short-Term Memory (xLSTM) 网络进行多标签 ECG 分类，旨在解决心血管疾病诊断中手动解读ECG信号耗时且易出错的问题。该方法通过 Short-Time Fourier Transform (STFT) 将时间序列ECG信号转换为频域，并设计xLSTM架构来捕捉12导联ECG记录的局部和全局特征。在PTB-XL数据集上的实验显示，该模型在多标签分类中表现出色，并在Georgia 12-Lead数据集上验证了其鲁棒性和效率，从而显著提升临床诊断准确性并推进患者护理。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16101v1",
      "published_date": "2025-04-14 16:12:46 UTC",
      "updated_date": "2025-04-14 16:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:44:00.696115"
    },
    {
      "arxiv_id": "2504.10358v1",
      "title": "FingER: Content Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Chen",
        "Lei Sun",
        "Jing Tang",
        "Geng Li",
        "Xiangxiang Chu"
      ],
      "abstract": "Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.",
      "tldr_zh": "该论文提出FingER框架，用于AI生成视频的细粒度评估，通过整合内容感知和推理机制来解决视频不一致性和缺陷的评估挑战。FingER首先利用LLMs自动生成五个视角的实体级问题，这些问题聚焦特定实体，便于MLLMs进行可解释的回答和评分，然后将这些评分加权求和得到整体分数。研究构建了包含约3.3k视频和60k QA注解的FingER数据集，并探索了各种训练协议，特别是采用Group Relative Policy Optimization (GRPO)与cold-start策略，显著提升了MLLMs的推理能力。实验结果显示，该模型在GenAI-Bench上相对提升11.8%、在MonetBench上提升5.5%，且仅需其他方法的1/10训练样本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10358v1",
      "published_date": "2025-04-14 16:07:16 UTC",
      "updated_date": "2025-04-14 16:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:44:11.500227"
    },
    {
      "arxiv_id": "2504.10340v2",
      "title": "Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families",
      "title_zh": "翻译失败",
      "authors": [
        "Shahriar Noroozizadeh",
        "Sayantan Kumar",
        "Jeremy C. Weiss"
      ],
      "abstract": "Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings -- extracted via an\nLLM-assisted annotation pipeline -- serve as the primary input for prediction.\nWe systematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.",
      "tldr_zh": "本研究探讨了从临床文本时间序列进行预测的问题，使用LLM-assisted注解管道提取时间戳临床发现作为主要输入，并评估了多种模型，包括微调的decoder-based large language models和encoder-based transformers，在事件发生预测、时间顺序和survival analysis任务上的性能。结果显示，encoder-based models在短期和长期事件预测中取得了更高的F1 scores和更好的temporal concordance，而微调的masking方法提升了排名性能；相比之下，instruction-tuned decoder models在survival analysis中表现出相对优势，尤其在早期预后场景。敏感性分析强调了时间顺序（time ordering）的重要性，超过了文本顺序（text ordering），突显了时间有序语料对LLM时代temporal任务的额外益处。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Machine Learning for Healthcare (MLHC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.10340v2",
      "published_date": "2025-04-14 15:48:56 UTC",
      "updated_date": "2025-04-20 19:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:44:23.023355"
    },
    {
      "arxiv_id": "2504.10337v2",
      "title": "Heimdall: test-time scaling on the generative verification",
      "title_zh": "Heimdall：生成式验证中的测试时缩放",
      "authors": [
        "Wenlei Shi",
        "Xing Jin"
      ],
      "abstract": "An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.",
      "tldr_zh": "该论文提出Heimdall，一种专注于长Chain-of-Thought Reasoning验证的语言模型，通过纯Reinforcement Learning将竞争性数学问题的验证准确率从62.5%提升至94.5%，并通过重复采样进一步达到97.5%。Heimdall展示出强大的泛化能力，能够检测训练中未涉及的数学证明问题。作者引入Pessimistic Verification方法，利用Heimdall评估解决方案，选择不确定性最低的正确答案，从而将DeepSeek-R1-Distill-Qwen-32B模型在AIME2025上的准确率从54.2%提高至70.0%（16x计算预算）或83.3%（更多预算），并在Gemini 2.5 Pro上达到93.0%。最终，Heimdall被整合到一个自动知识发现系统中，帮助识别NuminaMath数据集近半数的 flawed 记录。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10337v2",
      "published_date": "2025-04-14 15:46:33 UTC",
      "updated_date": "2025-04-16 14:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:44:36.354076"
    },
    {
      "arxiv_id": "2504.10326v1",
      "title": "AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference",
      "title_zh": "AlayaDB：高效且有效的长上下文LLM推理的数据基础",
      "authors": [
        "Yangshen Deng",
        "Zhengxin You",
        "Long Xiang",
        "Qilong Li",
        "Peiqi Yuan",
        "Zhaoyang Hong",
        "Yitao Zheng",
        "Wanting Li",
        "Runzhong Li",
        "Haotian Liu",
        "Kyriakos Mouratidis",
        "Man Lung Yiu",
        "Huan Li",
        "Qiaomu Shen",
        "Rui Mao",
        "Bo Tang"
      ],
      "abstract": "AlayaDB is a cutting-edge vector database system natively architected for\nefficient and effective long-context inference for Large Language Models (LLMs)\nat AlayaDB AI. Specifically, it decouples the KV cache and attention\ncomputation from the LLM inference systems, and encapsulates them into a novel\nvector database system. For the Model as a Service providers (MaaS), AlayaDB\nconsumes fewer hardware resources and offers higher generation quality for\nvarious workloads with different kinds of Service Level Objectives (SLOs), when\ncomparing with the existing alternative solutions (e.g., KV cache\ndisaggregation, retrieval-based sparse attention). The crux of AlayaDB is that\nit abstracts the attention computation and cache management for LLM inference\ninto a query processing procedure, and optimizes the performance via a native\nquery optimizer. In this work, we demonstrate the effectiveness of AlayaDB via\n(i) three use cases from our industry partners, and (ii) extensive experimental\nresults on LLM inference benchmarks.",
      "tldr_zh": "AlayaDB 是一种专为大型语言模型(LLMs)长上下文推理设计的先进矢量数据库系统，它将 KV cache 和注意力计算从 LLM 推理系统中解耦，并封装进一个新型数据库中，以实现更高效的资源利用和生成质量。\n该系统通过将注意力计算及缓存管理抽象为查询处理过程，并采用原生查询优化器，对各种服务水平目标(SLOs)的负载进行优化，相比现有方案（如 KV cache disaggregation 或基于检索的稀疏注意力）表现出显著优势。\n论文通过三个行业合作伙伴的实际用例以及广泛的 LLM 推理基准实验，证明了 AlayaDB 在减少硬件资源消耗和提升性能方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IR",
        "H.3.1; H.3.2; H.3.3; H.3.4"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 12 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2504.10326v1",
      "published_date": "2025-04-14 15:34:26 UTC",
      "updated_date": "2025-04-14 15:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:44:47.756497"
    },
    {
      "arxiv_id": "2504.16100v1",
      "title": "Towards Accurate Forecasting of Renewable Energy : Building Datasets and Benchmarking Machine Learning Models for Solar and Wind Power in France",
      "title_zh": "翻译失败",
      "authors": [
        "Eloi Lindas",
        "Yannig Goude",
        "Philippe Ciais"
      ],
      "abstract": "Accurate prediction of non-dispatchable renewable energy sources is essential\nfor grid stability and price prediction. Regional power supply forecasts are\nusually indirect through a bottom-up approach of plant-level forecasts,\nincorporate lagged power values, and do not use the potential of spatially\nresolved data. This study presents a comprehensive methodology for predicting\nsolar and wind power production at country scale in France using machine\nlearning models trained with spatially explicit weather data combined with\nspatial information about production sites capacity. A dataset is built\nspanning from 2012 to 2023, using daily power production data from RTE (the\nnational grid operator) as the target variable, with daily weather data from\nERA5, production sites capacity and location, and electricity prices as input\nfeatures. Three modeling approaches are explored to handle spatially resolved\nweather data: spatial averaging over the country, dimension reduction through\nprincipal component analysis, and a computer vision architecture to exploit\ncomplex spatial relationships. The study benchmarks state-of-the-art machine\nlearning models as well as hyperparameter tuning approaches based on\ncross-validation methods on daily power production data. Results indicate that\ncross-validation tailored to time series is best suited to reach low error. We\nfound that neural networks tend to outperform traditional tree-based models,\nwhich face challenges in extrapolation due to the increasing renewable capacity\nover time. Model performance ranges from 4% to 10% in nRMSE for midterm\nhorizon, achieving similar error metrics to local models established at a\nsingle-plant level, highlighting the potential of these methods for regional\npower supply forecasting.",
      "tldr_zh": "该研究针对法国太阳能和风能发电的准确预测，构建了一个从2012到2023年的数据集，使用RTE的每日电力生产数据作为目标变量，并结合ERA5天气数据、生产站点容量、位置和电力价格作为输入特征。论文探索了三种处理空间分辨率数据的方法：空间平均、主成分分析和计算机视觉架构，以充分利用复杂空间关系。基准测试显示，针对时间序列的交叉验证能实现低错误率，神经网络模型在中期预测中以4%到10%的nRMSE outperformed传统的树-based模型，后者面临外推挑战。整体结果证明，这些机器学习方法在区域电力供应预测中具有显著潜力，与单厂级模型相当。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "eess.SP",
      "comment": "24 pages, 4 tables, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16100v1",
      "published_date": "2025-04-14 15:30:54 UTC",
      "updated_date": "2025-04-14 15:30:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:45:00.793912"
    },
    {
      "arxiv_id": "2504.10561v2",
      "title": "Self-Controlled Dynamic Expansion Model for Continual Learning",
      "title_zh": "自控动态扩展模型用于持续学习",
      "authors": [
        "Runqing Wu",
        "Kaihui Huang",
        "Hanyi Zhang",
        "Fei Ye"
      ],
      "abstract": "Continual Learning (CL) epitomizes an advanced training paradigm wherein\nprior data samples remain inaccessible during the acquisition of new tasks.\nNumerous investigations have delved into leveraging a pre-trained Vision\nTransformer (ViT) to enhance model efficacy in continual learning. Nonetheless,\nthese approaches typically utilize a singular, static backbone, which\ninadequately adapts to novel tasks, particularly when engaging with diverse\ndata domains, due to a substantial number of inactive parameters. This paper\naddresses this limitation by introducing an innovative Self-Controlled Dynamic\nExpansion Model (SCDEM), which orchestrates multiple distinct trainable\npre-trained ViT backbones to furnish diverse and semantically enriched\nrepresentations. Specifically, by employing the multi-backbone architecture as\na shared module, the proposed SCDEM dynamically generates a new expert with\nminimal parameters to accommodate a new task. A novel Collaborative\nOptimization Mechanism (COM) is introduced to synergistically optimize multiple\nbackbones by harnessing prediction signals from historical experts, thereby\nfacilitating new task learning without erasing previously acquired knowledge.\nAdditionally, a novel Feature Distribution Consistency (FDC) approach is\nproposed to align semantic similarity between previously and currently learned\nrepresentations through an optimal transport distance-based mechanism,\neffectively mitigating negative knowledge transfer effects. Furthermore, to\nalleviate over-regularization challenges, this paper presents a novel Dynamic\nLayer-Wise Feature Attention Mechanism (DLWFAM) to autonomously determine the\npenalization intensity on each trainable representation layer. An extensive\nseries of experiments have been conducted to evaluate the proposed\nmethodology's efficacy, with empirical results corroborating that the approach\nattains state-of-the-art performance.",
      "tldr_zh": "这篇论文针对 Continual Learning (CL) 的挑战，提出了一种创新的 Self-Controlled Dynamic Expansion Model (SCDEM)，它利用多个可训练的预训练 Vision Transformer (ViT) 骨干网络动态生成新专家，以最小参数适应新任务，同时避免先前知识遗忘。SCDEM 引入 Collaborative Optimization Mechanism (COM) 来协同优化多个骨干网络，利用历史专家的预测信号；Feature Distribution Consistency (FDC) 通过最优传输距离机制对齐表示的语义相似性，减少负面知识转移；以及 Dynamic Layer-Wise Feature Attention Mechanism (DLWFAM) 来动态调整各层的惩罚强度，缓解过度正则化问题。实验结果显示，该方法在各种 CL 场景中达到了 state-of-the-art 性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures, 6 tables, Continual Learning, Cross-Domain\n  Continual Learning, Mixture Model",
      "pdf_url": "http://arxiv.org/pdf/2504.10561v2",
      "published_date": "2025-04-14 15:22:51 UTC",
      "updated_date": "2025-04-16 01:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:45:11.936378"
    },
    {
      "arxiv_id": "2504.10309v1",
      "title": "AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style Matching Text-to-Speech Synthesis",
      "title_zh": "AutoStyle-TTS：基于检索增强生成的自动风格匹配文本到语音合成",
      "authors": [
        "Dan Luo",
        "Chengyuan Ma",
        "Weiqin Li",
        "Jun Wang",
        "Wei Chen",
        "Zhiyong Wu"
      ],
      "abstract": "With the advancement of speech synthesis technology, users have higher\nexpectations for the naturalness and expressiveness of synthesized speech. But\nprevious research ignores the importance of prompt selection. This study\nproposes a text-to-speech (TTS) framework based on Retrieval-Augmented\nGeneration (RAG) technology, which can dynamically adjust the speech style\naccording to the text content to achieve more natural and vivid communication\neffects. We have constructed a speech style knowledge database containing\nhigh-quality speech samples in various contexts and developed a style matching\nscheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and\nMoka, to match with samples in the knowledge database, selecting the most\nappropriate speech style for synthesis. Furthermore, our empirical research\nvalidates the effectiveness of the proposed method. Our demo can be viewed at:\nhttps://thuhcsi.github.io/icme2025-AutoStyle-TTS",
      "tldr_zh": "该研究提出 AutoStyle-TTS 框架，利用 Retrieval-Augmented Generation (RAG) 技术，实现基于文本内容的自动语音风格匹配，以提升 Text-to-Speech (TTS) 合成的自然性和表现力。框架构建了一个包含各种语境的高质量语音样本知识数据库，并通过 Llama、PER-LLM-Embedder 和 Moka 提取的 embeddings 来匹配并选择最合适的语音风格。实验结果验证了该方法的有效性，并提供了一个在线 demo 供演示。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted by ICME25",
      "pdf_url": "http://arxiv.org/pdf/2504.10309v1",
      "published_date": "2025-04-14 15:18:59 UTC",
      "updated_date": "2025-04-14 15:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:45:22.316226"
    },
    {
      "arxiv_id": "2504.21008v1",
      "title": "Research on CNN-BiLSTM Network Traffic Anomaly Detection Model Based on MindSpore",
      "title_zh": "基于 MindSpore 的 CNN-BiLSTM 网络流量异常检测模型研究",
      "authors": [
        "Qiuyan Xiang",
        "Shuang Wu",
        "Dongze Wu",
        "Yuxin Liu",
        "Zhenkai Qin"
      ],
      "abstract": "With the widespread adoption of the Internet of Things (IoT) and Industrial\nIoT (IIoT) technologies, network architectures have become increasingly\ncomplex, and the volume of traffic has grown substantially. This evolution\nposes significant challenges to traditional security mechanisms, particularly\nin detecting high-frequency, diverse, and highly covert network attacks. To\naddress these challenges, this study proposes a novel network traffic anomaly\ndetection model that integrates a Convolutional Neural Network (CNN) with a\nBidirectional Long Short-Term Memory (BiLSTM) network, implemented on the\nMindSpore framework. Comprehensive experiments were conducted using the\nNF-BoT-IoT dataset. The results demonstrate that the proposed model achieves\n99% across accuracy, precision, recall, and F1-score, indicating its strong\nperformance and robustness in network intrusion detection tasks.",
      "tldr_zh": "本研究针对物联网(IoT)和工业物联网(IIoT)技术的普及导致的网络流量复杂化和安全挑战，提出了一种基于CNN和BiLSTM的网络流量异常检测模型，并使用MindSpore框架进行实现。该模型结合CNN的特征提取能力和BiLSTM的序列处理优势，能够有效识别高频、多样和隐蔽的网络攻击。在NF-BoT-IoT数据集上的实验显示，该模型在准确率、精确率、召回率和F1-score上均达到99%，展现出强大的性能和鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21008v1",
      "published_date": "2025-04-14 15:10:18 UTC",
      "updated_date": "2025-04-14 15:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:45:34.882229"
    },
    {
      "arxiv_id": "2504.10559v1",
      "title": "Efficient Process Reward Model Training via Active Learning",
      "title_zh": "通过主动学习的高效过程奖励模型训练",
      "authors": [
        "Keyu Duan",
        "Zichen Liu",
        "Xin Mao",
        "Tianyu Pang",
        "Changyu Chen",
        "Qiguang Chen",
        "Michael Qizhe Shieh",
        "Longxu Dou"
      ],
      "abstract": "Process Reward Models (PRMs) provide step-level supervision to large language\nmodels (LLMs), but scaling up training data annotation remains challenging for\nboth humans and LLMs. To address this limitation, we propose an active learning\napproach, ActPRM, which proactively selects the most uncertain samples for\ntraining, substantially reducing labeling costs. During training, we use the\nPRM to estimate uncertainty after the forward pass, retaining only highly\nuncertain data. A capable yet costly reasoning model then labels this data.\nThen we compute the loss with respect to the labels and update the PRM's\nweights. We compare ActPRM vs. vanilla fine-tuning, on a pool-based active\nlearning setting, demonstrating that ActPRM reduces 50% annotation, but\nachieving the comparable or even better performance. Beyond annotation\nefficiency, we further advance the actively trained PRM by filtering over 1M+\nmath reasoning trajectories with ActPRM, retaining 60% of the data. A\nsubsequent training on this selected dataset yields a new state-of-the-art\n(SOTA) PRM on ProcessBench (75.0%) and PRMBench (65.5%) compared with same\nsized models.",
      "tldr_zh": "本研究针对Process Reward Models (PRMs)训练中数据标注的挑战，提出了一种主动学习方法ActPRM，通过选择高度不确定样本并使用高效推理模型进行标注，显著降低了标注成本。ActPRM在训练过程中利用PRM估算不确定性，仅保留关键数据进行处理，从而实现高效更新模型权重。实验结果显示，与传统微调相比，ActPRM减少50%的标注量，同时在性能上达到或超过基线；在过滤超过1M+数学推理轨迹后，该方法帮助模型在ProcessBench上达到75.0%和PRMBench上65.5%的新的SOTA水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10559v1",
      "published_date": "2025-04-14 14:53:56 UTC",
      "updated_date": "2025-04-14 14:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:45:48.821377"
    },
    {
      "arxiv_id": "2504.10286v1",
      "title": "Characterizing LLM-driven Social Network: The Chirper.ai Case",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Zhu",
        "Yupeng He",
        "Ehsan-Ul Haq",
        "Gareth Tyson",
        "Pan Hui"
      ],
      "abstract": "Large language models (LLMs) demonstrate the ability to simulate human\ndecision-making processes, enabling their use as agents in modeling\nsophisticated social networks, both offline and online. Recent research has\nexplored collective behavioral patterns and structural characteristics of LLM\nagents within simulated networks. However, empirical comparisons between\nLLM-driven and human-driven online social networks remain scarce, limiting our\nunderstanding of how LLM agents differ from human users. This paper presents a\nlarge-scale analysis of Chirper.ai, an X/Twitter-like social network entirely\npopulated by LLM agents, comprising over 65,000 agents and 7.7 million\nAI-generated posts. For comparison, we collect a parallel dataset from\nMastodon, a human-driven decentralized social network, with over 117,000 users\nand 16 million posts. We examine key differences between LLM agents and humans\nin posting behaviors, abusive content, and social network structures. Our\nfindings provide critical insights into the evolving landscape of online social\nnetwork analysis in the AI era, offering a comprehensive profile of LLM agents\nin social simulations.",
      "tldr_zh": "这篇论文分析了大型语言模型 (LLMs) 作为代理模拟人类决策过程在社交网络中的表现，以Chirper.ai为例，该平台由超过65,000个LLM代理和7.7百万AI生成帖子组成。研究者通过与人类驱动的Mastodon平台（包含117,000+用户和16百万帖子）进行大规模实证比较，考察了LLM代理与人类在发布行为、辱骂内容以及社会网络结构上的关键差异。结果显示，LLM代理表现出与人类显著不同的模式，为AI时代在线社交网络分析提供了宝贵的洞见和全面的代理特征描述。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2504.10286v1",
      "published_date": "2025-04-14 14:53:31 UTC",
      "updated_date": "2025-04-14 14:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:45:59.541102"
    },
    {
      "arxiv_id": "2504.10281v1",
      "title": "Zero-shot Autonomous Microscopy for Scalable and Intelligent Characterization of 2D Materials",
      "title_zh": "零样本自治显微镜用于二维材料的可扩展和智能表征",
      "authors": [
        "Jingyun Yang",
        "Ruoyan Avery Yin",
        "Chi Jiang",
        "Yuepeng Hu",
        "Xiaokai Zhu",
        "Xingjian Hu",
        "Sutharsika Kumar",
        "Xiao Wang",
        "Xiaohua Zhai",
        "Keran Rong",
        "Yunyue Zhu",
        "Tianyi Zhang",
        "Zongyou Yin",
        "Jing Kong",
        "Neil Zhenqiang Gong",
        "Zhichu Ren",
        "Haozhe Wang"
      ],
      "abstract": "Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.",
      "tldr_zh": "本论文提出ATOMIC框架，实现零样本自治显微镜技术，用于可扩展和智能的二维（2D）材料表征，旨在解决传统方法依赖专家培训和大量数据集的瓶颈。框架整合Segment Anything Model、ChatGPT、无监督聚类和拓扑分析，通过提示工程自动化显微镜控制、样本扫描、图像分割及分析，无需额外训练。在MoS2样本上，ATOMIC实现了99.7%的单层识别准确率，并能检测人类难以辨识的grain boundary slits，同时在defocus、色温波动和曝光变化等条件下保持鲁棒性。该系统适用于多种2D材料如graphene、MoS2、WSe2和SnSe，建立了一个可扩展、数据高效的表征范式，变革纳米尺度材料研究。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10281v1",
      "published_date": "2025-04-14 14:49:45 UTC",
      "updated_date": "2025-04-14 14:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:46:12.119062"
    },
    {
      "arxiv_id": "2504.10277v1",
      "title": "RealHarm: A Collection of Real-World Language Model Application Failures",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Le Jeune",
        "Jiaen Liu",
        "Luca Rossi",
        "Matteo Dora"
      ],
      "abstract": "Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.",
      "tldr_zh": "这篇论文介绍了RealHarm数据集，该数据集通过系统审查公开报告的事件，收集了真实世界中语言模型应用失败的注释化交互案例。研究从部署者的视角分析了这些失败的harms、causes和hazards，发现reputational damage是主要组织危害，而misinformation是最常见的hazard类别。作者评估了state-of-the-art guardrails和content moderation systems，结果显示这些系统在防范此类事件方面存在显著gap，为改进AI应用的安全性提供了实证依据。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10277v1",
      "published_date": "2025-04-14 14:44:41 UTC",
      "updated_date": "2025-04-14 14:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:46:23.639844"
    },
    {
      "arxiv_id": "2504.10266v1",
      "title": "Vision based driving agent for race car simulation environments",
      "title_zh": "翻译失败",
      "authors": [
        "Gergely Bári",
        "László Palkovics"
      ],
      "abstract": "In recent years, autonomous driving has become a popular field of study. As\ncontrol at tire grip limit is essential during emergency situations, algorithms\ndeveloped for racecars are useful for road cars too. This paper examines the\nuse of Deep Reinforcement Learning (DRL) to solve the problem of grip limit\ndriving in a simulated environment. Proximal Policy Optimization (PPO) method\nis used to train an agent to control the steering wheel and pedals of the\nvehicle, using only visual inputs to achieve professional human lap times. The\npaper outlines the formulation of the task of time optimal driving on a race\ntrack as a deep reinforcement learning problem, and explains the chosen\nobservations, actions, and reward functions. The results demonstrate human-like\nlearning and driving behavior that utilize maximum tire grip potential.",
      "tldr_zh": "这篇论文使用深度强化学习（DRL）来训练一个基于视觉输入的驾驶代理，旨在解决模拟环境中赛车的极限抓地力驾驶问题。研究采用 Proximal Policy Optimization (PPO) 算法，通过视觉观察来控制车辆的转向和踏板，并设计了时间最优驾驶任务的观察、动作和奖励函数。结果表明，该代理展示了类似人类的学习和驾驶行为，能够充分利用轮胎抓地力潜力，实现接近专业人类水平的圈速。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to ICMCE 2024 (https://icmce.org/2024.html)",
      "pdf_url": "http://arxiv.org/pdf/2504.10266v1",
      "published_date": "2025-04-14 14:29:37 UTC",
      "updated_date": "2025-04-14 14:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:46:35.489030"
    },
    {
      "arxiv_id": "2504.10254v1",
      "title": "MASSeg : 2nd Technical Report for 4th PVUW MOSE Track",
      "title_zh": "翻译失败",
      "authors": [
        "Xuqiang Cao",
        "Linnan Zhao",
        "Jiaxuan Zhao",
        "Fang Liu",
        "Puhua Chen",
        "Wenping Ma"
      ],
      "abstract": "Complex video object segmentation continues to face significant challenges in\nsmall object recognition, occlusion handling, and dynamic scene modeling. This\nreport presents our solution, which ranked second in the MOSE track of CVPR\n2025 PVUW Challenge. Based on an existing segmentation framework, we propose an\nimproved model named MASSeg for complex video object segmentation, and\nconstruct an enhanced dataset, MOSE+, which includes typical scenarios with\nocclusions, cluttered backgrounds, and small target instances. During training,\nwe incorporate a combination of inter-frame consistent and inconsistent data\naugmentation strategies to improve robustness and generalization. During\ninference, we design a mask output scaling strategy to better adapt to varying\nobject sizes and occlusion levels. As a result, MASSeg achieves a J score of\n0.8250, F score of 0.9007, and a J&F score of 0.8628 on the MOSE test set.",
      "tldr_zh": "本研究针对复杂视频对象分割中的小对象识别、遮挡处理和动态场景建模等挑战，提出了一种改进模型MASSeg，并在CVPR 2025 PVUW Challenge的MOSE赛道中获得第二名。MASSeg基于现有分割框架，构建了增强数据集MOSE+，涵盖遮挡、杂乱背景和小目标实例的典型场景。训练过程中，采用帧间一致和不一致的数据增强策略，以提升模型的鲁棒性和泛化能力；推理阶段则设计了掩码输出缩放策略，适应不同对象大小和遮挡级别。最终，在MOSE测试集上，MASSeg实现了J score 0.8250、F score 0.9007和J&F score 0.8628的优异性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages,4 figures,Technical report on Complex Video Object\n  Segmentation",
      "pdf_url": "http://arxiv.org/pdf/2504.10254v1",
      "published_date": "2025-04-14 14:15:46 UTC",
      "updated_date": "2025-04-14 14:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:46:47.532189"
    },
    {
      "arxiv_id": "2504.10557v1",
      "title": "The Code Barrier: What LLMs Actually Understand?",
      "title_zh": "翻译失败",
      "authors": [
        "Serge Lionel Nikiema",
        "Jordan Samhi",
        "Abdoul Kader Kaboré",
        "Jacques Klein",
        "Tegawendé F. Bissyandé"
      ],
      "abstract": "Understanding code represents a core ability needed for automating software\ndevelopment tasks. While foundation models like LLMs show impressive results\nacross many software engineering challenges, the extent of their true semantic\nunderstanding beyond simple token recognition remains unclear. This research\nuses code obfuscation as a structured testing framework to evaluate LLMs'\nsemantic understanding capabilities. We methodically apply controlled\nobfuscation changes to source code and measure comprehension through two\ncomplementary tasks: generating accurate descriptions of obfuscated code and\nperforming deobfuscation, a skill with important implications for reverse\nengineering applications.\n  Our testing approach includes 13 cutting-edge models, covering both\ncode-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o)\narchitectures, evaluated on a benchmark created from CodeNet and consisting of\nfiltered 250 Java programming problems and their solutions. Findings show a\nstatistically significant performance decline as obfuscation complexity\nincreases, with unexpected resilience shown by general-purpose models compared\nto their code-focused counterparts. While some models successfully identify\nobfuscation techniques, their ability to reconstruct the underlying program\nlogic remains constrained, suggesting limitations in their semantic\nrepresentation mechanisms. This research introduces a new evaluation approach\nfor assessing code comprehension in language models and establishes empirical\nbaselines for advancing research in security-critical code analysis\napplications such as reverse engineering and adversarial code analysis.",
      "tldr_zh": "本文研究评估了大型语言模型（LLMs）的代码语义理解能力，超越简单 token 识别，通过代码混淆（code obfuscation）作为测试框架，对源代码进行受控修改，并评估模型在生成准确描述和进行 deobfuscation 的任务上的表现。实验涉及13个前沿模型，包括代码专用模型如 StarCoder2 和通用模型如 GPT-4o，使用基于 CodeNet 的基准数据集，包含250个过滤后的 Java 编程问题。结果显示，随着混淆复杂度增加，模型性能显著下降，但通用模型表现出意外的韧性，而代码专用模型的语义表示机制存在局限。总体而言，该研究引入了一种新评估方法，建立经验基准，支持安全关键应用如逆向工程和对抗代码分析的发展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10557v1",
      "published_date": "2025-04-14 14:11:26 UTC",
      "updated_date": "2025-04-14 14:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:47:01.015986"
    },
    {
      "arxiv_id": "2504.13928v1",
      "title": "LLM-Driven NPCs: Cross-Platform Dialogue System for Games and Social Platforms",
      "title_zh": "LLM驱动的NPCs：用于游戏和社会平台的跨平台对话系统",
      "authors": [
        "Li Song"
      ],
      "abstract": "NPCs in traditional games are often limited by static dialogue trees and a\nsingle platform for interaction. To overcome these constraints, this study\npresents a prototype system that enables large language model (LLM)-powered\nNPCs to communicate with players both in the game en vironment (Unity) and on a\nsocial platform (Discord). Dialogue logs are stored in a cloud database\n(LeanCloud), allowing the system to synchronize memory between platforms and\nkeep conversa tions coherent. Our initial experiments show that cross-platform\ninteraction is technically feasible and suggest a solid foundation for future\ndevelopments such as emotional modeling and persistent memory support.",
      "tldr_zh": "该研究提出了一种基于大型语言模型(LLM)驱动的NPC对话系统，旨在解决传统游戏中NPC受限于静态对话树和单一平台的局限性。该系统允许NPC在游戏环境(Unity)和社交平台(Discord)上与玩家进行跨平台互动，通过云数据库(LeanCloud)存储对话日志，实现记忆同步和对话连贯性。初步实验证明了这种交互的可行性，并为未来发展如情感建模和持久记忆支持提供了坚实基础。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13928v1",
      "published_date": "2025-04-14 14:06:26 UTC",
      "updated_date": "2025-04-14 14:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:47:10.530363"
    },
    {
      "arxiv_id": "2504.10556v1",
      "title": "VAE-based Feature Disentanglement for Data Augmentation and Compression in Generalized GNSS Interference Classification",
      "title_zh": "基于 VAE 的特征解耦，用于数据增强和压缩",
      "authors": [
        "Lucas Heublein",
        "Simon Kocher",
        "Tobias Feigl",
        "Alexander Rügamer",
        "Christopher Mutschler",
        "Felix Ott"
      ],
      "abstract": "Distributed learning and Edge AI necessitate efficient data processing,\nlow-latency communication, decentralized model training, and stringent data\nprivacy to facilitate real-time intelligence on edge devices while reducing\ndependency on centralized infrastructure and ensuring high model performance.\nIn the context of global navigation satellite system (GNSS) applications, the\nprimary objective is to accurately monitor and classify interferences that\ndegrade system performance in distributed environments, thereby enhancing\nsituational awareness. To achieve this, machine learning (ML) models can be\ndeployed on low-resource devices, ensuring minimal communication latency and\npreserving data privacy. The key challenge is to compress ML models while\nmaintaining high classification accuracy. In this paper, we propose variational\nautoencoders (VAEs) for disentanglement to extract essential latent features\nthat enable accurate classification of interferences. We demonstrate that the\ndisentanglement approach can be leveraged for both data compression and data\naugmentation by interpolating the lower-dimensional latent representations of\nsignal power. To validate our approach, we evaluate three VAE variants -\nvanilla, factorized, and conditional generative - on four distinct datasets,\nincluding two collected in controlled indoor environments and two real-world\nhighway datasets. Additionally, we conduct extensive hyperparameter searches to\noptimize performance. Our proposed VAE achieves a data compression rate ranging\nfrom 512 to 8,192 and achieves an accuracy up to 99.92%.",
      "tldr_zh": "该论文提出使用 Variational Autoencoders (VAEs) 进行特征解耦，以解决分布式学习和 Edge AI 在 GNSS 干扰分类中的数据压缩和增强挑战，从而实现高效数据处理和隐私保护。方法通过提取关键潜在特征，并利用插值技术进行数据增强和压缩，适用于多种数据集，包括室内控制环境和真实公路场景。实验评估了三种 VAE 变体（vanilla、factorized 和 conditional generative），结果显示数据压缩率达 512 到 8,192，同时实现高达 99.92% 的分类准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "94-05, 82-11",
        "E.0; I.2.0; I.5.4; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10556v1",
      "published_date": "2025-04-14 13:38:00 UTC",
      "updated_date": "2025-04-14 13:38:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:47:23.624101"
    },
    {
      "arxiv_id": "2504.10210v1",
      "title": "Can Competition Enhance the Proficiency of Agents Powered by Large Language Models in the Realm of News-driven Time Series Forecasting?",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Zhang",
        "Yangyang Feng",
        "Daifeng Li",
        "Kexin Zhang",
        "Junlan Chen",
        "Bowen Deng"
      ],
      "abstract": "Multi-agents-based news-driven time series forecasting is considered as a\npotential paradigm shift in the era of large language models (LLMs). The\nchallenge of this task lies in measuring the influences of different news\nevents towards the fluctuations of time series. This requires agents to possess\nstronger abilities of innovative thinking and the identifying misleading logic.\nHowever, the existing multi-agent discussion framework has limited enhancement\non time series prediction in terms of optimizing these two capabilities.\nInspired by the role of competition in fostering innovation, this study embeds\na competition mechanism within the multi-agent discussion to enhance agents'\ncapability of generating innovative thoughts. Furthermore, to bolster the\nmodel's proficiency in identifying misleading information, we incorporate a\nfine-tuned small-scale LLM model within the reflective stage, offering\nauxiliary decision-making support. Experimental results confirm that the\ncompetition can boost agents' capacity for innovative thinking, which can\nsignificantly improve the performances of time series prediction. Similar to\nthe findings of social science, the intensity of competition within this\nframework can influence the performances of agents, providing a new perspective\nfor studying LLMs-based multi-agent systems.",
      "tldr_zh": "这篇论文探讨了在新闻驱动时间序列预测领域，竞争机制是否能提升基于 Large Language Models (LLMs) 的多智能体代理的表现。研究者引入竞争机制到多智能体讨论框架中，以增强代理的创新思考能力，同时在反思阶段整合一个微调过的中小型 LLM 模型，提供辅助决策支持来识别误导信息。实验结果表明，竞争机制显著提高了代理的创新思考水平，从而改善了时间序列预测的性能，并证明了竞争强度对代理表现的影响，提供了一个新的视角来研究 LLMs-based 多智能体系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10210v1",
      "published_date": "2025-04-14 13:25:50 UTC",
      "updated_date": "2025-04-14 13:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:47:35.352532"
    },
    {
      "arxiv_id": "2504.10555v1",
      "title": "Beyond the Generative Learning Trilemma: Generative Model Assessment in Data Scarcity Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Salmè",
        "Lorenzo Tronchin",
        "Rosa Sicilia",
        "Paolo Soda",
        "Valerio Guarrasi"
      ],
      "abstract": "Data scarcity remains a critical bottleneck impeding technological\nadvancements across various domains, including but not limited to medicine and\nprecision agriculture. To address this challenge, we explore the potential of\nDeep Generative Models (DGMs) in producing synthetic data that satisfies the\nGenerative Learning Trilemma: fidelity, diversity, and sampling efficiency.\nHowever, recognizing that these criteria alone are insufficient for practical\napplications, we extend the trilemma to include utility, robustness, and\nprivacy, factors crucial for ensuring the applicability of DGMs in real-world\nscenarios. Evaluating these metrics becomes particularly challenging in\ndata-scarce environments, as DGMs traditionally rely on large datasets to\nperform optimally. This limitation is especially pronounced in domains like\nmedicine and precision agriculture, where ensuring acceptable model performance\nunder data constraints is vital. To address these challenges, we assess the\nGenerative Learning Trilemma in data-scarcity settings using state-of-the-art\nevaluation metrics, comparing three prominent DGMs: Variational Autoencoders\n(VAEs), Generative Adversarial Networks (GANs), and Diffusion Models (DMs).\nFurthermore, we propose a comprehensive framework to assess utility,\nrobustness, and privacy in synthetic data generated by DGMs. Our findings\ndemonstrate varying strengths among DGMs, with each model exhibiting unique\nadvantages based on the application context. This study broadens the scope of\nthe Generative Learning Trilemma, aligning it with real-world demands and\nproviding actionable guidance for selecting DGMs tailored to specific\napplications.",
      "tldr_zh": "这篇论文探讨了在数据稀缺领域（如医学和精密农业）评估 Deep Generative Models (DGMs) 的挑战，扩展了 Generative Learning Trilemma 以包括 fidelity、diversity、sampling efficiency、utility、robustness 和 privacy 等指标，确保模型在实际应用中的可靠性。研究者比较了 Variational Autoencoders (VAEs)、Generative Adversarial Networks (GANs) 和 Diffusion Models (DMs)，并提出一个全面框架来评估这些模型生成的合成数据。结果显示，每种 DGM 都展现出独特优势，取决于应用场景，为选择合适的模型提供实用指导，从而解决数据稀缺对技术进步的阻碍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10555v1",
      "published_date": "2025-04-14 13:15:44 UTC",
      "updated_date": "2025-04-14 13:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:47:48.049392"
    },
    {
      "arxiv_id": "2504.10191v1",
      "title": "Localized Cultural Knowledge is Conserved and Controllable in Large Language Models",
      "title_zh": "本地化文化知识在大语言模型中被保存且可控",
      "authors": [
        "Veniamin Veselovsky",
        "Berke Argin",
        "Benedikt Stroebl",
        "Chris Wendler",
        "Robert West",
        "James Evans",
        "Thomas L. Griffiths",
        "Arvind Narayanan"
      ],
      "abstract": "Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.",
      "tldr_zh": "该研究发现，大型语言模型（LLMs）在生成非英语语言时往往偏向英语中心化响应，但本地文化知识已在其内部被保存且可控。通过提供显式文化上下文，模型能显著提升文化本地化响应的能力，但这会加剧 explicit-implicit localization gap，导致答案多样性减少并倾向于刻板印象。研究者进一步识别了 explicit cultural customization vector，这种向量在多种非英语语言中保持一致，可引导模型从英语文化世界模型转向特定文化世界，同时保留响应多样性和减少刻板印象。该方法为LLMs在翻译、文化自定义等方面的可控应用提供了新途径，并探讨了使其隐式激活的可能性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10191v1",
      "published_date": "2025-04-14 12:53:58 UTC",
      "updated_date": "2025-04-14 12:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:47:59.333422"
    },
    {
      "arxiv_id": "2504.10188v1",
      "title": "Efficient Generative Model Training via Embedded Representation Warmup",
      "title_zh": "翻译失败",
      "authors": [
        "Deyuan Liu",
        "Peng Sun",
        "Xufeng Li",
        "Tao Lin"
      ],
      "abstract": "Diffusion models excel at generating high-dimensional data but fall short in\ntraining efficiency and representation quality compared to self-supervised\nmethods. We identify a key bottleneck: the underutilization of high-quality,\nsemantically rich representations during training notably slows down\nconvergence. Our systematic analysis reveals a critical representation\nprocessing region -- primarily in the early layers -- where semantic and\nstructural pattern learning takes place before generation can occur. To address\nthis, we propose Embedded Representation Warmup (ERW), a plug-and-play\nframework where in the first stage we get the ERW module serves as a warmup\nthat initializes the early layers of the diffusion model with high-quality,\npretrained representations. This warmup minimizes the burden of learning\nrepresentations from scratch, thereby accelerating convergence and boosting\nperformance. Our theoretical analysis demonstrates that ERW's efficacy depends\non its precise integration into specific neural network layers -- termed the\nrepresentation processing region -- where the model primarily processes and\ntransforms feature representations for later generation. We further establish\nthat ERW not only accelerates training convergence but also enhances\nrepresentation quality: empirically, our method achieves a 40$\\times$\nacceleration in training speed compared to REPA, the current state-of-the-art\nmethods. Code is available at https://github.com/LINs-lab/ERW.",
      "tldr_zh": "本研究发现，扩散模型（Diffusion models）在生成高维数据方面表现出色，但训练效率和表示质量不如自监督方法，主要由于早期层对语义丰富表示的利用不足，导致收敛变慢。为此，提出 Embedded Representation Warmup (ERW)，一个即插即用框架，通过在训练第一阶段预热扩散模型的早期层，使用预训练的高质量表示初始化，从而减少从零开始学习表示的负担。理论分析表明，ERW 的有效性依赖于其在表示处理区域的精确集成；实验结果显示，与当前最先进方法 REPA 相比，ERW 实现了 40 倍的训练速度加速，并显著提升了表示质量和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10188v1",
      "published_date": "2025-04-14 12:43:17 UTC",
      "updated_date": "2025-04-14 12:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:48:12.729099"
    },
    {
      "arxiv_id": "2504.10187v1",
      "title": "Deep Reasoning Translation via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaan Wang",
        "Fandong Meng",
        "Jie Zhou"
      ],
      "abstract": "Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown\npromising performance in various complex tasks. Free translation is an\nimportant and interesting task in the multilingual world, which requires going\nbeyond word-for-word translation and taking cultural differences into account.\nThis task is still under-explored in deep reasoning LLMs. In this paper, we\nintroduce DeepTrans, a deep reasoning translation model that learns free\ntranslation via reinforcement learning. Specifically, we carefully build a\nreward model with pre-defined scoring criteria on both the translation results\nand the thought process. Given the source sentences, the reward model teaches\nthe deep translation model how to think and free-translate them during\nreinforcement learning. In this way, training DeepTrans does not need any\nlabeled translations, avoiding the human-intensive annotation or\nresource-intensive data synthesis. Experimental results show the effectiveness\nof DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance\nby 16.3% in literature translation, and outperforms strong deep reasoning\nbaselines as well as baselines that are fine-tuned with synthesized data.\nMoreover, we summarize the failures and interesting findings during our RL\nexploration. We hope this work could inspire other researchers in free\ntranslation.",
      "tldr_zh": "这篇论文引入了 DeepTrans，一种通过 Reinforcement Learning 进行深度推理翻译的模型，旨在处理自由翻译任务（如考虑文化差异而非逐字翻译）。该模型构建了一个奖励模型（reward model）来评估翻译结果和思考过程，从而在强化学习中指导模型思考和生成翻译，而无需任何标记的训练数据。实验结果显示，使用 Qwen2.5-7B 作为基础模型，DeepTrans 在文学翻译上提升了 16.3% 的性能，并超过了其他深度推理基线和使用合成数据微调的模型。此外，作者总结了训练中的失败和有趣发现，以期激发更多自由翻译研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10187v1",
      "published_date": "2025-04-14 12:40:39 UTC",
      "updated_date": "2025-04-14 12:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:48:23.725814"
    },
    {
      "arxiv_id": "2504.10185v2",
      "title": "LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Soumyadeep Pal",
        "Changsheng Wang",
        "James Diffenderfer",
        "Bhavya Kailkhura",
        "Sijia Liu"
      ],
      "abstract": "Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.",
      "tldr_zh": "本文研究发现，在当前LLM unlearning基准（如WMDP和MUSE）中，存在一个比预期更强的coreset effect，即使用forget set的极小子集（如5%随机选择）即可维持有效的unlearning效果，同时保留模型的通用性。实验证明，这种效果在不同unlearning方法（如NPO和RMU）以及数据选择策略中均高度鲁棒。作者通过关键词分析解释了这一现象，表明unlearning主要由forget set中的高影响tokens驱动，而非整个数据集。此外，coreset-unlearned模型在mode connectivity和对jailbreaking attacks的鲁棒性方面也表现出忠诚度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10185v2",
      "published_date": "2025-04-14 12:38:37 UTC",
      "updated_date": "2025-04-16 14:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:48:35.925295"
    },
    {
      "arxiv_id": "2504.10179v1",
      "title": "The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Anwesha Mohanty",
        "Venkatesh Balavadhani Parthasarathy",
        "Arsalan Shahid"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.",
      "tldr_zh": "本研究对七种提示工程方法（包括 Zero-Shot、Few-Shot、Chain-of-Thought 等）在 13 个开源 MLLM（多模态大语言模型）上的表现进行了全面实验评估，涵盖 24 个任务，如推理、代码生成和知识检索。模型按参数规模分为小（<4B）、中（4B-10B）和大（>10B）类别，结果显示大模型在结构化任务如代码生成中可达 96.88% 准确率，但所有模型在复杂推理和抽象理解上准确率低于 60%，并伴随高达 75% 的幻觉率和延长响应时间。研究强调，没有单一方法适用于所有任务，建议采用自适应策略结合示例指导和选择性结构化推理，以提升 MLLM 的鲁棒性、效率和事实准确性，从而支持其在 AI 辅助编码和多模态理解等应用中的可靠部署。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10179v1",
      "published_date": "2025-04-14 12:31:39 UTC",
      "updated_date": "2025-04-14 12:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:48:51.205804"
    },
    {
      "arxiv_id": "2504.10168v1",
      "title": "HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed A. Abdallah",
        "Samhaa R. El-Beltagy"
      ],
      "abstract": "In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.",
      "tldr_zh": "本研究介绍了 HalluSearch，一种基于搜索增强的 RAG 管道，用于检测大型语言模型 (LLM) 输出中的虚构文本片段，作为 SemEval-2025 Task 3 和 Mu-SHROOM 项目的一部分。HalluSearch 通过检索增强验证 (retrieval-augmented verification) 和细粒度事实分割 (fine-grained factual splitting) 的结合，在 14 种语言中识别和定位幻觉。实验结果显示，该系统在英语和捷克语中表现出色，排名第四（英语在前十百分比内），但在在线覆盖有限的语言中面临挑战，强调了进一步研究以实现跨语言一致性的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10168v1",
      "published_date": "2025-04-14 12:22:30 UTC",
      "updated_date": "2025-04-14 12:22:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:48:59.237028"
    },
    {
      "arxiv_id": "2504.10167v1",
      "title": "C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Zhang",
        "Zhifei Liu",
        "Jiahao Wang",
        "Huixuan Zhang",
        "Fan Xu",
        "Junzhe Zhang",
        "Xiaojun Wan"
      ],
      "abstract": "Despite the rapid advancement of large language models, they remain highly\nsusceptible to generating hallucinations, which significantly hinders their\nwidespread application. Hallucination research requires dynamic and\nfine-grained evaluation. However, most existing hallucination benchmarks\n(especially in Chinese language) rely on human annotations, making automatical\nand cost-effective hallucination evaluation challenging. To address this, we\nintroduce HaluAgent, an agentic framework that automatically constructs\nfine-grained QA dataset based on some knowledge documents. Our experiments\ndemonstrate that the manually designed rules and prompt optimization can\nimprove the quality of generated data. Using HaluAgent, we construct C-FAITH, a\nChinese QA hallucination benchmark created from 1,399 knowledge documents\nobtained from web scraping, totaling 60,702 entries. We comprehensively\nevaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed\nexperimental results and analysis.",
      "tldr_zh": "该研究针对大语言模型(LLMs)易产生幻觉的问题，提出HaluAgent框架，该框架通过手动设计的规则和提示优化自动构建细粒度的QA数据集，以解决现有中文幻觉基准依赖人工标注的局限性。利用HaluAgent，他们基于1,399个网络抓取的知识文档创建了C-FAITH基准，总计60,702条中文QA条目，用于动态评估LLMs的幻觉。实验结果显示，该基准对16个主流LLMs进行了全面评估，提供详细分析，为自动化幻觉评估提供了高效工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10167v1",
      "published_date": "2025-04-14 12:21:55 UTC",
      "updated_date": "2025-04-14 12:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:49:11.447155"
    },
    {
      "arxiv_id": "2504.10165v2",
      "title": "WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs",
      "title_zh": "翻译失败",
      "authors": [
        "Nguyen Ngoc Dat",
        "Tom Richardson",
        "Matthew Watson",
        "Kilian Meier",
        "Jenna Kline",
        "Sid Reid",
        "Guy Maalouf",
        "Duncan Hine",
        "Majid Mirmehdi",
        "Tilo Burghardt"
      ],
      "abstract": "Live tracking of wildlife via high-resolution video processing directly\nonboard drones is widely unexplored and most existing solutions rely on\nstreaming video to ground stations to support navigation. Yet, both autonomous\nanimal-reactive flight control beyond visual line of sight and/or\nmission-specific individual and behaviour recognition tasks rely to some degree\non this capability. In response, we introduce WildLive -- a near real-time\nanimal detection and tracking framework for high-resolution imagery running\ndirectly onboard uncrewed aerial vehicles (UAVs). The system performs\nmulti-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video\nstreams suitable for operation during higher altitude flights to minimise\nanimal disturbance. Our system is optimised for Jetson Orin AGX onboard\nhardware. It integrates the efficiency of sparse optical flow tracking and\nmission-specific sampling with device-optimised and proven YOLO-driven object\ndetection and segmentation techniques. Essentially, computational resource is\nfocused onto spatio-temporal regions of high uncertainty to significantly\nimprove UAV processing speeds without domain-specific loss of accuracy.\nAlongside, we introduce our WildLive dataset, which comprises 200k+ annotated\nanimal instances across 19k+ frames from 4K UAV videos collected at the Ol\nPejeta Conservancy in Kenya. All frames contain ground truth bounding boxes,\nsegmentation masks, as well as individual tracklets and tracking point\ntrajectories. We compare our system against current object tracking approaches\nincluding OC-SORT, ByteTrack, and SORT. Our materials are available at:\nhttps://dat-nguyenvn.github.io/WildLive/",
      "tldr_zh": "本文提出 WildLive，一种在无人机(UAVs)上实现近实时野生动物检测和跟踪的框架，旨在解决现有系统依赖视频流传输到地面站的局限性。该框架整合 sparse optical flow tracking 和 YOLO-driven object detection 与 segmentation 技术，优化资源分配于高不确定性区域，实现 HD 视频 17fps+ 和 4K 视频 7fps+ 的处理速度，同时保持准确性。研究还发布了 WildLive 数据集，包含 20 万+ 标注动物实例的 4K UAV 视频，并通过与 OC-SORT、ByteTrack 和 SORT 等方法比较，证明了其在野生动物跟踪任务中的显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10165v2",
      "published_date": "2025-04-14 12:21:16 UTC",
      "updated_date": "2025-04-15 12:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:49:24.276822"
    },
    {
      "arxiv_id": "2504.10160v1",
      "title": "MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning",
      "title_zh": "MT",
      "authors": [
        "Zhaopeng Feng",
        "Shaosheng Cao",
        "Jiahan Ren",
        "Jiayuan Su",
        "Ruizhe Chen",
        "Yan Zhang",
        "Zhe Xu",
        "Yao Hu",
        "Jian Wu",
        "Zuozhu Liu"
      ],
      "abstract": "Large-scale reinforcement learning (RL) methods have proven highly effective\nin enhancing the reasoning abilities of large language models (LLMs),\nparticularly for tasks with verifiable solutions such as mathematics and\ncoding. However, applying this idea to machine translation (MT), where outputs\nare flexibly formatted and difficult to automatically evaluate with explicit\nrules, remains underexplored. In this work, we introduce MT-R1-Zero, the first\nopen-source adaptation of the R1-Zero RL framework for MT without supervised\nfine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to\nguide LLMs towards improved translation quality via emergent reasoning. On the\nWMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive\nperformance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points.\nMeanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across\nall metrics, placing it on par with advanced proprietary models such as GPT-4o\nand Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves\nstate-of-the-art scores on semantic metrics. Moreover, our work exhibits strong\ngeneralization capabilities on out-of-distribution MT tasks, robustly\nsupporting multilingual and low-resource settings. Extensive analysis of model\nbehavior across different initializations and reward metrics offers pioneering\ninsight into the critical role of reward design, LLM adaptability, training\ndynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT.\nOur code is available at https://github.com/fzp0424/MT-R1-Zero.",
      "tldr_zh": "本论文提出 MT-R1-Zero，一种基于 R1-Zero-like Reinforcement Learning 的开源框架，用于提升大型语言模型 (LLMs) 在机器翻译 (MT) 中的性能，而无需监督微调或冷启动，通过 rule-metric mixed reward 机制促进 emergent reasoning。实验结果显示，在 WMT 24 English-Chinese 基准上，MT-R1-Zero-3B-Mix 比 TowerInstruct-7B-v0.2 高出 1.26 分，而 MT-R1-Zero-7B-Mix 达到 62.25 分的平均分数，与 GPT-4o 和 Claude-3.5-Sonnet 相当，并在语义指标上实现 state-of-the-art 表现。该框架还展示了在多语言和低资源设置下的强泛化能力，并通过对奖励设计和模型行为的深入分析，提供对 R1-Zero 范式在 MT 中的关键洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Our code is available at\n  https://github.com/fzp0424/MT-R1-Zero",
      "pdf_url": "http://arxiv.org/pdf/2504.10160v1",
      "published_date": "2025-04-14 12:14:18 UTC",
      "updated_date": "2025-04-14 12:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:49:37.479523"
    },
    {
      "arxiv_id": "2504.10158v1",
      "title": "COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts",
      "title_zh": "COUNTS：分布偏移下的物体检测器和多模态大型语言模型基准测试",
      "authors": [
        "Jiansheng Li",
        "Xingxuan Zhang",
        "Hao Zou",
        "Yige Guo",
        "Renzhe Xu",
        "Yilong Liu",
        "Chuzhao Zhu",
        "Yue He",
        "Peng Cui"
      ],
      "abstract": "Current object detectors often suffer significant perfor-mance degradation in\nreal-world applications when encountering distributional shifts. Consequently,\nthe out-of-distribution (OOD) generalization capability of object detectors has\ngarnered increasing attention from researchers. Despite this growing interest,\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\nbenchmark with fine-grained annotations tailored to assess the OOD\ngeneralization on more intricate tasks like object detection and grounding. To\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\nto comprehensively evaluate the OOD generalization capabilities of object\ndetectors by utilizing controlled distribution shifts between training and\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\ngrounding abilities in multimodal large language models (MLLMs). Our findings\nreveal that, while large models and extensive pre-training data substantially\nen hance performance in in-distribution (IID) scenarios, significant\nlimitations and opportunities for improvement persist in OOD contexts for both\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\nCOUNTS facilitates advancements in the development and assessment of robust\nobject detectors and MLLMs capable of maintaining high performance under\ndistributional shifts.",
      "tldr_zh": "该研究针对对象检测器和多模态大语言模型(MLLMs)在分布偏移(Out-of-Distribution, OOD)下的性能下降问题，引入了一个大规模数据集COUNTS，以评估其OOD泛化能力。COUNTS包含14种自然分布偏移、超过222K样本和1.196M标注边界框，并基于此开发了两个新基准：O(OD)2用于测试对象检测器的OOD泛化，通过控制训练和测试数据的分布差异；OODG则评估MLLMs的定位能力的OOD性能。实验结果显示，虽然大模型在同分布(In-Distribution, IID)场景下表现良好，但在大模型如GPT-4o和Gemini-1.5的视觉定位任务中，准确率仅为56.7%和28.0%，暴露出显著的局限性。该基准有望推动开发更鲁棒的对象检测器和MLLMs，以应对真实世界的分布偏移挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10158v1",
      "published_date": "2025-04-14 12:13:33 UTC",
      "updated_date": "2025-04-14 12:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:49:48.576004"
    },
    {
      "arxiv_id": "2504.10149v2",
      "title": "BoTTA: Benchmarking on-device Test Time Adaptation",
      "title_zh": "BoTTA：设备上测试时适应的基准测试",
      "authors": [
        "Michal Danilowski",
        "Soumyajit Chatterjee",
        "Abhirup Ghosh"
      ],
      "abstract": "The performance of deep learning models depends heavily on test samples at\nruntime, and shifts from the training data distribution can significantly\nreduce accuracy. Test-time adaptation (TTA) addresses this by adapting models\nduring inference without requiring labeled test data or access to the original\ntraining set. While research has explored TTA from various perspectives like\nalgorithmic complexity, data and class distribution shifts, model\narchitectures, and offline versus continuous learning, constraints specific to\nmobile and edge devices remain underexplored. We propose BoTTA, a benchmark\ndesigned to evaluate TTA methods under practical constraints on mobile and edge\ndevices. Our evaluation targets four key challenges caused by limited resources\nand usage conditions: (i) limited test samples, (ii) limited exposure to\ncategories, (iii) diverse distribution shifts, and (iv) overlapping shifts\nwithin a sample. We assess state-of-the-art TTA methods under these scenarios\nusing benchmark datasets and report system-level metrics on a real testbed.\nFurthermore, unlike prior work, we align with on-device requirements by\nadvocating periodic adaptation instead of continuous inference-time adaptation.\nExperiments reveal key insights: many recent TTA algorithms struggle with small\ndatasets, fail to generalize to unseen categories, and depend on the diversity\nand complexity of distribution shifts. BoTTA also reports device-specific\nresource use. For example, while SHOT improves accuracy by $2.25\\times$ with\n$512$ adaptation samples, it uses $1.08\\times$ peak memory on Raspberry Pi\nversus the base model. BoTTA offers actionable guidance for TTA in real-world,\nresource-constrained deployments.",
      "tldr_zh": "该研究提出BoTTA基准，用于评估Test Time Adaptation (TTA)方法在移动和边缘设备上的性能，TTA旨在通过推理时模型适应来应对测试数据分布偏移，而无需标记数据或原始训练集。BoTTA针对四大挑战进行测试，包括有限测试样本、有限类别暴露、多样化分布偏移以及样本内重叠偏移，并使用基准数据集报告系统级指标，同时倡导周期性适应以符合设备资源限制。实验结果显示，许多TTA算法在小数据集上表现不佳，无法泛化到未见类别，且依赖分布偏移的复杂性；例如，SHOT在某些场景下准确率提升2.25倍，但会增加Raspberry Pi的峰值内存使用1.08倍，提供宝贵指导用于资源受限的实际部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10149v2",
      "published_date": "2025-04-14 12:00:00 UTC",
      "updated_date": "2025-04-16 13:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:50:00.012522"
    },
    {
      "arxiv_id": "2504.10146v2",
      "title": "GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions",
      "title_zh": "GeoUni: 用于生成几何图形、问题和问题解答的统一模型",
      "authors": [
        "Jo-Ku Cheng",
        "Zeren Zhang",
        "Ran Chen",
        "Jingyang Deng",
        "Ziran Qin",
        "Jinwen Ma"
      ],
      "abstract": "We propose GeoUni, the first unified geometry expert model capable of\ngenerating problem solutions and diagrams within a single framework in a way\nthat enables the creation of unique and individualized geometry problems.\nTraditionally, solving geometry problems and generating diagrams have been\ntreated as separate tasks in machine learning, with no models successfully\nintegrating both to support problem creation. However, we believe that mastery\nin geometry requires frictionless integration of all of these skills, from\nsolving problems to visualizing geometric relationships, and finally, crafting\ntailored problems. Our extensive experiments demonstrate that GeoUni, with only\n1.5B parameters, achieves performance comparable to larger models such as\nDeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni also\nexcels in generating precise geometric diagrams, surpassing both text-to-image\nmodels and unified models, including the GPT-4o image generation. Most\nimportantly, GeoUni is the only model capable of successfully generating\ntextual problems with matching diagrams based on specific knowledge points,\nthus offering a wider range of capabilities that extend beyond current models.",
      "tldr_zh": "该研究提出 GeoUni，这是一个统一的几何专家模型，能够在一个框架内生成几何图表、问题和解决方案，从而支持创建独特且个性化的几何问题。传统上，几何问题解决和图表生成被视为独立任务，而 GeoUni 首次整合这些技能，包括问题解决、可视化几何关系和问题制作，仅使用 1.5B 参数。实验结果显示，GeoUni 在几何推理任务中表现与更大模型如 DeepSeek-R1 (671B 参数) 相当，并在生成精确几何图表方面超越文本到图像模型和 GPT-4o。最重要的是，GeoUni 是唯一能基于特定知识点生成匹配文本问题和图表的模型，扩展了几何任务处理的能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10146v2",
      "published_date": "2025-04-14 11:56:55 UTC",
      "updated_date": "2025-05-08 14:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:50:12.700560"
    },
    {
      "arxiv_id": "2504.10127v2",
      "title": "Breaking the Data Barrier -- Building GUI Agents Through Task Generalization",
      "title_zh": "打破数据壁垒——通过任务",
      "authors": [
        "Junlei Zhang",
        "Zichen Ding",
        "Chang Ma",
        "Zijie Chen",
        "Qiushi Sun",
        "Zhenzhong Lan",
        "Junxian He"
      ],
      "abstract": "Graphical User Interface (GUI) agents offer cross-platform solutions for\nautomating complex digital tasks, with significant potential to transform\nproductivity workflows. However, their performance is often constrained by the\nscarcity of high-quality trajectory data. To address this limitation, we\npropose training Vision Language Models (VLMs) on data-rich,\nreasoning-intensive tasks during a dedicated mid-training stage, and then\nexamine how incorporating these tasks facilitates generalization to GUI\nplanning scenarios. Specifically, we explore a range of tasks with readily\navailable instruction-tuning data, including GUI perception, multimodal\nreasoning, and textual reasoning. Through extensive experiments across 11\nmid-training tasks, we demonstrate that: (1) Task generalization proves highly\neffective, yielding substantial improvements across most settings. For\ninstance, multimodal mathematical reasoning enhances performance on\nAndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data\nsignificantly boosts GUI web agent performance, achieving a 5.6% improvement on\nWebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal\ngeneralization from text-based to visual domains; (2) Contrary to prior\nassumptions, GUI perception data - previously considered closely aligned with\nGUI agent tasks and widely utilized for training - has a comparatively limited\nimpact on final performance; (3) Building on these insights, we identify the\nmost effective mid-training tasks and curate optimized mixture datasets,\nresulting in absolute performance gains of 8.0% on WebArena and 12.2% on\nAndroidWorld. Our work provides valuable insights into cross-domain knowledge\ntransfer for GUI agents and offers a practical approach to addressing data\nscarcity challenges in this emerging field. The code, data and models will be\navailable at https://github.com/hkust-nlp/GUIMid.",
      "tldr_zh": "这篇论文解决了图形用户界面 (GUI) 代理在自动化复杂数字任务时面临的数据稀缺问题，通过在中间训练阶段训练 Vision Language Models (VLMs) 于数据丰富的推理密集型任务（如 GUI 感知、多模态推理和文本推理），以提升任务泛化能力。实验结果显示，任务泛化高度有效，例如多模态数学推理使 AndroidWorld 性能提升 6.3%，而文本-only 数据也实现了跨模态提升，在 WebArena 和 AndroidWorld 上分别提高 5.6% 和 5.4%。与预期相反，GUI 感知数据对最终性能的影响有限。最终，该研究通过优化任务混合数据集，实现了 WebArena 提升 8.0% 和 AndroidWorld 提升 12.2%，并为 GUI 代理的跨域知识转移提供了实用见解和公开资源。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10127v2",
      "published_date": "2025-04-14 11:35:02 UTC",
      "updated_date": "2025-04-15 17:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:50:24.320131"
    },
    {
      "arxiv_id": "2504.10112v1",
      "title": "Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Happe",
        "Jürgen Cito"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as a powerful approach for driving\noffensive penetration-testing tooling. This paper analyzes the methodology and\nbenchmarking practices used for evaluating Large Language Model (LLM)-driven\nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16\nresearch papers detailing 15 prototypes and their respective testbeds.\n  We detail our findings and provide actionable recommendations for future\nresearch, emphasizing the importance of extending existing testbeds, creating\nbaselines, and including comprehensive metrics and qualitative analysis. We\nalso note the distinction between security research and practice, suggesting\nthat CTF-based challenges may not fully represent real-world penetration\ntesting scenarios.",
      "tldr_zh": "该论文分析了Large Language Models (LLMs) 在进攻性安全领域的基准测试实践，聚焦于LLM驱动的渗透测试工具，包括测试床、指标和实验设计。通过审查16篇研究论文和15个原型，作者提出了可操作的推荐，如扩展现有测试床、创建基准，以及整合全面指标和定性分析。研究还强调了安全研究与实际应用的区别，指出CTF-based挑战可能无法完全反映真实世界的渗透测试场景，从而为未来LLM安全研究提供了指导。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10112v1",
      "published_date": "2025-04-14 11:21:33 UTC",
      "updated_date": "2025-04-14 11:21:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:50:35.114795"
    },
    {
      "arxiv_id": "2504.10109v1",
      "title": "Lightweight Trustworthy Distributed Clustering",
      "title_zh": "轻量级可信分布式聚类",
      "authors": [
        "Hongyang Li",
        "Caesar Wu",
        "Mohammed Chadli",
        "Said Mammar",
        "Pascal Bouvry"
      ],
      "abstract": "Ensuring data trustworthiness within individual edge nodes while facilitating\ncollaborative data processing poses a critical challenge in edge computing\nsystems (ECS), particularly in resource-constrained scenarios such as\nautonomous systems sensor networks, industrial IoT, and smart cities. This\npaper presents a lightweight, fully distributed k-means clustering algorithm\nspecifically adapted for edge environments, leveraging a distributed averaging\napproach with additive secret sharing, a secure multiparty computation\ntechnique, during the cluster center update phase to ensure the accuracy and\ntrustworthiness of data across nodes.",
      "tldr_zh": "该论文针对边缘计算系统中数据可信性挑战，提出了一种轻量级的、全分布式的 k-means 聚类算法，适用于资源受限环境，如自主系统传感器网络、工业 IoT 和智能城市。算法在聚类中心更新阶段采用分布式 averaging approach 和 additive secret sharing（一种 secure multiparty computation 技术），以确保节点间数据处理的准确性和可信性。通过这种方法，论文为协作式边缘数据处理提供了高效、安全的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10109v1",
      "published_date": "2025-04-14 11:16:07 UTC",
      "updated_date": "2025-04-14 11:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:50:47.491995"
    },
    {
      "arxiv_id": "2504.10106v1",
      "title": "SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Gutiérrez-Pérez",
        "Antonio Agudo"
      ],
      "abstract": "Sports video analysis is a key domain in computer vision, enabling detailed\nspatial understanding through multi-view correspondences. In this work, we\nintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets\ndesigned for 3D scene understanding in soccer broadcast analysis. These\ndatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera\ncalibration and multi-view synchronization, enabling 3D object localization\nthrough triangulation. We propose a monocular 3D ball localization task built\nupon the triangulation of ground-truth 2D ball annotations, along with several\ncalibration and reprojection metrics to assess annotation quality on demand.\nAdditionally, we present a single-image 3D ball localization method as a\nbaseline, leveraging camera calibration and ball size priors to estimate the\nball's position from a monocular viewpoint. To further refine 2D annotations,\nwe introduce a bounding box optimization technique that ensures alignment with\nthe 3D scene representation. Our proposed datasets establish new benchmarks for\n3D soccer scene understanding, enhancing both spatial and temporal analysis in\nsports analytics. Finally, we provide code to facilitate access to our\nannotations and the generation pipelines for the datasets.",
      "tldr_zh": "这篇论文引入了SoccerNet-v3D和ISSIA-3D两个增强型数据集，用于足球广播分析中的3D场景理解，这些数据集扩展了原有版本，通过场线-based camera calibration和multi-view synchronization实现了3D对象定位(triangulation)。论文提出一个monocular 3D ball localization任务，基于ground-truth 2D球注解进行三角测量，并提供了一个单图像3D球定位方法作为基准，利用camera calibration和ball size priors来估计球的位置，同时引入bounding box optimization技术来精炼2D注解。总体上，这些数据集建立了新的基准，提升了体育视频分析的空间和时间精度，并提供了代码以便访问和生成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2; I.4; I.5"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10106v1",
      "published_date": "2025-04-14 11:15:13 UTC",
      "updated_date": "2025-04-14 11:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:51:00.918448"
    },
    {
      "arxiv_id": "2504.10081v1",
      "title": "RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning Capability",
      "title_zh": "翻译失败",
      "authors": [
        "Yichi Zhang",
        "Zihao Zeng",
        "Dongbai Li",
        "Yao Huang",
        "Zhijie Deng",
        "Yinpeng Dong"
      ],
      "abstract": "Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.",
      "tldr_zh": "该研究针对 Large Reasoning Models (LRMs) 如 DeepSeek-R1 的安全问题，提出了 RealSafe-R1，这是一个安全对齐的蒸馏模型版本，旨在抵御恶意查询和越狱攻击。研究团队构建了15k个安全aware推理轨迹数据集，由 DeepSeek-R1 生成，并通过明确拒绝行为的指令进行训练。实验和案例研究表明，RealSafe-R1 显著提升了安全性能，同时不影响模型的推理能力，因为训练数据保持在原生成分布内。模型权重已在 Hugging Face 上开源。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10081v1",
      "published_date": "2025-04-14 10:26:37 UTC",
      "updated_date": "2025-04-14 10:26:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:51:11.980380"
    },
    {
      "arxiv_id": "2504.10077v1",
      "title": "Towards Quantifying Commonsense Reasoning with Mechanistic Insights",
      "title_zh": "迈向通过机制洞见的常识推理量化",
      "authors": [
        "Abhinav Joshi",
        "Areeb Ahmad",
        "Divyaksh Shukla",
        "Ashutosh Modi"
      ],
      "abstract": "Commonsense reasoning deals with the implicit knowledge that is well\nunderstood by humans and typically acquired via interactions with the world. In\nrecent times, commonsense reasoning and understanding of various LLMs have been\nevaluated using text-based tasks. In this work, we argue that a proxy of this\nunderstanding can be maintained as a graphical structure that can further help\nto perform a rigorous evaluation of commonsense reasoning abilities about\nvarious real-world activities. We create an annotation scheme for capturing\nthis implicit knowledge in the form of a graphical structure for 37 daily human\nactivities. We find that the created resource can be used to frame an enormous\nnumber of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of\ncommonsense reasoning in LLMs. Moreover, recently, the remarkable performance\nof LLMs has raised questions about whether these models are truly capable of\nreasoning in the wild and, in general, how reasoning occurs inside these\nmodels. In this resource paper, we bridge this gap by proposing design\nmechanisms that facilitate research in a similar direction. Our findings\nsuggest that the reasoning components are localized in LLMs that play a\nprominent role in decision-making when prompted with a commonsense query.",
      "tldr_zh": "本论文探讨了如何通过机制洞察（Mechanistic Insights）量化常识推理（Commonsense Reasoning），即人类通过世界互动获得的隐性知识。作者提出使用图形结构来表示这种知识，并为37种日常人类活动创建了相应的注释方案，以生成大量常识查询（约10^{17}个），从而实现对大型语言模型（LLMs）的严格评估。研究发现，LLMs中的推理组件是局域化的，并在处理常识查询时发挥关键决策作用，为深入理解模型的真实推理能力提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025; 28 pages (9 pages + 7 pages references + 12\n  pages appendix)",
      "pdf_url": "http://arxiv.org/pdf/2504.10077v1",
      "published_date": "2025-04-14 10:21:59 UTC",
      "updated_date": "2025-04-14 10:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:51:24.073313"
    },
    {
      "arxiv_id": "2504.10074v3",
      "title": "MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Ling",
        "Zhiyao Guo",
        "Yixuan Huang",
        "Yi An",
        "Shuai Xiao",
        "Jinsong Lan",
        "Xiaoyong Zhu",
        "Bo Zheng"
      ],
      "abstract": "Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2% on the Single-Hop subset and\n+0.4% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8% on the Unseen-Q subset, +8.2% on the Unseen-E subset, and +8.1% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.",
      "tldr_zh": "该研究提出 MMKB-RAG，一种新型多模态知识驱动的检索增强生成框架，旨在解决大型语言模型（LLMs）和多模态 LLMs 依赖参数知识的问题，从而减少生成过时或错误信息。该框架通过利用模型的固有知识边界动态生成语义标签，并对检索文档进行联合过滤，只保留最相关和准确的引用。在知识驱动的视觉问答任务上，实验结果显示 MMKB-RAG 在 E-VQA 数据集上提升 4.2%（Single-Hop 子集）和 0.4%（全数据集），而在 InfoSeek 数据集上分别提升 7.8%（Unseen-Q 子集）、8.2%（Unseen-E 子集）和 8.1%（全数据集），显著提高了准确性和鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10074v3",
      "published_date": "2025-04-14 10:19:47 UTC",
      "updated_date": "2025-04-20 17:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:51:36.398133"
    },
    {
      "arxiv_id": "2504.10071v1",
      "title": "Pay Attention to What and Where? Interpretable Feature Extractor in Vision-based Deep Reinforcement Learning",
      "title_zh": "关注什么和哪里？ 基于视觉的深度强化学习中的可解释特征提取器",
      "authors": [
        "Tien Pham",
        "Angelo Cangelosi"
      ],
      "abstract": "Current approaches in Explainable Deep Reinforcement Learning have\nlimitations in which the attention mask has a displacement with the objects in\nvisual input. This work addresses a spatial problem within traditional\nConvolutional Neural Networks (CNNs). We propose the Interpretable Feature\nExtractor (IFE) architecture, aimed at generating an accurate attention mask to\nillustrate both \"what\" and \"where\" the agent concentrates on in the spatial\ndomain. Our design incorporates a Human-Understandable Encoding module to\ngenerate a fully interpretable attention mask, followed by an Agent-Friendly\nEncoding module to enhance the agent's learning efficiency. These two\ncomponents together form the Interpretable Feature Extractor for vision-based\ndeep reinforcement learning to enable the model's interpretability. The\nresulting attention mask is consistent, highly understandable by humans,\naccurate in spatial dimension, and effectively highlights important objects or\nlocations in visual input. The Interpretable Feature Extractor is integrated\ninto the Fast and Data-efficient Rainbow framework, and evaluated on 57 ATARI\ngames to show the effectiveness of the proposed approach on Spatial\nPreservation, Interpretability, and Data-efficiency. Finally, we showcase the\nversatility of our approach by incorporating the IFE into the Asynchronous\nAdvantage Actor-Critic Model.",
      "tldr_zh": "本研究针对视觉输入中注意力掩码位移问题，提出Interpretable Feature Extractor (IFE)架构，用于基于视觉的Deep Reinforcement Learning中生成准确的注意力掩码，以解释代理关注“什么”和“哪里”。IFE 包括Human-Understandable Encoding模块（生成易于人类理解的注意力掩码）和Agent-Friendly Encoding模块（提升代理学习效率），从而提高模型的解释性和空间精确性。该框架整合到Fast and Data-efficient Rainbow模型中，并在57个ATARI游戏上进行评估，展示了在Spatial Preservation、Interpretability和Data-efficiency方面的显著改进；此外，IFE还成功应用于Asynchronous Advantage Actor-Critic Model，证明其通用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10071v1",
      "published_date": "2025-04-14 10:18:34 UTC",
      "updated_date": "2025-04-14 10:18:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:51:47.535334"
    },
    {
      "arxiv_id": "2504.10068v1",
      "title": "Mavors: Multi-granularity Video Representation for Multimodal Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Shi",
        "Jiaheng Liu",
        "Yushuo Guan",
        "Zhenhua Wu",
        "Yuanxing Zhang",
        "Zihao Wang",
        "Weihong Lin",
        "Jingyun Hua",
        "Zekun Wang",
        "Xinlong Chen",
        "Bohan Zeng",
        "Wentao Zhang",
        "Fuzheng Zhang",
        "Wenjing Yang",
        "Di Zhang"
      ],
      "abstract": "Long-context video understanding in multimodal large language models (MLLMs)\nfaces a critical challenge: balancing computational efficiency with the\nretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,\nsparse sampling, dense sampling with low resolution, and token compression)\nsuffer from significant information loss in temporal dynamics, spatial details,\nor subtle interactions, particularly in videos with complex motion or varying\nresolutions. To address this, we propose $\\mathbf{Mavors}$, a novel framework\nthat introduces $\\mathbf{M}$ulti-gr$\\mathbf{a}$nularity\n$\\mathbf{v}$ide$\\mathbf{o}$ $\\mathbf{r}$epre$\\mathbf{s}$entation for holistic\nlong-video modeling. Specifically, Mavors directly encodes raw video content\ninto latent representations through two core components: 1) an Intra-chunk\nVision Encoder (IVE) that preserves high-resolution spatial features via 3D\nconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator\n(IFA) that establishes temporal coherence across chunks using transformer-based\ndependency modeling with chunk-level rotary position encodings. Moreover, the\nframework unifies image and video understanding by treating images as\nsingle-frame videos via sub-image decomposition. Experiments across diverse\nbenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity\nand temporal continuity, significantly outperforming existing methods in tasks\nrequiring fine-grained spatio-temporal reasoning.",
      "tldr_zh": "该论文提出 Mavors 框架，用于多模态大语言模型（MLLMs）的多粒度视频表示，旨在解决长视频理解中计算效率与保留细粒度时空模式之间的平衡问题，避免现有方法（如稀疏采样或令牌压缩）导致的信息损失。框架的核心组件包括 Intra-chunk Vision Encoder (IVE)，通过3D卷积和Vision Transformers保留高分辨率空间特征，以及 Inter-chunk Feature Aggregator (IFA)，利用Transformer-based依赖建模和chunk-level旋转位置编码建立时间连贯性。此外，Mavors 通过将图像视为单帧视频进行子图像分解，实现图像和视频理解的统一，并在各种基准测试中表现出色，显著优于现有方法，尤其在细粒度时空推理任务上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10068v1",
      "published_date": "2025-04-14 10:14:44 UTC",
      "updated_date": "2025-04-14 10:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:52:00.666748"
    },
    {
      "arxiv_id": "2504.10063v2",
      "title": "Hallucination Detection in LLMs with Topological Divergence on Attention Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandra Bazarova",
        "Aleksandr Yugay",
        "Andrey Shulga",
        "Alina Ermilova",
        "Andrei Volodichev",
        "Konstantin Polev",
        "Julia Belikova",
        "Rauf Parchiev",
        "Dmitry Simakov",
        "Maxim Savchenko",
        "Andrey Savchenko",
        "Serguei Barannikov",
        "Alexey Zaytsev"
      ],
      "abstract": "Hallucination, i.e., generating factually incorrect content, remains a\ncritical challenge for large language models (LLMs). We introduce TOHA, a\nTOpology-based HAllucination detector in the RAG setting, which leverages a\ntopological divergence metric to quantify the structural properties of graphs\ninduced by attention matrices. Examining the topological divergence between\nprompt and response subgraphs reveals consistent patterns: higher divergence\nvalues in specific attention heads correlate with hallucinated outputs,\nindependent of the dataset. Extensive experiments - including evaluation on\nquestion answering and summarization tasks - show that our approach achieves\nstate-of-the-art or competitive results on several benchmarks while requiring\nminimal annotated data and computational resources. Our findings suggest that\nanalyzing the topological structure of attention matrices can serve as an\nefficient and robust indicator of factual reliability in LLMs.",
      "tldr_zh": "本论文提出 TOHA，一种基于拓扑发散度（topological divergence）的幻觉检测方法，针对大型语言模型（LLMs）在 RAG 设置中生成事实错误内容的问题。它通过分析注意力矩阵诱导的图结构，比较提示和响应子图的拓扑差异，发现较高的发散值与幻觉输出高度相关，从而实现高效检测。在问答和总结任务的实验中，TOHA 取得了最先进或竞争性的基准性能，仅需少量标注数据和计算资源，为提升 LLMs 的事实可靠性提供了鲁棒指标。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10063v2",
      "published_date": "2025-04-14 10:06:27 UTC",
      "updated_date": "2025-05-22 12:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:52:12.583477"
    },
    {
      "arxiv_id": "2504.13196v1",
      "title": "Investigating cybersecurity incidents using large language models in latest-generation wireless networks",
      "title_zh": "使用大型语言模型调查最新一代无线网络中的网络安全事件",
      "authors": [
        "Leonid Legashev",
        "Arthur Zhigalov"
      ],
      "abstract": "The purpose of research: Detection of cybersecurity incidents and analysis of\ndecision support and assessment of the effectiveness of measures to counter\ninformation security threats based on modern generative models. The methods of\nresearch: Emulation of signal propagation data in MIMO systems, synthesis of\nadversarial examples, execution of adversarial attacks on machine learning\nmodels, fine tuning of large language models for detecting adversarial attacks,\nexplainability of decisions on detecting cybersecurity incidents based on the\nprompts technique. Scientific novelty: A binary classification of data\npoisoning attacks was performed using large language models, and the\npossibility of using large language models for investigating cybersecurity\nincidents in the latest generation wireless networks was investigated. The\nresult of research: Fine-tuning of large language models was performed on the\nprepared data of the emulated wireless network segment. Six large language\nmodels were compared for detecting adversarial attacks, and the capabilities of\nexplaining decisions made by a large language model were investigated. The\nGemma-7b model showed the best results according to the metrics Precision =\n0.89, Recall = 0.89 and F1-Score = 0.89. Based on various explainability\nprompts, the Gemma-7b model notes inconsistencies in the compromised data under\nstudy, performs feature importance analysis and provides various\nrecommendations for mitigating the consequences of adversarial attacks. Large\nlanguage models integrated with binary classifiers of network threats have\nsignificant potential for practical application in the field of cybersecurity\nincident investigation, decision support and assessing the effectiveness of\nmeasures to counter information security threats.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（Large Language Models, LLMs）在最新一代无线网络中调查网络安全事件，包括检测对抗攻击（adversarial attacks）、决策支持和评估对抗信息安全威胁措施的有效性。研究方法涉及模拟MIMO系统信号传播、合成对抗样本、微调LLMs用于二元分类数据投毒攻击，以及通过提示技术（prompts technique）解释决策。科学新颖性在于首次验证了LLMs在无线网络安全事件调查中的潜力。实验结果显示，Gemma-7b模型在检测性能上最佳，Precision=0.89、Recall=0.89和F1-Score=0.89，并能识别数据不一致性（inconsistencies）、进行特征重要性分析并提供缓解建议。最终，该框架证明了LLMs与二元威胁分类器整合在实际网络安全领域的显著应用潜力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13196v1",
      "published_date": "2025-04-14 09:57:20 UTC",
      "updated_date": "2025-04-14 09:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:52:25.629952"
    },
    {
      "arxiv_id": "2504.10045v1",
      "title": "CHARM: Calibrating Reward Models With Chatbot Arena Scores",
      "title_zh": "CHARM",
      "authors": [
        "Xiao Zhu",
        "Chenmien Tan",
        "Pinzhen Chen",
        "Rico Sennrich",
        "Yanlin Zhang",
        "Hanxu Hu"
      ],
      "abstract": "Reward models (RMs) play a crucial role in Reinforcement Learning from Human\nFeedback by serving as proxies for human preferences in aligning large language\nmodels. In this paper, we identify a model preference bias in RMs, where they\nsystematically assign disproportionately high scores to responses from certain\npolicy models. This bias distorts ranking evaluations and leads to unfair\njudgments. To address this issue, we propose a calibration method named CHatbot\nArena calibrated Reward Modeling (CHARM) that leverages Elo scores from the\nChatbot Arena leaderboard to mitigate RM overvaluation. We also introduce a\nMismatch Degree metric to measure this preference bias. Our approach is\ncomputationally efficient, requiring only a small preference dataset for\ncontinued training of the RM. We conduct extensive experiments on reward model\nbenchmarks and human preference alignment. Results demonstrate that our\ncalibrated RMs (1) achieve improved evaluation accuracy on RM-Bench and the\nChat-Hard domain of RewardBench, and (2) exhibit a stronger correlation with\nhuman preferences by producing scores more closely aligned with Elo rankings.\nBy mitigating model preference bias, our method provides a generalizable and\nefficient solution for building fairer and more reliable reward models.",
      "tldr_zh": "该研究识别出奖励模型（RMs）在人类反馈强化学习中存在的模型偏好偏差（model preference bias），导致对某些策略模型的响应过度高估，从而影响评估公平性。为解决此问题，提出CHARM（CHatbot Arena calibrated Reward Modeling）方法，利用Chatbot Arena排行榜的Elo scores对RMs进行校准，并引入Mismatch Degree指标来量化偏差。实验结果显示，校准后的RMs在RM-Bench和RewardBench的Chat-Hard领域实现了更高的评估准确性，并与人类偏好更紧密对齐。通过这种高效的校准策略，该方法为构建更公平可靠的奖励模型提供了通用解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10045v1",
      "published_date": "2025-04-14 09:51:09 UTC",
      "updated_date": "2025-04-14 09:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:52:37.258065"
    },
    {
      "arxiv_id": "2504.10030v1",
      "title": "EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical Challenge in Multi-Robot Control",
      "title_zh": "翻译失败",
      "authors": [
        "Hanwen Wan",
        "Yifei Chen",
        "Zeyu Wei",
        "Dongrui Li",
        "Zexin Lin",
        "Donghao Wu",
        "Jiu Cheng",
        "Yuxiang Zhang",
        "Xiaoqiang Ji"
      ],
      "abstract": "This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.",
      "tldr_zh": "这篇论文介绍了EmbodiedAgent，一种可扩展的层次化框架，用于解决异构多机器人控制中的实际挑战，特别是hallucination问题。该框架整合了next-action prediction范式和结构化记忆系统，将任务分解成可执行的机器人技能，并动态验证动作与环境约束。研究者构建了MultiPlan+数据集，包含超过18,000个标注的规划实例，涵盖100个场景，以缓解不切实际任务的幻觉。为评估性能，论文提出了Robot Planning Assessment Schema (RPAS)，结合自动化指标和LLM辅助评分。实验结果显示，EmbodiedAgent在RPAS得分达到71.85%，优于现有模型，并在真实世界办公室服务任务中成功协调异构机器人实现长期目标。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10030v1",
      "published_date": "2025-04-14 09:33:42 UTC",
      "updated_date": "2025-04-14 09:33:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:52:50.499132"
    },
    {
      "arxiv_id": "2504.10028v1",
      "title": "Sequence models for by-trial decoding of cognitive strategies from neural data",
      "title_zh": "用于从神经数据中逐试解码认知策略的序列模型",
      "authors": [
        "Rick den Otter",
        "Gabriel Weindel",
        "Sjoerd Stuit",
        "Leendert van Maanen"
      ],
      "abstract": "Understanding the sequence of cognitive operations that underlie\ndecision-making is a fundamental challenge in cognitive neuroscience.\nTraditional approaches often rely on group-level statistics, which obscure\ntrial-by-trial variations in cognitive strategies. In this study, we introduce\na novel machine learning method that combines Hidden Multivariate Pattern\nanalysis with a Structured State Space Sequence model to decode cognitive\nstrategies from electroencephalography data at the trial level. We apply this\nmethod to a decision-making task, where participants were instructed to\nprioritize either speed or accuracy in their responses. Our results reveal an\nadditional cognitive operation, labeled Confirmation, which seems to occur\npredominantly in the accuracy condition but also frequently in the speed\ncondition. The modeled probability that this operation occurs is associated\nwith higher probability of responding correctly as well as changes of mind, as\nindexed by electromyography data. By successfully modeling cognitive operations\nat the trial level, we provide empirical evidence for dynamic variability in\ndecision strategies, challenging the assumption of homogeneous cognitive\nprocesses within experimental conditions. Our approach shows the potential of\nsequence modeling in cognitive neuroscience to capture trial-level variability\nthat is obscured by aggregate analyses. The introduced method offers a new way\nto detect and understand cognitive strategies in a data-driven manner, with\nimplications for both theoretical research and practical applications in many\nfields.",
      "tldr_zh": "本研究提出了一种结合 Hidden Multivariate Pattern analysis 和 Structured State Space Sequence model 的机器学习方法，用于从 EEG 数据中解码决策任务中的试验级别认知策略。应用该方法于参与者优先速度或准确性的实验中，研究者发现了“Confirmation”认知操作，该操作在准确性条件下更常见，并与正确响应概率和改变主意的现象相关。结果挑战了认知过程在实验条件内同质的传统假设，并展示了序列建模在捕捉试验级变异性和数据驱动分析中的潜力，为认知神经科学理论和应用提供新工具。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10028v1",
      "published_date": "2025-04-14 09:33:02 UTC",
      "updated_date": "2025-04-14 09:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:53:00.886159"
    },
    {
      "arxiv_id": "2504.10025v1",
      "title": "Progressive Transfer Learning for Multi-Pass Fundus Image Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Uyen Phan",
        "Ozer Can Devecioglu",
        "Serkan Kiranyaz",
        "Moncef Gabbouj"
      ],
      "abstract": "Diabetic retinopathy is a leading cause of vision impairment, making its\nearly diagnosis through fundus imaging critical for effective treatment\nplanning. However, the presence of poor quality fundus images caused by factors\nsuch as inadequate illumination, noise, blurring and other motion artifacts\nyields a significant challenge for accurate DR screening. In this study, we\npropose progressive transfer learning for multi pass restoration to iteratively\nenhance the quality of degraded fundus images, ensuring more reliable DR\nscreening. Unlike previous methods that often focus on a single pass\nrestoration, multi pass restoration via PTL can achieve a superior blind\nrestoration performance that can even improve most of the good quality fundus\nimages in the dataset. Initially, a Cycle GAN model is trained to restore low\nquality images, followed by PTL induced restoration passes over the latest\nrestored outputs to improve overall quality in each pass. The proposed method\ncan learn blind restoration without requiring any paired data while surpassing\nits limitations by leveraging progressive learning and fine tuning strategies\nto minimize distortions and preserve critical retinal features. To evaluate\nPTL's effectiveness on multi pass restoration, we conducted experiments on\nDeepDRiD, a large scale fundus imaging dataset specifically curated for\ndiabetic retinopathy detection. Our result demonstrates state of the art\nperformance, showcasing PTL's potential as a superior approach to iterative\nimage quality restoration.",
      "tldr_zh": "本研究针对糖尿病视网膜病变（Diabetic Retinopathy, DR）的早期诊断问题，提出了一种Progressive Transfer Learning (PTL) for multi-pass restoration方法，用于迭代提升视网膜图像质量，以应对光照不足、噪声和模糊等因素导致的图像退化。不同于传统的单次恢复方法，该框架先利用Cycle GAN模型训练恢复低质量图像，然后通过PTL进行多轮优化，实现盲恢复（blind restoration），无需配对数据，同时最小化失真并保留关键视网膜特征。实验在DeepDRiD数据集上表明，该方法实现了最先进性能，甚至能进一步改善原本质量良好的图像，从而提升DR筛查的可靠性和准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "13 pages, 12 figures including appendix",
      "pdf_url": "http://arxiv.org/pdf/2504.10025v1",
      "published_date": "2025-04-14 09:28:10 UTC",
      "updated_date": "2025-04-14 09:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:53:12.724220"
    },
    {
      "arxiv_id": "2504.10020v2",
      "title": "The Mirage of Performance Gains: Why Contrastive Decoding Fails to Address Multimodal Hallucination",
      "title_zh": "性能提升的幻觉：为什么对比解码无法解决多模态幻觉",
      "authors": [
        "Hao Yin",
        "Guangzong Si",
        "Zilei Wang"
      ],
      "abstract": "Contrastive decoding strategies are widely used to reduce hallucinations in\nmultimodal large language models (MLLMs). These methods work by constructing\ncontrastive samples to induce hallucinations and then suppressing them in the\noutput distribution. However, this paper demonstrates that such approaches fail\nto effectively mitigate the hallucination problem. The performance improvements\nobserved on POPE Benchmark are largely driven by two misleading factors: (1)\ncrude, unidirectional adjustments to the model's output distribution and (2)\nthe adaptive plausibility constraint, which reduces the sampling strategy to\ngreedy search. To further illustrate these issues, we introduce a series of\nspurious improvement methods and evaluate their performance against contrastive\ndecoding techniques. Experimental results reveal that the observed performance\ngains in contrastive decoding are entirely unrelated to its intended goal of\nmitigating hallucinations. Our findings challenge common assumptions about the\neffectiveness of contrastive decoding strategies and pave the way for\ndeveloping genuinely effective solutions to hallucinations in MLLMs.",
      "tldr_zh": "该论文质疑了对比解码(Contrastive Decoding)策略在减少多模态大语言模型(MLLMs)幻觉(Multimodal Hallucination)方面的有效性，指出其性能提升主要是由输出分布的单向调整和自适应合理性约束所驱动，导致采样策略简化为贪婪搜索。作者通过引入一系列虚假改进方法，并与对比解码技术进行比较实验，发现这些收益与实际缓解幻觉无关。实验结果基于POPE Benchmark，证明对比解码未能实现其预期目标。最终，该研究挑战了现有假设，并为开发真正有效的MLLMs幻觉解决方案提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10020v2",
      "published_date": "2025-04-14 09:25:37 UTC",
      "updated_date": "2025-04-18 11:30:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:53:25.245505"
    },
    {
      "arxiv_id": "2504.10018v1",
      "title": "RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework",
      "title_zh": "基于 RGB-Event 的行人属性识别：一个",
      "authors": [
        "Xiao Wang",
        "Haiyang Wang",
        "Shiao Wang",
        "Qiang Chen",
        "Jiandong Jin",
        "Haoyu Song",
        "Bo Jiang",
        "Chenglong Li"
      ],
      "abstract": "Existing pedestrian attribute recognition methods are generally developed\nbased on RGB frame cameras. However, these approaches are constrained by the\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\nmotion blur, which hinder their performance. Furthermore, current attribute\nrecognition primarily focuses on analyzing pedestrians' external appearance and\nclothing, lacking an exploration of emotional dimensions. In this paper, we\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\nrecognition task by drawing inspiration from the advantages of event cameras in\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\nattributes related to both appearance and six human emotions, diverse scenes,\nand various seasons. By retraining and evaluating mainstream PAR models on this\ndataset, we establish a comprehensive benchmark and provide a solid foundation\nfor future research in terms of data and algorithmic baselines. In addition, we\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\nmodule. Extensive experiments are conducted on our proposed dataset as well as\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\nstate-of-the-art results. The source code and dataset will be released on\nhttps://github.com/Event-AHU/OpenPAR",
      "tldr_zh": "该研究指出现有基于RGB相机的行人属性识别方法受光照和运动模糊限制，且忽略情感维度，提出一种新型多模态RGB-Event属性识别任务，利用事件相机的低光高性能优势。论文贡献包括构建首个大规模数据集EventPAR，包含10万对RGB-Event样本，覆盖50个属性（如外观和六种人类情感）、多样场景和季节，并建立基准评估主流模型。作者还设计了一个基于RWKV的框架，包含RWKV视觉编码器和不对称RWKV融合模块，在EventPAR及模拟数据集上实验，实现了最先进的结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The First Benchmark Dataset for RGB-Event Multimodal Pedestrian\n  Attribute Recognition Task",
      "pdf_url": "http://arxiv.org/pdf/2504.10018v1",
      "published_date": "2025-04-14 09:22:16 UTC",
      "updated_date": "2025-04-14 09:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:53:36.041980"
    },
    {
      "arxiv_id": "2504.10014v1",
      "title": "Air Quality Prediction with A Meteorology-Guided Modality-Decoupled Spatio-Temporal Network",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Yin",
        "Yan-Ming Zhang",
        "Jian Xu",
        "Jian-Long Chang",
        "Yin Li",
        "Cheng-Lin Liu"
      ],
      "abstract": "Air quality prediction plays a crucial role in public health and\nenvironmental protection. Accurate air quality prediction is a complex\nmultivariate spatiotemporal problem, that involves interactions across temporal\npatterns, pollutant correlations, spatial station dependencies, and\nparticularly meteorological influences that govern pollutant dispersion and\nchemical transformations. Existing works underestimate the critical role of\natmospheric conditions in air quality prediction and neglect comprehensive\nmeteorological data utilization, thereby impairing the modeling of dynamic\ninterdependencies between air quality and meteorological data. To overcome\nthis, we propose MDSTNet, an encoder-decoder framework that explicitly models\nair quality observations and atmospheric conditions as distinct modalities,\nintegrating multi-pressure-level meteorological data and weather forecasts to\ncapture atmosphere-pollution dependencies for prediction. Meantime, we\nconstruct ChinaAirNet, the first nationwide dataset combining air quality\nrecords with multi-pressure-level meteorological observations. Experimental\nresults on ChinaAirNet demonstrate MDSTNet's superiority, substantially\nreducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art\nmodel. The source code and dataset will be available on github.",
      "tldr_zh": "这篇论文针对空气质量预测的复杂性，强调了气象影响的关键作用，并提出MDSTNet框架——一个气象引导的模态解耦时空网络，用于显式建模空气质量观测和大气条件作为不同模态，同时整合多压力层气象数据和天气预报以捕捉大气-污染依赖关系。研究者构建了ChinaAirNet，这是首个结合全国空气质量记录和多压力层气象观测的数据集。实验结果显示，MDSTNet在ChinaAirNet上将48小时预测错误减少了17.54%，优于现有最先进模型。源代码和数据集将在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10014v1",
      "published_date": "2025-04-14 09:18:11 UTC",
      "updated_date": "2025-04-14 09:18:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:53:49.225230"
    },
    {
      "arxiv_id": "2504.10005v1",
      "title": "Session-based Recommender Systems: User Interest as a Stochastic Process in the Latent Space",
      "title_zh": "基于会话的推荐系统：用户兴趣作为潜在空间中的随机过程",
      "authors": [
        "Klaudia Balcer",
        "Piotr Lipinski"
      ],
      "abstract": "This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.",
      "tldr_zh": "这篇论文针对session-based recommender systems中的数据不确定性、流行偏见和曝光偏见问题，提出将用户兴趣视为latent space中的stochastic process，并提供一个模型无关的实现框架。方法包括通过正则化实现debiasing item embeddings、从session prefixes建模密集用户兴趣，以及引入fake targets来模拟扩展曝光，从而缓解这些偏见在项目嵌入和推荐中的影响。在Diginetica和YooChoose 1/64数据集等基准测试上，实验结果显示该方法显著提升了推荐系统的性能和公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10005v1",
      "published_date": "2025-04-14 09:08:40 UTC",
      "updated_date": "2025-04-14 09:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:54:00.628259"
    },
    {
      "arxiv_id": "2504.10552v1",
      "title": "LEMUR Neural Network Dataset: Towards Seamless AutoML",
      "title_zh": "LEMUR 神经网络数据集：面向无缝 AutoML",
      "authors": [
        "Arash Torabi Goodarzi",
        "Roman Kochnev",
        "Waleed Khalid",
        "Furui Qin",
        "Tolgay Atinc Uzun",
        "Yashkumar Sanjaybhai Dhameliya",
        "Yash Kanubhai Kathiriya",
        "Zofia Antonina Bentyn",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "abstract": "Neural networks are fundamental in artificial intelligence, driving progress\nin computer vision and natural language processing. High-quality datasets are\ncrucial for their development, and there is growing interest in datasets\ncomposed of neural networks themselves to support benchmarking, automated\nmachine learning (AutoML), and model analysis. We introduce LEMUR, an open\nsource dataset of neural network models with well-structured code for diverse\narchitectures across tasks such as object detection, image classification,\nsegmentation, and natural language processing. LEMUR is primarily designed to\nenable fine-tuning of large language models (LLMs) for AutoML tasks, providing\na rich source of structured model representations and associated performance\ndata. Leveraging Python and PyTorch, LEMUR enables seamless extension to new\ndatasets and models while maintaining consistency. It integrates an\nOptuna-powered framework for evaluation, hyperparameter optimization,\nstatistical analysis, and graphical insights. LEMUR provides an extension that\nenables models to run efficiently on edge devices, facilitating deployment in\nresource-constrained environments. Providing tools for model evaluation,\npreprocessing, and database management, LEMUR supports researchers and\npractitioners in developing, testing, and analyzing neural networks.\nAdditionally, it offers an API that delivers comprehensive information about\nneural network models and their complete performance statistics with a single\nrequest, which can be used in experiments with code-generating large language\nmodels. The LEMUR will be released as an open source project under the MIT\nlicense upon acceptance of the paper.",
      "tldr_zh": "该论文介绍了 LEMUR 数据集，这是一个开源神经网络模型数据集，旨在支持 Automated Machine Learning (AutoML) 和模型分析。LEMUR 包含多样化架构的神经网络代码，涵盖物体检测、图像分类、分割和自然语言处理等任务，并提供结构化的模型表示和性能数据，便于大型语言模型 (LLMs) 的微调。利用 Python 和 PyTorch 构建，该数据集集成了 Optuna 驱动的框架，用于超参数优化、统计分析和图形洞见，同时支持边缘设备部署和高效 API 接口。整体设计促进了神经网络的开发、测试和分析，并计划以 MIT 许可开源发布。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10552v1",
      "published_date": "2025-04-14 09:08:00 UTC",
      "updated_date": "2025-04-14 09:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:54:14.513191"
    },
    {
      "arxiv_id": "2504.10000v1",
      "title": "Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?",
      "title_zh": "我们真的需要精选的恶意数据来实现多模态大语言模型的安全对齐吗？",
      "authors": [
        "Yanbo Wang",
        "Jiyang Guan",
        "Jian Liang",
        "Ran He"
      ],
      "abstract": "Multi-modal large language models (MLLMs) have made significant progress, yet\ntheir safety alignment remains limited. Typically, current open-source MLLMs\nrely on the alignment inherited from their language module to avoid harmful\ngenerations. However, the lack of safety measures specifically designed for\nmulti-modal inputs creates an alignment gap, leaving MLLMs vulnerable to\nvision-domain attacks such as typographic manipulation. Current methods utilize\na carefully designed safety dataset to enhance model defense capability, while\nthe specific knowledge or patterns acquired from the high-quality dataset\nremain unclear. Through comparison experiments, we find that the alignment gap\nprimarily arises from data distribution biases, while image content, response\nquality, or the contrastive behavior of the dataset makes little contribution\nto boosting multi-modal safety. To further investigate this and identify the\nkey factors in improving MLLM safety, we propose finetuning MLLMs on a small\nset of benign instruct-following data with responses replaced by simple, clear\nrejection sentences. Experiments show that, without the need for\nlabor-intensive collection of high-quality malicious data, model safety can\nstill be significantly improved, as long as a specific fraction of rejection\ndata exists in the finetuning set, indicating the security alignment is not\nlost but rather obscured during multi-modal pretraining or instruction\nfinetuning. Simply correcting the underlying data bias could narrow the safety\ngap in the vision domain.",
      "tldr_zh": "本研究质疑多模态大语言模型 (MLLMs) 的安全对齐是否需要精心策划的恶意数据集，通过实验发现，该问题主要源于数据分布偏差，而非图像内容或响应质量。作者提出一种简单方法：在小规模良性指令跟随数据上微调 MLLMs，并将响应替换为明确的拒绝句子。结果显示，只要微调集中包含特定比例的拒绝数据，就能显著提升模型的安全性能，证明通过纠正数据偏差即可缩小视觉领域的安全差距，而无需高成本的恶意数据收集。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to CVPR 2025, codes in process",
      "pdf_url": "http://arxiv.org/pdf/2504.10000v1",
      "published_date": "2025-04-14 09:03:51 UTC",
      "updated_date": "2025-04-14 09:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:54:25.266957"
    },
    {
      "arxiv_id": "2504.09998v1",
      "title": "Metric-Guided Synthesis of Class Activation Mapping",
      "title_zh": "基于度量引导的类激活映射合成",
      "authors": [
        "Alejandro Luque-Cerpa",
        "Elizabeth Polgreen",
        "Ajitha Rajan",
        "Hazem Torfah"
      ],
      "abstract": "Class activation mapping (CAM) is a widely adopted class of saliency methods\nused to explain the behavior of convolutional neural networks (CNNs). These\nmethods generate heatmaps that highlight the parts of the input most relevant\nto the CNN output. Various CAM methods have been proposed, each distinguished\nby the expressions used to derive heatmaps. In general, users look for heatmaps\nwith specific properties that reflect different aspects of CNN functionality.\nThese may include similarity to ground truth, robustness, equivariance, and\nmore. Although existing CAM methods implicitly encode some of these properties\nin their expressions, they do not allow for variability in heatmap generation\nfollowing the user's intent or domain knowledge. In this paper, we address this\nlimitation by introducing SyCAM, a metric-based approach for synthesizing CAM\nexpressions. Given a predefined evaluation metric for saliency maps, SyCAM\nautomatically generates CAM expressions optimized for that metric. We\nspecifically explore a syntax-guided synthesis instantiation of SyCAM, where\nCAM expressions are derived based on predefined syntactic constraints and the\ngiven metric. Using several established evaluation metrics, we demonstrate the\nefficacy and flexibility of our approach in generating targeted heatmaps. We\ncompare SyCAM with other well-known CAM methods on three prominent models:\nResNet50, VGG16, and VGG19.",
      "tldr_zh": "该论文提出 SyCAM，一种基于指标引导的 Class Activation Mapping (CAM) 合成方法，旨在解决现有 CAM 方法在生成热图时缺乏灵活性的问题。SyCAM 通过给定预定义的评估指标（如相似性、鲁棒性和等变性）自动优化 CAM 表达式，并采用语法引导合成来确保表达式的有效性和针对性。在实验中，SyCAM 在 ResNet50、VGG16 和 VGG19 等模型上与传统方法比较，展示了显著的灵活性和性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09998v1",
      "published_date": "2025-04-14 09:01:49 UTC",
      "updated_date": "2025-04-14 09:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:54:37.420495"
    },
    {
      "arxiv_id": "2504.09997v1",
      "title": "GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control",
      "title_zh": "翻译失败",
      "authors": [
        "Hanwen Wan",
        "Mengkang Li",
        "Donghao Wu",
        "Yebin Zhong",
        "Yixuan Deng",
        "Zhenglong Sun",
        "Xiaoqiang Ji"
      ],
      "abstract": "Developing bipedal robots capable of traversing diverse real-world terrains\npresents a fundamental robotics challenge, as existing methods using predefined\nheight maps and static environments fail to address the complexity of\nunstructured landscapes. To bridge this gap, we propose GenTe, a framework for\ngenerating physically realistic and adaptable terrains to train generalizable\nlocomotion policies. GenTe constructs an atomic terrain library that includes\nboth geometric and physical terrains, enabling curriculum training for\nreinforcement learning-based locomotion policies. By leveraging\nfunction-calling techniques and reasoning capabilities of Vision-Language\nModels (VLMs), GenTe generates complex, contextually relevant terrains from\ntextual and graphical inputs. The framework introduces realistic force modeling\nfor terrain interactions, capturing effects such as soil sinkage and\nhydrodynamic resistance. To the best of our knowledge, GenTe is the first\nframework that systemically generates simulation environments for legged robot\nlocomotion control. Additionally, we introduce a benchmark of 100 generated\nterrains. Experiments demonstrate improved generalization and robustness in\nbipedal robot locomotion.",
      "tldr_zh": "这篇论文提出了 GenTe 框架，用于生成物理真实且可适应的真实世界地形，以训练通用的腿部机器人运动策略，解决现有方法在处理非结构化景观时的局限性。GenTe 通过构建原子地形库、结合 Vision-Language Models (VLMs) 的函数调用和推理能力，从文本和图形输入生成复杂地形，并引入现实力建模（如土壤下沉和流体动力阻力），支持基于 reinforcement learning 的课程训练。该框架首次系统生成模拟环境，并通过 100 个地形基准的实验证明了双足机器人运动的泛化和鲁棒性显著提升。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09997v1",
      "published_date": "2025-04-14 09:01:44 UTC",
      "updated_date": "2025-04-14 09:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:54:49.730042"
    },
    {
      "arxiv_id": "2504.10551v1",
      "title": "MiMu: Mitigating Multiple Shortcut Learning Behavior of Transformers",
      "title_zh": "MiMu：缓解 Transformer 的多个捷径学习行为",
      "authors": [
        "Lili Zhao",
        "Qi Liu",
        "Wei Chen",
        "Liyi Chen",
        "Ruijun Sun",
        "Min Hou",
        "Yang Wang",
        "Shijin Wang"
      ],
      "abstract": "Empirical Risk Minimization (ERM) models often rely on spurious correlations\nbetween features and labels during the learning process, leading to shortcut\nlearning behavior that undermines robustness generalization performance.\nCurrent research mainly targets identifying or mitigating a single shortcut;\nhowever, in real-world scenarios, cues within the data are diverse and unknown.\nIn empirical studies, we reveal that the models rely to varying extents on\ndifferent shortcuts. Compared to weak shortcuts, models depend more heavily on\nstrong shortcuts, resulting in their poor generalization ability. To address\nthese challenges, we propose MiMu, a novel method integrated with\nTransformer-based ERMs designed to Mitigate Multiple shortcut learning\nbehavior, which incorporates self-calibration strategy and self-improvement\nstrategy. In the source model, we preliminarily propose the self-calibration\nstrategy to prevent the model from relying on shortcuts and make overconfident\npredictions. Then, we further design self-improvement strategy in target model\nto reduce the reliance on multiple shortcuts. The random mask strategy involves\nrandomly masking partial attention positions to diversify the focus of target\nmodel other than concentrating on a fixed region. Meanwhile, the adaptive\nattention alignment module facilitates the alignment of attention weights to\nthe calibrated source model, without the need for post-hoc attention maps or\nsupervision. Finally, extensive experiments conducted on Natural Language\nProcessing (NLP) and Computer Vision (CV) demonstrate the effectiveness of MiMu\nin improving robustness generalization abilities.",
      "tldr_zh": "该研究针对 Empirical Risk Minimization (ERM) 模型在学习过程中依赖虚假相关性导致的 shortcut learning 问题，提出 MiMu 方法，用于缓解 Transformer 模型中的多种 shortcut learning 行为。\nMiMu 整合了自校准策略（在源模型中防止模型过度依赖快捷方式并减少过度自信预测）和自改进策略（在目标模型中通过随机掩码策略分散注意力焦点，以及自适应注意力对齐模块对齐注意力权重）。\n实验结果显示，在 Natural Language Processing (NLP) 和 Computer Vision (CV) 任务上，MiMu 显著提高了模型的鲁棒性泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10551v1",
      "published_date": "2025-04-14 08:11:09 UTC",
      "updated_date": "2025-04-14 08:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:55:01.677584"
    },
    {
      "arxiv_id": "2504.09967v1",
      "title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data",
      "title_zh": "通过以图像为中心的多标注数据增强医疗通用基础模型的多任务学习能力",
      "authors": [
        "Xun Zhu",
        "Fanbin Mo",
        "Zheng Zhang",
        "Jiaxi Wang",
        "Yiming Shi",
        "Ming Wu",
        "Chuang Zhang",
        "Miao Li",
        "Ji Wu"
      ],
      "abstract": "The emergence of medical generalist foundation models has revolutionized\nconventional task-specific model development paradigms, aiming to better handle\nmultiple tasks through joint training on large-scale medical datasets. However,\nrecent advances prioritize simple data scaling or architectural component\nenhancement, while neglecting to re-examine multi-task learning from a\ndata-centric perspective. Critically, simply aggregating existing data\nresources leads to decentralized image-task alignment, which fails to cultivate\ncomprehensive image understanding or align with clinical needs for\nmulti-dimensional image interpretation. In this paper, we introduce the\nimage-centric multi-annotation X-ray dataset (IMAX), the first attempt to\nenhance the multi-task learning capabilities of medical multi-modal large\nlanguage models (MLLMs) from the data construction level. To be specific, IMAX\nis featured from the following attributes: 1) High-quality data curation. A\ncomprehensive collection of more than 354K entries applicable to seven\ndifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image is\nassociated with an average of 4.10 tasks and 7.46 training entries, ensuring\nmulti-task representation richness per image. Compared to the general\ndecentralized multi-annotation X-ray dataset (DMAX), IMAX consistently\ndemonstrates significant multi-task average performance gains ranging from\n3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.\nMoreover, we investigate differences in statistical patterns exhibited by IMAX\nand DMAX training processes, exploring potential correlations between\noptimization dynamics and multi-task performance. Finally, leveraging the core\nconcept of IMAX data construction, we propose an optimized DMAX-based training\nstrategy to alleviate the dilemma of obtaining high-quality IMAX data in\npractical scenarios.",
      "tldr_zh": "本研究旨在通过图像中心多标注数据增强医疗通用基础模型（medical generalist foundation model）的多任务学习能力，解决现有方法忽略数据视角的问题。论文引入了IMAX数据集，这是首个从数据构建层面优化医疗多模态大语言模型（MLLMs）的尝试，该数据集包含超过35.4K条高质量条目，适用于七个医疗任务，且每个X-ray图像平均关联4.10个任务和7.46个训练条目。相比于分散式多标注数据集（DMAX），IMAX在七个开源最先进MLLMs上实现了3.20%至21.05%的多任务平均性能提升。论文还分析了IMAX和DMAX的训练统计模式及其与性能的相关性，并提出了一种基于DMAX的优化训练策略，以应对实际场景下高质量数据获取的挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09967v1",
      "published_date": "2025-04-14 08:09:37 UTC",
      "updated_date": "2025-04-14 08:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:55:13.360245"
    },
    {
      "arxiv_id": "2504.09963v1",
      "title": "Towards Unbiased Federated Graph Learning: Label and Topology Perspectives",
      "title_zh": "迈向无偏联邦图学习：标签和拓扑视角",
      "authors": [
        "Zhengyu Wu",
        "Boyang Pang",
        "Xunkai Li",
        "Yinlin Zhu",
        "Daohan Su",
        "Bowen Fan",
        "Rong-Hua Li",
        "Guoren Wang",
        "Chenghu Zhou"
      ],
      "abstract": "Federated Graph Learning (FGL) enables privacy-preserving, distributed\ntraining of graph neural networks without sharing raw data. Among its\napproaches, subgraph-FL has become the dominant paradigm, with most work\nfocused on improving overall node classification accuracy. However, these\nmethods often overlook fairness due to the complexity of node features, labels,\nand graph structures. In particular, they perform poorly on nodes with\ndisadvantaged properties, such as being in the minority class within subgraphs\nor having heterophilous connections (neighbors with dissimilar labels or\nmisleading features). This reveals a critical issue: high accuracy can mask\ndegraded performance on structurally or semantically marginalized nodes. To\naddress this, we advocate for two fairness goals: (1) improving representation\nof minority class nodes for class-wise fairness and (2) mitigating topological\nbias from heterophilous connections for topology-aware fairness. We propose\nFairFGL, a novel framework that enhances fairness through fine-grained graph\nmining and collaborative learning. On the client side, the History-Preserving\nModule prevents overfitting to dominant local classes, while the Majority\nAlignment Module refines representations of heterophilous majority-class nodes.\nThe Gradient Modification Module transfers minority-class knowledge from\nstructurally favorable clients to improve fairness. On the server side, FairFGL\nuploads only the most influenced subset of parameters to reduce communication\ncosts and better reflect local distributions. A cluster-based aggregation\nstrategy reconciles conflicting updates and curbs global majority dominance .\nExtensive evaluations on eight benchmarks show FairFGL significantly improves\nminority-group performance , achieving up to a 22.62 percent Macro-F1 gain\nwhile enhancing convergence over state-of-the-art baselines.",
      "tldr_zh": "该论文探讨了Federated Graph Learning (FGL)中的公平性问题，强调现有方法在少数类节点和异质连接（heterophilous connections）上表现不佳，导致高准确率掩盖了对边缘化节点的偏置。作者提出FairFGL框架，通过客户端的History-Preserving Module防止过度拟合主导类、Majority Alignment Module优化异质多数类表示，以及Gradient Modification Module转移少数类知识；服务端则采用参数子集上传和基于聚类的聚合策略，以减少通信成本并提升全局公平性。实验在八个基准上显示，FairFGL显著提升少数群体的性能，最多提高22.62%的Macro-F1分数，并加速收敛，实现了更无偏的图学习。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.09963v1",
      "published_date": "2025-04-14 08:00:20 UTC",
      "updated_date": "2025-04-14 08:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:55:25.361345"
    },
    {
      "arxiv_id": "2504.09961v1",
      "title": "Privacy Meets Explainability: Managing Confidential Data and Transparency Policies in LLM-Empowered Science",
      "title_zh": "翻译失败",
      "authors": [
        "Yashothara Shanmugarasa",
        "Shidong Pan",
        "Ming Ding",
        "Dehai Zhao",
        "Thierry Rakotoarivelo"
      ],
      "abstract": "As Large Language Models (LLMs) become integral to scientific workflows,\nconcerns over the confidentiality and ethical handling of confidential data\nhave emerged. This paper explores data exposure risks through LLM-powered\nscientific tools, which can inadvertently leak confidential information,\nincluding intellectual property and proprietary data, from scientists'\nperspectives. We propose \"DataShield\", a framework designed to detect\nconfidential data leaks, summarize privacy policies, and visualize data flow,\nensuring alignment with organizational policies and procedures. Our approach\naims to inform scientists about data handling practices, enabling them to make\ninformed decisions and protect sensitive information. Ongoing user studies with\nscientists are underway to evaluate the framework's usability, trustworthiness,\nand effectiveness in tackling real-world privacy challenges.",
      "tldr_zh": "随着LLMs在科学工作流中的应用日益普及，本文探讨了这些模型可能无意泄露机密信息（如知识产权和专有数据）的风险，并从科学家的视角分析了数据暴露问题。论文提出\"DataShield\"框架，该框架通过检测机密数据泄露、总结隐私政策以及可视化数据流，确保数据处理符合组织政策和程序，从而帮助科学家做出明智决策并保护敏感信息。DataShield旨在提升数据处理的透明度和可解释性，目前正在进行用户研究以评估其可用性、可信度和在实际隐私挑战中的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.09961v1",
      "published_date": "2025-04-14 07:58:26 UTC",
      "updated_date": "2025-04-14 07:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:55:36.131036"
    },
    {
      "arxiv_id": "2504.09948v3",
      "title": "Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes",
      "title_zh": "翻译失败",
      "authors": [
        "Huijie Liu",
        "Bingcan Wang",
        "Jie Hu",
        "Xiaoming Wei",
        "Guoliang Kang"
      ],
      "abstract": "Dish images play a crucial role in the digital era, with the demand for\nculturally distinctive dish images continuously increasing due to the\ndigitization of the food industry and e-commerce. In general cases, existing\ntext-to-image generation models excel in producing high-quality images;\nhowever, they struggle to capture diverse characteristics and faithful details\nof specific domains, particularly Chinese dishes. To address this limitation,\nwe propose Omni-Dish, the first text-to-image generation model specifically\ntailored for Chinese dishes. We develop a comprehensive dish curation pipeline,\nbuilding the largest dish dataset to date. Additionally, we introduce a\nrecaption strategy and employ a coarse-to-fine training scheme to help the\nmodel better learn fine-grained culinary nuances. During inference, we enhance\nthe user's textual input using a pre-constructed high-quality caption library\nand a large language model, enabling more photorealistic and faithful image\ngeneration. Furthermore, to extend our model's capability for dish editing\ntasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish\nediting dataset and train a specialized editing model. Extensive experiments\ndemonstrate the superiority of our methods.",
      "tldr_zh": "该研究提出 Omni-Dish，这是首个针对中国菜肴的文本到图像生成模型，旨在解决现有模型在捕捉中国菜多样特性和细节方面的不足。通过构建迄今为止最大的菜肴数据集、引入重新标注策略和粗到细的训练方案，该模型能够更好地学习细粒度的烹饪 nuances。在推理阶段，Omni-Dish 使用高质量标题库和大型语言模型增强用户输入，实现更逼真且忠实的图像生成；此外，作者开发了 Concept-Enhanced P2P 方法及相应编辑数据集，扩展模型到菜肴编辑任务。实验结果证明，该方法在图像生成和编辑方面显著优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 10 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.09948v3",
      "published_date": "2025-04-14 07:18:32 UTC",
      "updated_date": "2025-05-01 01:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:55:49.253840"
    },
    {
      "arxiv_id": "2504.09941v1",
      "title": "FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous Environments",
      "title_zh": "FedRecon：分布式异构环境下的缺失模态重建",
      "authors": [
        "Junming Liu",
        "Guosun Zeng",
        "Ding Wang",
        "Yanting Gao",
        "Yufei Jin"
      ],
      "abstract": "Multimodal data are often incomplete and exhibit Non-Independent and\nIdentically Distributed (Non-IID) characteristics in real-world scenarios.\nThese inherent limitations lead to both modality heterogeneity through partial\nmodality absence and data heterogeneity from distribution divergence, creating\nfundamental challenges for effective federated learning (FL). To address these\ncoupled challenges, we propose FedRecon, the first method targeting\nsimultaneous missing modality reconstruction and Non-IID adaptation in\nmultimodal FL. Our approach first employs a lightweight Multimodal Variational\nAutoencoder (MVAE) to reconstruct missing modalities while preserving\ncross-modal consistency. Distinct from conventional imputation methods, we\nachieve sample-level alignment through a novel distribution mapping mechanism\nthat guarantees both data consistency and completeness. Additionally, we\nintroduce a strategy employing global generator freezing to prevent\ncatastrophic forgetting, which in turn mitigates Non-IID fluctuations.\nExtensive evaluations on multimodal datasets demonstrate FedRecon's superior\nperformance in modality reconstruction under Non-IID conditions, surpassing\nstate-of-the-art methods.",
      "tldr_zh": "该论文提出FedRecon，一种针对多模态联邦学习（FL）的创新方法，用于同时处理缺失模态重建和Non-IID（非独立同分布）适应问题。FedRecon采用轻量级的Multimodal Variational Autoencoder (MVAE)来重建缺失模态，同时通过一个新颖的分布映射机制确保样本级别的跨模态一致性和数据完整性。此外，该方法引入全局生成器冻结策略，以防止灾难性遗忘并缓解Non-IID波动。在多模态数据集上的广泛实验中，FedRecon在Non-IID条件下实现了模态重建的优越性能，超过了现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 32 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09941v1",
      "published_date": "2025-04-14 07:04:10 UTC",
      "updated_date": "2025-04-14 07:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:56:00.919273"
    },
    {
      "arxiv_id": "2504.09936v1",
      "title": "KeepKV: Eliminating Output Perturbation in KV Cache Compression for Efficient LLMs Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Tian",
        "Zihan Wang",
        "Yebo Peng",
        "Aomufei Yuan",
        "Zhiming Wang",
        "Bairen Yi",
        "Xin Liu",
        "Yong Cui",
        "Tong Yang"
      ],
      "abstract": "Efficient inference of large language models (LLMs) is hindered by an\never-growing key-value (KV) cache, making KV cache compression a critical\nresearch direction. Traditional methods selectively evict less important KV\ncache entries based on attention scores or position heuristics, which leads to\ninformation loss and hallucinations. Recently, merging-based strategies have\nbeen explored to retain more information by merging KV pairs that would be\ndiscarded; however, these existing approaches inevitably introduce\ninconsistencies in attention distributions before and after merging, causing\noutput perturbation and degraded generation quality. To overcome this\nchallenge, we propose KeepKV, a novel adaptive KV cache merging method designed\nto eliminate output perturbation while preserving performance under strict\nmemory constraints. KeepKV introduces the Electoral Votes mechanism that\nrecords merging history and adaptively adjusts attention scores. Moreover, it\nfurther leverages a novel Zero Inference-Perturbation Merging methods, keeping\nattention consistency and compensating for attention loss resulting from cache\nmerging. KeepKV successfully retains essential context information within a\nsignificantly compressed cache. Extensive experiments on various benchmarks and\nLLM architectures demonstrate that KeepKV substantially reduces memory usage,\nenhances inference throughput by more than 2x and keeps superior generation\nquality even with 10% KV cache budgets.",
      "tldr_zh": "这篇论文提出 KeepKV，一种新型自适应 KV cache 合并方法，旨在消除 LLMs 推理中的输出扰动问题，同时在严格内存约束下保留关键上下文信息。KeepKV 引入 Electoral Votes 机制来记录合并历史并调整 attention 得分，以及 Zero Inference-Perturbation Merging 方法来保持 attention 一致性并补偿注意力损失。实验在多种基准和 LLM 架构上证明，KeepKV 显著减少内存使用，提高推理吞吐量超过 2 倍，即使 KV cache 预算仅为 10% 时，也保持了优越的生成质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09936v1",
      "published_date": "2025-04-14 06:58:00 UTC",
      "updated_date": "2025-04-14 06:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:56:13.606228"
    },
    {
      "arxiv_id": "2504.09909v1",
      "title": "Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications",
      "title_zh": "量子自然语言处理：模型、方法和应用的全面综述",
      "authors": [
        "Farha Nausheen",
        "Khandakar Ahmed",
        "M Imad Khan"
      ],
      "abstract": "In recent developments, deep learning methodologies applied to Natural\nLanguage Processing (NLP) have revealed a paradox: They improve performance but\ndemand considerable data and resources for their training. Alternatively,\nquantum computing exploits the principles of quantum mechanics to overcome the\ncomputational limitations of current methodologies, thereby establishing an\nemerging field known as quantum natural language processing (QNLP). This domain\nholds the potential to attain a quantum advantage in the processing of\nlinguistic structures, surpassing classical models in both efficiency and\naccuracy. In this paper, it is proposed to categorise QNLP models based on\nquantum computing principles, architecture, and computational approaches. This\npaper attempts to provide a survey on how quantum meets language by mapping\nstate-of-the-art in this area, embracing quantum encoding techniques for\nclassical data, QNLP models for prevalent NLP tasks, and quantum optimisation\ntechniques for hyper parameter tuning. The landscape of quantum computing\napproaches applied to various NLP tasks is summarised by showcasing the\nspecific QNLP methods used, and the popularity of these methods is indicated by\ntheir count. From the findings, it is observed that QNLP approaches are still\nlimited to small data sets, with only a few models explored extensively, and\nthere is increasing interest in the application of quantum computing to natural\nlanguage processing tasks.",
      "tldr_zh": "这篇论文对 Quantum Natural Language Processing (QNLP) 进行了全面综述，探讨了量子计算如何通过量子力学原理克服传统 NLP 方法在数据和资源需求上的局限，从而提升语言处理的效率和准确性。作者基于量子计算原则、架构和计算方法对 QNLP 模型进行了分类，并调研了量子编码技术、QNLP 模型在常见 NLP 任务中的应用，以及量子优化技术用于超参数调整。研究发现，目前 QNLP 主要限于小数据集，且只有少数模型被广泛探索，但对量子计算在自然语言处理领域的兴趣正日益增加。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09909v1",
      "published_date": "2025-04-14 06:09:26 UTC",
      "updated_date": "2025-04-14 06:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:56:24.299563"
    },
    {
      "arxiv_id": "2504.09906v1",
      "title": "Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in Adaptive Video Streaming",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiang He",
        "Zhi Liu"
      ],
      "abstract": "Adaptive video streaming systems are designed to optimize Quality of\nExperience (QoE) and, in turn, enhance user satisfaction. However, differences\nin user profiles and video content lead to different weights for QoE factors,\nresulting in user-specific QoE functions and, thus, varying optimization\nobjectives. This variability poses significant challenges for neural networks,\nas they often struggle to generalize under evolving targets - a phenomenon\nknown as plasticity loss that prevents conventional models from adapting\neffectively to changing optimization objectives. To address this limitation, we\npropose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning\nframework that dynamically modulates network plasticity by balancing memory\nretention with selective forgetting. In particular, PA-MoE leverages noise\ninjection to promote the selective forgetting of outdated knowledge, thereby\nendowing neural networks with enhanced adaptive capabilities. In addition, we\npresent a rigorous theoretical analysis of PA-MoE by deriving a regret bound\nthat quantifies its learning performance. Experimental evaluations demonstrate\nthat PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in\ndynamic streaming environments. Further analysis reveals that the model\neffectively mitigates plasticity loss by optimizing neuron utilization.\nFinally, a parameter sensitivity study is performed by injecting varying levels\nof noise, and the results align closely with our theoretical predictions.",
      "tldr_zh": "这篇论文针对自适应视频流系统中QoE（Quality of Experience）变化带来的神经网络泛化挑战（如plasticity loss），提出了一种新型学习框架Plasticity-Aware Mixture of Experts (PA-MoE)。PA-MoE通过噪声注入动态平衡记忆保留和选择性遗忘，增强模型对用户特定QoE函数的适应能力，并提供了理论上的遗憾界（regret bound）来量化其学习性能。实验结果显示，PA-MoE在动态流媒体环境中比竞争基线提升45.5%的QoE，并有效优化神经元利用率，缓解plasticity loss问题。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09906v1",
      "published_date": "2025-04-14 06:02:41 UTC",
      "updated_date": "2025-04-14 06:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:56:37.288336"
    },
    {
      "arxiv_id": "2504.09895v1",
      "title": "Learning from Reference Answers: Versatile Language Model Alignment without Binary Human Preference Data",
      "title_zh": "从参考答案中学习：无需二元人类偏好数据的多功能语言模型对齐",
      "authors": [
        "Shuai Zhao",
        "Linchao Zhu",
        "Yi Yang"
      ],
      "abstract": "Large language models~(LLMs) are expected to be helpful, harmless, and\nhonest. In various alignment scenarios, such as general human preference,\nsafety, and confidence alignment, binary preference data collection and reward\nmodeling are resource-intensive but necessary for human preference\ntransferring. In this work, we explore using the similarity between sampled\ngenerations and high-quality reference answers as an alternative reward\nfunction for LLM alignment. Using similarity as a reward circumvents training\nreward models, and collecting a single reference answer potentially costs less\ntime than constructing binary preference pairs when multiple candidates are\navailable. Specifically, we develop \\textit{RefAlign}, a versatile\nREINFORCE-style alignment algorithm, which is free of reference and reward\nmodels. Instead, RefAlign utilizes BERTScore between sampled generations and\nhigh-quality reference answers as the surrogate reward. Beyond general human\npreference optimization, RefAlign can be readily extended to diverse scenarios,\nsuch as safety and confidence alignment, by incorporating the similarity reward\nwith task-related objectives. In various scenarios, {RefAlign} demonstrates\ncomparable performance to previous alignment methods while offering high\nefficiency.",
      "tldr_zh": "这篇论文提出了一种名为 RefAlign 的通用算法，用于对齐大型语言模型（LLMs），通过计算生成样本与高质量参考答案的相似度（如 BERTScore）作为奖励函数，取代了传统依赖二元人类偏好数据的资源密集型方法。RefAlign 基于 REINFORCE 风格设计，不需要训练奖励模型，仅需单一参考答案即可高效优化模型。实验显示，该方法在一般人类偏好、安全和信心对齐等场景中，性能与现有方法相当，但数据收集和计算效率更高。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2504.09895v1",
      "published_date": "2025-04-14 05:43:21 UTC",
      "updated_date": "2025-04-14 05:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:56:48.654190"
    },
    {
      "arxiv_id": "2504.09893v1",
      "title": "LangPert: Detecting and Handling Task-level Perturbations for Robust Object Rearrangement",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Yin",
        "Min-Sung Yoon",
        "Yuchi Huo",
        "Kang Zhang",
        "Sung-Eui Yoon"
      ],
      "abstract": "Task execution for object rearrangement could be challenged by Task-Level\nPerturbations (TLP), i.e., unexpected object additions, removals, and\ndisplacements that can disrupt underlying visual policies and fundamentally\ncompromise task feasibility and progress. To address these challenges, we\npresent LangPert, a language-based framework designed to detect and mitigate\nTLP situations in tabletop rearrangement tasks. LangPert integrates a Visual\nLanguage Model (VLM) to comprehensively monitor policy's skill execution and\nenvironmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT)\nreasoning mechanism to enhance the Large Language Model (LLM)'s contextual\nunderstanding and generate adaptive, corrective skill-execution plans. Our\nexperimental results demonstrate that LangPert handles diverse TLP situations\nmore effectively than baseline methods, achieving higher task completion rates,\nimproved execution efficiency, and potential generalization to unseen\nscenarios.",
      "tldr_zh": "本文提出 LangPert，一种基于语言的框架，用于检测和处理对象重排任务中的任务级扰动 (Task-Level Perturbations, TLP)，如对象添加、移除或位移，以提升任务的鲁棒性。该框架整合 Visual Language Model (VLM) 来监控技能执行和环境变化，并利用 Hierarchical Chain-of-Thought (HCoT) 推理机制增强 Large Language Model (LLM) 的上下文理解，从而生成适应性的纠正计划。实验结果表明，LangPert 比基线方法实现了更高的任务完成率、更好的执行效率，并展示了潜在的泛化能力到未见场景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09893v1",
      "published_date": "2025-04-14 05:39:15 UTC",
      "updated_date": "2025-04-14 05:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:57:01.176969"
    },
    {
      "arxiv_id": "2504.09877v1",
      "title": "Constructing Micro Knowledge Graphs from Technical Support Documents",
      "title_zh": "从技术支持文档构建微型知识图谱",
      "authors": [
        "Atul Kumar",
        "Nisha Gupta",
        "Saswati Dana"
      ],
      "abstract": "Short technical support pages such as IBM Technotes are quite common in\ntechnical support domain. These pages can be very useful as the knowledge\nsources for technical support applications such as chatbots, search engines and\nquestion-answering (QA) systems. Information extracted from documents to drive\ntechnical support applications is often stored in the form of Knowledge Graph\n(KG). Building KGs from a large corpus of documents poses a challenge of\ngranularity because a large number of entities and actions are present in each\npage. The KG becomes virtually unusable if all entities and actions from these\npages are stored in the KG. Therefore, only key entities and actions from each\npage are extracted and stored in the KG. This approach however leads to loss of\nknowledge represented by entities and actions left out of the KG as they are no\nlonger available to graph search and reasoning functions. We propose a set of\ntechniques to create micro knowledge graph (micrograph) for each of such web\npages. The micrograph stores all the entities and actions in a page and also\ntakes advantage of the structure of the page to represent exactly in which part\nof that page these entities and actions appeared, and also how they relate to\neach other. These micrographs can be used as additional knowledge sources by\ntechnical support applications. We define schemas for representing\nsemi-structured and plain text knowledge present in the technical support web\npages. Solutions in technical support domain include procedures made of steps.\nWe also propose a technique to extract procedures from these webpages and the\nschemas to represent them in the micrographs. We also discuss how technical\nsupport applications can take advantage of the micrographs.",
      "tldr_zh": "该论文探讨了从技术支持文档（如 IBM Technotes）构建知识图谱（KG）的挑战，即页面中大量实体和动作导致KG过于庞大而难以使用。作者提出一种方法，创建微知识图谱（micrograph）来存储每个页面的所有实体和动作，并利用页面结构表示这些元素的出现位置及其关系，同时定义了表示半结构化文本和程序（procedures）的模式。实验和讨论表明，这种方法能避免知识丢失，并增强技术支持应用如聊天机器人、搜索引擎和问答系统（QA）的性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09877v1",
      "published_date": "2025-04-14 04:57:49 UTC",
      "updated_date": "2025-04-14 04:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:57:13.495037"
    },
    {
      "arxiv_id": "2504.10548v1",
      "title": "Automated Testing of COBOL to Java Transformation",
      "title_zh": "COBOL 到 Java 转换的自动化测试",
      "authors": [
        "Sandeep Hans",
        "Atul Kumar",
        "Toshikai Yasue",
        "Kouichi Ono",
        "Saravanan Krishnan",
        "Devika Sondhi",
        "Fumiko Satoh",
        "Gerald Mitchell",
        "Sachin Kumar",
        "Diptikalyan Saha"
      ],
      "abstract": "Recent advances in Large Language Model (LLM) based Generative AI techniques\nhave made it feasible to translate enterprise-level code from legacy languages\nsuch as COBOL to modern languages such as Java or Python. While the results of\nLLM-based automatic transformation are encouraging, the resulting code cannot\nbe trusted to correctly translate the original code, making manual validation\nof translated Java code from COBOL a necessary but time-consuming and\nlabor-intensive process. In this paper, we share our experience of developing a\ntesting framework for IBM Watsonx Code Assistant for Z (WCA4Z) [5], an\nindustrial tool designed for COBOL to Java translation. The framework automates\nthe process of testing the functional equivalence of the translated Java code\nagainst the original COBOL programs in an industry context. Our framework uses\nsymbolic execution to generate unit tests for COBOL, mocking external calls and\ntransforming them into JUnit tests to validate semantic equivalence with\ntranslated Java. The results not only help identify and repair any detected\ndiscrepancies but also provide feedback to improve the AI model.",
      "tldr_zh": "该研究针对 Large Language Model (LLM) 驱动的 COBOL 到 Java 代码转换问题，开发了一个自动化测试框架，以解决手动验证的耗时问题。框架应用于 IBM Watsonx Code Assistant for Z (WCA4Z)，通过 symbolic execution 生成 COBOL 的单元测试，mocking 外部调用并将其转化为 JUnit 测试，以验证翻译代码的语义等价性。结果显示，该框架不仅能有效识别和修复代码差异，还能提供反馈来优化 AI 模型的性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10548v1",
      "published_date": "2025-04-14 04:53:30 UTC",
      "updated_date": "2025-04-14 04:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:57:25.022379"
    },
    {
      "arxiv_id": "2504.09876v2",
      "title": "HDC: Hierarchical Distillation for Multi-level Noisy Consistency in Semi-Supervised Fetal Ultrasound Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Tran Quoc Khanh Le",
        "Nguyen Lan Vi Vu",
        "Ha-Hieu Pham",
        "Xuan-Loc Huynh",
        "Tien-Huy Nguyen",
        "Minh Huu Nhat Le",
        "Quan Nguyen",
        "Hien D. Nguyen"
      ],
      "abstract": "Transvaginal ultrasound is a critical imaging modality for evaluating\ncervical anatomy and detecting physiological changes. However, accurate\nsegmentation of cervical structures remains challenging due to low contrast,\nshadow artifacts, and indistinct boundaries. While convolutional neural\nnetworks (CNNs) have demonstrated efficacy in medical image segmentation, their\nreliance on large-scale annotated datasets presents a significant limitation in\nclinical ultrasound imaging. Semi-supervised learning (SSL) offers a potential\nsolution by utilizing unlabeled data, yet existing teacher-student frameworks\noften encounter confirmation bias and high computational costs. In this paper,\na novel semi-supervised segmentation framework, called HDC, is proposed\nincorporating adaptive consistency learning with a single-teacher architecture.\nThe framework introduces a hierarchical distillation mechanism with two\nobjectives: Correlation Guidance Loss for aligning feature representations and\nMutual Information Loss for stabilizing noisy student learning. The proposed\napproach reduces model complexity while enhancing generalization. Experiments\non fetal ultrasound datasets, FUGC and PSFH, demonstrate competitive\nperformance with reduced computational overhead compared to multi-teacher\nmodels.",
      "tldr_zh": "该研究针对胎儿超声图像中子宫颈结构的分割挑战（如低对比度、阴影伪影和模糊边界），提出了一种新型半监督学习框架HDC，利用单teacher架构实现自适应一致性学习。HDC引入分层蒸馏机制，包括Correlation Guidance Loss用于对齐特征表示，以及Mutual Information Loss用于稳定noisy student学习，从而减少模型复杂度和计算开销。实验在FUGC和PSFH数据集上显示，该框架与多teacher模型相比表现出竞争性性能，同时提升了泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09876v2",
      "published_date": "2025-04-14 04:52:24 UTC",
      "updated_date": "2025-04-17 01:42:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:57:36.880419"
    },
    {
      "arxiv_id": "2504.09873v1",
      "title": "Truncated Matrix Completion - An Empirical Study",
      "title_zh": "翻译失败",
      "authors": [
        "Rishhabh Naik",
        "Nisarg Trivedi",
        "Davoud Ataee Tarzanagh",
        "Laura Balzano"
      ],
      "abstract": "Low-rank Matrix Completion (LRMC) describes the problem where we wish to\nrecover missing entries of partially observed low-rank matrix. Most existing\nmatrix completion work deals with sampling procedures that are independent of\nthe underlying data values. While this assumption allows the derivation of nice\ntheoretical guarantees, it seldom holds in real-world applications. In this\npaper, we consider various settings where the sampling mask is dependent on the\nunderlying data values, motivated by applications in sensing, sequential\ndecision-making, and recommender systems. Through a series of experiments, we\nstudy and compare the performance of various LRMC algorithms that were\noriginally successful for data-independent sampling patterns.",
      "tldr_zh": "这篇论文通过实证研究探讨了低秩矩阵补全 (LRMC)，即恢复部分观察到的低秩矩阵缺失条目的问题，强调了现有方法通常假设采样过程独立于底层数据值的局限性。作者考虑了采样掩码依赖数据值的实际场景，如传感、顺序决策和推荐系统，并通过一系列实验比较了各种原本成功于数据无关采样模式的 LRMC 算法性能。这些实验揭示了算法在真实世界设置下的优劣，为改进矩阵补全技术提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09873v1",
      "published_date": "2025-04-14 04:42:00 UTC",
      "updated_date": "2025-04-14 04:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:57:48.405205"
    },
    {
      "arxiv_id": "2504.09865v2",
      "title": "Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects",
      "title_zh": "将消息标记为AI生成不会减少其说服效果",
      "authors": [
        "Isabel O. Gallegos",
        "Chen Shani",
        "Weiyan Shi",
        "Federico Bianchi",
        "Izzy Gainsburg",
        "Dan Jurafsky",
        "Robb Willer"
      ],
      "abstract": "As generative artificial intelligence (AI) enables the creation and\ndissemination of information at massive scale and speed, it is increasingly\nimportant to understand how people perceive AI-generated content. One prominent\npolicy proposal requires explicitly labeling AI-generated content to increase\ntransparency and encourage critical thinking about the information, but prior\nresearch has not yet tested the effects of such labels. To address this gap, we\nconducted a survey experiment (N=1601) on a diverse sample of Americans,\npresenting participants with an AI-generated message about several public\npolicies (e.g., allowing colleges to pay student-athletes), randomly assigning\nwhether participants were told the message was generated by (a) an expert AI\nmodel, (b) a human policy expert, or (c) no label. We found that messages were\ngenerally persuasive, influencing participants' views of the policies by 9.74\npercentage points on average. However, while 94.6% of participants assigned to\nthe AI and human label conditions believed the authorship labels, labels had no\nsignificant effects on participants' attitude change toward the policies,\njudgments of message accuracy, nor intentions to share the message with others.\nThese patterns were robust across a variety of participant characteristics,\nincluding prior knowledge of the policy, prior experience with AI, political\nparty, education level, or age. Taken together, these results imply that, while\nauthorship labels would likely enhance transparency, they are unlikely to\nsubstantially affect the persuasiveness of the labeled content, highlighting\nthe need for alternative strategies to address challenges posed by AI-generated\ninformation.",
      "tldr_zh": "本研究通过一项调查实验（N=1601）考察了标记消息为 AI 生成是否能降低其说服力，实验中参与者随机接收关于公共政策的 AI 生成消息，并分配标签（AI 模型生成、人类专家生成或无标签）。结果显示，消息平均影响参与者对政策的观点达 9.74 百分比点，而 94.6% 的参与者相信标签，但标签并未显著改变态度、信息准确性判断或分享意图，且这些发现在参与者特征（如政策知识、AI 经验、政治党派、教育水平和年龄）中保持稳健。总体而言，该研究表明，AI-generated content 的标签能提升透明度，但无法实质减少其说服效果，因此需要探索其他策略应对 AI 生成信息带来的挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09865v2",
      "published_date": "2025-04-14 04:22:39 UTC",
      "updated_date": "2025-04-22 02:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:58:00.156078"
    },
    {
      "arxiv_id": "2504.12335v1",
      "title": "You've Changed: Detecting Modification of Black-Box Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alden Dima",
        "James Foulds",
        "Shimei Pan",
        "Philip Feldman"
      ],
      "abstract": "Large Language Models (LLMs) are often provided as a service via an API,\nmaking it challenging for developers to detect changes in their behavior. We\npresent an approach to monitor LLMs for changes by comparing the distributions\nof linguistic and psycholinguistic features of generated text. Our method uses\na statistical test to determine whether the distributions of features from two\nsamples of text are equivalent, allowing developers to identify when an LLM has\nchanged. We demonstrate the effectiveness of our approach using five OpenAI\ncompletion models and Meta's Llama 3 70B chat model. Our results show that\nsimple text features coupled with a statistical test can distinguish between\nlanguage models. We also explore the use of our approach to detect prompt\ninjection attacks. Our work enables frequent LLM change monitoring and avoids\ncomputationally expensive benchmark evaluations.",
      "tldr_zh": "这篇论文提出了一种检测黑盒Large Language Models (LLMs) 修改的方法，通过比较生成文本的语言学和心理语言学特征分布，使用统计测试来判断两个文本样本的特征是否等价，从而帮助开发者识别模型变化。实验在OpenAI的五个完成模型和Meta的Llama 3 70B聊天模型上进行，结果显示简单文本特征结合统计测试即可有效区分不同语言模型。论文还探讨了该方法在检测prompt injection attacks方面的潜力，并强调其优势在于实现频繁监测LLM变化，而避免了计算密集型的基准评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.12335v1",
      "published_date": "2025-04-14 04:16:43 UTC",
      "updated_date": "2025-04-14 04:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:58:12.743287"
    },
    {
      "arxiv_id": "2504.09861v1",
      "title": "EthosGPT: Mapping Human Value Diversity to Advance Sustainable Development Goals (SDGs)",
      "title_zh": "EthosGPT：映射人类价值多样性以推进可持续发展目标 (SDGs)",
      "authors": [
        "Luyao Zhang"
      ],
      "abstract": "Large language models (LLMs) are transforming global decision-making and\nsocietal systems by processing diverse data at unprecedented scales. However,\ntheir potential to homogenize human values poses critical risks, similar to\nbiodiversity loss undermining ecological resilience. Rooted in the ancient\nGreek concept of ethos, meaning both individual character and the shared moral\nfabric of communities, EthosGPT draws on a tradition that spans from\nAristotle's virtue ethics to Adam Smith's moral sentiments as the ethical\nfoundation of economic cooperation. These traditions underscore the vital role\nof value diversity in fostering social trust, institutional legitimacy, and\nlong-term prosperity. EthosGPT addresses the challenge of value homogenization\nby introducing an open-source framework for mapping and evaluating LLMs within\na global scale of human values. Using international survey data on cultural\nindices, prompt-based assessments, and comparative statistical analyses,\nEthosGPT reveals both the adaptability and biases of LLMs across regions and\ncultures. It offers actionable insights for developing inclusive LLMs, such as\ndiversifying training data and preserving endangered cultural heritage to\nensure representation in AI systems. These contributions align with the United\nNations Sustainable Development Goals (SDGs), especially SDG 10 (Reduced\nInequalities), SDG 11.4 (Cultural Heritage Preservation), and SDG 16 (Peace,\nJustice and Strong Institutions). Through interdisciplinary collaboration,\nEthosGPT promotes AI systems that are both technically robust and ethically\ninclusive, advancing value plurality as a cornerstone for sustainable and\nequitable futures.",
      "tldr_zh": "该论文提出 EthosGPT，一个开源框架，旨在映射人类价值多样性以应对大型语言模型 (LLMs) 可能导致的价值同质化风险，从而支持联合国可持续发展目标 (SDGs)。通过利用国际调查数据、基于提示的评估和统计分析，EthosGPT 揭示了 LLMs 在不同地区和文化中的适应性与偏见，提供可操作见解，如多样化训练数据和保护濒危文化遗产。最终，该框架促进技术上稳健且伦理包容的 AI 系统，与 SDG 10（减少不平等）、SDG 11.4（文化遗产保护）和 SDG 16（和平、正义与强大机构）紧密相关，推动可持续和公平的未来。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "econ.GN",
        "q-fin.EC",
        "stat.AP"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09861v1",
      "published_date": "2025-04-14 04:14:13 UTC",
      "updated_date": "2025-04-14 04:14:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:58:24.937030"
    },
    {
      "arxiv_id": "2504.09860v1",
      "title": "SUMART: SUMmARizing Translation from Wordy to Concise Expression",
      "title_zh": "翻译失败",
      "authors": [
        "Naoto Nishida",
        "Jun Rekimoto"
      ],
      "abstract": "We propose SUMART, a method for summarizing and compressing the volume of\nverbose subtitle translations. SUMART is designed for understanding translated\ncaptions (e.g., interlingual conversations via subtitle translation or when\nwatching movies in foreign language audio and translated captions). SUMART is\nintended for users who want a big-picture and fast understanding of the\nconversation, audio, video content, and speech in a foreign language. During\nthe training data collection, when a speaker makes a verbose statement, SUMART\nemploys a large language model on-site to compress the volume of subtitles.\nThis compressed data is then stored in a database for fine-tuning purposes.\nLater, SUMART uses data pairs from those non-compressed ASR results and\ncompressed translated results for fine-tuning the translation model to generate\nmore concise translations for practical uses. In practical applications, SUMART\nutilizes this trained model to produce concise translation results.\nFurthermore, as a practical application, we developed an application that\nallows conversations using subtitle translation in augmented reality spaces. As\na pilot study, we conducted qualitative surveys using a SUMART prototype and a\nsurvey on the summarization model for SUMART. We envision the most effective\nuse case of this system is where users need to consume a lot of information\nquickly (e.g., Speech, lectures, podcasts, Q&A in conferences).",
      "tldr_zh": "该研究提出 SUMART 方法，用于总结和压缩冗长字幕翻译，以帮助用户快速理解跨语言对话或外语内容（如电影字幕）。SUMART 通过大型语言模型(LLM)现场压缩冗长语句，构建数据集，并使用非压缩 ASR 结果和压缩翻译结果对翻译模型进行微调，从而生成更简洁的翻译输出。在实际应用中，系统开发了增强现实对话应用，并通过试点调查验证了其有效性，特别适用于快速消费大量信息的情景，如演讲、讲座和会议 Q&A。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "3 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09860v1",
      "published_date": "2025-04-14 04:13:09 UTC",
      "updated_date": "2025-04-14 04:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:58:37.268427"
    },
    {
      "arxiv_id": "2504.09858v1",
      "title": "Reasoning Models Can Be Effective Without Thinking",
      "title_zh": "推理模型无需思考也能有效",
      "authors": [
        "Wenjie Ma",
        "Jingxuan He",
        "Charlie Snell",
        "Tyler Griggs",
        "Sewon Min",
        "Matei Zaharia"
      ],
      "abstract": "Recent LLMs have significantly improved reasoning capabilities, primarily by\nincluding an explicit, lengthy Thinking process as part of generation. In this\npaper, we question whether this explicit thinking is necessary. Using the\nstate-of-the-art DeepSeek-R1-Distill-Qwen, we find that bypassing the thinking\nprocess via simple prompting, denoted as NoThinking, can be surprisingly\neffective. When controlling for the number of tokens, NoThinking outperforms\nThinking across a diverse set of seven challenging reasoning\ndatasets--including mathematical problem solving, formal theorem proving, and\ncoding--especially in low-budget settings, e.g., 51.3 vs. 28.9 on ACM 23 with\n700 tokens. Notably, the performance of NoThinking becomes more competitive\nwith pass@k as k increases. Building on this observation, we demonstrate that a\nparallel scaling approach that uses NoThinking to generate N outputs\nindependently and aggregates them is highly effective. For aggregation, we use\ntask-specific verifiers when available, or we apply simple best-of-N strategies\nsuch as confidence-based selection. Our method outperforms a range of baselines\nwith similar latency using Thinking, and is comparable to Thinking with\nsignificantly longer latency (up to 9x). Together, our research encourages a\nreconsideration of the necessity of lengthy thinking processes, while also\nestablishing a competitive reference for achieving strong reasoning performance\nin low-budget settings or at low latency using parallel scaling.",
      "tldr_zh": "本研究质疑大型语言模型（LLMs）是否需要显式的冗长思考过程来提升推理能力，使用 DeepSeek-R1-Distill-Qwen 模型通过 NoThinking 提示方法绕过思考，结果显示在七个挑战性数据集（如数学问题解决、形式定理证明和编码）上，NoThinking 在控制令牌数量时表现优于 Thinking，尤其在低预算设置下（例如，700 令牌时在 ACM 23 上达 51.3 vs. 28.9）。作者进一步提出一种并行缩放方法，独立生成 N 个输出并使用任务特定验证器或最佳-of-N 策略进行聚合，实现与 Thinking 相当的性能，但延迟降低高达 9 倍。该方法为低预算或低延迟场景提供高效的推理参考，鼓励重新审视思考过程的必要性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 7 main figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.09858v1",
      "published_date": "2025-04-14 04:08:16 UTC",
      "updated_date": "2025-04-14 04:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:58:51.026073"
    },
    {
      "arxiv_id": "2504.09857v1",
      "title": "Working with Large Language Models to Enhance Messaging Effectiveness for Vaccine Confidence",
      "title_zh": "利用大型语言模型提升疫苗信心信息传播的有效性",
      "authors": [
        "Lucinda Gullison",
        "Feng Fu"
      ],
      "abstract": "Vaccine hesitancy and misinformation are significant barriers to achieving\nwidespread vaccination coverage. Smaller public health departments may lack the\nexpertise or resources to craft effective vaccine messaging. This paper\nexplores the potential of ChatGPT-augmented messaging to promote confidence in\nvaccination uptake.\n  We conducted a survey in which participants chose between pairs of\nvaccination messages and assessed which was more persuasive and to what extent.\nIn each pair, one message was the original, and the other was augmented by\nChatGPT. At the end of the survey, participants were informed that half of the\nmessages had been generated by ChatGPT. They were then asked to provide both\nquantitative and qualitative responses regarding how knowledge of a message's\nChatGPT origin affected their impressions.\n  Overall, ChatGPT-augmented messages were rated slightly higher than the\noriginal messages. These messages generally scored better when they were\nlonger. Respondents did not express major concerns about ChatGPT-generated\ncontent, nor was there a significant relationship between participants' views\non ChatGPT and their message ratings. Notably, there was a correlation between\nwhether a message appeared first or second in a pair and its score.\n  These results point to the potential of ChatGPT to enhance vaccine messaging,\nsuggesting a promising direction for future research on human-AI collaboration\nin public health communication.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型（Large Language Models，如 ChatGPT）来提升疫苗宣传的有效性，以应对疫苗犹豫和误信息问题。研究通过一项调查，让参与者比较原版和 ChatGPT 增强的疫苗消息，结果显示增强消息的说服力略高，尤其在消息长度较长时，且参与者对 ChatGPT 生成内容没有重大担忧。论文还发现，消息呈现顺序会影响评分，并建议未来研究人类-AI 合作在公共卫生通信中的潜力。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09857v1",
      "published_date": "2025-04-14 04:06:46 UTC",
      "updated_date": "2025-04-14 04:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:59:00.853540"
    },
    {
      "arxiv_id": "2505.14841v1",
      "title": "Beyond Pairwise Plasticity: Group-Level Spike Synchrony Facilitates Efficient Learning in Spiking Neural Networks",
      "title_zh": "超越成对可塑性：群体级别的",
      "authors": [
        "Yuchen Tian",
        "Assel Kembay",
        "Nhan Duy Truong",
        "Jason K. Eshraghian",
        "Omid Kavehei"
      ],
      "abstract": "Brain networks rely on precise spike timing and coordinated activity to\nsupport robust and energy-efficient learning. Inspired by these principles,\nspiking neural networks (SNNs) are widely regarded as promising candidates for\nlow-power, event-driven computing. However, most biologically-inspired learning\nrules employed in SNNs, including spike-timing-dependent plasticity (STDP),\nrely on isolated spike pairs and lack sensitivity to population-level activity.\nThis limits their stability and generalization, particularly in noisy and\nfast-changing environments. Motivated by biological observations that neural\nsynchrony plays a central role in learning and memory, we introduce a\nspike-synchrony-dependent plasticity (SSDP) rule that adjusts synaptic weights\nbased on the degree of coordinated firing among neurons. SSDP supports stable\nand scalable learning by encouraging neurons to form coherent activity\npatterns. One prominent outcome is a sudden transition from unstable to stable\ndynamics during training, suggesting that synchrony may drive convergence\ntoward equilibrium firing regimes. We demonstrate SSDP's effectiveness across\nmultiple network types, from minimal-layer models to spiking ResNets and\nSNN-Transformer. To our knowledge, this is the first application of a synaptic\nplasticity mechanism in a spiking transformer. SSDP operates in a fully\nevent-driven manner and incurs minimal computational cost, making it\nwell-suited for neuromorphic deployment. In this approach, local synaptic\nmodifications are associated with the collective dynamics of neural networks,\nresulting in a learning strategy that adheres to biological principles while\nmaintaining practical efficiency, these findings position SSDP as a\ngeneral-purpose optimization strategy for SNNs, while offering new insights\ninto population-based learning mechanisms in the brain.",
      "tldr_zh": "该论文批评现有 SNNs 的学习规则，如 STDP，仅依赖于孤立的 spike pairs，导致在噪声环境中学习稳定性差。研究提出了一种新的 spike-synchrony-dependent plasticity (SSDP) 规则，通过基于神经元协调 firing 的程度调整突触权重，促进神经元形成连贯活动模式，从而实现稳定、可扩展的学习。实验验证了 SSDP 在多种网络类型上（如 spiking ResNets 和 SNN-Transformer）的有效性，展示了训练中从不稳定到稳定的转变，并证明其事件驱动、低计算成本，适合 neuromorphic 部署，为 SNNs 优化和脑部学习机制提供新见解。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "22 pages, 7 figures, 5 tables. This work proposes SSDP, a\n  biologically inspired spike-synchrony-dependent plasticity rule. We\n  demonstrate its effectiveness across shallow and deep spiking architectures\n  including Spiking-ResNet18 and SNN-Transformer",
      "pdf_url": "http://arxiv.org/pdf/2505.14841v1",
      "published_date": "2025-04-14 04:01:40 UTC",
      "updated_date": "2025-04-14 04:01:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:59:13.728793"
    },
    {
      "arxiv_id": "2504.09855v1",
      "title": "PestMA: LLM-based Multi-Agent System for Informed Pest Management",
      "title_zh": "翻译失败",
      "authors": [
        "Hongrui Shi",
        "Shunbao Li",
        "Zhipeng Yuan",
        "Po Yang"
      ],
      "abstract": "Effective pest management is complex due to the need for accurate,\ncontext-specific decisions. Recent advancements in large language models (LLMs)\nopen new possibilities for addressing these challenges by providing\nsophisticated, adaptive knowledge acquisition and reasoning. However, existing\nLLM-based pest management approaches often rely on a single-agent paradigm,\nwhich can limit their capacity to incorporate diverse external information,\nengage in systematic validation, and address complex, threshold-driven\ndecisions. To overcome these limitations, we introduce PestMA, an LLM-based\nmulti-agent system (MAS) designed to generate reliable and evidence-based pest\nmanagement advice. Building on an editorial paradigm, PestMA features three\nspecialized agents, an Editor for synthesizing pest management recommendations,\na Retriever for gathering relevant external data, and a Validator for ensuring\ncorrectness. Evaluations on real-world pest scenarios demonstrate that PestMA\nachieves an initial accuracy of 86.8% for pest management decisions, which\nincreases to 92.6% after validation. These results underscore the value of\ncollaborative agent-based workflows in refining and validating decisions,\nhighlighting the potential of LLM-based multi-agent systems to automate and\nenhance pest management processes.",
      "tldr_zh": "该研究引入了PestMA，一种基于LLM的Multi-Agent System，用于提供可靠的害虫管理建议，以解决现有单智能体方法的局限性，如整合外部信息和系统验证不足。PestMA采用编辑范式，由三个专门智能体组成：Editor负责合成推荐、Retriever收集相关外部数据，以及Validator确保决策的正确性。在真实害虫场景的评估中，PestMA的初始准确率达86.8%，经验证后提升至92.6%，突显了多智能体协作在自动化和优化害虫管理过程中的价值。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "I.2.1; I.2.7"
      ],
      "primary_category": "cs.MA",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.09855v1",
      "published_date": "2025-04-14 03:53:59 UTC",
      "updated_date": "2025-04-14 03:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:59:24.536184"
    },
    {
      "arxiv_id": "2504.09851v1",
      "title": "Carbon-Efficient 3D DNN Acceleration: Optimizing Performance and Sustainability",
      "title_zh": "翻译失败",
      "authors": [
        "Aikaterini Maria Panteleaki",
        "Konstantinos Balaskas",
        "Georgios Zervakis",
        "Hussam Amrouch",
        "Iraklis Anagnostopoulos"
      ],
      "abstract": "As Deep Neural Networks (DNNs) continue to drive advancements in artificial\nintelligence, the design of hardware accelerators faces growing concerns over\nembodied carbon footprint due to complex fabrication processes. 3D integration\nimproves performance but introduces sustainability challenges, making\ncarbon-aware optimization essential. In this work, we propose a\ncarbon-efficient design methodology for 3D DNN accelerators, leveraging\napproximate computing and genetic algorithm-based design space exploration to\noptimize Carbon Delay Product (CDP). By integrating area-efficient approximate\nmultipliers into Multiply-Accumulate (MAC) units, our approach effectively\nreduces silicon area and fabrication overhead while maintaining high\ncomputational accuracy. Experimental evaluations across three technology nodes\n(45nm, 14nm, and 7nm) show that our method reduces embodied carbon by up to 30%\nwith negligible accuracy drop.",
      "tldr_zh": "随着 Deep Neural Networks (DNNs) 的快速发展，硬件加速器设计面临着复杂的碳足迹问题，本文提出了一种碳高效的 3D DNN 加速器设计方法，旨在优化性能和可持续性。该方法结合 approximate computing 和 genetic algorithm-based design space exploration 来最小化 Carbon Delay Product (CDP)，并通过在 Multiply-Accumulate (MAC) 单位中集成 area-efficient approximate multipliers，显著减少硅面积和制造开销。实验评估在 45nm、14nm 和 7nm 技术节点上显示，该方法可将 embodied carbon 减少高达 30%，同时计算准确性损失微不足道。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Submitted in ISVLSI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09851v1",
      "published_date": "2025-04-14 03:48:37 UTC",
      "updated_date": "2025-04-14 03:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:59:39.031937"
    },
    {
      "arxiv_id": "2504.09848v1",
      "title": "A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Feng",
        "Jinwei Zeng",
        "Qingyue Long",
        "Hongyi Chen",
        "Jie Zhao",
        "Yanxin Xi",
        "Zhilun Zhou",
        "Yuan Yuan",
        "Shengyuan Wang",
        "Qingbin Zeng",
        "Songwei Li",
        "Yunke Zhang",
        "Yuming Lin",
        "Tong Li",
        "Jingtao Ding",
        "Chen Gao",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "Over the past year, the development of large language models (LLMs) has\nbrought spatial intelligence into focus, with much attention on vision-based\nembodied intelligence. However, spatial intelligence spans a broader range of\ndisciplines and scales, from navigation and urban planning to remote sensing\nand earth science. What are the differences and connections between spatial\nintelligence across these fields? In this paper, we first review human spatial\ncognition and its implications for spatial intelligence in LLMs. We then\nexamine spatial memory, knowledge representations, and abstract reasoning in\nLLMs, highlighting their roles and connections. Finally, we analyze spatial\nintelligence across scales -- from embodied to urban and global levels --\nfollowing a framework that progresses from spatial memory and understanding to\nspatial reasoning and intelligence. Through this survey, we aim to provide\ninsights into interdisciplinary spatial intelligence research and inspire\nfuture studies.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)驱动的空间智能在不同规模的应用，包括具身代理、智能城市和地球科学领域的发展。论文首先回顾人类空间认知及其对LLMs的影响，然后分析LLMs中的空间记忆、知识表示和抽象推理，并探讨这些元素在跨规模空间智能中的作用和联系。最终，通过一个从空间记忆到空间推理的框架，该研究揭示了这些领域的差异与关联，提供跨学科见解并激励未来的研究方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09848v1",
      "published_date": "2025-04-14 03:38:31 UTC",
      "updated_date": "2025-04-14 03:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T12:59:49.079997"
    },
    {
      "arxiv_id": "2504.09846v1",
      "title": "GlyTwin: Digital Twin for Glucose Control in Type 1 Diabetes Through Optimal Behavioral Modifications Using Patient-Centric Counterfactuals",
      "title_zh": "翻译失败",
      "authors": [
        "Asiful Arefeen",
        "Saman Khamesian",
        "Maria Adela Grando",
        "Bithika Thompson",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Frequent and long-term exposure to hyperglycemia (i.e., high blood glucose)\nincreases the risk of chronic complications such as neuropathy, nephropathy,\nand cardiovascular disease. Current technologies like continuous subcutaneous\ninsulin infusion (CSII) and continuous glucose monitoring (CGM) primarily model\nspecific aspects of glycemic control-like hypoglycemia prediction or insulin\ndelivery. Similarly, most digital twin approaches in diabetes management\nsimulate only physiological processes. These systems lack the ability to offer\nalternative treatment scenarios that support proactive behavioral\ninterventions. To address this, we propose GlyTwin, a novel digital twin\nframework that uses counterfactual explanations to simulate optimal treatments\nfor glucose regulation. Our approach helps patients and caregivers modify\nbehaviors like carbohydrate intake and insulin dosing to avoid abnormal glucose\nevents. GlyTwin generates behavioral treatment suggestions that proactively\nprevent hyperglycemia by recommending small adjustments to daily choices,\nreducing both frequency and duration of these events. Additionally, it\nincorporates stakeholder preferences into the intervention design, making\nrecommendations patient-centric and tailored. We evaluate GlyTwin on AZT1D, a\nnewly constructed dataset with longitudinal data from 21 type 1 diabetes (T1D)\npatients on automated insulin delivery systems over 26 days. Results show\nGlyTwin outperforms state-of-the-art counterfactual methods, generating 76.6%\nvalid and 86% effective interventions. These findings demonstrate the promise\nof counterfactual-driven digital twins in delivering personalized healthcare.",
      "tldr_zh": "本研究提出GlyTwin，一种新型数字孪生框架，用于1型糖尿病(T1D)患者，通过基于反事实解释(counterfactual explanations)的优化行为修改来实现血糖控制。该框架帮助患者和护理者调整日常行为，如碳水化合物摄入和胰岛素剂量，生成个性化的预防性建议，以减少高血糖事件的频率和持续时间，同时融入患者偏好确保推荐的针对性。在AZT1D数据集（来自21名T1D患者26天数据）的评估中，GlyTwin优于现有方法，实现了76.6%的干预有效性和86%的实际效果，展示了其在个性化医疗中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09846v1",
      "published_date": "2025-04-14 03:32:39 UTC",
      "updated_date": "2025-04-14 03:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:00:00.574316"
    },
    {
      "arxiv_id": "2504.09844v2",
      "title": "OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training",
      "title_zh": "翻译失败",
      "authors": [
        "Juntao Zhao",
        "Qi Lu",
        "Wei Jia",
        "Borui Wan",
        "Lei Zuo",
        "Junda Feng",
        "Jianyu Jiang",
        "Yangrui Chen",
        "Shuaishuai Cao",
        "Jialing He",
        "Kaihua Jiang",
        "Yuanzhe Hu",
        "Shibiao Nong",
        "Yanghua Peng",
        "Haibin Lin",
        "Xin Liu",
        "Chuan Wu"
      ],
      "abstract": "Modern frameworks for training large foundation models (LFMs) employ\ndataloaders in a data-parallel manner, with each loader processing a disjoint\nsubset of training data. Under multisource preprocessing, two fundamental\nchallenges exist. First, due to the quadratic computational complexity of the\nattention operator, the non-uniform sample distribution over data-parallel\nranks leads to significant workload imbalance among dataloaders, degrading the\ntraining efficiency. Second, supporting diverse data sources requires\nper-dataset file access states that are redundantly replicated across parallel\nloaders, consuming excessive memory. This also hinders dynamic data mixing\n(e.g., curriculum learning) and causes redundant access/memory overhead in\nhybrid parallelism.\n  We present Omniload, an industrial-grade distributed data loading\narchitecture for LFMs, with four innovations: (1) Disaggregated data\npreprocessing via role-specific actors (Source Loaders/Data Constructors) to\neliminate source and parallelism redundant data access and ensure multisource\nscalability. (2) Centralized and declarative data plane for elastic multisource\norchestration, such as long-short context, multimodality, and curriculum\nlearning. (3) Multi-level auto-partitioning and scaling mechanism for source\nloaders under heterogeneous preprocessing costs. (4) Shadow loaders with\ndifferential checkpointing for fault recovery without workflow interruption.\nDeployed on production clusters scaling to multi-thousand GPUs, Omniload\nachieves: (1) 4.5x end-to-end training throughput improvement, (2) 13.5x\nreduction in CPU memory usage.",
      "tldr_zh": "该论文探讨了在多源数据环境下训练大型基础模型（LFMs）的挑战，包括数据加载工作负载不均衡和冗余内存占用问题，导致训练效率低下。作者提出Omniload，一种工业级分布式数据加载架构，创新性地包括角色特定actors分离数据预处理、中央化数据平面支持弹性编排、多级自动分区机制以及影子加载器（Shadow loaders）用于故障恢复。实验结果显示，在数千GPU生产集群上，Omniload实现了4.5倍的端到端训练吞吐量提升和13.5倍的CPU内存使用减少，为高效扩展LFM训练提供了可靠解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09844v2",
      "published_date": "2025-04-14 03:31:22 UTC",
      "updated_date": "2025-05-18 15:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:00:13.220264"
    },
    {
      "arxiv_id": "2504.09841v1",
      "title": "StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Feng",
        "Xudong Pan"
      ],
      "abstract": "The proliferation of autonomous agents powered by large language models\n(LLMs) has revolutionized popular business applications dealing with tabular\ndata, i.e., tabular agents. Although LLMs are observed to be vulnerable against\nprompt injection attacks from external data sources, tabular agents impose\nstrict data formats and predefined rules on the attacker's payload, which are\nineffective unless the agent navigates multiple layers of structural data to\nincorporate the payload. To address the challenge, we present a novel attack\ntermed StruPhantom which specifically targets black-box LLM-powered tabular\nagents. Our attack designs an evolutionary optimization procedure which\ncontinually refines attack payloads via the proposed constrained Monte Carlo\nTree Search augmented by an off-topic evaluator. StruPhantom helps\nsystematically explore and exploit the weaknesses of target applications to\nachieve goal hijacking. Our evaluation validates the effectiveness of\nStruPhantom across various LLM-based agents, including those on real-world\nplatforms, and attack scenarios. Our attack achieves over 50% higher success\nrates than baselines in enforcing the application's response to contain\nphishing links or malicious codes.",
      "tldr_zh": "本研究提出了一种名为StruPhantom的攻击方法，针对黑盒Large Language Models (LLMs)驱动的表格代理(tabular agents)，通过进化优化过程来规避其严格数据格式和规则的限制，实现有效的提示注入攻击。方法利用约束的Monte Carlo Tree Search和off-topic evaluator持续优化攻击payload，以系统探索并利用目标应用的弱点，从而实现目标劫持。实验结果显示，StruPhantom在各种LLM-based代理上，包括真实世界平台，成功率比基线方法高出50%以上，能够强制应用响应包含钓鱼链接或恶意代码。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2504.09841v1",
      "published_date": "2025-04-14 03:22:04 UTC",
      "updated_date": "2025-04-14 03:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:00:24.483113"
    },
    {
      "arxiv_id": "2504.09839v1",
      "title": "SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis",
      "title_zh": "SafeSpeech：鲁棒且通用的语音保护对抗恶意语音合成",
      "authors": [
        "Zhisheng Zhang",
        "Derui Wang",
        "Qianyi Yang",
        "Pengyang Huang",
        "Junhan Pu",
        "Yuxin Cao",
        "Kai Ye",
        "Jie Hao",
        "Yixian Yang"
      ],
      "abstract": "Speech synthesis technology has brought great convenience, while the\nwidespread usage of realistic deepfake audio has triggered hazards. Malicious\nadversaries may unauthorizedly collect victims' speeches and clone a similar\nvoice for illegal exploitation (\\textit{e.g.}, telecom fraud). However, the\nexisting defense methods cannot effectively prevent deepfake exploitation and\nare vulnerable to robust training techniques. Therefore, a more effective and\nrobust data protection method is urgently needed. In response, we propose a\ndefensive framework, \\textit{\\textbf{SafeSpeech}}, which protects the users'\naudio before uploading by embedding imperceptible perturbations on original\nspeeches to prevent high-quality synthetic speech. In SafeSpeech, we devise a\nrobust and universal proactive protection technique, \\textbf{S}peech\n\\textbf{PE}rturbative \\textbf{C}oncealment (\\textbf{SPEC}), that leverages a\nsurrogate model to generate universally applicable perturbation for generative\nsynthetic models. Moreover, we optimize the human perception of embedded\nperturbation in terms of time and frequency domains. To evaluate our method\ncomprehensively, we conduct extensive experiments across advanced models and\ndatasets, both subjectively and objectively. Our experimental results\ndemonstrate that SafeSpeech achieves state-of-the-art (SOTA) voice protection\neffectiveness and transferability and is highly robust against advanced\nadaptive adversaries. Moreover, SafeSpeech has real-time capability in\nreal-world tests. The source code is available at\n\\href{https://github.com/wxzyd123/SafeSpeech}{https://github.com/wxzyd123/SafeSpeech}.",
      "tldr_zh": "该研究针对语音合成技术的滥用（如deepfake audio用于电信诈骗）提出了一种鲁棒且通用的防御框架SafeSpeech，通过在上传音频前嵌入不易察觉的扰动（imperceptible perturbations）来防止高品质合成语音生成。具体而言，SafeSpeech引入了Speech Perturbative Concealment (SPEC)方法，利用surrogate model生成适用于多种生成模型的通用扰动，并优化扰动在时间和频率域的人类感知。实验结果显示，SafeSpeech在多种高级模型和数据集上实现了state-of-the-art (SOTA)保护效果、转移性（transferability），并对adaptive adversaries高度鲁棒，同时具备实时处理能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to USENIX Security 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09839v1",
      "published_date": "2025-04-14 03:21:23 UTC",
      "updated_date": "2025-04-14 03:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:00:36.909830"
    },
    {
      "arxiv_id": "2504.09831v1",
      "title": "Offline Dynamic Inventory and Pricing Strategy: Addressing Censored and Dependent Demand",
      "title_zh": "翻译失败",
      "authors": [
        "Korel Gundem",
        "Zhengling Qi"
      ],
      "abstract": "In this paper, we study the offline sequential feature-based pricing and\ninventory control problem where the current demand depends on the past demand\nlevels and any demand exceeding the available inventory is lost. Our goal is to\nleverage the offline dataset, consisting of past prices, ordering quantities,\ninventory levels, covariates, and censored sales levels, to estimate the\noptimal pricing and inventory control policy that maximizes long-term profit.\nWhile the underlying dynamic without censoring can be modeled by Markov\ndecision process (MDP), the primary obstacle arises from the observed process\nwhere demand censoring is present, resulting in missing profit information, the\nfailure of the Markov property, and a non-stationary optimal policy. To\novercome these challenges, we first approximate the optimal policy by solving a\nhigh-order MDP characterized by the number of consecutive censoring instances,\nwhich ultimately boils down to solving a specialized Bellman equation tailored\nfor this problem. Inspired by offline reinforcement learning and survival\nanalysis, we propose two novel data-driven algorithms to solving these Bellman\nequations and, thus, estimate the optimal policy. Furthermore, we establish\nfinite sample regret bounds to validate the effectiveness of these algorithms.\nFinally, we conduct numerical experiments to demonstrate the efficacy of our\nalgorithms in estimating the optimal policy. To the best of our knowledge, this\nis the first data-driven approach to learning optimal pricing and inventory\ncontrol policies in a sequential decision-making environment characterized by\ncensored and dependent demand. The implementations of the proposed algorithms\nare available at https://github.com/gundemkorel/Inventory_Pricing_Control",
      "tldr_zh": "本文研究离线动态库存和定价策略，针对需求审查（censored demand）和依赖性问题，利用历史数据集（包括价格、订购量、库存水平、协变量和审查销售数据）来估计最优策略，以最大化长期利润。作者通过构建高阶 Markov Decision Process (MDP) 并解决专门的 Bellman equation 来近似最优策略，克服了审查导致的信息缺失和非平稳性挑战。基于 offline reinforcement learning 和 survival analysis 的灵感，提出两种新数据驱动算法，并建立了 finite sample regret bounds 来验证其有效性。数值实验显示，这些算法在估计最优策略方面表现出色，这是首个针对此类环境的创新方法。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.AP",
        "stat.TH",
        "90B05, 68T05, 90C40, 62N02"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09831v1",
      "published_date": "2025-04-14 02:57:51 UTC",
      "updated_date": "2025-04-14 02:57:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:00:50.236920"
    },
    {
      "arxiv_id": "2504.09812v1",
      "title": "Efficient Multi-Task Modeling through Automated Fusion of Trained Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jingxuan Zhou",
        "Weidong Bao",
        "Ji Wang",
        "Zhengyi Zhong",
        "Dayu Zhang"
      ],
      "abstract": "Although multi-task learning is widely applied in intelligent services,\ntraditional multi-task modeling methods often require customized designs based\non specific task combinations, resulting in a cumbersome modeling process.\nInspired by the rapid development and excellent performance of single-task\nmodels, this paper proposes an efficient multi-task modeling method that can\nautomatically fuse trained single-task models with different structures and\ntasks to form a multi-task model. As a general framework, this method allows\nmodelers to simply prepare trained models for the required tasks, simplifying\nthe modeling process while fully utilizing the knowledge contained in the\ntrained models. This eliminates the need for excessive focus on task\nrelationships and model structure design. To achieve this goal, we consider the\nstructural differences among various trained models and employ model\ndecomposition techniques to hierarchically decompose them into multiple\noperable model components. Furthermore, we have designed an Adaptive Knowledge\nFusion (AKF) module based on Transformer, which adaptively integrates\nintra-task and inter-task knowledge based on model components. Through the\nproposed method, we achieve efficient and automated construction of multi-task\nmodels, and its effectiveness is verified through extensive experiments on\nthree datasets.",
      "tldr_zh": "该论文提出了一种高效的多任务建模方法，能够自动融合不同结构和任务的训练单任务模型，形成多任务模型，从而简化建模过程并充分利用现有模型知识。方法通过模型分解技术将训练模型层次分解成可操作组件，并设计了基于Transformer's Adaptive Knowledge Fusion (AKF) 模块，来自适应整合任务内和任务间知识。相比传统方法，该框架无需过多关注任务关系和模型结构设计，并在三个数据集上通过广泛实验验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09812v1",
      "published_date": "2025-04-14 02:21:45 UTC",
      "updated_date": "2025-04-14 02:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:01:00.587806"
    },
    {
      "arxiv_id": "2504.09809v2",
      "title": "See or Recall: A Sanity Check for the Role of Vision in Solving Visualization Question Answer Tasks with Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Zhimin Li",
        "Haichao Miao",
        "Xinyuan Yan",
        "Valerio Pascucci",
        "Matthew Berger",
        "Shusen Liu"
      ],
      "abstract": "Recent developments in multimodal large language models (MLLM) have equipped\nlanguage models to reason about vision and language jointly. This permits MLLMs\nto both perceive and answer questions about data visualization across a variety\nof designs and tasks. Applying MLLMs to a broad range of visualization tasks\nrequires us to properly evaluate their capabilities, and the most common way to\nconduct evaluation is through measuring a model's visualization reasoning\ncapability, analogous to how we would evaluate human understanding of\nvisualizations (e.g., visualization literacy). However, we found that in the\ncontext of visualization question answering (VisQA), how an MLLM perceives and\nreasons about visualizations can be fundamentally different from how humans\napproach the same problem. During the evaluation, even without visualization,\nthe model could correctly answer a substantial portion of the visualization\ntest questions, regardless of whether any selection options were provided. We\nhypothesize that the vast amount of knowledge encoded in the language model\npermits factual recall that supersedes the need to seek information from the\nvisual signal. It raises concerns that the current VisQA evaluation may not\nfully capture the models' visualization reasoning capabilities. To address\nthis, we propose a comprehensive sanity check framework that integrates a\nrule-based decision tree and a sanity check table to disentangle the effects of\n\"seeing\" (visual processing) and \"recall\" (reliance on prior knowledge). This\nvalidates VisQA datasets for evaluation, highlighting where models are truly\n\"seeing\", positively or negatively affected by the factual recall, or relying\non inductive biases for question answering. Our study underscores the need for\ncareful consideration in designing future visualization understanding studies\nwhen utilizing MLLMs.",
      "tldr_zh": "这篇论文探讨了多模态大型语言模型 (Multimodal LLMs) 在可视化问题回答 (VisQA) 任务中，视觉处理 (“seeing”) 与知识回忆 (“recall”) 的作用，指出模型可能过度依赖其编码的先验知识，而非实际感知可视化信息。研究发现，即使没有可视化输入，MLLMs 也能正确回答大量问题，这质疑了当前 VisQA 评估的有效性。论文提出一个全面的 sanity check 框架，包括基于规则的决策树和 sanity check table，用于区分视觉处理和知识回忆的影响，从而验证 VisQA 数据集。最终，该研究强调在设计未来的可视化理解研究时，需要谨慎考虑 MLLMs 的归纳偏差和评估方法。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09809v2",
      "published_date": "2025-04-14 02:19:28 UTC",
      "updated_date": "2025-04-21 20:52:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:01:14.168041"
    },
    {
      "arxiv_id": "2504.09802v1",
      "title": "Training Small Reasoning LLMs with Cognitive Preference Alignment",
      "title_zh": "通过认知偏好对齐训练小型推理大语言模型",
      "authors": [
        "Wenrui Cai",
        "Chengyu Wang",
        "Junbing Yan",
        "Jun Huang",
        "Xiangzhong Fang"
      ],
      "abstract": "The reasoning capabilities of large language models (LLMs), such as OpenAI's\no1 and DeepSeek-R1, have seen substantial advancements through deep thinking.\nHowever, these enhancements come with significant resource demands,\nunderscoring the need to explore strategies to train effective reasoning LLMs\nwith far fewer parameters. A critical challenge is that smaller models have\ndifferent capacities and cognitive trajectories than their larger counterparts.\nHence, direct distillation of chain-of-thought (CoT) results from large LLMs to\nsmaller ones can be sometimes ineffective and requires a huge amount of\nannotated data. In this paper, we introduce a novel framework called\nCritique-Rethink-Verify (CRV), designed for training smaller yet powerful\nreasoning LLMs. Our CRV framework consists of multiple LLM agents, each\nspecializing in unique abilities: (i) critiquing the CoTs according to the\ncognitive capabilities of smaller models, (ii) rethinking and refining these\nCoTs based on the critiques, and (iii) verifying the correctness of the refined\nresults. We further propose the cognitive preference optimization (CogPO)\nalgorithm to enhance the reasoning abilities of smaller models by aligning\nthoughts of these models with their cognitive capacities. Comprehensive\nevaluations on challenging reasoning benchmarks demonstrate the efficacy of CRV\nand CogPO, which outperforms other training methods by a large margin.",
      "tldr_zh": "这篇论文探讨了训练小型推理大语言模型（LLMs）的挑战，特别是资源需求和认知能力差异问题，提出了一种名为 Critique-Rethink-Verify (CRV) 的框架来解决直接从大型模型中蒸馏 Chain-of-Thought (CoT) 的低效问题。CRV 框架由多个 LLM 代理组成，分别负责根据小型模型的认知能力批评 CoT、重新思考和精炼这些思路，以及验证结果的正确性。论文进一步引入了 Cognitive Preference Optimization (CogPO) 算法，通过优化小型模型的思考过程使其与自身认知容量对齐，从而增强推理能力。在各种挑战性推理基准测试中，CRV 和 CogPO 框架大幅优于其他训练方法，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09802v1",
      "published_date": "2025-04-14 02:03:54 UTC",
      "updated_date": "2025-04-14 02:03:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:01:25.403286"
    },
    {
      "arxiv_id": "2504.09800v1",
      "title": "Multi-task Federated Learning with Encoder-Decoder Structure: Enabling Collaborative Learning Across Different Tasks",
      "title_zh": "多任务联邦学习与编码器-解码器结构：实现不同任务间的协作学习",
      "authors": [
        "Jingxuan Zhou",
        "Weidong Bao",
        "Ji Wang",
        "Dayu Zhang",
        "Xiongtao Zhang",
        "Yaohong Zhang"
      ],
      "abstract": "Federated learning has been extensively studied and applied due to its\nability to ensure data security in distributed environments while building\nbetter models. However, clients participating in federated learning still face\nlimitations, as clients with different structures or tasks cannot participate\nin learning together. In view of this, constructing a federated learning\nframework that allows collaboration between clients with different model\nstructures and performing different tasks, enabling them to share valuable\nknowledge to enhance model efficiency, holds significant practical implications\nfor the widespread application of federated learning. To achieve this goal, we\npropose a multi-task federated learning with encoder-decoder structure (M-Fed).\nSpecifically, given the widespread adoption of the encoder-decoder architecture\nin current models, we leverage this structure to share intra-task knowledge\nthrough traditional federated learning methods and extract general knowledge\nfrom the encoder to achieve cross-task knowledge sharing. The training process\nis similar to traditional federated learning, and we incorporate local decoder\nand global decoder information into the loss function. The local decoder\niteratively updates and gradually approaches the global decoder until\nsufficient cross-task knowledge sharing is achieved. Our method is lightweight\nand modular, demonstrating innovation compared to previous research. It enables\nclients performing different tasks to share general knowledge while maintaining\nthe efficiency of traditional federated learning systems. We conducted\nexperiments on two widely used benchmark datasets to verify the feasibility of\nM-Fed and compared it with traditional methods. The experimental results\ndemonstrate the effectiveness of M-Fed in multi-task federated learning.",
      "tldr_zh": "这篇论文针对 Federated Learning 中不同模型结构或任务的客户端无法协作学习的问题，提出了一种名为 M-Fed 的多任务 Federated Learning 框架。M-Fed 利用 Encoder-Decoder 架构，通过传统 Federated Learning 方法共享任务内知识，并从 Encoder 提取通用知识实现跨任务知识共享，训练过程将本地和全局 Decoder 信息纳入损失函数以逐步优化。实验在两个基准数据集上验证了 M-Fed 的有效性，其性能优于传统方法，展示了其在提升模型效率方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09800v1",
      "published_date": "2025-04-14 02:01:39 UTC",
      "updated_date": "2025-04-14 02:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:01:36.774198"
    },
    {
      "arxiv_id": "2504.09797v1",
      "title": "IGL-DT: Iterative Global-Local Feature Learning with Dual-Teacher Semantic Segmentation Framework under Limited Annotation Scheme",
      "title_zh": "翻译失败",
      "authors": [
        "Dinh Dai Quan Tran",
        "Hoang-Thien Nguyen. Thanh-Huy Nguyen",
        "Gia-Van To",
        "Tien-Huy Nguyen",
        "Quan Nguyen"
      ],
      "abstract": "Semi-Supervised Semantic Segmentation (SSSS) aims to improve segmentation\naccuracy by leveraging a small set of labeled images alongside a larger pool of\nunlabeled data. Recent advances primarily focus on pseudo-labeling, consistency\nregularization, and co-training strategies. However, existing methods struggle\nto balance global semantic representation with fine-grained local feature\nextraction. To address this challenge, we propose a novel tri-branch\nsemi-supervised segmentation framework incorporating a dual-teacher strategy,\nnamed IGL-DT. Our approach employs SwinUnet for high-level semantic guidance\nthrough Global Context Learning and ResUnet for detailed feature refinement via\nLocal Regional Learning. Additionally, a Discrepancy Learning mechanism\nmitigates over-reliance on a single teacher, promoting adaptive feature\nlearning. Extensive experiments on benchmark datasets demonstrate that our\nmethod outperforms state-of-the-art approaches, achieving superior segmentation\nperformance across various data regimes.",
      "tldr_zh": "本研究针对半监督语义分割 (Semi-Supervised Semantic Segmentation, SSSS) 中全局语义表示与局部特征提取的平衡难题，提出了一种新型三分支框架 IGL-DT，该框架采用双教师策略 (Dual-Teacher Strategy)，利用 SwinUnet 进行全局上下文学习 (Global Context Learning) 和 ResUnet 进行局部区域学习 (Local Regional Learning)。此外，引入 Discrepancy Learning 机制来减少对单一教师的过度依赖，促进自适应特征学习。实验结果显示，IGL-DT 在基准数据集上超越了现有最先进方法，在各种数据条件下实现了更高的分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09797v1",
      "published_date": "2025-04-14 01:51:29 UTC",
      "updated_date": "2025-04-14 01:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:01:49.084349"
    },
    {
      "arxiv_id": "2504.09795v1",
      "title": "VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents",
      "title_zh": "VDocRAG：针对视觉丰富文档的检索增强生成",
      "authors": [
        "Ryota Tanaka",
        "Taichi Iki",
        "Taku Hasegawa",
        "Kyosuke Nishida",
        "Kuniko Saito",
        "Jun Suzuki"
      ],
      "abstract": "We aim to develop a retrieval-augmented generation (RAG) framework that\nanswers questions over a corpus of visually-rich documents presented in mixed\nmodalities (e.g., charts, tables) and diverse formats (e.g., PDF, PPTX). In\nthis paper, we introduce a new RAG framework, VDocRAG, which can directly\nunderstand varied documents and modalities in a unified image format to prevent\nmissing information that occurs by parsing documents to obtain text. To improve\nthe performance, we propose novel self-supervised pre-training tasks that adapt\nlarge vision-language models for retrieval by compressing visual information\ninto dense token representations while aligning them with textual content in\ndocuments. Furthermore, we introduce OpenDocVQA, the first unified collection\nof open-domain document visual question answering datasets, encompassing\ndiverse document types and formats. OpenDocVQA provides a comprehensive\nresource for training and evaluating retrieval and question answering models on\nvisually-rich documents in an open-domain setting. Experiments show that\nVDocRAG substantially outperforms conventional text-based RAG and has strong\ngeneralization capability, highlighting the potential of an effective RAG\nparadigm for real-world documents.",
      "tldr_zh": "本文提出 VDocRAG，一种检索增强生成 (RAG) 框架，用于处理视觉丰富的文档（如图表和表格），这些文档以混合模式和多样格式（如 PDF、PPTX）呈现，通过统一图像格式直接理解内容以避免解析文本时丢失信息。  \n为提升性能，该框架引入新型自监督预训练任务，适应大型视觉语言模型 (large vision-language models)，通过压缩视觉信息并与文本内容对齐来优化检索效果。  \n作者同时发布 OpenDocVQA，这是首个统一的开放域文档视觉问答数据集集合，涵盖多种文档类型和格式，用于训练和评估模型。  \n实验显示，VDocRAG 显著优于传统文本-based RAG 框架，并表现出强大的泛化能力，展示了其在真实世界文档处理中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by CVPR 2025; project page: https://vdocrag.github.io",
      "pdf_url": "http://arxiv.org/pdf/2504.09795v1",
      "published_date": "2025-04-14 01:50:33 UTC",
      "updated_date": "2025-04-14 01:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:02:02.514977"
    },
    {
      "arxiv_id": "2504.13926v2",
      "title": "A Multi-Layered Research Framework for Human-Centered AI: Defining the Path to Explainability and Trust",
      "title_zh": "翻译失败",
      "authors": [
        "Chameera De Silva",
        "Thilina Halloluwa",
        "Dhaval Vyas"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) into high-stakes domains such\nas healthcare, finance, and autonomous systems is often constrained by concerns\nover transparency, interpretability, and trust. While Human-Centered AI (HCAI)\nemphasizes alignment with human values, Explainable AI (XAI) enhances\ntransparency by making AI decisions more understandable. However, the lack of a\nunified approach limits AI's effectiveness in critical decision-making\nscenarios. This paper presents a novel three-layered framework that bridges\nHCAI and XAI to establish a structured explainability paradigm. The framework\ncomprises (1) a foundational AI model with built-in explainability mechanisms,\n(2) a human-centered explanation layer that tailors explanations based on\ncognitive load and user expertise, and (3) a dynamic feedback loop that refines\nexplanations through real-time user interaction. The framework is evaluated\nacross healthcare, finance, and software development, demonstrating its\npotential to enhance decision-making, regulatory compliance, and public trust.\nOur findings advance Human-Centered Explainable AI (HCXAI), fostering AI\nsystems that are transparent, adaptable, and ethically aligned.",
      "tldr_zh": "本论文提出一个多层研究框架，用于人类中心AI（Human-Centered AI, HCAI），旨在解决AI在医疗、金融和自动系统等高风险领域中的透明度、可解释性和信任问题。该框架包括三个层级：（1）基础AI模型层，内置可解释机制（Explainable AI, XAI）；（2）人类中心解释层，根据用户认知负荷和专业知识定制解释；以及（3）动态反馈循环，通过实时互动优化解释。框架在多个领域进行评估，证明其能提升决策质量、合规性和公众信任，并推进人类中心可解释AI（Human-Centered Explainable AI, HCXAI）的开发，使AI系统更透明、可适应和伦理对齐。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "I am requesting this withdrawal because I believe the current version\n  requires significant revisions and restructuring to better reflect the\n  intended research contributions. I plan to substantially improve the work and\n  may resubmit a revised version in the future. Thank you for your\n  understanding and support",
      "pdf_url": "http://arxiv.org/pdf/2504.13926v2",
      "published_date": "2025-04-14 01:29:30 UTC",
      "updated_date": "2025-04-26 01:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:02:14.812981"
    },
    {
      "arxiv_id": "2504.09789v1",
      "title": "EquiVDM: Equivariant Video Diffusion Models with Temporally Consistent Noise",
      "title_zh": "EquiVDM：带有时间一致性噪声的等变视频扩散模型",
      "authors": [
        "Chao Liu",
        "Arash Vahdat"
      ],
      "abstract": "Temporally consistent video-to-video generation is essential for applications\nof video diffusion models in areas such as sim-to-real, style-transfer, video\nupsampling, etc. In this paper, we propose a video diffusion framework that\nleverages temporally consistent noise to generate coherent video frames without\nspecialized modules or additional constraints. We show that the standard\ntraining objective of diffusion models, when applied with temporally consistent\nnoise, encourages the model to be equivariant to spatial transformations in\ninput video and noise. This enables our model to better follow motion patterns\nfrom the input video, producing aligned motion and high-fidelity frames.\nFurthermore, we extend our approach to 3D-consistent video generation by\nattaching noise as textures on 3D meshes, ensuring 3D consistency in\nsim-to-real applications. Experimental results demonstrate that our method\nsurpasses state-of-the-art baselines in motion alignment, 3D consistency, and\nvideo quality while requiring only a few sampling steps in practice.",
      "tldr_zh": "本研究提出EquiVDM框架，一种利用时间一致噪声的视频扩散模型，用于实现视频生成中的时间一致性，而无需特殊模块或额外约束。该框架通过标准训练目标鼓励模型对输入视频和噪声的空间变换具有equivariant特性，从而更好地跟随输入视频的运动模式，并生成高质量的帧。进一步扩展到3D一致视频生成，将噪声作为纹理附加到3D网格上，确保sim-to-real应用的3D一致性。实验结果显示，EquiVDM在运动对齐、3D一致性和视频质量上优于现有基线，且仅需少量采样步骤。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09789v1",
      "published_date": "2025-04-14 01:26:29 UTC",
      "updated_date": "2025-04-14 01:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:02:24.469567"
    },
    {
      "arxiv_id": "2504.09781v1",
      "title": "Reasoning Court: Combining Reasoning, Action, and Judgment for Multi-Hop Reasoning",
      "title_zh": "Reasoning Court：结合推理、行动和判断用于多跳推理",
      "authors": [
        "Jingtian Wu",
        "Claire Cardie"
      ],
      "abstract": "While large language models (LLMs) have demonstrated strong capabilities in\ntasks like question answering and fact verification, they continue to suffer\nfrom hallucinations and reasoning errors, especially in multi-hop tasks that\nrequire integration of multiple information sources. Current methods address\nthese issues through retrieval-based techniques (grounding reasoning in\nexternal evidence), reasoning-based approaches (enhancing coherence via\nimproved prompting), or hybrid strategies combining both elements. One\nprominent hybrid method, ReAct, has outperformed purely retrieval-based or\nreasoning-based approaches; however, it lacks internal verification of\nintermediate reasoning steps, allowing potential errors to propagate through\ncomplex reasoning tasks. In this paper, we introduce Reasoning Court (RC), a\nnovel framework that extends iterative reasoning-and-retrieval methods, such as\nReAct, with a dedicated LLM judge. Unlike ReAct, RC employs this judge to\nindependently evaluate multiple candidate answers and their associated\nreasoning generated by separate LLM agents. The judge is asked to select the\nanswer that it considers the most factually grounded and logically coherent\nbased on the presented reasoning and evidence, or synthesizes a new answer\nusing available evidence and its pre-trained knowledge if all candidates are\ninadequate, flawed, or invalid. Evaluations on multi-hop benchmarks (HotpotQA,\nMuSiQue) and fact-verification (FEVER) demonstrate that RC consistently\noutperforms state-of-the-art few-shot prompting methods without task-specific\nfine-tuning.",
      "tldr_zh": "这篇论文提出了 Reasoning Court (RC) 框架，用于提升大型语言模型 (LLMs) 在多跳推理任务中的性能，通过结合推理、行动和判断来解决现有方法的幻觉和错误传播问题。RC 扩展了 ReAct 策略，引入一个专用的 LLM judge 来独立评估多个候选答案及其推理过程，选择最可靠的选项，或在所有候选不足时合成新答案。实验结果显示，在 HotpotQA、MuSiQue 和 FEVER 等基准上，RC 显著超过了现有 few-shot prompting 方法，而无需任务特定的 fine-tuning。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09781v1",
      "published_date": "2025-04-14 00:56:08 UTC",
      "updated_date": "2025-04-14 00:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:02:36.887147"
    },
    {
      "arxiv_id": "2504.09779v1",
      "title": "\"All Roads Lead to ChatGPT\": How Generative AI is Eroding Social Interactions and Student Learning Communities",
      "title_zh": "翻译失败",
      "authors": [
        "Irene Hou",
        "Owen Man",
        "Kate Hamilton",
        "Srishty Muthusekaran",
        "Jeffin Johnykutty",
        "Leili Zadeh",
        "Stephen MacNeil"
      ],
      "abstract": "The widespread adoption of generative AI is already impacting learning and\nhelp-seeking. While the benefits of generative AI are well-understood, recent\nstudies have also raised concerns about increased potential for cheating and\nnegative impacts on students' metacognition and critical thinking. However, the\npotential impacts on social interactions, peer learning, and classroom dynamics\nare not yet well understood. To investigate these aspects, we conducted 17\nsemi-structured interviews with undergraduate computing students across seven\nR1 universities in North America. Our findings suggest that help-seeking\nrequests are now often mediated by generative AI. For example, students often\nredirected questions from their peers to generative AI instead of providing\nassistance themselves, undermining peer interaction. Students also reported\nfeeling increasingly isolated and demotivated as the social support systems\nthey rely on begin to break down. These findings are concerning given the\nimportant role that social interactions play in students' learning and sense of\nbelonging.",
      "tldr_zh": "该研究探讨了生成式 AI（如 ChatGPT）的广泛采用如何侵蚀社会互动和学生学习社区，通过对北美七所 R1 universities 的 17 名本科计算学生进行半结构化 interviews，揭示学生们越来越多地转向 Generative AI 求助，而非同伴互动，导致 peer learning 减少。结果显示，这种行为削弱了社会支持系统，使学生感到孤立和动力不足，进而影响他们的 metacognition、critical thinking 和整体学习体验。该发现强调了在利用 AI 益处的同时，需要关注其对课堂 dynamics 的潜在负面影响，以维护学生的归属感。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages, 1 table. To be published in the Proceedings of the 2025\n  Innovation and Technology in Computer Science Education (ITiCSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.09779v1",
      "published_date": "2025-04-14 00:40:58 UTC",
      "updated_date": "2025-04-14 00:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:02:49.561086"
    },
    {
      "arxiv_id": "2504.09777v1",
      "title": "Reasoning without Regret",
      "title_zh": "翻译失败",
      "authors": [
        "Tarun Chitra"
      ],
      "abstract": "Chain-of-thought reasoning enables large language models to solve multi-step\ntasks by framing problem solving as sequential decision problems. Outcome-based\nrewards, which provide feedback only on final answers, show impressive success,\nbut face challenges with credit assignment and slow convergence. In contrast,\nprocedure-based rewards offer efficient step-level feedback, but typically\nrequire costly human supervision. We introduce \\emph{Backwards Adaptive Reward\nShaping} (BARS), a no-regret framework that converts sparse outcomes-based\nrewards into effective procedure-based signals. BARS uses sparse rewards\ngenerated from terminal-state priors and cover trees to scale rewards while\npreventing exploitation. With Bellman contraction and $(\\Delta, \\epsilon)$-gap\nrewards, our backward Euler solver achieves $\\epsilon$-accuracy in\n$O\\left((R_{\\max}/\\Delta)\\log(1/\\epsilon)\\right)$ iterations with $O(\\log T)$\ndynamic regret over $T$ rounds. Our analysis, based on generic chaining,\ncontinuous scaling limits, and non-linear Feynman-Kac bounds, connects recent\noutcome-based methods' empirical successes with the benefits of intermediate\nsupervision. Combined, this provides the first rigorous no-regret algorithm for\noutcome reward shaping, providing a theoretical foundation for the empirical\nsuccess of DeepSeek's R1.",
      "tldr_zh": "这篇论文探讨了 Chain-of-Thought 推理如何将问题解决视为顺序决策问题，以帮助大型语言模型处理多步任务，但基于结果的奖励（outcome-based rewards）面临信用分配和收敛缓慢的挑战，而基于过程的奖励（procedure-based rewards）则需昂贵的人工监督。作者引入了 Backwards Adaptive Reward Shaping (BARS)，一个无后悔框架，通过利用稀疏奖励、终端状态先验和 cover trees，将稀疏结果奖励转换为有效的过程级反馈，同时防止利用。实验和理论分析显示，BARS 结合 Bellman contraction 和 (Δ, ε)-gap 奖励，能在 O((R_max/Δ)log(1/ε)) 迭代内达到 ε-准确性，并提供首个严格的无后悔算法，为 DeepSeek's R1 等方法的经验成功奠定理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09777v1",
      "published_date": "2025-04-14 00:34:20 UTC",
      "updated_date": "2025-04-14 00:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:03:02.558822"
    },
    {
      "arxiv_id": "2504.09775v3",
      "title": "Understanding and Optimizing Multi-Stage AI Inference Pipelines",
      "title_zh": "理解与优化多阶段 AI 推理管道",
      "authors": [
        "Abhimanyu Rajeshkumar Bambhaniya",
        "Hanjiang Wu",
        "Suvinay Subramanian",
        "Sudarshan Srinivasan",
        "Souvik Kundu",
        "Amir Yazdanbakhsh",
        "Midhilesh Elavazhagan",
        "Madhu Kumar",
        "Tushar Krishna"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) has driven the need for\nincreasingly sophisticated inference pipelines and hardware platforms. Modern\nLLM serving extends beyond traditional prefill-decode workflows, incorporating\nmulti-stage processes such as Retrieval Augmented Generation (RAG), key-value\n(KV) cache retrieval, dynamic model routing, and multi step reasoning. These\nstages exhibit diverse computational demands, requiring distributed systems\nthat integrate GPUs, ASICs, CPUs, and memory-centric architectures. However,\nexisting simulators lack the fidelity to model these heterogeneous,\nmulti-engine workflows, limiting their ability to inform architectural\ndecisions.\n  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM\ninference Execution Simulator. HERMES models diverse request stages; including\nRAG, KV retrieval, reasoning, prefill, and decode across complex hardware\nhierarchies. HERMES supports heterogeneous clients executing multiple models\nconcurrently unlike prior frameworks while incorporating advanced batching\nstrategies and multi-level memory hierarchies. By integrating real hardware\ntraces with analytical modeling, HERMES captures critical trade-offs such as\nmemory bandwidth contention, inter-cluster communication latency, and batching\nefficiency in hybrid CPU-accelerator deployments. Through case studies, we\nexplore the impact of reasoning stages on end-to-end latency, optimal batching\nstrategies for hybrid pipelines, and the architectural implications of remote\nKV cache retrieval. HERMES empowers system designers to navigate the evolving\nlandscape of LLM inference, providing actionable insights into optimizing\nhardware-software co-design for next-generation AI workloads.",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs)的多阶段推理管道优化问题，包括Retrieval Augmented Generation (RAG)、KV缓存检索、动态模型路由和多步推理，这些阶段需要整合GPU、ASICs、CPU和内存架构的异构系统。作者引入了HERMES模拟器，该框架能精确模拟各种推理阶段，支持异构客户端的并发模型执行、先进批处理策略和多级内存层次，并通过真实硬件追踪和分析建模捕捉内存带宽争用等关键权衡。案例研究显示，HERMES有助于降低端到端延迟、优化混合管道批处理策略，并为硬件-软件协同设计提供指导，以提升下一代AI工作负载的性能。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "Inference System Design for Multi-Stage AI Inference Pipelines. 13\n  Pages, 15 Figues, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2504.09775v3",
      "published_date": "2025-04-14 00:29:49 UTC",
      "updated_date": "2025-04-20 19:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:03:13.930991"
    },
    {
      "arxiv_id": "2504.09772v1",
      "title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning",
      "title_zh": "两个脑袋胜过一个：多智能体协作推理的测试时缩放",
      "authors": [
        "Can Jin",
        "Hongwu Peng",
        "Qixin Zhang",
        "Yujin Tang",
        "Dimitris N. Metaxas",
        "Tong Che"
      ],
      "abstract": "Multi-agent systems (MAS) built on large language models (LLMs) offer a\npromising path toward solving complex, real-world tasks that single-agent\nsystems often struggle to manage. While recent advancements in test-time\nscaling (TTS) have significantly improved single-agent performance on\nchallenging reasoning tasks, how to effectively scale collaboration and\nreasoning in MAS remains an open question. In this work, we introduce an\nadaptive multi-agent framework designed to enhance collaborative reasoning\nthrough both model-level training and system-level coordination. We construct\nM500, a high-quality dataset containing 500 multi-agent collaborative reasoning\ntraces, and fine-tune Qwen2.5-32B-Instruct on this dataset to produce M1-32B, a\nmodel optimized for multi-agent collaboration. To further enable adaptive\nreasoning, we propose a novel CEO agent that dynamically manages the discussion\nprocess, guiding agent collaboration and adjusting reasoning depth for more\neffective problem-solving. Evaluated in an open-source MAS across a range of\ntasks-including general understanding, mathematical reasoning, and coding-our\nsystem significantly outperforms strong baselines. For instance, M1-32B\nachieves 12% improvement on GPQA-Diamond, 41% on AIME2024, and 10% on\nMBPP-Sanitized, matching the performance of state-of-the-art models like\nDeepSeek-R1 on some tasks. These results highlight the importance of both\nlearned collaboration and adaptive coordination in scaling multi-agent\nreasoning. Code is available at https://github.com/jincan333/MAS-TTS",
      "tldr_zh": "该研究探讨了如何通过测试时缩放（TTS）提升多智能体系统（MAS）中的协作推理，针对单智能体系统在复杂任务上的局限性。研究提出一个自适应多智能体框架，结合模型级训练（如使用新构建的 M500 数据集微调 Qwen2.5-32B-Instruct 模型得到 M1-32B）和系统级协调（如引入 CEO agent 动态管理讨论和推理深度）。实验结果显示，该框架在多种任务上显著优于基线，例如在 GPQA-Diamond 上提升 12%、AIME2024 上提升 41%、MBPP-Sanitized 上提升 10%，并在某些任务上匹配 DeepSeek-R1 的性能，突显了学习协作和自适应协调的重要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09772v1",
      "published_date": "2025-04-14 00:27:45 UTC",
      "updated_date": "2025-04-14 00:27:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:03:26.141048"
    },
    {
      "arxiv_id": "2504.09763v1",
      "title": "Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Zaid Khan",
        "Elias Stengel-Eskin",
        "Archiki Prasad",
        "Jaemin Cho",
        "Mohit Bansal"
      ],
      "abstract": "Scientists often infer abstract procedures from specific instances of\nproblems and use the abstractions to generate new, related instances. For\nexample, programs encoding the formal rules and properties of a system have\nbeen useful in fields ranging from RL (procedural environments) to physics\n(simulation engines). These programs can be seen as functions which execute to\ndifferent outputs based on their parameterizations (e.g., gridworld\nconfiguration or initial physical conditions). We introduce the term EFA\n(Executable Functional Abstraction) to denote such programs for math problems.\nEFA-like constructs have been shown to be useful for math reasoning as problem\ngenerators for stress-testing models. However, prior work has been limited to\nabstractions for grade-school math (whose simple rules are easy to encode in\nprograms), while generating EFAs for advanced math has thus far required human\nengineering. We explore the automatic construction of EFAs for advanced math\nproblems. We operationalize the task of automatically constructing EFAs as a\nprogram synthesis task, and develop EFAGen, which conditions an LLM on a seed\nmath problem and its step-by-step solution to generate candidate EFA programs\nthat are faithful to the generalized problem and solution class underlying the\nseed problem. Furthermore, we formalize properties any valid EFA must possess\nin terms of executable unit tests, and show how the tests can be used as\nverifiable rewards to train LLMs to become better writers of EFAs. We\ndemonstrate that EFAs constructed by EFAGen behave rationally by remaining\nfaithful to seed problems, produce learnable problem variations, and that\nEFAGen can infer EFAs across multiple diverse sources of competition-level math\nproblems. Finally, we show downstream uses of model-written EFAs e.g. finding\nproblem variations that are harder or easier for a learner to solve, as well as\ndata generation.",
      "tldr_zh": "本研究引入了可执行功能抽象（EFA），旨在从特定数学问题实例中推断生成程序，以自动创建高级数学问题的抽象和变体。论文开发了EFAGen系统，该系统利用大型语言模型（LLM）基于种子问题及其解决方案生成候选EFA程序，并通过可执行单元测试作为可验证奖励来训练LLM，确保程序的准确性和泛化性。实验结果显示，EFAGen能为竞赛级数学问题生成忠实的EFA变体，支持下游应用，如创建难度不同的问题变体和数据生成，从而提升数学推理和模型训练的效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project Page: https://zaidkhan.me/EFAGen/",
      "pdf_url": "http://arxiv.org/pdf/2504.09763v1",
      "published_date": "2025-04-14 00:06:48 UTC",
      "updated_date": "2025-04-14 00:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:03:37.384181"
    },
    {
      "arxiv_id": "2504.09762v1",
      "title": "(How) Do reasoning models reason?",
      "title_zh": "翻译失败",
      "authors": [
        "Subbarao Kambhampati",
        "Kaya Stechly",
        "Karthik Valmeekam"
      ],
      "abstract": "We will provide a broad unifying perspective on the recent breed of Large\nReasoning Models (LRMs) such as OpenAI o1 and DeepSeek R1, including their\npromise, sources of power, misconceptions and limitations.",
      "tldr_zh": "这篇论文探讨了大型推理模型(LRMs)如OpenAI o1和DeepSeek R1的推理机制，提供了一个广泛的统一视角。论文分析了这些模型的潜力与承诺、力量来源、常见误解以及局限性。作为核心贡献，它旨在澄清LRMs的实际表现和挑战，为未来模型改进提供参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages (A version appears in The Annals of New York Academy of\n  Sciences)",
      "pdf_url": "http://arxiv.org/pdf/2504.09762v1",
      "published_date": "2025-04-14 00:03:34 UTC",
      "updated_date": "2025-04-14 00:03:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:03:48.998833"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 137,
  "processed_papers_count": 137,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T13:04:07.691985"
}