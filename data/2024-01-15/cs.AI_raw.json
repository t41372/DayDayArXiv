[
  {
    "arxiv_id": "2401.08014v1",
    "title": "Convolutional Neural Network Compression via Dynamic Parameter Rank Pruning",
    "authors": [
      "Manish Sharma",
      "Jamison Heard",
      "Eli Saber",
      "Panos P. Markopoulos"
    ],
    "abstract": "While Convolutional Neural Networks (CNNs) excel at learning complex\nlatent-space representations, their over-parameterization can lead to\noverfitting and reduced performance, particularly with limited data. This,\nalongside their high computational and memory demands, limits the applicability\nof CNNs for edge deployment. Low-rank matrix approximation has emerged as a\npromising approach to reduce CNN parameters, but its application presents\nchallenges including rank selection and performance loss. To address these\nissues, we propose an efficient training method for CNN compression via dynamic\nparameter rank pruning. Our approach integrates efficient matrix factorization\nand novel regularization techniques, forming a robust framework for dynamic\nrank reduction and model compression. We use Singular Value Decomposition (SVD)\nto model low-rank convolutional filters and dense weight matrices and we\nachieve model compression by training the SVD factors with back-propagation in\nan end-to-end way. We evaluate our method on an array of modern CNNs, including\nResNet-18, ResNet-20, and ResNet-32, and datasets like CIFAR-10, CIFAR-100, and\nImageNet (2012), showcasing its applicability in computer vision. Our\nexperiments show that the proposed method can yield substantial storage savings\nwhile maintaining or even enhancing classification performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.08014v1",
    "published_date": "2024-01-15 23:52:35 UTC",
    "updated_date": "2024-01-15 23:52:35 UTC"
  },
  {
    "arxiv_id": "2401.08008v1",
    "title": "Analysing the Needs of Homeless People Using Feature Selection and Mining Association Rules",
    "authors": [
      "José M. Alcalde-Llergo",
      "Carlos García-Martínez",
      "Manuel Vaquero-Abellán",
      "Pilar Aparicio-Martínez",
      "Enrique Yeguas-Bolívar"
    ],
    "abstract": "Homelessness is a social and health problem with great repercussions in\nEurope. Many non-governmental organisations help homeless people by collecting\nand analysing large amounts of information about them. However, these tasks are\nnot always easy to perform, and hinder other of the organisations duties. The\nSINTECH project was created to tackle this issue proposing two different tools:\na mobile application to quickly and easily collect data; and a software based\non artificial intelligence which obtains interesting information from the\ncollected data. The first one has been distributed to some Spanish\norganisations which are using it to conduct surveys of homeless people. The\nsecond tool implements different feature selection and association rules mining\nmethods. These artificial intelligence techniques have allowed us to identify\nthe most relevant features and some interesting association rules from\npreviously collected homeless data.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 4 figures, 4 tables, MetroXRAINE 2022",
    "pdf_url": "http://arxiv.org/pdf/2401.08008v1",
    "published_date": "2024-01-15 23:28:55 UTC",
    "updated_date": "2024-01-15 23:28:55 UTC"
  },
  {
    "arxiv_id": "2401.08003v1",
    "title": "Jewelry Recognition via Encoder-Decoder Models",
    "authors": [
      "José M. Alcalde-Llergo",
      "Enrique Yeguas-Bolívar",
      "Andrea Zingoni",
      "Alejandro Fuerte-Jurado"
    ],
    "abstract": "Jewelry recognition is a complex task due to the different styles and designs\nof accessories. Precise descriptions of the various accessories is something\nthat today can only be achieved by experts in the field of jewelry. In this\nwork, we propose an approach for jewelry recognition using computer vision\ntechniques and image captioning, trying to simulate this expert human behavior\nof analyzing accessories. The proposed methodology consist on using different\nimage captioning models to detect the jewels from an image and generate a\nnatural language description of the accessory. Then, this description is also\nutilized to classify the accessories at different levels of detail. The\ngenerated caption includes details such as the type of jewel, color, material,\nand design. To demonstrate the effectiveness of the proposed method in\naccurately recognizing different types of jewels, a dataset consisting of\nimages of accessories belonging to jewelry stores in C\\'ordoba (Spain) has been\ncreated. After testing the different image captioning architectures designed,\nthe final model achieves a captioning accuracy of 95\\%. The proposed\nmethodology has the potential to be used in various applications such as\njewelry e-commerce, inventory management or automatic jewels recognition to\nanalyze people's tastes and social status.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 5 figures, MetroXRAINE 2023 Conference",
    "pdf_url": "http://arxiv.org/pdf/2401.08003v1",
    "published_date": "2024-01-15 23:10:50 UTC",
    "updated_date": "2024-01-15 23:10:50 UTC"
  },
  {
    "arxiv_id": "2401.07993v2",
    "title": "Carrying over algorithm in transformers",
    "authors": [
      "Jorrit Kruthoff"
    ],
    "abstract": "Addition is perhaps one of the simplest arithmetic tasks one can think of and\nis usually performed using the carrying over algorithm. This algorithm consists\nof two tasks: adding digits in the same position and carrying over a one\nwhenever necessary. We study how transformer models implement this algorithm\nand how the two aforementioned tasks are allocated to different parts of the\nnetwork. We first focus on two-layer encoder-only models and show that the\ncarrying over algorithm is implemented in a modular fashion. The first layer is\nmostly responsible for adding digits in the same position. The second layer\nfirst decides, in the attention, which positions need a carried one or not, and\nthen performs the carrying of the one in the final MLP. We provide a simple way\nof precisely identifying which neurons are responsible for that task. This\nimplementation of the carrying over algorithm occurs across a range of\nhyperparameters for two as well as three-layer models. For small decoder-only\nmodels, we observe the same implementation and provide suggestive evidence for\nits existence in three 7B large language models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Comments welcome!",
    "pdf_url": "http://arxiv.org/pdf/2401.07993v2",
    "published_date": "2024-01-15 22:36:11 UTC",
    "updated_date": "2024-01-17 16:02:27 UTC"
  },
  {
    "arxiv_id": "2401.07969v1",
    "title": "Simulated Autopoiesis in Liquid Automata",
    "authors": [
      "Steve Battle"
    ],
    "abstract": "We present a novel form of Liquid Automata, using this to simulate\nautopoiesis, whereby living machines self-organise in the physical realm. This\nsimulation is based on an earlier Cellular Automaton described by Francisco\nVarela. The basis of Liquid Automata is a particle simulation with additional\nrules about how particles are transformed on collision with other particles.\nUnlike cellular automata, there is no fixed grid or time-step, only particles\nmoving about and colliding with each other in a continuous space/time.",
    "categories": [
      "nlin.CG",
      "cs.AI"
    ],
    "primary_category": "nlin.CG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.07969v1",
    "published_date": "2024-01-15 21:23:23 UTC",
    "updated_date": "2024-01-15 21:23:23 UTC"
  },
  {
    "arxiv_id": "2401.07964v3",
    "title": "AI-as-exploration: Navigating intelligence space",
    "authors": [
      "Dimitri Coelho Mollo"
    ],
    "abstract": "Artificial Intelligence is a field that lives many lives, and the term has\ncome to encompass a motley collection of scientific and commercial endeavours.\nIn this paper, I articulate the contours of a rather neglected but central\nscientific role that AI has to play, which I dub `AI-as-exploration'.The basic\nthrust of AI-as-exploration is that of creating and studying systems that can\nreveal candidate building blocks of intelligence that may differ from the forms\nof human and animal intelligence we are familiar with. In other words, I\nsuggest that AI is one of the best tools we have for exploring intelligence\nspace, namely the space of possible intelligent systems. I illustrate the value\nof AI-as-exploration by focusing on a specific case study, i.e., recent work on\nthe capacity to combine novel and invented concepts in humans and Large\nLanguage Models. I show that the latter, despite showing human-level accuracy\nin such a task, probably solve it in ways radically different, but no less\nrelevant to intelligence research, to those hypothesised for humans.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07964v3",
    "published_date": "2024-01-15 21:06:20 UTC",
    "updated_date": "2024-08-16 17:01:06 UTC"
  },
  {
    "arxiv_id": "2401.07955v2",
    "title": "A Study on Large Language Models' Limitations in Multiple-Choice Question Answering",
    "authors": [
      "Aisha Khatun",
      "Daniel G. Brown"
    ],
    "abstract": "The widespread adoption of Large Language Models (LLMs) has become\ncommonplace, particularly with the emergence of open-source models. More\nimportantly, smaller models are well-suited for integration into consumer\ndevices and are frequently employed either as standalone solutions or as\nsubroutines in various AI tasks. Despite their ubiquitous use, there is no\nsystematic analysis of their specific capabilities and limitations. In this\nstudy, we tackle one of the most widely used tasks - answering Multiple Choice\nQuestion (MCQ). We analyze 26 small open-source models and find that 65% of the\nmodels do not understand the task, only 4 models properly select an answer from\nthe given choices, and only 5 of these models are choice order independent.\nThese results are rather alarming given the extensive use of MCQ tests with\nthese models. We recommend exercising caution and testing task understanding\nbefore using MCQ to evaluate LLMs in any field whatsoever.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07955v2",
    "published_date": "2024-01-15 20:42:16 UTC",
    "updated_date": "2024-08-15 02:18:08 UTC"
  },
  {
    "arxiv_id": "2401.08714v1",
    "title": "Training program on sign language: social inclusion through Virtual Reality in ISENSE project",
    "authors": [
      "Alessia Bisio",
      "Enrique Yeguas-Bolívar",
      "Pilar Aparicio-Martínez",
      "María Dolores Redel-Macías",
      "Sara Pinzi",
      "Stefano Rossi",
      "Juri Taborri"
    ],
    "abstract": "Structured hand gestures that incorporate visual motions and signs are used\nin sign language. Sign language is a valuable means of daily communication for\nindividuals who are deaf or have speech impairments, but it is still rare among\nhearing people, and fewer are capable of understand it. Within the academic\ncontext, parents and teachers play a crucial role in supporting deaf students\nfrom childhood by facilitating their learning of sign language. In the last\nyears, among all the teaching tools useful for learning sign language, the use\nof Virtual Reality (VR) has increased, as it has been demonstrated to improve\nretention, memory and attention during the learning process. The ISENSE project\nhas been created to assist students with deafness during their academic life by\nproposing different technological tools for teaching sign language to the\nhearing community in the academic context. As part of the ISENSE project, this\nwork aims to develop an application for Spanish and Italian sign language\nrecognition that exploits the VR environment to quickly and easily create a\ncomprehensive database of signs and an Artificial Intelligence (AI)-based\nsoftware to accurately classify and recognize static and dynamic signs: from\nletters to sentences.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.HC",
    "comment": "6 pages, 4 figures, MetroXRAINE 2023 Conference, ISENSE european\n  project",
    "pdf_url": "http://arxiv.org/pdf/2401.08714v1",
    "published_date": "2024-01-15 20:40:46 UTC",
    "updated_date": "2024-01-15 20:40:46 UTC"
  },
  {
    "arxiv_id": "2402.01668v1",
    "title": "Determining the Difficulties of Students With Dyslexia via Virtual Reality and Artificial Intelligence: An Exploratory Analysis",
    "authors": [
      "Enrique Yeguas-Bolívar",
      "José M. Alcalde-Llergo",
      "Pilar Aparicio-Martínez",
      "Juri Taborri",
      "Andrea Zingoni",
      "Sara Pinzi"
    ],
    "abstract": "Learning disorders are neurological conditions that affect the brain's\nability to interconnect communication areas. Dyslexic students experience\nproblems with reading, memorizing, and exposing concepts; however the magnitude\nof these can be mitigated through both therapies and the creation of\ncompensatory mechanisms. Several efforts have been made to mitigate these\nissues, leading to the creation of digital resources for students with specific\nlearning disorders attending primary and secondary education levels.\nConversely, a standard approach is still missed in higher education. The\nVRAIlexia project has been created to tackle this issue by proposing two\ndifferent tools: a mobile application integrating virtual reality (VR) to\ncollect data quickly and easily, and an artificial intelligencebased software\n(AI) to analyze the collected data for customizing the supporting methodology\nfor each student. The first one has been created and is being distributed among\ndyslexic students in Higher Education Institutions, for the conduction of\nspecific psychological and psychometric tests. The second tool applies specific\nartificial intelligence algorithms to the data gathered via the application and\nother surveys. These AI techniques have allowed us to identify the most\nrelevant difficulties faced by the students' cohort. Our different models have\nobtained around 90\\% mean accuracy for predicting the support tools and\nlearning strategies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages, 5 figures, 3 tables, MetroXRAINE 2022 Conference, VRAILEXIA\n  european project",
    "pdf_url": "http://arxiv.org/pdf/2402.01668v1",
    "published_date": "2024-01-15 20:26:09 UTC",
    "updated_date": "2024-01-15 20:26:09 UTC"
  },
  {
    "arxiv_id": "2401.07931v2",
    "title": "Vertical Federated Image Segmentation",
    "authors": [
      "Paul K. Mandal",
      "Cole Leo"
    ],
    "abstract": "With the popularization of AI solutions for image based problems, there has\nbeen a growing concern for both data privacy and acquisition. In a large number\nof cases, information is located on separate data silos and it can be difficult\nfor a developer to consolidate all of it in a fashion that is appropriate for\nmachine learning model development. Alongside this, a portion of these\nlocalized data regions may not have access to a labelled ground truth. This\nindicates that they have the capacity to reach conclusions numerically, but are\nnot able to assign classifications amid a lack of pertinent information. Such a\ndetermination is often negligible, especially when attempting to develop image\nbased solutions that often necessitate this capability. With this being the\ncase, we propose an innovative vertical federated learning (VFL) model\narchitecture that can operate under this common set of conditions. This is the\nfirst (and currently the only) implementation of a system that can work under\nthe constraints of a VFL environment and perform image segmentation while\nmaintaining nominal accuracies. We achieved this by utilizing an FCN that\nboasts the ability to operate on federates that lack labelled data and\nprivately share the respective weights with a central server, that of which\nhosts the necessary features for classification. Tests were conducted on the\nCamVid dataset in order to determine the impact of heavy feature compression\nrequired for the transfer of information between federates, as well as to reach\nnominal conclusions about the overall performance metrics when working under\nsuch constraints.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "C.2.4; I.2.8; I.4; I.4.8"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.07931v2",
    "published_date": "2024-01-15 19:47:14 UTC",
    "updated_date": "2024-03-19 17:07:40 UTC"
  },
  {
    "arxiv_id": "2401.07927v4",
    "title": "Are self-explanations from Large Language Models faithful?",
    "authors": [
      "Andreas Madsen",
      "Sarath Chandar",
      "Siva Reddy"
    ],
    "abstract": "Instruction-tuned Large Language Models (LLMs) excel at many tasks and will\neven explain their reasoning, so-called self-explanations. However, convincing\nand wrong self-explanations can lead to unsupported confidence in LLMs, thus\nincreasing risk. Therefore, it's important to measure if self-explanations\ntruly reflect the model's behavior. Such a measure is called\ninterpretability-faithfulness and is challenging to perform since the ground\ntruth is inaccessible, and many LLMs only have an inference API. To address\nthis, we propose employing self-consistency checks to measure faithfulness. For\nexample, if an LLM says a set of words is important for making a prediction,\nthen it should not be able to make its prediction without these words. While\nself-consistency checks are a common approach to faithfulness, they have not\npreviously been successfully applied to LLM self-explanations for\ncounterfactual, feature attribution, and redaction explanations. Our results\ndemonstrate that faithfulness is explanation, model, and task-dependent,\nshowing self-explanations should not be trusted in general. For example, with\nsentiment classification, counterfactuals are more faithful for Llama2, feature\nattribution for Mistral, and redaction for Falcon 40B.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The 62nd Annual Meeting of the Association for Computational\n  Linguistics",
    "pdf_url": "http://arxiv.org/pdf/2401.07927v4",
    "published_date": "2024-01-15 19:39:15 UTC",
    "updated_date": "2024-05-16 20:26:43 UTC"
  },
  {
    "arxiv_id": "2401.07890v2",
    "title": "A Strategy for Implementing description Temporal Dynamic Algorithms in Dynamic Knowledge Graphs by SPIN",
    "authors": [
      "Alireza Shahbazi",
      "Seyyed Ahmad Mirsanei",
      "Malikeh Haj Khan Mirzaye Sarraf",
      "Behrouz Minaei Bidgoli"
    ],
    "abstract": "Planning and reasoning about actions and processes, in addition to reasoning\nabout propositions, are important issues in recent logical and computer science\nstudies. The widespread use of actions in everyday life such as IoT, semantic\nweb services, etc., and the limitations and issues in the action formalisms are\ntwo factors that lead us to study how actions are represented.\n  Since 2007, there have been some ideas to integrate Description Logic (DL)\nand action formalisms for representing both static and dynamic knowledge.\nMeanwhile, time is an important factor in dynamic situations, and actions\nchange states over time. In this study, on the one hand, we examined related\nlogical structures such as extensions of description logics (DLs), temporal\nformalisms, and action formalisms. On the other hand, we analyzed possible\ntools for designing and developing the Knowledge and Action Base (KAB).\n  For representation and reasoning about actions, we embedded actions into DLs\n(such as Dynamic-ALC and its extensions). We propose a terminable algorithm for\naction projection, planning, checking the satisfiability, consistency,\nrealizability, and executability, and also querying from KAB. Actions in this\nframework were modeled with SPIN and added to state space. This framework has\nalso been implemented as a plugin for the Prot\\'eg\\'e ontology editor.\n  During the last two decades, various algorithms have been presented, but due\nto the high computational complexity, we face many problems in implementing\ndynamic ontologies. In addition, an algorithm to detect the inconsistency of\nactions' effects was not explicitly stated. In the proposed strategy, the\ninteractions of actions with other parts of modeled knowledge, and a method to\ncheck consistency between the effects of actions are presented. With this\nframework, the ramification problem can be well handled in future works.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07890v2",
    "published_date": "2024-01-15 18:43:48 UTC",
    "updated_date": "2024-01-20 14:18:49 UTC"
  },
  {
    "arxiv_id": "2401.07889v1",
    "title": "Machine Learning Techniques to Identify Hand Gestures amidst Forearm Muscle Signals",
    "authors": [
      "Ryan Cho",
      "Sunil Patel",
      "Kyu Taek Cho",
      "Jaejin Hwang"
    ],
    "abstract": "This study investigated the use of forearm EMG data for distinguishing eight\nhand gestures, employing the Neural Network and Random Forest algorithms on\ndata from ten participants. The Neural Network achieved 97 percent accuracy\nwith 1000-millisecond windows, while the Random Forest achieved 85 percent\naccuracy with 200-millisecond windows. Larger window sizes improved gesture\nclassification due to increased temporal resolution. The Random Forest\nexhibited faster processing at 92 milliseconds, compared to the Neural\nNetwork's 124 milliseconds. In conclusion, the study identified a Neural\nNetwork with a 1000-millisecond stream as the most accurate (97 percent), and a\nRandom Forest with a 200-millisecond stream as the most efficient (85 percent).\nFuture research should focus on increasing sample size, incorporating more hand\ngestures, and exploring different feature extraction methods and modeling\nalgorithms to enhance system accuracy and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.07889v1",
    "published_date": "2024-01-15 18:39:13 UTC",
    "updated_date": "2024-01-15 18:39:13 UTC"
  },
  {
    "arxiv_id": "2401.07886v2",
    "title": "Learned Best-Effort LLM Serving",
    "authors": [
      "Siddharth Jha",
      "Coleman Hooper",
      "Xiaoxuan Liu",
      "Sehoon Kim",
      "Kurt Keutzer"
    ],
    "abstract": "Many applications must provide low-latency LLM service to users or risk\nunacceptable user experience. However, over-provisioning resources to serve\nfluctuating request patterns is often prohibitively expensive. In this work, we\npresent a best-effort serving system that employs deep reinforcement learning\nto adjust service quality based on the task distribution and system load. Our\nbest-effort system can maintain availability with over 10x higher client\nrequest rates, serves above 96% of peak performance 4.1x more often, and serves\nabove 98% of peak performance 2.3x more often than static serving on\nunpredictable workloads. Our learned router is robust to shifts in both the\narrival and task distribution. Compared to static serving, learned best-effort\nserving allows for cost-efficient serving through increased hardware utility.\nAdditionally, we argue that learned best-effort LLM serving is applicable in\nwide variety of settings and provides application developers great flexibility\nto meet their specific needs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Es-FoMo @ ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.07886v2",
    "published_date": "2024-01-15 18:28:17 UTC",
    "updated_date": "2024-07-15 03:54:20 UTC"
  },
  {
    "arxiv_id": "2401.07883v1",
    "title": "The Chronicles of RAG: The Retriever, the Chunk and the Generator",
    "authors": [
      "Paulo Finardi",
      "Leonardo Avila",
      "Rodrigo Castaldoni",
      "Pedro Gengo",
      "Celio Larcher",
      "Marcos Piau",
      "Pablo Costa",
      "Vinicius Caridá"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has become one of the most popular\nparadigms for enabling LLMs to access external data, and also as a mechanism\nfor grounding to mitigate against hallucinations. When implementing RAG you can\nface several challenges like effective integration of retrieval models,\nefficient representation learning, data diversity, computational efficiency\noptimization, evaluation, and quality of text generation. Given all these\nchallenges, every day a new technique to improve RAG appears, making it\nunfeasible to experiment with all combinations for your problem. In this\ncontext, this paper presents good practices to implement, optimize, and\nevaluate RAG for the Brazilian Portuguese language, focusing on the\nestablishment of a simple pipeline for inference and experiments. We explored a\ndiverse set of methods to answer questions about the first Harry Potter book.\nTo generate the answers we used the OpenAI's gpt-4, gpt-4-1106-preview,\ngpt-3.5-turbo-1106, and Google's Gemini Pro. Focusing on the quality of the\nretriever, our approach achieved an improvement of MRR@10 by 35.4% compared to\nthe baseline. When optimizing the input size in the application, we observed\nthat it is possible to further enhance it by 2.4%. Finally, we present the\ncomplete architecture of the RAG with our recommendations. As result, we moved\nfrom a baseline of 57.88% to a maximum relative score of 98.61%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 15 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.07883v1",
    "published_date": "2024-01-15 18:25:18 UTC",
    "updated_date": "2024-01-15 18:25:18 UTC"
  },
  {
    "arxiv_id": "2401.07877v1",
    "title": "EMBRE: Entity-aware Masking for Biomedical Relation Extraction",
    "authors": [
      "Mingjie Li",
      "Karin Verspoor"
    ],
    "abstract": "Information extraction techniques, including named entity recognition (NER)\nand relation extraction (RE), are crucial in many domains to support making\nsense of vast amounts of unstructured text data by identifying and connecting\nrelevant information. Such techniques can assist researchers in extracting\nvaluable insights. In this paper, we introduce the Entity-aware Masking for\nBiomedical Relation Extraction (EMBRE) method for biomedical relation\nextraction, as applied in the context of the BioRED challenge Task 1, in which\nhuman-annotated entities are provided as input. Specifically, we integrate\nentity knowledge into a deep neural network by pretraining the backbone model\nwith an entity masking objective. We randomly mask named entities for each\ninstance and let the model identify the masked entity along with its type. In\nthis way, the model is capable of learning more specific knowledge and more\nrobust representations. Then, we utilize the pre-trained model as our backbone\nto encode language representations and feed these representations into two\nmultilayer perceptron (MLPs) to predict the logits for relation and novelty,\nrespectively. The experimental results demonstrate that our proposed method can\nimprove the performances of entity pair, relation and novelty extraction over\nour baseline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2401.07877v1",
    "published_date": "2024-01-15 18:12:01 UTC",
    "updated_date": "2024-01-15 18:12:01 UTC"
  },
  {
    "arxiv_id": "2401.07871v1",
    "title": "Explainable Predictive Maintenance: A Survey of Current Methods, Challenges and Opportunities",
    "authors": [
      "Logan Cummins",
      "Alex Sommers",
      "Somayeh Bakhtiari Ramezani",
      "Sudip Mittal",
      "Joseph Jabour",
      "Maria Seale",
      "Shahram Rahimi"
    ],
    "abstract": "Predictive maintenance is a well studied collection of techniques that aims\nto prolong the life of a mechanical system by using artificial intelligence and\nmachine learning to predict the optimal time to perform maintenance. The\nmethods allow maintainers of systems and hardware to reduce financial and time\ncosts of upkeep. As these methods are adopted for more serious and potentially\nlife-threatening applications, the human operators need trust the predictive\nsystem. This attracts the field of Explainable AI (XAI) to introduce\nexplainability and interpretability into the predictive system. XAI brings\nmethods to the field of predictive maintenance that can amplify trust in the\nusers while maintaining well-performing systems. This survey on explainable\npredictive maintenance (XPM) discusses and presents the current methods of XAI\nas applied to predictive maintenance while following the Preferred Reporting\nItems for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines. We\ncategorize the different XPM methods into groups that follow the XAI\nliterature. Additionally, we include current challenges and a discussion on\nfuture research directions in XPM.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07871v1",
    "published_date": "2024-01-15 18:06:59 UTC",
    "updated_date": "2024-01-15 18:06:59 UTC"
  },
  {
    "arxiv_id": "2401.07870v2",
    "title": "JumpCoder: Go Beyond Autoregressive Coder via Online Modification",
    "authors": [
      "Mouxiang Chen",
      "Hao Tian",
      "Zhongxin Liu",
      "Xiaoxue Ren",
      "Jianling Sun"
    ],
    "abstract": "While existing code large language models (code LLMs) exhibit impressive\ncapabilities in code generation, their autoregressive sequential generation\ninherently lacks reversibility. This limitation hinders them from timely\ncorrecting previous missing statements during coding as humans do, often\nleading to error propagation and suboptimal performance. We introduce\nJumpCoder, a novel model-agnostic framework that enables human-like online\nmodification and non-sequential generation to augment code LLMs. The key idea\nbehind JumpCoder is to insert new code into the currently generated code when\nnecessary during generation, which is achieved through an auxiliary infilling\nmodel that works in tandem with the code LLM. Since identifying the best infill\nposition beforehand is intractable, we adopt an \\textit{infill-first,\njudge-later} strategy, which experiments with filling at the $k$ most critical\npositions following the generation of each line, and uses an Abstract Syntax\nTree (AST) parser alongside the Generation Model Scoring to effectively judge\nthe validity of each potential infill. Extensive experiments using six\nstate-of-the-art code LLMs across multiple and multilingual benchmarks\nconsistently indicate significant improvements over all baselines. Our code is\npublic at https://github.com/Keytoyze/JumpCoder.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (main)",
    "pdf_url": "http://arxiv.org/pdf/2401.07870v2",
    "published_date": "2024-01-15 18:04:29 UTC",
    "updated_date": "2024-06-05 14:12:03 UTC"
  },
  {
    "arxiv_id": "2401.07868v1",
    "title": "Consolidating Trees of Robotic Plans Generated Using Large Language Models to Improve Reliability",
    "authors": [
      "Md Sadman Sakib",
      "Yu Sun"
    ],
    "abstract": "The inherent probabilistic nature of Large Language Models (LLMs) introduces\nan element of unpredictability, raising concerns about potential discrepancies\nin their output. This paper introduces an innovative approach aims to generate\ncorrect and optimal robotic task plans for diverse real-world demands and\nscenarios. LLMs have been used to generate task plans, but they are unreliable\nand may contain wrong, questionable, or high-cost steps. The proposed approach\nuses LLM to generate a number of task plans as trees and amalgamates them into\na graph by removing questionable paths. Then an optimal task tree can be\nretrieved to circumvent questionable and high-cost nodes, thereby improving\nplanning accuracy and execution efficiency. The approach is further improved by\nincorporating a large knowledge network. Leveraging GPT-4 further, the\nhigh-level task plan is converted into a low-level Planning Domain Definition\nLanguage (PDDL) plan executable by a robot. Evaluation results highlight the\nsuperior accuracy and efficiency of our approach compared to previous\nmethodologies in the field of task planning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07868v1",
    "published_date": "2024-01-15 18:01:59 UTC",
    "updated_date": "2024-01-15 18:01:59 UTC"
  },
  {
    "arxiv_id": "2401.07862v1",
    "title": "Adaptive Neural-Operator Backstepping Control of a Benchmark Hyperbolic PDE",
    "authors": [
      "Maxence Lamarque",
      "Luke Bhan",
      "Yuanyuan Shi",
      "Miroslav Krstic"
    ],
    "abstract": "To stabilize PDEs, feedback controllers require gain kernel functions, which\nare themselves governed by PDEs. Furthermore, these gain-kernel PDEs depend on\nthe PDE plants' functional coefficients. The functional coefficients in PDE\nplants are often unknown. This requires an adaptive approach to PDE control,\ni.e., an estimation of the plant coefficients conducted concurrently with\ncontrol, where a separate PDE for the gain kernel must be solved at each\ntimestep upon the update in the plant coefficient function estimate. Solving a\nPDE at each timestep is computationally expensive and a barrier to the\nimplementation of real-time adaptive control of PDEs. Recently, results in\nneural operator (NO) approximations of functional mappings have been introduced\ninto PDE control, for replacing the computation of the gain kernel with a\nneural network that is trained, once offline, and reused in real-time for rapid\nsolution of the PDEs. In this paper, we present the first result on applying\nNOs in adaptive PDE control, presented for a benchmark 1-D hyperbolic PDE with\nrecirculation. We establish global stabilization via Lyapunov analysis, in the\nplant and parameter error states, and also present an alternative approach, via\npassive identifiers, which avoids the strong assumptions on kernel\ndifferentiability. We then present numerical simulations demonstrating\nstability and observe speedups up to three orders of magnitude, highlighting\nthe real-time efficacy of neural operators in adaptive control. Our code\n(Github) is made publicly available for future researchers.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "math.DS",
      "math.OC"
    ],
    "primary_category": "eess.SY",
    "comment": "16.5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.07862v1",
    "published_date": "2024-01-15 17:52:15 UTC",
    "updated_date": "2024-01-15 17:52:15 UTC"
  },
  {
    "arxiv_id": "2401.07844v6",
    "title": "The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise",
    "authors": [
      "Shuze Daniel Liu",
      "Shuhang Chen",
      "Shangtong Zhang"
    ],
    "abstract": "Stochastic approximation is a class of algorithms that update a vector\niteratively, incrementally, and stochastically, including, e.g., stochastic\ngradient descent and temporal difference learning. One fundamental challenge in\nanalyzing a stochastic approximation algorithm is to establish its stability,\ni.e., to show that the stochastic vector iterates are bounded almost surely. In\nthis paper, we extend the celebrated Borkar-Meyn theorem for stability from the\nMartingale difference noise setting to the Markovian noise setting, which\ngreatly improves its applicability in reinforcement learning, especially in\nthose off-policy reinforcement learning algorithms with linear function\napproximation and eligibility traces. Central to our analysis is the\ndiminishing asymptotic rate of change of a few functions, which is implied by\nboth a form of the strong law of large numbers and a form of the law of the\niterated logarithm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Journal of Machine Learning Research (JMLR), 2025",
    "pdf_url": "http://arxiv.org/pdf/2401.07844v6",
    "published_date": "2024-01-15 17:20:17 UTC",
    "updated_date": "2025-02-05 19:20:11 UTC"
  },
  {
    "arxiv_id": "2401.07836v3",
    "title": "Two Types of AI Existential Risk: Decisive and Accumulative",
    "authors": [
      "Atoosa Kasirzadeh"
    ],
    "abstract": "The conventional discourse on existential risks (x-risks) from AI typically\nfocuses on abrupt, dire events caused by advanced AI systems, particularly\nthose that might achieve or surpass human-level intelligence. These events have\nsevere consequences that either lead to human extinction or irreversibly\ncripple human civilization to a point beyond recovery. This discourse, however,\noften neglects the serious possibility of AI x-risks manifesting incrementally\nthrough a series of smaller yet interconnected disruptions, gradually crossing\ncritical thresholds over time. This paper contrasts the conventional \"decisive\nAI x-risk hypothesis\" with an \"accumulative AI x-risk hypothesis.\" While the\nformer envisions an overt AI takeover pathway, characterized by scenarios like\nuncontrollable superintelligence, the latter suggests a different causal\npathway to existential catastrophes. This involves a gradual accumulation of\ncritical AI-induced threats such as severe vulnerabilities and systemic erosion\nof economic and political structures. The accumulative hypothesis suggests a\nboiling frog scenario where incremental AI risks slowly converge, undermining\nsocietal resilience until a triggering event results in irreversible collapse.\nThrough systems analysis, this paper examines the distinct assumptions\ndifferentiating these two hypotheses. It is then argued that the accumulative\nview can reconcile seemingly incompatible perspectives on AI risks. The\nimplications of differentiating between these causal pathways -- the decisive\nand the accumulative -- for the governance of AI as well as long-term AI safety\nare discussed.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Journal article for Philosophical Studies",
    "pdf_url": "http://arxiv.org/pdf/2401.07836v3",
    "published_date": "2024-01-15 17:06:02 UTC",
    "updated_date": "2025-01-17 16:35:27 UTC"
  },
  {
    "arxiv_id": "2401.07810v1",
    "title": "Consolidating Strategies for Countering Hate Speech Using Persuasive Dialogues",
    "authors": [
      "Sougata Saha",
      "Rohini Srihari"
    ],
    "abstract": "Hateful comments are prevalent on social media platforms. Although tools for\nautomatically detecting, flagging, and blocking such false, offensive, and\nharmful content online have lately matured, such reactive and brute force\nmethods alone provide short-term and superficial remedies while the\nperpetrators persist. With the public availability of large language models\nwhich can generate articulate synthetic and engaging content at scale, there\nare concerns about the rapid growth of dissemination of such malicious content\non the web. There is now a need to focus on deeper, long-term solutions that\ninvolve engaging with the human perpetrator behind the source of the content to\nchange their viewpoint or at least bring down the rhetoric using persuasive\nmeans. To do that, we propose defining and experimenting with controllable\nstrategies for generating counter-arguments to hateful comments in online\nconversations. We experiment with controlling response generation using\nfeatures based on (i) argument structure and reasoning-based Walton argument\nschemes, (ii) counter-argument speech acts, and (iii) human\ncharacteristics-based qualities such as Big-5 personality traits and human\nvalues. Using automatic and human evaluations, we determine the best\ncombination of features that generate fluent, argumentative, and logically\nsound arguments for countering hate. We further share the developed\ncomputational models for automatically annotating text with such features, and\na silver-standard annotated version of an existing hate speech dialog corpora.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07810v1",
    "published_date": "2024-01-15 16:31:18 UTC",
    "updated_date": "2024-01-15 16:31:18 UTC"
  },
  {
    "arxiv_id": "2401.07796v2",
    "title": "Fusing Echocardiography Images and Medical Records for Continuous Patient Stratification",
    "authors": [
      "Nathan Painchaud",
      "Jérémie Stym-Popper",
      "Pierre-Yves Courand",
      "Nicolas Thome",
      "Pierre-Marc Jodoin",
      "Nicolas Duchateau",
      "Olivier Bernard"
    ],
    "abstract": "Deep learning enables automatic and robust extraction of cardiac function\ndescriptors from echocardiographic sequences, such as ejection fraction or\nstrain. These descriptors provide fine-grained information that physicians\nconsider, in conjunction with more global variables from the clinical record,\nto assess patients' condition. Drawing on novel transformer models applied to\ntabular data, we propose a method that considers all descriptors extracted from\nmedical records and echocardiograms to learn the representation of a\ncardiovascular pathology with a difficult-to-characterize continuum, namely\nhypertension. Our method first projects each variable into its own\nrepresentation space using modality-specific approaches. These standardized\nrepresentations of multimodal data are then fed to a transformer encoder, which\nlearns to merge them into a comprehensive representation of the patient through\nthe task of predicting a clinical rating. This stratification task is\nformulated as an ordinal classification to enforce a pathological continuum in\nthe representation space. We observe the major trends along this continuum on a\ncohort of 239 hypertensive patients, providing unprecedented details in the\ndescription of hypertension's impact on various cardiac function descriptors.\nOur analysis shows that i) the XTab foundation model's architecture allows to\nreach outstanding performance (98% AUROC) even with limited data (less than 200\ntraining samples), ii) stratification across the population is reproducible\nbetween trainings (within 3.6% MAE), and iii) patterns emerge in descriptors,\nsome of which align with established physiological knowledge about\nhypertension, while others could pave the way for a more comprehensive\nunderstanding of this pathology.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages + 2 pages of supplementary material, submitted to IEEE\n  journal",
    "pdf_url": "http://arxiv.org/pdf/2401.07796v2",
    "published_date": "2024-01-15 16:04:46 UTC",
    "updated_date": "2024-10-11 16:28:00 UTC"
  },
  {
    "arxiv_id": "2401.07764v2",
    "title": "When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment",
    "authors": [
      "Minrui Xu",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Shiwen Mao",
      "Zhu Han",
      "Dong In Kim",
      "Khaled B. Letaief"
    ],
    "abstract": "AI agents based on multimodal large language models (LLMs) are expected to\nrevolutionize human-computer interaction and offer more personalized assistant\nservices across various domains like healthcare, education, manufacturing, and\nentertainment. Deploying LLM agents in 6G networks enables users to access\npreviously expensive AI assistant services via mobile devices democratically,\nthereby reducing interaction latency and better preserving user privacy.\nNevertheless, the limited capacity of mobile devices constrains the\neffectiveness of deploying and executing local LLMs, which necessitates\noffloading complex tasks to global LLMs running on edge servers during\nlong-horizon interactions. In this article, we propose a split learning system\nfor LLM agents in 6G networks leveraging the collaboration between mobile\ndevices and edge servers, where multiple LLMs with different roles are\ndistributed across mobile devices and edge servers to perform user-agent\ninteractive tasks collaboratively. In the proposed system, LLM agents are split\ninto perception, grounding, and alignment modules, facilitating inter-module\ncommunications to meet extended user requirements on 6G network functions,\nincluding integrated sensing and communication, digital twins, and\ntask-oriented communications. Furthermore, we introduce a novel model caching\nalgorithm for LLMs within the proposed system to improve model utilization in\ncontext, thus reducing network costs of the collaborative mobile and edge LLM\nagents.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07764v2",
    "published_date": "2024-01-15 15:20:59 UTC",
    "updated_date": "2024-02-16 19:15:31 UTC"
  },
  {
    "arxiv_id": "2401.08711v1",
    "title": "Assistant, Parrot, or Colonizing Loudspeaker? ChatGPT Metaphors for Developing Critical AI Literacies",
    "authors": [
      "Anuj Gupta",
      "Yasser Atef",
      "Anna Mills",
      "Maha Bali"
    ],
    "abstract": "This study explores how discussing metaphors for AI can help build awareness\nof the frames that shape our understanding of AI systems, particularly large\nlanguage models (LLMs) like ChatGPT. Given the pressing need to teach \"critical\nAI literacy\", discussion of metaphor provides an opportunity for inquiry and\ndialogue with space for nuance, playfulness, and critique. Using a\ncollaborative autoethnographic methodology, we analyzed metaphors from a range\nof sources, and reflected on them individually according to seven questions,\nthen met and discussed our interpretations. We then analyzed how our\nreflections contributed to the three kinds of literacies delineated in Selber's\nmultiliteracies framework: functional, critical, and rhetorical. These allowed\nus to analyze questions of ethics, equity, and accessibility in relation to AI.\nWe explored each metaphor along the dimension of whether or not it was\npromoting anthropomorphizing, and to what extent such metaphors imply that AI\nis sentient. Our findings highlight the role of metaphor reflection in\nfostering a nuanced understanding of AI, suggesting that our collaborative\nautoethnographic approach as well as the heuristic model of plotting AI\nmetaphors on dimensions of anthropomorphism and multiliteracies, might be\nuseful for educators and researchers in the pursuit of advancing critical AI\nliteracy.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "I.2.0; K.3.0; K.3.1; K.4.0; K.4.2; J.4; J.5"
    ],
    "primary_category": "cs.HC",
    "comment": "This is a preprint (accepted version) of an article that has been\n  accepted for publication at the journal Open Praxis: https://openpraxis.org/",
    "pdf_url": "http://arxiv.org/pdf/2401.08711v1",
    "published_date": "2024-01-15 15:15:48 UTC",
    "updated_date": "2024-01-15 15:15:48 UTC"
  },
  {
    "arxiv_id": "2401.07744v2",
    "title": "Combining Machine Learning and Ontology: A Systematic Literature Review",
    "authors": [
      "Sarah Ghidalia",
      "Ouassila Labbani Narsis",
      "Aurélie Bertaux",
      "Christophe Nicolle"
    ],
    "abstract": "Motivated by the desire to explore the process of combining inductive and\ndeductive reasoning, we conducted a systematic literature review of articles\nthat investigate the integration of machine learning and ontologies. The\nobjective was to identify diverse techniques that incorporate both inductive\nreasoning (performed by machine learning) and deductive reasoning (performed by\nontologies) into artificial intelligence systems. Our review, which included\nthe analysis of 128 studies, allowed us to identify three main categories of\nhybridization between machine learning and ontologies: learning-enhanced\nontologies, semantic data mining, and learning and reasoning systems. We\nprovide a comprehensive examination of all these categories, emphasizing the\nvarious machine learning algorithms utilized in the studies. Furthermore, we\ncompared our classification with similar recent work in the field of hybrid AI\nand neuro-symbolic approaches.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07744v2",
    "published_date": "2024-01-15 14:56:04 UTC",
    "updated_date": "2024-02-19 10:43:51 UTC"
  },
  {
    "arxiv_id": "2401.07729v2",
    "title": "SSL-Interactions: Pretext Tasks for Interactive Trajectory Prediction",
    "authors": [
      "Prarthana Bhattacharyya",
      "Chengjie Huang",
      "Krzysztof Czarnecki"
    ],
    "abstract": "This paper addresses motion forecasting in multi-agent environments, pivotal\nfor ensuring safety of autonomous vehicles. Traditional as well as recent\ndata-driven marginal trajectory prediction methods struggle to properly learn\nnon-linear agent-to-agent interactions. We present SSL-Interactions that\nproposes pretext tasks to enhance interaction modeling for trajectory\nprediction. We introduce four interaction-aware pretext tasks to encapsulate\nvarious aspects of agent interactions: range gap prediction, closest distance\nprediction, direction of movement prediction, and type of interaction\nprediction. We further propose an approach to curate interaction-heavy\nscenarios from datasets. This curated data has two advantages: it provides a\nstronger learning signal to the interaction model, and facilitates generation\nof pseudo-labels for interaction-centric pretext tasks. We also propose three\nnew metrics specifically designed to evaluate predictions in interactive\nscenes. Our empirical evaluations indicate SSL-Interactions outperforms\nstate-of-the-art motion forecasting methods quantitatively with up to 8%\nimprovement, and qualitatively, for interaction-heavy scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at IV-2024. 13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.07729v2",
    "published_date": "2024-01-15 14:43:40 UTC",
    "updated_date": "2024-08-26 09:16:57 UTC"
  },
  {
    "arxiv_id": "2401.07722v1",
    "title": "Inferring Preferences from Demonstrations in Multi-Objective Residential Energy Management",
    "authors": [
      "Junlin Lu",
      "Patrick Mannion",
      "Karl Mason"
    ],
    "abstract": "It is often challenging for a user to articulate their preferences accurately\nin multi-objective decision-making problems. Demonstration-based preference\ninference (DemoPI) is a promising approach to mitigate this problem.\nUnderstanding the behaviours and values of energy customers is an example of a\nscenario where preference inference can be used to gain insights into the\nvalues of energy customers with multiple objectives, e.g. cost and comfort. In\nthis work, we applied the state-of-art DemoPI method, i.e., the dynamic\nweight-based preference inference (DWPI) algorithm in a multi-objective\nresidential energy consumption setting to infer preferences from energy\nconsumption demonstrations by simulated users following a rule-based approach.\nAccording to our experimental results, the DWPI model achieves accurate\ndemonstration-based preference inferring in three scenarios. These advancements\nenhance the usability and effectiveness of multi-objective reinforcement\nlearning (MORL) in energy management, enabling more intuitive and user-friendly\npreference specifications, and opening the door for DWPI to be applied in\nreal-world settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07722v1",
    "published_date": "2024-01-15 14:36:59 UTC",
    "updated_date": "2024-01-15 14:36:59 UTC"
  },
  {
    "arxiv_id": "2401.07710v1",
    "title": "Go-Explore for Residential Energy Management",
    "authors": [
      "Junlin Lu",
      "Patrick Mannion",
      "Karl Mason"
    ],
    "abstract": "Reinforcement learning is commonly applied in residential energy management,\nparticularly for optimizing energy costs. However, RL agents often face\nchallenges when dealing with deceptive and sparse rewards in the energy control\ndomain, especially with stochastic rewards. In such situations, thorough\nexploration becomes crucial for learning an optimal policy. Unfortunately, the\nexploration mechanism can be misled by deceptive reward signals, making\nthorough exploration difficult. Go-Explore is a family of algorithms which\ncombines planning methods and reinforcement learning methods to achieve\nefficient exploration. We use the Go-Explore algorithm to solve the cost-saving\ntask in residential energy management problems and achieve an improvement of up\nto 19.84\\% compared to the well-known reinforcement learning algorithms.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07710v1",
    "published_date": "2024-01-15 14:26:44 UTC",
    "updated_date": "2024-01-15 14:26:44 UTC"
  },
  {
    "arxiv_id": "2401.07709v2",
    "title": "Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks",
    "authors": [
      "Siyu Zou",
      "Jiji Tang",
      "Yiyi Zhou",
      "Jing He",
      "Chaoyi Zhao",
      "Rongsheng Zhang",
      "Zhipeng Hu",
      "Xiaoshuai Sun"
    ],
    "abstract": "Diffusion-based Image Editing (DIE) is an emerging research hot-spot, which\noften applies a semantic mask to control the target area for diffusion-based\nediting. However, most existing solutions obtain these masks via manual\noperations or off-line processing, greatly reducing their efficiency. In this\npaper, we propose a novel and efficient image editing method for Text-to-Image\n(T2I) diffusion models, termed Instant Diffusion Editing(InstDiffEdit). In\nparticular, InstDiffEdit aims to employ the cross-modal attention ability of\nexisting diffusion models to achieve instant mask guidance during the diffusion\nsteps. To reduce the noise of attention maps and realize the full automatics,\nwe equip InstDiffEdit with a training-free refinement scheme to adaptively\naggregate the attention distributions for the automatic yet accurate mask\ngeneration. Meanwhile, to supplement the existing evaluations of DIE, we\npropose a new benchmark called Editing-Mask to examine the mask accuracy and\nlocal editing ability of existing methods. To validate InstDiffEdit, we also\nconduct extensive experiments on ImageNet and Imagen, and compare it with a\nbunch of the SOTA methods. The experimental results show that InstDiffEdit not\nonly outperforms the SOTA methods in both image quality and editing results,\nbut also has a much faster inference speed, i.e., +5 to +6 times.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI2024",
    "pdf_url": "http://arxiv.org/pdf/2401.07709v2",
    "published_date": "2024-01-15 14:25:54 UTC",
    "updated_date": "2024-01-23 11:22:03 UTC"
  },
  {
    "arxiv_id": "2401.10158v3",
    "title": "DISTINQT: A Distributed Privacy Aware Learning Framework for QoS Prediction for Future Mobile and Wireless Networks",
    "authors": [
      "Nikolaos Koursioumpas",
      "Lina Magoula",
      "Ioannis Stavrakakis",
      "Nancy Alonistioti",
      "M. A. Gutierrez-Estevez",
      "Ramin Khalili"
    ],
    "abstract": "Beyond 5G and 6G networks are expected to support new and challenging use\ncases and applications that depend on a certain level of Quality of Service\n(QoS) to operate smoothly. Predicting the QoS in a timely manner is of high\nimportance, especially for safety-critical applications as in the case of\nvehicular communications. Although until recent years the QoS prediction has\nbeen carried out by centralized Artificial Intelligence (AI) solutions, a\nnumber of privacy, computational, and operational concerns have emerged.\nAlternative solutions have surfaced (e.g. Split Learning, Federated Learning),\ndistributing AI tasks of reduced complexity across nodes, while preserving the\nprivacy of the data. However, new challenges rise when it comes to scalable\ndistributed learning approaches, taking into account the heterogeneous nature\nof future wireless networks. The current work proposes DISTINQT, a novel\nmulti-headed input privacy-aware distributed learning framework for QoS\nprediction. Our framework supports multiple heterogeneous nodes, in terms of\ndata types and model architectures, by sharing computations across them. This\nenables the incorporation of diverse knowledge into a sole learning process\nthat will enhance the robustness and generalization capabilities of the final\nQoS prediction model. DISTINQT also contributes to data privacy preservation by\nencoding any raw input data into highly complex, compressed, and irreversible\nlatent representations before any transmission. Evaluation results showcase\nthat DISTINQT achieves a statistically identical performance compared to its\ncentralized version, while also proving the validity of the privacy preserving\nclaims. DISTINQT manages to achieve a reduction in prediction error of up to\n65% on average against six state-of-the-art centralized baseline solutions\npresented in the Tele-Operated Driving use case.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "12 Pages Double Column, 10 Figures, (Minor Revised Version) Accepted\n  for publication in the IEEE Transactions on Vehicular Technology (IEEE TVT)",
    "pdf_url": "http://arxiv.org/pdf/2401.10158v3",
    "published_date": "2024-01-15 13:00:48 UTC",
    "updated_date": "2024-11-04 13:26:36 UTC"
  },
  {
    "arxiv_id": "2401.07656v4",
    "title": "Learning Explainable and Better Performing Representations of POMDP Strategies",
    "authors": [
      "Alexander Bork",
      "Debraj Chakraborty",
      "Kush Grover",
      "Jan Kretinsky",
      "Stefanie Mohr"
    ],
    "abstract": "Strategies for partially observable Markov decision processes (POMDP)\ntypically require memory. One way to represent this memory is via automata. We\npresent a method to learn an automaton representation of a strategy using a\nmodification of the L*-algorithm. Compared to the tabular representation of a\nstrategy, the resulting automaton is dramatically smaller and thus also more\nexplainable. Moreover, in the learning process, our heuristics may even improve\nthe strategy's performance. In contrast to approaches that synthesize an\nautomaton directly from the POMDP thereby solving it, our approach is\nincomparably more scalable.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Technical report for the submission to TACAS 24",
    "pdf_url": "http://arxiv.org/pdf/2401.07656v4",
    "published_date": "2024-01-15 12:52:56 UTC",
    "updated_date": "2024-10-02 12:12:31 UTC"
  },
  {
    "arxiv_id": "2401.07655v1",
    "title": "MLAD: A Unified Model for Multi-system Log Anomaly Detection",
    "authors": [
      "Runqiang Zang",
      "Hongcheng Guo",
      "Jian Yang",
      "Jiaheng Liu",
      "Zhoujun Li",
      "Tieqiao Zheng",
      "Xu Shi",
      "Liangfan Zheng",
      "Bo Zhang"
    ],
    "abstract": "In spite of the rapid advancements in unsupervised log anomaly detection\ntechniques, the current mainstream models still necessitate specific training\nfor individual system datasets, resulting in costly procedures and limited\nscalability due to dataset size, thereby leading to performance bottlenecks.\nFurthermore, numerous models lack cognitive reasoning capabilities, posing\nchallenges in direct transferability to similar systems for effective anomaly\ndetection. Additionally, akin to reconstruction networks, these models often\nencounter the \"identical shortcut\" predicament, wherein the majority of system\nlogs are classified as normal, erroneously predicting normal classes when\nconfronted with rare anomaly logs due to reconstruction errors.\n  To address the aforementioned issues, we propose MLAD, a novel anomaly\ndetection model that incorporates semantic relational reasoning across multiple\nsystems. Specifically, we employ Sentence-bert to capture the similarities\nbetween log sequences and convert them into highly-dimensional learnable\nsemantic vectors. Subsequently, we revamp the formulas of the Attention layer\nto discern the significance of each keyword in the sequence and model the\noverall distribution of the multi-system dataset through appropriate vector\nspace diffusion. Lastly, we employ a Gaussian mixture model to highlight the\nuncertainty of rare words pertaining to the \"identical shortcut\" problem,\noptimizing the vector space of the samples using the maximum expectation model.\nExperiments on three real-world datasets demonstrate the superiority of MLAD.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07655v1",
    "published_date": "2024-01-15 12:51:13 UTC",
    "updated_date": "2024-01-15 12:51:13 UTC"
  },
  {
    "arxiv_id": "2401.07612v1",
    "title": "Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks Against LLM-Integrated Applications",
    "authors": [
      "Xuchen Suo"
    ],
    "abstract": "The critical challenge of prompt injection attacks in Large Language Models\n(LLMs) integrated applications, a growing concern in the Artificial\nIntelligence (AI) field. Such attacks, which manipulate LLMs through natural\nlanguage inputs, pose a significant threat to the security of these\napplications. Traditional defense strategies, including output and input\nfiltering, as well as delimiter use, have proven inadequate. This paper\nintroduces the 'Signed-Prompt' method as a novel solution. The study involves\nsigning sensitive instructions within command segments by authorized users,\nenabling the LLM to discern trusted instruction sources. The paper presents a\ncomprehensive analysis of prompt injection attack patterns, followed by a\ndetailed explanation of the Signed-Prompt concept, including its basic\narchitecture and implementation through both prompt engineering and fine-tuning\nof LLMs. Experiments demonstrate the effectiveness of the Signed-Prompt method,\nshowing substantial resistance to various types of prompt injection attacks,\nthus validating its potential as a robust defense strategy in AI security.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07612v1",
    "published_date": "2024-01-15 11:44:18 UTC",
    "updated_date": "2024-01-15 11:44:18 UTC"
  },
  {
    "arxiv_id": "2401.07603v3",
    "title": "Multi-task real-robot data with gaze attention for dual-arm fine manipulation",
    "authors": [
      "Heecheol Kim",
      "Yoshiyuki Ohmura",
      "Yasuo Kuniyoshi"
    ],
    "abstract": "In the field of robotic manipulation, deep imitation learning is recognized\nas a promising approach for acquiring manipulation skills. Additionally,\nlearning from diverse robot datasets is considered a viable method to achieve\nversatility and adaptability. In such research, by learning various tasks,\nrobots achieved generality across multiple objects. However, such multi-task\nrobot datasets have mainly focused on single-arm tasks that are relatively\nimprecise, not addressing the fine-grained object manipulation that robots are\nexpected to perform in the real world. This paper introduces a dataset of\ndiverse object manipulations that includes dual-arm tasks and/or tasks\nrequiring fine manipulation. To this end, we have generated dataset with 224k\nepisodes (150 hours, 1,104 language instructions) which includes dual-arm fine\ntasks such as bowl-moving, pencil-case opening or banana-peeling, and this data\nis publicly available. Additionally, this dataset includes visual attention\nsignals as well as dual-action labels, a signal that separates actions into a\nrobust reaching trajectory and precise interaction with objects, and language\ninstructions to achieve robust and precise object manipulation. We applied the\ndataset to our Dual-Action and Attention (DAA), a model designed for\nfine-grained dual arm manipulation tasks and robust against covariate shifts.\nThe model was tested with over 7k total trials in real robot manipulation\ntasks, demonstrating its capability in fine manipulation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, The dataset is available at\n  https://sites.google.com/view/multi-task-fine",
    "pdf_url": "http://arxiv.org/pdf/2401.07603v3",
    "published_date": "2024-01-15 11:20:34 UTC",
    "updated_date": "2024-03-19 11:17:00 UTC"
  },
  {
    "arxiv_id": "2401.07595v3",
    "title": "E3x: $\\mathrm{E}(3)$-Equivariant Deep Learning Made Easy",
    "authors": [
      "Oliver T. Unke",
      "Hartmut Maennel"
    ],
    "abstract": "This work introduces E3x, a software package for building neural networks\nthat are equivariant with respect to the Euclidean group $\\mathrm{E}(3)$,\nconsisting of translations, rotations, and reflections of three-dimensional\nspace. Compared to ordinary neural networks, $\\mathrm{E}(3)$-equivariant models\npromise benefits whenever input and/or output data are quantities associated\nwith three-dimensional objects. This is because the numeric values of such\nquantities (e.g. positions) typically depend on the chosen coordinate system.\nUnder transformations of the reference frame, the values change predictably,\nbut the underlying rules can be difficult to learn for ordinary machine\nlearning models. With built-in $\\mathrm{E}(3)$-equivariance, neural networks\nare guaranteed to satisfy the relevant transformation rules exactly, resulting\nin superior data efficiency and accuracy. The code for E3x is available from\nhttps://github.com/google-research/e3x, detailed documentation and usage\nexamples can be found on https://e3x.readthedocs.io.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07595v3",
    "published_date": "2024-01-15 11:04:47 UTC",
    "updated_date": "2024-11-11 14:53:38 UTC"
  },
  {
    "arxiv_id": "2401.13693v1",
    "title": "Challenge design roadmap",
    "authors": [
      "Hugo Jair Escalante Balderas",
      "Isabelle Guyon",
      "Addison Howard",
      "Walter Reade",
      "Sebastien Treguer"
    ],
    "abstract": "Challenges can be seen as a type of game that motivates participants to solve\nserious tasks. As a result, competition organizers must develop effective game\nrules. However, these rules have multiple objectives beyond making the game\nenjoyable for participants. These objectives may include solving real-world\nproblems, advancing scientific or technical areas, making scientific\ndiscoveries, and educating the public. In many ways, creating a challenge is\nsimilar to launching a product. It requires the same level of excitement and\nrigorous testing, and the goal is to attract ''customers'' in the form of\nparticipants. The process begins with a solid plan, such as a competition\nproposal that will eventually be submitted to an international conference and\nsubjected to peer review. Although peer review does not guarantee quality, it\ndoes force organizers to consider the impact of their challenge, identify\npotential oversights, and generally improve its quality. This chapter provides\nguidelines for creating a strong plan for a challenge. The material draws on\nthe preparation guidelines from organizations such as Kaggle 1 , ChaLearn 2 and\nTailor 3 , as well as the NeurIPS proposal template, which some of the authors\ncontributed to.",
    "categories": [
      "cs.OH",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.OH",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.13693v1",
    "published_date": "2024-01-15 10:58:30 UTC",
    "updated_date": "2024-01-15 10:58:30 UTC"
  },
  {
    "arxiv_id": "2401.07591v1",
    "title": "Multimodal Crowd Counting with Pix2Pix GANs",
    "authors": [
      "Muhammad Asif Khan",
      "Hamid Menouar",
      "Ridha Hamila"
    ],
    "abstract": "Most state-of-the-art crowd counting methods use color (RGB) images to learn\nthe density map of the crowd. However, these methods often struggle to achieve\nhigher accuracy in densely crowded scenes with poor illumination. Recently,\nsome studies have reported improvement in the accuracy of crowd counting models\nusing a combination of RGB and thermal images. Although multimodal data can\nlead to better predictions, multimodal data might not be always available\nbeforehand. In this paper, we propose the use of generative adversarial\nnetworks (GANs) to automatically generate thermal infrared (TIR) images from\ncolor (RGB) images and use both to train crowd counting models to achieve\nhigher accuracy. We use a Pix2Pix GAN network first to translate RGB images to\nTIR images. Our experiments on several state-of-the-art crowd counting models\nand benchmark crowd datasets report significant improvement in accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted version of the paper in 19th International Conference on\n  Computer Vision Theory and Applications (VISAPP), Rome, Italy, 27-29 Feb,\n  2024,",
    "pdf_url": "http://arxiv.org/pdf/2401.07591v1",
    "published_date": "2024-01-15 10:54:35 UTC",
    "updated_date": "2024-01-15 10:54:35 UTC"
  },
  {
    "arxiv_id": "2401.07586v1",
    "title": "Curriculum for Crowd Counting -- Is it Worthy?",
    "authors": [
      "Muhammad Asif Khan",
      "Hamid Menouar",
      "Ridha Hamila"
    ],
    "abstract": "Recent advances in deep learning techniques have achieved remarkable\nperformance in several computer vision problems. A notably intuitive technique\ncalled Curriculum Learning (CL) has been introduced recently for training deep\nlearning models. Surprisingly, curriculum learning achieves significantly\nimproved results in some tasks but marginal or no improvement in others. Hence,\nthere is still a debate about its adoption as a standard method to train\nsupervised learning models. In this work, we investigate the impact of\ncurriculum learning in crowd counting using the density estimation method. We\nperformed detailed investigations by conducting 112 experiments using six\ndifferent CL settings using eight different crowd models. Our experiments show\nthat curriculum learning improves the model learning performance and shortens\nthe convergence time.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted version of the paper in 19th International Conference on\n  Computer Vision Theory and Applications (VISAPP), Rome, Italy, 27-19 February\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2401.07586v1",
    "published_date": "2024-01-15 10:46:01 UTC",
    "updated_date": "2024-01-15 10:46:01 UTC"
  },
  {
    "arxiv_id": "2402.12381v1",
    "title": "Constrained Multi-objective Optimization with Deep Reinforcement Learning Assisted Operator Selection",
    "authors": [
      "Fei Ming",
      "Wenyin Gong",
      "Ling Wang",
      "Yaochu Jin"
    ],
    "abstract": "Solving constrained multi-objective optimization problems with evolutionary\nalgorithms has attracted considerable attention. Various constrained\nmulti-objective optimization evolutionary algorithms (CMOEAs) have been\ndeveloped with the use of different algorithmic strategies, evolutionary\noperators, and constraint-handling techniques. The performance of CMOEAs may be\nheavily dependent on the operators used, however, it is usually difficult to\nselect suitable operators for the problem at hand. Hence, improving operator\nselection is promising and necessary for CMOEAs. This work proposes an online\noperator selection framework assisted by Deep Reinforcement Learning. The\ndynamics of the population, including convergence, diversity, and feasibility,\nare regarded as the state; the candidate operators are considered as actions;\nand the improvement of the population state is treated as the reward. By using\na Q-Network to learn a policy to estimate the Q-values of all actions, the\nproposed approach can adaptively select an operator that maximizes the\nimprovement of the population according to the current state and thereby\nimprove the algorithmic performance. The framework is embedded into four\npopular CMOEAs and assessed on 42 benchmark problems. The experimental results\nreveal that the proposed Deep Reinforcement Learning-assisted operator\nselection significantly improves the performance of these CMOEAs and the\nresulting algorithm obtains better versatility compared to nine\nstate-of-the-art CMOEAs.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.12381v1",
    "published_date": "2024-01-15 09:51:19 UTC",
    "updated_date": "2024-01-15 09:51:19 UTC"
  },
  {
    "arxiv_id": "2401.07543v1",
    "title": "Must: Maximizing Latent Capacity of Spatial Transcriptomics Data",
    "authors": [
      "Zelin Zang",
      "Liangyu Li",
      "Yongjie Xu",
      "Chenrui Duan",
      "Kai Wang",
      "Yang You",
      "Yi Sun",
      "Stan Z. Li"
    ],
    "abstract": "Spatial transcriptomics (ST) technologies have revolutionized the study of\ngene expression patterns in tissues by providing multimodality data in\ntranscriptomic, spatial, and morphological, offering opportunities for\nunderstanding tissue biology beyond transcriptomics. However, we identify the\nmodality bias phenomenon in ST data species, i.e., the inconsistent\ncontribution of different modalities to the labels leads to a tendency for the\nanalysis methods to retain the information of the dominant modality. How to\nmitigate the adverse effects of modality bias to satisfy various downstream\ntasks remains a fundamental challenge. This paper introduces Multiple-modality\nStructure Transformation, named MuST, a novel methodology to tackle the\nchallenge. MuST integrates the multi-modality information contained in the ST\ndata effectively into a uniform latent space to provide a foundation for all\nthe downstream tasks. It learns intrinsic local structures by topology\ndiscovery strategy and topology fusion loss function to solve the\ninconsistencies among different modalities. Thus, these topology-based and deep\nlearning techniques provide a solid foundation for a variety of analytical\ntasks while coordinating different modalities. The effectiveness of MuST is\nassessed by performance metrics and biological significance. The results show\nthat it outperforms existing state-of-the-art methods with clear advantages in\nthe precision of identifying and preserving structures of tissues and\nbiomarkers. MuST offers a versatile toolkit for the intricate analysis of\ncomplex biological systems.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "30 pages and 6 figures, plus 27 pages and 14 figures in appendices",
    "pdf_url": "http://arxiv.org/pdf/2401.07543v1",
    "published_date": "2024-01-15 09:07:28 UTC",
    "updated_date": "2024-01-15 09:07:28 UTC"
  },
  {
    "arxiv_id": "2401.07532v1",
    "title": "Multi-view MidiVAE: Fusing Track- and Bar-view Representations for Long Multi-track Symbolic Music Generation",
    "authors": [
      "Zhiwei Lin",
      "Jun Chen",
      "Boshi Tang",
      "Binzhu Sha",
      "Jing Yang",
      "Yaolong Ju",
      "Fan Fan",
      "Shiyin Kang",
      "Zhiyong Wu",
      "Helen Meng"
    ],
    "abstract": "Variational Autoencoders (VAEs) constitute a crucial component of neural\nsymbolic music generation, among which some works have yielded outstanding\nresults and attracted considerable attention. Nevertheless, previous VAEs still\nencounter issues with overly long feature sequences and generated results lack\ncontextual coherence, thus the challenge of modeling long multi-track symbolic\nmusic still remains unaddressed. To this end, we propose Multi-view MidiVAE, as\none of the pioneers in VAE methods that effectively model and generate long\nmulti-track symbolic music. The Multi-view MidiVAE utilizes the two-dimensional\n(2-D) representation, OctupleMIDI, to capture relationships among notes while\nreducing the feature sequences length. Moreover, we focus on instrumental\ncharacteristics and harmony as well as global and local information about the\nmusical composition by employing a hybrid variational encoding-decoding\nstrategy to integrate both Track- and Bar-view MidiVAE features. Objective and\nsubjective experimental results on the CocoChorales dataset demonstrate that,\ncompared to the baseline, Multi-view MidiVAE exhibits significant improvements\nin terms of modeling long multi-track symbolic music.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.07532v1",
    "published_date": "2024-01-15 08:41:01 UTC",
    "updated_date": "2024-01-15 08:41:01 UTC"
  },
  {
    "arxiv_id": "2401.07526v1",
    "title": "Editing Arbitrary Propositions in LLMs without Subject Labels",
    "authors": [
      "Itai Feigenbaum",
      "Devansh Arpit",
      "Huan Wang",
      "Shelby Heinecke",
      "Juan Carlos Niebles",
      "Weiran Yao",
      "Caiming Xiong",
      "Silvio Savarese"
    ],
    "abstract": "Large Language Model (LLM) editing modifies factual information in LLMs.\nLocate-and-Edit (L\\&E) methods accomplish this by finding where relevant\ninformation is stored within the neural network, and editing the weights at\nthat location. The goal of editing is to modify the response of an LLM to a\nproposition independently of its phrasing, while not modifying its response to\nother related propositions. Existing methods are limited to binary\npropositions, which represent straightforward binary relations between a\nsubject and an object. Furthermore, existing methods rely on semantic subject\nlabels, which may not be available or even be well-defined in practice. In this\npaper, we show that both of these issues can be effectively skirted with a\nsimple and fast localization method called Gradient Tracing (GT). This\nlocalization method allows editing arbitrary propositions instead of just\nbinary ones, and does so without the need for subject labels. As propositions\nalways have a truth value, our experiments prompt an LLM as a boolean\nclassifier, and edit its T/F response to propositions. Our method applies GT\nfor location tracing, and then edit the model at that location using a mild\nvariant of Rank-One Model Editing (ROME). On datasets of binary propositions\nderived from the CounterFact dataset, we show that our method -- without access\nto subject labels -- performs close to state-of-the-art L\\&E methods which has\naccess subject labels. We then introduce a new dataset, Factual Accuracy\nClassification Test (FACT), which includes non-binary propositions and for\nwhich subject labels are not generally applicable, and therefore is beyond the\nscope of existing L\\&E methods. Nevertheless, we show that with our method\nediting is possible on FACT.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07526v1",
    "published_date": "2024-01-15 08:08:24 UTC",
    "updated_date": "2024-01-15 08:08:24 UTC"
  },
  {
    "arxiv_id": "2401.07525v2",
    "title": "TAROT: A Hierarchical Framework with Multitask Co-Pretraining on Semi-Structured Data towards Effective Person-Job Fit",
    "authors": [
      "Yihan Cao",
      "Xu Chen",
      "Lun Du",
      "Hao Chen",
      "Qiang Fu",
      "Shi Han",
      "Yushu Du",
      "Yanbin Kang",
      "Guangming Lu",
      "Zi Li"
    ],
    "abstract": "Person-job fit is an essential part of online recruitment platforms in\nserving various downstream applications like Job Search and Candidate\nRecommendation. Recently, pretrained large language models have further\nenhanced the effectiveness by leveraging richer textual information in user\nprofiles and job descriptions apart from user behavior features and job\nmetadata. However, the general domain-oriented design struggles to capture the\nunique structural information within user profiles and job descriptions,\nleading to a loss of latent semantic correlations. We propose TAROT, a\nhierarchical multitask co-pretraining framework, to better utilize structural\nand semantic information for informative text embeddings. TAROT targets\nsemi-structured text in profiles and jobs, and it is co-pretained with\nmulti-grained pretraining tasks to constrain the acquired semantic information\nat each level. Experiments on a real-world LinkedIn dataset show significant\nperformance improvements, proving its effectiveness in person-job fit tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICASSP 2024 camera ready. 5 pages, 1 figure, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.07525v2",
    "published_date": "2024-01-15 07:57:58 UTC",
    "updated_date": "2024-01-17 23:06:15 UTC"
  },
  {
    "arxiv_id": "2401.07519v2",
    "title": "InstantID: Zero-shot Identity-Preserving Generation in Seconds",
    "authors": [
      "Qixun Wang",
      "Xu Bai",
      "Haofan Wang",
      "Zekui Qin",
      "Anthony Chen",
      "Huaxia Li",
      "Xu Tang",
      "Yao Hu"
    ],
    "abstract": "There has been significant progress in personalized image synthesis with\nmethods such as Textual Inversion, DreamBooth, and LoRA. Yet, their real-world\napplicability is hindered by high storage demands, lengthy fine-tuning\nprocesses, and the need for multiple reference images. Conversely, existing ID\nembedding-based methods, while requiring only a single forward inference, face\nchallenges: they either necessitate extensive fine-tuning across numerous model\nparameters, lack compatibility with community pre-trained models, or fail to\nmaintain high face fidelity. Addressing these limitations, we introduce\nInstantID, a powerful diffusion model-based solution. Our plug-and-play module\nadeptly handles image personalization in various styles using just a single\nfacial image, while ensuring high fidelity. To achieve this, we design a novel\nIdentityNet by imposing strong semantic and weak spatial conditions,\nintegrating facial and landmark images with textual prompts to steer the image\ngeneration. InstantID demonstrates exceptional performance and efficiency,\nproving highly beneficial in real-world applications where identity\npreservation is paramount. Moreover, our work seamlessly integrates with\npopular pre-trained text-to-image diffusion models like SD1.5 and SDXL, serving\nas an adaptable plugin. Our codes and pre-trained checkpoints will be available\nat https://github.com/InstantID/InstantID.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report, project page available at\n  https://instantid.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2401.07519v2",
    "published_date": "2024-01-15 07:50:18 UTC",
    "updated_date": "2024-02-02 16:15:22 UTC"
  },
  {
    "arxiv_id": "2401.07518v3",
    "title": "Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends",
    "authors": [
      "Yunshi Lan",
      "Xinyuan Li",
      "Hanyue Du",
      "Xuesong Lu",
      "Ming Gao",
      "Weining Qian",
      "Aoying Zhou"
    ],
    "abstract": "Natural Language Processing (NLP) aims to analyze text or speech via\ntechniques in the computer science field. It serves the applications in domains\nof healthcare, commerce, education and so on. Particularly, NLP has been widely\napplied to the education domain and its applications have enormous potential to\nhelp teaching and learning. In this survey, we review recent advances in NLP\nwith the focus on solving problems relevant to the education domain. In detail,\nwe begin with introducing the related background and the real-world scenarios\nin education where NLP techniques could contribute. Then, we present a taxonomy\nof NLP in the education domain and highlight typical NLP applications including\nquestion answering, question construction, automated assessment, and error\ncorrection. Next, we illustrate the task definition, challenges, and\ncorresponding cutting-edge techniques based on the above taxonomy. In\nparticular, LLM-involved methods are included for discussion due to the wide\nusage of LLMs in diverse NLP applications. After that, we showcase some\noff-the-shelf demonstrations in this domain. At last, we conclude with six\npromising directions for future research, including more datasets in education\ndomain, controllable usage of LLMs, intervention of difficulty-level control,\ninterpretable educational NLP, methods with adaptive learning, and integrated\nsystems for education. We organize all relevant datasets and papers in the\nopen-available Github Link for better\nreview~\\url{https://github.com/LiXinyuan1015/NLP-for-Education}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07518v3",
    "published_date": "2024-01-15 07:48:42 UTC",
    "updated_date": "2024-03-15 05:10:05 UTC"
  },
  {
    "arxiv_id": "2401.07510v3",
    "title": "Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering",
    "authors": [
      "Qing Li",
      "Lei Li",
      "Yu Li"
    ],
    "abstract": "ChatGPT explores a strategic blueprint of question answering (QA) in\ndelivering medical diagnosis, treatment recommendations, and other healthcare\nsupport. This is achieved through the increasing incorporation of medical\ndomain data via natural language processing (NLP) and multimodal paradigms. By\ntransitioning the distribution of text, images, videos, and other modalities\nfrom the general domain to the medical domain, these techniques have expedited\nthe progress of medical domain question answering (MDQA). They bridge the gap\nbetween human natural language and sophisticated medical domain knowledge or\nexpert manual annotations, handling large-scale, diverse, unbalanced, or even\nunlabeled data analysis scenarios in medical contexts. Central to our focus is\nthe utilizing of language models and multimodal paradigms for medical question\nanswering, aiming to guide the research community in selecting appropriate\nmechanisms for their specific medical research requirements. Specialized tasks\nsuch as unimodal-related question answering, reading comprehension, reasoning,\ndiagnosis, relation extraction, probability modeling, and others, as well as\nmultimodal-related tasks like vision question answering, image caption,\ncross-modal retrieval, report summarization, and generation, are discussed in\ndetail. Each section delves into the intricate specifics of the respective\nmethod under consideration. This paper highlights the structures and\nadvancements of medical domain explorations against general domain methods,\nemphasizing their applications across different tasks and datasets. It also\noutlines current challenges and opportunities for future medical domain\nresearch, paving the way for continued innovation and application in this\nrapidly evolving field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CL, 92-02",
      "I.2.1"
    ],
    "primary_category": "cs.CL",
    "comment": "50 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.07510v3",
    "published_date": "2024-01-15 07:21:16 UTC",
    "updated_date": "2024-01-20 22:08:18 UTC"
  },
  {
    "arxiv_id": "2401.07489v1",
    "title": "The Principle of Minimum Pressure Gradient: An Alternative Basis for Physics-Informed Learning of Incompressible Fluid Mechanics",
    "authors": [
      "Hussam Alhussein",
      "Mohammed Daqaq"
    ],
    "abstract": "Recent advances in the application of physics-informed learning into the\nfield of fluid mechanics have been predominantly grounded in the Newtonian\nframework, primarly leveraging Navier-Stokes Equation or one of its various\nderivative to train a neural network. Here, we propose an alternative approach\nbased on variational methods. The proposed approach uses the principle of\nminimum pressure gradient combined with the continuity constraint to train a\nneural network and predict the flow field in incompressible fluids. We describe\nthe underlying principles of the proposed approach, then use a demonstrative\nexample to illustrate its implementation and show that it reduces the\ncomputational time per training epoch when compared to the conventional\napproach.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07489v1",
    "published_date": "2024-01-15 06:12:22 UTC",
    "updated_date": "2024-01-15 06:12:22 UTC"
  },
  {
    "arxiv_id": "2401.09479v2",
    "title": "Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep Learning",
    "authors": [
      "Rahul Vishwakarma",
      "Amin Rezaei"
    ],
    "abstract": "The risk of hardware Trojans being inserted at various stages of chip\nproduction has increased in a zero-trust fabless era. To counter this, various\nmachine learning solutions have been developed for the detection of hardware\nTrojans. While most of the focus has been on either a statistical or deep\nlearning approach, the limited number of Trojan-infected benchmarks affects the\ndetection accuracy and restricts the possibility of detecting zero-day Trojans.\nTo close the gap, we first employ generative adversarial networks to amplify\nour data in two alternative representation modalities, a graph and a tabular,\nensuring that the dataset is distributed in a representative manner. Further,\nwe propose a multimodal deep learning approach to detect hardware Trojans and\nevaluate the results from both early fusion and late fusion strategies. We also\nestimate the uncertainty quantification metrics of each prediction for\nrisk-aware decision-making. The outcomes not only confirms the efficacy of our\nproposed hardware Trojan detection method but also opens a new door for future\nstudies employing multimodality and uncertainty quantification to address other\nhardware security challenges.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "2024 Design, Automation and Test in Europe Conference | The European\n  Event for Electronic System Design & Test (accepted)",
    "pdf_url": "http://arxiv.org/pdf/2401.09479v2",
    "published_date": "2024-01-15 05:45:51 UTC",
    "updated_date": "2024-01-23 07:04:18 UTC"
  },
  {
    "arxiv_id": "2401.07470v1",
    "title": "Utilizing deep learning models for the identification of enhancers and super-enhancers based on genomic and epigenomic features",
    "authors": [
      "Zahra Ahani",
      "Moein Shahiki Tash",
      "Yoel Ledo Mezquita",
      "Jason Angel"
    ],
    "abstract": "This paper provides an extensive examination of a sizable dataset of English\ntweets focusing on nine widely recognized cryptocurrencies, specifically\nCardano, Binance, Bitcoin, Dogecoin, Ethereum, Fantom, Matic, Shiba, and\nRipple. Our primary objective was to conduct a psycholinguistic and emotion\nanalysis of social media content associated with these cryptocurrencies. To\nenable investigators to make more informed decisions. The study involved\ncomparing linguistic characteristics across the diverse digital coins, shedding\nlight on the distinctive linguistic patterns that emerge within each coin's\ncommunity. To achieve this, we utilized advanced text analysis techniques.\nAdditionally, our work unveiled an intriguing Understanding of the interplay\nbetween these digital assets within the cryptocurrency community. By examining\nwhich coin pairs are mentioned together most frequently in the dataset, we\nestablished correlations between different cryptocurrencies. To ensure the\nreliability of our findings, we initially gathered a total of 832,559 tweets\nfrom Twitter. These tweets underwent a rigorous preprocessing stage, resulting\nin a refined dataset of 115,899 tweets that were used for our analysis.\nOverall, our research offers valuable Perception into the linguistic nuances of\nvarious digital coins' online communities and provides a deeper understanding\nof their interactions in the cryptocurrency space.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 7 figures, 6 Tables",
    "pdf_url": "http://arxiv.org/pdf/2401.07470v1",
    "published_date": "2024-01-15 04:58:50 UTC",
    "updated_date": "2024-01-15 04:58:50 UTC"
  },
  {
    "arxiv_id": "2401.07468v2",
    "title": "CarSpeedNet: A Deep Neural Network-based Car Speed Estimation from Smartphone Accelerometer",
    "authors": [
      "Barak Or"
    ],
    "abstract": "We introduce the CarSpeedNet, a deep learning model designed to estimate car\nspeed using three-axis accelerometer data from smartphones. Using 13 hours of\ndata collected from a smartphone in cars across various roads, CarSpeedNet\naccurately models the relationship between smartphone acceleration and car\nspeed. Ground truth speed data was collected at 1 [Hz] from GPS receivers. The\nmodel provides high-frequency speed estimation by incorporating historical data\nand achieves a precision of less than 0.72 [m/s] during extended driving tests,\nrelying solely on smartphone accelerometer data without any connection to the\ncar.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 pages, under review",
    "pdf_url": "http://arxiv.org/pdf/2401.07468v2",
    "published_date": "2024-01-15 04:51:34 UTC",
    "updated_date": "2024-10-25 07:32:42 UTC"
  },
  {
    "arxiv_id": "2401.07466v1",
    "title": "Your Instructions Are Not Always Helpful: Assessing the Efficacy of Instruction Fine-tuning for Software Vulnerability Detection",
    "authors": [
      "Imam Nur Bani Yusuf",
      "Lingxiao Jiang"
    ],
    "abstract": "Software, while beneficial, poses potential cybersecurity risks due to\ninherent vulnerabilities. Detecting these vulnerabilities is crucial, and deep\nlearning has shown promise as an effective tool for this task due to its\nability to perform well without extensive feature engineering. However, a\nchallenge in deploying deep learning for vulnerability detection is the limited\navailability of training data. Recent research highlights the deep learning\nefficacy in diverse tasks. This success is attributed to instruction\nfine-tuning, a technique that remains under-explored in the context of\nvulnerability detection. This paper investigates the capability of models,\nspecifically a recent language model, to generalize beyond the programming\nlanguages used in their training data. It also examines the role of natural\nlanguage instructions in enhancing this generalization. Our study evaluates the\nmodel performance on a real-world dataset to predict vulnerable code. We\npresent key insights and lessons learned, contributing to understanding the\ndeep learning application in software vulnerability detection.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07466v1",
    "published_date": "2024-01-15 04:45:27 UTC",
    "updated_date": "2024-01-15 04:45:27 UTC"
  },
  {
    "arxiv_id": "2401.07456v2",
    "title": "Only Send What You Need: Learning to Communicate Efficiently in Federated Multilingual Machine Translation",
    "authors": [
      "Yun-Wei Chu",
      "Dong-Jun Han",
      "Christopher G. Brinton"
    ],
    "abstract": "Federated learning (FL) is a promising distributed machine learning paradigm\nthat enables multiple clients to collaboratively train a global model. In this\npaper, we focus on a practical federated multilingual learning setup where\nclients with their own language-specific data aim to collaboratively construct\na high-quality neural machine translation (NMT) model. However, communication\nconstraints in practical network systems present challenges for exchanging\nlarge-scale NMT engines between FL parties. We propose a meta-learning-based\nadaptive parameter selection methodology, MetaSend, that improves the\ncommunication efficiency of model transmissions from clients during FL-based\nmultilingual NMT training. Our approach learns a dynamic threshold for\nfiltering parameters prior to transmission without compromising the NMT model\nquality, based on the tensor deviations of clients between different FL rounds.\nThrough experiments on two NMT datasets with different language distributions,\nwe demonstrate that MetaSend obtains substantial improvements over baselines in\ntranslation quality in the presence of a limited communication budget.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07456v2",
    "published_date": "2024-01-15 04:04:26 UTC",
    "updated_date": "2025-04-18 15:41:23 UTC"
  },
  {
    "arxiv_id": "2401.07453v4",
    "title": "Model Editing at Scale leads to Gradual and Catastrophic Forgetting",
    "authors": [
      "Akshat Gupta",
      "Anurag Rao",
      "Gopala Anumanchipalli"
    ],
    "abstract": "Editing knowledge in large language models is an attractive capability to\nhave which allows us to correct incorrectly learnt facts during pre-training,\nas well as update the model with an ever-growing list of new facts. While\nexisting model editing techniques have shown promise, they are usually\nevaluated using metrics for reliability, specificity and generalization over\none or few edits. We argue that for model editing to have practical utility, we\nmust be able to make multiple edits to the same model. With this in mind, we\nevaluate the current model editing methods at scale, focusing on two state of\nthe art methods: ROME and MEMIT. We find that as the model is edited\nsequentially with multiple facts, it continually forgets previously edited\nfacts and the ability to perform downstream tasks. This forgetting happens in\ntwo phases -- an initial gradual but progressive forgetting phase followed by\nabrupt or catastrophic forgetting phase. Both gradual and catastrophic\nforgetting limit the usefulness of model editing methods at scale -- the former\nmaking model editing less effective as multiple edits are made to the model\nwhile the latter caps the scalability of such model editing methods. Our\nanalysis also highlights other key limitations of ROME and MEMIT at scale. With\nour work, we push for the development and evaluation of model editing methods\nkeeping scalability in mind.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2401.07453v4",
    "published_date": "2024-01-15 03:57:15 UTC",
    "updated_date": "2024-06-10 17:50:14 UTC"
  },
  {
    "arxiv_id": "2401.07450v4",
    "title": "HieraFashDiff: Hierarchical Fashion Design with Multi-stage Diffusion Models",
    "authors": [
      "Zhifeng Xie",
      "Hao Li",
      "Huiming Ding",
      "Mengtian Li",
      "Xinhan Di",
      "Ying Cao"
    ],
    "abstract": "Fashion design is a challenging and complex process.Recent works on fashion\ngeneration and editing are all agnostic of the actual fashion design process,\nwhich limits their usage in practice.In this paper, we propose a novel\nhierarchical diffusion-based framework tailored for fashion design, coined as\nHieraFashDiff. Our model is designed to mimic the practical fashion design\nworkflow, by unraveling the denosing process into two successive stages: 1) an\nideation stage that generates design proposals given high-level concepts and 2)\nan iteration stage that continuously refines the proposals using low-level\nattributes. Our model supports fashion design generation and fine-grained local\nediting in a single framework. To train our model, we contribute a new dataset\nof full-body fashion images annotated with hierarchical text descriptions.\nExtensive evaluations show that, as compared to prior approaches, our method\ncan generate fashion designs and edited results with higher fidelity and better\nprompt adherence, showing its promising potential to augment the practical\nfashion design workflow. Code and Dataset are available at\nhttps://github.com/haoli-zbdbc/hierafashdiff.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07450v4",
    "published_date": "2024-01-15 03:38:57 UTC",
    "updated_date": "2024-12-12 10:36:14 UTC"
  },
  {
    "arxiv_id": "2401.07448v2",
    "title": "Formal Logic Enabled Personalized Federated Learning Through Property Inference",
    "authors": [
      "Ziyan An",
      "Taylor T. Johnson",
      "Meiyi Ma"
    ],
    "abstract": "Recent advancements in federated learning (FL) have greatly facilitated the\ndevelopment of decentralized collaborative applications, particularly in the\ndomain of Artificial Intelligence of Things (AIoT). However, a critical aspect\nmissing from the current research landscape is the ability to enable\ndata-driven client models with symbolic reasoning capabilities. Specifically,\nthe inherent heterogeneity of participating client devices poses a significant\nchallenge, as each client exhibits unique logic reasoning properties. Failing\nto consider these device-specific specifications can result in critical\nproperties being missed in the client predictions, leading to suboptimal\nperformance. In this work, we propose a new training paradigm that leverages\ntemporal logic reasoning to address this issue. Our approach involves enhancing\nthe training process by incorporating mechanically generated logic expressions\nfor each FL client. Additionally, we introduce the concept of aggregation\nclusters and develop a partitioning algorithm to effectively group clients\nbased on the alignment of their temporal reasoning properties. We evaluate the\nproposed method on two tasks: a real-world traffic volume prediction task\nconsisting of sensory data from fifteen states and a smart city multi-task\nprediction utilizing synthetic data. The evaluation results exhibit clear\nimprovements, with performance accuracy improved by up to 54% across all\nsequential prediction models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07448v2",
    "published_date": "2024-01-15 03:25:37 UTC",
    "updated_date": "2024-01-24 01:48:00 UTC"
  },
  {
    "arxiv_id": "2401.07447v1",
    "title": "Taec: a Manually annotated text dataset for trait and phenotype extraction and entity linking in wheat breeding literature",
    "authors": [
      "Claire Nédellec",
      "Clara Sauvion",
      "Robert Bossy",
      "Mariya Borovikova",
      "Louise Deléger"
    ],
    "abstract": "Wheat varieties show a large diversity of traits and phenotypes. Linking them\nto genetic variability is essential for shorter and more efficient wheat\nbreeding programs. Newly desirable wheat variety traits include disease\nresistance to reduce pesticide use, adaptation to climate change, resistance to\nheat and drought stresses, or low gluten content of grains. Wheat breeding\nexperiments are documented by a large body of scientific literature and\nobservational data obtained in-field and under controlled conditions. The\ncross-referencing of complementary information from the literature and\nobservational data is essential to the study of the genotype-phenotype\nrelationship and to the improvement of wheat selection. The scientific\nliterature on genetic marker-assisted selection describes much information\nabout the genotype-phenotype relationship. However, the variety of expressions\nused to refer to traits and phenotype values in scientific articles is a hinder\nto finding information and cross-referencing it. When trained adequately by\nannotated examples, recent text mining methods perform highly in named entity\nrecognition and linking in the scientific domain. While several corpora contain\nannotations of human and animal phenotypes, currently, no corpus is available\nfor training and evaluating named entity recognition and entity-linking methods\nin plant phenotype literature. The Triticum aestivum trait Corpus is a new gold\nstandard for traits and phenotypes of wheat. It consists of 540 PubMed\nreferences fully annotated for trait, phenotype, and species named entities\nusing the Wheat Trait and Phenotype Ontology and the species taxonomy of the\nNational Center for Biotechnology Information. A study of the performance of\ntools trained on the Triticum aestivum trait Corpus shows that the corpus is\nsuitable for the training and evaluation of named entity recognition and\nlinking.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.07447v1",
    "published_date": "2024-01-15 03:23:24 UTC",
    "updated_date": "2024-01-15 03:23:24 UTC"
  },
  {
    "arxiv_id": "2401.07445v1",
    "title": "GACE: Learning Graph-Based Cross-Page Ads Embedding For Click-Through Rate Prediction",
    "authors": [
      "Haowen Wang",
      "Yuliang Du",
      "Congyun Jin",
      "Yujiao Li",
      "Yingbo Wang",
      "Tao Sun",
      "Piqi Qin",
      "Cong Fan"
    ],
    "abstract": "Predicting click-through rate (CTR) is the core task of many ads online\nrecommendation systems, which helps improve user experience and increase\nplatform revenue. In this type of recommendation system, we often encounter two\nmain problems: the joint usage of multi-page historical advertising data and\nthe cold start of new ads. In this paper, we proposed GACE, a graph-based\ncross-page ads embedding generation method. It can warm up and generate the\nrepresentation embedding of cold-start and existing ads across various pages.\nSpecifically, we carefully build linkages and a weighted undirected graph model\nconsidering semantic and page-type attributes to guide the direction of feature\nfusion and generation. We designed a variational auto-encoding task as\npre-training module and generated embedding representations for new and old ads\nbased on this task. The results evaluated in the public dataset AliEC from\nRecBole and the real-world industry dataset from Alipay show that our GACE\nmethod is significantly superior to the SOTA method. In the online A/B test,\nthe click-through rate on three real-world pages from Alipay has increased by\n3.6%, 2.13%, and 3.02%, respectively. Especially in the cold-start task, the\nCTR increased by 9.96%, 7.51%, and 8.97%, respectively.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.IR",
    "comment": "15 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.07445v1",
    "published_date": "2024-01-15 03:12:21 UTC",
    "updated_date": "2024-01-15 03:12:21 UTC"
  },
  {
    "arxiv_id": "2401.07426v1",
    "title": "Generalized Planning for the Abstraction and Reasoning Corpus",
    "authors": [
      "Chao Lei",
      "Nir Lipovetzky",
      "Krista A. Ehinger"
    ],
    "abstract": "The Abstraction and Reasoning Corpus (ARC) is a general artificial\nintelligence benchmark that poses difficulties for pure machine learning\nmethods due to its requirement for fluid intelligence with a focus on reasoning\nand abstraction. In this work, we introduce an ARC solver, Generalized Planning\nfor Abstract Reasoning (GPAR). It casts an ARC problem as a generalized\nplanning (GP) problem, where a solution is formalized as a planning program\nwith pointers. We express each ARC problem using the standard Planning Domain\nDefinition Language (PDDL) coupled with external functions representing\nobject-centric abstractions. We show how to scale up GP solvers via domain\nknowledge specific to ARC in the form of restrictions over the actions model,\npredicates, arguments and valid structure of planning programs. Our experiments\ndemonstrate that GPAR outperforms the state-of-the-art solvers on the\nobject-centric tasks of the ARC, showing the effectiveness of GP and the\nexpressiveness of PDDL to model ARC problems. The challenges provided by the\nARC benchmark motivate research to advance existing GP solvers and understand\nnew relations with other planning computational models. Code is available at\ngithub.com/you68681/GPAR.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at AAAI 2024 (extended version)",
    "pdf_url": "http://arxiv.org/pdf/2401.07426v1",
    "published_date": "2024-01-15 02:25:00 UTC",
    "updated_date": "2024-01-15 02:25:00 UTC"
  },
  {
    "arxiv_id": "2401.07395v1",
    "title": "Harnessing the Power of Beta Scoring in Deep Active Learning for Multi-Label Text Classification",
    "authors": [
      "Wei Tan",
      "Ngoc Dang Nguyen",
      "Lan Du",
      "Wray Buntine"
    ],
    "abstract": "Within the scope of natural language processing, the domain of multi-label\ntext classification is uniquely challenging due to its expansive and uneven\nlabel distribution. The complexity deepens due to the demand for an extensive\nset of annotated data for training an advanced deep learning model, especially\nin specialized fields where the labeling task can be labor-intensive and often\nrequires domain-specific knowledge. Addressing these challenges, our study\nintroduces a novel deep active learning strategy, capitalizing on the Beta\nfamily of proper scoring rules within the Expected Loss Reduction framework. It\ncomputes the expected increase in scores using the Beta Scoring Rules, which\nare then transformed into sample vector representations. These vector\nrepresentations guide the diverse selection of informative samples, directly\nlinking this process to the model's expected proper score. Comprehensive\nevaluations across both synthetic and real datasets reveal our method's\ncapability to often outperform established acquisition techniques in\nmulti-label text classification, presenting encouraging outcomes across various\narchitectural and dataset scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.07395v1",
    "published_date": "2024-01-15 00:06:24 UTC",
    "updated_date": "2024-01-15 00:06:24 UTC"
  }
]