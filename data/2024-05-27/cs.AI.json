{
  "date": "2024-05-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-27 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，包括强化学习、Large Language Models（LLM）优化、多模态模型、图神经网络和量子计算等话题，其中令人印象深刻的是像 Emma Brunskill 等知名学者参与的离线强化学习方法，以及高效的多模态生成模型如 GaussianFormer 和 NV-Embed，这些论文展示了 AI 在高效决策和跨模态任务中的潜力。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论那些重要、话题性强或涉及知名学者的文章（如强化学习和 LLM 相关），并快速掠过其他较常规的论文。每个条目会列出论文标题（中文 + 英文），并清晰描述主要贡献和发现，控制在简短描述中。\n\n### 强化学习和决策相关\n- **OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates of Multiple Estimators**（中文：OPERA：使用加权聚合的多估算器自动离线策略评估）  \n  这篇论文由 Emma Brunskill 等作者提出，主要贡献是通过自适应混合估算器实现一致的离线强化学习（Offline RL）评估，证明了其在医疗和机器人领域能选择更高性能策略，显著提升了通用离线 RL 的易用性和鲁棒性。\n\n- **BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments**（中文：BioDiscoveryAgent：用于设计遗传扰动实验的 AI 代理）  \n  Jure Leskovec 等参与的研究，利用 LLM 构建代理来设计遗传实验，主要发现是通过强化学习和工具交互，代理在预测基因扰动方面比传统贝叶斯优化方法提升 21%，并在真实数据集上表现出色，推动了生物计算实验的设计效率。\n\n- **Reinforcement Learning Based Escape Route Generation in Low Visibility Environments**（中文：基于强化学习的低能见度环境逃生路线生成）  \n  这篇论文提出使用强化学习生成火灾中的逃生路径，主要贡献是通过 LiDAR 和环境张量建模，实现比复杂算法更鲁棒的路径规划，适用于紧急响应场景。\n\n- **Ontology-Enhanced Decision-Making for Autonomous Agents in Dynamic and Partially Observable Environments**（中文：本体增强的自治代理在动态部分可观察环境中的决策）  \n  这篇博士论文的主要发现是，通过本体知识提升代理的实时观察和决策能力，在四个真实应用中超越传统 RL，强调了本体在处理不确定性的作用。\n\n其他强化学习论文如 Symmetric Reinforcement Learning Loss 等，则快速掠过：它们探索了损失函数改进 RL 鲁棒性，但贡献相对常规，未见重大突破。\n\n### LLM 和多模态模型优化\n- **TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial Robustness and Generalization Ability**（中文：TIMA：平衡零样本对抗鲁棒性和泛化能力的文本-图像互觉模型）  \n  这篇论文提出 TIMA 方法，通过文本和图像双向调整提升 CLIP 模型的鲁棒性，主要发现是在大扰动下显著改善零样本性能，同时保留泛化能力。\n\n- **NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models**（中文：NV-Embed：训练 LLM 作为通用嵌入模型的改进技术）  \n  作者优化了 LLM 的训练策略，主要贡献是通过两阶段对比学习和数据增强，在 MTEB 基准上排名第一，提升了文本嵌入的泛化性和效率。\n\n- **LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters**（中文：LoRA-XS：使用极少参数的低秩适配）  \n  这篇论文扩展了 LoRA 方法，主要发现是大幅减少参数（比 LoRA 减少 100 倍）同时保持性能，在各种基准上与 LoRA 相当或更好，适用于高效 LLM 微调。\n\n其他 LLM 论文如 ReflectionCoder 和 Prompt Optimization 等，则简要提到：它们通过反馈机制提升代码生成和提示优化，但未涉及核心创新。\n\n### 计算机视觉和图像处理\n- **GaussianFormer: Scene as Gaussians for Vision-Based 3D Semantic Occupancy Prediction**（中文：GaussianFormer：基于高斯表示的视觉3D语义占用预测）  \n  这篇论文使用高斯表示改进 3D 场景预测，主要贡献是高效融合图像信息，实现内存消耗更低的语义占用预测，在 nuScenes 数据集上表现出色。\n\n- **InversionView: A General-Purpose Method for Reading Information from Neural Activations**（中文：InversionView：从神经激活中读取信息的通用方法）  \n  这篇论文提出逆向查看技术，主要发现是通过解码器采样揭示神经网络的内部信息，包括复杂计数和位置知识，对解释 Transformer 模型有重要启发。\n\n其他视觉论文如 TIMA 和 Matryoshka Multimodal Models 等，快速掠过：它们优化多模态表示，但焦点在特定任务上，整体影响有限。\n\n### 其他领域快速掠过\n- 量子计算论文如 Utilising a Quantum Hybrid Solver（中文：利用量子混合求解器解决双目标二次分配问题），主要贡献是探索量子求解器在优化问题中的效率，但主题较 niche，仅供专业领域参考。\n- 图神经网络论文如 FUGNN（中文：FUGNN：在图神经网络中协调公平性和效用），提出谱图方法提升公平性，但与其他论文相比，影响力较小。\n- 音频和多模态论文如 Video Enriched Retrieval Augmented Generation（中文：使用对齐视频字幕增强检索生成），主要发现是改善 RAG 系统，但实验规模有限。\n\n今天的论文总体上强调 AI 的高效性和鲁棒性，强化学习和 LLM 领域尤为活跃。如果你对特定主题感兴趣，如离线 RL 或多模态模型，可以关注 OPERA 和 GaussianFormer 等论文。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2405.17708v2",
      "title": "OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates of Multiple Estimators",
      "title_zh": "翻译失败",
      "authors": [
        "Allen Nie",
        "Yash Chandak",
        "Christina J. Yuan",
        "Anirudhan Badrinath",
        "Yannis Flet-Berliac",
        "Emma Brunskil"
      ],
      "abstract": "Offline policy evaluation (OPE) allows us to evaluate and estimate a new\nsequential decision-making policy's performance by leveraging historical\ninteraction data collected from other policies. Evaluating a new policy online\nwithout a confident estimate of its performance can lead to costly, unsafe, or\nhazardous outcomes, especially in education and healthcare. Several OPE\nestimators have been proposed in the last decade, many of which have\nhyperparameters and require training. Unfortunately, choosing the best OPE\nalgorithm for each task and domain is still unclear. In this paper, we propose\na new algorithm that adaptively blends a set of OPE estimators given a dataset\nwithout relying on an explicit selection using a statistical procedure. We\nprove that our estimator is consistent and satisfies several desirable\nproperties for policy evaluation. Additionally, we demonstrate that when\ncompared to alternative approaches, our estimator can be used to select\nhigher-performing policies in healthcare and robotics. Our work contributes to\nimproving ease of use for a general-purpose, estimator-agnostic, off-policy\nevaluation framework for offline RL.",
      "tldr_zh": "本论文提出OPERA算法，用于自动离线策略评估（OPE），通过再加权聚合（re-weighted aggregates）的方法自适应混合多个估计器，从而在不依赖显式选择的条件下评估新策略的性能，避免在线测试带来的风险，如在教育和医疗领域的潜在危害。OPERA被证明具有一致性（consistent）和其他理想属性，并在实验中显示出在医疗和机器人应用中能选择更高性能的策略。总体上，该工作为离线强化学习（Offline RL）提供了一个通用、估计器无关的评估框架，提升了实际应用的易用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.17708v2",
      "published_date": "2024-05-27 23:51:20 UTC",
      "updated_date": "2024-10-31 23:40:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:19:24.297921"
    },
    {
      "arxiv_id": "2405.17706v1",
      "title": "Video Enriched Retrieval Augmented Generation Using Aligned Video Captions",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Dela Rosa"
      ],
      "abstract": "In this work, we propose the use of \"aligned visual captions\" as a mechanism\nfor integrating information contained within videos into retrieval augmented\ngeneration (RAG) based chat assistant systems. These captions are able to\ndescribe the visual and audio content of videos in a large corpus while having\nthe advantage of being in a textual format that is both easy to reason about &\nincorporate into large language model (LLM) prompts, but also typically require\nless multimedia content to be inserted into the multimodal LLM context window,\nwhere typical configurations can aggressively fill up the context window by\nsampling video frames from the source video. Furthermore, visual captions can\nbe adapted to specific use cases by prompting the original foundational model /\ncaptioner for particular visual details or fine tuning. In hopes of helping\nadvancing progress in this area, we curate a dataset and describe automatic\nevaluation procedures on common RAG tasks.",
      "tldr_zh": "本研究提出了一种使用“aligned visual captions”的方法，来增强Retrieval Augmented Generation (RAG) 基于的聊天助手系统，从而整合视频中的视觉和音频信息。这些captions以文本格式描述视频内容，便于Large Language Model (LLM) 处理，同时减少了对多模态LLM上下文窗口的占用，并允许根据特定用例进行自定义或微调。为推进该领域，论文整理了一个数据集并描述了自动评估程序，以支持常见RAG任务的测试。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "SIGIR 2024 Workshop on Multimodal Representation and Retrieval (MRR\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.17706v1",
      "published_date": "2024-05-27 23:39:17 UTC",
      "updated_date": "2024-05-27 23:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:19:35.343697"
    },
    {
      "arxiv_id": "2406.07568v1",
      "title": "Reinforcement Learning Based Escape Route Generation in Low Visibility Environments",
      "title_zh": "基于强化学习的低能见度环境逃生路线生成",
      "authors": [
        "Hari Srikanth"
      ],
      "abstract": "Structure fires are responsible for the majority of fire-related deaths\nnationwide. In order to assist with the rapid evacuation of trapped people,\nthis paper proposes the use of a system that determines optimal search paths\nfor firefighters and exit paths for civilians in real time based on\nenvironmental measurements. Through the use of a LiDAR mapping system evaluated\nand verified by a trust range derived from sonar and smoke concentration data,\na proposed solution to low visibility mapping is tested. These independent\npoint clouds are then used to create distinct maps, which are merged through\nthe use of a RANSAC based alignment methodology and simplified into a\nvisibility graph. Temperature and humidity data are then used to label each\nnode with a danger score, creating an environment tensor. After demonstrating\nhow a Linear Function Approximation based Natural Policy Gradient RL\nmethodology outperforms more complex competitors with respect to robustness and\nspeed, this paper outlines two systems (savior and refugee) that process the\nenvironment tensor to create safe rescue and escape routes, respectively.",
      "tldr_zh": "这篇论文针对结构火灾中低能见度环境下的逃生路径生成，提出了一种基于 Reinforcement Learning 的实时系统，用于确定消防员的最佳搜索路径（savior 系统）和平民的出口路径（refugee 系统）。系统利用 LiDAR 映射结合声呐和烟雾浓度数据进行验证，并通过 RANSAC 基于的对齐方法合并点云地图，生成简化后的可见性图。接着，使用温度和湿度数据为节点标注危险分数，形成环境张量。实验结果表明，Linear Function Approximation based Natural Policy Gradient RL 方法在鲁棒性和速度上优于复杂竞争者，从而提升了火灾救援和逃生的安全性和效率。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07568v1",
      "published_date": "2024-05-27 23:00:57 UTC",
      "updated_date": "2024-05-27 23:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:19:49.466858"
    },
    {
      "arxiv_id": "2405.17691v1",
      "title": "Ontology-Enhanced Decision-Making for Autonomous Agents in Dynamic and Partially Observable Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Saeedeh Ghanadbashi",
        "Fatemeh Golpayegani"
      ],
      "abstract": "Agents, whether software or hardware, perceive their environment through\nsensors and act using actuators, often operating in dynamic, partially\nobservable settings. They face challenges like incomplete and noisy data,\nunforeseen situations, and the need to adapt goals in real-time. Traditional\nreasoning and ML methods, including Reinforcement Learning (RL), help but are\nlimited by data needs, predefined goals, and extensive exploration periods.\nOntologies offer a solution by integrating diverse information sources,\nenhancing decision-making in complex environments. This thesis introduces an\nontology-enhanced decision-making model (OntoDeM) for autonomous agents.\nOntoDeM enriches agents' domain knowledge, allowing them to interpret\nunforeseen events, generate or adapt goals, and make better decisions. Key\ncontributions include: 1. An ontology-based method to improve agents' real-time\nobservations using prior knowledge. 2. The OntoDeM model for handling dynamic,\nunforeseen situations by evolving or generating new goals. 3. Implementation\nand evaluation in four real-world applications, demonstrating its\neffectiveness. Compared to traditional and advanced learning algorithms,\nOntoDeM shows superior performance in improving agents' observations and\ndecision-making in dynamic, partially observable environments.",
      "tldr_zh": "本研究探讨了自主代理在动态、部分可观察环境中面临的挑战，如不完整嘈杂数据和实时目标适应问题，并提出本体论增强决策模型（OntoDeM）作为解决方案。OntoDeM 通过整合本体论（Ontologies）来丰富代理的领域知识，提升对实时观察的解释能力，并允许代理处理意外情况、演化或生成新目标。关键贡献包括一种基于本体论的方法改进代理观察、一个动态决策框架，以及在四个真实世界应用中的实施，相比传统和高级学习算法如 Reinforcement Learning (RL)，OntoDeM 显示出显著提高代理观察和决策性能的优势。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2405.17691v1",
      "published_date": "2024-05-27 22:52:23 UTC",
      "updated_date": "2024-05-27 22:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:19:59.382762"
    },
    {
      "arxiv_id": "2405.17678v1",
      "title": "TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial Robustness and Generalization Ability",
      "title_zh": "翻译失败",
      "authors": [
        "Fengji Ma",
        "Li Liu",
        "Hei Victor Cheng"
      ],
      "abstract": "This work addresses the challenge of achieving zero-shot adversarial\nrobustness while preserving zero-shot generalization in large-scale foundation\nmodels, with a focus on the popular Contrastive Language-Image Pre-training\n(CLIP). Although foundation models were reported to have exceptional zero-shot\ngeneralization, they are highly vulnerable to adversarial perturbations.\nExisting methods achieve a comparable good tradeoff between zero-shot\nadversarial robustness and generalization under small adversarial\nperturbations. However, they fail to achieve a good tradeoff under large\nadversarial perturbations. To this end, we propose a novel Text-Image Mutual\nAwareness (TIMA) method that strikes a balance between zero-shot adversarial\nrobustness and generalization. More precisely, we propose an Image-Aware Text\n(IAT) tuning mechanism that increases the inter-class distance of text\nembeddings by incorporating the Minimum Hyperspherical Energy (MHE).\nSimultaneously, fixed pre-trained image embeddings are used as cross-modal\nauxiliary supervision to maintain the similarity between the MHE-tuned and\noriginal text embeddings by the knowledge distillation, preserving semantic\ninformation between different classes. Besides, we introduce a Text-Aware Image\n(TAI) tuning mechanism, which increases inter-class distance between image\nembeddings during the training stage by Text-distance based Adaptive Margin\n(TAM). Similarly, a knowledge distillation is utilized to retain the similarity\nbetween fine-tuned and pre-trained image embeddings. Extensive experimental\nresults demonstrate the effectiveness of our approach, showing impressive\nzero-shot performance against a wide range of adversarial perturbations while\npreserving the zero-shot generalization capabilities of the original CLIP\nmodel.",
      "tldr_zh": "这篇论文提出 TIMA（Text-Image Mutual Awareness）方法，旨在平衡大型基础模型如 CLIP 的零样本对抗鲁棒性（Zero-Shot Adversarial Robustness）和泛化能力（Generalization Ability），解决现有方法在大扰动下失效的问题。TIMA 包括 Image-Aware Text (IAT) 机制，通过 Minimum Hyperspherical Energy (MHE) 增加文本嵌入的类间距离，并利用知识蒸馏保持与原始嵌入的相似性；同时，Text-Aware Image (TAI) 机制使用 Text-distance based Adaptive Margin (TAM) 增强图像嵌入的类间距离，并通过知识蒸馏保留语义信息。实验结果表明，TIMA 在广泛对抗扰动下表现出色，同时维持了原 CLIP 模型的零样本泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17678v1",
      "published_date": "2024-05-27 22:10:17 UTC",
      "updated_date": "2024-05-27 22:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:20:13.554862"
    },
    {
      "arxiv_id": "2405.17676v1",
      "title": "Utilising a Quantum Hybrid Solver for Bi-objective Quadratic Assignment Problems",
      "title_zh": "利用量子混合求解",
      "authors": [
        "Mayowa Ayodele"
      ],
      "abstract": "The intersection between quantum computing and optimisation has been an area\nof interest in recent years. There have been numerous studies exploring the\napplication of quantum and quantum-hybrid solvers to various optimisation\nproblems. This work explores scalarisation methods within the context of\nsolving the bi-objective quadratic assignment problem using a quantum-hybrid\nsolver. We show results that are consistent with previous research on a\ndifferent Ising machine.",
      "tldr_zh": "这篇论文探讨了量子计算在优化问题中的应用，特别聚焦于使用量子混合求解器（Quantum Hybrid Solver）解决双目标二次分配问题（Bi-objective Quadratic Assignment Problems）。研究者考察了标量化方法（Scalarisation Methods）在这一情境下的有效性，通过实验验证了结果与之前在不同 Ising Machine 上的研究一致。总体而言，该工作强化了量子混合技术在多目标优化领域的潜力，为未来应用提供了参考。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "G.1.6"
      ],
      "primary_category": "quant-ph",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.17676v1",
      "published_date": "2024-05-27 22:03:26 UTC",
      "updated_date": "2024-05-27 22:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:20:22.988059"
    },
    {
      "arxiv_id": "2405.17672v1",
      "title": "Exploring Loss Design Techniques For Decision Tree Robustness To Label Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Lukasz Sztukiewicz",
        "Jack Henry Good",
        "Artur Dubrawski"
      ],
      "abstract": "In the real world, data is often noisy, affecting not only the quality of\nfeatures but also the accuracy of labels. Current research on mitigating label\nerrors stems primarily from advances in deep learning, and a gap exists in\nexploring interpretable models, particularly those rooted in decision trees. In\nthis study, we investigate whether ideas from deep learning loss design can be\napplied to improve the robustness of decision trees. In particular, we show\nthat loss correction and symmetric losses, both standard approaches, are not\neffective. We argue that other directions need to be explored to improve the\nrobustness of decision trees to label noise.",
      "tldr_zh": "本研究探讨了如何通过损失设计技术提升决策树(Decision Tree)对标签噪声(Label Noise)的鲁棒性，旨在将深度学习的损失设计理念应用到可解释模型中。研究者测试了损失校正和对称损失等标准方法，但发现这些方法对决策树的鲁棒性改善无效。作者强调，需要探索其他方向来增强决策树在真实噪声数据环境下的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17672v1",
      "published_date": "2024-05-27 21:49:57 UTC",
      "updated_date": "2024-05-27 21:49:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:20:35.066886"
    },
    {
      "arxiv_id": "2406.07567v1",
      "title": "A GRASP-based memetic algorithm with path relinking for the far from most string problem",
      "title_zh": "翻译失败",
      "authors": [
        "José E. Gallardo",
        "Carlos Cotta"
      ],
      "abstract": "The FAR FROM MOST STRING PROBLEM (FFMSP) is a string selection problem. The\nobjective is to find a string whose distance to other strings in a certain\ninput set is above a given threshold for as many of those strings as possible.\nThis problem has links with some tasks in computational biology and its\nresolution has been shown to be very hard. We propose a memetic algorithm (MA)\nto tackle the FFMSP. This MA exploits a heuristic objective function for the\nproblem and features initialization of the population via a Greedy Randomized\nAdaptive Search Procedure (GRASP) metaheuristic, intensive recombination via\npath relinking and local improvement via hill climbing. An extensive empirical\nevaluation using problem instances of both random and biological origin is done\nto assess parameter sensitivity and draw performance comparisons with other\nstate-of-the-art techniques. The MA is shown to perform better than these\nlatter techniques with statistical significance.",
      "tldr_zh": "该论文针对 FAR FROM MOST STRING PROBLEM (FFMSP) 提出了一种基于 GRASP 的 memetic algorithm，以最大化一个字符串与输入集合中其他字符串的距离超过给定阈值。算法通过 GRASP 进行种群初始化、path relinking 实现密集重组，以及 hill climbing 优化局部改进，利用启发式目标函数提升效率。实验评估显示，该算法在随机和生物来源的实例上，性能显著优于现有最先进技术，具有统计显著性。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07567v1",
      "published_date": "2024-05-27 21:33:15 UTC",
      "updated_date": "2024-05-27 21:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:20:48.199077"
    },
    {
      "arxiv_id": "2405.17653v4",
      "title": "InversionView: A General-Purpose Method for Reading Information from Neural Activations",
      "title_zh": "翻译失败",
      "authors": [
        "Xinting Huang",
        "Madhur Panwar",
        "Navin Goyal",
        "Michael Hahn"
      ],
      "abstract": "The inner workings of neural networks can be better understood if we can\nfully decipher the information encoded in neural activations. In this paper, we\nargue that this information is embodied by the subset of inputs that give rise\nto similar activations. We propose InversionView, which allows us to\npractically inspect this subset by sampling from a trained decoder model\nconditioned on activations. This helps uncover the information content of\nactivation vectors, and facilitates understanding of the algorithms implemented\nby transformer models. We present four case studies where we investigate models\nranging from small transformers to GPT-2. In these studies, we show that\nInversionView can reveal clear information contained in activations, including\nbasic information about tokens appearing in the context, as well as more\ncomplex information, such as the count of certain tokens, their relative\npositions, and abstract knowledge about the subject. We also provide causally\nverified circuits to confirm the decoded information.",
      "tldr_zh": "本论文提出了一种通用方法 InversionView，用于从神经激活中读取和理解编码的信息，该方法通过训练解码器模型从激活向量中采样，检查产生类似激活的输入子集，从而揭示神经网络的内部工作机制。研究在小型变压器模型到 GPT-2 等模型上进行案例分析，发现激活中包含了基础信息（如上下文中的令牌）和复杂信息（如令牌计数、相对位置以及抽象知识）。此外，论文提供了因果验证电路来确认这些解码信息，确保方法的可靠性和解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024; ICML 2024 Mechanistic Interpretability Workshop oral",
      "pdf_url": "http://arxiv.org/pdf/2405.17653v4",
      "published_date": "2024-05-27 20:53:22 UTC",
      "updated_date": "2024-11-02 19:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:20:59.328725"
    },
    {
      "arxiv_id": "2405.17642v1",
      "title": "Unifying Perspectives: Plausible Counterfactual Explanations on Global, Group-wise, and Local Levels",
      "title_zh": "统一视角",
      "authors": [
        "Patryk Wielopolski",
        "Oleksii Furman",
        "Jerzy Stefanowski",
        "Maciej Zięba"
      ],
      "abstract": "Growing regulatory and societal pressures demand increased transparency in\nAI, particularly in understanding the decisions made by complex machine\nlearning models. Counterfactual Explanations (CFs) have emerged as a promising\ntechnique within Explainable AI (xAI), offering insights into individual model\npredictions. However, to understand the systemic biases and disparate impacts\nof AI models, it is crucial to move beyond local CFs and embrace global\nexplanations, which offer a~holistic view across diverse scenarios and\npopulations. Unfortunately, generating Global Counterfactual Explanations\n(GCEs) faces challenges in computational complexity, defining the scope of\n\"global,\" and ensuring the explanations are both globally representative and\nlocally plausible. We introduce a novel unified approach for generating Local,\nGroup-wise, and Global Counterfactual Explanations for differentiable\nclassification models via gradient-based optimization to address these\nchallenges. This framework aims to bridge the gap between individual and\nsystemic insights, enabling a deeper understanding of model decisions and their\npotential impact on diverse populations. Our approach further innovates by\nincorporating a probabilistic plausibility criterion, enhancing actionability\nand trustworthiness. By offering a cohesive solution to the optimization and\nplausibility challenges in GCEs, our work significantly advances the\ninterpretability and accountability of AI models, marking a step forward in the\npursuit of transparent AI.",
      "tldr_zh": "该论文针对AI决策透明性的需求，提出了一种统一框架，用于生成局部、组级和全局Counterfactual Explanations (CFs)，以揭示复杂机器学习模型的系统偏见和不均等影响。该方法通过基于梯度的优化技术，为可微分类模型生成这些解释，解决了Global Counterfactual Explanations (GCEs)的计算复杂性、范围定义和合理性挑战。同时，该框架创新性地引入了probabilistic plausibility criterion，提升了解释的可行动性和可信度。总体上，此工作桥接了个体与系统洞见，显著推进了Explainable AI (xAI)的可解释性和AI系统的责任性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17642v1",
      "published_date": "2024-05-27 20:32:09 UTC",
      "updated_date": "2024-05-27 20:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:21:13.076337"
    },
    {
      "arxiv_id": "2405.17640v2",
      "title": "Probabilistically Plausible Counterfactual Explanations with Normalizing Flows",
      "title_zh": "翻译失败",
      "authors": [
        "Patryk Wielopolski",
        "Oleksii Furman",
        "Jerzy Stefanowski",
        "Maciej Zięba"
      ],
      "abstract": "We present PPCEF, a novel method for generating probabilistically plausible\ncounterfactual explanations (CFs). PPCEF advances beyond existing methods by\ncombining a probabilistic formulation that leverages the data distribution with\nthe optimization of plausibility within a unified framework. Compared to\nreference approaches, our method enforces plausibility by directly optimizing\nthe explicit density function without assuming a particular family of\nparametrized distributions. This ensures CFs are not only valid (i.e., achieve\nclass change) but also align with the underlying data's probability density.\nFor that purpose, our approach leverages normalizing flows as powerful density\nestimators to capture the complex high-dimensional data distribution.\nFurthermore, we introduce a novel loss that balances the trade-off between\nachieving class change and maintaining closeness to the original instance while\nalso incorporating a probabilistic plausibility term. PPCEF's unconstrained\nformulation allows for efficient gradient-based optimization with batch\nprocessing, leading to orders of magnitude faster computation compared to prior\nmethods. Moreover, the unconstrained formulation of PPCEF allows for the\nseamless integration of future constraints tailored to specific counterfactual\nproperties. Finally, extensive evaluations demonstrate PPCEF's superiority in\ngenerating high-quality, probabilistically plausible counterfactual\nexplanations in high-dimensional tabular settings. This makes PPCEF a powerful\ntool for not only interpreting complex machine learning models but also for\nimproving fairness, accountability, and trust in AI systems.",
      "tldr_zh": "我们介绍了 PPCEF，一种新型方法，用于生成概率上可信的反事实解释（Counterfactual Explanations, CFs），它通过结合概率公式和优化框架，确保 CFs 不仅实现类别改变，还与数据分布一致。PPCEF 利用 Normalizing Flows 作为密度估计器来捕捉复杂的高维数据分布，并引入一个新损失函数来平衡类别改变、与原实例的接近度以及概率可信度。该方法的无约束公式支持高效的梯度优化和批量处理，比现有方法快几个数量级，并在高维表格设置中的评估中表现出优越性能，从而提升机器学习模型的可解释性、公平性和 AI 系统的信任。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17640v2",
      "published_date": "2024-05-27 20:24:03 UTC",
      "updated_date": "2024-08-07 07:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:21:26.169975"
    },
    {
      "arxiv_id": "2405.17638v3",
      "title": "The surprising efficiency of temporal difference learning for rare event prediction",
      "title_zh": "时间差学习在稀有事件预测中的惊人效率",
      "authors": [
        "Xiaoou Cheng",
        "Jonathan Weare"
      ],
      "abstract": "We quantify the efficiency of temporal difference (TD) learning over the\ndirect, or Monte Carlo (MC), estimator for policy evaluation in reinforcement\nlearning, with an emphasis on estimation of quantities related to rare events.\nPolicy evaluation is complicated in the rare event setting by the long\ntimescale of the event and by the need for \\emph{relative accuracy} in\nestimates of very small values. Specifically, we focus on least-squares TD\n(LSTD) prediction for finite state Markov chains, and show that LSTD can\nachieve relative accuracy far more efficiently than MC. We prove a central\nlimit theorem for the LSTD estimator and upper bound the \\emph{relative\nasymptotic variance} by simple quantities characterizing the connectivity of\nstates relative to the transition probabilities between them. Using this bound,\nwe show that, even when both the timescale of the rare event and the relative\naccuracy of the MC estimator are exponentially large in the number of states,\nLSTD maintains a fixed level of relative accuracy with a total number of\nobserved transitions of the Markov chain that is only \\emph{polynomially} large\nin the number of states.",
      "tldr_zh": "本文研究了 Temporal Difference (TD) 学习与 Monte Carlo (MC) 估计器在强化学习中评估稀有事件预测的效率，强调 TD 学习在处理事件时间长和相对准确性需求时的优势。重点分析了 Least-Squares TD (LSTD) 在有限状态 Markov 链中的预测表现，证明 LSTD 估计器通过中心极限定理和相对渐近方差的上界，能比 MC 更高效地实现准确估计。研究发现，即使 MC 估计需要指数级样本来处理稀有事件，LSTD 仅需多项式级的观察样本即可维持固定相对准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Final camera-ready version published at NeurIPS 2024. Correct an\n  assumption statement and typos, and change/add a few sentences from the last\n  version",
      "pdf_url": "http://arxiv.org/pdf/2405.17638v3",
      "published_date": "2024-05-27 20:18:20 UTC",
      "updated_date": "2025-01-16 04:11:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:21:48.604294"
    },
    {
      "arxiv_id": "2405.17637v1",
      "title": "The Economic Implications of Large Language Model Selection on Earnings and Return on Investment: A Decision Theoretic Model",
      "title_zh": "大型语言模型选择对收益和投资回报的经济影响：一个决策理论模型",
      "authors": [
        "Geraldo Xexéo",
        "Filipe Braida",
        "Marcus Parreiras",
        "Paulo Xavier"
      ],
      "abstract": "Selecting language models in business contexts requires a careful analysis of\nthe final financial benefits of the investment. However, the emphasis of\nacademia and industry analysis of LLM is solely on performance. This work\nintroduces a framework to evaluate LLMs, focusing on the earnings and return on\ninvestment aspects that should be taken into account in business decision\nmaking. We use a decision-theoretic approach to compare the financial impact of\ndifferent LLMs, considering variables such as the cost per token, the\nprobability of success in the specific task, and the gain and losses associated\nwith LLMs use. The study reveals how the superior accuracy of more expensive\nmodels can, under certain conditions, justify a greater investment through more\nsignificant earnings but not necessarily a larger RoI. This article provides a\nframework for companies looking to optimize their technology choices, ensuring\nthat investment in cutting-edge technology aligns with strategic financial\nobjectives. In addition, we discuss how changes in operational variables\ninfluence the economics of using LLMs, offering practical insights for\nenterprise settings, finding that the predicted gain and loss and the different\nprobabilities of success and failure are the variables that most impact the\nsensitivity of the models.",
      "tldr_zh": "该论文引入了一个基于决策理论的框架，用于评估大型语言模型（LLMs）在商业决策中的经济影响，重点关注收益和投资回报率（RoI）。框架通过考虑变量如成本每token、任务成功概率以及相关收益和损失，来比较不同LLMs的财务影响。研究发现，更昂贵的LLMs在特定条件下可能带来更大收益，但不一定实现更高的RoI。最终，该框架为企业优化技术选择提供实用指导，并强调成功/失败概率等操作变量对模型敏感性的关键作用。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "I.2.m; K.6.1"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.17637v1",
      "published_date": "2024-05-27 20:08:41 UTC",
      "updated_date": "2024-05-27 20:08:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:21:50.141693"
    },
    {
      "arxiv_id": "2405.17631v3",
      "title": "BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuf Roohani",
        "Andrew Lee",
        "Qian Huang",
        "Jian Vora",
        "Zachary Steinhart",
        "Kexin Huang",
        "Alexander Marson",
        "Percy Liang",
        "Jure Leskovec"
      ],
      "abstract": "Agents based on large language models have shown great potential in\naccelerating scientific discovery by leveraging their rich background knowledge\nand reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an\nagent that designs new experiments, reasons about their outcomes, and\nefficiently navigates the hypothesis space to reach desired solutions. We\ndemonstrate our agent on the problem of designing genetic perturbation\nexperiments, where the aim is to find a small subset out of many possible genes\nthat, when perturbed, result in a specific phenotype (e.g., cell growth).\nUtilizing its biological knowledge, BioDiscoveryAgent can uniquely design new\nexperiments without the need to train a machine learning model or explicitly\ndesign an acquisition function as in Bayesian optimization. Moreover,\nBioDiscoveryAgent, using Claude 3.5 Sonnet, achieves an average of 21%\nimprovement in predicting relevant genetic perturbations across six datasets,\nand a 46% improvement in the harder task of non-essential gene perturbation,\ncompared to existing Bayesian optimization baselines specifically trained for\nthis task. Our evaluation includes one dataset that is unpublished, ensuring it\nis not part of the language model's training data. Additionally,\nBioDiscoveryAgent predicts gene combinations to perturb more than twice as\naccurately as a random baseline, a task so far not explored in the context of\nclosed-loop experiment design. The agent also has access to tools for searching\nthe biomedical literature, executing code to analyze biological datasets, and\nprompting another agent to critically evaluate its predictions. Overall,\nBioDiscoveryAgent is interpretable at every stage, representing an accessible\nnew paradigm in the computational design of biological experiments with the\npotential to augment scientists' efficacy.",
      "tldr_zh": "本文介绍了 BioDiscoveryAgent，一种基于大型语言模型的 AI 代理，用于设计遗传扰动实验，帮助识别一小部分基因的扰动以实现特定表型，如细胞生长。代理利用生物知识和推理能力设计新实验，无需训练机器学习模型或显式设计 Bayesian optimization 获取函数。实验结果显示，使用 Claude 3.5 Sonnet 的代理在六个数据集上预测相关遗传扰动的准确率平均提高了 21%，在非必需基因扰动任务上提高了 46%，并在基因组合预测方面比随机基线准确率高两倍以上。该框架通过访问生物医学文献搜索、代码执行和评估工具，提供可解释的闭环实验设计范式，有潜力提升科学家的效率。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17631v3",
      "published_date": "2024-05-27 19:57:17 UTC",
      "updated_date": "2025-03-09 21:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:22:03.327502"
    },
    {
      "arxiv_id": "2405.17628v1",
      "title": "Tensor Low-rank Approximation of Finite-horizon Value Functions",
      "title_zh": "有限时域价值函数的张量低秩逼近",
      "authors": [
        "Sergio Rozada",
        "Antonio G. Marques"
      ],
      "abstract": "The goal of reinforcement learning is estimating a policy that maps states to\nactions and maximizes the cumulative reward of a Markov Decision Process (MDP).\nThis is oftentimes achieved by estimating first the optimal (reward) value\nfunction (VF) associated with each state-action pair. When the MDP has an\ninfinite horizon, the optimal VFs and policies are stationary under mild\nconditions. However, in finite-horizon MDPs, the VFs (hence, the policies) vary\nwith time. This poses a challenge since the number of VFs to estimate grows not\nonly with the size of the state-action space but also with the time horizon.\nThis paper proposes a non-parametric low-rank stochastic algorithm to\napproximate the VFs of finite-horizon MDPs. First, we represent the (unknown)\nVFs as a multi-dimensional array, or tensor, where time is one of the\ndimensions. Then, we use rewards sampled from the MDP to estimate the optimal\nVFs. More precisely, we use the (truncated) PARAFAC decomposition to design an\nonline low-rank algorithm that recovers the entries of the tensor of VFs. The\nsize of the low-rank PARAFAC model grows additively with respect to each of its\ndimensions, rendering our approach efficient, as demonstrated via numerical\nexperiments.",
      "tldr_zh": "本研究针对有限时域马尔可夫决策过程 (MDP) 中的价值函数 (VF) 估计问题，提出了一种非参数的低秩随机算法，以解决 VF 随时间变化导致的计算复杂度增加。算法将 VF 表示为一个多维张量，其中时间作为其中一个维度，并利用截断 PARAFAC 分解进行在线低秩逼近，从而高效恢复张量条目。该方法使模型大小仅随每个维度线性增长，并在数值实验中证明了其效率，为强化学习中的有限时域优化提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17628v1",
      "published_date": "2024-05-27 19:52:00 UTC",
      "updated_date": "2024-05-27 19:52:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:22:13.430498"
    },
    {
      "arxiv_id": "2405.17626v1",
      "title": "Matrix Low-Rank Approximation For Policy Gradient Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Rozada",
        "Antonio G. Marques"
      ],
      "abstract": "Estimating a policy that maps states to actions is a central problem in\nreinforcement learning. Traditionally, policies are inferred from the so called\nvalue functions (VFs), but exact VF computation suffers from the curse of\ndimensionality. Policy gradient (PG) methods bypass this by learning directly a\nparametric stochastic policy. Typically, the parameters of the policy are\nestimated using neural networks (NNs) tuned via stochastic gradient descent.\nHowever, finding adequate NN architectures can be challenging, and convergence\nissues are common as well. In this paper, we put forth low-rank matrix-based\nmodels to estimate efficiently the parameters of PG algorithms. We collect the\nparameters of the stochastic policy into a matrix, and then, we leverage\nmatrix-completion techniques to promote (enforce) low rank. We demonstrate via\nnumerical studies how low-rank matrix-based policy models reduce the\ncomputational and sample complexities relative to NN models, while achieving a\nsimilar aggregated reward.",
      "tldr_zh": "本论文针对强化学习中策略估计的挑战，提出使用低秩矩阵逼近（low-rank matrix approximation）来优化Policy Gradient (PG) 方法，以避免传统价值函数（value functions, VFs）计算的维度诅咒（curse of dimensionality）。具体而言，作者将策略参数组织成矩阵，并通过matrix-completion 技术强制低秩结构，从而直接学习参数化的随机策略。实验结果表明，与神经网络（NNs）模型相比，这种方法显著降低了计算和样本复杂度，同时实现了相似的总奖励（aggregated reward）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17626v1",
      "published_date": "2024-05-27 19:49:08 UTC",
      "updated_date": "2024-05-27 19:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:22:25.596445"
    },
    {
      "arxiv_id": "2405.17625v1",
      "title": "Matrix Low-Rank Trust Region Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Rozada",
        "Antonio G. Marques"
      ],
      "abstract": "Most methods in reinforcement learning use a Policy Gradient (PG) approach to\nlearn a parametric stochastic policy that maps states to actions. The standard\napproach is to implement such a mapping via a neural network (NN) whose\nparameters are optimized using stochastic gradient descent. However, PG methods\nare prone to large policy updates that can render learning inefficient. Trust\nregion algorithms, like Trust Region Policy Optimization (TRPO), constrain the\npolicy update step, ensuring monotonic improvements. This paper introduces\nlow-rank matrix-based models as an efficient alternative for estimating the\nparameters of TRPO algorithms. By gathering the stochastic policy's parameters\ninto a matrix and applying matrix-completion techniques, we promote and enforce\nlow rank. Our numerical studies demonstrate that low-rank matrix-based policy\nmodels effectively reduce both computational and sample complexities compared\nto NN models, while maintaining comparable aggregated rewards.",
      "tldr_zh": "本论文针对强化学习中的策略梯度(PG)方法，使用神经网络(NN)优化策略参数时容易导致效率低下的问题，引入了Trust Region Policy Optimization (TRPO)算法来约束政策更新以确保单调改进。作者提出了一种基于低秩矩阵模型的方法，将策略参数组织成矩阵并应用矩阵补全技术来强制低秩，从而提高参数估计效率。实验结果显示，与NN模型相比，这种方法显著降低了计算和样本复杂度，同时保持了可比的聚合奖励。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17625v1",
      "published_date": "2024-05-27 19:46:31 UTC",
      "updated_date": "2024-05-27 19:46:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:22:40.829811"
    },
    {
      "arxiv_id": "2405.17618v2",
      "title": "Symmetric Reinforcement Learning Loss for Robust Learning on Diverse Tasks and Model Scales",
      "title_zh": "对称强化学习损失用于多样任务和模型规模上的鲁棒学习",
      "authors": [
        "Ju-Seung Byun",
        "Andrew Perrault"
      ],
      "abstract": "Reinforcement learning (RL) training is inherently unstable due to factors\nsuch as moving targets and high gradient variance. Reinforcement Learning from\nHuman Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF) can\nintroduce additional difficulty. Differing preferences can complicate the\nalignment process, and prediction errors in a trained reward model can become\nmore severe as the LLM generates unseen outputs. To enhance training\nrobustness, RL has adopted techniques from supervised learning, such as\nensembles and layer normalization. In this work, we improve the stability of RL\ntraining by adapting the reverse cross entropy (RCE) from supervised learning\nfor noisy data to define a symmetric RL loss. We demonstrate performance\nimprovements across various tasks and scales. We conduct experiments in\ndiscrete action tasks (Atari games) and continuous action space tasks (MuJoCo\nbenchmark and Box2D) using Symmetric A2C (SA2C) and Symmetric PPO (SPPO), with\nand without added noise with especially notable performance in SPPO across\ndifferent hyperparameters. Furthermore, we validate the benefits of the\nsymmetric RL loss when using SPPO for large language models through improved\nperformance in RLHF tasks, such as IMDB positive sentiment sentiment and TL;DR\nsummarization tasks.",
      "tldr_zh": "该研究针对强化学习（RL）训练的不稳定性问题（如移动目标和高梯度方差），以及 RLHF 和 RLAIF 的额外挑战，提出了一种 symmetric RL loss，通过适应 supervised learning 中的 reverse cross entropy (RCE) 来提升训练鲁棒性。作者在离散动作任务（如 Atari 游戏）和连续动作任务（如 MuJoCo 基准和 Box2D）上测试了 Symmetric A2C (SA2C) 和 Symmetric PPO (SPPO)，结果显示 SPPO 在不同超参数和噪声条件下表现出色，尤其在性能提升方面。进一步验证表明，该损失函数在大型语言模型的 RLHF 任务中（如 IMDB 正面情感和 TL;DR 总结）也取得了显著改善，为多样任务和模型规模的 RL 应用提供了更稳定的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17618v2",
      "published_date": "2024-05-27 19:28:33 UTC",
      "updated_date": "2024-05-29 04:19:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:22:50.767808"
    },
    {
      "arxiv_id": "2405.17610v1",
      "title": "Explainable machine learning multi-label classification of Spanish legal judgements",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco de Arriba-Pérez",
        "Silvia García-Méndez",
        "Francisco J. González-Castaño",
        "Jaime González-González"
      ],
      "abstract": "Artificial Intelligence techniques such as Machine Learning (ML) have not\nbeen exploited to their maximum potential in the legal domain. This has been\npartially due to the insufficient explanations they provided about their\ndecisions. Automatic expert systems with explanatory capabilities can be\nspecially useful when legal practitioners search jurisprudence to gather\ncontextual knowledge for their cases. Therefore, we propose a hybrid system\nthat applies ML for multi-label classification of judgements (sentences) and\nvisual and natural language descriptions for explanation purposes, boosted by\nNatural Language Processing techniques and deep legal reasoning to identify the\nentities, such as the parties, involved. We are not aware of any prior work on\nautomatic multi-label classification of legal judgements also providing natural\nlanguage explanations to the end-users with comparable overall quality. Our\nsolution achieves over 85 % micro precision on a labelled data set annotated by\nlegal experts. This endorses its interest to relieve human experts from\nmonotonous labour-intensive legal classification tasks.",
      "tldr_zh": "本研究探讨了在法律领域应用 Machine Learning (ML) 的潜力，提出一个混合系统，用于西班牙法律判决的多标签分类，并通过视觉和自然语言描述提供解释，以解决传统 ML 决策不透明的问题。该系统整合 Natural Language Processing (NLP) 技术和深度法律推理，识别实体如当事人并生成可解释的输出。在标记数据集上，该方法实现了超过85%的微精度（micro precision），有助于自动化单调的法律分类任务，减轻法律从业者的工作负担。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17610v1",
      "published_date": "2024-05-27 19:16:42 UTC",
      "updated_date": "2024-05-27 19:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:23:01.081922"
    },
    {
      "arxiv_id": "2405.17607v1",
      "title": "Advancing Cultural Inclusivity: Optimizing Embedding Spaces for Balanced Music Recommendations",
      "title_zh": "推进文化包容性：优化嵌入空间",
      "authors": [
        "Armin Moradi",
        "Nicola Neophytou",
        "Golnoosh Farnadi"
      ],
      "abstract": "Popularity bias in music recommendation systems -- where artists and tracks\nwith the highest listen counts are recommended more often -- can also propagate\nbiases along demographic and cultural axes. In this work, we identify these\nbiases in recommendations for artists from underrepresented cultural groups in\nprototype-based matrix factorization methods. Unlike traditional matrix\nfactorization methods, prototype-based approaches are interpretable. This\nallows us to directly link the observed bias in recommendations for minority\nartists (the effect) to specific properties of the embedding space (the cause).\nWe mitigate popularity bias in music recommendation through capturing both\nusers' and songs' cultural nuances in the embedding space. To address these\nchallenges while maintaining recommendation quality, we propose two novel\nenhancements to the embedding space: i) we propose an approach to filter-out\nthe irrelevant prototypes used to represent each user and item to improve\ngeneralizability, and ii) we introduce regularization techniques to reinforce a\nmore uniform distribution of prototypes within the embedding space. Our results\ndemonstrate significant improvements in reducing popularity bias and enhancing\ndemographic and cultural fairness in music recommendations while achieving\ncompetitive -- if not better -- overall performance.",
      "tldr_zh": "该研究探讨了音乐推荐系统中存在的流行度偏差（popularity bias），这种偏差导致热门艺术家和歌曲被优先推荐，从而加剧了人口统计学和文化方面的不公平。针对原型-based matrix factorization 方法的解释性优势，作者将偏差与嵌入空间（embedding space）的特定属性联系起来，并提出两种新增强：i) 过滤无关原型以提升泛化性，ii) 引入正则化技术（regularization techniques）使原型分布更均匀，从而更好地捕捉用户和歌曲的文化细微差别。实验结果显示，该方法显著降低了流行度偏差，提高了人口统计学和文化公平性，同时保持了或提升了整体推荐性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17607v1",
      "published_date": "2024-05-27 19:12:53 UTC",
      "updated_date": "2024-05-27 19:12:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:23:13.277738"
    },
    {
      "arxiv_id": "2405.17604v2",
      "title": "LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Klaudia Bałazy",
        "Mohammadreza Banaei",
        "Karl Aberer",
        "Jacek Tabor"
      ],
      "abstract": "The rapid expansion of large language models (LLMs) has underscored the need\nfor parameter-efficient fine-tuning methods, with LoRA (Low-Rank Adaptation)\nemerging as a popular solution. Although LoRA reduces the number of trainable\nparameters, serving multiple (task or user-specific) LoRA modules on top of a\nbase model still creates significant storage challenges. To address this, using\ntheoretical derivation, we introduce LoRA-XS (Low-Rank Adaptation with\neXtremely Small number of parameters), a novel low-rank adaptation method that\nconsiderably reduces the trainable parameters while showing superior or\ncompetitive performance. LoRA-XS achieves this by inserting a small, trainable\nr x r weight matrix between frozen low-rank matrices, which are constructed by\nSingular Value Decomposition (SVD) of the original weight matrix. This\nlightweight matrix enables fine-tuning with drastically reduced storage\nrequirements, making it feasible to deploy millions of personalized models\nwhile minimizing memory overhead. For instance, LoRA-XS achieves a remarkable\nreduction of trainable parameters by over 100x in 7B models compared to LoRA.\nOur evaluations across various benchmarks (including GLUE, GSM8K, MATH, and\neight commonsense reasoning datasets) demonstrate that LoRA-XS performs\ncompetitively or better than LoRA and other recent methods like VeRA while\nbeing significantly more parameter efficient. We also provide an extensive\nablation study on the importance of singular vectors in transformer weights,\nshedding light on the underlying mechanisms driving LoRA-XS's enhanced\nefficiency. These findings suggest that LoRA-XS is not only a storage-efficient\nalternative, but also a powerful tool for scaling and personalizing LLMs at\nunprecedented scales.",
      "tldr_zh": "该论文提出LoRA-XS，一种改进的Low-Rank Adaptation方法，旨在进一步减少大型语言模型(LLMs)微调的可训练参数数量，通过理论推导和Singular Value Decomposition (SVD)构建冻结低秩矩阵，并在其中插入一个小型r x r可训练权重矩阵，从而实现比LoRA减少100倍以上的参数。LoRA-XS在GLUE、GSM8K、MATH等基准测试中表现出与LoRA或VeRA相当或更优的性能，同时大幅降低存储需求。实验结果表明，该方法为大规模部署个性化LLMs提供了高效工具，并通过消融研究揭示了奇异向量在transformer权重中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17604v2",
      "published_date": "2024-05-27 19:07:13 UTC",
      "updated_date": "2024-10-08 16:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:23:26.196874"
    },
    {
      "arxiv_id": "2405.17580v2",
      "title": "Mixed Dynamics In Linear Networks: Unifying the Lazy and Active Regimes",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenfeng Tu",
        "Santiago Aranguri",
        "Arthur Jacot"
      ],
      "abstract": "The training dynamics of linear networks are well studied in two distinct\nsetups: the lazy regime and balanced/active regime, depending on the\ninitialization and width of the network. We provide a surprisingly simple\nunifying formula for the evolution of the learned matrix that contains as\nspecial cases both lazy and balanced regimes but also a mixed regime in between\nthe two. In the mixed regime, a part of the network is lazy while the other is\nbalanced. More precisely the network is lazy along singular values that are\nbelow a certain threshold and balanced along those that are above the same\nthreshold. At initialization, all singular values are lazy, allowing for the\nnetwork to align itself with the task, so that later in time, when some of the\nsingular value cross the threshold and become active they will converge rapidly\n(convergence in the balanced regime is notoriously difficult in the absence of\nalignment). The mixed regime is the `best of both worlds': it converges from\nany random initialization (in contrast to balanced dynamics which require\nspecial initialization), and has a low rank bias (absent in the lazy dynamics).\nThis allows us to prove an almost complete phase diagram of training behavior\nas a function of the variance at initialization and the width, for a MSE\ntraining task.",
      "tldr_zh": "本研究提出了一种统一的公式，描述线性网络的训练动态，将 lazy regime 和 balanced/active regime 整合为一个框架，同时引入了混合 regime，其中网络在某些奇异值（singular values）以下部分为 lazy，而在阈值以上部分为 balanced。该公式允许网络从初始化时所有奇异值均为 lazy 开始，与任务对齐，随后部分奇异值转为 active，从而实现快速收敛。混合 regime 结合了 lazy 动态的任意随机初始化能力和 balanced 动态的低秩偏差优势，最终证明了针对 MSE 训练任务的训练行为相图，作为初始化方差和网络宽度函数的几乎完整描述。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17580v2",
      "published_date": "2024-05-27 18:29:23 UTC",
      "updated_date": "2024-10-29 20:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:23:37.237120"
    },
    {
      "arxiv_id": "2405.17576v1",
      "title": "Container pre-marshalling problem minimizing CV@R under uncertainty of ship arrival times",
      "title_zh": "翻译失败",
      "authors": [
        "Daiki Ikuma",
        "Shunnosuke Ikeda",
        "Noriyoshi Sukegawa",
        "Yuichi Takano"
      ],
      "abstract": "This paper is concerned with the container pre-marshalling problem, which\ninvolves relocating containers in the storage area so that they can be\nefficiently loaded onto ships without reshuffles. In reality, however, ship\narrival times are affected by various external factors, which can cause the\norder of container retrieval to be different from the initial plan. To\nrepresent such uncertainty, we generate multiple scenarios from a multivariate\nprobability distribution of ship arrival times. We derive a mixed-integer\nlinear optimization model to find an optimal container layout such that the\nconditional value-at-risk is minimized for the number of misplaced containers\nresponsible for reshuffles. Moreover, we devise an exact algorithm based on the\ncutting-plane method to handle large-scale problems. Numerical experiments\nusing synthetic datasets demonstrate that our method can produce high-quality\ncontainer layouts compared with the conventional robust optimization model.\nAdditionally, our algorithm can speed up the computation of solving large-scale\nproblems.",
      "tldr_zh": "这篇论文针对容器预编排问题（Container pre-marshalling problem），在船只到达时间不确定性的情况下，提出了一种最小化条件风险价值（CV@R）的优化方法，以减少错位容器导致的重新整理。作者使用多变量概率分布生成多个场景，并开发了一个混合整数线性优化模型（mixed-integer linear optimization model）来优化容器布局。实验结果显示，该方法基于切割平面方法的精确算法（cutting-plane method）能产生比传统鲁棒优化模型更高质量的布局，并显著加速大规模问题的计算。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17576v1",
      "published_date": "2024-05-27 18:19:09 UTC",
      "updated_date": "2024-05-27 18:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:23:50.325667"
    },
    {
      "arxiv_id": "2405.17573v2",
      "title": "Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky ResNets",
      "title_zh": "特征学习的哈密顿力学：Leaky ResN",
      "authors": [
        "Arthur Jacot",
        "Alexandre Kaiser"
      ],
      "abstract": "We study Leaky ResNets, which interpolate between ResNets and Fully-Connected\nnets depending on an 'effective depth' hyper-parameter $\\tilde{L}$. In the\ninfinite depth limit, we study 'representation geodesics' $A_{p}$: continuous\npaths in representation space (similar to NeuralODEs) from input $p=0$ to\noutput $p=1$ that minimize the parameter norm of the network. We give a\nLagrangian and Hamiltonian reformulation, which highlight the importance of two\nterms: a kinetic energy which favors small layer derivatives\n$\\partial_{p}A_{p}$ and a potential energy that favors low-dimensional\nrepresentations, as measured by the 'Cost of Identity'. The balance between\nthese two forces offers an intuitive understanding of feature learning in\nResNets. We leverage this intuition to explain the emergence of a bottleneck\nstructure, as observed in previous work: for large $\\tilde{L}$ the potential\nenergy dominates and leads to a separation of timescales, where the\nrepresentation jumps rapidly from the high dimensional inputs to a\nlow-dimensional representation, move slowly inside the space of low-dimensional\nrepresentations, before jumping back to the potentially high-dimensional\noutputs. Inspired by this phenomenon, we train with an adaptive layer step-size\nto adapt to the separation of timescales.",
      "tldr_zh": "这篇论文研究了 Leaky ResNets 的特征学习机制，将其建模为 Hamiltonian 力学系统，焦点在于有效深度（effective depth）参数的影响。作者引入表示 geodesics（A_p）路径、Lagrangian 和 Hamiltonian 改革，强调动能（favor small layer derivatives）和势能（favor low-dimensional representations，如 Cost of Identity）的平衡，以解释 ResNets 中的特征学习过程。研究发现，在大有效深度下，势能主导导致瓶颈结构出现，即表示从高维输入快速跳转到低维空间、缓慢演化后返回高维输出；基于此，他们开发了自适应层步长训练方法来适应时间尺度的分离。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17573v2",
      "published_date": "2024-05-27 18:15:05 UTC",
      "updated_date": "2025-03-06 13:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:24:02.191714"
    },
    {
      "arxiv_id": "2405.17569v1",
      "title": "Discriminant audio properties in deep learning based respiratory insufficiency detection in Brazilian Portuguese",
      "title_zh": "翻译失败",
      "authors": [
        "Marcelo Matheus Gauy",
        "Larissa Cristina Berti",
        "Arnaldo Cândido Jr",
        "Augusto Camargo Neto",
        "Alfredo Goldman",
        "Anna Sara Shafferman Levin",
        "Marcus Martins",
        "Beatriz Raposo de Medeiros",
        "Marcelo Queiroz",
        "Ester Cerdeira Sabino",
        "Flaviane Romani Fernandes Svartman",
        "Marcelo Finger"
      ],
      "abstract": "This work investigates Artificial Intelligence (AI) systems that detect\nrespiratory insufficiency (RI) by analyzing speech audios, thus treating speech\nas a RI biomarker. Previous works collected RI data (P1) from COVID-19 patients\nduring the first phase of the pandemic and trained modern AI models, such as\nCNNs and Transformers, which achieved $96.5\\%$ accuracy, showing the\nfeasibility of RI detection via AI. Here, we collect RI patient data (P2) with\nseveral causes besides COVID-19, aiming at extending AI-based RI detection. We\nalso collected control data from hospital patients without RI. We show that the\nconsidered models, when trained on P1, do not generalize to P2, indicating that\nCOVID-19 RI has features that may not be found in all RI types.",
      "tldr_zh": "这篇论文探讨了使用深度学习模型（如CNNs和Transformers）分析巴西葡萄牙语语音音频，以检测呼吸不足（RI），并将语音视为RI的生物标志物。研究者扩展了先前基于COVID-19患者数据（P1）的工作，收集了多种原因导致的RI患者数据（P2）以及无RI对照数据。结果显示，P1训练的模型无法泛化到P2，表明COVID-19相关的RI特征可能不适用于所有RI类型，从而为AI在RI检测中的鲁棒性提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 2 figures, 1 table. Published in Artificial Intelligence in\n  Medicine (AIME) 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.17569v1",
      "published_date": "2024-05-27 18:04:49 UTC",
      "updated_date": "2024-05-27 18:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:24:14.634053"
    },
    {
      "arxiv_id": "2405.17556v2",
      "title": "Probabilistic Verification of Neural Networks using Branch and Bound",
      "title_zh": "翻译失败",
      "authors": [
        "David Boetius",
        "Stefan Leue",
        "Tobias Sutter"
      ],
      "abstract": "Probabilistic verification of neural networks is concerned with formally\nanalysing the output distribution of a neural network under a probability\ndistribution of the inputs. Examples of probabilistic verification include\nverifying the demographic parity fairness notion or quantifying the safety of a\nneural network. We present a new algorithm for the probabilistic verification\nof neural networks based on an algorithm for computing and iteratively refining\nlower and upper bounds on probabilities over the outputs of a neural network.\nBy applying state-of-the-art bound propagation and branch and bound techniques\nfrom non-probabilistic neural network verification, our algorithm significantly\noutpaces existing probabilistic verification algorithms, reducing solving times\nfor various benchmarks from the literature from tens of minutes to tens of\nseconds. Furthermore, our algorithm compares favourably even to dedicated\nalgorithms for restricted subsets of probabilistic verification. We complement\nour empirical evaluation with a theoretical analysis, proving that our\nalgorithm is sound and, under mildly restrictive conditions, also complete when\nusing a suitable set of heuristics.",
      "tldr_zh": "本论文提出了一种基于Branch and Bound的神经网络概率验证算法，用于正式分析神经网络在输入概率分布下的输出分布，例如验证人口平等等公平性或量化网络安全性。该算法通过计算和迭代细化输出概率的下限和上限，并整合最先进的边界传播和分支定界技术，显著提升了验证效率，将基准测试的解决时间从数分钟缩短至数秒。实验结果显示，该算法在各种场景中优于现有方法，甚至超越了针对特定子集的专用算法；此外，理论分析证明了算法的可靠性，并证明在某些条件下其完整性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at https://github.com/sen-uni-kn/probspecs; 19 pages,\n  3 figures, 30 pages references and appendix, including 7 more figures",
      "pdf_url": "http://arxiv.org/pdf/2405.17556v2",
      "published_date": "2024-05-27 18:00:03 UTC",
      "updated_date": "2025-01-30 15:57:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:24:25.806189"
    },
    {
      "arxiv_id": "2405.17430v2",
      "title": "Matryoshka Multimodal Models",
      "title_zh": "Matryoshka 多模态模型",
      "authors": [
        "Mu Cai",
        "Jianwei Yang",
        "Jianfeng Gao",
        "Yong Jae Lee"
      ],
      "abstract": "Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in\nvisual-linguistic reasoning. These models first embed images into a fixed large\nnumber of visual tokens and then feed them into a Large Language Model (LLM).\nHowever, this design causes an excessive number of tokens for dense visual\nscenarios such as high-resolution images and videos, leading to great\ninefficiency. While token pruning/merging methods do exist, they produce a\nsingle length output for each image and do not afford flexibility in trading\noff information density v.s. efficiency. Inspired by the concept of Matryoshka\nDolls, we propose M3: Matryoshka Multimodal Models, which learns to represent\nvisual content as nested sets of visual tokens that capture information across\nmultiple coarse-to-fine granularities. Our approach offers several unique\nbenefits for LMMs: (1) One can explicitly control the visual granularity per\ntest instance during inference, e.g. , adjusting the number of tokens used to\nrepresent an image based on the anticipated complexity or simplicity of the\ncontent; (2) M3 provides a framework for analyzing the granularity needed for\nexisting datasets, where we find that COCO-style benchmarks only need around ~9\nvisual tokens to obtain accuracy similar to that of using all 576 tokens; (3)\nOur approach provides a foundation to explore the best trade-off between\nperformance and visual token length at sample level, where our investigation\nreveals that a large gap exists between the oracle upper bound and current\nfixed-scale representations.",
      "tldr_zh": "本研究提出Matryoshka Multimodal Models (M3)，一种新型框架，旨在解决Large Multimodal Models (LMMs)如LLaVA在处理密集视觉场景（如高分辨率图像和视频）时产生的过多视觉tokens导致的低效问题。M3通过学习将视觉内容表示为嵌套的多粒度视觉tokens集，灵感来源于Matryoshka Dolls，从而允许用户在推理过程中灵活调整每个图像的tokens数量，以权衡信息密度和计算效率。实验分析显示，对于COCO-style基准，仅需约9个tokens即可达到使用全部576tokens的准确率，并揭示了当前固定规模表示与理想性能上界之间存在的巨大差距，为优化LMMs的性能和效率提供了新基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://matryoshka-mm.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.17430v2",
      "published_date": "2024-05-27 17:59:56 UTC",
      "updated_date": "2024-07-29 17:59:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:24:38.995570"
    },
    {
      "arxiv_id": "2405.17429v1",
      "title": "GaussianFormer: Scene as Gaussians for Vision-Based 3D Semantic Occupancy Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhui Huang",
        "Wenzhao Zheng",
        "Yunpeng Zhang",
        "Jie Zhou",
        "Jiwen Lu"
      ],
      "abstract": "3D semantic occupancy prediction aims to obtain 3D fine-grained geometry and\nsemantics of the surrounding scene and is an important task for the robustness\nof vision-centric autonomous driving. Most existing methods employ dense grids\nsuch as voxels as scene representations, which ignore the sparsity of occupancy\nand the diversity of object scales and thus lead to unbalanced allocation of\nresources. To address this, we propose an object-centric representation to\ndescribe 3D scenes with sparse 3D semantic Gaussians where each Gaussian\nrepresents a flexible region of interest and its semantic features. We\naggregate information from images through the attention mechanism and\niteratively refine the properties of 3D Gaussians including position,\ncovariance, and semantics. We then propose an efficient Gaussian-to-voxel\nsplatting method to generate 3D occupancy predictions, which only aggregates\nthe neighboring Gaussians for a certain position. We conduct extensive\nexperiments on the widely adopted nuScenes and KITTI-360 datasets. Experimental\nresults demonstrate that GaussianFormer achieves comparable performance with\nstate-of-the-art methods with only 17.8% - 24.8% of their memory consumption.\nCode is available at: https://github.com/huang-yh/GaussianFormer.",
      "tldr_zh": "这篇论文提出 GaussianFormer，一种将场景表示为稀疏 3D semantic Gaussians 的框架，用于视觉-based 3D semantic occupancy prediction，以提升自主驾驶的鲁棒性。该方法通过 attention mechanism 从图像中聚合信息，并迭代优化 Gaussians 的位置、covariance 和语义特征，从而解决现有基于 voxels 的方法在资源分配上的不平衡问题。随后，使用高效的 Gaussian-to-voxel splatting 技术生成 3D 占用预测，仅处理邻近 Gaussians。在 nuScenes 和 KITTI-360 数据集上的实验显示，GaussianFormer 取得了与最先进方法相当的性能，但内存消耗仅为其 17.8% - 24.8%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at: https://github.com/huang-yh/GaussianFormer",
      "pdf_url": "http://arxiv.org/pdf/2405.17429v1",
      "published_date": "2024-05-27 17:59:51 UTC",
      "updated_date": "2024-05-27 17:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:24:51.205278"
    },
    {
      "arxiv_id": "2405.17428v3",
      "title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models",
      "title_zh": "NV-Embed：训练 LLMs 作为通用嵌入模型的改进技术",
      "authors": [
        "Chankyu Lee",
        "Rajarshi Roy",
        "Mengyao Xu",
        "Jonathan Raiman",
        "Mohammad Shoeybi",
        "Bryan Catanzaro",
        "Wei Ping"
      ],
      "abstract": "Decoder-only LLM-based embedding models are beginning to outperform BERT or\nT5-based embedding models in general-purpose text embedding tasks, including\ndense vector-based retrieval. In this work, we introduce NV-Embed,\nincorporating architectural designs, training procedures, and curated datasets\nto significantly enhance the performance of LLM as a versatile embedding model,\nwhile maintaining its simplicity and reproducibility. For model architecture,\nwe propose a latent attention layer to obtain pooled embeddings, which\nconsistently improves retrieval and downstream task accuracy compared to mean\npooling or using the last <EOS> token embedding from LLMs. To enhance\nrepresentation learning, we remove the causal attention mask of LLMs during\ncontrastive training. For training algorithm, we introduce a two-stage\ncontrastive instruction-tuning method. It first applies contrastive training\nwith instructions on retrieval datasets, utilizing in-batch negatives and\ncurated hard negative examples. At stage-2, it blends various non-retrieval\ninto instruction tuning, which not only enhances non-retrieval task accuracy\nbut also improves retrieval performance. For training data, we utilize the\nhard-negative mining, synthetic data generation and existing public available\ndatasets to boost the performance of embedding model. By combining these\ntechniques, our NV-Embed-v1 and NV-Embed-v2 models obtained the No.1 position\non the MTEB leaderboard (as of May 24 and August 30, 2024, respectively) across\n56 tasks, demonstrating the sustained effectiveness of the proposed methods\nover time. It also achieved the highest scores in the Long Doc section and the\nsecond-highest scores in the QA section of the AIR Benchmark, which covers a\nrange of out-of-domain information retrieval topics beyond those in MTEB. We\nfurther provide the analysis of model compression techniques for generalist\nembedding models.",
      "tldr_zh": "本文提出 NV-Embed，一种改进技术，用于训练 LLM 作为通用嵌入模型，以超越 BERT 或 T5 在文本嵌入任务中的性能。关键创新包括引入 latent attention layer 用于获取 pooled embeddings、移除 causal attention mask 以增强表示学习，以及采用两阶段 contrastive instruction-tuning 方法（第一阶段聚焦检索数据集的对比训练，第二阶段混合非检索任务）。此外，通过 hard-negative mining、合成数据生成和现有数据集优化训练数据，该模型在 MTEB 排行榜上排名第一，并在 AIR Benchmark 的 Long Doc 和 QA 部分取得领先成绩。论文还分析了模型压缩技术，以提升实用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 (Spotlight). We open-source the model at:\n  https://huggingface.co/nvidia/NV-Embed-v2",
      "pdf_url": "http://arxiv.org/pdf/2405.17428v3",
      "published_date": "2024-05-27 17:59:45 UTC",
      "updated_date": "2025-02-25 00:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:25:02.368903"
    },
    {
      "arxiv_id": "2405.20774v3",
      "title": "Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-based Decision-Making Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ruochen Jiao",
        "Shaoyuan Xie",
        "Justin Yue",
        "Takami Sato",
        "Lixu Wang",
        "Yixuan Wang",
        "Qi Alfred Chen",
        "Qi Zhu"
      ],
      "abstract": "Large Language Models (LLMs) have shown significant promise in real-world\ndecision-making tasks for embodied artificial intelligence, especially when\nfine-tuned to leverage their inherent common sense and reasoning abilities\nwhile being tailored to specific applications. However, this fine-tuning\nprocess introduces considerable safety and security vulnerabilities, especially\nin safety-critical cyber-physical systems. In this work, we propose the first\ncomprehensive framework for Backdoor Attacks against LLM-based Decision-making\nsystems (BALD) in embodied AI, systematically exploring the attack surfaces and\ntrigger mechanisms. Specifically, we propose three distinct attack mechanisms:\nword injection, scenario manipulation, and knowledge injection, targeting\nvarious components in the LLM-based decision-making pipeline. We perform\nextensive experiments on representative LLMs (GPT-3.5, LLaMA2, PaLM2) in\nautonomous driving and home robot tasks, demonstrating the effectiveness and\nstealthiness of our backdoor triggers across various attack channels, with\ncases like vehicles accelerating toward obstacles and robots placing knives on\nbeds. Our word and knowledge injection attacks achieve nearly 100% success rate\nacross multiple models and datasets while requiring only limited access to the\nsystem. Our scenario manipulation attack yields success rates exceeding 65%,\nreaching up to 90%, and does not require any runtime system intrusion. We also\nassess the robustness of these attacks against defenses, revealing their\nresilience. Our findings highlight critical security vulnerabilities in\nembodied LLM systems and emphasize the urgent need for safeguarding these\nsystems to mitigate potential risks.",
      "tldr_zh": "该研究探讨了实体化 LLM（Large Language Models）决策系统在安全关键应用中的漏洞，首次提出后门攻击框架（BALD），针对 LLM 微调过程的潜在风险。框架包括三种攻击机制：word injection（单词注入）、scenario manipulation（场景操纵）和knowledge injection（知识注入），这些机制针对决策管道的不同组件，在自动驾驶和家用机器人任务上进行了实验。结果显示，word injection 和knowledge injection 攻击成功率接近 100%，而scenario manipulation 攻击成功率超过 65%（最高 90%），并展示了实际危害如车辆加速向障碍物和机器人放置刀具。该研究突出了实体化 LLM 系统的安全隐患，并呼吁开发更 robust 的防御措施以缓解潜在风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted paper at ICLR 2025, 31 pages, including main paper,\n  references, and appendix",
      "pdf_url": "http://arxiv.org/pdf/2405.20774v3",
      "published_date": "2024-05-27 17:59:43 UTC",
      "updated_date": "2025-04-30 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:25:25.638180"
    },
    {
      "arxiv_id": "2405.17422v1",
      "title": "Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Zeng",
        "Wenzhao Zheng",
        "Jiwen Lu",
        "Haibin Yan"
      ],
      "abstract": "3D object detection aims to recover the 3D information of concerning objects\nand serves as the fundamental task of autonomous driving perception. Its\nperformance greatly depends on the scale of labeled training data, yet it is\ncostly to obtain high-quality annotations for point cloud data. While\nconventional methods focus on generating pseudo-labels for unlabeled samples as\nsupplements for training, the structural nature of 3D point cloud data\nfacilitates the composition of objects and backgrounds to synthesize realistic\nscenes. Motivated by this, we propose a hardness-aware scene synthesis (HASS)\nmethod to generate adaptive synthetic scenes to improve the generalization of\nthe detection models. We obtain pseudo-labels for unlabeled objects and\ngenerate diverse scenes with different compositions of objects and backgrounds.\nAs the scene synthesis is sensitive to the quality of pseudo-labels, we further\npropose a hardness-aware strategy to reduce the effect of low-quality\npseudo-labels and maintain a dynamic pseudo-database to ensure the diversity\nand quality of synthetic scenes. Extensive experimental results on the widely\nused KITTI and Waymo datasets demonstrate the superiority of the proposed HASS\nmethod, which outperforms existing semi-supervised learning methods on 3D\nobject detection. Code: https://github.com/wzzheng/HASS.",
      "tldr_zh": "本文提出了一种 hardness-aware scene synthesis (HASS) 方法，用于半监督 3D object detection，以解决标注点云数据成本高的问题。HASS 通过生成伪标签并合成多样化的场景，包括不同物体和背景的组合，同时采用 hardness-aware 策略来减少低质量伪标签的影响，并维护动态伪数据库以确保场景的质量和多样性。在 KITTI 和 Waymo 数据集上的实验结果显示，HASS 优于现有半监督学习方法，提高了检测模型的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at: https://github.com/wzzheng/HASS",
      "pdf_url": "http://arxiv.org/pdf/2405.17422v1",
      "published_date": "2024-05-27 17:59:23 UTC",
      "updated_date": "2024-05-27 17:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:25:38.331163"
    },
    {
      "arxiv_id": "2405.17419v2",
      "title": "MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities",
      "title_zh": "MultiOOD：多模态分布外检测的",
      "authors": [
        "Hao Dong",
        "Yue Zhao",
        "Eleni Chatzi",
        "Olga Fink"
      ],
      "abstract": "Detecting out-of-distribution (OOD) samples is important for deploying\nmachine learning models in safety-critical applications such as autonomous\ndriving and robot-assisted surgery. Existing research has mainly focused on\nunimodal scenarios on image data. However, real-world applications are\ninherently multimodal, which makes it essential to leverage information from\nmultiple modalities to enhance the efficacy of OOD detection. To establish a\nfoundation for more realistic Multimodal OOD Detection, we introduce the\nfirst-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes\nand varying modality combinations. We first evaluate existing unimodal OOD\ndetection algorithms on MultiOOD, observing that the mere inclusion of\nadditional modalities yields substantial improvements. This underscores the\nimportance of utilizing multiple modalities for OOD detection. Based on the\nobservation of Modality Prediction Discrepancy between in-distribution (ID) and\nOOD data, and its strong correlation with OOD performance, we propose the\nAgree-to-Disagree (A2D) algorithm to encourage such discrepancy during\ntraining. Moreover, we introduce a novel outlier synthesis method, NP-Mix,\nwhich explores broader feature spaces by leveraging the information from\nnearest neighbor classes and complements A2D to strengthen OOD detection\nperformance. Extensive experiments on MultiOOD demonstrate that training with\nA2D and NP-Mix improves existing OOD detection algorithms by a large margin.\nOur source code and MultiOOD benchmark are available at\nhttps://github.com/donghao51/MultiOOD.",
      "tldr_zh": "该研究针对多模态场景下的异常分布（OOD）检测问题，引入了首个基准 MultiOOD，该基准包含多样数据集大小和模态组合，以模拟现实应用如自动驾驶和机器人辅助手术。实验发现，现有单模态 OOD 算法在添加更多模态后显著提升性能。论文提出 Agree-to-Disagree (A2D) 算法，利用模态预测差异（Modality Prediction Discrepancy）在训练中鼓励 ID 和 OOD 数据间的差异；同时引入 NP-Mix 方法，通过利用最近邻类信息探索更广的特征空间，进一步强化 OOD 检测。总体结果显示，结合 A2D 和 NP-Mix 后，现有 OOD 检测算法的性能大幅提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 spotlight. Code and MultiOOD benchmark:\n  https://github.com/donghao51/MultiOOD",
      "pdf_url": "http://arxiv.org/pdf/2405.17419v2",
      "published_date": "2024-05-27 17:59:02 UTC",
      "updated_date": "2024-10-26 16:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:25:51.988687"
    },
    {
      "arxiv_id": "2405.17537v4",
      "title": "CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "ZeMing Gong",
        "Austin T. Wang",
        "Xiaoliang Huo",
        "Joakim Bruslund Haurum",
        "Scott C. Lowe",
        "Graham W. Taylor",
        "Angel X. Chang"
      ],
      "abstract": "Measuring biodiversity is crucial for understanding ecosystem health. While\nprior works have developed machine learning models for taxonomic classification\nof photographic images and DNA separately, in this work, we introduce a\nmultimodal approach combining both, using CLIP-style contrastive learning to\nalign images, barcode DNA, and text-based representations of taxonomic labels\nin a unified embedding space. This allows for accurate classification of both\nknown and unknown insect species without task-specific fine-tuning, leveraging\ncontrastive learning for the first time to fuse barcode DNA and image data. Our\nmethod surpasses previous single-modality approaches in accuracy by over 8% on\nzero-shot learning tasks, showcasing its effectiveness in biodiversity studies.",
      "tldr_zh": "本研究提出 CLIBD 方法，通过 CLIP-style contrastive learning 将图像、barcode DNA 和文本表示对齐到统一嵌入空间，实现多模态融合，用于大规模生物多样性监测。这是一种创新的多模态方法，首次结合视觉和基因组数据，允许对已知和未知昆虫物种进行准确分类，而无需任务特定的微调。实验结果显示，该方法在零-shot learning 任务上比单模态方法准确率提高了超过8%，为生态系统健康评估提供了更有效的工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages with 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.17537v4",
      "published_date": "2024-05-27 17:57:48 UTC",
      "updated_date": "2025-04-02 22:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:26:02.408071"
    },
    {
      "arxiv_id": "2405.17413v1",
      "title": "Enhancing Music Genre Classification through Multi-Algorithm Analysis and User-Friendly Visualization",
      "title_zh": "通过多算法分析和用户友好可视化增强音乐流派分类",
      "authors": [
        "Navin Kamuni",
        "Dheerendra Panwar"
      ],
      "abstract": "The aim of this study is to teach an algorithm how to recognize different\ntypes of music. Users will submit songs for analysis. Since the algorithm\nhasn't heard these songs before, it needs to figure out what makes each song\nunique. It does this by breaking down the songs into different parts and\nstudying things like rhythm, melody, and tone via supervised learning because\nthe program learns from examples that are already labelled. One important thing\nto consider when classifying music is its genre, which can be quite complex. To\nensure accuracy, we use five different algorithms, each working independently,\nto analyze the songs. This helps us get a more complete understanding of each\nsong's characteristics. Therefore, our goal is to correctly identify the genre\nof each submitted song. Once the analysis is done, the results are presented\nusing a graphing tool, making it easy for users to understand and provide\nfeedback.",
      "tldr_zh": "本研究旨在通过多算法分析和用户友好可视化提升音乐流派分类的准确性，使用supervised learning从已标注样本中学习歌曲的节奏(rhythm)、旋律(melody)和音调(tone)等特征。研究采用五种不同的algorithms进行独立分析，以全面理解歌曲独特性并提高分类可靠性。最终，分析结果通过graphing tool呈现，便于用户轻松理解和提供反馈，从而实现高效的音乐识别系统。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17413v1",
      "published_date": "2024-05-27 17:57:20 UTC",
      "updated_date": "2024-05-27 17:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:26:14.304022"
    },
    {
      "arxiv_id": "2405.17412v5",
      "title": "Towards One Model for Classical Dimensionality Reduction: A Probabilistic Perspective on UMAP and t-SNE",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Ravuri",
        "Neil D. Lawrence"
      ],
      "abstract": "This paper shows that dimensionality reduction methods such as UMAP and\nt-SNE, can be approximately recast as MAP inference methods corresponding to a\nmodel introduced in Ravuri et al. (2023), that describes the graph Laplacian\n(an estimate of the data precision matrix) using a Wishart distribution, with a\nmean given by a non-linear covariance function evaluated on the latents. This\ninterpretation offers deeper theoretical and semantic insights into such\nalgorithms, and forging a connection to Gaussian process latent variable models\nby showing that well-known kernels can be used to describe covariances implied\nby graph Laplacians. We also introduce tools with which similar dimensionality\nreduction methods can be studied.",
      "tldr_zh": "这篇论文从概率视角重新诠释了经典维度降低方法 UMAP 和 t-SNE，将它们近似视为基于 Ravuri et al. (2023) 模型的 MAP inference 方法，该模型使用 Wishart 分布描述图 Laplacian（数据精度矩阵的估计），并通过非线性协方差函数定义其均值。  \n这种解释提供了更深入的理论和语义洞见，并建立了这些方法与 Gaussian process latent variable models 的联系，展示了已知核函数可用于描述图 Laplacian 隐含的协方差。  \n此外，论文引入了工具来研究类似维度降低方法，从而为这些算法的进一步分析奠定基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Updated figures",
      "pdf_url": "http://arxiv.org/pdf/2405.17412v5",
      "published_date": "2024-05-27 17:57:12 UTC",
      "updated_date": "2025-05-10 19:36:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:26:27.453688"
    },
    {
      "arxiv_id": "2405.17535v1",
      "title": "Calibrated Dataset Condensation for Faster Hyperparameter Search",
      "title_zh": "翻译失败",
      "authors": [
        "Mucong Ding",
        "Yuancheng Xu",
        "Tahseen Rabbani",
        "Xiaoyu Liu",
        "Brian Gravelle",
        "Teresa Ranadive",
        "Tai-Ching Tuan",
        "Furong Huang"
      ],
      "abstract": "Dataset condensation can be used to reduce the computational cost of training\nmultiple models on a large dataset by condensing the training dataset into a\nsmall synthetic set. State-of-the-art approaches rely on matching the model\ngradients between the real and synthetic data. However, there is no theoretical\nguarantee of the generalizability of the condensed data: data condensation\noften generalizes poorly across hyperparameters/architectures in practice. This\npaper considers a different condensation objective specifically geared toward\nhyperparameter search. We aim to generate a synthetic validation dataset so\nthat the validation-performance rankings of the models, with different\nhyperparameters, on the condensed and original datasets are comparable. We\npropose a novel hyperparameter-calibrated dataset condensation (HCDC)\nalgorithm, which obtains the synthetic validation dataset by matching the\nhyperparameter gradients computed via implicit differentiation and efficient\ninverse Hessian approximation. Experiments demonstrate that the proposed\nframework effectively maintains the validation-performance rankings of models\nand speeds up hyperparameter/architecture search for tasks on both images and\ngraphs.",
      "tldr_zh": "本文提出了一种校准数据集浓缩（HCDC）算法，旨在通过生成合成验证数据集来加速超参数搜索。该方法专注于匹配超参数梯度（利用隐式微分和高效逆Hessian近似），以确保模型在合成数据集和原始数据集上的验证性能排名一致，从而解决传统数据集浓缩在不同超参数或架构下泛化差的问题。实验结果显示，HCDC 框架在图像和图任务上有效维持了性能排名，并显著提高了超参数和架构搜索的效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17535v1",
      "published_date": "2024-05-27 17:55:01 UTC",
      "updated_date": "2024-05-27 17:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:26:38.125823"
    },
    {
      "arxiv_id": "2406.18559v1",
      "title": "Revision Matters: Generative Design Guided by Revision Edits",
      "title_zh": "修订至关重要：通过修订编辑指导的生成式设计",
      "authors": [
        "Tao Li",
        "Chin-Yi Cheng",
        "Amber Xie",
        "Gang Li",
        "Yang Li"
      ],
      "abstract": "Layout design, such as user interface or graphical layout in general, is\nfundamentally an iterative revision process. Through revising a design\nrepeatedly, the designer converges on an ideal layout. In this paper, we\ninvestigate how revision edits from human designer can benefit a multimodal\ngenerative model. To do so, we curate an expert dataset that traces how human\ndesigners iteratively edit and improve a layout generation with a prompted\nlanguage goal. Based on such data, we explore various supervised fine-tuning\ntask setups on top of a Gemini multimodal backbone, a large multimodal model.\nOur results show that human revision plays a critical role in iterative layout\nrefinement. While being noisy, expert revision edits lead our model to a\nsurprisingly strong design FID score ~10 which is close to human performance\n(~6). In contrast, self-revisions that fully rely on model's own judgement,\nlead to an echo chamber that prevents iterative improvement, and sometimes\nleads to generative degradation. Fortunately, we found that providing human\nguidance plays at early stage plays a critical role in final generation. In\nsuch human-in-the-loop scenario, our work paves the way for iterative design\nrevision based on pre-trained large multimodal models.",
      "tldr_zh": "这篇论文探讨了如何利用人类设计师的修订编辑来指导多模态生成模型进行布局设计改进，强调设计过程的迭代本质。研究者构建了一个专家数据集，记录人类如何迭代编辑布局以实现语言提示目标，并在 Gemini 多模态骨干上进行各种监督细调任务。结果显示，人类修订编辑尽管存在噪音，却显著提升了模型性能，使其 FID score 达到约 10，接近人类水平(~6)；相比之下，模型的自修订会导致回音室效应和生成退化。总体而言，该工作为预训练大模型的迭代设计修订提供了人类辅助的新框架。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18559v1",
      "published_date": "2024-05-27 17:54:51 UTC",
      "updated_date": "2024-05-27 17:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:26:51.367756"
    },
    {
      "arxiv_id": "2405.17404v1",
      "title": "Spectral Greedy Coresets for Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mucong Ding",
        "Yinhan He",
        "Jundong Li",
        "Furong Huang"
      ],
      "abstract": "The ubiquity of large-scale graphs in node-classification tasks significantly\nhinders the real-world applications of Graph Neural Networks (GNNs). Node\nsampling, graph coarsening, and dataset condensation are effective strategies\nfor enhancing data efficiency. However, owing to the interdependence of graph\nnodes, coreset selection, which selects subsets of the data examples, has not\nbeen successfully applied to speed up GNN training on large graphs, warranting\nspecial treatment. This paper studies graph coresets for GNNs and avoids the\ninterdependence issue by selecting ego-graphs (i.e., neighborhood subgraphs\naround a node) based on their spectral embeddings. We decompose the coreset\nselection problem for GNNs into two phases: a coarse selection of widely spread\nego graphs and a refined selection to diversify their topologies. We design a\ngreedy algorithm that approximately optimizes both objectives. Our spectral\ngreedy graph coreset (SGGC) scales to graphs with millions of nodes, obviates\nthe need for model pre-training, and applies to low-homophily graphs. Extensive\nexperiments on ten datasets demonstrate that SGGC outperforms other coreset\nmethods by a wide margin, generalizes well across GNN architectures, and is\nmuch faster than graph condensation.",
      "tldr_zh": "本论文提出了一种名为 Spectral Greedy Graph Coreset (SGGC) 的方法，用于加速 Graph Neural Networks (GNNs) 在大规模图上的训练，解决节点相互依赖性带来的挑战。SGGC 通过基于 spectral embeddings 选择 ego-graphs（节点周围的邻居子图），将 coreset 选择分解为粗选广泛分布的子图和精选以多样化拓扑的两个阶段，并采用贪婪算法(greedy algorithm)来近似优化这些目标。该方法无需模型预训练，适用于低-homophily 图，并在十个数据集上的实验中显著优于其他 coreset 方法，在不同 GNN 架构上具有良好泛化性，且训练速度远快于图浓缩技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17404v1",
      "published_date": "2024-05-27 17:52:12 UTC",
      "updated_date": "2024-05-27 17:52:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:27:03.187042"
    },
    {
      "arxiv_id": "2405.17403v3",
      "title": "A Closer Look at Time Steps is Worthy of Triple Speed-Up for Diffusion Model Training",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Wang",
        "Mingjia Shi",
        "Yukun Zhou",
        "Zekai Li",
        "Zhihang Yuan",
        "Yuzhang Shang",
        "Xiaojiang Peng",
        "Hanwang Zhang",
        "Yang You"
      ],
      "abstract": "Training diffusion models is always a computation-intensive task. In this\npaper, we introduce a novel speed-up method for diffusion model training,\ncalled, which is based on a closer look at time steps. Our key findings are: i)\nTime steps can be empirically divided into acceleration, deceleration, and\nconvergence areas based on the process increment. ii) These time steps are\nimbalanced, with many concentrated in the convergence area. iii) The\nconcentrated steps provide limited benefits for diffusion training. To address\nthis, we design an asymmetric sampling strategy that reduces the frequency of\nsteps from the convergence area while increasing the sampling probability for\nsteps from other areas. Additionally, we propose a weighting strategy to\nemphasize the importance of time steps with rapid-change process increments. As\na plug-and-play and architecture-agnostic approach, SpeeD consistently achieves\n3-times acceleration across various diffusion architectures, datasets, and\ntasks. Notably, due to its simple design, our approach significantly reduces\nthe cost of diffusion model training with minimal overhead. Our research\nenables more researchers to train diffusion models at a lower cost.",
      "tldr_zh": "本研究发现，扩散模型（diffusion models）的训练过程因时间步（time steps）的不平衡分布而计算密集：时间步可分为加速（acceleration）、减速（deceleration）和收敛（convergence）区域，其中收敛区域步骤众多但贡献有限。针对此问题，作者提出SpeeD方法，包括不对称采样策略（asymmetric sampling strategy）来减少收敛区域的采样频率并增加其他区域的概率，以及加权策略（weighting strategy）来强调快速变化过程增量的步骤。实验结果显示，SpeeD作为即插即用（plug-and-play）和架构无关（architecture-agnostic）的方案，能在各种扩散架构、数据集和任务上实现3倍加速，同时显著降低训练成本，几乎无额外开销，从而使更多研究者能更经济地训练扩散模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17403v3",
      "published_date": "2024-05-27 17:51:36 UTC",
      "updated_date": "2025-03-25 08:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:27:14.568609"
    },
    {
      "arxiv_id": "2405.17533v1",
      "title": "PAE: LLM-based Product Attribute Extraction for E-Commerce Fashion Trends",
      "title_zh": "翻译失败",
      "authors": [
        "Apurva Sinha",
        "Ekta Gujral"
      ],
      "abstract": "Product attribute extraction is an growing field in e-commerce business, with\nseveral applications including product ranking, product recommendation, future\nassortment planning and improving online shopping customer experiences.\nUnderstanding the customer needs is critical part of online business,\nspecifically fashion products. Retailers uses assortment planning to determine\nthe mix of products to offer in each store and channel, stay responsive to\nmarket dynamics and to manage inventory and catalogs. The goal is to offer the\nright styles, in the right sizes and colors, through the right channels. When\nshoppers find products that meet their needs and desires, they are more likely\nto return for future purchases, fostering customer loyalty. Product attributes\nare a key factor in assortment planning. In this paper we present PAE, a\nproduct attribute extraction algorithm for future trend reports consisting text\nand images in PDF format. Most existing methods focus on attribute extraction\nfrom titles or product descriptions or utilize visual information from existing\nproduct images. Compared to the prior works, our work focuses on attribute\nextraction from PDF files where upcoming fashion trends are explained. This\nwork proposes a more comprehensive framework that fully utilizes the different\nmodalities for attribute extraction and help retailers to plan the assortment\nin advance. Our contributions are three-fold: (a) We develop PAE, an efficient\nframework to extract attributes from unstructured data (text and images); (b)\nWe provide catalog matching methodology based on BERT representations to\ndiscover the existing attributes using upcoming attribute values; (c) We\nconduct extensive experiments with several baselines and show that PAE is an\neffective, flexible and on par or superior (avg 92.5% F1-Score) framework to\nexisting state-of-the-art for attribute value extraction task.",
      "tldr_zh": "这篇论文提出了 PAE，一种基于 LLM 的产品属性提取框架，旨在从电子商务时尚趋势的 PDF 文件（包含文本和图像）中提取关键属性，以支持产品排名、推荐和库存规划。PAE 框架充分利用多模态数据，并引入基于 BERT 的目录匹配方法，来发现和匹配现有属性值。实验结果显示，PAE 在属性值提取任务中平均 F1-Score 达到 92.5%，比现有方法更有效，帮助零售商提前优化产品组合。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Attribute Extraction, PDF files, Bert Embedding, Hashtag, Large\n  Language Model (LLM), Text and Images",
      "pdf_url": "http://arxiv.org/pdf/2405.17533v1",
      "published_date": "2024-05-27 17:50:25 UTC",
      "updated_date": "2024-05-27 17:50:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:27:28.897805"
    },
    {
      "arxiv_id": "2405.17399v2",
      "title": "Transformers Can Do Arithmetic with the Right Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Sean McLeish",
        "Arpit Bansal",
        "Alex Stein",
        "Neel Jain",
        "John Kirchenbauer",
        "Brian R. Bartoldson",
        "Bhavya Kailkhura",
        "Abhinav Bhatele",
        "Jonas Geiping",
        "Avi Schwarzschild",
        "Tom Goldstein"
      ],
      "abstract": "The poor performance of transformers on arithmetic tasks seems to stem in\nlarge part from their inability to keep track of the exact position of each\ndigit inside of a large span of digits. We mend this problem by adding an\nembedding to each digit that encodes its position relative to the start of the\nnumber. In addition to the boost these embeddings provide on their own, we show\nthat this fix enables architectural modifications such as input injection and\nrecurrent layers to improve performance even further.\n  With positions resolved, we can study the logical extrapolation ability of\ntransformers. Can they solve arithmetic problems that are larger and more\ncomplex than those in their training data? We find that training on only 20\ndigit numbers with a single GPU for one day, we can reach state-of-the-art\nperformance, achieving up to 99% accuracy on 100 digit addition problems.\nFinally, we show that these gains in numeracy also unlock improvements on other\nmulti-step reasoning tasks including sorting and multiplication.",
      "tldr_zh": "该研究发现，Transformers在算术任务上的表现不佳，主要源于无法精确跟踪数字在序列中的位置，因此提出为每个数字添加相对位置嵌入(embeddings)来解决这一问题。这种方法不仅自身提升了性能，还支持输入注入和循环层等架构修改，进一步优化了模型。实验结果显示，通过在单个GPU上训练一天仅20位数字的加法，模型在100位加法问题上达到99%的准确率，实现了state-of-the-art性能。这些改进还扩展到其他多步推理任务，如排序和乘法，提升了Transformers的整体逻辑外推能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17399v2",
      "published_date": "2024-05-27 17:49:18 UTC",
      "updated_date": "2024-12-23 12:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:27:41.717487"
    },
    {
      "arxiv_id": "2405.17398v5",
      "title": "Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability",
      "title_zh": "翻译失败",
      "authors": [
        "Shenyuan Gao",
        "Jiazhi Yang",
        "Li Chen",
        "Kashyap Chitta",
        "Yihang Qiu",
        "Andreas Geiger",
        "Jun Zhang",
        "Hongyang Li"
      ],
      "abstract": "World models can foresee the outcomes of different actions, which is of\nparamount importance for autonomous driving. Nevertheless, existing driving\nworld models still have limitations in generalization to unseen environments,\nprediction fidelity of critical details, and action controllability for\nflexible application. In this paper, we present Vista, a generalizable driving\nworld model with high fidelity and versatile controllability. Based on a\nsystematic diagnosis of existing methods, we introduce several key ingredients\nto address these limitations. To accurately predict real-world dynamics at high\nresolution, we propose two novel losses to promote the learning of moving\ninstances and structural information. We also devise an effective latent\nreplacement approach to inject historical frames as priors for coherent\nlong-horizon rollouts. For action controllability, we incorporate a versatile\nset of controls from high-level intentions (command, goal point) to low-level\nmaneuvers (trajectory, angle, and speed) through an efficient learning\nstrategy. After large-scale training, the capabilities of Vista can seamlessly\ngeneralize to different scenarios. Extensive experiments on multiple datasets\nshow that Vista outperforms the most advanced general-purpose video generator\nin over 70% of comparisons and surpasses the best-performing driving world\nmodel by 55% in FID and 27% in FVD. Moreover, for the first time, we utilize\nthe capacity of Vista itself to establish a generalizable reward for real-world\naction evaluation without accessing the ground truth actions.",
      "tldr_zh": "该论文提出Vista，一种通用驾驶世界模型（world models），旨在提升自动驾驶的预测泛化性、细节保真度（high fidelity）和多功能行动可控性（versatile controllability）。为了解决现有方法的局限，作者引入两种新型损失函数（losses）来优化移动实例和结构信息的学习，并设计潜变量替换方法（latent replacement approach）以注入历史帧作为先验，确保长时段预测的连贯性；同时，整合从高层意图（如命令、目标点）到低层操作（如轨迹、角度和速度）的控制策略，通过高效学习实现灵活应用。实验结果显示，Vista在多个数据集上超越最先进通用视频生成器在70%以上的比较中，并在FID上提高55%、FVD上提高27%；此外，首次利用Vista自身能力建立无需地面真实动作的泛化奖励，用于真实世界行动评估。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024. Code and model: https://github.com/OpenDriveLab/Vista,\n  demo page: https://vista-demo.github.io",
      "pdf_url": "http://arxiv.org/pdf/2405.17398v5",
      "published_date": "2024-05-27 17:49:15 UTC",
      "updated_date": "2024-10-28 05:53:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:27:54.479538"
    },
    {
      "arxiv_id": "2405.17386v1",
      "title": "MindMerger: Efficient Boosting LLM Reasoning in non-English Languages",
      "title_zh": "MindMerger：高效提升非英语语言中LLM推理",
      "authors": [
        "Zixian Huang",
        "Wenhao Zhu",
        "Gong Cheng",
        "Lei Li",
        "Fei Yuan"
      ],
      "abstract": "Reasoning capabilities are crucial for Large Language Models (LLMs), yet a\nnotable gap exists between English and non-English languages. To bridge this\ndisparity, some works fine-tune LLMs to relearn reasoning capabilities in\nnon-English languages, while others replace non-English inputs with an external\nmodel's outputs such as English translation text to circumvent the challenge of\nLLM understanding non-English. Unfortunately, these methods often underutilize\nthe built-in skilled reasoning and useful language understanding capabilities\nof LLMs. In order to better utilize the minds of reasoning and language\nunderstanding in LLMs, we propose a new method, namely MindMerger, which merges\nLLMs with the external language understanding capabilities from multilingual\nmodels to boost the multilingual reasoning performance. Furthermore, a two-step\ntraining scheme is introduced to first train to embeded the external\ncapabilities into LLMs and then train the collaborative utilization of the\nexternal capabilities and the built-in capabilities in LLMs. Experiments on\nthree multilingual reasoning datasets and a language understanding dataset\ndemonstrate that MindMerger consistently outperforms all baselines, especially\nin low-resource languages. Without updating the parameters of LLMs, the average\naccuracy improved by 6.7% and 8.0% across all languages and low-resource\nlanguages on the MGSM dataset, respectively.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 在非英语语言的推理能力差距，提出了 MindMerger 方法，通过将 LLMs 与外部多语言模型的语言理解能力合并，来更高效地提升多语言推理性能。MindMerger 采用一个两步训练方案：首先将外部能力嵌入 LLMs，然后训练 LLMs 协作利用内置和外部能力，避免了直接微调或翻译绕行策略的局限。实验结果显示，在三个多语言推理数据集（如 MGSM）和一个语言理解数据集上，MindMerger 优于所有基线，尤其在低资源语言中，平均准确率分别提高了 6.7% 和 8.0%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17386v1",
      "published_date": "2024-05-27 17:41:54 UTC",
      "updated_date": "2024-05-27 17:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:28:16.835200"
    },
    {
      "arxiv_id": "2405.17372v3",
      "title": "BehaviorGPT: Smart Agent Simulation for Autonomous Driving with Next-Patch Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zikang Zhou",
        "Haibo Hu",
        "Xinhong Chen",
        "Jianping Wang",
        "Nan Guan",
        "Kui Wu",
        "Yung-Hui Li",
        "Yu-Kai Huang",
        "Chun Jason Xue"
      ],
      "abstract": "Simulating realistic behaviors of traffic agents is pivotal for efficiently\nvalidating the safety of autonomous driving systems. Existing data-driven\nsimulators primarily use an encoder-decoder architecture to encode the\nhistorical trajectories before decoding the future. However, the heterogeneity\nbetween encoders and decoders complicates the models, and the manual separation\nof historical and future trajectories leads to low data utilization. Given\nthese limitations, we propose BehaviorGPT, a homogeneous and fully\nautoregressive Transformer designed to simulate the sequential behavior of\nmultiple agents. Crucially, our approach discards the traditional separation\nbetween \"history\" and \"future\" by modeling each time step as the \"current\" one\nfor motion generation, leading to a simpler, more parameter- and data-efficient\nagent simulator. We further introduce the Next-Patch Prediction Paradigm (NP3)\nto mitigate the negative effects of autoregressive modeling, in which models\nare trained to reason at the patch level of trajectories and capture long-range\nspatial-temporal interactions. Despite having merely 3M model parameters,\nBehaviorGPT won first place in the 2024 Waymo Open Sim Agents Challenge with a\nrealism score of 0.7473 and a minADE score of 1.4147, demonstrating its\nexceptional performance in traffic agent simulation.",
      "tldr_zh": "该研究提出BehaviorGPT，一种同构的全自回归Transformer框架，用于模拟自动驾驶系统中多个代理的真实行为，解决了传统编码器-解码器架构的异构复杂性和数据利用率低的问题。通过将每个时间步视为“当前”状态生成运动，BehaviorGPT实现了更简单、高效的参数和数据使用，并引入Next-Patch Prediction Paradigm (NP3)来在轨迹patch级别上推理，捕获长距离时空交互。实验结果显示，尽管模型仅拥有3M参数，BehaviorGPT在2024 Waymo Open Sim Agents Challenge中获得第一名，现实分数达0.7473，minADE分数为1.4147，证明了其在交通代理模拟中的卓越性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17372v3",
      "published_date": "2024-05-27 17:28:25 UTC",
      "updated_date": "2024-11-11 14:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:28:17.562343"
    },
    {
      "arxiv_id": "2405.17358v3",
      "title": "Rethinking Transformers in Solving POMDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Lu",
        "Ruizhe Shi",
        "Yuyao Liu",
        "Kaizhe Hu",
        "Simon S. Du",
        "Huazhe Xu"
      ],
      "abstract": "Sequential decision-making algorithms such as reinforcement learning (RL) in\nreal-world scenarios inevitably face environments with partial observability.\nThis paper scrutinizes the effectiveness of a popular architecture, namely\nTransformers, in Partially Observable Markov Decision Processes (POMDPs) and\nreveals its theoretical limitations. We establish that regular languages, which\nTransformers struggle to model, are reducible to POMDPs. This poses a\nsignificant challenge for Transformers in learning POMDP-specific inductive\nbiases, due to their lack of inherent recurrence found in other models like\nRNNs. This paper casts doubt on the prevalent belief in Transformers as\nsequence models for RL and proposes to introduce a point-wise recurrent\nstructure. The Deep Linear Recurrent Unit (LRU) emerges as a well-suited\nalternative for Partially Observable RL, with empirical results highlighting\nthe sub-optimal performance of the Transformer and considerable strength of\nLRU.",
      "tldr_zh": "这篇论文重新审视了 Transformers 在部分可观测马尔可夫决策过程 (POMDPs) 中的有效性，并揭示其理论局限性，因为 Transformers 难以建模正则语言，而这些语言可归约到 POMDPs，导致其在学习 POMDP 的归纳偏差方面缺乏像 RNNs 那样的固有循环结构。论文质疑 Transformers 在强化学习 (RL) 中的流行应用，并提出引入点式循环结构作为改进方案。作者推荐 Deep Linear Recurrent Unit (LRU) 作为 POMDPs 的更适合替代，并通过实证实验证明 LRU 在部分可观测 RL 中表现出显著优势，而 Transformers 的性能次优。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024; references added; typos fixed",
      "pdf_url": "http://arxiv.org/pdf/2405.17358v3",
      "published_date": "2024-05-27 17:02:35 UTC",
      "updated_date": "2024-05-30 07:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:28:30.306098"
    },
    {
      "arxiv_id": "2405.17346v1",
      "title": "Prompt Optimization with Human Feedback",
      "title_zh": "基于人类反馈的提示优化",
      "authors": [
        "Xiaoqiang Lin",
        "Zhongxiang Dai",
        "Arun Verma",
        "See-Kiong Ng",
        "Patrick Jaillet",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable performances in\nvarious tasks. However, the performance of LLMs heavily depends on the input\nprompt, which has given rise to a number of recent works on prompt\noptimization. However, previous works often require the availability of a\nnumeric score to assess the quality of every prompt. Unfortunately, when a\nhuman user interacts with a black-box LLM, attaining such a score is often\ninfeasible and unreliable. Instead, it is usually significantly easier and more\nreliable to obtain preference feedback from a human user, i.e., showing the\nuser the responses generated from a pair of prompts and asking the user which\none is preferred. Therefore, in this paper, we study the problem of prompt\noptimization with human feedback (POHF), in which we aim to optimize the prompt\nfor a black-box LLM using only human preference feedback. Drawing inspiration\nfrom dueling bandits, we design a theoretically principled strategy to select a\npair of prompts to query for preference feedback in every iteration, and hence\nintroduce our algorithm named automated POHF (APOHF). We apply our APOHF\nalgorithm to various tasks, including optimizing user instructions, prompt\noptimization for text-to-image generative models, and response optimization\nwith human feedback (i.e., further refining the response using a variant of our\nAPOHF). The results demonstrate that our APOHF can efficiently find a good\nprompt using a small number of preference feedback instances. Our code can be\nfound at \\url{https://github.com/xqlin98/APOHF}.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 的提示优化问题，指出传统方法依赖数值评分不可靠，转而使用人类偏好反馈（即比较两个提示的响应并让用户选择偏好哪一个）。他们提出了一种基于 dueling bandits 的算法 APOHF，通过策略性地选择提示对来查询反馈，从而高效优化提示。实验结果显示，APOHF 在优化用户指令、文本到图像生成模型的提示以及响应优化等任务中，仅需少量反馈即可获得高质量提示，并提供了开源代码支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint, 18 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.17346v1",
      "published_date": "2024-05-27 16:49:29 UTC",
      "updated_date": "2024-05-27 16:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:28:41.478813"
    },
    {
      "arxiv_id": "2405.17345v2",
      "title": "Exploring and steering the moral compass of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Tlaie"
      ],
      "abstract": "Large Language Models (LLMs) have become central to advancing automation and\ndecision-making across various sectors, raising significant ethical questions.\nThis study proposes a comprehensive comparative analysis of the most advanced\nLLMs to assess their moral profiles. We subjected several state-of-the-art\nmodels to a selection of ethical dilemmas and found that all the proprietary\nones are mostly utilitarian and all of the open-weights ones align mostly with\nvalues-based ethics. Furthermore, when using the Moral Foundations\nQuestionnaire, all models we probed - except for Llama 2-7B - displayed a\nstrong liberal bias. Lastly, in order to causally intervene in one of the\nstudied models, we propose a novel similarity-specific activation steering\ntechnique. Using this method, we were able to reliably steer the model's moral\ncompass to different ethical schools. All of these results showcase that there\nis an ethical dimension in already deployed LLMs, an aspect that is generally\noverlooked.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)的道德特征，通过对多种先进模型的比较分析，发现专有模型多倾向于功利主义(utilitarian)伦理，而开源模型则更偏向基于价值观(values-based ethics)的伦理。研究使用 Moral Foundations Questionnaire 测试，结果显示除 Llama 2-7B 外，大多数模型表现出强烈的自由主义偏见。论文提出了一种新型的相似性特定激活引导(activation steering)技术，能够可靠地干预模型的道德倾向，使其转向不同伦理学派。这些发现突出了已部署 LLMs 中的伦理维度，这一点通常被忽略。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17345v2",
      "published_date": "2024-05-27 16:49:22 UTC",
      "updated_date": "2024-06-06 11:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:28:54.206835"
    },
    {
      "arxiv_id": "2405.17337v1",
      "title": "Cost-efficient Knowledge-based Question Answering with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junnan Dong",
        "Qinggang Zhang",
        "Chuang Zhou",
        "Hao Chen",
        "Daochen Zha",
        "Xiao Huang"
      ],
      "abstract": "Knowledge-based question answering (KBQA) is widely used in many scenarios\nthat necessitate domain knowledge. Large language models (LLMs) bring\nopportunities to KBQA, while their costs are significantly higher and absence\nof domain-specific knowledge during pre-training. We are motivated to combine\nLLMs and prior small models on knowledge graphs (KGMs) for both inferential\naccuracy and cost saving. However, it remains challenging since accuracy and\ncost are not readily combined in the optimization as two distinct metrics. It\nis also laborious for model selection since different models excel in diverse\nknowledge. To this end, we propose Coke, a novel cost-efficient strategy for\nKBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimize\ncalls to LLMs within limited budgets. We first formulate the accuracy\nexpectation with a cluster-level Thompson Sampling for either KGMs or LLMs. A\ncontext-aware policy is optimized to further distinguish the expert model\nsubject to the question semantics. The overall decision is bounded by the cost\nregret according to historical expenditure on failures. Extensive experiments\nshowcase the superior performance of Coke, which moves the Pareto frontier with\nup to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy on\nthe benchmark datasets.",
      "tldr_zh": "本研究针对基于知识的问题回答（KBQA）提出了一种成本高效策略Coke，将大语言模型（LLMs）与知识图谱模型（KGMs）结合，以平衡推理准确性和调用成本。Coke将问题建模为定制的多臂老虎机（multi-armed bandit）问题，利用聚类级别的Thompson Sampling制定准确性期望，并优化上下文感知政策来选择最合适的专家模型，同时通过历史失败支出控制成本遗憾。实验结果显示，在基准数据集上，Coke比基线方法节省高达20.89%的GPT-4费用，同时实现了2.74%的准确率提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17337v1",
      "published_date": "2024-05-27 16:37:34 UTC",
      "updated_date": "2024-05-27 16:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:29:05.463720"
    },
    {
      "arxiv_id": "2406.01608v1",
      "title": "Detecting Deceptive Dark Patterns in E-commerce Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Arya Ramteke",
        "Sankalp Tembhurne",
        "Gunesh Sonawane",
        "Ratnmala N. Bhimanpallewar"
      ],
      "abstract": "Dark patterns are deceptive user interfaces employed by e-commerce websites\nto manipulate user's behavior in a way that benefits the website, often\nunethically. This study investigates the detection of such dark patterns.\nExisting solutions include UIGuard, which uses computer vision and natural\nlanguage processing, and approaches that categorize dark patterns based on\ndetectability or utilize machine learning models trained on datasets. We\npropose combining web scraping techniques with fine-tuned BERT language models\nand generative capabilities to identify dark patterns, including outliers. The\napproach scrapes textual content, feeds it into the BERT model for detection,\nand leverages BERT's bidirectional analysis and generation abilities. The study\nbuilds upon research on automatically detecting and explaining dark patterns,\naiming to raise awareness and protect consumers.",
      "tldr_zh": "本研究探讨了 e-commerce 平台上常见的欺骗性用户界面 Dark patterns，这些模式通过操纵用户行为为网站带来不道德利益。现有解决方案包括 UIGuard（利用计算机视觉和自然语言处理）以及基于机器学习模型的分类方法，而本文提出了一种结合 web scraping 技术与 fine-tuned BERT 语言模型的新方法。 specifically，该方法通过刮取文本内容输入 BERT 进行检测，并利用其双向分析和生成能力来识别包括异常（outliers）在内的 Dark patterns。实验结果表明，此方法有助于自动检测和解释这些模式，从而提高消费者意识并提供更好的保护。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.01608v1",
      "published_date": "2024-05-27 16:32:40 UTC",
      "updated_date": "2024-05-27 16:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:29:18.109866"
    },
    {
      "arxiv_id": "2405.17324v1",
      "title": "Leveraging Offline Data in Linear Latent Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Chinmaya Kausik",
        "Kevin Tan",
        "Ambuj Tewari"
      ],
      "abstract": "Sequential decision-making domains such as recommender systems, healthcare\nand education often have unobserved heterogeneity in the population that can be\nmodeled using latent bandits $-$ a framework where an unobserved latent state\ndetermines the model for a trajectory. While the latent bandit framework is\ncompelling, the extent of its generality is unclear. We first address this by\nestablishing a de Finetti theorem for decision processes, and show that\n$\\textit{every}$ exchangeable and coherent stateless decision process is a\nlatent bandit. The latent bandit framework lends itself particularly well to\nonline learning with offline datasets, a problem of growing interest in\nsequential decision-making. One can leverage offline latent bandit data to\nlearn a complex model for each latent state, so that an agent can simply learn\nthe latent state online to act optimally. We focus on a linear model for a\nlatent bandit with $d_A$-dimensional actions, where the latent states lie in an\nunknown $d_K$-dimensional subspace for $d_K \\ll d_A$. We present SOLD, a novel\nprincipled method to learn this subspace from short offline trajectories with\nguarantees. We then provide two methods to leverage this subspace online:\nLOCAL-UCB and ProBALL-UCB. We demonstrate that LOCAL-UCB enjoys $\\tilde\nO(\\min(d_A\\sqrt{T}, d_K\\sqrt{T}(1+\\sqrt{d_AT/d_KN})))$ regret guarantees, where\nthe effective dimension is lower when the size $N$ of the offline dataset is\nlarger. ProBALL-UCB enjoys a slightly weaker guarantee, but is more practical\nand computationally efficient. Finally, we establish the efficacy of our\nmethods using experiments on both synthetic data and real-life movie\nrecommendation data from MovieLens.",
      "tldr_zh": "本研究证明了所有可交换和连贯的无状态决策过程都可以建模为潜在带权模型（latent bandits），用于处理顺序决策领域（如推荐系统、医疗和教育）中的未观察异质性。作者提出SOLD方法，从短离线轨迹中学习线性潜在带权模型的低维子空间（维度d_K远小于动作维度d_A），并提供理论保证。随后，引入LOCAL-UCB和ProBALL-UCB两种在线算法，其中LOCAL-UCB实现Õ(min(d_A √T, d_K √T(1+√(d_A T / d_K N))))的遗憾界，当离线数据集大小N增大时，遗憾维度有效降低。实验在合成数据和MovieLens真实推荐数据上验证了这些方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages. 14 pages for main paper, 26 pages for references + appendix",
      "pdf_url": "http://arxiv.org/pdf/2405.17324v1",
      "published_date": "2024-05-27 16:23:34 UTC",
      "updated_date": "2024-05-27 16:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:29:30.487230"
    },
    {
      "arxiv_id": "2405.17293v1",
      "title": "Efficient Ensembles Improve Training Data Attribution",
      "title_zh": "高效集成提升训练数据归因",
      "authors": [
        "Junwei Deng",
        "Ting-Wei Li",
        "Shichang Zhang",
        "Jiaqi Ma"
      ],
      "abstract": "Training data attribution (TDA) methods aim to quantify the influence of\nindividual training data points on the model predictions, with broad\napplications in data-centric AI, such as mislabel detection, data selection,\nand copyright compensation. However, existing methods in this field, which can\nbe categorized as retraining-based and gradient-based, have struggled with the\ntrade-off between computational efficiency and attribution efficacy.\nRetraining-based methods can accurately attribute complex non-convex models but\nare computationally prohibitive, while gradient-based methods are efficient but\noften fail for non-convex models. Recent research has shown that augmenting\ngradient-based methods with ensembles of multiple independently trained models\ncan achieve significantly better attribution efficacy. However, this approach\nremains impractical for very large-scale applications.\n  In this work, we discover that expensive, fully independent training is\nunnecessary for ensembling the gradient-based methods, and we propose two\nefficient ensemble strategies, DROPOUT ENSEMBLE and LORA ENSEMBLE, alternative\nto naive independent ensemble. These strategies significantly reduce training\ntime (up to 80%), serving time (up to 60%), and space cost (up to 80%) while\nmaintaining similar attribution efficacy to the naive independent ensemble. Our\nextensive experimental results demonstrate that the proposed strategies are\neffective across multiple TDA methods on diverse datasets and models, including\ngenerative settings, significantly advancing the Pareto frontier of TDA methods\nwith better computational efficiency and attribution efficacy.",
      "tldr_zh": "训练数据归因(TDA)方法用于量化单个训练数据点对模型预测的影响，但现有基于重训和基于梯度的方法在计算效率和归因效果之间存在权衡。作者发现无需昂贵的独立模型训练，而是提出两种高效集成策略：DROPOUT ENSEMBLE和LORA ENSEMBLE，以显著减少训练时间（高达80%）、服务时间（高达60%）和空间成本（高达80%），同时保持与独立集成相似的归因效果。实验在多种TDA方法、数据集和模型（包括生成模型）上验证了这些策略的有效性，显著提升了TDA方法的计算效率和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17293v1",
      "published_date": "2024-05-27 15:58:34 UTC",
      "updated_date": "2024-05-27 15:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:29:43.510842"
    },
    {
      "arxiv_id": "2405.17287v2",
      "title": "Opinion-Guided Reinforcement Learning",
      "title_zh": "基于意见的强化学习",
      "authors": [
        "Kyanna Dagenais",
        "Istvan David"
      ],
      "abstract": "Human guidance is often desired in reinforcement learning to improve the\nperformance of the learning agent. However, human insights are often mere\nopinions and educated guesses rather than well-formulated arguments. While\nopinions are subject to uncertainty, e.g., due to partial informedness or\nignorance about a problem, they also emerge earlier than hard evidence can be\nproduced. Thus, guiding reinforcement learning agents by way of opinions offers\nthe potential for more performant learning processes, but comes with the\nchallenge of modeling and managing opinions in a formal way. In this article,\nwe present a method to guide reinforcement learning agents through opinions. To\nthis end, we provide an end-to-end method to model and manage advisors'\nopinions. To assess the utility of the approach, we evaluate it with synthetic\n(oracle) and human advisors, at different levels of uncertainty, and under\nmultiple advice strategies. Our results indicate that opinions, even if\nuncertain, improve the performance of reinforcement learning agents, resulting\nin higher rewards, more efficient exploration, and a better reinforced policy.\nAlthough we demonstrate our approach through a two-dimensional topological\nrunning example, our approach is applicable to complex problems with higher\ndimensions as well.",
      "tldr_zh": "本论文提出了一种Opinion-Guided Reinforcement Learning方法，利用人类意见来指导强化学习代理的表现，尽管这些意见可能因不确定性（如部分信息或无知）而不可靠。该方法提供了一个端到端框架，用于建模和管理顾问的意见，包括合成（oracle）和人类顾问在不同不确定性和建议策略下的评估。实验结果表明，即使意见不确定，也能显著提升代理的奖励、更高效的探索以及更好的强化策略；尽管以二维拓扑示例演示，该方法适用于更高维度的复杂问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17287v2",
      "published_date": "2024-05-27 15:52:27 UTC",
      "updated_date": "2024-08-03 17:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:30:05.443821"
    },
    {
      "arxiv_id": "2405.17284v2",
      "title": "An NLP Crosswalk Between the Common Core State Standards and NAEP Item Specifications",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Camilli"
      ],
      "abstract": "Natural language processing (NLP) is rapidly developing for applications in\neducational assessment. In this paper, I describe an NLP-based procedure that\ncan be used to support subject matter experts in establishing a crosswalk\nbetween item specifications and content standards. This paper extends recent\nwork by proposing and demonstrating the use of multivariate similarity based on\nembedding vectors for sentences or texts. In particular, a hybrid regression\nprocedure is demonstrated for establishing the match of each content standard\nto multiple item specifications. The procedure is used to evaluate the match of\nthe Common Core State Standards (CCSS) for mathematics at grade 4 to the\ncorresponding item specifications for the 2026 National Assessment of\nEducational Progress (NAEP).",
      "tldr_zh": "这篇论文提出了一种基于 Natural Language Processing (NLP) 的程序，用于辅助专家建立内容标准与项目规范之间的交叉对照，扩展了现有工作以支持教育评估应用。该程序采用基于嵌入向量的多变量相似性，并演示了混合回归方法来匹配每个内容标准与多个项目规范。具体应用于评估 Common Core State Standards (CCSS) 数学年级 4 与 2026 National Assessment of Educational Progress (NAEP) 项目规范的匹配度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Deleted repeated sections. Corrected proper nouns. Corrected type in\n  CCSS sentences",
      "pdf_url": "http://arxiv.org/pdf/2405.17284v2",
      "published_date": "2024-05-27 15:47:46 UTC",
      "updated_date": "2024-05-31 21:30:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:30:06.161827"
    },
    {
      "arxiv_id": "2405.17279v1",
      "title": "Socially-Aware Shared Control Navigation for Assistive Mobile Robots in the Built Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Xu",
        "Qianwei Wang",
        "Vineet Kamat",
        "Carol Menassa"
      ],
      "abstract": "As the number of Persons with Disabilities (PWD), particularly those with one\nor more physical impairments, increases, there is an increasing demand for\nassistive robotic technologies that can support independent mobility in the\nbuilt environment and reduce the burden on caregivers. Current assistive\nmobility platforms (e.g., robotic wheelchairs) often fail to incorporate user\npreferences and control, leading to reduced trust and efficiency. Existing\nshared control algorithms do not allow the incorporation of the user control\npreferences inside the navigation framework or the path planning algorithm. In\naddition, existing dynamic local planner algorithms for robotic wheelchairs do\nnot take into account the social spaces of people, potentially leading such\nplatforms to infringe upon these areas and cause discomfort. To address these\nconcerns, this work introduces a novel socially-aware shared autonomy-based\nnavigation system for assistive mobile robotic platforms.\n  Our navigation framework comprises a Global Planner and a Local Planner. To\nimplement the Global Planner, the proposed approach introduces a novel User\nPreference Field (UPF) theory within its global planning framework, explicitly\nacknowledging user preferences to adeptly navigate away from congested areas.\nFor the Local Planner, we propose a Socially-aware Shared Control-based Model\nPredictive Control with Dynamic Control Barrier Function (SS-MPC-DCBF) to\nadjust movements in real-time, integrating user preferences for safer, more\nautonomous navigation. Evaluation results show that our Global Planner aligns\nclosely with user preferences compared to baselines, and our Local Planner\ndemonstrates enhanced safety and efficiency in dynamic and static scenarios.\nThis integrated approach fosters trust and autonomy, crucial for the acceptance\nof assistive mobility technologies in the built environment.",
      "tldr_zh": "这篇论文针对残疾人辅助机器人（如机器人轮椅）的导航问题，提出了一种新型社会感知共享自治导航系统，以整合用户偏好并避免侵犯社交空间。系统包括全局规划器，利用 User Preference Field (UPF) 理论来避开拥挤区域，以及局部规划器，通过 Socially-aware Shared Control-based Model Predictive Control with Dynamic Control Barrier Function (SS-MPC-DCBF) 实现实时运动调整。实验结果显示，该框架比基线方法更符合用户偏好，并在动态和静态环境中提升了安全性和效率，从而增强了对辅助移动技术的信任和接受度。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "42 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.17279v1",
      "published_date": "2024-05-27 15:40:34 UTC",
      "updated_date": "2024-05-27 15:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:30:19.782819"
    },
    {
      "arxiv_id": "2405.17527v3",
      "title": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Zhou",
        "Yuezhou Ma",
        "Haixu Wu",
        "Haowen Wang",
        "Mingsheng Long"
      ],
      "abstract": "Deep models have recently emerged as a promising tool to solve partial\ndifferential equations (PDEs), known as neural PDE solvers. While neural\nsolvers trained from either simulation data or physics-informed loss can solve\nPDEs reasonably well, they are mainly restricted to a few instances of PDEs,\ne.g. a certain equation with a limited set of coefficients. This limits the\ngeneralization of neural solvers to diverse PDEs, impeding them from being\npractical surrogate models for numerical solvers. In this paper, we present the\nUniversal PDE Solver (Unisolver) capable of solving a wide scope of PDEs by\ntraining a novel Transformer model on diverse data and conditioned on diverse\nPDEs. Instead of purely scaling up data and parameters, Unisolver stems from\nthe theoretical analysis of the PDE-solving process. Our key finding is that a\nPDE solution is fundamentally under the control of a series of PDE components,\ne.g. equation symbols, coefficients, and boundary conditions. Inspired by the\nmathematical structure of PDEs, we define a complete set of PDE components and\nflexibly embed them as domain-wise (e.g. equation symbols) and point-wise (e.g.\nboundaries) conditions for Transformer PDE solvers. Integrating physical\ninsights with recent Transformer advances, Unisolver achieves consistent\nstate-of-the-art results on three challenging large-scale benchmarks, showing\nimpressive performance gains and favorable PDE generalizability.",
      "tldr_zh": "本论文提出 Unisolver，一种基于 Transformer 的通用偏微分方程 (PDE) 求解器，能够处理广泛的 PDE 实例，而非局限于特定方程或系数。Unisolver 通过对 PDE 求解过程的理论分析，将方程符号、系数和边界条件等组件定义为完整的条件集，并以域级（如方程符号）和点级（如边界）方式嵌入模型中，结合物理洞见提升求解性能。在三个大型基准测试中，Unisolver 实现了最先进的结果，显著提高了准确性和 PDE 泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17527v3",
      "published_date": "2024-05-27 15:34:35 UTC",
      "updated_date": "2024-10-08 03:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:30:30.873521"
    },
    {
      "arxiv_id": "2405.17272v2",
      "title": "DPN: Decoupling Partition and Navigation for Neural Solvers of Min-max Vehicle Routing Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Zheng",
        "Shunyu Yao",
        "Zhenkun Wang",
        "Xialiang Tong",
        "Mingxuan Yuan",
        "Ke Tang"
      ],
      "abstract": "The min-max vehicle routing problem (min-max VRP) traverses all given\ncustomers by assigning several routes and aims to minimize the length of the\nlongest route. Recently, reinforcement learning (RL)-based sequential planning\nmethods have exhibited advantages in solving efficiency and optimality.\nHowever, these methods fail to exploit the problem-specific properties in\nlearning representations, resulting in less effective features for decoding\noptimal routes. This paper considers the sequential planning process of min-max\nVRPs as two coupled optimization tasks: customer partition for different routes\nand customer navigation in each route (i.e., partition and navigation). To\neffectively process min-max VRP instances, we present a novel attention-based\nPartition-and-Navigation encoder (P&N Encoder) that learns distinct embeddings\nfor partition and navigation. Furthermore, we utilize an inherent symmetry in\ndecoding routes and develop an effective agent-permutation-symmetric (APS) loss\nfunction. Experimental results demonstrate that the proposed\nDecoupling-Partition-Navigation (DPN) method significantly surpasses existing\nlearning-based methods in both single-depot and multi-depot min-max VRPs. Our\ncode is available at",
      "tldr_zh": "本论文针对 min-max vehicle routing problem (min-max VRP) 提出了一种新型神经求解器 DPN，该方法通过解耦客户分区和导航任务，优化路由规划以最小化最长路由长度。DPN 引入了基于注意力的 Partition-and-Navigation encoder (P&N Encoder)，用于学习分区和导航的独立嵌入，并设计了 agent-permutation-symmetric (APS) loss 函数来处理解码过程中的对称性问题。实验结果表明，DPN 在单仓库和多仓库 min-max VRP 场景下显著优于现有基于 reinforcement learning (RL) 的方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17272v2",
      "published_date": "2024-05-27 15:33:16 UTC",
      "updated_date": "2024-06-06 10:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:30:44.566696"
    },
    {
      "arxiv_id": "2405.17258v1",
      "title": "$\\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Runqian Wang",
        "Soumya Ghosh",
        "David Cox",
        "Diego Antognini",
        "Aude Oliva",
        "Rogerio Feris",
        "Leonid Karlinsky"
      ],
      "abstract": "Low-rank adapters (LoRA) and their variants are popular parameter-efficient\nfine-tuning (PEFT) techniques that closely match full model fine-tune\nperformance while requiring only a small number of additional parameters. These\nadditional LoRA parameters are specific to the base model being adapted. When\nthe base model needs to be deprecated and replaced with a new one, all the\nassociated LoRA modules need to be re-trained. Such re-training requires access\nto the data used to train the LoRA for the original base model. This is\nespecially problematic for commercial cloud applications where the LoRA modules\nand the base models are hosted by service providers who may not be allowed to\nhost proprietary client task data. To address this challenge, we propose\n$\\textit{Trans-LoRA}$ -- a novel method for lossless, nearly data-free transfer\nof LoRAs across base models. Our approach relies on synthetic data to transfer\nLoRA modules. Using large language models, we design a synthetic data generator\nto approximate the data-generating process of the $\\textit{observed}$ task data\nsubset. Training on the resulting synthetic dataset transfers LoRA modules to\nnew models. We show the effectiveness of our approach using both LLama and\nGemma model families. Our approach achieves lossless (mostly improved) LoRA\ntransfer between models within and across different base model families, and\neven between different PEFT methods, on a wide variety of tasks.",
      "tldr_zh": "本研究针对参数高效微调（PEFT）技术中的 Low-rank adapters (LoRA)，提出了一种无需原始数据的转移方法，即 $\\textit{Trans-LoRA}$，以解决更换基础模型时需重新训练 LoRA 模块的问题。$\\textit{Trans-LoRA}$ 通过利用大型语言模型生成合成数据来模拟任务数据分布，从而实现 LoRA 模块的无损转移。实验结果显示，该方法在 LLama 和 Gemma 模型家族之间、甚至不同 PEFT 方法间，都实现了高效转移，并在多种任务上表现出等效或改进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17258v1",
      "published_date": "2024-05-27 15:15:08 UTC",
      "updated_date": "2024-05-27 15:15:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:30:54.870716"
    },
    {
      "arxiv_id": "2405.17253v1",
      "title": "Gaussian Embedding of Temporal Networks",
      "title_zh": "时变网络的高斯嵌入",
      "authors": [
        "Raphaël Romero",
        "Jefrey Lijffijt",
        "Riccardo Rastelli",
        "Marco Corneli",
        "Tijl De Bie"
      ],
      "abstract": "Representing the nodes of continuous-time temporal graphs in a\nlow-dimensional latent space has wide-ranging applications, from prediction to\nvisualization. Yet, analyzing continuous-time relational data with timestamped\ninteractions introduces unique challenges due to its sparsity. Merely embedding\nnodes as trajectories in the latent space overlooks this sparsity, emphasizing\nthe need to quantify uncertainty around the latent positions. In this paper, we\npropose TGNE (\\textbf{T}emporal \\textbf{G}aussian \\textbf{N}etwork\n\\textbf{E}mbedding), an innovative method that bridges two distinct strands of\nliterature: the statistical analysis of networks via Latent Space Models\n(LSM)\\cite{Hoff2002} and temporal graph machine learning. TGNE embeds nodes as\npiece-wise linear trajectories of Gaussian distributions in the latent space,\ncapturing both structural information and uncertainty around the trajectories.\nWe evaluate TGNE's effectiveness in reconstructing the original graph and\nmodelling uncertainty. The results demonstrate that TGNE generates competitive\ntime-varying embedding locations compared to common baselines for\nreconstructing unobserved edge interactions based on observed edges.\nFurthermore, the uncertainty estimates align with the time-varying degree\ndistribution in the network, providing valuable insights into the temporal\ndynamics of the graph. To facilitate reproducibility, we provide an open-source\nimplementation of TGNE at \\url{https://github.com/aida-ugent/tgne}.",
      "tldr_zh": "本研究提出 TGNE（Temporal Gaussian Network Embedding）方法，用于在低维潜空间中表示连续时间时间网络的节点，解决数据稀疏性问题，通过将节点嵌入为高斯分布的逐段线性轨迹来捕获结构信息和不确定性。TGNE 结合了 Latent Space Models (LSM) 和 temporal graph machine learning 框架，实现了对时间动态的精确建模。实验结果显示，TGNE 在图重构任务中比基线模型更具竞争力，能够基于观察边准确预测未观察边，同时其不确定性估计与网络的时间变化度分布高度一致，提供对时间网络动态的宝贵洞见。该方法已开源，网址为 https://github.com/aida-ugent/tgne。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17253v1",
      "published_date": "2024-05-27 15:07:57 UTC",
      "updated_date": "2024-05-27 15:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:31:07.070982"
    },
    {
      "arxiv_id": "2405.17249v2",
      "title": "Assessing LLMs Suitability for Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Vasile Ionut Remus Iga",
        "Gheorghe Cosmin Silaghi"
      ],
      "abstract": "Recent work has shown the capability of Large Language Models (LLMs) to solve\ntasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in\nZero- or Few-Shot paradigms. However, they are known to hallucinate answers, or\noutput results in a non-deterministic manner, thus leading to wrongly reasoned\nresponses, even if they satisfy the user's demands. To highlight opportunities\nand challenges in knowledge graphs-related tasks, we experiment with three\ndistinguished LLMs, namely Mixtral-8x7b-Instruct-v0.1, GPT-3.5-Turbo-0125 and\nGPT-4o, on Knowledge Graph Completion for static knowledge graphs, using\nprompts constructed following the TELeR taxonomy, in Zero- and One-Shot\ncontexts, on a Task-Oriented Dialogue system use case. When evaluated using\nboth strict and flexible metrics measurement manners, our results show that\nLLMs could be fit for such a task if prompts encapsulate sufficient information\nand relevant examples.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在知识图谱完成（Knowledge Graph Completion）任务中的适用性，突出了其在Zero-Shot和One-Shot范式下的机会与挑战。研究团队实验了Mixtral-8x7b-Instruct-v0.1、GPT-3.5-Turbo-0125和GPT-4o，使用TELeR taxonomy构建的提示，针对静态知识图谱和任务导向对话系统进行测试。结果表明，当提示包含足够信息和相关示例时，LLMs在严格和灵活评估指标下表现出色，证明其适合此类任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at 18th International Conference on Neural-Symbolic Learning\n  and Reasoning, NESY 2024. Evaluating Mixtral-8x7b-Instruct-v0.1,\n  GPT-3.5-Turbo-0125 and GPT-4o for Knowledge Graph Completion task with\n  prompts formatted according to the TELeR taxonomy",
      "pdf_url": "http://arxiv.org/pdf/2405.17249v2",
      "published_date": "2024-05-27 15:04:50 UTC",
      "updated_date": "2024-07-18 09:48:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:31:19.694795"
    },
    {
      "arxiv_id": "2405.17245v1",
      "title": "Galaxy: A Resource-Efficient Collaborative Edge AI System for In-situ Transformer Inference",
      "title_zh": "Galaxy: 一种资源高效的协作边缘 AI",
      "authors": [
        "Shengyuan Ye",
        "Jiangsu Du",
        "Liekang Zeng",
        "Wenzhong Ou",
        "Xiaowen Chu",
        "Yutong Lu",
        "Xu Chen"
      ],
      "abstract": "Transformer-based models have unlocked a plethora of powerful intelligent\napplications at the edge, such as voice assistant in smart home. Traditional\ndeployment approaches offload the inference workloads to the remote cloud\nserver, which would induce substantial pressure on the backbone network as well\nas raise users' privacy concerns. To address that, in-situ inference has been\nrecently recognized for edge intelligence, but it still confronts significant\nchallenges stemming from the conflict between intensive workloads and limited\non-device computing resources. In this paper, we leverage our observation that\nmany edge environments usually comprise a rich set of accompanying trusted edge\ndevices with idle resources and propose Galaxy, a collaborative edge AI system\nthat breaks the resource walls across heterogeneous edge devices for efficient\nTransformer inference acceleration. Galaxy introduces a novel hybrid model\nparallelism to orchestrate collaborative inference, along with a\nheterogeneity-aware parallelism planning for fully exploiting the resource\npotential. Furthermore, Galaxy devises a tile-based fine-grained overlapping of\ncommunication and computation to mitigate the impact of tensor synchronizations\non inference latency under bandwidth-constrained edge environments. Extensive\nevaluation based on prototype implementation demonstrates that Galaxy\nremarkably outperforms state-of-the-art approaches under various edge\nenvironment setups, achieving up to 2.5x end-to-end latency reduction.",
      "tldr_zh": "该研究针对Transformer模型在边缘设备上的in-situ inference面临资源限制问题，提出Galaxy系统——一个资源高效的协作边缘AI框架，利用边缘环境中闲置的异构设备资源进行协作推理。Galaxy引入hybrid model parallelism和heterogeneity-aware parallelism planning来优化资源利用，并采用tile-based fine-grained overlapping技术减少通信延迟的影响。实验结果显示，Galaxy在各种边缘环境中比现有方法降低高达2.5倍的端到端延迟，提供了一种高效的边缘智能解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted by IEEE International Conference on Computer Communications\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17245v1",
      "published_date": "2024-05-27 15:01:04 UTC",
      "updated_date": "2024-05-27 15:01:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:31:31.341183"
    },
    {
      "arxiv_id": "2405.17243v2",
      "title": "Surprise-Adaptive Intrinsic Motivation for Unsupervised Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Adriana Hugessen",
        "Roger Creus Castanyer",
        "Faisal Mohamed",
        "Glen Berseth"
      ],
      "abstract": "Both entropy-minimizing and entropy-maximizing (curiosity) objectives for\nunsupervised reinforcement learning (RL) have been shown to be effective in\ndifferent environments, depending on the environment's level of natural\nentropy. However, neither method alone results in an agent that will\nconsistently learn intelligent behavior across environments. In an effort to\nfind a single entropy-based method that will encourage emergent behaviors in\nany environment, we propose an agent that can adapt its objective online,\ndepending on the entropy conditions by framing the choice as a multi-armed\nbandit problem. We devise a novel intrinsic feedback signal for the bandit,\nwhich captures the agent's ability to control the entropy in its environment.\nWe demonstrate that such agents can learn to control entropy and exhibit\nemergent behaviors in both high- and low-entropy regimes and can learn skillful\nbehaviors in benchmark tasks. Videos of the trained agents and summarized\nfindings can be found on our project page\nhttps://sites.google.com/view/surprise-adaptive-agents",
      "tldr_zh": "这篇论文针对无监督强化学习（unsupervised reinforcement learning）中熵目标的局限性，提出了一种惊奇适应（surprise-adaptive）内在动机方法，该方法允许代理根据环境的熵条件在线调整其目标，将选择过程框架为多臂赌博机（multi-armed bandit）问题。代理通过一个新颖的内在反馈信号来评估其对环境熵的控制能力，从而在高熵和低熵环境中实现新兴行为的涌现。实验结果显示，该方法在基准任务中表现出色，帮助代理学习熟练技能，并证明了其在不同环境下的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the Reinforcement Learning Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17243v2",
      "published_date": "2024-05-27 14:58:24 UTC",
      "updated_date": "2024-08-16 17:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:31:44.653941"
    },
    {
      "arxiv_id": "2405.17234v6",
      "title": "Benchmarking General-Purpose In-Context Learning",
      "title_zh": "通用目的上下文学习的基准测试",
      "authors": [
        "Fan Wang",
        "Chuan Lin",
        "Yang Cao",
        "Yu Kang"
      ],
      "abstract": "In-context learning (ICL) empowers generative models to address new tasks\neffectively and efficiently on the fly, without relying on any artificially\ncrafted optimization techniques. In this paper, we study extending ICL to\naddress a broader range of tasks with an extended learning horizon and higher\nimprovement potential, namely General Purpose In-Context Learning (GPICL). To\nthis end, we introduce two lightweight benchmarks specifically crafted to train\nand evaluate GPICL functionalities. Each benchmark encompasses a vast number of\ntasks characterized by significant task variance. These tasks are also crafted\nto promote long-horizon in-context learning through continuous generation and\ninteraction, covering domains such as language modeling, decision-making, and\nworld modeling. The benchmarks necessitate the models to leverage contexts and\nhistory interactions to enhance their capabilities, which we believe to be the\nkey characteristics of GPICL. Our experiments indicate that the diversity of\ntraining tasks is positively correlated with the ability to generalize with\nICL, but inversely correlated with zero-shot capabilities. Additionally, our\nfindings indicate that the scale of parameters alone may not be crucial for ICL\nor GPICL, suggesting alternative approaches such as increasing the scale of\ncontexts and memory states.",
      "tldr_zh": "本研究探讨了扩展 In-Context Learning (ICL) 以处理更广泛任务的 General Purpose In-Context Learning (GPICL)，旨在通过长horizon学习提升模型效率和潜力。作者引入了两个轻量级基准，用于训练和评估GPICL，这些基准涵盖大量任务、多样化领域（如语言建模、决策和世界建模），并强调通过上下文和历史交互来促进持续生成和学习。实验结果显示，任务多样性与ICL的泛化能力正相关，但与zero-shot能力负相关；此外，模型参数规模并非关键因素，建议通过扩大上下文和记忆状态来优化性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17234v6",
      "published_date": "2024-05-27 14:50:42 UTC",
      "updated_date": "2024-09-12 15:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:31:54.957275"
    },
    {
      "arxiv_id": "2406.00038v1",
      "title": "ViSpeR: Multilingual Audio-Visual Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Sanath Narayan",
        "Yasser Abdelaziz Dahou Djilali",
        "Ankit Singh",
        "Eustache Le Bihan",
        "Hakim Hacid"
      ],
      "abstract": "This work presents an extensive and detailed study on Audio-Visual Speech\nRecognition (AVSR) for five widely spoken languages: Chinese, Spanish, English,\nArabic, and French. We have collected large-scale datasets for each language\nexcept for English, and have engaged in the training of supervised learning\nmodels. Our model, ViSpeR, is trained in a multi-lingual setting, resulting in\ncompetitive performance on newly established benchmarks for each language. The\ndatasets and models are released to the community with an aim to serve as a\nfoundation for triggering and feeding further research work and exploration on\nAudio-Visual Speech Recognition, an increasingly important area of research.\nCode available at\n\\href{https://github.com/YasserdahouML/visper}{https://github.com/YasserdahouML/visper}.",
      "tldr_zh": "这篇论文介绍了 ViSpeR，一种多语言 Audio-Visual Speech Recognition (AVSR) 系统，针对 Chinese, Spanish, English, Arabic 和 French 五种语言进行了深入研究。研究团队收集了大规模数据集（除英语外），并在多语言设置下训练了监督学习模型，结果在每个语言的新基准上取得了竞争性性能。数据集、模型和代码已开源发布，旨在为 AVSR 领域进一步的研究提供基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00038v1",
      "published_date": "2024-05-27 14:48:51 UTC",
      "updated_date": "2024-05-27 14:48:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:32:06.950930"
    },
    {
      "arxiv_id": "2405.17216v1",
      "title": "Autoformalizing Euclidean Geometry",
      "title_zh": "翻译失败",
      "authors": [
        "Logan Murphy",
        "Kaiyu Yang",
        "Jialiang Sun",
        "Zhaoyu Li",
        "Anima Anandkumar",
        "Xujie Si"
      ],
      "abstract": "Autoformalization involves automatically translating informal math into\nformal theorems and proofs that are machine-verifiable. Euclidean geometry\nprovides an interesting and controllable domain for studying autoformalization.\nIn this paper, we introduce a neuro-symbolic framework for autoformalizing\nEuclidean geometry, which combines domain knowledge, SMT solvers, and large\nlanguage models (LLMs). One challenge in Euclidean geometry is that informal\nproofs rely on diagrams, leaving gaps in texts that are hard to formalize. To\naddress this issue, we use theorem provers to fill in such diagrammatic\ninformation automatically, so that the LLM only needs to autoformalize the\nexplicit textual steps, making it easier for the model. We also provide\nautomatic semantic evaluation for autoformalized theorem statements. We\nconstruct LeanEuclid, an autoformalization benchmark consisting of problems\nfrom Euclid's Elements and the UniGeo dataset formalized in the Lean proof\nassistant. Experiments with GPT-4 and GPT-4V show the capability and\nlimitations of state-of-the-art LLMs on autoformalizing geometry problems. The\ndata and code are available at https://github.com/loganrjmurphy/LeanEuclid.",
      "tldr_zh": "这篇论文提出了一种神经符号框架，用于自动形式化（Autoformalization）欧几里得几何，将非正式数学定理和证明转化为机器可验证的形式。框架结合领域知识、SMT solvers 和大型语言模型（LLMs），通过定理证明器自动填充图表相关空白，从而简化LLMs对显式文本步骤的形式化过程，并提供自动语义评估。作者构建了LeanEuclid基准数据集，包括Euclid's Elements和UniGeo数据集的形式化问题，并使用GPT-4和GPT-4V进行实验，揭示了这些模型在几何问题处理上的能力和局限性。数据集和代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024. The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2405.17216v1",
      "published_date": "2024-05-27 14:35:10 UTC",
      "updated_date": "2024-05-27 14:35:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:32:20.780301"
    },
    {
      "arxiv_id": "2405.17202v3",
      "title": "Efficient multi-prompt evaluation of LLMs",
      "title_zh": "高效的多提示大语言模型评估",
      "authors": [
        "Felipe Maia Polo",
        "Ronald Xu",
        "Lucas Weber",
        "Mírian Silva",
        "Onkar Bhardwaj",
        "Leshem Choshen",
        "Allysson Flavio Melo de Oliveira",
        "Yuekai Sun",
        "Mikhail Yurochkin"
      ],
      "abstract": "Most popular benchmarks for comparing LLMs rely on a limited set of prompt\ntemplates, which may not fully capture the LLMs' abilities and can affect the\nreproducibility of results on leaderboards. Many recent works empirically\nverify prompt sensitivity and advocate for changes in LLM evaluation. In this\npaper, we consider the problem of estimating the performance distribution\nacross many prompt variants instead of finding a single prompt to evaluate\nwith. We introduce PromptEval, a method for estimating performance across a\nlarge set of prompts borrowing strength across prompts and examples to produce\naccurate estimates under practical evaluation budgets. The resulting\ndistribution can be used to obtain performance quantiles to construct various\nrobust performance metrics (e.g., top 95% quantile or median). We prove that\nPromptEval consistently estimates the performance distribution and demonstrate\nits efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench\nHard, and LMentry; for example, PromptEval can accurately estimate performance\nquantiles across 100 prompt templates on MMLU with a budget equivalent to two\nsingle-prompt evaluations. Moreover, we show how PromptEval can be useful in\nLLM-as-a-judge and best prompt identification applications.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的基准测试问题，指出现有方法依赖有限的提示模板，可能导致性能评估不全面和结果不可重复。作者引入了PromptEval方法，通过在提示和示例之间借用优势，高效估计LLMs在大量提示变体下的性能分布，从而在实际评估预算下计算稳健的性能指标，如top 95%分位数或中位数。实验在MMLU、BIG-bench Hard和LMentry等基准上验证了PromptEval的有效性，例如，仅相当于两次单提示评估的预算即可准确估计MMLU上100个提示模板的性能分位数。此外，该方法还适用于LLM-as-a-judge和最佳提示识别等应用中。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17202v3",
      "published_date": "2024-05-27 14:24:47 UTC",
      "updated_date": "2024-10-31 03:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:32:31.841003"
    },
    {
      "arxiv_id": "2406.00037v1",
      "title": "Aligning LLMs through Multi-perspective User Preference Ranking-based Feedback for Programming Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyu Yang",
        "Liyang He",
        "Min Hou",
        "Shuanghong Shen",
        "Rui Li",
        "Jiahui Hou",
        "Jianhui Ma",
        "Junda Zhao"
      ],
      "abstract": "Code Community Question Answering (CCQA) seeks to tackle programming-related\nissues, thereby boosting productivity in both software engineering and academic\nresearch. Recent advancements in Reinforcement Learning from Human Feedback\n(RLHF) have transformed the fine-tuning process of Large Language Models (LLMs)\nto produce responses that closely mimic human behavior. Leveraging LLMs with\nRLHF for practical CCQA applications has thus emerged as a promising area of\nstudy. Unlike standard code question-answering tasks, CCQA involves multiple\npossible answers, with varying user preferences for each response.\nAdditionally, code communities often show a preference for new APIs. These\nchallenges prevent LLMs from generating responses that cater to the diverse\npreferences of users in CCQA tasks. To address these issues, we propose a novel\nframework called Aligning LLMs through Multi-perspective User Preference\nRanking-based Feedback for Programming Question Answering (ALMupQA) to create\nuser-focused responses. Our approach starts with Multi-perspective Preference\nRanking Alignment (MPRA), which synthesizes varied user preferences based on\nthe characteristics of answers from code communities. We then introduce a\nRetrieval-augmented In-context Learning (RIL) module to mitigate the problem of\noutdated answers by retrieving responses to similar questions from a question\nbank. Due to the limited availability of high-quality, multi-answer CCQA\ndatasets, we also developed a dataset named StaCCQA from real code communities.\nExtensive experiments demonstrated the effectiveness of the ALMupQA framework\nin terms of accuracy and user preference. Compared to the base model, ALMupQA\nshowed nearly an 11% improvement in BLEU, with increases of 20% and 17.5% in\nBERTScore and CodeBERTScore, respectively.",
      "tldr_zh": "该论文提出了一种名为 ALMupQA 的框架，用于通过多视角用户偏好排名反馈（Multi-perspective Preference Ranking-based Feedback）对齐大型语言模型（LLMs），以提升代码社区问答（CCQA）的响应质量。框架的核心组件包括 Multi-perspective Preference Ranking Alignment (MPRA)，用于基于代码社区答案特性合成多样用户偏好，以及 Retrieval-augmented In-context Learning (RIL) 模块，通过检索类似问题回答来解决过时 API 问题；此外，作者构建了新数据集 StaCCQA，以弥补高质量多答案 CCQA 数据不足。实验结果显示，ALMupQA 相较基线模型在 BLEU 分数上提升近 11%，BERTScore 和 CodeBERTScore 分别提高 20% 和 17.5%，显著改善了准确性和用户偏好。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00037v1",
      "published_date": "2024-05-27 14:21:31 UTC",
      "updated_date": "2024-05-27 14:21:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:32:45.193829"
    },
    {
      "arxiv_id": "2405.17187v2",
      "title": "Memorize What Matters: Emergent Scene Decomposition from Multitraverse",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Li",
        "Zehong Wang",
        "Yue Wang",
        "Zhiding Yu",
        "Zan Gojcic",
        "Marco Pavone",
        "Chen Feng",
        "Jose M. Alvarez"
      ],
      "abstract": "Humans naturally retain memories of permanent elements, while ephemeral\nmoments often slip through the cracks of memory. This selective retention is\ncrucial for robotic perception, localization, and mapping. To endow robots with\nthis capability, we introduce 3D Gaussian Mapping (3DGM), a self-supervised,\ncamera-only offline mapping framework grounded in 3D Gaussian Splatting. 3DGM\nconverts multitraverse RGB videos from the same region into a Gaussian-based\nenvironmental map while concurrently performing 2D ephemeral object\nsegmentation. Our key observation is that the environment remains consistent\nacross traversals, while objects frequently change. This allows us to exploit\nself-supervision from repeated traversals to achieve environment-object\ndecomposition. More specifically, 3DGM formulates multitraverse environmental\nmapping as a robust differentiable rendering problem, treating pixels of the\nenvironment and objects as inliers and outliers, respectively. Using robust\nfeature distillation, feature residuals mining, and robust optimization, 3DGM\njointly performs 2D segmentation and 3D mapping without human intervention. We\nbuild the Mapverse benchmark, sourced from the Ithaca365 and nuPlan datasets,\nto evaluate our method in unsupervised 2D segmentation, 3D reconstruction, and\nneural rendering. Extensive results verify the effectiveness and potential of\nour method for self-driving and robotics.",
      "tldr_zh": "本研究提出 3D Gaussian Mapping (3DGM)，一个自监督的基于摄像头的离线映射框架，利用 3D Gaussian Splatting 处理多遍历 RGB 视频，实现环境地图构建和 2D 短暂对象 segmentation。核心机制通过观察环境在多次遍历中的一致性与对象的频繁变化，采用自监督策略将多遍历映射表述为鲁棒可微渲染问题，并结合 robust feature distillation、feature residuals mining 和 robust optimization 进行环境-对象分解，无需人工干预。实验在 Mapverse benchmark（基于 Ithaca365 和 nuPlan 数据集）上验证了 3DGM 在无监督 2D segmentation、3D reconstruction 和 neural rendering 中的有效性，提升了机器人感知、定位和映射能力，尤其适用于自驾车和机器人领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://3d-gaussian-mapping.github.io; Code and data:\n  https://github.com/NVlabs/3DGM",
      "pdf_url": "http://arxiv.org/pdf/2405.17187v2",
      "published_date": "2024-05-27 14:11:17 UTC",
      "updated_date": "2024-05-29 23:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:32:56.950078"
    },
    {
      "arxiv_id": "2405.17182v1",
      "title": "Exploring the Performance of Continuous-Time Dynamic Link Prediction Algorithms",
      "title_zh": "探索连续时间动态链接预测算法的性能",
      "authors": [
        "Raphaël Romero",
        "Maarten Buyl",
        "Tijl De Bie",
        "Jefrey Lijffijt"
      ],
      "abstract": "Dynamic Link Prediction (DLP) addresses the prediction of future links in\nevolving networks. However, accurately portraying the performance of DLP\nalgorithms poses challenges that might impede progress in the field.\nImportantly, common evaluation pipelines usually calculate ranking or binary\nclassification metrics, where the scores of observed interactions (positives)\nare compared with those of randomly generated ones (negatives). However, a\nsingle metric is not sufficient to fully capture the differences between DLP\nalgorithms, and is prone to overly optimistic performance evaluation. Instead,\nan in-depth evaluation should reflect performance variations across different\nnodes, edges, and time segments. In this work, we contribute tools to perform\nsuch a comprehensive evaluation. (1) We propose Birth-Death diagrams, a simple\nbut powerful visualization technique that illustrates the effect of time-based\ntrain-test splitting on the difficulty of DLP on a given dataset. (2) We\ndescribe an exhaustive taxonomy of negative sampling methods that can be used\nat evaluation time. (3) We carry out an empirical study of the effect of the\ndifferent negative sampling strategies. Our comparison between heuristics and\nstate-of-the-art memory-based methods on various real-world datasets confirms a\nstrong effect of using different negative sampling strategies on the test Area\nUnder the Curve (AUC). Moreover, we conduct a visual exploration of the\nprediction, with additional insights on which different types of errors are\nprominent over time.",
      "tldr_zh": "这篇论文探讨了动态链接预测(Dynamic Link Prediction, DLP)算法在连续时间网络中的性能评估问题，指出传统方法依赖单一指标（如排名或二分类指标）容易导致过度乐观的评估，且未能捕捉节点、边和时间段的性能差异。论文的主要贡献包括提出Birth-Death diagrams作为一种简单有效的可视化工具，来展示时间-based训练测试分割对DLP难度的影响；提供负面采样方法的详尽分类；并进行实证研究比较不同采样策略的效果。实验结果显示，不同负面采样策略对测试Area Under the Curve (AUC)有显著影响，并在真实数据集上突显了启发式方法与最先进内存-based方法的差异，同时通过视觉探索分析了预测错误随时间的演变。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17182v1",
      "published_date": "2024-05-27 14:03:28 UTC",
      "updated_date": "2024-05-27 14:03:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:33:08.432893"
    },
    {
      "arxiv_id": "2405.17176v1",
      "title": "DreamMat: High-quality PBR Material Generation with Geometry- and Light-aware Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqing Zhang",
        "Yuan Liu",
        "Zhiyu Xie",
        "Lei Yang",
        "Zhongyuan Liu",
        "Mengzhou Yang",
        "Runze Zhang",
        "Qilong Kou",
        "Cheng Lin",
        "Wenping Wang",
        "Xiaogang Jin"
      ],
      "abstract": "2D diffusion model, which often contains unwanted baked-in shading effects\nand results in unrealistic rendering effects in the downstream applications.\nGenerating Physically Based Rendering (PBR) materials instead of just RGB\ntextures would be a promising solution. However, directly distilling the PBR\nmaterial parameters from 2D diffusion models still suffers from incorrect\nmaterial decomposition, such as baked-in shading effects in albedo. We\nintroduce DreamMat, an innovative approach to resolve the aforementioned\nproblem, to generate high-quality PBR materials from text descriptions. We find\nout that the main reason for the incorrect material distillation is that\nlarge-scale 2D diffusion models are only trained to generate final shading\ncolors, resulting in insufficient constraints on material decomposition during\ndistillation. To tackle this problem, we first finetune a new light-aware 2D\ndiffusion model to condition on a given lighting environment and generate the\nshading results on this specific lighting condition. Then, by applying the same\nenvironment lights in the material distillation, DreamMat can generate\nhigh-quality PBR materials that are not only consistent with the given geometry\nbut also free from any baked-in shading effects in albedo. Extensive\nexperiments demonstrate that the materials produced through our methods exhibit\ngreater visual appeal to users and achieve significantly superior rendering\nquality compared to baseline methods, which are preferable for downstream tasks\nsuch as game and film production.",
      "tldr_zh": "该论文提出 DreamMat，一种基于 geometry- and light-aware diffusion models 的创新方法，用于从文本描述生成高质量 Physically Based Rendering (PBR) 材料，以解决传统 2D diffusion models 中 baked-in shading effects 的问题。DreamMat 通过先微调一个 light-aware 2D diffusion model，使其在特定 lighting environment 下生成 shading results，然后在 material distillation 过程中应用相同的环境光，确保生成的 PBR 材料与给定 geometry 一致，且 albedo 中没有不想要的阴影效果。实验结果显示，DreamMat 生成的材料在视觉吸引力和渲染质量上显著优于基线方法，特别适合下游应用如游戏和电影制作。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted to SIGGRAPH 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17176v1",
      "published_date": "2024-05-27 13:55:08 UTC",
      "updated_date": "2024-05-27 13:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:33:20.581185"
    },
    {
      "arxiv_id": "2407.01570v1",
      "title": "Ego-Foresight: Agent Visuomotor Prediction as Regularization for RL",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel S. Nunes",
        "Atabak Dehban",
        "Yiannis Demiris",
        "José Santos-Victor"
      ],
      "abstract": "Despite the significant advancements in Deep Reinforcement Learning (RL)\nobserved in the last decade, the amount of training experience necessary to\nlearn effective policies remains one of the primary concerns both in simulated\nand real environments. Looking to solve this issue, previous work has shown\nthat improved training efficiency can be achieved by separately modeling agent\nand environment, but usually requiring a supervisory agent mask. In contrast to\nRL, humans can perfect a new skill from a very small number of trials and in\nmost cases do so without a supervisory signal, making neuroscientific studies\nof human development a valuable source of inspiration for RL. In particular, we\nexplore the idea of motor prediction, which states that humans develop an\ninternal model of themselves and of the consequences that their motor commands\nhave on the immediate sensory inputs. Our insight is that the movement of the\nagent provides a cue that allows the duality between agent and environment to\nbe learned. To instantiate this idea, we present Ego-Foresight, a\nself-supervised method for disentangling agent and environment based on motion\nand prediction. Our main finding is that visuomotor prediction of the agent\nprovides regularization to the RL algorithm, by encouraging the actions to stay\nwithin predictable bounds. To test our approach, we first study the ability of\nour model to visually predict agent movement irrespective of the environment,\nin real-world robotic interactions. Then, we integrate Ego-Foresight with a\nmodel-free RL algorithm to solve simulated robotic manipulation tasks, showing\nan average improvement of 23% in efficiency and 8% in performance.",
      "tldr_zh": "本文提出Ego-Foresight，一种自监督方法，通过agent的visuomotor prediction来正则化Deep Reinforcement Learning (RL)，旨在解决RL算法需要大量训练经验的问题。该方法利用运动预测来分离agent和environment，避免了监督信号的需求，并鼓励动作保持在可预测范围内。实验结果显示，在真实机器人交互中，模型能准确预测agent运动；在模拟机器人操作任务中，与无模型RL算法结合后，效率平均提升23%，性能提升8%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 9 figures, 3 tables, conference",
      "pdf_url": "http://arxiv.org/pdf/2407.01570v1",
      "published_date": "2024-05-27 13:32:43 UTC",
      "updated_date": "2024-05-27 13:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:33:32.616962"
    },
    {
      "arxiv_id": "2405.17152v3",
      "title": "CoSLight: Co-optimizing Collaborator Selection and Decision-making to Enhance Traffic Signal Control",
      "title_zh": "翻译失败",
      "authors": [
        "Jingqing Ruan",
        "Ziyue Li",
        "Hua Wei",
        "Haoyuan Jiang",
        "Jiaming Lu",
        "Xuantang Xiong",
        "Hangyu Mao",
        "Rui Zhao"
      ],
      "abstract": "Effective multi-intersection collaboration is pivotal for\nreinforcement-learning-based traffic signal control to alleviate congestion.\nExisting work mainly chooses neighboring intersections as collaborators.\nHowever, quite an amount of congestion, even some wide-range congestion, is\ncaused by non-neighbors failing to collaborate. To address these issues, we\npropose to separate the collaborator selection as a second policy to be\nlearned, concurrently being updated with the original signal-controlling\npolicy. Specifically, the selection policy in real-time adaptively selects the\nbest teammates according to phase- and intersection-level features. Empirical\nresults on both synthetic and real-world datasets provide robust validation for\nthe superiority of our approach, offering significant improvements over\nexisting state-of-the-art methods. The code is available at\nhttps://github.com/bonaldli/CoSLight.",
      "tldr_zh": "这篇论文提出了 CoSLight 框架，用于增强基于强化学习的交通信号控制，通过同时优化合作者选择和决策策略来缓解拥堵问题。不同于现有方法仅选择邻近路口作为合作者，CoSLight 将合作者选择作为一个独立的策略来学习，根据相位和路口级别的实时特征动态选择最佳合作者。这种联合优化方法在合成和真实数据集上的实验中，显著超过了现有最先进技术，提供更鲁棒的性能提升。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17152v3",
      "published_date": "2024-05-27 13:26:59 UTC",
      "updated_date": "2024-06-19 10:07:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:33:44.398198"
    },
    {
      "arxiv_id": "2405.17139v2",
      "title": "Synergy and Diversity in CLIP: Enhancing Performance Through Adaptive Backbone Ensembling",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian Rodriguez-Opazo",
        "Ehsan Abbasnejad",
        "Damien Teney",
        "Hamed Damirchi",
        "Edison Marrese-Taylor",
        "Anton van den Hengel"
      ],
      "abstract": "Contrastive Language-Image Pretraining (CLIP) stands out as a prominent\nmethod for image representation learning. Various architectures, from vision\ntransformers (ViTs) to convolutional networks (ResNets) have been trained with\nCLIP to serve as general solutions to diverse vision tasks. This paper explores\nthe differences across various CLIP-trained vision backbones. Despite using the\nsame data and training objective, we find that these architectures have notably\ndifferent representations, different classification performance across\ndatasets, and different robustness properties to certain types of image\nperturbations. Our findings indicate a remarkable possible synergy across\nbackbones by leveraging their respective strengths. In principle,\nclassification accuracy could be improved by over 40 percentage with an\ninformed selection of the optimal backbone per test example.Using this insight,\nwe develop a straightforward yet powerful approach to adaptively ensemble\nmultiple backbones. The approach uses as few as one labeled example per class\nto tune the adaptive combination of backbones. On a large collection of\ndatasets, the method achieves a remarkable increase in accuracy of up to 39.1%\nover the best single backbone, well beyond traditional ensembles",
      "tldr_zh": "该研究探讨了Contrastive Language-Image Pretraining (CLIP)模型在不同视觉骨干网络（如ViTs和ResNets）间的差异，尽管它们使用相同的数据和训练目标，但表现出不同的表示、分类性能和对图像扰动的鲁棒性。论文发现，这些差异可带来显著协同效应，通过选择最佳骨干网络，每个测试样本的分类准确率可能提升超过40%。为此，研究提出了一种简单有效的自适应集成方法，仅需每个类别一个标记样本来调整骨干网络组合，在多个数据集上实现高达39.1%的准确率提升，远超传统集成策略。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025. arXiv admin note: text overlap with arXiv:2312.14400",
      "pdf_url": "http://arxiv.org/pdf/2405.17139v2",
      "published_date": "2024-05-27 12:59:35 UTC",
      "updated_date": "2025-02-16 08:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:33:56.544734"
    },
    {
      "arxiv_id": "2405.17523v2",
      "title": "Locally Testing Model Detections for Semantic Global Concepts",
      "title_zh": "针对语义全局概念的模型检测局部测试",
      "authors": [
        "Franz Motzkus",
        "Georgii Mikriukov",
        "Christian Hellert",
        "Ute Schmid"
      ],
      "abstract": "Ensuring the quality of black-box Deep Neural Networks (DNNs) has become ever\nmore significant, especially in safety-critical domains such as automated\ndriving. While global concept encodings generally enable a user to test a model\nfor a specific concept, linking global concept encodings to the local\nprocessing of single network inputs reveals their strengths and limitations.\nOur proposed framework global-to-local Concept Attribution (glCA) uses\napproaches from local (why a specific prediction originates) and global (how a\nmodel works generally) eXplainable Artificial Intelligence (xAI) to test DNNs\nfor a predefined semantical concept locally. The approach allows for\nconditioning local, post-hoc explanations on predefined semantic concepts\nencoded as linear directions in the model's latent space. Pixel-exact scoring\nconcerning the global concept usage assists the tester in further understanding\nthe model processing of single data points for the selected concept. Our\napproach has the advantage of fully covering the model-internal encoding of the\nsemantic concept and allowing the localization of relevant concept-related\ninformation. The results show major differences in the local perception and\nusage of individual global concept encodings and demand for further\ninvestigations regarding obtaining thorough semantic concept encodings.",
      "tldr_zh": "该研究提出了一种 global-to-local Concept Attribution (glCA) 框架，用于测试黑盒 Deep Neural Networks (DNNs) 对语义全局概念的本地检测，尤其适用于安全关键领域如自动驾驶。glCA 方法结合本地和全局 eXplainable Artificial Intelligence (xAI) 技术，将预定义的语义概念编码为模型潜在空间中的线性方向，并通过像素精确评分分析模型对单个输入的处理。结果显示，不同全局概念编码在本地感知和使用上存在显著差异，强调了需要进一步优化语义概念编码以提升模型的可解释性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17523v2",
      "published_date": "2024-05-27 12:52:45 UTC",
      "updated_date": "2024-05-29 07:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:34:08.214653"
    },
    {
      "arxiv_id": "2405.17129v2",
      "title": "TEII: Think, Explain, Interact and Iterate with Large Language Models to Solve Cross-lingual Emotion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Long Cheng",
        "Qihao Shao",
        "Christine Zhao",
        "Sheng Bi",
        "Gina-Anne Levow"
      ],
      "abstract": "Cross-lingual emotion detection allows us to analyze global trends, public\nopinion, and social phenomena at scale. We participated in the Explainability\nof Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score\nof 0.6046 on the evaluation set for the emotion detection sub-task. Our system\noutperformed the baseline by more than 0.16 F1-score absolute, and ranked\nsecond amongst competing systems. We conducted experiments using fine-tuning,\nzero-shot learning, and few-shot learning for Large Language Model (LLM)-based\nmodels as well as embedding-based BiLSTM and KNN for non-LLM-based techniques.\nAdditionally, we introduced two novel methods: the Multi-Iteration Agentic\nWorkflow and the Multi-Binary-Classifier Agentic Workflow. We found that\nLLM-based approaches provided good performance on multilingual emotion\ndetection. Furthermore, ensembles combining all our experimented models yielded\nhigher F1-scores than any single approach alone.",
      "tldr_zh": "本文提出 TEII 框架，利用大型语言模型(LLM)通过思考、解释、交互和迭代来解决跨语言情感检测问题，并在 EXALT 共享任务中取得 0.6046 的 F1-score，比基线高出 0.16，并排名第二。研究者实验了 fine-tuning、zero-shot learning 和 few-shot learning 等 LLM 方法，以及非 LLM 技术如 BiLSTM 和 KNN，同时引入了 Multi-Iteration Agentic Workflow 和 Multi-Binary-Classifier Agentic Workflow 两种新颖方法。结果显示，LLM 基于方法在多语言情感检测中表现出色，而将所有模型集成的集成策略进一步提升了 F1-score，证明了框架的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 13th Workshop on Computational Approaches to\n  Subjectivity, Sentiment, & Social Media Analysis (ACL 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.17129v2",
      "published_date": "2024-05-27 12:47:40 UTC",
      "updated_date": "2024-07-02 12:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:34:21.920231"
    },
    {
      "arxiv_id": "2405.17116v1",
      "title": "Mixtures of Unsupervised Lexicon Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Peratham Wiriyathammabhum"
      ],
      "abstract": "This paper presents a mixture version of the method-of-moment unsupervised\nlexicon classification by an incorporation of a Dirichlet process.",
      "tldr_zh": "本论文提出了一种混合版本的 unsupervised lexicon classification 方法，通过整合 Dirichlet process 来扩展传统的 method-of-moment 技术。该方法旨在提升无监督词汇分类的性能，允许模型更灵活地处理数据分布。整体创新为 lexicon classification 领域提供了更鲁棒的框架，支持更精确的聚类和建模。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "A draft on lexicon classification unsupervised learning. It shows\n  that aggregating lexicon scores is equivalent to a finite mixture of\n  multinomial Naive Bayes models. A very preliminary work of a few days\n  man-hours, like a weekly report/note, but might be useful",
      "pdf_url": "http://arxiv.org/pdf/2405.17116v1",
      "published_date": "2024-05-27 12:33:47 UTC",
      "updated_date": "2024-05-27 12:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:34:30.996575"
    },
    {
      "arxiv_id": "2405.17110v1",
      "title": "Superpixelwise Low-rank Approximation based Partial Label Learning for Hyperspectral Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Shujun Yang",
        "Yu Zhang",
        "Yao Ding",
        "Danfeng Hong"
      ],
      "abstract": "Insufficient prior knowledge of a captured hyperspectral image (HSI) scene\nmay lead the experts or the automatic labeling systems to offer incorrect\nlabels or ambiguous labels (i.e., assigning each training sample to a group of\ncandidate labels, among which only one of them is valid; this is also known as\npartial label learning) during the labeling process. Accordingly, how to learn\nfrom such data with ambiguous labels is a problem of great practical\nimportance. In this paper, we propose a novel superpixelwise low-rank\napproximation (LRA)-based partial label learning method, namely SLAP, which is\nthe first to take into account partial label learning in HSI classification.\nSLAP is mainly composed of two phases: disambiguating the training labels and\nacquiring the predictive model. Specifically, in the first phase, we propose a\nsuperpixelwise LRA-based model, preparing the affinity graph for the subsequent\nlabel propagation process while extracting the discriminative representation to\nenhance the following classification task of the second phase. Then to\ndisambiguate the training labels, label propagation propagates the labeling\ninformation via the affinity graph of training pixels. In the second phase, we\ntake advantage of the resulting disambiguated training labels and the\ndiscriminative representations to enhance the classification performance. The\nextensive experiments validate the advantage of the proposed SLAP method over\nstate-of-the-art methods.",
      "tldr_zh": "该论文针对高光谱图像 (HSI) 分类中标签模糊问题（partial label learning），提出了一种新型方法 SLAP，即基于 superpixelwise low-rank approximation (LRA) 的部分标签学习。SLAP 分为两个阶段：首先，通过 superpixelwise LRA 模型构建亲和图 (affinity graph) 并提取判别性表示 (discriminative representation)，然后利用标签传播 (label propagation) 消除训练标签的模糊性；其次，基于消除模糊后的标签和判别性表示来提升分类性能。实验结果显示，SLAP 在 HSI 分类任务上优于现有最先进方法，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17110v1",
      "published_date": "2024-05-27 12:26:49 UTC",
      "updated_date": "2024-05-27 12:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:34:44.935964"
    },
    {
      "arxiv_id": "2405.17104v2",
      "title": "LLM-Optic: Unveiling the Capabilities of Large Language Models for Universal Visual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Zhao",
        "Wenhang Ge",
        "Ying-cong Chen"
      ],
      "abstract": "Visual grounding is an essential tool that links user-provided text queries\nwith query-specific regions within an image. Despite advancements in visual\ngrounding models, their ability to comprehend complex queries remains limited.\nTo overcome this limitation, we introduce LLM-Optic, an innovative method that\nutilizes Large Language Models (LLMs) as an optical lens to enhance existing\nvisual grounding models in comprehending complex text queries involving\nintricate text structures, multiple objects, or object spatial relationships,\nsituations that current models struggle with. LLM-Optic first employs an LLM as\na Text Grounder to interpret complex text queries and accurately identify\nobjects the user intends to locate. Then a pre-trained visual grounding model\nis used to generate candidate bounding boxes given the refined query by the\nText Grounder. After that, LLM-Optic annotates the candidate bounding boxes\nwith numerical marks to establish a connection between text and specific image\nregions, thereby linking two distinct modalities. Finally, it employs a Large\nMultimodal Model (LMM) as a Visual Grounder to select the marked candidate\nobjects that best correspond to the original text query. Through LLM-Optic, we\nhave achieved universal visual grounding, which allows for the detection of\narbitrary objects specified by arbitrary human language input. Importantly, our\nmethod achieves this enhancement without requiring additional training or\nfine-tuning. Extensive experiments across various challenging benchmarks\ndemonstrate that LLM-Optic achieves state-of-the-art zero-shot visual grounding\ncapabilities. Project Page: https://haoyu-zhao.github.io/LLM-Optic.github.io/.",
      "tldr_zh": "这篇论文介绍了 LLM-Optic，一种创新方法，利用 Large Language Models (LLMs) 作为“光学透镜”来提升视觉 grounding 模型处理复杂文本查询的能力，例如涉及多个对象或空间关系的场景。方法包括使用 LLM 作为 Text Grounder 解释查询并识别对象、预训练视觉 grounding 模型生成候选边界框、标注边界框以连接文本和图像模态，以及采用 Large Multimodal Model (LMM) 作为 Visual Grounder 选择最佳匹配。LLM-Optic 实现了通用视觉 grounding，能检测任意对象而无需额外训练或微调，并在各种基准测试中达到最先进的零样本性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://haoyu-zhao.github.io/LLM-Optic.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.17104v2",
      "published_date": "2024-05-27 12:23:08 UTC",
      "updated_date": "2024-05-28 02:17:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:34:57.561536"
    },
    {
      "arxiv_id": "2405.17103v2",
      "title": "Empowering Character-level Text Infilling by Eliminating Sub-Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Houxing Ren",
        "Mingjie Zhan",
        "Zhongyuan Wu",
        "Hongsheng Li"
      ],
      "abstract": "In infilling tasks, sub-tokens, representing instances where a complete token\nis segmented into two parts, often emerge at the boundaries of prefixes,\nmiddles, and suffixes. Traditional methods focused on training models at the\ntoken level, leading to sub-optimal performance in character-level infilling\ntasks during the inference stage. Alternately, some approaches considered\ncharacter-level infilling, but they relied on predicting sub-tokens in\ninference, yet this strategy diminished ability in character-level infilling\ntasks due to the large perplexity of the model on sub-tokens. In this paper, we\nintroduce FIM-SE, which stands for Fill-In-the-Middle with both Starting and\nEnding character constraints. The proposed method addresses character-level\ninfilling tasks by utilizing a line-level format to avoid predicting any\nsub-token in inference. In addition, we incorporate two special tokens to\nsignify the rest of the incomplete lines, thereby enhancing generation\nguidance. Extensive experiments demonstrate that our proposed approach\nsurpasses previous methods, offering a significant advantage. Code is available\nat https://github.com/SenseLLM/FIM-SE.",
      "tldr_zh": "该论文针对文本 infilling 任务中 sub-tokens（完整 token 被分割的部分）问题，指出传统 token-level 方法在 character-level infilling 时的性能不足。作者提出 FIM-SE（Fill-In-the-Middle with both Starting and Ending character constraints）方法，使用 line-level 格式避免推理阶段预测 sub-tokens，并引入两个特殊 tokens 来表示不完整行的剩余部分，从而提升生成指导。实验结果表明，FIM-SE 在 character-level infilling 任务上显著优于现有方法，提供代码以供参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2405.17103v2",
      "published_date": "2024-05-27 12:21:48 UTC",
      "updated_date": "2024-06-14 09:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:35:09.241051"
    },
    {
      "arxiv_id": "2405.17097v2",
      "title": "A Comparative Study on Multi-task Uncertainty Quantification in Semantic Segmentation and Monocular Depth Estimation",
      "title_zh": "语义分割和单目深度估计中的多任务不确定性量化的比较研究",
      "authors": [
        "Steven Landgraf",
        "Markus Hillemann",
        "Theodor Kapler",
        "Markus Ulrich"
      ],
      "abstract": "Deep neural networks excel in perception tasks such as semantic segmentation\nand monocular depth estimation, making them indispensable in safety-critical\napplications like autonomous driving and industrial inspection. However, they\noften suffer from overconfidence and poor explainability, especially for\nout-of-domain data. While uncertainty quantification has emerged as a promising\nsolution to these challenges, multi-task settings have yet to be explored. In\nan effort to shed light on this, we evaluate Monte Carlo Dropout, Deep\nSub-Ensembles, and Deep Ensembles for joint semantic segmentation and monocular\ndepth estimation. Thereby, we reveal that Deep Ensembles stand out as the\npreferred choice, particularly in out-of-domain scenarios, and show the\npotential benefit of multi-task learning with regard to the uncertainty quality\nin comparison to solving both tasks separately. Additionally, we highlight the\nimpact of employing different uncertainty thresholds to classify pixels as\ncertain or uncertain, with the median uncertainty emerging as a robust default.",
      "tldr_zh": "本研究比较了在语义分割（semantic segmentation）和单目深度估计（monocular depth estimation）多任务设置中，不确定性量化（uncertainty quantification）方法的性能，针对深度神经网络的过度自信和可解释性问题。研究评估了 Monte Carlo Dropout、Deep Sub-Ensembles 和 Deep Ensembles 三种方法，结果显示 Deep Ensembles 在 out-of-domain 场景中表现最佳，并证明多任务学习比单独处理任务能提升不确定性质量。此外，采用 median uncertainty 作为阈值被推荐为稳健的默认选项，为安全关键应用如自动驾驶提供更可靠的感知模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This manuscript is an extended version of a previously published\n  conference paper and is currently in review for a journal",
      "pdf_url": "http://arxiv.org/pdf/2405.17097v2",
      "published_date": "2024-05-27 12:12:26 UTC",
      "updated_date": "2025-01-16 16:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:35:20.913264"
    },
    {
      "arxiv_id": "2405.17088v1",
      "title": "Phase Transitions in the Output Distribution of Large Language Models",
      "title_zh": "大型语言模型输出分布中的相变",
      "authors": [
        "Julian Arnold",
        "Flemming Holtorf",
        "Frank Schäfer",
        "Niels Lörch"
      ],
      "abstract": "In a physical system, changing parameters such as temperature can induce a\nphase transition: an abrupt change from one state of matter to another.\nAnalogous phenomena have recently been observed in large language models.\nTypically, the task of identifying phase transitions requires human analysis\nand some prior understanding of the system to narrow down which low-dimensional\nproperties to monitor and analyze. Statistical methods for the automated\ndetection of phase transitions from data have recently been proposed within the\nphysics community. These methods are largely system agnostic and, as shown\nhere, can be adapted to study the behavior of large language models. In\nparticular, we quantify distributional changes in the generated output via\nstatistical distances, which can be efficiently estimated with access to the\nprobability distribution over next-tokens. This versatile approach is capable\nof discovering new phases of behavior and unexplored transitions -- an ability\nthat is particularly exciting in light of the rapid development of language\nmodels and their emergent capabilities.",
      "tldr_zh": "本研究将物理系统中相变现象类比到大型语言模型（Large Language Models）的输出分布，探讨参数变化如何引发模型行为的突然转变。作者采用物理社区的统计方法，通过统计距离量化生成输出的分布变化，并利用 next-token 概率分布进行高效估计。这种系统无关的方法无需人工分析，即可自动识别语言模型的新行为阶段和未探索的转变。在语言模型快速发展和新兴能力背景下，此方法为深入理解模型动态提供了强大工具。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.17088v1",
      "published_date": "2024-05-27 12:04:36 UTC",
      "updated_date": "2024-05-27 12:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:35:32.207963"
    },
    {
      "arxiv_id": "2407.11978v1",
      "title": "\"It depends\": Configuring AI to Improve Clinical Usefulness Across Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Hubert D. Zając",
        "Jorge M. N. Ribeiro",
        "Silvia Ingala",
        "Simona Gentile",
        "Ruth Wanjohi",
        "Samuel N. Gitau",
        "Jonathan F. Carlsen",
        "Michael B. Nielsen",
        "Tariq O. Andersen"
      ],
      "abstract": "Artificial Intelligence (AI) repeatedly match or outperform radiologists in\nlab experiments. However, real-world implementations of radiological AI-based\nsystems are found to provide little to no clinical value. This paper explores\nhow to design AI for clinical usefulness in different contexts. We conducted 19\ndesign sessions and design interventions with 13 radiologists from 7 clinical\nsites in Denmark and Kenya, based on three iterations of a functional AI-based\nprototype. Ten sociotechnical dependencies were identified as crucial for the\ndesign of AI in radiology. We conceptualised four technical dimensions that\nmust be configured to the intended clinical context of use: AI functionality,\nAI medical focus, AI decision threshold, and AI Explainability. We present four\ndesign recommendations on how to address dependencies pertaining to the medical\nknowledge, clinic type, user expertise level, patient context, and user\nsituation that condition the configuration of these technical dimensions.",
      "tldr_zh": "本文研究了如何配置AI以提高其在不同临床环境中的实用性，因为尽管AI在实验室实验中能与放射科医生匹敌，但实际应用中价值有限。通过与13名放射科医生在7个临床站点进行的19个设计会议和基于三个迭代的AI原型，研究者识别了10个关键的sociotechnical dependencies，并概念化了四个技术维度：AI functionality、AI medical focus、AI decision threshold和AI Explainability，这些需要根据具体上下文调整。最终，论文提出了四个设计推荐，针对医疗知识、clinic type、用户专业水平、patient context和用户情况等因素，以优化AI的设计和部署。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11978v1",
      "published_date": "2024-05-27 11:49:05 UTC",
      "updated_date": "2024-05-27 11:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:35:46.672818"
    },
    {
      "arxiv_id": "2405.17076v1",
      "title": "Leveraging small language models for Text2SPARQL tasks to improve the resilience of AI assistance",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Brei",
        "Johannes Frey",
        "Lars-Peter Meyer"
      ],
      "abstract": "In this work we will show that language models with less than one billion\nparameters can be used to translate natural language to SPARQL queries after\nfine-tuning. Using three different datasets ranging from academic to real\nworld, we identify prerequisites that the training data must fulfill in order\nfor the training to be successful. The goal is to empower users of semantic web\ntechnology to use AI assistance with affordable commodity hardware, making them\nmore resilient against external factors.",
      "tldr_zh": "这篇论文探讨了利用小型语言模型（small language models），通过微调（fine-tuning）来实现自然语言到SPARQL查询的转换（Text2SPARQL任务），以增强AI辅助的韧性。研究使用了三个从学术到真实世界的数据集，识别了训练数据必须满足的先决条件，如数据质量和相关性。结果表明，这种方法使语义网（semantic web）技术的用户能够在廉价的硬件上部署AI辅助，提高了其对外部因素的弹性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in Proceedings of the Workshop on Linked Data-driven\n  Resilience Research 2024 (D2R2) co-located with Extended Semantic Web\n  Conference 2024 (ESWC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.17076v1",
      "published_date": "2024-05-27 11:47:21 UTC",
      "updated_date": "2024-05-27 11:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:35:56.839007"
    },
    {
      "arxiv_id": "2405.17072v1",
      "title": "A novel framework for systematic propositional formula simplification based on existential graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Jordina Francès de Mas",
        "Juliana Bowles"
      ],
      "abstract": "This paper presents a novel simplification calculus for propositional logic\nderived from Peirce's existential graphs' rules of inference and implication\ngraphs. Our rules can be applied to propositional logic formulae in nested\nform, are equivalence-preserving, guarantee a monotonically decreasing number\nof variables, clauses and literals, and maximise the preservation of structural\nproblem information. Our techniques can also be seen as higher-level SAT\npreprocessing, and we show how one of our rules (TWSR) generalises and\nstreamlines most of the known equivalence-preserving SAT preprocessing methods.\nIn addition, we propose a simplification procedure based on the systematic\napplication of two of our rules (EPR and TWSR) which is solver-agnostic and can\nbe used to simplify large Boolean satisfiability problems and propositional\nformulae in arbitrary form, and we provide a formal analysis of its algorithmic\ncomplexity in terms of space and time. Finally, we show how our rules can be\nfurther extended with a novel n-ary implication graph to capture all known\nequivalence-preserving preprocessing procedures.",
      "tldr_zh": "本论文提出了一种基于 Peirce 的 existential graphs 和 implication graphs 的新型命题逻辑简化演算框架，用于系统地简化 propositional logic 公式。 该框架的规则适用于嵌套形式的公式，确保等价性保存，同时减少变量、子句和字面量数量，并最大化保留结构问题信息。 作为高级 SAT preprocessing 技术，该框架中的 TWSR 规则概括并简化了现有等价性保存预处理方法。 此外，论文引入了一种基于 EPR 和 TWSR 的求解器无关简化过程，可处理大型布尔可满足性问题，并提供了其空间和时间复杂度的正式分析。 最后，该框架通过一个新的 n-ary implication graph 扩展规则，以涵盖所有已知等价性保存预处理过程。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "math.LO",
        "03B35, 03B70, 68N17, 68T27",
        "F.4.1; I.2.2; I.2.3; I.2.4"
      ],
      "primary_category": "cs.LO",
      "comment": "19 pages, 12 figures. Under consideration in Theory and Practice of\n  Logic Programming (TPLP)",
      "pdf_url": "http://arxiv.org/pdf/2405.17072v1",
      "published_date": "2024-05-27 11:42:46 UTC",
      "updated_date": "2024-05-27 11:42:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:36:09.908909"
    },
    {
      "arxiv_id": "2405.17067v2",
      "title": "Tokenization Matters! Degrading Large Language Models through Challenging Their Tokenization",
      "title_zh": "翻译失败",
      "authors": [
        "Dixuan Wang",
        "Yanda Li",
        "Junyuan Jiang",
        "Zepeng Ding",
        "Ziqin Luo",
        "Guochao Jiang",
        "Jiaqing Liang",
        "Deqing Yang"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. Nonetheless, it was also witnessed that LLMs tend\nto produce inaccurate responses to specific queries. This deficiency can be\ntraced to the tokenization step LLMs must undergo, which is an inevitable\nlimitation inherent to all LLMs. In fact, incorrect tokenization is the\ncritical point that hinders LLMs in understanding the input precisely, thus\nleading to unsatisfactory output. This defect is more obvious in Chinese\nscenarios. To demonstrate this flaw of LLMs, we construct an adversarial\ndataset, named as $\\textbf{ADT (Adversarial Dataset for Tokenizer)}$, which\ndraws upon the vocabularies of various open-source LLMs to challenge LLMs'\ntokenization. ADT consists of two subsets: the manually constructed ADT-Human\nand the automatically generated ADT-Auto. Our empirical results reveal that our\nADT is highly effective on challenging the tokenization of leading LLMs,\nincluding GPT-4o, Llama-3, Deepseek-R1 and so on, thus degrading these LLMs'\ncapabilities. Moreover, our method of automatic data generation has been proven\nefficient and robust, which can be applied to any open-source LLMs. In this\npaper, we substantially investigate LLMs' vulnerability in terms of challenging\ntheir token segmentation, which will shed light on the subsequent research of\nimproving LLMs' capabilities through optimizing their tokenization process and\nalgorithms.",
      "tldr_zh": "该研究揭示了Large Language Models (LLMs) 在tokenization 步骤上的固有缺陷，导致模型在处理特定查询时产生不准确响应，尤其在中文场景中更显著。作者构建了一个对抗数据集ADT (Adversarial Dataset for Tokenizer)，包括手动创建的ADT-Human和自动生成的ADT-Auto，通过利用开源LLMs的词汇表来挑战其tokenization过程。实验结果显示，ADT有效降低了领先LLMs（如GPT-4o、Llama-3和Deepseek-R1）的性能，准确率显著下降；此外，该自动生成方法高效且鲁棒，可应用于任何开源LLMs，为优化tokenization算法和提升LLMs能力提供重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17067v2",
      "published_date": "2024-05-27 11:39:59 UTC",
      "updated_date": "2025-05-15 15:57:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:36:21.981133"
    },
    {
      "arxiv_id": "2405.17060v1",
      "title": "Graph Neural Networks on Quantum Computers",
      "title_zh": "图神经网络在量子计算机上",
      "authors": [
        "Yidong Liao",
        "Xiao-Ming Zhang",
        "Chris Ferrie"
      ],
      "abstract": "Graph Neural Networks (GNNs) are powerful machine learning models that excel\nat analyzing structured data represented as graphs, demonstrating remarkable\nperformance in applications like social network analysis and recommendation\nsystems. However, classical GNNs face scalability challenges when dealing with\nlarge-scale graphs. This paper proposes frameworks for implementing GNNs on\nquantum computers to potentially address the challenges. We devise quantum\nalgorithms corresponding to the three fundamental types of classical GNNs:\nGraph Convolutional Networks, Graph Attention Networks, and Message-Passing\nGNNs. A complexity analysis of our quantum implementation of the Simplified\nGraph Convolutional (SGC) Network shows potential quantum advantages over its\nclassical counterpart, with significant improvements in time and space\ncomplexities. Our complexities can have trade-offs between the two: when\noptimizing for minimal circuit depth, our quantum SGC achieves logarithmic time\ncomplexity in the input sizes (albeit at the cost of linear space complexity).\nWhen optimizing for minimal qubit usage, the quantum SGC exhibits space\ncomplexity logarithmic in the input sizes, offering an exponential reduction\ncompared to classical SGCs, while still maintaining better time complexity.\nThese results suggest our Quantum GNN frameworks could efficiently process\nlarge-scale graphs. This work paves the way for implementing more advanced\nGraph Neural Network models on quantum computers, opening new possibilities in\nquantum machine learning for analyzing graph-structured data.",
      "tldr_zh": "本文提出在量子计算机上实现Graph Neural Networks (GNNs)的框架，以解决经典GNNs处理大规模图时面临的可扩展性挑战。研究设计了对应于Graph Convolutional Networks、Graph Attention Networks和Message-Passing GNNs的三种量子算法，并对量子Simplified Graph Convolutional (SGC) Network进行了复杂度分析，显示出潜在量子优势，包括时间复杂度可达对数级和空间复杂度指数级减少。结果表明，这种量子框架能更高效地处理大型图数据，为量子机器学习在分析图结构数据方面开辟新可能性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "50 Pages, 22 Figures",
      "pdf_url": "http://arxiv.org/pdf/2405.17060v1",
      "published_date": "2024-05-27 11:31:08 UTC",
      "updated_date": "2024-05-27 11:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:36:33.765220"
    },
    {
      "arxiv_id": "2405.17057v1",
      "title": "ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation",
      "title_zh": "Reflection",
      "authors": [
        "Houxing Ren",
        "Mingjie Zhan",
        "Zhongyuan Wu",
        "Aojun Zhou",
        "Junting Pan",
        "Hongsheng Li"
      ],
      "abstract": "Code generation plays a crucial role in various tasks, such as code\nauto-completion and mathematical reasoning. Previous work has proposed numerous\nmethods to enhance code generation performance, including integrating feedback\nfrom the compiler. Inspired by this, we present ReflectionCoder, a novel\napproach that effectively leverages reflection sequences constructed by\nintegrating compiler feedback to improve one-off code generation performance.\nFurthermore, we propose reflection self-distillation and dynamically masked\ndistillation to effectively utilize these reflection sequences. Extensive\nexperiments on three benchmarks, i.e., HumanEval (+), MBPP (+), and MultiPl-E,\ndemonstrate that models fine-tuned with our method achieve state-of-the-art\nperformance. Notably, ReflectionCoder-DeepSeek-Coder-33B reaches pass@1 of 82.9\n(76.8) on HumanEval (+) and 84.1 (72.0) on MBPP (+), on par with GPT-3.5-Turbo\nand Claude-3-opus, and surpasses early GPT-4. Beyond the code domain, we\nbelieve this approach can benefit other domains that focus on final results and\nrequire long reasoning paths. Code and data are available at\nhttps://github.com/SenseLLM/ReflectionCoder.",
      "tldr_zh": "本研究提出 ReflectionCoder，一种新方法，通过利用由编译器反馈构建的 reflection sequences 来提升一次性（one-off）代码生成的性能。论文引入 reflection self-distillation 和 dynamically masked distillation 技术，有效地处理这些序列，以优化模型训练。在 HumanEval (+)、MBPP (+) 和 MultiPl-E 等基准测试中，ReflectionCoder-DeepSeek-Coder-33B 模型达到最先进水平，pass@1 得分分别为 82.9（76.8）和 84.1（72.0），与 GPT-3.5-Turbo 和 Claude-3-opus 相当，并超过早期 GPT-4。这种方法不仅适用于代码生成，还可扩展到其他需要长推理路径的领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17057v1",
      "published_date": "2024-05-27 11:27:00 UTC",
      "updated_date": "2024-05-27 11:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:36:46.307164"
    },
    {
      "arxiv_id": "2405.17053v2",
      "title": "WirelessLLM: Empowering Large Language Models Towards Wireless Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Shao",
        "Jingwen Tong",
        "Qiong Wu",
        "Wei Guo",
        "Zijian Li",
        "Zehong Lin",
        "Jun Zhang"
      ],
      "abstract": "The rapid evolution of wireless technologies and the growing complexity of\nnetwork infrastructures necessitate a paradigm shift in how communication\nnetworks are designed, configured, and managed. Recent advancements in Large\nLanguage Models (LLMs) have sparked interest in their potential to\nrevolutionize wireless communication systems. However, existing studies on LLMs\nfor wireless systems are limited to a direct application for telecom language\nunderstanding. To empower LLMs with knowledge and expertise in the wireless\ndomain, this paper proposes WirelessLLM, a comprehensive framework for adapting\nand enhancing LLMs to address the unique challenges and requirements of\nwireless communication networks. We first identify three foundational\nprinciples that underpin WirelessLLM: knowledge alignment, knowledge fusion,\nand knowledge evolution. Then, we investigate the enabling technologies to\nbuild WirelessLLM, including prompt engineering, retrieval augmented\ngeneration, tool usage, multi-modal pre-training, and domain-specific\nfine-tuning. Moreover, we present three case studies to demonstrate the\npractical applicability and benefits of WirelessLLM for solving typical\nproblems in wireless networks. Finally, we conclude this paper by highlighting\nkey challenges and outlining potential avenues for future research.",
      "tldr_zh": "该论文提出 WirelessLLM 框架，以增强 Large Language Models (LLMs) 在无线通信领域的智能应用，解决现有研究仅限于电信语言理解的局限性。框架基于三个基础原则——knowledge alignment、knowledge fusion 和 knowledge evolution，并采用提示工程、retrieval augmented generation、工具使用、多模态预训练和领域特定微调等技术来适应无线网络的挑战。通过三个案例研究，WirelessLLM 展示了其在解决无线问题方面的实际益处，并讨论了关键挑战及未来研究方向。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17053v2",
      "published_date": "2024-05-27 11:18:25 UTC",
      "updated_date": "2024-06-15 07:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:37:00.333291"
    },
    {
      "arxiv_id": "2405.17051v1",
      "title": "BeamVQ: Aligning Space-Time Forecasting Model via Self-training on Physics-aware Metrics",
      "title_zh": "BeamVQ: 通过基于物理感知指标的自训练对齐时空预测模型",
      "authors": [
        "Hao Wu",
        "Xingjian Shi",
        "Ziyue Huang",
        "Penghao Zhao",
        "Wei Xiong",
        "Jinbao Xue",
        "Yangyu Tao",
        "Xiaomeng Huang",
        "Weiyan Wang"
      ],
      "abstract": "Data-driven deep learning has emerged as the new paradigm to model complex\nphysical space-time systems. These data-driven methods learn patterns by\noptimizing statistical metrics and tend to overlook the adherence to physical\nlaws, unlike traditional model-driven numerical methods. Thus, they often\ngenerate predictions that are not physically realistic. On the other hand, by\nsampling a large amount of high quality predictions from a data-driven model,\nsome predictions will be more physically plausible than the others and closer\nto what will happen in the future. Based on this observation, we propose\n\\emph{Beam search by Vector Quantization} (BeamVQ) to enhance the physical\nalignment of data-driven space-time forecasting models. The key of BeamVQ is to\ntrain model on self-generated samples filtered with physics-aware metrics. To\nbe flexibly support different backbone architectures, BeamVQ leverages a code\nbank to transform any encoder-decoder model to the continuous state space into\ndiscrete codes. Afterwards, it iteratively employs beam search to sample\nhigh-quality sequences, retains those with the highest physics-aware scores,\nand trains model on the new dataset. Comprehensive experiments show that BeamVQ\nnot only gave an average statistical skill score boost for more than 32% for\nten backbones on five datasets, but also significantly enhances physics-aware\nmetrics.",
      "tldr_zh": "该论文指出，数据驱动的深度学习模型在建模复杂物理时空系统时，通常优化统计指标而忽略物理定律，导致预测结果不现实。为解决这一问题，提出 BeamVQ 方法，通过自训练和基于 physics-aware metrics 的过滤来提升模型的物理一致性。具体而言，BeamVQ 利用 Vector Quantization 将编码器-解码器模型转化为离散代码，然后通过 beam search 采样高质量序列，并用物理感知分数最高的序列进行迭代训练。实验结果显示，BeamVQ 在五个数据集上为十个骨干模型平均提高了超过32%的统计技能分数，同时显著改善了物理感知指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17051v1",
      "published_date": "2024-05-27 11:07:47 UTC",
      "updated_date": "2024-05-27 11:07:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:37:09.807027"
    },
    {
      "arxiv_id": "2405.17044v3",
      "title": "Interesting Scientific Idea Generation using Knowledge Graphs and LLMs: Evaluations with 100 Research Group Leaders",
      "title_zh": "翻译失败",
      "authors": [
        "Xuemei Gu",
        "Mario Krenn"
      ],
      "abstract": "The rapid growth of scientific literature makes it challenging for\nresearchers to identify novel and impactful ideas, especially across\ndisciplines. Modern artificial intelligence (AI) systems offer new approaches,\npotentially inspiring ideas not conceived by humans alone. But how compelling\nare these AI-generated ideas, and how can we improve their quality? Here, we\nintroduce SciMuse, which uses 58 million research papers and a large-language\nmodel to generate research ideas. We conduct a large-scale evaluation in which\nover 100 research group leaders -- from natural sciences to humanities --\nranked more than 4,400 personalized ideas based on their interest. This data\nallows us to predict research interest using (1) supervised neural networks\ntrained on human evaluations, and (2) unsupervised zero-shot ranking with\nlarge-language models. Our results demonstrate how future systems can help\ngenerating compelling research ideas and foster unforeseen interdisciplinary\ncollaborations.",
      "tldr_zh": "本研究针对科学文献快速增长导致的创新想法识别难题，引入SciMuse系统，该系统利用知识图谱(Knowledge Graphs)和大型语言模型(LLMs)基于5800万篇论文生成个性化研究想法。研究者对4400多个想法进行大规模评估，由超过100名跨学科研究组领导者（从自然科学到人文）基于兴趣进行排名。结果显示，通过监督神经网络和无监督零样本排名(Zero-Shot Ranking)，系统能有效预测研究兴趣，提升AI生成想法的质量，并促进意想不到的跨学科合作。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages; 4 figures; Appendix: 6 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.17044v3",
      "published_date": "2024-05-27 11:00:51 UTC",
      "updated_date": "2025-01-07 21:29:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:37:21.077842"
    },
    {
      "arxiv_id": "2406.00036v2",
      "title": "EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation",
      "title_zh": "EMERGE：通过检索增强生成提升多模态电子健康记录预测建模",
      "authors": [
        "Yinghao Zhu",
        "Changyu Ren",
        "Zixiang Wang",
        "Xiaochen Zheng",
        "Shiyun Xie",
        "Junlan Feng",
        "Xi Zhu",
        "Zhoujun Li",
        "Liantao Ma",
        "Chengwei Pan"
      ],
      "abstract": "The integration of multimodal Electronic Health Records (EHR) data has\nsignificantly advanced clinical predictive capabilities. Existing models, which\nutilize clinical notes and multivariate time-series EHR data, often fall short\nof incorporating the necessary medical context for accurate clinical tasks,\nwhile previous approaches with knowledge graphs (KGs) primarily focus on\nstructured knowledge extraction. In response, we propose EMERGE, a\nRetrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR\npredictive modeling. We extract entities from both time-series data and\nclinical notes by prompting Large Language Models (LLMs) and align them with\nprofessional PrimeKG, ensuring consistency. In addition to triplet\nrelationships, we incorporate entities' definitions and descriptions for richer\nsemantics. The extracted knowledge is then used to generate task-relevant\nsummaries of patients' health statuses. Finally, we fuse the summary with other\nmodalities using an adaptive multimodal fusion network with cross-attention.\nExtensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital\nmortality and 30-day readmission tasks demonstrate the superior performance of\nthe EMERGE framework over baseline models. Comprehensive ablation studies and\nanalysis highlight the efficacy of each designed module and robustness to data\nsparsity. EMERGE contributes to refining the utilization of multimodal EHR data\nin healthcare, bridging the gap with nuanced medical contexts essential for\ninformed clinical predictions. We have publicly released the code at\nhttps://github.com/yhzhu99/EMERGE.",
      "tldr_zh": "本文提出EMERGE框架，利用Retrieval-Augmented Generation (RAG)技术增强多模态Electronic Health Records (EHR)数据的预测建模，旨在解决现有模型在医疗背景整合方面的不足。框架通过Large Language Models (LLMs)提示从时间序列数据和临床笔记中提取实体，并与PrimeKG对齐，生成丰富的语义摘要，然后使用自适应多模态融合网络（包括交叉注意力）融合多模态信息。实验在MIMIC-III和MIMIC-IV数据集上显示，EMERGE在院内死亡率和30天再入院任务中比基线模型表现更优越，并通过消融研究验证了各模块的有效性和对数据稀疏性的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "CIKM 2024 Full Research Paper; arXiv admin note: text overlap with\n  arXiv:2402.07016",
      "pdf_url": "http://arxiv.org/pdf/2406.00036v2",
      "published_date": "2024-05-27 10:53:15 UTC",
      "updated_date": "2025-02-26 13:18:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:37:35.563022"
    },
    {
      "arxiv_id": "2405.17038v1",
      "title": "Advancements in Tactile Hand Gesture Recognition for Enhanced Human-Machine Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Chiara Fumelli",
        "Anirvan Dutta",
        "Mohsen Kaboli"
      ],
      "abstract": "Motivated by the growing interest in enhancing intuitive physical\nHuman-Machine Interaction (HRI/HVI), this study aims to propose a robust\ntactile hand gesture recognition system. We performed a comprehensive\nevaluation of different hand gesture recognition approaches for a large area\ntactile sensing interface (touch interface) constructed from conductive\ntextiles. Our evaluation encompassed traditional feature engineering methods,\nas well as contemporary deep learning techniques capable of real-time\ninterpretation of a range of hand gestures, accommodating variations in hand\nsizes, movement velocities, applied pressure levels, and interaction points.\nOur extensive analysis of the various methods makes a significant contribution\nto tactile-based gesture recognition in the field of human-machine interaction.",
      "tldr_zh": "本研究旨在提升人类-机器交互（Human-Machine Interaction）的直观性，通过提出一个鲁棒的触觉手势识别系统。研究团队对基于导电纺织物的大型触觉界面进行了全面评估，涵盖了传统特征工程方法和现代深度学习技术，以实时识别各种手势，并适应手部大小、运动速度、施加压力和交互点等变异。结果显示，该系统在触觉-based 手势识别领域做出了重大贡献，为更高效的交互提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17038v1",
      "published_date": "2024-05-27 10:44:27 UTC",
      "updated_date": "2024-05-27 10:44:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:37:47.687895"
    },
    {
      "arxiv_id": "2405.17034v2",
      "title": "FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Renqiang Luo",
        "Huafei Huang",
        "Shuo Yu",
        "Zhuoyang Han",
        "Estrid He",
        "Xiuzhen Zhang",
        "Feng Xia"
      ],
      "abstract": "Fairness-aware Graph Neural Networks (GNNs) often face a challenging\ntrade-off, where prioritizing fairness may require compromising utility. In\nthis work, we re-examine fairness through the lens of spectral graph theory,\naiming to reconcile fairness and utility within the framework of spectral graph\nlearning. We explore the correlation between sensitive features and spectrum in\nGNNs, using theoretical analysis to delineate the similarity between original\nsensitive features and those after convolution under different spectra. Our\nanalysis reveals a reduction in the impact of similarity when the eigenvectors\nassociated with the largest magnitude eigenvalue exhibit directional\nsimilarity. Based on these theoretical insights, we propose FUGNN, a novel\nspectral graph learning approach that harmonizes the conflict between fairness\nand utility. FUGNN ensures algorithmic fairness and utility by truncating the\nspectrum and optimizing eigenvector distribution during the encoding process.\nThe fairness-aware eigenvector selection reduces the impact of convolution on\nsensitive features while concurrently minimizing the sacrifice of utility.\nFUGNN further optimizes the distribution of eigenvectors through a transformer\narchitecture. By incorporating the optimized spectrum into the graph\nconvolution network, FUGNN effectively learns node representations. Experiments\non six real-world datasets demonstrate the superiority of FUGNN over baseline\nmethods. The codes are available at https://github.com/yushuowiki/FUGNN.",
      "tldr_zh": "本文研究了公平性感知的 Graph Neural Networks (GNNs) 在公平性和实用性之间的权衡问题，通过谱图理论分析敏感特征与谱的相关性，揭示卷积前后特征相似性的影响机制。作者提出 FUGNN 框架，该框架通过截断谱、优化特征向量分布以及整合 Transformer 架构，来减少对敏感特征的影响，同时最小化实用性的牺牲。实验结果显示，FUGNN 在六个真实数据集上优于基线方法，为 GNNs 的公平性优化提供了有效途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in SIGKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17034v2",
      "published_date": "2024-05-27 10:40:21 UTC",
      "updated_date": "2024-08-13 15:04:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:38:01.798061"
    },
    {
      "arxiv_id": "2405.17025v1",
      "title": "SWAT: Scalable and Efficient Window Attention-based Transformers Acceleration on FPGAs",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Bai",
        "Pranav Dangi",
        "Huize Li",
        "Tulika Mitra"
      ],
      "abstract": "Efficiently supporting long context length is crucial for Transformer models.\nThe quadratic complexity of the self-attention computation plagues traditional\nTransformers. Sliding window-based static sparse attention mitigates the\nproblem by limiting the attention scope of the input tokens, reducing the\ntheoretical complexity from quadratic to linear. Although the sparsity induced\nby window attention is highly structured, it does not align perfectly with the\nmicroarchitecture of the conventional accelerators, leading to suboptimal\nimplementation. In response, we propose a dataflow-aware FPGA-based accelerator\ndesign, SWAT, that efficiently leverages the sparsity to achieve scalable\nperformance for long input. The proposed microarchitecture is based on a design\nthat maximizes data reuse by using a combination of row-wise dataflow, kernel\nfusion optimization, and an input-stationary design considering the distributed\nmemory and computation resources of FPGA. Consequently, it achieves up to\n22$\\times$ and 5.7$\\times$ improvement in latency and energy efficiency\ncompared to the baseline FPGA-based accelerator and 15$\\times$ energy\nefficiency compared to GPU-based solution.",
      "tldr_zh": "这篇论文针对 Transformer 模型的自注意力计算的二次方复杂度问题，提出了一种基于 FPGA 的加速器设计 SWAT，利用 sliding window-based static sparse attention 的结构化稀疏性来实现线性复杂度并支持长上下文。SWAT 通过 row-wise dataflow、kernel fusion optimization 和 input-stationary design 等优化，最大化数据重用并充分利用 FPGA 的分布式内存和计算资源。实验结果显示，与基线 FPGA 加速器相比，SWAT 的延迟改善高达 22 倍，能源效率提高 5.7 倍；与 GPU 方案相比，能源效率提升 15 倍。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepeted paper for DAC'22",
      "pdf_url": "http://arxiv.org/pdf/2405.17025v1",
      "published_date": "2024-05-27 10:25:08 UTC",
      "updated_date": "2024-05-27 10:25:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:38:12.979744"
    },
    {
      "arxiv_id": "2405.17022v1",
      "title": "Compositional Few-Shot Class-Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiong Zou",
        "Shanghang Zhang",
        "Haichen Zhou",
        "Yuhua Li",
        "Ruixuan Li"
      ],
      "abstract": "Few-shot class-incremental learning (FSCIL) is proposed to continually learn\nfrom novel classes with only a few samples after the (pre-)training on base\nclasses with sufficient data. However, this remains a challenge. In contrast,\nhumans can easily recognize novel classes with a few samples. Cognitive science\ndemonstrates that an important component of such human capability is\ncompositional learning. This involves identifying visual primitives from\nlearned knowledge and then composing new concepts using these transferred\nprimitives, making incremental learning both effective and interpretable. To\nimitate human compositional learning, we propose a cognitive-inspired method\nfor the FSCIL task. We define and build a compositional model based on set\nsimilarities, and then equip it with a primitive composition module and a\nprimitive reuse module. In the primitive composition module, we propose to\nutilize the Centered Kernel Alignment (CKA) similarity to approximate the\nsimilarity between primitive sets, allowing the training and evaluation based\non primitive compositions. In the primitive reuse module, we enhance primitive\nreusability by classifying inputs based on primitives replaced with the closest\nprimitives from other classes. Experiments on three datasets validate our\nmethod, showing it outperforms current state-of-the-art methods with improved\ninterpretability. Our code is available at\nhttps://github.com/Zoilsen/Comp-FSCIL.",
      "tldr_zh": "该论文针对 Few-Shot Class-Incremental Learning (FSCIL) 问题，提出一种受认知科学启发的组合学习方法，以模仿人类通过识别视觉基元并组合新概念来高效学习新类。方法包括构建基于集合相似性的组合模型，配备 primitive composition module（利用 Centered Kernel Alignment (CKA) 相似性评估基元集合）和 primitive reuse module（通过替换输入基元增强可重用性）。实验在三个数据集上验证了该方法的有效性，性能超越当前最先进方法，并提升了模型的可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17022v1",
      "published_date": "2024-05-27 10:21:38 UTC",
      "updated_date": "2024-05-27 10:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:38:25.640002"
    },
    {
      "arxiv_id": "2405.17009v3",
      "title": "Position: Foundation Agents as the Paradigm Shift for Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoqian Liu",
        "Xingzhou Lou",
        "Jianbin Jiao",
        "Junge Zhang"
      ],
      "abstract": "Decision making demands intricate interplay between perception, memory, and\nreasoning to discern optimal policies. Conventional approaches to decision\nmaking face challenges related to low sample efficiency and poor\ngeneralization. In contrast, foundation models in language and vision have\nshowcased rapid adaptation to diverse new tasks. Therefore, we advocate for the\nconstruction of foundation agents as a transformative shift in the learning\nparadigm of agents. This proposal is underpinned by the formulation of\nfoundation agents with their fundamental characteristics and challenges\nmotivated by the success of large language models (LLMs). Moreover, we specify\nthe roadmap of foundation agents from large interactive data collection or\ngeneration, to self-supervised pretraining and adaptation, and knowledge and\nvalue alignment with LLMs. Lastly, we pinpoint critical research questions\nderived from the formulation and delineate trends for foundation agents\nsupported by real-world use cases, addressing both technical and theoretical\naspects to propel the field towards a more comprehensive and impactful future.",
      "tldr_zh": "该论文主张将 foundation agents 视为决策领域的范式转变，以解决传统方法在样本效率和泛化方面的不足，强调其通过感知、记忆和推理的交互来优化决策策略。作者借鉴大型语言模型(LLMs)的成功，定义了 foundation agents 的核心特征和挑战，包括从大型交互数据收集、self-supervised pretraining 到适应过程，以及知识和价值 alignment 的路线图。最后，论文指出了关键研究问题和趋势，支持其在实际应用中的推广，推动决策代理的全面发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, camera-ready version of ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.17009v3",
      "published_date": "2024-05-27 09:54:50 UTC",
      "updated_date": "2024-05-29 14:15:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:38:36.182972"
    },
    {
      "arxiv_id": "2406.01607v2",
      "title": "Recent advances in text embedding: A Comprehensive Review of Top-Performing Methods on the MTEB Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Hongliu Cao"
      ],
      "abstract": "Text embedding methods have become increasingly popular in both industrial\nand academic fields due to their critical role in a variety of natural language\nprocessing tasks. The significance of universal text embeddings has been\nfurther highlighted with the rise of Large Language Models (LLMs) applications\nsuch as Retrieval-Augmented Systems (RAGs). While previous models have\nattempted to be general-purpose, they often struggle to generalize across tasks\nand domains. However, recent advancements in training data quantity, quality\nand diversity; synthetic data generation from LLMs as well as using LLMs as\nbackbones encourage great improvements in pursuing universal text embeddings.\nIn this paper, we provide an overview of the recent advances in universal text\nembedding models with a focus on the top performing text embeddings on Massive\nText Embedding Benchmark (MTEB). Through detailed comparison and analysis, we\nhighlight the key contributions and limitations in this area, and propose\npotentially inspiring future research directions.",
      "tldr_zh": "这篇论文回顾了文本嵌入（text embedding）方法的最新进展，强调其在自然语言处理任务中的关键作用，尤其是在大语言模型（LLMs）和检索增强系统（RAGs）应用中的重要性。作者分析了训练数据质量、合成数据生成以及LLMs作为骨干的改进，这些因素帮助提升了通用文本嵌入模型的泛化能力，并在Massive Text Embedding Benchmark (MTEB)上表现突出。通过详细比较顶尖模型的贡献和局限性，论文提出了未来研究方向，以推动该领域的进一步发展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.01607v2",
      "published_date": "2024-05-27 09:52:54 UTC",
      "updated_date": "2024-06-19 06:52:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:38:47.620807"
    },
    {
      "arxiv_id": "2405.16994v1",
      "title": "Vision-and-Language Navigation Generative Pretrained Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Hanlin"
      ],
      "abstract": "In the Vision-and-Language Navigation (VLN) field, agents are tasked with\nnavigating real-world scenes guided by linguistic instructions. Enabling the\nagent to adhere to instructions throughout the process of navigation represents\na significant challenge within the domain of VLN. To address this challenge,\ncommon approaches often rely on encoders to explicitly record past locations\nand actions, increasing model complexity and resource consumption. Our\nproposal, the Vision-and-Language Navigation Generative Pretrained Transformer\n(VLN-GPT), adopts a transformer decoder model (GPT2) to model trajectory\nsequence dependencies, bypassing the need for historical encoding modules. This\nmethod allows for direct historical information access through trajectory\nsequence, enhancing efficiency. Furthermore, our model separates the training\nprocess into offline pre-training with imitation learning and online\nfine-tuning with reinforcement learning. This distinction allows for more\nfocused training objectives and improved performance. Performance assessments\non the VLN dataset reveal that VLN-GPT surpasses complex state-of-the-art\nencoder-based models.",
      "tldr_zh": "本研究针对Vision-and-Language Navigation (VLN)领域的挑战，提出了一种名为VLN-GPT的模型，利用Transformer解码器（基于GPT2）来建模轨迹序列依赖性，从而避免了传统方法依赖历史编码模块带来的复杂性和资源消耗。VLN-GPT通过直接访问轨迹序列获取历史信息，提高了代理遵循语言指令的效率，并将训练过程分为离线预训练（采用imitation learning）和在线微调（采用reinforcement learning），以实现更专注的训练目标。在VLN数据集上的评估显示，VLN-GPT超越了现有的复杂基于编码器的最先进模型，展示了显著的性能提升。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16994v1",
      "published_date": "2024-05-27 09:42:04 UTC",
      "updated_date": "2024-05-27 09:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:38:59.508105"
    },
    {
      "arxiv_id": "2405.17516v2",
      "title": "Time Elastic Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre-François Marteau"
      ],
      "abstract": "We introduce and detail an atypical neural network architecture, called time\nelastic neural network (teNN), for multivariate time series classification. The\nnovelty compared to classical neural network architecture is that it explicitly\nincorporates time warping ability, as well as a new way of considering\nattention. In addition, this architecture is capable of learning a dropout\nstrategy, thus optimizing its own architecture.Behind the design of this\narchitecture, our overall objective is threefold: firstly, we are aiming at\nimproving the accuracy of instance based classification approaches that shows\nquite good performances as far as enough training data is available. Secondly\nwe seek to reduce the computational complexity inherent to these methods to\nimprove their scalability. Ideally, we seek to find an acceptable balance\nbetween these first two criteria. And finally, we seek to enhance the\nexplainability of the decision provided by this kind of neural architecture.The\nexperiment demonstrates that the stochastic gradient descent implemented to\ntrain a teNN is quite effective. To the extent that the selection of some\ncritical meta-parameters is correct, convergence is generally smooth and\nfast.While maintaining good accuracy, we get a drastic gain in scalability by\nfirst reducing the required number of reference time series, i.e. the number of\nteNN cells required. Secondly, we demonstrate that, during the training\nprocess, the teNN succeeds in reducing the number of neurons required within\neach cell. Finally, we show that the analysis of the activation and attention\nmatrices as well as the reference time series after training provides relevant\ninformation to interpret and explain the classification results.The comparative\nstudy that we have carried out and which concerns around thirty diverse and\nmultivariate datasets shows that the teNN obtains results comparable to those\nof the state of the art, in particular similar to those of a network mixing\nLSTM and CNN architectures for example.",
      "tldr_zh": "本研究提出了一种新型神经网络架构，time elastic neural network (teNN)，用于多变量时间序列分类，其创新之处在于显式整合time warping能力、新型attention机制以及自适应dropout策略，以优化网络结构。teNN的目标是提升基于实例的分类准确性、减少计算复杂性并增强决策的可解释性，通过随机梯度下降(stochastic gradient descent)训练实现平滑快速的收敛。实验结果显示，teNN在减少参考时间序列和神经元数量的同时，维持了高准确性，并在约30个多变量数据集上，其性能与最先进方法（如混合LSTM和CNN架构）相当。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17516v2",
      "published_date": "2024-05-27 09:01:30 UTC",
      "updated_date": "2024-06-13 07:34:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:39:12.440533"
    },
    {
      "arxiv_id": "2405.16964v2",
      "title": "Exploring the LLM Journey from Cognition to Expression with Linear Representations",
      "title_zh": "利用线性表示探索 LLM 从认知到表达的旅程",
      "authors": [
        "Yuzi Yan",
        "Jialian Li",
        "Yipin Zhang",
        "Dong Yan"
      ],
      "abstract": "This paper presents an in-depth examination of the evolution and interplay of\ncognitive and expressive capabilities in large language models (LLMs), with a\nspecific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese\nand English) LLM series. We define and explore the model's cognitive and\nexpressive capabilities through linear representations across three critical\nphases: Pretraining, Supervised Fine-Tuning (SFT), and Reinforcement Learning\nfrom Human Feedback (RLHF). Cognitive capability is defined as the quantity and\nquality of information conveyed by the neuron output vectors within the\nnetwork, similar to the neural signal processing in human cognition. Expressive\ncapability is defined as the model's capability to produce word-level output.\nOur findings unveil a sequential development pattern, where cognitive abilities\nare largely established during Pretraining, whereas expressive abilities\npredominantly advance during SFT and RLHF. Statistical analyses confirm a\nsignificant correlation between the two capabilities, suggesting that cognitive\ncapacity may limit expressive potential. The paper also explores the\ntheoretical underpinnings of these divergent developmental trajectories and\ntheir connection to the LLMs' architectural design. Moreover, we evaluate\nvarious optimization-independent strategies, such as few-shot learning and\nrepeated sampling, which bridge the gap between cognitive and expressive\ncapabilities. This research reveals the potential connection between the hidden\nspace and the output space, contributing valuable insights into the\ninterpretability and controllability of their training processes.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）如 Baichuan-7B 和 Baichuan-33B 的认知和表达能力的演变，通过线性表示分析预训练（Pretraining）、监督微调（SFT）和强化学习（RLHF）三个阶段。研究定义认知能力为神经元输出向量的信息量和质量，而表达能力为模型产生词级输出的能力，结果显示认知能力主要在预训练阶段建立，表达能力则在 SFT 和 RLHF 阶段显著提升，且两者存在显著相关性，暗示认知能力可能限制表达潜力。该研究还评估了 few-shot learning 和 repeated sampling 等优化无关策略，以桥接能力差距，并揭示隐藏空间与输出空间的潜在连接，提升 LLMs 训练过程的可解释性和可控性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16964v2",
      "published_date": "2024-05-27 08:57:04 UTC",
      "updated_date": "2024-11-08 05:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:39:25.634698"
    },
    {
      "arxiv_id": "2405.16961v2",
      "title": "Blind Data Adaptation to tackle Covariate Shift in Operational Steganalysis",
      "title_zh": "翻译失败",
      "authors": [
        "Rony Abecidan",
        "Vincent Itier",
        "Jérémie Boulanger",
        "Patrick Bas",
        "Tomáš Pevný"
      ],
      "abstract": "The proliferation of image manipulation for unethical purposes poses\nsignificant challenges in social networks. One particularly concerning method\nis Image Steganography, allowing individuals to hide illegal information in\ndigital images without arousing suspicions. Such a technique pose severe\nsecurity risks, making it crucial to develop effective steganalysis methods\nenabling to detect manipulated images for clandestine communications. Although\nsignificant advancements have been achieved with machine learning models, a\ncritical issue remains: the disparity between the controlled datasets used to\ntrain steganalysis models against real-world datasets of forensic\npractitioners, undermining severely the practical effectiveness of standardized\nsteganalysis models. In this paper, we address this issue focusing on a\nrealistic scenario where practitioners lack crucial information about the\nlimited target set of images under analysis, including details about their\ndevelopment process and even whereas it contains manipulated images or not. By\nleveraging geometric alignment and distribution matching of source and target\nresiduals, we develop TADA (Target Alignment through Data Adaptation), a novel\nmethodology enabling to emulate sources aligned with specific targets in\nsteganalysis, which is also relevant for highly unbalanced targets. The\nemulator is represented by a light convolutional network trained to align\ndistributions of image residuals. Experimental validation demonstrates the\npotential of our strategy over traditional methods fighting covariate shift in\nsteganalysis.",
      "tldr_zh": "本研究针对图像隐写术（Image Steganography）在实际应用中的协变量偏移（Covariate Shift）问题，提出了一种盲数据适应方法TADA（Target Alignment through Data Adaptation），以提升操作性隐写分析（Operational Steganalysis）的效果。TADA通过几何对齐和源目标残差分布匹配，利用一个轻量卷积网络训练来模拟与特定目标图像集对齐的源数据，从而处理真实场景中信息缺失和高不平衡挑战。实验结果显示，该方法在隐写分析中显著优于传统策略，证明了其在检测操纵图像方面的实用潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CR",
        "cs.MM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16961v2",
      "published_date": "2024-05-27 08:55:22 UTC",
      "updated_date": "2024-05-29 06:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:39:36.161737"
    },
    {
      "arxiv_id": "2405.16956v2",
      "title": "Functional Programming Paradigm of Python for Scientific Computation Pipeline Integration",
      "title_zh": "Python 的函数式编程范式用于科学计算管道集成",
      "authors": [
        "Chen Zhang",
        "Lecheng Jia",
        "Wei Zhang",
        "Ning Wen"
      ],
      "abstract": "The advent of modern data processing has led to an increasing tendency\ntowards interdisciplinarity, which frequently involves the importation of\ndifferent technical approaches. Consequently, there is an urgent need for a\nunified data control system to facilitate the integration of varying libraries.\nThis integration is of profound significance in accelerating prototype\nverification, optimising algorithm performance and minimising maintenance\ncosts. This paper presents a novel functional programming (FP) paradigm based\non the Python architecture and associated suites in programming practice,\ndesigned for the integration of pipelines of different data mapping operations.\nIn particular, the solution is intended for the integration of scientific\ncomputation flows, which affords a robust yet flexible solution for the\naforementioned challenges.",
      "tldr_zh": "现代数据处理日益强调跨学科整合，论文提出了一种基于 Python 的函数式编程 (FP) 范式，用于统一数据控制系统以整合不同数据映射操作的管道。  \n这种方法特别针对科学计算流程，能够加速原型验证、优化算法性能并降低维护成本。  \n总体而言，该范式提供了一个鲁棒且灵活的解决方案，解决了当前数据整合面临的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.16956v2",
      "published_date": "2024-05-27 08:46:57 UTC",
      "updated_date": "2024-06-03 10:42:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:39:47.411135"
    },
    {
      "arxiv_id": "2406.18557v1",
      "title": "Experimental Evaluation of Road-Crossing Decisions by Autonomous Wheelchairs against Environmental Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Franca Corradini",
        "Carlo Grigioni",
        "Alessandro Antonucci",
        "Jérôme Guzzi",
        "Francesco Flammini"
      ],
      "abstract": "Safe road crossing by autonomous wheelchairs can be affected by several\nenvironmental factors such as adverse weather conditions influencing the\naccuracy of artificial vision. Previous studies have addressed experimental\nevaluation of multi-sensor information fusion to support road-crossing\ndecisions in autonomous wheelchairs. In this study, we focus on the fine-tuning\nof tracking performance and on its experimental evaluation against outdoor\nenvironmental factors such as fog, rain, darkness, etc. It is rather intuitive\nthat those factors can negatively affect the tracking performance; therefore\nour aim is to provide an approach to quantify their effects in the reference\nscenario, in order to detect conditions of unacceptable accuracy. In those\ncases, warnings can be issued and system can be possibly reconfigured to reduce\nthe reputation of less accurate sensors, and thus improve overall safety.\nCritical situations can be detected by the main sensors or by additional\nsensors, e.g., light sensors, rain sensors, etc. Results have been achieved by\nusing an available laboratory dataset and by applying appropriate software\nfilters; they show that the approach can be adopted to evaluate video tracking\nand event detection robustness against outdoor environmental factors in\nrelevant operational scenarios.",
      "tldr_zh": "该研究实验评估了自主轮椅在 environmental factors（如雾、雨、黑暗等）下的道路穿越决策性能，旨在量化这些因素对 tracking performance 的负面影响。研究通过微调跟踪性能和多传感器信息融合方法，使用实验室数据集和软件过滤器进行实验，检测不可接受的准确性条件。结果显示，该方法能有效识别关键情况、发出警告并重新配置系统（如减少不准确 sensors 的依赖），从而提升视频跟踪和事件检测的鲁棒性及整体安全性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T45 (Primary), 68T37 (Secondary)",
        "I.2.10; I.2.9; C.4; I.4.8"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to the \"27th IEEE International Conference on Intelligent\n  Transportation Systems\"",
      "pdf_url": "http://arxiv.org/pdf/2406.18557v1",
      "published_date": "2024-05-27 08:43:26 UTC",
      "updated_date": "2024-05-27 08:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:40:01.880069"
    },
    {
      "arxiv_id": "2405.16946v1",
      "title": "Biological Neurons Compete with Deep Reinforcement Learning in Sample Efficiency in a Simulated Gameworld",
      "title_zh": "翻译失败",
      "authors": [
        "Moein Khajehnejad",
        "Forough Habibollahi",
        "Aswin Paul",
        "Adeel Razi",
        "Brett J. Kagan"
      ],
      "abstract": "How do biological systems and machine learning algorithms compare in the\nnumber of samples required to show significant improvements in completing a\ntask? We compared the learning efficiency of in vitro biological neural\nnetworks to the state-of-the-art deep reinforcement learning (RL) algorithms in\na simplified simulation of the game `Pong'. Using DishBrain, a system that\nembodies in vitro neural networks with in silico computation using a\nhigh-density multi-electrode array, we contrasted the learning rate and the\nperformance of these biological systems against time-matched learning from\nthree state-of-the-art deep RL algorithms (i.e., DQN, A2C, and PPO) in the same\ngame environment. This allowed a meaningful comparison between biological\nneural systems and deep RL. We find that when samples are limited to a\nreal-world time course, even these very simple biological cultures outperformed\ndeep RL algorithms across various game performance characteristics, implying a\nhigher sample efficiency. Ultimately, even when tested across multiple types of\ninformation input to assess the impact of higher dimensional data input,\nbiological neurons showcased faster learning than all deep reinforcement\nlearning agents.",
      "tldr_zh": "本研究比较了生物神经网络和深度强化学习（Deep Reinforcement Learning）算法在完成任务时所需的样本数量，焦点放在简化版 Pong 游戏的模拟环境中。研究利用 DishBrain 系统，将体外生物神经网络与高密度多电极阵列相结合，与 DQN、A2C 和 PPO 等算法进行学习效率对比。结果显示，在有限的真实世界时间样本下，生物神经网络表现出更高的样本效率和更快学习速度，即使在更高维数据输入条件下，也优于所有深度强化学习代理。最终，这表明生物系统在样本效率方面具有显著优势。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "13 Pages, 6 Figures - 38 Supplementary Pages, 6 Supplementary\n  Figures, 4 Supplementary Tables",
      "pdf_url": "http://arxiv.org/pdf/2405.16946v1",
      "published_date": "2024-05-27 08:38:17 UTC",
      "updated_date": "2024-05-27 08:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:40:22.201519"
    },
    {
      "arxiv_id": "2405.17514v3",
      "title": "AbstractBeam: Enhancing Bottom-Up Program Synthesis using Library Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Janis Zenkner",
        "Lukas Dierkes",
        "Tobias Sesterhenn",
        "Chrisitan Bartelt"
      ],
      "abstract": "LambdaBeam is a state-of-the-art, execution-guided algorithm for program\nsynthesis that utilizes higher-order functions, lambda functions, and iterative\nloops within a Domain-Specific Language (DSL). LambdaBeam generates each\nprogram from scratch but does not take advantage of the frequent recurrence of\nprogram blocks or subprograms commonly found in specific domains, such as loops\nfor list traversal. To address this limitation, we introduce AbstractBeam: a\nnovel program synthesis framework designed to enhance LambdaBeam by leveraging\nLibrary Learning. AbstractBeam identifies and integrates recurring program\nstructures into the DSL, optimizing the synthesis process. Our experimental\nevaluations demonstrate that AbstractBeam statistically significantly (p <\n0.05) outperforms LambdaBeam in the integer list manipulation domain. Beyond\nsolving more tasks, AbstractBeam's program synthesis is also more efficient,\nrequiring less time and fewer candidate programs to generate a solution.\nFurthermore, our findings indicate that Library Learning effectively enhances\nprogram synthesis in domains that are not explicitly designed to showcase its\nadvantages, thereby highlighting the broader applicability of Library Learning.",
      "tldr_zh": "本文提出 AbstractBeam，一种新型程序合成框架，通过 Library Learning 技术增强 LambdaBeam 的能力，针对 Domain-Specific Language (DSL) 中常见程序块（如列表遍历循环）的重复使用，优化从头生成程序的过程。AbstractBeam 能识别并整合这些 recurring program structures，从而提高合成效率和准确性。在实验中，AbstractBeam 在整数列表操作领域显著优于 LambdaBeam（p < 0.05），不仅解决更多任务，还减少了时间和候选程序数量。该框架还证明 Library Learning 在非专属设计领域具有广泛适用性，进一步拓展了程序合成的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17514v3",
      "published_date": "2024-05-27 08:31:12 UTC",
      "updated_date": "2024-09-12 06:11:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:40:24.304585"
    },
    {
      "arxiv_id": "2405.16929v2",
      "title": "Uncertainty Management in the Construction of Knowledge Graphs: a Survey",
      "title_zh": "知识图谱构建中的不确定性管理：一个综述",
      "authors": [
        "Lucas Jarnac",
        "Yoan Chabot",
        "Miguel Couceiro"
      ],
      "abstract": "Knowledge Graphs (KGs) are a major asset for companies thanks to their great\nflexibility in data representation and their numerous applications, e.g.,\nvocabulary sharing, Q/A or recommendation systems. To build a KG it is a common\npractice to rely on automatic methods for extracting knowledge from various\nheterogeneous sources. But in a noisy and uncertain world, knowledge may not be\nreliable and conflicts between data sources may occur. Integrating unreliable\ndata would directly impact the use of the KG, therefore such conflicts must be\nresolved. This could be done manually by selecting the best data to integrate.\nThis first approach is highly accurate, but costly and time-consuming. That is\nwhy recent efforts focus on automatic approaches, which represents a\nchallenging task since it requires handling the uncertainty of extracted\nknowledge throughout its integration into the KG. We survey state-of-the-art\napproaches in this direction and present constructions of both open and\nenterprise KGs and how their quality is maintained. We then describe different\nknowledge extraction methods, introducing additional uncertainty. We also\ndiscuss downstream tasks after knowledge acquisition, including KG completion\nusing embedding models, knowledge alignment, and knowledge fusion in order to\naddress the problem of knowledge uncertainty in KG construction. We conclude\nwith a discussion on the remaining challenges and perspectives when\nconstructing a KG taking into account uncertainty.",
      "tldr_zh": "这篇调查论文探讨了在构建 Knowledge Graphs (KGs) 时如何管理不确定性问题，包括从异构数据来源提取知识可能引发的冲突和不可靠性。论文比较了手动和自动处理方法，强调自动方法（如知识提取、KG 完成、knowledge alignment 和 knowledge fusion）的挑战与进展，以提升 KGs 的质量和可靠性。最终，它总结了当前状态艺术的局限性，并讨论了未来挑战和潜在展望。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16929v2",
      "published_date": "2024-05-27 08:22:52 UTC",
      "updated_date": "2024-07-19 07:46:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:40:37.472730"
    },
    {
      "arxiv_id": "2405.16922v2",
      "title": "Theories of synaptic memory consolidation and intelligent plasticity for continual learning",
      "title_zh": "翻译失败",
      "authors": [
        "Friedemann Zenke",
        "Axel Laborieux"
      ],
      "abstract": "Humans and animals learn throughout life. Such continual learning is crucial\nfor intelligence. In this chapter, we examine the pivotal role plasticity\nmechanisms with complex internal synaptic dynamics could play in enabling this\nability in neural networks. By surveying theoretical research, we highlight two\nfundamental enablers for continual learning. First, synaptic plasticity\nmechanisms must maintain and evolve an internal state over several behaviorally\nrelevant timescales. Second, plasticity algorithms must leverage the internal\nstate to intelligently regulate plasticity at individual synapses to facilitate\nthe seamless integration of new memories while avoiding detrimental\ninterference with existing ones. Our chapter covers successful applications of\nthese principles to deep neural networks and underscores the significance of\nsynaptic metaplasticity in sustaining continual learning capabilities. Finally,\nwe outline avenues for further research to understand the brain's superb\ncontinual learning abilities and harness similar mechanisms for artificial\nintelligence systems.",
      "tldr_zh": "本论文探讨了突触记忆巩固(synaptic memory consolidation)和智能可塑性(intelligent plasticity)在持续学习(continual learning)中的理论基础，强调突触可塑性(synaptic plasticity)机制如何通过维持内部状态和演化来支持终身学习。作者指出，塑性算法需利用内部状态智能调节单个突触的塑性，以整合新记忆同时避免干扰现有记忆。论文回顾了这些原则在深度神经网络中的成功应用，并突出了突触元可塑性(synaptic metaplasticity)在维持持续学习能力中的关键作用。最后，论文建议进一步研究大脑的持续学习机制，以开发类似功能的人工智能系统。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "An introductory-level book chapter. 35 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16922v2",
      "published_date": "2024-05-27 08:13:39 UTC",
      "updated_date": "2024-10-18 06:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:40:48.381978"
    },
    {
      "arxiv_id": "2405.16919v3",
      "title": "VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zejun Li",
        "Ruipu Luo",
        "Jiwen Zhang",
        "Minghui Qiu",
        "Xuanjing Huang",
        "Zhongyu Wei"
      ],
      "abstract": "While large multi-modal models (LMMs) have exhibited impressive capabilities\nacross diverse tasks, their effectiveness in handling complex tasks has been\nlimited by the prevailing single-step reasoning paradigm. To this end, this\npaper proposes VoCoT, a multi-step Visually grounded object-centric\nChain-of-Thought reasoning framework tailored for inference with LMMs. VoCoT is\ncharacterized by two key features: (1) object-centric reasoning paths that\nrevolve around cross-modal shared object-level information, and (2) visually\ngrounded representation of object concepts in a multi-modal interleaved and\naligned manner, which effectively bridges the modality gap within LMMs during\nlong-term generation. To adapt LMMs in reasoning with VoCoT, we further\nconstruct an instruction-tuning dataset. By combining VoCoT with the prevalent\nopen-source LMM architectures, we develop a VoCoT-based model, VolCano. With\nonly 7B parameters and limited input image resolution, VolCano demonstrates\nexcellent performance across various scenarios. In benchmarks like CLEVR and\nEmbSpatial, which highly require complex reasoning capabilities, VolCano\noutperforms SOTA models, including powerful GPT-4V. Related code, data and\nmodels are released in https://github.com/RupertLuo/VoCoT.",
      "tldr_zh": "这篇论文提出了 VoCoT 框架，一种针对大型多模态模型 (LMMs) 的视觉地锚定对象中心 Chain-of-Thought 推理方法，以克服现有模型在复杂任务中的单步推理限制。VoCoT 的关键特征包括基于跨模态共享对象信息的推理路径，以及多模态交错对齐的视觉地锚定表示，从而有效桥接模态间差距。作者构建了指令调整数据集，并开发了仅 7B 参数的 VolCano 模型，在 CLEVR 和 EmbSpatial 等基准测试中超越了 SOTA 模型如 GPT-4V。相关代码、数据和模型已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2405.16919v3",
      "published_date": "2024-05-27 08:12:00 UTC",
      "updated_date": "2025-03-08 17:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:41:01.747159"
    },
    {
      "arxiv_id": "2405.16907v5",
      "title": "GTA: Generative Trajectory Augmentation with Guidance for Offline Reinforcement Learning",
      "title_zh": "GTA：带有指导的生成式轨迹增强，用于离线强化学习",
      "authors": [
        "Jaewoo Lee",
        "Sujin Yun",
        "Taeyoung Yun",
        "Jinkyoo Park"
      ],
      "abstract": "Offline Reinforcement Learning (Offline RL) presents challenges of learning\neffective decision-making policies from static datasets without any online\ninteractions. Data augmentation techniques, such as noise injection and data\nsynthesizing, aim to improve Q-function approximation by smoothing the learned\nstate-action region. However, these methods often fall short of directly\nimproving the quality of offline datasets, leading to suboptimal results. In\nresponse, we introduce GTA, Generative Trajectory Augmentation, a novel\ngenerative data augmentation approach designed to enrich offline data by\naugmenting trajectories to be both high-rewarding and dynamically plausible.\nGTA applies a diffusion model within the data augmentation framework. GTA\npartially noises original trajectories and then denoises them with\nclassifier-free guidance via conditioning on amplified return value. Our\nresults show that GTA, as a general data augmentation strategy, enhances the\nperformance of widely used offline RL algorithms across various tasks with\nunique challenges. Furthermore, we conduct a quality analysis of data augmented\nby GTA and demonstrate that GTA improves the quality of the data. Our code is\navailable at https://github.com/Jaewoopudding/GTA",
      "tldr_zh": "论文提出 GTA（Generative Trajectory Augmentation），一种用于 Offline Reinforcement Learning 的生成式数据增强方法，旨在通过增强轨迹使其更具高回报和动态合理性，从而改善静态数据集的质量。GTA 利用 diffusion model 对原始轨迹进行部分噪声处理，并通过 classifier-free guidance 基于放大的回报值进行去噪，以生成更有效的训练数据。实验结果表明，GTA 作为通用策略，提升了多种离线 RL 算法在不同任务中的性能，并通过质量分析证明了其对数据整体改进的贡献。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024. Previously accepted (Spotlight) to ICLR 2024 Workshop\n  on Generative Models for Decision Making. Jaewoo Lee and Sujin Yun are equal\n  contribution authors",
      "pdf_url": "http://arxiv.org/pdf/2405.16907v5",
      "published_date": "2024-05-27 07:55:45 UTC",
      "updated_date": "2024-11-07 02:24:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:41:13.429789"
    },
    {
      "arxiv_id": "2405.16899v1",
      "title": "Partial Models for Building Adaptive Model-Based Reinforcement Learning Agents",
      "title_zh": "部分模型用于构建适应性基于模型的强化学习代理",
      "authors": [
        "Safa Alver",
        "Ali Rahimi-Kalahroudi",
        "Doina Precup"
      ],
      "abstract": "In neuroscience, one of the key behavioral tests for determining whether a\nsubject of study exhibits model-based behavior is to study its adaptiveness to\nlocal changes in the environment. In reinforcement learning, however, recent\nstudies have shown that modern model-based agents display poor adaptivity to\nsuch changes. The main reason for this is that modern agents are typically\ndesigned to improve sample efficiency in single task settings and thus do not\ntake into account the challenges that can arise in other settings. In local\nadaptation settings, one particularly important challenge is in quickly\nbuilding and maintaining a sufficiently accurate model after a local change.\nThis is challenging for deep model-based agents as their models and replay\nbuffers are monolithic structures lacking distribution shift handling\ncapabilities. In this study, we show that the conceptually simple idea of\npartial models can allow deep model-based agents to overcome this challenge and\nthus allow for building locally adaptive model-based agents. By modeling the\ndifferent parts of the state space through different models, the agent can not\nonly maintain a model that is accurate across the state space, but it can also\nquickly adapt it in the presence of a local change in the environment. We\ndemonstrate this by showing that the use of partial models in agents such as\ndeep Dyna-Q, PlaNet and Dreamer can allow for them to effectively adapt to the\nlocal changes in their environments.",
      "tldr_zh": "本研究针对强化学习（reinforcement learning）中的模型-based 代理（model-based agents）在环境局部变化时适应性差的问题，提出使用 partial models 的概念来构建更具适应性的代理。通过将状态空间的不同部分由不同的模型处理，代理能够维持整体模型准确性，并在局部变化发生时快速调整。实验结果显示，在 deep Dyna-Q、PlaNet 和 Dreamer 等代理中应用 partial models，能有效提升它们对环境局部变化的适应能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at CoLLAs 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16899v1",
      "published_date": "2024-05-27 07:46:36 UTC",
      "updated_date": "2024-05-27 07:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:41:27.638865"
    },
    {
      "arxiv_id": "2405.17512v2",
      "title": "On Fairness of Low-Rank Adaptation of Large Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhoujie Ding",
        "Ken Ziyu Liu",
        "Pura Peetathawatchai",
        "Berivan Isik",
        "Sanmi Koyejo"
      ],
      "abstract": "Low-rank adaptation of large models, particularly LoRA, has gained traction\ndue to its computational efficiency. This efficiency, contrasted with the\nprohibitive costs of full-model fine-tuning, means that practitioners often\nturn to LoRA and sometimes without a complete understanding of its\nramifications. In this study, we focus on fairness and ask whether LoRA has an\nunexamined impact on utility, calibration, and resistance to membership\ninference across different subgroups (e.g., genders, races, religions) compared\nto a full-model fine-tuning baseline. We present extensive experiments across\nvision and language domains and across classification and generation tasks\nusing ViT-Base, Swin-v2-Large, Llama-2 7B, and Mistral 7B. Intriguingly,\nexperiments suggest that while one can isolate cases where LoRA exacerbates\nmodel bias across subgroups, the pattern is inconsistent -- in many cases, LoRA\nhas equivalent or even improved fairness compared to the base model or its full\nfine-tuning baseline. We also examine the complications of evaluating\nfine-tuning fairness relating to task design and model token bias, calling for\nmore careful fairness evaluations in future work.",
      "tldr_zh": "本研究探讨了Low-Rank Adaptation (LoRA)在大模型中的公平性问题，与全模型微调相比，LoRA虽计算效率更高，但可能对不同子群（如性别、种族、宗教）的效用、校准和对成员推理的抵抗力产生影响。研究通过广泛实验，涵盖视觉和语言领域以及分类和生成任务，使用ViT-Base、Swin-v2-Large、Llama-2 7B和Mistral 7B模型进行对比。结果显示，LoRA有时会加剧模型偏差，但总体上与基线模型或全模型微调在公平性方面相当或更好。作者强调，评估微调公平性需考虑任务设计和模型标记偏差，并呼吁未来研究更谨慎地进行公平性评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "COLM 2024 camera ready",
      "pdf_url": "http://arxiv.org/pdf/2405.17512v2",
      "published_date": "2024-05-27 07:37:43 UTC",
      "updated_date": "2024-09-18 00:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:41:36.770736"
    },
    {
      "arxiv_id": "2405.16887v1",
      "title": "A Large Language Model-based multi-agent manufacturing system for intelligent shopfloor",
      "title_zh": "基于大型语言模型的多智能体制造系统，用于智能车间",
      "authors": [
        "Zhen Zhao",
        "Dunbing Tang",
        "Haihua Zhu",
        "Zequn Zhang",
        "Kai Chen",
        "Changchun Liu",
        "Yuchen Ji"
      ],
      "abstract": "As productivity advances, the demand of customers for multi-variety and\nsmall-batch production is increasing, thereby putting forward higher\nrequirements for manufacturing systems. When production tasks frequent changes\ndue to this demand, traditional manufacturing systems often cannot response\npromptly. The multi-agent manufacturing system is proposed to address this\nproblem. However, because of technical limitations, the negotiation among\nagents in this kind of system is realized through predefined heuristic rules,\nwhich is not intelligent enough to deal with the multi-variety and small batch\nproduction. To this end, a Large Language Model-based (LLM-based) multi-agent\nmanufacturing system for intelligent shopfloor is proposed in the present\nstudy. This system delineates the diverse agents and defines their\ncollaborative methods. The roles of the agents encompass Machine Server Agent\n(MSA), Bid Inviter Agent (BIA), Bidder Agent (BA), Thinking Agent (TA), and\nDecision Agent (DA). Due to the support of LLMs, TA and DA acquire the ability\nof analyzing the shopfloor condition and choosing the most suitable machine, as\nopposed to executing a predefined program artificially. The negotiation between\nBAs and BIA is the most crucial step in connecting manufacturing resources.\nWith the support of TA and DA, BIA will finalize the distribution of orders,\nrelying on the information of each machine returned by BA. MSAs bears the\nresponsibility for connecting the agents with the physical shopfloor. This\nsystem aims to distribute and transmit workpieces through the collaboration of\nthe agents with these distinct roles, distinguishing it from other scheduling\napproaches. Comparative experiments were also conducted to validate the\nperformance of this system.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Model (LLM-based) 的多智能体制造系统，用于智能车间，以应对多品种小批量生产的频繁变化需求。系统包括 Machine Server Agent (MSA)、Bid Inviter Agent (BIA)、Bidder Agent (BA)、Thinking Agent (TA) 和 Decision Agent (DA)，这些代理通过 LLM 支持进行智能分析、决策和资源协商，实现高效的订单分配与工件传输。相比传统依赖预定义规则的系统，该框架显著提升了响应速度，并通过比较实验验证了其性能优势。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16887v1",
      "published_date": "2024-05-27 07:10:04 UTC",
      "updated_date": "2024-05-27 07:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:41:49.968698"
    },
    {
      "arxiv_id": "2405.16883v2",
      "title": "Scorch: A Library for Sparse Deep Learning",
      "title_zh": "Scorch：用于稀疏深度学习的库",
      "authors": [
        "Bobby Yan",
        "Alexander J. Root",
        "Trevor Gale",
        "David Broman",
        "Fredrik Kjolstad"
      ],
      "abstract": "The rapid growth in the size of deep learning models strains the capabilities\nof traditional dense computation paradigms. Leveraging sparse computation has\nbecome increasingly popular for training and deploying large-scale models, but\nexisting deep learning frameworks lack extensive support for sparse operations.\nTo bridge this gap, we introduce Scorch, a library that seamlessly integrates\nefficient sparse tensor computation into the PyTorch ecosystem, with an initial\nfocus on inference workloads on CPUs. Scorch provides a flexible and intuitive\ninterface for sparse tensors, supporting diverse sparse data structures. Scorch\nintroduces a compiler stack that automates key optimizations, including\nautomatic loop ordering, tiling, and format inference. Combined with a runtime\nthat adapts its execution to both dense and sparse data, Scorch delivers\nsubstantial speedups over hand-written PyTorch Sparse (torch.sparse) operations\nwithout sacrificing usability. More importantly, Scorch enables efficient\ncomputation of complex sparse operations that lack hand-optimized PyTorch\nimplementations. This flexibility is crucial for exploring novel sparse\narchitectures. We demonstrate Scorch's ease of use and performance gains on\ndiverse deep learning models across multiple domains. With only minimal code\nchanges, Scorch achieves 1.05-5.78x speedups over PyTorch Sparse on end-to-end\ntasks. Scorch's seamless integration and performance gains make it a valuable\naddition to the PyTorch ecosystem. We believe Scorch will enable wider\nexploration of sparsity as a tool for scaling deep learning and inform the\ndevelopment of other sparse libraries.",
      "tldr_zh": "这篇论文介绍了 Scorch，一个专为稀疏深度学习设计的库，它无缝整合到 PyTorch 生态中，专注于 CPU 上的推理工作负载，以解决现有框架对稀疏操作支持不足的问题。Scorch 提供灵活的稀疏张量接口，支持多种稀疏数据结构，并通过一个编译器栈自动优化循环排序、平铺和格式推断，同时结合适应性运行时实现高效计算。相比手写 PyTorch Sparse 操作，Scorch 在端到端任务上实现了 1.05-5.78 倍的速度提升，并启用复杂稀疏操作的探索。总体而言，Scorch 将促进稀疏性在深度学习中的广泛应用，并为其他稀疏库的发展提供参考。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MS",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16883v2",
      "published_date": "2024-05-27 06:59:20 UTC",
      "updated_date": "2024-06-20 06:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:42:01.924045"
    },
    {
      "arxiv_id": "2405.16879v1",
      "title": "Unsupervised Generative Feature Transformation via Graph Contrastive Pre-training and Multi-objective Fine-tuning",
      "title_zh": "无监督生成式特征转换：通过图对比预训练和多目标微调",
      "authors": [
        "Wangyang Ying",
        "Dongjie Wang",
        "Xuanming Hu",
        "Yuanchun Zhou",
        "Charu C. Aggarwal",
        "Yanjie Fu"
      ],
      "abstract": "Feature transformation is to derive a new feature set from original features\nto augment the AI power of data. In many science domains such as material\nperformance screening, while feature transformation can model material formula\ninteractions and compositions and discover performance drivers, supervised\nlabels are collected from expensive and lengthy experiments. This issue\nmotivates an Unsupervised Feature Transformation Learning (UFTL) problem. Prior\nliterature, such as manual transformation, supervised feedback guided search,\nand PCA, either relies on domain knowledge or expensive supervised feedback, or\nsuffers from large search space, or overlooks non-linear feature-feature\ninteractions. UFTL imposes a major challenge on existing methods: how to design\na new unsupervised paradigm that captures complex feature interactions and\navoids large search space? To fill this gap, we connect graph, contrastive, and\ngenerative learning to develop a measurement-pretrain-finetune paradigm for\nUFTL. For unsupervised feature set utility measurement, we propose a feature\nvalue consistency preservation perspective and develop a mean discounted\ncumulative gain like unsupervised metric to evaluate feature set utility. For\nunsupervised feature set representation pretraining, we regard a feature set as\na feature-feature interaction graph, and develop an unsupervised graph\ncontrastive learning encoder to embed feature sets into vectors. For generative\ntransformation finetuning, we regard a feature set as a feature cross sequence\nand feature transformation as sequential generation. We develop a deep\ngenerative feature transformation model that coordinates the pretrained feature\nset encoder and the gradient information extracted from a feature set utility\nevaluator to optimize a transformed feature generator.",
      "tldr_zh": "该论文解决了无监督特征转换学习 (UFTL) 问题，旨在从原始特征派生新特征集以增强数据在材料性能筛选等领域的 AI 能力，而无需依赖昂贵的监督标签。作者提出一个测量-预训练-微调范式：首先开发一个基于特征值一致性保留的无监督指标来评估特征集效用；其次，使用无监督图对比学习 (Graph Contrastive Pre-training) 将特征集视为特征-特征交互图进行编码；最后，通过一个深度生成模型协调预训练编码器和梯度信息，实现多目标微调以优化特征转换。总体贡献在于捕捉复杂非线性特征交互、避免大型搜索空间，并为无监督生成特征转换提供新范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16879v1",
      "published_date": "2024-05-27 06:50:00 UTC",
      "updated_date": "2024-05-27 06:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:42:14.791412"
    },
    {
      "arxiv_id": "2405.16877v3",
      "title": "Are Self-Attentions Effective for Time Series Forecasting?",
      "title_zh": "自注意力在时间序列预测中是否有效？",
      "authors": [
        "Dongbin Kim",
        "Jinseong Park",
        "Jaewook Lee",
        "Hoki Kim"
      ],
      "abstract": "Time series forecasting is crucial for applications across multiple domains\nand various scenarios. Although Transformer models have dramatically advanced\nthe landscape of forecasting, their effectiveness remains debated. Recent\nfindings have indicated that simpler linear models might outperform complex\nTransformer-based approaches, highlighting the potential for more streamlined\narchitectures. In this paper, we shift the focus from evaluating the overall\nTransformer architecture to specifically examining the effectiveness of\nself-attention for time series forecasting. To this end, we introduce a new\narchitecture, Cross-Attention-only Time Series transformer (CATS), that\nrethinks the traditional Transformer framework by eliminating self-attention\nand leveraging cross-attention mechanisms instead. By establishing future\nhorizon-dependent parameters as queries and enhanced parameter sharing, our\nmodel not only improves long-term forecasting accuracy but also reduces the\nnumber of parameters and memory usage. Extensive experiment across various\ndatasets demonstrates that our model achieves superior performance with the\nlowest mean squared error and uses fewer parameters compared to existing\nmodels. The implementation of our model is available at:\nhttps://github.com/dongbeank/CATS.",
      "tldr_zh": "这篇论文质疑了self-attention在时间序列预测中的有效性，通过比较发现简单线性模型可能优于复杂的Transformer架构。作者提出了一种新模型Cross-Attention-only Time Series transformer (CATS)，它去除self-attention机制，仅使用cross-attention，并通过未来预测参数作为queries和增强参数共享来提升长期预测准确性，同时减少参数数量和内存使用。在多个数据集上的实验表明，CATS实现了最低的mean squared error，并比现有模型更高效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16877v3",
      "published_date": "2024-05-27 06:49:39 UTC",
      "updated_date": "2024-12-23 13:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:42:24.810305"
    },
    {
      "arxiv_id": "2405.16876v3",
      "title": "Transfer Learning for Diffusion Models",
      "title_zh": "扩散模型的迁移学习",
      "authors": [
        "Yidong Ouyang",
        "Liyan Xie",
        "Hongyuan Zha",
        "Guang Cheng"
      ],
      "abstract": "Diffusion models, a specific type of generative model, have achieved\nunprecedented performance in recent years and consistently produce high-quality\nsynthetic samples. A critical prerequisite for their notable success lies in\nthe presence of a substantial number of training samples, which can be\nimpractical in real-world applications due to high collection costs or\nassociated risks. Consequently, various finetuning and regularization\napproaches have been proposed to transfer knowledge from existing pre-trained\nmodels to specific target domains with limited data. This paper introduces the\nTransfer Guided Diffusion Process (TGDP), a novel approach distinct from\nconventional finetuning and regularization methods. We prove that the optimal\ndiffusion model for the target domain integrates pre-trained diffusion models\non the source domain with additional guidance from a domain classifier. We\nfurther extend TGDP to a conditional version for modeling the joint\ndistribution of data and its corresponding labels, together with two additional\nregularization terms to enhance the model performance. We validate the\neffectiveness of TGDP on both simulated and real-world datasets.",
      "tldr_zh": "本文提出 Transfer Guided Diffusion Process (TGDP)，一种新型转移学习方法，用于解决 Diffusion models 在数据有限场景下的训练挑战。该方法证明，目标域的最优 Diffusion models 应整合源域的预训练模型，并通过 domain classifier 提供额外指导，以提升模型在新域中的性能。TGDP 进一步扩展到条件版本，用于建模数据和标签的联合分布，并引入两个 regularization terms 以优化效果。在模拟和真实数据集上的实验验证了 TGDP 的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16876v3",
      "published_date": "2024-05-27 06:48:58 UTC",
      "updated_date": "2024-10-30 18:48:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:42:36.851065"
    },
    {
      "arxiv_id": "2405.16869v4",
      "title": "Multiple Heads are Better than One: Mixture of Modality Knowledge Experts for Entity Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yichi Zhang",
        "Zhuo Chen",
        "Lingbing Guo",
        "Yajing Xu",
        "Binbin Hu",
        "Ziqi Liu",
        "Wen Zhang",
        "Huajun Chen"
      ],
      "abstract": "Learning high-quality multi-modal entity representations is an important goal\nof multi-modal knowledge graph (MMKG) representation learning, which can\nenhance reasoning tasks within the MMKGs, such as MMKG completion (MMKGC). The\nmain challenge is to collaboratively model the structural information concealed\nin massive triples and the multi-modal features of the entities. Existing\nmethods focus on crafting elegant entity-wise multi-modal fusion strategies,\nyet they overlook the utilization of multi-perspective features concealed\nwithin the modalities under diverse relational contexts. To address this issue,\nwe introduce a novel framework with Mixture of Modality Knowledge experts\n(MoMoK for short) to learn adaptive multi-modal entity representations for\nbetter MMKGC. We design relation-guided modality knowledge experts to acquire\nrelation-aware modality embeddings and integrate the predictions from\nmulti-modalities to achieve joint decisions. Additionally, we disentangle the\nexperts by minimizing their mutual information. Experiments on four public MMKG\nbenchmarks demonstrate the outstanding performance of MoMoK under complex\nscenarios.",
      "tldr_zh": "该论文针对多模态知识图谱 (MMKG) 中的实体表示学习问题，提出了一种新型框架 Mixture of Modality Knowledge experts (MoMoK)，旨在通过 relation-guided modality knowledge experts 获取关系感知的模态嵌入，并整合多模态预测以实现联合决策，同时通过最小化专家间的互信息来解耦专家。MoMoK 解决了现有方法忽略多视角特征的局限，提升了实体表示的质量，从而改善 MMKG 完成 (MMKGC) 等推理任务。在四个公共 MMKG 基准上的实验显示，MoMoK 在复杂场景下表现出色，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 Camera-ready Version. Fix a caption typo in the current\n  version",
      "pdf_url": "http://arxiv.org/pdf/2405.16869v4",
      "published_date": "2024-05-27 06:36:17 UTC",
      "updated_date": "2025-04-06 09:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:42:49.986279"
    },
    {
      "arxiv_id": "2405.16867v1",
      "title": "Clustering-based Learning for UAV Tracking and Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaping Xiao",
        "Phumrapee Pisutsin",
        "Cheng Wen Tsao",
        "Mir Feroskhan"
      ],
      "abstract": "UAV tracking and pose estimation plays an imperative role in various\nUAV-related missions, such as formation control and anti-UAV measures.\nAccurately detecting and tracking UAVs in a 3D space remains a particularly\nchallenging problem, as it requires extracting sparse features of micro UAVs\nfrom different flight environments and continuously matching correspondences,\nespecially during agile flight. Generally, cameras and LiDARs are the two main\ntypes of sensors used to capture UAV trajectories in flight. However, both\nsensors have limitations in UAV classification and pose estimation. This\ntechnical report briefly introduces the method proposed by our team \"NTU-ICG\"\nfor the CVPR 2024 UG2+ Challenge Track 5. This work develops a clustering-based\nlearning detection approach, CL-Det, for UAV tracking and pose estimation using\ntwo types of LiDARs, namely Livox Avia and LiDAR 360. We combine the\ninformation from the two data sources to locate drones in 3D. We first align\nthe timestamps of Livox Avia data and LiDAR 360 data and then separate the\npoint cloud of objects of interest (OOIs) from the environment. The point cloud\nof OOIs is clustered using the DBSCAN method, with the midpoint of the largest\ncluster assumed to be the UAV position. Furthermore, we utilize historical\nestimations to fill in missing data. The proposed method shows competitive pose\nestimation performance and ranks 5th on the final leaderboard of the CVPR 2024\nUG2+ Challenge.",
      "tldr_zh": "这篇论文提出了一种基于聚类的学习方法 CL-Det，用于 UAV 跟踪和姿态估计，以应对在 3D 空间中提取稀疏特征和匹配对应物的挑战。方法利用 Livox Avia 和 LiDAR 360 两种 LiDAR 传感器，首先对数据进行时间戳对齐，然后分离目标对象点云（OOIs），并采用 DBSCAN 聚类算法识别最大聚类中点作为 UAV 位置，同时利用历史估计填充缺失数据。实验结果显示，该方法在 CVPR 2024 UG2+ Challenge Track 5 中排名第 5，展现了其在 UAV 相关任务中的竞争性性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted Report of CVPR 2024 UG2+ Challenge Track 5",
      "pdf_url": "http://arxiv.org/pdf/2405.16867v1",
      "published_date": "2024-05-27 06:33:25 UTC",
      "updated_date": "2024-05-27 06:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:43:04.474532"
    },
    {
      "arxiv_id": "2405.16860v1",
      "title": "Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias Towards Vision-Language Tasks",
      "title_zh": "先思再行：一个用于缓解视觉语言任务中性别偏见的双阶段框架",
      "authors": [
        "Yunqi Zhang",
        "Songda Li",
        "Chunyuan Deng",
        "Luyi Wang",
        "Hui Zhao"
      ],
      "abstract": "Gender bias in vision-language models (VLMs) can reinforce harmful\nstereotypes and discrimination. In this paper, we focus on mitigating gender\nbias towards vision-language tasks. We identify object hallucination as the\nessence of gender bias in VLMs. Existing VLMs tend to focus on salient or\nfamiliar attributes in images but ignore contextualized nuances. Moreover, most\nVLMs rely on the co-occurrence between specific objects and gender attributes\nto infer the ignored features, ultimately resulting in gender bias. We propose\nGAMA, a task-agnostic generation framework to mitigate gender bias. GAMA\nconsists of two stages: narrative generation and answer inference. During\nnarrative generation, GAMA yields all-sided but gender-obfuscated narratives,\nwhich prevents premature concentration on localized image features, especially\ngender attributes. During answer inference, GAMA integrates the image,\ngenerated narrative, and a task-specific question prompt to infer answers for\ndifferent vision-language tasks. This approach allows the model to rethink\ngender attributes and answers. We conduct extensive experiments on GAMA,\ndemonstrating its debiasing and generalization ability.",
      "tldr_zh": "本文提出 GAMA 框架，用于缓解视觉语言模型 (VLMs) 中的性别偏见问题，该偏见主要源于对象幻觉和对特定对象与性别属性的共现依赖。GAMA 采用两阶段方法：首先通过叙述生成阶段创建全面但隐藏性别的叙述，防止模型过早聚焦局部特征；其次在答案推断阶段整合图像、生成的叙述和任务特定问题提示，以重新评估性别属性和答案。该框架在广泛实验中展示了出色的去偏置和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accept to NAACL 2024(main)",
      "pdf_url": "http://arxiv.org/pdf/2405.16860v1",
      "published_date": "2024-05-27 06:20:58 UTC",
      "updated_date": "2024-05-27 06:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:43:12.679104"
    },
    {
      "arxiv_id": "2405.16852v2",
      "title": "EM Distillation for One-step Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sirui Xie",
        "Zhisheng Xiao",
        "Diederik P Kingma",
        "Tingbo Hou",
        "Ying Nian Wu",
        "Kevin Patrick Murphy",
        "Tim Salimans",
        "Ben Poole",
        "Ruiqi Gao"
      ],
      "abstract": "While diffusion models can learn complex distributions, sampling requires a\ncomputationally expensive iterative process. Existing distillation methods\nenable efficient sampling, but have notable limitations, such as performance\ndegradation with very few sampling steps, reliance on training data access, or\nmode-seeking optimization that may fail to capture the full distribution. We\npropose EM Distillation (EMD), a maximum likelihood-based approach that\ndistills a diffusion model to a one-step generator model with minimal loss of\nperceptual quality. Our approach is derived through the lens of\nExpectation-Maximization (EM), where the generator parameters are updated using\nsamples from the joint distribution of the diffusion teacher prior and inferred\ngenerator latents. We develop a reparametrized sampling scheme and a noise\ncancellation technique that together stabilizes the distillation process. We\nfurther reveal an interesting connection of our method with existing methods\nthat minimize mode-seeking KL. EMD outperforms existing one-step generative\nmethods in terms of FID scores on ImageNet-64 and ImageNet-128, and compares\nfavorably with prior work on distilling text-to-image diffusion models.",
      "tldr_zh": "本研究针对扩散模型(diffusion models)的高计算采样问题，提出了一种基于最大似然的EM Distillation (EMD)方法，将扩散模型蒸馏成高效的一步生成器模型，同时最小化感知质量损失。EMD通过Expectation-Maximization (EM)框架，使用扩散教师模型的先验和推断的生成器潜在变量的联合分布样本来更新参数，并引入重新参数化采样方案和噪声取消技术以稳定训练过程。该方法还揭示了与现有最小化模式搜索KL的技术的联系，并在ImageNet-64和ImageNet-128数据集上，EMD在FID scores上优于现有一步生成方法，并在文本到图像扩散模型的蒸馏中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16852v2",
      "published_date": "2024-05-27 05:55:22 UTC",
      "updated_date": "2024-12-06 06:07:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:43:25.500789"
    },
    {
      "arxiv_id": "2405.16851v1",
      "title": "Temporal Spiking Neural Networks with Synaptic Delay for Graph Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Mingqing Xiao",
        "Yixin Zhu",
        "Di He",
        "Zhouchen Lin"
      ],
      "abstract": "Spiking neural networks (SNNs) are investigated as biologically inspired\nmodels of neural computation, distinguished by their computational capability\nand energy efficiency due to precise spiking times and sparse spikes with\nevent-driven computation. A significant question is how SNNs can emulate\nhuman-like graph-based reasoning of concepts and relations, especially\nleveraging the temporal domain optimally. This paper reveals that SNNs, when\namalgamated with synaptic delay and temporal coding, are proficient in\nexecuting (knowledge) graph reasoning. It is elucidated that spiking time can\nfunction as an additional dimension to encode relation properties via a\nneural-generalized path formulation. Empirical results highlight the efficacy\nof temporal delay in relation processing and showcase exemplary performance in\ndiverse graph reasoning tasks. The spiking model is theoretically estimated to\nachieve $20\\times$ energy savings compared to non-spiking counterparts,\ndeepening insights into the capabilities and potential of biologically inspired\nSNNs for efficient reasoning. The code is available at\nhttps://github.com/pkuxmq/GRSNN.",
      "tldr_zh": "本论文探讨了脉冲神经网络(SNNs)如何通过突触延迟和时间编码来实现高效的图推理，强调其生物启发特性、计算能力和能量节约优势。研究揭示，SNNs利用脉冲时间作为额外维度编码关系属性，并通过神经广义路径公式处理知识图谱推理任务。实验结果显示，该方法在多种图推理任务中表现出色，并理论估计比非SNNs模型节省20倍能量，进一步深化了对生物启发计算潜力的理解。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16851v1",
      "published_date": "2024-05-27 05:53:30 UTC",
      "updated_date": "2024-05-27 05:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:43:37.200928"
    },
    {
      "arxiv_id": "2405.16847v1",
      "title": "TokenUnify: Scalable Autoregressive Visual Pre-training with Mixture Token Prediction",
      "title_zh": "Token",
      "authors": [
        "Yinda Chen",
        "Haoyuan Shi",
        "Xiaoyu Liu",
        "Te Shi",
        "Ruobing Zhang",
        "Dong Liu",
        "Zhiwei Xiong",
        "Feng Wu"
      ],
      "abstract": "Autoregressive next-token prediction is a standard pretraining method for\nlarge-scale language models, but its application to vision tasks is hindered by\nthe non-sequential nature of image data, leading to cumulative errors. Most\nvision models employ masked autoencoder (MAE) based pretraining, which faces\nscalability issues. To address these challenges, we introduce\n\\textbf{TokenUnify}, a novel pretraining method that integrates random token\nprediction, next-token prediction, and next-all token prediction. We provide\ntheoretical evidence demonstrating that TokenUnify mitigates cumulative errors\nin visual autoregression. Cooperated with TokenUnify, we have assembled a\nlarge-scale electron microscopy (EM) image dataset with ultra-high resolution,\nideal for creating spatially correlated long sequences. This dataset includes\nover 120 million annotated voxels, making it the largest neuron segmentation\ndataset to date and providing a unified benchmark for experimental validation.\nLeveraging the Mamba network inherently suited for long-sequence modeling on\nthis dataset, TokenUnify not only reduces the computational complexity but also\nleads to a significant 45\\% improvement in segmentation performance on\ndownstream EM neuron segmentation tasks compared to existing methods.\nFurthermore, TokenUnify demonstrates superior scalability over MAE and\ntraditional autoregressive methods, effectively bridging the gap between\npretraining strategies for language and vision models. Code is available at\n\\url{https://github.com/ydchen0806/TokenUnify}.",
      "tldr_zh": "该论文提出 TokenUnify，一种可扩展的自回归视觉预训练方法，通过整合随机 token 预测、下一个 token 预测和下一个所有 token 预测，解决了图像数据非顺序性导致的累积错误问题，并提供了理论证据支持其有效性。作者构建了一个大规模电子显微镜 (EM) 图像数据集，包含超过1.2亿标注 voxels，这是目前最大的神经元分割数据集，用于统一基准实验。利用 Mamba 网络处理长序列，TokenUnify 显著降低了计算复杂性，并在下游 EM 神经元分割任务上比现有方法提升45%的性能。最后，该方法展示了比 masked autoencoder (MAE) 和传统自回归方法更强的可扩展性，有效桥接了语言和视觉模型的预训练策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16847v1",
      "published_date": "2024-05-27 05:45:51 UTC",
      "updated_date": "2024-05-27 05:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:43:51.822568"
    },
    {
      "arxiv_id": "2405.16836v1",
      "title": "Enhancing Fast Feed Forward Networks with Load Balancing and a Master Leaf Node",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Charalampopoulos",
        "Nikolas Chatzis",
        "Foivos Ntoulas-Panagiotopoulos",
        "Charilaos Papaioannou",
        "Alexandros Potamianos"
      ],
      "abstract": "Fast feedforward networks (FFFs) are a class of neural networks that exploit\nthe observation that different regions of the input space activate distinct\nsubsets of neurons in wide networks. FFFs partition the input space into\nseparate sections using a differentiable binary tree of neurons and during\ninference descend the binary tree in order to improve computational efficiency.\nInspired by Mixture of Experts (MoE) research, we propose the incorporation of\nload balancing and Master Leaf techniques into the FFF architecture to improve\nperformance and simplify the training process. We reproduce experiments found\nin literature and present results on FFF models enhanced using these\ntechniques. The proposed architecture and training recipe achieves up to 16.3%\nand 3% absolute classification accuracy increase in training and test accuracy,\nrespectively, compared to the original FFF architecture. Additionally, we\nobserve a smaller variance in the results compared to those reported in prior\nresearch. These findings demonstrate the potential of integrating MoE-inspired\ntechniques into FFFs for developing more accurate and efficient models.",
      "tldr_zh": "本文提出了一种增强 Fast Feedforward Networks (FFFs) 的方法，通过整合 Load Balancing 和 Master Leaf 技术，旨在提高模型性能并简化训练过程。该方法受 Mixture of Experts (MoE) 研究启发，在 FFF 的可微分二进制树架构基础上优化输入空间分区和推理效率。实验结果显示，与原 FFF 架构相比，新方法使训练准确率提高高达16.3%，测试准确率提高3%，并显著降低了结果方差。这些改进证明了将 MoE 启发技术应用到 FFF 中，能开发出更准确和高效的神经网络模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16836v1",
      "published_date": "2024-05-27 05:06:24 UTC",
      "updated_date": "2024-05-27 05:06:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:44:02.174143"
    },
    {
      "arxiv_id": "2405.16830v2",
      "title": "Structured Graph Network for Constrained Robot Crowd Navigation with Low Fidelity Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuijing Liu",
        "Kaiwen Hong",
        "Neeloy Chakraborty",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "We investigate the feasibility of deploying reinforcement learning (RL)\npolicies for constrained crowd navigation using a low-fidelity simulator. We\nintroduce a representation of the dynamic environment, separating human and\nobstacle representations. Humans are represented through detected states, while\nobstacles are represented as computed point clouds based on maps and robot\nlocalization. This representation enables RL policies trained in a low-fidelity\nsimulator to deploy in real world with a reduced sim2real gap. Additionally, we\npropose a spatio-temporal graph to model the interactions between agents and\nobstacles. Based on the graph, we use attention mechanisms to capture the\nrobot-human, human-human, and human-obstacle interactions. Our method\nsignificantly improves navigation performance in both simulated and real-world\nenvironments. Video demonstrations can be found at\nhttps://sites.google.com/view/constrained-crowdnav/home.",
      "tldr_zh": "本文研究了使用低保真模拟器训练的强化学习（RL）策略在受限机器人人群导航中的可行性，提出了一种动态环境表示方法，将人类通过检测到的状态表示，而障碍物通过基于地图和机器人定位的点云表示，以减少 sim2real 差距。此外，作者引入了时空图（spatio-temporal graph）并应用注意力机制（attention mechanisms）来捕获机器人-人类、人类-人类和人类-障碍物的交互。实验结果显示，该方法在模拟和真实环境中显著提升了导航性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16830v2",
      "published_date": "2024-05-27 04:53:09 UTC",
      "updated_date": "2024-05-28 01:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:44:14.154868"
    },
    {
      "arxiv_id": "2405.16823v1",
      "title": "Unified Editing of Panorama, 3D Scenes, and Videos Through Disentangled Self-Attention Injection",
      "title_zh": "翻译失败",
      "authors": [
        "Gihyun Kwon",
        "Jangho Park",
        "Jong Chul Ye"
      ],
      "abstract": "While text-to-image models have achieved impressive capabilities in image\ngeneration and editing, their application across various modalities often\nnecessitates training separate models. Inspired by existing method of single\nimage editing with self attention injection and video editing with shared\nattention, we propose a novel unified editing framework that combines the\nstrengths of both approaches by utilizing only a basic 2D image text-to-image\n(T2I) diffusion model. Specifically, we design a sampling method that\nfacilitates editing consecutive images while maintaining semantic consistency\nutilizing shared self-attention features during both reference and consecutive\nimage sampling processes. Experimental results confirm that our method enables\nediting across diverse modalities including 3D scenes, videos, and panorama\nimages.",
      "tldr_zh": "本论文提出了一种统一编辑框架，通过Disentangled Self-Attention Injection，仅使用基本的2D文本到图像(T2I)扩散模型，实现对全景图像、3D场景和视频的多模态编辑。框架设计了一种采样方法，利用共享自注意力特征来处理连续图像的生成过程，确保语义一致性。实验结果证实，该方法在各种模态上均表现出色，消除了传统方法需单独训练模型的局限性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://unifyediting.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.16823v1",
      "published_date": "2024-05-27 04:44:36 UTC",
      "updated_date": "2024-05-27 04:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:44:26.164240"
    },
    {
      "arxiv_id": "2405.16820v1",
      "title": "Laboratory-Scale AI: Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings",
      "title_zh": "实验室规模AI：开放权重模型即使在低资源环境中也与ChatGPT具有竞争力",
      "authors": [
        "Robert Wolfe",
        "Isaac Slaughter",
        "Bin Han",
        "Bingbing Wen",
        "Yiwei Yang",
        "Lucas Rosenblatt",
        "Bernease Herman",
        "Eva Brown",
        "Zening Qu",
        "Nic Weber",
        "Bill Howe"
      ],
      "abstract": "The rapid proliferation of generative AI has raised questions about the\ncompetitiveness of lower-parameter, locally tunable, open-weight models\nrelative to high-parameter, API-guarded, closed-weight models in terms of\nperformance, domain adaptation, cost, and generalization. Centering\nunder-resourced yet risk-intolerant settings in government, research, and\nhealthcare, we see for-profit closed-weight models as incompatible with\nrequirements for transparency, privacy, adaptability, and standards of\nevidence. Yet the performance penalty in using open-weight models, especially\nin low-data and low-resource settings, is unclear.\n  We assess the feasibility of using smaller, open-weight models to replace\nGPT-4-Turbo in zero-shot, few-shot, and fine-tuned regimes, assuming access to\nonly a single, low-cost GPU. We assess value-sensitive issues around bias,\nprivacy, and abstention on three additional tasks relevant to those topics. We\nfind that with relatively low effort, very low absolute monetary cost, and\nrelatively little data for fine-tuning, small open-weight models can achieve\ncompetitive performance in domain-adapted tasks without sacrificing generality.\nWe then run experiments considering practical issues in bias, privacy, and\nhallucination risk, finding that open models offer several benefits over closed\nmodels. We intend this work as a case study in understanding the opportunity\ncost of reproducibility and transparency over for-profit state-of-the-art zero\nshot performance, finding this cost to be marginal under realistic settings.",
      "tldr_zh": "本研究探讨了小型开源模型（open-weight models）在低资源环境下的竞争力，评估其是否能取代GPT-4-Turbo，尤其在零样本、少样本和微调场景下，仅使用单低成本GPU。实验结果显示，这些模型在特定领域任务中可实现与ChatGPT相当的性能，同时在偏见、隐私和幻觉风险方面表现出优势，且所需的微调数据和成本极低。该工作证明了在政府、研究和医疗等资源有限的领域，选择开源模型的透明性和可复现性机会成本微乎其微。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16820v1",
      "published_date": "2024-05-27 04:38:10 UTC",
      "updated_date": "2024-05-27 04:38:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:44:38.398637"
    },
    {
      "arxiv_id": "2405.20776v1",
      "title": "Federated Learning with Blockchain-Enhanced Machine Unlearning: A Trustworthy Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Xuhan Zuo",
        "Minghao Wang",
        "Tianqing Zhu",
        "Lefeng Zhang",
        "Shui Yu",
        "Wanlei Zhou"
      ],
      "abstract": "With the growing need to comply with privacy regulations and respond to user\ndata deletion requests, integrating machine unlearning into IoT-based federated\nlearning has become imperative. Traditional unlearning methods, however, often\nlack verifiable mechanisms, leading to challenges in establishing trust. This\npaper delves into the innovative integration of blockchain technology with\nfederated learning to surmount these obstacles. Blockchain fortifies the\nunlearning process through its inherent qualities of immutability,\ntransparency, and robust security. It facilitates verifiable certification,\nharmonizes security with privacy, and sustains system efficiency. We introduce\na framework that melds blockchain with federated learning, thereby ensuring an\nimmutable record of unlearning requests and actions. This strategy not only\nbolsters the trustworthiness and integrity of the federated learning model but\nalso adeptly addresses efficiency and security challenges typical in IoT\nenvironments. Our key contributions encompass a certification mechanism for the\nunlearning process, the enhancement of data security and privacy, and the\noptimization of data management to ensure system responsiveness in IoT\nscenarios.",
      "tldr_zh": "该论文提出了一种可信的联邦学习框架，将区块链技术整合到机器遗忘（Machine Unlearning）中，以应对物联网（IoT）环境中隐私法规合规和数据删除请求的挑战。框架利用区块链的不可变性、透明性和安全性，提供可验证的遗忘过程认证机制，确保联邦学习模型的信任性和完整性。同时，该方法优化了数据管理和系统效率，解决了IoT场景中的安全和隐私问题。总体上，该研究增强了数据安全，改善了模型响应性，为隐私保护的分布式学习奠定了基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.20776v1",
      "published_date": "2024-05-27 04:35:49 UTC",
      "updated_date": "2024-05-27 04:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:44:49.374698"
    },
    {
      "arxiv_id": "2405.16807v2",
      "title": "Extreme Compression of Adaptive Neural Images",
      "title_zh": "翻译失败",
      "authors": [
        "Leo Hoshikawa",
        "Marcos V. Conde",
        "Takeshi Ohashi",
        "Atsushi Irie"
      ],
      "abstract": "Implicit Neural Representations (INRs) and Neural Fields are a novel paradigm\nfor signal representation, from images and audio to 3D scenes and videos. The\nfundamental idea is to represent a signal as a continuous and differentiable\nneural network. This idea offers unprecedented benefits such as continuous\nresolution and memory efficiency, enabling new compression techniques. However,\nrepresenting data as neural networks poses new challenges. For instance, given\na 2D image as a neural network, how can we further compress such a neural\nimage?. In this work, we present a novel analysis on compressing neural fields,\nwith the focus on images. We also introduce Adaptive Neural Images (ANI), an\nefficient neural representation that enables adaptation to different inference\nor transmission requirements. Our proposed method allows to reduce the\nbits-per-pixel (bpp) of the neural image by 4x, without losing sensitive\ndetails or harming fidelity. We achieve this thanks to our successful\nimplementation of 4-bit neural representations. Our work offers a new framework\nfor developing compressed neural fields.",
      "tldr_zh": "该论文探讨了 Implicit Neural Representations (INRs) 和 Neural Fields 在图像等信号表示中的新范式，这些方法通过连续可微的神经网络实现高效存储和无限分辨率，但面临进一步压缩的挑战。作者引入 Adaptive Neural Images (ANI)，一种可适应不同推理或传输需求的神经表示，并通过实现 4-bit 神经表示，将图像的 bits-per-pixel (bpp) 减少 4 倍，同时保持关键细节和保真度。总体上，该工作为开发压缩神经字段提供了创新框架，扩展了神经表示的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2405.16807v2",
      "published_date": "2024-05-27 03:54:09 UTC",
      "updated_date": "2024-06-04 18:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:45:02.182270"
    },
    {
      "arxiv_id": "2405.16806v2",
      "title": "Entity Alignment with Noisy Annotations from Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shengyuan Chen",
        "Qinggang Zhang",
        "Junnan Dong",
        "Wen Hua",
        "Qing Li",
        "Xiao Huang"
      ],
      "abstract": "Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying\nequivalent entity pairs. While existing methods heavily rely on human-generated\nlabels, it is prohibitively expensive to incorporate cross-domain experts for\nannotation in real-world scenarios. The advent of Large Language Models (LLMs)\npresents new avenues for automating EA with annotations, inspired by their\ncomprehensive capability to process semantic information. However, it is\nnontrivial to directly apply LLMs for EA since the annotation space in\nreal-world KGs is large. LLMs could also generate noisy labels that may mislead\nthe alignment. To this end, we propose a unified framework, LLM4EA, to\neffectively leverage LLMs for EA. Specifically, we design a novel active\nlearning policy to significantly reduce the annotation space by prioritizing\nthe most valuable entities based on the entire inter-KG and intra-KG structure.\nMoreover, we introduce an unsupervised label refiner to continuously enhance\nlabel accuracy through in-depth probabilistic reasoning. We iteratively\noptimize the policy based on the feedback from a base EA model. Extensive\nexperiments demonstrate the advantages of LLM4EA on four benchmark datasets in\nterms of effectiveness, robustness, and efficiency. Codes are available via\nhttps://github.com/chensyCN/llm4ea_official.",
      "tldr_zh": "这篇论文针对实体对齐 (EA) 的挑战，提出利用大语言模型 (LLMs) 自动生成标注来合并知识图谱 (KGs)，但需解决标注空间大和噪声标签的问题。作者设计了统一的框架 LLM4EA，包括一个新型主动学习策略，通过优先处理基于 KG 结构的最有价值实体来显著减少标注空间。框架还引入无监督标签精炼器，利用概率推理持续提升标签准确性，并通过反馈迭代优化基础 EA 模型。实验结果显示，LLM4EA 在四个基准数据集上表现出色，在有效性、鲁棒性和效率方面均优于基线方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16806v2",
      "published_date": "2024-05-27 03:52:55 UTC",
      "updated_date": "2024-05-28 07:50:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:45:14.383313"
    },
    {
      "arxiv_id": "2405.16800v1",
      "title": "TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Zhang",
        "Yuntong Hu",
        "Bo Pan",
        "Chen Ling",
        "Liang Zhao"
      ],
      "abstract": "Text-Attributed Graphs (TAGs) enhance graph structures with natural language\ndescriptions, enabling detailed representation of data and their relationships\nacross a broad spectrum of real-world scenarios. Despite the potential for\ndeeper insights, existing TAG representation learning primarily relies on\nsupervised methods, necessitating extensive labeled data and limiting\napplicability across diverse contexts. This paper introduces a new\nself-supervised learning framework, Text-And-Graph Multi-View Alignment (TAGA),\nwhich overcomes these constraints by integrating TAGs' structural and semantic\ndimensions. TAGA constructs two complementary views: Text-of-Graph view, which\norganizes node texts into structured documents based on graph topology, and the\nGraph-of-Text view, which converts textual nodes and connections into graph\ndata. By aligning representations from both views, TAGA captures joint textual\nand structural information. In addition, a novel structure-preserving random\nwalk algorithm is proposed for efficient training on large-sized TAGs. Our\nframework demonstrates strong performance in zero-shot and few-shot scenarios\nacross eight real-world datasets.",
      "tldr_zh": "该研究针对Text-Attributed Graphs (TAGs)提出了一种自监督学习框架TAGA，通过整合图结构和文本语义来克服现有方法的依赖于大量标注数据的局限性。TAGA构建了两个互补视图：Text-of-Graph view（基于图拓扑组织节点文本成结构化文档）和Graph-of-Text view（将文本节点和连接转换为图数据），并通过对这些视图的表示对齐来捕获联合文本和结构信息。此外，该框架引入了一种新型structure-preserving random walk算法，以实现大型TAGs的高效训练，并在八个真实数据集的零样本和少样本场景中表现出色表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16800v1",
      "published_date": "2024-05-27 03:40:16 UTC",
      "updated_date": "2024-05-27 03:40:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:45:25.705750"
    },
    {
      "arxiv_id": "2405.16797v1",
      "title": "A Real-Time Voice Activity Detection Based On Lightweight Neural",
      "title_zh": "翻译失败",
      "authors": [
        "Jidong Jia",
        "Pei Zhao",
        "Di Wang"
      ],
      "abstract": "Voice activity detection (VAD) is the task of detecting speech in an audio\nstream, which is challenging due to numerous unseen noises and low\nsignal-to-noise ratios in real environments. Recently, neural network-based\nVADs have alleviated the degradation of performance to some extent. However,\nthe majority of existing studies have employed excessively large models and\nincorporated future context, while neglecting to evaluate the operational\nefficiency and latency of the models. In this paper, we propose a lightweight\nand real-time neural network called MagicNet, which utilizes casual and depth\nseparable 1-D convolutions and GRU. Without relying on future features as\ninput, our proposed model is compared with two state-of-the-art algorithms on\nsynthesized in-domain and out-domain test datasets. The evaluation results\ndemonstrate that MagicNet can achieve improved performance and robustness with\nfewer parameter costs.",
      "tldr_zh": "本研究针对语音活动检测 (VAD) 的挑战，提出了一种轻量级实时神经网络 MagicNet，以应对真实环境中噪音干扰和低信噪比问题。MagicNet 采用 casual 和 depth separable 1-D convolutions 以及 GRU 作为核心组件，不依赖未来特征，从而提升模型的运行效率和延迟性能。在合成 in-domain 和 out-domain 测试数据集上，与两个 state-of-the-art 算法相比，MagicNet 实现了更好的性能和鲁棒性，同时显著减少了参数数量。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16797v1",
      "published_date": "2024-05-27 03:31:16 UTC",
      "updated_date": "2024-05-27 03:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:45:37.247998"
    },
    {
      "arxiv_id": "2405.16792v2",
      "title": "Laurel: Unblocking Automated Verification with Large Language Models",
      "title_zh": "Laurel：使用大型语言模型解除自动化验证的阻塞",
      "authors": [
        "Eric Mugnier",
        "Emmanuel Anaya Gonzalez",
        "Ranjit Jhala",
        "Nadia Polikarpova",
        "Yuanyuan Zhou"
      ],
      "abstract": "Program verifiers such as Dafny automate proofs by outsourcing them to an SMT\nsolver. This automation is not perfect, however, and the solver often requires\nhints in the form of assertions, creating a burden for the proof engineer. In\nthis paper, we propose Laurel, a tool that alleviates this burden by\nautomatically generating assertions using large language models (LLMs). To\nimprove the success rate of LLMs in this task, we design two domain-specific\nprompting techniques. First, we help the LLM determine the location of the\nmissing assertion by analyzing the verifier's error message and inserting an\nassertion placeholder at that location. Second, we provide the LLM with example\nassertions from the same codebase, which we select based on a new proof\nsimilarity metric. We evaluate our techniques on our new benchmark DafnyGym, a\ndataset of complex lemmas we extracted from three real-world Dafny codebases.\nOur evaluation shows that Laurel is able to generate over 56.6\\% of the\nrequired assertions given only a few attempts, making LLMs an affordable tool\nfor unblocking program verifiers without human intervention.",
      "tldr_zh": "该论文提出Laurel工具，利用Large Language Models (LLMs)自动生成assertions，以缓解程序验证器（如Dafny）依赖SMT solver时需手动添加提示的负担。Laurel采用两种领域特定提示技术：一是通过分析验证器的错误消息定位缺失assertion的位置并插入占位符；二是基于一个新的证明相似性指标，从同一代码库中选择示例assertions提供给LLM。实验在新的基准DafnyGym数据集上评估，结果显示Laurel在几次尝试中成功生成超过56.6%的所需assertions，从而无需人工干预，使LLMs成为高效的程序验证辅助工具。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "34 pages, accepted at OOPSLA 25",
      "pdf_url": "http://arxiv.org/pdf/2405.16792v2",
      "published_date": "2024-05-27 03:26:01 UTC",
      "updated_date": "2025-03-03 22:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:45:49.602468"
    },
    {
      "arxiv_id": "2405.16783v1",
      "title": "TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhou. Nie",
        "Yanting. Wang",
        "Jinyuan. Jia",
        "Michael J. De Lucia",
        "Nathaniel D. Bastian",
        "Wenbo. Guo",
        "Dawn. Song"
      ],
      "abstract": "One key challenge in backdoor attacks against large foundation models is the\nresource limits. Backdoor attacks usually require retraining the target model,\nwhich is impractical for very large foundation models. Existing backdoor\nattacks are mainly designed for supervised classifiers or small foundation\nmodels (e.g., BERT). None of these attacks has successfully compromised a very\nlarge foundation model, such as Llama-3-70B, especially with limited\ncomputational resources. In this paper, we propose TrojFM, a novel backdoor\nattack tailored for very large foundation models. Our primary technical\ncontribution is the development of a novel backdoor injection method. This\nmethod forces a backdoored model to generate similar hidden representations for\npoisoned inputs regardless of their actual semantics. Our approach injects such\nbackdoors by fine-tuning only a very small proportion of model parameters. This\nenables TrojFM to efficiently launch downstream task-agnostic backdoor attacks\nagainst very large foundation models under limited computational resources.\nMoreover, we optimize the fine-tuning process with our customized QLoRA\ntechnique, enabling launching our attack via only~\\textit{one A100 GPU}.\nFurthermore, we design a new trigger injection method to ensure our attack\nstealthiness. Through extensive experiments, we first demonstrate that TrojFM\ncan launch effective backdoor attacks against widely used large GPT-style\nmodels without jeopardizing their normal functionalities (and outperforming\nexisting attacks on BERT-style models). Furthermore, we show that TrojFM is\nresilient to SOTA defenses and is insensitive to changes in key\nhyper-parameters. Finally, we conduct a resource analysis to quantify that our\nmethod can significantly save computational and memory costs compared to\nexisting backdoor attacks.",
      "tldr_zh": "这篇论文提出了TrojFM，一种资源高效的后门攻击(Backdoor Attacks)方法，针对非常大的基础模型(Foundation Models)如Llama-3-70B，解决了现有攻击需重训练模型的资源限制问题。TrojFM的核心创新是通过一种新型后门注入方法，仅微调少量模型参数，使毒化输入生成相似的隐藏表示，同时结合自定义QLoRA技术，仅需一个A100 GPU即可实现下游任务无关的攻击，并确保触发器注入的隐蔽性。实验结果显示，TrojFM在大型GPT-style模型上有效，不影响正常功能，且优于现有攻击（如针对BERT-style模型的），同时对SOTA防御具有抵抗力，并显著降低了计算和内存成本。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16783v1",
      "published_date": "2024-05-27 03:10:57 UTC",
      "updated_date": "2024-05-27 03:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:46:01.978949"
    },
    {
      "arxiv_id": "2405.16766v2",
      "title": "Concept Matching with Agent for Out-of-Distribution Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiao Lee",
        "Xiaofeng Cao",
        "Jingcai Guo",
        "Wei Ye",
        "Qing Guo",
        "Yi Chang"
      ],
      "abstract": "The remarkable achievements of Large Language Models (LLMs) have captivated\nthe attention of both academia and industry, transcending their initial role in\ndialogue generation. To expand the usage scenarios of LLM, some works enhance\nthe effectiveness and capabilities of the model by introducing more external\ninformation, which is called the agent paradigm. Based on this idea, we propose\na new method that integrates the agent paradigm into out-of-distribution (OOD)\ndetection task, aiming to improve its robustness and adaptability. Our proposed\nmethod, Concept Matching with Agent (CMA), employs neutral prompts as agents to\naugment the CLIP-based OOD detection process. These agents function as dynamic\nobservers and communication hubs, interacting with both In-distribution (ID)\nlabels and data inputs to form vector triangle relationships. This triangular\nframework offers a more nuanced approach than the traditional binary\nrelationship, allowing for better separation and identification of ID and OOD\ninputs. Our extensive experimental results showcase the superior performance of\nCMA over both zero-shot and training-required methods in a diverse array of\nreal-world scenarios.",
      "tldr_zh": "这篇论文提出了一种名为 Concept Matching with Agent (CMA) 的方法，将 agent 范式引入 Out-of-Distribution (OOD) 检测任务，以提升其鲁棒性和适应性。CMA 使用 neutral prompts 作为 agents，在基于 CLIP 的检测过程中与 In-distribution (ID) 标签和数据输入形成 vector triangle relationships，这种三角框架比传统二元关系更能精确分离和识别 ID 与 OOD 输入。实验结果显示，CMA 在多种真实场景中优于零样本和需要训练的基准方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2405.16766v2",
      "published_date": "2024-05-27 02:27:28 UTC",
      "updated_date": "2025-01-07 03:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:46:13.604734"
    },
    {
      "arxiv_id": "2405.16761v1",
      "title": "Masked Face Recognition with Generative-to-Discriminative Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Shiming Ge",
        "Weijia Guo",
        "Chenyu Li",
        "Junzheng Zhang",
        "Yong Li",
        "Dan Zeng"
      ],
      "abstract": "Masked face recognition is important for social good but challenged by\ndiverse occlusions that cause insufficient or inaccurate representations. In\nthis work, we propose a unified deep network to learn\ngenerative-to-discriminative representations for facilitating masked face\nrecognition. To this end, we split the network into three modules and learn\nthem on synthetic masked faces in a greedy module-wise pretraining manner.\nFirst, we leverage a generative encoder pretrained for face inpainting and\nfinetune it to represent masked faces into category-aware descriptors.\nAttribute to the generative encoder's ability in recovering context\ninformation, the resulting descriptors can provide occlusion-robust\nrepresentations for masked faces, mitigating the effect of diverse masks. Then,\nwe incorporate a multi-layer convolutional network as a discriminative reformer\nand learn it to convert the category-aware descriptors into identity-aware\nvectors, where the learning is effectively supervised by distilling relation\nknowledge from off-the-shelf face recognition model. In this way, the\ndiscriminative reformer together with the generative encoder serves as the\npretrained backbone, providing general and discriminative representations\ntowards masked faces. Finally, we cascade one fully-connected layer following\nby one softmax layer into a feature classifier and finetune it to identify the\nreformed identity-aware vectors. Extensive experiments on synthetic and\nrealistic datasets demonstrate the effectiveness of our approach in recognizing\nmasked faces.",
      "tldr_zh": "本研究针对masked face recognition面临的多样遮挡问题，提出了一种统一深度网络，通过学习generative-to-discriminative representations来提升识别准确性。该网络分为三个模块：在合成遮挡脸部数据上进行贪婪模块式预训练，首先使用generative encoder进行脸部修复微调，生成category-aware descriptors以抵抗遮挡影响；其次，引入discriminative reformer（多层卷积网络）通过知识蒸馏将这些描述符转换为identity-aware vectors；最后，级联全连接层和softmax层作为特征分类器进行微调。实验在合成和真实数据集上证明，该方法显著提高了masked face recognition的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by International Conference on Machine Learning 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16761v1",
      "published_date": "2024-05-27 02:20:55 UTC",
      "updated_date": "2024-05-27 02:20:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:46:25.918785"
    },
    {
      "arxiv_id": "2405.16755v3",
      "title": "CHESS: Contextual Harnessing for Efficient SQL Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Shayan Talaei",
        "Mohammadreza Pourreza",
        "Yu-Chen Chang",
        "Azalia Mirhoseini",
        "Amin Saberi"
      ],
      "abstract": "Translating natural language questions into SQL queries, known as\ntext-to-SQL, is a long-standing research problem. Effective text-to-SQL\nsynthesis can become very challenging due to (i) the extensive size of database\ncatalogs (descriptions of tables and their columns) and database values, (ii)\nreasoning over large database schemas, (iii) ensuring the functional validity\nof the generated queries, and (iv) navigating the ambiguities of natural\nlanguage questions. We introduce CHESS, a Large Language Model (LLM) based\nmulti-agent framework for efficient and scalable SQL synthesis, comprising four\nspecialized agents, each targeting one of the aforementioned challenges: the\nInformation Retriever (IR) extracts relevant data, the Schema Selector (SS)\nprunes large schemas, the Candidate Generator (CG) generates high-quality\ncandidates and refines queries iteratively, and the Unit Tester (UT) validates\nqueries through LLM-based natural language unit tests. Our framework offers\nconfigurable features that adapt to various deployment constraints, including\n1) Supporting industrial-scale databases: leveraging the Schema Selector agent,\nCHESS efficiently narrows down very large database schemas into manageable\nsub-schemas, boosting system accuracy by approximately $2\\%$ and reducing the\nnumber of LLM tokens by $\\times 5$. 2) State-of-the-Art privacy-preserving\nperformance: Among the methods using open-source models, CHESS achieves\nstate-of-the-art performance, resulting in a high-performing,\nprivacy-preserving system suitable for industrial deployment. 3) Scalablity\nwith additional compute budget: In settings with high computational budgets,\nCHESS achieves $71.10\\%$ accuracy on the BIRD test set, within $2\\%$ of the\nleading proprietary method, while requiring approximately $83\\%$ fewer LLM\ncalls.",
      "tldr_zh": "CHESS 是一种基于 Large Language Model (LLM) 的多智能体框架，旨在高效处理 text-to-SQL 任务，解决数据库目录庞大、模式推理复杂、查询功能有效性和自然语言歧义等挑战。框架包括四个专门代理：Information Retriever (IR) 提取相关数据、Schema Selector (SS) 修剪大型数据库模式、Candidate Generator (CG) 生成并迭代精炼查询，以及 Unit Tester (UT) 通过 LLM 基于的自然语言单元测试验证查询。实验结果显示，CHESS 支持工业规模数据库，提高准确率约 2% 并减少 LLM 标记使用 5 倍；在开源模型中达到 state-of-the-art 隐私保护性能，并在高计算预算下于 BIRD 测试集上实现 71.10% 准确率，仅比领先专有方法低 2%，同时节省约 83% 的 LLM 调用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16755v3",
      "published_date": "2024-05-27 01:54:16 UTC",
      "updated_date": "2024-11-25 19:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:46:39.897634"
    },
    {
      "arxiv_id": "2405.16752v1",
      "title": "Model Ensembling for Constrained Optimization",
      "title_zh": "约束优化的模型集成",
      "authors": [
        "Ira Globus-Harris",
        "Varun Gupta",
        "Michael Kearns",
        "Aaron Roth"
      ],
      "abstract": "There is a long history in machine learning of model ensembling, beginning\nwith boosting and bagging and continuing to the present day. Much of this\nhistory has focused on combining models for classification and regression, but\nrecently there is interest in more complex settings such as ensembling policies\nin reinforcement learning. Strong connections have also emerged between\nensembling and multicalibration techniques. In this work, we further\ninvestigate these themes by considering a setting in which we wish to ensemble\nmodels for multidimensional output predictions that are in turn used for\ndownstream optimization. More precisely, we imagine we are given a number of\nmodels mapping a state space to multidimensional real-valued predictions. These\npredictions form the coefficients of a linear objective that we would like to\noptimize under specified constraints. The fundamental question we address is\nhow to improve and combine such models in a way that outperforms the best of\nthem in the downstream optimization problem. We apply multicalibration\ntechniques that lead to two provably efficient and convergent algorithms. The\nfirst of these (the white box approach) requires being given models that map\nstates to output predictions, while the second (the \\emph{black box} approach)\nrequires only policies (mappings from states to solutions to the optimization\nproblem). For both, we provide convergence and utility guarantees. We conclude\nby investigating the performance and behavior of the two algorithms in a\ncontrolled experimental setting.",
      "tldr_zh": "这篇论文探讨了模型集成（model ensembling）在约束优化问题中的应用，旨在通过结合多个模型来提升下游优化性能，特别是针对多维输出预测作为线性目标函数的系数。作者引入 multicalibration 技术，开发了两种高效算法：白盒方法（white box approach），要求模型从状态映射到预测；以及黑盒方法（black box approach），仅需状态到优化解决方案的策略。实验结果显示，这些算法具有收敛和实用性保证，并在受控环境中表现出色，优于单个模型的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16752v1",
      "published_date": "2024-05-27 01:48:07 UTC",
      "updated_date": "2024-05-27 01:48:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:46:50.682952"
    },
    {
      "arxiv_id": "2405.16751v2",
      "title": "REVECA: Adaptive Planning and Trajectory-based Validation in Cooperative Language Agents using Information Relevance and Relative Proximity",
      "title_zh": "翻译失败",
      "authors": [
        "SeungWon Seo",
        "SeongRae Noh",
        "Junhyeok Lee",
        "SooBin Lim",
        "Won Hee Lee",
        "HyeongYeop Kang"
      ],
      "abstract": "We address the challenge of multi-agent cooperation, where agents achieve a\ncommon goal by cooperating with decentralized agents under complex partial\nobservations. Existing cooperative agent systems often struggle with\nefficiently processing continuously accumulating information, managing globally\nsuboptimal planning due to lack of consideration of collaborators, and\naddressing false planning caused by environmental changes introduced by other\ncollaborators. To overcome these challenges, we propose the RElevance,\nProximity, and Validation-Enhanced Cooperative Language Agent (REVECA), a novel\ncognitive architecture powered by GPT-4o-mini. REVECA enables efficient memory\nmanagement, optimal planning, and cost-effective prevention of false planning\nby leveraging Relevance Estimation, Adaptive Planning, and Trajectory-based\nValidation. Extensive experimental results demonstrate REVECA's superiority\nover existing methods across various benchmarks, while a user study reveals its\npotential for achieving trustworthy human-AI cooperation.",
      "tldr_zh": "这篇论文针对多智能体合作中的挑战，提出 REVECA 框架——一个基于 GPT-4o-mini 的认知架构，用于处理复杂部分观察下的信息积累和规划问题。REVECA 通过 Relevance Estimation（相关性估计）、Adaptive Planning（自适应规划）和 Trajectory-based Validation（基于轨迹的验证）实现高效内存管理、最优规划以及防止环境变化导致的错误规划。实验结果显示，REVECA 在各种基准上优于现有方法，并在用户研究中证明了其在可信赖的人-AI 合作中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "v2 is the AAAI'25 camera-ready version, including the appendix, which\n  has been enhanced based on the reviewers' comments",
      "pdf_url": "http://arxiv.org/pdf/2405.16751v2",
      "published_date": "2024-05-27 01:47:14 UTC",
      "updated_date": "2024-12-18 08:38:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:47:02.517871"
    },
    {
      "arxiv_id": "2405.16739v1",
      "title": "Oracle-Efficient Reinforcement Learning for Max Value Ensembles",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel Hussing",
        "Michael Kearns",
        "Aaron Roth",
        "Sikata Bela Sengupta",
        "Jessica Sorrell"
      ],
      "abstract": "Reinforcement learning (RL) in large or infinite state spaces is notoriously\nchallenging, both theoretically (where worst-case sample and computational\ncomplexities must scale with state space cardinality) and experimentally (where\nfunction approximation and policy gradient techniques often scale poorly and\nsuffer from instability and high variance). One line of research attempting to\naddress these difficulties makes the natural assumption that we are given a\ncollection of heuristic base or $\\textit{constituent}$ policies upon which we\nwould like to improve in a scalable manner. In this work we aim to compete with\nthe $\\textit{max-following policy}$, which at each state follows the action of\nwhichever constituent policy has the highest value. The max-following policy is\nalways at least as good as the best constituent policy, and may be considerably\nbetter. Our main result is an efficient algorithm that learns to compete with\nthe max-following policy, given only access to the constituent policies (but\nnot their value functions). In contrast to prior work in similar settings, our\ntheoretical results require only the minimal assumption of an ERM oracle for\nvalue function approximation for the constituent policies (and not the global\noptimal policy or the max-following policy itself) on samplable distributions.\nWe illustrate our algorithm's experimental effectiveness and behavior on\nseveral robotic simulation testbeds.",
      "tldr_zh": "该论文探讨了强化学习（Reinforcement Learning）在大型或无限状态空间中的挑战，提出了一种高效算法来与 max-following policy 竞争，该策略在每个状态下选择价值最高的组成策略（constituent policies）的动作。算法仅需访问组成策略本身，而非它们的价值函数，并依赖于一个 ERM oracle 用于价值函数近似，从而避免了对全局最优策略的复杂需求。实验结果显示，该方法在多个机器人模拟环境中表现出色，能够显著提升学习效率和稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16739v1",
      "published_date": "2024-05-27 01:08:23 UTC",
      "updated_date": "2024-05-27 01:08:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:47:13.904948"
    },
    {
      "arxiv_id": "2405.16730v1",
      "title": "Latent Energy-Based Odyssey: Black-Box Optimization via Expanded Exploration in the Energy-Based Latent Space",
      "title_zh": "翻译失败",
      "authors": [
        "Peiyu Yu",
        "Dinghuai Zhang",
        "Hengzhi He",
        "Xiaojian Ma",
        "Ruiyao Miao",
        "Yifan Lu",
        "Yasi Zhang",
        "Deqian Kong",
        "Ruiqi Gao",
        "Jianwen Xie",
        "Guang Cheng",
        "Ying Nian Wu"
      ],
      "abstract": "Offline Black-Box Optimization (BBO) aims at optimizing a black-box function\nusing the knowledge from a pre-collected offline dataset of function values and\ncorresponding input designs. However, the high-dimensional and\nhighly-multimodal input design space of black-box function pose inherent\nchallenges for most existing methods that model and operate directly upon input\ndesigns. These issues include but are not limited to high sample complexity,\nwhich relates to inaccurate approximation of black-box function; and\ninsufficient coverage and exploration of input design modes, which leads to\nsuboptimal proposal of new input designs. In this work, we consider finding a\nlatent space that serves as a compressed yet accurate representation of the\ndesign-value joint space, enabling effective latent exploration of high-value\ninput design modes. To this end, we formulate an learnable energy-based latent\nspace, and propose Noise-intensified Telescoping density-Ratio Estimation\n(NTRE) scheme for variational learning of an accurate latent space model\nwithout costly Markov Chain Monte Carlo. The optimization process is then\nexploration of high-value designs guided by the learned energy-based model in\nthe latent space, formulated as gradient-based sampling from a\nlatent-variable-parameterized inverse model. We show that our particular\nparameterization encourages expanded exploration around high-value design\nmodes, motivated by inversion thinking of a fundamental result of conditional\ncovariance matrix typically used for variance reduction. We observe that our\nmethod, backed by an accurately learned informative latent space and an\nexpanding-exploration model design, yields significant improvements over strong\nprevious methods on both synthetic and real world datasets such as the\ndesign-bench suite.",
      "tldr_zh": "本论文针对离线 Black-Box Optimization (BBO) 的挑战，提出一种基于能量模型的潜在空间框架，旨在通过压缩设计-值联合空间来提升高维多模态输入的探索效率。作者引入 Noise-intensified Telescoping density-Ratio Estimation (NTRE) 方案，实现变分学习 (variational learning) 的准确潜在空间模型，而避免使用昂贵的 Markov Chain Monte Carlo (MCMC)。通过在潜在空间中进行梯度-based sampling 和扩展探索，方法鼓励在高价值设计模式周围进行更有效的逆向优化，最终在合成和真实数据集（如 design-bench suite）上，比现有方法显著提高优化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16730v1",
      "published_date": "2024-05-27 00:11:53 UTC",
      "updated_date": "2024-05-27 00:11:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:47:27.822146"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 139,
  "processed_papers_count": 139,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T12:47:51.814187"
}