[
  {
    "arxiv_id": "2408.08879v1",
    "title": "SHARP-Net: A Refined Pyramid Network for Deficiency Segmentation in Culverts and Sewer Pipes",
    "authors": [
      "Rasha Alshawi",
      "Md Meftahul Ferdaus",
      "Md Tamjidul Hoque",
      "Kendall Niles",
      "Ken Pathak",
      "Steve Sloan",
      "Mahdi Abdelguerfi"
    ],
    "abstract": "This paper introduces Semantic Haar-Adaptive Refined Pyramid Network\n(SHARP-Net), a novel architecture for semantic segmentation. SHARP-Net\nintegrates a bottom-up pathway featuring Inception-like blocks with varying\nfilter sizes (3x3$ and 5x5), parallel max-pooling, and additional spatial\ndetection layers. This design captures multi-scale features and fine structural\ndetails. Throughout the network, depth-wise separable convolutions are used to\nreduce complexity. The top-down pathway of SHARP-Net focuses on generating\nhigh-resolution features through upsampling and information fusion using\n$1\\times1$ and $3\\times3$ depth-wise separable convolutions. We evaluated our\nmodel using our developed challenging Culvert-Sewer Defects dataset and the\nbenchmark DeepGlobe Land Cover dataset. Our experimental evaluation\ndemonstrated the base model's (excluding Haar-like features) effectiveness in\nhandling irregular defect shapes, occlusions, and class imbalances. It\noutperformed state-of-the-art methods, including U-Net, CBAM U-Net, ASCU-Net,\nFPN, and SegFormer, achieving average improvements of 14.4% and 12.1% on the\nCulvert-Sewer Defects and DeepGlobe Land Cover datasets, respectively, with IoU\nscores of 77.2% and 70.6%. Additionally, the training time was reduced.\nFurthermore, the integration of carefully selected and fine-tuned Haar-like\nfeatures enhanced the performance of deep learning models by at least 20%. The\nproposed SHARP-Net, incorporating Haar-like features, achieved an impressive\nIoU of 94.75%, representing a 22.74% improvement over the base model. These\nfeatures were also applied to other deep learning models, showing a 35.0%\nimprovement, proving their versatility and effectiveness. SHARP-Net thus\nprovides a powerful and efficient solution for accurate semantic segmentation\nin challenging real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08879v1",
    "published_date": "2024-08-02 23:55:04 UTC",
    "updated_date": "2024-08-02 23:55:04 UTC"
  },
  {
    "arxiv_id": "2408.10230v1",
    "title": "A General-Purpose Device for Interaction with LLMs",
    "authors": [
      "Jiajun Xu",
      "Qun Wang",
      "Yuhang Cao",
      "Baitao Zeng",
      "Sicheng Liu"
    ],
    "abstract": "This paper investigates integrating large language models (LLMs) with\nadvanced hardware, focusing on developing a general-purpose device designed for\nenhanced interaction with LLMs. Initially, we analyze the current landscape,\nwhere virtual assistants and LLMs are reshaping human-technology interactions,\nhighlighting pivotal advancements and setting the stage for a new era of\nintelligent hardware. Despite substantial progress in LLM technology, a\nsignificant gap exists in hardware development, particularly concerning\nscalability, efficiency, affordability, and multimodal capabilities. This\ndisparity presents both challenges and opportunities, underscoring the need for\nhardware that is not only powerful but also versatile and capable of managing\nthe sophisticated demands of modern computation. Our proposed device addresses\nthese needs by emphasizing scalability, multimodal data processing, enhanced\nuser interaction, and privacy considerations, offering a comprehensive platform\nfor LLM integration in various applications.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10230v1",
    "published_date": "2024-08-02 23:43:29 UTC",
    "updated_date": "2024-08-02 23:43:29 UTC"
  },
  {
    "arxiv_id": "2408.01596v1",
    "title": "Trustworthy Machine Learning under Social and Adversarial Data Sources",
    "authors": [
      "Han Shao"
    ],
    "abstract": "Machine learning has witnessed remarkable breakthroughs in recent years. As\nmachine learning permeates various aspects of daily life, individuals and\norganizations increasingly interact with these systems, exhibiting a wide range\nof social and adversarial behaviors. These behaviors may have a notable impact\non the behavior and performance of machine learning systems. Specifically,\nduring these interactions, data may be generated by strategic individuals,\ncollected by self-interested data collectors, possibly poisoned by adversarial\nattackers, and used to create predictors, models, and policies satisfying\nmultiple objectives. As a result, the machine learning systems' outputs might\ndegrade, such as the susceptibility of deep neural networks to adversarial\nexamples (Shafahi et al., 2018; Szegedy et al., 2013) and the diminished\nperformance of classic algorithms in the presence of strategic individuals\n(Ahmadi et al., 2021). Addressing these challenges is imperative for the\nsuccess of machine learning in societal settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2408.01596v1",
    "published_date": "2024-08-02 22:51:52 UTC",
    "updated_date": "2024-08-02 22:51:52 UTC"
  },
  {
    "arxiv_id": "2408.11820v2",
    "title": "Responsible AI Question Bank: A Comprehensive Tool for AI Risk Assessment",
    "authors": [
      "Sung Une Lee",
      "Harsha Perera",
      "Yue Liu",
      "Boming Xia",
      "Qinghua Lu",
      "Liming Zhu",
      "Olivier Salvado",
      "Jon Whittle"
    ],
    "abstract": "The rapid growth of Artificial Intelligence (AI) has underscored the urgent\nneed for responsible AI practices. Despite increasing interest, a comprehensive\nAI risk assessment toolkit remains lacking. This study introduces our\nResponsible AI (RAI) Question Bank, a comprehensive framework and tool designed\nto support diverse AI initiatives. By integrating AI ethics principles such as\nfairness, transparency, and accountability into a structured question format,\nthe RAI Question Bank aids in identifying potential risks, aligning with\nemerging regulations like the EU AI Act, and enhancing overall AI governance. A\nkey benefit of the RAI Question Bank is its systematic approach to linking\nlower-level risk questions to higher-level ones and related themes, preventing\nsiloed assessments and ensuring a cohesive evaluation process. Case studies\nillustrate the practical application of the RAI Question Bank in assessing AI\nprojects, from evaluating risk factors to informing decision-making processes.\nThe study also demonstrates how the RAI Question Bank can be used to ensure\ncompliance with standards, mitigate risks, and promote the development of\ntrustworthy AI systems. This work advances RAI by providing organizations with\na valuable tool to navigate the complexities of ethical AI development and\ndeployment while ensuring comprehensive risk management.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "30 pages, 6 tables, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.11820v2",
    "published_date": "2024-08-02 22:40:20 UTC",
    "updated_date": "2025-01-22 05:42:45 UTC"
  },
  {
    "arxiv_id": "2408.07294v1",
    "title": "SumRecom: A Personalized Summarization Approach by Learning from Users' Feedback",
    "authors": [
      "Samira Ghodratnama",
      "Mehrdad Zakershahrak"
    ],
    "abstract": "Existing multi-document summarization approaches produce a uniform summary\nfor all users without considering individuals' interests, which is highly\nimpractical. Making a user-specific summary is a challenging task as it\nrequires: i) acquiring relevant information about a user; ii) aggregating and\nintegrating the information into a user-model; and iii) utilizing the provided\ninformation in making the personalized summary. Therefore, in this paper, we\npropose a solution to a substantial and challenging problem in summarization,\ni.e., recommending a summary for a specific user. The proposed approach, called\nSumRecom, brings the human into the loop and focuses on three aspects:\npersonalization, interaction, and learning user's interest without the need for\nreference summaries. SumRecom has two steps: i) The user preference extractor\nto capture users' inclination in choosing essential concepts, and ii) The\nsummarizer to discover the user's best-fitted summary based on the given\nfeedback. Various automatic and human evaluations on the benchmark dataset\ndemonstrate the supremacy SumRecom in generating user-specific summaries.\nDocument summarization and Interactive summarization and Personalized\nsummarization and Reinforcement learning.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07294v1",
    "published_date": "2024-08-02 22:33:59 UTC",
    "updated_date": "2024-08-02 22:33:59 UTC"
  },
  {
    "arxiv_id": "2408.01585v3",
    "title": "LibreLog: Accurate and Efficient Unsupervised Log Parsing Using Open-Source Large Language Models",
    "authors": [
      "Zeyang Ma",
      "Dong Jae Kim",
      "Tse-Hsun Chen"
    ],
    "abstract": "Log parsing is a critical step that transforms unstructured log data into\nstructured formats, facilitating subsequent log-based analysis. Traditional\nsyntax-based log parsers are efficient and effective, but they often experience\ndecreased accuracy when processing logs that deviate from the predefined rules.\nRecently, large language models (LLM) based log parsers have shown superior\nparsing accuracy. However, existing LLM-based parsers face three main\nchallenges: 1)time-consuming and labor-intensive manual labeling for\nfine-tuning or in-context learning, 2)increased parsing costs due to the vast\nvolume of log data and limited context size of LLMs, and 3)privacy risks from\nusing commercial models like ChatGPT with sensitive log information. To\novercome these limitations, this paper introduces LibreLog, an unsupervised log\nparsing approach that leverages open-source LLMs (i.e., Llama3-8B) to enhance\nprivacy and reduce operational costs while achieving state-of-the-art parsing\naccuracy. LibreLog first groups logs with similar static text but varying\ndynamic variables using a fixed-depth grouping tree. It then parses logs within\nthese groups using three components: i)similarity scoring-based retrieval\naugmented generation: selects diverse logs within each group based on Jaccard\nsimilarity, helping the LLM distinguish between static text and dynamic\nvariables; ii)self-reflection: iteratively query LLMs to refine log templates\nto improve parsing accuracy; and iii) log template memory: stores parsed\ntemplates to reduce LLM queries for improved parsing efficiency. Our evaluation\non LogHub-2.0 shows that LibreLog achieves 25% higher parsing accuracy and\nprocesses logs 2.7 times faster compared to state-of-the-art LLM-based parsers.\nIn short, LibreLog addresses privacy and cost concerns of using commercial LLMs\nwhile achieving state-of-the-arts parsing efficiency and accuracy.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01585v3",
    "published_date": "2024-08-02 21:54:13 UTC",
    "updated_date": "2024-11-18 05:18:51 UTC"
  },
  {
    "arxiv_id": "2408.01584v3",
    "title": "GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS",
    "authors": [
      "Saman Kazemkhani",
      "Aarav Pandya",
      "Daphne Cornelisse",
      "Brennan Shacklett",
      "Eugene Vinitsky"
    ],
    "abstract": "Multi-agent learning algorithms have been successful at generating superhuman\nplanning in various games but have had limited impact on the design of deployed\nmulti-agent planners. A key bottleneck in applying these techniques to\nmulti-agent planning is that they require billions of steps of experience. To\nenable the study of multi-agent planning at scale, we present GPUDrive.\nGPUDrive is a GPU-accelerated, multi-agent simulator built on top of the\nMadrona Game Engine capable of generating over a million simulation steps per\nsecond. Observation, reward, and dynamics functions are written directly in\nC++, allowing users to define complex, heterogeneous agent behaviors that are\nlowered to high-performance CUDA. Despite these low-level optimizations,\nGPUDrive is fully accessible through Python, offering a seamless and efficient\nworkflow for multi-agent, closed-loop simulation. Using GPUDrive, we train\nreinforcement learning agents on the Waymo Open Motion Dataset, achieving\nefficient goal-reaching in minutes and scaling to thousands of scenarios in\nhours. We open-source the code and pre-trained agents at\nhttps://github.com/Emerge-Lab/gpudrive.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.GR",
      "cs.PF"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2408.01584v3",
    "published_date": "2024-08-02 21:37:46 UTC",
    "updated_date": "2025-02-18 14:09:38 UTC"
  },
  {
    "arxiv_id": "2408.01582v1",
    "title": "Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference",
    "authors": [
      "Hengrui Cai",
      "Huaqing Jin",
      "Lexin Li"
    ],
    "abstract": "Estimating treatment effects from observational data is of central interest\nacross numerous application domains. Individual treatment effect offers the\nmost granular measure of treatment effect on an individual level, and is the\nmost useful to facilitate personalized care. However, its estimation and\ninference remain underdeveloped due to several challenges. In this article, we\npropose a novel conformal diffusion model-based approach that addresses those\nintricate challenges. We integrate the highly flexible diffusion modeling, the\nmodel-free statistical inference paradigm of conformal inference, along with\npropensity score and covariate local approximation that tackle distributional\nshifts. We unbiasedly estimate the distributions of potential outcomes for\nindividual treatment effect, construct an informative confidence interval, and\nestablish rigorous theoretical guarantees. We demonstrate the competitive\nperformance of the proposed method over existing solutions through extensive\nnumerical studies.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01582v1",
    "published_date": "2024-08-02 21:35:08 UTC",
    "updated_date": "2024-08-02 21:35:08 UTC"
  },
  {
    "arxiv_id": "2408.02689v1",
    "title": "Spatio-Temporal Partial Sensing Forecast for Long-term Traffic",
    "authors": [
      "Zibo Liu",
      "Zhe Jiang",
      "Zelin Xu",
      "Tingsong Xiao",
      "Zhengkun Xiao",
      "Haibo Wang",
      "Shigang Chen"
    ],
    "abstract": "Traffic forecasting uses recent measurements by sensors installed at chosen\nlocations to forecast the future road traffic. Existing work either assumes all\nlocations are equipped with sensors or focuses on short-term forecast. This\npaper studies partial sensing traffic forecast of long-term traffic, assuming\nsensors only at some locations. The study is important in lowering the\ninfrastructure investment cost in traffic management since deploying sensors at\nall locations could incur prohibitively high cost. However, the problem is\nchallenging due to the unknown distribution at unsensed locations, the\nintricate spatio-temporal correlation in long-term forecasting, as well as\nnoise in data and irregularities in traffic patterns (e.g., road closure). We\npropose a Spatio-Temporal Partial Sensing (STPS) forecast model for long-term\ntraffic prediction, with several novel contributions, including a rank-based\nembedding technique to capture irregularities and overcome noise, a spatial\ntransfer matrix to overcome the spatial distribution shift from permanently\nsensed locations to unsensed locations, and a multi-step training process that\nutilizes all available data to successively refine the model parameters for\nbetter accuracy. Extensive experiments on several real-world traffic datasets\ndemonstrate that STPS outperforms the state-of-the-art and achieves superior\naccuracy in partial sensing long-term forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02689v1",
    "published_date": "2024-08-02 21:22:22 UTC",
    "updated_date": "2024-08-02 21:22:22 UTC"
  },
  {
    "arxiv_id": "2408.03964v1",
    "title": "Telecom Foundation Models: Applications, Challenges, and Future Trends",
    "authors": [
      "Tahar Zanouda",
      "Meysam Masoudi",
      "Fitsum Gaim Gebre",
      "Mischa Dohler"
    ],
    "abstract": "Telecom networks are becoming increasingly complex, with diversified\ndeployment scenarios, multi-standards, and multi-vendor support. The intricate\nnature of the telecom network ecosystem presents challenges to effectively\nmanage, operate, and optimize networks. To address these hurdles, Artificial\nIntelligence (AI) has been widely adopted to solve different tasks in telecom\nnetworks. However, these conventional AI models are often designed for specific\ntasks, rely on extensive and costly-to-collect labeled data that require\nspecialized telecom expertise for development and maintenance. The AI models\nusually fail to generalize and support diverse deployment scenarios and\napplications. In contrast, Foundation Models (FMs) show effective\ngeneralization capabilities in various domains in language, vision, and\ndecision-making tasks. FMs can be trained on multiple data modalities generated\nfrom the telecom ecosystem and leverage specialized domain knowledge. Moreover,\nFMs can be fine-tuned to solve numerous specialized tasks with minimal\ntask-specific labeled data and, in some instances, are able to leverage context\nto solve previously unseen problems. At the dawn of 6G, this paper investigates\nthe potential opportunities of using FMs to shape the future of telecom\ntechnologies and standards. In particular, the paper outlines a conceptual\nprocess for developing Telecom FMs (TFMs) and discusses emerging opportunities\nfor orchestrating specialized TFMs for network configuration, operation, and\nmaintenance. Finally, the paper discusses the limitations and challenges of\ndeveloping and deploying TFMs.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03964v1",
    "published_date": "2024-08-02 21:09:13 UTC",
    "updated_date": "2024-08-02 21:09:13 UTC"
  },
  {
    "arxiv_id": "2408.01554v1",
    "title": "Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps Using Partial Surface Tactile Imaging",
    "authors": [
      "Siddhartha Kapuria",
      "Jeff Bonyun",
      "Yash Kulkarni",
      "Naruhiko Ikoma",
      "Sandeep Chinchali",
      "Farshid Alambeigi"
    ],
    "abstract": "In this paper, to collectively address the existing limitations on endoscopic\ndiagnosis of Advanced Gastric Cancer (AGC) Tumors, for the first time, we\npropose (i) utilization and evaluation of our recently developed Vision-based\nTactile Sensor (VTS), and (ii) a complementary Machine Learning (ML) algorithm\nfor classifying tumors using their textural features. Leveraging a seven DoF\nrobotic manipulator and unique custom-designed and additively-manufactured\nrealistic AGC tumor phantoms, we demonstrated the advantages of automated data\ncollection using the VTS addressing the problem of data scarcity and biases\nencountered in traditional ML-based approaches. Our synthetic-data-trained ML\nmodel was successfully evaluated and compared with traditional ML models\nutilizing various statistical metrics even under mixed morphological\ncharacteristics and partial sensor contact.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01554v1",
    "published_date": "2024-08-02 20:01:23 UTC",
    "updated_date": "2024-08-02 20:01:23 UTC"
  },
  {
    "arxiv_id": "2408.04645v1",
    "title": "Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course",
    "authors": [
      "Sebastian Kahl",
      "Felix Löffler",
      "Martin Maciol",
      "Fabian Ridder",
      "Marius Schmitz",
      "Jennifer Spanagel",
      "Jens Wienkamp",
      "Christopher Burgahn",
      "Malte Schilling"
    ],
    "abstract": "This study evaluates the performance of Large Language Models (LLMs) as an\nArtificial Intelligence-based tutor for a university course. In particular,\ndifferent advanced techniques are utilized, such as prompt engineering,\nRetrieval-Augmented-Generation (RAG), and fine-tuning. We assessed the\ndifferent models and applied techniques using common similarity metrics like\nBLEU-4, ROUGE, and BERTScore, complemented by a small human evaluation of\nhelpfulness and trustworthiness. Our findings indicate that RAG combined with\nprompt engineering significantly enhances model responses and produces better\nfactual answers. In the context of education, RAG appears as an ideal technique\nas it is based on enriching the input of the model with additional information\nand material which usually is already present for a university course.\nFine-tuning, on the other hand, can produce quite small, still strong expert\nmodels, but poses the danger of overfitting. Our study further asks how we\nmeasure performance of LLMs and how well current measurements represent\ncorrectness or relevance? We find high correlation on similarity metrics and a\nbias of most of these metrics towards shorter responses. Overall, our research\npoints to both the potential and challenges of integrating LLMs in educational\nsettings, suggesting a need for balanced training approaches and advanced\nevaluation frameworks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.RO"
    ],
    "primary_category": "cs.CL",
    "comment": "The article is an extended version of a paper presented at the\n  International Workshop on AI in Education and Educational Research (AIEER) at\n  ECAI-2024 (27th European Conference on Artificial Intelligence)",
    "pdf_url": "http://arxiv.org/pdf/2408.04645v1",
    "published_date": "2024-08-02 19:49:19 UTC",
    "updated_date": "2024-08-02 19:49:19 UTC"
  },
  {
    "arxiv_id": "2408.01536v2",
    "title": "Active Learning for Neural PDE Solvers",
    "authors": [
      "Daniel Musekamp",
      "Marimuthu Kalimuthu",
      "David Holzmüller",
      "Makoto Takamoto",
      "Mathias Niepert"
    ],
    "abstract": "Solving partial differential equations (PDEs) is a fundamental problem in\nscience and engineering. While neural PDE solvers can be more efficient than\nestablished numerical solvers, they often require large amounts of training\ndata that is costly to obtain. Active learning (AL) could help surrogate models\nreach the same accuracy with smaller training sets by querying classical\nsolvers with more informative initial conditions and PDE parameters. While AL\nis more common in other domains, it has yet to be studied extensively for\nneural PDE solvers. To bridge this gap, we introduce AL4PDE, a modular and\nextensible active learning benchmark. It provides multiple parametric PDEs and\nstate-of-the-art surrogate models for the solver-in-the-loop setting, enabling\nthe evaluation of existing and the development of new AL methods for neural PDE\nsolving. We use the benchmark to evaluate batch active learning algorithms such\nas uncertainty- and feature-based methods. We show that AL reduces the average\nerror by up to 71% compared to random sampling and significantly reduces\nworst-case errors. Moreover, AL generates similar datasets across repeated\nruns, with consistent distributions over the PDE parameters and initial\nconditions. The acquired datasets are reusable, providing benefits for\nsurrogate models not involved in the data generation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01536v2",
    "published_date": "2024-08-02 18:48:58 UTC",
    "updated_date": "2025-03-24 10:31:44 UTC"
  },
  {
    "arxiv_id": "2408.01532v2",
    "title": "Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization",
    "authors": [
      "Vinaya Sree Katamneni",
      "Ajita Rattani"
    ],
    "abstract": "In the digital age, the emergence of deepfakes and synthetic media presents a\nsignificant threat to societal and political integrity. Deepfakes based on\nmulti-modal manipulation, such as audio-visual, are more realistic and pose a\ngreater threat. Current multi-modal deepfake detectors are often based on the\nattention-based fusion of heterogeneous data streams from multiple modalities.\nHowever, the heterogeneous nature of the data (such as audio and visual\nsignals) creates a distributional modality gap and poses a significant\nchallenge in effective fusion and hence multi-modal deepfake detection. In this\npaper, we propose a novel multi-modal attention framework based on recurrent\nneural networks (RNNs) that leverages contextual information for audio-visual\ndeepfake detection. The proposed approach applies attention to multi-modal\nmulti-sequence representations and learns the contributing features among them\nfor deepfake detection and localization. Thorough experimental validations on\naudio-visual deepfake datasets, namely FakeAVCeleb, AV-Deepfake1M, TVIL, and\nLAV-DF datasets, demonstrate the efficacy of our approach. Cross-comparison\nwith the published studies demonstrates superior performance of our approach\nwith an improved accuracy and precision by 3.47% and 2.05% in deepfake\ndetection and localization, respectively. Thus, obtaining state-of-the-art\nperformance. To facilitate reproducibility, the code and the datasets\ninformation is available at https://github.com/vcbsl/audiovisual-deepfake/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01532v2",
    "published_date": "2024-08-02 18:45:01 UTC",
    "updated_date": "2024-08-06 21:19:20 UTC"
  },
  {
    "arxiv_id": "2408.01527v2",
    "title": "Using LLMs to Establish Implicit User Sentiment of Software Desirability",
    "authors": [
      "Sherri Weitl-Harms",
      "John D. Hastings",
      "Jonah Lum"
    ],
    "abstract": "This study explores the use of LLMs for providing quantitative zero-shot\nsentiment analysis of implicit software desirability, addressing a critical\nchallenge in product evaluation where traditional review scores, though\nconvenient, fail to capture the richness of qualitative user feedback.\nInnovations include establishing a method that 1) works with qualitative user\nexperience data without the need for explicit review scores, 2) focuses on\nimplicit user satisfaction, and 3) provides scaled numerical sentiment\nanalysis, offering a more nuanced understanding of user sentiment, instead of\nsimply classifying sentiment as positive, neutral, or negative.\n  Data is collected using the Microsoft Product Desirability Toolkit (PDT), a\nwell-known qualitative user experience analysis tool. For initial exploration,\nthe PDT metric was given to users of two software systems. PDT data was fed\nthrough several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and through a\nleading transfer learning technique, Twitter-Roberta-Base-Sentiment, and Vader,\na leading sentiment analysis tool. Each system was asked to evaluate the data\nin two ways, by looking at the sentiment expressed in the PDT word/explanation\npairs; and by looking at the sentiment expressed by the users in their grouped\nselection of five words and explanations, as a whole. Each LLM provided a\nsentiment score, its confidence (low, medium, high) in the score, and an\nexplanation of the score.\n  All LLMs tested were able to statistically detect user sentiment from the\nusers' grouped data, whereas TRBS and Vader were not. The confidence and\nexplanation of confidence provided by the LLMs assisted in understanding user\nsentiment. This study adds deeper understanding of evaluating user experiences,\ntoward the goal of creating a universal tool that quantifies implicit\nsentiment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SE",
      "I.2.7; D.2.8; I.2.6; H.5.2"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 figures, 2 tables, updated to incorporate feedback",
    "pdf_url": "http://arxiv.org/pdf/2408.01527v2",
    "published_date": "2024-08-02 18:40:10 UTC",
    "updated_date": "2024-09-08 19:59:06 UTC"
  },
  {
    "arxiv_id": "2408.01517v1",
    "title": "Gradient flow in parameter space is equivalent to linear interpolation in output space",
    "authors": [
      "Thomas Chen",
      "Patrícia Muñoz Ewald"
    ],
    "abstract": "We prove that the usual gradient flow in parameter space that underlies many\ntraining algorithms for neural networks in deep learning can be continuously\ndeformed into an adapted gradient flow which yields (constrained) Euclidean\ngradient flow in output space. Moreover, if the Jacobian of the outputs with\nrespect to the parameters is full rank (for fixed training data), then the time\nvariable can be reparametrized so that the resulting flow is simply linear\ninterpolation, and a global minimum can be achieved.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math-ph",
      "math.MP",
      "math.OC",
      "stat.ML",
      "62M45, 37C10"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01517v1",
    "published_date": "2024-08-02 18:23:17 UTC",
    "updated_date": "2024-08-02 18:23:17 UTC"
  },
  {
    "arxiv_id": "2408.01423v1",
    "title": "Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting",
    "authors": [
      "Xiangyu Zhao",
      "Chengqian Ma"
    ],
    "abstract": "Large Language Models (LLMs) exhibit remarkable proficiency in addressing a\ndiverse array of tasks within the Natural Language Processing (NLP) domain,\nwith various prompt design strategies significantly augmenting their\ncapabilities. However, these prompts, while beneficial, each possess inherent\nlimitations. The primary prompt design methodologies are twofold: The first,\nexemplified by the Chain of Thought (CoT), involves manually crafting prompts\nspecific to individual datasets, hence termed Expert-Designed Prompts (EDPs).\nOnce these prompts are established, they are unalterable, and their\neffectiveness is capped by the expertise of the human designers. When applied\nto LLMs, the static nature of EDPs results in a uniform approach to both simple\nand complex problems within the same dataset, leading to the inefficient use of\ntokens for straightforward issues. The second method involves prompts\nautonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which\nprovide tailored solutions to specific problems, mitigating the limitations of\nEDPs. However, LDPs may encounter a decline in performance when tackling\ncomplex problems due to the potential for error accumulation during the\nsolution planning process. To address these challenges, we have conceived a\nnovel Prompt Recursive Search (PRS) framework that leverages the LLM to\ngenerate solutions specific to the problem, thereby conserving tokens. The\nframework incorporates an assessment of problem complexity and an adjustable\nstructure, ensuring a reduction in the likelihood of errors. We have\nsubstantiated the efficacy of PRS framework through extensive experiments using\nLLMs with different numbers of parameters across a spectrum of datasets in\nvarious domains. Compared to the CoT method, the PRS method has increased the\naccuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%\nimprovement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages,4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01423v1",
    "published_date": "2024-08-02 17:59:42 UTC",
    "updated_date": "2024-08-02 17:59:42 UTC"
  },
  {
    "arxiv_id": "2408.01420v1",
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": [
      "Jingtong Su",
      "Julia Kempe",
      "Karen Ullrich"
    ],
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "published_date": "2024-08-02 17:55:50 UTC",
    "updated_date": "2024-08-02 17:55:50 UTC"
  },
  {
    "arxiv_id": "2408.01417v1",
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": [
      "Yilun Hua",
      "Yoav Artzi"
    ],
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "published_date": "2024-08-02 17:51:57 UTC",
    "updated_date": "2024-08-02 17:51:57 UTC"
  },
  {
    "arxiv_id": "2408.01416v1",
    "title": "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
    "authors": [
      "Aaron Mueller",
      "Jannik Brinkmann",
      "Millicent Li",
      "Samuel Marks",
      "Koyena Pal",
      "Nikhil Prakash",
      "Can Rager",
      "Aruna Sankaranarayanan",
      "Arnab Sen Sharma",
      "Jiuding Sun",
      "Eric Todd",
      "David Bau",
      "Yonatan Belinkov"
    ],
    "abstract": "Interpretability provides a toolset for understanding how and why neural\nnetworks behave in certain ways. However, there is little unity in the field:\nmost studies employ ad-hoc evaluations and do not share theoretical\nfoundations, making it difficult to measure progress and compare the pros and\ncons of different techniques. Furthermore, while mechanistic understanding is\nfrequently discussed, the basic causal units underlying these mechanisms are\noften not explicitly defined. In this paper, we propose a perspective on\ninterpretability research grounded in causal mediation analysis. Specifically,\nwe describe the history and current state of interpretability taxonomized\naccording to the types of causal units (mediators) employed, as well as methods\nused to search over mediators. We discuss the pros and cons of each mediator,\nproviding insights as to when particular kinds of mediators and search methods\nare most appropriate depending on the goals of a given study. We argue that\nthis framing yields a more cohesive narrative of the field, as well as\nactionable insights for future work. Specifically, we recommend a focus on\ndiscovering new mediators with better trade-offs between human-interpretability\nand compute-efficiency, and which can uncover more sophisticated abstractions\nfrom neural networks than the primarily linear mediators employed in current\nwork. We also argue for more standardized evaluations that enable principled\ncomparisons across mediator types, such that we can better understand when\nparticular causal units are better suited to particular use cases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01416v1",
    "published_date": "2024-08-02 17:51:42 UTC",
    "updated_date": "2024-08-02 17:51:42 UTC"
  },
  {
    "arxiv_id": "2408.01415v1",
    "title": "Conditional LoRA Parameter Generation",
    "authors": [
      "Xiaolong Jin",
      "Kai Wang",
      "Dongwen Tang",
      "Wangbo Zhao",
      "Yukun Zhou",
      "Junshu Tang",
      "Yang You"
    ],
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "published_date": "2024-08-02 17:43:34 UTC",
    "updated_date": "2024-08-02 17:43:34 UTC"
  },
  {
    "arxiv_id": "2408.01402v1",
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": [
      "Yu Yang",
      "Pan Xu"
    ],
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "2 figures, 8 tables. Accepted by the Training Agents with Foundation\n  Models Workshop at RLC 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "published_date": "2024-08-02 17:25:34 UTC",
    "updated_date": "2024-08-02 17:25:34 UTC"
  },
  {
    "arxiv_id": "2408.03866v2",
    "title": "A semantic approach to mapping the Provenance Ontology to Basic Formal Ontology",
    "authors": [
      "Tim Prudhomme",
      "Giacomo De Colle",
      "Austin Liebers",
      "Alec Sculley",
      "Peihong \"Karl\" Xie",
      "Sydney Cohen",
      "John Beverley"
    ],
    "abstract": "The Provenance Ontology (PROV-O) is a World Wide Web Consortium (W3C)\nrecommended ontology used to structure data about provenance across a wide\nvariety of domains. Basic Formal Ontology (BFO) is a top-level ontology ISO/IEC\nstandard used to structure a wide variety of ontologies, such as the OBO\nFoundry ontologies and the Common Core Ontologies (CCO). To enhance\ninteroperability between these two ontologies, their extensions, and data\norganized by them, a mapping methodology and set of alignments are presented\naccording to specific criteria which prioritize semantic and logical\nprinciples. The ontology alignments are evaluated by checking their logical\nconsistency with canonical examples of PROV-O instances and querying terms that\ndo not satisfy the alignment criteria as formalized in SPARQL. A variety of\nsemantic web technologies are used in support of FAIR (Findable, Accessible,\nInteroperable, Reusable) principles.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.DB",
    "comment": "31 pages, 12 figures. This version of the article has been accepted\n  for publication, after peer review (when applicable) but is not the Version\n  of Record and does not reflect post-acceptance improvements, or any\n  corrections. The Version of Record is available online at:\n  https://doi.org/10.1038/s41597-025-04580-1",
    "pdf_url": "http://arxiv.org/pdf/2408.03866v2",
    "published_date": "2024-08-02 16:50:17 UTC",
    "updated_date": "2025-03-23 17:23:51 UTC"
  },
  {
    "arxiv_id": "2408.01349v1",
    "title": "PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval",
    "authors": [
      "Yue Duan",
      "Zhangxuan Gu",
      "Zhenzhe Ying",
      "Lei Qi",
      "Changhua Meng",
      "Yinghuan Shi"
    ],
    "abstract": "In the realm of cross-modal retrieval, seamlessly integrating diverse\nmodalities within multimedia remains a formidable challenge, especially given\nthe complexities introduced by noisy correspondence learning (NCL). Such noise\noften stems from mismatched data pairs, which is a significant obstacle\ndistinct from traditional noisy labels. This paper introduces\nPseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address\nthis challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an\nauxiliary \"pseudo-classification\" task that interprets captions as categorical\nlabels, steering the model to learn image-text semantic similarity through a\nnon-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,\ncapitalizing on PC$^2$'s pseudo-classification capability, we generate\npseudo-captions to provide more informative and tangible supervision for each\nmismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed\nto assistant the correction of correspondence. In addition to technical\ncontributions, we develop a realistic NCL dataset called Noise of Web (NoW),\nwhich could be a new powerful NCL benchmark where noise exists naturally.\nEmpirical evaluations of PC$^2$ showcase marked improvements over existing\nstate-of-the-art robust cross-modal retrieval techniques on both simulated and\nrealistic datasets with various NCL settings. The contributed dataset and\nsource code are released at https://github.com/alipay/PC2-NoiseofWeb.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted by ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.01349v1",
    "published_date": "2024-08-02 15:54:49 UTC",
    "updated_date": "2024-08-02 15:54:49 UTC"
  },
  {
    "arxiv_id": "2408.01343v1",
    "title": "StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation",
    "authors": [
      "Bingyu Li",
      "Da Zhang",
      "Zhiyuan Zhao",
      "Junyu Gao",
      "Xuelong Li"
    ],
    "abstract": "Multimodal semantic segmentation shows significant potential for enhancing\nsegmentation accuracy in complex scenes. However, current methods often\nincorporate specialized feature fusion modules tailored to specific modalities,\nthereby restricting input flexibility and increasing the number of training\nparameters. To address these challenges, we propose StitchFusion, a\nstraightforward yet effective modal fusion framework that integrates\nlarge-scale pre-trained models directly as encoders and feature fusers. This\napproach facilitates comprehensive multi-modal and multi-scale feature fusion,\naccommodating any visual modal inputs. Specifically, Our framework achieves\nmodal integration during encoding by sharing multi-modal visual information. To\nenhance information exchange across modalities, we introduce a\nmulti-directional adapter module (MultiAdapter) to enable cross-modal\ninformation transfer during encoding. By leveraging MultiAdapter to propagate\nmulti-scale information across pre-trained encoders during the encoding\nprocess, StitchFusion achieves multi-modal visual information integration\nduring encoding. Extensive comparative experiments demonstrate that our model\nachieves state-of-the-art performance on four multi-modal segmentation datasets\nwith minimal additional parameters. Furthermore, the experimental integration\nof MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their\ncomplementary nature. Our code is available at StitchFusion_repo.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01343v1",
    "published_date": "2024-08-02 15:41:16 UTC",
    "updated_date": "2024-08-02 15:41:16 UTC"
  },
  {
    "arxiv_id": "2408.01342v1",
    "title": "Leveraging Knowledge Graph Embedding for Effective Conversational Recommendation",
    "authors": [
      "Yunwen Xia",
      "Hui Fang",
      "Jie Zhang",
      "Chong Long"
    ],
    "abstract": "Conversational recommender system (CRS), which combines the techniques of\ndialogue system and recommender system, has obtained increasing interest\nrecently. In contrast to traditional recommender system, it learns the user\npreference better through interactions (i.e. conversations), and then further\nboosts the recommendation performance. However, existing studies on CRS ignore\nto address the relationship among attributes, users, and items effectively,\nwhich might lead to inappropriate questions and inaccurate recommendations. In\nthis view, we propose a knowledge graph based conversational recommender system\n(referred as KG-CRS). Specifically, we first integrate the user-item graph and\nitem-attribute graph into a dynamic graph, i.e., dynamically changing during\nthe dialogue process by removing negative items or attributes. We then learn\ninformative embedding of users, items, and attributes by also considering\npropagation through neighbors on the graph. Extensive experiments on three real\ndatasets validate the superiority of our method over the state-of-the-art\napproaches in terms of both the recommendation and conversation tasks.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "26pages, 15figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01342v1",
    "published_date": "2024-08-02 15:38:55 UTC",
    "updated_date": "2024-08-02 15:38:55 UTC"
  },
  {
    "arxiv_id": "2408.01334v3",
    "title": "A Backbone for Long-Horizon Robot Task Understanding",
    "authors": [
      "Xiaoshuai Chen",
      "Wei Chen",
      "Dongmyoung Lee",
      "Yukun Ge",
      "Nicolas Rojas",
      "Petar Kormushev"
    ],
    "abstract": "End-to-end robot learning, particularly for long-horizon tasks, often results\nin unpredictable outcomes and poor generalization. To address these challenges,\nwe propose a novel Therblig-Based Backbone Framework (TBBF) as a fundamental\nstructure to enhance interpretability, data efficiency, and generalization in\nrobotic systems. TBBF utilizes expert demonstrations to enable therblig-level\ntask decomposition, facilitate efficient action-object mapping, and generate\nadaptive trajectories for new scenarios. The approach consists of two stages:\noffline training and online testing. During the offline training stage, we\ndeveloped the Meta-RGate SynerFusion (MGSF) network for accurate therblig\nsegmentation across various tasks. In the online testing stage, after a\none-shot demonstration of a new task is collected, our MGSF network extracts\nhigh-level knowledge, which is then encoded into the image using Action\nRegistration (ActionREG). Additionally, Large Language Model (LLM)-Alignment\nPolicy for Visual Correction (LAP-VC) is employed to ensure precise action\nregistration, facilitating trajectory transfer in novel robot scenarios.\nExperimental results validate these methods, achieving 94.37% recall in\ntherblig segmentation and success rates of 94.4% and 80% in real-world online\nrobot testing for simple and complex scenarios, respectively. Supplementary\nmaterial is available at:\nhttps://sites.google.com/view/therbligsbasedbackbone/home",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 8 figures. This work has been published by IEEE Robotics and\n  Automation Letters (RA-L)",
    "pdf_url": "http://arxiv.org/pdf/2408.01334v3",
    "published_date": "2024-08-02 15:32:42 UTC",
    "updated_date": "2025-03-06 11:59:11 UTC"
  },
  {
    "arxiv_id": "2408.01322v3",
    "title": "A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes",
    "authors": [
      "Vito Mengers",
      "Nicolas Roth",
      "Oliver Brock",
      "Klaus Obermayer",
      "Martin Rolfs"
    ],
    "abstract": "The objects we perceive guide our eye movements when observing real-world\ndynamic scenes. Yet, gaze shifts and selective attention are critical for\nperceiving details and refining object boundaries. Object segmentation and gaze\nbehavior are, however, typically treated as two independent processes. Here, we\npresent a computational model that simulates these processes in an\ninterconnected manner and allows for hypothesis-driven investigations of\ndistinct attentional mechanisms. Drawing on an information processing pattern\nfrom robotics, we use a Bayesian filter to recursively segment the scene, which\nalso provides an uncertainty estimate for the object boundaries that we use to\nguide active scene exploration. We demonstrate that this model closely\nresembles observers' free viewing behavior on a dataset of dynamic real-world\nscenes, measured by scanpath statistics, including foveation duration and\nsaccade amplitude distributions used for parameter fitting and higher-level\nstatistics not used for fitting. These include how object detections,\ninspections, and returns are balanced and a delay of returning saccades without\nan explicit implementation of such temporal inhibition of return. Extensive\nsimulations and ablation studies show that uncertainty promotes balanced\nexploration and that semantic object cues are crucial to forming the perceptual\nunits used in object-based attention. Moreover, we show how our model's modular\ndesign allows for extensions, such as incorporating saccadic momentum or\npre-saccadic attention, to further align its output with human scanpaths.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "comment": "40+25 pages, 8+7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01322v3",
    "published_date": "2024-08-02 15:20:34 UTC",
    "updated_date": "2025-02-11 11:18:26 UTC"
  },
  {
    "arxiv_id": "2408.01319v1",
    "title": "A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks",
    "authors": [
      "Jiaqi Wang",
      "Hanqi Jiang",
      "Yiheng Liu",
      "Chong Ma",
      "Xu Zhang",
      "Yi Pan",
      "Mengyuan Liu",
      "Peiran Gu",
      "Sichen Xia",
      "Wenjun Li",
      "Yutong Zhang",
      "Zihao Wu",
      "Zhengliang Liu",
      "Tianyang Zhong",
      "Bao Ge",
      "Tuo Zhang",
      "Ning Qiang",
      "Xintao Hu",
      "Xi Jiang",
      "Xin Zhang",
      "Wei Zhang",
      "Dinggang Shen",
      "Tianming Liu",
      "Shu Zhang"
    ],
    "abstract": "In an era defined by the explosive growth of data and rapid technological\nadvancements, Multimodal Large Language Models (MLLMs) stand at the forefront\nof artificial intelligence (AI) systems. Designed to seamlessly integrate\ndiverse data types-including text, images, videos, audio, and physiological\nsequences-MLLMs address the complexities of real-world applications far beyond\nthe capabilities of single-modality systems. In this paper, we systematically\nsort out the applications of MLLM in multimodal tasks such as natural language,\nvision, and audio. We also provide a comparative analysis of the focus of\ndifferent MLLMs in the tasks, and provide insights into the shortcomings of\ncurrent MLLMs, and suggest potential directions for future research. Through\nthese discussions, this paper hopes to provide valuable insights for the\nfurther development and application of MLLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01319v1",
    "published_date": "2024-08-02 15:14:53 UTC",
    "updated_date": "2024-08-02 15:14:53 UTC"
  },
  {
    "arxiv_id": "2408.01316v1",
    "title": "Synergistic pathways of modulation enable robust task packing within neural dynamics",
    "authors": [
      "Giacomo Vedovati",
      "ShiNung Ching"
    ],
    "abstract": "Understanding how brain networks learn and manage multiple tasks\nsimultaneously is of interest in both neuroscience and artificial intelligence.\nIn this regard, a recent research thread in theoretical neuroscience has\nfocused on how recurrent neural network models and their internal dynamics\nenact multi-task learning. To manage different tasks requires a mechanism to\nconvey information about task identity or context into the model, which from a\nbiological perspective may involve mechanisms of neuromodulation. In this\nstudy, we use recurrent network models to probe the distinctions between two\nforms of contextual modulation of neural dynamics, at the level of neuronal\nexcitability and at the level of synaptic strength. We characterize these\nmechanisms in terms of their functional outcomes, focusing on their robustness\nto context ambiguity and, relatedly, their efficiency with respect to packing\nmultiple tasks into finite size networks. We also demonstrate distinction\nbetween these mechanisms at the level of the neuronal dynamics they induce.\nTogether, these characterizations indicate complementarity and synergy in how\nthese mechanisms act, potentially over multiple time-scales, toward enhancing\nrobustness of multi-task learning.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "24 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01316v1",
    "published_date": "2024-08-02 15:12:01 UTC",
    "updated_date": "2024-08-02 15:12:01 UTC"
  },
  {
    "arxiv_id": "2408.01301v1",
    "title": "A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment",
    "authors": [
      "Gregory Canal",
      "Vladimir Leung",
      "Philip Sage",
      "Eric Heim",
      "I-Jeng Wang"
    ],
    "abstract": "Artificial intelligence (AI) has revolutionized decision-making processes and\nsystems throughout society and, in particular, has emerged as a significant\ntechnology in high-impact scenarios of national interest. Yet, despite AI's\nimpressive predictive capabilities in controlled settings, it still suffers\nfrom a range of practical setbacks preventing its widespread use in various\ncritical scenarios. In particular, it is generally unclear if a given AI\nsystem's predictions can be trusted by decision-makers in downstream\napplications. To address the need for more transparent, robust, and trustworthy\nAI systems, a suite of tools has been developed to quantify the uncertainty of\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\nof its predictions. In this manuscript, we categorize methods for AI\nself-assessment along several key dimensions and provide guidelines for\nselecting and designing the appropriate method for a practitioner's needs. In\nparticular, we focus on uncertainty estimation techniques that consider the\nimpact of self-assessment on the choices made by downstream decision-makers and\non the resulting costs and benefits of decision outcomes. To demonstrate the\nutility of our methodology for self-assessment design, we illustrate its use\nfor two realistic national-interest scenarios. This manuscript is a practical\nguide for machine learning engineers and AI system users to select the ideal\nself-assessment techniques for each problem.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01301v1",
    "published_date": "2024-08-02 14:43:45 UTC",
    "updated_date": "2024-08-02 14:43:45 UTC"
  },
  {
    "arxiv_id": "2408.01292v1",
    "title": "3DPX: Progressive 2D-to-3D Oral Image Reconstruction with Hybrid MLP-CNN Networks",
    "authors": [
      "Xiaoshuang Li",
      "Mingyuan Meng",
      "Zimo Huang",
      "Lei Bi",
      "Eduardo Delamare",
      "Dagan Feng",
      "Bin Sheng",
      "Jinman Kim"
    ],
    "abstract": "Panoramic X-ray (PX) is a prevalent modality in dental practice for its wide\navailability and low cost. However, as a 2D projection image, PX does not\ncontain 3D anatomical information, and therefore has limited use in dental\napplications that can benefit from 3D information, e.g., tooth angular\nmisa-lignment detection and classification. Reconstructing 3D structures\ndirectly from 2D PX has recently been explored to address limitations with\nexisting methods primarily reliant on Convolutional Neural Networks (CNNs) for\ndirect 2D-to-3D mapping. These methods, however, are unable to correctly infer\ndepth-axis spatial information. In addition, they are limited by the in-trinsic\nlocality of convolution operations, as the convolution kernels only capture the\ninformation of immediate neighborhood pixels. In this study, we propose a\nprogressive hybrid Multilayer Perceptron (MLP)-CNN pyra-mid network (3DPX) for\n2D-to-3D oral PX reconstruction. We introduce a progressive reconstruction\nstrategy, where 3D images are progressively re-constructed in the 3DPX with\nguidance imposed on the intermediate recon-struction result at each pyramid\nlevel. Further, motivated by the recent ad-vancement of MLPs that show promise\nin capturing fine-grained long-range dependency, our 3DPX integrates MLPs and\nCNNs to improve the semantic understanding during reconstruction. Extensive\nexperiments on two large datasets involving 464 studies demonstrate that our\n3DPX outperforms state-of-the-art 2D-to-3D oral reconstruction methods,\nincluding standalone MLP and transformers, in reconstruction quality, and also\nim-proves the performance of downstream angular misalignment classification\ntasks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "accepted by MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.01292v1",
    "published_date": "2024-08-02 14:28:10 UTC",
    "updated_date": "2024-08-02 14:28:10 UTC"
  },
  {
    "arxiv_id": "2408.01263v3",
    "title": "Designing the virtual CAT: A digital tool for algorithmic thinking assessment in compulsory education",
    "authors": [
      "Giorgia Adorni",
      "Alberto Piatti"
    ],
    "abstract": "Algorithmic thinking (AT) is a critical skill in today's digital society, and\nit is indispensable not only in computer science-related fields but also in\neveryday problem-solving. As a foundational component of digital education and\nliteracy, fostering AT skills is increasingly relevant for all students and\nshould become a standard part of compulsory education. However, successfully\nintegrating AT into formal education requires effective teaching strategies and\nrobust and scalable assessment procedures. In this paper, we present the design\nand development process of the virtual Cross Array Task (CAT), a digital\nadaptation of an unplugged assessment activity aimed at evaluating algorithmic\nskills in Swiss compulsory education. The development process followed\niterative design cycles, incorporating expert evaluations to refine the tool's\nusability, accessibility and functionality. A participatory design study played\na dual role in shaping the platform. First, it gathered valuable insights from\nend users, including students and teachers, to ensure the tool's relevance and\npracticality in classroom settings. Second, it facilitated the collection and\npreliminary analysis of data related to students' AT skills, providing an\ninitial evaluation of the tool's assessment capabilities across various\ndevelopmental stages. This was achieved through a pilot study involving a\ndiverse group of students aged 4 to 12, spanning preschool to lower secondary\nschool levels. The resulting instrument features multilingual support and\nincludes both gesture-based and visual block-based programming interfaces,\nmaking it accessible to a broad range of learners. Findings from the pilot\nstudy demonstrate the platform's usability and accessibility, as well as its\nsuitability for assessing AT skills, with preliminary results showing its\nability to cater to diverse age groups and educational contexts.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01263v3",
    "published_date": "2024-08-02 13:36:17 UTC",
    "updated_date": "2024-11-26 17:05:55 UTC"
  },
  {
    "arxiv_id": "2408.01257v1",
    "title": "Detection and Characterization of Coordinated Online Behavior: A Survey",
    "authors": [
      "Lorenzo Mannocci",
      "Michele Mazza",
      "Anna Monreale",
      "Maurizio Tesconi",
      "Stefano Cresci"
    ],
    "abstract": "Coordination is a fundamental aspect of life. The advent of social media has\nmade it integral also to online human interactions, such as those that\ncharacterize thriving online communities and social movements. At the same\ntime, coordination is also core to effective disinformation, manipulation, and\nhate campaigns. This survey collects, categorizes, and critically discusses the\nbody of work produced as a result of the growing interest on coordinated online\nbehavior. We reconcile industry and academic definitions, propose a\ncomprehensive framework to study coordinated online behavior, and review and\ncritically discuss the existing detection and characterization methods. Our\nanalysis identifies open challenges and promising directions of research,\nserving as a guide for scholars, practitioners, and policymakers in\nunderstanding and addressing the complexities inherent to online coordination.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01257v1",
    "published_date": "2024-08-02 13:27:56 UTC",
    "updated_date": "2024-08-02 13:27:56 UTC"
  },
  {
    "arxiv_id": "2408.01254v2",
    "title": "TrIM, Triangular Input Movement Systolic Array for Convolutional Neural Networks: Dataflow and Analytical Modelling",
    "authors": [
      "Cristian Sestito",
      "Shady Agwa",
      "Themis Prodromakis"
    ],
    "abstract": "In order to follow the ever-growing computational complexity and data\nintensity of state-of-the-art AI models, new computing paradigms are being\nproposed. These paradigms aim at achieving high energy efficiency, by\nmitigating the Von Neumann bottleneck that relates to the energy cost of moving\ndata between the processing cores and the memory. Convolutional Neural Networks\n(CNNs) are susceptible to this bottleneck, given the massive data they have to\nmanage. Systolic Arrays (SAs) are promising architectures to mitigate the data\ntransmission cost, thanks to high data utilization of Processing Elements\n(PEs). These PEs continuously exchange and process data locally based on\nspecific dataflows (like weight stationary and row stationary), in turn\nreducing the number of memory accesses to the main memory. In SAs, convolutions\nare managed either as matrix multiplications or exploiting the raster-order\nscan of sliding windows. However, data redundancy is a primary concern\naffecting area, power and energy. In this paper, we propose TrIM: a novel\ndataflow for SAs based on a Triangular Input Movement and compatible with CNN\ncomputing. TrIM maximizes the local input utilization, minimizes the weight\ndata movement and solves the data redundancy problem. Furthermore, TrIM does\nnot incur the significant on-chip memory penalty introduced by the row\nstationary dataflow. When compared to state-of-the-art SA dataflows the high\ndata utilization offered by TrIM guarantees ~10x less memory access.\nFurthermore, considering that PEs continuously overlap multiplications and\naccumulations, TrIM achieves high throughput (up to 81.8% higher than row\nstationary), other than requiring a limited number of registers (up to 15.6x\nfewer registers than row stationary).",
    "categories": [
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01254v2",
    "published_date": "2024-08-02 13:15:17 UTC",
    "updated_date": "2024-12-23 08:15:28 UTC"
  },
  {
    "arxiv_id": "2408.01253v2",
    "title": "Metareasoning in uncertain environments: a meta-BAMDP framework",
    "authors": [
      "Prakhar Godara",
      "Tilman Diego Aléman",
      "Angela J. Yu"
    ],
    "abstract": "\\textit{Reasoning} may be viewed as an algorithm $P$ that makes a choice of\nan action $a^* \\in \\mathcal{A}$, aiming to optimize some outcome. However,\nexecuting $P$ itself bears costs (time, energy, limited capacity, etc.) and\nneeds to be considered alongside explicit utility obtained by making the choice\nin the underlying decision problem. Finding the right $P$ can itself be framed\nas an optimization problem over the space of reasoning processes $P$, generally\nreferred to as \\textit{metareasoning}. Conventionally, human metareasoning\nmodels assume that the agent knows the transition and reward distributions of\nthe underlying MDP. This paper generalizes such models by proposing a meta\nBayes-Adaptive MDP (meta-BAMDP) framework to handle metareasoning in\nenvironments with unknown reward/transition distributions, which encompasses a\nfar larger and more realistic set of planning problems that humans and AI\nsystems face. As a first step, we apply the framework to Bernoulli bandit\ntasks. Owing to the meta problem's complexity, our solutions are necessarily\napproximate. However, we introduce two novel theorems that significantly\nenhance the tractability of the problem, enabling stronger approximations that\nare robust within a range of assumptions grounded in realistic human\ndecision-making scenarios. These results offer a resource-rational perspective\nand a normative framework for understanding human exploration under cognitive\nconstraints, as well as providing experimentally testable predictions about\nhuman behavior in Bernoulli Bandit tasks.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01253v2",
    "published_date": "2024-08-02 13:15:01 UTC",
    "updated_date": "2025-02-03 15:11:31 UTC"
  },
  {
    "arxiv_id": "2408.01248v1",
    "title": "Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system",
    "authors": [
      "Li Dong",
      "Feibo Jiang",
      "Minjie Wang",
      "Yubo Peng",
      "Xiaolong Li"
    ],
    "abstract": "The intelligent reflection surface (IRS) and unmanned aerial vehicle\n(UAV)-assisted mobile edge computing (MEC) system is widely used in temporary\nand emergency scenarios. Our goal is to minimize the energy consumption of the\nMEC system by jointly optimizing UAV locations, IRS phase shift, task\noffloading, and resource allocation with a variable number of UAVs. To this\nend, we propose a Flexible REsource Scheduling (FRES) framework by employing a\nnovel deep progressive reinforcement learning which includes the following\ninnovations: Firstly, a novel multi-task agent is presented to deal with the\nmixed integer nonlinear programming (MINLP) problem. The multi-task agent has\ntwo output heads designed for different tasks, in which a classified head is\nemployed to make offloading decisions with integer variables while a fitting\nhead is applied to solve resource allocation with continuous variables.\nSecondly, a progressive scheduler is introduced to adapt the agent to the\nvarying number of UAVs by progressively adjusting a part of neurons in the\nagent. This structure can naturally accumulate experiences and be immune to\ncatastrophic forgetting. Finally, a light taboo search (LTS) is introduced to\nenhance the global search of the FRES. The numerical results demonstrate the\nsuperiority of the FRES framework which can make real-time and optimal resource\nscheduling even in dynamic MEC systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01248v1",
    "published_date": "2024-08-02 13:10:33 UTC",
    "updated_date": "2024-08-02 13:10:33 UTC"
  },
  {
    "arxiv_id": "2408.01239v2",
    "title": "Tailoring Graph Neural Network-based Flow-guided Localization to Individual Bloodstreams and Activities",
    "authors": [
      "Pablo Galván",
      "Filip Lemic",
      "Gerard Calvo Bartra",
      "Sergi Abadal",
      "Xavier Costa Pérez"
    ],
    "abstract": "Flow-guided localization using in-body nanodevices in the bloodstream is\nexpected to be beneficial for early disease detection, continuous monitoring of\nbiological conditions, and targeted treatment. The nanodevices face size and\npower constraints that produce erroneous raw data for localization purposes.\nOn-body anchors receive this data, and use it to derive the locations of\ndiagnostic events of interest. Different Machine Learning (ML) approaches have\nbeen recently proposed for this task, yet they are currently restricted to a\nreference bloodstream of a resting patient. As such, they are unable to deal\nwith the physical diversity of patients' bloodstreams and cannot provide\ncontinuous monitoring due to changes in individual patient's activities. Toward\naddressing these issues for the current State-of-the-Art (SotA) flow-guided\nlocalization approach based on Graph Neural Networks (GNNs), we propose a\npipeline for GNN adaptation based on individual physiological indicators\nincluding height, weight, and heart rate. Our results indicate that the\nproposed adaptions are beneficial in reconciling the individual differences\nbetween bloodstreams and activities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 9 figures, 2 tables, 16 references, accepted at ACM\n  NanoCom'25",
    "pdf_url": "http://arxiv.org/pdf/2408.01239v2",
    "published_date": "2024-08-02 12:58:08 UTC",
    "updated_date": "2024-08-20 11:12:23 UTC"
  },
  {
    "arxiv_id": "2408.01221v1",
    "title": "Rubric-based Learner Modelling via Noisy Gates Bayesian Networks for Computational Thinking Skills Assessment",
    "authors": [
      "Giorgia Adorni",
      "Francesca Mangili",
      "Alberto Piatti",
      "Claudio Bonesana",
      "Alessandro Antonucci"
    ],
    "abstract": "In modern and personalised education, there is a growing interest in\ndeveloping learners' competencies and accurately assessing them. In a previous\nwork, we proposed a procedure for deriving a learner model for automatic skill\nassessment from a task-specific competence rubric, thus simplifying the\nimplementation of automated assessment tools. The previous approach, however,\nsuffered two main limitations: (i) the ordering between competencies defined by\nthe assessment rubric was only indirectly modelled; (ii) supplementary skills,\nnot under assessment but necessary for accomplishing the task, were not\nincluded in the model. In this work, we address issue (i) by introducing dummy\nobserved nodes, strictly enforcing the skills ordering without changing the\nnetwork's structure. In contrast, for point (ii), we design a network with two\nlayers of gates, one performing disjunctive operations by noisy-OR gates and\nthe other conjunctive operations through logical ANDs. Such changes improve the\nmodel outcomes' coherence and the modelling tool's flexibility without\ncompromising the model's compact parametrisation, interpretability and simple\nexperts' elicitation. We used this approach to develop a learner model for\nComputational Thinking (CT) skills assessment. The CT-cube skills assessment\nframework and the Cross Array Task (CAT) are used to exemplify it and\ndemonstrate its feasibility.",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01221v1",
    "published_date": "2024-08-02 12:21:05 UTC",
    "updated_date": "2024-08-02 12:21:05 UTC"
  },
  {
    "arxiv_id": "2408.01214v1",
    "title": "High-Throughput Phenotyping of Clinical Text Using Large Language Models",
    "authors": [
      "Daniel B. Hier",
      "S. Ilyas Munzir",
      "Anne Stahlfeld",
      "Tayo Obafemi-Ajayi",
      "Michael D. Carrithers"
    ],
    "abstract": "High-throughput phenotyping automates the mapping of patient signs to\nstandardized ontology concepts and is essential for precision medicine. This\nstudy evaluates the automation of phenotyping of clinical summaries from the\nOnline Mendelian Inheritance in Man (OMIM) database using large language\nmodels. Due to their rich phenotype data, these summaries can be surrogates for\nphysician notes. We conduct a performance comparison of GPT-4 and\nGPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in\nidentifying, categorizing, and normalizing signs, achieving concordance with\nmanual annotators comparable to inter-rater agreement. Despite some limitations\nin sign normalization, the extensive pre-training of GPT-4 results in high\nperformance and generalizability across several phenotyping tasks while\nobviating the need for manually annotated training data. Large language models\nare expected to be the dominant method for automating high-throughput\nphenotyping of clinical text.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.7; I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to IEEE-EMBS International Conference on Biomedical and\n  Health Informatics (BHI), Houston TX",
    "pdf_url": "http://arxiv.org/pdf/2408.01214v1",
    "published_date": "2024-08-02 12:00:00 UTC",
    "updated_date": "2024-08-02 12:00:00 UTC"
  },
  {
    "arxiv_id": "2408.02686v1",
    "title": "A Systematic Review of Intermediate Fusion in Multimodal Deep Learning for Biomedical Applications",
    "authors": [
      "Valerio Guarrasi",
      "Fatih Aksu",
      "Camillo Maria Caruso",
      "Francesco Di Feola",
      "Aurora Rofena",
      "Filippo Ruffini",
      "Paolo Soda"
    ],
    "abstract": "Deep learning has revolutionized biomedical research by providing\nsophisticated methods to handle complex, high-dimensional data. Multimodal deep\nlearning (MDL) further enhances this capability by integrating diverse data\ntypes such as imaging, textual data, and genetic information, leading to more\nrobust and accurate predictive models. In MDL, differently from early and late\nfusion methods, intermediate fusion stands out for its ability to effectively\ncombine modality-specific features during the learning process. This systematic\nreview aims to comprehensively analyze and formalize current intermediate\nfusion methods in biomedical applications. We investigate the techniques\nemployed, the challenges faced, and potential future directions for advancing\nintermediate fusion methods. Additionally, we introduce a structured notation\nto enhance the understanding and application of these methods beyond the\nbiomedical domain. Our findings are intended to support researchers, healthcare\nprofessionals, and the broader deep learning community in developing more\nsophisticated and insightful multimodal models. Through this review, we aim to\nprovide a foundational framework for future research and practical applications\nin the dynamic field of MDL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02686v1",
    "published_date": "2024-08-02 11:48:04 UTC",
    "updated_date": "2024-08-02 11:48:04 UTC"
  },
  {
    "arxiv_id": "2408.01188v2",
    "title": "Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems",
    "authors": [
      "Juan C. Rosero",
      "Ivana Dusparic",
      "Nicolás Cardozo"
    ],
    "abstract": "Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as\nit enables learning at runtime without the need for a model of the environment\nor predefined actions. However, most applications of RL in AS, such as those\nbased on Q-learning, can only optimize one objective, making it necessary in\nmulti-objective systems to combine multiple objectives in a single objective\nfunction with predefined weights. A number of Multi-Objective Reinforcement\nLearning (MORL) techniques exist but they have mostly been applied in RL\nbenchmarks rather than real-world AS systems. In this work, we use a MORL\ntechnique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers\nexemplar, a self-adaptive server, to find the optimal configuration for runtime\nperformance optimization. We compare DWN to two single-objective optimization\nimplementations: {\\epsilon}-greedy algorithm and Deep Q-Networks. Our initial\nevaluation shows that DWN optimizes multiple objectives simultaneously with\nsimilar results than DQN and {\\epsilon}-greedy approaches, having a better\nperformance for some metrics, and avoids issues associated with combining\nmultiple objectives into a single utility function.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "pages, Accepted to AI4AS 2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2408.01188v2",
    "published_date": "2024-08-02 11:16:09 UTC",
    "updated_date": "2024-09-30 13:15:14 UTC"
  },
  {
    "arxiv_id": "2408.01187v1",
    "title": "Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning",
    "authors": [
      "Michael Kölle",
      "Daniel Seidl",
      "Maximilian Zorn",
      "Philipp Altmann",
      "Jonas Stein",
      "Thomas Gabor"
    ],
    "abstract": "Quantum Reinforcement Learning (QRL) offers potential advantages over\nclassical Reinforcement Learning, such as compact state space representation\nand faster convergence in certain scenarios. However, practical benefits\nrequire further validation. QRL faces challenges like flat solution landscapes,\nwhere traditional gradient-based methods are inefficient, necessitating the use\nof gradient-free algorithms. This work explores the integration of\nmetaheuristic algorithms -- Particle Swarm Optimization, Ant Colony\nOptimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony\nSearch -- into QRL. These algorithms provide flexibility and efficiency in\nparameter optimization. Evaluations in $5\\times5$ MiniGrid Reinforcement\nLearning environments show that, all algorithms yield near-optimal results,\nwith Simulated Annealing and Particle Swarm Optimization performing best. In\nthe Cart Pole environment, Simulated Annealing, Genetic Algorithms, and\nParticle Swarm Optimization achieve optimal results, while the others perform\nslightly better than random action selection. These findings demonstrate the\npotential of Particle Swarm Optimization and Simulated Annealing for efficient\nQRL learning, emphasizing the need for careful algorithm selection and\nadaptation.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted at QCE24 - QCRL24 Workshop",
    "pdf_url": "http://arxiv.org/pdf/2408.01187v1",
    "published_date": "2024-08-02 11:14:41 UTC",
    "updated_date": "2024-08-02 11:14:41 UTC"
  },
  {
    "arxiv_id": "2408.01168v1",
    "title": "Misinforming LLMs: vulnerabilities, challenges and opportunities",
    "authors": [
      "Bo Zhou",
      "Daniel Geißler",
      "Paul Lukowicz"
    ],
    "abstract": "Large Language Models (LLMs) have made significant advances in natural\nlanguage processing, but their underlying mechanisms are often misunderstood.\nDespite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely\non statistical patterns in word embeddings rather than true cognitive\nprocesses. This leads to vulnerabilities such as \"hallucination\" and\nmisinformation. The paper argues that current LLM architectures are inherently\nuntrustworthy due to their reliance on correlations of sequential patterns of\nword embedding vectors. However, ongoing research into combining generative\ntransformer-based models with fact bases and logic programming languages may\nlead to the development of trustworthy LLMs capable of generating statements\nbased on given truth and explaining their self-reasoning process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01168v1",
    "published_date": "2024-08-02 10:35:49 UTC",
    "updated_date": "2024-08-02 10:35:49 UTC"
  },
  {
    "arxiv_id": "2408.01156v1",
    "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
    "authors": [
      "Yicheng Lin",
      "Dandan Zhang",
      "Yun Liu"
    ],
    "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01156v1",
    "published_date": "2024-08-02 10:16:28 UTC",
    "updated_date": "2024-08-02 10:16:28 UTC"
  },
  {
    "arxiv_id": "2408.01154v1",
    "title": "DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs",
    "authors": [
      "Zhichun Wang",
      "Xuan Chen"
    ],
    "abstract": "Entity Alignment (EA) aims to match equivalent entities in different\nKnowledge Graphs (KGs), which is essential for knowledge fusion and\nintegration. Recently, embedding-based EA has attracted significant attention\nand many approaches have been proposed. Early approaches primarily focus on\nlearning entity embeddings from the structural features of KGs, defined by\nrelation triples. Later methods incorporated entities' names and attributes as\nauxiliary information to enhance embeddings for EA. However, these approaches\noften used different techniques to encode structural and attribute information,\nlimiting their interaction and mutual enhancement. In this work, we propose a\ndense entity retrieval framework for EA, leveraging language models to\nuniformly encode various features of entities and facilitate nearest entity\nsearch across KGs. Alignment candidates are first generated through entity\nretrieval, which are subsequently reranked to determine the final alignments.\nWe conduct comprehensive experiments on both cross-lingual and monolingual EA\ndatasets, demonstrating that our approach achieves state-of-the-art performance\ncompared to existing EA methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01154v1",
    "published_date": "2024-08-02 10:12:42 UTC",
    "updated_date": "2024-08-02 10:12:42 UTC"
  },
  {
    "arxiv_id": "2408.01139v2",
    "title": "Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition",
    "authors": [
      "Róisín Luo",
      "James McDermott",
      "Colm O'Riordan"
    ],
    "abstract": "Perturbation robustness evaluates the vulnerabilities of models, arising from\na variety of perturbations, such as data corruptions and adversarial attacks.\nUnderstanding the mechanisms of perturbation robustness is critical for global\ninterpretability. We present a model-agnostic, global mechanistic\ninterpretability method to interpret the perturbation robustness of image\nmodels. This research is motivated by two key aspects. First, previous global\ninterpretability works, in tandem with robustness benchmarks, e.g. mean\ncorruption error (mCE), are not designed to directly interpret the mechanisms\nof perturbation robustness within image models. Second, we notice that the\nspectral signal-to-noise ratios (SNR) of perturbed natural images exponentially\ndecay over the frequency. This power-law-like decay implies that: Low-frequency\nsignals are generally more robust than high-frequency signals -- yet high\nclassification accuracy can not be achieved by low-frequency signals alone. By\napplying Shapley value theory, our method axiomatically quantifies the\npredictive powers of robust features and non-robust features within an\ninformation theory framework. Our method, dubbed as \\textbf{I-ASIDE}\n(\\textbf{I}mage \\textbf{A}xiomatic \\textbf{S}pectral \\textbf{I}mportance\n\\textbf{D}ecomposition \\textbf{E}xplanation), provides a unique insight into\nmodel robustness mechanisms. We conduct extensive experiments over a variety of\nvision models pre-trained on ImageNet to show that \\textbf{I-ASIDE} can not\nonly \\textbf{measure} the perturbation robustness but also \\textbf{provide\ninterpretations} of its mechanisms.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by Transactions on Machine Learning Research (TMLR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.01139v2",
    "published_date": "2024-08-02 09:35:06 UTC",
    "updated_date": "2024-08-18 17:13:31 UTC"
  },
  {
    "arxiv_id": "2408.01129v5",
    "title": "A Survey of Mamba",
    "authors": [
      "Haohao Qu",
      "Liangbo Ning",
      "Rui An",
      "Wenqi Fan",
      "Tyler Derr",
      "Hui Liu",
      "Xin Xu",
      "Qing Li"
    ],
    "abstract": "As one of the most representative DL techniques, Transformer architecture has\nempowered numerous advanced models, especially the large language models (LLMs)\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space models\n(SSMs), has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering three main aspects:\nthe advancements of Mamba-based models, the techniques of adapting Mamba to\ndiverse data, and the applications where Mamba can excel. Specifically, we\nfirst review the foundational knowledge of various representative deep learning\nmodels and the details of Mamba-1&2 as preliminaries. Then, to showcase the\nsignificance of Mamba for AI, we comprehensively review the related studies\nfocusing on Mamba models' architecture design, data adaptability, and\napplications. Finally, we present a discussion of current limitations and\nexplore various promising research directions to provide deeper insights for\nfuture investigations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01129v5",
    "published_date": "2024-08-02 09:18:41 UTC",
    "updated_date": "2024-12-13 06:16:06 UTC"
  },
  {
    "arxiv_id": "2408.01121v1",
    "title": "Being Accountable is Smart: Navigating the Technical and Regulatory Landscape of AI-based Services for Power Grid",
    "authors": [
      "Anna Volkova",
      "Mahdieh Hatamian",
      "Alina Anapyanova",
      "Hermann de Meer"
    ],
    "abstract": "The emergence of artificial intelligence and digitization of the power grid\nintroduced numerous effective application scenarios for AI-based services for\nthe smart grid. Nevertheless, adopting AI in critical infrastructures presents\nchallenges due to unclear regulations and lacking risk quantification\ntechniques. Regulated and accountable approaches for integrating AI-based\nservices into the smart grid could accelerate the adoption of innovative\nmethods in daily practices and address society's general safety concerns. This\npaper contributes to this objective by defining accountability and highlighting\nits importance for AI-based services in the energy sector. It underlines the\ncurrent shortcomings of the AI Act and proposes an approach to address these\nissues in a potential delegated act. The proposed technical approach for\ndeveloping and operating accountable AI-based smart grid services allows for\nassessing different service life cycle phases and identifying related\naccountability risks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Author's version of the paper for International Conference on\n  Information Technology for Social Good (GoodIT '24), September 4--6, 2024,\n  Bremen, Germany. It is posted here for your personal use. Not for\n  redistribution",
    "pdf_url": "http://arxiv.org/pdf/2408.01121v1",
    "published_date": "2024-08-02 09:02:42 UTC",
    "updated_date": "2024-08-02 09:02:42 UTC"
  },
  {
    "arxiv_id": "2408.01107v2",
    "title": "BioRAG: A RAG-LLM Framework for Biological Question Reasoning",
    "authors": [
      "Chengrui Wang",
      "Qingqing Long",
      "Meng Xiao",
      "Xunxin Cai",
      "Chengjun Wu",
      "Zhen Meng",
      "Xuezhi Wang",
      "Yuanchun Zhou"
    ],
    "abstract": "The question-answering system for Life science research, which is\ncharacterized by the rapid pace of discovery, evolving insights, and complex\ninteractions among knowledge entities, presents unique challenges in\nmaintaining a comprehensive knowledge warehouse and accurate information\nretrieval. To address these issues, we introduce BioRAG, a novel\nRetrieval-Augmented Generation (RAG) with the Large Language Models (LLMs)\nframework. Our approach starts with parsing, indexing, and segmenting an\nextensive collection of 22 million scientific papers as the basic knowledge,\nfollowed by training a specialized embedding model tailored to this domain.\nAdditionally, we enhance the vector retrieval process by incorporating a\ndomain-specific knowledge hierarchy, which aids in modeling the intricate\ninterrelationships among each query and context. For queries requiring the most\ncurrent information, BioRAG deconstructs the question and employs an iterative\nretrieval process incorporated with the search engine for step-by-step\nreasoning. Rigorous experiments have demonstrated that our model outperforms\nfine-tuned LLM, LLM with search engines, and other scientific RAG frameworks\nacross multiple life science question-answering tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01107v2",
    "published_date": "2024-08-02 08:37:03 UTC",
    "updated_date": "2024-08-14 09:54:24 UTC"
  },
  {
    "arxiv_id": "2408.01099v1",
    "title": "Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration",
    "authors": [
      "Donwon Park",
      "Hayeon Kim",
      "Se Young Chun"
    ],
    "abstract": "Recently, pre-trained model and efficient parameter tuning have achieved\nremarkable success in natural language processing and high-level computer\nvision with the aid of masked modeling and prompt tuning. In low-level computer\nvision, however, there have been limited investigations on pre-trained models\nand even efficient fine-tuning strategy has not yet been explored despite its\nimportance and benefit in various real-world tasks such as alleviating memory\ninflation issue when integrating new tasks on AI edge devices. Here, we propose\na novel efficient parameter tuning approach dubbed contribution-based low-rank\nadaptation (CoLoRA) for multiple image restorations along with effective\npre-training method with random order degradations (PROD). Unlike prior arts\nthat tune all network parameters, our CoLoRA effectively fine-tunes small\namount of parameters by leveraging LoRA (low-rank adaptation) for each new\nvision task with our contribution-based method to adaptively determine layer by\nlayer capacity for that task to yield comparable performance to full tuning.\nFurthermore, our PROD strategy allows to extend the capability of pre-trained\nmodels with improved performance as well as robustness to bridge synthetic\npre-training and real-world fine-tuning. Our CoLoRA with PROD has demonstrated\nits superior performance in various image restoration tasks across diverse\ndegradation types on both synthetic and real-world datasets for known and novel\ntasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "33 pages, 15 figures, for homepage see this url :\n  https://janeyeon.github.io/colora/",
    "pdf_url": "http://arxiv.org/pdf/2408.01099v1",
    "published_date": "2024-08-02 08:24:05 UTC",
    "updated_date": "2024-08-02 08:24:05 UTC"
  },
  {
    "arxiv_id": "2408.02685v1",
    "title": "Artificial Neural Networks for Photonic Applications: From Algorithms to Implementation",
    "authors": [
      "Pedro Freire",
      "Egor Manuylovich",
      "Jaroslaw E. Prilepsky",
      "Sergei K. Turitsy"
    ],
    "abstract": "This tutorial-review on applications of artificial neural networks in\nphotonics targets a broad audience, ranging from optical research and\nengineering communities to computer science and applied mathematics. We focus\nhere on the research areas at the interface between these disciplines,\nattempting to find the right balance between technical details specific to each\ndomain and overall clarity. First, we briefly recall key properties and\npeculiarities of some core neural network types, which we believe are the most\nrelevant to photonics, also linking the layer's theoretical design to some\nphotonics hardware realizations. After that, we elucidate the question of how\nto fine-tune the selected model's design to perform the required task with\noptimized accuracy. Then, in the review part, we discuss recent developments\nand progress for several selected applications of neural networks in photonics,\nincluding multiple aspects relevant to optical communications, imaging,\nsensing, and the design of new materials and lasers. In the following section,\nwe put a special emphasis on how to accurately evaluate the complexity of\nneural networks in the context of the transition from algorithms to hardware\nimplementation. The introduced complexity characteristics are used to analyze\nthe applications of neural networks in optical communications, as a specific,\nalbeit highly important example, comparing those with some benchmark signal\nprocessing methods. We combine the description of the well-known model\ncompression strategies used in machine learning, with some novel techniques\nintroduced recently in optical applications of neural networks. It is important\nto stress that although our focus in this tutorial-review is on photonics, we\nbelieve that the methods and techniques presented here can be handy in a much\nwider range of scientific and engineering applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "physics.optics"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02685v1",
    "published_date": "2024-08-02 08:22:49 UTC",
    "updated_date": "2024-08-02 08:22:49 UTC"
  },
  {
    "arxiv_id": "2408.01096v1",
    "title": "Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding",
    "authors": [
      "Danbinaerin Han",
      "Mark Gotham",
      "Dongmin Kim",
      "Hannah Park",
      "Sihun Lee",
      "Dasaem Jeong"
    ],
    "abstract": "We introduce a project that revives a piece of 15th-century Korean court\nmusic, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the\nDragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean\nmusical notation system, the remaining version only consists of a rudimentary\nmelody. Our research team, commissioned by the National Gugak (Korean\nTraditional Music) Center, aimed to transform this old melody into a\nperformable arrangement for a six-part ensemble. Using Jeongganbo data acquired\nthrough bespoke optical music recognition, we trained a BERT-like masked\nlanguage model and an encoder-decoder transformer model. We also propose an\nencoding scheme that strictly follows the structure of Jeongganbo and denotes\nnote durations as positions. The resulting machine-transformed version of\nChihwapyeong and Chwipunghyeong were evaluated by experts and performed by the\nCourt Music Orchestra of National Gugak Center. Our work demonstrates that\ngenerative models can successfully be applied to traditional music with limited\ntraining data if combined with careful design.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at the 25th International Society for Music Information\n  Retrieval Conference (ISMIR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.01096v1",
    "published_date": "2024-08-02 08:16:55 UTC",
    "updated_date": "2024-08-02 08:16:55 UTC"
  },
  {
    "arxiv_id": "2408.01091v2",
    "title": "Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions",
    "authors": [
      "Jin Gao",
      "Lei Gan",
      "Yuankai Li",
      "Yixin Ye",
      "Dequan Wang"
    ],
    "abstract": "Large multimodal models (LMMs) excel in adhering to human instructions.\nHowever, self-contradictory instructions may arise due to the increasing trend\nof multimodal interaction and context length, which is challenging for language\nbeginners and vulnerable populations. We introduce the Self-Contradictory\nInstructions benchmark to evaluate the capability of LMMs in recognizing\nconflicting commands. It comprises 20,000 conflicts, evenly distributed between\nlanguage and vision paradigms. It is constructed by a novel automatic dataset\ncreation framework, which expedites the process and enables us to encompass a\nwide range of instruction forms. Our comprehensive evaluation reveals current\nLMMs consistently struggle to identify multimodal instruction discordance due\nto a lack of self-awareness. Hence, we propose the Cognitive Awakening\nPrompting to inject cognition from external, largely enhancing dissonance\ndetection. The dataset and code are here: https://selfcontradiction.github.io/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by the 18th European Conference on Computer Vision ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.01091v2",
    "published_date": "2024-08-02 08:11:11 UTC",
    "updated_date": "2024-08-05 06:56:44 UTC"
  },
  {
    "arxiv_id": "2408.01075v1",
    "title": "The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic Purposes",
    "authors": [
      "Jasper Roe",
      "Mike Perkins",
      "Yulia Tregubova"
    ],
    "abstract": "The rapid advancement of Generative Artificial Intelligence (GenAI) presents\nboth opportunities and challenges for English for Academic Purposes (EAP)\ninstruction. This paper proposes an adaptation of the AI Assessment Scale\n(AIAS) specifically tailored for EAP contexts, termed the EAP-AIAS.\n  This framework aims to provide a structured approach for integrating GenAI\ntools into EAP assessment practices while maintaining academic integrity and\nsupporting language development. The EAP-AIAS consists of five levels, ranging\nfrom \"No AI\" to \"Full AI\", each delineating appropriate GenAI usage in EAP\ntasks. We discuss the rationale behind this adaptation, considering the unique\nneeds of language learners and the dual focus of EAP on language proficiency\nand academic acculturation.\n  This paper explores potential applications of the EAP-AIAS across various EAP\nassessment types, including writing tasks, presentations, and research\nprojects. By offering a flexible framework, the EAP-AIAS seeks to empower EAP\npractitioners seeking to deal with the complexities of GenAI integration in\neducation and prepare students for an AI-enhanced academic and professional\nfuture. This adaptation represents a step towards addressing the pressing need\nfor ethical and pedagogically sound AI integration in language education.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01075v1",
    "published_date": "2024-08-02 07:51:29 UTC",
    "updated_date": "2024-08-02 07:51:29 UTC"
  },
  {
    "arxiv_id": "2408.01072v3",
    "title": "A Survey on Self-play Methods in Reinforcement Learning",
    "authors": [
      "Ruize Zhang",
      "Zelai Xu",
      "Chengdong Ma",
      "Chao Yu",
      "Wei-Wei Tu",
      "Wenhao Tang",
      "Shiyu Huang",
      "Deheng Ye",
      "Wenbo Ding",
      "Yaodong Yang",
      "Yu Wang"
    ],
    "abstract": "Self-play, characterized by agents' interactions with copies or past versions\nof themselves, has recently gained prominence in reinforcement learning (RL).\nThis paper first clarifies the preliminaries of self-play, including the\nmulti-agent reinforcement learning framework and basic game theory concepts.\nThen, it provides a unified framework and classifies existing self-play\nalgorithms within this framework. Moreover, the paper bridges the gap between\nthe algorithms and their practical implications by illustrating the role of\nself-play in different scenarios. Finally, the survey highlights open\nchallenges and future research directions in self-play. This paper is an\nessential guide map for understanding the multifaceted landscape of self-play\nin RL.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01072v3",
    "published_date": "2024-08-02 07:47:51 UTC",
    "updated_date": "2025-03-27 13:42:00 UTC"
  },
  {
    "arxiv_id": "2408.01055v1",
    "title": "LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems",
    "authors": [
      "Zhensu Sun",
      "Haotian Zhu",
      "Bowen Xu",
      "Xiaoning Du",
      "Li Li",
      "David Lo"
    ],
    "abstract": "Unanticipated runtime errors, lacking predefined handlers, can abruptly\nterminate execution and lead to severe consequences, such as data loss or\nsystem crashes. Despite extensive efforts to identify potential errors during\nthe development phase, such unanticipated errors remain a challenge to to be\nentirely eliminated, making the runtime mitigation measurements still\nindispensable to minimize their impact. Automated self-healing techniques, such\nas reusing existing handlers, have been investigated to reduce the loss coming\nthrough with the execution termination. However, the usability of existing\nmethods is retained by their predefined heuristic rules and they fail to handle\ndiverse runtime errors adaptively. Recently, the advent of Large Language\nModels (LLMs) has opened new avenues for addressing this problem. Inspired by\ntheir remarkable capabilities in understanding and generating code, we propose\nto deal with the runtime errors in a real-time manner using LLMs.\n  Specifically, we propose Healer, the first LLM-assisted self-healing\nframework for handling runtime errors. When an unhandled runtime error occurs,\nHealer will be activated to generate a piece of error-handling code with the\nhelp of its internal LLM and the code will be executed inside the runtime\nenvironment owned by the framework to obtain a rectified program state from\nwhich the program should continue its execution. Our exploratory study\nevaluates the performance of Healer using four different code benchmarks and\nthree state-of-the-art LLMs, GPT-3.5, GPT-4, and CodeQwen-7B. Results show\nthat, without the need for any fine-tuning, GPT-4 can successfully help\nprograms recover from 72.8% of runtime errors, highlighting the potential of\nLLMs in handling runtime errors.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01055v1",
    "published_date": "2024-08-02 07:03:00 UTC",
    "updated_date": "2024-08-02 07:03:00 UTC"
  },
  {
    "arxiv_id": "2408.01051v1",
    "title": "From Stem to Stern: Contestability Along AI Value Chains",
    "authors": [
      "Agathe Balayn",
      "Yulu Pi",
      "David Gray Widder",
      "Kars Alfrink",
      "Mireia Yurrita",
      "Sohini Upadhyay",
      "Naveena Karusala",
      "Henrietta Lyons",
      "Cagatay Turkay",
      "Christelle Tessono",
      "Blair Attard-Frost",
      "Ujwal Gadiraju"
    ],
    "abstract": "This workshop will grow and consolidate a community of interdisciplinary CSCW\nresearchers focusing on the topic of contestable AI. As an outcome of the\nworkshop, we will synthesize the most pressing opportunities and challenges for\ncontestability along AI value chains in the form of a research roadmap. This\nroadmap will help shape and inspire imminent work in this field. Considering\nthe length and depth of AI value chains, it will especially spur discussions\naround the contestability of AI systems along various sites of such chains. The\nworkshop will serve as a platform for dialogue and demonstrations of concrete,\nsuccessful, and unsuccessful examples of AI systems that (could or should) have\nbeen contested, to identify requirements, obstacles, and opportunities for\ndesigning and deploying contestable AI in various contexts. This will be held\nprimarily as an in-person workshop, with some hybrid accommodation. The day\nwill consist of individual presentations and group activities to stimulate\nideation and inspire broad reflections on the field of contestable AI. Our aim\nis to facilitate interdisciplinary dialogue by bringing together researchers,\npractitioners, and stakeholders to foster the design and deployment of\ncontestable AI.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 0 figure, to be held as a workshop at CSCW'24",
    "pdf_url": "http://arxiv.org/pdf/2408.01051v1",
    "published_date": "2024-08-02 06:57:52 UTC",
    "updated_date": "2024-08-02 06:57:52 UTC"
  },
  {
    "arxiv_id": "2408.01024v2",
    "title": "Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments",
    "authors": [
      "Sangwoo Shin",
      "Seunghyun Kim",
      "Youngsoo Jang",
      "Moontae Lee",
      "Honguk Woo"
    ],
    "abstract": "In embodied instruction-following (EIF), the integration of pretrained\nlanguage models (LMs) as task planners emerges as a significant branch, where\ntasks are planned at the skill level by prompting LMs with pretrained skills\nand user instructions. However, grounding these pretrained skills in different\ndomains remains challenging due to their intricate entanglement with the\ndomain-specific knowledge. To address this challenge, we present a semantic\nskill grounding (SemGro) framework that leverages the hierarchical nature of\nsemantic skills. SemGro recognizes the broad spectrum of these skills, ranging\nfrom short-horizon low-semantic skills that are universally applicable across\ndomains to long-horizon rich-semantic skills that are highly specialized and\ntailored for particular domains. The framework employs an iterative skill\ndecomposition approach, starting from the higher levels of semantic skill\nhierarchy and then moving downwards, so as to ground each planned skill to an\nexecutable level within the target domain. To do so, we use the reasoning\ncapabilities of LMs for composing and decomposing semantic skills, as well as\ntheir multi-modal extension for assessing the skill feasibility in the target\ndomain. Our experiments in the VirtualHome benchmark show the efficacy of\nSemGro in 300 cross-domain EIF scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Findings of ACL-2024 Camera Ready Version",
    "pdf_url": "http://arxiv.org/pdf/2408.01024v2",
    "published_date": "2024-08-02 05:50:31 UTC",
    "updated_date": "2024-08-21 01:46:36 UTC"
  },
  {
    "arxiv_id": "2408.01018v4",
    "title": "GNN-SKAN: Harnessing the Power of SwallowKAN to Advance Molecular Representation Learning with GNNs",
    "authors": [
      "Ruifeng Li",
      "Mingqian Li",
      "Wei Liu",
      "Hongyang Chen"
    ],
    "abstract": "Effective molecular representation learning is crucial for advancing\nmolecular property prediction and drug design. Mainstream molecular\nrepresentation learning approaches are based on Graph Neural Networks (GNNs).\nHowever, these approaches struggle with three significant challenges:\ninsufficient annotations, molecular diversity, and architectural limitations\nsuch as over-squashing, which leads to the loss of critical structural details.\nTo address these challenges, we introduce a new class of GNNs that integrates\nthe Kolmogorov-Arnold Networks (KANs), known for their robust data-fitting\ncapabilities and high accuracy in small-scale AI + Science tasks. By\nincorporating KANs into GNNs, our model enhances the representation of\nmolecular structures. We further advance this approach with a variant called\nSwallowKAN (SKAN), which employs adaptive Radial Basis Functions (RBFs) as the\ncore of the non-linear neurons. This innovation improves both computational\nefficiency and adaptability to diverse molecular structures. Building on the\nstrengths of SKAN, we propose a new class of GNNs, GNN-SKAN, and its augmented\nvariant, GNN-SKAN+, which incorporates a SKAN-based classifier to further boost\nperformance. To our knowledge, this is the first work to integrate KANs into\nGNN architectures tailored for molecular representation learning. Experiments\nacross 6 classification datasets, 6 regression datasets, and 4 few-shot\nlearning datasets demonstrate that our approach achieves new state-of-the-art\nperformance in terms of accuracy and computational cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T99",
      "J.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01018v4",
    "published_date": "2024-08-02 05:36:14 UTC",
    "updated_date": "2024-11-09 14:22:03 UTC"
  },
  {
    "arxiv_id": "2408.01016v1",
    "title": "IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model",
    "authors": [
      "Eren Olug",
      "Kiymet Kaya",
      "Resul Tugay",
      "Sule Gunduz Oguducu"
    ],
    "abstract": "Road traffic congestion prediction is a crucial component of intelligent\ntransportation systems, since it enables proactive traffic management, enhances\nsuburban experience, reduces environmental impact, and improves overall safety\nand efficiency. Although there are several public datasets, especially for\nmetropolitan areas, these datasets may not be applicable to practical scenarios\ndue to insufficiency in the scale of data (i.e. number of sensors and road\nlinks) and several external factors like different characteristics of the\ntarget area such as urban, highways and the data collection location. To\naddress this, this paper introduces a novel IBB Traffic graph dataset as an\nalternative benchmark dataset to mitigate these limitations and enrich the\nliterature with new geographical characteristics. IBB Traffic graph dataset\ncovers the sensor data collected at 2451 distinct locations. Moreover, we\npropose a novel Road Traffic Prediction Model that strengthens temporal links\nthrough feature engineering, node embedding with GLEE to represent\ninter-related relationships within the traffic network, and traffic prediction\nwith ExtraTrees. The results indicate that the proposed model consistently\noutperforms the baseline models, demonstrating an average accuracy improvement\nof 4%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.01016v1",
    "published_date": "2024-08-02 05:23:19 UTC",
    "updated_date": "2024-08-02 05:23:19 UTC"
  },
  {
    "arxiv_id": "2408.01008v1",
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": [
      "Afia Anjum",
      "Maksim E. Eren",
      "Ismael Boureima",
      "Boian Alexandrov",
      "Manish Bhattarai"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "LA-UR-24-28177",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "published_date": "2024-08-02 04:45:58 UTC",
    "updated_date": "2024-08-02 04:45:58 UTC"
  },
  {
    "arxiv_id": "2408.01003v1",
    "title": "Piculet: Specialized Models-Guided Hallucination Decrease for MultiModal Large Language Models",
    "authors": [
      "Kohou Wang",
      "Xiang Liu",
      "Zhaoxiang Liu",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have made significant progress in\nbridging the gap between visual and language modalities. However,\nhallucinations in MLLMs, where the generated text does not align with image\ncontent, continue to be a major challenge. Existing methods for addressing\nhallucinations often rely on instruction-tuning, which requires retraining the\nmodel with specific data, which increases the cost of utilizing MLLMs further.\nIn this paper, we introduce a novel training-free method, named Piculet, for\nenhancing the input representation of MLLMs. Piculet leverages multiple\nspecialized models to extract descriptions of visual information from the input\nimage and combine these descriptions with the original image and query as input\nto the MLLM. We evaluate our method both quantitively and qualitatively, and\nthe results demonstrate that Piculet greatly decreases hallucinations of MLLMs.\nOur method can be easily extended to different MLLMs while being universal.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.01003v1",
    "published_date": "2024-08-02 04:34:37 UTC",
    "updated_date": "2024-08-02 04:34:37 UTC"
  },
  {
    "arxiv_id": "2408.00998v2",
    "title": "FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation",
    "authors": [
      "Xiang Gao",
      "Jiaying Liu"
    ],
    "abstract": "Large-scale text-to-image diffusion models have been a revolutionary\nmilestone in the evolution of generative AI and multimodal technology, allowing\nwonderful image generation with natural-language text prompt. However, the\nissue of lacking controllability of such models restricts their practical\napplicability for real-life content creation. Thus, attention has been focused\non leveraging a reference image to control text-to-image synthesis, which is\nalso regarded as manipulating (or editing) a reference image as per a text\nprompt, namely, text-driven image-to-image translation. This paper contributes\na novel, concise, and efficient approach that adapts pre-trained large-scale\ntext-to-image (T2I) diffusion model to the image-to-image (I2I) paradigm in a\nplug-and-play manner, realizing high-quality and versatile text-driven I2I\ntranslation without any model training, model fine-tuning, or online\noptimization process. To guide T2I generation with a reference image, we\npropose to decompose diverse guiding factors with different frequency bands of\ndiffusion features in the DCT spectral space, and accordingly devise a novel\nfrequency band substitution layer which realizes dynamic control of the\nreference image to the T2I generation result in a plug-and-play manner. We\ndemonstrate that our method allows flexible control over both guiding factor\nand guiding intensity of the reference image simply by tuning the type and\nbandwidth of the substituted frequency band, respectively. Extensive\nqualitative and quantitative experiments verify superiority of our approach\nover related methods in I2I translation visual quality, versatility, and\ncontrollability. The code is publicly available at:\nhttps://github.com/XiangGao1102/FBSDiff.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted conference paper of ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00998v2",
    "published_date": "2024-08-02 04:13:38 UTC",
    "updated_date": "2024-08-06 12:01:17 UTC"
  },
  {
    "arxiv_id": "2408.00997v1",
    "title": "A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments",
    "authors": [
      "Erfan Entezami",
      "Mahsa Sahebdel",
      "Dhawal Gupta"
    ],
    "abstract": "Training a model-free reinforcement learning agent requires allowing the\nagent to sufficiently explore the environment to search for an optimal policy.\nIn safety-constrained environments, utilizing unsupervised exploration or a\nnon-optimal policy may lead the agent to undesirable states, resulting in\noutcomes that are potentially costly or hazardous for both the agent and the\nenvironment. In this paper, we introduce a new exploration framework for\nnavigating the grid environments that enables model-free agents to interact\nwith the environment while adhering to safety constraints. Our framework\nincludes a pre-training phase, during which the agent learns to identify\npotentially unsafe states based on both observable features and specified\nsafety constraints in the environment. Subsequently, a binary classification\nmodel is trained to predict those unsafe states in new environments that\nexhibit similar dynamics. This trained classifier empowers model-free agents to\ndetermine situations in which employing random exploration or a suboptimal\npolicy may pose safety risks, in which case our framework prompts the agent to\nfollow a predefined safe policy to mitigate the potential for hazardous\nconsequences. We evaluated our framework on three randomly generated grid\nenvironments and demonstrated how model-free agents can safely adapt to new\ntasks and learn optimal policies for new environments. Our results indicate\nthat by defining an appropriate safe policy and utilizing a well-trained model\nto detect unsafe states, our framework enables a model-free agent to adapt to\nnew tasks and environments with significantly fewer safety violations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00997v1",
    "published_date": "2024-08-02 04:09:30 UTC",
    "updated_date": "2024-08-02 04:09:30 UTC"
  },
  {
    "arxiv_id": "2408.00996v1",
    "title": "IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing",
    "authors": [
      "Sai Shashank Peddiraju",
      "Kaustubh Harapanahalli",
      "Edward Andert",
      "Aviral Shrivastava"
    ],
    "abstract": "Prior art in traffic incident detection relies on high sensor coverage and is\nprimarily based on decision-tree and random forest models that have limited\nrepresentation capacity and, as a result, cannot detect incidents with high\naccuracy. This paper presents IncidentNet - a novel approach for classifying,\nlocalizing, and estimating the severity of traffic incidents using deep\nlearning models trained on data captured from sparsely placed sensors in urban\nenvironments. Our model works on microscopic traffic data that can be collected\nusing cameras installed at traffic intersections. Due to the unavailability of\ndatasets that provide microscopic traffic details and traffic incident details\nsimultaneously, we also present a methodology to generate a synthetic\nmicroscopic traffic dataset that matches given macroscopic traffic data.\nIncidentNet achieves a traffic incident detection rate of 98%, with false alarm\nrates of less than 7% in 197 seconds on average in urban environments with\ncameras on less than 20% of the traffic intersections.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 6 figures, 2024 IEEE 27th International Conference on\n  Intelligent Transportation Systems (ITSC)",
    "pdf_url": "http://arxiv.org/pdf/2408.00996v1",
    "published_date": "2024-08-02 04:09:15 UTC",
    "updated_date": "2024-08-02 04:09:15 UTC"
  },
  {
    "arxiv_id": "2408.00994v1",
    "title": "ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models",
    "authors": [
      "Hojae Han",
      "Jaejin Kim",
      "Jaeseok Yoo",
      "Youngwon Lee",
      "Seung-won Hwang"
    ],
    "abstract": "This paper aims to extend the code generation capability of large language\nmodels (LLMs) to automatically manage comprehensive software requirements from\ngiven textual descriptions. Such requirements include both functional (i.e.\nachieving expected behavior for inputs) and non-functional (e.g., time/space\nperformance, robustness, maintainability) requirements. However, textual\ndescriptions can either express requirements verbosely or may even omit some of\nthem. We introduce ARCHCODE, a novel framework that leverages in-context\nlearning to organize requirements observed in descriptions and to extrapolate\nunexpressed requirements from them. ARCHCODE generates requirements from given\ndescriptions, conditioning them to produce code snippets and test cases. Each\ntest case is tailored to one of the requirements, allowing for the ranking of\ncode snippets based on the compliance of their execution results with the\nrequirements. Public benchmarks show that ARCHCODE enhances to satisfy\nfunctional requirements, significantly improving Pass@k scores. Furthermore, we\nintroduce HumanEval-NFR, the first evaluation of LLMs' non-functional\nrequirements in code generation, demonstrating ARCHCODE's superiority over\nbaseline methods. The implementation of ARCHCODE and the HumanEval-NFR\nbenchmark are both publicly accessible.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by ACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2408.00994v1",
    "published_date": "2024-08-02 03:54:36 UTC",
    "updated_date": "2024-08-02 03:54:36 UTC"
  },
  {
    "arxiv_id": "2408.00989v3",
    "title": "On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents",
    "authors": [
      "Jen-tse Huang",
      "Jiaxu Zhou",
      "Tailin Jin",
      "Xuhui Zhou",
      "Zixi Chen",
      "Wenxuan Wang",
      "Youliang Yuan",
      "Michael R. Lyu",
      "Maarten Sap"
    ],
    "abstract": "Large language model-based multi-agent systems have shown great abilities\nacross various tasks due to the collaboration of expert agents, each focusing\non a specific domain. However, the impact of clumsy or even malicious agents,\ni.e., those who frequently make errors in their tasks, on the overall\nperformance of the system remains underexplored. This paper investigates: (1)\nWhat is the resilience of various system structures (e.g.,\nA$\\rightarrow$B$\\rightarrow$C, A$\\leftrightarrow$B$\\leftrightarrow$C) under\nfaulty agents, on different downstream tasks? (2) How can we increase system\nresilience to defend against these agents? To simulate faulty agents, we\npropose two approaches, AutoTransform and AutoInject, which introduce mistakes\ninto the agents' responses. We select four downstream tasks, including code\ngeneration, math problems, translation, and text evaluation. Results suggest\nthat the hierarchical structure, i.e., A$\\rightarrow$(B$\\leftrightarrow$C),\nexhibits superior resilience with the lowest performance drop of $9.2\\%$,\ncompared to $26.0\\%$ and $31.2\\%$ of other two structures. Additionally, we\nimprove the system resilience with two methods, introducing a mechanism for\neach agent to challenge others' outputs, and an additional agent to review and\ncorrect messages. Our code and data are available at\nhttps://github.com/CUHK-ARISE/MAS-Resilience.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages of main text; 11 pages of appendix",
    "pdf_url": "http://arxiv.org/pdf/2408.00989v3",
    "published_date": "2024-08-02 03:25:20 UTC",
    "updated_date": "2025-01-28 07:45:50 UTC"
  },
  {
    "arxiv_id": "2408.00986v1",
    "title": "A SAT-based approach to rigorous verification of Bayesian networks",
    "authors": [
      "Ignacy Stępka",
      "Nicholas Gisolfi",
      "Artur Dubrawski"
    ],
    "abstract": "Recent advancements in machine learning have accelerated its widespread\nadoption across various real-world applications. However, in safety-critical\ndomains, the deployment of machine learning models is riddled with challenges\ndue to their complexity, lack of interpretability, and absence of formal\nguarantees regarding their behavior. In this paper, we introduce a verification\nframework tailored for Bayesian networks, designed to address these drawbacks.\nOur framework comprises two key components: (1) a two-step compilation and\nencoding scheme that translates Bayesian networks into Boolean logic literals,\nand (2) formal verification queries that leverage these literals to verify\nvarious properties encoded as constraints. Specifically, we introduce two\nverification queries: if-then rules (ITR) and feature monotonicity (FMO). We\nbenchmark the efficiency of our verification scheme and demonstrate its\npractical utility in real-world scenarios.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Workshop on Explainable and Robust AI for Industry 4.0 & 5.0 (X-RAI)\n  at European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.00986v1",
    "published_date": "2024-08-02 03:06:51 UTC",
    "updated_date": "2024-08-02 03:06:51 UTC"
  },
  {
    "arxiv_id": "2408.00965v2",
    "title": "Integrating ESG and AI: A Comprehensive Responsible AI Assessment Framework",
    "authors": [
      "Sung Une Lee",
      "Harsha Perera",
      "Yue Liu",
      "Boming Xia",
      "Qinghua Lu",
      "Liming Zhu",
      "Jessica Cairns",
      "Moana Nottage"
    ],
    "abstract": "Artificial Intelligence (AI) is a widely developed and adopted technology\nacross entire industry sectors. Integrating environmental, social, and\ngovernance (ESG) considerations with AI investments is crucial for ensuring\nethical and sustainable technological advancement. Particularly from an\ninvestor perspective, this integration not only mitigates risks but also\nenhances long-term value creation by aligning AI initiatives with broader\nsocietal goals. Yet, this area has been less explored in both academia and\nindustry. To bridge the gap, we introduce a novel ESG-AI framework, which is\ndeveloped based on insights from engagements with 28 companies and comprises\nthree key components. The framework provides a structured approach to this\nintegration, developed in collaboration with industry practitioners. The ESG-AI\nframework provides an overview of the environmental and social impacts of AI\napplications, helping users such as investors assess the materiality of AI use.\nMoreover, it enables investors to evaluate a company's commitment to\nresponsible AI through structured engagements and thorough assessment of\nspecific risk areas. We have publicly released the framework and toolkit in\nApril 2024, which has received significant attention and positive feedback from\nthe investment community. This paper details each component of the framework,\ndemonstrating its applicability in real-world contexts and its potential to\nguide ethical AI investments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 8 tables, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00965v2",
    "published_date": "2024-08-02 00:58:01 UTC",
    "updated_date": "2024-08-06 00:12:50 UTC"
  },
  {
    "arxiv_id": "2408.00960v1",
    "title": "PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting",
    "authors": [
      "Liam Hebert",
      "Krishna Sayana",
      "Ambarish Jash",
      "Alexandros Karatzoglou",
      "Sukhdeep Sodhi",
      "Sumanth Doddapaneni",
      "Yanli Cai",
      "Dima Kuzmin"
    ],
    "abstract": "Understanding the nuances of a user's extensive interaction history is key to\nbuilding accurate and personalized natural language systems that can adapt to\nevolving user preferences. To address this, we introduce PERSOMA, Personalized\nSoft Prompt Adapter architecture. Unlike previous personalized prompting\nmethods for large language models, PERSOMA offers a novel approach to\nefficiently capture user history. It achieves this by resampling and\ncompressing interactions as free form text into expressive soft prompt\nembeddings, building upon recent research utilizing embedding representations\nas input for LLMs. We rigorously validate our approach by evaluating various\nadapter architectures, first-stage sampling strategies, parameter-efficient\ntuning techniques like LoRA, and other personalization methods. Our results\ndemonstrate PERSOMA's superior ability to handle large and complex user\nhistories compared to existing embedding-based and text-prompt-based\ntechniques.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00960v1",
    "published_date": "2024-08-02 00:24:22 UTC",
    "updated_date": "2024-08-02 00:24:22 UTC"
  }
]