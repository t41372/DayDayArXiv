[
  {
    "arxiv_id": "2405.02771v2",
    "title": "MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial Representation Learning",
    "authors": [
      "Vishal Nedungadi",
      "Ankit Kariryaa",
      "Stefan Oehmcke",
      "Serge Belongie",
      "Christian Igel",
      "Nico Lang"
    ],
    "abstract": "The volume of unlabelled Earth observation (EO) data is huge, but many\nimportant applications lack labelled training data. However, EO data offers the\nunique opportunity to pair data from different modalities and sensors\nautomatically based on geographic location and time, at virtually no human\nlabor cost. We seize this opportunity to create MMEarth, a diverse multi-modal\npretraining dataset at global scale. Using this new corpus of 1.2 million\nlocations, we propose a Multi-Pretext Masked Autoencoder (MP-MAE) approach to\nlearn general-purpose representations for optical satellite images. Our\napproach builds on the ConvNeXt V2 architecture, a fully convolutional masked\nautoencoder (MAE). Drawing upon a suite of multi-modal pretext tasks, we\ndemonstrate that our MP-MAE approach outperforms both MAEs pretrained on\nImageNet and MAEs pretrained on domain-specific satellite images. This is shown\non several downstream tasks including image classification and semantic\nsegmentation. We find that pretraining with multi-modal pretext tasks notably\nimproves the linear probing performance compared to pretraining on optical\nsatellite images only. This also leads to better label efficiency and parameter\nefficiency which are crucial aspects in global scale applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for ECCV 2024. Data and code:\n  https://vishalned.github.io/mmearth Update arXiv v2 (ECCV): 1. Dataset fix:\n  Removed duplicates and corrected ERA5 yearly statistics. 2. Data augmentation\n  fix: Random crops are now aligned. 3. Test metrics fix: Metrics are now\n  overall instead of mini-batch averages, matching GEO-Bench metrics. 4.\n  Pretrained on MMEarth v001 & evaluated on GEO-Bench v1.0",
    "pdf_url": "http://arxiv.org/pdf/2405.02771v2",
    "published_date": "2024-05-04 23:16:48 UTC",
    "updated_date": "2024-07-29 10:35:50 UTC"
  },
  {
    "arxiv_id": "2405.09561v1",
    "title": "GAD: A Real-time Gait Anomaly Detection System with Online Adaptive Learning",
    "authors": [
      "Ming-Chang Lee",
      "Jia-Chun Lin",
      "Sokratis Katsikas"
    ],
    "abstract": "Gait anomaly detection is a task that involves detecting deviations from a\nperson's normal gait pattern. These deviations can indicate health issues and\nmedical conditions in the healthcare domain, or fraudulent impersonation and\nunauthorized identity access in the security domain. A number of gait anomaly\ndetection approaches have been introduced, but many of them require offline\ndata preprocessing, offline model learning, setting parameters, and so on,\nwhich might restrict their effectiveness and applicability in real-world\nscenarios. To address these issues, this paper introduces GAD, a real-time gait\nanomaly detection system. GAD focuses on detecting anomalies within an\nindividual's three-dimensional accelerometer readings based on dimensionality\nreduction and Long Short-Term Memory (LSTM). Upon being launched, GAD begins\ncollecting a gait segment from the user and training an anomaly detector to\nlearn the user's walking pattern on the fly. If the subsequent model\nverification is successful, which involves validating the trained detector\nusing the user's subsequent steps, the detector is employed to identify\nabnormalities in the user's subsequent gait readings at the user's request. The\nanomaly detector will be retained online to adapt to minor pattern changes and\nwill undergo retraining as long as it cannot provide adequate prediction. We\nexplored two methods for capturing users' gait segments: a personalized method\ntailored to each individual's step length, and a uniform method utilizing a\nfixed step length. Experimental results using an open-source gait dataset show\nthat GAD achieves a higher detection accuracy ratio when combined with the\npersonalized method.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "14 pages, 8 figures, 3 tables, ICT Systems Security and Privacy\n  Protection 39th IFIP TC 11 International Conference, SEC 2024, Edinburgh, UK,\n  June 12-14, 2024, Proceedings (IFIP SEC2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.09561v1",
    "published_date": "2024-05-04 22:43:09 UTC",
    "updated_date": "2024-05-04 22:43:09 UTC"
  },
  {
    "arxiv_id": "2405.02766v1",
    "title": "Beyond Unimodal Learning: The Importance of Integrating Multiple Modalities for Lifelong Learning",
    "authors": [
      "Fahad Sarfraz",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "abstract": "While humans excel at continual learning (CL), deep neural networks (DNNs)\nexhibit catastrophic forgetting. A salient feature of the brain that allows\neffective CL is that it utilizes multiple modalities for learning and\ninference, which is underexplored in DNNs. Therefore, we study the role and\ninteractions of multiple modalities in mitigating forgetting and introduce a\nbenchmark for multimodal continual learning. Our findings demonstrate that\nleveraging multiple views and complementary information from multiple\nmodalities enables the model to learn more accurate and robust representations.\nThis makes the model less vulnerable to modality-specific regularities and\nconsiderably mitigates forgetting. Furthermore, we observe that individual\nmodalities exhibit varying degrees of robustness to distribution shift.\nFinally, we propose a method for integrating and aligning the information from\ndifferent modalities by utilizing the relational structural similarities\nbetween the data points in each modality. Our method sets a strong baseline\nthat enables both single- and multimodal inference. Our study provides a\npromising case for further exploring the role of multiple modalities in\nenabling CL and provides a standard benchmark for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at 3rd Conference on Lifelong Learning Agents (CoLLAs), 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.02766v1",
    "published_date": "2024-05-04 22:02:58 UTC",
    "updated_date": "2024-05-04 22:02:58 UTC"
  },
  {
    "arxiv_id": "2405.02765v3",
    "title": "Has this Fact been Edited? Detecting Knowledge Edits in Language Models",
    "authors": [
      "Paul Youssef",
      "Zhixue Zhao",
      "Christin Seifert",
      "Jörg Schlötterer"
    ],
    "abstract": "Knowledge editing methods (KEs) can update language models' obsolete or\ninaccurate knowledge learned from pre-training. However, KEs can be used for\nmalicious applications, e.g., inserting misinformation and toxic content.\nKnowing whether a generated output is based on edited knowledge or first-hand\nknowledge from pre-training can increase users' trust in generative models and\nprovide more transparency. Driven by this, we propose a novel task: detecting\nedited knowledge in language models. Given an edited model and a fact retrieved\nby a prompt from an edited model, the objective is to classify the knowledge as\neither unedited (based on the pre-training), or edited (based on subsequent\nediting). We instantiate the task with four KEs, two LLMs, and two datasets.\nAdditionally, we propose using the hidden state representations and the\nprobability distributions as features for the detection. Our results reveal\nthat, using these features as inputs to a simple AdaBoost classifiers\nestablishes a strong baseline. This classifier requires only a limited amount\nof data and maintains its performance even in cross-domain settings. Last, we\nfind it more challenging to distinguish edited knowledge from unedited but\nrelated knowledge, highlighting the need for further research. Our work lays\nthe groundwork for addressing malicious model editing, which is a critical\nchallenge associated with the strong generative capabilities of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL Main 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.02765v3",
    "published_date": "2024-05-04 22:02:24 UTC",
    "updated_date": "2025-02-10 12:35:49 UTC"
  },
  {
    "arxiv_id": "2405.06676v1",
    "title": "EDA Corpus: A Large Language Model Dataset for Enhanced Interaction with OpenROAD",
    "authors": [
      "Bing-Yue Wu",
      "Utsav Sharma",
      "Sai Rahul Dhanvi Kankipati",
      "Ajay Yadav",
      "Bintu Kappil George",
      "Sai Ritish Guntupalli",
      "Austin Rovinski",
      "Vidya A. Chhabria"
    ],
    "abstract": "Large language models (LLMs) serve as powerful tools for design, providing\ncapabilities for both task automation and design assistance. Recent\nadvancements have shown tremendous potential for facilitating LLM integration\ninto the chip design process; however, many of these works rely on data that\nare not publicly available and/or not permissively licensed for use in LLM\ntraining and distribution. In this paper, we present a solution aimed at\nbridging this gap by introducing an open-source dataset tailored for OpenROAD,\na widely adopted open-source EDA toolchain. The dataset features over 1000 data\npoints and is structured in two formats: (i) a pairwise set comprised of\nquestion prompts with prose answers, and (ii) a pairwise set comprised of code\nprompts and their corresponding OpenROAD scripts. By providing this dataset, we\naim to facilitate LLM-focused research within the EDA domain. The dataset is\navailable at https://github.com/OpenROAD-Assistant/EDA-Corpus.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review at Workshop on LLM-Aided Design (LAD'24)",
    "pdf_url": "http://arxiv.org/pdf/2405.06676v1",
    "published_date": "2024-05-04 21:29:37 UTC",
    "updated_date": "2024-05-04 21:29:37 UTC"
  },
  {
    "arxiv_id": "2405.02754v1",
    "title": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning",
    "authors": [
      "Weiye Zhao",
      "Tairan He",
      "Feihan Li",
      "Changliu Liu"
    ],
    "abstract": "Deep reinforcement learning (DRL) has demonstrated remarkable performance in\nmany continuous control tasks. However, a significant obstacle to the\nreal-world application of DRL is the lack of safety guarantees. Although DRL\nagents can satisfy system safety in expectation through reward shaping,\ndesigning agents to consistently meet hard constraints (e.g., safety\nspecifications) at every time step remains a formidable challenge. In contrast,\nexisting work in the field of safe control provides guarantees on persistent\nsatisfaction of hard safety constraints. However, these methods require\nexplicit analytical system dynamics models to synthesize safe control, which\nare typically inaccessible in DRL settings. In this paper, we present a\nmodel-free safe control algorithm, the implicit safe set algorithm, for\nsynthesizing safeguards for DRL agents that ensure provable safety throughout\ntraining. The proposed algorithm synthesizes a safety index (barrier\ncertificate) and a subsequent safe control law solely by querying a black-box\ndynamic function (e.g., a digital twin simulator). Moreover, we theoretically\nprove that the implicit safe set algorithm guarantees finite time convergence\nto the safe set and forward invariance for both continuous-time and\ndiscrete-time systems. We validate the proposed algorithm on the\nstate-of-the-art Safety Gym benchmark, where it achieves zero safety violations\nwhile gaining $95\\% \\pm 9\\%$ cumulative reward compared to state-of-the-art\nsafe DRL methods. Furthermore, the resulting algorithm scales well to\nhigh-dimensional systems with parallel computing.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "submissions to Journal of Artificial Intelligence Research. arXiv\n  admin note: text overlap with arXiv:2308.13140",
    "pdf_url": "http://arxiv.org/pdf/2405.02754v1",
    "published_date": "2024-05-04 20:59:06 UTC",
    "updated_date": "2024-05-04 20:59:06 UTC"
  },
  {
    "arxiv_id": "2405.02750v1",
    "title": "Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding",
    "authors": [
      "Zheng Zhao",
      "Emilio Monti",
      "Jens Lehmann",
      "Haytham Assem"
    ],
    "abstract": "Large language models (LLMs) tend to inadequately integrate input context\nduring text generation, relying excessively on encoded prior knowledge in model\nparameters, potentially resulting in generated text with factual\ninconsistencies or contextually unfaithful content. LLMs utilize two primary\nknowledge sources: 1) prior (parametric) knowledge from pretraining, and 2)\ncontextual (non-parametric) knowledge from input prompts. The study addresses\nthe open question of how LLMs effectively balance these knowledge sources\nduring the generation process, specifically in the context of open-domain\nquestion answering. To address this issue, we introduce a novel approach\nintegrating contrastive decoding with adversarial irrelevant passages as\nnegative samples to enhance robust context grounding during generation.\nNotably, our method operates at inference time without requiring further\ntraining. We conduct comprehensive experiments to demonstrate its applicability\nand effectiveness, providing empirical evidence showcasing its superiority over\nexisting methodologies. Our code is publicly available at:\nhttps://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.02750v1",
    "published_date": "2024-05-04 20:38:41 UTC",
    "updated_date": "2024-05-04 20:38:41 UTC"
  },
  {
    "arxiv_id": "2405.02738v1",
    "title": "Relations Prediction for Knowledge Graph Completion using Large Language Models",
    "authors": [
      "Sakher Khalil Alqaaidi",
      "Krzysztof Kochut"
    ],
    "abstract": "Knowledge Graphs have been widely used to represent facts in a structured\nformat. Due to their large scale applications, knowledge graphs suffer from\nbeing incomplete. The relation prediction task obtains knowledge graph\ncompletion by assigning one or more possible relations to each pair of nodes.\nIn this work, we make use of the knowledge graph node names to fine-tune a\nlarge language model for the relation prediction task. By utilizing the node\nnames only we enable our model to operate sufficiently in the inductive\nsettings. Our experiments show that we accomplish new scores on a widely used\nknowledge graph benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02738v1",
    "published_date": "2024-05-04 19:04:51 UTC",
    "updated_date": "2024-05-04 19:04:51 UTC"
  },
  {
    "arxiv_id": "2405.03714v2",
    "title": "UniDEC : Unified Dual Encoder and Classifier Training for Extreme Multi-Label Classification",
    "authors": [
      "Siddhant Kharbanda",
      "Devaansh Gupta",
      "Gururaj K",
      "Pankaj Malhotra",
      "Amit Singh",
      "Cho-Jui Hsieh",
      "Rohit Babbar"
    ],
    "abstract": "Extreme Multi-label Classification (XMC) involves predicting a subset of\nrelevant labels from an extremely large label space, given an input query and\nlabels with textual features. Models developed for this problem have\nconventionally made use of dual encoder (DE) to embed the queries and label\ntexts and one-vs-all (OvA) classifiers to rerank the shortlisted labels by the\nDE. While such methods have shown empirical success, a major drawback is their\ncomputational cost, often requiring upto 16 GPUs to train on the largest public\ndataset. Such a high cost is a consequence of calculating the loss over the\nentire label space. While shortlisting strategies have been proposed for\nclassifiers, we aim to study such methods for the DE framework. In this work,\nwe develop UniDEC, a loss-independent, end-to-end trainable framework which\ntrains the DE and classifier together in a unified manner with a multi-class\nloss, while reducing the computational cost by 4-16x. This is done via the\nproposed pick-some-label (PSL) reduction, which aims to compute the loss on\nonly a subset of positive and negative labels. These labels are carefully\nchosen in-batch so as to maximise their supervisory signals. Not only does the\nproposed framework achieve state-of-the-art results on datasets with labels in\nthe order of millions, it is also computationally and resource efficient in\nachieving this performance on a single GPU. Code is made available at\nhttps://github.com/the-catalyst/UniDEC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03714v2",
    "published_date": "2024-05-04 17:27:51 UTC",
    "updated_date": "2025-03-03 19:29:02 UTC"
  },
  {
    "arxiv_id": "2405.02711v1",
    "title": "The Role of AI in Peer Support for Young People: A Study of Preferences for Human- and AI-Generated Responses",
    "authors": [
      "Jordyn Young",
      "Laala M Jawara",
      "Diep N Nguyen",
      "Brian Daly",
      "Jina Huh-Yoo",
      "Afsaneh Razi"
    ],
    "abstract": "Generative Artificial Intelligence (AI) is integrated into everyday\ntechnology, including news, education, and social media. AI has further\npervaded private conversations as conversational partners, auto-completion, and\nresponse suggestions. As social media becomes young people's main method of\npeer support exchange, we need to understand when and how AI can facilitate and\nassist in such exchanges in a beneficial, safe, and socially appropriate way.\nWe asked 622 young people to complete an online survey and evaluate blinded\nhuman- and AI-generated responses to help-seeking messages. We found that\nparticipants preferred the AI-generated response to situations about\nrelationships, self-expression, and physical health. However, when addressing a\nsensitive topic, like suicidal thoughts, young people preferred the human\nresponse. We also discuss the role of training in online peer support exchange\nand its implications for supporting young people's well-being. Disclaimer: This\npaper includes sensitive topics, including suicide ideation. Reader discretion\nis advised.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02711v1",
    "published_date": "2024-05-04 16:53:19 UTC",
    "updated_date": "2024-05-04 16:53:19 UTC"
  },
  {
    "arxiv_id": "2405.06674v1",
    "title": "Open-SQL Framework: Enhancing Text-to-SQL on Open-source Large Language Models",
    "authors": [
      "Xiaojun Chen",
      "Tianle Wang",
      "Tianhao Qiu",
      "Jianbin Qin",
      "Min Yang"
    ],
    "abstract": "Despite the success of large language models (LLMs) in Text-to-SQL tasks,\nopen-source LLMs encounter challenges in contextual understanding and response\ncoherence. To tackle these issues, we present \\ours, a systematic methodology\ntailored for Text-to-SQL with open-source LLMs. Our contributions include a\ncomprehensive evaluation of open-source LLMs in Text-to-SQL tasks, the\n\\openprompt strategy for effective question representation, and novel\nstrategies for supervised fine-tuning. We explore the benefits of\nChain-of-Thought in step-by-step inference and propose the \\openexample method\nfor enhanced few-shot learning. Additionally, we introduce token-efficient\ntechniques, such as \\textbf{Variable-length Open DB Schema}, \\textbf{Target\nColumn Truncation}, and \\textbf{Example Column Truncation}, addressing\nchallenges in large-scale databases. Our findings emphasize the need for\nfurther investigation into the impact of supervised fine-tuning on contextual\nlearning capabilities. Remarkably, our method significantly improved Llama2-7B\nfrom 2.54\\% to 41.04\\% and Code Llama-7B from 14.54\\% to 48.24\\% on the\nBIRD-Dev dataset. Notably, the performance of Code Llama-7B surpassed GPT-4\n(46.35\\%) on the BIRD-Dev dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06674v1",
    "published_date": "2024-05-04 15:40:17 UTC",
    "updated_date": "2024-05-04 15:40:17 UTC"
  },
  {
    "arxiv_id": "2405.02698v1",
    "title": "Stable Diffusion Dataset Generation for Downstream Classification Tasks",
    "authors": [
      "Eugenio Lomurno",
      "Matteo D'Oria",
      "Matteo Matteucci"
    ],
    "abstract": "Recent advances in generative artificial intelligence have enabled the\ncreation of high-quality synthetic data that closely mimics real-world data.\nThis paper explores the adaptation of the Stable Diffusion 2.0 model for\ngenerating synthetic datasets, using Transfer Learning, Fine-Tuning and\ngeneration parameter optimisation techniques to improve the utility of the\ndataset for downstream classification tasks. We present a class-conditional\nversion of the model that exploits a Class-Encoder and optimisation of key\ngeneration parameters. Our methodology led to synthetic datasets that, in a\nthird of cases, produced models that outperformed those trained on real\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02698v1",
    "published_date": "2024-05-04 15:37:22 UTC",
    "updated_date": "2024-05-04 15:37:22 UTC"
  },
  {
    "arxiv_id": "2405.02696v1",
    "title": "DiffuseTrace: A Transparent and Flexible Watermarking Scheme for Latent Diffusion Model",
    "authors": [
      "Liangqi Lei",
      "Keke Gai",
      "Jing Yu",
      "Liehuang Zhu"
    ],
    "abstract": "Latent Diffusion Models (LDMs) enable a wide range of applications but raise\nethical concerns regarding illegal utilization.Adding watermarks to generative\nmodel outputs is a vital technique employed for copyright tracking and\nmitigating potential risks associated with AI-generated content. However,\npost-hoc watermarking techniques are susceptible to evasion. Existing\nwatermarking methods for LDMs can only embed fixed messages. Watermark message\nalteration requires model retraining. The stability of the watermark is\ninfluenced by model updates and iterations. Furthermore, the current\nreconstruction-based watermark removal techniques utilizing variational\nautoencoders (VAE) and diffusion models have the capability to remove a\nsignificant portion of watermarks. Therefore, we propose a novel technique\ncalled DiffuseTrace. The goal is to embed invisible watermarks in all generated\nimages for future detection semantically. The method establishes a unified\nrepresentation of the initial latent variables and the watermark information\nthrough training an encoder-decoder model. The watermark information is\nembedded into the initial latent variables through the encoder and integrated\ninto the sampling process. The watermark information is extracted by reversing\nthe diffusion process and utilizing the decoder. DiffuseTrace does not rely on\nfine-tuning of the diffusion model components. The watermark is embedded into\nthe image space semantically without compromising image quality. The\nencoder-decoder can be utilized as a plug-in in arbitrary diffusion models. We\nvalidate through experiments the effectiveness and flexibility of DiffuseTrace.\nDiffuseTrace holds an unprecedented advantage in combating the latest attacks\nbased on variational autoencoders and Diffusion Models.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02696v1",
    "published_date": "2024-05-04 15:32:57 UTC",
    "updated_date": "2024-05-04 15:32:57 UTC"
  },
  {
    "arxiv_id": "2405.02686v1",
    "title": "Boosting 3D Neuron Segmentation with 2D Vision Transformer Pre-trained on Natural Images",
    "authors": [
      "Yik San Cheng",
      "Runkai Zhao",
      "Heng Wang",
      "Hanchuan Peng",
      "Weidong Cai"
    ],
    "abstract": "Neuron reconstruction, one of the fundamental tasks in neuroscience, rebuilds\nneuronal morphology from 3D light microscope imaging data. It plays a critical\nrole in analyzing the structure-function relationship of neurons in the nervous\nsystem. However, due to the scarcity of neuron datasets and high-quality SWC\nannotations, it is still challenging to develop robust segmentation methods for\nsingle neuron reconstruction. To address this limitation, we aim to distill the\nconsensus knowledge from massive natural image data to aid the segmentation\nmodel in learning the complex neuron structures. Specifically, in this work, we\npropose a novel training paradigm that leverages a 2D Vision Transformer model\npre-trained on large-scale natural images to initialize our Transformer-based\n3D neuron segmentation model with a tailored 2D-to-3D weight transferring\nstrategy. Our method builds a knowledge sharing connection between the abundant\nnatural and the scarce neuron image domains to improve the 3D neuron\nsegmentation ability in a data-efficiency manner. Evaluated on a popular\nbenchmark, BigNeuron, our method enhances neuron segmentation performance by\n8.71% over the model trained from scratch with the same amount of training\nsamples.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "3 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.02686v1",
    "published_date": "2024-05-04 14:57:28 UTC",
    "updated_date": "2024-05-04 14:57:28 UTC"
  },
  {
    "arxiv_id": "2405.02685v1",
    "title": "FedProK: Trustworthy Federated Class-Incremental Learning via Prototypical Feature Knowledge Transfer",
    "authors": [
      "Xin Gao",
      "Xin Yang",
      "Hao Yu",
      "Yan Kang",
      "Tianrui Li"
    ],
    "abstract": "Federated Class-Incremental Learning (FCIL) focuses on continually\ntransferring the previous knowledge to learn new classes in dynamic Federated\nLearning (FL). However, existing methods do not consider the trustworthiness of\nFCIL, i.e., improving continual utility, privacy, and efficiency\nsimultaneously, which is greatly influenced by catastrophic forgetting and data\nheterogeneity among clients. To address this issue, we propose FedProK\n(Federated Prototypical Feature Knowledge Transfer), leveraging prototypical\nfeature as a novel representation of knowledge to perform spatial-temporal\nknowledge transfer. Specifically, FedProK consists of two components: (1)\nfeature translation procedure on the client side by temporal knowledge transfer\nfrom the learned classes and (2) prototypical knowledge fusion on the server\nside by spatial knowledge transfer among clients. Extensive experiments\nconducted in both synchronous and asynchronous settings demonstrate that our\nFedProK outperforms the other state-of-the-art methods in three perspectives of\ntrustworthiness, validating its effectiveness in selectively transferring\nspatial-temporal knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02685v1",
    "published_date": "2024-05-04 14:57:09 UTC",
    "updated_date": "2024-05-04 14:57:09 UTC"
  },
  {
    "arxiv_id": "2405.02678v3",
    "title": "Position: Quo Vadis, Unsupervised Time Series Anomaly Detection?",
    "authors": [
      "M. Saquib Sarfraz",
      "Mei-Yen Chen",
      "Lukas Layer",
      "Kunyu Peng",
      "Marios Koulakis"
    ],
    "abstract": "The current state of machine learning scholarship in Timeseries Anomaly\nDetection (TAD) is plagued by the persistent use of flawed evaluation metrics,\ninconsistent benchmarking practices, and a lack of proper justification for the\nchoices made in novel deep learning-based model designs. Our paper presents a\ncritical analysis of the status quo in TAD, revealing the misleading track of\ncurrent research and highlighting problematic methods, and evaluation\npractices. Our position advocates for a shift in focus from solely pursuing\nnovel model designs to improving benchmarking practices, creating non-trivial\ndatasets, and critically evaluating the utility of complex methods against\nsimpler baselines. Our findings demonstrate the need for rigorous evaluation\nprotocols, the creation of simple baselines, and the revelation that\nstate-of-the-art deep anomaly detection models effectively learn linear\nmappings. These findings suggest the need for more exploration and development\nof simple and interpretable TAD methods. The increment of model complexity in\nthe state-of-the-art deep-learning based models unfortunately offers very\nlittle improvement. We offer insights and suggestions for the field to move\nforward.\n  Code: https://github.com/ssarfraz/QuoVadisTAD",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.02678v3",
    "published_date": "2024-05-04 14:43:31 UTC",
    "updated_date": "2024-06-05 13:12:17 UTC"
  },
  {
    "arxiv_id": "2405.02675v1",
    "title": "Quranic Audio Dataset: Crowdsourced and Labeled Recitation from Non-Arabic Speakers",
    "authors": [
      "Raghad Salameh",
      "Mohamad Al Mdfaa",
      "Nursultan Askarbekuly",
      "Manuel Mazzara"
    ],
    "abstract": "This paper addresses the challenge of learning to recite the Quran for\nnon-Arabic speakers. We explore the possibility of crowdsourcing a carefully\nannotated Quranic dataset, on top of which AI models can be built to simplify\nthe learning process. In particular, we use the volunteer-based crowdsourcing\ngenre and implement a crowdsourcing API to gather audio assets. We integrated\nthe API into an existing mobile application called NamazApp to collect audio\nrecitations. We developed a crowdsourcing platform called Quran Voice for\nannotating the gathered audio assets. As a result, we have collected around\n7000 Quranic recitations from a pool of 1287 participants across more than 11\nnon-Arabic countries, and we have annotated 1166 recitations from the dataset\nin six categories. We have achieved a crowd accuracy of 0.77, an inter-rater\nagreement of 0.63 between the annotators, and 0.89 between the labels assigned\nby the algorithm and the expert judgments.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02675v1",
    "published_date": "2024-05-04 14:29:05 UTC",
    "updated_date": "2024-05-04 14:29:05 UTC"
  },
  {
    "arxiv_id": "2407.10296v1",
    "title": "Modern Information Technologies in Scientific Research and Educational Activities",
    "authors": [
      "Kyrylo Malakhov",
      "Vadislav Kaverinskiy",
      "Liliia Ivanova",
      "Oleksandr Romanyuk",
      "Oksana Romaniuk",
      "Svitlana Voinova",
      "Sergii Kotlyk",
      "Oksana Sokolova"
    ],
    "abstract": "The monograph summarizes and analyzes the current state of scientific\nresearch in the field of interactive artificial intelligence systems, text\ngeneration systems, diagnostics of the competitiveness of specialists, in the\nareas of correct color rendering in image formation, informatization of the\nwork of graduate students, accessible technology for creating three-dimensional\n3D models. The monograph will be useful both to specialists and employees of\ncompanies working in the IT field, as well as teachers, masters, students and\ngraduate students of higher educational institutions, as well as anyone\ninterested in issues related to information technology. The monograph was\ncompiled based on the results of the 16-th international scientific and\npractical conference Information technologies and automation - 2023, which took\nplace in October 2023 at Odessa National University of Technology.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.GR"
    ],
    "primary_category": "cs.CY",
    "comment": "Monograph Scientific publication (issue). Published By Iowa State\n  University Digital Press. ISBN 978-1-958291-07-8; 273 pages; Published May 1,\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2407.10296v1",
    "published_date": "2024-05-04 14:24:47 UTC",
    "updated_date": "2024-05-04 14:24:47 UTC"
  },
  {
    "arxiv_id": "2405.15792v1",
    "title": "IQLS: Framework for leveraging Metadata to enable Large Language Model based queries to complex, versatile Data",
    "authors": [
      "Sami Azirar",
      "Hossam A. Gabbar",
      "Chaouki Regoui"
    ],
    "abstract": "As the amount and complexity of data grows, retrieving it has become a more\ndifficult task that requires greater knowledge and resources. This is\nespecially true for the logistics industry, where new technologies for data\ncollection provide tremendous amounts of interconnected real-time data. The\nIntelligent Query and Learning System (IQLS) simplifies the process by allowing\nnatural language use to simplify data retrieval . It maps structured data into\na framework based on the available metadata and available data models. This\nframework creates an environment for an agent powered by a Large Language\nModel. The agent utilizes the hierarchical nature of the data to filter\niteratively by making multiple small context-aware decisions instead of\none-shot data retrieval. After the Data filtering, the IQLS enables the agent\nto fulfill tasks given by the user query through interfaces. These interfaces\nrange from multimodal transportation information retrieval to route planning\nunder multiple constraints. The latter lets the agent define a dynamic object,\nwhich is determined based on the query parameters. This object represents a\ndriver capable of navigating a road network. The road network is depicted as a\ngraph with attributes based on the data. Using a modified version of the\nDijkstra algorithm, the optimal route under the given constraints can be\ndetermined. Throughout the entire process, the user maintains the ability to\ninteract and guide the system. The IQLS is showcased in a case study on the\nCanadian logistics sector, allowing geospatial, visual, tabular and text data\nto be easily queried semantically in natural language.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15792v1",
    "published_date": "2024-05-04 13:44:05 UTC",
    "updated_date": "2024-05-04 13:44:05 UTC"
  },
  {
    "arxiv_id": "2405.02664v3",
    "title": "MedPromptExtract (Medical Data Extraction Tool): Anonymization and Hi-fidelity Automated data extraction using NLP and prompt engineering",
    "authors": [
      "Roomani Srivastava",
      "Suraj Prasad",
      "Lipika Bhat",
      "Sarvesh Deshpande",
      "Barnali Das",
      "Kshitij Jadhav"
    ],
    "abstract": "Introduction: The labour-intensive nature of data extraction from sources\nlike discharge summaries (DS) poses significant obstacles to the digitisation\nof medical records particularly for low- and middle-income countries (LMICs).\nIn this paper we present a completely automated method MedPromptExtract to\nefficiently extract data from DS while maintaining confidentiality. Methods:\nThe source of data was Discharge Summaries (DS) from Kokilaben Dhirubhai Ambani\nHospital (KDAH) of patients having Acute Kidney Injury (AKI). A pre-existing\ntool EIGEN which leverages semi-supervised learning techniques for\nhigh-fidelity information extraction was used to anonymize the DS, Natural\nLanguage Processing (NLP) was used to extract data from regular fields. We used\nPrompt Engineering and Large Language Model(LLM) to extract custom clinical\ninformation from free flowing text describing the patients stay in the\nhospital. Twelve features associated with occurrence of AKI were extracted. The\nLLM responses were validated against clinicians annotations. Results: The\nMedPromptExtracttool first subjected DS to the anonymization pipeline which\ntook three seconds per summary. Successful anonymization was verified by\nclinicians, thereafter NLP pipeline extracted structured text from the\nanonymized pdfs at the rate of 0.2 seconds per summary with 100%\naccuracy.Finally DS were analysed by the LLM pipeline using Gemini Pro for the\ntwelve features. Accuracy metrics were calculated by comparing model responses\nto clinicians annotations with seven features achieving AUCs above 0.9,\nindicating high fidelity of the extraction process. Conclusion:\nMedPromptExtract serves as an automated adaptable tool for efficient data\nextraction from medical records with a dynamic user interface. Keywords:\nDigitizing Medical Records, Automated Anonymisation, Information Retrieval,\nLarge Language Models, Prompt Engineering",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02664v3",
    "published_date": "2024-05-04 13:25:06 UTC",
    "updated_date": "2024-09-06 11:38:00 UTC"
  },
  {
    "arxiv_id": "2405.02654v2",
    "title": "Enhancing Cooperation through Selective Interaction and Long-term Experiences in Multi-Agent Reinforcement Learning",
    "authors": [
      "Tianyu Ren",
      "Xiao-Jun Zeng"
    ],
    "abstract": "The significance of network structures in promoting group cooperation within\nsocial dilemmas has been widely recognized. Prior studies attribute this\nfacilitation to the assortment of strategies driven by spatial interactions.\nAlthough reinforcement learning has been employed to investigate the impact of\ndynamic interaction on the evolution of cooperation, there remains a lack of\nunderstanding about how agents develop neighbour selection behaviours and the\nformation of strategic assortment within an explicit interaction structure. To\naddress this, our study introduces a computational framework based on\nmulti-agent reinforcement learning in the spatial Prisoner's Dilemma game. This\nframework allows agents to select dilemma strategies and interacting neighbours\nbased on their long-term experiences, differing from existing research that\nrelies on preset social norms or external incentives. By modelling each agent\nusing two distinct Q-networks, we disentangle the coevolutionary dynamics\nbetween cooperation and interaction. The results indicate that long-term\nexperience enables agents to develop the ability to identify non-cooperative\nneighbours and exhibit a preference for interaction with cooperative ones. This\nemergent self-organizing behaviour leads to the clustering of agents with\nsimilar strategies, thereby increasing network reciprocity and enhancing group\ncooperation.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted at IJCAI 2024 (33rd International Joint Conference on\n  Artificial Intelligence - Jeju)",
    "pdf_url": "http://arxiv.org/pdf/2405.02654v2",
    "published_date": "2024-05-04 12:42:55 UTC",
    "updated_date": "2024-08-18 14:30:52 UTC"
  },
  {
    "arxiv_id": "2405.02653v2",
    "title": "Isopignistic Canonical Decomposition via Belief Evolution Network",
    "authors": [
      "Qianli Zhou",
      "Tianxiang Zhan",
      "Yong Deng"
    ],
    "abstract": "Developing a general information processing model in uncertain environments\nis fundamental for the advancement of explainable artificial intelligence.\nDempster-Shafer theory of evidence is a well-known and effective reasoning\nmethod for representing epistemic uncertainty, which is closely related to\nsubjective probability theory and possibility theory. Although they can be\ntransformed to each other under some particular belief structures, there\nremains a lack of a clear and interpretable transformation process, as well as\na unified approach for information processing. In this paper, we aim to address\nthese issues from the perspectives of isopignistic belief functions and the\nhyper-cautious transferable belief model. Firstly, we propose an isopignistic\ntransformation based on the belief evolution network. This transformation\nallows for the adjustment of the information granule while retaining the\npotential decision outcome. The isopignistic transformation is integrated with\na hyper-cautious transferable belief model to establish a new canonical\ndecomposition. This decomposition offers a reverse path between the possibility\ndistribution and its isopignistic mass functions. The result of the canonical\ndecomposition, called isopignistic function, is an identical information\ncontent distribution to reflect the propensity and relative commitment degree\nof the BPA. Furthermore, this paper introduces a method to reconstruct the\nbasic belief assignment by adjusting the isopignistic function. It explores the\nadvantages of this approach in modeling and handling uncertainty within the\nhyper-cautious transferable belief model. More general, this paper establishes\na theoretical basis for building general models of artificial intelligence\nbased on probability theory, Dempster-Shafer theory, and possibility theory.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02653v2",
    "published_date": "2024-05-04 12:39:15 UTC",
    "updated_date": "2024-08-30 12:52:31 UTC"
  },
  {
    "arxiv_id": "2405.02652v2",
    "title": "Deep Pulse-Signal Magnification for remote Heart Rate Estimation in Compressed Videos",
    "authors": [
      "Joaquim Comas",
      "Adria Ruiz",
      "Federico Sukno"
    ],
    "abstract": "Recent advancements in data-driven approaches for remote photoplethysmography\n(rPPG) have significantly improved the accuracy of remote heart rate\nestimation. However, the performance of such approaches worsens considerably\nunder video compression, which is nevertheless necessary to store and transmit\nvideo data efficiently. In this paper, we present a novel approach to address\nthe impact of video compression on rPPG estimation, which leverages a\npulse-signal magnification transformation to adapt compressed videos to an\nuncompressed data domain in which the rPPG signal is magnified. We validate the\neffectiveness of our model by exhaustive evaluations on two publicly available\ndatasets, UCLA-rPPG and UBFC-rPPG, employing both intra- and cross-database\nperformance at several compression rates. Additionally, we assess the\nrobustness of our approach on two additional highly compressed and widely-used\ndatasets, MAHNOB-HCI and COHFACE, which reveal outstanding heart rate\nestimation results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02652v2",
    "published_date": "2024-05-04 12:37:07 UTC",
    "updated_date": "2024-06-25 16:53:21 UTC"
  },
  {
    "arxiv_id": "2405.02650v1",
    "title": "Identifying Narrative Patterns and Outliers in Holocaust Testimonies Using Topic Modeling",
    "authors": [
      "Maxim Ifergan",
      "Renana Keydar",
      "Omri Abend",
      "Amit Pinchevski"
    ],
    "abstract": "The vast collection of Holocaust survivor testimonies presents invaluable\nhistorical insights but poses challenges for manual analysis. This paper\nleverages advanced Natural Language Processing (NLP) techniques to explore the\nUSC Shoah Foundation Holocaust testimony corpus. By treating testimonies as\nstructured question-and-answer sections, we apply topic modeling to identify\nkey themes. We experiment with BERTopic, which leverages recent advances in\nlanguage modeling technology. We align testimony sections into fixed parts,\nrevealing the evolution of topics across the corpus of testimonies. This\nhighlights both a common narrative schema and divergences between subgroups\nbased on age and gender. We introduce a novel method to identify testimonies\nwithin groups that exhibit atypical topic distributions resembling those of\nother groups. This study offers unique insights into the complex narratives of\nHolocaust survivors, demonstrating the power of NLP to illuminate historical\ndiscourse and identify potential deviations in survivor experiences.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 7 figures, LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.02650v1",
    "published_date": "2024-05-04 12:29:00 UTC",
    "updated_date": "2024-05-04 12:29:00 UTC"
  },
  {
    "arxiv_id": "2405.02649v1",
    "title": "Generic Multi-modal Representation Learning for Network Traffic Analysis",
    "authors": [
      "Luca Gioacchini",
      "Idilio Drago",
      "Marco Mellia",
      "Zied Ben Houidi",
      "Dario Rossi"
    ],
    "abstract": "Network traffic analysis is fundamental for network management,\ntroubleshooting, and security. Tasks such as traffic classification, anomaly\ndetection, and novelty discovery are fundamental for extracting operational\ninformation from network data and measurements. We witness the shift from deep\npacket inspection and basic machine learning to Deep Learning (DL) approaches\nwhere researchers define and test a custom DL architecture designed for each\nspecific problem. We here advocate the need for a general DL architecture\nflexible enough to solve different traffic analysis tasks. We test this idea by\nproposing a DL architecture based on generic data adaptation modules, followed\nby an integration module that summarises the extracted information into a\ncompact and rich intermediate representation (i.e. embeddings). The result is a\nflexible Multi-modal Autoencoder (MAE) pipeline that can solve different use\ncases. We demonstrate the architecture with traffic classification (TC) tasks\nsince they allow us to quantitatively compare results with state-of-the-art\nsolutions. However, we argue that the MAE architecture is generic and can be\nused to learn representations useful in multiple scenarios. On TC, the MAE\nperforms on par or better than alternatives while avoiding cumbersome feature\nengineering, thus streamlining the adoption of DL solutions for traffic\nanalysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02649v1",
    "published_date": "2024-05-04 12:24:29 UTC",
    "updated_date": "2024-05-04 12:24:29 UTC"
  },
  {
    "arxiv_id": "2405.02648v2",
    "title": "A Conformal Prediction Score that is Robust to Label Noise",
    "authors": [
      "Coby Penso",
      "Jacob Goldberger"
    ],
    "abstract": "Conformal Prediction (CP) quantifies network uncertainty by building a small\nprediction set with a pre-defined probability that the correct class is within\nthis set. In this study we tackle the problem of CP calibration based on a\nvalidation set with noisy labels. We introduce a conformal score that is robust\nto label noise. The noise-free conformal score is estimated using the noisy\nlabeled data and the noise level. In the test phase the noise-free score is\nused to form the prediction set. We applied the proposed algorithm to several\nstandard medical imaging classification datasets. We show that our method\noutperforms current methods by a large margin, in terms of the average size of\nthe prediction set, while maintaining the required coverage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02648v2",
    "published_date": "2024-05-04 12:22:02 UTC",
    "updated_date": "2024-05-21 13:06:56 UTC"
  },
  {
    "arxiv_id": "2405.03712v1",
    "title": "Your Network May Need to Be Rewritten: Network Adversarial Based on High-Dimensional Function Graph Decomposition",
    "authors": [
      "Xiaoyan Su",
      "Yinghao Zhu",
      "Run Li"
    ],
    "abstract": "In the past, research on a single low dimensional activation function in\nnetworks has led to internal covariate shift and gradient deviation problems. A\nrelatively small research area is how to use function combinations to provide\nproperty completion for a single activation function application. We propose a\nnetwork adversarial method to address the aforementioned challenges. This is\nthe first method to use different activation functions in a network. Based on\nthe existing activation functions in the current network, an adversarial\nfunction with opposite derivative image properties is constructed, and the two\nare alternately used as activation functions for different network layers. For\ncomplex situations, we propose a method of high-dimensional function graph\ndecomposition(HD-FGD), which divides it into different parts and then passes\nthrough a linear layer. After integrating the inverse of the partial\nderivatives of each decomposed term, we obtain its adversarial function by\nreferring to the computational rules of the decomposition process. The use of\nnetwork adversarial methods or the use of HD-FGD alone can effectively replace\nthe traditional MLP+activation function mode. Through the above methods, we\nhave achieved a substantial improvement over standard activation functions\nregarding both training efficiency and predictive accuracy. The article\naddresses the adversarial issues associated with several prevalent activation\nfunctions, presenting alternatives that can be seamlessly integrated into\nexisting models without any adverse effects. We will release the code as open\nsource after the conference review process is completed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03712v1",
    "published_date": "2024-05-04 11:22:30 UTC",
    "updated_date": "2024-05-04 11:22:30 UTC"
  },
  {
    "arxiv_id": "2405.02637v1",
    "title": "TREC iKAT 2023: A Test Collection for Evaluating Conversational and Interactive Knowledge Assistants",
    "authors": [
      "Mohammad Aliannejadi",
      "Zahra Abbasiantaeb",
      "Shubham Chatterjee",
      "Jeffery Dalton",
      "Leif Azzopardi"
    ],
    "abstract": "Conversational information seeking has evolved rapidly in the last few years\nwith the development of Large Language Models (LLMs), providing the basis for\ninterpreting and responding in a naturalistic manner to user requests. The\nextended TREC Interactive Knowledge Assistance Track (iKAT) collection aims to\nenable researchers to test and evaluate their Conversational Search Agents\n(CSA). The collection contains a set of 36 personalized dialogues over 20\ndifferent topics each coupled with a Personal Text Knowledge Base (PTKB) that\ndefines the bespoke user personas. A total of 344 turns with approximately\n26,000 passages are provided as assessments on relevance, as well as additional\nassessments on generated responses over four key dimensions: relevance,\ncompleteness, groundedness, and naturalness. The collection challenges CSA to\nefficiently navigate diverse personal contexts, elicit pertinent persona\ninformation, and employ context for relevant conversations. The integration of\na PTKB and the emphasis on decisional search tasks contribute to the uniqueness\nof this test collection, making it an essential benchmark for advancing\nresearch in conversational and interactive knowledge assistants.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "To appear in SIGIR 2024. arXiv admin note: substantial text overlap\n  with arXiv:2401.01330",
    "pdf_url": "http://arxiv.org/pdf/2405.02637v1",
    "published_date": "2024-05-04 11:22:16 UTC",
    "updated_date": "2024-05-04 11:22:16 UTC"
  },
  {
    "arxiv_id": "2405.02634v1",
    "title": "Onboard Out-of-Calibration Detection of Deep Learning Models using Conformal Prediction",
    "authors": [
      "Protim Bhattacharjee",
      "Peter Jung"
    ],
    "abstract": "The black box nature of deep learning models complicate their usage in\ncritical applications such as remote sensing. Conformal prediction is a method\nto ensure trust in such scenarios. Subject to data exchangeability, conformal\nprediction provides finite sample coverage guarantees in the form of a\nprediction set that is guaranteed to contain the true class within a user\ndefined error rate. In this letter we show that conformal prediction algorithms\nare related to the uncertainty of the deep learning model and that this\nrelation can be used to detect if the deep learning model is\nout-of-calibration. Popular classification models like Resnet50, Densenet161,\nInceptionV3, and MobileNetV2 are applied on remote sensing datasets such as the\nEuroSAT to demonstrate how under noisy scenarios the model outputs become\nuntrustworthy. Furthermore an out-of-calibration detection procedure relating\nthe model uncertainty and the average size of the conformal prediction set is\npresented.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02634v1",
    "published_date": "2024-05-04 11:05:52 UTC",
    "updated_date": "2024-05-04 11:05:52 UTC"
  },
  {
    "arxiv_id": "2405.02628v1",
    "title": "Contrastive Dual-Interaction Graph Neural Network for Molecular Property Prediction",
    "authors": [
      "Zexing Zhao",
      "Guangsi Shi",
      "Xiaopeng Wu",
      "Ruohua Ren",
      "Xiaojun Gao",
      "Fuyi Li"
    ],
    "abstract": "Molecular property prediction is a key component of AI-driven drug discovery\nand molecular characterization learning. Despite recent advances, existing\nmethods still face challenges such as limited ability to generalize, and\ninadequate representation of learning from unlabeled data, especially for tasks\nspecific to molecular structures. To address these limitations, we introduce\nDIG-Mol, a novel self-supervised graph neural network framework for molecular\nproperty prediction. This architecture leverages the power of contrast learning\nwith dual interaction mechanisms and unique molecular graph enhancement\nstrategies. DIG-Mol integrates a momentum distillation network with two\ninterconnected networks to efficiently improve molecular characterization. The\nframework's ability to extract key information about molecular structure and\nhigher-order semantics is supported by minimizing loss of contrast. We have\nestablished DIG-Mol's state-of-the-art performance through extensive\nexperimental evaluation in a variety of molecular property prediction tasks. In\naddition to demonstrating superior transferability in a small number of\nlearning scenarios, our visualizations highlight DIG-Mol's enhanced\ninterpretability and representation capabilities. These findings confirm the\neffectiveness of our approach in overcoming challenges faced by traditional\nmethods and mark a significant advance in molecular property prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02628v1",
    "published_date": "2024-05-04 10:09:27 UTC",
    "updated_date": "2024-05-04 10:09:27 UTC"
  },
  {
    "arxiv_id": "2405.02612v3",
    "title": "Learning Linear Utility Functions From Pairwise Comparison Queries",
    "authors": [
      "Luise Ge",
      "Brendan Juba",
      "Yevgeniy Vorobeychik"
    ],
    "abstract": "We study learnability of linear utility functions from pairwise comparison\nqueries. In particular, we consider two learning objectives. The first\nobjective is to predict out-of-sample responses to pairwise comparisons,\nwhereas the second is to approximately recover the true parameters of the\nutility function. We show that in the passive learning setting, linear\nutilities are efficiently learnable with respect to the first objective, both\nwhen query responses are uncorrupted by noise, and under Tsybakov noise when\nthe distributions are sufficiently \"nice\". In contrast, we show that utility\nparameters are not learnable for a large set of data distributions without\nstrong modeling assumptions, even when query responses are noise-free. Next, we\nproceed to analyze the learning problem in an active learning setting. In this\ncase, we show that even the second objective is efficiently learnable, and\npresent algorithms for both the noise-free and noisy query response settings.\nOur results thus exhibit a qualitative learnability gap between passive and\nactive learning from pairwise preference queries, demonstrating the value of\nthe ability to select pairwise queries for utility learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to ECAI for review",
    "pdf_url": "http://arxiv.org/pdf/2405.02612v3",
    "published_date": "2024-05-04 08:43:45 UTC",
    "updated_date": "2024-06-19 17:08:13 UTC"
  },
  {
    "arxiv_id": "2405.02608v1",
    "title": "UnSAMFlow: Unsupervised Optical Flow Guided by Segment Anything Model",
    "authors": [
      "Shuai Yuan",
      "Lei Luo",
      "Zhuo Hui",
      "Can Pu",
      "Xiaoyu Xiang",
      "Rakesh Ranjan",
      "Denis Demandolx"
    ],
    "abstract": "Traditional unsupervised optical flow methods are vulnerable to occlusions\nand motion boundaries due to lack of object-level information. Therefore, we\npropose UnSAMFlow, an unsupervised flow network that also leverages object\ninformation from the latest foundation model Segment Anything Model (SAM). We\nfirst include a self-supervised semantic augmentation module tailored to SAM\nmasks. We also analyze the poor gradient landscapes of traditional smoothness\nlosses and propose a new smoothness definition based on homography instead. A\nsimple yet effective mask feature module has also been added to further\naggregate features on the object level. With all these adaptations, our method\nproduces clear optical flow estimation with sharp boundaries around objects,\nwhich outperforms state-of-the-art methods on both KITTI and Sintel datasets.\nOur method also generalizes well across domains and runs very efficiently.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2024. Code is available at\n  https://github.com/facebookresearch/UnSAMFlow",
    "pdf_url": "http://arxiv.org/pdf/2405.02608v1",
    "published_date": "2024-05-04 08:27:12 UTC",
    "updated_date": "2024-05-04 08:27:12 UTC"
  },
  {
    "arxiv_id": "2405.02605v1",
    "title": "MEXGEN: An Effective and Efficient Information Gain Approximation for Information Gathering Path Planning",
    "authors": [
      "Joshua Chesser",
      "Thuraiappah Sathyan",
      "Damith C. Ranasinghe"
    ],
    "abstract": "Autonomous robots for gathering information on objects of interest has\nnumerous real-world applications because of they improve efficiency,\nperformance and safety. Realizing autonomy demands online planning algorithms\nto solve sequential decision making problems under uncertainty; because,\nobjects of interest are often dynamic, object state, such as location is not\ndirectly observable and are obtained from noisy measurements. Such planning\nproblems are notoriously difficult due to the combinatorial nature of\npredicting the future to make optimal decisions. For information theoretic\nplanning algorithms, we develop a computationally efficient and effective\napproximation for the difficult problem of predicting the likely sensor\nmeasurements from uncertain belief states}. The approach more accurately\npredicts information gain from information gathering actions. Our theoretical\nanalysis proves the proposed formulation achieves a lower prediction error than\nthe current efficient-method. We demonstrate improved performance gains in\nradio-source tracking and localization problems using extensive simulated and\nfield experiments with a multirotor aerial robot.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L)(Demo Video:\n  https://www.youtube.com/watch?v=XrsCC6MkaB4)",
    "pdf_url": "http://arxiv.org/pdf/2405.02605v1",
    "published_date": "2024-05-04 08:09:16 UTC",
    "updated_date": "2024-05-04 08:09:16 UTC"
  },
  {
    "arxiv_id": "2405.02602v1",
    "title": "Astro-NER -- Astronomy Named Entity Recognition: Is GPT a Good Domain Expert Annotator?",
    "authors": [
      "Julia Evans",
      "Sameer Sadruddin",
      "Jennifer D'Souza"
    ],
    "abstract": "In this study, we address one of the challenges of developing NER models for\nscholarly domains, namely the scarcity of suitable labeled data. We experiment\nwith an approach using predictions from a fine-tuned LLM model to aid\nnon-domain experts in annotating scientific entities within astronomy\nliterature, with the goal of uncovering whether such a collaborative process\ncan approximate domain expertise. Our results reveal moderate agreement between\na domain expert and the LLM-assisted non-experts, as well as fair agreement\nbetween the domain expert and the LLM model's predictions. In an additional\nexperiment, we compare the performance of finetuned and default LLMs on this\ntask. We have also introduced a specialized scientific entity annotation scheme\nfor astronomy, validated by a domain expert. Our approach adopts a scholarly\nresearch contribution-centric perspective, focusing exclusively on scientific\nentities relevant to the research theme. The resultant dataset, containing\n5,000 annotated astronomy article titles, is made publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.02602v1",
    "published_date": "2024-05-04 08:04:39 UTC",
    "updated_date": "2024-05-04 08:04:39 UTC"
  },
  {
    "arxiv_id": "2405.02596v1",
    "title": "Random Masking Finds Winning Tickets for Parameter Efficient Fine-tuning",
    "authors": [
      "Jing Xu",
      "Jingzhao Zhang"
    ],
    "abstract": "Fine-tuning large language models (LLM) can be costly. Parameter-efficient\nfine-tuning (PEFT) addresses the problems by training a fraction of the\nparameters, whose success reveals the expressiveness and flexibility of\npretrained models. This paper studies the limit of PEFT, by further simplifying\nits design and reducing the number of trainable parameters beyond standard\nsetups. To this end, we use Random Masking to fine-tune the pretrained model.\nDespite its simplicity, we show that Random Masking is surprisingly effective:\nwith a larger-than-expected learning rate, Random Masking can match the\nperformance of standard PEFT algorithms such as LoRA on various tasks, using\nfewer trainable parameters. We provide both empirical and theoretical\nexplorations into the success of Random Masking. We show that masking induces a\nflatter loss landscape and more distant solutions, which allows for and\nnecessitates large learning rates.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.02596v1",
    "published_date": "2024-05-04 07:44:18 UTC",
    "updated_date": "2024-05-04 07:44:18 UTC"
  },
  {
    "arxiv_id": "2405.02583v1",
    "title": "Explainable Interface for Human-Autonomy Teaming: A Survey",
    "authors": [
      "Xiangqi Kong",
      "Yang Xing",
      "Antonios Tsourdos",
      "Ziyue Wang",
      "Weisi Guo",
      "Adolfo Perrusquia",
      "Andreas Wikander"
    ],
    "abstract": "Nowadays, large-scale foundation models are being increasingly integrated\ninto numerous safety-critical applications, including human-autonomy teaming\n(HAT) within transportation, medical, and defence domains. Consequently, the\ninherent 'black-box' nature of these sophisticated deep neural networks\nheightens the significance of fostering mutual understanding and trust between\nhumans and autonomous systems. To tackle the transparency challenges in HAT,\nthis paper conducts a thoughtful study on the underexplored domain of\nExplainable Interface (EI) in HAT systems from a human-centric perspective,\nthereby enriching the existing body of research in Explainable Artificial\nIntelligence (XAI). We explore the design, development, and evaluation of EI\nwithin XAI-enhanced HAT systems. To do so, we first clarify the distinctions\nbetween these concepts: EI, explanations and model explainability, aiming to\nprovide researchers and practitioners with a structured understanding. Second,\nwe contribute to a novel framework for EI, addressing the unique challenges in\nHAT. Last, our summarized evaluation framework for ongoing EI offers a holistic\nperspective, encompassing model performance, human-centered factors, and group\ntask objectives. Based on extensive surveys across XAI, HAT, psychology, and\nHuman-Computer Interaction (HCI), this review offers multiple novel insights\ninto incorporating XAI into HAT systems and outlines future directions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "45 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.02583v1",
    "published_date": "2024-05-04 06:35:38 UTC",
    "updated_date": "2024-05-04 06:35:38 UTC"
  },
  {
    "arxiv_id": "2405.02580v2",
    "title": "PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation",
    "authors": [
      "Ye Liu",
      "Yue Xue",
      "Daoyuan Wu",
      "Yuqiang Sun",
      "Yi Li",
      "Miaolei Shi",
      "Yang Liu"
    ],
    "abstract": "With recent advances in large language models (LLMs), this paper explores the\npotential of leveraging state-of-the-art LLMs,such as GPT-4, to transfer\nexisting human-written properties (e.g.,those from Certora auditing reports)\nand automatically generate customized properties for unknown code. To this end,\nwe embed existing properties into a vector database and retrieve a reference\nproperty for LLM-based in-context learning to generate a new property for a\ngiven code. While this basic process is relatively straightforward, ensuring\nthat the generated properties are (i) compilable, (ii) appropriate, and (iii)\nverifiable presents challenges. To address (i), we use the compilation and\nstatic analysis feedback as an external oracle to guide LLMs in iteratively\nrevising the generated properties. For (ii), we consider multiple dimensions of\nsimilarity to rank the properties and employ a weighted algorithm to identify\nthe top-K properties as the final result. For (iii), we design a dedicated\nprover to formally verify the correctness of the generated properties. We have\nimplemented these strategies into a novel LLM-based property generation tool\ncalled PropertyGPT. Our experiments show that PropertyGPT can generate\ncomprehensive and high-quality properties, achieving an 80% recall compared to\nthe ground truth. It successfully detected 26 CVEs/attack incidents out of 37\ntested and also uncovered 12 zero-day vulnerabilities, leading to $8,256 in bug\nbounty rewards.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by NDSS Symposium 2025. Please cite the conference version\n  of this paper, e.g., \"Ye Liu, Yue Xue, Daoyuan Wu, Yuqiang Sun, Yi Li,\n  Miaolei Shi, Yang Liu. PropertyGPT: LLM-driven Formal Verification of Smart\n  Contracts through Retrieval-Augmented Property Generation. In 32nd Annual\n  Network and Distributed System Security Symposium (NDSS 2025).\"",
    "pdf_url": "http://arxiv.org/pdf/2405.02580v2",
    "published_date": "2024-05-04 06:28:27 UTC",
    "updated_date": "2024-12-06 08:41:01 UTC"
  },
  {
    "arxiv_id": "2405.03711v1",
    "title": "Guidance Design for Escape Flight Vehicle Using Evolution Strategy Enhanced Deep Reinforcement Learning",
    "authors": [
      "Xiao Hu",
      "Tianshu Wang",
      "Min Gong",
      "Shaoshi Yang"
    ],
    "abstract": "Guidance commands of flight vehicles are a series of data sets with fixed\ntime intervals, thus guidance design constitutes a sequential decision problem\nand satisfies the basic conditions for using deep reinforcement learning (DRL).\nIn this paper, we consider the scenario where the escape flight vehicle (EFV)\ngenerates guidance commands based on DRL and the pursuit flight vehicle (PFV)\ngenerates guidance commands based on the proportional navigation method. For\nthe EFV, the objective of the guidance design entails progressively maximizing\nthe residual velocity, subject to the constraint imposed by the given evasion\ndistance. Thus an irregular dynamic max-min problem of extremely large-scale is\nformulated, where the time instant when the optimal solution can be attained is\nuncertain and the optimum solution depends on all the intermediate guidance\ncommands generated before. For solving this problem, a two-step strategy is\nconceived. In the first step, we use the proximal policy optimization (PPO)\nalgorithm to generate the guidance commands of the EFV. The results obtained by\nPPO in the global search space are coarse, despite the fact that the reward\nfunction, the neural network parameters and the learning rate are designed\nelaborately. Therefore, in the second step, we propose to invoke the evolution\nstrategy (ES) based algorithm, which uses the result of PPO as the initial\nvalue, to further improve the quality of the solution by searching in the local\nspace. Simulation results demonstrate that the proposed guidance design method\nbased on the PPO algorithm is capable of achieving a residual velocity of 67.24\nm/s, higher than the residual velocities achieved by the benchmark soft\nactor-critic and deep deterministic policy gradient algorithms. Furthermore,\nthe proposed ES-enhanced PPO algorithm outperforms the PPO algorithm by 2.7\\%,\nachieving a residual velocity of 69.04 m/s.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 13 figures, accepted to appear on IEEE Access, Mar. 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03711v1",
    "published_date": "2024-05-04 06:18:15 UTC",
    "updated_date": "2024-05-04 06:18:15 UTC"
  },
  {
    "arxiv_id": "2405.02576v3",
    "title": "CTD4 -- A Deep Continuous Distributional Actor-Critic Agent with a Kalman Fusion of Multiple Critics",
    "authors": [
      "David Valencia",
      "Henry Williams",
      "Yuning Xing",
      "Trevor Gee",
      "Bruce A MacDonald",
      "Minas Liarokapis"
    ],
    "abstract": "Categorical Distributional Reinforcement Learning (CDRL) has demonstrated\nsuperior sample efficiency in learning complex tasks compared to conventional\nReinforcement Learning (RL) approaches. However, the practical application of\nCDRL is encumbered by challenging projection steps, detailed parameter tuning,\nand domain knowledge. This paper addresses these challenges by introducing a\npioneering Continuous Distributional Model-Free RL algorithm tailored for\ncontinuous action spaces. The proposed algorithm simplifies the implementation\nof distributional RL, adopting an actor-critic architecture wherein the critic\noutputs a continuous probability distribution. Additionally, we propose an\nensemble of multiple critics fused through a Kalman fusion mechanism to\nmitigate overestimation bias. Through a series of experiments, we validate that\nour proposed method provides a sample-efficient solution for executing complex\ncontinuous-control tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02576v3",
    "published_date": "2024-05-04 05:38:38 UTC",
    "updated_date": "2025-02-06 02:52:59 UTC"
  },
  {
    "arxiv_id": "2405.02572v1",
    "title": "Off-OAB: Off-Policy Policy Gradient Method with Optimal Action-Dependent Baseline",
    "authors": [
      "Wenjia Meng",
      "Qian Zheng",
      "Long Yang",
      "Yilong Yin",
      "Gang Pan"
    ],
    "abstract": "Policy-based methods have achieved remarkable success in solving challenging\nreinforcement learning problems. Among these methods, off-policy policy\ngradient methods are particularly important due to that they can benefit from\noff-policy data. However, these methods suffer from the high variance of the\noff-policy policy gradient (OPPG) estimator, which results in poor sample\nefficiency during training. In this paper, we propose an off-policy policy\ngradient method with the optimal action-dependent baseline (Off-OAB) to\nmitigate this variance issue. Specifically, this baseline maintains the OPPG\nestimator's unbiasedness while theoretically minimizing its variance. To\nenhance practical computational efficiency, we design an approximated version\nof this optimal baseline. Utilizing this approximation, our method (Off-OAB)\naims to decrease the OPPG estimator's variance during policy optimization. We\nevaluate the proposed Off-OAB method on six representative tasks from OpenAI\nGym and MuJoCo, where it demonstrably surpasses state-of-the-art methods on the\nmajority of these tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.02572v1",
    "published_date": "2024-05-04 05:21:28 UTC",
    "updated_date": "2024-05-04 05:21:28 UTC"
  },
  {
    "arxiv_id": "2405.02569v1",
    "title": "Decoupling Exploration and Exploitation for Unsupervised Pre-training with Successor Features",
    "authors": [
      "JaeYoon Kim",
      "Junyu Xuan",
      "Christy Liang",
      "Farookh Hussain"
    ],
    "abstract": "Unsupervised pre-training has been on the lookout for the virtue of a value\nfunction representation referred to as successor features (SFs), which\ndecouples the dynamics of the environment from the rewards. It has a\nsignificant impact on the process of task-specific fine-tuning due to the\ndecomposition. However, existing approaches struggle with local optima due to\nthe unified intrinsic reward of exploration and exploitation without\nconsidering the linear regression problem and the discriminator supporting a\nsmall skill sapce. We propose a novel unsupervised pre-training model with SFs\nbased on a non-monolithic exploration methodology. Our approach pursues the\ndecomposition of exploitation and exploration of an agent built on SFs, which\nrequires separate agents for the respective purpose. The idea will leverage not\nonly the inherent characteristics of SFs such as a quick adaptation to new\ntasks but also the exploratory and task-agnostic capabilities. Our suggested\nmodel is termed Non-Monolithic unsupervised Pre-training with Successor\nfeatures (NMPS), which improves the performance of the original monolithic\nexploration method of pre-training with SFs. NMPS outperforms Active\nPre-training with Successor Features (APS) in a comparative experiment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCNN 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.02569v1",
    "published_date": "2024-05-04 05:03:11 UTC",
    "updated_date": "2024-05-04 05:03:11 UTC"
  },
  {
    "arxiv_id": "2405.02568v2",
    "title": "Active Neural 3D Reconstruction with Colorized Surface Voxel-based View Selection",
    "authors": [
      "Hyunseo Kim",
      "Hyeonseo Yang",
      "Taekyung Kim",
      "YoonSung Kim",
      "Jin-Hwa Kim",
      "Byoung-Tak Zhang"
    ],
    "abstract": "Active view selection in 3D scene reconstruction has been widely studied\nsince training on informative views is critical for reconstruction. Recently,\nNeural Radiance Fields (NeRF) variants have shown promising results in active\n3D reconstruction using uncertainty-guided view selection. They utilize\nuncertainties estimated with neural networks that encode scene geometry and\nappearance. However, the choice of uncertainty integration methods, either\nvoxel-based or neural rendering, has conventionally depended on the types of\nscene uncertainty being estimated, whether geometric or appearance-related. In\nthis paper, we introduce Colorized Surface Voxel (CSV)-based view selection, a\nnew next-best view (NBV) selection method exploiting surface voxel-based\nmeasurement of uncertainty in scene appearance. CSV encapsulates the\nuncertainty of estimated scene appearance (e.g., color uncertainty) and\nestimated geometric information (e.g., surface). Using the geometry\ninformation, we interpret the uncertainty of scene appearance 3D-wise during\nthe aggregation of the per-voxel uncertainty. Consequently, the uncertainty\nfrom occluded and complex regions is recognized under challenging scenarios\nwith limited input data. Our method outperforms previous works on popular\ndatasets, DTU and Blender, and our new dataset with imbalanced viewpoints,\nshowing that the CSV-based view selection significantly improves performance by\nup to 30%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "New experiments with newly published dataset are added. The main\n  claims are the same as in the previous version, but the naming and\n  explanations have been changed",
    "pdf_url": "http://arxiv.org/pdf/2405.02568v2",
    "published_date": "2024-05-04 05:01:58 UTC",
    "updated_date": "2024-06-10 17:05:28 UTC"
  },
  {
    "arxiv_id": "2405.02564v1",
    "title": "Leveraging the Human Ventral Visual Stream to Improve Neural Network Robustness",
    "authors": [
      "Zhenan Shao",
      "Linjian Ma",
      "Bo Li",
      "Diane M. Beck"
    ],
    "abstract": "Human object recognition exhibits remarkable resilience in cluttered and\ndynamic visual environments. In contrast, despite their unparalleled\nperformance across numerous visual tasks, Deep Neural Networks (DNNs) remain\nfar less robust than humans, showing, for example, a surprising susceptibility\nto adversarial attacks involving image perturbations that are (almost)\nimperceptible to humans. Human object recognition likely owes its robustness,\nin part, to the increasingly resilient representations that emerge along the\nhierarchy of the ventral visual cortex. Here we show that DNNs, when guided by\nneural representations from a hierarchical sequence of regions in the human\nventral visual stream, display increasing robustness to adversarial attacks.\nThese neural-guided models also exhibit a gradual shift towards more human-like\ndecision-making patterns and develop hierarchically smoother decision surfaces.\nImportantly, the resulting representational spaces differ in important ways\nfrom those produced by conventional smoothing methods, suggesting that such\nneural-guidance may provide previously unexplored robustness solutions. Our\nfindings support the gradual emergence of human robustness along the ventral\nvisual hierarchy and suggest that the key to DNN robustness may lie in\nincreasing emulation of the human brain.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02564v1",
    "published_date": "2024-05-04 04:33:20 UTC",
    "updated_date": "2024-05-04 04:33:20 UTC"
  },
  {
    "arxiv_id": "2406.17781v1",
    "title": "Large Language Models estimate fine-grained human color-concept associations",
    "authors": [
      "Kushin Mukherjee",
      "Timothy T. Rogers",
      "Karen B. Schloss"
    ],
    "abstract": "Concepts, both abstract and concrete, elicit a distribution of association\nstrengths across perceptual color space, which influence aspects of visual\ncognition ranging from object recognition to interpretation of information\nvisualizations. While prior work has hypothesized that color-concept\nassociations may be learned from the cross-modal statistical structure of\nexperience, it has been unclear whether natural environments possess such\nstructure or, if so, whether learning systems are capable of discovering and\nexploiting it without strong prior constraints. We addressed these questions by\ninvestigating the ability of GPT-4, a multimodal large language model, to\nestimate human-like color-concept associations without any additional training.\nStarting with human color-concept association ratings for 71 color set spanning\nperceptual color space (\\texttt{UW-71}) and concepts that varied in\nabstractness, we assessed how well association ratings generated by GPT-4 could\npredict human ratings. GPT-4 ratings were correlated with human ratings, with\nperformance comparable to state-of-the-art methods for automatically estimating\ncolor-concept associations from images. Variability in GPT-4's performance\nacross concepts could be explained by specificity of the concept's\ncolor-concept association distribution. This study suggests that high-order\ncovariances between language and perception, as expressed in the natural\nenvironment of the internet, contain sufficient information to support learning\nof human-like color-concept associations, and provides an existence proof that\na learning system can encode such associations without initial constraints. The\nwork further shows that GPT-4 can be used to efficiently estimate distributions\nof color associations for a broad range of concepts, potentially serving as a\ncritical tool for designing effective and intuitive information visualizations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17781v1",
    "published_date": "2024-05-04 04:19:15 UTC",
    "updated_date": "2024-05-04 04:19:15 UTC"
  },
  {
    "arxiv_id": "2405.02559v2",
    "title": "A Framework for Human Evaluation of Large Language Models in Healthcare Derived from Literature Review",
    "authors": [
      "Thomas Yu Chow Tam",
      "Sonish Sivarajkumar",
      "Sumit Kapoor",
      "Alisa V Stolyar",
      "Katelyn Polanska",
      "Karleigh R McCarthy",
      "Hunter Osterhoudt",
      "Xizhi Wu",
      "Shyam Visweswaran",
      "Sunyang Fu",
      "Piyush Mathur",
      "Giovanni E. Cacciamani",
      "Cong Sun",
      "Yifan Peng",
      "Yanshan Wang"
    ],
    "abstract": "With generative artificial intelligence (AI), particularly large language\nmodels (LLMs), continuing to make inroads in healthcare, it is critical to\nsupplement traditional automated evaluations with human evaluations.\nUnderstanding and evaluating the output of LLMs is essential to assuring\nsafety, reliability, and effectiveness. However, human evaluation's cumbersome,\ntime-consuming, and non-standardized nature presents significant obstacles to\ncomprehensive evaluation and widespread adoption of LLMs in practice. This\nstudy reviews existing literature on human evaluation methodologies for LLMs in\nhealthcare. We highlight a notable need for a standardized and consistent human\nevaluation approach. Our extensive literature search, adhering to the Preferred\nReporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines,\nincludes publications from January 2018 to February 2024. The review examines\nthe human evaluation of LLMs across various medical specialties, addressing\nfactors such as evaluation dimensions, sample types and sizes, selection, and\nrecruitment of evaluators, frameworks and metrics, evaluation process, and\nstatistical analysis type. Drawing on the diverse evaluation strategies\nemployed in these studies, we propose a comprehensive and practical framework\nfor human evaluation of LLMs: QUEST: Quality of Information, Understanding and\nReasoning, Expression Style and Persona, Safety and Harm, and Trust and\nConfidence. This framework aims to improve the reliability, generalizability,\nand applicability of human evaluation of LLMs in different healthcare\napplications by defining clear evaluation dimensions and offering detailed\nguidelines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02559v2",
    "published_date": "2024-05-04 04:16:07 UTC",
    "updated_date": "2024-09-23 18:00:20 UTC"
  },
  {
    "arxiv_id": "2405.06673v2",
    "title": "Overview of the EHRSQL 2024 Shared Task on Reliable Text-to-SQL Modeling on Electronic Health Records",
    "authors": [
      "Gyubok Lee",
      "Sunjun Kweon",
      "Seongsu Bae",
      "Edward Choi"
    ],
    "abstract": "Electronic Health Records (EHRs) are relational databases that store the\nentire medical histories of patients within hospitals. They record numerous\naspects of patients' medical care, from hospital admission and diagnosis to\ntreatment and discharge. While EHRs are vital sources of clinical data,\nexploring them beyond a predefined set of queries requires skills in query\nlanguages like SQL. To make information retrieval more accessible, one strategy\nis to build a question-answering system, possibly leveraging text-to-SQL models\nthat can automatically translate natural language questions into corresponding\nSQL queries and use these queries to retrieve the answers. The EHRSQL 2024\nshared task aims to advance and promote research in developing a\nquestion-answering system for EHRs using text-to-SQL modeling, capable of\nreliably providing requested answers to various healthcare professionals to\nimprove their clinical work processes and satisfy their needs. Among more than\n100 participants who applied to the shared task, eight teams were formed and\ncompleted the entire shared task requirement and demonstrated a wide range of\nmethods to effectively solve this task. In this paper, we describe the task of\nreliable text-to-SQL modeling, the dataset, and the methods and results of the\nparticipants. We hope this shared task will spur further research and insights\ninto developing reliable question-answering systems for EHRs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The 6th Clinical Natural Language Processing Workshop at NAACL 2024;\n  Minor Change from Camera-Ready",
    "pdf_url": "http://arxiv.org/pdf/2405.06673v2",
    "published_date": "2024-05-04 04:12:18 UTC",
    "updated_date": "2024-05-23 17:25:21 UTC"
  },
  {
    "arxiv_id": "2405.02548v1",
    "title": "CNN-LSTM and Transfer Learning Models for Malware Classification based on Opcodes and API Calls",
    "authors": [
      "Ahmed Bensaoud",
      "Jugal Kalita"
    ],
    "abstract": "In this paper, we propose a novel model for a malware classification system\nbased on Application Programming Interface (API) calls and opcodes, to improve\nclassification accuracy. This system uses a novel design of combined\nConvolutional Neural Network and Long Short-Term Memory. We extract opcode\nsequences and API Calls from Windows malware samples for classification. We\ntransform these features into N-grams (N = 2, 3, and 10)-gram sequences. Our\nexperiments on a dataset of 9,749,57 samples produce high accuracy of 99.91%\nusing the 8-gram sequences. Our method significantly improves the malware\nclassification performance when using a wide range of recent deep learning\narchitectures, leading to state-of-the-art performance. In particular, we\nexperiment with ConvNeXt-T, ConvNeXt-S, RegNetY-4GF, RegNetY-8GF, RegNetY-12GF,\nEfficientNetV2, Sequencer2D-L, Swin-T, ViT-G/14, ViT-Ti, ViT-S, VIT-B, VIT-L,\nand MaxViT-B. Among these architectures, Swin-T and Sequencer2D-L architectures\nachieved high accuracies of 99.82% and 99.70%, respectively, comparable to our\nCNN-LSTM architecture although not surpassing it.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02548v1",
    "published_date": "2024-05-04 03:13:13 UTC",
    "updated_date": "2024-05-04 03:13:13 UTC"
  },
  {
    "arxiv_id": "2405.02545v1",
    "title": "Prediction of Space Weather Events through Analysis of Active Region Magnetograms using Convolutional Neural Network",
    "authors": [
      "Shlesh Sakpal"
    ],
    "abstract": "Although space weather events may not directly affect human life, they have\nthe potential to inflict significant harm upon our communities. Harmful space\nweather events can trigger atmospheric changes that result in physical and\neconomic damages on a global scale. In 1989, Earth experienced the effects of a\npowerful geomagnetic storm that caused satellites to malfunction, while\ntriggering power blackouts in Canada, along with electricity disturbances in\nthe United States and Europe. With the solar cycle peak rapidly approaching,\nthere is an ever-increasing need to prepare and prevent the damages that can\noccur, especially to modern-day technology, calling for the need of a\ncomprehensive prediction system. This study aims to leverage machine learning\ntechniques to predict instances of space weather (solar flares, coronal mass\nejections, geomagnetic storms), based on active region magnetograms of the Sun.\nThis was done through the use of the NASA DONKI service to determine when these\nsolar events occur, then using data from the NASA Solar Dynamics Observatory to\ncompile a dataset that includes magnetograms of active regions of the Sun 24\nhours before the events. By inputting the magnetograms into a convolutional\nneural network (CNN) trained from this dataset, it can serve to predict whether\na space weather event will occur, and what type of event it will be. The model\nwas designed using a custom architecture CNN, and returned an accuracy of\n90.27%, a precision of 85.83%, a recall of 91.78%, and an average F1 score of\n92.14% across each class (Solar flare [Flare], geomagnetic storm [GMS], coronal\nmass ejection [CME]). Our results show that using magnetogram data as an input\nfor a CNN is a viable method to space weather prediction. Future work can\ninvolve prediction of the magnitude of solar events.",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.SR",
    "comment": "6 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.02545v1",
    "published_date": "2024-05-04 03:04:51 UTC",
    "updated_date": "2024-05-04 03:04:51 UTC"
  }
]