[
  {
    "arxiv_id": "2411.16007v1",
    "title": "Performance Implications of Multi-Chiplet Neural Processing Units on Autonomous Driving Perception",
    "authors": [
      "Mohanad Odema",
      "Luke Chen",
      "Hyoukjun Kwon",
      "Mohammad Abdullah Al Faruque"
    ],
    "abstract": "We study the application of emerging chiplet-based Neural Processing Units to\naccelerate vehicular AI perception workloads in constrained automotive\nsettings. The motivation stems from how chiplets technology is becoming\nintegral to emerging vehicular architectures, providing a cost-effective\ntrade-off between performance, modularity, and customization; and from\nperception models being the most computationally demanding workloads in a\nautonomous driving system. Using the Tesla Autopilot perception pipeline as a\ncase study, we first breakdown its constituent models and profile their\nperformance on different chiplet accelerators. From the insights, we propose a\nnovel scheduling strategy to efficiently deploy perception workloads on\nmulti-chip AI accelerators. Our experiments using a standard DNN performance\nsimulator, MAESTRO, show our approach realizes 82% and 2.8x increase in\nthroughput and processing engines utilization compared to monolithic\naccelerator designs.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.AR",
    "comment": "DATE'2025",
    "pdf_url": "http://arxiv.org/pdf/2411.16007v1",
    "published_date": "2024-11-24 22:59:11 UTC",
    "updated_date": "2024-11-24 22:59:11 UTC"
  },
  {
    "arxiv_id": "2411.16003v1",
    "title": "eFedLLM: Efficient LLM Inference Based on Federated Learning",
    "authors": [
      "Shengwen Ding",
      "Chenhui Hu"
    ],
    "abstract": "Large Language Models (LLMs) herald a transformative era in artificial\nintelligence (AI). However, the expansive scale of data and parameters of LLMs\nrequires high-demand computational and memory resources, restricting their\naccessibility to a broader range of users and researchers. This paper\nintroduces an effective approach that enhances the operational efficiency and\naffordability of LLM inference. By utilizing transformer-based federated\nlearning (FL) with model-parallel distributed training, our model efficiently\ndistributes the computational loads and memory requirements across a network of\nparticipants. This strategy permits users, especially those with limited\nresources to train state-of-the-art LLMs collaboratively. We also innovate an\nincentive mechanism within the FL framework, rewarding constructive\ncontributions and filtering out malicious activities, thereby safeguarding the\nintegrity and reliability of the training process. Concurrently, we leverage\nmemory hierarchy strategies and Singular Value Decomposition (SVD) on weight\nmatrices to boost computational and memory efficiencies further. Our results,\nderived from formulaic analyses and numerical calculations, demonstrate\nsignificant optimization of resource use and democratize access to cutting-edge\nLLMs, ensuring that a wide scale of users can both contribute to and benefit\nfrom these advanced models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16003v1",
    "published_date": "2024-11-24 22:50:02 UTC",
    "updated_date": "2024-11-24 22:50:02 UTC"
  },
  {
    "arxiv_id": "2411.15998v1",
    "title": "PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making",
    "authors": [
      "Jonathan Light",
      "Sixue Xing",
      "Yuanzhe Liu",
      "Weiqin Chen",
      "Min Cai",
      "Xiusi Chen",
      "Guanzhi Wang",
      "Wei Cheng",
      "Yisong Yue",
      "Ziniu Hu"
    ],
    "abstract": "Effective extraction of the world knowledge in LLMs for complex\ndecision-making tasks remains a challenge. We propose a framework PIANIST for\ndecomposing the world model into seven intuitive components conducive to\nzero-shot LLM generation. Given only the natural language description of the\ngame and how input observations are formatted, our method can generate a\nworking world model for fast and efficient MCTS simulation. We show that our\nmethod works well on two different games that challenge the planning and\ndecision making skills of the agent for both language and non-language based\naction taking, without any training on domain-specific training data or\nexplicitly defined world model.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at Language Gamification Workshop 2024 @ NeurIPS",
    "pdf_url": "http://arxiv.org/pdf/2411.15998v1",
    "published_date": "2024-11-24 22:36:34 UTC",
    "updated_date": "2024-11-24 22:36:34 UTC"
  },
  {
    "arxiv_id": "2411.15997v1",
    "title": "Ensuring Fair LLM Serving Amid Diverse Applications",
    "authors": [
      "Redwan Ibne Seraj Khan",
      "Kunal Jain",
      "Haiying Shen",
      "Ankur Mallick",
      "Anjaly Parayil",
      "Anoop Kulkarni",
      "Steve Kofsky",
      "Pankhuri Choudhary",
      "Renèe St. Amant",
      "Rujia Wang",
      "Yue Cheng",
      "Ali R. Butt",
      "Victor Rühle",
      "Chetan Bansal",
      "Saravan Rajmohan"
    ],
    "abstract": "In a multi-tenant large language model (LLM) serving platform hosting diverse\napplications, some users may submit an excessive number of requests, causing\nthe service to become unavailable to other users and creating unfairness.\nExisting fairness approaches do not account for variations in token lengths\nacross applications and multiple LLM calls, making them unsuitable for such\nplatforms. To address the fairness challenge, this paper analyzes millions of\nrequests from thousands of users on MS CoPilot, a real-world multi-tenant LLM\nplatform hosted by Microsoft. Our analysis confirms the inadequacy of existing\nmethods and guides the development of FairServe, a system that ensures fair LLM\naccess across diverse applications. FairServe proposes\napplication-characteristic aware request throttling coupled with a weighted\nservice counter based scheduling technique to curb abusive behavior and ensure\nfairness. Our experimental results on real-world traces demonstrate FairServe's\nsuperior performance compared to the state-of-the-art method in ensuring\nfairness. We are actively working on deploying our system in production,\nexpecting to benefit millions of customers world-wide.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15997v1",
    "published_date": "2024-11-24 22:35:44 UTC",
    "updated_date": "2024-11-24 22:35:44 UTC"
  },
  {
    "arxiv_id": "2411.15982v1",
    "title": "Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format",
    "authors": [
      "Chao Fang",
      "Man Shi",
      "Robin Geens",
      "Arne Symons",
      "Zhongfeng Wang",
      "Marian Verhelst"
    ],
    "abstract": "The widely-used, weight-only quantized large language models (LLMs), which\nleverage low-bit integer (INT) weights and retain floating-point (FP)\nactivations, reduce storage requirements while maintaining accuracy. However,\nthis shifts the energy and latency bottlenecks towards the FP activations that\nare associated with costly memory accesses and computations. Existing LLM\naccelerators focus primarily on computation optimizations, overlooking the\npotential of jointly optimizing FP computations and data movement, particularly\nfor the dominant FP-INT GeMM operations in LLM inference.\n  To address these challenges, we investigate the sensitivity of activation\nprecision across various LLM modules and its impact on overall model accuracy.\nBased on our findings, we first propose the Anda data type: an adaptive data\nformat with group-shared exponent bits and dynamic mantissa bit allocation.\nSecondly, we develop an iterative post-training adaptive precision search\nalgorithm that optimizes the bit-width for different LLM modules to balance\nmodel accuracy, energy efficiency, and inference speed. Lastly, a suite of\nhardware optimization techniques is proposed to maximally exploit the benefits\nof the Anda format. These include a bit-plane-based data organization scheme,\nAnda-enhanced processing units with bit-serial computation, and a runtime\nbit-plane Anda compressor to simultaneously optimize storage, computation, and\nmemory footprints. Our evaluations on FPINT GeMM operations show that Anda\nachieves a 2.4x speedup, 4.0x area efficiency, and 3.1x energy efficiency\nimprovement on average for popular LLMs including OPT, LLaMA, and LLaMA-2\nseries over the GPU-like FP-FP baseline. Anda demonstrates strong adaptability\nacross various application scenarios, accuracy requirements, and system\nperformance, enabling efficient LLM inference across a wide range of deployment\nscenarios.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "To appear in 2025 IEEE International Symposium on High-Performance\n  Computer Architecture (HPCA 2025)",
    "pdf_url": "http://arxiv.org/pdf/2411.15982v1",
    "published_date": "2024-11-24 20:59:39 UTC",
    "updated_date": "2024-11-24 20:59:39 UTC"
  },
  {
    "arxiv_id": "2411.16763v1",
    "title": "Hide in Plain Sight: Clean-Label Backdoor for Auditing Membership Inference",
    "authors": [
      "Depeng Chen",
      "Hao Chen",
      "Hulin Jin",
      "Jie Cui",
      "Hong Zhong"
    ],
    "abstract": "Membership inference attacks (MIAs) are critical tools for assessing privacy\nrisks and ensuring compliance with regulations like the General Data Protection\nRegulation (GDPR). However, their potential for auditing unauthorized use of\ndata remains under explored. To bridge this gap, we propose a novel clean-label\nbackdoor-based approach for MIAs, designed specifically for robust and stealthy\ndata auditing. Unlike conventional methods that rely on detectable poisoned\nsamples with altered labels, our approach retains natural labels, enhancing\nstealthiness even at low poisoning rates. Our approach employs an optimal\ntrigger generated by a shadow model that mimics the target model's behavior.\nThis design minimizes the feature-space distance between triggered samples and\nthe source class while preserving the original data labels. The result is a\npowerful and undetectable auditing mechanism that overcomes limitations of\nexisting approaches, such as label inconsistencies and visual artifacts in\npoisoned samples. The proposed method enables robust data auditing through\nblack-box access, achieving high attack success rates across diverse datasets\nand model architectures. Additionally, it addresses challenges related to\ntrigger stealthiness and poisoning durability, establishing itself as a\npractical and effective solution for data auditing. Comprehensive experiments\nvalidate the efficacy and generalizability of our approach, outperforming\nseveral baseline methods in both stealth and attack success metrics.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16763v1",
    "published_date": "2024-11-24 20:56:18 UTC",
    "updated_date": "2024-11-24 20:56:18 UTC"
  },
  {
    "arxiv_id": "2411.15976v2",
    "title": "DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation",
    "authors": [
      "Ruiqiang Xiao",
      "Songning Lai",
      "Yijun Yang",
      "Jiemin Wu",
      "Yutao Yue",
      "Lei Zhu"
    ],
    "abstract": "Adapting machine learning models to new domains without labeled data,\nespecially when source data is inaccessible, is a critical challenge in\napplications like medical imaging, autonomous driving, and remote sensing. This\ntask, known as Source-Free Unsupervised Domain Adaptation (SFUDA), involves\nadapting a pre-trained model to a target domain using only unlabeled target\ndata, which can lead to issues such as overfitting, underfitting, and poor\ngeneralization due to domain discrepancies and noise. Existing SFUDA methods\noften rely on single-model architectures, struggling with uncertainty and\nvariability in the target domain. To address these challenges, we propose DRIVE\n(Dual-Robustness through Information Variability and Entropy), a novel SFUDA\nframework leveraging a dual-model architecture. The two models, initialized\nwith identical weights, work in parallel to capture diverse target domain\ncharacteristics. One model is exposed to perturbations via projection gradient\ndescent (PGD) guided by mutual information, focusing on high-uncertainty\nregions. We also introduce an entropy-aware pseudo-labeling strategy that\nadjusts label weights based on prediction uncertainty, ensuring the model\nfocuses on reliable data while avoiding noisy regions. The adaptation process\nhas two stages: the first aligns the models on stable features using a mutual\ninformation consistency loss, and the second dynamically adjusts the\nperturbation level based on the loss from the first stage, encouraging the\nmodel to explore a broader range of the target domain while preserving existing\nperformance. This enhances generalization capabilities and robustness against\ninterference. Evaluations on standard SFUDA benchmarks show that DRIVE\nconsistently outperforms previous methods, delivering improved adaptation\naccuracy and stability across complex target domains.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15976v2",
    "published_date": "2024-11-24 20:35:04 UTC",
    "updated_date": "2024-12-23 09:01:29 UTC"
  },
  {
    "arxiv_id": "2411.15971v1",
    "title": "Advancing Transformative Education: Generative AI as a Catalyst for Equity and Innovation",
    "authors": [
      "Chiranjeevi Bura",
      "Praveen Kumar Myakala"
    ],
    "abstract": "Generative AI is transforming education by enabling personalized learning,\nenhancing administrative efficiency, and fostering creative engagement. This\npaper explores the opportunities and challenges these tools bring to pedagogy,\nproposing actionable frameworks to address existing equity gaps. Ethical\nconsiderations such as algorithmic bias, data privacy, and AI role in human\ncentric education are emphasized. The findings underscore the need for\nresponsible AI integration that ensures accessibility, equity, and innovation\nin educational systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.15971v1",
    "published_date": "2024-11-24 19:53:48 UTC",
    "updated_date": "2024-11-24 19:53:48 UTC"
  },
  {
    "arxiv_id": "2411.15951v1",
    "title": "Partial Identifiability and Misspecification in Inverse Reinforcement Learning",
    "authors": [
      "Joar Skalse",
      "Alessandro Abate"
    ],
    "abstract": "The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function\n$R$ from a policy $\\pi$. This problem is difficult, for several reasons. First\nof all, there are typically multiple reward functions which are compatible with\na given policy; this means that the reward function is only *partially\nidentifiable*, and that IRL contains a certain fundamental degree of ambiguity.\nSecondly, in order to infer $R$ from $\\pi$, an IRL algorithm must have a\n*behavioural model* of how $\\pi$ relates to $R$. However, the true relationship\nbetween human preferences and human behaviour is very complex, and practically\nimpossible to fully capture with a simple model. This means that the\nbehavioural model in practice will be *misspecified*, which raises the worry\nthat it might lead to unsound inferences if applied to real-world data. In this\npaper, we provide a comprehensive mathematical analysis of partial\nidentifiability and misspecification in IRL. Specifically, we fully\ncharacterise and quantify the ambiguity of the reward function for all of the\nbehavioural models that are most common in the current IRL literature. We also\nprovide necessary and sufficient conditions that describe precisely how the\nobserved demonstrator policy may differ from each of the standard behavioural\nmodels before that model leads to faulty inferences about the reward function\n$R$. In addition to this, we introduce a cohesive framework for reasoning about\npartial identifiability and misspecification in IRL, together with several\nformal tools that can be used to easily derive the partial identifiability and\nmisspecification robustness of new IRL models, or analyse other kinds of reward\nlearning algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15951v1",
    "published_date": "2024-11-24 18:35:46 UTC",
    "updated_date": "2024-11-24 18:35:46 UTC"
  },
  {
    "arxiv_id": "2412.00056v1",
    "title": "Improving Medical Diagnostics with Vision-Language Models: Convex Hull-Based Uncertainty Analysis",
    "authors": [
      "Ferhat Ozgur Catak",
      "Murat Kuzlu",
      "Taylor Patrick"
    ],
    "abstract": "In recent years, vision-language models (VLMs) have been applied to various\nfields, including healthcare, education, finance, and manufacturing, with\nremarkable performance. However, concerns remain regarding VLMs' consistency\nand uncertainty, particularly in critical applications such as healthcare,\nwhich demand a high level of trust and reliability. This paper proposes a novel\napproach to evaluate uncertainty in VLMs' responses using a convex hull\napproach on a healthcare application for Visual Question Answering (VQA).\nLLM-CXR model is selected as the medical VLM utilized to generate responses for\na given prompt at different temperature settings, i.e., 0.001, 0.25, 0.50,\n0.75, and 1.00. According to the results, the LLM-CXR VLM shows a high\nuncertainty at higher temperature settings. Experimental outcomes emphasize the\nimportance of uncertainty in VLMs' responses, especially in healthcare\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.00056v1",
    "published_date": "2024-11-24 17:49:48 UTC",
    "updated_date": "2024-11-24 17:49:48 UTC"
  },
  {
    "arxiv_id": "2411.15927v3",
    "title": "Generative Prompt Internalization",
    "authors": [
      "Haebin Shin",
      "Lei Ji",
      "Yeyun Gong",
      "Sungdong Kim",
      "Eunbi Choi",
      "Minjoon Seo"
    ],
    "abstract": "Prompts used in recent large language model based applications are often\nfixed and lengthy, leading to significant computational overhead. To address\nthis challenge, we propose Generative Prompt Internalization (GenPI), a\nlightweight method that employs a joint training approach. GenPI not only\nreplicates the behavior of models with prompt inputs but also generates the\ncontent of the prompt along with reasons for why the model's behavior should\nchange accordingly. We demonstrate that our approach effectively internalizes\ncomplex prompts across various agent-based application scenarios. For effective\ntraining without interactions with the dedicated environments, we introduce a\ndata synthesis technique that autonomously collects conversational datasets by\nswapping the roles of the agent and environment. This method is especially\nuseful in scenarios where only a predefined prompt is available without a\ncorresponding training dataset. By internalizing complex prompts, Generative\nPrompt Internalization enables high performance and efficient inference without\nthe need for explicit prompts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 (Main Conference)",
    "pdf_url": "http://arxiv.org/pdf/2411.15927v3",
    "published_date": "2024-11-24 17:32:20 UTC",
    "updated_date": "2025-03-25 00:38:02 UTC"
  },
  {
    "arxiv_id": "2411.15925v1",
    "title": "Making Images from Images: Interleaving Denoising and Transformation",
    "authors": [
      "Shumeet Baluja",
      "David Marwood",
      "Ashwin Baluja"
    ],
    "abstract": "Simply by rearranging the regions of an image, we can create a new image of\nany subject matter. The definition of regions is user definable, ranging from\nregularly and irregularly-shaped blocks, concentric rings, or even individual\npixels. Our method extends and improves recent work in the generation of\noptical illusions by simultaneously learning not only the content of the\nimages, but also the parameterized transformations required to transform the\ndesired images into each other. By learning the image transforms, we allow any\nsource image to be pre-specified; any existing image (e.g. the Mona Lisa) can\nbe transformed to a novel subject. We formulate this process as a constrained\noptimization problem and address it through interleaving the steps of image\ndiffusion with an energy minimization step. Unlike previous methods, increasing\nthe number of regions actually makes the problem easier and improves results.\nWe demonstrate our approach in both pixel and latent spaces. Creative\nextensions, such as using infinite copies of the source image and employing\nmultiple source images, are also given.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15925v1",
    "published_date": "2024-11-24 17:13:11 UTC",
    "updated_date": "2024-11-24 17:13:11 UTC"
  },
  {
    "arxiv_id": "2411.15923v1",
    "title": "Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan",
    "authors": [
      "Saba Zahid",
      "Sajid Ghuffar",
      "Obaid-ur-Rehman",
      "Syed Roshaan Ali Shah"
    ],
    "abstract": "This study explores the effectiveness of multi-temporal satellite imagery for\nbetter functional field boundary delineation using deep learning semantic\nsegmentation architecture on two distinct geographical and multi-scale farming\nsystems of Netherlands and Pakistan. Multidate images of April, August and\nOctober 2022 were acquired for PlanetScope and Sentinel-2 in sub regions of\nNetherlands and November 2022, February and March 2023 for selected area of\nDunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP)\nvector layer was used as labeled training data. while self-crafted field\nboundary vector data were utilized for Pakistan. Four deep learning models with\nUNET architecture were evaluated using different combinations of multi-date\nimages and NDVI stacks in the Netherlands subregions. A comparative analysis of\nIoU scores assessed the effectiveness of the proposed multi-date NDVI stack\napproach. These findings were then applied for transfer learning, using\npre-trained models from the Netherlands on the selected area in Pakistan.\nAdditionally, separate models were trained using self-crafted field boundary\ndata for Pakistan, and combined models were developed using data from both the\nNetherlands and Pakistan. Results indicate that multi-date NDVI stacks provide\nadditional temporal context, reflecting crop growth over different times of the\nseason. The study underscores the critical role of multi-scale ground\ninformation from diverse geographical areas in developing robust and\nuniversally applicable models for field boundary delineation. The results also\nhighlight the importance of fine spatial resolution for extraction of field\nboundaries in regions with small scale framing. The findings can be extended to\nmulti-scale implementations for improved automatic field boundary delineation\nin heterogeneous agricultural environments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "09 pages, To be published",
    "pdf_url": "http://arxiv.org/pdf/2411.15923v1",
    "published_date": "2024-11-24 17:10:36 UTC",
    "updated_date": "2024-11-24 17:10:36 UTC"
  },
  {
    "arxiv_id": "2411.15913v1",
    "title": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models",
    "authors": [
      "Sooyoung Kim",
      "Joonwoo Kwon",
      "Heehwan Wang",
      "Shinjae Yoo",
      "Yuewei Lin",
      "Jiook Cha"
    ],
    "abstract": "Music style transfer, while offering exciting possibilities for personalized\nmusic generation, often requires extensive training or detailed textual\ndescriptions. This paper introduces a novel training-free approach leveraging\npre-trained Latent Diffusion Models (LDMs). By manipulating the self-attention\nfeatures of the LDM, we effectively transfer the style of reference music onto\ncontent music without additional training. Our method achieves superior style\ntransfer and melody preservation compared to existing methods. This work opens\nnew creative avenues for personalized music generation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Codes will be released upon acceptance",
    "pdf_url": "http://arxiv.org/pdf/2411.15913v1",
    "published_date": "2024-11-24 16:53:34 UTC",
    "updated_date": "2024-11-24 16:53:34 UTC"
  },
  {
    "arxiv_id": "2411.15903v1",
    "title": "Bimanual Grasp Synthesis for Dexterous Robot Hands",
    "authors": [
      "Yanming Shao",
      "Chenxi Xiao"
    ],
    "abstract": "Humans naturally perform bimanual skills to handle large and heavy objects.\nTo enhance robots' object manipulation capabilities, generating effective\nbimanual grasp poses is essential. Nevertheless, bimanual grasp synthesis for\ndexterous hand manipulators remains underexplored. To bridge this gap, we\npropose the BimanGrasp algorithm for synthesizing bimanual grasps on 3D\nobjects. The BimanGrasp algorithm generates grasp poses by optimizing an energy\nfunction that considers grasp stability and feasibility. Furthermore, the\nsynthesized grasps are verified using the Isaac Gym physics simulation engine.\nThese verified grasp poses form the BimanGrasp-Dataset, the first large-scale\nsynthesized bimanual dexterous hand grasp pose dataset to our knowledge. The\ndataset comprises over 150k verified grasps on 900 objects, facilitating the\nsynthesis of bimanual grasps through a data-driven approach. Last, we propose\nBimanGrasp-DDPM, a diffusion model trained on the BimanGrasp-Dataset. This\nmodel achieved a grasp synthesis success rate of 69.87\\% and significant\nacceleration in computational speed compared to BimanGrasp algorithm.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Published in RA-L 24', 8 pages, 9 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.15903v1",
    "published_date": "2024-11-24 16:31:17 UTC",
    "updated_date": "2024-11-24 16:31:17 UTC"
  },
  {
    "arxiv_id": "2411.15895v1",
    "title": "Highly Efficient and Unsupervised Framework for Moving Object Detection in Satellite Videos",
    "authors": [
      "C. Xiao",
      "W. An",
      "Y. Zhang",
      "Z. Su",
      "M. Li",
      "W. Sheng",
      "M. Pietikäinen",
      "L. Liu"
    ],
    "abstract": "Moving object detection in satellite videos (SVMOD) is a challenging task due\nto the extremely dim and small target characteristics. Current learning-based\nmethods extract spatio-temporal information from multi-frame dense\nrepresentation with labor-intensive manual labels to tackle SVMOD, which needs\nhigh annotation costs and contains tremendous computational redundancy due to\nthe severe imbalance between foreground and background regions. In this paper,\nwe propose a highly efficient unsupervised framework for SVMOD. Specifically,\nwe propose a generic unsupervised framework for SVMOD, in which pseudo labels\ngenerated by a traditional method can evolve with the training process to\npromote detection performance. Furthermore, we propose a highly efficient and\neffective sparse convolutional anchor-free detection network by sampling the\ndense multi-frame image form into a sparse spatio-temporal point cloud\nrepresentation and skipping the redundant computation on background regions.\nCoping these two designs, we can achieve both high efficiency (label and\ncomputation efficiency) and effectiveness. Extensive experiments demonstrate\nthat our method can not only process 98.8 frames per second on 1024x1024 images\nbut also achieve state-of-the-art performance. The relabeled dataset and code\nare available at\nhttps://github.com/ChaoXiao12/Moving-object-detection-in-satellite-videos-HiEUM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.15895v1",
    "published_date": "2024-11-24 16:06:42 UTC",
    "updated_date": "2024-11-24 16:06:42 UTC"
  },
  {
    "arxiv_id": "2411.15894v1",
    "title": "Navigating the Effect of Parametrization for Dimensionality Reduction",
    "authors": [
      "Haiyang Huang",
      "Yingfan Wang",
      "Cynthia Rudin"
    ],
    "abstract": "Parametric dimensionality reduction methods have gained prominence for their\nability to generalize to unseen datasets, an advantage that traditional\napproaches typically lack. Despite their growing popularity, there remains a\nprevalent misconception among practitioners about the equivalence in\nperformance between parametric and non-parametric methods. Here, we show that\nthese methods are not equivalent -- parametric methods retain global structure\nbut lose significant local details. To explain this, we provide evidence that\nparameterized approaches lack the ability to repulse negative pairs, and the\nchoice of loss function also has an impact. Addressing these issues, we\ndeveloped a new parametric method, ParamRepulsor, that incorporates Hard\nNegative Mining and a loss function that applies a strong repulsive force. This\nnew method achieves state-of-the-art performance on local structure\npreservation for parametric methods without sacrificing the fidelity of global\nstructural representation. Our code is available at\nhttps://github.com/hyhuang00/ParamRepulsor.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.15894v1",
    "published_date": "2024-11-24 16:05:08 UTC",
    "updated_date": "2024-11-24 16:05:08 UTC"
  },
  {
    "arxiv_id": "2412.05296v1",
    "title": "Revisiting Your Memory: Reconstruction of Affect-Contextualized Memory via EEG-guided Audiovisual Generation",
    "authors": [
      "Joonwoo Kwon",
      "Heehwan Wang",
      "Jinwoo Lee",
      "Sooyoung Kim",
      "Shinjae Yoo",
      "Yuewei Lin",
      "Jiook Cha"
    ],
    "abstract": "In this paper, we introduce RecallAffectiveMemory, a novel task designed to\nreconstruct autobiographical memories through audio-visual generation guided by\naffect extracted from electroencephalogram (EEG) signals. To support this\npioneering task, we present the EEG-AffectiveMemory dataset, which encompasses\ntextual descriptions, visuals, music, and EEG recordings collected during\nmemory recall from nine participants. Furthermore, we propose RYM (Recall Your\nMemory), a three-stage framework for generating synchronized audio-visual\ncontents while maintaining dynamic personal memory affect trajectories.\nExperimental results indicate that our method can faithfully reconstruct\naffect-contextualized audio-visual memory across all subjects, both\nqualitatively and quantitatively, with participants reporting strong affective\nconcordance between their recalled memories and the generated content. Our\napproaches advance affect decoding research and its practical applications in\npersonalized media creation via neural-based affect comprehension.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "Codes and the dataset will be released upon acceptance",
    "pdf_url": "http://arxiv.org/pdf/2412.05296v1",
    "published_date": "2024-11-24 16:04:03 UTC",
    "updated_date": "2024-11-24 16:04:03 UTC"
  },
  {
    "arxiv_id": "2411.15893v1",
    "title": "Distribution-aware Online Continual Learning for Urban Spatio-Temporal Forecasting",
    "authors": [
      "Chengxin Wang",
      "Gary Tan",
      "Swagato Barman Roy",
      "Beng Chin Ooi"
    ],
    "abstract": "Urban spatio-temporal (ST) forecasting is crucial for various urban\napplications such as intelligent scheduling and trip planning. Previous studies\nfocus on modeling ST correlations among urban locations in offline settings,\nwhich often neglect the non-stationary nature of urban ST data, particularly,\ndistribution shifts over time. This oversight can lead to degraded performance\nin real-world scenarios. In this paper, we first analyze the distribution\nshifts in urban ST data, and then introduce DOST, a novel online continual\nlearning framework tailored for ST data characteristics. DOST employs an\nadaptive ST network equipped with a variable-independent adapter to address the\nunique distribution shifts at each urban location dynamically. Further, to\naccommodate the gradual nature of these shifts, we also develop an\nawake-hibernate learning strategy that intermittently fine-tunes the adapter\nduring the online phase to reduce computational overhead. This strategy\nintegrates a streaming memory update mechanism designed for urban ST sequential\ndata, enabling effective network adaptation to new patterns while preventing\ncatastrophic forgetting. Experimental results confirm DOST's superiority over\nstate-of-the-art models on four real-world datasets, providing online forecasts\nwithin an average of 0.1 seconds and achieving a 12.89% reduction in forecast\nerrors compared to baseline models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15893v1",
    "published_date": "2024-11-24 16:03:16 UTC",
    "updated_date": "2024-11-24 16:03:16 UTC"
  },
  {
    "arxiv_id": "2411.16761v2",
    "title": "Is 'Right' Right? Enhancing Object Orientation Understanding in Multimodal Large Language Models through Egocentric Instruction Tuning",
    "authors": [
      "Ji Hyeok Jung",
      "Eun Tae Kim",
      "Seoyeon Kim",
      "Joo Ho Lee",
      "Bumsoo Kim",
      "Buru Chang"
    ],
    "abstract": "Multimodal large language models (MLLMs) act as essential interfaces,\nconnecting humans with AI technologies in multimodal applications. However,\ncurrent MLLMs face challenges in accurately interpreting object orientation in\nimages due to inconsistent orientation annotations in training data, hindering\nthe development of a coherent orientation understanding. To overcome this, we\npropose egocentric instruction tuning, which aligns MLLMs' orientation\nunderstanding with the user's perspective, based on a consistent annotation\nstandard derived from the user's egocentric viewpoint. We first generate\negocentric instruction data that leverages MLLMs' ability to recognize object\ndetails and applies prior knowledge for orientation understanding. Using this\ndata, we perform instruction tuning to enhance the model's capability for\naccurate orientation interpretation. In addition, we introduce EgoOrientBench,\na benchmark that evaluates MLLMs' orientation understanding across three tasks\nusing images collected from diverse domains. Experimental results on this\nbenchmark show that egocentric instruction tuning significantly improves\norientation understanding without compromising overall MLLM performance. The\ninstruction data and benchmark dataset are available on our project page at\nhttps://github.com/jhCOR/EgoOrientBench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR2025 Camera-ready",
    "pdf_url": "http://arxiv.org/pdf/2411.16761v2",
    "published_date": "2024-11-24 15:07:47 UTC",
    "updated_date": "2025-03-29 09:24:00 UTC"
  },
  {
    "arxiv_id": "2411.16760v1",
    "title": "LibraGrad: Balancing Gradient Flow for Universally Better Vision Transformer Attributions",
    "authors": [
      "Faridoun Mehri",
      "Mahdieh Soleymani Baghshah",
      "Mohammad Taher Pilehvar"
    ],
    "abstract": "Why do gradient-based explanations struggle with Transformers, and how can we\nimprove them? We identify gradient flow imbalances in Transformers that violate\nFullGrad-completeness, a critical property for attribution faithfulness that\nCNNs naturally possess. To address this issue, we introduce LibraGrad -- a\ntheoretically grounded post-hoc approach that corrects gradient imbalances\nthrough pruning and scaling of backward paths, without changing the forward\npass or adding computational overhead. We evaluate LibraGrad using three metric\nfamilies: Faithfulness, which quantifies prediction changes under perturbations\nof the most and least relevant features; Completeness Error, which measures\nattribution conservation relative to model outputs; and Segmentation AP, which\nassesses alignment with human perception. Extensive experiments across 8\narchitectures, 4 model sizes, and 4 datasets show that LibraGrad universally\nenhances gradient-based methods, outperforming existing white-box methods --\nincluding Transformer-specific approaches -- across all metrics. We demonstrate\nsuperior qualitative results through two complementary evaluations: precise\ntext-prompted region highlighting on CLIP models and accurate class\ndiscrimination between co-occurring animals on ImageNet-finetuned models -- two\nsettings on which existing methods often struggle. LibraGrad is effective even\non the attention-free MLP-Mixer architecture, indicating potential for\nextension to other modern architectures. Our code is freely available at\nhttps://github.com/NightMachinery/LibraGrad.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16760v1",
    "published_date": "2024-11-24 15:02:52 UTC",
    "updated_date": "2024-11-24 15:02:52 UTC"
  },
  {
    "arxiv_id": "2412.07779v1",
    "title": "Evolution of Thought: Diverse and High-Quality Reasoning via Multi-Objective Optimization",
    "authors": [
      "Biqing Qi",
      "Zhouyi Qian",
      "Yiang Luo",
      "Junqi Gao",
      "Dong Li",
      "Kaiyan Zhang",
      "Bowen Zhou"
    ],
    "abstract": "As multi-modal large language models (MLLMs) are increasingly applied to\ncomplex reasoning tasks, the diversity and quality of reasoning paths become\ncrucial factors affecting their performance. Although current methods aim to\nenhance reasoning quality through path expansion, they often neglect the\ndiversity of reasoning paths and effective information sharing, leading to\nlocal optima and inefficiency. To address these challenges, we propose\nEvolution of Thought (EoT), a multi-objective framework designed to improve\nreasoning by fostering both high-quality and diverse reasoning paths.\nSpecifically, we introduce the Non-dominated Sorting Genetic Algorithm II for\nmulti-objective optimization, utilizing crossover and mutation operators to\npromote greater diversity in reasoning solutions. Additionally, we propose a\nCondensation-Aggregation mechanism to cluster and eliminate redundant paths,\nfacilitate improved information sharing among parent nodes, and ultimately\nenhance both the efficiency and quality of the reasoning process. Validation\nexperiments on various vision-language and language reasoning tasks demonstrate\nthat EoT achieves superior reasoning performance and efficiency compared to\nother competitive baselines. Our study provides a novel perspective on the\ndesign of heuristic reasoning frameworks for MLLMs.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.07779v1",
    "published_date": "2024-11-24 14:59:30 UTC",
    "updated_date": "2024-11-24 14:59:30 UTC"
  },
  {
    "arxiv_id": "2411.15862v4",
    "title": "Do LLMs Really Think Step-by-step In Implicit Reasoning?",
    "authors": [
      "Yijiong Yu"
    ],
    "abstract": "It has been well-known that Chain-of-Thought can remarkably enhance LLMs'\nperformance on complex tasks. However, because it also introduces slower\ninference speeds and higher computational costs, many researches have attempted\nto use implicit CoT, which does not need LLMs to explicitly generate the\nintermediate steps. However, the invisible reasoning process leaves us a doubt\nthat, can implicit CoT really be equal to explicit CoT? Therefore, in this\nstudy, we address this question through experiments. We probe the information\nof intermediate steps from the model's hidden states when it is either trained\nor prompted to perform implicit CoT. The results surprisingly indicate that\nwhen prompted, LLMs hardly think about intermediate steps, suggesting they may\njust rely on experience rather than strict step-by-step reasoning. But when\ntrained, they indeed calculate intermediate steps. Moreover, in both\nsituations, we find the effect of using implicit CoT is susceptible to the\nformat of the problem, reaffirming the current deficiency of implicit CoT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The code is in\n  https://github.com/yuyijiong/if_step_by_step_implicit_CoT",
    "pdf_url": "http://arxiv.org/pdf/2411.15862v4",
    "published_date": "2024-11-24 14:38:59 UTC",
    "updated_date": "2025-01-16 06:07:12 UTC"
  },
  {
    "arxiv_id": "2412.01705v1",
    "title": "Uncertainty-Aware Regularization for Image-to-Image Translation",
    "authors": [
      "Anuja Vats",
      "Ivar Farup",
      "Marius Pedersen",
      "Kiran Raja"
    ],
    "abstract": "The importance of quantifying uncertainty in deep networks has become\nparamount for reliable real-world applications. In this paper, we propose a\nmethod to improve uncertainty estimation in medical Image-to-Image (I2I)\ntranslation. Our model integrates aleatoric uncertainty and employs\nUncertainty-Aware Regularization (UAR) inspired by simple priors to refine\nuncertainty estimates and enhance reconstruction quality. We show that by\nleveraging simple priors on parameters, our approach captures more robust\nuncertainty maps, effectively refining them to indicate precisely where the\nnetwork encounters difficulties, while being less affected by noise. Our\nexperiments demonstrate that UAR not only improves translation performance, but\nalso provides better uncertainty estimations, particularly in the presence of\nnoise and artifacts. We validate our approach using two medical imaging\ndatasets, showcasing its effectiveness in maintaining high confidence in\nfamiliar regions while accurately identifying areas of uncertainty in\nnovel/ambiguous scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01705v1",
    "published_date": "2024-11-24 14:05:27 UTC",
    "updated_date": "2024-11-24 14:05:27 UTC"
  },
  {
    "arxiv_id": "2411.15844v1",
    "title": "Unveiling the Superior Paradigm: A Comparative Study of Source-Free Domain Adaptation and Unsupervised Domain Adaptation",
    "authors": [
      "Fan Wang",
      "Zhongyi Han",
      "Xingbo Liu",
      "Xin Gao",
      "Yilong Yin"
    ],
    "abstract": "In domain adaptation, there are two popular paradigms: Unsupervised Domain\nAdaptation (UDA), which aligns distributions using source data, and Source-Free\nDomain Adaptation (SFDA), which leverages pre-trained source models without\naccessing source data. Evaluating the superiority of UDA versus SFDA is an open\nand timely question with significant implications for deploying adaptive\nalgorithms in practical applications. In this study, we demonstrate through\npredictive coding theory and extensive experiments on multiple benchmark\ndatasets that SFDA generally outperforms UDA in real-world scenarios.\nSpecifically, SFDA offers advantages in time efficiency, storage requirements,\ntargeted learning objectives, reduced risk of negative transfer, and increased\nrobustness against overfitting. Notably, SFDA is particularly effective in\nmitigating negative transfer when there are substantial distribution\ndiscrepancies between source and target domains. Additionally, we introduce a\nnovel data-model fusion scenario, where data sharing among stakeholders varies\n(e.g., some provide raw data while others provide only models), and reveal that\ntraditional UDA and SFDA methods do not fully exploit their potential in this\ncontext. To address this limitation and capitalize on the strengths of SFDA, we\npropose a novel weight estimation method that effectively integrates available\nsource data into multi-SFDA (MSFDA) approaches, thereby enhancing model\nperformance within this scenario. This work provides a thorough analysis of UDA\nversus SFDA and advances a practical approach to model adaptation across\ndiverse real-world environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2411.15844v1",
    "published_date": "2024-11-24 13:49:29 UTC",
    "updated_date": "2024-11-24 13:49:29 UTC"
  },
  {
    "arxiv_id": "2411.15832v2",
    "title": "Creating Scalable AGI: the Open General Intelligence Framework",
    "authors": [
      "Daniel A. Dollinger",
      "Michael Singleton"
    ],
    "abstract": "Recent advancements in Artificial Intelligence (AI), particularly with Large\nLanguage Models (LLMs), have led to significant progress in narrow tasks such\nas image classification, language translation, coding, and writing. However,\nthese models face limitations in reliability and scalability due to their\nsiloed architectures, which are designed to handle only one data modality (data\ntype) at a time. This single modal approach hinders their ability to integrate\nthe complex set of data points required for real-world challenges and\nproblem-solving tasks like medical diagnosis, quality assurance, equipment\ntroubleshooting, and financial decision-making. Addressing these real-world\nchallenges requires a more capable Artificial General Intelligence (AGI)\nsystem. Our primary contribution is the development of the Open General\nIntelligence (OGI) framework, a novel systems architecture that serves as a\nmacro design reference for AGI. The OGI framework adopts a modular approach to\nthe design of intelligent systems, based on the premise that cognition must\noccur across multiple specialized modules that can seamlessly operate as a\nsingle system. OGI integrates these modules using a dynamic processing system\nand a fabric interconnect, enabling real-time adaptability, multi-modal\nintegration, and scalable processing. The OGI framework consists of three key\ncomponents: (1) Overall Macro Design Guidance that directs operational design\nand processing, (2) a Dynamic Processing System that controls routing, primary\ngoals, instructions, and weighting, and (3) Framework Areas, a set of\nspecialized modules that operate cohesively to form a unified cognitive system.\nBy incorporating known principles from human cognition into AI systems, the OGI\nframework aims to overcome the challenges observed in today's intelligent\nsystems, paving the way for more holistic and context-aware problem-solving\ncapabilities.",
    "categories": [
      "cs.AI",
      "I.2; C.5"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, IEEE SYSCON 2025 Submission",
    "pdf_url": "http://arxiv.org/pdf/2411.15832v2",
    "published_date": "2024-11-24 13:17:53 UTC",
    "updated_date": "2024-11-27 19:25:31 UTC"
  },
  {
    "arxiv_id": "2411.15831v1",
    "title": "Efficient and Private: Memorisation under differentially private parameter-efficient fine-tuning in language models",
    "authors": [
      "Olivia Ma",
      "Jonathan Passerat-Palmbach",
      "Dmitrii Usynin"
    ],
    "abstract": "Fine-tuning large language models (LLMs) for specific tasks introduces\nprivacy risks, as models may inadvertently memorise and leak sensitive training\ndata. While Differential Privacy (DP) offers a solution to mitigate these\nrisks, it introduces significant computational and performance trade-offs,\nparticularly with standard fine-tuning approaches. Previous work has primarily\nfocused on full-parameter updates, which are computationally intensive and may\nnot fully leverage DPs potential in large models. In this work, we address\nthese shortcomings by investigating Parameter-Efficient Fine-Tuning (PEFT)\nmethods under DP constraints. We show that PEFT methods achieve comparable\nperformance to standard fine-tuning while requiring fewer parameters and\nsignificantly reducing privacy leakage. Furthermore, we incorporate a data\npoisoning experiment involving intentional mislabelling to assess model\nmemorisation and directly measure privacy risks. Our findings indicate that\nPEFT methods not only provide a promising alternative but also serve as a\ncomplementary approach for privacy-preserving, resource-efficient fine-tuning\nof LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15831v1",
    "published_date": "2024-11-24 13:17:36 UTC",
    "updated_date": "2024-11-24 13:17:36 UTC"
  },
  {
    "arxiv_id": "2411.15821v2",
    "title": "Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?",
    "authors": [
      "Aryan Sajith",
      "Krishna Chaitanya Rao Kathala"
    ],
    "abstract": "This study investigates the relative impact of training data quality versus\nquantity on the performance of small language models (SLMs), utilizing the\nTinyStories dataset for empirical analysis. Analysis of dataset variations with\nrespect to size (25% and 50% of the original size) and duplication (controlled\nrates of 25%, 50%, 75%, and 100%) were performed. Model performance was\nevaluated based on the validation loss, accuracy, and perplexity metrics.\nResults indicate training data quality plays a more significant role in the\noverall performance of SLMs, especially given scale of this experiment. Minimal\nduplication positively impacted model accuracy (+0.87% increase in accuracy at\n25% duplication) without significantly increasing perplexity (+0.52% increase\ngoing from 0% to 25% duplication) but excessive duplication led to pronounced\nperformance degradation (-40% drop in accuracy at 100% duplication). The\nimplications of this exploration extend beyond just model performance; training\nlarge-scale models imposes significant financial and computational burdens,\nwhich can be prohibitive for organizations, individuals, and the public at\nlarge, especially in developing countries. Additionally, the energy consumption\nassociated with large-scale training raises environmental concerns.\nUnderstanding the relative importance of data quality versus quantity could\ndemocratize AI technology, making advanced models more accessible and\nsustainable for all.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.15821v2",
    "published_date": "2024-11-24 12:51:50 UTC",
    "updated_date": "2025-03-28 22:38:02 UTC"
  },
  {
    "arxiv_id": "2412.00053v1",
    "title": "LeMoLE: LLM-Enhanced Mixture of Linear Experts for Time Series Forecasting",
    "authors": [
      "Lingzheng Zhang",
      "Lifeng Shen",
      "Yimin Zheng",
      "Shiyuan Piao",
      "Ziyue Li",
      "Fugee Tsung"
    ],
    "abstract": "Recent research has shown that large language models (LLMs) can be\neffectively used for real-world time series forecasting due to their strong\nnatural language understanding capabilities. However, aligning time series into\nsemantic spaces of LLMs comes with high computational costs and inference\ncomplexity, particularly for long-range time series generation. Building on\nrecent advancements in using linear models for time series, this paper\nintroduces an LLM-enhanced mixture of linear experts for precise and efficient\ntime series forecasting. This approach involves developing a mixture of linear\nexperts with multiple lookback lengths and a new multimodal fusion mechanism.\nThe use of a mixture of linear experts is efficient due to its simplicity,\nwhile the multimodal fusion mechanism adaptively combines multiple linear\nexperts based on the learned features of the text modality from pre-trained\nlarge language models. In experiments, we rethink the need to align time series\nto LLMs by existing time-series large language models and further discuss their\nefficiency and effectiveness in time series forecasting. Our experimental\nresults show that the proposed LeMoLE model presents lower prediction errors\nand higher computational efficiency than existing LLM models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00053v1",
    "published_date": "2024-11-24 12:40:50 UTC",
    "updated_date": "2024-11-24 12:40:50 UTC"
  },
  {
    "arxiv_id": "2411.15811v3",
    "title": "FastTrackTr:Towards Fast Multi-Object Tracking with Transformers",
    "authors": [
      "Pan Liao",
      "Feng Yang",
      "Di Wu",
      "Jinwen Yu",
      "Wenhui Zhao",
      "Bo Liu"
    ],
    "abstract": "Transformer-based multi-object tracking (MOT) methods have captured the\nattention of many researchers in recent years. However, these models often\nsuffer from slow inference speeds due to their structure or other issues. To\naddress this problem, we revisited the Joint Detection and Tracking (JDT)\nmethod by looking back at past approaches. By integrating the original JDT\napproach with some advanced theories, this paper employs an efficient method of\ninformation transfer between frames on the DETR, constructing a fast and novel\nJDT-type MOT framework: FastTrackTr. Thanks to the superiority of this\ninformation transfer method, our approach not only reduces the number of\nqueries required during tracking but also avoids the excessive introduction of\nnetwork structures, ensuring model simplicity. Experimental results indicate\nthat our method has the potential to achieve real-time tracking and exhibits\ncompetitive tracking accuracy across multiple datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15811v3",
    "published_date": "2024-11-24 12:34:02 UTC",
    "updated_date": "2025-03-07 03:39:49 UTC"
  },
  {
    "arxiv_id": "2411.15806v2",
    "title": "Broad Critic Deep Actor Reinforcement Learning for Continuous Control",
    "authors": [
      "Shiron Thalagala",
      "Pak Kin Wong",
      "Xiaozheng Wang",
      "Tianang Sun"
    ],
    "abstract": "In the domain of continuous control, deep reinforcement learning (DRL)\ndemonstrates promising results. However, the dependence of DRL on deep neural\nnetworks (DNNs) results in the demand for extensive data and increased\ncomputational cost. To address this issue, a novel hybrid actor-critic\nreinforcement learning (RL) framework is introduced. The proposed framework\nintegrates the broad learning system (BLS) with DNN, aiming to merge the\nstrengths of both distinct architectural paradigms. Specifically, the critic\nnetwork employs BLS for rapid value estimation via ridge regression, while the\nactor network retains the DNN structure to optimize policy gradients. This\nhybrid design is generalizable and can enhance existing actor-critic\nalgorithms. To demonstrate its versatility, the proposed framework is\nintegrated into three widely used actor-critic algorithms -- deep deterministic\npolicy gradient (DDPG), soft actor-critic (SAC), and twin delayed DDPG (TD3),\nresulting in BLS-augmented variants. Experimental results reveal that all\nBLS-enhanced versions surpass their original counterparts in terms of training\nefficiency and accuracy. These improvements highlight the suitability of the\nproposed framework for real-time control scenarios, where computational\nefficiency and rapid adaptation are critical.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, The final published version is available at:\n  https://ieeexplore.ieee.org/document/10957827 (DOI:\n  10.1109/TNNLS.2025.3554082)",
    "pdf_url": "http://arxiv.org/pdf/2411.15806v2",
    "published_date": "2024-11-24 12:24:46 UTC",
    "updated_date": "2025-04-12 14:53:47 UTC"
  },
  {
    "arxiv_id": "2411.15805v1",
    "title": "Benchmarking Active Learning for NILM",
    "authors": [
      "Dhruv Patel",
      "Ankita Kumari Jain",
      "Haikoo Khandor",
      "Xhitij Choudhary",
      "Nipun Batra"
    ],
    "abstract": "Non-intrusive load monitoring (NILM) focuses on disaggregating total\nhousehold power consumption into appliance-specific usage. Many advanced NILM\nmethods are based on neural networks that typically require substantial amounts\nof labeled appliance data, which can be challenging and costly to collect in\nreal-world settings. We hypothesize that appliance data from all households\ndoes not uniformly contribute to NILM model improvements. Thus, we propose an\nactive learning approach to selectively install appliance monitors in a limited\nnumber of houses. This work is the first to benchmark the use of active\nlearning for strategically selecting appliance-level data to optimize NILM\nperformance. We first develop uncertainty-aware neural networks for NILM and\nthen install sensors in homes where disaggregation uncertainty is highest.\nBenchmarking our method on the publicly available Pecan Street Dataport\ndataset, we demonstrate that our approach significantly outperforms a standard\nrandom baseline and achieves performance comparable to models trained on the\nentire dataset. Using this approach, we achieve comparable NILM accuracy with\napproximately 30% of the data, and for a fixed number of sensors, we observe up\nto a 2x reduction in disaggregation errors compared to random sampling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15805v1",
    "published_date": "2024-11-24 12:22:59 UTC",
    "updated_date": "2024-11-24 12:22:59 UTC"
  },
  {
    "arxiv_id": "2411.15804v1",
    "title": "LoRA-Mini : Adaptation Matrices Decomposition and Selective Training",
    "authors": [
      "Ayush Singh",
      "Rajdeep Aher",
      "Shivank Garg"
    ],
    "abstract": "The rapid advancements in large language models (LLMs) have revolutionized\nnatural language processing, creating an increased need for efficient,\ntask-specific fine-tuning methods. Traditional fine-tuning of LLMs involves\nupdating a large number of parameters, which is computationally expensive and\nmemory-intensive. Low-Rank Adaptation (LoRA) has emerged as a promising\nsolution, enabling parameter-efficient fine-tuning by reducing the number of\ntrainable parameters. However, while LoRA reduces the number of trainable\nparameters, LoRA modules still create significant storage challenges. We\npropose LoRA-Mini, an optimized adaptation of LoRA that improves parameter\nefficiency by splitting low-rank matrices into four parts, with only the two\ninner matrices being trainable. This approach achieves upto a 20x reduction\ncompared to standard LoRA in the number of trainable parameters while\npreserving performance levels comparable to standard LoRA, addressing both\ncomputational and storage efficiency in LLM fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.15804v1",
    "published_date": "2024-11-24 12:21:14 UTC",
    "updated_date": "2024-11-24 12:21:14 UTC"
  },
  {
    "arxiv_id": "2411.15802v1",
    "title": "Medical Slice Transformer: Improved Diagnosis and Explainability on 3D Medical Images with DINOv2",
    "authors": [
      "Gustav Müller-Franzes",
      "Firas Khader",
      "Robert Siepmann",
      "Tianyu Han",
      "Jakob Nikolas Kather",
      "Sven Nebelung",
      "Daniel Truhn"
    ],
    "abstract": "MRI and CT are essential clinical cross-sectional imaging techniques for\ndiagnosing complex conditions. However, large 3D datasets with annotations for\ndeep learning are scarce. While methods like DINOv2 are encouraging for 2D\nimage analysis, these methods have not been applied to 3D medical images.\nFurthermore, deep learning models often lack explainability due to their\n\"black-box\" nature. This study aims to extend 2D self-supervised models,\nspecifically DINOv2, to 3D medical imaging while evaluating their potential for\nexplainable outcomes. We introduce the Medical Slice Transformer (MST)\nframework to adapt 2D self-supervised models for 3D medical image analysis. MST\ncombines a Transformer architecture with a 2D feature extractor, i.e., DINOv2.\nWe evaluate its diagnostic performance against a 3D convolutional neural\nnetwork (3D ResNet) across three clinical datasets: breast MRI (651 patients),\nchest CT (722 patients), and knee MRI (1199 patients). Both methods were tested\nfor diagnosing breast cancer, predicting lung nodule dignity, and detecting\nmeniscus tears. Diagnostic performance was assessed by calculating the Area\nUnder the Receiver Operating Characteristic Curve (AUC). Explainability was\nevaluated through a radiologist's qualitative comparison of saliency maps based\non slice and lesion correctness. P-values were calculated using Delong's test.\nMST achieved higher AUC values compared to ResNet across all three datasets:\nbreast (0.94$\\pm$0.01 vs. 0.91$\\pm$0.02, P=0.02), chest (0.95$\\pm$0.01 vs.\n0.92$\\pm$0.02, P=0.13), and knee (0.85$\\pm$0.04 vs. 0.69$\\pm$0.05, P=0.001).\nSaliency maps were consistently more precise and anatomically correct for MST\nthan for ResNet. Self-supervised 2D models like DINOv2 can be effectively\nadapted for 3D medical imaging using MST, offering enhanced diagnostic accuracy\nand explainability compared to convolutional neural networks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15802v1",
    "published_date": "2024-11-24 12:11:11 UTC",
    "updated_date": "2024-11-24 12:11:11 UTC"
  },
  {
    "arxiv_id": "2411.15801v1",
    "title": "A review on Machine Learning based User-Centric Multimedia Streaming Techniques",
    "authors": [
      "Monalisa Ghosh",
      "Chetna Singhal"
    ],
    "abstract": "The multimedia content and streaming are a major means of information\nexchange in the modern era and there is an increasing demand for such services.\nThis coupled with the advancement of future wireless networks B5G/6G and the\nproliferation of intelligent handheld mobile devices, has facilitated the\navailability of multimedia content to heterogeneous mobile users. Apart from\nthe conventional video, the 360$^o$ videos have gained popularity with the\nemerging virtual reality applications. All formats of videos (conventional and\n360$^o$) undergo processing, compression, and transmission across dynamic\nwireless channels with restricted bandwidth to facilitate the streaming\nservices. This causes video impairments, leading to quality degradation and\nposes challenges in delivering good Quality-of-Experience (QoE) to the viewers.\nThe QoE is a prominent subjective quality measure to assess multimedia\nservices. This requires end-to-end QoE evaluation. Efficient multimedia\nstreaming techniques can improve the service quality while dealing with dynamic\nnetwork and end-user challenges. A paradigm shift in user-centric multimedia\nservices is envisioned with a focus on Machine Learning (ML) based QoE modeling\nand streaming strategies. This survey paper presents a comprehensive overview\nof the overall and continuous, time varying QoE modeling for the purpose of QoE\nmanagement in multimedia services. It also examines the recent research on\nintelligent and adaptive multimedia streaming strategies, with a special\nemphasis on ML based techniques for video (conventional and 360$^o$) streaming.\nThis paper discusses the overall and continuous QoE modeling to optimize the\nend-user viewing experience, efficient video streaming with a focus on\nuser-centric strategies, associated datasets for modeling and streaming, along\nwith existing shortcoming and open challenges.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MM",
    "comment": "Computer Communications",
    "pdf_url": "http://arxiv.org/pdf/2411.15801v1",
    "published_date": "2024-11-24 12:07:47 UTC",
    "updated_date": "2024-11-24 12:07:47 UTC"
  },
  {
    "arxiv_id": "2411.15796v1",
    "title": "Data Lineage Inference: Uncovering Privacy Vulnerabilities of Dataset Pruning",
    "authors": [
      "Qi Li",
      "Cheng-Long Wang",
      "Yinzhi Cao",
      "Di Wang"
    ],
    "abstract": "In this work, we systematically explore the data privacy issues of dataset\npruning in machine learning systems. Our findings reveal, for the first time,\nthat even if data in the redundant set is solely used before model training,\nits pruning-phase membership status can still be detected through attacks.\nSince this is a fully upstream process before model training, traditional model\noutput-based privacy inference methods are completely unsuitable. To address\nthis, we introduce a new task called Data-Centric Membership Inference and\npropose the first ever data-centric privacy inference paradigm named Data\nLineage Inference (DaLI). Under this paradigm, four threshold-based attacks are\nproposed, named WhoDis, CumDis, ArraDis and SpiDis. We show that even without\naccess to downstream models, adversaries can accurately identify the redundant\nset with only limited prior knowledge. Furthermore, we find that different\npruning methods involve varying levels of privacy leakage, and even the same\npruning method can present different privacy risks at different pruning\nfractions. We conducted an in-depth analysis of these phenomena and introduced\na metric called the Brimming score to offer guidance for selecting pruning\nmethods with privacy protection in mind.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15796v1",
    "published_date": "2024-11-24 11:46:59 UTC",
    "updated_date": "2024-11-24 11:46:59 UTC"
  },
  {
    "arxiv_id": "2411.15778v4",
    "title": "Enhancing the automatic segmentation and analysis of 3D liver vasculature models",
    "authors": [
      "Yassine Machta",
      "Omar Ali",
      "Kevin Hakkakian",
      "Ana Vlasceanu",
      "Amaury Facque",
      "Nicolas Golse",
      "Irene Vignon-Clementel"
    ],
    "abstract": "Surgical assessment of liver cancer patients requires identification of the\nvessel trees from medical images. Specifically, the venous trees - the portal\n(perfusing) and the hepatic (draining) trees are important for understanding\nthe liver anatomy and disease state, and perform surgery planning. This\nresearch aims to improve the 3D segmentation, skeletonization, and subsequent\nanalysis of vessel trees, by creating an automatic pipeline based on deep\nlearning and image processing techniques.\n  The first part of this work explores the impact of differentiable\nskeletonization methods such as ClDice and morphological skeletonization loss,\non the overall liver vessel segmentation performance. To this aim, it studies\nhow to improve vessel tree connectivity.\n  The second part of this study converts a single class vessel segmentation\ninto multi-class ones, separating the two venous trees. It builds on the\nprevious two-class vessel segmentation model, which vessel tree outputs might\nbe entangled, and on connected components and skeleton analyses of the trees.\n  After providing sub-labeling of the specific anatomical branches of each\nvenous tree, these algorithms also enable a morphometric analysis of the vessel\ntrees by extracting various geometrical markers.\n  In conclusion, we propose a method that successfully improves current\nskeletonization methods, for extensive vascular trees that contain vessels of\ndifferent calibers. The separation algorithm creates a clean multi-class\nsegmentation of the vessels, validated by surgeons to provide low error. A new,\npublicly shared high-quality liver vessel dataset of 77 cases is thus created.\nFinally a method to annotate vessel trees according to anatomy is provided,\nenabling a unique liver vessel morphometry analysis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Paper presented at MICCAI 2024 Workshop: ADSMI. This work was done in\n  the context of an internship at Simbiotx, Inria",
    "pdf_url": "http://arxiv.org/pdf/2411.15778v4",
    "published_date": "2024-11-24 10:58:48 UTC",
    "updated_date": "2025-03-19 12:48:55 UTC"
  },
  {
    "arxiv_id": "2411.15758v1",
    "title": "Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT",
    "authors": [
      "Siqi Wang",
      "Chao Liang",
      "Yunfan Gao",
      "Yang Liu",
      "Jing Li",
      "Haofen Wang"
    ],
    "abstract": "Industrial parks are critical to urban economic growth. Yet, their\ndevelopment often encounters challenges stemming from imbalances between\nindustrial requirements and urban services, underscoring the need for strategic\nplanning and operations. This paper introduces IndustryScopeKG, a pioneering\nlarge-scale multi-modal, multi-level industrial park knowledge graph, which\nintegrates diverse urban data including street views, corporate,\nsocio-economic, and geospatial information, capturing the complex relationships\nand semantics within industrial parks. Alongside this, we present the\nIndustryScopeGPT framework, which leverages Large Language Models (LLMs) with\nMonte Carlo Tree Search to enhance tool-augmented reasoning and decision-making\nin Industrial Park Planning and Operation (IPPO). Our work significantly\nimproves site recommendation and functional planning, demonstrating the\npotential of combining LLMs with structured datasets to advance industrial park\nmanagement. This approach sets a new benchmark for intelligent IPPO research\nand lays a robust foundation for advancing urban industrial development. The\ndataset and related code are available at\nhttps://github.com/Tongji-KGLLM/IndustryScope.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.SI",
      "I.2.0; I.2.7; H.3.3; H.4.0"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures, the 32nd ACM International Conference on\n  Multimedia",
    "pdf_url": "http://arxiv.org/pdf/2411.15758v1",
    "published_date": "2024-11-24 08:33:19 UTC",
    "updated_date": "2024-11-24 08:33:19 UTC"
  },
  {
    "arxiv_id": "2411.15743v1",
    "title": "Beyond Data Scarcity: A Frequency-Driven Framework for Zero-Shot Forecasting",
    "authors": [
      "Liran Nochumsohn",
      "Michal Moshkovitz",
      "Orly Avner",
      "Dotan Di Castro",
      "Omri Azencot"
    ],
    "abstract": "Time series forecasting is critical in numerous real-world applications,\nrequiring accurate predictions of future values based on observed patterns.\nWhile traditional forecasting techniques work well in in-domain scenarios with\nample data, they struggle when data is scarce or not available at all,\nmotivating the emergence of zero-shot and few-shot learning settings. Recent\nadvancements often leverage large-scale foundation models for such tasks, but\nthese methods require extensive data and compute resources, and their\nperformance may be hindered by ineffective learning from the available training\nset. This raises a fundamental question: What factors influence effective\nlearning from data in time series forecasting? Toward addressing this, we\npropose using Fourier analysis to investigate how models learn from synthetic\nand real-world time series data. Our findings reveal that forecasters commonly\nsuffer from poor learning from data with multiple frequencies and poor\ngeneralization to unseen frequencies, which impedes their predictive\nperformance. To alleviate these issues, we present a novel synthetic data\ngeneration framework, designed to enhance real data or replace it completely by\ncreating task-specific frequency information, requiring only the sampling rate\nof the target data. Our approach, Freq-Synth, improves the robustness of both\nfoundation as well as nonfoundation forecast models in zero-shot and few-shot\nsettings, facilitating more reliable time series forecasting under limited data\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15743v1",
    "published_date": "2024-11-24 07:44:39 UTC",
    "updated_date": "2024-11-24 07:44:39 UTC"
  },
  {
    "arxiv_id": "2411.15742v1",
    "title": "PEnG: Pose-Enhanced Geo-Localisation",
    "authors": [
      "Tavis Shore",
      "Oscar Mendez",
      "Simon Hadfield"
    ],
    "abstract": "Cross-view Geo-localisation is typically performed at a coarse granularity,\nbecause densely sampled satellite image patches overlap heavily. This heavy\noverlap would make disambiguating patches very challenging. However, by opting\nfor sparsely sampled patches, prior work has placed an artificial upper bound\non the localisation accuracy that is possible. Even a perfect oracle system\ncannot achieve accuracy greater than the average separation of the tiles. To\nsolve this limitation, we propose combining cross-view geo-localisation and\nrelative pose estimation to increase precision to a level practical for\nreal-world application. We develop PEnG, a 2-stage system which first predicts\nthe most likely edges from a city-scale graph representation upon which a query\nimage lies. It then performs relative pose estimation within these edges to\ndetermine a precise position. PEnG presents the first technique to utilise both\nviewpoints available within cross-view geo-localisation datasets to enhance\nprecision to a sub-metre level, with some examples achieving centimetre level\naccuracy. Our proposed ensemble achieves state-of-the-art precision - with\nrelative Top-5m retrieval improvements on previous works of 213%. Decreasing\nthe median euclidean distance error by 96.90% from the previous best of 734m\ndown to 22.77m, when evaluating with 90 degree horizontal FOV images. Code will\nbe made available: tavisshore.co.uk/PEnG",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.15742v1",
    "published_date": "2024-11-24 07:42:50 UTC",
    "updated_date": "2024-11-24 07:42:50 UTC"
  },
  {
    "arxiv_id": "2411.15740v1",
    "title": "LTCF-Net: A Transformer-Enhanced Dual-Channel Fourier Framework for Low-Light Image Restoration",
    "authors": [
      "Gaojing Zhang",
      "Jinglun Feng"
    ],
    "abstract": "We introduce LTCF-Net, a novel network architecture designed for enhancing\nlow-light images. Unlike Retinex-based methods, our approach utilizes two color\nspaces - LAB and YUV - to efficiently separate and process color information,\nby leveraging the separation of luminance from chromatic components in color\nimages. In addition, our model incorporates the Transformer architecture to\ncomprehensively understand image content while maintaining computational\nefficiency. To dynamically balance the brightness in output images, we also\nintroduce a Fourier transform module that adjusts the luminance channel in the\nfrequency domain. This mechanism could uniformly balance brightness across\ndifferent regions while eliminating background noises, and thereby enhancing\nvisual quality. By combining these innovative components, LTCF-Net effectively\nimproves low-light image quality while keeping the model lightweight.\nExperimental results demonstrate that our method outperforms current\nstate-of-the-art approaches across multiple evaluation metrics and datasets,\nachieving more natural color restoration and a balanced brightness\ndistribution.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15740v1",
    "published_date": "2024-11-24 07:21:17 UTC",
    "updated_date": "2024-11-24 07:21:17 UTC"
  },
  {
    "arxiv_id": "2411.15737v3",
    "title": "TableTime: Reformulating Time Series Classification as Training-Free Table Understanding with Large Language Models",
    "authors": [
      "Jiahao Wang",
      "Mingyue Cheng",
      "Qingyang Mao",
      "Yitong Zhou",
      "Feiyang Xu",
      "Xin Li"
    ],
    "abstract": "Large language models (LLMs) have demonstrated their effectiveness in\nmultivariate time series classification (MTSC). Effective adaptation of LLMs\nfor MTSC necessitates informative data representations. Existing LLM-based\nmethods directly encode embeddings for time series within the latent space of\nLLMs from scratch to align with semantic space of LLMs. Despite their\neffectiveness, we reveal that these methods conceal three inherent bottlenecks:\n(1) they struggle to encode temporal and channel-specific information in a\nlossless manner, both of which are critical components of multivariate time\nseries; (2) it is much difficult to align the learned representation space with\nthe semantic space of the LLMs; (3) they require task-specific retraining,\nwhich is both computationally expensive and labor-intensive. To bridge these\ngaps, we propose TableTime, which reformulates MTSC as a table understanding\ntask. Specifically, TableTime introduces the following strategies: (1) convert\nmultivariate time series into a tabular form, thus minimizing information loss\nto the greatest extent; (2) represent tabular time series in text format to\nachieve natural alignment with the semantic space of LLMs; (3) design a\nreasoning framework that integrates contextual text information, neighborhood\nassistance, multi-path inference and problem decomposition to enhance the\nreasoning ability of LLMs and realize zero-shot classification. Extensive\nexperiments performed on 10 publicly representative datasets from UEA archive\nverify the superiorities of the TableTime.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15737v3",
    "published_date": "2024-11-24 07:02:32 UTC",
    "updated_date": "2025-02-16 12:03:52 UTC"
  },
  {
    "arxiv_id": "2412.00051v2",
    "title": "TransFair: Transferring Fairness from Ocular Disease Classification to Progression Prediction",
    "authors": [
      "Leila Gheisi",
      "Henry Chu",
      "Raju Gottumukkala",
      "Yan Luo",
      "Xingquan Zhu",
      "Mengyu Wang",
      "Min Shi"
    ],
    "abstract": "The use of artificial intelligence (AI) in automated disease classification\nsignificantly reduces healthcare costs and improves the accessibility of\nservices. However, this transformation has given rise to concerns about the\nfairness of AI, which disproportionately affects certain groups, particularly\npatients from underprivileged populations. Recently, a number of methods and\nlarge-scale datasets have been proposed to address group performance\ndisparities. Although these methods have shown effectiveness in disease\nclassification tasks, they may fall short in ensuring fair prediction of\ndisease progression, mainly because of limited longitudinal data with diverse\ndemographics available for training a robust and equitable prediction model. In\nthis paper, we introduce TransFair to enhance demographic fairness in\nprogression prediction for ocular diseases. TransFair aims to transfer a\nfairness-enhanced disease classification model to the task of progression\nprediction with fairness preserved. Specifically, we train a fair EfficientNet,\ntermed FairEN, equipped with a fairness-aware attention mechanism using\nextensive data for ocular disease classification. Subsequently, this fair\nclassification model is adapted to a fair progression prediction model through\nknowledge distillation, which aims to minimize the latent feature distances\nbetween the classification and progression prediction models. We evaluate\nFairEN and TransFair for fairness-enhanced ocular disease classification and\nprogression prediction using both two-dimensional (2D) and 3D retinal images.\nExtensive experiments and comparisons with models with and without considering\nfairness learning show that TransFair effectively enhances demographic equity\nin predicting ocular disease progression.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.00051v2",
    "published_date": "2024-11-24 06:39:06 UTC",
    "updated_date": "2024-12-03 03:33:50 UTC"
  },
  {
    "arxiv_id": "2411.15731v1",
    "title": "Fusion Matters: Learning Fusion in Deep Click-through Rate Prediction Models",
    "authors": [
      "Kexin Zhang",
      "Fuyuan Lyu",
      "Xing Tang",
      "Dugang Liu",
      "Chen Ma",
      "Kaize Ding",
      "Xiuqiang He",
      "Xue Liu"
    ],
    "abstract": "The evolution of previous Click-Through Rate (CTR) models has mainly been\ndriven by proposing complex components, whether shallow or deep, that are adept\nat modeling feature interactions. However, there has been less focus on\nimproving fusion design. Instead, two naive solutions, stacked and parallel\nfusion, are commonly used. Both solutions rely on pre-determined fusion\nconnections and fixed fusion operations. It has been repetitively observed that\nchanges in fusion design may result in different performances, highlighting the\ncritical role that fusion plays in CTR models. While there have been attempts\nto refine these basic fusion strategies, these efforts have often been\nconstrained to specific settings or dependent on specific components. Neural\narchitecture search has also been introduced to partially deal with fusion\ndesign, but it comes with limitations. The complexity of the search space can\nlead to inefficient and ineffective results. To bridge this gap, we introduce\nOptFusion, a method that automates the learning of fusion, encompassing both\nthe connection learning and the operation selection. We have proposed a\none-shot learning algorithm tackling these tasks concurrently. Our experiments\nare conducted over three large-scale datasets. Extensive experiments prove both\nthe effectiveness and efficiency of OptFusion in improving CTR model\nperformance. Our code implementation is available\nhere\\url{https://github.com/kexin-kxzhang/OptFusion}.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by WSDM 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.15731v1",
    "published_date": "2024-11-24 06:21:59 UTC",
    "updated_date": "2024-11-24 06:21:59 UTC"
  },
  {
    "arxiv_id": "2411.16754v1",
    "title": "Visual Counter Turing Test (VCT^2): Discovering the Challenges for AI-Generated Image Detection and Introducing Visual AI Index (V_AI)",
    "authors": [
      "Nasrin Imanpour",
      "Shashwat Bajpai",
      "Subhankar Ghosh",
      "Sainath Reddy Sankepally",
      "Abhilekh Borah",
      "Hasnat Md Abdullah",
      "Nishoak Kosaraju",
      "Shreyas Dixit",
      "Ashhar Aziz",
      "Shwetangshu Biswas",
      "Vinija Jain",
      "Aman Chadha",
      "Amit Sheth",
      "Amitava Das"
    ],
    "abstract": "The proliferation of AI techniques for image generation, coupled with their\nincreasing accessibility, has raised significant concerns about the potential\nmisuse of these images to spread misinformation. Recent AI-generated image\ndetection (AGID) methods include CNNDetection, NPR, DM Image Detection, Fake\nImage Detection, DIRE, LASTED, GAN Image Detection, AIDE, SSP, DRCT, RINE,\nOCC-CLIP, De-Fake, and Deep Fake Detection. However, we argue that the current\nstate-of-the-art AGID techniques are inadequate for effectively detecting\ncontemporary AI-generated images and advocate for a comprehensive reevaluation\nof these methods. We introduce the Visual Counter Turing Test (VCT^2), a\nbenchmark comprising ~130K images generated by contemporary text-to-image\nmodels (Stable Diffusion 2.1, Stable Diffusion XL, Stable Diffusion 3, DALL-E\n3, and Midjourney 6). VCT^2 includes two sets of prompts sourced from tweets by\nthe New York Times Twitter account and captions from the MS COCO dataset. We\nalso evaluate the performance of the aforementioned AGID techniques on the\nVCT$^2$ benchmark, highlighting their ineffectiveness in detecting AI-generated\nimages. As image-generative AI models continue to evolve, the need for a\nquantifiable framework to evaluate these models becomes increasingly critical.\nTo meet this need, we propose the Visual AI Index (V_AI), which assesses\ngenerated images from various visual perspectives, including texture complexity\nand object coherence, setting a new standard for evaluating image-generative AI\nmodels. To foster research in this domain, we make our\nhttps://huggingface.co/datasets/anonymous1233/COCO_AI and\nhttps://huggingface.co/datasets/anonymous1233/twitter_AI datasets publicly\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.16754v1",
    "published_date": "2024-11-24 06:03:49 UTC",
    "updated_date": "2024-11-24 06:03:49 UTC"
  },
  {
    "arxiv_id": "2411.16751v1",
    "title": "An investigation into the performances of the Current state-of-the-art Naive Bayes, Non-Bayesian and Deep Learning Based Classifier for Phishing Detection: A Survey",
    "authors": [
      "Tosin Ige",
      "Christopher Kiekintveld",
      "Aritran Piplai",
      "Amy Waggler",
      "Olukunle Kolade",
      "Bolanle Hafiz Matti"
    ],
    "abstract": "Phishing is one of the most effective ways in which cybercriminals get\nsensitive details such as credentials for online banking, digital wallets,\nstate secrets, and many more from potential victims. They do this by spamming\nusers with malicious URLs with the sole purpose of tricking them into divulging\nsensitive information which is later used for various cybercrimes. In this\nresearch, we did a comprehensive review of current state-of-the-art machine\nlearning and deep learning phishing detection techniques to expose their\nvulnerabilities and future research direction. For better analysis and\nobservation, we split machine learning techniques into Bayesian, non-Bayesian,\nand deep learning. We reviewed the most recent advances in Bayesian and\nnon-Bayesian-based classifiers before exploiting their corresponding weaknesses\nto indicate future research direction. While exploiting weaknesses in both\nBayesian and non-Bayesian classifiers, we also compared each performance with a\ndeep learning classifier. For a proper review of deep learning-based\nclassifiers, we looked at Recurrent Neural Networks (RNN), Convolutional Neural\nNetworks (CNN), and Long Short Term Memory Networks (LSTMs). We did an\nempirical analysis to evaluate the performance of each classifier along with\nmany of the proposed state-of-the-art anti-phishing techniques to identify\nfuture research directions, we also made a series of proposals on how the\nperformance of the under-performing algorithm can improved in addition to a\ntwo-stage prediction model",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16751v1",
    "published_date": "2024-11-24 05:20:09 UTC",
    "updated_date": "2024-11-24 05:20:09 UTC"
  },
  {
    "arxiv_id": "2411.15710v1",
    "title": "Understanding Student Acceptance, Trust, and Attitudes Toward AI-Generated Images for Educational Purposes",
    "authors": [
      "Aung Pyae"
    ],
    "abstract": "Recent advancements in artificial intelligence (AI) have broadened the\napplicability of AI-generated images across various sectors, including the\ncreative industry and design. However, their utilization in educational\ncontexts, particularly among undergraduate students in computer science and\nsoftware engineering, remains underexplored. This study adopts an exploratory\napproach, employing questionnaires and interviews, to assess students'\nacceptance, trust, and positive attitudes towards AI-generated images for\neducational tasks such as presentations, reports, and web design. The results\nreveal high acceptance, trust, and positive attitudes among students who value\nthe ease of use and potential academic benefits. However, concerns regarding\nthe lack of technical precision, where the AI fails to accurately produce\nimages as specified by prompts, moderately impact their practical application\nin detail-oriented educational tasks. These findings suggest a need for\ndeveloping comprehensive guidelines that address ethical considerations and\nintellectual property issues, while also setting quality standards for\nAI-generated images to enhance their educational use. Enhancing the\ncapabilities of AI tools to meet precise user specifications could foster\ncreativity and improve educational outcomes in technical disciplines.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15710v1",
    "published_date": "2024-11-24 04:39:48 UTC",
    "updated_date": "2024-11-24 04:39:48 UTC"
  },
  {
    "arxiv_id": "2411.17411v1",
    "title": "Advancing Uncertain Combinatorics through Graphization, Hyperization, and Uncertainization: Fuzzy, Neutrosophic, Soft, Rough, and Beyond",
    "authors": [
      "Takaaki Fujita"
    ],
    "abstract": "To better handle real-world uncertainty, concepts such as fuzzy sets,\nneutrosophic sets, rough sets, and soft sets have been introduced. For example,\nneutrosophic sets, which simultaneously represent truth, indeterminacy, and\nfalsehood, have proven to be valuable tools for modeling uncertainty in complex\nsystems. These set concepts are increasingly studied in graphized forms, and\ngeneralized graph concepts now encompass well-known structures such as\nhypergraphs and superhypergraphs. Furthermore, hyperconcepts and\nsuperhyperconcepts are being actively researched in areas beyond graph theory.\n  Combinatorics, uncertain sets (including fuzzy sets, neutrosophic sets, rough\nsets, soft sets, and plithogenic sets), uncertain graphs, and hyper and\nsuperhyper concepts are active areas of research with significant mathematical\nand practical implications. Recognizing their importance, this paper explores\nnew graph and set concepts, as well as hyper and superhyper concepts, as\ndetailed in the \"Results\" section of \"The Structure of the Paper.\"\nAdditionally, this work aims to consolidate recent findings, providing a\nsurvey-like resource to inform and engage readers.\n  For instance, we extend several graph concepts by introducing Neutrosophic\nOversets, Neutrosophic Undersets, Neutrosophic Offsets, and the Nonstandard\nReal Set. This paper defines a variety of concepts with the goal of inspiring\nnew ideas and serving as a valuable resource for researchers in their academic\npursuits.",
    "categories": [
      "cs.AI",
      "03B52"
    ],
    "primary_category": "cs.AI",
    "comment": "255 pages. 11 figures. Published as a book in 2024. Publisher: Biblio\n  Publishing. ISBN: 978-1-59973-812-3",
    "pdf_url": "http://arxiv.org/pdf/2411.17411v1",
    "published_date": "2024-11-24 04:28:53 UTC",
    "updated_date": "2024-11-24 04:28:53 UTC"
  },
  {
    "arxiv_id": "2411.15707v1",
    "title": "Nimbus: Secure and Efficient Two-Party Inference for Transformers",
    "authors": [
      "Zhengyi Li",
      "Kang Yang",
      "Jin Tan",
      "Wen-jie Lu",
      "Haoqi Wu",
      "Xiao Wang",
      "Yu Yu",
      "Derun Zhao",
      "Yancheng Zheng",
      "Minyi Guo",
      "Jingwen Leng"
    ],
    "abstract": "Transformer models have gained significant attention due to their power in\nmachine learning tasks. Their extensive deployment has raised concerns about\nthe potential leakage of sensitive information during inference. However, when\nbeing applied to Transformers, existing approaches based on secure two-party\ncomputation (2PC) bring about efficiency limitations in two folds: (1)\nresource-intensive matrix multiplications in linear layers, and (2) complex\nnon-linear activation functions like $\\mathsf{GELU}$ and $\\mathsf{Softmax}$.\nThis work presents a new two-party inference framework $\\mathsf{Nimbus}$ for\nTransformer models. For the linear layer, we propose a new 2PC paradigm along\nwith an encoding approach to securely compute matrix multiplications based on\nan outer-product insight, which achieves $2.9\\times \\sim 12.5\\times$\nperformance improvements compared to the state-of-the-art (SOTA) protocol. For\nthe non-linear layer, through a new observation of utilizing the input\ndistribution, we propose an approach of low-degree polynomial approximation for\n$\\mathsf{GELU}$ and $\\mathsf{Softmax}$, which improves the performance of the\nSOTA polynomial approximation by $2.9\\times \\sim 4.0\\times$, where the average\naccuracy loss of our approach is 0.08\\% compared to the non-2PC inference\nwithout privacy. Compared with the SOTA two-party inference, $\\mathsf{Nimbus}$\nimproves the end-to-end performance of \\bert{} inference by $2.7\\times \\sim\n4.7\\times$ across different network settings.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by NIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.15707v1",
    "published_date": "2024-11-24 04:24:31 UTC",
    "updated_date": "2024-11-24 04:24:31 UTC"
  },
  {
    "arxiv_id": "2411.15700v1",
    "title": "RAMIE: Retrieval-Augmented Multi-task Information Extraction with Large Language Models on Dietary Supplements",
    "authors": [
      "Zaifu Zhan",
      "Shuang Zhou",
      "Mingchen Li",
      "Rui Zhang"
    ],
    "abstract": "\\textbf{Objective:} We aimed to develop an advanced multi-task large language\nmodel (LLM) framework to extract multiple types of information about dietary\nsupplements (DS) from clinical records.\n  \\textbf{Methods:} We used four core DS information extraction tasks - namely,\nnamed entity recognition (NER: 2,949 clinical sentences), relation extraction\n(RE: 4,892 sentences), triple extraction (TE: 2,949 sentences), and usage\nclassification (UC: 2,460 sentences) as our multitasks. We introduced a novel\nRetrieval-Augmented Multi-task Information Extraction (RAMIE) Framework,\nincluding: 1) employed instruction fine-tuning techniques with task-specific\nprompts, 2) trained LLMs for multiple tasks with improved storage efficiency\nand lower training costs, and 3) incorporated retrieval augmentation generation\n(RAG) techniques by retrieving similar examples from the training set. We\ncompared RAMIE's performance to LLMs with instruction fine-tuning alone and\nconducted an ablation study to assess the contributions of multi-task learning\nand RAG to improved multitasking performance.\n  \\textbf{Results:} With the aid of the RAMIE framework, Llama2-13B achieved an\nF1 score of 87.39 (3.51\\% improvement) on the NER task and demonstrated\noutstanding performance on the RE task with an F1 score of 93.74 (1.15\\%\nimprovement). For the TE task, Llama2-7B scored 79.45 (14.26\\% improvement),\nand MedAlpaca-7B achieved the highest F1 score of 93.45 (0.94\\% improvement) on\nthe UC task. The ablation study revealed that while MTL increased efficiency\nwith a slight trade-off in performance, RAG significantly boosted overall\naccuracy.\n  \\textbf{Conclusion:} This study presents a novel RAMIE framework that\ndemonstrates substantial improvements in multi-task information extraction for\nDS-related data from clinical records. Our framework can potentially be applied\nto other domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15700v1",
    "published_date": "2024-11-24 03:56:43 UTC",
    "updated_date": "2024-11-24 03:56:43 UTC"
  },
  {
    "arxiv_id": "2412.00049v1",
    "title": "A Survey of Recent Advances and Challenges in Deep Audio-Visual Correlation Learning",
    "authors": [
      "Luis Vilaca",
      "Yi Yu",
      "Paula Vinan"
    ],
    "abstract": "Audio-visual correlation learning aims to capture and understand natural\nphenomena between audio and visual data. The rapid growth of Deep Learning\npropelled the development of proposals that process audio-visual data and can\nbe observed in the number of proposals in the past years. Thus encouraging the\ndevelopment of a comprehensive survey. Besides analyzing the models used in\nthis context, we also discuss some tasks of definition and paradigm applied in\nAI multimedia. In addition, we investigate objective functions frequently used\nand discuss how audio-visual data is exploited in the optimization process,\ni.e., the different methodologies for representing knowledge in the\naudio-visual domain. In fact, we focus on how human-understandable mechanisms,\ni.e., structured knowledge that reflects comprehensible knowledge, can guide\nthe learning process. Most importantly, we provide a summarization of the\nrecent progress of Audio-Visual Correlation Learning (AVCL) and discuss the\nfuture research directions.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.MM",
    "comment": "arXiv admin note: text overlap with arXiv:2202.13673",
    "pdf_url": "http://arxiv.org/pdf/2412.00049v1",
    "published_date": "2024-11-24 03:26:34 UTC",
    "updated_date": "2024-11-24 03:26:34 UTC"
  },
  {
    "arxiv_id": "2411.15685v1",
    "title": "State-Space Large Audio Language Models",
    "authors": [
      "Saurabhchand Bhati",
      "Yuan Gong",
      "Leonid Karlinsky",
      "Hilde Kuehne",
      "Rogerio Feris",
      "James Glass"
    ],
    "abstract": "Large Audio Language Models (LALM) combine the audio perception models and\nthe Large Language Models (LLM) and show a remarkable ability to reason about\nthe input audio, infer the meaning, and understand the intent. However, these\nsystems rely on Transformers which scale quadratically with the input sequence\nlengths which poses computational challenges in deploying these systems in\nmemory and time-constrained scenarios. Recently, the state-space models (SSMs)\nhave emerged as an alternative to transformer networks.\n  While there have been successful attempts to replace transformer-based audio\nperception models with state-space ones, state-space-based LALMs remain\nunexplored. First, we begin by replacing the transformer-based audio perception\nmodule and then replace the transformer-based LLM and propose the first\nstate-space-based LALM. Experimental results demonstrate that space-based LALM\ndespite having a significantly lower number of parameters performs\ncompetitively with transformer-based LALMs on close-ended tasks on a variety of\ndatasets.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15685v1",
    "published_date": "2024-11-24 02:21:28 UTC",
    "updated_date": "2024-11-24 02:21:28 UTC"
  },
  {
    "arxiv_id": "2411.15674v1",
    "title": "Quantile deep learning models for multi-step ahead time series prediction",
    "authors": [
      "Jimmy Cheung",
      "Smruthi Rangarajan",
      "Amelia Maddocks",
      "Xizhe Chen",
      "Rohitash Chandra"
    ],
    "abstract": "Uncertainty quantification is crucial in time series prediction, and quantile\nregression offers a valuable mechanism for uncertainty quantification which is\nuseful for extreme value forecasting. Although deep learning models have been\nprominent in multi-step ahead prediction, the development and evaluation of\nquantile deep learning models have been limited. We present a novel quantile\nregression deep learning framework for multi-step time series prediction. In\nthis way, we elevate the capabilities of deep learning models by incorporating\nquantile regression, thus providing a more nuanced understanding of predictive\nvalues. We provide an implementation of prominent deep learning models for\nmulti-step ahead time series prediction and evaluate their performance under\nhigh volatility and extreme conditions. We include multivariate and univariate\nmodelling, strategies and provide a comparison with conventional deep learning\nmodels from the literature. Our models are tested on two cryptocurrencies:\nBitcoin and Ethereum, using daily close-price data and selected benchmark time\nseries datasets. The results show that integrating a quantile loss function\nwith deep learning provides additional predictions for selected quantiles\nwithout a loss in the prediction accuracy when compared to the literature. Our\nquantile model has the ability to handle volatility more effectively and\nprovides additional information for decision-making and uncertainty\nquantification through the use of quantiles when compared to conventional deep\nlearning models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15674v1",
    "published_date": "2024-11-24 00:00:10 UTC",
    "updated_date": "2024-11-24 00:00:10 UTC"
  }
]