{
  "date": "2024-05-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-19 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 43 篇论文，主要聚焦 AI、机器学习和多模态应用等领域，亮点包括对大型语言模型 (LLM) 的线性特性分析、脑科学动态建模以及 AI 安全强化学习等；令人印象深刻的是 \"Your Transformer is Secretly Linear\"，揭示 Transformer 架构的潜在线性机制，而知名学者如 Vince Calhoun 参与的 DSAM 框架也值得关注。\n\n下面，我将挑选几篇重要、话题度高的论文优先讨论（如 LLM 相关和 AI 解释性），并将相关主题归类快速掠过其他论文。每个条目会列出论文标题（中文 + 英文），并简要描述核心贡献、方法和发现。\n\n### 重点论文讨论\n\n1. **DSAM: 一个深度学习框架用于分析脑网络的时空动态 (DSAM: A Deep Learning Framework for Analyzing Temporal and Spatial Dynamics in Brain Networks)**  \n   作者包括知名学者 Vince Calhoun 和 Jingyu Liu。这篇论文提出 DSAM 框架，使用时序因果卷积网络和图神经网络，从 fMRI 数据中学习目标特定的功能连接矩阵。贡献在于捕捉脑的时空动态，实现性别分类准确率提升，并提供可解释的脑连接模式，暗示 AI 在神经科学中的潜力。\n\n2. **Your Transformer is Secretly Linear (Your Transformer is Secretly Linear)**  \n   作者团队包括 Ivan Oseledets。该研究发现 Transformer 解码器（如 GPT、LLaMA）存在近乎完美的线性关系（Procrustes 相似度 0.99），并通过实验证明移除线性块不影响性能。贡献是挑战传统理解，提出余弦相似性正则化改善模型表现，可能重塑 LLM 优化策略。\n\n3. **可解释的人机交互：一个规划视角 (Explainable Human-AI Interaction: A Planning Perspective)**  \n   作者 Subbarao Kambhampati 等。该论文讨论 AI 代理如何考虑人类心理模型进行规划，支持合作场景并防范欺骗。核心发现是 AI 可通过解释性通信适应人类期望，提升人机协同效率，对 AI 伦理和实际应用有重要启示。\n\n4. **MeteoRA: 多任务嵌入的 LoRA 用于大型语言模型 (MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models)**  \n   这篇论文引入 MeteoRA 框架，将多个 LoRA 适配器嵌入 LLM 通过 Mixture-of-Experts 架构，实现高效多任务切换。贡献在于提升复合任务性能（如顺序问题解决），并通过 LlaMA2 和 LlaMA3 模型验证，展示了 LLM 适配器的实用性。\n\n5. **大型语言模型可以从用户互动中推断个性 (Large Language Models Can Infer Personality from Free-Form User Interactions)**  \n   作者包括 Moran Cerf。该研究使用 GPT-4 聊天机器人从用户互动中推断 Big Five 个性特征，准确率中等（相关系数 0.443），并讨论伦理挑战。发现是 LLM 在心理分析中的潜力，但需平衡自然性和准确性。\n\n### 相关主题快速掠过\n- **AI 安全与强化学习**：如 \"Do No Harm: A Counterfactual Approach to Safe Reinforcement Learning\"，提出基于反事实约束的安全 RL 方法，提升代理在不确定环境中的安全性；\"Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems\" 使用梯度优化生成隐形对抗对象，强调 AI 鲁棒性。其他如 \"An Invisible Backdoor Attack Based On Semantic Feature\" 等，快速提及其对抗攻击方法，但不深究细节。\n  \n- **多模态和应用**：论文如 \"Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning\"，开发多模态医疗推理框架，实现零样本诊断；\"Track Anything Rapter (TAR)\" 整合 DINO 和 SAM 用于对象跟踪，提升 UAV 精度。这些展示 AI 在医疗和机器人中的潜力，但篇幅有限，仅点到为止。\n\n- **其他领域**：如 \"Deep Ensemble Art Style Recognition\" 使用集成深度网络达到艺术风格识别的 state-of-the-art 准确率；\"Transcriptomics-guided Slide Representation Learning\" 通过多模态预训练改善病理图像分析；\"Language Reconstruction with Brain Predictive Coding from fMRI Data\" 利用预测编码从脑信号重建语言，BLEU-1 达 27.8%。这些论文虽有创新，但影响力较小，故简要概述。\n\n总体而言，今天的论文突显 AI 模型的优化和应用潜力，但需关注伦理和安全问题。读者可根据兴趣优先查看 LLM 或脑科学相关内容，完整列表可查 arXiv。明天见！",
  "papers": [
    {
      "arxiv_id": "2405.15805v1",
      "title": "DSAM: A Deep Learning Framework for Analyzing Temporal and Spatial Dynamics in Brain Networks",
      "title_zh": "DSAM：一种用于分析脑网络中时间和空间动态的深度学习框架",
      "authors": [
        "Bishal Thapaliya",
        "Robyn Miller",
        "Jiayu Chen",
        "Yu-Ping Wang",
        "Esra Akbas",
        "Ram Sapkota",
        "Bhaskar Ray",
        "Pranav Suresh",
        "Santosh Ghimire",
        "Vince Calhoun",
        "Jingyu Liu"
      ],
      "abstract": "Resting-state functional magnetic resonance imaging (rs-fMRI) is a\nnoninvasive technique pivotal for understanding human neural mechanisms of\nintricate cognitive processes. Most rs-fMRI studies compute a single static\nfunctional connectivity matrix across brain regions of interest, or dynamic\nfunctional connectivity matrices with a sliding window approach. These\napproaches are at risk of oversimplifying brain dynamics and lack proper\nconsideration of the goal at hand. While deep learning has gained substantial\npopularity for modeling complex relational data, its application to uncovering\nthe spatiotemporal dynamics of the brain is still limited. We propose a novel\ninterpretable deep learning framework that learns goal-specific functional\nconnectivity matrix directly from time series and employs a specialized graph\nneural network for the final classification. Our model, DSAM, leverages\ntemporal causal convolutional networks to capture the temporal dynamics in both\nlow- and high-level feature representations, a temporal attention unit to\nidentify important time points, a self-attention unit to construct the\ngoal-specific connectivity matrix, and a novel variant of graph neural network\nto capture the spatial dynamics for downstream classification. To validate our\napproach, we conducted experiments on the Human Connectome Project dataset with\n1075 samples to build and interpret the model for the classification of sex\ngroup, and the Adolescent Brain Cognitive Development Dataset with 8520 samples\nfor independent testing. Compared our proposed framework with other\nstate-of-art models, results suggested this novel approach goes beyond the\nassumption of a fixed connectivity matrix and provides evidence of\ngoal-specific brain connectivity patterns, which opens up the potential to gain\ndeeper insights into how the human brain adapts its functional connectivity\nspecific to the task at hand.",
      "tldr_zh": "本研究提出DSAM框架，一种可解释的深度学习模型，用于分析rs-fMRI数据的时空动态，旨在克服传统方法（如静态或滑动窗口功能连接矩阵）对脑动态的简化问题。DSAM直接从时间序列中学习目标特定的功能连接矩阵，结合temporal causal convolutional networks捕捉时间动态、temporal attention unit识别关键时间点、self-attention unit构建连接矩阵，以及一种新型graph neural network捕捉空间动态以进行分类。实验在Human Connectome Project数据集（1075样本，用于性别分类）和Adolescent Brain Cognitive Development Dataset（8520样本，用于独立测试）上验证，结果显示DSAM超越了固定连接矩阵的假设，并揭示了任务特定的脑连接模式，为深入理解脑功能适应性提供了新见解。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "18 Pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.15805v1",
      "published_date": "2024-05-19 23:35:06 UTC",
      "updated_date": "2024-05-19 23:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:34:28.630938"
    },
    {
      "arxiv_id": "2405.12250v1",
      "title": "Your Transformer is Secretly Linear",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Razzhigaev",
        "Matvey Mikhalchuk",
        "Elizaveta Goncharova",
        "Nikolai Gerasimenko",
        "Ivan Oseledets",
        "Denis Dimitrov",
        "Andrey Kuznetsov"
      ],
      "abstract": "This paper reveals a novel linear characteristic exclusive to transformer\ndecoders, including models such as GPT, LLaMA, OPT, BLOOM and others. We\nanalyze embedding transformations between sequential layers, uncovering a\nnear-perfect linear relationship (Procrustes similarity score of 0.99).\nHowever, linearity decreases when the residual component is removed due to a\nconsistently low output norm of the transformer layer. Our experiments show\nthat removing or linearly approximating some of the most linear blocks of\ntransformers does not affect significantly the loss or model performance.\nMoreover, in our pretraining experiments on smaller models we introduce a\ncosine-similarity-based regularization, aimed at reducing layer linearity. This\nregularization improves performance metrics on benchmarks like Tiny Stories and\nSuperGLUE and as well successfully decreases the linearity of the models. This\nstudy challenges the existing understanding of transformer architectures,\nsuggesting that their operation may be more linear than previously assumed.",
      "tldr_zh": "本研究揭示了Transformer解码器（如GPT、LLaMA、OPT和BLOOM等模型）的隐藏线性特征，通过分析顺序层之间的嵌入转换，发现了近乎完美的线性关系（Procrustes similarity score of 0.99），但移除residual component后线性度下降。实验显示，移除或线性近似这些线性块不会显著影响模型的损失或性能；在较小模型的预训练中，引入基于cosine-similarity的正则化不仅降低了层线性度，还提升了Tiny Stories和SuperGLUE等基准的性能指标。该发现挑战了现有对Transformer架构的理解，表明其操作可能比之前假设的更线性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.12250v1",
      "published_date": "2024-05-19 22:44:00 UTC",
      "updated_date": "2024-05-19 22:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:34:40.124234"
    },
    {
      "arxiv_id": "2405.15804v1",
      "title": "Explainable Human-AI Interaction: A Planning Perspective",
      "title_zh": "可解释的人- AI 交互：规划视角",
      "authors": [
        "Sarath Sreedharan",
        "Anagha Kulkarni",
        "Subbarao Kambhampati"
      ],
      "abstract": "From its inception, AI has had a rather ambivalent relationship with humans\n-- swinging between their augmentation and replacement. Now, as AI technologies\nenter our everyday lives at an ever increasing pace, there is a greater need\nfor AI systems to work synergistically with humans. One critical requirement\nfor such synergistic human-AI interaction is that the AI systems be explainable\nto the humans in the loop. To do this effectively, AI agents need to go beyond\nplanning with their own models of the world, and take into account the mental\nmodel of the human in the loop. Drawing from several years of research in our\nlab, we will discuss how the AI agent can use these mental models to either\nconform to human expectations, or change those expectations through explanatory\ncommunication. While the main focus of the book is on cooperative scenarios, we\nwill point out how the same mental models can be used for obfuscation and\ndeception. Although the book is primarily driven by our own research in these\nareas, in every chapter, we will provide ample connections to relevant research\nfrom other groups.",
      "tldr_zh": "该论文从规划（planning）的角度探讨可解释的人机交互（human-AI interaction），强调AI系统需考虑人类的心理模型（mental model）以实现协同工作。作者基于实验室研究，提出AI代理可以通过这些模型来符合人类期望，或通过解释性沟通改变这些期望，从而提升交互效果。尽管重点在于合作场景，该方法也可用于混淆和欺骗（obfuscation and deception）。整体上，该书提供了与其他相关研究的广泛连接，为构建可信任的AI系统提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15804v1",
      "published_date": "2024-05-19 22:22:21 UTC",
      "updated_date": "2024-05-19 22:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:34:51.304788"
    },
    {
      "arxiv_id": "2405.11675v1",
      "title": "Deep Ensemble Art Style Recognition",
      "title_zh": "深度集成艺术风格识别",
      "authors": [
        "Orfeas Menis-Mastromichalakis",
        "Natasa Sofou",
        "Giorgos Stamou"
      ],
      "abstract": "The massive digitization of artworks during the last decades created the need\nfor categorization, analysis, and management of huge amounts of data related to\nabstract concepts, highlighting a challenging problem in the field of computer\nscience. The rapid progress of artificial intelligence and neural networks has\nprovided tools and technologies that seem worthy of the challenge. Recognition\nof various art features in artworks has gained attention in the deep learning\nsociety. In this paper, we are concerned with the problem of art style\nrecognition using deep networks. We compare the performance of 8 different deep\narchitectures (VGG16, VGG19, ResNet50, ResNet152, Inception-V3, DenseNet121,\nDenseNet201 and Inception-ResNet-V2), on two different art datasets, including\n3 architectures that have never been used on this task before, leading to\nstate-of-the-art performance. We study the effect of data preprocessing prior\nto applying a deep learning model. We introduce a stacking ensemble method\ncombining the results of first-stage classifiers through a meta-classifier,\nwith the innovation of a versatile approach based on multiple models that\nextract and recognize different characteristics of the input, creating a more\nconsistent model compared to existing works and achieving state-of-the-art\naccuracy on the largest art dataset available (WikiArt - 68,55%). We also\ndiscuss the impact of the data and art styles themselves on the performance of\nour models forming a manifold perspective on the problem.",
      "tldr_zh": "这篇论文探讨了使用深度学习模型进行艺术风格识别的问题，比较了8个不同深度网络架构（如VGG16、VGG19、ResNet50等）在两个艺术数据集上的性能，其中包括3个之前未应用于此任务的架构，并研究了数据预处理的影响。作者引入了一种创新的stacking ensemble方法，通过元分类器结合第一阶段分类器的输出，提取和识别输入的不同特征，实现了比现有工作更高的准确率，在WikiArt数据集上达到68.55%的state-of-the-art性能。该方法还分析了数据和艺术风格本身对模型性能的影响，提供了一个多角度的视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11675v1",
      "published_date": "2024-05-19 21:26:11 UTC",
      "updated_date": "2024-05-19 21:26:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:35:04.704081"
    },
    {
      "arxiv_id": "2405.13053v3",
      "title": "MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwei Xu",
        "Junyu Lai",
        "Yunpeng Huang"
      ],
      "abstract": "The pretrain+fine-tune paradigm is foundational for deploying large language\nmodels (LLMs) across various downstream applications. Within this framework,\nLow-Rank Adaptation (LoRA) stands out for its parameter-efficient fine-tuning\n(PEFT), producing numerous reusable task-specific LoRA adapters. However, this\napproach requires explicit task intention selection, posing challenges for\nautonomous task sensing and switching during inference with multiple existing\nLoRA adapters embedded in a single LLM. In this work, we introduce MeteoRA\n(Multiple-tasks embedded LoRA), a scalable and efficient framework that reuses\nmultiple task-specific LoRA adapters into the base LLM via a full-mode\nMixture-of-Experts (MoE) architecture. This framework also includes novel MoE\nforward acceleration strategies to address the efficiency challenges of\ntraditional MoE implementations. Our evaluation, using the LlaMA2-13B and\nLlaMA3-8B base models equipped with 28 existing LoRA adapters through MeteoRA,\ndemonstrates equivalent performance with the traditional PEFT method. Moreover,\nthe LLM equipped with MeteoRA achieves superior performance in handling\ncomposite tasks, effectively solving ten sequential problems in a single\ninference pass, thereby demonstrating the framework's enhanced capability for\ntimely adapter switching.",
      "tldr_zh": "该研究提出 MeteoRA 框架，用于在大型语言模型(LLMs)中嵌入多个任务特定 LoRA 适配器，实现参数高效微调(PEFT)下的多任务处理，而无需显式任务选择。MeteoRA 采用全模式 Mixture-of-Experts (MoE) 架构，并引入新型 MoE 前向加速策略，以提升效率和自主任务切换能力。在 LlaMA2-13B 和 LlaMA3-8B 模型上实验显示，该框架的性能与传统 PEFT 方法相当，并在处理复合任务时表现出色，能在单次推理中解决十个顺序问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.13053v3",
      "published_date": "2024-05-19 20:46:07 UTC",
      "updated_date": "2024-10-09 15:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:35:18.026046"
    },
    {
      "arxiv_id": "2405.13052v1",
      "title": "Large Language Models Can Infer Personality from Free-Form User Interactions",
      "title_zh": "大语言模型可以从自由形式的用户互动中推断个性",
      "authors": [
        "Heinrich Peters",
        "Moran Cerf",
        "Sandra C. Matz"
      ],
      "abstract": "This study investigates the capacity of Large Language Models (LLMs) to infer\nthe Big Five personality traits from free-form user interactions. The results\ndemonstrate that a chatbot powered by GPT-4 can infer personality with moderate\naccuracy, outperforming previous approaches drawing inferences from static text\ncontent. The accuracy of inferences varied across different conversational\nsettings. Performance was highest when the chatbot was prompted to elicit\npersonality-relevant information from users (mean r=.443, range=[.245, .640]),\nfollowed by a condition placing greater emphasis on naturalistic interaction\n(mean r=.218, range=[.066, .373]). Notably, the direct focus on personality\nassessment did not result in a less positive user experience, with participants\nreporting the interactions to be equally natural, pleasant, engaging, and\nhumanlike across both conditions. A chatbot mimicking ChatGPT's default\nbehavior of acting as a helpful assistant led to markedly inferior personality\ninferences and lower user experience ratings but still captured psychologically\nmeaningful information for some of the personality traits (mean r=.117,\nrange=[-.004, .209]). Preliminary analyses suggest that the accuracy of\npersonality inferences varies only marginally across different\nsocio-demographic subgroups. Our results highlight the potential of LLMs for\npsychological profiling based on conversational interactions. We discuss\npractical implications and ethical challenges associated with these findings.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 从自由形式用户互动中推断 Big Five 个性特征的能力，结果显示使用 GPT-4 驱动的聊天机器人能以中等准确度进行推断，并优于基于静态文本的方法。实验在不同对话设置中测试性能，主动获取个性相关信息的条件表现最佳（mean r=.443），其次是自然互动（mean r=.218），而模仿 ChatGPT 默认助手行为的条件则最差（mean r=.117），但仍能捕捉部分心理信息。值得注意的是，直接进行个性评估并未影响用户体验，用户报告互动同样自然、愉快和人性化，且准确度在不同社会人口统计子群中变化不大。该研究突出了 LLMs 在心理画像中的潜力，同时讨论了实际应用和伦理挑战。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13052v1",
      "published_date": "2024-05-19 20:33:36 UTC",
      "updated_date": "2024-05-19 20:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:35:29.530968"
    },
    {
      "arxiv_id": "2405.11669v1",
      "title": "Do No Harm: A Counterfactual Approach to Safe Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sean Vaskov",
        "Wilko Schwarting",
        "Chris L. Baker"
      ],
      "abstract": "Reinforcement Learning (RL) for control has become increasingly popular due\nto its ability to learn rich feedback policies that take into account\nuncertainty and complex representations of the environment. When considering\nsafety constraints, constrained optimization approaches, where agents are\npenalized for constraint violations, are commonly used. In such methods, if\nagents are initialized in, or must visit, states where constraint violation\nmight be inevitable, it is unclear how much they should be penalized. We\naddress this challenge by formulating a constraint on the counterfactual harm\nof the learned policy compared to a default, safe policy. In a philosophical\nsense this formulation only penalizes the learner for constraint violations\nthat it caused; in a practical sense it maintains feasibility of the optimal\ncontrol problem. We present simulation studies on a rover with uncertain road\nfriction and a tractor-trailer parking environment that demonstrate our\nconstraint formulation enables agents to learn safer policies than contemporary\nconstrained RL methods.",
      "tldr_zh": "这篇论文提出了一种基于反事实(counterfactual)的方法，用于安全强化学习(Reinforcement Learning)，通过将代理的策略与默认安全策略比较，仅惩罚代理造成的额外约束违反，从而解决传统约束优化在不可避免违反场景下的难题。相比于现有方法，该方法在哲学上确保只对代理的责任行为进行处罚，并在实践上保持优化问题的可行性。模拟实验在rovers（探测器）和tractor-trailer停车环境中证明，该方法使代理学习到比当代约束RL方法更安全的策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11669v1",
      "published_date": "2024-05-19 20:33:21 UTC",
      "updated_date": "2024-05-19 20:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:35:39.388784"
    },
    {
      "arxiv_id": "2405.13051v1",
      "title": "Towards Contactless Elevators with TinyML using CNN-based Person Detection and Keyword Spotting",
      "title_zh": "翻译失败",
      "authors": [
        "Anway S. Pimpalkar",
        "Deeplaxmi V. Niture"
      ],
      "abstract": "This study presents a proof of concept for a contactless elevator operation\nsystem aimed at minimizing human intervention while enhancing safety,\nintelligence, and efficiency. A microcontroller-based edge device executing\ntiny Machine Learning (tinyML) inferences is developed for elevator operation.\nUsing person detection and keyword spotting algorithms, the system offers\ncost-effective and robust units requiring minimal infrastructural changes. The\ndesign incorporates preprocessing steps and quantized convolutional neural\nnetworks in a multitenant framework to optimize accuracy and response time.\nResults show a person detection accuracy of 83.34% and keyword spotting\nefficacy of 80.5%, with an overall latency under 5 seconds, indicating\neffectiveness in real-world scenarios. Unlike current high-cost and\ninconsistent contactless technologies, this system leverages tinyML to provide\na cost-effective, reliable, and scalable solution, enhancing user safety and\noperational efficiency without significant infrastructural changes. The study\nhighlights promising results, though further exploration is needed for\nscalability and integration with existing systems. The demonstrated energy\nefficiency, simplicity, and safety benefits suggest that tinyML adoption could\nrevolutionize elevator systems, serving as a model for future technological\nadvancements. This technology could significantly impact public health and\nconvenience in multi-floor buildings by reducing physical contact and improving\noperational efficiency, particularly relevant in the context of pandemics or\nhygiene concerns.",
      "tldr_zh": "这篇论文提出了一种基于 TinyML 的无接触电梯系统，使用 CNN 基于的人检测和关键词识别算法，旨在减少人为干预并提升安全、效率和卫生水平。系统在微控制器边缘设备上运行，通过预处理步骤和量化卷积神经网络优化多租户框架，实现了83.34%的人检测准确率、80.5%的关键词识别效率，以及低于5秒的总体延迟。实验结果显示，该方案比传统技术更具成本效益和可扩展性，并为公共建筑减少物理接触和改善操作效率提供了可靠模型，尤其在疫情或卫生场景中具有重要潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13051v1",
      "published_date": "2024-05-19 20:24:31 UTC",
      "updated_date": "2024-05-19 20:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:35:52.931985"
    },
    {
      "arxiv_id": "2405.11657v2",
      "title": "On the Expressivity of Recurrent Neural Cascades with Identity",
      "title_zh": "翻译失败",
      "authors": [
        "Nadezda Alexandrovna Knorozova",
        "Alessandro Ronca"
      ],
      "abstract": "Recurrent Neural Cascades (RNC) are the class of recurrent neural networks\nwith no cyclic dependencies among recurrent neurons. Their subclass RNC+ with\npositive recurrent weights has been shown to be closely connected to the\nstar-free regular languages, which are the expressivity of many\nwell-established temporal logics. The existing expressivity results show that\nthe regular languages captured by RNC+ are the star-free ones, and they leave\nopen the possibility that RNC+ may capture languages beyond regular. We exclude\nthis possibility for languages that include an identity element, i.e., an input\nthat can occur an arbitrary number of times without affecting the output.\nNamely, in the presence of an identity element, we show that the languages\ncaptured by RNC+ are exactly the star-free regular languages. Identity elements\nare ubiquitous in temporal patterns, and hence our results apply to a large\nnumber of applications. The implications of our results go beyond expressivity.\nAt their core, we establish a close structural correspondence between RNC+ and\nsemiautomata cascades, showing that every neuron can be equivalently captured\nby a three-state semiautomaton. A notable consequence of this result is that\nRNC+ are no more succinct than cascades of three-state semiautomata.",
      "tldr_zh": "本研究探讨了Recurrent Neural Cascades (RNC)及其子类RNC+的表达能力，特别关注RNC+与star-free regular languages的关联。作者证明，如果语言包含一个identity element（即一个可任意多次出现而不影响输出的输入），则RNC+捕捉的语言恰好是star-free regular languages，从而排除了RNC+可能捕捉更广泛语言的可能性。论文还建立了RNC+与semiautomata cascades的结构对应，每个神经元可等效于一个三状态semiautomaton，这意味着RNC+的简洁性不超过三状态semiautomata cascades，并为时间模式应用提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.FL",
        "cs.LO",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Full version with appendix of a paper with the same title that will\n  appear in the proceedings of KR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.11657v2",
      "published_date": "2024-05-19 20:06:38 UTC",
      "updated_date": "2024-09-09 09:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:36:03.978121"
    },
    {
      "arxiv_id": "2405.11656v3",
      "title": "URDFormer: A Pipeline for Constructing Articulated Simulation Environments from Real-World Images",
      "title_zh": "URDFormer：",
      "authors": [
        "Zoey Chen",
        "Aaron Walsman",
        "Marius Memmel",
        "Kaichun Mo",
        "Alex Fang",
        "Karthikeya Vemuri",
        "Alan Wu",
        "Dieter Fox",
        "Abhishek Gupta"
      ],
      "abstract": "Constructing simulation scenes that are both visually and physically\nrealistic is a problem of practical interest in domains ranging from robotics\nto computer vision. This problem has become even more relevant as researchers\nwielding large data-hungry learning methods seek new sources of training data\nfor physical decision-making systems. However, building simulation models is\noften still done by hand. A graphic designer and a simulation engineer work\nwith predefined assets to construct rich scenes with realistic dynamic and\nkinematic properties. While this may scale to small numbers of scenes, to\nachieve the generalization properties that are required for data-driven robotic\ncontrol, we require a pipeline that is able to synthesize large numbers of\nrealistic scenes, complete with 'natural' kinematic and dynamic structures. To\nattack this problem, we develop models for inferring structure and generating\nsimulation scenes from natural images, allowing for scalable scene generation\nfrom web-scale datasets. To train these image-to-simulation models, we show how\ncontrollable text-to-image generative models can be used in generating paired\ntraining data that allows for modeling of the inverse problem, mapping from\nrealistic images back to complete scene models. We show how this paradigm\nallows us to build large datasets of scenes in simulation with semantic and\nphysical realism. We present an integrated end-to-end pipeline that generates\nsimulation scenes complete with articulated kinematic and dynamic structures\nfrom real-world images and use these for training robotic control policies. We\nthen robustly deploy in the real world for tasks like articulated object\nmanipulation. In doing so, our work provides both a pipeline for large-scale\ngeneration of simulation environments and an integrated system for training\nrobust robotic control policies in the resulting environments.",
      "tldr_zh": "本文提出URDFormer管道，用于从真实世界图像构建铰接模拟环境（articulated simulation environments），以解决手动场景构建的低效问题。该管道结合图像到模拟模型和可控文本到图像生成模型（text-to-image generative models），通过生成配对训练数据，实现大规模合成语义和物理真实的模拟场景。最终，该系统用于训练机器人控制策略（robotic control policies），并在真实世界任务如铰接物体操纵中实现鲁棒部署。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at RSS2024",
      "pdf_url": "http://arxiv.org/pdf/2405.11656v3",
      "published_date": "2024-05-19 20:01:29 UTC",
      "updated_date": "2024-05-31 16:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:36:15.543077"
    },
    {
      "arxiv_id": "2405.11655v2",
      "title": "Track Anything Rapter(TAR)",
      "title_zh": "翻译失败",
      "authors": [
        "Tharun V. Puthanveettil",
        "Fnu Obaid ur Rahman"
      ],
      "abstract": "Object tracking is a fundamental task in computer vision with broad practical\napplications across various domains, including traffic monitoring, robotics,\nand autonomous vehicle tracking. In this project, we aim to develop a\nsophisticated aerial vehicle system known as Track Anything Rapter (TAR),\ndesigned to detect, segment, and track objects of interest based on\nuser-provided multimodal queries, such as text, images, and clicks. TAR\nutilizes cutting-edge pre-trained models like DINO, CLIP, and SAM to estimate\nthe relative pose of the queried object. The tracking problem is approached as\na Visual Servoing task, enabling the UAV to consistently focus on the object\nthrough advanced motion planning and control algorithms. We showcase how the\nintegration of these foundational models with a custom high-level control\nalgorithm results in a highly stable and precise tracking system deployed on a\ncustom-built PX4 Autopilot-enabled Voxl2 M500 drone. To validate the tracking\nalgorithm's performance, we compare it against Vicon-based ground truth.\nAdditionally, we evaluate the reliability of the foundational models in aiding\ntracking in scenarios involving occlusions. Finally, we test and validate the\nmodel's ability to work seamlessly with multiple modalities, such as click,\nbounding box, and image templates.",
      "tldr_zh": "本研究开发了Track Anything Rapter (TAR)，一个先进的空中车辆系统，用于基于用户多模态查询（如文本、图像和点击）来检测、分割和跟踪感兴趣的对象，适用于交通监控、机器人和自动车辆等领域。TAR 利用预训练模型如 DINO、CLIP 和 SAM 来估计对象的相对姿态，并将跟踪问题视为 Visual Servoing 任务，通过高级运动规划和控制算法在自定义的 PX4 Autopilot-enabled Voxl2 M500 无人机上实现稳定精确的跟踪。实验结果显示，该系统在与 Vicon-based 地面真相比较中表现出色，能够在遮挡场景中可靠工作，并无缝支持多种模态查询如点击、边界框和图像模板。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11655v2",
      "published_date": "2024-05-19 19:51:41 UTC",
      "updated_date": "2024-05-29 16:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:36:28.899927"
    },
    {
      "arxiv_id": "2405.11647v3",
      "title": "Hummer: Towards Limited Competitive Preference Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Li Jiang",
        "Yusen Wu",
        "Junwu Xiong",
        "Jingqing Ruan",
        "Yichuan Ding",
        "Qingpei Guo",
        "Zujie Wen",
        "Jun Zhou",
        "Xiaotie Deng"
      ],
      "abstract": "Preference datasets are essential for incorporating human preferences into\npre-trained language models, playing a key role in the success of Reinforcement\nLearning from Human Feedback. However, these datasets often demonstrate\nconflicting alignment objectives, leading to increased vulnerability to\njailbreak attacks and challenges in adapting downstream tasks to prioritize\nspecific alignment objectives without negatively impacting others. In this\nwork, we introduce a novel statistical metric, Alignment Dimension Conflict, to\nquantify the degree of conflict within preference datasets. We then present\n\\texttt{Hummer} and its fine-grained variant, \\texttt{Hummer-F}, as innovative\npairwise preference datasets with reduced-conflict alignment objectives.\n\\texttt{Hummer} is built based on UltraFeedback and is enhanced by AI feedback\nfrom GPT-4, marking as the first preference dataset aimed at reducing the\ncompetition between alignment objectives. Furthermore, we develop reward\nmodels, HummerRM and HummerRM-F, which employ a hybrid sampling approach to\nbalance diverse alignment objectives effectively. This sampling method\npositions HummerRM as an ideal model for domain-specific further fine-tuning\nand reducing vulnerabilities to attacks.",
      "tldr_zh": "该论文针对偏好数据集在 Reinforcement Learning from Human Feedback (RLHF) 中的冲突 alignment 目标问题，引入了 Alignment Dimension Conflict 指标来量化这些冲突程度，以减少 jailbreak attacks 的风险和下游任务的适应挑战。研究者构建了 Hummer 和其细粒度变体 Hummer-F 数据集，这些数据集基于 UltraFeedback 并利用 GPT-4 的 AI 反馈，首次专注于降低 alignment 目标之间的竞争。最终，他们开发了奖励模型 HummerRM 和 HummerRM-F，通过混合采样方法有效平衡多样化目标，提升了模型在领域特定微调中的性能和安全性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11647v3",
      "published_date": "2024-05-19 18:57:25 UTC",
      "updated_date": "2024-08-06 14:12:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:36:40.389831"
    },
    {
      "arxiv_id": "2405.11640v1",
      "title": "Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zishan Gu",
        "Fenglin Liu",
        "Changchang Yin",
        "Ping Zhang"
      ],
      "abstract": "The adoption of large language models (LLMs) in healthcare has attracted\nsignificant research interest. However, their performance in healthcare remains\nunder-investigated and potentially limited, due to i) they lack rich\ndomain-specific knowledge and medical reasoning skills; and ii) most\nstate-of-the-art LLMs are unimodal, text-only models that cannot directly\nprocess multimodal inputs. To this end, we propose a multimodal medical\ncollaborative reasoning framework \\textbf{MultiMedRes}, which incorporates a\nlearner agent to proactively gain essential information from domain-specific\nexpert models, to solve medical multimodal reasoning problems. Our method\nincludes three steps: i) \\textbf{Inquire}: The learner agent first decomposes\ngiven complex medical reasoning problems into multiple domain-specific\nsub-problems; ii) \\textbf{Interact}: The agent then interacts with\ndomain-specific expert models by repeating the ``ask-answer'' process to\nprogressively obtain different domain-specific knowledge; iii)\n\\textbf{Integrate}: The agent finally integrates all the acquired\ndomain-specific knowledge to accurately address the medical reasoning problem.\nWe validate the effectiveness of our method on the task of difference visual\nquestion answering for X-ray images. The experiments demonstrate that our\nzero-shot prediction achieves state-of-the-art performance, and even\noutperforms the fully supervised methods. Besides, our approach can be\nincorporated into various LLMs and multimodal LLMs to significantly boost their\nperformance.",
      "tldr_zh": "该研究提出了一种主动代理协作框架 MultiMedRes，用于解决大型语言模型 (LLMs) 在医疗领域的局限性，如缺乏领域特定知识和处理多模态输入的能力。框架包括三个关键步骤：Inquire（将复杂医疗推理问题分解为领域特定子问题）、Interact（通过“问答”过程与专家模型交互获取知识），以及Integrate（整合获取的知识以准确解决问题）。在X射线图像差异视觉问答任务上，实验显示该zero-shot方法达到最先进性能，甚至超越完全监督方法，且可轻松整合到各种LLMs和多模态LLMs中以提升整体表现。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11640v1",
      "published_date": "2024-05-19 18:26:11 UTC",
      "updated_date": "2024-05-19 18:26:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:36:51.979956"
    },
    {
      "arxiv_id": "2405.11629v1",
      "title": "Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shengxiang Sun",
        "Shenzhe Zhu"
      ],
      "abstract": "Numerous studies on adversarial attacks targeting self-driving policies fail\nto incorporate realistic-looking adversarial objects, limiting real-world\napplicability. Building upon prior research that facilitated the transition of\nadversarial objects from simulations to practical applications, this paper\ndiscusses a modified gradient-based texture optimization method to discover\nrealistic-looking adversarial objects. While retaining the core architecture\nand techniques of the prior research, the proposed addition involves an entity\ntermed the 'Judge'. This agent assesses the texture of a rendered object,\nassigning a probability score reflecting its realism. This score is integrated\ninto the loss function to encourage the NeRF object renderer to concurrently\nlearn realistic and adversarial textures. The paper analyzes four strategies\nfor developing a robust 'Judge': 1) Leveraging cutting-edge vision-language\nmodels. 2) Fine-tuning open-sourced vision-language models. 3) Pretraining\nneurosymbolic systems. 4) Utilizing traditional image processing techniques.\nOur findings indicate that strategies 1) and 4) yield less reliable outcomes,\npointing towards strategies 2) or 3) as more promising directions for future\nresearch.",
      "tldr_zh": "本文提出了一种修改的gradient-based texture optimization方法，用于在自动驾驶系统中搜索真实外观的adversarial objects，以提升对抗攻击的实际应用性。该方法引入了'Judge'实体来评估渲染对象的纹理真实性，并将该实体的概率分数整合到损失函数中，使NeRF对象渲染器同时优化真实性和对抗性。研究分析了四种开发'Judge'的策略，包括利用vision-language models、微调开源模型、预训练neurosymbolic systems以及传统图像处理技术，结果显示前两种策略效果较差，而后两种策略更具潜力，为未来对抗攻击研究提供了指导方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11629v1",
      "published_date": "2024-05-19 17:42:24 UTC",
      "updated_date": "2024-05-19 17:42:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:37:05.164945"
    },
    {
      "arxiv_id": "2405.11619v1",
      "title": "Novel Interpretable and Robust Web-based AI Platform for Phishing Email Detection",
      "title_zh": "新颖、可解释且",
      "authors": [
        "Abdulla Al-Subaiey",
        "Mohammed Al-Thani",
        "Naser Abdullah Alam",
        "Kaniz Fatema Antora",
        "Amith Khandakar",
        "SM Ashfaq Uz Zaman"
      ],
      "abstract": "Phishing emails continue to pose a significant threat, causing financial\nlosses and security breaches. This study addresses limitations in existing\nresearch, such as reliance on proprietary datasets and lack of real-world\napplication, by proposing a high-performance machine learning model for email\nclassification. Utilizing a comprehensive and largest available public dataset,\nthe model achieves a f1 score of 0.99 and is designed for deployment within\nrelevant applications. Additionally, Explainable AI (XAI) is integrated to\nenhance user trust. This research offers a practical and highly accurate\nsolution, contributing to the fight against phishing by empowering users with a\nreal-time web-based application for phishing email detection.",
      "tldr_zh": "本研究针对钓鱼邮件造成的财务损失和安全风险，提出一个新型、可解释且鲁棒的基于网络的AI平台，以解决现有模型依赖专有数据集和缺乏实际应用的问题。平台采用机器学习模型，利用最大的可用公共数据集进行训练，实现了高达0.99的F1 score，并整合Explainable AI (XAI)来提升用户信任。该平台支持实时部署，提供高效的网页应用，帮助用户即时检测钓鱼邮件并增强网络安全防护。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 7 figures, dataset link:\n  https://www.kaggle.com/datasets/naserabdullahalam/phishing-email-dataset/",
      "pdf_url": "http://arxiv.org/pdf/2405.11619v1",
      "published_date": "2024-05-19 17:18:27 UTC",
      "updated_date": "2024-05-19 17:18:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:37:16.457549"
    },
    {
      "arxiv_id": "2405.11618v1",
      "title": "Transcriptomics-guided Slide Representation Learning in Computational Pathology",
      "title_zh": "翻译失败",
      "authors": [
        "Guillaume Jaume",
        "Lukas Oldenburg",
        "Anurag Vaidya",
        "Richard J. Chen",
        "Drew F. K. Williamson",
        "Thomas Peeters",
        "Andrew H. Song",
        "Faisal Mahmood"
      ],
      "abstract": "Self-supervised learning (SSL) has been successful in building patch\nembeddings of small histology images (e.g., 224x224 pixels), but scaling these\nmodels to learn slide embeddings from the entirety of giga-pixel whole-slide\nimages (WSIs) remains challenging. Here, we leverage complementary information\nfrom gene expression profiles to guide slide representation learning using\nmultimodal pre-training. Expression profiles constitute highly detailed\nmolecular descriptions of a tissue that we hypothesize offer a strong\ntask-agnostic training signal for learning slide embeddings. Our slide and\nexpression (S+E) pre-training strategy, called Tangle, employs\nmodality-specific encoders, the outputs of which are aligned via contrastive\nlearning. Tangle was pre-trained on samples from three different organs: liver\n(n=6,597 S+E pairs), breast (n=1,020), and lung (n=1,012) from two different\nspecies (Homo sapiens and Rattus norvegicus). Across three independent test\ndatasets consisting of 1,265 breast WSIs, 1,946 lung WSIs, and 4,584 liver\nWSIs, Tangle shows significantly better few-shot performance compared to\nsupervised and SSL baselines. When assessed using prototype-based\nclassification and slide retrieval, Tangle also shows a substantial performance\nimprovement over all baselines. Code available at\nhttps://github.com/mahmoodlab/TANGLE.",
      "tldr_zh": "该论文提出了一种名为 Tangle 的多模态预训练策略，用于在计算病理学中通过转录组学指导的幻灯片表示学习（Transcriptomics-guided Slide Representation Learning），以解决自监督学习（SSL）在处理巨像素全滑片图像（WSIs）时的挑战。Tangle 方法使用模态特定编码器对幻灯片图像和基因表达配置文件进行编码，并通过对比学习（contrastive learning）对齐这两个模态的输出，从而利用基因表达作为任务无关的训练信号。在肝脏、乳腺和肺脏的样本上预训练后，Tangle 在多个独立测试数据集上显示出显著优势，比监督和 SSL 基线在少样本性能、基于原型的分类和幻灯片检索任务中提升了整体表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR'24, Oral",
      "pdf_url": "http://arxiv.org/pdf/2405.11618v1",
      "published_date": "2024-05-19 17:17:35 UTC",
      "updated_date": "2024-05-19 17:17:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:37:28.697021"
    },
    {
      "arxiv_id": "2405.11612v2",
      "title": "Sociotechnical Implications of Generative Artificial Intelligence for Information Access",
      "title_zh": "生成式人工智能对信息访问的社会技术影响",
      "authors": [
        "Bhaskar Mitra",
        "Henriette Cramer",
        "Olya Gurevich"
      ],
      "abstract": "Robust access to trustworthy information is a critical need for society with\nimplications for knowledge production, public health education, and promoting\ninformed citizenry in democratic societies. Generative AI technologies may\nenable new ways to access information and improve effectiveness of existing\ninformation retrieval systems but we are only starting to understand and\ngrapple with their long-term social implications. In this chapter, we present\nan overview of some of the systemic consequences and risks of employing\ngenerative AI in the context of information access. We also provide\nrecommendations for evaluation and mitigation, and discuss challenges for\nfuture research.",
      "tldr_zh": "这篇论文探讨了生成式 AI 在信息访问中的社会技术影响（Sociotechnical Implications），强调其可能提升信息检索系统效能并提供新访问方式，但也带来长期社会风险，如对知识生产、公共卫生教育和民主社会的潜在负面影响。作者概述了这些技术的系统性后果和风险，并提出评估与缓解策略，以确保信息可信度。未来研究需应对这些挑战，以促进负责任的 AI 应用。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11612v2",
      "published_date": "2024-05-19 17:04:39 UTC",
      "updated_date": "2024-07-16 15:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:37:39.417674"
    },
    {
      "arxiv_id": "2405.11598v1",
      "title": "AI-Assisted Diagnosis for Covid-19 CXR Screening: From Data Collection to Clinical Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Carlo Alberto Barbano",
        "Riccardo Renzulli",
        "Marco Grosso",
        "Domenico Basile",
        "Marco Busso",
        "Marco Grangetto"
      ],
      "abstract": "In this paper, we present the major results from the Covid Radiographic\nimaging System based on AI (Co.R.S.A.) project, which took place in Italy. This\nproject aims to develop a state-of-the-art AI-based system for diagnosing\nCovid-19 pneumonia from Chest X-ray (CXR) images. The contributions of this\nwork are manyfold: the release of the public CORDA dataset, a deep learning\npipeline for Covid-19 detection, and the clinical validation of the developed\nsolution by expert radiologists. The proposed detection model is based on a\ntwo-step approach that, paired with state-of-the-art debiasing, provides\nreliable results. Most importantly, our investigation includes the actual usage\nof the diagnosis aid tool by radiologists, allowing us to assess the real\nbenefits in terms of accuracy and time efficiency. Project homepage:\nhttps://corsa.di.unito.it/",
      "tldr_zh": "本研究介绍了意大利 Co.R.S.A. 项目，该项目开发了一种基于 AI 的系统，用于从 Chest X-ray (CXR) 图像诊断 Covid-19 肺炎。关键贡献包括发布公共 CORDA 数据集、构建一个两步深度学习管道结合 state-of-the-art 去偏置技术以提高检测可靠性，以及通过放射科医生进行的临床验证。结果显示，该诊断辅助工具显著提升了准确性和时间效率，为实际医疗应用提供了实际益处。项目主页为 https://corsa.di.unito.it/。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T07",
        "I.2.1; I.4.0"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at 21st IEEE International Symposium on Biomedical Imaging\n  (ISBI)",
      "pdf_url": "http://arxiv.org/pdf/2405.11598v1",
      "published_date": "2024-05-19 16:06:26 UTC",
      "updated_date": "2024-05-19 16:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:37:50.771994"
    },
    {
      "arxiv_id": "2405.11597v1",
      "title": "Language Reconstruction with Brain Predictive Coding from fMRI Data",
      "title_zh": "翻译失败",
      "authors": [
        "Congchi Yin",
        "Ziyi Ye",
        "Piji Li"
      ],
      "abstract": "Many recent studies have shown that the perception of speech can be decoded\nfrom brain signals and subsequently reconstructed as continuous language.\nHowever, there is a lack of neurological basis for how the semantic information\nembedded within brain signals can be used more effectively to guide language\nreconstruction. The theory of predictive coding suggests that human brain\nnaturally engages in continuously predicting future word representations that\nspan multiple timescales. This implies that the decoding of brain signals could\npotentially be associated with a predictable future. To explore the predictive\ncoding theory within the context of language reconstruction, this paper\nproposes a novel model \\textsc{PredFT} for jointly modeling neural decoding and\nbrain prediction. It consists of a main decoding network for language\nreconstruction and a side network for predictive coding. The side network\nobtains brain predictive coding representation from related brain regions of\ninterest with a multi-head self-attention module. This representation is fused\ninto the main decoding network with cross-attention to facilitate the language\nmodels' generation process. Experiments are conducted on the largest\nnaturalistic language comprehension fMRI dataset Narratives. \\textsc{PredFT}\nachieves current state-of-the-art decoding performance with a maximum BLEU-1\nscore of $27.8\\%$.",
      "tldr_zh": "本研究探讨了从fMRI数据中重建语言的过程，基于预测编码（predictive coding）理论，该理论认为大脑通过预测未来词表示来处理语义信息。研究提出了一种新模型PredFT，它联合建模神经解码和脑预测，包括一个主解码网络用于语言重建，以及一个侧网络通过多头自注意力（multi-head self-attention）模块从相关脑区获取预测编码表示，并通过交叉注意力（cross-attention）融合到主网络中。实验在最大的自然语言理解fMRI数据集Narratives上进行，PredFT 实现了当前最先进的解码性能，BLEU-1分数最高达27.8%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11597v1",
      "published_date": "2024-05-19 16:06:02 UTC",
      "updated_date": "2024-05-19 16:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:38:03.740024"
    },
    {
      "arxiv_id": "2405.11591v1",
      "title": "Generative Students: Using LLM-Simulated Student Profiles to Support Question Item Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Lu",
        "Xu Wang"
      ],
      "abstract": "Evaluating the quality of automatically generated question items has been a\nlong standing challenge. In this paper, we leverage LLMs to simulate student\nprofiles and generate responses to multiple-choice questions (MCQs). The\ngenerative students' responses to MCQs can further support question item\nevaluation. We propose Generative Students, a prompt architecture designed\nbased on the KLI framework. A generative student profile is a function of the\nlist of knowledge components the student has mastered, has confusion about or\nhas no evidence of knowledge of. We instantiate the Generative Students concept\non the subject domain of heuristic evaluation. We created 45 generative\nstudents using GPT-4 and had them respond to 20 MCQs. We found that the\ngenerative students produced logical and believable responses that were aligned\nwith their profiles. We then compared the generative students' responses to\nreal students' responses on the same set of MCQs and found a high correlation.\nMoreover, there was considerable overlap in the difficult questions identified\nby generative students and real students. A subsequent case study demonstrated\nthat an instructor could improve question quality based on the signals provided\nby Generative Students.",
      "tldr_zh": "本文提出Generative Students，一种基于KLI framework的prompt architecture，使用LLMs模拟学生profiles来评估多项选择题(MCQs)的质量。生成学生profiles根据学生掌握的知识组件（包括已掌握、混淆或无证据的）进行设计，并通过GPT-4实例化45个profiles，让它们响应20个启发式评估领域的MCQs。实验结果显示，生成学生的响应逻辑且与真实学生响应高度相关，能有效识别困难问题，并在后续案例研究中帮助教师改进问题项质量。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To be published in L@S'24: Proceedings of the Eleventh ACM Conference\n  on Learning @ Scale",
      "pdf_url": "http://arxiv.org/pdf/2405.11591v1",
      "published_date": "2024-05-19 15:53:18 UTC",
      "updated_date": "2024-05-19 15:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:38:15.588677"
    },
    {
      "arxiv_id": "2405.11577v4",
      "title": "A Multi-Perspective Analysis of Memorization in Large Language Models",
      "title_zh": "从多视角分析大语言模型中的记忆化",
      "authors": [
        "Bowen Chen",
        "Namgi Han",
        "Yusuke Miyao"
      ],
      "abstract": "Large Language Models (LLMs), trained on massive corpora with billions of\nparameters, show unprecedented performance in various fields. Though surprised\nby their excellent performances, researchers also noticed some special\nbehaviors of those LLMs. One of those behaviors is memorization, in which LLMs\ncan generate the same content used to train them. Though previous research has\ndiscussed memorization, the memorization of LLMs still lacks explanation,\nespecially the cause of memorization and the dynamics of generating them. In\nthis research, we comprehensively discussed memorization from various\nperspectives and extended the discussion scope to not only just the memorized\ncontent but also less and unmemorized content. Through various studies, we\nfound that: (1) Through experiments, we revealed the relation of memorization\nbetween model size, continuation size, and context size. Further, we showed how\nunmemorized sentences transition to memorized sentences. (2) Through embedding\nanalysis, we showed the distribution and decoding dynamics across model size in\nembedding space for sentences with different memorization scores. The n-gram\nstatistics analysis presents d (3) An analysis over n-gram and entropy decoding\ndynamics discovered a boundary effect when the model starts to generate\nmemorized sentences or unmemorized sentences. (4)We trained a Transformer model\nto predict the memorization of different models, showing that it is possible to\npredict memorizations by context.",
      "tldr_zh": "这篇论文从多个角度分析大型语言模型(LLMs)的记忆化行为，包括其成因、生成动态以及未记忆内容的扩展讨论。研究者通过实验揭示了模型大小、延续大小和上下文大小之间的关系，并展示了句子从未记忆到记忆的过渡过程；同时，利用嵌入分析、n-gram 统计和熵分析，探讨了记忆化句子的分布、解码动态以及生成边界效应。最终，他们训练了一个 Transformer 模型来预测记忆化，证明可以通过上下文信息实现这种预测，从而为理解和缓解 LLMs 的记忆化问题提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11577v4",
      "published_date": "2024-05-19 15:00:50 UTC",
      "updated_date": "2024-06-04 15:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:38:27.897231"
    },
    {
      "arxiv_id": "2405.11574v1",
      "title": "Reproducibility Study of CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification",
      "title_zh": "CDUL 的可重复性研究：CLIP 驱动的无监督学习用于多标签图像分类",
      "authors": [
        "Manan Shah",
        "Yash Bhalgat"
      ],
      "abstract": "This report is a reproducibility study of the paper \"CDUL: CLIP-Driven\nUnsupervised Learning for Multi-Label Image Classification\" (Abdelfattah et al,\nICCV 2023). Our report makes the following contributions: (1) We provide a\nreproducible, well commented and open-sourced code implementation for the\nentire method specified in the original paper. (2) We try to verify the\neffectiveness of the novel aggregation strategy which uses the CLIP model to\ninitialize the pseudo labels for the subsequent unsupervised multi-label image\nclassification task. (3) We try to verify the effectiveness of the\ngradient-alignment training method specified in the original paper, which is\nused to update the network parameters and pseudo labels. The code can be found\nat https://github.com/cs-mshah/CDUL",
      "tldr_zh": "本研究是对论文“CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification”（Abdelfattah et al., ICCV 2023）的可重复性研究，主要贡献包括提供一个可重复的开源代码实现。研究验证了使用 CLIP 模型初始化伪标签的聚合策略的有效性，该策略应用于后续的无监督多标签图像分类任务。 additionally, 它还验证了梯度对齐训练方法在更新网络参数和伪标签方面的效能，代码可从 https://github.com/cs-mshah/CDUL 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Reproducibility study",
      "pdf_url": "http://arxiv.org/pdf/2405.11574v1",
      "published_date": "2024-05-19 14:48:19 UTC",
      "updated_date": "2024-05-19 14:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:38:39.694216"
    },
    {
      "arxiv_id": "2405.11559v1",
      "title": "DaVinci at SemEval-2024 Task 9: Few-shot prompting GPT-3.5 for Unconventional Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Suyash Vardhan Mathur",
        "Akshett Rai Jindal",
        "Manish Shrivastava"
      ],
      "abstract": "While significant work has been done in the field of NLP on vertical\nthinking, which involves primarily logical thinking, little work has been done\ntowards lateral thinking, which involves looking at problems from an\nunconventional perspective and defying existing conceptions and notions.\nTowards this direction, SemEval 2024 introduces the task of BRAINTEASER, which\ninvolves two types of questions -- Sentence Puzzles and Word Puzzles that defy\nconventional common-sense reasoning and constraints. In this paper, we tackle\nboth types of questions using few-shot prompting on GPT-3.5 and gain insights\nregarding the difference in the nature of the two types. Our prompting strategy\nplaced us 26th on the leaderboard for the Sentence Puzzle and 15th on the Word\nPuzzle task.",
      "tldr_zh": "本论文探讨了NLP领域中横向思考（unconventional reasoning）的不足，并针对SemEval-2024 Task 9的BRAINTEASER任务处理Sentence Puzzles和Word Puzzles，这两种问题挑战了传统的常识推理。作者采用few-shot prompting on GPT-3.5的方法，通过少量示例提示模型进行解答，并分析了两种谜题在性质上的差异。实验结果显示，该策略在Sentence Puzzle任务中排名第26，在Word Puzzle任务中排名第15，为非传统推理的研究提供了宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11559v1",
      "published_date": "2024-05-19 14:21:53 UTC",
      "updated_date": "2024-05-19 14:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:38:54.032122"
    },
    {
      "arxiv_id": "2405.11551v1",
      "title": "An Invisible Backdoor Attack Based On Semantic Feature",
      "title_zh": "基于语义特征的隐形后门攻击",
      "authors": [
        "Yangming Chen"
      ],
      "abstract": "Backdoor attacks have severely threatened deep neural network (DNN) models in\nthe past several years. These attacks can occur in almost every stage of the\ndeep learning pipeline. Although the attacked model behaves normally on benign\nsamples, it makes wrong predictions for samples containing triggers. However,\nmost existing attacks use visible patterns (e.g., a patch or image\ntransformations) as triggers, which are vulnerable to human inspection. In this\npaper, we propose a novel backdoor attack, making imperceptible changes.\nConcretely, our attack first utilizes the pre-trained victim model to extract\nlow-level and high-level semantic features from clean images and generates\ntrigger pattern associated with high-level features based on channel attention.\nThen, the encoder model generates poisoned images based on the trigger and\nextracted low-level semantic features without causing noticeable feature loss.\nWe evaluate our attack on three prominent image classification DNN across three\nstandard datasets. The results demonstrate that our attack achieves high attack\nsuccess rates while maintaining robustness against backdoor defenses.\nFurthermore, we conduct extensive image similarity experiments to emphasize the\nstealthiness of our attack strategy.",
      "tldr_zh": "这篇论文提出了一种基于语义特征的隐形后门攻击（backdoor attack），旨在通过微小的不可察觉变化来规避人类检查，同时威胁深度神经网络（DNN）的安全性。方法包括利用预训练的受害者模型从干净图像中提取低级和高高级义特征，并基于通道注意力生成与高级特征相关的触发模式，然后通过编码器模型创建中毒图像，以最小化特征损失。实验结果显示，该攻击在三个图像分类DNN和三个标准数据集上实现了高攻击成功率，并对backdoor防御表现出强鲁棒性，同时通过图像相似性实验证明了其隐蔽性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11551v1",
      "published_date": "2024-05-19 13:50:40 UTC",
      "updated_date": "2024-05-19 13:50:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:39:04.725882"
    },
    {
      "arxiv_id": "2405.13050v2",
      "title": "Human-Centered LLM-Agent User Interface: A Position Paper",
      "title_zh": "以人为中心的 LLM-Agent 用户界面：一份立场论文",
      "authors": [
        "Daniel Chin",
        "Yuxuan Wang",
        "Gus Xia"
      ],
      "abstract": "Large Language Model (LLM) -in-the-loop applications have been shown to\neffectively interpret the human user's commands, make plans, and operate\nexternal tools/systems accordingly. Still, the operation scope of the LLM agent\nis limited to passively following the user, requiring the user to frame his/her\nneeds with regard to the underlying tools/systems. We note that the potential\nof an LLM-Agent User Interface (LAUI) is much greater. A user mostly ignorant\nto the underlying tools/systems should be able to work with a LAUI to discover\nan emergent workflow. Contrary to the conventional way of designing an\nexplorable GUI to teach the user a predefined set of ways to use the system, in\nthe ideal LAUI, the LLM agent is initialized to be proficient with the system,\nproactively studies the user and his/her needs, and proposes new interaction\nschemes to the user. To illustrate LAUI, we present Flute X GPT, a concrete\nexample using an LLM agent, a prompt manager, and a flute-tutoring multi-modal\nsoftware-hardware system to facilitate the complex, real-time user experience\nof learning to play the flute.",
      "tldr_zh": "这篇立场论文提出了 Human-Centered LLM-Agent User Interface (LAUI)，一种以人为本的用户界面设计，旨在让 LLM 代理不仅仅被动响应用户命令，而是主动理解用户需求并提出新的交互方案。不同于传统 GUI 的预定义操作方式，LAUI 允许用户在不熟悉底层工具的情况下，通过代理的学习和优化来发现新兴工作流。论文以 Flute X GPT 为例，展示了如何在吹笛子学习的多模态系统中实现实时、复杂的用户体验，从而提升 LLM 代理在实际应用中的可用性和潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13050v2",
      "published_date": "2024-05-19 13:02:45 UTC",
      "updated_date": "2024-09-23 16:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:39:16.249526"
    },
    {
      "arxiv_id": "2405.11537v3",
      "title": "VR-GPT: Visual Language Model for Intelligent Virtual Reality Applications",
      "title_zh": "VR-GPT：用于智能虚拟现实应用的视觉语言模型",
      "authors": [
        "Mikhail Konenkov",
        "Artem Lykov",
        "Daria Trinitatova",
        "Dzmitry Tsetserukou"
      ],
      "abstract": "The advent of immersive Virtual Reality applications has transformed various\ndomains, yet their integration with advanced artificial intelligence\ntechnologies like Visual Language Models remains underexplored. This study\nintroduces a pioneering approach utilizing VLMs within VR environments to\nenhance user interaction and task efficiency. Leveraging the Unity engine and a\ncustom-developed VLM, our system facilitates real-time, intuitive user\ninteractions through natural language processing, without relying on visual\ntext instructions. The incorporation of speech-to-text and text-to-speech\ntechnologies allows for seamless communication between the user and the VLM,\nenabling the system to guide users through complex tasks effectively.\nPreliminary experimental results indicate that utilizing VLMs not only reduces\ntask completion times but also improves user comfort and task engagement\ncompared to traditional VR interaction methods.",
      "tldr_zh": "这项研究引入了 VR-GPT，一种将 Visual Language Models (VLMs) 整合到虚拟现实 (VR) 应用中的创新方法，以提升用户交互和任务效率。系统利用 Unity engine 和自定义 VLM，通过自然语言处理、speech-to-text 和 text-to-speech 技术，实现实时直观交互，而不依赖视觉文本指令。初步实验结果显示，该方法显著缩短任务完成时间，并提高了用户舒适度和参与度。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.RO",
      "comment": "Updated version",
      "pdf_url": "http://arxiv.org/pdf/2405.11537v3",
      "published_date": "2024-05-19 12:56:00 UTC",
      "updated_date": "2024-08-03 10:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:39:27.663982"
    },
    {
      "arxiv_id": "2405.11531v2",
      "title": "Knowledge Graph Pruning for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Fake Lin",
        "Xi Zhu",
        "Ziwei Zhao",
        "Deqiang Huang",
        "Yu Yu",
        "Xueying Li",
        "Zhi Zheng",
        "Tong Xu",
        "Enhong Chen"
      ],
      "abstract": "Recent years have witnessed the prosperity of knowledge graph based\nrecommendation system (KGRS), which enriches the representation of users,\nitems, and entities by structural knowledge with striking improvement.\nNevertheless, its unaffordable computational cost still limits researchers from\nexploring more sophisticated models. We observe that the bottleneck for\ntraining efficiency arises from the knowledge graph, which is plagued by the\nwell-known issue of knowledge explosion. Recently, some works have attempted to\nslim the inflated KG via summarization techniques. However, these summarized\nnodes may ignore the collaborative signals and deviate from the facts that\nnodes in knowledge graph represent symbolic abstractions of entities from the\nreal-world. To this end, in this paper, we propose a novel approach called\nKGTrimmer for knowledge graph pruning tailored for recommendation, to remove\nthe unessential nodes while minimizing performance degradation. Specifically,\nwe design an importance evaluator from a dual-view perspective. For the\ncollective view, we embrace the idea of collective intelligence by extracting\ncommunity consensus based on abundant collaborative signals, i.e. nodes are\nconsidered important if they attract attention of numerous users. For the\nholistic view, we learn a global mask to identify the valueless nodes from\ntheir inherent properties or overall popularity. Next, we build an end-to-end\nimportance-aware graph neural network, which injects filtered knowledge to\nenhance the distillation of valuable user-item collaborative signals.\nUltimately, we generate a pruned knowledge graph with lightweight, stable, and\nrobust properties to facilitate the following-up recommendation task. Extensive\nexperiments are conducted on three publicly available datasets to prove the\neffectiveness and generalization ability of KGTrimmer.",
      "tldr_zh": "该论文针对基于知识图谱的推荐系统（KGRS）计算成本高的问题，提出了一种新型知识图谱修剪方法KGTrimmer，以移除不必要节点的同时最小化性能损失。具体而言，该方法采用双视角的重要性评估器——集体视角基于用户协作信号提取社区共识，整体视角通过全局掩码识别节点固有属性和流行度——并构建端到端的importance-aware graph neural network来注入过滤后的知识，增强用户-物品协作信号的提炼。最终，KGTrimmer生成轻量级、稳定且鲁棒的修剪知识图谱，并在三个公开数据集上的广泛实验中证明了其有效性和泛化能力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11531v2",
      "published_date": "2024-05-19 12:07:24 UTC",
      "updated_date": "2024-07-09 08:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:39:41.314814"
    },
    {
      "arxiv_id": "2405.11525v2",
      "title": "Overcoming Data and Model Heterogeneities in Decentralized Federated Learning via Synthetic Anchors",
      "title_zh": "通过合成锚点克服去中心化联邦学习中的数据和模型异质性",
      "authors": [
        "Chun-Yin Huang",
        "Kartik Srinivas",
        "Xin Zhang",
        "Xiaoxiao Li"
      ],
      "abstract": "Conventional Federated Learning (FL) involves collaborative training of a\nglobal model while maintaining user data privacy. One of its branches,\ndecentralized FL, is a serverless network that allows clients to own and\noptimize different local models separately, which results in saving management\nand communication resources. Despite the promising advancements in\ndecentralized FL, it may reduce model generalizability due to lacking a global\nmodel. In this scenario, managing data and model heterogeneity among clients\nbecomes a crucial problem, which poses a unique challenge that must be\novercome: How can every client's local model learn generalizable representation\nin a decentralized manner? To address this challenge, we propose a novel\nDecentralized FL technique by introducing Synthetic Anchors, dubbed as DeSA.\nBased on the theory of domain adaptation and Knowledge Distillation (KD), we\ntheoretically and empirically show that synthesizing global anchors based on\nraw data distribution facilitates mutual knowledge transfer. We further design\ntwo effective regularization terms for local training: 1) REG loss that\nregularizes the distribution of the client's latent embedding with the anchors\nand 2) KD loss that enables clients to learn from others. Through extensive\nexperiments on diverse client data distributions, we showcase the effectiveness\nof DeSA in enhancing both inter- and intra-domain accuracy of each client.",
      "tldr_zh": "该论文针对去中心化联邦学习（Decentralized FL）中的数据和模型异质性问题，提出了一种名为 DeSA 的新方法，以解决客户端本地模型在缺乏全局模型的情况下学习可泛化表示的挑战。DeSA 通过合成全局锚点（Synthetic Anchors）基于领域适应和知识蒸馏（KD）的理论，促进客户端间的知识转移，并引入两个正则化项：REG loss 用于调节客户端潜在嵌入分布，以及 KD loss 用于从其他客户端学习。实验结果显示，在多样化的客户端数据分布上，DeSA 显著提升了每个客户端的 inter- 和 intra-domain 准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper Accepted at ICML 2024, 23 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.11525v2",
      "published_date": "2024-05-19 11:36:45 UTC",
      "updated_date": "2025-03-12 04:39:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:39:52.508956"
    },
    {
      "arxiv_id": "2405.11504v2",
      "title": "Machine Learning & Wi-Fi: Unveiling the Path Towards AI/ML-Native IEEE 802.11 Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Francesc Wilhelmi",
        "Szymon Szott",
        "Katarzyna Kosek-Szott",
        "Boris Bellalta"
      ],
      "abstract": "Artificial intelligence (AI) and machine learning (ML) are nowadays mature\ntechnologies considered essential for driving the evolution of future\ncommunications systems. Simultaneously, Wi-Fi technology has constantly evolved\nover the past three decades and incorporated new features generation after\ngeneration, thus gaining in complexity. As such, researchers have observed that\nAI/ML functionalities may be required to address the upcoming Wi-Fi challenges\nthat will be otherwise difficult to solve with traditional approaches. This\npaper discusses the role of AI/ML in current and future Wi-Fi networks and\ndepicts the ways forward. A roadmap towards AI/ML-native Wi-Fi, key challenges,\nstandardization efforts, and major enablers are also discussed. An exemplary\nuse case is provided to showcase the potential of AI/ML in Wi-Fi at different\nadoption stages.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)和机器学习(ML)在Wi-Fi网络中的作用，强调了AI/ML如何解决传统方法难以应对的复杂挑战，推动IEEE 802.11网络向AI/ML-Native演变。论文提供了AI/ML在Wi-Fi的路线图，包括关键挑战、标准化努力和主要推动因素。作者通过一个示例用例展示了AI/ML在不同采用阶段的潜力，为未来通信系统的演进提供了指导。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11504v2",
      "published_date": "2024-05-19 10:12:20 UTC",
      "updated_date": "2024-08-30 05:11:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:40:03.956722"
    },
    {
      "arxiv_id": "2405.13049v3",
      "title": "SemEval-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Fanfan Wang",
        "Heqing Ma",
        "Jianfei Yu",
        "Rui Xia",
        "Erik Cambria"
      ],
      "abstract": "The ability to understand emotions is an essential component of human-like\nartificial intelligence, as emotions greatly influence human cognition,\ndecision making, and social interactions. In addition to emotion recognition in\nconversations, the task of identifying the potential causes behind an\nindividual's emotional state in conversations, is of great importance in many\napplication scenarios. We organize SemEval-2024 Task 3, named Multimodal\nEmotion Cause Analysis in Conversations, which aims at extracting all pairs of\nemotions and their corresponding causes from conversations. Under different\nmodality settings, it consists of two subtasks: Textual Emotion-Cause Pair\nExtraction in Conversations (TECPE) and Multimodal Emotion-Cause Pair\nExtraction in Conversations (MECPE). The shared task has attracted 143\nregistrations and 216 successful submissions. In this paper, we introduce the\ntask, dataset and evaluation settings, summarize the systems of the top teams,\nand discuss the findings of the participants.",
      "tldr_zh": "该论文介绍了 SemEval-2024 Task 3：Multimodal Emotion Cause Analysis in Conversations，这是一个旨在从对话中提取情绪及其对应原因的共享任务，以提升人工智能对人类情绪的理解。任务分为两个子任务：TECPE（Textual Emotion-Cause Pair Extraction in Conversations）和 MECPE（Multimodal Emotion-Cause Pair Extraction in Conversations），分别处理文本和多模态设置。该任务吸引了143个注册和216个提交，论文总结了顶级团队的系统表现并讨论了参与者的关键发现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 18th International Workshop on Semantic Evaluation\n  (SemEval-2024). 12 pages, 3 figures, 4 Tables",
      "pdf_url": "http://arxiv.org/pdf/2405.13049v3",
      "published_date": "2024-05-19 09:59:00 UTC",
      "updated_date": "2024-07-08 07:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:40:15.572701"
    },
    {
      "arxiv_id": "2405.11476v1",
      "title": "NubbleDrop: A Simple Way to Improve Matching Strategy for Prompted One-Shot Segmentation",
      "title_zh": "NubbleDrop：一种简单的方法来改进提示引导的一次性分割匹配策略",
      "authors": [
        "Zhiyu Xu",
        "Qingliang Chen"
      ],
      "abstract": "Driven by large data trained segmentation models, such as SAM , research in\none-shot segmentation has experienced significant advancements. Recent\ncontributions like PerSAM and MATCHER , presented at ICLR 2024, utilize a\nsimilar approach by leveraging SAM with one or a few reference images to\ngenerate high quality segmentation masks for target images. Specifically, they\nutilize raw encoded features to compute cosine similarity between patches\nwithin reference and target images along the channel dimension, effectively\ngenerating prompt points or boxes for the target images a technique referred to\nas the matching strategy. However, relying solely on raw features might\nintroduce biases and lack robustness for such a complex task. To address this\nconcern, we delve into the issues of feature interaction and uneven\ndistribution inherent in raw feature based matching. In this paper, we propose\na simple and training-free method to enhance the validity and robustness of the\nmatching strategy at no additional computational cost (NubbleDrop). The core\nconcept involves randomly dropping feature channels (setting them to zero)\nduring the matching process, thereby preventing models from being influenced by\nchannels containing deceptive information. This technique mimics discarding\npathological nubbles, and it can be seamlessly applied to other similarity\ncomputing scenarios. We conduct a comprehensive set of experiments, considering\na wide range of factors, to demonstrate the effectiveness and validity of our\nproposed method. Our results showcase the significant improvements achieved\nthrough this simmple and straightforward approach.",
      "tldr_zh": "这篇论文针对基于 SAM 的 one-shot segmentation 中，matching strategy 依赖原始特征可能引入偏差和缺乏鲁棒性的问题，提出了一种简单、无需训练的方法 NubbleDrop。NubbleDrop 的核心是通过在匹配过程中随机丢弃特征通道（设置为零），模拟丢弃误导性信息，从而增强特征交互和分布的均匀性，提高策略的有效性。该方法无需额外计算成本，并在广泛实验中展示了显著改进，包括在各种因素下提升分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2405.11476v1",
      "published_date": "2024-05-19 08:00:38 UTC",
      "updated_date": "2024-05-19 08:00:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:40:27.437111"
    },
    {
      "arxiv_id": "2405.11473v4",
      "title": "FIFO-Diffusion: Generating Infinite Videos from Text without Training",
      "title_zh": "翻译失败",
      "authors": [
        "Jihwan Kim",
        "Junoh Kang",
        "Jinyoung Choi",
        "Bohyung Han"
      ],
      "abstract": "We propose a novel inference technique based on a pretrained diffusion model\nfor text-conditional video generation. Our approach, called FIFO-Diffusion, is\nconceptually capable of generating infinitely long videos without additional\ntraining. This is achieved by iteratively performing diagonal denoising, which\nsimultaneously processes a series of consecutive frames with increasing noise\nlevels in a queue; our method dequeues a fully denoised frame at the head while\nenqueuing a new random noise frame at the tail. However, diagonal denoising is\na double-edged sword as the frames near the tail can take advantage of cleaner\nframes by forward reference but such a strategy induces the discrepancy between\ntraining and inference. Hence, we introduce latent partitioning to reduce the\ntraining-inference gap and lookahead denoising to leverage the benefit of\nforward referencing. Practically, FIFO-Diffusion consumes a constant amount of\nmemory regardless of the target video length given a baseline model, while\nwell-suited for parallel inference on multiple GPUs. We have demonstrated the\npromising results and effectiveness of the proposed methods on existing\ntext-to-video generation baselines. Generated video examples and source codes\nare available at our project page.",
      "tldr_zh": "我们提出了一种名为 FIFO-Diffusion 的推理技术，利用预训练扩散模型从文本生成无限长视频，而无需额外训练。该方法通过迭代的对角去噪（diagonal denoising）处理一系列连续帧队列，实现从队列头部输出完全去噪帧并添加新噪声帧，同时引入潜在分区（latent partitioning）和前瞻去噪（lookahead denoising）来减少训练-推理差距并利用前向引用优势。实验结果显示，FIFO-Diffusion 在现有文本到视频生成基线上表现出色，具有恒定内存消耗和多 GPU 平行推理能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://jjihwan.github.io/projects/FIFO-Diffusion",
      "pdf_url": "http://arxiv.org/pdf/2405.11473v4",
      "published_date": "2024-05-19 07:48:41 UTC",
      "updated_date": "2024-11-03 12:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:40:40.945938"
    },
    {
      "arxiv_id": "2405.11470v1",
      "title": "VCformer: Variable Correlation Transformer with Inherent Lagged Correlation for Multivariate Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yingnan Yang",
        "Qingling Zhu",
        "Jianyong Chen"
      ],
      "abstract": "Multivariate time series (MTS) forecasting has been extensively applied\nacross diverse domains, such as weather prediction and energy consumption.\nHowever, current studies still rely on the vanilla point-wise self-attention\nmechanism to capture cross-variable dependencies, which is inadequate in\nextracting the intricate cross-correlation implied between variables. To fill\nthis gap, we propose Variable Correlation Transformer (VCformer), which\nutilizes Variable Correlation Attention (VCA) module to mine the correlations\namong variables. Specifically, based on the stochastic process theory, VCA\ncalculates and integrates the cross-correlation scores corresponding to\ndifferent lags between queries and keys, thereby enhancing its ability to\nuncover multivariate relationships. Additionally, inspired by Koopman dynamics\ntheory, we also develop Koopman Temporal Detector (KTD) to better address the\nnon-stationarity in time series. The two key components enable VCformer to\nextract both multivariate correlations and temporal dependencies. Our extensive\nexperiments on eight real-world datasets demonstrate the effectiveness of\nVCformer, achieving top-tier performance compared to other state-of-the-art\nbaseline models. Code is available at this repository:\nhttps://github.com/CSyyn/VCformer.",
      "tldr_zh": "本研究针对多变量时间序列(Multivariate Time Series, MTS)预测中的问题，指出现有方法依赖于点式自注意力(point-wise self-attention)机制，无法有效捕捉变量间的复杂相关性。作者提出Variable Correlation Transformer (VCformer)，其核心组件Variable Correlation Attention (VCA)基于随机过程理论(stochastic process theory)计算不同滞后(lags)的交叉相关分数(cross-correlation scores)，从而更好地挖掘多变量关系；同时，引入Koopman Temporal Detector (KTD)，受Koopman dynamics theory启发，用于处理时间序列的非平稳性(non-stationarity)。VCformer能够同时提取多变量相关性和时间依赖性，在八个真实世界数据集上的实验显示，其性能优于最先进基线模型。代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.11470v1",
      "published_date": "2024-05-19 07:39:22 UTC",
      "updated_date": "2024-05-19 07:39:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:40:52.513769"
    },
    {
      "arxiv_id": "2405.11464v3",
      "title": "Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Pengxiang Lan",
        "Enneng Yang",
        "Yuting Liu",
        "Guibing Guo",
        "Jianzhe Zhao",
        "Xingwei Wang"
      ],
      "abstract": "Prompt tuning is a promising method to fine-tune a pre-trained language model\nwithout retraining its large-scale parameters. Instead, it attaches a soft\nprompt to the input text, whereby downstream tasks can be well adapted by\nmerely learning the embeddings of prompt tokens. Nevertheless, existing methods\nstill suffer from two challenges: (i) they are hard to balance accuracy and\nefficiency. A longer (shorter) soft prompt generally leads to a better(worse)\naccuracy but at the cost of more (less) training time. (ii)The performance may\nnot be consistent when adapting to different downstream tasks. We attribute it\nto the same embedding space but responsible for different requirements of\ndownstream tasks. To address these issues, we propose an Efficient Prompt\nTuning method (EPT) by multi-space projection and prompt fusion. Specifically,\nit decomposes a given soft prompt into a shorter prompt and two low-rank\nmatrices, significantly reducing the training time. Accuracy is also enhanced\nby leveraging low-rank matrices and the short prompt as additional knowledge\nsources to enrich the semantics of the original short prompt. In addition, we\nproject the soft prompt into multiple subspaces to improve the performance\nconsistency, and then adaptively learn the combination weights of different\nspaces through a gating network. Experiments on 13 natural language processing\ndownstream tasks show that our method significantly and consistently\noutperforms 11 comparison methods with the relative percentage of improvements\nup to 12.9%, and training time decreased by 14%.",
      "tldr_zh": "本文提出 Efficient Prompt Tuning (EPT) 方法，通过多空间投影和提示融合来解决传统软提示调整在准确性、效率和任务适应性上的挑战。具体而言，EPT 将软提示分解为较短提示和低秩矩阵，以减少训练时间并丰富语义，同时将提示投影到多个子空间，并通过门控网络自适应学习权重以提升性能一致性。在 13 个自然语言处理任务的实验中，EPT 相较 11 个基准方法，准确率提升高达 12.9%，训练时间减少 14%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11464v3",
      "published_date": "2024-05-19 06:43:12 UTC",
      "updated_date": "2024-12-11 08:03:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:41:04.334710"
    },
    {
      "arxiv_id": "2405.11461v1",
      "title": "DocReLM: Mastering Document Retrieval with Language Model",
      "title_zh": "DocReLM：利用语言模型掌握文档检索",
      "authors": [
        "Gengchen Wei",
        "Xinle Pang",
        "Tianning Zhang",
        "Yu Sun",
        "Xun Qian",
        "Chen Lin",
        "Han-Sen Zhong",
        "Wanli Ouyang"
      ],
      "abstract": "With over 200 million published academic documents and millions of new\ndocuments being written each year, academic researchers face the challenge of\nsearching for information within this vast corpus. However, existing retrieval\nsystems struggle to understand the semantics and domain knowledge present in\nacademic papers. In this work, we demonstrate that by utilizing large language\nmodels, a document retrieval system can achieve advanced semantic understanding\ncapabilities, significantly outperforming existing systems. Our approach\ninvolves training the retriever and reranker using domain-specific data\ngenerated by large language models. Additionally, we utilize large language\nmodels to identify candidates from the references of retrieved papers to\nfurther enhance the performance. We use a test set annotated by academic\nresearchers in the fields of quantum physics and computer vision to evaluate\nour system's performance. The results show that DocReLM achieves a Top 10\naccuracy of 44.12% in computer vision, compared to Google Scholar's 15.69%, and\nan increase to 36.21% in quantum physics, while that of Google Scholar is\n12.96%.",
      "tldr_zh": "本论文提出DocReLM，一种利用大型语言模型（LLMs）提升文档检索性能的系统，旨在解决现有检索系统在理解学术论文语义和领域知识方面的不足。方法包括使用LLMs生成的领域特定数据训练retriever和reranker，并通过从检索论文的引用中识别候选项来进一步优化性能。实验结果显示，DocReLM在计算机视觉领域的Top 10准确率达到44.12%（远超Google Scholar的15.69%），而在量子物理领域为36.21%（比Google Scholar的12.96%有显著提升），从而为高效的学术信息检索提供了新途径。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11461v1",
      "published_date": "2024-05-19 06:30:22 UTC",
      "updated_date": "2024-05-19 06:30:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:41:16.266360"
    },
    {
      "arxiv_id": "2405.11458v1",
      "title": "CPS-LLM: Large Language Model based Safe Usage Plan Generator for Human-in-the-Loop Human-in-the-Plant Cyber-Physical System",
      "title_zh": "翻译失败",
      "authors": [
        "Ayan Banerjee",
        "Aranyak Maity",
        "Payal Kamboj",
        "Sandeep K. S. Gupta"
      ],
      "abstract": "We explore the usage of large language models (LLM) in human-in-the-loop\nhuman-in-the-plant cyber-physical systems (CPS) to translate a high-level\nprompt into a personalized plan of actions, and subsequently convert that plan\ninto a grounded inference of sequential decision-making automated by a\nreal-world CPS controller to achieve a control goal. We show that it is\nrelatively straightforward to contextualize an LLM so it can generate\ndomain-specific plans. However, these plans may be infeasible for the physical\nsystem to execute or the plan may be unsafe for human users. To address this,\nwe propose CPS-LLM, an LLM retrained using an instruction tuning framework,\nwhich ensures that generated plans not only align with the physical system\ndynamics of the CPS but are also safe for human users. The CPS-LLM consists of\ntwo innovative components: a) a liquid time constant neural network-based\nphysical dynamics coefficient estimator that can derive coefficients of\ndynamical models with some unmeasured state variables; b) the model\ncoefficients are then used to train an LLM with prompts embodied with traces\nfrom the dynamical system and the corresponding model coefficients. We show\nthat when the CPS-LLM is integrated with a contextualized chatbot such as BARD\nit can generate feasible and safe plans to manage external events such as meals\nfor automated insulin delivery systems used by Type 1 Diabetes subjects.",
      "tldr_zh": "该研究探讨了在人类参与的网络物理系统（Cyber-Physical Systems, CPS）中，使用Large Language Models (LLM)将高层提示转化为个性化的行动计划，并转化为安全的顺序决策，以实现控制目标。针对LLM生成的计划可能不可行或不安全的挑战，提出CPS-LLM框架，该框架通过指令微调重新训练LLM，包括一个基于liquid time constant neural network的物理动态系数估计器来推断动态模型系数，以及使用动态系统痕迹训练LLM以确保计划符合系统动态和人类安全。实验结果显示，CPS-LLM与聊天机器人如BARD整合后，能生成可行且安全的计划，例如管理Type 1 Diabetes患者的自动胰岛素递送系统，从而提升了CPS的安全性和可靠性。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in AAAI 2024, Planning for Cyber Physical\n  Systems",
      "pdf_url": "http://arxiv.org/pdf/2405.11458v1",
      "published_date": "2024-05-19 06:00:18 UTC",
      "updated_date": "2024-05-19 06:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:41:28.150743"
    },
    {
      "arxiv_id": "2405.11457v1",
      "title": "Deep Dive into Model-free Reinforcement Learning for Biological and Robotic Systems: Theory and Practice",
      "title_zh": "翻译失败",
      "authors": [
        "Yusheng Jiao",
        "Feng Ling",
        "Sina Heydari",
        "Nicolas Heess",
        "Josh Merel",
        "Eva Kanso"
      ],
      "abstract": "Animals and robots exist in a physical world and must coordinate their bodies\nto achieve behavioral objectives. With recent developments in deep\nreinforcement learning, it is now possible for scientists and engineers to\nobtain sensorimotor strategies (policies) for specific tasks using physically\nsimulated bodies and environments. However, the utility of these methods goes\nbeyond the constraints of a specific task; they offer an exciting framework for\nunderstanding the organization of an animal sensorimotor system in connection\nto its morphology and physical interaction with the environment, as well as for\nderiving general design rules for sensing and actuation in robotic systems.\nAlgorithms and code implementing both learning agents and environments are\nincreasingly available, but the basic assumptions and choices that go into the\nformulation of an embodied feedback control problem using deep reinforcement\nlearning may not be immediately apparent. Here, we present a concise exposition\nof the mathematical and algorithmic aspects of model-free reinforcement\nlearning, specifically through the use of \\textit{actor-critic} methods, as a\ntool for investigating the feedback control underlying animal and robotic\nbehavior.",
      "tldr_zh": "这篇论文深入探讨了无模型强化学习（model-free reinforcement learning）在生物和机器人系统中的理论与实践，特别聚焦于 actor-critic 方法，以获取传感器运动策略（policies）。论文强调，这种方法不仅适用于特定任务，还提供了一个框架来理解动物传感器系统的组织、形态与环境的物理交互，以及为机器人系统的传感和驱动设计制定通用规则。通过算法和代码的可用性，研究者可以更易于构建和分析反馈控制问题，从而推动动物行为和机器人工程领域的进展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.11457v1",
      "published_date": "2024-05-19 05:58:44 UTC",
      "updated_date": "2024-05-19 05:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:41:40.221884"
    },
    {
      "arxiv_id": "2405.11451v1",
      "title": "Error Analysis of Three-Layer Neural Network Trained with PGD for Deep Ritz Method",
      "title_zh": "翻译失败",
      "authors": [
        "Yuling Jiao",
        "Yanming Lai",
        "Yang Wang"
      ],
      "abstract": "Machine learning is a rapidly advancing field with diverse applications\nacross various domains. One prominent area of research is the utilization of\ndeep learning techniques for solving partial differential equations(PDEs). In\nthis work, we specifically focus on employing a three-layer tanh neural network\nwithin the framework of the deep Ritz method(DRM) to solve second-order\nelliptic equations with three different types of boundary conditions. We\nperform projected gradient descent(PDG) to train the three-layer network and we\nestablish its global convergence. To the best of our knowledge, we are the\nfirst to provide a comprehensive error analysis of using overparameterized\nnetworks to solve PDE problems, as our analysis simultaneously includes\nestimates for approximation error, generalization error, and optimization\nerror. We present error bound in terms of the sample size $n$ and our work\nprovides guidance on how to set the network depth, width, step size, and number\nof iterations for the projected gradient descent algorithm. Importantly, our\nassumptions in this work are classical and we do not require any additional\nassumptions on the solution of the equation. This ensures the broad\napplicability and generality of our results.",
      "tldr_zh": "本研究分析了使用三层 tanh 神经网络结合 Projected Gradient Descent (PGD) 算法在 Deep Ritz Method (DRM) 框架中解决二阶椭圆方程（包括三种边界条件）的错误问题。论文首次对过参数化网络应用于 partial differential equations (PDEs) 进行全面错误分析，包括近似错误、泛化错误和优化错误，并证明了 PGD 的全局收敛。研究提供了错误界限与样本大小 $n$ 的关系，并指导如何设置网络深度、宽度、步长和迭代次数，且仅依赖经典假设，确保结果的广泛适用性。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "math.AP",
        "stat.ML",
        "65N12, 65N15, 68T07, 62G05, 35J25"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11451v1",
      "published_date": "2024-05-19 05:07:09 UTC",
      "updated_date": "2024-05-19 05:07:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:41:52.448434"
    },
    {
      "arxiv_id": "2405.12954v2",
      "title": "A Method on Searching Better Activation Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyuan Sun",
        "Zihao Wu",
        "Bo Xia",
        "Pu Chang",
        "Zibin Dong",
        "Yifu Yuan",
        "Yongzhe Chang",
        "Xueqian Wang"
      ],
      "abstract": "The success of artificial neural networks (ANNs) hinges greatly on the\njudicious selection of an activation function, introducing non-linearity into\nnetwork and enabling them to model sophisticated relationships in data.\nHowever, the search of activation functions has largely relied on empirical\nknowledge in the past, lacking theoretical guidance, which has hindered the\nidentification of more effective activation functions. In this work, we offer a\nproper solution to such issue. Firstly, we theoretically demonstrate the\nexistence of the worst activation function with boundary conditions (WAFBC)\nfrom the perspective of information entropy. Furthermore, inspired by the\nTaylor expansion form of information entropy functional, we propose the\nEntropy-based Activation Function Optimization (EAFO) methodology. EAFO\nmethodology presents a novel perspective for designing static activation\nfunctions in deep neural networks and the potential of dynamically optimizing\nactivation during iterative training. Utilizing EAFO methodology, we derive a\nnovel activation function from ReLU, known as Correction Regularized ReLU\n(CRReLU). Experiments conducted with vision transformer and its variants on\nCIFAR-10, CIFAR-100 and ImageNet-1K datasets demonstrate the superiority of\nCRReLU over existing corrections of ReLU. Extensive empirical studies on task\nof large language model (LLM) fine-tuning, CRReLU exhibits superior performance\ncompared to GELU, suggesting its broader potential for practical applications.",
      "tldr_zh": "该研究针对激活函数在人工神经网络(ANNs)中的选择问题，提出了一种基于理论指导的方法，以解决过去依赖经验知识的局限性。首先，通过信息熵视角，证明了存在最差激活函数(WAFBC)，并基于熵函数的Taylor展开形式，开发了熵-based激活函数优化(EAFO)方法，用于设计静态激活函数和动态训练优化。其次，利用EAFO从ReLU派生出新的Correction Regularized ReLU(CRReLU)激活函数。实验结果显示，CRReLU在Vision Transformer及其变体上，在CIFAR-10、CIFAR-100和ImageNet-1K数据集上优于现有ReLU修正；在大型语言模型(LLM)微调任务中，CRReLU也超过了GELU，展示了其在实际应用中的广泛潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.12954v2",
      "published_date": "2024-05-19 03:48:05 UTC",
      "updated_date": "2024-05-22 15:43:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:42:04.674051"
    },
    {
      "arxiv_id": "2407.12153v1",
      "title": "A Comparative Analysis of Student Performance Predictions in Online Courses using Heterogeneous Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Trask",
        "Nicholas Lytle",
        "Michael Boyle",
        "David Joyner",
        "Ahmed Mubarak"
      ],
      "abstract": "As online courses become the norm in the higher-education landscape,\ninvestigations into student performance between students who take online vs\non-campus versions of classes become necessary. While attention has been given\nto looking at differences in learning outcomes through comparisons of students'\nend performance, less attention has been given in comparing students'\nengagement patterns between different modalities. In this study, we analyze a\nheterogeneous knowledge graph consisting of students, course videos, formative\nassessments and their interactions to predict student performance via a Graph\nConvolutional Network (GCN). Using students' performance on the assessments, we\nattempt to determine a useful model for identifying at-risk students. We then\ncompare the models generated between 5 on-campus and 2 fully-online MOOC-style\ninstances of the same course. The model developed achieved a 70-90\\% accuracy\nof predicting whether a student would pass a particular problem set based on\ncontent consumed, course instance, and modality.",
      "tldr_zh": "本研究比较了在线课程与校园课程中学生表现的预测差异，重点分析学生参与模式和学习成果。研究利用异构知识图（Heterogeneous Knowledge Graphs）整合学生、课程视频、形成性评估及其互动数据，通过Graph Convolutional Network (GCN)构建模型，以识别高风险学生。结果显示，该模型在5个校园课程和2个在线MOOC实例中，基于内容消耗、课程实例和模式，预测学生通过特定问题集的准确率达70-90%。这项工作为在线教育中的学生支持策略提供了实用见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages, 3 figures, 2 tables, Educational Data Mining Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12153v1",
      "published_date": "2024-05-19 03:33:59 UTC",
      "updated_date": "2024-05-19 03:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:42:15.993924"
    },
    {
      "arxiv_id": "2405.13048v1",
      "title": "Human-Generative AI Collaborative Problem Solving Who Leads and How Students Perceive the Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Gaoxia Zhu",
        "Vidya Sudarshan",
        "Jason Fok Kow",
        "Yew Soon Ong"
      ],
      "abstract": "This research investigates distinct human-generative AI collaboration types\nand students' interaction experiences when collaborating with generative AI\n(i.e., ChatGPT) for problem-solving tasks and how these factors relate to\nstudents' sense of agency and perceived collaborative problem solving. By\nanalyzing the surveys and reflections of 79 undergraduate students, we\nidentified three human-generative AI collaboration types: even contribution,\nhuman leads, and AI leads. Notably, our study shows that 77.21% of students\nperceived they led or had even contributed to collaborative problem-solving\nwhen collaborating with ChatGPT. On the other hand, 15.19% of the human\nparticipants indicated that the collaborations were led by ChatGPT, indicating\na potential tendency for students to rely on ChatGPT. Furthermore, 67.09% of\nstudents perceived their interaction experiences with ChatGPT to be positive or\nmixed. We also found a positive correlation between positive interaction\nexperience and a sense of positive agency. The results of this study contribute\nto our understanding of the collaboration between students and generative AI\nand highlight the need to study further why some students let ChatGPT lead\ncollaborative problem-solving and how to enhance their interaction experience\nthrough curriculum and technology design.",
      "tldr_zh": "本研究探讨了人类与生成式 AI（如 ChatGPT）在问题解决中的协作类型、互动体验，以及这些因素与学生代理感（sense of agency）和感知协作问题解决的关系。研究通过分析79名本科生的调查和反思，识别出三种协作类型：平等贡献（even contribution）、人类主导（human leads）和AI主导（AI leads）。结果显示，77.21%的学生认为自己在协作中主导或平等贡献，而15.19%的学生表示ChatGPT主导，揭示了学生对AI的潜在依赖；此外，67.09%的学生对互动体验持正面或混合态度，并与正面代理感正相关。该研究为理解人类-AI协作提供了洞见，并强调需要进一步探究学生依赖AI的原因，以及通过课程和技术设计优化互动体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This paper appears at the IEEE Conference on Artificial Intelligence\n  (CAI) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13048v1",
      "published_date": "2024-05-19 03:29:16 UTC",
      "updated_date": "2024-05-19 03:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:42:29.571804"
    },
    {
      "arxiv_id": "2405.11422v1",
      "title": "Large Language Models are Biased Reinforcement Learners",
      "title_zh": "大语言模型是有偏差的强化学习者",
      "authors": [
        "William M. Hayes",
        "Nicolas Yax",
        "Stefano Palminteri"
      ],
      "abstract": "In-context learning enables large language models (LLMs) to perform a variety\nof tasks, including learning to make reward-maximizing choices in simple bandit\ntasks. Given their potential use as (autonomous) decision-making agents, it is\nimportant to understand how these models perform such reinforcement learning\n(RL) tasks and the extent to which they are susceptible to biases. Motivated by\nthe fact that, in humans, it has been widely documented that the value of an\noutcome depends on how it compares to other local outcomes, the present study\nfocuses on whether similar value encoding biases apply to how LLMs encode\nrewarding outcomes. Results from experiments with multiple bandit tasks and\nmodels show that LLMs exhibit behavioral signatures of a relative value bias.\nAdding explicit outcome comparisons to the prompt produces opposing effects on\nperformance, enhancing maximization in trained choice sets but impairing\ngeneralization to new choice sets. Computational cognitive modeling reveals\nthat LLM behavior is well-described by a simple RL algorithm that incorporates\nrelative values at the outcome encoding stage. Lastly, we present preliminary\nevidence that the observed biases are not limited to fine-tuned LLMs, and that\nrelative value processing is detectable in the final hidden layer activations\nof a raw, pretrained model. These findings have important implications for the\nuse of LLMs in decision-making applications.",
      "tldr_zh": "本研究发现，大型语言模型 (LLMs) 在执行强化学习 (RL) 任务时存在相对价值偏差，与人类行为类似，即结果的价值取决于与其他局部结果的比较。实验通过多个老虎机 (bandit) 任务和提示修改（如添加显式结果比较）显示，这种偏差导致 LLMs 在训练选择集上提升了最大化性能，但在新选择集上降低了泛化能力。计算认知建模进一步证明，LLMs 的行为可由一个纳入相对价值的简单 RL 算法解释，并初步证据显示这种偏差也存在于预训练模型的隐藏层激活中。这些发现对 LLMs 在决策应用中的可靠性和潜在风险具有重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11422v1",
      "published_date": "2024-05-19 01:43:52 UTC",
      "updated_date": "2024-05-19 01:43:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:42:39.865562"
    },
    {
      "arxiv_id": "2405.11421v1",
      "title": "Assessing Group Fairness with Social Welfare Optimization",
      "title_zh": "基于社会福利优化的群体公平评估",
      "authors": [
        "Violet Chen",
        "J. N. Hooker",
        "Derek Leben"
      ],
      "abstract": "Statistical parity metrics have been widely studied and endorsed in the AI\ncommunity as a means of achieving fairness, but they suffer from at least two\nweaknesses. They disregard the actual welfare consequences of decisions and may\ntherefore fail to achieve the kind of fairness that is desired for\ndisadvantaged groups. In addition, they are often incompatible with each other,\nand there is no convincing justification for selecting one rather than another.\nThis paper explores whether a broader conception of social justice, based on\noptimizing a social welfare function (SWF), can be useful for assessing various\ndefinitions of parity. We focus on the well-known alpha fairness SWF, which has\nbeen defended by axiomatic and bargaining arguments over a period of 70 years.\nWe analyze the optimal solution and show that it can justify demographic parity\nor equalized odds under certain conditions, but frequently requires a departure\nfrom these types of parity. In addition, we find that predictive rate parity is\nof limited usefulness. These results suggest that optimization theory can shed\nlight on the intensely discussed question of how to achieve group fairness in\nAI.",
      "tldr_zh": "该论文批评了统计平权指标（statistical parity metrics）的不足，包括忽略决策的福利后果以及指标间的互不兼容问题，提出通过优化社会福利函数（SWF）来评估群体公平。研究重点分析了alpha fairness SWF，并发现其最优解在某些条件下可支持人口平权（demographic parity）或均衡化胜算（equalized odds），但通常需要偏离这些标准，同时预测率平权（predictive rate parity）的效用有限。主要贡献在于，优化理论为AI中实现群体公平提供了新的评估框架和见解。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11421v1",
      "published_date": "2024-05-19 01:41:04 UTC",
      "updated_date": "2024-05-19 01:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:42:53.524142"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 43,
  "processed_papers_count": 43,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T09:43:13.323100"
}