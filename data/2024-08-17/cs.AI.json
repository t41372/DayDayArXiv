{
  "date": "2024-08-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-17 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 43 篇论文，主要聚焦于大型语言模型（LLMs）的提示敏感性、联邦学习在医疗中的应用、神经网络优化以及跨领域 AI 技术，如自动驾驶和图像处理，其中令人印象深刻的包括 Neuro-Symbolic AI 在军事决策的潜力，以及多个被顶级会议（如 EMNLP、NeurIPS）接受的论文，突显了 AI 模型的鲁棒性和泛化能力的提升。\n\n### 重点论文聚焦：LLMs 和 AI 优化\n今天的大部分论文围绕 LLMs 的鲁棒性、泛化性和应用展开，先聊聊这些热门主题。LLMs 的提示敏感性和不确定性分析备受关注，因为它们直接影响模型在实际部署中的可靠性。\n\n- **How Susceptible are LLMs to Influence in Prompts?（LLMs 对提示的影响易感性如何？）**  \n  这篇论文探讨了 LLMs（如 Llama、Mixtral）对提示中额外信息的敏感性，发现模型容易受权威或自信来源的影响，导致响应偏差。核心贡献是通过实验证明了提供解释的提示会增强模型的易变性，这对确保 LLMs 的可靠部署有重要启示。\n\n- **Unraveling Text Generation in LLMs: A Stochastic Differential Equation Approach（解构 LLMs 中的文本生成：随机微分方程方法）**  \n  作者 Yukun Zhang 提出使用随机微分方程建模 LLMs 的文本生成过程，捕捉确定性和随机变异。关键发现是通过神经网络拟合漂移和扩散项，能更深入理解语言生成动态，提高文本质量的诊断和优化。\n\n- **Reference-Guided Verdict: LLMs-as-Judges in Automatic Evaluation of Free-Form Text（参考指导判决：LLMs 作为评判者在自由形式文本的自动评估中）**  \n  这篇论文使用多个 LLMs 作为评判者，通过参考指导提升开放式任务的评估准确性。贡献在于证明了多模型结合能与人类评估高度相关，提供更可靠的替代传统指标（如 BLEU）的方法。\n\n- **Cognitive LLMs: Towards Integrating Cognitive Architectures and Large Language Models for Manufacturing Decision-making（认知 LLMs：整合认知架构和大型语言模型用于制造决策）**  \n  作者们（如 C. Lee Giles）探索将认知架构（如 ACT-R）与 LLMs 整合，应用于制造决策。发现这种神经符号方法能提升模型的决策鲁棒性，并在实验中表现出色，桥接了人类认知与 AI 的鸿沟。\n\n其他 LLMs 相关论文，如 **Selective Prompt Anchoring for Code Generation（选择性提示锚定用于代码生成）**，提出通过锚定提示提升代码生成准确性，提升了 Pass@1 率高达 12.9%；以及 **Unlocking the Power of LLM Uncertainty for Active In-Context Example Selection（解锁 LLM 不确定性用于主动上下文示例选择）**，使用不确定性指导示例选择，改善了上下文学习效果。这些论文强化了 LLMs 在代码和决策中的潜力，但细节较技术性，快速掠过。\n\n### 医疗和联邦学习应用\n医疗领域的论文特别突出联邦学习在隐私保护下的知识注入，相关论文值得一提。\n\n- **FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models（FEDKIM：自适应联邦知识注入到医疗基础模型）**  \n  这篇被 EMNLP'24 接受的论文提出 FEDKIM 框架，使用联邦学习从私有数据提取知识注入医疗模型。核心发现是它在多模态任务中提升了模型性能，同时保护隐私，在 12 个任务上表现出色。\n\n- **FedKBP: Federated dose prediction framework for knowledge-based planning in radiation therapy（FedKBP：辐射治疗中基于知识规划的联邦剂量预测框架）**  \n  作者开发了 FedKBP，使用联邦学习优化辐射治疗剂量预测。贡献在于证明了联邦训练比独立训练更高效，在非独立分布数据下显著提高预测准确性。\n\n其他医疗论文，如 **EEG-SCMM: Soft Contrastive Masked Modeling for Cross-Corpus EEG-Based Emotion Recognition（EEG-SCMM：软对比掩码建模用于跨语料 EEG 情绪识别）**，通过软对比学习提升 EEG 情绪识别准确性，达到 SOTA 水平；以及 **FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection（FEDMEKI：通过联邦知识注入扩展医疗基础模型的基准）**，构建了基准测试联邦学习在医疗的多模态任务。这些快速提到，因为它们扩展了联邦学习的实用性。\n\n### 其他领域亮点\n交通和图像处理的论文也有亮点，先聊聊最具话题度的。\n\n- **V2X-VLM: End-to-End V2X Cooperative Autonomous Driving Through Large Vision-Language Models（V2X-VLM：通过大型视觉语言模型的端到端 V2X 合作自动驾驶）**  \n  这篇论文引入 V2X-VLM 框架，使用 VLMs 和对比学习提升自动驾驶感知和决策。在 DAIR-V2X 数据集上超越 SOTA，展示了在复杂场景中的鲁棒性。\n\n- **Flatten: Video Action Recognition is an Image Classification task（Flatten：视频动作识别就是图像分类任务）**  \n  作者提出 Flatten 模块，将视频数据扁平化为 2D 图像，简化动作识别过程。发现它能提升现有图像模型的性能，在 Kinetics-400 等数据集上显著改进。\n\n剩余论文如 **TimeSense: Multi-Person Device-free Indoor Localization via RTT（TimeSense：通过 RTT 的多人在室内无设备定位）**，使用深度学习实现高精度室内定位；**Neuro-Symbolic AI for Military Applications（神经符号 AI 用于军事应用）**，被 IEEE TAI 接受，探讨其在决策中的潜力；以及 **Linear Attention is Enough in Spatial-Temporal Forecasting（线性注意力足以用于时空预测）**，提出 STformer 模型简化交通预测。这些论文贡献稳健，但非核心话题，快速掠过不做深聊。\n\n总之，今天的 arXiv 论文强调了 AI 模型的泛化和鲁棒性，尤其是 LLMs 在医疗和自动驾驶的创新应用，值得跟踪。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2408.09307v1",
      "title": "A Benchmark Time Series Dataset for Semiconductor Fabrication Manufacturing Constructed using Component-based Discrete-Event Simulation Models",
      "title_zh": "使用基于组件的离散事件模拟模型构建的半导体制造基准时间序列数据集",
      "authors": [
        "Vamsi Krishna Pendyala",
        "Hessam S. Sarjoughian",
        "Bala Potineni",
        "Edward J. Yellig"
      ],
      "abstract": "Advancements in high-computing devices increase the necessity for improved\nand new understanding and development of smart manufacturing factories.\nDiscrete-event models with simulators have been shown to be critical to\narchitect, designing, building, and operating the manufacturing of\nsemiconductor chips. The diffusion, implantation, and lithography machines have\nintricate processes due to their feedforward and feedback connectivity. The\ndataset collected from simulations of the factory models holds the promise of\ngenerating valuable machine-learning models. As surrogate data-based models,\ntheir executions are highly efficient compared to the physics-based counterpart\nmodels. For the development of surrogate models, it is beneficial to have\npublicly available benchmark simulation models that are grounded in factory\nmodels that have concise structures and accurate behaviors. Hence, in this\nresearch, a dataset is devised and constructed based on a benchmark model of an\nIntel semiconductor fabrication factory. The model is formalized using the\nParallel Discrete-Event System Specification and executed using the DEVS-Suite\nsimulator. The time series dataset is constructed using discrete-event time\ntrajectories. This dataset is further analyzed and used to develop baseline\nunivariate and multivariate machine learning models. The dataset can also be\nutilized in the machine learning community for behavioral analysis based on\nformalized and scalable component-based discrete-event models and simulations.",
      "tldr_zh": "本研究构建了一个基准时间序列数据集，用于半导体制造领域，旨在支持智能工厂的理解和开发。数据集基于组件化的离散事件模拟模型（Component-based Discrete-Event Simulation Models），利用 Parallel Discrete-Event System Specification 进行形式化建模，并通过 DEVS-Suite 模拟器生成，聚焦于半导体芯片制造过程如扩散、植入和光刻机器的复杂交互。实验结果显示，该数据集可用于开发基线单变量和多变量机器学习模型，提高模拟效率，并为机器学习社区提供可扩展的组件化离散事件模拟分析工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09307v1",
      "published_date": "2024-08-17 23:05:47 UTC",
      "updated_date": "2024-08-17 23:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:05:37.140908"
    },
    {
      "arxiv_id": "2408.09285v2",
      "title": "Evaluating Usability and Engagement of Large Language Models in Virtual Reality for Traditional Scottish Curling",
      "title_zh": "翻译失败",
      "authors": [
        "Ka Hei Carrie Lau",
        "Efe Bozkir",
        "Hong Gao",
        "Enkelejda Kasneci"
      ],
      "abstract": "This paper explores the innovative application of Large Language Models\n(LLMs) in Virtual Reality (VR) environments to promote heritage education,\nfocusing on traditional Scottish curling presented in the game ``Scottish\nBonspiel VR''. Our study compares the effectiveness of LLM-based chatbots with\npre-defined scripted chatbots, evaluating key criteria such as usability, user\nengagement, and learning outcomes. The results show that LLM-based chatbots\nsignificantly improve interactivity and engagement, creating a more dynamic and\nimmersive learning environment. This integration helps document and preserve\ncultural heritage and enhances dissemination processes, which are crucial for\nsafeguarding intangible cultural heritage (ICH) amid environmental changes.\nFurthermore, the study highlights the potential of novel technologies in\neducation to provide immersive experiences that foster a deeper appreciation of\ncultural heritage. These findings support the wider application of LLMs and VR\nin cultural education to address global challenges and promote sustainable\npractices to preserve and enhance cultural heritage.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）在虚拟现实（VR）环境中推广传统苏格兰冰壶文化遗产教育的可用性和用户参与度，焦点是游戏“Scottish Bonspiel VR”。研究通过比较LLMs-based聊天机器人与预定义脚本聊天机器人，考察了可用性、用户参与度和学习成果等方面。结果显示，LLMs聊天机器人显著提升了互动性和参与度，创造更动态的沉浸式学习环境，从而有助于记录、保存非物质文化遗产（ICH）并促进其传播。整体发现支持在文化教育中更广泛应用LLMs和VR，以应对全球挑战并推动可持续遗产保护实践。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09285v2",
      "published_date": "2024-08-17 20:13:34 UTC",
      "updated_date": "2024-09-25 13:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:05:50.473055"
    },
    {
      "arxiv_id": "2408.11865v1",
      "title": "How Susceptible are LLMs to Influence in Prompts?",
      "title_zh": "翻译失败",
      "authors": [
        "Sotiris Anagnostidis",
        "Jannis Bulian"
      ],
      "abstract": "Large Language Models (LLMs) are highly sensitive to prompts, including\nadditional context provided therein. As LLMs grow in capability, understanding\ntheir prompt-sensitivity becomes increasingly crucial for ensuring reliable and\nrobust performance, particularly since evaluating these models becomes more\nchallenging. In this work, we investigate how current models (Llama, Mixtral,\nFalcon) respond when presented with additional input from another model,\nmimicking a scenario where a more capable model -- or a system with access to\nmore external information -- provides supplementary information to the target\nmodel. Across a diverse spectrum of question-answering tasks, we study how an\nLLM's response to multiple-choice questions changes when the prompt includes a\nprediction and explanation from another model. Specifically, we explore the\ninfluence of the presence of an explanation, the stated authoritativeness of\nthe source, and the stated confidence of the supplementary input. Our findings\nreveal that models are strongly influenced, and when explanations are provided\nthey are swayed irrespective of the quality of the explanation. The models are\nmore likely to be swayed if the input is presented as being authoritative or\nconfident, but the effect is small in size. This study underscores the\nsignificant prompt-sensitivity of LLMs and highlights the potential risks of\nincorporating outputs from external sources without thorough scrutiny and\nfurther validation. As LLMs continue to advance, understanding and mitigating\nsuch sensitivities will be crucial for their reliable and trustworthy\ndeployment.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 对提示中额外输入的敏感性，特别是当提示包含另一个模型的预测和解释时。研究者测试了 Llama、Mixtral 和 Falcon 等模型在多种问答任务中的响应，考察了解释的存在、来源的权威性和置信度的影响。结果显示，LLMs 容易受到这些因素影响，尤其当提供解释时，无论解释质量如何；来源的权威性和置信度虽有轻微增强效果，但整体影响显著。这突出了 LLMs 的提示敏感性风险，强调在整合外部输入时需进行彻底验证，以确保模型的可靠和可信部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11865v1",
      "published_date": "2024-08-17 17:40:52 UTC",
      "updated_date": "2024-08-17 17:40:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:06:02.087991"
    },
    {
      "arxiv_id": "2408.09262v1",
      "title": "PREMAP: A Unifying PREiMage APproximation Framework for Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xiyue Zhang",
        "Benjie Wang",
        "Marta Kwiatkowska",
        "Huan Zhang"
      ],
      "abstract": "Most methods for neural network verification focus on bounding the image,\ni.e., set of outputs for a given input set. This can be used to, for example,\ncheck the robustness of neural network predictions to bounded perturbations of\nan input. However, verifying properties concerning the preimage, i.e., the set\nof inputs satisfying an output property, requires abstractions in the input\nspace. We present a general framework for preimage abstraction that produces\nunder- and over-approximations of any polyhedral output set. Our framework\nemploys cheap parameterised linear relaxations of the neural network, together\nwith an anytime refinement procedure that iteratively partitions the input\nregion by splitting on input features and neurons. The effectiveness of our\napproach relies on carefully designed heuristics and optimization objectives to\nachieve rapid improvements in the approximation volume. We evaluate our method\non a range of tasks, demonstrating significant improvement in efficiency and\nscalability to high-input-dimensional image classification tasks compared to\nstate-of-the-art techniques. Further, we showcase the application to\nquantitative verification and robustness analysis, presenting a sound and\ncomplete algorithm for the former and providing sound quantitative results for\nthe latter.",
      "tldr_zh": "本研究提出PREMAP框架，这是一个统一的预图像逼近方法，用于神经网络验证，通过生成任何多面体输出集的下限和上限逼近来分析满足输出属性的输入集。框架采用廉价的参数化线性松弛（parameterised linear relaxations）结合随时可用的精炼过程（anytime refinement procedure），通过在输入特征和神经元上迭代分区，并利用精心设计的启发式和优化目标来快速改善逼近体积。实验结果显示，该方法在效率和可扩展性上显著优于现有技术，尤其适用于高输入维度的图像分类任务，并成功应用于定量验证和鲁棒性分析，提供可靠且完整的算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2305.03686",
      "pdf_url": "http://arxiv.org/pdf/2408.09262v1",
      "published_date": "2024-08-17 17:24:47 UTC",
      "updated_date": "2024-08-17 17:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:06:14.143607"
    },
    {
      "arxiv_id": "2408.09251v2",
      "title": "V2X-VLM: End-to-End V2X Cooperative Autonomous Driving Through Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junwei You",
        "Haotian Shi",
        "Zhuoyu Jiang",
        "Zilin Huang",
        "Rui Gan",
        "Keshu Wu",
        "Xi Cheng",
        "Xiaopeng Li",
        "Bin Ran"
      ],
      "abstract": "Advancements in autonomous driving have increasingly focused on end-to-end\n(E2E) systems that manage the full spectrum of driving tasks, from\nenvironmental perception to vehicle navigation and control. This paper\nintroduces V2X-VLM, an innovative E2E vehicle-infrastructure cooperative\nautonomous driving (VICAD) framework with Vehicle-to-Everything (V2X) systems\nand large vision-language models (VLMs). V2X-VLM is designed to enhance\nsituational awareness, decision-making, and ultimate trajectory planning by\nintegrating multimodel data from vehicle-mounted cameras, infrastructure\nsensors, and textual information. The contrastive learning method is further\nemployed to complement VLM by refining feature discrimination, assisting the\nmodel to learn robust representations of the driving environment. Evaluations\non the DAIR-V2X dataset show that V2X-VLM outperforms state-of-the-art\ncooperative autonomous driving methods, while additional tests on corner cases\nvalidate its robustness in real-world driving conditions.",
      "tldr_zh": "本论文提出 V2X-VLM，一种端到端 (E2E) 车辆-基础设施合作自动驾驶 (VICAD) 框架，结合 Vehicle-to-Everything (V2X) 系统和大型视觉语言模型 (VLMs)，旨在提升情境感知、决策和轨迹规划，通过整合车辆摄像头、基础设施传感器以及文本信息等多模态数据。框架采用对比学习方法来优化 VLM 的特征区分能力，从而帮助模型学习更鲁棒的驾驶环境表示。在 DAIR-V2X 数据集上的评估显示，V2X-VLM 优于现有最先进方法，并在极端驾驶场景中证明了其在真实世界条件下的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09251v2",
      "published_date": "2024-08-17 16:42:13 UTC",
      "updated_date": "2024-09-16 05:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:06:25.572846"
    },
    {
      "arxiv_id": "2408.09239v1",
      "title": "Towards Effective Top-N Hamming Search via Bipartite Graph Contrastive Hashing",
      "title_zh": "通过二分图对比",
      "authors": [
        "Yankai Chen",
        "Yixiang Fang",
        "Yifei Zhang",
        "Chenhao Ma",
        "Yang Hong",
        "Irwin King"
      ],
      "abstract": "Searching on bipartite graphs serves as a fundamental task for various\nreal-world applications, such as recommendation systems, database retrieval,\nand document querying. Conventional approaches rely on similarity matching in\ncontinuous Euclidean space of vectorized node embeddings. To handle intensive\nsimilarity computation efficiently, hashing techniques for graph-structured\ndata have emerged as a prominent research direction. However, despite the\nretrieval efficiency in Hamming space, previous studies have encountered\ncatastrophic performance decay. To address this challenge, we investigate the\nproblem of hashing with Graph Convolutional Network for effective Top-N search.\nOur findings indicate the learning effectiveness of incorporating hashing\ntechniques within the exploration of bipartite graph reception fields, as\nopposed to simply treating hashing as post-processing to output embeddings. To\nfurther enhance the model performance, we advance upon these findings and\npropose Bipartite Graph Contrastive Hashing (BGCH+). BGCH+ introduces a novel\ndual augmentation approach to both intermediate information and hash code\noutputs in the latent feature spaces, thereby producing more expressive and\nrobust hash codes within a dual self-supervised learning paradigm.\nComprehensive empirical analyses on six real-world benchmarks validate the\neffectiveness of our dual feature contrastive learning in boosting the\nperformance of BGCH+ compared to existing approaches.",
      "tldr_zh": "本研究针对二部图上的Top-N Hamming搜索问题，探讨了如何通过Graph Convolutional Network（GCN）结合哈希技术来提升检索效率和准确性，以应用于推荐系统和数据库检索等场景。作者提出Bipartite Graph Contrastive Hashing（BGCH+）模型，通过双重增强方法对中间特征和哈希码输出进行增强，实现双重自监督学习，从而生成更具表达性和鲁棒性的哈希码。实验结果显示，BGCH+在六个真实世界基准上显著优于现有方法，证明了其在处理图结构数据时的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09239v1",
      "published_date": "2024-08-17 16:21:32 UTC",
      "updated_date": "2024-08-17 16:21:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:06:37.871752"
    },
    {
      "arxiv_id": "2408.09236v3",
      "title": "Hybrid Semantic Search: Unveiling User Intent Beyond Keywords",
      "title_zh": "混合语义搜索：揭示超越关键词的用户意图",
      "authors": [
        "Aman Ahluwalia",
        "Bishwajit Sutradhar",
        "Karishma Ghosh",
        "Indrapal Yadav",
        "Arpan Sheetal",
        "Prashant Patil"
      ],
      "abstract": "This paper addresses the limitations of traditional keyword-based search in\nunderstanding user intent and introduces a novel hybrid search approach that\nleverages the strengths of non-semantic search engines, Large Language Models\n(LLMs), and embedding models. The proposed system integrates keyword matching,\nsemantic vector embeddings, and LLM-generated structured queries to deliver\nhighly relevant and contextually appropriate search results. By combining these\ncomplementary methods, the hybrid approach effectively captures both explicit\nand implicit user intent.The paper further explores techniques to optimize\nquery execution for faster response times and demonstrates the effectiveness of\nthis hybrid search model in producing comprehensive and accurate search\noutcomes.",
      "tldr_zh": "本文针对传统关键词-based search 在理解用户意图方面的局限性，提出了一种新型混合搜索方法，该方法整合非语义搜索引擎、Large Language Models (LLMs) 和 embedding models 的优势。系统通过关键词匹配、语义向量嵌入以及 LLM 生成的结构化查询，捕捉显性和隐性用户意图，从而提供相关性和上下文更强的搜索结果。论文还探讨了优化查询执行以提升响应速度的技术，并证明了这一混合模型在实现全面、准确搜索方面的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09236v3",
      "published_date": "2024-08-17 16:04:31 UTC",
      "updated_date": "2024-09-06 13:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:06:52.036592"
    },
    {
      "arxiv_id": "2408.09235v2",
      "title": "Reference-Guided Verdict: LLMs-as-Judges in Automatic Evaluation of Free-Form Text",
      "title_zh": "翻译失败",
      "authors": [
        "Sher Badshah",
        "Hassan Sajjad"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) as chat assistants capable of\ngenerating human-like conversations has amplified the need for robust\nevaluation methods, particularly for open-ended tasks. Conventional metrics\nlike BLEU and ROUGE, while useful, are increasingly inadequate for capturing\nthe subtle semantics and contextual richness of such generative outputs. We\npropose a reference-guided verdict method that automates the evaluation process\nby leveraging multiple LLMs-as-judges. Through experiments on three open-ended\nquestion-answering tasks, we demonstrate that combining multiple LLMs-as-judges\nsignificantly improves the reliability and accuracy of evaluations,\nparticularly in complex tasks where a single model might struggle. Our findings\nreveal a strong correlation with human evaluations, establishing our method as\na viable and effective alternative to traditional metrics and human judgments,\nparticularly in the context of LLM-based chat assistants where the complexity\nand diversity of responses challenge existing benchmarks.",
      "tldr_zh": "本研究探讨了评估大型语言模型(LLMs)生成的人类对话时面临的挑战，指出传统指标如BLEU和ROUGE无法捕捉细微语义和上下文。作者提出了一种参考引导的评估方法，即使用多个LLMs-as-Judges来自动评估开放式文本，通过三个问答任务的实验证明，这种组合方式显著提高了评估的可靠性和准确性。结果显示，该方法与人类评估高度相关，为LLM-based聊天助手的复杂响应评估提供了一个有效替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50, 68T07, 68T20",
        "I.2.0; I.2.7; I.2.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09235v2",
      "published_date": "2024-08-17 16:01:45 UTC",
      "updated_date": "2024-08-20 15:12:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:07:01.034473"
    },
    {
      "arxiv_id": "2408.10276v4",
      "title": "FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models",
      "title_zh": "FEDKIM：自适应联邦知识注入到医学基础模型中",
      "authors": [
        "Xiaochen Wang",
        "Jiaqi Wang",
        "Houping Xiao",
        "Jinghui Chen",
        "Fenglong Ma"
      ],
      "abstract": "Foundation models have demonstrated remarkable capabilities in handling\ndiverse modalities and tasks, outperforming conventional artificial\nintelligence (AI) approaches that are highly task-specific and\nmodality-reliant. In the medical domain, however, the development of\ncomprehensive foundation models is constrained by limited access to diverse\nmodalities and stringent privacy regulations. To address these constraints,\nthis study introduces a novel knowledge injection approach, FedKIM, designed to\nscale the medical foundation model within a federated learning framework.\nFedKIM leverages lightweight local models to extract healthcare knowledge from\nprivate data and integrates this knowledge into a centralized foundation model\nusing a designed adaptive Multitask Multimodal Mixture Of Experts (M3OE)\nmodule. This method not only preserves privacy but also enhances the model's\nability to handle complex medical tasks involving multiple modalities. Our\nextensive experiments across twelve tasks in seven modalities demonstrate the\neffectiveness of FedKIM in various settings, highlighting its potential to\nscale medical foundation models without direct access to sensitive data.",
      "tldr_zh": "本文提出FEDKIM，一种自适应联邦知识注入方法，用于在联邦学习框架下扩展医疗Foundation models，以应对数据访问限制和隐私法规的挑战。该方法利用轻量级本地模型从私有数据中提取医疗知识，并通过设计的自适应Multitask Multimodal Mixture Of Experts (M3OE)模块整合到集中式模型中，从而增强模型处理多模态复杂任务的能力，同时保护数据隐私。在七个模态的十二个任务上进行的广泛实验证明了FEDKIM的有效性，展示了其在不直接访问敏感数据的情况下扩展医疗模型的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by EMNLP'24 Main",
      "pdf_url": "http://arxiv.org/pdf/2408.10276v4",
      "published_date": "2024-08-17 15:42:29 UTC",
      "updated_date": "2025-05-04 20:14:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:07:14.396616"
    },
    {
      "arxiv_id": "2408.11863v1",
      "title": "Unraveling Text Generation in LLMs: A Stochastic Differential Equation Approach",
      "title_zh": "揭示 LLMs 中的文本生成：一种随机微分方程方法",
      "authors": [
        "Yukun Zhang"
      ],
      "abstract": "This paper explores the application of Stochastic Differential Equations\n(SDE) to interpret the text generation process of Large Language Models (LLMs)\nsuch as GPT-4. Text generation in LLMs is modeled as a stochastic process where\neach step depends on previously generated content and model parameters,\nsampling the next word from a vocabulary distribution. We represent this\ngeneration process using SDE to capture both deterministic trends and\nstochastic perturbations. The drift term describes the deterministic trends in\nthe generation process, while the diffusion term captures the stochastic\nvariations. We fit these functions using neural networks and validate the model\non real-world text corpora. Through numerical simulations and comprehensive\nanalyses, including drift and diffusion analysis, stochastic process property\nevaluation, and phase space exploration, we provide deep insights into the\ndynamics of text generation. This approach not only enhances the understanding\nof the inner workings of LLMs but also offers a novel mathematical perspective\non language generation, which is crucial for diagnosing, optimizing, and\ncontrolling the quality of generated text.",
      "tldr_zh": "本文使用 Stochastic Differential Equations (SDE) 来解读大型语言模型 (LLMs) 如 GPT-4 的文本生成过程，将其建模为一个随机过程，其中 drift term 描述确定性趋势，diffusion term 捕获随机变异。研究者通过神经网络拟合这些函数，并在真实文本语料上进行验证和模拟分析，包括漂移与扩散分析、随机过程属性评估以及相空间探索。结果表明，这一方法为理解 LLMs 的内部动态提供了新颖的数学视角，有助于诊断、优化和控制生成的文本质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11863v1",
      "published_date": "2024-08-17 15:30:27 UTC",
      "updated_date": "2024-08-17 15:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:07:26.242852"
    },
    {
      "arxiv_id": "2408.09230v1",
      "title": "Siamese Multiple Attention Temporal Convolution Networks for Human Mobility Signature Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng Zheng",
        "Yuchen Jiang",
        "Shiyao Zhang",
        "Xuetao Wei"
      ],
      "abstract": "The Human Mobility Signature Identification (HuMID) problem stands as a\nfundamental task within the realm of driving style representation, dedicated to\ndiscerning latent driving behaviors and preferences from diverse driver\ntrajectories for driver identification. Its solutions hold significant\nimplications across various domains (e.g., ride-hailing, insurance), wherein\ntheir application serves to safeguard users and mitigate potential fraudulent\nactivities. Present HuMID solutions often exhibit limitations in adaptability\nwhen confronted with lengthy trajectories, consequently incurring substantial\ncomputational overhead. Furthermore, their inability to effectively extract\ncrucial local information further impedes their performance. To address this\nproblem, we propose a Siamese Multiple Attention Temporal Convolutional Network\n(Siamese MA-TCN) to capitalize on the strengths of both TCN architecture and\nmulti-head self-attention, enabling the proficient extraction of both local and\nlong-term dependencies. Additionally, we devise a novel attention mechanism\ntailored for the efficient aggregation of multi-scale representations derived\nfrom our model. Experimental evaluations conducted on two real-world taxi\ntrajectory datasets reveal that our proposed model effectively extracts both\nlocal key information and long-term dependencies. These findings highlight the\nmodel's outstanding generalization capabilities, demonstrating its robustness\nand adaptability across datasets of varying sizes.",
      "tldr_zh": "本文针对Human Mobility Signature Identification (HuMID)问题，提出Siamese Multiple Attention Temporal Convolution Networks (Siamese MA-TCN)模型，该模型结合TCN架构和多头自注意力机制，能够高效提取驾驶轨迹中的本地关键信息和长期依赖。模型还设计了一种新型注意力机制，用于聚合多尺度表示，以提升处理长轨迹的适应性和计算效率。在两个真实出租车轨迹数据集上的实验结果表明，Siamese MA-TCN在泛化能力、鲁棒性和整体性能上均表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "27th IEEE International Conference on Intelligent Transportation\n  Systems (ITSC) (ITSC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.09230v1",
      "published_date": "2024-08-17 15:27:38 UTC",
      "updated_date": "2024-08-17 15:27:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:07:39.506442"
    },
    {
      "arxiv_id": "2408.09227v1",
      "title": "FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Wang",
        "Xiaochen Wang",
        "Lingjuan Lyu",
        "Jinghui Chen",
        "Fenglong Ma"
      ],
      "abstract": "This study introduces the Federated Medical Knowledge Injection (FEDMEKI)\nplatform, a new benchmark designed to address the unique challenges of\nintegrating medical knowledge into foundation models under privacy constraints.\nBy leveraging a cross-silo federated learning approach, FEDMEKI circumvents the\nissues associated with centralized data collection, which is often prohibited\nunder health regulations like the Health Insurance Portability and\nAccountability Act (HIPAA) in the USA. The platform is meticulously designed to\nhandle multi-site, multi-modal, and multi-task medical data, which includes 7\nmedical modalities, including images, signals, texts, laboratory test results,\nvital signs, input variables, and output variables. The curated dataset to\nvalidate FEDMEKI covers 8 medical tasks, including 6 classification tasks (lung\nopacity detection, COVID-19 detection, electrocardiogram (ECG) abnormal\ndetection, mortality prediction, sepsis prediction, and enlarged\ncardiomediastinum detection) and 2 generation tasks (medical visual question\nanswering (MedVQA) and ECG noise clarification). This comprehensive dataset is\npartitioned across several clients to facilitate the decentralized training\nprocess under 16 benchmark approaches. FEDMEKI not only preserves data privacy\nbut also enhances the capability of medical foundation models by allowing them\nto learn from a broader spectrum of medical knowledge without direct data\nexposure, thereby setting a new benchmark in the application of foundation\nmodels within the healthcare sector.",
      "tldr_zh": "这篇论文引入了 FEDMEKI 基准平台，通过联邦知识注入（Federated Knowledge Injection）方法扩展医疗基础模型，同时在隐私约束下（如 HIPAA 法规）避免集中式数据收集。FEDMEKI 采用跨站点联邦学习（Federated Learning）处理多站点、多模态和多任务医疗数据，包括图像、信号、文本、实验室测试结果、生命体征等 7 种模态。平台涵盖 8 个医疗任务（6 个分类任务如肺不透明检测和 COVID-19 检测，以及 2 个生成任务如 MedVQA 和 ECG 噪声澄清），数据集被分区在多个客户端上使用 16 种基准方法进行去中心化训练。最终，FEDMEKI 提升了模型从广泛医疗知识中学习的能力，同时保护数据隐私，为医疗领域的基础模型应用树立了新标准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to Neurips 2024 DB Track",
      "pdf_url": "http://arxiv.org/pdf/2408.09227v1",
      "published_date": "2024-08-17 15:18:56 UTC",
      "updated_date": "2024-08-17 15:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:07:53.872993"
    },
    {
      "arxiv_id": "2408.09224v2",
      "title": "Neuro-Symbolic AI for Military Applications",
      "title_zh": "神经符号 AI 用于军事应用",
      "authors": [
        "Desta Haileselassie Hagos",
        "Danda B. Rawat"
      ],
      "abstract": "Artificial Intelligence (AI) plays a significant role in enhancing the\ncapabilities of defense systems, revolutionizing strategic decision-making, and\nshaping the future landscape of military operations. Neuro-Symbolic AI is an\nemerging approach that leverages and augments the strengths of neural networks\nand symbolic reasoning. These systems have the potential to be more impactful\nand flexible than traditional AI systems, making them well-suited for military\napplications. This paper comprehensively explores the diverse dimensions and\ncapabilities of Neuro-Symbolic AI, aiming to shed light on its potential\napplications in military contexts. We investigate its capacity to improve\ndecision-making, automate complex intelligence analysis, and strengthen\nautonomous systems. We further explore its potential to solve complex tasks in\nvarious domains, in addition to its applications in military contexts. Through\nthis exploration, we address ethical, strategic, and technical considerations\ncrucial to the development and deployment of Neuro-Symbolic AI in military and\ncivilian applications. Contributing to the growing body of research, this study\nrepresents a comprehensive exploration of the extensive possibilities offered\nby Neuro-Symbolic AI.",
      "tldr_zh": "本论文探讨了 Neuro-Symbolic AI 在军事领域的应用，该技术结合了神经网络和符号推理的优势，使其比传统 AI 系统更具影响力和灵活性。研究重点分析了 Neuro-Symbolic AI 如何提升决策过程、自动化复杂情报分析以及强化自主系统，并在军事及其他领域解决复杂任务。论文还讨论了相关的伦理、战略和技术考虑，为其在军事和民用应用中的开发提供全面见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IEEE Transactions on Artificial Intelligence (TAI)",
      "pdf_url": "http://arxiv.org/pdf/2408.09224v2",
      "published_date": "2024-08-17 15:06:43 UTC",
      "updated_date": "2024-08-24 20:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:08:02.254798"
    },
    {
      "arxiv_id": "2408.09220v1",
      "title": "Flatten: Video Action Recognition is an Image Classification task",
      "title_zh": "Flatten：视频动作识别是一个图像分类任务",
      "authors": [
        "Junlin Chen",
        "Chengcheng Xu",
        "Yangfan Xu",
        "Jian Yang",
        "Jun Li",
        "Zhiping Shi"
      ],
      "abstract": "In recent years, video action recognition, as a fundamental task in the field\nof video understanding, has been deeply explored by numerous researchers.Most\ntraditional video action recognition methods typically involve converting\nvideos into three-dimensional data that encapsulates both spatial and temporal\ninformation, subsequently leveraging prevalent image understanding models to\nmodel and analyze these data. However,these methods have significant drawbacks.\nFirstly, when delving into video action recognition tasks, image understanding\nmodels often need to be adapted accordingly in terms of model architecture and\npreprocessing for these spatiotemporal tasks; Secondly, dealing with\nhigh-dimensional data often poses greater challenges and incurs higher time\ncosts compared to its lower-dimensional counterparts.To bridge the gap between\nimage-understanding and video-understanding tasks while simplifying the\ncomplexity of video comprehension, we introduce a novel video representation\narchitecture, Flatten, which serves as a plug-and-play module that can be\nseamlessly integrated into any image-understanding network for efficient and\neffective 3D temporal data modeling.Specifically, by applying specific\nflattening operations (e.g., row-major transform), 3D spatiotemporal data is\ntransformed into 2D spatial information, and then ordinary image understanding\nmodels are used to capture temporal dynamic and spatial semantic information,\nwhich in turn accomplishes effective and efficient video action recognition.\nExtensive experiments on commonly used datasets (Kinetics-400,\nSomething-Something v2, and HMDB-51) and three classical image classification\nmodels (Uniformer, SwinV2, and ResNet), have demonstrated that embedding\nFlatten provides a significant performance improvements over original model.",
      "tldr_zh": "本文提出 Flatten 架构，将视频动作识别任务简化为图像分类任务，以解决传统方法中处理三维时空数据的复杂性和高计算成本问题。Flatten 作为一个即插即用的模块，通过行主变换等扁平化操作，将 3D 时空数据转换为 2D 空间信息，然后利用普通图像理解模型（如 Uniformer、SwinV2 和 ResNet）捕捉时序动态和空间语义。实验在 Kinetics-400、Something-Something v2 和 HMDB-51 数据集上显示，嵌入 Flatten 后，基线模型的性能显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13pages, 6figures",
      "pdf_url": "http://arxiv.org/pdf/2408.09220v1",
      "published_date": "2024-08-17 14:59:58 UTC",
      "updated_date": "2024-08-17 14:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:08:16.251472"
    },
    {
      "arxiv_id": "2408.10275v2",
      "title": "FedKBP: Federated dose prediction framework for knowledge-based planning in radiation therapy",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyun Chen",
        "Martin King",
        "Yading Yuan"
      ],
      "abstract": "Dose prediction plays a key role in knowledge-based planning (KBP) by\nautomatically generating patient-specific dose distribution. Recent advances in\ndeep learning-based dose prediction methods necessitates collaboration among\ndata contributors for improved performance. Federated learning (FL) has emerged\nas a solution, enabling medical centers to jointly train deep-learning models\nwithout compromising patient data privacy. We developed the FedKBP framework to\nevaluate the performances of centralized, federated, and individual (i.e.\nseparated) training of dose prediction model on the 340 plans from OpenKBP\ndataset. To simulate FL and individual training, we divided the data into 8\ntraining sites. To evaluate the effect of inter-site data variation on model\ntraining, we implemented two types of case distributions: 1) Independent and\nidentically distributed (IID), where the training and validating cases were\nevenly divided among the 8 sites, and 2) non-IID, where some sites have more\ncases than others. The results show FL consistently outperforms individual\ntraining on both model optimization speed and out-of-sample testing scores,\nhighlighting the advantage of FL over individual training. Under IID data\ndivision, FL shows comparable performance to centralized training, underscoring\nFL as a promising alternative to traditional pooled-data training. Under\nnon-IID division, larger sites outperformed smaller sites by up to 19% on\ntesting scores, confirming the need of collaboration among data owners to\nachieve better prediction accuracy. Meanwhile, non-IID FL showed reduced\nperformance as compared to IID FL, posing the need for more sophisticated FL\nmethod beyond mere model averaging to handle data variation among participating\nsites.",
      "tldr_zh": "本论文提出了 FedKBP 框架，这是一种基于 Federated learning (FL) 的剂量预测方法，用于知识-based planning (KBP) 在放射治疗中的应用，旨在通过多中心合作训练模型来提升性能，同时保护患者数据隐私。研究在 OpenKBP 数据集的 340 个计划上评估了集中式、FL 和独立训练的性能，并模拟了 Independent and identically distributed (IID) 和 non-IID 数据分布场景。结果显示，FL 在模型优化速度和测试分数上均优于独立训练，并在 IID 分布下与集中式训练相当，证明了其作为替代方案的价值。在 non-IID 分布下，较大站点比小站点高出 19% 的测试分数，突显了数据变异性对性能的影响，并强调了需要更先进的 FL 方法来处理这种变异，以实现更准确的预测。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by SPIE Medical Imaging 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2408.10275v2",
      "published_date": "2024-08-17 14:57:14 UTC",
      "updated_date": "2025-01-28 23:30:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:08:27.890815"
    },
    {
      "arxiv_id": "2408.09210v2",
      "title": "On the Improvement of Generalization and Stability of Forward-Only Learning via Neural Polarization",
      "title_zh": "翻译失败",
      "authors": [
        "Erik B. Terres-Escudero",
        "Javier Del Ser",
        "Pablo Garcia-Bringas"
      ],
      "abstract": "Forward-only learning algorithms have recently gained attention as\nalternatives to gradient backpropagation, replacing the backward step of this\nlatter solver with an additional contrastive forward pass. Among these\napproaches, the so-called Forward-Forward Algorithm (FFA) has been shown to\nachieve competitive levels of performance in terms of generalization and\ncomplexity. Networks trained using FFA learn to contrastively maximize a\nlayer-wise defined goodness score when presented with real data (denoted as\npositive samples) and to minimize it when processing synthetic data (corr.\nnegative samples). However, this algorithm still faces weaknesses that\nnegatively affect the model accuracy and training stability, primarily due to a\ngradient imbalance between positive and negative samples. To overcome this\nissue, in this work we propose a novel implementation of the FFA algorithm,\ndenoted as Polar-FFA, which extends the original formulation by introducing a\nneural division (\\emph{polarization}) between positive and negative instances.\nNeurons in each of these groups aim to maximize their goodness when presented\nwith their respective data type, thereby creating a symmetric gradient\nbehavior. To empirically gauge the improved learning capabilities of our\nproposed Polar-FFA, we perform several systematic experiments using different\nactivation and goodness functions over image classification datasets. Our\nresults demonstrate that Polar-FFA outperforms FFA in terms of accuracy and\nconvergence speed. Furthermore, its lower reliance on hyperparameters reduces\nthe need for hyperparameter tuning to guarantee optimal generalization\ncapabilities, thereby allowing for a broader range of neural network\nconfigurations.",
      "tldr_zh": "本研究针对 Forward-Only Learning 算法中的梯度不平衡问题，提出了一种改进方法 Polar-FFA，以提升模型的泛化能力和训练稳定性。Polar-FFA 在原有 Forward-Forward Algorithm (FFA) 的基础上，引入 neural polarization，将神经元分为正负样本组，使每个组针对各自数据类型最大化 layer-wise goodness score，从而实现梯度行为的对称性。通过在图像分类数据集上的系统实验，Polar-FFA 展示了比 FFA 更高的准确率和更快收敛速度，同时减少了对超参数的依赖，拓宽了神经网络配置的适用范围。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in European Conference on Artificial Intelligence (ECAI),\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2408.09210v2",
      "published_date": "2024-08-17 14:32:18 UTC",
      "updated_date": "2024-09-11 16:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:08:39.479049"
    },
    {
      "arxiv_id": "2408.09205v2",
      "title": "Architectural Foundations for the Large Language Model Infrastructures",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyin Zhu"
      ],
      "abstract": "The development of a large language model (LLM) infrastructure is a pivotal\nundertaking in artificial intelligence. This paper explores the intricate\nlandscape of LLM infrastructure, software, and data management. By analyzing\nthese core components, we emphasize the pivotal considerations and safeguards\ncrucial for successful LLM development. This work presents a concise synthesis\nof the challenges and strategies inherent in constructing a robust and\neffective LLM infrastructure, offering valuable insights for researchers and\npractitioners alike.",
      "tldr_zh": "本论文探讨了大型语言模型(LLM)基础设施的架构基础，包括基础设施、软件和数据管理，通过分析这些核心组件来强调成功开发LLM的关键考虑和保障措施。该研究总结了构建稳健有效LLM基础设施所面临的挑战与策略，提供宝贵的见解以指导研究者和从业者。整体上，这为LLM开发提供了简明综合的框架，推动人工智能领域的实践进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09205v2",
      "published_date": "2024-08-17 13:54:34 UTC",
      "updated_date": "2024-08-21 11:34:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:08:51.447915"
    },
    {
      "arxiv_id": "2408.09196v1",
      "title": "Maintainability Challenges in ML: A Systematic Literature Review",
      "title_zh": "机器学习中的可维护性挑战：一项系统文献综述",
      "authors": [
        "Karthik Shivashankar",
        "Antonio Martini"
      ],
      "abstract": "Background: As Machine Learning (ML) advances rapidly in many fields, it is\nbeing adopted by academics and businesses alike. However, ML has a number of\ndifferent challenges in terms of maintenance not found in traditional software\nprojects. Identifying what causes these maintainability challenges can help\nmitigate them early and continue delivering value in the long run without\ndegrading ML performance. Aim: This study aims to identify and synthesise the\nmaintainability challenges in different stages of the ML workflow and\nunderstand how these stages are interdependent and impact each other's\nmaintainability. Method: Using a systematic literature review, we screened more\nthan 13000 papers, then selected and qualitatively analysed 56 of them.\nResults: (i) a catalogue of maintainability challenges in different stages of\nData Engineering, Model Engineering workflows and the current challenges when\nbuilding ML systems are discussed; (ii) a map of 13 maintainability challenges\nto different interdependent stages of ML that impact the overall workflow;\n(iii) Provided insights to developers of ML tools and researchers. Conclusions:\nIn this study, practitioners and organisations will learn about maintainability\nchallenges and their impact at different stages of ML workflow. This will\nenable them to avoid pitfalls and help to build a maintainable ML system. The\nimplications and challenges will also serve as a basis for future research to\nstrengthen our understanding of the ML system's maintainability.",
      "tldr_zh": "这篇系统文献综述探讨了Machine Learning (ML) 系统中的可维护性挑战，这些挑战在数据工程、模型工程工作流的不同阶段出现，并影响整体工作流相互依赖性。研究者通过筛选超过13000篇论文并定性分析56篇，识别并目录化了13个关键维护挑战，并映射了这些挑战如何在ML阶段间传播。结果为ML工具开发者提供了实用见解，帮助从业者和组织避免常见陷阱，从而构建更可维护的ML系统，并为未来研究提供基础。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09196v1",
      "published_date": "2024-08-17 13:24:15 UTC",
      "updated_date": "2024-08-17 13:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:09:03.439078"
    },
    {
      "arxiv_id": "2409.00031v1",
      "title": "Quality Assessment in the Era of Large Models: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Zicheng Zhang",
        "Yingjie Zhou",
        "Chunyi Li",
        "Baixuan Zhao",
        "Xiaohong Liu",
        "Guangtao Zhai"
      ],
      "abstract": "Quality assessment, which evaluates the visual quality level of multimedia\nexperiences, has garnered significant attention from researchers and has\nevolved substantially through dedicated efforts. Before the advent of large\nmodels, quality assessment typically relied on small expert models tailored for\nspecific tasks. While these smaller models are effective at handling their\ndesignated tasks and predicting quality levels, they often lack explainability\nand robustness. With the advancement of large models, which align more closely\nwith human cognitive and perceptual processes, many researchers are now\nleveraging the prior knowledge embedded in these large models for quality\nassessment tasks. This emergence of quality assessment within the context of\nlarge models motivates us to provide a comprehensive review focusing on two key\naspects: 1) the assessment of large models, and 2) the role of large models in\nassessment tasks. We begin by reflecting on the historical development of\nquality assessment. Subsequently, we move to detailed discussions of related\nworks concerning quality assessment in the era of large models. Finally, we\noffer insights into the future progression and potential pathways for quality\nassessment in this new era. We hope this survey will enable a rapid\nunderstanding of the development of quality assessment in the era of large\nmodels and inspire further advancements in the field.",
      "tldr_zh": "本调查回顾了质量 assessment 的历史演变，从传统依赖小专家模型（small expert models）的特定任务方法，转向利用大型模型（large models）的先验知识，以提升explainability和robustness。论文重点讨论两个方面：1) 对large models的评估，2) large models在质量 assessment 任务中的应用，通过分析相关研究展示其与人类认知和感知过程的紧密结合。最终，论文展望了这一领域的未来路径，并旨在加速理解和推动创新。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00031v1",
      "published_date": "2024-08-17 13:20:55 UTC",
      "updated_date": "2024-08-17 13:20:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:09:14.695232"
    },
    {
      "arxiv_id": "2409.00030v1",
      "title": "TimeSense: Multi-Person Device-free Indoor Localization via RTT",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Mohsen",
        "Hamada Rizk",
        "Hirozumi Yamaguch",
        "Moustafa Youssef"
      ],
      "abstract": "Locating the persons moving through an environment without the necessity of\nthem being equipped with special devices has become vital for many applications\nincluding security, IoT, healthcare, etc. Existing device-free indoor\nlocalization systems commonly rely on the utilization of Received Signal\nStrength Indicator (RSSI) and WiFi Channel State Information (CSI) techniques.\nHowever, the accuracy of RSSI is adversely affected by environmental factors\nlike multi-path interference and fading. Additionally, the lack of\nstandardization in CSI necessitates the use of specialized hardware and\nsoftware. In this paper, we present TimeSense, a deep learning-based\nmulti-person device-free indoor localization system that addresses these\nchallenges. TimeSense leverages Time of Flight information acquired by the\nfine-time measurement protocol of IEEE 802.11-2016 standard. Specifically, the\nmeasured round trip time between the transmitter and receiver is influenced by\nthe dynamic changes in the environment induced by human presence. TimeSense\neffectively detects this anomalous behavior using a stacked denoising\nauto-encoder model, thereby estimating the user's location. The system\nincorporates a probabilistic approach on top of the deep learning model to\nensure seamless tracking of the users. The evaluation of TimeSene in two\nrealistic environments demonstrates its efficacy, achieving a median\nlocalization accuracy of 1.57 and 2.65 meters. This surpasses the performance\nof state-of-the-art techniques by 49% and 103% in the two testbeds.",
      "tldr_zh": "本研究提出TimeSense，一种基于深度学习的多人无设备室内定位系统，利用IEEE 802.11-2016标准的Fine-Time Measurement Protocol获取Round Trip Time (RTT)信息，以克服传统RSSI和CSI技术的环境干扰和硬件依赖问题。TimeSense通过堆叠去噪自编码器(stacked denoising auto-encoder)模型检测人类存在引起的RTT异常变化，并结合概率方法实现用户位置的精确估计和无缝跟踪。在两个真实环境中，该系统实现了1.57和2.65米的定位准确率中位数，分别比现有技术提高了49%和103%。这为安全、IoT和医疗等应用提供了更可靠的定位解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00030v1",
      "published_date": "2024-08-17 13:12:33 UTC",
      "updated_date": "2024-08-17 13:12:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:09:27.063853"
    },
    {
      "arxiv_id": "2408.09193v1",
      "title": "AI Managed Emergency Documentation with a Pretrained Model",
      "title_zh": "翻译失败",
      "authors": [
        "David Menzies",
        "Sean Kirwan",
        "Ahmad Albarqawi"
      ],
      "abstract": "This study investigates the use of a large language model system to improve\nefficiency and quality in emergency department (ED) discharge letter writing.\nTime constraints and infrastructural deficits make compliance with current\ndischarge letter targets difficult. We explored potential efficiencies from an\nartificial intelligence software in the generation of ED discharge letters and\nthe attitudes of doctors toward this technology. The evaluated system leverages\nadvanced techniques to fine-tune a model to generate discharge summaries from\nshort-hand inputs, including voice, text, and electronic health record data.\nNineteen physicians with emergency medicine experience evaluated the system\ntext and voice-to-text interfaces against manual typing. The results showed\nsignificant time savings with MedWrite LLM interfaces compared to manual\nmethods.",
      "tldr_zh": "这篇论文探讨使用大型语言模型(LLM)系统来提升急诊室(ED)出院信的效率和质量，针对时间限制和基础设施不足等问题。研究方法包括微调预训练模型，从语音、文本和电子健康记录(EHR)数据生成出院总结，并评估医生的态度。实验中，19名有急诊经验的医生比较了MedWrite LLM的文本和语音接口与手动输入，结果显示前者显著节省时间。该技术为AI在医疗文档管理中的应用提供了潜在改进路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Ethical approval for the study was obtained from the University\n  College Dublin, Human Research Ethics Committee (UCD HREC)",
      "pdf_url": "http://arxiv.org/pdf/2408.09193v1",
      "published_date": "2024-08-17 13:11:46 UTC",
      "updated_date": "2024-08-17 13:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:09:40.555013"
    },
    {
      "arxiv_id": "2408.09189v1",
      "title": "SA-GDA: Spectral Augmentation for Graph Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhui Pang",
        "Zixuan Wang",
        "Jiliang Tang",
        "Mingyan Xiao",
        "Nan Yin"
      ],
      "abstract": "Graph neural networks (GNNs) have achieved impressive impressions for\ngraph-related tasks. However, most GNNs are primarily studied under the cases\nof signal domain with supervised training, which requires abundant\ntask-specific labels and is difficult to transfer to other domains. There are\nfew works focused on domain adaptation for graph node classification. They\nmainly focused on aligning the feature space of the source and target domains,\nwithout considering the feature alignment between different categories, which\nmay lead to confusion of classification in the target domain. However, due to\nthe scarcity of labels of the target domain, we cannot directly perform\neffective alignment of categories from different domains, which makes the\nproblem more challenging. In this paper, we present the \\textit{Spectral\nAugmentation for Graph Domain Adaptation (\\method{})} for graph node\nclassification. First, we observe that nodes with the same category in\ndifferent domains exhibit similar characteristics in the spectral domain, while\ndifferent classes are quite different. Following the observation, we align the\ncategory feature space of different domains in the spectral domain instead of\naligning the whole features space, and we theoretical proof the stability of\nproposed \\method{}. Then, we develop a dual graph convolutional network to\njointly exploits local and global consistency for feature aggregation. Last, we\nutilize a domain classifier with an adversarial learning submodule to\nfacilitate knowledge transfer between different domain graphs. Experimental\nresults on a variety of publicly available datasets reveal the effectiveness of\nour \\method{}.",
      "tldr_zh": "该论文针对图神经网络（GNNs）在图节点分类任务中面临的多域适应挑战，提出了一种名为 SA-GDA 的方法，以解决现有方法仅对齐整体特征空间而忽略类别间对齐的问题，导致目标域分类混乱。SA-GDA 通过在频谱域（spectral domain）对不同域的类别特征空间进行对齐，并理论证明了其稳定性，同时利用双图卷积网络（dual graph convolutional network）整合局部和全局特征聚合，以及域分类器结合对抗学习（adversarial learning）促进知识转移。实验结果在多种公开数据集上验证了 SA-GDA 的有效性，提升了跨域图节点分类的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09189v1",
      "published_date": "2024-08-17 13:01:45 UTC",
      "updated_date": "2024-08-17 13:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:09:52.222742"
    },
    {
      "arxiv_id": "2408.09186v1",
      "title": "EEG-SCMM: Soft Contrastive Masked Modeling for Cross-Corpus EEG-Based Emotion Recognition",
      "title_zh": "EEG-SCM",
      "authors": [
        "Qile Liu",
        "Weishan Ye",
        "Yulu Liu",
        "Zhen Liang"
      ],
      "abstract": "Emotion recognition using electroencephalography (EEG) signals has garnered\nwidespread attention in recent years. However, existing studies have struggled\nto develop a sufficiently generalized model suitable for different datasets\nwithout re-training (cross-corpus). This difficulty arises because distribution\ndifferences across datasets far exceed the intra-dataset variability. To solve\nthis problem, we propose a novel Soft Contrastive Masked Modeling (SCMM)\nframework. Inspired by emotional continuity, SCMM integrates soft contrastive\nlearning with a new hybrid masking strategy to effectively mine the \"short-term\ncontinuity\" characteristics inherent in human emotions. During the\nself-supervised learning process, soft weights are assigned to sample pairs,\nenabling adaptive learning of similarity relationships across samples.\nFurthermore, we introduce an aggregator that weightedly aggregates\ncomplementary information from multiple close samples based on pairwise\nsimilarities among samples to enhance fine-grained feature representation,\nwhich is then used for original sample reconstruction. Extensive experiments on\nthe SEED, SEED-IV and DEAP datasets show that SCMM achieves state-of-the-art\n(SOTA) performance, outperforming the second-best method by an average accuracy\nof 4.26% under two types of cross-corpus conditions (same-class and\ndifferent-class) for EEG-based emotion recognition.",
      "tldr_zh": "该论文提出EEG-SCMM框架，即Soft Contrastive Masked Modeling，用于解决跨数据集（cross-corpus）EEG情感识别的泛化难题，该问题源于数据集间分布差异大于内部变异。框架结合软对比学习（soft contrastive learning）和混合掩码策略，基于情感连续性挖掘人类情绪的“短期连续性”特征，通过为样本对分配软权重实现自适应相似性学习，并引入聚合器加权聚合多个近似样本的互补信息以增强细粒度特征表示和原始样本重建。在SEED、SEED-IV和DEAP数据集上的实验显示，EEG-SCMM在两种cross-corpus条件下（same-class和different-class）实现了SOTA性能，比第二好方法平均准确率提高4.26%。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "16 pages, 8 figures, 15 tables, submitted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.09186v1",
      "published_date": "2024-08-17 12:35:13 UTC",
      "updated_date": "2024-08-17 12:35:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:10:15.389076"
    },
    {
      "arxiv_id": "2408.09177v1",
      "title": "Chinese Metaphor Recognition Using a Multi-stage Prompting Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Wang",
        "Jin Wang",
        "Xuejie Zhang"
      ],
      "abstract": "Metaphors are common in everyday language, and the identification and\nunderstanding of metaphors are facilitated by models to achieve a better\nunderstanding of the text. Metaphors are mainly identified and generated by\npre-trained models in existing research, but situations, where tenors or\nvehicles are not included in the metaphor, cannot be handled. The problem can\nbe effectively solved by using Large Language Models (LLMs), but significant\nroom for exploration remains in this early-stage research area. A multi-stage\ngenerative heuristic-enhanced prompt framework is proposed in this study to\nenhance the ability of LLMs to recognize tenors, vehicles, and grounds in\nChinese metaphors. In the first stage, a small model is trained to obtain the\nrequired confidence score for answer candidate generation. In the second stage,\nquestions are clustered and sampled according to specific rules. Finally, the\nheuristic-enhanced prompt needed is formed by combining the generated answer\ncandidates and demonstrations. The proposed model achieved 3rd place in Track 1\nof Subtask 1, 1st place in Track 2 of Subtask 1, and 1st place in both tracks\nof Subtask 2 at the NLPCC-2024 Shared Task 9.",
      "tldr_zh": "本论文提出了一种多阶段生成启发式增强提示框架，用于提升 Large Language Models (LLMs) 在中文隐喻识别中的能力，特别针对 tenors、vehicles 和 grounds 的识别问题，以解决现有预训练模型无法处理隐喻缺失部分的情况。框架包括三个阶段：首先训练一个小模型获取答案候选的置信度分数；其次根据特定规则对问题进行聚类和采样；最后结合生成的答案候选和演示形成启发式增强提示。该方法在 NLPCC-2024 Shared Task 9 中取得了 Subtask 1 Track 1 的第三名、Subtask 1 Track 2 和 Subtask 2 两轨道的第一名，展示了其在隐喻识别任务上的优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09177v1",
      "published_date": "2024-08-17 11:56:38 UTC",
      "updated_date": "2024-08-17 11:56:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:10:27.136271"
    },
    {
      "arxiv_id": "2408.09176v1",
      "title": "Cognitive LLMs: Towards Integrating Cognitive Architectures and Large Language Models for Manufacturing Decision-making",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Wu",
        "Alessandro Oltramari",
        "Jonathan Francis",
        "C. Lee Giles",
        "Frank E. Ritter"
      ],
      "abstract": "Resolving the dichotomy between the human-like yet constrained reasoning\nprocesses of Cognitive Architectures and the broad but often noisy inference\nbehavior of Large Language Models (LLMs) remains a challenging but exciting\npursuit, for enabling reliable machine reasoning capabilities in production\nsystems. Because Cognitive Architectures are famously developed for the purpose\nof modeling the internal mechanisms of human cognitive decision-making at a\ncomputational level, new investigations consider the goal of informing LLMs\nwith the knowledge necessary for replicating such processes, e.g., guided\nperception, memory, goal-setting, and action. Previous approaches that use LLMs\nfor grounded decision-making struggle with complex reasoning tasks that require\nslower, deliberate cognition over fast and intuitive inference -- reporting\nissues related to the lack of sufficient grounding, as in hallucination. To\nresolve these challenges, we introduce LLM-ACTR, a novel neuro-symbolic\narchitecture that provides human-aligned and versatile decision-making by\nintegrating the ACT-R Cognitive Architecture with LLMs. Our framework extracts\nand embeds knowledge of ACT-R's internal decision-making process as latent\nneural representations, injects this information into trainable LLM adapter\nlayers, and fine-tunes the LLMs for downstream prediction. Our experiments on\nnovel Design for Manufacturing tasks show both improved task performance as\nwell as improved grounded decision-making capability of our approach, compared\nto LLM-only baselines that leverage chain-of-thought reasoning strategies.",
      "tldr_zh": "该论文探讨了整合Cognitive Architectures和Large Language Models (LLMs)，以解决制造决策中LLMs推理噪声大和认知受限的问题，目标是实现更可靠的人类对齐决策。作者提出LLM-ACTR框架，将ACT-R认知架构的内部决策知识提取为神经表示，注入LLMs的适配器层并进行微调，从而增强引导感知、记忆和行动等过程。实验结果显示，在Design for Manufacturing任务上，该框架比仅使用LLMs的基线模型取得了更好的任务性能和决策可靠性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 8 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.09176v1",
      "published_date": "2024-08-17 11:49:53 UTC",
      "updated_date": "2024-08-17 11:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:10:28.178682"
    },
    {
      "arxiv_id": "2408.09172v4",
      "title": "Unlocking the Power of LLM Uncertainty for Active In-Context Example Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Hsiu-Yuan Huang",
        "Zichen Wu",
        "Yutong Yang",
        "Junzhao Zhang",
        "Yunfang Wu"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable performance across a wide\nrange of downstream tasks. However, it is challenging for users to discern\nwhether the responses of LLM are generated with certainty or are fabricated to\nmeet user expectations. In this paper, we introduce Uncertainty Tripartite\nTesting Paradigm (Unc-TTP), a novel method for classifying LLM uncertainty by\nleveraging output inconsistency. Specifically, Unc-TTP performs three rounds of\nsampling under varying label injection interference, enumerating all possible\noutcomes, and uses the degree of output inconsistency as the indicator of the\nLLM's intrinsic uncertainty. To validate the effectiveness of this\ninconsistency-defined uncertainty, we draw inspiration from Active Learning,\ncomparing the informativeness of actively selected in-context examples. Our\nexperiments show that uncertainty examples selected via Unc-TTP are more\ninformative than certainty examples. Furthermore, the Unc-TTP-guided\nuncertainty-based active example selection strategy outperforms existing\nmethods, highlighting its effectiveness in classifying LLM uncertainty and\nenhancing in-context learning. This work not only underscores the potential of\ninconsistency-based uncertainty classification for both open- and closed-source\nLLMs but also presents a practical approach for leveraging uncertainty to\nimprove LLM performance in real-world tasks.",
      "tldr_zh": "本论文提出Uncertainty Tripartite Testing Paradigm (Unc-TTP)，一种通过输出不一致性来分类大型语言模型(LLMs)不确定性的新方法。具体而言，Unc-TTP通过三轮采样和标签注入干扰枚举所有可能结果，并使用不一致度作为不确定性指标，以指导Active Learning中的in-context examples选择。实验显示，Unc-TTP选择的uncertainty examples比certainty examples更具信息性，且这种策略优于现有方法，能提升LLMs在真实任务中的性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09172v4",
      "published_date": "2024-08-17 11:33:23 UTC",
      "updated_date": "2025-01-12 16:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:10:40.484768"
    },
    {
      "arxiv_id": "2408.09168v1",
      "title": "Ranking Across Different Content Types: The Robust Beauty of Multinomial Blending",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Malte Lichtenberg",
        "Giuseppe Di Benedetto",
        "Matteo Ruffini"
      ],
      "abstract": "An increasing number of media streaming services have expanded their\nofferings to include entities of multiple content types. For instance, audio\nstreaming services that started by offering music only, now also offer\npodcasts, merchandise items, and videos. Ranking items across different content\ntypes into a single slate poses a significant challenge for traditional\nlearning-to-rank (LTR) algorithms due to differing user engagement patterns for\ndifferent content types. We explore a simple method for cross-content-type\nranking, called multinomial blending (MB), which can be used in conjunction\nwith most existing LTR algorithms. We compare MB to existing baselines not only\nin terms of ranking quality but also from other industry-relevant perspectives\nsuch as interpretability, ease-of-use, and stability in dynamic environments\nwith changing user behavior and ranking model retraining. Finally, we report\nthe results of an A/B test from an Amazon Music ranking use-case.",
      "tldr_zh": "该研究探讨了媒体流媒体服务（如音频平台）扩展到多种内容类型（例如音乐、播客和视频）时，传统学习到排名 (LTR) 算法面临的挑战，这些挑战源于不同内容类型的用户互动模式差异。为解决此问题，作者提出了一种简单方法——multinomial blending (MB)，可与现有 LTR 算法结合，用于跨内容类型排名。实验结果显示，MB 不仅在排名质量上优于基线，还在解释性、易用性和动态环境稳定性方面表现出色；最终，通过 Amazon Music 的 A/B 测试，验证了 MB 的实际有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "To appear in 18th ACM Conference on Recommender Systems (RecSys24),\n  Bari, Italy. ACM, New York, NY, USA, 3 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.09168v1",
      "published_date": "2024-08-17 11:11:31 UTC",
      "updated_date": "2024-08-17 11:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:11:02.607651"
    },
    {
      "arxiv_id": "2408.09158v2",
      "title": "Linear Attention is Enough in Spatial-Temporal Forecasting",
      "title_zh": "线性注意力在时空预测中就足够了",
      "authors": [
        "Xinyu Ning"
      ],
      "abstract": "As the most representative scenario of spatial-temporal forecasting tasks,\nthe traffic forecasting task attracted numerous attention from machine learning\ncommunity due to its intricate correlation both in space and time dimension.\nExisting methods often treat road networks over time as spatial-temporal\ngraphs, addressing spatial and temporal representations independently. However,\nthese approaches struggle to capture the dynamic topology of road networks,\nencounter issues with message passing mechanisms and over-smoothing, and face\nchallenges in learning spatial and temporal relationships separately. To\naddress these limitations, we propose treating nodes in road networks at\ndifferent time steps as independent spatial-temporal tokens and feeding them\ninto a vanilla Transformer to learn complex spatial-temporal patterns, design\n\\textbf{STformer} achieving SOTA. Given its quadratic complexity, we introduce\na variant \\textbf{NSTformer} based on Nystr$\\ddot{o}$m method to approximate\nself-attention with linear complexity but even slightly better than former in a\nfew cases astonishingly. Extensive experimental results on traffic datasets\ndemonstrate that the proposed method achieves state-of-the-art performance at\nan affordable computational cost. Our code is available at\n\\href{https://github.com/XinyuNing/STformer-and-NSTformer}{https://github.com/XinyuNing/STformer-and-NSTformer}.",
      "tldr_zh": "本论文指出，现有的空间-时间预测方法（如交通预测）在处理道路网络的动态拓扑、消息传递机制和过度平滑问题时存在局限性，因此提出将道路网络节点在不同时间步视为独立的 Spatial-Temporal 标记，并使用 vanilla Transformer 构建 STformer 模型，以学习复杂的空间-时间模式并达到 SOTA 性能。针对 Transformer 的二次复杂度问题，论文引入基于 Nyström 方法的 NSTformer 变体，实现线性复杂度注意力机制，并在某些情况下表现略优于 STformer。实验结果显示，该方法在多个交通数据集上取得了最先进性能，同时保持了可负担的计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09158v2",
      "published_date": "2024-08-17 10:06:50 UTC",
      "updated_date": "2024-09-13 14:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:11:05.475567"
    },
    {
      "arxiv_id": "2408.09150v3",
      "title": "CogLM: Tracking Cognitive Development of Large Language Models",
      "title_zh": "CogLM：追踪大型语言模型的认知发展",
      "authors": [
        "Xinglin Wang",
        "Peiwen Yuan",
        "Shaoxiong Feng",
        "Yiwei Li",
        "Boyuan Pan",
        "Heda Wang",
        "Yao Hu",
        "Kan Li"
      ],
      "abstract": "Piaget's Theory of Cognitive Development (PTC) posits that the development of\ncognitive levels forms the foundation for human learning across various\nabilities. As Large Language Models (LLMs) have recently shown remarkable\nabilities across a wide variety of tasks, we are curious about the cognitive\nlevels of current LLMs: to what extent they have developed and how this\ndevelopment has been achieved. To this end, we construct a benchmark CogLM\n(Cognitive Ability Evaluation for Language Model) based on PTC to assess the\ncognitive levels of LLMs. CogLM comprises 1,220 questions spanning 10 cognitive\nabilities crafted by more than 20 human experts, providing a comprehensive\ntestbed for the cognitive levels of LLMs. Through extensive experiments across\nmultiple mainstream LLMs with CogLM, we find that: (1) In our testing\nframework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive\nabilities, comparable to those of a 20-year-old human. (2) The parameter size\nand optimization objective are two key factors affecting the cognitive levels\nof LLMs. (3) The performance on downstream tasks is positively correlated with\nthe level of cognitive abilities. These findings fill the gap in research on\nthe cognitive abilities of LLMs, tracing the development of LLMs from a\ncognitive perspective and guiding the future direction of their evolution.",
      "tldr_zh": "该研究基于 Piaget's Theory of Cognitive Development (PTC) 构建了 CogLM 基准，用于评估大型语言模型 (LLMs) 的认知水平，该基准包括 1220 个问题，覆盖 10 个认知能力，由 20 多位专家设计。\n实验结果显示，高级 LLMs 如 GPT-4 已达到类似于 20 岁人类的认知水平，且参数大小和优化目标是影响其认知发展的关键因素。\n此外，LLMs 在下游任务上的表现与认知能力水平正相关，这些发现填补了 LLMs 认知研究空白，并为未来模型进化提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2408.09150v3",
      "published_date": "2024-08-17 09:49:40 UTC",
      "updated_date": "2025-02-12 03:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:11:26.960769"
    },
    {
      "arxiv_id": "2408.09140v1",
      "title": "Learning to Explore for Stochastic Gradient MCMC",
      "title_zh": "翻译失败",
      "authors": [
        "SeungHyun Kim",
        "Seohyeon Jung",
        "Seonghyeon Kim",
        "Juho Lee"
      ],
      "abstract": "Bayesian Neural Networks(BNNs) with high-dimensional parameters pose a\nchallenge for posterior inference due to the multi-modality of the posterior\ndistributions. Stochastic Gradient MCMC(SGMCMC) with cyclical learning rate\nscheduling is a promising solution, but it requires a large number of sampling\nsteps to explore high-dimensional multi-modal posteriors, making it\ncomputationally expensive. In this paper, we propose a meta-learning strategy\nto build \\gls{sgmcmc} which can efficiently explore the multi-modal target\ndistributions. Our algorithm allows the learned SGMCMC to quickly explore the\nhigh-density region of the posterior landscape. Also, we show that this\nexploration property is transferrable to various tasks, even for the ones\nunseen during a meta-training stage. Using popular image classification\nbenchmarks and a variety of downstream tasks, we demonstrate that our method\nsignificantly improves the sampling efficiency, achieving better performance\nthan vanilla \\gls{sgmcmc} without incurring significant computational overhead.",
      "tldr_zh": "该论文针对Bayesian Neural Networks (BNNs)的高维参数和多模态后验分布带来的推断挑战，提出了一种meta-learning策略来优化Stochastic Gradient MCMC (SGMCMC)。这种策略使SGMCMC能够更高效地探索后验分布的高密度区域，并展示出可转移性，即使应用于meta-training阶段未见任务。实验结果显示，该方法在图像分类基准和各种下游任务上显著提高了采样效率，优于传统SGMCMC，且未增加显著计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09140v1",
      "published_date": "2024-08-17 08:36:42 UTC",
      "updated_date": "2024-08-17 08:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:11:27.104728"
    },
    {
      "arxiv_id": "2408.09135v3",
      "title": "Vanilla Gradient Descent for Oblique Decision Trees",
      "title_zh": "翻译失败",
      "authors": [
        "Subrat Prasad Panda",
        "Blaise Genest",
        "Arvind Easwaran",
        "Ponnuthurai Nagaratnam Suganthan"
      ],
      "abstract": "Decision Trees (DTs) constitute one of the major highly non-linear AI models,\nvalued, e.g., for their efficiency on tabular data. Learning accurate DTs is,\nhowever, complicated, especially for oblique DTs, and does take a significant\ntraining time. Further, DTs suffer from overfitting, e.g., they proverbially\n\"do not generalize\" in regression tasks. Recently, some works proposed ways to\nmake (oblique) DTs differentiable. This enables highly efficient\ngradient-descent algorithms to be used to learn DTs. It also enables\ngeneralizing capabilities by learning regressors at the leaves simultaneously\nwith the decisions in the tree. Prior approaches to making DTs differentiable\nrely either on probabilistic approximations at the tree's internal nodes (soft\nDTs) or on approximations in gradient computation at the internal node\n(quantized gradient descent). In this work, we propose DTSemNet, a novel\nsemantically equivalent and invertible encoding for (hard, oblique) DTs as\nNeural Networks (NNs), that uses standard vanilla gradient descent. Experiments\nacross various classification and regression benchmarks show that oblique DTs\nlearned using DTSemNet are more accurate than oblique DTs of similar size\nlearned using state-of-the-art techniques. Further, DT training time is\nsignificantly reduced. We also experimentally demonstrate that DTSemNet can\nlearn DT policies as efficiently as NN policies in the Reinforcement Learning\n(RL) setup with physical inputs (dimensions $\\leq32$). The code is available at\nhttps://github.com/CPS-research-group/dtsemnet.",
      "tldr_zh": "本文提出了一种名为 DTSemNet 的新方法，将硬决策树 (hard, oblique DTs) 语义等价且可逆地编码为神经网络 (NNs)，从而使用标准的 vanilla gradient descent 进行训练，以解决决策树 (DTs) 在训练复杂性、过拟合和效率问题上的挑战。相比现有依赖概率近似 (soft DTs) 或梯度计算近似的技术，DTSemNet 能够在各种分类和回归基准上使 oblique DTs 的准确率更高，同时显著减少训练时间。实验还表明，该方法在强化学习 (RL) 场景中能像 NN 策略一样高效地学习 DT 策略，为高效的 DT 训练提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in European Conference on Artificial Intelligence (ECAI),\n  2024. Full version (includes supplementary material)",
      "pdf_url": "http://arxiv.org/pdf/2408.09135v3",
      "published_date": "2024-08-17 08:18:40 UTC",
      "updated_date": "2024-10-15 12:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:11:41.232833"
    },
    {
      "arxiv_id": "2408.09134v1",
      "title": "Better Python Programming for all: With the focus on Maintainability",
      "title_zh": "翻译失败",
      "authors": [
        "Karthik Shivashankar",
        "Antonio Martini"
      ],
      "abstract": "This study aims to enhance the maintainability of code generated by Large\nLanguage Models (LLMs), with a focus on the Python programming language. As the\nuse of LLMs for coding assistance grows, so do concerns about the\nmaintainability of the code they produce. Previous research has mainly\nconcentrated on the functional accuracy and testing success of generated code,\noverlooking aspects of maintainability.\n  Our approach involves the use of a specifically designed dataset for training\nand evaluating the model, ensuring a thorough assessment of code\nmaintainability. At the heart of our work is the fine-tuning of an LLM for code\nrefactoring, aimed at enhancing code readability, reducing complexity, and\nimproving overall maintainability.\n  After fine-tuning an LLM to prioritize code maintainability, our evaluations\nindicate that this model significantly improves code maintainability standards,\nsuggesting a promising direction for the future of AI-assisted software\ndevelopment.",
      "tldr_zh": "这篇论文旨在提升 Large Language Models (LLMs) 生成的 Python 代码可维护性，填补了以往研究主要关注功能准确性和测试成功，而忽略可维护性方面的空白。研究团队使用一个专门设计的数据集来训练和评估模型，并对 LLM 进行微调，以实现代码重构、提高代码可读性、减少复杂性。结果表明，该微调模型显著改善了代码可维护性标准，为 AI 辅助软件开发提供了有前景的方向。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09134v1",
      "published_date": "2024-08-17 08:14:22 UTC",
      "updated_date": "2024-08-17 08:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:11:51.944506"
    },
    {
      "arxiv_id": "2408.09128v1",
      "title": "Identifying Technical Debt and Its Types Across Diverse Software Projects Issues",
      "title_zh": "在多样化软件项目问题中识别技术债务及其类型",
      "authors": [
        "Karthik Shivashankar",
        "Mili Orucevic",
        "Maren Maritsdatter Kruke",
        "Antonio Martini"
      ],
      "abstract": "Technical Debt (TD) identification in software projects issues is crucial for\nmaintaining code quality, reducing long-term maintenance costs, and improving\noverall project health. This study advances TD classification using\ntransformer-based models, addressing the critical need for accurate and\nefficient TD identification in large-scale software development.\n  Our methodology employs multiple binary classifiers for TD and its type,\ncombined through ensemble learning, to enhance accuracy and robustness in\ndetecting various forms of TD. We train and evaluate these models on a\ncomprehensive dataset from GitHub Archive Issues (2015-2024), supplemented with\nindustrial data validation.\n  We demonstrate that in-project fine-tuned transformer models significantly\noutperform task-specific fine-tuned models in TD classification, highlighting\nthe importance of project-specific context in accurate TD identification. Our\nresearch also reveals the superiority of specialized binary classifiers over\nmulti-class models for TD and its type identification, enabling more targeted\ndebt resolution strategies. A comparative analysis shows that the smaller\nDistilRoBERTa model is more effective than larger language models like GPTs for\nTD classification tasks, especially after fine-tuning, offering insights into\nefficient model selection for specific TD detection tasks.\n  The study also assesses generalization capabilities using metrics such as\nMCC, AUC ROC, Recall, and F1 score, focusing on model effectiveness,\nfine-tuning impact, and relative performance. By validating our approach on\nout-of-distribution and real-world industrial datasets, we ensure practical\napplicability, addressing the diverse nature of software projects.",
      "tldr_zh": "这篇论文研究了在多样化软件项目中识别 Technical Debt (TD) 及其类型，使用 transformer-based models 和集成学习方法，以提高代码质量和项目健康。研究方法采用多个二元分类器结合 ensemble learning，在 GitHub Archive Issues (2015-2024) 数据集上训练，并通过工业数据验证。关键发现包括：项目内微调的模型比任务特定微调模型更准确，DistilRoBERTa 模型在 TD 分类中优于大型模型如 GPTs，且二元分类器比多类模型更适合针对性债务解决；使用 MCC、AUC ROC、Recall 和 F1 score 等指标评估后，证明了方法的泛化能力和实际适用性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09128v1",
      "published_date": "2024-08-17 07:46:54 UTC",
      "updated_date": "2024-08-17 07:46:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:12:05.350926"
    },
    {
      "arxiv_id": "2408.09125v1",
      "title": "Markov Balance Satisfaction Improves Performance in Strictly Batch Offline Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rishabh Agrawal",
        "Nathan Dahlin",
        "Rahul Jain",
        "Ashutosh Nayyar"
      ],
      "abstract": "Imitation learning (IL) is notably effective for robotic tasks where directly\nprogramming behaviors or defining optimal control costs is challenging. In this\nwork, we address a scenario where the imitator relies solely on observed\nbehavior and cannot make environmental interactions during learning. It does\nnot have additional supplementary datasets beyond the expert's dataset nor any\ninformation about the transition dynamics. Unlike state-of-the-art (SOTA) IL\nmethods, this approach tackles the limitations of conventional IL by operating\nin a more constrained and realistic setting. Our method uses the Markov balance\nequation and introduces a novel conditional density estimation-based imitation\nlearning framework. It employs conditional normalizing flows for transition\ndynamics estimation and aims at satisfying a balance equation for the\nenvironment. Through a series of numerical experiments on Classic Control and\nMuJoCo environments, we demonstrate consistently superior empirical performance\ncompared to many SOTA IL algorithms.",
      "tldr_zh": "这篇论文针对严格批量离线 Imitation Learning (IL) 场景，提出了一种新方法，通过使用 Markov balance equation 和基于条件密度估计的框架来改进性能。该框架采用 conditional normalizing flows 估计过渡动态，并确保环境平衡方程的满足，从而克服了传统 IL 在无环境交互和额外数据限制下的局限性。在 Classic Control 和 MuJoCo 环境上的数值实验中，该方法比 SOTA IL 算法显示出一致的优越性能，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09125v1",
      "published_date": "2024-08-17 07:17:19 UTC",
      "updated_date": "2024-08-17 07:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:12:19.638042"
    },
    {
      "arxiv_id": "2408.09121v4",
      "title": "Selective Prompt Anchoring for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Tian",
        "Tianyi Zhang"
      ],
      "abstract": "Recent advances in large language models (LLMs) have transformed software\ndevelopment by automatically generating code from natural language. Yet\nchallenges remain in generating fully correct code that aligns with user\nintent. Our study reveals that LLMs tend to pay less attention to user prompts\nas more code tokens are generated. We hypothesize that this attention dilution\nissue is an important reason for code generation errors. To mitigate this\nissue, we propose Selective Prompt Anchoring (SPA) to guide code LLMs to pay\nmore attention to user intent when generating code. We evaluate SPA using six\nbase LLMs across six benchmarks. Our results demonstrate that SPA enhances\nPass@1 by up to 12.9%, consistently outperforming SOTA code generation methods\nin all settings. Our code is available at\nhttps://github.com/magic-YuanTian/Selective-Prompt-Anchoring.",
      "tldr_zh": "该研究发现，大型语言模型 (LLMs) 在代码生成过程中，随着生成更多代码标记，对用户提示的关注逐渐减少，从而导致代码错误和与意图不符的问题。为解决这一问题，研究提出 Selective Prompt Anchoring (SPA) 方法，通过引导 LLMs 更注重用户意图来提升代码生成质量。在六个基准上评估六种基线 LLMs 后，结果显示 SPA 将 Pass@1 指标提高了高达 12.9%，在所有设置中优于现有最先进 (SOTA) 方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09121v4",
      "published_date": "2024-08-17 07:11:02 UTC",
      "updated_date": "2025-02-21 03:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:12:28.030950"
    },
    {
      "arxiv_id": "2408.11067v1",
      "title": "Toward End-to-End Bearing Fault Diagnosis for Industrial Scenarios with Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yongqi Ding",
        "Lin Zuo",
        "Mengmeng Jing",
        "Kunshan Yang",
        "Biao Chen",
        "Yunqian Yu"
      ],
      "abstract": "Spiking neural networks (SNNs) transmit information via low-power binary\nspikes and have received widespread attention in areas such as computer vision\nand reinforcement learning. However, there have been very few explorations of\nSNNs in more practical industrial scenarios. In this paper, we focus on the\napplication of SNNs in bearing fault diagnosis to facilitate the integration of\nhigh-performance AI algorithms and real-world industries. In particular, we\nidentify two key limitations of existing SNN fault diagnosis methods:\ninadequate encoding capacity that necessitates cumbersome data preprocessing,\nand non-spike-oriented architectures that constrain the performance of SNNs. To\nalleviate these problems, we propose a Multi-scale Residual Attention SNN\n(MRA-SNN) to simultaneously improve the efficiency, performance, and robustness\nof SNN methods. By incorporating a lightweight attention mechanism, we have\ndesigned a multi-scale attention encoding module to extract multiscale fault\nfeatures from vibration signals and encode them as spatio-temporal spikes,\neliminating the need for complicated preprocessing. Then, the spike residual\nattention block extracts high-dimensional fault features and enhances the\nexpressiveness of sparse spikes with the attention mechanism for end-to-end\ndiagnosis. In addition, the performance and robustness of MRA-SNN is further\nenhanced by introducing the lightweight attention mechanism within the spiking\nneurons to simulate the biological dendritic filtering effect. Extensive\nexperiments on MFPT and JNU benchmark datasets demonstrate that MRA-SNN\nsignificantly outperforms existing methods in terms of accuracy, energy\nconsumption and noise robustness, and is more feasible for deployment in\nreal-world industrial scenarios.",
      "tldr_zh": "本研究聚焦于使用Spiking Neural Networks (SNNs) 实现工业场景下的端到端轴承故障诊断，针对现有SNN方法中编码能力不足和非尖峰导向架构的问题，提出Multi-scale Residual Attention SNN (MRA-SNN)框架。该框架通过多尺度注意力编码模块从振动信号提取并编码多尺度故障特征，消除复杂数据预处理需求，并利用尖峰残差注意力块和注意力增强尖峰神经元来提取高维特征并提升稀疏尖峰的表达能力，从而实现高效的端到端诊断。在MFPT和JNU基准数据集上的实验表明，MRA-SNN在准确率、能耗和噪声鲁棒性方面显著优于现有方法，更适合实际工业部署。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "13 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11067v1",
      "published_date": "2024-08-17 06:41:58 UTC",
      "updated_date": "2024-08-17 06:41:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:12:43.518855"
    },
    {
      "arxiv_id": "2408.09111v2",
      "title": "Measuring Agreeableness Bias in Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyuk Lim",
        "Bruce W. Lee"
      ],
      "abstract": "This paper examines a phenomenon in multimodal language models where\npre-marked options in question images can significantly influence model\nresponses. Our study employs a systematic methodology to investigate this\neffect: we present models with images of multiple-choice questions, which they\ninitially answer correctly, then expose the same model to versions with\npre-marked options. Our findings reveal a significant shift in the models'\nresponses towards the pre-marked option, even when it contradicts their answers\nin the neutral settings. Comprehensive evaluations demonstrate that this\nagreeableness bias is a consistent and quantifiable behavior across various\nmodel architectures. These results show potential limitations in the\nreliability of these models when processing images with pre-marked options,\nraising important questions about their application in critical decision-making\ncontexts where such visual cues might be present.",
      "tldr_zh": "本文研究了多模态模型中的agreeableness bias，即图像中预标记选项对模型响应产生的显著影响。研究采用系统方法，先让模型回答中性多选题图像，然后比较预标记版本的响应，发现模型倾向于转向预标记选项，即使这与原始答案矛盾。全面评估显示，这种偏差在各种模型架构中一致且可量化，揭示了模型在处理视觉提示时的可靠性局限性，并质疑其在关键决策环境中的应用潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09111v2",
      "published_date": "2024-08-17 06:25:36 UTC",
      "updated_date": "2024-10-15 02:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:12:51.909022"
    },
    {
      "arxiv_id": "2408.09108v3",
      "title": "Temporal Reversal Regularization for Spiking Neural Networks: Hybrid Spatio-Temporal Invariance for Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Zuo",
        "Yongqi Ding",
        "Wenwei Luo",
        "Mengmeng Jing",
        "Kunshan Yang"
      ],
      "abstract": "Spiking neural networks (SNNs) have received widespread attention as an\nultra-low power computing paradigm. Recent studies have shown that SNNs suffer\nfrom severe overfitting, which limits their generalization performance. In this\npaper, we propose a simple yet effective Temporal Reversal Regularization (TRR)\nto mitigate overfitting during training and facilitate generalization of SNNs.\nWe exploit the inherent temporal properties of SNNs to perform input/feature\ntemporal reversal perturbations, prompting the SNN to produce original-reversed\nconsistent outputs and learn perturbation-invariant representations. To further\nenhance generalization, we utilize the lightweight ``star operation\" (Hadamard\nproduct) for feature hybridization of original and temporally reversed spike\nfiring rates, which expands the implicit dimensionality and acts as a\nspatio-temporal regularizer. We show theoretically that our method is able to\ntighten the upper bound of the generalization error, and extensive experiments\non static/neuromorphic recognition as well as 3D point cloud classification\ntasks demonstrate its effectiveness, versatility, and adversarial robustness.\nIn particular, our regularization significantly improves the recognition\naccuracy of low-latency SNN for neuromorphic objects, contributing to the\nreal-world deployment of neuromorphic computational software-hardware\nintegration.",
      "tldr_zh": "本文针对脉冲神经网络(SNNs)的过拟合问题，提出了一种简单有效的Temporal Reversal Regularization (TRR)方法，通过输入/特征的时间反转扰动，让SNNs学习产生原反转一致的输出，从而获得对扰动不变的表示。TRR进一步利用Hadamard product进行原特征和时间反转特征的混合，扩展隐式维度并作为时空正则化器，以提升泛化性能。理论分析显示该方法能收紧泛化错误的upper bound，实验在静态/神经形态识别和3D点云分类任务上验证了其有效性、多功能性和对抗鲁棒性，特别是显著提高了低延迟SNN在神经形态对象识别中的准确率，促进了神经形态计算的实际部署。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.09108v3",
      "published_date": "2024-08-17 06:23:38 UTC",
      "updated_date": "2025-03-10 08:30:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:13:05.570766"
    },
    {
      "arxiv_id": "2408.09106v3",
      "title": "Fragment-Masked Diffusion for Molecular Optimization",
      "title_zh": "片段掩码扩散用于分子优化",
      "authors": [
        "Kun Li",
        "Xiantao Cai",
        "Jia Wu",
        "Shirui Pan",
        "Huiting Xu",
        "Bo Du",
        "Wenbin Hu"
      ],
      "abstract": "Molecular optimization is a crucial aspect of drug discovery, aimed at\nrefining molecular structures to enhance drug efficacy and minimize side\neffects, ultimately accelerating the overall drug development process. Many\nmolecular optimization methods have been proposed, significantly advancing drug\ndiscovery. These methods primarily on understanding the specific drug target\nstructures or their hypothesized roles in combating diseases. However,\nchallenges such as a limited number of available targets and a difficulty\ncapturing clear structures hinder innovative drug development. In contrast,\nphenotypic drug discovery (PDD) does not depend on clear target structures and\ncan identify hits with novel and unbiased polypharmacology signatures. As a\nresult, PDD-based molecular optimization can reduce potential safety risks\nwhile optimizing phenotypic activity, thereby increasing the likelihood of\nclinical success. Therefore, we propose a fragment-masked molecular\noptimization method based on PDD (FMOP). FMOP employs a regression-free\ndiffusion model to conditionally optimize the molecular masked regions,\neffectively generating new molecules with similar scaffolds. On the large-scale\ndrug response dataset GDSCv2, we optimize the potential molecules across all\n985 cell lines. The overall experiments demonstrate that the in-silico\noptimization success rate reaches 95.4\\%, with an average efficacy increase of\n7.5\\%. Additionally, we conduct extensive ablation and visualization\nexperiments, confirming that FMOP is an effective and robust molecular\noptimization method. The code is available at:\nhttps://anonymous.4open.science/r/FMOP-98C2.",
      "tldr_zh": "本研究针对分子优化在药物发现中的挑战，提出了一种基于表型药物发现 (PDD) 的方法，名为 Fragment-Masked Diffusion for Molecular Optimization (FMOP)。FMOP 利用无回归的扩散模型 (regression-free diffusion model) 来优化分子掩码区域，生成具有相似支架的新分子，从而减少对特定目标结构的依赖，并降低潜在安全风险。实验在大型药物响应数据集 GDSCv2 上优化了 985 个细胞系的分子，结果显示 in-silico 优化成功率达 95.4%，平均效能提升 7.5%，并通过消融和可视化实验验证了其有效性和鲁棒性。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "12 pages, 9 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.09106v3",
      "published_date": "2024-08-17 06:00:58 UTC",
      "updated_date": "2025-05-14 16:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:13:16.959606"
    },
    {
      "arxiv_id": "2408.09097v1",
      "title": "Depth-guided Texture Diffusion for Image Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Sun",
        "Yuan Li",
        "Qixiang Ye",
        "Jianbin Jiao",
        "Yanzhao Zhou"
      ],
      "abstract": "Depth information provides valuable insights into the 3D structure especially\nthe outline of objects, which can be utilized to improve the semantic\nsegmentation tasks. However, a naive fusion of depth information can disrupt\nfeature and compromise accuracy due to the modality gap between the depth and\nthe vision. In this work, we introduce a Depth-guided Texture Diffusion\napproach that effectively tackles the outlined challenge. Our method extracts\nlow-level features from edges and textures to create a texture image. This\nimage is then selectively diffused across the depth map, enhancing structural\ninformation vital for precisely extracting object outlines. By integrating this\nenriched depth map with the original RGB image into a joint feature embedding,\nour method effectively bridges the disparity between the depth map and the\nimage, enabling more accurate semantic segmentation. We conduct comprehensive\nexperiments across diverse, commonly-used datasets spanning a wide range of\nsemantic segmentation tasks, including Camouflaged Object Detection (COD),\nSalient Object Detection (SOD), and indoor semantic segmentation. With\nsource-free estimated depth or depth captured by depth cameras, our method\nconsistently outperforms existing baselines and achieves new state-of-theart\nresults, demonstrating the effectiveness of our Depth-guided Texture Diffusion\nfor image semantic segmentation.",
      "tldr_zh": "该研究提出了一种Depth-guided Texture Diffusion方法，用于提升图像语义分割的准确性，通过利用深度信息来改善对象轮廓提取，同时解决深度图与RGB图像之间的模态差距问题。具体而言，该方法从边缘和纹理提取低级特征，生成纹理图像并选择性扩散到深度图中，增强结构信息，然后将增强后的深度图与原始RGB图像整合到联合特征嵌入中。实验结果显示，在Camouflaged Object Detection (COD)、Salient Object Detection (SOD)和室内语义分割等任务上，该方法在使用估计深度或深度相机捕获的深度时，均超越现有基线并实现新的state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09097v1",
      "published_date": "2024-08-17 04:55:03 UTC",
      "updated_date": "2024-08-17 04:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:13:28.067297"
    },
    {
      "arxiv_id": "2408.09094v1",
      "title": "Research on color recipe recommendation based on unstructured data using TENN",
      "title_zh": "翻译失败",
      "authors": [
        "Seongsu Jhang",
        "Donghwi Yoo",
        "Jaeyong Kown"
      ],
      "abstract": "Recently, services and business models based on large language models, such\nas OpenAI Chatgpt, Google BARD, and Microsoft copilot, have been introduced,\nand the applications utilizing natural language processing with deep learning\nare increasing, and it is one of the natural language preprocessing methods.\nConversion to machine language through tokenization and processing of\nunstructured data are increasing. Although algorithms that can understand and\napply human language are becoming increasingly sophisticated, it is difficult\nto apply them to processes that rely on human emotions and senses in industries\nthat still mainly deal with standardized data. In particular, in processes\nwhere brightness, saturation, and color information are essential, such as\npainting and injection molding, most small and medium-sized companies,\nexcluding large corporations, rely on the tacit knowledge and sensibility of\ncolor mixers, and even customer companies often present non-standardized\nrequirements. . In this paper, we proposed TENN to infer color recipe based on\nunstructured data with emotional natural language, and demonstrated it.",
      "tldr_zh": "该研究探讨了利用非结构化数据进行颜色配方推荐的问题，针对传统依赖人类情感和感官的行业（如绘画和注塑成型）提出 TENN 方法。TENN 通过自然语言处理（NLP）和深度学习技术，将情感自然语言转换为机器可理解的格式，从而推断颜色配方，包括亮度、饱和度和颜色信息。实验演示表明，该方法有助于小中型企业摆脱对默契知识的依赖，提供更标准化和高效的颜色推荐解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09094v1",
      "published_date": "2024-08-17 04:45:48 UTC",
      "updated_date": "2024-08-17 04:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:13:40.144796"
    },
    {
      "arxiv_id": "2408.11862v1",
      "title": "Sentiment analysis of preservice teachers' reflections using a large language model",
      "title_zh": "翻译失败",
      "authors": [
        "Yunsoo Park",
        "Younkyung Hong"
      ],
      "abstract": "In this study, the emotion and tone of preservice teachers' reflections were\nanalyzed using sentiment analysis with LLMs: GPT-4, Gemini, and BERT. We\ncompared the results to understand how each tool categorizes and describes\nindividual reflections and multiple reflections as a whole. This study aims to\nexplore ways to bridge the gaps between qualitative, quantitative, and\ncomputational analyses of reflective practices in teacher education. This study\nfinds that to effectively integrate LLM analysis into teacher education,\ndeveloping an analysis method and result format that are both comprehensive and\nrelevant for preservice teachers and teacher educators is crucial.",
      "tldr_zh": "本研究使用大型语言模型（LLMs）如 GPT-4、Gemini 和 BERT 进行情感分析，评估在职教师（preservice teachers）的反思内容中的情感和语气。研究者比较了这些工具在分类和描述单个反思与整体反思方面的表现，旨在桥接教师教育中的定性、定量和计算分析方法。结果表明，要有效整合 LLM 分析，需要开发全面且相关的分析方法和结果格式，以更好地服务于教师和教育者。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 tables, WAIE 2024 (2024 6th International Workshop on\n  Artificial Intelligence and Education)",
      "pdf_url": "http://arxiv.org/pdf/2408.11862v1",
      "published_date": "2024-08-17 01:56:15 UTC",
      "updated_date": "2024-08-17 01:56:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:13:51.823034"
    },
    {
      "arxiv_id": "2408.09065v1",
      "title": "Linking Robustness and Generalization: A k* Distribution Analysis of Concept Clustering in Latent Space for Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shashank Kotyan",
        "Pin-Yu Chen",
        "Danilo Vasconcellos Vargas"
      ],
      "abstract": "Most evaluations of vision models use indirect methods to assess latent space\nquality. These methods often involve adding extra layers to project the latent\nspace into a new one. This projection makes it difficult to analyze and compare\nthe original latent space. This article uses the k* Distribution, a local\nneighborhood analysis method, to examine the learned latent space at the level\nof individual concepts, which can be extended to examine the entire latent\nspace. We introduce skewness-based true and approximate metrics for\ninterpreting individual concepts to assess the overall quality of vision\nmodels' latent space. Our findings indicate that current vision models\nfrequently fracture the distributions of individual concepts within the latent\nspace. Nevertheless, as these models improve in generalization across multiple\ndatasets, the degree of fracturing diminishes. A similar trend is observed in\nrobust vision models, where increased robustness correlates with reduced\nfracturing. Ultimately, this approach enables a direct interpretation and\ncomparison of the latent spaces of different vision models and reveals a\nrelationship between a model's generalizability and robustness. Results show\nthat as a model becomes more general and robust, it tends to learn features\nthat result in better clustering of concepts. Project Website is available\nonline at https://shashankkotyan.github.io/k-Distribution/",
      "tldr_zh": "本研究通过 k* Distribution（一种局部邻域分析方法）直接评估视觉模型的 latent space，避免了传统间接投影方法的局限。作者引入 skewness-based true 和 approximate metrics 来分析单个概念的聚类质量，发现当前视觉模型常导致概念分布在 latent space 中破碎，但随着模型的 generalization 和 robustness 提升，这种破碎程度会减少。结果表明，更泛化和鲁棒的模型倾向于学习更好的概念 clustering，从而揭示了模型性能与 latent space 质量之间的紧密关系。项目网站提供在线资源以进一步比较不同模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.09065v1",
      "published_date": "2024-08-17 01:43:51 UTC",
      "updated_date": "2024-08-17 01:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:14:05.712922"
    },
    {
      "arxiv_id": "2408.12665v1",
      "title": "Fairness-Aware Streaming Feature Selection with Causal Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Leizhen Zhang",
        "Lusi Li",
        "Di Wu",
        "Sheng Chen",
        "Yi He"
      ],
      "abstract": "Its crux lies in the optimization of a tradeoff between accuracy and fairness\nof resultant models on the selected feature subset. The technical challenge of\nour setting is twofold: 1) streaming feature inputs, such that an informative\nfeature may become obsolete or redundant for prediction if its information has\nbeen covered by other similar features that arrived prior to it, and 2)\nnon-associational feature correlation, such that bias may be leaked from those\nseemingly admissible, non-protected features. To overcome this, we propose\nStreaming Feature Selection with Causal Fairness (SFCF) that builds two causal\ngraphs egocentric to prediction label and protected feature, respectively,\nstriving to model the complex correlation structure among streaming features,\nlabels, and protected information. As such, bias can be eradicated from\npredictive modeling by removing those features being causally correlated with\nthe protected feature yet independent to the labels. We theorize that the\noriginally redundant features for prediction can later become admissible, when\nthe learning accuracy is compromised by the large number of removed features\n(non-protected but can be used to reconstruct bias information). We benchmark\nSFCF\\ on five datasets widely used in streaming feature research, and the\nresults substantiate its performance superiority over six rival models in terms\nof efficiency and sparsity of feature selection and equalized odds of the\nresultant predictive models.",
      "tldr_zh": "该研究提出了一种公平感知的流式特征选择方法Streaming Feature Selection with Causal Fairness (SFCF)，旨在优化模型准确性和公平性之间的权衡，尤其针对流式特征输入的冗余问题和非关联特征的相关性导致的偏见泄露。SFCF 通过构建两个因果图（一个以预测标签为中心，另一个以保护特征为中心）来建模特征、标签和保护信息间的复杂相关结构，并移除那些与保护特征因果相关但与标签无关的特征，从而消除偏见。实验在五个流式特征数据集上验证了SFCF的表现，相比六种竞争模型，它在特征选择的效率、稀疏性和结果模型的equalized odds公平性指标上均显示出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by the 2024 IEEE International\n  Conference on Systems, Man, and Cybernetics (SMC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.12665v1",
      "published_date": "2024-08-17 00:41:02 UTC",
      "updated_date": "2024-08-17 00:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:14:28.032881"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 44,
  "processed_papers_count": 44,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T16:14:59.776067"
}