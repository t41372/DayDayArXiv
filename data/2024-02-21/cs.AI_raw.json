[
  {
    "arxiv_id": "2402.14881v1",
    "title": "A Study on the Vulnerability of Test Questions against ChatGPT-based Cheating",
    "authors": [
      "Shanker Ram",
      "Chen Qian"
    ],
    "abstract": "ChatGPT is a chatbot that can answer text prompts fairly accurately, even\nperforming very well on postgraduate-level questions. Many educators have found\nthat their take-home or remote tests and exams are vulnerable to ChatGPT-based\ncheating because students may directly use answers provided by tools like\nChatGPT. In this paper, we try to provide an answer to an important question:\nhow well ChatGPT can answer test questions and how we can detect whether the\nquestions of a test can be answered correctly by ChatGPT. We generated\nChatGPT's responses to the MedMCQA dataset, which contains over 10,000 medical\nschool entrance exam questions. We analyzed the responses and uncovered certain\ntypes of questions ChatGPT answers more inaccurately than others. In addition,\nwe have created a basic natural language processing model to single out the\nmost vulnerable questions to ChatGPT in a collection of questions or a sample\nexam. Our tool can be used by test-makers to avoid ChatGPT-vulnerable test\nquestions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "2023 International Conference on Machine Learning and Applications\n  (ICMLA)",
    "pdf_url": "http://arxiv.org/pdf/2402.14881v1",
    "published_date": "2024-02-21 23:51:06 UTC",
    "updated_date": "2024-02-21 23:51:06 UTC"
  },
  {
    "arxiv_id": "2402.16611v2",
    "title": "Understanding the Dataset Practitioners Behind Large Language Model Development",
    "authors": [
      "Crystal Qian",
      "Emily Reif",
      "Minsuk Kahng"
    ],
    "abstract": "As large language models (LLMs) become more advanced and impactful, it is\nincreasingly important to scrutinize the data that they rely upon and produce.\nWhat is it to be a dataset practitioner doing this work? We approach this in\ntwo parts: first, we define the role of \"dataset practitioners\" by performing a\nretrospective analysis on the responsibilities of teams contributing to LLM\ndevelopment at a technology company, Google. Then, we conduct semi-structured\ninterviews with a cross-section of these practitioners (N=10). We find that\nalthough data quality is a top priority, there is little consensus around what\ndata quality is and how to evaluate it. Consequently, practitioners either rely\non their own intuition or write custom code to evaluate their data. We discuss\npotential reasons for this phenomenon and opportunities for alignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 2 figures. To be published in In Extended Abstracts of the\n  CHI Conference on Human Factors in Computing Systems (CHI EA '24). Revised to\n  reflect updates from CHI LBW reviewer feedback",
    "pdf_url": "http://arxiv.org/pdf/2402.16611v2",
    "published_date": "2024-02-21 23:50:37 UTC",
    "updated_date": "2024-04-01 19:58:43 UTC"
  },
  {
    "arxiv_id": "2402.14179v1",
    "title": "Bangla AI: A Framework for Machine Translation Utilizing Large Language Models for Ethnic Media",
    "authors": [
      "MD Ashraful Goni",
      "Fahad Mostafa",
      "Kerk F. Kee"
    ],
    "abstract": "Ethnic media, which caters to diaspora communities in host nations, serves as\na vital platform for these communities to both produce content and access\ninformation. Rather than utilizing the language of the host nation, ethnic\nmedia delivers news in the language of the immigrant community. For instance,\nin the USA, Bangla ethnic media presents news in Bangla rather than English.\nThis research delves into the prospective integration of large language models\n(LLM) and multi-lingual machine translations (MMT) within the ethnic media\nindustry. It centers on the transformative potential of using LLM in MMT in\nvarious facets of news translation, searching, and categorization. The paper\noutlines a theoretical framework elucidating the integration of LLM and MMT\ninto the news searching and translation processes for ethnic media.\nAdditionally, it briefly addresses the potential ethical challenges associated\nwith the incorporation of LLM and MMT in news translation procedures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 Pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2402.14179v1",
    "published_date": "2024-02-21 23:43:04 UTC",
    "updated_date": "2024-02-21 23:43:04 UTC"
  },
  {
    "arxiv_id": "2402.14174v3",
    "title": "Blending Data-Driven Priors in Dynamic Games",
    "authors": [
      "Justin Lidard",
      "Haimin Hu",
      "Asher Hancock",
      "Zixu Zhang",
      "Albert Gimó Contreras",
      "Vikash Modi",
      "Jonathan DeCastro",
      "Deepak Gopinath",
      "Guy Rosman",
      "Naomi Ehrich Leonard",
      "María Santos",
      "Jaime Fernández Fisac"
    ],
    "abstract": "As intelligent robots like autonomous vehicles become increasingly deployed\nin the presence of people, the extent to which these systems should leverage\nmodel-based game-theoretic planners versus data-driven policies for safe,\ninteraction-aware motion planning remains an open question. Existing dynamic\ngame formulations assume all agents are task-driven and behave optimally.\nHowever, in reality, humans tend to deviate from the decisions prescribed by\nthese models, and their behavior is better approximated under a noisy-rational\nparadigm. In this work, we investigate a principled methodology to blend a\ndata-driven reference policy with an optimization-based game-theoretic policy.\nWe formulate KLGame, an algorithm for solving non-cooperative dynamic game with\nKullback-Leibler (KL) regularization with respect to a general, stochastic, and\npossibly multi-modal reference policy. Our method incorporates, for each\ndecision maker, a tunable parameter that permits modulation between task-driven\nand data-driven behaviors. We propose an efficient algorithm for computing\nmulti-modal approximate feedback Nash equilibrium strategies of KLGame in real\ntime. Through a series of simulated and real-world autonomous driving\nscenarios, we demonstrate that KLGame policies can more effectively incorporate\nguidance from the reference policy and account for noisily-rational human\nbehaviors versus non-regularized baselines. Website with additional\ninformation, videos, and code: https://kl-games.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.RO",
    "comment": "20 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14174v3",
    "published_date": "2024-02-21 23:22:32 UTC",
    "updated_date": "2024-07-07 02:54:35 UTC"
  },
  {
    "arxiv_id": "2402.14162v1",
    "title": "On Large Visual Language Models for Medical Imaging Analysis: An Empirical Study",
    "authors": [
      "Minh-Hao Van",
      "Prateek Verma",
      "Xintao Wu"
    ],
    "abstract": "Recently, large language models (LLMs) have taken the spotlight in natural\nlanguage processing. Further, integrating LLMs with vision enables the users to\nexplore emergent abilities with multimodal data. Visual language models (VLMs),\nsuch as LLaVA, Flamingo, or CLIP, have demonstrated impressive performance on\nvarious visio-linguistic tasks. Consequently, there are enormous applications\nof large models that could be potentially used in the biomedical imaging field.\nAlong that direction, there is a lack of related work to show the ability of\nlarge models to diagnose the diseases. In this work, we study the zero-shot and\nfew-shot robustness of VLMs on the medical imaging analysis tasks. Our\ncomprehensive experiments demonstrate the effectiveness of VLMs in analyzing\nbiomedical images such as brain MRIs, microscopic images of blood cells, and\nchest X-rays.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14162v1",
    "published_date": "2024-02-21 23:01:38 UTC",
    "updated_date": "2024-02-21 23:01:38 UTC"
  },
  {
    "arxiv_id": "2402.14160v2",
    "title": "Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement",
    "authors": [
      "Wonseok Jeon",
      "Mukul Gagrani",
      "Raghavv Goel",
      "Junyoung Park",
      "Mingu Lee",
      "Christopher Lott"
    ],
    "abstract": "Speculative decoding is an inference-acceleration method for large language\nmodels (LLMs) where a small language model generates a draft-token sequence\nwhich is further verified by the target LLM in parallel. Recent works have\nadvanced this method by establishing a draft-token tree, achieving superior\nperformance over a single-sequence speculative decoding. However, those works\nindependently generate tokens at each level of the tree, not leveraging the\ntree's entire diversifiability. Besides, their empirical superiority has been\nshown for fixed length of sequences, implicitly granting more computational\nresource to LLM for the tree-based methods. None of the existing works has\nconducted empirical studies with fixed target computational budgets despite its\nimportance to resource-bounded devices. We present Recursive Speculative\nDecoding (RSD), a novel tree-based method that samples draft tokens without\nreplacement and maximizes the diversity of the tree. During RSD's drafting, the\ntree is built by either Gumbel-Top-$k$ trick that draws tokens without\nreplacement in parallel or Stochastic Beam Search that samples sequences\nwithout replacement while early-truncating unlikely draft sequences and\nreducing the computational cost of LLM. We empirically evaluate RSD with Llama\n2 and OPT models, showing that RSD outperforms the baseline methods,\nconsistently for fixed draft sequence length and in most cases for fixed\ncomputational budgets at LLM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "82 pages, 9 figures, 54 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.14160v2",
    "published_date": "2024-02-21 22:57:49 UTC",
    "updated_date": "2024-03-05 06:55:26 UTC"
  },
  {
    "arxiv_id": "2402.14155v1",
    "title": "Can Similarity-Based Domain-Ordering Reduce Catastrophic Forgetting for Intent Recognition?",
    "authors": [
      "Amogh Mannekote",
      "Xiaoyi Tian",
      "Kristy Elizabeth Boyer",
      "Bonnie J. Dorr"
    ],
    "abstract": "Task-oriented dialogue systems are expected to handle a constantly expanding\nset of intents and domains even after they have been deployed to support more\nand more functionalities. To live up to this expectation, it becomes critical\nto mitigate the catastrophic forgetting problem (CF) that occurs in continual\nlearning (CL) settings for a task such as intent recognition. While existing\ndialogue systems research has explored replay-based and regularization-based\nmethods to this end, the effect of domain ordering on the CL performance of\nintent recognition models remains unexplored. If understood well, domain\nordering has the potential to be an orthogonal technique that can be leveraged\nalongside existing techniques such as experience replay. Our work fills this\ngap by comparing the impact of three domain-ordering strategies (min-sum path,\nmax-sum path, random) on the CL performance of a generative intent recognition\nmodel. Our findings reveal that the min-sum path strategy outperforms the\nothers in reducing catastrophic forgetting when training on the 220M T5-Base\nmodel. However, this advantage diminishes with the larger 770M T5-Large model.\nThese results underscores the potential of domain ordering as a complementary\nstrategy for mitigating catastrophic forgetting in continually learning intent\nrecognition models, particularly in resource-constrained scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14155v1",
    "published_date": "2024-02-21 22:30:57 UTC",
    "updated_date": "2024-02-21 22:30:57 UTC"
  },
  {
    "arxiv_id": "2402.14880v1",
    "title": "Automatic Histograms: Leveraging Language Models for Text Dataset Exploration",
    "authors": [
      "Emily Reif",
      "Crystal Qian",
      "James Wexler",
      "Minsuk Kahng"
    ],
    "abstract": "Making sense of unstructured text datasets is perennially difficult, yet\nincreasingly relevant with Large Language Models. Data workers often rely on\ndataset summaries, especially distributions of various derived features. Some\nfeatures, like toxicity or topics, are relevant to many datasets, but many\ninteresting features are domain specific: instruments and genres for a music\ndataset, or diseases and symptoms for a medical dataset. Accordingly, data\nworkers often run custom analyses for each dataset, which is cumbersome and\ndifficult. We present AutoHistograms, a visualization tool leveragingLLMs.\nAutoHistograms automatically identifies relevant features, visualizes them with\nhistograms, and allows the user to interactively query the dataset for\ncategories of entities and create new histograms. In a user study with 10 data\nworkers (n=10), we observe that participants can quickly identify insights and\nexplore the data using AutoHistograms, and conceptualize a broad range of\napplicable use cases. Together, this tool and user study contributeto the\ngrowing field of LLM-assisted sensemaking tools.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14880v1",
    "published_date": "2024-02-21 22:29:16 UTC",
    "updated_date": "2024-02-21 22:29:16 UTC"
  },
  {
    "arxiv_id": "2402.14151v2",
    "title": "BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives",
    "authors": [
      "Xiaoyue Wang",
      "Jianyou Wang",
      "Weili Cao",
      "Kaicheng Wang",
      "Ramamohan Paturi",
      "Leon Bergen"
    ],
    "abstract": "We present the Benchmark of Information Retrieval (IR) tasks with Complex\nObjectives (BIRCO). BIRCO evaluates the ability of IR systems to retrieve\ndocuments given multi-faceted user objectives. The benchmark's complexity and\ncompact size make it suitable for evaluating large language model (LLM)-based\ninformation retrieval systems. We present a modular framework for investigating\nfactors that may influence LLM performance on retrieval tasks, and identify a\nsimple baseline model which matches or outperforms existing approaches and more\ncomplex alternatives. No approach achieves satisfactory performance on all\nbenchmark tasks, suggesting that stronger models and new retrieval protocols\nare necessary to address complex user needs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14151v2",
    "published_date": "2024-02-21 22:22:30 UTC",
    "updated_date": "2024-04-03 20:11:02 UTC"
  },
  {
    "arxiv_id": "2402.14147v1",
    "title": "Wikibench: Community-Driven Data Curation for AI Evaluation on Wikipedia",
    "authors": [
      "Tzu-Sheng Kuo",
      "Aaron Halfaker",
      "Zirui Cheng",
      "Jiwoo Kim",
      "Meng-Hsin Wu",
      "Tongshuang Wu",
      "Kenneth Holstein",
      "Haiyi Zhu"
    ],
    "abstract": "AI tools are increasingly deployed in community contexts. However, datasets\nused to evaluate AI are typically created by developers and annotators outside\na given community, which can yield misleading conclusions about AI performance.\nHow might we empower communities to drive the intentional design and curation\nof evaluation datasets for AI that impacts them? We investigate this question\non Wikipedia, an online community with multiple AI-based content moderation\ntools deployed. We introduce Wikibench, a system that enables communities to\ncollaboratively curate AI evaluation datasets, while navigating ambiguities and\ndifferences in perspective through discussion. A field study on Wikipedia shows\nthat datasets curated using Wikibench can effectively capture community\nconsensus, disagreement, and uncertainty. Furthermore, study participants used\nWikibench to shape the overall data curation process, including refining label\ndefinitions, determining data inclusion criteria, and authoring data\nstatements. Based on our findings, we propose future directions for systems\nthat support community-driven data curation.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14147v1",
    "published_date": "2024-02-21 22:10:21 UTC",
    "updated_date": "2024-02-21 22:10:21 UTC"
  },
  {
    "arxiv_id": "2402.14143v1",
    "title": "SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings",
    "authors": [
      "Rishabh Bajpai",
      "Bhooma Aravamuthan"
    ],
    "abstract": "Movement disorders are typically diagnosed by consensus-based expert\nevaluation of clinically acquired patient videos. However, such broad sharing\nof patient videos poses risks to patient privacy. Face blurring can be used to\nde-identify videos, but this process is often manual and time-consuming.\nAvailable automated face blurring techniques are subject to either excessive,\ninconsistent, or insufficient facial blurring - all of which can be disastrous\nfor video assessment and patient privacy. Furthermore, assessing movement\ndisorders in these videos is often subjective. The extraction of quantifiable\nkinematic features can help inform movement disorder assessment in these\nvideos, but existing methods to do this are prone to errors if using\npre-blurred videos. We have developed an open-source software called SecurePose\nthat can both achieve reliable face blurring and automated kinematic extraction\nin patient videos recorded in a clinic setting using an iPad. SecurePose,\nextracts kinematics using a pose estimation method (OpenPose), tracks and\nuniquely identifies all individuals in the video, identifies the patient, and\nperforms face blurring. The software was validated on gait videos recorded in\noutpatient clinic visits of 116 children with cerebral palsy. The validation\ninvolved assessing intermediate steps of kinematics extraction and face\nblurring with manual blurring (ground truth). Moreover, when SecurePose was\ncompared with six selected existing methods, it outperformed other methods in\nautomated face detection and achieved ceiling accuracy in 91.08% less time than\na robust manual face blurring method. Furthermore, ten experienced researchers\nfound SecurePose easy to learn and use, as evidenced by the System Usability\nScale. The results of this work validated the performance and usability of\nSecurePose on clinically recorded gait videos for face blurring and kinematics\nextraction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14143v1",
    "published_date": "2024-02-21 21:55:29 UTC",
    "updated_date": "2024-02-21 21:55:29 UTC"
  },
  {
    "arxiv_id": "2402.14879v1",
    "title": "Driving Generative Agents With Their Personality",
    "authors": [
      "Lawrence J. Klinkert",
      "Stephanie Buongiorno",
      "Corey Clark"
    ],
    "abstract": "This research explores the potential of Large Language Models (LLMs) to\nutilize psychometric values, specifically personality information, within the\ncontext of video game character development. Affective Computing (AC) systems\nquantify a Non-Player character's (NPC) psyche, and an LLM can take advantage\nof the system's information by using the values for prompt generation. The\nresearch shows an LLM can consistently represent a given personality profile,\nthereby enhancing the human-like characteristics of game characters.\nRepurposing a human examination, the International Personality Item Pool (IPIP)\nquestionnaire, to evaluate an LLM shows that the model can accurately generate\ncontent concerning the personality provided. Results show that the improvement\nof LLM, such as the latest GPT-4 model, can consistently utilize and interpret\na personality to represent behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 Pages, 4 figures, Draft",
    "pdf_url": "http://arxiv.org/pdf/2402.14879v1",
    "published_date": "2024-02-21 21:29:57 UTC",
    "updated_date": "2024-02-21 21:29:57 UTC"
  },
  {
    "arxiv_id": "2402.14878v2",
    "title": "Energy-efficiency Limits on Training AI Systems using Learning-in-Memory",
    "authors": [
      "Zihao Chen",
      "Johannes Leugering",
      "Gert Cauwenberghs",
      "Shantanu Chakrabartty"
    ],
    "abstract": "Learning-in-memory (LIM) is a recently proposed paradigm to overcome\nfundamental memory bottlenecks in training machine learning systems. While\ncompute-in-memory (CIM) approaches can address the so-called memory-wall (i.e.\nenergy dissipated due to repeated memory read access) they are agnostic to the\nenergy dissipated due to repeated memory writes at the precision required for\ntraining (the update-wall), and they don't account for the energy dissipated\nwhen transferring information between short-term and long-term memories (the\nconsolidation-wall). The LIM paradigm proposes that these bottlenecks, too, can\nbe overcome if the energy barrier of physical memories is adaptively modulated\nsuch that the dynamics of memory updates and consolidation match the Lyapunov\ndynamics of gradient-descent training of an AI model. In this paper, we derive\nnew theoretical lower bounds on energy dissipation when training AI systems\nusing different LIM approaches. The analysis presented here is model-agnostic\nand highlights the trade-off between energy efficiency and the speed of\ntraining. The resulting non-equilibrium energy-efficiency bounds have a similar\nflavor as that of Landauer's energy-dissipation bounds. We also extend these\nlimits by taking into account the number of floating-point operations (FLOPs)\nused for training, the size of the AI model, and the precision of the training\nparameters. Our projections suggest that the energy-dissipation lower-bound to\ntrain a brain scale AI system (comprising of $10^{15}$ parameters) using LIM is\n$10^8 \\sim 10^9$ Joules, which is on the same magnitude the Landauer's\nadiabatic lower-bound and $6$ to $7$ orders of magnitude lower than the\nprojections obtained using state-of-the-art AI accelerator hardware\nlower-bounds.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14878v2",
    "published_date": "2024-02-21 21:02:11 UTC",
    "updated_date": "2024-05-21 20:05:51 UTC"
  },
  {
    "arxiv_id": "2402.14123v2",
    "title": "DeiSAM: Segment Anything with Deictic Prompting",
    "authors": [
      "Hikaru Shindo",
      "Manuel Brack",
      "Gopika Sudhakaran",
      "Devendra Singh Dhami",
      "Patrick Schramowski",
      "Kristian Kersting"
    ],
    "abstract": "Large-scale, pre-trained neural networks have demonstrated strong\ncapabilities in various tasks, including zero-shot image segmentation. To\nidentify concrete objects in complex scenes, humans instinctively rely on\ndeictic descriptions in natural language, i.e., referring to something\ndepending on the context such as \"The object that is on the desk and behind the\ncup.\". However, deep learning approaches cannot reliably interpret such deictic\nrepresentations due to their lack of reasoning capabilities in complex\nscenarios. To remedy this issue, we propose DeiSAM -- a combination of large\npre-trained neural networks with differentiable logic reasoners -- for deictic\npromptable segmentation. Given a complex, textual segmentation description,\nDeiSAM leverages Large Language Models (LLMs) to generate first-order logic\nrules and performs differentiable forward reasoning on generated scene graphs.\nSubsequently, DeiSAM segments objects by matching them to the logically\ninferred image regions. As part of our evaluation, we propose the Deictic\nVisual Genome (DeiVG) dataset, containing paired visual input and complex,\ndeictic textual prompts. Our empirical results demonstrate that DeiSAM is a\nsubstantial improvement over purely data-driven baselines for deictic\npromptable segmentation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14123v2",
    "published_date": "2024-02-21 20:43:49 UTC",
    "updated_date": "2024-12-05 13:15:34 UTC"
  },
  {
    "arxiv_id": "2402.14118v1",
    "title": "Masked Matrix Multiplication for Emergent Sparsity",
    "authors": [
      "Brian Wheatman",
      "Meghana Madhyastha",
      "Randal Burns"
    ],
    "abstract": "Artificial intelligence workloads, especially transformer models, exhibit\nemergent sparsity in which computations perform selective sparse access to\ndense data. The workloads are inefficient on hardware designed for dense\ncomputations and do not map well onto sparse data representations. We build a\nvectorized and parallel matrix-multiplication system A X B = C that eliminates\nunnecessary computations and avoids branches based on a runtime evaluation of\nsparsity. We use a combination of dynamic code lookup to adapt to the specific\nsparsity encoded in the B matrix and preprocessing of sparsity maps of the A\nand B matrices to compute conditional branches once for the whole computation.\nFor a wide range of sparsity, from 60% to 95% zeros, our implementation\nperforms fewer instructions and increases performance when compared with Intel\nMKL's dense or sparse matrix multiply routines. Benefits can be as large as 2\ntimes speedup and 4 times fewer instructions.",
    "categories": [
      "cs.DS",
      "cs.AI"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14118v1",
    "published_date": "2024-02-21 20:36:08 UTC",
    "updated_date": "2024-02-21 20:36:08 UTC"
  },
  {
    "arxiv_id": "2402.14116v2",
    "title": "FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models",
    "authors": [
      "Andrew Zhu",
      "Alyssa Hwang",
      "Liam Dugan",
      "Chris Callison-Burch"
    ],
    "abstract": "One type of question that is commonly found in day-to-day scenarios is\n``fan-out'' questions, complex multi-hop, multi-document reasoning questions\nthat require finding information about a large number of entities. However,\nthere exist few resources to evaluate this type of question-answering\ncapability among large language models. To evaluate complex reasoning in LLMs\nmore fully, we present FanOutQA, a high-quality dataset of fan-out\nquestion-answer pairs and human-annotated decompositions with English Wikipedia\nas the knowledge base. We formulate three benchmark settings across our dataset\nand benchmark 7 LLMs, including GPT-4, LLaMA 2, Claude-2.1, and Mixtral-8x7B,\nfinding that contemporary models still have room to improve reasoning over\ninter-document dependencies in a long context. We provide our dataset and\nopen-source tools to run models to encourage evaluation at https://fanoutqa.com",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 2 figures. ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14116v2",
    "published_date": "2024-02-21 20:30:45 UTC",
    "updated_date": "2024-06-06 16:41:21 UTC"
  },
  {
    "arxiv_id": "2402.14096v3",
    "title": "EyeTrans: Merging Human and Machine Attention for Neural Code Summarization",
    "authors": [
      "Yifan Zhang",
      "Jiliang Li",
      "Zachary Karas",
      "Aakash Bansal",
      "Toby Jia-Jun Li",
      "Collin McMillan",
      "Kevin Leach",
      "Yu Huang"
    ],
    "abstract": "Neural code summarization leverages deep learning models to automatically\ngenerate brief natural language summaries of code snippets. The development of\nTransformer models has led to extensive use of attention during model design.\nWhile existing work has primarily and almost exclusively focused on static\nproperties of source code and related structural representations like the\nAbstract Syntax Tree (AST), few studies have considered human attention, that\nis, where programmers focus while examining and comprehending code. In this\npaper, we develop a method for incorporating human attention into machine\nattention to enhance neural code summarization. To facilitate this\nincorporation and vindicate this hypothesis, we introduce EyeTrans, which\nconsists of three steps: (1) we conduct an extensive eye-tracking human study\nto collect and pre-analyze data for model training, (2) we devise a\ndata-centric approach to integrate human attention with machine attention in\nthe Transformer architecture, and (3) we conduct comprehensive experiments on\ntwo code summarization tasks to demonstrate the effectiveness of incorporating\nhuman attention into Transformers. Integrating human attention leads to an\nimprovement of up to 29.91% in Functional Summarization and up to 6.39% in\nGeneral Code Summarization performance, demonstrating the substantial benefits\nof this combination. We further explore performance in terms of robustness and\nefficiency by creating challenging summarization scenarios in which EyeTrans\nexhibits interesting properties. We also visualize the attention map to depict\nthe simplifying effect of machine attention in the Transformer by incorporating\nhuman attention. This work has the potential to propel AI research in software\nengineering by introducing more human-centered approaches and data.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14096v3",
    "published_date": "2024-02-21 19:45:06 UTC",
    "updated_date": "2024-02-29 13:33:58 UTC"
  },
  {
    "arxiv_id": "2402.14095v4",
    "title": "Zero-shot generalization across architectures for visual classification",
    "authors": [
      "Evan Gerritz",
      "Luciano Dyballa",
      "Steven W. Zucker"
    ],
    "abstract": "Generalization to unseen data is a key desideratum for deep networks, but its\nrelation to classification accuracy is unclear. Using a minimalist vision\ndataset and a measure of generalizability, we show that popular networks, from\ndeep convolutional networks (CNNs) to transformers, vary in their power to\nextrapolate to unseen classes both across layers and across architectures.\nAccuracy is not a good predictor of generalizability, and generalization varies\nnon-monotonically with layer depth.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.6; I.5.1; I.4.10"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a Tiny Paper at ICLR 2024. Code available at\n  https://github.com/dyballa/generalization/tree/ICLR2024TinyPaper",
    "pdf_url": "http://arxiv.org/pdf/2402.14095v4",
    "published_date": "2024-02-21 19:45:05 UTC",
    "updated_date": "2024-05-03 15:25:09 UTC"
  },
  {
    "arxiv_id": "2403.08820v1",
    "title": "Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns",
    "authors": [
      "Zheyuan Zhang",
      "Zehong Wang",
      "Shifu Hou",
      "Evan Hall",
      "Landon Bachman",
      "Vincent Galassi",
      "Jasmine White",
      "Nitesh V. Chawla",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "The opioid crisis has been one of the most critical society concerns in the\nUnited States. Although the medication assisted treatment (MAT) is recognized\nas the most effective treatment for opioid misuse and addiction, the various\nside effects can trigger opioid relapse. In addition to MAT, the dietary\nnutrition intervention has been demonstrated its importance in opioid misuse\nprevention and recovery. However, research on the alarming connections between\ndietary patterns and opioid misuse remain under-explored. In response to this\ngap, in this paper, we first establish a large-scale multifaceted dietary\nbenchmark dataset related to opioid users at the first attempt and then develop\na novel framework - i.e., namely Opioid Misuse Detection with Interpretable\nDietary Patterns (Diet-ODIN) - to bridge heterogeneous graph (HG) and large\nlanguage model (LLM) for the identification of users with opioid misuse and the\ninterpretation of their associated dietary patterns. Specifically, in\nDiet-ODIN, we first construct an HG to comprehensively incorporate both dietary\nand health-related information, and then we devise a holistic graph learning\nframework with noise reduction to fully capitalize both users' individual\ndietary habits and shared dietary patterns for the detection of users with\nopioid misuse. To further delve into the intricate correlations between dietary\npatterns and opioid misuse, we exploit an LLM by utilizing the knowledge\nobtained from the graph learning model for interpretation. The extensive\nexperimental results based on our established benchmark with quantitative and\nqualitative measures demonstrate the outstanding performance of Diet-ODIN in\nexploring the complex interplay between opioid misuse and dietary patterns, by\ncomparison with state-of-the-art baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08820v1",
    "published_date": "2024-02-21 19:36:24 UTC",
    "updated_date": "2024-02-21 19:36:24 UTC"
  },
  {
    "arxiv_id": "2402.14090v3",
    "title": "Social Environment Design",
    "authors": [
      "Edwin Zhang",
      "Sadie Zhao",
      "Tonghan Wang",
      "Safwan Hossain",
      "Henry Gasztowtt",
      "Stephan Zheng",
      "David C. Parkes",
      "Milind Tambe",
      "Yiling Chen"
    ],
    "abstract": "Artificial Intelligence (AI) holds promise as a technology that can be used\nto improve government and economic policy-making. This paper proposes a new\nresearch agenda towards this end by introducing Social Environment Design, a\ngeneral framework for the use of AI for automated policy-making that connects\nwith the Reinforcement Learning, EconCS, and Computational Social Choice\ncommunities. The framework seeks to capture general economic environments,\nincludes voting on policy objectives, and gives a direction for the systematic\nanalysis of government and economic policy through AI simulation. We highlight\nkey open problems for future research in AI-based policy-making. By solving\nthese challenges, we hope to achieve various social welfare objectives, thereby\npromoting more ethical and responsible decision making.",
    "categories": [
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "ICML 2024 Position Paper. Website at https://sed.eddie.win",
    "pdf_url": "http://arxiv.org/pdf/2402.14090v3",
    "published_date": "2024-02-21 19:29:14 UTC",
    "updated_date": "2024-06-17 16:45:47 UTC"
  },
  {
    "arxiv_id": "2402.14086v3",
    "title": "LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons",
    "authors": [
      "Zheng-Xin Yong",
      "Cristina Menghini",
      "Stephen H. Bach"
    ],
    "abstract": "Data scarcity in low-resource languages can be addressed with word-to-word\ntranslations from labeled task data in high-resource languages using bilingual\nlexicons. However, bilingual lexicons often have limited lexical overlap with\ntask data, which results in poor translation coverage and lexicon utilization.\nWe propose lexicon-conditioned data generation LexC-Gen, a method that\ngenerates low-resource-language classification task data at scale.\nSpecifically, LexC-Gen first uses high-resource-language words from bilingual\nlexicons to generate lexicon-compatible task data, and then it translates them\ninto low-resource languages with bilingual lexicons via word translation.\nAcross 17 extremely low-resource languages, LexC-Gen generated data is\ncompetitive with expert-translated gold data, and yields on average 5.6 and 8.9\npoints improvement over existing lexicon-based word translation methods on\nsentiment analysis and topic classification tasks respectively. Through\nablation study, we show that conditioning on bilingual lexicons is the key\ncomponent of LexC-Gen. LexC-Gen serves as a potential solution to close the\nperformance gap between open-source multilingual models, such as BLOOMZ and\nAya-101, and state-of-the-art commercial models like GPT-4o on\nlow-resource-language tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14086v3",
    "published_date": "2024-02-21 19:20:06 UTC",
    "updated_date": "2024-10-28 03:18:55 UTC"
  },
  {
    "arxiv_id": "2402.14083v2",
    "title": "Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping",
    "authors": [
      "Lucas Lehnert",
      "Sainbayar Sukhbaatar",
      "DiJia Su",
      "Qinqing Zheng",
      "Paul Mcvay",
      "Michael Rabbat",
      "Yuandong Tian"
    ],
    "abstract": "While Transformers have enabled tremendous progress in various application\nsettings, such architectures still trail behind traditional symbolic planners\nfor solving complex decision making tasks. In this work, we demonstrate how to\ntrain Transformers to solve complex planning tasks. This is accomplished by\ntraining an encoder-decoder Transformer model to predict the search dynamics of\nthe $A^*$ search algorithm. We fine tune this model to obtain a Searchformer, a\nTransformer model that optimally solves previously unseen Sokoban puzzles 93.7%\nof the time, while using up to 26.8% fewer search steps than the $A^*$\nimplementation that was used for training initially. In our training method,\n$A^*$'s search dynamics are expressed as a token sequence outlining when task\nstates are added and removed into the search tree during symbolic planning.\nSearchformer significantly outperforms baselines that predict the optimal plan\ndirectly with a 5-10$\\times$ smaller model size and a 10$\\times$ smaller\ntraining dataset. Lastly, we demonstrate how Searchformer scales to larger and\nmore complex decision making tasks with improved percentage of solved tasks and\nshortened search dynamics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14083v2",
    "published_date": "2024-02-21 19:17:28 UTC",
    "updated_date": "2024-04-26 21:05:19 UTC"
  },
  {
    "arxiv_id": "2402.14081v3",
    "title": "Motion Code: Robust Time Series Classification and Forecasting via Sparse Variational Multi-Stochastic Processes Learning",
    "authors": [
      "Chandrajit Bajaj",
      "Minh Nguyen"
    ],
    "abstract": "Despite extensive research, time series classification and forecasting on\nnoisy data remain highly challenging. The main difficulties lie in finding\nsuitable mathematical concepts to describe time series and effectively separate\nnoise from the true signals. Unlike traditional methods treating time series as\nstatic vectors or fixed sequences, we propose a novel framework that views each\ntime series, regardless of length, as a realization of a continuous-time\nstochastic process. This mathematical approach captures dependencies across\ntimestamps and detects hidden, time-varying signals within the noise. However,\nreal-world data often involves multiple distinct dynamics, making it\ninsufficient to model the entire process with a single stochastic model. To\naddress this, we assign each dynamic a unique signature vector and introduce\nthe concept of \"most informative timestamps\" to infer a sparse approximation of\nthe individual dynamics from these vectors. The resulting model, called Motion\nCode, includes parameters that fully capture diverse underlying dynamics in an\nintegrated manner, enabling simultaneous classification and forecasting of time\nseries. Extensive experiments on noisy datasets, including real-world\nParkinson's disease sensor tracking, demonstrate Motion Code's strong\nperformance against established benchmarks for time series classification and\nforecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.14081v3",
    "published_date": "2024-02-21 19:10:08 UTC",
    "updated_date": "2024-11-25 18:57:35 UTC"
  },
  {
    "arxiv_id": "2402.14080v1",
    "title": "Efficient Normalized Conformal Prediction and Uncertainty Quantification for Anti-Cancer Drug Sensitivity Prediction with Deep Regression Forests",
    "authors": [
      "Daniel Nolte",
      "Souparno Ghosh",
      "Ranadip Pal"
    ],
    "abstract": "Deep learning models are being adopted and applied on various critical\ndecision-making tasks, yet they are trained to provide point predictions\nwithout providing degrees of confidence. The trustworthiness of deep learning\nmodels can be increased if paired with uncertainty estimations. Conformal\nPrediction has emerged as a promising method to pair machine learning models\nwith prediction intervals, allowing for a view of the model's uncertainty.\nHowever, popular uncertainty estimation methods for conformal prediction fail\nto provide heteroskedastic intervals that are equally accurate for all samples.\nIn this paper, we propose a method to estimate the uncertainty of each sample\nby calculating the variance obtained from a Deep Regression Forest. We show\nthat the deep regression forest variance improves the efficiency and coverage\nof normalized inductive conformal prediction on a drug response prediction\ntask.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2402.14080v1",
    "published_date": "2024-02-21 19:09:53 UTC",
    "updated_date": "2024-02-21 19:09:53 UTC"
  },
  {
    "arxiv_id": "2402.14015v2",
    "title": "Corrective Machine Unlearning",
    "authors": [
      "Shashwat Goel",
      "Ameya Prabhu",
      "Philip Torr",
      "Ponnurangam Kumaraguru",
      "Amartya Sanyal"
    ],
    "abstract": "Machine Learning models increasingly face data integrity challenges due to\nthe use of large-scale training datasets drawn from the Internet. We study what\nmodel developers can do if they detect that some data was manipulated or\nincorrect. Such manipulated data can cause adverse effects including\nvulnerability to backdoored samples, systemic biases, and reduced accuracy on\ncertain input domains. Realistically, all manipulated training samples cannot\nbe identified, and only a small, representative subset of the affected data can\nbe flagged.\n  We formalize Corrective Machine Unlearning as the problem of mitigating the\nimpact of data affected by unknown manipulations on a trained model, only\nhaving identified a subset of the corrupted data. We demonstrate that the\nproblem of corrective unlearning has significantly different requirements from\ntraditional privacy-oriented unlearning. We find most existing unlearning\nmethods, including retraining-from-scratch without the deletion set, require\nmost of the manipulated data to be identified for effective corrective\nunlearning. However, one approach, Selective Synaptic Dampening, achieves\nlimited success, unlearning adverse effects with just a small portion of the\nmanipulated samples in our setting, which shows encouraging signs for future\nprogress. We hope our work spurs research towards developing better methods for\ncorrective unlearning and offers practitioners a new strategy to handle data\nintegrity challenges arising from web-scale training. Code is available at\nhttps://github.com/drimpossible/corrective-unlearning-bench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Transactions of Machine Learning Research (TMLR), 17\n  pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14015v2",
    "published_date": "2024-02-21 18:54:37 UTC",
    "updated_date": "2024-10-17 16:47:51 UTC"
  },
  {
    "arxiv_id": "2402.14007v2",
    "title": "Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models",
    "authors": [
      "Zhiwei He",
      "Binglin Zhou",
      "Hongkun Hao",
      "Aiwei Liu",
      "Xing Wang",
      "Zhaopeng Tu",
      "Zhuosheng Zhang",
      "Rui Wang"
    ],
    "abstract": "Text watermarking technology aims to tag and identify content produced by\nlarge language models (LLMs) to prevent misuse. In this study, we introduce the\nconcept of cross-lingual consistency in text watermarking, which assesses the\nability of text watermarks to maintain their effectiveness after being\ntranslated into other languages. Preliminary empirical results from two LLMs\nand three watermarking methods reveal that current text watermarking\ntechnologies lack consistency when texts are translated into various languages.\nBased on this observation, we propose a Cross-lingual Watermark Removal Attack\n(CWRA) to bypass watermarking by first obtaining a response from an LLM in a\npivot language, which is then translated into the target language. CWRA can\neffectively remove watermarks, decreasing the AUCs to a random-guessing level\nwithout performance loss. Furthermore, we analyze two key factors that\ncontribute to the cross-lingual consistency in text watermarking and propose\nX-SIR as a defense method against CWRA. Code: https://github.com/zwhe99/X-SIR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (main conference)",
    "pdf_url": "http://arxiv.org/pdf/2402.14007v2",
    "published_date": "2024-02-21 18:48:38 UTC",
    "updated_date": "2024-06-04 14:24:15 UTC"
  },
  {
    "arxiv_id": "2403.14645v1",
    "title": "Designing Multi-Step Action Models for Enterprise AI Adoption",
    "authors": [
      "Shreyash Mishra",
      "Shrey Shah",
      "Rex Pereira"
    ],
    "abstract": "This paper introduces the Multi-Step Action Model (MSAM), a closed-source AI\nmodel designed by Empsing to address challenges hindering AI adoption in\nenterprises. Through a holistic examination, this paper explores MSAM's\nfoundational principles, design architecture, and future trajectory. It\nevaluates MSAM's performance via rigorous testing methodologies and envisions\nits potential impact on advancing AI adoption within organizations.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "68T42",
      "I.2.1; I.2.8"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.14645v1",
    "published_date": "2024-02-21 18:37:13 UTC",
    "updated_date": "2024-02-21 18:37:13 UTC"
  },
  {
    "arxiv_id": "2402.14875v3",
    "title": "What's in a Name? Auditing Large Language Models for Race and Gender Bias",
    "authors": [
      "Alejandro Salinas",
      "Amit Haim",
      "Julian Nyarko"
    ],
    "abstract": "We employ an audit design to investigate biases in state-of-the-art large\nlanguage models, including GPT-4. In our study, we prompt the models for advice\ninvolving a named individual across a variety of scenarios, such as during car\npurchase negotiations or election outcome predictions. We find that the advice\nsystematically disadvantages names that are commonly associated with racial\nminorities and women. Names associated with Black women receive the least\nadvantageous outcomes. The biases are consistent across 42 prompt templates and\nseveral models, indicating a systemic issue rather than isolated incidents.\nWhile providing numerical, decision-relevant anchors in the prompt can\nsuccessfully counteract the biases, qualitative details have inconsistent\neffects and may even increase disparities. Our findings underscore the\nimportance of conducting audits at the point of LLM deployment and\nimplementation to mitigate their potential for harm against marginalized\ncommunities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "62 pages, 34 tables, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14875v3",
    "published_date": "2024-02-21 18:25:25 UTC",
    "updated_date": "2025-01-24 01:15:16 UTC"
  },
  {
    "arxiv_id": "2402.14049v2",
    "title": "Generative Adversarial Models for Extreme Geospatial Downscaling",
    "authors": [
      "Guiye Li",
      "Guofeng Cao"
    ],
    "abstract": "Addressing the challenges of climate change requires accurate and\nhigh-resolution mapping of geospatial data, especially climate and weather\nvariables. However, many existing geospatial datasets, such as the gridded\noutputs of the state-of-the-art numerical climate models (e.g., general\ncirculation models), are only available at very coarse spatial resolutions due\nto the model complexity and extremely high computational demand.\nDeep-learning-based methods, particularly generative adversarial networks\n(GANs) and their variants, have proved effective for refining natural images\nand have shown great promise in improving geospatial datasets. This paper\ndescribes a conditional GAN-based stochastic geospatial downscaling method that\ncan accommodates very high scaling factors. Compared to most existing methods,\nthe method can generate high-resolution accurate climate datasets from very\nlow-resolution inputs. More importantly, the method explicitly considers the\nuncertainty inherent to the downscaling process that tends to be ignored in\nexisting methods. Given an input, the method can produce a multitude of\nplausible high-resolution samples instead of one single deterministic result.\nThese samples allow for an empirical exploration and inferences of model\nuncertainty and robustness. With a case study of gridded climate datasets (wind\nvelocity and solar irradiance), we demonstrate the performances of the\nframework in downscaling tasks with large scaling factors (up to $64\\times$)\nand highlight the advantages of the framework with a comprehensive comparison\nwith commonly used and most recent downscaling methods, including area-to-point\n(ATP) kriging, deep image prior (DIP), enhanced super-resolution generative\nadversarial networks (ESRGAN), physics-informed resolution-enhancing GAN (PhIRE\nGAN), and an efficient diffusion model for remote sensing image\nsuper-resolution (EDiffSR).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14049v2",
    "published_date": "2024-02-21 18:25:04 UTC",
    "updated_date": "2024-08-07 17:09:10 UTC"
  },
  {
    "arxiv_id": "2402.13979v1",
    "title": "The Importance of Architecture Choice in Deep Learning for Climate Applications",
    "authors": [
      "Simon Dräger",
      "Maike Sonnewald"
    ],
    "abstract": "Machine Learning has become a pervasive tool in climate science applications.\nHowever, current models fail to address nonstationarity induced by\nanthropogenic alterations in greenhouse emissions and do not routinely quantify\nthe uncertainty of proposed projections. In this paper, we model the Atlantic\nMeridional Overturning Circulation (AMOC) which is of major importance to\nclimate in Europe and the US East Coast by transporting warm water to these\nregions, and has the potential for abrupt collapse. We can generate arbitrarily\nextreme climate scenarios through arbitrary time scales which we then predict\nusing neural networks. Our analysis shows that the AMOC is predictable using\nneural networks under a diverse set of climate scenarios. Further experiments\nreveal that MLPs and Deep Ensembles can learn the physics of the AMOC instead\nof imitating its progression through autocorrelation. With quantified\nuncertainty, an intriguing pattern of \"spikes\" before critical points of\ncollapse in the AMOC casts doubt on previous analyses that predicted an AMOC\ncollapse within this century. Our results show that Bayesian Neural Networks\nperform poorly compared to more dense architectures and care should be taken\nwhen applying neural networks to nonstationary scenarios such as climate\nprojections. Further, our results highlight that big NN models might have\ndifficulty in modeling global Earth System dynamics accurately and be\nsuccessfully applied in nonstationary climate scenarios due to the physics\nbeing challenging for neural networks to capture.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13979v1",
    "published_date": "2024-02-21 18:09:04 UTC",
    "updated_date": "2024-02-21 18:09:04 UTC"
  },
  {
    "arxiv_id": "2402.19237v1",
    "title": "Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting",
    "authors": [
      "Edgar Medina",
      "Leyong Loh",
      "Namrata Gurung",
      "Kyung Hun Oh",
      "Niels Heller"
    ],
    "abstract": "Human motion prediction is still an open problem extremely important for\nautonomous driving and safety applications. Due to the complex spatiotemporal\nrelation of motion sequences, this remains a challenging problem not only for\nmovement prediction but also to perform a preliminary interpretation of the\njoint connections. In this work, we present a Context-based Interpretable\nSpatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D\nhuman pose forecasting model based on GCNs that encompasses specific layers,\naiding model interpretability and providing information that might be useful\nwhen analyzing motion distribution and body behavior. Our architecture extracts\nmeaningful information from pose sequences, aggregates displacements and\naccelerations into the input model, and finally predicts the output\ndisplacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI\ndatasets demonstrate that CIST-GCN outperforms previous methods in human motion\nprediction and robustness. Since the idea of enhancing interpretability for\nmotion prediction has its merits, we showcase experiments towards it and\nprovide preliminary evaluations of such insights here. available code:\nhttps://github.com/QualityMinds/cistgcn",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.19237v1",
    "published_date": "2024-02-21 17:51:30 UTC",
    "updated_date": "2024-02-21 17:51:30 UTC"
  },
  {
    "arxiv_id": "2402.14874v2",
    "title": "Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation",
    "authors": [
      "Phuc Phan",
      "Hieu Tran",
      "Long Phan"
    ],
    "abstract": "We propose a straightforward approach called Distillation Contrastive\nDecoding (DCD) to enhance the reasoning capabilities of Large Language Models\n(LLMs) during inference. In contrast to previous approaches that relied on\nsmaller amateur models or analysis of hidden state differences, DCD employs\nContrastive Chain-of-thought Prompting and advanced distillation techniques,\nincluding Dropout and Quantization. This approach effectively addresses the\nlimitations of Contrastive Decoding (CD), which typically requires both an\nexpert and an amateur model, thus increasing computational resource demands. By\nintegrating contrastive prompts with distillation, DCD obviates the need for an\namateur model and reduces memory usage. Our evaluations demonstrate that DCD\nsignificantly enhances LLM performance across a range of reasoning benchmarks,\nsurpassing both CD and existing methods in the GSM8K and StrategyQA datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2402.14874v2",
    "published_date": "2024-02-21 17:20:38 UTC",
    "updated_date": "2024-08-23 07:31:42 UTC"
  },
  {
    "arxiv_id": "2402.13945v1",
    "title": "Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty in Scientific Machine Learning",
    "authors": [
      "Farhad Pourkamali-Anaraki",
      "Jamal F. Husseini",
      "Scott E. Stapleton"
    ],
    "abstract": "This paper investigates the use of probabilistic neural networks (PNNs) to\nmodel aleatoric uncertainty, which refers to the inherent variability in the\ninput-output relationships of a system, often characterized by unequal variance\nor heteroscedasticity. Unlike traditional neural networks that produce\ndeterministic outputs, PNNs generate probability distributions for the target\nvariable, allowing the determination of both predicted means and intervals in\nregression scenarios. Contributions of this paper include the development of a\nprobabilistic distance metric to optimize PNN architecture, and the deployment\nof PNNs in controlled data sets as well as a practical material science case\ninvolving fiber-reinforced composites. The findings confirm that PNNs\neffectively model aleatoric uncertainty, proving to be more appropriate than\nthe commonly employed Gaussian process regression for this purpose.\nSpecifically, in a real-world scientific machine learning context, PNNs yield\nremarkably accurate output mean estimates with R-squared scores approaching\n0.97, and their predicted intervals exhibit a high correlation coefficient of\nnearly 0.80, closely matching observed data intervals. Hence, this research\ncontributes to the ongoing exploration of leveraging the sophisticated\nrepresentational capacity of neural networks to delineate complex input-output\nrelationships in scientific problems.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13945v1",
    "published_date": "2024-02-21 17:15:47 UTC",
    "updated_date": "2024-02-21 17:15:47 UTC"
  },
  {
    "arxiv_id": "2402.14873v3",
    "title": "Technical Report on the Pangram AI-Generated Text Classifier",
    "authors": [
      "Bradley Emi",
      "Max Spero"
    ],
    "abstract": "We present Pangram Text, a transformer-based neural network trained to\ndistinguish text written by large language models from text written by humans.\nPangram Text outperforms zero-shot methods such as DetectGPT as well as leading\ncommercial AI detection tools with over 38 times lower error rates on a\ncomprehensive benchmark comprised of 10 text domains (student writing, creative\nwriting, scientific writing, books, encyclopedias, news, email, scientific\npapers, short-form Q&A) and 8 open- and closed-source large language models. We\npropose a training algorithm, hard negative mining with synthetic mirrors, that\nenables our classifier to achieve orders of magnitude lower false positive\nrates on high-data domains such as reviews. Finally, we show that Pangram Text\nis not biased against nonnative English speakers and generalizes to domains and\nmodels unseen during training.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14873v3",
    "published_date": "2024-02-21 17:13:41 UTC",
    "updated_date": "2024-07-29 08:27:34 UTC"
  },
  {
    "arxiv_id": "2402.13934v2",
    "title": "Do Efficient Transformers Really Save Computation?",
    "authors": [
      "Kai Yang",
      "Jan Ackermann",
      "Zhenyu He",
      "Guhao Feng",
      "Bohang Zhang",
      "Yunzhen Feng",
      "Qiwei Ye",
      "Di He",
      "Liwei Wang"
    ],
    "abstract": "As transformer-based language models are trained on increasingly large\ndatasets and with vast numbers of parameters, finding more efficient\nalternatives to the standard Transformer has become very valuable. While many\nefficient Transformers and Transformer alternatives have been proposed, none\nprovide theoretical guarantees that they are a suitable replacement for the\nstandard Transformer. This makes it challenging to identify when to use a\nspecific model and what directions to prioritize for further investigation. In\nthis paper, we aim to understand the capabilities and limitations of efficient\nTransformers, specifically the Sparse Transformer and the Linear Transformer.\nWe focus on their reasoning capability as exhibited by Chain-of-Thought (CoT)\nprompts and follow previous works to model them as Dynamic Programming (DP)\nproblems. Our results show that while these models are expressive enough to\nsolve general DP tasks, contrary to expectations, they require a model size\nthat scales with the problem size. Nonetheless, we identify a class of DP\nproblems for which these models can be more efficient than the standard\nTransformer. We confirm our theoretical results through experiments on\nrepresentative DP tasks, adding to the understanding of efficient Transformers'\npractical strengths and weaknesses.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, ICML 2024 Camera Ready Version",
    "pdf_url": "http://arxiv.org/pdf/2402.13934v2",
    "published_date": "2024-02-21 17:00:56 UTC",
    "updated_date": "2024-11-09 04:25:03 UTC"
  },
  {
    "arxiv_id": "2402.13929v3",
    "title": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation",
    "authors": [
      "Shanchuan Lin",
      "Anran Wang",
      "Xiao Yang"
    ],
    "abstract": "We propose a diffusion distillation method that achieves new state-of-the-art\nin one-step/few-step 1024px text-to-image generation based on SDXL. Our method\ncombines progressive and adversarial distillation to achieve a balance between\nquality and mode coverage. In this paper, we discuss the theoretical analysis,\ndiscriminator design, model formulation, and training techniques. We\nopen-source our distilled SDXL-Lightning models both as LoRA and full UNet\nweights.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13929v3",
    "published_date": "2024-02-21 16:51:05 UTC",
    "updated_date": "2024-03-02 09:09:32 UTC"
  },
  {
    "arxiv_id": "2402.13927v1",
    "title": "The Delusional Hedge Algorithm as a Model of Human Learning from Diverse Opinions",
    "authors": [
      "Yun-Shiuan Chuang",
      "Jerry Zhu",
      "Timothy T. Rogers"
    ],
    "abstract": "Whereas cognitive models of learning often assume direct experience with both\nthe features of an event and with a true label or outcome, much of everyday\nlearning arises from hearing the opinions of others, without direct access to\neither the experience or the ground truth outcome. We consider how people can\nlearn which opinions to trust in such scenarios by extending the hedge\nalgorithm: a classic solution for learning from diverse information sources. We\nfirst introduce a semi-supervised variant we call the delusional hedge capable\nof learning from both supervised and unsupervised experiences. In two\nexperiments, we examine the alignment between human judgments and predictions\nfrom the standard hedge, the delusional hedge, and a heuristic baseline model.\nResults indicate that humans effectively incorporate both labeled and unlabeled\ninformation in a manner consistent with the delusional hedge algorithm --\nsuggesting that human learners not only gauge the accuracy of information\nsources but also their consistency with other reliable sources. The findings\nadvance our understanding of human learning from diverse opinions, with\nimplications for the development of algorithms that better capture how people\nlearn to weigh conflicting information sources.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13927v1",
    "published_date": "2024-02-21 16:48:07 UTC",
    "updated_date": "2024-02-21 16:48:07 UTC"
  },
  {
    "arxiv_id": "2402.13926v1",
    "title": "Large Language Models are Vulnerable to Bait-and-Switch Attacks for Generating Harmful Content",
    "authors": [
      "Federico Bianchi",
      "James Zou"
    ],
    "abstract": "The risks derived from large language models (LLMs) generating deceptive and\ndamaging content have been the subject of considerable research, but even safe\ngenerations can lead to problematic downstream impacts. In our study, we shift\nthe focus to how even safe text coming from LLMs can be easily turned into\npotentially dangerous content through Bait-and-Switch attacks. In such attacks,\nthe user first prompts LLMs with safe questions and then employs a simple\nfind-and-replace post-hoc technique to manipulate the outputs into harmful\nnarratives. The alarming efficacy of this approach in generating toxic content\nhighlights a significant challenge in developing reliable safety guardrails for\nLLMs. In particular, we stress that focusing on the safety of the verbatim LLM\noutputs is insufficient and that we also need to consider post-hoc\ntransformations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13926v1",
    "published_date": "2024-02-21 16:46:36 UTC",
    "updated_date": "2024-02-21 16:46:36 UTC"
  },
  {
    "arxiv_id": "2403.14643v2",
    "title": "Exploring ChatGPT and its Impact on Society",
    "authors": [
      "Md. Asraful Haque",
      "Shuai Li"
    ],
    "abstract": "Artificial intelligence has been around for a while, but suddenly it has\nreceived more attention than ever before. Thanks to innovations from companies\nlike Google, Microsoft, Meta, and other major brands in technology. OpenAI,\nthough, has triggered the button with its ground-breaking invention ChatGPT.\nChatGPT is a Large Language Model (LLM) based on Transformer architecture that\nhas the ability to generate human-like responses in a conversational context.\nIt uses deep learning algorithms to generate natural language responses to\ninput text. Its large number of parameters, contextual generation, and\nopen-domain training make it a versatile and effective tool for a wide range of\napplications, from chatbots to customer service to language translation. It has\nthe potential to revolutionize various industries and transform the way we\ninteract with technology. However, the use of ChatGPT has also raised several\nconcerns, including ethical, social, and employment challenges, which must be\ncarefully considered to ensure the responsible use of this technology. The\narticle provides an overview of ChatGPT, delving into its architecture and\ntraining process. It highlights the potential impacts of ChatGPT on the\nsociety. In this paper, we suggest some approaches involving technology,\nregulation, education, and ethics in an effort to maximize ChatGPT's benefits\nwhile minimizing its negative impacts. This study is expected to contribute to\na greater understanding of ChatGPT and aid in predicting the potential changes\nit may bring about.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "68Txx"
    ],
    "primary_category": "cs.CY",
    "comment": "13 Pages",
    "pdf_url": "http://arxiv.org/pdf/2403.14643v2",
    "published_date": "2024-02-21 16:44:35 UTC",
    "updated_date": "2024-03-25 05:35:12 UTC"
  },
  {
    "arxiv_id": "2402.14048v1",
    "title": "PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial Optimization",
    "authors": [
      "André Hottung",
      "Mridul Mahajan",
      "Kevin Tierney"
    ],
    "abstract": "Reinforcement learning-based methods for constructing solutions to\ncombinatorial optimization problems are rapidly approaching the performance of\nhuman-designed algorithms. To further narrow the gap, learning-based approaches\nmust efficiently explore the solution space during the search process. Recent\napproaches artificially increase exploration by enforcing diverse solution\ngeneration through handcrafted rules, however, these rules can impair solution\nquality and are difficult to design for more complex problems. In this paper,\nwe introduce PolyNet, an approach for improving exploration of the solution\nspace by learning complementary solution strategies. In contrast to other\nworks, PolyNet uses only a single-decoder and a training schema that does not\nenforce diverse solution generation through handcrafted rules. We evaluate\nPolyNet on four combinatorial optimization problems and observe that the\nimplicit diversity mechanism allows PolyNet to find better solutions than\napproaches the explicitly enforce diverse solution generation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14048v1",
    "published_date": "2024-02-21 16:38:14 UTC",
    "updated_date": "2024-02-21 16:38:14 UTC"
  },
  {
    "arxiv_id": "2402.13919v4",
    "title": "SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization",
    "authors": [
      "Prakamya Mishra",
      "Zonghai Yao",
      "Parth Vashisht",
      "Feiyun Ouyang",
      "Beining Wang",
      "Vidhi Dhaval Mody",
      "Hong Yu"
    ],
    "abstract": "Large Language Models (LLMs) such as GPT & Llama have demonstrated\nsignificant achievements in summarization tasks but struggle with factual\ninaccuracies, a critical issue in clinical NLP applications where errors could\nlead to serious consequences. To counter the high costs and limited\navailability of expert-annotated data for factual alignment, this study\nintroduces an innovative pipeline that utilizes >100B parameter GPT variants\nlike GPT-3.5 & GPT-4 to act as synthetic experts to generate high-quality\nsynthetics feedback aimed at enhancing factual consistency in clinical note\nsummarization. Our research primarily focuses on edit feedback generated by\nthese synthetic feedback experts without additional human annotations,\nmirroring and optimizing the practical scenario in which medical professionals\nrefine AI system outputs. Although such 100B+ parameter GPT variants have\nproven to demonstrate expertise in various clinical NLP tasks, such as the\nMedical Licensing Examination, there is scant research on their capacity to act\nas synthetic feedback experts and deliver expert-level edit feedback for\nimproving the generation quality of weaker (<10B parameter) LLMs like GPT-2\n(1.5B) & Llama 2 (7B) in clinical domain. So in this work, we leverage 100B+\nGPT variants to act as synthetic feedback experts offering expert-level edit\nfeedback, that is used to reduce hallucinations and align weaker (<10B\nparameter) LLMs with medical facts using two distinct alignment algorithms (DPO\n& SALT), endeavoring to narrow the divide between AI-generated content and\nfactual accuracy. This highlights the substantial potential of LLM-based\nsynthetic edits in enhancing the alignment of clinical factuality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Equal contribution for the first two authors; To appear in\n  proceedings of the Main Conference on Empirical Methods in Natural Language\n  Processing (EMNLP) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13919v4",
    "published_date": "2024-02-21 16:33:22 UTC",
    "updated_date": "2024-10-03 02:54:46 UTC"
  },
  {
    "arxiv_id": "2402.13917v2",
    "title": "Could We Have Had Better Multilingual LLMs If English Was Not the Central Language?",
    "authors": [
      "Ryandito Diandaru",
      "Lucky Susanto",
      "Zilu Tang",
      "Ayu Purwarianti",
      "Derry Wijaya"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate strong machine translation\ncapabilities on languages they are trained on. However, the impact of factors\nbeyond training data size on translation performance remains a topic of debate,\nespecially concerning languages not directly encountered during training. Our\nstudy delves into Llama2's translation capabilities. By modeling a linear\nrelationship between linguistic feature distances and machine translation\nscores, we ask ourselves if there are potentially better central languages for\nLLMs other than English. Our experiments show that the 7B Llama2 model yields\nabove 10 BLEU when translating into all languages it has seen, which rarely\nhappens for languages it has not seen. Most translation improvements into\nunseen languages come from scaling up the model size rather than instruction\ntuning or increasing shot count. Furthermore, our correlation analysis reveals\nthat syntactic similarity is not the only linguistic factor that strongly\ncorrelates with machine translation scores. Interestingly, we discovered that\nunder specific circumstances, some languages (e.g. Swedish, Catalan), despite\nhaving significantly less training data, exhibit comparable correlation levels\nto English. These insights challenge the prevailing landscape of LLMs,\nsuggesting that models centered around languages other than English could\nprovide a more efficient foundation for multilingual applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "TDLE 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13917v2",
    "published_date": "2024-02-21 16:32:38 UTC",
    "updated_date": "2024-04-05 05:26:05 UTC"
  },
  {
    "arxiv_id": "2402.13914v2",
    "title": "Position: Explain to Question not to Justify",
    "authors": [
      "Przemyslaw Biecek",
      "Wojciech Samek"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) is a young but very promising field\nof research. Unfortunately, the progress in this field is currently slowed down\nby divergent and incompatible goals. We separate various threads tangled within\nthe area of XAI into two complementary cultures of human/value-oriented\nexplanations (BLUE XAI) and model/validation-oriented explanations (RED XAI).\nThis position paper argues that the area of RED XAI is currently\nunder-explored, i.e., more methods for explainability are desperately needed to\nquestion models (e.g., extract knowledge from well-performing models as well as\nspotting and fixing bugs in faulty models), and the area of RED XAI hides great\nopportunities and potential for important research necessary to ensure the\nsafety of AI systems. We conclude this paper by presenting promising challenges\nin this area.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13914v2",
    "published_date": "2024-02-21 16:30:24 UTC",
    "updated_date": "2024-06-28 08:37:28 UTC"
  },
  {
    "arxiv_id": "2402.13897v2",
    "title": "Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning",
    "authors": [
      "Loïc Rakotoson",
      "Sylvain Massip",
      "Fréjus A. A. Laleye"
    ],
    "abstract": "Information retrieval is a rapidly evolving field. However it still faces\nsignificant limitations in the scientific and industrial vast amounts of\ninformation, such as semantic divergence and vocabulary gaps in sparse\nretrieval, low precision and lack of interpretability in semantic search, or\nhallucination and outdated information in generative models. In this paper, we\nintroduce a two-block approach to tackle these hurdles for long documents. The\nfirst block enhances language understanding in sparse retrieval by query\nexpansion to retrieve relevant documents. The second block deepens the result\nby providing comprehensive and informative answers to the complex question\nusing only the information spread in the long document, enabling bidirectional\nengagement. At various stages of the pipeline, intermediate results are\npresented to users to facilitate understanding of the system's reasoning. We\nbelieve this bidirectional approach brings significant advancements in terms of\ntransparency, logical thinking, and comprehensive understanding in the field of\nscientific information retrieval.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "H.3.1; H.3.3; I.7; K.4"
    ],
    "primary_category": "cs.IR",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13897v2",
    "published_date": "2024-02-21 16:09:25 UTC",
    "updated_date": "2024-03-14 00:21:09 UTC"
  },
  {
    "arxiv_id": "2402.14047v2",
    "title": "Simple and Effective Transfer Learning for Neuro-Symbolic Integration",
    "authors": [
      "Alessandro Daniele",
      "Tommaso Campari",
      "Sagar Malhotra",
      "Luciano Serafini"
    ],
    "abstract": "Deep Learning (DL) techniques have achieved remarkable successes in recent\nyears. However, their ability to generalize and execute reasoning tasks remains\na challenge. A potential solution to this issue is Neuro-Symbolic Integration\n(NeSy), where neural approaches are combined with symbolic reasoning. Most of\nthese methods exploit a neural network to map perceptions to symbols and a\nlogical reasoner to predict the output of the downstream task. These methods\nexhibit superior generalization capacity compared to fully neural\narchitectures. However, they suffer from several issues, including slow\nconvergence, learning difficulties with complex perception tasks, and\nconvergence to local minima. This paper proposes a simple yet effective method\nto ameliorate these problems. The key idea involves pretraining a neural model\non the downstream task. Then, a NeSy model is trained on the same task via\ntransfer learning, where the weights of the perceptual part are injected from\nthe pretrained network. The key observation of our work is that the neural\nnetwork fails to generalize only at the level of the symbolic part while being\nperfectly capable of learning the mapping from perceptions to symbols. We have\ntested our training strategy on various SOTA NeSy methods and datasets,\ndemonstrating consistent improvements in the aforementioned problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as full paper at the International Conference on\n  Neural-Symbolic Learning and Reasoning (NeSy 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.14047v2",
    "published_date": "2024-02-21 15:51:01 UTC",
    "updated_date": "2024-07-15 08:49:49 UTC"
  },
  {
    "arxiv_id": "2402.13871v1",
    "title": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach",
    "authors": [
      "Mohammad Amaz Uddin",
      "Iqbal H. Sarker"
    ],
    "abstract": "Phishing email is a serious cyber threat that tries to deceive users by\nsending false emails with the intention of stealing confidential information or\ncausing financial harm. Attackers, often posing as trustworthy entities,\nexploit technological advancements and sophistication to make detection and\nprevention of phishing more challenging. Despite extensive academic research,\nphishing detection remains an ongoing and formidable challenge in the\ncybersecurity landscape. Large Language Models (LLMs) and Masked Language\nModels (MLMs) possess immense potential to offer innovative solutions to\naddress long-standing challenges. In this research paper, we present an\noptimized, fine-tuned transformer-based DistilBERT model designed for the\ndetection of phishing emails. In the detection process, we work with a phishing\nemail dataset and utilize the preprocessing techniques to clean and solve the\nimbalance class issues. Through our experiments, we found that our model\neffectively achieves high accuracy, demonstrating its capability to perform\nwell. Finally, we demonstrate our fine-tuned model using Explainable-AI (XAI)\ntechniques such as Local Interpretable Model-Agnostic Explanations (LIME) and\nTransformer Interpret to explain how our model makes predictions in the context\nof text classification for phishing emails.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13871v1",
    "published_date": "2024-02-21 15:23:21 UTC",
    "updated_date": "2024-02-21 15:23:21 UTC"
  },
  {
    "arxiv_id": "2402.13866v2",
    "title": "Kuaiji: the First Chinese Accounting Large Language Model",
    "authors": [
      "Jiayuan Luo",
      "Songhua Yang",
      "Xiaoling Qiu",
      "Panyu Chen",
      "Yufei Nai",
      "Wenxuan Zeng",
      "Wentao Zhang",
      "Xinke Jiang"
    ],
    "abstract": "Large Language Models (LLMs) like ChatGPT and GPT-4 have demonstrated\nimpressive proficiency in comprehending and generating natural language.\nHowever, they encounter difficulties when tasked with adapting to specialized\ndomains such as accounting. To address this challenge, we introduce Kuaiji, a\ntailored Accounting Large Language Model. Kuaiji is meticulously fine-tuned\nusing the Baichuan framework, which encompasses continuous pre-training and\nsupervised fine-tuning processes. Supported by CAtAcctQA, a dataset containing\nlarge genuine accountant-client dialogues, Kuaiji exhibits exceptional accuracy\nand response speed. Our contributions encompass the creation of the first\nChinese accounting dataset, the establishment of Kuaiji as a leading\nopen-source Chinese accounting LLM, and the validation of its efficacy through\nreal-world accounting scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "version 2.0",
    "pdf_url": "http://arxiv.org/pdf/2402.13866v2",
    "published_date": "2024-02-21 15:14:20 UTC",
    "updated_date": "2024-02-24 07:03:44 UTC"
  },
  {
    "arxiv_id": "2402.14872v2",
    "title": "Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs",
    "authors": [
      "Xiaoxia Li",
      "Siyuan Liang",
      "Jiyi Zhang",
      "Han Fang",
      "Aishan Liu",
      "Ee-Chien Chang"
    ],
    "abstract": "Large Language Models (LLMs), used in creative writing, code generation, and\ntranslation, generate text based on input sequences but are vulnerable to\njailbreak attacks, where crafted prompts induce harmful outputs. Most jailbreak\nprompt methods use a combination of jailbreak templates followed by questions\nto ask to create jailbreak prompts. However, existing jailbreak prompt designs\ngenerally suffer from excessive semantic differences, resulting in an inability\nto resist defenses that use simple semantic metrics as thresholds. Jailbreak\nprompts are semantically more varied than the original questions used for\nqueries. In this paper, we introduce a Semantic Mirror Jailbreak (SMJ) approach\nthat bypasses LLMs by generating jailbreak prompts that are semantically\nsimilar to the original question. We model the search for jailbreak prompts\nthat satisfy both semantic similarity and jailbreak validity as a\nmulti-objective optimization problem and employ a standardized set of genetic\nalgorithms for generating eligible prompts. Compared to the baseline\nAutoDAN-GA, SMJ achieves attack success rates (ASR) that are at most 35.4%\nhigher without ONION defense and 85.2% higher with ONION defense. SMJ's better\nperformance in all three semantic meaningfulness metrics of Jailbreak Prompt,\nSimilarity, and Outlier, also means that SMJ is resistant to defenses that use\nthose metrics as thresholds.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14872v2",
    "published_date": "2024-02-21 15:13:50 UTC",
    "updated_date": "2024-02-27 13:49:22 UTC"
  },
  {
    "arxiv_id": "2402.13853v2",
    "title": "RealDex: Towards Human-like Grasping for Robotic Dexterous Hand",
    "authors": [
      "Yumeng Liu",
      "Yaxun Yang",
      "Youzhuo Wang",
      "Xiaofei Wu",
      "Jiamin Wang",
      "Yichen Yao",
      "Sören Schwertfeger",
      "Sibei Yang",
      "Wenping Wang",
      "Jingyi Yu",
      "Xuming He",
      "Yuexin Ma"
    ],
    "abstract": "In this paper, we introduce RealDex, a pioneering dataset capturing authentic\ndexterous hand grasping motions infused with human behavioral patterns,\nenriched by multi-view and multimodal visual data. Utilizing a teleoperation\nsystem, we seamlessly synchronize human-robot hand poses in real time. This\ncollection of human-like motions is crucial for training dexterous hands to\nmimic human movements more naturally and precisely. RealDex holds immense\npromise in advancing humanoid robot for automated perception, cognition, and\nmanipulation in real-world scenarios. Moreover, we introduce a cutting-edge\ndexterous grasping motion generation framework, which aligns with human\nexperience and enhances real-world applicability through effectively utilizing\nMultimodal Large Language Models. Extensive experiments have demonstrated the\nsuperior performance of our method on RealDex and other open datasets. The\ncomplete dataset and code will be made available upon the publication of this\nwork.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Page: https://4dvlab.github.io/RealDex_page/",
    "pdf_url": "http://arxiv.org/pdf/2402.13853v2",
    "published_date": "2024-02-21 14:59:46 UTC",
    "updated_date": "2024-12-07 04:38:21 UTC"
  },
  {
    "arxiv_id": "2402.13852v3",
    "title": "Neural Control System for Continuous Glucose Monitoring and Maintenance",
    "authors": [
      "Azmine Toushik Wasi"
    ],
    "abstract": "Precise glucose level monitoring is critical for people with diabetes to\navoid serious complications. While there are several methods for continuous\nglucose level monitoring, research on maintenance devices is limited. To\nmitigate the gap, we provide a novel neural control system for continuous\nglucose monitoring and management that uses differential predictive control.\nOur approach, led by a sophisticated neural policy and differentiable modeling,\nconstantly adjusts insulin supply in real-time, thereby improving glucose level\noptimization in the body. This end-to-end method maximizes efficiency,\nproviding personalized care and improved health outcomes, as confirmed by\nempirical evidence. Code and data are available at:\n\\url{https://github.com/azminewasi/NeuralCGMM}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "9 Pages, 4 figures, ICLR 2024 Tiny Papers Track\n  https://openreview.net/forum?id=Te4P3Cn54g",
    "pdf_url": "http://arxiv.org/pdf/2402.13852v3",
    "published_date": "2024-02-21 14:56:36 UTC",
    "updated_date": "2024-06-07 11:16:12 UTC"
  },
  {
    "arxiv_id": "2402.13846v2",
    "title": "Large Language Models are Advanced Anonymizers",
    "authors": [
      "Robin Staab",
      "Mark Vero",
      "Mislav Balunović",
      "Martin Vechev"
    ],
    "abstract": "Recent privacy research on large language models (LLMs) has shown that they\nachieve near-human-level performance at inferring personal data from online\ntexts. With ever-increasing model capabilities, existing text anonymization\nmethods are currently lacking behind regulatory requirements and adversarial\nthreats. In this work, we take two steps to bridge this gap: First, we present\na new setting for evaluating anonymization in the face of adversarial LLM\ninferences, allowing for a natural measurement of anonymization performance\nwhile remedying some of the shortcomings of previous metrics. Then, within this\nsetting, we develop a novel LLM-based adversarial anonymization framework\nleveraging the strong inferential capabilities of LLMs to inform our\nanonymization procedure. We conduct a comprehensive experimental evaluation of\nadversarial anonymization across 13 LLMs on real-world and synthetic online\ntexts, comparing it against multiple baselines and industry-grade anonymizers.\nOur evaluation shows that adversarial anonymization outperforms current\ncommercial anonymizers both in terms of the resulting utility and privacy. We\nsupport our findings with a human study (n=50) highlighting a strong and\nconsistent human preference for LLM-anonymized texts.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "International Conference on Learning Representations (ICLR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.13846v2",
    "published_date": "2024-02-21 14:44:00 UTC",
    "updated_date": "2025-02-03 16:03:13 UTC"
  },
  {
    "arxiv_id": "2402.13840v2",
    "title": "Multi-view Intent Learning and Alignment with Large Language Models for Session-based Recommendation",
    "authors": [
      "Shutong Qiao",
      "Wei Zhou",
      "Junhao Wen",
      "Chen Gao",
      "Qun Luo",
      "Peixuan Chen",
      "Yong Li"
    ],
    "abstract": "Session-based recommendation (SBR) methods often rely on user behavior data,\nwhich can struggle with the sparsity of session data, limiting performance.\nResearchers have identified that beyond behavioral signals, rich semantic\ninformation in item descriptions is crucial for capturing hidden user intent.\nWhile large language models (LLMs) offer new ways to leverage this semantic\ndata, the challenges of session anonymity, short-sequence nature, and high LLM\ntraining costs have hindered the development of a lightweight, efficient LLM\nframework for SBR.\n  To address the above challenges, we propose an LLM-enhanced SBR framework\nthat integrates semantic and behavioral signals from multiple views. This\ntwo-stage framework leverages the strengths of both LLMs and traditional SBR\nmodels while minimizing training costs. In the first stage, we use multi-view\nprompts to infer latent user intentions at the session semantic level,\nsupported by an intent localization module to alleviate LLM hallucinations. In\nthe second stage, we align and unify these semantic inferences with behavioral\nrepresentations, effectively merging insights from both large and small models.\nExtensive experiments on two real datasets demonstrate that the LLM4SBR\nframework can effectively improve model performance. We release our codes along\nwith the baselines at https://github.com/tsinghua-fib-lab/LLM4SBR.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13840v2",
    "published_date": "2024-02-21 14:38:02 UTC",
    "updated_date": "2025-04-14 02:13:08 UTC"
  },
  {
    "arxiv_id": "2402.13820v1",
    "title": "FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning",
    "authors": [
      "Chenhao Li",
      "Elijah Stanger-Jones",
      "Steve Heim",
      "Sangbae Kim"
    ],
    "abstract": "Motion trajectories offer reliable references for physics-based motion\nlearning but suffer from sparsity, particularly in regions that lack sufficient\ndata coverage. To address this challenge, we introduce a self-supervised,\nstructured representation and generation method that extracts spatial-temporal\nrelationships in periodic or quasi-periodic motions. The motion dynamics in a\ncontinuously parameterized latent space enable our method to enhance the\ninterpolation and generalization capabilities of motion learning algorithms.\nThe motion learning controller, informed by the motion parameterization,\noperates online tracking of a wide range of motions, including targets unseen\nduring training. With a fallback mechanism, the controller dynamically adapts\nits tracking strategy and automatically resorts to safe action execution when a\npotentially risky target is proposed. By leveraging the identified\nspatial-temporal structure, our work opens new possibilities for future\nadvancements in general motion representation and learning algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13820v1",
    "published_date": "2024-02-21 13:59:21 UTC",
    "updated_date": "2024-02-21 13:59:21 UTC"
  },
  {
    "arxiv_id": "2402.14871v1",
    "title": "LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain",
    "authors": [
      "Emanuele Musumeci",
      "Michele Brienza",
      "Vincenzo Suriani",
      "Daniele Nardi",
      "Domenico Daniele Bloisi"
    ],
    "abstract": "In the last years' digitalization process, the creation and management of\ndocuments in various domains, particularly in Public Administration (PA), have\nbecome increasingly complex and diverse. This complexity arises from the need\nto handle a wide range of document types, often characterized by\nsemi-structured forms. Semi-structured documents present a fixed set of data\nwithout a fixed format. As a consequence, a template-based solution cannot be\nused, as understanding a document requires the extraction of the data\nstructure. The recent introduction of Large Language Models (LLMs) has enabled\nthe creation of customized text output satisfying user requests. In this work,\nwe propose a novel approach that combines the LLMs with prompt engineering and\nmulti-agent systems for generating new documents compliant with a desired\nstructure. The main contribution of this work concerns replacing the commonly\nused manual prompting with a task description generated by semantic retrieval\nfrom an LLM. The potential of this approach is demonstrated through a series of\nexperiments and case studies, showcasing its effectiveness in real-world PA\nscenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at HCI INTERNATIONAL 2024 - 26th International Conference on\n  Human-Computer Interaction. Washington Hilton Hotel, Washington DC, USA, 29\n  June - 4 July 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14871v1",
    "published_date": "2024-02-21 13:54:53 UTC",
    "updated_date": "2024-02-21 13:54:53 UTC"
  },
  {
    "arxiv_id": "2402.13809v3",
    "title": "NeuralDiffuser: Neuroscience-inspired Diffusion Guidance for fMRI Visual Reconstruction",
    "authors": [
      "Haoyu Li",
      "Hao Wu",
      "Badong Chen"
    ],
    "abstract": "Reconstructing visual stimuli from functional Magnetic Resonance Imaging fMRI\nenables fine-grained retrieval of brain activity. However, the accurate\nreconstruction of diverse details, including structure, background, texture,\ncolor, and more, remains challenging. The stable diffusion models inevitably\nresult in the variability of reconstructed images, even under identical\nconditions. To address this challenge, we first uncover the neuroscientific\nperspective of diffusion methods, which primarily involve top-down creation\nusing pre-trained knowledge from extensive image datasets, but tend to lack\ndetail-driven bottom-up perception, leading to a loss of faithful details. In\nthis paper, we propose NeuralDiffuser, which incorporates primary visual\nfeature guidance to provide detailed cues in the form of gradients. This\nextension of the bottom-up process for diffusion models achieves both semantic\ncoherence and detail fidelity when reconstructing visual stimuli. Furthermore,\nwe have developed a novel guidance strategy for reconstruction tasks that\nensures the consistency of repeated outputs with original images rather than\nwith various outputs. Extensive experimental results on the Natural Senses\nDataset (NSD) qualitatively and quantitatively demonstrate the advancement of\nNeuralDiffuser by comparing it against baseline and state-of-the-art methods\nhorizontally, as well as conducting longitudinal ablation studies.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13809v3",
    "published_date": "2024-02-21 13:46:25 UTC",
    "updated_date": "2025-01-08 14:21:46 UTC"
  },
  {
    "arxiv_id": "2402.13785v2",
    "title": "Composing Reinforcement Learning Policies, with Formal Guarantees",
    "authors": [
      "Florent Delgrange",
      "Guy Avni",
      "Anna Lukina",
      "Christian Schilling",
      "Ann Nowé",
      "Guillermo A. Pérez"
    ],
    "abstract": "We propose a novel framework to controller design in environments with a\ntwo-level structure: a known high-level graph (\"map\") in which each vertex is\npopulated by a Markov decision process, called a \"room\". The framework\n\"separates concerns\" by using different design techniques for low- and\nhigh-level tasks. We apply reactive synthesis for high-level tasks: given a\nspecification as a logical formula over the high-level graph and a collection\nof low-level policies obtained together with \"concise\" latent structures, we\nconstruct a \"planner\" that selects which low-level policy to apply in each\nroom. We develop a reinforcement learning procedure to train low-level policies\non latent structures, which unlike previous approaches, circumvents a model\ndistillation step. We pair the policy with probably approximately correct\nguarantees on its performance and on the abstraction quality, and lift these\nguarantees to the high-level task. These formal guarantees are the main\nadvantage of the framework. Other advantages include scalability (rooms are\nlarge and their dynamics are unknown) and reusability of low-level policies. We\ndemonstrate feasibility in challenging case studies where an agent navigates\nenvironments with moving obstacles and visual inputs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "AAMAS 2025, 8 pages main text, 19 pages Appendix (excluding\n  references)",
    "pdf_url": "http://arxiv.org/pdf/2402.13785v2",
    "published_date": "2024-02-21 13:10:58 UTC",
    "updated_date": "2025-03-10 11:38:38 UTC"
  },
  {
    "arxiv_id": "2402.13782v1",
    "title": "Semirings for Probabilistic and Neuro-Symbolic Logic Programming",
    "authors": [
      "Vincent Derkinderen",
      "Robin Manhaeve",
      "Pedro Zuidberg Dos Martires",
      "Luc De Raedt"
    ],
    "abstract": "The field of probabilistic logic programming (PLP) focuses on integrating\nprobabilistic models into programming languages based on logic. Over the past\n30 years, numerous languages and frameworks have been developed for modeling,\ninference and learning in probabilistic logic programs. While originally PLP\nfocused on discrete probability, more recent approaches have incorporated\ncontinuous distributions as well as neural networks, effectively yielding\nneural-symbolic methods. We provide a unified algebraic perspective on PLP,\nshowing that many if not most of the extensions of PLP can be cast within a\ncommon algebraic logic programming framework, in which facts are labeled with\nelements of a semiring and disjunction and conjunction are replaced by addition\nand multiplication. This does not only hold for the PLP variations itself but\nalso for the underlying execution mechanism that is based on (algebraic) model\ncounting.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13782v1",
    "published_date": "2024-02-21 13:06:52 UTC",
    "updated_date": "2024-02-21 13:06:52 UTC"
  },
  {
    "arxiv_id": "2402.13779v1",
    "title": "Contextual Molecule Representation Learning from Chemical Reaction Knowledge",
    "authors": [
      "Han Tang",
      "Shikun Feng",
      "Bicheng Lin",
      "Yuyan Ni",
      "JIngjing Liu",
      "Wei-Ying Ma",
      "Yanyan Lan"
    ],
    "abstract": "In recent years, self-supervised learning has emerged as a powerful tool to\nharness abundant unlabelled data for representation learning and has been\nbroadly adopted in diverse areas. However, when applied to molecular\nrepresentation learning (MRL), prevailing techniques such as masked sub-unit\nreconstruction often fall short, due to the high degree of freedom in the\npossible combinations of atoms within molecules, which brings insurmountable\ncomplexity to the masking-reconstruction paradigm. To tackle this challenge, we\nintroduce REMO, a self-supervised learning framework that takes advantage of\nwell-defined atom-combination rules in common chemistry. Specifically, REMO\npre-trains graph/Transformer encoders on 1.7 million known chemical reactions\nin the literature. We propose two pre-training objectives: Masked Reaction\nCentre Reconstruction (MRCR) and Reaction Centre Identification (RCI). REMO\noffers a novel solution to MRL by exploiting the underlying shared patterns in\nchemical reactions as \\textit{context} for pre-training, which effectively\ninfers meaningful representations of common chemistry knowledge. Such\ncontextual representations can then be utilized to support diverse downstream\nmolecular tasks with minimum finetuning, such as affinity prediction and\ndrug-drug interaction prediction. Extensive experimental results on\nMoleculeACE, ACNet, drug-drug interaction (DDI), and reaction type\nclassification show that across all tested downstream tasks, REMO outperforms\nthe standard baseline of single-molecule masked modeling used in current MRL.\nRemarkably, REMO is the pioneering deep learning model surpassing\nfingerprint-based methods in activity cliff benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2402.13779v1",
    "published_date": "2024-02-21 12:58:40 UTC",
    "updated_date": "2024-02-21 12:58:40 UTC"
  },
  {
    "arxiv_id": "2402.13777v5",
    "title": "Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions",
    "authors": [
      "Jiayu Chen",
      "Bhargav Ganguly",
      "Yang Xu",
      "Yongsheng Mei",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "abstract": "Deep generative models (DGMs) have demonstrated great success across various\ndomains, particularly in generating texts, images, and videos using models\ntrained from offline data. Similarly, data-driven decision-making and robotic\ncontrol also necessitate learning a generator function from the offline data to\nserve as the strategy or policy. In this case, applying deep generative models\nin offline policy learning exhibits great potential, and numerous studies have\nexplored in this direction. However, this field still lacks a comprehensive\nreview and so developments of different branches are relatively independent. In\nthis paper, we provide the first systematic review on the applications of deep\ngenerative models for offline policy learning. In particular, we cover five\nmainstream deep generative models, including Variational Auto-Encoders,\nGenerative Adversarial Networks, Normalizing Flows, Transformers, and Diffusion\nModels, and their applications in both offline reinforcement learning (offline\nRL) and imitation learning (IL). Offline RL and IL are two main branches of\noffline policy learning and are widely-adopted techniques for sequential\ndecision-making. Notably, for each type of DGM-based offline policy learning,\nwe distill its fundamental scheme, categorize related works based on the usage\nof the DGM, and sort out the development process of algorithms in that field.\nSubsequent to the main content, we provide in-depth discussions on deep\ngenerative models and offline policy learning as a summary, based on which we\npresent our perspectives on future research directions. This work offers a\nhands-on reference for the research progress in deep generative models for\noffline policy learning, and aims to inspire improved DGM-based offline RL or\nIL algorithms. For convenience, we maintain a paper list on\nhttps://github.com/LucasCJYSDL/DGMs-for-Offline-Policy-Learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "We restructured the paper and added more discussion",
    "pdf_url": "http://arxiv.org/pdf/2402.13777v5",
    "published_date": "2024-02-21 12:54:48 UTC",
    "updated_date": "2024-05-26 00:23:47 UTC"
  },
  {
    "arxiv_id": "2402.13771v1",
    "title": "Mask-up: Investigating Biases in Face Re-identification for Masked Faces",
    "authors": [
      "Siddharth D Jaiswal",
      "Ankit Kr. Verma",
      "Animesh Mukherjee"
    ],
    "abstract": "AI based Face Recognition Systems (FRSs) are now widely distributed and\ndeployed as MLaaS solutions all over the world, moreso since the COVID-19\npandemic for tasks ranging from validating individuals' faces while buying SIM\ncards to surveillance of citizens. Extensive biases have been reported against\nmarginalized groups in these systems and have led to highly discriminatory\noutcomes. The post-pandemic world has normalized wearing face masks but FRSs\nhave not kept up with the changing times. As a result, these systems are\nsusceptible to mask based face occlusion. In this study, we audit four\ncommercial and nine open-source FRSs for the task of face re-identification\nbetween different varieties of masked and unmasked images across five benchmark\ndatasets (total 14,722 images). These simulate a realistic\nvalidation/surveillance task as deployed in all major countries around the\nworld. Three of the commercial and five of the open-source FRSs are highly\ninaccurate; they further perpetuate biases against non-White individuals, with\nthe lowest accuracy being 0%. A survey for the same task with 85 human\nparticipants also results in a low accuracy of 40%. Thus a human-in-the-loop\nmoderation in the pipeline does not alleviate the concerns, as has been\nfrequently hypothesized in literature. Our large-scale study shows that\ndevelopers, lawmakers and users of such services need to rethink the design\nprinciples behind FRSs, especially for the task of face re-identification,\ntaking cognizance of observed biases.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2402.13771v1",
    "published_date": "2024-02-21 12:48:45 UTC",
    "updated_date": "2024-02-21 12:48:45 UTC"
  },
  {
    "arxiv_id": "2402.13764v5",
    "title": "CriticEval: Evaluating Large Language Model as Critic",
    "authors": [
      "Tian Lan",
      "Wenwei Zhang",
      "Chen Xu",
      "Heyan Huang",
      "Dahua Lin",
      "Kai Chen",
      "Xian-ling Mao"
    ],
    "abstract": "Critique ability, i.e., the capability of Large Language Models (LLMs) to\nidentify and rectify flaws in responses, is crucial for their applications in\nself-improvement and scalable oversight. While numerous studies have been\nproposed to evaluate critique ability of LLMs, their comprehensiveness and\nreliability are still limited. To overcome this problem, we introduce\nCriticEval, a novel benchmark designed to comprehensively and reliably evaluate\ncritique ability of LLMs. Specifically, to ensure the comprehensiveness,\nCriticEval evaluates critique ability from four dimensions across nine diverse\ntask scenarios. It evaluates both scalar-valued and textual critiques,\ntargeting responses of varying quality. To ensure the reliability, a large\nnumber of critiques are annotated to serve as references, enabling GPT-4 to\nevaluate textual critiques reliably. Extensive evaluations of open-source and\nclosed-source LLMs first validate the reliability of evaluation in CriticEval.\nThen, experimental results demonstrate the promising potential of open-source\nLLMs, the effectiveness of critique datasets and several intriguing\nrelationships between the critique ability and some critical factors, including\ntask types, response qualities and critique dimensions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13764v5",
    "published_date": "2024-02-21 12:38:59 UTC",
    "updated_date": "2024-10-20 05:32:25 UTC"
  },
  {
    "arxiv_id": "2402.13754v4",
    "title": "Reinforcement learning-assisted quantum architecture search for variational quantum algorithms",
    "authors": [
      "Akash Kundu"
    ],
    "abstract": "A significant hurdle in the noisy intermediate-scale quantum (NISQ) era is\nidentifying functional quantum circuits. These circuits must also adhere to the\nconstraints imposed by current quantum hardware limitations. Variational\nquantum algorithms (VQAs), a class of quantum-classical optimization\nalgorithms, were developed to address these challenges in the currently\navailable quantum devices. However, the overall performance of VQAs depends on\nthe initialization strategy of the variational circuit, the structure of the\ncircuit (also known as ansatz), and the configuration of the cost function.\nFocusing on the structure of the circuit, in this thesis, we improve the\nperformance of VQAs by automating the search for an optimal structure for the\nvariational circuits using reinforcement learning (RL). Within the thesis, the\noptimality of a circuit is determined by evaluating its depth, the overall\ncount of gates and parameters, and its accuracy in solving the given problem.\nThe task of automating the search for optimal quantum circuits is known as\nquantum architecture search (QAS). The majority of research in QAS is primarily\nfocused on a noiseless scenario. Yet, the impact of noise on the QAS remains\ninadequately explored. In this thesis, we tackle the issue by introducing a\ntensor-based quantum circuit encoding, restrictions on environment dynamics to\nexplore the search space of possible circuits efficiently, an episode halting\nscheme to steer the agent to find shorter circuits, a double deep Q-network\n(DDQN) with an $\\epsilon$-greedy policy for better stability. The numerical\nexperiments on noiseless and noisy quantum hardware show that in dealing with\nvarious VQAs, our RL-based QAS outperforms existing QAS. Meanwhile, the methods\nwe propose in the thesis can be readily adapted to address a wide range of\nother VQAs.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "With many pages, figures and tables, I, Akash Kundu upload the final\n  version of my thesis! Including reviewers response and a kind of brief\n  overview of recent quantum architecture search methods",
    "pdf_url": "http://arxiv.org/pdf/2402.13754v4",
    "published_date": "2024-02-21 12:30:39 UTC",
    "updated_date": "2024-10-01 19:58:40 UTC"
  },
  {
    "arxiv_id": "2402.13752v1",
    "title": "AI-Powered Predictions for Electricity Load in Prosumer Communities",
    "authors": [
      "Aleksei Kychkin",
      "Georgios C. Chasparis"
    ],
    "abstract": "The flexibility in electricity consumption and production in communities of\nresidential buildings, including those with renewable energy sources and energy\nstorage (a.k.a., prosumers), can effectively be utilized through the\nadvancement of short-term demand response mechanisms. It is known that\nflexibility can further be increased if demand response is performed at the\nlevel of communities of prosumers, since aggregated groups can better\ncoordinate electricity consumption. However, the effectiveness of such\nshort-term optimization is highly dependent on the accuracy of electricity load\nforecasts both for each building as well as for the whole community. Structural\nvariations in the electricity load profile can be associated with different\nexogenous factors, such as weather conditions, calendar information and day of\nthe week, as well as user behavior. In this paper, we review a wide range of\nelectricity load forecasting techniques, that can provide significant\nassistance in optimizing load consumption in prosumer communities. We present\nand test artificial intelligence (AI) powered short-term load forecasting\nmethodologies that operate with black-box time series models, such as\nFacebook's Prophet and Long Short-term Memory (LSTM) models; season-based\nSARIMA and smoothing Holt-Winters models; and empirical regression-based models\nthat utilize domain knowledge. The integration of weather forecasts into\ndata-driven time series forecasts is also tested. Results show that the\ncombination of persistent and regression terms (adapted to the load forecasting\ntask) achieves the best forecast accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "It has been presented in the 18. Symposium Energieinnovation\n  (14.-16.02.2024). Further information can be found at:\n  https://www.tugraz.at/events/eninnov2024/home",
    "pdf_url": "http://arxiv.org/pdf/2402.13752v1",
    "published_date": "2024-02-21 12:23:09 UTC",
    "updated_date": "2024-02-21 12:23:09 UTC"
  },
  {
    "arxiv_id": "2402.13750v1",
    "title": "Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph",
    "authors": [
      "Qian Zhao",
      "Hao Qian",
      "Ziqi Liu",
      "Gong-Duo Zhang",
      "Lihong Gu"
    ],
    "abstract": "Recommendation systems are widely used in e-commerce websites and online\nplatforms to address information overload. However, existing systems primarily\nrely on historical data and user feedback, making it difficult to capture user\nintent transitions. Recently, Knowledge Base (KB)-based models are proposed to\nincorporate expert knowledge, but it struggle to adapt to new items and the\nevolving e-commerce environment. To address these challenges, we propose a\nnovel Large Language Model based Complementary Knowledge Enhanced\nRecommendation System (LLM-KERec). It introduces an entity extractor that\nextracts unified concept terms from item and user information. To provide\ncost-effective and reliable prior knowledge, entity pairs are generated based\non entity popularity and specific strategies. The large language model\ndetermines complementary relationships in each entity pair, constructing a\ncomplementary knowledge graph. Furthermore, a new complementary recall module\nand an Entity-Entity-Item (E-E-I) weight decision model refine the scoring of\nthe ranking model using real complementary exposure-click samples. Extensive\nexperiments conducted on three industry datasets demonstrate the significant\nperformance improvement of our model compared to existing approaches.\nAdditionally, detailed analysis shows that LLM-KERec enhances users' enthusiasm\nfor consumption by recommending complementary items. In summary, LLM-KERec\naddresses the limitations of traditional recommendation systems by\nincorporating complementary knowledge and utilizing a large language model to\ncapture user intent transitions, adapt to new items, and enhance recommendation\nefficiency in the evolving e-commerce landscape.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13750v1",
    "published_date": "2024-02-21 12:22:01 UTC",
    "updated_date": "2024-02-21 12:22:01 UTC"
  },
  {
    "arxiv_id": "2403.14642v1",
    "title": "Revolutionising Distance Learning: A Comparative Study of Learning Progress with AI-Driven Tutoring",
    "authors": [
      "Moritz Möller",
      "Gargi Nirmal",
      "Dario Fabietti",
      "Quintus Stierstorfer",
      "Mark Zakhvatkin",
      "Holger Sommerfeld",
      "Sven Schütt"
    ],
    "abstract": "Generative AI is expected to have a vast, positive impact on education;\nhowever, at present, this potential has not yet been demonstrated at scale at\nuniversity level. In this study, we present first evidence that generative AI\ncan increase the speed of learning substantially in university students. We\ntested whether using the AI-powered teaching assistant Syntea affected the\nspeed of learning of hundreds of distance learning students across more than 40\ncourses at the IU International University of Applied Sciences. Our analysis\nsuggests that using Syntea reduced their study time substantially--by about\n27\\% on average--in the third month after the release of Syntea. Taken\ntogether, the magnitude of the effect and the scalability of the approach\nimplicate generative AI as a key lever to significantly improve and accelerate\nlearning by personalisation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14642v1",
    "published_date": "2024-02-21 12:15:58 UTC",
    "updated_date": "2024-02-21 12:15:58 UTC"
  },
  {
    "arxiv_id": "2402.13741v1",
    "title": "Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction",
    "authors": [
      "Guozheng Li",
      "Wenjun Ke",
      "Peng Wang",
      "Zijie Xu",
      "Ke Ji",
      "Jiajun Liu",
      "Ziyu Shang",
      "Qiqing Luo"
    ],
    "abstract": "The in-context learning (ICL) for relational triple extraction (RTE) has\nachieved promising performance, but still encounters two key challenges: (1)\nhow to design effective prompts and (2) how to select proper demonstrations.\nExisting methods, however, fail to address these challenges appropriately. On\nthe one hand, they usually recast RTE task to text-to-text prompting formats,\nwhich is unnatural and results in a mismatch between the output format at the\npre-training time and the inference time for large language models (LLMs). On\nthe other hand, they only utilize surface natural language features and lack\nconsideration of triple semantics in sample selection. These issues are\nblocking improved performance in ICL for RTE, thus we aim to tackle prompt\ndesigning and sample selection challenges simultaneously. To this end, we\ndevise a tabular prompting for RTE (\\textsc{TableIE}) which frames RTE task\ninto a table generation task to incorporate explicit structured information\ninto ICL, facilitating conversion of outputs to RTE structures. Then we propose\ninstructive in-context learning (I$^2$CL) which only selects and annotates a\nfew samples considering internal triple semantics in massive unlabeled samples.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13741v1",
    "published_date": "2024-02-21 12:12:16 UTC",
    "updated_date": "2024-02-21 12:12:16 UTC"
  },
  {
    "arxiv_id": "2402.13731v2",
    "title": "Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models",
    "authors": [
      "Yuheng Chen",
      "Pengfei Cao",
      "Yubo Chen",
      "Yining Wang",
      "Shengping Liu",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "Large language models (LLMs) store extensive factual knowledge, but the\nunderlying mechanisms remain unclear. Previous research suggests that factual\nknowledge is stored within multi-layer perceptron weights, and some storage\nunits exhibit degeneracy, referred to as Degenerate Knowledge Neurons (DKNs).\nDespite the novelty and unique properties of this concept, it has not been\nrigorously defined or systematically studied. We first consider the connection\nweight patterns of MLP neurons and define DKNs from both structural and\nfunctional aspects. Based on this, we introduce the Neurological Topology\nClustering method, which allows the formation of DKNs in any numbers and\nstructures, leading to a more accurate DKN acquisition. Furthermore, inspired\nby cognitive science, we explore the relationship between DKNs and the\nrobustness, evolvability, and complexity of LLMs. Our execution of 34\nexperiments under 6 settings demonstrates the connection between DKNs and these\nthree properties. The code will be available soon.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13731v2",
    "published_date": "2024-02-21 11:50:32 UTC",
    "updated_date": "2024-06-17 03:44:10 UTC"
  },
  {
    "arxiv_id": "2402.14867v1",
    "title": "Effects of term weighting approach with and without stop words removing on Arabic text classification",
    "authors": [
      "Esra'a Alhenawi",
      "Ruba Abu Khurma",
      "Pedro A. Castillo",
      "Maribel G. Arenas"
    ],
    "abstract": "Classifying text is a method for categorizing documents into pre-established\ngroups. Text documents must be prepared and represented in a way that is\nappropriate for the algorithms used for data mining prior to classification. As\na result, a number of term weighting strategies have been created in the\nliterature to enhance text categorization algorithms' functionality. This study\ncompares the effects of Binary and Term frequency weighting feature\nmethodologies on the text's classification method when stop words are\neliminated once and when they are not. In recognition of assessing the effects\nof prior weighting of features approaches on classification results in terms of\naccuracy, recall, precision, and F-measure values, we used an Arabic data set\nmade up of 322 documents divided into six main topics (agriculture, economy,\nhealth, politics, science, and sport), each of which contains 50 documents,\nwith the exception of the health category, which contains 61 documents. The\nresults demonstrate that for all metrics, the term frequency feature weighting\napproach with stop word removal outperforms the binary approach, while for\naccuracy, recall, and F-Measure, the binary approach outperforms the TF\napproach without stop word removal. However, for precision, the two approaches\nproduce results that are very similar. Additionally, it is clear from the data\nthat, using the same phrase weighting approach, stop word removing increases\nclassification accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14867v1",
    "published_date": "2024-02-21 11:31:04 UTC",
    "updated_date": "2024-02-21 11:31:04 UTC"
  },
  {
    "arxiv_id": "2402.14044v1",
    "title": "A new approach for solving global optimization and engineering problems based on modified Sea Horse Optimizer",
    "authors": [
      "Fatma A. Hashim",
      "Reham R. Mostafa",
      "Ruba Abu Khurma",
      "Raneem Qaddoura",
      "P. A. Castillo"
    ],
    "abstract": "Sea Horse Optimizer (SHO) is a noteworthy metaheuristic algorithm that\nemulates various intelligent behaviors exhibited by sea horses, encompassing\nfeeding patterns, male reproductive strategies, and intricate movement\npatterns. To mimic the nuanced locomotion of sea horses, SHO integrates the\nlogarithmic helical equation and Levy flight, effectively incorporating both\nrandom movements with substantial step sizes and refined local exploitation.\nAdditionally, the utilization of Brownian motion facilitates a more\ncomprehensive exploration of the search space. This study introduces a robust\nand high-performance variant of the SHO algorithm named mSHO. The enhancement\nprimarily focuses on bolstering SHO's exploitation capabilities by replacing\nits original method with an innovative local search strategy encompassing three\ndistinct steps: a neighborhood-based local search, a global non-neighbor-based\nsearch, and a method involving circumnavigation of the existing search region.\nThese techniques improve mSHO algorithm's search capabilities, allowing it to\nnavigate the search space and converge toward optimal solutions efficiently.\nThe comprehensive results distinctly establish the supremacy and efficiency of\nthe mSHO method as an exemplary tool for tackling an array of optimization\nquandaries. The results show that the proposed mSHO algorithm has a total rank\nof 1 for CEC'2020 test functions. In contrast, the mSHO achieved the best value\nfor the engineering problems, recording a value of 0.012665, 2993.634, 0.01266,\n1.724967, 263.8915, 0.032255, 58507.14, 1.339956, and 0.23524 for the pressure\nvessel design, speed reducer design, tension/compression spring, welded beam\ndesign, three-bar truss engineering design, industrial refrigeration system,\nmulti-Product batch plant, cantilever beam problem, multiple disc clutch brake\nproblems, respectively.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14044v1",
    "published_date": "2024-02-21 11:28:00 UTC",
    "updated_date": "2024-02-21 11:28:00 UTC"
  },
  {
    "arxiv_id": "2402.13714v1",
    "title": "An Evaluation of Large Language Models in Bioinformatics Research",
    "authors": [
      "Hengchuang Yin",
      "Zhonghui Gu",
      "Fanhao Wang",
      "Yiparemu Abuduhaibaier",
      "Yanqiao Zhu",
      "Xinming Tu",
      "Xian-Sheng Hua",
      "Xiao Luo",
      "Yizhou Sun"
    ],
    "abstract": "Large language models (LLMs) such as ChatGPT have gained considerable\ninterest across diverse research communities. Their notable ability for text\ncompletion and generation has inaugurated a novel paradigm for\nlanguage-interfaced problem solving. However, the potential and efficacy of\nthese models in bioinformatics remain incompletely explored. In this work, we\nstudy the performance LLMs on a wide spectrum of crucial bioinformatics tasks.\nThese tasks include the identification of potential coding regions, extraction\nof named entities for genes and proteins, detection of antimicrobial and\nanti-cancer peptides, molecular optimization, and resolution of educational\nbioinformatics problems. Our findings indicate that, given appropriate prompts,\nLLMs like GPT variants can successfully handle most of these tasks. In\naddition, we provide a thorough analysis of their limitations in the context of\ncomplicated bioinformatics tasks. In conclusion, we believe that this work can\nprovide new perspectives and motivate future research in the field of LLMs\napplications, AI for Science and bioinformatics.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2402.13714v1",
    "published_date": "2024-02-21 11:27:31 UTC",
    "updated_date": "2024-02-21 11:27:31 UTC"
  },
  {
    "arxiv_id": "2402.13711v4",
    "title": "DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning",
    "authors": [
      "Seungyoon Choi",
      "Wonjoong Kim",
      "Sungwon Kim",
      "Yeonjun In",
      "Sein Kim",
      "Chanyoung Park"
    ],
    "abstract": "We investigate the replay buffer in rehearsal-based approaches for graph\ncontinual learning (GCL) methods. Existing rehearsal-based GCL methods select\nthe most representative nodes for each class and store them in a replay buffer\nfor later use in training subsequent tasks. However, we discovered that\nconsidering only the class representativeness of each replayed node makes the\nreplayed nodes to be concentrated around the center of each class, incurring a\npotential risk of overfitting to nodes residing in those regions, which\naggravates catastrophic forgetting. Moreover, as the rehearsal-based approach\nheavily relies on a few replayed nodes to retain knowledge obtained from\nprevious tasks, involving the replayed nodes that have irrelevant neighbors in\nthe model training may have a significant detrimental impact on model\nperformance. In this paper, we propose a GCL model named DSLR, specifically, we\ndevise a coverage-based diversity (CD) approach to consider both the class\nrepresentativeness and the diversity within each class of the replayed nodes.\nMoreover, we adopt graph structure learning (GSL) to ensure that the replayed\nnodes are connected to truly informative neighbors. Extensive experimental\nresults demonstrate the effectiveness and efficiency of DSLR. Our source code\nis available at https://github.com/seungyoon-Choi/DSLR_official.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ACM TheWebConf 2024 (WWW 2024) (Oral presentation)",
    "pdf_url": "http://arxiv.org/pdf/2402.13711v4",
    "published_date": "2024-02-21 11:25:54 UTC",
    "updated_date": "2024-03-03 08:01:54 UTC"
  },
  {
    "arxiv_id": "2402.13709v2",
    "title": "SaGE: Evaluating Moral Consistency in Large Language Models",
    "authors": [
      "Vamshi Krishna Bonagiri",
      "Sreeram Vennam",
      "Priyanshul Govil",
      "Ponnurangam Kumaraguru",
      "Manas Gaur"
    ],
    "abstract": "Despite recent advancements showcasing the impressive capabilities of Large\nLanguage Models (LLMs) in conversational systems, we show that even\nstate-of-the-art LLMs are morally inconsistent in their generations,\nquestioning their reliability (and trustworthiness in general). Prior works in\nLLM evaluation focus on developing ground-truth data to measure accuracy on\nspecific tasks. However, for moral scenarios that often lack universally\nagreed-upon answers, consistency in model responses becomes crucial for their\nreliability. To address this issue, we propose an information-theoretic measure\ncalled Semantic Graph Entropy (SaGE), grounded in the concept of \"Rules of\nThumb\" (RoTs) to measure a model's moral consistency. RoTs are abstract\nprinciples learned by a model and can help explain their decision-making\nstrategies effectively. To this extent, we construct the Moral Consistency\nCorpus (MCC), containing 50K moral questions, responses to them by LLMs, and\nthe RoTs that these models followed. Furthermore, to illustrate the\ngeneralizability of SaGE, we use it to investigate LLM consistency on two\npopular datasets -- TruthfulQA and HellaSwag. Our results reveal that\ntask-accuracy and consistency are independent problems, and there is a dire\nneed to investigate these issues further.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13709v2",
    "published_date": "2024-02-21 11:23:21 UTC",
    "updated_date": "2024-03-08 14:35:30 UTC"
  },
  {
    "arxiv_id": "2402.14042v2",
    "title": "Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records",
    "authors": [
      "Navid Ashrafi",
      "Vera Schmitt",
      "Robert P. Spang",
      "Sebastian Möller",
      "Jan-Niklas Voigt-Antons"
    ],
    "abstract": "Preservation of private user data is of paramount importance for high Quality\nof Experience (QoE) and acceptability, particularly with services treating\nsensitive data, such as IT-based health services. Whereas anonymization\ntechniques were shown to be prone to data re-identification, synthetic data\ngeneration has gradually replaced anonymization since it is relatively less\ntime and resource-consuming and more robust to data leakage. Generative\nAdversarial Networks (GANs) have been used for generating synthetic datasets,\nespecially GAN frameworks adhering to the differential privacy phenomena. This\nresearch compares state-of-the-art GAN-based models for synthetic data\ngeneration to generate time-series synthetic medical records of dementia\npatients which can be distributed without privacy concerns. Predictive\nmodeling, autocorrelation, and distribution analysis are used to assess the\nQuality of Generating (QoG) of the generated data. The privacy preservation of\nthe respective models is assessed by applying membership inference attacks to\ndetermine potential data leakage risks. Our experiments indicate the\nsuperiority of the privacy-preserving GAN (PPGAN) model over other models\nregarding privacy preservation while maintaining an acceptable level of QoG.\nThe presented results can support better data protection for medical use cases\nin the future.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14042v2",
    "published_date": "2024-02-21 10:24:34 UTC",
    "updated_date": "2024-03-01 11:46:26 UTC"
  },
  {
    "arxiv_id": "2402.14041v6",
    "title": "E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series",
    "authors": [
      "Zhichen Lai",
      "Huan Li",
      "Dalin Zhang",
      "Yan Zhao",
      "Weizhu Qian",
      "Christian S. Jensen"
    ],
    "abstract": "Cyber-physical system sensors emit multivariate time series (MTS) that\nmonitor physical system processes. Such time series generally capture unknown\nnumbers of states, each with a different duration, that correspond to specific\nconditions, e.g., \"walking\" or \"running\" in human-activity monitoring.\nUnsupervised identification of such states facilitates storage and processing\nin subsequent data analyses, as well as enhances result interpretability.\nExisting state-detection proposals face three challenges. First, they introduce\nsubstantial computational overhead, rendering them impractical in\nresourceconstrained or streaming settings. Second, although state-of-the-art\n(SOTA) proposals employ contrastive learning for representation, insufficient\nattention to false negatives hampers model convergence and accuracy. Third,\nSOTA proposals predominantly only emphasize offline non-streaming deployment,\nwe highlight an urgent need to optimize online streaming scenarios. We propose\nE2Usd that enables efficient-yet-accurate unsupervised MTS state detection.\nE2Usd exploits a Fast Fourier Transform-based Time Series Compressor\n(fftCompress) and a Decomposed Dual-view Embedding Module (ddEM) that together\nencode input MTSs at low computational overhead. Additionally, we propose a\nFalse Negative Cancellation Contrastive Learning method (fnccLearning) to\ncounteract the effects of false negatives and to achieve more cluster-friendly\nembedding spaces. To reduce computational overhead further in streaming\nsettings, we introduce Adaptive Threshold Detection (adaTD). Comprehensive\nexperiments with six baselines and six datasets offer evidence that E2Usd is\ncapable of SOTA accuracy at significantly reduced computational overhead.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by The Web Conference 2024 (WWW 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.14041v6",
    "published_date": "2024-02-21 10:16:57 UTC",
    "updated_date": "2024-05-27 08:14:20 UTC"
  },
  {
    "arxiv_id": "2402.13671v2",
    "title": "KInIT at SemEval-2024 Task 8: Fine-tuned LLMs for Multilingual Machine-Generated Text Detection",
    "authors": [
      "Michal Spiegel",
      "Dominik Macko"
    ],
    "abstract": "SemEval-2024 Task 8 is focused on multigenerator, multidomain, and\nmultilingual black-box machine-generated text detection. Such a detection is\nimportant for preventing a potential misuse of large language models (LLMs),\nthe newest of which are very capable in generating multilingual human-like\ntexts. We have coped with this task in multiple ways, utilizing language\nidentification and parameter-efficient fine-tuning of smaller LLMs for text\nclassification. We have further used the per-language classification-threshold\ncalibration to uniquely combine fine-tuned models predictions with statistical\ndetection metrics to improve generalization of the system detection\nperformance. Our submitted method achieved competitive results, ranking at the\nfourth place, just under 1 percentage point behind the winner.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "SemEval-2024 Task 8",
    "pdf_url": "http://arxiv.org/pdf/2402.13671v2",
    "published_date": "2024-02-21 10:09:56 UTC",
    "updated_date": "2024-06-17 13:43:28 UTC"
  },
  {
    "arxiv_id": "2402.13647v1",
    "title": "Unsupervised Text Style Transfer via LLMs and Attention Masking with Multi-way Interactions",
    "authors": [
      "Lei Pan",
      "Yunshi Lan",
      "Yang Li",
      "Weining Qian"
    ],
    "abstract": "Unsupervised Text Style Transfer (UTST) has emerged as a critical task within\nthe domain of Natural Language Processing (NLP), aiming to transfer one\nstylistic aspect of a sentence into another style without changing its\nsemantics, syntax, or other attributes. This task is especially challenging\ngiven the intrinsic lack of parallel text pairings. Among existing methods for\nUTST tasks, attention masking approach and Large Language Models (LLMs) are\ndeemed as two pioneering methods. However, they have shortcomings in generating\nunsmooth sentences and changing the original contents, respectively. In this\npaper, we investigate if we can combine these two methods effectively. We\npropose four ways of interactions, that are pipeline framework with tuned\norders; knowledge distillation from LLMs to attention masking model; in-context\nlearning with constructed parallel examples. We empirically show these\nmulti-way interactions can improve the baselines in certain perspective of\nstyle strength, content preservation and text fluency. Experiments also\ndemonstrate that simply conducting prompting followed by attention\nmasking-based revision can consistently surpass the other systems, including\nsupervised text style transfer systems. On Yelp-clean and Amazon-clean\ndatasets, it improves the previously best mean metric by 0.5 and 3.0 absolute\npercentages respectively, and achieves new SOTA results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13647v1",
    "published_date": "2024-02-21 09:28:02 UTC",
    "updated_date": "2024-02-21 09:28:02 UTC"
  },
  {
    "arxiv_id": "2402.13635v1",
    "title": "The METRIC-framework for assessing data quality for trustworthy AI in medicine: a systematic review",
    "authors": [
      "Daniel Schwabe",
      "Katinka Becker",
      "Martin Seyferth",
      "Andreas Klaß",
      "Tobias Schäffter"
    ],
    "abstract": "The adoption of machine learning (ML) and, more specifically, deep learning\n(DL) applications into all major areas of our lives is underway. The\ndevelopment of trustworthy AI is especially important in medicine due to the\nlarge implications for patients' lives. While trustworthiness concerns various\naspects including ethical, technical and privacy requirements, we focus on the\nimportance of data quality (training/test) in DL. Since data quality dictates\nthe behaviour of ML products, evaluating data quality will play a key part in\nthe regulatory approval of medical AI products. We perform a systematic review\nfollowing PRISMA guidelines using the databases PubMed and ACM Digital Library.\nWe identify 2362 studies, out of which 62 records fulfil our eligibility\ncriteria. From this literature, we synthesise the existing knowledge on data\nquality frameworks and combine it with the perspective of ML applications in\nmedicine. As a result, we propose the METRIC-framework, a specialised data\nquality framework for medical training data comprising 15 awareness dimensions,\nalong which developers of medical ML applications should investigate a dataset.\nThis knowledge helps to reduce biases as a major source of unfairness, increase\nrobustness, facilitate interpretability and thus lays the foundation for\ntrustworthy AI in medicine. Incorporating such systematic assessment of medical\ndatasets into regulatory approval processes has the potential to accelerate the\napproval of ML products and builds the basis for new standards.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13635v1",
    "published_date": "2024-02-21 09:15:46 UTC",
    "updated_date": "2024-02-21 09:15:46 UTC"
  },
  {
    "arxiv_id": "2402.16733v2",
    "title": "DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing",
    "authors": [
      "Haneul Yoo",
      "Jieun Han",
      "So-Yeon Ahn",
      "Alice Oh"
    ],
    "abstract": "Automated essay scoring (AES) is a useful tool in English as a Foreign\nLanguage (EFL) writing education, offering real-time essay scores for students\nand instructors. However, previous AES models were trained on essays and scores\nirrelevant to the practical scenarios of EFL writing education and usually\nprovided a single holistic score due to the lack of appropriate datasets. In\nthis paper, we release DREsS, a large-scale, standard dataset for rubric-based\nautomated essay scoring. DREsS comprises three sub-datasets: DREsS_New,\nDREsS_Std., and DREsS_CASE. We collect DREsS_New, a real-classroom dataset with\n2.3K essays authored by EFL undergraduate students and scored by English\neducation experts. We also standardize existing rubric-based essay scoring\ndatasets as DREsS_Std. We suggest CASE, a corruption-based augmentation\nstrategy for essays, which generates 40.1K synthetic samples of DREsS_CASE and\nimproves the baseline results by 45.44%. DREsS will enable further research to\nprovide a more accurate and practical AES system for EFL writing education.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.16733v2",
    "published_date": "2024-02-21 09:12:16 UTC",
    "updated_date": "2024-11-04 06:54:34 UTC"
  },
  {
    "arxiv_id": "2402.13615v1",
    "title": "Analyizing the Conjunction Fallacy as a Fact",
    "authors": [
      "Tomas Veloz",
      "Olha Sobetska"
    ],
    "abstract": "Since the seminal paper by Tversky and Kahneman, the conjunction fallacy has\nbeen the subject of multiple debates and become a fundamental challenge for\ncognitive theories in decision-making. In this article, we take a rather\nuncommon perspective on this phenomenon. Instead of trying to explain the\nnature or causes of the conjunction fallacy (intensional definition), we\nanalyze its range of factual possibilities (extensional definition). We show\nthat the majority of research on the conjunction fallacy, according to our\nsample of experiments reviewed which covers literature between 1983 and 2016,\nhas focused on a narrow part of the a priori factual possibilities, implying\nthat explanations of the conjunction fallacy are fundamentally biased by the\nshort scope of possibilities explored. The latter is a rather curious aspect of\nthe research evolution in the conjunction fallacy considering that the very\nnature of it is motivated by extensional considerations.",
    "categories": [
      "cs.AI",
      "math.PR",
      "nlin.AO"
    ],
    "primary_category": "cs.AI",
    "comment": "book chapter",
    "pdf_url": "http://arxiv.org/pdf/2402.13615v1",
    "published_date": "2024-02-21 08:40:04 UTC",
    "updated_date": "2024-02-21 08:40:04 UTC"
  },
  {
    "arxiv_id": "2403.14641v1",
    "title": "Testing autonomous vehicles and AI: perspectives and challenges from cybersecurity, transparency, robustness and fairness",
    "authors": [
      "David Fernández Llorca",
      "Ronan Hamon",
      "Henrik Junklewitz",
      "Kathrin Grosse",
      "Lars Kunze",
      "Patrick Seiniger",
      "Robert Swaim",
      "Nick Reed",
      "Alexandre Alahi",
      "Emilia Gómez",
      "Ignacio Sánchez",
      "Akos Kriston"
    ],
    "abstract": "This study explores the complexities of integrating Artificial Intelligence\n(AI) into Autonomous Vehicles (AVs), examining the challenges introduced by AI\ncomponents and the impact on testing procedures, focusing on some of the\nessential requirements for trustworthy AI. Topics addressed include the role of\nAI at various operational layers of AVs, the implications of the EU's AI Act on\nAVs, and the need for new testing methodologies for Advanced Driver Assistance\nSystems (ADAS) and Automated Driving Systems (ADS). The study also provides a\ndetailed analysis on the importance of cybersecurity audits, the need for\nexplainability in AI decision-making processes and protocols for assessing the\nrobustness and ethical behaviour of predictive systems in AVs. The paper\nidentifies significant challenges and suggests future directions for research\nand development of AI in AV technology, highlighting the need for\nmultidisciplinary expertise.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "44 pages, 8 figures, submitted to a peer-review journal",
    "pdf_url": "http://arxiv.org/pdf/2403.14641v1",
    "published_date": "2024-02-21 08:29:42 UTC",
    "updated_date": "2024-02-21 08:29:42 UTC"
  },
  {
    "arxiv_id": "2402.13610v1",
    "title": "Data-driven Discovery with Large Generative Models",
    "authors": [
      "Bodhisattwa Prasad Majumder",
      "Harshit Surana",
      "Dhruv Agarwal",
      "Sanchaita Hazra",
      "Ashish Sabharwal",
      "Peter Clark"
    ],
    "abstract": "With the accumulation of data at an unprecedented rate, its potential to fuel\nscientific discovery is growing exponentially. This position paper urges the\nMachine Learning (ML) community to exploit the capabilities of large generative\nmodels (LGMs) to develop automated systems for end-to-end data-driven discovery\n-- a paradigm encompassing the search and verification of hypotheses purely\nfrom a set of provided datasets, without the need for additional data\ncollection or physical experiments. We first outline several desiderata for an\nideal data-driven discovery system. Then, through DATAVOYAGER, a\nproof-of-concept utilizing GPT-4, we demonstrate how LGMs fulfill several of\nthese desiderata -- a feat previously unattainable -- while also highlighting\nimportant limitations in the current system that open up opportunities for\nnovel ML research. We contend that achieving accurate, reliable, and robust\nend-to-end discovery systems solely through the current capabilities of LGMs is\nchallenging. We instead advocate for fail-proof tool integration, along with\nactive user moderation through feedback mechanisms, to foster data-driven\nscientific discoveries with efficiency and reproducibility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13610v1",
    "published_date": "2024-02-21 08:26:43 UTC",
    "updated_date": "2024-02-21 08:26:43 UTC"
  },
  {
    "arxiv_id": "2402.13602v4",
    "title": "Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving",
    "authors": [
      "Mehdi Azarafza",
      "Mojtaba Nayyeri",
      "Charles Steinmetz",
      "Steffen Staab",
      "Achim Rettberg"
    ],
    "abstract": "Large Language Models (LLMs) have garnered significant attention for their\nability to understand text and images, generate human-like text, and perform\ncomplex reasoning tasks. However, their ability to generalize this advanced\nreasoning with a combination of natural language text for decision-making in\ndynamic situations requires further exploration. In this study, we investigate\nhow well LLMs can adapt and apply a combination of arithmetic and common-sense\nreasoning, particularly in autonomous driving scenarios. We hypothesize that\nLLMs hybrid reasoning abilities can improve autonomous driving by enabling them\nto analyze detected object and sensor data, understand driving regulations and\nphysical laws, and offer additional context. This addresses complex scenarios,\nlike decisions in low visibility (due to weather conditions), where traditional\nmethods might fall short. We evaluated Large Language Models (LLMs) based on\naccuracy by comparing their answers with human-generated ground truth inside\nCARLA. The results showed that when a combination of images (detected objects)\nand sensor data is fed into the LLM, it can offer precise information for brake\nand throttle control in autonomous vehicles across various weather conditions.\nThis formulation and answers can assist in decision-making for auto-pilot\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13602v4",
    "published_date": "2024-02-21 08:09:05 UTC",
    "updated_date": "2024-08-19 13:27:55 UTC"
  },
  {
    "arxiv_id": "2402.13598v2",
    "title": "User-LLM: Efficient LLM Contextualization with User Embeddings",
    "authors": [
      "Lin Ning",
      "Luyang Liu",
      "Jiaxing Wu",
      "Neo Wu",
      "Devora Berlowitz",
      "Sushant Prakash",
      "Bradley Green",
      "Shawn O'Banion",
      "Jun Xie"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable success across various\ndomains, but effectively incorporating complex and potentially noisy user\ntimeline data into LLMs remains a challenge. Current approaches often involve\ntranslating user timelines into text descriptions before feeding them to LLMs,\nwhich can be inefficient and may not fully capture the nuances of user\nbehavior. Inspired by how LLMs are effectively integrated with images through\ndirect embeddings, we propose User-LLM, a novel framework that leverages user\nembeddings to directly contextualize LLMs with user history interactions. These\nembeddings, generated by a user encoder pretrained using self-supervised\nlearning on diverse user interactions, capture latent user behaviors and\ninterests as well as their evolution over time. We integrate these user\nembeddings with LLMs through cross-attention, enabling LLMs to dynamically\nadapt their responses based on the context of a user's past actions and\npreferences.\n  Our approach achieves significant efficiency gains by representing user\ntimelines directly as embeddings, leading to substantial inference speedups of\nup to 78.1X. Comprehensive experiments on MovieLens, Amazon Review, and Google\nLocal Review datasets demonstrate that User-LLM outperforms text-prompt-based\ncontextualization on tasks requiring deep user understanding, with improvements\nof up to 16.33%, particularly excelling on long sequences that capture subtle\nshifts in user behavior. Furthermore, the incorporation of Perceiver layers\nstreamlines the integration between user encoders and LLMs, yielding additional\ncomputational savings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13598v2",
    "published_date": "2024-02-21 08:03:27 UTC",
    "updated_date": "2024-09-09 19:51:57 UTC"
  },
  {
    "arxiv_id": "2402.14866v2",
    "title": "APTQ: Attention-aware Post-Training Mixed-Precision Quantization for Large Language Models",
    "authors": [
      "Ziyi Guan",
      "Hantao Huang",
      "Yupeng Su",
      "Hong Huang",
      "Ngai Wong",
      "Hao Yu"
    ],
    "abstract": "Large Language Models (LLMs) have greatly advanced the natural language\nprocessing paradigm. However, the high computational load and huge model sizes\npose a grand challenge for deployment on edge devices. To this end, we propose\nAPTQ (Attention-aware Post-Training Mixed-Precision Quantization) for LLMs,\nwhich considers not only the second-order information of each layer's weights,\nbut also, for the first time, the nonlinear effect of attention outputs on the\nentire model. We leverage the Hessian trace as a sensitivity metric for\nmixed-precision quantization, ensuring an informed precision reduction that\nretains model performance. Experiments show APTQ surpasses previous\nquantization methods, achieving an average of 4 bit width a 5.22 perplexity\nnearly equivalent to full precision in the C4 dataset. In addition, APTQ\nattains state-of-the-art zero-shot accuracy of 68.24\\% and 70.48\\% at an\naverage bitwidth of 3.8 in LLaMa-7B and LLaMa-13B, respectively, demonstrating\nits effectiveness to produce high-quality quantized LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 2 figures, published to DAC 2024: 61st IEEE/ACM Design\n  Automation Conference. (DAC'24)",
    "pdf_url": "http://arxiv.org/pdf/2402.14866v2",
    "published_date": "2024-02-21 07:45:22 UTC",
    "updated_date": "2024-04-16 03:18:38 UTC"
  },
  {
    "arxiv_id": "2402.13582v1",
    "title": "Mastering the Game of Guandan with Deep Reinforcement Learning and Behavior Regulating",
    "authors": [
      "Yifan Yanggong",
      "Hao Pan",
      "Lei Wang"
    ],
    "abstract": "Games are a simplified model of reality and often serve as a favored platform\nfor Artificial Intelligence (AI) research. Much of the research is concerned\nwith game-playing agents and their decision making processes. The game of\nGuandan (literally, \"throwing eggs\") is a challenging game where even\nprofessional human players struggle to make the right decision at times. In\nthis paper we propose a framework named GuanZero for AI agents to master this\ngame using Monte-Carlo methods and deep neural networks. The main contribution\nof this paper is about regulating agents' behavior through a carefully designed\nneural network encoding scheme. We then demonstrate the effectiveness of the\nproposed framework by comparing it with state-of-the-art approaches.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13582v1",
    "published_date": "2024-02-21 07:26:06 UTC",
    "updated_date": "2024-02-21 07:26:06 UTC"
  },
  {
    "arxiv_id": "2402.13575v3",
    "title": "Flexible Physical Camouflage Generation Based on a Differential Approach",
    "authors": [
      "Yang Li",
      "Wenyi Tan",
      "Tingrui Wang",
      "Xinkai Liang",
      "Quan Pan"
    ],
    "abstract": "This study introduces a novel approach to neural rendering, specifically\ntailored for adversarial camouflage, within an extensive 3D rendering\nframework. Our method, named FPA, goes beyond traditional techniques by\nfaithfully simulating lighting conditions and material variations, ensuring a\nnuanced and realistic representation of textures on a 3D target. To achieve\nthis, we employ a generative approach that learns adversarial patterns from a\ndiffusion model. This involves incorporating a specially designed adversarial\nloss and covert constraint loss to guarantee the adversarial and covert nature\nof the camouflage in the physical world. Furthermore, we showcase the\neffectiveness of the proposed camouflage in sticker mode, demonstrating its\nability to cover the target without compromising adversarial information.\nThrough empirical and physical experiments, FPA exhibits strong performance in\nterms of attack success rate and transferability. Additionally, the designed\nsticker-mode camouflage, coupled with a concealment constraint, adapts to the\nenvironment, yielding diverse styles of texture. Our findings highlight the\nversatility and efficacy of the FPA approach in adversarial camouflage\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13575v3",
    "published_date": "2024-02-21 07:15:16 UTC",
    "updated_date": "2024-12-12 04:43:56 UTC"
  },
  {
    "arxiv_id": "2402.13573v3",
    "title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution Images",
    "authors": [
      "Ethan Smith",
      "Nayan Saxena",
      "Aninda Saha"
    ],
    "abstract": "Attention mechanism has been crucial for image diffusion models, however,\ntheir quadratic computational complexity limits the sizes of images we can\nprocess within reasonable time and memory constraints. This paper investigates\nthe importance of dense attention in generative image models, which often\ncontain redundant features, making them suitable for sparser attention\nmechanisms. We propose a novel training-free method ToDo that relies on token\ndownsampling of key and value tokens to accelerate Stable Diffusion inference\nby up to 2x for common sizes and up to 4.5x or more for high resolutions like\n2048x2048. We demonstrate that our approach outperforms previous methods in\nbalancing efficient throughput and fidelity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13573v3",
    "published_date": "2024-02-21 07:10:28 UTC",
    "updated_date": "2024-05-08 05:09:48 UTC"
  },
  {
    "arxiv_id": "2402.15527v1",
    "title": "PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain",
    "authors": [
      "Liang Chen",
      "Yichi Zhang",
      "Shuhuai Ren",
      "Haozhe Zhao",
      "Zefan Cai",
      "Yuchi Wang",
      "Peiyi Wang",
      "Xiangdi Meng",
      "Tianyu Liu",
      "Baobao Chang"
    ],
    "abstract": "We present PCA-Bench, a multimodal decision-making benchmark for evaluating\nthe integrated capabilities of Multimodal Large Language Models (MLLMs).\nDeparting from previous benchmarks focusing on simplistic tasks and individual\nmodel capability, PCA-Bench introduces three complex scenarios: autonomous\ndriving, domestic robotics, and open-world games. Given task instructions and\ndiverse contexts, the model is required to seamlessly integrate multiple\ncapabilities of Perception, Cognition, and Action in a reasoning chain to make\naccurate decisions. Moreover, PCA-Bench features error localization\ncapabilities, scrutinizing model inaccuracies in areas such as perception,\nknowledge, or reasoning. This enhances the reliability of deploying MLLMs. To\nbalance accuracy and efficiency in evaluation, we propose PCA-Eval, an\nautomatic evaluation protocol, and assess 10 prevalent MLLMs. The results\nreveal significant performance disparities between open-source models and\npowerful proprietary models like GPT-4 Vision. To address this, we introduce\nEmbodied-Instruction-Evolution (EIE), an automatic framework for synthesizing\ninstruction tuning examples in multimodal embodied environments. EIE generates\n7,510 training examples in PCA-Bench and enhances the performance of\nopen-source MLLMs, occasionally surpassing GPT-4 Vision (+3\\% in decision\naccuracy), thereby validating the effectiveness of EIE. Our findings suggest\nthat robust MLLMs like GPT4-Vision show promise for decision-making in embodied\nagents, opening new avenues for MLLM research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Code and Data released at https://github.com/pkunlp-icler/PCA-EVAL.\n  Leaderboard at: https://docs.qq.com/sheet/DVUd4WUpGRHRqUnNV. This article\n  supersedes its workshop version arxiv: 2310.02071. arXiv admin note: text\n  overlap with arXiv:2310.02071",
    "pdf_url": "http://arxiv.org/pdf/2402.15527v1",
    "published_date": "2024-02-21 07:09:58 UTC",
    "updated_date": "2024-02-21 07:09:58 UTC"
  },
  {
    "arxiv_id": "2402.13572v2",
    "title": "AlgoFormer: An Efficient Transformer Framework with Algorithmic Structures",
    "authors": [
      "Yihang Gao",
      "Chuanyang Zheng",
      "Enze Xie",
      "Han Shi",
      "Tianyang Hu",
      "Yu Li",
      "Michael K. Ng",
      "Zhenguo Li",
      "Zhaoqiang Liu"
    ],
    "abstract": "Besides natural language processing, transformers exhibit extraordinary\nperformance in solving broader applications, including scientific computing and\ncomputer vision. Previous works try to explain this from the expressive power\nand capability perspectives that standard transformers are capable of\nperforming some algorithms. To empower transformers with algorithmic\ncapabilities and motivated by the recently proposed looped transformer, we\ndesign a novel transformer framework, dubbed Algorithm Transformer (abbreviated\nas AlgoFormer). We provide an insight that efficient transformer architectures\ncan be designed by leveraging prior knowledge of tasks and the underlying\nstructure of potential algorithms. Compared with the standard transformer and\nvanilla looped transformer, the proposed AlgoFormer can perform efficiently in\nalgorithm representation in some specific tasks. In particular, inspired by the\nstructure of human-designed learning algorithms, our transformer framework\nconsists of a pre-transformer that is responsible for task preprocessing, a\nlooped transformer for iterative optimization algorithms, and a\npost-transformer for producing the desired results after post-processing. We\nprovide theoretical evidence of the expressive power of the AlgoFormer in\nsolving some challenging problems, mirroring human-designed algorithms.\nFurthermore, some theoretical and empirical results are presented to show that\nthe designed transformer has the potential to perform algorithm representation\nand learning. Experimental results demonstrate the empirical superiority of the\nproposed transformer in that it outperforms the standard transformer and\nvanilla looped transformer in some specific tasks. An extensive experiment on\nreal language tasks (e.g., neural machine translation of German and English,\nand text classification) further validates the expressiveness and effectiveness\nof AlgoFormer.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at Transactions on Machine Learning Research (TMLR). The\n  paper provides insight that the Transformer architectures can mimic the\n  algorithm structures in (in-context) algorithm learning and representation.\n  The incorporated algorithmic structure in Algoformer shows its potential in\n  (deep learning for) scientific computing, besides the real language tasks",
    "pdf_url": "http://arxiv.org/pdf/2402.13572v2",
    "published_date": "2024-02-21 07:07:54 UTC",
    "updated_date": "2025-01-10 09:11:39 UTC"
  },
  {
    "arxiv_id": "2402.13571v2",
    "title": "Multilingual Coreference Resolution in Low-resource South Asian Languages",
    "authors": [
      "Ritwik Mishra",
      "Pooja Desur",
      "Rajiv Ratn Shah",
      "Ponnurangam Kumaraguru"
    ],
    "abstract": "Coreference resolution involves the task of identifying text spans within a\ndiscourse that pertain to the same real-world entity. While this task has been\nextensively explored in the English language, there has been a notable scarcity\nof publicly accessible resources and models for coreference resolution in South\nAsian languages. We introduce a Translated dataset for Multilingual Coreference\nResolution (TransMuCoRes) in 31 South Asian languages using off-the-shelf tools\nfor translation and word-alignment. Nearly all of the predicted translations\nsuccessfully pass a sanity check, and 75% of English references align with\ntheir predicted translations. Using multilingual encoders, two off-the-shelf\ncoreference resolution models were trained on a concatenation of TransMuCoRes\nand a Hindi coreference resolution dataset with manual annotations. The best\nperforming model achieved a score of 64 and 68 for LEA F1 and CoNLL F1,\nrespectively, on our test-split of Hindi golden set. This study is the first to\nevaluate an end-to-end coreference resolution model on a Hindi golden set.\nFurthermore, this work underscores the limitations of current coreference\nevaluation metrics when applied to datasets with split antecedents, advocating\nfor the development of more suitable evaluation metrics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13571v2",
    "published_date": "2024-02-21 07:05:51 UTC",
    "updated_date": "2024-03-23 08:22:58 UTC"
  },
  {
    "arxiv_id": "2402.13567v1",
    "title": "Spot Check Equivalence: an Interpretable Metric for Information Elicitation Mechanisms",
    "authors": [
      "Shengwei Xu",
      "Yichi Zhang",
      "Paul Resnick",
      "Grant Schoenebeck"
    ],
    "abstract": "Because high-quality data is like oxygen for AI systems, effectively\neliciting information from crowdsourcing workers has become a first-order\nproblem for developing high-performance machine learning algorithms. Two\nprevalent paradigms, spot-checking and peer prediction, enable the design of\nmechanisms to evaluate and incentivize high-quality data from human labelers.\nSo far, at least three metrics have been proposed to compare the performances\nof these techniques [33, 8, 3]. However, different metrics lead to divergent\nand even contradictory results in various contexts. In this paper, we harmonize\nthese divergent stories, showing that two of these metrics are actually the\nsame within certain contexts and explain the divergence of the third. Moreover,\nwe unify these different contexts by introducing \\textit{Spot Check\nEquivalence}, which offers an interpretable metric for the effectiveness of a\npeer prediction mechanism. Finally, we present two approaches to compute spot\ncheck equivalence in various contexts, where simulation results verify the\neffectiveness of our proposed metric.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the Web Conference 2024 (WWW '24)",
    "pdf_url": "http://arxiv.org/pdf/2402.13567v1",
    "published_date": "2024-02-21 06:57:07 UTC",
    "updated_date": "2024-02-21 06:57:07 UTC"
  },
  {
    "arxiv_id": "2402.14865v2",
    "title": "Dynamic Evaluation of Large Language Models by Meta Probing Agents",
    "authors": [
      "Kaijie Zhu",
      "Jindong Wang",
      "Qinlin Zhao",
      "Ruochen Xu",
      "Xing Xie"
    ],
    "abstract": "Evaluation of large language models (LLMs) has raised great concerns in the\ncommunity due to the issue of data contamination. Existing work designed\nevaluation protocols using well-defined algorithms for specific tasks, which\ncannot be easily extended to diverse scenarios. Moreover, current evaluation\nbenchmarks can only provide the overall benchmark results and cannot support a\nfine-grained and multifaceted analysis of LLMs' abilities. In this paper, we\npropose meta probing agents (MPA), a general dynamic evaluation protocol\ninspired by psychometrics to evaluate LLMs. MPA is the key component of DyVal\n2, which naturally extends the previous DyVal~\\citep{zhu2023dyval}. MPA designs\nthe probing and judging agents to automatically transform an original\nevaluation problem into a new one following psychometric theory on three basic\ncognitive abilities: language understanding, problem solving, and domain\nknowledge. These basic abilities are also dynamically configurable, allowing\nmultifaceted analysis. We conducted extensive evaluations using MPA and found\nthat most LLMs achieve poorer performance, indicating room for improvement. Our\nmultifaceted analysis demonstrated the strong correlation between the basic\nabilities and an implicit Matthew effect on model size, i.e., larger models\npossess stronger correlations of the abilities. MPA can also be used as a data\naugmentation approach to enhance LLMs. Code is available at:\nhttps://github.com/microsoft/promptbench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "International Conference on Machine Learning (ICML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14865v2",
    "published_date": "2024-02-21 06:46:34 UTC",
    "updated_date": "2024-06-07 09:19:45 UTC"
  },
  {
    "arxiv_id": "2402.14039v1",
    "title": "Specialty detection in the context of telemedicine in a highly imbalanced multi-class distribution",
    "authors": [
      "Alaa Alomari",
      "Hossam Faris",
      "Pedro A. Castillo"
    ],
    "abstract": "The Covid-19 pandemic has led to an increase in the awareness of and demand\nfor telemedicine services, resulting in a need for automating the process and\nrelying on machine learning (ML) to reduce the operational load. This research\nproposes a specialty detection classifier based on a machine learning model to\nautomate the process of detecting the correct specialty for each question and\nrouting it to the correct doctor. The study focuses on handling multiclass and\nhighly imbalanced datasets for Arabic medical questions, comparing some\noversampling techniques, developing a Deep Neural Network (DNN) model for\nspecialty detection, and exploring the hidden business areas that rely on\nspecialty detection such as customizing and personalizing the consultation flow\nfor different specialties. The proposed module is deployed in both synchronous\nand asynchronous medical consultations to provide more real-time\nclassification, minimize the doctor effort in addressing the correct specialty,\nand give the system more flexibility in customizing the medical consultation\nflow. The evaluation and assessment are based on accuracy, precision, recall,\nand F1-score. The experimental results suggest that combining multiple\ntechniques, such as SMOTE and reweighing with keyword identification, is\nnecessary to achieve improved performance in detecting rare classes in\nimbalanced multiclass datasets. By using these techniques, specialty detection\nmodels can more accurately detect rare classes in real-world scenarios where\nimbalanced data is common.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14039v1",
    "published_date": "2024-02-21 06:39:04 UTC",
    "updated_date": "2024-02-21 06:39:04 UTC"
  },
  {
    "arxiv_id": "2402.13556v1",
    "title": "Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective",
    "authors": [
      "Yuchen Yan",
      "Peiyan Zhang",
      "Zheng Fang",
      "Qingqing Long"
    ],
    "abstract": "The \"Graph pre-training and fine-tuning\" paradigm has significantly improved\nGraph Neural Networks(GNNs) by capturing general knowledge without manual\nannotations for downstream tasks. However, due to the immense gap of data and\ntasks between the pre-training and fine-tuning stages, the model performance is\nstill limited. Inspired by prompt fine-tuning in Natural Language\nProcessing(NLP), many endeavors have been made to bridge the gap in graph\ndomain. But existing methods simply reformulate the form of fine-tuning tasks\nto the pre-training ones. With the premise that the pre-training graphs are\ncompatible with the fine-tuning ones, these methods typically operate in\ntransductive setting. In order to generalize graph pre-training to inductive\nscenario where the fine-tuning graphs might significantly differ from\npre-training ones, we propose a novel graph prompt based method called\nInductive Graph Alignment Prompt(IGAP). Firstly, we unify the mainstream graph\npre-training frameworks and analyze the essence of graph pre-training from\ngraph spectral theory. Then we identify the two sources of the data gap in\ninductive setting: (i) graph signal gap and (ii) graph structure gap. Based on\nthe insight of graph pre-training, we propose to bridge the graph signal gap\nand the graph structure gap with learnable prompts in the spectral space. A\ntheoretical analysis ensures the effectiveness of our method. At last, we\nconduct extensive experiments among nodes classification and graph\nclassification tasks under the transductive, semi-inductive and inductive\nsettings. The results demonstrate that our proposed method can successfully\nbridge the data gap under different settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "E.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13556v1",
    "published_date": "2024-02-21 06:25:54 UTC",
    "updated_date": "2024-02-21 06:25:54 UTC"
  },
  {
    "arxiv_id": "2402.14037v1",
    "title": "An Effective Networks Intrusion Detection Approach Based on Hybrid Harris Hawks and Multi-Layer Perceptron",
    "authors": [
      "Moutaz Alazab",
      "Ruba Abu Khurma",
      "Pedro A. Castillo",
      "Bilal Abu-Salih",
      "Alejandro Martin",
      "David Camacho"
    ],
    "abstract": "This paper proposes an Intrusion Detection System (IDS) employing the Harris\nHawks Optimization algorithm (HHO) to optimize Multilayer Perceptron learning\nby optimizing bias and weight parameters. HHO-MLP aims to select optimal\nparameters in its learning process to minimize intrusion detection errors in\nnetworks. HHO-MLP has been implemented using EvoloPy NN framework, an\nopen-source Python tool specialized for training MLPs using evolutionary\nalgorithms. For purposes of comparing the HHO model against other evolutionary\nmethodologies currently available, specificity and sensitivity measures,\naccuracy measures, and mse and rmse measures have been calculated using KDD\ndatasets. Experiments have demonstrated the HHO MLP method is effective at\nidentifying malicious patterns. HHO-MLP has been tested against evolutionary\nalgorithms like Butterfly Optimization Algorithm (BOA), Grasshopper\nOptimization Algorithms (GOA), and Black Widow Optimizations (BOW), with\nvalidation by Random Forest (RF), XG-Boost. HHO-MLP showed superior performance\nby attaining top scores with accuracy rate of 93.17%, sensitivity level of\n89.25%, and specificity percentage of 95.41%.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14037v1",
    "published_date": "2024-02-21 06:25:50 UTC",
    "updated_date": "2024-02-21 06:25:50 UTC"
  },
  {
    "arxiv_id": "2402.13550v2",
    "title": "Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues",
    "authors": [
      "Deuksin Kwon",
      "Emily Weiss",
      "Tara Kulshrestha",
      "Kushal Chawla",
      "Gale M. Lucas",
      "Jonathan Gratch"
    ],
    "abstract": "A successful negotiation requires a range of capabilities, including\ncomprehension of the conversation context, Theory-of-Mind (ToM) skills to infer\nthe partner's motives, strategic reasoning, and effective communication, making\nit challenging for automated systems. Despite the remarkable performance of\nLLMs in various NLP tasks, there is no systematic evaluation of their\ncapabilities in negotiation. Such an evaluation is critical for advancing AI\nnegotiation agents and negotiation research, ranging from designing dialogue\nsystems to providing pedagogical feedback and scaling up data collection\npractices. This work aims to systematically analyze the multifaceted\ncapabilities of LLMs across diverse dialogue scenarios throughout the stages of\na typical negotiation interaction. Our analysis highlights GPT-4's superior\nperformance in many tasks while identifying specific challenges, such as making\nsubjective assessments and generating contextually appropriate, strategically\nadvantageous responses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13550v2",
    "published_date": "2024-02-21 06:11:03 UTC",
    "updated_date": "2024-10-02 08:32:31 UTC"
  },
  {
    "arxiv_id": "2402.13542v2",
    "title": "ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling",
    "authors": [
      "Lingxi Zhang",
      "Yue Yu",
      "Kuan Wang",
      "Chao Zhang"
    ],
    "abstract": "Retrieval-augmented generation enhances large language models (LLMs) by\nincorporating relevant information from external knowledge sources. This\nenables LLMs to adapt to specific domains and mitigate hallucinations in\nknowledge-intensive tasks. However, existing retrievers are often misaligned\nwith LLMs due to their separate training processes and the black-box nature of\nLLMs. To address this challenge, we propose ARL2, a retriever learning\ntechnique that harnesses LLMs as labelers. ARL2 leverages LLMs to annotate and\nscore relevant evidence, enabling learning the retriever from robust LLM\nsupervision. Furthermore, ARL2 uses an adaptive self-training strategy for\ncurating high-quality and diverse relevance data, which can effectively reduce\nthe annotation cost. Extensive experiments demonstrate the effectiveness of\nARL2, achieving accuracy improvements of 5.4% on NQ and 4.6% on MMLU compared\nto the state-of-the-art methods. Additionally, ARL2 exhibits robust transfer\nlearning capabilities and strong zero-shot generalization abilities. Our code\nwill be published at \\url{https://github.com/zhanglingxi-cs/ARL2}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13542v2",
    "published_date": "2024-02-21 05:41:34 UTC",
    "updated_date": "2024-06-04 05:17:24 UTC"
  },
  {
    "arxiv_id": "2402.13536v1",
    "title": "Exploring the Limits of Semantic Image Compression at Micro-bits per Pixel",
    "authors": [
      "Jordan Dotzel",
      "Bahaa Kotb",
      "James Dotzel",
      "Mohamed Abdelfattah",
      "Zhiru Zhang"
    ],
    "abstract": "Traditional methods, such as JPEG, perform image compression by operating on\nstructural information, such as pixel values or frequency content. These\nmethods are effective to bitrates around one bit per pixel (bpp) and higher at\nstandard image sizes. In contrast, text-based semantic compression directly\nstores concepts and their relationships using natural language, which has\nevolved with humans to efficiently represent these salient concepts. These\nmethods can operate at extremely low bitrates by disregarding structural\ninformation like location, size, and orientation. In this work, we use GPT-4V\nand DALL-E3 from OpenAI to explore the quality-compression frontier for image\ncompression and identify the limitations of current technology. We push\nsemantic compression as low as 100 $\\mu$bpp (up to $10,000\\times$ smaller than\nJPEG) by introducing an iterative reflection process to improve the decoded\nimage. We further hypothesize this 100 $\\mu$bpp level represents a soft limit\non semantic compression at standard image resolutions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICLR Tiny Papers 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13536v1",
    "published_date": "2024-02-21 05:14:30 UTC",
    "updated_date": "2024-02-21 05:14:30 UTC"
  },
  {
    "arxiv_id": "2402.13534v1",
    "title": "An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling",
    "authors": [
      "Xuemei Tang",
      "Qi Su"
    ],
    "abstract": "Sequence labeling models often benefit from incorporating external knowledge.\nHowever, this practice introduces data heterogeneity and complicates the model\nwith additional modules, leading to increased expenses for training a\nhigh-performing model. To address this challenge, we propose a two-stage\ncurriculum learning (TCL) framework specifically designed for sequence labeling\ntasks. The TCL framework enhances training by gradually introducing data\ninstances from easy to hard, aiming to improve both performance and training\nspeed. Furthermore, we explore different metrics for assessing the difficulty\nlevels of sequence labeling tasks. Through extensive experimentation on six\nChinese word segmentation (CWS) and Part-of-speech tagging (POS) datasets, we\ndemonstrate the effectiveness of our model in enhancing the performance of\nsequence labeling models. Additionally, our analysis indicates that TCL\naccelerates training and alleviates the slow training problem associated with\ncomplex models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 9 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13534v1",
    "published_date": "2024-02-21 05:04:29 UTC",
    "updated_date": "2024-02-21 05:04:29 UTC"
  },
  {
    "arxiv_id": "2402.13533v1",
    "title": "FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing",
    "authors": [
      "Xiao-Yang Liu",
      "Jie Zhang",
      "Guoxuan Wang",
      "Weiqing Tong",
      "Anwar Walid"
    ],
    "abstract": "Large language models (LLMs) are computationally intensive. The computation\nworkload and the memory footprint grow quadratically with the dimension (layer\nwidth). Most of LLMs' parameters come from the linear layers of the transformer\nstructure and are highly redundant. These linear layers contribute more than\n80% of the computation workload and 99% of the model size. To pretrain and\nfinetune LLMs efficiently, there are three major challenges to address: 1)\nreducing redundancy of the linear layers; 2) reducing GPU memory footprint; 3)\nimproving GPU utilization when using distributed training. Prior methods, such\nas LoRA and QLoRA, utilized low-rank matrices and quantization to reduce the\nnumber of trainable parameters and model size, respectively. However, the\nresulting model still consumes a large amount of GPU memory. In this paper, we\npresent high-performance GPU-based methods that exploit low-rank structures to\npretrain and finetune LLMs for financial applications. We replace one\nconventional linear layer of the transformer structure with two narrower linear\nlayers, which allows us to reduce the number of parameters by several orders of\nmagnitude. By quantizing the parameters into low precision (8-bit and 4-bit),\nthe memory consumption of the resulting model is further reduced. Compared with\nexisting LLMs, our methods achieve a speedup of 1.3X and a model compression\nratio of 2.64X for pretaining without accuracy drop. For finetuning, our\nmethods achieve an average accuracy increase of 6.3% and 24.0% in general tasks\nand financial tasks, respectively, and GPU memory consumption ratio of 6.3X.\nThe sizes of our models are smaller than 0.59 GB, allowing inference on a\nsmartphone.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13533v1",
    "published_date": "2024-02-21 05:03:17 UTC",
    "updated_date": "2024-02-21 05:03:17 UTC"
  },
  {
    "arxiv_id": "2404.07215v1",
    "title": "Computation Offloading for Multi-server Multi-access Edge Vehicular Networks: A DDQN-based Method",
    "authors": [
      "Siyu Wang",
      "Bo Yang",
      "Zhiwen Yu",
      "Xuelin Cao",
      "Yan Zhang",
      "Chau Yuen"
    ],
    "abstract": "In this paper, we investigate a multi-user offloading problem in the\noverlapping domain of a multi-server mobile edge computing system. We divide\nthe original problem into two stages: the offloading decision making stage and\nthe request scheduling stage. To prevent the terminal from going out of service\narea during offloading, we consider the mobility parameter of the terminal\naccording to the human behaviour model when making the offloading decision, and\nthen introduce a server evaluation mechanism based on both the mobility\nparameter and the server load to select the optimal offloading server. In order\nto fully utilise the server resources, we design a double deep Q-network\n(DDQN)-based reward evaluation algorithm that considers the priority of tasks\nwhen scheduling offload requests. Finally, numerical simulations are conducted\nto verify that our proposed method outperforms traditional mathematical\ncomputation methods as well as the DQN algorithm.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07215v1",
    "published_date": "2024-02-21 04:41:46 UTC",
    "updated_date": "2024-02-21 04:41:46 UTC"
  },
  {
    "arxiv_id": "2402.14035v3",
    "title": "Wisdom of Committee: Distilling from Foundation Model to Specialized Application Model",
    "authors": [
      "Zichang Liu",
      "Qingyun Liu",
      "Yuening Li",
      "Liang Liu",
      "Anshumali Shrivastava",
      "Shuchao Bi",
      "Lichan Hong",
      "Ed H. Chi",
      "Zhe Zhao"
    ],
    "abstract": "Recent advancements in foundation models have yielded impressive performance\nacross a wide range of tasks. Meanwhile, for specific applications,\npractitioners have been developing specialized application models. To enjoy the\nbenefits of both kinds of models, one natural path is to transfer the knowledge\nin foundation models into specialized application models, which are generally\nmore efficient for serving. Techniques from knowledge distillation may be\napplied here, where the application model learns to mimic the foundation model.\nHowever, specialized application models and foundation models have substantial\ngaps in capacity, employing distinct architectures, using different input\nfeatures from different modalities, and being optimized on different\ndistributions. These differences in model characteristics lead to significant\nchallenges for distillation methods. In this work, we propose creating a\nteaching committee comprising both foundation model teachers and complementary\nteachers. Complementary teachers possess model characteristics akin to the\nstudent's, aiming to bridge the gap between the foundation model and\nspecialized application models for a smoother knowledge transfer. Further, to\naccommodate the dissimilarity among the teachers in the committee, we introduce\nDiverseDistill, which allows the student to understand the expertise of each\nteacher and extract task knowledge. Our evaluations demonstrate that adding\ncomplementary teachers enhances student performance. Finally, DiverseDistill\nconsistently outperforms baseline distillation methods, regardless of the\nteacher choices, resulting in significantly improved student performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14035v3",
    "published_date": "2024-02-21 04:33:26 UTC",
    "updated_date": "2024-05-15 12:42:04 UTC"
  },
  {
    "arxiv_id": "2402.14034v2",
    "title": "AgentScope: A Flexible yet Robust Multi-Agent Platform",
    "authors": [
      "Dawei Gao",
      "Zitao Li",
      "Xuchen Pan",
      "Weirui Kuang",
      "Zhijian Ma",
      "Bingchen Qian",
      "Fei Wei",
      "Wenhao Zhang",
      "Yuexiang Xie",
      "Daoyuan Chen",
      "Liuyi Yao",
      "Hongyi Peng",
      "Zeyu Zhang",
      "Lin Zhu",
      "Chen Cheng",
      "Hongzhu Shi",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "abstract": "With the rapid advancement of Large Language Models (LLMs), significant\nprogress has been made in multi-agent applications. However, the complexities\nin coordinating agents' cooperation and LLMs' erratic performance pose notable\nchallenges in developing robust and efficient multi-agent applications. To\ntackle these challenges, we propose AgentScope, a developer-centric multi-agent\nplatform with message exchange as its core communication mechanism. The\nabundant syntactic tools, built-in agents and service functions, user-friendly\ninterfaces for application demonstration and utility monitor, zero-code\nprogramming workstation, and automatic prompt tuning mechanism significantly\nlower the barriers to both development and deployment. Towards robust and\nflexible multi-agent application, AgentScope provides both built-in and\ncustomizable fault tolerance mechanisms. At the same time, it is also armed\nwith system-level support for managing and utilizing multi-modal data, tools,\nand external knowledge. Additionally, we design an actor-based distribution\nframework, enabling easy conversion between local and distributed deployments\nand automatic parallel optimization without extra effort. With these features,\nAgentScope empowers developers to build applications that fully realize the\npotential of intelligent agents. We have released AgentScope at\nhttps://github.com/modelscope/agentscope, and hope AgentScope invites wider\nparticipation and innovation in this fast-moving field.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "We have released code on https://github.com/modelscope/agentscope",
    "pdf_url": "http://arxiv.org/pdf/2402.14034v2",
    "published_date": "2024-02-21 04:11:28 UTC",
    "updated_date": "2024-05-20 04:01:08 UTC"
  },
  {
    "arxiv_id": "2402.13521v2",
    "title": "Test-Driven Development for Code Generation",
    "authors": [
      "Noble Saji Mathews",
      "Meiyappan Nagappan"
    ],
    "abstract": "Recent Large Language Models (LLMs) have demonstrated significant\ncapabilities in generating code snippets directly from problem statements. This\nincreasingly automated process mirrors traditional human-led software\ndevelopment, where code is often written in response to a requirement.\nHistorically, Test-Driven Development (TDD) has proven its merit, requiring\ndevelopers to write tests before the functional code, ensuring alignment with\nthe initial problem statements. Applying TDD principles to LLM-based code\ngeneration offers one distinct benefit: it enables developers to verify the\ncorrectness of generated code against predefined tests. This paper investigates\nif and how TDD can be incorporated into AI-assisted code-generation processes.\nWe experimentally evaluate our hypothesis that providing LLMs like GPT-4 and\nLlama 3 with tests in addition to the problem statements enhances code\ngeneration outcomes. We experimented with established function-level code\ngeneration benchmarks such as MBPP and HumanEval. Our results consistently\ndemonstrate that including test cases leads to higher success in solving\nprogramming challenges. We assert that TDD is a promising paradigm for helping\nensure that the code generated by LLMs effectively captures the requirements.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13521v2",
    "published_date": "2024-02-21 04:10:12 UTC",
    "updated_date": "2024-06-11 15:53:35 UTC"
  },
  {
    "arxiv_id": "2402.13517v2",
    "title": "Round Trip Translation Defence against Large Language Model Jailbreaking Attacks",
    "authors": [
      "Canaan Yung",
      "Hadi Mohaghegh Dolatabadi",
      "Sarah Erfani",
      "Christopher Leckie"
    ],
    "abstract": "Large language models (LLMs) are susceptible to social-engineered attacks\nthat are human-interpretable but require a high level of comprehension for LLMs\nto counteract. Existing defensive measures can only mitigate less than half of\nthese attacks at most. To address this issue, we propose the Round Trip\nTranslation (RTT) method, the first algorithm specifically designed to defend\nagainst social-engineered attacks on LLMs. RTT paraphrases the adversarial\nprompt and generalizes the idea conveyed, making it easier for LLMs to detect\ninduced harmful behavior. This method is versatile, lightweight, and\ntransferrable to different LLMs. Our defense successfully mitigated over 70% of\nPrompt Automatic Iterative Refinement (PAIR) attacks, which is currently the\nmost effective defense to the best of our knowledge. We are also the first to\nattempt mitigating the MathsAttack and reduced its attack success rate by\nalmost 40%. Our code is publicly available at\nhttps://github.com/Cancanxxx/Round_Trip_Translation_Defence\n  This version of the article has been accepted for publication, after peer\nreview (when applicable) but is not the Version of Record and does not reflect\npost-acceptance improvements, or any corrections. The Version of Record is\navailable online at: https://doi.org/10.48550/arXiv.2402.13517 Use of this\nAccepted Version is subject to the publisher's Accepted Manuscript terms of use\nhttps://www.springernature.com/gp/open-research/policies/accepted-manuscript-terms",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13517v2",
    "published_date": "2024-02-21 03:59:52 UTC",
    "updated_date": "2025-04-30 05:13:56 UTC"
  },
  {
    "arxiv_id": "2402.13516v7",
    "title": "ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models",
    "authors": [
      "Chenyang Song",
      "Xu Han",
      "Zhengyan Zhang",
      "Shengding Hu",
      "Xiyu Shi",
      "Kuai Li",
      "Chen Chen",
      "Zhiyuan Liu",
      "Guangli Li",
      "Tao Yang",
      "Maosong Sun"
    ],
    "abstract": "Activation sparsity refers to the existence of considerable\nweakly-contributed elements among activation outputs. As a prevalent property\nof the models using the ReLU activation function, activation sparsity has been\nproven a promising paradigm to boost model inference efficiency. Nevertheless,\nmost large language models (LLMs) adopt activation functions without intrinsic\nactivation sparsity (e.g., GELU and Swish). Some recent efforts have explored\nintroducing ReLU or its variants as the substitutive activation function to\nhelp LLMs achieve activation sparsity and inference acceleration, but few can\nsimultaneously obtain high sparsity and comparable model performance. This\npaper introduces a simple and effective sparsification method named \"ProSparse\"\nto push LLMs for higher activation sparsity while maintaining comparable\nperformance. Specifically, after substituting the activation function of LLMs\nwith ReLU, ProSparse adopts progressive sparsity regularization with a factor\nsmoothly increasing along the multi-stage sine curves. This can enhance\nactivation sparsity and mitigate performance degradation by avoiding radical\nshifts in activation distributions. With ProSparse, we obtain high sparsity of\n89.32% for LLaMA2-7B, 88.80% for LLaMA2-13B, and 87.89% for end-size\nMiniCPM-1B, respectively, achieving comparable performance to their original\nSwish-activated versions. These present the most sparsely activated models\namong open-source LLaMA versions and competitive end-size models, considerably\nsurpassing ReluLLaMA-7B (66.98%) and ReluLLaMA-13B (71.56%). Our inference\nacceleration experiments further demonstrate the significant practical\nacceleration potential of LLMs with higher activation sparsity, obtaining up to\n4.52$\\times$ inference speedup.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 4 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.13516v7",
    "published_date": "2024-02-21 03:58:49 UTC",
    "updated_date": "2025-01-07 05:26:54 UTC"
  },
  {
    "arxiv_id": "2402.13514v2",
    "title": "Self-DC: When to Reason and When to Act? Self Divide-and-Conquer for Compositional Unknown Questions",
    "authors": [
      "Hongru Wang",
      "Boyang Xue",
      "Baohang Zhou",
      "Tianhua Zhang",
      "Cunxiang Wang",
      "Huimin Wang",
      "Guanhua Chen",
      "Kam-fai Wong"
    ],
    "abstract": "Previous research has typically concentrated on leveraging the internal\nknowledge of Large Language Models (LLMs) to answer known questions (i.e.,\n\\textit{internal reasoning such as generate-then-read}). In contrast, for\nquestions that fall outside their known scope, these models rely on external\nknowledge retrieval to provide accurate responses (i.e., \\textit{external\nacting such as retrieve-then-read}). However, few previous works consider the\n\\textit{compositional questions}, which consist of several known and unknown\nsub-questions, necessitating the dynamic combination of previous two methods\n(i.e., \\textit{internal reasoning and external acting}) to achieve a better\ntrade-off between effectiveness and efficiency. To this end, we introduce a\n\\textbf{Self} \\textbf{D}ivide-and-\\textbf{C}onquer (\\textit{\\texttt{Self-DC}})\nframework, accompanying with the first \\textbf{C}ompositional \\textbf{u}nknown\n\\textbf{Q}uestion-\\textbf{A}nswering dataset (CuQA). This framework enables\nLLMs to adaptively choose between using internal knowledge and retrieving\nexternal knowledge as needed, resulting in a better trade-off between\neffectiveness and efficiency. Experimental results on two datasets demonstrate\nthat \\textit{\\texttt{Self-DC}} can achieve comparable or even better\nperformance with much fewer external calls compared with several strong\nbaselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13514v2",
    "published_date": "2024-02-21 03:55:02 UTC",
    "updated_date": "2025-01-25 22:44:29 UTC"
  },
  {
    "arxiv_id": "2402.13512v1",
    "title": "From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers",
    "authors": [
      "M. Emrullah Ildiz",
      "Yixiao Huang",
      "Yingcong Li",
      "Ankit Singh Rawat",
      "Samet Oymak"
    ],
    "abstract": "Modern language models rely on the transformer architecture and attention\nmechanism to perform language understanding and text generation. In this work,\nwe study learning a 1-layer self-attention model from a set of prompts and\nassociated output data sampled from the model. We first establish a precise\nmapping between the self-attention mechanism and Markov models: Inputting a\nprompt to the model samples the output token according to a context-conditioned\nMarkov chain (CCMC) which weights the transition matrix of a base Markov chain.\nAdditionally, incorporating positional encoding results in position-dependent\nscaling of the transition probabilities. Building on this formalism, we develop\nidentifiability/coverage conditions for the prompt distribution that guarantee\nconsistent estimation and establish sample complexity guarantees under IID\nsamples. Finally, we study the problem of learning from a single output\ntrajectory generated from an initial prompt. We characterize an intriguing\nwinner-takes-all phenomenon where the generative process implemented by\nself-attention collapses into sampling a limited subset of tokens due to its\nnon-mixing nature. This provides a mathematical explanation to the tendency of\nmodern LLMs to generate repetitive text. In summary, the equivalence to CCMC\nprovides a simple but powerful framework to study self-attention and its\nproperties.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.13512v1",
    "published_date": "2024-02-21 03:51:34 UTC",
    "updated_date": "2024-02-21 03:51:34 UTC"
  },
  {
    "arxiv_id": "2402.14033v1",
    "title": "VN Network: Embedding Newly Emerging Entities with Virtual Neighbors",
    "authors": [
      "Yongquan He",
      "Zihan Wang",
      "Peng Zhang",
      "Zhaopeng Tu",
      "Zhaochun Ren"
    ],
    "abstract": "Embedding entities and relations into continuous vector spaces has attracted\na surge of interest in recent years. Most embedding methods assume that all\ntest entities are available during training, which makes it time-consuming to\nretrain embeddings for newly emerging entities. To address this issue, recent\nworks apply the graph neural network on the existing neighbors of the unseen\nentities. In this paper, we propose a novel framework, namely Virtual Neighbor\n(VN) network, to address three key challenges. Firstly, to reduce the neighbor\nsparsity problem, we introduce the concept of the virtual neighbors inferred by\nrules. And we assign soft labels to these neighbors by solving a\nrule-constrained problem, rather than simply regarding them as unquestionably\ntrue. Secondly, many existing methods only use one-hop or two-hop neighbors for\naggregation and ignore the distant information that may be helpful. Instead, we\nidentify both logic and symmetric path rules to capture complex patterns.\nFinally, instead of one-time injection of rules, we employ an iterative\nlearning scheme between the embedding method and virtual neighbor prediction to\ncapture the interactions within. Experimental results on two knowledge graph\ncompletion tasks demonstrate that our VN network significantly outperforms\nstate-of-the-art baselines. Furthermore, results on Subject/Object-R show that\nour proposed VN network is highly robust to the neighbor sparsity problem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.4; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14033v1",
    "published_date": "2024-02-21 03:04:34 UTC",
    "updated_date": "2024-02-21 03:04:34 UTC"
  },
  {
    "arxiv_id": "2402.13482v1",
    "title": "Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks",
    "authors": [
      "Minju Seo",
      "Jinheon Baek",
      "James Thorne",
      "Sung Ju Hwang"
    ],
    "abstract": "Despite large successes of recent language models on diverse tasks, they\nsuffer from severe performance degeneration in low-resource settings with\nlimited training data available. Many existing works tackle this problem by\ngenerating synthetic data from the training data and then training models on\nthem, recently using Large Language Models (LLMs). However, in low-resource\nsettings, the amount of seed data samples to use for data augmentation is very\nsmall, which makes generated samples suboptimal and less diverse. To tackle\nthis challenge, we propose a novel method that augments training data by\nincorporating a wealth of examples from other datasets, along with the given\ntraining data. Specifically, we first retrieve the relevant instances from\nother datasets, such as their input-output pairs or contexts, based on their\nsimilarities with the given seed data, and then prompt LLMs to generate new\nsamples with the contextual information within and across the original and\nretrieved samples. This approach can ensure that the generated data is not only\nrelevant but also more diverse than what could be achieved using the limited\nseed data alone. We validate our proposed Retrieval-Augmented Data Augmentation\n(RADA) framework on multiple datasets under low-resource settings of training\nand test-time data augmentation scenarios, on which it outperforms existing\nLLM-powered data augmentation baselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13482v1",
    "published_date": "2024-02-21 02:45:46 UTC",
    "updated_date": "2024-02-21 02:45:46 UTC"
  },
  {
    "arxiv_id": "2402.13481v1",
    "title": "Learning to Model Diverse Driving Behaviors in Highly Interactive Autonomous Driving Scenarios with Multi-Agent Reinforcement Learning",
    "authors": [
      "Liu Weiwei",
      "Hu Wenxuan",
      "Jing Wei",
      "Lei Lanxin",
      "Gao Lingping",
      "Liu Yong"
    ],
    "abstract": "Autonomous vehicles trained through Multi-Agent Reinforcement Learning (MARL)\nhave shown impressive results in many driving scenarios. However, the\nperformance of these trained policies can be impacted when faced with diverse\ndriving styles and personalities, particularly in highly interactive\nsituations. This is because conventional MARL algorithms usually operate under\nthe assumption of fully cooperative behavior among all agents and focus on\nmaximizing team rewards during training. To address this issue, we introduce\nthe Personality Modeling Network (PeMN), which includes a cooperation value\nfunction and personality parameters to model the varied interactions in\nhigh-interactive scenarios. The PeMN also enables the training of a background\ntraffic flow with diverse behaviors, thereby improving the performance and\ngeneralization of the ego vehicle. Our extensive experimental studies, which\nincorporate different personality parameters in high-interactive driving\nscenarios, demonstrate that the personality parameters effectively model\ndiverse driving styles and that policies trained with PeMN demonstrate better\ngeneralization compared to traditional MARL methods.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13481v1",
    "published_date": "2024-02-21 02:44:33 UTC",
    "updated_date": "2024-02-21 02:44:33 UTC"
  },
  {
    "arxiv_id": "2402.13475v1",
    "title": "Multi-scale Spatio-temporal Transformer-based Imbalanced Longitudinal Learning for Glaucoma Forecasting from Irregular Time Series Images",
    "authors": [
      "Xikai Yang",
      "Jian Wu",
      "Xi Wang",
      "Yuchen Yuan",
      "Ning Li Wang",
      "Pheng-Ann Heng"
    ],
    "abstract": "Glaucoma is one of the major eye diseases that leads to progressive optic\nnerve fiber damage and irreversible blindness, afflicting millions of\nindividuals. Glaucoma forecast is a good solution to early screening and\nintervention of potential patients, which is helpful to prevent further\ndeterioration of the disease. It leverages a series of historical fundus images\nof an eye and forecasts the likelihood of glaucoma occurrence in the future.\nHowever, the irregular sampling nature and the imbalanced class distribution\nare two challenges in the development of disease forecasting approaches. To\nthis end, we introduce the Multi-scale Spatio-temporal Transformer Network\n(MST-former) based on the transformer architecture tailored for sequential\nimage inputs, which can effectively learn representative semantic information\nfrom sequential images on both temporal and spatial dimensions. Specifically,\nwe employ a multi-scale structure to extract features at various resolutions,\nwhich can largely exploit rich spatial information encoded in each image.\nBesides, we design a time distance matrix to scale time attention in a\nnon-linear manner, which could effectively deal with the irregularly sampled\ndata. Furthermore, we introduce a temperature-controlled Balanced Softmax\nCross-entropy loss to address the class imbalance issue. Extensive experiments\non the Sequential fundus Images for Glaucoma Forecast (SIGF) dataset\ndemonstrate the superiority of the proposed MST-former method, achieving an AUC\nof 98.6% for glaucoma forecasting. Besides, our method shows excellent\ngeneralization capability on the Alzheimer's Disease Neuroimaging Initiative\n(ADNI) MRI dataset, with an accuracy of 90.3% for mild cognitive impairment and\nAlzheimer's disease prediction, outperforming the compared method by a large\nmargin.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.13475v1",
    "published_date": "2024-02-21 02:16:59 UTC",
    "updated_date": "2024-02-21 02:16:59 UTC"
  },
  {
    "arxiv_id": "2402.13463v4",
    "title": "RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models",
    "authors": [
      "Jianhao Yan",
      "Yun Luo",
      "Yue Zhang"
    ],
    "abstract": "The application scope of large language models (LLMs) is increasingly\nexpanding. In practical use, users might provide feedback based on the model's\noutput, hoping for a responsive model that can complete responses according to\ntheir feedback. Whether the model can appropriately respond to users' refuting\nfeedback and consistently follow through with execution has not been thoroughly\nanalyzed. In light of this, this paper proposes a comprehensive benchmark,\nRefuteBench, covering tasks such as question answering, machine translation,\nand email writing. The evaluation aims to assess whether models can positively\naccept feedback in form of refuting instructions and whether they can\nconsistently adhere to user demands throughout the conversation. We conduct\nevaluations on numerous LLMs and find that LLMs are stubborn, i.e. exhibit\ninclination to their internal knowledge, often failing to comply with user\nfeedback. Additionally, as the length of the conversation increases, models\ngradually forget the user's stated feedback and roll back to their own\nresponses. We further propose a recall-and-repeat prompts as a simple and\neffective way to enhance the model's responsiveness to feedback.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 final version",
    "pdf_url": "http://arxiv.org/pdf/2402.13463v4",
    "published_date": "2024-02-21 01:39:56 UTC",
    "updated_date": "2024-07-24 06:50:18 UTC"
  },
  {
    "arxiv_id": "2402.13462v1",
    "title": "Potential and Challenges of Model Editing for Social Debiasing",
    "authors": [
      "Jianhao Yan",
      "Futing Wang",
      "Yafu Li",
      "Yue Zhang"
    ],
    "abstract": "Large language models (LLMs) trained on vast corpora suffer from inevitable\nstereotype biases. Mitigating these biases with fine-tuning could be both\ncostly and data-hungry. Model editing methods, which focus on modifying LLMs in\na post-hoc manner, are of great potential to address debiasing. However, it\nlacks a comprehensive study that facilitates both internal and external model\nediting methods, supports various bias types, as well as understands the pros\nand cons of applying editing methods to stereotypical debiasing. To mitigate\nthis gap, we carefully formulate social debiasing into an editing problem and\nbenchmark seven existing model editing algorithms on stereotypical debiasing,\ni.e., debias editing. Our findings in three scenarios reveal both the potential\nand challenges of debias editing: (1) Existing model editing methods can\neffectively preserve knowledge and mitigate biases, while the generalization of\ndebias effect from edited sentences to semantically equivalent sentences is\nlimited.(2) Sequential editing highlights the robustness of SERAC (Mitchell et\nal. 2022b), while internal editing methods degenerate with the number of edits.\n(3) Model editing algorithms achieve generalization towards unseen biases both\nwithin the same type and from different types. In light of these findings, we\nfurther propose two simple but effective methods to improve debias editing, and\nexperimentally show the effectiveness of the proposed methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2402.13462v1",
    "published_date": "2024-02-21 01:35:26 UTC",
    "updated_date": "2024-02-21 01:35:26 UTC"
  },
  {
    "arxiv_id": "2402.14861v1",
    "title": "CloudNine: Analyzing Meteorological Observation Impact on Weather Prediction Using Explainable Graph Neural Networks",
    "authors": [
      "Hyeon-Ju Jeon",
      "Jeon-Ho Kang",
      "In-Hyuk Kwon",
      "O-Joun Lee"
    ],
    "abstract": "The impact of meteorological observations on weather forecasting varies with\nsensor type, location, time, and other environmental factors. Thus,\nquantitative analysis of observation impacts is crucial for effective and\nefficient development of weather forecasting systems. However, the existing\nimpact analysis methods are difficult to be widely applied due to their high\ndependencies on specific forecasting systems. Also, they cannot provide\nobservation impacts at multiple spatio-temporal scales, only global impacts of\nobservation types. To address these issues, we present a novel system called\n``CloudNine,'' which allows analysis of individual observations' impacts on\nspecific predictions based on explainable graph neural networks (XGNNs).\nCombining an XGNN-based atmospheric state estimation model with a numerical\nweather prediction model, we provide a web application to search for\nobservations in the 3D space of the Earth system and to visualize the impact of\nindividual observations on predictions in specific spatial regions and time\nperiods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14861v1",
    "published_date": "2024-02-21 01:29:17 UTC",
    "updated_date": "2024-02-21 01:29:17 UTC"
  },
  {
    "arxiv_id": "2402.13457v2",
    "title": "A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models",
    "authors": [
      "Zihao Xu",
      "Yi Liu",
      "Gelei Deng",
      "Yuekang Li",
      "Stjepan Picek"
    ],
    "abstract": "Large Language Models (LLMS) have increasingly become central to generating\ncontent with potential societal impacts. Notably, these models have\ndemonstrated capabilities for generating content that could be deemed harmful.\nTo mitigate these risks, researchers have adopted safety training techniques to\nalign model outputs with societal values to curb the generation of malicious\ncontent. However, the phenomenon of \"jailbreaking\", where carefully crafted\nprompts elicit harmful responses from models, persists as a significant\nchallenge. This research conducts a comprehensive analysis of existing studies\non jailbreaking LLMs and their defense techniques. We meticulously investigate\nnine attack techniques and seven defense techniques applied across three\ndistinct language models: Vicuna, LLama, and GPT-3.5 Turbo. We aim to evaluate\nthe effectiveness of these attack and defense techniques. Our findings reveal\nthat existing white-box attacks underperform compared to universal techniques\nand that including special tokens in the input significantly affects the\nlikelihood of successful attacks. This research highlights the need to\nconcentrate on the security facets of LLMs. Additionally, we contribute to the\nfield by releasing our datasets and testing framework, aiming to foster further\nresearch into LLM security. We believe these contributions will facilitate the\nexploration of security measures within this domain.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "18 pages, 9 figures, Accepted in ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.13457v2",
    "published_date": "2024-02-21 01:26:39 UTC",
    "updated_date": "2024-05-17 05:00:24 UTC"
  },
  {
    "arxiv_id": "2402.14860v4",
    "title": "Ranking Large Language Models without Ground Truth",
    "authors": [
      "Amit Dhurandhar",
      "Rahul Nair",
      "Moninder Singh",
      "Elizabeth Daly",
      "Karthikeyan Natesan Ramamurthy"
    ],
    "abstract": "Evaluation and ranking of large language models (LLMs) has become an\nimportant problem with the proliferation of these models and their impact.\nEvaluation methods either require human responses which are expensive to\nacquire or use pairs of LLMs to evaluate each other which can be unreliable. In\nthis paper, we provide a novel perspective where, given a dataset of prompts\n(viz. questions, instructions, etc.) and a set of LLMs, we rank them without\naccess to any ground truth or reference responses. Inspired by real life where\nboth an expert and a knowledgeable person can identify a novice our main idea\nis to consider triplets of models, where each one of them evaluates the other\ntwo, correctly identifying the worst model in the triplet with high\nprobability. We also analyze our idea and provide sufficient conditions for it\nto succeed. Applying this idea repeatedly, we propose two methods to rank LLMs.\nIn experiments on different generative tasks (summarization, multiple-choice,\nand dialog), our methods reliably recover close to true rankings without\nreference data. This points to a viable low-resource mechanism for practical\nuse.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14860v4",
    "published_date": "2024-02-21 00:49:43 UTC",
    "updated_date": "2024-06-10 16:25:30 UTC"
  },
  {
    "arxiv_id": "2402.13448v2",
    "title": "ED-Copilot: Reduce Emergency Department Wait Time with Language Model Diagnostic Assistance",
    "authors": [
      "Liwen Sun",
      "Abhineet Agarwal",
      "Aaron Kornblith",
      "Bin Yu",
      "Chenyan Xiong"
    ],
    "abstract": "In the emergency department (ED), patients undergo triage and multiple\nlaboratory tests before diagnosis. This time-consuming process causes ED\ncrowding which impacts patient mortality, medical errors, staff burnout, etc.\nThis work proposes (time) cost-effective diagnostic assistance that leverages\nartificial intelligence systems to help ED clinicians make efficient and\naccurate diagnoses. In collaboration with ED clinicians, we use public patient\ndata to curate MIMIC-ED-Assist, a benchmark for AI systems to suggest\nlaboratory tests that minimize wait time while accurately predicting critical\noutcomes such as death. With MIMIC-ED-Assist, we develop ED-Copilot which\nsequentially suggests patient-specific laboratory tests and makes diagnostic\npredictions. ED-Copilot employs a pre-trained bio-medical language model to\nencode patient information and uses reinforcement learning to minimize ED wait\ntime and maximize prediction accuracy. On MIMIC-ED-Assist, ED-Copilot improves\nprediction accuracy over baselines while halving average wait time from four\nhours to two hours. ED-Copilot can also effectively personalize treatment\nrecommendations based on patient severity, further highlighting its potential\nas a diagnostic assistant. Since MIMIC-ED-Assist is a retrospective benchmark,\nED-Copilot is restricted to recommend only observed tests. We show ED-Copilot\nachieves competitive performance without this restriction as the maximum\nallowed time increases. Our code is available at\nhttps://github.com/cxcscmu/ED-Copilot.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13448v2",
    "published_date": "2024-02-21 00:49:42 UTC",
    "updated_date": "2024-05-27 22:30:46 UTC"
  },
  {
    "arxiv_id": "2402.13440v1",
    "title": "A Neuro-Symbolic Approach to Multi-Agent RL for Interpretability and Probabilistic Decision Making",
    "authors": [
      "Chitra Subramanian",
      "Miao Liu",
      "Naweed Khan",
      "Jonathan Lenchner",
      "Aporva Amarnath",
      "Sarathkrishna Swaminathan",
      "Ryan Riegel",
      "Alexander Gray"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) is well-suited for runtime\ndecision-making in optimizing the performance of systems where multiple agents\ncoexist and compete for shared resources. However, applying common deep\nlearning-based MARL solutions to real-world problems suffers from issues of\ninterpretability, sample efficiency, partial observability, etc. To address\nthese challenges, we present an event-driven formulation, where decision-making\nis handled by distributed co-operative MARL agents using neuro-symbolic\nmethods. The recently introduced neuro-symbolic Logical Neural Networks (LNN)\nframework serves as a function approximator for the RL, to train a rules-based\npolicy that is both logical and interpretable by construction. To enable\ndecision-making under uncertainty and partial observability, we developed a\nnovel probabilistic neuro-symbolic framework, Probabilistic Logical Neural\nNetworks (PLNN), which combines the capabilities of logical reasoning with\nprobabilistic graphical models. In PLNN, the upward/downward inference\nstrategy, inherited from LNN, is coupled with belief bounds by setting the\nactivation function for the logical operator associated with each neural\nnetwork node to a probability-respecting generalization of the Fr\\'echet\ninequalities. These PLNN nodes form the unifying element that combines\nprobabilistic logic and Bayes Nets, permitting inference for variables with\nunobserved states. We demonstrate our contributions by addressing key MARL\nchallenges for power sharing in a system-on-chip application.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.13440v1",
    "published_date": "2024-02-21 00:16:08 UTC",
    "updated_date": "2024-02-21 00:16:08 UTC"
  }
]