{
  "date": "2024-02-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-21 的 arXiv 中文 TLDR 快报！今天的 arXiv 更新聚焦于 AI 模型的安全性和优化、LLM 在多领域应用（如医疗和推荐系统）的潜力，以及高效计算方法的创新，其中 \"Cracking Factual Knowledge\" 和 \"ProSparse\" 等论文探讨了 LLM 的知识表示和稀疏性，突显了 AI 研究的前沿进展。\n\n今天共有 119 篇论文，我将优先讨论那些重要、具有话题性和影响力的文章，如 LLM 安全、医疗应用和高效模型优化，并将相关主题归类讨论。其他较次要的论文（如一些纯技术或领域特定的实验）将快速掠过，只提核心点。\n\n### LLM 安全与优化\n- **Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models**（英文原题：Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models）  \n  这篇论文分析了 LLM 中退化知识神经元（Degenerate Knowledge Neurons），发现它们影响模型的鲁棒性和知识存储，主要贡献是通过神经拓扑聚类方法精确识别这些神经元，并探讨了其与模型复杂性的关系，揭示了 LLM 知识表示的潜在缺陷。\n\n- **Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models**（英文原题：Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models）  \n  作者探讨了 LLM 水印在跨语言翻译中的鲁棒性，发现现有水印易被去除；主要发现是通过 Cross-lingual Watermark Removal Attack 攻击方法，提出 X-SIR 防御策略，提升了水印的跨语言一致性。\n\n- **ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models**（英文原题：ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models）  \n  这篇论文引入了激活稀疏性（Intrinsic Activation Sparsity）来优化 LLM，贡献在于提出渐进式稀疏正则化方法，使 LLaMA 模型在保持性能的同时实现高达 89% 的稀疏率，显著提升了推理效率。\n\n- **Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement**（英文原题：Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement）  \n  针对 LLM 推理效率，论文提出 Recursive Speculative Decoding 算法，使用无放回采样和 Gumbel-Top-k 技巧加速生成，贡献在于减少计算开销，在固定预算下比基线方法快 2 倍。\n\n- **Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation**（英文原题：Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation）  \n  论文通过对比蒸馏（Distillation Contrastive Decoding）提升 LLM 推理能力，贡献在于结合 Dropout 和量化技术，在 GSM8K 和 StrategyQA 数据集上提升 6-29% 的性能，同时减少计算资源。\n\n其他 LLM 相关论文，如 \"Understanding the Dataset Practitioners Behind Large Language Model Development\"，快速提一下：它分析了 LLM 数据集从业者的角色，发现数据质量评估缺乏共识，但对 LLM 开发有启发。\n\n### 医疗与生物信息学应用\n- **On Large Visual Language Models for Medical Imaging Analysis: An Empirical Study**（英文原题：On Large Visual Language Models for Medical Imaging Analysis: An Empirical Study）  \n  这篇论文评估了视觉语言模型（VLMs）在医学图像分析中的零样本和少样本鲁棒性，主要发现 VLMs 在脑 MRI 和 X 光图像上表现出色，能有效检测疾病，填补了生物医学领域的应用空白。\n\n- **Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns**（英文原题：Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns）  \n  论文提出 Diet-ODIN 框架，使用异构图和 LLM 检测阿片类药物滥用，贡献在于结合饮食模式进行可解释预测，在数据集上提升了检测准确性，并揭示了饮食与药物滥用的相关性。\n\n- **SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings**（英文原题：SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings）  \n  针对临床视频隐私，论文开发了 SecurePose 软件，实现自动化面部模糊和运动学提取，主要发现它在脑瘫患者视频上比手动方法快 91%，并提供高可用性。\n\n其他医疗论文，如 \"Probabilistic Neural Networks for Modeling Aleatoric Uncertainty\"，快速掠过：它使用神经网络建模不确定性，在药物响应预测中提升了准确性。\n\n### 多代理系统与推荐\n- **Blending Data-Driven Priors in Dynamic Games**（英文原题：Blending Data-Driven Priors in Dynamic Games）  \n  论文提出 KLGame 算法，用于多代理动态游戏中的策略融合，贡献在于结合数据驱动和优化方法，提高了自动驾驶场景中的交互鲁棒性。\n\n- **Social Environment Design**（英文原题：Social Environment Design）  \n  作者引入多代理强化学习框架设计社会环境，贡献在于提出新框架用于政策模拟，强调 AI 在政府决策中的潜力。\n\n其他推荐系统论文，如 \"Multi-view Intent Learning and Alignment with Large Language Models for Session-based Recommendation\"，快速提一下：它使用 LLM 提升推荐系统的意图学习，改善了用户互动。\n\n### 其他亮点\n- **DeiSAM: Segment Anything with Deictic Prompting**（英文原题：DeiSAM: Segment Anything with Deictic Prompting）  \n  论文将 LLM 与逻辑推理结合，实现指示性提示下的图像分割，贡献在于提出 DeiVG 数据集和 DeiSAM 框架，提升了视觉任务的零样本性能。\n\n- **FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models**（英文原题：FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models）  \n  构建了 FanOutQA 数据集，评估 LLM 在多跳问答中的性能，主要发现现有模型在复杂查询上仍有不足。\n\n剩余论文多为技术细节或特定领域实验（如 \"Energy-efficiency Limits on Training AI Systems\"），我快速掠过：它们提供了 AI 训练效率的理论界限，但影响较小，不做深入讨论。\n\n总之，今天的 arXiv 强调了 LLM 的安全和应用潜力，但也暴露了挑战，如知识偏差和计算效率。更多论文细节可查阅 arXiv 页面，保持关注 AI 领域的动态进展！",
  "papers": [
    {
      "arxiv_id": "2402.14881v1",
      "title": "A Study on the Vulnerability of Test Questions against ChatGPT-based Cheating",
      "title_zh": "翻译失败",
      "authors": [
        "Shanker Ram",
        "Chen Qian"
      ],
      "abstract": "ChatGPT is a chatbot that can answer text prompts fairly accurately, even\nperforming very well on postgraduate-level questions. Many educators have found\nthat their take-home or remote tests and exams are vulnerable to ChatGPT-based\ncheating because students may directly use answers provided by tools like\nChatGPT. In this paper, we try to provide an answer to an important question:\nhow well ChatGPT can answer test questions and how we can detect whether the\nquestions of a test can be answered correctly by ChatGPT. We generated\nChatGPT's responses to the MedMCQA dataset, which contains over 10,000 medical\nschool entrance exam questions. We analyzed the responses and uncovered certain\ntypes of questions ChatGPT answers more inaccurately than others. In addition,\nwe have created a basic natural language processing model to single out the\nmost vulnerable questions to ChatGPT in a collection of questions or a sample\nexam. Our tool can be used by test-makers to avoid ChatGPT-vulnerable test\nquestions.",
      "tldr_zh": "本研究探讨了测试问题对ChatGPT-based作弊的脆弱性，分析ChatGPT在回答各种考试问题时的准确性。研究者使用MedMCQA数据集（包含超过10,000个医学院入学考试问题）生成ChatGPT的响应，发现某些问题类型（如特定复杂查询）更容易导致ChatGPT回答不准确。论文还开发了一个基本的natural language processing (NLP)模型，用于识别和筛选出最易受ChatGPT影响的问题类型，从而帮助考试制定者设计更安全的测试。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "2023 International Conference on Machine Learning and Applications\n  (ICMLA)",
      "pdf_url": "http://arxiv.org/pdf/2402.14881v1",
      "published_date": "2024-02-21 23:51:06 UTC",
      "updated_date": "2024-02-21 23:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:29:43.089097"
    },
    {
      "arxiv_id": "2402.16611v2",
      "title": "Understanding the Dataset Practitioners Behind Large Language Model Development",
      "title_zh": "翻译失败",
      "authors": [
        "Crystal Qian",
        "Emily Reif",
        "Minsuk Kahng"
      ],
      "abstract": "As large language models (LLMs) become more advanced and impactful, it is\nincreasingly important to scrutinize the data that they rely upon and produce.\nWhat is it to be a dataset practitioner doing this work? We approach this in\ntwo parts: first, we define the role of \"dataset practitioners\" by performing a\nretrospective analysis on the responsibilities of teams contributing to LLM\ndevelopment at a technology company, Google. Then, we conduct semi-structured\ninterviews with a cross-section of these practitioners (N=10). We find that\nalthough data quality is a top priority, there is little consensus around what\ndata quality is and how to evaluate it. Consequently, practitioners either rely\non their own intuition or write custom code to evaluate their data. We discuss\npotential reasons for this phenomenon and opportunities for alignment.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)开发中数据集从业者(dataset practitioners)的角色，通过回顾Google团队的责任和对10位从业者的半结构化访谈进行分析。研究发现，虽然数据质量是首要优先事项，但业界缺乏对数据质量的共识，导致从业者主要依赖个人直觉或编写自定义代码来评估数据。主要贡献包括讨论这一现象的潜在原因，并提出机会以实现数据质量评估的标准化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 figures. To be published in In Extended Abstracts of the\n  CHI Conference on Human Factors in Computing Systems (CHI EA '24). Revised to\n  reflect updates from CHI LBW reviewer feedback",
      "pdf_url": "http://arxiv.org/pdf/2402.16611v2",
      "published_date": "2024-02-21 23:50:37 UTC",
      "updated_date": "2024-04-01 19:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:29:54.583888"
    },
    {
      "arxiv_id": "2402.14179v1",
      "title": "Bangla AI: A Framework for Machine Translation Utilizing Large Language Models for Ethnic Media",
      "title_zh": "翻译失败",
      "authors": [
        "MD Ashraful Goni",
        "Fahad Mostafa",
        "Kerk F. Kee"
      ],
      "abstract": "Ethnic media, which caters to diaspora communities in host nations, serves as\na vital platform for these communities to both produce content and access\ninformation. Rather than utilizing the language of the host nation, ethnic\nmedia delivers news in the language of the immigrant community. For instance,\nin the USA, Bangla ethnic media presents news in Bangla rather than English.\nThis research delves into the prospective integration of large language models\n(LLM) and multi-lingual machine translations (MMT) within the ethnic media\nindustry. It centers on the transformative potential of using LLM in MMT in\nvarious facets of news translation, searching, and categorization. The paper\noutlines a theoretical framework elucidating the integration of LLM and MMT\ninto the news searching and translation processes for ethnic media.\nAdditionally, it briefly addresses the potential ethical challenges associated\nwith the incorporation of LLM and MMT in news translation procedures.",
      "tldr_zh": "本研究提出 Bangla AI 框架，利用 Large Language Models (LLM) 和 Multi-lingual Machine Translation (MMT) 来提升民族媒体的新闻翻译、搜索和分类能力，针对 diaspora 社区提供本土语言内容，如美国孟加拉语媒体使用 Bangla 而非英语。框架详细阐述了将 LLM 和 MMT 整合到新闻处理流程中的理论模型，强调其在变革新闻传播方面的潜力。论文同时讨论了相关伦理挑战，如潜在的偏见和隐私问题，以确保技术的负责任应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 Pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2402.14179v1",
      "published_date": "2024-02-21 23:43:04 UTC",
      "updated_date": "2024-02-21 23:43:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:30:07.292849"
    },
    {
      "arxiv_id": "2402.14174v3",
      "title": "Blending Data-Driven Priors in Dynamic Games",
      "title_zh": "在动态博弈中融合数据驱动先验",
      "authors": [
        "Justin Lidard",
        "Haimin Hu",
        "Asher Hancock",
        "Zixu Zhang",
        "Albert Gimó Contreras",
        "Vikash Modi",
        "Jonathan DeCastro",
        "Deepak Gopinath",
        "Guy Rosman",
        "Naomi Ehrich Leonard",
        "María Santos",
        "Jaime Fernández Fisac"
      ],
      "abstract": "As intelligent robots like autonomous vehicles become increasingly deployed\nin the presence of people, the extent to which these systems should leverage\nmodel-based game-theoretic planners versus data-driven policies for safe,\ninteraction-aware motion planning remains an open question. Existing dynamic\ngame formulations assume all agents are task-driven and behave optimally.\nHowever, in reality, humans tend to deviate from the decisions prescribed by\nthese models, and their behavior is better approximated under a noisy-rational\nparadigm. In this work, we investigate a principled methodology to blend a\ndata-driven reference policy with an optimization-based game-theoretic policy.\nWe formulate KLGame, an algorithm for solving non-cooperative dynamic game with\nKullback-Leibler (KL) regularization with respect to a general, stochastic, and\npossibly multi-modal reference policy. Our method incorporates, for each\ndecision maker, a tunable parameter that permits modulation between task-driven\nand data-driven behaviors. We propose an efficient algorithm for computing\nmulti-modal approximate feedback Nash equilibrium strategies of KLGame in real\ntime. Through a series of simulated and real-world autonomous driving\nscenarios, we demonstrate that KLGame policies can more effectively incorporate\nguidance from the reference policy and account for noisily-rational human\nbehaviors versus non-regularized baselines. Website with additional\ninformation, videos, and code: https://kl-games.github.io/.",
      "tldr_zh": "本文探讨了在动态游戏中融合数据驱动策略的问题，以提升智能机器人（如自动驾驶车辆）在与人类互动时的安全规划。论文提出 KLGame 算法，通过 Kullback-Leibler (KL) regularization 将一个随机、多模态的参考策略与优化-based 游戏理论策略相结合，每个决策者可通过可调参数在任务驱动和数据驱动行为间调节。实验结果显示，KLGame 在模拟和真实自动驾驶场景中，比非正则化基线更有效地整合参考策略并处理人类的 noisy-rational 行为，提高了交互aware 运动规划的性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14174v3",
      "published_date": "2024-02-21 23:22:32 UTC",
      "updated_date": "2024-07-07 02:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:30:20.911989"
    },
    {
      "arxiv_id": "2402.14162v1",
      "title": "On Large Visual Language Models for Medical Imaging Analysis: An Empirical Study",
      "title_zh": "翻译失败",
      "authors": [
        "Minh-Hao Van",
        "Prateek Verma",
        "Xintao Wu"
      ],
      "abstract": "Recently, large language models (LLMs) have taken the spotlight in natural\nlanguage processing. Further, integrating LLMs with vision enables the users to\nexplore emergent abilities with multimodal data. Visual language models (VLMs),\nsuch as LLaVA, Flamingo, or CLIP, have demonstrated impressive performance on\nvarious visio-linguistic tasks. Consequently, there are enormous applications\nof large models that could be potentially used in the biomedical imaging field.\nAlong that direction, there is a lack of related work to show the ability of\nlarge models to diagnose the diseases. In this work, we study the zero-shot and\nfew-shot robustness of VLMs on the medical imaging analysis tasks. Our\ncomprehensive experiments demonstrate the effectiveness of VLMs in analyzing\nbiomedical images such as brain MRIs, microscopic images of blood cells, and\nchest X-rays.",
      "tldr_zh": "这篇论文通过实证研究探讨了大型视觉语言模型（VLMs），如 LLaVA、Flamingo 和 CLIP，在医疗图像分析中的应用潜力。研究重点评估了 VLMs 在零样本（zero-shot）和少样本（few-shot）场景下的鲁棒性，包括脑部 MRI、血液细胞显微图像和胸部 X 光片等任务。结果显示，VLMs 在这些生物医学图像分析中表现出色，证明了其在诊断疾病方面的有效性，并填补了相关领域的应用研究空白。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14162v1",
      "published_date": "2024-02-21 23:01:38 UTC",
      "updated_date": "2024-02-21 23:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:30:31.769419"
    },
    {
      "arxiv_id": "2402.14160v2",
      "title": "Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement",
      "title_zh": "翻译失败",
      "authors": [
        "Wonseok Jeon",
        "Mukul Gagrani",
        "Raghavv Goel",
        "Junyoung Park",
        "Mingu Lee",
        "Christopher Lott"
      ],
      "abstract": "Speculative decoding is an inference-acceleration method for large language\nmodels (LLMs) where a small language model generates a draft-token sequence\nwhich is further verified by the target LLM in parallel. Recent works have\nadvanced this method by establishing a draft-token tree, achieving superior\nperformance over a single-sequence speculative decoding. However, those works\nindependently generate tokens at each level of the tree, not leveraging the\ntree's entire diversifiability. Besides, their empirical superiority has been\nshown for fixed length of sequences, implicitly granting more computational\nresource to LLM for the tree-based methods. None of the existing works has\nconducted empirical studies with fixed target computational budgets despite its\nimportance to resource-bounded devices. We present Recursive Speculative\nDecoding (RSD), a novel tree-based method that samples draft tokens without\nreplacement and maximizes the diversity of the tree. During RSD's drafting, the\ntree is built by either Gumbel-Top-$k$ trick that draws tokens without\nreplacement in parallel or Stochastic Beam Search that samples sequences\nwithout replacement while early-truncating unlikely draft sequences and\nreducing the computational cost of LLM. We empirically evaluate RSD with Llama\n2 and OPT models, showing that RSD outperforms the baseline methods,\nconsistently for fixed draft sequence length and in most cases for fixed\ncomputational budgets at LLM.",
      "tldr_zh": "本研究提出Recursive Speculative Decoding (RSD)，一种新型树-based 方法，用于加速大型语言模型 (LLMs) 的推理过程，通过无放回采样最大化草稿令牌树的多样性，以解决现有方法未充分利用树多样性和计算资源限制的问题。RSD 在构建树时采用Gumbel-Top-k 技巧进行并行无放回采样，或使用Stochastic Beam Search 采样序列，同时通过提前截断低概率序列来降低LLM的计算成本。在Llama 2 和 OPT 模型上的实验表明，RSD 优于基线方法，在固定草稿序列长度和大多数固定计算预算情况下均表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "82 pages, 9 figures, 54 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.14160v2",
      "published_date": "2024-02-21 22:57:49 UTC",
      "updated_date": "2024-03-05 06:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:30:44.057957"
    },
    {
      "arxiv_id": "2402.14155v1",
      "title": "Can Similarity-Based Domain-Ordering Reduce Catastrophic Forgetting for Intent Recognition?",
      "title_zh": "基于相似性的领域排序能否减少意图识别中的灾难性遗忘？",
      "authors": [
        "Amogh Mannekote",
        "Xiaoyi Tian",
        "Kristy Elizabeth Boyer",
        "Bonnie J. Dorr"
      ],
      "abstract": "Task-oriented dialogue systems are expected to handle a constantly expanding\nset of intents and domains even after they have been deployed to support more\nand more functionalities. To live up to this expectation, it becomes critical\nto mitigate the catastrophic forgetting problem (CF) that occurs in continual\nlearning (CL) settings for a task such as intent recognition. While existing\ndialogue systems research has explored replay-based and regularization-based\nmethods to this end, the effect of domain ordering on the CL performance of\nintent recognition models remains unexplored. If understood well, domain\nordering has the potential to be an orthogonal technique that can be leveraged\nalongside existing techniques such as experience replay. Our work fills this\ngap by comparing the impact of three domain-ordering strategies (min-sum path,\nmax-sum path, random) on the CL performance of a generative intent recognition\nmodel. Our findings reveal that the min-sum path strategy outperforms the\nothers in reducing catastrophic forgetting when training on the 220M T5-Base\nmodel. However, this advantage diminishes with the larger 770M T5-Large model.\nThese results underscores the potential of domain ordering as a complementary\nstrategy for mitigating catastrophic forgetting in continually learning intent\nrecognition models, particularly in resource-constrained scenarios.",
      "tldr_zh": "本研究探讨了基于相似性的领域排序（domain ordering）是否能减少任务导向对话系统在持续学习（continual learning）中处理意图识别时的灾难性遗忘（Catastrophic Forgetting）。作者比较了三种领域排序策略——min-sum path、max-sum path 和 random——在 T5-Base (220M) 和 T5-Large (770M) 模型上的性能。结果显示，min-sum path 策略在 T5-Base 模型上表现出色，能显著降低遗忘问题，但其优势在 T5-Large 模型上减弱。这些发现表明，领域排序可作为现有方法（如经验回放）的补充策略，特别适用于资源受限的场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14155v1",
      "published_date": "2024-02-21 22:30:57 UTC",
      "updated_date": "2024-02-21 22:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:30:57.062128"
    },
    {
      "arxiv_id": "2402.14880v1",
      "title": "Automatic Histograms: Leveraging Language Models for Text Dataset Exploration",
      "title_zh": "自动直方图：利用语言模型进行文本数据集探索",
      "authors": [
        "Emily Reif",
        "Crystal Qian",
        "James Wexler",
        "Minsuk Kahng"
      ],
      "abstract": "Making sense of unstructured text datasets is perennially difficult, yet\nincreasingly relevant with Large Language Models. Data workers often rely on\ndataset summaries, especially distributions of various derived features. Some\nfeatures, like toxicity or topics, are relevant to many datasets, but many\ninteresting features are domain specific: instruments and genres for a music\ndataset, or diseases and symptoms for a medical dataset. Accordingly, data\nworkers often run custom analyses for each dataset, which is cumbersome and\ndifficult. We present AutoHistograms, a visualization tool leveragingLLMs.\nAutoHistograms automatically identifies relevant features, visualizes them with\nhistograms, and allows the user to interactively query the dataset for\ncategories of entities and create new histograms. In a user study with 10 data\nworkers (n=10), we observe that participants can quickly identify insights and\nexplore the data using AutoHistograms, and conceptualize a broad range of\napplicable use cases. Together, this tool and user study contributeto the\ngrowing field of LLM-assisted sensemaking tools.",
      "tldr_zh": "本文提出 Automatic Histograms，一种利用 Large Language Models (LLMs) 的可视化工具，用于简化非结构化文本数据集的探索。该工具自动识别相关特征（如毒性、主题或领域特定元素，如音乐中的乐器或医疗中的疾病），并通过直方图可视化这些特征，同时支持用户交互查询和创建新直方图。在用户研究（n=10）中，参与者能够快速识别数据洞见并扩展适用场景，为 LLM 辅助的感知工具领域提供了新贡献。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14880v1",
      "published_date": "2024-02-21 22:29:16 UTC",
      "updated_date": "2024-02-21 22:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:31:08.002506"
    },
    {
      "arxiv_id": "2402.14151v2",
      "title": "BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyue Wang",
        "Jianyou Wang",
        "Weili Cao",
        "Kaicheng Wang",
        "Ramamohan Paturi",
        "Leon Bergen"
      ],
      "abstract": "We present the Benchmark of Information Retrieval (IR) tasks with Complex\nObjectives (BIRCO). BIRCO evaluates the ability of IR systems to retrieve\ndocuments given multi-faceted user objectives. The benchmark's complexity and\ncompact size make it suitable for evaluating large language model (LLM)-based\ninformation retrieval systems. We present a modular framework for investigating\nfactors that may influence LLM performance on retrieval tasks, and identify a\nsimple baseline model which matches or outperforms existing approaches and more\ncomplex alternatives. No approach achieves satisfactory performance on all\nbenchmark tasks, suggesting that stronger models and new retrieval protocols\nare necessary to address complex user needs.",
      "tldr_zh": "本研究引入了 BIRCO 基准测试，用于评估信息检索 (IR) 系统处理多方面用户目标的能力。BIRCO 的设计复杂且紧凑，特别适合测试基于大型语言模型 (LLM) 的检索系统，并提供一个模块化框架来探索影响 LLM 性能的因素。研究发现，一个简单基线模型能与现有方法匹敌或优于更复杂的替代方案，但没有方法在所有任务上达到满意水平，表明需要更强的模型和新颖的检索协议来满足复杂用户需求。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14151v2",
      "published_date": "2024-02-21 22:22:30 UTC",
      "updated_date": "2024-04-03 20:11:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:31:19.097938"
    },
    {
      "arxiv_id": "2402.14147v1",
      "title": "Wikibench: Community-Driven Data Curation for AI Evaluation on Wikipedia",
      "title_zh": "翻译失败",
      "authors": [
        "Tzu-Sheng Kuo",
        "Aaron Halfaker",
        "Zirui Cheng",
        "Jiwoo Kim",
        "Meng-Hsin Wu",
        "Tongshuang Wu",
        "Kenneth Holstein",
        "Haiyi Zhu"
      ],
      "abstract": "AI tools are increasingly deployed in community contexts. However, datasets\nused to evaluate AI are typically created by developers and annotators outside\na given community, which can yield misleading conclusions about AI performance.\nHow might we empower communities to drive the intentional design and curation\nof evaluation datasets for AI that impacts them? We investigate this question\non Wikipedia, an online community with multiple AI-based content moderation\ntools deployed. We introduce Wikibench, a system that enables communities to\ncollaboratively curate AI evaluation datasets, while navigating ambiguities and\ndifferences in perspective through discussion. A field study on Wikipedia shows\nthat datasets curated using Wikibench can effectively capture community\nconsensus, disagreement, and uncertainty. Furthermore, study participants used\nWikibench to shape the overall data curation process, including refining label\ndefinitions, determining data inclusion criteria, and authoring data\nstatements. Based on our findings, we propose future directions for systems\nthat support community-driven data curation.",
      "tldr_zh": "这篇论文探讨了AI评估数据集的社区驱动整理问题，强调由外部创建的数据集可能导致对AI性能的误导性结论，并提出让社区主导数据设计的方法。研究引入Wikibench系统，允许Wikipedia社区通过协作讨论处理歧义和视角差异，从而共同整理AI evaluation datasets。实地研究显示，该系统能有效捕捉社区共识、分歧和不确定性，并让参与者参与标签定义、数据包含标准和数据声明的制定。最终，论文基于这些发现，提出未来支持community-driven data curation的系统设计方向。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14147v1",
      "published_date": "2024-02-21 22:10:21 UTC",
      "updated_date": "2024-02-21 22:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:31:32.921231"
    },
    {
      "arxiv_id": "2402.14143v1",
      "title": "SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Rishabh Bajpai",
        "Bhooma Aravamuthan"
      ],
      "abstract": "Movement disorders are typically diagnosed by consensus-based expert\nevaluation of clinically acquired patient videos. However, such broad sharing\nof patient videos poses risks to patient privacy. Face blurring can be used to\nde-identify videos, but this process is often manual and time-consuming.\nAvailable automated face blurring techniques are subject to either excessive,\ninconsistent, or insufficient facial blurring - all of which can be disastrous\nfor video assessment and patient privacy. Furthermore, assessing movement\ndisorders in these videos is often subjective. The extraction of quantifiable\nkinematic features can help inform movement disorder assessment in these\nvideos, but existing methods to do this are prone to errors if using\npre-blurred videos. We have developed an open-source software called SecurePose\nthat can both achieve reliable face blurring and automated kinematic extraction\nin patient videos recorded in a clinic setting using an iPad. SecurePose,\nextracts kinematics using a pose estimation method (OpenPose), tracks and\nuniquely identifies all individuals in the video, identifies the patient, and\nperforms face blurring. The software was validated on gait videos recorded in\noutpatient clinic visits of 116 children with cerebral palsy. The validation\ninvolved assessing intermediate steps of kinematics extraction and face\nblurring with manual blurring (ground truth). Moreover, when SecurePose was\ncompared with six selected existing methods, it outperformed other methods in\nautomated face detection and achieved ceiling accuracy in 91.08% less time than\na robust manual face blurring method. Furthermore, ten experienced researchers\nfound SecurePose easy to learn and use, as evidenced by the System Usability\nScale. The results of this work validated the performance and usability of\nSecurePose on clinically recorded gait videos for face blurring and kinematics\nextraction.",
      "tldr_zh": "这篇论文介绍了 SecurePose，一款开源软件，用于自动模糊临床视频中的面部并提取人体运动学特征，从而保护患者隐私并提升运动障碍诊断的客观性。SecurePose 采用 OpenPose 姿势估计技术，结合个体跟踪和识别功能，对视频进行可靠的面部模糊和运动学数据提取。在对 116 名脑瘫儿童步态视频的验证中，该软件在面部检测准确性上优于六种现有方法，处理速度比手动模糊快 91.08%，并被经验研究人员评为易学易用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14143v1",
      "published_date": "2024-02-21 21:55:29 UTC",
      "updated_date": "2024-02-21 21:55:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:31:46.076300"
    },
    {
      "arxiv_id": "2402.14879v1",
      "title": "Driving Generative Agents With Their Personality",
      "title_zh": "翻译失败",
      "authors": [
        "Lawrence J. Klinkert",
        "Stephanie Buongiorno",
        "Corey Clark"
      ],
      "abstract": "This research explores the potential of Large Language Models (LLMs) to\nutilize psychometric values, specifically personality information, within the\ncontext of video game character development. Affective Computing (AC) systems\nquantify a Non-Player character's (NPC) psyche, and an LLM can take advantage\nof the system's information by using the values for prompt generation. The\nresearch shows an LLM can consistently represent a given personality profile,\nthereby enhancing the human-like characteristics of game characters.\nRepurposing a human examination, the International Personality Item Pool (IPIP)\nquestionnaire, to evaluate an LLM shows that the model can accurately generate\ncontent concerning the personality provided. Results show that the improvement\nof LLM, such as the latest GPT-4 model, can consistently utilize and interpret\na personality to represent behavior.",
      "tldr_zh": "这篇论文探讨大型语言模型（LLMs）如何利用个性信息（如心理测量值）来驱动生成代理（Generative Agents），特别是在视频游戏角色开发中。通过情感计算（AC）系统量化非玩家角色（NPC）的心理，并使用国际个性项目池（IPIP）问卷评估，研究证明LLMs能一致地代表给定的人格配置文件，从而提升角色的拟人化特征。结果显示，改进的LLMs（如GPT-4）能够准确解释和生成与个性相符的行为，为游戏角色设计提供更真实可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 Pages, 4 figures, Draft",
      "pdf_url": "http://arxiv.org/pdf/2402.14879v1",
      "published_date": "2024-02-21 21:29:57 UTC",
      "updated_date": "2024-02-21 21:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:31:57.816749"
    },
    {
      "arxiv_id": "2402.14878v2",
      "title": "Energy-efficiency Limits on Training AI Systems using Learning-in-Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Chen",
        "Johannes Leugering",
        "Gert Cauwenberghs",
        "Shantanu Chakrabartty"
      ],
      "abstract": "Learning-in-memory (LIM) is a recently proposed paradigm to overcome\nfundamental memory bottlenecks in training machine learning systems. While\ncompute-in-memory (CIM) approaches can address the so-called memory-wall (i.e.\nenergy dissipated due to repeated memory read access) they are agnostic to the\nenergy dissipated due to repeated memory writes at the precision required for\ntraining (the update-wall), and they don't account for the energy dissipated\nwhen transferring information between short-term and long-term memories (the\nconsolidation-wall). The LIM paradigm proposes that these bottlenecks, too, can\nbe overcome if the energy barrier of physical memories is adaptively modulated\nsuch that the dynamics of memory updates and consolidation match the Lyapunov\ndynamics of gradient-descent training of an AI model. In this paper, we derive\nnew theoretical lower bounds on energy dissipation when training AI systems\nusing different LIM approaches. The analysis presented here is model-agnostic\nand highlights the trade-off between energy efficiency and the speed of\ntraining. The resulting non-equilibrium energy-efficiency bounds have a similar\nflavor as that of Landauer's energy-dissipation bounds. We also extend these\nlimits by taking into account the number of floating-point operations (FLOPs)\nused for training, the size of the AI model, and the precision of the training\nparameters. Our projections suggest that the energy-dissipation lower-bound to\ntrain a brain scale AI system (comprising of $10^{15}$ parameters) using LIM is\n$10^8 \\sim 10^9$ Joules, which is on the same magnitude the Landauer's\nadiabatic lower-bound and $6$ to $7$ orders of magnitude lower than the\nprojections obtained using state-of-the-art AI accelerator hardware\nlower-bounds.",
      "tldr_zh": "该论文探讨了使用 Learning-in-Memory (LIM) 范式训练 AI 系统的能量效率下限，LIM 通过动态调整物理内存能量屏障来克服传统 Compute-in-Memory (CIM) 无法解决的内存写入（update-wall）和信息整合（consolidation-wall）瓶颈，从而匹配梯度下降训练的 Lyapunov 动力学。研究推导了新的理论能量耗散下限，这些界限模型无关，并突出了能量效率与训练速度之间的权衡，类似于 Landauer's 能量耗散界限。论文还考虑了浮点运算（FLOPs）、AI 模型规模和参数精度，预测训练一个包含 10^15 参数的脑规模 AI 系统的最低能量耗散为 10^8 ~ 10^9 焦耳，比当前硬件下限低 6 到 7 个数量级。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14878v2",
      "published_date": "2024-02-21 21:02:11 UTC",
      "updated_date": "2024-05-21 20:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:32:10.376562"
    },
    {
      "arxiv_id": "2402.14123v2",
      "title": "DeiSAM: Segment Anything with Deictic Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Hikaru Shindo",
        "Manuel Brack",
        "Gopika Sudhakaran",
        "Devendra Singh Dhami",
        "Patrick Schramowski",
        "Kristian Kersting"
      ],
      "abstract": "Large-scale, pre-trained neural networks have demonstrated strong\ncapabilities in various tasks, including zero-shot image segmentation. To\nidentify concrete objects in complex scenes, humans instinctively rely on\ndeictic descriptions in natural language, i.e., referring to something\ndepending on the context such as \"The object that is on the desk and behind the\ncup.\". However, deep learning approaches cannot reliably interpret such deictic\nrepresentations due to their lack of reasoning capabilities in complex\nscenarios. To remedy this issue, we propose DeiSAM -- a combination of large\npre-trained neural networks with differentiable logic reasoners -- for deictic\npromptable segmentation. Given a complex, textual segmentation description,\nDeiSAM leverages Large Language Models (LLMs) to generate first-order logic\nrules and performs differentiable forward reasoning on generated scene graphs.\nSubsequently, DeiSAM segments objects by matching them to the logically\ninferred image regions. As part of our evaluation, we propose the Deictic\nVisual Genome (DeiVG) dataset, containing paired visual input and complex,\ndeictic textual prompts. Our empirical results demonstrate that DeiSAM is a\nsubstantial improvement over purely data-driven baselines for deictic\npromptable segmentation.",
      "tldr_zh": "论文提出 DeiSAM，一种结合大型预训练神经网络和可微逻辑推理器的框架，用于处理指示性（deictic）提示的图像分割任务，以解决深度学习模型在复杂场景中缺乏推理能力的局限性。该方法利用 Large Language Models (LLMs) 生成一阶逻辑规则，并在生成的场景图上进行可微前向推理，随后通过匹配逻辑推断的图像区域来实现物体分割。作为贡献，作者创建了 Deictic Visual Genome (DeiVG) 数据集用于评估，实验结果表明 DeiSAM 在 deictic promptable segmentation 任务上比纯数据驱动基线有显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14123v2",
      "published_date": "2024-02-21 20:43:49 UTC",
      "updated_date": "2024-12-05 13:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:32:22.189118"
    },
    {
      "arxiv_id": "2402.14118v1",
      "title": "Masked Matrix Multiplication for Emergent Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Wheatman",
        "Meghana Madhyastha",
        "Randal Burns"
      ],
      "abstract": "Artificial intelligence workloads, especially transformer models, exhibit\nemergent sparsity in which computations perform selective sparse access to\ndense data. The workloads are inefficient on hardware designed for dense\ncomputations and do not map well onto sparse data representations. We build a\nvectorized and parallel matrix-multiplication system A X B = C that eliminates\nunnecessary computations and avoids branches based on a runtime evaluation of\nsparsity. We use a combination of dynamic code lookup to adapt to the specific\nsparsity encoded in the B matrix and preprocessing of sparsity maps of the A\nand B matrices to compute conditional branches once for the whole computation.\nFor a wide range of sparsity, from 60% to 95% zeros, our implementation\nperforms fewer instructions and increases performance when compared with Intel\nMKL's dense or sparse matrix multiply routines. Benefits can be as large as 2\ntimes speedup and 4 times fewer instructions.",
      "tldr_zh": "该研究针对人工智能工作负载，尤其是 transformer 模型中的 emergent sparsity 问题，提出了一种 masked matrix multiplication 系统，以优化对密集数据的选择性稀疏访问。该系统通过矢量化和并行化处理 A X B = C 的矩阵乘法，利用动态代码查找适应 B 矩阵的特定稀疏性，并预处理 A 和 B 矩阵的稀疏性映射来一次性计算条件分支，从而消除不必要的计算和分支。对于 60% 到 95% 零元素的稀疏度，该实现比 Intel MKL 的密集或稀疏矩阵乘法例程减少多达 4 倍指令，并实现最高 2 倍的性能提升。",
      "categories": [
        "cs.DS",
        "cs.AI"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14118v1",
      "published_date": "2024-02-21 20:36:08 UTC",
      "updated_date": "2024-02-21 20:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:32:34.019978"
    },
    {
      "arxiv_id": "2402.14116v2",
      "title": "FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Zhu",
        "Alyssa Hwang",
        "Liam Dugan",
        "Chris Callison-Burch"
      ],
      "abstract": "One type of question that is commonly found in day-to-day scenarios is\n``fan-out'' questions, complex multi-hop, multi-document reasoning questions\nthat require finding information about a large number of entities. However,\nthere exist few resources to evaluate this type of question-answering\ncapability among large language models. To evaluate complex reasoning in LLMs\nmore fully, we present FanOutQA, a high-quality dataset of fan-out\nquestion-answer pairs and human-annotated decompositions with English Wikipedia\nas the knowledge base. We formulate three benchmark settings across our dataset\nand benchmark 7 LLMs, including GPT-4, LLaMA 2, Claude-2.1, and Mixtral-8x7B,\nfinding that contemporary models still have room to improve reasoning over\ninter-document dependencies in a long context. We provide our dataset and\nopen-source tools to run models to encourage evaluation at https://fanoutqa.com",
      "tldr_zh": "这篇论文引入了FanOutQA数据集，这是一个针对Large Language Models (LLMs)的基准，用于评估复杂的多跳(multi-hop)和多文档(multi-document)推理问题，特别是“fan-out”问题，这些问题涉及大量实体的信息。数据集基于English Wikipedia，包含高质量的问题-答案对和人工标注的分解，并制定了三个基准设置来测试7个LLMs，如GPT-4和LLaMA 2。实验结果显示，当代模型在处理长上下文中的跨文档依赖时仍有改进空间，并提供了开源工具（https://fanoutqa.com）以促进进一步评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 2 figures. ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14116v2",
      "published_date": "2024-02-21 20:30:45 UTC",
      "updated_date": "2024-06-06 16:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:32:45.734118"
    },
    {
      "arxiv_id": "2402.14096v3",
      "title": "EyeTrans: Merging Human and Machine Attention for Neural Code Summarization",
      "title_zh": "EyeTrans: 融合人类和机器注意力用于神经代码摘要",
      "authors": [
        "Yifan Zhang",
        "Jiliang Li",
        "Zachary Karas",
        "Aakash Bansal",
        "Toby Jia-Jun Li",
        "Collin McMillan",
        "Kevin Leach",
        "Yu Huang"
      ],
      "abstract": "Neural code summarization leverages deep learning models to automatically\ngenerate brief natural language summaries of code snippets. The development of\nTransformer models has led to extensive use of attention during model design.\nWhile existing work has primarily and almost exclusively focused on static\nproperties of source code and related structural representations like the\nAbstract Syntax Tree (AST), few studies have considered human attention, that\nis, where programmers focus while examining and comprehending code. In this\npaper, we develop a method for incorporating human attention into machine\nattention to enhance neural code summarization. To facilitate this\nincorporation and vindicate this hypothesis, we introduce EyeTrans, which\nconsists of three steps: (1) we conduct an extensive eye-tracking human study\nto collect and pre-analyze data for model training, (2) we devise a\ndata-centric approach to integrate human attention with machine attention in\nthe Transformer architecture, and (3) we conduct comprehensive experiments on\ntwo code summarization tasks to demonstrate the effectiveness of incorporating\nhuman attention into Transformers. Integrating human attention leads to an\nimprovement of up to 29.91% in Functional Summarization and up to 6.39% in\nGeneral Code Summarization performance, demonstrating the substantial benefits\nof this combination. We further explore performance in terms of robustness and\nefficiency by creating challenging summarization scenarios in which EyeTrans\nexhibits interesting properties. We also visualize the attention map to depict\nthe simplifying effect of machine attention in the Transformer by incorporating\nhuman attention. This work has the potential to propel AI research in software\nengineering by introducing more human-centered approaches and data.",
      "tldr_zh": "这篇论文提出EyeTrans方法，将人类注意力（通过eye-tracking研究收集）融入Transformer模型的机器注意力，以提升神经代码总结（neural code summarization）的性能。研究首先进行大规模眼动追踪人类实验，收集数据并设计数据导向策略，将人类注意力整合到Abstract Syntax Tree (AST) 等静态代码表示中。实验结果显示，在功能总结（Functional Summarization）任务上性能提升高达29.91%，在一般代码总结（General Code Summarization）任务上提升高达6.39%，并证明了EyeTrans在鲁棒性和效率方面的优势，为AI在软件工程中的以人为本方法提供了新方向。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14096v3",
      "published_date": "2024-02-21 19:45:06 UTC",
      "updated_date": "2024-02-29 13:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:32:58.648140"
    },
    {
      "arxiv_id": "2402.14095v4",
      "title": "Zero-shot generalization across architectures for visual classification",
      "title_zh": "翻译失败",
      "authors": [
        "Evan Gerritz",
        "Luciano Dyballa",
        "Steven W. Zucker"
      ],
      "abstract": "Generalization to unseen data is a key desideratum for deep networks, but its\nrelation to classification accuracy is unclear. Using a minimalist vision\ndataset and a measure of generalizability, we show that popular networks, from\ndeep convolutional networks (CNNs) to transformers, vary in their power to\nextrapolate to unseen classes both across layers and across architectures.\nAccuracy is not a good predictor of generalizability, and generalization varies\nnon-monotonically with layer depth.",
      "tldr_zh": "这篇论文探讨了视觉分类中零-shot generalization（零样本泛化）能力，使用一个简约的视觉数据集和泛化度量，比较了不同网络架构如CNNs和transformers在层级间的表现。研究发现，网络的泛化能力在不同层和架构间存在差异，且准确率并非可靠的预测指标。更为重要的是，泛化能力随层深度呈现非单调变化，这为理解深度网络的泛化机制提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.6; I.5.1; I.4.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a Tiny Paper at ICLR 2024. Code available at\n  https://github.com/dyballa/generalization/tree/ICLR2024TinyPaper",
      "pdf_url": "http://arxiv.org/pdf/2402.14095v4",
      "published_date": "2024-02-21 19:45:05 UTC",
      "updated_date": "2024-05-03 15:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:33:08.819129"
    },
    {
      "arxiv_id": "2403.08820v1",
      "title": "Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns",
      "title_zh": "Diet-ODIN：一种新型框架，用于阿片类",
      "authors": [
        "Zheyuan Zhang",
        "Zehong Wang",
        "Shifu Hou",
        "Evan Hall",
        "Landon Bachman",
        "Vincent Galassi",
        "Jasmine White",
        "Nitesh V. Chawla",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "The opioid crisis has been one of the most critical society concerns in the\nUnited States. Although the medication assisted treatment (MAT) is recognized\nas the most effective treatment for opioid misuse and addiction, the various\nside effects can trigger opioid relapse. In addition to MAT, the dietary\nnutrition intervention has been demonstrated its importance in opioid misuse\nprevention and recovery. However, research on the alarming connections between\ndietary patterns and opioid misuse remain under-explored. In response to this\ngap, in this paper, we first establish a large-scale multifaceted dietary\nbenchmark dataset related to opioid users at the first attempt and then develop\na novel framework - i.e., namely Opioid Misuse Detection with Interpretable\nDietary Patterns (Diet-ODIN) - to bridge heterogeneous graph (HG) and large\nlanguage model (LLM) for the identification of users with opioid misuse and the\ninterpretation of their associated dietary patterns. Specifically, in\nDiet-ODIN, we first construct an HG to comprehensively incorporate both dietary\nand health-related information, and then we devise a holistic graph learning\nframework with noise reduction to fully capitalize both users' individual\ndietary habits and shared dietary patterns for the detection of users with\nopioid misuse. To further delve into the intricate correlations between dietary\npatterns and opioid misuse, we exploit an LLM by utilizing the knowledge\nobtained from the graph learning model for interpretation. The extensive\nexperimental results based on our established benchmark with quantitative and\nqualitative measures demonstrate the outstanding performance of Diet-ODIN in\nexploring the complex interplay between opioid misuse and dietary patterns, by\ncomparison with state-of-the-art baseline methods.",
      "tldr_zh": "本研究针对阿片类药物滥用(Opioid Misuse)危机，强调了饮食营养干预的重要性，并首次建立了一个大规模多方面饮食基准数据集。研究提出Diet-ODIN框架，通过构建异构图(HG)整合饮食和健康信息，并结合图学习模型进行噪声减少，以检测潜在滥用用户并分析其饮食模式；随后利用大型语言模型(LLM)基于图学习结果进行解释。实验结果显示，Diet-ODIN在基准数据集上显著优于现有方法，在定量和定性评估中展现出色的性能，为探索饮食模式与阿片类药物滥用的复杂关联提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08820v1",
      "published_date": "2024-02-21 19:36:24 UTC",
      "updated_date": "2024-02-21 19:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:33:21.664827"
    },
    {
      "arxiv_id": "2402.14090v3",
      "title": "Social Environment Design",
      "title_zh": "社会环境设计",
      "authors": [
        "Edwin Zhang",
        "Sadie Zhao",
        "Tonghan Wang",
        "Safwan Hossain",
        "Henry Gasztowtt",
        "Stephan Zheng",
        "David C. Parkes",
        "Milind Tambe",
        "Yiling Chen"
      ],
      "abstract": "Artificial Intelligence (AI) holds promise as a technology that can be used\nto improve government and economic policy-making. This paper proposes a new\nresearch agenda towards this end by introducing Social Environment Design, a\ngeneral framework for the use of AI for automated policy-making that connects\nwith the Reinforcement Learning, EconCS, and Computational Social Choice\ncommunities. The framework seeks to capture general economic environments,\nincludes voting on policy objectives, and gives a direction for the systematic\nanalysis of government and economic policy through AI simulation. We highlight\nkey open problems for future research in AI-based policy-making. By solving\nthese challenges, we hope to achieve various social welfare objectives, thereby\npromoting more ethical and responsible decision making.",
      "tldr_zh": "本论文提出 Social Environment Design 框架，作为一种通用方法，利用 AI 自动化政府和经济政策制定，连接 Reinforcement Learning、EconCS 和 Computational Social Choice 等社区。框架捕捉一般经济环境，包括政策目标投票机制，并通过 AI 模拟进行系统分析，以解决政策决策中的关键挑战。最终目标是通过解决这些开放问题，提升社会福利，实现更道德和负责任的决策。",
      "categories": [
        "cs.AI",
        "econ.GN",
        "q-fin.EC",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML 2024 Position Paper. Website at https://sed.eddie.win",
      "pdf_url": "http://arxiv.org/pdf/2402.14090v3",
      "published_date": "2024-02-21 19:29:14 UTC",
      "updated_date": "2024-06-17 16:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:33:31.919817"
    },
    {
      "arxiv_id": "2402.14086v3",
      "title": "LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons",
      "title_zh": "LexC-Gen：利用大型语言模型和双语词典为极度低资源语言生成数据",
      "authors": [
        "Zheng-Xin Yong",
        "Cristina Menghini",
        "Stephen H. Bach"
      ],
      "abstract": "Data scarcity in low-resource languages can be addressed with word-to-word\ntranslations from labeled task data in high-resource languages using bilingual\nlexicons. However, bilingual lexicons often have limited lexical overlap with\ntask data, which results in poor translation coverage and lexicon utilization.\nWe propose lexicon-conditioned data generation LexC-Gen, a method that\ngenerates low-resource-language classification task data at scale.\nSpecifically, LexC-Gen first uses high-resource-language words from bilingual\nlexicons to generate lexicon-compatible task data, and then it translates them\ninto low-resource languages with bilingual lexicons via word translation.\nAcross 17 extremely low-resource languages, LexC-Gen generated data is\ncompetitive with expert-translated gold data, and yields on average 5.6 and 8.9\npoints improvement over existing lexicon-based word translation methods on\nsentiment analysis and topic classification tasks respectively. Through\nablation study, we show that conditioning on bilingual lexicons is the key\ncomponent of LexC-Gen. LexC-Gen serves as a potential solution to close the\nperformance gap between open-source multilingual models, such as BLOOMZ and\nAya-101, and state-of-the-art commercial models like GPT-4o on\nlow-resource-language tasks.",
      "tldr_zh": "本文提出 LexC-Gen 方法，利用 Large Language Models 和 bilingual lexicons，为极低资源语言生成分类任务数据，以解决现有翻译覆盖率低的问题。LexC-Gen 先基于高资源语言的词典单词生成兼容任务数据，然后通过双语词典进行单词翻译，从而大规模创建低资源语言数据。在 17 种极低资源语言上，该方法在 sentiment analysis 和 topic classification 任务上分别比现有方法提高了 5.6 和 8.9 分，并接近专家翻译数据的性能；消融研究显示，conditioning on bilingual lexicons 是其关键组件，有助于缩小开源模型如 BLOOMZ 和 Aya-101 与 GPT-4o 在低资源任务上的性能差距。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14086v3",
      "published_date": "2024-02-21 19:20:06 UTC",
      "updated_date": "2024-10-28 03:18:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:33:48.488923"
    },
    {
      "arxiv_id": "2402.14083v2",
      "title": "Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Lehnert",
        "Sainbayar Sukhbaatar",
        "DiJia Su",
        "Qinqing Zheng",
        "Paul Mcvay",
        "Michael Rabbat",
        "Yuandong Tian"
      ],
      "abstract": "While Transformers have enabled tremendous progress in various application\nsettings, such architectures still trail behind traditional symbolic planners\nfor solving complex decision making tasks. In this work, we demonstrate how to\ntrain Transformers to solve complex planning tasks. This is accomplished by\ntraining an encoder-decoder Transformer model to predict the search dynamics of\nthe $A^*$ search algorithm. We fine tune this model to obtain a Searchformer, a\nTransformer model that optimally solves previously unseen Sokoban puzzles 93.7%\nof the time, while using up to 26.8% fewer search steps than the $A^*$\nimplementation that was used for training initially. In our training method,\n$A^*$'s search dynamics are expressed as a token sequence outlining when task\nstates are added and removed into the search tree during symbolic planning.\nSearchformer significantly outperforms baselines that predict the optimal plan\ndirectly with a 5-10$\\times$ smaller model size and a 10$\\times$ smaller\ntraining dataset. Lastly, we demonstrate how Searchformer scales to larger and\nmore complex decision making tasks with improved percentage of solved tasks and\nshortened search dynamics.",
      "tldr_zh": "本研究提出了一种超越 A* 算法的规划方法，通过 Search Dynamics Bootstrapping 训练 Transformers 模型来预测 A* 的搜索动态，从而提升复杂决策任务的性能。具体而言，作者训练一个编码器-解码器 Transformer 模型来模拟 A* 搜索过程中的状态添加和移除，并微调为 Searchformer 模型，使其在 Sokoban 谜题上解决率达 93.7%，并比原始 A* 减少 26.8% 的搜索步骤。相比直接预测最优计划的基线，Searchformer 使用 5-10 倍更小的模型大小和 10 倍更小的训练数据集，表现出显著优势。最后，该方法扩展到更大更复杂的任务中，提高了解决率并缩短了搜索动态。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14083v2",
      "published_date": "2024-02-21 19:17:28 UTC",
      "updated_date": "2024-04-26 21:05:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:33:57.781315"
    },
    {
      "arxiv_id": "2402.14081v3",
      "title": "Motion Code: Robust Time Series Classification and Forecasting via Sparse Variational Multi-Stochastic Processes Learning",
      "title_zh": "Motion Code：基于稀疏变分多随机过程学习的鲁棒时间序列分类与预测",
      "authors": [
        "Chandrajit Bajaj",
        "Minh Nguyen"
      ],
      "abstract": "Despite extensive research, time series classification and forecasting on\nnoisy data remain highly challenging. The main difficulties lie in finding\nsuitable mathematical concepts to describe time series and effectively separate\nnoise from the true signals. Unlike traditional methods treating time series as\nstatic vectors or fixed sequences, we propose a novel framework that views each\ntime series, regardless of length, as a realization of a continuous-time\nstochastic process. This mathematical approach captures dependencies across\ntimestamps and detects hidden, time-varying signals within the noise. However,\nreal-world data often involves multiple distinct dynamics, making it\ninsufficient to model the entire process with a single stochastic model. To\naddress this, we assign each dynamic a unique signature vector and introduce\nthe concept of \"most informative timestamps\" to infer a sparse approximation of\nthe individual dynamics from these vectors. The resulting model, called Motion\nCode, includes parameters that fully capture diverse underlying dynamics in an\nintegrated manner, enabling simultaneous classification and forecasting of time\nseries. Extensive experiments on noisy datasets, including real-world\nParkinson's disease sensor tracking, demonstrate Motion Code's strong\nperformance against established benchmarks for time series classification and\nforecasting.",
      "tldr_zh": "本文提出 Motion Code 框架，通过将时间序列视为连续时间随机过程的实现，解决了噪声数据中时间序列分类和预测的挑战。该框架采用稀疏变分多随机过程学习（Sparse Variational Multi-Stochastic Processes Learning），引入独特的签名向量和“most informative timestamps”概念，来推断并整合多种底层动态，实现鲁棒的分类和预测。实验在真实噪声数据集上，包括帕金森病传感器跟踪，显示 Motion Code 显著优于基准模型，在分类和预测性能上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.14081v3",
      "published_date": "2024-02-21 19:10:08 UTC",
      "updated_date": "2024-11-25 18:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:34:10.909757"
    },
    {
      "arxiv_id": "2402.14080v1",
      "title": "Efficient Normalized Conformal Prediction and Uncertainty Quantification for Anti-Cancer Drug Sensitivity Prediction with Deep Regression Forests",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Nolte",
        "Souparno Ghosh",
        "Ranadip Pal"
      ],
      "abstract": "Deep learning models are being adopted and applied on various critical\ndecision-making tasks, yet they are trained to provide point predictions\nwithout providing degrees of confidence. The trustworthiness of deep learning\nmodels can be increased if paired with uncertainty estimations. Conformal\nPrediction has emerged as a promising method to pair machine learning models\nwith prediction intervals, allowing for a view of the model's uncertainty.\nHowever, popular uncertainty estimation methods for conformal prediction fail\nto provide heteroskedastic intervals that are equally accurate for all samples.\nIn this paper, we propose a method to estimate the uncertainty of each sample\nby calculating the variance obtained from a Deep Regression Forest. We show\nthat the deep regression forest variance improves the efficiency and coverage\nof normalized inductive conformal prediction on a drug response prediction\ntask.",
      "tldr_zh": "这篇论文针对深度学习模型在抗癌药物敏感性预测中的不确定性问题，提出了一种高效的 Normalized Conformal Prediction 方法，以提供更可靠的预测区间。作者使用 Deep Regression Forests 计算每个样本的方差，从而实现异方差（heteroskedastic）不确定性估计，确保预测区间对所有样本同样准确。实验结果表明，该方法在药物响应预测任务中显著提高了效率和覆盖率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2402.14080v1",
      "published_date": "2024-02-21 19:09:53 UTC",
      "updated_date": "2024-02-21 19:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:34:20.514998"
    },
    {
      "arxiv_id": "2402.14015v2",
      "title": "Corrective Machine Unlearning",
      "title_zh": "纠正性机器遗忘",
      "authors": [
        "Shashwat Goel",
        "Ameya Prabhu",
        "Philip Torr",
        "Ponnurangam Kumaraguru",
        "Amartya Sanyal"
      ],
      "abstract": "Machine Learning models increasingly face data integrity challenges due to\nthe use of large-scale training datasets drawn from the Internet. We study what\nmodel developers can do if they detect that some data was manipulated or\nincorrect. Such manipulated data can cause adverse effects including\nvulnerability to backdoored samples, systemic biases, and reduced accuracy on\ncertain input domains. Realistically, all manipulated training samples cannot\nbe identified, and only a small, representative subset of the affected data can\nbe flagged.\n  We formalize Corrective Machine Unlearning as the problem of mitigating the\nimpact of data affected by unknown manipulations on a trained model, only\nhaving identified a subset of the corrupted data. We demonstrate that the\nproblem of corrective unlearning has significantly different requirements from\ntraditional privacy-oriented unlearning. We find most existing unlearning\nmethods, including retraining-from-scratch without the deletion set, require\nmost of the manipulated data to be identified for effective corrective\nunlearning. However, one approach, Selective Synaptic Dampening, achieves\nlimited success, unlearning adverse effects with just a small portion of the\nmanipulated samples in our setting, which shows encouraging signs for future\nprogress. We hope our work spurs research towards developing better methods for\ncorrective unlearning and offers practitioners a new strategy to handle data\nintegrity challenges arising from web-scale training. Code is available at\nhttps://github.com/drimpossible/corrective-unlearning-bench.",
      "tldr_zh": "本研究探讨了机器学习模型在使用大规模互联网数据集时面临的数据完整性挑战，形式化了“Corrective Machine Unlearning”问题，即在仅识别出一小部分受影响数据的情况下，减轻未知操纵数据对模型的影响，以避免漏洞、系统偏差和准确性下降。不同于传统的隐私导向unlearning，该问题要求更高效的处理策略，因为不可能识别所有操纵样本。实验结果显示，大多数现有unlearning方法（如重新训练）需要大部分操纵数据才能有效，而Selective Synaptic Dampening方法仅需一小部分样本即可部分成功地缓解负面影响。该工作呼吁开发更好的corrective unlearning方法，并为从业者提供处理数据完整性挑战的策略，代码已在GitHub上开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in Transactions of Machine Learning Research (TMLR), 17\n  pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14015v2",
      "published_date": "2024-02-21 18:54:37 UTC",
      "updated_date": "2024-10-17 16:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:34:33.267010"
    },
    {
      "arxiv_id": "2402.14007v2",
      "title": "Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei He",
        "Binglin Zhou",
        "Hongkun Hao",
        "Aiwei Liu",
        "Xing Wang",
        "Zhaopeng Tu",
        "Zhuosheng Zhang",
        "Rui Wang"
      ],
      "abstract": "Text watermarking technology aims to tag and identify content produced by\nlarge language models (LLMs) to prevent misuse. In this study, we introduce the\nconcept of cross-lingual consistency in text watermarking, which assesses the\nability of text watermarks to maintain their effectiveness after being\ntranslated into other languages. Preliminary empirical results from two LLMs\nand three watermarking methods reveal that current text watermarking\ntechnologies lack consistency when texts are translated into various languages.\nBased on this observation, we propose a Cross-lingual Watermark Removal Attack\n(CWRA) to bypass watermarking by first obtaining a response from an LLM in a\npivot language, which is then translated into the target language. CWRA can\neffectively remove watermarks, decreasing the AUCs to a random-guessing level\nwithout performance loss. Furthermore, we analyze two key factors that\ncontribute to the cross-lingual consistency in text watermarking and propose\nX-SIR as a defense method against CWRA. Code: https://github.com/zwhe99/X-SIR.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)文本水印技术的跨语言一致性，即水印在翻译后是否仍能有效标识内容。实验结果显示，现有的水印方法在多种语言翻译后缺乏一致性，导致识别能力下降。作者提出Cross-lingual Watermark Removal Attack (CWRA)攻击，通过在枢纽语言获取响应再翻译到目标语言，从而有效移除水印，使AUC降至随机猜测水平，而不影响模型性能。最后，论文分析了影响一致性的关键因素，并引入X-SIR作为防御方法，以提升水印的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2402.14007v2",
      "published_date": "2024-02-21 18:48:38 UTC",
      "updated_date": "2024-06-04 14:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:34:44.800932"
    },
    {
      "arxiv_id": "2403.14645v1",
      "title": "Designing Multi-Step Action Models for Enterprise AI Adoption",
      "title_zh": "翻译失败",
      "authors": [
        "Shreyash Mishra",
        "Shrey Shah",
        "Rex Pereira"
      ],
      "abstract": "This paper introduces the Multi-Step Action Model (MSAM), a closed-source AI\nmodel designed by Empsing to address challenges hindering AI adoption in\nenterprises. Through a holistic examination, this paper explores MSAM's\nfoundational principles, design architecture, and future trajectory. It\nevaluates MSAM's performance via rigorous testing methodologies and envisions\nits potential impact on advancing AI adoption within organizations.",
      "tldr_zh": "这篇论文介绍了Multi-Step Action Model (MSAM)，一个由Empsing设计的闭源AI模型，旨在解决企业AI采用中的挑战。论文通过整体考察MSAM的基础原则、设计架构和未来发展，并采用严格的测试方法评估其性能。最终，研究展望了MSAM在推动组织AI采用方面的潜在影响，有望提升企业AI应用的效率和可行性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "68T42",
        "I.2.1; I.2.8"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14645v1",
      "published_date": "2024-02-21 18:37:13 UTC",
      "updated_date": "2024-02-21 18:37:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:34:55.589689"
    },
    {
      "arxiv_id": "2402.14875v3",
      "title": "What's in a Name? Auditing Large Language Models for Race and Gender Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Salinas",
        "Amit Haim",
        "Julian Nyarko"
      ],
      "abstract": "We employ an audit design to investigate biases in state-of-the-art large\nlanguage models, including GPT-4. In our study, we prompt the models for advice\ninvolving a named individual across a variety of scenarios, such as during car\npurchase negotiations or election outcome predictions. We find that the advice\nsystematically disadvantages names that are commonly associated with racial\nminorities and women. Names associated with Black women receive the least\nadvantageous outcomes. The biases are consistent across 42 prompt templates and\nseveral models, indicating a systemic issue rather than isolated incidents.\nWhile providing numerical, decision-relevant anchors in the prompt can\nsuccessfully counteract the biases, qualitative details have inconsistent\neffects and may even increase disparities. Our findings underscore the\nimportance of conducting audits at the point of LLM deployment and\nimplementation to mitigate their potential for harm against marginalized\ncommunities.",
      "tldr_zh": "本研究通过审计设计（auditing）调查了大型语言模型（Large Language Models, LLMs）如GPT-4中的种族和性别偏见，方法是提示模型在各种场景（如汽车谈判或选举预测）中为特定名字提供建议。结果显示，模型的建议系统性地对与种族少数群体和女性相关的名字不利，尤其是黑人女性名字，导致它们获得最不利的outcome。偏见在42个提示模板和多个模型中一致存在，而添加数字锚点（numerical anchors）可有效缓解偏见，但定性细节可能加剧不平等。该研究强调，在LLM部署时进行审计以减少对边缘化社区的潜在伤害至关重要。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "62 pages, 34 tables, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14875v3",
      "published_date": "2024-02-21 18:25:25 UTC",
      "updated_date": "2025-01-24 01:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:35:10.293858"
    },
    {
      "arxiv_id": "2402.14049v2",
      "title": "Generative Adversarial Models for Extreme Geospatial Downscaling",
      "title_zh": "翻译失败",
      "authors": [
        "Guiye Li",
        "Guofeng Cao"
      ],
      "abstract": "Addressing the challenges of climate change requires accurate and\nhigh-resolution mapping of geospatial data, especially climate and weather\nvariables. However, many existing geospatial datasets, such as the gridded\noutputs of the state-of-the-art numerical climate models (e.g., general\ncirculation models), are only available at very coarse spatial resolutions due\nto the model complexity and extremely high computational demand.\nDeep-learning-based methods, particularly generative adversarial networks\n(GANs) and their variants, have proved effective for refining natural images\nand have shown great promise in improving geospatial datasets. This paper\ndescribes a conditional GAN-based stochastic geospatial downscaling method that\ncan accommodates very high scaling factors. Compared to most existing methods,\nthe method can generate high-resolution accurate climate datasets from very\nlow-resolution inputs. More importantly, the method explicitly considers the\nuncertainty inherent to the downscaling process that tends to be ignored in\nexisting methods. Given an input, the method can produce a multitude of\nplausible high-resolution samples instead of one single deterministic result.\nThese samples allow for an empirical exploration and inferences of model\nuncertainty and robustness. With a case study of gridded climate datasets (wind\nvelocity and solar irradiance), we demonstrate the performances of the\nframework in downscaling tasks with large scaling factors (up to $64\\times$)\nand highlight the advantages of the framework with a comprehensive comparison\nwith commonly used and most recent downscaling methods, including area-to-point\n(ATP) kriging, deep image prior (DIP), enhanced super-resolution generative\nadversarial networks (ESRGAN), physics-informed resolution-enhancing GAN (PhIRE\nGAN), and an efficient diffusion model for remote sensing image\nsuper-resolution (EDiffSR).",
      "tldr_zh": "这篇论文提出了一种基于条件 GAN 的随机地理空间降尺度方法，用于从低分辨率输入生成高分辨率气候数据集，解决现有数值气候模型（如通用环流模型）输出分辨率粗糙的问题。不同于传统方法，该方法显式考虑降尺度过程中的不确定性，能够生成多个可能的样本，从而支持模型不确定性和鲁棒性的实证探索和推断。在针对风速和太阳能辐照度的案例研究中，该框架在高达64倍的缩放因子下，表现优于其他方法如ATP kriging、DIP、ESRGAN、PhIRE GAN 和 EDiffSR。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14049v2",
      "published_date": "2024-02-21 18:25:04 UTC",
      "updated_date": "2024-08-07 17:09:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:35:21.738079"
    },
    {
      "arxiv_id": "2402.13979v1",
      "title": "The Importance of Architecture Choice in Deep Learning for Climate Applications",
      "title_zh": "深度学习中架构选择的重要性用于气候应用",
      "authors": [
        "Simon Dräger",
        "Maike Sonnewald"
      ],
      "abstract": "Machine Learning has become a pervasive tool in climate science applications.\nHowever, current models fail to address nonstationarity induced by\nanthropogenic alterations in greenhouse emissions and do not routinely quantify\nthe uncertainty of proposed projections. In this paper, we model the Atlantic\nMeridional Overturning Circulation (AMOC) which is of major importance to\nclimate in Europe and the US East Coast by transporting warm water to these\nregions, and has the potential for abrupt collapse. We can generate arbitrarily\nextreme climate scenarios through arbitrary time scales which we then predict\nusing neural networks. Our analysis shows that the AMOC is predictable using\nneural networks under a diverse set of climate scenarios. Further experiments\nreveal that MLPs and Deep Ensembles can learn the physics of the AMOC instead\nof imitating its progression through autocorrelation. With quantified\nuncertainty, an intriguing pattern of \"spikes\" before critical points of\ncollapse in the AMOC casts doubt on previous analyses that predicted an AMOC\ncollapse within this century. Our results show that Bayesian Neural Networks\nperform poorly compared to more dense architectures and care should be taken\nwhen applying neural networks to nonstationary scenarios such as climate\nprojections. Further, our results highlight that big NN models might have\ndifficulty in modeling global Earth System dynamics accurately and be\nsuccessfully applied in nonstationary climate scenarios due to the physics\nbeing challenging for neural networks to capture.",
      "tldr_zh": "本研究强调了在气候应用中选择深度学习架构的重要性，特别是在处理温室气体排放引起的不平稳性和不确定性量化时。研究者使用神经网络（如MLP和Deep Ensembles）对大西洋经向翻转环流（AMOC）进行预测，生成各种极端气候场景，结果显示这些模型能学习AMOC的物理过程，而非简单模仿其自相关性。实验揭示Bayesian Neural Networks的表现不如密集架构，且在AMOC崩溃前观察到的“spikes”模式质疑了先前预测AMOC在本世纪崩溃的可能性。该研究警示，在非平稳气候场景中，大型神经网络可能难以准确捕捉全球地球系统动态，因此需谨慎选择架构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13979v1",
      "published_date": "2024-02-21 18:09:04 UTC",
      "updated_date": "2024-02-21 18:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:35:34.155771"
    },
    {
      "arxiv_id": "2402.19237v1",
      "title": "Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Edgar Medina",
        "Leyong Loh",
        "Namrata Gurung",
        "Kyung Hun Oh",
        "Niels Heller"
      ],
      "abstract": "Human motion prediction is still an open problem extremely important for\nautonomous driving and safety applications. Due to the complex spatiotemporal\nrelation of motion sequences, this remains a challenging problem not only for\nmovement prediction but also to perform a preliminary interpretation of the\njoint connections. In this work, we present a Context-based Interpretable\nSpatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D\nhuman pose forecasting model based on GCNs that encompasses specific layers,\naiding model interpretability and providing information that might be useful\nwhen analyzing motion distribution and body behavior. Our architecture extracts\nmeaningful information from pose sequences, aggregates displacements and\naccelerations into the input model, and finally predicts the output\ndisplacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI\ndatasets demonstrate that CIST-GCN outperforms previous methods in human motion\nprediction and robustness. Since the idea of enhancing interpretability for\nmotion prediction has its merits, we showcase experiments towards it and\nprovide preliminary evaluations of such insights here. available code:\nhttps://github.com/QualityMinds/cistgcn",
      "tldr_zh": "本论文提出了一种基于上下文的解释性时空图卷积网络 (CIST-GCN)，用于人类运动预测，以处理复杂时空关系并提升模型可解释性。该模型通过特定层从姿势序列中提取信息、聚合位移和加速度，并预测输出位移，从而为自动驾驶和安全应用提供更可靠的预测。实验在 Human 3.6M、AMASS、3DPW 和 ExPI 数据集上表明，CIST-GCN 优于现有方法，提高了预测准确性和鲁棒性，并提供了初步的可解释性评估，代码可从 GitHub 获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.19237v1",
      "published_date": "2024-02-21 17:51:30 UTC",
      "updated_date": "2024-02-21 17:51:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:35:47.685966"
    },
    {
      "arxiv_id": "2402.14874v2",
      "title": "Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Phuc Phan",
        "Hieu Tran",
        "Long Phan"
      ],
      "abstract": "We propose a straightforward approach called Distillation Contrastive\nDecoding (DCD) to enhance the reasoning capabilities of Large Language Models\n(LLMs) during inference. In contrast to previous approaches that relied on\nsmaller amateur models or analysis of hidden state differences, DCD employs\nContrastive Chain-of-thought Prompting and advanced distillation techniques,\nincluding Dropout and Quantization. This approach effectively addresses the\nlimitations of Contrastive Decoding (CD), which typically requires both an\nexpert and an amateur model, thus increasing computational resource demands. By\nintegrating contrastive prompts with distillation, DCD obviates the need for an\namateur model and reduces memory usage. Our evaluations demonstrate that DCD\nsignificantly enhances LLM performance across a range of reasoning benchmarks,\nsurpassing both CD and existing methods in the GSM8K and StrategyQA datasets.",
      "tldr_zh": "我们提出了一种名为Distillation Contrastive Decoding (DCD)的方法，用于提升Large Language Models (LLMs)的推理能力。DCD通过整合Contrastive Chain-of-thought Prompting和先进的蒸馏技术（如Dropout和Quantization），解决了传统Contrastive Decoding (CD)的局限性，即无需额外的amateur模型，从而减少计算资源和内存使用。在GSM8K和StrategyQA等推理基准测试中，DCD的表现显著优于CD和其他现有方法，展示了其在提升LLMs性能方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2402.14874v2",
      "published_date": "2024-02-21 17:20:38 UTC",
      "updated_date": "2024-08-23 07:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:35:59.323783"
    },
    {
      "arxiv_id": "2402.13945v1",
      "title": "Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty in Scientific Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Farhad Pourkamali-Anaraki",
        "Jamal F. Husseini",
        "Scott E. Stapleton"
      ],
      "abstract": "This paper investigates the use of probabilistic neural networks (PNNs) to\nmodel aleatoric uncertainty, which refers to the inherent variability in the\ninput-output relationships of a system, often characterized by unequal variance\nor heteroscedasticity. Unlike traditional neural networks that produce\ndeterministic outputs, PNNs generate probability distributions for the target\nvariable, allowing the determination of both predicted means and intervals in\nregression scenarios. Contributions of this paper include the development of a\nprobabilistic distance metric to optimize PNN architecture, and the deployment\nof PNNs in controlled data sets as well as a practical material science case\ninvolving fiber-reinforced composites. The findings confirm that PNNs\neffectively model aleatoric uncertainty, proving to be more appropriate than\nthe commonly employed Gaussian process regression for this purpose.\nSpecifically, in a real-world scientific machine learning context, PNNs yield\nremarkably accurate output mean estimates with R-squared scores approaching\n0.97, and their predicted intervals exhibit a high correlation coefficient of\nnearly 0.80, closely matching observed data intervals. Hence, this research\ncontributes to the ongoing exploration of leveraging the sophisticated\nrepresentational capacity of neural networks to delineate complex input-output\nrelationships in scientific problems.",
      "tldr_zh": "本论文探讨了使用 Probabilistic Neural Networks (PNNs) 来建模科学机器学习中的 aleatoric uncertainty，即系统输入输出关系的固有变异性。PNNs 通过生成目标变量的概率分布，提供预测均值和置信区间，这比传统确定性神经网络更先进。论文的主要贡献包括开发一种 probabilistic distance metric 来优化 PNN 架构，并将其应用于控制数据集和材料科学案例，如纤维增强复合材料。实验结果显示，PNNs 优于 Gaussian process regression，在实际场景中实现输出均值估计的 R-squared 接近 0.97，且预测区间与观察数据相关系数近 0.80，从而更好地处理复杂输入输出关系。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13945v1",
      "published_date": "2024-02-21 17:15:47 UTC",
      "updated_date": "2024-02-21 17:15:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:36:11.844052"
    },
    {
      "arxiv_id": "2402.14873v3",
      "title": "Technical Report on the Pangram AI-Generated Text Classifier",
      "title_zh": "Pangram AI 生成文本分类器的技术报告",
      "authors": [
        "Bradley Emi",
        "Max Spero"
      ],
      "abstract": "We present Pangram Text, a transformer-based neural network trained to\ndistinguish text written by large language models from text written by humans.\nPangram Text outperforms zero-shot methods such as DetectGPT as well as leading\ncommercial AI detection tools with over 38 times lower error rates on a\ncomprehensive benchmark comprised of 10 text domains (student writing, creative\nwriting, scientific writing, books, encyclopedias, news, email, scientific\npapers, short-form Q&A) and 8 open- and closed-source large language models. We\npropose a training algorithm, hard negative mining with synthetic mirrors, that\nenables our classifier to achieve orders of magnitude lower false positive\nrates on high-data domains such as reviews. Finally, we show that Pangram Text\nis not biased against nonnative English speakers and generalizes to domains and\nmodels unseen during training.",
      "tldr_zh": "该论文介绍了 Pangram Text，一种基于 Transformer 的神经网络分类器，用于区分大型语言模型生成的文本与人类撰写的文本。相比零样本方法如 DetectGPT 和领先商业工具，Pangram Text 在涵盖10个文本领域（包括学生写作、创意写作等）和8个语言模型的综合基准上，错误率降低了38倍以上。论文提出了一种训练算法——hard negative mining with synthetic mirrors，以显著降低高数据领域的假阳性率；此外，该分类器不对非母语英语使用者有偏见，并能泛化到训练中未见过的领域和模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14873v3",
      "published_date": "2024-02-21 17:13:41 UTC",
      "updated_date": "2024-07-29 08:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:36:23.733906"
    },
    {
      "arxiv_id": "2402.13934v2",
      "title": "Do Efficient Transformers Really Save Computation?",
      "title_zh": "高效 Transformer 真的能",
      "authors": [
        "Kai Yang",
        "Jan Ackermann",
        "Zhenyu He",
        "Guhao Feng",
        "Bohang Zhang",
        "Yunzhen Feng",
        "Qiwei Ye",
        "Di He",
        "Liwei Wang"
      ],
      "abstract": "As transformer-based language models are trained on increasingly large\ndatasets and with vast numbers of parameters, finding more efficient\nalternatives to the standard Transformer has become very valuable. While many\nefficient Transformers and Transformer alternatives have been proposed, none\nprovide theoretical guarantees that they are a suitable replacement for the\nstandard Transformer. This makes it challenging to identify when to use a\nspecific model and what directions to prioritize for further investigation. In\nthis paper, we aim to understand the capabilities and limitations of efficient\nTransformers, specifically the Sparse Transformer and the Linear Transformer.\nWe focus on their reasoning capability as exhibited by Chain-of-Thought (CoT)\nprompts and follow previous works to model them as Dynamic Programming (DP)\nproblems. Our results show that while these models are expressive enough to\nsolve general DP tasks, contrary to expectations, they require a model size\nthat scales with the problem size. Nonetheless, we identify a class of DP\nproblems for which these models can be more efficient than the standard\nTransformer. We confirm our theoretical results through experiments on\nrepresentative DP tasks, adding to the understanding of efficient Transformers'\npractical strengths and weaknesses.",
      "tldr_zh": "本论文探讨了高效 Transformer（如 Sparse Transformer 和 Linear Transformer）是否真正节省计算资源，针对其缺乏理论保证的问题进行分析。研究者通过将这些模型建模为 Dynamic Programming (DP) 问题，并使用 Chain-of-Thought (CoT) 提示评估其推理能力。结果显示，虽然这些模型能解决一般 DP 任务，但所需模型大小会随问题规模增加，并非总是更高效；然而，对于特定 DP 问题的子类，它们比标准 Transformer 更具计算优势。实验验证了这些发现，增强了对高效 Transformer 实际优缺点的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, ICML 2024 Camera Ready Version",
      "pdf_url": "http://arxiv.org/pdf/2402.13934v2",
      "published_date": "2024-02-21 17:00:56 UTC",
      "updated_date": "2024-11-09 04:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:36:34.957716"
    },
    {
      "arxiv_id": "2402.13929v3",
      "title": "SDXL-Lightning: Progressive Adversarial Diffusion Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Shanchuan Lin",
        "Anran Wang",
        "Xiao Yang"
      ],
      "abstract": "We propose a diffusion distillation method that achieves new state-of-the-art\nin one-step/few-step 1024px text-to-image generation based on SDXL. Our method\ncombines progressive and adversarial distillation to achieve a balance between\nquality and mode coverage. In this paper, we discuss the theoretical analysis,\ndiscriminator design, model formulation, and training techniques. We\nopen-source our distilled SDXL-Lightning models both as LoRA and full UNet\nweights.",
      "tldr_zh": "本论文提出了一种名为 SDXL-Lightning 的扩散蒸馏方法（diffusion distillation），通过结合 progressive adversarial distillation 来实现一步或少步生成 1024px 文本到图像任务，并平衡生成质量和模式覆盖。论文详细讨论了理论分析、鉴别器设计、模型公式以及训练技巧，以提升生成效率和效果。实验结果显示，该方法在文本到图像生成上达到了新的最先进水平，并开源了模型权重，包括 LoRA 和 full UNet 版本。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13929v3",
      "published_date": "2024-02-21 16:51:05 UTC",
      "updated_date": "2024-03-02 09:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:36:46.265476"
    },
    {
      "arxiv_id": "2402.13927v1",
      "title": "The Delusional Hedge Algorithm as a Model of Human Learning from Diverse Opinions",
      "title_zh": "翻译失败",
      "authors": [
        "Yun-Shiuan Chuang",
        "Jerry Zhu",
        "Timothy T. Rogers"
      ],
      "abstract": "Whereas cognitive models of learning often assume direct experience with both\nthe features of an event and with a true label or outcome, much of everyday\nlearning arises from hearing the opinions of others, without direct access to\neither the experience or the ground truth outcome. We consider how people can\nlearn which opinions to trust in such scenarios by extending the hedge\nalgorithm: a classic solution for learning from diverse information sources. We\nfirst introduce a semi-supervised variant we call the delusional hedge capable\nof learning from both supervised and unsupervised experiences. In two\nexperiments, we examine the alignment between human judgments and predictions\nfrom the standard hedge, the delusional hedge, and a heuristic baseline model.\nResults indicate that humans effectively incorporate both labeled and unlabeled\ninformation in a manner consistent with the delusional hedge algorithm --\nsuggesting that human learners not only gauge the accuracy of information\nsources but also their consistency with other reliable sources. The findings\nadvance our understanding of human learning from diverse opinions, with\nimplications for the development of algorithms that better capture how people\nlearn to weigh conflicting information sources.",
      "tldr_zh": "该研究探讨了人类从多样意见中学习的过程，扩展了经典的 hedge algorithm，引入一种半监督变体——delusional hedge algorithm——以处理 supervised 和 unsupervised experiences。研究通过两个实验比较了人类判断与 standard hedge、delusional hedge 以及 heuristic baseline model 的预测，结果显示人类能有效整合标记和未标记信息，与 delusional hedge algorithm 的机制一致，不仅评估信息源的准确性，还考虑其与其他可靠源的一致性。这些发现深化了对人类学习行为的理解，并为开发更贴合人类决策的算法提供重要启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13927v1",
      "published_date": "2024-02-21 16:48:07 UTC",
      "updated_date": "2024-02-21 16:48:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:36:58.674970"
    },
    {
      "arxiv_id": "2402.13926v1",
      "title": "Large Language Models are Vulnerable to Bait-and-Switch Attacks for Generating Harmful Content",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Bianchi",
        "James Zou"
      ],
      "abstract": "The risks derived from large language models (LLMs) generating deceptive and\ndamaging content have been the subject of considerable research, but even safe\ngenerations can lead to problematic downstream impacts. In our study, we shift\nthe focus to how even safe text coming from LLMs can be easily turned into\npotentially dangerous content through Bait-and-Switch attacks. In such attacks,\nthe user first prompts LLMs with safe questions and then employs a simple\nfind-and-replace post-hoc technique to manipulate the outputs into harmful\nnarratives. The alarming efficacy of this approach in generating toxic content\nhighlights a significant challenge in developing reliable safety guardrails for\nLLMs. In particular, we stress that focusing on the safety of the verbatim LLM\noutputs is insufficient and that we also need to consider post-hoc\ntransformations.",
      "tldr_zh": "这篇论文揭示了大型语言模型 (LLMs) 在生成有害内容的潜在漏洞，特别是通过 Bait-and-Switch 攻击来利用安全输出。攻击方法涉及先用安全问题提示 LLMs 生成无害文本，然后应用简单的 find-and-replace 后处理技术，将其转化为毒性叙述。研究结果显示，这种攻击高度有效，强调当前的安全防护机制仅关注原始输出是不够的，还需考虑后处理变换以提升 LLMs 的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13926v1",
      "published_date": "2024-02-21 16:46:36 UTC",
      "updated_date": "2024-02-21 16:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:37:10.381823"
    },
    {
      "arxiv_id": "2403.14643v2",
      "title": "Exploring ChatGPT and its Impact on Society",
      "title_zh": "探索 ChatGPT 及其对社会的影响",
      "authors": [
        "Md. Asraful Haque",
        "Shuai Li"
      ],
      "abstract": "Artificial intelligence has been around for a while, but suddenly it has\nreceived more attention than ever before. Thanks to innovations from companies\nlike Google, Microsoft, Meta, and other major brands in technology. OpenAI,\nthough, has triggered the button with its ground-breaking invention ChatGPT.\nChatGPT is a Large Language Model (LLM) based on Transformer architecture that\nhas the ability to generate human-like responses in a conversational context.\nIt uses deep learning algorithms to generate natural language responses to\ninput text. Its large number of parameters, contextual generation, and\nopen-domain training make it a versatile and effective tool for a wide range of\napplications, from chatbots to customer service to language translation. It has\nthe potential to revolutionize various industries and transform the way we\ninteract with technology. However, the use of ChatGPT has also raised several\nconcerns, including ethical, social, and employment challenges, which must be\ncarefully considered to ensure the responsible use of this technology. The\narticle provides an overview of ChatGPT, delving into its architecture and\ntraining process. It highlights the potential impacts of ChatGPT on the\nsociety. In this paper, we suggest some approaches involving technology,\nregulation, education, and ethics in an effort to maximize ChatGPT's benefits\nwhile minimizing its negative impacts. This study is expected to contribute to\na greater understanding of ChatGPT and aid in predicting the potential changes\nit may bring about.",
      "tldr_zh": "这篇论文探讨了 ChatGPT，这是一个基于 Transformer 架构的大型语言模型 (LLM)，能够生成类人对话并应用于聊天机器人、客服和翻译等领域，具有革命化行业潜力的优势。论文分析了 ChatGPT 对社会的积极影响，如改变人机互动方式，同时指出了潜在挑战，包括伦理、社会和就业问题。作者建议通过技术、法规、教育和伦理策略来最大化其益处并最小化负面影响，以促进对 ChatGPT 的全面理解和未来变化的预测。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "68Txx"
      ],
      "primary_category": "cs.CY",
      "comment": "13 Pages",
      "pdf_url": "http://arxiv.org/pdf/2403.14643v2",
      "published_date": "2024-02-21 16:44:35 UTC",
      "updated_date": "2024-03-25 05:35:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:37:22.247138"
    },
    {
      "arxiv_id": "2402.14048v1",
      "title": "PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "André Hottung",
        "Mridul Mahajan",
        "Kevin Tierney"
      ],
      "abstract": "Reinforcement learning-based methods for constructing solutions to\ncombinatorial optimization problems are rapidly approaching the performance of\nhuman-designed algorithms. To further narrow the gap, learning-based approaches\nmust efficiently explore the solution space during the search process. Recent\napproaches artificially increase exploration by enforcing diverse solution\ngeneration through handcrafted rules, however, these rules can impair solution\nquality and are difficult to design for more complex problems. In this paper,\nwe introduce PolyNet, an approach for improving exploration of the solution\nspace by learning complementary solution strategies. In contrast to other\nworks, PolyNet uses only a single-decoder and a training schema that does not\nenforce diverse solution generation through handcrafted rules. We evaluate\nPolyNet on four combinatorial optimization problems and observe that the\nimplicit diversity mechanism allows PolyNet to find better solutions than\napproaches the explicitly enforce diverse solution generation.",
      "tldr_zh": "该论文提出了 PolyNet，一种用于神经组合优化(Neural Combinatorial Optimization)的强化学习方法，通过学习互补的解决方案策略来提升解决方案空间的探索，而非依赖手工规则。PolyNet 采用单一解码器和不强制多样性的训练方案，从而避免了传统方法可能损害解决方案质量的问题。在四个组合优化问题上的实验显示，PolyNet 凭借其隐式多样性机制，比显式强制多样性生成的方法找到了更优的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14048v1",
      "published_date": "2024-02-21 16:38:14 UTC",
      "updated_date": "2024-02-21 16:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:37:34.082062"
    },
    {
      "arxiv_id": "2402.13919v4",
      "title": "SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Prakamya Mishra",
        "Zonghai Yao",
        "Parth Vashisht",
        "Feiyun Ouyang",
        "Beining Wang",
        "Vidhi Dhaval Mody",
        "Hong Yu"
      ],
      "abstract": "Large Language Models (LLMs) such as GPT & Llama have demonstrated\nsignificant achievements in summarization tasks but struggle with factual\ninaccuracies, a critical issue in clinical NLP applications where errors could\nlead to serious consequences. To counter the high costs and limited\navailability of expert-annotated data for factual alignment, this study\nintroduces an innovative pipeline that utilizes >100B parameter GPT variants\nlike GPT-3.5 & GPT-4 to act as synthetic experts to generate high-quality\nsynthetics feedback aimed at enhancing factual consistency in clinical note\nsummarization. Our research primarily focuses on edit feedback generated by\nthese synthetic feedback experts without additional human annotations,\nmirroring and optimizing the practical scenario in which medical professionals\nrefine AI system outputs. Although such 100B+ parameter GPT variants have\nproven to demonstrate expertise in various clinical NLP tasks, such as the\nMedical Licensing Examination, there is scant research on their capacity to act\nas synthetic feedback experts and deliver expert-level edit feedback for\nimproving the generation quality of weaker (<10B parameter) LLMs like GPT-2\n(1.5B) & Llama 2 (7B) in clinical domain. So in this work, we leverage 100B+\nGPT variants to act as synthetic feedback experts offering expert-level edit\nfeedback, that is used to reduce hallucinations and align weaker (<10B\nparameter) LLMs with medical facts using two distinct alignment algorithms (DPO\n& SALT), endeavoring to narrow the divide between AI-generated content and\nfactual accuracy. This highlights the substantial potential of LLM-based\nsynthetic edits in enhancing the alignment of clinical factuality.",
      "tldr_zh": "这篇论文提出了 SYNFAC-EDIT 框架，利用 GPT-3.5 和 GPT-4 等 >100B 参数的大型语言模型（LLMs）作为合成专家，生成高质量的编辑反馈，以解决临床笔记总结中的事实不准确问题。该方法避免了昂贵的人类标注，直接通过合成反馈对较小模型（如 GPT-2 和 Llama 2）进行事实对齐，使用 DPO 和 SALT 算法减少幻觉并提升生成质量。研究结果显示，这种基于 LLMs 的合成编辑反馈能显著增强临床事实性对齐，为实际医疗 NLP 应用提供了高效、可扩展的优化路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Equal contribution for the first two authors; To appear in\n  proceedings of the Main Conference on Empirical Methods in Natural Language\n  Processing (EMNLP) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13919v4",
      "published_date": "2024-02-21 16:33:22 UTC",
      "updated_date": "2024-10-03 02:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:37:48.336547"
    },
    {
      "arxiv_id": "2402.13917v2",
      "title": "Could We Have Had Better Multilingual LLMs If English Was Not the Central Language?",
      "title_zh": "如果英语不是中心语言，我们是否能有更好的多语言大语言模型？",
      "authors": [
        "Ryandito Diandaru",
        "Lucky Susanto",
        "Zilu Tang",
        "Ayu Purwarianti",
        "Derry Wijaya"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate strong machine translation\ncapabilities on languages they are trained on. However, the impact of factors\nbeyond training data size on translation performance remains a topic of debate,\nespecially concerning languages not directly encountered during training. Our\nstudy delves into Llama2's translation capabilities. By modeling a linear\nrelationship between linguistic feature distances and machine translation\nscores, we ask ourselves if there are potentially better central languages for\nLLMs other than English. Our experiments show that the 7B Llama2 model yields\nabove 10 BLEU when translating into all languages it has seen, which rarely\nhappens for languages it has not seen. Most translation improvements into\nunseen languages come from scaling up the model size rather than instruction\ntuning or increasing shot count. Furthermore, our correlation analysis reveals\nthat syntactic similarity is not the only linguistic factor that strongly\ncorrelates with machine translation scores. Interestingly, we discovered that\nunder specific circumstances, some languages (e.g. Swedish, Catalan), despite\nhaving significantly less training data, exhibit comparable correlation levels\nto English. These insights challenge the prevailing landscape of LLMs,\nsuggesting that models centered around languages other than English could\nprovide a more efficient foundation for multilingual applications.",
      "tldr_zh": "这篇论文探讨了如果不以英语为中心语言，是否能开发出更有效的多语言大型语言模型（LLMs）。研究者通过分析 Llama2 模型的翻译能力，并建模语言特征距离与机器翻译分数的线性关系，发现模型规模的增加比指令微调或增加样本数更能提升对未见语言的翻译性能（BLEU 分数超过 10）。此外，相关性分析显示句法相似性并非唯一因素，有些语言如瑞典语和加泰罗尼亚语尽管训练数据较少，却表现出与英语相当的相关性，暗示以其他语言为中心可能为多语言应用提供更高效的模型基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "TDLE 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13917v2",
      "published_date": "2024-02-21 16:32:38 UTC",
      "updated_date": "2024-04-05 05:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:37:59.531229"
    },
    {
      "arxiv_id": "2402.13914v2",
      "title": "Position: Explain to Question not to Justify",
      "title_zh": "翻译失败",
      "authors": [
        "Przemyslaw Biecek",
        "Wojciech Samek"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) is a young but very promising field\nof research. Unfortunately, the progress in this field is currently slowed down\nby divergent and incompatible goals. We separate various threads tangled within\nthe area of XAI into two complementary cultures of human/value-oriented\nexplanations (BLUE XAI) and model/validation-oriented explanations (RED XAI).\nThis position paper argues that the area of RED XAI is currently\nunder-explored, i.e., more methods for explainability are desperately needed to\nquestion models (e.g., extract knowledge from well-performing models as well as\nspotting and fixing bugs in faulty models), and the area of RED XAI hides great\nopportunities and potential for important research necessary to ensure the\nsafety of AI systems. We conclude this paper by presenting promising challenges\nin this area.",
      "tldr_zh": "这篇立场论文讨论了 Explainable Artificial Intelligence (XAI) 领域中目标不一致的问题，将其分为两种互补文化：BLUE XAI（人类/价值导向的解释）和 RED XAI（模型/验证导向的解释）。论文主张 RED XAI 当前被低估，亟需开发更多方法来质疑模型、提取知识并修复错误，从而提升 AI 系统的安全性和可靠性。最终，论文指出了 RED XAI 领域的关键挑战，为未来研究提供了潜在机会。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13914v2",
      "published_date": "2024-02-21 16:30:24 UTC",
      "updated_date": "2024-06-28 08:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:38:10.455565"
    },
    {
      "arxiv_id": "2402.13897v2",
      "title": "Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Loïc Rakotoson",
        "Sylvain Massip",
        "Fréjus A. A. Laleye"
      ],
      "abstract": "Information retrieval is a rapidly evolving field. However it still faces\nsignificant limitations in the scientific and industrial vast amounts of\ninformation, such as semantic divergence and vocabulary gaps in sparse\nretrieval, low precision and lack of interpretability in semantic search, or\nhallucination and outdated information in generative models. In this paper, we\nintroduce a two-block approach to tackle these hurdles for long documents. The\nfirst block enhances language understanding in sparse retrieval by query\nexpansion to retrieve relevant documents. The second block deepens the result\nby providing comprehensive and informative answers to the complex question\nusing only the information spread in the long document, enabling bidirectional\nengagement. At various stages of the pipeline, intermediate results are\npresented to users to facilitate understanding of the system's reasoning. We\nbelieve this bidirectional approach brings significant advancements in terms of\ntransparency, logical thinking, and comprehensive understanding in the field of\nscientific information retrieval.",
      "tldr_zh": "该论文提出“Science Checker Reloaded”，一种双向范式（bidirectional paradigm），旨在解决信息检索领域的挑战，如语义分歧（semantic divergence）、词汇差距和稀疏检索（sparse retrieval）的低精度问题。方法包括两个模块：第一模块通过查询扩展（query expansion）增强稀疏检索，以获取相关长文档；第二模块基于这些文档提供全面、信息的答案，实现双向互动（bidirectional engagement）。通过在管道各阶段呈现中间结果，该方法提高了系统的透明度和逻辑推理能力，在科学信息检索的全面理解方面取得了显著进步。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "H.3.1; H.3.3; I.7; K.4"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13897v2",
      "published_date": "2024-02-21 16:09:25 UTC",
      "updated_date": "2024-03-14 00:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:38:22.468941"
    },
    {
      "arxiv_id": "2402.14047v2",
      "title": "Simple and Effective Transfer Learning for Neuro-Symbolic Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Daniele",
        "Tommaso Campari",
        "Sagar Malhotra",
        "Luciano Serafini"
      ],
      "abstract": "Deep Learning (DL) techniques have achieved remarkable successes in recent\nyears. However, their ability to generalize and execute reasoning tasks remains\na challenge. A potential solution to this issue is Neuro-Symbolic Integration\n(NeSy), where neural approaches are combined with symbolic reasoning. Most of\nthese methods exploit a neural network to map perceptions to symbols and a\nlogical reasoner to predict the output of the downstream task. These methods\nexhibit superior generalization capacity compared to fully neural\narchitectures. However, they suffer from several issues, including slow\nconvergence, learning difficulties with complex perception tasks, and\nconvergence to local minima. This paper proposes a simple yet effective method\nto ameliorate these problems. The key idea involves pretraining a neural model\non the downstream task. Then, a NeSy model is trained on the same task via\ntransfer learning, where the weights of the perceptual part are injected from\nthe pretrained network. The key observation of our work is that the neural\nnetwork fails to generalize only at the level of the symbolic part while being\nperfectly capable of learning the mapping from perceptions to symbols. We have\ntested our training strategy on various SOTA NeSy methods and datasets,\ndemonstrating consistent improvements in the aforementioned problems.",
      "tldr_zh": "本文提出了一种简单有效的转移学习(Transfer Learning)方法，用于改善 Neuro-Symbolic Integration (NeSy) 的性能问题。NeSy 通过结合神经网络和符号推理来提升泛化和推理能力，但常面临慢收敛、复杂感知任务学习困难以及收敛到局部最小的挑战。关键方法是先在下游任务上预训练神经模型，然后通过转移学习将预训练的感知部分权重注入 NeSy 模型，利用神经网络在感知到符号映射上的优势。实验在多种 SOTA NeSy 方法和数据集上验证了该策略，能显著提升收敛速度和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as full paper at the International Conference on\n  Neural-Symbolic Learning and Reasoning (NeSy 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.14047v2",
      "published_date": "2024-02-21 15:51:01 UTC",
      "updated_date": "2024-07-15 08:49:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:38:34.861141"
    },
    {
      "arxiv_id": "2402.13871v1",
      "title": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Amaz Uddin",
        "Iqbal H. Sarker"
      ],
      "abstract": "Phishing email is a serious cyber threat that tries to deceive users by\nsending false emails with the intention of stealing confidential information or\ncausing financial harm. Attackers, often posing as trustworthy entities,\nexploit technological advancements and sophistication to make detection and\nprevention of phishing more challenging. Despite extensive academic research,\nphishing detection remains an ongoing and formidable challenge in the\ncybersecurity landscape. Large Language Models (LLMs) and Masked Language\nModels (MLMs) possess immense potential to offer innovative solutions to\naddress long-standing challenges. In this research paper, we present an\noptimized, fine-tuned transformer-based DistilBERT model designed for the\ndetection of phishing emails. In the detection process, we work with a phishing\nemail dataset and utilize the preprocessing techniques to clean and solve the\nimbalance class issues. Through our experiments, we found that our model\neffectively achieves high accuracy, demonstrating its capability to perform\nwell. Finally, we demonstrate our fine-tuned model using Explainable-AI (XAI)\ntechniques such as Local Interpretable Model-Agnostic Explanations (LIME) and\nTransformer Interpret to explain how our model makes predictions in the context\nof text classification for phishing emails.",
      "tldr_zh": "这篇论文针对钓鱼邮件检测的严峻挑战，提出了一种基于Transformer的DistilBERT模型，通过Large Language Models (LLMs) 和Masked Language Models (MLMs) 进行优化微调。研究者利用数据集预处理技术（如清洗和解决类别不平衡问题）来提升模型性能，实验结果显示该模型实现了高准确率。最终，通过Explainable-AI (XAI) 技术，包括Local Interpretable Model-Agnostic Explanations (LIME) 和Transformer Interpret，对模型的预测过程进行了可解释分析，从而增强了钓鱼邮件检测的可信度和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13871v1",
      "published_date": "2024-02-21 15:23:21 UTC",
      "updated_date": "2024-02-21 15:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:38:47.030815"
    },
    {
      "arxiv_id": "2402.13866v2",
      "title": "Kuaiji: the First Chinese Accounting Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayuan Luo",
        "Songhua Yang",
        "Xiaoling Qiu",
        "Panyu Chen",
        "Yufei Nai",
        "Wenxuan Zeng",
        "Wentao Zhang",
        "Xinke Jiang"
      ],
      "abstract": "Large Language Models (LLMs) like ChatGPT and GPT-4 have demonstrated\nimpressive proficiency in comprehending and generating natural language.\nHowever, they encounter difficulties when tasked with adapting to specialized\ndomains such as accounting. To address this challenge, we introduce Kuaiji, a\ntailored Accounting Large Language Model. Kuaiji is meticulously fine-tuned\nusing the Baichuan framework, which encompasses continuous pre-training and\nsupervised fine-tuning processes. Supported by CAtAcctQA, a dataset containing\nlarge genuine accountant-client dialogues, Kuaiji exhibits exceptional accuracy\nand response speed. Our contributions encompass the creation of the first\nChinese accounting dataset, the establishment of Kuaiji as a leading\nopen-source Chinese accounting LLM, and the validation of its efficacy through\nreal-world accounting scenarios.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)如ChatGPT和GPT-4在会计领域的适应困难，引入了Kuaiji，这是首个专为中文会计场景设计的LLM。Kuaiji基于Baichuan框架，通过连续预训练和监督微调，利用CAtAcctQA数据集（包含真实会计师-客户对话）进行优化，提升了模型的准确性和响应速度。主要贡献包括创建第一个中文会计数据集、开发Kuaiji作为领先的开源中文会计LLM，以及通过真实世界会计场景验证其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "version 2.0",
      "pdf_url": "http://arxiv.org/pdf/2402.13866v2",
      "published_date": "2024-02-21 15:14:20 UTC",
      "updated_date": "2024-02-24 07:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:38:59.372693"
    },
    {
      "arxiv_id": "2402.14872v2",
      "title": "Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxia Li",
        "Siyuan Liang",
        "Jiyi Zhang",
        "Han Fang",
        "Aishan Liu",
        "Ee-Chien Chang"
      ],
      "abstract": "Large Language Models (LLMs), used in creative writing, code generation, and\ntranslation, generate text based on input sequences but are vulnerable to\njailbreak attacks, where crafted prompts induce harmful outputs. Most jailbreak\nprompt methods use a combination of jailbreak templates followed by questions\nto ask to create jailbreak prompts. However, existing jailbreak prompt designs\ngenerally suffer from excessive semantic differences, resulting in an inability\nto resist defenses that use simple semantic metrics as thresholds. Jailbreak\nprompts are semantically more varied than the original questions used for\nqueries. In this paper, we introduce a Semantic Mirror Jailbreak (SMJ) approach\nthat bypasses LLMs by generating jailbreak prompts that are semantically\nsimilar to the original question. We model the search for jailbreak prompts\nthat satisfy both semantic similarity and jailbreak validity as a\nmulti-objective optimization problem and employ a standardized set of genetic\nalgorithms for generating eligible prompts. Compared to the baseline\nAutoDAN-GA, SMJ achieves attack success rates (ASR) that are at most 35.4%\nhigher without ONION defense and 85.2% higher with ONION defense. SMJ's better\nperformance in all three semantic meaningfulness metrics of Jailbreak Prompt,\nSimilarity, and Outlier, also means that SMJ is resistant to defenses that use\nthose metrics as thresholds.",
      "tldr_zh": "本文提出 Semantic Mirror Jailbreak (SMJ) 方法，使用 genetic algorithms 生成语义上与原问题相似的 jailbreak 提示，以攻击开源 Large Language Models (LLMs)，从而绕过基于语义指标的防御。SMJ 将提示生成建模为多目标优化问题，优化语义相似性和 jailbreak 有效性，同时避免现有方法的语义差异过大问题。与基线 AutoDAN-GA 相比，SMJ 的攻击成功率 (ASR) 最高提高 35.4% (无 ONION 防御) 和 85.2% (有 ONION 防御)，并在 Jailbreak Prompt、Similarity 和 Outlier 等指标上表现出色，更能抵抗相关防御机制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14872v2",
      "published_date": "2024-02-21 15:13:50 UTC",
      "updated_date": "2024-02-27 13:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:39:11.873700"
    },
    {
      "arxiv_id": "2402.13853v2",
      "title": "RealDex: Towards Human-like Grasping for Robotic Dexterous Hand",
      "title_zh": "翻译失败",
      "authors": [
        "Yumeng Liu",
        "Yaxun Yang",
        "Youzhuo Wang",
        "Xiaofei Wu",
        "Jiamin Wang",
        "Yichen Yao",
        "Sören Schwertfeger",
        "Sibei Yang",
        "Wenping Wang",
        "Jingyi Yu",
        "Xuming He",
        "Yuexin Ma"
      ],
      "abstract": "In this paper, we introduce RealDex, a pioneering dataset capturing authentic\ndexterous hand grasping motions infused with human behavioral patterns,\nenriched by multi-view and multimodal visual data. Utilizing a teleoperation\nsystem, we seamlessly synchronize human-robot hand poses in real time. This\ncollection of human-like motions is crucial for training dexterous hands to\nmimic human movements more naturally and precisely. RealDex holds immense\npromise in advancing humanoid robot for automated perception, cognition, and\nmanipulation in real-world scenarios. Moreover, we introduce a cutting-edge\ndexterous grasping motion generation framework, which aligns with human\nexperience and enhances real-world applicability through effectively utilizing\nMultimodal Large Language Models. Extensive experiments have demonstrated the\nsuperior performance of our method on RealDex and other open datasets. The\ncomplete dataset and code will be made available upon the publication of this\nwork.",
      "tldr_zh": "本文提出 RealDex 数据集，该数据集捕捉了融入人类行为模式的真实 dexterous hand 抓取动作，并包含多视图和多模态视觉数据，通过 teleoperation system 实现人类和机器人手姿势的实时同步。RealDex 用于训练机器人灵巧手更自然精确地模仿人类动作，从而提升人形机器人在真实场景中的感知、认知和操作能力。此外，作者引入一个先进的 dexterous grasping 动作生成框架，利用 Multimodal Large Language Models 与人类经验对齐，提高实际应用性。实验结果显示，该框架在 RealDex 和其他公开数据集上表现出色，性能优于基线方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://4dvlab.github.io/RealDex_page/",
      "pdf_url": "http://arxiv.org/pdf/2402.13853v2",
      "published_date": "2024-02-21 14:59:46 UTC",
      "updated_date": "2024-12-07 04:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:39:23.162137"
    },
    {
      "arxiv_id": "2402.13852v3",
      "title": "Neural Control System for Continuous Glucose Monitoring and Maintenance",
      "title_zh": "翻译失败",
      "authors": [
        "Azmine Toushik Wasi"
      ],
      "abstract": "Precise glucose level monitoring is critical for people with diabetes to\navoid serious complications. While there are several methods for continuous\nglucose level monitoring, research on maintenance devices is limited. To\nmitigate the gap, we provide a novel neural control system for continuous\nglucose monitoring and management that uses differential predictive control.\nOur approach, led by a sophisticated neural policy and differentiable modeling,\nconstantly adjusts insulin supply in real-time, thereby improving glucose level\noptimization in the body. This end-to-end method maximizes efficiency,\nproviding personalized care and improved health outcomes, as confirmed by\nempirical evidence. Code and data are available at:\n\\url{https://github.com/azminewasi/NeuralCGMM}.",
      "tldr_zh": "该论文提出了一种Neural Control System，用于连续血糖监测和维护，以解决糖尿病患者管理中的关键挑战。该系统采用differential predictive control、neural policy和differentiable modeling，实时调整胰岛素供应，实现体内的血糖水平优化。作为一个end-to-end方法，它提供个性化的护理，并通过实证证据证实了其效率和健康益处。代码和数据可从GitHub获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.SY",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "9 Pages, 4 figures, ICLR 2024 Tiny Papers Track\n  https://openreview.net/forum?id=Te4P3Cn54g",
      "pdf_url": "http://arxiv.org/pdf/2402.13852v3",
      "published_date": "2024-02-21 14:56:36 UTC",
      "updated_date": "2024-06-07 11:16:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:39:35.365006"
    },
    {
      "arxiv_id": "2402.13846v2",
      "title": "Large Language Models are Advanced Anonymizers",
      "title_zh": "翻译失败",
      "authors": [
        "Robin Staab",
        "Mark Vero",
        "Mislav Balunović",
        "Martin Vechev"
      ],
      "abstract": "Recent privacy research on large language models (LLMs) has shown that they\nachieve near-human-level performance at inferring personal data from online\ntexts. With ever-increasing model capabilities, existing text anonymization\nmethods are currently lacking behind regulatory requirements and adversarial\nthreats. In this work, we take two steps to bridge this gap: First, we present\na new setting for evaluating anonymization in the face of adversarial LLM\ninferences, allowing for a natural measurement of anonymization performance\nwhile remedying some of the shortcomings of previous metrics. Then, within this\nsetting, we develop a novel LLM-based adversarial anonymization framework\nleveraging the strong inferential capabilities of LLMs to inform our\nanonymization procedure. We conduct a comprehensive experimental evaluation of\nadversarial anonymization across 13 LLMs on real-world and synthetic online\ntexts, comparing it against multiple baselines and industry-grade anonymizers.\nOur evaluation shows that adversarial anonymization outperforms current\ncommercial anonymizers both in terms of the resulting utility and privacy. We\nsupport our findings with a human study (n=50) highlighting a strong and\nconsistent human preference for LLM-anonymized texts.",
      "tldr_zh": "该研究发现，大语言模型 (LLMs) 在从在线文本中推断个人信息方面已达到接近人类水平，但现有文本匿名化方法无法满足监管要求和对抗性威胁。论文提出一个新的评估设置和基于 LLMs 的对抗匿名化框架，利用 LLMs 的强大推理能力来优化匿名化过程。实验结果显示，该框架在 13 个 LLMs 上处理真实和合成文本时，在隐私和效用方面优于多个基线和商业匿名器，且一项人类研究 (n=50) 证实人们更倾向于 LLMs 匿名化的文本。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "International Conference on Learning Representations (ICLR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.13846v2",
      "published_date": "2024-02-21 14:44:00 UTC",
      "updated_date": "2025-02-03 16:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:39:48.257782"
    },
    {
      "arxiv_id": "2402.13840v2",
      "title": "Multi-view Intent Learning and Alignment with Large Language Models for Session-based Recommendation",
      "title_zh": "多视图意图学习与对齐，使用大型语言模型，用于基于会话的推荐",
      "authors": [
        "Shutong Qiao",
        "Wei Zhou",
        "Junhao Wen",
        "Chen Gao",
        "Qun Luo",
        "Peixuan Chen",
        "Yong Li"
      ],
      "abstract": "Session-based recommendation (SBR) methods often rely on user behavior data,\nwhich can struggle with the sparsity of session data, limiting performance.\nResearchers have identified that beyond behavioral signals, rich semantic\ninformation in item descriptions is crucial for capturing hidden user intent.\nWhile large language models (LLMs) offer new ways to leverage this semantic\ndata, the challenges of session anonymity, short-sequence nature, and high LLM\ntraining costs have hindered the development of a lightweight, efficient LLM\nframework for SBR.\n  To address the above challenges, we propose an LLM-enhanced SBR framework\nthat integrates semantic and behavioral signals from multiple views. This\ntwo-stage framework leverages the strengths of both LLMs and traditional SBR\nmodels while minimizing training costs. In the first stage, we use multi-view\nprompts to infer latent user intentions at the session semantic level,\nsupported by an intent localization module to alleviate LLM hallucinations. In\nthe second stage, we align and unify these semantic inferences with behavioral\nrepresentations, effectively merging insights from both large and small models.\nExtensive experiments on two real datasets demonstrate that the LLM4SBR\nframework can effectively improve model performance. We release our codes along\nwith the baselines at https://github.com/tsinghua-fib-lab/LLM4SBR.",
      "tldr_zh": "本研究针对基于会话的推荐系统（SBR）面临的会话数据稀疏问题，提出了一种整合语义和行为信号的LLM增强框架（LLM4SBR）。该框架采用两阶段方法：第一阶段通过多-view提示和意图定位模块推断潜在用户意图，同时缓解LLMs的幻觉问题；第二阶段则对语义推理与行为表示进行对齐和统一，融合大模型和小模型的优点。实验在两个真实数据集上证明，该框架显著提升了推荐性能，并开源了代码以便进一步研究。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13840v2",
      "published_date": "2024-02-21 14:38:02 UTC",
      "updated_date": "2025-04-14 02:13:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:39:59.503826"
    },
    {
      "arxiv_id": "2402.13820v1",
      "title": "FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Li",
        "Elijah Stanger-Jones",
        "Steve Heim",
        "Sangbae Kim"
      ],
      "abstract": "Motion trajectories offer reliable references for physics-based motion\nlearning but suffer from sparsity, particularly in regions that lack sufficient\ndata coverage. To address this challenge, we introduce a self-supervised,\nstructured representation and generation method that extracts spatial-temporal\nrelationships in periodic or quasi-periodic motions. The motion dynamics in a\ncontinuously parameterized latent space enable our method to enhance the\ninterpolation and generalization capabilities of motion learning algorithms.\nThe motion learning controller, informed by the motion parameterization,\noperates online tracking of a wide range of motions, including targets unseen\nduring training. With a fallback mechanism, the controller dynamically adapts\nits tracking strategy and automatically resorts to safe action execution when a\npotentially risky target is proposed. By leveraging the identified\nspatial-temporal structure, our work opens new possibilities for future\nadvancements in general motion representation and learning algorithms.",
      "tldr_zh": "本论文提出FLD（Fourier Latent Dynamics）方法，通过自监督学习提取周期性或准周期性运动中的空间-时间关系，从而解决运动轨迹数据稀疏性问题。FLD在连续参数化的潜在空间中表示运动动态，提升了运动学习算法的插值和泛化能力，并支持在线跟踪各种运动，包括训练中未见的目标。实验表明，该方法配备后备机制，能动态调整跟踪策略并执行安全动作，为通用运动表示和学习算法的未来发展提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13820v1",
      "published_date": "2024-02-21 13:59:21 UTC",
      "updated_date": "2024-02-21 13:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:40:10.993296"
    },
    {
      "arxiv_id": "2402.14871v1",
      "title": "LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele Musumeci",
        "Michele Brienza",
        "Vincenzo Suriani",
        "Daniele Nardi",
        "Domenico Daniele Bloisi"
      ],
      "abstract": "In the last years' digitalization process, the creation and management of\ndocuments in various domains, particularly in Public Administration (PA), have\nbecome increasingly complex and diverse. This complexity arises from the need\nto handle a wide range of document types, often characterized by\nsemi-structured forms. Semi-structured documents present a fixed set of data\nwithout a fixed format. As a consequence, a template-based solution cannot be\nused, as understanding a document requires the extraction of the data\nstructure. The recent introduction of Large Language Models (LLMs) has enabled\nthe creation of customized text output satisfying user requests. In this work,\nwe propose a novel approach that combines the LLMs with prompt engineering and\nmulti-agent systems for generating new documents compliant with a desired\nstructure. The main contribution of this work concerns replacing the commonly\nused manual prompting with a task description generated by semantic retrieval\nfrom an LLM. The potential of this approach is demonstrated through a series of\nexperiments and case studies, showcasing its effectiveness in real-world PA\nscenarios.",
      "tldr_zh": "本文提出了一种基于LLMs（Large Language Models）和多智能体系统的创新方法，用于从语义模板生成公共行政（PA）领域的半结构化文档，以应对文档复杂性和格式灵活性的挑战。该方法的核心贡献是通过语义检索从LLM生成任务描述，取代传统的manual prompting，从而提升文档生成的可定制性和准确性。实验和案例研究证明了该方法在真实PA场景中的有效性，为文档自动化管理提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at HCI INTERNATIONAL 2024 - 26th International Conference on\n  Human-Computer Interaction. Washington Hilton Hotel, Washington DC, USA, 29\n  June - 4 July 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14871v1",
      "published_date": "2024-02-21 13:54:53 UTC",
      "updated_date": "2024-02-21 13:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:40:22.915591"
    },
    {
      "arxiv_id": "2402.13809v3",
      "title": "NeuralDiffuser: Neuroscience-inspired Diffusion Guidance for fMRI Visual Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Li",
        "Hao Wu",
        "Badong Chen"
      ],
      "abstract": "Reconstructing visual stimuli from functional Magnetic Resonance Imaging fMRI\nenables fine-grained retrieval of brain activity. However, the accurate\nreconstruction of diverse details, including structure, background, texture,\ncolor, and more, remains challenging. The stable diffusion models inevitably\nresult in the variability of reconstructed images, even under identical\nconditions. To address this challenge, we first uncover the neuroscientific\nperspective of diffusion methods, which primarily involve top-down creation\nusing pre-trained knowledge from extensive image datasets, but tend to lack\ndetail-driven bottom-up perception, leading to a loss of faithful details. In\nthis paper, we propose NeuralDiffuser, which incorporates primary visual\nfeature guidance to provide detailed cues in the form of gradients. This\nextension of the bottom-up process for diffusion models achieves both semantic\ncoherence and detail fidelity when reconstructing visual stimuli. Furthermore,\nwe have developed a novel guidance strategy for reconstruction tasks that\nensures the consistency of repeated outputs with original images rather than\nwith various outputs. Extensive experimental results on the Natural Senses\nDataset (NSD) qualitatively and quantitatively demonstrate the advancement of\nNeuralDiffuser by comparing it against baseline and state-of-the-art methods\nhorizontally, as well as conducting longitudinal ablation studies.",
      "tldr_zh": "本论文提出 NeuralDiffuser，一种受神经科学启发的扩散指导框架，用于从 fMRI 数据重建视觉刺激，以解决现有扩散模型在细节重建（如结构、背景、纹理和颜色）上的变异性和细节丢失问题。该框架通过融入初级视觉特征指导，提供梯度形式的详细线索，增强扩散模型的 bottom-up 过程，从而实现重建图像的语义连贯性和细节保真，同时引入一种新指导策略确保输出一致性。在 Natural Senses Dataset (NSD) 上进行的实验表明，NeuralDiffuser 相比基线和最先进方法在定性和定量指标上表现出显著优势，并通过纵向消融研究验证了其有效性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13809v3",
      "published_date": "2024-02-21 13:46:25 UTC",
      "updated_date": "2025-01-08 14:21:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:40:35.420590"
    },
    {
      "arxiv_id": "2402.13785v2",
      "title": "Composing Reinforcement Learning Policies, with Formal Guarantees",
      "title_zh": "强化学习策略的组合，具有形式化保证",
      "authors": [
        "Florent Delgrange",
        "Guy Avni",
        "Anna Lukina",
        "Christian Schilling",
        "Ann Nowé",
        "Guillermo A. Pérez"
      ],
      "abstract": "We propose a novel framework to controller design in environments with a\ntwo-level structure: a known high-level graph (\"map\") in which each vertex is\npopulated by a Markov decision process, called a \"room\". The framework\n\"separates concerns\" by using different design techniques for low- and\nhigh-level tasks. We apply reactive synthesis for high-level tasks: given a\nspecification as a logical formula over the high-level graph and a collection\nof low-level policies obtained together with \"concise\" latent structures, we\nconstruct a \"planner\" that selects which low-level policy to apply in each\nroom. We develop a reinforcement learning procedure to train low-level policies\non latent structures, which unlike previous approaches, circumvents a model\ndistillation step. We pair the policy with probably approximately correct\nguarantees on its performance and on the abstraction quality, and lift these\nguarantees to the high-level task. These formal guarantees are the main\nadvantage of the framework. Other advantages include scalability (rooms are\nlarge and their dynamics are unknown) and reusability of low-level policies. We\ndemonstrate feasibility in challenging case studies where an agent navigates\nenvironments with moving obstacles and visual inputs.",
      "tldr_zh": "本文提出一个新框架，用于在两级结构环境中设计强化学习(Reinforcement Learning)控制器：高层使用反应性合成(Reactive Synthesis)基于逻辑公式构建规划器，选择在每个马尔可夫决策过程(Markov Decision Process) \"房间\" 中应用低层策略。框架通过强化学习过程训练低层策略，利用潜在结构(latent structures)避免模型蒸馏步骤，并提供大致的正确(Probably Approximately Correct)保证，确保策略性能和抽象质量的可靠性。该框架的优势包括可伸缩性、低层策略的可重用性，并在挑战性案例研究中（如代理在有移动障碍和视觉输入的环境中导航）中证明其可行性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "AAMAS 2025, 8 pages main text, 19 pages Appendix (excluding\n  references)",
      "pdf_url": "http://arxiv.org/pdf/2402.13785v2",
      "published_date": "2024-02-21 13:10:58 UTC",
      "updated_date": "2025-03-10 11:38:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:40:48.336568"
    },
    {
      "arxiv_id": "2402.13782v1",
      "title": "Semirings for Probabilistic and Neuro-Symbolic Logic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Derkinderen",
        "Robin Manhaeve",
        "Pedro Zuidberg Dos Martires",
        "Luc De Raedt"
      ],
      "abstract": "The field of probabilistic logic programming (PLP) focuses on integrating\nprobabilistic models into programming languages based on logic. Over the past\n30 years, numerous languages and frameworks have been developed for modeling,\ninference and learning in probabilistic logic programs. While originally PLP\nfocused on discrete probability, more recent approaches have incorporated\ncontinuous distributions as well as neural networks, effectively yielding\nneural-symbolic methods. We provide a unified algebraic perspective on PLP,\nshowing that many if not most of the extensions of PLP can be cast within a\ncommon algebraic logic programming framework, in which facts are labeled with\nelements of a semiring and disjunction and conjunction are replaced by addition\nand multiplication. This does not only hold for the PLP variations itself but\nalso for the underlying execution mechanism that is based on (algebraic) model\ncounting.",
      "tldr_zh": "这篇论文从代数视角审视概率逻辑编程（PLP）和神经符号方法，提出一种统一的框架，将这些领域的许多扩展整合起来。框架利用 Semirings 来标记事实，并将传统的析取和合取运算替换为加法和乘法操作，从而简化了建模、推理和学习过程。该方法不仅适用于 PLP 的离散概率和连续分布变体，还扩展到神经网络以及基于代数模型计数的执行机制，为这些领域提供了更一致的理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13782v1",
      "published_date": "2024-02-21 13:06:52 UTC",
      "updated_date": "2024-02-21 13:06:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:41:01.249732"
    },
    {
      "arxiv_id": "2402.13779v1",
      "title": "Contextual Molecule Representation Learning from Chemical Reaction Knowledge",
      "title_zh": "基于化学反应知识的情境分子表示学习",
      "authors": [
        "Han Tang",
        "Shikun Feng",
        "Bicheng Lin",
        "Yuyan Ni",
        "JIngjing Liu",
        "Wei-Ying Ma",
        "Yanyan Lan"
      ],
      "abstract": "In recent years, self-supervised learning has emerged as a powerful tool to\nharness abundant unlabelled data for representation learning and has been\nbroadly adopted in diverse areas. However, when applied to molecular\nrepresentation learning (MRL), prevailing techniques such as masked sub-unit\nreconstruction often fall short, due to the high degree of freedom in the\npossible combinations of atoms within molecules, which brings insurmountable\ncomplexity to the masking-reconstruction paradigm. To tackle this challenge, we\nintroduce REMO, a self-supervised learning framework that takes advantage of\nwell-defined atom-combination rules in common chemistry. Specifically, REMO\npre-trains graph/Transformer encoders on 1.7 million known chemical reactions\nin the literature. We propose two pre-training objectives: Masked Reaction\nCentre Reconstruction (MRCR) and Reaction Centre Identification (RCI). REMO\noffers a novel solution to MRL by exploiting the underlying shared patterns in\nchemical reactions as \\textit{context} for pre-training, which effectively\ninfers meaningful representations of common chemistry knowledge. Such\ncontextual representations can then be utilized to support diverse downstream\nmolecular tasks with minimum finetuning, such as affinity prediction and\ndrug-drug interaction prediction. Extensive experimental results on\nMoleculeACE, ACNet, drug-drug interaction (DDI), and reaction type\nclassification show that across all tested downstream tasks, REMO outperforms\nthe standard baseline of single-molecule masked modeling used in current MRL.\nRemarkably, REMO is the pioneering deep learning model surpassing\nfingerprint-based methods in activity cliff benchmarks.",
      "tldr_zh": "本研究提出REMO，一种自监督学习框架，用于分子表示学习(MRL)，通过利用170万条化学反应的原子组合规则来解决传统masked sub-unit重建方法的局限性。具体而言，REMO采用Masked Reaction Centre Reconstruction (MRCR)和Reaction Centre Identification (RCI)作为预训练目标，在graph/Transformer编码器上进行预训练，从而从化学反应的共享模式中提取上下文化的分子表示。这些表示可轻松应用于下游任务，如亲和力预测和药物-药物相互作用(DDI)预测。实验结果显示，REMO在MoleculeACE、ACNet、DDI和反应类型分类等任务上优于基于单分子masked modeling的基线，并在activity cliff基准上首次超越指纹方法(fingerprint-based methods)。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2402.13779v1",
      "published_date": "2024-02-21 12:58:40 UTC",
      "updated_date": "2024-02-21 12:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:41:12.245056"
    },
    {
      "arxiv_id": "2402.13777v5",
      "title": "Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Chen",
        "Bhargav Ganguly",
        "Yang Xu",
        "Yongsheng Mei",
        "Tian Lan",
        "Vaneet Aggarwal"
      ],
      "abstract": "Deep generative models (DGMs) have demonstrated great success across various\ndomains, particularly in generating texts, images, and videos using models\ntrained from offline data. Similarly, data-driven decision-making and robotic\ncontrol also necessitate learning a generator function from the offline data to\nserve as the strategy or policy. In this case, applying deep generative models\nin offline policy learning exhibits great potential, and numerous studies have\nexplored in this direction. However, this field still lacks a comprehensive\nreview and so developments of different branches are relatively independent. In\nthis paper, we provide the first systematic review on the applications of deep\ngenerative models for offline policy learning. In particular, we cover five\nmainstream deep generative models, including Variational Auto-Encoders,\nGenerative Adversarial Networks, Normalizing Flows, Transformers, and Diffusion\nModels, and their applications in both offline reinforcement learning (offline\nRL) and imitation learning (IL). Offline RL and IL are two main branches of\noffline policy learning and are widely-adopted techniques for sequential\ndecision-making. Notably, for each type of DGM-based offline policy learning,\nwe distill its fundamental scheme, categorize related works based on the usage\nof the DGM, and sort out the development process of algorithms in that field.\nSubsequent to the main content, we provide in-depth discussions on deep\ngenerative models and offline policy learning as a summary, based on which we\npresent our perspectives on future research directions. This work offers a\nhands-on reference for the research progress in deep generative models for\noffline policy learning, and aims to inspire improved DGM-based offline RL or\nIL algorithms. For convenience, we maintain a paper list on\nhttps://github.com/LucasCJYSDL/DGMs-for-Offline-Policy-Learning.",
      "tldr_zh": "这篇论文提供了首个系统综述，探讨了Deep Generative Models在离线策略学习中的应用，包括Variational Auto-Encoders、Generative Adversarial Networks、Normalizing Flows、Transformers和Diffusion Models在离线强化学习(offline RL)和模仿学习(IL)中的具体使用。作者分类了相关工作，总结了每种模型的基本方案和发展过程，并讨论了算法的独立性和整合潜力。最终，论文基于这些分析，给出了未来研究方向的视角，并维护了一个论文列表以便参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "We restructured the paper and added more discussion",
      "pdf_url": "http://arxiv.org/pdf/2402.13777v5",
      "published_date": "2024-02-21 12:54:48 UTC",
      "updated_date": "2024-05-26 00:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:41:24.153291"
    },
    {
      "arxiv_id": "2402.13771v1",
      "title": "Mask-up: Investigating Biases in Face Re-identification for Masked Faces",
      "title_zh": "翻译失败",
      "authors": [
        "Siddharth D Jaiswal",
        "Ankit Kr. Verma",
        "Animesh Mukherjee"
      ],
      "abstract": "AI based Face Recognition Systems (FRSs) are now widely distributed and\ndeployed as MLaaS solutions all over the world, moreso since the COVID-19\npandemic for tasks ranging from validating individuals' faces while buying SIM\ncards to surveillance of citizens. Extensive biases have been reported against\nmarginalized groups in these systems and have led to highly discriminatory\noutcomes. The post-pandemic world has normalized wearing face masks but FRSs\nhave not kept up with the changing times. As a result, these systems are\nsusceptible to mask based face occlusion. In this study, we audit four\ncommercial and nine open-source FRSs for the task of face re-identification\nbetween different varieties of masked and unmasked images across five benchmark\ndatasets (total 14,722 images). These simulate a realistic\nvalidation/surveillance task as deployed in all major countries around the\nworld. Three of the commercial and five of the open-source FRSs are highly\ninaccurate; they further perpetuate biases against non-White individuals, with\nthe lowest accuracy being 0%. A survey for the same task with 85 human\nparticipants also results in a low accuracy of 40%. Thus a human-in-the-loop\nmoderation in the pipeline does not alleviate the concerns, as has been\nfrequently hypothesized in literature. Our large-scale study shows that\ndevelopers, lawmakers and users of such services need to rethink the design\nprinciples behind FRSs, especially for the task of face re-identification,\ntaking cognizance of observed biases.",
      "tldr_zh": "这篇论文调查了面部识别系统 (FRSs) 在处理戴口罩面部时的偏见问题，特别是在后疫情时代这些系统在面部重新识别任务中的表现。研究者审计了 4 个商业和 9 个开源 FRSs，使用 5 个基准数据集（共 14,722 图像）模拟真实验证/监控场景，结果显示三家商业和五家开源系统准确率极低，且进一步加剧了对非白人个体的歧视，准确率最低达 0%。此外，一项涉及 85 名人类的调查显示准确率仅为 40%，表明人类干预无法完全缓解这些偏见。论文呼吁开发者、法务者和用户重新审视 FRSs 的设计原则，以解决观察到的偏见问题。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2402.13771v1",
      "published_date": "2024-02-21 12:48:45 UTC",
      "updated_date": "2024-02-21 12:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:41:37.559876"
    },
    {
      "arxiv_id": "2402.13764v5",
      "title": "CriticEval: Evaluating Large Language Model as Critic",
      "title_zh": "翻译失败",
      "authors": [
        "Tian Lan",
        "Wenwei Zhang",
        "Chen Xu",
        "Heyan Huang",
        "Dahua Lin",
        "Kai Chen",
        "Xian-ling Mao"
      ],
      "abstract": "Critique ability, i.e., the capability of Large Language Models (LLMs) to\nidentify and rectify flaws in responses, is crucial for their applications in\nself-improvement and scalable oversight. While numerous studies have been\nproposed to evaluate critique ability of LLMs, their comprehensiveness and\nreliability are still limited. To overcome this problem, we introduce\nCriticEval, a novel benchmark designed to comprehensively and reliably evaluate\ncritique ability of LLMs. Specifically, to ensure the comprehensiveness,\nCriticEval evaluates critique ability from four dimensions across nine diverse\ntask scenarios. It evaluates both scalar-valued and textual critiques,\ntargeting responses of varying quality. To ensure the reliability, a large\nnumber of critiques are annotated to serve as references, enabling GPT-4 to\nevaluate textual critiques reliably. Extensive evaluations of open-source and\nclosed-source LLMs first validate the reliability of evaluation in CriticEval.\nThen, experimental results demonstrate the promising potential of open-source\nLLMs, the effectiveness of critique datasets and several intriguing\nrelationships between the critique ability and some critical factors, including\ntask types, response qualities and critique dimensions.",
      "tldr_zh": "本研究引入CriticEval，一种新型基准，用于全面可靠地评估Large Language Models (LLMs)的critique ability，即识别和修正响应缺陷的能力。CriticEval从四个维度覆盖九个多样化任务场景，评估标量值和文本批评，针对不同质量的响应，并利用大量标注数据和GPT-4作为参考以确保评估可靠性。实验结果验证了CriticEval的可靠性，突显了开源LLMs的潜力、critique数据集的有效性，以及critique ability与任务类型、响应质量和批评维度之间的关键关系。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13764v5",
      "published_date": "2024-02-21 12:38:59 UTC",
      "updated_date": "2024-10-20 05:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:41:48.966785"
    },
    {
      "arxiv_id": "2402.13754v4",
      "title": "Reinforcement learning-assisted quantum architecture search for variational quantum algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Kundu"
      ],
      "abstract": "A significant hurdle in the noisy intermediate-scale quantum (NISQ) era is\nidentifying functional quantum circuits. These circuits must also adhere to the\nconstraints imposed by current quantum hardware limitations. Variational\nquantum algorithms (VQAs), a class of quantum-classical optimization\nalgorithms, were developed to address these challenges in the currently\navailable quantum devices. However, the overall performance of VQAs depends on\nthe initialization strategy of the variational circuit, the structure of the\ncircuit (also known as ansatz), and the configuration of the cost function.\nFocusing on the structure of the circuit, in this thesis, we improve the\nperformance of VQAs by automating the search for an optimal structure for the\nvariational circuits using reinforcement learning (RL). Within the thesis, the\noptimality of a circuit is determined by evaluating its depth, the overall\ncount of gates and parameters, and its accuracy in solving the given problem.\nThe task of automating the search for optimal quantum circuits is known as\nquantum architecture search (QAS). The majority of research in QAS is primarily\nfocused on a noiseless scenario. Yet, the impact of noise on the QAS remains\ninadequately explored. In this thesis, we tackle the issue by introducing a\ntensor-based quantum circuit encoding, restrictions on environment dynamics to\nexplore the search space of possible circuits efficiently, an episode halting\nscheme to steer the agent to find shorter circuits, a double deep Q-network\n(DDQN) with an $\\epsilon$-greedy policy for better stability. The numerical\nexperiments on noiseless and noisy quantum hardware show that in dealing with\nvarious VQAs, our RL-based QAS outperforms existing QAS. Meanwhile, the methods\nwe propose in the thesis can be readily adapted to address a wide range of\nother VQAs.",
      "tldr_zh": "本研究提出了一种强化学习（RL）辅助的量子架构搜索（QAS）方法，用于优化变分量子算法（VQAs）的电路结构，以应对噪声中等规模量子（NISQ）时代硬件限制的挑战。具体而言，该方法引入张量-based 量子电路编码、环境动态限制、episode halting 方案以及双深Q网络（DDQN）结合ε-greedy 政策，来高效搜索电路深度、门数、参数数和准确性的最优组合。实验结果显示，在无噪声和有噪声量子硬件上，该RL-based QAS在多种VQAs任务中优于现有方法，同时易于扩展应用于其他变分量子算法。总的来说，此方法提升了VQAs的整体性能，为量子电路设计提供了自动化、可信赖的解决方案。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "With many pages, figures and tables, I, Akash Kundu upload the final\n  version of my thesis! Including reviewers response and a kind of brief\n  overview of recent quantum architecture search methods",
      "pdf_url": "http://arxiv.org/pdf/2402.13754v4",
      "published_date": "2024-02-21 12:30:39 UTC",
      "updated_date": "2024-10-01 19:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:42:01.832510"
    },
    {
      "arxiv_id": "2402.13752v1",
      "title": "AI-Powered Predictions for Electricity Load in Prosumer Communities",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksei Kychkin",
        "Georgios C. Chasparis"
      ],
      "abstract": "The flexibility in electricity consumption and production in communities of\nresidential buildings, including those with renewable energy sources and energy\nstorage (a.k.a., prosumers), can effectively be utilized through the\nadvancement of short-term demand response mechanisms. It is known that\nflexibility can further be increased if demand response is performed at the\nlevel of communities of prosumers, since aggregated groups can better\ncoordinate electricity consumption. However, the effectiveness of such\nshort-term optimization is highly dependent on the accuracy of electricity load\nforecasts both for each building as well as for the whole community. Structural\nvariations in the electricity load profile can be associated with different\nexogenous factors, such as weather conditions, calendar information and day of\nthe week, as well as user behavior. In this paper, we review a wide range of\nelectricity load forecasting techniques, that can provide significant\nassistance in optimizing load consumption in prosumer communities. We present\nand test artificial intelligence (AI) powered short-term load forecasting\nmethodologies that operate with black-box time series models, such as\nFacebook's Prophet and Long Short-term Memory (LSTM) models; season-based\nSARIMA and smoothing Holt-Winters models; and empirical regression-based models\nthat utilize domain knowledge. The integration of weather forecasts into\ndata-driven time series forecasts is also tested. Results show that the\ncombination of persistent and regression terms (adapted to the load forecasting\ntask) achieves the best forecast accuracy.",
      "tldr_zh": "这篇论文探讨了在 prosumer 社区（包含可再生能源和储能的住宅群）中，利用 AI 驱动的短期电力负载预测来优化需求响应机制，以提高电力消费协调效率。作者回顾了多种预测技术，包括黑箱时间序列模型（如 Prophet 和 LSTM）、季节性模型（如 SARIMA 和 Holt-Winters），以及基于经验的回归模型，并测试了整合天气预报的效果。结果显示，结合持久性项和回归项的模型在预测准确性上表现最佳，为 prosumer 社区的电力优化提供了有效的工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "It has been presented in the 18. Symposium Energieinnovation\n  (14.-16.02.2024). Further information can be found at:\n  https://www.tugraz.at/events/eninnov2024/home",
      "pdf_url": "http://arxiv.org/pdf/2402.13752v1",
      "published_date": "2024-02-21 12:23:09 UTC",
      "updated_date": "2024-02-21 12:23:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:42:14.328890"
    },
    {
      "arxiv_id": "2402.13750v1",
      "title": "Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Zhao",
        "Hao Qian",
        "Ziqi Liu",
        "Gong-Duo Zhang",
        "Lihong Gu"
      ],
      "abstract": "Recommendation systems are widely used in e-commerce websites and online\nplatforms to address information overload. However, existing systems primarily\nrely on historical data and user feedback, making it difficult to capture user\nintent transitions. Recently, Knowledge Base (KB)-based models are proposed to\nincorporate expert knowledge, but it struggle to adapt to new items and the\nevolving e-commerce environment. To address these challenges, we propose a\nnovel Large Language Model based Complementary Knowledge Enhanced\nRecommendation System (LLM-KERec). It introduces an entity extractor that\nextracts unified concept terms from item and user information. To provide\ncost-effective and reliable prior knowledge, entity pairs are generated based\non entity popularity and specific strategies. The large language model\ndetermines complementary relationships in each entity pair, constructing a\ncomplementary knowledge graph. Furthermore, a new complementary recall module\nand an Entity-Entity-Item (E-E-I) weight decision model refine the scoring of\nthe ranking model using real complementary exposure-click samples. Extensive\nexperiments conducted on three industry datasets demonstrate the significant\nperformance improvement of our model compared to existing approaches.\nAdditionally, detailed analysis shows that LLM-KERec enhances users' enthusiasm\nfor consumption by recommending complementary items. In summary, LLM-KERec\naddresses the limitations of traditional recommendation systems by\nincorporating complementary knowledge and utilizing a large language model to\ncapture user intent transitions, adapt to new items, and enhance recommendation\nefficiency in the evolving e-commerce landscape.",
      "tldr_zh": "本文提出 LLM-KERec，一种基于大型语言模型 (LLMs) 的互补知识增强推荐系统，旨在解决传统推荐系统难以捕捉用户意图变化和适应新物品的局限性。该模型通过实体提取器从物品和用户信息中提取统一概念术语，并利用实体流行度和特定策略生成实体对，然后由 LLMs 确定实体间的互补关系，构建互补知识图。进一步，引入互补回忆模块和 Entity-Entity-Item (E-E-I) 权重决策模型，使用真实数据精炼排名评分。在三个工业数据集上的实验显示，LLM-KERec 显著提升了推荐性能，并通过推荐互补物品增强了用户消费热情。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13750v1",
      "published_date": "2024-02-21 12:22:01 UTC",
      "updated_date": "2024-02-21 12:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:42:27.791893"
    },
    {
      "arxiv_id": "2403.14642v1",
      "title": "Revolutionising Distance Learning: A Comparative Study of Learning Progress with AI-Driven Tutoring",
      "title_zh": "翻译失败",
      "authors": [
        "Moritz Möller",
        "Gargi Nirmal",
        "Dario Fabietti",
        "Quintus Stierstorfer",
        "Mark Zakhvatkin",
        "Holger Sommerfeld",
        "Sven Schütt"
      ],
      "abstract": "Generative AI is expected to have a vast, positive impact on education;\nhowever, at present, this potential has not yet been demonstrated at scale at\nuniversity level. In this study, we present first evidence that generative AI\ncan increase the speed of learning substantially in university students. We\ntested whether using the AI-powered teaching assistant Syntea affected the\nspeed of learning of hundreds of distance learning students across more than 40\ncourses at the IU International University of Applied Sciences. Our analysis\nsuggests that using Syntea reduced their study time substantially--by about\n27\\% on average--in the third month after the release of Syntea. Taken\ntogether, the magnitude of the effect and the scalability of the approach\nimplicate generative AI as a key lever to significantly improve and accelerate\nlearning by personalisation.",
      "tldr_zh": "这篇论文比较了生成式 AI 在大学远程学习中的影响，特别评估了 AI 驱动教学助手 Syntea 对学习进度的作用。研究涉及数百名学生和超过 40 门课程，结果显示使用 Syntea 后，学生的学习时间在第三个月平均减少了 27%。这些发现首次证明生成式 AI 通过个性化教学，能大规模提升大学学习的效率和速度。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14642v1",
      "published_date": "2024-02-21 12:15:58 UTC",
      "updated_date": "2024-02-21 12:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:42:37.829719"
    },
    {
      "arxiv_id": "2402.13741v1",
      "title": "Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Guozheng Li",
        "Wenjun Ke",
        "Peng Wang",
        "Zijie Xu",
        "Ke Ji",
        "Jiajun Liu",
        "Ziyu Shang",
        "Qiqing Luo"
      ],
      "abstract": "The in-context learning (ICL) for relational triple extraction (RTE) has\nachieved promising performance, but still encounters two key challenges: (1)\nhow to design effective prompts and (2) how to select proper demonstrations.\nExisting methods, however, fail to address these challenges appropriately. On\nthe one hand, they usually recast RTE task to text-to-text prompting formats,\nwhich is unnatural and results in a mismatch between the output format at the\npre-training time and the inference time for large language models (LLMs). On\nthe other hand, they only utilize surface natural language features and lack\nconsideration of triple semantics in sample selection. These issues are\nblocking improved performance in ICL for RTE, thus we aim to tackle prompt\ndesigning and sample selection challenges simultaneously. To this end, we\ndevise a tabular prompting for RTE (\\textsc{TableIE}) which frames RTE task\ninto a table generation task to incorporate explicit structured information\ninto ICL, facilitating conversion of outputs to RTE structures. Then we propose\ninstructive in-context learning (I$^2$CL) which only selects and annotates a\nfew samples considering internal triple semantics in massive unlabeled samples.",
      "tldr_zh": "本论文针对关系三元组提取(RTE)中的 in-context learning (ICL) 挑战，提出了 tabular prompting for RTE（简称 TableIE），将 RTE 任务转化为表格生成任务，以融入结构化信息并解决输出格式不匹配问题。同时，引入 instructive in-context learning (I²CL)，通过考虑内部三元组语义在大量未标注样本中选择和标注少量样本。实验表明，这些方法能有效提升 ICL 的性能，避免了传统方法依赖表面语言特征的局限。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13741v1",
      "published_date": "2024-02-21 12:12:16 UTC",
      "updated_date": "2024-02-21 12:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:42:51.761240"
    },
    {
      "arxiv_id": "2402.13731v2",
      "title": "Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Chen",
        "Pengfei Cao",
        "Yubo Chen",
        "Yining Wang",
        "Shengping Liu",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Large language models (LLMs) store extensive factual knowledge, but the\nunderlying mechanisms remain unclear. Previous research suggests that factual\nknowledge is stored within multi-layer perceptron weights, and some storage\nunits exhibit degeneracy, referred to as Degenerate Knowledge Neurons (DKNs).\nDespite the novelty and unique properties of this concept, it has not been\nrigorously defined or systematically studied. We first consider the connection\nweight patterns of MLP neurons and define DKNs from both structural and\nfunctional aspects. Based on this, we introduce the Neurological Topology\nClustering method, which allows the formation of DKNs in any numbers and\nstructures, leading to a more accurate DKN acquisition. Furthermore, inspired\nby cognitive science, we explore the relationship between DKNs and the\nrobustness, evolvability, and complexity of LLMs. Our execution of 34\nexperiments under 6 settings demonstrates the connection between DKNs and these\nthree properties. The code will be available soon.",
      "tldr_zh": "本研究对大型语言模型(LLMs)中退化知识神经元(Degenerate Knowledge Neurons, DKNs)的机制进行了全面分析，揭示了事实知识主要存储在多层感知器(MLP)权重中，但DKNs的定义和作用尚未得到系统研究。作者从结构和功能角度定义了DKNs，并引入了Neurological Topology Clustering方法，以更精确地识别各种形式的DKNs。实验结果显示，DKNs与LLMs的鲁棒性、evolvability和complexity密切相关，通过34个实验验证了这些关联，为优化LLMs的知识存储提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13731v2",
      "published_date": "2024-02-21 11:50:32 UTC",
      "updated_date": "2024-06-17 03:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:43:02.384631"
    },
    {
      "arxiv_id": "2402.14867v1",
      "title": "Effects of term weighting approach with and without stop words removing on Arabic text classification",
      "title_zh": "翻译失败",
      "authors": [
        "Esra'a Alhenawi",
        "Ruba Abu Khurma",
        "Pedro A. Castillo",
        "Maribel G. Arenas"
      ],
      "abstract": "Classifying text is a method for categorizing documents into pre-established\ngroups. Text documents must be prepared and represented in a way that is\nappropriate for the algorithms used for data mining prior to classification. As\na result, a number of term weighting strategies have been created in the\nliterature to enhance text categorization algorithms' functionality. This study\ncompares the effects of Binary and Term frequency weighting feature\nmethodologies on the text's classification method when stop words are\neliminated once and when they are not. In recognition of assessing the effects\nof prior weighting of features approaches on classification results in terms of\naccuracy, recall, precision, and F-measure values, we used an Arabic data set\nmade up of 322 documents divided into six main topics (agriculture, economy,\nhealth, politics, science, and sport), each of which contains 50 documents,\nwith the exception of the health category, which contains 61 documents. The\nresults demonstrate that for all metrics, the term frequency feature weighting\napproach with stop word removal outperforms the binary approach, while for\naccuracy, recall, and F-Measure, the binary approach outperforms the TF\napproach without stop word removal. However, for precision, the two approaches\nproduce results that are very similar. Additionally, it is clear from the data\nthat, using the same phrase weighting approach, stop word removing increases\nclassification accuracy.",
      "tldr_zh": "这篇论文探讨了在阿拉伯语文本分类中，Binary 和 Term Frequency (TF) 术语权重方法的效果，比较了移除停用词与不移除停用词的情况。研究使用了一个包含 322 个文档的 Arabic 数据集，分为农业、经济、健康、政治、科技和体育等六个主题，并通过准确率、召回率、精确率和 F-Measure 指标进行评估。结果表明，TF 方法结合移除停用词在所有指标上优于 Binary 方法，而 Binary 方法在不移除停用词时在准确率、召回率和 F-Measure 上略胜于 TF 方法；在精确率上，二者表现相似，且移除停用词总体上提高了分类性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14867v1",
      "published_date": "2024-02-21 11:31:04 UTC",
      "updated_date": "2024-02-21 11:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:43:14.516837"
    },
    {
      "arxiv_id": "2402.14044v1",
      "title": "A new approach for solving global optimization and engineering problems based on modified Sea Horse Optimizer",
      "title_zh": "翻译失败",
      "authors": [
        "Fatma A. Hashim",
        "Reham R. Mostafa",
        "Ruba Abu Khurma",
        "Raneem Qaddoura",
        "P. A. Castillo"
      ],
      "abstract": "Sea Horse Optimizer (SHO) is a noteworthy metaheuristic algorithm that\nemulates various intelligent behaviors exhibited by sea horses, encompassing\nfeeding patterns, male reproductive strategies, and intricate movement\npatterns. To mimic the nuanced locomotion of sea horses, SHO integrates the\nlogarithmic helical equation and Levy flight, effectively incorporating both\nrandom movements with substantial step sizes and refined local exploitation.\nAdditionally, the utilization of Brownian motion facilitates a more\ncomprehensive exploration of the search space. This study introduces a robust\nand high-performance variant of the SHO algorithm named mSHO. The enhancement\nprimarily focuses on bolstering SHO's exploitation capabilities by replacing\nits original method with an innovative local search strategy encompassing three\ndistinct steps: a neighborhood-based local search, a global non-neighbor-based\nsearch, and a method involving circumnavigation of the existing search region.\nThese techniques improve mSHO algorithm's search capabilities, allowing it to\nnavigate the search space and converge toward optimal solutions efficiently.\nThe comprehensive results distinctly establish the supremacy and efficiency of\nthe mSHO method as an exemplary tool for tackling an array of optimization\nquandaries. The results show that the proposed mSHO algorithm has a total rank\nof 1 for CEC'2020 test functions. In contrast, the mSHO achieved the best value\nfor the engineering problems, recording a value of 0.012665, 2993.634, 0.01266,\n1.724967, 263.8915, 0.032255, 58507.14, 1.339956, and 0.23524 for the pressure\nvessel design, speed reducer design, tension/compression spring, welded beam\ndesign, three-bar truss engineering design, industrial refrigeration system,\nmulti-Product batch plant, cantilever beam problem, multiple disc clutch brake\nproblems, respectively.",
      "tldr_zh": "本研究提出了一种基于改进版 Sea Horse Optimizer (mSHO) 的新方法，用于解决全局优化和工程问题。mSHO 在原 SHO 算法的基础上增强了局部搜索能力，通过引入基于邻域的局部搜索、全局非邻域搜索以及搜索区域环绕策略，结合对数螺旋方程、Levy flight 和 Brownian motion 来优化搜索空间探索和收敛效率。实验结果显示，mSHO 在 CEC'2020 测试函数中排名第一，并在多个工程问题上取得最佳性能，例如压力容器设计的最优值为 0.012665，以及其他如速度减速器设计和焊接梁设计的具体数值。总体而言，该方法为优化难题提供了高效且可靠的工具。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14044v1",
      "published_date": "2024-02-21 11:28:00 UTC",
      "updated_date": "2024-02-21 11:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:43:25.406840"
    },
    {
      "arxiv_id": "2402.13714v1",
      "title": "An Evaluation of Large Language Models in Bioinformatics Research",
      "title_zh": "大型语言模型在生物信息学研究中的评估",
      "authors": [
        "Hengchuang Yin",
        "Zhonghui Gu",
        "Fanhao Wang",
        "Yiparemu Abuduhaibaier",
        "Yanqiao Zhu",
        "Xinming Tu",
        "Xian-Sheng Hua",
        "Xiao Luo",
        "Yizhou Sun"
      ],
      "abstract": "Large language models (LLMs) such as ChatGPT have gained considerable\ninterest across diverse research communities. Their notable ability for text\ncompletion and generation has inaugurated a novel paradigm for\nlanguage-interfaced problem solving. However, the potential and efficacy of\nthese models in bioinformatics remain incompletely explored. In this work, we\nstudy the performance LLMs on a wide spectrum of crucial bioinformatics tasks.\nThese tasks include the identification of potential coding regions, extraction\nof named entities for genes and proteins, detection of antimicrobial and\nanti-cancer peptides, molecular optimization, and resolution of educational\nbioinformatics problems. Our findings indicate that, given appropriate prompts,\nLLMs like GPT variants can successfully handle most of these tasks. In\naddition, we provide a thorough analysis of their limitations in the context of\ncomplicated bioinformatics tasks. In conclusion, we believe that this work can\nprovide new perspectives and motivate future research in the field of LLMs\napplications, AI for Science and bioinformatics.",
      "tldr_zh": "本文评估了Large Language Models (LLMs)，如ChatGPT，在生物信息学研究中的性能，涵盖任务如识别编码区域、提取基因和蛋白质的命名实体、检测抗菌和抗癌肽、分子优化以及解决教育问题。研究发现，通过适当的提示，LLMs 能够成功处理大多数任务，但仍存在局限性，尤其在复杂任务的准确性和可靠性方面。总体而言，该工作为LLMs 在AI for Science 和生物信息学领域的应用提供了新视角，并有望激励未来的相关研究。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2402.13714v1",
      "published_date": "2024-02-21 11:27:31 UTC",
      "updated_date": "2024-02-21 11:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:43:38.175826"
    },
    {
      "arxiv_id": "2402.13711v4",
      "title": "DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning",
      "title_zh": "DSLR：用于基于重演的图连续学习的多样性增强和结构学习",
      "authors": [
        "Seungyoon Choi",
        "Wonjoong Kim",
        "Sungwon Kim",
        "Yeonjun In",
        "Sein Kim",
        "Chanyoung Park"
      ],
      "abstract": "We investigate the replay buffer in rehearsal-based approaches for graph\ncontinual learning (GCL) methods. Existing rehearsal-based GCL methods select\nthe most representative nodes for each class and store them in a replay buffer\nfor later use in training subsequent tasks. However, we discovered that\nconsidering only the class representativeness of each replayed node makes the\nreplayed nodes to be concentrated around the center of each class, incurring a\npotential risk of overfitting to nodes residing in those regions, which\naggravates catastrophic forgetting. Moreover, as the rehearsal-based approach\nheavily relies on a few replayed nodes to retain knowledge obtained from\nprevious tasks, involving the replayed nodes that have irrelevant neighbors in\nthe model training may have a significant detrimental impact on model\nperformance. In this paper, we propose a GCL model named DSLR, specifically, we\ndevise a coverage-based diversity (CD) approach to consider both the class\nrepresentativeness and the diversity within each class of the replayed nodes.\nMoreover, we adopt graph structure learning (GSL) to ensure that the replayed\nnodes are connected to truly informative neighbors. Extensive experimental\nresults demonstrate the effectiveness and efficiency of DSLR. Our source code\nis available at https://github.com/seungyoon-Choi/DSLR_official.",
      "tldr_zh": "本文研究了基于重演(rehearsal-based)方法的图持续学习(Graph Continual Learning, GCL)中重演缓冲区的问题，指出现有方法仅关注类代表性导致节点集中在类中心，易造成过拟合和灾难性遗忘，并可能受无关邻居影响。针对这些问题，提出DSLR模型，通过覆盖-based多样性(Coverage-based Diversity, CD)方法增强重演节点的类代表性和内部多样性，并采用图结构学习(Graph Structure Learning, GSL)优化节点连接以保留真正信息丰富的邻居。实验结果证明DSLR在GCL任务上有效且高效，显著提高了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACM TheWebConf 2024 (WWW 2024) (Oral presentation)",
      "pdf_url": "http://arxiv.org/pdf/2402.13711v4",
      "published_date": "2024-02-21 11:25:54 UTC",
      "updated_date": "2024-03-03 08:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:43:50.848940"
    },
    {
      "arxiv_id": "2402.13709v2",
      "title": "SaGE: Evaluating Moral Consistency in Large Language Models",
      "title_zh": "SaGE：评估大语言模型中的道德一致性",
      "authors": [
        "Vamshi Krishna Bonagiri",
        "Sreeram Vennam",
        "Priyanshul Govil",
        "Ponnurangam Kumaraguru",
        "Manas Gaur"
      ],
      "abstract": "Despite recent advancements showcasing the impressive capabilities of Large\nLanguage Models (LLMs) in conversational systems, we show that even\nstate-of-the-art LLMs are morally inconsistent in their generations,\nquestioning their reliability (and trustworthiness in general). Prior works in\nLLM evaluation focus on developing ground-truth data to measure accuracy on\nspecific tasks. However, for moral scenarios that often lack universally\nagreed-upon answers, consistency in model responses becomes crucial for their\nreliability. To address this issue, we propose an information-theoretic measure\ncalled Semantic Graph Entropy (SaGE), grounded in the concept of \"Rules of\nThumb\" (RoTs) to measure a model's moral consistency. RoTs are abstract\nprinciples learned by a model and can help explain their decision-making\nstrategies effectively. To this extent, we construct the Moral Consistency\nCorpus (MCC), containing 50K moral questions, responses to them by LLMs, and\nthe RoTs that these models followed. Furthermore, to illustrate the\ngeneralizability of SaGE, we use it to investigate LLM consistency on two\npopular datasets -- TruthfulQA and HellaSwag. Our results reveal that\ntask-accuracy and consistency are independent problems, and there is a dire\nneed to investigate these issues further.",
      "tldr_zh": "本研究揭示了大型语言模型 (LLMs) 在生成道德相关响应时存在不一致性问题，这影响了其可靠性和可信度。作者提出了一种信息理论度量——Semantic Graph Entropy (SaGE)，基于“Rules of Thumb” (RoTs) 的概念，来评估模型的道德一致性，其中 RoTs 代表模型学到的抽象决策原则。为此，他们构建了 Moral Consistency Corpus (MCC)，包含 50K 条道德问题、LLMs 的响应及其遵循的 RoTs。实验结果显示，SaGE 在 TruthfulQA 和 HellaSwag 数据集上验证了任务准确性和一致性是独立问题，强调了进一步研究的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13709v2",
      "published_date": "2024-02-21 11:23:21 UTC",
      "updated_date": "2024-03-08 14:35:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:44:03.375438"
    },
    {
      "arxiv_id": "2402.14042v2",
      "title": "Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records",
      "title_zh": "翻译失败",
      "authors": [
        "Navid Ashrafi",
        "Vera Schmitt",
        "Robert P. Spang",
        "Sebastian Möller",
        "Jan-Niklas Voigt-Antons"
      ],
      "abstract": "Preservation of private user data is of paramount importance for high Quality\nof Experience (QoE) and acceptability, particularly with services treating\nsensitive data, such as IT-based health services. Whereas anonymization\ntechniques were shown to be prone to data re-identification, synthetic data\ngeneration has gradually replaced anonymization since it is relatively less\ntime and resource-consuming and more robust to data leakage. Generative\nAdversarial Networks (GANs) have been used for generating synthetic datasets,\nespecially GAN frameworks adhering to the differential privacy phenomena. This\nresearch compares state-of-the-art GAN-based models for synthetic data\ngeneration to generate time-series synthetic medical records of dementia\npatients which can be distributed without privacy concerns. Predictive\nmodeling, autocorrelation, and distribution analysis are used to assess the\nQuality of Generating (QoG) of the generated data. The privacy preservation of\nthe respective models is assessed by applying membership inference attacks to\ndetermine potential data leakage risks. Our experiments indicate the\nsuperiority of the privacy-preserving GAN (PPGAN) model over other models\nregarding privacy preservation while maintaining an acceptable level of QoG.\nThe presented results can support better data protection for medical use cases\nin the future.",
      "tldr_zh": "这篇论文探讨了使用 GANs 生成时间序列医疗记录的合成数据方法，以保护敏感医疗数据的隐私，避免数据再识别风险。研究比较了多种状态-of-the-art GAN 模型，包括符合 differential privacy 的框架，针对痴呆患者记录进行合成数据生成。评估通过预测建模、autocorrelation 和 distribution analysis 衡量生成数据的 Quality of Generating (QoG)，并利用 membership inference attacks 测试隐私泄露风险。实验结果表明，privacy-preserving GAN (PPGAN) 在隐私保护方面优于其他模型，同时保持了可接受的 QoG。该方法为未来医疗用例的数据保护提供了重要支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14042v2",
      "published_date": "2024-02-21 10:24:34 UTC",
      "updated_date": "2024-03-01 11:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:44:14.765172"
    },
    {
      "arxiv_id": "2402.14041v6",
      "title": "E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Zhichen Lai",
        "Huan Li",
        "Dalin Zhang",
        "Yan Zhao",
        "Weizhu Qian",
        "Christian S. Jensen"
      ],
      "abstract": "Cyber-physical system sensors emit multivariate time series (MTS) that\nmonitor physical system processes. Such time series generally capture unknown\nnumbers of states, each with a different duration, that correspond to specific\nconditions, e.g., \"walking\" or \"running\" in human-activity monitoring.\nUnsupervised identification of such states facilitates storage and processing\nin subsequent data analyses, as well as enhances result interpretability.\nExisting state-detection proposals face three challenges. First, they introduce\nsubstantial computational overhead, rendering them impractical in\nresourceconstrained or streaming settings. Second, although state-of-the-art\n(SOTA) proposals employ contrastive learning for representation, insufficient\nattention to false negatives hampers model convergence and accuracy. Third,\nSOTA proposals predominantly only emphasize offline non-streaming deployment,\nwe highlight an urgent need to optimize online streaming scenarios. We propose\nE2Usd that enables efficient-yet-accurate unsupervised MTS state detection.\nE2Usd exploits a Fast Fourier Transform-based Time Series Compressor\n(fftCompress) and a Decomposed Dual-view Embedding Module (ddEM) that together\nencode input MTSs at low computational overhead. Additionally, we propose a\nFalse Negative Cancellation Contrastive Learning method (fnccLearning) to\ncounteract the effects of false negatives and to achieve more cluster-friendly\nembedding spaces. To reduce computational overhead further in streaming\nsettings, we introduce Adaptive Threshold Detection (adaTD). Comprehensive\nexperiments with six baselines and six datasets offer evidence that E2Usd is\ncapable of SOTA accuracy at significantly reduced computational overhead.",
      "tldr_zh": "该论文提出 E2USD，一种高效且准确的无监督多变量时间序列 (MTS) 状态检测方法，旨在解决现有方法在计算开销大、对比学习中假负样本问题以及流式部署方面的挑战。E2USD 核心组件包括 Fast Fourier Transform-based Time Series Compressor (fftCompress) 和 Decomposed Dual-view Embedding Module (ddEM)，用于低开销编码输入序列，以及 False Negative Cancellation Contrastive Learning (fnccLearning) 来优化嵌入空间和 Adaptive Threshold Detection (adaTD) 以适应流式场景。实验结果显示，E2USD 与六种基线在六种数据集上实现了 state-of-the-art (SOTA) 准确率，同时显著降低了计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by The Web Conference 2024 (WWW 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.14041v6",
      "published_date": "2024-02-21 10:16:57 UTC",
      "updated_date": "2024-05-27 08:14:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:44:29.222986"
    },
    {
      "arxiv_id": "2402.13671v2",
      "title": "KInIT at SemEval-2024 Task 8: Fine-tuned LLMs for Multilingual Machine-Generated Text Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Michal Spiegel",
        "Dominik Macko"
      ],
      "abstract": "SemEval-2024 Task 8 is focused on multigenerator, multidomain, and\nmultilingual black-box machine-generated text detection. Such a detection is\nimportant for preventing a potential misuse of large language models (LLMs),\nthe newest of which are very capable in generating multilingual human-like\ntexts. We have coped with this task in multiple ways, utilizing language\nidentification and parameter-efficient fine-tuning of smaller LLMs for text\nclassification. We have further used the per-language classification-threshold\ncalibration to uniquely combine fine-tuned models predictions with statistical\ndetection metrics to improve generalization of the system detection\nperformance. Our submitted method achieved competitive results, ranking at the\nfourth place, just under 1 percentage point behind the winner.",
      "tldr_zh": "这篇论文参与了SemEval-2024 Task 8，专注于多生成器、多领域和多语言的黑箱机器生成文本检测，以防止LLMs滥用并识别其生成的类人文本。研究团队采用了语言识别技术以及对较小LLMs的参数高效微调来进行文本分类，并通过基于语言的分类阈值校准结合统计检测指标，提升了系统的泛化性能。最终，他们的方法在比赛中排名第四，仅落后获胜者不到1个百分点，展示了其竞争力的检测框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "SemEval-2024 Task 8",
      "pdf_url": "http://arxiv.org/pdf/2402.13671v2",
      "published_date": "2024-02-21 10:09:56 UTC",
      "updated_date": "2024-06-17 13:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:44:39.796897"
    },
    {
      "arxiv_id": "2402.13647v1",
      "title": "Unsupervised Text Style Transfer via LLMs and Attention Masking with Multi-way Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Pan",
        "Yunshi Lan",
        "Yang Li",
        "Weining Qian"
      ],
      "abstract": "Unsupervised Text Style Transfer (UTST) has emerged as a critical task within\nthe domain of Natural Language Processing (NLP), aiming to transfer one\nstylistic aspect of a sentence into another style without changing its\nsemantics, syntax, or other attributes. This task is especially challenging\ngiven the intrinsic lack of parallel text pairings. Among existing methods for\nUTST tasks, attention masking approach and Large Language Models (LLMs) are\ndeemed as two pioneering methods. However, they have shortcomings in generating\nunsmooth sentences and changing the original contents, respectively. In this\npaper, we investigate if we can combine these two methods effectively. We\npropose four ways of interactions, that are pipeline framework with tuned\norders; knowledge distillation from LLMs to attention masking model; in-context\nlearning with constructed parallel examples. We empirically show these\nmulti-way interactions can improve the baselines in certain perspective of\nstyle strength, content preservation and text fluency. Experiments also\ndemonstrate that simply conducting prompting followed by attention\nmasking-based revision can consistently surpass the other systems, including\nsupervised text style transfer systems. On Yelp-clean and Amazon-clean\ndatasets, it improves the previously best mean metric by 0.5 and 3.0 absolute\npercentages respectively, and achieves new SOTA results.",
      "tldr_zh": "本研究探讨了无监督文本风格转移（UTST），旨在通过结合大型语言模型（LLMs）和注意力掩码（attention masking）方法，将句子的风格方面转移，而不改变其语义或语法。论文提出四种多方式交互，包括管道框架调整顺序、从 LLMs 到注意力掩码模型的知识蒸馏（knowledge distillation）、以及基于构建平行示例的上下文学习（in-context learning），这些方法有效改善了风格强度、内容保留和文本流畅性。实验结果显示，简单采用提示后跟注意力掩码修订的策略，在 Yelp-clean 和 Amazon-clean 数据集上分别提升了最佳平均指标 0.5% 和 3.0%，并达到了新的 SOTA 结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13647v1",
      "published_date": "2024-02-21 09:28:02 UTC",
      "updated_date": "2024-02-21 09:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:44:51.246126"
    },
    {
      "arxiv_id": "2402.13635v1",
      "title": "The METRIC-framework for assessing data quality for trustworthy AI in medicine: a systematic review",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Schwabe",
        "Katinka Becker",
        "Martin Seyferth",
        "Andreas Klaß",
        "Tobias Schäffter"
      ],
      "abstract": "The adoption of machine learning (ML) and, more specifically, deep learning\n(DL) applications into all major areas of our lives is underway. The\ndevelopment of trustworthy AI is especially important in medicine due to the\nlarge implications for patients' lives. While trustworthiness concerns various\naspects including ethical, technical and privacy requirements, we focus on the\nimportance of data quality (training/test) in DL. Since data quality dictates\nthe behaviour of ML products, evaluating data quality will play a key part in\nthe regulatory approval of medical AI products. We perform a systematic review\nfollowing PRISMA guidelines using the databases PubMed and ACM Digital Library.\nWe identify 2362 studies, out of which 62 records fulfil our eligibility\ncriteria. From this literature, we synthesise the existing knowledge on data\nquality frameworks and combine it with the perspective of ML applications in\nmedicine. As a result, we propose the METRIC-framework, a specialised data\nquality framework for medical training data comprising 15 awareness dimensions,\nalong which developers of medical ML applications should investigate a dataset.\nThis knowledge helps to reduce biases as a major source of unfairness, increase\nrobustness, facilitate interpretability and thus lays the foundation for\ntrustworthy AI in medicine. Incorporating such systematic assessment of medical\ndatasets into regulatory approval processes has the potential to accelerate the\napproval of ML products and builds the basis for new standards.",
      "tldr_zh": "本研究通过系统性综述（遵循 PRISMA 指南）评估了数据质量在医疗 AI 中的作用，聚焦于 machine learning (ML) 和 deep learning (DL) 应用，以提升 trustworthy AI。研究者从 PubMed 和 ACM Digital Library 等数据库中筛选出 62 条相关记录，并提出 METRIC-framework，这是一个针对医疗训练数据的质量评估框架，涵盖 15 个 awareness dimensions。框架有助于减少偏差、提升模型鲁棒性和可解释性，从而为医疗 AI 的监管批准提供基础，并加速其采用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13635v1",
      "published_date": "2024-02-21 09:15:46 UTC",
      "updated_date": "2024-02-21 09:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:45:02.542314"
    },
    {
      "arxiv_id": "2402.16733v2",
      "title": "DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing",
      "title_zh": "翻译失败",
      "authors": [
        "Haneul Yoo",
        "Jieun Han",
        "So-Yeon Ahn",
        "Alice Oh"
      ],
      "abstract": "Automated essay scoring (AES) is a useful tool in English as a Foreign\nLanguage (EFL) writing education, offering real-time essay scores for students\nand instructors. However, previous AES models were trained on essays and scores\nirrelevant to the practical scenarios of EFL writing education and usually\nprovided a single holistic score due to the lack of appropriate datasets. In\nthis paper, we release DREsS, a large-scale, standard dataset for rubric-based\nautomated essay scoring. DREsS comprises three sub-datasets: DREsS_New,\nDREsS_Std., and DREsS_CASE. We collect DREsS_New, a real-classroom dataset with\n2.3K essays authored by EFL undergraduate students and scored by English\neducation experts. We also standardize existing rubric-based essay scoring\ndatasets as DREsS_Std. We suggest CASE, a corruption-based augmentation\nstrategy for essays, which generates 40.1K synthetic samples of DREsS_CASE and\nimproves the baseline results by 45.44%. DREsS will enable further research to\nprovide a more accurate and practical AES system for EFL writing education.",
      "tldr_zh": "这篇论文介绍了 DREsS，一个大规模标准数据集，用于基于 Rubric 的自动作文评分 (AES) 系统，针对英语作为外语 (EFL) 写作教育场景。DREsS 包含三个子数据集：DREsS_New (2.3K 篇由 EFL 本科生撰写的真实作文，由专家评分)、DREsS_Std. (标准化现有 Rubric-based 作文数据集)，以及 DREsS_CASE (通过 CASE 腐败增强策略生成的 40.1K 合成样本，提高基线结果 45.44%)。该数据集解决了现有 AES 模型数据不相关和仅提供单一整体分数的局限性，促进更准确、实用的 EFL 写作教育工具开发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16733v2",
      "published_date": "2024-02-21 09:12:16 UTC",
      "updated_date": "2024-11-04 06:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:45:16.107946"
    },
    {
      "arxiv_id": "2402.13615v1",
      "title": "Analyizing the Conjunction Fallacy as a Fact",
      "title_zh": "翻译失败",
      "authors": [
        "Tomas Veloz",
        "Olha Sobetska"
      ],
      "abstract": "Since the seminal paper by Tversky and Kahneman, the conjunction fallacy has\nbeen the subject of multiple debates and become a fundamental challenge for\ncognitive theories in decision-making. In this article, we take a rather\nuncommon perspective on this phenomenon. Instead of trying to explain the\nnature or causes of the conjunction fallacy (intensional definition), we\nanalyze its range of factual possibilities (extensional definition). We show\nthat the majority of research on the conjunction fallacy, according to our\nsample of experiments reviewed which covers literature between 1983 and 2016,\nhas focused on a narrow part of the a priori factual possibilities, implying\nthat explanations of the conjunction fallacy are fundamentally biased by the\nshort scope of possibilities explored. The latter is a rather curious aspect of\nthe research evolution in the conjunction fallacy considering that the very\nnature of it is motivated by extensional considerations.",
      "tldr_zh": "这篇论文从事实可能性（extensional definition）的角度审视结合谬误（conjunction fallacy），而非传统的本质或原因解释（intensional definition）。作者通过审查1983年至2016年间的实验样本，发现大多数研究仅关注了该谬误的狭窄部分。结果显示，这种研究偏差导致了对结合谬误的解释存在根本性偏见。最终，论文强调了这种现象的讽刺性，因为结合谬误的本质本身源于extensional considerations。",
      "categories": [
        "cs.AI",
        "math.PR",
        "nlin.AO"
      ],
      "primary_category": "cs.AI",
      "comment": "book chapter",
      "pdf_url": "http://arxiv.org/pdf/2402.13615v1",
      "published_date": "2024-02-21 08:40:04 UTC",
      "updated_date": "2024-02-21 08:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:45:26.128211"
    },
    {
      "arxiv_id": "2403.14641v1",
      "title": "Testing autonomous vehicles and AI: perspectives and challenges from cybersecurity, transparency, robustness and fairness",
      "title_zh": "翻译失败",
      "authors": [
        "David Fernández Llorca",
        "Ronan Hamon",
        "Henrik Junklewitz",
        "Kathrin Grosse",
        "Lars Kunze",
        "Patrick Seiniger",
        "Robert Swaim",
        "Nick Reed",
        "Alexandre Alahi",
        "Emilia Gómez",
        "Ignacio Sánchez",
        "Akos Kriston"
      ],
      "abstract": "This study explores the complexities of integrating Artificial Intelligence\n(AI) into Autonomous Vehicles (AVs), examining the challenges introduced by AI\ncomponents and the impact on testing procedures, focusing on some of the\nessential requirements for trustworthy AI. Topics addressed include the role of\nAI at various operational layers of AVs, the implications of the EU's AI Act on\nAVs, and the need for new testing methodologies for Advanced Driver Assistance\nSystems (ADAS) and Automated Driving Systems (ADS). The study also provides a\ndetailed analysis on the importance of cybersecurity audits, the need for\nexplainability in AI decision-making processes and protocols for assessing the\nrobustness and ethical behaviour of predictive systems in AVs. The paper\nidentifies significant challenges and suggests future directions for research\nand development of AI in AV technology, highlighting the need for\nmultidisciplinary expertise.",
      "tldr_zh": "本研究探讨了将人工智能 (AI) 整合到自动驾驶车辆 (Autonomous Vehicles, AVs) 中的复杂性，焦点在于测试程序面临的挑战，包括 cybersecurity、transparency、robustness 和 fairness 等关键要求。论文分析了 AI 在 AVs 不同操作层的作用、欧盟 AI Act 的影响，以及针对高级驾驶辅助系统 (Advanced Driver Assistance Systems, ADAS) 和自动驾驶系统 (Automated Driving Systems, ADS) 的新测试方法，同时强调了 cybersecurity audits、AI 决策的 explainability 以及评估 robustness 和 ethical behaviour 的必要性。最终，该研究识别出主要挑战，并提出未来研究方向，呼吁多学科 expertise 的参与以推动 AI 在 AV 技术中的可靠发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "44 pages, 8 figures, submitted to a peer-review journal",
      "pdf_url": "http://arxiv.org/pdf/2403.14641v1",
      "published_date": "2024-02-21 08:29:42 UTC",
      "updated_date": "2024-02-21 08:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:45:38.923424"
    },
    {
      "arxiv_id": "2402.13610v1",
      "title": "Data-driven Discovery with Large Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bodhisattwa Prasad Majumder",
        "Harshit Surana",
        "Dhruv Agarwal",
        "Sanchaita Hazra",
        "Ashish Sabharwal",
        "Peter Clark"
      ],
      "abstract": "With the accumulation of data at an unprecedented rate, its potential to fuel\nscientific discovery is growing exponentially. This position paper urges the\nMachine Learning (ML) community to exploit the capabilities of large generative\nmodels (LGMs) to develop automated systems for end-to-end data-driven discovery\n-- a paradigm encompassing the search and verification of hypotheses purely\nfrom a set of provided datasets, without the need for additional data\ncollection or physical experiments. We first outline several desiderata for an\nideal data-driven discovery system. Then, through DATAVOYAGER, a\nproof-of-concept utilizing GPT-4, we demonstrate how LGMs fulfill several of\nthese desiderata -- a feat previously unattainable -- while also highlighting\nimportant limitations in the current system that open up opportunities for\nnovel ML research. We contend that achieving accurate, reliable, and robust\nend-to-end discovery systems solely through the current capabilities of LGMs is\nchallenging. We instead advocate for fail-proof tool integration, along with\nactive user moderation through feedback mechanisms, to foster data-driven\nscientific discoveries with efficiency and reproducibility.",
      "tldr_zh": "这篇立场论文呼吁机器学习(ML)社区利用大型生成模型(LGMs)开发自动化系统，实现端到端的纯数据驱动发现，即从给定数据集搜索和验证假设，而无需额外数据或物理实验。作者首先概述了理想系统的需求，并通过DATAVOYAGER——一个基于GPT-4的概念验证——展示了LGMs如何满足部分需求，如自动化处理和假设生成，但也暴露了当前系统的局限性，包括准确性和可靠性不足。论文主张通过整合故障证明工具和用户反馈机制，来提升数据驱动发现的效率、可重复性和稳健性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13610v1",
      "published_date": "2024-02-21 08:26:43 UTC",
      "updated_date": "2024-02-21 08:26:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:45:50.941723"
    },
    {
      "arxiv_id": "2402.13602v4",
      "title": "Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Mehdi Azarafza",
        "Mojtaba Nayyeri",
        "Charles Steinmetz",
        "Steffen Staab",
        "Achim Rettberg"
      ],
      "abstract": "Large Language Models (LLMs) have garnered significant attention for their\nability to understand text and images, generate human-like text, and perform\ncomplex reasoning tasks. However, their ability to generalize this advanced\nreasoning with a combination of natural language text for decision-making in\ndynamic situations requires further exploration. In this study, we investigate\nhow well LLMs can adapt and apply a combination of arithmetic and common-sense\nreasoning, particularly in autonomous driving scenarios. We hypothesize that\nLLMs hybrid reasoning abilities can improve autonomous driving by enabling them\nto analyze detected object and sensor data, understand driving regulations and\nphysical laws, and offer additional context. This addresses complex scenarios,\nlike decisions in low visibility (due to weather conditions), where traditional\nmethods might fall short. We evaluated Large Language Models (LLMs) based on\naccuracy by comparing their answers with human-generated ground truth inside\nCARLA. The results showed that when a combination of images (detected objects)\nand sensor data is fed into the LLM, it can offer precise information for brake\nand throttle control in autonomous vehicles across various weather conditions.\nThis formulation and answers can assist in decision-making for auto-pilot\nsystems.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 的混合推理能力在自动驾驶中的应用，结合算术和常识推理来分析检测对象、传感器数据，并理解驾驶法规和物理定律，以应对动态复杂场景如低能见度天气。研究假设这种混合推理能提升自动驾驶系统的决策准确性，并通过CARLA模拟器进行评估，与人类基准答案比较。结果显示，当输入图像和传感器数据时，LLMs 能提供精确的制动和油门控制信息，在各种天气条件下显著改善自动驾驶性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13602v4",
      "published_date": "2024-02-21 08:09:05 UTC",
      "updated_date": "2024-08-19 13:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:46:04.011895"
    },
    {
      "arxiv_id": "2402.13598v2",
      "title": "User-LLM: Efficient LLM Contextualization with User Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Ning",
        "Luyang Liu",
        "Jiaxing Wu",
        "Neo Wu",
        "Devora Berlowitz",
        "Sushant Prakash",
        "Bradley Green",
        "Shawn O'Banion",
        "Jun Xie"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable success across various\ndomains, but effectively incorporating complex and potentially noisy user\ntimeline data into LLMs remains a challenge. Current approaches often involve\ntranslating user timelines into text descriptions before feeding them to LLMs,\nwhich can be inefficient and may not fully capture the nuances of user\nbehavior. Inspired by how LLMs are effectively integrated with images through\ndirect embeddings, we propose User-LLM, a novel framework that leverages user\nembeddings to directly contextualize LLMs with user history interactions. These\nembeddings, generated by a user encoder pretrained using self-supervised\nlearning on diverse user interactions, capture latent user behaviors and\ninterests as well as their evolution over time. We integrate these user\nembeddings with LLMs through cross-attention, enabling LLMs to dynamically\nadapt their responses based on the context of a user's past actions and\npreferences.\n  Our approach achieves significant efficiency gains by representing user\ntimelines directly as embeddings, leading to substantial inference speedups of\nup to 78.1X. Comprehensive experiments on MovieLens, Amazon Review, and Google\nLocal Review datasets demonstrate that User-LLM outperforms text-prompt-based\ncontextualization on tasks requiring deep user understanding, with improvements\nof up to 16.33%, particularly excelling on long sequences that capture subtle\nshifts in user behavior. Furthermore, the incorporation of Perceiver layers\nstreamlines the integration between user encoders and LLMs, yielding additional\ncomputational savings.",
      "tldr_zh": "该论文提出 User-LLM 框架，通过用户嵌入（user embeddings）直接上下文化大型语言模型（LLMs），以高效处理复杂且嘈杂的用户时间线数据，避免了传统文本描述方法的低效和细节丢失。框架利用自监督学习预训练的用户编码器生成嵌入，并通过交叉注意力（cross-attention）机制整合用户历史互动，让 LLMs 动态适应用户行为和偏好。实验结果显示，User-LLM 在 MovieLens、Amazon Review 和 Google Local Review 数据集上，比基于文本提示的方法提升高达 16.33%，并实现高达 78.1X 的推理加速，同时借助 Perceiver 层进一步优化计算资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13598v2",
      "published_date": "2024-02-21 08:03:27 UTC",
      "updated_date": "2024-09-09 19:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:46:16.372609"
    },
    {
      "arxiv_id": "2402.14866v2",
      "title": "APTQ: Attention-aware Post-Training Mixed-Precision Quantization for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Guan",
        "Hantao Huang",
        "Yupeng Su",
        "Hong Huang",
        "Ngai Wong",
        "Hao Yu"
      ],
      "abstract": "Large Language Models (LLMs) have greatly advanced the natural language\nprocessing paradigm. However, the high computational load and huge model sizes\npose a grand challenge for deployment on edge devices. To this end, we propose\nAPTQ (Attention-aware Post-Training Mixed-Precision Quantization) for LLMs,\nwhich considers not only the second-order information of each layer's weights,\nbut also, for the first time, the nonlinear effect of attention outputs on the\nentire model. We leverage the Hessian trace as a sensitivity metric for\nmixed-precision quantization, ensuring an informed precision reduction that\nretains model performance. Experiments show APTQ surpasses previous\nquantization methods, achieving an average of 4 bit width a 5.22 perplexity\nnearly equivalent to full precision in the C4 dataset. In addition, APTQ\nattains state-of-the-art zero-shot accuracy of 68.24\\% and 70.48\\% at an\naverage bitwidth of 3.8 in LLaMa-7B and LLaMa-13B, respectively, demonstrating\nits effectiveness to produce high-quality quantized LLMs.",
      "tldr_zh": "该论文提出 APTQ，一种关注注意力输出的后训练混合精度量化方法，用于优化 Large Language Models (LLMs)，以解决其高计算负载和模型尺寸问题。APTQ 不仅考虑了每个层权重的二阶信息（second-order information），还首次整合注意力输出（attention outputs）的非线性效应，并使用 Hessian trace 作为敏感度指标来指导精度降低。实验结果显示，APTQ 在 C4 数据集上实现了平均 4 位宽度的 5.22 perplexity，几乎等同于全精度；在 LLaMa-7B 和 LLaMa-13B 上，平均位宽 3.8 时，zero-shot accuracy 分别达到 68.24% 和 70.48%，超越了现有量化方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 2 figures, published to DAC 2024: 61st IEEE/ACM Design\n  Automation Conference. (DAC'24)",
      "pdf_url": "http://arxiv.org/pdf/2402.14866v2",
      "published_date": "2024-02-21 07:45:22 UTC",
      "updated_date": "2024-04-16 03:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:46:28.960587"
    },
    {
      "arxiv_id": "2402.13582v1",
      "title": "Mastering the Game of Guandan with Deep Reinforcement Learning and Behavior Regulating",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Yanggong",
        "Hao Pan",
        "Lei Wang"
      ],
      "abstract": "Games are a simplified model of reality and often serve as a favored platform\nfor Artificial Intelligence (AI) research. Much of the research is concerned\nwith game-playing agents and their decision making processes. The game of\nGuandan (literally, \"throwing eggs\") is a challenging game where even\nprofessional human players struggle to make the right decision at times. In\nthis paper we propose a framework named GuanZero for AI agents to master this\ngame using Monte-Carlo methods and deep neural networks. The main contribution\nof this paper is about regulating agents' behavior through a carefully designed\nneural network encoding scheme. We then demonstrate the effectiveness of the\nproposed framework by comparing it with state-of-the-art approaches.",
      "tldr_zh": "这篇论文提出GuanZero框架，利用Deep Reinforcement Learning和行为调节机制，帮助AI代理掌握Guandan游戏，该游戏是AI决策研究的挑战性平台。框架的核心贡献是通过精心设计的神经网络编码方案来调节代理的行为，确保更优决策。实验结果显示，GuanZero与现有方法相比表现出色，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13582v1",
      "published_date": "2024-02-21 07:26:06 UTC",
      "updated_date": "2024-02-21 07:26:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:46:39.605174"
    },
    {
      "arxiv_id": "2402.13575v3",
      "title": "Flexible Physical Camouflage Generation Based on a Differential Approach",
      "title_zh": "基于差分方法的灵活物理伪装生成",
      "authors": [
        "Yang Li",
        "Wenyi Tan",
        "Tingrui Wang",
        "Xinkai Liang",
        "Quan Pan"
      ],
      "abstract": "This study introduces a novel approach to neural rendering, specifically\ntailored for adversarial camouflage, within an extensive 3D rendering\nframework. Our method, named FPA, goes beyond traditional techniques by\nfaithfully simulating lighting conditions and material variations, ensuring a\nnuanced and realistic representation of textures on a 3D target. To achieve\nthis, we employ a generative approach that learns adversarial patterns from a\ndiffusion model. This involves incorporating a specially designed adversarial\nloss and covert constraint loss to guarantee the adversarial and covert nature\nof the camouflage in the physical world. Furthermore, we showcase the\neffectiveness of the proposed camouflage in sticker mode, demonstrating its\nability to cover the target without compromising adversarial information.\nThrough empirical and physical experiments, FPA exhibits strong performance in\nterms of attack success rate and transferability. Additionally, the designed\nsticker-mode camouflage, coupled with a concealment constraint, adapts to the\nenvironment, yielding diverse styles of texture. Our findings highlight the\nversatility and efficacy of the FPA approach in adversarial camouflage\napplications.",
      "tldr_zh": "本研究提出了一种名为 FPA 的新方法，用于基于神经渲染的对抗伪装生成，能够在广泛的 3D 渲染框架中真实模拟光照条件和材料变化，从而实现对 3D 目标纹理的细致表示。FPA 采用生成式方法从 diffusion model 学习对抗模式，并结合 specially designed adversarial loss 和 covert constraint loss，确保伪装在物理世界中具备对抗性和隐蔽性，同时在 sticker mode 下有效覆盖目标而不丢失关键信息。通过实证和物理实验，FPA 展示了出色的攻击成功率和 transferability，并能适应环境产生多样纹理风格，突显其在对抗伪装应用中的通用性和效能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13575v3",
      "published_date": "2024-02-21 07:15:16 UTC",
      "updated_date": "2024-12-12 04:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:46:51.826863"
    },
    {
      "arxiv_id": "2402.13573v3",
      "title": "ToDo: Token Downsampling for Efficient Generation of High-Resolution Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan Smith",
        "Nayan Saxena",
        "Aninda Saha"
      ],
      "abstract": "Attention mechanism has been crucial for image diffusion models, however,\ntheir quadratic computational complexity limits the sizes of images we can\nprocess within reasonable time and memory constraints. This paper investigates\nthe importance of dense attention in generative image models, which often\ncontain redundant features, making them suitable for sparser attention\nmechanisms. We propose a novel training-free method ToDo that relies on token\ndownsampling of key and value tokens to accelerate Stable Diffusion inference\nby up to 2x for common sizes and up to 4.5x or more for high resolutions like\n2048x2048. We demonstrate that our approach outperforms previous methods in\nbalancing efficient throughput and fidelity.",
      "tldr_zh": "本论文探讨了attention mechanism在图像扩散模型中的二次计算复杂度问题，该问题限制了处理高分辨率图像的速度和内存使用。论文提出了一种无需训练的创新方法ToDo，通过对key和value tokens进行token downsampling，显著加速Stable Diffusion的推理过程，实现常见尺寸下2倍加速和高分辨率（如2048x2048）下4.5倍或更高的性能提升。该方法在高效吞吐量和图像保真度之间取得了比现有技术更好的平衡，为生成高分辨率图像提供了更实用的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13573v3",
      "published_date": "2024-02-21 07:10:28 UTC",
      "updated_date": "2024-05-08 05:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:47:03.982843"
    },
    {
      "arxiv_id": "2402.15527v1",
      "title": "PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain",
      "title_zh": "PCA-Bench：在感知-认知-行动链中评估多模态大语言模型",
      "authors": [
        "Liang Chen",
        "Yichi Zhang",
        "Shuhuai Ren",
        "Haozhe Zhao",
        "Zefan Cai",
        "Yuchi Wang",
        "Peiyi Wang",
        "Xiangdi Meng",
        "Tianyu Liu",
        "Baobao Chang"
      ],
      "abstract": "We present PCA-Bench, a multimodal decision-making benchmark for evaluating\nthe integrated capabilities of Multimodal Large Language Models (MLLMs).\nDeparting from previous benchmarks focusing on simplistic tasks and individual\nmodel capability, PCA-Bench introduces three complex scenarios: autonomous\ndriving, domestic robotics, and open-world games. Given task instructions and\ndiverse contexts, the model is required to seamlessly integrate multiple\ncapabilities of Perception, Cognition, and Action in a reasoning chain to make\naccurate decisions. Moreover, PCA-Bench features error localization\ncapabilities, scrutinizing model inaccuracies in areas such as perception,\nknowledge, or reasoning. This enhances the reliability of deploying MLLMs. To\nbalance accuracy and efficiency in evaluation, we propose PCA-Eval, an\nautomatic evaluation protocol, and assess 10 prevalent MLLMs. The results\nreveal significant performance disparities between open-source models and\npowerful proprietary models like GPT-4 Vision. To address this, we introduce\nEmbodied-Instruction-Evolution (EIE), an automatic framework for synthesizing\ninstruction tuning examples in multimodal embodied environments. EIE generates\n7,510 training examples in PCA-Bench and enhances the performance of\nopen-source MLLMs, occasionally surpassing GPT-4 Vision (+3\\% in decision\naccuracy), thereby validating the effectiveness of EIE. Our findings suggest\nthat robust MLLMs like GPT4-Vision show promise for decision-making in embodied\nagents, opening new avenues for MLLM research.",
      "tldr_zh": "本论文引入了 PCA-Bench，一种用于评估多模态大语言模型 (MLLMs) 在感知-认知-行动链中的决策能力的基准测试，涵盖自动驾驶、家庭机器人和开放世界游戏等复杂场景。PCA-Bench 通过要求模型整合 Perception、Cognition 和 Action 的推理链来做出准确决策，并具备错误定位功能，以识别模型在感知、知识或推理方面的不足，从而提升部署可靠性。论文提出 PCA-Eval 作为自动评估协议，对 10 个流行 MLLMs 进行评估，结果显示开源模型显著落后于 GPT-4 Vision；为解决此问题，引入 Embodied-Instruction-Evolution (EIE) 框架，生成 7,510 个训练示例，提升开源模型性能，有时甚至超过 GPT-4 Vision (+3% 在决策准确率)。这些发现为 MLLMs 在具身代理决策中的应用开辟了新研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and Data released at https://github.com/pkunlp-icler/PCA-EVAL.\n  Leaderboard at: https://docs.qq.com/sheet/DVUd4WUpGRHRqUnNV. This article\n  supersedes its workshop version arxiv: 2310.02071. arXiv admin note: text\n  overlap with arXiv:2310.02071",
      "pdf_url": "http://arxiv.org/pdf/2402.15527v1",
      "published_date": "2024-02-21 07:09:58 UTC",
      "updated_date": "2024-02-21 07:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:47:17.668795"
    },
    {
      "arxiv_id": "2402.13572v2",
      "title": "AlgoFormer: An Efficient Transformer Framework with Algorithmic Structures",
      "title_zh": "AlgoFormer：高效的Transformer框架，具有算法结构",
      "authors": [
        "Yihang Gao",
        "Chuanyang Zheng",
        "Enze Xie",
        "Han Shi",
        "Tianyang Hu",
        "Yu Li",
        "Michael K. Ng",
        "Zhenguo Li",
        "Zhaoqiang Liu"
      ],
      "abstract": "Besides natural language processing, transformers exhibit extraordinary\nperformance in solving broader applications, including scientific computing and\ncomputer vision. Previous works try to explain this from the expressive power\nand capability perspectives that standard transformers are capable of\nperforming some algorithms. To empower transformers with algorithmic\ncapabilities and motivated by the recently proposed looped transformer, we\ndesign a novel transformer framework, dubbed Algorithm Transformer (abbreviated\nas AlgoFormer). We provide an insight that efficient transformer architectures\ncan be designed by leveraging prior knowledge of tasks and the underlying\nstructure of potential algorithms. Compared with the standard transformer and\nvanilla looped transformer, the proposed AlgoFormer can perform efficiently in\nalgorithm representation in some specific tasks. In particular, inspired by the\nstructure of human-designed learning algorithms, our transformer framework\nconsists of a pre-transformer that is responsible for task preprocessing, a\nlooped transformer for iterative optimization algorithms, and a\npost-transformer for producing the desired results after post-processing. We\nprovide theoretical evidence of the expressive power of the AlgoFormer in\nsolving some challenging problems, mirroring human-designed algorithms.\nFurthermore, some theoretical and empirical results are presented to show that\nthe designed transformer has the potential to perform algorithm representation\nand learning. Experimental results demonstrate the empirical superiority of the\nproposed transformer in that it outperforms the standard transformer and\nvanilla looped transformer in some specific tasks. An extensive experiment on\nreal language tasks (e.g., neural machine translation of German and English,\nand text classification) further validates the expressiveness and effectiveness\nof AlgoFormer.",
      "tldr_zh": "该研究提出了一种高效的 Transformer 框架 AlgoFormer，通过整合算法结构和任务先验知识，提升模型在科学计算、计算机视觉等领域的算法表示能力。AlgoFormer 由 pre-transformer（负责任务预处理）、looped transformer（执行迭代优化算法）和 post-transformer（进行后处理）三部分组成，旨在模仿人类设计的学习算法。实验结果显示，该框架在特定任务中优于标准 Transformer 和 vanilla looped transformer，并在真实语言任务（如德英神经机器翻译和文本分类）上验证了其表现力和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at Transactions on Machine Learning Research (TMLR). The\n  paper provides insight that the Transformer architectures can mimic the\n  algorithm structures in (in-context) algorithm learning and representation.\n  The incorporated algorithmic structure in Algoformer shows its potential in\n  (deep learning for) scientific computing, besides the real language tasks",
      "pdf_url": "http://arxiv.org/pdf/2402.13572v2",
      "published_date": "2024-02-21 07:07:54 UTC",
      "updated_date": "2025-01-10 09:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:47:27.725229"
    },
    {
      "arxiv_id": "2402.13571v2",
      "title": "Multilingual Coreference Resolution in Low-resource South Asian Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Ritwik Mishra",
        "Pooja Desur",
        "Rajiv Ratn Shah",
        "Ponnurangam Kumaraguru"
      ],
      "abstract": "Coreference resolution involves the task of identifying text spans within a\ndiscourse that pertain to the same real-world entity. While this task has been\nextensively explored in the English language, there has been a notable scarcity\nof publicly accessible resources and models for coreference resolution in South\nAsian languages. We introduce a Translated dataset for Multilingual Coreference\nResolution (TransMuCoRes) in 31 South Asian languages using off-the-shelf tools\nfor translation and word-alignment. Nearly all of the predicted translations\nsuccessfully pass a sanity check, and 75% of English references align with\ntheir predicted translations. Using multilingual encoders, two off-the-shelf\ncoreference resolution models were trained on a concatenation of TransMuCoRes\nand a Hindi coreference resolution dataset with manual annotations. The best\nperforming model achieved a score of 64 and 68 for LEA F1 and CoNLL F1,\nrespectively, on our test-split of Hindi golden set. This study is the first to\nevaluate an end-to-end coreference resolution model on a Hindi golden set.\nFurthermore, this work underscores the limitations of current coreference\nevaluation metrics when applied to datasets with split antecedents, advocating\nfor the development of more suitable evaluation metrics.",
      "tldr_zh": "本研究针对低资源南亚语言的核心ference resolution（识别文本中指向同一实体的跨度）问题，引入了TransMuCoRes数据集，该数据集通过现成翻译和词对齐工具为31种南亚语言创建，几乎所有翻译通过sanity check，且75%的英语引用成功对齐。研究者使用多语言编码器，在TransMuCoRes和一个手动标注的印地语数据集上训练两个核心ference resolution模型。实验结果显示，最佳模型在印地语黄金集测试集上达到LEA F1 64和CoNLL F1 68，这是首次在印地语黄金集上评估端到端模型；此外，该工作突出了当前评估指标在处理split antecedents数据集时的局限性，呼吁开发更合适的指标。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13571v2",
      "published_date": "2024-02-21 07:05:51 UTC",
      "updated_date": "2024-03-23 08:22:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:47:40.534808"
    },
    {
      "arxiv_id": "2402.13567v1",
      "title": "Spot Check Equivalence: an Interpretable Metric for Information Elicitation Mechanisms",
      "title_zh": "翻译失败",
      "authors": [
        "Shengwei Xu",
        "Yichi Zhang",
        "Paul Resnick",
        "Grant Schoenebeck"
      ],
      "abstract": "Because high-quality data is like oxygen for AI systems, effectively\neliciting information from crowdsourcing workers has become a first-order\nproblem for developing high-performance machine learning algorithms. Two\nprevalent paradigms, spot-checking and peer prediction, enable the design of\nmechanisms to evaluate and incentivize high-quality data from human labelers.\nSo far, at least three metrics have been proposed to compare the performances\nof these techniques [33, 8, 3]. However, different metrics lead to divergent\nand even contradictory results in various contexts. In this paper, we harmonize\nthese divergent stories, showing that two of these metrics are actually the\nsame within certain contexts and explain the divergence of the third. Moreover,\nwe unify these different contexts by introducing \\textit{Spot Check\nEquivalence}, which offers an interpretable metric for the effectiveness of a\npeer prediction mechanism. Finally, we present two approaches to compute spot\ncheck equivalence in various contexts, where simulation results verify the\neffectiveness of our proposed metric.",
      "tldr_zh": "这篇论文针对从众包工作者获取高质量数据的问题，比较了 spot-checking 和 peer prediction 这两种信息获取机制。作者分析了现有三种评估指标的差异，发现其中两个指标在特定语境下是相同的，并解释了第三个指标的矛盾。论文引入了 Spot Check Equivalence，这是一个可解释的指标，用于统一评估 peer prediction 机制的有效性。最后，作者提出了两种计算该指标的方法，并通过模拟结果验证了其可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the Web Conference 2024 (WWW '24)",
      "pdf_url": "http://arxiv.org/pdf/2402.13567v1",
      "published_date": "2024-02-21 06:57:07 UTC",
      "updated_date": "2024-02-21 06:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:47:52.608353"
    },
    {
      "arxiv_id": "2402.14865v2",
      "title": "Dynamic Evaluation of Large Language Models by Meta Probing Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Kaijie Zhu",
        "Jindong Wang",
        "Qinlin Zhao",
        "Ruochen Xu",
        "Xing Xie"
      ],
      "abstract": "Evaluation of large language models (LLMs) has raised great concerns in the\ncommunity due to the issue of data contamination. Existing work designed\nevaluation protocols using well-defined algorithms for specific tasks, which\ncannot be easily extended to diverse scenarios. Moreover, current evaluation\nbenchmarks can only provide the overall benchmark results and cannot support a\nfine-grained and multifaceted analysis of LLMs' abilities. In this paper, we\npropose meta probing agents (MPA), a general dynamic evaluation protocol\ninspired by psychometrics to evaluate LLMs. MPA is the key component of DyVal\n2, which naturally extends the previous DyVal~\\citep{zhu2023dyval}. MPA designs\nthe probing and judging agents to automatically transform an original\nevaluation problem into a new one following psychometric theory on three basic\ncognitive abilities: language understanding, problem solving, and domain\nknowledge. These basic abilities are also dynamically configurable, allowing\nmultifaceted analysis. We conducted extensive evaluations using MPA and found\nthat most LLMs achieve poorer performance, indicating room for improvement. Our\nmultifaceted analysis demonstrated the strong correlation between the basic\nabilities and an implicit Matthew effect on model size, i.e., larger models\npossess stronger correlations of the abilities. MPA can also be used as a data\naugmentation approach to enhance LLMs. Code is available at:\nhttps://github.com/microsoft/promptbench.",
      "tldr_zh": "本文提出 meta probing agents (MPA)，一种基于 psychometrics 的动态评估协议，作为 DyVal 2 的关键组件，用于评估 large language models (LLMs)，以解决数据污染问题和现有基准的局限性。MPA 通过 probing 和 judging agents 自动将原始评估问题转化为涉及 language understanding、problem solving 和 domain knowledge 的新问题，这些基本能力可动态配置，支持细粒度和多方面分析。实验结果显示，大多数 LLMs 表现较差，并揭示了这些能力间的强相关性以及模型大小的隐含 Matthew effect；此外，MPA 还能用作数据增强方法来提升 LLMs 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "International Conference on Machine Learning (ICML) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14865v2",
      "published_date": "2024-02-21 06:46:34 UTC",
      "updated_date": "2024-06-07 09:19:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:48:06.752100"
    },
    {
      "arxiv_id": "2402.14039v1",
      "title": "Specialty detection in the context of telemedicine in a highly imbalanced multi-class distribution",
      "title_zh": "在远程医疗语境下高度不平衡多类分布中的专科检测",
      "authors": [
        "Alaa Alomari",
        "Hossam Faris",
        "Pedro A. Castillo"
      ],
      "abstract": "The Covid-19 pandemic has led to an increase in the awareness of and demand\nfor telemedicine services, resulting in a need for automating the process and\nrelying on machine learning (ML) to reduce the operational load. This research\nproposes a specialty detection classifier based on a machine learning model to\nautomate the process of detecting the correct specialty for each question and\nrouting it to the correct doctor. The study focuses on handling multiclass and\nhighly imbalanced datasets for Arabic medical questions, comparing some\noversampling techniques, developing a Deep Neural Network (DNN) model for\nspecialty detection, and exploring the hidden business areas that rely on\nspecialty detection such as customizing and personalizing the consultation flow\nfor different specialties. The proposed module is deployed in both synchronous\nand asynchronous medical consultations to provide more real-time\nclassification, minimize the doctor effort in addressing the correct specialty,\nand give the system more flexibility in customizing the medical consultation\nflow. The evaluation and assessment are based on accuracy, precision, recall,\nand F1-score. The experimental results suggest that combining multiple\ntechniques, such as SMOTE and reweighing with keyword identification, is\nnecessary to achieve improved performance in detecting rare classes in\nimbalanced multiclass datasets. By using these techniques, specialty detection\nmodels can more accurately detect rare classes in real-world scenarios where\nimbalanced data is common.",
      "tldr_zh": "这篇论文针对COVID-19背景下telemedicine服务的专科检测问题，提出了一种基于machine learning的分类器，用于自动化处理高度不平衡的多类阿拉伯语医疗数据集。该方法比较了多种oversampling技术，如SMOTE，并开发了Deep Neural Network (DNN)模型，结合再加权和关键词识别来提升稀有类的检测性能。实验结果显示，这种组合策略显著提高了准确率、精确率、召回率和F1-score，并在同步和异步医疗咨询中实际部署，减少了医生工作量并优化了咨询流程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14039v1",
      "published_date": "2024-02-21 06:39:04 UTC",
      "updated_date": "2024-02-21 06:39:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:48:18.227195"
    },
    {
      "arxiv_id": "2402.13556v1",
      "title": "Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective",
      "title_zh": "归纳式图对齐提示：从谱视角桥接图预训练与归纳式微调之间的差距",
      "authors": [
        "Yuchen Yan",
        "Peiyan Zhang",
        "Zheng Fang",
        "Qingqing Long"
      ],
      "abstract": "The \"Graph pre-training and fine-tuning\" paradigm has significantly improved\nGraph Neural Networks(GNNs) by capturing general knowledge without manual\nannotations for downstream tasks. However, due to the immense gap of data and\ntasks between the pre-training and fine-tuning stages, the model performance is\nstill limited. Inspired by prompt fine-tuning in Natural Language\nProcessing(NLP), many endeavors have been made to bridge the gap in graph\ndomain. But existing methods simply reformulate the form of fine-tuning tasks\nto the pre-training ones. With the premise that the pre-training graphs are\ncompatible with the fine-tuning ones, these methods typically operate in\ntransductive setting. In order to generalize graph pre-training to inductive\nscenario where the fine-tuning graphs might significantly differ from\npre-training ones, we propose a novel graph prompt based method called\nInductive Graph Alignment Prompt(IGAP). Firstly, we unify the mainstream graph\npre-training frameworks and analyze the essence of graph pre-training from\ngraph spectral theory. Then we identify the two sources of the data gap in\ninductive setting: (i) graph signal gap and (ii) graph structure gap. Based on\nthe insight of graph pre-training, we propose to bridge the graph signal gap\nand the graph structure gap with learnable prompts in the spectral space. A\ntheoretical analysis ensures the effectiveness of our method. At last, we\nconduct extensive experiments among nodes classification and graph\nclassification tasks under the transductive, semi-inductive and inductive\nsettings. The results demonstrate that our proposed method can successfully\nbridge the data gap under different settings.",
      "tldr_zh": "这篇论文针对图神经网络(GNNs)预训练和微调之间的数据与任务差距问题，提出了一种新方法Inductive Graph Alignment Prompt(IGAP)，旨在将预训练扩展到归纳式(inductive)场景。IGAP从图谱理论(spectral perspective)统一主流预训练框架，识别出归纳设置中的图信号差距和图结构差距，并通过在谱空间添加可学习提示来桥接这些差距。实验结果表明，该方法在节点分类和图分类任务中，在传递式(transductive)、半归纳式和归纳式设置下均成功缩小了数据差距，提高了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "E.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13556v1",
      "published_date": "2024-02-21 06:25:54 UTC",
      "updated_date": "2024-02-21 06:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:48:29.824781"
    },
    {
      "arxiv_id": "2402.14037v1",
      "title": "An Effective Networks Intrusion Detection Approach Based on Hybrid Harris Hawks and Multi-Layer Perceptron",
      "title_zh": "翻译失败",
      "authors": [
        "Moutaz Alazab",
        "Ruba Abu Khurma",
        "Pedro A. Castillo",
        "Bilal Abu-Salih",
        "Alejandro Martin",
        "David Camacho"
      ],
      "abstract": "This paper proposes an Intrusion Detection System (IDS) employing the Harris\nHawks Optimization algorithm (HHO) to optimize Multilayer Perceptron learning\nby optimizing bias and weight parameters. HHO-MLP aims to select optimal\nparameters in its learning process to minimize intrusion detection errors in\nnetworks. HHO-MLP has been implemented using EvoloPy NN framework, an\nopen-source Python tool specialized for training MLPs using evolutionary\nalgorithms. For purposes of comparing the HHO model against other evolutionary\nmethodologies currently available, specificity and sensitivity measures,\naccuracy measures, and mse and rmse measures have been calculated using KDD\ndatasets. Experiments have demonstrated the HHO MLP method is effective at\nidentifying malicious patterns. HHO-MLP has been tested against evolutionary\nalgorithms like Butterfly Optimization Algorithm (BOA), Grasshopper\nOptimization Algorithms (GOA), and Black Widow Optimizations (BOW), with\nvalidation by Random Forest (RF), XG-Boost. HHO-MLP showed superior performance\nby attaining top scores with accuracy rate of 93.17%, sensitivity level of\n89.25%, and specificity percentage of 95.41%.",
      "tldr_zh": "这篇论文提出了一种有效的网络入侵检测系统（Intrusion Detection System, IDS），即 HHO-MLP，通过 Harris Hawks Optimization 算法 (HHO) 优化 Multilayer Perceptron (MLP) 的偏置和权重参数，以最小化检测错误。HHO-MLP 使用 EvoloPy NN 框架实现，并与 Butterfly Optimization Algorithm (BOA)、Grasshopper Optimization Algorithms (GOA) 和 Black Widow Optimizations (BWO) 等进化算法进行比较，同时验证了 Random Forest (RF) 和 XG-Boost 的性能。实验结果显示，在 KDD 数据集上，HHO-MLP 取得了 93.17% 的准确率、89.25% 的敏感性和 95.41% 的特异性，显著优于其他基准模型。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14037v1",
      "published_date": "2024-02-21 06:25:50 UTC",
      "updated_date": "2024-02-21 06:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:48:41.887281"
    },
    {
      "arxiv_id": "2402.13550v2",
      "title": "Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Deuksin Kwon",
        "Emily Weiss",
        "Tara Kulshrestha",
        "Kushal Chawla",
        "Gale M. Lucas",
        "Jonathan Gratch"
      ],
      "abstract": "A successful negotiation requires a range of capabilities, including\ncomprehension of the conversation context, Theory-of-Mind (ToM) skills to infer\nthe partner's motives, strategic reasoning, and effective communication, making\nit challenging for automated systems. Despite the remarkable performance of\nLLMs in various NLP tasks, there is no systematic evaluation of their\ncapabilities in negotiation. Such an evaluation is critical for advancing AI\nnegotiation agents and negotiation research, ranging from designing dialogue\nsystems to providing pedagogical feedback and scaling up data collection\npractices. This work aims to systematically analyze the multifaceted\ncapabilities of LLMs across diverse dialogue scenarios throughout the stages of\na typical negotiation interaction. Our analysis highlights GPT-4's superior\nperformance in many tasks while identifying specific challenges, such as making\nsubjective assessments and generating contextually appropriate, strategically\nadvantageous responses.",
      "tldr_zh": "该论文系统评估了大型语言模型（LLMs）在谈判对话中的多方面能力，包括理解上下文、Theory-of-Mind (ToM) 技能、战略推理和有效沟通，以填补现有研究的空白。通过分析 LLMs 在不同对话场景和谈判阶段的表现，研究发现 GPT-4 在许多任务中表现出色，但仍存在挑战，如进行主观评估和生成战略性、上下文合适的响应。该工作为推进 AI 谈判代理的设计、提供教学反馈以及扩展数据收集实践提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13550v2",
      "published_date": "2024-02-21 06:11:03 UTC",
      "updated_date": "2024-10-02 08:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:48:52.853044"
    },
    {
      "arxiv_id": "2402.13542v2",
      "title": "ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling",
      "title_zh": "ARL2：通过自引导的自适应相关性标记对黑盒大语言模型的检索器进行对齐",
      "authors": [
        "Lingxi Zhang",
        "Yue Yu",
        "Kuan Wang",
        "Chao Zhang"
      ],
      "abstract": "Retrieval-augmented generation enhances large language models (LLMs) by\nincorporating relevant information from external knowledge sources. This\nenables LLMs to adapt to specific domains and mitigate hallucinations in\nknowledge-intensive tasks. However, existing retrievers are often misaligned\nwith LLMs due to their separate training processes and the black-box nature of\nLLMs. To address this challenge, we propose ARL2, a retriever learning\ntechnique that harnesses LLMs as labelers. ARL2 leverages LLMs to annotate and\nscore relevant evidence, enabling learning the retriever from robust LLM\nsupervision. Furthermore, ARL2 uses an adaptive self-training strategy for\ncurating high-quality and diverse relevance data, which can effectively reduce\nthe annotation cost. Extensive experiments demonstrate the effectiveness of\nARL2, achieving accuracy improvements of 5.4% on NQ and 4.6% on MMLU compared\nto the state-of-the-art methods. Additionally, ARL2 exhibits robust transfer\nlearning capabilities and strong zero-shot generalization abilities. Our code\nwill be published at \\url{https://github.com/zhanglingxi-cs/ARL2}.",
      "tldr_zh": "本研究提出 ARL2 方法，通过自引导的自适应相关性标注（Self-guided Adaptive Relevance Labeling）来对齐检索器与黑盒 Large Language Models (LLMs)，以解决检索增强生成（Retrieval-augmented generation）中存在的 misalignment 问题。ARL2 利用 LLMs 作为标签器来注解和评分相关证据，并采用自适应自训练策略生成高质量、多样化的相关数据，从而有效降低注解成本。实验结果显示，ARL2 在 NQ 数据集上准确率提升 5.4%，在 MMLU 上提升 4.6%，并表现出强大的转移学习和零样本泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13542v2",
      "published_date": "2024-02-21 05:41:34 UTC",
      "updated_date": "2024-06-04 05:17:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:49:06.139729"
    },
    {
      "arxiv_id": "2402.13536v1",
      "title": "Exploring the Limits of Semantic Image Compression at Micro-bits per Pixel",
      "title_zh": "探索语义图像压缩在微比特每像素的极限",
      "authors": [
        "Jordan Dotzel",
        "Bahaa Kotb",
        "James Dotzel",
        "Mohamed Abdelfattah",
        "Zhiru Zhang"
      ],
      "abstract": "Traditional methods, such as JPEG, perform image compression by operating on\nstructural information, such as pixel values or frequency content. These\nmethods are effective to bitrates around one bit per pixel (bpp) and higher at\nstandard image sizes. In contrast, text-based semantic compression directly\nstores concepts and their relationships using natural language, which has\nevolved with humans to efficiently represent these salient concepts. These\nmethods can operate at extremely low bitrates by disregarding structural\ninformation like location, size, and orientation. In this work, we use GPT-4V\nand DALL-E3 from OpenAI to explore the quality-compression frontier for image\ncompression and identify the limitations of current technology. We push\nsemantic compression as low as 100 $\\mu$bpp (up to $10,000\\times$ smaller than\nJPEG) by introducing an iterative reflection process to improve the decoded\nimage. We further hypothesize this 100 $\\mu$bpp level represents a soft limit\non semantic compression at standard image resolutions.",
      "tldr_zh": "本论文探讨了语义图像压缩的极限，相比传统方法如 JPEG（依赖像素值或频率信息），语义压缩使用自然语言存储概念和关系，从而在极低比特率下忽略结构信息如位置、大小和方向。研究者利用 GPT-4V 和 DALL-E3 模型，通过引入迭代反射过程，将压缩率推低至 100 μbpp（比 JPEG 小 10,000 倍），显著提升了图像质量-压缩边界。实验结果表明，这一水平可能代表了标准图像分辨率下的软极限，为未来图像压缩技术提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICLR Tiny Papers 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13536v1",
      "published_date": "2024-02-21 05:14:30 UTC",
      "updated_date": "2024-02-21 05:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:49:17.589878"
    },
    {
      "arxiv_id": "2402.13534v1",
      "title": "An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling",
      "title_zh": "翻译失败",
      "authors": [
        "Xuemei Tang",
        "Qi Su"
      ],
      "abstract": "Sequence labeling models often benefit from incorporating external knowledge.\nHowever, this practice introduces data heterogeneity and complicates the model\nwith additional modules, leading to increased expenses for training a\nhigh-performing model. To address this challenge, we propose a two-stage\ncurriculum learning (TCL) framework specifically designed for sequence labeling\ntasks. The TCL framework enhances training by gradually introducing data\ninstances from easy to hard, aiming to improve both performance and training\nspeed. Furthermore, we explore different metrics for assessing the difficulty\nlevels of sequence labeling tasks. Through extensive experimentation on six\nChinese word segmentation (CWS) and Part-of-speech tagging (POS) datasets, we\ndemonstrate the effectiveness of our model in enhancing the performance of\nsequence labeling models. Additionally, our analysis indicates that TCL\naccelerates training and alleviates the slow training problem associated with\ncomplex models.",
      "tldr_zh": "本研究针对序列标注任务中整合外部知识导致的数据异质性和模型复杂化问题，提出了一种有效的两阶段课程学习（TCL）框架。该框架通过逐步从简单到困难引入数据实例，提高模型性能和训练效率，并探索了评估任务难度水平的多种指标。在六个中文分词（CWS）和词性标注（POS）数据集上的广泛实验中，TCL 框架显著提升了模型表现，并加速了训练过程，缓解了复杂模型的慢速训练问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 9 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13534v1",
      "published_date": "2024-02-21 05:04:29 UTC",
      "updated_date": "2024-02-21 05:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:49:28.194527"
    },
    {
      "arxiv_id": "2402.13533v1",
      "title": "FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao-Yang Liu",
        "Jie Zhang",
        "Guoxuan Wang",
        "Weiqing Tong",
        "Anwar Walid"
      ],
      "abstract": "Large language models (LLMs) are computationally intensive. The computation\nworkload and the memory footprint grow quadratically with the dimension (layer\nwidth). Most of LLMs' parameters come from the linear layers of the transformer\nstructure and are highly redundant. These linear layers contribute more than\n80% of the computation workload and 99% of the model size. To pretrain and\nfinetune LLMs efficiently, there are three major challenges to address: 1)\nreducing redundancy of the linear layers; 2) reducing GPU memory footprint; 3)\nimproving GPU utilization when using distributed training. Prior methods, such\nas LoRA and QLoRA, utilized low-rank matrices and quantization to reduce the\nnumber of trainable parameters and model size, respectively. However, the\nresulting model still consumes a large amount of GPU memory. In this paper, we\npresent high-performance GPU-based methods that exploit low-rank structures to\npretrain and finetune LLMs for financial applications. We replace one\nconventional linear layer of the transformer structure with two narrower linear\nlayers, which allows us to reduce the number of parameters by several orders of\nmagnitude. By quantizing the parameters into low precision (8-bit and 4-bit),\nthe memory consumption of the resulting model is further reduced. Compared with\nexisting LLMs, our methods achieve a speedup of 1.3X and a model compression\nratio of 2.64X for pretaining without accuracy drop. For finetuning, our\nmethods achieve an average accuracy increase of 6.3% and 24.0% in general tasks\nand financial tasks, respectively, and GPU memory consumption ratio of 6.3X.\nThe sizes of our models are smaller than 0.59 GB, allowing inference on a\nsmartphone.",
      "tldr_zh": "该论文提出FinGPT-HPC框架，利用高性能计算（HPC）优化大型语言模型（LLMs）的预训练和微调过程，针对金融应用中的计算密集问题。方法包括替换Transformer结构中的线性层为两个更窄的线性层，以减少参数冗余，并结合量化技术（如8-bit和4-bit）来进一步降低GPU内存占用。相比现有方法如LoRA和QLoRA，该框架在预训练时实现1.3倍加速和2.64倍模型压缩而不损失准确率；在微调时，泛化任务准确率提高6.3%，金融任务提高24.0%，并将GPU内存消耗减少6.3倍，使模型大小小于0.59 GB，可在智能手机上进行推理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13533v1",
      "published_date": "2024-02-21 05:03:17 UTC",
      "updated_date": "2024-02-21 05:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:49:41.332852"
    },
    {
      "arxiv_id": "2404.07215v1",
      "title": "Computation Offloading for Multi-server Multi-access Edge Vehicular Networks: A DDQN-based Method",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Wang",
        "Bo Yang",
        "Zhiwen Yu",
        "Xuelin Cao",
        "Yan Zhang",
        "Chau Yuen"
      ],
      "abstract": "In this paper, we investigate a multi-user offloading problem in the\noverlapping domain of a multi-server mobile edge computing system. We divide\nthe original problem into two stages: the offloading decision making stage and\nthe request scheduling stage. To prevent the terminal from going out of service\narea during offloading, we consider the mobility parameter of the terminal\naccording to the human behaviour model when making the offloading decision, and\nthen introduce a server evaluation mechanism based on both the mobility\nparameter and the server load to select the optimal offloading server. In order\nto fully utilise the server resources, we design a double deep Q-network\n(DDQN)-based reward evaluation algorithm that considers the priority of tasks\nwhen scheduling offload requests. Finally, numerical simulations are conducted\nto verify that our proposed method outperforms traditional mathematical\ncomputation methods as well as the DQN algorithm.",
      "tldr_zh": "本研究针对多服务器多接入边缘车辆网络中的多用户计算卸载问题，将其分为卸载决策阶段和请求调度阶段，以优化资源利用。卸载决策阶段考虑终端的移动性参数（基于人类行为模型）和服务器负载，引入服务器评估机制来选择最佳卸载服务器。请求调度阶段设计了基于双深度 Q 网络 (DDQN) 的奖励评估算法，优先考虑任务优先级。通过数值模拟验证，该方法优于传统数学计算方法和 DQN 算法，在性能上表现出显著优势。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07215v1",
      "published_date": "2024-02-21 04:41:46 UTC",
      "updated_date": "2024-02-21 04:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:49:53.155958"
    },
    {
      "arxiv_id": "2402.14035v3",
      "title": "Wisdom of Committee: Distilling from Foundation Model to Specialized Application Model",
      "title_zh": "委员会的智慧：从基础模型到专业应用模型的蒸馏",
      "authors": [
        "Zichang Liu",
        "Qingyun Liu",
        "Yuening Li",
        "Liang Liu",
        "Anshumali Shrivastava",
        "Shuchao Bi",
        "Lichan Hong",
        "Ed H. Chi",
        "Zhe Zhao"
      ],
      "abstract": "Recent advancements in foundation models have yielded impressive performance\nacross a wide range of tasks. Meanwhile, for specific applications,\npractitioners have been developing specialized application models. To enjoy the\nbenefits of both kinds of models, one natural path is to transfer the knowledge\nin foundation models into specialized application models, which are generally\nmore efficient for serving. Techniques from knowledge distillation may be\napplied here, where the application model learns to mimic the foundation model.\nHowever, specialized application models and foundation models have substantial\ngaps in capacity, employing distinct architectures, using different input\nfeatures from different modalities, and being optimized on different\ndistributions. These differences in model characteristics lead to significant\nchallenges for distillation methods. In this work, we propose creating a\nteaching committee comprising both foundation model teachers and complementary\nteachers. Complementary teachers possess model characteristics akin to the\nstudent's, aiming to bridge the gap between the foundation model and\nspecialized application models for a smoother knowledge transfer. Further, to\naccommodate the dissimilarity among the teachers in the committee, we introduce\nDiverseDistill, which allows the student to understand the expertise of each\nteacher and extract task knowledge. Our evaluations demonstrate that adding\ncomplementary teachers enhances student performance. Finally, DiverseDistill\nconsistently outperforms baseline distillation methods, regardless of the\nteacher choices, resulting in significantly improved student performance.",
      "tldr_zh": "该论文探讨了从 foundation models 向 specialized application models 转移知识的问题，旨在结合基础模型的强大性能与专用模型的高效性。作者提出创建 teaching committee，包括 foundation model teachers 和 complementary teachers，后者与学生模型特性类似，以桥接模型差异；同时引入 DiverseDistill 方法，让学生模型理解各老师的专长并提取任务知识。实验结果显示，添加 complementary teachers 提升了学生性能，而 DiverseDistill 比基线知识 distillation 方法更有效，显著提高了整体模型表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14035v3",
      "published_date": "2024-02-21 04:33:26 UTC",
      "updated_date": "2024-05-15 12:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:50:05.905974"
    },
    {
      "arxiv_id": "2402.14034v2",
      "title": "AgentScope: A Flexible yet Robust Multi-Agent Platform",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Gao",
        "Zitao Li",
        "Xuchen Pan",
        "Weirui Kuang",
        "Zhijian Ma",
        "Bingchen Qian",
        "Fei Wei",
        "Wenhao Zhang",
        "Yuexiang Xie",
        "Daoyuan Chen",
        "Liuyi Yao",
        "Hongyi Peng",
        "Zeyu Zhang",
        "Lin Zhu",
        "Chen Cheng",
        "Hongzhu Shi",
        "Yaliang Li",
        "Bolin Ding",
        "Jingren Zhou"
      ],
      "abstract": "With the rapid advancement of Large Language Models (LLMs), significant\nprogress has been made in multi-agent applications. However, the complexities\nin coordinating agents' cooperation and LLMs' erratic performance pose notable\nchallenges in developing robust and efficient multi-agent applications. To\ntackle these challenges, we propose AgentScope, a developer-centric multi-agent\nplatform with message exchange as its core communication mechanism. The\nabundant syntactic tools, built-in agents and service functions, user-friendly\ninterfaces for application demonstration and utility monitor, zero-code\nprogramming workstation, and automatic prompt tuning mechanism significantly\nlower the barriers to both development and deployment. Towards robust and\nflexible multi-agent application, AgentScope provides both built-in and\ncustomizable fault tolerance mechanisms. At the same time, it is also armed\nwith system-level support for managing and utilizing multi-modal data, tools,\nand external knowledge. Additionally, we design an actor-based distribution\nframework, enabling easy conversion between local and distributed deployments\nand automatic parallel optimization without extra effort. With these features,\nAgentScope empowers developers to build applications that fully realize the\npotential of intelligent agents. We have released AgentScope at\nhttps://github.com/modelscope/agentscope, and hope AgentScope invites wider\nparticipation and innovation in this fast-moving field.",
      "tldr_zh": "该研究提出AgentScope，一种以消息交换为核心通信机制的开发者友好型多智能体平台，旨在解决Large Language Models (LLMs)应用中代理协调和性能不稳定等问题。AgentScope提供丰富的语法工具、内置代理、服务函数、零代码编程工作站以及自动提示调整机制，大大降低开发和部署门槛，同时支持内置和自定义的容错机制、多模态数据管理以及基于actor的分布式框架，实现本地与分布式部署的无缝转换和自动并行优化。通过这些功能，AgentScope帮助开发者构建高效、鲁棒的多智能体应用，并已开源在GitHub上以促进进一步创新。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "We have released code on https://github.com/modelscope/agentscope",
      "pdf_url": "http://arxiv.org/pdf/2402.14034v2",
      "published_date": "2024-02-21 04:11:28 UTC",
      "updated_date": "2024-05-20 04:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:50:17.020695"
    },
    {
      "arxiv_id": "2402.13521v2",
      "title": "Test-Driven Development for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Noble Saji Mathews",
        "Meiyappan Nagappan"
      ],
      "abstract": "Recent Large Language Models (LLMs) have demonstrated significant\ncapabilities in generating code snippets directly from problem statements. This\nincreasingly automated process mirrors traditional human-led software\ndevelopment, where code is often written in response to a requirement.\nHistorically, Test-Driven Development (TDD) has proven its merit, requiring\ndevelopers to write tests before the functional code, ensuring alignment with\nthe initial problem statements. Applying TDD principles to LLM-based code\ngeneration offers one distinct benefit: it enables developers to verify the\ncorrectness of generated code against predefined tests. This paper investigates\nif and how TDD can be incorporated into AI-assisted code-generation processes.\nWe experimentally evaluate our hypothesis that providing LLMs like GPT-4 and\nLlama 3 with tests in addition to the problem statements enhances code\ngeneration outcomes. We experimented with established function-level code\ngeneration benchmarks such as MBPP and HumanEval. Our results consistently\ndemonstrate that including test cases leads to higher success in solving\nprogramming challenges. We assert that TDD is a promising paradigm for helping\nensure that the code generated by LLMs effectively captures the requirements.",
      "tldr_zh": "这篇论文探讨了将测试驱动开发 (TDD) 原则应用于大型语言模型 (LLMs) 的代码生成过程，以确保生成的代码符合问题语句要求。研究者通过实验评估了在提供测试用例的情况下，使用 GPT-4 和 Llama 3 等模型在 MBPP 和 HumanEval 等基准上的性能，结果显示添加测试用例显著提高了代码生成成功率。论文证明，TDD 可以帮助验证 LLM 生成代码的正确性，并为 AI 辅助软件开发提供一个可靠的范式。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13521v2",
      "published_date": "2024-02-21 04:10:12 UTC",
      "updated_date": "2024-06-11 15:53:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:50:31.513171"
    },
    {
      "arxiv_id": "2402.13517v2",
      "title": "Round Trip Translation Defence against Large Language Model Jailbreaking Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Canaan Yung",
        "Hadi Mohaghegh Dolatabadi",
        "Sarah Erfani",
        "Christopher Leckie"
      ],
      "abstract": "Large language models (LLMs) are susceptible to social-engineered attacks\nthat are human-interpretable but require a high level of comprehension for LLMs\nto counteract. Existing defensive measures can only mitigate less than half of\nthese attacks at most. To address this issue, we propose the Round Trip\nTranslation (RTT) method, the first algorithm specifically designed to defend\nagainst social-engineered attacks on LLMs. RTT paraphrases the adversarial\nprompt and generalizes the idea conveyed, making it easier for LLMs to detect\ninduced harmful behavior. This method is versatile, lightweight, and\ntransferrable to different LLMs. Our defense successfully mitigated over 70% of\nPrompt Automatic Iterative Refinement (PAIR) attacks, which is currently the\nmost effective defense to the best of our knowledge. We are also the first to\nattempt mitigating the MathsAttack and reduced its attack success rate by\nalmost 40%. Our code is publicly available at\nhttps://github.com/Cancanxxx/Round_Trip_Translation_Defence\n  This version of the article has been accepted for publication, after peer\nreview (when applicable) but is not the Version of Record and does not reflect\npost-acceptance improvements, or any corrections. The Version of Record is\navailable online at: https://doi.org/10.48550/arXiv.2402.13517 Use of this\nAccepted Version is subject to the publisher's Accepted Manuscript terms of use\nhttps://www.springernature.com/gp/open-research/policies/accepted-manuscript-terms",
      "tldr_zh": "本研究针对大型语言模型（Large Language Models, LLMs）易受社会工程攻击（如jailbreaking）的问题，提出了一种新型防御算法Round Trip Translation (RTT)。RTT通过改写和泛化攻击提示，使LLMs更容易检测并缓解有害行为，该方法轻量级且可转移到不同模型。实验结果显示，RTT成功缓解了超过70%的Prompt Automatic Iterative Refinement (PAIR)攻击，并首次降低了MathsAttack的成功率近40%，显著优于现有防御措施。代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13517v2",
      "published_date": "2024-02-21 03:59:52 UTC",
      "updated_date": "2025-04-30 05:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:50:41.725395"
    },
    {
      "arxiv_id": "2402.13516v7",
      "title": "ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models",
      "title_zh": "ProSparse：在大型语言模型中引入和增强内在激活稀疏性",
      "authors": [
        "Chenyang Song",
        "Xu Han",
        "Zhengyan Zhang",
        "Shengding Hu",
        "Xiyu Shi",
        "Kuai Li",
        "Chen Chen",
        "Zhiyuan Liu",
        "Guangli Li",
        "Tao Yang",
        "Maosong Sun"
      ],
      "abstract": "Activation sparsity refers to the existence of considerable\nweakly-contributed elements among activation outputs. As a prevalent property\nof the models using the ReLU activation function, activation sparsity has been\nproven a promising paradigm to boost model inference efficiency. Nevertheless,\nmost large language models (LLMs) adopt activation functions without intrinsic\nactivation sparsity (e.g., GELU and Swish). Some recent efforts have explored\nintroducing ReLU or its variants as the substitutive activation function to\nhelp LLMs achieve activation sparsity and inference acceleration, but few can\nsimultaneously obtain high sparsity and comparable model performance. This\npaper introduces a simple and effective sparsification method named \"ProSparse\"\nto push LLMs for higher activation sparsity while maintaining comparable\nperformance. Specifically, after substituting the activation function of LLMs\nwith ReLU, ProSparse adopts progressive sparsity regularization with a factor\nsmoothly increasing along the multi-stage sine curves. This can enhance\nactivation sparsity and mitigate performance degradation by avoiding radical\nshifts in activation distributions. With ProSparse, we obtain high sparsity of\n89.32% for LLaMA2-7B, 88.80% for LLaMA2-13B, and 87.89% for end-size\nMiniCPM-1B, respectively, achieving comparable performance to their original\nSwish-activated versions. These present the most sparsely activated models\namong open-source LLaMA versions and competitive end-size models, considerably\nsurpassing ReluLLaMA-7B (66.98%) and ReluLLaMA-13B (71.56%). Our inference\nacceleration experiments further demonstrate the significant practical\nacceleration potential of LLMs with higher activation sparsity, obtaining up to\n4.52$\\times$ inference speedup.",
      "tldr_zh": "该论文介绍了ProSparse，一种简单有效的稀疏化方法，用于在大语言模型（LLMs）中引入和增强激活稀疏性（activation sparsity），以提高模型推理效率。ProSparse首先将LLMs的激活函数替换为ReLU，然后采用渐进式稀疏正则化（progressive sparsity regularization），通过沿多阶段正弦曲线的平滑因子增加来提升稀疏性，同时减少性能损失。实验结果显示，ProSparse在LLaMA2-7B上实现89.32%的稀疏率，在LLaMA2-13B和MiniCPM-1B上分别达到88.80%和87.89%，性能与原GELU或Swish激活版本相当，并带来高达4.52倍的推理加速，显著优于现有方法如ReluLLaMA。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 4 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.13516v7",
      "published_date": "2024-02-21 03:58:49 UTC",
      "updated_date": "2025-01-07 05:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:50:54.351876"
    },
    {
      "arxiv_id": "2402.13514v2",
      "title": "Self-DC: When to Reason and When to Act? Self Divide-and-Conquer for Compositional Unknown Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Hongru Wang",
        "Boyang Xue",
        "Baohang Zhou",
        "Tianhua Zhang",
        "Cunxiang Wang",
        "Huimin Wang",
        "Guanhua Chen",
        "Kam-fai Wong"
      ],
      "abstract": "Previous research has typically concentrated on leveraging the internal\nknowledge of Large Language Models (LLMs) to answer known questions (i.e.,\n\\textit{internal reasoning such as generate-then-read}). In contrast, for\nquestions that fall outside their known scope, these models rely on external\nknowledge retrieval to provide accurate responses (i.e., \\textit{external\nacting such as retrieve-then-read}). However, few previous works consider the\n\\textit{compositional questions}, which consist of several known and unknown\nsub-questions, necessitating the dynamic combination of previous two methods\n(i.e., \\textit{internal reasoning and external acting}) to achieve a better\ntrade-off between effectiveness and efficiency. To this end, we introduce a\n\\textbf{Self} \\textbf{D}ivide-and-\\textbf{C}onquer (\\textit{\\texttt{Self-DC}})\nframework, accompanying with the first \\textbf{C}ompositional \\textbf{u}nknown\n\\textbf{Q}uestion-\\textbf{A}nswering dataset (CuQA). This framework enables\nLLMs to adaptively choose between using internal knowledge and retrieving\nexternal knowledge as needed, resulting in a better trade-off between\neffectiveness and efficiency. Experimental results on two datasets demonstrate\nthat \\textit{\\texttt{Self-DC}} can achieve comparable or even better\nperformance with much fewer external calls compared with several strong\nbaselines.",
      "tldr_zh": "本研究针对组合未知问题（compositional unknown questions），提出Self-DC框架，该框架允许Large Language Models (LLMs)自适应地选择内部推理（internal reasoning，如generate-then-read）和外部行动（external acting，如retrieve-then-read），以实现效果和效率的更好权衡。研究同时引入了首个Compositional unknown Question-Answering数据集（CuQA），用于评估此类问题。实验结果显示，Self-DC在两个数据集上取得了与强基线相当或更高的性能，同时显著减少了外部调用（fewer external calls）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13514v2",
      "published_date": "2024-02-21 03:55:02 UTC",
      "updated_date": "2025-01-25 22:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:51:04.299060"
    },
    {
      "arxiv_id": "2402.13512v1",
      "title": "From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "M. Emrullah Ildiz",
        "Yixiao Huang",
        "Yingcong Li",
        "Ankit Singh Rawat",
        "Samet Oymak"
      ],
      "abstract": "Modern language models rely on the transformer architecture and attention\nmechanism to perform language understanding and text generation. In this work,\nwe study learning a 1-layer self-attention model from a set of prompts and\nassociated output data sampled from the model. We first establish a precise\nmapping between the self-attention mechanism and Markov models: Inputting a\nprompt to the model samples the output token according to a context-conditioned\nMarkov chain (CCMC) which weights the transition matrix of a base Markov chain.\nAdditionally, incorporating positional encoding results in position-dependent\nscaling of the transition probabilities. Building on this formalism, we develop\nidentifiability/coverage conditions for the prompt distribution that guarantee\nconsistent estimation and establish sample complexity guarantees under IID\nsamples. Finally, we study the problem of learning from a single output\ntrajectory generated from an initial prompt. We characterize an intriguing\nwinner-takes-all phenomenon where the generative process implemented by\nself-attention collapses into sampling a limited subset of tokens due to its\nnon-mixing nature. This provides a mathematical explanation to the tendency of\nmodern LLMs to generate repetitive text. In summary, the equivalence to CCMC\nprovides a simple but powerful framework to study self-attention and its\nproperties.",
      "tldr_zh": "该论文建立了自注意力机制与马尔可夫模型的精确映射，揭示了生成Transformer模型的动态，特别将自注意力描述为上下文条件马尔可夫链(CCMC)，并考虑了位置编码对转移概率的影响。研究发展了提示分布的可识别性和覆盖条件，确保了从一组提示和输出数据中学习1层自注意力模型的样本复杂性保证。同时，通过分析单个输出轨迹，论文揭示了“赢家通吃”现象，导致模型生成重复文本，从而为解释现代大型语言模型(LLMs)的这一倾向提供了数学依据。总之，这种等价框架为深入研究自注意力机制的属性提供了简单而强大的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.13512v1",
      "published_date": "2024-02-21 03:51:34 UTC",
      "updated_date": "2024-02-21 03:51:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:51:18.570904"
    },
    {
      "arxiv_id": "2402.14033v1",
      "title": "VN Network: Embedding Newly Emerging Entities with Virtual Neighbors",
      "title_zh": "翻译失败",
      "authors": [
        "Yongquan He",
        "Zihan Wang",
        "Peng Zhang",
        "Zhaopeng Tu",
        "Zhaochun Ren"
      ],
      "abstract": "Embedding entities and relations into continuous vector spaces has attracted\na surge of interest in recent years. Most embedding methods assume that all\ntest entities are available during training, which makes it time-consuming to\nretrain embeddings for newly emerging entities. To address this issue, recent\nworks apply the graph neural network on the existing neighbors of the unseen\nentities. In this paper, we propose a novel framework, namely Virtual Neighbor\n(VN) network, to address three key challenges. Firstly, to reduce the neighbor\nsparsity problem, we introduce the concept of the virtual neighbors inferred by\nrules. And we assign soft labels to these neighbors by solving a\nrule-constrained problem, rather than simply regarding them as unquestionably\ntrue. Secondly, many existing methods only use one-hop or two-hop neighbors for\naggregation and ignore the distant information that may be helpful. Instead, we\nidentify both logic and symmetric path rules to capture complex patterns.\nFinally, instead of one-time injection of rules, we employ an iterative\nlearning scheme between the embedding method and virtual neighbor prediction to\ncapture the interactions within. Experimental results on two knowledge graph\ncompletion tasks demonstrate that our VN network significantly outperforms\nstate-of-the-art baselines. Furthermore, results on Subject/Object-R show that\nour proposed VN network is highly robust to the neighbor sparsity problem.",
      "tldr_zh": "本文提出 VN Network 框架，用于嵌入新出现的实体（Newly Emerging Entities），以解决传统实体嵌入方法需重新训练的问题。该框架通过引入虚拟邻居（Virtual Neighbors）来缓解邻居稀疏问题，并使用规则推断分配软标签，同时识别逻辑和对称路径规则（logic and symmetric path rules）捕获复杂模式。不同于现有方法，VN Network 采用迭代学习方案，在嵌入方法和虚拟邻居预测之间交互优化。实验结果显示，在两个知识图谱完成（Knowledge Graph Completion）任务上，该框架显著优于最先进基线，并在 Subject/Object-R 测试中表现出对邻居稀疏问题的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.4; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14033v1",
      "published_date": "2024-02-21 03:04:34 UTC",
      "updated_date": "2024-02-21 03:04:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:51:29.784036"
    },
    {
      "arxiv_id": "2402.13482v1",
      "title": "Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Minju Seo",
        "Jinheon Baek",
        "James Thorne",
        "Sung Ju Hwang"
      ],
      "abstract": "Despite large successes of recent language models on diverse tasks, they\nsuffer from severe performance degeneration in low-resource settings with\nlimited training data available. Many existing works tackle this problem by\ngenerating synthetic data from the training data and then training models on\nthem, recently using Large Language Models (LLMs). However, in low-resource\nsettings, the amount of seed data samples to use for data augmentation is very\nsmall, which makes generated samples suboptimal and less diverse. To tackle\nthis challenge, we propose a novel method that augments training data by\nincorporating a wealth of examples from other datasets, along with the given\ntraining data. Specifically, we first retrieve the relevant instances from\nother datasets, such as their input-output pairs or contexts, based on their\nsimilarities with the given seed data, and then prompt LLMs to generate new\nsamples with the contextual information within and across the original and\nretrieved samples. This approach can ensure that the generated data is not only\nrelevant but also more diverse than what could be achieved using the limited\nseed data alone. We validate our proposed Retrieval-Augmented Data Augmentation\n(RADA) framework on multiple datasets under low-resource settings of training\nand test-time data augmentation scenarios, on which it outperforms existing\nLLM-powered data augmentation baselines.",
      "tldr_zh": "针对低资源领域任务，论文提出了一种名为 Retrieval-Augmented Data Augmentation (RADA) 的新框架，以解决现有 Large Language Models (LLMs) 在数据增强时因种子数据有限而导致生成样本不优和不多样的问题。RADA 通过从其他数据集检索与种子数据相似的相关实例（如输入-输出对或上下文），然后利用这些实例提示 LLMs 生成更相关且多样的合成样本，从而增强训练数据。实验在多个低资源设置下的数据集上验证了 RADA，在训练和测试时数据增强场景中，RADA 超过了现有 LLM 增强基线，提升了模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13482v1",
      "published_date": "2024-02-21 02:45:46 UTC",
      "updated_date": "2024-02-21 02:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:51:41.817948"
    },
    {
      "arxiv_id": "2402.13481v1",
      "title": "Learning to Model Diverse Driving Behaviors in Highly Interactive Autonomous Driving Scenarios with Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Weiwei",
        "Hu Wenxuan",
        "Jing Wei",
        "Lei Lanxin",
        "Gao Lingping",
        "Liu Yong"
      ],
      "abstract": "Autonomous vehicles trained through Multi-Agent Reinforcement Learning (MARL)\nhave shown impressive results in many driving scenarios. However, the\nperformance of these trained policies can be impacted when faced with diverse\ndriving styles and personalities, particularly in highly interactive\nsituations. This is because conventional MARL algorithms usually operate under\nthe assumption of fully cooperative behavior among all agents and focus on\nmaximizing team rewards during training. To address this issue, we introduce\nthe Personality Modeling Network (PeMN), which includes a cooperation value\nfunction and personality parameters to model the varied interactions in\nhigh-interactive scenarios. The PeMN also enables the training of a background\ntraffic flow with diverse behaviors, thereby improving the performance and\ngeneralization of the ego vehicle. Our extensive experimental studies, which\nincorporate different personality parameters in high-interactive driving\nscenarios, demonstrate that the personality parameters effectively model\ndiverse driving styles and that policies trained with PeMN demonstrate better\ngeneralization compared to traditional MARL methods.",
      "tldr_zh": "本研究针对多智能体强化学习(MARL)训练的自治车辆在高度互动驾驶场景中面对多样驾驶风格时性能受限的问题，提出了一种Personality Modeling Network (PeMN)。PeMN 通过引入合作价值函数和个性参数来模拟各种互动行为，并训练背景交通流以多样化行为，从而提升ego vehicle的性能和泛化能力。实验结果表明，与传统MARL方法相比，使用PeMN训练的政策在不同个性参数设置下更有效地建模驾驶风格，并表现出更好的泛化效果。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13481v1",
      "published_date": "2024-02-21 02:44:33 UTC",
      "updated_date": "2024-02-21 02:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:51:54.670901"
    },
    {
      "arxiv_id": "2402.13475v1",
      "title": "Multi-scale Spatio-temporal Transformer-based Imbalanced Longitudinal Learning for Glaucoma Forecasting from Irregular Time Series Images",
      "title_zh": "翻译失败",
      "authors": [
        "Xikai Yang",
        "Jian Wu",
        "Xi Wang",
        "Yuchen Yuan",
        "Ning Li Wang",
        "Pheng-Ann Heng"
      ],
      "abstract": "Glaucoma is one of the major eye diseases that leads to progressive optic\nnerve fiber damage and irreversible blindness, afflicting millions of\nindividuals. Glaucoma forecast is a good solution to early screening and\nintervention of potential patients, which is helpful to prevent further\ndeterioration of the disease. It leverages a series of historical fundus images\nof an eye and forecasts the likelihood of glaucoma occurrence in the future.\nHowever, the irregular sampling nature and the imbalanced class distribution\nare two challenges in the development of disease forecasting approaches. To\nthis end, we introduce the Multi-scale Spatio-temporal Transformer Network\n(MST-former) based on the transformer architecture tailored for sequential\nimage inputs, which can effectively learn representative semantic information\nfrom sequential images on both temporal and spatial dimensions. Specifically,\nwe employ a multi-scale structure to extract features at various resolutions,\nwhich can largely exploit rich spatial information encoded in each image.\nBesides, we design a time distance matrix to scale time attention in a\nnon-linear manner, which could effectively deal with the irregularly sampled\ndata. Furthermore, we introduce a temperature-controlled Balanced Softmax\nCross-entropy loss to address the class imbalance issue. Extensive experiments\non the Sequential fundus Images for Glaucoma Forecast (SIGF) dataset\ndemonstrate the superiority of the proposed MST-former method, achieving an AUC\nof 98.6% for glaucoma forecasting. Besides, our method shows excellent\ngeneralization capability on the Alzheimer's Disease Neuroimaging Initiative\n(ADNI) MRI dataset, with an accuracy of 90.3% for mild cognitive impairment and\nAlzheimer's disease prediction, outperforming the compared method by a large\nmargin.",
      "tldr_zh": "该研究针对青光眼预测面临的挑战，包括不规则采样和类别不平衡问题，提出了一种基于Transformer架构的Multi-scale Spatio-temporal Transformer Network (MST-former)，用于从时间序列图像中学习空间和时间维度特征。具体而言，该方法采用多尺度结构提取不同分辨率的图像特征、设计时间距离矩阵处理不规则数据，以及引入温度控制的Balanced Softmax Cross-entropy loss来缓解类别不平衡。在Sequential fundus Images for Glaucoma Forecast (SIGF)数据集上，MST-former实现了98.6%的AUC，显著优于基线模型，并在Alzheimer's Disease Neuroimaging Initiative (ADNI) MRI数据集上表现出色，准确率达90.3%。这为早期青光眼筛查和类似疾病预测提供了高效的框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.13475v1",
      "published_date": "2024-02-21 02:16:59 UTC",
      "updated_date": "2024-02-21 02:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:52:06.403278"
    },
    {
      "arxiv_id": "2402.13463v4",
      "title": "RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jianhao Yan",
        "Yun Luo",
        "Yue Zhang"
      ],
      "abstract": "The application scope of large language models (LLMs) is increasingly\nexpanding. In practical use, users might provide feedback based on the model's\noutput, hoping for a responsive model that can complete responses according to\ntheir feedback. Whether the model can appropriately respond to users' refuting\nfeedback and consistently follow through with execution has not been thoroughly\nanalyzed. In light of this, this paper proposes a comprehensive benchmark,\nRefuteBench, covering tasks such as question answering, machine translation,\nand email writing. The evaluation aims to assess whether models can positively\naccept feedback in form of refuting instructions and whether they can\nconsistently adhere to user demands throughout the conversation. We conduct\nevaluations on numerous LLMs and find that LLMs are stubborn, i.e. exhibit\ninclination to their internal knowledge, often failing to comply with user\nfeedback. Additionally, as the length of the conversation increases, models\ngradually forget the user's stated feedback and roll back to their own\nresponses. We further propose a recall-and-repeat prompts as a simple and\neffective way to enhance the model's responsiveness to feedback.",
      "tldr_zh": "这篇论文引入了 RefuteBench，一个全面基准，用于评估大型语言模型 (LLMs) 在处理反驳指令时的表现，涵盖问答、机器翻译和电子邮件写作等任务。评估发现，LLMs 往往固执于内部知识，难以积极接受用户反馈，并在长对话中逐渐忘记反馈，导致响应不一致。作者提出 recall-and-repeat prompts 作为一种简单有效的提示方法，以提升模型对用户需求的持续遵守。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 final version",
      "pdf_url": "http://arxiv.org/pdf/2402.13463v4",
      "published_date": "2024-02-21 01:39:56 UTC",
      "updated_date": "2024-07-24 06:50:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:52:17.509765"
    },
    {
      "arxiv_id": "2402.13462v1",
      "title": "Potential and Challenges of Model Editing for Social Debiasing",
      "title_zh": "模型编辑在社会去偏见中的潜力与挑战",
      "authors": [
        "Jianhao Yan",
        "Futing Wang",
        "Yafu Li",
        "Yue Zhang"
      ],
      "abstract": "Large language models (LLMs) trained on vast corpora suffer from inevitable\nstereotype biases. Mitigating these biases with fine-tuning could be both\ncostly and data-hungry. Model editing methods, which focus on modifying LLMs in\na post-hoc manner, are of great potential to address debiasing. However, it\nlacks a comprehensive study that facilitates both internal and external model\nediting methods, supports various bias types, as well as understands the pros\nand cons of applying editing methods to stereotypical debiasing. To mitigate\nthis gap, we carefully formulate social debiasing into an editing problem and\nbenchmark seven existing model editing algorithms on stereotypical debiasing,\ni.e., debias editing. Our findings in three scenarios reveal both the potential\nand challenges of debias editing: (1) Existing model editing methods can\neffectively preserve knowledge and mitigate biases, while the generalization of\ndebias effect from edited sentences to semantically equivalent sentences is\nlimited.(2) Sequential editing highlights the robustness of SERAC (Mitchell et\nal. 2022b), while internal editing methods degenerate with the number of edits.\n(3) Model editing algorithms achieve generalization towards unseen biases both\nwithin the same type and from different types. In light of these findings, we\nfurther propose two simple but effective methods to improve debias editing, and\nexperimentally show the effectiveness of the proposed methods.",
      "tldr_zh": "这篇论文探讨了使用模型编辑方法来缓解大型语言模型（LLMs）中的社会刻板偏见问题，这些偏见源于训练数据，而传统微调方法成本高且数据需求大。研究者将社会去偏见转化为模型编辑问题，并基准测试了七种现有算法，结果显示这些方法能有效保留模型知识并减少偏见，但去偏效果在语义等价句子上的泛化有限。论文进一步发现，SERAC算法在顺序编辑中表现出色，而内部编辑方法在多次编辑后性能下降；同时，模型编辑能泛化到未见偏见，包括同一类型和不同类型。最后，作者提出了两个简单有效的改进方法，并通过实验验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2402.13462v1",
      "published_date": "2024-02-21 01:35:26 UTC",
      "updated_date": "2024-02-21 01:35:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:52:31.092605"
    },
    {
      "arxiv_id": "2402.14861v1",
      "title": "CloudNine: Analyzing Meteorological Observation Impact on Weather Prediction Using Explainable Graph Neural Networks",
      "title_zh": "CloudNine：使用可解释图神经网络分析气象观测对天气预测的影响",
      "authors": [
        "Hyeon-Ju Jeon",
        "Jeon-Ho Kang",
        "In-Hyuk Kwon",
        "O-Joun Lee"
      ],
      "abstract": "The impact of meteorological observations on weather forecasting varies with\nsensor type, location, time, and other environmental factors. Thus,\nquantitative analysis of observation impacts is crucial for effective and\nefficient development of weather forecasting systems. However, the existing\nimpact analysis methods are difficult to be widely applied due to their high\ndependencies on specific forecasting systems. Also, they cannot provide\nobservation impacts at multiple spatio-temporal scales, only global impacts of\nobservation types. To address these issues, we present a novel system called\n``CloudNine,'' which allows analysis of individual observations' impacts on\nspecific predictions based on explainable graph neural networks (XGNNs).\nCombining an XGNN-based atmospheric state estimation model with a numerical\nweather prediction model, we provide a web application to search for\nobservations in the 3D space of the Earth system and to visualize the impact of\nindividual observations on predictions in specific spatial regions and time\nperiods.",
      "tldr_zh": "本文提出 CloudNine 系统，利用 Explainable Graph Neural Networks (XGNNs) 来分析气象观测对天气预报的影响，解决了现有方法依赖特定预报系统且仅提供全局影响的局限性。该系统结合 XGNNs 基于的大气状态估计模型和 Numerical Weather Prediction 模型，能评估单个观测在多时空尺度上的具体影响。CloudNine 通过一个网络应用允许用户在地球系统的 3D 空间搜索观测，并可视化其对特定空间区域和时间段的预报影响，从而提升天气预报系统的开发效率和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14861v1",
      "published_date": "2024-02-21 01:29:17 UTC",
      "updated_date": "2024-02-21 01:29:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:52:42.014053"
    },
    {
      "arxiv_id": "2402.13457v2",
      "title": "A Comprehensive Study of Jailbreak Attack versus Defense for Large Language Models",
      "title_zh": "针对大型语言模型的越狱攻击与防御全面研究",
      "authors": [
        "Zihao Xu",
        "Yi Liu",
        "Gelei Deng",
        "Yuekang Li",
        "Stjepan Picek"
      ],
      "abstract": "Large Language Models (LLMS) have increasingly become central to generating\ncontent with potential societal impacts. Notably, these models have\ndemonstrated capabilities for generating content that could be deemed harmful.\nTo mitigate these risks, researchers have adopted safety training techniques to\nalign model outputs with societal values to curb the generation of malicious\ncontent. However, the phenomenon of \"jailbreaking\", where carefully crafted\nprompts elicit harmful responses from models, persists as a significant\nchallenge. This research conducts a comprehensive analysis of existing studies\non jailbreaking LLMs and their defense techniques. We meticulously investigate\nnine attack techniques and seven defense techniques applied across three\ndistinct language models: Vicuna, LLama, and GPT-3.5 Turbo. We aim to evaluate\nthe effectiveness of these attack and defense techniques. Our findings reveal\nthat existing white-box attacks underperform compared to universal techniques\nand that including special tokens in the input significantly affects the\nlikelihood of successful attacks. This research highlights the need to\nconcentrate on the security facets of LLMs. Additionally, we contribute to the\nfield by releasing our datasets and testing framework, aiming to foster further\nresearch into LLM security. We believe these contributions will facilitate the\nexploration of security measures within this domain.",
      "tldr_zh": "本研究对大型语言模型（LLMs）的越狱攻击（jailbreaking）和防御技术进行了全面分析，旨在解决这些模型生成有害内容的潜在风险。研究者评估了九种攻击技术和七种防御技术在Vicuna、LLaMA和GPT-3.5 Turbo三个模型上的表现，发现白盒攻击（white-box attacks）的效果不如通用技术，且输入中包含特殊标记会显著提高攻击成功率。这些发现突出了LLMs安全性的紧迫性，并通过发布数据集和测试框架，促进了进一步的安全研究探索。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 9 figures, Accepted in ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.13457v2",
      "published_date": "2024-02-21 01:26:39 UTC",
      "updated_date": "2024-05-17 05:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:52:53.341604"
    },
    {
      "arxiv_id": "2402.14860v4",
      "title": "Ranking Large Language Models without Ground Truth",
      "title_zh": "翻译失败",
      "authors": [
        "Amit Dhurandhar",
        "Rahul Nair",
        "Moninder Singh",
        "Elizabeth Daly",
        "Karthikeyan Natesan Ramamurthy"
      ],
      "abstract": "Evaluation and ranking of large language models (LLMs) has become an\nimportant problem with the proliferation of these models and their impact.\nEvaluation methods either require human responses which are expensive to\nacquire or use pairs of LLMs to evaluate each other which can be unreliable. In\nthis paper, we provide a novel perspective where, given a dataset of prompts\n(viz. questions, instructions, etc.) and a set of LLMs, we rank them without\naccess to any ground truth or reference responses. Inspired by real life where\nboth an expert and a knowledgeable person can identify a novice our main idea\nis to consider triplets of models, where each one of them evaluates the other\ntwo, correctly identifying the worst model in the triplet with high\nprobability. We also analyze our idea and provide sufficient conditions for it\nto succeed. Applying this idea repeatedly, we propose two methods to rank LLMs.\nIn experiments on different generative tasks (summarization, multiple-choice,\nand dialog), our methods reliably recover close to true rankings without\nreference data. This points to a viable low-resource mechanism for practical\nuse.",
      "tldr_zh": "这篇论文提出了一种无需ground truth数据的方法来排名大型语言模型(LLMs)，通过利用prompts数据集和一组LLMs进行相互评估。核心想法是基于LLMs三元组(triplets)，其中每个模型评估其他两个，以高概率正确识别最差的模型，并通过重复应用此过程开发出两种排名方法。实验在摘要、多选题和对话等生成任务上显示，该方法可靠地恢复接近真实的排名，为低资源的LLMs评估机制提供了可行方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14860v4",
      "published_date": "2024-02-21 00:49:43 UTC",
      "updated_date": "2024-06-10 16:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:53:05.993270"
    },
    {
      "arxiv_id": "2402.13448v2",
      "title": "ED-Copilot: Reduce Emergency Department Wait Time with Language Model Diagnostic Assistance",
      "title_zh": "翻译失败",
      "authors": [
        "Liwen Sun",
        "Abhineet Agarwal",
        "Aaron Kornblith",
        "Bin Yu",
        "Chenyan Xiong"
      ],
      "abstract": "In the emergency department (ED), patients undergo triage and multiple\nlaboratory tests before diagnosis. This time-consuming process causes ED\ncrowding which impacts patient mortality, medical errors, staff burnout, etc.\nThis work proposes (time) cost-effective diagnostic assistance that leverages\nartificial intelligence systems to help ED clinicians make efficient and\naccurate diagnoses. In collaboration with ED clinicians, we use public patient\ndata to curate MIMIC-ED-Assist, a benchmark for AI systems to suggest\nlaboratory tests that minimize wait time while accurately predicting critical\noutcomes such as death. With MIMIC-ED-Assist, we develop ED-Copilot which\nsequentially suggests patient-specific laboratory tests and makes diagnostic\npredictions. ED-Copilot employs a pre-trained bio-medical language model to\nencode patient information and uses reinforcement learning to minimize ED wait\ntime and maximize prediction accuracy. On MIMIC-ED-Assist, ED-Copilot improves\nprediction accuracy over baselines while halving average wait time from four\nhours to two hours. ED-Copilot can also effectively personalize treatment\nrecommendations based on patient severity, further highlighting its potential\nas a diagnostic assistant. Since MIMIC-ED-Assist is a retrospective benchmark,\nED-Copilot is restricted to recommend only observed tests. We show ED-Copilot\nachieves competitive performance without this restriction as the maximum\nallowed time increases. Our code is available at\nhttps://github.com/cxcscmu/ED-Copilot.",
      "tldr_zh": "本研究针对急诊室（ED）患者分诊和实验室测试导致的等待时间过长问题，提出 ED-Copilot，一种基于语言模型的诊断辅助系统，以提高诊断效率并减少等待时间。ED-Copilot 使用预训练的生物医学语言模型编码患者信息，并结合强化学习（reinforcement learning）来顺序建议患者特定的实验室测试，同时最大化预测准确性。在 MIMIC-ED-Assist 基准上，该系统将平均等待时间从四小时减半至两小时，同时提升了预测准确性，并能根据患者严重程度提供个性化治疗推荐。该方法展示了 AI 在 ED 环境中的潜力，尽管目前限于回顾性数据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13448v2",
      "published_date": "2024-02-21 00:49:42 UTC",
      "updated_date": "2024-05-27 22:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:53:19.061691"
    },
    {
      "arxiv_id": "2402.13440v1",
      "title": "A Neuro-Symbolic Approach to Multi-Agent RL for Interpretability and Probabilistic Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Chitra Subramanian",
        "Miao Liu",
        "Naweed Khan",
        "Jonathan Lenchner",
        "Aporva Amarnath",
        "Sarathkrishna Swaminathan",
        "Ryan Riegel",
        "Alexander Gray"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) is well-suited for runtime\ndecision-making in optimizing the performance of systems where multiple agents\ncoexist and compete for shared resources. However, applying common deep\nlearning-based MARL solutions to real-world problems suffers from issues of\ninterpretability, sample efficiency, partial observability, etc. To address\nthese challenges, we present an event-driven formulation, where decision-making\nis handled by distributed co-operative MARL agents using neuro-symbolic\nmethods. The recently introduced neuro-symbolic Logical Neural Networks (LNN)\nframework serves as a function approximator for the RL, to train a rules-based\npolicy that is both logical and interpretable by construction. To enable\ndecision-making under uncertainty and partial observability, we developed a\nnovel probabilistic neuro-symbolic framework, Probabilistic Logical Neural\nNetworks (PLNN), which combines the capabilities of logical reasoning with\nprobabilistic graphical models. In PLNN, the upward/downward inference\nstrategy, inherited from LNN, is coupled with belief bounds by setting the\nactivation function for the logical operator associated with each neural\nnetwork node to a probability-respecting generalization of the Fr\\'echet\ninequalities. These PLNN nodes form the unifying element that combines\nprobabilistic logic and Bayes Nets, permitting inference for variables with\nunobserved states. We demonstrate our contributions by addressing key MARL\nchallenges for power sharing in a system-on-chip application.",
      "tldr_zh": "这篇论文提出了一种神经符号方法，用于多智能体强化学习 (Multi-Agent RL)，以解决解释性、样本效率和部分可观察性等问题。作者使用事件驱动的公式和 Logical Neural Networks (LNN) 作为函数逼近器，训练基于规则的政策，确保决策过程的逻辑性和可解释性。同时，他们开发了新的 Probabilistic Logical Neural Networks (PLNN) 框架，将逻辑推理与概率图形模型结合，通过修改激活函数（如 Fréchet 不等式的概率化版本）来处理不确定性和部分可观察性。在系统-on-chip 的功率共享应用中，该方法成功解决了关键 MARL 挑战，展示了其实际有效性。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.13440v1",
      "published_date": "2024-02-21 00:16:08 UTC",
      "updated_date": "2024-02-21 00:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:53:30.824843"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 119,
  "processed_papers_count": 119,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T08:53:59.794796"
}