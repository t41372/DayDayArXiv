{
  "date": "2025-01-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-18 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 在教育、医疗和数据处理领域的创新应用，强调生成式 AI、强化学习和多模态模型的进展，其中 Mixture of Experts 的回顾（作者包括知名学者 Philip S. Yu）令人印象深刻，也有一些医疗 AI 和认知诊断方法展现了实际潜力；整体上，论文探讨了如何提升模型的鲁棒性和效率，值得 AI 研究者关注。\n\n下面，我将挑选并简要讨论几篇关键论文，先从 AI 和教育领域的亮点开始，然后过渡到医疗和数据处理相关内容。对于其他较次要的论文（如特定应用或小众领域），我将快速掠过，只列出标题和核心要点，以控制篇幅。\n\n### 1. **混合专家模型（Mixture of Experts (MoE): A Big Data Perspective）**  \n   作者：Wensheng Gan, Zhenyao Ning, Zhenlian Qi, Philip S. Yu  \n   这篇论文由知名学者 Philip S. Yu 参与，提供对 Mixture of Experts (MoE) 的全面回顾，涵盖其基本原理、算法模型和大数据应用。核心贡献是分析 MoE 在处理海量数据的优势，如解决传统 AI 算法的局限，并总结其在实际场景中的创新应用。该方法有望成为大数据时代 AI 的重要范式，影响深远。\n\n### 2. **通过互动学习框架提升 LLM 代理适应性（Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments）**  \n   作者：Hongjin Su, Ruoxi Sun, Jinsung Yoon, Pengcheng Yin, Tao Yu, Sercan Ö. Arık  \n   论文提出 Learn-by-interact 框架，使用无标注数据合成代理-环境交互轨迹，帮助大型语言模型 (LLMs) 在真实环境中自适应。关键发现是通过后向构建和检索优化，在代码、网页和桌面任务上提升了性能（如在 SWE-bench 上提高 19.5%），这为数据稀缺场景下的 AI 代理训练提供了高效方法。\n\n### 3. **逐步二元反馈优化数学推理（Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback）**  \n   作者：Yen-Ting Lin, Di Jin, Tengyu Xu, Tianhao Wu, Sainbayar Sukhbaatar, Chen Zhu, Yun He, Yun-Nung Chen, Jason Weston, Yuandong Tian, Arash Rahnama, Sinong Wang, Hao Ma, Han Fang  \n   这篇论文引入 Step-KTO 框架，通过对中间步骤和最终答案的双重二元反馈，提升 LLM 在数学推理中的可靠性。核心贡献是改善推理轨迹的连贯性，在 MATH-500 数据集上显著提高 Pass@1 准确率，强调了反馈机制在可解释 AI 中的作用，适合教育和推理任务。\n\n### 4. **医疗细粒度语言-图像预训练（MedFILIP: Medical Fine-grained Language-Image Pre-training）**  \n   作者：Xinjie Liang, Xiangyu Li, Fanding Li, Jie Jiang, Qing Dong, Wei Wang, Kuanquan Wang, Suyu Dong, Gongning Luo, Shuo Li  \n   论文提出 MedFILIP 模型，通过细粒度对比学习和知识注入，提升医疗图像-文本预训练的准确性。关键发现是它在多数据集（如 RSNA-Pneumonia）上提高了分类准确率（最高提升 6.69%），并改进了疾病细节提取，这对医疗诊断有实际意义。\n\n### 5. **全球高分辨率土地覆盖 SAR 数据集（OpenEarthMap-SAR: A Benchmark Synthetic Aperture Radar Dataset for Global High-Resolution Land Cover Mapping）**  \n   作者：Junshi Xia, Hongruixuan Chen, Clifford Broni-Bediako, Yimin Wei, Jian Song, Naoto Yokoya  \n   由 Naoto Yokoya 等作者发布，这篇论文引入 OpenEarthMap-SAR 数据集，包含 1.5 百万段 SAR 图像，用于土地覆盖映射。核心贡献是提供全天候数据支持，并评估了语义分割方法，填补了 SAR 基准数据集的空白，对环境监测和灾害响应有重要影响。\n\n### 6. **JSON 模式基准测试（JSONSchemaBench: A Rigorous Benchmark of Structured Outputs for Language Models）**  \n   作者：Saibo Geng, Hudson Cooper, Michał Moskal, Samuel Jenkins, Julian Berman, Nathan Ranchin, Robert West, Eric Horvitz, Harsha Nori  \n   论文发布 JSONSchemaBench 基准，评估语言模型的结构化输出生成。关键发现是通过评估框架（如 Guidance 和 OpenAI），揭示了约束解码的效率和局限性，这有助于改进 LLM 在实际应用中的鲁棒性。\n\n### 7. **生成式安全应用工程课程（A Generative Security Application Engineering Curriculum）**  \n   作者：Wu-chang Feng, David Baker-Robinson  \n   这篇论文设计了生成式 AI 在安全领域的课程，强调如何整合 AI 自动化。核心贡献是重新聚焦人类独特技能，准备学生应对未来技术景观，对安全教育有指导意义。\n\n### 8. **扩散模型在多标签不平衡数据中的应用（Addressing Multilabel Imbalance with an Efficiency-Focused Approach Using Diffusion Model-Generated Synthetic Samples）**  \n   作者：Francisco Charte, Miguel Ángel Dávila, María Dolores Pérez-Godoy, María José del Jesus  \n   论文提出 MLDM（MultiLabel Diffusion Model），生成合成样本解决多标签不平衡问题。关键发现是它在效率上优于传统方法，提升了模型性能，对数据稀缺领域有帮助。\n\n其他论文如强化学习库存控制（Classical and Deep Reinforcement Learning Inventory Control Policies for Pharmaceutical Supply Chains with Perishability and Non-Stationarity）、零样本事实检查（Zero-shot and Few-shot Learning with Instruction-following LLMs for Claim Matching in Automated Fact-checking）等，快速掠过：它们探讨了特定领域应用，如药物供应链优化和事实检查，但影响力较小，仅验证了 DRL 和 LLM 的潜力。\n\n总体而言，今天的论文突出了 AI 的跨领域创新，尤其在教育和医疗的实际应用上，提醒我们关注模型的鲁棒性和数据质量。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2501.10900v1",
      "title": "A Generative Security Application Engineering Curriculum",
      "title_zh": "生成式安全应用工程课程",
      "authors": [
        "Wu-chang Feng",
        "David Baker-Robinson"
      ],
      "abstract": "Generative AI and large language models (LLMs) are transforming security by\nautomating many tasks being performed manually. With such automation changing\nthe practice of security as we know it, it is imperative that we prepare future\nstudents for the technology landscape they will ultimately face. Towards this\nend, we describe an initial curriculum and course that attempts to show\nstudents how to apply generative AI in order to solve problems in security. By\nrefocusing security education and training on aspects uniquely suited for\nhumans and showing students how to leverage automation for the rest, we believe\nwe can better align security education practices with generative AI as it\nevolves.",
      "tldr_zh": "这篇论文提出一个 Generative AI 应用工程课程，旨在帮助学生学习如何在安全领域利用生成式 AI 和大型语言模型(LLMs)自动化手动任务，以适应未来的技术景观。课程强调重新聚焦安全教育，将人类擅长的方面（如问题分析）与 AI 自动化相结合，从而提升问题解决效率。最终，该方法有助于使安全教育实践与 Generative AI 的持续演进保持一致。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10900v1",
      "published_date": "2025-01-18 23:17:34 UTC",
      "updated_date": "2025-01-18 23:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:48:30.468417"
    },
    {
      "arxiv_id": "2501.10895v1",
      "title": "Classical and Deep Reinforcement Learning Inventory Control Policies for Pharmaceutical Supply Chains with Perishability and Non-Stationarity",
      "title_zh": "针对具有易腐性和非平稳性的制药供应链的经典和深度强化学习库存控制策略",
      "authors": [
        "Francesco Stranieri",
        "Chaaben Kouki",
        "Willem van Jaarsveld",
        "Fabio Stella"
      ],
      "abstract": "We study inventory control policies for pharmaceutical supply chains,\naddressing challenges such as perishability, yield uncertainty, and\nnon-stationary demand, combined with batching constraints, lead times, and lost\nsales. Collaborating with Bristol-Myers Squibb (BMS), we develop a realistic\ncase study incorporating these factors and benchmark three\npolicies--order-up-to (OUT), projected inventory level (PIL), and deep\nreinforcement learning (DRL) using the proximal policy optimization (PPO)\nalgorithm--against a BMS baseline based on human expertise. We derive and\nvalidate bounds-based procedures for optimizing OUT and PIL policy parameters\nand propose a methodology for estimating projected inventory levels, which are\nalso integrated into the DRL policy with demand forecasts to improve\ndecision-making under non-stationarity. Compared to a human-driven policy,\nwhich avoids lost sales through higher holding costs, all three implemented\npolicies achieve lower average costs but exhibit greater cost variability.\nWhile PIL demonstrates robust and consistent performance, OUT struggles under\nhigh lost sales costs, and PPO excels in complex and variable scenarios but\nrequires significant computational effort. The findings suggest that while DRL\nshows potential, it does not outperform classical policies in all numerical\nexperiments, highlighting 1) the need to integrate diverse policies to manage\npharmaceutical challenges effectively, based on the current state-of-the-art,\nand 2) that practical problems in this domain seem to lack a single policy\nclass that yields universally acceptable performance.",
      "tldr_zh": "本研究探讨了制药供应链的库存控制策略，针对易腐性、产量不确定性和非平稳需求等问题，比较了 order-up-to (OUT)、projected inventory level (PIL) 和 deep reinforcement learning (DRL) 使用 proximal policy optimization (PPO) 算法的三种方法，与 Bristol-Myers Squibb (BMS) 的基于人类专家的基准进行评估。\n他们开发了优化 OUT 和 PIL 参数的边界-based 程序，并提出了一种估计 projected inventory levels 的方法，将其整合到 DRL 策略中以改善非平稳条件下的决策。\n结果显示，三种策略比人类驱动策略实现了更低的平均成本，但成本变异性更高；PIL 表现稳健，OUT 在高丢失销售成本下表现较差，而 DRL 在复杂场景中更出色但计算资源密集。\n总体而言，该研究强调了 DRL 并非在所有情况下优于经典策略，建议整合多种策略来有效管理制药供应链挑战。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10895v1",
      "published_date": "2025-01-18 22:40:33 UTC",
      "updated_date": "2025-01-18 22:40:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:48:45.747230"
    },
    {
      "arxiv_id": "2501.10893v1",
      "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
      "title_zh": "Learn-by-interact：一个以数据为中心的框架，用于真实环境中的自适应代理",
      "authors": [
        "Hongjin Su",
        "Ruoxi Sun",
        "Jinsung Yoon",
        "Pengcheng Yin",
        "Tao Yu",
        "Sercan Ö. Arık"
      ],
      "abstract": "Autonomous agents powered by large language models (LLMs) have the potential\nto enhance human capabilities, assisting with digital tasks from sending emails\nto performing data analysis. The abilities of existing LLMs at such tasks are\noften hindered by the lack of high-quality agent data from the corresponding\nenvironments they interact with. We propose Learn-by-interact, a data-centric\nframework to adapt LLM agents to any given environments without human\nannotations. Learn-by-interact synthesizes trajectories of agent-environment\ninteractions based on documentations, and constructs instructions by\nsummarizing or abstracting the interaction histories, a process called backward\nconstruction. We assess the quality of our synthetic data by using them in both\ntraining-based scenarios and training-free in-context learning (ICL), where we\ncraft innovative retrieval approaches optimized for agents. Extensive\nexperiments on SWE-bench, WebArena, OSWorld and Spider2-V spanning across\nrealistic coding, web, and desktop environments show the effectiveness of\nLearn-by-interact in various downstream agentic tasks -- baseline results are\nimproved by up to 12.2\\% for ICL with Claude-3.5 and 19.5\\% for training with\nCodestral-22B. We further demonstrate the critical role of backward\nconstruction, which provides up to 14.0\\% improvement for training. Our\nablation studies demonstrate the efficiency provided by our synthesized data in\nICL and the superiority of our retrieval pipeline over alternative approaches\nlike conventional retrieval-augmented generation (RAG). We expect that\nLearn-by-interact will serve as a foundation for agent data synthesis as LLMs\nare increasingly deployed at real-world environments.",
      "tldr_zh": "本研究提出Learn-by-interact框架，这是一个数据中心方法，旨在帮助LLMs驱动的自治代理适应真实环境，而无需人工标注。通过基于文档合成代理-环境交互轨迹，并使用backward construction过程总结交互历史来构建指令，该框架生成高质量的合成数据。实验在SWE-bench、WebArena、OSWorld和Spider2-V等基准上显示，Learn-by-interact在ICL场景中提升了高达12.2%（Claude-3.5），在训练场景中提升了19.5%（Codestral-22B），backward construction进一步提供了14.0%的改进。该框架证明了其在代理数据合成中的效率和优越性，有望成为LLMs在真实世界部署的基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10893v1",
      "published_date": "2025-01-18 22:34:41 UTC",
      "updated_date": "2025-01-18 22:34:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:48:55.971723"
    },
    {
      "arxiv_id": "2501.10891v2",
      "title": "OpenEarthMap-SAR: A Benchmark Synthetic Aperture Radar Dataset for Global High-Resolution Land Cover Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Junshi Xia",
        "Hongruixuan Chen",
        "Clifford Broni-Bediako",
        "Yimin Wei",
        "Jian Song",
        "Naoto Yokoya"
      ],
      "abstract": "High-resolution land cover mapping plays a crucial role in addressing a wide\nrange of global challenges, including urban planning, environmental monitoring,\ndisaster response, and sustainable development. However, creating accurate,\nlarge-scale land cover datasets remains a significant challenge due to the\ninherent complexities of geospatial data, such as diverse terrain, varying\nsensor modalities, and atmospheric conditions. Synthetic Aperture Radar (SAR)\nimagery, with its ability to penetrate clouds and capture data in all-weather,\nday-and-night conditions, offers unique advantages for land cover mapping.\nDespite these strengths, the lack of benchmark datasets tailored for SAR\nimagery has limited the development of robust models specifically designed for\nthis data modality. To bridge this gap and facilitate advancements in SAR-based\ngeospatial analysis, we introduce OpenEarthMap-SAR, a benchmark SAR dataset,\nfor global high-resolution land cover mapping. OpenEarthMap-SAR consists of 1.5\nmillion segments of 5033 aerial and satellite images with the size of\n1024$\\times$1024 pixels, covering 35 regions from Japan, France, and the USA,\nwith partially manually annotated and fully pseudo 8-class land cover labels at\na ground sampling distance of 0.15--0.5 m. We evaluated the performance of\nstate-of-the-art methods for semantic segmentation and present challenging\nproblem settings suitable for further technical development. The dataset also\nserves the official dataset for IEEE GRSS Data Fusion Contest Track I. The\ndataset has been made publicly available at\nhttps://zenodo.org/records/14622048.",
      "tldr_zh": "该论文介绍了 OpenEarthMap-SAR，这是一个针对全球高分辨率土地覆盖映射的基准 Synthetic Aperture Radar (SAR) 数据集，旨在解决现有数据集缺乏问题，以支持城市规划、环境监测和灾害响应等应用。数据集包含 1.5 百万段图像，总计 5033 张 1024×1024 像素的航空和卫星图像，覆盖日本、法国和美国的 35 个地区，并提供部分手动标注和全伪标签的 8 类土地覆盖标签，地面采样距离为 0.15–0.5 m。作者评估了最先进语义分割方法的表现，提出了挑战性问题设置，并将数据集作为 IEEE GRSS Data Fusion Contest Track I 的官方资源公开提供，以推动 SAR 图像分析的进一步发展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10891v2",
      "published_date": "2025-01-18 22:30:27 UTC",
      "updated_date": "2025-01-22 02:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:49:08.318907"
    },
    {
      "arxiv_id": "2501.10868v3",
      "title": "JSONSchemaBench: A Rigorous Benchmark of Structured Outputs for Language Models",
      "title_zh": "JSONSchemaBench：语言模型结构化输出的严格基准测试",
      "authors": [
        "Saibo Geng",
        "Hudson Cooper",
        "Michał Moskal",
        "Samuel Jenkins",
        "Julian Berman",
        "Nathan Ranchin",
        "Robert West",
        "Eric Horvitz",
        "Harsha Nori"
      ],
      "abstract": "Reliably generating structured outputs has become a critical capability for\nmodern language model (LM) applications. Constrained decoding has emerged as\nthe dominant technology across sectors for enforcing structured outputs during\ngeneration. Despite its growing adoption, little has been done with the\nsystematic evaluation of the behaviors and performance of constrained decoding.\nConstrained decoding frameworks have standardized around JSON Schema as a\nstructured data format, with most uses guaranteeing constraint compliance given\na schema. However, there is poor understanding of the effectiveness of the\nmethods in practice. We present an evaluation framework to assess constrained\ndecoding approaches across three critical dimensions: efficiency in generating\nconstraint-compliant outputs, coverage of diverse constraint types, and quality\nof the generated outputs. To facilitate this evaluation, we introduce\nJSONSchemaBench, a benchmark for constrained decoding comprising 10K real-world\nJSON schemas that encompass a wide range of constraints with varying\ncomplexity. We pair the benchmark with the existing official JSON Schema Test\nSuite and evaluate six state-of-the-art constrained decoding frameworks,\nincluding Guidance, Outlines, Llamacpp, XGrammar, OpenAI, and Gemini. Through\nextensive experiments, we gain insights into the capabilities and limitations\nof constrained decoding on structured generation with real-world JSON schemas.\nOur work provides actionable insights for improving constrained decoding\nframeworks and structured generation tasks, setting a new standard for\nevaluating constrained decoding and structured generation. We release\nJSONSchemaBench at https://github.com/guidance-ai/jsonschemabench",
      "tldr_zh": "本论文引入了 JSONSchemaBench，一种针对语言模型 (Language Models) 生成结构化输出的严格基准，用于系统评估约束解码框架在效率、约束类型覆盖和输出质量三个关键维度上的表现。该基准包含 10K 个真实世界 JSON schemas，并结合现有 JSON Schema Test Suite，对六种先进框架（如 Guidance 和 Outlines）进行实验评估。结果揭示了约束解码的局限性与优势，为优化结构化生成任务提供了可操作见解，并通过开源发布（https://github.com/guidance-ai/jsonschemabench）设定了新的评估标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10868v3",
      "published_date": "2025-01-18 20:26:00 UTC",
      "updated_date": "2025-02-27 15:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:49:19.549247"
    },
    {
      "arxiv_id": "2501.16352v1",
      "title": "Mixture of Experts (MoE): A Big Data Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Wensheng Gan",
        "Zhenyao Ning",
        "Zhenlian Qi",
        "Philip S. Yu"
      ],
      "abstract": "As the era of big data arrives, traditional artificial intelligence\nalgorithms have difficulty processing the demands of massive and diverse data.\nMixture of experts (MoE) has shown excellent performance and broad application\nprospects. This paper provides an in-depth review and analysis of the latest\nprogress in this field from multiple perspectives, including the basic\nprinciples, algorithmic models, key technical challenges, and application\npractices of MoE. First, we introduce the basic concept of MoE and its core\nidea and elaborate on its advantages over traditional single models. Then, we\ndiscuss the basic architecture of MoE and its main components, including the\ngating network, expert networks, and learning algorithms. Next, we review the\napplications of MoE in addressing key technical issues in big data. For each\nchallenge, we provide specific MoE solutions and their innovations.\nFurthermore, we summarize the typical use cases of MoE in various application\ndomains. This fully demonstrates the powerful capability of MoE in big data\nprocessing. We also analyze the advantages of MoE in big data environments.\nFinally, we explore the future development trends of MoE. We believe that MoE\nwill become an important paradigm of artificial intelligence in the era of big\ndata. In summary, this paper systematically elaborates on the principles,\ntechniques, and applications of MoE in big data processing, providing\ntheoretical and practical references to further promote the application of MoE\nin real scenarios.",
      "tldr_zh": "这篇论文从大数据视角审视 Mixture of Experts (MoE) 模型，介绍了其基本概念、核心优势（如比传统单模型更高效处理海量多样数据），以及架构组件包括 gating network、expert networks 和学习算法。论文回顾了 MoE 在解决大数据关键技术挑战（如数据处理瓶颈）的创新解决方案，并总结了其在各种应用领域的典型用例，展示了 MoE 的强大处理能力。最后，论文预测 MoE 将成为大数据时代人工智能的重要范式，并为实际应用提供理论和实践指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.16352v1",
      "published_date": "2025-01-18 20:17:31 UTC",
      "updated_date": "2025-01-18 20:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:49:32.018104"
    },
    {
      "arxiv_id": "2501.10861v1",
      "title": "Dynamic Continual Learning: Harnessing Parameter Uncertainty for Improved Network Adaptation",
      "title_zh": "动态",
      "authors": [
        "Christopher Angelini",
        "Nidhal Bouaynaya"
      ],
      "abstract": "When fine-tuning Deep Neural Networks (DNNs) to new data, DNNs are prone to\noverwriting network parameters required for task-specific functionality on\npreviously learned tasks, resulting in a loss of performance on those tasks. We\npropose using parameter-based uncertainty to determine which parameters are\nrelevant to a network's learned function and regularize training to prevent\nchange in these important parameters. We approach this regularization in two\nways: (1), we constrain critical parameters from significant changes by\nassociating more critical parameters with lower learning rates, thereby\nlimiting alterations in those parameters; (2), important parameters are\nrestricted from change by imposing a higher regularization weighting, causing\nparameters to revert to their states prior to the learning of subsequent tasks.\nWe leverage a Bayesian Moment Propagation framework which learns network\nparameters concurrently with their associated uncertainties while allowing each\nparameter to contribute uncertainty to the network's predictive distribution,\navoiding the pitfalls of existing sampling-based methods. The proposed approach\nis evaluated for common sequential benchmark datasets and compared to existing\npublished approaches from the Continual Learning community. Ultimately, we show\nimproved Continual Learning performance for Average Test Accuracy and Backward\nTransfer metrics compared to sampling-based methods and other\nnon-uncertainty-based approaches.",
      "tldr_zh": "本研究针对深度神经网络(DNNs)在微调新数据时易覆盖先前任务参数导致性能下降的问题，提出了一种动态持续学习方法，通过利用参数不确定性来识别并保护重要参数。方法包括两种正则化策略：(1) 为关键参数分配更低的学习率以限制其变化；(2) 施加更高的正则化权重，使这些参数回归到之前状态，并采用 Bayesian Moment Propagation 框架同时学习参数及其不确定性，避免传统采样方法的缺点。在常见顺序基准数据集上的实验显示，该方法在平均测试准确率和后向转移指标上优于现有持续学习(Continual Learning)方法和非不确定性方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10861v1",
      "published_date": "2025-01-18 19:58:53 UTC",
      "updated_date": "2025-01-18 19:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:49:44.020084"
    },
    {
      "arxiv_id": "2501.10860v2",
      "title": "Zero-shot and Few-shot Learning with Instruction-following LLMs for Claim Matching in Automated Fact-checking",
      "title_zh": "零",
      "authors": [
        "Dina Pisarevskaya",
        "Arkaitz Zubiaga"
      ],
      "abstract": "The claim matching (CM) task can benefit an automated fact-checking pipeline\nby putting together claims that can be resolved with the same fact-check. In\nthis work, we are the first to explore zero-shot and few-shot learning\napproaches to the task. We consider CM as a binary classification task and\nexperiment with a set of instruction-following large language models\n(GPT-3.5-turbo, Gemini-1.5-flash, Mistral-7B-Instruct, and\nLlama-3-8B-Instruct), investigating prompt templates. We introduce a new CM\ndataset, ClaimMatch, which will be released upon acceptance. We put LLMs to the\ntest in the CM task and find that it can be tackled by leveraging more mature\nyet similar tasks such as natural language inference or paraphrase detection.\nWe also propose a pipeline for CM, which we evaluate on texts of different\nlengths.",
      "tldr_zh": "本文首次探索零-shot 和 few-shot 学习在声明匹配（Claim Matching, CM）任务中的应用，以提升自动化事实检查（Automated Fact-checking）管道的效率，将可通过相同事实检查解决的声明配对。研究将 CM 视为二元分类任务，使用指令跟随的大型语言模型（LLMs）如 GPT-3.5-turbo、Gemini-1.5-flash、Mistral-7B-Instruct 和 Llama-3-8B-Instruct，并测试不同提示模板。作者引入了一个新数据集 ClaimMatch，并提出一个 CM 管道，通过利用类似任务如自然语言推理（Natural Language Inference）和释义检测（Paraphrase Detection）来优化性能。实验结果表明，该方法在不同文本长度上表现出色，证明 LLMs 可有效处理 CM 任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at the 31st International Conference on Computational\n  Linguistics (COLING 2025). Compared to the conference version of the paper,\n  the dataset link is added here & 2 minor typos fixed",
      "pdf_url": "http://arxiv.org/pdf/2501.10860v2",
      "published_date": "2025-01-18 19:57:54 UTC",
      "updated_date": "2025-02-28 22:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:49:57.335038"
    },
    {
      "arxiv_id": "2501.10858v1",
      "title": "Reliable Text-to-SQL with Adaptive Abstention",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiwen Chen",
        "Yueting Chen",
        "Xiaohui Yu",
        "Nick Koudas"
      ],
      "abstract": "Large language models (LLMs) have revolutionized natural language interfaces\nfor databases, particularly in text-to-SQL conversion. However, current\napproaches often generate unreliable outputs when faced with ambiguity or\ninsufficient context. We present Reliable Text-to-SQL (RTS), a novel framework\nthat enhances query generation reliability by incorporating abstention and\nhuman-in-the-loop mechanisms. RTS focuses on the critical schema linking phase,\nwhich aims to identify the key database elements needed for generating SQL\nqueries. It autonomously detects potential errors during the answer generation\nprocess and responds by either abstaining or engaging in user interaction. A\nvital component of RTS is the Branching Point Prediction (BPP) which utilizes\nstatistical conformal techniques on the hidden layers of the LLM model for\nschema linking, providing probabilistic guarantees on schema linking accuracy.\nWe validate our approach through comprehensive experiments on the BIRD\nbenchmark, demonstrating significant improvements in robustness and\nreliability. Our findings highlight the potential of combining transparent-box\nLLMs with human-in-the-loop processes to create more robust natural language\ninterfaces for databases. For the BIRD benchmark, our approach achieves\nnear-perfect schema linking accuracy, autonomously involving a human when\nneeded. Combined with query generation, we demonstrate that near-perfect schema\nlinking and a small query generation model can almost match SOTA accuracy\nachieved with a model orders of magnitude larger than the one we use.",
      "tldr_zh": "本文提出 Reliable Text-to-SQL (RTS) 框架，通过自适应弃权机制和 human-in-the-loop 人工介入，提升大型语言模型 (LLMs) 在文本到 SQL 转换中的可靠性，特别是针对模糊或上下文不足的问题。RTS 重点优化 schema linking 阶段，利用 Branching Point Prediction (BPP) 和统计 conformal techniques 在 LLM 隐藏层进行错误检测，提供概率保证的准确性。实验在 BIRD benchmark 上验证，RTS 实现了近乎完美的 schema linking 准确率，并证明使用较小模型结合该框架可几乎匹配比其大几个数量级的 SOTA 性能。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10858v1",
      "published_date": "2025-01-18 19:36:37 UTC",
      "updated_date": "2025-01-18 19:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:50:07.343964"
    },
    {
      "arxiv_id": "2501.10848v1",
      "title": "Fake Advertisements Detection Using Automated Multimodal Learning: A Case Study for Vietnamese Real Estate Data",
      "title_zh": "翻译失败",
      "authors": [
        "Duy Nguyen",
        "Trung T. Nguyen",
        "Cuong V. Nguyen"
      ],
      "abstract": "The popularity of e-commerce has given rise to fake advertisements that can\nexpose users to financial and data risks while damaging the reputation of these\ne-commerce platforms. For these reasons, detecting and removing such fake\nadvertisements are important for the success of e-commerce websites. In this\npaper, we propose FADAML, a novel end-to-end machine learning system to detect\nand filter out fake online advertisements. Our system combines techniques in\nmultimodal machine learning and automated machine learning to achieve a high\ndetection rate. As a case study, we apply FADAML to detect fake advertisements\non popular Vietnamese real estate websites. Our experiments show that we can\nachieve 91.5% detection accuracy, which significantly outperforms three\ndifferent state-of-the-art fake news detection systems.",
      "tldr_zh": "本研究针对电商平台的假广告问题，提出了一种新型端到端机器学习系统FADAML，用于检测和过滤假在线广告，以减少用户财务和数据风险。FADAML结合multimodal machine learning和automated machine learning技术，实现高检测率，并作为案例研究应用于越南房地产网站。实验结果显示，该系统在检测准确率上达到91.5%，显著优于现有假新闻检测系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10848v1",
      "published_date": "2025-01-18 18:48:06 UTC",
      "updated_date": "2025-01-18 18:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:50:18.952221"
    },
    {
      "arxiv_id": "2501.10841v1",
      "title": "Practical and Ready-to-Use Methodology to Assess the re-identification Risk in Anonymized Datasets",
      "title_zh": "评估匿名数据集再识别风险的实用且即用型方法论",
      "authors": [
        "Louis-Philippe Sondeck",
        "Maryline Laurent"
      ],
      "abstract": "To prove that a dataset is sufficiently anonymized, many privacy policies\nsuggest that a re-identification risk assessment be performed, but do not\nprovide a precise methodology for doing so, leaving the industry alone with the\nproblem. This paper proposes a practical and ready-to-use methodology for\nre-identification risk assessment, the originality of which is manifold: (1) it\nis the first to follow well-known risk analysis methods (e.g. EBIOS) that have\nbeen used in the cybersecurity field for years, which consider not only the\nability to perform an attack, but also the impact such an attack can have on an\nindividual; (2) it is the first to qualify attributes and values of attributes\nwith e.g. degree of exposure, as known real-world attacks mainly target certain\ntypes of attributes and not others.",
      "tldr_zh": "本论文提出了一种实用的、现成的再-identification风险评估方法，用于证明匿名数据集的匿名化是否足够。该方法首次借鉴网络安全领域的风险分析方法（如EBIOS），不仅评估攻击的可能性，还考虑攻击对个人的潜在影响。该方法还对属性和属性值进行定性评估，例如暴露程度，以针对现实世界中主要针对特定属性的攻击，提供了一个行业可直接应用的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10841v1",
      "published_date": "2025-01-18 18:22:27 UTC",
      "updated_date": "2025-01-18 18:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:50:31.776226"
    },
    {
      "arxiv_id": "2501.16350v1",
      "title": "A Method for Multi-Hop Question Answering on Persian Knowledge Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Arash Ghafouri",
        "Mahdi Firouzmandi",
        "Hasan Naderi"
      ],
      "abstract": "Question answering systems are the latest evolution in information retrieval\ntechnology, designed to accept complex queries in natural language and provide\naccurate answers using both unstructured and structured knowledge sources.\nKnowledge Graph Question Answering (KGQA) systems fulfill users' information\nneeds by utilizing structured data, representing a vast number of facts as a\ngraph. However, despite significant advancements, major challenges persist in\nanswering multi-hop complex questions, particularly in Persian. One of the main\nchallenges is the accurate understanding and transformation of these multi-hop\ncomplex questions into semantically equivalent SPARQL queries, which allows for\nprecise answer retrieval from knowledge graphs. In this study, to address this\nissue, a dataset of 5,600 Persian multi-hop complex questions was developed,\nalong with their decomposed forms based on the semantic representation of the\nquestions. Following this, Persian language models were trained using this\ndataset, and an architecture was proposed for answering complex questions using\na Persian knowledge graph. Finally, the proposed method was evaluated against\nsimilar systems on the PeCoQ dataset. The results demonstrated the superiority\nof our approach, with an improvement of 12.57% in F1-score and 12.06% in\naccuracy compared to the best comparable method.",
      "tldr_zh": "本研究针对波斯语知识图上的多跳复杂问题问答（KGQA）系统，解决了将自然语言查询准确转换为等价SPARQL查询的挑战。研究者开发了一个包含5600个波斯语多跳复杂问题的数据集，并基于其语义分解形式训练波斯语模型，同时提出了一种新的架构来利用波斯语知识图回答这些问题。在PeCoQ数据集上的评估显示，该方法相比最佳基准方法，F1-score提高了12.57%，准确率提高了12.06%。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16350v1",
      "published_date": "2025-01-18 18:11:29 UTC",
      "updated_date": "2025-01-18 18:11:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:50:43.486932"
    },
    {
      "arxiv_id": "2501.10836v2",
      "title": "BAP v2: An Enhanced Task Framework for Instruction Following in Minecraft Dialogues",
      "title_zh": "BAP v2：用于 Minecraft 对话中指令遵循的增强任务框架",
      "authors": [
        "Prashant Jayannavar",
        "Liliang Ren",
        "Marisa Hudspeth",
        "Charlotte Lambert",
        "Ariel Cordes",
        "Elizabeth Kaplan",
        "Anjali Narayan-Chen",
        "Julia Hockenmaier"
      ],
      "abstract": "Interactive agents capable of understanding and executing instructions in the\nphysical world have long been a central goal in AI research. The Minecraft\nCollaborative Building Task (MCBT) provides one such setting to work towards\nthis goal (Narayan-Chen, Jayannavar, and Hockenmaier 2019). It is a two-player\ngame in which an Architect (A) instructs a Builder (B) to construct a target\nstructure in a simulated Blocks World Environment. We focus on the challenging\nBuilder Action Prediction (BAP) subtask of predicting correct action sequences\nin a given multimodal game context with limited training data (Jayannavar,\nNarayan-Chen, and Hockenmaier 2020). We take a closer look at evaluation and\ndata for the BAP task, discovering key challenges and making significant\nimprovements on both fronts to propose BAP v2, an upgraded version of the task.\nThis will allow future work to make more efficient and meaningful progress on\nit. It comprises of: (1) an enhanced evaluation benchmark that includes a\ncleaner test set and fairer, more insightful metrics, and (2) additional\nsynthetic training data generated from novel Minecraft dialogue and target\nstructure simulators emulating the MCBT. We show that the synthetic data can be\nused to train more performant and robust neural models even with relatively\nsimple training methods. Looking ahead, such data could also be crucial for\ntraining more sophisticated, data-hungry deep transformer models and\ntraining/fine-tuning increasingly large LLMs. Although modeling is not the\nprimary focus of this work, we also illustrate the impact of our data and\ntraining methodologies on a simple LLM- and transformer-based model, thus\nvalidating the robustness of our approach, and setting the stage for more\nadvanced architectures and LLMs going forward.",
      "tldr_zh": "这篇论文介绍了 BAP v2，一种增强版的 Minecraft 协作构建任务 (MCBT) 框架，针对 Builder Action Prediction (BAP) 子任务，旨在改进指令遵循的评估和数据挑战。BAP v2 包括更干净的测试集、更公平的评估指标，以及通过新型 Minecraft 对话和目标结构模拟器生成的额外合成训练数据，这些数据能显著提升神经模型的性能和鲁棒性，即使采用简单的训练方法。实验验证了这种方法在 LLM 和 transformer 模型上的有效性，为未来训练更先进的数据密集型模型奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10836v2",
      "published_date": "2025-01-18 18:06:03 UTC",
      "updated_date": "2025-02-23 02:54:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:50:55.573778"
    },
    {
      "arxiv_id": "2501.10834v1",
      "title": "Visual RAG: Expanding MLLM visual knowledge without fine-tuning",
      "title_zh": "Visual RAG：无需微调扩展 MLLM 视觉知识",
      "authors": [
        "Mirco Bonomo",
        "Simone Bianco"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have achieved notable performance in\ncomputer vision tasks that require reasoning across visual and textual\nmodalities, yet their capabilities are limited to their pre-trained data,\nrequiring extensive fine-tuning for updates. Recent researches have explored\nthe use of In-Context Learning (ICL) to overcome these challenges by providing\na set of demonstrating examples as context to augment MLLMs performance in\nseveral tasks, showing that many-shot ICL leads to substantial improvements\ncompared to few-shot ICL. However, the reliance on numerous demonstrating\nexamples and the limited MLLMs context windows presents significant obstacles.\nThis paper aims to address these challenges by introducing a novel approach,\nVisual RAG, that synergically combines the MLLMs capability to learn from the\ncontext, with a retrieval mechanism. The crux of this approach is to ensure to\naugment the MLLM knowledge by selecting only the most relevant demonstrating\nexamples for the query, pushing it to learn by analogy. In this way, relying on\nthe new information provided dynamically during inference time, the resulting\nsystem is not limited to the knowledge extracted from the training data, but\ncan be updated rapidly and easily without fine-tuning. Furthermore, this\ngreatly reduces the computational costs for improving the model image\nclassification performance, and augments the model knowledge to new visual\ndomains and tasks it was not trained for. Extensive experiments on eight\ndifferent datasets in the state of the art spanning several domains and image\nclassification tasks show that the proposed Visual RAG, compared to the most\nrecent state of the art (i.e., many-shot ICL), is able to obtain an accuracy\nthat is very close or even higher (approx. +2% improvement on average) while\nusing a much smaller set of demonstrating examples (approx. only 23% on\naverage).",
      "tldr_zh": "该研究提出Visual RAG方法，用于扩展Multimodal Large Language Models (MLLMs)的视觉知识，而无需进行微调。该方法结合MLLMs的In-Context Learning (ICL)能力与检索机制，通过选择与查询最相关的演示示例，实现模型的类比学习，从而动态更新知识并降低计算成本。实验在八个跨领域的图像分类数据集上显示，Visual RAG相较于最先进的多示例ICL方法，平均准确率提升约2%，却仅使用约23%的演示示例，证明其在扩展新视觉领域和任务方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10834v1",
      "published_date": "2025-01-18 17:43:05 UTC",
      "updated_date": "2025-01-18 17:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:51:07.944237"
    },
    {
      "arxiv_id": "2501.10822v1",
      "title": "Addressing Multilabel Imbalance with an Efficiency-Focused Approach Using Diffusion Model-Generated Synthetic Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Charte",
        "Miguel Ángel Dávila",
        "María Dolores Pérez-Godoy",
        "María José del Jesus"
      ],
      "abstract": "Predictive models trained on imbalanced data tend to produce biased results.\nThis problem is exacerbated when there is not just one output label, but a set\nof them. This is the case for multilabel learning (MLL) algorithms used to\nclassify patterns, rank labels, or learn the distribution of outputs. Many\nsolutions have been proposed in the literature. The one that can be applied\nuniversally, independent of the algorithm used to build the model, is data\nresampling. The generation of new instances associated with minority labels, so\nthat empty areas of the feature space are filled, helps to improve the obtained\nmodels. The quality of these new instances depends on the algorithm used to\ngenerate them. In this paper, a diffusion model tailored to produce new\ninstances for MLL data, called MLDM (\\textit{MultiLabel Diffusion Model}), is\nproposed. Diffusion models have been mainly used to generate artificial images\nand videos. Our proposed MLDM is based on this type of models. The experiments\nconducted compare MLDM with several other MLL resampling algorithms. The\nresults show that MLDM is competitive while it improves efficiency.",
      "tldr_zh": "该论文针对多标签学习（multilabel learning）中的数据不平衡问题，提出了一种以效率为重点的方法，使用扩散模型（diffusion models）生成的合成样本进行数据重采样，以减少模型偏见。论文引入了新的模型 MLDM（MultiLabel Diffusion Model），该模型专门设计用于生成高质量的少数标签实例，填充特征空间的空缺区域。实验结果表明，MLDM 与其他多标签重采样算法相比，具有竞争力，同时显著提高了效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 8 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.10822v1",
      "published_date": "2025-01-18 16:56:50 UTC",
      "updated_date": "2025-01-18 16:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:51:18.728085"
    },
    {
      "arxiv_id": "2501.16349v1",
      "title": "Risk-Informed Diffusion Transformer for Long-Tail Trajectory Prediction in the Crash Scenario",
      "title_zh": "翻译失败",
      "authors": [
        "Junlan Chen",
        "Pei Liu",
        "Zihao Zhang",
        "Hongyi Zhao",
        "Yufei Ji",
        "Ziyuan Pu"
      ],
      "abstract": "Trajectory prediction methods have been widely applied in autonomous driving\ntechnologies. Although the overall performance accuracy of trajectory\nprediction is relatively high, the lack of trajectory data in critical\nscenarios in the training data leads to the long-tail phenomenon. Normally, the\ntrajectories of the tail data are more critical and more difficult to predict\nand may include rare scenarios such as crashes. To solve this problem, we\nextracted the trajectory data from real-world crash scenarios, which contain\nmore long-tail data. Meanwhile, based on the trajectory data in this scenario,\nwe integrated graph-based risk information and diffusion with transformer and\nproposed the Risk-Informed Diffusion Transformer (RI-DiT) trajectory prediction\nmethod. Extensive experiments were conducted on trajectory data in the\nreal-world crash scenario, and the results show that the algorithm we proposed\nhas good performance. When predicting the data of the tail 10\\% (Top 10\\%), the\nminADE and minFDE indicators are 0.016/2.667 m. At the same time, we showed the\ntrajectory conditions of different long-tail distributions. The distribution of\ntrajectory data is closer to the tail, the less smooth the trajectory is.\nThrough the trajectory data in real-world crash scenarios, Our work expands the\nmethods to overcome the long-tail challenges in trajectory prediction. Our\nmethod, RI-DiT, integrates inverse time to collision (ITTC) and the feature of\ntraffic flow, which can predict long-tail trajectories more accurately and\nimprove the safety of autonomous driving systems.",
      "tldr_zh": "这篇论文针对轨迹预测(long-tail trajectory prediction)中的长尾问题，特别是碰撞(crash scenario)场景数据不足的问题，提出了Risk-Informed Diffusion Transformer (RI-DiT) 方法，该方法整合了图-based风险信息、扩散模型和Transformer架构，并使用真实碰撞场景数据进行训练。实验结果显示，RI-DiT在长尾数据（Top 10%）上的minADE和minFDE指标分别达到0.016/2.667 m，显著提高了预测性能，并展示了不同长尾分布下轨迹的平滑性差异。该方法通过结合逆时间碰撞(ITTC)和交通流特征，增强了长尾轨迹的准确预测，从而提升了自动驾驶系统的安全性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16349v1",
      "published_date": "2025-01-18 16:47:29 UTC",
      "updated_date": "2025-01-18 16:47:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:51:32.101906"
    },
    {
      "arxiv_id": "2501.10814v2",
      "title": "No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling",
      "title_zh": "无需滑动窗口：利用可微Top-k",
      "authors": [
        "Young Seok Jeon",
        "Hongfei Yang",
        "Huazhu Fu",
        "Mengling Feng"
      ],
      "abstract": "3D models surpass 2D models in CT/MRI segmentation by effectively capturing\ninter-slice relationships. However, the added depth dimension substantially\nincreases memory consumption. While patch-based training alleviates memory\nconstraints, it significantly slows down the inference speed due to the sliding\nwindow (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel\nend-to-end trainable framework that enhances the efficiency of generic 3D\nsegmentation backbone during an inference step by eliminating the need for SW.\nNMSW employs a differentiable Top-k module to selectively sample only the most\nrelevant patches, thereby minimizing redundant computations. When patch-level\npredictions are insufficient, the framework intelligently leverages coarse\nglobal predictions to refine results. Evaluated across 3 tasks using 3\nsegmentation backbones, NMSW achieves competitive accuracy compared to SW\ninference while significantly reducing computational complexity by 91% (88.0 to\n8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU\n(99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to\n189 sec). NMSW is model-agnostic, further boosting efficiency when integrated\nwith any existing efficient segmentation backbones.",
      "tldr_zh": "该研究针对3D医疗图像分割中的内存消耗和推断速度问题，提出No More Sliding Window (NMSW)框架，使用Differentiable Top-k模块选择最相关patches，消除传统sliding window的冗余计算，并通过粗糙全局预测精炼结果。NMSW在3个任务和3个分割骨干上实现与sliding window相当的准确性，同时减少91%的计算复杂度（从88.0到8.00 TMACs）。此外，该框架在H100 GPU上加速9.1倍（从99.0到8.3秒），在Xeon Gold CPU上加速11.1倍（从2110到189秒），并支持与其他高效分割骨干整合，进一步提升整体效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10814v2",
      "published_date": "2025-01-18 16:23:09 UTC",
      "updated_date": "2025-03-06 11:05:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:51:45.151078"
    },
    {
      "arxiv_id": "2501.10812v1",
      "title": "Graph Coloring to Reduce Computation Time in Prioritized Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Scheffe",
        "Julius Kahle",
        "Bassam Alrifaee"
      ],
      "abstract": "Distributing computations among agents in large networks reduces\ncomputational effort in multi-agent path finding (MAPF). One distribution\nstrategy is prioritized planning (PP). In PP, we couple and prioritize\ninteracting agents to achieve a desired behavior across all agents in the\nnetwork. We characterize the interaction with a directed acyclic graph (DAG).\nThe computation time for solving MAPF problem using PP is mainly determined\nthrough the longest path in this DAG. The longest path depends on the fixed\nundirected coupling graph and the variable prioritization. The approaches from\nliterature to prioritize agents are numerous and pursue various goals. This\narticle presents an approach for prioritization in PP to reduce the longest\npath length in the coupling DAG and thus the computation time for MAPF using\nPP. We prove that this problem can be mapped to a graph-coloring problem, in\nwhich the number of colors required corresponds to the longest path length in\nthe coupling DAG. We propose a decentralized graph-coloring algorithm to\ndetermine priorities for the agents. We evaluate the approach by applying it to\nmulti-agent motion planning (MAMP) for connected and automated vehicles (CAVs)\non roads using, a variant of MAPF.",
      "tldr_zh": "这篇论文针对多智能体路径寻找 (MAPF) 中的优先级规划 (PP)，提出了一种使用图着色方法来优化代理优先级，从而减少计算时间的核心策略。通过将代理间的交互建模为有向无环图 (DAG)，作者证明了该问题可以映射为图着色问题，其中所需颜色数对应于 DAG 的最长路径长度。论文开发了一种去中心化的图着色算法来动态确定代理优先级，并在多智能体运动规划 (MAMP) 的应用场景（如连接和自动车辆）中进行评估，展示了显著的计算效率提升。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10812v1",
      "published_date": "2025-01-18 16:22:07 UTC",
      "updated_date": "2025-01-18 16:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:51:56.114759"
    },
    {
      "arxiv_id": "2501.10809v2",
      "title": "Efficient auto-labeling of large-scale poultry datasets (ALPD) using an ensemble model with self- and active-learning approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Ramesh Bahadur Bist",
        "Lilong Chai",
        "Shawna Weimer",
        "Hannah Atungulua",
        "Chantel Pennicott",
        "Xiao Yang",
        "Sachin Subedi",
        "Chaitanya Pallerla",
        "Yang Tian",
        "Dongyi Wang"
      ],
      "abstract": "The rapid growth of artificial intelligence in poultry farming has\nhighlighted the challenge of efficiently labeling large, diverse datasets.\nManual annotation is time-consuming and costly, making it impractical for\nmodern systems that continuously generate data. This study addresses this\nchallenge by exploring semi-supervised auto-labeling methods, integrating self\nand active learning approaches to develop an efficient, label-scarce framework\nfor auto-labeling large poultry datasets (ALPD). For this study, video data\nwere collected from broilers and laying hens housed. Various machine learning\nmodels, including zero-shot models and supervised models, were utilized for\nbroilers and hens detection. The results showed that YOLOv8s-World and YOLOv9s\nperformed better when compared performance metrics for broiler and hen\ndetection under supervised learning, while among the semi-supervised model,\nYOLOv8s-ALPD achieved the highest precision (96.1%) and recall (99%) with an\nRMSE of 1.87. The hybrid YOLO-World model, incorporating the optimal YOLOv8s\nbackbone with zero-shot models, demonstrated the highest overall performance.\nIt achieved a precision of 99.2%, recall of 99.4%, and an F1 score of 98.7% for\ndetection. In addition, the semi-supervised models with minimal human\nintervention (active learning) reduced annotation time by over 80% compared to\nfull manual labeling. Moreover, integrating zero-shot models with the best\nmodels enhanced broiler and hen detection, achieving comparable results to\nsupervised models while significantly increasing speed. In conclusion,\nintegrating semi-supervised auto-labeling and zero-shot models significantly\nimproves detection accuracy. It reduces manual annotation efforts, offering a\npromising solution to optimize AI-driven systems in poultry farming, advancing\nprecision livestock management, and promoting more sustainable practices.",
      "tldr_zh": "本文提出了一种高效的自动标注框架 ALPD，用于大规模家禽数据集，通过整合 ensemble model、self-learning 和 active-learning 方法，解决手动标注的耗时问题。研究利用 YOLOv8s-World 和 YOLOv9s 等模型进行家禽检测，在半监督学习中，YOLOv8s-ALPD 取得了 96.1% 精度、99% 召回率和 RMSE 1.87 的最佳性能。混合模型 YOLO-World 进一步提升了整体效果，达到 99.2% 精度、99.4% 召回率和 98.7% F1 分数，同时将标注时间减少 80%。这种方法整合 zero-shot models 显著提高了检测准确性和速度，为家禽养殖的 AI 驱动系统优化提供了可行方案，促进精准畜牧管理和可持续发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10809v2",
      "published_date": "2025-01-18 16:20:04 UTC",
      "updated_date": "2025-02-22 00:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:52:09.201292"
    },
    {
      "arxiv_id": "2501.10799v1",
      "title": "Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback",
      "title_zh": "Step-KTO：通过逐步二元反馈优化数学推理",
      "authors": [
        "Yen-Ting Lin",
        "Di Jin",
        "Tengyu Xu",
        "Tianhao Wu",
        "Sainbayar Sukhbaatar",
        "Chen Zhu",
        "Yun He",
        "Yun-Nung Chen",
        "Jason Weston",
        "Yuandong Tian",
        "Arash Rahnama",
        "Sinong Wang",
        "Hao Ma",
        "Han Fang"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated remarkable success in\nmathematical reasoning. Despite progress in methods like chain-of-thought\nprompting and self-consistency sampling, these advances often focus on final\ncorrectness without ensuring that the underlying reasoning process is coherent\nand reliable. This paper introduces Step-KTO, a training framework that\ncombines process-level and outcome-level binary feedback to guide LLMs toward\nmore trustworthy reasoning trajectories. By providing binary evaluations for\nboth the intermediate reasoning steps and the final answer, Step-KTO encourages\nthe model to adhere to logical progressions rather than relying on superficial\nshortcuts. Our experiments on challenging mathematical benchmarks show that\nStep-KTO significantly improves both final answer accuracy and the quality of\nintermediate reasoning steps. For example, on the MATH-500 dataset, Step-KTO\nachieves a notable improvement in Pass@1 accuracy over strong baselines. These\nresults highlight the promise of integrating stepwise process feedback into LLM\ntraining, paving the way toward more interpretable and dependable reasoning\ncapabilities.",
      "tldr_zh": "这篇论文提出了 Step-KTO 框架，用于优化大型语言模型 (LLMs) 的数学推理问题。Step-KTO 通过结合过程级和结果级的二元反馈 (binary feedback)，为中间推理步骤和最终答案提供二进制评估，鼓励模型遵循逻辑进展而非依赖表面捷径。相比传统方法如 chain-of-thought prompting 和 self-consistency sampling，该框架显著提升了推理的连贯性和可靠性。在 MATH-500 数据集等基准测试中，Step-KTO 实现了 Pass@1 准确率的显著改善，并提高了整体推理质量。这些结果展示了将 stepwise process feedback 整合到 LLM 训练中的潜力，为更可解释和可靠的数学推理能力铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10799v1",
      "published_date": "2025-01-18 15:38:03 UTC",
      "updated_date": "2025-01-18 15:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:52:20.708166"
    },
    {
      "arxiv_id": "2501.10782v1",
      "title": "ML-SceGen: A Multi-level Scenario Generation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Xiao",
        "Yangyang Sun",
        "Yicheng Lin"
      ],
      "abstract": "Current scientific research witnesses various attempts at applying Large\nLanguage Models for scenario generation but is inclined only to comprehensive\nor dangerous scenarios. In this paper, we seek to build a three-stage framework\nthat not only lets users regain controllability over the generated scenarios\nbut also generates comprehensive scenarios containing danger factors in\nuncontrolled intersection settings. In the first stage, LLM agents will\ncontribute to translating the key components of the description of the expected\nscenarios into Functional Scenarios. For the second stage, we use Answer Set\nProgramming (ASP) solver Clingo to help us generate comprehensive logical\ntraffic within intersections. During the last stage, we use LLM to update\nrelevant parameters to increase the critical level of the concrete scenario.",
      "tldr_zh": "本文提出ML-SceGen框架，一个多级场景生成系统，旨在提升用户对生成场景的可控性，同时生成包含危险因素的全面场景，特别是在不受控制的交叉路口设置。框架分为三阶段：第一阶段使用Large Language Models (LLMs)代理将预期场景的关键组件转化为Functional Scenarios；第二阶段采用Answer Set Programming (ASP)求解器Clingo生成交叉路口内的逻辑交通；第三阶段通过LLM更新相关参数，以提高具体场景的临界水平。该框架有助于解决当前LLMs在场景生成中的局限性，提供更可靠和全面的输出。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.10782v1",
      "published_date": "2025-01-18 14:43:40 UTC",
      "updated_date": "2025-01-18 14:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:52:31.886371"
    },
    {
      "arxiv_id": "2501.10781v1",
      "title": "Simultaneous Computation with Multiple Prioritizations in Multi-Agent Motion Planning",
      "title_zh": "多智能体运动规划中的多优先级同时计算",
      "authors": [
        "Patrick Scheffe",
        "Julius Kahle",
        "Bassam Alrifaee"
      ],
      "abstract": "Multi-agent path finding (MAPF) in large networks is computationally\nchallenging. An approach for MAPF is prioritized planning (PP), in which agents\nplan sequentially according to their priority. Albeit a computationally\nefficient approach for MAPF, the solution quality strongly depends on the\nprioritization. Most prioritizations rely either on heuristics, which do not\ngeneralize well, or iterate to find adequate priorities, which costs\ncomputational effort. In this work, we show how agents can compute with\nmultiple prioritizations simultaneously. Our approach is general as it does not\nrely on domain-specific knowledge. The context of this work is multi-agent\nmotion planning (MAMP) with a receding horizon subject to computation time\nconstraints. MAMP considers the system dynamics in more detail compared to\nMAPF. In numerical experiments on MAMP, we demonstrate that our approach to\nprioritization comes close to optimal prioritization and outperforms\nstate-of-the-art methods with only a minor increase in computation time. We\nshow real-time capability in an experiment on a road network with ten vehicles\nin our Cyber-Physical Mobility Lab.",
      "tldr_zh": "这篇论文解决了多智能体路径寻找(MAPF)中的计算挑战，提出了一种同时计算多个优先级的规划方法(prioritized planning, PP)，该方法不依赖特定领域知识，能在多智能体运动规划(MAMP)中考虑系统动态和计算时间约束。相比传统启发式或迭代方法，该方法显著提高了解决方案质量，接近最优优先级，仅需微增计算时间。实验结果显示，在数值测试和实际道路网络（如十辆车的Cyber-Physical Mobility Lab）中，它优于现有技术，并实现了实时性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10781v1",
      "published_date": "2025-01-18 14:35:32 UTC",
      "updated_date": "2025-01-18 14:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:52:43.494073"
    },
    {
      "arxiv_id": "2501.16348v1",
      "title": "An Integrated Approach to AI-Generated Content in e-health",
      "title_zh": "翻译失败",
      "authors": [
        "Tasnim Ahmed",
        "Salimur Choudhury"
      ],
      "abstract": "Artificial Intelligence-Generated Content, a subset of Generative Artificial\nIntelligence, holds significant potential for advancing the e-health sector by\ngenerating diverse forms of data. In this paper, we propose an end-to-end\nclass-conditioned framework that addresses the challenge of data scarcity in\nhealth applications by generating synthetic medical images and text data,\nevaluating on practical applications such as retinopathy detection, skin\ninfections and mental health assessments. Our framework integrates Diffusion\nand Large Language Models (LLMs) to generate data that closely match real-world\npatterns, which is essential for improving downstream task performance and\nmodel robustness in e-health applications. Experimental results demonstrate\nthat the synthetic images produced by the proposed diffusion model outperform\ntraditional GAN architectures. Similarly, in the text modality, data generated\nby uncensored LLM achieves significantly better alignment with real-world data\nthan censored models in replicating the authentic tone.",
      "tldr_zh": "这篇论文提出了一种端到端的类条件框架，用于生成合成医疗图像和文本数据，以解决 e-health 领域的数据稀缺问题。该框架整合了 Diffusion 模型和 Large Language Models (LLMs)，生成与真实世界模式高度匹配的数据，并应用于视网膜病变检测、皮肤感染和心理健康评估等实际场景。实验结果表明，该框架生成的合成图像在性能上优于传统 GAN 架构，而未审查的 LLMs 生成的文本在真实性方面显著优于审查模型，从而提升了下游任务的性能和模型的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for presentation at 2025 IEEE International Conference on\n  Communications (IEEE ICC25)",
      "pdf_url": "http://arxiv.org/pdf/2501.16348v1",
      "published_date": "2025-01-18 14:35:29 UTC",
      "updated_date": "2025-01-18 14:35:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:52:55.933213"
    },
    {
      "arxiv_id": "2501.10775v1",
      "title": "MedFILIP: Medical Fine-grained Language-Image Pre-training",
      "title_zh": "MedFILIP：医疗细粒度语言-图像预训练",
      "authors": [
        "Xinjie Liang",
        "Xiangyu Li",
        "Fanding Li",
        "Jie Jiang",
        "Qing Dong",
        "Wei Wang",
        "Kuanquan Wang",
        "Suyu Dong",
        "Gongning Luo",
        "Shuo Li"
      ],
      "abstract": "Medical vision-language pretraining (VLP) that leverages naturally-paired\nmedical image-report data is crucial for medical image analysis. However,\nexisting methods struggle to accurately characterize associations between\nimages and diseases, leading to inaccurate or incomplete diagnostic results. In\nthis work, we propose MedFILIP, a fine-grained VLP model, introduces medical\nimage-specific knowledge through contrastive learning, specifically: 1) An\ninformation extractor based on a large language model is proposed to decouple\ncomprehensive disease details from reports, which excels in extracting disease\ndeals through flexible prompt engineering, thereby effectively reducing text\ncomplexity while retaining rich information at a tiny cost. 2) A knowledge\ninjector is proposed to construct relationships between categories and visual\nattributes, which help the model to make judgments based on image features, and\nfosters knowledge extrapolation to unfamiliar disease categories. 3) A semantic\nsimilarity matrix based on fine-grained annotations is proposed, providing\nsmoother, information-richer labels, thus allowing fine-grained image-text\nalignment. 4) We validate MedFILIP on numerous datasets, e.g., RSNA-Pneumonia,\nNIH ChestX-ray14, VinBigData, and COVID-19. For single-label, multi-label, and\nfine-grained classification, our model achieves state-of-the-art performance,\nthe classification accuracy has increased by a maximum of 6.69\\%. The code is\navailable in https://github.com/PerceptionComputingLab/MedFILIP.",
      "tldr_zh": "本研究提出 MedFILIP，一种细粒度的医疗视觉语言预训练(VLP)模型，通过 contrastive learning 注入医疗图像特定知识，以解决现有方法在图像-疾病关联表征上的不足。\nMedFILIP 包括三个关键组件：基于大语言模型的信息提取器（用于从报告中解耦疾病细节并减少文本复杂性）、知识注入器（构建类别与视觉属性关系，支持知识外推）和语义相似性矩阵（提供细粒度注释以实现图像-文本对齐）。\n在数据集如 RSNA-Pneumonia 和 NIH ChestX-ray14 上，MedFILIP 在单标签、多标签和细粒度分类任务中达到最先进性能，分类准确率最高提升 6.69%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures, IEEE Journal of Biomedical and Health\n  Informatics 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.10775v1",
      "published_date": "2025-01-18 14:08:33 UTC",
      "updated_date": "2025-01-18 14:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:55:10.560765"
    },
    {
      "arxiv_id": "2501.10770v1",
      "title": "Enhancing Diagnostic in 3D COVID-19 Pneumonia CT-scans through Explainable Uncertainty Bayesian Quantification",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Manuel Liscano Fierro",
        "Hector J. Hortua"
      ],
      "abstract": "Accurately classifying COVID-19 pneumonia in 3D CT scans remains a\nsignificant challenge in the field of medical image analysis. Although\ndeterministic neural networks have shown promising results in this area, they\nprovide only point estimates outputs yielding poor diagnostic in clinical\ndecision-making. In this paper, we explore the use of Bayesian neural networks\nfor classifying COVID-19 pneumonia in 3D CT scans providing uncertainties in\ntheir predictions. We compare deterministic networks and their Bayesian\ncounterpart, enhancing the decision-making accuracy under uncertainty\ninformation. Remarkably, our findings reveal that lightweight architectures\nachieve the highest accuracy of 96\\% after developing extensive hyperparameter\ntuning. Furthermore, the Bayesian counterpart of these architectures via\nMultiplied Normalizing Flow technique kept a similar performance along with\ncalibrated uncertainty estimates. Finally, we have developed a 3D-visualization\napproach to explain the neural network outcomes based on SHAP values. We\nconclude that explainability along with uncertainty quantification will offer\nbetter clinical decisions in medical image analysis, contributing to ongoing\nefforts for improving the diagnosis and treatment of COVID-19 pneumonia.",
      "tldr_zh": "本研究探讨了使用Bayesian神经网络来提升3D CT扫描中COVID-19肺炎的分类准确性，通过提供不确定性预测来改善临床决策。相比于确定性神经网络，该方法在不确定性信息下显著增强了决策精度，且轻量级架构经超参数优化后达到96%的准确率，同时Bayesian版本利用Multiplied Normalizing Flow技术维持了类似性能并输出校准的不确定性估计。研究还开发了基于SHAP值的3D可视化方法，以解释神经网络结果，最终强调解释性和不确定性量化能促进COVID-19肺炎的诊断和治疗。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "61 pages, 16 figures. Comments are welcome",
      "pdf_url": "http://arxiv.org/pdf/2501.10770v1",
      "published_date": "2025-01-18 13:54:33 UTC",
      "updated_date": "2025-01-18 13:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:53:20.006888"
    },
    {
      "arxiv_id": "2501.10768v1",
      "title": "MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science",
      "title_zh": "MAPS：推进专家级物理科学中的多模态推理",
      "authors": [
        "Erle Zhu",
        "Yadi Liu",
        "Zhe Zhang",
        "Xujun Li",
        "Jin Zhou",
        "Xinjie Yu",
        "Minlie Huang",
        "Hongning Wang"
      ],
      "abstract": "Pre-trained on extensive text and image corpora, current Multi-Modal Large\nLanguage Models (MLLM) have shown strong capabilities in general visual\nreasoning tasks. However, their performance is still lacking in physical\ndomains that require understanding diagrams with complex physical structures\nand quantitative analysis based on multi-modal information. To address this, we\ndevelop a new framework, named Multi-Modal Scientific Reasoning with Physics\nPerception and Simulation (MAPS) based on an MLLM. MAPS decomposes expert-level\nmulti-modal reasoning task into physical diagram understanding via a Physical\nPerception Model (PPM) and reasoning with physical knowledge via a simulator.\nThe PPM module is obtained by fine-tuning a visual language model using\ncarefully designed synthetic data with paired physical diagrams and\ncorresponding simulation language descriptions. At the inference stage, MAPS\nintegrates the simulation language description of the input diagram provided by\nPPM and results obtained through a Chain-of-Simulation process with MLLM to\nderive the underlying rationale and the final answer. Validated using our\ncollected college-level circuit analysis problems, MAPS significantly improves\nreasoning accuracy of MLLM and outperforms all existing models. The results\nconfirm MAPS offers a promising direction for enhancing multi-modal scientific\nreasoning ability of MLLMs. We will release our code, model and dataset used\nfor our experiments upon publishing of this paper.",
      "tldr_zh": "本文提出 MAPS 框架，用于提升 Multi-Modal Large Language Models (MLLM) 在专家级物理科学领域的多模态推理能力，特别是处理复杂物理结构图表和定量分析。MAPS 将任务分解为通过 Physical Perception Model (PPM) 理解物理图表，以及利用模拟器进行物理知识推理，其中 PPM 通过微调视觉语言模型和合成数据来生成模拟语言描述。在推理阶段，MAPS 整合 PPM 的输出、Chain-of-Simulation 过程和 MLLM，以得出推理依据和最终答案。实验在收集的大学级电路分析问题上显示，MAPS 显著提高了 MLLM 的准确率，并超越所有现有模型，为增强多模态科学推理能力提供了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10768v1",
      "published_date": "2025-01-18 13:54:00 UTC",
      "updated_date": "2025-01-18 13:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:55:24.562584"
    },
    {
      "arxiv_id": "2501.10736v2",
      "title": "Semi-supervised Semantic Segmentation for Remote Sensing Images via Multi-scale Uncertainty Consistency and Cross-Teacher-Student Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Shanwen Wang",
        "Xin Sun",
        "Changrui Chen",
        "Danfeng Hong",
        "Jungong Han"
      ],
      "abstract": "Semi-supervised learning offers an appealing solution for remote sensing (RS)\nimage segmentation to relieve the burden of labor-intensive pixel-level\nlabeling. However, RS images pose unique challenges, including rich multi-scale\nfeatures and high inter-class similarity. To address these problems, this paper\nproposes a novel semi-supervised Multi-Scale Uncertainty and\nCross-Teacher-Student Attention (MUCA) model for RS image semantic segmentation\ntasks. Specifically, MUCA constrains the consistency among feature maps at\ndifferent layers of the network by introducing a multi-scale uncertainty\nconsistency regularization. It improves the multi-scale learning capability of\nsemi-supervised algorithms on unlabeled data. Additionally, MUCA utilizes a\nCross-Teacher-Student attention mechanism to guide the student network, guiding\nthe student network to construct more discriminative feature representations\nthrough complementary features from the teacher network. This design\neffectively integrates weak and strong augmentations (WA and SA) to further\nboost segmentation performance. To verify the effectiveness of our model, we\nconduct extensive experiments on ISPRS-Potsdam and LoveDA datasets. The\nexperimental results show the superiority of our method over state-of-the-art\nsemi-supervised methods. Notably, our model excels in distinguishing highly\nsimilar objects, showcasing its potential for advancing semi-supervised RS\nimage segmentation tasks.",
      "tldr_zh": "这篇论文提出了一种新型半监督语义分割模型 MUCA，用于遥感图像处理，以缓解手动像素级标注的负担。MUCA 通过多尺度不确定性一致性正则化约束网络不同层特征图的一致性，提升无标签数据上的多尺度学习能力；同时，引入 Cross-Teacher-Student attention 机制，让学生网络从教师网络获取互补特征，并整合弱增强和强增强（WA and SA）来优化分割性能。在 ISPRS-Potsdam 和 LoveDA 数据集上的实验显示，该方法优于现有半监督技术，尤其擅长区分高类间相似性的物体。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10736v2",
      "published_date": "2025-01-18 11:57:20 UTC",
      "updated_date": "2025-03-13 14:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:55:44.817822"
    },
    {
      "arxiv_id": "2501.10734v1",
      "title": "GEC-RAG: Improving Generative Error Correction via Retrieval-Augmented Generation for Automatic Speech Recognition Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Amin Robatian",
        "Mohammad Hajipour",
        "Mohammad Reza Peyghan",
        "Fatemeh Rajabi",
        "Sajjad Amini",
        "Shahrokh Ghaemmaghami",
        "Iman Gholampour"
      ],
      "abstract": "Automatic Speech Recognition (ASR) systems have demonstrated remarkable\nperformance across various applications. However, limited data and the unique\nlanguage features of specific domains, such as low-resource languages,\nsignificantly degrade their performance and lead to higher Word Error Rates\n(WER). In this study, we propose Generative Error Correction via\nRetrieval-Augmented Generation (GEC-RAG), a novel approach designed to improve\nASR accuracy for low-resource domains, like Persian. Our approach treats the\nASR system as a black-box, a common practice in cloud-based services, and\nproposes a Retrieval-Augmented Generation (RAG) approach within the In-Context\nLearning (ICL) scheme to enhance the quality of ASR predictions. By\nconstructing a knowledge base that pairs ASR predictions (1-best and 5-best\nhypotheses) with their corresponding ground truths, GEC-RAG retrieves lexically\nsimilar examples to the ASR transcription using the Term Frequency-Inverse\nDocument Frequency (TF-IDF) measure. This process provides relevant error\npatterns of the system alongside the ASR transcription to the Generative Large\nLanguage Model (LLM), enabling targeted corrections. Our results demonstrate\nthat this strategy significantly reduces WER in Persian and highlights a\npotential for domain adaptation and low-resource scenarios. This research\nunderscores the effectiveness of using RAG in enhancing ASR systems without\nrequiring direct model modification or fine-tuning, making it adaptable to any\ndomain by simply updating the transcription knowledge base with domain-specific\ndata.",
      "tldr_zh": "该研究提出GEC-RAG，一种通过Retrieval-Augmented Generation (RAG)改进自动语音识别（ASR）系统错误修正的方法，针对低资源语言（如波斯语）的高Word Error Rates (WER)问题。GEC-RAG将ASR视为黑盒系统，使用In-Context Learning (ICL)构建知识库，将ASR预测（1-best和5-best假设）与真实标签配对，通过Term Frequency-Inverse Document Frequency (TF-IDF)检索词汇相似的错误模式，并提供给Generative Large Language Model (LLM)进行针对性修正。实验结果显示，该方法显著降低了WER，并展示了无需模型微调即可适应不同领域的潜力，为低资源场景的ASR优化提供了有效策略。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.10734v1",
      "published_date": "2025-01-18 11:53:22 UTC",
      "updated_date": "2025-01-18 11:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:55:49.617012"
    },
    {
      "arxiv_id": "2501.10727v1",
      "title": "In the Picture: Medical Imaging Datasets, Artifacts, and their Living Review",
      "title_zh": "翻译失败",
      "authors": [
        "Amelia Jiménez-Sánchez",
        "Natalia-Rozalia Avlona",
        "Sarah de Boer",
        "Víctor M. Campello",
        "Aasa Feragen",
        "Enzo Ferrante",
        "Melanie Ganz",
        "Judy Wawira Gichoya",
        "Camila González",
        "Steff Groefsema",
        "Alessa Hering",
        "Adam Hulman",
        "Leo Joskowicz",
        "Dovile Juodelyte",
        "Melih Kandemir",
        "Thijs Kooi",
        "Jorge del Pozo Lérida",
        "Livie Yumeng Li",
        "Andre Pacheco",
        "Tim Rädsch",
        "Mauricio Reyes",
        "Théo Sourget",
        "Bram van Ginneken",
        "David Wen",
        "Nina Weng",
        "Jack Junchi Xu",
        "Hubert Dariusz Zając",
        "Maria A. Zuluaga",
        "Veronika Cheplygina"
      ],
      "abstract": "Datasets play a critical role in medical imaging research, yet issues such as\nlabel quality, shortcuts, and metadata are often overlooked. This lack of\nattention may harm the generalizability of algorithms and, consequently,\nnegatively impact patient outcomes. While existing medical imaging literature\nreviews mostly focus on machine learning (ML) methods, with only a few focusing\non datasets for specific applications, these reviews remain static -- they are\npublished once and not updated thereafter. This fails to account for emerging\nevidence, such as biases, shortcuts, and additional annotations that other\nresearchers may contribute after the dataset is published. We refer to these\nnewly discovered findings of datasets as research artifacts. To address this\ngap, we propose a living review that continuously tracks public datasets and\ntheir associated research artifacts across multiple medical imaging\napplications. Our approach includes a framework for the living review to\nmonitor data documentation artifacts, and an SQL database to visualize the\ncitation relationships between research artifact and dataset. Lastly, we\ndiscuss key considerations for creating medical imaging datasets, review best\npractices for data annotation, discuss the significance of shortcuts and\ndemographic diversity, and emphasize the importance of managing datasets\nthroughout their entire lifecycle. Our demo is publicly available at\nhttp://130.226.140.142.",
      "tldr_zh": "这篇论文指出了医疗成像数据集中的常见问题，如标签质量、shortcuts和元数据缺失，这些可能影响算法的泛化性和患者结果，并批评现有文献评论的静态性。作者提出一个living review框架，用于持续跟踪公共数据集及其关联的research artifacts，包括监控数据文档artifacts和一个SQL database来可视化引用关系。主要贡献包括讨论创建数据集的最佳实践、shortcuts的影响、人口多样性的重要性，以及管理数据集整个生命周期的策略，并提供公开演示网站。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Manuscript under review",
      "pdf_url": "http://arxiv.org/pdf/2501.10727v1",
      "published_date": "2025-01-18 11:03:59 UTC",
      "updated_date": "2025-01-18 11:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:54:08.692862"
    },
    {
      "arxiv_id": "2501.16347v2",
      "title": "Fast and Accurate Identification of Hardware Trojan Locations in Gate-Level Netlist using Nearest Neighbour Approach integrated with Machine Learning Technique",
      "title_zh": "翻译失败",
      "authors": [
        "Anindita Chattopadhyay",
        "Siddharth Bisariya",
        "Vijay Kumar Sutrakar"
      ],
      "abstract": "In the evolving landscape of integrated circuit design, detecting Hardware\nTrojans (HTs) within a multi entity based design cycle presents significant\nchallenges. This research proposes an innovative machine learning-based\nmethodology for identifying malicious logic gates in gate-level netlists. By\nfocusing on path retrace algorithms. The methodology is validated across three\ndistinct cases, each employing different machine learning models to classify\nHTs. Case I utilizes a decision tree algorithm for node-to-node comparisons,\nsignificantly improving detection accuracy through the integration of Principal\nComponent Analysis (PCA). Case II introduces a graph-to-graph classification\nusing a Graph Neural Network (GNN) model, enabling the differentiation between\nnormal and Trojan-infected circuit designs. Case III applies GNN-based node\nclassification to identify individual compromised nodes and its location.\nAdditionally, nearest neighbor (NN) method has been combined with GNN\ngraph-to-graph in Case II and GNN node-to-node in Case III. Despite the\npotential of GNN model graph-to-graph classification, NN approach demonstrated\nsuperior performance, with the first nearest neighbor (1st NN) achieving 73.2%\naccuracy and the second nearest neighbor (2nd NN) method reaching 97.7%. In\ncomparison, the GNN model achieved an accuracy of 62.8%. Similarly, GNN model\nnode-to-node classification, NN approach demonstrated superior performance,\nwith the 1st NN achieving 93% accuracy and the 2nd NN method reaching 97.7%. In\ncomparison, the GNN model achieved an accuracy of 79.8%. However, higher and\nhigher NN will lead to large code coverage for the identification of HTs.",
      "tldr_zh": "本研究提出了一种快速准确的 Hardware Trojans (HTs) 定位方法，针对门级网表中的恶意逻辑门，使用 Nearest Neighbour (NN) 方法整合机器学习技术，包括决策树、Principal Component Analysis (PCA) 和 Graph Neural Network (GNN)。该方法通过三个案例验证：Case I 利用决策树和 PCA 进行节点比较以提高检测准确率；Case II 采用 GNN 进行图到图分类并结合 NN；Case III 使用 GNN 进行节点分类并整合 NN。实验结果显示，NN 方法在 Case II 中实现最高 97.7% 准确率（远超 GNN 的 62.8%），而在 Case III 中达到 97.7%（优于 GNN 的 79.8%），但过高的 NN 会导致代码覆盖率增加，从而为 HTs 检测提供更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16347v2",
      "published_date": "2025-01-18 10:15:16 UTC",
      "updated_date": "2025-04-27 18:12:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:56:16.181145"
    },
    {
      "arxiv_id": "2502.10396v1",
      "title": "DASKT: A Dynamic Affect Simulation Method for Knowledge Tracing",
      "title_zh": "DASKT：一种动态情感模拟知识追踪方法",
      "authors": [
        "Xinjie Sun",
        "Kai Zhang",
        "Qi Liu",
        "Shuanghong Shen",
        "Fei Wang",
        "Yuxiang Guo",
        "Enhong Chen"
      ],
      "abstract": "Knowledge Tracing (KT) predicts future performance by modeling students'\nhistorical interactions, and understanding students' affective states can\nenhance the effectiveness of KT, thereby improving the quality of education.\nAlthough traditional KT values students' cognition and learning behaviors,\nefficient evaluation of students' affective states and their application in KT\nstill require further exploration due to the non-affect-oriented nature of the\ndata and budget constraints. To address this issue, we propose a\ncomputation-driven approach, Dynamic Affect Simulation Knowledge Tracing\n(DASKT), to explore the impact of various student affective states (such as\nfrustration, concentration, boredom, and confusion) on their knowledge states.\nIn this model, we first extract affective factors from students'\nnon-affect-oriented behavioral data, then use clustering and spatiotemporal\nsequence modeling to accurately simulate students' dynamic affect changes when\ndealing with different problems. Subsequently, {\\color{blue}we incorporate\naffect with time-series analysis to improve the model's ability to infer\nknowledge states over time and space.} Extensive experimental results on two\npublic real-world educational datasets show that DASKT can achieve more\nreasonable knowledge states under the effect of students' affective states.\nMoreover, DASKT outperforms the most advanced KT methods in predicting student\nperformance. Our research highlights a promising avenue for future KT studies,\nfocusing on achieving high interpretability and accuracy.",
      "tldr_zh": "本研究提出DASKT，一种动态感情模拟知识追踪(KT)方法，旨在通过模拟学生的感情状态（如沮丧、专注、无聊和困惑）来提升KT模型的预测准确性和教育质量。该方法从学生的非感情导向行为数据中提取感情因素，并利用聚类和时空序列建模来模拟动态感情变化，随后结合时间序列分析来改进知识状态的推断。实验结果显示，在两个公开教育数据集上，DASKT在考虑学生感情影响下实现了更合理的知识状态预测，并超过了最先进KT方法的性能，为未来高可解释性和准确性的KT研究提供了新方向。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.10396v1",
      "published_date": "2025-01-18 10:02:10 UTC",
      "updated_date": "2025-01-18 10:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:56:27.086271"
    },
    {
      "arxiv_id": "2501.10711v3",
      "title": "How Should We Build A Benchmark? Revisiting 274 Code-Related Benchmarks For LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jialun Cao",
        "Yuk-Kit Chan",
        "Zixuan Ling",
        "Wenxuan Wang",
        "Shuqing Li",
        "Mingwei Liu",
        "Ruixi Qiao",
        "Yuting Han",
        "Chaozheng Wang",
        "Boxi Yu",
        "Pinjia He",
        "Shuai Wang",
        "Zibin Zheng",
        "Michael R. Lyu",
        "Shing-Chi Cheung"
      ],
      "abstract": "Various benchmarks have been proposed to assess the performance of large\nlanguage models (LLMs) in different coding scenarios. We refer to them as\ncode-related benchmarks. However, there are no systematic guidelines by which\nsuch a benchmark should be developed to ensure its quality, reliability, and\nreproducibility. We propose How2Bench, which is comprised of a 55-criteria\nchecklist as a set of guidelines to govern the development of code-related\nbenchmarks comprehensively. Using HOW2BENCH, we profiled 274 benchmarks\nreleased within the past decade and found concerning issues. Nearly 70% of the\nbenchmarks did not take measures for data quality assurance; over 10% did not\neven open source or only partially open source. Many highly cited benchmarks\nhave loopholes, including duplicated samples, incorrect reference\ncodes/tests/prompts, and unremoved sensitive/confidential information. Finally,\nwe conducted a human study involving 49 participants, which revealed\nsignificant gaps in awareness of the importance of data quality,\nreproducibility, and transparency.",
      "tldr_zh": "本研究审视了274个代码相关基准（benchmarks），评估大型语言模型（LLMs）在编码任务中的性能，并提出了How2Bench框架，包括一个55项标准检查列表，用于指导基准开发的质量、可靠性和可重复性。分析发现，近70%的基准缺乏数据质量保障措施，超过10%未完全开源，许多高引用基准存在问题，如重复样本、错误参考代码/测试/提示以及未移除的敏感信息。通过一项涉及49名参与者的研究，论文揭示了人们对数据质量、可重复性和透明度重要性的认识存在显著差距。这些发现为未来基准设计提供了关键指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "42 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.10711v3",
      "published_date": "2025-01-18 09:51:57 UTC",
      "updated_date": "2025-02-17 13:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:56:38.726457"
    },
    {
      "arxiv_id": "2501.10709v1",
      "title": "Revisiting Ensemble Methods for Stock Trading and Crypto Trading Tasks at ACM ICAIF FinRL Contest 2023-2024",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaus Holzer",
        "Keyi Wang",
        "Kairong Xiao",
        "Xiao-Yang Liu Yanglet"
      ],
      "abstract": "Reinforcement learning has demonstrated great potential for performing\nfinancial tasks. However, it faces two major challenges: policy instability and\nsampling bottlenecks. In this paper, we revisit ensemble methods with massively\nparallel simulations on graphics processing units (GPUs), significantly\nenhancing the computational efficiency and robustness of trained models in\nvolatile financial markets. Our approach leverages the parallel processing\ncapability of GPUs to significantly improve the sampling speed for training\nensemble models. The ensemble models combine the strengths of component agents\nto improve the robustness of financial decision-making strategies. We conduct\nexperiments in both stock and cryptocurrency trading tasks to evaluate the\neffectiveness of our approach. Massively parallel simulation on a single GPU\nimproves the sampling speed by up to $1,746\\times$ using $2,048$ parallel\nenvironments compared to a single environment. The ensemble models have high\ncumulative returns and outperform some individual agents, reducing maximum\ndrawdown by up to $4.17\\%$ and improving the Sharpe ratio by up to $0.21$.\n  This paper describes trading tasks at ACM ICAIF FinRL Contests in 2023 and\n2024.",
      "tldr_zh": "本文重新审视 Ensemble Methods 在股票和加密货币交易任务中的应用，利用 GPU 的大规模并行模拟来解决强化学习的政策不稳定性和采样瓶颈问题。通过 2048 个并行环境，采样速度比单一环境提升高达 1,746 倍，集成模型结合多个代理的优点，提升金融决策策略的鲁棒性。实验结果显示，该方法在 ACM ICAIF FinRL 比赛 2023-2024 的任务中实现更高累积回报，减少最大回撤高达 4.17% 并提高 Sharpe ratio 至多 0.21。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10709v1",
      "published_date": "2025-01-18 09:36:14 UTC",
      "updated_date": "2025-01-18 09:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:56:51.931641"
    },
    {
      "arxiv_id": "2501.10696v1",
      "title": "Algorithmic Derivation of Human Spatial Navigation Indices From Eye Movement Data",
      "title_zh": "从眼动数据中算法",
      "authors": [
        "Sobhan Teymouri",
        "Fatemeh Alizadehziri",
        "Mobina Zibandehpoor",
        "Mehdi Delrobaei"
      ],
      "abstract": "Spatial navigation is a complex cognitive function involving sensory inputs,\nsuch as visual, auditory, and proprioceptive information, to understand and\nmove within space. This ability allows humans to create mental maps, navigate\nthrough environments, and process directional cues, crucial for exploring new\nplaces and finding one's way in unfamiliar surroundings. This study takes an\nalgorithmic approach to extract indices relevant to human spatial navigation\nusing eye movement data. Leveraging electrooculography signals, we analyzed\nstatistical features and applied feature engineering techniques to study eye\nmovements during navigation tasks. The proposed work combines signal processing\nand machine learning approaches to develop indices for navigation and\norientation, spatial anxiety, landmark recognition, path survey, and path\nroute. The analysis yielded five subscore indices with notable accuracy. Among\nthese, the navigation and orientation subscore achieved an R2 score of 0.72,\nwhile the landmark recognition subscore attained an R2 score of 0.50.\nAdditionally, statistical features highly correlated with eye movement metrics,\nincluding blinks, saccades, and fixations, were identified. The findings of\nthis study can lead to more cognitive assessments and enable early detection of\nspatial navigation impairments, particularly among individuals at risk of\ncognitive decline.",
      "tldr_zh": "这篇论文提出了一种算法方法，从眼动数据中提取人类空间导航指标，利用electrooculography信号进行统计特征分析和特征工程，并结合信号处理和machine learning技术，开发了五个子分数指标，包括导航和方向、空间焦虑、地标识别、路径调查和路径路线。研究结果显示，导航和方向子分数达到R2 score of 0.72，而地标识别子分数为0.50，并识别了与眼动指标如saccades、fixations和blinks高度相关的统计特征。这些发现有助于提升认知评估的准确性，并实现对空间导航障碍的早期检测，特别是针对认知衰退风险人群。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "The dataset is available in the following work: Mobina Zibandehpoor,\n  Fatemeh Alizadehziri, Arash Abbasi Larki, Sobhan Teymouri, and Mehdi\n  Delrobaei. Electrooculography Dataset for Objective Spatial Navigation\n  Assessment in Healthy Participants. arXiv preprint arXiv:2411.06811, 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.10696v1",
      "published_date": "2025-01-18 08:26:33 UTC",
      "updated_date": "2025-01-18 08:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:57:04.052575"
    },
    {
      "arxiv_id": "2501.10693v1",
      "title": "Distributionally Robust Policy Evaluation and Learning for Continuous Treatment with Observational Data",
      "title_zh": "翻译失败",
      "authors": [
        "Cheuk Hang Leung",
        "Yiyan Huang",
        "Yijun Li",
        "Qi Wu"
      ],
      "abstract": "Using offline observational data for policy evaluation and learning allows\ndecision-makers to evaluate and learn a policy that connects characteristics\nand interventions. Most existing literature has focused on either discrete\ntreatment spaces or assumed no difference in the distributions between the\npolicy-learning and policy-deployed environments. These restrict applications\nin many real-world scenarios where distribution shifts are present with\ncontinuous treatment. To overcome these challenges, this paper focuses on\ndeveloping a distributionally robust policy under a continuous treatment\nsetting. The proposed distributionally robust estimators are established using\nthe Inverse Probability Weighting (IPW) method extended from the discrete one\nfor policy evaluation and learning under continuous treatments. Specifically,\nwe introduce a kernel function into the proposed IPW estimator to mitigate the\nexclusion of observations that can occur in the standard IPW method to\ncontinuous treatments. We then provide finite-sample analysis that guarantees\nthe convergence of the proposed distributionally robust policy evaluation and\nlearning estimators. The comprehensive experiments further verify the\neffectiveness of our approach when distribution shifts are present.",
      "tldr_zh": "本文针对使用离线观测数据进行政策评估和学习的问题，提出了一种在连续治疗设置下的分布鲁棒政策方法，以应对分布偏移的挑战。方法扩展了 Inverse Probability Weighting (IPW) 估计器，通过引入核函数来缓解标准 IPW 在连续治疗中排除观察的局限性，并确保估计器的鲁棒性。研究提供了有限样本分析，证明了分布鲁棒政策评估和学习估计器的收敛性；实验结果进一步验证了该方法在存在分布偏移时的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10693v1",
      "published_date": "2025-01-18 08:12:56 UTC",
      "updated_date": "2025-01-18 08:12:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:57:14.982841"
    },
    {
      "arxiv_id": "2501.10688v2",
      "title": "Neural Algorithmic Reasoning for Hypergraphs with Looped Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Li",
        "Yingyu Liang",
        "Jiangxuan Long",
        "Zhenmei Shi",
        "Zhao Song",
        "Zhen Zhuang"
      ],
      "abstract": "Looped Transformers have shown exceptional neural algorithmic reasoning\ncapability in simulating traditional graph algorithms, but their application to\nmore complex structures like hypergraphs remains underexplored. Hypergraphs\ngeneralize graphs by modeling higher-order relationships among multiple\nentities, enabling richer representations but introducing significant\ncomputational challenges. In this work, we extend the Loop Transformer\narchitecture's neural algorithmic reasoning capability to simulate hypergraph\nalgorithms, addressing the gap between neural networks and combinatorial\noptimization over hypergraphs. Specifically, we propose a novel degradation\nmechanism for reducing hypergraphs to graph representations, enabling the\nsimulation of graph-based algorithms, such as Dijkstra's shortest path.\nFurthermore, we introduce a hyperedge-aware encoding scheme to simulate\nhypergraph-specific algorithms, exemplified by Helly's algorithm. We establish\ntheoretical guarantees for these simulations, demonstrating the feasibility of\nprocessing high-dimensional and combinatorial data using Loop Transformers.\nThis work highlights the potential of Transformers as general-purpose\nalgorithmic solvers for structured data.",
      "tldr_zh": "本研究扩展了Looped Transformers在神经算法推理方面的能力，将其应用于超图(hypergraphs)，以模拟处理更高阶关系的组合优化问题。论文提出了一种新型降级机制(degradation mechanism)，将超图降级为图表示，从而模拟如Dijkstra's shortest path等图算法；同时，引入超边感知编码方案(hyperedge-aware encoding scheme)，用于模拟超图特定算法，如Helly's algorithm。实验和理论分析证明了Looped Transformers在处理高维和组合数据的可行性，突显其作为通用算法求解器的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10688v2",
      "published_date": "2025-01-18 07:58:45 UTC",
      "updated_date": "2025-02-02 23:41:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:57:26.604293"
    },
    {
      "arxiv_id": "2501.10677v2",
      "title": "Class-Imbalanced-Aware Adaptive Dataset Distillation for Scalable Pretrained Model on Credit Scoring",
      "title_zh": "翻译失败",
      "authors": [
        "Xia Li",
        "Hanghang Zheng",
        "Xiao Chen",
        "Hong Liu",
        "Mao Mao"
      ],
      "abstract": "The advent of artificial intelligence has significantly enhanced credit\nscoring technologies. Despite the remarkable efficacy of advanced deep learning\nmodels, mainstream adoption continues to favor tree-structured models due to\ntheir robust predictive performance on tabular data. Although pretrained models\nhave seen considerable development, their application within the financial\nrealm predominantly revolves around question-answering tasks and the use of\nsuch models for tabular-structured credit scoring datasets remains largely\nunexplored. Tabular-oriented large models, such as TabPFN, has made the\napplication of large models in credit scoring feasible, albeit can only\nprocessing with limited sample sizes. This paper provides a novel framework to\ncombine tabular-tailored dataset distillation technique with the pretrained\nmodel, empowers the scalability for TabPFN. Furthermore, though class imbalance\ndistribution is the common nature in financial datasets, its influence during\ndataset distillation has not been explored. We thus integrate the\nimbalance-aware techniques during dataset distillation, resulting in improved\nperformance in financial datasets (e.g., a 2.5% enhancement in AUC). This study\npresents a novel framework for scaling up the application of large pretrained\nmodels on financial tabular datasets and offers a comparative analysis of the\ninfluence of class imbalance on the dataset distillation process. We believe\nthis approach can broaden the applications and downstream tasks of large models\nin the financial domain.",
      "tldr_zh": "本文提出了一种考虑类别不平衡（class-imbalanced-aware）的自适应数据集蒸馏（dataset distillation）框架，用于扩展预训练模型（如TabPFN）在信用评分任务上的可扩展性，以应对金融表格数据处理中的样本限制问题。该框架将表格专用数据集蒸馏技术与预训练模型结合，并整合imbalance-aware技术，显著提升了模型在不平衡数据集上的性能，例如AUC提升2.5%。研究结果表明，此方法不仅增强了大型预训练模型在金融领域的适用性，还通过比较分析揭示了类别不平衡对数据集蒸馏过程的影响，为未来金融AI应用提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.RM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10677v2",
      "published_date": "2025-01-18 06:59:36 UTC",
      "updated_date": "2025-02-01 03:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:57:39.967017"
    },
    {
      "arxiv_id": "2501.10661v1",
      "title": "Unveiling the Mystery of Weight in Large Foundation Models: Gaussian Distribution Never Fades",
      "title_zh": "揭示大型基础模型中权重的奥秘：高斯分布永不消逝",
      "authors": [
        "Chongjie Si",
        "Jingjing Jiang",
        "Wei Shen"
      ],
      "abstract": "This paper presents a pioneering exploration of the mechanisms underlying\nlarge foundation models' (LFMs) weights, aiming to simplify AI research.\nThrough extensive observation and analysis on prevailing LFMs, we find that\nregardless of initialization strategies, their weights predominantly follow a\nGaussian distribution, with occasional sharp, inverted T-shaped, or linear\npatterns. We further discover that the weights share the i.i.d. properties of\nGaussian noise, and explore their direct relationship. We find that\ntransformation weights can be derived from Gaussian noise, and they primarily\nserve to increase the standard deviation of pre-trained weights, with their\nstandard deviation growing with layer depth. In other words, transformation\nweights broaden the acceptable deviation from the optimal weights, facilitating\nadaptation to downstream tasks. Building upon the above conclusions, we\nthoroughly discussed the nature of optimal weights, ultimately concluding that\nthey should exhibit zero-mean, symmetry, and sparsity, with the sparse values\nbeing a truncated Gaussian distribution and a few outliers. Our experiments in\nLFM adaptation and editing demonstrate the effectiveness of these insights. We\nhope these findings can provide a foundational understanding to pave the way\nfor future advancements in the LFM community.",
      "tldr_zh": "这篇论文揭示了大型基础模型 (LFMs) 权重的底层机制，发现无论初始化策略如何，权重主要遵循 Gaussian distribution，并偶尔呈现尖锐、倒 T 形或线性模式。研究通过对现有 LFMs 的观察和分析，证明权重具有 i.i.d. 的高斯噪声特性，且转换权重可从 Gaussian noise 中衍生，主要作用是增加权重的标准差，随着层深度的增长而增强，从而便于模型适应下游任务。最优权重应具备零均值、对称性和稀疏性，其中稀疏值表现为截断 Gaussian distribution 加上少量异常值；实验在 LFM 适应和编辑中验证了这些发现的有效性，为 AI 研究奠定了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Revisions ongoing",
      "pdf_url": "http://arxiv.org/pdf/2501.10661v1",
      "published_date": "2025-01-18 05:43:17 UTC",
      "updated_date": "2025-01-18 05:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:57:52.658416"
    },
    {
      "arxiv_id": "2501.13944v1",
      "title": "Fanar: An Arabic-Centric Multimodal Generative AI Platform",
      "title_zh": "Fanar：以阿拉伯语为中心的多模态生成式人工智能平台",
      "authors": [
        "Fanar Team",
        "Ummar Abbas",
        "Mohammad Shahmeer Ahmad",
        "Firoj Alam",
        "Enes Altinisik",
        "Ehsannedin Asgari",
        "Yazan Boshmaf",
        "Sabri Boughorbel",
        "Sanjay Chawla",
        "Shammur Chowdhury",
        "Fahim Dalvi",
        "Kareem Darwish",
        "Nadir Durrani",
        "Mohamed Elfeky",
        "Ahmed Elmagarmid",
        "Mohamed Eltabakh",
        "Masoomali Fatehkia",
        "Anastasios Fragkopoulos",
        "Maram Hasanain",
        "Majd Hawasly",
        "Mus'ab Husaini",
        "Soon-Gyo Jung",
        "Ji Kim Lucas",
        "Walid Magdy",
        "Safa Messaoud",
        "Abubakr Mohamed",
        "Tasnim Mohiuddin",
        "Basel Mousi",
        "Hamdy Mubarak",
        "Ahmad Musleh",
        "Zan Naeem",
        "Mourad Ouzzani",
        "Dorde Popovic",
        "Amin Sadeghi",
        "Husrev Taha Sencar",
        "Mohammed Shinoy",
        "Omar Sinan",
        "Yifan Zhang",
        "Ahmed Ali",
        "Yassine El Kheir",
        "Xiaosong Ma",
        "Chaoyi Ruan"
      ],
      "abstract": "We present Fanar, a platform for Arabic-centric multimodal generative AI\nsystems, that supports language, speech and image generation tasks. At the\nheart of Fanar are Fanar Star and Fanar Prime, two highly capable Arabic Large\nLanguage Models (LLMs) that are best in the class on well established\nbenchmarks for similar sized models. Fanar Star is a 7B (billion) parameter\nmodel that was trained from scratch on nearly 1 trillion clean and deduplicated\nArabic, English and Code tokens. Fanar Prime is a 9B parameter model\ncontinually trained on the Gemma-2 9B base model on the same 1 trillion token\nset. Both models are concurrently deployed and designed to address different\ntypes of prompts transparently routed through a custom-built orchestrator. The\nFanar platform provides many other capabilities including a customized Islamic\nRetrieval Augmented Generation (RAG) system for handling religious prompts, a\nRecency RAG for summarizing information about current or recent events that\nhave occurred after the pre-training data cut-off date. The platform provides\nadditional cognitive capabilities including in-house bilingual speech\nrecognition that supports multiple Arabic dialects, voice and image generation\nthat is fine-tuned to better reflect regional characteristics. Finally, Fanar\nprovides an attribution service that can be used to verify the authenticity of\nfact based generated content.\n  The design, development, and implementation of Fanar was entirely undertaken\nat Hamad Bin Khalifa University's Qatar Computing Research Institute (QCRI) and\nwas sponsored by Qatar's Ministry of Communications and Information Technology\nto enable sovereign AI technology development.",
      "tldr_zh": "我们介绍了 Fanar，这是一个以阿拉伯语为中心的多模态生成 AI 平台，支持语言、语音和图像生成任务。平台的核心是 Fanar Star（7B 参数模型，从零开始训练于近 1 万亿的阿拉伯语、英语和代码标记）和 Fanar Prime（9B 参数模型，在 Gemma-2 9B 基础上持续训练），两者在类似规模的基准上表现出最佳性能，并通过自定义编排器透明处理不同提示。Fanar 还提供 Islamic RAG 系统用于宗教查询、Recency RAG 用于总结最新事件、双语语音识别支持多种阿拉伯方言，以及针对区域特色的语音和图像生成功能。整体平台由卡塔尔哈马德·本·哈利法大学的 Qatar Computing Research Institute (QCRI) 开发，旨在推动主权 AI 技术发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.0; D.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13944v1",
      "published_date": "2025-01-18 05:35:32 UTC",
      "updated_date": "2025-01-18 05:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:58:04.390206"
    },
    {
      "arxiv_id": "2501.10658v1",
      "title": "LUT-DLA: Lookup Table as Efficient Extreme Low-Bit Deep Learning Accelerator",
      "title_zh": "LUT-DLA：查找表作为高效极低比特深度学习加速器",
      "authors": [
        "Guoyu Li",
        "Shengyu Ye",
        "Chunyun Chen",
        "Yang Wang",
        "Fan Yang",
        "Ting Cao",
        "Cheng Liu",
        "Mohamed M. Sabry",
        "Mao Yang"
      ],
      "abstract": "The emergence of neural network capabilities invariably leads to a\nsignificant surge in computational demands due to expanding model sizes and\nincreased computational complexity. To reduce model size and lower inference\ncosts, recent research has focused on simplifying models and designing hardware\naccelerators using low-bit quantization. However, due to numerical\nrepresentation limits, scalar quantization cannot reduce bit width lower than\n1-bit, diminishing its benefits. To break through these limitations, we\nintroduce LUT-DLA, a Look-Up Table (LUT) Deep Learning Accelerator Framework\nthat utilizes vector quantization to convert neural network models into LUTs,\nachieving extreme low-bit quantization. The LUT-DLA framework facilitates\nefficient and cost-effective hardware accelerator designs and supports the\nLUTBoost algorithm, which helps to transform various DNN models into LUT-based\nmodels via multistage training, drastically cutting both computational and\nhardware overhead. Additionally, through co-design space exploration, LUT-DLA\nassesses the impact of various model and hardware parameters to fine-tune\nhardware configurations for different application scenarios, optimizing\nperformance and efficiency. Our comprehensive experiments show that LUT-DLA\nachieves improvements in power efficiency and area efficiency with gains of\n$1.4$~$7.0\\times$ and $1.5$~$146.1\\times$, respectively, while maintaining only\na modest accuracy drop. For CNNs, accuracy decreases by $0.1\\%$~$3.1\\%$ using\nthe $L_2$ distance similarity, $0.1\\%$~$3.4\\%$ with the $L_1$ distance\nsimilarity, and $0.1\\%$~$3.8\\%$ when employing the Chebyshev distance\nsimilarity. For transformer-based models, the accuracy drop ranges from $1.4\\%$\nto $3.0\\%$.",
      "tldr_zh": "该研究提出 LUT-DLA 框架，利用 Lookup Table (LUT) 和向量量化技术，将神经网络模型转换为极低位宽的 LUT 形式，以降低模型大小和推理成本，突破传统标量量化低于 1-bit 的限制。框架结合 LUTBoost 算法，通过多阶段训练将各种 DNN 模型转化为 LUT 模型，并通过联合设计空间探索优化硬件配置以适应不同应用场景。实验结果显示，LUT-DLA 在保持 CNNs 准确率仅下降 0.1%~3.8% 和 Transformer 模型下降 1.4%~3.0% 的情况下，实现了功率效率提高 1.4~7.0 倍和面积效率提高 1.5~146.1 倍。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "12 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10658v1",
      "published_date": "2025-01-18 05:27:25 UTC",
      "updated_date": "2025-01-18 05:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:58:15.203777"
    },
    {
      "arxiv_id": "2501.16346v1",
      "title": "Self-supervised Graph Transformer with Contrastive Learning for Brain Connectivity Analysis towards Improving Autism Detection",
      "title_zh": "自监督图变换器结合对比学习用于脑连接性分析以改善自闭症检测",
      "authors": [
        "Yicheng Leng",
        "Syed Muhammad Anwar",
        "Islem Rekik",
        "Sen He",
        "Eung-Joo Lee"
      ],
      "abstract": "Functional Magnetic Resonance Imaging (fMRI) provides useful insights into\nthe brain function both during task or rest. Representing fMRI data using\ncorrelation matrices is found to be a reliable method of analyzing the inherent\nconnectivity of the brain in the resting and active states. Graph Neural\nNetworks (GNNs) have been widely used for brain network analysis due to their\ninherent explainability capability. In this work, we introduce a novel\nframework using contrastive self-supervised learning graph transformers,\nincorporating a brain network transformer encoder with random graph\nalterations. The proposed network leverages both contrastive learning and graph\nalterations to effectively train the graph transformer for autism detection.\nOur approach, tested on Autism Brain Imaging Data Exchange (ABIDE) data,\ndemonstrates superior autism detection, achieving an AUROC of 82.6 and an\naccuracy of 74%, surpassing current state-of-the-art methods.",
      "tldr_zh": "本研究提出了一种基于对比自监督学习（contrastive self-supervised learning）的图变换器框架，用于分析 fMRI 脑连接数据，以提升自闭症检测性能。该框架整合脑网络变换器编码器和随机图改变（random graph alterations），通过对比学习技术有效训练模型，捕捉脑功能连接矩阵的内在模式。在 Autism Brain Imaging Data Exchange (ABIDE) 数据集上测试，该方法实现了 AUROC 82.6% 和准确率 74%，优于现有 Graph Neural Networks (GNNs) 等基准方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16346v1",
      "published_date": "2025-01-18 05:12:40 UTC",
      "updated_date": "2025-01-18 05:12:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:58:26.578768"
    },
    {
      "arxiv_id": "2501.13943v1",
      "title": "Language Representation Favored Zero-Shot Cross-Domain Cognitive Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Liu",
        "Zihan Zhou",
        "Yuanhao Liu",
        "Jing Zhang",
        "Hong Qian"
      ],
      "abstract": "Cognitive diagnosis aims to infer students' mastery levels based on their\nhistorical response logs. However, existing cognitive diagnosis models (CDMs),\nwhich rely on ID embeddings, often have to train specific models on specific\ndomains. This limitation may hinder their directly practical application in\nvarious target domains, such as different subjects (e.g., Math, English and\nPhysics) or different education platforms (e.g., ASSISTments, Junyi Academy and\nKhan Academy). To address this issue, this paper proposes the language\nrepresentation favored zero-shot cross-domain cognitive diagnosis (LRCD).\nSpecifically, LRCD first analyzes the behavior patterns of students, exercises\nand concepts in different domains, and then describes the profiles of students,\nexercises and concepts using textual descriptions. Via recent advanced\ntext-embedding modules, these profiles can be transformed to vectors in the\nunified language space. Moreover, to address the discrepancy between the\nlanguage space and the cognitive diagnosis space, we propose language-cognitive\nmappers in LRCD to learn the mapping from the former to the latter. Then, these\nprofiles can be easily and efficiently integrated and trained with existing\nCDMs. Extensive experiments show that training LRCD on real-world datasets can\nachieve commendable zero-shot performance across different target domains, and\nin some cases, it can even achieve competitive performance with some classic\nCDMs trained on the full response data on target domains. Notably, we\nsurprisingly find that LRCD can also provide interesting insights into the\ndifferences between various subjects (such as humanities and sciences) and\nsources (such as primary and secondary education).",
      "tldr_zh": "本论文针对认知诊断（cognitive diagnosis）模型（CDMs）依赖 ID embeddings 的局限性，提出了一种基于语言表示的零样本跨领域方法，名为 LRCD（Language Representation Favored Zero-Shot Cross-Domain Cognitive Diagnosis），以实现不同领域（如科目或教育平台）的直接应用。LRCD 通过分析学生、练习和概念的行为模式，并使用文本描述将其转化为统一语言空间中的向量，同时引入 language-cognitive mappers 来桥接语言空间与认知诊断空间，从而与现有 CDMs 轻松整合。实验结果显示，LRCD 在真实数据集上实现了出色的零样本性能，在某些情况下甚至与在目标领域全数据训练的经典 CDMs 相当；此外，它还提供了有趣的洞见，如揭示不同科目（如人文和科学）和来源（如初等和中等教育）的差异。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13943v1",
      "published_date": "2025-01-18 03:35:44 UTC",
      "updated_date": "2025-01-18 03:35:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:58:39.706677"
    },
    {
      "arxiv_id": "2501.10627v1",
      "title": "AI/ML Based Detection and Categorization of Covert Communication in IPv6 Network",
      "title_zh": "基于 AI/ML 的 IPv6 网络中隐蔽通信检测和分类",
      "authors": [
        "Mohammad Wali Ur Rahman",
        "Yu-Zheng Lin",
        "Carter Weeks",
        "David Ruddell",
        "Jeff Gabriellini",
        "Bill Hayes",
        "Salim Hariri",
        "Edward V. Ziegler Jr"
      ],
      "abstract": "The flexibility and complexity of IPv6 extension headers allow attackers to\ncreate covert channels or bypass security mechanisms, leading to potential data\nbreaches or system compromises. The mature development of machine learning has\nbecome the primary detection technology option used to mitigate covert\ncommunication threats. However, the complexity of detecting covert\ncommunication, evolving injection techniques, and scarcity of data make\nbuilding machine-learning models challenging. In previous related research,\nmachine learning has shown good performance in detecting covert communications,\nbut oversimplified attack scenario assumptions cannot represent the complexity\nof modern covert technologies and make it easier for machine learning models to\ndetect covert communications. To bridge this gap, in this study, we analyzed\nthe packet structure and network traffic behavior of IPv6, used encryption\nalgorithms, and performed covert communication injection without changing\nnetwork packet behavior to get closer to real attack scenarios. In addition to\nanalyzing and injecting methods for covert communications, this study also uses\ncomprehensive machine learning techniques to train the model proposed in this\nstudy to detect threats, including traditional decision trees such as random\nforests and gradient boosting, as well as complex neural network architectures\nsuch as CNNs and LSTMs, to achieve detection accuracy of over 90\\%. This study\ndetails the methods used for dataset augmentation and the comparative\nperformance of the applied models, reinforcing insights into the adaptability\nand resilience of the machine learning application in IPv6 covert\ncommunication. In addition, we also proposed a Generative AI-assisted\ninterpretation concept based on prompt engineering as a preliminary study of\nthe role of Generative AI agents in covert communication.",
      "tldr_zh": "本文研究了 IPv6 网络中隐蔽通信的检测和分类问题，分析了数据包结构和网络流量行为，使用加密算法进行真实场景模拟的隐蔽通信注入，以克服现有机器学习模型的局限性。研究应用多种机器学习技术，包括 random forests、gradient boosting、CNNs 和 LSTMs，对增强数据集进行训练，实现了超过 90% 的检测准确率。最终，该研究强调了机器学习在复杂攻击场景中的适应性，并提出基于 Generative AI 的提示工程辅助解释概念，作为未来应用的初步探索。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10627v1",
      "published_date": "2025-01-18 02:05:37 UTC",
      "updated_date": "2025-01-18 02:05:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:58:51.859834"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 43,
  "processed_papers_count": 43,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T00:59:07.991996"
}