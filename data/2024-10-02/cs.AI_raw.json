[
  {
    "arxiv_id": "2410.02094v3",
    "title": "Tracking objects that change in appearance with phase synchrony",
    "authors": [
      "Sabine Muzellec",
      "Drew Linsley",
      "Alekh K. Ashok",
      "Ennio Mingolla",
      "Girik Malik",
      "Rufin VanRullen",
      "Thomas Serre"
    ],
    "abstract": "Objects we encounter often change appearance as we interact with them.\nChanges in illumination (shadows), object pose, or the movement of non-rigid\nobjects can drastically alter available image features. How do biological\nvisual systems track objects as they change? One plausible mechanism involves\nattentional mechanisms for reasoning about the locations of objects\nindependently of their appearances -- a capability that prominent neuroscience\ntheories have associated with computing through neural synchrony. Here, we\ndescribe a novel deep learning circuit that can learn to precisely control\nattention to features separately from their location in the world through\nneural synchrony: the complex-valued recurrent neural network (CV-RNN). Next,\nwe compare object tracking in humans, the CV-RNN, and other deep neural\nnetworks (DNNs), using FeatureTracker: a large-scale challenge that asks\nobservers to track objects as their locations and appearances change in\nprecisely controlled ways. While humans effortlessly solved FeatureTracker,\nstate-of-the-art DNNs did not. In contrast, our CV-RNN behaved similarly to\nhumans on the challenge, providing a computational proof-of-concept for the\nrole of phase synchronization as a neural substrate for tracking\nappearance-morphing objects as they move about.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02094v3",
    "published_date": "2024-10-02 23:30:05 UTC",
    "updated_date": "2025-03-02 14:04:22 UTC"
  },
  {
    "arxiv_id": "2410.02091v1",
    "title": "The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot",
    "authors": [
      "Fangchen Song",
      "Ashish Agarwal",
      "Wen Wen"
    ],
    "abstract": "Generative artificial intelligence (AI) has opened the possibility of\nautomated content production, including coding in software development, which\ncan significantly influence the participation and performance of software\ndevelopers. To explore this impact, we investigate the role of GitHub Copilot,\na generative AI pair programmer, on software development in open-source\ncommunity, where multiple developers voluntarily collaborate on software\nprojects. Using GitHub's dataset for open-source repositories and a generalized\nsynthetic control method, we find that Copilot significantly enhances\nproject-level productivity by 6.5%. Delving deeper, we dissect the key\nmechanisms driving this improvement. Our findings reveal a 5.5% increase in\nindividual productivity and a 5.4% increase in participation. However, this is\naccompanied with a 41.6% increase in integration time, potentially due to\nhigher coordination costs. Interestingly, we also observe the differential\neffects among developers. We discover that core developers achieve greater\nproject-level productivity gains from using Copilot, benefiting more in terms\nof individual productivity and participation compared to peripheral developers,\nplausibly due to their deeper familiarity with software projects. We also find\nthat the increase in project-level productivity is accompanied with no change\nin code quality. We conclude that AI pair programmers bring benefits to\ndevelopers to automate and augment their code, but human developers' knowledge\nof software projects can enhance the benefits. In summary, our research\nunderscores the role of AI pair programmers in impacting project-level\nproductivity within the open-source community and suggests potential\nimplications for the structure of open-source software projects.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02091v1",
    "published_date": "2024-10-02 23:26:10 UTC",
    "updated_date": "2024-10-02 23:26:10 UTC"
  },
  {
    "arxiv_id": "2410.02089v2",
    "title": "RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning",
    "authors": [
      "Jonas Gehring",
      "Kunhao Zheng",
      "Jade Copet",
      "Vegard Mella",
      "Quentin Carbonneaux",
      "Taco Cohen",
      "Gabriel Synnaeve"
    ],
    "abstract": "Large language models (LLMs) deployed as agents solve user-specified tasks\nover multiple steps while keeping the required manual engagement to a minimum.\nCrucially, such LLMs need to ground their generations in any feedback obtained\nto reliably achieve the desired outcomes. We propose an end-to-end\nreinforcement learning method for teaching models to leverage execution\nfeedback in the realm of code synthesis, where state-of-the-art LLMs struggle\nto improve code iteratively compared to independent sampling. We benchmark on\ncompetitive programming tasks, where we achieve new state-of-the art results\nwith both small (8B parameters) and large (70B) models while reducing the\namount of samples required by an order of magnitude. Our analysis of\ninference-time behavior demonstrates that our method produces LLMs that\neffectively leverage automatic feedback over multiple steps.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Add repair model ablation, update related work",
    "pdf_url": "http://arxiv.org/pdf/2410.02089v2",
    "published_date": "2024-10-02 23:25:17 UTC",
    "updated_date": "2025-02-18 11:39:46 UTC"
  },
  {
    "arxiv_id": "2410.02085v1",
    "title": "Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification",
    "authors": [
      "Mandeep Kaur Saggi",
      "Amandeep Singh Bhatia",
      "Mensah Isaiah",
      "Humaira Gowher",
      "Sabre Kais"
    ],
    "abstract": "Quantum Machine Learning (QML) is a red-hot field that brings novel\ndiscoveries and exciting opportunities to resolve, speed up, or refine the\nanalysis of a wide range of computational problems. In the realm of biomedical\nresearch and personalized medicine, the significance of multi-omics integration\nlies in its ability to provide a thorough and holistic comprehension of complex\nbiological systems. This technology links fundamental research to clinical\npractice. The insights gained from integrated omics data can be translated into\nclinical tools for diagnosis, prognosis, and treatment planning. The fusion of\nquantum computing and machine learning holds promise for unraveling complex\npatterns within multi-omics datasets, providing unprecedented insights into the\nmolecular landscape of lung cancer. Due to the heterogeneity, complexity, and\nhigh dimensionality of multi-omic cancer data, characterized by the vast number\nof features (such as gene expression, micro-RNA, and DNA methylation) relative\nto the limited number of lung cancer patient samples, our prime motivation for\nthis paper is the integration of multi-omic data, unique feature selection, and\ndiagnostic classification of lung subtypes: lung squamous cell carcinoma\n(LUSC-I) and lung adenocarcinoma (LUAD-II) using quantum machine learning. We\ndeveloped a method for finding the best differentiating features between LUAD\nand LUSC datasets, which has the potential for biomarker discovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.02085v1",
    "published_date": "2024-10-02 23:16:31 UTC",
    "updated_date": "2024-10-02 23:16:31 UTC"
  },
  {
    "arxiv_id": "2410.03772v1",
    "title": "Precision Knowledge Editing: Enhancing Safety in Large Language Models",
    "authors": [
      "Xuying Li",
      "Zhuo Li",
      "Yuji Kosuga",
      "Yasuhiro Yoshida",
      "Victor Bian"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but\nthey also pose risks related to the generation of toxic or harmful content.\nThis work introduces Precision Knowledge Editing (PKE), an advanced technique\nthat builds upon existing knowledge editing methods to more effectively\nidentify and modify toxic parameter regions within LLMs. By leveraging neuron\nweight tracking and activation pathway tracing, PKE achieves finer granularity\nin toxic content management compared to previous methods like Detoxifying\nInstance Neuron Modification (DINM). Our experiments demonstrate that PKE\nsignificantly reduces the attack success rate (ASR) across various models,\nincluding Llama2-7b and Llama-3-8b-instruct, while maintaining overall model\nperformance. Additionally, we also compared the performance of some\nclosed-source models (gpt-4-0613 and Claude 3 Sonnet) in our experiments, and\nfound that models adjusted using our method far outperformed the closed-source\nmodels in terms of safety. This research contributes to the ongoing efforts to\nmake LLMs safer and more reliable for real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03772v1",
    "published_date": "2024-10-02 23:15:53 UTC",
    "updated_date": "2024-10-02 23:15:53 UTC"
  },
  {
    "arxiv_id": "2410.02077v1",
    "title": "Kolmogorov-Arnold Network Autoencoders",
    "authors": [
      "Mohammadamin Moradi",
      "Shirin Panahi",
      "Erik Bollt",
      "Ying-Cheng Lai"
    ],
    "abstract": "Deep learning models have revolutionized various domains, with Multi-Layer\nPerceptrons (MLPs) being a cornerstone for tasks like data regression and image\nclassification. However, a recent study has introduced Kolmogorov-Arnold\nNetworks (KANs) as promising alternatives to MLPs, leveraging activation\nfunctions placed on edges rather than nodes. This structural shift aligns KANs\nclosely with the Kolmogorov-Arnold representation theorem, potentially\nenhancing both model accuracy and interpretability. In this study, we explore\nthe efficacy of KANs in the context of data representation via autoencoders,\ncomparing their performance with traditional Convolutional Neural Networks\n(CNNs) on the MNIST, SVHN, and CIFAR-10 datasets. Our results demonstrate that\nKAN-based autoencoders achieve competitive performance in terms of\nreconstruction accuracy, thereby suggesting their viability as effective tools\nin data analysis tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2410.02077v1",
    "published_date": "2024-10-02 22:56:00 UTC",
    "updated_date": "2024-10-02 22:56:00 UTC"
  },
  {
    "arxiv_id": "2410.02056v2",
    "title": "Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data",
    "authors": [
      "Sreyan Ghosh",
      "Sonal Kumar",
      "Zhifeng Kong",
      "Rafael Valle",
      "Bryan Catanzaro",
      "Dinesh Manocha"
    ],
    "abstract": "We present Synthio, a novel approach for augmenting small-scale audio\nclassification datasets with synthetic data. Our goal is to improve audio\nclassification accuracy with limited labeled data. Traditional data\naugmentation techniques, which apply artificial transformations (e.g., adding\nrandom noise or masking segments), struggle to create data that captures the\ntrue diversity present in real-world audios. To address this shortcoming, we\npropose to augment the dataset with synthetic audio generated from\ntext-to-audio (T2A) diffusion models. However, synthesizing effective\naugmentations is challenging because not only should the generated data be\nacoustically consistent with the underlying small-scale dataset, but they\nshould also have sufficient compositional diversity. To overcome the first\nchallenge, we align the generations of the T2A model with the small-scale\ndataset using preference optimization. This ensures that the acoustic\ncharacteristics of the generated data remain consistent with the small-scale\ndataset. To address the second challenge, we propose a novel caption generation\ntechnique that leverages the reasoning capabilities of Large Language Models to\n(1) generate diverse and meaningful audio captions and (2) iteratively refine\ntheir quality. The generated captions are then used to prompt the aligned T2A\nmodel. We extensively evaluate Synthio on ten datasets and four simulated\nlimited-data settings. Results indicate our method consistently outperforms all\nbaselines by 0.1%-39% using a T2A model trained only on weakly-captioned\nAudioSet.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at ICLR 2025. Code and Checkpoints available here:\n  https://github.com/Sreyan88/Synthio",
    "pdf_url": "http://arxiv.org/pdf/2410.02056v2",
    "published_date": "2024-10-02 22:05:36 UTC",
    "updated_date": "2025-03-12 00:25:08 UTC"
  },
  {
    "arxiv_id": "2410.02042v1",
    "title": "EAB-FL: Exacerbating Algorithmic Bias through Model Poisoning Attacks in Federated Learning",
    "authors": [
      "Syed Irfan Ali Meerza",
      "Jian Liu"
    ],
    "abstract": "Federated Learning (FL) is a technique that allows multiple parties to train\na shared model collaboratively without disclosing their private data. It has\nbecome increasingly popular due to its distinct privacy advantages. However, FL\nmodels can suffer from biases against certain demographic groups (e.g., racial\nand gender groups) due to the heterogeneity of data and party selection.\nResearchers have proposed various strategies for characterizing the group\nfairness of FL algorithms to address this issue. However, the effectiveness of\nthese strategies in the face of deliberate adversarial attacks has not been\nfully explored. Although existing studies have revealed various threats (e.g.,\nmodel poisoning attacks) against FL systems caused by malicious participants,\ntheir primary aim is to decrease model accuracy, while the potential of\nleveraging poisonous model updates to exacerbate model unfairness remains\nunexplored. In this paper, we propose a new type of model poisoning attack,\nEAB-FL, with a focus on exacerbating group unfairness while maintaining a good\nlevel of model utility. Extensive experiments on three datasets demonstrate the\neffectiveness and efficiency of our attack, even with state-of-the-art fairness\noptimization algorithms and secure aggregation rules employed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02042v1",
    "published_date": "2024-10-02 21:22:48 UTC",
    "updated_date": "2024-10-02 21:22:48 UTC"
  },
  {
    "arxiv_id": "2410.02033v1",
    "title": "Model Comparisons: XNet Outperforms KAN",
    "authors": [
      "Xin Li",
      "Zhihong Jeff Xia",
      "Xiaotao Zheng"
    ],
    "abstract": "In the fields of computational mathematics and artificial intelligence, the\nneed for precise data modeling is crucial, especially for predictive machine\nlearning tasks. This paper explores further XNet, a novel algorithm that\nemploys the complex-valued Cauchy integral formula, offering a superior network\narchitecture that surpasses traditional Multi-Layer Perceptrons (MLPs) and\nKolmogorov-Arnold Networks (KANs). XNet significant improves speed and accuracy\nacross various tasks in both low and high-dimensional spaces, redefining the\nscope of data-driven model development and providing substantial improvements\nover established time series models like LSTMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02033v1",
    "published_date": "2024-10-02 20:59:47 UTC",
    "updated_date": "2024-10-02 20:59:47 UTC"
  },
  {
    "arxiv_id": "2410.02027v2",
    "title": "Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval",
    "authors": [
      "Kyle Buettner",
      "Adriana Kovashka"
    ],
    "abstract": "There is a scarcity of multilingual vision-language models that properly\naccount for the perceptual differences that are reflected in image captions\nacross languages and cultures. In this work, through a multimodal, multilingual\nretrieval case study, we quantify the existing lack of model flexibility. We\nempirically show performance gaps between training on captions that come from\nnative German perception and captions that have been either machine-translated\nor human-translated from English into German. To address these gaps, we further\npropose and evaluate caption augmentation strategies. While we achieve mean\nrecall improvements (+1.3), gaps still remain, indicating an open area of\nfuture work for the community.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "EMNLP 2024 Main - Short",
    "pdf_url": "http://arxiv.org/pdf/2410.02027v2",
    "published_date": "2024-10-02 20:47:53 UTC",
    "updated_date": "2024-10-08 15:22:53 UTC"
  },
  {
    "arxiv_id": "2410.02026v1",
    "title": "Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics",
    "authors": [
      "Yuan Zhou",
      "Peng Zhang",
      "Mengya Song",
      "Alice Zheng",
      "Yiwen Lu",
      "Zhiheng Liu",
      "Yong Chen",
      "Zhaohan Xi"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable progress in\nhealthcare. However, a significant gap remains regarding LLMs' professionalism\nin domain-specific clinical practices, limiting their application in real-world\ndiagnostics. In this work, we introduce ZODIAC, an LLM-powered framework with\ncardiologist-level professionalism designed to engage LLMs in cardiological\ndiagnostics. ZODIAC assists cardiologists by extracting clinically relevant\ncharacteristics from patient data, detecting significant arrhythmias, and\ngenerating preliminary reports for the review and refinement by cardiologists.\nTo achieve cardiologist-level professionalism, ZODIAC is built on a multi-agent\ncollaboration framework, enabling the processing of patient data across\nmultiple modalities. Each LLM agent is fine-tuned using real-world patient data\nadjudicated by cardiologists, reinforcing the model's professionalism. ZODIAC\nundergoes rigorous clinical validation with independent cardiologists,\nevaluated across eight metrics that measure clinical effectiveness and address\nsecurity concerns. Results show that ZODIAC outperforms industry-leading\nmodels, including OpenAI's GPT-4o, Meta's Llama-3.1-405B, and Google's\nGemini-pro, as well as medical-specialist LLMs like Microsoft's BioGPT. ZODIAC\ndemonstrates the transformative potential of specialized LLMs in healthcare by\ndelivering domain-specific solutions that meet the stringent demands of medical\npractice. Notably, ZODIAC has been successfully integrated into\nelectrocardiography (ECG) devices, exemplifying the growing trend of embedding\nLLMs into Software-as-Medical-Device (SaMD).",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02026v1",
    "published_date": "2024-10-02 20:46:39 UTC",
    "updated_date": "2024-10-02 20:46:39 UTC"
  },
  {
    "arxiv_id": "2410.02025v1",
    "title": "A Likelihood Based Approach to Distribution Regression Using Conditional Deep Generative Models",
    "authors": [
      "Shivam Kumar",
      "Yun Yang",
      "Lizhen Lin"
    ],
    "abstract": "In this work, we explore the theoretical properties of conditional deep\ngenerative models under the statistical framework of distribution regression\nwhere the response variable lies in a high-dimensional ambient space but\nconcentrates around a potentially lower-dimensional manifold. More\nspecifically, we study the large-sample properties of a likelihood-based\napproach for estimating these models. Our results lead to the convergence rate\nof a sieve maximum likelihood estimator (MLE) for estimating the conditional\ndistribution (and its devolved counterpart) of the response given predictors in\nthe Hellinger (Wasserstein) metric. Our rates depend solely on the intrinsic\ndimension and smoothness of the true conditional distribution. These findings\nprovide an explanation of why conditional deep generative models can circumvent\nthe curse of dimensionality from the perspective of statistical foundations and\ndemonstrate that they can learn a broader class of nearly singular conditional\ndistributions. Our analysis also emphasizes the importance of introducing a\nsmall noise perturbation to the data when they are supported sufficiently close\nto a manifold. Finally, in our numerical studies, we demonstrate the effective\nimplementation of the proposed approach using both synthetic and real-world\ndatasets, which also provide complementary validation to our theoretical\nfindings.",
    "categories": [
      "math.ST",
      "cs.AI",
      "cs.LG",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST",
    "comment": "arXiv admin note: text overlap with arXiv:1708.06633 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2410.02025v1",
    "published_date": "2024-10-02 20:46:21 UTC",
    "updated_date": "2024-10-02 20:46:21 UTC"
  },
  {
    "arxiv_id": "2410.02024v3",
    "title": "FLAG: Financial Long Document Classification via AMR-based GNN",
    "authors": [
      "Bolun \"Namir\" Xia",
      "Aparna Gupta",
      "Mohammed J. Zaki"
    ],
    "abstract": "The advent of large language models (LLMs) has initiated much research into\ntheir various financial applications. However, in applying LLMs on long\ndocuments, semantic relations are not explicitly incorporated, and a full or\narbitrarily sparse attention operation is employed. In recent years, progress\nhas been made in Abstract Meaning Representation (AMR), which is a graph-based\nrepresentation of text to preserve its semantic relations. Since AMR can\nrepresent semantic relationships at a deeper level, it can be beneficially\nutilized by graph neural networks (GNNs) for constructing effective\ndocument-level graph representations built upon LLM embeddings to predict\ntarget metrics in the financial domain. We propose FLAG: Financial Long\ndocument classification via AMR-based GNN, an AMR graph based framework to\ngenerate document-level embeddings for long financial document classification.\nWe construct document-level graphs from sentence-level AMR graphs, endow them\nwith specialized LLM word embeddings in the financial domain, apply a deep\nlearning mechanism that utilizes a GNN, and examine the efficacy of our\nAMR-based approach in predicting labeled target data from long financial\ndocuments. Extensive experiments are conducted on a dataset of quarterly\nearnings calls transcripts of companies in various sectors of the economy, as\nwell as on a corpus of more recent earnings calls of companies in the S&P 1500\nComposite Index. We find that our AMR-based approach outperforms fine-tuning\nLLMs directly on text in predicting stock price movement trends at different\ntime horizons in both datasets. Our work also outperforms previous work\nutilizing document graphs and GNNs for text classification.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CE",
    "comment": "8 pages, 3 figures, to be published in CIFEr Conference 2024 as\n  \"Semantic Graph Learning for Trend Prediction from Long Financial Documents\"",
    "pdf_url": "http://arxiv.org/pdf/2410.02024v3",
    "published_date": "2024-10-02 20:45:51 UTC",
    "updated_date": "2024-10-22 18:22:11 UTC"
  },
  {
    "arxiv_id": "2410.02023v2",
    "title": "DeepProtein: Deep Learning Library and Benchmark for Protein Sequence Learning",
    "authors": [
      "Jiaqing Xie",
      "Tianfan Fu"
    ],
    "abstract": "Deep learning has deeply influenced protein science, enabling breakthroughs\nin predicting protein properties, higher-order structures, and molecular\ninteractions. This paper introduces DeepProtein, a comprehensive and\nuser-friendly deep learning library tailored for protein-related tasks. It\nenables researchers to seamlessly address protein data with cutting-edge deep\nlearning models. To assess model performance, we establish a benchmark\nevaluating different deep learning architectures across multiple\nprotein-related tasks, including protein function prediction, subcellular\nlocalization prediction, protein-protein interaction prediction, and protein\nstructure prediction. Furthermore, we introduce DeepProt-T5, a series of\nfine-tuned Prot-T5-based models that achieve state-of-the-art performance on\nfour benchmark tasks, while demonstrating competitive results on six of others.\nComprehensive documentation and tutorials are available which could ensure\naccessibility and support reproducibility. Built upon the widely used drug\ndiscovery library DeepPurpose, DeepProtein is publicly available at\nhttps://github.com/jiaqingxie/DeepProtein.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Bioinformatics",
    "pdf_url": "http://arxiv.org/pdf/2410.02023v2",
    "published_date": "2024-10-02 20:42:32 UTC",
    "updated_date": "2025-04-06 18:40:55 UTC"
  },
  {
    "arxiv_id": "2410.02017v1",
    "title": "Review Non-convex Optimization Method for Machine Learning",
    "authors": [
      "Greg B Fotopoulos",
      "Paul Popovich",
      "Nicholas Hall Papadopoulos"
    ],
    "abstract": "Non-convex optimization is a critical tool in advancing machine learning,\nespecially for complex models like deep neural networks and support vector\nmachines. Despite challenges such as multiple local minima and saddle points,\nnon-convex techniques offer various pathways to reduce computational costs.\nThese include promoting sparsity through regularization, efficiently escaping\nsaddle points, and employing subsampling and approximation strategies like\nstochastic gradient descent. Additionally, non-convex methods enable model\npruning and compression, which reduce the size of models while maintaining\nperformance. By focusing on good local minima instead of exact global minima,\nnon-convex optimization ensures competitive accuracy with faster convergence\nand lower computational overhead. This paper examines the key methods and\napplications of non-convex optimization in machine learning, exploring how it\ncan lower computation costs while enhancing model performance. Furthermore, it\noutlines future research directions and challenges, including scalability and\ngeneralization, that will shape the next phase of non-convex optimization in\nmachine learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02017v1",
    "published_date": "2024-10-02 20:34:33 UTC",
    "updated_date": "2024-10-02 20:34:33 UTC"
  },
  {
    "arxiv_id": "2410.02006v1",
    "title": "Addressing Data Heterogeneity in Federated Learning with Adaptive Normalization-Free Feature Recalibration",
    "authors": [
      "Vasilis Siomos",
      "Sergio Naval-Marimont",
      "Jonathan Passerat-Palmbach",
      "Giacomo Tarroni"
    ],
    "abstract": "Federated learning is a decentralized collaborative training paradigm that\npreserves stakeholders' data ownership while improving performance and\ngeneralization. However, statistical heterogeneity among client datasets poses\na fundamental challenge by degrading system performance. To address this issue,\nwe propose Adaptive Normalization-free Feature Recalibration (ANFR), an\narchitecture-level approach that combines weight standardization and channel\nattention. Weight standardization normalizes the weights of layers instead of\nactivations. This is less susceptible to mismatched client statistics and\ninconsistent averaging, thereby more robust under heterogeneity. Channel\nattention produces learnable scaling factors for feature maps, suppressing\nthose that are inconsistent between clients due to heterogeneity. We\ndemonstrate that combining these techniques boosts model performance beyond\ntheir individual contributions, by enhancing class selectivity and optimizing\nchannel attention weight distribution. ANFR operates independently of the\naggregation method and is effective in both global and personalized federated\nlearning settings, with minimal computational overhead. Furthermore, when\ntraining with differential privacy, ANFR achieves an appealing balance between\nprivacy and utility, enabling strong privacy guarantees without sacrificing\nperformance. By integrating weight standardization and channel attention in the\nbackbone model, ANFR offers a novel and versatile approach to the challenge of\nstatistical heterogeneity. We demonstrate through extensive experiments that\nANFR consistently outperforms established baselines across various aggregation\nmethods, datasets, and heterogeneity conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.02006v1",
    "published_date": "2024-10-02 20:16:56 UTC",
    "updated_date": "2024-10-02 20:16:56 UTC"
  },
  {
    "arxiv_id": "2410.02004v2",
    "title": "Normalizing Flow-Based Metric for Image Generation",
    "authors": [
      "Pranav Jeevan",
      "Neeraj Nixon",
      "Amit Sethi"
    ],
    "abstract": "We propose two new evaluation metrics to assess realness of generated images\nbased on normalizing flows: a simpler and efficient flow-based likelihood\ndistance (FLD) and a more exact dual-flow based likelihood distance (D-FLD).\nBecause normalizing flows can be used to compute the exact likelihood, the\nproposed metrics assess how closely generated images align with the\ndistribution of real images from a given domain. This property gives the\nproposed metrics a few advantages over the widely used Fr\\'echet inception\ndistance (FID) and other recent metrics. Firstly, the proposed metrics need\nonly a few hundred images to stabilize (converge in mean), as opposed to tens\nof thousands needed for FID, and at least a few thousand for the other metrics.\nThis allows confident evaluation of even small sets of generated images, such\nas validation batches inside training loops. Secondly, the network used to\ncompute the proposed metric has over an order of magnitude fewer parameters\ncompared to Inception-V3 used to compute FID, making it computationally more\nefficient. For assessing the realness of generated images in new domains (e.g.,\nx-ray images), ideally these networks should be retrained on real images to\nmodel their distinct distributions. Thus, our smaller network will be even more\nadvantageous for new domains. Extensive experiments show that the proposed\nmetrics have the desired monotonic relationships with the extent of image\ndegradation of various kinds.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10; I.4.0; I.4.4; I.4.3; I.4.5; I.4.1; I.4.2; I.4.6; I.4.7;\n  I.4.8; I.4.9; I.4.10; I.2.10; I.5.1; I.5.2; I.5.4"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.02004v2",
    "published_date": "2024-10-02 20:09:58 UTC",
    "updated_date": "2024-10-05 11:31:54 UTC"
  },
  {
    "arxiv_id": "2410.14682v2",
    "title": "ET-Plan-Bench: Embodied Task-level Planning Benchmark Towards Spatial-Temporal Cognition with Foundation Models",
    "authors": [
      "Lingfeng Zhang",
      "Yuening Wang",
      "Hongjian Gu",
      "Atia Hamidizadeh",
      "Zhanguang Zhang",
      "Yuecheng Liu",
      "Yutong Wang",
      "David Gamaliel Arcos Bravo",
      "Junyi Dong",
      "Shunbo Zhou",
      "Tongtong Cao",
      "Xingyue Quan",
      "Yuzheng Zhuang",
      "Yingxue Zhang",
      "Jianye Hao"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have spurred numerous\nattempts to apply these technologies to embodied tasks, particularly focusing\non high-level task planning and task decomposition. To further explore this\narea, we introduce a new embodied task planning benchmark, ET-Plan-Bench, which\nspecifically targets embodied task planning using LLMs. It features a\ncontrollable and diverse set of embodied tasks varying in different levels of\ndifficulties and complexities, and is designed to evaluate two critical\ndimensions of LLMs' application in embodied task understanding: spatial\n(relation constraint, occlusion for target objects) and temporal & causal\nunderstanding of the sequence of actions in the environment. By using\nmulti-source simulators as the backend simulator, it can provide immediate\nenvironment feedback to LLMs, which enables LLMs to interact dynamically with\nthe environment and re-plan as necessary. We evaluated the state-of-the-art\nopen source and closed source foundation models, including GPT-4, LLAMA and\nMistral on our proposed benchmark. While they perform adequately well on simple\nnavigation tasks, their performance can significantly deteriorate when faced\nwith tasks that require a deeper understanding of spatial, temporal, and causal\nrelationships. Thus, our benchmark distinguishes itself as a large-scale,\nquantifiable, highly automated, and fine-grained diagnostic framework that\npresents a significant challenge to the latest foundation models. We hope it\ncan spark and drive further research in embodied task planning using foundation\nmodels.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14682v2",
    "published_date": "2024-10-02 19:56:38 UTC",
    "updated_date": "2025-02-13 14:54:31 UTC"
  },
  {
    "arxiv_id": "2410.01989v1",
    "title": "UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription",
    "authors": [
      "Reza Basiri",
      "Ali Abedi",
      "Chau Nguyen",
      "Milos R. Popovic",
      "Shehroz S. Khan"
    ],
    "abstract": "Diabetic foot ulcers (DFUs) are a leading cause of hospitalizations and lower\nlimb amputations, placing a substantial burden on patients and healthcare\nsystems. Early detection and accurate classification of DFUs are critical for\npreventing serious complications, yet many patients experience delays in\nreceiving care due to limited access to specialized services. Telehealth has\nemerged as a promising solution, improving access to care and reducing the need\nfor in-person visits. The integration of artificial intelligence and pattern\nrecognition into telemedicine has further enhanced DFU management by enabling\nautomatic detection, classification, and monitoring from images. Despite\nadvancements in artificial intelligence-driven approaches for DFU image\nanalysis, the application of large language models for DFU image transcription\nhas not yet been explored. To address this gap, we introduce UlcerGPT, a novel\nmultimodal approach leveraging large language and vision models for DFU image\ntranscription. This framework combines advanced vision and language models,\nsuch as Large Language and Vision Assistant and Chat Generative Pre-trained\nTransformer, to transcribe DFU images by jointly detecting, classifying, and\nlocalizing regions of interest. Through detailed experiments on a public\ndataset, evaluated by expert clinicians, UlcerGPT demonstrates promising\nresults in the accuracy and efficiency of DFU transcription, offering potential\nsupport for clinicians in delivering timely care via telemedicine.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 3 figures, ICPR 2024 Conference (PRHA workshop)",
    "pdf_url": "http://arxiv.org/pdf/2410.01989v1",
    "published_date": "2024-10-02 19:51:48 UTC",
    "updated_date": "2024-10-02 19:51:48 UTC"
  },
  {
    "arxiv_id": "2410.01985v2",
    "title": "Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks",
    "authors": [
      "Hamed Firooz",
      "Maziar Sanjabi",
      "Wenlong Jiang",
      "Xiaoling Zhai"
    ],
    "abstract": "Despite significant advancements, Large Language Models (LLMs) exhibit blind\nspots that impair their ability to retrieve and process relevant contextual\ndata effectively. We demonstrate that LLM performance in graph tasks with\ncomplexities beyond the \"needle-in-a-haystack\" scenario-where solving the\nproblem requires cross-referencing and reasoning across multiple subproblems\njointly-is influenced by the proximity of relevant information within the\ncontext, a phenomenon we term \"lost-in-distance\". We examine two fundamental\ngraph tasks: identifying common connections between two nodes and assessing\nsimilarity among three nodes, and show that the model's performance in these\ntasks significantly depends on the relative positioning of common edges. We\nevaluate three publicly available LLMs using various graph encoding techniques\nthat represent graph structures for LLM input. We propose a formulation for the\nlost-in-distance phenomenon and demonstrate that lost-in-distance and\nlost-in-the middle phenomenas occur independently. Results indicate that model\naccuracy can decline by up to 6x as the distance between node connections\nincreases, independent of graph encoding and model size.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01985v2",
    "published_date": "2024-10-02 19:45:19 UTC",
    "updated_date": "2025-01-02 04:15:37 UTC"
  },
  {
    "arxiv_id": "2410.01978v2",
    "title": "LLM+KG@VLDB'24 Workshop Summary",
    "authors": [
      "Arijit Khan",
      "Tianxing Wu",
      "Xi Chen"
    ],
    "abstract": "The unification of large language models (LLMs) and knowledge graphs (KGs)\nhas emerged as a hot topic. At the LLM+KG'24 workshop, held in conjunction with\nVLDB 2024 in Guangzhou, China, one of the key themes explored was important\ndata management challenges and opportunities due to the effective interaction\nbetween LLMs and KGs. This report outlines the major directions and approaches\npresented by various speakers during the LLM+KG'24 workshop.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "accepted at ACM SIGMOD Record 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01978v2",
    "published_date": "2024-10-02 19:35:35 UTC",
    "updated_date": "2025-03-22 20:58:34 UTC"
  },
  {
    "arxiv_id": "2410.03770v1",
    "title": "A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model",
    "authors": [
      "Xueshen Li",
      "Xinlong Hou",
      "Nirupama Ravi",
      "Ziyi Huang",
      "Yu Gan"
    ],
    "abstract": "Efficient patient-doctor interaction is among the key factors for a\nsuccessful disease diagnosis. During the conversation, the doctor could query\ncomplementary diagnostic information, such as the patient's symptoms, previous\nsurgery, and other related information that goes beyond medical evidence data\n(test results) to enhance disease diagnosis. However, this procedure is usually\ntime-consuming and less-efficient, which can be potentially optimized through\ncomputer-assisted systems. As such, we propose a diagnostic dialogue system to\nautomate the patient information collection procedure. By exploiting medical\nhistory and conversation logic, our conversation agents, particularly the\ndoctor agent, can pose multi-round clinical queries to effectively collect the\nmost relevant disease diagnostic information. Moreover, benefiting from our\ntwo-stage recommendation structure, carefully designed ranking criteria, and\ninteractive patient agent, our model is able to overcome the under-exploration\nand non-flexible challenges in dialogue generation. Our experimental results on\na real-world medical conversation dataset show that our model can generate\nclinical queries that mimic the conversation style of real doctors, with\nefficient fluency, professionalism, and safety, while effectively collecting\nrelevant disease diagnostic information.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Prepare for submission",
    "pdf_url": "http://arxiv.org/pdf/2410.03770v1",
    "published_date": "2024-10-02 19:32:11 UTC",
    "updated_date": "2024-10-02 19:32:11 UTC"
  },
  {
    "arxiv_id": "2410.01966v3",
    "title": "Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker",
    "authors": [
      "Xinlong Hou",
      "Sen Shen",
      "Xueshen Li",
      "Xinran Gao",
      "Ziyi Huang",
      "Steven J. Holiday",
      "Matthew R. Cribbet",
      "Susan W. White",
      "Edward Sazonov",
      "Yu Gan"
    ],
    "abstract": "Being able to accurately monitor the screen exposure of young children is\nimportant for research on phenomena linked to screen use such as childhood\nobesity, physical activity, and social interaction. Most existing studies rely\nupon self-report or manual measures from bulky wearable sensors, thus lacking\nefficiency and accuracy in capturing quantitative screen exposure data. In this\nwork, we developed a novel sensor informatics framework that utilizes\negocentric images from a wearable sensor, termed the screen time tracker (STT),\nand a vision language model (VLM). In particular, we devised a multi-view VLM\nthat takes multiple views from egocentric image sequences and interprets screen\nexposure dynamically. We validated our approach by using a dataset of\nchildren's free-living activities, demonstrating significant improvement over\nexisting methods in plain vision language models and object detection models.\nResults supported the promise of this monitoring approach, which could optimize\nbehavioral research on screen exposure in children's naturalistic settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Prepare for submission",
    "pdf_url": "http://arxiv.org/pdf/2410.01966v3",
    "published_date": "2024-10-02 19:16:47 UTC",
    "updated_date": "2025-05-08 20:00:26 UTC"
  },
  {
    "arxiv_id": "2410.01944v1",
    "title": "One-step Noisy Label Mitigation",
    "authors": [
      "Hao Li",
      "Jiayang Gu",
      "Jingkuan Song",
      "An Zhang",
      "Lianli Gao"
    ],
    "abstract": "Mitigating the detrimental effects of noisy labels on the training process\nhas become increasingly critical, as obtaining entirely clean or\nhuman-annotated samples for large-scale pre-training tasks is often\nimpractical. Nonetheless, existing noise mitigation methods often encounter\nlimitations in practical applications due to their task-specific design, model\ndependency, and significant computational overhead. In this work, we exploit\nthe properties of high-dimensional orthogonality to identify a robust and\neffective boundary in cone space for separating clean and noisy samples.\nBuilding on this, we propose One-step Anti-Noise (OSA), a model-agnostic noisy\nlabel mitigation paradigm that employs an estimator model and a scoring\nfunction to assess the noise level of input pairs through just one-step\ninference, a cost-efficient process. We empirically demonstrate the superiority\nof OSA, highlighting its enhanced training robustness, improved task\ntransferability, ease of deployment, and reduced computational costs across\nvarious benchmarks, models, and tasks. Our code is released at\nhttps://github.com/leolee99/OSA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 4 figures, 11 Tables",
    "pdf_url": "http://arxiv.org/pdf/2410.01944v1",
    "published_date": "2024-10-02 18:42:56 UTC",
    "updated_date": "2024-10-02 18:42:56 UTC"
  },
  {
    "arxiv_id": "2410.01943v1",
    "title": "CHASE-SQL: Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL",
    "authors": [
      "Mohammadreza Pourreza",
      "Hailong Li",
      "Ruoxi Sun",
      "Yeounoh Chung",
      "Shayan Talaei",
      "Gaurav Tarlok Kakkar",
      "Yu Gan",
      "Amin Saberi",
      "Fatma Ozcan",
      "Sercan O. Arik"
    ],
    "abstract": "In tackling the challenges of large language model (LLM) performance for\nText-to-SQL tasks, we introduce CHASE-SQL, a new framework that employs\ninnovative strategies, using test-time compute in multi-agent modeling to\nimprove candidate generation and selection. CHASE-SQL leverages LLMs' intrinsic\nknowledge to generate diverse and high-quality SQL candidates using different\nLLM generators with: (1) a divide-and-conquer method that decomposes complex\nqueries into manageable sub-queries in a single LLM call; (2) chain-of-thought\nreasoning based on query execution plans, reflecting the steps a database\nengine takes during execution; and (3) a unique instance-aware synthetic\nexample generation technique, which offers specific few-shot demonstrations\ntailored to test questions.To identify the best candidate, a selection agent is\nemployed to rank the candidates through pairwise comparisons with a fine-tuned\nbinary-candidates selection LLM. This selection approach has been demonstrated\nto be more robust over alternatives. The proposed generators-selector framework\nnot only enhances the quality and diversity of SQL queries but also outperforms\nprevious methods. Overall, our proposed CHASE-SQL achieves the state-of-the-art\nexecution accuracy of 73.0% and 73.01% on the test set and development set of\nthe notable BIRD Text-to-SQL dataset benchmark, rendering CHASE-SQL the top\nsubmission of the leaderboard (at the time of paper submission).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01943v1",
    "published_date": "2024-10-02 18:41:35 UTC",
    "updated_date": "2024-10-02 18:41:35 UTC"
  },
  {
    "arxiv_id": "2410.01930v2",
    "title": "Don't flatten, tokenize! Unlocking the key to SoftMoE's efficacy in deep RL",
    "authors": [
      "Ghada Sokar",
      "Johan Obando-Ceron",
      "Aaron Courville",
      "Hugo Larochelle",
      "Pablo Samuel Castro"
    ],
    "abstract": "The use of deep neural networks in reinforcement learning (RL) often suffers\nfrom performance degradation as model size increases. While soft mixtures of\nexperts (SoftMoEs) have recently shown promise in mitigating this issue for\nonline RL, the reasons behind their effectiveness remain largely unknown. In\nthis work we provide an in-depth analysis identifying the key factors driving\nthis performance gain. We discover the surprising result that tokenizing the\nencoder output, rather than the use of multiple experts, is what is behind the\nefficacy of SoftMoEs. Indeed, we demonstrate that even with an appropriately\nscaled single expert, we are able to maintain the performance gains, largely\nthanks to tokenization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01930v2",
    "published_date": "2024-10-02 18:22:45 UTC",
    "updated_date": "2025-02-26 20:36:25 UTC"
  },
  {
    "arxiv_id": "2410.01929v1",
    "title": "LLM-Augmented Symbolic Reinforcement Learning with Landmark-Based Task Decomposition",
    "authors": [
      "Alireza Kheirandish",
      "Duo Xu",
      "Faramarz Fekri"
    ],
    "abstract": "One of the fundamental challenges in reinforcement learning (RL) is to take a\ncomplex task and be able to decompose it to subtasks that are simpler for the\nRL agent to learn. In this paper, we report on our work that would identify\nsubtasks by using some given positive and negative trajectories for solving the\ncomplex task. We assume that the states are represented by first-order\npredicate logic using which we devise a novel algorithm to identify the\nsubtasks. Then we employ a Large Language Model (LLM) to generate first-order\nlogic rule templates for achieving each subtask. Such rules were then further\nfined tuned to a rule-based policy via an Inductive Logic Programming\n(ILP)-based RL agent. Through experiments, we verify the accuracy of our\nalgorithm in detecting subtasks which successfully detect all of the subtasks\ncorrectly. We also investigated the quality of the common-sense rules produced\nby the language model to achieve the subtasks. Our experiments show that our\nLLM-guided rule template generation can produce rules that are necessary for\nsolving a subtask, which leads to solving complex tasks with fewer assumptions\nabout predefined first-order logic predicates of the environment.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01929v1",
    "published_date": "2024-10-02 18:22:42 UTC",
    "updated_date": "2024-10-02 18:22:42 UTC"
  },
  {
    "arxiv_id": "2410.01927v1",
    "title": "Risk Alignment in Agentic AI Systems",
    "authors": [
      "Hayley Clatterbuck",
      "Clinton Castro",
      "Arvo Muñoz Morán"
    ],
    "abstract": "Agentic AIs $-$ AIs that are capable and permitted to undertake complex\nactions with little supervision $-$ mark a new frontier in AI capabilities and\nraise new questions about how to safely create and align such systems with\nusers, developers, and society. Because agents' actions are influenced by their\nattitudes toward risk, one key aspect of alignment concerns the risk profiles\nof agentic AIs. Risk alignment will matter for user satisfaction and trust, but\nit will also have important ramifications for society more broadly, especially\nas agentic AIs become more autonomous and are allowed to control key aspects of\nour lives. AIs with reckless attitudes toward risk (either because they are\ncalibrated to reckless human users or are poorly designed) may pose significant\nthreats. They might also open 'responsibility gaps' in which there is no agent\nwho can be held accountable for harmful actions. What risk attitudes should\nguide an agentic AI's decision-making? How might we design AI systems that are\ncalibrated to the risk attitudes of their users? What guardrails, if any,\nshould be placed on the range of permissible risk attitudes? What are the\nethical considerations involved when designing systems that make risky\ndecisions on behalf of others? We present three papers that bear on key\nnormative and technical aspects of these questions.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01927v1",
    "published_date": "2024-10-02 18:21:08 UTC",
    "updated_date": "2024-10-02 18:21:08 UTC"
  },
  {
    "arxiv_id": "2410.01917v2",
    "title": "Provably Accurate Shapley Value Estimation via Leverage Score Sampling",
    "authors": [
      "Christopher Musco",
      "R. Teal Witter"
    ],
    "abstract": "Originally introduced in game theory, Shapley values have emerged as a\ncentral tool in explainable machine learning, where they are used to attribute\nmodel predictions to specific input features. However, computing Shapley values\nexactly is expensive: for a general model with $n$ features, $O(2^n)$ model\nevaluations are necessary. To address this issue, approximation algorithms are\nwidely used. One of the most popular is the Kernel SHAP algorithm, which is\nmodel agnostic and remarkably effective in practice. However, to the best of\nour knowledge, Kernel SHAP has no strong non-asymptotic complexity guarantees.\nWe address this issue by introducing Leverage SHAP, a light-weight modification\nof Kernel SHAP that provides provably accurate Shapley value estimates with\njust $O(n\\log n)$ model evaluations. Our approach takes advantage of a\nconnection between Shapley value estimation and agnostic active learning by\nemploying leverage score sampling, a powerful regression tool. Beyond\ntheoretical guarantees, we show that Leverage SHAP consistently outperforms\neven the highly optimized implementation of Kernel SHAP available in the\nubiquitous SHAP library [Lundberg & Lee, 2017].",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01917v2",
    "published_date": "2024-10-02 18:15:48 UTC",
    "updated_date": "2025-03-10 15:52:54 UTC"
  },
  {
    "arxiv_id": "2410.01912v1",
    "title": "A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation",
    "authors": [
      "Liang Chen",
      "Sinan Tan",
      "Zefan Cai",
      "Weichu Xie",
      "Haozhe Zhao",
      "Yichi Zhang",
      "Junyang Lin",
      "Jinze Bai",
      "Tianyu Liu",
      "Baobao Chang"
    ],
    "abstract": "This work tackles the information loss bottleneck of vector-quantization (VQ)\nautoregressive image generation by introducing a novel model architecture\ncalled the 2-Dimensional Autoregression (DnD) Transformer. The DnD-Transformer\npredicts more codes for an image by introducing a new autoregression direction,\n\\textit{model depth}, along with the sequence length direction. Compared to\ntraditional 1D autoregression and previous work utilizing similar 2D image\ndecomposition such as RQ-Transformer, the DnD-Transformer is an end-to-end\nmodel that can generate higher quality images with the same backbone model size\nand sequence length, opening a new optimization perspective for autoregressive\nimage generation. Furthermore, our experiments reveal that the\nDnD-Transformer's potential extends beyond generating natural images. It can\neven generate images with rich text and graphical elements in a self-supervised\nmanner, demonstrating an understanding of these combined modalities. This has\nnot been previously demonstrated for popular vision generative models such as\ndiffusion models, showing a spark of vision-language intelligence when trained\nsolely on images. Code, datasets and models are open at\nhttps://github.com/chenllliang/DnD-Transformer.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages, 20 figures, code is open at\n  https://github.com/chenllliang/DnD-Transformer",
    "pdf_url": "http://arxiv.org/pdf/2410.01912v1",
    "published_date": "2024-10-02 18:10:05 UTC",
    "updated_date": "2024-10-02 18:10:05 UTC"
  },
  {
    "arxiv_id": "2410.01906v1",
    "title": "Social Media Authentication and Combating Deepfakes using Semi-fragile Invisible Image Watermarking",
    "authors": [
      "Aakash Varma Nadimpalli",
      "Ajita Rattani"
    ],
    "abstract": "With the significant advances in deep generative models for image and video\nsynthesis, Deepfakes and manipulated media have raised severe societal\nconcerns. Conventional machine learning classifiers for deepfake detection\noften fail to cope with evolving deepfake generation technology and are\nsusceptible to adversarial attacks. Alternatively, invisible image watermarking\nis being researched as a proactive defense technique that allows media\nauthentication by verifying an invisible secret message embedded in the image\npixels. A handful of invisible image watermarking techniques introduced for\nmedia authentication have proven vulnerable to basic image processing\noperations and watermark removal attacks. In response, we have proposed a\nsemi-fragile image watermarking technique that embeds an invisible secret\nmessage into real images for media authentication. Our proposed watermarking\nframework is designed to be fragile to facial manipulations or tampering while\nbeing robust to benign image-processing operations and watermark removal\nattacks. This is facilitated through a unique architecture of our proposed\ntechnique consisting of critic and adversarial networks that enforce high image\nquality and resiliency to watermark removal efforts, respectively, along with\nthe backbone encoder-decoder and the discriminator networks. Thorough\nexperimental investigations on SOTA facial Deepfake datasets demonstrate that\nour proposed model can embed a $64$-bit secret as an imperceptible image\nwatermark that can be recovered with a high-bit recovery accuracy when benign\nimage processing operations are applied while being non-recoverable when unseen\nDeepfake manipulations are applied. In addition, our proposed watermarking\ntechnique demonstrates high resilience to several white-box and black-box\nwatermark removal attacks. Thus, obtaining state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "ACM Transactions (Digital Threats: Research and Practice)",
    "pdf_url": "http://arxiv.org/pdf/2410.01906v1",
    "published_date": "2024-10-02 18:05:03 UTC",
    "updated_date": "2024-10-02 18:05:03 UTC"
  },
  {
    "arxiv_id": "2410.01899v1",
    "title": "The potential of LLM-generated reports in DevSecOps",
    "authors": [
      "Nikolaos Lykousas",
      "Vasileios Argyropoulos",
      "Fran Casino"
    ],
    "abstract": "Alert fatigue is a common issue faced by software teams using the DevSecOps\nparadigm. The overwhelming number of warnings and alerts generated by security\nand code scanning tools, particularly in smaller teams where resources are\nlimited, leads to desensitization and diminished responsiveness to security\nwarnings, potentially exposing systems to vulnerabilities. This paper explores\nthe potential of LLMs in generating actionable security reports that emphasize\nthe financial impact and consequences of detected security issues, such as\ncredential leaks, if they remain unaddressed. A survey conducted among\ndevelopers indicates that LLM-generated reports significantly enhance the\nlikelihood of immediate action on security issues by providing clear,\ncomprehensive, and motivating insights. Integrating these reports into\nDevSecOps workflows can mitigate attention saturation and alert fatigue,\nensuring that critical security warnings are addressed effectively.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "Published in AIESE 2024 (International Conference on AI empowered\n  Software Engineering)",
    "pdf_url": "http://arxiv.org/pdf/2410.01899v1",
    "published_date": "2024-10-02 18:01:12 UTC",
    "updated_date": "2024-10-02 18:01:12 UTC"
  },
  {
    "arxiv_id": "2410.01806v1",
    "title": "Samba: Synchronized Set-of-Sequences Modeling for Multiple Object Tracking",
    "authors": [
      "Mattia Segu",
      "Luigi Piccinelli",
      "Siyuan Li",
      "Yung-Hsu Yang",
      "Bernt Schiele",
      "Luc Van Gool"
    ],
    "abstract": "Multiple object tracking in complex scenarios - such as coordinated dance\nperformances, team sports, or dynamic animal groups - presents unique\nchallenges. In these settings, objects frequently move in coordinated patterns,\nocclude each other, and exhibit long-term dependencies in their trajectories.\nHowever, it remains a key open research question on how to model long-range\ndependencies within tracklets, interdependencies among tracklets, and the\nassociated temporal occlusions. To this end, we introduce Samba, a novel\nlinear-time set-of-sequences model designed to jointly process multiple\ntracklets by synchronizing the multiple selective state-spaces used to model\neach tracklet. Samba autoregressively predicts the future track query for each\nsequence while maintaining synchronized long-term memory representations across\ntracklets. By integrating Samba into a tracking-by-propagation framework, we\npropose SambaMOTR, the first tracker effectively addressing the aforementioned\nissues, including long-range dependencies, tracklet interdependencies, and\ntemporal occlusions. Additionally, we introduce an effective technique for\ndealing with uncertain observations (MaskObs) and an efficient training recipe\nto scale SambaMOTR to longer sequences. By modeling long-range dependencies and\ninteractions among tracked objects, SambaMOTR implicitly learns to track\nobjects accurately through occlusions without any hand-crafted heuristics. Our\napproach significantly surpasses prior state-of-the-art on the DanceTrack, BFT,\nand SportsMOT datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01806v1",
    "published_date": "2024-10-02 17:59:57 UTC",
    "updated_date": "2024-10-02 17:59:57 UTC"
  },
  {
    "arxiv_id": "2410.01801v1",
    "title": "FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments Generation from In-The-Wild Clothing Images",
    "authors": [
      "Cheng Zhang",
      "Yuanhao Wang",
      "Francisco Vicente Carrasco",
      "Chenglei Wu",
      "Jinlong Yang",
      "Thabo Beeler",
      "Fernando De la Torre"
    ],
    "abstract": "We introduce FabricDiffusion, a method for transferring fabric textures from\na single clothing image to 3D garments of arbitrary shapes. Existing approaches\ntypically synthesize textures on the garment surface through 2D-to-3D texture\nmapping or depth-aware inpainting via generative models. Unfortunately, these\nmethods often struggle to capture and preserve texture details, particularly\ndue to challenging occlusions, distortions, or poses in the input image.\nInspired by the observation that in the fashion industry, most garments are\nconstructed by stitching sewing patterns with flat, repeatable textures, we\ncast the task of clothing texture transfer as extracting distortion-free,\ntileable texture materials that are subsequently mapped onto the UV space of\nthe garment. Building upon this insight, we train a denoising diffusion model\nwith a large-scale synthetic dataset to rectify distortions in the input\ntexture image. This process yields a flat texture map that enables a tight\ncoupling with existing Physically-Based Rendering (PBR) material generation\npipelines, allowing for realistic relighting of the garment under various\nlighting conditions. We show that FabricDiffusion can transfer various features\nfrom a single clothing image including texture patterns, material properties,\nand detailed prints and logos. Extensive experiments demonstrate that our model\nsignificantly outperforms state-to-the-art methods on both synthetic data and\nreal-world, in-the-wild clothing images while generalizing to unseen textures\nand garment shapes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to SIGGRAPH Asia 2024. Project page:\n  https://humansensinglab.github.io/fabric-diffusion",
    "pdf_url": "http://arxiv.org/pdf/2410.01801v1",
    "published_date": "2024-10-02 17:57:12 UTC",
    "updated_date": "2024-10-02 17:57:12 UTC"
  },
  {
    "arxiv_id": "2410.01871v2",
    "title": "Auction-Based Regulation for Artificial Intelligence",
    "authors": [
      "Marco Bornstein",
      "Zora Che",
      "Suhas Julapalli",
      "Abdirisak Mohamed",
      "Amrit Singh Bedi",
      "Furong Huang"
    ],
    "abstract": "In an era of \"moving fast and breaking things\", regulators have moved slowly\nto pick up the safety, bias, and legal debris left in the wake of broken\nArtificial Intelligence (AI) deployment. While there is much-warranted\ndiscussion about how to address the safety, bias, and legal woes of\nstate-of-the-art AI models, rigorous and realistic mathematical frameworks to\nregulate AI are lacking. Our paper addresses this challenge, proposing an\nauction-based regulatory mechanism that provably incentivizes devices (i) to\ndeploy compliant models and (ii) to participate in the regulation process. We\nformulate AI regulation as an all-pay auction where enterprises submit models\nfor approval. The regulator enforces compliance thresholds and further rewards\nmodels exhibiting higher compliance than their peers. We derive Nash Equilibria\ndemonstrating that rational agents will submit models exceeding the prescribed\ncompliance threshold. Empirical results show that our regulatory auction boosts\ncompliance rates by 20% and participation rates by 15% compared to baseline\nregulatory mechanisms, outperforming simpler frameworks that merely impose\nminimum compliance standards.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.CY",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.GT",
    "comment": "22 pages, 8 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.01871v2",
    "published_date": "2024-10-02 17:57:02 UTC",
    "updated_date": "2025-02-03 18:56:15 UTC"
  },
  {
    "arxiv_id": "2410.01798v3",
    "title": "Windowed MAPF with Completeness Guarantees",
    "authors": [
      "Rishi Veerapaneni",
      "Muhammad Suhail Saleem",
      "Jiaoyang Li",
      "Maxim Likhachev"
    ],
    "abstract": "Traditional multi-agent path finding (MAPF) methods try to compute entire\nstart-goal paths which are collision free. However, computing an entire path\ncan take too long for MAPF systems where agents need to replan fast. Methods\nthat address this typically employ a \"windowed\" approach and only try to find\ncollision free paths for a small windowed timestep horizon. This adaptation\ncomes at the cost of incompleteness; all current windowed approaches can become\nstuck in deadlock or livelock. Our main contribution is to introduce our\nframework, WinC-MAPF, for Windowed MAPF that enables completeness. Our\nframework uses heuristic update insights from single-agent real-time heuristic\nsearch algorithms as well as agent independence ideas from MAPF algorithms. We\nalso develop Single-Step CBS (SS-CBS), an instantiation of this framework using\na novel modification to CBS. We show how SS-CBS, which only plans a single step\nand updates heuristics, can effectively solve tough scenarios where existing\nwindowed approaches fail.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01798v3",
    "published_date": "2024-10-02 17:55:46 UTC",
    "updated_date": "2025-04-28 00:39:38 UTC"
  },
  {
    "arxiv_id": "2410.01792v2",
    "title": "When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1",
    "authors": [
      "R. Thomas McCoy",
      "Shunyu Yao",
      "Dan Friedman",
      "Mathew D. Hardy",
      "Thomas L. Griffiths"
    ],
    "abstract": "In \"Embers of Autoregression\" (McCoy et al., 2023), we showed that several\nlarge language models (LLMs) have some important limitations that are\nattributable to their origins in next-word prediction. Here we investigate\nwhether these issues persist with o1, a new system from OpenAI that differs\nfrom previous LLMs in that it is optimized for reasoning. We find that o1\nsubstantially outperforms previous LLMs in many cases, with particularly large\nimprovements on rare variants of common tasks (e.g., forming acronyms from the\nsecond letter of each word in a list, rather than the first letter). Despite\nthese quantitative improvements, however, o1 still displays the same\nqualitative trends that we observed in previous systems. Specifically, o1 --\nlike previous LLMs -- is sensitive to the probability of examples and tasks,\nperforming better and requiring fewer \"thinking tokens\" in high-probability\nsettings than in low-probability ones. These results show that optimizing a\nlanguage model for reasoning can mitigate but might not fully overcome the\nlanguage model's probability sensitivity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages; updated to fix typo in Fig 4 caption",
    "pdf_url": "http://arxiv.org/pdf/2410.01792v2",
    "published_date": "2024-10-02 17:50:19 UTC",
    "updated_date": "2024-10-04 03:57:33 UTC"
  },
  {
    "arxiv_id": "2410.01791v1",
    "title": "DreamGarden: A Designer Assistant for Growing Games from a Single Prompt",
    "authors": [
      "Sam Earle",
      "Samyak Parajuli",
      "Andrzej Banburski-Fahey"
    ],
    "abstract": "Coding assistants are increasingly leveraged in game design, both generating\ncode and making high-level plans. To what degree can these tools align with\ndeveloper workflows, and what new modes of human-computer interaction can\nemerge from their use? We present DreamGarden, an AI system capable of\nassisting with the development of diverse game environments in Unreal Engine.\nAt the core of our method is an LLM-driven planner, capable of breaking down a\nsingle, high-level prompt -- a dream, memory, or imagined scenario provided by\na human user -- into a hierarchical action plan, which is then distributed\nacross specialized submodules facilitating concrete implementation. This system\nis presented to the user as a garden of plans and actions, both growing\nindependently and responding to user intervention via seed prompts, pruning,\nand feedback. Through a user study, we explore design implications of this\nsystem, charting courses for future work in semi-autonomous assistants and\nopen-ended simulation design.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages + appendix, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01791v1",
    "published_date": "2024-10-02 17:49:07 UTC",
    "updated_date": "2024-10-02 17:49:07 UTC"
  },
  {
    "arxiv_id": "2410.01789v1",
    "title": "Investigating on RLHF methodology",
    "authors": [
      "Alexey Kutalev",
      "Sergei Markoff"
    ],
    "abstract": "In this article, we investigate the alignment of Large Language Models\naccording to human preferences. We discuss the features of training a\nPreference Model, which simulates human preferences, and the methods and\ndetails we found essential for achieving the best results. We also discuss\nusing Reinforcement Learning to fine-tune Large Language Models and describe\nthe challenges we faced and the ways to overcome them. Additionally, we present\nour experience with the Direct Preference Optimization method, which enables us\nto align a Large Language Model with human preferences without creating a\nseparate Preference Model. As our contribution, we introduce the approach for\ncollecting a preference dataset through perplexity filtering, which makes the\nprocess of creating such a dataset for a specific Language Model much easier\nand more cost-effective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.01789v1",
    "published_date": "2024-10-02 17:46:22 UTC",
    "updated_date": "2024-10-02 17:46:22 UTC"
  },
  {
    "arxiv_id": "2410.13876v1",
    "title": "Deep Knowledge Tracing for Personalized Adaptive Learning at Historically Black Colleges and Universities",
    "authors": [
      "Ming-Mu Kuo",
      "Xiangfang Li",
      "Lijun Qian",
      "Pamela Obiomon",
      "Xishuang Dong"
    ],
    "abstract": "Personalized adaptive learning (PAL) stands out by closely monitoring\nindividual students' progress and tailoring their learning paths to their\nunique knowledge and needs. A crucial technique for effective PAL\nimplementation is knowledge tracing, which models students' evolving knowledge\nto predict their future performance. Recent advancements in deep learning have\nsignificantly enhanced knowledge tracing through Deep Knowledge Tracing (DKT).\nHowever, there is limited research on DKT for Science, Technology, Engineering,\nand Math (STEM) education at Historically Black Colleges and Universities\n(HBCUs). This study builds a comprehensive dataset to investigate DKT for\nimplementing PAL in STEM education at HBCUs, utilizing multiple\nstate-of-the-art (SOTA) DKT models to examine knowledge tracing performance.\nThe dataset includes 352,148 learning records for 17,181 undergraduate students\nacross eight colleges at Prairie View A&M University (PVAMU). The SOTA DKT\nmodels employed include DKT, DKT+, DKVMN, SAKT, and KQN. Experimental results\ndemonstrate the effectiveness of DKT models in accurately predicting students'\nacademic outcomes. Specifically, the SAKT and KQN models outperform others in\nterms of accuracy and AUC. These findings have significant implications for\nfaculty members and academic advisors, providing valuable insights for\nidentifying students at risk of academic underperformance before the end of the\nsemester. Furthermore, this allows for proactive interventions to support\nstudents' academic progress, potentially enhancing student retention and\ngraduation rates.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13876v1",
    "published_date": "2024-10-02 17:42:59 UTC",
    "updated_date": "2024-10-02 17:42:59 UTC"
  },
  {
    "arxiv_id": "2410.01782v1",
    "title": "Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models",
    "authors": [
      "Shayekh Bin Islam",
      "Md Asib Rahman",
      "K S M Tozammel Hossain",
      "Enamul Hoque",
      "Shafiq Joty",
      "Md Rizwan Parvez"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has been shown to enhance the factual\naccuracy of Large Language Models (LLMs), but existing methods often suffer\nfrom limited reasoning capabilities in effectively using the retrieved\nevidence, particularly when using open-source LLMs. To mitigate this gap, we\nintroduce a novel framework, Open-RAG, designed to enhance reasoning\ncapabilities in RAG with open-source LLMs. Our framework transforms an\narbitrary dense LLM into a parameter-efficient sparse mixture of experts (MoE)\nmodel capable of handling complex reasoning tasks, including both single- and\nmulti-hop queries. Open-RAG uniquely trains the model to navigate challenging\ndistractors that appear relevant but are misleading. As a result, Open-RAG\nleverages latent learning, dynamically selecting relevant experts and\nintegrating external knowledge effectively for more accurate and contextually\nrelevant responses. In addition, we propose a hybrid adaptive retrieval method\nto determine retrieval necessity and balance the trade-off between performance\ngain and inference speed. Experimental results show that the Llama2-7B-based\nOpen-RAG outperforms state-of-the-art LLMs and RAG models such as ChatGPT,\nSelf-RAG, and Command R+ in various knowledge-intensive tasks. We open-source\nour code and models at https://openragmoe.github.io/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Findings. Website:\n  https://openragmoe.github.io/. 14 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.01782v1",
    "published_date": "2024-10-02 17:37:18 UTC",
    "updated_date": "2024-10-02 17:37:18 UTC"
  },
  {
    "arxiv_id": "2410.01779v3",
    "title": "Composing Global Optimizers to Reasoning Tasks via Algebraic Objects in Neural Nets",
    "authors": [
      "Yuandong Tian"
    ],
    "abstract": "We prove rich algebraic structures of the solution space for 2-layer neural\nnetworks with quadratic activation and $L_2$ loss, trained on reasoning tasks\nin Abelian group (e.g., modular addition). Such a rich structure enables\nanalytical construction of global optimal solutions from partial solutions that\nonly satisfy part of the loss, despite its high nonlinearity. We coin the\nframework as CoGO (Composing Global Optimizers). Specifically, we show that the\nweight space over different numbers of hidden nodes of the 2-layer network is\nequipped with a semi-ring algebraic structure, and the loss function to be\noptimized consists of monomial potentials, which are ring homomorphism,\nallowing partial solutions to be composed into global ones by ring addition and\nmultiplication. Our experiments show that around $95\\%$ of the solutions\nobtained by gradient descent match exactly our theoretical constructions.\nAlthough the global optimizers constructed only required a small number of\nhidden nodes, our analysis on gradient dynamics shows that\nover-parameterization asymptotically decouples training dynamics and is\nbeneficial. We further show that training dynamics favors simpler solutions\nunder weight decay, and thus high-order global optimizers such as perfect\nmemorization are unfavorable. Code can be found at\nhttps://github.com/facebookresearch/luckmatters/tree/yuandong3/ssl/real-dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.AC",
      "math.RA"
    ],
    "primary_category": "cs.LG",
    "comment": "Update presentation and add more lemmas for necessary conditions",
    "pdf_url": "http://arxiv.org/pdf/2410.01779v3",
    "published_date": "2024-10-02 17:33:26 UTC",
    "updated_date": "2024-12-03 20:19:54 UTC"
  },
  {
    "arxiv_id": "2410.01772v1",
    "title": "DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning",
    "authors": [
      "Yebowen Hu",
      "Xiaoyang Wang",
      "Wenlin Yao",
      "Yiming Lu",
      "Daoan Zhang",
      "Hassan Foroosh",
      "Dong Yu",
      "Fei Liu"
    ],
    "abstract": "LLMs are ideal for decision-making due to their ability to reason over long\ncontexts and identify critical factors. However, challenges arise when\nprocessing transcripts of spoken speech describing complex scenarios. These\ntranscripts often contain ungrammatical or incomplete sentences, repetitions,\nhedging, and vagueness. For example, during a company's earnings call, an\nexecutive might project a positive revenue outlook to reassure investors,\ndespite significant uncertainty regarding future earnings. It is crucial for\nLLMs to incorporate this uncertainty systematically when making decisions. In\nthis paper, we introduce DeFine, a new framework that constructs probabilistic\nfactor profiles from complex scenarios. DeFine then integrates these profiles\nwith analogical reasoning, leveraging insights from similar past experiences to\nguide LLMs in making critical decisions in novel situations. Our framework\nseparates the tasks of quantifying uncertainty in complex scenarios and\nincorporating it into LLM decision-making. This approach is particularly useful\nin fields such as medical consultations, negotiations, and political debates,\nwhere making decisions under uncertainty is vital.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01772v1",
    "published_date": "2024-10-02 17:29:34 UTC",
    "updated_date": "2024-10-02 17:29:34 UTC"
  },
  {
    "arxiv_id": "2410.01869v1",
    "title": "Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement",
    "authors": [
      "Shouvon Sarker",
      "Xishuang Dong",
      "Xiangfang Li",
      "Lijun Qian"
    ],
    "abstract": "Text-to-SQLs enables non-expert users to effortlessly retrieve desired\ninformation from relational databases using natural language queries. While\nrecent advancements, particularly with Large Language Models (LLMs) like GPT\nand T5, have shown impressive performance on large-scale benchmarks such as\nBIRD, current state-of-the-art (SOTA) LLM-based Text-to-SQLs models often\nrequire significant efforts to develop auxiliary tools like SQL classifiers to\nachieve high performance. This paper proposed a novel approach that only needs\nSQL Quality Measurement to enhance LLMs-based Text-to-SQLs performance. It\nestablishes a SQL quality evaluation mechanism to assess the generated SQL\nqueries against predefined criteria and actual database responses. This\nfeedback loop enables continuous learning and refinement of model outputs based\non both syntactic correctness and semantic accuracy. The proposed method\nundergoes comprehensive validation on the BIRD benchmark, assessing Execution\nAccuracy (EX) and Valid Efficiency Score (VES) across various Text-to-SQLs\ndifficulty levels. Experimental results reveal competitive performance in both\nEX and VES compared to SOTA models like GPT4 and T5.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01869v1",
    "published_date": "2024-10-02 17:21:51 UTC",
    "updated_date": "2024-10-02 17:21:51 UTC"
  },
  {
    "arxiv_id": "2410.01739v2",
    "title": "Mimicking Human Intuition: Cognitive Belief-Driven Q-Learning",
    "authors": [
      "Xingrui Gu",
      "Guanren Qiao",
      "Chuyi Jiang",
      "Tianqing Xia",
      "Hangyu Mao"
    ],
    "abstract": "Reinforcement learning encounters challenges in various environments related\nto robustness and explainability. Traditional Q-learning algorithms cannot\neffectively make decisions and utilize the historical learning experience. To\novercome these limitations, we propose Cognitive Belief-Driven Q-Learning\n(CBDQ), which integrates subjective belief modeling into the Q-learning\nframework, enhancing decision-making accuracy by endowing agents with\nhuman-like learning and reasoning capabilities. Drawing inspiration from\ncognitive science, our method maintains a subjective belief distribution over\nthe expectation of actions, leveraging a cluster-based subjective belief model\nthat enables agents to reason about the potential probability associated with\neach decision. CBDQ effectively mitigates overestimated phenomena and optimizes\ndecision-making policies by integrating historical experiences with current\ncontextual information, mimicking the dynamics of human decision-making. We\nevaluate the proposed method on discrete control benchmark tasks in various\ncomplicate environments. The results demonstrate that CBDQ exhibits stronger\nadaptability, robustness, and human-like characteristics in handling these\nenvironments, outperforming other baselines. We hope this work will give\nresearchers a fresh perspective on understanding and explaining Q-learning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01739v2",
    "published_date": "2024-10-02 16:50:29 UTC",
    "updated_date": "2024-10-03 23:18:17 UTC"
  },
  {
    "arxiv_id": "2410.01738v2",
    "title": "VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models",
    "authors": [
      "Kailai Feng",
      "Yabo Zhang",
      "Haodong Yu",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Hongzhi Zhang",
      "Wangmeng Zuo"
    ],
    "abstract": "Artistic typography is a technique to visualize the meaning of input\ncharacter in an imaginable and readable manner. With powerful text-to-image\ndiffusion models, existing methods directly design the overall geometry and\ntexture of input character, making it challenging to ensure both creativity and\nlegibility. In this paper, we introduce a dual-branch and training-free method,\nnamely VitaGlyph, enabling flexible artistic typography along with controllable\ngeometry change to maintain the readability. The key insight of VitaGlyph is to\ntreat input character as a scene composed of Subject and Surrounding, followed\nby rendering them under varying degrees of geometry transformation. The subject\nflexibly expresses the essential concept of input character, while the\nsurrounding enriches relevant background without altering the shape.\nSpecifically, we implement VitaGlyph through a three-phase framework: (i)\nKnowledge Acquisition leverages large language models to design text\ndescriptions of subject and surrounding. (ii) Regional decomposition detects\nthe part that most matches the subject description and divides input glyph\nimage into subject and surrounding regions. (iii) Typography Stylization\nfirstly refines the structure of subject region via Semantic Typography, and\nthen separately renders the textures of Subject and Surrounding regions through\nControllable Compositional Generation. Experimental results demonstrate that\nVitaGlyph not only achieves better artistry and readability, but also manages\nto depict multiple customize concepts, facilitating more creative and pleasing\nartistic typography generation. Our code will be made publicly at\nhttps://github.com/Carlofkl/VitaGlyph.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "https://github.com/Carlofkl/VitaGlyph",
    "pdf_url": "http://arxiv.org/pdf/2410.01738v2",
    "published_date": "2024-10-02 16:48:47 UTC",
    "updated_date": "2024-11-25 09:46:45 UTC"
  },
  {
    "arxiv_id": "2410.01729v1",
    "title": "Evaluating Robustness of Reward Models for Mathematical Reasoning",
    "authors": [
      "Sunghwan Kim",
      "Dongjin Kang",
      "Taeyoon Kwon",
      "Hyungjoo Chae",
      "Jungsoo Won",
      "Dongha Lee",
      "Jinyoung Yeo"
    ],
    "abstract": "Reward models are key in reinforcement learning from human feedback (RLHF)\nsystems, aligning the model behavior with human preferences. Particularly in\nthe math domain, there have been plenty of studies using reward models to align\npolicies for improving reasoning capabilities. Recently, as the importance of\nreward models has been emphasized, RewardBench is proposed to understand their\nbehavior. However, we figure out that the math subset of RewardBench has\ndifferent representations between chosen and rejected completions, and relies\non a single comparison, which may lead to unreliable results as it only see an\nisolated case. Therefore, it fails to accurately present the robustness of\nreward models, leading to a misunderstanding of its performance and potentially\nresulting in reward hacking. In this work, we introduce a new design for\nreliable evaluation of reward models, and to validate this, we construct\nRewardMATH, a benchmark that effectively represents the robustness of reward\nmodels in mathematical reasoning tasks. We demonstrate that the scores on\nRewardMATH strongly correlate with the results of optimized policy and\neffectively estimate reward overoptimization, whereas the existing benchmark\nshows almost no correlation. The results underscore the potential of our design\nto enhance the reliability of evaluation, and represent the robustness of\nreward model. We make our code and data publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2410.01729v1",
    "published_date": "2024-10-02 16:39:58 UTC",
    "updated_date": "2024-10-02 16:39:58 UTC"
  },
  {
    "arxiv_id": "2410.03769v2",
    "title": "SciSafeEval: A Comprehensive Benchmark for Safety Alignment of Large Language Models in Scientific Tasks",
    "authors": [
      "Tianhao Li",
      "Jingyu Lu",
      "Chuangxin Chu",
      "Tianyu Zeng",
      "Yujia Zheng",
      "Mei Li",
      "Haotian Huang",
      "Bin Wu",
      "Zuoxian Liu",
      "Kai Ma",
      "Xuejing Yuan",
      "Xingkai Wang",
      "Keyan Ding",
      "Huajun Chen",
      "Qiang Zhang"
    ],
    "abstract": "Large language models (LLMs) have a transformative impact on a variety of\nscientific tasks across disciplines including biology, chemistry, medicine, and\nphysics. However, ensuring the safety alignment of these models in scientific\nresearch remains an underexplored area, with existing benchmarks primarily\nfocusing on textual content and overlooking key scientific representations such\nas molecular, protein, and genomic languages. Moreover, the safety mechanisms\nof LLMs in scientific tasks are insufficiently studied. To address these\nlimitations, we introduce SciSafeEval, a comprehensive benchmark designed to\nevaluate the safety alignment of LLMs across a range of scientific tasks.\nSciSafeEval spans multiple scientific languages-including textual, molecular,\nprotein, and genomic-and covers a wide range of scientific domains. We evaluate\nLLMs in zero-shot, few-shot and chain-of-thought settings, and introduce a\n\"jailbreak\" enhancement feature that challenges LLMs equipped with safety\nguardrails, rigorously testing their defenses against malicious intention. Our\nbenchmark surpasses existing safety datasets in both scale and scope, providing\na robust platform for assessing the safety and performance of LLMs in\nscientific contexts. This work aims to facilitate the responsible development\nand deployment of LLMs, promoting alignment with safety and ethical standards\nin scientific research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03769v2",
    "published_date": "2024-10-02 16:34:48 UTC",
    "updated_date": "2024-12-16 12:57:23 UTC"
  },
  {
    "arxiv_id": "2410.01724v1",
    "title": "Auto-Demo Prompting: Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting",
    "authors": [
      "Longyu Feng",
      "Mengze Hong",
      "Chen Jason Zhang"
    ],
    "abstract": "Batch prompting is a common technique in large language models (LLMs) used to\nprocess multiple inputs simultaneously, aiming to improve computational\nefficiency. However, as batch sizes increase, performance degradation often\noccurs due to the model's difficulty in handling lengthy context inputs.\nExisting methods that attempt to mitigate these issues rely solely on batch\ndata arrangement and majority voting rather than improving the design of the\nbatch prompt itself. In this paper, we address these limitations by proposing\n\"Auto-Demo Prompting,\" a novel approach that leverages the question-output\npairs from earlier questions within a batch as demonstrations for subsequent\nanswer inference. We provide a formal theoretical analysis of how Auto-Demo\nPrompting functions within the autoregressive generation process of LLMs,\nillustrating how it utilizes prior outputs to optimize the model's internal\nrepresentations. Our method effectively bridges the gap between batch prompting\nand few-shot prompting, enhancing performance with only a slight compromise in\ntoken usage. Experimental results across five NLP tasks demonstrate its\neffectiveness in mitigating performance degradation and occasionally\noutperforming single prompts. Furthermore, it opens new avenues for applying\nfew-shot learning techniques, such as demonstration selection, within batch\nprompting, making it a robust solution for real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01724v1",
    "published_date": "2024-10-02 16:34:40 UTC",
    "updated_date": "2024-10-02 16:34:40 UTC"
  },
  {
    "arxiv_id": "2410.12831v1",
    "title": "Segment as You Wish -- Free-Form Language-Based Segmentation for Medical Images",
    "authors": [
      "Longchao Da",
      "Rui Wang",
      "Xiaojian Xu",
      "Parminder Bhatia",
      "Taha Kass-Hout",
      "Hua Wei",
      "Cao Xiao"
    ],
    "abstract": "Medical imaging is crucial for diagnosing a patient's health condition, and\naccurate segmentation of these images is essential for isolating regions of\ninterest to ensure precise diagnosis and treatment planning. Existing methods\nprimarily rely on bounding boxes or point-based prompts, while few have\nexplored text-related prompts, despite clinicians often describing their\nobservations and instructions in natural language. To address this gap, we\nfirst propose a RAG-based free-form text prompt generator, that leverages the\ndomain corpus to generate diverse and realistic descriptions. Then, we\nintroduce FLanS, a novel medical image segmentation model that handles various\nfree-form text prompts, including professional anatomy-informed queries,\nanatomy-agnostic position-driven queries, and anatomy-agnostic size-driven\nqueries. Additionally, our model also incorporates a symmetry-aware\ncanonicalization module to ensure consistent, accurate segmentations across\nvarying scan orientations and reduce confusion between the anatomical position\nof an organ and its appearance in the scan. FLanS is trained on a large-scale\ndataset of over 100k medical images from 7 public datasets. Comprehensive\nexperiments demonstrate the model's superior language understanding and\nsegmentation precision, along with a deep comprehension of the relationship\nbetween them, outperforming SOTA baselines on both in-domain and out-of-domain\ndatasets.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12831v1",
    "published_date": "2024-10-02 16:34:32 UTC",
    "updated_date": "2024-10-02 16:34:32 UTC"
  },
  {
    "arxiv_id": "2410.01720v3",
    "title": "Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective",
    "authors": [
      "Zeyu Gan",
      "Yong Liu"
    ],
    "abstract": "Synthetic data has become a pivotal resource in post-training tasks for large\nlanguage models (LLMs) due to the scarcity of high-quality, specific data.\nWhile various methods have been developed to generate synthetic data, there\nremains a discernible gap between the practical effects of synthetic data and\nour theoretical comprehension. To address this challenge, we commence by\npresenting a detailed modeling of the prevalent synthetic data generation\nprocess. Building upon this modeling, we demonstrate that the generalization\ncapability of the post-trained model is critically determined by the\ninformation gain derived from the generative model, as analyzed from a novel\nreverse-bottleneck perspective. Moreover, we introduce the concept of\nGeneralization Gain via Mutual Information (GGMI) and elucidate the\nrelationship between generalization gain and information gain. This analysis\nserves as a theoretical foundation for synthetic data generation and further\nhighlights its connection with the generalization capability of post-trained\nmodels, offering an understanding about the design of synthetic data generation\ntechniques and the optimization of the post-training process. We open-source\nour code at\nhttps://github.com/ZyGan1999/Towards-a-Theoretical-Understanding-of-Synthetic-Data-in-LLM-Post-Training.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01720v3",
    "published_date": "2024-10-02 16:32:05 UTC",
    "updated_date": "2025-02-06 06:42:17 UTC"
  },
  {
    "arxiv_id": "2410.01707v3",
    "title": "Interpretable Contrastive Monte Carlo Tree Search Reasoning",
    "authors": [
      "Zitian Gao",
      "Boye Niu",
      "Xuzheng He",
      "Haotian Xu",
      "Hongzhang Liu",
      "Aiwei Liu",
      "Xuming Hu",
      "Lijie Wen"
    ],
    "abstract": "We propose SC-MCTS*: a novel Monte Carlo Tree Search (MCTS) reasoning\nalgorithm for Large Language Models (LLMs), significantly improves both\nreasoning accuracy and speed. Our motivation comes from: 1. Previous MCTS LLM\nreasoning works often overlooked its biggest drawback--slower speed compared to\nCoT; 2. Previous research mainly used MCTS as a tool for LLM reasoning on\nvarious tasks with limited quantitative analysis or ablation studies of its\ncomponents from reasoning interpretability perspective. 3. The reward model is\nthe most crucial component in MCTS, however previous work has rarely conducted\nin-depth study or improvement of MCTS's reward models. Thus, we conducted\nextensive ablation studies and quantitative analysis on components of MCTS,\nrevealing the impact of each component on the MCTS reasoning performance of\nLLMs. Building on this, (i) we designed a highly interpretable reward model\nbased on the principle of contrastive decoding and (ii) achieved an average\nspeed improvement of 51.9% per node using speculative decoding. Additionally,\n(iii) we improved UCT node selection strategy and backpropagation used in\nprevious works, resulting in significant performance improvement. We\noutperformed o1-mini by an average of 17.4% on the Blocksworld multi-step\nreasoning dataset using Llama-3.1-70B with SC-MCTS*. Our code is available at\nhttps://github.com/zitian-gao/SC-MCTS.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01707v3",
    "published_date": "2024-10-02 16:15:31 UTC",
    "updated_date": "2024-12-25 13:32:54 UTC"
  },
  {
    "arxiv_id": "2410.01706v4",
    "title": "Sable: a Performant, Efficient and Scalable Sequence Model for MARL",
    "authors": [
      "Omayma Mahjoub",
      "Sasha Abramowitz",
      "Ruan de Kock",
      "Wiem Khlifi",
      "Simon du Toit",
      "Jemma Daniel",
      "Louay Ben Nessir",
      "Louise Beyers",
      "Claude Formanek",
      "Liam Clark",
      "Arnu Pretorius"
    ],
    "abstract": "As multi-agent reinforcement learning (MARL) progresses towards solving\nlarger and more complex problems, it becomes increasingly important that\nalgorithms exhibit the key properties of (1) strong performance, (2) memory\nefficiency and (3) scalability. In this work, we introduce Sable, a performant,\nmemory efficient and scalable sequence modeling approach to MARL. Sable works\nby adapting the retention mechanism in Retentive Networks (Sun et al., 2023) to\nachieve computationally efficient processing of multi-agent observations with\nlong context memory for temporal reasoning. Through extensive evaluations\nacross six diverse environments, we demonstrate how Sable is able to\nsignificantly outperform existing state-of-the-art methods in a large number of\ndiverse tasks (34 out of 45 tested). Furthermore, Sable maintains performance\nas we scale the number of agents, handling environments with more than a\nthousand agents while exhibiting a linear increase in memory usage. Finally, we\nconduct ablation studies to isolate the source of Sable's performance gains and\nconfirm its efficient computational memory usage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01706v4",
    "published_date": "2024-10-02 16:15:26 UTC",
    "updated_date": "2025-03-17 18:39:11 UTC"
  },
  {
    "arxiv_id": "2410.01696v1",
    "title": "CreDes: Causal Reasoning Enhancement and Dual-End Searching for Solving Long-Range Reasoning Problems using LLMs",
    "authors": [
      "Kangsheng Wang",
      "Xiao Zhang",
      "Hao Liu",
      "Songde Han",
      "Huimin Ma",
      "Tianyu Hu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated limitations in handling\ncombinatorial optimization problems involving long-range reasoning, partially\ndue to causal hallucinations and huge search space. As for causal\nhallucinations, i.e., the inconsistency between reasoning and corresponding\nstate transition, this paper introduces the Causal Relationship Enhancement\n(CRE) mechanism combining cause-effect interventions and the Individual\nTreatment Effect (ITE) to guarantee the solid causal rightness between each\nstep of reasoning and state transition. As for the long causal range and huge\nsearch space limiting the performances of existing models featuring\nsingle-direction search, a Dual-End Searching (DES) approach is proposed to\nseek solutions by simultaneously starting from both the initial and goal states\non the causal probability tree. By integrating CRE and DES (CreDes), our model\nhas realized simultaneous multi-step reasoning, circumventing the\ninefficiencies from cascading multiple one-step reasoning like the\nChain-of-Thought (CoT). Experiments demonstrate that CreDes significantly\noutperforms existing State-Of-The-Art (SOTA) solutions in long-range reasoning\ntasks in terms of both accuracy and time efficiency.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01696v1",
    "published_date": "2024-10-02 16:05:01 UTC",
    "updated_date": "2024-10-02 16:05:01 UTC"
  },
  {
    "arxiv_id": "2410.01695v3",
    "title": "From Prohibition to Adoption: How Hong Kong Universities Are Navigating ChatGPT in Academic Workflows",
    "authors": [
      "Junjun Huang",
      "Jifan Wu",
      "Qing Wang",
      "Kemeng Yuan",
      "Jiefeng Li",
      "Di Lu"
    ],
    "abstract": "This paper aims at comparing the time when Hong Kong universities used to ban\nChatGPT to the current periods where it has become integrated in the academic\nprocesses. Bolted by concerns of integrity and ethical issues in technologies,\ninstitutions have adapted by moving towards the center adopting AI literacy and\nresponsibility policies. This study examines new paradigms which have been\ndeveloped to help implement these positives while preventing negative effects\non academia. Keywords: ChatGPT, Academic Integrity, AI Literacy, Ethical AI\nUse, Generative AI in Education, University Policy, AI Integration in Academia,\nHigher Education and Technology",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01695v3",
    "published_date": "2024-10-02 16:04:33 UTC",
    "updated_date": "2024-10-20 09:22:01 UTC"
  },
  {
    "arxiv_id": "2410.01692v2",
    "title": "U-shaped and Inverted-U Scaling behind Emergent Abilities of Large Language Models",
    "authors": [
      "Tung-Yu Wu",
      "Pei-Yu Lo"
    ],
    "abstract": "Large language models (LLMs) have been shown to exhibit emergent abilities in\nsome downstream tasks, where model performance stagnates at first and then\nimproves sharply and unpredictably with scale beyond a threshold. In this work,\nwe investigate the phenomenon by grouping questions based on difficulty level\nand provide a possible explanation for emergent abilities. Specifically, we\nobserve U-shaped scaling for hard questions and inverted-U scaling followed by\nsteady improvement for easy questions. The two scaling patterns initially\noffset each other, causing stagnant overall performance. The performance starts\nto soar when the scaling pattern of easy questions reverts from inverse to\nstandard scaling, leading to emergent abilities. Based on this finding, we\npropose a simple yet effective pipeline, called Slice-and-Sandwich, to predict\nthe emergence threshold and model performance beyond the threshold. Our code is\npublicly available at https://github.com/tony10101105/ExpEmergence.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01692v2",
    "published_date": "2024-10-02 16:03:49 UTC",
    "updated_date": "2025-02-12 13:03:09 UTC"
  },
  {
    "arxiv_id": "2410.01691v1",
    "title": "FactAlign: Long-form Factuality Alignment of Large Language Models",
    "authors": [
      "Chao-Wei Huang",
      "Yun-Nung Chen"
    ],
    "abstract": "Large language models have demonstrated significant potential as the\nnext-generation information access engines. However, their reliability is\nhindered by issues of hallucination and generating non-factual content. This is\nparticularly problematic in long-form responses, where assessing and ensuring\nfactual accuracy is complex. In this paper, we address this gap by proposing\nFactAlign, a novel alignment framework designed to enhance the factuality of\nLLMs' long-form responses while maintaining their helpfulness. We introduce\nfKTO, a fine-grained, sentence-level alignment algorithm that extends the\nKahneman-Tversky Optimization (KTO) alignment method. Leveraging recent\nadvances in automatic factuality evaluation, FactAlign utilizes fine-grained\nfactuality assessments to guide the alignment process. Our experiments on\nopen-domain prompts and information-seeking questions demonstrate that\nFactAlign significantly improves the factual accuracy of LLM responses while\nalso improving their helpfulness. Further analyses identify that FactAlign is\ncapable of training LLMs to provide more information without losing factual\nprecision, thus improving the factual F1 score. Our source code, datasets, and\ntrained models are publicly available at https://github.com/MiuLab/FactAlign",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.01691v1",
    "published_date": "2024-10-02 16:03:13 UTC",
    "updated_date": "2024-10-02 16:03:13 UTC"
  },
  {
    "arxiv_id": "2410.01690v1",
    "title": "Why context matters in VQA and Reasoning: Semantic interventions for VLM input modalities",
    "authors": [
      "Kenza Amara",
      "Lukas Klein",
      "Carsten Lüth",
      "Paul Jäger",
      "Hendrik Strobelt",
      "Mennatallah El-Assady"
    ],
    "abstract": "The various limitations of Generative AI, such as hallucinations and model\nfailures, have made it crucial to understand the role of different modalities\nin Visual Language Model (VLM) predictions. Our work investigates how the\nintegration of information from image and text modalities influences the\nperformance and behavior of VLMs in visual question answering (VQA) and\nreasoning tasks. We measure this effect through answer accuracy, reasoning\nquality, model uncertainty, and modality relevance. We study the interplay\nbetween text and image modalities in different configurations where visual\ncontent is essential for solving the VQA task. Our contributions include (1)\nthe Semantic Interventions (SI)-VQA dataset, (2) a benchmark study of various\nVLM architectures under different modality configurations, and (3) the\nInteractive Semantic Interventions (ISI) tool. The SI-VQA dataset serves as the\nfoundation for the benchmark, while the ISI tool provides an interface to test\nand apply semantic interventions in image and text inputs, enabling more\nfine-grained analysis. Our results show that complementary information between\nmodalities improves answer and reasoning quality, while contradictory\ninformation harms model performance and confidence. Image text annotations have\nminimal impact on accuracy and uncertainty, slightly increasing image\nrelevance. Attention analysis confirms the dominant role of image inputs over\ntext in VQA tasks. In this study, we evaluate state-of-the-art VLMs that allow\nus to extract attention coefficients for each modality. A key finding is\nPaliGemma's harmful overconfidence, which poses a higher risk of silent\nfailures compared to the LLaVA models. This work sets the foundation for\nrigorous analysis of modality integration, supported by datasets specifically\ndesigned for this purpose.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01690v1",
    "published_date": "2024-10-02 16:02:02 UTC",
    "updated_date": "2024-10-02 16:02:02 UTC"
  },
  {
    "arxiv_id": "2410.01687v2",
    "title": "Uncertainty Quantification with Bayesian Higher Order ReLU KANs",
    "authors": [
      "James Giroux",
      "Cristiano Fanelli"
    ],
    "abstract": "We introduce the first method of uncertainty quantification in the domain of\nKolmogorov-Arnold Networks, specifically focusing on (Higher Order) ReLUKANs to\nenhance computational efficiency given the computational demands of Bayesian\nmethods. The method we propose is general in nature, providing access to both\nepistemic and aleatoric uncertainties. It is also capable of generalization to\nother various basis functions. We validate our method through a series of\nclosure tests, including simple one-dimensional functions and application to\nthe domain of (Stochastic) Partial Differential Equations. Referring to the\nlatter, we demonstrate the method's ability to correctly identify functional\ndependencies introduced through the inclusion of a stochastic term. The code\nsupporting this work can be found at\nhttps://github.com/wmdataphys/Bayesian-HR-KAN",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01687v2",
    "published_date": "2024-10-02 15:57:18 UTC",
    "updated_date": "2024-10-03 02:21:38 UTC"
  },
  {
    "arxiv_id": "2410.01686v2",
    "title": "Positional Attention: Expressivity and Learnability of Algorithmic Computation",
    "authors": [
      "Artur Back de Luca",
      "George Giapitzakis",
      "Shenghao Yang",
      "Petar Veličković",
      "Kimon Fountoulakis"
    ],
    "abstract": "There is a growing interest in the ability of neural networks to execute\nalgorithmic tasks (e.g., arithmetic, summary statistics, and sorting). The goal\nof this work is to better understand the role of attention in Transformers for\nalgorithmic execution. Its importance for algorithmic execution has been\nstudied theoretically and empirically using parallel computational models.\nNotably, many parallel algorithms communicate between processors solely using\npositional information. Inspired by this observation, we investigate how\nTransformers can execute algorithms using positional attention, where attention\nweights depend exclusively on positional encodings. We prove that Transformers\nwith positional attention (positional Transformers) maintain the same\nexpressivity of parallel computational models, incurring a logarithmic depth\ncost relative to the input length. We analyze their in-distribution\nlearnability and explore how parameter norms in positional attention affect\nsample complexity. Our results show that positional Transformers introduce a\nlearning trade-off: while they exhibit better theoretical dependence on\nparameter norms, certain tasks may require more layers, which can, in turn,\nincrease sample complexity. Finally, we empirically explore the\nout-of-distribution performance of positional Transformers and find that they\nperform well in tasks where their underlying algorithmic solution relies on\npositional information.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "64 pages, 37 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01686v2",
    "published_date": "2024-10-02 15:55:08 UTC",
    "updated_date": "2025-02-01 04:14:51 UTC"
  },
  {
    "arxiv_id": "2410.01680v1",
    "title": "PHI-S: Distribution Balancing for Label-Free Multi-Teacher Distillation",
    "authors": [
      "Mike Ranzinger",
      "Jon Barker",
      "Greg Heinrich",
      "Pavlo Molchanov",
      "Bryan Catanzaro",
      "Andrew Tao"
    ],
    "abstract": "Various visual foundation models have distinct strengths and weaknesses, both\nof which can be improved through heterogeneous multi-teacher knowledge\ndistillation without labels, termed \"agglomerative models.\" We build upon this\nbody of work by studying the effect of the teachers' activation statistics,\nparticularly the impact of the loss function on the resulting student model\nquality. We explore a standard toolkit of statistical normalization techniques\nto better align the different distributions and assess their effects. Further,\nwe examine the impact on downstream teacher-matching metrics, which motivates\nthe use of Hadamard matrices. With these matrices, we demonstrate useful\nproperties, showing how they can be used for isotropic standardization, where\neach dimension of a multivariate distribution is standardized using the same\nscale. We call this technique \"PHI Standardization\" (PHI-S) and empirically\ndemonstrate that it produces the best student model across the suite of methods\nstudied.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01680v1",
    "published_date": "2024-10-02 15:50:35 UTC",
    "updated_date": "2024-10-02 15:50:35 UTC"
  },
  {
    "arxiv_id": "2410.01677v3",
    "title": "Mind Scramble: Unveiling Large Language Model Psychology Via Typoglycemia",
    "authors": [
      "Miao Yu",
      "Junyuan Mao",
      "Guibin Zhang",
      "Jingheng Ye",
      "Junfeng Fang",
      "Aoxiao Zhong",
      "Yang Liu",
      "Yuxuan Liang",
      "Kun Wang",
      "Qingsong Wen"
    ],
    "abstract": "Research into the external behaviors and internal mechanisms of large\nlanguage models (LLMs) has shown promise in addressing complex tasks in the\nphysical world. Studies suggest that powerful LLMs, like GPT-4, are beginning\nto exhibit human-like cognitive abilities, including planning, reasoning, and\nreflection. In this paper, we introduce a research line and methodology called\nLLM Psychology, leveraging human psychology experiments to investigate the\ncognitive behaviors and mechanisms of LLMs. We migrate the Typoglycemia\nphenomenon from psychology to explore the \"mind\" of LLMs. Unlike human brains,\nwhich rely on context and word patterns to comprehend scrambled text, LLMs use\ndistinct encoding and decoding processes. Through Typoglycemia experiments at\nthe character, word, and sentence levels, we observe: (I) LLMs demonstrate\nhuman-like behaviors on a macro scale, such as lower task accuracy and higher\ntoken/time consumption; (II) LLMs exhibit varying robustness to scrambled\ninput, making Typoglycemia a benchmark for model evaluation without new\ndatasets; (III) Different task types have varying impacts, with complex logical\ntasks (e.g., math) being more challenging in scrambled form; (IV) Each LLM has\na unique and consistent \"cognitive pattern\" across tasks, revealing general\nmechanisms in its psychology process. We provide an in-depth analysis of hidden\nlayers to explain these phenomena, paving the way for future research in LLM\nPsychology and deeper interpretability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01677v3",
    "published_date": "2024-10-02 15:47:25 UTC",
    "updated_date": "2024-10-24 02:49:36 UTC"
  },
  {
    "arxiv_id": "2410.01675v1",
    "title": "Trying to be human: Linguistic traces of stochastic empathy in language models",
    "authors": [
      "Bennett Kleinberg",
      "Jari Zegers",
      "Jonas Festor",
      "Stefana Vida",
      "Julian Präsent",
      "Riccardo Loconte",
      "Sanne Peereboom"
    ],
    "abstract": "Differentiating between generated and human-written content is important for\nnavigating the modern world. Large language models (LLMs) are crucial drivers\nbehind the increased quality of computer-generated content. Reportedly, humans\nfind it increasingly difficult to identify whether an AI model generated a\npiece of text. Our work tests how two important factors contribute to the human\nvs AI race: empathy and an incentive to appear human. We address both aspects\nin two experiments: human participants and a state-of-the-art LLM wrote\nrelationship advice (Study 1, n=530) or mere descriptions (Study 2, n=610),\neither instructed to be as human as possible or not. New samples of humans\n(n=428 and n=408) then judged the texts' source. Our findings show that when\nempathy is required, humans excel. Contrary to expectations, instructions to\nappear human were only effective for the LLM, so the human advantage\ndiminished. Computational text analysis revealed that LLMs become more human\nbecause they may have an implicit representation of what makes a text human and\neffortlessly apply these heuristics. The model resorts to a conversational,\nself-referential, informal tone with a simpler vocabulary to mimic stochastic\nempathy. We discuss these findings in light of recent claims on the on-par\nperformance of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.01675v1",
    "published_date": "2024-10-02 15:46:40 UTC",
    "updated_date": "2024-10-02 15:46:40 UTC"
  },
  {
    "arxiv_id": "2410.01671v2",
    "title": "Bridging Context Gaps: Leveraging Coreference Resolution for Long Contextual Understanding",
    "authors": [
      "Yanming Liu",
      "Xinyue Peng",
      "Jiannan Cao",
      "Shi Bo",
      "Yanxin Shen",
      "Tianyu Du",
      "Sheng Cheng",
      "Xun Wang",
      "Jianwei Yin",
      "Xuhong Zhang"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in natural\nlanguage processing; however, they still face difficulties when tasked with\nunderstanding lengthy contexts and executing effective question answering.\nThese challenges often arise due to the complexity and ambiguity present in\nlonger texts. To enhance the performance of LLMs in such scenarios, we\nintroduce the Long Question Coreference Adaptation (LQCA) method. This\ninnovative framework focuses on coreference resolution tailored to long\ncontexts, allowing the model to identify and manage references effectively. The\nLQCA method encompasses four key steps: resolving coreferences within\nsub-documents, computing the distances between mentions, defining a\nrepresentative mention for coreference, and answering questions through mention\nreplacement. By processing information systematically, the framework provides\neasier-to-handle partitions for LLMs, promoting better understanding.\nExperimental evaluations on a range of LLMs and datasets have yielded positive\nresults, with a notable improvements on OpenAI-o1-mini and GPT-4o models,\nhighlighting the effectiveness of leveraging coreference resolution to bridge\ncontext gaps in question answering. Our code is public at\nhttps://github.com/OceannTwT/LQCA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 camera ready version, with updated metadata",
    "pdf_url": "http://arxiv.org/pdf/2410.01671v2",
    "published_date": "2024-10-02 15:39:55 UTC",
    "updated_date": "2025-02-28 07:09:00 UTC"
  },
  {
    "arxiv_id": "2410.03767v2",
    "title": "Reasoning Elicitation in Language Models via Counterfactual Feedback",
    "authors": [
      "Alihan Hüyük",
      "Xinnuo Xu",
      "Jacqueline Maasch",
      "Aditya V. Nori",
      "Javier González"
    ],
    "abstract": "Despite the increasing effectiveness of language models, their reasoning\ncapabilities remain underdeveloped. In particular, causal reasoning through\ncounterfactual question answering is lacking. This work aims to bridge this\ngap. We first derive novel metrics that balance accuracy in factual and\ncounterfactual questions, capturing a more complete view of the reasoning\nabilities of language models than traditional factual-only based metrics.\nSecond, we propose several fine-tuning approaches that aim to elicit better\nreasoning mechanisms, in the sense of the proposed metrics. Finally, we\nevaluate the performance of the fine-tuned language models in a variety of\nrealistic scenarios. In particular, we investigate to what extent our\nfine-tuning approaches systemically achieve better generalization with respect\nto the base models in several problems that require, among others, inductive\nand deductive reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The 13th International Conference on Learning Representations (ICLR\n  2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.03767v2",
    "published_date": "2024-10-02 15:33:30 UTC",
    "updated_date": "2025-03-15 18:40:04 UTC"
  },
  {
    "arxiv_id": "2410.01665v2",
    "title": "Towards a vision foundation model for comprehensive assessment of Cardiac MRI",
    "authors": [
      "Athira J Jacob",
      "Indraneel Borgohain",
      "Teodora Chitiboi",
      "Puneet Sharma",
      "Dorin Comaniciu",
      "Daniel Rueckert"
    ],
    "abstract": "Cardiac magnetic resonance imaging (CMR), considered the gold standard for\nnoninvasive cardiac assessment, is a diverse and complex modality requiring a\nwide variety of image processing tasks for comprehensive assessment of cardiac\nmorphology and function. Advances in deep learning have enabled the development\nof state-of-the-art (SoTA) models for these tasks. However, model training is\nchallenging due to data and label scarcity, especially in the less common\nimaging sequences. Moreover, each model is often trained for a specific task,\nwith no connection between related tasks. In this work, we introduce a vision\nfoundation model trained for CMR assessment, that is trained in a\nself-supervised fashion on 36 million CMR images. We then finetune the model in\nsupervised way for 9 clinical tasks typical to a CMR workflow, across\nclassification, segmentation, landmark localization, and pathology detection.\nWe demonstrate improved accuracy and robustness across all tasks, over a range\nof available labeled dataset sizes. We also demonstrate improved few-shot\nlearning with fewer labeled samples, a common challenge in medical image\nanalyses. We achieve an out-of-box performance comparable to SoTA for most\nclinical tasks. The proposed method thus presents a resource-efficient, unified\nframework for CMR assessment, with the potential to accelerate the development\nof deep learning-based solutions for image analysis tasks, even with few\nannotated data available.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "11 pages, 3 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.01665v2",
    "published_date": "2024-10-02 15:32:01 UTC",
    "updated_date": "2024-10-06 22:28:20 UTC"
  },
  {
    "arxiv_id": "2410.01661v2",
    "title": "Finding path and cycle counting formulae in graphs with Deep Reinforcement Learning",
    "authors": [
      "Jason Piquenot",
      "Maxime Bérar",
      "Pierre Héroux",
      "Jean-Yves Ramel",
      "Romain Raveaux",
      "Sébastien Adam"
    ],
    "abstract": "This paper presents Grammar Reinforcement Learning (GRL), a reinforcement\nlearning algorithm that uses Monte Carlo Tree Search (MCTS) and a transformer\narchitecture that models a Pushdown Automaton (PDA) within a context-free\ngrammar (CFG) framework. Taking as use case the problem of efficiently counting\npaths and cycles in graphs, a key challenge in network analysis, computer\nscience, biology, and social sciences, GRL discovers new matrix-based formulas\nfor path/cycle counting that improve computational efficiency by factors of two\nto six w.r.t state-of-the-art approaches. Our contributions include: (i) a\nframework for generating gramformers that operate within a CFG, (ii) the\ndevelopment of GRL for optimizing formulas within grammatical structures, and\n(iii) the discovery of novel formulas for graph substructure counting, leading\nto significant computational improvements.",
    "categories": [
      "cs.AI",
      "cs.FL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01661v2",
    "published_date": "2024-10-02 15:29:42 UTC",
    "updated_date": "2025-01-23 09:09:29 UTC"
  },
  {
    "arxiv_id": "2410.01660v2",
    "title": "Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering",
    "authors": [
      "Klaus-Rudolf Kladny",
      "Bernhard Schölkopf",
      "Michael Muehlebach"
    ],
    "abstract": "Generative models lack rigorous statistical guarantees for their outputs and\nare therefore unreliable in safety-critical applications. In this work, we\npropose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a\nsequential conformal prediction method producing prediction sets that satisfy a\nrigorous statistical guarantee called conformal admissibility control. This\nguarantee states that with high probability, the prediction sets contain at\nleast one admissible (or valid) example. To this end, our method first samples\nan initial set of i.i.d. examples from a black box generative model. Then, this\nset is iteratively pruned via so-called greedy filters. As a consequence of the\niterative generation procedure, admissibility of the final prediction set\nfactorizes as a Markov chain. This factorization is crucial, because it allows\nto control each factor separately, using conformal prediction. In comparison to\nprior work, our method demonstrates a large reduction in the number of\nadmissibility evaluations during calibration. This reduction is important in\nsafety-critical applications, where these evaluations must be conducted\nmanually by domain experts and are therefore costly and time consuming. We\nhighlight the advantages of our method in terms of admissibility evaluations\nand cardinality of the prediction sets through experiments in natural language\ngeneration and molecular graph extension tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01660v2",
    "published_date": "2024-10-02 15:26:52 UTC",
    "updated_date": "2025-02-15 15:33:38 UTC"
  },
  {
    "arxiv_id": "2410.03766v2",
    "title": "FutureFill: Fast Generation from Convolutional Sequence Models",
    "authors": [
      "Naman Agarwal",
      "Xinyi Chen",
      "Evan Dogariu",
      "Vlad Feinberg",
      "Daniel Suo",
      "Peter Bartlett",
      "Elad Hazan"
    ],
    "abstract": "We address the challenge of efficient auto-regressive generation in sequence\nprediction models by introducing FutureFill - a method for fast generation that\napplies to any sequence prediction algorithm based on convolutional operators.\nOur approach reduces the generation time requirement from quadratic to\nquasilinear relative to the context length. Additionally, FutureFill requires a\nprefill cache sized only by the number of tokens generated, which is smaller\nthan the cache requirements for standard convolutional and attention-based\nmodels. We validate our theoretical findings with experimental evidence\ndemonstrating correctness and efficiency gains in a synthetic generation task.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03766v2",
    "published_date": "2024-10-02 15:22:08 UTC",
    "updated_date": "2024-10-25 19:45:33 UTC"
  },
  {
    "arxiv_id": "2410.01651v2",
    "title": "Efficient Length-Generalizable Attention via Causal Retrieval for Long-Context Language Modeling",
    "authors": [
      "Xiang Hu",
      "Zhihao Teng",
      "Jun Zhao",
      "Wei Wu",
      "Kewei Tu"
    ],
    "abstract": "Despite the success of Transformers, handling long contexts remains\nchallenging due to the limited length generalization and quadratic complexity\nof self-attention. Thus Transformers often require post-training with a larger\nattention window, significantly increasing computational and memory costs. In\nthis paper, we propose a novel attention mechanism based on dynamic context,\nGrouped Cross Attention (GCA), which can generalize to 1000 times the\npre-training context length while maintaining the ability to access distant\ninformation with a constant attention window size. For a given input sequence,\nwe split it into chunks and use each chunk to retrieve top-k relevant past\nchunks for subsequent text generation. Specifically, unlike most previous works\nthat use an off-the-shelf retriever, our key innovation allows the retriever to\nlearn how to retrieve past chunks that better minimize the auto-regressive loss\nof subsequent tokens in an end-to-end manner. Such a mechanism accommodates\nretrieved chunks with a fixed-size attention window to achieve long-range\ninformation access, significantly reducing computational and memory costs\nduring training and inference. Experiments show that GCA-based models achieve\nnear-perfect accuracy in passkey retrieval for 16M context lengths, which is\n1000 times the training length.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.01651v2",
    "published_date": "2024-10-02 15:18:34 UTC",
    "updated_date": "2025-01-27 07:08:49 UTC"
  },
  {
    "arxiv_id": "2410.01649v1",
    "title": "shapiq: Shapley Interactions for Machine Learning",
    "authors": [
      "Maximilian Muschalik",
      "Hubert Baniecki",
      "Fabian Fumagalli",
      "Patrick Kolpaczki",
      "Barbara Hammer",
      "Eyke Hüllermeier"
    ],
    "abstract": "Originally rooted in game theory, the Shapley Value (SV) has recently become\nan important tool in machine learning research. Perhaps most notably, it is\nused for feature attribution and data valuation in explainable artificial\nintelligence. Shapley Interactions (SIs) naturally extend the SV and address\nits limitations by assigning joint contributions to groups of entities, which\nenhance understanding of black box machine learning models. Due to the\nexponential complexity of computing SVs and SIs, various methods have been\nproposed that exploit structural assumptions or yield probabilistic estimates\ngiven limited resources. In this work, we introduce shapiq, an open-source\nPython package that unifies state-of-the-art algorithms to efficiently compute\nSVs and any-order SIs in an application-agnostic framework. Moreover, it\nincludes a benchmarking suite containing 11 machine learning applications of\nSIs with pre-computed games and ground-truth values to systematically assess\ncomputational performance across domains. For practitioners, shapiq is able to\nexplain and visualize any-order feature interactions in predictions of models,\nincluding vision transformers, language models, as well as XGBoost and LightGBM\nwith TreeSHAP-IQ. With shapiq, we extend shap beyond feature attributions and\nconsolidate the application of SVs and SIs in machine learning that facilitates\nfuture research. The source code and documentation are available at\nhttps://github.com/mmschlk/shapiq.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.01649v1",
    "published_date": "2024-10-02 15:16:53 UTC",
    "updated_date": "2024-10-02 15:16:53 UTC"
  },
  {
    "arxiv_id": "2410.01643v4",
    "title": "Stable Offline Value Function Learning with Bisimulation-based Representations",
    "authors": [
      "Brahma S. Pavse",
      "Yudong Chen",
      "Qiaomin Xie",
      "Josiah P. Hanna"
    ],
    "abstract": "In reinforcement learning, offline value function learning is the procedure\nof using an offline dataset to estimate the expected discounted return from\neach state when taking actions according to a fixed target policy. The\nstability of this procedure, i.e., whether it converges to its fixed-point,\ncritically depends on the representations of the state-action pairs. Poorly\nlearned representations can make value function learning unstable, or even\ndivergent. Therefore, it is critical to stabilize value function learning by\nexplicitly shaping the state-action representations. Recently, the class of\nbisimulation-based algorithms have shown promise in shaping representations for\ncontrol. However, it is still unclear if this class of methods can\n\\emph{stabilize} value function learning. In this work, we investigate this\nquestion and answer it affirmatively. We introduce a bisimulation-based\nalgorithm called kernel representations for offline policy evaluation\n(\\textsc{krope}). \\textsc{krope} uses a kernel to shape state-action\nrepresentations such that state-action pairs that have similar immediate\nrewards and lead to similar next state-action pairs under the target policy\nalso have similar representations. We show that \\textsc{krope}: 1) learns\nstable representations and 2) leads to lower value error than baselines. Our\nanalysis provides new theoretical insight into the stability properties of\nbisimulation-based methods and suggests that practitioners can use these\nmethods to improve the stability and accuracy of offline evaluation of\nreinforcement learning agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the International Conference on Machine Learning (ICML)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01643v4",
    "published_date": "2024-10-02 15:13:25 UTC",
    "updated_date": "2025-05-17 17:57:46 UTC"
  },
  {
    "arxiv_id": "2410.01639v4",
    "title": "Moral Alignment for LLM Agents",
    "authors": [
      "Elizaveta Tennant",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "abstract": "Decision-making agents based on pre-trained Large Language Models (LLMs) are\nincreasingly being deployed across various domains of human activity. While\ntheir applications are currently rather specialized, several research efforts\nare underway to develop more generalist agents. As LLM-based systems become\nmore agentic, their influence on human activity will grow and their\ntransparency will decrease. Consequently, developing effective methods for\naligning them to human values is vital.\n  The prevailing practice in alignment often relies on human preference data\n(e.g., in RLHF or DPO), in which values are implicit, opaque and are\nessentially deduced from relative preferences over different model outputs. In\nthis work, instead of relying on human feedback, we introduce the design of\nreward functions that explicitly and transparently encode core human values for\nReinforcement Learning-based fine-tuning of foundation agent models.\nSpecifically, we use intrinsic rewards for the moral alignment of LLM agents.\n  We evaluate our approach using the traditional philosophical frameworks of\nDeontological Ethics and Utilitarianism, quantifying moral rewards for agents\nin terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD)\nenvironment. We also show how moral fine-tuning can be deployed to enable an\nagent to unlearn a previously developed selfish strategy. Finally, we find that\ncertain moral strategies learned on the IPD game generalize to several other\nmatrix game environments. In summary, we demonstrate that fine-tuning with\nintrinsic rewards is a promising general solution for aligning LLM agents to\nhuman values, and it might represent a more transparent and cost-effective\nalternative to currently predominant alignment techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the 13th International Conference on Learning\n  Representations (ICLR'25), Singapore, Apr 2025.\n  https://openreview.net/forum?id=MeGDmZjUXy",
    "pdf_url": "http://arxiv.org/pdf/2410.01639v4",
    "published_date": "2024-10-02 15:09:36 UTC",
    "updated_date": "2025-05-11 19:14:09 UTC"
  },
  {
    "arxiv_id": "2410.01638v1",
    "title": "Data Extrapolation for Text-to-image Generation on Small Datasets",
    "authors": [
      "Senmao Ye",
      "Fei Liu"
    ],
    "abstract": "Text-to-image generation requires large amount of training data to\nsynthesizing high-quality images. For augmenting training data, previous\nmethods rely on data interpolations like cropping, flipping, and mixing up,\nwhich fail to introduce new information and yield only marginal improvements.\nIn this paper, we propose a new data augmentation method for text-to-image\ngeneration using linear extrapolation. Specifically, we apply linear\nextrapolation only on text feature, and new image data are retrieved from the\ninternet by search engines. For the reliability of new text-image pairs, we\ndesign two outlier detectors to purify retrieved images. Based on\nextrapolation, we construct training samples dozens of times larger than the\noriginal dataset, resulting in a significant improvement in text-to-image\nperformance. Moreover, we propose a NULL-guidance to refine score estimation,\nand apply recurrent affine transformation to fuse text information. Our model\nachieves FID scores of 7.91, 9.52 and 5.00 on the CUB, Oxford and COCO\ndatasets. The code and data will be available on GitHub\n(https://github.com/senmaoy/RAT-Diffusion).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01638v1",
    "published_date": "2024-10-02 15:08:47 UTC",
    "updated_date": "2024-10-02 15:08:47 UTC"
  },
  {
    "arxiv_id": "2410.01635v1",
    "title": "Does Graph Prompt Work? A Data Operation Perspective with Theoretical Analysis",
    "authors": [
      "Qunzhong Wang",
      "Xiangguo Sun",
      "Hong Cheng"
    ],
    "abstract": "In recent years, graph prompting has emerged as a promising research\ndirection, enabling the learning of additional tokens or subgraphs appended to\nthe original graphs without requiring retraining of pre-trained graph models\nacross various applications. This novel paradigm, shifting from the traditional\npretraining and finetuning to pretraining and prompting has shown significant\nempirical success in simulating graph data operations, with applications\nranging from recommendation systems to biological networks and graph\ntransferring. However, despite its potential, the theoretical underpinnings of\ngraph prompting remain underexplored, raising critical questions about its\nfundamental effectiveness. The lack of rigorous theoretical proof of why and\nhow much it works is more like a dark cloud over the graph prompt area to go\nfurther. To fill this gap, this paper introduces a theoretical framework that\nrigorously analyzes graph prompting from a data operation perspective. Our\ncontributions are threefold: First, we provide a formal guarantee theorem,\ndemonstrating graph prompts capacity to approximate graph transformation\noperators, effectively linking upstream and downstream tasks. Second, we derive\nupper bounds on the error of these data operations by graph prompts for a\nsingle graph and extend this discussion to batches of graphs, which are common\nin graph model training. Third, we analyze the distribution of data operation\nerrors, extending our theoretical findings from linear graph models (e.g., GCN)\nto non-linear graph models (e.g., GAT). Extensive experiments support our\ntheoretical results and confirm the practical implications of these guarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01635v1",
    "published_date": "2024-10-02 15:07:13 UTC",
    "updated_date": "2024-10-02 15:07:13 UTC"
  },
  {
    "arxiv_id": "2410.01628v3",
    "title": "Stochasticity in Motion: An Information-Theoretic Approach to Trajectory Prediction",
    "authors": [
      "Aron Distelzweig",
      "Andreas Look",
      "Eitan Kosman",
      "Faris Janjoš",
      "Jörg Wagner",
      "Abhinav Valada"
    ],
    "abstract": "In autonomous driving, accurate motion prediction is crucial for safe and\nefficient motion planning. To ensure safety, planners require reliable\nuncertainty estimates of the predicted behavior of surrounding agents, yet this\naspect has received limited attention. In particular, decomposing uncertainty\ninto its aleatoric and epistemic components is essential for distinguishing\nbetween inherent environmental randomness and model uncertainty, thereby\nenabling more robust and informed decision-making. This paper addresses the\nchallenge of uncertainty modeling in trajectory prediction with a holistic\napproach that emphasizes uncertainty quantification, decomposition, and the\nimpact of model composition. Our method, grounded in information theory,\nprovides a theoretically principled way to measure uncertainty and decompose it\ninto aleatoric and epistemic components. Unlike prior work, our approach is\ncompatible with state-of-the-art motion predictors, allowing for broader\napplicability. We demonstrate its utility by conducting extensive experiments\non the nuScenes dataset, which shows how different architectures and\nconfigurations influence uncertainty quantification and model robustness.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 5 figures, submitted to International Conference on\n  Intelligent Robots and Systems (IROS 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.01628v3",
    "published_date": "2024-10-02 15:02:32 UTC",
    "updated_date": "2025-02-28 16:28:50 UTC"
  },
  {
    "arxiv_id": "2410.01623v2",
    "title": "Fira: Can We Achieve Full-rank Training of LLMs Under Low-rank Constraint?",
    "authors": [
      "Xi Chen",
      "Kaituo Feng",
      "Changsheng Li",
      "Xunhao Lai",
      "Xiangyu Yue",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "abstract": "Low-rank training has emerged as a promising approach for reducing memory\nusage in training Large Language Models (LLMs). Previous methods either rely on\ndecomposing weight matrices (e.g., LoRA), or seek to decompose gradient\nmatrices (e.g., GaLore) to ensure reduced memory consumption. However, both of\nthem constrain the training in a low-rank subspace, thus inevitably leading to\nsub-optimal performance. This raises a question: whether it is possible to\nconsistently preserve the low-rank constraint for memory efficiency, while\nachieving full-rank training (i.e., training with full-rank gradients of\nfull-rank weights) to avoid inferior outcomes? In this paper, we propose a new\nplug-and-play training framework for LLMs called Fira, as the first attempt to\nachieve this goal. First, we observe an interesting phenomenon during LLM\ntraining: the scaling impact of adaptive optimizers (e.g., Adam) on the\ngradient norm remains similar from low-rank to full-rank training. Based on\nthis observation, we propose a norm-based scaling method, which utilizes the\nscaling impact of low-rank optimizers as substitutes for that of original\nfull-rank optimizers to enable full-rank training. In this way, we can preserve\nthe low-rank constraint in the optimizer while achieving full-rank training for\nbetter performance. Moreover, we find that there are sudden gradient rises\nduring the optimization process, potentially causing loss spikes. To address\nthis, we further put forward a norm-growth limiter to smooth the gradient via\nregulating the relative increase of gradient norms. Extensive experiments on\nthe pre-training and fine-tuning of LLMs show that Fira outperforms both LoRA\nand GaLore, achieving performance that is comparable to or even better than\nfull-rank training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Add further analysis of the scaling factor, code is available at:\n  https://github.com/xichen-fy/Fira",
    "pdf_url": "http://arxiv.org/pdf/2410.01623v2",
    "published_date": "2024-10-02 14:58:27 UTC",
    "updated_date": "2024-10-12 08:44:01 UTC"
  },
  {
    "arxiv_id": "2410.01611v2",
    "title": "DRUPI: Dataset Reduction Using Privileged Information",
    "authors": [
      "Shaobo Wang",
      "Yantai Yang",
      "Shuaiyu Zhang",
      "Chenghao Sun",
      "Weiya Li",
      "Xuming Hu",
      "Linfeng Zhang"
    ],
    "abstract": "Dataset reduction (DR) seeks to select or distill samples from large datasets\ninto smaller subsets while preserving performance on target tasks. Existing\nmethods primarily focus on pruning or synthesizing data in the same format as\nthe original dataset, typically the input data and corresponding labels.\nHowever, in DR settings, we find it is possible to synthesize more information\nbeyond the data-label pair as an additional learning target to facilitate model\ntraining. In this paper, we introduce Dataset Reduction Using Privileged\nInformation (DRUPI), which enriches DR by synthesizing privileged information\nalongside the reduced dataset. This privileged information can take the form of\nfeature labels or attention labels, providing auxiliary supervision to improve\nmodel learning. Our findings reveal that effective feature labels must balance\nbetween being overly discriminative and excessively diverse, with a moderate\nlevel proving optimal for improving the reduced dataset's efficacy. Extensive\nexperiments on ImageNet, CIFAR-10/100, and Tiny ImageNet demonstrate that DRUPI\nintegrates seamlessly with existing dataset reduction methods, offering\nsignificant performance gains. *The code will be released after the paper is\naccepted.*",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01611v2",
    "published_date": "2024-10-02 14:49:05 UTC",
    "updated_date": "2024-10-09 06:52:54 UTC"
  },
  {
    "arxiv_id": "2410.01610v1",
    "title": "Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging",
    "authors": [
      "Tingfeng Hui",
      "Zhenyu Zhang",
      "Shuohuan Wang",
      "Yu Sun",
      "Hua Wu",
      "Sen Su"
    ],
    "abstract": "Mixture-of-Experts (MoE) shines brightly in large language models (LLMs) and\ndemonstrates outstanding performance in plentiful natural language processing\ntasks. However, existing methods transforming LLMs from dense to MoE face\nsignificant data requirements and typically rely on large-scale post-training.\nIn this paper, we propose Upcycling Instruction Tuning (UpIT), a data-efficient\napproach for tuning a dense pre-trained model into a MoE instruction model.\nSpecifically, we first point out that intermediate checkpoints during\ninstruction tuning of the dense model are naturally suitable for specialized\nexperts, and then propose an expert expansion stage to flexibly achieve models\nwith flexible numbers of experts, where genetic algorithm and parameter merging\nare introduced to ensure sufficient diversity of new extended experts. To\nensure that each specialized expert in the MoE model works as expected, we\nselect a small amount of seed data that each expert excels to pre-optimize the\nrouter. Extensive experiments with various data scales and upcycling settings\ndemonstrate the outstanding performance and data efficiency of UpIT, as well as\nstable improvement in expert or data scaling. Further analysis reveals the\nimportance of ensuring expert diversity in upcycling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2410.01610v1",
    "published_date": "2024-10-02 14:48:22 UTC",
    "updated_date": "2024-10-02 14:48:22 UTC"
  },
  {
    "arxiv_id": "2410.01606v1",
    "title": "Automated Red Teaming with GOAT: the Generative Offensive Agent Tester",
    "authors": [
      "Maya Pavlova",
      "Erik Brinkman",
      "Krithika Iyer",
      "Vitor Albiero",
      "Joanna Bitton",
      "Hailey Nguyen",
      "Joe Li",
      "Cristian Canton Ferrer",
      "Ivan Evtimov",
      "Aaron Grattafiori"
    ],
    "abstract": "Red teaming assesses how large language models (LLMs) can produce content\nthat violates norms, policies, and rules set during their safety training.\nHowever, most existing automated methods in the literature are not\nrepresentative of the way humans tend to interact with AI models. Common users\nof AI models may not have advanced knowledge of adversarial machine learning\nmethods or access to model internals, and they do not spend a lot of time\ncrafting a single highly effective adversarial prompt. Instead, they are likely\nto make use of techniques commonly shared online and exploit the multiturn\nconversational nature of LLMs. While manual testing addresses this gap, it is\nan inefficient and often expensive process. To address these limitations, we\nintroduce the Generative Offensive Agent Tester (GOAT), an automated agentic\nred teaming system that simulates plain language adversarial conversations\nwhile leveraging multiple adversarial prompting techniques to identify\nvulnerabilities in LLMs. We instantiate GOAT with 7 red teaming attacks by\nprompting a general-purpose model in a way that encourages reasoning through\nthe choices of methods available, the current target model's response, and the\nnext steps. Our approach is designed to be extensible and efficient, allowing\nhuman testers to focus on exploring new areas of risk while automation covers\nthe scaled adversarial stress-testing of known risk territory. We present the\ndesign and evaluation of GOAT, demonstrating its effectiveness in identifying\nvulnerabilities in state-of-the-art LLMs, with an ASR@10 of 97% against Llama\n3.1 and 88% against GPT-4 on the JailbreakBench dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01606v1",
    "published_date": "2024-10-02 14:47:05 UTC",
    "updated_date": "2024-10-02 14:47:05 UTC"
  },
  {
    "arxiv_id": "2410.01598v1",
    "title": "Elaborative Subtopic Query Reformulation for Broad and Indirect Queries in Travel Destination Recommendation",
    "authors": [
      "Qianfeng Wen",
      "Yifan Liu",
      "Joshua Zhang",
      "George Saad",
      "Anton Korikov",
      "Yury Sambale",
      "Scott Sanner"
    ],
    "abstract": "In Query-driven Travel Recommender Systems (RSs), it is crucial to understand\nthe user intent behind challenging natural language(NL) destination queries\nsuch as the broadly worded \"youth-friendly activities\" or the indirect\ndescription \"a high school graduation trip\". Such queries are challenging due\nto the wide scope and subtlety of potential user intents that confound the\nability of retrieval methods to infer relevant destinations from available\ntextual descriptions such as WikiVoyage. While query reformulation (QR) has\nproven effective in enhancing retrieval by addressing user intent, existing QR\nmethods tend to focus only on expanding the range of potentially matching query\nsubtopics (breadth) or elaborating on the potential meaning of a query (depth),\nbut not both. In this paper, we introduce Elaborative Subtopic Query\nReformulation (EQR), a large language model-based QR method that combines both\nbreadth and depth by generating potential query subtopics with information-rich\nelaborations. We also release TravelDest, a novel dataset for query-driven\ntravel destination RSs. Experiments on TravelDest show that EQR achieves\nsignificant improvements in recall and precision over existing state-of-the-art\nQR methods.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages, 7 figures,The 1st Workshop on Risks, Opportunities, and\n  Evaluation of Generative Models in Recommender Systems (ROEGEN@RecSys 2024),\n  October 2024, Bari, Italy",
    "pdf_url": "http://arxiv.org/pdf/2410.01598v1",
    "published_date": "2024-10-02 14:36:18 UTC",
    "updated_date": "2024-10-02 14:36:18 UTC"
  },
  {
    "arxiv_id": "2410.01595v3",
    "title": "KnobGen: Controlling the Sophistication of Artwork in Sketch-Based Diffusion Models",
    "authors": [
      "Pouyan Navard",
      "Amin Karimi Monsefi",
      "Mengxi Zhou",
      "Wei-Lun Chao",
      "Alper Yilmaz",
      "Rajiv Ramnath"
    ],
    "abstract": "Recent advances in diffusion models have significantly improved text-to-image\n(T2I) generation, but they often struggle to balance fine-grained precision\nwith high-level control. Methods like ControlNet and T2I-Adapter excel at\nfollowing sketches by seasoned artists but tend to be overly rigid, replicating\nunintentional flaws in sketches from novice users. Meanwhile, coarse-grained\nmethods, such as sketch-based abstraction frameworks, offer more accessible\ninput handling but lack the precise control needed for detailed, professional\nuse. To address these limitations, we propose KnobGen, a dual-pathway framework\nthat democratizes sketch-based image generation by seamlessly adapting to\nvarying levels of sketch complexity and user skill. KnobGen uses a\nCoarse-Grained Controller (CGC) module for high-level semantics and a\nFine-Grained Controller (FGC) module for detailed refinement. The relative\nstrength of these two modules can be adjusted through our knob inference\nmechanism to align with the user's specific needs. These mechanisms ensure that\nKnobGen can flexibly generate images from both novice sketches and those drawn\nby seasoned artists. This maintains control over the final output while\npreserving the natural appearance of the image, as evidenced on the\nMultiGen-20M dataset and a newly collected sketch dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025 Workshop on CVEU",
    "pdf_url": "http://arxiv.org/pdf/2410.01595v3",
    "published_date": "2024-10-02 14:33:12 UTC",
    "updated_date": "2025-04-09 22:27:10 UTC"
  },
  {
    "arxiv_id": "2410.01591v2",
    "title": "Imaging foundation model for universal enhancement of non-ideal measurement CT",
    "authors": [
      "Yuxin Liu",
      "Rongjun Ge",
      "Yuting He",
      "Zhan Wu",
      "Shangwen Yang",
      "Yuan Gao",
      "Chenyu You",
      "Ge Wang",
      "Yang Chen",
      "Shuo Li"
    ],
    "abstract": "Non-ideal measurement computed tomography (NICT) employs suboptimal imaging\nprotocols to expand CT applications. However, the resulting trade-offs degrade\nimage quality, limiting clinical acceptability. Although deep learning methods\nhave been used to enhance NICT images, their reliance on large training\ndatasets and limited generalizability across diverse settings hinder practical\nuse. We propose the multi-scale integrated Transformer AMPlifier (TAMP), the\nfirst imaging foundation model for universal NICT enhancement. Pre-trained on\n10.8 million physics-driven simulated NICT images, TAMP generalizes effectively\nacross various NICT settings, defect degrees, and body regions. Moreover, a\nparameter-efficient fine-tuning strategy enables TAMP to adapt to specific\nclinical scenarios using only few slices. Extensive experiments, including\nradiologists and real-world validations, demonstrate that TAMP consistently\nimproves image quality and clinical acceptability, underscoring its significant\npotential to advance CT imaging and broaden NICT applications in clinical\npractice.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01591v2",
    "published_date": "2024-10-02 14:25:02 UTC",
    "updated_date": "2025-02-25 18:28:49 UTC"
  },
  {
    "arxiv_id": "2410.01583v1",
    "title": "Iterated Local Search with Linkage Learning",
    "authors": [
      "Renato Tinós",
      "Michal W. Przewozniczek",
      "Darrell Whitley",
      "Francisco Chicano"
    ],
    "abstract": "In pseudo-Boolean optimization, a variable interaction graph represents\nvariables as vertices, and interactions between pairs of variables as edges. In\nblack-box optimization, the variable interaction graph may be at least\npartially discovered by using empirical linkage learning techniques. These\nmethods never report false variable interactions, but they are computationally\nexpensive. The recently proposed local search with linkage learning discovers\nthe partial variable interaction graph as a side-effect of iterated local\nsearch. However, information about the strength of the interactions is not\nlearned by the algorithm. We propose local search with linkage learning 2,\nwhich builds a weighted variable interaction graph that stores information\nabout the strength of the interaction between variables. The weighted variable\ninteraction graph can provide new insights about the optimization problem and\nbehavior of optimizers. Experiments with NK landscapes, knapsack problem, and\nfeature selection show that local search with linkage learning 2 is able to\nefficiently build weighted variable interaction graphs. In particular,\nexperiments with feature selection show that the weighted variable interaction\ngraphs can be used for visualizing the feature interactions in machine\nlearning. Additionally, new transformation operators that exploit the\ninteractions between variables can be designed. We illustrate this ability by\nproposing a new perturbation operator for iterated local search.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01583v1",
    "published_date": "2024-10-02 14:17:50 UTC",
    "updated_date": "2024-10-02 14:17:50 UTC"
  },
  {
    "arxiv_id": "2410.01579v1",
    "title": "Spoken Grammar Assessment Using LLM",
    "authors": [
      "Sunil Kumar Kopparapu",
      "Chitralekha Bhat",
      "Ashish Panda"
    ],
    "abstract": "Spoken language assessment (SLA) systems restrict themselves to evaluating\nthe pronunciation and oral fluency of a speaker by analysing the read and\nspontaneous spoken utterances respectively. The assessment of language grammar\nor vocabulary is relegated to written language assessment (WLA) systems. Most\nWLA systems present a set of sentences from a curated finite-size database of\nsentences thereby making it possible to anticipate the test questions and train\noneself. In this paper, we propose a novel end-to-end SLA system to assess\nlanguage grammar from spoken utterances thus making WLA systems redundant;\nadditionally, we make the assessment largely unteachable by employing a large\nlanguage model (LLM) to bring in variations in the test. We further demonstrate\nthat a hybrid automatic speech recognition (ASR) with a custom-built language\nmodel outperforms the state-of-the-art ASR engine for spoken grammar\nassessment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01579v1",
    "published_date": "2024-10-02 14:15:13 UTC",
    "updated_date": "2024-10-02 14:15:13 UTC"
  },
  {
    "arxiv_id": "2410.05289v3",
    "title": "MARS: A neurosymbolic approach for interpretable drug discovery",
    "authors": [
      "Lauren Nicole DeLong",
      "Yojana Gadiya",
      "Paola Galdi",
      "Jacques D. Fleuriot",
      "Daniel Domingo-Fernández"
    ],
    "abstract": "Neurosymbolic (NeSy) artificial intelligence describes the combination of\nlogic or rule-based techniques with neural networks. Compared to neural\napproaches, NeSy methods often possess enhanced interpretability, which is\nparticularly promising for biomedical applications like drug discovery.\nHowever, since interpretability is broadly defined, there are no clear\nguidelines for assessing the biological plausibility of model interpretations.\nTo assess interpretability in the context of drug discovery, we devise a novel\nprediction task, called drug mechanism-of-action (MoA) deconvolution, with an\nassociated, tailored knowledge graph (KG), MoA-net. We then develop the MoA\nRetrieval System (MARS), a NeSy approach for drug discovery which leverages\nlogical rules with learned rule weights. Using this interpretable feature\nalongside domain knowledge, we find that MARS and other NeSy approaches on KGs\nare susceptible to reasoning shortcuts, in which the prediction of true labels\nis driven by \"degree-bias\" rather than the domain-based rules. Subsequently, we\ndemonstrate ways to identify and mitigate this. Thereafter, MARS achieves\nperformance on par with current state-of-the-art models while producing model\ninterpretations aligned with known MoAs.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review. 10 pages, 7 supplementary pages. Corresponding code is\n  here: https://github.com/laurendelong21/MARS and here:\n  https://github.com/laurendelong21/MoA-Net",
    "pdf_url": "http://arxiv.org/pdf/2410.05289v3",
    "published_date": "2024-10-02 14:14:17 UTC",
    "updated_date": "2025-01-10 15:25:06 UTC"
  },
  {
    "arxiv_id": "2410.01575v1",
    "title": "Computing Ex Ante Equilibrium in Heterogeneous Zero-Sum Team Games",
    "authors": [
      "Naming Liu",
      "Mingzhi Wang",
      "Xihuai Wang",
      "Weinan Zhang",
      "Yaodong Yang",
      "Youzhi Zhang",
      "Bo An",
      "Ying Wen"
    ],
    "abstract": "The ex ante equilibrium for two-team zero-sum games, where agents within each\nteam collaborate to compete against the opposing team, is known to be the best\na team can do for coordination. Many existing works on ex ante equilibrium\nsolutions are aiming to extend the scope of ex ante equilibrium solving to\nlarge-scale team games based on Policy Space Response Oracle (PSRO). However,\nthe joint team policy space constructed by the most prominent method, Team\nPSRO, cannot cover the entire team policy space in heterogeneous team games\nwhere teammates play distinct roles. Such insufficient policy expressiveness\ncauses Team PSRO to be trapped into a sub-optimal ex ante equilibrium with\nsignificantly higher exploitability and never converges to the global ex ante\nequilibrium. To find the global ex ante equilibrium without introducing\nadditional computational complexity, we first parameterize heterogeneous\npolicies for teammates, and we prove that optimizing the heterogeneous\nteammates' policies sequentially can guarantee a monotonic improvement in team\nrewards. We further propose Heterogeneous-PSRO (H-PSRO), a novel framework for\nheterogeneous team games, which integrates the sequential correlation mechanism\ninto the PSRO framework and serves as the first PSRO framework for\nheterogeneous team games. We prove that H-PSRO achieves lower exploitability\nthan Team PSRO in heterogeneous team games. Empirically, H-PSRO achieves\nconvergence in matrix heterogeneous games that are unsolvable by\nnon-heterogeneous baselines. Further experiments reveal that H-PSRO outperforms\nnon-heterogeneous baselines in both heterogeneous team games and homogeneous\nsettings.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01575v1",
    "published_date": "2024-10-02 14:12:00 UTC",
    "updated_date": "2024-10-02 14:12:00 UTC"
  },
  {
    "arxiv_id": "2410.12830v3",
    "title": "Incorporating Metabolic Information into LLMs for Anomaly Detection in Clinical Time-Series",
    "authors": [
      "Maxx Richard Rahman",
      "Ruoxuan Liu",
      "Wolfgang Maass"
    ],
    "abstract": "Anomaly detection in clinical time-series holds significant potential in\nidentifying suspicious patterns in different biological parameters. In this\npaper, we propose a targeted method that incorporates the clinical domain\nknowledge into LLMs to improve their ability to detect anomalies. We introduce\nthe Metabolism Pathway-driven Prompting (MPP) method, which integrates the\ninformation about metabolic pathways to better capture the structural and\ntemporal changes in biological samples. We applied our method for doping\ndetection in sports, focusing on steroid metabolism, and evaluated using\nreal-world data from athletes. The results show that our method improves\nanomaly detection performance by leveraging metabolic context, providing a more\nnuanced and accurate prediction of suspicious samples in athletes' profiles.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12830v3",
    "published_date": "2024-10-02 14:05:21 UTC",
    "updated_date": "2024-11-24 15:45:35 UTC"
  },
  {
    "arxiv_id": "2410.01560v2",
    "title": "OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data",
    "authors": [
      "Shubham Toshniwal",
      "Wei Du",
      "Ivan Moshkov",
      "Branislav Kisacanin",
      "Alexan Ayrapetyan",
      "Igor Gitman"
    ],
    "abstract": "Mathematical reasoning continues to be a critical challenge in large language\nmodel (LLM) development with significant interest. However, most of the\ncutting-edge progress in mathematical reasoning with LLMs has become\n\\emph{closed-source} due to lack of access to training data. This lack of data\naccess limits researchers from understanding the impact of different choices\nfor synthesizing and utilizing the data. With the goal of creating a\nhigh-quality finetuning (SFT) dataset for math reasoning, we conduct careful\nablation experiments on data synthesis using the recently released\n\\texttt{Llama3.1} family of models. Our experiments show that: (a) solution\nformat matters, with excessively verbose solutions proving detrimental to SFT\nperformance, (b) data generated by a strong teacher outperforms equally-sized\ndata generated by a weak student model, (c) SFT is robust to low-quality\nsolutions, allowing for imprecise data filtering, and (d) question diversity is\ncrucial for achieving data scaling gains. Based on these insights, we create\nthe OpenMathInstruct-2 dataset, which consists of 14M question-solution pairs\n($\\approx$ 600K unique questions), making it nearly eight times larger than the\nprevious largest open-source math reasoning dataset. Finetuning the\n\\texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2 outperforms\n\\texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\\% (51.9\\%\n$\\rightarrow$ 67.8\\%). Finally, to accelerate the open-source efforts, we\nrelease the code, the finetuned models, and the OpenMathInstruct-2 dataset\nunder a commercially permissive license.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01560v2",
    "published_date": "2024-10-02 14:00:09 UTC",
    "updated_date": "2024-10-05 03:54:22 UTC"
  },
  {
    "arxiv_id": "2410.01556v4",
    "title": "Integrative Decoding: Improve Factuality via Implicit Self-consistency",
    "authors": [
      "Yi Cheng",
      "Xiao Liang",
      "Yeyun Gong",
      "Wen Xiao",
      "Song Wang",
      "Yuji Zhang",
      "Wenjun Hou",
      "Kaishuai Xu",
      "Wenge Liu",
      "Wenjie Li",
      "Jian Jiao",
      "Qi Chen",
      "Peng Cheng",
      "Wayne Xiong"
    ],
    "abstract": "Self-consistency-based approaches, which involve repeatedly sampling multiple\noutputs and selecting the most consistent one as the final response, prove to\nbe remarkably effective in improving the factual accuracy of large language\nmodels. Nonetheless, existing methods usually have strict constraints on the\ntask format, largely limiting their applicability. In this paper, we present\nIntegrative Decoding (ID), to unlock the potential of self-consistency in\nopen-ended generation tasks. ID operates by constructing a set of inputs, each\nprepended with a previously sampled response, and then processes them\nconcurrently, with the next token being selected by aggregating of all their\ncorresponding predictions at each decoding step. In essence, this simple\napproach implicitly incorporates self-consistency in the decoding objective.\nExtensive evaluation shows that ID consistently enhances factuality over a wide\nrange of language models, with substantial improvements on the TruthfulQA\n(+11.2%), Biographies (+15.4%) and LongFact (+8.5%) benchmarks. The performance\ngains amplify progressively as the number of sampled responses increases,\nindicating the potential of ID to scale up with repeated sampling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01556v4",
    "published_date": "2024-10-02 13:52:55 UTC",
    "updated_date": "2025-01-23 13:14:28 UTC"
  },
  {
    "arxiv_id": "2410.01553v1",
    "title": "MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework",
    "authors": [
      "Zonghai Yao",
      "Zihao Zhang",
      "Chaolong Tang",
      "Xingyu Bian",
      "Youxia Zhao",
      "Zhichao Yang",
      "Junda Wang",
      "Huixue Zhou",
      "Won Seok Jang",
      "Feiyun Ouyang",
      "Hong Yu"
    ],
    "abstract": "Artificial intelligence (AI) and large language models (LLMs) in healthcare\nrequire advanced clinical skills (CS), yet current benchmarks fail to evaluate\nthese comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by\nmedical education's Objective Structured Clinical Examinations (OSCEs), to\naddress this gap. MedQA-CS evaluates LLMs through two instruction-following\ntasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real\nclinical scenarios. Our contributions include developing MedQA-CS, a\ncomprehensive evaluation framework with publicly available data and expert\nannotations, and providing the quantitative and qualitative assessment of LLMs\nas reliable judges in CS evaluation. Our experiments show that MedQA-CS is a\nmore challenging benchmark for evaluating clinical skills than traditional\nmultiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,\nMedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities\nfor both open- and closed-source LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01553v1",
    "published_date": "2024-10-02 13:47:17 UTC",
    "updated_date": "2024-10-02 13:47:17 UTC"
  },
  {
    "arxiv_id": "2410.14790v2",
    "title": "SSL-NBV: A Self-Supervised-Learning-Based Next-Best-View algorithm for Efficient 3D Plant Reconstruction by a Robot",
    "authors": [
      "Jianchao Ci",
      "Eldert J. van Henten",
      "Xin Wang",
      "Akshay K. Burusa",
      "Gert Kootstra"
    ],
    "abstract": "The 3D reconstruction of plants is challenging due to their complex shape\ncausing many occlusions. Next-Best-View (NBV) methods address this by\niteratively selecting new viewpoints to maximize information gain (IG).\nDeep-learning-based NBV (DL-NBV) methods demonstrate higher computational\nefficiency over classic voxel-based NBV approaches but current methods require\nextensive training using ground-truth plant models, making them impractical for\nreal-world plants. These methods, moreover, rely on offline training with\npre-collected data, limiting adaptability in changing agricultural\nenvironments. This paper proposes a self-supervised learning-based NBV method\n(SSL-NBV) that uses a deep neural network to predict the IG for candidate\nviewpoints. The method allows the robot to gather its own training data during\ntask execution by comparing new 3D sensor data to the earlier gathered data and\nby employing weakly-supervised learning and experience replay for efficient\nonline learning. Comprehensive evaluations were conducted in simulation and\nreal-world environments using cross-validation. The results showed that SSL-NBV\nrequired fewer views for plant reconstruction than non-NBV methods and was over\n800 times faster than a voxel-based method. SSL-NBV reduced training\nannotations by over 90% compared to a baseline DL-NBV. Furthermore, SSL-NBV\ncould adapt to novel scenarios through online fine-tuning. Also using real\nplants, the results showed that the proposed method can learn to effectively\nplan new viewpoints for 3D plant reconstruction. Most importantly, SSL-NBV\nautomated the entire network training and uses continuous online learning,\nallowing it to operate in changing agricultural environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 11 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2410.14790v2",
    "published_date": "2024-10-02 13:42:38 UTC",
    "updated_date": "2024-10-31 09:34:45 UTC"
  },
  {
    "arxiv_id": "2410.01540v3",
    "title": "Edge-preserving noise for diffusion models",
    "authors": [
      "Jente Vandersanden",
      "Sascha Holl",
      "Xingchang Huang",
      "Gurprit Singh"
    ],
    "abstract": "Classical generative diffusion models learn an isotropic Gaussian denoising\nprocess, treating all spatial regions uniformly, thus neglecting potentially\nvaluable structural information in the data. Inspired by the long-established\nwork on anisotropic diffusion in image processing, we present a novel\nedge-preserving diffusion model that generalizes over existing isotropic models\nby considering a hybrid noise scheme. In particular, we introduce an edge-aware\nnoise scheduler that varies between edge-preserving and isotropic Gaussian\nnoise. We show that our model's generative process converges faster to results\nthat more closely match the target distribution. We demonstrate its capability\nto better learn the low-to-mid frequencies within the dataset, which plays a\ncrucial role in representing shapes and structural information. Our\nedge-preserving diffusion process consistently outperforms state-of-the-art\nbaselines in unconditional image generation. It is also particularly more\nrobust for generative tasks guided by a shape-based prior, such as\nstroke-to-image generation. We present qualitative and quantitative results\n(FID and CLIP score) showing consistent improvements of up to 30% for both\ntasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01540v3",
    "published_date": "2024-10-02 13:29:52 UTC",
    "updated_date": "2025-04-19 12:43:13 UTC"
  },
  {
    "arxiv_id": "2410.01532v3",
    "title": "Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models",
    "authors": [
      "Angela Lopez-Cardona",
      "Carlos Segura",
      "Alexandros Karatzoglou",
      "Sergi Abadal",
      "Ioannis Arapakis"
    ],
    "abstract": "Advancements in Natural Language Processing (NLP), have led to the emergence\nof Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which\nexcel across a range of tasks but require extensive fine-tuning to align their\noutputs with human expectations. A widely used method for achieving this\nalignment is Reinforcement Learning from Human Feedback (RLHF), which, despite\nits success, faces challenges in accurately modelling human preferences. In\nthis paper, we introduce GazeReward, a novel framework that integrates implicit\nfeedback -- and specifically eye-tracking (ET) data -- into the Reward Model\n(RM). In addition, we explore how ET-based features can provide insights into\nuser preferences. Through ablation studies we test our framework with different\nintegration methods, LLMs, and ET generator models, demonstrating that our\napproach significantly improves the accuracy of the RM on established human\npreference datasets. This work advances the ongoing discussion on optimizing AI\nalignment with human values, exploring the potential of cognitive data for\nshaping future NLP research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01532v3",
    "published_date": "2024-10-02 13:24:56 UTC",
    "updated_date": "2025-03-29 11:32:39 UTC"
  },
  {
    "arxiv_id": "2410.01531v2",
    "title": "TiVaT: A Transformer with a Single Unified Mechanism for Capturing Asynchronous Dependencies in Multivariate Time Series Forecasting",
    "authors": [
      "Junwoo Ha",
      "Hyukjae Kwon",
      "Sungsoo Kim",
      "Kisu Lee",
      "Seungjae Park",
      "Ha Young Kim"
    ],
    "abstract": "Multivariate time series (MTS) forecasting is vital across various domains\nbut remains challenging due to the need to simultaneously model temporal and\ninter-variate dependencies. Existing channel-dependent models, where\nTransformer-based models dominate, process these dependencies separately,\nlimiting their capacity to capture complex interactions such as lead-lag\ndynamics. To address this issue, we propose TiVaT (Time-variate Transformer), a\nnovel architecture incorporating a single unified module, a Joint-Axis (JA)\nattention module, that concurrently processes temporal and variate modeling.\nThe JA attention module dynamically selects relevant features to particularly\ncapture asynchronous interactions. In addition, we introduce distance-aware\ntime-variate sampling in the JA attention, a novel mechanism that extracts\nsignificant patterns through a learned 2D embedding space while reducing noise.\nExtensive experiments demonstrate TiVaT's overall performance across diverse\ndatasets, particularly excelling in scenarios with intricate asynchronous\ndependencies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "15pages",
    "pdf_url": "http://arxiv.org/pdf/2410.01531v2",
    "published_date": "2024-10-02 13:24:24 UTC",
    "updated_date": "2025-01-31 02:32:39 UTC"
  },
  {
    "arxiv_id": "2410.03762v1",
    "title": "Getting in the Door: Streamlining Intake in Civil Legal Services with Large Language Models",
    "authors": [
      "Quinten Steenhuis",
      "Hannes Westermann"
    ],
    "abstract": "Legal intake, the process of finding out if an applicant is eligible for help\nfrom a free legal aid program, takes significant time and resources. In part\nthis is because eligibility criteria are nuanced, open-textured, and require\nfrequent revision as grants start and end. In this paper, we investigate the\nuse of large language models (LLMs) to reduce this burden. We describe a\ndigital intake platform that combines logical rules with LLMs to offer\neligibility recommendations, and we evaluate the ability of 8 different LLMs to\nperform this task. We find promising results for this approach to help close\nthe access to justice gap, with the best model reaching an F1 score of .82,\nwhile minimizing false negatives.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03762v1",
    "published_date": "2024-10-02 13:20:14 UTC",
    "updated_date": "2024-10-02 13:20:14 UTC"
  },
  {
    "arxiv_id": "2410.01512v1",
    "title": "InstaTrans: An Instruction-Aware Translation Framework for Non-English Instruction Datasets",
    "authors": [
      "Yungi Kim",
      "Chanjun Park"
    ],
    "abstract": "It is challenging to generate high-quality instruction datasets for\nnon-English languages due to tail phenomena, which limit performance on less\nfrequently observed data. To mitigate this issue, we propose translating\nexisting high-quality English instruction datasets as a solution, emphasizing\nthe need for complete and instruction-aware translations to maintain the\ninherent attributes of these datasets. We claim that fine-tuning LLMs with\ndatasets translated in this way can improve their performance in the target\nlanguage. To this end, we introduces a new translation framework tailored for\ninstruction datasets, named InstaTrans (INSTruction-Aware TRANSlation). Through\nextensive experiments, we demonstrate the superiority of InstaTrans over other\ncompetitors in terms of completeness and instruction-awareness of translation,\nhighlighting its potential to broaden the accessibility of LLMs across diverse\nlanguages at a relatively low cost. Furthermore, we have validated that\nfine-tuning LLMs with datasets translated by InstaTrans can effectively improve\ntheir performance in the target language.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01512v1",
    "published_date": "2024-10-02 13:02:23 UTC",
    "updated_date": "2024-10-02 13:02:23 UTC"
  },
  {
    "arxiv_id": "2410.01506v4",
    "title": "Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion",
    "authors": [
      "Dexuan Ding",
      "Lei Wang",
      "Liyun Zhu",
      "Tom Gedeon",
      "Piotr Koniusz"
    ],
    "abstract": "In computer vision tasks, features often come from diverse representations,\ndomains (e.g., indoor and outdoor), and modalities (e.g., text, images, and\nvideos). Effectively fusing these features is essential for robust performance,\nespecially with the availability of powerful pre-trained models like\nvision-language models. However, common fusion methods, such as concatenation,\nelement-wise operations, and non-linear techniques, often fail to capture\nstructural relationships, deep feature interactions, and suffer from\ninefficiency or misalignment of features across domains or modalities. In this\npaper, we shift from high-dimensional feature space to a lower-dimensional,\ninterpretable graph space by constructing relationship graphs that encode\nfeature relationships at different levels, e.g., clip, frame, patch, token,\netc. To capture deeper interactions, we expand graphs through iterative graph\nrelationship updates and introduce a learnable graph fusion operator to\nintegrate these expanded relationships for more effective fusion. Our approach\nis relationship-centric, operates in a homogeneous space, and is mathematically\nprincipled, resembling element-wise relationship score aggregation via\nmultilinear polynomials. We demonstrate the effectiveness of our graph-based\nfusion method on video anomaly detection, showing strong performance across\nmulti-representational, multi-modal, and multi-domain feature fusion tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.01506v4",
    "published_date": "2024-10-02 12:58:55 UTC",
    "updated_date": "2025-02-28 13:52:40 UTC"
  },
  {
    "arxiv_id": "2410.01500v2",
    "title": "Discrete Diffusion Schrödinger Bridge Matching for Graph Transformation",
    "authors": [
      "Jun Hyeong Kim",
      "Seonghwan Kim",
      "Seokhyun Moon",
      "Hyeongwoo Kim",
      "Jeheon Woo",
      "Woo Youn Kim"
    ],
    "abstract": "Transporting between arbitrary distributions is a fundamental goal in\ngenerative modeling. Recently proposed diffusion bridge models provide a\npotential solution, but they rely on a joint distribution that is difficult to\nobtain in practice. Furthermore, formulations based on continuous domains limit\ntheir applicability to discrete domains such as graphs. To overcome these\nlimitations, we propose Discrete Diffusion Schr\\\"odinger Bridge Matching\n(DDSBM), a novel framework that utilizes continuous-time Markov chains to solve\nthe SB problem in a high-dimensional discrete state space. Our approach extends\nIterative Markovian Fitting to discrete domains, and we have proved its\nconvergence to the SB. Furthermore, we adapt our framework for the graph\ntransformation, and show that our design choice of underlying dynamics\ncharacterized by independent modifications of nodes and edges can be\ninterpreted as the entropy-regularized version of optimal transport with a cost\nfunction described by the graph edit distance. To demonstrate the effectiveness\nof our framework, we have applied DDSBM to molecular optimization in the field\nof chemistry. Experimental results demonstrate that DDSBM effectively optimizes\nmolecules' property-of-interest with minimal graph transformation, successfully\nretaining other features. Source code is available\n$\\href{https://github.com/junhkim1226/DDSBM}{here}$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01500v2",
    "published_date": "2024-10-02 12:51:25 UTC",
    "updated_date": "2025-02-28 08:55:22 UTC"
  },
  {
    "arxiv_id": "2410.01497v2",
    "title": "DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic, Lightweight Plugin for Large Language Models",
    "authors": [
      "Yuxuan Zhang",
      "Ruizhe Li"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have achieved robust\nperformance across diverse tasks, but fine-tuning these models for specific\ndomains remains resource-intensive. Parameter-Efficient Fine-Tuning (PEFT)\nmethods like Low-Rank Adaptation (LoRA) address this challenge by fine-tuning a\nsmall subset of parameters. However, existing methods for fusing multiple LoRAs\nlack dynamic fusion based on contextual inputs and often increase inference\ntime due to token-level operations. We propose DLP-LoRA, a Dynamic Lightweight\nPlugin that employs a mini-MLP module with only 5M parameters to dynamically\nfuse multiple LoRAs at the sentence level using top-p sampling strategies. This\napproach reduces inference time to less than twice that of single LoRA\ninference by leveraging parallel computation. Evaluations across 26\ntasks-including multiple-choice questions and question answering-demonstrate\nthat DLP-LoRA achieves an average accuracy of 92.34% on multiple-choice\ndatasets and significant improvements in BLEU and ROUGE scores on QA datasets,\noutperforming different LLMs backbones under composite task settings. DLP-LoRA\neffectively balances performance and efficiency, making it a practical solution\nfor dynamic multi-task adaptation in LLMs. Our code is available at\nhttps://github.com/MeCuping/DLP-LoRA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint under review, 18 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01497v2",
    "published_date": "2024-10-02 12:45:52 UTC",
    "updated_date": "2025-02-18 11:30:17 UTC"
  },
  {
    "arxiv_id": "2410.01482v1",
    "title": "One Wave to Explain Them All: A Unifying Perspective on Post-hoc Explainability",
    "authors": [
      "Gabriel Kasmi",
      "Amandine Brunetto",
      "Thomas Fel",
      "Jayneel Parekh"
    ],
    "abstract": "Despite the growing use of deep neural networks in safety-critical\ndecision-making, their inherent black-box nature hinders transparency and\ninterpretability. Explainable AI (XAI) methods have thus emerged to understand\na model's internal workings, and notably attribution methods also called\nsaliency maps. Conventional attribution methods typically identify the\nlocations -- the where -- of significant regions within an input. However,\nbecause they overlook the inherent structure of the input data, these methods\noften fail to interpret what these regions represent in terms of structural\ncomponents (e.g., textures in images or transients in sounds). Furthermore,\nexisting methods are usually tailored to a single data modality, limiting their\ngeneralizability. In this paper, we propose leveraging the wavelet domain as a\nrobust mathematical foundation for attribution. Our approach, the Wavelet\nAttribution Method (WAM) extends the existing gradient-based feature\nattributions into the wavelet domain, providing a unified framework for\nexplaining classifiers across images, audio, and 3D shapes. Empirical\nevaluations demonstrate that WAM matches or surpasses state-of-the-art methods\nacross faithfulness metrics and models in image, audio, and 3D explainability.\nFinally, we show how our method explains not only the where -- the important\nparts of the input -- but also the what -- the relevant patterns in terms of\nstructural components.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "main: 10 pages, appendix: 14 pages, 5 Tables, 25 Figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01482v1",
    "published_date": "2024-10-02 12:34:04 UTC",
    "updated_date": "2024-10-02 12:34:04 UTC"
  },
  {
    "arxiv_id": "2410.01481v2",
    "title": "SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios",
    "authors": [
      "Kai Li",
      "Wendi Sang",
      "Chang Zeng",
      "Runxuan Yang",
      "Guo Chen",
      "Xiaolin Hu"
    ],
    "abstract": "Systematic evaluation of speech separation and enhancement models under\nmoving sound source conditions requires extensive and diverse data. However,\nreal-world datasets often lack sufficient data for training and evaluation, and\nsynthetic datasets, while larger, lack acoustic realism. Consequently, neither\neffectively meets practical needs. To address this issue, we introduce\nSonicSim, a synthetic toolkit based on the embodied AI simulation platform\nHabitat-sim, designed to generate highly customizable data for moving sound\nsources. SonicSim supports multi-level adjustments, including scene-level,\nmicrophone-level, and source-level adjustments, enabling the creation of more\ndiverse synthetic data. Leveraging SonicSim, we constructed a benchmark dataset\ncalled SonicSet, utilizing LibriSpeech, Freesound Dataset 50k (FSD50K), Free\nMusic Archive (FMA), and 90 scenes from Matterport3D to evaluate speech\nseparation and enhancement models. Additionally, to investigate the differences\nbetween synthetic and real-world data, we selected 5 hours of raw,\nnon-reverberant data from the SonicSet validation set and recorded a real-world\nspeech separation dataset, providing a reference for comparing SonicSet with\nother synthetic datasets. For speech enhancement, we utilized the real-world\ndataset RealMAN to validate the acoustic gap between SonicSet and existing\nsynthetic datasets. The results indicate that models trained on SonicSet\ngeneralize better to real-world scenarios compared to other synthetic datasets.\nThe code is publicly available at https://cslikai.cn/SonicSim/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01481v2",
    "published_date": "2024-10-02 12:33:59 UTC",
    "updated_date": "2025-03-06 04:11:26 UTC"
  },
  {
    "arxiv_id": "2410.01470v1",
    "title": "Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders",
    "authors": [
      "Andreea Iana",
      "Goran Glavaš",
      "Heiko Paulheim"
    ],
    "abstract": "Encoder architectures play a pivotal role in neural news recommenders by\nembedding the semantic and contextual information of news and users. Thus,\nresearch has heavily focused on enhancing the representational capabilities of\nnews and user encoders to improve recommender performance. Despite the\nsignificant impact of encoder architectures on the quality of news and user\nrepresentations, existing analyses of encoder designs focus only on the overall\ndownstream recommendation performance. This offers a one-sided assessment of\nthe encoders' similarity, ignoring more nuanced differences in their behavior,\nand potentially resulting in sub-optimal model selection. In this work, we\nperform a comprehensive analysis of encoder architectures in neural news\nrecommender systems. We systematically evaluate the most prominent news and\nuser encoder architectures, focusing on their (i) representational similarity,\nmeasured with the Central Kernel Alignment, (ii) overlap of generated\nrecommendation lists, quantified with the Jaccard similarity, and (iii) the\noverall recommendation performance. Our analysis reveals that the complexity of\ncertain encoding techniques is often empirically unjustified, highlighting the\npotential for simpler, more efficient architectures. By isolating the effects\nof individual components, we provide valuable insights for researchers and\npractitioners to make better informed decisions about encoder selection and\navoid unnecessary complexity in the design of news recommenders.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "H.3.3; I.2.7"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at the 12th International Workshop on News Recommendation\n  and Analytics (INRA 2024) in conjunction with ACM RecSys 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.01470v1",
    "published_date": "2024-10-02 12:21:31 UTC",
    "updated_date": "2024-10-02 12:21:31 UTC"
  },
  {
    "arxiv_id": "2410.01469v2",
    "title": "TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation",
    "authors": [
      "Mohan Xu",
      "Kai Li",
      "Guo Chen",
      "Xiaolin Hu"
    ],
    "abstract": "In recent years, much speech separation research has focused primarily on\nimproving model performance. However, for low-latency speech processing\nsystems, high efficiency is equally important. Therefore, we propose a speech\nseparation model with significantly reduced parameters and computational costs:\nTime-frequency Interleaved Gain Extraction and Reconstruction network (TIGER).\nTIGER leverages prior knowledge to divide frequency bands and compresses\nfrequency information. We employ a multi-scale selective attention module to\nextract contextual features while introducing a full-frequency-frame attention\nmodule to capture both temporal and frequency contextual information.\nAdditionally, to more realistically evaluate the performance of speech\nseparation models in complex acoustic environments, we introduce a dataset\ncalled EchoSet. This dataset includes noise and more realistic reverberation\n(e.g., considering object occlusions and material properties), with speech from\ntwo speakers overlapping at random proportions. Experimental results showed\nthat models trained on EchoSet had better generalization ability than those\ntrained on other datasets compared to the data collected in the physical world,\nwhich validated the practical value of the EchoSet. On EchoSet and real-world\ndata, TIGER significantly reduces the number of parameters by 94.3% and the\nMACs by 95.3% while achieving performance surpassing the state-of-the-art\n(SOTA) model TF-GridNet.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICLR 2025, demo page: https://cslikai.cn/TIGER/",
    "pdf_url": "http://arxiv.org/pdf/2410.01469v2",
    "published_date": "2024-10-02 12:21:06 UTC",
    "updated_date": "2025-03-06 04:03:53 UTC"
  },
  {
    "arxiv_id": "2410.13871v2",
    "title": "Explaining an image classifier with a generative model conditioned by uncertainty",
    "authors": [
      "Adrien LeCoz",
      "Stéphane Herbin",
      "Faouzi Adjed"
    ],
    "abstract": "We propose to condition a generative model by a given image classifier\nuncertainty in order to analyze and explain its behavior. Preliminary\nexperiments on synthetic data and a corrupted version of MNIST dataset\nillustrate the idea.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13871v2",
    "published_date": "2024-10-02 12:14:31 UTC",
    "updated_date": "2024-11-05 09:07:14 UTC"
  },
  {
    "arxiv_id": "2410.01458v1",
    "title": "From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with LLM-Guided Knowledge",
    "authors": [
      "Xiefeng Wu"
    ],
    "abstract": "Q-shaping is an extension of Q-value initialization and serves as an\nalternative to reward shaping for incorporating domain knowledge to accelerate\nagent training, thereby improving sample efficiency by directly shaping\nQ-values. This approach is both general and robust across diverse tasks,\nallowing for immediate impact assessment while guaranteeing optimality. We\nevaluated Q-shaping across 20 different environments using a large language\nmodel (LLM) as the heuristic provider. The results demonstrate that Q-shaping\nsignificantly enhances sample efficiency, achieving a \\textbf{16.87\\%}\nimprovement over the best baseline in each environment and a \\textbf{253.80\\%}\nimprovement compared to LLM-based reward shaping methods. These findings\nestablish Q-shaping as a superior and unbiased alternative to conventional\nreward shaping in reinforcement learning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "q-shaping, reinforcement learning, reward shaping",
    "pdf_url": "http://arxiv.org/pdf/2410.01458v1",
    "published_date": "2024-10-02 12:10:07 UTC",
    "updated_date": "2024-10-02 12:10:07 UTC"
  },
  {
    "arxiv_id": "2410.01450v1",
    "title": "Agent-Driven Large Language Models for Mandarin Lyric Generation",
    "authors": [
      "Hong-Hsiang Liu",
      "Yi-Wen Liu"
    ],
    "abstract": "Generative Large Language Models have shown impressive in-context learning\nabilities, performing well across various tasks with just a prompt. Previous\nmelody-to-lyric research has been limited by scarce high-quality aligned data\nand unclear standard for creativeness. Most efforts focused on general themes\nor emotions, which are less valuable given current language model capabilities.\nIn tonal contour languages like Mandarin, pitch contours are influenced by both\nmelody and tone, leading to variations in lyric-melody fit. Our study,\nvalidated by the Mpop600 dataset, confirms that lyricists and melody writers\nconsider this fit during their composition process. In this research, we\ndeveloped a multi-agent system that decomposes the melody-to-lyric task into\nsub-tasks, with each agent controlling rhyme, syllable count, lyric-melody\nalignment, and consistency. Listening tests were conducted via a\ndiffusion-based singing voice synthesizer to evaluate the quality of lyrics\ngenerated by different agent groups.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, figures, Accepted at O-COCOSDA 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.01450v1",
    "published_date": "2024-10-02 12:01:32 UTC",
    "updated_date": "2024-10-02 12:01:32 UTC"
  },
  {
    "arxiv_id": "2410.01866v2",
    "title": "House of Cards: Massive Weights in LLMs",
    "authors": [
      "Jaehoon Oh",
      "Seungjun Shin",
      "Dokwan Oh"
    ],
    "abstract": "Massive activations, which manifest in specific feature dimensions of hidden\nstates, introduce a significant bias in large language models (LLMs), leading\nto an overemphasis on the corresponding token. In this paper, we identify that\nmassive activations originate not from the hidden state but from the\nintermediate state of a feed-forward network module in an early layer.\nExpanding on the previous observation that massive activations occur only in\nspecific feature dimensions, we dive deep into the weights that cause massive\nactivations. Specifically, we define top-$k$ massive weights as the weights\nthat contribute to the dimensions with the top-$k$ magnitudes in the\nintermediate state. When these massive weights are set to zero, the\nfunctionality of LLMs is entirely disrupted. However, when all weights except\nfor massive weights are set to zero, it results in a relatively minor\nperformance drop, even though a much larger number of weights are set to zero.\nThis implies that during the pre-training process, learning is dominantly\nfocused on massive weights. Building on this observation, we propose a simple\nplug-and-play method called MacDrop (massive weights curriculum dropout), to\nrely less on massive weights during parameter-efficient fine-tuning. This\nmethod applies dropout to the pre-trained massive weights, starting with a high\ndropout probability and gradually decreasing it as fine-tuning progresses.\nThrough various experiments, including zero-shot downstream tasks, long-context\ntasks, and ablation studies, we demonstrate that \\texttt{MacDrop} generally\nimproves performance and strengthens robustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2410.01866v2",
    "published_date": "2024-10-02 11:54:21 UTC",
    "updated_date": "2025-02-06 11:54:35 UTC"
  },
  {
    "arxiv_id": "2410.01444v3",
    "title": "Geometric Signatures of Compositionality Across a Language Model's Lifetime",
    "authors": [
      "Jin Hwa Lee",
      "Thomas Jiralerspong",
      "Lei Yu",
      "Yoshua Bengio",
      "Emily Cheng"
    ],
    "abstract": "By virtue of linguistic compositionality, few syntactic rules and a finite\nlexicon can generate an unbounded number of sentences. That is, language,\nthough seemingly high-dimensional, can be explained using relatively few\ndegrees of freedom. An open question is whether contemporary language models\n(LMs) reflect the intrinsic simplicity of language that is enabled by\ncompositionality. We take a geometric view of this problem by relating the\ndegree of compositionality in a dataset to the intrinsic dimension (ID) of its\nrepresentations under an LM, a measure of feature complexity. We find not only\nthat the degree of dataset compositionality is reflected in representations'\nID, but that the relationship between compositionality and geometric complexity\narises due to learned linguistic features over training. Finally, our analyses\nreveal a striking contrast between nonlinear and linear dimensionality, showing\nthey respectively encode semantic and superficial aspects of linguistic\ncomposition.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review at ARR",
    "pdf_url": "http://arxiv.org/pdf/2410.01444v3",
    "published_date": "2024-10-02 11:54:06 UTC",
    "updated_date": "2025-02-07 03:19:02 UTC"
  },
  {
    "arxiv_id": "2410.01865v1",
    "title": "Simplifying complex machine learning by linearly separable network embedding spaces",
    "authors": [
      "Alexandros Xenos",
      "Noel-Malod Dognin",
      "Natasa Przulj"
    ],
    "abstract": "Low-dimensional embeddings are a cornerstone in the modelling and analysis of\ncomplex networks. However, most existing approaches for mining network\nembedding spaces rely on computationally intensive machine learning systems to\nfacilitate downstream tasks. In the field of NLP, word embedding spaces capture\nsemantic relationships \\textit{linearly}, allowing for information retrieval\nusing \\textit{simple linear operations} on word embedding vectors. Here, we\ndemonstrate that there are structural properties of network data that yields\nthis linearity. We show that the more homophilic the network representation,\nthe more linearly separable the corresponding network embedding space, yielding\nbetter downstream analysis results. Hence, we introduce novel graphlet-based\nmethods enabling embedding of networks into more linearly separable spaces,\nallowing for their better mining. Our fundamental insights into the structure\nof network data that enable their \\textit{\\textbf{linear}} mining and\nexploitation enable the ML community to build upon, towards efficiently and\nexplainably mining of the complex network data.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG",
      "I.2; J.3"
    ],
    "primary_category": "cs.SI",
    "comment": "26 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01865v1",
    "published_date": "2024-10-02 11:41:17 UTC",
    "updated_date": "2024-10-02 11:41:17 UTC"
  },
  {
    "arxiv_id": "2410.01423v1",
    "title": "Fair4Free: Generating High-fidelity Fair Synthetic Samples using Data Free Distillation",
    "authors": [
      "Md Fahim Sikder",
      "Daniel de Leng",
      "Fredrik Heintz"
    ],
    "abstract": "This work presents Fair4Free, a novel generative model to generate synthetic\nfair data using data-free distillation in the latent space. Fair4Free can work\non the situation when the data is private or inaccessible. In our approach, we\nfirst train a teacher model to create fair representation and then distil the\nknowledge to a student model (using a smaller architecture). The process of\ndistilling the student model is data-free, i.e. the student model does not have\naccess to the training dataset while distilling. After the distillation, we use\nthe distilled model to generate fair synthetic samples. Our extensive\nexperiments show that our synthetic samples outperform state-of-the-art models\nin all three criteria (fairness, utility and synthetic quality) with a\nperformance increase of 5% for fairness, 8% for utility and 12% in synthetic\nquality for both tabular and image datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01423v1",
    "published_date": "2024-10-02 11:16:11 UTC",
    "updated_date": "2024-10-02 11:16:11 UTC"
  },
  {
    "arxiv_id": "2410.01417v2",
    "title": "The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs",
    "authors": [
      "Hong Li",
      "Nanxi Li",
      "Yuanjie Chen",
      "Jianbin Zhu",
      "Qinlu Guo",
      "Cewu Lu",
      "Yong-Lu Li"
    ],
    "abstract": "Multi-modal Large Language Models (MLLMs) have exhibited impressive\ncapability. However, recently many deficiencies of MLLMs have been found\ncompared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the\nMLLMs study, the community dedicated efforts to building larger benchmarks with\ncomplex tasks. In this paper, we propose benchmarking an essential but usually\noverlooked intelligence: $\\textbf{association}$, a human's basic capability to\nlink observation and prior practice memory. To comprehensively investigate\nMLLM's performance on the association, we formulate the association task and\ndevise a standard benchmark based on adjective and verb semantic concepts.\nInstead of costly data annotation and curation, we propose a convenient\n$\\textbf{annotation-free}$ construction method transforming the general dataset\nfor our association tasks. Simultaneously, we devise a rigorous data refinement\nprocess to eliminate confusion in the raw dataset. Building on this database,\nwe establish three levels of association tasks: single-step, synchronous, and\nasynchronous associations. Moreover, we conduct a comprehensive investigation\ninto the MLLMs' zero-shot association capabilities, addressing multiple\ndimensions, including three distinct memory strategies, both open-source and\nclosed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the\ninvolvement of human experts. Our systematic investigation shows that current\nopen-source MLLMs consistently exhibit poor capability in our association\ntasks, even the currently state-of-the-art GPT-4V(vision) also has a\nsignificant gap compared to humans. We believe our benchmark would pave the way\nfor future MLLM studies. $\\textit{Our data and code are available at:}$\nhttps://mvig-rhos.com/llm_inception.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025. Project page:\n  https://mvig-rhos.com/llm_inception",
    "pdf_url": "http://arxiv.org/pdf/2410.01417v2",
    "published_date": "2024-10-02 10:58:54 UTC",
    "updated_date": "2025-03-03 00:41:36 UTC"
  },
  {
    "arxiv_id": "2410.01413v1",
    "title": "Improving Fuzzy Rule Classifier with Brain Storm Optimization and Rule Modification",
    "authors": [
      "Yan Huang",
      "Wei Liu",
      "Xiaogang Zang"
    ],
    "abstract": "The expanding complexity and dimensionality in the search space can adversely\naffect inductive learning in fuzzy rule classifiers, thus impacting the\nscalability and accuracy of fuzzy systems. This research specifically addresses\nthe challenge of diabetic classification by employing the Brain Storm\nOptimization (BSO) algorithm to propose a novel fuzzy system that redefines\nrule generation for this context. An exponential model is integrated into the\nstandard BSO algorithm to enhance rule derivation, tailored specifically for\ndiabetes-related data. The innovative fuzzy system is then applied to\nclassification tasks involving diabetic datasets, demonstrating a substantial\nimprovement in classification accuracy, as evidenced by our experiments.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages,8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01413v1",
    "published_date": "2024-10-02 10:48:23 UTC",
    "updated_date": "2024-10-02 10:48:23 UTC"
  },
  {
    "arxiv_id": "2410.01410v1",
    "title": "On the Convergence of FedProx with Extrapolation and Inexact Prox",
    "authors": [
      "Hanmin Li",
      "Peter Richtárik"
    ],
    "abstract": "Enhancing the FedProx federated learning algorithm (Li et al., 2020) with\nserver-side extrapolation, Li et al. (2024a) recently introduced the FedExProx\nmethod. Their theoretical analysis, however, relies on the assumption that each\nclient computes a certain proximal operator exactly, which is impractical since\nthis is virtually never possible to do in real settings. In this paper, we\ninvestigate the behavior of FedExProx without this exactness assumption in the\nsmooth and globally strongly convex setting. We establish a general convergence\nresult, showing that inexactness leads to convergence to a neighborhood of the\nsolution. Additionally, we demonstrate that, with careful control, the adverse\neffects of this inexactness can be mitigated. By linking inexactness to biased\ncompression (Beznosikov et al., 2023), we refine our analysis, highlighting\nrobustness of extrapolation to inexact proximal updates. We also examine the\nlocal iteration complexity required by each client to achieved the required\nlevel of inexactness using various local optimizers. Our theoretical insights\nare validated through comprehensive numerical experiments.",
    "categories": [
      "math.OC",
      "cs.AI",
      "90C25"
    ],
    "primary_category": "math.OC",
    "comment": "36 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01410v1",
    "published_date": "2024-10-02 10:42:27 UTC",
    "updated_date": "2024-10-02 10:42:27 UTC"
  },
  {
    "arxiv_id": "2410.05287v1",
    "title": "Hate Speech Detection Using Cross-Platform Social Media Data In English and German Language",
    "authors": [
      "Gautam Kishore Shahi",
      "Tim A. Majchrzak"
    ],
    "abstract": "Hate speech has grown into a pervasive phenomenon, intensifying during times\nof crisis, elections, and social unrest. Multiple approaches have been\ndeveloped to detect hate speech using artificial intelligence, but a\ngeneralized model is yet unaccomplished. The challenge for hate speech\ndetection as text classification is the cost of obtaining high-quality training\ndata. This study focuses on detecting bilingual hate speech in YouTube comments\nand measuring the impact of using additional data from other platforms in the\nperformance of the classification model. We examine the value of additional\ntraining datasets from cross-platforms for improving the performance of\nclassification models. We also included factors such as content similarity,\ndefinition similarity, and common hate words to measure the impact of datasets\non performance. Our findings show that adding more similar datasets based on\ncontent similarity, hate words, and definitions improves the performance of\nclassification models. The best performance was obtained by combining datasets\nfrom YouTube comments, Twitter, and Gab with an F1-score of 0.74 and 0.68 for\nEnglish and German YouTube comments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05287v1",
    "published_date": "2024-10-02 10:22:53 UTC",
    "updated_date": "2024-10-02 10:22:53 UTC"
  },
  {
    "arxiv_id": "2410.01396v1",
    "title": "Can We Delegate Learning to Automation?: A Comparative Study of LLM Chatbots, Search Engines, and Books",
    "authors": [
      "Yeonsun Yang",
      "Ahyeon Shin",
      "Mincheol Kang",
      "Jiheon Kang",
      "Jean Young Song"
    ],
    "abstract": "Learning is a key motivator behind information search behavior. With the\nemergence of LLM-based chatbots, students are increasingly turning to these\ntools as their primary resource for acquiring knowledge. However, the\ntransition from traditional resources like textbooks and web searches raises\nconcerns among educators. They worry that these fully-automated LLMs might lead\nstudents to delegate critical steps of search as learning. In this paper, we\nsystematically uncover three main concerns from educators' perspectives. In\nresponse to these concerns, we conducted a mixed-methods study with 92\nuniversity students to compare three learning sources with different automation\nlevels. Our results show that LLMs support comprehensive understanding of key\nconcepts without promoting passive learning, though their effectiveness in\nknowledge retention was limited. Additionally, we found that academic\nperformance impacted both learning outcomes and search patterns. Notably,\nhigher-competence learners engaged more deeply with content through\nreading-intensive behaviors rather than relying on search activities.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.IR",
      "K.3.2"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01396v1",
    "published_date": "2024-10-02 10:16:54 UTC",
    "updated_date": "2024-10-02 10:16:54 UTC"
  },
  {
    "arxiv_id": "2410.01386v2",
    "title": "FLAME: Adaptive and Reactive Concept Drift Mitigation for Federated Learning Deployments",
    "authors": [
      "Ioannis Mavromatis",
      "Stefano De Feo",
      "Aftab Khan"
    ],
    "abstract": "This paper presents Federated Learning with Adaptive Monitoring and\nElimination (FLAME), a novel solution capable of detecting and mitigating\nconcept drift in Federated Learning (FL) Internet of Things (IoT) environments.\nConcept drift poses significant challenges for FL models deployed in dynamic\nand real-world settings. FLAME leverages an FL architecture, considers a\nreal-world FL pipeline, and proves capable of maintaining model performance and\naccuracy while addressing bandwidth and privacy constraints. Introducing\nvarious features and extensions on previous works, FLAME offers a robust\nsolution to concept drift, significantly reducing computational load and\ncommunication overhead. Compared to well-known lightweight mitigation methods,\nFLAME demonstrates superior performance in maintaining high F1 scores and\nreducing resource utilisation in large-scale IoT deployments, making it a\npromising approach for real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for Publication at ACM EWSN 2024 - EMERGE Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.01386v2",
    "published_date": "2024-10-02 09:55:58 UTC",
    "updated_date": "2024-10-07 14:14:39 UTC"
  },
  {
    "arxiv_id": "2410.01380v3",
    "title": "Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition",
    "authors": [
      "Jiyeon Kim",
      "Hyunji Lee",
      "Hyowon Cho",
      "Joel Jang",
      "Hyeonbin Hwang",
      "Seungpil Won",
      "Youbin Ahn",
      "Dohaeng Lee",
      "Minjoon Seo"
    ],
    "abstract": "In this work, we investigate how a model's tendency to broadly integrate its\nparametric knowledge evolves throughout pretraining, and how this behavior\naffects overall performance, particularly in terms of knowledge acquisition and\nforgetting. We introduce the concept of knowledge entropy, which quantifies the\nrange of memory sources the model engages with; high knowledge entropy\nindicates that the model utilizes a wide range of memory sources, while low\nknowledge entropy suggests reliance on specific sources with greater certainty.\nOur analysis reveals a consistent decline in knowledge entropy as pretraining\nadvances. We also find that the decline is closely associated with a reduction\nin the model's ability to acquire and retain knowledge, leading us to conclude\nthat diminishing knowledge entropy (smaller number of active memory sources)\nimpairs the model's knowledge acquisition and retention capabilities. We find\nfurther support for this by demonstrating that increasing the activity of\ninactive memory sources enhances the model's capacity for knowledge acquisition\nand retention.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025, Oral",
    "pdf_url": "http://arxiv.org/pdf/2410.01380v3",
    "published_date": "2024-10-02 09:49:45 UTC",
    "updated_date": "2025-03-12 04:17:41 UTC"
  },
  {
    "arxiv_id": "2410.01368v1",
    "title": "Theoretical Lower Bounds for the Oven Scheduling Problem",
    "authors": [
      "Francesca Da Ros",
      "Marie-Louise Lackner",
      "Nysret Musliu"
    ],
    "abstract": "The Oven Scheduling Problem (OSP) is an NP-hard real-world parallel batch\nscheduling problem arising in the semiconductor industry. The objective of the\nproblem is to schedule a set of jobs on ovens while minimizing several factors,\nnamely total oven runtime, job tardiness, and setup costs. At the same time, it\nmust adhere to various constraints such as oven eligibility and availability,\njob release dates, setup times between batches, and oven capacity limitations.\nThe key to obtaining efficient schedules is to process compatible jobs\nsimultaneously in batches. In this paper, we develop theoretical,\nproblem-specific lower bounds for the OSP that can be computed very quickly. We\nthoroughly examine these lower bounds, evaluating their quality and exploring\ntheir integration into existing solution methods. Specifically, we investigate\ntheir contribution to exact methods and a metaheuristic local search approach\nusing simulated annealing. Moreover, these problem-specific lower bounds enable\nus to assess the solution quality for large instances for which exact methods\noften fail to provide tight lower bounds.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2203.12517",
    "pdf_url": "http://arxiv.org/pdf/2410.01368v1",
    "published_date": "2024-10-02 09:30:01 UTC",
    "updated_date": "2024-10-02 09:30:01 UTC"
  },
  {
    "arxiv_id": "2410.01363v1",
    "title": "PCQPR: Proactive Conversational Question Planning with Reflection",
    "authors": [
      "Shasha Guo",
      "Lizi Liao",
      "Jing Zhang",
      "Cuiping Li",
      "Hong Chen"
    ],
    "abstract": "Conversational Question Generation (CQG) enhances the interactivity of\nconversational question-answering systems in fields such as education, customer\nservice, and entertainment. However, traditional CQG, focusing primarily on the\nimmediate context, lacks the conversational foresight necessary to guide\nconversations toward specified conclusions. This limitation significantly\nrestricts their ability to achieve conclusion-oriented conversational outcomes.\nIn this work, we redefine the CQG task as Conclusion-driven Conversational\nQuestion Generation (CCQG) by focusing on proactivity, not merely reacting to\nthe unfolding conversation but actively steering it towards a\nconclusion-oriented question-answer pair. To address this, we propose a novel\napproach, called Proactive Conversational Question Planning with self-Refining\n(PCQPR). Concretely, by integrating a planning algorithm inspired by Monte\nCarlo Tree Search (MCTS) with the analytical capabilities of large language\nmodels (LLMs), PCQPR predicts future conversation turns and continuously\nrefines its questioning strategies. This iterative self-refining mechanism\nensures the generation of contextually relevant questions strategically devised\nto reach a specified outcome. Our extensive evaluations demonstrate that PCQPR\nsignificantly surpasses existing CQG methods, marking a paradigm shift towards\nconclusion-oriented conversational question-answering systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2410.01363v1",
    "published_date": "2024-10-02 09:23:07 UTC",
    "updated_date": "2024-10-02 09:23:07 UTC"
  },
  {
    "arxiv_id": "2410.03758v3",
    "title": "Towards a Deeper Understanding of Transformer for Residential Non-intrusive Load Monitoring",
    "authors": [
      "Minhajur Rahman",
      "Yasir Arafat"
    ],
    "abstract": "Transformer models have demonstrated impressive performance in Non-Intrusive\nLoad Monitoring (NILM) applications in recent years. Despite their success,\nexisting studies have not thoroughly examined the impact of various\nhyper-parameters on model performance, which is crucial for advancing\nhigh-performing transformer models. In this work, a comprehensive series of\nexperiments have been conducted to analyze the influence of these\nhyper-parameters in the context of residential NILM. This study delves into the\neffects of the number of hidden dimensions in the attention layer, the number\nof attention layers, the number of attention heads, and the dropout ratio on\ntransformer performance. Furthermore, the role of the masking ratio has\nexplored in BERT-style transformer training, providing a detailed investigation\ninto its impact on NILM tasks. Based on these experiments, the optimal\nhyper-parameters have been selected and used them to train a transformer model,\nwhich surpasses the performance of existing models. The experimental findings\noffer valuable insights and guidelines for optimizing transformer\narchitectures, aiming to enhance their effectiveness and efficiency in NILM\napplications. It is expected that this work will serve as a foundation for\nfuture research and development of more robust and capable transformer models\nfor NILM.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted to 4th IEEE-ICISET",
    "pdf_url": "http://arxiv.org/pdf/2410.03758v3",
    "published_date": "2024-10-02 09:14:50 UTC",
    "updated_date": "2024-10-13 12:40:37 UTC"
  },
  {
    "arxiv_id": "2410.01353v3",
    "title": "Codev-Bench: How Do LLMs Understand Developer-Centric Code Completion?",
    "authors": [
      "Zhenyu Pan",
      "Rongyu Cao",
      "Yongchang Cao",
      "Yingwei Ma",
      "Binhua Li",
      "Fei Huang",
      "Han Liu",
      "Yongbin Li"
    ],
    "abstract": "Code completion, a key downstream task in code generation, is one of the most\nfrequent and impactful methods for enhancing developer productivity in software\ndevelopment. As intelligent completion tools evolve, we need a robust\nevaluation benchmark that enables meaningful comparisons between products and\nguides future advancements. However, existing benchmarks focus more on\ncoarse-grained tasks without industrial analysis resembling general code\ngeneration rather than the real-world scenarios developers encounter. Moreover,\nthese benchmarks often rely on costly and time-consuming human annotation, and\nthe standalone test cases fail to leverage minimal tests for maximum\nrepository-level understanding and code coverage. To address these limitations,\nwe first analyze business data from an industrial code completion tool and\nredefine the evaluation criteria to better align with the developer's intent\nand desired completion behavior throughout the coding process. Based on these\ninsights, we introduce Codev-Agent, an agent-based system that automates\nrepository crawling, constructs execution environments, extracts dynamic\ncalling chains from existing unit tests, and generates new test samples to\navoid data leakage, ensuring fair and effective comparisons. Using Codev-Agent,\nwe present the Code-Development Benchmark (Codev-Bench), a fine-grained,\nreal-world, repository-level, and developer-centric evaluation framework.\nCodev-Bench assesses whether a code completion tool can capture a developer's\nimmediate intent and suggest appropriate code across diverse contexts,\nproviding a more realistic benchmark for code completion in modern software\ndevelopment.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01353v3",
    "published_date": "2024-10-02 09:11:10 UTC",
    "updated_date": "2024-10-24 06:24:56 UTC"
  },
  {
    "arxiv_id": "2410.01350v2",
    "title": "Takin-VC: Expressive Zero-Shot Voice Conversion via Adaptive Hybrid Content Encoding and Enhanced Timbre Modeling",
    "authors": [
      "Yuguang Yang",
      "Yu Pan",
      "Jixun Yao",
      "Xiang Zhang",
      "Jianhao Ye",
      "Hongbin Zhou",
      "Lei Xie",
      "Lei Ma",
      "Jianjun Zhao"
    ],
    "abstract": "Expressive zero-shot voice conversion (VC) is a critical and challenging task\nthat aims to transform the source timbre into an arbitrary unseen speaker while\npreserving the original content and expressive qualities. Despite recent\nprogress in zero-shot VC, there remains considerable potential for improvements\nin speaker similarity and speech naturalness. Moreover, existing zero-shot VC\nsystems struggle to fully reproduce paralinguistic information in highly\nexpressive speech, such as breathing, crying, and emotional nuances, limiting\ntheir practical applicability. To address these issues, we propose Takin-VC, a\nnovel expressive zero-shot VC framework via adaptive hybrid content encoding\nand memory-augmented context-aware timbre modeling. Specifically, we introduce\nan innovative hybrid content encoder that incorporates an adaptive fusion\nmodule, capable of effectively integrating quantized features of the\npre-trained WavLM and HybridFormer in an implicit manner, so as to extract\nprecise linguistic features while enriching paralinguistic elements. For timbre\nmodeling, we propose advanced memory-augmented and context-aware modules to\ngenerate high-quality target timbre features and fused representations that\nseamlessly align source content with target timbre. To enhance real-time\nperformance, we advocate a conditional flow matching model to reconstruct the\nMel-spectrogram of the source speech. Experimental results show that our\nTakin-VC consistently surpasses state-of-the-art VC systems, achieving notable\nimprovements in terms of speech naturalness, speech expressiveness, and speaker\nsimilarity, while offering enhanced inference speed.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Work in Progress; Under Review",
    "pdf_url": "http://arxiv.org/pdf/2410.01350v2",
    "published_date": "2024-10-02 09:07:33 UTC",
    "updated_date": "2025-01-10 05:35:32 UTC"
  },
  {
    "arxiv_id": "2410.01349v1",
    "title": "Life, uh, Finds a Way: Systematic Neural Search",
    "authors": [
      "Alex Baranski",
      "Jun Tani"
    ],
    "abstract": "We tackle the challenge of rapidly adapting an agent's behavior to solve\nspatiotemporally continuous problems in novel settings. Animals exhibit\nextraordinary abilities to adapt to new contexts, a capacity unmatched by\nartificial systems. Instead of focusing on generalization through deep\nreinforcement learning, we propose viewing behavior as the physical\nmanifestation of a search procedure, where robust problem-solving emerges from\nan exhaustive search across all possible behaviors. Surprisingly, this can be\ndone efficiently using online modification of a cognitive graph that guides\naction, challenging the predominant view that exhaustive search in continuous\nspaces is impractical. We describe an algorithm that implicitly enumerates\nbehaviors by regulating the tight feedback loop between execution of behaviors\nand mutation of the graph, and provide a neural implementation based on Hebbian\nlearning and a novel high-dimensional harmonic representation inspired by\nentorhinal cortex. By framing behavior as search, we provide a mathematically\nsimple and biologically plausible model for real-time behavioral adaptation,\nsuccessfully solving a variety of continuous state-space navigation problems.\nThis framework not only offers a flexible neural substrate for other\napplications but also presents a powerful paradigm for understanding adaptive\nbehavior. Our results suggest potential advancements in developmental learning\nand unsupervised skill acquisition, paving the way for autonomous robots to\nmaster complex skills in data-sparse environments demanding flexibility.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01349v1",
    "published_date": "2024-10-02 09:06:54 UTC",
    "updated_date": "2024-10-02 09:06:54 UTC"
  },
  {
    "arxiv_id": "2410.13868v1",
    "title": "Stars, Stripes, and Silicon: Unravelling the ChatGPT's All-American, Monochrome, Cis-centric Bias",
    "authors": [
      "Federico Torrielli"
    ],
    "abstract": "This paper investigates the challenges associated with bias, toxicity,\nunreliability, and lack of robustness in large language models (LLMs) such as\nChatGPT. It emphasizes that these issues primarily stem from the quality and\ndiversity of data on which LLMs are trained, rather than the model\narchitectures themselves. As LLMs are increasingly integrated into various\nreal-world applications, their potential to negatively impact society by\namplifying existing biases and generating harmful content becomes a pressing\nconcern. The paper calls for interdisciplinary efforts to address these\nchallenges. Additionally, it highlights the need for collaboration between\nresearchers, practitioners, and stakeholders to establish governance\nframeworks, oversight, and accountability mechanisms to mitigate the harmful\nconsequences of biased LLMs. By proactively addressing these challenges, the AI\ncommunity can harness the enormous potential of LLMs for the betterment of\nsociety without perpetuating harmful biases or exacerbating existing\ninequalities.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13868v1",
    "published_date": "2024-10-02 08:55:00 UTC",
    "updated_date": "2024-10-02 08:55:00 UTC"
  },
  {
    "arxiv_id": "2410.01337v3",
    "title": "PhyMPGN: Physics-encoded Message Passing Graph Network for spatiotemporal PDE systems",
    "authors": [
      "Bocheng Zeng",
      "Qi Wang",
      "Mengtao Yan",
      "Yang Liu",
      "Ruizhi Chengze",
      "Yi Zhang",
      "Hongsheng Liu",
      "Zidong Wang",
      "Hao Sun"
    ],
    "abstract": "Solving partial differential equations (PDEs) serves as a cornerstone for\nmodeling complex dynamical systems. Recent progresses have demonstrated grand\nbenefits of data-driven neural-based models for predicting spatiotemporal\ndynamics (e.g., tremendous speedup gain compared with classical numerical\nmethods). However, most existing neural models rely on rich training data, have\nlimited extrapolation and generalization abilities, and suffer to produce\nprecise or reliable physical prediction under intricate conditions (e.g.,\nirregular mesh or geometry, complex boundary conditions, diverse PDE\nparameters, etc.). To this end, we propose a new graph learning approach,\nnamely, Physics-encoded Message Passing Graph Network (PhyMPGN), to model\nspatiotemporal PDE systems on irregular meshes given small training datasets.\nSpecifically, we incorporate a GNN into a numerical integrator to approximate\nthe temporal marching of spatiotemporal dynamics for a given PDE system.\nConsidering that many physical phenomena are governed by diffusion processes,\nwe further design a learnable Laplace block, which encodes the discrete\nLaplace-Beltrami operator, to aid and guide the GNN learning in a physically\nfeasible solution space. A boundary condition padding strategy is also designed\nto improve the model convergence and accuracy. Extensive experiments\ndemonstrate that PhyMPGN is capable of accurately predicting various types of\nspatiotemporal dynamics on coarse unstructured meshes, consistently achieves\nthe state-of-the-art results, and outperforms other baselines with considerable\ngains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01337v3",
    "published_date": "2024-10-02 08:54:18 UTC",
    "updated_date": "2025-03-03 02:50:30 UTC"
  },
  {
    "arxiv_id": "2410.01335v2",
    "title": "Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language Models",
    "authors": [
      "Lucas Bandarkar",
      "Benjamin Muller",
      "Pritish Yuvraj",
      "Rui Hou",
      "Nayan Singhal",
      "Hongjiang Lv",
      "Bing Liu"
    ],
    "abstract": "Model merging, such as model souping, is the practice of combining different\nmodels with the same architecture together without further training. In this\nwork, we present a model merging methodology that addresses the difficulty of\nfine-tuning Large Language Models (LLMs) for target tasks in non-English\nlanguages, where task-specific data is often unavailable. We focus on\nmathematical reasoning and without in-language math data, facilitate\ncross-lingual transfer by composing language and math capabilities. Starting\nfrom the same pretrained model, we fine-tune separate \"experts\" on math\ninstruction data in English and on generic instruction data in the target\nlanguage. We then replace the top and bottom transformer layers of the math\nexpert directly with layers from the language expert, which consequently\nenhances math performance in the target language. The resulting merged models\noutperform the individual experts and other merging methods on the math\nbenchmark, MGSM, by 10% across four major languages where math instruction data\nis scarce. In addition, this layer swapping is simple, inexpensive, and\nintuitive, as it is based on an interpretative analysis of the most important\nparameter changes during the fine-tuning of each expert. The ability to\nsuccessfully re-compose LLMs for cross-lingual transfer in this manner opens up\nfuture possibilities to combine model expertise, create modular solutions, and\ntransfer reasoning capabilities across languages all post hoc.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025, Spotlight Paper, In The Thirteenth International\n  Conference on Learning Representations, 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.01335v2",
    "published_date": "2024-10-02 08:53:07 UTC",
    "updated_date": "2025-03-04 18:15:16 UTC"
  },
  {
    "arxiv_id": "2410.01334v2",
    "title": "Unveiling Language Skills via Path-Level Circuit Discovery",
    "authors": [
      "Hang Chen",
      "Jiaying Zhu",
      "Xinyu Yang",
      "Wenya Wang"
    ],
    "abstract": "Circuit discovery with edge-level ablation has become a foundational\nframework for mechanism interpretability of language models. However, its focus\non individual edges often overlooks the sequential, path-level causal\nrelationships that underpin complex behaviors, thus potentially leading to\nmisleading or incomplete circuit discoveries. To address this issue, we propose\na novel path-level circuit discovery framework capturing how behaviors emerge\nthrough interconnected linear chain and build towards complex behaviors. Our\nframework is constructed upon a fully-disentangled linear combinations of\n``memory circuits'' decomposed from the original model. To discover functional\ncircuit paths, we leverage a 2-step pruning strategy by first reducing the\ncomputational graph to a faithful and minimal subgraph and then applying causal\nmediation to identify common paths of a specific skill, termed as skill paths.\nIn contrast to circuit graph from existing works, we focus on the complete\npaths of a generic skill rather than on the fine-grained responses to\nindividual components of the input. To demonstrate this, we explore three\ngeneric language skills, namely Previous Token Skill, Induction Skill and\nIn-Context Learning Skill using our framework and provide more compelling\nevidence to substantiate stratification and inclusiveness of these skills.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.01334v2",
    "published_date": "2024-10-02 08:52:58 UTC",
    "updated_date": "2024-12-16 03:33:36 UTC"
  },
  {
    "arxiv_id": "2410.02832v1",
    "title": "FlipAttack: Jailbreak LLMs via Flipping",
    "authors": [
      "Yue Liu",
      "Xiaoxin He",
      "Miao Xiong",
      "Jinlan Fu",
      "Shumin Deng",
      "Bryan Hooi"
    ],
    "abstract": "This paper proposes a simple yet effective jailbreak attack named FlipAttack\nagainst black-box LLMs. First, from the autoregressive nature, we reveal that\nLLMs tend to understand the text from left to right and find that they struggle\nto comprehend the text when noise is added to the left side. Motivated by these\ninsights, we propose to disguise the harmful prompt by constructing left-side\nnoise merely based on the prompt itself, then generalize this idea to 4\nflipping modes. Second, we verify the strong ability of LLMs to perform the\ntext-flipping task, and then develop 4 variants to guide LLMs to denoise,\nunderstand, and execute harmful behaviors accurately. These designs keep\nFlipAttack universal, stealthy, and simple, allowing it to jailbreak black-box\nLLMs within only 1 query. Experiments on 8 LLMs demonstrate the superiority of\nFlipAttack. Remarkably, it achieves $\\sim$98\\% attack success rate on GPT-4o,\nand $\\sim$98\\% bypass rate against 5 guardrail models on average. The codes are\navailable at GitHub\\footnote{https://github.com/yueliu1999/FlipAttack}.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "43 pages, 31 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.02832v1",
    "published_date": "2024-10-02 08:41:23 UTC",
    "updated_date": "2024-10-02 08:41:23 UTC"
  },
  {
    "arxiv_id": "2410.01324v1",
    "title": "Fair Class-Incremental Learning using Sample Weighting",
    "authors": [
      "Jaeyoung Park",
      "Minsu Kim",
      "Steven Euijong Whang"
    ],
    "abstract": "Model fairness is becoming important in class-incremental learning for\nTrustworthy AI. While accuracy has been a central focus in class-incremental\nlearning, fairness has been relatively understudied. However, naively using all\nthe samples of the current task for training results in unfair catastrophic\nforgetting for certain sensitive groups including classes. We theoretically\nanalyze that forgetting occurs if the average gradient vector of the current\ntask data is in an \"opposite direction\" compared to the average gradient vector\nof a sensitive group, which means their inner products are negative. We then\npropose a fair class-incremental learning framework that adjusts the training\nweights of current task samples to change the direction of the average gradient\nvector and thus reduce the forgetting of underperforming groups and achieve\nfairness. For various group fairness measures, we formulate optimization\nproblems to minimize the overall losses of sensitive groups while minimizing\nthe disparities among them. We also show the problems can be solved with linear\nprogramming and propose an efficient Fairness-aware Sample Weighting (FSW)\nalgorithm. Experiments show that FSW achieves better accuracy-fairness tradeoff\nresults than state-of-the-art approaches on real datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01324v1",
    "published_date": "2024-10-02 08:32:21 UTC",
    "updated_date": "2024-10-02 08:32:21 UTC"
  },
  {
    "arxiv_id": "2410.01322v2",
    "title": "Forte : Finding Outliers with Representation Typicality Estimation",
    "authors": [
      "Debargha Ganguly",
      "Warren Morningstar",
      "Andrew Yu",
      "Vipin Chaudhary"
    ],
    "abstract": "Generative models can now produce photorealistic synthetic data which is\nvirtually indistinguishable from the real data used to train it. This is a\nsignificant evolution over previous models which could produce reasonable\nfacsimiles of the training data, but ones which could be visually distinguished\nfrom the training data by human evaluation. Recent work on OOD detection has\nraised doubts that generative model likelihoods are optimal OOD detectors due\nto issues involving likelihood misestimation, entropy in the generative\nprocess, and typicality. We speculate that generative OOD detectors also failed\nbecause their models focused on the pixels rather than the semantic content of\nthe data, leading to failures in near-OOD cases where the pixels may be similar\nbut the information content is significantly different. We hypothesize that\nestimating typical sets using self-supervised learners leads to better OOD\ndetectors. We introduce a novel approach that leverages representation\nlearning, and informative summary statistics based on manifold estimation, to\naddress all of the aforementioned issues. Our method outperforms other\nunsupervised approaches and achieves state-of-the art performance on\nwell-established challenging benchmarks, and new synthetic data detection\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01322v2",
    "published_date": "2024-10-02 08:26:37 UTC",
    "updated_date": "2024-12-09 05:13:27 UTC"
  },
  {
    "arxiv_id": "2410.01319v1",
    "title": "Finetuning Pre-trained Model with Limited Data for LiDAR-based 3D Object Detection by Bridging Domain Gaps",
    "authors": [
      "Jiyun Jang",
      "Mincheol Chang",
      "Jongwon Park",
      "Jinkyu Kim"
    ],
    "abstract": "LiDAR-based 3D object detectors have been largely utilized in various\napplications, including autonomous vehicles or mobile robots. However,\nLiDAR-based detectors often fail to adapt well to target domains with different\nsensor configurations (e.g., types of sensors, spatial resolution, or FOVs) and\nlocation shifts. Collecting and annotating datasets in a new setup is commonly\nrequired to reduce such gaps, but it is often expensive and time-consuming.\nRecent studies suggest that pre-trained backbones can be learned in a\nself-supervised manner with large-scale unlabeled LiDAR frames. However,\ndespite their expressive representations, they remain challenging to generalize\nwell without substantial amounts of data from the target domain. Thus, we\npropose a novel method, called Domain Adaptive Distill-Tuning (DADT), to adapt\na pre-trained model with limited target data (approximately 100 LiDAR frames),\nretaining its representation power and preventing it from overfitting.\nSpecifically, we use regularizers to align object-level and context-level\nrepresentations between the pre-trained and finetuned models in a\nteacher-student architecture. Our experiments with driving benchmarks, i.e.,\nWaymo Open dataset and KITTI, confirm that our method effectively finetunes a\npre-trained model, achieving significant gains in accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.01319v1",
    "published_date": "2024-10-02 08:22:42 UTC",
    "updated_date": "2024-10-02 08:22:42 UTC"
  },
  {
    "arxiv_id": "2410.01308v2",
    "title": "Rethinking GNN Expressive Power Research in the Machine Learning Community: Limitations, Issues, and Corrections",
    "authors": [
      "Guanyu Cui",
      "Zhewei Wei",
      "Hsin-Hao Su"
    ],
    "abstract": "The success of graph neural networks (GNNs) has spurred theoretical\nexplorations into their expressive power. In the graph machine learning\ncommunity, researchers often equate GNNs with the Weisfeiler-Lehman (WL) tests\nas a foundation for theoretical analysis. However, we identify two major\nlimitations of this approach: (1) the semantics of WL tests involve verifying\npurely structural equivalences through a set of logical sentences. As a result,\nthey do not align well with the concept of expressive power, which is typically\ndefined as the class of functions that GNNs can express, and they are not\nwell-suited for handling graphs with features; (2) by leveraging communication\ncomplexity, we show that the lower bound on a GNN's capacity (depth multiplied\nby width) to simulate one iteration of the WL test grows almost linearly with\nthe graph size. This finding indicates that the WL test is not locally\ncomputable and is misaligned with the message-passing GNNs. Furthermore, we\nshow that allowing unlimited precomputation or directly integrating features\ncomputed by external models, while claiming that these precomputations enhance\nthe expressiveness of GNNs, can sometimes lead to issues. Such problems can\neven be observed in an influential paper published in a top-tier machine\nlearning conference. We argue that using well-defined computational models,\nsuch as the CONGEST model from distributed computing, is a reasonable approach\nto characterizing and exploring GNNs' expressive power. Following this\napproach, we present some results on the effects of virtual nodes and edges.\nFinally, we highlight several open problems regarding GNN expressive power for\nfurther exploration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "+"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01308v2",
    "published_date": "2024-10-02 08:01:50 UTC",
    "updated_date": "2025-02-15 12:13:08 UTC"
  },
  {
    "arxiv_id": "2410.01307v1",
    "title": "FanCric : Multi-Agentic Framework for Crafting Fantasy 11 Cricket Teams",
    "authors": [
      "Mohit Bhatnagar"
    ],
    "abstract": "Cricket, with its intricate strategies and deep history, increasingly\ncaptivates a global audience. The Indian Premier League (IPL), epitomizing\nTwenty20 cricket, showcases talent in a format that lasts just a few hours as\nopposed to the longer forms of the game. Renowned for its fusion of technology\nand fan engagement, the IPL stands as the world's most popular cricket league.\nThis study concentrates on Dream11, India's leading fantasy cricket league for\nIPL, where participants craft virtual teams based on real player performances\nto compete internationally. Building a winning fantasy team requires navigating\nvarious complex factors including player form and match conditions.\nTraditionally, this has been approached through operations research and machine\nlearning. This research introduces the FanCric framework, an advanced\nmulti-agent system leveraging Large Language Models (LLMs) and a robust\norchestration framework to enhance fantasy team selection in cricket. FanCric\nemploys both structured and unstructured data to surpass traditional methods by\nincorporating sophisticated AI technologies. The analysis involved scrutinizing\napproximately 12.7 million unique entries from a Dream11 contest, evaluating\nFanCric's efficacy against the collective wisdom of crowds and a simpler Prompt\nEngineering approach. Ablation studies further assessed the impact of\ngenerating varying numbers of teams. The exploratory findings are promising,\nindicating that further investigation into FanCric's capabilities is warranted\nto fully realize its potential in enhancing strategic decision-making using\nLLMs in fantasy sports and business in general.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01307v1",
    "published_date": "2024-10-02 08:01:28 UTC",
    "updated_date": "2024-10-02 08:01:28 UTC"
  },
  {
    "arxiv_id": "2410.01306v2",
    "title": "Emotion-Aware Embedding Fusion in LLMs (Flan-T5, LLAMA 2, DeepSeek-R1, and ChatGPT 4) for Intelligent Response Generation",
    "authors": [
      "Abdur Rasool",
      "Muhammad Irfan Shahzad",
      "Hafsa Aslam",
      "Vincent Chan",
      "Muhammad Ali Arshad"
    ],
    "abstract": "Empathetic and coherent responses are critical in auto-mated\nchatbot-facilitated psychotherapy. This study addresses the challenge of\nenhancing the emotional and contextual understanding of large language models\n(LLMs) in psychiatric applications. We introduce Emotion-Aware Embedding\nFusion, a novel framework integrating hierarchical fusion and attention\nmechanisms to prioritize semantic and emotional features in therapy\ntranscripts. Our approach combines multiple emotion lexicons, including NRC\nEmotion Lexicon, VADER, WordNet, and SentiWordNet, with state-of-the-art LLMs\nsuch as Flan-T5, LLAMA 2, DeepSeek-R1, and ChatGPT 4. Therapy session\ntranscripts, comprising over 2,000 samples are segmented into hierarchical\nlevels (word, sentence, and session) using neural networks, while hierarchical\nfusion combines these features with pooling techniques to refine emotional\nrepresentations. Atten-tion mechanisms, including multi-head self-attention and\ncross-attention, further prioritize emotional and contextual features, enabling\ntemporal modeling of emotion-al shifts across sessions. The processed\nembeddings, computed using BERT, GPT-3, and RoBERTa are stored in the Facebook\nAI similarity search vector database, which enables efficient similarity search\nand clustering across dense vector spaces. Upon user queries, relevant segments\nare retrieved and provided as context to LLMs, enhancing their ability to\ngenerate empathetic and con-textually relevant responses. The proposed\nframework is evaluated across multiple practical use cases to demonstrate\nreal-world applicability, including AI-driven therapy chatbots. The system can\nbe integrated into existing mental health platforms to generate personalized\nresponses based on retrieved therapy session data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01306v2",
    "published_date": "2024-10-02 08:01:05 UTC",
    "updated_date": "2025-03-11 10:08:37 UTC"
  },
  {
    "arxiv_id": "2410.01296v1",
    "title": "Speculative Coreset Selection for Task-Specific Fine-tuning",
    "authors": [
      "Xiaoyu Zhang",
      "Juan Zhai",
      "Shiqing Ma",
      "Chao Shen",
      "Tianlin Li",
      "Weipeng Jiang",
      "Yang Liu"
    ],
    "abstract": "Task-specific fine-tuning is essential for the deployment of large language\nmodels (LLMs), but it requires significant computational resources and time.\nExisting solutions have proposed coreset selection methods to improve data\nefficiency and reduce model training overhead, but they still have limitations:\n1) Overlooking valuable samples at high pruning rates, which degrades the\ncoreset's performance. 2) Requiring high time overhead during coreset selection\nto fine-tune and evaluate the target LLM. In this paper, we introduce STAFF, a\nspeculative coreset selection method. STAFF leverages a small model from the\nsame family as the target LLM to efficiently estimate data scores and then\nverifies the scores on the target LLM to accurately identify and allocate more\nselection budget to important regions while maintaining coverage of easy\nregions. We evaluate STAFF on three LLMs and three downstream tasks and show\nthat STAFF improves the performance of SOTA methods by up to 54.3% and reduces\nselection overhead by up to 70.5% at different pruning rates. Furthermore, we\nobserve that the coreset selected by STAFF at low pruning rates (i.e., 20%) can\neven obtain better fine-tuning performance than the full dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 4 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.01296v1",
    "published_date": "2024-10-02 07:42:25 UTC",
    "updated_date": "2024-10-02 07:42:25 UTC"
  },
  {
    "arxiv_id": "2410.01290v1",
    "title": "Towards a Law of Iterated Expectations for Heuristic Estimators",
    "authors": [
      "Paul Christiano",
      "Jacob Hilton",
      "Andrea Lincoln",
      "Eric Neyman",
      "Mark Xu"
    ],
    "abstract": "Christiano et al. (2022) define a *heuristic estimator* to be a hypothetical\nalgorithm that estimates the values of mathematical expressions from arguments.\nIn brief, a heuristic estimator $\\mathbb{G}$ takes as input a mathematical\nexpression $Y$ and a formal \"heuristic argument\" $\\pi$, and outputs an estimate\n$\\mathbb{G}(Y \\mid \\pi)$ of $Y$. In this work, we argue for the informal\nprinciple that a heuristic estimator ought not to be able to predict its own\nerrors, and we explore approaches to formalizing this principle. Most simply,\nthe principle suggests that $\\mathbb{G}(Y - \\mathbb{G}(Y \\mid \\pi) \\mid \\pi)$\nought to equal zero for all $Y$ and $\\pi$. We argue that an ideal heuristic\nestimator ought to satisfy two stronger properties in this vein, which we term\n*iterated estimation* (by analogy to the law of iterated expectations) and\n*error orthogonality*.\n  Although iterated estimation and error orthogonality are intuitively\nappealing, it can be difficult to determine whether a given heuristic estimator\nsatisfies the properties. As an alternative approach, we explore *accuracy*: a\nproperty that (roughly) states that $\\mathbb{G}$ has zero average error over a\ndistribution of mathematical expressions. However, in the context of two\nestimation problems, we demonstrate barriers to creating an accurate heuristic\nestimator. We finish by discussing challenges and potential paths forward for\nfinding a heuristic estimator that accords with our intuitive understanding of\nhow such an estimator ought to behave, as well as the potential applications of\nheuristic estimators to understanding the behavior of neural networks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "47 pages, 2 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.01290v1",
    "published_date": "2024-10-02 07:33:27 UTC",
    "updated_date": "2024-10-02 07:33:27 UTC"
  },
  {
    "arxiv_id": "2410.01281v2",
    "title": "Uncertainty-aware Human Mobility Modeling and Anomaly Detection",
    "authors": [
      "Haomin Wen",
      "Shurui Cao",
      "Zeeshan Rasheed",
      "Khurram Hassan Shafique",
      "Leman Akoglu"
    ],
    "abstract": "Given the temporal GPS coordinates from a large set of human agents, how can\nwe model their mobility behavior toward effective anomaly (e.g. bad-actor or\nmalicious behavior) detection without any labeled data? Human mobility and\ntrajectory modeling have been extensively studied, showcasing varying abilities\nto manage complex inputs and balance performance-efficiency trade-offs. In this\nwork, we formulate anomaly detection in complex human behavior by modeling raw\nGPS data as a sequence of stay-point events, each characterized by\nspatio-temporal features, along with trips (i.e. commute) between the\nstay-points. Our problem formulation allows us to leverage modern sequence\nmodels for unsupervised training and anomaly detection. Notably, we equip our\nproposed model USTAD (for Uncertainty-aware Spatio-Temporal Anomaly Detection)\nwith aleatoric (i.e. data) uncertainty estimation to account for inherent\nstochasticity in certain individuals' behavior, as well as epistemic (i.e.\nmodel) uncertainty to handle data sparsity under a large variety of human\nbehaviors. Together, aleatoric and epistemic uncertainties unlock a robust loss\nfunction as well as uncertainty-aware decision-making in anomaly scoring.\nExtensive experiments shows that USTAD improves anomaly detection AUCROC by\n3\\%-15\\% over baselines in industry-scale data.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01281v2",
    "published_date": "2024-10-02 06:57:08 UTC",
    "updated_date": "2025-05-05 22:42:32 UTC"
  },
  {
    "arxiv_id": "2410.01276v1",
    "title": "Deep Unlearn: Benchmarking Machine Unlearning",
    "authors": [
      "Xavier F. Cadet",
      "Anastasia Borovykh",
      "Mohammad Malekzadeh",
      "Sara Ahmadi-Abhari",
      "Hamed Haddadi"
    ],
    "abstract": "Machine unlearning (MU) aims to remove the influence of particular data\npoints from the learnable parameters of a trained machine learning model. This\nis a crucial capability in light of data privacy requirements, trustworthiness,\nand safety in deployed models. MU is particularly challenging for deep neural\nnetworks (DNNs), such as convolutional nets or vision transformers, as such\nDNNs tend to memorize a notable portion of their training dataset.\nNevertheless, the community lacks a rigorous and multifaceted study that looks\ninto the success of MU methods for DNNs. In this paper, we investigate 18\nstate-of-the-art MU methods across various benchmark datasets and models, with\neach evaluation conducted over 10 different initializations, a comprehensive\nevaluation involving MU over 100K models. We show that, with the proper\nhyperparameters, Masked Small Gradients (MSG) and Convolution Transpose (CT),\nconsistently perform better in terms of model accuracy and run-time efficiency\nacross different models, datasets, and initializations, assessed by\npopulation-based membership inference attacks (MIA) and per-sample unlearning\nlikelihood ratio attacks (U-LiRA). Furthermore, our benchmark highlights the\nfact that comparing a MU method only with commonly used baselines, such as\nGradient Ascent (GA) or Successive Random Relabeling (SRL), is inadequate, and\nwe need better baselines like Negative Gradient Plus (NG+) with proper\nhyperparameter selection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01276v1",
    "published_date": "2024-10-02 06:41:58 UTC",
    "updated_date": "2024-10-02 06:41:58 UTC"
  },
  {
    "arxiv_id": "2410.03756v2",
    "title": "The Smart Buildings Control Suite: A Diverse Open Source Benchmark to Evaluate and Scale HVAC Control Policies for Sustainability",
    "authors": [
      "Judah Goldfeder",
      "Victoria Dean",
      "Zixin Jiang",
      "Xuezheng Wang",
      "Bing dong",
      "Hod Lipson",
      "John Sipple"
    ],
    "abstract": "Commercial buildings account for 17% of U.S. carbon emissions, with roughly\nhalf of that from Heating, Ventilation, and Air Conditioning (HVAC). HVAC\ndevices form a complex thermodynamic system, and while Model Predictive Control\nand Reinforcement Learning have been used to optimize control policies, scaling\nto thousands of buildings remains a significant unsolved challenge. Most\ncurrent algorithms are over-optimized for specific buildings and rely on\nproprietary data or hard-to-configure simulations. We present the Smart\nBuildings Control Suite, the first open source interactive HVAC control\nbenchmark with a focus on solutions that scale. It consists of 3 components:\nreal-world telemetric data extracted from 11 buildings over 6 years, a\nlightweight data-driven simulator for each building, and a modular Physically\nInformed Neural Network (PINN) building model as a simulator alternative. The\nbuildings span a variety of climates, management systems, and sizes, and both\nthe simulator and PINN easily scale to new buildings, ensuring solutions using\nthis benchmark are robust to these factors and only reliant on fully scalable\nbuilding models. This represents a major step towards scaling HVAC optimization\nfrom the lab to buildings everywhere. To facilitate use, our benchmark is\ncompatible with the Gym standard, and our data is part of TensorFlow Datasets.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.DC",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03756v2",
    "published_date": "2024-10-02 06:30:07 UTC",
    "updated_date": "2025-01-31 14:29:42 UTC"
  },
  {
    "arxiv_id": "2410.01265v3",
    "title": "Transformers Handle Endogeneity in In-Context Linear Regression",
    "authors": [
      "Haodong Liang",
      "Krishnakumar Balasubramanian",
      "Lifeng Lai"
    ],
    "abstract": "We explore the capability of transformers to address endogeneity in\nin-context linear regression. Our main finding is that transformers inherently\npossess a mechanism to handle endogeneity effectively using instrumental\nvariables (IV). First, we demonstrate that the transformer architecture can\nemulate a gradient-based bi-level optimization procedure that converges to the\nwidely used two-stage least squares $(\\textsf{2SLS})$ solution at an\nexponential rate. Next, we propose an in-context pretraining scheme and provide\ntheoretical guarantees showing that the global minimizer of the pre-training\nloss achieves a small excess loss. Our extensive experiments validate these\ntheoretical findings, showing that the trained transformer provides more robust\nand reliable in-context predictions and coefficient estimates than the\n$\\textsf{2SLS}$ method, in the presence of endogeneity.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "econ.EM",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "37 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01265v3",
    "published_date": "2024-10-02 06:21:04 UTC",
    "updated_date": "2025-05-11 02:08:45 UTC"
  },
  {
    "arxiv_id": "2410.01257v2",
    "title": "HelpSteer2-Preference: Complementing Ratings with Preferences",
    "authors": [
      "Zhilin Wang",
      "Alexander Bukharin",
      "Olivier Delalleau",
      "Daniel Egert",
      "Gerald Shen",
      "Jiaqi Zeng",
      "Oleksii Kuchaiev",
      "Yi Dong"
    ],
    "abstract": "Reward models are critical for aligning models to follow instructions, and\nare typically trained following one of two popular paradigms: Bradley-Terry\nstyle or Regression style. However, there is a lack of evidence that either\napproach is better than the other, when adequately matched for data. This is\nprimarily because these approaches require data collected in different (but\nincompatible) formats, meaning that adequately matched data is not available in\nexisting public datasets. To tackle this problem, we release preference\nannotations (designed for Bradley-Terry training) to complement existing\nratings (designed for Regression style training) in the HelpSteer2 dataset. To\nimprove data interpretability, preference annotations are accompanied with\nhuman-written justifications. Using this data, we conduct the first\nhead-to-head comparison of Bradley-Terry and Regression models when adequately\nmatched for data. Based on insights derived from such a comparison, we propose\na novel approach to combine Bradley-Terry and Regression reward modeling. A\nLlama-3.1-70B-Instruct model tuned with this approach scores 94.1 on\nRewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. This\nreward model can then be used with REINFORCE algorithm (RLHF) to align an\nInstruct model to reach 85.0 on Arena Hard, which is No. 1 as of 1 Oct 2024. We\nopen-source this dataset (CC-BY-4.0 license) at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new -- 1-oct-2024\nand openly release the trained Reward and Instruct models at\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025; 28 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01257v2",
    "published_date": "2024-10-02 06:05:52 UTC",
    "updated_date": "2025-03-06 12:13:14 UTC"
  },
  {
    "arxiv_id": "2410.01246v1",
    "title": "AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses",
    "authors": [
      "Xiaotian Lu",
      "Jiyi Li",
      "Koh Takeuchi",
      "Hisashi Kashima"
    ],
    "abstract": "Question answering (QA) tasks have been extensively studied in the field of\nnatural language processing (NLP). Answers to open-ended questions are highly\ndiverse and difficult to quantify, and cannot be simply evaluated as correct or\nincorrect, unlike close-ended questions with definitive answers. While large\nlanguage models (LLMs) have demonstrated strong capabilities across various\ntasks, they exhibit relatively weaker performance in evaluating answers to\nopen-ended questions. In this study, we propose a method that leverages LLMs\nand the analytic hierarchy process (AHP) to assess answers to open-ended\nquestions. We utilized LLMs to generate multiple evaluation criteria for a\nquestion. Subsequently, answers were subjected to pairwise comparisons under\neach criterion with LLMs, and scores for each answer were calculated in the\nAHP. We conducted experiments on four datasets using both ChatGPT-3.5-turbo and\nGPT-4. Our results indicate that our approach more closely aligns with human\njudgment compared to the four baselines. Additionally, we explored the impact\nof the number of criteria, variations in models, and differences in datasets on\nthe results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.01246v1",
    "published_date": "2024-10-02 05:22:07 UTC",
    "updated_date": "2024-10-02 05:22:07 UTC"
  },
  {
    "arxiv_id": "2410.01242v2",
    "title": "RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance",
    "authors": [
      "Haolin Jin",
      "Zechao Sun",
      "Huaming Chen"
    ],
    "abstract": "Large Language Models (LLMs) have shown incredible potential in code\ngeneration tasks, and recent research in prompt engineering have enhanced LLMs'\nunderstanding of textual information. However, ensuring the accuracy of\ngenerated code often requires extensive testing and validation by programmers.\nWhile LLMs can typically generate code based on task descriptions, their\naccuracy remains limited, especially for complex tasks that require a deeper\nunderstanding of both the problem statement and the code generation process.\nThis limitation is primarily due to the LLMs' need to simultaneously comprehend\ntext and generate syntactically and semantically correct code, without having\nthe capability to automatically refine the code. In real-world software\ndevelopment, programmers rarely produce flawless code in a single attempt based\non the task description alone, they rely on iterative feedback and debugging to\nrefine their programs. Inspired by this process, we introduce a novel\narchitecture of LLM-based agents for code generation and automatic debugging:\nRefinement and Guidance Debugging (RGD). The RGD framework is a multi-LLM-based\nagent debugger that leverages three distinct LLM agents-Guide Agent, Debug\nAgent, and Feedback Agent. RGD decomposes the code generation task into\nmultiple steps, ensuring a clearer workflow and enabling iterative code\nrefinement based on self-reflection and feedback. Experimental results\ndemonstrate that RGD exhibits remarkable code generation capabilities,\nachieving state-of-the-art performance with a 9.8% improvement on the HumanEval\ndataset and a 16.2% improvement on the MBPP dataset compared to the\nstate-of-the-art approaches and traditional direct prompting approaches. We\nhighlight the effectiveness of the RGD framework in enhancing LLMs' ability to\ngenerate and refine code autonomously.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01242v2",
    "published_date": "2024-10-02 05:07:02 UTC",
    "updated_date": "2024-10-03 13:12:24 UTC"
  },
  {
    "arxiv_id": "2410.01227v1",
    "title": "See Me and Believe Me: Causality and Intersectionality in Testimonial Injustice in Healthcare",
    "authors": [
      "Kenya S. Andrews",
      "Mesrob I. Ohannessian",
      "Elena Zheleva"
    ],
    "abstract": "In medical settings, it is critical that all who are in need of care are\ncorrectly heard and understood. When this is not the case due to prejudices a\nlistener has, the speaker is experiencing \\emph{testimonial injustice}, which,\nbuilding upon recent work, we quantify by the presence of several categories of\nunjust vocabulary in medical notes. In this paper, we use FCI, a causal\ndiscovery method, to study the degree to which certain demographic features\ncould lead to marginalization (e.g., age, gender, and race) by way of\ncontributing to testimonial injustice. To achieve this, we review physicians'\nnotes for each patient, where we identify occurrences of unjust vocabulary,\nalong with the demographic features present, and use causal discovery to build\na Structural Causal Model (SCM) relating those demographic features to\ntestimonial injustice. We analyze and discuss the resulting SCMs to show the\ninteraction of these factors and how they influence the experience of\ninjustice. Despite the potential presence of some confounding variables, we\nobserve how one contributing feature can make a person more prone to\nexperiencing another contributor of testimonial injustice. There is no single\nroot of injustice and thus intersectionality cannot be ignored. These results\ncall for considering more than singular or equalized attributes of who a person\nis when analyzing and improving their experiences of bias and injustice. This\nwork is thus a first foray at using causal discovery to understand the nuanced\nexperiences of patients in medical settings, and its insights could be used to\nguide design principles throughout healthcare, to build trust and promote\nbetter patient care.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01227v1",
    "published_date": "2024-10-02 04:10:55 UTC",
    "updated_date": "2024-10-02 04:10:55 UTC"
  },
  {
    "arxiv_id": "2410.01218v1",
    "title": "An uncertainty-aware Digital Shadow for underground multimodal CO2 storage monitoring",
    "authors": [
      "Abhinav Prakash Gahlot",
      "Rafael Orozco",
      "Ziyi Yin",
      "Felix J. Herrmann"
    ],
    "abstract": "Geological Carbon Storage GCS is arguably the only scalable net-negative CO2\nemission technology available While promising subsurface complexities and\nheterogeneity of reservoir properties demand a systematic approach to quantify\nuncertainty when optimizing production and mitigating storage risks which\ninclude assurances of Containment and Conformance of injected supercritical CO2\nAs a first step towards the design and implementation of a Digital Twin for\nmonitoring underground storage operations a machine learning based\ndata-assimilation framework is introduced and validated on carefully designed\nrealistic numerical simulations As our implementation is based on Bayesian\ninference but does not yet support control and decision-making we coin our\napproach an uncertainty-aware Digital Shadow To characterize the posterior\ndistribution for the state of CO2 plumes conditioned on multi-modal time-lapse\ndata the envisioned Shadow combines techniques from Simulation-Based Inference\nSBI and Ensemble Bayesian Filtering to establish probabilistic baselines and\nassimilate multi-modal data for GCS problems that are challenged by large\ndegrees of freedom nonlinear multi-physics non-Gaussianity and computationally\nexpensive to evaluate fluid flow and seismic simulations To enable SBI for\ndynamic systems a recursive scheme is proposed where the Digital Shadows neural\nnetworks are trained on simulated ensembles for their state and observed data\nwell and/or seismic Once training is completed the systems state is inferred\nwhen time-lapse field data becomes available In this computational study we\nobserve that a lack of knowledge on the permeability field can be factored into\nthe Digital Shadows uncertainty quantification To our knowledge this work\nrepresents the first proof of concept of an uncertainty-aware in-principle\nscalable Digital Shadow.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01218v1",
    "published_date": "2024-10-02 03:58:45 UTC",
    "updated_date": "2024-10-02 03:58:45 UTC"
  },
  {
    "arxiv_id": "2410.01216v1",
    "title": "RS-FME-SwinT: A Novel Feature Map Enhancement Framework Integrating Customized SwinT with Residual and Spatial CNN for Monkeypox Diagnosis",
    "authors": [
      "Saddam Hussain Khan",
      "Rashid Iqbal"
    ],
    "abstract": "Monkeypox (MPox) has emerged as a significant global concern, with cases\nsteadily increasing daily. Conventional detection methods, including polymerase\nchain reaction (PCR) and manual examination, exhibit challenges of low\nsensitivity, high cost, and substantial workload. Therefore, deep learning\noffers an automated solution; however, the datasets include data scarcity,\ntexture, contrast, inter-intra class variability, and similarities with other\nskin infectious diseases. In this regard, a novel hybrid approach is proposed\nthat integrates the learning capacity of Residual Learning and Spatial\nExploitation Convolutional Neural Network (CNN) with a customized Swin\nTransformer (RS-FME-SwinT) to capture multi-scale global and local correlated\nfeatures for MPox diagnosis. The proposed RS-FME-SwinT technique employs a\ntransfer learning-based feature map enhancement (FME) technique, integrating\nthe customized SwinT for global information capture, residual blocks for\ntexture extraction, and spatial blocks for local contrast variations. Moreover,\nincorporating new inverse residual blocks within the proposed SwinT effectively\ncaptures local patterns and mitigates vanishing gradients. The proposed\nRS-FME-SwinT has strong learning potential of diverse features that\nsystematically reduce intra-class MPox variation and enable precise\ndiscrimination from other skin diseases. Finally, the proposed RS-FME-SwinT is\na holdout cross-validated on a diverse MPox dataset and achieved outperformance\non state-of-the-art CNNs and ViTs. The proposed RS-FME-SwinT demonstrates\ncommendable results of an accuracy of 97.80%, sensitivity of 96.82%, precision\nof 98.06%, and an F-score of 97.44% in MPox detection. The RS-FME-SwinT could\nbe a valuable tool for healthcare practitioners, enabling prompt and accurate\nMPox diagnosis and contributing significantly to mitigation efforts.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "37 Pages, 5 Tables, 10 Figures",
    "pdf_url": "http://arxiv.org/pdf/2410.01216v1",
    "published_date": "2024-10-02 03:57:57 UTC",
    "updated_date": "2024-10-02 03:57:57 UTC"
  },
  {
    "arxiv_id": "2410.01215v2",
    "title": "From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging",
    "authors": [
      "Yuling Shi",
      "Songsong Wang",
      "Chengcheng Wan",
      "Xiaodong Gu"
    ],
    "abstract": "While large language models have made significant strides in code generation,\nthe pass rate of the generated code is bottlenecked on subtle errors, often\nrequiring human intervention to pass tests, especially for complex problems.\nExisting LLM-based debugging systems treat generated programs as monolithic\nunits, failing to address bugs at multiple levels of granularity, from\nlow-level syntax errors to high-level algorithmic flaws. In this paper, we\nintroduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger\nby isolating, identifying, and resolving bugs at various levels of granularity.\nMGDebugger decomposes problematic code into a hierarchical tree structure of\nsubfunctions, with each level representing a particular granularity of error.\nDuring debugging, it analyzes each subfunction and iteratively resolves bugs in\na bottom-up manner. To effectively test each subfunction, we propose an\nLLM-simulated Python executor, which traces code execution and tracks important\nvariable states to pinpoint errors accurately. Extensive experiments\ndemonstrate that MGDebugger outperforms existing debugging systems, achieving\nan 18.9% improvement in accuracy over seed generations in HumanEval and a 97.6%\nrepair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes\nbugs across different categories and difficulty levels, demonstrating its\nrobustness and effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Code and data available at https://github.com/YerbaPage/MGDebugger",
    "pdf_url": "http://arxiv.org/pdf/2410.01215v2",
    "published_date": "2024-10-02 03:57:21 UTC",
    "updated_date": "2024-10-05 04:37:06 UTC"
  },
  {
    "arxiv_id": "2410.01213v1",
    "title": "A versatile machine learning workflow for high-throughput analysis of supported metal catalyst particles",
    "authors": [
      "Arda Genc",
      "Justin Marlowe",
      "Anika Jalil",
      "Libor Kovarik",
      "Phillip Christopher"
    ],
    "abstract": "Accurate and efficient characterization of nanoparticles (NPs), particularly\nregarding particle size distribution, is essential for advancing our\nunderstanding of their structure-property relationships and facilitating their\ndesign for various applications. In this study, we introduce a novel two-stage\nartificial intelligence (AI)-driven workflow for NP analysis that leverages\nprompt engineering techniques from state-of-the-art single-stage object\ndetection and large-scale vision transformer (ViT) architectures. This\nmethodology was applied to transmission electron microscopy (TEM) and scanning\nTEM (STEM) images of heterogeneous catalysts, enabling high-resolution,\nhigh-throughput analysis of particle size distributions for supported metal\ncatalysts. The model's performance in detecting and segmenting NPs was\nvalidated across diverse heterogeneous catalyst systems, including various\nmetals (Cu, Ru, Pt, and PtCo), supports (silica ($\\text{SiO}_2$),\n$\\gamma$-alumina ($\\gamma$-$\\text{Al}_2\\text{O}_3$), and carbon black), and\nparticle diameter size distributions with means and standard deviations of 2.9\n$\\pm$ 1.1 nm, 1.6 $\\pm$ 0.2 nm, 9.7 $\\pm$ 4.6 nm, and 4 $\\pm$ 1.0 nm.\nAdditionally, the proposed machine learning (ML) approach successfully detects\nand segments overlapping NPs anchored on non-uniform catalytic support\nmaterials, providing critical insights into their spatial arrangements and\ninteractions. Our AI-assisted NP analysis workflow demonstrates robust\ngeneralization across diverse datasets and can be readily applied to similar NP\nsegmentation tasks without requiring costly model retraining.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01213v1",
    "published_date": "2024-10-02 03:50:01 UTC",
    "updated_date": "2024-10-02 03:50:01 UTC"
  },
  {
    "arxiv_id": "2410.01210v1",
    "title": "Polyp-SES: Automatic Polyp Segmentation with Self-Enriched Semantic Model",
    "authors": [
      "Quang Vinh Nguyen",
      "Thanh Hoang Son Vo",
      "Sae-Ryung Kang",
      "Soo-Hyung Kim"
    ],
    "abstract": "Automatic polyp segmentation is crucial for effective diagnosis and treatment\nin colonoscopy images. Traditional methods encounter significant challenges in\naccurately delineating polyps due to limitations in feature representation and\nthe handling of variability in polyp appearance. Deep learning techniques,\nincluding CNN and Transformer-based methods, have been explored to improve\npolyp segmentation accuracy. However, existing approaches often neglect\nadditional semantics, restricting their ability to acquire adequate contexts of\npolyps in colonoscopy images. In this paper, we propose an innovative method\nnamed ``Automatic Polyp Segmentation with Self-Enriched Semantic Model'' to\naddress these limitations. First, we extract a sequence of features from an\ninput image and decode high-level features to generate an initial segmentation\nmask. Using the proposed self-enriched semantic module, we query potential\nsemantics and augment deep features with additional semantics, thereby aiding\nthe model in understanding context more effectively. Extensive experiments show\nsuperior segmentation performance of the proposed method against\nstate-of-the-art polyp segmentation baselines across five polyp benchmarks in\nboth superior learning and generalization capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.5.4; I.2.1; I.4.6; J.3"
    ],
    "primary_category": "cs.CV",
    "comment": "Asian Conference on Computer Vision 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.01210v1",
    "published_date": "2024-10-02 03:34:23 UTC",
    "updated_date": "2024-10-02 03:34:23 UTC"
  },
  {
    "arxiv_id": "2410.01201v3",
    "title": "Were RNNs All We Needed?",
    "authors": [
      "Leo Feng",
      "Frederick Tung",
      "Mohamed Osama Ahmed",
      "Yoshua Bengio",
      "Hossein Hajimirsadeghi"
    ],
    "abstract": "The introduction of Transformers in 2017 reshaped the landscape of deep\nlearning. Originally proposed for sequence modelling, Transformers have since\nachieved widespread success across various domains. However, the scalability\nlimitations of Transformers - particularly with respect to sequence length -\nhave sparked renewed interest in novel recurrent models that are parallelizable\nduring training, offer comparable performance, and scale more effectively. In\nthis work, we revisit sequence modelling from a historical perspective,\nfocusing on Recurrent Neural Networks (RNNs), which dominated the field for two\ndecades before the rise of Transformers. Specifically, we examine LSTMs (1997)\nand GRUs (2014). We demonstrate that by simplifying these models, we can derive\nminimal versions (minLSTMs and minGRUs) that (1) use fewer parameters than\ntheir traditional counterparts, (2) are fully parallelizable during training,\nand (3) achieve surprisingly competitive performance on a range of tasks,\nrivalling recent models including Transformers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01201v3",
    "published_date": "2024-10-02 03:06:49 UTC",
    "updated_date": "2024-11-28 07:10:33 UTC"
  },
  {
    "arxiv_id": "2410.01176v1",
    "title": "Generative Diffusion-based Contract Design for Efficient AI Twins Migration in Vehicular Embodied AI Networks",
    "authors": [
      "Yue Zhong",
      "Jiawen Kang",
      "Jinbo Wen",
      "Dongdong Ye",
      "Jiangtian Nie",
      "Dusit Niyato",
      "Xiaozheng Gao",
      "Shengli Xie"
    ],
    "abstract": "Embodied AI is a rapidly advancing field that bridges the gap between\ncyberspace and physical space, enabling a wide range of applications. This\nevolution has led to the development of the Vehicular Embodied AI NETwork\n(VEANET), where advanced AI capabilities are integrated into vehicular systems\nto enhance autonomous operations and decision-making. Embodied agents, such as\nAutonomous Vehicles (AVs), are autonomous entities that can perceive their\nenvironment and take actions to achieve specific goals, actively interacting\nwith the physical world. Embodied twins are digital models of these embodied\nagents, with various embodied AI twins for intelligent applications in\ncyberspace. In VEANET, embodied AI twins act as in-vehicle AI assistants to\nperform diverse tasks supporting autonomous driving using generative AI models.\nDue to limited computational resources of AVs, these AVs often offload\ncomputationally intensive tasks, such as constructing and updating embodied AI\ntwins, to nearby RSUs. However, since the rapid mobility of AVs and the limited\nprovision coverage of a single RSU, embodied AI twins require dynamic\nmigrations from current RSU to other RSUs in real-time, resulting in the\nchallenge of selecting suitable RSUs for efficient embodied AI twins\nmigrations. Given information asymmetry, AVs cannot know the detailed\ninformation of RSUs. To this end, in this paper, we construct a\nmulti-dimensional contract theoretical model between AVs and alternative RSUs.\nConsidering that AVs may exhibit irrational behavior, we utilize prospect\ntheory instead of expected utility theory to model the actual utilities of AVs.\nFinally, we employ a generative diffusion model-based algorithm to identify the\noptimal contract designs. Compared with traditional deep reinforcement learning\nalgorithms, numerical results demonstrate the effectiveness of the proposed\nscheme.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01176v1",
    "published_date": "2024-10-02 02:20:42 UTC",
    "updated_date": "2024-10-02 02:20:42 UTC"
  },
  {
    "arxiv_id": "2410.01174v1",
    "title": "Towards Inference-time Category-wise Safety Steering for Large Language Models",
    "authors": [
      "Amrita Bhattacharjee",
      "Shaona Ghosh",
      "Traian Rebedea",
      "Christopher Parisien"
    ],
    "abstract": "While large language models (LLMs) have seen unprecedented advancements in\ncapabilities and applications across a variety of use-cases, safety alignment\nof these models is still an area of active research. The fragile nature of\nLLMs, even models that have undergone extensive alignment and safety training\nregimes, warrants additional safety steering steps via training-free,\ninference-time methods. While recent work in the area of mechanistic\ninterpretability has investigated how activations in latent representation\nspaces may encode concepts, and thereafter performed representation engineering\nto induce such concepts in LLM outputs, the applicability of such for safety is\nrelatively under-explored. Unlike recent inference-time safety steering works,\nin this paper we explore safety steering of LLM outputs using: (i)\ncategory-specific steering vectors, thereby enabling fine-grained control over\nthe steering, and (ii) sophisticated methods for extracting informative\nsteering vectors for more effective safety steering while retaining quality of\nthe generated text. We demonstrate our exploration on multiple LLMs and\ndatasets, and showcase the effectiveness of the proposed steering method, along\nwith a discussion on the implications and best practices.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01174v1",
    "published_date": "2024-10-02 02:02:06 UTC",
    "updated_date": "2024-10-02 02:02:06 UTC"
  },
  {
    "arxiv_id": "2410.03752v1",
    "title": "Efficient Streaming LLM for Speech Recognition",
    "authors": [
      "Junteng Jia",
      "Gil Keren",
      "Wei Zhou",
      "Egor Lakomkin",
      "Xiaohui Zhang",
      "Chunyang Wu",
      "Frank Seide",
      "Jay Mahadeokar",
      "Ozlem Kalinli"
    ],
    "abstract": "Recent works have shown that prompting large language models with audio\nencodings can unlock speech recognition capabilities. However, existing\ntechniques do not scale efficiently, especially while handling long form\nstreaming audio inputs -- not only do they extrapolate poorly beyond the audio\nlength seen during training, but they are also computationally inefficient due\nto the quadratic cost of attention.\n  In this work, we introduce SpeechLLM-XL, a linear scaling decoder-only model\nfor streaming speech recognition. We process audios in configurable chunks\nusing limited attention window for reduced computation, and the text tokens for\neach audio chunk are generated auto-regressively until an EOS is predicted.\nDuring training, the transcript is segmented into chunks, using a CTC forced\nalignment estimated from encoder output. SpeechLLM-XL with 1.28 seconds chunk\nsize achieves 2.7%/6.7% WER on LibriSpeech test clean/other, and it shows no\nquality degradation on long form utterances 10x longer than the training\nutterances.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03752v1",
    "published_date": "2024-10-02 01:54:35 UTC",
    "updated_date": "2024-10-02 01:54:35 UTC"
  },
  {
    "arxiv_id": "2410.01149v1",
    "title": "Recovering Manifold Structure Using Ollivier-Ricci Curvature",
    "authors": [
      "Tristan Luca Saidi",
      "Abigail Hickok",
      "Andrew J. Blumberg"
    ],
    "abstract": "We introduce ORC-ManL, a new algorithm to prune spurious edges from nearest\nneighbor graphs using a criterion based on Ollivier-Ricci curvature and\nestimated metric distortion. Our motivation comes from manifold learning: we\nshow that when the data generating the nearest-neighbor graph consists of noisy\nsamples from a low-dimensional manifold, edges that shortcut through the\nambient space have more negative Ollivier-Ricci curvature than edges that lie\nalong the data manifold. We demonstrate that our method outperforms alternative\npruning methods and that it significantly improves performance on many\ndownstream geometric data analysis tasks that use nearest neighbor graphs as\ninput. Specifically, we evaluate on manifold learning, persistent homology,\ndimension estimation, and others. We also show that ORC-ManL can be used to\nimprove clustering and manifold learning of single-cell RNA sequencing data.\nFinally, we provide empirical convergence experiments that support our\ntheoretical findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01149v1",
    "published_date": "2024-10-02 01:00:30 UTC",
    "updated_date": "2024-10-02 01:00:30 UTC"
  },
  {
    "arxiv_id": "2410.01145v1",
    "title": "ProxiMix: Enhancing Fairness with Proximity Samples in Subgroups",
    "authors": [
      "Jingyu Hu",
      "Jun Hong",
      "Mengnan Du",
      "Weiru Liu"
    ],
    "abstract": "Many bias mitigation methods have been developed for addressing fairness\nissues in machine learning. We found that using linear mixup alone, a data\naugmentation technique, for bias mitigation, can still retain biases present in\ndataset labels. Research presented in this paper aims to address this issue by\nproposing a novel pre-processing strategy in which both an existing mixup\nmethod and our new bias mitigation algorithm can be utilized to improve the\ngeneration of labels of augmented samples, which are proximity aware.\nSpecifically, we proposed ProxiMix which keeps both pairwise and proximity\nrelationships for fairer data augmentation. We conducted thorough experiments\nwith three datasets, three ML models, and different hyperparameters settings.\nOur experimental results showed the effectiveness of ProxiMix from both\nfairness of predictions and fairness of recourse perspectives.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01145v1",
    "published_date": "2024-10-02 00:47:03 UTC",
    "updated_date": "2024-10-02 00:47:03 UTC"
  },
  {
    "arxiv_id": "2410.01141v2",
    "title": "Evaluating Deduplication Techniques for Economic Research Paper Titles with a Focus on Semantic Similarity using NLP and LLMs",
    "authors": [
      "Doohee You",
      "Samuel Fraiberger"
    ],
    "abstract": "This study investigates efficient deduplication techniques for a large NLP\ndataset of economic research paper titles. We explore various pairing methods\nalongside established distance measures (Levenshtein distance, cosine\nsimilarity) and a sBERT model for semantic evaluation. Our findings suggest a\npotentially low prevalence of duplicates based on the observed semantic\nsimilarity across different methods. Further exploration with a human-annotated\nground truth set is completed for a more conclusive assessment. The result\nsupports findings from the NLP, LLM based distance metrics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.01141v2",
    "published_date": "2024-10-02 00:43:10 UTC",
    "updated_date": "2024-12-11 19:37:05 UTC"
  },
  {
    "arxiv_id": "2410.13866v2",
    "title": "Associative memory and dead neurons",
    "authors": [
      "Vladimir Fanaskov",
      "Ivan Oseledets"
    ],
    "abstract": "In \"Large Associative Memory Problem in Neurobiology and Machine Learning,\"\nDmitry Krotov and John Hopfield introduced a general technique for the\nsystematic construction of neural ordinary differential equations with\nnon-increasing energy or Lyapunov function. We study this energy function and\nidentify that it is vulnerable to the problem of dead neurons. Each point in\nthe state space where the neuron dies is contained in a non-compact region with\nconstant energy. In these flat regions, energy function alone does not\ncompletely determine all degrees of freedom and, as a consequence, can not be\nused to analyze stability or find steady states or basins of attraction. We\nperform a direct analysis of the dynamical system and show how to resolve\nproblems caused by flat directions corresponding to dead neurons: (i) all\ninformation about the state vector at a fixed point can be extracted from the\nenergy and Hessian matrix (of Lagrange function), (ii) it is enough to analyze\nstability in the range of Hessian matrix, (iii) if steady state touching flat\nregion is stable the whole flat region is the basin of attraction. The analysis\nof the Hessian matrix can be complicated for realistic architectures, so we\nshow that for a slightly altered dynamical system (with the same structure of\nsteady states), one can derive a diverse family of Lyapunov functions that do\nnot have flat regions corresponding to dead neurons. In addition, these energy\nfunctions allow one to use Lagrange functions with Hessian matrices that are\nnot necessarily positive definite and even consider architectures with\nnon-symmetric feedforward and feedback connections.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Reviewed in https://openreview.net/forum?id=mkNVPGpEPm, accepted to\n  ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13866v2",
    "published_date": "2024-10-02 00:25:30 UTC",
    "updated_date": "2025-02-26 17:04:33 UTC"
  }
]