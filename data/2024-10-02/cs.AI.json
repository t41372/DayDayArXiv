{
  "date": "2024-10-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-02 的 arXiv 中文 TLDR 快报！今天的论文涵盖 AI 模型优化、迁移学习、LLM 在医疗和软件开发中的应用、图神经网络理论，以及强化学习等领域，其中 LLM 安全和高效训练方法（如 GitHub Copilot 的影响和心脏诊断框架）最为引人注目，同时有 Yoshua Bengio 和 John Hopfield 等知名学者的作品值得关注。\n\n今天共有 158 篇论文，我将优先讨论那些重要、具有话题性和影响力高的文章，包括 LLM 相关创新、医疗应用和理论分析。其他论文将快速掠过，只提核心点。以下按主题归类简要概述：\n\n### LLM 优化与安全\n- **翻转攻击：越狱 LLM 的方法（FlipAttack: Jailbreak LLMs via Flipping）**  \n  这篇论文探讨了通过文本翻转（如添加噪声）来攻击黑盒 LLM 的方法。主要贡献是提出 FlipAttack 框架，能在单次查询下成功越狱模型（如 GPT-4o），攻击成功率高达 98%。发现显示，这种方法隐蔽且高效，揭示了 LLM 安全漏洞，值得关注 AI 防御研究。\n\n- **多 LLM 代理调试器：通过细化与生成指导（RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance）**  \n  作者提出 RGD 框架，使用多个 LLM 代理（如 Guide Agent 和 Debug Agent）来迭代调试代码生成。主要发现是 RGD 在 HumanEval 和 MBPP 数据集上提升了代码准确率 9.8% 和 16.2%，比直接提示方法更有效，强调了 LLM 在自动化调试中的潜力。\n\n- **多标准评估：使用 AHP 的 LLM 响应生成（AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses）**  \n  这篇工作使用分析层次过程 (AHP) 结合 LLM 来评估开放式问题响应。主要贡献是提出一个多标准评估框架，提升了响应质量，在实验中与人类判断更一致，适用于教育和决策场景。\n\n### 医疗与生物应用\n- **Zodiac：LLM 在心脏诊断的多代理框架（Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics）**  \n  作者（包括 Yong Chen 和 Zhaohan Xi）开发了 Zodiac 框架，使用多代理 LLM 处理心脏数据诊断。主要发现是它在八个指标上超越 GPT-4o 和 Llama-3.1，提供专业级诊断，并已集成到 ECG 设备中，展示了 LLM 在医疗的实际价值。\n\n- **多模态方法：用于糖尿病足溃疡图像转录（UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription）**  \n  这篇论文提出 UlcerGPT，使用 LLM 和视觉模型分析溃疡图像。主要贡献是实现高精度检测和分类，实验在公开数据集上表现突出，强调了 LLM 在 telemedicine 中的潜力。\n\n- **量子机器学习：用于肺癌分类（Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification）**  \n  作者（包括 Sabre Kais）整合多组学数据和量子机器学习进行肺癌亚型分类。主要发现是提出新特征选择方法，提高了诊断准确性，尽管页面较长，但其在生物医学的创新性值得一读。\n\n### 图神经网络与理论进展\n- **图操作扩展：用于多模态特征融合（Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion）**  \n  作者（包括 Piotr Koniusz）提出可学习图操作扩展框架，用于多模态特征融合。主要贡献是通过图关系更新捕获全局和局部特征，提升了视频异常检测等任务的性能。\n\n- **图神经网络表现力：重新审视机器学习社区（Rethinking GNN Expressive Power Research in the Machine Learning Community: Limitations, Issues, and Corrections）**  \n  作者（包括 Hsin-Hao Su）分析了图神经网络 (GNN) 的表现力问题，指出现有方法（如 Weisfeiler-Lehman 测试）的局限性。主要发现是提出基于分布式计算模型的理论框架，并验证了虚拟节点的影响。\n\n- **联想记忆与死神经元（Associative memory and dead neurons）**  \n  作者（包括 Ivan Oseledets）研究了 Hopfield 网络的能量函数，解决了死神经元问题。主要贡献是证明了能量函数的鲁棒性，并为神经动力学提供了新分析方法，这篇与 John Hopfield 相关的工作有理论深度。\n\n### 其他快速掠过\n其他论文涉及强化学习、语音处理和数据增强等，但相对次要。这里快速提几点：\n- **语音生成：高效流式 LLM（Efficient Streaming LLM for Speech Recognition）** 提出流式处理方法，提升了语音识别的实时性。\n- **药物发现：神经符号方法（MARS: A neurosymbolic approach for interpretable drug discovery）** 使用神经符号框架提高药物机制解释性。\n- **数学推理：LLM 训练数据生成（OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data）** 构建大规模开源数据集，提升数学任务性能。\n- 还有一些如第 17 篇的图像生成指标和第 29 篇的 Shapley 值估计，贡献在于技术优化，但影响力较小。\n\n总之，今天的论文突出了 LLM 在实际应用（如医疗和软件）的潜力，同时强调了安全和理论挑战。未来几天，继续关注 AI 模型的鲁棒性和泛化能力！如果有特定主题感兴趣，欢迎反馈。",
  "papers": [
    {
      "arxiv_id": "2410.02094v3",
      "title": "Tracking objects that change in appearance with phase synchrony",
      "title_zh": "利用相位同步追踪外观发生变化的物体",
      "authors": [
        "Sabine Muzellec",
        "Drew Linsley",
        "Alekh K. Ashok",
        "Ennio Mingolla",
        "Girik Malik",
        "Rufin VanRullen",
        "Thomas Serre"
      ],
      "abstract": "Objects we encounter often change appearance as we interact with them.\nChanges in illumination (shadows), object pose, or the movement of non-rigid\nobjects can drastically alter available image features. How do biological\nvisual systems track objects as they change? One plausible mechanism involves\nattentional mechanisms for reasoning about the locations of objects\nindependently of their appearances -- a capability that prominent neuroscience\ntheories have associated with computing through neural synchrony. Here, we\ndescribe a novel deep learning circuit that can learn to precisely control\nattention to features separately from their location in the world through\nneural synchrony: the complex-valued recurrent neural network (CV-RNN). Next,\nwe compare object tracking in humans, the CV-RNN, and other deep neural\nnetworks (DNNs), using FeatureTracker: a large-scale challenge that asks\nobservers to track objects as their locations and appearances change in\nprecisely controlled ways. While humans effortlessly solved FeatureTracker,\nstate-of-the-art DNNs did not. In contrast, our CV-RNN behaved similarly to\nhumans on the challenge, providing a computational proof-of-concept for the\nrole of phase synchronization as a neural substrate for tracking\nappearance-morphing objects as they move about.",
      "tldr_zh": "本论文探讨了生物视觉系统如何追踪外观变化的物体（如光照、姿态或非刚性运动引起的改变），并提出了一种新颖的深度学习电路——复杂值循环神经网络(CV-RNN)，通过相位同步(phase synchrony)来精确控制注意力，分离物体特征和位置。研究者使用 FeatureTracker 挑战进行比较，发现人类能轻松应对，而传统深度神经网络(DNNs)表现不佳，但 CV-RNN 与人类类似，提供神经同步作为追踪外观动态物体的潜在神经机制的计算证据。该方法为理解和模拟生物视觉追踪能力奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02094v3",
      "published_date": "2024-10-02 23:30:05 UTC",
      "updated_date": "2025-03-02 14:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:53:36.097646"
    },
    {
      "arxiv_id": "2410.02091v1",
      "title": "The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot",
      "title_zh": "生成式人工智能对协作开源软件开发的影响：基于 GitHub Copilot 的证据",
      "authors": [
        "Fangchen Song",
        "Ashish Agarwal",
        "Wen Wen"
      ],
      "abstract": "Generative artificial intelligence (AI) has opened the possibility of\nautomated content production, including coding in software development, which\ncan significantly influence the participation and performance of software\ndevelopers. To explore this impact, we investigate the role of GitHub Copilot,\na generative AI pair programmer, on software development in open-source\ncommunity, where multiple developers voluntarily collaborate on software\nprojects. Using GitHub's dataset for open-source repositories and a generalized\nsynthetic control method, we find that Copilot significantly enhances\nproject-level productivity by 6.5%. Delving deeper, we dissect the key\nmechanisms driving this improvement. Our findings reveal a 5.5% increase in\nindividual productivity and a 5.4% increase in participation. However, this is\naccompanied with a 41.6% increase in integration time, potentially due to\nhigher coordination costs. Interestingly, we also observe the differential\neffects among developers. We discover that core developers achieve greater\nproject-level productivity gains from using Copilot, benefiting more in terms\nof individual productivity and participation compared to peripheral developers,\nplausibly due to their deeper familiarity with software projects. We also find\nthat the increase in project-level productivity is accompanied with no change\nin code quality. We conclude that AI pair programmers bring benefits to\ndevelopers to automate and augment their code, but human developers' knowledge\nof software projects can enhance the benefits. In summary, our research\nunderscores the role of AI pair programmers in impacting project-level\nproductivity within the open-source community and suggests potential\nimplications for the structure of open-source software projects.",
      "tldr_zh": "本研究考察了生成式 AI 工具 GitHub Copilot 对开源软件开发的影响，使用 GitHub 数据和广义合成控制方法（generalized synthetic control method）进行分析。结果显示，Copilot 使项目级生产力提升 6.5%，个体生产力增加 5.5%，参与度提升 5.4%，但整合时间延长 41.6%，可能由于协调成本增加。核心开发者比外围开发者获得更大收益，而代码质量未见变化；总体而言，AI 配对编程工具能自动化和增强代码开发，但人类开发者的项目知识可进一步放大其益处。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02091v1",
      "published_date": "2024-10-02 23:26:10 UTC",
      "updated_date": "2024-10-02 23:26:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:53:48.035572"
    },
    {
      "arxiv_id": "2410.02089v2",
      "title": "RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Gehring",
        "Kunhao Zheng",
        "Jade Copet",
        "Vegard Mella",
        "Quentin Carbonneaux",
        "Taco Cohen",
        "Gabriel Synnaeve"
      ],
      "abstract": "Large language models (LLMs) deployed as agents solve user-specified tasks\nover multiple steps while keeping the required manual engagement to a minimum.\nCrucially, such LLMs need to ground their generations in any feedback obtained\nto reliably achieve the desired outcomes. We propose an end-to-end\nreinforcement learning method for teaching models to leverage execution\nfeedback in the realm of code synthesis, where state-of-the-art LLMs struggle\nto improve code iteratively compared to independent sampling. We benchmark on\ncompetitive programming tasks, where we achieve new state-of-the art results\nwith both small (8B parameters) and large (70B) models while reducing the\namount of samples required by an order of magnitude. Our analysis of\ninference-time behavior demonstrates that our method produces LLMs that\neffectively leverage automatic feedback over multiple steps.",
      "tldr_zh": "该研究提出RLEF方法，使用强化学习(Reinforcement Learning)来训练大语言模型(LLMs)，使它们能够有效利用执行反馈在代码合成任务中进行迭代改进，从而减少手动干预。RLEF是一种端到端的强化学习框架，针对LLMs在多步骤任务中的不足，特别是在竞争性编程场景下进行基准测试。实验结果显示，该方法在小模型(8B参数)和大模型(70B参数)上实现了新的最先进(State-of-the-art)性能，同时将所需样本量减少一个数量级，并证明了模型在推理时能高效处理自动反馈。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Add repair model ablation, update related work",
      "pdf_url": "http://arxiv.org/pdf/2410.02089v2",
      "published_date": "2024-10-02 23:25:17 UTC",
      "updated_date": "2025-02-18 11:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:53:59.128788"
    },
    {
      "arxiv_id": "2410.02085v1",
      "title": "Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mandeep Kaur Saggi",
        "Amandeep Singh Bhatia",
        "Mensah Isaiah",
        "Humaira Gowher",
        "Sabre Kais"
      ],
      "abstract": "Quantum Machine Learning (QML) is a red-hot field that brings novel\ndiscoveries and exciting opportunities to resolve, speed up, or refine the\nanalysis of a wide range of computational problems. In the realm of biomedical\nresearch and personalized medicine, the significance of multi-omics integration\nlies in its ability to provide a thorough and holistic comprehension of complex\nbiological systems. This technology links fundamental research to clinical\npractice. The insights gained from integrated omics data can be translated into\nclinical tools for diagnosis, prognosis, and treatment planning. The fusion of\nquantum computing and machine learning holds promise for unraveling complex\npatterns within multi-omics datasets, providing unprecedented insights into the\nmolecular landscape of lung cancer. Due to the heterogeneity, complexity, and\nhigh dimensionality of multi-omic cancer data, characterized by the vast number\nof features (such as gene expression, micro-RNA, and DNA methylation) relative\nto the limited number of lung cancer patient samples, our prime motivation for\nthis paper is the integration of multi-omic data, unique feature selection, and\ndiagnostic classification of lung subtypes: lung squamous cell carcinoma\n(LUSC-I) and lung adenocarcinoma (LUAD-II) using quantum machine learning. We\ndeveloped a method for finding the best differentiating features between LUAD\nand LUSC datasets, which has the potential for biomarker discovery.",
      "tldr_zh": "本文探讨了Quantum Machine Learning (QML)与多组学整合在肺癌亚型分类中的应用，旨在处理多组学数据（如基因表达、micro-RNA和DNA甲基化）的异质性、高维度和样本有限问题。研究开发了一种独特特征选择方法，用于识别lung squamous cell carcinoma (LUSC)和lung adenocarcinoma (LUAD)之间的最佳差异特征，并通过QML实现精确诊断分类。该方法具有发现生物标志物的潜力，为生物医学研究和个性化治疗提供新的洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02085v1",
      "published_date": "2024-10-02 23:16:31 UTC",
      "updated_date": "2024-10-02 23:16:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:54:12.096070"
    },
    {
      "arxiv_id": "2410.03772v1",
      "title": "Precision Knowledge Editing: Enhancing Safety in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xuying Li",
        "Zhuo Li",
        "Yuji Kosuga",
        "Yasuhiro Yoshida",
        "Victor Bian"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but\nthey also pose risks related to the generation of toxic or harmful content.\nThis work introduces Precision Knowledge Editing (PKE), an advanced technique\nthat builds upon existing knowledge editing methods to more effectively\nidentify and modify toxic parameter regions within LLMs. By leveraging neuron\nweight tracking and activation pathway tracing, PKE achieves finer granularity\nin toxic content management compared to previous methods like Detoxifying\nInstance Neuron Modification (DINM). Our experiments demonstrate that PKE\nsignificantly reduces the attack success rate (ASR) across various models,\nincluding Llama2-7b and Llama-3-8b-instruct, while maintaining overall model\nperformance. Additionally, we also compared the performance of some\nclosed-source models (gpt-4-0613 and Claude 3 Sonnet) in our experiments, and\nfound that models adjusted using our method far outperformed the closed-source\nmodels in terms of safety. This research contributes to the ongoing efforts to\nmake LLMs safer and more reliable for real-world applications.",
      "tldr_zh": "这篇论文介绍了 Precision Knowledge Editing (PKE)，一种高级技术，用于提升 Large Language Models (LLMs) 的安全性，通过更有效地识别和修改模型中的有毒参数区域来减少有害内容生成。PKE 利用 neuron weight tracking 和 activation pathway tracing，实现比现有方法如 Detoxifying Instance Neuron Modification (DINM) 更细粒度的管理。实验结果显示，PKE 在模型如 Llama2-7b 和 Llama-3-8b-instruct 上显著降低了 attack success rate (ASR)，同时保持了整体性能，并超过了闭源模型如 gpt-4-0613 和 Claude 3 Sonnet 在安全指标上。该研究为 LLMs 在实际应用中实现更可靠的部署提供了关键贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03772v1",
      "published_date": "2024-10-02 23:15:53 UTC",
      "updated_date": "2024-10-02 23:15:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:54:25.548156"
    },
    {
      "arxiv_id": "2410.02077v1",
      "title": "Kolmogorov-Arnold Network Autoencoders",
      "title_zh": "Kolmogorov-Arnold 网络自动编码器",
      "authors": [
        "Mohammadamin Moradi",
        "Shirin Panahi",
        "Erik Bollt",
        "Ying-Cheng Lai"
      ],
      "abstract": "Deep learning models have revolutionized various domains, with Multi-Layer\nPerceptrons (MLPs) being a cornerstone for tasks like data regression and image\nclassification. However, a recent study has introduced Kolmogorov-Arnold\nNetworks (KANs) as promising alternatives to MLPs, leveraging activation\nfunctions placed on edges rather than nodes. This structural shift aligns KANs\nclosely with the Kolmogorov-Arnold representation theorem, potentially\nenhancing both model accuracy and interpretability. In this study, we explore\nthe efficacy of KANs in the context of data representation via autoencoders,\ncomparing their performance with traditional Convolutional Neural Networks\n(CNNs) on the MNIST, SVHN, and CIFAR-10 datasets. Our results demonstrate that\nKAN-based autoencoders achieve competitive performance in terms of\nreconstruction accuracy, thereby suggesting their viability as effective tools\nin data analysis tasks.",
      "tldr_zh": "本研究探讨了Kolmogorov-Arnold Networks (KANs)作为Multi-Layer Perceptrons (MLPs)的替代方案，KANs通过将激活函数置于边上而非节点上，符合Kolmogorov-Arnold表示定理，从而提升模型的准确性和可解释性。论文将KANs应用于自编码器(autoencoders)，并与传统的Convolutional Neural Networks (CNNs)在MNIST、SVHN和CIFAR-10数据集上进行性能比较。结果显示，基于KANs的自编码器在重建准确性方面表现出色，与CNNs相当，证明了其在数据分析任务中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2410.02077v1",
      "published_date": "2024-10-02 22:56:00 UTC",
      "updated_date": "2024-10-02 22:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:54:35.953439"
    },
    {
      "arxiv_id": "2410.02056v2",
      "title": "Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data",
      "title_zh": "Synthio：使用合成数据增强小规模音频分类数据集",
      "authors": [
        "Sreyan Ghosh",
        "Sonal Kumar",
        "Zhifeng Kong",
        "Rafael Valle",
        "Bryan Catanzaro",
        "Dinesh Manocha"
      ],
      "abstract": "We present Synthio, a novel approach for augmenting small-scale audio\nclassification datasets with synthetic data. Our goal is to improve audio\nclassification accuracy with limited labeled data. Traditional data\naugmentation techniques, which apply artificial transformations (e.g., adding\nrandom noise or masking segments), struggle to create data that captures the\ntrue diversity present in real-world audios. To address this shortcoming, we\npropose to augment the dataset with synthetic audio generated from\ntext-to-audio (T2A) diffusion models. However, synthesizing effective\naugmentations is challenging because not only should the generated data be\nacoustically consistent with the underlying small-scale dataset, but they\nshould also have sufficient compositional diversity. To overcome the first\nchallenge, we align the generations of the T2A model with the small-scale\ndataset using preference optimization. This ensures that the acoustic\ncharacteristics of the generated data remain consistent with the small-scale\ndataset. To address the second challenge, we propose a novel caption generation\ntechnique that leverages the reasoning capabilities of Large Language Models to\n(1) generate diverse and meaningful audio captions and (2) iteratively refine\ntheir quality. The generated captions are then used to prompt the aligned T2A\nmodel. We extensively evaluate Synthio on ten datasets and four simulated\nlimited-data settings. Results indicate our method consistently outperforms all\nbaselines by 0.1%-39% using a T2A model trained only on weakly-captioned\nAudioSet.",
      "tldr_zh": "该研究提出Synthio，一种创新方法，通过文本到音频(T2A)扩散模型生成合成数据来增强小规模音频分类数据集，旨在提升分类准确性并解决传统增强技术（如添加噪声）无法捕捉真实音频多样性的问题。为确保合成数据与原数据集声学一致，研究采用偏好优化（preference optimization）对T2A模型进行对齐；同时，利用Large Language Models的推理能力生成多样音频标题并迭代优化，以提升组成多样性。实验在十个数据集和四种有限数据设置中显示，Synthio比基线方法提高了0.1%至39%的性能，即使使用仅在弱标记AudioSet上训练的T2A模型。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICLR 2025. Code and Checkpoints available here:\n  https://github.com/Sreyan88/Synthio",
      "pdf_url": "http://arxiv.org/pdf/2410.02056v2",
      "published_date": "2024-10-02 22:05:36 UTC",
      "updated_date": "2025-03-12 00:25:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:54:47.599216"
    },
    {
      "arxiv_id": "2410.02042v1",
      "title": "EAB-FL: Exacerbating Algorithmic Bias through Model Poisoning Attacks in Federated Learning",
      "title_zh": "EAB-FL：通过模型投毒攻击在联邦学习中加剧算法偏差",
      "authors": [
        "Syed Irfan Ali Meerza",
        "Jian Liu"
      ],
      "abstract": "Federated Learning (FL) is a technique that allows multiple parties to train\na shared model collaboratively without disclosing their private data. It has\nbecome increasingly popular due to its distinct privacy advantages. However, FL\nmodels can suffer from biases against certain demographic groups (e.g., racial\nand gender groups) due to the heterogeneity of data and party selection.\nResearchers have proposed various strategies for characterizing the group\nfairness of FL algorithms to address this issue. However, the effectiveness of\nthese strategies in the face of deliberate adversarial attacks has not been\nfully explored. Although existing studies have revealed various threats (e.g.,\nmodel poisoning attacks) against FL systems caused by malicious participants,\ntheir primary aim is to decrease model accuracy, while the potential of\nleveraging poisonous model updates to exacerbate model unfairness remains\nunexplored. In this paper, we propose a new type of model poisoning attack,\nEAB-FL, with a focus on exacerbating group unfairness while maintaining a good\nlevel of model utility. Extensive experiments on three datasets demonstrate the\neffectiveness and efficiency of our attack, even with state-of-the-art fairness\noptimization algorithms and secure aggregation rules employed.",
      "tldr_zh": "该论文探讨了Federated Learning (FL)中算法偏见问题，指出FL模型可能因数据异质性和参与方选择而对某些群体（如种族或性别）产生不公平。研究提出了一种新攻击方法EAB-FL，通过模型投毒攻击来加剧群体不公平性，同时保持模型的整体效用水平。实验在三个数据集上验证了EAB-FL的有效性和效率，即使在采用最先进的公平性优化算法和安全聚合规则的情况下。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02042v1",
      "published_date": "2024-10-02 21:22:48 UTC",
      "updated_date": "2024-10-02 21:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:54:59.113792"
    },
    {
      "arxiv_id": "2410.02033v1",
      "title": "Model Comparisons: XNet Outperforms KAN",
      "title_zh": "模型",
      "authors": [
        "Xin Li",
        "Zhihong Jeff Xia",
        "Xiaotao Zheng"
      ],
      "abstract": "In the fields of computational mathematics and artificial intelligence, the\nneed for precise data modeling is crucial, especially for predictive machine\nlearning tasks. This paper explores further XNet, a novel algorithm that\nemploys the complex-valued Cauchy integral formula, offering a superior network\narchitecture that surpasses traditional Multi-Layer Perceptrons (MLPs) and\nKolmogorov-Arnold Networks (KANs). XNet significant improves speed and accuracy\nacross various tasks in both low and high-dimensional spaces, redefining the\nscope of data-driven model development and providing substantial improvements\nover established time series models like LSTMs.",
      "tldr_zh": "这篇论文比较了XNet算法与传统模型，XNet基于complex-valued Cauchy integral formula构建了一个优于Multi-Layer Perceptrons (MLPs)和Kolmogorov-Arnold Networks (KANs)的网络架构。在计算数学和人工智能领域，XNet显著提升了速度和准确性，尤其在低和高维空间的任务中。实验结果显示，XNet在时间序列建模方面也超过了像LSTMs这样的模型，重新定义了数据驱动模型的发展方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02033v1",
      "published_date": "2024-10-02 20:59:47 UTC",
      "updated_date": "2024-10-02 20:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:55:11.236169"
    },
    {
      "arxiv_id": "2410.02027v2",
      "title": "Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle Buettner",
        "Adriana Kovashka"
      ],
      "abstract": "There is a scarcity of multilingual vision-language models that properly\naccount for the perceptual differences that are reflected in image captions\nacross languages and cultures. In this work, through a multimodal, multilingual\nretrieval case study, we quantify the existing lack of model flexibility. We\nempirically show performance gaps between training on captions that come from\nnative German perception and captions that have been either machine-translated\nor human-translated from English into German. To address these gaps, we further\npropose and evaluate caption augmentation strategies. While we achieve mean\nrecall improvements (+1.3), gaps still remain, indicating an open area of\nfuture work for the community.",
      "tldr_zh": "本研究量化了在多模态、多语言检索训练中，翻译标题与原生感知之间的性能差距，焦点在于视觉语言模型未能充分考虑不同语言和文化的图像描述差异。通过案例研究，实验显示，使用从英语翻译到德语的标题（包括机器翻译和人工翻译）相比原生德语标题，模型性能存在显著下降。为解决此问题，研究者提出并评估了标题增强策略，实现了均召回率提升1.3%，但差距依然存在，指出这仍是未来研究的开放领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2024 Main - Short",
      "pdf_url": "http://arxiv.org/pdf/2410.02027v2",
      "published_date": "2024-10-02 20:47:53 UTC",
      "updated_date": "2024-10-08 15:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:55:23.046756"
    },
    {
      "arxiv_id": "2410.02026v1",
      "title": "Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Zhou",
        "Peng Zhang",
        "Mengya Song",
        "Alice Zheng",
        "Yiwen Lu",
        "Zhiheng Liu",
        "Yong Chen",
        "Zhaohan Xi"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable progress in\nhealthcare. However, a significant gap remains regarding LLMs' professionalism\nin domain-specific clinical practices, limiting their application in real-world\ndiagnostics. In this work, we introduce ZODIAC, an LLM-powered framework with\ncardiologist-level professionalism designed to engage LLMs in cardiological\ndiagnostics. ZODIAC assists cardiologists by extracting clinically relevant\ncharacteristics from patient data, detecting significant arrhythmias, and\ngenerating preliminary reports for the review and refinement by cardiologists.\nTo achieve cardiologist-level professionalism, ZODIAC is built on a multi-agent\ncollaboration framework, enabling the processing of patient data across\nmultiple modalities. Each LLM agent is fine-tuned using real-world patient data\nadjudicated by cardiologists, reinforcing the model's professionalism. ZODIAC\nundergoes rigorous clinical validation with independent cardiologists,\nevaluated across eight metrics that measure clinical effectiveness and address\nsecurity concerns. Results show that ZODIAC outperforms industry-leading\nmodels, including OpenAI's GPT-4o, Meta's Llama-3.1-405B, and Google's\nGemini-pro, as well as medical-specialist LLMs like Microsoft's BioGPT. ZODIAC\ndemonstrates the transformative potential of specialized LLMs in healthcare by\ndelivering domain-specific solutions that meet the stringent demands of medical\npractice. Notably, ZODIAC has been successfully integrated into\nelectrocardiography (ECG) devices, exemplifying the growing trend of embedding\nLLMs into Software-as-Medical-Device (SaMD).",
      "tldr_zh": "该论文提出 ZODIAC，一种基于大型语言模型（LLM）的多智能体框架，旨在提升 LLMs 在心脏病诊断中的专业性，达到心脏病专家水平。ZODIAC 通过多智能体协作处理多模态患者数据，包括提取临床相关特征、检测重要心律失常（如 arrhythmias）和生成初步报告，以辅助心脏病专家。框架采用真实患者数据微调每个 LLM 代理，并经过严格临床验证，在八个指标上优于 GPT-4o、Llama-3.1-405B 和 BioGPT 等模型。最终，ZODIAC 已成功集成到心电图（ECG）设备中，作为 Software-as-Medical-Device（SaMD），展示了专业化 LLM 在医疗领域的变革潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02026v1",
      "published_date": "2024-10-02 20:46:39 UTC",
      "updated_date": "2024-10-02 20:46:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:55:35.902690"
    },
    {
      "arxiv_id": "2410.02025v1",
      "title": "A Likelihood Based Approach to Distribution Regression Using Conditional Deep Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shivam Kumar",
        "Yun Yang",
        "Lizhen Lin"
      ],
      "abstract": "In this work, we explore the theoretical properties of conditional deep\ngenerative models under the statistical framework of distribution regression\nwhere the response variable lies in a high-dimensional ambient space but\nconcentrates around a potentially lower-dimensional manifold. More\nspecifically, we study the large-sample properties of a likelihood-based\napproach for estimating these models. Our results lead to the convergence rate\nof a sieve maximum likelihood estimator (MLE) for estimating the conditional\ndistribution (and its devolved counterpart) of the response given predictors in\nthe Hellinger (Wasserstein) metric. Our rates depend solely on the intrinsic\ndimension and smoothness of the true conditional distribution. These findings\nprovide an explanation of why conditional deep generative models can circumvent\nthe curse of dimensionality from the perspective of statistical foundations and\ndemonstrate that they can learn a broader class of nearly singular conditional\ndistributions. Our analysis also emphasizes the importance of introducing a\nsmall noise perturbation to the data when they are supported sufficiently close\nto a manifold. Finally, in our numerical studies, we demonstrate the effective\nimplementation of the proposed approach using both synthetic and real-world\ndatasets, which also provide complementary validation to our theoretical\nfindings.",
      "tldr_zh": "这篇论文提出了一种基于似然的分布回归方法，使用条件深度生成模型（conditional deep generative models），针对响应变量在高维空间但可能集中在低维流形上的场景。论文分析了筛子最大似然估计器（sieve MLE）的收敛率，在 Hellinger 和 Wasserstein 度量下，这些率仅依赖于真条件分布的内在维度和光滑度，从而解释了该模型如何规避维度诅咒并学习更广泛的近似奇异条件分布。研究还强调，当数据支持接近流形时，添加小噪声扰动的重要性，以提升模型性能。最后，通过合成和真实数据集的数值实验，验证了该方法的有效性，并为理论发现提供了实证支持。",
      "categories": [
        "math.ST",
        "cs.AI",
        "cs.LG",
        "stat.ME",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "math.ST",
      "comment": "arXiv admin note: text overlap with arXiv:1708.06633 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2410.02025v1",
      "published_date": "2024-10-02 20:46:21 UTC",
      "updated_date": "2024-10-02 20:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:55:51.315221"
    },
    {
      "arxiv_id": "2410.02024v3",
      "title": "FLAG: Financial Long Document Classification via AMR-based GNN",
      "title_zh": "翻译失败",
      "authors": [
        "Bolun \"Namir\" Xia",
        "Aparna Gupta",
        "Mohammed J. Zaki"
      ],
      "abstract": "The advent of large language models (LLMs) has initiated much research into\ntheir various financial applications. However, in applying LLMs on long\ndocuments, semantic relations are not explicitly incorporated, and a full or\narbitrarily sparse attention operation is employed. In recent years, progress\nhas been made in Abstract Meaning Representation (AMR), which is a graph-based\nrepresentation of text to preserve its semantic relations. Since AMR can\nrepresent semantic relationships at a deeper level, it can be beneficially\nutilized by graph neural networks (GNNs) for constructing effective\ndocument-level graph representations built upon LLM embeddings to predict\ntarget metrics in the financial domain. We propose FLAG: Financial Long\ndocument classification via AMR-based GNN, an AMR graph based framework to\ngenerate document-level embeddings for long financial document classification.\nWe construct document-level graphs from sentence-level AMR graphs, endow them\nwith specialized LLM word embeddings in the financial domain, apply a deep\nlearning mechanism that utilizes a GNN, and examine the efficacy of our\nAMR-based approach in predicting labeled target data from long financial\ndocuments. Extensive experiments are conducted on a dataset of quarterly\nearnings calls transcripts of companies in various sectors of the economy, as\nwell as on a corpus of more recent earnings calls of companies in the S&P 1500\nComposite Index. We find that our AMR-based approach outperforms fine-tuning\nLLMs directly on text in predicting stock price movement trends at different\ntime horizons in both datasets. Our work also outperforms previous work\nutilizing document graphs and GNNs for text classification.",
      "tldr_zh": "这篇论文提出了 FLAG 框架，利用 Abstract Meaning Representation (AMR) 构建的图神经网络 (GNN) 来提升长金融文档的分类性能，旨在解决大型语言模型 (LLMs) 在处理长文档时忽略语义关系的问题。框架通过从句子级 AMR 图构建文档级图，并结合金融领域的 LLM 词嵌入和 GNN 机制，生成有效的文档级嵌入以预测目标指标。实验结果显示，在季度收益电话会议数据集上，FLAG 在预测股票价格运动趋势方面优于直接微调 LLMs 和现有文档图方法，证明了其有效性。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CE",
      "comment": "8 pages, 3 figures, to be published in CIFEr Conference 2024 as\n  \"Semantic Graph Learning for Trend Prediction from Long Financial Documents\"",
      "pdf_url": "http://arxiv.org/pdf/2410.02024v3",
      "published_date": "2024-10-02 20:45:51 UTC",
      "updated_date": "2024-10-22 18:22:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:55:59.872428"
    },
    {
      "arxiv_id": "2410.02023v2",
      "title": "DeepProtein: Deep Learning Library and Benchmark for Protein Sequence Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqing Xie",
        "Tianfan Fu"
      ],
      "abstract": "Deep learning has deeply influenced protein science, enabling breakthroughs\nin predicting protein properties, higher-order structures, and molecular\ninteractions. This paper introduces DeepProtein, a comprehensive and\nuser-friendly deep learning library tailored for protein-related tasks. It\nenables researchers to seamlessly address protein data with cutting-edge deep\nlearning models. To assess model performance, we establish a benchmark\nevaluating different deep learning architectures across multiple\nprotein-related tasks, including protein function prediction, subcellular\nlocalization prediction, protein-protein interaction prediction, and protein\nstructure prediction. Furthermore, we introduce DeepProt-T5, a series of\nfine-tuned Prot-T5-based models that achieve state-of-the-art performance on\nfour benchmark tasks, while demonstrating competitive results on six of others.\nComprehensive documentation and tutorials are available which could ensure\naccessibility and support reproducibility. Built upon the widely used drug\ndiscovery library DeepPurpose, DeepProtein is publicly available at\nhttps://github.com/jiaqingxie/DeepProtein.",
      "tldr_zh": "本文介绍了DeepProtein，这是一个全面且用户友好的深度学习库，专门用于蛋白序列学习任务，帮助研究人员轻松应用先进模型处理蛋白质数据。作者建立了基准评估不同深度学习架构在蛋白功能预测、亚细胞定位预测、蛋白-蛋白相互作用预测和蛋白结构预测等任务上的性能。特别地，DeepProt-T5系列模型基于Prot-T5微调，在四个基准任务上实现了最先进性能，并在其他六个任务上表现出竞争力。该库开源在GitHub上，并提供详细文档以确保可访问性和可重复性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Bioinformatics",
      "pdf_url": "http://arxiv.org/pdf/2410.02023v2",
      "published_date": "2024-10-02 20:42:32 UTC",
      "updated_date": "2025-04-06 18:40:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:56:11.619079"
    },
    {
      "arxiv_id": "2410.02017v1",
      "title": "Review Non-convex Optimization Method for Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Greg B Fotopoulos",
        "Paul Popovich",
        "Nicholas Hall Papadopoulos"
      ],
      "abstract": "Non-convex optimization is a critical tool in advancing machine learning,\nespecially for complex models like deep neural networks and support vector\nmachines. Despite challenges such as multiple local minima and saddle points,\nnon-convex techniques offer various pathways to reduce computational costs.\nThese include promoting sparsity through regularization, efficiently escaping\nsaddle points, and employing subsampling and approximation strategies like\nstochastic gradient descent. Additionally, non-convex methods enable model\npruning and compression, which reduce the size of models while maintaining\nperformance. By focusing on good local minima instead of exact global minima,\nnon-convex optimization ensures competitive accuracy with faster convergence\nand lower computational overhead. This paper examines the key methods and\napplications of non-convex optimization in machine learning, exploring how it\ncan lower computation costs while enhancing model performance. Furthermore, it\noutlines future research directions and challenges, including scalability and\ngeneralization, that will shape the next phase of non-convex optimization in\nmachine learning.",
      "tldr_zh": "这篇论文审视了非-convex optimization 在机器学习中的关键方法和应用，特别是针对复杂模型如 deep neural networks 和 support vector machines。论文讨论了非-convex 优化如何通过正则化、逃离 saddle points 以及 subsampling 和 approximation 策略（如 stochastic gradient descent）来降低计算成本，同时促进模型稀疏性、剪枝和压缩，以实现更快收敛和保持高性能。通过关注好的 local minima 而非全局极小点，论文展示了这些方法如何提升模型效率，并指出了未来研究方向，如可扩展性和 generalization 的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02017v1",
      "published_date": "2024-10-02 20:34:33 UTC",
      "updated_date": "2024-10-02 20:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:56:33.059482"
    },
    {
      "arxiv_id": "2410.02006v1",
      "title": "Addressing Data Heterogeneity in Federated Learning with Adaptive Normalization-Free Feature Recalibration",
      "title_zh": "通过自适应无归一化特征重新校准解决联邦学习中的数据异质性",
      "authors": [
        "Vasilis Siomos",
        "Sergio Naval-Marimont",
        "Jonathan Passerat-Palmbach",
        "Giacomo Tarroni"
      ],
      "abstract": "Federated learning is a decentralized collaborative training paradigm that\npreserves stakeholders' data ownership while improving performance and\ngeneralization. However, statistical heterogeneity among client datasets poses\na fundamental challenge by degrading system performance. To address this issue,\nwe propose Adaptive Normalization-free Feature Recalibration (ANFR), an\narchitecture-level approach that combines weight standardization and channel\nattention. Weight standardization normalizes the weights of layers instead of\nactivations. This is less susceptible to mismatched client statistics and\ninconsistent averaging, thereby more robust under heterogeneity. Channel\nattention produces learnable scaling factors for feature maps, suppressing\nthose that are inconsistent between clients due to heterogeneity. We\ndemonstrate that combining these techniques boosts model performance beyond\ntheir individual contributions, by enhancing class selectivity and optimizing\nchannel attention weight distribution. ANFR operates independently of the\naggregation method and is effective in both global and personalized federated\nlearning settings, with minimal computational overhead. Furthermore, when\ntraining with differential privacy, ANFR achieves an appealing balance between\nprivacy and utility, enabling strong privacy guarantees without sacrificing\nperformance. By integrating weight standardization and channel attention in the\nbackbone model, ANFR offers a novel and versatile approach to the challenge of\nstatistical heterogeneity. We demonstrate through extensive experiments that\nANFR consistently outperforms established baselines across various aggregation\nmethods, datasets, and heterogeneity conditions.",
      "tldr_zh": "本研究针对 Federated Learning 中数据异质性（statistical heterogeneity）导致的性能下降问题，提出了一种架构级方法 Adaptive Normalization-free Feature Recalibration (ANFR)，它结合 weight standardization 和 channel attention 来增强模型鲁棒性。Weight standardization 通过标准化层权重而非激活值，减少了对客户端统计差异的敏感性，而 channel attention 则生成可学习的缩放因子，以抑制异质性引起的特征不一致。实验结果显示，ANFR 独立于聚合方法，在全局和个性化 Federated Learning 设置中均优于基线模型，并在 differential privacy 训练下实现了隐私与实用性的良好平衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02006v1",
      "published_date": "2024-10-02 20:16:56 UTC",
      "updated_date": "2024-10-02 20:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:56:38.169680"
    },
    {
      "arxiv_id": "2410.02004v2",
      "title": "Normalizing Flow-Based Metric for Image Generation",
      "title_zh": "基于归一化流的图像生成度量标准",
      "authors": [
        "Pranav Jeevan",
        "Neeraj Nixon",
        "Amit Sethi"
      ],
      "abstract": "We propose two new evaluation metrics to assess realness of generated images\nbased on normalizing flows: a simpler and efficient flow-based likelihood\ndistance (FLD) and a more exact dual-flow based likelihood distance (D-FLD).\nBecause normalizing flows can be used to compute the exact likelihood, the\nproposed metrics assess how closely generated images align with the\ndistribution of real images from a given domain. This property gives the\nproposed metrics a few advantages over the widely used Fr\\'echet inception\ndistance (FID) and other recent metrics. Firstly, the proposed metrics need\nonly a few hundred images to stabilize (converge in mean), as opposed to tens\nof thousands needed for FID, and at least a few thousand for the other metrics.\nThis allows confident evaluation of even small sets of generated images, such\nas validation batches inside training loops. Secondly, the network used to\ncompute the proposed metric has over an order of magnitude fewer parameters\ncompared to Inception-V3 used to compute FID, making it computationally more\nefficient. For assessing the realness of generated images in new domains (e.g.,\nx-ray images), ideally these networks should be retrained on real images to\nmodel their distinct distributions. Thus, our smaller network will be even more\nadvantageous for new domains. Extensive experiments show that the proposed\nmetrics have the desired monotonic relationships with the extent of image\ndegradation of various kinds.",
      "tldr_zh": "本论文提出两种基于 Normalizing Flows 的新指标，FLD 和 D-FLD，用于评估生成图像的真实性。这些指标通过计算精确似然度来衡量生成图像与真实图像分布的接近程度，与 FID 等现有方法相比，具有数据需求少（只需几百张图像即可稳定）和计算效率高（网络参数远少于 Inception-V3）的优势。实验结果显示，这些指标能准确捕捉图像退化的各种程度，并表现出期望的单调关系。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10; I.4.0; I.4.4; I.4.3; I.4.5; I.4.1; I.4.2; I.4.6; I.4.7;\n  I.4.8; I.4.9; I.4.10; I.2.10; I.5.1; I.5.2; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02004v2",
      "published_date": "2024-10-02 20:09:58 UTC",
      "updated_date": "2024-10-05 11:31:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:56:50.527555"
    },
    {
      "arxiv_id": "2410.14682v2",
      "title": "ET-Plan-Bench: Embodied Task-level Planning Benchmark Towards Spatial-Temporal Cognition with Foundation Models",
      "title_zh": "ET-Plan-Bench：",
      "authors": [
        "Lingfeng Zhang",
        "Yuening Wang",
        "Hongjian Gu",
        "Atia Hamidizadeh",
        "Zhanguang Zhang",
        "Yuecheng Liu",
        "Yutong Wang",
        "David Gamaliel Arcos Bravo",
        "Junyi Dong",
        "Shunbo Zhou",
        "Tongtong Cao",
        "Xingyue Quan",
        "Yuzheng Zhuang",
        "Yingxue Zhang",
        "Jianye Hao"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have spurred numerous\nattempts to apply these technologies to embodied tasks, particularly focusing\non high-level task planning and task decomposition. To further explore this\narea, we introduce a new embodied task planning benchmark, ET-Plan-Bench, which\nspecifically targets embodied task planning using LLMs. It features a\ncontrollable and diverse set of embodied tasks varying in different levels of\ndifficulties and complexities, and is designed to evaluate two critical\ndimensions of LLMs' application in embodied task understanding: spatial\n(relation constraint, occlusion for target objects) and temporal & causal\nunderstanding of the sequence of actions in the environment. By using\nmulti-source simulators as the backend simulator, it can provide immediate\nenvironment feedback to LLMs, which enables LLMs to interact dynamically with\nthe environment and re-plan as necessary. We evaluated the state-of-the-art\nopen source and closed source foundation models, including GPT-4, LLAMA and\nMistral on our proposed benchmark. While they perform adequately well on simple\nnavigation tasks, their performance can significantly deteriorate when faced\nwith tasks that require a deeper understanding of spatial, temporal, and causal\nrelationships. Thus, our benchmark distinguishes itself as a large-scale,\nquantifiable, highly automated, and fine-grained diagnostic framework that\npresents a significant challenge to the latest foundation models. We hope it\ncan spark and drive further research in embodied task planning using foundation\nmodels.",
      "tldr_zh": "该论文引入了 ET-Plan-Bench，这是一个新的具身任务规划基准，旨在评估 Large Language Models (LLMs) 在空间（关系约束和目标对象遮挡）和时间/因果理解方面的能力。该基准包含可控、多样化的任务，支持多源模拟器提供即时环境反馈，让 LLMs 能够动态互动和重新规划。实验结果显示，模型如 GPT-4、LLAMA 和 Mistral 在简单导航任务中表现良好，但面对需要深度空间、时间和因果关系的复杂任务时，性能显著下降。该基准作为一个大规模、可量化的诊断框架，有望推动基础模型在具身任务规划领域的进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14682v2",
      "published_date": "2024-10-02 19:56:38 UTC",
      "updated_date": "2025-02-13 14:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:57:02.413251"
    },
    {
      "arxiv_id": "2410.01989v1",
      "title": "UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription",
      "title_zh": "翻译失败",
      "authors": [
        "Reza Basiri",
        "Ali Abedi",
        "Chau Nguyen",
        "Milos R. Popovic",
        "Shehroz S. Khan"
      ],
      "abstract": "Diabetic foot ulcers (DFUs) are a leading cause of hospitalizations and lower\nlimb amputations, placing a substantial burden on patients and healthcare\nsystems. Early detection and accurate classification of DFUs are critical for\npreventing serious complications, yet many patients experience delays in\nreceiving care due to limited access to specialized services. Telehealth has\nemerged as a promising solution, improving access to care and reducing the need\nfor in-person visits. The integration of artificial intelligence and pattern\nrecognition into telemedicine has further enhanced DFU management by enabling\nautomatic detection, classification, and monitoring from images. Despite\nadvancements in artificial intelligence-driven approaches for DFU image\nanalysis, the application of large language models for DFU image transcription\nhas not yet been explored. To address this gap, we introduce UlcerGPT, a novel\nmultimodal approach leveraging large language and vision models for DFU image\ntranscription. This framework combines advanced vision and language models,\nsuch as Large Language and Vision Assistant and Chat Generative Pre-trained\nTransformer, to transcribe DFU images by jointly detecting, classifying, and\nlocalizing regions of interest. Through detailed experiments on a public\ndataset, evaluated by expert clinicians, UlcerGPT demonstrates promising\nresults in the accuracy and efficiency of DFU transcription, offering potential\nsupport for clinicians in delivering timely care via telemedicine.",
      "tldr_zh": "糖尿病足溃疡 (DFUs) 是导致住院和截肢的主要原因，需要早期检测和分类以防止并发症，但患者常因医疗资源有限而延误就诊。论文引入 UlcerGPT，一种多模态框架，利用大型语言模型和视觉模型（如 Large Language and Vision Assistant 和 Chat Generative Pre-trained Transformer），实现 DFU 图像的转录，包括检测、分类和定位感兴趣区域。该方法填补了大型语言模型在 DFU 图像分析中的空白，通过在公共数据集上的实验，由专家临床医生评估，展示了显著的准确性和效率提升，有望通过远程医疗提供及时支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 3 figures, ICPR 2024 Conference (PRHA workshop)",
      "pdf_url": "http://arxiv.org/pdf/2410.01989v1",
      "published_date": "2024-10-02 19:51:48 UTC",
      "updated_date": "2024-10-02 19:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:57:11.830780"
    },
    {
      "arxiv_id": "2410.01985v2",
      "title": "Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Firooz",
        "Maziar Sanjabi",
        "Wenlong Jiang",
        "Xiaoling Zhai"
      ],
      "abstract": "Despite significant advancements, Large Language Models (LLMs) exhibit blind\nspots that impair their ability to retrieve and process relevant contextual\ndata effectively. We demonstrate that LLM performance in graph tasks with\ncomplexities beyond the \"needle-in-a-haystack\" scenario-where solving the\nproblem requires cross-referencing and reasoning across multiple subproblems\njointly-is influenced by the proximity of relevant information within the\ncontext, a phenomenon we term \"lost-in-distance\". We examine two fundamental\ngraph tasks: identifying common connections between two nodes and assessing\nsimilarity among three nodes, and show that the model's performance in these\ntasks significantly depends on the relative positioning of common edges. We\nevaluate three publicly available LLMs using various graph encoding techniques\nthat represent graph structures for LLM input. We propose a formulation for the\nlost-in-distance phenomenon and demonstrate that lost-in-distance and\nlost-in-the middle phenomenas occur independently. Results indicate that model\naccuracy can decline by up to 6x as the distance between node connections\nincreases, independent of graph encoding and model size.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在处理复杂图任务时出现的 \"lost-in-distance\" 现象，即相关信息的上下文距离会显著影响模型的性能和准确率。研究者评估了两个基本图任务——识别两个节点之间的共同连接以及评估三个节点之间的相似性，并使用各种图编码技术测试了三个公开的 LLMs。结果显示，随着节点连接距离增加，模型准确率可能下降高达 6 倍，且这一现象独立于图编码方法、模型大小以及 \"lost-in-the-middle\" 现象。总体而言，该研究为理解和缓解 LLMs 在图任务中的盲点提供了重要见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01985v2",
      "published_date": "2024-10-02 19:45:19 UTC",
      "updated_date": "2025-01-02 04:15:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:57:24.037932"
    },
    {
      "arxiv_id": "2410.01978v2",
      "title": "LLM+KG@VLDB'24 Workshop Summary",
      "title_zh": "翻译失败",
      "authors": [
        "Arijit Khan",
        "Tianxing Wu",
        "Xi Chen"
      ],
      "abstract": "The unification of large language models (LLMs) and knowledge graphs (KGs)\nhas emerged as a hot topic. At the LLM+KG'24 workshop, held in conjunction with\nVLDB 2024 in Guangzhou, China, one of the key themes explored was important\ndata management challenges and opportunities due to the effective interaction\nbetween LLMs and KGs. This report outlines the major directions and approaches\npresented by various speakers during the LLM+KG'24 workshop.",
      "tldr_zh": "LLM+KG'24 工作坊作为 VLDB 2024 在中国广州的附属活动，聚焦于大型语言模型 (LLMs) 和知识图谱 (KGs) 的统一，探讨了这一热门主题在数据管理领域的关键挑战和机会。该工作坊强调了 LLMs 与 KGs 有效交互带来的创新潜力，包括处理数据管理问题的新方法。报告总结了演讲者提出的主要方向和方法，为未来研究提供了宝贵见解。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "accepted at ACM SIGMOD Record 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01978v2",
      "published_date": "2024-10-02 19:35:35 UTC",
      "updated_date": "2025-03-22 20:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:57:36.226722"
    },
    {
      "arxiv_id": "2410.03770v1",
      "title": "A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xueshen Li",
        "Xinlong Hou",
        "Nirupama Ravi",
        "Ziyi Huang",
        "Yu Gan"
      ],
      "abstract": "Efficient patient-doctor interaction is among the key factors for a\nsuccessful disease diagnosis. During the conversation, the doctor could query\ncomplementary diagnostic information, such as the patient's symptoms, previous\nsurgery, and other related information that goes beyond medical evidence data\n(test results) to enhance disease diagnosis. However, this procedure is usually\ntime-consuming and less-efficient, which can be potentially optimized through\ncomputer-assisted systems. As such, we propose a diagnostic dialogue system to\nautomate the patient information collection procedure. By exploiting medical\nhistory and conversation logic, our conversation agents, particularly the\ndoctor agent, can pose multi-round clinical queries to effectively collect the\nmost relevant disease diagnostic information. Moreover, benefiting from our\ntwo-stage recommendation structure, carefully designed ranking criteria, and\ninteractive patient agent, our model is able to overcome the under-exploration\nand non-flexible challenges in dialogue generation. Our experimental results on\na real-world medical conversation dataset show that our model can generate\nclinical queries that mimic the conversation style of real doctors, with\nefficient fluency, professionalism, and safety, while effectively collecting\nrelevant disease diagnostic information.",
      "tldr_zh": "该论文提出了一种Two-Stage Proactive Dialogue Generator，利用Large Language Model，旨在优化患者-医生互动以高效收集临床信息。该系统通过医生代理进行多轮临床查询，结合医疗历史和对话逻辑，采用两阶段推荐结构、精心设计的排名标准以及互动患者代理，解决了对话生成中的探索不足和灵活性问题。实验结果显示，在真实医疗对话数据集上，该模型生成的查询模仿了真实医生的风格，具有高效的流畅性、专业性和安全性，并成功收集了相关疾病诊断信息。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Prepare for submission",
      "pdf_url": "http://arxiv.org/pdf/2410.03770v1",
      "published_date": "2024-10-02 19:32:11 UTC",
      "updated_date": "2024-10-02 19:32:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:57:47.857464"
    },
    {
      "arxiv_id": "2410.01966v3",
      "title": "Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker",
      "title_zh": "翻译失败",
      "authors": [
        "Xinlong Hou",
        "Sen Shen",
        "Xueshen Li",
        "Xinran Gao",
        "Ziyi Huang",
        "Steven J. Holiday",
        "Matthew R. Cribbet",
        "Susan W. White",
        "Edward Sazonov",
        "Yu Gan"
      ],
      "abstract": "Being able to accurately monitor the screen exposure of young children is\nimportant for research on phenomena linked to screen use such as childhood\nobesity, physical activity, and social interaction. Most existing studies rely\nupon self-report or manual measures from bulky wearable sensors, thus lacking\nefficiency and accuracy in capturing quantitative screen exposure data. In this\nwork, we developed a novel sensor informatics framework that utilizes\negocentric images from a wearable sensor, termed the screen time tracker (STT),\nand a vision language model (VLM). In particular, we devised a multi-view VLM\nthat takes multiple views from egocentric image sequences and interprets screen\nexposure dynamically. We validated our approach by using a dataset of\nchildren's free-living activities, demonstrating significant improvement over\nexisting methods in plain vision language models and object detection models.\nResults supported the promise of this monitoring approach, which could optimize\nbehavioral research on screen exposure in children's naturalistic settings.",
      "tldr_zh": "该研究开发了一种新型传感器信息框架，用于精确监测儿童屏幕暴露时间，以支持对儿童肥胖、体力活动和社会互动等现象的研究。框架结合可穿戴传感器Screen Time Tracker (STT)采集的第一人称视角图像，以及一个多视图Vision Language Model (VLM)，该模型通过处理多个视角的图像序列来动态解释屏幕暴露情况。在儿童自由活动数据集上的验证显示，该方法显著优于传统VLM和物体检测模型，证明了其在自然环境中的监测潜力，可优化相关行为研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Prepare for submission",
      "pdf_url": "http://arxiv.org/pdf/2410.01966v3",
      "published_date": "2024-10-02 19:16:47 UTC",
      "updated_date": "2025-05-08 20:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:57:59.251840"
    },
    {
      "arxiv_id": "2410.01944v1",
      "title": "One-step Noisy Label Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Jiayang Gu",
        "Jingkuan Song",
        "An Zhang",
        "Lianli Gao"
      ],
      "abstract": "Mitigating the detrimental effects of noisy labels on the training process\nhas become increasingly critical, as obtaining entirely clean or\nhuman-annotated samples for large-scale pre-training tasks is often\nimpractical. Nonetheless, existing noise mitigation methods often encounter\nlimitations in practical applications due to their task-specific design, model\ndependency, and significant computational overhead. In this work, we exploit\nthe properties of high-dimensional orthogonality to identify a robust and\neffective boundary in cone space for separating clean and noisy samples.\nBuilding on this, we propose One-step Anti-Noise (OSA), a model-agnostic noisy\nlabel mitigation paradigm that employs an estimator model and a scoring\nfunction to assess the noise level of input pairs through just one-step\ninference, a cost-efficient process. We empirically demonstrate the superiority\nof OSA, highlighting its enhanced training robustness, improved task\ntransferability, ease of deployment, and reduced computational costs across\nvarious benchmarks, models, and tasks. Our code is released at\nhttps://github.com/leolee99/OSA.",
      "tldr_zh": "该论文针对噪声标签对训练过程的负面影响，提出了一种模型无关的缓解方法 One-step Anti-Noise (OSA)。OSA 利用高维正交性在锥空间中分离干净和噪声样本，通过一个估算器模型及评分函数，仅需一步推理即可评估输入对的噪声水平，从而实现高效计算。实验结果显示，OSA 在多种基准、模型和任务上提升了训练鲁棒性、任务转移能力，并降低了部署成本和计算开销。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 4 figures, 11 Tables",
      "pdf_url": "http://arxiv.org/pdf/2410.01944v1",
      "published_date": "2024-10-02 18:42:56 UTC",
      "updated_date": "2024-10-02 18:42:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:58:11.289915"
    },
    {
      "arxiv_id": "2410.01943v1",
      "title": "CHASE-SQL: Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL",
      "title_zh": "CHASE-SQL：文本到SQL中的多路径推理和偏好优化候选选择",
      "authors": [
        "Mohammadreza Pourreza",
        "Hailong Li",
        "Ruoxi Sun",
        "Yeounoh Chung",
        "Shayan Talaei",
        "Gaurav Tarlok Kakkar",
        "Yu Gan",
        "Amin Saberi",
        "Fatma Ozcan",
        "Sercan O. Arik"
      ],
      "abstract": "In tackling the challenges of large language model (LLM) performance for\nText-to-SQL tasks, we introduce CHASE-SQL, a new framework that employs\ninnovative strategies, using test-time compute in multi-agent modeling to\nimprove candidate generation and selection. CHASE-SQL leverages LLMs' intrinsic\nknowledge to generate diverse and high-quality SQL candidates using different\nLLM generators with: (1) a divide-and-conquer method that decomposes complex\nqueries into manageable sub-queries in a single LLM call; (2) chain-of-thought\nreasoning based on query execution plans, reflecting the steps a database\nengine takes during execution; and (3) a unique instance-aware synthetic\nexample generation technique, which offers specific few-shot demonstrations\ntailored to test questions.To identify the best candidate, a selection agent is\nemployed to rank the candidates through pairwise comparisons with a fine-tuned\nbinary-candidates selection LLM. This selection approach has been demonstrated\nto be more robust over alternatives. The proposed generators-selector framework\nnot only enhances the quality and diversity of SQL queries but also outperforms\nprevious methods. Overall, our proposed CHASE-SQL achieves the state-of-the-art\nexecution accuracy of 73.0% and 73.01% on the test set and development set of\nthe notable BIRD Text-to-SQL dataset benchmark, rendering CHASE-SQL the top\nsubmission of the leaderboard (at the time of paper submission).",
      "tldr_zh": "该研究提出CHASE-SQL框架，通过多路径推理和优化的候选选择机制，提升大语言模型(LLM)在Text-to-SQL任务中的性能。具体方法包括divide-and-conquer分解复杂查询、基于查询执行计划的chain-of-thought推理，以及instance-aware synthetic example generation生成针对性few-shot演示，以产生多样高质量SQL候选。框架采用一个选择代理通过fine-tuned的binary-candidates selection LLM进行成对比较排名，确保最佳候选选择。最终，CHASE-SQL在BIRD数据集上实现了73.0%和73.01%的执行准确率，位居基准测试榜首。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01943v1",
      "published_date": "2024-10-02 18:41:35 UTC",
      "updated_date": "2024-10-02 18:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:58:23.686516"
    },
    {
      "arxiv_id": "2410.01930v2",
      "title": "Don't flatten, tokenize! Unlocking the key to SoftMoE's efficacy in deep RL",
      "title_zh": "翻译失败",
      "authors": [
        "Ghada Sokar",
        "Johan Obando-Ceron",
        "Aaron Courville",
        "Hugo Larochelle",
        "Pablo Samuel Castro"
      ],
      "abstract": "The use of deep neural networks in reinforcement learning (RL) often suffers\nfrom performance degradation as model size increases. While soft mixtures of\nexperts (SoftMoEs) have recently shown promise in mitigating this issue for\nonline RL, the reasons behind their effectiveness remain largely unknown. In\nthis work we provide an in-depth analysis identifying the key factors driving\nthis performance gain. We discover the surprising result that tokenizing the\nencoder output, rather than the use of multiple experts, is what is behind the\nefficacy of SoftMoEs. Indeed, we demonstrate that even with an appropriately\nscaled single expert, we are able to maintain the performance gains, largely\nthanks to tokenization.",
      "tldr_zh": "本研究探讨了在强化学习（RL）中使用深度神经网络时，随着模型规模增加而导致性能下降的问题，并分析了SoftMoEs（软混合专家）在在线RL中的有效性。研究发现，SoftMoEs的关键因素并非多个专家的使用，而是对编码器输出的tokenizing操作，这大大提升了性能。实验证明，即使采用适当缩放的单一专家，通过tokenizing也能保持相似的性能收益，为优化RL模型提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01930v2",
      "published_date": "2024-10-02 18:22:45 UTC",
      "updated_date": "2025-02-26 20:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:58:35.514750"
    },
    {
      "arxiv_id": "2410.01929v1",
      "title": "LLM-Augmented Symbolic Reinforcement Learning with Landmark-Based Task Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Kheirandish",
        "Duo Xu",
        "Faramarz Fekri"
      ],
      "abstract": "One of the fundamental challenges in reinforcement learning (RL) is to take a\ncomplex task and be able to decompose it to subtasks that are simpler for the\nRL agent to learn. In this paper, we report on our work that would identify\nsubtasks by using some given positive and negative trajectories for solving the\ncomplex task. We assume that the states are represented by first-order\npredicate logic using which we devise a novel algorithm to identify the\nsubtasks. Then we employ a Large Language Model (LLM) to generate first-order\nlogic rule templates for achieving each subtask. Such rules were then further\nfined tuned to a rule-based policy via an Inductive Logic Programming\n(ILP)-based RL agent. Through experiments, we verify the accuracy of our\nalgorithm in detecting subtasks which successfully detect all of the subtasks\ncorrectly. We also investigated the quality of the common-sense rules produced\nby the language model to achieve the subtasks. Our experiments show that our\nLLM-guided rule template generation can produce rules that are necessary for\nsolving a subtask, which leads to solving complex tasks with fewer assumptions\nabout predefined first-order logic predicates of the environment.",
      "tldr_zh": "这篇论文提出了一种增强符号强化学习 (Reinforcement Learning) 的方法，通过基于地标的任务分解来识别子任务，利用给定正负轨迹和一阶谓词逻辑 (first-order predicate logic) 算法进行分解。研究使用大型语言模型 (LLM) 生成一阶逻辑规则模板来实现每个子任务，并通过归纳逻辑编程 (ILP)-based RL 代理进一步微调这些规则为基于规则的策略。实验结果表明，该方法准确检测所有子任务，且 LLM 生成的常识规则能减少对预定义一阶逻辑谓词的依赖，从而更高效地解决复杂任务。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01929v1",
      "published_date": "2024-10-02 18:22:42 UTC",
      "updated_date": "2024-10-02 18:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:58:47.902018"
    },
    {
      "arxiv_id": "2410.01927v1",
      "title": "Risk Alignment in Agentic AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Hayley Clatterbuck",
        "Clinton Castro",
        "Arvo Muñoz Morán"
      ],
      "abstract": "Agentic AIs $-$ AIs that are capable and permitted to undertake complex\nactions with little supervision $-$ mark a new frontier in AI capabilities and\nraise new questions about how to safely create and align such systems with\nusers, developers, and society. Because agents' actions are influenced by their\nattitudes toward risk, one key aspect of alignment concerns the risk profiles\nof agentic AIs. Risk alignment will matter for user satisfaction and trust, but\nit will also have important ramifications for society more broadly, especially\nas agentic AIs become more autonomous and are allowed to control key aspects of\nour lives. AIs with reckless attitudes toward risk (either because they are\ncalibrated to reckless human users or are poorly designed) may pose significant\nthreats. They might also open 'responsibility gaps' in which there is no agent\nwho can be held accountable for harmful actions. What risk attitudes should\nguide an agentic AI's decision-making? How might we design AI systems that are\ncalibrated to the risk attitudes of their users? What guardrails, if any,\nshould be placed on the range of permissible risk attitudes? What are the\nethical considerations involved when designing systems that make risky\ndecisions on behalf of others? We present three papers that bear on key\nnormative and technical aspects of these questions.",
      "tldr_zh": "这篇论文探讨了 Agentic AIs（能够独立执行复杂任务的 AI 系统）在风险对齐（Risk Alignment）方面的挑战，强调 AI 的风险态度如何影响用户信任、社会安全和责任问题。论文分析了如何设计 AI 系统以匹配用户风险态度，同时设置适当的界限来防范鲁莽决策可能带来的威胁，如责任漏洞。最终，它提出了相关伦理考虑，并介绍了三篇论文，针对这些规范和技术问题提供见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01927v1",
      "published_date": "2024-10-02 18:21:08 UTC",
      "updated_date": "2024-10-02 18:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:58:58.980705"
    },
    {
      "arxiv_id": "2410.01917v2",
      "title": "Provably Accurate Shapley Value Estimation via Leverage Score Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Musco",
        "R. Teal Witter"
      ],
      "abstract": "Originally introduced in game theory, Shapley values have emerged as a\ncentral tool in explainable machine learning, where they are used to attribute\nmodel predictions to specific input features. However, computing Shapley values\nexactly is expensive: for a general model with $n$ features, $O(2^n)$ model\nevaluations are necessary. To address this issue, approximation algorithms are\nwidely used. One of the most popular is the Kernel SHAP algorithm, which is\nmodel agnostic and remarkably effective in practice. However, to the best of\nour knowledge, Kernel SHAP has no strong non-asymptotic complexity guarantees.\nWe address this issue by introducing Leverage SHAP, a light-weight modification\nof Kernel SHAP that provides provably accurate Shapley value estimates with\njust $O(n\\log n)$ model evaluations. Our approach takes advantage of a\nconnection between Shapley value estimation and agnostic active learning by\nemploying leverage score sampling, a powerful regression tool. Beyond\ntheoretical guarantees, we show that Leverage SHAP consistently outperforms\neven the highly optimized implementation of Kernel SHAP available in the\nubiquitous SHAP library [Lundberg & Lee, 2017].",
      "tldr_zh": "这篇论文针对Shapley values在可解释机器学习中的应用，解决了其精确计算需O(2^n)模型评估的效率问题。作者提出Leverage SHAP，一种对Kernel SHAP的轻量修改，通过leverage score sampling仅需O(n log n)模型评估，即可提供可证明准确的Shapley值估计。Leverage SHAP利用Shapley值估计与无偏主动学习的联系，显著提升了计算效率，并在实验中一致优于SHAP库中的Kernel SHAP实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01917v2",
      "published_date": "2024-10-02 18:15:48 UTC",
      "updated_date": "2025-03-10 15:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:59:12.691029"
    },
    {
      "arxiv_id": "2410.01912v1",
      "title": "A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation",
      "title_zh": "视觉-",
      "authors": [
        "Liang Chen",
        "Sinan Tan",
        "Zefan Cai",
        "Weichu Xie",
        "Haozhe Zhao",
        "Yichi Zhang",
        "Junyang Lin",
        "Jinze Bai",
        "Tianyu Liu",
        "Baobao Chang"
      ],
      "abstract": "This work tackles the information loss bottleneck of vector-quantization (VQ)\nautoregressive image generation by introducing a novel model architecture\ncalled the 2-Dimensional Autoregression (DnD) Transformer. The DnD-Transformer\npredicts more codes for an image by introducing a new autoregression direction,\n\\textit{model depth}, along with the sequence length direction. Compared to\ntraditional 1D autoregression and previous work utilizing similar 2D image\ndecomposition such as RQ-Transformer, the DnD-Transformer is an end-to-end\nmodel that can generate higher quality images with the same backbone model size\nand sequence length, opening a new optimization perspective for autoregressive\nimage generation. Furthermore, our experiments reveal that the\nDnD-Transformer's potential extends beyond generating natural images. It can\neven generate images with rich text and graphical elements in a self-supervised\nmanner, demonstrating an understanding of these combined modalities. This has\nnot been previously demonstrated for popular vision generative models such as\ndiffusion models, showing a spark of vision-language intelligence when trained\nsolely on images. Code, datasets and models are open at\nhttps://github.com/chenllliang/DnD-Transformer.",
      "tldr_zh": "本研究针对向量-quantization (VQ) 自回归图像生成中的信息损失瓶颈，引入了新型架构：2-Dimensional Autoregression (DnD) Transformer，通过在模型深度方向添加新的自回归维度，实现更高效的细粒度图像生成。相比传统1D自回归和类似RQ-Transformer，该模型是端到端的，能够以相同骨干模型大小和序列长度生成更高质量的图像。实验结果显示，DnD-Transformer不仅能生成自然图像，还能在自监督方式下处理包含丰富文本和图形元素的图像，展现出视觉-语言智能的潜力，这在扩散模型等流行框架中尚未实现。总的来说，该工作为自回归图像生成提供了新的优化视角，并开源了代码、数据集和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 20 figures, code is open at\n  https://github.com/chenllliang/DnD-Transformer",
      "pdf_url": "http://arxiv.org/pdf/2410.01912v1",
      "published_date": "2024-10-02 18:10:05 UTC",
      "updated_date": "2024-10-02 18:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:59:27.204186"
    },
    {
      "arxiv_id": "2410.01906v1",
      "title": "Social Media Authentication and Combating Deepfakes using Semi-fragile Invisible Image Watermarking",
      "title_zh": "利用半易损隐形图像水印进行社交媒体认证和对抗深度伪造",
      "authors": [
        "Aakash Varma Nadimpalli",
        "Ajita Rattani"
      ],
      "abstract": "With the significant advances in deep generative models for image and video\nsynthesis, Deepfakes and manipulated media have raised severe societal\nconcerns. Conventional machine learning classifiers for deepfake detection\noften fail to cope with evolving deepfake generation technology and are\nsusceptible to adversarial attacks. Alternatively, invisible image watermarking\nis being researched as a proactive defense technique that allows media\nauthentication by verifying an invisible secret message embedded in the image\npixels. A handful of invisible image watermarking techniques introduced for\nmedia authentication have proven vulnerable to basic image processing\noperations and watermark removal attacks. In response, we have proposed a\nsemi-fragile image watermarking technique that embeds an invisible secret\nmessage into real images for media authentication. Our proposed watermarking\nframework is designed to be fragile to facial manipulations or tampering while\nbeing robust to benign image-processing operations and watermark removal\nattacks. This is facilitated through a unique architecture of our proposed\ntechnique consisting of critic and adversarial networks that enforce high image\nquality and resiliency to watermark removal efforts, respectively, along with\nthe backbone encoder-decoder and the discriminator networks. Thorough\nexperimental investigations on SOTA facial Deepfake datasets demonstrate that\nour proposed model can embed a $64$-bit secret as an imperceptible image\nwatermark that can be recovered with a high-bit recovery accuracy when benign\nimage processing operations are applied while being non-recoverable when unseen\nDeepfake manipulations are applied. In addition, our proposed watermarking\ntechnique demonstrates high resilience to several white-box and black-box\nwatermark removal attacks. Thus, obtaining state-of-the-art performance.",
      "tldr_zh": "该论文针对Deepfakes和媒体操纵的社会风险，提出了一种semi-fragile invisible image watermarking技术，用于社交媒体认证和对抗假冒内容。该方法在图像中嵌入64-bit不可见秘密消息，通过critic networks、adversarial networks、encoder-decoder和discriminator networks的独特架构，确保水印对面部操纵或篡改脆弱，而对良性图像处理和水印移除攻击（如白盒和黑盒攻击）具有高抵抗力。实验在SOTA面部Deepfake数据集上证明，该技术能实现高位恢复准确率，并在未知Deepfake操纵下使水印不可恢复，从而达到了state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM Transactions (Digital Threats: Research and Practice)",
      "pdf_url": "http://arxiv.org/pdf/2410.01906v1",
      "published_date": "2024-10-02 18:05:03 UTC",
      "updated_date": "2024-10-02 18:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:59:39.120866"
    },
    {
      "arxiv_id": "2410.01899v1",
      "title": "The potential of LLM-generated reports in DevSecOps",
      "title_zh": "LLM 生成报告在 DevSecOps 中的潜力",
      "authors": [
        "Nikolaos Lykousas",
        "Vasileios Argyropoulos",
        "Fran Casino"
      ],
      "abstract": "Alert fatigue is a common issue faced by software teams using the DevSecOps\nparadigm. The overwhelming number of warnings and alerts generated by security\nand code scanning tools, particularly in smaller teams where resources are\nlimited, leads to desensitization and diminished responsiveness to security\nwarnings, potentially exposing systems to vulnerabilities. This paper explores\nthe potential of LLMs in generating actionable security reports that emphasize\nthe financial impact and consequences of detected security issues, such as\ncredential leaks, if they remain unaddressed. A survey conducted among\ndevelopers indicates that LLM-generated reports significantly enhance the\nlikelihood of immediate action on security issues by providing clear,\ncomprehensive, and motivating insights. Integrating these reports into\nDevSecOps workflows can mitigate attention saturation and alert fatigue,\nensuring that critical security warnings are addressed effectively.",
      "tldr_zh": "本论文探讨了LLM生成的安全报告在DevSecOps中的潜力，旨在解决警报疲劳问题，该问题因过多警告导致开发者脱敏和响应降低，尤其在资源有限的小型团队中。研究通过调查开发者发现，LLM生成的报告强调未解决安全问题（如凭证泄露）的财务影响和后果，能提供清晰、全面的见解，从而显著提升立即采取行动的可能性。将这些报告整合到DevSecOps工作流中，可有效缓解注意力饱和，确保关键安全警告得到及时处理。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Published in AIESE 2024 (International Conference on AI empowered\n  Software Engineering)",
      "pdf_url": "http://arxiv.org/pdf/2410.01899v1",
      "published_date": "2024-10-02 18:01:12 UTC",
      "updated_date": "2024-10-02 18:01:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:59:49.758877"
    },
    {
      "arxiv_id": "2410.01806v1",
      "title": "Samba: Synchronized Set-of-Sequences Modeling for Multiple Object Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Mattia Segu",
        "Luigi Piccinelli",
        "Siyuan Li",
        "Yung-Hsu Yang",
        "Bernt Schiele",
        "Luc Van Gool"
      ],
      "abstract": "Multiple object tracking in complex scenarios - such as coordinated dance\nperformances, team sports, or dynamic animal groups - presents unique\nchallenges. In these settings, objects frequently move in coordinated patterns,\nocclude each other, and exhibit long-term dependencies in their trajectories.\nHowever, it remains a key open research question on how to model long-range\ndependencies within tracklets, interdependencies among tracklets, and the\nassociated temporal occlusions. To this end, we introduce Samba, a novel\nlinear-time set-of-sequences model designed to jointly process multiple\ntracklets by synchronizing the multiple selective state-spaces used to model\neach tracklet. Samba autoregressively predicts the future track query for each\nsequence while maintaining synchronized long-term memory representations across\ntracklets. By integrating Samba into a tracking-by-propagation framework, we\npropose SambaMOTR, the first tracker effectively addressing the aforementioned\nissues, including long-range dependencies, tracklet interdependencies, and\ntemporal occlusions. Additionally, we introduce an effective technique for\ndealing with uncertain observations (MaskObs) and an efficient training recipe\nto scale SambaMOTR to longer sequences. By modeling long-range dependencies and\ninteractions among tracked objects, SambaMOTR implicitly learns to track\nobjects accurately through occlusions without any hand-crafted heuristics. Our\napproach significantly surpasses prior state-of-the-art on the DanceTrack, BFT,\nand SportsMOT datasets.",
      "tldr_zh": "这篇论文针对多对象跟踪(Multiple Object Tracking)中的复杂场景（如舞蹈表演、团队体育或动物群），提出了 Samba 模型，该模型是一种线性时间的序列集框架，通过同步多个 selective state-spaces 来处理轨迹(tracklets)间的长程依赖、相互依赖和临时遮挡。作者将 Samba 整合到 SambaMOTR 跟踪框架中，并引入 MaskObs 技术来管理不确定观察，同时采用高效训练方法以适应更长序列。结果显示，SambaMOTR 在 DanceTrack、BFT 和 SportsMOT 数据集上显著超越了现有最先进方法，能够在不依赖手动启发式规则的情况下准确跟踪遮挡对象。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01806v1",
      "published_date": "2024-10-02 17:59:57 UTC",
      "updated_date": "2024-10-02 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:01:55.746815"
    },
    {
      "arxiv_id": "2410.01801v1",
      "title": "FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments Generation from In-The-Wild Clothing Images",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Zhang",
        "Yuanhao Wang",
        "Francisco Vicente Carrasco",
        "Chenglei Wu",
        "Jinlong Yang",
        "Thabo Beeler",
        "Fernando De la Torre"
      ],
      "abstract": "We introduce FabricDiffusion, a method for transferring fabric textures from\na single clothing image to 3D garments of arbitrary shapes. Existing approaches\ntypically synthesize textures on the garment surface through 2D-to-3D texture\nmapping or depth-aware inpainting via generative models. Unfortunately, these\nmethods often struggle to capture and preserve texture details, particularly\ndue to challenging occlusions, distortions, or poses in the input image.\nInspired by the observation that in the fashion industry, most garments are\nconstructed by stitching sewing patterns with flat, repeatable textures, we\ncast the task of clothing texture transfer as extracting distortion-free,\ntileable texture materials that are subsequently mapped onto the UV space of\nthe garment. Building upon this insight, we train a denoising diffusion model\nwith a large-scale synthetic dataset to rectify distortions in the input\ntexture image. This process yields a flat texture map that enables a tight\ncoupling with existing Physically-Based Rendering (PBR) material generation\npipelines, allowing for realistic relighting of the garment under various\nlighting conditions. We show that FabricDiffusion can transfer various features\nfrom a single clothing image including texture patterns, material properties,\nand detailed prints and logos. Extensive experiments demonstrate that our model\nsignificantly outperforms state-to-the-art methods on both synthetic data and\nreal-world, in-the-wild clothing images while generalizing to unseen textures\nand garment shapes.",
      "tldr_zh": "本研究提出FabricDiffusion，一种高保真度纹理转移方法，用于从野外服装图像生成任意形状的3D服装。方法将纹理转移任务视为提取无扭曲、可平铺的纹理材料，并使用去噪扩散模型（denoising diffusion model）在大型合成数据集上训练，以修正输入图像中的扭曲和遮挡问题，从而生成可与Physically-Based Rendering (PBR)管道结合的平整纹理映射，实现真实照明下的服装重渲染。实验结果显示，FabricDiffusion在合成数据和真实世界图像上显著优于现有方法，能够准确转移纹理图案、材料属性以及详细打印和标志，并泛化到未见纹理和服装形状。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to SIGGRAPH Asia 2024. Project page:\n  https://humansensinglab.github.io/fabric-diffusion",
      "pdf_url": "http://arxiv.org/pdf/2410.01801v1",
      "published_date": "2024-10-02 17:57:12 UTC",
      "updated_date": "2024-10-02 17:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:00:18.917788"
    },
    {
      "arxiv_id": "2410.01871v2",
      "title": "Auction-Based Regulation for Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Bornstein",
        "Zora Che",
        "Suhas Julapalli",
        "Abdirisak Mohamed",
        "Amrit Singh Bedi",
        "Furong Huang"
      ],
      "abstract": "In an era of \"moving fast and breaking things\", regulators have moved slowly\nto pick up the safety, bias, and legal debris left in the wake of broken\nArtificial Intelligence (AI) deployment. While there is much-warranted\ndiscussion about how to address the safety, bias, and legal woes of\nstate-of-the-art AI models, rigorous and realistic mathematical frameworks to\nregulate AI are lacking. Our paper addresses this challenge, proposing an\nauction-based regulatory mechanism that provably incentivizes devices (i) to\ndeploy compliant models and (ii) to participate in the regulation process. We\nformulate AI regulation as an all-pay auction where enterprises submit models\nfor approval. The regulator enforces compliance thresholds and further rewards\nmodels exhibiting higher compliance than their peers. We derive Nash Equilibria\ndemonstrating that rational agents will submit models exceeding the prescribed\ncompliance threshold. Empirical results show that our regulatory auction boosts\ncompliance rates by 20% and participation rates by 15% compared to baseline\nregulatory mechanisms, outperforming simpler frameworks that merely impose\nminimum compliance standards.",
      "tldr_zh": "该论文针对AI部署的安全、偏见和法律问题，提出了一种基于拍卖的监管机制（auction-based regulatory mechanism），以激励企业部署合规模型并积极参与监管过程。通过将AI监管表述为全支付拍卖（all-pay auction），监管者强制执行合规阈值并奖励表现优于同行的模型，并推导出Nash Equilibria，证明理性代理会提交超过阈值的模型。实证结果显示，该机制相较于基线方法，提高了20%的合规率和15%的参与率，为AI监管提供了可行的数学框架。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CY",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.GT",
      "comment": "22 pages, 8 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.01871v2",
      "published_date": "2024-10-02 17:57:02 UTC",
      "updated_date": "2025-02-03 18:56:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:00:36.250840"
    },
    {
      "arxiv_id": "2410.01798v3",
      "title": "Windowed MAPF with Completeness Guarantees",
      "title_zh": "具有完备性保证的窗口化 MAPF",
      "authors": [
        "Rishi Veerapaneni",
        "Muhammad Suhail Saleem",
        "Jiaoyang Li",
        "Maxim Likhachev"
      ],
      "abstract": "Traditional multi-agent path finding (MAPF) methods try to compute entire\nstart-goal paths which are collision free. However, computing an entire path\ncan take too long for MAPF systems where agents need to replan fast. Methods\nthat address this typically employ a \"windowed\" approach and only try to find\ncollision free paths for a small windowed timestep horizon. This adaptation\ncomes at the cost of incompleteness; all current windowed approaches can become\nstuck in deadlock or livelock. Our main contribution is to introduce our\nframework, WinC-MAPF, for Windowed MAPF that enables completeness. Our\nframework uses heuristic update insights from single-agent real-time heuristic\nsearch algorithms as well as agent independence ideas from MAPF algorithms. We\nalso develop Single-Step CBS (SS-CBS), an instantiation of this framework using\na novel modification to CBS. We show how SS-CBS, which only plans a single step\nand updates heuristics, can effectively solve tough scenarios where existing\nwindowed approaches fail.",
      "tldr_zh": "该论文探讨了多智能体路径规划（MAPF）问题，传统方法计算完整无碰撞路径耗时过长，而现有的窗口化方法虽能快速规划短期路径，但可能导致不完整性，如陷入死锁或活锁。作者提出WinC-MAPF框架，通过借鉴单智能体实时启发式搜索的启发式更新和MAPF的智能体独立性，确保窗口化规划的完整性。框架的具体实现包括Single-Step CBS（SS-CBS）算法，该算法仅规划一步并更新启发式，从而在现有窗口化方法失败的复杂场景中有效解决问题。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01798v3",
      "published_date": "2024-10-02 17:55:46 UTC",
      "updated_date": "2025-04-28 00:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:00:41.567019"
    },
    {
      "arxiv_id": "2410.01792v2",
      "title": "When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1",
      "title_zh": "翻译失败",
      "authors": [
        "R. Thomas McCoy",
        "Shunyu Yao",
        "Dan Friedman",
        "Mathew D. Hardy",
        "Thomas L. Griffiths"
      ],
      "abstract": "In \"Embers of Autoregression\" (McCoy et al., 2023), we showed that several\nlarge language models (LLMs) have some important limitations that are\nattributable to their origins in next-word prediction. Here we investigate\nwhether these issues persist with o1, a new system from OpenAI that differs\nfrom previous LLMs in that it is optimized for reasoning. We find that o1\nsubstantially outperforms previous LLMs in many cases, with particularly large\nimprovements on rare variants of common tasks (e.g., forming acronyms from the\nsecond letter of each word in a list, rather than the first letter). Despite\nthese quantitative improvements, however, o1 still displays the same\nqualitative trends that we observed in previous systems. Specifically, o1 --\nlike previous LLMs -- is sensitive to the probability of examples and tasks,\nperforming better and requiring fewer \"thinking tokens\" in high-probability\nsettings than in low-probability ones. These results show that optimizing a\nlanguage model for reasoning can mitigate but might not fully overcome the\nlanguage model's probability sensitivity.",
      "tldr_zh": "本研究分析了OpenAI的o1模型，该模型被优化用于推理，以评估其是否仍存在像之前LLMs（大型语言模型）那样的autoregression遗留问题，如在McCoy et al. (2023)的\"Embers of Autoregression\"中所述。结果显示，o1在许多任务上显著优于先前模型，尤其在罕见任务变体（如从单词的第二字母形成首字母缩写）上，表现出更高的准确性和更少的\"thinking tokens\"。尽管这些量化改进显著，但o1仍对示例和任务的概率敏感，在高概率场景中表现更好，而无法完全克服这一局限。总之，该研究表明，针对推理优化语言模型可以缓解但不彻底消除其概率敏感性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages; updated to fix typo in Fig 4 caption",
      "pdf_url": "http://arxiv.org/pdf/2410.01792v2",
      "published_date": "2024-10-02 17:50:19 UTC",
      "updated_date": "2024-10-04 03:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:00:50.555163"
    },
    {
      "arxiv_id": "2410.01791v1",
      "title": "DreamGarden: A Designer Assistant for Growing Games from a Single Prompt",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Earle",
        "Samyak Parajuli",
        "Andrzej Banburski-Fahey"
      ],
      "abstract": "Coding assistants are increasingly leveraged in game design, both generating\ncode and making high-level plans. To what degree can these tools align with\ndeveloper workflows, and what new modes of human-computer interaction can\nemerge from their use? We present DreamGarden, an AI system capable of\nassisting with the development of diverse game environments in Unreal Engine.\nAt the core of our method is an LLM-driven planner, capable of breaking down a\nsingle, high-level prompt -- a dream, memory, or imagined scenario provided by\na human user -- into a hierarchical action plan, which is then distributed\nacross specialized submodules facilitating concrete implementation. This system\nis presented to the user as a garden of plans and actions, both growing\nindependently and responding to user intervention via seed prompts, pruning,\nand feedback. Through a user study, we explore design implications of this\nsystem, charting courses for future work in semi-autonomous assistants and\nopen-ended simulation design.",
      "tldr_zh": "本文介绍了 DreamGarden，一种 AI 辅助工具，旨在从单一高层次提示（如梦想或场景）生成 Unreal Engine 中的多样化游戏环境。系统核心采用 LLM-driven planner，将提示分解成层次化行动计划，并分配到专门子模块中实现具体执行，用户可通过种子提示、修剪和反馈干预系统。用户研究显示，该系统增强了开发者工作流，探索了新的人机交互模式，并为半自治助手和开放式模拟设计提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages + appendix, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01791v1",
      "published_date": "2024-10-02 17:49:07 UTC",
      "updated_date": "2024-10-02 17:49:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:01:02.251254"
    },
    {
      "arxiv_id": "2410.01789v1",
      "title": "Investigating on RLHF methodology",
      "title_zh": "翻译失败",
      "authors": [
        "Alexey Kutalev",
        "Sergei Markoff"
      ],
      "abstract": "In this article, we investigate the alignment of Large Language Models\naccording to human preferences. We discuss the features of training a\nPreference Model, which simulates human preferences, and the methods and\ndetails we found essential for achieving the best results. We also discuss\nusing Reinforcement Learning to fine-tune Large Language Models and describe\nthe challenges we faced and the ways to overcome them. Additionally, we present\nour experience with the Direct Preference Optimization method, which enables us\nto align a Large Language Model with human preferences without creating a\nseparate Preference Model. As our contribution, we introduce the approach for\ncollecting a preference dataset through perplexity filtering, which makes the\nprocess of creating such a dataset for a specific Language Model much easier\nand more cost-effective.",
      "tldr_zh": "本文调查了 Reinforcement Learning from Human Feedback (RLHF) 方法，用于根据人类偏好对齐 Large Language Models (LLMs)。研究讨论了训练 Preference Model 的关键技术和细节，以模拟人类偏好，并探讨了使用 Reinforcement Learning 微调 LLMs 时面临的挑战及其解决方案。作者还介绍了 Direct Preference Optimization 方法，可在不创建单独 Preference Model 的情况下实现模型对齐，并贡献了一种通过 perplexity filtering 收集偏好数据集的创新方法，使其针对特定 LLMs 的数据集创建过程更简单且成本更低。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 6 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.01789v1",
      "published_date": "2024-10-02 17:46:22 UTC",
      "updated_date": "2024-10-02 17:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:01:19.431684"
    },
    {
      "arxiv_id": "2410.13876v1",
      "title": "Deep Knowledge Tracing for Personalized Adaptive Learning at Historically Black Colleges and Universities",
      "title_zh": "翻译失败",
      "authors": [
        "Ming-Mu Kuo",
        "Xiangfang Li",
        "Lijun Qian",
        "Pamela Obiomon",
        "Xishuang Dong"
      ],
      "abstract": "Personalized adaptive learning (PAL) stands out by closely monitoring\nindividual students' progress and tailoring their learning paths to their\nunique knowledge and needs. A crucial technique for effective PAL\nimplementation is knowledge tracing, which models students' evolving knowledge\nto predict their future performance. Recent advancements in deep learning have\nsignificantly enhanced knowledge tracing through Deep Knowledge Tracing (DKT).\nHowever, there is limited research on DKT for Science, Technology, Engineering,\nand Math (STEM) education at Historically Black Colleges and Universities\n(HBCUs). This study builds a comprehensive dataset to investigate DKT for\nimplementing PAL in STEM education at HBCUs, utilizing multiple\nstate-of-the-art (SOTA) DKT models to examine knowledge tracing performance.\nThe dataset includes 352,148 learning records for 17,181 undergraduate students\nacross eight colleges at Prairie View A&M University (PVAMU). The SOTA DKT\nmodels employed include DKT, DKT+, DKVMN, SAKT, and KQN. Experimental results\ndemonstrate the effectiveness of DKT models in accurately predicting students'\nacademic outcomes. Specifically, the SAKT and KQN models outperform others in\nterms of accuracy and AUC. These findings have significant implications for\nfaculty members and academic advisors, providing valuable insights for\nidentifying students at risk of academic underperformance before the end of the\nsemester. Furthermore, this allows for proactive interventions to support\nstudents' academic progress, potentially enhancing student retention and\ngraduation rates.",
      "tldr_zh": "本研究探讨了在 Historically Black Colleges and Universities (HBCUs) 的 STEM 教育中应用 Deep Knowledge Tracing (DKT) 来实现 Personalized Adaptive Learning (PAL)，以预测学生学术表现并个性化学习路径。研究构建了一个包含 352,148 条学习记录的数据集，涵盖 17,181 名本科生，并评估了多种 SOTA DKT 模型，包括 DKT, DKT+, DKVMN, SAKT 和 KQN。实验结果显示 SAKT 和 KQN 模型在准确性和 AUC 上表现出色，能够有效预测学生成绩并识别风险学生。这些发现为教师和学术顾问提供宝贵洞见，支持主动干预措施，提升 HBCUs 的学生保留率和毕业率。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13876v1",
      "published_date": "2024-10-02 17:42:59 UTC",
      "updated_date": "2024-10-02 17:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:01:29.716964"
    },
    {
      "arxiv_id": "2410.01782v1",
      "title": "Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shayekh Bin Islam",
        "Md Asib Rahman",
        "K S M Tozammel Hossain",
        "Enamul Hoque",
        "Shafiq Joty",
        "Md Rizwan Parvez"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has been shown to enhance the factual\naccuracy of Large Language Models (LLMs), but existing methods often suffer\nfrom limited reasoning capabilities in effectively using the retrieved\nevidence, particularly when using open-source LLMs. To mitigate this gap, we\nintroduce a novel framework, Open-RAG, designed to enhance reasoning\ncapabilities in RAG with open-source LLMs. Our framework transforms an\narbitrary dense LLM into a parameter-efficient sparse mixture of experts (MoE)\nmodel capable of handling complex reasoning tasks, including both single- and\nmulti-hop queries. Open-RAG uniquely trains the model to navigate challenging\ndistractors that appear relevant but are misleading. As a result, Open-RAG\nleverages latent learning, dynamically selecting relevant experts and\nintegrating external knowledge effectively for more accurate and contextually\nrelevant responses. In addition, we propose a hybrid adaptive retrieval method\nto determine retrieval necessity and balance the trade-off between performance\ngain and inference speed. Experimental results show that the Llama2-7B-based\nOpen-RAG outperforms state-of-the-art LLMs and RAG models such as ChatGPT,\nSelf-RAG, and Command R+ in various knowledge-intensive tasks. We open-source\nour code and models at https://openragmoe.github.io/",
      "tldr_zh": "该论文提出 Open-RAG 框架，以提升开源 Large Language Models (LLMs) 在 Retrieval-Augmented Generation (RAG) 中的推理能力，解决现有方法在利用检索证据时的局限性。该框架将任意稠密 LLM 转化为参数高效的 Mixture of Experts (MoE) 模型，支持单跳和多跳查询，并通过训练处理误导性 distractors，实现动态专家选择和外部知识整合。此外，引入混合自适应检索方法，以平衡性能提升和推理速度。实验结果表明，基于 Llama2-7B 的 Open-RAG 在知识密集型任务中超越 ChatGPT、Self-RAG 和 Command R+ 等模型，并开源了代码和模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Findings. Website:\n  https://openragmoe.github.io/. 14 pages, 7 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.01782v1",
      "published_date": "2024-10-02 17:37:18 UTC",
      "updated_date": "2024-10-02 17:37:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:02:07.416018"
    },
    {
      "arxiv_id": "2410.01779v3",
      "title": "Composing Global Optimizers to Reasoning Tasks via Algebraic Objects in Neural Nets",
      "title_zh": "翻译失败",
      "authors": [
        "Yuandong Tian"
      ],
      "abstract": "We prove rich algebraic structures of the solution space for 2-layer neural\nnetworks with quadratic activation and $L_2$ loss, trained on reasoning tasks\nin Abelian group (e.g., modular addition). Such a rich structure enables\nanalytical construction of global optimal solutions from partial solutions that\nonly satisfy part of the loss, despite its high nonlinearity. We coin the\nframework as CoGO (Composing Global Optimizers). Specifically, we show that the\nweight space over different numbers of hidden nodes of the 2-layer network is\nequipped with a semi-ring algebraic structure, and the loss function to be\noptimized consists of monomial potentials, which are ring homomorphism,\nallowing partial solutions to be composed into global ones by ring addition and\nmultiplication. Our experiments show that around $95\\%$ of the solutions\nobtained by gradient descent match exactly our theoretical constructions.\nAlthough the global optimizers constructed only required a small number of\nhidden nodes, our analysis on gradient dynamics shows that\nover-parameterization asymptotically decouples training dynamics and is\nbeneficial. We further show that training dynamics favors simpler solutions\nunder weight decay, and thus high-order global optimizers such as perfect\nmemorization are unfavorable. Code can be found at\nhttps://github.com/facebookresearch/luckmatters/tree/yuandong3/ssl/real-dataset.",
      "tldr_zh": "本文证明了在 Abelian group 任务（如模加法）上，使用 quadratic activation 和 L2 loss 的 2-layer neural networks 的解决方案空间具有丰富的代数结构，并引入 CoGO 框架，通过半环 algebraic structure 和 ring homomorphism 将部分解决方案组合成全局最优解。实验结果显示，约 95% 的梯度下降得到的解决方案与理论构建精确匹配，且过参数化有助于解耦训练动态。进一步分析表明，在权重衰减下，训练动态更偏好简单解决方案，从而使高阶全局优化器（如完美记忆）变得不利于。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.AC",
        "math.RA"
      ],
      "primary_category": "cs.LG",
      "comment": "Update presentation and add more lemmas for necessary conditions",
      "pdf_url": "http://arxiv.org/pdf/2410.01779v3",
      "published_date": "2024-10-02 17:33:26 UTC",
      "updated_date": "2024-12-03 20:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:02:19.948644"
    },
    {
      "arxiv_id": "2410.01772v1",
      "title": "DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yebowen Hu",
        "Xiaoyang Wang",
        "Wenlin Yao",
        "Yiming Lu",
        "Daoan Zhang",
        "Hassan Foroosh",
        "Dong Yu",
        "Fei Liu"
      ],
      "abstract": "LLMs are ideal for decision-making due to their ability to reason over long\ncontexts and identify critical factors. However, challenges arise when\nprocessing transcripts of spoken speech describing complex scenarios. These\ntranscripts often contain ungrammatical or incomplete sentences, repetitions,\nhedging, and vagueness. For example, during a company's earnings call, an\nexecutive might project a positive revenue outlook to reassure investors,\ndespite significant uncertainty regarding future earnings. It is crucial for\nLLMs to incorporate this uncertainty systematically when making decisions. In\nthis paper, we introduce DeFine, a new framework that constructs probabilistic\nfactor profiles from complex scenarios. DeFine then integrates these profiles\nwith analogical reasoning, leveraging insights from similar past experiences to\nguide LLMs in making critical decisions in novel situations. Our framework\nseparates the tasks of quantifying uncertainty in complex scenarios and\nincorporating it into LLM decision-making. This approach is particularly useful\nin fields such as medical consultations, negotiations, and political debates,\nwhere making decisions under uncertainty is vital.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在决策过程中的优势与挑战，特别是处理复杂口头转录时面临的语法不完整、重复和不确定性问题，例如公司财报中潜在的收入不确定性。论文引入 DeFine 框架，该框架通过构建概率因子 profiles（probabilistic factor profiles）来量化场景中的不确定性，并将其与 analogical reasoning（类比推理）相结合，利用类似过去的经验指导 LLMs 在新情况下的决策。DeFine 将不确定性量化与决策整合分开，从而提升模型在医疗咨询、谈判和政治辩论等领域的可靠性和效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01772v1",
      "published_date": "2024-10-02 17:29:34 UTC",
      "updated_date": "2024-10-02 17:29:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:02:30.459936"
    },
    {
      "arxiv_id": "2410.01869v1",
      "title": "Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement",
      "title_zh": "翻译失败",
      "authors": [
        "Shouvon Sarker",
        "Xishuang Dong",
        "Xiangfang Li",
        "Lijun Qian"
      ],
      "abstract": "Text-to-SQLs enables non-expert users to effortlessly retrieve desired\ninformation from relational databases using natural language queries. While\nrecent advancements, particularly with Large Language Models (LLMs) like GPT\nand T5, have shown impressive performance on large-scale benchmarks such as\nBIRD, current state-of-the-art (SOTA) LLM-based Text-to-SQLs models often\nrequire significant efforts to develop auxiliary tools like SQL classifiers to\nachieve high performance. This paper proposed a novel approach that only needs\nSQL Quality Measurement to enhance LLMs-based Text-to-SQLs performance. It\nestablishes a SQL quality evaluation mechanism to assess the generated SQL\nqueries against predefined criteria and actual database responses. This\nfeedback loop enables continuous learning and refinement of model outputs based\non both syntactic correctness and semantic accuracy. The proposed method\nundergoes comprehensive validation on the BIRD benchmark, assessing Execution\nAccuracy (EX) and Valid Efficiency Score (VES) across various Text-to-SQLs\ndifficulty levels. Experimental results reveal competitive performance in both\nEX and VES compared to SOTA models like GPT4 and T5.",
      "tldr_zh": "本论文提出了一种新方法，通过 SQL Quality Measurement 来提升 Large Language Models (LLMs) 在 Text-to-SQLs 任务中的 Fine-tuning 效果，减少对辅助工具如 SQL 分类器的依赖。该方法建立了一个 SQL 质量评估机制，对生成的 SQL 查询进行语法正确性和语义准确性的评估，并利用反馈循环实现模型输出的持续优化。在 BIRD benchmark 的全面验证中，该方法在 Execution Accuracy (EX) 和 Valid Efficiency Score (VES) 上表现出与 SOTA 模型如 GPT4 和 T5 相当的竞争性能。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01869v1",
      "published_date": "2024-10-02 17:21:51 UTC",
      "updated_date": "2024-10-02 17:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:02:46.110915"
    },
    {
      "arxiv_id": "2410.01739v2",
      "title": "Mimicking Human Intuition: Cognitive Belief-Driven Q-Learning",
      "title_zh": "模仿人类直觉：认知信念驱动Q学习",
      "authors": [
        "Xingrui Gu",
        "Guanren Qiao",
        "Chuyi Jiang",
        "Tianqing Xia",
        "Hangyu Mao"
      ],
      "abstract": "Reinforcement learning encounters challenges in various environments related\nto robustness and explainability. Traditional Q-learning algorithms cannot\neffectively make decisions and utilize the historical learning experience. To\novercome these limitations, we propose Cognitive Belief-Driven Q-Learning\n(CBDQ), which integrates subjective belief modeling into the Q-learning\nframework, enhancing decision-making accuracy by endowing agents with\nhuman-like learning and reasoning capabilities. Drawing inspiration from\ncognitive science, our method maintains a subjective belief distribution over\nthe expectation of actions, leveraging a cluster-based subjective belief model\nthat enables agents to reason about the potential probability associated with\neach decision. CBDQ effectively mitigates overestimated phenomena and optimizes\ndecision-making policies by integrating historical experiences with current\ncontextual information, mimicking the dynamics of human decision-making. We\nevaluate the proposed method on discrete control benchmark tasks in various\ncomplicate environments. The results demonstrate that CBDQ exhibits stronger\nadaptability, robustness, and human-like characteristics in handling these\nenvironments, outperforming other baselines. We hope this work will give\nresearchers a fresh perspective on understanding and explaining Q-learning.",
      "tldr_zh": "本文提出 Cognitive Belief-Driven Q-Learning (CBDQ)，一种将主观信念建模整合到 Q-learning 框架中的方法，以解决强化学习在鲁棒性和可解释性方面的挑战。CBDQ 借鉴认知科学，使用基于聚类的主观信念模型，让代理模仿人类决策动态，通过整合历史经验和当前上下文减少过估计现象并优化决策策略。在各种复杂环境的离散控制基准任务上，实验结果显示 CBDQ 表现出更高的适应性、鲁棒性和人类特性，优于其他基线方法。该工作为理解和解释 Q-learning 提供了新颖视角。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01739v2",
      "published_date": "2024-10-02 16:50:29 UTC",
      "updated_date": "2024-10-03 23:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:02:55.154509"
    },
    {
      "arxiv_id": "2410.01738v2",
      "title": "VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models",
      "title_zh": "VitaGlyph：通过灵活双分支扩散模型活化艺术排印",
      "authors": [
        "Kailai Feng",
        "Yabo Zhang",
        "Haodong Yu",
        "Zhilong Ji",
        "Jinfeng Bai",
        "Hongzhi Zhang",
        "Wangmeng Zuo"
      ],
      "abstract": "Artistic typography is a technique to visualize the meaning of input\ncharacter in an imaginable and readable manner. With powerful text-to-image\ndiffusion models, existing methods directly design the overall geometry and\ntexture of input character, making it challenging to ensure both creativity and\nlegibility. In this paper, we introduce a dual-branch and training-free method,\nnamely VitaGlyph, enabling flexible artistic typography along with controllable\ngeometry change to maintain the readability. The key insight of VitaGlyph is to\ntreat input character as a scene composed of Subject and Surrounding, followed\nby rendering them under varying degrees of geometry transformation. The subject\nflexibly expresses the essential concept of input character, while the\nsurrounding enriches relevant background without altering the shape.\nSpecifically, we implement VitaGlyph through a three-phase framework: (i)\nKnowledge Acquisition leverages large language models to design text\ndescriptions of subject and surrounding. (ii) Regional decomposition detects\nthe part that most matches the subject description and divides input glyph\nimage into subject and surrounding regions. (iii) Typography Stylization\nfirstly refines the structure of subject region via Semantic Typography, and\nthen separately renders the textures of Subject and Surrounding regions through\nControllable Compositional Generation. Experimental results demonstrate that\nVitaGlyph not only achieves better artistry and readability, but also manages\nto depict multiple customize concepts, facilitating more creative and pleasing\nartistic typography generation. Our code will be made publicly at\nhttps://github.com/Carlofkl/VitaGlyph.",
      "tldr_zh": "本研究提出 VitaGlyph，一种双分支且无需训练的扩散模型方法，用于提升艺术排版（artistic typography）的创意性和可读性。VitaGlyph 将输入字符视为由 Subject 和 Surrounding 组成的场景，并通过几何变换灵活渲染 Subject 以表达核心概念，同时丰富 Surrounding 的背景而不改变整体形状。框架包括三个阶段：Knowledge Acquisition 使用大语言模型生成描述、Regional decomposition 分割字符区域，以及 Typography Stylization 通过 Semantic Typography 优化结构并进行可控纹理生成。实验结果显示，VitaGlyph 不仅在艺术性和可读性上优于现有方法，还能描绘多个自定义概念，促进更具创意的排版生成。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "https://github.com/Carlofkl/VitaGlyph",
      "pdf_url": "http://arxiv.org/pdf/2410.01738v2",
      "published_date": "2024-10-02 16:48:47 UTC",
      "updated_date": "2024-11-25 09:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:03:06.717712"
    },
    {
      "arxiv_id": "2410.01729v1",
      "title": "Evaluating Robustness of Reward Models for Mathematical Reasoning",
      "title_zh": "评估奖励模型在数学推理中的鲁棒性",
      "authors": [
        "Sunghwan Kim",
        "Dongjin Kang",
        "Taeyoon Kwon",
        "Hyungjoo Chae",
        "Jungsoo Won",
        "Dongha Lee",
        "Jinyoung Yeo"
      ],
      "abstract": "Reward models are key in reinforcement learning from human feedback (RLHF)\nsystems, aligning the model behavior with human preferences. Particularly in\nthe math domain, there have been plenty of studies using reward models to align\npolicies for improving reasoning capabilities. Recently, as the importance of\nreward models has been emphasized, RewardBench is proposed to understand their\nbehavior. However, we figure out that the math subset of RewardBench has\ndifferent representations between chosen and rejected completions, and relies\non a single comparison, which may lead to unreliable results as it only see an\nisolated case. Therefore, it fails to accurately present the robustness of\nreward models, leading to a misunderstanding of its performance and potentially\nresulting in reward hacking. In this work, we introduce a new design for\nreliable evaluation of reward models, and to validate this, we construct\nRewardMATH, a benchmark that effectively represents the robustness of reward\nmodels in mathematical reasoning tasks. We demonstrate that the scores on\nRewardMATH strongly correlate with the results of optimized policy and\neffectively estimate reward overoptimization, whereas the existing benchmark\nshows almost no correlation. The results underscore the potential of our design\nto enhance the reliability of evaluation, and represent the robustness of\nreward model. We make our code and data publicly available.",
      "tldr_zh": "这篇论文评估了奖励模型（Reward Models）在数学推理任务中的鲁棒性，指出现有基准如 RewardBench 存在问题，包括 chosen 和 rejected 完成表示差异及单一比较导致的不可靠结果，可能引发奖励篡改（Reward Hacking）。作者引入了一种新设计，并构建了 RewardMATH 基准，用于更准确地评估奖励模型的鲁棒性。实验显示，RewardMATH 的分数与优化策略结果高度相关，能有效估计奖励过度优化（Reward Overoptimization），而现有基准几乎无相关性。作者公开了代码和数据，以提升评估的可靠性和可重复性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2410.01729v1",
      "published_date": "2024-10-02 16:39:58 UTC",
      "updated_date": "2024-10-02 16:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:03:21.703566"
    },
    {
      "arxiv_id": "2410.03769v2",
      "title": "SciSafeEval: A Comprehensive Benchmark for Safety Alignment of Large Language Models in Scientific Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Tianhao Li",
        "Jingyu Lu",
        "Chuangxin Chu",
        "Tianyu Zeng",
        "Yujia Zheng",
        "Mei Li",
        "Haotian Huang",
        "Bin Wu",
        "Zuoxian Liu",
        "Kai Ma",
        "Xuejing Yuan",
        "Xingkai Wang",
        "Keyan Ding",
        "Huajun Chen",
        "Qiang Zhang"
      ],
      "abstract": "Large language models (LLMs) have a transformative impact on a variety of\nscientific tasks across disciplines including biology, chemistry, medicine, and\nphysics. However, ensuring the safety alignment of these models in scientific\nresearch remains an underexplored area, with existing benchmarks primarily\nfocusing on textual content and overlooking key scientific representations such\nas molecular, protein, and genomic languages. Moreover, the safety mechanisms\nof LLMs in scientific tasks are insufficiently studied. To address these\nlimitations, we introduce SciSafeEval, a comprehensive benchmark designed to\nevaluate the safety alignment of LLMs across a range of scientific tasks.\nSciSafeEval spans multiple scientific languages-including textual, molecular,\nprotein, and genomic-and covers a wide range of scientific domains. We evaluate\nLLMs in zero-shot, few-shot and chain-of-thought settings, and introduce a\n\"jailbreak\" enhancement feature that challenges LLMs equipped with safety\nguardrails, rigorously testing their defenses against malicious intention. Our\nbenchmark surpasses existing safety datasets in both scale and scope, providing\na robust platform for assessing the safety and performance of LLMs in\nscientific contexts. This work aims to facilitate the responsible development\nand deployment of LLMs, promoting alignment with safety and ethical standards\nin scientific research.",
      "tldr_zh": "本研究引入 SciSafeEval，这是一个全面基准，用于评估 Large Language Models (LLMs) 在科学任务中的安全对齐，解决现有基准忽略分子、蛋白质和基因组等科学表示的问题。SciSafeEval 覆盖文本、分子、蛋白质和基因组等多种科学语言，并涉及生物、化学、医学和物理等领域。评估包括 zero-shot、few-shot 和 chain-of-thought 设置，并添加“jailbreak”增强功能来测试模型对恶意意图的防御。该基准在规模和范围上超越现有安全数据集，促进 LLMs 的负责任开发，确保其符合科学研究的伦理和安全标准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03769v2",
      "published_date": "2024-10-02 16:34:48 UTC",
      "updated_date": "2024-12-16 12:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:03:30.809552"
    },
    {
      "arxiv_id": "2410.01724v1",
      "title": "Auto-Demo Prompting: Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting",
      "title_zh": "Auto",
      "authors": [
        "Longyu Feng",
        "Mengze Hong",
        "Chen Jason Zhang"
      ],
      "abstract": "Batch prompting is a common technique in large language models (LLMs) used to\nprocess multiple inputs simultaneously, aiming to improve computational\nefficiency. However, as batch sizes increase, performance degradation often\noccurs due to the model's difficulty in handling lengthy context inputs.\nExisting methods that attempt to mitigate these issues rely solely on batch\ndata arrangement and majority voting rather than improving the design of the\nbatch prompt itself. In this paper, we address these limitations by proposing\n\"Auto-Demo Prompting,\" a novel approach that leverages the question-output\npairs from earlier questions within a batch as demonstrations for subsequent\nanswer inference. We provide a formal theoretical analysis of how Auto-Demo\nPrompting functions within the autoregressive generation process of LLMs,\nillustrating how it utilizes prior outputs to optimize the model's internal\nrepresentations. Our method effectively bridges the gap between batch prompting\nand few-shot prompting, enhancing performance with only a slight compromise in\ntoken usage. Experimental results across five NLP tasks demonstrate its\neffectiveness in mitigating performance degradation and occasionally\noutperforming single prompts. Furthermore, it opens new avenues for applying\nfew-shot learning techniques, such as demonstration selection, within batch\nprompting, making it a robust solution for real-world applications.",
      "tldr_zh": "本论文提出 Auto-Demo Prompting 方法，以解决大型语言模型（LLMs）在批处理提示（Batch Prompting）中，随着批量增加而导致的性能下降问题。该方法利用批处理中早期问题的问答对作为后续回答的演示，从而优化模型的自回归生成过程，并在理论上分析了其如何提升内部表示。相比现有仅依赖数据安排的策略，Auto-Demo Prompting 有效桥接了批处理提示和少样本提示（Few-Shot Prompting），仅略微增加令牌使用。实验结果显示，在五个 NLP 任务上，该方法显著缓解了性能下降，并偶尔优于单提示，还为在批处理中应用演示选择等少样本技术开辟了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01724v1",
      "published_date": "2024-10-02 16:34:40 UTC",
      "updated_date": "2024-10-02 16:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:03:43.195417"
    },
    {
      "arxiv_id": "2410.12831v1",
      "title": "Segment as You Wish -- Free-Form Language-Based Segmentation for Medical Images",
      "title_zh": "随您所愿——基于自由形式语言的医疗图像分割",
      "authors": [
        "Longchao Da",
        "Rui Wang",
        "Xiaojian Xu",
        "Parminder Bhatia",
        "Taha Kass-Hout",
        "Hua Wei",
        "Cao Xiao"
      ],
      "abstract": "Medical imaging is crucial for diagnosing a patient's health condition, and\naccurate segmentation of these images is essential for isolating regions of\ninterest to ensure precise diagnosis and treatment planning. Existing methods\nprimarily rely on bounding boxes or point-based prompts, while few have\nexplored text-related prompts, despite clinicians often describing their\nobservations and instructions in natural language. To address this gap, we\nfirst propose a RAG-based free-form text prompt generator, that leverages the\ndomain corpus to generate diverse and realistic descriptions. Then, we\nintroduce FLanS, a novel medical image segmentation model that handles various\nfree-form text prompts, including professional anatomy-informed queries,\nanatomy-agnostic position-driven queries, and anatomy-agnostic size-driven\nqueries. Additionally, our model also incorporates a symmetry-aware\ncanonicalization module to ensure consistent, accurate segmentations across\nvarying scan orientations and reduce confusion between the anatomical position\nof an organ and its appearance in the scan. FLanS is trained on a large-scale\ndataset of over 100k medical images from 7 public datasets. Comprehensive\nexperiments demonstrate the model's superior language understanding and\nsegmentation precision, along with a deep comprehension of the relationship\nbetween them, outperforming SOTA baselines on both in-domain and out-of-domain\ndatasets.",
      "tldr_zh": "该研究针对医疗图像分割的局限性，提出了一种基于 RAG 的自由形式文本提示生成器，利用领域语料生成多样化的自然语言描述，以更好地适应临床医生的观察和指令。接着，引入 FLanS 模型，一种新型医疗图像分割框架，能够处理各种文本查询（如专业解剖信息查询、位置驱动或大小驱动查询），并通过 symmetry-aware canonicalization module 确保在不同扫描方向上的准确性和一致性。FLanS 在超过 10 万张图像的7个公共数据集上训练，实验结果显示其在语言理解和分割精度上优于 SOTA 基线，在域内和域外数据集上均表现出色。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12831v1",
      "published_date": "2024-10-02 16:34:32 UTC",
      "updated_date": "2024-10-02 16:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:03:56.267275"
    },
    {
      "arxiv_id": "2410.01720v3",
      "title": "Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Gan",
        "Yong Liu"
      ],
      "abstract": "Synthetic data has become a pivotal resource in post-training tasks for large\nlanguage models (LLMs) due to the scarcity of high-quality, specific data.\nWhile various methods have been developed to generate synthetic data, there\nremains a discernible gap between the practical effects of synthetic data and\nour theoretical comprehension. To address this challenge, we commence by\npresenting a detailed modeling of the prevalent synthetic data generation\nprocess. Building upon this modeling, we demonstrate that the generalization\ncapability of the post-trained model is critically determined by the\ninformation gain derived from the generative model, as analyzed from a novel\nreverse-bottleneck perspective. Moreover, we introduce the concept of\nGeneralization Gain via Mutual Information (GGMI) and elucidate the\nrelationship between generalization gain and information gain. This analysis\nserves as a theoretical foundation for synthetic data generation and further\nhighlights its connection with the generalization capability of post-trained\nmodels, offering an understanding about the design of synthetic data generation\ntechniques and the optimization of the post-training process. We open-source\nour code at\nhttps://github.com/ZyGan1999/Towards-a-Theoretical-Understanding-of-Synthetic-Data-in-LLM-Post-Training.",
      "tldr_zh": "这篇论文探讨了合成数据在大型语言模型(LLMs)后训练中的理论基础，从逆瓶颈视角分析其生成过程和影响。作者通过详细建模合成数据生成机制，证明了后训练模型的泛化能力主要取决于从生成模型获得的信息增益。论文引入了通过互信息的泛化增益(GGMI)概念，阐明了泛化增益与信息增益之间的关系，为优化合成数据生成技术和后训练过程提供了理论指导。该研究还开源了相关代码，以促进进一步应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01720v3",
      "published_date": "2024-10-02 16:32:05 UTC",
      "updated_date": "2025-02-06 06:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:04:07.483744"
    },
    {
      "arxiv_id": "2410.01707v3",
      "title": "Interpretable Contrastive Monte Carlo Tree Search Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zitian Gao",
        "Boye Niu",
        "Xuzheng He",
        "Haotian Xu",
        "Hongzhang Liu",
        "Aiwei Liu",
        "Xuming Hu",
        "Lijie Wen"
      ],
      "abstract": "We propose SC-MCTS*: a novel Monte Carlo Tree Search (MCTS) reasoning\nalgorithm for Large Language Models (LLMs), significantly improves both\nreasoning accuracy and speed. Our motivation comes from: 1. Previous MCTS LLM\nreasoning works often overlooked its biggest drawback--slower speed compared to\nCoT; 2. Previous research mainly used MCTS as a tool for LLM reasoning on\nvarious tasks with limited quantitative analysis or ablation studies of its\ncomponents from reasoning interpretability perspective. 3. The reward model is\nthe most crucial component in MCTS, however previous work has rarely conducted\nin-depth study or improvement of MCTS's reward models. Thus, we conducted\nextensive ablation studies and quantitative analysis on components of MCTS,\nrevealing the impact of each component on the MCTS reasoning performance of\nLLMs. Building on this, (i) we designed a highly interpretable reward model\nbased on the principle of contrastive decoding and (ii) achieved an average\nspeed improvement of 51.9% per node using speculative decoding. Additionally,\n(iii) we improved UCT node selection strategy and backpropagation used in\nprevious works, resulting in significant performance improvement. We\noutperformed o1-mini by an average of 17.4% on the Blocksworld multi-step\nreasoning dataset using Llama-3.1-70B with SC-MCTS*. Our code is available at\nhttps://github.com/zitian-gao/SC-MCTS.",
      "tldr_zh": "本文提出 SC-MCTS*，一种新型的 Monte Carlo Tree Search (MCTS) 推理算法，旨在提升 Large Language Models (LLMs) 的推理准确性和速度，针对以往 MCTS 方法的缺点如速度慢于 Chain-of-Thought (CoT) 和缺乏组件分析进行优化。研究通过广泛的消融研究和定量分析，设计了基于 Contrastive Decoding 的高度可解释奖励模型，并通过 Speculative Decoding 实现了每个节点的平均速度提升 51.9%，同时改进了 UCT 节点选择策略和回传策略。实验结果显示，使用 Llama-3.1-70B 模型的 SC-MCTS* 在 Blocksworld 多步推理数据集上比 o1-mini 平均提高了 17.4% 的性能，为可解释的 LLM 推理提供了新框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01707v3",
      "published_date": "2024-10-02 16:15:31 UTC",
      "updated_date": "2024-12-25 13:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:04:20.782844"
    },
    {
      "arxiv_id": "2410.01706v4",
      "title": "Sable: a Performant, Efficient and Scalable Sequence Model for MARL",
      "title_zh": "翻译失败",
      "authors": [
        "Omayma Mahjoub",
        "Sasha Abramowitz",
        "Ruan de Kock",
        "Wiem Khlifi",
        "Simon du Toit",
        "Jemma Daniel",
        "Louay Ben Nessir",
        "Louise Beyers",
        "Claude Formanek",
        "Liam Clark",
        "Arnu Pretorius"
      ],
      "abstract": "As multi-agent reinforcement learning (MARL) progresses towards solving\nlarger and more complex problems, it becomes increasingly important that\nalgorithms exhibit the key properties of (1) strong performance, (2) memory\nefficiency and (3) scalability. In this work, we introduce Sable, a performant,\nmemory efficient and scalable sequence modeling approach to MARL. Sable works\nby adapting the retention mechanism in Retentive Networks (Sun et al., 2023) to\nachieve computationally efficient processing of multi-agent observations with\nlong context memory for temporal reasoning. Through extensive evaluations\nacross six diverse environments, we demonstrate how Sable is able to\nsignificantly outperform existing state-of-the-art methods in a large number of\ndiverse tasks (34 out of 45 tested). Furthermore, Sable maintains performance\nas we scale the number of agents, handling environments with more than a\nthousand agents while exhibiting a linear increase in memory usage. Finally, we\nconduct ablation studies to isolate the source of Sable's performance gains and\nconfirm its efficient computational memory usage.",
      "tldr_zh": "该论文引入了 Sable，一种高效、可扩展的序列模型，用于多智能体强化学习 (MARL)，旨在实现强性能、内存效率和可扩展性。Sable 通过改编 Retentive Networks 中的保留机制，处理多智能体观察并支持长上下文记忆以进行时间推理。实验在六个多样化环境中评估，Sable 在 45 个任务中胜出 34 个，显著优于现有方法，同时在扩展到超过一千个智能体时，内存使用仅线性增加。消融研究进一步证实了 Sable 性能提升的核心来源及其高效计算内存使用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01706v4",
      "published_date": "2024-10-02 16:15:26 UTC",
      "updated_date": "2025-03-17 18:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:04:32.139556"
    },
    {
      "arxiv_id": "2410.01696v1",
      "title": "CreDes: Causal Reasoning Enhancement and Dual-End Searching for Solving Long-Range Reasoning Problems using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Kangsheng Wang",
        "Xiao Zhang",
        "Hao Liu",
        "Songde Han",
        "Huimin Ma",
        "Tianyu Hu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated limitations in handling\ncombinatorial optimization problems involving long-range reasoning, partially\ndue to causal hallucinations and huge search space. As for causal\nhallucinations, i.e., the inconsistency between reasoning and corresponding\nstate transition, this paper introduces the Causal Relationship Enhancement\n(CRE) mechanism combining cause-effect interventions and the Individual\nTreatment Effect (ITE) to guarantee the solid causal rightness between each\nstep of reasoning and state transition. As for the long causal range and huge\nsearch space limiting the performances of existing models featuring\nsingle-direction search, a Dual-End Searching (DES) approach is proposed to\nseek solutions by simultaneously starting from both the initial and goal states\non the causal probability tree. By integrating CRE and DES (CreDes), our model\nhas realized simultaneous multi-step reasoning, circumventing the\ninefficiencies from cascading multiple one-step reasoning like the\nChain-of-Thought (CoT). Experiments demonstrate that CreDes significantly\noutperforms existing State-Of-The-Art (SOTA) solutions in long-range reasoning\ntasks in terms of both accuracy and time efficiency.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）在处理长程推理的组合优化问题时面临的因果幻觉和巨大搜索空间问题，提出了 CreDes 框架。CreDes 包括 Causal Relationship Enhancement (CRE) 机制，通过 cause-effect interventions 和 Individual Treatment Effect (ITE) 确保推理步骤与状态转换的因果正确性；同时引入 Dual-End Searching (DES) 方法，从初始状态和目标状态双向搜索因果概率树，以提高效率。相比传统的 Chain-of-Thought (CoT) 方法，CreDes 实现了同时多步推理，并在实验中显著优于现有 State-Of-The-Art (SOTA) 解决方案，在准确性和时间效率方面表现出色。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01696v1",
      "published_date": "2024-10-02 16:05:01 UTC",
      "updated_date": "2024-10-02 16:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:04:44.102730"
    },
    {
      "arxiv_id": "2410.01695v3",
      "title": "From Prohibition to Adoption: How Hong Kong Universities Are Navigating ChatGPT in Academic Workflows",
      "title_zh": "翻译失败",
      "authors": [
        "Junjun Huang",
        "Jifan Wu",
        "Qing Wang",
        "Kemeng Yuan",
        "Jiefeng Li",
        "Di Lu"
      ],
      "abstract": "This paper aims at comparing the time when Hong Kong universities used to ban\nChatGPT to the current periods where it has become integrated in the academic\nprocesses. Bolted by concerns of integrity and ethical issues in technologies,\ninstitutions have adapted by moving towards the center adopting AI literacy and\nresponsibility policies. This study examines new paradigms which have been\ndeveloped to help implement these positives while preventing negative effects\non academia. Keywords: ChatGPT, Academic Integrity, AI Literacy, Ethical AI\nUse, Generative AI in Education, University Policy, AI Integration in Academia,\nHigher Education and Technology",
      "tldr_zh": "这篇论文探讨了香港大学从禁止ChatGPT到将其整合进学术工作流程的转变过程，起初由于Academic Integrity和Ethical AI Use等诚信及伦理问题的担忧而实施禁令。研究分析了机构如何通过采用AI Literacy和责任政策来适应这一变化，发展出新的范式以发挥Generative AI in Education的积极作用，同时防范负面影响。最终，该研究为Higher Education and Technology的AI Integration提供政策指导，强调平衡创新与风险的管理策略。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01695v3",
      "published_date": "2024-10-02 16:04:33 UTC",
      "updated_date": "2024-10-20 09:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:04:54.150302"
    },
    {
      "arxiv_id": "2410.01692v2",
      "title": "U-shaped and Inverted-U Scaling behind Emergent Abilities of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tung-Yu Wu",
        "Pei-Yu Lo"
      ],
      "abstract": "Large language models (LLMs) have been shown to exhibit emergent abilities in\nsome downstream tasks, where model performance stagnates at first and then\nimproves sharply and unpredictably with scale beyond a threshold. In this work,\nwe investigate the phenomenon by grouping questions based on difficulty level\nand provide a possible explanation for emergent abilities. Specifically, we\nobserve U-shaped scaling for hard questions and inverted-U scaling followed by\nsteady improvement for easy questions. The two scaling patterns initially\noffset each other, causing stagnant overall performance. The performance starts\nto soar when the scaling pattern of easy questions reverts from inverse to\nstandard scaling, leading to emergent abilities. Based on this finding, we\npropose a simple yet effective pipeline, called Slice-and-Sandwich, to predict\nthe emergence threshold and model performance beyond the threshold. Our code is\npublicly available at https://github.com/tony10101105/ExpEmergence.",
      "tldr_zh": "本研究探讨了大语言模型 (Large Language Models) 在下游任务中的紧急能力 (emergent abilities)，发现模型性能在规模增加时会先停滞，然后急剧改善。研究通过按问题难度分组，观察到困难问题呈现 U-shaped scaling（先下降后上升），而简单问题则显示 inverted-U scaling 后稳定改善，这两种模式最初相互抵消导致整体停滞。最终，当简单问题的缩放模式转为标准上升时，性能开始爆发。基于这一发现，作者提出了一种简单有效的管道 Slice-and-Sandwich，用于预测紧急阈值和模型性能，并公开了相关代码。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01692v2",
      "published_date": "2024-10-02 16:03:49 UTC",
      "updated_date": "2025-02-12 13:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:05:07.548559"
    },
    {
      "arxiv_id": "2410.01691v1",
      "title": "FactAlign: Long-form Factuality Alignment of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chao-Wei Huang",
        "Yun-Nung Chen"
      ],
      "abstract": "Large language models have demonstrated significant potential as the\nnext-generation information access engines. However, their reliability is\nhindered by issues of hallucination and generating non-factual content. This is\nparticularly problematic in long-form responses, where assessing and ensuring\nfactual accuracy is complex. In this paper, we address this gap by proposing\nFactAlign, a novel alignment framework designed to enhance the factuality of\nLLMs' long-form responses while maintaining their helpfulness. We introduce\nfKTO, a fine-grained, sentence-level alignment algorithm that extends the\nKahneman-Tversky Optimization (KTO) alignment method. Leveraging recent\nadvances in automatic factuality evaluation, FactAlign utilizes fine-grained\nfactuality assessments to guide the alignment process. Our experiments on\nopen-domain prompts and information-seeking questions demonstrate that\nFactAlign significantly improves the factual accuracy of LLM responses while\nalso improving their helpfulness. Further analyses identify that FactAlign is\ncapable of training LLMs to provide more information without losing factual\nprecision, thus improving the factual F1 score. Our source code, datasets, and\ntrained models are publicly available at https://github.com/MiuLab/FactAlign",
      "tldr_zh": "该研究提出 FactAlign，一种新型对齐框架，旨在提升大型语言模型(LLMs)长形式响应的真实性，同时保持其帮助性，以解决幻觉和非事实内容问题。\nFactAlign 引入 fKTO 算法，这是一种细粒度的句子级对齐方法，扩展了 Kahneman-Tversky Optimization (KTO)，并利用自动事实性评估来指导训练过程。\n实验结果显示，在开放域提示和信息寻求问题上，FactAlign 显著提高了 LLMs 的事实准确性、帮助性和事实 F1 分数，同时支持提供更多信息而不损失精度。开源代码、数据集和模型可从 GitHub 获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.01691v1",
      "published_date": "2024-10-02 16:03:13 UTC",
      "updated_date": "2024-10-02 16:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:05:19.552739"
    },
    {
      "arxiv_id": "2410.01690v1",
      "title": "Why context matters in VQA and Reasoning: Semantic interventions for VLM input modalities",
      "title_zh": "为什么上下文在 VQA 和推理中很重要：针对 VLM 输入模态的语义干预",
      "authors": [
        "Kenza Amara",
        "Lukas Klein",
        "Carsten Lüth",
        "Paul Jäger",
        "Hendrik Strobelt",
        "Mennatallah El-Assady"
      ],
      "abstract": "The various limitations of Generative AI, such as hallucinations and model\nfailures, have made it crucial to understand the role of different modalities\nin Visual Language Model (VLM) predictions. Our work investigates how the\nintegration of information from image and text modalities influences the\nperformance and behavior of VLMs in visual question answering (VQA) and\nreasoning tasks. We measure this effect through answer accuracy, reasoning\nquality, model uncertainty, and modality relevance. We study the interplay\nbetween text and image modalities in different configurations where visual\ncontent is essential for solving the VQA task. Our contributions include (1)\nthe Semantic Interventions (SI)-VQA dataset, (2) a benchmark study of various\nVLM architectures under different modality configurations, and (3) the\nInteractive Semantic Interventions (ISI) tool. The SI-VQA dataset serves as the\nfoundation for the benchmark, while the ISI tool provides an interface to test\nand apply semantic interventions in image and text inputs, enabling more\nfine-grained analysis. Our results show that complementary information between\nmodalities improves answer and reasoning quality, while contradictory\ninformation harms model performance and confidence. Image text annotations have\nminimal impact on accuracy and uncertainty, slightly increasing image\nrelevance. Attention analysis confirms the dominant role of image inputs over\ntext in VQA tasks. In this study, we evaluate state-of-the-art VLMs that allow\nus to extract attention coefficients for each modality. A key finding is\nPaliGemma's harmful overconfidence, which poses a higher risk of silent\nfailures compared to the LLaVA models. This work sets the foundation for\nrigorous analysis of modality integration, supported by datasets specifically\ndesigned for this purpose.",
      "tldr_zh": "本文研究了图像和文本模态在视觉语言模型(VLM)上的整合如何影响视觉问答(VQA)和推理任务的性能，包括答案准确性、推理质量、模型不确定性和模态相关性。主要贡献包括构建Semantic Interventions (SI)-VQA数据集、基准测试各种VLM架构以及开发Interactive Semantic Interventions (ISI)工具，以分析模态互动。结果表明，模态间互补信息提升答案和推理质量，而矛盾信息会损害模型性能和信心；注意力分析显示图像输入在VQA中占主导作用，且PaliGemma模型的overconfidence可能导致更高风险的silent failures。该工作为模态整合的严格分析提供了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01690v1",
      "published_date": "2024-10-02 16:02:02 UTC",
      "updated_date": "2024-10-02 16:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:05:32.148707"
    },
    {
      "arxiv_id": "2410.01687v2",
      "title": "Uncertainty Quantification with Bayesian Higher Order ReLU KANs",
      "title_zh": "翻译失败",
      "authors": [
        "James Giroux",
        "Cristiano Fanelli"
      ],
      "abstract": "We introduce the first method of uncertainty quantification in the domain of\nKolmogorov-Arnold Networks, specifically focusing on (Higher Order) ReLUKANs to\nenhance computational efficiency given the computational demands of Bayesian\nmethods. The method we propose is general in nature, providing access to both\nepistemic and aleatoric uncertainties. It is also capable of generalization to\nother various basis functions. We validate our method through a series of\nclosure tests, including simple one-dimensional functions and application to\nthe domain of (Stochastic) Partial Differential Equations. Referring to the\nlatter, we demonstrate the method's ability to correctly identify functional\ndependencies introduced through the inclusion of a stochastic term. The code\nsupporting this work can be found at\nhttps://github.com/wmdataphys/Bayesian-HR-KAN",
      "tldr_zh": "本研究提出了不确定性量化（Uncertainty Quantification）在 Kolmogorov-Arnold Networks（KANs）领域的首创方法，特别针对 Higher Order ReLU KANs，以提升 Bayesian 方法的计算效率。该方法通用，能够同时提供 epistemic 和 aleatoric 不确定性，并扩展适用于其他基函数。通过闭合测试验证，包括一维简单函数和 Stochastic Partial Differential Equations 应用，该方法成功识别随机项引入的功能依赖，为相关领域提供了可靠工具。代码可从 https://github.com/wmdataphys/Bayesian-HR-KAN 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.data-an"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01687v2",
      "published_date": "2024-10-02 15:57:18 UTC",
      "updated_date": "2024-10-03 02:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:05:42.824916"
    },
    {
      "arxiv_id": "2410.01686v2",
      "title": "Positional Attention: Expressivity and Learnability of Algorithmic Computation",
      "title_zh": "位置注意力：算法计算的表达性和可学习性",
      "authors": [
        "Artur Back de Luca",
        "George Giapitzakis",
        "Shenghao Yang",
        "Petar Veličković",
        "Kimon Fountoulakis"
      ],
      "abstract": "There is a growing interest in the ability of neural networks to execute\nalgorithmic tasks (e.g., arithmetic, summary statistics, and sorting). The goal\nof this work is to better understand the role of attention in Transformers for\nalgorithmic execution. Its importance for algorithmic execution has been\nstudied theoretically and empirically using parallel computational models.\nNotably, many parallel algorithms communicate between processors solely using\npositional information. Inspired by this observation, we investigate how\nTransformers can execute algorithms using positional attention, where attention\nweights depend exclusively on positional encodings. We prove that Transformers\nwith positional attention (positional Transformers) maintain the same\nexpressivity of parallel computational models, incurring a logarithmic depth\ncost relative to the input length. We analyze their in-distribution\nlearnability and explore how parameter norms in positional attention affect\nsample complexity. Our results show that positional Transformers introduce a\nlearning trade-off: while they exhibit better theoretical dependence on\nparameter norms, certain tasks may require more layers, which can, in turn,\nincrease sample complexity. Finally, we empirically explore the\nout-of-distribution performance of positional Transformers and find that they\nperform well in tasks where their underlying algorithmic solution relies on\npositional information.",
      "tldr_zh": "这篇论文探讨了 Transformer 中位置注意力(positional attention)在执行算法任务（如算术和排序）中的表达性(expressivity)和可学习性(learnability)。作者证明了使用位置注意力的 Transformer（positional Transformers）能保持与并行计算模型相同的表达性，但会引入对输入长度的对数深度成本，并分析了参数范数如何影响样本复杂度。研究发现，这种机制带来学习权衡：虽然在参数依赖上更高效，但某些任务可能需更多层从而增加样本复杂度。最后，实证结果显示，positional Transformers 在依赖位置信息的任务上表现出色，尤其在分布外场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "64 pages, 37 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01686v2",
      "published_date": "2024-10-02 15:55:08 UTC",
      "updated_date": "2025-02-01 04:14:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:05:56.182219"
    },
    {
      "arxiv_id": "2410.01680v1",
      "title": "PHI-S: Distribution Balancing for Label-Free Multi-Teacher Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Mike Ranzinger",
        "Jon Barker",
        "Greg Heinrich",
        "Pavlo Molchanov",
        "Bryan Catanzaro",
        "Andrew Tao"
      ],
      "abstract": "Various visual foundation models have distinct strengths and weaknesses, both\nof which can be improved through heterogeneous multi-teacher knowledge\ndistillation without labels, termed \"agglomerative models.\" We build upon this\nbody of work by studying the effect of the teachers' activation statistics,\nparticularly the impact of the loss function on the resulting student model\nquality. We explore a standard toolkit of statistical normalization techniques\nto better align the different distributions and assess their effects. Further,\nwe examine the impact on downstream teacher-matching metrics, which motivates\nthe use of Hadamard matrices. With these matrices, we demonstrate useful\nproperties, showing how they can be used for isotropic standardization, where\neach dimension of a multivariate distribution is standardized using the same\nscale. We call this technique \"PHI Standardization\" (PHI-S) and empirically\ndemonstrate that it produces the best student model across the suite of methods\nstudied.",
      "tldr_zh": "本论文探讨了无标签多教师知识蒸馏（multi-teacher distillation）中教师激活统计的影响，特别是损失函数对学生模型质量的作用。研究者通过统计归一化技术对齐不同分布，并评估其效果，同时引入Hadamard matrices进行各向同性标准化。最终，他们提出了PHI-S（PHI Standardization）技术，并在实验中证明它能产生最佳的学生模型表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01680v1",
      "published_date": "2024-10-02 15:50:35 UTC",
      "updated_date": "2024-10-02 15:50:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:06:07.517133"
    },
    {
      "arxiv_id": "2410.01677v3",
      "title": "Mind Scramble: Unveiling Large Language Model Psychology Via Typoglycemia",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Yu",
        "Junyuan Mao",
        "Guibin Zhang",
        "Jingheng Ye",
        "Junfeng Fang",
        "Aoxiao Zhong",
        "Yang Liu",
        "Yuxuan Liang",
        "Kun Wang",
        "Qingsong Wen"
      ],
      "abstract": "Research into the external behaviors and internal mechanisms of large\nlanguage models (LLMs) has shown promise in addressing complex tasks in the\nphysical world. Studies suggest that powerful LLMs, like GPT-4, are beginning\nto exhibit human-like cognitive abilities, including planning, reasoning, and\nreflection. In this paper, we introduce a research line and methodology called\nLLM Psychology, leveraging human psychology experiments to investigate the\ncognitive behaviors and mechanisms of LLMs. We migrate the Typoglycemia\nphenomenon from psychology to explore the \"mind\" of LLMs. Unlike human brains,\nwhich rely on context and word patterns to comprehend scrambled text, LLMs use\ndistinct encoding and decoding processes. Through Typoglycemia experiments at\nthe character, word, and sentence levels, we observe: (I) LLMs demonstrate\nhuman-like behaviors on a macro scale, such as lower task accuracy and higher\ntoken/time consumption; (II) LLMs exhibit varying robustness to scrambled\ninput, making Typoglycemia a benchmark for model evaluation without new\ndatasets; (III) Different task types have varying impacts, with complex logical\ntasks (e.g., math) being more challenging in scrambled form; (IV) Each LLM has\na unique and consistent \"cognitive pattern\" across tasks, revealing general\nmechanisms in its psychology process. We provide an in-depth analysis of hidden\nlayers to explain these phenomena, paving the way for future research in LLM\nPsychology and deeper interpretability.",
      "tldr_zh": "这篇论文引入了LLM Psychology方法，通过迁移人类心理学实验（如Typoglycemia现象）来探索大型语言模型(LLMs)的认知行为和内部机制。实验在字符、单词和句子级别测试Typoglycemia的影响，发现LLMs在处理乱序文本时表现出类似人类的宏观行为，包括任务准确率降低和处理时间增加，同时不同任务类型（如复杂逻辑任务）受影响程度不同。研究进一步揭示每个LLMs都有独特的一致“认知模式”，并通过隐藏层分析提供深入解释，为LLMs的评估和未来心理学研究奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01677v3",
      "published_date": "2024-10-02 15:47:25 UTC",
      "updated_date": "2024-10-24 02:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:06:20.787707"
    },
    {
      "arxiv_id": "2410.01675v1",
      "title": "Trying to be human: Linguistic traces of stochastic empathy in language models",
      "title_zh": "翻译失败",
      "authors": [
        "Bennett Kleinberg",
        "Jari Zegers",
        "Jonas Festor",
        "Stefana Vida",
        "Julian Präsent",
        "Riccardo Loconte",
        "Sanne Peereboom"
      ],
      "abstract": "Differentiating between generated and human-written content is important for\nnavigating the modern world. Large language models (LLMs) are crucial drivers\nbehind the increased quality of computer-generated content. Reportedly, humans\nfind it increasingly difficult to identify whether an AI model generated a\npiece of text. Our work tests how two important factors contribute to the human\nvs AI race: empathy and an incentive to appear human. We address both aspects\nin two experiments: human participants and a state-of-the-art LLM wrote\nrelationship advice (Study 1, n=530) or mere descriptions (Study 2, n=610),\neither instructed to be as human as possible or not. New samples of humans\n(n=428 and n=408) then judged the texts' source. Our findings show that when\nempathy is required, humans excel. Contrary to expectations, instructions to\nappear human were only effective for the LLM, so the human advantage\ndiminished. Computational text analysis revealed that LLMs become more human\nbecause they may have an implicit representation of what makes a text human and\neffortlessly apply these heuristics. The model resorts to a conversational,\nself-referential, informal tone with a simpler vocabulary to mimic stochastic\nempathy. We discuss these findings in light of recent claims on the on-par\nperformance of LLMs.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)如何通过语言特征模仿人类的随机移情(stochastic empathy)，以应对区分人类和AI生成内容的挑战。研究通过两个实验（涉及530和610名参与者生成关系建议或描述文本）测试了移情和“显得人性化”的指令对表现的影响，结果显示人类在需要移情的任务中更具优势，而LLMs在受指令时会采用对话式、自指涉、非正式语气和简单词汇来提升拟人性。计算文本分析揭示了LLMs可能依赖隐含的“人性化”启发式策略，这些发现质疑了LLMs性能与人类相当的说法，并为AI评估提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.01675v1",
      "published_date": "2024-10-02 15:46:40 UTC",
      "updated_date": "2024-10-02 15:46:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:06:32.891804"
    },
    {
      "arxiv_id": "2410.01671v2",
      "title": "Bridging Context Gaps: Leveraging Coreference Resolution for Long Contextual Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Jiannan Cao",
        "Shi Bo",
        "Yanxin Shen",
        "Tianyu Du",
        "Sheng Cheng",
        "Xun Wang",
        "Jianwei Yin",
        "Xuhong Zhang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in natural\nlanguage processing; however, they still face difficulties when tasked with\nunderstanding lengthy contexts and executing effective question answering.\nThese challenges often arise due to the complexity and ambiguity present in\nlonger texts. To enhance the performance of LLMs in such scenarios, we\nintroduce the Long Question Coreference Adaptation (LQCA) method. This\ninnovative framework focuses on coreference resolution tailored to long\ncontexts, allowing the model to identify and manage references effectively. The\nLQCA method encompasses four key steps: resolving coreferences within\nsub-documents, computing the distances between mentions, defining a\nrepresentative mention for coreference, and answering questions through mention\nreplacement. By processing information systematically, the framework provides\neasier-to-handle partitions for LLMs, promoting better understanding.\nExperimental evaluations on a range of LLMs and datasets have yielded positive\nresults, with a notable improvements on OpenAI-o1-mini and GPT-4o models,\nhighlighting the effectiveness of leveraging coreference resolution to bridge\ncontext gaps in question answering. Our code is public at\nhttps://github.com/OceannTwT/LQCA.",
      "tldr_zh": "大型语言模型（LLMs）在处理长上下文和问答时常面临复杂性和歧义挑战，为此，本文提出Long Question Coreference Adaptation (LQCA) 方法，通过核心ference resolution（coreference resolution）来桥接上下文差距。LQCA 框架包括四个关键步骤：解析子文档中的核心ference、计算mentions之间的距离、定义代表性mention，以及通过mention替换进行问答，从而使LLMs 更容易处理信息分区。实验结果显示，该方法显著提升了OpenAI-o1-mini和GPT-4o等模型的表现，代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 camera ready version, with updated metadata",
      "pdf_url": "http://arxiv.org/pdf/2410.01671v2",
      "published_date": "2024-10-02 15:39:55 UTC",
      "updated_date": "2025-02-28 07:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:06:42.881229"
    },
    {
      "arxiv_id": "2410.03767v2",
      "title": "Reasoning Elicitation in Language Models via Counterfactual Feedback",
      "title_zh": "通过反事实反馈激发语言模型的推理",
      "authors": [
        "Alihan Hüyük",
        "Xinnuo Xu",
        "Jacqueline Maasch",
        "Aditya V. Nori",
        "Javier González"
      ],
      "abstract": "Despite the increasing effectiveness of language models, their reasoning\ncapabilities remain underdeveloped. In particular, causal reasoning through\ncounterfactual question answering is lacking. This work aims to bridge this\ngap. We first derive novel metrics that balance accuracy in factual and\ncounterfactual questions, capturing a more complete view of the reasoning\nabilities of language models than traditional factual-only based metrics.\nSecond, we propose several fine-tuning approaches that aim to elicit better\nreasoning mechanisms, in the sense of the proposed metrics. Finally, we\nevaluate the performance of the fine-tuned language models in a variety of\nrealistic scenarios. In particular, we investigate to what extent our\nfine-tuning approaches systemically achieve better generalization with respect\nto the base models in several problems that require, among others, inductive\nand deductive reasoning capabilities.",
      "tldr_zh": "该研究针对语言模型的推理能力不足，特别是反事实问题回答（counterfactual question answering）的缺失，提出了一种通过反事实反馈（Counterfactual Feedback）来提升推理机制的方法。首先，作者开发了新的指标，这些指标平衡了事实性和反事实性问题的准确性，提供比传统基于事实的指标更全面的评估。其次，提出几种微调（fine-tuning）方法，以激发模型在归纳和演绎推理（inductive and deductive reasoning）等场景中的性能。实验结果显示，这些方法显著提高了语言模型（language models）的泛化能力，在各种现实问题上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "The 13th International Conference on Learning Representations (ICLR\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.03767v2",
      "published_date": "2024-10-02 15:33:30 UTC",
      "updated_date": "2025-03-15 18:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:06:54.873234"
    },
    {
      "arxiv_id": "2410.01665v2",
      "title": "Towards a vision foundation model for comprehensive assessment of Cardiac MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Athira J Jacob",
        "Indraneel Borgohain",
        "Teodora Chitiboi",
        "Puneet Sharma",
        "Dorin Comaniciu",
        "Daniel Rueckert"
      ],
      "abstract": "Cardiac magnetic resonance imaging (CMR), considered the gold standard for\nnoninvasive cardiac assessment, is a diverse and complex modality requiring a\nwide variety of image processing tasks for comprehensive assessment of cardiac\nmorphology and function. Advances in deep learning have enabled the development\nof state-of-the-art (SoTA) models for these tasks. However, model training is\nchallenging due to data and label scarcity, especially in the less common\nimaging sequences. Moreover, each model is often trained for a specific task,\nwith no connection between related tasks. In this work, we introduce a vision\nfoundation model trained for CMR assessment, that is trained in a\nself-supervised fashion on 36 million CMR images. We then finetune the model in\nsupervised way for 9 clinical tasks typical to a CMR workflow, across\nclassification, segmentation, landmark localization, and pathology detection.\nWe demonstrate improved accuracy and robustness across all tasks, over a range\nof available labeled dataset sizes. We also demonstrate improved few-shot\nlearning with fewer labeled samples, a common challenge in medical image\nanalyses. We achieve an out-of-box performance comparable to SoTA for most\nclinical tasks. The proposed method thus presents a resource-efficient, unified\nframework for CMR assessment, with the potential to accelerate the development\nof deep learning-based solutions for image analysis tasks, even with few\nannotated data available.",
      "tldr_zh": "本文提出了一种视觉基础模型，用于全面评估心脏磁共振成像(CMR)，以解决数据和标签稀缺问题。该模型首先通过自监督方式在3600万CMR图像上训练，然后监督微调应用于9个临床任务，包括分类、分割、landmark localization和病理检测。实验结果显示，该模型在不同标注数据规模下实现了更高的准确性和鲁棒性，尤其在少样本学习中表现出色，与state-of-the-art (SoTA) 模型相当。该方法提供了一个资源高效的统一框架，有潜力加速深度学习在医疗图像分析任务中的发展，即使标注数据有限。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 3 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.01665v2",
      "published_date": "2024-10-02 15:32:01 UTC",
      "updated_date": "2024-10-06 22:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:07:08.896680"
    },
    {
      "arxiv_id": "2410.01661v2",
      "title": "Finding path and cycle counting formulae in graphs with Deep Reinforcement Learning",
      "title_zh": "使用深度强化学习在图中发现路径和循环计数公式",
      "authors": [
        "Jason Piquenot",
        "Maxime Bérar",
        "Pierre Héroux",
        "Jean-Yves Ramel",
        "Romain Raveaux",
        "Sébastien Adam"
      ],
      "abstract": "This paper presents Grammar Reinforcement Learning (GRL), a reinforcement\nlearning algorithm that uses Monte Carlo Tree Search (MCTS) and a transformer\narchitecture that models a Pushdown Automaton (PDA) within a context-free\ngrammar (CFG) framework. Taking as use case the problem of efficiently counting\npaths and cycles in graphs, a key challenge in network analysis, computer\nscience, biology, and social sciences, GRL discovers new matrix-based formulas\nfor path/cycle counting that improve computational efficiency by factors of two\nto six w.r.t state-of-the-art approaches. Our contributions include: (i) a\nframework for generating gramformers that operate within a CFG, (ii) the\ndevelopment of GRL for optimizing formulas within grammatical structures, and\n(iii) the discovery of novel formulas for graph substructure counting, leading\nto significant computational improvements.",
      "tldr_zh": "本论文提出 Grammar Reinforcement Learning (GRL) 算法，该算法结合 Monte Carlo Tree Search (MCTS) 和 Transformer 架构，在 Context-Free Grammar (CFG) 框架内模拟 Pushdown Automaton (PDA)，用于高效计数图中的路径和循环。\nGRL 通过优化公式结构，发现了新的矩阵-based 公式，使计算效率比现有方法提高 2 到 6 倍。\n主要贡献包括：(i) 开发 gramformers 生成框架，(ii) 优化文法中的公式，以及 (iii) 发现新型图子结构计数公式，推动了网络分析等领域的研究。",
      "categories": [
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01661v2",
      "published_date": "2024-10-02 15:29:42 UTC",
      "updated_date": "2025-01-23 09:09:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:07:19.636711"
    },
    {
      "arxiv_id": "2410.01660v2",
      "title": "Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering",
      "title_zh": "通过顺序贪婪过滤改进样本效率的保形生成",
      "authors": [
        "Klaus-Rudolf Kladny",
        "Bernhard Schölkopf",
        "Michael Muehlebach"
      ],
      "abstract": "Generative models lack rigorous statistical guarantees for their outputs and\nare therefore unreliable in safety-critical applications. In this work, we\npropose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a\nsequential conformal prediction method producing prediction sets that satisfy a\nrigorous statistical guarantee called conformal admissibility control. This\nguarantee states that with high probability, the prediction sets contain at\nleast one admissible (or valid) example. To this end, our method first samples\nan initial set of i.i.d. examples from a black box generative model. Then, this\nset is iteratively pruned via so-called greedy filters. As a consequence of the\niterative generation procedure, admissibility of the final prediction set\nfactorizes as a Markov chain. This factorization is crucial, because it allows\nto control each factor separately, using conformal prediction. In comparison to\nprior work, our method demonstrates a large reduction in the number of\nadmissibility evaluations during calibration. This reduction is important in\nsafety-critical applications, where these evaluations must be conducted\nmanually by domain experts and are therefore costly and time consuming. We\nhighlight the advantages of our method in terms of admissibility evaluations\nand cardinality of the prediction sets through experiments in natural language\ngeneration and molecular graph extension tasks.",
      "tldr_zh": "本文提出 Sequential Conformal Prediction for Generative Models (SCOPE-Gen)，一种通过顺序贪婪过滤(sequential greedy filtering)改进生成模型样本效率的方法，以实现严格的 conformal admissibility control 保证，确保高概率下预测集包含至少一个 admissible 样本。方法涉及从黑箱生成模型采样 i.i.d. 样本，然后通过迭代修剪和 Markov chain 分解分别控制每个因子的 admissibility，从而减少手动评估的次数。与现有工作相比，SCOPE-Gen 在自然语言生成和分子图扩展任务的实验中，大幅降低了 admissibility evaluations 的数量，同时保持了预测集的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01660v2",
      "published_date": "2024-10-02 15:26:52 UTC",
      "updated_date": "2025-02-15 15:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:07:41.876922"
    },
    {
      "arxiv_id": "2410.03766v2",
      "title": "FutureFill: Fast Generation from Convolutional Sequence Models",
      "title_zh": "FutureFill：基于卷积",
      "authors": [
        "Naman Agarwal",
        "Xinyi Chen",
        "Evan Dogariu",
        "Vlad Feinberg",
        "Daniel Suo",
        "Peter Bartlett",
        "Elad Hazan"
      ],
      "abstract": "We address the challenge of efficient auto-regressive generation in sequence\nprediction models by introducing FutureFill - a method for fast generation that\napplies to any sequence prediction algorithm based on convolutional operators.\nOur approach reduces the generation time requirement from quadratic to\nquasilinear relative to the context length. Additionally, FutureFill requires a\nprefill cache sized only by the number of tokens generated, which is smaller\nthan the cache requirements for standard convolutional and attention-based\nmodels. We validate our theoretical findings with experimental evidence\ndemonstrating correctness and efficiency gains in a synthetic generation task.",
      "tldr_zh": "这篇论文引入了 FutureFill，一种快速生成方法，适用于基于卷积操作的序列预测模型，以解决高效自回归生成挑战。FutureFill 将生成时间从二次复杂度降低到准线性复杂度（相对于上下文长度），并只需一个由生成 tokens 数决定的预填充缓存，这比标准卷积和注意力模型的缓存需求更小。通过合成生成任务的实验，论文验证了理论分析的正确性和效率提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03766v2",
      "published_date": "2024-10-02 15:22:08 UTC",
      "updated_date": "2024-10-25 19:45:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:07:55.031892"
    },
    {
      "arxiv_id": "2410.01651v2",
      "title": "Efficient Length-Generalizable Attention via Causal Retrieval for Long-Context Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Hu",
        "Zhihao Teng",
        "Jun Zhao",
        "Wei Wu",
        "Kewei Tu"
      ],
      "abstract": "Despite the success of Transformers, handling long contexts remains\nchallenging due to the limited length generalization and quadratic complexity\nof self-attention. Thus Transformers often require post-training with a larger\nattention window, significantly increasing computational and memory costs. In\nthis paper, we propose a novel attention mechanism based on dynamic context,\nGrouped Cross Attention (GCA), which can generalize to 1000 times the\npre-training context length while maintaining the ability to access distant\ninformation with a constant attention window size. For a given input sequence,\nwe split it into chunks and use each chunk to retrieve top-k relevant past\nchunks for subsequent text generation. Specifically, unlike most previous works\nthat use an off-the-shelf retriever, our key innovation allows the retriever to\nlearn how to retrieve past chunks that better minimize the auto-regressive loss\nof subsequent tokens in an end-to-end manner. Such a mechanism accommodates\nretrieved chunks with a fixed-size attention window to achieve long-range\ninformation access, significantly reducing computational and memory costs\nduring training and inference. Experiments show that GCA-based models achieve\nnear-perfect accuracy in passkey retrieval for 16M context lengths, which is\n1000 times the training length.",
      "tldr_zh": "这篇论文针对 Transformer 在长上下文语言建模中的长度泛化有限和二次方复杂度问题，提出了一种基于动态上下文的注意力机制——Grouped Cross Attention (GCA)。GCA 通过将输入序列分成块，并使用端到端学习的方式检索 top-k 最相关的过去块，以最小化自回归损失，从而在固定大小的注意力窗口下实现对预训练上下文长度的 1000 倍泛化，同时减少计算和内存开销。实验结果显示，基于 GCA 的模型在 16M 上下文长度上实现了近乎完美的 passkey 检索准确率，为高效的长上下文处理提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.01651v2",
      "published_date": "2024-10-02 15:18:34 UTC",
      "updated_date": "2025-01-27 07:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:07:57.020981"
    },
    {
      "arxiv_id": "2410.01649v1",
      "title": "shapiq: Shapley Interactions for Machine Learning",
      "title_zh": "shapiq：Shapley交互用于机器",
      "authors": [
        "Maximilian Muschalik",
        "Hubert Baniecki",
        "Fabian Fumagalli",
        "Patrick Kolpaczki",
        "Barbara Hammer",
        "Eyke Hüllermeier"
      ],
      "abstract": "Originally rooted in game theory, the Shapley Value (SV) has recently become\nan important tool in machine learning research. Perhaps most notably, it is\nused for feature attribution and data valuation in explainable artificial\nintelligence. Shapley Interactions (SIs) naturally extend the SV and address\nits limitations by assigning joint contributions to groups of entities, which\nenhance understanding of black box machine learning models. Due to the\nexponential complexity of computing SVs and SIs, various methods have been\nproposed that exploit structural assumptions or yield probabilistic estimates\ngiven limited resources. In this work, we introduce shapiq, an open-source\nPython package that unifies state-of-the-art algorithms to efficiently compute\nSVs and any-order SIs in an application-agnostic framework. Moreover, it\nincludes a benchmarking suite containing 11 machine learning applications of\nSIs with pre-computed games and ground-truth values to systematically assess\ncomputational performance across domains. For practitioners, shapiq is able to\nexplain and visualize any-order feature interactions in predictions of models,\nincluding vision transformers, language models, as well as XGBoost and LightGBM\nwith TreeSHAP-IQ. With shapiq, we extend shap beyond feature attributions and\nconsolidate the application of SVs and SIs in machine learning that facilitates\nfuture research. The source code and documentation are available at\nhttps://github.com/mmschlk/shapiq.",
      "tldr_zh": "本研究扩展了博弈论中的 Shapley Value (SV)，通过引入 Shapley Interactions (SIs) 来更好地解释黑箱机器学习模型的特征交互和数据估值。研究者开发了开源 Python 包 shapiq，它统一了高效算法，支持计算 SV 和任意阶 SIs，并提供了一个包含11个机器学习应用的基准测试套件，用于评估计算性能。shapiq 能够可视化模型预测中的特征交互，适用于视觉变压器、语言模型、XGBoost 和 LightGBM 等，并扩展了 shap 的功能，促进未来机器学习解释性研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.01649v1",
      "published_date": "2024-10-02 15:16:53 UTC",
      "updated_date": "2024-10-02 15:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:08:08.639641"
    },
    {
      "arxiv_id": "2410.01643v4",
      "title": "Stable Offline Value Function Learning with Bisimulation-based Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Brahma S. Pavse",
        "Yudong Chen",
        "Qiaomin Xie",
        "Josiah P. Hanna"
      ],
      "abstract": "In reinforcement learning, offline value function learning is the procedure\nof using an offline dataset to estimate the expected discounted return from\neach state when taking actions according to a fixed target policy. The\nstability of this procedure, i.e., whether it converges to its fixed-point,\ncritically depends on the representations of the state-action pairs. Poorly\nlearned representations can make value function learning unstable, or even\ndivergent. Therefore, it is critical to stabilize value function learning by\nexplicitly shaping the state-action representations. Recently, the class of\nbisimulation-based algorithms have shown promise in shaping representations for\ncontrol. However, it is still unclear if this class of methods can\n\\emph{stabilize} value function learning. In this work, we investigate this\nquestion and answer it affirmatively. We introduce a bisimulation-based\nalgorithm called kernel representations for offline policy evaluation\n(\\textsc{krope}). \\textsc{krope} uses a kernel to shape state-action\nrepresentations such that state-action pairs that have similar immediate\nrewards and lead to similar next state-action pairs under the target policy\nalso have similar representations. We show that \\textsc{krope}: 1) learns\nstable representations and 2) leads to lower value error than baselines. Our\nanalysis provides new theoretical insight into the stability properties of\nbisimulation-based methods and suggests that practitioners can use these\nmethods to improve the stability and accuracy of offline evaluation of\nreinforcement learning agents.",
      "tldr_zh": "本研究探讨了强化学习（reinforcement learning）中离线价值函数学习（offline value function learning）的稳定性问题，该过程依赖于状态-动作对的表示，而不当表示可能导致不稳定或发散。作者引入了一种基于双模拟（bisimulation-based）的算法，名为 kernel representations for offline policy evaluation (\\textsc{krope})，它利用内核（kernel）塑造表示，使具有相似即时奖励和下一状态-动作对的状态-动作对在表示上更接近，从而提升稳定性。实验结果显示，\\textsc{krope} 比基线方法实现了更低的价值错误，并提供了新的理论洞见，建议在实践中使用此类方法来提高强化学习代理的离线评估（offline policy evaluation）的准确性和稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the International Conference on Machine Learning (ICML)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01643v4",
      "published_date": "2024-10-02 15:13:25 UTC",
      "updated_date": "2025-05-17 17:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:08:20.216711"
    },
    {
      "arxiv_id": "2410.01639v4",
      "title": "Moral Alignment for LLM Agents",
      "title_zh": "LLM 代理的道德对齐",
      "authors": [
        "Elizaveta Tennant",
        "Stephen Hailes",
        "Mirco Musolesi"
      ],
      "abstract": "Decision-making agents based on pre-trained Large Language Models (LLMs) are\nincreasingly being deployed across various domains of human activity. While\ntheir applications are currently rather specialized, several research efforts\nare underway to develop more generalist agents. As LLM-based systems become\nmore agentic, their influence on human activity will grow and their\ntransparency will decrease. Consequently, developing effective methods for\naligning them to human values is vital.\n  The prevailing practice in alignment often relies on human preference data\n(e.g., in RLHF or DPO), in which values are implicit, opaque and are\nessentially deduced from relative preferences over different model outputs. In\nthis work, instead of relying on human feedback, we introduce the design of\nreward functions that explicitly and transparently encode core human values for\nReinforcement Learning-based fine-tuning of foundation agent models.\nSpecifically, we use intrinsic rewards for the moral alignment of LLM agents.\n  We evaluate our approach using the traditional philosophical frameworks of\nDeontological Ethics and Utilitarianism, quantifying moral rewards for agents\nin terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD)\nenvironment. We also show how moral fine-tuning can be deployed to enable an\nagent to unlearn a previously developed selfish strategy. Finally, we find that\ncertain moral strategies learned on the IPD game generalize to several other\nmatrix game environments. In summary, we demonstrate that fine-tuning with\nintrinsic rewards is a promising general solution for aligning LLM agents to\nhuman values, and it might represent a more transparent and cost-effective\nalternative to currently predominant alignment techniques.",
      "tldr_zh": "本文提出了一种显式编码核心人类价值观的奖励函数方法，用于强化学习(RL)微调大型语言模型(LLMs)代理的道德对齐，取代依赖人类反馈（如RLHF或DPO）的传统不透明做法。方法通过内在奖励(intrinsic rewards)评估代理在Iterated Prisoner's Dilemma(IPD)环境中的行为，基于Deontological Ethics和Utilitarianism框架量化道德奖励。实验结果显示，该微调能让代理放弃先前自私策略，并将学到的道德策略泛化到其他矩阵游戏环境，提供了一种更透明、成本有效的LLM代理对齐解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the 13th International Conference on Learning\n  Representations (ICLR'25), Singapore, Apr 2025.\n  https://openreview.net/forum?id=MeGDmZjUXy",
      "pdf_url": "http://arxiv.org/pdf/2410.01639v4",
      "published_date": "2024-10-02 15:09:36 UTC",
      "updated_date": "2025-05-11 19:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:08:34.304878"
    },
    {
      "arxiv_id": "2410.01638v1",
      "title": "Data Extrapolation for Text-to-image Generation on Small Datasets",
      "title_zh": "数据外推用于小数据集的文本到图像生成",
      "authors": [
        "Senmao Ye",
        "Fei Liu"
      ],
      "abstract": "Text-to-image generation requires large amount of training data to\nsynthesizing high-quality images. For augmenting training data, previous\nmethods rely on data interpolations like cropping, flipping, and mixing up,\nwhich fail to introduce new information and yield only marginal improvements.\nIn this paper, we propose a new data augmentation method for text-to-image\ngeneration using linear extrapolation. Specifically, we apply linear\nextrapolation only on text feature, and new image data are retrieved from the\ninternet by search engines. For the reliability of new text-image pairs, we\ndesign two outlier detectors to purify retrieved images. Based on\nextrapolation, we construct training samples dozens of times larger than the\noriginal dataset, resulting in a significant improvement in text-to-image\nperformance. Moreover, we propose a NULL-guidance to refine score estimation,\nand apply recurrent affine transformation to fuse text information. Our model\nachieves FID scores of 7.91, 9.52 and 5.00 on the CUB, Oxford and COCO\ndatasets. The code and data will be available on GitHub\n(https://github.com/senmaoy/RAT-Diffusion).",
      "tldr_zh": "本研究针对文本到图像生成在小数据集上的挑战，提出了一种基于linear extrapolation的数据增强方法，通过在外推文本特征后使用搜索引擎检索新图像，从而引入更多新信息。作者设计了两个outlier detectors来净化检索图像，确保新文本-图像对的可靠性，并结合NULL-guidance改进分数估计，以及recurrent affine transformation融合文本信息。实验结果显示，该方法显著提升了生成性能，在CUB、Oxford和COCO数据集上分别获得FID scores为7.91、9.52和5.00，构建的训练样本比原数据集大几十倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01638v1",
      "published_date": "2024-10-02 15:08:47 UTC",
      "updated_date": "2024-10-02 15:08:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:08:47.401194"
    },
    {
      "arxiv_id": "2410.01635v1",
      "title": "Does Graph Prompt Work? A Data Operation Perspective with Theoretical Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Qunzhong Wang",
        "Xiangguo Sun",
        "Hong Cheng"
      ],
      "abstract": "In recent years, graph prompting has emerged as a promising research\ndirection, enabling the learning of additional tokens or subgraphs appended to\nthe original graphs without requiring retraining of pre-trained graph models\nacross various applications. This novel paradigm, shifting from the traditional\npretraining and finetuning to pretraining and prompting has shown significant\nempirical success in simulating graph data operations, with applications\nranging from recommendation systems to biological networks and graph\ntransferring. However, despite its potential, the theoretical underpinnings of\ngraph prompting remain underexplored, raising critical questions about its\nfundamental effectiveness. The lack of rigorous theoretical proof of why and\nhow much it works is more like a dark cloud over the graph prompt area to go\nfurther. To fill this gap, this paper introduces a theoretical framework that\nrigorously analyzes graph prompting from a data operation perspective. Our\ncontributions are threefold: First, we provide a formal guarantee theorem,\ndemonstrating graph prompts capacity to approximate graph transformation\noperators, effectively linking upstream and downstream tasks. Second, we derive\nupper bounds on the error of these data operations by graph prompts for a\nsingle graph and extend this discussion to batches of graphs, which are common\nin graph model training. Third, we analyze the distribution of data operation\nerrors, extending our theoretical findings from linear graph models (e.g., GCN)\nto non-linear graph models (e.g., GAT). Extensive experiments support our\ntheoretical results and confirm the practical implications of these guarantees.",
      "tldr_zh": "这篇论文探讨了graph prompting的有效性，从数据操作视角进行理论分析，旨在填补其理论基础的空白。论文的主要贡献包括：提出一个正式的保证定理，证明graph prompts能够近似图变换操作，从而连接上游和下游任务；推导出数据操作错误的上下界，并扩展到单个图、批量图以及从线性模型（如GCN）到非线性模型（如GAT）的场景；分析错误分布以验证理论适用性。实验结果支持这些理论发现，证实了graph prompting在实际应用中的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01635v1",
      "published_date": "2024-10-02 15:07:13 UTC",
      "updated_date": "2024-10-02 15:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:09:00.324874"
    },
    {
      "arxiv_id": "2410.01628v3",
      "title": "Stochasticity in Motion: An Information-Theoretic Approach to Trajectory Prediction",
      "title_zh": "运动中的随机性：一种基于信息理论的轨迹预测方法",
      "authors": [
        "Aron Distelzweig",
        "Andreas Look",
        "Eitan Kosman",
        "Faris Janjoš",
        "Jörg Wagner",
        "Abhinav Valada"
      ],
      "abstract": "In autonomous driving, accurate motion prediction is crucial for safe and\nefficient motion planning. To ensure safety, planners require reliable\nuncertainty estimates of the predicted behavior of surrounding agents, yet this\naspect has received limited attention. In particular, decomposing uncertainty\ninto its aleatoric and epistemic components is essential for distinguishing\nbetween inherent environmental randomness and model uncertainty, thereby\nenabling more robust and informed decision-making. This paper addresses the\nchallenge of uncertainty modeling in trajectory prediction with a holistic\napproach that emphasizes uncertainty quantification, decomposition, and the\nimpact of model composition. Our method, grounded in information theory,\nprovides a theoretically principled way to measure uncertainty and decompose it\ninto aleatoric and epistemic components. Unlike prior work, our approach is\ncompatible with state-of-the-art motion predictors, allowing for broader\napplicability. We demonstrate its utility by conducting extensive experiments\non the nuScenes dataset, which shows how different architectures and\nconfigurations influence uncertainty quantification and model robustness.",
      "tldr_zh": "本论文提出了一种基于信息理论的方法，用于轨迹预测的不确定性建模，旨在区分 aleatoric（环境随机性）和 epistemic（模型不确定性），从而提升自动驾驶的安全性和决策可靠性。该方法通过量化不确定性并分解其组成部分，兼容现有最先进运动预测器，提供更全面的模型评估和优化。在 nuScenes 数据集上的广泛实验表明，不同架构和配置会显著影响不确定性量化和模型鲁棒性，为更可靠的运动规划奠定基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures, submitted to International Conference on\n  Intelligent Robots and Systems (IROS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.01628v3",
      "published_date": "2024-10-02 15:02:32 UTC",
      "updated_date": "2025-02-28 16:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:09:08.592107"
    },
    {
      "arxiv_id": "2410.01623v2",
      "title": "Fira: Can We Achieve Full-rank Training of LLMs Under Low-rank Constraint?",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Chen",
        "Kaituo Feng",
        "Changsheng Li",
        "Xunhao Lai",
        "Xiangyu Yue",
        "Ye Yuan",
        "Guoren Wang"
      ],
      "abstract": "Low-rank training has emerged as a promising approach for reducing memory\nusage in training Large Language Models (LLMs). Previous methods either rely on\ndecomposing weight matrices (e.g., LoRA), or seek to decompose gradient\nmatrices (e.g., GaLore) to ensure reduced memory consumption. However, both of\nthem constrain the training in a low-rank subspace, thus inevitably leading to\nsub-optimal performance. This raises a question: whether it is possible to\nconsistently preserve the low-rank constraint for memory efficiency, while\nachieving full-rank training (i.e., training with full-rank gradients of\nfull-rank weights) to avoid inferior outcomes? In this paper, we propose a new\nplug-and-play training framework for LLMs called Fira, as the first attempt to\nachieve this goal. First, we observe an interesting phenomenon during LLM\ntraining: the scaling impact of adaptive optimizers (e.g., Adam) on the\ngradient norm remains similar from low-rank to full-rank training. Based on\nthis observation, we propose a norm-based scaling method, which utilizes the\nscaling impact of low-rank optimizers as substitutes for that of original\nfull-rank optimizers to enable full-rank training. In this way, we can preserve\nthe low-rank constraint in the optimizer while achieving full-rank training for\nbetter performance. Moreover, we find that there are sudden gradient rises\nduring the optimization process, potentially causing loss spikes. To address\nthis, we further put forward a norm-growth limiter to smooth the gradient via\nregulating the relative increase of gradient norms. Extensive experiments on\nthe pre-training and fine-tuning of LLMs show that Fira outperforms both LoRA\nand GaLore, achieving performance that is comparable to or even better than\nfull-rank training.",
      "tldr_zh": "这篇论文探讨了在低秩约束下是否能实现大型语言模型(LLMs)的全秩训练，以减少内存消耗同时避免性能下降。作者提出 Fira 框架，通过观察自适应优化器(如 Adam)对梯度范数的相似缩放影响，设计了一种基于范数的缩放方法，使用低秩优化器替代全秩优化器来实现全秩训练，同时引入 norm-growth limiter 来平滑梯度并防止损失峰值。实验结果显示，Fira 在 LLMs 的预训练和微调中优于 LoRA 和 GaLore，其性能可与全秩训练相当或更优。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Add further analysis of the scaling factor, code is available at:\n  https://github.com/xichen-fy/Fira",
      "pdf_url": "http://arxiv.org/pdf/2410.01623v2",
      "published_date": "2024-10-02 14:58:27 UTC",
      "updated_date": "2024-10-12 08:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:09:20.682967"
    },
    {
      "arxiv_id": "2410.01611v2",
      "title": "DRUPI: Dataset Reduction Using Privileged Information",
      "title_zh": "翻译失败",
      "authors": [
        "Shaobo Wang",
        "Yantai Yang",
        "Shuaiyu Zhang",
        "Chenghao Sun",
        "Weiya Li",
        "Xuming Hu",
        "Linfeng Zhang"
      ],
      "abstract": "Dataset reduction (DR) seeks to select or distill samples from large datasets\ninto smaller subsets while preserving performance on target tasks. Existing\nmethods primarily focus on pruning or synthesizing data in the same format as\nthe original dataset, typically the input data and corresponding labels.\nHowever, in DR settings, we find it is possible to synthesize more information\nbeyond the data-label pair as an additional learning target to facilitate model\ntraining. In this paper, we introduce Dataset Reduction Using Privileged\nInformation (DRUPI), which enriches DR by synthesizing privileged information\nalongside the reduced dataset. This privileged information can take the form of\nfeature labels or attention labels, providing auxiliary supervision to improve\nmodel learning. Our findings reveal that effective feature labels must balance\nbetween being overly discriminative and excessively diverse, with a moderate\nlevel proving optimal for improving the reduced dataset's efficacy. Extensive\nexperiments on ImageNet, CIFAR-10/100, and Tiny ImageNet demonstrate that DRUPI\nintegrates seamlessly with existing dataset reduction methods, offering\nsignificant performance gains. *The code will be released after the paper is\naccepted.*",
      "tldr_zh": "该论文提出了一种名为 DRUPI 的数据集缩减（Dataset Reduction）方法，通过合成特权信息（Privileged Information）来辅助模型训练，提升缩减数据集的效能。不同于传统方法仅处理输入数据和标签，DRUPI 额外生成特征标签（feature labels）或注意力标签（attention labels）作为辅助监督，以优化模型学习。研究发现，特权信息需保持适中平衡——既不过于区分性也不太多样化，以最大化缩减数据集的效果。在 ImageNet、CIFAR-10/100 和 Tiny ImageNet 等数据集上的广泛实验表明，DRUPI 与现有缩减方法无缝整合，并显著提升性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01611v2",
      "published_date": "2024-10-02 14:49:05 UTC",
      "updated_date": "2024-10-09 06:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:09:31.661035"
    },
    {
      "arxiv_id": "2410.01610v1",
      "title": "Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Tingfeng Hui",
        "Zhenyu Zhang",
        "Shuohuan Wang",
        "Yu Sun",
        "Hua Wu",
        "Sen Su"
      ],
      "abstract": "Mixture-of-Experts (MoE) shines brightly in large language models (LLMs) and\ndemonstrates outstanding performance in plentiful natural language processing\ntasks. However, existing methods transforming LLMs from dense to MoE face\nsignificant data requirements and typically rely on large-scale post-training.\nIn this paper, we propose Upcycling Instruction Tuning (UpIT), a data-efficient\napproach for tuning a dense pre-trained model into a MoE instruction model.\nSpecifically, we first point out that intermediate checkpoints during\ninstruction tuning of the dense model are naturally suitable for specialized\nexperts, and then propose an expert expansion stage to flexibly achieve models\nwith flexible numbers of experts, where genetic algorithm and parameter merging\nare introduced to ensure sufficient diversity of new extended experts. To\nensure that each specialized expert in the MoE model works as expected, we\nselect a small amount of seed data that each expert excels to pre-optimize the\nrouter. Extensive experiments with various data scales and upcycling settings\ndemonstrate the outstanding performance and data efficiency of UpIT, as well as\nstable improvement in expert or data scaling. Further analysis reveals the\nimportance of ensuring expert diversity in upcycling.",
      "tldr_zh": "本论文提出 Upcycling Instruction Tuning (UpIT)，一种数据高效的方法，将密集预训练模型转换为 Mixture-of-Experts (MoE) 指令模型，减少了传统方法对大规模数据的依赖。\nUpIT 利用密集模型指令调优过程中的中间检查点作为专家基础，并通过遗传算法和参数合并扩展多样化的专家，同时使用少量种子数据预优化路由器以确保专家功能正常。\n实验结果显示，UpIT 在不同数据规模和设置下表现出色，具有显著的数据效率，并证明专家多样性对性能提升至关重要。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2410.01610v1",
      "published_date": "2024-10-02 14:48:22 UTC",
      "updated_date": "2024-10-02 14:48:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:09:45.011762"
    },
    {
      "arxiv_id": "2410.01606v1",
      "title": "Automated Red Teaming with GOAT: the Generative Offensive Agent Tester",
      "title_zh": "翻译失败",
      "authors": [
        "Maya Pavlova",
        "Erik Brinkman",
        "Krithika Iyer",
        "Vitor Albiero",
        "Joanna Bitton",
        "Hailey Nguyen",
        "Joe Li",
        "Cristian Canton Ferrer",
        "Ivan Evtimov",
        "Aaron Grattafiori"
      ],
      "abstract": "Red teaming assesses how large language models (LLMs) can produce content\nthat violates norms, policies, and rules set during their safety training.\nHowever, most existing automated methods in the literature are not\nrepresentative of the way humans tend to interact with AI models. Common users\nof AI models may not have advanced knowledge of adversarial machine learning\nmethods or access to model internals, and they do not spend a lot of time\ncrafting a single highly effective adversarial prompt. Instead, they are likely\nto make use of techniques commonly shared online and exploit the multiturn\nconversational nature of LLMs. While manual testing addresses this gap, it is\nan inefficient and often expensive process. To address these limitations, we\nintroduce the Generative Offensive Agent Tester (GOAT), an automated agentic\nred teaming system that simulates plain language adversarial conversations\nwhile leveraging multiple adversarial prompting techniques to identify\nvulnerabilities in LLMs. We instantiate GOAT with 7 red teaming attacks by\nprompting a general-purpose model in a way that encourages reasoning through\nthe choices of methods available, the current target model's response, and the\nnext steps. Our approach is designed to be extensible and efficient, allowing\nhuman testers to focus on exploring new areas of risk while automation covers\nthe scaled adversarial stress-testing of known risk territory. We present the\ndesign and evaluation of GOAT, demonstrating its effectiveness in identifying\nvulnerabilities in state-of-the-art LLMs, with an ASR@10 of 97% against Llama\n3.1 and 88% against GPT-4 on the JailbreakBench dataset.",
      "tldr_zh": "这篇论文介绍了 GOAT（Generative Offensive Agent Tester），一个自动化的红队测试（Red Teaming）系统，用于评估大型语言模型（LLMs）在安全训练中产生违规内容的漏洞。GOAT 通过模拟人类对话方式，结合多种对抗提示技术（如7种红队攻击），让代理模型通过推理选择方法、分析响应和规划下一步，从而高效识别风险。实验结果显示，GOAT 在 JailbreakBench 数据集上对 Llama 3.1 的 ASR@10 达到97%，对 GPT-4 达到88%，证明其在扩展性和效率上优于手动测试。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01606v1",
      "published_date": "2024-10-02 14:47:05 UTC",
      "updated_date": "2024-10-02 14:47:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:09:56.267023"
    },
    {
      "arxiv_id": "2410.01598v1",
      "title": "Elaborative Subtopic Query Reformulation for Broad and Indirect Queries in Travel Destination Recommendation",
      "title_zh": "针对旅游目的地推荐中广泛和间接查询的详细子主题查询重述",
      "authors": [
        "Qianfeng Wen",
        "Yifan Liu",
        "Joshua Zhang",
        "George Saad",
        "Anton Korikov",
        "Yury Sambale",
        "Scott Sanner"
      ],
      "abstract": "In Query-driven Travel Recommender Systems (RSs), it is crucial to understand\nthe user intent behind challenging natural language(NL) destination queries\nsuch as the broadly worded \"youth-friendly activities\" or the indirect\ndescription \"a high school graduation trip\". Such queries are challenging due\nto the wide scope and subtlety of potential user intents that confound the\nability of retrieval methods to infer relevant destinations from available\ntextual descriptions such as WikiVoyage. While query reformulation (QR) has\nproven effective in enhancing retrieval by addressing user intent, existing QR\nmethods tend to focus only on expanding the range of potentially matching query\nsubtopics (breadth) or elaborating on the potential meaning of a query (depth),\nbut not both. In this paper, we introduce Elaborative Subtopic Query\nReformulation (EQR), a large language model-based QR method that combines both\nbreadth and depth by generating potential query subtopics with information-rich\nelaborations. We also release TravelDest, a novel dataset for query-driven\ntravel destination RSs. Experiments on TravelDest show that EQR achieves\nsignificant improvements in recall and precision over existing state-of-the-art\nQR methods.",
      "tldr_zh": "本研究针对查询驱动的旅行推荐系统，处理宽泛或间接的自然语言查询（如“youth-friendly activities”），这些查询因用户意图微妙而难以为检索方法推断相关目的地。论文提出Elaborative Subtopic Query Reformulation (EQR)，一种基于大语言模型的查询重构(QR)方法，结合查询子话题的广度（扩展潜在匹配范围）和深度（提供信息丰富的阐述），以提升推荐准确性。同时，研究发布了TravelDest数据集，一种新型查询驱动旅行目的地推荐数据集。实验结果显示，EQR在TravelDest上显著提高了召回率和精确率，超越了现有最先进QR方法。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 7 figures,The 1st Workshop on Risks, Opportunities, and\n  Evaluation of Generative Models in Recommender Systems (ROEGEN@RecSys 2024),\n  October 2024, Bari, Italy",
      "pdf_url": "http://arxiv.org/pdf/2410.01598v1",
      "published_date": "2024-10-02 14:36:18 UTC",
      "updated_date": "2024-10-02 14:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:10:07.832630"
    },
    {
      "arxiv_id": "2410.01595v3",
      "title": "KnobGen: Controlling the Sophistication of Artwork in Sketch-Based Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pouyan Navard",
        "Amin Karimi Monsefi",
        "Mengxi Zhou",
        "Wei-Lun Chao",
        "Alper Yilmaz",
        "Rajiv Ramnath"
      ],
      "abstract": "Recent advances in diffusion models have significantly improved text-to-image\n(T2I) generation, but they often struggle to balance fine-grained precision\nwith high-level control. Methods like ControlNet and T2I-Adapter excel at\nfollowing sketches by seasoned artists but tend to be overly rigid, replicating\nunintentional flaws in sketches from novice users. Meanwhile, coarse-grained\nmethods, such as sketch-based abstraction frameworks, offer more accessible\ninput handling but lack the precise control needed for detailed, professional\nuse. To address these limitations, we propose KnobGen, a dual-pathway framework\nthat democratizes sketch-based image generation by seamlessly adapting to\nvarying levels of sketch complexity and user skill. KnobGen uses a\nCoarse-Grained Controller (CGC) module for high-level semantics and a\nFine-Grained Controller (FGC) module for detailed refinement. The relative\nstrength of these two modules can be adjusted through our knob inference\nmechanism to align with the user's specific needs. These mechanisms ensure that\nKnobGen can flexibly generate images from both novice sketches and those drawn\nby seasoned artists. This maintains control over the final output while\npreserving the natural appearance of the image, as evidenced on the\nMultiGen-20M dataset and a newly collected sketch dataset.",
      "tldr_zh": "该论文提出KnobGen，一种双路径框架，用于在基于草图的Diffusion Models中控制艺术作品的复杂性，解决现有方法如ControlNet和T2I-Adapter在细粒度精度和高层次控制之间平衡不足的问题。KnobGen包括Coarse-Grained Controller (CGC)模块处理高层次语义，以及Fine-Grained Controller (FGC)模块进行详细精炼，通过knob inference机制动态调整两个模块的相对强度，以适应新手或专业用户的草图输入。实验结果显示，该框架在MultiGen-20M数据集和新收集的草图数据集上实现了灵活的图像生成，保持了输出控制和自然外观的平衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025 Workshop on CVEU",
      "pdf_url": "http://arxiv.org/pdf/2410.01595v3",
      "published_date": "2024-10-02 14:33:12 UTC",
      "updated_date": "2025-04-09 22:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:10:20.498105"
    },
    {
      "arxiv_id": "2410.01591v2",
      "title": "Imaging foundation model for universal enhancement of non-ideal measurement CT",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxin Liu",
        "Rongjun Ge",
        "Yuting He",
        "Zhan Wu",
        "Shangwen Yang",
        "Yuan Gao",
        "Chenyu You",
        "Ge Wang",
        "Yang Chen",
        "Shuo Li"
      ],
      "abstract": "Non-ideal measurement computed tomography (NICT) employs suboptimal imaging\nprotocols to expand CT applications. However, the resulting trade-offs degrade\nimage quality, limiting clinical acceptability. Although deep learning methods\nhave been used to enhance NICT images, their reliance on large training\ndatasets and limited generalizability across diverse settings hinder practical\nuse. We propose the multi-scale integrated Transformer AMPlifier (TAMP), the\nfirst imaging foundation model for universal NICT enhancement. Pre-trained on\n10.8 million physics-driven simulated NICT images, TAMP generalizes effectively\nacross various NICT settings, defect degrees, and body regions. Moreover, a\nparameter-efficient fine-tuning strategy enables TAMP to adapt to specific\nclinical scenarios using only few slices. Extensive experiments, including\nradiologists and real-world validations, demonstrate that TAMP consistently\nimproves image quality and clinical acceptability, underscoring its significant\npotential to advance CT imaging and broaden NICT applications in clinical\npractice.",
      "tldr_zh": "本文针对非理想测量 CT (NICT) 的图像质量问题及其现有深度学习方法的局限性（如依赖大量数据和泛化性差），提出了一种名为 TAMP 的多尺度集成 Transformer 基础模型，用于通用 NICT 增强。TAMP 在 1080 万张基于物理模拟的 NICT 图像上预训练，能够有效泛化到各种 NICT 设置、缺陷程度和身体部位。采用参数高效的微调策略，仅需少量切片即可适应特定临床场景。实验结果，包括放射科医生评估和真实世界验证，证明 TAMP 显著提高了图像质量和临床接受度，推动了 CT 成像技术的进步和 NICT 应用的扩展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01591v2",
      "published_date": "2024-10-02 14:25:02 UTC",
      "updated_date": "2025-02-25 18:28:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:10:35.271779"
    },
    {
      "arxiv_id": "2410.01583v1",
      "title": "Iterated Local Search with Linkage Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Renato Tinós",
        "Michal W. Przewozniczek",
        "Darrell Whitley",
        "Francisco Chicano"
      ],
      "abstract": "In pseudo-Boolean optimization, a variable interaction graph represents\nvariables as vertices, and interactions between pairs of variables as edges. In\nblack-box optimization, the variable interaction graph may be at least\npartially discovered by using empirical linkage learning techniques. These\nmethods never report false variable interactions, but they are computationally\nexpensive. The recently proposed local search with linkage learning discovers\nthe partial variable interaction graph as a side-effect of iterated local\nsearch. However, information about the strength of the interactions is not\nlearned by the algorithm. We propose local search with linkage learning 2,\nwhich builds a weighted variable interaction graph that stores information\nabout the strength of the interaction between variables. The weighted variable\ninteraction graph can provide new insights about the optimization problem and\nbehavior of optimizers. Experiments with NK landscapes, knapsack problem, and\nfeature selection show that local search with linkage learning 2 is able to\nefficiently build weighted variable interaction graphs. In particular,\nexperiments with feature selection show that the weighted variable interaction\ngraphs can be used for visualizing the feature interactions in machine\nlearning. Additionally, new transformation operators that exploit the\ninteractions between variables can be designed. We illustrate this ability by\nproposing a new perturbation operator for iterated local search.",
      "tldr_zh": "该研究提出了一种改进的算法——local search with linkage learning 2，用于伪布尔优化(pseudo-Boolean optimization)，它在迭代局部搜索的基础上构建加权的变量交互图(variable interaction graph)，以捕获变量间交互的强度，从而提供更深入的优化问题洞见。相比传统经验性联系学习(empirical linkage learning)方法，该算法在不报告虚假交互的前提下，降低了计算成本，并作为副产品学习交互强度。实验在 NK landscapes、knapsack problem 和特征选择(feature selection)上显示，该方法能高效构建加权图，用于可视化特征交互并设计新转换算子，例如一个新的扰动算子(perturbation operator)来提升迭代局部搜索的性能。总的来说，这为黑箱优化提供了更具解释性的工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01583v1",
      "published_date": "2024-10-02 14:17:50 UTC",
      "updated_date": "2024-10-02 14:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:10:47.035628"
    },
    {
      "arxiv_id": "2410.01579v1",
      "title": "Spoken Grammar Assessment Using LLM",
      "title_zh": "使用 LLM 的口语语法评估",
      "authors": [
        "Sunil Kumar Kopparapu",
        "Chitralekha Bhat",
        "Ashish Panda"
      ],
      "abstract": "Spoken language assessment (SLA) systems restrict themselves to evaluating\nthe pronunciation and oral fluency of a speaker by analysing the read and\nspontaneous spoken utterances respectively. The assessment of language grammar\nor vocabulary is relegated to written language assessment (WLA) systems. Most\nWLA systems present a set of sentences from a curated finite-size database of\nsentences thereby making it possible to anticipate the test questions and train\noneself. In this paper, we propose a novel end-to-end SLA system to assess\nlanguage grammar from spoken utterances thus making WLA systems redundant;\nadditionally, we make the assessment largely unteachable by employing a large\nlanguage model (LLM) to bring in variations in the test. We further demonstrate\nthat a hybrid automatic speech recognition (ASR) with a custom-built language\nmodel outperforms the state-of-the-art ASR engine for spoken grammar\nassessment.",
      "tldr_zh": "本文提出一种新型端到端 Spoken Language Assessment (SLA) 系统，使用 Large Language Model (LLM) 从口语中评估语法，从而取代传统的 Written Language Assessment (WLA) 系统，并通过引入测试变异性使评估不易被预测和针对性训练。现有 SLA 系统仅关注发音和口语流利度，而本系统整合了混合 Automatic Speech Recognition (ASR) 及自定义语言模型，以处理口语语法评估。实验结果表明，该系统在口语语法评估任务中优于现有最先进 ASR 引擎，为更全面的语言评估提供了创新方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01579v1",
      "published_date": "2024-10-02 14:15:13 UTC",
      "updated_date": "2024-10-02 14:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:10:56.402787"
    },
    {
      "arxiv_id": "2410.05289v3",
      "title": "MARS: A neurosymbolic approach for interpretable drug discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Lauren Nicole DeLong",
        "Yojana Gadiya",
        "Paola Galdi",
        "Jacques D. Fleuriot",
        "Daniel Domingo-Fernández"
      ],
      "abstract": "Neurosymbolic (NeSy) artificial intelligence describes the combination of\nlogic or rule-based techniques with neural networks. Compared to neural\napproaches, NeSy methods often possess enhanced interpretability, which is\nparticularly promising for biomedical applications like drug discovery.\nHowever, since interpretability is broadly defined, there are no clear\nguidelines for assessing the biological plausibility of model interpretations.\nTo assess interpretability in the context of drug discovery, we devise a novel\nprediction task, called drug mechanism-of-action (MoA) deconvolution, with an\nassociated, tailored knowledge graph (KG), MoA-net. We then develop the MoA\nRetrieval System (MARS), a NeSy approach for drug discovery which leverages\nlogical rules with learned rule weights. Using this interpretable feature\nalongside domain knowledge, we find that MARS and other NeSy approaches on KGs\nare susceptible to reasoning shortcuts, in which the prediction of true labels\nis driven by \"degree-bias\" rather than the domain-based rules. Subsequently, we\ndemonstrate ways to identify and mitigate this. Thereafter, MARS achieves\nperformance on par with current state-of-the-art models while producing model\ninterpretations aligned with known MoAs.",
      "tldr_zh": "这篇论文提出了一种 Neurosymbolic (NeSy) 方法 MARS，用于可解释的药物发现，通过结合逻辑规则和神经网络来提升模型在生物医学应用中的透明度。研究者设计了一个新任务——药物作用机制 (MoA) 分析，并构建了相关的知识图谱 (KG) MoA-net，以评估模型解释的生物合理性。MARS 通过学习带权重的逻辑规则实现了与当前最先进模型相当的性能，同时识别并缓解了推理捷径问题，如 degree-bias，确保预测更依赖于领域知识而非偏差。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review. 10 pages, 7 supplementary pages. Corresponding code is\n  here: https://github.com/laurendelong21/MARS and here:\n  https://github.com/laurendelong21/MoA-Net",
      "pdf_url": "http://arxiv.org/pdf/2410.05289v3",
      "published_date": "2024-10-02 14:14:17 UTC",
      "updated_date": "2025-01-10 15:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:11:09.451462"
    },
    {
      "arxiv_id": "2410.01575v1",
      "title": "Computing Ex Ante Equilibrium in Heterogeneous Zero-Sum Team Games",
      "title_zh": "在异质零和团队博弈中计算事前均衡",
      "authors": [
        "Naming Liu",
        "Mingzhi Wang",
        "Xihuai Wang",
        "Weinan Zhang",
        "Yaodong Yang",
        "Youzhi Zhang",
        "Bo An",
        "Ying Wen"
      ],
      "abstract": "The ex ante equilibrium for two-team zero-sum games, where agents within each\nteam collaborate to compete against the opposing team, is known to be the best\na team can do for coordination. Many existing works on ex ante equilibrium\nsolutions are aiming to extend the scope of ex ante equilibrium solving to\nlarge-scale team games based on Policy Space Response Oracle (PSRO). However,\nthe joint team policy space constructed by the most prominent method, Team\nPSRO, cannot cover the entire team policy space in heterogeneous team games\nwhere teammates play distinct roles. Such insufficient policy expressiveness\ncauses Team PSRO to be trapped into a sub-optimal ex ante equilibrium with\nsignificantly higher exploitability and never converges to the global ex ante\nequilibrium. To find the global ex ante equilibrium without introducing\nadditional computational complexity, we first parameterize heterogeneous\npolicies for teammates, and we prove that optimizing the heterogeneous\nteammates' policies sequentially can guarantee a monotonic improvement in team\nrewards. We further propose Heterogeneous-PSRO (H-PSRO), a novel framework for\nheterogeneous team games, which integrates the sequential correlation mechanism\ninto the PSRO framework and serves as the first PSRO framework for\nheterogeneous team games. We prove that H-PSRO achieves lower exploitability\nthan Team PSRO in heterogeneous team games. Empirically, H-PSRO achieves\nconvergence in matrix heterogeneous games that are unsolvable by\nnon-heterogeneous baselines. Further experiments reveal that H-PSRO outperforms\nnon-heterogeneous baselines in both heterogeneous team games and homogeneous\nsettings.",
      "tldr_zh": "这篇论文针对异构零和团队游戏，提出了一种新的框架 Heterogeneous-PSRO (H-PSRO)，旨在计算 ex ante equilibrium，以解决现有方法如 Team PSRO 在异构团队（队友角色不同）中无法覆盖完整政策空间的问题，导致次优平衡和高 exploitability。H-PSRO 通过参数化异构政策并顺序优化队友策略，确保团队奖励的单调改进，并将其整合到 PSRO 框架中。实验结果显示，H-PSRO 在矩阵异构游戏中实现收敛，并在异构和同构设置中均优于非异构基线模型。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01575v1",
      "published_date": "2024-10-02 14:12:00 UTC",
      "updated_date": "2024-10-02 14:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:11:20.465903"
    },
    {
      "arxiv_id": "2410.12830v3",
      "title": "Incorporating Metabolic Information into LLMs for Anomaly Detection in Clinical Time-Series",
      "title_zh": "将代谢信息整合到 LLMs 中，用于临床时间序列的异常检测",
      "authors": [
        "Maxx Richard Rahman",
        "Ruoxuan Liu",
        "Wolfgang Maass"
      ],
      "abstract": "Anomaly detection in clinical time-series holds significant potential in\nidentifying suspicious patterns in different biological parameters. In this\npaper, we propose a targeted method that incorporates the clinical domain\nknowledge into LLMs to improve their ability to detect anomalies. We introduce\nthe Metabolism Pathway-driven Prompting (MPP) method, which integrates the\ninformation about metabolic pathways to better capture the structural and\ntemporal changes in biological samples. We applied our method for doping\ndetection in sports, focusing on steroid metabolism, and evaluated using\nreal-world data from athletes. The results show that our method improves\nanomaly detection performance by leveraging metabolic context, providing a more\nnuanced and accurate prediction of suspicious samples in athletes' profiles.",
      "tldr_zh": "本论文提出了一种将代谢信息整合到 LLMs 中的方法，以提升临床时间序列异常检测的准确性。具体引入了 Metabolism Pathway-driven Prompting (MPP) 方法，该方法利用代谢途径信息捕捉生物样本的结构和时间变化。研究在体育兴奋剂检测（聚焦于 steroid metabolism）中应用，使用真实运动员数据进行评估，结果显示该方法通过代谢上下文显著提高了异常检测性能，提供更细致和准确的预测。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12830v3",
      "published_date": "2024-10-02 14:05:21 UTC",
      "updated_date": "2024-11-24 15:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:11:33.420446"
    },
    {
      "arxiv_id": "2410.01560v2",
      "title": "OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Toshniwal",
        "Wei Du",
        "Ivan Moshkov",
        "Branislav Kisacanin",
        "Alexan Ayrapetyan",
        "Igor Gitman"
      ],
      "abstract": "Mathematical reasoning continues to be a critical challenge in large language\nmodel (LLM) development with significant interest. However, most of the\ncutting-edge progress in mathematical reasoning with LLMs has become\n\\emph{closed-source} due to lack of access to training data. This lack of data\naccess limits researchers from understanding the impact of different choices\nfor synthesizing and utilizing the data. With the goal of creating a\nhigh-quality finetuning (SFT) dataset for math reasoning, we conduct careful\nablation experiments on data synthesis using the recently released\n\\texttt{Llama3.1} family of models. Our experiments show that: (a) solution\nformat matters, with excessively verbose solutions proving detrimental to SFT\nperformance, (b) data generated by a strong teacher outperforms equally-sized\ndata generated by a weak student model, (c) SFT is robust to low-quality\nsolutions, allowing for imprecise data filtering, and (d) question diversity is\ncrucial for achieving data scaling gains. Based on these insights, we create\nthe OpenMathInstruct-2 dataset, which consists of 14M question-solution pairs\n($\\approx$ 600K unique questions), making it nearly eight times larger than the\nprevious largest open-source math reasoning dataset. Finetuning the\n\\texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2 outperforms\n\\texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\\% (51.9\\%\n$\\rightarrow$ 67.8\\%). Finally, to accelerate the open-source efforts, we\nrelease the code, the finetuned models, and the OpenMathInstruct-2 dataset\nunder a commercially permissive license.",
      "tldr_zh": "这篇论文通过对数据合成进行消融实验，探讨了提升大型语言模型(LLM)数学推理性能的关键因素，包括解决方案格式、教师模型强度、数据质量鲁棒性和问题多样性。基于这些发现，作者创建了OpenMathInstruct-2数据集，包含约14M问题-解决方案对（约600K唯一问题），是现有最大开源数学数据集的八倍大。使用该数据集微调Llama-3.1-8B-Base模型，在MATH基准上比Llama3.1-8B-Instruct提升了15.9%（从51.9%到67.8%）。最后，作者开源了代码、微调模型和数据集，以促进开源数学AI的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01560v2",
      "published_date": "2024-10-02 14:00:09 UTC",
      "updated_date": "2024-10-05 03:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:11:45.032808"
    },
    {
      "arxiv_id": "2410.01556v4",
      "title": "Integrative Decoding: Improve Factuality via Implicit Self-consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Cheng",
        "Xiao Liang",
        "Yeyun Gong",
        "Wen Xiao",
        "Song Wang",
        "Yuji Zhang",
        "Wenjun Hou",
        "Kaishuai Xu",
        "Wenge Liu",
        "Wenjie Li",
        "Jian Jiao",
        "Qi Chen",
        "Peng Cheng",
        "Wayne Xiong"
      ],
      "abstract": "Self-consistency-based approaches, which involve repeatedly sampling multiple\noutputs and selecting the most consistent one as the final response, prove to\nbe remarkably effective in improving the factual accuracy of large language\nmodels. Nonetheless, existing methods usually have strict constraints on the\ntask format, largely limiting their applicability. In this paper, we present\nIntegrative Decoding (ID), to unlock the potential of self-consistency in\nopen-ended generation tasks. ID operates by constructing a set of inputs, each\nprepended with a previously sampled response, and then processes them\nconcurrently, with the next token being selected by aggregating of all their\ncorresponding predictions at each decoding step. In essence, this simple\napproach implicitly incorporates self-consistency in the decoding objective.\nExtensive evaluation shows that ID consistently enhances factuality over a wide\nrange of language models, with substantial improvements on the TruthfulQA\n(+11.2%), Biographies (+15.4%) and LongFact (+8.5%) benchmarks. The performance\ngains amplify progressively as the number of sampled responses increases,\nindicating the potential of ID to scale up with repeated sampling.",
      "tldr_zh": "该论文提出Integrative Decoding (ID) 方法，通过隐式self-consistency机制提升大语言模型的事实准确性，克服了现有self-consistency方法对任务格式的严格限制，使其适用于开放生成任务。ID的工作原理是构建一组输入，每个预加一个之前采样的响应，然后在每个解码步骤中并发处理并聚合所有预测来选择下一个标记，从而在解码目标中隐式整合self-consistency。实验结果显示，ID在TruthfulQA基准上提升11.2%、Biographies上提升15.4%、LongFact上提升8.5%，且性能随采样响应数量增加而显著放大，展示了其扩展潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01556v4",
      "published_date": "2024-10-02 13:52:55 UTC",
      "updated_date": "2025-01-23 13:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:11:56.119904"
    },
    {
      "arxiv_id": "2410.01553v1",
      "title": "MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zonghai Yao",
        "Zihao Zhang",
        "Chaolong Tang",
        "Xingyu Bian",
        "Youxia Zhao",
        "Zhichao Yang",
        "Junda Wang",
        "Huixue Zhou",
        "Won Seok Jang",
        "Feiyun Ouyang",
        "Hong Yu"
      ],
      "abstract": "Artificial intelligence (AI) and large language models (LLMs) in healthcare\nrequire advanced clinical skills (CS), yet current benchmarks fail to evaluate\nthese comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by\nmedical education's Objective Structured Clinical Examinations (OSCEs), to\naddress this gap. MedQA-CS evaluates LLMs through two instruction-following\ntasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real\nclinical scenarios. Our contributions include developing MedQA-CS, a\ncomprehensive evaluation framework with publicly available data and expert\nannotations, and providing the quantitative and qualitative assessment of LLMs\nas reliable judges in CS evaluation. Our experiments show that MedQA-CS is a\nmore challenging benchmark for evaluating clinical skills than traditional\nmultiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,\nMedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities\nfor both open- and closed-source LLMs.",
      "tldr_zh": "本研究引入了MedQA-CS，这是一个基于AI-SCE框架的基准测试工具，受医疗教育中Objective Structured Clinical Examinations (OSCEs)启发，用于全面评估Large Language Models (LLMs)的临床技能 (CS)。MedQA-CS通过两个指令遵循任务——LLM-as-medical-student和LLM-as-CS-examiner——模拟真实临床场景，并提供公开数据和专家注解来进行定量和定性评估。实验结果显示，MedQA-CS比传统多选问答基准（如MedQA）更具挑战性，并能与现有基准结合，全面评估开源和闭源LLMs的临床能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01553v1",
      "published_date": "2024-10-02 13:47:17 UTC",
      "updated_date": "2024-10-02 13:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:12:08.000806"
    },
    {
      "arxiv_id": "2410.14790v2",
      "title": "SSL-NBV: A Self-Supervised-Learning-Based Next-Best-View algorithm for Efficient 3D Plant Reconstruction by a Robot",
      "title_zh": "SSL-NBV：一种基于自监督学习的下一最佳视图算法，用于机器人高效的3D植物重建",
      "authors": [
        "Jianchao Ci",
        "Eldert J. van Henten",
        "Xin Wang",
        "Akshay K. Burusa",
        "Gert Kootstra"
      ],
      "abstract": "The 3D reconstruction of plants is challenging due to their complex shape\ncausing many occlusions. Next-Best-View (NBV) methods address this by\niteratively selecting new viewpoints to maximize information gain (IG).\nDeep-learning-based NBV (DL-NBV) methods demonstrate higher computational\nefficiency over classic voxel-based NBV approaches but current methods require\nextensive training using ground-truth plant models, making them impractical for\nreal-world plants. These methods, moreover, rely on offline training with\npre-collected data, limiting adaptability in changing agricultural\nenvironments. This paper proposes a self-supervised learning-based NBV method\n(SSL-NBV) that uses a deep neural network to predict the IG for candidate\nviewpoints. The method allows the robot to gather its own training data during\ntask execution by comparing new 3D sensor data to the earlier gathered data and\nby employing weakly-supervised learning and experience replay for efficient\nonline learning. Comprehensive evaluations were conducted in simulation and\nreal-world environments using cross-validation. The results showed that SSL-NBV\nrequired fewer views for plant reconstruction than non-NBV methods and was over\n800 times faster than a voxel-based method. SSL-NBV reduced training\nannotations by over 90% compared to a baseline DL-NBV. Furthermore, SSL-NBV\ncould adapt to novel scenarios through online fine-tuning. Also using real\nplants, the results showed that the proposed method can learn to effectively\nplan new viewpoints for 3D plant reconstruction. Most importantly, SSL-NBV\nautomated the entire network training and uses continuous online learning,\nallowing it to operate in changing agricultural environments.",
      "tldr_zh": "本研究针对植物复杂形状导致的遮挡问题，提出了一种基于Self-Supervised Learning的自监督学习NBV（Next-Best-View）算法SSL-NBV，用于机器人高效进行3D植物重建。该算法使用深度神经网络预测候选视角的信息增益（Information Gain），并通过机器人实时收集数据、弱监督学习和经验回放实现在线学习，从而避免了传统DL-NBV方法依赖大量地面实况数据的缺点。在模拟和真实环境中评估显示，SSL-NBV比非NBV方法需要更少的视角，比体素方法快800倍，并减少90%的训练标注，同时支持在线微调以适应变化的农业环境。总的来说，该方法自动化了网络训练过程，提升了3D重建的效率和适应性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 11 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2410.14790v2",
      "published_date": "2024-10-02 13:42:38 UTC",
      "updated_date": "2024-10-31 09:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:12:20.121098"
    },
    {
      "arxiv_id": "2410.01540v3",
      "title": "Edge-preserving noise for diffusion models",
      "title_zh": "边缘保持噪声用于扩散模型",
      "authors": [
        "Jente Vandersanden",
        "Sascha Holl",
        "Xingchang Huang",
        "Gurprit Singh"
      ],
      "abstract": "Classical generative diffusion models learn an isotropic Gaussian denoising\nprocess, treating all spatial regions uniformly, thus neglecting potentially\nvaluable structural information in the data. Inspired by the long-established\nwork on anisotropic diffusion in image processing, we present a novel\nedge-preserving diffusion model that generalizes over existing isotropic models\nby considering a hybrid noise scheme. In particular, we introduce an edge-aware\nnoise scheduler that varies between edge-preserving and isotropic Gaussian\nnoise. We show that our model's generative process converges faster to results\nthat more closely match the target distribution. We demonstrate its capability\nto better learn the low-to-mid frequencies within the dataset, which plays a\ncrucial role in representing shapes and structural information. Our\nedge-preserving diffusion process consistently outperforms state-of-the-art\nbaselines in unconditional image generation. It is also particularly more\nrobust for generative tasks guided by a shape-based prior, such as\nstroke-to-image generation. We present qualitative and quantitative results\n(FID and CLIP score) showing consistent improvements of up to 30% for both\ntasks.",
      "tldr_zh": "这篇论文针对传统生成扩散模型（diffusion models）使用各向同性高斯噪声（isotropic Gaussian noise）而忽略数据结构信息的问题，提出了一种新型边缘保留扩散模型。模型引入边缘感知噪声调度器（edge-aware noise scheduler），采用混合噪声方案，使生成过程更快收敛并更好地学习数据集中的低到中频信息，从而更准确地表示形状和结构。实验结果显示，该模型在无条件图像生成和基于形状的生成任务（如笔画到图像生成）中，优于现有基准，FID 和 CLIP score 改善高达 30%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01540v3",
      "published_date": "2024-10-02 13:29:52 UTC",
      "updated_date": "2025-04-19 12:43:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:12:32.631942"
    },
    {
      "arxiv_id": "2410.01532v3",
      "title": "Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Angela Lopez-Cardona",
        "Carlos Segura",
        "Alexandros Karatzoglou",
        "Sergi Abadal",
        "Ioannis Arapakis"
      ],
      "abstract": "Advancements in Natural Language Processing (NLP), have led to the emergence\nof Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which\nexcel across a range of tasks but require extensive fine-tuning to align their\noutputs with human expectations. A widely used method for achieving this\nalignment is Reinforcement Learning from Human Feedback (RLHF), which, despite\nits success, faces challenges in accurately modelling human preferences. In\nthis paper, we introduce GazeReward, a novel framework that integrates implicit\nfeedback -- and specifically eye-tracking (ET) data -- into the Reward Model\n(RM). In addition, we explore how ET-based features can provide insights into\nuser preferences. Through ablation studies we test our framework with different\nintegration methods, LLMs, and ET generator models, demonstrating that our\napproach significantly improves the accuracy of the RM on established human\npreference datasets. This work advances the ongoing discussion on optimizing AI\nalignment with human values, exploring the potential of cognitive data for\nshaping future NLP research.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）输出与人类期望的错位问题，提出GazeReward框架，使用眼动追踪（ET）数据作为隐式反馈来增强Reward Model（RM），从而改善Reinforcement Learning from Human Feedback（RLHF）的准确性。通过消融研究，该框架在不同整合方法、LLMs和ET生成模型上进行了测试，结果显示其显著提高了RM在人类偏好数据集上的表现。该工作为优化AI与人类价值的对齐提供了新见解，并探索了认知数据在NLP研究中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01532v3",
      "published_date": "2024-10-02 13:24:56 UTC",
      "updated_date": "2025-03-29 11:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:12:43.805060"
    },
    {
      "arxiv_id": "2410.01531v2",
      "title": "TiVaT: A Transformer with a Single Unified Mechanism for Capturing Asynchronous Dependencies in Multivariate Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Junwoo Ha",
        "Hyukjae Kwon",
        "Sungsoo Kim",
        "Kisu Lee",
        "Seungjae Park",
        "Ha Young Kim"
      ],
      "abstract": "Multivariate time series (MTS) forecasting is vital across various domains\nbut remains challenging due to the need to simultaneously model temporal and\ninter-variate dependencies. Existing channel-dependent models, where\nTransformer-based models dominate, process these dependencies separately,\nlimiting their capacity to capture complex interactions such as lead-lag\ndynamics. To address this issue, we propose TiVaT (Time-variate Transformer), a\nnovel architecture incorporating a single unified module, a Joint-Axis (JA)\nattention module, that concurrently processes temporal and variate modeling.\nThe JA attention module dynamically selects relevant features to particularly\ncapture asynchronous interactions. In addition, we introduce distance-aware\ntime-variate sampling in the JA attention, a novel mechanism that extracts\nsignificant patterns through a learned 2D embedding space while reducing noise.\nExtensive experiments demonstrate TiVaT's overall performance across diverse\ndatasets, particularly excelling in scenarios with intricate asynchronous\ndependencies.",
      "tldr_zh": "这篇论文针对多变量时间序列 (Multivariate Time Series) 预测的挑战，提出了一种新型 Transformer 模型 TiVaT，以单一统一的机制同时捕获时间和变量间的异步依赖。TiVaT 核心是 Joint-Axis (JA) attention 模块，该模块动态选择相关特征，处理复杂交互如 lead-lag 动态。论文还引入了 distance-aware time-variate sampling 机制，通过学习的 2D 嵌入空间提取显著模式并减少噪声。实验结果表明，TiVaT 在多种数据集上表现出色，尤其在涉及复杂异步依赖的场景中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "15pages",
      "pdf_url": "http://arxiv.org/pdf/2410.01531v2",
      "published_date": "2024-10-02 13:24:24 UTC",
      "updated_date": "2025-01-31 02:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:12:56.927871"
    },
    {
      "arxiv_id": "2410.03762v1",
      "title": "Getting in the Door: Streamlining Intake in Civil Legal Services with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Quinten Steenhuis",
        "Hannes Westermann"
      ],
      "abstract": "Legal intake, the process of finding out if an applicant is eligible for help\nfrom a free legal aid program, takes significant time and resources. In part\nthis is because eligibility criteria are nuanced, open-textured, and require\nfrequent revision as grants start and end. In this paper, we investigate the\nuse of large language models (LLMs) to reduce this burden. We describe a\ndigital intake platform that combines logical rules with LLMs to offer\neligibility recommendations, and we evaluate the ability of 8 different LLMs to\nperform this task. We find promising results for this approach to help close\nthe access to justice gap, with the best model reaching an F1 score of .82,\nwhile minimizing false negatives.",
      "tldr_zh": "该论文探讨了使用大型语言模型(LLMs)来简化民事法律服务的摄入过程，该过程因资格标准细微且经常变化而耗费大量资源。研究开发了一个数字平台，将逻辑规则与LLMs结合，提供资格推荐，并评估了8个不同LLMs的性能。结果显示，最佳模型的F1分数达到0.82，同时最小化了假阴性，这有助于有效缩小司法准入差距。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03762v1",
      "published_date": "2024-10-02 13:20:14 UTC",
      "updated_date": "2024-10-02 13:20:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:13:07.755159"
    },
    {
      "arxiv_id": "2410.01512v1",
      "title": "InstaTrans: An Instruction-Aware Translation Framework for Non-English Instruction Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Yungi Kim",
        "Chanjun Park"
      ],
      "abstract": "It is challenging to generate high-quality instruction datasets for\nnon-English languages due to tail phenomena, which limit performance on less\nfrequently observed data. To mitigate this issue, we propose translating\nexisting high-quality English instruction datasets as a solution, emphasizing\nthe need for complete and instruction-aware translations to maintain the\ninherent attributes of these datasets. We claim that fine-tuning LLMs with\ndatasets translated in this way can improve their performance in the target\nlanguage. To this end, we introduces a new translation framework tailored for\ninstruction datasets, named InstaTrans (INSTruction-Aware TRANSlation). Through\nextensive experiments, we demonstrate the superiority of InstaTrans over other\ncompetitors in terms of completeness and instruction-awareness of translation,\nhighlighting its potential to broaden the accessibility of LLMs across diverse\nlanguages at a relatively low cost. Furthermore, we have validated that\nfine-tuning LLMs with datasets translated by InstaTrans can effectively improve\ntheir performance in the target language.",
      "tldr_zh": "该研究针对非英语语言指令数据集生成面临的挑战（如尾部现象导致的性能下降），提出InstaTrans框架，这是一种指令感知的翻译方法，用于翻译高质量英语指令数据集，以保持其固有属性。InstaTrans通过强调翻译的完整性和指令-awareness，显著优于其他竞争框架，能够以较低成本扩展LLMs在多种语言中的可访问性。实验验证显示，使用InstaTrans翻译的数据集进行LLMs微调，能有效提升目标语言的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01512v1",
      "published_date": "2024-10-02 13:02:23 UTC",
      "updated_date": "2024-10-02 13:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:13:19.879945"
    },
    {
      "arxiv_id": "2410.01506v4",
      "title": "Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion",
      "title_zh": "用于",
      "authors": [
        "Dexuan Ding",
        "Lei Wang",
        "Liyun Zhu",
        "Tom Gedeon",
        "Piotr Koniusz"
      ],
      "abstract": "In computer vision tasks, features often come from diverse representations,\ndomains (e.g., indoor and outdoor), and modalities (e.g., text, images, and\nvideos). Effectively fusing these features is essential for robust performance,\nespecially with the availability of powerful pre-trained models like\nvision-language models. However, common fusion methods, such as concatenation,\nelement-wise operations, and non-linear techniques, often fail to capture\nstructural relationships, deep feature interactions, and suffer from\ninefficiency or misalignment of features across domains or modalities. In this\npaper, we shift from high-dimensional feature space to a lower-dimensional,\ninterpretable graph space by constructing relationship graphs that encode\nfeature relationships at different levels, e.g., clip, frame, patch, token,\netc. To capture deeper interactions, we expand graphs through iterative graph\nrelationship updates and introduce a learnable graph fusion operator to\nintegrate these expanded relationships for more effective fusion. Our approach\nis relationship-centric, operates in a homogeneous space, and is mathematically\nprincipled, resembling element-wise relationship score aggregation via\nmultilinear polynomials. We demonstrate the effectiveness of our graph-based\nfusion method on video anomaly detection, showing strong performance across\nmulti-representational, multi-modal, and multi-domain feature fusion tasks.",
      "tldr_zh": "本研究针对计算机视觉任务中多模态特征融合的挑战，指出现有方法如连接或元素级操作难以捕获结构关系和深度交互，并提出一种可学习的图操作符扩展方法。方法通过构建关系图编码不同级别特征（如帧、补丁）的关系，并利用迭代图更新和图融合操作符在低维同质空间中整合这些关系，实现更有效的特征融合。该方法数学上基于多线性多项式聚合关系分数，并在视频异常检测任务上表现出色，显著提升了多表示、多模态和多领域特征融合的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.01506v4",
      "published_date": "2024-10-02 12:58:55 UTC",
      "updated_date": "2025-02-28 13:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:13:32.718893"
    },
    {
      "arxiv_id": "2410.01500v2",
      "title": "Discrete Diffusion Schrödinger Bridge Matching for Graph Transformation",
      "title_zh": "用于图变换的离散扩散施罗丁格桥匹配",
      "authors": [
        "Jun Hyeong Kim",
        "Seonghwan Kim",
        "Seokhyun Moon",
        "Hyeongwoo Kim",
        "Jeheon Woo",
        "Woo Youn Kim"
      ],
      "abstract": "Transporting between arbitrary distributions is a fundamental goal in\ngenerative modeling. Recently proposed diffusion bridge models provide a\npotential solution, but they rely on a joint distribution that is difficult to\nobtain in practice. Furthermore, formulations based on continuous domains limit\ntheir applicability to discrete domains such as graphs. To overcome these\nlimitations, we propose Discrete Diffusion Schr\\\"odinger Bridge Matching\n(DDSBM), a novel framework that utilizes continuous-time Markov chains to solve\nthe SB problem in a high-dimensional discrete state space. Our approach extends\nIterative Markovian Fitting to discrete domains, and we have proved its\nconvergence to the SB. Furthermore, we adapt our framework for the graph\ntransformation, and show that our design choice of underlying dynamics\ncharacterized by independent modifications of nodes and edges can be\ninterpreted as the entropy-regularized version of optimal transport with a cost\nfunction described by the graph edit distance. To demonstrate the effectiveness\nof our framework, we have applied DDSBM to molecular optimization in the field\nof chemistry. Experimental results demonstrate that DDSBM effectively optimizes\nmolecules' property-of-interest with minimal graph transformation, successfully\nretaining other features. Source code is available\n$\\href{https://github.com/junhkim1226/DDSBM}{here}$.",
      "tldr_zh": "本论文提出 Discrete Diffusion Schrödinger Bridge Matching (DDSBM) 框架，用于在离散域（如图）之间传输分布，解决了传统扩散桥模型依赖联合分布和仅适用于连续域的局限性。DDSBM 利用连续时间 Markov chains 扩展 Iterative Markovian Fitting 方法，并证明其收敛到 Schrödinger Bridge 问题。框架通过独立修改节点和边的底层动态，实现熵正则化的最优传输，成本函数基于 graph edit distance。在化学领域的分子优化实验中，DDSBM 有效提升了分子属性，同时最小化图变换并保留其他特征。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01500v2",
      "published_date": "2024-10-02 12:51:25 UTC",
      "updated_date": "2025-02-28 08:55:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:13:44.175962"
    },
    {
      "arxiv_id": "2410.01497v2",
      "title": "DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic, Lightweight Plugin for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Zhang",
        "Ruizhe Li"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have achieved robust\nperformance across diverse tasks, but fine-tuning these models for specific\ndomains remains resource-intensive. Parameter-Efficient Fine-Tuning (PEFT)\nmethods like Low-Rank Adaptation (LoRA) address this challenge by fine-tuning a\nsmall subset of parameters. However, existing methods for fusing multiple LoRAs\nlack dynamic fusion based on contextual inputs and often increase inference\ntime due to token-level operations. We propose DLP-LoRA, a Dynamic Lightweight\nPlugin that employs a mini-MLP module with only 5M parameters to dynamically\nfuse multiple LoRAs at the sentence level using top-p sampling strategies. This\napproach reduces inference time to less than twice that of single LoRA\ninference by leveraging parallel computation. Evaluations across 26\ntasks-including multiple-choice questions and question answering-demonstrate\nthat DLP-LoRA achieves an average accuracy of 92.34% on multiple-choice\ndatasets and significant improvements in BLEU and ROUGE scores on QA datasets,\noutperforming different LLMs backbones under composite task settings. DLP-LoRA\neffectively balances performance and efficiency, making it a practical solution\nfor dynamic multi-task adaptation in LLMs. Our code is available at\nhttps://github.com/MeCuping/DLP-LoRA.",
      "tldr_zh": "本论文提出 DLP-LoRA，一种高效的任务特定 LoRA 融合方法，使用一个仅 5M 参数的动态轻量插件（Dynamic Lightweight Plugin），通过 mini-MLP 模块和 top-p sampling 在句子级别动态融合多个 LoRA，从而减少推理时间到不到单 LoRA 的两倍，并支持并行计算。相比现有 PEFT 方法，DLP-LoRA 解决了缺乏上下文动态融合的问题，提升了 Large Language Models (LLMs) 的多任务适应性。在 26 个任务的评估中，该方法在多选题数据集上达到 92.34% 的平均准确率，并在问答任务上显著提升 BLEU 和 ROUGE 分数，整体性能优于不同 LLM 骨干模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint under review, 18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01497v2",
      "published_date": "2024-10-02 12:45:52 UTC",
      "updated_date": "2025-02-18 11:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:13:56.472431"
    },
    {
      "arxiv_id": "2410.01482v1",
      "title": "One Wave to Explain Them All: A Unifying Perspective on Post-hoc Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Kasmi",
        "Amandine Brunetto",
        "Thomas Fel",
        "Jayneel Parekh"
      ],
      "abstract": "Despite the growing use of deep neural networks in safety-critical\ndecision-making, their inherent black-box nature hinders transparency and\ninterpretability. Explainable AI (XAI) methods have thus emerged to understand\na model's internal workings, and notably attribution methods also called\nsaliency maps. Conventional attribution methods typically identify the\nlocations -- the where -- of significant regions within an input. However,\nbecause they overlook the inherent structure of the input data, these methods\noften fail to interpret what these regions represent in terms of structural\ncomponents (e.g., textures in images or transients in sounds). Furthermore,\nexisting methods are usually tailored to a single data modality, limiting their\ngeneralizability. In this paper, we propose leveraging the wavelet domain as a\nrobust mathematical foundation for attribution. Our approach, the Wavelet\nAttribution Method (WAM) extends the existing gradient-based feature\nattributions into the wavelet domain, providing a unified framework for\nexplaining classifiers across images, audio, and 3D shapes. Empirical\nevaluations demonstrate that WAM matches or surpasses state-of-the-art methods\nacross faithfulness metrics and models in image, audio, and 3D explainability.\nFinally, we show how our method explains not only the where -- the important\nparts of the input -- but also the what -- the relevant patterns in terms of\nstructural components.",
      "tldr_zh": "尽管深度神经网络在安全决策中广泛应用，但其黑盒性质阻碍了透明度和可解释性，现有的 attribution methods 和 saliency maps 通常只识别输入中的重要区域（where），而忽略了结构组件（如图像纹理或音频瞬变）的含义，且限于单一数据模态。  \n本文提出 Wavelet Attribution Method (WAM)，通过将梯度-based 特征归因扩展到 wavelet domain，提供一个统一的框架，用于解释图像、音频和 3D 形状等分类器的内部工作机制。  \nWAM 不仅解释重要部分（where），还揭示相关模式和结构组件（what），实验结果显示其在 faithfulness metrics 上匹配或超过最先进方法，为跨模态的可解释 AI 奠定了基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "main: 10 pages, appendix: 14 pages, 5 Tables, 25 Figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01482v1",
      "published_date": "2024-10-02 12:34:04 UTC",
      "updated_date": "2024-10-02 12:34:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:14:08.547635"
    },
    {
      "arxiv_id": "2410.01481v2",
      "title": "SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios",
      "title_zh": "SonicSim: 一种用于移动声源场景的语音处理可定制模拟平台",
      "authors": [
        "Kai Li",
        "Wendi Sang",
        "Chang Zeng",
        "Runxuan Yang",
        "Guo Chen",
        "Xiaolin Hu"
      ],
      "abstract": "Systematic evaluation of speech separation and enhancement models under\nmoving sound source conditions requires extensive and diverse data. However,\nreal-world datasets often lack sufficient data for training and evaluation, and\nsynthetic datasets, while larger, lack acoustic realism. Consequently, neither\neffectively meets practical needs. To address this issue, we introduce\nSonicSim, a synthetic toolkit based on the embodied AI simulation platform\nHabitat-sim, designed to generate highly customizable data for moving sound\nsources. SonicSim supports multi-level adjustments, including scene-level,\nmicrophone-level, and source-level adjustments, enabling the creation of more\ndiverse synthetic data. Leveraging SonicSim, we constructed a benchmark dataset\ncalled SonicSet, utilizing LibriSpeech, Freesound Dataset 50k (FSD50K), Free\nMusic Archive (FMA), and 90 scenes from Matterport3D to evaluate speech\nseparation and enhancement models. Additionally, to investigate the differences\nbetween synthetic and real-world data, we selected 5 hours of raw,\nnon-reverberant data from the SonicSet validation set and recorded a real-world\nspeech separation dataset, providing a reference for comparing SonicSet with\nother synthetic datasets. For speech enhancement, we utilized the real-world\ndataset RealMAN to validate the acoustic gap between SonicSet and existing\nsynthetic datasets. The results indicate that models trained on SonicSet\ngeneralize better to real-world scenarios compared to other synthetic datasets.\nThe code is publicly available at https://cslikai.cn/SonicSim/.",
      "tldr_zh": "该研究提出SonicSim，一种基于Habitat-sim的合成工具包，用于生成高度可自定义的移动声源语音处理数据，以解决真实数据集不足和合成数据集缺乏真实感的问题。SonicSim支持场景级、麦克风级和声源级的多级别调整，并基于此构建了SonicSet基准数据集，利用LibriSpeech、FSD50K、FMA和Matterport3D等资源来评估speech separation和speech enhancement模型。实验结果显示，在SonicSet上训练的模型相比其他合成数据集，在真实场景中具有更好的泛化性能，为语音处理研究提供了可公开代码的实用平台（代码地址：https://cslikai.cn/SonicSim/）。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01481v2",
      "published_date": "2024-10-02 12:33:59 UTC",
      "updated_date": "2025-03-06 04:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:14:20.901743"
    },
    {
      "arxiv_id": "2410.01470v1",
      "title": "Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders",
      "title_zh": "翻译失败",
      "authors": [
        "Andreea Iana",
        "Goran Glavaš",
        "Heiko Paulheim"
      ],
      "abstract": "Encoder architectures play a pivotal role in neural news recommenders by\nembedding the semantic and contextual information of news and users. Thus,\nresearch has heavily focused on enhancing the representational capabilities of\nnews and user encoders to improve recommender performance. Despite the\nsignificant impact of encoder architectures on the quality of news and user\nrepresentations, existing analyses of encoder designs focus only on the overall\ndownstream recommendation performance. This offers a one-sided assessment of\nthe encoders' similarity, ignoring more nuanced differences in their behavior,\nand potentially resulting in sub-optimal model selection. In this work, we\nperform a comprehensive analysis of encoder architectures in neural news\nrecommender systems. We systematically evaluate the most prominent news and\nuser encoder architectures, focusing on their (i) representational similarity,\nmeasured with the Central Kernel Alignment, (ii) overlap of generated\nrecommendation lists, quantified with the Jaccard similarity, and (iii) the\noverall recommendation performance. Our analysis reveals that the complexity of\ncertain encoding techniques is often empirically unjustified, highlighting the\npotential for simpler, more efficient architectures. By isolating the effects\nof individual components, we provide valuable insights for researchers and\npractitioners to make better informed decisions about encoder selection and\navoid unnecessary complexity in the design of news recommenders.",
      "tldr_zh": "本文对神经新闻推荐系统中的编码器架构进行了深入评估，焦点在于其代表性相似性（Central Kernel Alignment）、推荐列表重叠（Jaccard similarity）和整体推荐性能。研究发现，许多复杂编码技术的使用在经验上缺乏充分 justification，表明更简单高效的架构可能同样有效。通过系统隔离各个组件的影响，该工作为研究者和从业者提供宝贵见解，帮助他们在设计新闻推荐器时避免不必要的复杂性，并优化模型选择。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.3.3; I.2.7"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at the 12th International Workshop on News Recommendation\n  and Analytics (INRA 2024) in conjunction with ACM RecSys 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.01470v1",
      "published_date": "2024-10-02 12:21:31 UTC",
      "updated_date": "2024-10-02 12:21:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:14:32.540833"
    },
    {
      "arxiv_id": "2410.01469v2",
      "title": "TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation",
      "title_zh": "翻译失败",
      "authors": [
        "Mohan Xu",
        "Kai Li",
        "Guo Chen",
        "Xiaolin Hu"
      ],
      "abstract": "In recent years, much speech separation research has focused primarily on\nimproving model performance. However, for low-latency speech processing\nsystems, high efficiency is equally important. Therefore, we propose a speech\nseparation model with significantly reduced parameters and computational costs:\nTime-frequency Interleaved Gain Extraction and Reconstruction network (TIGER).\nTIGER leverages prior knowledge to divide frequency bands and compresses\nfrequency information. We employ a multi-scale selective attention module to\nextract contextual features while introducing a full-frequency-frame attention\nmodule to capture both temporal and frequency contextual information.\nAdditionally, to more realistically evaluate the performance of speech\nseparation models in complex acoustic environments, we introduce a dataset\ncalled EchoSet. This dataset includes noise and more realistic reverberation\n(e.g., considering object occlusions and material properties), with speech from\ntwo speakers overlapping at random proportions. Experimental results showed\nthat models trained on EchoSet had better generalization ability than those\ntrained on other datasets compared to the data collected in the physical world,\nwhich validated the practical value of the EchoSet. On EchoSet and real-world\ndata, TIGER significantly reduces the number of parameters by 94.3% and the\nMACs by 95.3% while achieving performance surpassing the state-of-the-art\n(SOTA) model TF-GridNet.",
      "tldr_zh": "本研究提出了一种高效语音分离模型TIGER（Time-frequency Interleaved Gain Extraction and Reconstruction），旨在减少参数和计算成本，同时提升性能。TIGER利用先验知识分隔频带并压缩频率信息，结合多尺度选择性注意力模块和全频帧注意力模块来提取时频上下文特征。研究者引入了新数据集EchoSet，该数据集包含噪声和更真实的混响（如物体遮挡和材料属性），用于评估模型在复杂声学环境下的泛化能力。实验结果显示，TIGER在EchoSet和真实数据上参数减少94.3%、MACs减少95.3%，并超越SOTA模型TF-GridNet的性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICLR 2025, demo page: https://cslikai.cn/TIGER/",
      "pdf_url": "http://arxiv.org/pdf/2410.01469v2",
      "published_date": "2024-10-02 12:21:06 UTC",
      "updated_date": "2025-03-06 04:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:14:44.198893"
    },
    {
      "arxiv_id": "2410.13871v2",
      "title": "Explaining an image classifier with a generative model conditioned by uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Adrien LeCoz",
        "Stéphane Herbin",
        "Faouzi Adjed"
      ],
      "abstract": "We propose to condition a generative model by a given image classifier\nuncertainty in order to analyze and explain its behavior. Preliminary\nexperiments on synthetic data and a corrupted version of MNIST dataset\nillustrate the idea.",
      "tldr_zh": "本研究提出了一种新方法，使用不确定性（uncertainty）条件化的生成模型（generative model）来分析和解释图像分类器（image classifier）的行为，从而提升模型的可解释性。方法的核心是将生成模型基于分类器的不确定性进行训练，以揭示其决策过程。初步实验在合成数据和被破坏的 MNIST dataset 上验证了这一想法，展示了该方法的潜在有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13871v2",
      "published_date": "2024-10-02 12:14:31 UTC",
      "updated_date": "2024-11-05 09:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:14:55.047059"
    },
    {
      "arxiv_id": "2410.01458v1",
      "title": "From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with LLM-Guided Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Xiefeng Wu"
      ],
      "abstract": "Q-shaping is an extension of Q-value initialization and serves as an\nalternative to reward shaping for incorporating domain knowledge to accelerate\nagent training, thereby improving sample efficiency by directly shaping\nQ-values. This approach is both general and robust across diverse tasks,\nallowing for immediate impact assessment while guaranteeing optimality. We\nevaluated Q-shaping across 20 different environments using a large language\nmodel (LLM) as the heuristic provider. The results demonstrate that Q-shaping\nsignificantly enhances sample efficiency, achieving a \\textbf{16.87\\%}\nimprovement over the best baseline in each environment and a \\textbf{253.80\\%}\nimprovement compared to LLM-based reward shaping methods. These findings\nestablish Q-shaping as a superior and unbiased alternative to conventional\nreward shaping in reinforcement learning.",
      "tldr_zh": "本研究提出 Q-shaping 作为一种扩展 Q-value 初始化方法，用以取代传统 reward shaping，通过整合 LLM 引导的领域知识来加速代理训练并提高样本效率。该方法在各种任务中表现出通用性和鲁棒性，能立即评估影响并确保最优性，而不会引入偏置。在 20 个环境中进行的实验显示，Q-shaping 比最佳基线提升了 16.87% 的样本效率，并比 LLM-based reward shaping 方法提升了 253.80%，从而确立其作为 reinforcement learning 中更优的无偏替代方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "q-shaping, reinforcement learning, reward shaping",
      "pdf_url": "http://arxiv.org/pdf/2410.01458v1",
      "published_date": "2024-10-02 12:10:07 UTC",
      "updated_date": "2024-10-02 12:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:15:08.237778"
    },
    {
      "arxiv_id": "2410.01450v1",
      "title": "Agent-Driven Large Language Models for Mandarin Lyric Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hong-Hsiang Liu",
        "Yi-Wen Liu"
      ],
      "abstract": "Generative Large Language Models have shown impressive in-context learning\nabilities, performing well across various tasks with just a prompt. Previous\nmelody-to-lyric research has been limited by scarce high-quality aligned data\nand unclear standard for creativeness. Most efforts focused on general themes\nor emotions, which are less valuable given current language model capabilities.\nIn tonal contour languages like Mandarin, pitch contours are influenced by both\nmelody and tone, leading to variations in lyric-melody fit. Our study,\nvalidated by the Mpop600 dataset, confirms that lyricists and melody writers\nconsider this fit during their composition process. In this research, we\ndeveloped a multi-agent system that decomposes the melody-to-lyric task into\nsub-tasks, with each agent controlling rhyme, syllable count, lyric-melody\nalignment, and consistency. Listening tests were conducted via a\ndiffusion-based singing voice synthesizer to evaluate the quality of lyrics\ngenerated by different agent groups.",
      "tldr_zh": "这篇论文探讨了使用 Agent-Driven Large Language Models 生成普通话歌词的问题，针对旋律到歌词转换中的数据稀缺和创意标准不明确等挑战。研究开发了一个多智能体系统，将任务分解为子任务，包括控制 rhyme、syllable count、lyric-melody alignment 和一致性，并通过 Mpop600 数据集验证了歌词与旋律拟合的重要性。听力测试利用 diffusion-based singing voice synthesizer 评估不同智能体组生成的歌词质量，结果表明该方法显著提升了生成效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, figures, Accepted at O-COCOSDA 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.01450v1",
      "published_date": "2024-10-02 12:01:32 UTC",
      "updated_date": "2024-10-02 12:01:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:15:21.728540"
    },
    {
      "arxiv_id": "2410.01866v2",
      "title": "House of Cards: Massive Weights in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehoon Oh",
        "Seungjun Shin",
        "Dokwan Oh"
      ],
      "abstract": "Massive activations, which manifest in specific feature dimensions of hidden\nstates, introduce a significant bias in large language models (LLMs), leading\nto an overemphasis on the corresponding token. In this paper, we identify that\nmassive activations originate not from the hidden state but from the\nintermediate state of a feed-forward network module in an early layer.\nExpanding on the previous observation that massive activations occur only in\nspecific feature dimensions, we dive deep into the weights that cause massive\nactivations. Specifically, we define top-$k$ massive weights as the weights\nthat contribute to the dimensions with the top-$k$ magnitudes in the\nintermediate state. When these massive weights are set to zero, the\nfunctionality of LLMs is entirely disrupted. However, when all weights except\nfor massive weights are set to zero, it results in a relatively minor\nperformance drop, even though a much larger number of weights are set to zero.\nThis implies that during the pre-training process, learning is dominantly\nfocused on massive weights. Building on this observation, we propose a simple\nplug-and-play method called MacDrop (massive weights curriculum dropout), to\nrely less on massive weights during parameter-efficient fine-tuning. This\nmethod applies dropout to the pre-trained massive weights, starting with a high\ndropout probability and gradually decreasing it as fine-tuning progresses.\nThrough various experiments, including zero-shot downstream tasks, long-context\ntasks, and ablation studies, we demonstrate that \\texttt{MacDrop} generally\nimproves performance and strengthens robustness.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）中的 massive activations 问题，这些激活发生在隐藏状态的特定维度，导致模型过度强调对应标记，并追踪其根源至早期层前馈网络模块的 intermediate state 中的 massive weights。作者发现，训练过程主要依赖这些 massive weights，因为将其设置为零会完全破坏模型功能，而移除其他权重仅导致轻微性能下降。为减少对 massive weights 的依赖，提出了一种插件式方法 MacDrop，通过在参数高效微调中从高 dropout 概率逐步降低来增强模型鲁棒性。实验结果显示，MacDrop 在零样本下游任务、长上下文任务和消融研究中普遍提高了性能和稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2410.01866v2",
      "published_date": "2024-10-02 11:54:21 UTC",
      "updated_date": "2025-02-06 11:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:15:33.065807"
    },
    {
      "arxiv_id": "2410.01444v3",
      "title": "Geometric Signatures of Compositionality Across a Language Model's Lifetime",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Hwa Lee",
        "Thomas Jiralerspong",
        "Lei Yu",
        "Yoshua Bengio",
        "Emily Cheng"
      ],
      "abstract": "By virtue of linguistic compositionality, few syntactic rules and a finite\nlexicon can generate an unbounded number of sentences. That is, language,\nthough seemingly high-dimensional, can be explained using relatively few\ndegrees of freedom. An open question is whether contemporary language models\n(LMs) reflect the intrinsic simplicity of language that is enabled by\ncompositionality. We take a geometric view of this problem by relating the\ndegree of compositionality in a dataset to the intrinsic dimension (ID) of its\nrepresentations under an LM, a measure of feature complexity. We find not only\nthat the degree of dataset compositionality is reflected in representations'\nID, but that the relationship between compositionality and geometric complexity\narises due to learned linguistic features over training. Finally, our analyses\nreveal a striking contrast between nonlinear and linear dimensionality, showing\nthey respectively encode semantic and superficial aspects of linguistic\ncomposition.",
      "tldr_zh": "这篇论文探讨了语言模型（LMs）中语言组合性（compositionality）的几何特征，旨在检验模型是否捕捉到语言的内在简单性，即通过少量规则生成无限句子的能力。研究者通过分析数据集组合性与表示的内在维度（ID）——一个衡量特征复杂性的指标——之间的关系，发现这种组合性在模型训练过程中通过学习语言特征而体现出来。进一步分析显示，非线性维度编码了语义方面的语言组合，而线性维度则反映了表面的语言特征，从而揭示了LMs在处理语言复杂性时的几何签名。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review at ARR",
      "pdf_url": "http://arxiv.org/pdf/2410.01444v3",
      "published_date": "2024-10-02 11:54:06 UTC",
      "updated_date": "2025-02-07 03:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:15:45.579064"
    },
    {
      "arxiv_id": "2410.01865v1",
      "title": "Simplifying complex machine learning by linearly separable network embedding spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandros Xenos",
        "Noel-Malod Dognin",
        "Natasa Przulj"
      ],
      "abstract": "Low-dimensional embeddings are a cornerstone in the modelling and analysis of\ncomplex networks. However, most existing approaches for mining network\nembedding spaces rely on computationally intensive machine learning systems to\nfacilitate downstream tasks. In the field of NLP, word embedding spaces capture\nsemantic relationships \\textit{linearly}, allowing for information retrieval\nusing \\textit{simple linear operations} on word embedding vectors. Here, we\ndemonstrate that there are structural properties of network data that yields\nthis linearity. We show that the more homophilic the network representation,\nthe more linearly separable the corresponding network embedding space, yielding\nbetter downstream analysis results. Hence, we introduce novel graphlet-based\nmethods enabling embedding of networks into more linearly separable spaces,\nallowing for their better mining. Our fundamental insights into the structure\nof network data that enable their \\textit{\\textbf{linear}} mining and\nexploitation enable the ML community to build upon, towards efficiently and\nexplainably mining of the complex network data.",
      "tldr_zh": "本文提出，通过线性可分（linearly separable）的网络嵌入空间简化复杂机器学习，强调网络数据的结构特性（如同质性，homophilic）能使嵌入空间更易于线性操作，从而提升下游分析任务的性能。研究发现，网络同质性越高，对应的嵌入空间越线性可分，这借鉴了NLP中词嵌入的语义捕捉机制。作者引入新型基于图元的（graphlet-based）方法，将网络嵌入到更线性可分的空间中，实现更高效的网络挖掘。该方法为机器学习社区提供可解释的复杂网络数据利用框架。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG",
        "I.2; J.3"
      ],
      "primary_category": "cs.SI",
      "comment": "26 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01865v1",
      "published_date": "2024-10-02 11:41:17 UTC",
      "updated_date": "2024-10-02 11:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:16:00.831798"
    },
    {
      "arxiv_id": "2410.01423v1",
      "title": "Fair4Free: Generating High-fidelity Fair Synthetic Samples using Data Free Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Md Fahim Sikder",
        "Daniel de Leng",
        "Fredrik Heintz"
      ],
      "abstract": "This work presents Fair4Free, a novel generative model to generate synthetic\nfair data using data-free distillation in the latent space. Fair4Free can work\non the situation when the data is private or inaccessible. In our approach, we\nfirst train a teacher model to create fair representation and then distil the\nknowledge to a student model (using a smaller architecture). The process of\ndistilling the student model is data-free, i.e. the student model does not have\naccess to the training dataset while distilling. After the distillation, we use\nthe distilled model to generate fair synthetic samples. Our extensive\nexperiments show that our synthetic samples outperform state-of-the-art models\nin all three criteria (fairness, utility and synthetic quality) with a\nperformance increase of 5% for fairness, 8% for utility and 12% in synthetic\nquality for both tabular and image datasets.",
      "tldr_zh": "这篇论文提出了 Fair4Free，一种新型生成模型，通过 data-free distillation 在潜在空间生成高保真公平合成样本，适用于数据私有或不可访问的场景。方法包括先训练教师模型创建公平表示，然后将知识蒸馏到更小架构的学生模型中，整个蒸馏过程无需访问原始训练数据集。实验结果显示，生成的合成样本在公平性、utility 和 synthetic quality 三个指标上均优于现有模型，提高了5%（公平性）、8%（utility）和12%（synthetic quality），适用于表格和图像数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01423v1",
      "published_date": "2024-10-02 11:16:11 UTC",
      "updated_date": "2024-10-02 11:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:16:16.102142"
    },
    {
      "arxiv_id": "2410.01417v2",
      "title": "The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Li",
        "Nanxi Li",
        "Yuanjie Chen",
        "Jianbin Zhu",
        "Qinlu Guo",
        "Cewu Lu",
        "Yong-Lu Li"
      ],
      "abstract": "Multi-modal Large Language Models (MLLMs) have exhibited impressive\ncapability. However, recently many deficiencies of MLLMs have been found\ncompared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the\nMLLMs study, the community dedicated efforts to building larger benchmarks with\ncomplex tasks. In this paper, we propose benchmarking an essential but usually\noverlooked intelligence: $\\textbf{association}$, a human's basic capability to\nlink observation and prior practice memory. To comprehensively investigate\nMLLM's performance on the association, we formulate the association task and\ndevise a standard benchmark based on adjective and verb semantic concepts.\nInstead of costly data annotation and curation, we propose a convenient\n$\\textbf{annotation-free}$ construction method transforming the general dataset\nfor our association tasks. Simultaneously, we devise a rigorous data refinement\nprocess to eliminate confusion in the raw dataset. Building on this database,\nwe establish three levels of association tasks: single-step, synchronous, and\nasynchronous associations. Moreover, we conduct a comprehensive investigation\ninto the MLLMs' zero-shot association capabilities, addressing multiple\ndimensions, including three distinct memory strategies, both open-source and\nclosed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the\ninvolvement of human experts. Our systematic investigation shows that current\nopen-source MLLMs consistently exhibit poor capability in our association\ntasks, even the currently state-of-the-art GPT-4V(vision) also has a\nsignificant gap compared to humans. We believe our benchmark would pave the way\nfor future MLLM studies. $\\textit{Our data and code are available at:}$\nhttps://mvig-rhos.com/llm_inception.",
      "tldr_zh": "本论文探讨了多模态大语言模型 (MLLMs) 在联想 (association) 能力上的缺陷，该能力是人类将观察与记忆联系的基本智力。研究者提出了一种annotation-free的数据构建方法，并基于形容词和动词语义概念设计了一个标准benchmark，包括single-step、synchronous和asynchronous三种任务级别，以全面评估MLLMs的零样本联想性能。实验结果显示，当前开源MLLMs在这些任务上表现较差，即使是Mixture-of-Experts (MoE) 模型和GPT-4V也显著落后于人类水平。该benchmark有望为未来MLLMs研究铺平道路，并提供了开源数据和代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025. Project page:\n  https://mvig-rhos.com/llm_inception",
      "pdf_url": "http://arxiv.org/pdf/2410.01417v2",
      "published_date": "2024-10-02 10:58:54 UTC",
      "updated_date": "2025-03-03 00:41:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:16:24.605143"
    },
    {
      "arxiv_id": "2410.01413v1",
      "title": "Improving Fuzzy Rule Classifier with Brain Storm Optimization and Rule Modification",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Huang",
        "Wei Liu",
        "Xiaogang Zang"
      ],
      "abstract": "The expanding complexity and dimensionality in the search space can adversely\naffect inductive learning in fuzzy rule classifiers, thus impacting the\nscalability and accuracy of fuzzy systems. This research specifically addresses\nthe challenge of diabetic classification by employing the Brain Storm\nOptimization (BSO) algorithm to propose a novel fuzzy system that redefines\nrule generation for this context. An exponential model is integrated into the\nstandard BSO algorithm to enhance rule derivation, tailored specifically for\ndiabetes-related data. The innovative fuzzy system is then applied to\nclassification tasks involving diabetic datasets, demonstrating a substantial\nimprovement in classification accuracy, as evidenced by our experiments.",
      "tldr_zh": "该研究针对模糊规则分类器（Fuzzy Rule Classifier）在复杂高维搜索空间中的归纳学习挑战，特别是糖尿病分类问题，提出了一种改进方法。研究利用 Brain Storm Optimization (BSO) 算法并整合指数模型来重定义规则生成过程，从而增强规则推导的针对性和效率。在糖尿病数据集的分类任务中，实验结果显示，该创新模糊系统显著提高了分类准确率。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01413v1",
      "published_date": "2024-10-02 10:48:23 UTC",
      "updated_date": "2024-10-02 10:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:16:36.173596"
    },
    {
      "arxiv_id": "2410.01410v1",
      "title": "On the Convergence of FedProx with Extrapolation and Inexact Prox",
      "title_zh": "翻译失败",
      "authors": [
        "Hanmin Li",
        "Peter Richtárik"
      ],
      "abstract": "Enhancing the FedProx federated learning algorithm (Li et al., 2020) with\nserver-side extrapolation, Li et al. (2024a) recently introduced the FedExProx\nmethod. Their theoretical analysis, however, relies on the assumption that each\nclient computes a certain proximal operator exactly, which is impractical since\nthis is virtually never possible to do in real settings. In this paper, we\ninvestigate the behavior of FedExProx without this exactness assumption in the\nsmooth and globally strongly convex setting. We establish a general convergence\nresult, showing that inexactness leads to convergence to a neighborhood of the\nsolution. Additionally, we demonstrate that, with careful control, the adverse\neffects of this inexactness can be mitigated. By linking inexactness to biased\ncompression (Beznosikov et al., 2023), we refine our analysis, highlighting\nrobustness of extrapolation to inexact proximal updates. We also examine the\nlocal iteration complexity required by each client to achieved the required\nlevel of inexactness using various local optimizers. Our theoretical insights\nare validated through comprehensive numerical experiments.",
      "tldr_zh": "本论文分析了 FedExProx 方法（FedProx 的增强版，添加服务器端推断）在近端算子（proximal operator）不精确情况下的收敛行为，针对平滑且全局强凸设置。研究结果表明，不精确性会导致算法收敛到解决方案的邻域，但通过仔细控制参数，可以有效缓解其负面影响。论文进一步将不精确性与有偏压缩（biased compression）联系起来，证明了推断机制的鲁棒性，并评估了客户端使用各种局部优化器所需的迭代复杂性；这些理论见解通过全面数值实验得到验证。",
      "categories": [
        "math.OC",
        "cs.AI",
        "90C25"
      ],
      "primary_category": "math.OC",
      "comment": "36 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01410v1",
      "published_date": "2024-10-02 10:42:27 UTC",
      "updated_date": "2024-10-02 10:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:17:41.040585"
    },
    {
      "arxiv_id": "2410.05287v1",
      "title": "Hate Speech Detection Using Cross-Platform Social Media Data In English and German Language",
      "title_zh": "翻译失败",
      "authors": [
        "Gautam Kishore Shahi",
        "Tim A. Majchrzak"
      ],
      "abstract": "Hate speech has grown into a pervasive phenomenon, intensifying during times\nof crisis, elections, and social unrest. Multiple approaches have been\ndeveloped to detect hate speech using artificial intelligence, but a\ngeneralized model is yet unaccomplished. The challenge for hate speech\ndetection as text classification is the cost of obtaining high-quality training\ndata. This study focuses on detecting bilingual hate speech in YouTube comments\nand measuring the impact of using additional data from other platforms in the\nperformance of the classification model. We examine the value of additional\ntraining datasets from cross-platforms for improving the performance of\nclassification models. We also included factors such as content similarity,\ndefinition similarity, and common hate words to measure the impact of datasets\non performance. Our findings show that adding more similar datasets based on\ncontent similarity, hate words, and definitions improves the performance of\nclassification models. The best performance was obtained by combining datasets\nfrom YouTube comments, Twitter, and Gab with an F1-score of 0.74 and 0.68 for\nEnglish and German YouTube comments.",
      "tldr_zh": "本研究探讨了使用跨平台社交媒体数据检测英语和德语仇恨言论的问题，重点解决高质量训练数据获取的挑战。研究方法包括整合YouTube评论与其他平台（如Twitter和Gab）的数据，并评估内容相似性、定义相似性和常见仇恨词对模型性能的影响。结果显示，添加相似数据集显著提升了分类模型的表现，结合YouTube、Twitter和Gab的数据实现了最佳F1-score，分别为英语0.74和德语0.68。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05287v1",
      "published_date": "2024-10-02 10:22:53 UTC",
      "updated_date": "2024-10-02 10:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:16:59.079790"
    },
    {
      "arxiv_id": "2410.01396v1",
      "title": "Can We Delegate Learning to Automation?: A Comparative Study of LLM Chatbots, Search Engines, and Books",
      "title_zh": "翻译失败",
      "authors": [
        "Yeonsun Yang",
        "Ahyeon Shin",
        "Mincheol Kang",
        "Jiheon Kang",
        "Jean Young Song"
      ],
      "abstract": "Learning is a key motivator behind information search behavior. With the\nemergence of LLM-based chatbots, students are increasingly turning to these\ntools as their primary resource for acquiring knowledge. However, the\ntransition from traditional resources like textbooks and web searches raises\nconcerns among educators. They worry that these fully-automated LLMs might lead\nstudents to delegate critical steps of search as learning. In this paper, we\nsystematically uncover three main concerns from educators' perspectives. In\nresponse to these concerns, we conducted a mixed-methods study with 92\nuniversity students to compare three learning sources with different automation\nlevels. Our results show that LLMs support comprehensive understanding of key\nconcepts without promoting passive learning, though their effectiveness in\nknowledge retention was limited. Additionally, we found that academic\nperformance impacted both learning outcomes and search patterns. Notably,\nhigher-competence learners engaged more deeply with content through\nreading-intensive behaviors rather than relying on search activities.",
      "tldr_zh": "这篇论文探讨了学生是否能将学习过程委托给自动化工具，通过比较LLM chatbots、search engines和books作为学习资源的效果。研究者从教育者视角识别了三个主要担忧，包括学生可能忽略学习的关键步骤，并针对这些问题开展了涉及92名大学生的混合方法研究。结果显示，LLM chatbots有助于全面理解关键概念，但知识保留效果有限，且不会促进被动学习；此外，学术表现影响学习成果，高能力学习者更倾向于深入阅读而非依赖搜索行为。总的来说，该研究为评估自动化工具在教育中的作用提供了重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR",
        "K.3.2"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01396v1",
      "published_date": "2024-10-02 10:16:54 UTC",
      "updated_date": "2024-10-02 10:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:17:13.045052"
    },
    {
      "arxiv_id": "2410.01386v2",
      "title": "FLAME: Adaptive and Reactive Concept Drift Mitigation for Federated Learning Deployments",
      "title_zh": "翻译失败",
      "authors": [
        "Ioannis Mavromatis",
        "Stefano De Feo",
        "Aftab Khan"
      ],
      "abstract": "This paper presents Federated Learning with Adaptive Monitoring and\nElimination (FLAME), a novel solution capable of detecting and mitigating\nconcept drift in Federated Learning (FL) Internet of Things (IoT) environments.\nConcept drift poses significant challenges for FL models deployed in dynamic\nand real-world settings. FLAME leverages an FL architecture, considers a\nreal-world FL pipeline, and proves capable of maintaining model performance and\naccuracy while addressing bandwidth and privacy constraints. Introducing\nvarious features and extensions on previous works, FLAME offers a robust\nsolution to concept drift, significantly reducing computational load and\ncommunication overhead. Compared to well-known lightweight mitigation methods,\nFLAME demonstrates superior performance in maintaining high F1 scores and\nreducing resource utilisation in large-scale IoT deployments, making it a\npromising approach for real-world applications.",
      "tldr_zh": "本研究提出FLAME，一种自适应和响应式的框架，用于检测和缓解Federated Learning (FL)环境中的Concept Drift问题，尤其适用于动态的Internet of Things (IoT)部署。FLAME基于FL架构，结合真实世界FL管道，通过自适应监控和消除机制，维持模型性能和准确性，同时满足带宽和隐私约束。相比于现有轻量级缓解方法，FLAME在大规模IoT应用中表现出色，能显著减少计算负载和通信开销，同时保持高F1分数和资源利用效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for Publication at ACM EWSN 2024 - EMERGE Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.01386v2",
      "published_date": "2024-10-02 09:55:58 UTC",
      "updated_date": "2024-10-07 14:14:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:17:28.006084"
    },
    {
      "arxiv_id": "2410.01380v3",
      "title": "Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition",
      "title_zh": "语言模型预训练期间的知识熵衰减阻碍新知识获取",
      "authors": [
        "Jiyeon Kim",
        "Hyunji Lee",
        "Hyowon Cho",
        "Joel Jang",
        "Hyeonbin Hwang",
        "Seungpil Won",
        "Youbin Ahn",
        "Dohaeng Lee",
        "Minjoon Seo"
      ],
      "abstract": "In this work, we investigate how a model's tendency to broadly integrate its\nparametric knowledge evolves throughout pretraining, and how this behavior\naffects overall performance, particularly in terms of knowledge acquisition and\nforgetting. We introduce the concept of knowledge entropy, which quantifies the\nrange of memory sources the model engages with; high knowledge entropy\nindicates that the model utilizes a wide range of memory sources, while low\nknowledge entropy suggests reliance on specific sources with greater certainty.\nOur analysis reveals a consistent decline in knowledge entropy as pretraining\nadvances. We also find that the decline is closely associated with a reduction\nin the model's ability to acquire and retain knowledge, leading us to conclude\nthat diminishing knowledge entropy (smaller number of active memory sources)\nimpairs the model's knowledge acquisition and retention capabilities. We find\nfurther support for this by demonstrating that increasing the activity of\ninactive memory sources enhances the model's capacity for knowledge acquisition\nand retention.",
      "tldr_zh": "本文研究了语言模型在预训练过程中知识熵（knowledge entropy）的衰减及其对知识获取的影响，知识熵用于量化模型使用内存来源的范围。研究发现，随着预训练推进，知识熵持续下降，导致模型依赖特定内存来源并削弱其获取和保留新知识的能力。作者通过实验验证了这一现象，并证明增加不活跃内存来源的活动可以显著提升模型的知识获取和保留性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025, Oral",
      "pdf_url": "http://arxiv.org/pdf/2410.01380v3",
      "published_date": "2024-10-02 09:49:45 UTC",
      "updated_date": "2025-03-12 04:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:17:38.627059"
    },
    {
      "arxiv_id": "2410.01368v1",
      "title": "Theoretical Lower Bounds for the Oven Scheduling Problem",
      "title_zh": "Oven Scheduling Problem 的理论下界",
      "authors": [
        "Francesca Da Ros",
        "Marie-Louise Lackner",
        "Nysret Musliu"
      ],
      "abstract": "The Oven Scheduling Problem (OSP) is an NP-hard real-world parallel batch\nscheduling problem arising in the semiconductor industry. The objective of the\nproblem is to schedule a set of jobs on ovens while minimizing several factors,\nnamely total oven runtime, job tardiness, and setup costs. At the same time, it\nmust adhere to various constraints such as oven eligibility and availability,\njob release dates, setup times between batches, and oven capacity limitations.\nThe key to obtaining efficient schedules is to process compatible jobs\nsimultaneously in batches. In this paper, we develop theoretical,\nproblem-specific lower bounds for the OSP that can be computed very quickly. We\nthoroughly examine these lower bounds, evaluating their quality and exploring\ntheir integration into existing solution methods. Specifically, we investigate\ntheir contribution to exact methods and a metaheuristic local search approach\nusing simulated annealing. Moreover, these problem-specific lower bounds enable\nus to assess the solution quality for large instances for which exact methods\noften fail to provide tight lower bounds.",
      "tldr_zh": "本论文针对半导体行业的 Oven Scheduling Problem (OSP)——一个 NP-hard 的并行批处理调度问题——开发了理论下界，以最小化总炉运行时间、作业延误和设置成本，同时满足炉子资格、作业发布日期、设置时间和容量限制等约束。研究者提出这些下界可以快速计算，并通过评估其质量，探讨将其整合到精确方法和模拟退火(metaheuristic local search) 等解决方案中。结果表明，这些问题特定下界显著提升了对大型实例的解决方案质量评估，为优化调度策略提供了高效工具。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2203.12517",
      "pdf_url": "http://arxiv.org/pdf/2410.01368v1",
      "published_date": "2024-10-02 09:30:01 UTC",
      "updated_date": "2024-10-02 09:30:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:17:57.225562"
    },
    {
      "arxiv_id": "2410.01363v1",
      "title": "PCQPR: Proactive Conversational Question Planning with Reflection",
      "title_zh": "PCQPR：主动对话问题规划与反思",
      "authors": [
        "Shasha Guo",
        "Lizi Liao",
        "Jing Zhang",
        "Cuiping Li",
        "Hong Chen"
      ],
      "abstract": "Conversational Question Generation (CQG) enhances the interactivity of\nconversational question-answering systems in fields such as education, customer\nservice, and entertainment. However, traditional CQG, focusing primarily on the\nimmediate context, lacks the conversational foresight necessary to guide\nconversations toward specified conclusions. This limitation significantly\nrestricts their ability to achieve conclusion-oriented conversational outcomes.\nIn this work, we redefine the CQG task as Conclusion-driven Conversational\nQuestion Generation (CCQG) by focusing on proactivity, not merely reacting to\nthe unfolding conversation but actively steering it towards a\nconclusion-oriented question-answer pair. To address this, we propose a novel\napproach, called Proactive Conversational Question Planning with self-Refining\n(PCQPR). Concretely, by integrating a planning algorithm inspired by Monte\nCarlo Tree Search (MCTS) with the analytical capabilities of large language\nmodels (LLMs), PCQPR predicts future conversation turns and continuously\nrefines its questioning strategies. This iterative self-refining mechanism\nensures the generation of contextually relevant questions strategically devised\nto reach a specified outcome. Our extensive evaluations demonstrate that PCQPR\nsignificantly surpasses existing CQG methods, marking a paradigm shift towards\nconclusion-oriented conversational question-answering systems.",
      "tldr_zh": "该论文重新定义了Conversational Question Generation (CQG)为Conclusion-driven Conversational Question Generation (CCQG)，强调主动引导对话达到指定结论，而非仅依赖即时上下文。作者提出PCQPR方法，通过整合Monte Carlo Tree Search (MCTS)启发的规划算法与大型语言模型 (LLMs)的分析能力，预测未来对话转折并进行迭代自我优化，以生成战略性问题。实验结果显示，PCQPR显著优于现有CQG方法，推动了结论导向的对话问答系统范式转变。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2410.01363v1",
      "published_date": "2024-10-02 09:23:07 UTC",
      "updated_date": "2024-10-02 09:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:18:08.401607"
    },
    {
      "arxiv_id": "2410.03758v3",
      "title": "Towards a Deeper Understanding of Transformer for Residential Non-intrusive Load Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Minhajur Rahman",
        "Yasir Arafat"
      ],
      "abstract": "Transformer models have demonstrated impressive performance in Non-Intrusive\nLoad Monitoring (NILM) applications in recent years. Despite their success,\nexisting studies have not thoroughly examined the impact of various\nhyper-parameters on model performance, which is crucial for advancing\nhigh-performing transformer models. In this work, a comprehensive series of\nexperiments have been conducted to analyze the influence of these\nhyper-parameters in the context of residential NILM. This study delves into the\neffects of the number of hidden dimensions in the attention layer, the number\nof attention layers, the number of attention heads, and the dropout ratio on\ntransformer performance. Furthermore, the role of the masking ratio has\nexplored in BERT-style transformer training, providing a detailed investigation\ninto its impact on NILM tasks. Based on these experiments, the optimal\nhyper-parameters have been selected and used them to train a transformer model,\nwhich surpasses the performance of existing models. The experimental findings\noffer valuable insights and guidelines for optimizing transformer\narchitectures, aiming to enhance their effectiveness and efficiency in NILM\napplications. It is expected that this work will serve as a foundation for\nfuture research and development of more robust and capable transformer models\nfor NILM.",
      "tldr_zh": "本文通过一系列全面实验，深入分析了 Transformer 模型在住宅 Non-intrusive Load Monitoring (NILM) 任务中的超参数影响，包括隐藏维度数、注意力层数、注意力头数、dropout 比率以及 BERT-style 训练中的 masking 比率。这些实验揭示了各超参数对模型性能的关键作用，并基于最优配置训练出一款超越现有模型的 Transformer 模型。研究结果为优化 Transformer 架构提供了宝贵见解和指导，有助于提升 NILM 应用的效率和鲁棒性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted to 4th IEEE-ICISET",
      "pdf_url": "http://arxiv.org/pdf/2410.03758v3",
      "published_date": "2024-10-02 09:14:50 UTC",
      "updated_date": "2024-10-13 12:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:18:19.340280"
    },
    {
      "arxiv_id": "2410.01353v3",
      "title": "Codev-Bench: How Do LLMs Understand Developer-Centric Code Completion?",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Pan",
        "Rongyu Cao",
        "Yongchang Cao",
        "Yingwei Ma",
        "Binhua Li",
        "Fei Huang",
        "Han Liu",
        "Yongbin Li"
      ],
      "abstract": "Code completion, a key downstream task in code generation, is one of the most\nfrequent and impactful methods for enhancing developer productivity in software\ndevelopment. As intelligent completion tools evolve, we need a robust\nevaluation benchmark that enables meaningful comparisons between products and\nguides future advancements. However, existing benchmarks focus more on\ncoarse-grained tasks without industrial analysis resembling general code\ngeneration rather than the real-world scenarios developers encounter. Moreover,\nthese benchmarks often rely on costly and time-consuming human annotation, and\nthe standalone test cases fail to leverage minimal tests for maximum\nrepository-level understanding and code coverage. To address these limitations,\nwe first analyze business data from an industrial code completion tool and\nredefine the evaluation criteria to better align with the developer's intent\nand desired completion behavior throughout the coding process. Based on these\ninsights, we introduce Codev-Agent, an agent-based system that automates\nrepository crawling, constructs execution environments, extracts dynamic\ncalling chains from existing unit tests, and generates new test samples to\navoid data leakage, ensuring fair and effective comparisons. Using Codev-Agent,\nwe present the Code-Development Benchmark (Codev-Bench), a fine-grained,\nreal-world, repository-level, and developer-centric evaluation framework.\nCodev-Bench assesses whether a code completion tool can capture a developer's\nimmediate intent and suggest appropriate code across diverse contexts,\nproviding a more realistic benchmark for code completion in modern software\ndevelopment.",
      "tldr_zh": "该论文分析了现有代码补全基准的不足，如过度关注粗粒度任务、依赖昂贵的人工标注，以及无法模拟真实开发场景。作者基于工业数据重定义了评估标准，并引入了 Codev-Agent 系统，该系统自动化仓库爬取、构建执行环境、提取动态调用链并生成新测试样本，以避免数据泄露。最终，论文提出了 Codev-Bench，一个细粒度、真实世界、仓库级且开发者中心的评估框架，用于评估 LLMs 是否能捕捉开发者的即时意图并在多样上下文中提供适当代码建议，从而更好地指导代码补全工具的改进。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01353v3",
      "published_date": "2024-10-02 09:11:10 UTC",
      "updated_date": "2024-10-24 06:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:18:34.790872"
    },
    {
      "arxiv_id": "2410.01350v2",
      "title": "Takin-VC: Expressive Zero-Shot Voice Conversion via Adaptive Hybrid Content Encoding and Enhanced Timbre Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yuguang Yang",
        "Yu Pan",
        "Jixun Yao",
        "Xiang Zhang",
        "Jianhao Ye",
        "Hongbin Zhou",
        "Lei Xie",
        "Lei Ma",
        "Jianjun Zhao"
      ],
      "abstract": "Expressive zero-shot voice conversion (VC) is a critical and challenging task\nthat aims to transform the source timbre into an arbitrary unseen speaker while\npreserving the original content and expressive qualities. Despite recent\nprogress in zero-shot VC, there remains considerable potential for improvements\nin speaker similarity and speech naturalness. Moreover, existing zero-shot VC\nsystems struggle to fully reproduce paralinguistic information in highly\nexpressive speech, such as breathing, crying, and emotional nuances, limiting\ntheir practical applicability. To address these issues, we propose Takin-VC, a\nnovel expressive zero-shot VC framework via adaptive hybrid content encoding\nand memory-augmented context-aware timbre modeling. Specifically, we introduce\nan innovative hybrid content encoder that incorporates an adaptive fusion\nmodule, capable of effectively integrating quantized features of the\npre-trained WavLM and HybridFormer in an implicit manner, so as to extract\nprecise linguistic features while enriching paralinguistic elements. For timbre\nmodeling, we propose advanced memory-augmented and context-aware modules to\ngenerate high-quality target timbre features and fused representations that\nseamlessly align source content with target timbre. To enhance real-time\nperformance, we advocate a conditional flow matching model to reconstruct the\nMel-spectrogram of the source speech. Experimental results show that our\nTakin-VC consistently surpasses state-of-the-art VC systems, achieving notable\nimprovements in terms of speech naturalness, speech expressiveness, and speaker\nsimilarity, while offering enhanced inference speed.",
      "tldr_zh": "本文提出 Takin-VC，一种用于 expressive zero-shot voice conversion 的框架，旨在将源音色转换为任意未见过的说话者，同时保留原内容和表现力，如呼吸、哭泣及情感细微差别。框架的核心创新包括 adaptive hybrid content encoding，通过 adaptive fusion module 整合 WavLM 和 HybridFormer 的量化特征，以提取精确语言特征并丰富副语言元素；以及 enhanced timbre modeling，利用 memory-augmented and context-aware modules 生成高质量目标音色特征，并无缝融合源内容。针对实时性能，该系统采用 conditional flow matching model 重建 Mel-spectrogram。实验结果显示，Takin-VC 在语音自然度、表现力和说话者相似度上显著优于现有系统，同时提升了推理速度。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Work in Progress; Under Review",
      "pdf_url": "http://arxiv.org/pdf/2410.01350v2",
      "published_date": "2024-10-02 09:07:33 UTC",
      "updated_date": "2025-01-10 05:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:18:44.416516"
    },
    {
      "arxiv_id": "2410.01349v1",
      "title": "Life, uh, Finds a Way: Systematic Neural Search",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Baranski",
        "Jun Tani"
      ],
      "abstract": "We tackle the challenge of rapidly adapting an agent's behavior to solve\nspatiotemporally continuous problems in novel settings. Animals exhibit\nextraordinary abilities to adapt to new contexts, a capacity unmatched by\nartificial systems. Instead of focusing on generalization through deep\nreinforcement learning, we propose viewing behavior as the physical\nmanifestation of a search procedure, where robust problem-solving emerges from\nan exhaustive search across all possible behaviors. Surprisingly, this can be\ndone efficiently using online modification of a cognitive graph that guides\naction, challenging the predominant view that exhaustive search in continuous\nspaces is impractical. We describe an algorithm that implicitly enumerates\nbehaviors by regulating the tight feedback loop between execution of behaviors\nand mutation of the graph, and provide a neural implementation based on Hebbian\nlearning and a novel high-dimensional harmonic representation inspired by\nentorhinal cortex. By framing behavior as search, we provide a mathematically\nsimple and biologically plausible model for real-time behavioral adaptation,\nsuccessfully solving a variety of continuous state-space navigation problems.\nThis framework not only offers a flexible neural substrate for other\napplications but also presents a powerful paradigm for understanding adaptive\nbehavior. Our results suggest potential advancements in developmental learning\nand unsupervised skill acquisition, paving the way for autonomous robots to\nmaster complex skills in data-sparse environments demanding flexibility.",
      "tldr_zh": "本文提出一种将行为视为搜索过程的框架，用于快速适应新环境的连续时空问题（spatiotemporally continuous problems），挑战了传统深度强化学习（deep reinforcement learning）的局限性。方法通过在线修改认知图（cognitive graph）来高效进行隐式行为枚举，利用Hebbian learning和受entorhinal cortex启发的高维谐波表示（high-dimensional harmonic representation）实现行为执行与图修改的紧密反馈循环。该框架在各种连续状态空间导航问题上表现出色，提供了一个简单且生物学上合理的模型，推动了开发学习和无监督技能获取的应用，为机器人数据稀缺环境中的自主技能掌握开辟新路径。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01349v1",
      "published_date": "2024-10-02 09:06:54 UTC",
      "updated_date": "2024-10-02 09:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:18:55.223087"
    },
    {
      "arxiv_id": "2410.13868v1",
      "title": "Stars, Stripes, and Silicon: Unravelling the ChatGPT's All-American, Monochrome, Cis-centric Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Torrielli"
      ],
      "abstract": "This paper investigates the challenges associated with bias, toxicity,\nunreliability, and lack of robustness in large language models (LLMs) such as\nChatGPT. It emphasizes that these issues primarily stem from the quality and\ndiversity of data on which LLMs are trained, rather than the model\narchitectures themselves. As LLMs are increasingly integrated into various\nreal-world applications, their potential to negatively impact society by\namplifying existing biases and generating harmful content becomes a pressing\nconcern. The paper calls for interdisciplinary efforts to address these\nchallenges. Additionally, it highlights the need for collaboration between\nresearchers, practitioners, and stakeholders to establish governance\nframeworks, oversight, and accountability mechanisms to mitigate the harmful\nconsequences of biased LLMs. By proactively addressing these challenges, the AI\ncommunity can harness the enormous potential of LLMs for the betterment of\nsociety without perpetuating harmful biases or exacerbating existing\ninequalities.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）如 ChatGPT 中的偏见（bias）、毒性、不可靠性和缺乏鲁棒性问题，这些主要源于训练数据的质量和多样性，而非模型架构本身。论文强调，随着 LLMs 融入现实应用，它们可能放大现有偏见并产生有害内容，从而对社会造成负面影响。作者呼吁跨学科合作，建立治理框架、监督和问责机制，以缓解这些挑战，并确保 LLMs 被用于造福社会而不加剧不平等。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13868v1",
      "published_date": "2024-10-02 08:55:00 UTC",
      "updated_date": "2024-10-02 08:55:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:19:07.524808"
    },
    {
      "arxiv_id": "2410.01337v3",
      "title": "PhyMPGN: Physics-encoded Message Passing Graph Network for spatiotemporal PDE systems",
      "title_zh": "翻译失败",
      "authors": [
        "Bocheng Zeng",
        "Qi Wang",
        "Mengtao Yan",
        "Yang Liu",
        "Ruizhi Chengze",
        "Yi Zhang",
        "Hongsheng Liu",
        "Zidong Wang",
        "Hao Sun"
      ],
      "abstract": "Solving partial differential equations (PDEs) serves as a cornerstone for\nmodeling complex dynamical systems. Recent progresses have demonstrated grand\nbenefits of data-driven neural-based models for predicting spatiotemporal\ndynamics (e.g., tremendous speedup gain compared with classical numerical\nmethods). However, most existing neural models rely on rich training data, have\nlimited extrapolation and generalization abilities, and suffer to produce\nprecise or reliable physical prediction under intricate conditions (e.g.,\nirregular mesh or geometry, complex boundary conditions, diverse PDE\nparameters, etc.). To this end, we propose a new graph learning approach,\nnamely, Physics-encoded Message Passing Graph Network (PhyMPGN), to model\nspatiotemporal PDE systems on irregular meshes given small training datasets.\nSpecifically, we incorporate a GNN into a numerical integrator to approximate\nthe temporal marching of spatiotemporal dynamics for a given PDE system.\nConsidering that many physical phenomena are governed by diffusion processes,\nwe further design a learnable Laplace block, which encodes the discrete\nLaplace-Beltrami operator, to aid and guide the GNN learning in a physically\nfeasible solution space. A boundary condition padding strategy is also designed\nto improve the model convergence and accuracy. Extensive experiments\ndemonstrate that PhyMPGN is capable of accurately predicting various types of\nspatiotemporal dynamics on coarse unstructured meshes, consistently achieves\nthe state-of-the-art results, and outperforms other baselines with considerable\ngains.",
      "tldr_zh": "本研究提出PhyMPGN（Physics-encoded Message Passing Graph Network），一种新型图学习方法，用于在小数据集上建模时空PDE（Partial Differential Equations）系统，解决现有神经模型在不规则网格、复杂边界条件等复杂场景下的泛化能力和准确性问题。具体而言，PhyMPGN将GNN（Graph Neural Network）整合到数值积分器中，以近似时空动态的时序演化，并通过设计可学习的Laplace块（编码离散Laplace-Beltrami算子）和边界条件填充策略，确保模型在物理上可行且收敛性更强。实验结果显示，PhyMPGN在粗糙的不规则网格上准确预测各种时空动态，实现了state-of-the-art性能，并显著优于其他基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01337v3",
      "published_date": "2024-10-02 08:54:18 UTC",
      "updated_date": "2025-03-03 02:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:19:19.884807"
    },
    {
      "arxiv_id": "2410.01335v2",
      "title": "Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Bandarkar",
        "Benjamin Muller",
        "Pritish Yuvraj",
        "Rui Hou",
        "Nayan Singhal",
        "Hongjiang Lv",
        "Bing Liu"
      ],
      "abstract": "Model merging, such as model souping, is the practice of combining different\nmodels with the same architecture together without further training. In this\nwork, we present a model merging methodology that addresses the difficulty of\nfine-tuning Large Language Models (LLMs) for target tasks in non-English\nlanguages, where task-specific data is often unavailable. We focus on\nmathematical reasoning and without in-language math data, facilitate\ncross-lingual transfer by composing language and math capabilities. Starting\nfrom the same pretrained model, we fine-tune separate \"experts\" on math\ninstruction data in English and on generic instruction data in the target\nlanguage. We then replace the top and bottom transformer layers of the math\nexpert directly with layers from the language expert, which consequently\nenhances math performance in the target language. The resulting merged models\noutperform the individual experts and other merging methods on the math\nbenchmark, MGSM, by 10% across four major languages where math instruction data\nis scarce. In addition, this layer swapping is simple, inexpensive, and\nintuitive, as it is based on an interpretative analysis of the most important\nparameter changes during the fine-tuning of each expert. The ability to\nsuccessfully re-compose LLMs for cross-lingual transfer in this manner opens up\nfuture possibilities to combine model expertise, create modular solutions, and\ntransfer reasoning capabilities across languages all post hoc.",
      "tldr_zh": "这篇论文提出了一种层交换（layer swapping）方法，用于实现大型语言模型（LLMs）的零样本跨语言转移（zero-shot cross-lingual transfer），以解决非英语语言中任务数据稀缺的问题，特别是针对数学推理任务。方法包括从同一预训练模型微调英语数学专家和目标语言通用专家，然后直接替换数学专家的顶层和底层 transformer 层，以组合语言和数学能力。实验结果显示，合并模型在 MGSM 基准上比单个专家和其它模型合并方法高出 10%，适用于四个主要语言；此外，这种方法简单、廉价，并基于微调参数变化的解释性分析，为未来模型专长组合和跨语言推理转移提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025, Spotlight Paper, In The Thirteenth International\n  Conference on Learning Representations, 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01335v2",
      "published_date": "2024-10-02 08:53:07 UTC",
      "updated_date": "2025-03-04 18:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:19:32.363899"
    },
    {
      "arxiv_id": "2410.01334v2",
      "title": "Unveiling Language Skills via Path-Level Circuit Discovery",
      "title_zh": "通过路径级电路发现揭示语言技能",
      "authors": [
        "Hang Chen",
        "Jiaying Zhu",
        "Xinyu Yang",
        "Wenya Wang"
      ],
      "abstract": "Circuit discovery with edge-level ablation has become a foundational\nframework for mechanism interpretability of language models. However, its focus\non individual edges often overlooks the sequential, path-level causal\nrelationships that underpin complex behaviors, thus potentially leading to\nmisleading or incomplete circuit discoveries. To address this issue, we propose\na novel path-level circuit discovery framework capturing how behaviors emerge\nthrough interconnected linear chain and build towards complex behaviors. Our\nframework is constructed upon a fully-disentangled linear combinations of\n``memory circuits'' decomposed from the original model. To discover functional\ncircuit paths, we leverage a 2-step pruning strategy by first reducing the\ncomputational graph to a faithful and minimal subgraph and then applying causal\nmediation to identify common paths of a specific skill, termed as skill paths.\nIn contrast to circuit graph from existing works, we focus on the complete\npaths of a generic skill rather than on the fine-grained responses to\nindividual components of the input. To demonstrate this, we explore three\ngeneric language skills, namely Previous Token Skill, Induction Skill and\nIn-Context Learning Skill using our framework and provide more compelling\nevidence to substantiate stratification and inclusiveness of these skills.",
      "tldr_zh": "本研究提出了一种路径级电路发现框架，以解决现有边级消融方法忽略顺序因果关系的问题，从而实现对语言模型机制的更完整解读。该框架基于从原始模型分解的“memory circuits”的完全解耦线性组合，并采用2步修剪策略：先将计算图缩减为最小子图，然后通过“causal mediation”识别特定技能的共同路径（skill paths）。与传统方法不同，该框架关注通用技能的完整路径，而非输入组件的细粒度响应；在探索Previous Token Skill、Induction Skill和In-Context Learning Skill时，提供更可靠的证据支持这些技能的分层和包容性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.01334v2",
      "published_date": "2024-10-02 08:52:58 UTC",
      "updated_date": "2024-12-16 03:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:19:43.536980"
    },
    {
      "arxiv_id": "2410.02832v1",
      "title": "FlipAttack: Jailbreak LLMs via Flipping",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Liu",
        "Xiaoxin He",
        "Miao Xiong",
        "Jinlan Fu",
        "Shumin Deng",
        "Bryan Hooi"
      ],
      "abstract": "This paper proposes a simple yet effective jailbreak attack named FlipAttack\nagainst black-box LLMs. First, from the autoregressive nature, we reveal that\nLLMs tend to understand the text from left to right and find that they struggle\nto comprehend the text when noise is added to the left side. Motivated by these\ninsights, we propose to disguise the harmful prompt by constructing left-side\nnoise merely based on the prompt itself, then generalize this idea to 4\nflipping modes. Second, we verify the strong ability of LLMs to perform the\ntext-flipping task, and then develop 4 variants to guide LLMs to denoise,\nunderstand, and execute harmful behaviors accurately. These designs keep\nFlipAttack universal, stealthy, and simple, allowing it to jailbreak black-box\nLLMs within only 1 query. Experiments on 8 LLMs demonstrate the superiority of\nFlipAttack. Remarkably, it achieves $\\sim$98\\% attack success rate on GPT-4o,\nand $\\sim$98\\% bypass rate against 5 guardrail models on average. The codes are\navailable at GitHub\\footnote{https://github.com/yueliu1999/FlipAttack}.",
      "tldr_zh": "本论文提出了一种简单有效的jailbreak attack方法，名为FlipAttack，用于攻击黑盒LLMs。它利用LLMs的autoregressive特性，发现模型在左侧添加噪声时理解困难，从而通过基于提示自身构建的左侧噪声和4种flipping modes来伪装有害提示，并开发4种变体引导模型进行denoise、understand和执行有害行为。实验结果显示，FlipAttack在8个LLMs上表现出色，在GPT-4o上实现约98%的攻击成功率，并在5个guardrail models上平均达到98%的bypass率，仅需1个查询即可实现。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "43 pages, 31 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.02832v1",
      "published_date": "2024-10-02 08:41:23 UTC",
      "updated_date": "2024-10-02 08:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:19:54.922770"
    },
    {
      "arxiv_id": "2410.01324v1",
      "title": "Fair Class-Incremental Learning using Sample Weighting",
      "title_zh": "使用",
      "authors": [
        "Jaeyoung Park",
        "Minsu Kim",
        "Steven Euijong Whang"
      ],
      "abstract": "Model fairness is becoming important in class-incremental learning for\nTrustworthy AI. While accuracy has been a central focus in class-incremental\nlearning, fairness has been relatively understudied. However, naively using all\nthe samples of the current task for training results in unfair catastrophic\nforgetting for certain sensitive groups including classes. We theoretically\nanalyze that forgetting occurs if the average gradient vector of the current\ntask data is in an \"opposite direction\" compared to the average gradient vector\nof a sensitive group, which means their inner products are negative. We then\npropose a fair class-incremental learning framework that adjusts the training\nweights of current task samples to change the direction of the average gradient\nvector and thus reduce the forgetting of underperforming groups and achieve\nfairness. For various group fairness measures, we formulate optimization\nproblems to minimize the overall losses of sensitive groups while minimizing\nthe disparities among them. We also show the problems can be solved with linear\nprogramming and propose an efficient Fairness-aware Sample Weighting (FSW)\nalgorithm. Experiments show that FSW achieves better accuracy-fairness tradeoff\nresults than state-of-the-art approaches on real datasets.",
      "tldr_zh": "这篇论文探讨了类增量学习（class-incremental learning）中模型公平性的重要性，指出传统方法在训练时使用所有当前任务样本会导致敏感群体（如特定类别的类）出现不公平的灾难性遗忘（catastrophic forgetting）。作者通过理论分析发现，遗忘发生在当前任务数据的平均梯度向量（average gradient vector）与敏感群体的平均梯度向量内积为负时，并提出一个公平框架，通过调整样本训练权重来改变梯度向量方向，减少敏感群体的遗忘并实现公平。针对各种群体公平性措施（group fairness measures），他们制定了优化问题来最小化敏感群体的整体损失和差异，并使用线性规划（linear programming）解决这些问题，同时开发了高效的 Fairness-aware Sample Weighting (FSW) 算法。实验结果表明，FSW 在真实数据集上比最先进方法实现了更好的准确性-公平性权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01324v1",
      "published_date": "2024-10-02 08:32:21 UTC",
      "updated_date": "2024-10-02 08:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:20:08.653950"
    },
    {
      "arxiv_id": "2410.01322v2",
      "title": "Forte : Finding Outliers with Representation Typicality Estimation",
      "title_zh": "Forte：通过表示典型性估计发现异常值",
      "authors": [
        "Debargha Ganguly",
        "Warren Morningstar",
        "Andrew Yu",
        "Vipin Chaudhary"
      ],
      "abstract": "Generative models can now produce photorealistic synthetic data which is\nvirtually indistinguishable from the real data used to train it. This is a\nsignificant evolution over previous models which could produce reasonable\nfacsimiles of the training data, but ones which could be visually distinguished\nfrom the training data by human evaluation. Recent work on OOD detection has\nraised doubts that generative model likelihoods are optimal OOD detectors due\nto issues involving likelihood misestimation, entropy in the generative\nprocess, and typicality. We speculate that generative OOD detectors also failed\nbecause their models focused on the pixels rather than the semantic content of\nthe data, leading to failures in near-OOD cases where the pixels may be similar\nbut the information content is significantly different. We hypothesize that\nestimating typical sets using self-supervised learners leads to better OOD\ndetectors. We introduce a novel approach that leverages representation\nlearning, and informative summary statistics based on manifold estimation, to\naddress all of the aforementioned issues. Our method outperforms other\nunsupervised approaches and achieves state-of-the art performance on\nwell-established challenging benchmarks, and new synthetic data detection\ntasks.",
      "tldr_zh": "该论文提出了一种名为Forte的新方法，用于通过表示典型性估计（Representation Typicality Estimation）检测异常数据（OOD）。作者指出，现有生成模型在OOD检测中存在问题，如似然性误估和对像素而非语义内容的过度关注，导致在近似OOD场景下表现不佳。Forte利用自监督学习和基于流形估计的信息摘要统计来估计典型集，从而解决这些问题，并在无监督方法中超越其他方法，实现了在经典基准测试和新合成数据检测任务上的最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01322v2",
      "published_date": "2024-10-02 08:26:37 UTC",
      "updated_date": "2024-12-09 05:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:20:18.538913"
    },
    {
      "arxiv_id": "2410.01319v1",
      "title": "Finetuning Pre-trained Model with Limited Data for LiDAR-based 3D Object Detection by Bridging Domain Gaps",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyun Jang",
        "Mincheol Chang",
        "Jongwon Park",
        "Jinkyu Kim"
      ],
      "abstract": "LiDAR-based 3D object detectors have been largely utilized in various\napplications, including autonomous vehicles or mobile robots. However,\nLiDAR-based detectors often fail to adapt well to target domains with different\nsensor configurations (e.g., types of sensors, spatial resolution, or FOVs) and\nlocation shifts. Collecting and annotating datasets in a new setup is commonly\nrequired to reduce such gaps, but it is often expensive and time-consuming.\nRecent studies suggest that pre-trained backbones can be learned in a\nself-supervised manner with large-scale unlabeled LiDAR frames. However,\ndespite their expressive representations, they remain challenging to generalize\nwell without substantial amounts of data from the target domain. Thus, we\npropose a novel method, called Domain Adaptive Distill-Tuning (DADT), to adapt\na pre-trained model with limited target data (approximately 100 LiDAR frames),\nretaining its representation power and preventing it from overfitting.\nSpecifically, we use regularizers to align object-level and context-level\nrepresentations between the pre-trained and finetuned models in a\nteacher-student architecture. Our experiments with driving benchmarks, i.e.,\nWaymo Open dataset and KITTI, confirm that our method effectively finetunes a\npre-trained model, achieving significant gains in accuracy.",
      "tldr_zh": "该论文针对LiDAR-based 3D Object Detection的问题，提出一种新方法Domain Adaptive Distill-Tuning (DADT)，以桥接传感器配置和位置变化带来的领域间差距。DADT利用教师-学生架构，通过对齐对象级和上下文级表示来微调预训练模型，仅需有限的标注数据（如约100帧LiDAR数据），从而避免过拟合并保留模型的表示能力。实验结果显示，在Waymo Open dataset和KITTI基准上，该方法显著提高了检测准确率，证明了其在数据有限场景下的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.01319v1",
      "published_date": "2024-10-02 08:22:42 UTC",
      "updated_date": "2024-10-02 08:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:20:34.804252"
    },
    {
      "arxiv_id": "2410.01308v2",
      "title": "Rethinking GNN Expressive Power Research in the Machine Learning Community: Limitations, Issues, and Corrections",
      "title_zh": "翻译失败",
      "authors": [
        "Guanyu Cui",
        "Zhewei Wei",
        "Hsin-Hao Su"
      ],
      "abstract": "The success of graph neural networks (GNNs) has spurred theoretical\nexplorations into their expressive power. In the graph machine learning\ncommunity, researchers often equate GNNs with the Weisfeiler-Lehman (WL) tests\nas a foundation for theoretical analysis. However, we identify two major\nlimitations of this approach: (1) the semantics of WL tests involve verifying\npurely structural equivalences through a set of logical sentences. As a result,\nthey do not align well with the concept of expressive power, which is typically\ndefined as the class of functions that GNNs can express, and they are not\nwell-suited for handling graphs with features; (2) by leveraging communication\ncomplexity, we show that the lower bound on a GNN's capacity (depth multiplied\nby width) to simulate one iteration of the WL test grows almost linearly with\nthe graph size. This finding indicates that the WL test is not locally\ncomputable and is misaligned with the message-passing GNNs. Furthermore, we\nshow that allowing unlimited precomputation or directly integrating features\ncomputed by external models, while claiming that these precomputations enhance\nthe expressiveness of GNNs, can sometimes lead to issues. Such problems can\neven be observed in an influential paper published in a top-tier machine\nlearning conference. We argue that using well-defined computational models,\nsuch as the CONGEST model from distributed computing, is a reasonable approach\nto characterizing and exploring GNNs' expressive power. Following this\napproach, we present some results on the effects of virtual nodes and edges.\nFinally, we highlight several open problems regarding GNN expressive power for\nfurther exploration.",
      "tldr_zh": "本论文重新审视了机器学习社区中图神经网络（GNNs）的表达能力（expressive power）研究，指出将 GNNs 与 Weisfeiler-Lehman (WL) tests 等同起来的方法存在两大局限：一是 WL tests 仅关注结构等价性，不适用于定义 GNNs 的功能表达类，尤其是处理有特征的图；二是通过通信复杂性分析，证明模拟 WL tests 一轮需要 GNNs 的容量几乎线性增长于图大小，这与消息传递 GNNs 的局部计算特性不匹配。论文进一步批评了允许无限预计算或整合外部模型特征的做法，可能导致研究问题，并建议采用分布式计算中的 CONGEST 模型来更准确地表征 GNNs 的表达能力。最终，论文呈现了关于虚拟节点和边的效果结果，并提出了几个开放问题以推动未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "+"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01308v2",
      "published_date": "2024-10-02 08:01:50 UTC",
      "updated_date": "2025-02-15 12:13:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:20:44.446931"
    },
    {
      "arxiv_id": "2410.01307v1",
      "title": "FanCric : Multi-Agentic Framework for Crafting Fantasy 11 Cricket Teams",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Bhatnagar"
      ],
      "abstract": "Cricket, with its intricate strategies and deep history, increasingly\ncaptivates a global audience. The Indian Premier League (IPL), epitomizing\nTwenty20 cricket, showcases talent in a format that lasts just a few hours as\nopposed to the longer forms of the game. Renowned for its fusion of technology\nand fan engagement, the IPL stands as the world's most popular cricket league.\nThis study concentrates on Dream11, India's leading fantasy cricket league for\nIPL, where participants craft virtual teams based on real player performances\nto compete internationally. Building a winning fantasy team requires navigating\nvarious complex factors including player form and match conditions.\nTraditionally, this has been approached through operations research and machine\nlearning. This research introduces the FanCric framework, an advanced\nmulti-agent system leveraging Large Language Models (LLMs) and a robust\norchestration framework to enhance fantasy team selection in cricket. FanCric\nemploys both structured and unstructured data to surpass traditional methods by\nincorporating sophisticated AI technologies. The analysis involved scrutinizing\napproximately 12.7 million unique entries from a Dream11 contest, evaluating\nFanCric's efficacy against the collective wisdom of crowds and a simpler Prompt\nEngineering approach. Ablation studies further assessed the impact of\ngenerating varying numbers of teams. The exploratory findings are promising,\nindicating that further investigation into FanCric's capabilities is warranted\nto fully realize its potential in enhancing strategic decision-making using\nLLMs in fantasy sports and business in general.",
      "tldr_zh": "这篇论文介绍了 FanCric，一个基于 Large Language Models (LLMs) 的多智能体框架，旨在优化 IPL 幻想板球团队的创建，超越传统运筹学和机器学习方法。FanCric 通过整合结构化和非结构化数据，以及先进的 AI 编排技术，帮助用户考虑球员状态和比赛条件等复杂因素。研究分析了约 1270 万条 Dream11 比赛条目，将 FanCric 与集体智慧和简单 Prompt Engineering 方法比较，结果显示其表现更优越；消融研究进一步评估了生成不同数量团队的影响。总体而言，该框架展示了在幻想体育和商业决策中应用 LLMs 的潜力，值得进一步探索。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01307v1",
      "published_date": "2024-10-02 08:01:28 UTC",
      "updated_date": "2024-10-02 08:01:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:20:55.912002"
    },
    {
      "arxiv_id": "2410.01306v2",
      "title": "Emotion-Aware Embedding Fusion in LLMs (Flan-T5, LLAMA 2, DeepSeek-R1, and ChatGPT 4) for Intelligent Response Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Abdur Rasool",
        "Muhammad Irfan Shahzad",
        "Hafsa Aslam",
        "Vincent Chan",
        "Muhammad Ali Arshad"
      ],
      "abstract": "Empathetic and coherent responses are critical in auto-mated\nchatbot-facilitated psychotherapy. This study addresses the challenge of\nenhancing the emotional and contextual understanding of large language models\n(LLMs) in psychiatric applications. We introduce Emotion-Aware Embedding\nFusion, a novel framework integrating hierarchical fusion and attention\nmechanisms to prioritize semantic and emotional features in therapy\ntranscripts. Our approach combines multiple emotion lexicons, including NRC\nEmotion Lexicon, VADER, WordNet, and SentiWordNet, with state-of-the-art LLMs\nsuch as Flan-T5, LLAMA 2, DeepSeek-R1, and ChatGPT 4. Therapy session\ntranscripts, comprising over 2,000 samples are segmented into hierarchical\nlevels (word, sentence, and session) using neural networks, while hierarchical\nfusion combines these features with pooling techniques to refine emotional\nrepresentations. Atten-tion mechanisms, including multi-head self-attention and\ncross-attention, further prioritize emotional and contextual features, enabling\ntemporal modeling of emotion-al shifts across sessions. The processed\nembeddings, computed using BERT, GPT-3, and RoBERTa are stored in the Facebook\nAI similarity search vector database, which enables efficient similarity search\nand clustering across dense vector spaces. Upon user queries, relevant segments\nare retrieved and provided as context to LLMs, enhancing their ability to\ngenerate empathetic and con-textually relevant responses. The proposed\nframework is evaluated across multiple practical use cases to demonstrate\nreal-world applicability, including AI-driven therapy chatbots. The system can\nbe integrated into existing mental health platforms to generate personalized\nresponses based on retrieved therapy session data.",
      "tldr_zh": "这篇论文提出 Emotion-Aware Embedding Fusion 框架，用于提升 LLMs（如 Flan-T5、LLAMA 2、DeepSeek-R1 和 ChatGPT 4）在心理治疗中的情感和上下文理解，从而生成更具共情力的智能响应。框架整合了多种情感词库（如 NRC Emotion Lexicon、VADER、WordNet 和 SentiWordNet），并采用层次化融合、注意力机制（如多头自注意力）和神经网络对治疗会话文本进行分层处理（词、句子和会话级别）。实验结果显示，该方法能通过向量数据库（如 Facebook AI similarity search）高效检索相关段落，提供个性化响应，并在 AI 驱动的治疗聊天机器人等实际应用中得到验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01306v2",
      "published_date": "2024-10-02 08:01:05 UTC",
      "updated_date": "2025-03-11 10:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:21:07.689036"
    },
    {
      "arxiv_id": "2410.01296v1",
      "title": "Speculative Coreset Selection for Task-Specific Fine-tuning",
      "title_zh": "针对任务特定微调的推测性核心集选择",
      "authors": [
        "Xiaoyu Zhang",
        "Juan Zhai",
        "Shiqing Ma",
        "Chao Shen",
        "Tianlin Li",
        "Weipeng Jiang",
        "Yang Liu"
      ],
      "abstract": "Task-specific fine-tuning is essential for the deployment of large language\nmodels (LLMs), but it requires significant computational resources and time.\nExisting solutions have proposed coreset selection methods to improve data\nefficiency and reduce model training overhead, but they still have limitations:\n1) Overlooking valuable samples at high pruning rates, which degrades the\ncoreset's performance. 2) Requiring high time overhead during coreset selection\nto fine-tune and evaluate the target LLM. In this paper, we introduce STAFF, a\nspeculative coreset selection method. STAFF leverages a small model from the\nsame family as the target LLM to efficiently estimate data scores and then\nverifies the scores on the target LLM to accurately identify and allocate more\nselection budget to important regions while maintaining coverage of easy\nregions. We evaluate STAFF on three LLMs and three downstream tasks and show\nthat STAFF improves the performance of SOTA methods by up to 54.3% and reduces\nselection overhead by up to 70.5% at different pruning rates. Furthermore, we\nobserve that the coreset selected by STAFF at low pruning rates (i.e., 20%) can\neven obtain better fine-tuning performance than the full dataset.",
      "tldr_zh": "本文提出 STAFF，一种推测性 coreset 选择方法，用于解决任务特定微调中的大语言模型(LLMs)训练开销问题，克服现有方法在高 pruning rates 下忽略有价值样本和高时间开销的局限。STAFF 利用与目标 LLM 同家族的小模型高效估计数据分数，然后在目标 LLM 上验证这些分数，以优先分配预算给重要区域，同时确保对简单区域的覆盖。实验结果显示，在三个 LLM 和三个下游任务上，STAFF 比 SOTA 方法性能提升高达 54.3%，并减少选择开销达 70.5%；此外，在低 pruning rates（如 20%）下，STAFF 选择的 coreset 甚至可实现优于完整数据集的微调性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 4 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.01296v1",
      "published_date": "2024-10-02 07:42:25 UTC",
      "updated_date": "2024-10-02 07:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:21:19.875779"
    },
    {
      "arxiv_id": "2410.01290v1",
      "title": "Towards a Law of Iterated Expectations for Heuristic Estimators",
      "title_zh": "迈向启发式估计器的迭代期望定律",
      "authors": [
        "Paul Christiano",
        "Jacob Hilton",
        "Andrea Lincoln",
        "Eric Neyman",
        "Mark Xu"
      ],
      "abstract": "Christiano et al. (2022) define a *heuristic estimator* to be a hypothetical\nalgorithm that estimates the values of mathematical expressions from arguments.\nIn brief, a heuristic estimator $\\mathbb{G}$ takes as input a mathematical\nexpression $Y$ and a formal \"heuristic argument\" $\\pi$, and outputs an estimate\n$\\mathbb{G}(Y \\mid \\pi)$ of $Y$. In this work, we argue for the informal\nprinciple that a heuristic estimator ought not to be able to predict its own\nerrors, and we explore approaches to formalizing this principle. Most simply,\nthe principle suggests that $\\mathbb{G}(Y - \\mathbb{G}(Y \\mid \\pi) \\mid \\pi)$\nought to equal zero for all $Y$ and $\\pi$. We argue that an ideal heuristic\nestimator ought to satisfy two stronger properties in this vein, which we term\n*iterated estimation* (by analogy to the law of iterated expectations) and\n*error orthogonality*.\n  Although iterated estimation and error orthogonality are intuitively\nappealing, it can be difficult to determine whether a given heuristic estimator\nsatisfies the properties. As an alternative approach, we explore *accuracy*: a\nproperty that (roughly) states that $\\mathbb{G}$ has zero average error over a\ndistribution of mathematical expressions. However, in the context of two\nestimation problems, we demonstrate barriers to creating an accurate heuristic\nestimator. We finish by discussing challenges and potential paths forward for\nfinding a heuristic estimator that accords with our intuitive understanding of\nhow such an estimator ought to behave, as well as the potential applications of\nheuristic estimators to understanding the behavior of neural networks.",
      "tldr_zh": "本文探讨了 heuristic estimator 的设计原则，提出它不应预测自身错误，并定义了两个关键属性：iterated estimation 和 error orthogonality，以类似 law of iterated expectations 的方式，确保估计器的理想行为。作者分析了这些属性的直观吸引力及其验证难度，并引入 accuracy 属性，即 heuristic estimator 在数学表达式分布上具有零平均错误，但通过两个估计问题展示了实现 accuracy 的障碍。最终，论文讨论了构建符合直觉 heuristic estimator 的挑战、潜在路径，以及其在理解神经网络行为的应用前景。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "47 pages, 2 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.01290v1",
      "published_date": "2024-10-02 07:33:27 UTC",
      "updated_date": "2024-10-02 07:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:21:31.782952"
    },
    {
      "arxiv_id": "2410.01281v2",
      "title": "Uncertainty-aware Human Mobility Modeling and Anomaly Detection",
      "title_zh": "不确定性感知的人类移动建模与异常检测",
      "authors": [
        "Haomin Wen",
        "Shurui Cao",
        "Zeeshan Rasheed",
        "Khurram Hassan Shafique",
        "Leman Akoglu"
      ],
      "abstract": "Given the temporal GPS coordinates from a large set of human agents, how can\nwe model their mobility behavior toward effective anomaly (e.g. bad-actor or\nmalicious behavior) detection without any labeled data? Human mobility and\ntrajectory modeling have been extensively studied, showcasing varying abilities\nto manage complex inputs and balance performance-efficiency trade-offs. In this\nwork, we formulate anomaly detection in complex human behavior by modeling raw\nGPS data as a sequence of stay-point events, each characterized by\nspatio-temporal features, along with trips (i.e. commute) between the\nstay-points. Our problem formulation allows us to leverage modern sequence\nmodels for unsupervised training and anomaly detection. Notably, we equip our\nproposed model USTAD (for Uncertainty-aware Spatio-Temporal Anomaly Detection)\nwith aleatoric (i.e. data) uncertainty estimation to account for inherent\nstochasticity in certain individuals' behavior, as well as epistemic (i.e.\nmodel) uncertainty to handle data sparsity under a large variety of human\nbehaviors. Together, aleatoric and epistemic uncertainties unlock a robust loss\nfunction as well as uncertainty-aware decision-making in anomaly scoring.\nExtensive experiments shows that USTAD improves anomaly detection AUCROC by\n3\\%-15\\% over baselines in industry-scale data.",
      "tldr_zh": "本研究针对无标注数据的GPS坐标，提出Uncertainty-aware Human Mobility Modeling and Anomaly Detection方法，用于建模人类移动行为并检测异常（如恶意行为）。他们将GPS数据建模为一系列stay-point events和trips序列，利用现代序列模型开发USTAD框架，该框架整合aleatoric uncertainty（数据不确定性）和epistemic uncertainty（模型不确定性），以处理行为随机性和数据稀疏性，从而实现鲁棒的损失函数和不确定性感知的异常评分。实验结果显示，USTAD在工业规模数据上将异常检测的AUCROC提高了3%-15%，比基线模型显著提升。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01281v2",
      "published_date": "2024-10-02 06:57:08 UTC",
      "updated_date": "2025-05-05 22:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:21:42.788823"
    },
    {
      "arxiv_id": "2410.01276v1",
      "title": "Deep Unlearn: Benchmarking Machine Unlearning",
      "title_zh": "Deep Unlearn：机器遗忘的基准测试",
      "authors": [
        "Xavier F. Cadet",
        "Anastasia Borovykh",
        "Mohammad Malekzadeh",
        "Sara Ahmadi-Abhari",
        "Hamed Haddadi"
      ],
      "abstract": "Machine unlearning (MU) aims to remove the influence of particular data\npoints from the learnable parameters of a trained machine learning model. This\nis a crucial capability in light of data privacy requirements, trustworthiness,\nand safety in deployed models. MU is particularly challenging for deep neural\nnetworks (DNNs), such as convolutional nets or vision transformers, as such\nDNNs tend to memorize a notable portion of their training dataset.\nNevertheless, the community lacks a rigorous and multifaceted study that looks\ninto the success of MU methods for DNNs. In this paper, we investigate 18\nstate-of-the-art MU methods across various benchmark datasets and models, with\neach evaluation conducted over 10 different initializations, a comprehensive\nevaluation involving MU over 100K models. We show that, with the proper\nhyperparameters, Masked Small Gradients (MSG) and Convolution Transpose (CT),\nconsistently perform better in terms of model accuracy and run-time efficiency\nacross different models, datasets, and initializations, assessed by\npopulation-based membership inference attacks (MIA) and per-sample unlearning\nlikelihood ratio attacks (U-LiRA). Furthermore, our benchmark highlights the\nfact that comparing a MU method only with commonly used baselines, such as\nGradient Ascent (GA) or Successive Random Relabeling (SRL), is inadequate, and\nwe need better baselines like Negative Gradient Plus (NG+) with proper\nhyperparameter selection.",
      "tldr_zh": "本研究针对机器卸载（Machine Unlearning, MU）问题，评估了18种最先进的方法在深度神经网络（DNNs）上的性能，旨在解决数据隐私和模型安全挑战。研究通过在多个基准数据集和模型上进行大规模基准测试（超过100K模型，每个评估10个初始化），使用基于种群的成员推理攻击（MIA）和每样本卸载似然比攻击（U-LiRA）来衡量卸载效果。结果显示，Masked Small Gradients (MSG) 和 Convolution Transpose (CT) 方法在模型准确性和运行效率方面表现出色，并强调需要改进基线方法，如采用Negative Gradient Plus (NG+)以进行更可靠的比较。总的来说，该基准为MU方法的发展提供了关键见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01276v1",
      "published_date": "2024-10-02 06:41:58 UTC",
      "updated_date": "2024-10-02 06:41:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:21:56.300884"
    },
    {
      "arxiv_id": "2410.03756v2",
      "title": "The Smart Buildings Control Suite: A Diverse Open Source Benchmark to Evaluate and Scale HVAC Control Policies for Sustainability",
      "title_zh": "翻译失败",
      "authors": [
        "Judah Goldfeder",
        "Victoria Dean",
        "Zixin Jiang",
        "Xuezheng Wang",
        "Bing dong",
        "Hod Lipson",
        "John Sipple"
      ],
      "abstract": "Commercial buildings account for 17% of U.S. carbon emissions, with roughly\nhalf of that from Heating, Ventilation, and Air Conditioning (HVAC). HVAC\ndevices form a complex thermodynamic system, and while Model Predictive Control\nand Reinforcement Learning have been used to optimize control policies, scaling\nto thousands of buildings remains a significant unsolved challenge. Most\ncurrent algorithms are over-optimized for specific buildings and rely on\nproprietary data or hard-to-configure simulations. We present the Smart\nBuildings Control Suite, the first open source interactive HVAC control\nbenchmark with a focus on solutions that scale. It consists of 3 components:\nreal-world telemetric data extracted from 11 buildings over 6 years, a\nlightweight data-driven simulator for each building, and a modular Physically\nInformed Neural Network (PINN) building model as a simulator alternative. The\nbuildings span a variety of climates, management systems, and sizes, and both\nthe simulator and PINN easily scale to new buildings, ensuring solutions using\nthis benchmark are robust to these factors and only reliant on fully scalable\nbuilding models. This represents a major step towards scaling HVAC optimization\nfrom the lab to buildings everywhere. To facilitate use, our benchmark is\ncompatible with the Gym standard, and our data is part of TensorFlow Datasets.",
      "tldr_zh": "该论文介绍了 Smart Buildings Control Suite，这是一个多样化的开源基准，用于评估和扩展 HVAC 控制策略，以减少商业建筑对碳排放的贡献（占美国总排放的17%）。该基准包括从11个建筑提取的6年真实遥测数据、轻量级数据驱动模拟器，以及模块化 Physically Informed Neural Network (PINN) 模型，这些组件覆盖多种气候、管理系统和建筑大小，并易于扩展到新建筑。相比现有算法，该基准避免了对专有数据的依赖，促进 HVAC 优化从实验室向大规模实际应用扩展，并与 Gym 标准和 TensorFlow Datasets 兼容。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.DC",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03756v2",
      "published_date": "2024-10-02 06:30:07 UTC",
      "updated_date": "2025-01-31 14:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:22:08.129110"
    },
    {
      "arxiv_id": "2410.01265v3",
      "title": "Transformers Handle Endogeneity in In-Context Linear Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Haodong Liang",
        "Krishnakumar Balasubramanian",
        "Lifeng Lai"
      ],
      "abstract": "We explore the capability of transformers to address endogeneity in\nin-context linear regression. Our main finding is that transformers inherently\npossess a mechanism to handle endogeneity effectively using instrumental\nvariables (IV). First, we demonstrate that the transformer architecture can\nemulate a gradient-based bi-level optimization procedure that converges to the\nwidely used two-stage least squares $(\\textsf{2SLS})$ solution at an\nexponential rate. Next, we propose an in-context pretraining scheme and provide\ntheoretical guarantees showing that the global minimizer of the pre-training\nloss achieves a small excess loss. Our extensive experiments validate these\ntheoretical findings, showing that the trained transformer provides more robust\nand reliable in-context predictions and coefficient estimates than the\n$\\textsf{2SLS}$ method, in the presence of endogeneity.",
      "tldr_zh": "本研究探讨了 transformers 在 in-context linear regression 中处理 endogeneity 的能力，发现 transformers 能通过 instrumental variables (IV) 内在机制有效应对这一问题。论文证明 transformers 可以模拟梯度-based 双层优化过程，以指数速率收敛到 two-stage least squares (2SLS) 解决方案，并提出 in-context pretraining 方案，提供理论保证确保预训练损失的全局最小值实现小 excess loss。通过广泛实验验证，训练后的 transformers 在 endogeneity 存在时，提供比 2SLS 更稳健和可靠的 in-context 预测及系数估计。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "econ.EM",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "37 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01265v3",
      "published_date": "2024-10-02 06:21:04 UTC",
      "updated_date": "2025-05-11 02:08:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:22:19.855866"
    },
    {
      "arxiv_id": "2410.01257v2",
      "title": "HelpSteer2-Preference: Complementing Ratings with Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Zhilin Wang",
        "Alexander Bukharin",
        "Olivier Delalleau",
        "Daniel Egert",
        "Gerald Shen",
        "Jiaqi Zeng",
        "Oleksii Kuchaiev",
        "Yi Dong"
      ],
      "abstract": "Reward models are critical for aligning models to follow instructions, and\nare typically trained following one of two popular paradigms: Bradley-Terry\nstyle or Regression style. However, there is a lack of evidence that either\napproach is better than the other, when adequately matched for data. This is\nprimarily because these approaches require data collected in different (but\nincompatible) formats, meaning that adequately matched data is not available in\nexisting public datasets. To tackle this problem, we release preference\nannotations (designed for Bradley-Terry training) to complement existing\nratings (designed for Regression style training) in the HelpSteer2 dataset. To\nimprove data interpretability, preference annotations are accompanied with\nhuman-written justifications. Using this data, we conduct the first\nhead-to-head comparison of Bradley-Terry and Regression models when adequately\nmatched for data. Based on insights derived from such a comparison, we propose\na novel approach to combine Bradley-Terry and Regression reward modeling. A\nLlama-3.1-70B-Instruct model tuned with this approach scores 94.1 on\nRewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. This\nreward model can then be used with REINFORCE algorithm (RLHF) to align an\nInstruct model to reach 85.0 on Arena Hard, which is No. 1 as of 1 Oct 2024. We\nopen-source this dataset (CC-BY-4.0 license) at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new -- 1-oct-2024\nand openly release the trained Reward and Instruct models at\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct",
      "tldr_zh": "本研究探讨了奖励模型（Reward models）的训练方法，比较了 Bradley-Terry 风格和 Regression 风格的有效性，并通过发布偏好注解（preference annotations）来补充 HelpSteer2 数据集，这些注解附带人类书写的理由，以实现数据格式的兼容。研究者进行了首次直接比较，并在基于洞见的新方法中结合了两种风格的奖励建模。结果显示，使用此方法训练的 Llama-3.1-70B-Instruct 模型在 RewardBench 上得分 94.1 排名第一，并通过 REINFORCE 算法（RLHF）对齐的 Instruct 模型在 Arena Hard 上达到 85.0 排名第一；数据集和模型已开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025; 28 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01257v2",
      "published_date": "2024-10-02 06:05:52 UTC",
      "updated_date": "2025-03-06 12:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:22:32.270786"
    },
    {
      "arxiv_id": "2410.01246v1",
      "title": "AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaotian Lu",
        "Jiyi Li",
        "Koh Takeuchi",
        "Hisashi Kashima"
      ],
      "abstract": "Question answering (QA) tasks have been extensively studied in the field of\nnatural language processing (NLP). Answers to open-ended questions are highly\ndiverse and difficult to quantify, and cannot be simply evaluated as correct or\nincorrect, unlike close-ended questions with definitive answers. While large\nlanguage models (LLMs) have demonstrated strong capabilities across various\ntasks, they exhibit relatively weaker performance in evaluating answers to\nopen-ended questions. In this study, we propose a method that leverages LLMs\nand the analytic hierarchy process (AHP) to assess answers to open-ended\nquestions. We utilized LLMs to generate multiple evaluation criteria for a\nquestion. Subsequently, answers were subjected to pairwise comparisons under\neach criterion with LLMs, and scores for each answer were calculated in the\nAHP. We conducted experiments on four datasets using both ChatGPT-3.5-turbo and\nGPT-4. Our results indicate that our approach more closely aligns with human\njudgment compared to the four baselines. Additionally, we explored the impact\nof the number of criteria, variations in models, and differences in datasets on\nthe results.",
      "tldr_zh": "该研究针对自然语言处理(NLP)中开放式问题回答的评估挑战，提出了一种基于分析层次过程(AHP)的LLM推理方法，以多标准方式量化多样化的回答。方法包括利用LLMs生成多个评价标准，对答案进行成对比较，并应用AHP计算分数。实验在四个数据集上使用ChatGPT-3.5-turbo和GPT-4进行测试，结果显示该方法比四个基线更接近人类判断。进一步分析了标准数量、模型变异和数据集差异对结果的影响，为开放式回答评估提供了更可靠的框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.01246v1",
      "published_date": "2024-10-02 05:22:07 UTC",
      "updated_date": "2024-10-02 05:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:22:43.257246"
    },
    {
      "arxiv_id": "2410.01242v2",
      "title": "RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Haolin Jin",
        "Zechao Sun",
        "Huaming Chen"
      ],
      "abstract": "Large Language Models (LLMs) have shown incredible potential in code\ngeneration tasks, and recent research in prompt engineering have enhanced LLMs'\nunderstanding of textual information. However, ensuring the accuracy of\ngenerated code often requires extensive testing and validation by programmers.\nWhile LLMs can typically generate code based on task descriptions, their\naccuracy remains limited, especially for complex tasks that require a deeper\nunderstanding of both the problem statement and the code generation process.\nThis limitation is primarily due to the LLMs' need to simultaneously comprehend\ntext and generate syntactically and semantically correct code, without having\nthe capability to automatically refine the code. In real-world software\ndevelopment, programmers rarely produce flawless code in a single attempt based\non the task description alone, they rely on iterative feedback and debugging to\nrefine their programs. Inspired by this process, we introduce a novel\narchitecture of LLM-based agents for code generation and automatic debugging:\nRefinement and Guidance Debugging (RGD). The RGD framework is a multi-LLM-based\nagent debugger that leverages three distinct LLM agents-Guide Agent, Debug\nAgent, and Feedback Agent. RGD decomposes the code generation task into\nmultiple steps, ensuring a clearer workflow and enabling iterative code\nrefinement based on self-reflection and feedback. Experimental results\ndemonstrate that RGD exhibits remarkable code generation capabilities,\nachieving state-of-the-art performance with a 9.8% improvement on the HumanEval\ndataset and a 16.2% improvement on the MBPP dataset compared to the\nstate-of-the-art approaches and traditional direct prompting approaches. We\nhighlight the effectiveness of the RGD framework in enhancing LLMs' ability to\ngenerate and refine code autonomously.",
      "tldr_zh": "该研究提出了一种名为 RGD 的多 LLM 代理调试框架，用于提升大型语言模型 (LLMs) 在代码生成任务中的准确性，通过模拟程序员的迭代调试过程。RGD 框架包括三个关键代理：Guide Agent 负责任务指导、Debug Agent 进行代码调试，以及 Feedback Agent 提供反馈，从而将代码生成分解为多个步骤，实现自主代码精炼和自我反思。实验结果显示，RGD 在 HumanEval 数据集上比现有方法提高了 9.8%，在 MBPP 数据集上提高了 16.2%，显著增强了 LLMs 的代码生成和优化能力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01242v2",
      "published_date": "2024-10-02 05:07:02 UTC",
      "updated_date": "2024-10-03 13:12:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:22:55.385942"
    },
    {
      "arxiv_id": "2410.01227v1",
      "title": "See Me and Believe Me: Causality and Intersectionality in Testimonial Injustice in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Kenya S. Andrews",
        "Mesrob I. Ohannessian",
        "Elena Zheleva"
      ],
      "abstract": "In medical settings, it is critical that all who are in need of care are\ncorrectly heard and understood. When this is not the case due to prejudices a\nlistener has, the speaker is experiencing \\emph{testimonial injustice}, which,\nbuilding upon recent work, we quantify by the presence of several categories of\nunjust vocabulary in medical notes. In this paper, we use FCI, a causal\ndiscovery method, to study the degree to which certain demographic features\ncould lead to marginalization (e.g., age, gender, and race) by way of\ncontributing to testimonial injustice. To achieve this, we review physicians'\nnotes for each patient, where we identify occurrences of unjust vocabulary,\nalong with the demographic features present, and use causal discovery to build\na Structural Causal Model (SCM) relating those demographic features to\ntestimonial injustice. We analyze and discuss the resulting SCMs to show the\ninteraction of these factors and how they influence the experience of\ninjustice. Despite the potential presence of some confounding variables, we\nobserve how one contributing feature can make a person more prone to\nexperiencing another contributor of testimonial injustice. There is no single\nroot of injustice and thus intersectionality cannot be ignored. These results\ncall for considering more than singular or equalized attributes of who a person\nis when analyzing and improving their experiences of bias and injustice. This\nwork is thus a first foray at using causal discovery to understand the nuanced\nexperiences of patients in medical settings, and its insights could be used to\nguide design principles throughout healthcare, to build trust and promote\nbetter patient care.",
      "tldr_zh": "本研究探讨了医疗环境中证言不公（testimonial injustice），即由于听众偏见导致患者被错误理解的问题。研究者使用FCI（一种因果发现方法）分析医生的笔记中不公正词汇的出现，并构建结构因果模型（SCM）来考察人口统计特征（如年龄、性别和种族）如何相互作用并促成边缘化。结果显示，这些特征并非独立存在，而是通过交叉性（intersectionality）相互影响，导致多重不公，而非单一根源。该工作首次应用因果发现方法揭示医疗中的复杂偏见，提供见解以指导医疗实践，提升患者信任和护理质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01227v1",
      "published_date": "2024-10-02 04:10:55 UTC",
      "updated_date": "2024-10-02 04:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:23:08.742841"
    },
    {
      "arxiv_id": "2410.01218v1",
      "title": "An uncertainty-aware Digital Shadow for underground multimodal CO2 storage monitoring",
      "title_zh": "不确定性感知的 Digital Shadow 用于地下",
      "authors": [
        "Abhinav Prakash Gahlot",
        "Rafael Orozco",
        "Ziyi Yin",
        "Felix J. Herrmann"
      ],
      "abstract": "Geological Carbon Storage GCS is arguably the only scalable net-negative CO2\nemission technology available While promising subsurface complexities and\nheterogeneity of reservoir properties demand a systematic approach to quantify\nuncertainty when optimizing production and mitigating storage risks which\ninclude assurances of Containment and Conformance of injected supercritical CO2\nAs a first step towards the design and implementation of a Digital Twin for\nmonitoring underground storage operations a machine learning based\ndata-assimilation framework is introduced and validated on carefully designed\nrealistic numerical simulations As our implementation is based on Bayesian\ninference but does not yet support control and decision-making we coin our\napproach an uncertainty-aware Digital Shadow To characterize the posterior\ndistribution for the state of CO2 plumes conditioned on multi-modal time-lapse\ndata the envisioned Shadow combines techniques from Simulation-Based Inference\nSBI and Ensemble Bayesian Filtering to establish probabilistic baselines and\nassimilate multi-modal data for GCS problems that are challenged by large\ndegrees of freedom nonlinear multi-physics non-Gaussianity and computationally\nexpensive to evaluate fluid flow and seismic simulations To enable SBI for\ndynamic systems a recursive scheme is proposed where the Digital Shadows neural\nnetworks are trained on simulated ensembles for their state and observed data\nwell and/or seismic Once training is completed the systems state is inferred\nwhen time-lapse field data becomes available In this computational study we\nobserve that a lack of knowledge on the permeability field can be factored into\nthe Digital Shadows uncertainty quantification To our knowledge this work\nrepresents the first proof of concept of an uncertainty-aware in-principle\nscalable Digital Shadow.",
      "tldr_zh": "该研究针对地质碳存储（GCS）的地下多模态监测，提出了一种 uncertainty-aware Digital Shadow 框架，以系统量化不确定性并优化生产过程。该框架基于机器学习的数据同化方法，结合 Bayesian inference、Simulation-Based Inference (SBI) 和 Ensemble Bayesian Filtering，通过在模拟集合上训练神经网络来推断 CO2 羽状物的状态，并处理多模态时间序列数据。实验结果显示，该框架能有效应对高自由度、非线性多物理过程和计算密集型模拟，并在真实数据应用中量化渗透性场的未知不确定性，这是首个 uncertainty-aware Digital Shadow 的概念证明。",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01218v1",
      "published_date": "2024-10-02 03:58:45 UTC",
      "updated_date": "2024-10-02 03:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:23:20.626751"
    },
    {
      "arxiv_id": "2410.01216v1",
      "title": "RS-FME-SwinT: A Novel Feature Map Enhancement Framework Integrating Customized SwinT with Residual and Spatial CNN for Monkeypox Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Saddam Hussain Khan",
        "Rashid Iqbal"
      ],
      "abstract": "Monkeypox (MPox) has emerged as a significant global concern, with cases\nsteadily increasing daily. Conventional detection methods, including polymerase\nchain reaction (PCR) and manual examination, exhibit challenges of low\nsensitivity, high cost, and substantial workload. Therefore, deep learning\noffers an automated solution; however, the datasets include data scarcity,\ntexture, contrast, inter-intra class variability, and similarities with other\nskin infectious diseases. In this regard, a novel hybrid approach is proposed\nthat integrates the learning capacity of Residual Learning and Spatial\nExploitation Convolutional Neural Network (CNN) with a customized Swin\nTransformer (RS-FME-SwinT) to capture multi-scale global and local correlated\nfeatures for MPox diagnosis. The proposed RS-FME-SwinT technique employs a\ntransfer learning-based feature map enhancement (FME) technique, integrating\nthe customized SwinT for global information capture, residual blocks for\ntexture extraction, and spatial blocks for local contrast variations. Moreover,\nincorporating new inverse residual blocks within the proposed SwinT effectively\ncaptures local patterns and mitigates vanishing gradients. The proposed\nRS-FME-SwinT has strong learning potential of diverse features that\nsystematically reduce intra-class MPox variation and enable precise\ndiscrimination from other skin diseases. Finally, the proposed RS-FME-SwinT is\na holdout cross-validated on a diverse MPox dataset and achieved outperformance\non state-of-the-art CNNs and ViTs. The proposed RS-FME-SwinT demonstrates\ncommendable results of an accuracy of 97.80%, sensitivity of 96.82%, precision\nof 98.06%, and an F-score of 97.44% in MPox detection. The RS-FME-SwinT could\nbe a valuable tool for healthcare practitioners, enabling prompt and accurate\nMPox diagnosis and contributing significantly to mitigation efforts.",
      "tldr_zh": "本研究针对Monkeypox（MPox）诊断的挑战，如传统方法的低敏感性、高成本和数据集问题（包括数据稀缺、纹理对比度变异及与其他皮肤疾病的相似性），提出了一种新型框架RS-FME-SwinT。 该框架整合了Residual Learning、Spatial Exploitation CNN和定制Swin Transformer，通过转移学习-based的特征图增强（FME）技术捕获多尺度全局和局部特征，并引入inverse residual blocks来提取局部模式并缓解梯度消失问题。 实验在MPox数据集上进行holdout交叉验证，结果显示RS-FME-SwinT的准确率达97.80%、敏感性96.82%、精确度98.06%和F-score97.44%，优于现有CNN和ViT模型，为医疗从业者提供高效的诊断工具以快速识别MPox并助力防控努力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "37 Pages, 5 Tables, 10 Figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01216v1",
      "published_date": "2024-10-02 03:57:57 UTC",
      "updated_date": "2024-10-02 03:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:23:32.223924"
    },
    {
      "arxiv_id": "2410.01215v2",
      "title": "From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging",
      "title_zh": "翻译失败",
      "authors": [
        "Yuling Shi",
        "Songsong Wang",
        "Chengcheng Wan",
        "Xiaodong Gu"
      ],
      "abstract": "While large language models have made significant strides in code generation,\nthe pass rate of the generated code is bottlenecked on subtle errors, often\nrequiring human intervention to pass tests, especially for complex problems.\nExisting LLM-based debugging systems treat generated programs as monolithic\nunits, failing to address bugs at multiple levels of granularity, from\nlow-level syntax errors to high-level algorithmic flaws. In this paper, we\nintroduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger\nby isolating, identifying, and resolving bugs at various levels of granularity.\nMGDebugger decomposes problematic code into a hierarchical tree structure of\nsubfunctions, with each level representing a particular granularity of error.\nDuring debugging, it analyzes each subfunction and iteratively resolves bugs in\na bottom-up manner. To effectively test each subfunction, we propose an\nLLM-simulated Python executor, which traces code execution and tracks important\nvariable states to pinpoint errors accurately. Extensive experiments\ndemonstrate that MGDebugger outperforms existing debugging systems, achieving\nan 18.9% improvement in accuracy over seed generations in HumanEval and a 97.6%\nrepair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes\nbugs across different categories and difficulty levels, demonstrating its\nrobustness and effectiveness.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）在代码生成中存在的微妙错误问题，提出Multi-Granularity Debugger (MGDebugger)，一个分层代码调试器，用于隔离、识别和修复不同粒度的错误，从低级语法错误到高级算法缺陷。MGDebugger将代码分解成分层树结构，并采用自底向上的迭代方式分析子函数，同时利用LLM-simulated Python executor追踪代码执行和变量状态以精确定位错误。实验结果显示，该系统在HumanEval数据集上比基线模型准确率提升18.9%，在HumanEvalFix上修复成功率达97.6%，并在各种错误类别和难度级别上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and data available at https://github.com/YerbaPage/MGDebugger",
      "pdf_url": "http://arxiv.org/pdf/2410.01215v2",
      "published_date": "2024-10-02 03:57:21 UTC",
      "updated_date": "2024-10-05 04:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:23:44.323947"
    },
    {
      "arxiv_id": "2410.01213v1",
      "title": "A versatile machine learning workflow for high-throughput analysis of supported metal catalyst particles",
      "title_zh": "一种通用的机器学习工作流，用于负载金属催化剂颗粒的高通量分析",
      "authors": [
        "Arda Genc",
        "Justin Marlowe",
        "Anika Jalil",
        "Libor Kovarik",
        "Phillip Christopher"
      ],
      "abstract": "Accurate and efficient characterization of nanoparticles (NPs), particularly\nregarding particle size distribution, is essential for advancing our\nunderstanding of their structure-property relationships and facilitating their\ndesign for various applications. In this study, we introduce a novel two-stage\nartificial intelligence (AI)-driven workflow for NP analysis that leverages\nprompt engineering techniques from state-of-the-art single-stage object\ndetection and large-scale vision transformer (ViT) architectures. This\nmethodology was applied to transmission electron microscopy (TEM) and scanning\nTEM (STEM) images of heterogeneous catalysts, enabling high-resolution,\nhigh-throughput analysis of particle size distributions for supported metal\ncatalysts. The model's performance in detecting and segmenting NPs was\nvalidated across diverse heterogeneous catalyst systems, including various\nmetals (Cu, Ru, Pt, and PtCo), supports (silica ($\\text{SiO}_2$),\n$\\gamma$-alumina ($\\gamma$-$\\text{Al}_2\\text{O}_3$), and carbon black), and\nparticle diameter size distributions with means and standard deviations of 2.9\n$\\pm$ 1.1 nm, 1.6 $\\pm$ 0.2 nm, 9.7 $\\pm$ 4.6 nm, and 4 $\\pm$ 1.0 nm.\nAdditionally, the proposed machine learning (ML) approach successfully detects\nand segments overlapping NPs anchored on non-uniform catalytic support\nmaterials, providing critical insights into their spatial arrangements and\ninteractions. Our AI-assisted NP analysis workflow demonstrates robust\ngeneralization across diverse datasets and can be readily applied to similar NP\nsegmentation tasks without requiring costly model retraining.",
      "tldr_zh": "本文提出了一种多功能机器学习工作流，用于高通量分析支持金属催化剂颗粒，特别是粒径分布。该工作流采用两阶段 AI 方法，结合提示工程、单阶段物体检测和大型视觉 transformer (ViT) 架构，应用于传输电子显微镜 (TEM) 和扫描 TEM (STEM) 图像。实验在多种催化剂系统上验证了模型的性能，包括不同金属 (Cu, Ru, Pt, PtCo) 和载体 (SiO2, γ-Al2O3, 碳黑)，成功检测和分割重叠 NPs，并提供空间排列洞见。该方法展示了鲁棒的泛化能力，可直接应用于类似 NPs 分析任务，无需重新训练。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01213v1",
      "published_date": "2024-10-02 03:50:01 UTC",
      "updated_date": "2024-10-02 03:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:23:56.299198"
    },
    {
      "arxiv_id": "2410.01210v1",
      "title": "Polyp-SES: Automatic Polyp Segmentation with Self-Enriched Semantic Model",
      "title_zh": "翻译失败",
      "authors": [
        "Quang Vinh Nguyen",
        "Thanh Hoang Son Vo",
        "Sae-Ryung Kang",
        "Soo-Hyung Kim"
      ],
      "abstract": "Automatic polyp segmentation is crucial for effective diagnosis and treatment\nin colonoscopy images. Traditional methods encounter significant challenges in\naccurately delineating polyps due to limitations in feature representation and\nthe handling of variability in polyp appearance. Deep learning techniques,\nincluding CNN and Transformer-based methods, have been explored to improve\npolyp segmentation accuracy. However, existing approaches often neglect\nadditional semantics, restricting their ability to acquire adequate contexts of\npolyps in colonoscopy images. In this paper, we propose an innovative method\nnamed ``Automatic Polyp Segmentation with Self-Enriched Semantic Model'' to\naddress these limitations. First, we extract a sequence of features from an\ninput image and decode high-level features to generate an initial segmentation\nmask. Using the proposed self-enriched semantic module, we query potential\nsemantics and augment deep features with additional semantics, thereby aiding\nthe model in understanding context more effectively. Extensive experiments show\nsuperior segmentation performance of the proposed method against\nstate-of-the-art polyp segmentation baselines across five polyp benchmarks in\nboth superior learning and generalization capabilities.",
      "tldr_zh": "该研究针对结肠镜图像中的自动息肉分割问题，提出了一种创新方法Polyp-SES，以解决传统方法和现有CNN及Transformer-based方法在特征表示和语义理解方面的局限性。Polyp-SES首先从输入图像提取特征序列并生成初始分割掩码，然后通过self-enriched semantic module查询潜在语义并增强深度特征，从而提升模型对息肉上下文的理解能力。在五个息肉基准上的广泛实验表明，该方法在分割性能、学习能力和泛化能力上均优于最先进基线。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.5.4; I.2.1; I.4.6; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "Asian Conference on Computer Vision 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.01210v1",
      "published_date": "2024-10-02 03:34:23 UTC",
      "updated_date": "2024-10-02 03:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:24:07.723982"
    },
    {
      "arxiv_id": "2410.01201v3",
      "title": "Were RNNs All We Needed?",
      "title_zh": "RNNs 是否就是我们所需要的一切？",
      "authors": [
        "Leo Feng",
        "Frederick Tung",
        "Mohamed Osama Ahmed",
        "Yoshua Bengio",
        "Hossein Hajimirsadeghi"
      ],
      "abstract": "The introduction of Transformers in 2017 reshaped the landscape of deep\nlearning. Originally proposed for sequence modelling, Transformers have since\nachieved widespread success across various domains. However, the scalability\nlimitations of Transformers - particularly with respect to sequence length -\nhave sparked renewed interest in novel recurrent models that are parallelizable\nduring training, offer comparable performance, and scale more effectively. In\nthis work, we revisit sequence modelling from a historical perspective,\nfocusing on Recurrent Neural Networks (RNNs), which dominated the field for two\ndecades before the rise of Transformers. Specifically, we examine LSTMs (1997)\nand GRUs (2014). We demonstrate that by simplifying these models, we can derive\nminimal versions (minLSTMs and minGRUs) that (1) use fewer parameters than\ntheir traditional counterparts, (2) are fully parallelizable during training,\nand (3) achieve surprisingly competitive performance on a range of tasks,\nrivalling recent models including Transformers.",
      "tldr_zh": "该论文从历史视角重新审视循环神经网络(RNNs)，特别是LSTMs(1997)和GRUs(2014)，探讨它们是否能与Transformers匹敌。作者通过简化这些模型，开发了参数更少且训练时完全可并行化的minLSTMs和minGRUs。实验结果表明，这些简化模型在各种序列建模任务上表现出色，与Transformers等现代模型的性能相当，从而重新点燃了对RNNs的兴趣。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01201v3",
      "published_date": "2024-10-02 03:06:49 UTC",
      "updated_date": "2024-11-28 07:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:24:19.234093"
    },
    {
      "arxiv_id": "2410.01176v1",
      "title": "Generative Diffusion-based Contract Design for Efficient AI Twins Migration in Vehicular Embodied AI Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Zhong",
        "Jiawen Kang",
        "Jinbo Wen",
        "Dongdong Ye",
        "Jiangtian Nie",
        "Dusit Niyato",
        "Xiaozheng Gao",
        "Shengli Xie"
      ],
      "abstract": "Embodied AI is a rapidly advancing field that bridges the gap between\ncyberspace and physical space, enabling a wide range of applications. This\nevolution has led to the development of the Vehicular Embodied AI NETwork\n(VEANET), where advanced AI capabilities are integrated into vehicular systems\nto enhance autonomous operations and decision-making. Embodied agents, such as\nAutonomous Vehicles (AVs), are autonomous entities that can perceive their\nenvironment and take actions to achieve specific goals, actively interacting\nwith the physical world. Embodied twins are digital models of these embodied\nagents, with various embodied AI twins for intelligent applications in\ncyberspace. In VEANET, embodied AI twins act as in-vehicle AI assistants to\nperform diverse tasks supporting autonomous driving using generative AI models.\nDue to limited computational resources of AVs, these AVs often offload\ncomputationally intensive tasks, such as constructing and updating embodied AI\ntwins, to nearby RSUs. However, since the rapid mobility of AVs and the limited\nprovision coverage of a single RSU, embodied AI twins require dynamic\nmigrations from current RSU to other RSUs in real-time, resulting in the\nchallenge of selecting suitable RSUs for efficient embodied AI twins\nmigrations. Given information asymmetry, AVs cannot know the detailed\ninformation of RSUs. To this end, in this paper, we construct a\nmulti-dimensional contract theoretical model between AVs and alternative RSUs.\nConsidering that AVs may exhibit irrational behavior, we utilize prospect\ntheory instead of expected utility theory to model the actual utilities of AVs.\nFinally, we employ a generative diffusion model-based algorithm to identify the\noptimal contract designs. Compared with traditional deep reinforcement learning\nalgorithms, numerical results demonstrate the effectiveness of the proposed\nscheme.",
      "tldr_zh": "本文提出了一种基于生成扩散模型（Generative Diffusion Model）的合同设计方案，用于提升 Vehicular Embodied AI Networks (VEANET) 中 AI Twins 迁移的效率。针对 AVs（Autonomous Vehicles）和 RSUs（Roadside Units）之间的信息不对称问题，该方法采用 Prospect Theory 建模 AVs 的非理性行为，并构建多维度合同理论模型来优化迁移决策。与传统深度强化学习算法相比，数值实验结果表明，该方案显著提高了迁移效率和整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01176v1",
      "published_date": "2024-10-02 02:20:42 UTC",
      "updated_date": "2024-10-02 02:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:24:32.092372"
    },
    {
      "arxiv_id": "2410.01174v1",
      "title": "Towards Inference-time Category-wise Safety Steering for Large Language Models",
      "title_zh": "朝向大型语言模型的",
      "authors": [
        "Amrita Bhattacharjee",
        "Shaona Ghosh",
        "Traian Rebedea",
        "Christopher Parisien"
      ],
      "abstract": "While large language models (LLMs) have seen unprecedented advancements in\ncapabilities and applications across a variety of use-cases, safety alignment\nof these models is still an area of active research. The fragile nature of\nLLMs, even models that have undergone extensive alignment and safety training\nregimes, warrants additional safety steering steps via training-free,\ninference-time methods. While recent work in the area of mechanistic\ninterpretability has investigated how activations in latent representation\nspaces may encode concepts, and thereafter performed representation engineering\nto induce such concepts in LLM outputs, the applicability of such for safety is\nrelatively under-explored. Unlike recent inference-time safety steering works,\nin this paper we explore safety steering of LLM outputs using: (i)\ncategory-specific steering vectors, thereby enabling fine-grained control over\nthe steering, and (ii) sophisticated methods for extracting informative\nsteering vectors for more effective safety steering while retaining quality of\nthe generated text. We demonstrate our exploration on multiple LLMs and\ndatasets, and showcase the effectiveness of the proposed steering method, along\nwith a discussion on the implications and best practices.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 的安全对齐问题，提出了一种推理时的类别特定安全引导方法，以应对模型易受影响的脆弱性。该方法利用机制解释性 (mechanistic interpretability) 探索潜在表示空间，并通过类别-specific steering vectors 实现更精细的控制，同时采用先进的提取技术来优化引导效果，确保生成文本的质量。实验在多个 LLMs 和数据集上验证了该方法的有效性，准确提升了安全性能，并讨论了其实施含义和最佳实践。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01174v1",
      "published_date": "2024-10-02 02:02:06 UTC",
      "updated_date": "2024-10-02 02:02:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:24:42.782180"
    },
    {
      "arxiv_id": "2410.03752v1",
      "title": "Efficient Streaming LLM for Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Junteng Jia",
        "Gil Keren",
        "Wei Zhou",
        "Egor Lakomkin",
        "Xiaohui Zhang",
        "Chunyang Wu",
        "Frank Seide",
        "Jay Mahadeokar",
        "Ozlem Kalinli"
      ],
      "abstract": "Recent works have shown that prompting large language models with audio\nencodings can unlock speech recognition capabilities. However, existing\ntechniques do not scale efficiently, especially while handling long form\nstreaming audio inputs -- not only do they extrapolate poorly beyond the audio\nlength seen during training, but they are also computationally inefficient due\nto the quadratic cost of attention.\n  In this work, we introduce SpeechLLM-XL, a linear scaling decoder-only model\nfor streaming speech recognition. We process audios in configurable chunks\nusing limited attention window for reduced computation, and the text tokens for\neach audio chunk are generated auto-regressively until an EOS is predicted.\nDuring training, the transcript is segmented into chunks, using a CTC forced\nalignment estimated from encoder output. SpeechLLM-XL with 1.28 seconds chunk\nsize achieves 2.7%/6.7% WER on LibriSpeech test clean/other, and it shows no\nquality degradation on long form utterances 10x longer than the training\nutterances.",
      "tldr_zh": "本研究针对现有语音识别方法在处理长音频时的低效问题（如注意力机制的二次计算成本），提出了一种高效的流式语音识别模型SpeechLLM-XL。该模型采用线性缩放的解码器-only架构，通过处理可配置的音频块、有限注意力窗口和自回归文本生成（直到预测EOS），显著降低了计算开销。训练过程中，利用从编码器输出估计的CTC强制对齐来分割转录文本。实验结果显示，SpeechLLM-XL在LibriSpeech测试集上实现2.7%/6.7% WER（干净/其他），并在比训练音频长10倍的长音频上保持质量无损。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03752v1",
      "published_date": "2024-10-02 01:54:35 UTC",
      "updated_date": "2024-10-02 01:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:24:56.584822"
    },
    {
      "arxiv_id": "2410.01149v1",
      "title": "Recovering Manifold Structure Using Ollivier-Ricci Curvature",
      "title_zh": "使用 Ollivier-Ricci 曲率恢复流形结构",
      "authors": [
        "Tristan Luca Saidi",
        "Abigail Hickok",
        "Andrew J. Blumberg"
      ],
      "abstract": "We introduce ORC-ManL, a new algorithm to prune spurious edges from nearest\nneighbor graphs using a criterion based on Ollivier-Ricci curvature and\nestimated metric distortion. Our motivation comes from manifold learning: we\nshow that when the data generating the nearest-neighbor graph consists of noisy\nsamples from a low-dimensional manifold, edges that shortcut through the\nambient space have more negative Ollivier-Ricci curvature than edges that lie\nalong the data manifold. We demonstrate that our method outperforms alternative\npruning methods and that it significantly improves performance on many\ndownstream geometric data analysis tasks that use nearest neighbor graphs as\ninput. Specifically, we evaluate on manifold learning, persistent homology,\ndimension estimation, and others. We also show that ORC-ManL can be used to\nimprove clustering and manifold learning of single-cell RNA sequencing data.\nFinally, we provide empirical convergence experiments that support our\ntheoretical findings.",
      "tldr_zh": "我们引入了 ORC-ManL 算法，使用 Ollivier-Ricci Curvature 和估计的度量失真作为标准，从 nearest neighbor graphs 中修剪虚假边，以恢复数据流形的结构。该方法基于流形学习的动机，即噪声样本从低维流形中时，穿越环境空间的边具有更负的 Ollivier-Ricci Curvature，而沿数据流形的边则相对较正，从而提高图的准确性。实验结果表明，ORC-ManL 优于其他修剪方法，并在下游任务如 manifold learning、persistent homology 和维度估计上显著提升性能；此外，它还可改善单细胞 RNA 测序数据的聚类和学习效果，并通过经验收敛实验支持了理论发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01149v1",
      "published_date": "2024-10-02 01:00:30 UTC",
      "updated_date": "2024-10-02 01:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:25:18.702971"
    },
    {
      "arxiv_id": "2410.01145v1",
      "title": "ProxiMix: Enhancing Fairness with Proximity Samples in Subgroups",
      "title_zh": "ProxiMix：通过子群中的邻近样本增强公平性",
      "authors": [
        "Jingyu Hu",
        "Jun Hong",
        "Mengnan Du",
        "Weiru Liu"
      ],
      "abstract": "Many bias mitigation methods have been developed for addressing fairness\nissues in machine learning. We found that using linear mixup alone, a data\naugmentation technique, for bias mitigation, can still retain biases present in\ndataset labels. Research presented in this paper aims to address this issue by\nproposing a novel pre-processing strategy in which both an existing mixup\nmethod and our new bias mitigation algorithm can be utilized to improve the\ngeneration of labels of augmented samples, which are proximity aware.\nSpecifically, we proposed ProxiMix which keeps both pairwise and proximity\nrelationships for fairer data augmentation. We conducted thorough experiments\nwith three datasets, three ML models, and different hyperparameters settings.\nOur experimental results showed the effectiveness of ProxiMix from both\nfairness of predictions and fairness of recourse perspectives.",
      "tldr_zh": "这篇论文针对机器学习中的公平性问题，发现单纯使用 mixup 数据增强技术无法完全消除数据集标签中的偏见。作者提出了一种新预处理策略 ProxiMix，它结合现有 mixup 方法和新型偏见缓解算法，确保增强样本的标签生成考虑样本的邻近关系（proximity aware），从而保持成对和邻近关系以实现更公平的数据增强。通过在三个数据集、三个 ML 模型和不同超参数设置下的实验，结果显示 ProxiMix 显著提高了预测公平性和补救公平性（fairness of predictions and fairness of recourse）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01145v1",
      "published_date": "2024-10-02 00:47:03 UTC",
      "updated_date": "2024-10-02 00:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:25:19.859210"
    },
    {
      "arxiv_id": "2410.01141v2",
      "title": "Evaluating Deduplication Techniques for Economic Research Paper Titles with a Focus on Semantic Similarity using NLP and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Doohee You",
        "Samuel Fraiberger"
      ],
      "abstract": "This study investigates efficient deduplication techniques for a large NLP\ndataset of economic research paper titles. We explore various pairing methods\nalongside established distance measures (Levenshtein distance, cosine\nsimilarity) and a sBERT model for semantic evaluation. Our findings suggest a\npotentially low prevalence of duplicates based on the observed semantic\nsimilarity across different methods. Further exploration with a human-annotated\nground truth set is completed for a more conclusive assessment. The result\nsupports findings from the NLP, LLM based distance metrics.",
      "tldr_zh": "这项研究评估了使用 NLP 和 LLMs 去重经济研究论文标题的技术，重点关注语义相似性。研究者探索了多种配对方法、Levenshtein distance、cosine similarity 以及 sBERT 模型来进行语义评估。结果表明，基于这些方法的语义相似性显示重复项的发生率可能较低，并通过人类标注的真实数据集验证了 NLP 和 LLM 基于的距离指标的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.01141v2",
      "published_date": "2024-10-02 00:43:10 UTC",
      "updated_date": "2024-12-11 19:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:25:31.001904"
    },
    {
      "arxiv_id": "2410.13866v2",
      "title": "Associative memory and dead neurons",
      "title_zh": "关联记忆与死神经元",
      "authors": [
        "Vladimir Fanaskov",
        "Ivan Oseledets"
      ],
      "abstract": "In \"Large Associative Memory Problem in Neurobiology and Machine Learning,\"\nDmitry Krotov and John Hopfield introduced a general technique for the\nsystematic construction of neural ordinary differential equations with\nnon-increasing energy or Lyapunov function. We study this energy function and\nidentify that it is vulnerable to the problem of dead neurons. Each point in\nthe state space where the neuron dies is contained in a non-compact region with\nconstant energy. In these flat regions, energy function alone does not\ncompletely determine all degrees of freedom and, as a consequence, can not be\nused to analyze stability or find steady states or basins of attraction. We\nperform a direct analysis of the dynamical system and show how to resolve\nproblems caused by flat directions corresponding to dead neurons: (i) all\ninformation about the state vector at a fixed point can be extracted from the\nenergy and Hessian matrix (of Lagrange function), (ii) it is enough to analyze\nstability in the range of Hessian matrix, (iii) if steady state touching flat\nregion is stable the whole flat region is the basin of attraction. The analysis\nof the Hessian matrix can be complicated for realistic architectures, so we\nshow that for a slightly altered dynamical system (with the same structure of\nsteady states), one can derive a diverse family of Lyapunov functions that do\nnot have flat regions corresponding to dead neurons. In addition, these energy\nfunctions allow one to use Lagrange functions with Hessian matrices that are\nnot necessarily positive definite and even consider architectures with\nnon-symmetric feedforward and feedback connections.",
      "tldr_zh": "本论文探讨了神经网络中关联记忆模型的能量函数问题，特别关注 dead neurons（死神经元）导致的漏洞。研究者分析了 Krotov 和 Hopfield 的神经普通微分方程（ODE）技术，发现 dead neurons 会创建能量恒定的非紧凑区域，阻碍稳定性分析、稳态确定和吸引域计算。为解决此问题，他们直接分析动态系统，提出从能量和 Hessian matrix 中提取固定点信息、在 Hessian matrix 范围内评估稳定性的方法，并证明稳定稳态可扩展至整个平坦区域。此外，论文引入了一种修改的动态系统及其多样化 Lyapunov functions，以消除 dead neurons 的平坦区域，支持非正定 Hessian matrix 和非对称连接的架构。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Reviewed in https://openreview.net/forum?id=mkNVPGpEPm, accepted to\n  ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13866v2",
      "published_date": "2024-10-02 00:25:30 UTC",
      "updated_date": "2025-02-26 17:04:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:25:44.444082"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 158,
  "processed_papers_count": 158,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T06:26:02.614120"
}