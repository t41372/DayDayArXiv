{
  "date": "2025-12-29",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-12-29 的 arXiv 中文 TLDR 快报！\n\n👋 大家好，我是你们的 AI 研究员朋友。\n\n**一句话总结今天：**\n今天的 arXiv 爆发了 **Agentic AI** 的进化浪潮，从单纯的工具调用转向了“技能习得”和“层级化协作”；同时，关于 AI 对人类认知影响的辩论正在升温，而 DeepMind 等团队在教育领域的 RCT 实测为 AI 落地提供了坚实证据。\n\n---\n\n### 🚀 焦点头条：教育、认知与世界模型\n\n**1. [教育] AI 辅导真的有效且安全吗？英国课堂的随机对照试验**\n**AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms**\n> LearnLM Team, Eedi et al.\n> **核心:** 这是一项罕见的、在真实课堂进行的 RCT（随机对照试验）。Google DeepMind 的 LearnLM 团队与 Eedi 合作，在英国 5 所中学测试了基于 LearnLM 的数学辅导系统。\n> **发现:** 结果令人振奋。AI 辅导不仅安全（人类导师批准了 76.4% 的 AI 消息且几乎未做修改），而且有效：学生表现不亚于人类辅导，且在解决新问题时的成功率比人类辅导组高出 5.5%。\n> **Implication:** 这为 AI 在教育领域的规模化应用提供了强有力的实证支持，证明了经过教学微调的模型可以作为可靠的“苏格拉底式”导师。\n\n**2. [认知科学] 关于“ChatGPT 脑”的辩论：认知债务是真的吗？**\n**Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks**\n> Milos Stankovic et al.\n> **核心:** 这是一篇针对 Kosmyna 等人 (2025) 关于“使用 AI 导致认知债务累积”研究的评论文章。\n> **观点:** 作者对“使用 AI 会让大脑变懒/变笨”这一结论持保留态度。他们指出了原研究在样本量、脑电（EEG）分析方法和结果复现性上的问题。这场辩论对于我们理解 AI 辅助对人类长期认知能力的影响至关重要。\n\n**3. [World Model] Web World Models: 介于固定网络与完全生成之间的新范式**\n**Web World Models**\n> Jichen Feng, Mengdi Wang (Princeton) et al.\n> **核心:** 现有的 Agent 环境要么是固定的 Web 页面，要么是不可控的完全生成世界。本文提出了 **Web World Model (WWM)**，一种“中间路线”。\n> **方法:** 物理规则和状态由代码定义（保证逻辑一致性），而叙事和决策由 LLM 生成。这让 Agent 可以在一个既有结构化约束（如地理、游戏规则）又具备无限探索可能性的环境中学习。\n\n---\n\n### 🤖 Agent 进化：从“工具人”到“技能大师”\n\n今天的 Agent 论文扎堆，趋势非常明显：不再满足于简单的 Prompt Engineering，而是向**自我进化**和**层级化**发展。\n\n**4. [技能进化] CASCADE: 通过自主开发和进化实现累积式 Agent 技能创造**\n**CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution**\n> Xu Huang, Gerbrand Ceder et al.\n> **核心:** 提出了 CASCADE 框架，标志着 Agent 从“LLM + 工具使用”向“LLM + 技能习得”的转变。\n> **亮点:** Agent 可以像人类科学家一样，通过反思和搜索，将成功的操作固化为“技能”并复用。在材料科学基准测试中，使用 GPT-5 的 CASCADE 成功率高达 93.3%（无进化版本仅 35.4%）。\n\n**5. [软件工程] BOAD: 通过 Bandit 优化发现层级化软件工程 Agent**\n**BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization**\n> Iris Xu, Zhang-Wei Hong et al.\n> **核心:** 针对复杂的软件工程任务，单个 Agent 往往顾此失彼。本文不仅提出要用“多 Agent 协作”，还提出用 **多臂老虎机 (MAB)** 算法来自动搜索最优的 Agent 层级结构（谁负责定位 bug，谁负责修，谁负责测）。\n> **战绩:** 在 SWE-bench-Live 上排名第二，甚至击败了更大型的模型。\n\n**6. [Web Agent] 嵌套式浏览器学习框架**\n**Nested Browser-Use Learning for Agentic Information Seeking**\n> Baixuan Li et al.\n> **核心:** 针对 Web Agent 只能看 API 或简单 URL 的痛点，提出了 **NestBrowse**。它将“交互控制”与“页面探索”解耦，让 Agent 能像人一样深度浏览网页获取信息，大幅提升了信息搜寻能力。\n\n**7. [安全基准] TRAP: Web Agent 的任务重定向劝说基准**\n**It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents**\n> Karolina Korgul et al.\n> **核心:** 这是一个针对 Web Agent 的“陷阱”测试。研究发现，通过在网页中隐藏对抗性指令（Prompt Injection），可以轻易诱导 Agent 偏离原本的任务（例如把邮件发给错误的人）。GPT-5 的中招率是 13%，而 DeepSeek-R1 高达 43%。\n\n---\n\n### 🧠 LLM 推理、对齐与安全\n\n**8. [推理加速] 熵感知的投机采样：提升 LLM 推理能力**\n**Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning**\n> Tiancheng Su et al.\n> **核心:** 传统的投机采样（Speculative Decoding）受限于 Draft Model 的能力。本文提出的 **EASD** 引入了熵（Entropy）作为不确定性指标。如果 Draft Model 和 Target Model 都很“迷茫”（高熵），就果断拒绝并重采样。这不仅加速了推理，甚至在某些 Benchmark 上让模型表现超越了原始 Target LLM。\n\n**9. [自我反思] InSPO: 释放 LLM 偏好优化的内在自我反思能力**\n**InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization**\n> Yu Li et al.\n> **核心:** 挑战了 DPO (Direct Preference Optimization)。作者认为 DPO 过于依赖人为的参数选择。**InSPO** 通过让模型在生成时不仅考虑上下文，还对比替代回复，激发模型的“内在自我反思”，在不增加推理开销的情况下优于 DPO。\n\n**10. [鲁棒性测试] DDFT: 语言模型认知鲁棒性的测量协议**\n**The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models**\n> Rahul Baxi\n> **核心:** 模型“知道”知识，但在压力下还能保持正确吗？DDFT 协议通过对抗性地“捏造”事实和压缩语义来给模型施压。结论很扎心：**模型规模大并不代表认知鲁棒性强**，错误检测能力才是关键瓶颈。\n\n**11. [安全解释性] SAILS: 基于稀疏自编码器的可解释安全对齐**\n**Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation**\n> Dianyun Wang et al.\n> **核心:** 如何让模型变安全（不回答有害问题）又保持有用？传统 LoRA 效果一般。SAILS 利用 **稀疏自编码器 (SAE)** 将模型的特征解耦，找到专门控制“安全性”的低秩子空间进行微调。Gemma-2-9B 上实现了 99.6% 的安全率。\n\n---\n\n### 🎨 多模态与生成式 AI\n\n**12. [人体动作] HY-Motion 1.0: 十亿参数级的文本生成 3D 动作模型**\n**HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation**\n> Yuxin Wen, Tencent Hunyuan Team et al.\n> **核心:** 腾讯混元团队发布。这是首个将 DiT (Diffusion Transformer) 扩展到 1B 参数量的 3D 动作生成模型。经过 3000 小时数据预训练和 RLHF，它能听懂复杂的文本指令生成高质量人体动作。\n\n**13. [实时 Avatar] SoulX-FlashTalk: 音频驱动 Avatar 的实时无限流生成**\n**SoulX-FlashTalk: Real-Time Infinite Streaming of Audio-Driven Avatars via Self-Correcting Bidirectional Distillation**\n> Le Shen et al.\n> **核心:** 搞定了一个工程难题：14B 的大模型，实现了 **0.87秒的启动延迟** 和 **32 FPS** 的实时生成。通过“双向蒸馏”和“自我纠正”机制，解决了长时间生成容易崩坏的问题。\n\n**14. [多对象生成] AnyMS: 布局引导的多主体定制化图像生成**\n**AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization**\n> Binhe Yu et al.\n> **核心:** 现在的文生图很难同时画好“一只猫、一只狗和一个杯子”且保持它们各自的特征。AnyMS 提出了一种无需训练（Training-free）的方法，通过解耦 Attention，让每个物体乖乖待在布局规定的地方，互不干扰。\n\n---\n\n### 🔬 AI for Science (医学与金融)\n\n**15. [医学] MedGemma vs GPT-4: 开源模型在医学图像分类上的逆袭**\n**MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images**\n> Md. Sazzadul Islam Prottasha et al.\n> **核心:** 这是一个好消息：经过 LoRA 微调的开源模型 **MedGemma-4b** (80.37% 准确率) 在特定疾病分类任务上击败了未微调的 **GPT-4** (69.58%)。这证明了垂直领域微调依然是王道。\n\n**16. [金融] Alpha-R1: 基于强化学习的 LLM 量化因子挖掘**\n**Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning**\n> Zuoyou Jiang et al.\n> **核心:** 传统的量化金融只看数字，容易失效。Alpha-R1 是一个 8B 的推理模型，它结合了**经济学逻辑**和**实时新闻**来筛选 Alpha 因子。利用 RL 训练后，它能判断一个因子在当前市场环境下是否“Make Sense”，从而避免过拟合。\n\n**17. [病理学] PathFound: 主动搜寻证据的病理诊断 Agent**\n**PathFound: An Agentic Multimodal Model Activating Evidence-seeking Pathological Diagnosis**\n> Shengyi Hua et al.\n> **核心:** 模仿医生看切片的逻辑：不是看一眼就下结论，而是“初步诊断 -> 寻找证据 -> 修正诊断”。PathFound 将这一流程 Agent 化，大幅提升了病理诊断的准确性。\n\n---\n\n### 🍱 其它值得关注的研究\n\n*   **[物理] Autoregressive long-horizon prediction of plasma edge dynamics**: 利用 Transformer 替代昂贵的 SOLPS-ITER 模拟，加速核聚变边缘等离子体研究。\n*   **[安全] Security Without Detection**: 提出“经济拒绝安全 (EDS)”，不靠检测攻击，而是通过增加攻击者的经济成本（计算谜题等）来保护 IoT 设备。\n*   **[评估] The Law of Multi-Model Collaboration**: 提出了多模型协作的 Scaling Law，发现异构模型（不同家族）组队比同构模型组队效果更好。\n*   **[图表] RxnBench**: 一个新的化学反应理解基准，发现现在的多模态模型在理解化学结构和逻辑上还有很大欠缺（准确率<50%）。\n\n---\n**结语：**\n今天的论文让我们看到，AI 正在从“通才”走向“专才”（医学、金融、化学），同时在通用能力上，**Agent 的架构创新**（如层级化、自我反思、技能复用）正在成为突破 Scaling Law 的新路径。\n\n祝大家阅读愉快，科研顺利！",
  "papers": [
    {
      "arxiv_id": "2601.00856v1",
      "title": "Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks",
      "title_zh": "评述：ChatGPT下的大脑：使用AI助手进行短文写作任务时的认知负债累积",
      "authors": [
        "Milos Stankovic",
        "Ella Hirche",
        "Sarah Kollatzsch",
        "Julia Nadine Doetsch"
      ],
      "abstract": "Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.",
      "tldr_zh": "该研究是对 Kosmyna 等人 (2025) 关于使用 AI 助手进行写作任务时产生认知债务 (Cognitive Debt) 这一研究的评论。作者在肯定原研究开创性贡献及自动分析流程 (NLP) 的同时，对其实验结论的解释提出了更为审慎的建议。评述重点关注了原研究在实验设计中的局限性，特别是指出了样本量 (Sample Size) 有限的问题。此外，文章对 EEG 分析的方法论严谨性、数据分析的可重复性 (Reproducibility) 以及结果报告中的不一致性表达了担忧。最后，评述指出原研究在程序透明度方面存在不足，旨在通过这些建设性意见提升相关研究在同行评审出版中的质量与严谨程度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Comment on arXiv:2506.08872",
      "pdf_url": "https://arxiv.org/pdf/2601.00856v1",
      "published_date": "2025-12-29 23:47:19 UTC",
      "updated_date": "2025-12-29 23:47:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:25:45.279900+00:00"
    },
    {
      "arxiv_id": "2512.23898v1",
      "title": "Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City",
      "title_zh": "面向短期太阳辐照度时间序列预测的高效深度学习：Ho Chi Minh City 基准研究",
      "authors": [
        "Tin Hoang"
      ],
      "abstract": "Reliable forecasting of Global Horizontal Irradiance (GHI) is essential for mitigating the variability of solar energy in power grids. This study presents a comprehensive benchmark of ten deep learning architectures for short-term (1-hour ahead) GHI time series forecasting in Ho Chi Minh City, leveraging high-resolution NSRDB satellite data (2011-2020) to compare established baselines (e.g. LSTM, TCN) against emerging state-of-the-art architectures, including Transformer, Informer, iTransformer, TSMixer, and Mamba. Experimental results identify the Transformer as the superior architecture, achieving the highest predictive accuracy with an R^2 of 0.9696. The study further utilizes SHAP analysis to contrast the temporal reasoning of these architectures, revealing that Transformers exhibit a strong \"recency bias\" focused on immediate atmospheric conditions, whereas Mamba explicitly leverages 24-hour periodic dependencies to inform predictions. Furthermore, we demonstrate that Knowledge Distillation can compress the high-performance Transformer by 23.5% while surprisingly reducing error (MAE: 23.78 W/m^2), offering a proven pathway for deploying sophisticated, low-latency forecasting on resource-constrained edge devices.",
      "tldr_zh": "该研究针对胡志明市的短期（提前1小时）全球水平辐照度(Global Horizontal Irradiance, GHI)预测，对十种深度学习架构进行了全面的基准测试。实验对比了包括LSTM、TCN、Transformer、Informer、iTransformer、TSMixer和Mamba在内的多种传统基线与最先进架构。结果表明，Transformer在所有模型中表现最优，其预测准确率达到了0.9696的R^2值。研究进一步通过SHAP分析揭示了不同架构的时间推理差异，发现Transformer表现出强烈的“近期偏差”(recency bias)，主要关注即时大气条件，而Mamba则显式利用24小时的周期性依赖进行预测。此外，研究证明通过知识蒸馏(Knowledge Distillation)能在将Transformer模型压缩23.5%的同时降低预测误差，使MAE达到23.78 W/m^2。该成果为在资源受限的边缘设备上部署高精度、低延迟的太阳能预测系统提供了切实可行的技术路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "preprint, 40 pages",
      "pdf_url": "https://arxiv.org/pdf/2512.23898v1",
      "published_date": "2025-12-29 23:22:25 UTC",
      "updated_date": "2025-12-29 23:22:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:25:51.400058+00:00"
    },
    {
      "arxiv_id": "2512.23889v1",
      "title": "How Large Language Models Systematically Misrepresent American Climate Opinions",
      "title_zh": "大语言模型如何系统性地错误表征美国公众的气候观点",
      "authors": [
        "Sola Kim",
        "Jieshu Wang",
        "Marco A. Janssen",
        "John M. Anderies"
      ],
      "abstract": "Federal agencies and researchers increasingly use large language models to analyze and simulate public opinion. When AI mediates between the public and policymakers, accuracy across intersecting identities becomes consequential; inaccurate group-level estimates can mislead outreach, consultation, and policy design. While research examines intersectionality in LLM outputs, no study has compared these outputs against real human responses across intersecting identities. Climate policy is one such domain, and this is particularly urgent for climate change, where opinion is contested and diverse. We investigate how LLMs represent intersectional patterns in U.S. climate opinions. We prompted six LLMs with profiles of 978 respondents from a nationally representative U.S. climate opinion survey and compared AI-generated responses to actual human answers across 20 questions. We find that LLMs appear to compress the diversity of American climate opinions, predicting less-concerned groups as more concerned and vice versa. This compression is intersectional: LLMs apply uniform gender assumptions that match reality for White and Hispanic Americans but misrepresent Black Americans, where actual gender patterns differ. These patterns, which may be invisible to standard auditing approaches, could undermine equitable climate governance.",
      "tldr_zh": "这项研究探讨了 Large Language Models (LLMs) 在模拟美国公众气候观点时如何产生系统性偏差，特别是在交叉性 (intersectional) 身份背景下的表现。研究团队使用来自美国全国性气候观点调查的 978 名受访者画像对六种 LLMs 进行提示，并将 AI 生成的回答与真实的 20 个问题的人类回答进行对比。研究发现 LLMs 显著压缩了美国气候观点的多样性，即将关注度较低的群体预测为更高，而将关注度高的群体预测为更低。这种压缩现象呈现出交叉性特征，LLMs 采用的统一性别假设虽符合白人和西班牙裔美国人的情况，却误读了黑人群体中独特的性别观点模式。由于这些模式在标准审计方法中可能处于隐身状态，将 LLMs 用于分析公众舆论或辅助政策设计可能会误导外联工作，进而破坏公平的气候治理 (equitable climate governance)。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23889v1",
      "published_date": "2025-12-29 22:29:10 UTC",
      "updated_date": "2025-12-29 22:29:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:25:52.705060+00:00"
    },
    {
      "arxiv_id": "2512.23884v1",
      "title": "Autoregressive long-horizon prediction of plasma edge dynamics",
      "title_zh": "等离子体边缘动力学的自回归长时程预测",
      "authors": [
        "Hunor Csala",
        "Sebastian De Pascuale",
        "Paul Laiu",
        "Jeremy Lore",
        "Jae-Sun Park",
        "Pei Zhang"
      ],
      "abstract": "Accurate modeling of scrape-off layer (SOL) and divertor-edge dynamics is vital for designing plasma-facing components in fusion devices. High-fidelity edge fluid/neutral codes such as SOLPS-ITER capture SOL physics with high accuracy, but their computational cost limits broad parameter scans and long transient studies. We present transformer-based, autoregressive surrogates for efficient prediction of 2D, time-dependent plasma edge state fields. Trained on SOLPS-ITER spatiotemporal data, the surrogates forecast electron temperature, electron density, and radiated power over extended horizons. We evaluate model variants trained with increasing autoregressive horizons (1-100 steps) on short- and long-horizon prediction tasks. Longer-horizon training systematically improves rollout stability and mitigates error accumulation, enabling stable predictions over hundreds to thousands of steps and reproducing key dynamical features such as the motion of high-radiation regions. Measured end-to-end wall-clock times show the surrogate is orders of magnitude faster than SOLPS-ITER, enabling rapid parameter exploration. Prediction accuracy degrades when the surrogate enters physical regimes not represented in the training dataset, motivating future work on data enrichment and physics-informed constraints. Overall, this approach provides a fast, accurate surrogate for computationally intensive plasma edge simulations, supporting rapid scenario exploration, control-oriented studies, and progress toward real-time applications in fusion devices.",
      "tldr_zh": "该研究提出了一种基于 Transformer 的自回归 (autoregressive) 代理模型，旨在实现对 2D 随时间演化的等离子体边缘状态场的高效预测。该方法针对 SOLPS-ITER 等高保真边缘流体/中性代码计算成本过高、难以支持长瞬态研究的问题，利用时空数据对电子温度 (electron temperature)、电子密度 (electron density) 和辐射功率 (radiated power) 进行预测。通过引入长时域 (long-horizon) 训练策略，模型显著提升了滚动预测的稳定性并有效抑制了误差积累，能够复现高辐射区域运动等关键动力学特征。实验结果表明，该代理模型的计算速度比 SOLPS-ITER 快出数个数量级，为聚变装置的快速场景探索、控制研究以及实时应用提供了强有力的支持。尽管在超出训练集物理范围时精度会有所下降，但这一工作为处理计算密集型等离子体模拟提供了高效的替代方案。",
      "categories": [
        "physics.plasm-ph",
        "cs.AI"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23884v1",
      "published_date": "2025-12-29 22:19:27 UTC",
      "updated_date": "2025-12-29 22:19:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:25:53.792252+00:00"
    },
    {
      "arxiv_id": "2512.23881v1",
      "title": "Breaking Audio Large Language Models by Attacking Only the Encoder: A Universal Targeted Latent-Space Audio Attack",
      "title_zh": "仅通过攻击编码器破解音频大语言模型：一种通用的针对性潜空间音频攻击",
      "authors": [
        "Roee Ziv",
        "Raz Lapid",
        "Moshe Sipper"
      ],
      "abstract": "Audio-language models combine audio encoders with large language models to enable multimodal reasoning, but they also introduce new security vulnerabilities. We propose a universal targeted latent space attack, an encoder-level adversarial attack that manipulates audio latent representations to induce attacker-specified outputs in downstream language generation. Unlike prior waveform-level or input-specific attacks, our approach learns a universal perturbation that generalizes across inputs and speakers and does not require access to the language model. Experiments on Qwen2-Audio-7B-Instruct demonstrate consistently high attack success rates with minimal perceptual distortion, revealing a critical and previously underexplored attack surface at the encoder level of multimodal systems.",
      "tldr_zh": "该研究提出了一种针对音频编码器(audio encoder)层级的通用针对性潜在空间攻击(universal targeted latent space attack)，旨在通过操纵音频潜在表示(latent representations)来诱导下游语言模型生成攻击者指定的输出。与以往的波形级别或特定输入的攻击不同，该方法通过学习一种通用扰动(universal perturbation)，能够在不同输入和说话者之间实现泛化，且无需访问大型语言模型(LLM)。在Qwen2-Audio-7B-Instruct上的实验结果显示，该攻击在感官失真(perceptual distortion)极低的情况下，依然能够保持持续且极高的攻击成功率。这项工作揭示了多模态系统(multimodal systems)中编码器层级一个关键且此前未被充分探索的攻击面，为评估和增强音频语言模型的安全性提供了重要见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23881v1",
      "published_date": "2025-12-29 21:56:13 UTC",
      "updated_date": "2025-12-29 21:56:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:26:21.880935+00:00"
    },
    {
      "arxiv_id": "2512.23880v1",
      "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution",
      "title_zh": "CASCADE：基于自主发展与演进的累积式智能体技能构建",
      "authors": [
        "Xu Huang",
        "Junwu Chen",
        "Yuxing Fei",
        "Zhuohan Li",
        "Philippe Schwaller",
        "Gerbrand Ceder"
      ],
      "abstract": "Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from \"LLM + tool use\" to \"LLM + skill acquisition\". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.",
      "tldr_zh": "该研究提出了CASCADE，一个通过自主开发和进化实现累积智能体技能创建的自我进化框架，标志着从“LLM + 工具使用”向“LLM + 技能获取”的范式转变。CASCADE使智能体能够通过两种元技能（Meta-skills）掌握复杂的外部工具并编码知识，包括通过Web Search和Code Extraction进行的持续学习，以及通过Introspection和Knowledge Graph探索进行的自我反思。在包含116项材料科学和化学研究任务的SciSkillBench基准测试中，CASCADE配合GPT-5实现了93.3%的成功率，远高于无进化机制时的35.4%。该框架在计算分析、自主实验室实验和选择性复现已发表论文等现实场景中展示了卓越的应用潜力。通过Human-agent Collaboration和Memory Consolidation，CASCADE能够积累可在智能体与科学家之间共享的可执行技能，为实现可扩展的AI辅助科学研究奠定了基础。",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23880v1",
      "published_date": "2025-12-29 21:50:23 UTC",
      "updated_date": "2025-12-29 21:50:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:25:57.852782+00:00"
    },
    {
      "arxiv_id": "2512.23862v1",
      "title": "Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining",
      "title_zh": "探究压缩记忆的极限：Infini-Attention 在小规模预训练中的研究",
      "authors": [
        "Ruizhe Huang",
        "Kexuan Zhang",
        "Yihao Fang",
        "Baifeng Yu"
      ],
      "abstract": "This study investigates small-scale pretraining for Small Language Models (SLMs) to enable efficient use of limited data and compute, improve accessibility in low-resource settings and reduce costs. To enhance long-context extrapolation in compact models, we focus on Infini-attention, which builds a compressed memory from past segments while preserving local attention. In our work, we conduct an empirical study using 300M-parameter LLaMA models pretrained with Infini-attention. The model demonstrates training stability and outperforms the baseline in long-context retrieval. We identify the balance factor as a key part of the model performance, and we found that retrieval accuracy drops with repeated memory compressions over long sequences. Even so, Infini-attention still effectively compensates for the SLM's limited parameters. Particularly, despite performance degradation at a 16,384-token context, the Infini-attention model achieves up to 31% higher accuracy than the baseline. Our findings suggest that achieving robust long-context capability in SLMs benefits from architectural memory like Infini-attention.",
      "tldr_zh": "该研究调查了针对小语言模型（Small Language Models, SLMs）的小规模预训练，旨在有限资源下提升长文本处理效率，并重点探讨了 Infini-attention 机制。该机制通过保留局部注意力（local attention）并利用过去片段构建压缩内存（compressed memory），在 300M 参数的 LLaMA 模型上实现了优于基线的训练稳定性和长上下文检索（long-context retrieval）性能。实验发现平衡因子（balance factor）对模型表现至关重要，虽然检索准确率会随长序列的多次压缩而有所下降，但 Infini-attention 仍能有效弥补模型参数量较小的局限。特别是在 16,384 token 的上下文场景下，该模型的准确率比基线高出多达 31%。最后，研究指出利用 Infini-attention 等架构内存（architectural memory）是实现 SLMs 稳健长文本能力的关键途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23862v1",
      "published_date": "2025-12-29 21:02:14 UTC",
      "updated_date": "2025-12-29 21:02:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:26:06.457030+00:00"
    },
    {
      "arxiv_id": "2512.23860v2",
      "title": "Lifelong Domain Adaptive 3D Human Pose Estimation",
      "title_zh": "终身领域自适应 3D 人体姿态估计",
      "authors": [
        "Qucheng Peng",
        "Hongfei Xue",
        "Pu Wang",
        "Chen Chen"
      ],
      "abstract": "3D Human Pose Estimation (3D HPE) is vital in various applications, from person re-identification and action recognition to virtual reality. However, the reliance on annotated 3D data collected in controlled environments poses challenges for generalization to diverse in-the-wild scenarios. Existing domain adaptation (DA) paradigms like general DA and source-free DA for 3D HPE overlook the issues of non-stationary target pose datasets. To address these challenges, we propose a novel task named lifelong domain adaptive 3D HPE. To our knowledge, we are the first to introduce the lifelong domain adaptation to the 3D HPE task. In this lifelong DA setting, the pose estimator is pretrained on the source domain and subsequently adapted to distinct target domains. Moreover, during adaptation to the current target domain, the pose estimator cannot access the source and all the previous target domains. The lifelong DA for 3D HPE involves overcoming challenges in adapting to current domain poses and preserving knowledge from previous domains, particularly combating catastrophic forgetting. We present an innovative Generative Adversarial Network (GAN) framework, which incorporates 3D pose generators, a 2D pose discriminator, and a 3D pose estimator. This framework effectively mitigates domain shifts and aligns original and augmented poses. Moreover, we construct a novel 3D pose generator paradigm, integrating pose-aware, temporal-aware, and domain-aware knowledge to enhance the current domain's adaptation and alleviate catastrophic forgetting on previous domains. Our method demonstrates superior performance through extensive experiments on diverse domain adaptive 3D HPE datasets.",
      "tldr_zh": "该研究针对3D人体姿态估计(3D HPE)在多样化野外场景中泛化能力不足的问题，首次提出了终身领域自适应3D人体姿态估计(Lifelong Domain Adaptive 3D HPE)这一新任务。在无法访问源域和历史目标域数据的约束下，该任务旨在应对持续学习中的领域偏移和灾难性遗忘(Catastrophic Forgetting)挑战。为此，研究者提出了一种创新的生成对抗网络(GAN)框架，通过整合3D姿态生成器、2D姿态判别器和3D姿态估计器来对齐原始与增强姿态。该框架核心在于构建了一种集成了姿态感知(Pose-aware)、时间感知(Temporal-aware)和领域感知(Domain-aware)知识的生成器范式，显著增强了对当前域的适应性并有效保留了历史知识。实验证明，该方法在多种领域自适应数据集上均取得了优越性能，为实现稳健的持续性3D姿态估计提供了有效方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.23860v2",
      "published_date": "2025-12-29 20:56:06 UTC",
      "updated_date": "2026-01-15 04:43:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:26:08.094149+00:00"
    },
    {
      "arxiv_id": "2512.23859v1",
      "title": "Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis",
      "title_zh": "寻求深夜生命线：心理健康危机中对话式 AI 的使用体验",
      "authors": [
        "Leah Hope Ajmani",
        "Arka Ghosh",
        "Benjamin Kaveladze",
        "Eugenia Kim",
        "Keertana Namuduri",
        "Theresa Nguyen",
        "Ebele Okoli",
        "Jessica Schleider",
        "Denae Ford",
        "Jina Suh"
      ],
      "abstract": "Online, people often recount their experiences turning to conversational AI agents (e.g., ChatGPT, Claude, Copilot) for mental health support -- going so far as to replace their therapists. These anecdotes suggest that AI agents have great potential to offer accessible mental health support. However, it's unclear how to meet this potential in extreme mental health crisis use cases. In this work, we explore the first-person experience of turning to a conversational AI agent in a mental health crisis. From a testimonial survey (n = 53) of lived experiences, we find that people use AI agents to fill the in-between spaces of human support; they turn to AI due to lack of access to mental health professionals or fears of burdening others. At the same time, our interviews with mental health experts (n = 16) suggest that human-human connection is an essential positive action when managing a mental health crisis. Using the stages of change model, our results suggest that a responsible AI crisis intervention is one that increases the user's preparedness to take a positive action while de-escalating any intended negative action. We discuss the implications of designing conversational AI agents as bridges towards human-human connection rather than ends in themselves.",
      "tldr_zh": "该研究探讨了用户在心理健康危机（mental health crisis）中使用对话式人工智能（Conversational AI）的真实体验。研究通过对53名具有实际经历的用户进行见证式调查（testimonial survey），并结合16名心理健康专家的访谈，分析了AI在危机干预中的作用与局限。结果显示，用户主要利用AI填补人类支持系统的空白，其动因通常是难以获取专业心理健康服务或担心给他人造成负担。与此同时，心理健康专家强调人际连接（human-human connection）在管理危机时依然是核心的积极要素。基于跨理论模型（stages of change model），研究提出负责任的AI危机干预应在缓解用户负面行为意图的同时，提高其采取积极行动的准备度。论文最终指出，应将对话式人工智能设计为引导用户建立人际连接的桥梁，而非将其视为心理支持的终点。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23859v1",
      "published_date": "2025-12-29 20:52:17 UTC",
      "updated_date": "2025-12-29 20:52:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:26:17.914920+00:00"
    },
    {
      "arxiv_id": "2601.03278v1",
      "title": "A Quantum Model for Constrained Markowitz Modern Portfolio Using Slack Variables to Process Mixed-Binary Optimization under QAOA",
      "title_zh": "QAOA 框架下利用松弛变量处理混合二进制优化的约束性马科维茨现代投资组合量子模型",
      "authors": [
        "Pablo Thomassin",
        "Guillaume Guerard",
        "Sonia Djebali",
        "Vincent Marc Lambert"
      ],
      "abstract": "Effectively encoding inequality constraints is a primary obstacle in applying quantum algorithms to financial optimization. A quantum model for Markowitz portfolio optimization is presented that resolves this by embedding slack variables directly into the problem Hamiltonian. The method maps each slack variable to a dedicated ancilla qubit, transforming the problem into a Quadratic Unconstrained Binary Optimization (QUBO) formulation suitable for the Quantum Approximate Optimization Algorithm (QAOA). This process internalizes the constraints within the quantum state, altering the problem's energy landscape to facilitate optimization. The model is empirically validated through simulation, showing it consistently finds the optimal portfolio where a standard penalty-based QAOA fails. This work demonstrates that modifying the Hamiltonian architecture via a slack-ancilla scheme provides a robust and effective pathway for solving constrained optimization problems on quantum computers. A fundamental quantum limit on the simultaneous precision of portfolio risk and return is also posited.",
      "tldr_zh": "该研究针对金融优化中不等式约束编码困难的问题，提出了一种用于 Markowitz 投资组合优化的量子模型。该方法通过将 Slack Variables 直接嵌入到问题的 Hamiltonian 中，并将其映射到专用的 Ancilla Qubit，成功将约束优化问题转化为适用于 QAOA 的 QUBO 形式。这种处理过程将约束内化于量子态内，通过改变问题的 Energy Landscape 来显著促进优化过程。实验模拟结果显示，在标准的基于惩罚项的 QAOA 算法失效的情况下，该模型仍能稳定地找到最优投资组合。该研究证明了利用 Slack-Ancilla 方案修改 Hamiltonian 结构是量子计算机解决受限优化问题的有效途径，并提出了一项关于投资组合风险与收益同时精确度的基本量子限制。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.03278v1",
      "published_date": "2025-12-29 20:40:16 UTC",
      "updated_date": "2025-12-29 20:40:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:26:47.314742+00:00"
    },
    {
      "arxiv_id": "2512.23850v1",
      "title": "The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models",
      "title_zh": "DDFT（钻取与伪造测试）：一种评估语言模型认识论鲁棒性的协议",
      "authors": [
        "Rahul Baxi"
      ],
      "abstract": "Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.",
      "tldr_zh": "该研究提出了钻取与伪造测试(Drill-Down and Fabricate Test, DDFT)，这是一种专门用于衡量语言模型在语义压缩和对抗性伪造压力下保持事实准确性的认识论鲁棒性(epistemic robustness)的评估协议。研究提出了一个由生成文本的语义系统(Semantic System)和负责验证的认识论验证器(Epistemic Verifier)组成的认知模型，并对9个前沿模型进行了多维度的深入评估。实验发现，认识论鲁棒性与模型的参数规模(parameter count)或架构类型(architectural type)并无显著相关性，表明鲁棒性源于与当前主流方法不同的训练方法和验证机制。错误检测能力(error detection capability)被确定为提升鲁棒性的关键瓶颈，且研究观察到旗舰级模型也可能表现出脆性，而小规模模型反而能达到较高的鲁棒性水平。该框架不仅挑战了模型规模与可靠性正相关的传统假设，也为在关键领域部署语言模型前的安全性评估提供了理论支撑和实用工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Currently under review at TMLR",
      "pdf_url": "https://arxiv.org/pdf/2512.23850v1",
      "published_date": "2025-12-29 20:29:09 UTC",
      "updated_date": "2025-12-29 20:29:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:01.011554+00:00"
    },
    {
      "arxiv_id": "2512.23849v1",
      "title": "Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense",
      "title_zh": "无需检测的安全：将经济阻断作为边缘与物联网防御的原语",
      "authors": [
        "Samaresh Kumar Singh",
        "Joyjit Roy"
      ],
      "abstract": "Detection-based security fails against sophisticated attackers using encryption, stealth, and low-rate techniques, particularly in IoT/edge environments where resource constraints preclude ML-based intrusion detection. We present Economic Denial Security (EDS), a detection-independent framework that makes attacks economically infeasible by exploiting a fundamental asymmetry: defenders control their environment while attackers cannot. EDS composes four mechanisms adaptive computational puzzles, decoy-driven interaction entropy, temporal stretching, and bandwidth taxation achieving provably superlinear cost amplification. We formalize EDS as a Stackelberg game, deriving closed-form equilibria for optimal parameter selection (Theorem 1) and proving that mechanism composition yields 2.1x greater costs than the sum of individual mechanisms (Theorem 2). EDS requires < 12KB memory, enabling deployment on ESP32 class microcontrollers. Evaluation on a 20-device heterogeneous IoT testbed across four attack scenarios (n = 30 trials, p < 0.001) demonstrates: 32-560x attack slowdown, 85-520:1 cost asymmetry, 8-62% attack success reduction, < 20ms latency overhead, and close to 0% false positives. Validation against IoT-23 malware (Mirai, Torii, Hajime) shows 88% standalone mitigation; combined with ML-IDS, EDS achieves 94% mitigation versus 67% for IDS alone a 27% improvement. EDS provides detection-independent protection suitable for resource-constrained environments where traditional approaches fail. The ability to detect and mitigate the malware samples tested was enhanced; however, the benefits provided by EDS were realized even without the inclusion of an IDS. Overall, the implementation of EDS serves to shift the economic balance in favor of the defender and provides a viable method to protect IoT and edge systems methodologies.",
      "tldr_zh": "该研究提出了Economic Denial Security (EDS)，这是一种不依赖于检测(detection-independent)的防御框架，旨在解决物联网(IoT)和边缘计算环境在资源受限下难以应对复杂加密及低速率攻击的问题。该框架通过结合自适应计算谜题(adaptive computational puzzles)、诱饵驱动的交互熵(decoy-driven interaction entropy)、时间拉伸(temporal stretching)和带宽税收(bandwidth taxation)四种机制，利用防御者对环境的控制权实现对攻击成本的超线性放大。研究将EDS形式化为Stackelberg game，通过理论证明了机制组合产生的攻击成本比单一机制之和高出2.1倍。EDS在实现上仅需小于12KB的内存，能够部署在ESP32级别的微控制器上，且增加的延迟低于20ms。实验结果显示，该框架使攻击速度降低了32-560倍，实现了高达520:1的成本不对称性。针对Mirai、Torii和Hajime等恶意软件的测试表明，EDS在独立运行时可实现88%的缓解效果，与传统的入侵检测系统(ML-IDS)结合时可将缓解率从67%提升至94%，为资源受限环境提供了一种高效且不依赖于检测的防御新范式。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 2 figures, submitted to 3rd International Conference on Intelligent Digitization of Systems and Services (IDSS2026)",
      "pdf_url": "https://arxiv.org/pdf/2512.23849v1",
      "published_date": "2025-12-29 20:28:46 UTC",
      "updated_date": "2025-12-29 20:28:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:08.157313+00:00"
    },
    {
      "arxiv_id": "2512.23844v1",
      "title": "From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering",
      "title_zh": "从正确性到协作：面向软件工程 AI 智能体行为评估的以人为中心框架",
      "authors": [
        "Tao Dong",
        "Harini Sampath",
        "Ja Young Lee",
        "Sherry Y. Shi",
        "Andrew Macvean"
      ],
      "abstract": "As Large Language Models (LLMs) evolve from code generators into collaborative partners for software engineers, our methods for evaluation are lagging. Current benchmarks, focused on code correctness, fail to capture the nuanced, interactive behaviors essential for successful human-AI partnership. To bridge this evaluation gap, this paper makes two core contributions. First, we present a foundational taxonomy of desirable agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. This taxonomy defines four key expectations of agent behavior: Adhere to Standards and Processes, Ensure Code Quality and Reliability, Solving Problems Effectively, and Collaborating with the User.\n  Second, recognizing that these expectations are not static, we introduce the Context-Adaptive Behavior (CAB) Framework. This emerging framework reveals how behavioral expectations shift along two empirically-derived axes: the Time Horizon (from immediate needs to future ideals), established through interviews with 15 expert engineers, and the Type of Work (from enterprise production to rapid prototyping, for example), identified through a prompt analysis of a prototyping agent. Together, these contributions offer a human-centered foundation for designing and evaluating the next generation of AI agents, moving the field's focus from the correctness of generated code toward the dynamics of true collaborative intelligence.",
      "tldr_zh": "随着大型语言模型(LLMs)从代码生成器演变为软件工程师的协作伙伴，该研究指出目前的评估指标由于过度关注代码正确性(Correctness)而无法捕捉人类与AI协作中至关重要的交互行为。为此，本文首先通过分析91组用户定义的智能体规则，构建了一个企业级软件工程智能体行为的分类学(Taxonomy)，涵盖了遵守标准与流程、确保代码质量与可靠性、有效解决问题及与用户协作(Collaborating with the User)四大核心维度。其次，研究提出了语境自适应行为(CAB)框架(Context-Adaptive Behavior Framework)，该框架通过对15位专家工程师的访谈和原型智能体的提示分析，揭示了行为预期在时间跨度(Time Horizon)和工作类型(Type of Work)两个轴线上的动态演变。该项工作的核心贡献在于为设计和评估下一代AI智能体提供了一个以人为中心的理论基础，推动研究重心从单一的代码正确性转向真正的协作智能(Collaborative Intelligence)动态。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23844v1",
      "published_date": "2025-12-29 20:18:57 UTC",
      "updated_date": "2025-12-29 20:18:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:07.461084+00:00"
    },
    {
      "arxiv_id": "2601.00029v1",
      "title": "From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers",
      "title_zh": "From Clay to Code：AI 对 Iranian 鸽塔解读中的类型学与物质性推理",
      "authors": [
        "Abolhassan Pishahang",
        "Maryam Badiei"
      ],
      "abstract": "This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.",
      "tldr_zh": "该研究探讨了生成式人工智能（Generative AI）系统如何解读民居建筑形式中所蕴含的建筑智能，并以伊朗鸽子塔（Iranian pigeon tower）作为研究案例。研究在参考性、适应性和投机性三个提示阶段，测试了 Midjourney v6、DALL-E 3 和基于 Stable Diffusion XL (SDXL) 的 DreamStudio 三种扩散模型。通过类型学（typology）、物质性（materiality）、环境、现实主义和文化特异性五个维度的评估框架，研究发现人工智能虽能可靠地重现几何图案，但在理解材料和气候逻辑方面存在明显偏差。结果表明，参考图像的使用虽提升了现实感却限制了创造力，而脱离参考的生成虽然具有创意，但在文化表征上较为模糊。该发现界定了视觉相似性与建筑推理（architectural reasoning）之间的界限，并提出了计算民居推理（computational vernacular reasoning）框架，为分析人工智能如何感知、扭曲及重构传统设计智能提供了理论基础。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Proceedings of SIGraDi 2025: XXIX International Conference of the Ibero-American Society of Digital Graphics, Córdoba, Argentina, 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.00029v1",
      "published_date": "2025-12-29 20:03:48 UTC",
      "updated_date": "2025-12-29 20:03:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:30.610162+00:00"
    },
    {
      "arxiv_id": "2512.23837v1",
      "title": "Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation",
      "title_zh": "Adversarial Lens：利用注意力层生成用于评估的对抗样本",
      "authors": [
        "Kaustubh Dhole"
      ],
      "abstract": "Recent advances in mechanistic interpretability suggest that intermediate attention layers encode token-level hypotheses that are iteratively refined toward the final output. In this work, we exploit this property to generate adversarial examples directly from attention-layer token distributions. Unlike prompt-based or gradient-based attacks, our approach leverages model-internal token predictions, producing perturbations that are both plausible and internally consistent with the model's own generation process. We evaluate whether tokens extracted from intermediate layers can serve as effective adversarial perturbations for downstream evaluation tasks. We conduct experiments on argument quality assessment using the ArgQuality dataset, with LLaMA-3.1-Instruct-8B serving as both the generator and evaluator. Our results show that attention-based adversarial examples lead to measurable drops in evaluation performance while remaining semantically similar to the original inputs. However, we also observe that substitutions drawn from certain layers and token positions can introduce grammatical degradation, limiting their practical effectiveness. Overall, our findings highlight both the promise and current limitations of using intermediate-layer representations as a principled source of adversarial examples for stress-testing LLM-based evaluation pipelines.",
      "tldr_zh": "该研究提出了 Adversarial Lens，一种利用 Transformer 模型中间注意力层（attention layers）的 token 分布生成对抗样本的方法。与传统的基于提示（prompt-based）或梯度（gradient-based）的攻击不同，该方法直接利用模型内部的 token 预测，生成与模型自身生成过程逻辑一致且具有合理性的扰动。研究人员在 ArgQuality 数据集上利用 LLaMA-3.1-Instruct-8B 模型进行了论点质量评估实验。结果表明，这种基于注意力层的对抗样本能够有效导致评估性能下降，且样本在语义上与原始输入保持相似。此外，研究还发现从特定层级提取的 token 可能会导致语法降级，这指出了该方法目前的局限性。该项工作为利用中间层表示对大语言模型（LLM）评估流水线进行压力测试提供了新的视角和改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23837v1",
      "published_date": "2025-12-29 19:59:52 UTC",
      "updated_date": "2025-12-29 19:59:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:13.723207+00:00"
    },
    {
      "arxiv_id": "2512.23836v1",
      "title": "Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?",
      "title_zh": "检索增强问答：大语言模型何时应当承认无知？",
      "authors": [
        "Dingmin Wang",
        "Ji Ma",
        "Shankar Kumar"
      ],
      "abstract": "The success of expanded context windows in Large Language Models (LLMs) has driven increased use of broader context in retrieval-augmented generation. We investigate the use of LLMs for retrieval augmented question answering. While longer contexts make it easier to incorporate targeted knowledge, they introduce more irrelevant information that hinders the model's generation process and degrades its performance. To address the issue, we design an adaptive prompting strategy which involves splitting the retrieved information into smaller chunks and sequentially prompting a LLM to answer the question using each chunk. Adjusting the chunk size allows a trade-off between incorporating relevant information and reducing irrelevant information. Experimental results on three open-domain question answering datasets demonstrate that the adaptive strategy matches the performance of standard prompting while using fewer tokens. Our analysis reveals that when encountering insufficient information, the LLM often generates incorrect answers instead of declining to respond, which constitutes a major source of error. This finding highlights the need for further research into enhancing LLMs' ability to effectively decline requests when faced with inadequate information.",
      "tldr_zh": "这项研究探讨了在检索增强生成 (retrieval-augmented generation) 中，长上下文虽然有助于整合知识，但引入的无关信息会干扰大语言模型 (LLMs) 的生成并降低性能。针对此问题，作者提出了一种自适应提示策略 (adaptive prompting strategy)，通过将检索信息分割为较小的块并依次提示模型回答，实现了相关信息提取与无关信息减少之间的平衡。实验结果表明，该策略在三个开放域问答数据集上以更少的 Token 消耗达到了与标准提示相当的性能。分析还揭示了一个关键发现：当检索信息不足时，模型通常会生成错误答案而非承认无知，这成为了主要错误来源。该研究由此强调，急需增强 LLMs 在面对不充分信息时有效拒绝回答的能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23836v1",
      "published_date": "2025-12-29 19:59:10 UTC",
      "updated_date": "2025-12-29 19:59:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:13.311060+00:00"
    },
    {
      "arxiv_id": "2512.23835v1",
      "title": "Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms",
      "title_zh": "新闻偏见检测解释：Transformer 模型决策机制的 SHAP 对比分析",
      "authors": [
        "Himel Ghosh"
      ],
      "abstract": "Automated bias detection in news text is heavily used to support journalistic analysis and media accountability, yet little is known about how bias detection models arrive at their decisions or why they fail. In this work, we present a comparative interpretability study of two transformer-based bias detection models: a bias detector fine-tuned on the BABE dataset and a domain-adapted pre-trained RoBERTa model fine-tuned on the BABE dataset, using SHAP-based explanations. We analyze word-level attributions across correct and incorrect predictions to characterize how different model architectures operationalize linguistic bias. Our results show that although both models attend to similar categories of evaluative language, they differ substantially in how these signals are integrated into predictions. The bias detector model assigns stronger internal evidence to false positives than to true positives, indicating a misalignment between attribution strength and prediction correctness and contributing to systematic over-flagging of neutral journalistic content. In contrast, the domain-adaptive model exhibits attribution patterns that better align with prediction outcomes and produces 63\\% fewer false positives. We further demonstrate that model errors arise from distinct linguistic mechanisms, with false positives driven by discourse-level ambiguity rather than explicit bias cues. These findings highlight the importance of interpretability-aware evaluation for bias detection systems and suggest that architectural and training choices critically affect both model reliability and deployment suitability in journalistic contexts.",
      "tldr_zh": "该研究针对新闻偏见检测自动化过程中的模型决策机制，对比分析了基于 SHAP (Shapley Additive Explanations) 的两种 Transformer 模型：在 BABE 数据集上微调的偏见检测模型以及领域自适应的 RoBERTa 预训练模型。研究通过词级归因 (word-level attributions) 分析了模型在正确和错误预测中的决策逻辑，揭示了不同架构如何将语言偏见转化为预测信号。结果显示，尽管两款模型关注类似的评价性语言类别，但在处理信号的方式上存在显著差异。其中偏见检测模型在处理假阳性 (false positives) 时比真阳性 (true positives) 分配了更强的内部证据，导致对中立新闻内容的系统性误报。相比之下，领域自适应模型 (domain-adaptive model) 的归因模式与预测结果吻合度更高，且假阳性率降低了 63%。进一步研究发现，模型错误主要源于话语层面的歧义 (discourse-level ambiguity) 而非明确的偏见线索。该研究强调了可解释性评估在偏见检测系统中的重要性，并指出架构和训练选择对模型在新闻背景下的可靠性和部署适用性具有关键影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23835v1",
      "published_date": "2025-12-29 19:58:11 UTC",
      "updated_date": "2025-12-29 19:58:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:19.206271+00:00"
    },
    {
      "arxiv_id": "2512.23834v1",
      "title": "Artificial Intelligence for All? Brazilian Teachers on Ethics, Equity, and the Everyday Challenges of AI in Education",
      "title_zh": "人工智能普惠全员？巴西教师谈教育人工智能的伦理、公平与日常挑战",
      "authors": [
        "Bruno Florentino",
        "Camila Sestito",
        "Wellington Cruz",
        "André de Carvalho",
        "Robson Bonidia"
      ],
      "abstract": "This study examines the perceptions of Brazilian K-12 education teachers regarding the use of AI in education, specifically General Purpose AI. This investigation employs a quantitative analysis approach, extracting information from a questionnaire completed by 346 educators from various regions of Brazil regarding their AI literacy and use. Educators vary in their educational level, years of experience, and type of educational institution. The analysis of the questionnaires shows that although most educators had only basic or limited knowledge of AI (80.3\\%), they showed a strong interest in its application, particularly for the creation of interactive content (80.6%), lesson planning (80.2%), and personalized assessment (68.6%). The potential of AI to promote inclusion and personalized learning is also widely recognized (65.5%). The participants emphasized the importance of discussing ethics and digital citizenship, reflecting on technological dependence, biases, transparency, and responsible use of AI, aligning with critical education and the development of conscious students. Despite enthusiasm for the pedagogical potential of AI, significant structural challenges were identified, including a lack of training (43.4%), technical support (41.9%), and limitations of infrastructure, such as low access to computers, reliable Internet connections, and multimedia resources in schools. The study shows that Brazil is still in a bottom-up model for AI integration, missing official curricula to guide its implementation and structured training for teachers and students. Furthermore, effective implementation of AI depends on integrated public policies, adequate teacher training, and equitable access to technology, promoting ethical, inclusive, and contextually grounded adoption of AI in Brazilian K-12 education.",
      "tldr_zh": "这项研究通过对巴西不同地区的346名中小学教师进行定量分析，探讨了他们对教育中应用人工智能(AI)，特别是通用人工智能(General Purpose AI)的认知与态度。调查结果显示，尽管80.3%的教师仅具备基础或有限的人工智能素养(AI literacy)，但他们对AI在互动内容创作、教案编写和个性化评估等方面的应用表现出强烈兴趣，并认可其在促进教育包容性方面的潜力。受访者高度重视人工智能伦理、数字公民意识(digital citizenship)以及算法偏见和透明度等议题，强调了培养学生负责任使用技术的必要性。然而，研究也指出巴西面临缺乏专业培训(43.4%)、技术支持不足(41.9%)及基础设施落后等结构性挑战。目前巴西的AI教育整合呈现“自下而上”的模式，亟需通过整合性的公共政策、系统的教师培训和公平的技术准入，以实现伦理驱动且符合国情的教育变革。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23834v1",
      "published_date": "2025-12-29 19:58:09 UTC",
      "updated_date": "2025-12-29 19:58:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:40.803004+00:00"
    },
    {
      "arxiv_id": "2601.00853v1",
      "title": "FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments",
      "title_zh": "FedSCAM（基于聚类聚合与调制的联邦锐度感知最小化）：异构环境下实现鲁棒联邦优化的抗干扰 SAM",
      "authors": [
        "Sameer Rahil",
        "Zain Abdullah Ahmad",
        "Talha Asif"
      ],
      "abstract": "Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \\textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.",
      "tldr_zh": "该研究针对联邦学习(Federated Learning)中非独立同分布(non-IID)数据带来的挑战，指出目前的Sharpness-Aware Minimization (SAM)方法因采用统一扰动半径而忽视了客户端异质性。为此，作者提出了FedSCAM算法，通过动态调整客户端的扰动半径和聚合权重来增强模型的鲁棒性。该方法利用异质性得分对扰动半径进行反比例调制，能够有效抑制高方差客户端对全局模型的负面影响。此外，FedSCAM还引入了异质性感知加权聚合机制，优先考虑与全局优化方向一致的客户端贡献。在CIFAR-10和Fashion-MNIST上的实验表明，在多种Dirichlet标签偏移场景下，FedSCAM在收敛速度和最终准确率上均显著优于FedSAM和FedLESAM等基线模型。该研究为异构环境下的联邦优化提供了一种高效且具备抗干扰能力的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 27 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.00853v1",
      "published_date": "2025-12-29 19:42:50 UTC",
      "updated_date": "2025-12-29 19:42:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:31.279474+00:00"
    },
    {
      "arxiv_id": "2512.23819v1",
      "title": "Video-Based Performance Evaluation for ECR Drills in Synthetic Training Environments",
      "title_zh": "合成训练环境中 ECR 演练的基于视频的表现评估",
      "authors": [
        "Surya Rayala",
        "Marcos Quinones-Grueiro",
        "Naveeduddin Mohammed",
        "Ashwin T S",
        "Benjamin Goldberg",
        "Randall Spain",
        "Paige Lawton",
        "Gautam Biswas"
      ],
      "abstract": "Effective urban warfare training requires situational awareness and muscle memory, developed through repeated practice in realistic yet controlled environments. A key drill, Enter and Clear the Room (ECR), demands threat assessment, coordination, and securing confined spaces. The military uses Synthetic Training Environments that offer scalable, controlled settings for repeated exercises. However, automatic performance assessment remains challenging, particularly when aiming for objective evaluation of cognitive, psychomotor, and teamwork skills. Traditional methods often rely on costly, intrusive sensors or subjective human observation, limiting scalability and accuracy. This paper introduces a video-based assessment pipeline that derives performance analytics from training videos without requiring additional hardware. By utilizing computer vision models, the system extracts 2D skeletons, gaze vectors, and movement trajectories. From these data, we develop task-specific metrics that measure psychomotor fluency, situational awareness, and team coordination. These metrics feed into an extended Cognitive Task Analysis (CTA) hierarchy, which employs a weighted combination to generate overall performance scores for teamwork and cognition. We demonstrate the approach with a case study of real-world ECR drills, providing actionable, domain specific metrics that capture individual and team performance. We also discuss how these insights can support After Action Reviews with interactive dashboards within Gamemaster and the Generalized Intelligent Framework for Tutoring (GIFT), providing intuitive and understandable feedback. We conclude by addressing limitations, including tracking difficulties, ground-truth validation, and the broader applicability of our approach. Future work includes expanding analysis to 3D video data and leveraging video analysis to enable scalable evaluation within STEs.",
      "tldr_zh": "该研究针对城市作战训练中的核心科目“进入并清理房间”(Enter and Clear the Room, ECR)，提出了一种基于视频的性能评估流水线，旨在解决合成训练环境(Synthetic Training Environments) 中自动评估认知、心理运动和团队协作能力的难题。该系统利用计算机视觉模型从训练视频中提取 2D skeletons、gaze vectors 和运动轨迹，无需额外硬件即可获取性能分析数据。基于这些数据，研究团队开发了衡量 psychomotor fluency、situational awareness 和团队协调性的特定指标，并将其整合到扩展的认知任务分析 (Cognitive Task Analysis, CTA) 体系中，通过加权组合生成整体评分。通过对真实 ECR 演练的案例研究，证明了该方法能够有效捕获个人与团队的表现并提供可操作的领域特定指标。此外，这些见解可通过交互式仪表盘支持 Gamemaster 和 GIFT 框架中的战后复盘 (After Action Reviews)，为受训者提供直观且易于理解的反馈。该工作为在合成训练环境中实现低成本、可扩展的自动化表现评估奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 9 figures, I/ITSEC-2025",
      "pdf_url": "https://arxiv.org/pdf/2512.23819v1",
      "published_date": "2025-12-29 19:30:41 UTC",
      "updated_date": "2025-12-29 19:30:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:34.486643+00:00"
    },
    {
      "arxiv_id": "2512.23817v1",
      "title": "Quantum Error Mitigation with Attention Graph Transformers for Burgers Equation Solvers on NISQ Hardware",
      "title_zh": "基于注意力图 Transformer 的 NISQ 硬件 Burgers 方程求解器量子误差缓解",
      "authors": [
        "Seyed Mohamad Ali Tousi",
        "Adib Bazgir",
        "Yuwen Zhang",
        "G. N. DeSouza"
      ],
      "abstract": "We present a hybrid quantum-classical framework augmented with learned error mitigation for solving the viscous Burgers equation on noisy intermediate-scale quantum (NISQ) hardware. Using the Cole-Hopf transformation, the nonlinear Burgers equation is mapped to a diffusion equation, discretized on uniform grids, and encoded into a quantum state whose time evolution is approximated via Trotterized nearest-neighbor circuits implemented in Qiskit. Quantum simulations are executed on noisy Aer backends and IBM superconducting quantum devices and are benchmarked against high-accuracy classical solutions obtained using a Krylov-based solver applied to the corresponding discretized Hamiltonian. From measured quantum amplitudes, we reconstruct the velocity field and evaluate physical and numerical diagnostics, including the L2 error, shock location, and dissipation rate, both with and without zero-noise extrapolation (ZNE). To enable data-driven error mitigation, we construct a large parametric dataset by sweeping viscosity, time step, grid resolution, and boundary conditions, producing matched tuples of noisy, ZNE-corrected, hardware, and classical solutions together with detailed circuit metadata. Leveraging this dataset, we train an attention-based graph neural network that incorporates circuit structure, light-cone information, global circuit parameters, and noisy quantum outputs to predict error-mitigated solutions. Across a wide range of parameters, the learned model consistently reduces the discrepancy between quantum and classical solutions beyond what is achieved by ZNE alone. We discuss extensions of this approach to higher-dimensional Burgers systems and more general quantum partial differential equation solvers, highlighting learned error mitigation as a promising complement to physics-based noise reduction techniques on NISQ devices.",
      "tldr_zh": "该研究提出了一个量子-经典混合框架，旨在解决 NISQ 硬件上求解黏性 Burgers 方程时的误差缓解问题。该框架利用 Cole-Hopf 变换将非线性方程映射为扩散方程，通过 uniform grids 离散化后，在 IBM 超导量子设备上利用 Trotterized 线路进行演化模拟。研究团队构建了包含线路元数据的大规模参数化数据集，并训练了一个结合电路结构与光锥信息的 Attention-based Graph Neural Network 模型。实验结果显示，通过对量子输出进行数据驱动的误差预测，该模型在评估 L2 error、激波位置和耗散率等指标时，表现出比传统 Zero-Noise Extrapolation (ZNE) 更显著的精度提升。这一方法不仅有效缩小了量子解与经典解之间的差距，也为高维 Burgers 系统及更通用的量子偏微分方程求解器提供了可扩展的误差缓解方案。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23817v1",
      "published_date": "2025-12-29 19:23:20 UTC",
      "updated_date": "2025-12-29 19:23:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:55.840566+00:00"
    },
    {
      "arxiv_id": "2512.23816v1",
      "title": "Improved Bounds for Private and Robust Alignment",
      "title_zh": "隐私与鲁棒对齐的改进界限",
      "authors": [
        "Wenqian Weng",
        "Yi He",
        "Xingyu Zhou"
      ],
      "abstract": "In this paper, we study the private and robust alignment of language models from a theoretical perspective by establishing upper bounds on the suboptimality gap in both offline and online settings. We consider preference labels subject to privacy constraints and/or adversarial corruption, and analyze two distinct interplays between them: privacy-first and corruption-first. For the privacy-only setting, we show that log loss with an MLE-style algorithm achieves near-optimal rates, in contrast to conventional wisdom. For the joint privacy-and-corruption setting, we first demonstrate that existing offline algorithms in fact provide stronger guarantees -- simultaneously in terms of corruption level and privacy parameters -- than previously known, which further yields improved bounds in the corruption-only regime. In addition, we also present the first set of results for private and robust online alignment. Our results are enabled by new uniform convergence guarantees for log loss and square loss under privacy and corruption, which we believe have broad applicability across learning theory and statistics.",
      "tldr_zh": "该研究从理论角度探讨了语言模型在离线和在线场景下的 Private 与 Robust 对齐问题，通过建立 Suboptimality Gap 的上界提升了理论边界。研究针对受隐私约束和 Adversarial Corruption 影响的偏好标签，深入分析了 Privacy-first 与 Corruption-first 两种相互作用模式。在仅考虑隐私的设置中，研究证明了结合 MLE 风格算法的 Log Loss 能实现近乎最优的速率，挑战了关于该领域的传统认知。对于隐私与破坏并存的复杂场景，作者揭示了现有离线算法具备比此前已知更强的保证，并给出了首个 Private 与 Robust 在线对齐的研究结果。该论文的核心贡献在于提出了在隐私和破坏条件下针对 Log Loss 与 Square Loss 的全新 Uniform Convergence 保证，这些理论发现对于学习理论和统计学领域具有广泛的适用价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23816v1",
      "published_date": "2025-12-29 19:20:35 UTC",
      "updated_date": "2025-12-29 19:20:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:27:57.296559+00:00"
    },
    {
      "arxiv_id": "2601.06077v1",
      "title": "One if by Land, Two if by Sea, Three if by Four Seas, and More to Come -- Values of Perception, Prediction, Communication, and Common Sense in Decision Making",
      "title_zh": "一若陆路，二若海路，三若四海，及至未来——感知、预测、通信与常识在决策中的价值",
      "authors": [
        "Aolin Xu"
      ],
      "abstract": "This work aims to rigorously define the values of perception, prediction, communication, and common sense in decision making. The defined quantities are decision-theoretic, but have information-theoretic analogues, e.g., they share some simple but key mathematical properties with Shannon entropy and mutual information, and can reduce to these quantities in particular settings. One interesting observation is that, the value of perception without prediction can be negative, while the value of perception together with prediction and the value of prediction alone are always nonnegative. The defined quantities suggest answers to practical questions arising in the design of autonomous decision-making systems. Example questions include: Do we need to observe and predict the behavior of a particular agent? How important is it? What is the best order to observe and predict the agents? The defined quantities may also provide insights to cognitive science and neural science, toward the understanding of how natural decision makers make use of information gained from different sources and operations.",
      "tldr_zh": "该研究从决策论（decision-theoretic）的角度出发，严格定义了感知（perception）、预测（prediction）、通信（communication）和常识（common sense）在决策过程中的价值。这些定义的量化指标与信息论（information-theoretic）中的香农熵（Shannon entropy）和互信息（mutual information）具有相似的数学属性，并在特定设定下可以简化为这些量。研究发现了一个有趣的现象：在缺乏预测的情况下，感知的价值可能为负值，而感知与预测结合或单纯进行预测的价值则始终是非负的。这些指标为自主决策系统（autonomous decision-making systems）的设计提供了理论依据，可用于判断观察和预测特定智能体的必要性、重要性及其最佳顺序。此外，该项工作还为认知科学和神经科学提供了新见解，有助于深入理解自然决策者如何利用来自不同来源和操作的信息。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.06077v1",
      "published_date": "2025-12-29 19:18:19 UTC",
      "updated_date": "2025-12-29 19:18:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:24.837265+00:00"
    },
    {
      "arxiv_id": "2512.23813v1",
      "title": "StressRoBERTa: Cross-Condition Transfer Learning from Depression, Anxiety, and PTSD to Stress Detection",
      "title_zh": "StressRoBERTa：从抑郁、焦虑和 PTSD 到压力检测的跨条件迁移学习",
      "authors": [
        "Amal Alqahtani",
        "Efsun Kayi",
        "Mona Diab"
      ],
      "abstract": "The prevalence of chronic stress represents a significant public health concern, with social media platforms like Twitter serving as important venues for individuals to share their experiences. This paper introduces StressRoBERTa, a cross-condition transfer learning approach for automatic detection of self-reported chronic stress in English tweets. The investigation examines whether continual training on clinically related conditions (depression, anxiety, PTSD), disorders with high comorbidity with chronic stress, improves stress detection compared to general language models and broad mental health models. RoBERTa is continually trained on the Stress-SMHD corpus (108M words from users with self-reported diagnoses of depression, anxiety, and PTSD) and fine-tuned on the SMM4H 2022 Task 8 dataset. StressRoBERTa achieves 82% F1-score, outperforming the best shared task system (79% F1) by 3 percentage points. The results demonstrate that focused cross-condition transfer from stress-related disorders (+1% F1 over vanilla RoBERTa) provides stronger representations than general mental health training. Evaluation on Dreaddit (81% F1) further demonstrates transfer from clinical mental health contexts to situational stress discussions.",
      "tldr_zh": "该研究提出了StressRoBERTa，这是一种采用跨病症迁移学习(cross-condition transfer learning)方法来自动检测Twitter推文中自我报告的慢性压力的模型。针对慢性压力与抑郁(depression)、焦虑(anxiety)和创伤后应激障碍(PTSD)等病症的高共病性，该方法在包含1.08亿词量的Stress-SMHD语料库上对RoBERTa进行持续训练，并在SMM4H 2022 Task 8数据集上进行微调。实验结果显示，StressRoBERTa达到了82%的F1-score，比该共享任务中表现最好的系统高出3个百分点。研究结果表明，相比于通用语言模型或通用的心理健康模型，利用特定相关的精神障碍进行针对性的跨病症迁移能提供更强的特征表示。此外，该模型在Dreaddit数据集上取得了81%的F1-score，进一步验证了从临床心理健康背景向情景压力讨论进行知识迁移的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23813v1",
      "published_date": "2025-12-29 19:16:14 UTC",
      "updated_date": "2025-12-29 19:16:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:04.452706+00:00"
    },
    {
      "arxiv_id": "2512.23809v1",
      "title": "Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems",
      "title_zh": "面向安全工业物联网防御系统的零信任智能体联邦学习",
      "authors": [
        "Samaresh Kumar Singh",
        "Joyjit Roy",
        "Martin So"
      ],
      "abstract": "Recent attacks on critical infrastructure, including the 2021 Oldsmar water treatment breach and 2023 Danish energy sector compromises, highlight urgent security gaps in Industrial IoT (IIoT) deployments. While Federated Learning (FL) enables privacy-preserving collaborative intrusion detection, existing frameworks remain vulnerable to Byzantine poisoning attacks and lack robust agent authentication. We propose Zero-Trust Agentic Federated Learning (ZTA-FL), a defense in depth framework combining: (1) TPM-based cryptographic attestation achieving less than 0.0000001 false acceptance rate, (2) a novel SHAP-weighted aggregation algorithm providing explainable Byzantine detection under non-IID conditions with theoretical guarantees, and (3) privacy-preserving on-device adversarial training. Comprehensive experiments across three IDS benchmarks (Edge-IIoTset, CIC-IDS2017, UNSW-NB15) demonstrate that ZTA-FL achieves 97.8 percent detection accuracy, 93.2 percent accuracy under 30 percent Byzantine attacks (outperforming FLAME by 3.1 percent, p less than 0.01), and 89.3 percent adversarial robustness while reducing communication overhead by 34 percent. We provide theoretical analysis, failure mode characterization, and release code for reproducibility.",
      "tldr_zh": "该研究提出了零信任智能体联邦学习(Zero-Trust Agentic Federated Learning, ZTA-FL)，旨在解决工业物联网(IIoT)中现有联邦学习(FL)框架面临的拜占庭投毒攻击(Byzantine poisoning attacks)及智能体认证缺失等安全挑战。该框架通过集成基于TPM的密码学身份验证、新型SHAP加权聚合算法以及隐私保护的端侧对抗训练(adversarial training)，构建了多层深度的防御体系。SHAP加权算法在非独立同分布(non-IID)条件下实现了可解释的拜占庭检测，并提供了严谨的理论保障。实验结果显示，ZTA-FL在Edge-IIoTset等多个入侵检测基准上实现了97.8%的检测准确率，并在遭受30%拜占庭攻击时表现出优于FLAME模型的鲁棒性。此外，该方案在保证89.3%对抗鲁棒性的同时，成功降低了34%的通信开销，为构建安全、高效的IIoT防御系统提供了关键技术支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "9 Pages and 6 figures, Submitted in conference 2nd IEEE Conference on Secure and Trustworthy Cyber Infrastructure for IoT and Microelectronics, Houston TX, USA",
      "pdf_url": "https://arxiv.org/pdf/2512.23809v1",
      "published_date": "2025-12-29 19:07:11 UTC",
      "updated_date": "2025-12-29 19:07:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:05.337529+00:00"
    },
    {
      "arxiv_id": "2512.23684v1",
      "title": "Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing",
      "title_zh": "针对基于大语言模型学术评审的多语言隐蔽提示注入攻击",
      "authors": [
        "Panagiotis Theocharopoulos",
        "Ajinkya Kulkarni",
        "Mathew Magimai. -Doss"
      ],
      "abstract": "Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using an LLM. We find that prompt injection induces substantial changes in review scores and accept/reject decisions for English, Japanese, and Chinese injections, while Arabic injections produce little to no effect. These results highlight the susceptibility of LLM-based reviewing systems to document-level prompt injection and reveal notable differences in vulnerability across languages.",
      "tldr_zh": "该研究探讨了基于大语言模型(LLMs)的学术评审系统在面对文档级隐藏提示词注入攻击(Hidden Prompt Injection Attacks)时的脆弱性。研究团队构建了一个包含约500篇ICML录用论文的数据集，并在这些文档中嵌入了英语、日语、中文和阿拉伯语这四种语言且语义等效的对抗性指令。随后，研究者利用LLM对注入了攻击指令的论文进行评审，以评估注入攻击对评审结果的具体影响。实验结果显示，英语、日语和中文的提示词注入能够显著改变评审分数以及录用/拒绝(Accept/Reject)的最终决策，而阿拉伯语的注入几乎没有产生任何影响。这一发现揭示了基于LLM的评审系统对文档级注入攻击的高度敏感性，并指出了不同语言在漏洞脆弱性方面存在的显著差异。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23684v1",
      "published_date": "2025-12-29 18:43:05 UTC",
      "updated_date": "2025-12-29 18:43:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:20.083940+00:00"
    },
    {
      "arxiv_id": "2512.23676v1",
      "title": "Web World Models",
      "title_zh": "Web 世界模型",
      "authors": [
        "Jichen Feng",
        "Yifan Zhang",
        "Chenggong Zhang",
        "Yifu Lu",
        "Shilong Liu",
        "Mengdi Wang"
      ],
      "abstract": "Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the expense of controllability and practical engineering. In this work, we introduce the Web World Model (WWM), a middle ground where world state and ``physics'' are implemented in ordinary web code to ensure logical consistency, while large language models generate context, narratives, and high-level decisions on top of this structured latent state. We build a suite of WWMs on a realistic web stack, including an infinite travel atlas grounded in real geography, fictional galaxy explorers, web-scale encyclopedic and narrative worlds, and simulation- and game-like environments. Across these systems, we identify practical design principles for WWMs: separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation to achieve unlimited but structured exploration. Our results suggest that web stacks themselves can serve as a scalable substrate for world models, enabling controllable yet open-ended environments. Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models.",
      "tldr_zh": "该研究提出了 Web World Model (WWM)，旨在解决语言智能体在需要持久化环境进行行动、记忆和学习时，现有框架在可靠逻辑与无限生成能力之间难以平衡的问题。该模型采用了一种折衷方案，即在普通 Web 代码中实现世界状态和“物理规则”以确保逻辑一致性，同时利用大语言模型 (Large Language Models) 在这种结构化潜在状态之上生成上下文、叙事和高层决策。研究团队基于真实的 Web 技术栈 (Web stack) 构建了一系列应用，包括基于真实地理的无限旅行地图、虚构星系探索器以及百科全书式的叙事世界。研究进一步总结了 WWM 的核心设计原则，即分离代码定义的规则与模型驱动的想象力，将潜在状态表示为类型化的 Web 接口，并利用确定性生成实现无限制但结构化的探索。实验结果表明，Web 技术栈可以作为世界模型的可扩展基座，为开发可控且开放的自主智能体环境提供了有效的路径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models",
      "pdf_url": "https://arxiv.org/pdf/2512.23676v1",
      "published_date": "2025-12-29 18:31:45 UTC",
      "updated_date": "2025-12-29 18:31:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:10.003252+00:00"
    },
    {
      "arxiv_id": "2512.23647v1",
      "title": "Nested Browser-Use Learning for Agentic Information Seeking",
      "title_zh": "面向智能体化信息获取的嵌套式浏览器使用学习",
      "authors": [
        "Baixuan Li",
        "Jialong Wu",
        "Wenbiao Yin",
        "Kuan Li",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Zhengwei Tao",
        "Liwen Zhang",
        "Pengjun Xie",
        "Jingren Zhou",
        "Yong Jiang"
      ],
      "abstract": "Information-seeking (IS) agents have achieved strong performance across a range of wide and deep search tasks, yet their tool use remains largely restricted to API-level snippet retrieval and URL-based page fetching, limiting access to the richer information available through real browsing. While full browser interaction could unlock deeper capabilities, its fine-grained control and verbose page content returns introduce substantial complexity for ReAct-style function-calling agents. To bridge this gap, we propose Nested Browser-Use Learning (NestBrowse), which introduces a minimal and complete browser-action framework that decouples interaction control from page exploration through a nested structure. This design simplifies agentic reasoning while enabling effective deep-web information acquisition. Empirical results on challenging deep IS benchmarks demonstrate that NestBrowse offers clear benefits in practice. Further in-depth analyses underscore its efficiency and flexibility.",
      "tldr_zh": "该研究针对信息搜索(Information-seeking)智能体在API层面的片段检索和基于URL的页面抓取方面存在的局限性，提出了NestBrowse框架。传统的全浏览器交互虽然潜力巨大，但其细粒度的控制和冗长的页面内容为ReAct样式的函数调用(function-calling)智能体带来了巨大的复杂性。为了弥补这一差距，NestBrowse引入了一个极简且完备的浏览器动作框架，通过嵌套结构(nested structure)将交互控制与页面探索进行解耦。这种设计在简化智能体推理过程的同时，使其能够更有效地获取深层网络(deep-web)中的关键信息。在挑战性深层信息搜索基准测试上的实验结果表明，NestBrowse在实际应用中具有显著优势。进一步的深入分析也验证了该框架在执行任务时的效率和灵活性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23647v1",
      "published_date": "2025-12-29 17:59:14 UTC",
      "updated_date": "2025-12-29 17:59:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:19.527025+00:00"
    },
    {
      "arxiv_id": "2512.23633v1",
      "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
      "title_zh": "AI 辅导能够安全有效地支持学生：一项在 UK 课堂开展的探索性随机对照试验",
      "authors": [
        "LearnLM Team",
        "Eedi",
        ":",
        "Albert Wang",
        "Aliya Rysbek",
        "Andrea Huber",
        "Anjali Nambiar",
        "Anna Kenolty",
        "Ben Caulfield",
        "Beth Lilley-Draper",
        "Bibi Groot",
        "Brian Veprek",
        "Chelsea Burdett",
        "Claire Willis",
        "Craig Barton",
        "Digory Smith",
        "George Mu",
        "Harriet Walters",
        "Irina Jurenka",
        "Iris Hulls",
        "James Stalley-Moores",
        "Jonathan Caton",
        "Julia Wilkowski",
        "Kaiz Alarakyia",
        "Kevin R. McKee",
        "Liam McCafferty",
        "Lucy Dalton",
        "Markus Kunesch",
        "Pauline Malubay",
        "Rachel Kidson",
        "Rich Wells",
        "Sam Wheeler",
        "Sara Wiltberger",
        "Shakir Mohamed",
        "Simon Woodhead",
        "Vasco Brazão"
      ],
      "abstract": "One-to-one tutoring is widely considered the gold standard for personalized education, yet it remains prohibitively expensive to scale. To evaluate whether generative AI might help expand access to this resource, we conducted an exploratory randomized controlled trial (RCT) with $N = 165$ students across five UK secondary schools. We integrated LearnLM -- a generative AI model fine-tuned for pedagogy -- into chat-based tutoring sessions on the Eedi mathematics platform. In the RCT, expert tutors directly supervised LearnLM, with the remit to revise each message it drafted until they would be satisfied sending it themselves. LearnLM proved to be a reliable source of pedagogical instruction, with supervising tutors approving 76.4% of its drafted messages making zero or minimal edits (i.e., changing only one or two characters). This translated into effective tutoring support: students guided by LearnLM performed at least as well as students chatting with human tutors on each learning outcome we measured. In fact, students who received support from LearnLM were 5.5 percentage points more likely to solve novel problems on subsequent topics (with a success rate of 66.2%) than those who received tutoring from human tutors alone (rate of 60.7%). In interviews, tutors highlighted LearnLM's strength at drafting Socratic questions that encouraged deeper reflection from students, with multiple tutors even reporting that they learned new pedagogical practices from the model. Overall, our results suggest that pedagogically fine-tuned AI tutoring systems may play a promising role in delivering effective, individualized learning support at scale.",
      "tldr_zh": "这项研究通过在五所英国中学开展涉及165名学生的探索性随机对照试验（RCT），评估了生成式人工智能（Generative AI）在扩展一对一辅导资源方面的潜力。研究团队将针对教学法微调的 LearnLM 模型集成到 Eedi 数学辅导平台中，并由专家导师对 AI 生成的每条信息进行监督与修订。实验结果显示，LearnLM 具有极高的教学可靠性，导师对 76.4% 的草拟信息仅需零修改或极少修改即可发送。在学习成效上，接受 AI 辅助辅导的学生表现不亚于纯人工组，且在解决后续章节新问题时的成功率（66.2%）比纯人工辅导组（60.7%）高出 5.5 个百分点。导师们特别称赞了 LearnLM 在设计苏格拉底式提问（Socratic questions）以引导学生深入思考方面的能力，甚至有导师表示从中学习到了新的教学实践。总体而言，该研究证明了经过教学优化的 AI 辅导系统能够在保障安全和有效性的前提下，为实现大规模个性化教育提供有力支持。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23633v1",
      "published_date": "2025-12-29 17:44:03 UTC",
      "updated_date": "2025-12-29 17:44:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:37.825248+00:00"
    },
    {
      "arxiv_id": "2512.23631v2",
      "title": "BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization",
      "title_zh": "BOAD：基于多臂老虎机优化的分层软件工程智能体自动发现",
      "authors": [
        "Iris Xu",
        "Guangtao Zeng",
        "Zexue He",
        "Charles Jin",
        "Aldo Pareja",
        "Dan Gutfreund",
        "Chuang Gan",
        "Zhang-Wei Hong"
      ],
      "abstract": "Large language models (LLMs) have shown strong reasoning and coding capabilities, yet they struggle to generalize to real-world software engineering (SWE) problems that are long-horizon and out of distribution. Existing systems often rely on a single agent to handle the entire workflow-interpreting issues, navigating large codebases, and implementing fixes-within one reasoning chain. Such monolithic designs force the model to retain irrelevant context, leading to spurious correlations and poor generalization. Motivated by how human engineers decompose complex problems, we propose structuring SWE agents as orchestrators coordinating specialized sub-agents for sub-tasks such as localization, editing, and validation. The challenge lies in discovering effective hierarchies automatically: as the number of sub-agents grows, the search space becomes combinatorial, and it is difficult to attribute credit to individual sub-agents within a team. We address these challenges by formulating hierarchy discovery as a multi-armed bandit (MAB) problem, where each arm represents a candidate sub-agent and the reward measures its helpfulness when collaborating with others. This framework, termed Bandit Optimization for Agent Design (BOAD), enables efficient exploration of sub-agent designs under limited evaluation budgets. On SWE-bench-Verified, BOAD outperforms single-agent and manually designed multi-agent systems. On SWE-bench-Live, featuring more recent and out-of-distribution issues, our 36B system ranks second on the leaderboard at the time of evaluation, surpassing larger models such as GPT-4 and Claude. These results demonstrate that automatically discovered hierarchical multi-agent systems significantly improve generalization on challenging long-horizon SWE tasks. Code is available at https://github.com/iamxjy/BOAD-SWE-Agent.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在处理具有长时程(long-horizon)和分布外(out-of-distribution)特性的现实世界软件工程(SWE)问题时泛化能力不足的问题，提出了将智能体构建为由协调者管理专门化子智能体的层级化系统。为了解决自动发现有效层级结构的组合优化难题，研究者提出了Bandit Optimization for Agent Design (BOAD)框架，将层级发现建模为多臂老虎机(Multi-Armed Bandit, MAB)问题。该框架通过将候选子智能体视为“臂”并以其协作贡献作为奖励，实现了在有限评估预算下对智能体设计空间的高效探索。实验结果显示，BOAD在SWE-bench-Verified基准测试中优于单智能体及人工设计的多智能体系统。在包含最新问题的SWE-bench-Live测试中，该系统的表现位列排行榜第二，性能超越了GPT-4和Claude等更大规模的模型。这一研究证明了自动发现的层级化多智能体架构能显著提升复杂软件工程任务的执行效率与泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23631v2",
      "published_date": "2025-12-29 17:41:11 UTC",
      "updated_date": "2026-01-01 00:11:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:26.046822+00:00"
    },
    {
      "arxiv_id": "2512.23626v1",
      "title": "Regret-Based Federated Causal Discovery with Unknown Interventions",
      "title_zh": "未知干预下基于后悔值的联邦因果发现",
      "authors": [
        "Federico Baldo",
        "Charles K. Assaad"
      ],
      "abstract": "Most causal discovery methods recover a completed partially directed acyclic graph representing a Markov equivalence class from observational data. Recent work has extended these methods to federated settings to address data decentralization and privacy constraints, but often under idealized assumptions that all clients share the same causal model. Such assumptions are unrealistic in practice, as client-specific policies or protocols, for example, across hospitals, naturally induce heterogeneous and unknown interventions. In this work, we address federated causal discovery under unknown client-level interventions. We propose I-PERI, a novel federated algorithm that first recovers the CPDAG of the union of client graphs and then orients additional edges by exploiting structural differences induced by interventions across clients. This yields a tighter equivalence class, which we call the $\\mathbfΦ$-Markov Equivalence Class, represented by the $\\mathbfΦ$-CPDAG. We provide theoretical guarantees on the convergence of I-PERI, as well as on its privacy-preserving properties, and present empirical evaluations on synthetic data demonstrating the effectiveness of the proposed algorithm.",
      "tldr_zh": "该研究针对联邦因果发现(Federated Causal Discovery)中由于客户端特定策略或协议产生的异构且未知的干预(unknown interventions)问题，提出了名为I-PERI的新型联邦算法。该算法突破了以往研究中假设所有客户端必须共享相同因果模型的理想化局限，能够有效处理真实场景下客户端级别的未知干预。I-PERI首先恢复客户端图并集的CPDAG，随后通过利用不同客户端干预所诱导的结构差异来定向更多边缘，从而获得一个比传统方法更紧凑的等价类，即$\\Phi$-Markov Equivalence Class (由$\\Phi$-CPDAG表示)。研究不仅为I-PERI提供了收敛性和隐私保护属性的理论保证，还通过合成数据的实验验证了其在发现因果结构方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23626v1",
      "published_date": "2025-12-29 17:30:01 UTC",
      "updated_date": "2025-12-29 17:30:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:28:50.676159+00:00"
    },
    {
      "arxiv_id": "2512.23624v2",
      "title": "Physics-Informed Neural Networks for Device and Circuit Modeling: A Case Study of NeuroSPICE",
      "title_zh": "物理信息神经网络在器件与电路建模中的应用：以 NeuroSPICE 为例",
      "authors": [
        "Chien-Ting Tung",
        "Chenming Hu"
      ],
      "abstract": "We present NeuroSPICE, a physics-informed neural network (PINN) framework for device and circuit simulation. Unlike conventional SPICE, which relies on time-discretized numerical solvers, NeuroSPICE leverages PINNs to solve circuit differential-algebraic equations (DAEs) by minimizing the residual of the equations through backpropagation. It models device and circuit waveforms using analytical equations in time domain with exact temporal derivatives. While PINNs do not outperform SPICE in speed or accuracy during training, they offer unique advantages such as surrogate models for design optimization and inverse problems. NeuroSPICE's flexibility enables the simulation of emerging devices, including highly nonlinear systems such as ferroelectric memories.",
      "tldr_zh": "该研究提出了NeuroSPICE，这是一个用于器件和电路模拟的物理信息神经网络(PINN)框架。与依赖时间离散化数值解法器的传统SPICE不同，NeuroSPICE通过反向传播(backpropagation)最小化电路微分代数方程(DAEs)的残差。该框架利用时域中的解析方程和精确的时间导数来建模器件及电路波形，确保了物理一致性。虽然PINN在训练阶段的速度或精度上不一定优于SPICE，但它在设计优化和逆问题(inverse problems)求解中展现出作为代理模型(surrogate models)的独特优势。此外，NeuroSPICE的高度灵活性使其能够有效模拟包括铁电存储器(ferroelectric memories)在内的高度非线性新兴器件，为下一代电路仿真提供了新的范式。",
      "categories": [
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to IEEE Electron Device Letters",
      "pdf_url": "https://arxiv.org/pdf/2512.23624v2",
      "published_date": "2025-12-29 17:28:35 UTC",
      "updated_date": "2025-12-31 16:31:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:55.491083+00:00"
    },
    {
      "arxiv_id": "2512.23617v1",
      "title": "Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning",
      "title_zh": "Le Cam 失真：稳健迁移学习的决策论框架",
      "authors": [
        "Deniz Akdemir"
      ],
      "abstract": "Distribution shift is the defining challenge of real-world machine learning. The dominant paradigm--Unsupervised Domain Adaptation (UDA)--enforces feature invariance, aligning source and target representations via symmetric divergence minimization [Ganin et al., 2016]. We demonstrate that this approach is fundamentally flawed: when domains are unequally informative (e.g., high-quality vs degraded sensors), strict invariance necessitates information destruction, causing \"negative transfer\" that can be catastrophic in safety-critical applications [Wang et al., 2019].\n  We propose a decision-theoretic framework grounded in Le Cam's theory of statistical experiments [Le Cam, 1986], using constructive approximations to replace symmetric invariance with directional simulability. We introduce Le Cam Distortion, quantified by the Deficiency Distance $δ(E_1, E_2)$, as a rigorous upper bound for transfer risk conditional on simulability. Our framework enables transfer without source degradation by learning a kernel that simulates the target from the source. Across five experiments (genomics, vision, reinforcement learning), Le Cam Distortion achieves: (1) near-perfect frequency estimation in HLA genomics (correlation $r=0.999$, matching classical methods), (2) zero source utility loss in CIFAR-10 image classification (81.2% accuracy preserved vs 34.7% drop for CycleGAN), and (3) safe policy transfer in RL control where invariance-based methods suffer catastrophic collapse. Le Cam Distortion provides the first principled framework for risk-controlled transfer learning in domains where negative transfer is unacceptable: medical imaging, autonomous systems, and precision medicine.",
      "tldr_zh": "该研究提出了Le Cam Distortion，这是一个基于Le Cam统计实验理论(Le Cam's theory of statistical experiments)的决策论框架，旨在解决鲁棒迁移学习(Robust Transfer Learning)中的分布偏移(Distribution shift)挑战。针对传统无监督领域自适应(UDA)因追求特征不变性(feature invariance)而导致信息损失及负向迁移(negative transfer)的问题，该框架利用方向模拟性(directional simulability)取代了对称不变性。研究引入亏缺距离(Deficiency Distance) $\\delta(E_1, E_2)$ 作为迁移风险的严格上限，通过学习一种能够从源域模拟目标域的核函数，在不退化源域信息的前提下实现有效迁移。在基因组学、计算机视觉和强化学习的多项实验中，该方法展示了极高的预测相关性，并在保持分类准确率的同时避免了策略崩溃。Le Cam Distortion为医学影像、自主系统和精准医疗等安全关键领域提供了首个有原则且风险受控的迁移学习方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23617v1",
      "published_date": "2025-12-29 17:21:44 UTC",
      "updated_date": "2025-12-29 17:21:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:57.062028+00:00"
    },
    {
      "arxiv_id": "2512.23601v1",
      "title": "Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation",
      "title_zh": "大语言模型在创造性问题生成中的发散-收敛思维",
      "authors": [
        "Manh Hung Nguyen",
        "Adish Singla"
      ],
      "abstract": "Large language models (LLMs) have significant potential for generating educational questions and problems, enabling educators to create large-scale learning materials. However, LLMs are fundamentally limited by the ``Artificial Hivemind'' effect, where they generate similar responses within the same model and produce homogeneous outputs across different models. As a consequence, students may be exposed to overly similar and repetitive LLM-generated problems, which harms diversity of thought. Drawing inspiration from Wallas's theory of creativity and Guilford's framework of divergent-convergent thinking, we propose CreativeDC, a two-phase prompting method that explicitly scaffolds the LLM's reasoning into distinct phases. By decoupling creative exploration from constraint satisfaction, our method enables LLMs to explore a broader space of ideas before committing to a final problem. We evaluate CreativeDC for creative problem generation using a comprehensive set of metrics that capture diversity, novelty, and utility. The results show that CreativeDC achieves significantly higher diversity and novelty compared to baselines while maintaining high utility. Moreover, scaling analysis shows that CreativeDC generates a larger effective number of distinct problems as more are sampled, increasing at a faster rate than baseline methods.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在生成教育题目时存在的“人工蜂群效应”(Artificial Hivemind)及由此导致的输出同质化问题，提出了CreativeDC两阶段提示方法。该方法受Wallas创造力理论和Guilford的发散-收敛思维(Divergent-Convergent Thinking)框架启发，通过将创造性探索与约束满足过程解耦，显式地将LLM的推理划分为不同阶段。这种机制使模型在最终确定问题前能够探索更广泛的想法空间，从而提升生成内容的创造力。实验评估结果显示，CreativeDC在多样性(Diversity)和新颖性(Novelty)指标上显著优于基线方法，同时保持了极高的实用性(Utility)。规模化分析进一步表明，CreativeDC随样本量增加生成截然不同问题的效率更高，为大规模、多样化教学材料的自动化生成提供了有效方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2512.23601v1",
      "published_date": "2025-12-29 16:53:48 UTC",
      "updated_date": "2025-12-29 16:53:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:00.141611+00:00"
    },
    {
      "arxiv_id": "2512.23565v4",
      "title": "RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature",
      "title_zh": "RxnBench：用于评估大语言模型对科学文献中化学反应理解能力的多模态基准",
      "authors": [
        "Hanzheng Li",
        "Xi Fang",
        "Yixuan Li",
        "Chaozheng Huang",
        "Junjie Wang",
        "Xi Wang",
        "Hongzhe Bai",
        "Bojun Hao",
        "Shenyu Lin",
        "Huiqi Liang",
        "Linfeng Zhang",
        "Guolin Ke"
      ],
      "abstract": "The integration of Multimodal Large Language Models (MLLMs) into chemistry promises to revolutionize scientific discovery, yet their ability to comprehend the dense, graphical language of reactions within authentic literature remains underexplored. Here, we introduce RxnBench, a multi-tiered benchmark designed to rigorously evaluate MLLMs on chemical reaction understanding from scientific PDFs. RxnBench comprises two tasks: Single-Figure QA (SF-QA), which tests fine-grained visual perception and mechanistic reasoning using 1,525 questions derived from 305 curated reaction schemes, and Full-Document QA (FD-QA), which challenges models to synthesize information from 108 articles, requiring cross-modal integration of text, schemes, and tables. Our evaluation of MLLMs reveals a critical capability gap: while models excel at extracting explicit text, they struggle with deep chemical logic and precise structural recognition. Notably, models with inference-time reasoning significantly outperform standard architectures, yet none achieve 50\\% accuracy on FD-QA. These findings underscore the urgent need for domain-specific visual encoders and stronger reasoning engines to advance autonomous AI chemists.",
      "tldr_zh": "该研究推出了RxnBench，这是一个旨在严格评估多模态大语言模型（MLLMs）在理解科学文献中化学反应能力的综合基准测试。基准包含单图问答（SF-QA）和全文档问答（FD-QA）两项任务，涵盖了细粒度视觉感知、机制推理以及跨文本、示意图和表格的多模态信息整合。评估结果显示，尽管目前的模型擅长提取显性文本，但在深度化学逻辑（chemical logic）和精确结构识别（structural recognition）方面存在明显的性能瓶颈。研究发现具有推理时间推理（inference-time reasoning）的模型表现显著优于标准架构，但在复杂的全文档问答任务中，仍没有模型能够达到50%的准确率。这些发现强调了开发领域特定视觉编码器和更强大推理引擎的紧迫性，以进一步推动自主AI化学家的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23565v4",
      "published_date": "2025-12-29 16:05:38 UTC",
      "updated_date": "2026-01-20 09:46:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:02.688888+00:00"
    },
    {
      "arxiv_id": "2512.23562v1",
      "title": "VL-RouterBench: A Benchmark for Vision-Language Model Routing",
      "title_zh": "VL-RouterBench：视觉-语言模型路由评测基准",
      "authors": [
        "Zhehao Huang",
        "Baijiong Lin",
        "Jingyuan Zhang",
        "Jingying Wang",
        "Yuhang Liu",
        "Ning Lu",
        "Tao Li",
        "Xiaolin Huang"
      ],
      "abstract": "Multi-model routing has evolved from an engineering technique into essential infrastructure, yet existing work lacks a systematic, reproducible benchmark for evaluating vision-language models (VLMs). We present VL-RouterBench to assess the overall capability of VLM routing systems systematically. The benchmark is grounded in raw inference and scoring logs from VLMs and constructs quality and cost matrices over sample-model pairs. In scale, VL-RouterBench covers 14 datasets across 3 task groups, totaling 30,540 samples, and includes 15 open-source models and 2 API models, yielding 519,180 sample-model pairs and a total input-output token volume of 34,494,977. The evaluation protocol jointly measures average accuracy, average cost, and throughput, and builds a ranking score from the harmonic mean of normalized cost and accuracy to enable comparison across router configurations and cost budgets. On this benchmark, we evaluate 10 routing methods and baselines and observe a significant routability gain, while the best current routers still show a clear gap to the ideal Oracle, indicating considerable room for improvement in router architecture through finer visual cues and modeling of textual structure. We will open-source the complete data construction and evaluation toolchain to promote comparability, reproducibility, and practical deployment in multimodal routing research.",
      "tldr_zh": "该研究针对视觉语言模型(Vision-Language Models)多模型路由系统缺乏系统性和可重复性基准的问题，提出了VL-RouterBench评估框架。该基准涵盖了14个数据集、3类任务组，共计30,540个样本，并整合了15个开源模型和2个API模型，形成了一个规模庞大的质量与成本评估矩阵。评估协议综合衡量了准确率、成本和吞吐量，并利用归一化成本与准确率的调和平均值生成排名得分，从而支持在不同成本预算下对Router配置进行公平比较。实验对10种路由方法进行了评估，结果显示现有路由器虽然带来了显著的性能增益，但与理想的Oracle模型相比仍有较大改进空间。研究指出，未来需要通过更精细的视觉线索和文本结构建模来优化Router架构。该研究将开源完整的数据构建与评估工具链，为多模态路由技术的实战部署和后续研究提供了重要的基础设施支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23562v1",
      "published_date": "2025-12-29 16:01:19 UTC",
      "updated_date": "2025-12-29 16:01:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:08.664891+00:00"
    },
    {
      "arxiv_id": "2512.23557v1",
      "title": "Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks",
      "title_zh": "迈向可信代理式人工智能：一种用于防御提示词注入攻击的多模态框架",
      "authors": [
        "Toqeer Ali Syed",
        "Mishal Ateeq Almutairi",
        "Mahmoud Abdel Moaty"
      ],
      "abstract": "Powerful autonomous systems, which reason, plan, and converse using and between numerous tools and agents, are made possible by Large Language Models (LLMs), Vision-Language Models (VLMs), and new agentic AI systems, like LangChain and GraphChain. Nevertheless, this agentic environment increases the probability of the occurrence of multimodal prompt injection (PI) attacks, in which concealed or malicious instructions carried in text, pictures, metadata, or agent-to-agent messages may spread throughout the graph and lead to unintended behavior, a breach of policy, or corruption of state. In order to mitigate these risks, this paper suggests a Cross-Agent Multimodal Provenanc- Aware Defense Framework whereby all the prompts, either user-generated or produced by upstream agents, are sanitized and all the outputs generated by an LLM are verified independently before being sent to downstream nodes. This framework contains a Text sanitizer agent, visual sanitizer agent, and output validator agent all coordinated by a provenance ledger, which keeps metadata of modality, source, and trust level throughout the entire agent network. This architecture makes sure that agent-to-agent communication abides by clear trust frames such such that injected instructions are not propagated down LangChain or GraphChain-style-workflows. The experimental assessments show that multimodal injection detection accuracy is significantly enhanced, and the cross-agent trust leakage is minimized, as well as, agentic execution pathways become stable. The framework, which expands the concept of provenance tracking and validation to the multi-agent orchestration, enhances the establishment of secure, understandable and reliable agentic AI systems.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 和 Vision-Language Models (VLMs) 驱动的智能体系统在 LangChain 和 GraphChain 等工作流中面临的多模态提示注入攻击 (prompt injection, PI) 风险，提出了一种 Cross-Agent Multimodal Provenance-Aware Defense Framework。该框架通过集成 Text sanitizer agent、visual sanitizer agent 和 output validator agent，对所有输入提示进行清理并在输出发送至下游节点前进行独立验证。其核心在于利用 provenance ledger 记录模态、来源和信任级别等元数据，确保智能体间的通信符合预定义的信任框架，防止恶意指令在网络中传播。实验评估证明，该方法显著提高了多模态注入检测的准确性，并有效减少了跨智能体的信任泄露。该框架通过将溯源追踪和验证扩展到多智能体编排中，为构建安全、可解释且可靠的 Agentic AI 系统奠定了基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "It is accepted in a conference paper, ICCA 2025 in Bahrain on 21 to 23 December",
      "pdf_url": "https://arxiv.org/pdf/2512.23557v1",
      "published_date": "2025-12-29 15:54:33 UTC",
      "updated_date": "2025-12-29 15:54:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:12.508008+00:00"
    },
    {
      "arxiv_id": "2512.23547v1",
      "title": "Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs",
      "title_zh": "对我说谎：基于知识图谱的大语言模型鲁棒幻觉自检测",
      "authors": [
        "Sahil Kale",
        "Antonio Luca Alfeo"
      ],
      "abstract": "Hallucinations, the generation of apparently convincing yet false statements, remain a major barrier to the safe deployment of LLMs. Building on the strong performance of self-detection methods, we examine the use of structured knowledge representations, namely knowledge graphs, to improve hallucination self-detection. Specifically, we propose a simple yet powerful approach that enriches hallucination self-detection by (i) converting LLM responses into knowledge graphs of entities and relations, and (ii) using these graphs to estimate the likelihood that a response contains hallucinations. We evaluate the proposed approach using two widely used LLMs, GPT-4o and Gemini-2.5-Flash, across two hallucination detection datasets. To support more reliable future benchmarking, one of these datasets has been manually curated and enhanced and is released as a secondary outcome of this work. Compared to standard self-detection methods and SelfCheckGPT, a state-of-the-art approach, our method achieves up to 16% relative improvement in accuracy and 20% in F1-score. Our results show that LLMs can better analyse atomic facts when they are structured as knowledge graphs, even when initial outputs contain inaccuracies. This low-cost, model-agnostic approach paves the way toward safer and more trustworthy language models.",
      "tldr_zh": "该研究针对大语言模型（LLMs）中普遍存在的幻觉（Hallucinations）问题，提出了一种利用结构化知识表示即知识图谱（Knowledge Graphs）来增强模型自检测能力的创新方法。该方法通过将LLM生成的响应转化为由实体和关系构成的知识图谱，并以此评估响应中包含幻觉的可能性。研究人员在GPT-4o和Gemini-2.5-Flash模型以及两个幻觉检测数据集上进行了广泛评估，其中一个数据集经过人工精细校对并作为研究成果发布。实验结果表明，该方法相比于传统的自检测手段及SelfCheckGPT等先进方法，在准确率上实现了16%的相对提升，F1-score提升了20%。研究证明，即便初始输出包含不准确信息，将原子事实（atomic facts）结构化为知识图谱也能帮助LLMs更有效地进行事实分析。这种低成本且模型无关（model-agnostic）的方法为构建更安全、更可信的语言模型提供了有效路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICPRAM 2026 in Marbella, Spain",
      "pdf_url": "https://arxiv.org/pdf/2512.23547v1",
      "published_date": "2025-12-29 15:41:13 UTC",
      "updated_date": "2025-12-29 15:41:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:20.170107+00:00"
    },
    {
      "arxiv_id": "2512.23545v1",
      "title": "PathFound: An Agentic Multimodal Model Activating Evidence-seeking Pathological Diagnosis",
      "title_zh": "PathFound：一种驱动主动取证式病理诊断的智能体多模态模型",
      "authors": [
        "Shengyi Hua",
        "Jianfeng Wu",
        "Tianle Shen",
        "Kangzhe Hu",
        "Zhongzhen Huang",
        "Shujuan Ni",
        "Zhihong Zhang",
        "Yuan Li",
        "Zhe Wang",
        "Xiaofan Zhang"
      ],
      "abstract": "Recent pathological foundation models have substantially advanced visual representation learning and multimodal interaction. However, most models still rely on a static inference paradigm in which whole-slide images are processed once to produce predictions, without reassessment or targeted evidence acquisition under ambiguous diagnoses. This contrasts with clinical diagnostic workflows that refine hypotheses through repeated slide observations and further examination requests. We propose PathFound, an agentic multimodal model designed to support evidence-seeking inference in pathological diagnosis. PathFound integrates the power of pathological visual foundation models, vision-language models, and reasoning models trained with reinforcement learning to perform proactive information acquisition and diagnosis refinement by progressing through the initial diagnosis, evidence-seeking, and final decision stages. Across several large multimodal models, adopting this strategy consistently improves diagnostic accuracy, indicating the effectiveness of evidence-seeking workflows in computational pathology. Among these models, PathFound achieves state-of-the-art diagnostic performance across diverse clinical scenarios and demonstrates strong potential to discover subtle details, such as nuclear features and local invasions.",
      "tldr_zh": "该研究提出了 PathFound，这是一种智能体多模态模型 (agentic multimodal model)，旨在模拟临床诊断中通过反复观察和证据获取来完善假设的流程，从而解决现有病理基础模型静态推理范式在模糊诊断下缺乏重新评估的问题。PathFound 整合了病理视觉基础模型、视觉语言模型 (VLMs) 以及通过强化学习 (reinforcement learning) 训练的推理模型，能够实现主动的信息获取。该框架通过初始诊断、证据寻求 (evidence-seeking) 和最终决策三个阶段，实现了诊断结果的持续精炼。实验结果表明，在多种多模态模型中采用这种策略均能一致地提升诊断准确率。目前，PathFound 在多种临床场景中均取得了 SOTA 性能，并展现出发现细胞核特征 (nuclear features) 和局部浸润 (local invasions) 等病理细微细节的强大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23545v1",
      "published_date": "2025-12-29 15:34:27 UTC",
      "updated_date": "2025-12-29 15:34:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:29.909367+00:00"
    },
    {
      "arxiv_id": "2512.23541v1",
      "title": "Act2Goal: From World Model To General Goal-conditioned Policy",
      "title_zh": "Act2Goal：从世界模型到通用目标条件策略",
      "authors": [
        "Pengfei Zhou",
        "Liliang Chen",
        "Shengcong Chen",
        "Di Chen",
        "Wenzhi Zhao",
        "Rongjun Jin",
        "Guanghui Ren",
        "Jianlan Luo"
      ],
      "abstract": "Specifying robotic manipulation tasks in a manner that is both expressive and precise remains a central challenge. While visual goals provide a compact and unambiguous task specification, existing goal-conditioned policies often struggle with long-horizon manipulation due to their reliance on single-step action prediction without explicit modeling of task progress. We propose Act2Goal, a general goal-conditioned manipulation policy that integrates a goal-conditioned visual world model with multi-scale temporal control. Given a current observation and a target visual goal, the world model generates a plausible sequence of intermediate visual states that captures long-horizon structure. To translate this visual plan into robust execution, we introduce Multi-Scale Temporal Hashing (MSTH), which decomposes the imagined trajectory into dense proximal frames for fine-grained closed-loop control and sparse distal frames that anchor global task consistency. The policy couples these representations with motor control through end-to-end cross-attention, enabling coherent long-horizon behavior while remaining reactive to local disturbances. Act2Goal achieves strong zero-shot generalization to novel objects, spatial layouts, and environments. We further enable reward-free online adaptation through hindsight goal relabeling with LoRA-based finetuning, allowing rapid autonomous improvement without external supervision. Real-robot experiments demonstrate that Act2Goal improves success rates from 30% to 90% on challenging out-of-distribution tasks within minutes of autonomous interaction, validating that goal-conditioned world models with multi-scale temporal control provide structured guidance necessary for robust long-horizon manipulation. Project page: https://act2goal.github.io/",
      "tldr_zh": "该研究提出了Act2Goal，一种通用的目标条件(goal-conditioned)机器人操作策略，旨在解决现有策略在长程操作(long-horizon manipulation)任务中因缺乏任务进度显式建模而难以执行的问题。Act2Goal整合了一个目标条件视觉世界模型(visual world model)，能够根据当前观察和视觉目标生成捕获长程结构的中间视觉状态序列。为了将视觉规划转化为鲁棒执行，研究引入了多尺度时间哈希(Multi-Scale Temporal Hashing, MSTH)，通过密集近端帧实现细粒度闭环控制，并利用稀疏远端帧确保全局任务的一致性。该策略通过端到端交叉注意力(cross-attention)将这些视觉表征与电机控制耦合，使机器人在保持连贯长程行为的同时能灵活应对局部干扰。此外，研究还通过事后目标重标记(hindsight goal relabeling)和基于LoRA的微调实现了无奖励在线自适应，允许机器人在没有外部监督的情况下自主优化。真实机器人实验表明，Act2Goal在分布外(out-of-distribution)任务中的成功率从30%显著提升至90%，证明了视觉世界模型结合多尺度时间控制在处理复杂机器人任务中的卓越泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23541v1",
      "published_date": "2025-12-29 15:28:42 UTC",
      "updated_date": "2025-12-29 15:28:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:29:42.449965+00:00"
    },
    {
      "arxiv_id": "2512.23537v2",
      "title": "AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization",
      "title_zh": "AnyMS：面向布局引导与免训练多主体定制的自底向上注意力解耦",
      "authors": [
        "Binhe Yu",
        "Zhen Wang",
        "Kexin Li",
        "Yuqian Yuan",
        "Wenqiao Zhang",
        "Long Chen",
        "Juncheng Li",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Multi-subject customization aims to synthesize multiple user-specified subjects into a coherent image. To address issues such as subjects missing or conflicts, recent works incorporate layout guidance to provide explicit spatial constraints. However, existing methods still struggle to balance three critical objectives: text alignment, subject identity preservation, and layout control, while the reliance on additional training further limits their scalability and efficiency. In this paper, we present AnyMS, a novel training-free framework for layout-guided multi-subject customization. AnyMS leverages three input conditions: text prompt, subject images, and layout constraints, and introduces a bottom-up dual-level attention decoupling mechanism to harmonize their integration during generation. Specifically, global decoupling separates cross-attention between textual and visual conditions to ensure text alignment. Local decoupling confines each subject's attention to its designated area, which prevents subject conflicts and thus guarantees identity preservation and layout control. Moreover, AnyMS employs pre-trained image adapters to extract subject-specific features aligned with the diffusion model, removing the need for subject learning or adapter tuning. Extensive experiments demonstrate that AnyMS achieves state-of-the-art performance, supporting complex compositions and scaling to a larger number of subjects.",
      "tldr_zh": "该研究提出了 AnyMS，一种无需训练 (Training-free) 的布局引导多主体定制化框架，旨在解决图像合成中主体缺失、冲突以及文本对齐、身份保持 (Identity preservation) 与布局控制难以兼顾的问题。该框架引入了自底向上的双层注意力解耦机制 (Bottom-up dual-level attention decoupling)，通过全局解耦分离文本与视觉条件的交叉注意力以确保文本一致性。同时，局部解耦将各主体的注意力限制在预设区域内，有效防止了主体间的属性干扰并保证了精准的布局控制。AnyMS 结合预训练的图像适配器 (Image adapters) 提取主体特征，从而消除了对主体学习或适配器微调的需求。大量实验证明，AnyMS 在处理复杂构图和多主体扩展方面表现出色，达到了当前的 SOTA 性能水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23537v2",
      "published_date": "2025-12-29 15:26:25 UTC",
      "updated_date": "2026-01-02 06:21:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:10.141317+00:00"
    },
    {
      "arxiv_id": "2601.06075v1",
      "title": "Jamming Detection in Cell-Free MIMO with Dynamic Graphs",
      "title_zh": "基于动态图的无小区 MIMO 干扰检测",
      "authors": [
        "Ali Hossary",
        "Laura Crosara",
        "Stefano Tomasin"
      ],
      "abstract": "Jamming attacks pose a critical threat to wireless networks, particularly in cell-free massive MIMO systems, where distributed access points and user equipment (UE) create complex, time-varying topologies. This paper proposes a novel jamming detection framework leveraging dynamic graphs and graph convolutional neural networks (GCN) to address this challenge. By modeling the network as a dynamic graph, we capture evolving communication links and detect jamming attacks as anomalies in the graph evolution. A GCN-Transformer-based model, trained with supervised learning, learns graph embeddings to identify malicious interference. Performance evaluation in simulated scenarios with moving UEs, varying jamming conditions and channel fadings, demonstrates the method's effectiveness, which is assessed through accuracy and F1 score metrics, achieving promising results for effective jamming detection.",
      "tldr_zh": "该研究针对 Cell-Free Massive MIMO 系统中由分布式接入点和用户设备（UE）形成的复杂时变拓扑，提出了一种利用 Dynamic Graphs 和 Graph Convolutional Neural Networks (GCN) 的新型干扰检测框架。该框架通过将网络建模为 Dynamic Graphs 来捕捉不断演进的通信链路，并将干扰攻击视为图演化过程中的异常。研究采用基于 GCN-Transformer 的模型，通过监督学习获取 Graph Embeddings，从而有效识别恶意干扰。在包含移动 UE、多变干扰条件和信道衰落的仿真场景中，实验结果验证了该方法的有效性，在 Accuracy 和 F1 score 指标上均取得了理想的检测结果。",
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.06075v1",
      "published_date": "2025-12-29 15:06:14 UTC",
      "updated_date": "2025-12-29 15:06:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:15.612945+00:00"
    },
    {
      "arxiv_id": "2601.11572v1",
      "title": "Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces",
      "title_zh": "LLM 嵌入空间中的离散语义状态与哈密顿动力学",
      "authors": [
        "Timo Aukusti Laine"
      ],
      "abstract": "We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.",
      "tldr_zh": "该研究利用线性代数(linear algebra)和哈密顿力学(Hamiltonian formalism)等数学工具，深入探讨了大语言模型(LLM)嵌入空间(embedding spaces)的结构特征。研究基于对嵌入向量呈现出的离散语义状态(discrete semantic states)的观察，借鉴量子力学(quantum mechanical systems)的类比来分析复杂的语义关系。作者证明了模型架构中普遍存在的L2正则化(L2 normalization)约束，使得嵌入空间具备了适用于哈密顿力学分析的结构化基础。通过该框架，研究推导了余弦相似度(cosine similarity)与嵌入向量扰动(perturbations)之间的数学关系，并深入探讨了直接和间接的语义转换(semantic transitions)。此外，研究还提出了一种受量子力学启发的视角，推导了零点能(zero-point energy)的类似物，并讨论了其与Koopman-von Neumann力学的潜在联系。这种方法为深入理解LLM的内在工作机制提供了独特途径，并展现出在缓解模型幻觉(hallucinations)方面的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.11572v1",
      "published_date": "2025-12-29 15:01:43 UTC",
      "updated_date": "2025-12-29 15:01:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:47.503887+00:00"
    },
    {
      "arxiv_id": "2512.23515v1",
      "title": "Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning",
      "title_zh": "Alpha-R1：基于强化学习与大语言模型推理的 Alpha 因子筛选",
      "authors": [
        "Zuoyou Jiang",
        "Li Zhao",
        "Rui Sun",
        "Ruohan Sun",
        "Zhongjian Li",
        "Jing Li",
        "Daxin Jiang",
        "Zuo Bai",
        "Cheng Hua"
      ],
      "abstract": "Signal decay and regime shifts pose recurring challenges for data-driven investment strategies in non-stationary markets. Conventional time-series and machine learning approaches, which rely primarily on historical correlations, often struggle to generalize when the economic environment changes. While large language models (LLMs) offer strong capabilities for processing unstructured information, their potential to support quantitative factor screening through explicit economic reasoning remains underexplored. Existing factor-based methods typically reduce alphas to numerical time series, overlooking the semantic rationale that determines when a factor is economically relevant. We propose Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. Alpha-R1 reasons over factor logic and real-time news to evaluate alpha relevance under changing market conditions, selectively activating or deactivating factors based on contextual consistency. Empirical results across multiple asset pools show that Alpha-R1 consistently outperforms benchmark strategies and exhibits improved robustness to alpha decay. The full implementation and resources are available at https://github.com/FinStep-AI/Alpha-R1.",
      "tldr_zh": "该研究提出了Alpha-R1，一种通过强化学习(Reinforcement Learning)训练的8B参数推理模型，旨在解决非平稳市场中信号衰减(Signal decay)和状态切换(Regime shifts)给传统投资策略带来的泛化挑战。Alpha-R1能够结合因子逻辑和实时新闻进行上下文感知(Context-aware)的因子筛选(Alpha screening)，在动态变化的市场环境下评估因子的经济相关性。通过根据上下文一致性选择性地激活或停用因子，该模型克服了传统方法仅依赖数值时间序列而忽视语义逻辑的局限。在多个资产池的实证结果表明，Alpha-R1的表现一致优于基准策略，且对因子衰减展现出更强的鲁棒性。该研究证明了利用大语言模型(LLMs)进行显式经济推理在量化因子管理中的有效性与潜力。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-fin.TR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23515v1",
      "published_date": "2025-12-29 14:50:23 UTC",
      "updated_date": "2025-12-29 14:50:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:22.941091+00:00"
    },
    {
      "arxiv_id": "2512.23512v2",
      "title": "UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?",
      "title_zh": "UniHetero：生成能否在大规模数据尺度下增强视觉语言模型的理解能力？",
      "authors": [
        "Fengjiao Chen",
        "Minhao Jing",
        "Weitao Lu",
        "Yan Feng",
        "Xiaoyu Li",
        "Xuezhi Cao"
      ],
      "abstract": "Vision-language large models are moving toward the unification of visual understanding and visual generation tasks. However, whether generation can enhance understanding is still under-explored on large data scale. In this work, we analysis the unified structure with a concise model, UniHetero, under large-scale pretraining (>200M samples). Our key observations are: (1) Generation can improve understanding, but Only if you generate Semantics, Not Pixels. A common assumption in unified vision-language models is that adding generation will naturally strengthen understanding. However, this is not always true at scale. At 200M+ pretraining samples, generation helps understanding only when it operates at the semantic level, i.e. when the model learns to autoregress high-level visual representations inside the LLM. Once pixel-level objectives (e.g., diffusion losses) directly interfere with the LLM, understanding performance often degrades. (2) Generation reveals a superior Data Scaling trend and higher Data Utilization. Unified generation-understanding demonstrates a superior scaling trend compared to understanding alone, revealing a more effective way to learn vision-only knowledge directive from vision modality rather than captioning to text. (3) Autoregression on Input Embedding is effective to capture visual details. Compared to the commonly-used vision encoder, make visual autoregression on input embedding shows less cumulative error and is modality independent, which can be extend to all modalities. The learned semantic representations capture visual information such as objects, locations, shapes, and colors; further enable pixel-level image generation.",
      "tldr_zh": "该研究提出了UniHetero模型，在超过2亿样本的大规模预训练环境下，探讨了视觉语言模型(Vision-Language Models)中生成任务对理解任务的增强作用。研究指出，生成任务仅在语义层面运作，即在LLM内部自回归高层视觉表示时，才能有效提升理解性能，而引入像素级目标(Pixel-level objectives)则可能导致理解性能下降。实验结果显示，统一的生成与理解框架展现出比单纯理解模型更优越的数据缩放(Data Scaling)趋势和更高的数据利用率。此外，在输入嵌入(Input Embedding)上进行视觉自回归被证明能更精准地捕捉物体、位置和形状等视觉细节，且具有模态无关的潜力。这种方法不仅减少了累积误差，还通过学习到的语义表示成功支持了像素级的图像生成任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23512v2",
      "published_date": "2025-12-29 14:49:50 UTC",
      "updated_date": "2025-12-30 13:23:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:38.138896+00:00"
    },
    {
      "arxiv_id": "2512.23508v1",
      "title": "Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities",
      "title_zh": "人工智能安全为何需要不确定性、不完备偏好与非阿基米德效用",
      "authors": [
        "Alessio Benavoli",
        "Alessandro Facchini",
        "Marco Zaffalon"
      ],
      "abstract": "How can we ensure that AI systems are aligned with human values and remain safe? We can study this problem through the frameworks of the AI assistance and the AI shutdown games. The AI assistance problem concerns designing an AI agent that helps a human to maximise their utility function(s). However, only the human knows these function(s); the AI assistant must learn them. The shutdown problem instead concerns designing AI agents that: shut down when a shutdown button is pressed; neither try to prevent nor cause the pressing of the shutdown button; and otherwise accomplish their task competently. In this paper, we show that addressing these challenges requires AI agents that can reason under uncertainty and handle both incomplete and non-Archimedean preferences.",
      "tldr_zh": "该研究探讨了如何确保人工智能系统的安全性以及与人类价值观的对齐(AI alignment)，并重点通过AI assistance和AI shutdown博弈框架进行了深入分析。AI assistance问题旨在设计能够学习并最大化人类效用函数(utility functions)的智能体，而shutdown问题则关注如何使智能体在按下关机按钮时能可靠执行且不产生干预行为。文章通过理论分析证明，要解决这些对齐挑战，AI智能体必须具备在不确定性(uncertainty)下进行推理的能力。此外，智能体还需能够同时处理不完备偏好(incomplete preferences)以及非阿基米德效用(non-Archimedean utilities)。该研究强调了传统效用理论在安全关键型任务中的局限性，并为构建更具鲁棒性的安全AI系统提供了必要的理论支撑。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23508v1",
      "published_date": "2025-12-29 14:47:05 UTC",
      "updated_date": "2025-12-29 14:47:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:23.841723+00:00"
    },
    {
      "arxiv_id": "2512.23493v1",
      "title": "Joint Link Adaptation and Device Scheduling Approach for URLLC Industrial IoT Network: A DRL-based Method with Bayesian Optimization",
      "title_zh": "面向URLLC工业物联网网络的联合链路自适应与设备调度方案：基于贝叶斯优化的深度强化学习方法",
      "authors": [
        "Wei Gao",
        "Paul Zheng",
        "Peng Wu",
        "Yulin Hu",
        "Anke Schmeink"
      ],
      "abstract": "In this article, we consider an industrial internet of things (IIoT) network supporting multi-device dynamic ultra-reliable low-latency communication (URLLC) while the channel state information (CSI) is imperfect. A joint link adaptation (LA) and device scheduling (including the order) design is provided, aiming at maximizing the total transmission rate under strict block error rate (BLER) constraints. In particular, a Bayesian optimization (BO) driven Twin Delayed Deep Deterministic Policy Gradient (TD3) method is proposed, which determines the device served order sequence and the corresponding modulation and coding scheme (MCS) adaptively based on the imperfect CSI. Note that the imperfection of CSI, error sample imbalance in URLLC networks, as well as the parameter sensitivity nature of the TD3 algorithm likely diminish the algorithm's convergence speed and reliability. To address such an issue, we proposed a BO based training mechanism for the convergence speed improvement, which provides a more reliable learning direction and sample selection method to track the imbalance sample problem. Via extensive simulations, we show that the proposed algorithm achieves faster convergence and higher sum-rate performance compared to existing solutions.",
      "tldr_zh": "该研究针对信道状态信息(CSI)不完善的工业物联网(IIoT)网络，提出了一种支持多设备动态超高可靠低时延通信(URLLC)的联合链路自适应(Link Adaptation)与设备调度方案。为了在严格的误块率(BLER)约束下最大化总传输速率，研究采用了一种由贝叶斯优化(BO)驱动的双延迟深度确定性策略梯度(TD3)方法，旨在自适应地确定设备服务顺序和相应的调制编码方案(MCS)。针对URLLC网络中样本不平衡及CSI不完美导致的算法收敛性与可靠性挑战，研究引入了基于BO的训练机制，为模型提供了更可靠的学习方向和样本选择策略。仿真结果表明，该算法在收敛速度和总速率性能方面均显著优于现有方案，有效增强了复杂工业环境下的通信质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 page,10 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23493v1",
      "published_date": "2025-12-29 14:32:34 UTC",
      "updated_date": "2025-12-29 14:32:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:46.972788+00:00"
    },
    {
      "arxiv_id": "2512.23489v2",
      "title": "The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction",
      "title_zh": "投资成功之路：面向风险投资预测的信息驱动大语言模型图推理",
      "authors": [
        "Haoyu Pei",
        "Zhongyang Liu",
        "Xiangyi Xiao",
        "Xiaocong Du",
        "Suting Hong",
        "Kunpeng Zhang",
        "Haipeng Zhang"
      ],
      "abstract": "Most venture capital (VC) investments fail, while a few deliver outsized returns. Accurately predicting startup success requires synthesizing complex relational evidence, including company disclosures, investor track records, and investment network structures, through explicit reasoning to form coherent, interpretable investment theses. Traditional machine learning and graph neural networks both lack this reasoning capability. Large language models (LLMs) offer strong reasoning but face a modality mismatch with graphs. Recent graph-LLM methods target in-graph tasks where answers lie within the graph, whereas VC prediction is off-graph: the target exists outside the network. The core challenge is selecting graph paths that maximize predictor performance on an external objective while enabling step-by-step reasoning. We present MIRAGE-VC, a multi-perspective retrieval-augmented generation framework that addresses two obstacles: path explosion (thousands of candidate paths overwhelm LLM context) and heterogeneous evidence fusion (different startups need different analytical emphasis). Our information-gain-driven path retriever iteratively selects high-value neighbors, distilling investment networks into compact chains for explicit reasoning. A multi-agent architecture integrates three evidence streams via a learnable gating mechanism based on company attributes. Under strict anti-leakage controls, MIRAGE-VC achieves +5.0% F1 and +16.6% PrecisionAt5, and sheds light on other off-graph prediction tasks such as recommendation and risk assessment. Code: https://anonymous.4open.science/r/MIRAGE-VC-323F.",
      "tldr_zh": "该研究提出了MIRAGE-VC，这是一个多视角检索增强生成(RAG)框架，旨在解决风险投资(Venture Capital)预测中由于传统机器学习和图神经网络(GNNs)缺乏显式推理能力以及大语言模型(LLMs)与图结构模态不匹配带来的挑战。针对VC预测这一“脱图”(off-graph)预测任务中的路径爆炸和异构证据融合难题，该框架引入了信息增益驱动的路径检索器(Information-gain-driven path retriever)，通过迭代选择高价值邻居将复杂的投资网络浓缩为紧凑的推理链。同时，MIRAGE-VC采用多智能体架构(Multi-agent architecture)，结合可学习的门控机制，有效整合了公司披露、投资者记录和网络结构等多维异构证据。实验结果显示，在严格的防泄漏控制下，MIRAGE-VC在F1分数上提升了5.0%，在PrecisionAt5上提升了16.6%，并为推荐系统和风险评估等其他脱图预测任务提供了新的研究范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23489v2",
      "published_date": "2025-12-29 14:20:31 UTC",
      "updated_date": "2026-01-03 15:00:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:38.739642+00:00"
    },
    {
      "arxiv_id": "2512.23487v1",
      "title": "ML Compass: Navigating Capability, Cost, and Compliance Trade-offs in AI Model Deployment",
      "title_zh": "ML Compass：权衡 AI 模型部署中的能力、成本与合规性",
      "authors": [
        "Vassilis Digalakis",
        "Ramayya Krishnan",
        "Gonzalo Martin Fernandez",
        "Agni Orfanoudaki"
      ],
      "abstract": "We study how organizations should select among competing AI models when user utility, deployment costs, and compliance requirements jointly matter. Widely used capability leaderboards do not translate directly into deployment decisions, creating a capability -- deployment gap; to bridge it, we take a systems-level view in which model choice is tied to application outcomes, operating constraints, and a capability-cost frontier. We develop ML Compass, a framework that treats model selection as constrained optimization over this frontier. On the theory side, we characterize optimal model configurations under a parametric frontier and show a three-regime structure in optimal internal measures: some dimensions are pinned at compliance minima, some saturate at maximum levels, and the remainder take interior values governed by frontier curvature. We derive comparative statics that quantify how budget changes, regulatory tightening, and technological progress propagate across capability dimensions and costs. On the implementation side, we propose a pipeline that (i) extracts low-dimensional internal measures from heterogeneous model descriptors, (ii) estimates an empirical frontier from capability and cost data, (iii) learns a user- or task-specific utility function from interaction outcome data, and (iv) uses these components to target capability-cost profiles and recommend models. We validate ML Compass with two case studies: a general-purpose conversational setting using the PRISM Alignment dataset and a healthcare setting using a custom dataset we build using HealthBench. In both environments, our framework produces recommendations -- and deployment-aware leaderboards based on predicted deployment value under constraints -- that can differ materially from capability-only rankings, and clarifies how trade-offs between capability, cost, and safety shape optimal model choice.",
      "tldr_zh": "该研究提出了 ML Compass 框架，旨在解决组织在选择 AI 模型时面临的性能 (Capability)、成本 (Cost) 和合规性 (Compliance) 之间的权衡难题。该框架从系统级视角出发，将模型选择视为一种在 Capability-cost frontier 上的约束优化问题，旨在弥合能力排行榜与实际部署决策之间的鸿沟。在理论上，研究者界定了最优模型配置的三种状态结构，并分析了预算变化、监管加强及技术进步对成本和能力维度的影响。在应用方面，ML Compass 包含一个能够提取度量指标、估计经验边界并学习特定任务效用函数的完整流水线。通过对通用对话场景和医疗场景的验证，该框架生成的 deployment-aware leaderboards 与传统排名显著不同，揭示了安全性与成本约束对最优模型选择的深层影响。该研究为企业在复杂约束下导航模型部署提供了系统性的理论指导和实践工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23487v1",
      "published_date": "2025-12-29 14:19:48 UTC",
      "updated_date": "2025-12-29 14:19:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:41.994526+00:00"
    },
    {
      "arxiv_id": "2512.23485v1",
      "title": "FRoD: Full-Rank Efficient Fine-Tuning with Rotational Degrees for Fast Convergence",
      "title_zh": "FRoD：基于旋转自由度的快速收敛全秩高效微调",
      "authors": [
        "Guoan Wan",
        "Tianyu Chen",
        "Fangzheng Feng",
        "Haoyi Zhou",
        "Runhua Xu"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) methods have emerged as a practical solution for adapting large foundation models to downstream tasks, reducing computational and memory costs by updating only a small subset of parameters. Among them, approaches like LoRA aim to strike a balance between efficiency and expressiveness, but often suffer from slow convergence and limited adaptation capacity due to their inherent low-rank constraints. This trade-off hampers the ability of PEFT methods to capture complex patterns needed for diverse tasks. To address these challenges, we propose FRoD, a novel fine-tuning method that combines hierarchical joint decomposition with rotational degrees of freedom. By extracting a globally shared basis across layers and injecting sparse, learnable perturbations into scaling factors for flexible full-rank updates, FRoD enhances expressiveness and efficiency, leading to faster and more robust convergence. On 20 benchmarks spanning vision, reasoning, and language understanding, FRoD matches full model fine-tuning in accuracy, while using only 1.72% of trainable parameters under identical training budgets.",
      "tldr_zh": "该研究针对参数高效微调(PEFT)方法（如LoRA）因低秩约束(low-rank constraints)导致的收敛速度慢和自适应能力有限等问题，提出了名为FRoD的全秩高效微调方法。该方法创新性地结合了层级联合分解(hierarchical joint decomposition)与旋转自由度(rotational degrees of freedom)，通过在不同层级间提取全局共享基底，并向缩放因子注入稀疏的可学习扰动，实现了灵活的全秩更新。FRoD在显著增强模型表达能力的同时，有效提升了微调效率，实现了更快速且更稳健的收敛。实验在视觉、推理和语言理解等20项基准测试中展开，结果显示FRoD的准确率达到了全量模型微调(full model fine-tuning)的水平。此外，在相同训练预算下，FRoD仅需使用1.72%的可训练参数，成功克服了传统PEFT方法在捕获复杂模式方面的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 40th Annual AAAI Conference on Artificial Intelligence",
      "pdf_url": "https://arxiv.org/pdf/2512.23485v1",
      "published_date": "2025-12-29 14:13:45 UTC",
      "updated_date": "2025-12-29 14:13:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:30:59.339134+00:00"
    },
    {
      "arxiv_id": "2512.23482v2",
      "title": "Theory of Mind for Explainable Human-Robot Interaction",
      "title_zh": "面向可解释人机交互的心智理论",
      "authors": [
        "Marie S. Bauer",
        "Julia Gachot",
        "Matthias Kerzel",
        "Cornelius Weber",
        "Stefan Wermter"
      ],
      "abstract": "Within the context of human-robot interaction (HRI), Theory of Mind (ToM) is intended to serve as a user-friendly backend to the interface of robotic systems, enabling robots to infer and respond to human mental states. When integrated into robots, ToM allows them to adapt their internal models to users' behaviors, enhancing the interpretability and predictability of their actions. Similarly, Explainable Artificial Intelligence (XAI) aims to make AI systems transparent and interpretable, allowing humans to understand and interact with them effectively. Since ToM in HRI serves related purposes, we propose to consider ToM as a form of XAI and evaluate it through the eValuation XAI (VXAI) framework and its seven desiderata. This paper identifies a critical gap in the application of ToM within HRI, as existing methods rarely assess the extent to which explanations correspond to the robot's actual internal reasoning. To address this limitation, we propose to integrate ToM within XAI frameworks. By embedding ToM principles inside XAI, we argue for a shift in perspective, as current XAI research focuses predominantly on the AI system itself and often lacks user-centered explanations. Incorporating ToM would enable a change in focus, prioritizing the user's informational needs and perspective.",
      "tldr_zh": "该研究探讨了在人机交互(Human-Robot Interaction, HRI)背景下将心理理论(Theory of Mind, ToM)作为可解释人工智能(Explainable Artificial Intelligence, XAI)的一种形式进行整合的必要性。通过将心理理论(ToM)集成到机器人系统中，能够使机器推断并响应人类心理状态，从而显著增强其行为的可解释性和可预测性。论文采用eValuation XAI (VXAI)框架及其七项核心指标对该方法进行评估，并指出现有HRI研究在评估解释内容与机器人实际内部推理一致性方面存在关键空白。为填补这一空白，作者建议将心理理论(ToM)原则嵌入到可解释人工智能(XAI)框架内，从而推动研究重心从单一的AI系统本身转向以用户为中心的解释逻辑。这种转变旨在优先满足用户的信息需求和视角，为构建更透明、更高效的人机协作环境提供了理论支撑。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23482v2",
      "published_date": "2025-12-29 14:09:05 UTC",
      "updated_date": "2025-12-31 12:36:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:21.160884+00:00"
    },
    {
      "arxiv_id": "2512.23480v1",
      "title": "Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation",
      "title_zh": "软件供应链安全自主防御中的智能体 AI：从来源追溯迈向漏洞缓解",
      "authors": [
        "Toqeer Ali Syed",
        "Mohammad Riyaz Belgaum",
        "Salman Jan",
        "Asadullah Abdullah Khan",
        "Saad Said Alqahtani"
      ],
      "abstract": "The software supply chain attacks are becoming more and more focused on trusted development and delivery procedures, so the conventional post-build integrity mechanisms cannot be used anymore. The available frameworks like SLSA, SBOM and in toto are majorly used to offer provenance and traceability but do not have the capabilities of actively identifying and removing vulnerabilities in software production. The current paper includes an example of agentic artificial intelligence (AI) based on autonomous software supply chain security that combines large language model (LLM)-based reasoning, reinforcement learning (RL), and multi-agent coordination. The suggested system utilizes specialized security agents coordinated with the help of LangChain and LangGraph, communicates with actual CI/CD environments with the Model Context Protocol (MCP), and documents all the observations and actions in a blockchain security ledger to ensure integrity and auditing. Reinforcement learning can be used to achieve adaptive mitigation strategies that consider the balance between security effectiveness and the operational overhead, and LLMs can be used to achieve semantic vulnerability analysis, as well as explainable decisions. This framework is tested based on simulated pipelines, as well as, actual world CI/CD integrations on GitHub Actions and Jenkins, including injection attacks, insecure deserialization, access control violations, and configuration errors. Experimental outcomes indicate better detection accuracy, shorter mitigation latency and reasonable build-time overhead than rule-based, provenance only and RL only baselines. These results show that agentic AI can facilitate the transition to self defending, proactive software supply chains rather than reactive verification ones.",
      "tldr_zh": "该研究针对传统软件供应链安全机制（如 SLSA、SBOM 和 in-toto）在主动识别与修复漏洞方面的局限性，提出了一种基于 Agentic AI 的自主防御框架。该框架整合了基于 Large Language Model (LLM) 的推理能力、Reinforcement Learning (RL) 的自适应策略以及多智能体协作技术，利用 LangChain 和 LangGraph 协调专用安全智能体，并通过 Model Context Protocol (MCP) 与真实的 CI/CD 环境进行交互。为了确保操作的透明度与不可篡改性，系统引入了 Blockchain 安全账本记录所有防御行为，并结合 RL 在安全有效性与运行开销之间取得平衡。实验结果表明，该系统在 GitHub Actions 和 Jenkins 等真实流水线中对注入攻击、反序列化漏洞及配置错误表现出更高的检测准确率和更低的防御延迟。该研究成果证明了 Agentic AI 能够推动软件供应链安全从被动的溯源验证向主动的、具备自防御能力的体系转型。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Conference paper, accept in ACCA IEEE Bahrain",
      "pdf_url": "https://arxiv.org/pdf/2512.23480v1",
      "published_date": "2025-12-29 14:06:09 UTC",
      "updated_date": "2025-12-29 14:06:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:18.331344+00:00"
    },
    {
      "arxiv_id": "2512.23471v1",
      "title": "Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings",
      "title_zh": "结合嵌套密度方法与大语言模型嵌入的文本语料库语义树推断",
      "authors": [
        "Thomas Haschka",
        "Joseph Bakarji"
      ],
      "abstract": "Semantic text classification has undergone significant advances in recent years due to the rise of large language models (LLMs) and their high dimensional embeddings. While LLM-embeddings are frequently used to store and retrieve text by semantic similarity in vector databases, the global structure semantic relationships in text corpora often remains opaque. Herein we propose a nested density clustering approach, to infer hierarchical trees of semantically related texts. The method starts by identifying texts of strong semantic similarity as it searches for dense clusters in LLM embedding space. As the density criterion is gradually relaxed, these dense clusters merge into more diffuse clusters, until the whole dataset is represented by a single cluster -- the root of the tree. By embedding dense clusters into increasingly diffuse ones, we construct a tree structure that captures hierarchical semantic relationships among texts. We outline how this approach can be used to classify textual data for abstracts of scientific abstracts as a case study. This enables the data-driven discovery research areas and their subfields without predefined categories. To evaluate the general applicability of the method, we further apply it to established benchmark datasets such as the 20 Newsgroups and IMDB 50k Movie Reviews, demonstrating its robustness across domains. Finally we discuss possible applications on scientometrics, topic evolution, highlighting how nested density trees can reveal semantic structure and evolution in textual datasets.",
      "tldr_zh": "该研究提出了一种基于嵌套密度聚类(Nested Density Clustering)的方法，利用大型语言模型嵌入(LLM Embeddings)从文本语料库中推理层次语义树，旨在解决语料库全局语义结构不透明的问题。该方法通过在 LLM embedding 空间中搜索高密度簇，并逐渐放宽密度准则以使簇合并，从而构建出一个捕捉文本间多层次语义关系的树状结构。通过对科学论文摘要的案例研究，该方法实现了无需预定义类别的研究领域及其子领域的自动化发现。研究进一步在 20 Newsgroups 和 IMDB 50k Movie Reviews 等基准数据集上进行了验证，证明了其跨领域的鲁棒性。最后，作者讨论了该技术在科学计量学(Scientometrics)和主题演变(Topic Evolution)中的应用前景，强调了嵌套密度树在揭示文本数据集语义结构与演化方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23471v1",
      "published_date": "2025-12-29 13:55:23 UTC",
      "updated_date": "2025-12-29 13:55:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:26.881701+00:00"
    },
    {
      "arxiv_id": "2512.23464v1",
      "title": "HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation",
      "title_zh": "HY-Motion 1.0：面向文本到动作生成的规模化流匹配模型",
      "authors": [
        "Yuxin Wen",
        "Qing Shuai",
        "Di Kang",
        "Jing Li",
        "Cheng Wen",
        "Yue Qian",
        "Ningxin Jiao",
        "Changhai Chen",
        "Weijie Chen",
        "Yiran Wang",
        "Jinkun Guo",
        "Dongyue An",
        "Han Liu",
        "Yanyu Tong",
        "Chao Zhang",
        "Qing Guo",
        "Juan Chen",
        "Qiao Zhang",
        "Youyi Zhang",
        "Zihao Yao",
        "Cheng Zhang",
        "Hong Duan",
        "Xiaoping Wu",
        "Qi Chen",
        "Fei Cheng",
        "Liang Dong",
        "Peng He",
        "Hao Zhang",
        "Jiaxin Lin",
        "Chao Zhang",
        "Zhongyi Fan",
        "Yifan Li",
        "Zhichao Hu",
        "Yuhong Liu",
        "Linus",
        "Jie Jiang",
        "Xiaolong Li",
        "Linchao Bao"
      ],
      "abstract": "We present HY-Motion 1.0, a series of state-of-the-art, large-scale, motion generation models capable of generating 3D human motions from textual descriptions. HY-Motion 1.0 represents the first successful attempt to scale up Diffusion Transformer (DiT)-based flow matching models to the billion-parameter scale within the motion generation domain, delivering instruction-following capabilities that significantly outperform current open-source benchmarks. Uniquely, we introduce a comprehensive, full-stage training paradigm -- including large-scale pretraining on over 3,000 hours of motion data, high-quality fine-tuning on 400 hours of curated data, and reinforcement learning from both human feedback and reward models -- to ensure precise alignment with the text instruction and high motion quality. This framework is supported by our meticulous data processing pipeline, which performs rigorous motion cleaning and captioning. Consequently, our model achieves the most extensive coverage, spanning over 200 motion categories across 6 major classes. We release HY-Motion 1.0 to the open-source community to foster future research and accelerate the transition of 3D human motion generation models towards commercial maturity.",
      "tldr_zh": "该研究推出了HY-Motion 1.0系列模型，这是在人体动作生成领域首次成功将基于Diffusion Transformer (DiT)的Flow Matching模型扩展至十亿参数规模。该框架采用了全阶段训练范式，包括在超过3000小时动作数据上的大规模预训练，以及在400小时精选数据上的高质量微调。此外，研究团队还引入了来自人类反馈和奖励模型的强化学习(Reinforcement Learning)，以确保生成的动作与文本指令精确对齐。为了提升质量，项目通过严格的动作清理和自动标注(Captioning)建立了细致的数据处理流程。实验结果显示，HY-Motion 1.0在指令遵循能力上显著超越了现有的开源基准，并涵盖了跨越6个大类的200多种动作类别。该模型的开源不仅为学术研究提供了强有力的支持，还加速了3D人体动作生成技术向商业化成熟阶段的转变。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Github: see https://github.com/Tencent-Hunyuan/HY-Motion-1.0",
      "pdf_url": "https://arxiv.org/pdf/2512.23464v1",
      "published_date": "2025-12-29 13:46:24 UTC",
      "updated_date": "2025-12-29 13:46:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:44.244960+00:00"
    },
    {
      "arxiv_id": "2512.23779v2",
      "title": "Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark",
      "title_zh": "提示诱导过度生成作为拒绝服务：黑盒攻击侧基准",
      "authors": [
        "Manu",
        "Yi Guo",
        "Kanchana Thilakarathna",
        "Nirhoshan Sivaroopan",
        "Jo Plested",
        "Tim Lynar",
        "Jack Yang",
        "Wangli Yang"
      ],
      "abstract": "Large Language Models (LLMs) can be driven into over-generation, emitting thousands of tokens before producing an end-of-sequence (EOS) token. This degrades answer quality, inflates latency and cost, and can be weaponized as a denial-of-service (DoS) attack. Recent work has begun to study DoS-style prompt attacks, but typically focuses on a single attack algorithm or assumes white-box access, without an attack-side benchmark that compares prompt-based attackers in a black-box, query-only regime with a known tokenizer. We introduce such a benchmark and study two prompt-only attackers. The first is an Evolutionary Over-Generation Prompt Search (EOGen) that searches the token space for prefixes that suppress EOS and induce long continuations. The second is a goal-conditioned reinforcement learning attacker (RL-GOAL) that trains a network to generate prefixes conditioned on a target length. To characterize behavior, we introduce Over-Generation Factor (OGF): the ratio of produced tokens to a model's context window, along with stall and latency summaries. EOGen discovers short-prefix attacks that raise Phi-3 to OGF = 1.39 +/- 1.14 (Success@>=2: 25.2%); RL-GOAL nearly doubles severity to OGF = 2.70 +/- 1.43 (Success@>=2: 64.3%) and drives budget-hit non-termination in 46% of trials.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)因诱导而产生过度生成(over-generation)的问题，这种现象会显著增加推理延迟与成本，甚至被利用为拒绝服务(DoS)攻击。为了系统化研究这一威胁，作者提出了一个黑盒模式下的攻击端基准测试，并对比了两种仅依赖提示词的攻击策略。其中进化过度生成提示搜索(EOGen)通过在令牌空间中搜索前缀来抑制停止令牌(EOS)的产生，而目标条件强化学习攻击者(RL-GOAL)则通过训练网络生成特定目标长度的前缀。研究进一步引入了过度生成因子(OGF)来衡量攻击严重程度，即生成令牌数与模型上下文窗口的比率。实验结果显示，RL-GOAL在Phi-3模型上的表现尤为强悍，将OGF提升至2.70，并在46%的试验中导致了预算耗尽型的非终止运行。这一研究成果揭示了黑盒提示攻击在破坏LLM服务稳定性及消耗计算资源方面的巨大风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23779v2",
      "published_date": "2025-12-29 13:42:08 UTC",
      "updated_date": "2026-01-17 02:07:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:39.271152+00:00"
    },
    {
      "arxiv_id": "2512.23461v1",
      "title": "Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance",
      "title_zh": "基于信息论引导消除奖励模型中的归纳偏置",
      "authors": [
        "Zhuo Li",
        "Pengyu Cheng",
        "Zhechao Yu",
        "Feifei Tong",
        "Anningzhe Gao",
        "Tsung-Hui Chang",
        "Xiang Wan",
        "Erchao Zhao",
        "Xiaoxi Jiang",
        "Guanjun Jiang"
      ],
      "abstract": "Reward models (RMs) are essential in reinforcement learning from human feedback (RLHF) to align large language models (LLMs) with human values. However, RM training data is commonly recognized as low-quality, containing inductive biases that can easily lead to overfitting and reward hacking. For example, more detailed and comprehensive responses are usually human-preferred but with more words, leading response length to become one of the inevitable inductive biases. A limited number of prior RM debiasing approaches either target a single specific type of bias or model the problem with only simple linear correlations, \\textit{e.g.}, Pearson coefficients. To mitigate more complex and diverse inductive biases in reward modeling, we introduce a novel information-theoretic debiasing method called \\textbf{D}ebiasing via \\textbf{I}nformation optimization for \\textbf{R}M (DIR). Inspired by the information bottleneck (IB), we maximize the mutual information (MI) between RM scores and human preference pairs, while minimizing the MI between RM outputs and biased attributes of preference inputs. With theoretical justification from information theory, DIR can handle more sophisticated types of biases with non-linear correlations, broadly extending the real-world application scenarios for RM debiasing methods. In experiments, we verify the effectiveness of DIR with three types of inductive biases: \\textit{response length}, \\textit{sycophancy}, and \\textit{format}. We discover that DIR not only effectively mitigates target inductive biases but also enhances RLHF performance across diverse benchmarks, yielding better generalization abilities. The code and training recipes are available at https://github.com/Qwen-Applications/DIR.",
      "tldr_zh": "在强化学习人类反馈(RLHF)中，奖励模型(Reward Models)常因训练数据中的归纳偏置(Inductive Bias)（如回复长度、奉承性等）导致过拟合和奖励作弊(Reward Hacking)。针对现有方法仅能处理简单线性相关性或单一偏置的局限，该研究提出了DIR (Debiasing via Information optimization for RM)，一种基于信息论的通用去偏框架。受信息瓶颈(Information Bottleneck)启发，该方法通过最大化奖励分数与人类偏好对之间的互信息(Mutual Information)，同时最小化模型输出与输入中偏置属性之间的互信息，实现了对复杂非线性偏置的有效抑制。实验在回复长度(Response Length)、奉承性(Sycophancy)和格式(Format)三种典型偏置上验证了DIR的有效性。研究结果表明，DIR不仅能显著缓解目标偏置，还能在多种基准测试中提升RLHF的泛化性能和模型对齐效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23461v1",
      "published_date": "2025-12-29 13:39:41 UTC",
      "updated_date": "2025-12-29 13:39:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:31.766295+00:00"
    },
    {
      "arxiv_id": "2512.23457v1",
      "title": "Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following",
      "title_zh": "将失败重放为成功：面向指令遵循的高样本效率强化学习",
      "authors": [
        "Kongcheng Zhang",
        "Qi Yao",
        "Shunyu Liu",
        "Wenjian Zhang",
        "Min Cen",
        "Yang Zhou",
        "Wenkai Fang",
        "Yiru Zhao",
        "Baisheng Lai",
        "Mingli Song"
      ],
      "abstract": "Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (HiR), a novel sample-efficient RL framework for complex instruction following tasks, which employs a select-then-rewrite strategy to replay failed attempts as successes based on the constraints that have been satisfied in hindsight. We perform RL on these replayed samples as well as the original ones, theoretically framing the objective as dual-preference learning at both the instruction- and response-level to enable efficient optimization using only a binary reward signal. Extensive experiments demonstrate that the proposed HiR yields promising results across different instruction following tasks, while requiring less computational budget. Our code and dataset is available at https://github.com/sastpg/HIR.",
      "tldr_zh": "该研究提出了Hindsight instruction Replay (HiR)，这是一种针对复杂指令遵循任务的高效强化学习(Reinforcement Learning)框架。针对初始模型在复杂约束下难以生成高质量响应导致奖励稀疏的问题，HiR采用了“选择并改写”(select-then-rewrite)策略，将失败的尝试根据事后实际满足的约束重新标记为成功案例进行重播。在理论层面，该框架将优化目标构建为指令层级和响应层级的双重偏好学习(dual-preference learning)，使得模型仅利用二元奖励信号即可实现高效优化。大量实验证明，HiR在多种指令遵循任务中均取得了优异结果，且显著降低了所需的计算预算。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23457v1",
      "published_date": "2025-12-29 13:31:08 UTC",
      "updated_date": "2025-12-29 13:31:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:37.134763+00:00"
    },
    {
      "arxiv_id": "2512.23777v1",
      "title": "A Survey on Graph Neural Networks for Fraud Detection in Ride Hailing Platforms",
      "title_zh": "面向网约车平台欺诈检测的图神经网络综述",
      "authors": [
        "Kanishka Hewageegana",
        "Janani Harischandra",
        "Nipuna Senanayake",
        "Gihan Danansuriya",
        "Kavindu Hapuarachchi",
        "Pooja Illangarathne"
      ],
      "abstract": "This study investigates fraud detection in ride hailing platforms through Graph Neural Networks (GNNs),focusing on the effectiveness of various models. By analyzing prevalent fraudulent activities, the research highlights and compares the existing work related to fraud detection which can be useful when addressing fraudulent incidents within the online ride hailing platforms. Also, the paper highlights addressing class imbalance and fraudulent camouflage. It also outlines a structured overview of GNN architectures and methodologies applied to anomaly detection, identifying significant methodological progress and gaps. The paper calls for further exploration into real-world applicability and technical improvements to enhance fraud detection strategies in the rapidly evolving ride-hailing industry.",
      "tldr_zh": "该综述探讨了在线打车平台中利用图神经网络 (Graph Neural Networks, GNNs) 进行欺诈检测的现状，重点评估并对比了多种模型的有效性。研究深入分析了常见的欺诈行为，为解决打车平台中的安全隐患提供了系统性的参考。论文特别强调了在模型设计中应对类别不平衡 (class imbalance) 和欺诈伪装 (fraudulent camouflage) 等核心挑战的重要性。此外，该文提供了一个结构化的 GNN 架构与异常检测 (anomaly detection) 方法论概述，明确了当前的技术进展与研究空白。最后，作者呼吁针对现实世界的可应用性进行深度探索和技术改进，以提升快速演变的打车行业中的欺诈检测效能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures, 2 tables. Presented at the 2024 7th International Conference on Artificial Intelligence and Big Data (ICAIBD)",
      "pdf_url": "https://arxiv.org/pdf/2512.23777v1",
      "published_date": "2025-12-29 13:26:06 UTC",
      "updated_date": "2025-12-29 13:26:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:42.143439+00:00"
    },
    {
      "arxiv_id": "2512.23453v1",
      "title": "CoFi-Dec: Hallucination-Resistant Decoding via Coarse-to-Fine Generative Feedback in Large Vision-Language Models",
      "title_zh": "CoFi-Dec：大视觉语言模型中基于由粗到细生成式反馈的抗幻觉解码",
      "authors": [
        "Zongsheng Cao",
        "Yangfan He",
        "Anran Liu",
        "Jun Xie",
        "Feng Chen",
        "Zepeng Wang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have achieved impressive progress in multi-modal understanding and generation. However, they still tend to produce hallucinated content that is inconsistent with the visual input, which limits their reliability in real-world applications. We propose \\textbf{CoFi-Dec}, a training-free decoding framework that mitigates hallucinations by integrating generative self-feedback with coarse-to-fine visual conditioning. Inspired by the human visual process from global scene perception to detailed inspection, CoFi-Dec first generates two intermediate textual responses conditioned on coarse- and fine-grained views of the original image. These responses are then transformed into synthetic images using a text-to-image model, forming multi-level visual hypotheses that enrich grounding cues. To unify the predictions from these multiple visual conditions, we introduce a Wasserstein-based fusion mechanism that aligns their predictive distributions into a geometrically consistent decoding trajectory. This principled fusion reconciles high-level semantic consistency with fine-grained visual grounding, leading to more robust and faithful outputs. Extensive experiments on six hallucination-focused benchmarks show that CoFi-Dec substantially reduces both entity-level and semantic-level hallucinations, outperforming existing decoding strategies. The framework is model-agnostic, requires no additional training, and can be seamlessly applied to a wide range of LVLMs. The implementation is available at https://github.com/AI-Researcher-Team/CoFi-Dec.",
      "tldr_zh": "该研究提出了CoFi-Dec，一种无需训练的解码框架，旨在缓解Large Vision-Language Models (LVLMs)在生成过程中出现的幻觉问题。受人类从全局场景感知到细节检查的视觉过程启发，CoFi-Dec首先基于原图的粗粒度(coarse-grained)和细粒度(fine-grained)视图生成中间文本响应，并利用text-to-image模型将其转化为合成图像，形成多层级的视觉假设以增强辅助信息。为了统一多种视觉条件下的预测，研究引入了基于Wasserstein的融合机制，将预测分布对齐为几何一致的解码轨迹，从而平衡高层语义一致性与细粒度视觉对齐。在六个幻觉评估基准上的广泛实验表明，CoFi-Dec在实体级和语义级幻觉上均表现出显著的消减效果，且性能优于现有的解码策略。该框架具有模型无关性(model-agnostic)，无需额外训练即可无缝应用于多种主流LVLMs，为构建更可靠的多模态系统提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23453v1",
      "published_date": "2025-12-29 13:23:20 UTC",
      "updated_date": "2025-12-29 13:23:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:45.893754+00:00"
    },
    {
      "arxiv_id": "2512.23436v2",
      "title": "Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification",
      "title_zh": "融合模糊逻辑与深度学习的环境感知路面分类",
      "authors": [
        "Mustafa Demetgul",
        "Sanja Lazarova Molnar"
      ],
      "abstract": "Monitoring states of road surfaces provides valuable information for the planning and controlling vehicles and active vehicle control systems. Classical road monitoring methods are expensive and unsystematic because they require time for measurements. This article proposes an real time system based on weather conditional data and road surface condition data. For this purpose, we collected data with a mobile phone camera on the roads around the campus of the Karlsruhe Institute of Technology. We tested a large number of different image-based deep learning algorithms for road classification. In addition, we used road acceleration data along with road image data for training by using them as images. We compared the performances of acceleration-based and camera image-based approaches. The performances of the simple Alexnet, LeNet, VGG, and Resnet algorithms were compared as deep learning algorithms. For road condition classification, 5 classes were considered: asphalt, damaged asphalt, gravel road, damaged gravel road, pavement road and over 95% accuracy performance was achieved. It is also proposed to use the acceleration or the camera image to classify the road surface according to the weather and the time of day using fuzzy logic.",
      "tldr_zh": "该研究提出了一种结合模糊逻辑(Fuzzy-Logic)与深度学习(Deep Learning)的实时道路表面分类系统，旨在解决传统道路监控方法成本高且效率低的问题。研究团队利用智能手机摄像头收集了道路图像和加速度数据，并将加速度数据转换为图像形式用于深度学习模型的训练与对比。通过评估 Alexnet、LeNet、VGG 和 Resnet 等多种算法，该系统在沥青路、损坏沥青路、碎石路等五类路面的分类任务中达到了超过 95% 的准确率。此外，研究还利用模糊逻辑(Fuzzy-Logic)根据天气状况和时间段灵活调用加速度或图像数据进行分类。这一方法显著提升了道路表面识别在不同环境条件下的鲁棒性，为自动驾驶和车辆主动控制系统提供了重要的实时数据支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been withdrawn by the authors because the manuscript was submitted before all authors reached a final agreement on the content and readiness of the work. The paper should not be cited",
      "pdf_url": "https://arxiv.org/pdf/2512.23436v2",
      "published_date": "2025-12-29 12:54:48 UTC",
      "updated_date": "2026-01-12 16:25:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:31:50.701914+00:00"
    },
    {
      "arxiv_id": "2512.23435v2",
      "title": "Distilled HuBERT for Mobile Speech Emotion Recognition: A Cross-Corpus Validation Study",
      "title_zh": "面向移动端语音情感识别的蒸馏 HuBERT：跨语料库验证研究",
      "authors": [
        "Saifelden M. Ismail"
      ],
      "abstract": "Speech Emotion Recognition (SER) has significant potential for mobile applications, yet deployment remains constrained by the computational demands of state-of-the-art transformer architectures. This paper presents a mobile-efficient SER system based on DistilHuBERT, a distilled and 8-bit quantized transformer that achieves approximately 92% parameter reduction compared to full-scale Wav2Vec 2.0 models while maintaining competitive accuracy. We conduct a rigorous 5-fold Leave-One-Session-Out (LOSO) cross-validation on the IEMOCAP dataset to ensure speaker independence, augmented with cross-corpus training on CREMA-D to enhance generalization. Cross-corpus training with CREMA-D yields a 1.2% improvement in Weighted Accuracy, a 1.4% gain in Macro F1-score, and a 32% reduction in cross-fold variance, with the Neutral class showing the most substantial benefit at 5.4% F1-score improvement. Our approach achieves an Unweighted Accuracy of 61.4% with a quantized model footprint of only 23 MB, representing approximately 91% of the Unweighted Accuracy of a full-scale baseline. Cross-corpus evaluation on RAVDESS reveals that the theatrical nature of acted emotions causes predictions to cluster by arousal level rather than by specific emotion categories - happiness predictions systematically bleed into anger predictions, and sadness predictions bleed into neutral predictions, due to acoustic saturation when actors prioritize clarity over subtlety. Despite this theatricality effect reducing overall RAVDESS accuracy to 46.64%, the model maintains robust arousal detection with 99% recall for anger, 55% recall for neutral, and 27% recall for sadness. These findings demonstrate a Pareto-optimal tradeoff between model size and accuracy, enabling practical affect recognition on resource-constrained mobile devices.",
      "tldr_zh": "该研究针对移动端语音情感识别(Speech Emotion Recognition, SER)面临的计算资源限制，提出了一种基于DistilHuBERT的轻量级系统。该系统通过蒸馏(distilled)和8比特量化(8-bit quantized)技术，在保持竞争力的准确率的同时，相比于全量级Wav2Vec 2.0模型实现了约92%的参数缩减。研究人员在IEMOCAP数据集上进行了5折留一会话交叉验证(Leave-One-Session-Out, LOSO)，并结合CREMA-D数据集进行跨语料库(cross-corpus)训练以提升泛化能力。实验结果显示，跨语料库训练有效提升了模型性能并显著降低了跨折方差，量化后的模型体积仅为23 MB，达到了全量级基准模型约91%的非加权准确率(Unweighted Accuracy)。在RAVDESS数据集上的评估进一步揭示了戏剧化情感表达对预测的影响，发现预测结果倾向于按唤醒度(arousal)水平聚类而非具体情感类别。该研究证明了模型大小与准确率之间的帕累托最优(Pareto-optimal)权衡，为在资源受限的移动设备上实现实用的情绪识别提供了技术支持。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 2 tables, 1 figure. Not yet submitted to a conference",
      "pdf_url": "https://arxiv.org/pdf/2512.23435v2",
      "published_date": "2025-12-29 12:53:39 UTC",
      "updated_date": "2025-12-31 12:50:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:11.294622+00:00"
    },
    {
      "arxiv_id": "2512.23424v1",
      "title": "AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis",
      "title_zh": "AKG kernel Agent：一种面向跨平台内核合成的多智能体框架",
      "authors": [
        "Jinye Du",
        "Quan Yuan",
        "Zuyao Zhang",
        "Yanzhi Yi",
        "Jiahui Hu",
        "Wangyi Chen",
        "Yiyang Zhu",
        "Qishui Zheng",
        "Wenxiang Zou",
        "Xiangyu Chang",
        "Zuohe Zheng",
        "Zichun Ye",
        "Chao Liu",
        "Shanni Li",
        "Renwei Zhang",
        "Yiping Deng",
        "Xinwei Hu",
        "Xuefeng Jin",
        "Jie Zhao"
      ],
      "abstract": "Modern AI models demand high-performance computation kernels. The growing complexity of LLMs, multimodal architectures, and recommendation systems, combined with techniques like sparsity and quantization, creates significant computational challenges. Moreover, frequent hardware updates and diverse chip architectures further complicate this landscape, requiring tailored kernel implementations for each platform. However, manual optimization cannot keep pace with these demands, creating a critical bottleneck in AI system development. Recent advances in LLM code generation capabilities have opened new possibilities for automating kernel development. In this work, we propose AKG kernel agent (AI-driven Kernel Generator), a multi-agent system that automates kernel generation, migration, and performance tuning. AKG kernel agent is designed to support multiple domain-specific languages (DSLs), including Triton, TileLang, CPP, and CUDA-C, enabling it to target different hardware backends while maintaining correctness and portability. The system's modular design allows rapid integration of new DSLs and hardware targets. When evaluated on KernelBench using Triton DSL across GPU and NPU backends, AKG kernel agent achieves an average speedup of 1.46$\\times$ over PyTorch Eager baselines implementations, demonstrating its effectiveness in accelerating kernel development for modern AI workloads.",
      "tldr_zh": "该研究提出了 AKG kernel Agent (AI-driven Kernel Generator)，这是一个旨在自动化内核生成、迁移和性能调优的多智能体 (Multi-Agent) 框架。该系统针对现代 AI 模型日益增长的计算需求和多样化硬件架构带来的开发瓶颈，支持包括 Triton, TileLang, CPP 和 CUDA-C 在内的多种领域专用语言 (DSLs)。通过模块化设计，AKG kernel Agent 能够快速适配不同的硬件后端，在保证代码正确性的同时提升跨平台的可移植性。实验结果显示，在 KernelBench 评测中，该框架在 GPU 和 NPU 后端上的表现优于 PyTorch Eager 基准模型，实现了平均 1.46 倍的加速。该工作有效证明了利用大语言模型 (LLMs) 自动化开发高性能计算内核的潜力，为缓解 AI 系统开发中的性能瓶颈提供了创新方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23424v1",
      "published_date": "2025-12-29 12:42:05 UTC",
      "updated_date": "2025-12-29 12:42:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:07.409836+00:00"
    },
    {
      "arxiv_id": "2512.23419v1",
      "title": "The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis",
      "title_zh": "世界更广阔！大世界假设的计算嵌入视角",
      "authors": [
        "Alex Lewandowski",
        "Adtiya A. Ramesh",
        "Edan Meyer",
        "Dale Schuurmans",
        "Marlos C. Machado"
      ],
      "abstract": "Continual learning is often motivated by the idea, known as the big world hypothesis, that \"the world is bigger\" than the agent. Recent problem formulations capture this idea by explicitly constraining an agent relative to the environment. These constraints lead to solutions in which the agent continually adapts to best use its limited capacity, rather than converging to a fixed solution. However, explicit constraints can be ad hoc, difficult to incorporate, and may limit the effectiveness of scaling up the agent's capacity. In this paper, we characterize a problem setting in which an agent, regardless of its capacity, is constrained by being embedded in the environment. In particular, we introduce a computationally-embedded perspective that represents an embedded agent as an automaton simulated within a universal (formal) computer. Such an automaton is always constrained; we prove that it is equivalent to an agent that interacts with a partially observable Markov decision process over a countably infinite state-space. We propose an objective for this setting, which we call interactivity, that measures an agent's ability to continually adapt its behaviour by learning new predictions. We then develop a model-based reinforcement learning algorithm for interactivity-seeking, and use it to construct a synthetic problem to evaluate continual learning capability. Our results show that deep nonlinear networks struggle to sustain interactivity, whereas deep linear networks sustain higher interactivity as capacity increases.",
      "tldr_zh": "该研究从计算嵌入（computationally-embedded perspective）的角度对持续学习（Continual learning）中的“大世界假设”（big world hypothesis）进行了重新审视，提出了智能体始终受限于其嵌入环境的观点。研究者将这种嵌入式智能体建模为在通用计算机中运行的自动机，并证明其在数学上等价于在一个具有可数无限状态空间的部分可观测马尔可夫决策过程（POMDP）中进行交互。为了评估智能体持续适应和学习新预测的能力，论文引入了名为“交互性”（interactivity）的新目标函数。随后，研究开发了一种旨在寻求交互性的模型驱动强化学习（model-based reinforcement learning）算法，并构建了合成实验进行验证。实验结果表明，深层非线性网络在维持交互性方面面临挑战，而深层线性网络则展现出随容量增加而提升交互性的能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2025 (spotlight)",
      "pdf_url": "https://arxiv.org/pdf/2512.23419v1",
      "published_date": "2025-12-29 12:31:46 UTC",
      "updated_date": "2025-12-29 12:31:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:57.258235+00:00"
    },
    {
      "arxiv_id": "2512.23412v2",
      "title": "MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning",
      "title_zh": "MindWatcher：迈向更智能的多模态工具集成推理",
      "authors": [
        "Jiawei Chen",
        "Xintian Shen",
        "Lihao Zheng",
        "Zhenwei Shao",
        "Handong Cui",
        "Chaoqun Du",
        "Li Gong",
        "Feng Gu",
        "Xuefeng Hao",
        "Wei He",
        "Jiabang He",
        "Yi Hu",
        "Bin Huang",
        "Shanshan Li",
        "Qizhen Li",
        "Jing Luo",
        "Zide Liu",
        "Xiaobo Liu",
        "Ning Mao",
        "Lifu Mu",
        "Xuhao Pan",
        "Zhiheng Qu",
        "Chang Ren",
        "Xudong Rao",
        "Haoyi Sun",
        "Qian Wang",
        "Shuai Wang",
        "Zhichao Wang",
        "Wei Wang",
        "Lian Wen",
        "Jiqing Zhan",
        "Hongfu Yang",
        "Sheng Yang",
        "Jiajun Yang",
        "Pengfei Yu",
        "Hongyuan Zhang",
        "Bin Zhang",
        "Chunpeng Zhou",
        "Zheng Zhou",
        "Shucheng Zhou",
        "Shuo Xie",
        "Yun Zhu",
        "Hao Ma",
        "Tao Wei",
        "Pan Zhou",
        "Wei Chen"
      ],
      "abstract": "Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks involving multi-step interactions with external environments. In this work, we introduce MindWatcher, a TIR agent integrating interleaved thinking and multimodal chain-of-thought (CoT) reasoning. MindWatcher can autonomously decide whether and how to invoke diverse tools and coordinate their use, without relying on human prompts or workflows. The interleaved thinking paradigm enables the model to switch between thinking and tool calling at any intermediate stage, while its multimodal CoT capability allows manipulation of images during reasoning to yield more precise search results. We implement automated data auditing and evaluation pipelines, complemented by manually curated high-quality datasets for training, and we construct a benchmark, called MindWatcher-Evaluate Bench (MWE-Bench), to evaluate its performance. MindWatcher is equipped with a comprehensive suite of auxiliary reasoning tools, enabling it to address broad-domain multimodal problems. A large-scale, high-quality local image retrieval database, covering eight categories including cars, animals, and plants, endows model with robust object recognition despite its small size. Finally, we design a more efficient training infrastructure for MindWatcher, enhancing training speed and hardware utilization. Experiments not only demonstrate that MindWatcher matches or exceeds the performance of larger or more recent models through superior tool invocation, but also uncover critical insights for agent training, such as the genetic inheritance phenomenon in agentic RL.",
      "tldr_zh": "该研究提出了 MindWatcher，一种集成交织思考 (interleaved thinking) 与多模态链式思维 (multimodal CoT) 推理的工具集成推理 (TIR) 智能体。该智能体无需依赖人工预设工作流，即可自主决定工具的调用与协调，并利用多模态能力在推理过程中操作图像以显著提升搜索精度。研究团队同步构建了涵盖八类实体的本地图像检索数据库及评估基准 MindWatcher-Evaluate Bench (MWE-Bench)，并设计了高效的训练基础设施。实验证明 MindWatcher 的工具调用表现优于或匹配更大型的前沿模型，并揭示了智能体强化学习 (agentic RL) 中的遗传继承现象等关键训练洞察。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Technique Report",
      "pdf_url": "https://arxiv.org/pdf/2512.23412v2",
      "published_date": "2025-12-29 12:16:12 UTC",
      "updated_date": "2026-01-07 10:27:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:23.073368+00:00"
    },
    {
      "arxiv_id": "2512.23410v1",
      "title": "Directly Constructing Low-Dimensional Solution Subspaces in Deep Neural Networks",
      "title_zh": "深度神经网络中低维解子空间的直接构建",
      "authors": [
        "Yusuf Kalyoncuoglu"
      ],
      "abstract": "While it is well-established that the weight matrices and feature manifolds of deep neural networks exhibit a low Intrinsic Dimension (ID), current state-of-the-art models still rely on massive high-dimensional widths. This redundancy is not required for representation, but is strictly necessary to solve the non-convex optimization search problem-finding a global minimum, which remains intractable for compact networks. In this work, we propose a constructive approach to bypass this optimization bottleneck. By decoupling the solution geometry from the ambient search space, we empirically demonstrate across ResNet-50, ViT, and BERT that the classification head can be compressed by even huge factors of 16 with negligible performance degradation. This motivates Subspace-Native Distillation as a novel paradigm: by defining the target directly in this constructed subspace, we provide a stable geometric coordinate system for student models, potentially allowing them to circumvent the high-dimensional search problem entirely and realize the vision of Train Big, Deploy Small.",
      "tldr_zh": "该研究针对深度神经网络(Deep Neural Networks)中权重矩阵和特征流形表现出的低本征维度(Intrinsic Dimension, ID)特性，指出冗余的高维宽度主要是为了解决非凸优化搜索问题而非表示需求。为绕过这一优化瓶颈，作者提出了一种构造性方法，通过将解的几何结构与环境搜索空间解耦，在ResNet-50、ViT和BERT等模型上证明了分类头可以实现高达16倍的压缩且性能损失极小。基于此，研究进一步提出了子空间原生蒸馏(Subspace-Native Distillation)的新范式，通过在构建的子空间中直接定义目标，为学生模型提供稳定的几何坐标系。该方法有助于紧凑型模型完全避开高维搜索难题，为实现“大模型训练，小模型部署(Train Big, Deploy Small)”的愿景提供了切实可行的路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at https://github.com/yuskal/Directly-Constructing-Low-Dimensional-Solution-Subspaces-in-Deep-Neural-Networks",
      "pdf_url": "https://arxiv.org/pdf/2512.23410v1",
      "published_date": "2025-12-29 12:13:15 UTC",
      "updated_date": "2025-12-29 12:13:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:16.507337+00:00"
    },
    {
      "arxiv_id": "2512.23407v2",
      "title": "Theoretical Foundations of Scaling Law in Familial Models",
      "title_zh": "家族化模型缩放定律的理论基础",
      "authors": [
        "Huan Song",
        "Qingfei Zhao",
        "Ting Long",
        "Shuyu Tian",
        "Hongjun An",
        "Jiawei Shao",
        "Xuelong Li"
      ],
      "abstract": "Neural scaling laws have become foundational for optimizing large language model (LLM) training, yet they typically assume a single dense model output. This limitation effectively overlooks \"Familial models, a transformative paradigm essential for realizing ubiquitous intelligence across heterogeneous device-edge-cloud hierarchies. Transcending static architectures, familial models integrate early exits with relay-style inference to spawn G deployable sub-models from a single shared backbone. In this work, we theoretically and empirically extend the scaling law to capture this \"one-run, many-models\" paradigm by introducing Granularity (G) as a fundamental scaling variable alongside model size (N) and training tokens (D). To rigorously quantify this relationship, we propose a unified functional form L(N, D, G) and parameterize it using large-scale empirical runs. Specifically, we employ a rigorous IsoFLOP experimental design to strictly isolate architectural impact from computational scale. Across fixed budgets, we systematically sweep model sizes (N) and granularities (G) while dynamically adjusting tokens (D). This approach effectively decouples the marginal cost of granularity from the benefits of scale, ensuring high-fidelity parameterization of our unified scaling law. Our results reveal that the granularity penalty follows a multiplicative power law with an extremely small exponent. Theoretically, this bridges fixed-compute training with dynamic architectures. Practically, it validates the \"train once, deploy many\" paradigm, demonstrating that deployment flexibility is achievable without compromising the compute-optimality of dense baselines.",
      "tldr_zh": "该研究探讨了Familial models在Scaling Law中的理论基础，针对以往Scaling Law仅假设单一稠密模型输出的局限性，提出了适用于跨异构设备-边缘-云层次结构的“一次训练，多次部署”范式。研究者将粒度(Granularity, G)作为除模型规模(N)和训练数据量(D)之外的第三个基本缩放变量，并构建了统一的函数形式L(N, D, G)。通过严谨的IsoFLOP实验设计，研究系统地分析了固定计算预算下模型规模和粒度的相互作用，从而解耦了粒度的边际成本与规模收益。实验结果揭示，粒度惩罚(Granularity penalty)遵循一个指数极小的乘法幂律，证明了在不牺牲Dense基准模型计算最优性的前提下，可以获得极高的部署灵活性。该成果在理论上桥接了固定计算训练与动态架构，在实践中验证了Familial models在实现普适智能方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23407v2",
      "published_date": "2025-12-29 12:01:58 UTC",
      "updated_date": "2026-01-23 15:36:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:22.477146+00:00"
    },
    {
      "arxiv_id": "2512.23773v1",
      "title": "FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading",
      "title_zh": "FineFT：高效且风险感知的期货交易集成强化学习",
      "authors": [
        "Molei Qin",
        "Xinyu Cai",
        "Yewen Li",
        "Haochong Xia",
        "Chuqiao Zong",
        "Shuo Sun",
        "Xinrun Wang",
        "Bo An"
      ],
      "abstract": "Futures are contracts obligating the exchange of an asset at a predetermined date and price, notable for their high leverage and liquidity and, therefore, thrive in the Crypto market. RL has been widely applied in various quantitative tasks. However, most methods focus on the spot and could not be directly applied to the futures market with high leverage because of 2 challenges. First, high leverage amplifies reward fluctuations, making training stochastic and difficult to converge. Second, prior works lacked self-awareness of capability boundaries, exposing them to the risk of significant loss when encountering new market state (e.g.,a black swan event like COVID-19). To tackle these challenges, we propose the Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading (FineFT), a novel three-stage ensemble RL framework with stable training and proper risk management. In stage I, ensemble Q learners are selectively updated by ensemble TD errors to improve convergence. In stage II, we filter the Q-learners based on their profitabilities and train VAEs on market states to identify the capability boundaries of the learners. In stage III, we choose from the filtered ensemble and a conservative policy, guided by trained VAEs, to maintain profitability and mitigate risk with new market states. Through extensive experiments on crypto futures in a high-frequency trading environment with high fidelity and 5x leverage, we demonstrate that FineFT outperforms 12 SOTA baselines in 6 financial metrics, reducing risk by more than 40% while achieving superior profitability compared to the runner-up. Visualization of the selective update mechanism shows that different agents specialize in distinct market dynamics, and ablation studies certify routing with VAEs reduces maximum drawdown effectively, and selective update improves convergence and performance.",
      "tldr_zh": "该研究提出了一种名为 FineFT 的高效且具备风险意识的集成强化学习 (Ensemble Reinforcement Learning) 框架，旨在解决期货交易中由高杠杆引起的训练不稳定性及黑天鹅事件带来的风险管理难题。该框架采用三阶段设计，首先利用集成 TD 误差 (TD errors) 选择性地更新 Q 学习器 (Q-learners) 以确保训练收敛，随后通过变分自编码器 (VAEs) 学习市场状态并识别不同智能体的能力边界 (capability boundaries)。在决策阶段，FineFT 根据 VAEs 的引导在筛选出的集成模型与保守策略间进行动态路由，从而在新市场环境下维持盈利并对冲风险。实验结果表明，在 5 倍杠杆的加密货币期货高频交易环境中，FineFT 在 6 项关键指标上均优于 12 种 SOTA 基准模型，在保持卓越盈利能力的同时将风险降低了 40% 以上。此外，消融实验证实了该机制能有效降低最大回撤 (maximum drawdown)，为高杠杆金融场景下的智能交易提供了更具鲁棒性的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23773v1",
      "published_date": "2025-12-29 11:56:33 UTC",
      "updated_date": "2025-12-29 11:56:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:30.025811+00:00"
    },
    {
      "arxiv_id": "2512.23396v1",
      "title": "PINNs for Electromagnetic Wave Propagation",
      "title_zh": "用于电磁波传播的 PINNs",
      "authors": [
        "Nilufer K. Bulut"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) are a methodology that aims to solve physical systems by directly embedding PDE constraints into the neural network training process. In electromagnetism, where well-established methodologies such as FDTD and FEM already exist, new methodologies are expected to provide clear advantages to be accepted. Despite their mesh-free nature and applicability to inverse problems, PINNs can exhibit deficiencies in terms of accuracy and energy metrics when compared to FDTD solutions. This study demonstrates hybrid training strategies can bring PINNs closer to FDTD-level accuracy and energy consistency.\n  This study presents a hybrid methodology addressing common challenges in wave propagation scenarios. The causality collapse problem in time-dependent PINN training is addressed via time marching and causality-aware weighting. In order to mitigate the discontinuities that are introduced by time marching, a two-stage interface continuity loss is applied. In order to suppress loss accumulation, which is manifested as cumulative energy drift in electromagnetic waves, a local Poynting-based regularizer has been developed.\n  In the developed PINN model, high field accuracy is achieved with an average 0.09\\% $NRMSE$ and 1.01\\% $L^2$ error over time. Energy conservation is achieved on the PINN side with only a 0.024\\% relative energy mismatch in the 2D PEC cavity scenario. Training is performed without labeled field data, using only physics-based residual losses; FDTD is used solely for post-training evaluation. The results demonstrate that PINNs can achieve competitive results with FDTD in canonical electromagnetic examples and are a viable alternative.",
      "tldr_zh": "该研究探讨了物理信息神经网络 (PINNs) 在电磁波传播中的应用，旨在解决其在精度和能量一致性方面相较于 FDTD 的不足。为了应对时间依赖型 PINN 训练中的因果崩溃问题，研究引入了 time marching 和 causality-aware weighting 策略，并结合 two-stage interface continuity loss 来处理由于时间步进引入的不连续性。此外，研究开发了一种基于 local Poynting 的正则化器，以有效抑制电磁波传播过程中的累积能量漂移。实验结果显示，该模型在仅使用物理残差损失且无标签数据的情况下，实现了 0.09% 的 NRMSE 和 1.01% 的 L^2 误差。在 2D PEC cavity 场景中，能量失配仅为 0.024%，证明了 PINNs 在典型电磁仿真任务中具有与 FDTD 竞争的潜力，是电磁建模领域的一种高精度且符合物理规律的可行替代方案。",
      "categories": [
        "physics.comp-ph",
        "cs.AI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23396v1",
      "published_date": "2025-12-29 11:36:26 UTC",
      "updated_date": "2025-12-29 11:36:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:34.869757+00:00"
    },
    {
      "arxiv_id": "2512.23385v2",
      "title": "Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?",
      "title_zh": "保障人工智能供应链安全：开发者报告的 AI 项目安全问题及解决方案带来的启示",
      "authors": [
        "The Anh Nguyen",
        "Triet Huynh Minh Le",
        "M. Ali Babar"
      ],
      "abstract": "The rapid growth of Artificial Intelligence (AI) models and applications has led to an increasingly complex security landscape. Developers of AI projects must contend not only with traditional software supply chain issues but also with novel, AI-specific security threats. However, little is known about what security issues are commonly encountered and how they are resolved in practice. This gap hinders the development of effective security measures for each component of the AI supply chain. We bridge this gap by conducting an empirical investigation of developer-reported issues and solutions, based on discussions from Hugging Face and GitHub. To identify security-related discussions, we develop a pipeline that combines keyword matching with an optimal fine-tuned distilBERT classifier, which achieved the best performance in our extensive comparison of various deep learning and large language models. This pipeline produces a dataset of 312,868 security discussions, providing insights into the security reporting practices of AI applications and projects. We conduct a thematic analysis of 753 posts sampled from our dataset and uncover a fine-grained taxonomy of 32 security issues and 24 solutions across four themes: (1) System and Software, (2) External Tools and Ecosystem, (3) Model, and (4) Data. We reveal that many security issues arise from the complex dependencies and black-box nature of AI components. Notably, challenges related to Models and Data often lack concrete solutions. Our insights can offer evidence-based guidance for developers and researchers to address real-world security threats across the AI supply chain.",
      "tldr_zh": "该研究针对人工智能(AI)供应链中日益复杂的安全威胁，通过对Hugging Face和GitHub上开发者报告的问题与解决方案进行了实证调查。作者开发了一套结合关键词匹配和微调distilBERT分类器的自动化流水线，从海量讨论中筛选并构建了包含312,868条安全相关讨论的数据集。通过对样本进行主题分析，研究提炼出了涵盖系统与软件(System and Software)、外部工具与生态系统(External Tools and Ecosystem)、模型(Model)及数据(Data)四个维度的32种安全问题和24种解决方案。研究揭示了许多安全漏洞源于AI组件复杂的依赖关系和黑盒(black-box)特性，并指出模型和数据层面的挑战目前往往缺乏具体的解决手段。该成果为开发者和研究人员理解并应对AI供应链中的现实安全威胁提供了重要的实证依据和分类指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026) - Research Track",
      "pdf_url": "https://arxiv.org/pdf/2512.23385v2",
      "published_date": "2025-12-29 11:22:11 UTC",
      "updated_date": "2026-01-09 05:35:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:35.040454+00:00"
    },
    {
      "arxiv_id": "2512.23380v1",
      "title": "A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers",
      "title_zh": "基于协同 Transformer 的操作系统日志点异常与集体异常检测统一框架",
      "authors": [
        "Mohammad Nasirzadeh",
        "Jafar Tahmoresnezhad",
        "Parviz Rashidi-Khazaee"
      ],
      "abstract": "Log anomaly detection is crucial for preserving the security of operating systems. Depending on the source of log data collection, various information is recorded in logs that can be considered log modalities. In light of this intuition, unimodal methods often struggle by ignoring the different modalities of log data. Meanwhile, multimodal methods fail to handle the interactions between these modalities. Applying multimodal sentiment analysis to log anomaly detection, we propose CoLog, a framework that collaboratively encodes logs utilizing various modalities. CoLog utilizes collaborative transformers and multi-head impressed attention to learn interactions among several modalities, ensuring comprehensive anomaly detection. To handle the heterogeneity caused by these interactions, CoLog incorporates a modality adaptation layer, which adapts the representations from different log modalities. This methodology enables CoLog to learn nuanced patterns and dependencies within the data, enhancing its anomaly detection capabilities. Extensive experiments demonstrate CoLog's superiority over existing state-of-the-art methods. Furthermore, in detecting both point and collective anomalies, CoLog achieves a mean precision of 99.63%, a mean recall of 99.59%, and a mean F1 score of 99.61% across seven benchmark datasets for log-based anomaly detection. The comprehensive detection capabilities of CoLog make it highly suitable for cybersecurity, system monitoring, and operational efficiency. CoLog represents a significant advancement in log anomaly detection, providing a sophisticated and effective solution to point and collective anomaly detection through a unified framework and a solution to the complex challenges automatic log data analysis poses. We also provide the implementation of CoLog at https://github.com/NasirzadehMoh/CoLog.",
      "tldr_zh": "该研究提出了 CoLog，这是一个旨在检测操作系统日志中 Point 和 Collective Anomalies 的统一框架。针对现有方法在处理日志多模态交互方面的不足，CoLog 采用了 Collaborative Transformers 和 Multi-head Impressed Attention 来协作编码不同模态的信息。该框架通过 Modality Adaptation Layer 处理模态间的异构性，从而捕捉数据中复杂的模式与依赖关系。实验表明，CoLog 在七个基准数据集上的平均 Precision、Recall 和 F1 分数分别达到 99.63%、99.59% 和 99.61%，性能显著优于现有最先进方法。这项研究为自动化日志数据分析面临的挑战提供了高效的解决方案，在网络安全、系统监控和运营效率领域具有广阔的应用前景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NI",
        "cs.OS"
      ],
      "primary_category": "cs.LG",
      "comment": "72 pages, 19 figures, 19 tables, accepted in scientific reports on 5 November 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.23380v1",
      "published_date": "2025-12-29 11:18:34 UTC",
      "updated_date": "2025-12-29 11:18:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:32:39.495229+00:00"
    },
    {
      "arxiv_id": "2512.23379v3",
      "title": "SoulX-FlashTalk: Real-Time Infinite Streaming of Audio-Driven Avatars via Self-Correcting Bidirectional Distillation",
      "title_zh": "SoulX-FlashTalk：基于自纠错双向蒸馏的音频驱动数字人实时无限流式生成",
      "authors": [
        "Le Shen",
        "Qian Qiao",
        "Tan Yu",
        "Ke Zhou",
        "Tianhang Yu",
        "Yu Zhan",
        "Zhenjie Wang",
        "Ming Tao",
        "Shunshun Yin",
        "Siyuan Liu"
      ],
      "abstract": "Deploying massive diffusion models for real-time, infinite-duration, audio-driven avatar generation presents a significant engineering challenge, primarily due to the conflict between computational load and strict latency constraints. Existing approaches often compromise visual fidelity by enforcing strictly unidirectional attention mechanisms or reducing model capacity. To address this problem, we introduce \\textbf{SoulX-FlashTalk}, a 14B-parameter framework optimized for high-fidelity real-time streaming. Diverging from conventional unidirectional paradigms, we use a \\textbf{Self-correcting Bidirectional Distillation} strategy that retains bidirectional attention within video chunks. This design preserves critical spatiotemporal correlations, significantly enhancing motion coherence and visual detail. To ensure stability during infinite generation, we incorporate a \\textbf{Multi-step Retrospective Self-Correction Mechanism}, enabling the model to autonomously recover from accumulated errors and preventing collapse. Furthermore, we engineered a full-stack inference acceleration suite incorporating hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations. Extensive evaluations confirm that SoulX-FlashTalk is the first 14B-scale system to achieve a \\textbf{sub-second start-up latency (0.87s)} while reaching a real-time throughput of \\textbf{32 FPS}, setting a new standard for high-fidelity interactive digital human synthesis.",
      "tldr_zh": "该研究针对大规模扩散模型在生成实时、无限时长且由音频驱动的数字人形象时面临的计算负载与延迟瓶颈，提出了 SoulX-FlashTalk 框架。该框架拥有 14B 参数规模，专为高保真实时流式传输而优化。与传统的单向范式不同，SoulX-FlashTalk 采用了 Self-correcting Bidirectional Distillation 策略，在视频块内保留双向注意力机制，从而增强了时空相关性、动作连贯性和视觉细节。为了确保持续生成的稳定性，该研究引入了 Multi-step Retrospective Self-Correction Mechanism，使模型能够自动从累积误差中恢复，有效防止了长时间生成导致的系统崩溃。此外，研究团队还开发了包含混合序列并行 (hybrid sequence parallelism)、Parallel VAE 和内核级优化在内的全栈推理加速套件。实验结果显示，SoulX-FlashTalk 是首个在 14B 规模下实现低于一秒启动延迟（0.87s）并达到 32 FPS 实时吞吐量的系统，为高保真交互式数字人合成树立了新标准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23379v3",
      "published_date": "2025-12-29 11:18:24 UTC",
      "updated_date": "2026-01-06 04:58:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:10.649554+00:00"
    },
    {
      "arxiv_id": "2512.23367v2",
      "title": "Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2",
      "title_zh": "面向 Atlas A2 高效部署的 OpenPangu 模型训练后量化",
      "authors": [
        "Yilun Luo",
        "Huaqing Zheng",
        "Haoqian Meng",
        "Wenyuan Liu",
        "Peng Zhang"
      ],
      "abstract": "Huawei's openPangu-Embedded-1B and openPangu-Embedded-7B are variants of the openPangu large language model, designed for efficient deployment on Ascend NPUs. The 7B variant supports three distinct Chain-of-Thought (CoT) reasoning paradigms, namely slow_think, auto_think, and no_think, while the 1B variant operates exclusively in the no_think mode, which employs condensed reasoning for higher efficiency. Although CoT reasoning enhances capability, the generation of extended reasoning traces introduces substantial memory and latency overheads, posing challenges for practical deployment on Ascend NPUs. This paper addresses these computational constraints by leveraging low-bit quantization, which transforms FP16 computations into more efficient integer arithmetic. We introduce a unified low-bit inference framework, supporting INT8 (W8A8) and W4A8 quantization, specifically optimized for openPangu-Embedded models on the Atlas A2. Our comprehensive evaluation on code generation benchmarks (HumanEval and MBPP) demonstrates the efficacy of this approach. INT8 quantization consistently preserves over 90\\% of the FP16 baseline accuracy and achieves a 1.5x prefill speedup on the Atlas A2. Furthermore, W4A8 quantization significantly reduces memory consumption, albeit with a moderate trade-off in accuracy. These findings collectively indicate that low-bit quantization effectively facilitates efficient CoT reasoning on Ascend NPUs, maintaining high model fidelity.",
      "tldr_zh": "该研究针对华为推出的 openPangu-Embedded-1B 和 7B 模型在 Ascend NPUs 上的高效部署进行了深入探讨，重点解决 Chain-of-Thought (CoT) 推理带来的巨大内存和延迟开销。为了应对这些计算限制，作者提出了一套针对 Atlas A2 优化的统一低比特推理框架，支持将 FP16 计算转化为更高效的 INT8 (W8A8) 和 W4A8 量化算术。在 HumanEval 和 MBPP 代码生成基准测试中的评估结果显示，INT8 量化能够保留 FP16 基准模型 90% 以上的准确率，并在 Atlas A2 上实现 1.5 倍的 prefill 加速。此外，W4A8 量化虽然在准确率上存在一定折中，但显著降低了显存消耗。实验结果表明，低比特量化方案在保持模型高保真度的同时，有效促进了 CoT 推理在昇腾架构硬件上的高效运行，为大规模语言模型在边缘侧的实际部署提供了参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23367v2",
      "published_date": "2025-12-29 10:50:23 UTC",
      "updated_date": "2026-01-08 09:20:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:15.979604+00:00"
    },
    {
      "arxiv_id": "2512.23366v1",
      "title": "AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis",
      "title_zh": "AGRO-SQL：结合高保真数据合成的智能体组相对优化",
      "authors": [
        "Cehua Yang",
        "Dongyu Xiao",
        "Junming Lin",
        "Yuyang Song",
        "Hanxu Yan",
        "Shawn Guo",
        "Wei Zhang",
        "Jian Yang",
        "Mingjie Tang",
        "Bryan Dai"
      ],
      "abstract": "The advancement of Text-to-SQL systems is currently hindered by the scarcity of high-quality training data and the limited reasoning capabilities of models in complex scenarios. In this paper, we propose a holistic framework that addresses these issues through a dual-centric approach. From a Data-Centric perspective, we construct an iterative data factory that synthesizes RL-ready data characterized by high correctness and precise semantic-logic alignment, ensured by strict verification. From a Model-Centric perspective, we introduce a novel Agentic Reinforcement Learning framework. This framework employs a Diversity-Aware Cold Start stage to initialize a robust policy, followed by Group Relative Policy Optimization (GRPO) to refine the agent's reasoning via environmental feedback. Extensive experiments on BIRD and Spider benchmarks demonstrate that our synergistic approach achieves state-of-the-art performance among single-model methods.",
      "tldr_zh": "该研究提出了 AGRO-SQL，一个旨在解决 Text-to-SQL 系统中高质量训练数据稀缺以及模型在复杂场景下推理能力不足问题的综合性框架。在数据中心（Data-Centric）维度，该框架通过迭代数据工厂合成具有高正确性和精确语义逻辑对齐的 RL-ready 数据，并确保经过严格验证。在模型中心（Model-Centric）维度，研究引入了 Agentic Reinforcement Learning 框架，通过 Diversity-Aware Cold Start 阶段初始化稳健策略，并利用 Group Relative Policy Optimization (GRPO) 结合环境反馈来优化智能体的推理路径。实验结果显示，AGRO-SQL 在 BIRD 和 Spider 基准测试中均取得了单模型方法中的 state-of-the-art 性能，证明了数据合成与强化学习协同作用的有效性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23366v1",
      "published_date": "2025-12-29 10:49:35 UTC",
      "updated_date": "2025-12-29 10:49:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:19.916423+00:00"
    },
    {
      "arxiv_id": "2512.23347v1",
      "title": "ECG-RAMBA: Zero-Shot ECG Generalization by Morphology-Rhythm Disentanglement and Long-Range Modeling",
      "title_zh": "ECG-RAMBA：基于形态-节律解耦与长程建模的零样本心电图泛化",
      "authors": [
        "Hai Duong Nguyen",
        "Xuan-The Tran"
      ],
      "abstract": "Deep learning has achieved strong performance for electrocardiogram (ECG) classification within individual datasets, yet dependable generalization across heterogeneous acquisition settings remains a major obstacle to clinical deployment and longitudinal monitoring. A key limitation of many model architectures is the implicit entanglement of morphological waveform patterns and rhythm dynamics, which can promote shortcut learning and amplify sensitivity to distribution shifts. We propose ECG-RAMBA, a framework that separates morphology and rhythm and then re-integrates them through context-aware fusion. ECG-RAMBA combines: (i) deterministic morphological features extracted by MiniRocket, (ii) global rhythm descriptors computed from heart-rate variability (HRV), and (iii) long-range contextual modeling via a bi-directional Mamba backbone. To improve sensitivity to transient abnormalities under windowed inference, we introduce a numerically stable Power Mean pooling operator ($Q=3$) that emphasizes high-evidence segments while avoiding the brittleness of max pooling and the dilution of averaging. We evaluate under a protocol-faithful setting with subject-level cross-validation, a fixed decision threshold, and no test-time adaptation. On the Chapman--Shaoxing dataset, ECG-RAMBA achieves a macro ROC-AUC $\\approx 0.85$. In zero-shot transfer, it attains PR-AUC $=0.708$ for atrial fibrillation detection on the external CPSC-2021 dataset, substantially outperforming a comparable raw-signal Mamba baseline, and shows consistent cross-dataset performance on PTB-XL. Ablation studies indicate that deterministic morphology provides a strong foundation, while explicit rhythm modeling and long-range context are critical drivers of cross-domain robustness.",
      "tldr_zh": "该研究提出了ECG-RAMBA框架，旨在解决深度学习模型在心电图(ECG)分类中因形态特征与节律动力学耦合导致的跨数据集泛化难题。该框架通过MiniRocket提取确定性Morphology特征，并结合基于心率变异性(HRV)的全局Rhythm描述符，最后利用双向Mamba (Bi-directional Mamba)主干网络进行长程上下文建模。为了增强对窗口推理下瞬时异常的敏感性，研究引入了数值稳定的Power Mean pooling算子，有效平衡了高置信度片段的强调与信号稀释问题。实验结果显示，ECG-RAMBA在Chapman--Shaoxing数据集上实现了约0.85的宏观ROC-AUC。在CPSC-2021数据集的零样本(Zero-Shot)迁移测试中，该模型在房颤检测任务中表现出色，PR-AUC达到0.708，显著优于原始信号Mamba基准模型。消融研究进一步证实，显式的节律建模和长程上下文捕捉是驱动跨领域鲁棒性的核心因素，为心电图的临床可靠部署和长程监控提供了有效的技术支撑。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23347v1",
      "published_date": "2025-12-29 10:14:52 UTC",
      "updated_date": "2025-12-29 10:14:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:33.454598+00:00"
    },
    {
      "arxiv_id": "2601.05277v1",
      "title": "Evolving Cognitive Architectures",
      "title_zh": "演化式认知架构",
      "authors": [
        "Alexander Serov"
      ],
      "abstract": "This article proposes a research and development direction that would lead to the creation of next-generation intelligent technical systems. A distinctive feature of these systems is their ability to undergo evolutionary change. Cognitive architectures are now one of the most promising ways to create Artificial General Intelligence systems. One of the main problems of modern cognitive architectures is an excessively schematic approach to modeling the processes of cognitive activity. It does not allow the creation of a universal architecture that would be capable of reproducing higher nervous functions without using a predetermined set of perception patterns. Our paper proposes an evolutionary approach to creating a cognitive architecture. The basis of this approach is the use of a functional core, which consistently generates the intellectual functions of an autonomous agent. We are considering a cognitive architecture that includes components, the interaction of which ensures the evolution of the agent. The discussion of the development of intelligence is carried out using the conceptual apparatus of semiotics. This allows us to consider the task of developing cognitive functions as a problem of establishing a connection between the Merkwelt and the Werkwelt through the creation of the Innenwelt. The problem of early postnatal ontogenesis is investigated on the basis of the theory of constructivism: we discuss the requirements for the functional core and its composition, as well as the mechanism that initiates the process of cognition.",
      "tldr_zh": "该研究探讨了下一代智能技术系统的研发方向，重点关注具备进化能力的认知架构(Cognitive Architectures)，旨在解决当前通用人工智能(AGI)系统在建模认知活动时过于模式化且依赖预设感知模式的局限。论文提出了一种进化式路径，其核心是利用功能核(Functional Core)持续生成自主智能体的各项智力功能，并通过组件间的交互确保智能体的持续进化。通过引入符号学(Semiotics)概念，研究将认知功能的发展定义为在知觉世界(Merkwelt)与作用世界(Werkwelt)之间通过构建内部世界(Innenwelt)建立联系的过程。此外，研究还基于建构主义(Constructivism)理论调查了早期产后个体发育(Early postnatal ontogenesis)问题，详细阐述了功能核的组成要求及其启动认知过程的机制。这种方法为实现能够自主再现高级神经功能且无需预设模式的通用智能架构提供了全新的理论框架与实现路径。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.05277v1",
      "published_date": "2025-12-29 10:09:20 UTC",
      "updated_date": "2025-12-29 10:09:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:23.494922+00:00"
    },
    {
      "arxiv_id": "2512.23343v1",
      "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
      "title_zh": "AI 遇见大脑：从认知神经科学到自主智能体的记忆系统",
      "authors": [
        "Jiafeng Liang",
        "Hao Li",
        "Chang Li",
        "Jiaqi Zhou",
        "Shixin Jiang",
        "Zekun Wang",
        "Changkai Ji",
        "Zhihao Zhu",
        "Runxuan Liu",
        "Tao Ren",
        "Jinlan Fu",
        "See-Kiong Ng",
        "Xia Liang",
        "Ming Liu",
        "Bing Qin"
      ],
      "abstract": "Memory serves as the pivotal nexus bridging past and future, providing both humans and AI systems with invaluable concepts and experience to navigate complex tasks. Recent research on autonomous agents has increasingly focused on designing efficient memory workflows by drawing on cognitive neuroscience. However, constrained by interdisciplinary barriers, existing works struggle to assimilate the essence of human memory mechanisms. To bridge this gap, we systematically synthesizes interdisciplinary knowledge of memory, connecting insights from cognitive neuroscience with LLM-driven agents. Specifically, we first elucidate the definition and function of memory along a progressive trajectory from cognitive neuroscience through LLMs to agents. We then provide a comparative analysis of memory taxonomy, storage mechanisms, and the complete management lifecycle from both biological and artificial perspectives. Subsequently, we review the mainstream benchmarks for evaluating agent memory. Additionally, we explore memory security from dual perspectives of attack and defense. Finally, we envision future research directions, with a focus on multimodal memory systems and skill acquisition.",
      "tldr_zh": "该研究系统性地综述了从认知神经科学(Cognitive Neuroscience)到自主智能体(Autonomous Agents)的记忆系统，旨在弥合生物记忆机制与人工智能之间的跨学科鸿沟。文章首先阐明了记忆在认知神经科学、大语言模型(LLM)及智能体演进过程中的定义与功能，并从生物与人工双重视角对记忆分类、存储机制及全生命周期管理进行了对比分析。此外，研究还回顾了评估智能体记忆性能的主流基准(Benchmarks)，并从攻击与防御两个维度探讨了记忆安全挑战。最后，作者提出了对未来研究方向的展望，重点聚焦于多模态记忆系统(Multimodal Memory Systems)与技能获取。该综述通过整合跨学科知识，为开发受脑科学启发的、更高效的智能体记忆工作流提供了重要的理论支撑。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "57 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23343v1",
      "published_date": "2025-12-29 10:01:32 UTC",
      "updated_date": "2025-12-29 10:01:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:31.211278+00:00"
    },
    {
      "arxiv_id": "2512.23340v1",
      "title": "The Law of Multi-Model Collaboration: Scaling Limits of Model Ensembling for Large Language Models",
      "title_zh": "多模型协作定律：大语言模型集成的扩展极限",
      "authors": [
        "Dakuan Lu",
        "Jiaqi Zhang",
        "Cheng Yuan",
        "Jiawei Shao",
        "Chi Zhang",
        "Xuelong Li"
      ],
      "abstract": "Recent advances in large language models (LLMs) have been largely driven by scaling laws for individual models, which predict performance improvements as model parameters and data volume increase. However, the capabilities of any single LLM are inherently bounded. One solution originates from intricate interactions among multiple LLMs, rendering their collective performance surpasses that of any constituent model. Despite the rapid proliferation of multi-model integration techniques such as model routing and post-hoc ensembling, a unifying theoretical framework of performance scaling for multi-model collaboration remains absent. In this work, we propose the Law of Multi-model Collaboration, a scaling law that predicts the performance limits of LLM ensembles based on their aggregated parameter budget. To quantify the intrinsic upper bound of multi-model collaboration, we adopt a method-agnostic formulation and assume an idealized integration oracle where the total cross-entropy loss of each sample is determined by the minimum loss of any model in the model pool. Experimental results reveal that multi-model systems follow a power-law scaling with respect to the total parameter count, exhibiting a more significant improvement trend and a lower theoretical loss floor compared to single model scaling. Moreover, ensembles of heterogeneous model families achieve better performance scaling than those formed within a single model family, indicating that model diversity is a primary driver of collaboration gains. These findings suggest that model collaboration represents a critical axis for extending the intelligence frontier of LLMs.",
      "tldr_zh": "该研究提出了“多模型协作法则”（Law of Multi-model Collaboration），旨在通过聚合参数预算预测大语言模型集成（LLM ensembles）的性能极限。为了量化多模型协作的内在上限，研究采用了与方法无关的公式化表述，并假设了一种理想的集成预测机制（integration oracle），即每个样本的交叉熵损失（cross-entropy loss）由模型池中损失最小的模型决定。实验结果显示，多模型系统在总参数量上遵循幂律缩放（power-law scaling），相比单模型缩放，其具有更显著的提升趋势和更低的理论损失下限。此外，异构模型家族（heterogeneous model families）的集成表现优于单一家族内部的集成，表明模型多样性（model diversity）是协作增益的主要驱动力。这些发现强调了模型协作是突破单个大语言模型（LLMs）能力边界、扩展智能前沿的关键路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23340v1",
      "published_date": "2025-12-29 09:55:12 UTC",
      "updated_date": "2025-12-29 09:55:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:28.986857+00:00"
    },
    {
      "arxiv_id": "2601.00848v1",
      "title": "Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models",
      "title_zh": "多智能体 AI 工作流中的时序攻击模式检测：用于训练基于追踪的安全模型的开放框架",
      "authors": [
        "Ron F. Del Rosario"
      ],
      "abstract": "We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.",
      "tldr_zh": "该研究提出了一个开源框架，旨在通过 OpenTelemetry 追踪分析检测多智能体 AI 工作流（Multi-Agent AI Workflows）中的时序攻击模式。作者策划了一个包含 80,851 个安全示例和 35,026 个合成 OpenTelemetry 追踪的数据集，并采用迭代式 QLoRA 微调方法在 ARM64 硬件上进行训练。实验结果显示，定制化的基准测试准确率从 42.86% 显著提升至 74.29%，证明了针对性训练数据在填补知识差距方面优于盲目扩大数据规模。研究的核心贡献包括针对多智能体协同攻击的合成追踪生成方法，以及证实训练数据组成决定模型行为的实证证据。该工作通过在 HuggingFace 上开源完整的数据集、脚本和评估基准，确立了首个可复现的框架，使从业者能够构建适应特定威胁环境的定制化代理安全模型。尽管目前实际部署仍需人工监督以管理误报率，该研究为提升智能体系统的安全性和合规性提供了重要参考。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 3 figures, 7 tables. Datasets and code: https://huggingface.co/guerilla7/agentic-safety-gguf",
      "pdf_url": "https://arxiv.org/pdf/2601.00848v1",
      "published_date": "2025-12-29 09:41:22 UTC",
      "updated_date": "2025-12-29 09:41:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:34.570033+00:00"
    },
    {
      "arxiv_id": "2512.23328v3",
      "title": "CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations",
      "title_zh": "CubeBench：部分观测下交互式长程空间推理的诊断",
      "authors": [
        "Huan-ang Gao",
        "Zikang Zhang",
        "Tianwei Luo",
        "Kaisen Yang",
        "Xinzhe Juan",
        "Jiahao Qiu",
        "Tianxing Chen",
        "Bingxiang He",
        "Hao Zhao",
        "Hao Zhou",
        "Shilong Liu",
        "Mengdi Wang"
      ],
      "abstract": "Large Language Model (LLM) agents, while proficient in the digital realm, face a significant gap in physical-world deployment due to the challenge of forming and maintaining a robust spatial mental model. We identify three core cognitive challenges hindering this transition: spatial reasoning, long-horizon state tracking via mental simulation, and active exploration under partial observation. To isolate and evaluate these faculties, we introduce CubeBench, a novel generative benchmark centered on the Rubik's Cube. CubeBench uses a three-tiered diagnostic framework that progressively assesses agent capabilities, from foundational state tracking with full symbolic information to active exploration with only partial visual data. Our experiments on leading LLMs reveal critical limitations, including a uniform 0.00% pass rate on all long-horizon tasks, exposing a fundamental failure in long-term planning. We also propose a diagnostic framework to isolate these cognitive bottlenecks by providing external solver tools. By analyzing the failure modes, we provide key insights to guide the development of more physically-grounded intelligent agents.",
      "tldr_zh": "该研究探讨了大型语言模型(LLM)智能体在物理世界部署中面临的空间心理模型构建挑战，指出空间推理(spatial reasoning)、长程状态跟踪(long-horizon state tracking)及部分观测下的主动探索(active exploration)是其核心认知障碍。为此，作者提出了CubeBench，一个以魔方(Rubik's Cube)为核心的新型生成式基准测试，旨在隔离并评估这些能力。CubeBench通过三层诊断框架，评估智能体从处理完整符号信息到仅依赖部分视觉数据进行探索的表现。实验结果显示，当前领先的LLM在所有长程任务中的通过率均为0.00%，暴露了其在长程规划(long-term planning)方面的根本性缺陷。研究还通过提供外部求解工具(external solver tools)构建了诊断框架以定位认知瓶颈。通过分析失败模式，该研究为开发更具物理落地(physically-grounded)能力的智能体提供了关键指导。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Webpage: https://cubebench.c7w.tech/",
      "pdf_url": "https://arxiv.org/pdf/2512.23328v3",
      "published_date": "2025-12-29 09:25:56 UTC",
      "updated_date": "2026-01-01 15:48:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:36.313685+00:00"
    },
    {
      "arxiv_id": "2512.23324v1",
      "title": "On Conformant Planning and Model-Checking of $\\exists^*\\forall^*$ Hyperproperties",
      "title_zh": "论 $\\exists^*\\forall^*$ 超属性的一致性规划与模型检测",
      "authors": [
        "Raven Beutner",
        "Bernd Finkbeiner"
      ],
      "abstract": "We study the connection of two problems within the planning and verification community: Conformant planning and model-checking of hyperproperties. Conformant planning is the task of finding a sequential plan that achieves a given objective independent of non-deterministic action effects during the plan's execution. Hyperproperties are system properties that relate multiple execution traces of a system and, e.g., capture information-flow and fairness policies. In this paper, we show that model-checking of $\\exists^*\\forall^*$ hyperproperties is closely related to the problem of computing a conformant plan. Firstly, we show that we can efficiently reduce a hyperproperty model-checking instance to a conformant planning instance, and prove that our encoding is sound and complete. Secondly, we establish the converse direction: Every conformant planning problem is, itself, a hyperproperty model-checking task.",
      "tldr_zh": "该研究深入探讨了规划与验证领域中一致性规划(Conformant Planning)与$\\exists^*\\forall^*$超属性(Hyperproperties)的模型检测(Model-checking)之间的内在联系。一致性规划旨在非确定性环境下寻找实现目标的顺序计划，而超属性则用于描述涉及多个执行轨迹的系统特性，如信息流和公平性。论文证明了这两类问题在计算本质上是紧密相关的，并展示了如何将超属性模型检测实例高效地还原为一致性规划实例。研究者不仅证明了该编码方案在理论上的完备性(Sound and Complete)，还确立了反向的逻辑关系，即每个一致性规划问题本身都可以被视为一个超属性模型检测任务。这项工作为跨领域问题的转换与求解提供了坚实的理论基础和方法论支持。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "ECAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.23324v1",
      "published_date": "2025-12-29 09:20:29 UTC",
      "updated_date": "2025-12-29 09:20:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:33:47.903041+00:00"
    },
    {
      "arxiv_id": "2512.23312v1",
      "title": "Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants",
      "title_zh": "面向避障机器人操纵的可解释神经逆运动学：IKNet 变体对比分析",
      "authors": [
        "Sheng-Kai Chen",
        "Yi-Ling Tsai",
        "Chun-Chih Chang",
        "Yan-Chen Chen",
        "Po-Chiang Lin"
      ],
      "abstract": "Deep neural networks have accelerated inverse-kinematics (IK) inference to the point where low cost manipulators can execute complex trajectories in real time, yet the opaque nature of these models contradicts the transparency and safety requirements emerging in responsible AI regulation. This study proposes an explainability centered workflow that integrates Shapley-value attribution with physics-based obstacle avoidance evaluation for the ROBOTIS OpenManipulator-X. Building upon the original IKNet, two lightweight variants-Improved IKNet with residual connections and Focused IKNet with position-orientation decoupling are trained on a large, synthetically generated pose-joint dataset. SHAP is employed to derive both global and local importance rankings, while the InterpretML toolkit visualizes partial-dependence patterns that expose non-linear couplings between Cartesian poses and joint angles. To bridge algorithmic insight and robotic safety, each network is embedded in a simulator that subjects the arm to randomized single and multi-obstacle scenes; forward kinematics, capsule-based collision checks, and trajectory metrics quantify the relationship between attribution balance and physical clearance. Qualitative heat maps reveal that architectures distributing importance more evenly across pose dimensions tend to maintain wider safety margins without compromising positional accuracy. The combined analysis demonstrates that explainable AI(XAI) techniques can illuminate hidden failure modes, guide architectural refinements, and inform obstacle aware deployment strategies for learning based IK. The proposed methodology thus contributes a concrete path toward trustworthy, data-driven manipulation that aligns with emerging responsible-AI standards.",
      "tldr_zh": "该研究针对深度神经网络在逆运动学(Inverse Kinematics)推理中的不透明性，提出了一种以可解释性为核心的工作流，旨在满足负责任AI的透明度与安全要求。作者基于ROBOTIS OpenManipulator-X平台，对比了原始IKNet以及引入残差连接的Improved IKNet和实现位姿解耦的Focused IKNet两种轻量化变体。通过集成Shapley-value归因分析与InterpretML可视化工具，研究揭示了笛卡尔位姿与关节角度之间的非线性耦合关系。在物理模拟器的障碍物规避测试中，该研究量化了归因平衡与物理安全间隙之间的关系。定性热图分析发现，在位姿维度上重要性分布更均匀的架构能够在保证精度的同时维持更宽的安全裕度。这项工作证明了可解释人工智能(XAI)技术能有效识别潜在故障模式并指导架构优化，为实现符合安全标准的可靠数据驱动型机器人操控提供了明确路径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "27 pages, 16 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23312v1",
      "published_date": "2025-12-29 09:02:02 UTC",
      "updated_date": "2025-12-29 09:02:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:03.689785+00:00"
    },
    {
      "arxiv_id": "2512.23310v1",
      "title": "Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL",
      "title_zh": "Splitwise：基于 Lyapunov 辅助深度强化学习的大语言模型边云协同推理",
      "authors": [
        "Abolfazl Younesi",
        "Abbas Shabrang Maryan",
        "Elyas Oustad",
        "Zahra Najafabadi Samani",
        "Mohsen Ansari",
        "Thomas Fahringer"
      ],
      "abstract": "Deploying large language models (LLMs) on edge devices is challenging due to their limited memory and power resources. Cloud-only inference reduces device burden but introduces high latency and cost. Static edge-cloud partitions optimize a single metric and struggle when bandwidth fluctuates. We propose Splitwise, a novel Lyapunov-assisted deep reinforcement learning (DRL) framework for fine-grained, adaptive partitioning of LLMs across edge and cloud environments. Splitwise decomposes transformer layers into attention heads and feed-forward sub-blocks, exposing more partition choices than layer-wise schemes. A hierarchical DRL policy, guided by Lyapunov optimization, jointly minimizes latency, energy consumption, and accuracy degradation while guaranteeing queue stability under stochastic workloads and variable network bandwidth. Splitwise also guarantees robustness via partition checkpoints with exponential backoff recovery in case of communication failures. Experiments on Jetson Orin NX, Galaxy S23, and Raspberry Pi 5 with GPT-2 (1.5B), LLaMA-7B, and LLaMA-13B show that Splitwise reduces end-to-end latency by 1.4x-2.8x and cuts energy consumption by up to 41% compared with existing partitioners. It lowers the 95th-percentile latency by 53-61% relative to cloud-only execution, while maintaining accuracy and modest memory requirements.",
      "tldr_zh": "该研究提出了 Splitwise，一种基于 Lyapunov 辅助的深度强化学习 (DRL) 框架，旨在实现大语言模型 (LLMs) 在边缘与云端环境之间的细粒度自适应协同推理。针对边缘设备内存与功耗受限以及云端推理延迟高的问题，Splitwise 将 Transformer 层进一步分解为注意力头 (attention heads) 和前馈子块 (feed-forward sub-blocks)，提供了比传统层级方案更灵活的分区选择。该框架采用层次化 DRL 策略并结合 Lyapunov 优化，在保证随机负载下队列稳定性的同时，协同最小化延迟、能耗及精度损失。实验表明，在 Jetson Orin NX 和 Galaxy S23 等设备上运行 LLaMA-7B/13B 等模型时，Splitwise 的端到端延迟降低了 1.4 至 2.8 倍，能耗最高削减了 41%。此外，该系统通过分区检查点和指数退避恢复机制确保了通信故障下的鲁棒性，显著优于现有的静态分区及纯云端执行方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 9 figures. Accepted by ACM for presentation at UCC '25 (18th International Conference on Utility and Cloud Computing), December 1-4, 2025, France. Proceedings publication pending",
      "pdf_url": "https://arxiv.org/pdf/2512.23310v1",
      "published_date": "2025-12-29 08:57:58 UTC",
      "updated_date": "2025-12-29 08:57:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:04.294846+00:00"
    },
    {
      "arxiv_id": "2512.23304v1",
      "title": "MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images",
      "title_zh": "MedGemma 与 GPT-4：基于医学图像的开源与闭源零样本疾病分类对比",
      "authors": [
        "Md. Sazzadul Islam Prottasha",
        "Nabil Walid Rafi"
      ],
      "abstract": "Multimodal Large Language Models (LLMs) introduce an emerging paradigm for medical imaging by interpreting scans through the lens of extensive clinical knowledge, offering a transformative approach to disease classification. This study presents a critical comparison between two fundamentally different AI architectures: the specialized open-source agent MedGemma and the proprietary large multimodal model GPT-4 for diagnosing six different diseases. The MedGemma-4b-it model, fine-tuned using Low-Rank Adaptation (LoRA), demonstrated superior diagnostic capability by achieving a mean test accuracy of 80.37% compared to 69.58% for the untuned GPT-4. Furthermore, MedGemma exhibited notably higher sensitivity in high-stakes clinical tasks, such as cancer and pneumonia detection. Quantitative analysis via confusion matrices and classification reports provides comprehensive insights into model performance across all categories. These results emphasize that domain-specific fine-tuning is essential for minimizing hallucinations in clinical implementation, positioning MedGemma as a sophisticated tool for complex, evidence-based medical reasoning.",
      "tldr_zh": "本研究对开源专用智能体 MedGemma 与闭源多模态大模型 GPT-4 在六种不同疾病的零样本 (Zero-shot) 医学影像分类任务中进行了对比分析。MedGemma-4b-it 模型通过低秩自适应 (Low-Rank Adaptation, LoRA) 进行了微调，而 GPT-4 则在未微调的状态下直接应用。实验结果显示，MedGemma 的平均测试准确率达到了 80.37%，显著优于 GPT-4 的 69.58%。特别是在癌症和肺炎检测等高风险临床任务中，MedGemma 展现出了更高的敏感性 (Sensitivity)。通过混淆矩阵和分类报告的定量分析进一步证明，领域特定的微调 (Domain-specific fine-tuning) 对于减少临床应用中的幻觉 (Hallucinations) 至关重要。该研究将 MedGemma 定位为一种能够进行复杂循证医学推理的高级工具，有力地展示了开源微调模型在医学影像诊断领域的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in the Journal of Machine Learning and Deep Learning (JMLDL). 9 pages, 9 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2512.23304v1",
      "published_date": "2025-12-29 08:48:36 UTC",
      "updated_date": "2025-12-29 08:48:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:06.268041+00:00"
    },
    {
      "arxiv_id": "2512.23292v2",
      "title": "Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control",
      "title_zh": "智能体物理人工智能：迈向核反应堆控制的领域专用基础模型",
      "authors": [
        "Yoonpyo Lee",
        "Kazuma Kobayashi",
        "Sai Puppala",
        "Sajedul Talukder",
        "Seid Koric",
        "Souvik Chakraborty",
        "Syed Bahauddin Alam"
      ],
      "abstract": "The prevailing paradigm in AI for physical systems, scaling general-purpose foundation models toward universal multimodal reasoning, confronts a fundamental barrier at the control interface. Recent benchmarks show that even frontier vision-language models achieve only 50-53% accuracy on basic quantitative physics tasks, behaving as approximate guessers that preserve semantic plausibility while violating physical constraints. This input unfaithfulness is not a scaling deficiency but a structural limitation. Perception-centric architectures optimize parameter-space imitation, whereas safety-critical control demands outcome-space guarantees over executed actions. Here, we present a fundamentally different pathway toward domain-specific foundation models by introducing compact language models operating as Agentic Physical AI, in which policy optimization is driven by physics-based validation rather than perceptual inference. We train a 360-million-parameter model on synthetic reactor control scenarios, scaling the dataset from 10^3 to 10^5 examples. This induces a sharp phase transition absent in general-purpose models. Small-scale systems exhibit high-variance imitation with catastrophic tail risk, while large-scale models undergo variance collapse exceeding 500x reduction, stabilizing execution-level behavior. Despite balanced exposure to four actuation families, the model autonomously rejects approximately 70% of the training distribution and concentrates 95% of runtime execution on a single-bank strategy. Learned representations transfer across distinct physics and continuous input modalities without architectural modification.",
      "tldr_zh": "该研究针对通用大模型在物理系统控制界面面临的结构性局限，提出了一种面向核反应堆控制的领域特定基础模型，即智能体化物理人工智能(Agentic Physical AI)。该方法采用3.6亿参数的紧凑语言模型，通过在合成反应堆控制场景中将数据集规模从10^3扩展至10^5，实现了由物理验证驱动而非感知推理驱动的策略优化。研究发现模型在数据规模扩大后经历了显著的相变，方差坍缩(variance collapse)超过500倍，极大地增强了执行行为的稳定性。在实际运行中，模型能够自主过滤掉约70%的训练分布，并将95%的执行任务集中在单排策略(single-bank strategy)上。此外，该模型学习到的表示在无需修改架构的情况下，即可在不同物理规律和连续输入模态间实现迁移，为安全关键型物理系统的控制提供了新的技术范式。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23292v2",
      "published_date": "2025-12-29 08:26:27 UTC",
      "updated_date": "2026-01-06 02:29:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:08.417883+00:00"
    },
    {
      "arxiv_id": "2512.23260v2",
      "title": "Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation",
      "title_zh": "基于 SAE 构建低秩子空间适配的可解释安全对齐",
      "authors": [
        "Dianyun Wang",
        "Qingsen Ma",
        "Yuhu Shang",
        "Zhifeng Lu",
        "Zhenbo Xu",
        "Lechen Ning",
        "Huijia Wu",
        "Zhaofeng He"
      ],
      "abstract": "Safety alignment -- training large language models (LLMs) to refuse harmful requests while remaining helpful -- is critical for responsible deployment. Prior work established that safety behaviors are governed by low-rank structures, suggesting parameter-efficient fine-tuning (PEFT) should be well-suited for alignment. However, Low-Rank Adaptation (LoRA) consistently underperforms full fine-tuning and reinforcement learning on safety benchmarks. We attribute this gap to semantic entanglement: safety-relevant directions are intertwined with unrelated concepts due to polysemanticity, impeding implicit subspace identification. To address this, we propose SAILS (Safety Alignment via Interpretable Low-rank Subspace), which leverages Sparse Autoencoders (SAEs) to disentangle representations into monosemantic features, constructs an interpretable safety subspace from SAE decoder directions, and uses it to initialize LoRA adapters. Theoretically, we prove that SAE-based identification achieves arbitrarily small recovery error under monosemanticity assumptions, while direct identification suffers an irreducible error floor. Empirically, SAILS achieves up to 99.6% safety rate on Gemma-2-9B -- exceeding full fine-tuning by 7.4 points and matching RLHF-based models -- while updating only 0.19% of parameters and providing interpretability.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在安全对齐(Safety alignment)中存在的语义纠缠(semantic entanglement)问题，提出了SAILS框架。由于多语义性(polysemanticity)导致传统的低秩自适应(LoRA)表现不佳，SAILS利用稀疏自编码器(Sparse Autoencoders, SAEs)将模型表示分解为单语义特征(monosemantic features)，并以此构建可解释的安全子空间来初始化LoRA适配器。理论分析表明，相比直接识别，基于SAE的方法能显著降低恢复误差。实验结果显示，SAILS在Gemma-2-9B模型上仅通过更新0.19%的参数，就实现了高达99.6%的安全率，不仅超过了全参数微调7.4个百分点，还达到了与RLHF模型相当的性能。这一工作为开发高效且可解释的负责任人工智能部署技术提供了重要参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23260v2",
      "published_date": "2025-12-29 07:39:49 UTC",
      "updated_date": "2026-01-05 13:39:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:14.000155+00:00"
    },
    {
      "arxiv_id": "2512.23770v1",
      "title": "Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions",
      "title_zh": "安全偏置策略优化：基于置信域实现硬约束强化学习",
      "authors": [
        "Ankit Kanwar",
        "Dominik Wagner",
        "Luke Ong"
      ],
      "abstract": "Reinforcement learning (RL) in safety-critical domains requires agents to maximise rewards while strictly adhering to safety constraints. Existing approaches, such as Lagrangian and projection-based methods, often either fail to ensure near-zero safety violations or sacrifice reward performance in the face of hard constraints. We propose Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new trust-region algorithm for hard-constrained RL. SB-TRPO adaptively biases policy updates towards constraint satisfaction while still seeking reward improvement. Concretely, it performs trust-region updates using a convex combination of the natural policy gradients of cost and reward, ensuring a fixed fraction of optimal cost reduction at each step. We provide a theoretical guarantee of local progress towards safety, with reward improvement when gradients are suitably aligned. Experiments on standard and challenging Safety Gymnasium tasks show that SB-TRPO consistently achieves the best balance of safety and meaningful task completion compared to state-of-the-art methods.",
      "tldr_zh": "该研究提出了Safety-Biased Trust Region Policy Optimisation (SB-TRPO)，这是一种针对硬约束强化学习 (Hard-Constrained RL) 的新型信任区域算法。该算法旨在解决现有Lagrangian和投影方法在保证近零安全违反与维持奖励性能之间的权衡难题。SB-TRPO通过利用成本和奖励的自然策略梯度 (Natural Policy Gradients) 的凸组合，在信任区域内自适应地偏置策略更新以优先满足约束，同时寻求奖励改进。理论证明该方法能保证向安全性的局部进展，并在梯度对齐时提升奖励。在Safety Gymnasium任务上的实验结果证明，SB-TRPO在安全性和任务完成度之间达到了现有最先进方法中的最佳平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23770v1",
      "published_date": "2025-12-29 07:15:07 UTC",
      "updated_date": "2025-12-29 07:15:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:20.067653+00:00"
    },
    {
      "arxiv_id": "2512.23244v1",
      "title": "ViLaCD-R1: A Vision-Language Framework for Semantic Change Detection in Remote Sensing",
      "title_zh": "ViLaCD-R1：面向遥感语义变化检测的视觉语言框架",
      "authors": [
        "Xingwei Ma",
        "Shiyang Feng",
        "Bo Zhang",
        "Bin Wang"
      ],
      "abstract": "Remote sensing change detection (RSCD), a complex multi-image inference task, traditionally uses pixel-based operators or encoder-decoder networks that inadequately capture high-level semantics and are vulnerable to non-semantic perturbations. Although recent multimodal and vision-language model (VLM)-based approaches enhance semantic understanding of change regions by incorporating textual descriptions, they still suffer from challenges such as inaccurate spatial localization, imprecise pixel-level boundary delineation, and limited interpretability. To address these issues, we propose ViLaCD-R1, a two-stage framework comprising a Multi-Image Reasoner (MIR) and a Mask-Guided Decoder (MGD). Specifically, the VLM is trained through supervised fine-tuning (SFT) and reinforcement learning (RL) on block-level dual-temporal inference tasks, taking dual-temporal image patches as input and outputting a coarse change mask. Then, the decoder integrates dual-temporal image features with this coarse mask to predict a precise binary change map. Comprehensive evaluations on multiple RSCD benchmarks demonstrate that ViLaCD-R1 substantially improves true semantic change recognition and localization, robustly suppresses non-semantic variations, and achieves state-of-the-art accuracy in complex real-world scenarios.",
      "tldr_zh": "该研究针对遥感变化检测 (Remote Sensing Change Detection, RSCD) 中传统方法难以捕捉高层语义且易受非语义干扰的问题，提出了 ViLaCD-R1 视觉语言框架。该框架由多图像推理器 (Multi-Image Reasoner, MIR) 和掩码引导解码器 (Mask-Guided Decoder, MGD) 组成，采用两阶段处理流程。在第一阶段，视觉语言模型 (VLM) 经过有监督微调 (SFT) 和强化学习 (RL) 训练，根据双时态图像块输出粗略的变化掩码。随后，解码器将双时态特征与该掩码相结合，以预测精确的像素级二值变化图。实验结果表明，ViLaCD-R1 在多个基准测试中显著提升了语义变化的识别与定位精度，能有效抑制非语义波动，并在复杂现实场景中达到了最先进的 (state-of-the-art) 准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23244v1",
      "published_date": "2025-12-29 06:58:46 UTC",
      "updated_date": "2025-12-29 06:58:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:30.906436+00:00"
    },
    {
      "arxiv_id": "2512.23769v1",
      "title": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
      "title_zh": "揭示歧视簇：系统性公平性违规的量化与解释",
      "authors": [
        "Ranit Debnath Akash",
        "Ashish Kumar",
        "Verya Monjezi",
        "Ashutosh Trivedi",
        "Gang",
        "Tan",
        "Saeid Tizpaz-Niari"
      ],
      "abstract": "Fairness in algorithmic decision-making is often framed in terms of individual fairness, which requires that similar individuals receive similar outcomes. A system violates individual fairness if there exists a pair of inputs differing only in protected attributes (such as race or gender) that lead to significantly different outcomes-for example, one favorable and the other unfavorable. While this notion highlights isolated instances of unfairness, it fails to capture broader patterns of systematic or clustered discrimination that may affect entire subgroups. We introduce and motivate the concept of discrimination clustering, a generalization of individual fairness violations. Rather than detecting single counterfactual disparities, we seek to uncover regions of the input space where small perturbations in protected features lead to k-significantly distinct clusters of outcomes. That is, for a given input, we identify a local neighborhood-differing only in protected attributes-whose members' outputs separate into many distinct clusters. These clusters reveal significant arbitrariness in treatment solely based on protected attributes that help expose patterns of algorithmic bias that elude pairwise fairness checks. We present HyFair, a hybrid technique that combines formal symbolic analysis (via SMT and MILP solvers) to certify individual fairness with randomized search to discover discriminatory clusters. This combination enables both formal guarantees-when no counterexamples exist-and the detection of severe violations that are computationally challenging for symbolic methods alone. Given a set of inputs exhibiting high k-unfairness, we introduce a novel explanation method to generate interpretable, decision-tree-style artifacts. Our experiments demonstrate that HyFair outperforms state-of-the-art fairness verification and local explanation methods.",
      "tldr_zh": "这项研究提出了 Discrimination Clustering（歧视聚类）的概念，作为 Individual Fairness（个体公平性）违背情况的泛化，旨在揭示算法决策中系统性的歧视模式。与仅关注单对反事实差异的传统方法不同，该研究致力于识别输入空间中那些仅因受保护属性的小幅扰动而产生多个显著不同结果簇的区域，从而暴露逃避了成对公平性检查的算法偏见。为此，研究者开发了名为 HyFair 的混合技术，结合了基于 SMT 和 MILP 求解器的形式化符号分析与随机搜索，既能提供形式化公平性保证，也能检测到符号方法难以处理的严重违规行为。针对表现出高 k-unfairness 的输入集，研究还引入了一种新型解释方法，通过生成决策树风格的人工制品来提升模型的可解释性。实验结果证明，HyFair 在公平性验证和局部解释效能方面均优于现有的先进方法。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "In 40th IEEE/ACM International Conference on Automated Software Engineering (ASE 2025)",
      "pdf_url": "https://arxiv.org/pdf/2512.23769v1",
      "published_date": "2025-12-29 06:44:07 UTC",
      "updated_date": "2025-12-29 06:44:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:24.036209+00:00"
    },
    {
      "arxiv_id": "2512.23236v3",
      "title": "KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta",
      "title_zh": "KernelEvolve：面向 Meta 异构 AI 加速器的大规模智能体内核编程",
      "authors": [
        "Gang Liao",
        "Hongsen Qin",
        "Ying Wang",
        "Alicia Golden",
        "Michael Kuchnik",
        "Yavuz Yetim",
        "Jia Jiunn Ang",
        "Chunli Fu",
        "Yihan He",
        "Samuel Hsia",
        "Zewei Jiang",
        "Dianshi Li",
        "Uladzimir Pashkevich",
        "Varna Puvvada",
        "Feng Shi",
        "Matt Steiner",
        "Ruichao Xiao",
        "Nathan Yan",
        "Xiayu Yu",
        "Zhou Fang",
        "Roman Levenstein",
        "Kunming Ho",
        "Haishan Zhu",
        "Alec Hammond",
        "Richard Li",
        "Ajit Mathews",
        "Kaustubh Gondkar",
        "Abdul Zainul-Abedin",
        "Ketan Singh",
        "Hongtao Yu",
        "Wenyuan Chi",
        "Barney Huang",
        "Sean Zhang",
        "Noah Weller",
        "Zach Marine",
        "Wyatt Cook",
        "Carole-Jean Wu",
        "Gaoxiang Liu"
      ],
      "abstract": "Making deep learning recommendation model (DLRM) training and inference fast and efficient is important. However, this presents three key system challenges - model architecture diversity, kernel primitive diversity, and hardware generation and architecture heterogeneity. This paper presents KernelEvolve-an agentic kernel coding framework-to tackle heterogeneity at-scale for DLRM. KernelEvolve is designed to take kernel specifications as input and automate the process of kernel generation and optimization for recommendation model across heterogeneous hardware architectures. KernelEvolve does so by operating at multiple programming abstractions, from Triton and CuTe DSL to low-level hardware agnostic languages, spanning the full hardware-software optimization stack. The kernel optimization process is described as graph-based search with selection policy, universal operator, fitness function, and termination rule, dynamically adapts to runtime execution context through retrieval-augmented prompt synthesis. We designed, implemented, and deployed KernelEvolve to optimize a wide variety of production recommendation models across generations of NVIDIA and AMD GPUs, as well as Meta's AI accelerators. We validate KernelEvolve on the publicly-available KernelBench suite, achieving 100% pass rate on all 250 problems across three difficulty levels, and 160 PyTorch ATen operators across three heterogeneous hardware platforms, demonstrating 100% correctness. KernelEvolve reduces development time from weeks to hours and achieves substantial performance improvements over PyTorch baselines across diverse production use cases and for heterogeneous AI systems at-scale. Beyond performance efficiency improvements, KernelEvolve significantly mitigates the programmability barrier for new AI hardware by enabling automated kernel generation for in-house developed AI hardware.",
      "tldr_zh": "该研究介绍了 KernelEvolve，一个旨在解决深度学习推荐模型 (DLRM) 在异构 AI 加速器上训练与推理效率挑战的智能体内核编码框架。该框架通过在 Triton、CuTe DSL 及底层硬件无关语言等多个编程抽象层操作，实现了内核生成与优化的自动化，并利用基于图的搜索策略和检索增强提示合成 (Retrieval-Augmented Prompt Synthesis) 动态适应运行时执行上下文。KernelEvolve 已在 Meta 的生产环境大规模部署，成功优化了跨多代 NVIDIA、AMD GPU 及 Meta 自研 AI 加速器的多种生产模型。实验结果显示，该框架在 KernelBench 套件和 PyTorch ATen 算子上均达到了 100% 的正确率，将内核开发时间从数周缩短至数小时。此外，KernelEvolve 在显著提升异构 AI 系统性能的同时，有效降低了新硬件的编程门槛，为自动化内核开发提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.MA",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23236v3",
      "published_date": "2025-12-29 06:31:55 UTC",
      "updated_date": "2026-01-16 22:31:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:31.416703+00:00"
    },
    {
      "arxiv_id": "2512.23234v2",
      "title": "Physics-Inspired Modeling and Content Adaptive Routing in an Infrared Gas Leak Detection Network",
      "title_zh": "红外气体泄漏检测网络中的物理启发建模与内容自适应路由",
      "authors": [
        "Dongsheng Li",
        "Tianli Ma",
        "Siling Wang",
        "Beibei Duan",
        "Song Gao"
      ],
      "abstract": "Detecting infrared gas leaks is critical for environmental monitoring and industrial safety, yet remains difficult because plumes are faint, small, semitransparent, and have weak, diffuse boundaries. We present physics-edge hybrid gas dynamic routing network (PEG-DRNet). First, we introduce the Gas Block, a diffusion-convection unit modeling gas transport: a local branch captures short-range variations, while a large-kernel branch captures long-range propagation. An edge-gated learnable fusion module balances local detail and global context, strengthening weak-contrast plume and contour cues. Second, we propose the adaptive gradient and phase edge operator (AGPEO), computing reliable edge priors from multi-directional gradients and phase-consistent responses. These are transformed by a multi-scale edge perception module (MSEPM) into hierarchical edge features that reinforce boundaries. Finally, the content-adaptive sparse routing path aggregation network (CASR-PAN), with adaptive information modulation modules for fusion and self, selectively propagates informative features across scales based on edge and content cues, improving cross-scale discriminability while reducing redundancy. Experiments on the IIG dataset show that PEG-DRNet achieves an overall AP of 29.8\\%, an AP$_{50}$ of 84.3\\%, and a small-object AP of 25.3\\%, surpassing the RT-DETR-R18 baseline by 3.0\\%, 6.5\\%, and 5.3\\%, respectively, while requiring only 43.7 Gflops and 14.9 M parameters. The proposed PEG-DRNet achieves superior overall performance with the best balance of accuracy and computational efficiency, outperforming existing CNN and Transformer detectors in AP and AP$_{50}$ on the IIG and LangGas dataset.",
      "tldr_zh": "该研究提出了 PEG-DRNet，一种物理驱动的边缘混合气体动态路由网络，旨在解决红外气体泄漏检测中烟羽因微弱、细小、半透明且边界模糊而难以识别的难题。框架核心引入了 Gas Block 扩散对流单元，通过局部分支和大核分支分别捕捉短程和远程的气体传播特性，并利用边缘门控融合模块强化弱对比度线索。研究还设计了自适应梯度与相位边缘算子 (AGPEO) 及多尺度边缘感知模块 (MSEPM)，用于计算可靠的边缘先验并生成层级边缘特征以强化边界。此外，通过内容自适应稀疏路由路径聚合网络 (CASR-PAN)，模型能根据内容线索跨尺度选择性传播信息，在提升判别力的同时降低了计算冗余。实验表明，PEG-DRNet 在 IIG 数据集上的 AP 达到 29.8%，AP$_{50}$ 达到 84.3%，性能显著优于 RT-DETR-R18 等基准模型。该方案在 IIG 和 LangGas 数据集上均表现出优于现有 CNN 和 Transformer 检测器的性能，以仅 14.9 M 的参数量实现了高精度与低计算开销的最佳平衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23234v2",
      "published_date": "2025-12-29 06:28:20 UTC",
      "updated_date": "2026-01-12 11:42:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:36.148526+00:00"
    },
    {
      "arxiv_id": "2512.23227v1",
      "title": "Anomaly Detection by Effectively Leveraging Synthetic Images",
      "title_zh": "基于有效利用合成图像的异常检测",
      "authors": [
        "Sungho Kang",
        "Hyunkyu Park",
        "Yeonho Lee",
        "Hanbyul Lee",
        "Mijoo Jeong",
        "YeongHyeon Park",
        "Injae Lee",
        "Juneho Yi"
      ],
      "abstract": "Anomaly detection plays a vital role in industrial manufacturing. Due to the scarcity of real defect images, unsupervised approaches that rely solely on normal images have been extensively studied. Recently, diffusion-based generative models brought attention to training data synthesis as an alternative solution. In this work, we focus on a strategy to effectively leverage synthetic images to maximize the anomaly detection performance. Previous synthesis strategies are broadly categorized into two groups, presenting a clear trade-off. Rule-based synthesis, such as injecting noise or pasting patches, is cost-effective but often fails to produce realistic defect images. On the other hand, generative model-based synthesis can create high-quality defect images but requires substantial cost. To address this problem, we propose a novel framework that leverages a pre-trained text-guided image-to-image translation model and image retrieval model to efficiently generate synthetic defect images. Specifically, the image retrieval model assesses the similarity of the generated images to real normal images and filters out irrelevant outputs, thereby enhancing the quality and relevance of the generated defect images. To effectively leverage synthetic images, we also introduce a two stage training strategy. In this strategy, the model is first pre-trained on a large volume of images from rule-based synthesis and then fine-tuned on a smaller set of high-quality images. This method significantly reduces the cost for data collection while improving the anomaly detection performance. Experiments on the MVTec AD dataset demonstrate the effectiveness of our approach.",
      "tldr_zh": "该研究探讨了工业制造中的异常检测(Anomaly Detection)问题，针对真实缺陷图像稀缺的挑战，提出了一种有效利用合成图像来提升模型性能的策略。研究团队提出了一个新颖框架，利用预训练的文本引导图像到图像转换模型(text-guided image-to-image translation model)和图像检索模型(image retrieval model)来高效生成缺陷图像。该框架通过图像检索模型评估生成图像与真实正常图像的相似性并过滤无关输出，显著增强了生成缺陷图像的质量和相关性。此外，研究还引入了两阶段训练策略(two stage training strategy)，即先在大量规则合成数据上预训练，再在少量高质量合成图像上进行微调。这种方法在显著降低数据采集成本的同时，有效提升了异常检测的准确率。在MVTec AD数据集上的实验结果证明了该方法的有效性，为解决工业视觉检测中的样本稀缺问题提供了新颖且高效的路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23227v1",
      "published_date": "2025-12-29 06:06:30 UTC",
      "updated_date": "2025-12-29 06:06:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:51.447502+00:00"
    },
    {
      "arxiv_id": "2512.23221v1",
      "title": "Holi-DETR: Holistic Fashion Item Detection Leveraging Contextual Information",
      "title_zh": "Holi-DETR：利用上下文信息的整体时尚单品检测",
      "authors": [
        "Youngchae Kwon",
        "Jinyoung Choi",
        "Injung Kim"
      ],
      "abstract": "Fashion item detection is challenging due to the ambiguities introduced by the highly diverse appearances of fashion items and the similarities among item subcategories. To address this challenge, we propose a novel Holistic Detection Transformer (Holi-DETR) that detects fashion items in outfit images holistically, by leveraging contextual information. Fashion items often have meaningful relationships as they are combined to create specific styles. Unlike conventional detectors that detect each item independently, Holi-DETR detects multiple items while reducing ambiguities by leveraging three distinct types of contextual information: (1) the co-occurrence relationship between fashion items, (2) the relative position and size based on inter-item spatial arrangements, and (3) the spatial relationships between items and human body key-points. %Holi-DETR explicitly incorporates three types of contextual information: (1) the co-occurrence probability between fashion items, (2) the relative position and size based on inter-item spatial arrangements, and (3) the spatial relationships between items and human body key-points. To this end, we propose a novel architecture that integrates these three types of heterogeneous contextual information into the Detection Transformer (DETR) and its subsequent models. In experiments, the proposed methods improved the performance of the vanilla DETR and the more recently developed Co-DETR by 3.6 percent points (pp) and 1.1 pp, respectively, in terms of average precision (AP).",
      "tldr_zh": "该研究提出了 Holi-DETR (Holistic Detection Transformer)，旨在通过利用多维度的上下文信息解决时尚单品检测中因外观多样性和类别相似性导致的歧义问题。与传统独立检测单品的方法不同，Holi-DETR 采用整体检测策略，显式整合了三类关键背景信息：单品间的共现关系 (co-occurrence relationship)、基于空间排列的相对位置与尺寸、以及单品与人体关键点 (human body key-points) 之间的空间联系。这种新颖的架构将异构上下文信息无缝集成到 Detection Transformer (DETR) 及其后续变体中。实验结果表明，该方法在平均精度 (AP) 指标上显著优于基准模型，使原始 DETR 提升了 3.6 个百分点，Co-DETR 提升了 1.1 个百分点。该研究有效证明了利用结构化关系信息增强复杂时尚场景识别能力的价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23221v1",
      "published_date": "2025-12-29 05:55:01 UTC",
      "updated_date": "2025-12-29 05:55:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:35:09.446555+00:00"
    },
    {
      "arxiv_id": "2601.02398v1",
      "title": "AI-Native Integrated Sensing and Communications for Self-Organizing Wireless Networks: Architectures, Learning Paradigms, and System-Level Design",
      "title_zh": "面向自组织无线网络的AI原生通感一体化：架构、学习范式与系统级设计",
      "authors": [
        "S. Zhang",
        "M. Feizarefi",
        "A. F. Mirzaei"
      ],
      "abstract": "Integrated Sensing and Communications (ISAC) is emerging as a foundational paradigm for next-generation wireless networks, enabling communication infrastructures to simultaneously support data transmission and environment sensing. By tightly coupling radio sensing with communication functions, ISAC unlocks new capabilities for situational awareness, localization, tracking, and network adaptation. At the same time, the increasing scale, heterogeneity, and dynamics of future wireless systems demand self-organizing network intelligence capable of autonomously managing resources, topology, and services. Artificial intelligence (AI), particularly learning-driven and data-centric methods, has become a key enabler for realizing this vision. This survey provides a comprehensive and system-level review of AI-native ISAC-enabled self-organizing wireless networks. We develop a unified taxonomy that spans: (i) ISAC signal models and sensing modalities, (ii) network state abstraction and perception from sensing-aware radio data, (iii) learning-driven self-organization mechanisms for resource allocation, topology control, and mobility management, and (iv) cross-layer architectures integrating sensing, communication, and network intelligence. We further examine emerging learning paradigms, including deep reinforcement learning, graph-based learning, multi-agent coordination, and federated intelligence that enable autonomous adaptation under uncertainty, mobility, and partial observability. Practical considerations such as sensing-communication trade-offs, scalability, latency, reliability, and security are discussed alongside representative evaluation methodologies and performance metrics. Finally, we identify key open challenges and future research directions toward deployable, trustworthy, and scalable AI-native ISAC systems for 6G and beyond.",
      "tldr_zh": "该综述系统地审视了面向自组织无线网络的AI-Native集成感知与通信(ISAC)技术，旨在通过感知与通信功能的深度耦合实现环境态势感知与网络自主适配。研究建立了一个涵盖信号模型、网络状态抽象、自组织机制及跨层架构的统一分类体系，并深入探讨了深度强化学习(Deep Reinforcement Learning)、图学习(Graph-based Learning)和联邦智能(Federated Intelligence)等新兴范式在应对网络动态性与不确定性方面的应用。文中详细分析了感知与通信的权衡(Sensing-communication trade-offs)、可扩展性、时延及安全性等系统级设计考量。通过总结性能指标与评估方法，该研究识别了构建可部署、可信赖的AI-Native ISAC系统所面临的关键挑战。这一成果为6G及未来移动通信网络中感知、通信与网络智能的深度融合提供了全面的技术路径与未来研究方向。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.02398v1",
      "published_date": "2025-12-29 05:45:57 UTC",
      "updated_date": "2025-12-29 05:45:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:35:00.712234+00:00"
    },
    {
      "arxiv_id": "2512.23217v1",
      "title": "TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI",
      "title_zh": "TCEval：利用热舒适度评估人工智能的认知与感知能力",
      "authors": [
        "Jingming Li"
      ],
      "abstract": "A critical gap exists in LLM task-specific benchmarks. Thermal comfort, a sophisticated interplay of environmental factors and personal perceptions involving sensory integration and adaptive decision-making, serves as an ideal paradigm for evaluating real-world cognitive capabilities of AI systems. To address this, we propose TCEval, the first evaluation framework that assesses three core cognitive capacities of AI, cross-modal reasoning, causal association, and adaptive decision-making, by leveraging thermal comfort scenarios and large language model (LLM) agents. The methodology involves initializing LLM agents with virtual personality attributes, guiding them to generate clothing insulation selections and thermal comfort feedback, and validating outputs against the ASHRAE Global Database and Chinese Thermal Comfort Database. Experiments on four LLMs show that while agent feedback has limited exact alignment with humans, directional consistency improves significantly with a 1 PMV tolerance. Statistical tests reveal that LLM-generated PMV distributions diverge markedly from human data, and agents perform near-randomly in discrete thermal comfort classification. These results confirm the feasibility of TCEval as an ecologically valid Cognitive Turing Test for AI, demonstrating that current LLMs possess foundational cross-modal reasoning ability but lack precise causal understanding of the nonlinear relationships between variables in thermal comfort. TCEval complements traditional benchmarks, shifting AI evaluation focus from abstract task proficiency to embodied, context-aware perception and decision-making, offering valuable insights for advancing AI in human-centric applications like smart buildings.",
      "tldr_zh": "该研究提出了TCEval，这是首个利用热舒适度(Thermal Comfort)场景评估人工智能核心认知能力的评价框架，旨在弥补大语言模型(LLMs)在特定任务基准测试中的缺口。该框架通过LLM agents模拟虚拟人格，重点评估其跨模态推理(Cross-modal reasoning)、因果关联(Causal association)和自适应决策(Adaptive decision-making)三项核心能力。实验引导智能体生成衣着绝缘选择和热舒适反馈，并将其输出与ASHRAE全球数据库及中国热舒适数据库进行比对验证。研究发现，虽然智能体反馈与人类的精确对齐度有限，但在1 PMV容差下其方向一致性显著提升，且LLM生成的分布与人类真实数据存在显著差异。结果证实了TCEval作为一种生态有效的认知图灵测试(Cognitive Turing Test)的可行性，揭示了当前LLMs虽具备基础跨模态推理能力，但仍缺乏对热舒适变量间复杂非线性关系的精确因果理解。该项工作推动了AI评估从抽象任务向具身化、情境感知的决策转变，为智能建筑等以人为中心的应用提供了重要见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23217v1",
      "published_date": "2025-12-29 05:41:25 UTC",
      "updated_date": "2025-12-29 05:41:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:34:59.474582+00:00"
    },
    {
      "arxiv_id": "2512.23213v1",
      "title": "Scoring, Reasoning, and Selecting the Best! Ensembling Large Language Models via a Peer-Review Process",
      "title_zh": "评分、推理与择优：基于同行评审的大语言模型集成",
      "authors": [
        "Zhijun Chen",
        "Zeyu Ji",
        "Qianren Mao",
        "Junhang Cheng",
        "Bangjie Qin",
        "Hao Wu",
        "Zhuoran Li",
        "Jingzheng Li",
        "Kai Sun",
        "Zizhe Wang",
        "Yikun Ban",
        "Zhu Sun",
        "Xiangyang Ji",
        "Hailong Sun"
      ],
      "abstract": "We propose LLM-PeerReview, an unsupervised LLM Ensemble method that selects the most ideal response from multiple LLM-generated candidates for each query, harnessing the collective wisdom of multiple models with diverse strengths. LLM-PeerReview is built on a novel, peer-review-inspired framework that offers a clear and interpretable mechanism, while remaining fully unsupervised for flexible adaptability and generalization. Specifically, it operates in three stages: For scoring, we use the emerging LLM-as-a-Judge technique to evaluate each response by reusing multiple LLMs at hand; For reasoning, we can apply a principled graphical model-based truth inference algorithm or a straightforward averaging strategy to aggregate multiple scores to produce a final score for each response; Finally, the highest-scoring response is selected as the best ensemble output. LLM-PeerReview is conceptually simple and empirically powerful. The two variants of the proposed approach obtain strong results across four datasets, including outperforming the recent advanced model Smoothie-Global by 6.9% and 7.3% points, respectively.",
      "tldr_zh": "该研究提出了 LLM-PeerReview，一种无监督的 LLM Ensemble 方法，通过结合具有不同优势的多模型集体智慧，为每个查询从多个候选响应中选择最理想的输出。该框架借鉴了 Peer-Review 机制，提供了一种清晰且可解释的架构，同时保持完全无监督以实现灵活的适配与泛化。其运行过程包含三个阶段：在 Scoring 阶段利用 LLM-as-a-Judge 技术评估候选响应，在 Reasoning 阶段应用基于图形模型的 Truth Inference 算法或平均策略聚合分数，最后在 Selecting 阶段输出最高分响应。LLM-PeerReview 概念简单且实证效果强大，在四个数据集上的实验表明，其两种变体分别比先进模型 Smoothie-Global 的准确率高出 6.9% 和 7.3%。该方法为提升 Large Language Models 的生成质量提供了一种高效且稳健的集成方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23213v1",
      "published_date": "2025-12-29 05:25:49 UTC",
      "updated_date": "2025-12-29 05:25:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:35:03.749300+00:00"
    },
    {
      "arxiv_id": "2512.23208v1",
      "title": "Exploring Syn-to-Real Domain Adaptation for Military Target Detection",
      "title_zh": "军事目标检测中从仿真到真实的领域自适应探究",
      "authors": [
        "Jongoh Jeong",
        "Youngjin Oh",
        "Gyeongrae Nam",
        "Jeongeun Lee",
        "Kuk-Jin Yoon"
      ],
      "abstract": "Object detection is one of the key target tasks of interest in the context of civil and military applications. In particular, the real-world deployment of target detection methods is pivotal in the decision-making process during military command and reconnaissance. However, current domain adaptive object detection algorithms consider adapting one domain to another similar one only within the scope of natural or autonomous driving scenes. Since military domains often deal with a mixed variety of environments, detecting objects from multiple varying target domains poses a greater challenge. Several studies for armored military target detection have made use of synthetic aperture radar (SAR) data due to its robustness to all weather, long range, and high-resolution characteristics. Nevertheless, the costs of SAR data acquisition and processing are still much higher than those of the conventional RGB camera, which is a more affordable alternative with significantly lower data processing time. Furthermore, the lack of military target detection datasets limits the use of such a low-cost approach. To mitigate these issues, we propose to generate RGB-based synthetic data using a photorealistic visual tool, Unreal Engine, for military target detection in a cross-domain setting. To this end, we conducted synthetic-to-real transfer experiments by training our synthetic dataset and validating on our web-collected real military target datasets. We benchmark the state-of-the-art domain adaptation methods distinguished by the degree of supervision on our proposed train-val dataset pair, and find that current methods using minimal hints on the image (e.g., object class) achieve a substantial improvement over unsupervised or semi-supervised DA methods. From these observations, we recognize the current challenges that remain to be overcome.",
      "tldr_zh": "该研究探讨了军事目标检测中的虚实域迁移(Syn-to-Real Domain Adaptation)问题，旨在解决军事领域环境复杂且缺乏低成本RGB数据集的挑战。作者提出利用Unreal Engine生成高保真的合成数据，并构建了用于跨域实验的训练与验证数据集。通过在合成数据上训练并在网络采集的真实军事目标数据集上进行验证，该研究系统评估了多种最先进的域适应(Domain Adaptation)方法。实验结果表明，在图像中利用物体类别等极少量提示的方法，其性能显著优于完全无监督或半监督的DA方法。该项工作揭示了军事场景下跨域检测面临的现有挑战，并为利用低成本视觉传感器实现高效指挥与侦察提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23208v1",
      "published_date": "2025-12-29 05:05:41 UTC",
      "updated_date": "2025-12-29 05:05:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:35:22.619862+00:00"
    },
    {
      "arxiv_id": "2512.23206v1",
      "title": "Not too long do read: Evaluating LLM-generated extreme scientific summaries",
      "title_zh": "极简科学摘要：评估大语言模型生成的极致科学摘要",
      "authors": [
        "Zhuoqi Lyu",
        "Qing Ke"
      ],
      "abstract": "High-quality scientific extreme summary (TLDR) facilitates effective science communication. How do large language models (LLMs) perform in generating them? How are LLM-generated summaries different from those written by human experts? However, the lack of a comprehensive, high-quality scientific TLDR dataset hinders both the development and evaluation of LLMs' summarization ability. To address these, we propose a novel dataset, BiomedTLDR, containing a large sample of researcher-authored summaries from scientific papers, which leverages the common practice of including authors' comments alongside bibliography items. We then test popular open-weight LLMs for generating TLDRs based on abstracts. Our analysis reveals that, although some of them successfully produce humanoid summaries, LLMs generally exhibit a greater affinity for the original text's lexical choices and rhetorical structures, hence tend to be more extractive rather than abstractive in general, compared to humans. Our code and datasets are available at https://github.com/netknowledge/LLM_summarization (Lyu and Ke, 2025).",
      "tldr_zh": "该研究探讨了高质量科学极简摘要(TLDR)在科学传播中的重要性，并针对高质量科研摘要数据集匮乏的问题提出了BiomedTLDR数据集。该数据集通过收集科研人员为参考文献撰写的注释，构建了一个包含大量真实作者摘要的资源库。研究团队基于该数据集测试了多种主流的开源大语言模型(open-weight LLMs)，并对比了模型生成摘要与人类专家摘要的差异。实验分析表明，虽然部分大语言模型(LLMs)能够生成具有可读性的摘要，但在词汇选择和修辞结构上对原文的依赖程度更高。相比于人类专家的归纳式(abstractive)写作风格，模型生成的摘要在整体上表现出更强的抽取式(extractive)特征。该研究为理解和优化大语言模型在科学文献自动摘要领域的表现提供了重要的基准数据与洞察。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23206v1",
      "published_date": "2025-12-29 05:03:02 UTC",
      "updated_date": "2025-12-29 05:03:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:35:17.037450+00:00"
    },
    {
      "arxiv_id": "2512.23767v1",
      "title": "Enabling Physical AI at the Edge: Hardware-Accelerated Recovery of System Dynamics",
      "title_zh": "实现边缘侧物理 AI：硬件加速的系统动力学重构",
      "authors": [
        "Bin Xu",
        "Ayan Banerjee",
        "Sandeep Gupta"
      ],
      "abstract": "Physical AI at the edge -- enabling autonomous systems to understand and predict real-world dynamics in real time -- requires hardware-efficient learning and inference. Model recovery (MR), which identifies governing equations from sensor data, is a key primitive for safe and explainable monitoring in mission-critical autonomous systems operating under strict latency, compute, and power constraints. However, state-of-the-art MR methods (e.g., EMILY and PINN+SR) rely on Neural ODE formulations that require iterative solvers and are difficult to accelerate efficiently on edge hardware. We present \\textbf{MERINDA} (Model Recovery in Reconfigurable Dynamic Architecture), an FPGA-accelerated MR framework designed to make physical AI practical on resource-constrained devices. MERINDA replaces expensive Neural ODE components with a hardware-friendly formulation that combines (i) GRU-based discretized dynamics, (ii) dense inverse-ODE layers, (iii) sparsity-driven dropout, and (iv) lightweight ODE solvers. The resulting computation is structured for streaming parallelism, enabling critical kernels to be fully parallelized on the FPGA. Across four benchmark nonlinear dynamical systems, MERINDA delivers substantial gains over GPU implementations: \\textbf{114$\\times$ lower energy} (434~J vs.\\ 49{,}375~J), \\textbf{28$\\times$ smaller memory footprint} (214~MB vs.\\ 6{,}118~MB), and \\textbf{1.68$\\times$ faster training}, while matching state-of-the-art model-recovery accuracy. These results demonstrate that MERINDA can bring accurate, explainable MR to the edge for real-time monitoring of autonomous systems.",
      "tldr_zh": "该研究针对物理AI (Physical AI) 在边缘端实时理解系统动态特性的需求，提出了 MERINDA 框架，旨在解决现有模型恢复 (Model Recovery) 方法因依赖 Neural ODE 而难以在边缘硬件高效加速的难题。作为一个 FPGA 加速的 MR 框架，MERINDA 采用了硬件友好的公式，整合了基于 GRU 的离散化动力学、稠密逆 ODE 层 (dense inverse-ODE layers)、稀疏驱动丢弃 (sparsity-driven dropout) 以及轻量级 ODE 求解器。其计算结构专为流式并行 (streaming parallelism) 设计，确保关键内核在 FPGA 上实现全并行化运行。实验表明，在四个非线性动力系统基准测试中，MERINDA 在保持顶尖精度的同时，能耗比 GPU 实现降低了 114 倍，内存占用减少了 28 倍，且训练速度提升了 1.68 倍。该成果证明了 MERINDA 能够为资源受限的边缘设备提供准确、可解释的实时自主系统监控方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "2025 59th Asilomar Conference on Signals, Systems, and Computers",
      "pdf_url": "https://arxiv.org/pdf/2512.23767v1",
      "published_date": "2025-12-29 04:51:51 UTC",
      "updated_date": "2025-12-29 04:51:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:35:33.528697+00:00"
    },
    {
      "arxiv_id": "2512.23196v1",
      "title": "ForCM: Forest Cover Mapping from Multispectral Sentinel-2 Image by Integrating Deep Learning with Object-Based Image Analysis",
      "title_zh": "ForCM：结合深度学习与面向对象图像分析的多光谱 Sentinel-2 影像森林覆盖制图",
      "authors": [
        "Maisha Haque",
        "Israt Jahan Ayshi",
        "Sadaf M. Anis",
        "Nahian Tasnim",
        "Mithila Moontaha",
        "Md. Sabbir Ahmed",
        "Muhammad Iqbal Hossain",
        "Mohammad Zavid Parvez",
        "Subrata Chakraborty",
        "Biswajeet Pradhan",
        "Biswajit Banik"
      ],
      "abstract": "This research proposes \"ForCM\", a novel approach to forest cover mapping that combines Object-Based Image Analysis (OBIA) with Deep Learning (DL) using multispectral Sentinel-2 imagery. The study explores several DL models, including UNet, UNet++, ResUNet, AttentionUNet, and ResNet50-Segnet, applied to high-resolution Sentinel-2 Level 2A satellite images of the Amazon Rainforest. The datasets comprise three collections: two sets of three-band imagery and one set of four-band imagery. After evaluation, the most effective DL models are individually integrated with the OBIA technique to enhance mapping accuracy. The originality of this work lies in evaluating different deep learning models combined with OBIA and comparing them with traditional OBIA methods. The results show that the proposed ForCM method improves forest cover mapping, achieving overall accuracies of 94.54 percent with ResUNet-OBIA and 95.64 percent with AttentionUNet-OBIA, compared to 92.91 percent using traditional OBIA. This research also demonstrates the potential of free and user-friendly tools such as QGIS for accurate mapping within their limitations, supporting global environmental monitoring and conservation efforts.",
      "tldr_zh": "该研究提出了 ForCM，一种通过将面向对象影像分析 (Object-Based Image Analysis, OBIA) 与深度学习 (Deep Learning, DL) 相结合的森林覆盖制图新方法。该方法利用多光谱 Sentinel-2 卫星影像，在亚马逊雨林数据集上评估了包括 UNet、UNet++、ResUNet、AttentionUNet 和 ResNet50-Segnet 在内的多种深度学习模型。研究的核心创新在于将性能最优的深度学习模型与 OBIA 技术集成，并将其与传统 OBIA 方法进行对比。实验结果显示，ForCM 显著提升了制图精度，其中 AttentionUNet-OBIA 的总体准确率达到 95.64%，ResUNet-OBIA 达到 94.54%，均优于传统 OBIA 的 92.91%。该研究证明了集成深度学习与 OBIA 在处理高分辨率卫星影像时的有效性，并展示了利用 QGIS 等开源工具进行精确环境监测的潜力，为全球生态保护提供了技术支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 7 figures. Accepted for presentation at the Australasian Data Science and Machine Learning Conference (AusDM 2024)",
      "pdf_url": "https://arxiv.org/pdf/2512.23196v1",
      "published_date": "2025-12-29 04:23:50 UTC",
      "updated_date": "2025-12-29 04:23:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:35:50.275923+00:00"
    },
    {
      "arxiv_id": "2512.23185v1",
      "title": "EIR: Enhanced Image Representations for Medical Report Generation",
      "title_zh": "EIR：面向医疗报告生成的增强型图像表征",
      "authors": [
        "Qiang Sun",
        "Zongcheng Ji",
        "Yinlong Xiao",
        "Peng Chang",
        "Jun Yu"
      ],
      "abstract": "Generating medical reports from chest X-ray images is a critical and time-consuming task for radiologists, especially in emergencies. To alleviate the stress on radiologists and reduce the risk of misdiagnosis, numerous research efforts have been dedicated to automatic medical report generation in recent years. Most recent studies have developed methods that represent images by utilizing various medical metadata, such as the clinical document history of the current patient and the medical graphs constructed from retrieved reports of other similar patients. However, all existing methods integrate additional metadata representations with visual representations through a simple \"Add and LayerNorm\" operation, which suffers from the information asymmetry problem due to the distinct distributions between them. In addition, chest X-ray images are usually represented using pre-trained models based on natural domain images, which exhibit an obvious domain gap between general and medical domain images. To this end, we propose a novel approach called Enhanced Image Representations (EIR) for generating accurate chest X-ray reports. We utilize cross-modal transformers to fuse metadata representations with image representations, thereby effectively addressing the information asymmetry problem between them, and we leverage medical domain pre-trained models to encode medical images, effectively bridging the domain gap for image representation. Experimental results on the widely used MIMIC and Open-I datasets demonstrate the effectiveness of our proposed method.",
      "tldr_zh": "该研究提出了名为Enhanced Image Representations (EIR) 的新方法，旨在通过增强图像表示来提高胸部X射线报告生成的准确性。针对现有研究在融合医学元数据（metadata）与图像表示时存在的“信息不对称”问题，以及使用通用领域预训练模型导致的“领域差距”，该方法引入了Cross-modal Transformers以实现更深度的跨模态特征融合。同时，EIR采用医学领域预训练模型进行图像编码，有效地弥合了自然图像与医学图像之间的特征分布差异。在主流的MIMIC和Open-I数据集上的实验结果充分验证了该方法的有效性，证明其能有效提升医疗报告的生成质量并降低误诊风险。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23185v1",
      "published_date": "2025-12-29 03:51:16 UTC",
      "updated_date": "2025-12-29 03:51:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:35:28.230430+00:00"
    },
    {
      "arxiv_id": "2512.23184v1",
      "title": "From Model Choice to Model Belief: Establishing a New Measure for LLM-Based Research",
      "title_zh": "从模型选择到模型信念：构建基于大语言模型研究的新型度量指标",
      "authors": [
        "Hongshen Sun",
        "Juanjuan Zhang"
      ],
      "abstract": "Large language models (LLMs) are increasingly used to simulate human behavior, but common practices to use LLM-generated data are inefficient. Treating an LLM's output (\"model choice\") as a single data point underutilizes the information inherent to the probabilistic nature of LLMs. This paper introduces and formalizes \"model belief,\" a measure derived from an LLM's token-level probabilities that captures the model's belief distribution over choice alternatives in a single generation run. The authors prove that model belief is asymptotically equivalent to the mean of model choices (a non-trivial property) but forms a more statistically efficient estimator, with lower variance and a faster convergence rate. Analogous properties are shown to hold for smooth functions of model belief and model choice often used in downstream applications. The authors demonstrate the performance of model belief through a demand estimation study, where an LLM simulates consumer responses to different prices. In practical settings with limited numbers of runs, model belief explains and predicts ground-truth model choice better than model choice itself, and reduces the computation needed to reach sufficiently accurate estimates by roughly a factor of 20. The findings support using model belief as the default measure to extract more information from LLM-generated data.",
      "tldr_zh": "本研究引入并形式化了 model belief 这一新指标，旨在解决大型语言模型(LLMs)在模拟人类行为时，传统的 model choice 输出数据利用率低且不高效的问题。与仅将单次生成结果视为数据点不同，model belief 从 LLM 的 token-level probabilities 中推导出来，能够在单次运行中捕捉模型对不同选择项的信念分布。作者在数学上证明了 model belief 与 model choices 的均值具有渐近等价性，但作为估计量在统计上更有效，具有更低的方差(lower variance)和更快的收敛速度(faster convergence rate)。通过一项模拟消费者对价格反应的需求估计研究，实验结果表明在运行次数有限的情况下，model belief 比 model choice 能更好地解释和预测真实模型选择。此外，该方法将达到足够准确度所需的计算量减少了约20倍。这些发现支持将 model belief 作为从 LLM 生成数据中提取信息的默认衡量标准，从而显著提升基于 LLM 的研究效率。",
      "categories": [
        "cs.AI",
        "econ.EM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23184v1",
      "published_date": "2025-12-29 03:50:40 UTC",
      "updated_date": "2025-12-29 03:50:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:30.717518+00:00"
    },
    {
      "arxiv_id": "2512.23173v1",
      "title": "EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion",
      "title_zh": "EquaCode：基于方程求解与代码补全的大语言模型多策略越狱方法",
      "authors": [
        "Zhen Liang",
        "Hai Huang",
        "Zhengkui Chen"
      ],
      "abstract": "Large language models (LLMs), such as ChatGPT, have achieved remarkable success across a wide range of fields. However, their trustworthiness remains a significant concern, as they are still susceptible to jailbreak attacks aimed at eliciting inappropriate or harmful responses. However, existing jailbreak attacks mainly operate at the natural language level and rely on a single attack strategy, limiting their effectiveness in comprehensively assessing LLM robustness. In this paper, we propose Equacode, a novel multi-strategy jailbreak approach for large language models via equation-solving and code completion. This approach transforms malicious intent into a mathematical problem and then requires the LLM to solve it using code, leveraging the complexity of cross-domain tasks to divert the model's focus toward task completion rather than safety constraints. Experimental results show that Equacode achieves an average success rate of 91.19% on the GPT series and 98.65% across 3 state-of-the-art LLMs, all with only a single query. Further, ablation experiments demonstrate that EquaCode outperforms either the mathematical equation module or the code module alone. This suggests a strong synergistic effect, thereby demonstrating that multi-strategy approach yields results greater than the sum of its parts.",
      "tldr_zh": "该研究提出了 EquaCode，一种针对 Large Language Models (LLMs) 的新型多策略 Jailbreak 攻击方法，通过结合 Equation Solving 和 Code Completion 来评估模型的鲁棒性。EquaCode 将恶意意图转化为复杂的数学问题，并要求 LLM 使用代码进行求解，利用跨领域任务的复杂性将模型的注意力从安全性约束转向任务执行。实验结果显示，EquaCode 在 GPT 系列模型上实现了 91.19% 的平均攻击成功率，在三款 State-of-the-art LLMs 上更是达到了 98.65%，且所有攻击均通过单次查询完成。消融实验进一步证明，该方法的效果优于单一的数学或代码模块，展现了多策略协同在绕过 LLM 防护机制方面的强大威力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This is a preprint. A revised version will appear in the Proceedings of AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2512.23173v1",
      "published_date": "2025-12-29 03:28:30 UTC",
      "updated_date": "2025-12-29 03:28:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:23.006214+00:00"
    },
    {
      "arxiv_id": "2512.23167v1",
      "title": "SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search",
      "title_zh": "SPIRAL：基于具地与反思性搜索的符号化大语言模型规划",
      "authors": [
        "Yifan Zhang",
        "Giridhar Ganapavarapu",
        "Srideepika Jayaraman",
        "Bhavna Agrawal",
        "Dhaval Patel",
        "Achille Fokoue"
      ],
      "abstract": "Large Language Models (LLMs) often falter at complex planning tasks that require exploration and self-correction, as their linear reasoning process struggles to recover from early mistakes. While search algorithms like Monte Carlo Tree Search (MCTS) can explore alternatives, they are often ineffective when guided by sparse rewards and fail to leverage the rich semantic capabilities of LLMs. We introduce SPIRAL (Symbolic LLM Planning via Grounded and Reflective Search), a novel framework that embeds a cognitive architecture of three specialized LLM agents into an MCTS loop. SPIRAL's key contribution is its integrated planning pipeline where a Planner proposes creative next steps, a Simulator grounds the search by predicting realistic outcomes, and a Critic provides dense reward signals through reflection. This synergy transforms MCTS from a brute-force search into a guided, self-correcting reasoning process. On the DailyLifeAPIs and HuggingFace datasets, SPIRAL consistently outperforms the default Chain-of-Thought planning method and other state-of-the-art agents. More importantly, it substantially surpasses other state-of-the-art agents; for example, SPIRAL achieves 83.6% overall accuracy on DailyLifeAPIs, an improvement of over 16 percentage points against the next-best search framework, while also demonstrating superior token efficiency. Our work demonstrates that structuring LLM reasoning as a guided, reflective, and grounded search process yields more robust and efficient autonomous planners. The source code, full appendices, and all experimental data are available for reproducibility at the official project repository.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在处理复杂规划任务时因线性推理难以从早期错误中恢复的问题，提出了名为SPIRAL的创新框架。该框架将由Planner、Simulator和Critic三个专业智能体构成的认知架构嵌入到蒙特卡洛树搜索(MCTS)循环中，旨在将传统的暴力搜索转化为引导式、具备自我纠错能力的推理过程。其中Planner负责提出创意步骤，Simulator通过预测现实结果实现搜索的落地(Grounded)，而Critic则通过反射(Reflective)提供密集的奖励信号。实验结果表明，SPIRAL在DailyLifeAPIs和HuggingFace数据集上均显著优于默认的链式思维(Chain-of-Thought)及其他最先进(SOTA)的智能体。特别是在DailyLifeAPIs任务中，SPIRAL以83.6%的整体准确率超越次优框架16个百分点以上，同时展现出卓越的Token效率。这项工作证明了将推理结构化为引导、反射且接地的搜索过程，是构建更鲁棒、更高效的自主规划器的有效途径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23167v1",
      "published_date": "2025-12-29 03:19:42 UTC",
      "updated_date": "2025-12-29 03:19:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:14.466373+00:00"
    },
    {
      "arxiv_id": "2512.23163v1",
      "title": "Why We Need a New Framework for Emotional Intelligence in AI",
      "title_zh": "为什么我们需要人工智能情感智能新框架",
      "authors": [
        "Max Parks",
        "Kheli Atluru",
        "Meera Vinod",
        "Mike Kuniavsky",
        "Jud Brewer",
        "Sean White",
        "Sarah Adler",
        "Wendy Ju"
      ],
      "abstract": "In this paper, we develop the position that current frameworks for evaluating emotional intelligence (EI) in artificial intelligence (AI) systems need refinement because they do not adequately or comprehensively measure the various aspects of EI relevant in AI. Human EI often involves a phenomenological component and a sense of understanding that artificially intelligent systems lack; therefore, some aspects of EI are irrelevant in evaluating AI systems. However, EI also includes an ability to sense an emotional state, explain it, respond appropriately, and adapt to new contexts (e.g., multicultural), and artificially intelligent systems can do such things to greater or lesser degrees. Several benchmark frameworks specialize in evaluating the capacity of different AI models to perform some tasks related to EI, but these often lack a solid foundation regarding the nature of emotion and what it is to be emotionally intelligent. In this project, we begin by reviewing different theories about emotion and general EI, evaluating the extent to which each is applicable to artificial systems. We then critically evaluate the available benchmark frameworks, identifying where each falls short in light of the account of EI developed in the first section. Lastly, we outline some options for improving evaluation strategies to avoid these shortcomings in EI evaluation in AI systems.",
      "tldr_zh": "该研究指出当前评估人工智能(AI)情感智能(Emotional Intelligence, EI)的框架存在局限，无法全面衡量AI相关的情感维度。论文通过区分人类EI中的现象学组成部分与AI所具备的情绪感知、解释、响应及环境适应能力，强调了现有评估标准往往缺乏对情绪本质的理论支撑。作者首先回顾了多种关于情绪和通用EI的理论并评估其在人工系统中的适用性，随后对现有的基准框架(Benchmark Frameworks)进行了批判性分析，识别出其在理论基础和评价维度上的不足。最后，研究提出了改进评估策略的多种选择，旨在避免现有体系的缺陷并为构建更完善的人工智能情感智能评价体系提供方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23163v1",
      "published_date": "2025-12-29 03:05:05 UTC",
      "updated_date": "2025-12-29 03:05:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:25.522008+00:00"
    },
    {
      "arxiv_id": "2601.00845v1",
      "title": "Enhancing Temporal Awareness in LLMs for Temporal Point Processes",
      "title_zh": "提升面向时间点过程的大语言模型时序感知能力",
      "authors": [
        "Lili Chen",
        "Wensheng Gan",
        "Shuang Liang",
        "Philip S. Yu"
      ],
      "abstract": "Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL",
      "tldr_zh": "时间点过程(Temporal Point Processes, TPPs)在金融、医疗和社会系统等领域对分析不规则事件及其依赖关系至关重要，但现有的大语言模型(LLMs)在处理此类任务时难以有效捕获时间信息与语义上下文之间的复杂交互。为了解决这一挑战，该研究提出了TPP-TAL，一种旨在增强LLMs内部时间推理能力的即插即用(plug-and-play)框架。与传统的简单拼接事件时间与类型嵌入的方法不同，TPP-TAL在将信息输入LLM之前显式地将时间动态(temporal dynamics)与上下文语义(contextual semantics)进行对齐，使模型能够更好地感知事件之间的时间依赖关系和长程交互。在多个基准数据集上的实验结果表明，TPP-TAL在时间似然估计(temporal likelihood estimation)和事件预测准确率方面取得了显著提升。该研究不仅证明了增强LLMs时间意识在连续时间事件建模中的重要性，还为相关领域的研究提供了开源的实现方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "preprint",
      "pdf_url": "https://arxiv.org/pdf/2601.00845v1",
      "published_date": "2025-12-29 03:01:24 UTC",
      "updated_date": "2025-12-29 03:01:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:13.625154+00:00"
    },
    {
      "arxiv_id": "2512.23150v1",
      "title": "Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan",
      "title_zh": "针对最小化最大完工时间的精确延迟单机耦合任务调度问题的约束规划模型与偏置随机键遗传算法",
      "authors": [
        "Vítor A. Barbosa",
        "Rafael A. Melo"
      ],
      "abstract": "We consider the strongly NP-hard single-machine coupled task scheduling problem with exact delays to minimize the makespan. In this problem, a set of jobs has to be scheduled, each composed of two tasks interspersed by an exact delay. Given that no preemption is allowed, the goal consists of minimizing the completion time of the last scheduled task. We model the problem using constraint programming (CP) and propose a biased random-key genetic algorithm (BRKGA). Our CP model applies well-established global constraints. Our BRKGA combines some successful components in the literature: an initial solution generator, periodical restarts and shakes, and a local search algorithm. Furthermore, the BRKGA's decoder is focused on efficiency rather than optimality, which accelerates the solution space exploration. Computational experiments on a benchmark set containing instances with up to 100 jobs (200 tasks) indicate that the proposed BRKGA can efficiently explore the problem solution space, providing high-quality approximate solutions within low computational times. It can also provide better solutions than the CP model under the same computational settings, i.e., three minutes of time limit and a single thread. The CP model, when offered a longer running time of 3600 seconds and multiple threads, significantly improved the results, reaching the current best-known solution for 90.56% of these instances. Finally, our experiments highlight the importance of the shake and local search components in the BRKGA, whose combination significantly improves the results of a standard BRKGA.",
      "tldr_zh": "该研究探讨了以最小化完工时间 (makespan) 为目标的带精确延迟的单机耦合任务调度问题 (single-machine coupled task scheduling problem with exact delays)，这是一个强 NP-hard 问题。作者提出了基于全局约束的约束规划 (Constraint Programming, CP) 模型，以及一种结合了周期性重启、抖动机制 (shake) 和局部搜索的偏置随机键遗传算法 (biased random-key genetic algorithm, BRKGA)。实验表明，在三分钟的计算时限内，BRKGA 能够比 CP 模型更高效地生成高质量的近似解。而在长时运行和多线程配置下，CP 模型表现更为出色，在 90.56% 的基准算例中均能寻获当前已知最佳解。研究结果进一步证明了抖动机制和局部搜索在增强算法性能方面的核心价值。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23150v1",
      "published_date": "2025-12-29 02:27:45 UTC",
      "updated_date": "2025-12-29 02:27:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:27.414405+00:00"
    },
    {
      "arxiv_id": "2512.23145v1",
      "title": "Reservoir Computing inspired Matrix Multiplication-free Language Model",
      "title_zh": "受储备池计算启发的无矩阵乘法语言模型",
      "authors": [
        "Takumi Shiratsuchi",
        "Yuichiro Tanaka",
        "Hakaru Tamukoh"
      ],
      "abstract": "Large language models (LLMs) have achieved state-of-the-art performance in natural language processing; however, their high computational cost remains a major bottleneck. In this study, we target computational efficiency by focusing on a matrix multiplication free language model (MatMul-free LM) and further reducing the training cost through an architecture inspired by reservoir computing. Specifically, we partially fix and share the weights of selected layers in the MatMul-free LM and insert reservoir layers to obtain rich dynamic representations without additional training overhead. Additionally, several operations are combined to reduce memory accesses. Experimental results show that the proposed architecture reduces the number of parameters by up to 19%, training time by 9.9%, and inference time by 8.0%, while maintaining comparable performance to the baseline model.",
      "tldr_zh": "该研究提出了一种受 Reservoir Computing 启发的无矩阵乘法语言模型 (MatMul-free LM)，旨在降低大语言模型 (LLMs) 高昂的计算成本。该架构通过部分固定并共享 MatMul-free LM 特定层的权重，并引入 Reservoir layers，在不增加额外训练开销的情况下获得了丰富的动态表示。此外，研究还通过合并多项操作减少了内存访问，进一步优化了计算效率。实验结果表明，该方案在保持与基线模型相当性能的前提下，成功将参数量减少了 19%，并将训练时间和推理时间分别缩短了 9.9% 和 8.0%。这一改进为构建更高效、低成本的语言模型提供了有效的技术路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23145v1",
      "published_date": "2025-12-29 02:20:37 UTC",
      "updated_date": "2025-12-29 02:20:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:49.956344+00:00"
    },
    {
      "arxiv_id": "2512.23144v1",
      "title": "An Inference-Based Architecture for Intent and Affordance Saturation in Decision-Making",
      "title_zh": "面向决策中意图与示能饱和的推理架构",
      "authors": [
        "Wendyam Eric Lionel Ilboudo",
        "Saori C Tanaka"
      ],
      "abstract": "Decision paralysis, i.e. hesitation, freezing, or failure to act despite full knowledge and motivation, poses a challenge for choice models that assume options are already specified and readily comparable. Drawing on qualitative reports in autism research that are especially salient, we propose a computational account in which paralysis arises from convergence failure in a hierarchical decision process. We separate intent selection (what to pursue) from affordance selection (how to pursue the goal) and formalize commitment as inference under a mixture of reverse- and forward-Kullback-Leibler (KL) objectives. Reverse KL is mode-seeking and promotes rapid commitment, whereas forward KL is mode-covering and preserves multiple plausible goals or actions. In static and dynamic (drift-diffusion) models, forward-KL-biased inference yields slow, heavy-tailed response times and two distinct failure modes, intent saturation and affordance saturation, when values are similar. Simulations in multi-option tasks reproduce key features of decision inertia and shutdown, treating autism as an extreme regime of a general, inference-based, decision-making continuum.",
      "tldr_zh": "该研究针对决策瘫痪(Decision paralysis)现象提出了一种基于推理的计算架构，通过借鉴自闭症研究中的定性报告，构建了层次化决策模型。作者将决策过程拆分为意图选择(Intent selection)与可得性选择(Affordance selection)，并将决策承诺过程形式化为反向与前向 Kullback-Leibler (KL) 目标的混合推理。研究指出，反向 KL 具有模式寻找(Mode-seeking)特性以促进快速决策，而前向 KL 的模式覆盖(Mode-covering)特性则会导致决策过程保留过多选项。在静态与动态模型的模拟中，前向 KL 偏向的推理引发了意图饱和(Intent saturation)与可得性饱和(Affordance saturation)两种失败模式，导致响应时间呈现重尾分布。该框架不仅成功再现了决策惯性与停滞的核心特征，还将自闭症定义为通用决策推理连续体中的一种极端状态。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "32 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.23144v1",
      "published_date": "2025-12-29 02:13:34 UTC",
      "updated_date": "2025-12-29 02:13:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:45.686124+00:00"
    },
    {
      "arxiv_id": "2512.23130v2",
      "title": "PathoSyn: Imaging-Pathology MRI Synthesis via Disentangled Deviation Diffusion",
      "title_zh": "PathoSyn：基于解耦偏差扩散的影像-病理 MRI 合成",
      "authors": [
        "Jian Wang",
        "Sixing Rong",
        "Jiarui Xing",
        "Yuling Xu",
        "Weide Liu"
      ],
      "abstract": "We present PathoSyn, a unified generative framework for Magnetic Resonance Imaging (MRI) image synthesis that reformulates imaging-pathology as a disentangled additive deviation on a stable anatomical manifold. Current generative models typically operate in the global pixel domain or rely on binary masks, these paradigms often suffer from feature entanglement, leading to corrupted anatomical substrates or structural discontinuities. PathoSyn addresses these limitations by decomposing the synthesis task into deterministic anatomical reconstruction and stochastic deviation modeling. Central to our framework is a Deviation-Space Diffusion Model designed to learn the conditional distribution of pathological residuals, thereby capturing localized intensity variations while preserving global structural integrity by construction. To ensure spatial coherence, the diffusion process is coupled with a seam-aware fusion strategy and an inference-time stabilization module, which collectively suppress boundary artifacts and produce high-fidelity internal lesion heterogeneity. PathoSyn provides a mathematically principled pipeline for generating high-fidelity patient-specific synthetic datasets, facilitating the development of robust diagnostic algorithms in low-data regimes. By allowing interpretable counterfactual disease progression modeling, the framework supports precision intervention planning and provides a controlled environment for benchmarking clinical decision-support systems. Quantitative and qualitative evaluations on tumor imaging benchmarks demonstrate that PathoSyn significantly outperforms holistic diffusion and mask-conditioned baselines in both perceptual realism and anatomical fidelity. The source code of this work will be made publicly available.",
      "tldr_zh": "该研究提出了PathoSyn，这是一个用于MRI图像合成的统一生成框架，旨在解决现有模型在影像病理合成中由于特征纠缠(feature entanglement)导致的解剖结构损坏或不连续问题。PathoSyn将合成任务分解为确定性的解剖重建(anatomical reconstruction)和随机的偏差建模，将影像病理重新表述为稳定解剖流形上的解耦加性偏差。其核心的偏差空间扩散模型(Deviation-Space Diffusion Model)通过学习病理残差的条件分布，在保持全局结构完整性的同时捕捉局部强度变化。为了确保空间连贯性，该框架结合了接缝感知融合策略(seam-aware fusion strategy)和推理时稳定模块，有效抑制了边界伪影并生成了高保真度的内部病变异质性。在肿瘤成像基准上的评估表明，PathoSyn在感知现实感和解剖忠实度方面均显著优于整体扩散模型和掩码调节基准。该框架不仅支持可解释的反事实疾病进展建模，还为低数据环境下的稳健诊断算法开发提供了高质量的合成数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23130v2",
      "published_date": "2025-12-29 01:13:50 UTC",
      "updated_date": "2026-01-13 03:27:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:36:44.312141+00:00"
    },
    {
      "arxiv_id": "2512.23128v1",
      "title": "It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents",
      "title_zh": "It's a TRAP！面向网络智能体的任务重定向说服基准",
      "authors": [
        "Karolina Korgul",
        "Yushi Yang",
        "Arkadiusz Drohomirecki",
        "Piotr Błaszczyk",
        "Will Howard",
        "Lukas Aichberger",
        "Chris Russell",
        "Philip H. S. Torr",
        "Adam Mahdi",
        "Adel Bibi"
      ],
      "abstract": "Web-based agents powered by large language models are increasingly used for tasks such as email management or professional networking. Their reliance on dynamic web content, however, makes them vulnerable to prompt injection attacks: adversarial instructions hidden in interface elements that persuade the agent to divert from its original task. We introduce the Task-Redirecting Agent Persuasion Benchmark (TRAP), an evaluation for studying how persuasion techniques misguide autonomous web agents on realistic tasks. Across six frontier models, agents are susceptible to prompt injection in 25\\% of tasks on average (13\\% for GPT-5 to 43\\% for DeepSeek-R1), with small interface or contextual changes often doubling success rates and revealing systemic, psychologically driven vulnerabilities in web-based agents. We also provide a modular social-engineering injection framework with controlled experiments on high-fidelity website clones, allowing for further benchmark expansion.",
      "tldr_zh": "该研究探讨了基于大语言模型(LLMs)的Web智能体在处理动态网页内容时，容易受到提示注入攻击(Prompt Injection Attacks)的问题，即界面中的对抗性指令可能诱导智能体偏离原始任务。为此，作者提出了TRAP (Task-Redirecting Agent Persuasion Benchmark)，这是一个用于评估说服技术如何误导自主Web智能体执行现实任务的基准测试。通过对六种前沿模型的评估，研究发现智能体在平均25%的任务中表现出脆弱性，其中GPT-5的受攻击成功率为13%，而DeepSeek-R1高达43%。研究进一步表明，微小的界面或上下文变化往往能使攻击成功率翻倍，揭示了Web智能体中普遍存在的系统性且受心理驱动的脆弱性。此外，该研究还提供了一个模块化的社会工程注入框架及高保真网站克隆实验环境，为基准测试的持续扩展和安全评估奠定了基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23128v1",
      "published_date": "2025-12-29 01:09:10 UTC",
      "updated_date": "2025-12-29 01:09:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:37:47.923249+00:00"
    },
    {
      "arxiv_id": "2512.23126v2",
      "title": "InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization",
      "title_zh": "InSPO：挖掘内在自我反思潜力的大语言模型偏好优化",
      "authors": [
        "Yu Li",
        "Tian Lan",
        "Zhengling Qi"
      ],
      "abstract": "Direct Preference Optimization (DPO) and its variants have become standard for aligning Large Language Models due to their simplicity and offline stability. However, we identify two fundamental limitations. First, the optimal policy depends on arbitrary modeling choices (scalarization function, reference policy), yielding behavior reflecting parameterization artifacts rather than true preferences. Second, treating response generation in isolation fails to leverage comparative information in pairwise data, leaving the model's capacity for intrinsic self-reflection untapped. To address it, we propose Intrinsic Self-reflective Preference Optimization (InSPO), deriving a globally optimal policy conditioning on both context and alternative responses. We prove this formulation superior to DPO/RLHF while guaranteeing invariance to scalarization and reference choices. InSPO serves as a plug-and-play enhancement without architectural changes or inference overhead. Experiments demonstrate consistent improvements in win rates and length-controlled metrics, validating that unlocking self-reflection yields more robust, human-aligned LLMs.",
      "tldr_zh": "该研究针对直接偏好优化(Direct Preference Optimization, DPO)存在的模型选择依赖性及缺乏内在自我反思能力等局限性，提出了内在自我反思偏好优化(Intrinsic Self-reflective Preference Optimization, InSPO)。该方法通过在上下文和备选回答的共同约束下导出全局最优策略，有效地利用了成对数据中的比较信息，弥补了传统方法孤立处理响应生成的不足。理论证明InSPO优于DPO和RLHF，且对标量化函数(scalarization function)和参考策略(reference policy)的选择具有不变性。作为一种即插即用的增强方案，InSPO无需更改架构或增加推理开销即可显著提升模型胜率和长度控制指标。实验结果验证了通过解锁LLM的内在自我反思能力，可以获得更加鲁棒且符合人类偏好的大语言模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23126v2",
      "published_date": "2025-12-29 00:59:23 UTC",
      "updated_date": "2025-12-30 14:17:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:38:06.969908+00:00"
    },
    {
      "arxiv_id": "2512.23765v1",
      "title": "Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning",
      "title_zh": "旨在提升大语言模型推理能力的熵感知投机性解码",
      "authors": [
        "Tiancheng Su",
        "Meicong Zhang",
        "Guoxiu He"
      ],
      "abstract": "Speculative decoding (SD) accelerates large language model (LLM) reasoning by using a small draft model to generate candidate tokens, which the target LLM either accepts directly or regenerates upon rejection. However, excessive alignment between the draft and target models constrains SD to the performance of the target LLM. To address this limitation, we propose Entropy-Aware Speculative Decoding (EASD), a training-free enhancement. Building on standard SD, EASD incorporates a dynamic entropy-based penalty. At each decoding step, we employ the entropy of the sampling distribution to quantify model uncertainty. When both models exhibit high entropy with substantial overlap among their top-N predictions, the corresponding token is rejected and re-sampled by the target LLM. This penalty prevents low-confidence errors from propagating. By incorporating draft-model verification, EASD enables the possibility of surpassing the target model's inherent performance. Experiments across multiple reasoning benchmarks demonstrate that EASD consistently outperforms existing SD methods and, in most cases, surpasses the target LLM itself. We further prove that the efficiency of EASD is comparable to that of SD. The code can be found in the Supplementary Materials.",
      "tldr_zh": "该研究提出了熵感知投机解码(Entropy-Aware Speculative Decoding, EASD)，这是一种无需训练的增强方案，旨在提升大语言模型(LLM)的推理性能。传统的投机解码(Speculative Decoding, SD)因模型间的高度对齐而受限于目标模型的性能上限，EASD 通过引入动态熵惩罚机制来克服这一缺陷。该方法在解码过程中利用采样分布的熵来量化模型不确定性，当草案模型与目标模型在高熵状态下出现显著预测重叠时，会主动拒绝相关 token 并由目标模型重新采样，以防止低置信度错误的传播。实验结果表明，EASD 在多个推理基准测试中不仅优于现有的 SD 方法，甚至在多数情况下超越了目标模型本身的固有性能。此外，EASD 在保持推理增强效果的同时，其运行效率与标准 SD 相当，为提升 LLM 推理质量提供了高效的新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2512.23765v1",
      "published_date": "2025-12-29 00:45:19 UTC",
      "updated_date": "2025-12-29 00:45:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-26T20:38:09.172308+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 112,
  "processed_papers_count": 112,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-26T20:39:10.939289+00:00"
}