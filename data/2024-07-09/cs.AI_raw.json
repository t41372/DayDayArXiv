[
  {
    "arxiv_id": "2407.07277v1",
    "title": "Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning",
    "authors": [
      "A. Ali Heydari",
      "Naghmeh Rezaei",
      "Javier L. Prieto",
      "Shwetak N. Patel",
      "Ahmed A. Metwally"
    ],
    "abstract": "Blood biomarkers are an essential tool for healthcare providers to diagnose,\nmonitor, and treat a wide range of medical conditions. Current reference values\nand recommended ranges often rely on population-level statistics, which may not\nadequately account for the influence of inter-individual variability driven by\nfactors such as lifestyle and genetics. In this work, we introduce a novel\nframework for predicting future blood biomarker values and define personalized\nreferences through learned representations from lifestyle data (physical\nactivity and sleep) and blood biomarkers. Our proposed method learns a\nsimilarity-based embedding space that captures the complex relationship between\nbiomarkers and lifestyle factors. Using the UK Biobank (257K participants), our\nresults show that our deep-learned embeddings outperform traditional and\ncurrent state-of-the-art representation learning techniques in predicting\nclinical diagnosis. Using a subset of UK Biobank of 6440 participants who have\nfollow-up visits, we validate that the inclusion of these embeddings and\nlifestyle factors directly in blood biomarker models improves the prediction of\nfuture lab values from a single lab visit. This personalized modeling approach\nprovides a foundation for developing more accurate risk stratification tools\nand tailoring preventative care strategies. In clinical settings, this\ntranslates to the potential for earlier disease detection, more timely\ninterventions, and ultimately, a shift towards personalized healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07277v1",
    "published_date": "2024-07-09 23:52:53 UTC",
    "updated_date": "2024-07-09 23:52:53 UTC"
  },
  {
    "arxiv_id": "2407.07276v1",
    "title": "Exploring Camera Encoder Designs for Autonomous Driving Perception",
    "authors": [
      "Barath Lakshmanan",
      "Joshua Chen",
      "Shiyi Lan",
      "Maying Shen",
      "Zhiding Yu",
      "Jose M. Alvarez"
    ],
    "abstract": "The cornerstone of autonomous vehicles (AV) is a solid perception system,\nwhere camera encoders play a crucial role. Existing works usually leverage\npre-trained Convolutional Neural Networks (CNN) or Vision Transformers (ViTs)\ndesigned for general vision tasks, such as image classification, segmentation,\nand 2D detection. Although those well-known architectures have achieved\nstate-of-the-art accuracy in AV-related tasks, e.g., 3D Object Detection, there\nremains significant potential for improvement in network design due to the\nnuanced complexities of industrial-level AV dataset. Moreover, existing public\nAV benchmarks usually contain insufficient data, which might lead to inaccurate\nevaluation of those architectures.To reveal the AV-specific model insights, we\nstart from a standard general-purpose encoder, ConvNeXt and progressively\ntransform the design. We adjust different design parameters including width and\ndepth of the model, stage compute ratio, attention mechanisms, and input\nresolution, supported by systematic analysis to each modifications. This\ncustomization yields an architecture optimized for AV camera encoder achieving\n8.79% mAP improvement over the baseline. We believe our effort could become a\nsweet cookbook of image encoders for AV and pave the way to the next-level\ndrive system.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07276v1",
    "published_date": "2024-07-09 23:44:58 UTC",
    "updated_date": "2024-07-09 23:44:58 UTC"
  },
  {
    "arxiv_id": "2407.17515v1",
    "title": "Quality Diversity for Robot Learning: Limitations and Future Directions",
    "authors": [
      "Sumeet Batra",
      "Bryon Tjanaka",
      "Stefanos Nikolaidis",
      "Gaurav Sukhatme"
    ],
    "abstract": "Quality Diversity (QD) has shown great success in discovering\nhigh-performing, diverse policies for robot skill learning. While current\nbenchmarks have led to the development of powerful QD methods, we argue that\nnew paradigms must be developed to facilitate open-ended search and\ngeneralizability. In particular, many methods focus on learning diverse agents\nthat each move to a different xy position in MAP-Elites-style bounded archives.\nHere, we show that such tasks can be accomplished with a single,\ngoal-conditioned policy paired with a classical planner, achieving O(1) space\ncomplexity w.r.t. the number of policies and generalization to task variants.\nWe hypothesize that this approach is successful because it extracts\ntask-invariant structural knowledge by modeling a relational graph between\nadjacent cells in the archive. We motivate this view with emerging evidence\nfrom computational neuroscience and explore connections between QD and models\nof cognitive maps in human and other animal brains. We conclude with a\ndiscussion exploring the relationships between QD and cognitive maps, and\npropose future research directions inspired by cognitive maps towards future\ngeneralizable algorithms capable of truly open-ended search.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to GECCO 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.17515v1",
    "published_date": "2024-07-09 23:29:54 UTC",
    "updated_date": "2024-07-09 23:29:54 UTC"
  },
  {
    "arxiv_id": "2407.07229v1",
    "title": "Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models",
    "authors": [
      "Yun Qi Li",
      "Tuan Do",
      "Evan Jones",
      "Bernie Boscoe",
      "Kevin Alfaro",
      "Zooey Nguyen"
    ],
    "abstract": "Generative models producing images have enormous potential to advance\ndiscoveries across scientific fields and require metrics capable of quantifying\nthe high dimensional output. We propose that astrophysics data, such as galaxy\nimages, can test generative models with additional physics-motivated ground\ntruths in addition to human judgment. For example, galaxies in the Universe\nform and change over billions of years, following physical laws and\nrelationships that are both easy to characterize and difficult to encode in\ngenerative models. We build a conditional denoising diffusion probabilistic\nmodel (DDPM) and a conditional variational autoencoder (CVAE) and test their\nability to generate realistic galaxies conditioned on their redshifts (galaxy\nages). This is one of the first studies to probe these generative models using\nphysically motivated metrics. We find that both models produce comparable\nrealistic galaxies based on human evaluation, but our physics-based metrics are\nbetter able to discern the strengths and weaknesses of the generative models.\nOverall, the DDPM model performs better than the CVAE on the majority of the\nphysics-based metrics. Ultimately, if we can show that generative models can\nlearn the physics of galaxy evolution, they have the potential to unlock new\nastrophysical discoveries.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "20 pages, 14 figures, 1 Table, code:\n  https://github.com/astrodatalab/li2024_public, training data:\n  https://zenodo.org/records/11117528",
    "pdf_url": "http://arxiv.org/pdf/2407.07229v1",
    "published_date": "2024-07-09 21:01:08 UTC",
    "updated_date": "2024-07-09 21:01:08 UTC"
  },
  {
    "arxiv_id": "2407.17428v1",
    "title": "Vision Language Model-Empowered Contract Theory for AIGC Task Allocation in Teleoperation",
    "authors": [
      "Zijun Zhan",
      "Yaxian Dong",
      "Yuqing Hu",
      "Shuai Li",
      "Shaohua Cao",
      "Zhu Han"
    ],
    "abstract": "Integrating low-light image enhancement techniques, in which diffusion-based\nAI-generated content (AIGC) models are promising, is necessary to enhance\nnighttime teleoperation. Remarkably, the AIGC model is computation-intensive,\nthus necessitating the allocation of AIGC tasks to edge servers with ample\ncomputational resources. Given the distinct cost of the AIGC model trained with\nvarying-sized datasets and AIGC tasks possessing disparate demand, it is\nimperative to formulate a differential pricing strategy to optimize the utility\nof teleoperators and edge servers concurrently. Nonetheless, the pricing\nstrategy formulation is under information asymmetry, i.e., the demand (e.g.,\nthe difficulty level of AIGC tasks and their distribution) of AIGC tasks is\nhidden information to edge servers. Additionally, manually assessing the\ndifficulty level of AIGC tasks is tedious and unnecessary for teleoperators. To\nthis end, we devise a framework of AIGC task allocation assisted by the Vision\nLanguage Model (VLM)-empowered contract theory, which includes two components:\nVLM-empowered difficulty assessment and contract theory-assisted AIGC task\nallocation. The first component enables automatic and accurate AIGC task\ndifficulty assessment. The second component is capable of formulating the\npricing strategy for edge servers under information asymmetry, thereby\noptimizing the utility of both edge servers and teleoperators. The simulation\nresults demonstrated that our proposed framework can improve the average\nutility of teleoperators and edge servers by 10.88~12.43% and 1.4~2.17%,\nrespectively. Code and data are available at\nhttps://github.com/ZiJun0819/VLM-Contract-Theory.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.17428v1",
    "published_date": "2024-07-09 20:08:26 UTC",
    "updated_date": "2024-07-09 20:08:26 UTC"
  },
  {
    "arxiv_id": "2407.07094v1",
    "title": "AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning",
    "authors": [
      "Jiaxi Cui",
      "Wentao Zhang",
      "Jing Tang",
      "Xudong Tong",
      "Zhenwei Zhang",
      "Amie",
      "Jing Wen",
      "Rongsheng Wang",
      "Pengfei Wu"
    ],
    "abstract": "The pervasive deployment of Large Language Models-LLMs in various sectors\noften neglects the nuanced requirements of individuals and small organizations,\nwho benefit more from models precisely tailored to their specific business\ncontexts rather than those with broadly superior general capabilities. This\nwork introduces \\textbf{AnyTaskTune}, a novel fine-tuning methodology coined as\n\\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on\na diverse array of domain-specific tasks. This method involves a meticulous\nprocess to identify and define targeted sub-tasks within a domain, followed by\nthe creation of specialized enhancement datasets for fine-tuning, thereby\noptimizing task-specific model performance. We conducted comprehensive\nfine-tuning experiments not only in the legal domain for tasks such as keyword\nextraction and sentence prediction but across over twenty different sub-tasks\nderived from the domains of finance, healthcare, law, psychology, consumer\nservices, and human resources. To substantiate our approach and facilitate\ncommunity engagement, we will open-source these bilingual task datasets. Our\nfindings demonstrate that models fine-tuned using the \\textbf{Task-Fine-Tune}\nmethodology not only achieve superior performance on these specific tasks but\nalso significantly outperform models with higher general capabilities in their\nrespective domains. Our work is publicly available at\n\\url{https://github.com/PandaVT/DataTager}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07094v1",
    "published_date": "2024-07-09 17:59:56 UTC",
    "updated_date": "2024-07-09 17:59:56 UTC"
  },
  {
    "arxiv_id": "2407.07093v1",
    "title": "FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation",
    "authors": [
      "Liqun Ma",
      "Mingjie Sun",
      "Zhiqiang Shen"
    ],
    "abstract": "This work presents a Fully BInarized Large Language Model (FBI-LLM),\ndemonstrating for the first time how to train a large-scale binary language\nmodel from scratch (not the partial binary or ternary LLM like BitNet b1.58) to\nmatch the performance of its full-precision counterparts (e.g., FP16 or BF16)\nin transformer-based LLMs. It achieves this by employing an autoregressive\ndistillation (AD) loss with maintaining equivalent model dimensions (130M,\n1.3B, 7B) and training data volume as regular LLM pretraining, while delivering\ncompetitive results in terms of perplexity and task-specific effectiveness.\nIntriguingly, by analyzing the training trajectory, we find that the pretrained\nweight is not necessary for training binarized LLMs from scratch. This research\nencourages a new computational framework and may facilitate the future design\nof specialized hardware tailored for fully 1-bit LLMs. We make all models,\ncode, and training dataset fully accessible and transparent to support further\nresearch (Code: https://github.com/LiqunMa/FBI-LLM. Model:\nhttps://huggingface.co/LiqunMa/).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Github at https://github.com/LiqunMa/FBI-LLM",
    "pdf_url": "http://arxiv.org/pdf/2407.07093v1",
    "published_date": "2024-07-09 17:59:48 UTC",
    "updated_date": "2024-07-09 17:59:48 UTC"
  },
  {
    "arxiv_id": "2407.07092v1",
    "title": "V-VIPE: Variational View Invariant Pose Embedding",
    "authors": [
      "Mara Levy",
      "Abhinav Shrivastava"
    ],
    "abstract": "Learning to represent three dimensional (3D) human pose given a two\ndimensional (2D) image of a person, is a challenging problem. In order to make\nthe problem less ambiguous it has become common practice to estimate 3D pose in\nthe camera coordinate space. However, this makes the task of comparing two 3D\nposes difficult. In this paper, we address this challenge by separating the\nproblem of estimating 3D pose from 2D images into two steps. We use a\nvariational autoencoder (VAE) to find an embedding that represents 3D poses in\ncanonical coordinate space. We refer to this embedding as variational\nview-invariant pose embedding V-VIPE. Using V-VIPE we can encode 2D and 3D\nposes and use the embedding for downstream tasks, like retrieval and\nclassification. We can estimate 3D poses from these embeddings using the\ndecoder as well as generate unseen 3D poses. The variability of our encoding\nallows it to generalize well to unseen camera views when mapping from 2D space.\nTo the best of our knowledge, V-VIPE is the only representation to offer this\ndiversity of applications. Code and more information can be found at\nhttps://v-vipe.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024 - RHOBIN Workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.07092v1",
    "published_date": "2024-07-09 17:59:47 UTC",
    "updated_date": "2024-07-09 17:59:47 UTC"
  },
  {
    "arxiv_id": "2407.07088v1",
    "title": "Safe and Reliable Training of Learning-Based Aerospace Controllers",
    "authors": [
      "Udayan Mandal",
      "Guy Amir",
      "Haoze Wu",
      "Ieva Daukantas",
      "Fletcher Lee Newell",
      "Umberto Ravaioli",
      "Baoluo Meng",
      "Michael Durling",
      "Kerianne Hobbs",
      "Milan Ganai",
      "Tobey Shim",
      "Guy Katz",
      "Clark Barrett"
    ],
    "abstract": "In recent years, deep reinforcement learning (DRL) approaches have generated\nhighly successful controllers for a myriad of complex domains. However, the\nopaque nature of these models limits their applicability in aerospace systems\nand safety-critical domains, in which a single mistake can have dire\nconsequences. In this paper, we present novel advancements in both the training\nand verification of DRL controllers, which can help ensure their safe behavior.\nWe showcase a design-for-verification approach utilizing k-induction and\ndemonstrate its use in verifying liveness properties. In addition, we also give\na brief overview of neural Lyapunov Barrier certificates and summarize their\ncapabilities on a case study. Finally, we describe several other novel\nreachability-based approaches which, despite failing to provide guarantees of\ninterest, could be effective for verification of other DRL systems, and could\nbe of further interest to the community.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.07088v1",
    "published_date": "2024-07-09 17:58:50 UTC",
    "updated_date": "2024-07-09 17:58:50 UTC"
  },
  {
    "arxiv_id": "2407.07086v2",
    "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
    "authors": [
      "Logan Cross",
      "Violet Xiang",
      "Agam Bhatia",
      "Daniel LK Yamins",
      "Nick Haber"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) methods struggle with the\nnon-stationarity of multi-agent systems and fail to adaptively learn online\nwhen tested with novel agents. Here, we leverage large language models (LLMs)\nto create an autonomous agent that can handle these challenges. Our agent,\nHypothetical Minds, consists of a cognitively-inspired architecture, featuring\nmodular components for perception, memory, and hierarchical planning over two\nlevels of abstraction. We introduce the Theory of Mind module that scaffolds\nthe high-level planning process by generating hypotheses about other agents'\nstrategies in natural language. It then evaluates and iteratively refines these\nhypotheses by reinforcing hypotheses that make correct predictions about the\nother agents' behavior. Hypothetical Minds significantly improves performance\nover previous LLM-agent and RL baselines on a range of competitive, mixed\nmotive, and collaborative domains in the Melting Pot benchmark, including both\ndyadic and population-based environments. Additionally, comparisons against\nLLM-agent baselines and ablations reveal the importance of hypothesis\nevaluation and refinement for succeeding on complex scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07086v2",
    "published_date": "2024-07-09 17:57:15 UTC",
    "updated_date": "2024-12-12 01:41:28 UTC"
  },
  {
    "arxiv_id": "2407.07082v3",
    "title": "Can Learned Optimization Make Reinforcement Learning Less Difficult?",
    "authors": [
      "Alexander David Goldie",
      "Chris Lu",
      "Matthew Thomas Jackson",
      "Shimon Whiteson",
      "Jakob Nicolaus Foerster"
    ],
    "abstract": "While reinforcement learning (RL) holds great potential for decision making\nin the real world, it suffers from a number of unique difficulties which often\nneed specific consideration. In particular: it is highly non-stationary;\nsuffers from high degrees of plasticity loss; and requires exploration to\nprevent premature convergence to local optima and maximize return. In this\npaper, we consider whether learned optimization can help overcome these\nproblems. Our method, Learned Optimization for Plasticity, Exploration and\nNon-stationarity (OPEN), meta-learns an update rule whose input features and\noutput structure are informed by previously proposed solutions to these\ndifficulties. We show that our parameterization is flexible enough to enable\nmeta-learning in diverse learning contexts, including the ability to use\nstochasticity for exploration. Our experiments demonstrate that when\nmeta-trained on single and small sets of environments, OPEN outperforms or\nequals traditionally used optimizers. Furthermore, OPEN shows strong\ngeneralization characteristics across a range of environments and agent\narchitectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Added Metadata for Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.07082v3",
    "published_date": "2024-07-09 17:55:23 UTC",
    "updated_date": "2025-04-15 15:07:30 UTC"
  },
  {
    "arxiv_id": "2407.07077v1",
    "title": "ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction",
    "authors": [
      "Shaozhe Hao",
      "Kai Han",
      "Zhengyao Lv",
      "Shihao Zhao",
      "Kwan-Yee K. Wong"
    ],
    "abstract": "While personalized text-to-image generation has enabled the learning of a\nsingle concept from multiple images, a more practical yet challenging scenario\ninvolves learning multiple concepts within a single image. However, existing\nworks tackling this scenario heavily rely on extensive human annotations. In\nthis paper, we introduce a novel task named Unsupervised Concept Extraction\n(UCE) that considers an unsupervised setting without any human knowledge of the\nconcepts. Given an image that contains multiple concepts, the task aims to\nextract and recreate individual concepts solely relying on the existing\nknowledge from pretrained diffusion models. To achieve this, we present\nConceptExpress that tackles UCE by unleashing the inherent capabilities of\npretrained diffusion models in two aspects. Specifically, a concept\nlocalization approach automatically locates and disentangles salient concepts\nby leveraging spatial correspondence from diffusion self-attention; and based\non the lookup association between a concept and a conceptual token, a\nconcept-wise optimization process learns discriminative tokens that represent\neach individual concept. Finally, we establish an evaluation protocol tailored\nfor the UCE task. Extensive experiments demonstrate that ConceptExpress is a\npromising solution to the UCE task. Our code and data are available at:\nhttps://github.com/haoosz/ConceptExpress",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024, Project page: https://haoosz.github.io/ConceptExpress/",
    "pdf_url": "http://arxiv.org/pdf/2407.07077v1",
    "published_date": "2024-07-09 17:50:28 UTC",
    "updated_date": "2024-07-09 17:50:28 UTC"
  },
  {
    "arxiv_id": "2407.07071v2",
    "title": "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps",
    "authors": [
      "Yung-Sung Chuang",
      "Linlu Qiu",
      "Cheng-Yu Hsieh",
      "Ranjay Krishna",
      "Yoon Kim",
      "James Glass"
    ],
    "abstract": "When asked to summarize articles or answer questions given a passage, large\nlanguage models (LLMs) can hallucinate details and respond with unsubstantiated\nanswers that are inaccurate with respect to the input context. This paper\ndescribes a simple approach for detecting such contextual hallucinations. We\nhypothesize that contextual hallucinations are related to the extent to which\nan LLM attends to information in the provided context versus its own\ngenerations. Based on this intuition, we propose a simple hallucination\ndetection model whose input features are given by the ratio of attention\nweights on the context versus newly generated tokens (for each attention head).\nWe find that a linear classifier based on these lookback ratio features is as\neffective as a richer detector that utilizes the entire hidden states of an LLM\nor a text-based entailment model. The lookback ratio-based detector -- Lookback\nLens -- is found to transfer across tasks and even models, allowing a detector\nthat is trained on a 7B model to be applied (without retraining) to a larger\n13B model. We further apply this detector to mitigate contextual\nhallucinations, and find that a simple classifier-guided decoding approach is\nable to reduce the amount of hallucination, for example by 9.6% in the XSum\nsummarization task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 main conference long paper. The source code is available\n  at https://github.com/voidism/Lookback-Lens",
    "pdf_url": "http://arxiv.org/pdf/2407.07071v2",
    "published_date": "2024-07-09 17:44:34 UTC",
    "updated_date": "2024-10-03 17:26:48 UTC"
  },
  {
    "arxiv_id": "2407.07064v2",
    "title": "Prompting Techniques for Secure Code Generation: A Systematic Investigation",
    "authors": [
      "Catherine Tony",
      "Nicolás E. Díaz Ferreyra",
      "Markus Mutas",
      "Salem Dhiff",
      "Riccardo Scandariato"
    ],
    "abstract": "Large Language Models (LLMs) are gaining momentum in software development\nwith prompt-driven programming enabling developers to create code from natural\nlanguage (NL) instructions. However, studies have questioned their ability to\nproduce secure code and, thereby, the quality of prompt-generated software.\nAlongside, various prompting techniques that carefully tailor prompts have\nemerged to elicit optimal responses from LLMs. Still, the interplay between\nsuch prompting strategies and secure code generation remains under-explored and\ncalls for further investigations. OBJECTIVE: In this study, we investigate the\nimpact of different prompting techniques on the security of code generated from\nNL instructions by LLMs. METHOD: First we perform a systematic literature\nreview to identify the existing prompting techniques that can be used for code\ngeneration tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5,\nand GPT-4 models for secure code generation. For this, we used an existing\ndataset consisting of 150 NL security-relevant code-generation prompts.\nRESULTS: Our work (i) classifies potential prompting techniques for code\ngeneration (ii) adapts and evaluates a subset of the identified techniques for\nsecure code generation tasks and (iii) observes a reduction in security\nweaknesses across the tested LLMs, especially after using an existing technique\ncalled Recursive Criticism and Improvement (RCI), contributing valuable\ninsights to the ongoing discourse on LLM-generated code security.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Work partially supported by the EU-funded project Sec4AI4Sec:\n  Cybersecurity for AI-Augmented Systems (grant no. 101120393) - ACCEPTED at\n  ACM Transactions on Software Engineering and Methodology (Feb. 2025)",
    "pdf_url": "http://arxiv.org/pdf/2407.07064v2",
    "published_date": "2024-07-09 17:38:03 UTC",
    "updated_date": "2025-02-26 14:28:11 UTC"
  },
  {
    "arxiv_id": "2407.07046v2",
    "title": "CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis",
    "authors": [
      "Yangmin Li",
      "Ruiqi Zhu",
      "Wengen Li"
    ],
    "abstract": "Multimodal sentiment analysis is an active research area that combines\nmultiple data modalities, e.g., text, image and audio, to analyze human\nemotions and benefits a variety of applications. Existing multimodal sentiment\nanalysis methods can be classified as modality interaction-based methods,\nmodality transformation-based methods and modality similarity-based methods.\nHowever, most of these methods highly rely on the strong correlations between\nmodalities, and cannot fully uncover and utilize the correlations between\nmodalities to enhance sentiment analysis. Therefore, these methods usually\nachieve bad performance for identifying the sentiment of multimodal data with\nweak correlations. To address this issue, we proposed a two-stage\nsemi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT)\nwhich consists pre-training stage and prediction stage. At the pre-training\nstage, a modality correlation contrastive learning module is designed to\nefficiently learn modality correlation coefficients between different\nmodalities. At the prediction stage, the learned correlation coefficients are\nfused with modality representations to make the sentiment prediction. According\nto the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT\nobviously surpasses state-of-the-art multimodal sentiment analysis methods.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07046v2",
    "published_date": "2024-07-09 17:07:29 UTC",
    "updated_date": "2024-08-29 06:15:55 UTC"
  },
  {
    "arxiv_id": "2407.07045v1",
    "title": "Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs",
    "authors": [
      "Christian Riefolo",
      "Nicola Fanizzi",
      "Claudia d'Amato"
    ],
    "abstract": "Tackling the problem of learning probabilistic classifiers from incomplete\ndata in the context of Knowledge Graphs expressed in Description Logics, we\ndescribe an inductive approach based on learning simple belief networks.\nSpecifically, we consider a basic probabilistic model, a Naive Bayes\nclassifier, based on multivariate Bernoullis and its extension to a two-tier\nnetwork in which this classification model is connected to a lower layer\nconsisting of a mixture of Bernoullis. We show how such models can be converted\ninto (probabilistic) axioms (or rules) thus ensuring more interpretability.\nMoreover they may be also initialized exploiting expert knowledge. We present\nand discuss the outcomes of an empirical evaluation which aimed at testing the\neffectiveness of the models on a number of random classification problems with\ndifferent ontologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 4 figures, 2 tables peer reviewed / presented at IJCLR\n  2023, 3rd International Joint Conference on Learning & Reasoning\n  https://ijclr2023.di.uniba.it/",
    "pdf_url": "http://arxiv.org/pdf/2407.07045v1",
    "published_date": "2024-07-09 17:05:52 UTC",
    "updated_date": "2024-07-09 17:05:52 UTC"
  },
  {
    "arxiv_id": "2407.07042v2",
    "title": "ProtoSAM: One-Shot Medical Image Segmentation With Foundational Models",
    "authors": [
      "Lev Ayzenberg",
      "Raja Giryes",
      "Hayit Greenspan"
    ],
    "abstract": "This work introduces a new framework, ProtoSAM, for one-shot medical image\nsegmentation. It combines the use of prototypical networks, known for few-shot\nsegmentation, with SAM - a natural image foundation model. The method proposed\ncreates an initial coarse segmentation mask using the ALPnet prototypical\nnetwork, augmented with a DINOv2 encoder. Following the extraction of an\ninitial mask, prompts are extracted, such as points and bounding boxes, which\nare then input into the Segment Anything Model (SAM). State-of-the-art results\nare shown on several medical image datasets and demonstrate automated\nsegmentation capabilities using a single image example (one shot) with no need\nfor fine-tuning of the foundation model. Our code is available at:\nhttps://github.com/levayz/ProtoSAM",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 3 figures, 4 tables, code:\n  https://github.com/levayz/ProtoSAM",
    "pdf_url": "http://arxiv.org/pdf/2407.07042v2",
    "published_date": "2024-07-09 17:04:08 UTC",
    "updated_date": "2024-07-18 07:58:11 UTC"
  },
  {
    "arxiv_id": "2407.07041v2",
    "title": "Hiding Local Manipulations on SAR Images: a Counter-Forensic Attack",
    "authors": [
      "Sara Mandelli",
      "Edoardo Daniele Cannas",
      "Paolo Bestagini",
      "Stefano Tebaldini",
      "Stefano Tubaro"
    ],
    "abstract": "The vast accessibility of Synthetic Aperture Radar (SAR) images through\nonline portals has propelled the research across various fields. This\nwidespread use and easy availability have unfortunately made SAR data\nsusceptible to malicious alterations, such as local editing applied to the\nimages for inserting or covering the presence of sensitive targets.\nVulnerability is further emphasized by the fact that most SAR products, despite\ntheir original complex nature, are often released as amplitude-only\ninformation, allowing even inexperienced attackers to edit and easily alter the\npixel content. To contrast malicious manipulations, in the last years the\nforensic community has begun to dig into the SAR manipulation issue, proposing\ndetectors that effectively localize the tampering traces in amplitude images.\nNonetheless, in this paper we demonstrate that an expert practitioner can\nexploit the complex nature of SAR data to obscure any signs of manipulation\nwithin a locally altered amplitude image. We refer to this approach as a\ncounter-forensic attack. To achieve the concealment of manipulation traces, the\nattacker can simulate a re-acquisition of the manipulated scene by the SAR\nsystem that initially generated the pristine image. In doing so, the attacker\ncan obscure any evidence of manipulation, making it appear as if the image was\nlegitimately produced by the system. This attack has unique features that make\nit both highly generalizable and relatively easy to apply. First, it is a\nblack-box attack, meaning it is not designed to deceive a specific forensic\ndetector. Furthermore, it does not require a training phase and is not based on\nadversarial operations. We assess the effectiveness of the proposed\ncounter-forensic approach across diverse scenarios, examining various\nmanipulation operations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07041v2",
    "published_date": "2024-07-09 17:03:57 UTC",
    "updated_date": "2025-03-14 11:31:15 UTC"
  },
  {
    "arxiv_id": "2407.07030v1",
    "title": "Trajectory Data Mining and Trip Travel Time Prediction on Specific Roads",
    "authors": [
      "Muhammad Awais Amin",
      "Jawad-Ur-Rehman Chughtai",
      "Waqar Ahmad",
      "Waqas Haider Bangyal",
      "Irfan Ul Haq"
    ],
    "abstract": "Predicting a trip's travel time is essential for route planning and\nnavigation applications. The majority of research is based on international\ndata that does not apply to Pakistan's road conditions. We designed a complete\npipeline for mining trajectories from sensors data. On this data, we employed\nstate-of-the-art approaches, including a shallow artificial neural network, a\ndeep multi-layered perceptron, and a long-short-term memory, to explore the\nissue of travel time prediction on frequent routes. The experimental results\ndemonstrate an average prediction error ranging from 30 seconds to 1.2 minutes\non trips lasting 10 minutes to 60 minutes on six most frequent routes in\nregions of Islamabad, Pakistan.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "N/A",
    "pdf_url": "http://arxiv.org/pdf/2407.07030v1",
    "published_date": "2024-07-09 16:50:15 UTC",
    "updated_date": "2024-07-09 16:50:15 UTC"
  },
  {
    "arxiv_id": "2407.07024v3",
    "title": "Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization",
    "authors": [
      "Jeongseok Hyun",
      "Su Ho Han",
      "Hyolim Kang",
      "Joon-Young Lee",
      "Seon Joo Kim"
    ],
    "abstract": "The vocabulary size in temporal action localization (TAL) is limited by the\nscarcity of large-scale annotated datasets. To overcome this, recent works\nintegrate vision-language models (VLMs), such as CLIP, for open-vocabulary TAL\n(OV-TAL). However, despite the success of VLMs trained on extensive datasets,\nexisting OV-TAL methods still rely on human-labeled TAL datasets of limited\nsize to train action localizers, limiting their generalizability. In this\npaper, we explore the scalability of self-training with unlabeled YouTube\nvideos for OV-TAL. Our approach consists of two stages: (1) a class-agnostic\naction localizer is trained on a human-labeled TAL dataset to generate\npseudo-labels for unlabeled videos, and (2) the large-scale pseudo-labeled\ndataset is then used to train the localizer. Extensive experiments demonstrate\nthat leveraging web-scale videos in self-training significantly enhances the\ngeneralizability of an action localizer. Additionally, we identify limitations\nin existing OV-TAL evaluation schemes and propose a new benchmark for thorough\nassessment. Finally, we showcase the TAL performance of the large multimodal\nmodel Gemini-1.5 on our new benchmark. Code is released at\nhttps://github.com/HYUNJS/STOV-TAL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.07024v3",
    "published_date": "2024-07-09 16:44:04 UTC",
    "updated_date": "2024-12-19 14:07:44 UTC"
  },
  {
    "arxiv_id": "2407.07020v1",
    "title": "Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction",
    "authors": [
      "Haicheng Liao",
      "Yongkang Li",
      "Zhenning Li",
      "Chengyue Wang",
      "Chunlin Tian",
      "Yuming Huang",
      "Zilin Bian",
      "Kaiqun Zhu",
      "Guofa Li",
      "Ziyuan Pu",
      "Jia Hu",
      "Zhiyong Cui",
      "Chengzhong Xu"
    ],
    "abstract": "Accurately and safely predicting the trajectories of surrounding vehicles is\nessential for fully realizing autonomous driving (AD). This paper presents the\nHuman-Like Trajectory Prediction model (HLTP++), which emulates human cognitive\nprocesses to improve trajectory prediction in AD. HLTP++ incorporates a novel\nteacher-student knowledge distillation framework. The \"teacher\" model equipped\nwith an adaptive visual sector, mimics the dynamic allocation of attention\nhuman drivers exhibit based on factors like spatial orientation, proximity, and\ndriving speed. On the other hand, the \"student\" model focuses on real-time\ninteraction and human decision-making, drawing parallels to the human memory\nstorage mechanism. Furthermore, we improve the model's efficiency by\nintroducing a new Fourier Adaptive Spike Neural Network (FA-SNN), allowing for\nfaster and more precise predictions with fewer parameters. Evaluated using the\nNGSIM, HighD, and MoCAD benchmarks, HLTP++ demonstrates superior performance\ncompared to existing models, which reduces the predicted trajectory error with\nover 11% on the NGSIM dataset and 25% on the HighD datasets. Moreover, HLTP++\ndemonstrates strong adaptability in challenging environments with incomplete\ninput data. This marks a significant stride in the journey towards fully AD\nsystems.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.19251",
    "pdf_url": "http://arxiv.org/pdf/2407.07020v1",
    "published_date": "2024-07-09 16:42:17 UTC",
    "updated_date": "2024-07-09 16:42:17 UTC"
  },
  {
    "arxiv_id": "2407.07009v2",
    "title": "Explainable AI for Enhancing Efficiency of DL-based Channel Estimation",
    "authors": [
      "Abdul Karim Gizzini",
      "Yahia Medjahdi",
      "Ali J. Ghandour",
      "Laurent Clavier"
    ],
    "abstract": "The support of artificial intelligence (AI) based decision-making is a key\nelement in future 6G networks, where the concept of native AI will be\nintroduced. Moreover, AI is widely employed in different critical applications\nsuch as autonomous driving and medical diagnosis. In such applications, using\nAI as black-box models is risky and challenging. Hence, it is crucial to\nunderstand and trust the decisions taken by these models. Tackling this issue\ncan be achieved by developing explainable AI (XAI) schemes that aim to explain\nthe logic behind the black-box model behavior, and thus, ensure its efficient\nand safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST\nframework that is oriented toward channel estimation in wireless\ncommunications. The core idea of the XAI-CHEST framework is to identify the\nrelevant model inputs by inducing high noise on the irrelevant ones. This\nmanuscript provides the detailed theoretical foundations of the XAI-CHEST\nframework. In particular, we derive the analytical expressions of the XAI-CHEST\nloss functions and the noise threshold fine-tuning optimization problem. Hence\nthe designed XAI-CHEST delivers a smart input feature selection methodology\nthat can further improve the overall performance while optimizing the\narchitecture of the employed model. Simulation results show that the XAI-CHEST\nframework provides valid interpretations, where it offers an improved bit error\nrate performance while reducing the required computational complexity in\ncomparison to the classical DL-based channel estimation.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been submitted to the IEEE Transactions on Machine\n  Learning in Communications and Networking on 19 March 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.07009v2",
    "published_date": "2024-07-09 16:24:21 UTC",
    "updated_date": "2025-04-07 13:02:14 UTC"
  },
  {
    "arxiv_id": "2407.07004v2",
    "title": "Empirical analysis of Binding Precedent efficiency in the Brazilian Supreme Court via Similar Case Retrieval",
    "authors": [
      "Raphaël Tinarrage",
      "Henrique Ennes",
      "Lucas E. Resck",
      "Lucas T. Gomes",
      "Jean R. Ponciano",
      "Jorge Poco"
    ],
    "abstract": "Binding precedents (S\\'umulas Vinculantes) constitute a juridical instrument\nunique to the Brazilian legal system and whose objectives include the\nprotection of the Federal Supreme Court against repetitive demands. Studies of\nthe effectiveness of these instruments in decreasing the Court's exposure to\nsimilar cases, however, indicate that they tend to fail in such a direction,\nwith some of the binding precedents seemingly creating new demands. We\nempirically assess the legal impact of five binding precedents, 11, 14, 17, 26\nand 37, at the highest court level through their effects on the legal subjects\nthey address. This analysis is only possible through the comparison of the\nCourt's ruling about the precedents' themes before they are created, which\nmeans that these decisions should be detected through techniques of Similar\nCase Retrieval. The contributions of this article are therefore twofold: on the\nmathematical side, we compare the uses of different methods of Natural Language\nProcessing -- TF-IDF, LSTM, BERT, and regex -- for Similar Case Retrieval,\nwhereas on the legal side, we contrast the inefficiency of these binding\nprecedents with a set of hypotheses that may justify their repeated usage. We\nobserve that the deep learning models performed significantly worse in the\nspecific Similar Case Retrieval task and that the reasons for binding\nprecedents to fail in responding to repetitive demand are heterogeneous and\ncase-dependent, making it impossible to single out a specific cause.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "68T50 (Primary), 68T07 (Secondary)"
    ],
    "primary_category": "cs.CL",
    "comment": "54 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.07004v2",
    "published_date": "2024-07-09 16:17:16 UTC",
    "updated_date": "2024-07-23 18:20:45 UTC"
  },
  {
    "arxiv_id": "2407.07003v1",
    "title": "Learning to Complement and to Defer to Multiple Users",
    "authors": [
      "Zheng Zhang",
      "Wenjie Ai",
      "Kevin Wells",
      "David Rosewarne",
      "Thanh-Toan Do",
      "Gustavo Carneiro"
    ],
    "abstract": "With the development of Human-AI Collaboration in Classification (HAI-CC),\nintegrating users and AI predictions becomes challenging due to the complex\ndecision-making process. This process has three options: 1) AI autonomously\nclassifies, 2) learning to complement, where AI collaborates with users, and 3)\nlearning to defer, where AI defers to users. Despite their interconnected\nnature, these options have been studied in isolation rather than as components\nof a unified system. In this paper, we address this weakness with the novel\nHAI-CC methodology, called Learning to Complement and to Defer to Multiple\nUsers (LECODU). LECODU not only combines learning to complement and learning to\ndefer strategies, but it also incorporates an estimation of the optimal number\nof users to engage in the decision process. The training of LECODU maximises\nclassification accuracy and minimises collaboration costs associated with user\ninvolvement. Comprehensive evaluations across real-world and synthesized\ndatasets demonstrate LECODU's superior performance compared to state-of-the-art\nHAI-CC methods. Remarkably, even when relying on unreliable users with high\nrates of label noise, LECODU exhibits significant improvement over both human\ndecision-makers alone and AI alone.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.07003v1",
    "published_date": "2024-07-09 16:16:44 UTC",
    "updated_date": "2024-07-09 16:16:44 UTC"
  },
  {
    "arxiv_id": "2407.07000v2",
    "title": "Etalon: Holistic Performance Evaluation Framework for LLM Inference Systems",
    "authors": [
      "Amey Agrawal",
      "Anmol Agarwal",
      "Nitin Kedia",
      "Jayashree Mohan",
      "Souvik Kundu",
      "Nipun Kwatra",
      "Ramachandran Ramjee",
      "Alexey Tumanov"
    ],
    "abstract": "Serving large language models (LLMs) in production can incur substantial\ncosts, which has prompted recent advances in inference system optimizations.\nToday, these systems are evaluated against conventional latency and throughput\nmetrics (eg. TTFT, TBT, Normalised Latency and TPOT). However, these metrics\nfail to fully capture the nuances of LLM inference, leading to an incomplete\nassessment of user-facing performance crucial for real-time applications such\nas chat and translation. In this paper, we first identify the pitfalls of\ncurrent performance metrics in evaluating LLM inference systems. We then\npropose Etalon, a comprehensive performance evaluation framework that includes\nfluidity-index -- a novel metric designed to reflect the intricacies of the LLM\ninference process and its impact on real-time user experience. Finally, we\nevaluate various existing open-source platforms and model-as-a-service\nofferings using Etalon, discussing their strengths and weaknesses. Etalon is\navailable at https://github.com/project-etalon/etalon.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07000v2",
    "published_date": "2024-07-09 16:13:26 UTC",
    "updated_date": "2024-08-30 01:19:42 UTC"
  },
  {
    "arxiv_id": "2407.06992v2",
    "title": "Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective",
    "authors": [
      "Yu-An Liu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Maarten de Rijke",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "abstract": "Recent advances in neural information retrieval (IR) models have\nsignificantly enhanced their effectiveness over various IR tasks. The\nrobustness of these models, essential for ensuring their reliability in\npractice, has also garnered significant attention. With a wide array of\nresearch on robust IR being proposed, we believe it is the opportune moment to\nconsolidate the current status, glean insights from existing methodologies, and\nlay the groundwork for future development. We view the robustness of IR to be a\nmultifaceted concept, emphasizing its necessity against adversarial attacks,\nout-of-distribution (OOD) scenarios and performance variance. With a focus on\nadversarial and OOD robustness, we dissect robustness solutions for dense\nretrieval models (DRMs) and neural ranking models (NRMs), respectively,\nrecognizing them as pivotal components of the neural IR pipeline. We provide an\nin-depth discussion of existing methods, datasets, and evaluation metrics,\nshedding light on challenges and future directions in the era of large language\nmodels. To the best of our knowledge, this is the first comprehensive survey on\nthe robustness of neural IR models, and we will also be giving our first\ntutorial presentation at SIGIR 2024\n\\url{https://sigir2024-robust-information-retrieval.github.io}. Along with the\norganization of existing work, we introduce a Benchmark for robust IR (BestIR),\na heterogeneous evaluation benchmark for robust neural information retrieval,\nwhich is publicly available at \\url{https://github.com/Davion-Liu/BestIR}. We\nhope that this study provides useful clues for future research on the\nrobustness of IR models and helps to develop trustworthy search engines\n\\url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Survey paper",
    "pdf_url": "http://arxiv.org/pdf/2407.06992v2",
    "published_date": "2024-07-09 16:07:01 UTC",
    "updated_date": "2024-08-16 08:18:19 UTC"
  },
  {
    "arxiv_id": "2407.06985v4",
    "title": "PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods",
    "authors": [
      "Yiying Wang",
      "Xiaojing Li",
      "Binzhu Wang",
      "Yueyang Zhou",
      "Yingru Lin",
      "Han Ji",
      "Hong Chen",
      "Jinshi Zhang",
      "Fei Yu",
      "Zewei Zhao",
      "Song Jin",
      "Renji Gong",
      "Wanqing Xu"
    ],
    "abstract": "In domain-specific applications, GPT-4, augmented with precise prompts or\nRetrieval-Augmented Generation (RAG), shows notable potential but faces the\ncritical tri-lemma of performance, cost, and data privacy. High performance\nrequires sophisticated processing techniques, yet managing multiple agents\nwithin a complex workflow often proves costly and challenging. To address this,\nwe introduce the PEER (Plan, Execute, Express, Review) multi-agent framework.\nThis systematizes domain-specific tasks by integrating precise question\ndecomposition, advanced information retrieval, comprehensive summarization, and\nrigorous self-assessment. Given the concerns of cost and data privacy,\nenterprises are shifting from proprietary models like GPT-4 to custom models,\nstriking a balance between cost, security, and performance. We developed\nindustrial practices leveraging online data and user feedback for efficient\nmodel tuning. This study provides best practice guidelines for applying\nmulti-agent systems in domain-specific problem-solving and implementing\neffective agent tuning strategies. Our empirical studies, particularly in the\nfinancial question-answering domain, demonstrate that our approach achieves\n95.0% of GPT-4's performance, while effectively managing costs and ensuring\ndata privacy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06985v4",
    "published_date": "2024-07-09 15:59:28 UTC",
    "updated_date": "2024-08-30 06:27:58 UTC"
  },
  {
    "arxiv_id": "2407.06979v3",
    "title": "Can virtual staining for high-throughput screening generalize?",
    "authors": [
      "Samuel Tonks",
      "Cuong Nguyen",
      "Steve Hood",
      "Ryan Musso",
      "Ceridwen Hopely",
      "Steve Titus",
      "Minh Doan",
      "Iain Styles",
      "Alexander Krull"
    ],
    "abstract": "The large volume and variety of imaging data from high-throughput screening\n(HTS) in the pharmaceutical industry present an excellent resource for training\nvirtual staining models. However, the potential of models trained under one set\nof experimental conditions to generalize to other conditions remains\nunderexplored. This study systematically investigates whether data from three\ncell types (lung, ovarian, and breast) and two phenotypes (toxic and non-toxic\nconditions) commonly found in HTS can effectively train virtual staining models\nto generalize across three typical HTS distribution shifts: unseen phenotypes,\nunseen cell types, and the combination of both. Utilizing a dataset of 772,416\npaired bright-field, cytoplasm, nuclei, and DNA-damage stain images, we\nevaluate the generalization capabilities of models across pixel-based,\ninstance-wise, and biological-feature-based levels. Our findings indicate that\ntraining virtual nuclei and cytoplasm models on non-toxic condition samples not\nonly generalizes to toxic condition samples but leads to improved performance\nacross all evaluation levels compared to training on toxic condition samples.\nGeneralization to unseen cell types shows variability depending on the cell\ntype; models trained on ovarian or lung cell samples often perform well under\nother conditions, while those trained on breast cell samples consistently show\npoor generalization. Generalization to unseen cell types and phenotypes shows\ngood generalization across all levels of evaluation compared to addressing\nunseen cell types alone. This study represents the first large-scale,\ndata-centric analysis of the generalization capability of virtual staining\nmodels trained on diverse HTS datasets, providing valuable strategies for\nexperimental training data generation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06979v3",
    "published_date": "2024-07-09 15:54:06 UTC",
    "updated_date": "2024-09-30 08:51:46 UTC"
  },
  {
    "arxiv_id": "2407.06976v1",
    "title": "Advancing Manuscript Metadata: Work in Progress at the Jagiellonian University",
    "authors": [
      "Luiz do Valle Miranda",
      "Krzysztof Kutt",
      "Grzegorz J. Nalepa"
    ],
    "abstract": "As part of ongoing research projects, three Jagiellonian University units --\nthe Jagiellonian University Museum, the Jagiellonian University Archives, and\nthe Jagiellonian Library -- are collaborating to digitize cultural heritage\ndocuments, describe them in detail, and then integrate these descriptions into\na linked data cloud. Achieving this goal requires, as a first step, the\ndevelopment of a metadata model that, on the one hand, complies with existing\nstandards, on the other hand, allows interoperability with other systems, and\non the third, captures all the elements of description established by the\ncurators of the collections. In this paper, we present a report on the current\nstatus of the work, in which we outline the most important requirements for the\ndata model under development and then make a detailed comparison with the two\nstandards that are the most relevant from the point of view of collections:\nEuropeana Data Model used in Europeana and Encoded Archival Description used in\nKalliope.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "9 pages; submitted to TPLD 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.06976v1",
    "published_date": "2024-07-09 15:52:06 UTC",
    "updated_date": "2024-07-09 15:52:06 UTC"
  },
  {
    "arxiv_id": "2407.06972v1",
    "title": "Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects",
    "authors": [
      "Krzysztof Kutt",
      "Jakub Gomułka",
      "Luiz do Valle Miranda",
      "Grzegorz J. Nalepa"
    ],
    "abstract": "In response to several cultural heritage initiatives at the Jagiellonian\nUniversity, we have developed a new digitization workflow in collaboration with\nthe Jagiellonian Library (JL). The solution is based on easy-to-access\ntechnological solutions -- Microsoft 365 cloud with MS Excel files as metadata\nacquisition interfaces, Office Script for validation, and MS Sharepoint for\nstorage -- that allows metadata acquisition by domain experts (philologists,\nhistorians, philosophers, librarians, archivists, curators, etc.) regardless of\ntheir experience with information systems. The ultimate goal is to create a\nknowledge graph that describes the analyzed holdings, linked to general\nknowledge bases, as well as to other cultural heritage collections, so careful\nattention is paid to the high accuracy of metadata and proper links to external\nsources. The workflow has already been evaluated in two pilots in the DiHeLib\nproject focused on digitizing the so-called \"Berlin Collection\" and in two\nworkshops with international guests, which allowed for its refinement and\nconfirmation of its correctness and usability for JL. As the proposed workflow\ndoes not interfere with existing systems or domain guidelines regarding\ndigitization and basic metadata collection in a given institution (e.g., file\ntype, image quality, use of Dublin Core/MARC-21), but extends them in order to\nenable rich metadata collection, not previously possible, we believe that it\ncould be of interest to all GLAMs (galleries, libraries, archives, and\nmuseums).",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.DL",
    "comment": "19 pages; submitted to Multimedia Tools and Applications",
    "pdf_url": "http://arxiv.org/pdf/2407.06972v1",
    "published_date": "2024-07-09 15:49:47 UTC",
    "updated_date": "2024-07-09 15:49:47 UTC"
  },
  {
    "arxiv_id": "2407.07135v1",
    "title": "Improving Out-of-Distribution Detection by Combining Existing Post-hoc Methods",
    "authors": [
      "Paul Novello",
      "Yannick Prudent",
      "Joseba Dalmau",
      "Corentin Friedrich",
      "Yann Pequignot"
    ],
    "abstract": "Since the seminal paper of Hendrycks et al. arXiv:1610.02136, Post-hoc deep\nOut-of-Distribution (OOD) detection has expanded rapidly. As a result,\npractitioners working on safety-critical applications and seeking to improve\nthe robustness of a neural network now have a plethora of methods to choose\nfrom. However, no method outperforms every other on every dataset\narXiv:2210.07242, so the current best practice is to test all the methods on\nthe datasets at hand. This paper shifts focus from developing new methods to\neffectively combining existing ones to enhance OOD detection. We propose and\ncompare four different strategies for integrating multiple detection scores\ninto a unified OOD detector, based on techniques such as majority vote,\nempirical and copulas-based Cumulative Distribution Function modeling, and\nmultivariate quantiles based on optimal transport. We extend common OOD\nevaluation metrics -- like AUROC and FPR at fixed TPR rates -- to these\nmulti-dimensional OOD detectors, allowing us to evaluate them and compare them\nwith individual methods on extensive benchmarks. Furthermore, we propose a\nseries of guidelines to choose what OOD detectors to combine in more realistic\nsettings, i.e. in the absence of known OOD data, relying on principles drawn\nfrom Outlier Exposure arXiv:1812.04606. The code is available at\nhttps://github.com/paulnovello/multi-ood.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07135v1",
    "published_date": "2024-07-09 15:46:39 UTC",
    "updated_date": "2024-07-09 15:46:39 UTC"
  },
  {
    "arxiv_id": "2407.06950v1",
    "title": "Spanish TrOCR: Leveraging Transfer Learning for Language Adaptation",
    "authors": [
      "Filipe Lauar",
      "Valentin Laurent"
    ],
    "abstract": "This study explores the transfer learning capabilities of the TrOCR\narchitecture to Spanish. TrOCR is a transformer-based Optical Character\nRecognition (OCR) model renowned for its state-of-the-art performance in\nEnglish benchmarks. Inspired by Li et al. assertion regarding its adaptability\nto multilingual text recognition, we investigate two distinct approaches to\nadapt the model to a new language: integrating an English TrOCR encoder with a\nlanguage specific decoder and train the model on this specific language, and\nfine-tuning the English base TrOCR model on a new language data. Due to the\nscarcity of publicly available datasets, we present a resource-efficient\npipeline for creating OCR datasets in any language, along with a comprehensive\nbenchmark of the different image generation methods employed with a focus on\nVisual Rich Documents (VRDs). Additionally, we offer a comparative analysis of\nthe two approaches for the Spanish language, demonstrating that fine-tuning the\nEnglish TrOCR on Spanish yields superior recognition than the language specific\ndecoder for a fixed dataset size. We evaluate our model employing character and\nword error rate metrics on a public available printed dataset, comparing the\nperformance against other open-source and cloud OCR spanish models. As far as\nwe know, these resources represent the best open-source model for OCR in\nSpanish. The Spanish TrOCR models are publicly available on HuggingFace [20]\nand the code to generate the dataset is available on Github [25].",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.06950v1",
    "published_date": "2024-07-09 15:31:41 UTC",
    "updated_date": "2024-07-09 15:31:41 UTC"
  },
  {
    "arxiv_id": "2407.06946v2",
    "title": "Self-Recognition in Language Models",
    "authors": [
      "Tim R. Davidson",
      "Viacheslav Surkov",
      "Veniamin Veselovsky",
      "Giuseppe Russo",
      "Robert West",
      "Caglar Gulcehre"
    ],
    "abstract": "A rapidly growing number of applications rely on a small set of closed-source\nlanguage models (LMs). This dependency might introduce novel security risks if\nLMs develop self-recognition capabilities. Inspired by human identity\nverification methods, we propose a novel approach for assessing\nself-recognition in LMs using model-generated \"security questions\". Our test\ncan be externally administered to monitor frontier models as it does not\nrequire access to internal model parameters or output probabilities. We use our\ntest to examine self-recognition in ten of the most capable open- and\nclosed-source LMs currently publicly available. Our extensive experiments found\nno empirical evidence of general or consistent self-recognition in any examined\nLM. Instead, our results suggest that given a set of alternatives, LMs seek to\npick the \"best\" answer, regardless of its origin. Moreover, we find indications\nthat preferences about which models produce the best answers are consistent\nacross LMs. We additionally uncover novel insights on position bias\nconsiderations for LMs in multiple-choice settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024, code to reproduce experiments and replicate\n  findings available at https://github.com/trdavidson/self-recognition",
    "pdf_url": "http://arxiv.org/pdf/2407.06946v2",
    "published_date": "2024-07-09 15:23:28 UTC",
    "updated_date": "2024-10-10 11:07:47 UTC"
  },
  {
    "arxiv_id": "2407.06941v1",
    "title": "Raply: A profanity-mitigated rap generator",
    "authors": [
      "Omar Manil Bendali",
      "Samir Ferroum",
      "Ekaterina Kozachenko",
      "Youssef Parviz",
      "Hanna Shcharbakova",
      "Anna Tokareva",
      "Shemair Williams"
    ],
    "abstract": "The task of writing rap is challenging and involves producing complex rhyming\nschemes, yet meaningful lyrics. In this work, we propose Raply, a fine-tuned\nGPT-2 model capable of producing meaningful rhyming text in the style of rap.\nIn addition to its rhyming capabilities, the model is able to generate less\noffensive content. It was achieved through the fine-tuning the model on a new\ndataset Mitislurs, a profanity-mitigated corpus. We evaluate the output of the\nmodel on two criteria: 1) rhyming based on the rhyme density metric; 2)\nprofanity content, using the list of profanities for the English language. To\nour knowledge, this is the first attempt at profanity mitigation for rap lyrics\ngeneration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06941v1",
    "published_date": "2024-07-09 15:18:56 UTC",
    "updated_date": "2024-07-09 15:18:56 UTC"
  },
  {
    "arxiv_id": "2407.06930v1",
    "title": "Integrating Ontology Design with the CRISP-DM in the context of Cyber-Physical Systems Maintenance",
    "authors": [
      "Milapji Singh Gill",
      "Tom Westermann",
      "Gernot Steindl",
      "Felix Gehlhoff",
      "Alexander Fay"
    ],
    "abstract": "In the following contribution, a method is introduced that integrates domain\nexpert-centric ontology design with the Cross-Industry Standard Process for\nData Mining (CRISP-DM). This approach aims to efficiently build an\napplication-specific ontology tailored to the corrective maintenance of\nCyber-Physical Systems (CPS). The proposed method is divided into three phases.\nIn phase one, ontology requirements are systematically specified, defining the\nrelevant knowledge scope. Accordingly, CPS life cycle data is contextualized in\nphase two using domain-specific ontological artifacts. This formalized domain\nknowledge is then utilized in the CRISP-DM to efficiently extract new insights\nfrom the data. Finally, the newly developed data-driven model is employed to\npopulate and expand the ontology. Thus, information extracted from this model\nis semantically annotated and aligned with the existing ontology in phase\nthree. The applicability of this method has been evaluated in an anomaly\ndetection case study for a modular process plant.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06930v1",
    "published_date": "2024-07-09 15:06:47 UTC",
    "updated_date": "2024-07-09 15:06:47 UTC"
  },
  {
    "arxiv_id": "2407.19096v1",
    "title": "AI Companions Reduce Loneliness",
    "authors": [
      "Julian De Freitas",
      "Ahmet K Uguralp",
      "Zeliha O Uguralp",
      "Puntoni Stefano"
    ],
    "abstract": "Chatbots are now able to engage in sophisticated conversations with consumers\nin the domain of relationships, providing a potential coping solution to\nwidescale societal loneliness. Behavioral research provides little insight into\nwhether these applications are effective at alleviating loneliness. We address\nthis question by focusing on AI companions applications designed to provide\nconsumers with synthetic interaction partners. Studies 1 and 2 find suggestive\nevidence that consumers use AI companions to alleviate loneliness, by employing\na novel methodology for fine tuning large language models to detect loneliness\nin conversations and reviews. Study 3 finds that AI companions successfully\nalleviate loneliness on par only with interacting with another person, and more\nthan other activities such watching YouTube videos. Moreover, consumers\nunderestimate the degree to which AI companions improve their loneliness. Study\n4 uses a longitudinal design and finds that an AI companion consistently\nreduces loneliness over the course of a week. Study 5 provides evidence that\nboth the chatbots' performance and, especially, whether it makes users feel\nheard, explain reductions in loneliness. Study 6 provides an additional\nrobustness check for the loneliness alleviating benefits of AI companions.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19096v1",
    "published_date": "2024-07-09 15:04:08 UTC",
    "updated_date": "2024-07-09 15:04:08 UTC"
  },
  {
    "arxiv_id": "2407.06910v1",
    "title": "Fine-grained large-scale content recommendations for MSX sellers",
    "authors": [
      "Manpreet Singh",
      "Ravdeep Pasricha",
      "Ravi Prasad Kondapalli",
      "Kiran R",
      "Nitish Singh",
      "Akshita Agarwalla",
      "Manoj R",
      "Manish Prabhakar",
      "Laurent Boué"
    ],
    "abstract": "One of the most critical tasks of Microsoft sellers is to meticulously track\nand nurture potential business opportunities through proactive engagement and\ntailored solutions. Recommender systems play a central role to help sellers\nachieve their goals. In this paper, we present a content recommendation model\nwhich surfaces various types of content (technical documentation, comparison\nwith competitor products, customer success stories etc.) that sellers can share\nwith their customers or use for their own self-learning. The model operates at\nthe opportunity level which is the lowest possible granularity and the most\nrelevant one for sellers. It is based on semantic matching between metadata\nfrom the contents and carefully selected attributes of the opportunities.\nConsidering the volume of seller-managed opportunities in organizations such as\nMicrosoft, we show how to perform efficient semantic matching over a very large\nnumber of opportunity-content combinations. The main challenge is to ensure\nthat the top-5 relevant contents for each opportunity are recommended out of a\ntotal of $\\approx 40,000$ published contents. We achieve this target through an\nextensive comparison of different model architectures and feature selection.\nFinally, we further examine the quality of the recommendations in a\nquantitative manner using a combination of human domain experts as well as by\nusing the recently proposed \"LLM as a judge\" framework.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06910v1",
    "published_date": "2024-07-09 14:46:09 UTC",
    "updated_date": "2024-07-09 14:46:09 UTC"
  },
  {
    "arxiv_id": "2407.06909v1",
    "title": "Intercepting Unauthorized Aerial Robots in Controlled Airspace Using Reinforcement Learning",
    "authors": [
      "Francisco Giral",
      "Ignacio Gómez",
      "Soledad Le Clainche"
    ],
    "abstract": "The proliferation of unmanned aerial vehicles (UAVs) in controlled airspace\npresents significant risks, including potential collisions, disruptions to air\ntraffic, and security threats. Ensuring the safe and efficient operation of\nairspace, particularly in urban environments and near critical infrastructure,\nnecessitates effective methods to intercept unauthorized or non-cooperative\nUAVs. This work addresses the critical need for robust, adaptive systems\ncapable of managing such threats through the use of Reinforcement Learning\n(RL). We present a novel approach utilizing RL to train fixed-wing UAV pursuer\nagents for intercepting dynamic evader targets. Our methodology explores both\nmodel-based and model-free RL algorithms, specifically DreamerV3, Truncated\nQuantile Critics (TQC), and Soft Actor-Critic (SAC). The training and\nevaluation of these algorithms were conducted under diverse scenarios,\nincluding unseen evasion strategies and environmental perturbations. Our\napproach leverages high-fidelity flight dynamics simulations to create\nrealistic training environments. This research underscores the importance of\ndeveloping intelligent, adaptive control systems for UAV interception,\nsignificantly contributing to the advancement of secure and efficient airspace\nmanagement. It demonstrates the potential of RL to train systems capable of\nautonomously achieving these critical tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06909v1",
    "published_date": "2024-07-09 14:45:47 UTC",
    "updated_date": "2024-07-09 14:45:47 UTC"
  },
  {
    "arxiv_id": "2407.06904v1",
    "title": "Hypergraph based Understanding for Document Semantic Entity Recognition",
    "authors": [
      "Qiwei Li",
      "Zuchao Li",
      "Ping Wang",
      "Haojun Ai",
      "Hai Zhao"
    ],
    "abstract": "Semantic entity recognition is an important task in the field of\nvisually-rich document understanding. It distinguishes the semantic types of\ntext by analyzing the position relationship between text nodes and the relation\nbetween text content. The existing document understanding models mainly focus\non entity categories while ignoring the extraction of entity boundaries. We\nbuild a novel hypergraph attention document semantic entity recognition\nframework, HGA, which uses hypergraph attention to focus on entity boundaries\nand entity categories at the same time. It can conduct a more detailed analysis\nof the document text representation analyzed by the upstream model and achieves\na better performance of semantic information. We apply this method on the basis\nof GraphLayoutLM to construct a new semantic entity recognition model\nHGALayoutLM. Our experiment results on FUNSD, CORD, XFUND and SROIE show that\nour method can effectively improve the performance of semantic entity\nrecognition tasks based on the original model. The results of HGALayoutLM on\nFUNSD and XFUND reach the new state-of-the-art results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06904v1",
    "published_date": "2024-07-09 14:35:49 UTC",
    "updated_date": "2024-07-09 14:35:49 UTC"
  },
  {
    "arxiv_id": "2407.06902v1",
    "title": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective",
    "authors": [
      "Shahana Ibrahim",
      "Panagiotis A. Traganitis",
      "Xiao Fu",
      "Georgios B. Giannakis"
    ],
    "abstract": "One of the primary catalysts fueling advances in artificial intelligence (AI)\nand machine learning (ML) is the availability of massive, curated datasets. A\ncommonly used technique to curate such massive datasets is crowdsourcing, where\ndata are dispatched to multiple annotators. The annotator-produced labels are\nthen fused to serve downstream learning and inference tasks. This annotation\nprocess often creates noisy labels due to various reasons, such as the limited\nexpertise, or unreliability of annotators, among others. Therefore, a core\nobjective in crowdsourcing is to develop methods that effectively mitigate the\nnegative impact of such label noise on learning tasks. This feature article\nintroduces advances in learning from noisy crowdsourced labels. The focus is on\nkey crowdsourcing models and their methodological treatments, from classical\nstatistical models to recent deep learning-based approaches, emphasizing\nanalytical insights and algorithmic developments. In particular, this article\nreviews the connections between signal processing (SP) theory and methods, such\nas identifiability of tensor and nonnegative matrix factorization, and novel,\nprincipled solutions of longstanding challenges in crowdsourcing -- showing how\nSP perspectives drive the advancements of this field. Furthermore, this article\ntouches upon emerging topics that are critical for developing cutting-edge\nAI/ML systems, such as crowdsourcing in reinforcement learning with human\nfeedback (RLHF) and direct preference optimization (DPO) that are key\ntechniques for fine-tuning large language models (LLMs).",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06902v1",
    "published_date": "2024-07-09 14:34:40 UTC",
    "updated_date": "2024-07-09 14:34:40 UTC"
  },
  {
    "arxiv_id": "2407.06886v7",
    "title": "Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI",
    "authors": [
      "Yang Liu",
      "Weixing Chen",
      "Yongjie Bai",
      "Xiaodan Liang",
      "Guanbin Li",
      "Wen Gao",
      "Liang Lin"
    ],
    "abstract": "Embodied Artificial Intelligence (Embodied AI) is crucial for achieving\nArtificial General Intelligence (AGI) and serves as a foundation for various\napplications that bridge cyberspace and the physical world. Recently, the\nemergence of Multi-modal Large Models (MLMs) and World Models (WMs) have\nattracted significant attention due to their remarkable perception,\ninteraction, and reasoning capabilities, making them a promising architecture\nfor the brain of embodied agents. However, there is no comprehensive survey for\nEmbodied AI in the era of MLMs. In this survey, we give a comprehensive\nexploration of the latest advancements in Embodied AI. Our analysis firstly\nnavigates through the forefront of representative works of embodied robots and\nsimulators, to fully understand the research focuses and their limitations.\nThen, we analyze four main research targets: 1) embodied perception, 2)\nembodied interaction, 3) embodied agent, and 4) sim-to-real adaptation,\ncovering the state-of-the-art methods, essential paradigms, and comprehensive\ndatasets. Additionally, we explore the complexities of MLMs in virtual and real\nembodied agents, highlighting their significance in facilitating interactions\nin dynamic digital and physical environments. Finally, we summarize the\nchallenges and limitations of embodied AI and discuss their potential future\ndirections. We hope this survey will serve as a foundational reference for the\nresearch community and inspire continued innovation. The associated project can\nbe found at https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "The first comprehensive review of Embodied AI in the era of MLMs, 39\n  pages. We also provide the paper list for Embodied AI:\n  https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List",
    "pdf_url": "http://arxiv.org/pdf/2407.06886v7",
    "published_date": "2024-07-09 14:14:47 UTC",
    "updated_date": "2024-08-26 03:25:12 UTC"
  },
  {
    "arxiv_id": "2407.06866v2",
    "title": "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context",
    "authors": [
      "Victoria R. Li",
      "Yida Chen",
      "Naomi Saphra"
    ],
    "abstract": "While the biases of language models in production are extensively documented,\nthe biases of their guardrails have been neglected. This paper studies how\ncontextual information about the user influences the likelihood of an LLM to\nrefuse to execute a request. By generating user biographies that offer\nideological and demographic information, we find a number of biases in\nguardrail sensitivity on GPT-3.5. Younger, female, and Asian-American personas\nare more likely to trigger a refusal guardrail when requesting censored or\nillegal information. Guardrails are also sycophantic, refusing to comply with\nrequests for a political position the user is likely to disagree with. We find\nthat certain identity groups and seemingly innocuous information, e.g., sports\nfandom, can elicit changes in guardrail sensitivity similar to direct\nstatements of political ideology. For each demographic category and even for\nAmerican football team fandom, we find that ChatGPT appears to infer a likely\npolitical ideology and modify guardrail behavior accordingly.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06866v2",
    "published_date": "2024-07-09 13:53:38 UTC",
    "updated_date": "2024-07-10 18:47:55 UTC"
  },
  {
    "arxiv_id": "2407.06862v1",
    "title": "Trust and Resilience in Federated Learning Through Smart Contracts Enabled Decentralized Systems",
    "authors": [
      "Lorenzo Cassano",
      "Jacopo D'Abramo",
      "Siraj Munir",
      "Stefano Ferretti"
    ],
    "abstract": "In this paper, we present a study of a Federated Learning (FL) system, based\non the use of decentralized architectures to ensure trust and increase\nreliability. The system is based on the idea that the FL collaborators upload\nthe (ciphered) model parameters on the Inter-Planetary File System (IPFS) and\ninteract with a dedicated smart contract to track their behavior. Thank to this\nsmart contract, the phases of parameter updates are managed efficiently,\nthereby strengthening data security. We have carried out an experimental study\nthat exploits two different methods of weight aggregation, i.e., a classic\naveraging scheme and a federated proximal aggregation. The results confirm the\nfeasibility of the proposal.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "TRUSTCHAIN workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.06862v1",
    "published_date": "2024-07-09 13:50:32 UTC",
    "updated_date": "2024-07-09 13:50:32 UTC"
  },
  {
    "arxiv_id": "2407.18921v2",
    "title": "Mobile Edge Intelligence for Large Language Models: A Contemporary Survey",
    "authors": [
      "Guanqiao Qu",
      "Qiyuan Chen",
      "Wei Wei",
      "Zheng Lin",
      "Xianhao Chen",
      "Kaibin Huang"
    ],
    "abstract": "On-device large language models (LLMs), referring to running LLMs on edge\ndevices, have raised considerable interest since they are more cost-effective,\nlatency-efficient, and privacy-preserving compared with the cloud paradigm.\nNonetheless, the performance of on-device LLMs is intrinsically constrained by\nresource limitations on edge devices. Sitting between cloud and on-device AI,\nmobile edge intelligence (MEI) presents a viable solution by provisioning AI\ncapabilities at the edge of mobile networks, enabling end users to offload\nheavy AI computation to capable edge servers nearby. This article provides a\ncontemporary survey on harnessing MEI for LLMs. We begin by illustrating\nseveral killer applications to demonstrate the urgent need for deploying LLMs\nat the network edge. Next, we present the preliminaries of LLMs and MEI,\nfollowed by resource-efficient LLM techniques. We then present an architectural\noverview of MEI for LLMs (MEI4LLM), outlining its core components and how it\nsupports the deployment of LLMs. Subsequently, we delve into various aspects of\nMEI4LLM, extensively covering edge LLM caching and delivery, edge LLM training,\nand edge LLM inference. Finally, we identify future research opportunities. We\nhope this article inspires researchers in the field to leverage mobile edge\ncomputing to facilitate LLM deployment, thereby unleashing the potential of\nLLMs across various privacy- and delay-sensitive applications.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "42 pages, 17 figures. This paper has been accepted by IEEE\n  Communications Surveys & Tutorials",
    "pdf_url": "http://arxiv.org/pdf/2407.18921v2",
    "published_date": "2024-07-09 13:47:05 UTC",
    "updated_date": "2025-03-20 05:23:42 UTC"
  },
  {
    "arxiv_id": "2407.06852v1",
    "title": "TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis",
    "authors": [
      "Jacob Thrasher",
      "Alina Devkota",
      "Ahmed Tafti",
      "Binod Bhattarai",
      "Prashnna Gyawali"
    ],
    "abstract": "Alzheimer's Dementia (AD) represents one of the most pressing challenges in\nthe field of neurodegenerative disorders, with its progression analysis being\ncrucial for understanding disease dynamics and developing targeted\ninterventions. Recent advancements in deep learning and various representation\nlearning strategies, including self-supervised learning (SSL), have shown\nsignificant promise in enhancing medical image analysis, providing innovative\nways to extract meaningful patterns from complex data. Notably, the computer\nvision literature has demonstrated that incorporating supervisory signals into\nSSL can further augment model performance by guiding the learning process with\nadditional relevant information. However, the application of such supervisory\nsignals in the context of disease progression analysis remains largely\nunexplored. This gap is particularly pronounced given the inherent challenges\nof incorporating both event and time-to-event information into the learning\nparadigm. Addressing this, we propose a novel framework, Time and Even-aware\nSSL (TE-SSL), which integrates time-to-event and event data as supervisory\nsignals to refine the learning process. Our comparative analysis with existing\nSSL-based methods in the downstream task of survival analysis shows superior\nperformance across standard metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8.5 pages, 2 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.06852v1",
    "published_date": "2024-07-09 13:41:32 UTC",
    "updated_date": "2024-07-09 13:41:32 UTC"
  },
  {
    "arxiv_id": "2407.06849v1",
    "title": "TeVAE: A Variational Autoencoder Approach for Discrete Online Anomaly Detection in Variable-state Multivariate Time-series Data",
    "authors": [
      "Lucas Correia",
      "Jan-Christoph Goos",
      "Philipp Klein",
      "Thomas Bäck",
      "Anna V. Kononova"
    ],
    "abstract": "As attention to recorded data grows in the realm of automotive testing and\nmanual evaluation reaches its limits, there is a growing need for automatic\nonline anomaly detection. This real-world data is complex in many ways and\nrequires the modelling of testee behaviour. To address this, we propose a\ntemporal variational autoencoder (TeVAE) that can detect anomalies with minimal\nfalse positives when trained on unlabelled data. Our approach also avoids the\nbypass phenomenon and introduces a new method to remap individual windows to a\ncontinuous time series. Furthermore, we propose metrics to evaluate the\ndetection delay and root-cause capability of our approach and present results\nfrom experiments on a real-world industrial data set. When properly configured,\nTeVAE flags anomalies only 6% of the time wrongly and detects 65% of anomalies\npresent. It also has the potential to perform well with a smaller training and\nvalidation subset but requires a more sophisticated threshold estimation\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to Studies in Computational Intelligence Journal. arXiv\n  admin note: substantial text overlap with arXiv:2309.02253",
    "pdf_url": "http://arxiv.org/pdf/2407.06849v1",
    "published_date": "2024-07-09 13:32:33 UTC",
    "updated_date": "2024-07-09 13:32:33 UTC"
  },
  {
    "arxiv_id": "2407.12856v1",
    "title": "AI AI Bias: Large Language Models Favor Their Own Generated Content",
    "authors": [
      "Walter Laurito",
      "Benjamin Davis",
      "Peli Grietzer",
      "Tomáš Gavenčiak",
      "Ada Böhm",
      "Jan Kulveit"
    ],
    "abstract": "Are large language models (LLMs) biased towards text generated by LLMs over\ntext authored by humans, leading to possible anti-human bias? Utilizing a\nclassical experimental design inspired by employment discrimination studies, we\ntested widely-used LLMs, including GPT-3.5 and GPT4, in binary-choice\nscenarios. These involved LLM-based agents selecting between products and\nacademic papers described either by humans or LLMs under identical conditions.\nOur results show a consistent tendency for LLM-based AIs to prefer\nLLM-generated content. This suggests the possibility of AI systems implicitly\ndiscriminating against humans, giving AI agents an unfair advantage.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2407.12856v1",
    "published_date": "2024-07-09 13:15:14 UTC",
    "updated_date": "2024-07-09 13:15:14 UTC"
  },
  {
    "arxiv_id": "2407.18334v1",
    "title": "A Comprehensive Analysis of Machine Learning Models for Algorithmic Trading of Bitcoin",
    "authors": [
      "Abdul Jabbar",
      "Syed Qaisar Jalil"
    ],
    "abstract": "This study evaluates the performance of 41 machine learning models, including\n21 classifiers and 20 regressors, in predicting Bitcoin prices for algorithmic\ntrading. By examining these models under various market conditions, we\nhighlight their accuracy, robustness, and adaptability to the volatile\ncryptocurrency market. Our comprehensive analysis reveals the strengths and\nlimitations of each model, providing critical insights for developing effective\ntrading strategies. We employ both machine learning metrics (e.g., Mean\nAbsolute Error, Root Mean Squared Error) and trading metrics (e.g., Profit and\nLoss percentage, Sharpe Ratio) to assess model performance. Our evaluation\nincludes backtesting on historical data, forward testing on recent unseen data,\nand real-world trading scenarios, ensuring the robustness and practical\napplicability of our models. Key findings demonstrate that certain models, such\nas Random Forest and Stochastic Gradient Descent, outperform others in terms of\nprofit and risk management. These insights offer valuable guidance for traders\nand researchers aiming to leverage machine learning for cryptocurrency trading.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.TR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18334v1",
    "published_date": "2024-07-09 13:07:43 UTC",
    "updated_date": "2024-07-09 13:07:43 UTC"
  },
  {
    "arxiv_id": "2407.06826v1",
    "title": "VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction",
    "authors": [
      "Thanh-Dat Nguyen",
      "Tung Do-Viet",
      "Hung Nguyen-Duy",
      "Tuan-Hai Luu",
      "Hung Le",
      "Bach Le",
      "Patanamon",
      "Thongtanunam"
    ],
    "abstract": "Businesses need to query visually rich documents (VRDs) like receipts,\nmedical records, and insurance forms to make decisions. Existing techniques for\nextracting entities from VRDs struggle with new layouts or require extensive\npre-training data. We introduce VRDSynth, a program synthesis method to\nautomatically extract entity relations from multilingual VRDs without\npre-training data. To capture the complexity of VRD domain, we design a\ndomain-specific language (DSL) to capture spatial and textual relations to\ndescribe the synthesized programs. Along with this, we also derive a new\nsynthesis algorithm utilizing frequent spatial relations, search space pruning,\nand a combination of positive, negative, and exclusive programs to improve\ncoverage.\n  We evaluate VRDSynth on the FUNSD and XFUND benchmarks for semantic entity\nlinking, consisting of 1,592 forms in 8 languages. VRDSynth outperforms\nstate-of-the-art pre-trained models (LayoutXLM, InfoXLMBase, and\nXLMRobertaBase) in 5, 6, and 7 out of 8 languages, respectively, improving the\nF1 score by 42% over LayoutXLM in English. To test the extensibility of the\nmodel, we further improve VRDSynth with automated table recognition, creating\nVRDSynth(Table), and compare it with extended versions of the pre-trained\nmodels, InfoXLM(Large) and XLMRoberta(Large). VRDSynth(Table) outperforms these\nbaselines in 4 out of 8 languages and in average F1 score. VRDSynth also\nsignificantly reduces memory footprint (1M and 380MB vs. 1.48GB and 3GB for\nLayoutXLM) while maintaining similar time efficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in ISSTA'24",
    "pdf_url": "http://arxiv.org/pdf/2407.06826v1",
    "published_date": "2024-07-09 12:59:58 UTC",
    "updated_date": "2024-07-09 12:59:58 UTC"
  },
  {
    "arxiv_id": "2407.06823v1",
    "title": "Cue Point Estimation using Object Detection",
    "authors": [
      "Giulia Argüello",
      "Luca A. Lanzendörfer",
      "Roger Wattenhofer"
    ],
    "abstract": "Cue points indicate possible temporal boundaries in a transition between two\npieces of music in DJ mixing and constitute a crucial element in autonomous DJ\nsystems as well as for live mixing. In this work, we present a novel method for\nautomatic cue point estimation, interpreted as a computer vision object\ndetection task. Our proposed system is based on a pre-trained object detection\ntransformer which we fine-tune on our novel cue point dataset. Our provided\ndataset contains 21k manually annotated cue points from human experts as well\nas metronome information for nearly 5k individual tracks, making this dataset\n35x larger than the previously available cue point dataset. Unlike previous\nmethods, our approach does not require low-level musical information analysis,\nwhile demonstrating increased precision in retrieving cue point positions.\nMoreover, our proposed method demonstrates high adherence to phrasing, a type\nof high-level music structure commonly emphasized in electronic dance music.\nThe code, model checkpoints, and dataset are made publicly available.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06823v1",
    "published_date": "2024-07-09 12:56:30 UTC",
    "updated_date": "2024-07-09 12:56:30 UTC"
  },
  {
    "arxiv_id": "2407.19098v2",
    "title": "Evaluating Human-AI Collaboration: A Review and Methodological Framework",
    "authors": [
      "George Fragiadakis",
      "Christos Diou",
      "George Kousiouris",
      "Mara Nikolaidou"
    ],
    "abstract": "The use of artificial intelligence (AI) in working environments with\nindividuals, known as Human-AI Collaboration (HAIC), has become essential in a\nvariety of domains, boosting decision-making, efficiency, and innovation.\nDespite HAIC's wide potential, evaluating its effectiveness remains challenging\ndue to the complex interaction of components involved.\n  This paper provides a detailed analysis of existing HAIC evaluation\napproaches and develops a fresh paradigm for more effectively evaluating these\nsystems.\n  Our framework includes a structured decision tree which assists to select\nrelevant metrics based on distinct HAIC modes (AI-Centric, Human-Centric, and\nSymbiotic). By including both quantitative and qualitative metrics, the\nframework seeks to represent HAIC's dynamic and reciprocal nature, enabling the\nassessment of its impact and success. This framework's practicality can be\nexamined by its application in an array of domains, including manufacturing,\nhealthcare, finance, and education, each of which has unique challenges and\nrequirements. Our hope is that this study will facilitate further research on\nthe systematic evaluation of HAIC in real-world applications.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.19098v2",
    "published_date": "2024-07-09 12:52:22 UTC",
    "updated_date": "2025-03-07 08:27:00 UTC"
  },
  {
    "arxiv_id": "2407.06814v1",
    "title": "Historical Review of Variants of Informal Semantics for Logic Programs under Answer Set Semantics: GL'88, GL'91, GK'14, D-V'12",
    "authors": [
      "Yuliya Lierler"
    ],
    "abstract": "This note presents a historical survey of informal semantics that are\nassociated with logic programming under answer set semantics. We review these\nin uniform terms and align them with two paradigms: Answer Set Programming and\nASP-Prolog -- two prominent Knowledge Representation and Reasoning Paradigms in\nArtificial Intelligence. Under consideration in Theory and Practice of Logic\nProgramming (TPLP).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)",
    "pdf_url": "http://arxiv.org/pdf/2407.06814v1",
    "published_date": "2024-07-09 12:40:58 UTC",
    "updated_date": "2024-07-09 12:40:58 UTC"
  },
  {
    "arxiv_id": "2407.06813v4",
    "title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy",
    "authors": [
      "Zhenyu Guan",
      "Xiangyu Kong",
      "Fangwei Zhong",
      "Yizhou Wang"
    ],
    "abstract": "Diplomacy is one of the most sophisticated activities in human society,\ninvolving complex interactions among multiple parties that require skills in\nsocial reasoning, negotiation, and long-term strategic planning. Previous AI\nagents have demonstrated their ability to handle multi-step games and large\naction spaces in multi-agent tasks. However, diplomacy involves a staggering\nmagnitude of decision spaces, especially considering the negotiation stage\nrequired. While recent agents based on large language models (LLMs) have shown\npotential in various applications, they still struggle with extended planning\nperiods in complex multi-agent settings. Leveraging recent technologies for\nLLM-based agents, we aim to explore AI's potential to create a human-like agent\ncapable of executing comprehensive multi-agent missions by integrating three\nfundamental capabilities: 1) strategic planning with memory and reflection; 2)\ngoal-oriented negotiation with social reasoning; and 3) augmenting memory\nthrough self-play games for self-evolution without human in the loop.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06813v4",
    "published_date": "2024-07-09 12:37:54 UTC",
    "updated_date": "2024-10-23 06:39:57 UTC"
  },
  {
    "arxiv_id": "2407.06807v1",
    "title": "A Hybrid Training-time and Run-time Defense Against Adversarial Attacks in Modulation Classification",
    "authors": [
      "Lu Zhang",
      "Sangarapillai Lambotharan",
      "Gan Zheng",
      "Guisheng Liao",
      "Ambra Demontis",
      "Fabio Roli"
    ],
    "abstract": "Motivated by the superior performance of deep learning in many applications\nincluding computer vision and natural language processing, several recent\nstudies have focused on applying deep neural network for devising future\ngenerations of wireless networks. However, several recent works have pointed\nout that imperceptible and carefully designed adversarial examples (attacks)\ncan significantly deteriorate the classification accuracy. In this paper, we\ninvestigate a defense mechanism based on both training-time and run-time\ndefense techniques for protecting machine learning-based radio signal\n(modulation) classification against adversarial attacks. The training-time\ndefense consists of adversarial training and label smoothing, while the\nrun-time defense employs a support vector machine-based neural rejection (NR).\nConsidering a white-box scenario and real datasets, we demonstrate that our\nproposed techniques outperform existing state-of-the-art technologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in IEEE Wireless Communications Letters, vol. 11, no. 6,\n  pp. 1161-1165, June 2022",
    "pdf_url": "http://arxiv.org/pdf/2407.06807v1",
    "published_date": "2024-07-09 12:28:38 UTC",
    "updated_date": "2024-07-09 12:28:38 UTC"
  },
  {
    "arxiv_id": "2407.07133v1",
    "title": "Neuromimetic metaplasticity for adaptive continual learning",
    "authors": [
      "Suhee Cho",
      "Hyeonsu Lee",
      "Seungdae Baek",
      "Se-Bum Paik"
    ],
    "abstract": "Conventional intelligent systems based on deep neural network (DNN) models\nencounter challenges in achieving human-like continual learning due to\ncatastrophic forgetting. Here, we propose a metaplasticity model inspired by\nhuman working memory, enabling DNNs to perform catastrophic forgetting-free\ncontinual learning without any pre- or post-processing. A key aspect of our\napproach involves implementing distinct types of synapses from stable to\nflexible, and randomly intermixing them to train synaptic connections with\ndifferent degrees of flexibility. This strategy allowed the network to\nsuccessfully learn a continuous stream of information, even under unexpected\nchanges in input length. The model achieved a balanced tradeoff between memory\ncapacity and performance without requiring additional training or structural\nmodifications, dynamically allocating memory resources to retain both old and\nnew information. Furthermore, the model demonstrated robustness against data\npoisoning attacks by selectively filtering out erroneous memories, leveraging\nthe Hebb repetition effect to reinforce the retention of significant data.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "25 pages, 5 figures, 1 table, 4 supplementary figures",
    "pdf_url": "http://arxiv.org/pdf/2407.07133v1",
    "published_date": "2024-07-09 12:21:35 UTC",
    "updated_date": "2024-07-09 12:21:35 UTC"
  },
  {
    "arxiv_id": "2407.06798v2",
    "title": "It Cannot Be Right If It Was Written by AI: On Lawyers' Preferences of Documents Perceived as Authored by an LLM vs a Human",
    "authors": [
      "Jakub Harasta",
      "Tereza Novotná",
      "Jaromir Savelka"
    ],
    "abstract": "Large Language Models (LLMs) enable a future in which certain types of legal\ndocuments may be generated automatically. This has a great potential to\nstreamline legal processes, lower the cost of legal services, and dramatically\nincrease access to justice. While many researchers focus on proposing and\nevaluating LLM-based applications supporting tasks in the legal domain, there\nis a notable lack of investigations into how legal professionals perceive\ncontent if they believe an LLM has generated it. Yet, this is a critical point\nas over-reliance or unfounded scepticism may influence whether such documents\nbring about appropriate legal consequences. This study is the necessary\nanalysis of the ongoing transition towards mature generative AI systems.\nSpecifically, we examined whether the perception of legal documents' by lawyers\nand law students (n=75) varies based on their assumed origin (human-crafted vs\nAI-generated). The participants evaluated the documents, focusing on their\ncorrectness and language quality. Our analysis revealed a clear preference for\ndocuments perceived as crafted by a human over those believed to be generated\nby AI. At the same time, most participants expect the future in which documents\nwill be generated automatically. These findings could be leveraged by legal\npractitioners, policymakers, and legislators to implement and adopt legal\ndocument generation technology responsibly and to fuel the necessary\ndiscussions on how legal processes should be updated to reflect recent\ntechnological developments.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "40 pages, 12 figures. Accepted for publication with Artificial\n  Intelligence and Law (Springer Nature)",
    "pdf_url": "http://arxiv.org/pdf/2407.06798v2",
    "published_date": "2024-07-09 12:11:25 UTC",
    "updated_date": "2024-10-10 06:48:13 UTC"
  },
  {
    "arxiv_id": "2407.06797v1",
    "title": "ED-VAE: Entropy Decomposition of ELBO in Variational Autoencoders",
    "authors": [
      "Fotios Lygerakis",
      "Elmar Rueckert"
    ],
    "abstract": "Traditional Variational Autoencoders (VAEs) are constrained by the\nlimitations of the Evidence Lower Bound (ELBO) formulation, particularly when\nutilizing simplistic, non-analytic, or unknown prior distributions. These\nlimitations inhibit the VAE's ability to generate high-quality samples and\nprovide clear, interpretable latent representations. This work introduces the\nEntropy Decomposed Variational Autoencoder (ED-VAE), a novel re-formulation of\nthe ELBO that explicitly includes entropy and cross-entropy components. This\nreformulation significantly enhances model flexibility, allowing for the\nintegration of complex and non-standard priors. By providing more detailed\ncontrol over the encoding and regularization of latent spaces, ED-VAE not only\nimproves interpretability but also effectively captures the complex\ninteractions between latent variables and observed data, thus leading to better\ngenerative performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06797v1",
    "published_date": "2024-07-09 12:09:21 UTC",
    "updated_date": "2024-07-09 12:09:21 UTC"
  },
  {
    "arxiv_id": "2407.06796v1",
    "title": "Countermeasures Against Adversarial Examples in Radio Signal Classification",
    "authors": [
      "Lu Zhang",
      "Sangarapillai Lambotharan",
      "Gan Zheng",
      "Basil AsSadhan",
      "Fabio Roli"
    ],
    "abstract": "Deep learning algorithms have been shown to be powerful in many communication\nnetwork design problems, including that in automatic modulation classification.\nHowever, they are vulnerable to carefully crafted attacks called adversarial\nexamples. Hence, the reliance of wireless networks on deep learning algorithms\nposes a serious threat to the security and operation of wireless networks. In\nthis letter, we propose for the first time a countermeasure against adversarial\nexamples in modulation classification. Our countermeasure is based on a neural\nrejection technique, augmented by label smoothing and Gaussian noise injection,\nthat allows to detect and reject adversarial examples with high accuracy. Our\nresults demonstrate that the proposed countermeasure can protect deep-learning\nbased modulation classification systems against adversarial examples.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in IEEE Wireless Communications Letters, vol. 10, no. 8,\n  pp. 1830-1834, Aug. 2021",
    "pdf_url": "http://arxiv.org/pdf/2407.06796v1",
    "published_date": "2024-07-09 12:08:50 UTC",
    "updated_date": "2024-07-09 12:08:50 UTC"
  },
  {
    "arxiv_id": "2407.06785v1",
    "title": "Towards physics-informed neural networks for landslide prediction",
    "authors": [
      "Ashok Dahal",
      "Luigi Lombardo"
    ],
    "abstract": "For decades, solutions to regional scale landslide prediction have mostly\nrelied on data-driven models, by definition, disconnected from the physics of\nthe failure mechanism. The success and spread of such tools came from the\nability to exploit proxy variables rather than explicit geotechnical ones, as\nthe latter are prohibitive to acquire over broad landscapes. Our work\nimplements a Physics Informed Neural Network (PINN) approach, thereby adding to\na standard data-driven architecture, an intermediate constraint to solve for\nthe permanent deformation typical of Newmark slope stability methods. This\ntranslates into a neural network tasked with explicitly retrieving geotechnical\nparameters from common proxy variables and then minimize a loss function with\nrespect to the available coseismic landside inventory. The results are very\npromising, because our model not only produces excellent predictive performance\nin the form of standard susceptibility output, but in the process, also\ngenerates maps of the expected geotechnical properties at a regional scale.\nSuch architecture is therefore framed to tackle coseismic landslide prediction,\nsomething that, if confirmed in other studies, could open up towards PINN-based\nnear-real-time predictions.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06785v1",
    "published_date": "2024-07-09 11:54:49 UTC",
    "updated_date": "2024-07-09 11:54:49 UTC"
  },
  {
    "arxiv_id": "2407.06778v1",
    "title": "A BERT-based Empirical Study of Privacy Policies' Compliance with GDPR",
    "authors": [
      "Lu Zhang",
      "Nabil Moukafih",
      "Hamad Alamri",
      "Gregory Epiphaniou",
      "Carsten Maple"
    ],
    "abstract": "Since its implementation in May 2018, the General Data Protection Regulation\n(GDPR) has prompted businesses to revisit and revise their data handling\npractices to ensure compliance. The privacy policy, which serves as the primary\nmeans of informing users about their privacy rights and the data practices of\ncompanies, has been significantly updated by numerous businesses post-GDPR\nimplementation. However, many privacy policies remain packed with technical\njargon, lengthy explanations, and vague descriptions of data practices and user\nrights. This makes it a challenging task for users and regulatory authorities\nto manually verify the GDPR compliance of these privacy policies. In this\nstudy, we aim to address the challenge of compliance analysis between GDPR\n(Article 13) and privacy policies for 5G networks. We manually collected\nprivacy policies from almost 70 different 5G MNOs, and we utilized an automated\nBERT-based model for classification. We show that an encouraging 51$\\%$ of\ncompanies demonstrate a strong adherence to GDPR. In addition, we present the\nfirst study that provides current empirical evidence on the readability of\nprivacy policies for 5G network. we adopted readability analysis toolset that\nincorporates various established readability metrics. The findings empirically\nshow that the readability of the majority of current privacy policies remains a\nsignificant challenge. Hence, 5G providers need to invest considerable effort\ninto revising these documents to enhance both their utility and the overall\nuser experience.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Published in IEEE Conference on Communications and Network Security\n  (CNS), 2023",
    "pdf_url": "http://arxiv.org/pdf/2407.06778v1",
    "published_date": "2024-07-09 11:47:52 UTC",
    "updated_date": "2024-07-09 11:47:52 UTC"
  },
  {
    "arxiv_id": "2407.06774v1",
    "title": "A new validity measure for fuzzy c-means clustering",
    "authors": [
      "Dae-Won Kim",
      "Kwang H. Lee"
    ],
    "abstract": "A new cluster validity index is proposed for fuzzy clusters obtained from\nfuzzy c-means algorithm. The proposed validity index exploits inter-cluster\nproximity between fuzzy clusters. Inter-cluster proximity is used to measure\nthe degree of overlap between clusters. A low proximity value refers to\nwell-partitioned clusters. The best fuzzy c-partition is obtained by minimizing\ninter-cluster proximity with respect to c. Well-known data sets are tested to\nshow the effectiveness and reliability of the proposed index.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at FIP-2002",
    "pdf_url": "http://arxiv.org/pdf/2407.06774v1",
    "published_date": "2024-07-09 11:45:02 UTC",
    "updated_date": "2024-07-09 11:45:02 UTC"
  },
  {
    "arxiv_id": "2407.06765v1",
    "title": "A Generalization Bound for Nearly-Linear Networks",
    "authors": [
      "Eugene Golikov"
    ],
    "abstract": "We consider nonlinear networks as perturbations of linear ones. Based on this\napproach, we present novel generalization bounds that become non-vacuous for\nnetworks that are close to being linear. The main advantage over the previous\nworks which propose non-vacuous generalization bounds is that our bounds are\na-priori: performing the actual training is not required for evaluating the\nbounds. To the best of our knowledge, they are the first non-vacuous\ngeneralization bounds for neural nets possessing this property.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.06765v1",
    "published_date": "2024-07-09 11:20:01 UTC",
    "updated_date": "2024-07-09 11:20:01 UTC"
  },
  {
    "arxiv_id": "2407.12855v1",
    "title": "Large Language Models can impersonate politicians and other public figures",
    "authors": [
      "Steffen Herbold",
      "Alexander Trautsch",
      "Zlata Kikteva",
      "Annette Hautli-Janisz"
    ],
    "abstract": "Modern AI technology like Large language models (LLMs) has the potential to\npollute the public information sphere with made-up content, which poses a\nsignificant threat to the cohesion of societies at large. A wide range of\nresearch has shown that LLMs are capable of generating text of impressive\nquality, including persuasive political speech, text with a pre-defined style,\nand role-specific content. But there is a crucial gap in the literature: We\nlack large-scale and systematic studies of how capable LLMs are in\nimpersonating political and societal representatives and how the general public\njudges these impersonations in terms of authenticity, relevance and coherence.\nWe present the results of a study based on a cross-section of British society\nthat shows that LLMs are able to generate responses to debate questions that\nwere part of a broadcast political debate programme in the UK. The impersonated\nresponses are judged to be more authentic and relevant than the original\nresponses given by people who were impersonated. This shows two things: (1)\nLLMs can be made to contribute meaningfully to the public political debate and\n(2) there is a dire need to inform the general public of the potential harm\nthis can have on society.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2407.12855v1",
    "published_date": "2024-07-09 11:16:19 UTC",
    "updated_date": "2024-07-09 11:16:19 UTC"
  },
  {
    "arxiv_id": "2407.06762v3",
    "title": "Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social Interactions",
    "authors": [
      "Matteo Bortoletto",
      "Constantin Ruhdorfer",
      "Lei Shi",
      "Andreas Bulling"
    ],
    "abstract": "We propose MToMnet - a Theory of Mind (ToM) neural network for predicting\nbeliefs and their dynamics during human social interactions from multimodal\ninput. ToM is key for effective nonverbal human communication and\ncollaboration, yet, existing methods for belief modelling have not included\nexplicit ToM modelling or have typically been limited to one or two modalities.\nMToMnet encodes contextual cues (scene videos and object locations) and\nintegrates them with person-specific cues (human gaze and body language) in a\nseparate MindNet for each person. Inspired by prior research on social\ncognition and computational ToM, we propose three different MToMnet variants:\ntwo involving fusion of latent representations and one involving re-ranking of\nclassification scores. We evaluate our approach on two challenging real-world\ndatasets, one focusing on belief prediction, while the other examining belief\ndynamics prediction. Our results demonstrate that MToMnet surpasses existing\nmethods by a large margin while at the same time requiring a significantly\nsmaller number of parameters. Taken together, our method opens up a highly\npromising direction for future work on artificial intelligent systems that can\nrobustly predict human beliefs from their non-verbal behaviour and, as such,\nmore effectively collaborate with humans.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.06762v3",
    "published_date": "2024-07-09 11:15:51 UTC",
    "updated_date": "2024-08-28 11:26:06 UTC"
  },
  {
    "arxiv_id": "2407.06756v2",
    "title": "Frequency and Generalisation of Periodic Activation Functions in Reinforcement Learning",
    "authors": [
      "Augustine N. Mavor-Parker",
      "Matthew J. Sargent",
      "Caswell Barry",
      "Lewis Griffin",
      "Clare Lyle"
    ],
    "abstract": "Periodic activation functions, often referred to as learned Fourier features\nhave been widely demonstrated to improve sample efficiency and stability in a\nvariety of deep RL algorithms. Potentially incompatible hypotheses have been\nmade about the source of these improvements. One is that periodic activations\nlearn low frequency representations and as a result avoid overfitting to\nbootstrapped targets. Another is that periodic activations learn high frequency\nrepresentations that are more expressive, allowing networks to quickly fit\ncomplex value functions. We analyse these claims empirically, finding that\nperiodic representations consistently converge to high frequencies regardless\nof their initialisation frequency. We also find that while periodic activation\nfunctions improve sample efficiency, they exhibit worse generalization on\nstates with added observation noise -- especially when compared to otherwise\nequivalent networks with ReLU activation functions. Finally, we show that\nweight decay regularization is able to partially offset the overfitting of\nperiodic activation functions, delivering value functions that learn quickly\nwhile also generalizing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "RLC format, fixed bug which incorrectly gave vanilla ReLU training\n  runs weight decay",
    "pdf_url": "http://arxiv.org/pdf/2407.06756v2",
    "published_date": "2024-07-09 11:07:41 UTC",
    "updated_date": "2025-03-18 20:09:25 UTC"
  },
  {
    "arxiv_id": "2407.06754v2",
    "title": "Threats and Defenses in Federated Learning Life Cycle: A Comprehensive Survey and Challenges",
    "authors": [
      "Yanli Li",
      "Zhongliang Guo",
      "Nan Yang",
      "Huaming Chen",
      "Dong Yuan",
      "Weiping Ding"
    ],
    "abstract": "Federated Learning (FL) offers innovative solutions for privacy-preserving\ncollaborative machine learning (ML). Despite its promising potential, FL is\nvulnerable to various attacks due to its distributed nature, affecting the\nentire life cycle of FL services. These threats can harm the model's utility or\ncompromise participants' privacy, either directly or indirectly. In response,\nnumerous defense frameworks have been proposed, demonstrating effectiveness in\nspecific settings and scenarios. To provide a clear understanding of the\ncurrent research landscape, this paper reviews the most representative and\nstate-of-the-art threats and defense frameworks throughout the FL service life\ncycle. We start by identifying FL threats that harm utility and privacy,\nincluding those with potential or direct impacts. Then, we dive into the\ndefense frameworks, analyze the relationship between threats and defenses, and\ncompare the trade-offs among different defense strategies. Finally, we\nsummarize current research bottlenecks and offer insights into future research\ndirections to conclude this survey. We hope this survey sheds light on\ntrustworthy FL research and contributes to the FL community.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06754v2",
    "published_date": "2024-07-09 11:05:45 UTC",
    "updated_date": "2024-07-11 11:50:03 UTC"
  },
  {
    "arxiv_id": "2407.07925v1",
    "title": "Enhancing Social Media Personalization: Dynamic User Profile Embeddings and Multimodal Contextual Analysis Using Transformer Models",
    "authors": [
      "Pranav Vachharajani"
    ],
    "abstract": "This study investigates the impact of dynamic user profile embedding on\npersonalized context-aware experiences in social networks. A comparative\nanalysis of multilingual and English transformer models was performed on a\ndataset of over twenty million data points. The analysis included a wide range\nof metrics and performance indicators to compare dynamic profile embeddings\nversus non-embeddings (effectively static profile embeddings). A comparative\nstudy using degradation functions was conducted. Extensive testing and research\nconfirmed that dynamic embedding successfully tracks users' changing tastes and\npreferences, providing more accurate recommendations and higher user\nengagement. These results are important for social media platforms aiming to\nimprove user experience through relevant features and sophisticated\nrecommendation engines.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.IR",
    "comment": "21 pages, 13 figures. Mentor: Prof Pritam Ranjan",
    "pdf_url": "http://arxiv.org/pdf/2407.07925v1",
    "published_date": "2024-07-09 10:58:46 UTC",
    "updated_date": "2024-07-09 10:58:46 UTC"
  },
  {
    "arxiv_id": "2407.06748v1",
    "title": "iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine",
    "authors": [
      "Anastasia Krithara",
      "Fotis Aisopos",
      "Vassiliki Rentoumi",
      "Anastasios Nentidis",
      "Konstantinos Bougatiotis",
      "Maria-Esther Vidal",
      "Ernestina Menasalvas",
      "Alejandro Rodriguez-Gonzalez",
      "Eleftherios G. Samaras",
      "Peter Garrard",
      "Maria Torrente",
      "Mariano Provencio Pulla",
      "Nikos Dimakopoulos",
      "Rui Mauricio",
      "Jordi Rambla De Argila",
      "Gian Gaetano Tartaglia",
      "George Paliouras"
    ],
    "abstract": "The vision of IASIS project is to turn the wave of big biomedical data\nheading our way into actionable knowledge for decision makers. This is achieved\nby integrating data from disparate sources, including genomics, electronic\nhealth records and bibliography, and applying advanced analytics methods to\ndiscover useful patterns. The goal is to turn large amounts of available data\ninto actionable information to authorities for planning public health\nactivities and policies. The integration and analysis of these heterogeneous\nsources of information will enable the best decisions to be made, allowing for\ndiagnosis and treatment to be personalised to each individual. The project\noffers a common representation schema for the heterogeneous data sources. The\niASiS infrastructure is able to convert clinical notes into usable data,\ncombine them with genomic data, related bibliography, image data and more, and\ncreate a global knowledge base. This facilitates the use of intelligent methods\nin order to discover useful patterns across different resources. Using semantic\nintegration of data gives the opportunity to generate information that is rich,\nauditable and reliable. This information can be used to provide better care,\nreduce errors and create more confidence in sharing data, thus providing more\ninsights and opportunities. Data resources for two different disease categories\nare explored within the iASiS use cases, dementia and lung cancer.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 2 figures, accepted at 2019 IEEE 32nd International\n  Symposium on Computer-Based Medical Systems (CBMS)",
    "pdf_url": "http://arxiv.org/pdf/2407.06748v1",
    "published_date": "2024-07-09 10:52:19 UTC",
    "updated_date": "2024-07-09 10:52:19 UTC"
  },
  {
    "arxiv_id": "2407.06740v2",
    "title": "Sustainable techniques to improve Data Quality for training image-based explanatory models for Recommender Systems",
    "authors": [
      "Jorge Paz-Ruza",
      "David Esteban-Martínez",
      "Amparo Alonso-Betanzos",
      "Bertha Guijarro-Berdiñas"
    ],
    "abstract": "Visual explanations based on user-uploaded images are an effective and\nself-contained approach to provide transparency to Recommender Systems (RS),\nbut intrinsic limitations of data used in this explainability paradigm cause\nexisting approaches to use bad quality training data that is highly sparse and\nsuffers from labelling noise. Popular training enrichment approaches like model\nenlargement or massive data gathering are expensive and environmentally\nunsustainable, thus we seek to provide better visual explanations to RS\naligning with the principles of Responsible AI. In this work, we research the\nintersection of effective and sustainable training enrichment strategies for\nvisual-based RS explainability models by developing three novel strategies that\nfocus on training Data Quality: 1) selection of reliable negative training\nexamples using Positive-unlabelled Learning, 2) transform-based data\naugmentation, and 3) text-to-image generative-based data augmentation. The\nintegration of these strategies in three state-of-the-art explainability models\nincreases 5% the performance in relevant ranking metrics of these visual-based\nRS explainability models without penalizing their practical long-term\nsustainability, as tested in multiple real-world restaurant recommendation\nexplanation datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06740v2",
    "published_date": "2024-07-09 10:40:31 UTC",
    "updated_date": "2025-03-29 10:16:08 UTC"
  },
  {
    "arxiv_id": "2407.06723v2",
    "title": "Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions",
    "authors": [
      "Yu-Guan Hsieh",
      "Cheng-Yu Hsieh",
      "Shih-Ying Yeh",
      "Louis Béthune",
      "Hadi Pour Ansari",
      "Pavan Kumar Anasosalu Vasu",
      "Chun-Liang Li",
      "Ranjay Krishna",
      "Oncel Tuzel",
      "Marco Cuturi"
    ],
    "abstract": "Humans describe complex scenes with compositionality, using simple text\ndescriptions enriched with links and relationships. While vision-language\nresearch has aimed to develop models with compositional understanding\ncapabilities, this is not reflected yet in existing datasets which, for the\nmost part, still use plain text to describe images. In this work, we propose a\nnew annotation strategy, graph-based captioning (GBC) that describes an image\nusing a labeled graph structure, with nodes of various types. The nodes in GBC\nare created through a two-stage process: first, identifying and describing\nentity nodes; second, linking these nodes by highlighting \\textit{compositions}\nand \\textit{relations} among them. Since \\textit{all} GBC nodes hold plain text\ndescriptions, GBC retains the flexibility found in natural language, but can\nalso encode hierarchical information in its edges. We demonstrate that GBC can\nbe produced automatically, using off-the-shelf multimodal LLMs and object\ndetection models, by building a new dataset GBC10M that gathers GBC annotations\nfor about 10M images of the CC12M dataset. Through CLIP training on GBC10M, we\nshow that leveraging GBC nodes' annotations -- particularly those in\ncomposition and relation nodes -- significantly boosts the model's performance\nacross various benchmarks compared to when other annotations are used. To\nfurther explore the opportunities provided by GBC, we also investigate the use\nof GBC as middleware for text-to-image generation, and show the extra benefits\nof incorporating the graph structure in this task. Our code and datasets are\nreleased at https://github.com/apple/ml-gbc and\nhttps://huggingface.co/graph-based-captions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "59 pages, 42 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.06723v2",
    "published_date": "2024-07-09 09:55:04 UTC",
    "updated_date": "2025-02-26 22:54:53 UTC"
  },
  {
    "arxiv_id": "2407.06718v1",
    "title": "A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts",
    "authors": [
      "Atilla Özgür",
      "Yılmaz Uygun"
    ],
    "abstract": "This study proposes a simple architecture for Enterprise application for\nLarge Language Models (LLMs) for role based security and NATO clearance levels.\nOur proposal aims to address the limitations of current LLMs in handling\nsecurity and information access. The proposed architecture could be used while\nutilizing Retrieval-Augmented Generation (RAG) and fine tuning of Mixture of\nexperts models (MoE). It could be used only with RAG, or only with MoE or with\nboth of them. Using roles and security clearance level of the user, documents\nin RAG and experts in MoE are filtered. This way information leakage is\nprevented.",
    "categories": [
      "cs.AI",
      "D.2.11; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06718v1",
    "published_date": "2024-07-09 09:46:23 UTC",
    "updated_date": "2024-07-09 09:46:23 UTC"
  },
  {
    "arxiv_id": "2407.11054v3",
    "title": "Generative AI for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations",
    "authors": [
      "Rachael Fleurence",
      "Jiang Bian",
      "Xiaoyan Wang",
      "Hua Xu",
      "Dalia Dawoud",
      "Mitch Higashi",
      "Jagpreet Chhatwal"
    ],
    "abstract": "This review introduces the transformative potential of generative Artificial\nIntelligence (AI) and foundation models, including large language models\n(LLMs), for health technology assessment (HTA). We explore their applications\nin four critical areas, evidence synthesis, evidence generation, clinical\ntrials and economic modeling: (1) Evidence synthesis: Generative AI has the\npotential to assist in automating literature reviews and meta-analyses by\nproposing search terms, screening abstracts, and extracting data with notable\naccuracy; (2) Evidence generation: These models can potentially facilitate\nautomating the process and analyze the increasingly available large collections\nof real-world data (RWD), including unstructured clinical notes and imaging,\nenhancing the speed and quality of real-world evidence (RWE) generation; (3)\nClinical trials: Generative AI can be used to optimize trial design, improve\npatient matching, and manage trial data more efficiently; and (4) Economic\nmodeling: Generative AI can also aid in the development of health economic\nmodels, from conceptualization to validation, thus streamlining the overall HTA\nprocess. Despite their promise, these technologies, while rapidly improving,\nare still nascent and continued careful evaluation in their applications to HTA\nis required. To ensure their responsible use and implementation, both\ndevelopers and users of research incorporating these tools, should familiarize\nthemselves with their current limitations, including the issues related to\nscientific validity, risk of bias, and consider equity and ethical\nimplications. We also surveyed the current policy landscape and provide\nsuggestions for HTA agencies on responsibly integrating generative AI into\ntheir workflows, emphasizing the importance of human oversight and the\nfast-evolving nature of these tools.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 1 figure, 1 table, 2 boxes, 103 references",
    "pdf_url": "http://arxiv.org/pdf/2407.11054v3",
    "published_date": "2024-07-09 09:25:27 UTC",
    "updated_date": "2024-09-21 19:41:09 UTC"
  },
  {
    "arxiv_id": "2407.06692v1",
    "title": "Deep-Motion-Net: GNN-based volumetric organ shape reconstruction from single-view 2D projections",
    "authors": [
      "Isuru Wijesinghe",
      "Michael Nix",
      "Arezoo Zakeri",
      "Alireza Hokmabadi",
      "Bashar Al-Qaisieh",
      "Ali Gooya",
      "Zeike A. Taylor"
    ],
    "abstract": "We propose Deep-Motion-Net: an end-to-end graph neural network (GNN)\narchitecture that enables 3D (volumetric) organ shape reconstruction from a\nsingle in-treatment kV planar X-ray image acquired at any arbitrary projection\nangle. Estimating and compensating for true anatomical motion during\nradiotherapy is essential for improving the delivery of planned radiation dose\nto target volumes while sparing organs-at-risk, and thereby improving the\ntherapeutic ratio. Achieving this using only limited imaging available during\nirradiation and without the use of surrogate signals or invasive fiducial\nmarkers is attractive. The proposed model learns the mesh regression from a\npatient-specific template and deep features extracted from kV images at\narbitrary projection angles. A 2D-CNN encoder extracts image features, and four\nfeature pooling networks fuse these features to the 3D template organ mesh. A\nResNet-based graph attention network then deforms the feature-encoded mesh. The\nmodel is trained using synthetically generated organ motion instances and\ncorresponding kV images. The latter is generated by deforming a reference CT\nvolume aligned with the template mesh, creating digitally reconstructed\nradiographs (DRRs) at required projection angles, and DRR-to-kV style\ntransferring with a conditional CycleGAN model. The overall framework was\ntested quantitatively on synthetic respiratory motion scenarios and\nqualitatively on in-treatment images acquired over full scan series for liver\ncancer patients. Overall mean prediction errors for synthetic motion test\ndatasets were 0.16$\\pm$0.13 mm, 0.18$\\pm$0.19 mm, 0.22$\\pm$0.34 mm, and\n0.12$\\pm$0.11 mm. Mean peak prediction errors were 1.39 mm, 1.99 mm, 3.29 mm,\nand 1.16 mm.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06692v1",
    "published_date": "2024-07-09 09:07:18 UTC",
    "updated_date": "2024-07-09 09:07:18 UTC"
  },
  {
    "arxiv_id": "2407.06690v1",
    "title": "Hierarchical Average-Reward Linearly-solvable Markov Decision Processes",
    "authors": [
      "Guillermo Infante",
      "Anders Jonsson",
      "Vicenç Gómez"
    ],
    "abstract": "We introduce a novel approach to hierarchical reinforcement learning for\nLinearly-solvable Markov Decision Processes (LMDPs) in the infinite-horizon\naverage-reward setting. Unlike previous work, our approach allows learning\nlow-level and high-level tasks simultaneously, without imposing limiting\nrestrictions on the low-level tasks. Our method relies on partitions of the\nstate space that create smaller subtasks that are easier to solve, and the\nequivalence between such partitions to learn more efficiently. We then exploit\nthe compositionality of low-level tasks to exactly represent the value function\nof the high-level task. Experiments show that our approach can outperform flat\naverage-reward reinforcement learning by one or several orders of magnitude.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06690v1",
    "published_date": "2024-07-09 09:06:44 UTC",
    "updated_date": "2024-07-09 09:06:44 UTC"
  },
  {
    "arxiv_id": "2407.06682v1",
    "title": "A Predictive Model Based on Transformer with Statistical Feature Embedding in Manufacturing Sensor Dataset",
    "authors": [
      "Gyeong Taek Lee",
      "Oh-Ran Kwon"
    ],
    "abstract": "In the manufacturing process, sensor data collected from equipment is crucial\nfor building predictive models to manage processes and improve productivity.\nHowever, in the field, it is challenging to gather sufficient data to build\nrobust models. This study proposes a novel predictive model based on the\nTransformer, utilizing statistical feature embedding and window positional\nencoding. Statistical features provide an effective representation of sensor\ndata, and the embedding enables the Transformer to learn both time- and\nsensor-related information. Window positional encoding captures precise time\ndetails from the feature embedding. The model's performance is evaluated in two\nproblems: fault detection and virtual metrology, showing superior results\ncompared to baseline models. This improvement is attributed to the efficient\nuse of parameters, which is particularly beneficial for sensor data that often\nhas limited sample sizes. The results support the model's applicability across\nvarious manufacturing industries, demonstrating its potential for enhancing\nprocess management and yield.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06682v1",
    "published_date": "2024-07-09 08:59:27 UTC",
    "updated_date": "2024-07-09 08:59:27 UTC"
  },
  {
    "arxiv_id": "2407.06676v1",
    "title": "Games played by Exponential Weights Algorithms",
    "authors": [
      "Maurizio d'Andrea",
      "Fabien Gensbittel",
      "Jérôme Renault"
    ],
    "abstract": "This paper studies the last-iterate convergence properties of the exponential\nweights algorithm with constant learning rates. We consider a repeated\ninteraction in discrete time, where each player uses an exponential weights\nalgorithm characterized by an initial mixed action and a fixed learning rate,\nso that the mixed action profile $p^t$ played at stage $t$ follows an\nhomogeneous Markov chain. At first, we show that whenever a strict Nash\nequilibrium exists, the probability to play a strict Nash equilibrium at the\nnext stage converges almost surely to 0 or 1. Secondly, we show that the limit\nof $p^t$, whenever it exists, belongs to the set of ``Nash Equilibria with\nEqualizing Payoffs''. Thirdly, we show that in strong coordination games, where\nthe payoff of a player is positive on the diagonal and 0 elsewhere, $p^t$\nconverges almost surely to one of the strict Nash equilibria. We conclude with\nopen questions.",
    "categories": [
      "cs.AI",
      "math.PR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06676v1",
    "published_date": "2024-07-09 08:49:51 UTC",
    "updated_date": "2024-07-09 08:49:51 UTC"
  },
  {
    "arxiv_id": "2407.06660v1",
    "title": "Collaborative Design of AI-Enhanced Learning Activities",
    "authors": [
      "Margarida Romero"
    ],
    "abstract": "Artificial intelligence has accelerated innovations in different aspects of\ncitizens' lives. Many contexts have already addressed technology-enhanced\nlearning, but educators at different educational levels now need to develop AI\nliteracy and the ability to integrate appropriate AI usage into their teaching.\nWe take into account this objective, along with the creative learning design,\nto create a formative intervention that enables preservice teachers, in-service\nteachers, and EdTech specialists to effectively incorporate AI into their\nteaching practices. We developed the formative intervention with Terra Numerica\nand Maison de l'Intelligence Artificielle in two phases in order to enhance\ntheir understanding of AI and foster its creative application in learning\ndesign. Participants reflect on AI's potential in teaching and learning by\nexploring different activities that can integrate AI literacy in education,\nincluding its ethical considerations and potential for innovative pedagogy. The\napproach emphasises not only acculturating professionals to AI but also\nempowering them to collaboratively design AI-enhanced educational activities\nthat promote learner engagement and personalised learning experiences. Through\nthis process, participants in the workshops develop the skills and mindset\nnecessary to effectively leverage AI while maintaining a critical awareness of\nits implications in education.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06660v1",
    "published_date": "2024-07-09 08:34:08 UTC",
    "updated_date": "2024-07-09 08:34:08 UTC"
  },
  {
    "arxiv_id": "2407.06658v2",
    "title": "TriQXNet: Forecasting Dst Index from Solar Wind Data Using an Interpretable Parallel Classical-Quantum Framework with Uncertainty Quantification",
    "authors": [
      "Md Abrar Jahin",
      "M. F. Mridha",
      "Zeyar Aung",
      "Nilanjan Dey",
      "R. Simon Sherratt"
    ],
    "abstract": "Geomagnetic storms, caused by solar wind energy transfer to Earth's magnetic\nfield, can disrupt critical infrastructure like GPS, satellite communications,\nand power grids. The disturbance storm-time (Dst) index measures storm\nintensity. Despite advancements in empirical, physics-based, and\nmachine-learning models using real-time solar wind data, accurately forecasting\nextreme geomagnetic events remains challenging due to noise and sensor\nfailures. This research introduces TriQXNet, a novel hybrid classical-quantum\nneural network for Dst forecasting. Our model integrates classical and quantum\ncomputing, conformal prediction, and explainable AI (XAI) within a hybrid\narchitecture. To ensure high-quality input data, we developed a comprehensive\npreprocessing pipeline that included feature selection, normalization,\naggregation, and imputation. TriQXNet processes preprocessed solar wind data\nfrom NASA's ACE and NOAA's DSCOVR satellites, predicting the Dst index for the\ncurrent hour and the next, providing vital advance notice to mitigate\ngeomagnetic storm impacts. TriQXNet outperforms 13 state-of-the-art hybrid\ndeep-learning models, achieving a root mean squared error of 9.27 nanoteslas\n(nT). Rigorous evaluation through 10-fold cross-validated paired t-tests\nconfirmed its superior performance with 95% confidence. Conformal prediction\ntechniques provide quantifiable uncertainty, which is essential for operational\ndecisions, while XAI methods like ShapTime enhance interpretability.\nComparative analysis shows TriQXNet's superior forecasting accuracy, setting a\nnew level of expectations for geomagnetic storm prediction and highlighting the\npotential of classical-quantum hybrid models in space weather forecasting.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06658v2",
    "published_date": "2024-07-09 08:30:42 UTC",
    "updated_date": "2024-07-10 16:53:38 UTC"
  },
  {
    "arxiv_id": "2407.06655v1",
    "title": "Teacher agency in the age of generative AI: towards a framework of hybrid intelligence for learning design",
    "authors": [
      "Thomas B Frøsig",
      "Margarida Romero"
    ],
    "abstract": "Generative AI (genAI) is being used in education for different purposes. From\nthe teachers' perspective, genAI can support activities such as learning\ndesign. However, there is a need to study the impact of genAI on the teachers'\nagency. While GenAI can support certain processes of idea generation and\nco-creation, GenAI has the potential to negatively affect professional agency\ndue to teachers' limited power to (i) act, (ii) affect matters, and (iii) make\ndecisions or choices, as well as the possibility to (iv) take a stance. Agency\nis identified in the learning sciences studies as being one of the factors in\nteachers' ability to trust AI. This paper aims to introduce a dual perspective.\nFirst, educational technology, as opposed to other computer-mediated\ncommunication (CMC) tools, has two distinctly different user groups and\ndifferent user needs, in the form of learners and teachers, to cater for.\nSecond, the design of educational technology often prioritises learner agency\nand engagement, thereby limiting the opportunities for teachers to influence\nthe technology and take action. This study aims to analyse the way GenAI is\ninfluencing teachers' agency. After identifying the current limits of GenAI, a\nsolution based on the combination of human intelligence and artificial\nintelligence through a hybrid intelligence approach is proposed. This\ncombination opens up the discussion of a collaboration between teacher and\ngenAI being able to open up new practices in learning design in which they HI\nsupport the extension of the teachers' activity.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06655v1",
    "published_date": "2024-07-09 08:28:05 UTC",
    "updated_date": "2024-07-09 08:28:05 UTC"
  },
  {
    "arxiv_id": "2407.12854v1",
    "title": "Scaling Retrieval-Based Language Models with a Trillion-Token Datastore",
    "authors": [
      "Rulin Shao",
      "Jacqueline He",
      "Akari Asai",
      "Weijia Shi",
      "Tim Dettmers",
      "Sewon Min",
      "Luke Zettlemoyer",
      "Pang Wei Koh"
    ],
    "abstract": "Scaling laws with respect to the amount of training data and the number of\nparameters allow us to predict the cost-benefit trade-offs of pretraining\nlanguage models (LMs) in different configurations. In this paper, we consider\nanother dimension of scaling: the amount of data available at inference time.\nSpecifically, we find that increasing the size of the datastore used by a\nretrieval-based LM monotonically improves language modeling and several\ndownstream tasks without obvious saturation, such that a smaller model\naugmented with a large datastore outperforms a larger LM-only model on\nknowledge-intensive tasks. By plotting compute-optimal scaling curves with\nvaried datastore, model, and pretraining data sizes, we show that using larger\ndatastores can significantly improve model performance for the same training\ncompute budget. We carry out our study by constructing a 1.4 trillion-token\ndatastore named MassiveDS, which is the largest and the most diverse\nopen-sourced datastore for retrieval-based LMs to date, and designing an\nefficient pipeline for studying datastore scaling in a computationally\naccessible manner. Finally, we analyze the effect of improving the retriever,\ndatastore quality filtering, and other design choices on our observed scaling\ntrends. Overall, our results show that datastore size should be considered as\nan integral part of LM efficiency and performance trade-offs. To facilitate\nfuture research, we open-source our datastore and code at\nhttps://github.com/RulinShao/retrieval-scaling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12854v1",
    "published_date": "2024-07-09 08:27:27 UTC",
    "updated_date": "2024-07-09 08:27:27 UTC"
  },
  {
    "arxiv_id": "2407.06654v1",
    "title": "SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training",
    "authors": [
      "Nan He",
      "Weichen Xiong",
      "Hanwen Liu",
      "Yi Liao",
      "Lei Ding",
      "Kai Zhang",
      "Guohua Tang",
      "Xiao Han",
      "Wei Yang"
    ],
    "abstract": "The effectiveness of large language models (LLMs) is often hindered by\nduplicated data in their extensive pre-training datasets. Current approaches\nprimarily focus on detecting and removing duplicates, which risks the loss of\nvaluable information and neglects the varying degrees of duplication. To\naddress this, we propose a soft deduplication method that maintains dataset\nintegrity while selectively reducing the sampling weight of data with high\ncommonness. Central to our approach is the concept of \"data commonness\", a\nmetric we introduce to quantify the degree of duplication by measuring the\noccurrence probabilities of samples using an n-gram model. Empirical analysis\nshows that this method significantly improves training efficiency, achieving\ncomparable perplexity scores with at least a 26% reduction in required training\nsteps. Additionally, it enhances average few-shot downstream accuracy by 1.77%\nwhen trained for an equivalent duration. Importantly, this approach\nconsistently improves performance, even on rigorously deduplicated datasets,\nindicating its potential to complement existing methods and become a standard\npre-training process for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.06654v1",
    "published_date": "2024-07-09 08:26:39 UTC",
    "updated_date": "2024-07-09 08:26:39 UTC"
  },
  {
    "arxiv_id": "2407.06622v1",
    "title": "Reasoning about unpredicted change and explicit time",
    "authors": [
      "Florence Dupin de Saint-Cyr",
      "Jérôme Lang"
    ],
    "abstract": "Reasoning about unpredicted change consists in explaining observations by\nevents; we propose here an approach for explaining time-stamped observations by\nsurprises, which are simple events consisting in the change of the truth value\nof a fluent. A framework for dealing with surprises is defined. Minimal sets of\nsurprises are provided together with time intervals where each surprise has\noccurred, and they are characterized from a model-based diagnosis point of\nview. Then, a probabilistic approach of surprise minimisation is proposed.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06622v1",
    "published_date": "2024-07-09 07:49:57 UTC",
    "updated_date": "2024-07-09 07:49:57 UTC"
  },
  {
    "arxiv_id": "2407.06611v1",
    "title": "CEIA: CLIP-Based Event-Image Alignment for Open-World Event-Based Understanding",
    "authors": [
      "Wenhao Xu",
      "Wenming Weng",
      "Yueyi Zhang",
      "Zhiwei Xiong"
    ],
    "abstract": "We present CEIA, an effective framework for open-world event-based\nunderstanding. Currently training a large event-text model still poses a huge\nchallenge due to the shortage of paired event-text data. In response to this\nchallenge, CEIA learns to align event and image data as an alternative instead\nof directly aligning event and text data. Specifically, we leverage the rich\nevent-image datasets to learn an event embedding space aligned with the image\nspace of CLIP through contrastive learning. In this way, event and text data\nare naturally aligned via using image data as a bridge. Particularly, CEIA\noffers two distinct advantages. First, it allows us to take full advantage of\nthe existing event-image datasets to make up the shortage of large-scale\nevent-text datasets. Second, leveraging more training data, it also exhibits\nthe flexibility to boost performance, ensuring scalable capability. In\nhighlighting the versatility of our framework, we make extensive evaluations\nthrough a diverse range of event-based multi-modal applications, such as object\nrecognition, event-image retrieval, event-text retrieval, and domain\nadaptation. The outcomes demonstrate CEIA's distinct zero-shot superiority over\nexisting methods on these applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06611v1",
    "published_date": "2024-07-09 07:26:15 UTC",
    "updated_date": "2024-07-09 07:26:15 UTC"
  },
  {
    "arxiv_id": "2407.07924v1",
    "title": "Solving General Natural-Language-Description Optimization Problems with Large Language Models",
    "authors": [
      "Jihai Zhang",
      "Wei Wang",
      "Siyan Guo",
      "Li Wang",
      "Fangquan Lin",
      "Cheng Yang",
      "Wotao Yin"
    ],
    "abstract": "Optimization problems seek to find the best solution to an objective under a\nset of constraints, and have been widely investigated in real-world\napplications. Modeling and solving optimization problems in a specific domain\ntypically require a combination of domain knowledge, mathematical skills, and\nprogramming ability, making it difficult for general users and even domain\nprofessionals. In this paper, we propose a novel framework called OptLLM that\naugments LLMs with external solvers. Specifically, OptLLM accepts user queries\nin natural language, convert them into mathematical formulations and\nprogramming codes, and calls the solvers to calculate the results for\ndecision-making. In addition, OptLLM supports multi-round dialogues to\ngradually refine the modeling and solving of optimization problems. To\nillustrate the effectiveness of OptLLM, we provide tutorials on three typical\noptimization applications and conduct experiments on both prompt-based GPT\nmodels and a fine-tuned Qwen model using a large-scale selfdeveloped\noptimization dataset. Experimental results show that OptLLM works with various\nLLMs, and the fine-tuned model achieves an accuracy boost compared to the\npromptbased models. Some features of OptLLM framework have been available for\ntrial since June 2023 (https://opt.alibabacloud.com/chat or\nhttps://opt.aliyun.com/chat).",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07924v1",
    "published_date": "2024-07-09 07:11:10 UTC",
    "updated_date": "2024-07-09 07:11:10 UTC"
  },
  {
    "arxiv_id": "2407.06597v2",
    "title": "TVR-Ranking: A Dataset for Ranked Video Moment Retrieval with Imprecise Queries",
    "authors": [
      "Renjie Liang",
      "Li Li",
      "Chongzhi Zhang",
      "Jing Wang",
      "Xizhou Zhu",
      "Aixin Sun"
    ],
    "abstract": "In this paper, we propose the task of \\textit{Ranked Video Moment Retrieval}\n(RVMR) to locate a ranked list of matching moments from a collection of videos,\nthrough queries in natural language. Although a few related tasks have been\nproposed and studied by CV, NLP, and IR communities, RVMR is the task that best\nreflects the practical setting of moment search. To facilitate research in\nRVMR, we develop the TVR-Ranking dataset, based on the raw videos and existing\nmoment annotations provided in the TVR dataset. Our key contribution is the\nmanual annotation of relevance levels for 94,442 query-moment pairs. We then\ndevelop the $NDCG@K, IoU\\geq \\mu$ evaluation metric for this new task and\nconduct experiments to evaluate three baseline models. Our experiments show\nthat the new RVMR task brings new challenges to existing models and we believe\nthis new dataset contributes to the research on multi-modality search. The\ndataset is available at \\url{https://github.com/Ranking-VMR/TVR-Ranking}",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06597v2",
    "published_date": "2024-07-09 06:57:30 UTC",
    "updated_date": "2024-07-24 03:54:53 UTC"
  },
  {
    "arxiv_id": "2407.06590v1",
    "title": "Revolutionizing Battery Disassembly: The Design and Implementation of a Battery Disassembly Autonomous Mobile Manipulator Robot(BEAM-1)",
    "authors": [
      "Yanlong Peng",
      "Zhigang Wang",
      "Yisheng Zhang",
      "Shengmin Zhang",
      "Nan Cai",
      "Fan Wu",
      "Ming Chen"
    ],
    "abstract": "The efficient disassembly of end-of-life electric vehicle batteries(EOL-EVBs)\nis crucial for green manufacturing and sustainable development. The current\npre-programmed disassembly conducted by the Autonomous Mobile Manipulator\nRobot(AMMR) struggles to meet the disassembly requirements in dynamic\nenvironments, complex scenarios, and unstructured processes. In this paper, we\npropose a Battery Disassembly AMMR(BEAM-1) system based on NeuralSymbolic AI.\nIt detects the environmental state by leveraging a combination of multi-sensors\nand neural predicates and then translates this information into a\nquasi-symbolic space. In real-time, it identifies the optimal sequence of\naction primitives through LLM-heuristic tree search, ensuring high-precision\nexecution of these primitives. Additionally, it employs positional speculative\nsampling using intuitive networks and achieves the disassembly of various bolt\ntypes with a meticulously designed end-effector. Importantly, BEAM-1 is a\ncontinuously learning embodied intelligence system capable of subjective\nreasoning like a human, and possessing intuition. A large number of real scene\nexperiments have proved that it can autonomously perceive, decide, and execute\nto complete the continuous disassembly of bolts in multiple, multi-category,\nand complex situations, with a success rate of 98.78%. This research attempts\nto use NeuroSymbolic AI to give robots real autonomous reasoning, planning, and\nlearning capabilities. BEAM-1 realizes the revolution of battery disassembly.\nIts framework can be easily ported to any robotic system to realize different\napplication scenarios, which provides a ground-breaking idea for the design and\nimplementation of future embodied intelligent robotic systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06590v1",
    "published_date": "2024-07-09 06:44:20 UTC",
    "updated_date": "2024-07-09 06:44:20 UTC"
  },
  {
    "arxiv_id": "2407.11052v2",
    "title": "Revisiting, Benchmarking and Understanding Unsupervised Graph Domain Adaptation",
    "authors": [
      "Meihan Liu",
      "Zhen Zhang",
      "Jiachen Tang",
      "Jiajun Bu",
      "Bingsheng He",
      "Sheng Zhou"
    ],
    "abstract": "Unsupervised Graph Domain Adaptation (UGDA) involves the transfer of\nknowledge from a label-rich source graph to an unlabeled target graph under\ndomain discrepancies. Despite the proliferation of methods designed for this\nemerging task, the lack of standard experimental settings and fair performance\ncomparisons makes it challenging to understand which and when models perform\nwell across different scenarios. To fill this gap, we present the first\ncomprehensive benchmark for unsupervised graph domain adaptation named\nGDABench, which encompasses 16 algorithms across 5 datasets with 74 adaptation\ntasks. Through extensive experiments, we observe that the performance of\ncurrent UGDA models varies significantly across different datasets and\nadaptation scenarios. Specifically, we recognize that when the source and\ntarget graphs face significant distribution shifts, it is imperative to\nformulate strategies to effectively address and mitigate graph structural\nshifts. We also find that with appropriate neighbourhood aggregation\nmechanisms, simple GNN variants can even surpass state-of-the-art UGDA\nbaselines. To facilitate reproducibility, we have developed an easy-to-use\nlibrary PyGDA for training and evaluating existing UGDA methods, providing a\nstandardized platform in this community. Our source codes and datasets can be\nfound at: https://github.com/pygda-team/pygda.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS-24",
    "pdf_url": "http://arxiv.org/pdf/2407.11052v2",
    "published_date": "2024-07-09 06:44:09 UTC",
    "updated_date": "2024-11-11 12:16:49 UTC"
  },
  {
    "arxiv_id": "2407.06581v6",
    "title": "Vision language models are blind: Failing to translate detailed visual features into words",
    "authors": [
      "Pooyan Rahmanzadehgervi",
      "Logan Bolton",
      "Mohammad Reza Taesiri",
      "Anh Totti Nguyen"
    ],
    "abstract": "While large language models with vision capabilities (VLMs), e.g., GPT-4o and\nGemini 1.5 Pro, score high on many vision-understanding benchmarks, they are\nstill struggling with low-level vision tasks that are easy to humans.\nSpecifically, on BlindTest, our suite of 7 very simple tasks, including\nidentifying (a) whether two circles overlap; (b) how many times two lines\nintersect; (c) which letter is being circled in a word; and (d) the number of\ncircles in an Olympic-like logo, four state-of-the-art VLMs are only 58.07%\naccurate on average. Claude 3.5 Sonnet performs the best at 77.84% accuracy,\nfar from the human expected accuracy of 100%. Across different image\nresolutions and line widths, VLMs including slow-thinking models consistently\nstruggle with those tasks that require precise spatial information when\ngeometric primitives overlap or are close. Yet, VLMs perform at near-100%\naccuracy when much more space is added to separate shapes and letters. Linear\nprobing experiments show that vision encoders contain sufficient visual\ninformation to solve BlindTest and that language models fail to decode this\ninformation into correct answers. Code and data are at:\nhttps://vlmsareblind.github.io",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06581v6",
    "published_date": "2024-07-09 06:20:17 UTC",
    "updated_date": "2025-03-27 16:16:09 UTC"
  },
  {
    "arxiv_id": "2407.06576v3",
    "title": "Virtual Personas for Language Models via an Anthology of Backstories",
    "authors": [
      "Suhong Moon",
      "Marwa Abdulhai",
      "Minwoo Kang",
      "Joseph Suh",
      "Widyadewi Soedarmadji",
      "Eran Kohen Behar",
      "David M. Chan"
    ],
    "abstract": "Large language models (LLMs) are trained from vast repositories of text\nauthored by millions of distinct authors, reflecting an enormous diversity of\nhuman traits. While these models bear the potential to be used as\napproximations of human subjects in behavioral studies, prior efforts have been\nlimited in steering model responses to match individual human users. In this\nwork, we introduce \"Anthology\", a method for conditioning LLMs to particular\nvirtual personas by harnessing open-ended life narratives, which we refer to as\n\"backstories.\" We show that our methodology enhances the consistency and\nreliability of experimental outcomes while ensuring better representation of\ndiverse sub-populations. Across three nationally representative human surveys\nconducted as part of Pew Research Center's American Trends Panel (ATP), we\ndemonstrate that Anthology achieves up to 18% improvement in matching the\nresponse distributions of human respondents and 27% improvement in consistency\nmetrics. Our code and generated backstories are available at\nhttps://github.com/CannyLab/anthology.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2407.06576v3",
    "published_date": "2024-07-09 06:11:18 UTC",
    "updated_date": "2024-11-01 22:45:48 UTC"
  },
  {
    "arxiv_id": "2407.07959v1",
    "title": "Source Code Summarization in the Era of Large Language Models",
    "authors": [
      "Weisong Sun",
      "Yun Miao",
      "Yuekang Li",
      "Hongyu Zhang",
      "Chunrong Fang",
      "Yi Liu",
      "Gelei Deng",
      "Yang Liu",
      "Zhenyu Chen"
    ],
    "abstract": "To support software developers in understanding and maintaining programs,\nvarious automatic (source) code summarization techniques have been proposed to\ngenerate a concise natural language summary (i.e., comment) for a given code\nsnippet. Recently, the emergence of large language models (LLMs) has led to a\ngreat boost in the performance of code-related tasks. In this paper, we\nundertake a systematic and comprehensive study on code summarization in the era\nof LLMs, which covers multiple aspects involved in the workflow of LLM-based\ncode summarization. Specifically, we begin by examining prevalent automated\nevaluation methods for assessing the quality of summaries generated by LLMs and\nfind that the results of the GPT-4 evaluation method are most closely aligned\nwith human evaluation. Then, we explore the effectiveness of five prompting\ntechniques (zero-shot, few-shot, chain-of-thought, critique, and expert) in\nadapting LLMs to code summarization tasks. Contrary to expectations, advanced\nprompting techniques may not outperform simple zero-shot prompting. Next, we\ninvestigate the impact of LLMs' model settings (including top\\_p and\ntemperature parameters) on the quality of generated summaries. We find the\nimpact of the two parameters on summary quality varies by the base LLM and\nprogramming language, but their impacts are similar. Moreover, we canvass LLMs'\nabilities to summarize code snippets in distinct types of programming\nlanguages. The results reveal that LLMs perform suboptimally when summarizing\ncode written in logic programming languages compared to other language types.\nFinally, we unexpectedly find that CodeLlama-Instruct with 7B parameters can\noutperform advanced GPT-4 in generating summaries describing code\nimplementation details and asserting code properties. We hope that our findings\ncan provide a comprehensive understanding of code summarization in the era of\nLLMs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "68-04",
      "D.2.3; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "Just accepted to the 47th International Conference on Software\n  Engineering (ICSE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2407.07959v1",
    "published_date": "2024-07-09 05:48:42 UTC",
    "updated_date": "2024-07-09 05:48:42 UTC"
  },
  {
    "arxiv_id": "2407.06564v1",
    "title": "Combining Knowledge Graphs and Large Language Models",
    "authors": [
      "Amanda Kau",
      "Xuzeng He",
      "Aishwarya Nambissan",
      "Aland Astudillo",
      "Hui Yin",
      "Amir Aryani"
    ],
    "abstract": "In recent years, Natural Language Processing (NLP) has played a significant\nrole in various Artificial Intelligence (AI) applications such as chatbots,\ntext generation, and language translation. The emergence of large language\nmodels (LLMs) has greatly improved the performance of these applications,\nshowing astonishing results in language understanding and generation. However,\nthey still show some disadvantages, such as hallucinations and lack of\ndomain-specific knowledge, that affect their performance in real-world tasks.\nThese issues can be effectively mitigated by incorporating knowledge graphs\n(KGs), which organise information in structured formats that capture\nrelationships between entities in a versatile and interpretable fashion.\nLikewise, the construction and validation of KGs present challenges that LLMs\ncan help resolve. The complementary relationship between LLMs and KGs has led\nto a trend that combines these technologies to achieve trustworthy results.\nThis work collected 28 papers outlining methods for KG-powered LLMs, LLM-based\nKGs, and LLM-KG hybrid approaches. We systematically analysed and compared\nthese approaches to provide a comprehensive overview highlighting key trends,\ninnovative techniques, and common challenges. This synthesis will benefit\nresearchers new to the field and those seeking to deepen their understanding of\nhow KGs and LLMs can be effectively combined to enhance AI applications\ncapabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06564v1",
    "published_date": "2024-07-09 05:42:53 UTC",
    "updated_date": "2024-07-09 05:42:53 UTC"
  },
  {
    "arxiv_id": "2407.06560v2",
    "title": "TCKAN:A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients",
    "authors": [
      "Fanglin Dong"
    ],
    "abstract": "Sepsis poses a major global health threat, accounting for millions of deaths\nannually and significant economic costs. Accurately predicting the risk of\nmortality in sepsis patients enables early identification, promotes the\nefficient allocation of medical resources, and facilitates timely\ninterventions, thereby improving patient outcomes. Current methods typically\nutilize only one type of data--either constant, temporal, or ICD codes. This\nstudy introduces a novel approach, the Time-Constant Kolmogorov-Arnold Network\n(TCKAN), which uniquely integrates temporal data, constant data, and ICD codes\nwithin a single predictive model. Unlike existing methods that typically rely\non one type of data, TCKAN leverages a multi-modal data integration strategy,\nresulting in superior predictive accuracy and robustness in identifying\nhigh-risk sepsis patients. Validated against the MIMIC-III and MIMIC-IV\ndatasets, TCKAN surpasses existing machine learning and deep learning methods\nin accuracy, sensitivity, and specificity. Notably, TCKAN achieved AUCs of\n87.76% and 88.07%, demonstrating superior capability in identifying high-risk\npatients. Additionally, TCKAN effectively combats the prevalent issue of data\nimbalance in clinical settings, improving the detection of patients at elevated\nrisk of mortality and facilitating timely interventions. These results confirm\nthe model's effectiveness and its potential to transform patient management and\ntreatment optimization in clinical practice. Although the TCKAN model has\nalready incorporated temporal, constant, and ICD code data, future research\ncould include more diverse medical data types, such as imaging and laboratory\ntest results, to achieve a more comprehensive data integration and further\nimprove predictive accuracy.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06560v2",
    "published_date": "2024-07-09 05:37:50 UTC",
    "updated_date": "2024-11-08 07:07:49 UTC"
  },
  {
    "arxiv_id": "2407.06549v1",
    "title": "AutoTask: Task Aware Multi-Faceted Single Model for Multi-Task Ads Relevance",
    "authors": [
      "Shouchang Guo",
      "Sonam Damani",
      "Keng-hao Chang"
    ],
    "abstract": "Ads relevance models are crucial in determining the relevance between user\nsearch queries and ad offers, often framed as a classification problem. The\ncomplexity of modeling increases significantly with multiple ad types and\nvarying scenarios that exhibit both similarities and differences. In this work,\nwe introduce a novel multi-faceted attention model that performs task aware\nfeature combination and cross task interaction modeling. Our technique\nformulates the feature combination problem as \"language\" modeling with\nauto-regressive attentions across both feature and task dimensions.\nSpecifically, we introduce a new dimension of task ID encoding for task\nrepresentations, thereby enabling precise relevance modeling across diverse ad\nscenarios with substantial improvement in generality capability for unseen\ntasks. We demonstrate that our model not only effectively handles the increased\ncomputational and maintenance demands as scenarios proliferate, but also\noutperforms generalized DNN models and even task-specific models across a\nspectrum of ad applications using a single unified model.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06549v1",
    "published_date": "2024-07-09 05:13:45 UTC",
    "updated_date": "2024-07-09 05:13:45 UTC"
  },
  {
    "arxiv_id": "2407.06540v1",
    "title": "General and Task-Oriented Video Segmentation",
    "authors": [
      "Mu Chen",
      "Liulei Li",
      "Wenguan Wang",
      "Ruijie Quan",
      "Yi Yang"
    ],
    "abstract": "We present GvSeg, a general video segmentation framework for addressing four\ndifferent video segmentation tasks (i.e., instance, semantic, panoptic, and\nexemplar-guided) while maintaining an identical architectural design.\nCurrently, there is a trend towards developing general video segmentation\nsolutions that can be applied across multiple tasks. This streamlines research\nendeavors and simplifies deployment. However, such a highly homogenized\nframework in current design, where each element maintains uniformity, could\noverlook the inherent diversity among different tasks and lead to suboptimal\nperformance. To tackle this, GvSeg: i) provides a holistic disentanglement and\nmodeling for segment targets, thoroughly examining them from the perspective of\nappearance, position, and shape, and on this basis, ii) reformulates the query\ninitialization, matching and sampling strategies in alignment with the\ntask-specific requirement. These architecture-agnostic innovations empower\nGvSeg to effectively address each unique task by accommodating the specific\nproperties that characterize them. Extensive experiments on seven gold-standard\nbenchmark datasets demonstrate that GvSeg surpasses all existing\nspecialized/general solutions by a significant margin on four different video\nsegmentation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024; Project page: https://github.com/kagawa588/GvSeg",
    "pdf_url": "http://arxiv.org/pdf/2407.06540v1",
    "published_date": "2024-07-09 04:21:38 UTC",
    "updated_date": "2024-07-09 04:21:38 UTC"
  },
  {
    "arxiv_id": "2407.06537v2",
    "title": "Efficient and Accurate Memorable Conversation Model using DPO based on sLLM",
    "authors": [
      "Youngkyung Seo",
      "Yoonseok Heo",
      "Jun-Seok Koh",
      "Du-Seong Chang"
    ],
    "abstract": "In multi-session dialog system, it is essential to continuously update the\nmemory as the session progresses. Simply accumulating memory can make it\ndifficult to focus on the content of the conversation for inference due to the\nlimited input sentence size. Therefore, efficient and accurate conversation\nmodel that is capable of managing memory to reflect the conversation history\ncontinuously is necessary. This paper presents a conversation model that\nefficiently manages memory as sessions progress and incorporates this into the\nmodel to reflect the conversation history accurately with 3 methodologies: SFT,\nDPO and DPO with SFT model. Our model using DPO algorithm shows an improvement\nabout 0.0591 of BERTScore in memory accuracy, and the rate of responses\nreflecting the memory increased as well. Also, response generation performance\nenhanced about 4.292 in fluency, 3.935 in coherence, and 2.896 in consistency.\nThis paper describes a training method that yields better performance than\nmodels with more than twice the parameter size, even when the model size is\nsmaller. Thus, our model demonstrates efficiency not only in terms of accuracy\nbut also in resource utilization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06537v2",
    "published_date": "2024-07-09 04:17:39 UTC",
    "updated_date": "2024-08-27 04:43:59 UTC"
  },
  {
    "arxiv_id": "2407.06533v1",
    "title": "LETS-C: Leveraging Language Embedding for Time Series Classification",
    "authors": [
      "Rachneet Kaur",
      "Zhen Zeng",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "abstract": "Recent advancements in language modeling have shown promising results when\napplied to time series data. In particular, fine-tuning pre-trained large\nlanguage models (LLMs) for time series classification tasks has achieved\nstate-of-the-art (SOTA) performance on standard benchmarks. However, these\nLLM-based models have a significant drawback due to the large model size, with\nthe number of trainable parameters in the millions. In this paper, we propose\nan alternative approach to leveraging the success of language modeling in the\ntime series domain. Instead of fine-tuning LLMs, we utilize a language\nembedding model to embed time series and then pair the embeddings with a simple\nclassification head composed of convolutional neural networks (CNN) and\nmultilayer perceptron (MLP). We conducted extensive experiments on\nwell-established time series classification benchmark datasets. We demonstrated\nLETS-C not only outperforms the current SOTA in classification accuracy but\nalso offers a lightweight solution, using only 14.5% of the trainable\nparameters on average compared to the SOTA model. Our findings suggest that\nleveraging language encoders to embed time series data, combined with a simple\nyet effective classification head, offers a promising direction for achieving\nhigh-performance time series classification while maintaining a lightweight\nmodel architecture.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 5 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.06533v1",
    "published_date": "2024-07-09 04:07:57 UTC",
    "updated_date": "2024-07-09 04:07:57 UTC"
  },
  {
    "arxiv_id": "2407.14530v1",
    "title": "FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network",
    "authors": [
      "Yi Zhan",
      "Yang Sun",
      "Han Weng",
      "Longjie Cui",
      "Guifeng Wang",
      "Jiajun Xie",
      "Yu Tian",
      "Xiaoming Yin",
      "Boyi Liu",
      "Dongchi Huang"
    ],
    "abstract": "In this paper, we propose a novel graph-based methodology to evaluate the\nfunctional correctness of SQL generation. Conventional metrics for assessing\nSQL code generation, such as matching-based and execution-based methods (e.g.,\nexact set match and execution accuracy), are subject to two primary\nlimitations. Firstly, the former fails to effectively assess functional\ncorrectness, as different SQL queries may possess identical functionalities.\nSecondly, the latter is susceptible to producing false positive samples in\nevaluations. Our proposed evaluation method, \\texttt{FuncEvalGMN}, does not\ndepend on the sufficient preparation of the test data, and it enables precise\ntesting of the functional correctness of the code. Firstly, we parse SQL using\na relational operator tree (ROT) called \\textit{Relnode}, which contains rich\nsemantic information from the perspective of logical execution.Then, we\nintroduce a GNN-based approach for predicting the functional correctness of\ngenerated SQL. This approach incorporates global positional embeddings to\naddress the limitations with the loss of topological information in\nconventional graph matching frameworks. As an auxiliary contribution, we\npropose a rule-based matching algorithm, Relnode Partial Matching\n(\\texttt{RelPM}) as a baseline. Finally, we contribute a dataset,\n\\texttt{Pair-Aug-Spider} with a training set and two testing sets, each\ncomprising pairs of SQL codes to simulate various SQL code evaluation\nscenarios. The training set and one testing dataset focus on code generation\nusing large language models (LLMs), while the other emphasizes SQL equivalence\nrewriting.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14530v1",
    "published_date": "2024-07-09 03:05:27 UTC",
    "updated_date": "2024-07-09 03:05:27 UTC"
  },
  {
    "arxiv_id": "2407.06512v3",
    "title": "LuSNAR:A Lunar Segmentation, Navigation and Reconstruction Dataset based on Muti-sensor for Autonomous Exploration",
    "authors": [
      "Jiayi Liu",
      "Qianyu Zhang",
      "Xue Wan",
      "Shengyang Zhang",
      "Yaolin Tian",
      "Haodong Han",
      "Yutao Zhao",
      "Baichuan Liu",
      "Zeyuan Zhao",
      "Xubo Luo"
    ],
    "abstract": "With the complexity of lunar exploration missions, the moon needs to have a\nhigher level of autonomy. Environmental perception and navigation algorithms\nare the foundation for lunar rovers to achieve autonomous exploration. The\ndevelopment and verification of algorithms require highly reliable data\nsupport. Most of the existing lunar datasets are targeted at a single task,\nlacking diverse scenes and high-precision ground truth labels. To address this\nissue, we propose a multi-task, multi-scene, and multi-label lunar benchmark\ndataset LuSNAR. This dataset can be used for comprehensive evaluation of\nautonomous perception and navigation systems, including high-resolution stereo\nimage pairs, panoramic semantic labels, dense depth maps, LiDAR point clouds,\nand the position of rover. In order to provide richer scene data, we built 9\nlunar simulation scenes based on Unreal Engine. Each scene is divided according\nto topographic relief and the density of objects. To verify the usability of\nthe dataset, we evaluated and analyzed the algorithms of semantic segmentation,\n3D reconstruction, and autonomous navigation. The experiment results prove that\nthe dataset proposed in this paper can be used for ground verification of tasks\nsuch as autonomous environment perception and navigation, and provides a lunar\nbenchmark dataset for testing the accessibility of algorithm metrics. We make\nLuSNAR publicly available at: https://github.com/zqyu9/LuSNAR-dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 13 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.06512v3",
    "published_date": "2024-07-09 02:47:58 UTC",
    "updated_date": "2024-09-26 02:11:38 UTC"
  },
  {
    "arxiv_id": "2407.07124v1",
    "title": "FedClust: Tackling Data Heterogeneity in Federated Learning through Weight-Driven Client Clustering",
    "authors": [
      "Md Sirajul Islam",
      "Simin Javaherian",
      "Fei Xu",
      "Xu Yuan",
      "Li Chen",
      "Nian-Feng Tzeng"
    ],
    "abstract": "Federated learning (FL) is an emerging distributed machine learning paradigm\nthat enables collaborative training of machine learning models over\ndecentralized devices without exposing their local data. One of the major\nchallenges in FL is the presence of uneven data distributions across client\ndevices, violating the well-known assumption of\nindependent-and-identically-distributed (IID) training samples in conventional\nmachine learning. To address the performance degradation issue incurred by such\ndata heterogeneity, clustered federated learning (CFL) shows its promise by\ngrouping clients into separate learning clusters based on the similarity of\ntheir local data distributions. However, state-of-the-art CFL approaches\nrequire a large number of communication rounds to learn the distribution\nsimilarities during training until the formation of clusters is stabilized.\nMoreover, some of these algorithms heavily rely on a predefined number of\nclusters, thus limiting their flexibility and adaptability. In this paper, we\npropose {\\em FedClust}, a novel approach for CFL that leverages the correlation\nbetween local model weights and the data distribution of clients. {\\em\nFedClust} groups clients into clusters in a one-shot manner by measuring the\nsimilarity degrees among clients based on the strategically selected partial\nweights of locally trained models. We conduct extensive experiments on four\nbenchmark datasets with different non-IID data settings. Experimental results\ndemonstrate that {\\em FedClust} achieves higher model accuracy up to $\\sim$45\\%\nas well as faster convergence with a significantly reduced communication cost\nup to 2.7$\\times$ compared to its state-of-the-art counterparts.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07124v1",
    "published_date": "2024-07-09 02:47:16 UTC",
    "updated_date": "2024-07-09 02:47:16 UTC"
  },
  {
    "arxiv_id": "2407.06507v1",
    "title": "Economic span selection of bridge based on deep reinforcement learning",
    "authors": [
      "Leye Zhang",
      "Xiangxiang Tian",
      "Chengli Zhang",
      "Hongjun Zhang"
    ],
    "abstract": "Deep Q-network algorithm is used to select economic span of bridge. Selection\nof bridge span has a significant impact on the total cost of bridge, and a\nreasonable selection of span can reduce engineering cost. Economic span of\nbridge is theoretically analyzed, and the theoretical solution formula of\neconomic span is deduced. Construction process of bridge simulation environment\nis described in detail, including observation space, action space and reward\nfunction of the environment. Agent is constructed, convolutional neural network\nis used to approximate Q function,{\\epsilon} greedy policy is used for action\nselection, and experience replay is used for training. The test verifies that\nthe agent can successfully learn optimal policy and realize economic span\nselection of bridge. This study provides a potential decision-making tool for\nbridge design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.06507v1",
    "published_date": "2024-07-09 02:27:52 UTC",
    "updated_date": "2024-07-09 02:27:52 UTC"
  },
  {
    "arxiv_id": "2407.06501v3",
    "title": "STORYSUMM: Evaluating Faithfulness in Story Summarization",
    "authors": [
      "Melanie Subbiah",
      "Faisal Ladhak",
      "Akankshya Mishra",
      "Griffin Adams",
      "Lydia B. Chilton",
      "Kathleen McKeown"
    ],
    "abstract": "Human evaluation has been the gold standard for checking faithfulness in\nabstractive summarization. However, with a challenging source domain like\nnarrative, multiple annotators can agree a summary is faithful, while missing\ndetails that are obvious errors only once pointed out. We therefore introduce a\nnew dataset, STORYSUMM, comprising LLM summaries of short stories with\nlocalized faithfulness labels and error explanations. This benchmark is for\nevaluation methods, testing whether a given method can detect challenging\ninconsistencies. Using this dataset, we first show that any one human\nannotation protocol is likely to miss inconsistencies, and we advocate for\npursuing a range of methods when establishing ground truth for a summarization\ndataset. We finally test recent automatic metrics and find that none of them\nachieve more than 70% balanced accuracy on this task, demonstrating that it is\na challenging benchmark for future work in faithfulness evaluation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP Main 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.06501v3",
    "published_date": "2024-07-09 02:06:30 UTC",
    "updated_date": "2025-04-01 16:54:54 UTC"
  },
  {
    "arxiv_id": "2407.06494v4",
    "title": "DiffPhyCon: A Generative Approach to Control Complex Physical Systems",
    "authors": [
      "Long Wei",
      "Peiyan Hu",
      "Ruiqi Feng",
      "Haodong Feng",
      "Yixuan Du",
      "Tao Zhang",
      "Rui Wang",
      "Yue Wang",
      "Zhi-Ming Ma",
      "Tailin Wu"
    ],
    "abstract": "Controlling the evolution of complex physical systems is a fundamental task\nacross science and engineering. Classical techniques suffer from limited\napplicability or huge computational costs. On the other hand, recent deep\nlearning and reinforcement learning-based approaches often struggle to optimize\nlong-term control sequences under the constraints of system dynamics. In this\nwork, we introduce Diffusion Physical systems Control (DiffPhyCon), a new class\nof method to address the physical systems control problem. DiffPhyCon excels by\nsimultaneously minimizing both the learned generative energy function and the\npredefined control objectives across the entire trajectory and control\nsequence. Thus, it can explore globally and plan near-optimal control\nsequences. Moreover, we enhance DiffPhyCon with prior reweighting, enabling the\ndiscovery of control sequences that significantly deviate from the training\ndistribution. We test our method on three tasks: 1D Burgers' equation, 2D\njellyfish movement control, and 2D high-dimensional smoke control, where our\ngenerated jellyfish dataset is released as a benchmark for complex physical\nsystem control research. Our method outperforms widely applied classical\napproaches and state-of-the-art deep learning and reinforcement learning\nmethods. Notably, DiffPhyCon unveils an intriguing fast-close-slow-open pattern\nobserved in the jellyfish, aligning with established findings in the field of\nfluid dynamics. The project website, jellyfish dataset, and code can be found\nat https://github.com/AI4Science-WestlakeU/diffphycon.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 poster. 51 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.06494v4",
    "published_date": "2024-07-09 01:56:23 UTC",
    "updated_date": "2024-10-29 18:28:07 UTC"
  },
  {
    "arxiv_id": "2407.12853v1",
    "title": "Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches",
    "authors": [
      "Islam Eldifrawi",
      "Shengrui Wang",
      "Amine Trabelsi"
    ],
    "abstract": "Automated Fact-Checking (AFC) is the automated verification of claim\naccuracy. AFC is crucial in discerning truth from misinformation, especially\ngiven the huge amounts of content are generated online daily. Current research\nfocuses on predicting claim veracity through metadata analysis and language\nscrutiny, with an emphasis on justifying verdicts. This paper surveys recent\nmethodologies, proposing a comprehensive taxonomy and presenting the evolution\nof research in that landscape. A comparative analysis of methodologies and\nfuture directions for improving fact-checking explainability are also\ndiscussed.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.12853v1",
    "published_date": "2024-07-09 01:54:13 UTC",
    "updated_date": "2024-07-09 01:54:13 UTC"
  },
  {
    "arxiv_id": "2407.06486v2",
    "title": "Optimal Decision Making Through Scenario Simulations Using Large Language Models",
    "authors": [
      "Sumedh Rasal",
      "E. J. Hauer"
    ],
    "abstract": "The rapid evolution of Large Language Models (LLMs) has markedly expanded\ntheir application across diverse domains, transforming how complex problems are\napproached and solved. Initially conceived to predict subsequent words in\ntexts, these models have transcended their original design to comprehend and\nrespond to the underlying contexts of queries. Today, LLMs routinely perform\ntasks that once seemed formidable, such as writing essays, poems, stories, and\neven developing software code. As their capabilities continue to grow, so too\ndo the expectations of their performance in even more sophisticated domains.\n  Despite these advancements, LLMs still encounter significant challenges,\nparticularly in scenarios requiring intricate decision-making, such as planning\ntrips or choosing among multiple viable options. These tasks often demand a\nnuanced understanding of various outcomes and the ability to predict the\nconsequences of different choices, which are currently outside the typical\noperational scope of LLMs.\n  This paper proposes an innovative approach to bridge this capability gap. By\nenabling LLMs to request multiple potential options and their respective\nparameters from users, our system introduces a dynamic framework that\nintegrates an optimization function within the decision-making process. This\nfunction is designed to analyze the provided options, simulate potential\noutcomes, and determine the most advantageous solution based on a set of\npredefined criteria. By harnessing this methodology, LLMs can offer tailored,\noptimal solutions to complex, multi-variable problems, significantly enhancing\ntheir utility and effectiveness in real-world applications. This approach not\nonly expands the functional envelope of LLMs but also paves the way for more\nautonomous and intelligent systems capable of supporting sophisticated\ndecision-making tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06486v2",
    "published_date": "2024-07-09 01:23:09 UTC",
    "updated_date": "2024-07-10 02:57:49 UTC"
  },
  {
    "arxiv_id": "2407.06485v1",
    "title": "CrowdTransfer: Enabling Crowd Knowledge Transfer in AIoT Community",
    "authors": [
      "Yan Liu",
      "Bin Guo",
      "Nuo Li",
      "Yasan Ding",
      "Zhouyangzi Zhang",
      "Zhiwen Yu"
    ],
    "abstract": "Artificial Intelligence of Things (AIoT) is an emerging frontier based on the\ndeep fusion of Internet of Things (IoT) and Artificial Intelligence (AI)\ntechnologies. Although advanced deep learning techniques enhance the efficient\ndata processing and intelligent analysis of complex IoT data, they still suffer\nfrom notable challenges when deployed to practical AIoT applications, such as\nconstrained resources, and diverse task requirements. Knowledge transfer is an\neffective method to enhance learning performance by avoiding the exorbitant\ncosts associated with data recollection and model retraining. Notably, although\nthere are already some valuable and impressive surveys on transfer learning,\nthese surveys introduce approaches in a relatively isolated way and lack the\nrecent advances of various knowledge transfer techniques for AIoT field. This\nsurvey endeavors to introduce a new concept of knowledge transfer, referred to\nas Crowd Knowledge Transfer (CrowdTransfer), which aims to transfer prior\nknowledge learned from a crowd of agents to reduce the training cost and as\nwell as improve the performance of the model in real-world complicated\nscenarios. Particularly, we present four transfer modes from the perspective of\ncrowd intelligence, including derivation, sharing, evolution and fusion modes.\nBuilding upon conventional transfer learning methods, we further delve into\nadvanced crowd knowledge transfer models from three perspectives for various\nAIoT applications. Furthermore, we explore some applications of AIoT areas,\nsuch as human activity recognition, urban computing, multi-robot system, and\nsmart factory. Finally, we discuss the open issues and outline future research\ndirections of knowledge transfer in AIoT community.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted for publication in IEEE Communications\n  Surveys & Tutorials. Copyright will be transferred without notice, after this\n  version may no longer be accessible",
    "pdf_url": "http://arxiv.org/pdf/2407.06485v1",
    "published_date": "2024-07-09 01:20:37 UTC",
    "updated_date": "2024-07-09 01:20:37 UTC"
  }
]