{
  "date": "2024-06-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-26 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于人工智能（AI）、大型语言模型（LLMs）、多模态学习和应用创新等领域，涵盖了从多模态图像生成到生物医学诊断和天气预测的广泛主题。其中，LLMs 在复杂任务中的优化和应用（如 Step-DPO 和 Geode）最为令人印象深刻，而知名学者如 Frank Hutter 和 Ion Stoica 的作品（如 Fast Optimizer Benchmark 和 RouteLLM）突出展示了 AI 优化和多任务泛化的潜力。\n\n下面，我挑选了其中最具影响力和话题度的论文进行简要讨论，将相关主题归类，并快速掠过较次要的文章。重点放在创新性强、实际应用广泛或涉及名人学者的论文上，每篇论文标题以“中文标题 | 英文标题”的格式列出。\n\n### AI 和 LLMs 优化与应用\n- **MUMU: Bootstrapping Multimodal Image Generation | MUMU: Bootstrapping Multimodal Image Generation**  \n  这篇论文由 Alexander Peysakhovich 等作者提出，核心贡献是通过引导多模态数据集训练一个视觉-语言模型（包括扩散解码器），实现从文本和图像混合提示生成连贯的多模态图像。主要发现是模型能处理风格转移和角色一致性，即使训练数据仅来自图像裁剪，也能合成新内容。该方法在多模态生成领域有重要启发，作者的背景提升了其影响力。\n\n- **Step-DPO: Step-wise Preference Optimization | Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs**  \n  作者 Xin Lai 等开发了一种针对 LLMs 长链推理的逐步偏好优化方法。关键创新是将偏好优化细化到每个推理步骤，避免整体评估的局限。主要发现是，使用少量数据（如 10K 对），模型在 MATH 和 GSM8K 数据集上提升了近 3% 的准确率，超越了 GPT-4 和 Gemini-1.5-Pro。该论文在 LLM 优化上具有话题度。\n\n- **RouteLLM: Learning to Route LLMs with Preference Data | RouteLLM: Learning to Route LLMs with Preference Data**  \n  Ion Stoica 等知名学者参与，这篇论文提出了一种基于偏好数据的 LLM 路由框架。核心贡献是动态选择强弱模型以平衡性能和成本，主要发现是路由模型在基准测试中减少了 2 倍成本，同时保持响应质量。该方法为高效 LLM 部署提供了实用指导。\n\n- **Learning to Correct for QA Reasoning with Black-box LLMs | Learning to Correct for QA Reasoning with Black-box LLMs**  \n  这篇论文探索了在黑箱 LLMs 中改进问答推理的方法。作者使用 seq2seq 映射纠正错误推理，主要发现是模型显著提升了 QA 基准的准确率。该工作突出了 LLM 在实际推理任务中的鲁棒性改进。\n\n- **Few-shot Personalization of LLMs with Mis-aligned Responses | Few-shot Personalization of LLMs with Mis-aligned Responses**  \n  相关主题的延续，这篇论文提出 Fermi 框架，通过迭代提示学习个性化 LLM。核心贡献是利用错位响应上下文提升适应性，主要发现是显著改善了个性化基准的性能，与前文 LLM 优化论文互补。\n\n其他如 **Fast Optimizer Benchmark | Fast Optimizer Benchmark**（Frank Hutter 参与，提出深度学习优化工具，但相对常规）和 **DPA-RAG | Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation**（提升 RAG 系统偏好对齐），这些在 LLM 领域有贡献，但细节较琐碎，故快速掠过。\n\n### 多模态和生物医学应用\n- **Geode: A Zero-shot Geospatial Question-Answering Agent | Geode: A Zero-shot Geospatial Question-Answering Agent with Explicit Reasoning and Precise Spatio-Temporal Retrieval**  \n  这篇论文令人印象深刻，作者提出一个零样本地理空间问答代理。核心贡献是结合自注意力机制和时空检索，提升了对地理数据的理解。主要发现是显著改善了复杂查询的准确性，在多模态领域有实际应用潜力。\n\n- **WavRx: A Disease-Agnostic, Generalizable, and Privacy-Preserving Speech Health Diagnostic Model | WavRx: A Disease-Agnostic, Generalizable, and Privacy-Preserving Speech Health Diagnostic Model**  \n  作者开发了一个通用的语音健康诊断模型。核心贡献是捕捉呼吸和发音动态，同时保护隐私。主要发现是模型在多个数据集上达到新状态-of-the-art，并在隐私保护中表现出色。该论文在生物医学 AI 上有话题度。\n\n- **LLM-Driven Multimodal Opinion Expression Identification | LLM-Driven Multimodal Opinion Expression Identification**  \n  这篇论文将 LLMs 应用于多模态情感识别。核心贡献是结合语音和文本模态识别意见表达，主要发现是显著提升了情感分析性能，扩展了 LLM 的应用场景。\n\n其他生物相关如 **EHR-Based Mobile and Web Platform | EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction**（使用 LLMs 预测慢性病风险，但实现细节较常规），快速掠过。\n\n### 其他领域创新\n- **WV-Net: A foundation model for SAR WV-mode satellite imagery | WV-Net: A foundation model for SAR WV-mode satellite imagery trained using contrastive self-supervised learning**  \n  作者 Peter Sadowski 等提出一个基于对比自监督学习的 SAR 图像模型。核心贡献是使用近 10 百万图像训练，提升了波高估计和分类任务的性能。主要发现是模型在海洋监测中优于 ImageNet 预训练模型，具有实际地理应用价值。\n\n- **Conformalized Link Prediction on Graph Neural Networks | Conformalized Link Prediction on Graph Neural Networks**  \n  这篇论文在图神经网络领域创新，引入无分布假设的预测区间。核心贡献是结合图结构和幂律分布，提高了链接预测的鲁棒性。主要发现是显著提升了预测效率和覆盖率。\n\n其他如 **AlphaForge | AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha Factors**（金融 AI 框架，但主题较窄）和 **Graph Neural Networks for Emulation of Finite-Element Ice Dynamics | Graph Neural Networks for Emulation of Finite-Element Ice Dynamics**（天气模拟，但不那么突出），这些论文有技术贡献，但影响力有限，故仅简要提及。\n\n今天的论文总量达 108 篇，许多涉及理论数学、优化工具或小众领域（如量子模型或特定图像处理），这些相对无聊或不那么重要的文章（如纯理论的 Kolmogorov-Arnold Graph Neural Networks），我已快速掠过，仅列出标题而不深究，以控制篇幅。总体而言，这些论文突显了 AI 在多领域融合的潜力，期待后续应用落地。明天见！",
  "papers": [
    {
      "arxiv_id": "2406.18790v2",
      "title": "MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data",
      "title_zh": "翻译失败",
      "authors": [
        "William Berman",
        "Alexander Peysakhovich"
      ],
      "abstract": "We train a model to generate images from multimodal prompts of interleaved\ntext and images such as \"a <picture of a man> man and his <picture of a dog>\ndog in an <picture of a cartoon> animated style.\" We bootstrap a multimodal\ndataset by extracting semantically meaningful image crops corresponding to\nwords in the image captions of synthetically generated and publicly available\ntext-image data. Our model, MUMU, is composed of a vision-language model\nencoder with a diffusion decoder and is trained on a single 8xH100 GPU node.\nDespite being only trained on crops from the same image, MUMU learns to compose\ninputs from different images into a coherent output. For example, an input of a\nrealistic person and a cartoon will output the same person in the cartoon\nstyle, and an input of a standing subject and a scooter will output the subject\nriding the scooter. As a result, our model generalizes to tasks such as style\ntransfer and character consistency. Our results show the promise of using\nmultimodal models as general purpose controllers for image generation.",
      "tldr_zh": "该研究提出 MUMU 模型，通过从合成和公开的文本-图像数据中提取语义图像作物来构建多模态数据集，从而实现从交替文本和图像提示（如“a <picture of a man> man”）生成图像。MUMU 由 vision-language model encoder 和 diffusion decoder 组成，并在单 8xH100 GPU 节点上训练，尽管仅使用同一图像的作物，模型仍能将不同图像输入组合成连贯输出，例如将现实人物转化为卡通风格或调整主体姿势。实验结果显示，MUMU 推广到风格转移（style transfer）和角色一致性（character consistency）等任务，证明了多模态模型作为图像生成通用控制器的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18790v2",
      "published_date": "2024-06-26 23:21:42 UTC",
      "updated_date": "2024-09-11 21:56:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:47:01.365055"
    },
    {
      "arxiv_id": "2407.11014v1",
      "title": "Geode: A Zero-shot Geospatial Question-Answering Agent with Explicit Reasoning and Precise Spatio-Temporal Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Devashish Vikas Gupta",
        "Azeez Syed Ali Ishaqui",
        "Divya Kiran Kadiyala"
      ],
      "abstract": "Large language models (LLMs) have shown promising results in learning and\ncontextualizing information from different forms of data. Recent advancements\nin foundational models, particularly those employing self-attention mechanisms,\nhave significantly enhanced our ability to comprehend the semantics of diverse\ndata types. One such area that could highly benefit from multi-modality is in\nunderstanding geospatial data, which inherently has multiple modalities.\nHowever, current Natural Language Processing (NLP) mechanisms struggle to\neffectively address geospatial queries. Existing pre-trained LLMs are\ninadequately equipped to meet the unique demands of geospatial data, lacking\nthe ability to retrieve precise spatio-temporal data in real-time, thus leading\nto significantly reduced accuracy in answering complex geospatial queries. To\naddress these limitations, we introduce Geode--a pioneering system designed to\ntackle zero-shot geospatial question-answering tasks with high precision using\nspatio-temporal data retrieval. Our approach represents a significant\nimprovement in addressing the limitations of current LLM models, demonstrating\nremarkable improvement in geospatial question-answering abilities compared to\nexisting state-of-the-art pre-trained models.",
      "tldr_zh": "该研究指出，现有的 LLMs 在处理地理空间查询时存在局限性，无法实时检索精确的 spatio-temporal 数据，导致问答准确性降低。为解决这一问题，论文引入 Geode，这是一个 zero-shot 地理空间问答代理，采用 Explicit Reasoning 和 Precise Spatio-Temporal Retrieval 方法，实现高精度查询处理。实验结果显示，Geode 相较于现有最先进模型，在地理空间问答任务上取得了显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11014v1",
      "published_date": "2024-06-26 21:59:54 UTC",
      "updated_date": "2024-06-26 21:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:47:12.694045"
    },
    {
      "arxiv_id": "2406.18765v1",
      "title": "WV-Net: A foundation model for SAR WV-mode satellite imagery trained using contrastive self-supervised learning on 10 million images",
      "title_zh": "翻译失败",
      "authors": [
        "Yannik Glaser",
        "Justin E. Stopa",
        "Linnea M. Wolniewicz",
        "Ralph Foster",
        "Doug Vandemark",
        "Alexis Mouche",
        "Bertrand Chapron",
        "Peter Sadowski"
      ],
      "abstract": "The European Space Agency's Copernicus Sentinel-1 (S-1) mission is a\nconstellation of C-band synthetic aperture radar (SAR) satellites that provide\nunprecedented monitoring of the world's oceans. S-1's wave mode (WV) captures\n20x20 km image patches at 5 m pixel resolution and is unaffected by cloud cover\nor time-of-day. The mission's open data policy has made SAR data easily\naccessible for a range of applications, but the need for manual image\nannotations is a bottleneck that hinders the use of machine learning methods.\nThis study uses nearly 10 million WV-mode images and contrastive\nself-supervised learning to train a semantic embedding model called WV-Net. In\nmultiple downstream tasks, WV-Net outperforms a comparable model that was\npre-trained on natural images (ImageNet) with supervised learning. Experiments\nshow improvements for estimating wave height (0.50 vs 0.60 RMSE using linear\nprobing), estimating near-surface air temperature (0.90 vs 0.97 RMSE), and\nperforming multilabel-classification of geophysical and atmospheric phenomena\n(0.96 vs 0.95 micro-averaged AUROC). WV-Net embeddings are also superior in an\nunsupervised image-retrieval task and scale better in data-sparse settings.\nTogether, these results demonstrate that WV-Net embeddings can support\ngeophysical research by providing a convenient foundation model for a variety\nof data analysis and exploration tasks.",
      "tldr_zh": "本文开发了WV-Net，一种针对SAR WV-mode卫星图像的基模型，通过对比自监督学习(self-supervised learning)在近1000万图像上进行训练，解决了手动标注的瓶颈问题。相比于在ImageNet上监督预训练的模型，WV-Net在下游任务中表现出色，包括波高估计(RMSE从0.60降至0.50)、近表面空气温度估计(RMSE从0.97降至0.90)以及多标签分类(微平均AUROC从0.95升至0.96)。此外，WV-Net在无监督图像检索任务中表现优越，并在数据稀缺场景下具有更好的扩展性。该模型为地球物理研究提供了一个便利的基础模型，支持各种数据分析和探索任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "J.2; I.4.10"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 9 figures, submitted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18765v1",
      "published_date": "2024-06-26 21:30:41 UTC",
      "updated_date": "2024-06-26 21:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:47:27.735078"
    },
    {
      "arxiv_id": "2406.18763v2",
      "title": "Conformalized Link Prediction on Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Zhao",
        "Jian Kang",
        "Lu Cheng"
      ],
      "abstract": "Graph Neural Networks (GNNs) excel in diverse tasks, yet their applications\nin high-stakes domains are often hampered by unreliable predictions. Although\nnumerous uncertainty quantification methods have been proposed to address this\nlimitation, they often lack \\textit{rigorous} uncertainty estimates. This work\nmakes the first attempt to introduce a distribution-free and model-agnostic\nuncertainty quantification approach to construct a predictive interval with a\nstatistical guarantee for GNN-based link prediction. We term it as\n\\textit{conformalized link prediction.} Our approach builds upon conformal\nprediction (CP), a framework that promises to construct statistically robust\nprediction sets or intervals. We first theoretically and empirically establish\na permutation invariance condition for the application of CP in link prediction\ntasks, along with an exact test-time coverage. Leveraging the important\nstructural information in graphs, we then identify a novel and crucial\nconnection between a graph's adherence to the power law distribution and the\nefficiency of CP. This insight leads to the development of a simple yet\neffective sampling-based method to align the graph structure with a power law\ndistribution prior to the standard CP procedure. Extensive experiments\ndemonstrate that for conformalized link prediction, our approach achieves the\ndesired marginal coverage while significantly improving the efficiency of CP\ncompared to baseline methods.",
      "tldr_zh": "这篇论文针对 Graph Neural Networks (GNNs) 在链接预测中的不确定性问题，首次引入了无分布假设且模型无关的 conformalized link prediction 方法，以构建具有统计保证的预测区间。作者建立了 permutation invariance 条件，确保 CP (conformal prediction) 在链接预测任务中的精确覆盖，并发现了图结构遵循 power law distribution 与 CP 效率的相关性，进而开发了一种基于采样的方法来优化图结构。实验结果表明，该方法实现了预期的边际覆盖率，并显著提高了 CP 的效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18763v2",
      "published_date": "2024-06-26 21:17:37 UTC",
      "updated_date": "2024-07-18 22:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:47:37.418931"
    },
    {
      "arxiv_id": "2406.18757v2",
      "title": "The Impact of Feature Representation on the Accuracy of Photonic Neural Networks",
      "title_zh": "特征表示对光子神经网络准确性的影响",
      "authors": [
        "Mauricio Gomes de Queiroz",
        "Paul Jimenez",
        "Raphael Cardoso",
        "Mateus Vidaletti Costa",
        "Mohab Abdalla",
        "Ian O'Connor",
        "Alberto Bosio",
        "Fabio Pavanello"
      ],
      "abstract": "Photonic Neural Networks (PNNs) are gaining significant interest in the\nresearch community due to their potential for high parallelization, low\nlatency, and energy efficiency. PNNs compute using light, which leads to\nseveral differences in implementation when compared to electronics, such as the\nneed to represent input features in the photonic domain before feeding them\ninto the network. In this encoding process, it is common to combine multiple\nfeatures into a single input to reduce the number of inputs and associated\ndevices, leading to smaller and more energy-efficient PNNs. Although this\nalters the network's handling of input data, its impact on PNNs remains\nunderstudied. This paper addresses this open question, investigating the effect\nof commonly used encoding strategies that combine features on the performance\nand learning capabilities of PNNs. Here, using the concept of feature\nimportance, we develop a mathematical methodology for analyzing feature\ncombination. Through this methodology, we demonstrate that encoding multiple\nfeatures together in a single input determines their relative importance, thus\nlimiting the network's ability to learn from the data. Given some prior\nknowledge of the data, however, this can also be leveraged for higher accuracy.\nBy selecting an optimal encoding method, we achieve up to a 12.3% improvement\nin accuracy of PNNs trained on the Iris dataset compared to other encoding\ntechniques, surpassing the performance of networks where features are not\ncombined. These findings highlight the importance of carefully choosing the\nencoding to the accuracy and decision-making strategies of PNNs, particularly\nin size or power constrained applications.",
      "tldr_zh": "该研究探讨了特征表示方式对光子神经网络（Photonic Neural Networks, PNNs）的准确率影响，PNNs 因其高并行化、低延迟和能源效率而备受关注，但需将输入特征转换为光子域，且常通过组合多个特征来减少输入设备。作者开发了一种基于特征重要性（feature importance）的数学方法，分析了常见编码策略对 PNNs 性能和学习能力的冲击，发现特征组合会改变特征的相对重要性，从而限制网络的学习效果。实验结果显示，在 Iris 数据集上，使用最优编码方法比其他技术提高了 12.3% 的准确率，甚至超过了不组合特征的网络，这强调了在尺寸或功率受限应用中选择适当编码策略的重要性。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18757v2",
      "published_date": "2024-06-26 20:55:26 UTC",
      "updated_date": "2024-06-28 17:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:47:49.741792"
    },
    {
      "arxiv_id": "2406.18747v2",
      "title": "A Stem-Agnostic Single-Decoder System for Music Source Separation Beyond Four Stems",
      "title_zh": "翻译失败",
      "authors": [
        "Karn N. Watcharasupat",
        "Alexander Lerch"
      ],
      "abstract": "Despite significant recent progress across multiple subtasks of audio source\nseparation, few music source separation systems support separation beyond the\nfour-stem vocals, drums, bass, and other (VDBO) setup. Of the very few current\nsystems that support source separation beyond this setup, most continue to rely\non an inflexible decoder setup that can only support a fixed pre-defined set of\nstems. Increasing stem support in these inflexible systems correspondingly\nrequires increasing computational complexity, rendering extensions of these\nsystems computationally infeasible for long-tail instruments. In this work, we\npropose Banquet, a system that allows source separation of multiple stems using\njust one decoder. A bandsplit source separation model is extended to work in a\nquery-based setup in tandem with a music instrument recognition PaSST model. On\nthe MoisesDB dataset, Banquet, at only 24.9 M trainable parameters, approached\nthe performance level of the significantly more complex 6-stem Hybrid\nTransformer Demucs on VDBO stems and outperformed it on guitar and piano. The\nquery-based setup allows for the separation of narrow instrument classes such\nas clean acoustic guitars, and can be successfully applied to the extraction of\nless common stems such as reeds and organs. Implementation is available at\nhttps://github.com/kwatcharasupat/query-bandit.",
      "tldr_zh": "本论文提出Banquet系统，这是一种不依赖特定声道的单解码器框架，用于音乐源分离，支持超过四声道（VDBO）的设置，从而解决现有系统灵活性和计算复杂度问题。Banquet通过扩展bandsplit source separation模型，结合query-based setup和music instrument recognition PaSST模型，实现高效的多声道分离。实验结果显示，在MoisesDB数据集上，该系统仅需24.9 M可训练参数，就在VDBO声道上接近更复杂的6-stem Hybrid Transformer Demucs性能，并在吉他和钢琴分离上表现出色，同时能处理窄类仪器如干净原声吉他，以及不常见声道如reeds和organs。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to the 25th International Society for Music Information\n  Retrieval Conference (ISMIR 2024). Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.18747v2",
      "published_date": "2024-06-26 20:25:53 UTC",
      "updated_date": "2024-08-26 01:07:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:48:02.753719"
    },
    {
      "arxiv_id": "2406.18741v1",
      "title": "Decentralized Semantic Traffic Control in AVs Using RL and DQN for Dynamic Roadblocks",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuel Figetakis",
        "Yahuza Bello",
        "Ahmed Refaey",
        "Abdallah Shami"
      ],
      "abstract": "Autonomous Vehicles (AVs), furnished with sensors capable of capturing\nessential vehicle dynamics such as speed, acceleration, and precise location,\npossess the capacity to execute intelligent maneuvers, including lane changes,\nin anticipation of approaching roadblocks. Nevertheless, the sheer volume of\nsensory data and the processing necessary to derive informed decisions can\noften overwhelm the vehicles, rendering them unable to handle the task\nindependently. Consequently, a common approach in traffic scenarios involves\ntransmitting the data to servers for processing, a practice that introduces\nchallenges, particularly in situations demanding real-time processing. In\nresponse to this challenge, we present a novel DL-based semantic traffic\ncontrol system that entrusts semantic encoding responsibilities to the vehicles\nthemselves. This system processes driving decisions obtained from a\nReinforcement Learning (RL) agent, streamlining the decision-making process.\nSpecifically, our framework envisions scenarios where abrupt roadblocks\nmaterialize due to factors such as road maintenance, accidents, or vehicle\nrepairs, necessitating vehicles to make determinations concerning lane-keeping\nor lane-changing actions to navigate past these obstacles. To formulate this\nscenario mathematically, we employ a Markov Decision Process (MDP) and harness\nthe Deep Q Learning (DQN) algorithm to unearth viable solutions.",
      "tldr_zh": "本研究针对自主车辆（AVs）在面对动态路障（如道路维护或事故）时的数据处理挑战，提出了一种去中心化的语义交通控制系统。该系统让车辆自行负责语义编码，利用强化学习（RL）代理来优化驾驶决策，并通过Markov Decision Process (MDP) 和 Deep Q Learning (DQN) 算法建模并解决车道保持或变道行为。相比传统依赖服务器的方法，该框架提升了实时处理能力，有助于AVs 更高效地应对突发场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18741v1",
      "published_date": "2024-06-26 20:12:48 UTC",
      "updated_date": "2024-06-26 20:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:48:12.992792"
    },
    {
      "arxiv_id": "2406.18731v1",
      "title": "WavRx: a Disease-Agnostic, Generalizable, and Privacy-Preserving Speech Health Diagnostic Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zhu",
        "Tiago Falk"
      ],
      "abstract": "Speech is known to carry health-related attributes, which has emerged as a\nnovel venue for remote and long-term health monitoring. However, existing\nmodels are usually tailored for a specific type of disease, and have been shown\nto lack generalizability across datasets. Furthermore, concerns have been\nraised recently towards the leakage of speaker identity from health embeddings.\nTo mitigate these limitations, we propose WavRx, a speech health diagnostics\nmodel that captures the respiration and articulation related dynamics from a\nuniversal speech representation. Our in-domain and cross-domain experiments on\nsix pathological speech datasets demonstrate WavRx as a new state-of-the-art\nhealth diagnostic model. Furthermore, we show that the amount of speaker\nidentity entailed in the WavRx health embeddings is significantly reduced\nwithout extra guidance during training. An in-depth analysis of the model was\nperformed, thus providing physiological interpretation of its improved\ngeneralizability and privacy-preserving ability.",
      "tldr_zh": "该研究提出 WavRx，一种不依赖特定疾病的语音健康诊断模型，具有泛化性和隐私保护能力，旨在解决现有模型在泛化性和说话者身份泄露方面的局限性。WavRx 通过从通用语音表示中捕获呼吸和发音相关动态，实现对多种病理语音的诊断。实验结果显示，该模型在六个病理语音数据集上的同域和跨域测试中，达到了新的最先进水平，同时显著减少了健康嵌入中说话者身份的信息泄露，并通过深入分析提供了生理解释。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "Under review; Model script available at\n  https://github.com/zhu00121/WavRx",
      "pdf_url": "http://arxiv.org/pdf/2406.18731v1",
      "published_date": "2024-06-26 19:59:21 UTC",
      "updated_date": "2024-06-26 19:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:48:25.173731"
    },
    {
      "arxiv_id": "2406.18701v1",
      "title": "Fast Optimizer Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Blauth",
        "Tobias Bürger",
        "Zacharias Häringer",
        "Jörg Franke",
        "Frank Hutter"
      ],
      "abstract": "In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed\nfor evaluating deep learning optimizers during their development. The benchmark\nsupports tasks from multiple domains such as computer vision, natural language\nprocessing, and graph learning. The focus is on convenient usage, featuring\nhuman-readable YAML configurations, SLURM integration, and plotting utilities.\nFOB can be used together with existing hyperparameter optimization (HPO) tools\nas it handles training and resuming of runs. The modular design enables\nintegration into custom pipelines, using it simply as a collection of tasks. We\nshowcase an optimizer comparison as a usage example of our tool. FOB can be\nfound on GitHub: https://github.com/automl/FOB.",
      "tldr_zh": "本论文介绍了 Fast Optimizer Benchmark (FOB)，一个专为深度学习优化器开发而设计的评估工具，支持计算机视觉、自然语言处理和图学习等多个领域的任务。FOB 强调易用性，通过 human-readable YAML 配置、SLURM 集成和绘图工具简化操作，并可与现有的 hyperparameter optimization (HPO) 工具结合使用，同时其模块化设计便于集成到自定义管道中。作为示例，论文展示了优化器比较的应用，并提供了 GitHub 仓库链接（https://github.com/automl/FOB）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages + 12 appendix pages, submitted to AutoML Conf 2024 Workshop\n  Track",
      "pdf_url": "http://arxiv.org/pdf/2406.18701v1",
      "published_date": "2024-06-26 19:10:34 UTC",
      "updated_date": "2024-06-26 19:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:48:37.167188"
    },
    {
      "arxiv_id": "2406.18695v2",
      "title": "Learning to Correct for QA Reasoning with Black-box LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyung Kim",
        "Dongyoung Kim",
        "Yiming Yang"
      ],
      "abstract": "An open challenge in recent machine learning is about how to improve the\nreasoning capability of large language models (LLMs) in a black-box setting,\ni.e., without access to detailed information such as output token\nprobabilities. Existing approaches either rely on accessibility (which is often\nunrealistic) or involve significantly increased train- and inference-time\ncosts. This paper addresses those limitations or shortcomings by proposing a\nnovel approach, namely CoBB (Correct for improving QA reasoning of Black-Box\nLLMs). It uses a trained adaptation model to perform a seq2seq mapping from the\noften-imperfect reasonings of the original black-box LLM to the correct or\nimproved reasonings. Specifically, the adaptation model is initialized with a\nrelatively small open-source LLM and adapted over a collection of sub-sampled\ntraining pairs. To select the representative pairs of correct and incorrect\nreasonings, we formulated the dataset construction as an optimization problem\nthat minimizes the statistical divergence between the sampled subset and the\nentire collection, and solved it via a genetic algorithm. We then train the\nadaptation model over the sampled pairs by contrasting the likelihoods of\ncorrect and incorrect reasonings. Our experimental results demonstrate that\nCoBB significantly improves reasoning accuracy across various QA benchmarks,\ncompared to the best-performing adaptation baselines.",
      "tldr_zh": "该研究针对黑-box LLMs 的推理能力改进问题，提出了一种新方法 CoBB（Correct for improving QA reasoning of Black-Box LLMs），旨在无需访问模型详细信息即可提升问答（QA）任务的推理准确率。CoBB 使用一个基于小开源 LLM 初始化并训练的适应模型，通过 seq2seq 映射将原模型的不完美推理转化为正确推理，并采用遗传算法优化采样训练对以最小化统计差异。实验结果显示，CoBB 在各种 QA 基准上显著提高了推理准确率，优于现有适应基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages; EMNLP 2024 (long, main)",
      "pdf_url": "http://arxiv.org/pdf/2406.18695v2",
      "published_date": "2024-06-26 18:57:32 UTC",
      "updated_date": "2024-10-08 06:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:48:49.314007"
    },
    {
      "arxiv_id": "2406.18690v1",
      "title": "Petal-X: Human-Centered Visual Explanations to Improve Cardiovascular Risk Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Diego Rojo",
        "Houda Lamqaddam",
        "Lucija Gosak",
        "Katrien Verbert"
      ],
      "abstract": "Cardiovascular diseases (CVDs), the leading cause of death worldwide, can be\nprevented in most cases through behavioral interventions. Therefore, effective\ncommunication of CVD risk and projected risk reduction by risk factor\nmodification plays a crucial role in reducing CVD risk at the individual level.\nHowever, despite interest in refining risk estimation with improved prediction\nmodels such as SCORE2, the guidelines for presenting these risk estimations in\nclinical practice remained essentially unchanged in the last few years, with\ngraphical score charts (GSCs) continuing to be one of the prevalent systems.\nThis work describes the design and implementation of Petal-X, a novel tool to\nsupport clinician-patient shared decision-making by explaining the CVD risk\ncontributions of different factors and facilitating what-if analysis. Petal-X\nrelies on a novel visualization, Petal Product Plots, and a tailor-made global\nsurrogate model of SCORE2, whose fidelity is comparable to that of the GSCs\nused in clinical practice. We evaluated Petal-X compared to GSCs in a\ncontrolled experiment with 88 healthcare students, all but one with experience\nwith chronic patients. The results show that Petal-X outperforms GSC in\ncritical tasks, such as comparing the contribution to the patient's 10-year CVD\nrisk of each modifiable risk factor, without a significant loss of perceived\ntransparency, trust, or intent to use. Our study provides an innovative\napproach to the visualization and explanation of risk in clinical practice\nthat, due to its model-agnostic nature, could continue to support\nnext-generation artificial intelligence risk assessment models.",
      "tldr_zh": "本研究针对心血管疾病（CVDs）的预防，提出Petal-X工具，以改善风险沟通。该工具采用Petal Product Plots可视化和SCORE2的全局代理模型，帮助临床医生和患者解释风险因素贡献并进行what-if分析，从而支持共享决策。在一项涉及88名医疗学生的对照实验中，Petal-X在比较可修改风险因素对10年CVD风险贡献的任务上优于传统的Graphical Score Charts (GSCs)，同时保持了相似的透明度、信任和使用意图。该方法因其模型无关特性，可扩展至未来AI风险评估模型，提供创新的临床实践解决方案。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18690v1",
      "published_date": "2024-06-26 18:48:50 UTC",
      "updated_date": "2024-06-26 18:48:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:49:02.041649"
    },
    {
      "arxiv_id": "2406.18682v2",
      "title": "The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm",
      "title_zh": "多语言对齐棱镜：对齐全球和本地偏好以减少危害",
      "authors": [
        "Aakanksha",
        "Arash Ahmadian",
        "Beyza Ermis",
        "Seraphina Goldfarb-Tarrant",
        "Julia Kreutzer",
        "Marzieh Fadaee",
        "Sara Hooker"
      ],
      "abstract": "A key concern with the concept of \"alignment\" is the implicit question of\n\"alignment to what?\". AI systems are increasingly used across the world, yet\nsafety alignment is often focused on homogeneous monolingual settings.\nAdditionally, preference training and safety measures often overfit to harms\ncommon in Western-centric datasets. Here, we explore the viability of different\nalignment approaches when balancing dual objectives: addressing and optimizing\nfor a non-homogeneous set of languages and cultural preferences while\nminimizing both global and local harms. We collect the first set of human\nannotated red-teaming prompts in different languages distinguishing between\nglobal and local harm, which serve as a laboratory for understanding the\nreliability of alignment techniques when faced with preference distributions\nthat are non-stationary across geographies and languages. While this setting is\nseldom covered by the literature to date, which primarily centers on English\nharm mitigation, it captures real-world interactions with AI systems around the\nworld. We establish a new precedent for state-of-the-art alignment techniques\nacross 6 languages with minimal degradation in general performance. Our work\nprovides important insights into cross-lingual transfer and novel optimization\napproaches to safeguard AI systems designed to serve global populations.",
      "tldr_zh": "该研究探讨了AI系统对齐（alignment）的关键问题，即“对齐什么？”，强调需要在多语言和文化环境中平衡全球和本地偏好以减少危害。研究者收集了首套人类标注的红队测试提示（red-teaming prompts）在不同语言中，区分全球和本地危害，并以此评估对齐技术在非平稳偏好分布下的可靠性。实验结果显示，在6种语言中，该方法建立了新的最先进对齐技术，同时最小化一般性能退化，并提供了跨语言转移（cross-lingual transfer）和优化策略的宝贵见解，以更好地保护面向全球人口的AI系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18682v2",
      "published_date": "2024-06-26 18:39:08 UTC",
      "updated_date": "2024-07-08 14:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:49:14.536884"
    },
    {
      "arxiv_id": "2406.18679v1",
      "title": "Speakers Unembedded: Embedding-free Approach to Long-form Neural Diarization",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Li",
        "Vivek Govindan",
        "Rohit Paturi",
        "Sundararajan Srinivasan"
      ],
      "abstract": "End-to-end neural diarization (EEND) models offer significant improvements\nover traditional embedding-based Speaker Diarization (SD) approaches but falls\nshort on generalizing to long-form audio with large number of speakers.\nEEND-vector-clustering method mitigates this by combining local EEND with\nglobal clustering of speaker embeddings from local windows, but this requires\nan additional speaker embedding framework alongside the EEND module. In this\npaper, we propose a novel framework applying EEND both locally and globally for\nlong-form audio without separate speaker embeddings. This approach achieves\nsignificant relative DER reduction of 13% and 10% over the conventional 1-pass\nEEND on Callhome American English and RT03-CTS datasets respectively and\nmarginal improvements over EEND-vector-clustering without the need for\nadditional speaker embeddings. Furthermore, we discuss the computational\ncomplexity of our proposed framework and explore strategies for reducing\nprocessing times.",
      "tldr_zh": "本研究提出了一种无嵌入（embedding-free）的框架，用于处理长音频的神经说话人二值化（neural diarization），旨在解决端到端神经二值化（EEND）模型在多说话人场景下泛化能力不足的问题。该框架在局部和全局层面均应用 EEND，而无需额外的说话者嵌入模块，从而简化了系统设计。在 Callhome American English 和 RT03-CTS 数据集上，该方法比传统的 1-pass EEND 分别降低了 13% 和 10% 的二值化错误率（DER），并在性能上略优于 EEND-vector-clustering 方法。此外，论文讨论了该框架的计算复杂性，并探索了减少处理时间的策略。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18679v1",
      "published_date": "2024-06-26 18:32:16 UTC",
      "updated_date": "2024-06-26 18:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:49:26.114861"
    },
    {
      "arxiv_id": "2406.18678v2",
      "title": "Few-shot Personalization of LLMs with Mis-aligned Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyung Kim",
        "Yiming Yang"
      ],
      "abstract": "As the diversity of users increases, the capability of providing personalized\nresponses by large language models (LLMs) has become increasingly important.\nExisting approaches have only limited successes in LLM personalization, due to\nthe absence of personalized learning or the reliance on shared personal data.\nThis paper proposes a new approach for a few-shot personalization of LLMs with\ntheir mis-aligned responses (Fermi). Our key idea is to learn a set of\npersonalized prompts for each user by progressively improving the prompts using\nLLMs, based on user profile (e.g., demographic information) and a few examples\nof previous opinions. During an iterative process of prompt improvement, we\nincorporate the contexts of mis-aligned responses by LLMs, which are especially\ncrucial for the effective personalization of LLMs. In addition, we develop an\neffective inference method to further leverage the context of the test query\nand the personalized prompts. Our experimental results demonstrate that Fermi\nsignificantly improves performance across various benchmarks, compared to\nbest-performing baselines.",
      "tldr_zh": "这篇论文提出了一种名为 Fermi 的 few-shot 个性化方法，用于处理大型语言模型 (LLMs) 的 mis-aligned responses，从而提升个性化响应的能力。Fermi 的核心机制是通过迭代改进一组个性化 prompts，利用用户配置文件（如人口统计信息）和少数示例意见，同时融入 LLMs 的错误对齐响应上下文，以实现有效的个性化学习。此外，该方法开发了一种推理技术，进一步利用测试查询的上下文和个性化 prompts。实验结果显示，Fermi 在各种基准上显著优于最佳基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NAACL 25 (main, long), 32 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.18678v2",
      "published_date": "2024-06-26 18:29:12 UTC",
      "updated_date": "2025-03-04 03:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:49:38.135784"
    },
    {
      "arxiv_id": "2406.18676v2",
      "title": "Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Guanting Dong",
        "Yutao Zhu",
        "Chenghao Zhang",
        "Zechen Wang",
        "Zhicheng Dou",
        "Ji-Rong Wen"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has demonstrated effectiveness in\nmitigating the hallucination problem of large language models (LLMs). However,\nthe difficulty of aligning the retriever with the diverse LLMs' knowledge\npreferences inevitably poses an inevitable challenge in developing a reliable\nRAG system. To address this issue, we propose DPA-RAG, a universal framework\ndesigned to align diverse knowledge preferences within RAG systems.\nSpecifically, we initially introduce a preference knowledge construction\npipline and incorporate five novel query augmentation strategies to alleviate\npreference data scarcity. Based on preference data, DPA-RAG accomplishes both\nexternal and internal preference alignment: 1) It jointly integrate pair-wise,\npoint-wise, and contrastive preference alignment abilities into the reranker,\nachieving external preference alignment among RAG components. 2) It further\nintroduces a pre-aligned stage before vanilla Supervised Fine-tuning (SFT),\nenabling LLMs to implicitly capture knowledge aligned with their reasoning\npreferences, achieving LLMs' internal alignment. Experimental results across\nfour knowledge-intensive QA datasets demonstrate that DPA-RAG outperforms all\nbaselines and seamlessly integrates both black-box and open-sourced LLM\nreaders. Further qualitative analysis and discussions also provide empirical\nguidance for achieving reliable RAG systems. Our code is publicly available at\nhttps://github.com/dongguanting/DPA-RAG.",
      "tldr_zh": "这篇论文提出了 DPA-RAG 框架，用于解决 Retrieval-Augmented Generation (RAG) 系统在与 Large Language Models (LLMs) 知识偏好对齐方面的挑战。框架通过一个偏好知识构建流程和五种查询增强策略来缓解偏好数据稀缺问题，并实现双重对齐：外部对齐将成对、点式和对比偏好整合到 reranker 中，内部对齐则在 Supervised Fine-tuning (SFT) 前引入预对齐阶段，让 LLMs 隐式捕获与其推理偏好一致的知识。实验结果显示，在四个知识密集型 QA 数据集上，DPA-RAG 优于所有基线模型，并兼容黑盒和开源 LLM，提供可靠 RAG 系统的实证指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2406.18676v2",
      "published_date": "2024-06-26 18:26:53 UTC",
      "updated_date": "2024-07-18 08:28:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:49:51.096596"
    },
    {
      "arxiv_id": "2406.18675v2",
      "title": "Human-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants",
      "title_zh": "人类-AI 协作分类法构建：特定职业写作助手的案例研究",
      "authors": [
        "Minhwa Lee",
        "Zae Myung Kim",
        "Vivek Khetan",
        "Dongyeop Kang"
      ],
      "abstract": "Large Language Models (LLMs) have assisted humans in several writing tasks,\nincluding text revision and story generation. However, their effectiveness in\nsupporting domain-specific writing, particularly in business contexts, is\nrelatively less explored. Our formative study with industry professionals\nrevealed the limitations in current LLMs' understanding of the nuances in such\ndomain-specific writing. To address this gap, we propose an approach of\nhuman-AI collaborative taxonomy development to perform as a guideline for\ndomain-specific writing assistants. This method integrates iterative feedback\nfrom domain experts and multiple interactions between these experts and LLMs to\nrefine the taxonomy. Through larger-scale experiments, we aim to validate this\nmethodology and thus improve LLM-powered writing assistance, tailoring it to\nmeet the unique requirements of different stakeholder needs.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 在支持特定职业写作（如商业环境）方面的局限性，通过形成性研究发现这些模型在理解领域细微差别上存在不足。论文提出一种人类-AI 合作构建taxonomy的方法，该方法整合领域专家的迭代反馈和多次专家与LLMs互动，以完善taxonomy作为领域特定写作助手的指导框架。通过更大规模的实验，旨在验证此方法并提升LLM驱动的写作辅助系统，以满足不同利益相关者的独特需求。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to CHI 2024 In2Writing Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.18675v2",
      "published_date": "2024-06-26 18:25:06 UTC",
      "updated_date": "2024-07-16 00:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:50:02.199265"
    },
    {
      "arxiv_id": "2406.18665v4",
      "title": "RouteLLM: Learning to Route LLMs with Preference Data",
      "title_zh": "翻译失败",
      "authors": [
        "Isaac Ong",
        "Amjad Almahairi",
        "Vincent Wu",
        "Wei-Lin Chiang",
        "Tianhao Wu",
        "Joseph E. Gonzalez",
        "M Waleed Kadous",
        "Ion Stoica"
      ],
      "abstract": "Large language models (LLMs) exhibit impressive capabilities across a wide\nrange of tasks, yet the choice of which model to use often involves a trade-off\nbetween performance and cost. More powerful models, though effective, come with\nhigher expenses, while less capable models are more cost-effective. To address\nthis dilemma, we propose several efficient router models that dynamically\nselect between a stronger and a weaker LLM during inference, aiming to optimize\nthe balance between cost and response quality. We develop a training framework\nfor these routers leveraging human preference data and data augmentation\ntechniques to enhance performance. Our evaluation on widely-recognized\nbenchmarks shows that our approach significantly reduces costs-by over 2 times\nin certain cases-without compromising the quality of responses. Interestingly,\nour router models also demonstrate significant transfer learning capabilities,\nmaintaining their performance even when the strong and weak models are changed\nat test time. This highlights the potential of these routers to provide a\ncost-effective yet high-performance solution for deploying LLMs.",
      "tldr_zh": "这篇论文提出了 RouteLLM，一种基于偏好数据的框架，用于学习路由大型语言模型(LLMs)，以动态选择更强或更弱的模型，从而优化性能和成本的平衡。研究开发了高效的 router models，通过人类偏好数据和数据增强技术进行训练，确保在推理过程中实现最佳决策。在广泛的基准测试中，该方法显著降低了成本（某些情况下超过 2 倍），而不影响响应质量，同时展示了路由模型的强大迁移学习能力，为部署 LLMs 提供了一个高性能且经济高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18665v4",
      "published_date": "2024-06-26 18:10:22 UTC",
      "updated_date": "2025-02-23 08:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:50:14.392987"
    },
    {
      "arxiv_id": "2406.18630v1",
      "title": "Improving Hyperparameter Optimization with Checkpointed Model Weights",
      "title_zh": "利用检查点模型权重改善超参数优化",
      "authors": [
        "Nikhil Mehta",
        "Jonathan Lorraine",
        "Steve Masson",
        "Ramanathan Arunachalam",
        "Zaid Pervaiz Bhat",
        "James Lucas",
        "Arun George Zachariah"
      ],
      "abstract": "When training deep learning models, the performance depends largely on the\nselected hyperparameters. However, hyperparameter optimization (HPO) is often\none of the most expensive parts of model design. Classical HPO methods treat\nthis as a black-box optimization problem. However, gray-box HPO methods, which\nincorporate more information about the setup, have emerged as a promising\ndirection for more efficient optimization. For example, using intermediate loss\nevaluations to terminate bad selections. In this work, we propose an HPO method\nfor neural networks using logged checkpoints of the trained weights to guide\nfuture hyperparameter selections. Our method, Forecasting Model Search (FMS),\nembeds weights into a Gaussian process deep kernel surrogate model, using a\npermutation-invariant graph metanetwork to be data-efficient with the logged\nnetwork weights. To facilitate reproducibility and further research, we\nopen-source our code at https://github.com/NVlabs/forecasting-model-search.",
      "tldr_zh": "本研究针对深度学习模型的超参数优化 (HPO) 问题，提出了一种灰箱优化方法，以提高效率。传统 HPO 将其视为黑箱问题，而新方法 Forecasting Model Search (FMS) 利用训练过程中的检查点权重来指导未来超参数选择，通过将权重嵌入高斯过程深度内核代理模型，并采用置换不变图元网络 (permutation-invariant graph metanetwork) 来实现数据高效优化。该方法不仅提升了 HPO 的性能，还开源了代码（https://github.com/NVlabs/forecasting-model-search），促进了可重复性和进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T05",
        "I.2.6; G.1.6; D.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "See the project website at\n  https://research.nvidia.com/labs/toronto-ai/FMS/",
      "pdf_url": "http://arxiv.org/pdf/2406.18630v1",
      "published_date": "2024-06-26 17:59:54 UTC",
      "updated_date": "2024-06-26 17:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:50:26.157895"
    },
    {
      "arxiv_id": "2406.18532v1",
      "title": "Symbolic Learning Enables Self-Evolving Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Wangchunshu Zhou",
        "Yixin Ou",
        "Shengwei Ding",
        "Long Li",
        "Jialong Wu",
        "Tiannan Wang",
        "Jiamin Chen",
        "Shuai Wang",
        "Xiaohua Xu",
        "Ningyu Zhang",
        "Huajun Chen",
        "Yuchen Eleanor Jiang"
      ],
      "abstract": "The AI community has been exploring a pathway to artificial general\nintelligence (AGI) by developing \"language agents\", which are complex large\nlanguage models (LLMs) pipelines involving both prompting techniques and tool\nusage methods. While language agents have demonstrated impressive capabilities\nfor many real-world tasks, a fundamental limitation of current language agents\nresearch is that they are model-centric, or engineering-centric. That's to say,\nthe progress on prompts, tools, and pipelines of language agents requires\nsubstantial manual engineering efforts from human experts rather than\nautomatically learning from data. We believe the transition from model-centric,\nor engineering-centric, to data-centric, i.e., the ability of language agents\nto autonomously learn and evolve in environments, is the key for them to\npossibly achieve AGI.\n  In this work, we introduce agent symbolic learning, a systematic framework\nthat enables language agents to optimize themselves on their own in a\ndata-centric way using symbolic optimizers. Specifically, we consider agents as\nsymbolic networks where learnable weights are defined by prompts, tools, and\nthe way they are stacked together. Agent symbolic learning is designed to\noptimize the symbolic network within language agents by mimicking two\nfundamental algorithms in connectionist learning: back-propagation and gradient\ndescent. Instead of dealing with numeric weights, agent symbolic learning works\nwith natural language simulacrums of weights, loss, and gradients. We conduct\nproof-of-concept experiments on both standard benchmarks and complex real-world\ntasks and show that agent symbolic learning enables language agents to update\nthemselves after being created and deployed in the wild, resulting in\n\"self-evolving agents\".",
      "tldr_zh": "这项研究指出，现有的语言代理（language agents）依赖手动工程，无法从数据中自主学习，这阻碍了通向人工通用智能（AGI）的进展。作者引入了 agent symbolic learning 框架，将代理视为符号网络，通过模拟 back-propagation 和 gradient descent 的原理，使用自然语言来优化提示、工具和管道结构。实验结果显示，这种框架使代理能够在部署后自我更新，成为“self-evolving agents”，并在标准基准和复杂真实任务上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code available at https://github.com/aiwaves-cn/agents",
      "pdf_url": "http://arxiv.org/pdf/2406.18532v1",
      "published_date": "2024-06-26 17:59:18 UTC",
      "updated_date": "2024-06-26 17:59:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:50:36.383777"
    },
    {
      "arxiv_id": "2406.18518v1",
      "title": "APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets",
      "title_zh": "APIGen：用于生成",
      "authors": [
        "Zuxin Liu",
        "Thai Hoang",
        "Jianguo Zhang",
        "Ming Zhu",
        "Tian Lan",
        "Shirley Kokane",
        "Juntao Tan",
        "Weiran Yao",
        "Zhiwei Liu",
        "Yihao Feng",
        "Rithesh Murthy",
        "Liangwei Yang",
        "Silvio Savarese",
        "Juan Carlos Niebles",
        "Huan Wang",
        "Shelby Heinecke",
        "Caiming Xiong"
      ],
      "abstract": "The advancement of function-calling agent models requires diverse, reliable,\nand high-quality datasets. This paper presents APIGen, an automated data\ngeneration pipeline designed to synthesize verifiable high-quality datasets for\nfunction-calling applications. We leverage APIGen and collect 3,673 executable\nAPIs across 21 different categories to generate diverse function-calling\ndatasets in a scalable and structured manner. Each data in our dataset is\nverified through three hierarchical stages: format checking, actual function\nexecutions, and semantic verification, ensuring its reliability and\ncorrectness. We demonstrate that models trained with our curated datasets, even\nwith only 7B parameters, can achieve state-of-the-art performance on the\nBerkeley Function-Calling Benchmark, outperforming multiple GPT-4 models.\nMoreover, our 1B model achieves exceptional performance, surpassing\nGPT-3.5-Turbo and Claude-3 Haiku. We release a dataset containing 60,000\nhigh-quality entries, aiming to advance the field of function-calling agent\ndomains. The dataset is available on Huggingface:\nhttps://huggingface.co/datasets/Salesforce/xlam-function-calling-60k and the\nproject homepage: https://apigen-pipeline.github.io/",
      "tldr_zh": "本研究引入了 APIGen，一种自动化管道，用于生成可验证且多样的函数调用(function-calling)数据集，以支持函数调用代理模型的进步。APIGen 利用收集的 3,673 个可执行 API 跨越 21 个类别，通过可扩展的结构化方法合成数据集，并通过三个层次验证阶段（format checking、actual function executions 和 semantic verification）确保数据的可靠性和正确性。实验结果显示，使用该数据集训练的 7B 参数模型在 Berkeley Function-Calling Benchmark 上达到了 state-of-the-art 性能，超过了多个 GPT-4 模型，而 1B 参数模型甚至超越了 GPT-3.5-Turbo 和 Claude-3 Haiku。该数据集包含 60,000 个高质量条目，已在 Huggingface 上公开发布，旨在推动函数调用领域的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18518v1",
      "published_date": "2024-06-26 17:49:11 UTC",
      "updated_date": "2024-06-26 17:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:50:50.249691"
    },
    {
      "arxiv_id": "2406.18629v1",
      "title": "Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs",
      "title_zh": "Step-DPO：针对大型语言模型长链推理的逐步偏好优化",
      "authors": [
        "Xin Lai",
        "Zhuotao Tian",
        "Yukang Chen",
        "Senqiao Yang",
        "Xiangru Peng",
        "Jiaya Jia"
      ],
      "abstract": "Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs) due to the extensive and precise chain of reasoning required for\naccuracy. Ensuring the correctness of each reasoning step is critical. To\naddress this, we aim to enhance the robustness and factuality of LLMs by\nlearning from human feedback. However, Direct Preference Optimization (DPO) has\nshown limited benefits for long-chain mathematical reasoning, as models\nemploying DPO struggle to identify detailed errors in incorrect answers. This\nlimitation stems from a lack of fine-grained process supervision. We propose a\nsimple, effective, and data-efficient method called Step-DPO, which treats\nindividual reasoning steps as units for preference optimization rather than\nevaluating answers holistically. Additionally, we have developed a data\nconstruction pipeline for Step-DPO, enabling the creation of a high-quality\ndataset containing 10K step-wise preference pairs. We also observe that in DPO,\nself-generated data is more effective than data generated by humans or GPT-4,\ndue to the latter's out-of-distribution nature. Our findings demonstrate that\nas few as 10K preference data pairs and fewer than 500 Step-DPO training steps\ncan yield a nearly 3% gain in accuracy on MATH for models with over 70B\nparameters. Notably, Step-DPO, when applied to Qwen2-72B-Instruct, achieves\nscores of 70.8% and 94.0% on the test sets of MATH and GSM8K, respectively,\nsurpassing a series of closed-source models, including GPT-4-1106,\nClaude-3-Opus, and Gemini-1.5-Pro. Our code, data, and models are available at\nhttps://github.com/dvlab-research/Step-DPO.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)在数学推理中的挑战，提出了一种Step-DPO方法，通过将每个推理步骤作为偏好优化的单位，而不是整体评估答案，从而提升模型的鲁棒性和事实性，以解决Direct Preference Optimization (DPO)的局限性。研究开发了一个数据构建管道，生成10K对高质量的步骤级偏好数据，并发现自生成数据比人类或GPT-4数据更有效。实验结果显示，仅需10K对数据和少于500训练步骤，就能使70B参数以上模型在MATH数据集上准确率提高近3%；此外，应用Step-DPO于Qwen2-72B-Instruct模型，分别在MATH和GSM8K测试集上达到70.8%和94.0%的分数，超越了GPT-4-1106、Claude-3-Opus和Gemini-1.5-Pro等闭源模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Code, data, and models are available at\n  https://github.com/dvlab-research/Step-DPO",
      "pdf_url": "http://arxiv.org/pdf/2406.18629v1",
      "published_date": "2024-06-26 17:43:06 UTC",
      "updated_date": "2024-06-26 17:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:51:03.995761"
    },
    {
      "arxiv_id": "2407.01603v3",
      "title": "A Review of Large Language Models and Autonomous Agents in Chemistry",
      "title_zh": "翻译失败",
      "authors": [
        "Mayk Caldas Ramos",
        "Christopher J. Collison",
        "Andrew D. White"
      ],
      "abstract": "Large language models (LLMs) have emerged as powerful tools in chemistry,\nsignificantly impacting molecule design, property prediction, and synthesis\noptimization. This review highlights LLM capabilities in these domains and\ntheir potential to accelerate scientific discovery through automation. We also\nreview LLM-based autonomous agents: LLMs with a broader set of tools to\ninteract with their surrounding environment. These agents perform diverse tasks\nsuch as paper scraping, interfacing with automated laboratories, and synthesis\nplanning. As agents are an emerging topic, we extend the scope of our review of\nagents beyond chemistry and discuss across any scientific domains. This review\ncovers the recent history, current capabilities, and design of LLMs and\nautonomous agents, addressing specific challenges, opportunities, and future\ndirections in chemistry. Key challenges include data quality and integration,\nmodel interpretability, and the need for standard benchmarks, while future\ndirections point towards more sophisticated multi-modal agents and enhanced\ncollaboration between agents and experimental methods. Due to the quick pace of\nthis field, a repository has been built to keep track of the latest studies:\nhttps://github.com/ur-whitelab/LLMs-in-science.",
      "tldr_zh": "本综述探讨了Large Language Models (LLMs) 在化学领域的应用，包括分子设计、属性预测和合成优化等方面，并强调了 LLMs 通过自动化加速科学发现的潜力。论文还审视了基于 LLMs 的 Autonomous Agents，这些代理能够执行多样任务，如论文抓取、与自动化实验室交互和合成规划，并扩展讨论到其他科学领域。关键挑战包括数据质量、模型可解释性和标准化基准，而未来方向则聚焦于开发更先进的多模态代理以及加强代理与实验方法的协作。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01603v3",
      "published_date": "2024-06-26 17:33:21 UTC",
      "updated_date": "2024-11-14 23:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:51:14.210863"
    },
    {
      "arxiv_id": "2406.18505v1",
      "title": "Mental Modeling of Reinforcement Learning Agents by Language Models",
      "title_zh": "语言模型对强化学习代理的心智建模",
      "authors": [
        "Wenhao Lu",
        "Xufeng Zhao",
        "Josua Spisak",
        "Jae Hee Lee",
        "Stefan Wermter"
      ],
      "abstract": "Can emergent language models faithfully model the intelligence of\ndecision-making agents? Though modern language models exhibit already some\nreasoning ability, and theoretically can potentially express any probable\ndistribution over tokens, it remains underexplored how the world knowledge\nthese pretrained models have memorized can be utilized to comprehend an agent's\nbehaviour in the physical world. This study empirically examines, for the first\ntime, how well large language models (LLMs) can build a mental model of agents,\ntermed agent mental modelling, by reasoning about an agent's behaviour and its\neffect on states from agent interaction history. This research may unveil the\npotential of leveraging LLMs for elucidating RL agent behaviour, addressing a\nkey challenge in eXplainable reinforcement learning (XRL). To this end, we\npropose specific evaluation metrics and test them on selected RL task datasets\nof varying complexity, reporting findings on agent mental model establishment.\nOur results disclose that LLMs are not yet capable of fully mental modelling\nagents through inference alone without further innovations. This work thus\nprovides new insights into the capabilities and limitations of modern LLMs.",
      "tldr_zh": "本文研究大型语言模型（LLMs）是否能够忠实地建模强化学习（RL）代理的智能，通过分析代理互动历史来推理其行为和对状态的影响。研究首次进行实证评估，提出特定指标并在不同复杂度的RL任务数据集上测试，旨在揭示LLMs在eXplainable reinforcement learning (XRL)中的潜力。结果表明，LLMs目前无法完全通过推理实现agent mental modelling，需要进一步创新，这为理解现代LLMs的能力和限制提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "https://lukaswill.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.18505v1",
      "published_date": "2024-06-26 17:14:45 UTC",
      "updated_date": "2024-06-26 17:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:51:26.704501"
    },
    {
      "arxiv_id": "2407.01464v1",
      "title": "Graph Neural Network as Computationally Efficient Emulator of Ice-sheet and Sea-level System Model (ISSM)",
      "title_zh": "图神经网络作为冰盖和海平面系统模型 (ISSM) 的计算高效仿真器",
      "authors": [
        "Younghyun Koo",
        "Maryam Rahnemoonfar"
      ],
      "abstract": "The Ice-sheet and Sea-level System Model (ISSM) provides solutions for Stokes\nequations relevant to ice sheet dynamics by employing finite element and fine\nmesh adaption. However, since its finite element method is compatible only with\nCentral Processing Units (CPU), the ISSM has limits on further economizing\ncomputational time. Thus, by taking advantage of Graphics Processing Units\n(GPUs), we design a graph convolutional network (GCN) as a fast emulator for\nISSM. The GCN is trained and tested using the 20-year transient ISSM\nsimulations in the Pine Island Glacier (PIG). The GCN reproduces ice thickness\nand velocity with a correlation coefficient greater than 0.998, outperforming\nthe traditional convolutional neural network (CNN). Additionally, GCN shows 34\ntimes faster computational speed than the CPU-based ISSM modeling. The\nGPU-based GCN emulator allows us to predict how the PIG will change in the\nfuture under different melting rate scenarios with high fidelity and much\nfaster computational time.",
      "tldr_zh": "本研究提出使用Graph Neural Network (GCN)作为Ice-sheet and Sea-level System Model (ISSM)的快速模拟器，以解决ISSM基于CPU的有限元方法导致的计算效率问题。GCN利用Graphics Processing Units (GPUs)进行训练和测试，基于Pine Island Glacier (PIG)的20年瞬态模拟数据，成功重现冰厚和速度，相关系数超过0.998，并优于传统Convolutional Neural Network (CNN)。结果显示，GCN的计算速度比CPU-based ISSM快34倍，可高效预测PIG在不同融化率场景下的未来变化，为冰盖动力学模拟提供高保真且快速的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 4 figures, submitted to the 2024 IEEE International\n  Geoscience and Remote Sensing Symposium. arXiv admin note: text overlap with\n  arXiv:2402.05291",
      "pdf_url": "http://arxiv.org/pdf/2407.01464v1",
      "published_date": "2024-06-26 16:13:11 UTC",
      "updated_date": "2024-06-26 16:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:51:39.695746"
    },
    {
      "arxiv_id": "2406.18460v1",
      "title": "Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Njifenjou",
        "Virgile Sucal",
        "Bassam Jabaian",
        "Fabrice Lefèvre"
      ],
      "abstract": "Recently, various methods have been proposed to create open-domain\nconversational agents with Large Language Models (LLMs). These models are able\nto answer user queries, but in a one-way Q&A format rather than a true\nconversation. Fine-tuning on particular datasets is the usual way to modify\ntheir style to increase conversational ability, but this is expensive and\nusually only available in a few languages. In this study, we explore role-play\nzero-shot prompting as an efficient and cost-effective solution for open-domain\nconversation, using capable multilingual LLMs (Beeching et al., 2023) trained\nto obey instructions. We design a prompting system that, when combined with an\ninstruction-following model - here Vicuna (Chiang et al., 2023) - produces\nconversational agents that match and even surpass fine-tuned models in human\nevaluation in French in two different tasks.",
      "tldr_zh": "这篇论文探讨了角色扮演零-shot prompting 的方法，以提升大型语言模型 (LLMs) 在开放域人机对话中的性能，解决传统单向问答格式的局限性。研究者设计了一个提示系统，结合多语言指令遵循模型（如 Vicuna），无需昂贵的微调过程即可生成高质量对话代理。该方法在法语的两个任务中，通过人类评估，其效果匹配甚至超过微调模型，证明了其高效性和跨语言适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated version of a paper originally submitted at SIGDIAL 2023",
      "pdf_url": "http://arxiv.org/pdf/2406.18460v1",
      "published_date": "2024-06-26 16:10:53 UTC",
      "updated_date": "2024-06-26 16:10:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:51:51.350827"
    },
    {
      "arxiv_id": "2406.18451v3",
      "title": "Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Ngnawé",
        "Sabyasachi Sahoo",
        "Yann Pequignot",
        "Frédéric Precioso",
        "Christian Gagné"
      ],
      "abstract": "Despite extensive research on adversarial training strategies to improve\nrobustness, the decisions of even the most robust deep learning models can\nstill be quite sensitive to imperceptible perturbations, creating serious risks\nwhen deploying them for high-stakes real-world applications. While detecting\nsuch cases may be critical, evaluating a model's vulnerability at a\nper-instance level using adversarial attacks is computationally too intensive\nand unsuitable for real-time deployment scenarios. The input space margin is\nthe exact score to detect non-robust samples and is intractable for deep neural\nnetworks. This paper introduces the concept of margin consistency -- a property\nthat links the input space margins and the logit margins in robust models --\nfor efficient detection of vulnerable samples. First, we establish that margin\nconsistency is a necessary and sufficient condition to use a model's logit\nmargin as a score for identifying non-robust samples. Next, through\ncomprehensive empirical analysis of various robustly trained models on CIFAR10\nand CIFAR100 datasets, we show that they indicate high margin consistency with\na strong correlation between their input space margins and the logit margins.\nThen, we show that we can effectively and confidently use the logit margin to\ndetect brittle decisions with such models. Finally, we address cases where the\nmodel is not sufficiently margin-consistent by learning a pseudo-margin from\nthe feature representation. Our findings highlight the potential of leveraging\ndeep representations to assess adversarial vulnerability in deployment\nscenarios efficiently.",
      "tldr_zh": "本研究针对深度学习模型的鲁棒性问题，提出了一种高效检测脆弱决策的方法，即利用“margin consistency”属性来识别非鲁棒样本，而无需昂贵的对抗攻击。研究证明，“margin consistency”是使用“logit margin”作为检测分数（与输入空间 margin 相关联）的必要和充分条件，并在 CIFAR10 和 CIFAR100 数据集上实验验证了鲁棒模型的高一致性，从而实现了对脆弱决策的准确检测。对于不充分一致的模型，作者引入从特征表示中学习“pseudo-margin”的策略。总体结果表明，此方法能高效评估模型的对抗脆弱性，适用于实时部署场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures, 2 tables. Version Update: Neurips Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2406.18451v3",
      "published_date": "2024-06-26 16:00:35 UTC",
      "updated_date": "2024-11-01 02:13:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:52:05.940521"
    },
    {
      "arxiv_id": "2406.18450v2",
      "title": "Preference Elicitation for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Alizée Pace",
        "Bernhard Schölkopf",
        "Gunnar Rätsch",
        "Giorgia Ramponi"
      ],
      "abstract": "Applying reinforcement learning (RL) to real-world problems is often made\nchallenging by the inability to interact with the environment and the\ndifficulty of designing reward functions. Offline RL addresses the first\nchallenge by considering access to an offline dataset of environment\ninteractions labeled by the reward function. In contrast, Preference-based RL\ndoes not assume access to the reward function and learns it from preferences,\nbut typically requires an online interaction with the environment. We bridge\nthe gap between these frameworks by exploring efficient methods for acquiring\npreference feedback in a fully offline setup. We propose Sim-OPRL, an offline\npreference-based reinforcement learning algorithm, which leverages a learned\nenvironment model to elicit preference feedback on simulated rollouts. Drawing\non insights from both the offline RL and the preference-based RL literature,\nour algorithm employs a pessimistic approach for out-of-distribution data, and\nan optimistic approach for acquiring informative preferences about the optimal\npolicy. We provide theoretical guarantees regarding the sample complexity of\nour approach, dependent on how well the offline data covers the optimal policy.\nFinally, we demonstrate the empirical performance of Sim-OPRL in various\nenvironments.",
      "tldr_zh": "这篇论文探讨了强化学习（RL）在实际应用中的挑战，特别是无法与环境互动和设计奖励函数的难题。作者提出Sim-OPRL算法，这是一种离线偏好-based RL方法，通过学习的环境模型在模拟回滚上获取偏好反馈，同时采用悲观方法处理分布外数据和乐观方法优化最优策略。论文提供了样本复杂度的理论保证，取决于离线数据对最优策略的覆盖程度，并通过实验在各种环境中验证了算法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.18450v2",
      "published_date": "2024-06-26 15:59:13 UTC",
      "updated_date": "2025-02-28 08:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:52:17.916255"
    },
    {
      "arxiv_id": "2406.18449v2",
      "title": "Cascading Large Language Models for Salient Event Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xingwei Tan",
        "Yuxiang Zhou",
        "Gabriele Pergola",
        "Yulan He"
      ],
      "abstract": "Generating event graphs from long documents is challenging due to the\ninherent complexity of multiple tasks involved such as detecting events,\nidentifying their relationships, and reconciling unstructured input with\nstructured graphs. Recent studies typically consider all events with equal\nimportance, failing to distinguish salient events crucial for understanding\nnarratives. This paper presents CALLMSAE, a CAscading Large Language Model\nframework for SAlient Event graph generation, which leverages the capabilities\nof LLMs and eliminates the need for costly human annotations. We first identify\nsalient events by prompting LLMs to generate summaries, from which salient\nevents are identified. Next, we develop an iterative code refinement prompting\nstrategy to generate event relation graphs, removing hallucinated relations and\nrecovering missing edges. Powered by CALLMSAE, we present \\textit{NYT-SEG}, a\nlarge-scale automatically annotated event graph dataset which can serve as\ndistant supervision signals. Fine-tuning contextualised graph generation models\non \\textit{NYT-SEG} outperforms the models trained on CAEVO data. Results on a\nhuman-annotated test set show that the proposed method generates salient and\nmore accurate graphs, outperforming competitive baselines.",
      "tldr_zh": "该论文提出CALLMSAE，一种级联Large Language Models框架，用于从长文档生成显著事件图，解决传统方法忽略事件重要性和处理非结构化输入的挑战。首先，通过提示LLMs生成摘要并从中识别显著事件，其次采用迭代代码精炼提示策略来构建事件关系图，移除幻觉关系并恢复缺失边。该框架无需昂贵的人工标注，创建了大规模自动标注数据集NYT-SEG作为远程监督信号；实验显示，在NYT-SEG上微调的模型优于CAEVO数据训练的模型，并在人类标注测试集上生成更准确的显著事件图。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Camera-ready (9 + 14 pages)",
      "pdf_url": "http://arxiv.org/pdf/2406.18449v2",
      "published_date": "2024-06-26 15:53:54 UTC",
      "updated_date": "2025-02-08 17:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:52:26.322805"
    },
    {
      "arxiv_id": "2406.18423v1",
      "title": "Graph Neural Networks for Emulation of Finite-Element Ice Dynamics in Greenland and Antarctic Ice Sheets",
      "title_zh": "翻译失败",
      "authors": [
        "Younghyun Koo",
        "Maryam Rahnemoonfar"
      ],
      "abstract": "Although numerical models provide accurate solutions for ice sheet dynamics\nbased on physics laws, they accompany intensified computational demands to\nsolve partial differential equations. In recent years, convolutional neural\nnetworks (CNNs) have been widely used as statistical emulators for those\nnumerical models. However, since CNNs operate on regular grids, they cannot\nrepresent the refined meshes and computational efficiency of finite-element\nnumerical models. Therefore, instead of CNNs, this study adopts an equivariant\ngraph convolutional network (EGCN) as an emulator for the ice sheet dynamics\nmodeling. EGCN reproduces ice thickness and velocity changes in the Helheim\nGlacier, Greenland, and Pine Island Glacier, Antarctica, with 260 times and 44\ntimes faster computation time, respectively. Compared to the traditional CNN\nand graph convolutional network, EGCN shows outstanding accuracy in thickness\nprediction near fast ice streams by preserving the equivariance to the\ntranslation and rotation of graphs.",
      "tldr_zh": "本文提出使用Equivariant Graph Convolutional Network (EGCN)作为模拟器，来解决传统数值模型在冰盖动力学模拟中的高计算需求问题，因为EGCN能更好地处理有限元模型的精炼网格。研究在格陵兰Helheim Glacier和南极Pine Island Glacier上测试EGCN，成功再现冰厚和速度变化，计算速度分别比传统模型快260倍和44倍。与传统CNN和Graph Convolutional Network相比，EGCN在快速冰流附近的冰厚预测中表现出色，受益于其对图形平移和旋转的等变性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 2 figures, submitted to the ICML 2024 Workshop on Machine\n  Learning for Earth System Modeling",
      "pdf_url": "http://arxiv.org/pdf/2406.18423v1",
      "published_date": "2024-06-26 15:18:49 UTC",
      "updated_date": "2024-06-26 15:18:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:52:38.875966"
    },
    {
      "arxiv_id": "2406.18420v1",
      "title": "Mixture of Experts in a Mixture of RL settings",
      "title_zh": "翻译失败",
      "authors": [
        "Timon Willi",
        "Johan Obando-Ceron",
        "Jakob Foerster",
        "Karolina Dziugaite",
        "Pablo Samuel Castro"
      ],
      "abstract": "Mixtures of Experts (MoEs) have gained prominence in (self-)supervised\nlearning due to their enhanced inference efficiency, adaptability to\ndistributed training, and modularity. Previous research has illustrated that\nMoEs can significantly boost Deep Reinforcement Learning (DRL) performance by\nexpanding the network's parameter count while reducing dormant neurons, thereby\nenhancing the model's learning capacity and ability to deal with\nnon-stationarity. In this work, we shed more light on MoEs' ability to deal\nwith non-stationarity and investigate MoEs in DRL settings with \"amplified\"\nnon-stationarity via multi-task training, providing further evidence that MoEs\nimprove learning capacity. In contrast to previous work, our multi-task results\nallow us to better understand the underlying causes for the beneficial effect\nof MoE in DRL training, the impact of the various MoE components, and insights\ninto how best to incorporate them in actor-critic-based DRL networks. Finally,\nwe also confirm results from previous work.",
      "tldr_zh": "本文研究了 Mixtures of Experts (MoEs) 在 Deep Reinforcement Learning (DRL) 设置中的应用，强调其在处理非平稳性（non-stationarity）方面的优势，通过扩大网络参数并减少休眠神经元来提升学习能力。与以往工作不同，本文通过多任务训练放大非平稳性，深入分析了 MoEs 的有益效果、各个组件的影响，以及如何最佳整合到 actor-critic-based DRL 网络中。实验结果进一步证实了 MoEs 能显著提高 DRL 性能，并为未来应用提供了关键见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18420v1",
      "published_date": "2024-06-26 15:15:15 UTC",
      "updated_date": "2024-06-26 15:15:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:52:54.171831"
    },
    {
      "arxiv_id": "2406.18414v2",
      "title": "BiTrack: Bidirectional Offline 3D Multi-Object Tracking Using Camera-LiDAR Data",
      "title_zh": "BiTrack: 基于相机-LiDAR 数据的",
      "authors": [
        "Kemiao Huang",
        "Yinqi Chen",
        "Meiying Zhang",
        "Qi Hao"
      ],
      "abstract": "Compared with real-time multi-object tracking (MOT), offline multi-object\ntracking (OMOT) has the advantages to perform 2D-3D detection fusion, erroneous\nlink correction, and full track optimization but has to deal with the\nchallenges from bounding box misalignment and track evaluation, editing, and\nrefinement. This paper proposes \"BiTrack\", a 3D OMOT framework that includes\nmodules of 2D-3D detection fusion, initial trajectory generation, and\nbidirectional trajectory re-optimization to achieve optimal tracking results\nfrom camera-LiDAR data. The novelty of this paper includes threefold: (1)\ndevelopment of a point-level object registration technique that employs a\ndensity-based similarity metric to achieve accurate fusion of 2D-3D detection\nresults; (2) development of a set of data association and track management\nskills that utilizes a vertex-based similarity metric as well as false alarm\nrejection and track recovery mechanisms to generate reliable bidirectional\nobject trajectories; (3) development of a trajectory re-optimization scheme\nthat re-organizes track fragments of different fidelities in a greedy fashion,\nas well as refines each trajectory with completion and smoothing techniques.\nThe experiment results on the KITTI dataset demonstrate that BiTrack achieves\nthe state-of-the-art performance for 3D OMOT tasks in terms of accuracy and\nefficiency.",
      "tldr_zh": "该论文提出 BiTrack，一种基于相机-LiDAR 数据的双向离线 3D 多对象跟踪（OMOT）框架，旨在通过 2D-3D 检测融合、初始轨迹生成和双向轨迹再优化模块，解决边界框不对齐以及轨迹评估和精炼的挑战。创新点包括：开发点级对象注册技术使用基于密度的相似度指标实现准确融合；采用顶点-based 相似度指标结合误报拒绝和轨迹恢复机制生成可靠轨迹；以及贪婪式轨迹再优化方案重组和精炼轨迹片段。实验结果在 KITTI 数据集上表明，BiTrack 在 3D OMOT 任务中实现了最先进的准确性和效率性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18414v2",
      "published_date": "2024-06-26 15:09:54 UTC",
      "updated_date": "2025-03-18 14:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:53:08.290756"
    },
    {
      "arxiv_id": "2406.18406v2",
      "title": "IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Shi",
        "Renren Jin",
        "Tianhao Shen",
        "Weilong Dong",
        "Xinwei Wu",
        "Deyi Xiong"
      ],
      "abstract": "It is widely acknowledged that large language models (LLMs) encode a vast\nreservoir of knowledge after being trained on mass data. Recent studies\ndisclose knowledge conflicts in LLM generation, wherein outdated or incorrect\nparametric knowledge (i.e., encoded knowledge) contradicts new knowledge\nprovided in the context. To mitigate such knowledge conflicts, we propose a\nnovel framework, IRCAN (Identifying and Reweighting Context-Aware Neurons) to\ncapitalize on neurons that are crucial in processing contextual cues.\nSpecifically, IRCAN first identifies neurons that significantly contribute to\ncontext processing, utilizing a context-aware attribution score derived from\nintegrated gradients. Subsequently, the identified context-aware neurons are\nstrengthened via reweighting. In doing so, we steer LLMs to generate\ncontext-sensitive outputs with respect to the new knowledge provided in the\ncontext. Extensive experiments conducted across a variety of models and tasks\ndemonstrate that IRCAN not only achieves remarkable improvements in handling\nknowledge conflicts but also offers a scalable, plug-and-play solution that can\nbe integrated seamlessly with existing models. Our codes are released at\nhttps://github.com/danshi777/IRCAN.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 中存在的知识冲突问题（如编码知识与上下文新知识的矛盾），提出了一种新框架 IRCAN，通过识别和重新加权上下文感知神经元 (context-aware neurons) 来缓解这一问题。具体而言，IRCAN 首先利用基于集成梯度的上下文感知归因分数 (integrated gradients) 识别关键神经元，然后通过重新加权加强这些神经元，以引导模型生成更符合上下文的输出。实验结果显示，IRCAN 在多种模型和任务上显著提升了知识冲突处理能力，并提供了一个可扩展的即插即用解决方案，便于与其他模型无缝集成。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18406v2",
      "published_date": "2024-06-26 14:57:38 UTC",
      "updated_date": "2024-11-14 10:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:53:18.563022"
    },
    {
      "arxiv_id": "2406.19418v1",
      "title": "A Quantization-based Technique for Privacy Preserving Distributed Learning",
      "title_zh": "一种基于量化的隐私保护分布式学习技术",
      "authors": [
        "Maurizio Colombo",
        "Rasool Asal",
        "Ernesto Damiani",
        "Lamees Mahmoud AlQassem",
        "Al Anoud Almemari",
        "Yousof Alhammadi"
      ],
      "abstract": "The massive deployment of Machine Learning (ML) models raises serious\nconcerns about data protection. Privacy-enhancing technologies (PETs) offer a\npromising first step, but hard challenges persist in achieving confidentiality\nand differential privacy in distributed learning. In this paper, we describe a\nnovel, regulation-compliant data protection technique for the distributed\ntraining of ML models, applicable throughout the ML life cycle regardless of\nthe underlying ML architecture. Designed from the data owner's perspective, our\nmethod protects both training data and ML model parameters by employing a\nprotocol based on a quantized multi-hash data representation Hash-Comb combined\nwith randomization. The hyper-parameters of our scheme can be shared using\nstandard Secure Multi-Party computation protocols. Our experimental results\ndemonstrate the robustness and accuracy-preserving properties of our approach.",
      "tldr_zh": "本研究提出了一种基于量化的技术，用于隐私保护分布式学习，旨在解决机器学习模型训练中数据保密和差分隐私（differential privacy）的挑战。该方法从数据所有者视角出发，利用Hash-Comb（一种量化的多哈希数据表示）结合随机化协议，来保护训练数据和ML模型参数，并支持Secure Multi-Party Computation协议以共享超参数。实验结果证明，该技术在ML生命周期的各个阶段都表现出色，能够保持模型准确性，同时确保鲁棒性和法规合规性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.19418v1",
      "published_date": "2024-06-26 14:54:12 UTC",
      "updated_date": "2024-06-26 14:54:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:53:29.150306"
    },
    {
      "arxiv_id": "2406.18394v5",
      "title": "AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Shi",
        "Weili Song",
        "Xinting Zhang",
        "Jiahe Shi",
        "Cuicui Luo",
        "Xiang Ao",
        "Hamid Arian",
        "Luis Seco"
      ],
      "abstract": "The complexity of financial data, characterized by its variability and low\nsignal-to-noise ratio, necessitates advanced methods in quantitative investment\nthat prioritize both performance and interpretability.Transitioning from early\nmanual extraction to genetic programming, the most advanced approach in the\nalpha factor mining domain currently employs reinforcement learning to mine a\nset of combination factors with fixed weights. However, the performance of\nresultant alpha factors exhibits inconsistency, and the inflexibility of fixed\nfactor weights proves insufficient in adapting to the dynamic nature of\nfinancial markets. To address this issue, this paper proposes a two-stage\nformulaic alpha generating framework AlphaForge, for alpha factor mining and\nfactor combination. This framework employs a generative-predictive neural\nnetwork to generate factors, leveraging the robust spatial exploration\ncapabilities inherent in deep learning while concurrently preserving diversity.\nThe combination model within the framework incorporates the temporal\nperformance of factors for selection and dynamically adjusts the weights\nassigned to each component alpha factor. Experiments conducted on real-world\ndatasets demonstrate that our proposed model outperforms contemporary\nbenchmarks in formulaic alpha factor mining. Furthermore, our model exhibits a\nnotable enhancement in portfolio returns within the realm of quantitative\ninvestment and real money investment.",
      "tldr_zh": "这篇论文提出 AlphaForge 框架，用于挖掘和动态组合 formulaic alpha factors，以应对金融数据变异性和低信噪比带来的量化投资挑战。框架采用两阶段方法：首先利用 generative-predictive neural network 生成多样化的 alpha 因子，结合深度学习的探索能力；其次，通过评估因子的 temporal performance 进行选择并动态调整权重。实验在真实数据集上显示，AlphaForge 优于现有基准模型，如基于 reinforcement learning 的方法，并在量化投资和真实资金投资中显著提升了投资回报。",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "10 pages, 3 figures, Accepted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2406.18394v5",
      "published_date": "2024-06-26 14:34:37 UTC",
      "updated_date": "2024-12-12 08:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:53:42.513089"
    },
    {
      "arxiv_id": "2406.18388v3",
      "title": "SAM: Semi-Active Mechanism for Extensible Continuum Manipulator and Real-time Hysteresis Compensation Control Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Junhyun Park",
        "Seonghyeok Jang",
        "Myeongbo Park",
        "Hyojae Park",
        "Jeonghyeon Yoon",
        "Minho Hwang"
      ],
      "abstract": "Cable-Driven Continuum Manipulators (CDCMs) enable scar-free procedures but\nface limitations in workspace and control accuracy due to hysteresis. We\nintroduce an extensible CDCM with a Semi-active Mechanism (SAM) and develop a\nreal-time hysteresis compensation control algorithm using a Temporal\nConvolutional Network (TCN) based on data collected from fiducial markers and\nRGBD sensing. Performance validation shows the proposed controller\nsignificantly reduces hysteresis by up to 69.5% in random trajectory tracking\ntest and approximately 26% in the box pointing task. The SAM mechanism enables\naccess to various lesions without damaging surrounding tissues. The proposed\ncontroller with TCN-based compensation effectively predicts hysteresis behavior\nand minimizes position and joint angle errors in real-time, which has the\npotential to enhance surgical task performance.",
      "tldr_zh": "本文提出了一种可扩展的 Cable-Driven Continuum Manipulators (CDCMs)，配备 Semi-active Mechanism (SAM)，以解决其工作空间有限和滞后(hysteresis)导致的控制精度问题。研究开发了基于 Temporal Convolutional Network (TCN)的实时滞后补偿控制算法，利用 fiducial markers 和 RGBD sensing 数据进行预测和校正。实验验证显示，该算法在随机轨迹跟踪测试中将滞后减少多达 69.5%，在箱子指向任务中减少约 26%，从而有效提升手术任务的精确性和安全性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "22 pages, 19 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.18388v3",
      "published_date": "2024-06-26 14:30:51 UTC",
      "updated_date": "2024-09-30 08:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:53:55.661006"
    },
    {
      "arxiv_id": "2407.15022v1",
      "title": "Encouraging Responsible Use of Generative AI in Education: A Reward-Based Learning Approach",
      "title_zh": "鼓励生成式 AI 在教育中的负责任使用：一种基于奖励的学习方法",
      "authors": [
        "Aditi Singh",
        "Abul Ehtesham",
        "Saket Kumar",
        "Gaurav Kumar Gupta",
        "Tala Talaei Khoei"
      ],
      "abstract": "This research introduces an innovative mathematical learning approach that\nintegrates generative AI to cultivate a structured learning rather than quick\nsolution. Our method combines chatbot capabilities and generative AI to offer\ninteractive problem-solving exercises, enhancing learning through a stepby-step\napproach for varied problems, advocating for the responsible use of AI in\neducation. Our approach emphasizes that immediate answers from ChatGPT can\nimpede real learning. We introduce a reward-based system that requires students\nto solve mathematical problems effectively to receive the final answer. This\nencourages a progressive learning path from basic to complex problems,\nrewarding mastery with final solutions. The goal is to transition students from\nseeking quick fixes to engaging actively in a comprehensive learning\nexperience.",
      "tldr_zh": "这篇论文提出了一种创新的数学学习方法，旨在促进 generative AI 在教育中的负责任使用，通过结合聊天机器人和 generative AI 提供交互式、逐步问题解决练习。该方法引入 reward-based system，要求学生有效解决从基本到复杂的问题才能获得最终答案，从而鼓励渐进式学习路径。最终目标是帮助学生避免依赖 ChatGPT 等工具的即时答案，转向主动参与全面的学习体验，以提升真实学习效果。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.15022v1",
      "published_date": "2024-06-26 14:27:24 UTC",
      "updated_date": "2024-06-26 14:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:54:06.893292"
    },
    {
      "arxiv_id": "2406.18626v1",
      "title": "An LLM-based Knowledge Synthesis and Scientific Reasoning Framework for Biomedical Discovery",
      "title_zh": "基于LLM的生物医学发现知识合成与科学推理框架",
      "authors": [
        "Oskar Wysocki",
        "Magdalena Wysocka",
        "Danilo Carvalho",
        "Alex Teodor Bogatu",
        "Danilo Miranda Gusicuma",
        "Maxime Delmas",
        "Harriet Unsworth",
        "Andre Freitas"
      ],
      "abstract": "We present BioLunar, developed using the Lunar framework, as a tool for\nsupporting biological analyses, with a particular emphasis on molecular-level\nevidence enrichment for biomarker discovery in oncology. The platform\nintegrates Large Language Models (LLMs) to facilitate complex scientific\nreasoning across distributed evidence spaces, enhancing the capability for\nharmonizing and reasoning over heterogeneous data sources. Demonstrating its\nutility in cancer research, BioLunar leverages modular design, reusable data\naccess and data analysis components, and a low-code user interface, enabling\nresearchers of all programming levels to construct LLM-enabled scientific\nworkflows. By facilitating automatic scientific discovery and inference from\nheterogeneous evidence, BioLunar exemplifies the potential of the integration\nbetween LLMs, specialised databases and biomedical tools to support\nexpert-level knowledge synthesis and discovery.",
      "tldr_zh": "本研究提出了 BioLunar，一种基于 LLM（Large Language Models）的知识合成和科学推理框架，利用 Lunar 框架支持生物医学分析，特别是肿瘤学中的生物标志物发现。BioLunar 通过整合 LLMs 来处理分布式证据空间的复杂推理，结合模块化设计、可重用数据组件和低代码用户界面，允许不同编程水平的研究人员构建高效的科学工作流。该框架展示了 LLMs 与专业数据库和生物医学工具的整合潜力，提升了异构数据源的自动发现和推理能力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.QM",
      "comment": "accepted for ACL 2024 System Demonstration Track",
      "pdf_url": "http://arxiv.org/pdf/2406.18626v1",
      "published_date": "2024-06-26 14:22:46 UTC",
      "updated_date": "2024-06-26 14:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:54:18.375649"
    },
    {
      "arxiv_id": "2406.18379v2",
      "title": "MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Haolang Lu",
        "Hongrui Peng",
        "Guoshun Nan",
        "Jiaoyang Cui",
        "Cheng Wang",
        "Weifei Jin",
        "Songtao Wang",
        "Shengli Pan",
        "Xiaofeng Tao"
      ],
      "abstract": "Binary malware summarization aims to automatically generate human-readable\ndescriptions of malware behaviors from executable files, facilitating tasks\nlike malware cracking and detection. Previous methods based on Large Language\nModels (LLMs) have shown great promise. However, they still face significant\nissues, including poor usability, inaccurate explanations,and incomplete\nsummaries, primarily due to the obscure pseudocode structure and the lack of\nmalware training summaries. Further, calling relationships between functions,\nwhich involve the rich interactions within a binary malware, remain largely\nunderexplored. To this end, we propose MALSIGHT, a novel code summarization\nframework that can iteratively generate descriptions of binary malware by\nexploring malicious source code and benign pseudocode. Specifically, we\nconstruct the first malware summary dataset, MalS and MalP, using an LLM and\nmanually refine this dataset with human effort. At the training stage, we tune\nour proposed MalT5, a novel LLM-based code model, on the MalS and benign\npseudocode datasets. Then, at the test stage, we iteratively feed the\npseudocode functions into MalT5 to obtain the summary. Such a procedure\nfacilitates the understanding of pseudocode structure and captures the\nintricate interactions between functions, thereby benefiting summaries'\nusability, accuracy, and completeness. Additionally, we propose a novel\nevaluation benchmark, BLEURT-sum, to measure the quality of summaries.\nExperiments on three datasets show the effectiveness of the proposed MALSIGHT.\nNotably, our proposed MalT5, with only 0.77B parameters, delivers comparable\nperformance to much larger Code-Llama.",
      "tldr_zh": "这篇论文提出 MALSIGHT 框架，用于迭代生成二进制恶意软件的总结，通过探索恶意源代码和良性伪代码，解决现有 Large Language Models (LLMs) 方法在可用性、准确性和完整性方面的不足。框架首先构建了首个恶意软件总结数据集 MalS 和 MalP，利用 LLM 生成并手动精炼，然后训练新型模型 MalT5 在这些数据集上进行微调。测试阶段，MALSIGHT 通过迭代输入伪代码函数，捕获函数间的调用关系，提升总结的理解和质量。实验结果显示，在三个数据集上，MALSIGHT 显著有效，且 MalT5（仅 0.77B 参数）性能可与更大模型 Code-Llama 媲美，同时引入了新的评估基准 BLEURT-sum 来量化总结质量。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "14 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.18379v2",
      "published_date": "2024-06-26 14:21:09 UTC",
      "updated_date": "2024-11-06 13:26:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:54:33.995193"
    },
    {
      "arxiv_id": "2406.18370v1",
      "title": "Learning pure quantum states (almost) without regret",
      "title_zh": "翻译失败",
      "authors": [
        "Josep Lumbreras",
        "Mikhail Terekhov",
        "Marco Tomamichel"
      ],
      "abstract": "We initiate the study of quantum state tomography with minimal regret. A\nlearner has sequential oracle access to an unknown pure quantum state, and in\neach round selects a pure probe state. Regret is incurred if the unknown state\nis measured orthogonal to this probe, and the learner's goal is to minimise the\nexpected cumulative regret over $T$ rounds. The challenge is to find a balance\nbetween the most informative measurements and measurements incurring minimal\nregret. We show that the cumulative regret scales as\n$\\Theta(\\operatorname{polylog} T)$ using a new tomography algorithm based on a\nmedian of means least squares estimator. This algorithm employs measurements\nbiased towards the unknown state and produces online estimates that are optimal\n(up to logarithmic terms) in the number of observed samples.",
      "tldr_zh": "本文研究了量子态层析(quantum state tomography)，目标是学习未知纯量子态(pure quantum state)时最小化遗憾(regret)。学习者通过顺序预言机访问(oracle access)选择纯探针态(pure probe state)进行测量，需平衡信息性与遗憾最小化。论文提出了一种新算法，使用中位数均值最小二乘估计器(median of means least squares estimator)的测量策略，结果显示累积遗憾缩放为 Θ(polylog T)，并提供在观察样本数量上最优的在线估计(up to logarithmic terms)。这为高效量子态学习奠定了基础。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "quant-ph",
      "comment": "24 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.18370v1",
      "published_date": "2024-06-26 14:13:50 UTC",
      "updated_date": "2024-06-26 14:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:54:53.914572"
    },
    {
      "arxiv_id": "2407.09541v1",
      "title": "MATE: Meet At The Embedding -- Connecting Images with Long Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Young Kyun Jang",
        "Junmo Kang",
        "Yong Jae Lee",
        "Donghyun Kim"
      ],
      "abstract": "While advancements in Vision Language Models (VLMs) have significantly\nimproved the alignment of visual and textual data, these models primarily focus\non aligning images with short descriptive captions. This focus limits their\nability to handle complex text interactions, particularly with longer texts\nsuch as lengthy captions or documents, which have not been extensively explored\nyet. In this paper, we introduce Meet At The Embedding (MATE), a novel approach\nthat combines the capabilities of VLMs with Large Language Models (LLMs) to\novercome this challenge without the need for additional image-long text pairs.\nSpecifically, we replace the text encoder of the VLM with a pretrained\nLLM-based encoder that excels in understanding long texts. To bridge the gap\nbetween VLM and LLM, MATE incorporates a projection module that is trained in a\nmulti-stage manner. It starts by aligning the embeddings from the VLM text\nencoder with those from the LLM using extensive text pairs. This module is then\nemployed to seamlessly align image embeddings closely with LLM embeddings. We\npropose two new cross-modal retrieval benchmarks to assess the task of\nconnecting images with long texts (lengthy captions / documents). Extensive\nexperimental results demonstrate that MATE effectively connects images with\nlong texts, uncovering diverse semantic relationships.",
      "tldr_zh": "这篇论文提出了 MATE（Meet At The Embedding），一种创新方法，用于将图像与长文本（如详细描述或文档）连接，以解决 Vision Language Models (VLMs) 在处理复杂文本时的局限性。MATE 通过替换 VLM 的文本编码器为预训练的 Large Language Models (LLMs)-based 编码器，并引入一个多阶段训练的投影模块，来对齐图像嵌入和 LLM 嵌入，从而实现无缝跨模态对齐。该方法无需额外图像-长文本对数据，即可有效处理长文本交互。论文还引入了两个新的跨模态检索基准，并通过实验证明，MATE 显著提升了图像与长文本的语义关联能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09541v1",
      "published_date": "2024-06-26 14:10:00 UTC",
      "updated_date": "2024-06-26 14:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:54:55.134785"
    },
    {
      "arxiv_id": "2406.18364v1",
      "title": "Research on Information Extraction of LCSTS Dataset Based on an Improved BERTSum-LSTM Model",
      "title_zh": "基于改进的 BERTSum-LSTM 模型的 LCSTS 数据集信息提取研究",
      "authors": [
        "Yiming Chen",
        "Haobin Chen",
        "Simin Liu",
        "Yunyun Liu",
        "Fanhao Zhou",
        "Bing Wei"
      ],
      "abstract": "With the continuous advancement of artificial intelligence, natural language\nprocessing technology has become widely utilized in various fields. At the same\ntime, there are many challenges in creating Chinese news summaries. First of\nall, the semantics of Chinese news is complex, and the amount of information is\nenormous. Extracting critical information from Chinese news presents a\nsignificant challenge. Second, the news summary should be concise and clear,\nfocusing on the main content and avoiding redundancy. In addition, the\nparticularity of the Chinese language, such as polysemy, word segmentation,\netc., makes it challenging to generate Chinese news summaries. Based on the\nabove, this paper studies the information extraction method of the LCSTS\ndataset based on an improved BERTSum-LSTM model. We improve the BERTSum-LSTM\nmodel to make it perform better in generating Chinese news summaries. The\nexperimental results show that the proposed method has a good effect on\ncreating news summaries, which is of great importance to the construction of\nnews summaries.",
      "tldr_zh": "本研究针对中文新闻摘要面临的挑战，如语义复杂、信息量大以及语言特性（包括多义词和词分段），提出了一种基于改进的BERTSum-LSTM模型的信息提取方法。研究聚焦于LCSTS Dataset，通过优化模型来提升中文新闻摘要的生成质量，确保摘要简洁、清晰并避免冗余。实验结果表明，该方法在创建新闻摘要方面表现出色，对新闻摘要构建具有重要意义。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "submitted to ICMIII 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18364v1",
      "published_date": "2024-06-26 14:04:15 UTC",
      "updated_date": "2024-06-26 14:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:55:06.241974"
    },
    {
      "arxiv_id": "2406.18361v3",
      "title": "Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Lin",
        "Zhiguang Chen",
        "Zhonghao Yan",
        "Weijiang Yu",
        "Fudan Zheng"
      ],
      "abstract": "Diffusion models have demonstrated their effectiveness across various\ngenerative tasks. However, when applied to medical image segmentation, these\nmodels encounter several challenges, including significant resource and time\nrequirements. They also necessitate a multi-step reverse process and multiple\nsamples to produce reliable predictions. To address these challenges, we\nintroduce the first latent diffusion segmentation model, named SDSeg, built\nupon stable diffusion (SD). SDSeg incorporates a straightforward latent\nestimation strategy to facilitate a single-step reverse process and utilizes\nlatent fusion concatenation to remove the necessity for multiple samples.\nExtensive experiments indicate that SDSeg surpasses existing state-of-the-art\nmethods on five benchmark datasets featuring diverse imaging modalities.\nRemarkably, SDSeg is capable of generating stable predictions with a solitary\nreverse step and sample, epitomizing the model's stability as implied by its\nname. The code is available at\nhttps://github.com/lin-tianyu/Stable-Diffusion-Seg",
      "tldr_zh": "该论文提出了 SDSeg，一种基于 Stable Diffusion 的首个潜在扩散分割模型，用于生物医学图像分割，以解决传统 Diffusion models 的资源消耗大、多步反向过程和多样本需求等问题。SDSeg 引入简单的潜在估计策略和潜在融合连接（latent fusion concatenation）技术，实现单步反向过程和单一样本的稳定预测。实验结果显示，SDSeg 在五个基准数据集上超越了现有最先进方法，提供更高效且可靠的分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at MICCAI 2024. Code and citation info see\n  https://github.com/lin-tianyu/Stable-Diffusion-Seg",
      "pdf_url": "http://arxiv.org/pdf/2406.18361v3",
      "published_date": "2024-06-26 14:01:07 UTC",
      "updated_date": "2024-07-09 17:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:55:29.535208"
    },
    {
      "arxiv_id": "2406.18354v1",
      "title": "Kolmogorov-Arnold Graph Neural Networks",
      "title_zh": "Kolmogorov-Arnold 图神经网络",
      "authors": [
        "Gianluca De Carlo",
        "Andrea Mastropietro",
        "Aris Anagnostopoulos"
      ],
      "abstract": "Graph neural networks (GNNs) excel in learning from network-like data but\noften lack interpretability, making their application challenging in domains\nrequiring transparent decision-making. We propose the Graph Kolmogorov-Arnold\nNetwork (GKAN), a novel GNN model leveraging spline-based activation functions\non edges to enhance both accuracy and interpretability. Our experiments on five\nbenchmark datasets demonstrate that GKAN outperforms state-of-the-art GNN\nmodels in node classification, link prediction, and graph classification tasks.\nIn addition to the improved accuracy, GKAN's design inherently provides clear\ninsights into the model's decision-making process, eliminating the need for\npost-hoc explainability techniques. This paper discusses the methodology,\nperformance, and interpretability of GKAN, highlighting its potential for\napplications in domains where interpretability is crucial.",
      "tldr_zh": "本研究针对 Graph Neural Networks (GNNs) 在处理网络数据时存在的可解释性不足问题，提出了一种新型模型 Graph Kolmogorov-Arnold Network (GKAN)。GKAN 通过在边上应用基于样条的激活函数，提升了模型的准确性和内在可解释性，从而无需依赖事后解释技术。实验结果显示，在五个基准数据集上，GKAN 在节点分类、链接预测和图分类任务中优于现有最先进 GNN 模型。总体而言，该方法为需要透明决策的领域提供了重要潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 4 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2406.18354v1",
      "published_date": "2024-06-26 13:54:59 UTC",
      "updated_date": "2024-06-26 13:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:55:32.291799"
    },
    {
      "arxiv_id": "2406.18351v2",
      "title": "Reinforcement Learning with Intrinsically Motivated Feedback Graph for Lost-sales Inventory Control",
      "title_zh": "翻译失败",
      "authors": [
        "Zifan Liu",
        "Xinran Li",
        "Shibo Chen",
        "Gen Li",
        "Jiashuo Jiang",
        "Jun Zhang"
      ],
      "abstract": "Reinforcement learning (RL) has proven to be well-performed and\ngeneral-purpose in the inventory control (IC). However, further improvement of\nRL algorithms in the IC domain is impeded due to two limitations of online\nexperience. First, online experience is expensive to acquire in real-world\napplications. With the low sample efficiency nature of RL algorithms, it would\ntake extensive time to train the RL policy to convergence. Second, online\nexperience may not reflect the true demand due to the lost sales phenomenon\ntypical in IC, which makes the learning process more challenging. To address\nthe above challenges, we propose a decision framework that combines\nreinforcement learning with feedback graph (RLFG) and intrinsically motivated\nexploration (IME) to boost sample efficiency. In particular, we first take\nadvantage of the inherent properties of lost-sales IC problems and design the\nfeedback graph (FG) specially for lost-sales IC problems to generate abundant\nside experiences aid RL updates. Then we conduct a rigorous theoretical\nanalysis of how the designed FG reduces the sample complexity of RL methods.\nBased on the theoretical insights, we design an intrinsic reward to direct the\nRL agent to explore to the state-action space with more side experiences,\nfurther exploiting FG's power. Experimental results demonstrate that our method\ngreatly improves the sample efficiency of applying RL in IC. Our code is\navailable at https://anonymous.4open.science/r/RLIMFG4IC-811D/",
      "tldr_zh": "该研究针对强化学习（RL）在失销库存控制（IC）中的样本效率低和失销现象问题，提出了一种结合反馈图（FG）和内在动机探索（IME）的决策框架，以提升RL的性能。具体方法包括利用失销IC问题的特性设计FG生成额外经验，并通过理论分析证明了FG能降低RL的样本复杂度。随后，引入内在奖励机制引导代理探索更多经验丰富的状态-动作空间。实验结果显示，该方法显著提高了RL在IC领域的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18351v2",
      "published_date": "2024-06-26 13:52:47 UTC",
      "updated_date": "2025-02-17 09:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:55:43.281641"
    },
    {
      "arxiv_id": "2407.11013v2",
      "title": "Quantum-tunnelling deep neural network for optical illusion recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan S. Maksymov"
      ],
      "abstract": "The discovery of the quantum tunnelling (QT) effect -- the transmission of\nparticles through a high potential barrier -- was one of the most impressive\nachievements of quantum mechanics made in the 1920s. Responding to the\ncontemporary challenges, I introduce a deep neural network (DNN) architecture\nthat processes information using the effect of QT. I demonstrate the ability of\nQT-DNN to recognise optical illusions like a human. Tasking QT-DNN to simulate\nhuman perception of the Necker cube and Rubin's vase, I provide arguments in\nfavour of the superiority of QT-based activation functions over the activation\nfunctions optimised for modern applications in machine vision, also showing\nthat, at the fundamental level, QT-DNN is closely related to biology-inspired\nDNNs and models based on the principles of quantum information processing.",
      "tldr_zh": "该研究引入了一种基于量子隧道效应（Quantum-tunnelling, QT）的深度神经网络（Deep Neural Network, DNN）架构，用于识别光学幻觉。QT-DNN 通过 QT 效果作为激活函数，模拟人类感知，能够准确识别如 Necker 立方体和 Rubin's 花瓶等幻觉。实验结果表明，QT 激活函数在性能上优于现代机器视觉优化的激活函数，并展示了 QT-DNN 与生物启发 DNN 以及量子信息处理模型的密切关联，为更先进的视觉认知系统提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.NE",
        "physics.soc-ph",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "A part of the special collection \"Neuromorphic Technologies for Novel\n  Hardware AI\"",
      "pdf_url": "http://arxiv.org/pdf/2407.11013v2",
      "published_date": "2024-06-26 13:49:07 UTC",
      "updated_date": "2025-02-22 01:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:56:04.778151"
    },
    {
      "arxiv_id": "2406.18346v1",
      "title": "AI Alignment through Reinforcement Learning from Human Feedback? Contradictions and Limitations",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Dahlgren Lindström",
        "Leila Methnani",
        "Lea Krause",
        "Petter Ericson",
        "Íñigo Martínez de Rituerto de Troya",
        "Dimitri Coelho Mollo",
        "Roel Dobbe"
      ],
      "abstract": "This paper critically evaluates the attempts to align Artificial Intelligence\n(AI) systems, especially Large Language Models (LLMs), with human values and\nintentions through Reinforcement Learning from Feedback (RLxF) methods,\ninvolving either human feedback (RLHF) or AI feedback (RLAIF). Specifically, we\nshow the shortcomings of the broadly pursued alignment goals of honesty,\nharmlessness, and helpfulness. Through a multidisciplinary sociotechnical\ncritique, we examine both the theoretical underpinnings and practical\nimplementations of RLxF techniques, revealing significant limitations in their\napproach to capturing the complexities of human ethics and contributing to AI\nsafety. We highlight tensions and contradictions inherent in the goals of RLxF.\nIn addition, we discuss ethically-relevant issues that tend to be neglected in\ndiscussions about alignment and RLxF, among which the trade-offs between\nuser-friendliness and deception, flexibility and interpretability, and system\nsafety. We conclude by urging researchers and practitioners alike to critically\nassess the sociotechnical ramifications of RLxF, advocating for a more nuanced\nand reflective approach to its application in AI development.",
      "tldr_zh": "这篇论文批判性地评估了通过强化学习从反馈（RLxF）方法（如 RLHF 和 RLAIF）来实现 AI Alignment 的尝试，特别是针对大型语言模型（LLMs）的诚实（honesty）、无害（harmlessness）和帮助性（helpfulness）目标。作者采用多学科的社会技术批判，揭示了 RLxF 在捕捉人类伦理复杂性和提升 AI 安全方面的理论和实践局限性，包括目标间的张力和矛盾，例如用户友好性与欺骗、灵活性与可解释性的权衡。论文强调了这些方法常忽略的伦理问题，并呼吁研究者和从业者更审慎地评估 RLxF 的社会技术影响，采用更细致和反思性的 AI 开发方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 1 table, to be submitted",
      "pdf_url": "http://arxiv.org/pdf/2406.18346v1",
      "published_date": "2024-06-26 13:42:13 UTC",
      "updated_date": "2024-06-26 13:42:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:56:08.708644"
    },
    {
      "arxiv_id": "2407.10329v1",
      "title": "Generative Discrimination: What Happens When Generative AI Exhibits Bias, and What Can Be Done About It",
      "title_zh": "生成式歧视：当生成式 AI ",
      "authors": [
        "Philipp Hacker"
      ],
      "abstract": "As generative Artificial Intelligence (genAI) technologies proliferate across\nsectors, they offer significant benefits but also risk exacerbating\ndiscrimination. This chapter explores how genAI intersects with\nnon-discrimination laws, identifying shortcomings and suggesting improvements.\nIt highlights two main types of discriminatory outputs: (i) demeaning and\nabusive content and (ii) subtler biases due to inadequate representation of\nprotected groups, which may not be overtly discriminatory in individual cases\nbut have cumulative discriminatory effects. For example, genAI systems may\npredominantly depict white men when asked for images of people in important\njobs.\n  This chapter examines these issues, categorizing problematic outputs into\nthree legal categories: discriminatory content; harassment; and legally hard\ncases like unbalanced content, harmful stereotypes or misclassification. It\nargues for holding genAI providers and deployers liable for discriminatory\noutputs and highlights the inadequacy of traditional legal frameworks to\naddress genAI-specific issues. The chapter suggests updating EU laws, including\nthe AI Act, to mitigate biases in training and input data, mandating testing\nand auditing, and evolving legislation to enforce standards for bias mitigation\nand inclusivity as technology advances.",
      "tldr_zh": "本章探讨生成式 AI (genAI) 在各种领域中的应用如何带来益处，同时加剧歧视问题，特别是通过输出贬低内容或微妙偏差（如对保护群体不足代表）导致的累积歧视效果，例如生成图像时偏向描绘白人男性。作者将这些问题分类为三个法律类别：歧视内容、骚扰，以及复杂案例如不平衡内容或有害刻板印象，并主张对 genAI 提供者和部署者追究责任。针对传统法律框架的不足，该章建议更新欧盟法律，包括 AI Act 中的规定，以缓解训练和输入数据的偏差、强制实施测试和审计，并制定动态标准来推动偏见缓解和包容性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "arXiv admin comment: This version has been removed by arXiv\n  administrators as the submitter did not have the rights to agree to the\n  license at the time of submission",
      "pdf_url": "http://arxiv.org/pdf/2407.10329v1",
      "published_date": "2024-06-26 13:32:58 UTC",
      "updated_date": "2024-06-26 13:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:56:20.471045"
    },
    {
      "arxiv_id": "2406.18625v1",
      "title": "Automatic Prediction of Amyotrophic Lateral Sclerosis Progression using Longitudinal Speech Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Liming Wang",
        "Yuan Gong",
        "Nauman Dawalatabad",
        "Marco Vilela",
        "Katerina Placek",
        "Brian Tracey",
        "Yishu Gong",
        "Alan Premasiri",
        "Fernando Vieira",
        "James Glass"
      ],
      "abstract": "Automatic prediction of amyotrophic lateral sclerosis (ALS) disease\nprogression provides a more efficient and objective alternative than manual\napproaches. We propose ALS longitudinal speech transformer (ALST), a neural\nnetwork-based automatic predictor of ALS disease progression from longitudinal\nspeech recordings of ALS patients. By taking advantage of high-quality\npretrained speech features and longitudinal information in the recordings, our\nbest model achieves 91.0\\% AUC, improving upon the previous best model by 5.6\\%\nrelative on the ALS TDI dataset. Careful analysis reveals that ALST is capable\nof fine-grained and interpretable predictions of ALS progression, especially\nfor distinguishing between rarer and more severe cases. Code is publicly\navailable.",
      "tldr_zh": "本研究提出了一种名为 ALST 的神经网络模型，用于从 ALS 患者的纵向语音记录中自动预测疾病进展，从而提供比手动方法更高效和客观的评估。ALST 利用高质量的预训练语音特征和纵向信息进行预测，在 ALS TDI 数据集上实现 91.0% AUC 的表现，比之前的最佳模型相对提高了 5.6%。此外，分析显示该模型能够进行细粒度的可解释预测，尤其在区分罕见和严重 ALS 病例方面表现出色，且相关代码已公开可用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18625v1",
      "published_date": "2024-06-26 13:28:24 UTC",
      "updated_date": "2024-06-26 13:28:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:56:31.274249"
    },
    {
      "arxiv_id": "2406.18333v1",
      "title": "Continuous Sign Language Recognition Using Intra-inter Gloss Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Ranjbar",
        "Alireza Taheri"
      ],
      "abstract": "Many continuous sign language recognition (CSLR) studies adopt\ntransformer-based architectures for sequence modeling due to their powerful\ncapacity for capturing global contexts. Nevertheless, vanilla self-attention,\nwhich serves as the core module of the transformer, calculates a weighted\naverage over all time steps; therefore, the local temporal semantics of sign\nvideos may not be fully exploited. In this study, we introduce a novel module\nin sign language recognition studies, called intra-inter gloss attention\nmodule, to leverage the relationships among frames within glosses and the\nsemantic and grammatical dependencies between glosses in the video. In the\nintra-gloss attention module, the video is divided into equally sized chunks\nand a self-attention mechanism is applied within each chunk. This localized\nself-attention significantly reduces complexity and eliminates noise introduced\nby considering non-relative frames. In the inter-gloss attention module, we\nfirst aggregate the chunk-level features within each gloss chunk by average\npooling along the temporal dimension. Subsequently, multi-head self-attention\nis applied to all chunk-level features. Given the non-significance of the\nsigner-environment interaction, we utilize segmentation to remove the\nbackground of the videos. This enables the proposed model to direct its focus\ntoward the signer. Experimental results on the PHOENIX-2014 benchmark dataset\ndemonstrate that our method can effectively extract sign language features in\nan end-to-end manner without any prior knowledge, improve the accuracy of CSLR,\nand achieve the word error rate (WER) of 20.4 on the test set which is a\ncompetitive result compare to the state-of-the-art which uses additional\nsupervisions.",
      "tldr_zh": "本研究针对连续手语识别(CSLR)中，基于Transformer的架构可能未充分利用局部时间语义的问题，提出了一种新型intra-inter gloss attention模块。该模块包括intra-gloss attention（将视频分成等大小块，并在每个块内应用self-attention以减少噪声）和inter-gloss attention（聚合块级特征后进行multi-head self-attention，以捕捉词汇间的语义依赖）。此外，通过视频分割去除背景，模型更专注于手语者。在PHOENIX-2014数据集上的实验显示，该方法实现了20.4%的word error rate (WER)，在端到端方式下无需额外监督，比现有最先进方法更具竞争力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18333v1",
      "published_date": "2024-06-26 13:21:08 UTC",
      "updated_date": "2024-06-26 13:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:56:43.357504"
    },
    {
      "arxiv_id": "2406.18326v2",
      "title": "PaCoST: Paired Confidence Significance Testing for Benchmark Contamination Detection in Large Language Models",
      "title_zh": "PaCoST：用于大型语言模型基准测试污染检测的配对置信度显著性检验",
      "authors": [
        "Huixuan Zhang",
        "Yun Lin",
        "Xiaojun Wan"
      ],
      "abstract": "Large language models (LLMs) are known to be trained on vast amounts of data,\nwhich may unintentionally or intentionally include data from commonly used\nbenchmarks. This inclusion can lead to cheatingly high scores on model\nleaderboards, yet result in disappointing performance in real-world\napplications. To address this benchmark contamination problem, we first propose\na set of requirements that practical contamination detection methods should\nfollow. Following these proposed requirements, we introduce PaCoST, a Paired\nConfidence Significance Testing to effectively detect benchmark contamination\nin LLMs. Our method constructs a counterpart for each piece of data with the\nsame distribution, and performs statistical analysis of the corresponding\nconfidence to test whether the model is significantly more confident under the\noriginal benchmark. We validate the effectiveness of PaCoST and apply it on\npopular open-source models and benchmarks. We find that almost all models and\nbenchmarks we tested are suspected contaminated more or less. We finally call\nfor new LLM evaluation methods.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)可能因基准测试数据污染而导致虚假高分和实际应用表现差的问题，提出了一套实用检测要求和PaCoST方法，即配对置信度显著性测试。PaCoST通过为每个数据构建相同分布的对应物，并进行置信度统计分析，检测模型在原始基准下的置信度是否显著更高，从而有效识别污染。实验结果显示，几乎所有测试的开源模型和基准都存在不同程度的可疑污染，最终呼吁开发新的LLM评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.18326v2",
      "published_date": "2024-06-26 13:12:40 UTC",
      "updated_date": "2025-03-18 08:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:56:55.362827"
    },
    {
      "arxiv_id": "2406.18321v1",
      "title": "MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Fang",
        "Xiangpeng Wan",
        "Fei Lu",
        "Fei Xing",
        "Kai Zou"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced natural language\nunderstanding and demonstrated strong problem-solving abilities. Despite these\nsuccesses, most LLMs still struggle with solving mathematical problems due to\nthe intricate reasoning required. This paper investigates the mathematical\nproblem-solving capabilities of LLMs using the newly developed \"MathOdyssey\"\ndataset. The dataset includes diverse mathematical problems at high school and\nuniversity levels, created by experts from notable institutions to rigorously\ntest LLMs in advanced problem-solving scenarios and cover a wider range of\nsubject areas. By providing the MathOdyssey dataset as a resource to the AI\ncommunity, we aim to contribute to the understanding and improvement of AI\ncapabilities in complex mathematical problem-solving. We conduct benchmarking\non open-source models, such as Llama-3 and DBRX-Instruct, and closed-source\nmodels from the GPT series and Gemini models. Our results indicate that while\nLLMs perform well on routine and moderately difficult tasks, they face\nsignificant challenges with Olympiad-level problems and complex\nuniversity-level questions. Our analysis shows a narrowing performance gap\nbetween open-source and closed-source models, yet substantial challenges\nremain, particularly with the most demanding problems. This study highlights\nthe ongoing need for research to enhance the mathematical reasoning of LLMs.\nThe dataset, results, and code are publicly available.",
      "tldr_zh": "本研究引入了MathOdyssey数据集，用于评估大型语言模型(LLMs)在数学问题解决方面的能力，该数据集包含高中和大学水平的多样化问题，由专家创建，以测试高级推理场景。研究者对开源模型（如Llama-3和DBRX-Instruct）以及闭源模型（如GPT系列和Gemini模型）进行了基准测试，结果显示LLMs在常规和中等难度任务上表现良好，但面对奥林匹克级和复杂大学问题时仍存在显著挑战。尽管开源和闭源模型的性能差距正在缩小，该研究强调了提升LLMs数学推理能力的必要性，并公开了数据集、结果和代码以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18321v1",
      "published_date": "2024-06-26 13:02:35 UTC",
      "updated_date": "2024-06-26 13:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:57:07.475820"
    },
    {
      "arxiv_id": "2406.18312v4",
      "title": "AI-native Memory: A Pathway from LLMs Towards AGI",
      "title_zh": "AI 原生记忆：从 LLMs 到 AGI 的途径",
      "authors": [
        "Jingbo Shang",
        "Zai Zheng",
        "Jiale Wei",
        "Xiang Ying",
        "Felix Tao",
        "Mindverse Team"
      ],
      "abstract": "Large language models (LLMs) have demonstrated the world with the sparks of\nartificial general intelligence (AGI). One opinion, especially from some\nstartups working on LLMs, argues that an LLM with nearly unlimited context\nlength can realize AGI. However, they might be too optimistic about the\nlong-context capability of (existing) LLMs -- (1) Recent literature has shown\nthat their effective context length is significantly smaller than their claimed\ncontext length; and (2) Our reasoning-in-a-haystack experiments further\ndemonstrate that simultaneously finding the relevant information from a long\ncontext and conducting (simple) reasoning is nearly impossible. In this paper,\nwe envision a pathway from LLMs to AGI through the integration of\n\\emph{memory}. We believe that AGI should be a system where LLMs serve as core\nprocessors. In addition to raw data, the memory in this system would store a\nlarge number of important conclusions derived from reasoning processes.\nCompared with retrieval-augmented generation (RAG) that merely processing raw\ndata, this approach not only connects semantically related information closer,\nbut also simplifies complex inferences at the time of querying. As an\nintermediate stage, the memory will likely be in the form of natural language\ndescriptions, which can be directly consumed by users too. Ultimately, every\nagent/person should have its own large personal model, a deep neural network\nmodel (thus \\emph{AI-native}) that parameterizes and compresses all types of\nmemory, even the ones cannot be described by natural languages. Finally, we\ndiscuss the significant potential of AI-native memory as the transformative\ninfrastructure for (proactive) engagement, personalization, distribution, and\nsocial in the AGI era, as well as the incurred privacy and security challenges\nwith preliminary solutions.",
      "tldr_zh": "这篇论文探讨了从大型语言模型（LLMs）向人工智能通用智能（AGI）发展的路径，强调了AI-native Memory的重要性。作者认为，现有LLMs的长上下文能力有限，无法有效处理信息检索和推理，因此提出通过集成记忆系统，将LLMs作为核心处理器来存储推理得出的重要结论，而不是仅依赖检索增强生成（RAG）。这种方法能更紧密地连接语义相关信息、简化查询过程，并最终发展成个人化的深度神经网络模型，支持主动参与、个性化分发和社会互动。论文还讨论了这一系统带来的隐私和安全挑战，并提出初步解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18312v4",
      "published_date": "2024-06-26 12:51:37 UTC",
      "updated_date": "2024-08-28 08:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:57:20.498027"
    },
    {
      "arxiv_id": "2406.18305v1",
      "title": "S3: A Simple Strong Sample-effective Multimodal Dialog System",
      "title_zh": "翻译失败",
      "authors": [
        "Elisei Rykov",
        "Egor Malkershin",
        "Alexander Panchenko"
      ],
      "abstract": "In this work, we present a conceptually simple yet powerful baseline for the\nmultimodal dialog task, an S3 model, that achieves near state-of-the-art\nresults on two compelling leaderboards: MMMU and AI Journey Contest 2023. The\nsystem is based on a pre-trained large language model, pre-trained modality\nencoders for image and audio, and a trainable modality projector. The proposed\neffective data mixture for training such an architecture demonstrates that a\nmultimodal model based on a strong language model and trained on a small amount\nof multimodal data can perform efficiently in the task of multimodal dialog.",
      "tldr_zh": "本研究提出了一种简单而强大的多模态对话系统 S3 模型，作为一个高效基线，实现了 MMMU 和 AI Journey Contest 2023 排行榜上的近乎最先进结果。S3 基于预训练的大型语言模型（large language model）、图像和音频的预训练模态编码器（pre-trained modality encoders），并结合一个可训练的模态投影器（trainable modality projector）。通过有效的训练数据混合，该模型证明了使用少量多模态数据即可高效训练基于强大语言模型的多模态系统，从而提升对话任务的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18305v1",
      "published_date": "2024-06-26 12:45:43 UTC",
      "updated_date": "2024-06-26 12:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:57:31.639471"
    },
    {
      "arxiv_id": "2407.12013v2",
      "title": "Dating ancient manuscripts using radiocarbon and AI-based writing style analysis",
      "title_zh": "利用放射性碳和基于AI的书写风格分析对古代手稿进行年代测定",
      "authors": [
        "Mladen Popović",
        "Maruf A. Dhali",
        "Lambert Schomaker",
        "Johannes van der Plicht",
        "Kaare Lund Rasmussen",
        "Jacopo La Nasa",
        "Ilaria Degano",
        "Maria Perla Colombini",
        "Eibert Tigchelaar"
      ],
      "abstract": "Determining the chronology of ancient handwritten manuscripts is essential\nfor reconstructing the evolution of ideas. For the Dead Sea Scrolls, this is\nparticularly important. However, there is an almost complete lack of\ndate-bearing manuscripts evenly distributed across the timeline and written in\nsimilar scripts available for palaeographic comparison. Here, we present Enoch,\na state-of-the-art AI-based date-prediction model, trained on the basis of new\nradiocarbon-dated samples of the scrolls. Enoch uses established\nhandwriting-style descriptors and applies Bayesian ridge regression. The\nchallenge of this study is that the number of radiocarbon-dated manuscripts is\nsmall, while current machine learning requires an abundance of training data.\nWe show that by using combined angular and allographic writing style feature\nvectors and applying Bayesian ridge regression, Enoch could predict the\nradiocarbon-based dates from style, supported by leave-one-out validation, with\nvaried MAEs of 27.9 to 30.7 years relative to the radiocarbon dating. Enoch was\nthen used to estimate the dates of 135 unseen manuscripts, revealing that 79\nper cent of the samples were considered 'realistic' upon palaeographic post-hoc\nevaluation. We present a new chronology of the scrolls. The radiocarbon ranges\nand Enoch's style-based predictions are often older than the traditionally\nassumed palaeographic estimates. In the range of 300-50 BCE, Enoch's date\nprediction provides an improved granularity. The study is in line with current\ndevelopments in multimodal machine-learning techniques, and the methods can be\nused for date prediction in other partially-dated manuscript collections. This\nresearch shows how Enoch's quantitative, probability-based approach can be a\ntool for palaeographers and historians, re-dating ancient Jewish key texts and\ncontributing to current debates on Jewish and Christian origins.",
      "tldr_zh": "本研究开发了Enoch模型，通过结合radiocarbon定年和AI-based写作风格分析，解决Dead Sea Scrolls等古代手稿年代确定的难题，该模型使用angular和allographic writing style feature vectors，并应用Bayesian ridge regression进行训练。面对小样本数据挑战，Enoch通过leave-one-out validation实现了27.9至30.7年的平均绝对误差（MAE），并对135个未见手稿进行日期预测，其中79%被古文字学评估为“真实”。结果显示，Enoch的预测往往比传统古文字学估计更早，并在300-50 BCE范围内提供了更细粒度的编年史。该方法可扩展至其他手稿集合，作为定量工具支持古文字学家和历史学家重新审视犹太和基督教起源的相关辩论。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "16 pages of main article, 103 pages of supplementary materials; the\n  first version of this article is originally prepared in July 2023 after the\n  completion of all the experiments",
      "pdf_url": "http://arxiv.org/pdf/2407.12013v2",
      "published_date": "2024-06-26 12:33:34 UTC",
      "updated_date": "2024-10-18 08:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:57:45.276136"
    },
    {
      "arxiv_id": "2406.18293v2",
      "title": "Combining Automated Optimisation of Hyperparameters and Reward Shape",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Dierkes",
        "Emma Cramer",
        "Holger H. Hoos",
        "Sebastian Trimpe"
      ],
      "abstract": "There has been significant progress in deep reinforcement learning (RL) in\nrecent years. Nevertheless, finding suitable hyperparameter configurations and\nreward functions remains challenging even for experts, and performance heavily\nrelies on these design choices. Also, most RL research is conducted on known\nbenchmarks where knowledge about these choices already exists. However, novel\npractical applications often pose complex tasks for which no prior knowledge\nabout good hyperparameters and reward functions is available, thus\nnecessitating their derivation from scratch. Prior work has examined\nautomatically tuning either hyperparameters or reward functions individually.\nWe demonstrate empirically that an RL algorithm's hyperparameter configurations\nand reward function are often mutually dependent, meaning neither can be fully\noptimised without appropriate values for the other. We then propose a\nmethodology for the combined optimisation of hyperparameters and the reward\nfunction. Furthermore, we include a variance penalty as an optimisation\nobjective to improve the stability of learned policies. We conducted extensive\nexperiments using Proximal Policy Optimisation and Soft Actor-Critic on four\nenvironments. Our results show that combined optimisation significantly\nimproves over baseline performance in half of the environments and achieves\ncompetitive performance in the others, with only a minor increase in\ncomputational costs. This suggests that combined optimisation should be best\npractice.",
      "tldr_zh": "该研究探讨了深度强化学习（RL）中超参数和奖励函数的优化问题，指出两者相互依赖，单独优化难以实现最佳性能，尤其在缺乏先验知识的新任务中。论文提出了一种结合自动优化超参数和奖励函数的方法，并引入方差惩罚作为优化目标，以提高学习策略的稳定性。在使用 Proximal Policy Optimisation (PPO) 和 Soft Actor-Critic (SAC) 的四个环境中进行实验，结果显示这种结合优化在半数环境中显著提升了性能，在其他环境中保持竞争力，同时仅导致轻微的计算成本增加，建议其作为RL的最佳实践。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Reinforcement Learning Journal 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18293v2",
      "published_date": "2024-06-26 12:23:54 UTC",
      "updated_date": "2024-10-09 14:24:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:57:56.119966"
    },
    {
      "arxiv_id": "2407.01601v2",
      "title": "Unveiling and Controlling Anomalous Attention Distribution in Transformers",
      "title_zh": "揭示与控制 Transformers 中的异常注意力分布",
      "authors": [
        "Ruiqing Yan",
        "Xingbo Du",
        "Haoyu Deng",
        "Linghan Zheng",
        "Qiuzhuang Sun",
        "Jifang Hu",
        "Yuhang Shao",
        "Penghao Jiang",
        "Jinrong Jiang",
        "Lian Zhao"
      ],
      "abstract": "With the advent of large models based on the Transformer architecture,\nresearchers have observed an anomalous phenomenon in the Attention\nmechanism--there is a very high attention on the first element, which is\nprevalent across Transformer-based models. It is crucial to understand it for\nthe development of techniques focusing on attention distribution, such as\nKey-Value (KV) Cache compression and infinite extrapolation; however, the\nlatent cause leaves to be unknown. In this paper, we analyze such a phenomenon\nfrom the perspective of waiver phenomenon, which involves reducing the internal\nvalues of certain elements in the sequence, allowing them to absorb excess\nattention without affecting their contribution to information. In specific\nmodels, due to differences in positional encoding and attention patterns, we\nhave found that the selection of waiver elements by the model can be\ncategorized into two methods: positional-encoding-based and\nfeature-distribution-within-elements-based.",
      "tldr_zh": "本研究揭示了Transformer模型中注意力机制的异常现象，即对序列第一个元素的过高注意力，这种现象在多种模型中普遍存在。论文从waiver phenomenon（涉及减少某些元素内部值以吸收多余注意力而不影响信息贡献）的角度进行分析，探讨了其潜在原因。研究发现，模型选择waiver元素的策略可分为两种：基于positional encoding的和基于feature distribution within elements的。最终，这为控制注意力分布的技术（如KV Cache压缩和无限外推）提供了关键洞见和潜在方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01601v2",
      "published_date": "2024-06-26 11:53:35 UTC",
      "updated_date": "2024-07-03 16:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:58:07.385974"
    },
    {
      "arxiv_id": "2406.18259v1",
      "title": "Detecting Machine-Generated Texts: Not Just \"AI vs Humans\" and Explainability is Complicated",
      "title_zh": "翻译失败",
      "authors": [
        "Jiazhou Ji",
        "Ruizhe Li",
        "Shujun Li",
        "Jie Guo",
        "Weidong Qiu",
        "Zheng Huang",
        "Chiyu Chen",
        "Xiaoyu Jiang",
        "Xinru Lu"
      ],
      "abstract": "As LLMs rapidly advance, increasing concerns arise regarding risks about\nactual authorship of texts we see online and in real world. The task of\ndistinguishing LLM-authored texts is complicated by the nuanced and overlapping\nbehaviors of both machines and humans. In this paper, we challenge the current\npractice of considering LLM-generated text detection a binary classification\ntask of differentiating human from AI. Instead, we introduce a novel ternary\ntext classification scheme, adding an \"undecided\" category for texts that could\nbe attributed to either source, and we show that this new category is crucial\nto understand how to make the detection result more explainable to lay users.\nThis research shifts the paradigm from merely classifying to explaining\nmachine-generated texts, emphasizing need for detectors to provide clear and\nunderstandable explanations to users. Our study involves creating four new\ndatasets comprised of texts from various LLMs and human authors. Based on new\ndatasets, we performed binary classification tests to ascertain the most\neffective SOTA detection methods and identified SOTA LLMs capable of producing\nharder-to-detect texts. We constructed a new dataset of texts generated by two\ntop-performing LLMs and human authors, and asked three human annotators to\nproduce ternary labels with explanation notes. This dataset was used to\ninvestigate how three top-performing SOTA detectors behave in new ternary\nclassification context. Our results highlight why \"undecided\" category is much\nneeded from the viewpoint of explainability. Additionally, we conducted an\nanalysis of explainability of the three best-performing detectors and the\nexplanation notes of the human annotators, revealing insights about the\ncomplexity of explainable detection of machine-generated texts. Finally, we\npropose guidelines for developing future detection systems with improved\nexplanatory power.",
      "tldr_zh": "该研究挑战了将大型语言模型（LLMs）生成文本检测视为简单二元分类（AI vs 人类）的传统做法，而是引入了三元分类方案，包括“undecided”类别，以提升检测结果的可解释性。研究者创建了四个新数据集，包含各种LLMs和人类作者的文本，并通过二元分类测试评估了SOTA检测方法，识别出难以检测的LLMs生成文本。基于一个新数据集，他们让人类标注者提供三元标签和解释，分析了三个顶尖检测器在三元分类中的表现，发现“undecided”类别有助于揭示检测的复杂性。最终，该论文提出指导方针，以开发更具解释能力的未来检测系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.18259v1",
      "published_date": "2024-06-26 11:11:47 UTC",
      "updated_date": "2024-06-26 11:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:58:20.840933"
    },
    {
      "arxiv_id": "2406.18254v1",
      "title": "Improving the Consistency in Cross-Lingual Cross-Modal Retrieval with 1-to-K Contrastive Learning",
      "title_zh": "通过 1-to-K 对比学习改善跨语言跨模态检索中的一致性",
      "authors": [
        "Zhijie Nie",
        "Richong Zhang",
        "Zhangchi Feng",
        "Hailang Huang",
        "Xudong Liu"
      ],
      "abstract": "Cross-lingual Cross-modal Retrieval (CCR) is an essential task in web search,\nwhich aims to break the barriers between modality and language simultaneously\nand achieves image-text retrieval in the multi-lingual scenario with a single\nmodel. In recent years, excellent progress has been made based on cross-lingual\ncross-modal pre-training; particularly, the methods based on contrastive\nlearning on large-scale data have significantly improved retrieval tasks.\nHowever, these methods directly follow the existing pre-training methods in the\ncross-lingual or cross-modal domain, leading to two problems of inconsistency\nin CCR: The methods with cross-lingual style suffer from the intra-modal error\npropagation, resulting in inconsistent recall performance across languages in\nthe whole dataset. The methods with cross-modal style suffer from the\ninter-modal optimization direction bias, resulting in inconsistent rank across\nlanguages within each instance, which cannot be reflected by Recall@K. To solve\nthese problems, we propose a simple but effective 1-to-K contrastive learning\nmethod, which treats each language equally and eliminates error propagation and\noptimization bias. In addition, we propose a new evaluation metric, Mean Rank\nVariance (MRV), to reflect the rank inconsistency across languages within each\ninstance. Extensive experiments on four CCR datasets show that our method\nimproves both recall rates and MRV with smaller-scale pre-trained data,\nachieving the new state-of-art.",
      "tldr_zh": "这篇论文针对 Cross-Lingual Cross-Modal Retrieval (CCR) 任务中的不一致问题，提出了 1-to-K contrastive learning 方法，以平等对待每种语言并消除 intra-modal error propagation 和 inter-modal optimization direction bias。作者还引入了新的评估指标 Mean Rank Variance (MRV)，用于量化每个实例中不同语言排名的不一致性。实验在四个 CCR 数据集上证明，该方法在使用较小规模预训练数据的情况下，提高了召回率和 MRV，达到了新的 state-of-the-art 水平。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by KDD 2024 Research Track",
      "pdf_url": "http://arxiv.org/pdf/2406.18254v1",
      "published_date": "2024-06-26 11:04:25 UTC",
      "updated_date": "2024-06-26 11:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:58:34.178828"
    },
    {
      "arxiv_id": "2406.18239v1",
      "title": "Zero-shot prompt-based classification: topic labeling in times of foundation models in German Tweets",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Münker",
        "Kai Kugler",
        "Achim Rettinger"
      ],
      "abstract": "Filtering and annotating textual data are routine tasks in many areas, like\nsocial media or news analytics. Automating these tasks allows to scale the\nanalyses wrt. speed and breadth of content covered and decreases the manual\neffort required. Due to technical advancements in Natural Language Processing,\nspecifically the success of large foundation models, a new tool for automating\nsuch annotation processes by using a text-to-text interface given written\nguidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing\nthem in an annotation task on German Twitter data about social and political\nEuropean crises. We compare the prompt-based results with our human annotation\nand preceding classification approaches, including Naive Bayes and a BERT-based\nfine-tuning/domain adaptation pipeline. Our results show that the prompt-based\napproach - despite being limited by local computation resources during the\nmodel selection - is comparable with the fine-tuned BERT but without any\nannotated training data. Our findings emphasize the ongoing paradigm shift in\nthe NLP landscape, i.e., the unification of downstream tasks and elimination of\nthe need for pre-labeled training data.",
      "tldr_zh": "这篇论文探讨了Zero-shot prompt-based classification在处理德国Twitter数据主题标注时的应用，旨在通过大型基础模型(foundation models)自动过滤和标注文本，而无需提供训练样本。研究者对关于欧洲社会和政治危机的Twitter数据集进行了实证测试，将prompt-based方法与人工标注、Naive Bayes和fine-tuned BERT方法进行比较。结果显示，尽管受限于本地计算资源，prompt-based方法的表现可与fine-tuned BERT相当，且无需预标注训练数据，突显了NLP领域向任务统一和减少数据依赖的范式转变。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 2 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.18239v1",
      "published_date": "2024-06-26 10:44:02 UTC",
      "updated_date": "2024-06-26 10:44:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:58:43.386584"
    },
    {
      "arxiv_id": "2406.18237v1",
      "title": "PlaMo: Plan and Move in Rich 3D Physical Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Assaf Hallak",
        "Gal Dalal",
        "Chen Tessler",
        "Kelly Guo",
        "Shie Mannor",
        "Gal Chechik"
      ],
      "abstract": "Controlling humanoids in complex physically simulated worlds is a\nlong-standing challenge with numerous applications in gaming, simulation, and\nvisual content creation. In our setup, given a rich and complex 3D scene, the\nuser provides a list of instructions composed of target locations and\nlocomotion types. To solve this task we present PlaMo, a scene-aware path\nplanner and a robust physics-based controller. The path planner produces a\nsequence of motion paths, considering the various limitations the scene imposes\non the motion, such as location, height, and speed. Complementing the planner,\nour control policy generates rich and realistic physical motion adhering to the\nplan. We demonstrate how the combination of both modules enables traversing\ncomplex landscapes in diverse forms while responding to real-time changes in\nthe environment. Video: https://youtu.be/wWlqSQlRZ9M .",
      "tldr_zh": "这篇论文介绍了 PlaMo，一种用于在丰富 3D 物理环境中控制人形机器人的框架，旨在处理复杂场景下的路径规划和移动任务。PlaMo 结合了场景感知路径规划器（scene-aware path planner），该规划器生成考虑位置、高度和速度等限制的运动路径序列，以及一个鲁棒的基于物理的控制器（physics-based controller），以产生真实且动态的物理运动。实验结果显示，该系统能使机器人有效穿越多样化地形并实时响应环境变化，适用于游戏、模拟和视觉内容创建领域。",
      "categories": [
        "cs.AI",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18237v1",
      "published_date": "2024-06-26 10:41:07 UTC",
      "updated_date": "2024-06-26 10:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:58:56.303883"
    },
    {
      "arxiv_id": "2407.09539v1",
      "title": "Classification of Inkjet Printers based on Droplet Statistics",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Takenaka",
        "Manuel Eberhardinger",
        "Daniel Grießhaber",
        "Johannes Maucher"
      ],
      "abstract": "Knowing the printer model used to print a given document may provide a\ncrucial lead towards identifying counterfeits or conversely verifying the\nvalidity of a real document. Inkjet printers produce probabilistic droplet\npatterns that appear to be distinct for each printer model and as such we\ninvestigate the utilization of droplet characteristics including frequency\ndomain features extracted from printed document scans for the classification of\nthe underlying printer model. We collect and publish a dataset of high\nresolution document scans and show that our extracted features are informative\nenough to enable a neural network to distinguish not only the printer\nmanufacturer, but also individual printer models.",
      "tldr_zh": "这篇论文探讨了基于墨滴统计（Droplet Statistics）来分类喷墨打印机（Inkjet Printers）的技术，以识别伪造文件或验证真实性。研究人员从打印文档扫描中提取墨滴特征，包括频率域特征，并利用这些特征训练神经网络（neural network），从而区分打印机制造商和具体型号。他们收集并发布了高分辨率文档扫描数据集，结果证明这些特征具有足够的辨识能力，有助于提升文件鉴别准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "to be published in 2024 International Joint Conference on Neural\n  Networks (IJCNN)",
      "pdf_url": "http://arxiv.org/pdf/2407.09539v1",
      "published_date": "2024-06-26 10:20:01 UTC",
      "updated_date": "2024-06-26 10:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:59:09.888584"
    },
    {
      "arxiv_id": "2406.18221v3",
      "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Venditti",
        "Elena Sofia Ruzzetti",
        "Giancarlo A. Xompero",
        "Cristina Giannone",
        "Andrea Favalli",
        "Raniero Romagnoli",
        "Fabio Massimo Zanzotto"
      ],
      "abstract": "Large language models (LLMs) require a significant redesign in solutions to\npreserve privacy in data-intensive applications due to their text-generation\ncapabilities. Indeed, LLMs tend to memorize and emit private information when\nmaliciously prompted. In this paper, we introduce Private Association Editing\n(PAE) as a novel defense approach for private data leakage. PAE is designed to\neffectively remove Personally Identifiable Information (PII) without retraining\nthe model. Experimental results demonstrate the effectiveness of PAE with\nrespect to alternative baseline methods. We believe PAE will serve as a\ncritical tool in the ongoing effort to protect data privacy in LLMs,\nencouraging the development of safer models for real-world applications.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在处理数据密集型应用时易于记忆并泄露个人信息 (PII) 的问题，提出了一种新型防御方法：Private Association Editing (PAE)。PAE 能够有效移除 PII 而无需重新训练模型，通过编辑关联来增强数据隐私保护。实验结果显示，PAE 优于现有基线方法，并有望成为推动更安全 LLMs 应用于现实世界的关键工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18221v3",
      "published_date": "2024-06-26 10:08:47 UTC",
      "updated_date": "2024-10-16 13:31:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:59:20.111555"
    },
    {
      "arxiv_id": "2406.18220v1",
      "title": "Guiding Video Prediction with Explicit Procedural Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Takenaka",
        "Johannes Maucher",
        "Marco F. Huber"
      ],
      "abstract": "We propose a general way to integrate procedural knowledge of a domain into\ndeep learning models. We apply it to the case of video prediction, building on\ntop of object-centric deep models and show that this leads to a better\nperformance than using data-driven models alone. We develop an architecture\nthat facilitates latent space disentanglement in order to use the integrated\nprocedural knowledge, and establish a setup that allows the model to learn the\nprocedural interface in the latent space using the downstream task of video\nprediction. We contrast the performance to a state-of-the-art data-driven\napproach and show that problems where purely data-driven approaches struggle\ncan be handled by using knowledge about the domain, providing an alternative to\nsimply collecting more data.",
      "tldr_zh": "这篇论文提出了一种将显式程序知识（procedural knowledge）整合到深度学习模型中的通用方法，应用于视频预测任务，以提升模型性能。研究构建在物体中心深度模型之上，开发了一个架构来促进潜在空间解耦（latent space disentanglement），并让模型通过下游视频预测任务学习程序接口。实验结果显示，与最先进的数据驱动方法相比，这种方法在数据驱动模型挣扎的问题上表现更好，提供了一个无需收集更多数据的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in 2023 IEEE/CVF International Conference on Computer\n  Vision Workshops (ICCVW)",
      "pdf_url": "http://arxiv.org/pdf/2406.18220v1",
      "published_date": "2024-06-26 10:08:24 UTC",
      "updated_date": "2024-06-26 10:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:59:32.431234"
    },
    {
      "arxiv_id": "2407.09538v1",
      "title": "A Dynamic Systems Approach to Modelling Human-Machine Rhythm Interaction",
      "title_zh": "一种动态系统方法用于建模人机节奏互动",
      "authors": [
        "Zhongju Yuan",
        "Wannes Van Ransbeeck",
        "Geraint Wiggins",
        "Dick Botteldooren"
      ],
      "abstract": "In exploring the simulation of human rhythmic perception and synchronization\ncapabilities, this study introduces a computational model inspired by the\nphysical and biological processes underlying rhythm processing. Utilizing a\nreservoir computing framework that simulates the function of cerebellum, the\nmodel features a dual-neuron classification and incorporates parameters to\nmodulate information transfer, reflecting biological neural network\ncharacteristics. Our findings demonstrate the model's ability to accurately\nperceive and adapt to rhythmic patterns within the human perceptible range,\nexhibiting behavior closely aligned with human rhythm interaction. By\nincorporating fine-tuning mechanisms and delay-feedback, the model enables\ncontinuous learning and precise rhythm prediction. The introduction of\ncustomized settings further enhances its capacity to stimulate diverse human\nrhythmic behaviors, underscoring the potential of this architecture in temporal\ncognitive task modeling and the study of rhythm synchronization and prediction\nin artificial and biological systems. Therefore, our model is capable of\ntransparently modelling cognitive theories that elucidate the dynamic processes\nby which the brain generates rhythm-related behavior.",
      "tldr_zh": "本研究提出了一种基于动态系统的计算模型，用于模拟人类节奏感知和同步能力，采用 reservoir computing 框架模拟小脑功能，并融入 dual-neuron classification 和参数调节以反映生物神经网络特性。模型通过微调机制和 delay-feedback 实现持续学习和精确节奏预测，能够准确适应人类可感知范围内的节奏模式，其行为与人类互动紧密相符。实验结果表明，该模型不仅增强了对多样人类节奏行为的模拟能力，还为节奏同步、预测在人工和生物系统中的应用提供透明的认知理论建模基础。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.HC",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09538v1",
      "published_date": "2024-06-26 10:07:20 UTC",
      "updated_date": "2024-06-26 10:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:59:44.977143"
    },
    {
      "arxiv_id": "2406.18211v1",
      "title": "AI Cards: Towards an Applied Framework for Machine-Readable AI and Risk Documentation Inspired by the EU AI Act",
      "title_zh": "翻译失败",
      "authors": [
        "Delaram Golpayegani",
        "Isabelle Hupont",
        "Cecilia Panigutti",
        "Harshvardhan J. Pandit",
        "Sven Schade",
        "Declan O'Sullivan",
        "Dave Lewis"
      ],
      "abstract": "With the upcoming enforcement of the EU AI Act, documentation of high-risk AI\nsystems and their risk management information will become a legal requirement\nplaying a pivotal role in demonstration of compliance. Despite its importance,\nthere is a lack of standards and guidelines to assist with drawing up AI and\nrisk documentation aligned with the AI Act. This paper aims to address this gap\nby providing an in-depth analysis of the AI Act's provisions regarding\ntechnical documentation, wherein we particularly focus on AI risk management.\nOn the basis of this analysis, we propose AI Cards as a novel holistic\nframework for representing a given intended use of an AI system by encompassing\ninformation regarding technical specifications, context of use, and risk\nmanagement, both in human- and machine-readable formats. While the\nhuman-readable representation of AI Cards provides AI stakeholders with a\ntransparent and comprehensible overview of the AI use case, its\nmachine-readable specification leverages on state of the art Semantic Web\ntechnologies to embody the interoperability needed for exchanging documentation\nwithin the AI value chain. This brings the flexibility required for reflecting\nchanges applied to the AI system and its context, provides the scalability\nneeded to accommodate potential amendments to legal requirements, and enables\ndevelopment of automated tools to assist with legal compliance and conformity\nassessment tasks. To solidify the benefits, we provide an exemplar AI Card for\nan AI-based student proctoring system and further discuss its potential\napplications within and beyond the context of the AI Act.",
      "tldr_zh": "这篇论文针对即将实施的 EU AI Act 中对高风险 AI 系统文档化的法律要求，分析了相关规定并指出了现有标准的缺失。作者提出 AI Cards 框架，这是一个整体性框架，用于表示 AI 系统的预期用途，包括技术规格、使用上下文和风险管理，支持人类可读和机器可读格式。AI Cards 利用 Semantic Web 技术实现文档的互操作性，从而提升灵活性、可扩展性和自动化合规工具开发。论文通过一个 AI-based student proctoring system 的示例，展示了该框架的应用潜力，并讨论了其在 EU AI Act 内部外的扩展可能性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18211v1",
      "published_date": "2024-06-26 09:51:49 UTC",
      "updated_date": "2024-06-26 09:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T00:59:57.877597"
    },
    {
      "arxiv_id": "2406.18193v1",
      "title": "MammothModa: Multi-Modal Large Language Model",
      "title_zh": "MammothModa：多模态大语言模型",
      "authors": [
        "Qi She",
        "Junwen Pan",
        "Xin Wan",
        "Rui Zhang",
        "Dawei Lu",
        "Kai Huang"
      ],
      "abstract": "In this report, we introduce MammothModa, yet another multi-modal large\nlanguage model (MLLM) designed to achieve state-of-the-art performance starting\nfrom an elementary baseline. We focus on three key design insights: (i)\nIntegrating Visual Capabilities while Maintaining Complex Language\nUnderstanding: In addition to the vision encoder, we incorporated the Visual\nAttention Experts into the LLM to enhance its visual capabilities. (ii)\nExtending Context Window for High-Resolution and Long-Duration Visual Feature:\nWe explore the Visual Merger Module to effectively reduce the token number of\nhigh-resolution images and incorporated frame position ids to avoid position\ninterpolation. (iii) High-Quality Bilingual Datasets: We meticulously curated\nand filtered a high-quality bilingual multimodal dataset to reduce visual\nhallucinations. With above recipe we build MammothModa that consistently\noutperforms the state-of-the-art models, e.g., LLaVA-series, across main\nreal-world visual language benchmarks without bells and whistles.",
      "tldr_zh": "本研究介绍了 MammothModa，一种多模态大型语言模型 (MLLM)，旨在从基础基准出发实现最先进性能。关键设计包括：(i) 整合 Visual Attention Experts 到 LLM 中，以增强视觉能力同时保持复杂语言理解；(ii) 通过 Visual Merger Module 减少高分辨率图像的 token 数量，并使用 frame position ids 扩展上下文窗口以处理长时序视觉特征；(iii) 精心策划和过滤高质量双语多模态数据集，以降低视觉幻觉。实验结果显示，MammothModa 在主要真实世界视觉语言基准上，稳健地超越了如 LLaVA-series 等最先进模型，而无需额外优化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2406.18193v1",
      "published_date": "2024-06-26 09:17:27 UTC",
      "updated_date": "2024-06-26 09:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:00:08.720297"
    },
    {
      "arxiv_id": "2406.18192v2",
      "title": "Methodology of Adapting Large English Language Models for Specific Cultural Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjing Zhang",
        "Siqi Xiao",
        "Xuejiao Lei",
        "Ning Wang",
        "Huazheng Zhang",
        "Meijuan An",
        "Bikun Yang",
        "Zhaoxiang Liu",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "The rapid growth of large language models(LLMs) has emerged as a prominent\ntrend in the field of artificial intelligence. However, current\nstate-of-the-art LLMs are predominantly based on English. They encounter\nlimitations when directly applied to tasks in specific cultural domains, due to\ndeficiencies in domain-specific knowledge and misunderstandings caused by\ndifferences in cultural values. To address this challenge, our paper proposes a\nrapid adaptation method for large models in specific cultural contexts, which\nleverages instruction-tuning based on specific cultural knowledge and safety\nvalues data. Taking Chinese as the specific cultural context and utilizing the\nLLaMA3-8B as the experimental English LLM, the evaluation results demonstrate\nthat the adapted LLM significantly enhances its capabilities in domain-specific\nknowledge and adaptability to safety values, while maintaining its original\nexpertise advantages.",
      "tldr_zh": "本研究探讨了基于英语的大型语言模型（LLMs）在特定文化语境下存在的局限性，如领域特定知识缺失和文化价值观差异导致的误解。论文提出了一种快速适应方法，通过instruction-tuning利用特定文化知识和安全价值观数据进行微调。针对中文语境，使用LLaMA3-8B作为实验模型，结果显示适应后的模型显著提升了领域特定知识和安全价值观适应性，同时保留了原有专业优势。整体方法为跨文化AI应用提供了实用框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.18192v2",
      "published_date": "2024-06-26 09:16:08 UTC",
      "updated_date": "2024-06-27 02:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:00:20.607961"
    },
    {
      "arxiv_id": "2406.18187v1",
      "title": "Selective Prompting Tuning for Personalized Conversations with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Qiushi Huang",
        "Xubo Liu",
        "Tom Ko",
        "Bo Wu",
        "Wenwu Wang",
        "Yu Zhang",
        "Lilian Tang"
      ],
      "abstract": "In conversational AI, personalizing dialogues with persona profiles and\ncontextual understanding is essential. Despite large language models' (LLMs)\nimproved response coherence, effective persona integration remains a challenge.\nIn this work, we first study two common approaches for personalizing LLMs:\ntextual prompting and direct fine-tuning. We observed that textual prompting\noften struggles to yield responses that are similar to the ground truths in\ndatasets, while direct fine-tuning tends to produce repetitive or overly\ngeneric replies. To alleviate those issues, we propose \\textbf{S}elective\n\\textbf{P}rompt \\textbf{T}uning (SPT), which softly prompts LLMs for\npersonalized conversations in a selective way. Concretely, SPT initializes a\nset of soft prompts and uses a trainable dense retriever to adaptively select\nsuitable soft prompts for LLMs according to different input contexts, where the\nprompt retriever is dynamically updated through feedback from the LLMs.\nAdditionally, we propose context-prompt contrastive learning and prompt fusion\nlearning to encourage the SPT to enhance the diversity of personalized\nconversations. Experiments on the CONVAI2 dataset demonstrate that SPT\nsignificantly enhances response diversity by up to 90\\%, along with\nimprovements in other critical performance indicators. Those results highlight\nthe efficacy of SPT in fostering engaging and personalized dialogue generation.\nThe SPT model code (https://github.com/hqsiswiliam/SPT) is publicly available\nfor further exploration.",
      "tldr_zh": "这篇论文探讨了在对话AI中使用LLMs进行个性化对话的挑战，指出textual prompting难以生成与ground truths相似的响应，而direct fine-tuning则容易导致repetitive或overly generic的回复。作者提出Selective Prompt Tuning (SPT)，一种通过初始化软提示并使用可训练的dense retriever根据输入上下文自适应选择和动态更新提示的方法，同时引入context-prompt contrastive learning和prompt fusion learning来提升对话多样性。在CONVAI2数据集上的实验显示，SPT将响应多样性提高了高达90%，并改善了其他关键性能指标，从而促进了更吸引人的个性化对话生成。模型代码已开源以供进一步探索。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2406.18187v1",
      "published_date": "2024-06-26 09:03:52 UTC",
      "updated_date": "2024-06-26 09:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:00:34.877854"
    },
    {
      "arxiv_id": "2407.09537v1",
      "title": "ViPro: Enabling and Controlling Video Prediction for Complex Dynamical Scenarios using Procedural Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Takenaka",
        "Johannes Maucher",
        "Marco F. Huber"
      ],
      "abstract": "We propose a novel architecture design for video prediction in order to\nutilize procedural domain knowledge directly as part of the computational graph\nof data-driven models. On the basis of new challenging scenarios we show that\nstate-of-the-art video predictors struggle in complex dynamical settings, and\nhighlight that the introduction of prior process knowledge makes their learning\nproblem feasible. Our approach results in the learning of a symbolically\naddressable interface between data-driven aspects in the model and our\ndedicated procedural knowledge module, which we utilize in downstream control\ntasks.",
      "tldr_zh": "该论文提出ViPro，一种新架构设计，用于在复杂动态场景中启用和控制视频预测，通过直接将程序化领域知识(procedural knowledge)整合到数据驱动模型(computational graph)中。研究发现，现有的最先进视频预测器在这些场景中表现不佳，但引入先验过程知识能使学习问题变得可行。ViPro通过学习一个符号可寻址接口(symbolically addressable interface)，连接数据驱动部分和专用知识模块，并将其应用于下游控制任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted at NeSy2024, to be published in LNCS/LNAI",
      "pdf_url": "http://arxiv.org/pdf/2407.09537v1",
      "published_date": "2024-06-26 09:01:35 UTC",
      "updated_date": "2024-06-26 09:01:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:00:46.018000"
    },
    {
      "arxiv_id": "2406.18178v2",
      "title": "Games of Knightian Uncertainty as AGI testbeds",
      "title_zh": "翻译失败",
      "authors": [
        "Spyridon Samothrakis",
        "Dennis J. N. J. Soemers",
        "Damian Machlanski"
      ],
      "abstract": "Arguably, for the latter part of the late 20th and early 21st centuries,\ngames have been seen as the drosophila of AI. Games are a set of exciting\ntestbeds, whose solutions (in terms of identifying optimal players) would lead\nto machines that would possess some form of general intelligence, or at the\nvery least help us gain insights toward building intelligent machines.\nFollowing impressive successes in traditional board games like Go, Chess, and\nPoker, but also video games like the Atari 2600 collection, it is clear that\nthis is not the case. Games have been attacked successfully, but we are nowhere\nnear AGI developments (or, as harsher critics might say, useful AI\ndevelopments!). In this short vision paper, we argue that for game research to\nbecome again relevant to the AGI pathway, we need to be able to address\n\\textit{Knightian uncertainty} in the context of games, i.e. agents need to be\nable to adapt to rapid changes in game rules on the fly with no warning, no\nprevious data, and no model access.",
      "tldr_zh": "该论文认为，游戏曾被视为AI发展的关键测试床，但尽管在棋类和视频游戏中取得进展，我们仍未实现AGI或有用的AI。作者提出，为使游戏研究重新相关于AGI路径，需要引入Knightian uncertainty，即代理需在游戏规则突然变化时，立即适应，而无警告、数据或模型访问。这种方法能帮助构建更智能的系统，推动AGI研究向前迈进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18178v2",
      "published_date": "2024-06-26 08:52:34 UTC",
      "updated_date": "2024-06-27 09:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:00:55.784444"
    },
    {
      "arxiv_id": "2406.18175v2",
      "title": "Galaxy spectroscopy without spectra: Galaxy properties from photometric images with conditional diffusion models",
      "title_zh": "翻译失败",
      "authors": [
        "Lars Doorenbos",
        "Eva Sextl",
        "Kevin Heng",
        "Stefano Cavuoti",
        "Massimo Brescia",
        "Olena Torbaniuk",
        "Giuseppe Longo",
        "Raphael Sznitman",
        "Pablo Márquez-Neila"
      ],
      "abstract": "Modern spectroscopic surveys can only target a small fraction of the vast\namount of photometrically cataloged sources in wide-field surveys. Here, we\nreport the development of a generative AI method capable of predicting optical\ngalaxy spectra from photometric broad-band images alone. This method draws from\nthe latest advances in diffusion models in combination with contrastive\nnetworks. We pass multi-band galaxy images into the architecture to obtain\noptical spectra. From these, robust values for galaxy properties can be derived\nwith any methods in the spectroscopic toolbox, such as standard population\nsynthesis techniques and Lick indices. When trained and tested on 64x64-pixel\nimages from the Sloan Digital Sky Survey, the global bimodality of star-forming\nand quiescent galaxies in photometric space is recovered, as well as a\nmass-metallicity relation of star-forming galaxies. The comparison between the\nobserved and the artificially created spectra shows good agreement in overall\nmetallicity, age, Dn4000, stellar velocity dispersion, and E(B-V) values.\nPhotometric redshift estimates of our generative algorithm can compete with\nother current, specialized deep-learning techniques. Moreover, this work is the\nfirst attempt in the literature to infer velocity dispersion from photometric\nimages. Additionally, we can predict the presence of an active galactic nucleus\nup to an accuracy of 82%. With our method, scientifically interesting galaxy\nproperties, normally requiring spectroscopic inputs, can be obtained in future\ndata sets from large-scale photometric surveys alone. The spectra prediction\nvia AI can further assist in creating realistic mock catalogs.",
      "tldr_zh": "该研究提出了一种使用条件扩散模型（conditional diffusion models）和对比网络（contrastive networks）的方法，从光度图像（photometric images）直接预测星系光谱（galaxy spectra），从而无需实际光谱即可推导出星系属性。  \n在 Sloan Digital Sky Survey 的 64x64 像素图像上训练和测试后，该方法成功恢复了星系的全球双峰分布（star-forming 和 quiescent 星系）以及 star-forming 星系的质量-金属丰度关系，并与观测光谱在 metallicity、age、Dn4000、stellar velocity dispersion 和 E(B-V) 值上表现出良好一致性。  \n此外，该算法的 photometric redshift 估计可与专业深度学习技术媲美，并首次从光度图像推断 stellar velocity dispersion，还能以82%的准确率预测 active galactic nucleus（AGN）的存在，为未来大型光度调查提供高效工具和 realistic mock catalogs。",
      "categories": [
        "astro-ph.GA",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.GA",
      "comment": "Accepted by The Astrophysical Journal. Code is available at\n  https://github.com/LarsDoorenbos/generate-spectra",
      "pdf_url": "http://arxiv.org/pdf/2406.18175v2",
      "published_date": "2024-06-26 08:49:51 UTC",
      "updated_date": "2024-10-28 11:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:01:11.368669"
    },
    {
      "arxiv_id": "2406.18621v2",
      "title": "Towards Deep Active Learning in Avian Bioacoustics",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Rauch",
        "Denis Huseljic",
        "Moritz Wirth",
        "Jens Decke",
        "Bernhard Sick",
        "Christoph Scholz"
      ],
      "abstract": "Passive acoustic monitoring (PAM) in avian bioacoustics enables\ncost-effective and extensive data collection with minimal disruption to natural\nhabitats. Despite advancements in computational avian bioacoustics, deep\nlearning models continue to encounter challenges in adapting to diverse\nenvironments in practical PAM scenarios. This is primarily due to the scarcity\nof annotations, which requires labor-intensive efforts from human experts.\nActive learning (AL) reduces annotation cost and speed ups adaption to diverse\nscenarios by querying the most informative instances for labeling. This paper\noutlines a deep AL approach, introduces key challenges, and conducts a\nsmall-scale pilot study.",
      "tldr_zh": "本研究探讨了在鸟类生物声学中应用被动声学监测 (PAM) 的挑战，强调深度学习模型在适应多样环境时因标注数据稀缺而需依赖专家的劳动密集型工作。论文提出了一种深度主动学习 (Active Learning, AL) 方法，通过查询最有信息量的实例来减少标注成本并加速模型适应。最终，该研究概述了关键挑战，并进行了一个小规模试点研究，以验证 AL 在实际 PAM 场景中的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted at IAL@ECML-PKDD24",
      "pdf_url": "http://arxiv.org/pdf/2406.18621v2",
      "published_date": "2024-06-26 08:43:05 UTC",
      "updated_date": "2024-11-05 13:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:01:19.954201"
    },
    {
      "arxiv_id": "2406.18620v1",
      "title": "Documentation Practices of Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Arnold",
        "Dilara Yesilbas",
        "Rene Gröbner",
        "Dominik Riedelbauch",
        "Maik Horn",
        "Sven Weinzierl"
      ],
      "abstract": "Artificial Intelligence (AI) faces persistent challenges in terms of\ntransparency and accountability, which requires rigorous documentation. Through\na literature review on documentation practices, we provide an overview of\nprevailing trends, persistent issues, and the multifaceted interplay of factors\ninfluencing the documentation. Our examination of key characteristics such as\nscope, target audiences, support for multimodality, and level of automation,\nhighlights a dynamic evolution in documentation practices, underscored by a\nshift towards a more holistic, engaging, and automated documentation.",
      "tldr_zh": "这篇论文通过文献综述探讨了人工智能 (AI) 在透明度和责任方面面临的挑战，以及文档化的重要性。研究概述了当前文档实践的趋势、持续问题和影响因素，包括文档的范围、目标受众、多模态支持以及自动化水平。结果突显了文档实践的动态演变，向更全面、引人入胜和自动化的方向发展。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18620v1",
      "published_date": "2024-06-26 08:33:52 UTC",
      "updated_date": "2024-06-26 08:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:01:32.265504"
    },
    {
      "arxiv_id": "2406.18166v1",
      "title": "Start from Zero: Triple Set Prediction for Automatic Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Zhang",
        "Yajing Xu",
        "Peng Ye",
        "Zhiwei Huang",
        "Zezhong Xu",
        "Jiaoyan Chen",
        "Jeff Z. Pan",
        "Huajun Chen"
      ],
      "abstract": "Knowledge graph (KG) completion aims to find out missing triples in a KG.\nSome tasks, such as link prediction and instance completion, have been proposed\nfor KG completion. They are triple-level tasks with some elements in a missing\ntriple given to predict the missing element of the triple. However, knowing\nsome elements of the missing triple in advance is not always a realistic\nsetting. In this paper, we propose a novel graph-level automatic KG completion\ntask called Triple Set Prediction (TSP) which assumes none of the elements in\nthe missing triples is given. TSP is to predict a set of missing triples given\na set of known triples. To properly and accurately evaluate this new task, we\npropose 4 evaluation metrics including 3 classification metrics and 1 ranking\nmetric, considering both the partial-open-world and the closed-world\nassumptions. Furthermore, to tackle the huge candidate triples for prediction,\nwe propose a novel and efficient subgraph-based method GPHT that can predict\nthe triple set fast. To fairly compare the TSP results, we also propose two\ntypes of methods RuleTensor-TSP and KGE-TSP applying the existing rule- and\nembedding-based methods for TSP as baselines. During experiments, we evaluate\nthe proposed methods on two datasets extracted from Wikidata following the\nrelation-similarity partial-open-world assumption proposed by us, and also\ncreate a complete family data set to evaluate TSP results following the\nclosed-world assumption. Results prove that the methods can successfully\ngenerate a set of missing triples and achieve reasonable scores on the new\ntask, and GPHT performs better than the baselines with significantly shorter\nprediction time. The datasets and code for experiments are available at\nhttps://github.com/zjukg/GPHT-for-TSP.",
      "tldr_zh": "该论文提出了一种新的知识图谱（KG）补全任务Triple Set Prediction (TSP)，旨在从零开始预测一组缺失三元组，而不依赖任何已知元素，从而更贴近现实场景。作者设计了4个评估指标，包括3个分类指标和1个排名指标，以适应部分开放世界和封闭世界假设，并引入了一个高效的子图-based方法GPHT来快速预测缺失三元组集。实验在Wikidata数据集上验证了方法的有效性，GPHT比基线方法RuleTensor-TSP和KGE-TSP表现出色，不仅准确率更高，还显著缩短了预测时间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted by TKDE in 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18166v1",
      "published_date": "2024-06-26 08:26:32 UTC",
      "updated_date": "2024-06-26 08:26:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:01:44.845825"
    },
    {
      "arxiv_id": "2406.18142v1",
      "title": "Innovating for Tomorrow: The Convergence of SE and Green AI",
      "title_zh": "翻译失败",
      "authors": [
        "Luís Cruz",
        "Xavier Franch Gutierrez",
        "Silverio Martínez-Fernández"
      ],
      "abstract": "The latest advancements in machine learning, specifically in foundation\nmodels, are revolutionizing the frontiers of existing software engineering (SE)\nprocesses. This is a bi-directional phenomona, where 1) software systems are\nnow challenged to provide AI-enabled features to their users, and 2) AI is used\nto automate tasks within the software development lifecycle. In an era where\nsustainability is a pressing societal concern, our community needs to adopt a\nlong-term plan enabling a conscious transformation that aligns with\nenvironmental sustainability values. In this paper, we reflect on the impact of\nadopting environmentally friendly practices to create AI-enabled software\nsystems and make considerations on the environmental impact of using foundation\nmodels for software development.",
      "tldr_zh": "这篇论文探讨了软件工程（SE）和绿色AI（Green AI）的融合，特别是在基础模型（foundation models）推动下，如何革新现有SE流程的双向影响：一方面，软件系统需提供AI功能；另一方面，AI用于自动化软件开发生命周期。作者强调，在可持续性成为社会核心关切的时代，需要制定长期计划以推动环保实践，确保AI-enabled软件系统的环境友好性。该研究反思了采用绿色策略的益处，并评估了使用基础模型进行软件开发的环境影响，为可持续AI创新提供重要见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted in SE 2030 - International Workshop on Software Engineering\n  in 2030",
      "pdf_url": "http://arxiv.org/pdf/2406.18142v1",
      "published_date": "2024-06-26 07:47:04 UTC",
      "updated_date": "2024-06-26 07:47:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:02:00.611564"
    },
    {
      "arxiv_id": "2406.18140v3",
      "title": "Exclusive Style Removal for Cross Domain Novel Class Discovery",
      "title_zh": "跨域新类发现的排他式风格移除",
      "authors": [
        "Yicheng Wang",
        "Feng Liu",
        "Junmin Liu",
        "Kai Sun"
      ],
      "abstract": "As a promising field in open-world learning, \\textit{Novel Class Discovery}\n(NCD) is usually a task to cluster unseen novel classes in an unlabeled set\nbased on the prior knowledge of labeled data within the same domain. However,\nthe performance of existing NCD methods could be severely compromised when\nnovel classes are sampled from a different distribution with the labeled ones.\nIn this paper, we explore and establish the solvability of NCD in cross domain\nsetting with the necessary condition that style information must be removed.\nBased on the theoretical analysis, we introduce an exclusive style removal\nmodule for extracting style information that is distinctive from the baseline\nfeatures, thereby facilitating inference. Moreover, this module is easy to\nintegrate with other NCD methods, acting as a plug-in to improve performance on\nnovel classes with different distributions compared to the seen labeled set.\nAdditionally, recognizing the non-negligible influence of different backbones\nand pre-training strategies on the performance of the NCD methods, we build a\nfair benchmark for future NCD research. Extensive experiments on three common\ndatasets demonstrate the effectiveness of our proposed module.",
      "tldr_zh": "本研究探讨了 Novel Class Discovery (NCD) 在跨域设置下的挑战，即当未标记的新类来自不同分布时，现有方法性能会显著下降。论文通过理论分析确立了移除风格信息（style information）的必要条件，并提出一个 exclusive style removal module，用于提取与基线特征不同的风格信息，从而提升跨域推理能力。该模块可作为插件轻松整合到其他 NCD 方法中，以改善新类分布不同的场景下的表现；此外，研究还建立了一个公平基准（fair benchmark），考虑不同骨干网和预训练策略的影响。在三个常见数据集上的广泛实验证明，该模块有效提高了 NCD 的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18140v3",
      "published_date": "2024-06-26 07:44:27 UTC",
      "updated_date": "2024-09-13 11:36:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:02:08.670177"
    },
    {
      "arxiv_id": "2406.18125v2",
      "title": "ResumeAtlas: Revisiting Resume Classification with Large-Scale Datasets and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Heakl",
        "Youssef Mohamed",
        "Noran Mohamed",
        "Aly Elsharkawy",
        "Ahmed Zaky"
      ],
      "abstract": "The increasing reliance on online recruitment platforms coupled with the\nadoption of AI technologies has highlighted the critical need for efficient\nresume classification methods. However, challenges such as small datasets, lack\nof standardized resume templates, and privacy concerns hinder the accuracy and\neffectiveness of existing classification models. In this work, we address these\nchallenges by presenting a comprehensive approach to resume classification. We\ncurated a large-scale dataset of 13,389 resumes from diverse sources and\nemployed Large Language Models (LLMs) such as BERT and Gemma1.1 2B for\nclassification. Our results demonstrate significant improvements over\ntraditional machine learning approaches, with our best model achieving a top-1\naccuracy of 92\\% and a top-5 accuracy of 97.5\\%. These findings underscore the\nimportance of dataset quality and advanced model architectures in enhancing the\naccuracy and robustness of resume classification systems, thus advancing the\nfield of online recruitment practices.",
      "tldr_zh": "这篇论文针对在线招聘中简历分类的挑战，如小数据集、缺乏标准化模板和隐私问题，构建了一个大规模数据集ResumeAtlas，包含13,389份多样化简历。研究团队使用Large Language Models (LLMs)如BERT和Gemma1.1 2B进行分类，显著提升了模型性能。结果显示，最佳模型的top-1 accuracy达到92%，top-5 accuracy为97.5%，优于传统机器学习方法。这些发现突出了数据集质量和高级模型架构在提高简历分类系统准确性和鲁棒性方面的关键作用，从而推动在线招聘实践的进步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 6 figures, 1 table, 6th International Conference on AI in\n  Computational Linguistics",
      "pdf_url": "http://arxiv.org/pdf/2406.18125v2",
      "published_date": "2024-06-26 07:25:18 UTC",
      "updated_date": "2024-07-12 18:19:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:02:21.468189"
    },
    {
      "arxiv_id": "2406.18122v1",
      "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqiu Wang",
        "Jun Liu",
        "Shengkai Zhang",
        "Yang Yang"
      ],
      "abstract": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）的安全漏洞，特别针对jailbreak攻击，该攻击旨在绕过模型的安全机制诱导生成不当内容。研究者首次提出indirect jailbreak概念，并开发了Poisoned-LangChain (PLC)方法，通过污染外部知识基和利用Retrieval-Augmented Generation (RAG)技术，使LLMs生成恶意对话。在六种LLMs上的实验中，PLC在三种jailbreak场景下实现了高达88.56%、79.04%和82.69%的成功率，强调了RAG系统潜在风险并呼吁加强防御措施。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages,2 figures,This paper is a submission to ACM TURC. It has been\n  accepted by the editor of the organizer",
      "pdf_url": "http://arxiv.org/pdf/2406.18122v1",
      "published_date": "2024-06-26 07:21:02 UTC",
      "updated_date": "2024-06-26 07:21:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:02:32.538507"
    },
    {
      "arxiv_id": "2406.18120v2",
      "title": "ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Heakl",
        "Youssef Zaghloul",
        "Mennatullah Ali",
        "Rania Hossam",
        "Walid Gomaa"
      ],
      "abstract": "Motivated by the widespread increase in the phenomenon of code-switching\nbetween Egyptian Arabic and English in recent times, this paper explores the\nintricacies of machine translation (MT) and automatic speech recognition (ASR)\nsystems, focusing on translating code-switched Egyptian Arabic-English to\neither English or Egyptian Arabic. Our goal is to present the methodologies\nemployed in developing these systems, utilizing large language models such as\nLLama and Gemma. In the field of ASR, we explore the utilization of the Whisper\nmodel for code-switched Egyptian Arabic recognition, detailing our experimental\nprocedures including data preprocessing and training techniques. Through the\nimplementation of a consecutive speech-to-text translation system that\nintegrates ASR with MT, we aim to overcome challenges posed by limited\nresources and the unique characteristics of the Egyptian Arabic dialect.\nEvaluation against established metrics showcases promising results, with our\nmethodologies yielding a significant improvement of $56\\%$ in English\ntranslation over the state-of-the-art and $9.3\\%$ in Arabic translation. Since\ncode-switching is deeply inherent in spoken languages, it is crucial that ASR\nsystems can effectively handle this phenomenon. This capability is crucial for\nenabling seamless interaction in various domains, including business\nnegotiations, cultural exchanges, and academic discourse. Our models and code\nare available as open-source resources. Code:\n\\url{http://github.com/ahmedheakl/arazn-llm}}, Models:\n\\url{http://huggingface.co/collections/ahmedheakl/arazn-llm-662ceaf12777656607b9524e}.",
      "tldr_zh": "本论文探讨了埃及阿拉伯语和英语的代码切换（code-switching）现象，针对机器翻译（MT）和自动语音识别（ASR）系统，开发了将代码切换语言翻译成英语或埃及阿拉伯语的方法。研究利用大型语言模型（LLMs）如 LLaMA 和 Gemma 进行 MT，并采用 Whisper 模型处理 ASR，通过数据预处理、训练技术和 ASR 与 MT 的整合来克服资源有限和方言特性的挑战。实验结果显示，该系统在英语翻译上比现有技术提高了 56%，在阿拉伯语翻译上提高了 9.3%，从而提升了代码切换语言的处理能力。模型和代码已开源，旨在支持商业、文化和学术领域的无缝互动。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures, 5 tables, 6th International Conference on AI in\n  Computational Linguistics",
      "pdf_url": "http://arxiv.org/pdf/2406.18120v2",
      "published_date": "2024-06-26 07:19:51 UTC",
      "updated_date": "2024-07-12 18:22:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:02:44.640813"
    },
    {
      "arxiv_id": "2407.00092v1",
      "title": "Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models (MLLMs): Solving TSP and mTSP Combinatorial Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Elhenawy",
        "Ahmad Abutahoun",
        "Taqwa I. Alhadidi",
        "Ahmed Jaber",
        "Huthaifa I. Ashqar",
        "Shadi Jaradat",
        "Ahmed Abdelhay",
        "Sebastien Glaser",
        "Andry Rakotonirainy"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) harness comprehensive knowledge\nspanning text, images, and audio to adeptly tackle complex problems, including\nzero-shot in-context learning scenarios. This study explores the ability of\nMLLMs in visually solving the Traveling Salesman Problem (TSP) and Multiple\nTraveling Salesman Problem (mTSP) using images that portray point distributions\non a two-dimensional plane. We introduce a novel approach employing multiple\nspecialized agents within the MLLM framework, each dedicated to optimizing\nsolutions for these combinatorial challenges. Our experimental investigation\nincludes rigorous evaluations across zero-shot settings and introduces\ninnovative multi-agent zero-shot in-context scenarios. The results demonstrated\nthat both multi-agent models. Multi-Agent 1, which includes the Initializer,\nCritic, and Scorer agents, and Multi-Agent 2, which comprises only the\nInitializer and Critic agents; significantly improved solution quality for TSP\nand mTSP problems. Multi-Agent 1 excelled in environments requiring detailed\nroute refinement and evaluation, providing a robust framework for sophisticated\noptimizations. In contrast, Multi-Agent 2, focusing on iterative refinements by\nthe Initializer and Critic, proved effective for rapid decision-making\nscenarios. These experiments yield promising outcomes, showcasing the robust\nvisual reasoning capabilities of MLLMs in addressing diverse combinatorial\nproblems. The findings underscore the potential of MLLMs as powerful tools in\ncomputational optimization, offering insights that could inspire further\nadvancements in this promising field. Project link:\nhttps://github.com/ahmed-abdulhuy/Solving-TSP-and-mTSP-Combinatorial-Challenges-using-Visual-Reasoning-and-Multi-Agent-Approach-MLLMs-.git",
      "tldr_zh": "本研究探索了Multimodal Large Language Models (MLLMs)在视觉推理方面的能力，专注于通过图像表示点分布来解决Traveling Salesman Problem (TSP)和Multiple Traveling Salesman Problem (mTSP)等组合优化挑战。研究引入了一种多智能体框架，包括Multi-Agent 1（由Initializer、Critic和Scorer代理组成）和Multi-Agent 2（仅由Initializer和Critic代理组成），在零样本和多智能体零样本情境下进行实验。结果显示，这两种多智能体模型显著提升了TSP和mTSP的解决方案质量，其中Multi-Agent 1在需要详细路由优化和评估的环境中表现出色，而Multi-Agent 2则适用于快速决策场景。这些发现突显了MLLMs在计算优化领域的潜力，并为未来研究提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00092v1",
      "published_date": "2024-06-26 07:12:06 UTC",
      "updated_date": "2024-06-26 07:12:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:02:56.652965"
    },
    {
      "arxiv_id": "2406.18116v1",
      "title": "BADGE: BADminton report Generation and Evaluation with LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Shang-Hsuan Chiang",
        "Lin-Wei Chao",
        "Kuang-Da Wang",
        "Chih-Chuan Wang",
        "Wen-Chih Peng"
      ],
      "abstract": "Badminton enjoys widespread popularity, and reports on matches generally\ninclude details such as player names, game scores, and ball types, providing\naudiences with a comprehensive view of the games. However, writing these\nreports can be a time-consuming task. This challenge led us to explore whether\na Large Language Model (LLM) could automate the generation and evaluation of\nbadminton reports. We introduce a novel framework named BADGE, designed for\nthis purpose using LLM. Our method consists of two main phases: Report\nGeneration and Report Evaluation. Initially, badminton-related data is\nprocessed by the LLM, which then generates a detailed report of the match. We\ntested different Input Data Types, In-Context Learning (ICL), and LLM, finding\nthat GPT-4 performs best when using CSV data type and the Chain of Thought\nprompting. Following report generation, the LLM evaluates and scores the\nreports to assess their quality. Our comparisons between the scores evaluated\nby GPT-4 and human judges show a tendency to prefer GPT-4 generated reports.\nSince the application of LLM in badminton reporting remains largely unexplored,\nour research serves as a foundational step for future advancements in this\narea. Moreover, our method can be extended to other sports games, thereby\nenhancing sports promotion. For more details, please refer to\nhttps://github.com/AndyChiangSH/BADGE.",
      "tldr_zh": "本研究提出BADGE框架，利用Large Language Model (LLM)自动生成和评估羽毛球比赛报告，以解决手动撰写报告的耗时问题。框架包括报告生成阶段（使用GPT-4处理CSV数据类型，并结合In-Context Learning (ICL)和Chain of Thought提示，生成高质量报告）和报告评估阶段（LLM评估报告分数，与人类评判一致）。实验结果显示，GPT-4生成的报告更受欢迎，且该方法可扩展至其他体育项目，促进体育推广。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IJCAI 2024 Workshop: The 2nd International Workshop on\n  Intelligent Technologies for Precision Sports Science (IT4PSS)",
      "pdf_url": "http://arxiv.org/pdf/2406.18116v1",
      "published_date": "2024-06-26 07:07:52 UTC",
      "updated_date": "2024-06-26 07:07:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:03:08.193165"
    },
    {
      "arxiv_id": "2406.18115v1",
      "title": "Open-vocabulary Mobile Manipulation in Unseen Dynamic Environments with 3D Semantic Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Dicong Qiu",
        "Wenzong Ma",
        "Zhenfu Pan",
        "Hui Xiong",
        "Junwei Liang"
      ],
      "abstract": "Open-Vocabulary Mobile Manipulation (OVMM) is a crucial capability for\nautonomous robots, especially when faced with the challenges posed by unknown\nand dynamic environments. This task requires robots to explore and build a\nsemantic understanding of their surroundings, generate feasible plans to\nachieve manipulation goals, adapt to environmental changes, and comprehend\nnatural language instructions from humans. To address these challenges, we\npropose a novel framework that leverages the zero-shot detection and grounded\nrecognition capabilities of pretraining visual-language models (VLMs) combined\nwith dense 3D entity reconstruction to build 3D semantic maps. Additionally, we\nutilize large language models (LLMs) for spatial region abstraction and online\nplanning, incorporating human instructions and spatial semantic context. We\nhave built a 10-DoF mobile manipulation robotic platform JSR-1 and demonstrated\nin real-world robot experiments that our proposed framework can effectively\ncapture spatial semantics and process natural language user instructions for\nzero-shot OVMM tasks under dynamic environment settings, with an overall\nnavigation and task success rate of 80.95% and 73.33% over 105 episodes, and\nbetter SFT and SPL by 157.18% and 19.53% respectively compared to the baseline.\nFurthermore, the framework is capable of replanning towards the next most\nprobable candidate location based on the spatial semantic context derived from\nthe 3D semantic map when initial plans fail, keeping an average success rate of\n76.67%.",
      "tldr_zh": "该研究提出了一种新框架，用于在未知动态环境中实现开放词汇移动操作（OVMM），通过结合预训练视觉语言模型（VLMs）的零样本检测与密集 3D 实体重建，构建 3D 语义地图，并利用大型语言模型（LLMs）进行空间区域抽象、在线规划和整合人类指令。框架在 10-DoF 移动操作机器人平台 JSR-1 上进行实证实验，展示了在动态环境下的有效性，总导航成功率达 80.95%、任务成功率达 73.33%，并在 SFT 和 SPL 指标上分别比基线提升 157.18% 和 19.53%。此外，该框架能基于 3D 语义地图进行重新规划，当初始计划失败时保持平均成功率 76.67%，显著提高了机器人的适应性和鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Open-vocabulary, Mobile Manipulation, Dynamic Environments, 3D\n  Semantic Maps, Zero-shot, LLMs, VLMs, 18 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.18115v1",
      "published_date": "2024-06-26 07:06:42 UTC",
      "updated_date": "2024-06-26 07:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:03:22.627010"
    },
    {
      "arxiv_id": "2406.18088v2",
      "title": "LLM-Driven Multimodal Opinion Expression Identification",
      "title_zh": "LLM驱动的多模态观点表达识别",
      "authors": [
        "Bonian Jia",
        "Huiyao Chen",
        "Yueheng Sun",
        "Meishan Zhang",
        "Min Zhang"
      ],
      "abstract": "Opinion Expression Identification (OEI) is essential in NLP for applications\nranging from voice assistants to depression diagnosis. This study extends OEI\nto encompass multimodal inputs, underlining the significance of auditory cues\nin delivering emotional subtleties beyond the capabilities of text. We\nintroduce a novel multimodal OEI (MOEI) task, integrating text and speech to\nmirror real-world scenarios. Utilizing CMU MOSEI and IEMOCAP datasets, we\nconstruct the CI-MOEI dataset. Additionally, Text-to-Speech (TTS) technology is\napplied to the MPQA dataset to obtain the CIM-OEI dataset. We design a template\nfor the OEI task to take full advantage of the generative power of large\nlanguage models (LLMs). Advancing further, we propose an LLM-driven method\nSTOEI, which combines speech and text modal to identify opinion expressions.\nOur experiments demonstrate that MOEI significantly improves the performance\nwhile our method outperforms existing methods by 9.20\\% and obtains SOTA\nresults.",
      "tldr_zh": "这篇论文扩展了 Opinion Expression Identification (OEI) 到多模态输入，强调语音在传达情感细微方面的作用，并提出新的 Multimodal OEI (MOEI) 任务，整合文本和语音以模拟真实场景。研究者构建了 CI-MOEI 和 CIM-OEI 数据集，利用 Text-to-Speech (TTS) 技术和现有数据集，并设计了基于 Large Language Models (LLMs) 的 STOEI 方法，将语音与文本模态结合进行意见表达识别。实验结果表明，该方法比现有方法提高了 9.20% 的性能，并取得了 State-of-the-Art (SOTA) 结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 3 Figures, Accept by Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18088v2",
      "published_date": "2024-06-26 05:52:47 UTC",
      "updated_date": "2024-06-29 09:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:03:33.798972"
    },
    {
      "arxiv_id": "2406.18087v1",
      "title": "EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction Using Large Language Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chun-Chieh Liao",
        "Wei-Ting Kuo",
        "I-Hsuan Hu",
        "Yen-Chen Shih",
        "Jun-En Ding",
        "Feng Liu",
        "Fang-Ming Hung"
      ],
      "abstract": "Traditional diagnosis of chronic diseases involves in-person consultations\nwith physicians to identify the disease. However, there is a lack of research\nfocused on predicting and developing application systems using clinical notes\nand blood test values. We collected five years of Electronic Health Records\n(EHRs) from Taiwan's hospital database between 2017 and 2021 as an AI database.\nFurthermore, we developed an EHR-based chronic disease prediction platform\nutilizing Large Language Multimodal Models (LLMMs), successfully integrating\nwith frontend web and mobile applications for prediction. This prediction\nplatform can also connect to the hospital's backend database, providing\nphysicians with real-time risk assessment diagnostics. The demonstration link\ncan be found at https://www.youtube.com/watch?v=oqmL9DEDFgA.",
      "tldr_zh": "这篇论文提出了一种基于EHR（Electronic Health Records）的移动和网络平台，利用Large Language Multimodal Models (LLMMs)来预测慢性疾病风险，旨在解决传统面对面诊断的局限性。研究团队收集了台湾医院2017-2021年的EHR数据，包括临床笔记和血液测试值，作为AI数据库，并成功开发了该平台，支持前端网页和移动应用的集成。平台可连接医院后端数据库，提供实时风险评估诊断，提升了慢性疾病预测的便利性和效率。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18087v1",
      "published_date": "2024-06-26 05:51:08 UTC",
      "updated_date": "2024-06-26 05:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:03:45.658856"
    },
    {
      "arxiv_id": "2406.19417v1",
      "title": "\"Glue pizza and eat rocks\" -- Exploiting Vulnerabilities in Retrieval-Augmented Generative Models",
      "title_zh": "\"Glue pizza and eat rocks\" -- 利用检索增强生成模型中的漏洞",
      "authors": [
        "Zhen Tan",
        "Chengshuai Zhao",
        "Raha Moraffah",
        "Yifan Li",
        "Song Wang",
        "Jundong Li",
        "Tianlong Chen",
        "Huan Liu"
      ],
      "abstract": "Retrieval-Augmented Generative (RAG) models enhance Large Language Models\n(LLMs) by integrating external knowledge bases, improving their performance in\napplications like fact-checking and information searching. In this paper, we\ndemonstrate a security threat where adversaries can exploit the openness of\nthese knowledge bases by injecting deceptive content into the retrieval\ndatabase, intentionally changing the model's behavior. This threat is critical\nas it mirrors real-world usage scenarios where RAG systems interact with\npublicly accessible knowledge bases, such as web scrapings and user-contributed\ndata pools. To be more realistic, we target a realistic setting where the\nadversary has no knowledge of users' queries, knowledge base data, and the LLM\nparameters. We demonstrate that it is possible to exploit the model\nsuccessfully through crafted content uploads with access to the retriever. Our\nfindings emphasize an urgent need for security measures in the design and\ndeployment of RAG systems to prevent potential manipulation and ensure the\nintegrity of machine-generated content.",
      "tldr_zh": "本论文探讨了 Retrieval-Augmented Generative (RAG) 模型的安全漏洞，攻击者可以通过向外部知识库注入欺骗性内容来操纵模型的行为，从而改变其输出结果。在现实设置下，攻击者无需了解用户的查询、知识库数据或 Large Language Models (LLMs) 参数，仅需通过对检索器的访问和精心设计的内容上传，即可成功实施攻击。研究发现此威胁在实际应用中非常严重，并呼吁在 RAG 系统设计和部署中紧急采用安全措施，以维护生成内容的完整性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2406.19417v1",
      "published_date": "2024-06-26 05:36:23 UTC",
      "updated_date": "2024-06-26 05:36:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:03:58.692880"
    },
    {
      "arxiv_id": "2406.18078v1",
      "title": "Self-Training with Pseudo-Label Scorer for Aspect Sentiment Quad Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yice Zhang",
        "Jie Zeng",
        "Weiming Hu",
        "Ziyi Wang",
        "Shiwei Chen",
        "Ruifeng Xu"
      ],
      "abstract": "Aspect Sentiment Quad Prediction (ASQP) aims to predict all quads (aspect\nterm, aspect category, opinion term, sentiment polarity) for a given review,\nwhich is the most representative and challenging task in aspect-based sentiment\nanalysis. A key challenge in the ASQP task is the scarcity of labeled data,\nwhich limits the performance of existing methods. To tackle this issue, we\npropose a self-training framework with a pseudo-label scorer, wherein a scorer\nassesses the match between reviews and their pseudo-labels, aiming to filter\nout mismatches and thereby enhance the effectiveness of self-training. We\nhighlight two critical aspects to ensure the scorer's effectiveness and\nreliability: the quality of the training dataset and its model architecture. To\nthis end, we create a human-annotated comparison dataset and train a generative\nmodel on it using ranking-based objectives. Extensive experiments on public\nASQP datasets reveal that using our scorer can greatly and consistently improve\nthe effectiveness of self-training. Moreover, we explore the possibility of\nreplacing humans with large language models for comparison dataset annotation,\nand experiments demonstrate its feasibility. We release our code and data at\nhttps://github.com/HITSZ-HLT/ST-w-Scorer-ABSA .",
      "tldr_zh": "该论文针对Aspect Sentiment Quad Prediction (ASQP)任务，提出了一种自训练框架，使用pseudo-label scorer来评估评论与伪标签的匹配度，从而过滤不匹配的伪标签并提升自训练的有效性。研究者强调了训练数据集质量和模型架构的重要性，通过创建人工标注的比较数据集并采用基于排名的目标训练生成模型，确保了scorer的可靠性能。实验在公共ASQP数据集上显示，使用该scorer后，自训练框架的性能得到显著和一致的改善。此外，论文探索了使用large language models代替人类进行数据集标注的可行性，并通过实验验证了其潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2406.18078v1",
      "published_date": "2024-06-26 05:30:21 UTC",
      "updated_date": "2024-06-26 05:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:04:10.498278"
    },
    {
      "arxiv_id": "2406.18074v1",
      "title": "Few-Shot Medical Image Segmentation with High-Fidelity Prototypes",
      "title_zh": "翻译失败",
      "authors": [
        "Song Tang",
        "Shaxu Yan",
        "Xiaozhi Qi",
        "Jianxin Gao",
        "Mao Ye",
        "Jianwei Zhang",
        "Xiatian Zhu"
      ],
      "abstract": "Few-shot Semantic Segmentation (FSS) aims to adapt a pretrained model to new\nclasses with as few as a single labelled training sample per class. Despite the\nprototype based approaches have achieved substantial success, existing models\nare limited to the imaging scenarios with considerably distinct objects and not\nhighly complex background, e.g., natural images. This makes such models\nsuboptimal for medical imaging with both conditions invalid. To address this\nproblem, we propose a novel Detail Self-refined Prototype Network (DSPNet) to\nconstructing high-fidelity prototypes representing the object foreground and\nthe background more comprehensively. Specifically, to construct global\nsemantics while maintaining the captured detail semantics, we learn the\nforeground prototypes by modelling the multi-modal structures with clustering\nand then fusing each in a channel-wise manner. Considering that the background\noften has no apparent semantic relation in the spatial dimensions, we integrate\nchannel-specific structural information under sparse channel-aware regulation.\nExtensive experiments on three challenging medical image benchmarks show the\nsuperiority of DSPNet over previous state-of-the-art methods.",
      "tldr_zh": "该论文针对Few-Shot Semantic Segmentation (FSS)在医疗图像中的挑战，提出了一种新型Detail Self-refined Prototype Network (DSPNet)，通过构建高保真原型来更全面地表示对象前景和复杂背景。DSPNet的具体方法包括对前景原型进行多模态结构建模（如聚类和通道-wise融合），以捕捉全局和细节语义，同时对背景原型采用稀疏通道感知调节，整合通道特定结构信息以处理空间维度上的无明显语义关系。实验在三个医疗图像基准上证明，DSPNet 优于现有最先进方法，展示了其在少样本场景下的显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18074v1",
      "published_date": "2024-06-26 05:06:14 UTC",
      "updated_date": "2024-06-26 05:06:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:04:21.111576"
    },
    {
      "arxiv_id": "2407.07111v1",
      "title": "Diffusion Model-Based Video Editing: A Survey",
      "title_zh": "基于扩散模型的视频编辑：综述",
      "authors": [
        "Wenhao Sun",
        "Rong-Cheng Tu",
        "Jingyi Liao",
        "Dacheng Tao"
      ],
      "abstract": "The rapid development of diffusion models (DMs) has significantly advanced\nimage and video applications, making \"what you want is what you see\" a reality.\nAmong these, video editing has gained substantial attention and seen a swift\nrise in research activity, necessitating a comprehensive and systematic review\nof the existing literature. This paper reviews diffusion model-based video\nediting techniques, including theoretical foundations and practical\napplications. We begin by overviewing the mathematical formulation and image\ndomain's key methods. Subsequently, we categorize video editing approaches by\nthe inherent connections of their core technologies, depicting evolutionary\ntrajectory. This paper also dives into novel applications, including\npoint-based editing and pose-guided human video editing. Additionally, we\npresent a comprehensive comparison using our newly introduced V2VBench.\nBuilding on the progress achieved to date, the paper concludes with ongoing\nchallenges and potential directions for future research.",
      "tldr_zh": "本论文对基于Diffusion Models (DMs)的视频编辑技术进行系统回顾，涵盖了其理论基础、数学公式以及从图像领域到视频领域的关键方法。作者根据核心技术的内在联系对视频编辑方法进行了分类，并探讨了新颖应用，如点-based editing和pose-guided human video editing，同时引入了新的基准V2VBench进行全面比较。最终，该研究总结了当前面临的挑战，包括模型泛化性和效率问题，并指出了未来研究的方向，如增强视频编辑的实时性和多样性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 12 figures, a project related to this paper can be found at\n  https://github.com/wenhao728/awesome-diffusion-v2v",
      "pdf_url": "http://arxiv.org/pdf/2407.07111v1",
      "published_date": "2024-06-26 04:58:39 UTC",
      "updated_date": "2024-06-26 04:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:04:32.768992"
    },
    {
      "arxiv_id": "2406.18069v3",
      "title": "Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals",
      "title_zh": "翻译失败",
      "authors": [
        "Zengding Liu",
        "Chen Chen",
        "Jiannong Cao",
        "Minglei Pan",
        "Jikui Liu",
        "Nan Li",
        "Fen Miao",
        "Ye Li"
      ],
      "abstract": "Large language models (LLMs) have captured significant interest from both\nacademia and industry due to their impressive performance across various\ntextual tasks. However, the potential of LLMs to analyze physiological\ntime-series data remains an emerging research field. Particularly, there is a\nnotable gap in the utilization of LLMs for analyzing wearable biosignals to\nachieve cuffless blood pressure (BP) measurement, which is critical for the\nmanagement of cardiovascular diseases. This paper presents the first work to\nexplore the capacity of LLMs to perform cuffless BP estimation based on\nwearable biosignals. We extracted physiological features from electrocardiogram\n(ECG) and photoplethysmogram (PPG) signals and designed context-enhanced\nprompts by combining these features with BP domain knowledge and user\ninformation. Subsequently, we adapted LLMs to BP estimation tasks through\nfine-tuning. To evaluate the proposed approach, we conducted assessments of ten\nadvanced LLMs using a comprehensive public dataset of wearable biosignals from\n1,272 participants. The experimental results demonstrate that the optimally\nfine-tuned LLM significantly surpasses conventional task-specific baselines,\nachieving an estimation error of 0.00 $\\pm$ 9.25 mmHg for systolic BP and 1.29\n$\\pm$ 6.37 mmHg for diastolic BP. Notably, the ablation studies highlight the\nbenefits of our context enhancement strategy, leading to an 8.9% reduction in\nmean absolute error for systolic BP estimation. This paper pioneers the\nexploration of LLMs for cuffless BP measurement, providing a potential solution\nto enhance the accuracy of cuffless BP measurement.",
      "tldr_zh": "本研究首次探讨大型语言模型 (LLMs) 在基于可穿戴生物信号的无袖带血压 (BP) 测量中的潜力，旨在解决心血管疾病管理中的关键需求。研究团队从心电图 (ECG) 和光体积描记图 (PPG) 信号中提取生理特征，并设计上下文增强提示，将这些特征与 BP 领域知识和用户信息结合，通过 fine-tuning 方法适应 LLMs 进行 BP 估计。实验结果显示，最优 fine-tuned LLM 超过了传统基线模型，收缩压估计误差为 0.00 ± 9.25 mmHg、舒张压为 1.29 ± 6.37 mmHg，且上下文增强策略使收缩压平均绝对误差降低了 8.9%。这项工作开创了 LLMs 在无袖带 BP 测量领域的应用，提供了一种提升准确性的潜在解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18069v3",
      "published_date": "2024-06-26 04:54:45 UTC",
      "updated_date": "2024-07-05 01:25:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:04:46.267628"
    },
    {
      "arxiv_id": "2406.18062v1",
      "title": "Breaking the Barrier: Enhanced Utility and Robustness in Smoothed DRL Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Chung-En Sun",
        "Sicun Gao",
        "Tsui-Wei Weng"
      ],
      "abstract": "Robustness remains a paramount concern in deep reinforcement learning (DRL),\nwith randomized smoothing emerging as a key technique for enhancing this\nattribute. However, a notable gap exists in the performance of current smoothed\nDRL agents, often characterized by significantly low clean rewards and weak\nrobustness. In response to this challenge, our study introduces innovative\nalgorithms aimed at training effective smoothed robust DRL agents. We propose\nS-DQN and S-PPO, novel approaches that demonstrate remarkable improvements in\nclean rewards, empirical robustness, and robustness guarantee across standard\nRL benchmarks. Notably, our S-DQN and S-PPO agents not only significantly\noutperform existing smoothed agents by an average factor of $2.16\\times$ under\nthe strongest attack, but also surpass previous robustly-trained agents by an\naverage factor of $2.13\\times$. This represents a significant leap forward in\nthe field. Furthermore, we introduce Smoothed Attack, which is $1.89\\times$\nmore effective in decreasing the rewards of smoothed agents than existing\nadversarial attacks.",
      "tldr_zh": "本研究针对深度强化学习 (DRL) 中的鲁棒性问题，指出现有随机平滑 (randomized smoothing) 代理存在低清洁奖励 (clean rewards) 和弱鲁棒性的缺陷，并提出创新算法 S-DQN 和 S-PPO，以显著提升代理的清洁奖励、经验鲁棒性和鲁棒性保证。实验结果显示，在标准 RL 基准上，S-DQN 和 S-PPO 在最强攻击下比现有平滑代理提高 2.16 倍，比之前鲁棒训练代理提高 2.13 倍，标志着领域的重大进步。此外，研究引入了 Smoothed Attack，这种新攻击比现有对抗攻击更有效，能将平滑代理的奖励降低 1.89 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18062v1",
      "published_date": "2024-06-26 04:49:03 UTC",
      "updated_date": "2024-06-26 04:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:04:57.751604"
    },
    {
      "arxiv_id": "2406.18060v3",
      "title": "AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Yang",
        "Kai Zhen",
        "Ershad Banijamal",
        "Athanasios Mouchtaris",
        "Zheng Zhang"
      ],
      "abstract": "Fine-tuning large language models (LLMs) has achieved remarkable performance\nacross various natural language processing tasks, yet it demands more and more\nmemory as model sizes keep growing. To address this issue, the recently\nproposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs\nusing only forward passes, thereby avoiding the need for a backpropagation\ngraph. However, significant performance drops and a high risk of divergence\nhave limited their widespread adoption. In this paper, we propose the Adaptive\nZeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed\nto improve the performance and convergence of the ZO methods. To enhance\ndimension-dependent ZO estimation accuracy, we introduce a fast-forward,\nlow-parameter tensorized adapter. To tackle the frequently observed divergence\nissue in large-scale ZO fine-tuning tasks, we propose an adaptive query number\nschedule that guarantees convergence. Detailed theoretical analysis and\nextensive experimental results on Roberta-Large and Llama-2-7B models\nsubstantiate the efficacy of our AdaZeta framework in terms of accuracy, memory\nefficiency, and convergence speed.",
      "tldr_zh": "这篇论文提出了 AdaZeta 框架，用于实现内存高效的 Large Language Models (LLMs) 微调，旨在解决现有 Memory-efficient Zeroth-Order (MeZO) 方法的性能下降和发散风险问题。AdaZeta 通过引入 fast-forward, low-parameter tensorized adapter 来提升 Zeroth-Order (ZO) 估计的准确性，并采用 adaptive query number schedule 来保证收敛。实验结果显示，该框架在 Roberta-Large 和 Llama-2-7B 模型上显著提高了准确性、内存效率和收敛速度，为大规模 LLMs 微调提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18060v3",
      "published_date": "2024-06-26 04:33:13 UTC",
      "updated_date": "2024-12-02 19:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:05:11.151817"
    },
    {
      "arxiv_id": "2406.18616v1",
      "title": "Towards Large Language Model Aided Program Refinement",
      "title_zh": "迈向大语言模型辅助的程序精炼",
      "authors": [
        "Yufan Cai",
        "Zhe Hou",
        "Xiaokun Luan",
        "David Miguel Sanan Baena",
        "Yun Lin",
        "Jun Sun",
        "Jin Song Dong"
      ],
      "abstract": "Program refinement involves correctness-preserving transformations from\nformal high-level specification statements into executable programs.\nTraditional verification tool support for program refinement is highly\ninteractive and lacks automation. On the other hand, the emergence of large\nlanguage models (LLMs) enables automatic code generations from informal natural\nlanguage specifications. However, code generated by LLMs is often unreliable.\nMoreover, the opaque procedure from specification to code provided by LLM is an\nuncontrolled black box. We propose LLM4PR, a tool that combines formal program\nrefinement techniques with informal LLM-based methods to (1) transform the\nspecification to preconditions and postconditions, (2) automatically build\nprompts based on refinement calculus, (3) interact with LLM to generate code,\nand finally, (4) verify that the generated code satisfies the conditions of\nrefinement calculus, thus guaranteeing the correctness of the code. We have\nimplemented our tool using GPT4, Coq, and Coqhammer, and evaluated it on the\nHumanEval and EvalPlus datasets.",
      "tldr_zh": "本研究针对程序精炼（program refinement）的传统方法过于交互式且自动化不足的问题，提出LLM4PR工具，将大型语言模型（LLMs）与正式精炼技术结合，以从非正式自然语言规范生成可靠代码。LLM4PR的流程包括：将规范转换为前置条件和后置条件、基于精炼演算（refinement calculus）自动构建提示、与LLM（如GPT4）交互生成代码，并通过验证确保代码正确性，从而解决LLMs生成代码不可靠的黑箱问题。该工具已使用GPT4、Coq和Coqhammer实现，并在HumanEval和EvalPlus数据集上进行了评估，展示了其在提升程序精炼自动化和正确性方面的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "K.6.3"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18616v1",
      "published_date": "2024-06-26 04:29:27 UTC",
      "updated_date": "2024-06-26 04:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:05:22.843888"
    },
    {
      "arxiv_id": "2406.18053v1",
      "title": "Bidirectional-Reachable Hierarchical Reinforcement Learning with Mutually Responsive Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Luo",
        "Fuchun Sun",
        "Tianying Ji",
        "Xianyuan Zhan"
      ],
      "abstract": "Hierarchical reinforcement learning (HRL) addresses complex long-horizon\ntasks by skillfully decomposing them into subgoals. Therefore, the\neffectiveness of HRL is greatly influenced by subgoal reachability. Typical HRL\nmethods only consider subgoal reachability from the unilateral level, where a\ndominant level enforces compliance to the subordinate level. However, we\nobserve that when the dominant level becomes trapped in local exploration or\ngenerates unattainable subgoals, the subordinate level is negatively affected\nand cannot follow the dominant level's actions. This can potentially make both\nlevels stuck in local optima, ultimately hindering subsequent subgoal\nreachability. Allowing real-time bilateral information sharing and error\ncorrection would be a natural cure for this issue, which motivates us to\npropose a mutual response mechanism. Based on this, we propose the\nBidirectional-reachable Hierarchical Policy Optimization (BrHPO)--a simple yet\neffective algorithm that also enjoys computation efficiency. Experiment results\non a variety of long-horizon tasks showcase that BrHPO outperforms other\nstate-of-the-art HRL baselines, coupled with a significantly higher exploration\nefficiency and robustness.",
      "tldr_zh": "该论文针对层次强化学习(HRL)中子目标可达性的问题，指出传统方法仅考虑单向可达性会导致上级和下级策略陷入局部最优。作者提出互惠响应机制，实现双向信息共享和错误修正，并基于此开发了Bidirectional-reachable Hierarchical Policy Optimization (BrHPO)算法，该算法简单高效。实验结果显示，BrHPO在各种长时序任务上优于现有HRL基线，显著提升了探索效率和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18053v1",
      "published_date": "2024-06-26 04:05:04 UTC",
      "updated_date": "2024-06-26 04:05:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:05:34.079071"
    },
    {
      "arxiv_id": "2406.18049v1",
      "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
      "title_zh": "使用深度学习和微调大型语言模型集成改进实体识别：从多个来源提取不良事件的案例研究",
      "authors": [
        "Yiming Li",
        "Deepthi Viswaroopan",
        "William He",
        "Jianfu Li",
        "Xu Zuo",
        "Hua Xu",
        "Cui Tao"
      ],
      "abstract": "Adverse event (AE) extraction following COVID-19 vaccines from text data is\ncrucial for monitoring and analyzing the safety profiles of immunizations.\nTraditional deep learning models are adept at learning intricate feature\nrepresentations and dependencies in sequential data, but often require\nextensive labeled data. In contrast, large language models (LLMs) excel in\nunderstanding contextual information, but exhibit unstable performance on named\nentity recognition tasks, possibly due to their broad but unspecific training.\nThis study aims to evaluate the effectiveness of LLMs and traditional deep\nlearning models in AE extraction, and to assess the impact of ensembling these\nmodels on performance. In this study, we utilized reports and posts from the\nVAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal\nwas to extract three types of entities: \"vaccine\", \"shot\", and \"ae\". We\nexplored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,\nGPT-4, and Llama-2, as well as traditional deep learning models like RNN and\nBioBERT. To enhance performance, we created ensembles of the three models with\nthe best performance. For evaluation, we used strict and relaxed F1 scores to\nevaluate the performance for each entity type, and micro-average F1 was used to\nassess the overall performance. The ensemble model achieved the highest\nperformance in \"vaccine\", \"shot\", and \"ae\" with strict F1-scores of 0.878,\n0.930, and 0.925, respectively, along with a micro-average score of 0.903. In\nconclusion, this study demonstrates the effectiveness and robustness of\nensembling fine-tuned traditional deep learning models and LLMs, for extracting\nAE-related information. This study contributes to the advancement of biomedical\nnatural language processing, providing valuable insights into improving AE\nextraction from text data for pharmacovigilance and public health surveillance.",
      "tldr_zh": "本研究针对COVID-19疫苗的不良事件(AE)提取问题，比较了传统深度学习模型（如RNN和BioBERT）和微调的大型语言模型(LLMs，如GPT-2、GPT-3.5和Llama-2)的性能，旨在通过模型集成提升实体识别准确性。研究使用VAERS、Twitter和Reddit的数据集，提取\"vaccine\"、\"shot\"和\"ae\"实体，并将表现最佳的三个模型进行集成。结果显示，集成模型的严格F1分数分别达到0.878（vaccine）、0.930（shot）和0.925（ae），整体微平均F1为0.903。该方法证明了集成策略的有效性，为生物医学自然语言处理提供了重要见解，支持药物警戒和公共健康监控。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18049v1",
      "published_date": "2024-06-26 03:56:21 UTC",
      "updated_date": "2024-06-26 03:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:05:48.118914"
    },
    {
      "arxiv_id": "2406.18045v3",
      "title": "PharmaGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical and Chemistry",
      "title_zh": "PharmaGPT：面向生物制药和化学的特定领域大型语言模型",
      "authors": [
        "Linqing Chen",
        "Weilei Wang",
        "Zilong Bai",
        "Peng Xu",
        "Yan Fang",
        "Jie Fang",
        "Wentao Wu",
        "Lizhi Zhou",
        "Ruiji Zhang",
        "Yubin Xia",
        "Chaobo Xu",
        "Ran Hu",
        "Licong Xu",
        "Qijun Cai",
        "Haoran Hua",
        "Jing Sun",
        "Jin Liu",
        "Tian Qiu",
        "Haowen Liu",
        "Meng Hu",
        "Xiuwen Li",
        "Fei Gao",
        "Yufu Wang",
        "Lin Tie",
        "Chaochao Wang",
        "Jianping Lu",
        "Cheng Sun",
        "Yixin Wang",
        "Shengjie Yang",
        "Yuancheng Li",
        "Lu Jin",
        "Lisha Zhang",
        "Fu Bian",
        "Zhongkai Ye",
        "Lidong Pei",
        "Changyang Tu"
      ],
      "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision\nareas where general purpose LLMs often fall short. In this study, we introduce\nPharmaGPT, a suite of domain specilized LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus tailored to the\nBio-Pharmaceutical and Chemical domains. Our evaluation shows that PharmaGPT\nsurpasses existing general models on specific-domain benchmarks such as NAPLEX,\ndemonstrating its exceptional capability in domain-specific tasks. Remarkably,\nthis performance is achieved with a model that has only a fraction, sometimes\njust one-tenth-of the parameters of general-purpose large models. This\nadvancement establishes a new benchmark for LLMs in the bio-pharmaceutical and\nchemical fields, addressing the existing gap in specialized language modeling.\nIt also suggests a promising path for enhanced research and development, paving\nthe way for more precise and effective NLP applications in these areas.",
      "tldr_zh": "本文介绍了 PharmaGPT，一套针对生物制药和化学领域的特定 Large Language Models (LLMs)，包括 13 亿和 70 亿参数的版本，这些模型使用量身定制的领域语料库进行训练，以应对这些领域的复杂术语和专业知识需求。评估结果显示，PharmaGPT 在特定基准测试如 NAPLEX 上超过了通用模型，即使其参数量仅为后者的几分之一，有时只需十分之一。PharmaGPT 的这一进展为生物制药和化学领域的 NLP 应用建立了新基准，并为更精确的研究和开发铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18045v3",
      "published_date": "2024-06-26 03:43:09 UTC",
      "updated_date": "2024-07-09 06:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:05:58.488716"
    },
    {
      "arxiv_id": "2406.18043v2",
      "title": "GenRL: Multimodal-foundation world models for generalization in embodied agents",
      "title_zh": "翻译失败",
      "authors": [
        "Pietro Mazzaglia",
        "Tim Verbelen",
        "Bart Dhoedt",
        "Aaron Courville",
        "Sai Rajeswar"
      ],
      "abstract": "Learning generalist embodied agents, able to solve multitudes of tasks in\ndifferent domains is a long-standing problem. Reinforcement learning (RL) is\nhard to scale up as it requires a complex reward design for each task. In\ncontrast, language can specify tasks in a more natural way. Current foundation\nvision-language models (VLMs) generally require fine-tuning or other\nadaptations to be adopted in embodied contexts, due to the significant domain\ngap. However, the lack of multimodal data in such domains represents an\nobstacle to developing foundation models for embodied applications. In this\nwork, we overcome these problems by presenting multimodal-foundation world\nmodels, able to connect and align the representation of foundation VLMs with\nthe latent space of generative world models for RL, without any language\nannotations. The resulting agent learning framework, GenRL, allows one to\nspecify tasks through vision and/or language prompts, ground them in the\nembodied domain's dynamics, and learn the corresponding behaviors in\nimagination. As assessed through large-scale multi-task benchmarking in\nlocomotion and manipulation domains, GenRL enables multi-task generalization\nfrom language and visual prompts. Furthermore, by introducing a data-free\npolicy learning strategy, our approach lays the groundwork for foundational\npolicy learning using generative world models. Website, code and data:\nhttps://mazpie.github.io/genrl/",
      "tldr_zh": "该论文提出GenRL框架，利用multimodal-foundation world models，将foundation vision-language models (VLMs)的表示与generative world models的潜在空间对齐，帮助embodied agents在无需语言标注的情况下实现多任务泛化。GenRL允许通过vision和/或language prompts指定任务，并在imagination中学习行为，从而克服强化学习 (RL) 的复杂奖励设计和领域差距问题。在locomotion和manipulation领域的多任务基准测试中，GenRL展示了出色的泛化能力，并引入data-free policy learning策略，为基于generative world models的foundational policy learning奠定基础。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18043v2",
      "published_date": "2024-06-26 03:41:48 UTC",
      "updated_date": "2024-10-30 20:16:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:06:12.268957"
    },
    {
      "arxiv_id": "2407.03361v1",
      "title": "PianoBART: Symbolic Piano Music Generation and Understanding with Large-Scale Pre-Training",
      "title_zh": "PianoBART：基于大规模预训练的符号化钢琴音乐生成与理解",
      "authors": [
        "Xiao Liang",
        "Zijian Zhao",
        "Weichao Zeng",
        "Yutong He",
        "Fupeng He",
        "Yiyi Wang",
        "Chengying Gao"
      ],
      "abstract": "Learning musical structures and composition patterns is necessary for both\nmusic generation and understanding, but current methods do not make uniform use\nof learned features to generate and comprehend music simultaneously. In this\npaper, we propose PianoBART, a pre-trained model that uses BART for both\nsymbolic piano music generation and understanding. We devise a multi-level\nobject selection strategy for different pre-training tasks of PianoBART, which\ncan prevent information leakage or loss and enhance learning ability. The\nmusical semantics captured in pre-training are fine-tuned for music generation\nand understanding tasks. Experiments demonstrate that PianoBART efficiently\nlearns musical patterns and achieves outstanding performance in generating\nhigh-quality coherent pieces and comprehending music. Our code and\nsupplementary material are available at https://github.com/RS2002/PianoBart.",
      "tldr_zh": "该论文提出PianoBART，一种基于BART架构的预训练模型，用于同时实现符号钢琴音乐的生成和理解，从而统一处理音乐结构和作曲模式的学习。模型采用多级对象选择策略来优化预训练任务，防止信息泄漏或损失，并通过捕获音乐语义进行细调以适应生成和理解任务。实验结果显示，PianoBART高效学习音乐模式，在生成高质量连贯音乐片段和理解音乐方面表现出色，并提供了开源代码以供进一步研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.03361v1",
      "published_date": "2024-06-26 03:35:54 UTC",
      "updated_date": "2024-06-26 03:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:06:21.564957"
    },
    {
      "arxiv_id": "2406.18033v1",
      "title": "Boosting Soft Q-Learning by Bounding",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob Adamczyk",
        "Volodymyr Makarenko",
        "Stas Tiomkin",
        "Rahul V. Kulkarni"
      ],
      "abstract": "An agent's ability to leverage past experience is critical for efficiently\nsolving new tasks. Prior work has focused on using value function estimates to\nobtain zero-shot approximations for solutions to a new task. In soft\nQ-learning, we show how any value function estimate can also be used to derive\ndouble-sided bounds on the optimal value function. The derived bounds lead to\nnew approaches for boosting training performance which we validate\nexperimentally. Notably, we find that the proposed framework suggests an\nalternative method for updating the Q-function, leading to boosted performance.",
      "tldr_zh": "本论文探讨了如何通过价值函数估计提升Soft Q-Learning的训练性能，特别针对新任务的零射逼近问题。作者展示了任何价值函数估计都可以用于派生最优价值函数的双侧边界，从而提出新的训练方法，包括一种备选的Q-function更新策略。实验结果验证了该框架的有效性，导致了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in the 1st Reinforcement Learning Conference",
      "pdf_url": "http://arxiv.org/pdf/2406.18033v1",
      "published_date": "2024-06-26 03:02:22 UTC",
      "updated_date": "2024-06-26 03:02:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:06:32.902998"
    },
    {
      "arxiv_id": "2406.18027v2",
      "title": "Automated Clinical Data Extraction with Knowledge Conditioned LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Diya Li",
        "Asim Kadav",
        "Aijing Gao",
        "Rui Li",
        "Richard Bourgon"
      ],
      "abstract": "The extraction of lung lesion information from clinical and medical imaging\nreports is crucial for research on and clinical care of lung-related diseases.\nLarge language models (LLMs) can be effective at interpreting unstructured text\nin reports, but they often hallucinate due to a lack of domain-specific\nknowledge, leading to reduced accuracy and posing challenges for use in\nclinical settings. To address this, we propose a novel framework that aligns\ngenerated internal knowledge with external knowledge through in-context\nlearning (ICL). Our framework employs a retriever to identify relevant units of\ninternal or external knowledge and a grader to evaluate the truthfulness and\nhelpfulness of the retrieved internal-knowledge rules, to align and update the\nknowledge bases. Experiments with expert-curated test datasets demonstrate that\nthis ICL approach can increase the F1 score for key fields (lesion size, margin\nand solidity) by an average of 12.9% over existing ICL methods.",
      "tldr_zh": "这篇论文提出了一种基于知识条件化的LLMs框架，用于自动从临床和医学影像报告中提取肺部病变信息，以解决LLMs因缺乏领域特定知识而产生的幻觉问题。框架通过in-context learning (ICL)将生成的内部知识与外部知识对齐，采用retriever识别相关知识单位，并使用grader评估检索知识的真实性和有用性，从而更新知识库。实验在专家策划的测试数据集上显示，该方法使关键字段（如病变大小、边缘和固体度）的F1 score平均提高了12.9%，比现有ICL方法更有效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING25 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2406.18027v2",
      "published_date": "2024-06-26 02:49:28 UTC",
      "updated_date": "2024-11-15 02:07:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:06:46.323914"
    },
    {
      "arxiv_id": "2406.18022v2",
      "title": "Automated Off-Policy Estimator Selection via Supervised Learning",
      "title_zh": "通过监督学习的自动离策略估计器选择",
      "authors": [
        "Nicolò Felicioni",
        "Michael Benigni",
        "Maurizio Ferrari Dacrema"
      ],
      "abstract": "The Off-Policy Evaluation (OPE) problem consists of evaluating the\nperformance of counterfactual policies with data collected by another one. To\nsolve the OPE problem, we resort to estimators, which aim to estimate in the\nmost accurate way possible the performance that the counterfactual policies\nwould have had if they were deployed in place of the logging policy. In the\nliterature, several estimators have been developed, all with different\ncharacteristics and theoretical guarantees. Therefore, there is no dominant\nestimator and each estimator may be the best for different OPE problems,\ndepending on the characteristics of the dataset at hand. Although the selection\nof the estimator is a crucial choice for an accurate OPE, this problem has been\nwidely overlooked in the literature. We propose an automated data-driven OPE\nestimator selection method based on supervised learning. In particular, the\ncore idea we propose in this paper is to create several synthetic OPE tasks and\nuse a machine learning model trained to predict the best estimator for those\nsynthetic tasks. We empirically show how our method is able to perform a better\nestimator selection compared to a baseline method on several real-world\ndatasets, with a computational cost significantly lower than the one of the\nbaseline.",
      "tldr_zh": "该论文解决了Off-Policy Evaluation (OPE)问题中估计器选择的难题，提出了一种基于Supervised Learning的自动数据驱动方法。核心思路是通过创建合成OPE任务并训练机器学习模型，来预测最适合的估计器。实验结果显示，该方法在多个真实数据集上比基线方法更准确地选择估计器，同时显著降低了计算成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18022v2",
      "published_date": "2024-06-26 02:34:48 UTC",
      "updated_date": "2024-11-09 19:06:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:06:57.362104"
    },
    {
      "arxiv_id": "2406.18020v1",
      "title": "MolFusion: Multimodal Fusion Learning for Molecular Representations via Multi-granularity Views",
      "title_zh": "翻译失败",
      "authors": [
        "Muzhen Cai",
        "Sendong Zhao",
        "Haochun Wang",
        "Yanrui Du",
        "Zewen Qiang",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "Artificial Intelligence predicts drug properties by encoding drug molecules,\naiding in the rapid screening of candidates. Different molecular\nrepresentations, such as SMILES and molecule graphs, contain complementary\ninformation for molecular encoding. Thus exploiting complementary information\nfrom different molecular representations is one of the research priorities in\nmolecular encoding. Most existing methods for combining molecular\nmulti-modalities only use molecular-level information, making it hard to encode\nintra-molecular alignment information between different modalities. To address\nthis issue, we propose a multi-granularity fusion method that is MolFusion. The\nproposed MolFusion consists of two key components: (1) MolSim, a\nmolecular-level encoding component that achieves molecular-level alignment\nbetween different molecular representations. and (2) AtomAlign, an atomic-level\nencoding component that achieves atomic-level alignment between different\nmolecular representations. Experimental results show that MolFusion effectively\nutilizes complementary multimodal information, leading to significant\nimprovements in performance across various classification and regression tasks.",
      "tldr_zh": "这篇论文提出 MolFusion，一种多粒度融合学习方法，用于通过不同视图（如 SMILES 和分子图）编码分子表示，以更好地预测药物特性并辅助快速筛选。MolFusion 包括两个关键组件：MolSim 负责分子级对齐，实现不同分子表示之间的整体信息整合；AtomAlign 则处理原子级对齐，捕捉分子内部的细粒度互补信息。实验结果显示，该方法有效利用多模态互补信息，在各种分子分类和回归任务中显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.18020v1",
      "published_date": "2024-06-26 02:26:50 UTC",
      "updated_date": "2024-06-26 02:26:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:07:10.193191"
    },
    {
      "arxiv_id": "2407.07110v2",
      "title": "Foundation Models for ECG: Leveraging Hybrid Self-Supervised Learning for Advanced Cardiac Diagnostics",
      "title_zh": "ECG 的基础模型：利用混合自监督学习实现先进的心脏诊断",
      "authors": [
        "Junho Song",
        "Jong-Hwan Jang",
        "Byeong Tak Lee",
        "DongGyun Hong",
        "Joon-myoung Kwon",
        "Yong-Yeon Jo"
      ],
      "abstract": "Using foundation models enhanced by self-supervised learning (SSL) methods\npresents an innovative approach to electrocardiogram (ECG) analysis, which is\ncrucial for cardiac health monitoring and diagnosis. This study comprehensively\nevaluates foundation models for ECGs, leveraging SSL methods, including\ngenerative and contrastive learning, on a vast dataset comprising approximately\n1.3 million ECG samples. By integrating these methods with consideration of the\nunique characteristics of ECGs, we developed a Hybrid Learning (HL) for\nfoundation models that improve the precision and reliability of cardiac\ndiagnostics. The HL-based foundation model adeptly captures the intricate\ndetails of ECGs, enhancing diagnostic capability. The results underscore the\nconsiderable potential of SSL-enhanced foundation models in clinical settings,\nsetting the stage for future research into their scalable applications across a\nbroader range of medical diagnostics. This work sets a new standard in the ECG\nfield, emphasizing the transformative influence of tailored, data-driven model\ntraining on the effectiveness and accuracy of medical diagnostics.",
      "tldr_zh": "该研究探讨了使用基础模型（foundation models）结合自监督学习（SSL）方法，包括生成式和对比学习，来提升心电图（ECG）分析的诊断能力。研究者基于约130万ECG样本的大规模数据集，开发了Hybrid Learning (HL) 框架，该框架考虑ECG的独特特性，提高了诊断的精确性和可靠性。结果显示，HL-based 基础模型能够有效捕捉ECG的复杂细节，并在临床应用中展现出巨大潜力，为更广泛的医疗诊断领域设定新标准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.07110v2",
      "published_date": "2024-06-26 02:24:13 UTC",
      "updated_date": "2024-10-15 09:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:07:21.473979"
    },
    {
      "arxiv_id": "2407.01598v1",
      "title": "Long-Term Prediction Accuracy Improvement of Data-Driven Medium-Range Global Weather Forecast",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Hu",
        "Fukang Yin",
        "Weimin Zhang",
        "Kaijun Ren",
        "Junqiang Song",
        "Kefeng Deng",
        "Di Zhang"
      ],
      "abstract": "Long-term stability stands as a crucial requirement in data-driven\nmedium-range global weather forecasting. Spectral bias is recognized as the\nprimary contributor to instabilities, as data-driven methods difficult to learn\nsmall-scale dynamics. In this paper, we reveal that the universal mechanism for\nthese instabilities is not only related to spectral bias but also to\ndistortions brought by processing spherical data using conventional\nconvolution. These distortions lead to a rapid amplification of errors over\nsuccessive long-term iterations, resulting in a significant decline in forecast\naccuracy. To address this issue, a universal neural operator called the\nSpherical Harmonic Neural Operator (SHNO) is introduced to improve long-term\niterative forecasts. SHNO uses the spherical harmonic basis to mitigate\ndistortions for spherical data and uses gated residual spectral attention\n(GRSA) to correct spectral bias caused by spurious correlations across\ndifferent scales. The effectiveness and merit of the proposed method have been\nvalidated through its application for spherical Shallow Water Equations (SWEs)\nand medium-range global weather forecasting. Our findings highlight the\nbenefits and potential of SHNO to improve the accuracy of long-term prediction.",
      "tldr_zh": "这篇论文揭示了数据驱动中期全球天气预报中长期不稳定的关键机制，不仅涉及spectral bias（导致难以学习小规模动态），还包括处理球形数据时传统卷积带来的扭曲，这些扭曲会放大错误并降低预测准确性。为解决此问题，作者提出了一种通用神经算子Spherical Harmonic Neural Operator (SHNO)，它利用spherical harmonic basis减轻球形数据扭曲，并通过gated residual spectral attention (GRSA)纠正不同尺度间的虚假相关。实验验证显示，SHNO在Spherical Shallow Water Equations (SWEs)和中期全球天气预报应用中显著提高了长期预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01598v1",
      "published_date": "2024-06-26 02:06:27 UTC",
      "updated_date": "2024-06-26 02:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:07:34.698781"
    },
    {
      "arxiv_id": "2406.18012v2",
      "title": "View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with Adaptive View Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Subin Varghese",
        "Vedhus Hoskere"
      ],
      "abstract": "Visual anomaly detection in the built environment is a valuable tool for\napplications such as infrastructure assessment, construction monitoring,\nsecurity surveillance, and urban planning. Anomaly detection approaches are\ntypically unsupervised and work by detecting deviations from an expected state\nwhere no assumptions are made exact type of deviation. Unsupervised pixel-level\nanomaly detection methods have been developed to successfully recognize and\nsegment anomalies; however, existing techniques are designed for industrial\nsettings with a fixed camera position. In the built environment, images are\nperiodically captured by a camera operated manually or mounted on aerial or\nground vehicles. The camera pose between successive collections may vary widely\nvoiding a fundamental assumption in existing anomaly detection approaches. To\naddress this gap, we introduce the problem of Scene Anomaly Detection (Scene\nAD), where the goal is to detect anomalies from two sets of images: one set\nwithout anomalies and one set that may or may not contain anomalies. No labeled\nsemantic segmentation data are provided for training. We propose a novel\nnetwork, OmniAD, to tackle Scene AD by refining the reverse distillation\nanomaly detection method, leading to a 40\\% improvement in pixel-level anomaly\ndetection. Additionally, we introduce two new data augmentation strategies that\nleverage novel view synthesis and camera localization to enhance\ngeneralization. We evaluate our approach both qualitatively and quantitatively\non a new dataset, ToyCity the first Scene AD dataset featuring multiple objects\nas well as on the established single object centric dataset, MAD. Our method\ndemonstrates marked improvement over baseline approaches, paving the way for\nrobust anomaly detection in scenes with real-world camera pose variations\ncommonly observed in the built environment. https://drags99.github.io/OmniAD/",
      "tldr_zh": "该研究针对建筑环境中相机位姿变化带来的挑战，引入了 Scene Anomaly Detection（Scene AD）问题，旨在实现 View-Invariant Pixelwise Anomaly Detection，以检测多对象场景中的异常。提出了一种新网络 OmniAD，通过改进 reverse distillation 方法并引入 novel view synthesis 和 camera localization 的数据增强策略，实现了像素级异常检测性能的 40% 提升。在新的 ToyCity 数据集（多对象）和 MAD 数据集（单对象）上，OmniAD 显著优于基线方法，为真实世界监控和规划应用提供了更鲁棒的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18012v2",
      "published_date": "2024-06-26 01:54:10 UTC",
      "updated_date": "2025-04-01 00:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:07:46.609571"
    },
    {
      "arxiv_id": "2406.18002v2",
      "title": "Decoding with Limited Teacher Supervision Requires Understanding When to Trust the Teacher",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunjong Ok",
        "Jegwang Ryu",
        "Jaeho Lee"
      ],
      "abstract": "How can small-scale large language models (LLMs) efficiently utilize the\nsupervision of LLMs to improve their generative quality? This question has been\nwell studied in scenarios where there is no restriction on the number of LLM\nsupervisions one can use, giving birth to many decoding algorithms that utilize\nsupervision without further training. However, it is still unclear what is an\neffective strategy under the $\\textit{limited supervision}$ scenario, where we\nassume that no more than a few tokens can be generated by LLMs. To this end, we\ndevelop an algorithm to effectively aggregate the small-scale LLM and LLM\npredictions on initial tokens so that the generated tokens can more accurately\ncondition the subsequent token generation by small-scale LLM only. Critically,\nwe find that it is essential to adaptively overtrust or disregard the LLM\nprediction based on the confidence of the small-scale LLM. Through our\nexperiments on a wide range of models and datasets, we demonstrate that our\nmethod provides a consistent improvement over conventional decoding strategies.\n$\\small$ $\\textbf{Code:}$ https://github.com/HJ-Ok/DecLimSup",
      "tldr_zh": "本研究探讨了小规模大语言模型 (LLMs) 在有限监督场景下如何有效利用大型 LLMs 的指导，以提升生成质量。作者提出了一种算法，通过聚合小规模 LLMs 和大型 LLMs 对初始 token 的预测，并根据小规模 LLMs 的置信度自适应地过度信任或忽略大型 LLMs 的输出，从而使后续 token 生成更准确。实验在多种模型和数据集上证明，该方法比传统解码策略提供了持续的改进性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 7 figures, EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.18002v2",
      "published_date": "2024-06-26 01:16:12 UTC",
      "updated_date": "2024-10-03 07:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:07:59.034112"
    },
    {
      "arxiv_id": "2406.17992v1",
      "title": "Catching Chameleons: Detecting Evolving Disinformation Generated using Large Language Models",
      "title_zh": "捕捉变色龙：检测使用大型语言模型生成的演变虚假信息",
      "authors": [
        "Bohan Jiang",
        "Chengshuai Zhao",
        "Zhen Tan",
        "Huan Liu"
      ],
      "abstract": "Despite recent advancements in detecting disinformation generated by large\nlanguage models (LLMs), current efforts overlook the ever-evolving nature of\nthis disinformation. In this work, we investigate a challenging yet practical\nresearch problem of detecting evolving LLM-generated disinformation.\nDisinformation evolves constantly through the rapid development of LLMs and\ntheir variants. As a consequence, the detection model faces significant\nchallenges. First, it is inefficient to train separate models for each\ndisinformation generator. Second, the performance decreases in scenarios when\nevolving LLM-generated disinformation is encountered in sequential order. To\naddress this problem, we propose DELD (Detecting Evolving LLM-generated\nDisinformation), a parameter-efficient approach that jointly leverages the\ngeneral fact-checking capabilities of pre-trained language models (PLM) and the\nindependent disinformation generation characteristics of various LLMs. In\nparticular, the learned characteristics are concatenated sequentially to\nfacilitate knowledge accumulation and transformation. DELD addresses the issue\nof label scarcity by integrating the semantic embeddings of disinformation with\ntrainable soft prompts to elicit model-specific knowledge. Our experiments show\nthat \\textit{DELD} significantly outperforms state-of-the-art methods.\nMoreover, our method provides critical insights into the unique patterns of\ndisinformation generation across different LLMs, offering valuable perspectives\nin this line of research.",
      "tldr_zh": "该研究探讨了检测由大型语言模型 (LLMs) 生成的不断演变的虚假信息问题，强调了现有方法在处理快速演化 disinformation 时存在的效率和性能挑战。论文提出 DELD（Detecting Evolving LLM-generated Disinformation）方法，该框架参数高效地整合预训练语言模型 (PLM) 的通用事实检查能力与各种 LLMs 的独立生成特征，通过顺序连接语义嵌入和可训练软提示来实现知识积累和解决标签稀缺问题。实验结果表明，DELD 显著优于现有 state-of-the-art 方法，并揭示了不同 LLMs 在虚假信息生成中的独特模式，提供宝贵的研究洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.17992v1",
      "published_date": "2024-06-26 00:21:39 UTC",
      "updated_date": "2024-06-26 00:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:08:11.135830"
    },
    {
      "arxiv_id": "2406.17990v1",
      "title": "Explicit Diversity Conditions for Effective Question Answer Generation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vikas Yadav",
        "Hyuk Joon Kwon",
        "Vijay Srinivasan",
        "Hongxia Jin"
      ],
      "abstract": "Question Answer Generation (QAG) is an effective data augmentation technique\nto improve the accuracy of question answering systems, especially in\nlow-resource domains. While recent pretrained and large language model-based\nQAG methods have made substantial progress, they face the critical issue of\nredundant QA pair generation, affecting downstream QA systems. Implicit\ndiversity techniques such as sampling and diverse beam search are proven\neffective solutions but often yield smaller diversity. We present explicit\ndiversity conditions for QAG, focusing on spatial aspects, question types, and\nentities, substantially increasing diversity in QA generation. Our work\nemphasizes the need of explicit diversity conditions for generating diverse\nquestion-answer synthetic data by showing significant improvements in\ndownstream QA task over existing widely adopted implicit diversity techniques.\nIn particular, generated QA pairs from explicit diversity conditions when used\nto train the downstream QA model results in an average 4.1% exact match and\n4.5% F1 improvement over QAG from implicit sampling techniques on SQuADDU. Our\nwork emphasizes the need for explicit diversity conditions even more in\nlow-resource datasets (SubjQA), where average downstream QA performance\nimprovements are around 12% EM.",
      "tldr_zh": "这篇论文针对 Question Answer Generation (QAG) 的冗余问题，提出使用显式多样性条件来提升基于 Large Language Models 的 QA 生成多样性，这些条件聚焦于 spatial aspects、question types 和 entities。相比传统的隐式多样性技术（如采样和多样性 beam search），显式方法显著改善了下游 QA 任务的性能，在 SQuADDU 数据集上实现了 4.1% exact match 和 4.5% F1 分数的平均提升。特别是在低资源数据集 SubjQA 上，该方法带来了约 12% EM 的性能改善，强调了显式多样性条件在生成合成数据方面的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.17990v1",
      "published_date": "2024-06-26 00:12:08 UTC",
      "updated_date": "2024-06-26 00:12:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:08:23.369846"
    },
    {
      "arxiv_id": "2406.17987v4",
      "title": "Multi-step Inference over Unstructured Data",
      "title_zh": "针对非结构化数据的多步推理",
      "authors": [
        "Aditya Kalyanpur",
        "Kailash Karthik Saravanakumar",
        "Victor Barres",
        "CJ McFate",
        "Lori Moon",
        "Nati Seifu",
        "Maksim Eremeev",
        "Jose Barrera",
        "Abraham Bautista-Castillo",
        "Eric Brown",
        "David Ferrucci"
      ],
      "abstract": "The advent of Large Language Models (LLMs) and Generative AI has\nrevolutionized natural language applications across various domains. However,\nhigh-stakes decision-making tasks in fields such as medical, legal and finance\nrequire a level of precision, comprehensiveness, and logical consistency that\npure LLM or Retrieval-Augmented-Generation (RAG) approaches often fail to\ndeliver. At Elemental Cognition (EC), we have developed a neuro-symbolic AI\nplatform to tackle these problems. The platform integrates fine-tuned LLMs for\nknowledge extraction and alignment with a robust symbolic reasoning engine for\nlogical inference, planning and interactive constraint solving. We describe\nCora, a Collaborative Research Assistant built on this platform, that is\ndesigned to perform complex research and discovery tasks in high-stakes\ndomains. This paper discusses the multi-step inference challenges inherent in\nsuch domains, critiques the limitations of existing LLM-based methods, and\ndemonstrates how Cora's neuro-symbolic approach effectively addresses these\nissues. We provide an overview of the system architecture, key algorithms for\nknowledge extraction and formal reasoning, and present preliminary evaluation\nresults that highlight Cora's superior performance compared to well-known LLM\nand RAG baselines.",
      "tldr_zh": "该论文讨论了大型语言模型（LLMs）和生成式 AI 在高风险领域（如医疗、法律和金融）中的局限性，包括缺乏精确性、全面性和逻辑一致性。作者介绍了 Elemental Cognition (EC) 的神经符号 AI 平台，该平台结合微调的 LLMs 用于知识提取和对齐，以及一个符号推理引擎来处理逻辑推理、规划和交互约束求解。基于此平台，他们开发了 Cora，这是一个协作研究助手，旨在执行复杂的研究和发现任务。初步评估结果显示，Cora 在多步推理任务上比现有的 LLM 和 Retrieval-Augmented-Generation (RAG) 基线表现出色，提供了一种更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.17987v4",
      "published_date": "2024-06-26 00:00:45 UTC",
      "updated_date": "2024-07-24 18:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T01:08:35.735132"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 108,
  "processed_papers_count": 108,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T01:09:01.142860"
}