{
  "date": "2024-10-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-01 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI、机器学习和医疗领域，涵盖了大型语言模型（LLM）的优化、医疗诊断的解释性方法、交通预测的鲁棒性，以及机器人导航等话题。重点包括 nGPT 的高效训练机制和 softmax 机制的理论分析，令人印象深刻的文章有 Ilya Loshchilov 参与的 nGPT 论文，以及 Petar Veličković 的注意力机制研究，这些工作展示了知名学者在深度学习领域的创新。\n\n下面，我将挑选并简要讨论几篇重要的、话题度高的论文，先从 AI 和 LLM 相关的内容入手，然后涉及医疗和机器人领域。对于其他较无聊或次要的论文（如游戏 AI 或特定领域小实验），我将快速掠过，只列出标题和核心要点，以控制篇幅。\n\n### AI 和 LLM 优化相关\n- **nGPT: Normalized Transformer with Representation Learning on the Hypersphere（nGPT: 归一化 Transformer 与超球面表示学习）**  \n  作者包括 Ilya Loshchilov，这篇论文提出了一种新型归一化 Transformer 架构（nGPT），所有向量（如嵌入和隐藏状态）都保持单位范数，实现嵌入在超球面上的表示学习。主要贡献是显著加速训练，减少 4 到 20 倍的训练步数，同时保持准确性。该方法在序列建模任务中表现出色，展示了 Transformer 效率优化的潜力。\n\n- **softmax is not enough (for sharp out-of-distribution)（softmax 不足以处理尖锐的分布外数据）**  \n  作者 Petar Veličković 等，这篇论文挑战了 softmax 在 AI 推理中的局限性，证明了 softmax 无法鲁棒地处理分布外数据。主要发现是通过理论证明和实验，softmax 会导致模型在高维输入时发散，并提出自适应温度技术来改善推理的锐利性。该工作对 AI 系统决策的鲁棒性有重要启发。\n\n- **Truth or Deceit? A Bayesian Decoding Game Enhances Consistency and Reliability（Truth or Deceit? 贝叶斯解码游戏提升一致性和可靠性）**  \n  这篇论文引入贝叶斯解码游戏框架，优化 LLM 的输出一致性。通过建模多阶段游戏，实现无反馈的输出校准。主要贡献是提升 LLM 在模糊场景下的可靠性，小模型（如 LLaMA-13B）可超越大模型（如 PaLM-540B），为高效 AI 推理提供新路径。\n\n- **RATIONALYST: Pre-training Process-Supervision for Improving Reasoning（RATIONALYST: 用于提升推理的预训练过程监督）**  \n  该论文提出 RATIONALYST 框架，从海量无标签数据中提取推理依据，进行预训练以提升 LLM 的推理能力。主要发现是细调后在多种基准（如数学和逻辑推理）上平均提升 3.9% 准确率，并开源代码，强调了过程监督在泛化任务中的作用。\n\n- **Mixing It Up: The Cocktail Effect of Multi-Task Fine-Tuning on LLM Performance（Mixing It Up: 多任务微调对 LLM 性能的混合效应）**  \n  聚焦 LLM 在金融领域的应用，论文发现多任务微调优于单一任务，能让小模型（如 Phi-3-Mini）超越大模型（如 GPT-4-o）。主要贡献是通过 200+ 实验验证多任务微调的益处，提升数值推理和泛化能力，对领域适应性 LLM 设计有实际启发。\n\n- **Ask, Pose, Unite: Scaling Data Acquisition for Close Interactions with Vision Language Models（Ask, Pose, Unite: 使用视觉语言模型扩展亲密互动数据获取）**  \n  这篇论文开发了 APU 数据集和框架，利用视觉语言模型生成伪地面实数据，提高人机互动建模。主要发现是提升了人体网格估计的准确性，适用于亲密场景，展示了 VLMs 在数据稀缺任务中的潜力。\n\n### 医疗和诊断相关\n- **Explainable Diagnosis Prediction through Neuro-Symbolic Integration（通过神经符号集成实现可解释的诊断预测）**  \n  作者团队包括 Hongfang Liu，这篇论文使用 Logical Neural Networks (LNNs) 结合逻辑规则进行糖尿病预测，实现高达 80.52% 准确率和 0.8457 AUROC。主要贡献是提升医疗 AI 的可解释性和准确性，桥接了传统模型和解释性需求的鸿沟。\n\n- **EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control（EmoKnob: 通过细粒度情绪控制增强语音克隆）**  \n  论文提出 EmoKnob 框架，支持少样本语音合成中的情绪强度控制。主要发现是通过实验验证了其在语音生成中的有效性，超越商业 TTS 系统，提供更精细的情感表达接口。\n\n### 机器人和交通预测相关\n- **Learning to Build by Building Your Own Instructions（通过构建自己的指令学习构建）**  \n  这篇论文开发了 LTRON 环境下的代理模型，能从互动中生成视觉指令书，实现 LEGO 组装任务。主要贡献是通过在线模仿学习处理大型组件，释放新数据集，展示了机器人学习的适应性。\n\n- **STGformer: Efficient Spatiotemporal Graph Transformer for Traffic Forecasting（STGformer: 用于交通预测的高效时空图 Transformer）**  \n  论文提出 STGformer 架构，优化交通预测的时空建模，显著减少计算开销。主要发现是比基线方法快 100 倍，并在 LargeST 基准上表现优异，提升了交通预测的鲁棒性。\n\n其他论文涉及游戏 AI（如 CS:GO 技能分析）、音频处理、多模态生成等，但这些主题较 niche 或不那么影响广泛，我仅快速列出部分标题和要点：\n- **Skill Issues: An Analysis of CS:GO Skill Rating Systems（CS:GO 技能评级系统的分析）**：分析 Elo 和 Glicko2 等算法在游戏匹配中的性能，贡献在于实证评估数据效率。\n- **Augmentation through Laundering Attacks for Audio Spoof Detection（通过清洗攻击增强音频欺骗检测）**：提出数据增强方法改善音频检测，针对 ASVspoof 挑战。\n- **MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages（MOSEL: 用于欧盟语言开源语音基础模型训练的 95 万小时语音数据）**：发布大规模开源语音数据集，促进语音模型训练。\n- **ManiSkill3: GPU Parallelized Robotics Simulation and Rendering for Generalizable Embodied AI（ManiSkill3: 用于泛化具身 AI 的 GPU 并行机器人模拟和渲染）**：开源高效机器人模拟框架，支持多任务训练。\n\n总之，今天的 arXiv 更新了 98 篇论文，其中 AI 和医疗领域的创新工作最值得关注。AI 优化论文如 nGPT 和 softmax 研究展示了高效模型设计的潜力，而医疗 AI 的解释性进展（如 Explainable Diagnosis）为实际应用提供了可靠路径。如果您对特定领域感兴趣，建议查看这些重点论文的原文！",
  "papers": [
    {
      "arxiv_id": "2410.01131v2",
      "title": "nGPT: Normalized Transformer with Representation Learning on the Hypersphere",
      "title_zh": "翻译失败",
      "authors": [
        "Ilya Loshchilov",
        "Cheng-Ping Hsieh",
        "Simeng Sun",
        "Boris Ginsburg"
      ],
      "abstract": "We propose a novel neural network architecture, the normalized Transformer\n(nGPT) with representation learning on the hypersphere. In nGPT, all vectors\nforming the embeddings, MLP, attention matrices and hidden states are unit norm\nnormalized. The input stream of tokens travels on the surface of a hypersphere,\nwith each layer contributing a displacement towards the target output\npredictions. These displacements are defined by the MLP and attention blocks,\nwhose vector components also reside on the same hypersphere. Experiments show\nthat nGPT learns much faster, reducing the number of training steps required to\nachieve the same accuracy by a factor of 4 to 20, depending on the sequence\nlength.",
      "tldr_zh": "本论文提出了一种新颖的神经网络架构 nGPT（Normalized Transformer），它通过在 hypersphere 上进行表示学习，将所有向量（如嵌入、MLP、注意力矩阵和隐藏状态）进行单位范数归一化。nGPT 使输入标记流在 hypersphere 表面传播，每层通过 MLP 和注意力块产生位移，以引导向目标输出预测。实验结果显示，nGPT 显著提高了学习效率，将达到相同精度的训练步数减少 4 到 20 倍，取决于序列长度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01131v2",
      "published_date": "2024-10-01 23:50:09 UTC",
      "updated_date": "2025-04-23 18:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:33:40.624994"
    },
    {
      "arxiv_id": "2410.02831v1",
      "title": "Skill Issues: An Analysis of CS:GO Skill Rating Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Mikel Bober-Irizar",
        "Naunidh Dua",
        "Max McGuinness"
      ],
      "abstract": "The meteoric rise of online games has created a need for accurate skill\nrating systems for tracking improvement and fair matchmaking. Although many\nskill rating systems are deployed, with various theoretical foundations, less\nwork has been done at analysing the real-world performance of these algorithms.\nIn this paper, we perform an empirical analysis of Elo, Glicko2 and TrueSkill\nthrough the lens of surrogate modelling, where skill ratings influence future\nmatchmaking with a configurable acquisition function. We look both at overall\nperformance and data efficiency, and perform a sensitivity analysis based on a\nlarge dataset of Counter-Strike: Global Offensive matches.",
      "tldr_zh": "这篇论文分析了在线游戏中技能评分系统的实际表现，特别是Elo、Glicko2和TrueSkill算法，旨在评估它们在跟踪玩家进步和实现公平匹配方面的效果。研究采用代理建模（surrogate modelling）方法，通过配置获取函数（acquisition function）来考察整体性能、数据效率，并基于大量Counter-Strike: Global Offensive (CS:GO)比赛数据进行敏感性分析。结果为优化这些系统提供了实证依据，有助于改进在线游戏的匹配机制。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02831v1",
      "published_date": "2024-10-01 23:19:31 UTC",
      "updated_date": "2024-10-01 23:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:33:42.169288"
    },
    {
      "arxiv_id": "2410.01855v2",
      "title": "Explainable Diagnosis Prediction through Neuro-Symbolic Integration",
      "title_zh": "通过神经符号整合的可解释诊断预测",
      "authors": [
        "Qiuhao Lu",
        "Rui Li",
        "Elham Sagheb",
        "Andrew Wen",
        "Jinlian Wang",
        "Liwei Wang",
        "Jungwei W. Fan",
        "Hongfang Liu"
      ],
      "abstract": "Diagnosis prediction is a critical task in healthcare, where timely and\naccurate identification of medical conditions can significantly impact patient\noutcomes. Traditional machine learning and deep learning models have achieved\nnotable success in this domain but often lack interpretability which is a\ncrucial requirement in clinical settings. In this study, we explore the use of\nneuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop\nexplainable models for diagnosis prediction. Essentially, we design and\nimplement LNN-based models that integrate domain-specific knowledge through\nlogical rules with learnable thresholds. Our models, particularly\n$M_{\\text{multi-pathway}}$ and $M_{\\text{comprehensive}}$, demonstrate superior\nperformance over traditional models such as Logistic Regression, SVM, and\nRandom Forest, achieving higher accuracy (up to 80.52\\%) and AUROC scores (up\nto 0.8457) in the case study of diabetes prediction. The learned weights and\nthresholds within the LNN models provide direct insights into feature\ncontributions, enhancing interpretability without compromising predictive\npower. These findings highlight the potential of neuro-symbolic approaches in\nbridging the gap between accuracy and explainability in healthcare AI\napplications. By offering transparent and adaptable diagnostic models, our work\ncontributes to the advancement of precision medicine and supports the\ndevelopment of equitable healthcare solutions. Future research will focus on\nextending these methods to larger and more diverse datasets to further validate\ntheir applicability across different medical conditions and populations.",
      "tldr_zh": "该研究探讨了通过神经符号整合（Neuro-Symbolic Integration）实现可解释的诊断预测，特别使用 Logical Neural Networks (LNNs) 整合领域特定逻辑规则和可学习阈值，以解决传统机器学习模型的可解释性不足问题。开发的模型如 $M_{\\text{multi-pathway}}$ 和 $M_{\\text{comprehensive}}$ 在糖尿病预测案例中表现出色，准确率高达 80.52% 和 AUROC 达 0.8457，优于 Logistic Regression、SVM 和 Random Forest 等基准模型。LNNs 的权重和阈值提供直接的特征贡献洞察，提升了模型的可解释性，同时维持了预测性能，为精确医学和公平医疗应用铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of AMIA Informatics Summit 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.01855v2",
      "published_date": "2024-10-01 22:47:24 UTC",
      "updated_date": "2025-01-07 23:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:33:54.069894"
    },
    {
      "arxiv_id": "2410.01111v1",
      "title": "Learning to Build by Building Your Own Instructions",
      "title_zh": "通过构建自己的指令来学习构建",
      "authors": [
        "Aaron Walsman",
        "Muru Zhang",
        "Adam Fishman",
        "Ali Farhadi",
        "Dieter Fox"
      ],
      "abstract": "Structural understanding of complex visual objects is an important unsolved\ncomponent of artificial intelligence. To study this, we develop a new technique\nfor the recently proposed Break-and-Make problem in LTRON where an agent must\nlearn to build a previously unseen LEGO assembly using a single interactive\nsession to gather information about its components and their structure. We\nattack this problem by building an agent that we call \\textbf{\\ours} that is\nable to make its own visual instruction book. By disassembling an unseen\nassembly and periodically saving images of it, the agent is able to create a\nset of instructions so that it has the information necessary to rebuild it.\nThese instructions form an explicit memory that allows the model to reason\nabout the assembly process one step at a time, avoiding the need for long-term\nimplicit memory. This in turn allows us to train on much larger LEGO assemblies\nthan has been possible in the past. To demonstrate the power of this model, we\nrelease a new dataset of procedurally built LEGO vehicles that contain an\naverage of 31 bricks each and require over one hundred steps to disassemble and\nreassemble. We train these models using online imitation learning which allows\nthe model to learn from its own mistakes. Finally, we also provide some small\nimprovements to LTRON and the Break-and-Make problem that simplify the learning\nenvironment and improve usability.",
      "tldr_zh": "这篇论文提出了一种新方法，用于解决 LTRON 环境中的 Break-and-Make 问题，代理通过创建自己的视觉指令书来学习构建未见 LEGO 组件。具体而言，名为 \\textbf{\\ours} 的代理会拆解组件并保存图像，形成显式记忆，从而一步步推理，避免依赖长时隐式记忆，并支持处理更大规模的组件。作者发布了新数据集，包含平均 31 个积木的 LEGO 车辆，需要超过 100 步拆解和重新组装，并使用 online imitation learning 训练模型，让代理从错误中学习。最后，该研究还对 LTRON 和 Break-and-Make 问题进行了小改进，以简化学习环境和提升可用性。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01111v1",
      "published_date": "2024-10-01 22:39:58 UTC",
      "updated_date": "2024-10-01 22:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:34:08.490687"
    },
    {
      "arxiv_id": "2410.01109v2",
      "title": "Mixing It Up: The Cocktail Effect of Multi-Task Fine-Tuning on LLM Performance -- A Case Study in Finance",
      "title_zh": "翻译失败",
      "authors": [
        "Meni Brief",
        "Oded Ovadia",
        "Gil Shenderovitz",
        "Noga Ben Yoash",
        "Rachel Lemberg",
        "Eitam Sheetrit"
      ],
      "abstract": "The application of large language models (LLMs) in domain-specific contexts,\nincluding finance, has expanded rapidly. Domain-specific LLMs are typically\nevaluated based on their performance in various downstream tasks relevant to\nthe domain. In this work, we present a detailed analysis of fine-tuning LLMs\nfor such tasks. Somewhat counterintuitively, we find that in domain-specific\ncases, fine-tuning exclusively on the target task is not always the most\neffective strategy. Instead, multi-task finetuning - where models are trained\non a cocktail of related tasks - can significantly enhance performance. We\ndemonstrate how this approach enables a small model, such as Phi-3-Mini, to\nachieve state-of-the-art results, even surpassing the much larger GPT-4-o model\non financial benchmarks. Our study involves a large-scale experiment,\nconducting over 200 training experiments using several widely adopted LLMs as\nbaselines, and empirically confirms the benefits of multi-task fine-tuning.\nAdditionally, we explore the use of general instruction data as a form of\nregularization, suggesting that it helps minimize performance degradation. We\nalso investigate the inclusion of mathematical data, finding improvements in\nnumerical reasoning that transfer effectively to financial tasks. Finally, we\nnote that while fine-tuning for downstream tasks leads to targeted improvements\nin task performance, it does not necessarily result in broader gains in domain\nknowledge or complex domain reasoning abilities.",
      "tldr_zh": "这篇论文研究了在金融领域对大型语言模型（LLMs）进行多任务微调的“鸡尾酒效应”，发现多任务微调（训练模型处理相关任务的混合）比单一任务微调更有效，甚至让小型模型如Phi-3-Mini在金融基准上超越了更大的GPT-4-o。研究者通过超过200次实验验证了这一方法的好处，并指出使用通用指令数据作为正则化能减少性能下降，而加入数学数据则改善了数值推理能力。总体而言，多任务微调针对性地提升了下游任务性能，但并未显著增强更广泛的领域知识或复杂推理。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01109v2",
      "published_date": "2024-10-01 22:35:56 UTC",
      "updated_date": "2024-12-04 20:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:34:18.891852"
    },
    {
      "arxiv_id": "2410.01108v1",
      "title": "Augmentation through Laundering Attacks for Audio Spoof Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Hashim Ali",
        "Surya Subramani",
        "Hafiz Malik"
      ],
      "abstract": "Recent text-to-speech (TTS) developments have made voice cloning (VC) more\nrealistic, affordable, and easily accessible. This has given rise to many\npotential abuses of this technology, including Joe Biden's New Hampshire\ndeepfake robocall. Several methodologies have been proposed to detect such\nclones. However, these methodologies have been trained and evaluated on\nrelatively clean databases. Recently, ASVspoof 5 Challenge introduced a new\ncrowd-sourced database of diverse acoustic conditions including various\nspoofing attacks and codec conditions. This paper is our submission to the\nASVspoof 5 Challenge and aims to investigate the performance of Audio Spoof\nDetection, trained using data augmentation through laundering attacks, on the\nASVSpoof 5 database. The results demonstrate that our system performs worst on\nA18, A19, A20, A26, and A30 spoofing attacks and in the codec and compression\nconditions of C08, C09, and C10.",
      "tldr_zh": "这篇论文探讨了使用数据增强技术（通过 laundering attacks）来训练音频欺骗检测系统，以应对文本到语音（TTS）和语音克隆（VC）技术的滥用问题，如深度伪造音频。研究团队针对 ASVspoof 5 Challenge 的多样化数据库进行了评估，模型在各种声学条件下表现出了改进，但结果显示在 A18, A19, A20, A26, A30 等欺骗攻击和 C08, C09, C10 等编解码条件下性能最差。主要贡献在于证明了数据增强方法在音频欺骗检测中的潜在局限性，为未来系统优化提供了见解。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01108v1",
      "published_date": "2024-10-01 22:34:51 UTC",
      "updated_date": "2024-10-01 22:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:34:31.049743"
    },
    {
      "arxiv_id": "2410.01104v2",
      "title": "softmax is not enough (for sharp out-of-distribution)",
      "title_zh": "翻译失败",
      "authors": [
        "Petar Veličković",
        "Christos Perivolaropoulos",
        "Federico Barbero",
        "Razvan Pascanu"
      ],
      "abstract": "A key property of reasoning systems is the ability to make sharp decisions on\ntheir input data. For contemporary AI systems, a key carrier of sharp behaviour\nis the softmax function, with its capability to perform differentiable\nquery-key lookups. It is a common belief that the predictive power of networks\nleveraging softmax arises from \"circuits\" which sharply perform certain kinds\nof computations consistently across many diverse inputs. However, for these\ncircuits to be robust, they would need to generalise well to arbitrary valid\ninputs. In this paper, we dispel this myth: even for tasks as simple as finding\nthe maximum key, any learned circuitry must disperse as the number of items\ngrows at test time. We attribute this to a fundamental limitation of the\nsoftmax function to robustly approximate sharp functions, prove this phenomenon\ntheoretically, and propose adaptive temperature as an ad-hoc technique for\nimproving the sharpness of softmax at inference time.",
      "tldr_zh": "本论文质疑了 softmax 函数在处理 out-of-distribution 输入时的不足，指出它无法提供足够的锐利度，导致学到的“circuits”在输入规模增大时无法保持一致的计算行为。即使在简单任务如找到最大键上，电路也会分散。作者通过理论证明了 softmax 无法鲁棒地近似锐利函数的根本限制，并提出使用自适应温度作为一种在推理时改进锐利度的临时技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "Comments welcome. 15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.01104v2",
      "published_date": "2024-10-01 22:22:35 UTC",
      "updated_date": "2024-10-07 13:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:34:42.299021"
    },
    {
      "arxiv_id": "2410.01103v1",
      "title": "Approximately Aligned Decoding",
      "title_zh": "近似对齐解码",
      "authors": [
        "Daniel Melcer",
        "Sujan Gonugondla",
        "Pramuditha Perera",
        "Haifeng Qian",
        "Wen-Hao Chiang",
        "Yanjun Wang",
        "Nihal Jain",
        "Pranav Garg",
        "Xiaofei Ma",
        "Anoop Deoras"
      ],
      "abstract": "It is common to reject undesired outputs of Large Language Models (LLMs);\nhowever, current methods to do so require an excessive amount of computation,\nor severely distort the distribution of outputs. We present a method to balance\nthe distortion of the output distribution with computational efficiency,\nallowing for the generation of long sequences of text with difficult-to-satisfy\nconstraints, with less amplification of low probability outputs compared to\nexisting methods. We show through a series of experiments that the\ntask-specific performance of our method is comparable to methods that do not\ndistort the output distribution, while being much more computationally\nefficient.",
      "tldr_zh": "这篇论文提出了 Approximately Aligned Decoding 方法，用于处理 Large Language Models (LLMs) 的 undesired 输出问题，该方法在减少输出分布扭曲的同时，提高了计算效率。相比现有方法，它能生成长序列文本并满足困难约束，同时避免过度放大低概率输出。通过一系列实验，研究者证明了该方法的任务特定性能与不扭曲输出分布的基准方法相当，但计算效率显著提升。总的来说，这为高效的约束生成任务提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages main, 22 pages total",
      "pdf_url": "http://arxiv.org/pdf/2410.01103v1",
      "published_date": "2024-10-01 22:22:13 UTC",
      "updated_date": "2024-10-01 22:22:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:34:53.500061"
    },
    {
      "arxiv_id": "2410.01098v2",
      "title": "Exploring Gen-AI applications in building research and industry: A review",
      "title_zh": "探索 Gen-AI 在建筑研究和行业的应用：综述",
      "authors": [
        "Hanlong Wan",
        "Jian Zhang",
        "Yan Chen",
        "Weili Xu",
        "Fan Feng"
      ],
      "abstract": "This paper investigates the transformative potential of Generative AI\n(Gen-AI) technologies, particularly large language models, within the building\nindustry. By leveraging these advanced AI tools, the study explores their\napplication across key areas such as automated compliance checking and building\ndesign assistance. The research highlights how Gen-AI can automate\nlabor-intensive processes, significantly improving efficiency and reducing\ncosts in building practices. The paper first discusses the two widely applied\nfundamental models-Transformer and Diffusion model-and summarizes current\npathways for accessing Gen-AI models and the most common techniques for\ncustomizing them. It then explores applications for text generation, such as\ncompliance checking, control support, data mining, and building simulation\ninput file editing. Additionally, it examines image generation, including\ndirect generation through diffusion models and indirect generation through\nlanguage model-supported template creation based on existing Computer-Aided\nDesign or other design tools with rendering. The paper concludes with a\ncomprehensive analysis of the current capabilities of Gen-AI in the building\nindustry, outlining future directions for research and development, with the\ngoal of paving the way for smarter, more effective, and responsive design,\nconstruction, and operational practices.",
      "tldr_zh": "这篇论文综述了Generative AI (Gen-AI)，特别是大型语言模型，在建筑研究和行业的应用潜力，包括自动化合规检查和建筑设计辅助。论文首先讨论了Transformer和Diffusion模型的核心机制，并总结了访问和自定义这些模型的常见技术。接着，它探索了Gen-AI在文本生成（如合规检查、数据挖掘和模拟输入编辑）和图像生成（如扩散模型直接生成或语言模型辅助设计）的具体应用，这些应用能显著提高效率并降低成本。最终，论文分析了当前Gen-AI的能力，并展望未来研究方向，以推动更智能、响应迅速的建筑设计、建设和运营实践。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.IV",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "This is a pre-peer review and copy editing version of an article\n  published in Building Simulation. The final authenticated version is\n  available online at:https://doi.org/10.1007/s12273-025-1279-x",
      "pdf_url": "http://arxiv.org/pdf/2410.01098v2",
      "published_date": "2024-10-01 21:59:08 UTC",
      "updated_date": "2025-05-11 04:14:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:35:07.005011"
    },
    {
      "arxiv_id": "2410.01096v1",
      "title": "Mechanic Maker: Accessible Game Development Via Symbolic Learning Program Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Megan Sumner",
        "Vardan Saini",
        "Matthew Guzdial"
      ],
      "abstract": "Game development is a highly technical practice that traditionally requires\nprogramming skills. This serves as a barrier to entry for would-be developers\nor those hoping to use games as part of their creative expression. While there\nhave been prior game development tools focused on accessibility, they generally\nstill require programming, or have major limitations in terms of the kinds of\ngames they can make. In this paper we introduce Mechanic Maker, a tool for\ncreating a wide-range of game mechanics without programming. It instead relies\non a backend symbolic learning system to synthesize game mechanics from\nexamples. We conducted a user study to evaluate the benefits of the tool for\nparticipants with a variety of programming and game development experience. Our\nresults demonstrated that participants' ability to use the tool was unrelated\nto programming ability. We conclude that tools like ours could help democratize\ngame development, making the practice accessible regardless of programming\nskills.",
      "tldr_zh": "这篇论文介绍了 Mechanic Maker，一种无需编程技能的游戏开发工具，通过 symbolic learning program synthesis 从用户示例中自动合成各种游戏机制，从而降低游戏开发的门槛。研究团队进行了用户研究，结果显示参与者的工具使用能力与编程经验无关，这证明 Mechanic Maker 能为不同背景的用户提供平等的访问机会。该工具的创新设计有助于民主化游戏开发，使更多人能够轻松表达创意。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 8 figures, AAAI Conference on Artificial Intelligence and\n  Interactive Digital Entertainment",
      "pdf_url": "http://arxiv.org/pdf/2410.01096v1",
      "published_date": "2024-10-01 21:58:28 UTC",
      "updated_date": "2024-10-01 21:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:35:17.495125"
    },
    {
      "arxiv_id": "2410.01091v2",
      "title": "Efficient and Private Marginal Reconstruction with Local Non-Negativity",
      "title_zh": "翻译失败",
      "authors": [
        "Brett Mullins",
        "Miguel Fuentes",
        "Yingtai Xiao",
        "Daniel Kifer",
        "Cameron Musco",
        "Daniel Sheldon"
      ],
      "abstract": "Differential privacy is the dominant standard for formal and quantifiable\nprivacy and has been used in major deployments that impact millions of people.\nMany differentially private algorithms for query release and synthetic data\ncontain steps that reconstruct answers to queries from answers to other queries\nthat have been measured privately. Reconstruction is an important subproblem\nfor such mechanisms to economize the privacy budget, minimize error on\nreconstructed answers, and allow for scalability to high-dimensional datasets.\nIn this paper, we introduce a principled and efficient postprocessing method\nReM (Residuals-to-Marginals) for reconstructing answers to marginal queries.\nOur method builds on recent work on efficient mechanisms for marginal query\nrelease, based on making measurements using a residual query basis that admits\nefficient pseudoinversion, which is an important primitive used in\nreconstruction. An extension GReM-LNN (Gaussian Residuals-to-Marginals with\nLocal Non-negativity) reconstructs marginals under Gaussian noise satisfying\nconsistency and non-negativity, which often reduces error on reconstructed\nanswers. We demonstrate the utility of ReM and GReM-LNN by applying them to\nimprove existing private query answering mechanisms.",
      "tldr_zh": "本论文提出了一种高效且私有的边际查询（Marginal Queries）重建方法，名为 ReM（Residuals-to-Marginals），旨在优化差分隐私（Differential Privacy）算法中的重建步骤，以经济化隐私预算（Privacy Budget）、最小化重建错误，并提升高维数据集的可扩展性。该方法基于残差查询基础（Residual Query Basis）和高效伪逆（Pseudoinversion）技术进行后处理。扩展版本 GReM-LNN（Gaussian Residuals-to-Marginals with Local Non-negativity）在高斯噪声（Gaussian Noise）下确保重建结果的一致性和非负性，从而进一步减少错误；实验结果显示，这些方法显著改进了现有的私有查询回答机制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.01091v2",
      "published_date": "2024-10-01 21:39:28 UTC",
      "updated_date": "2024-12-07 05:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:35:30.127366"
    },
    {
      "arxiv_id": "2410.01066v2",
      "title": "From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Mohammadjafari",
        "Anthony S. Maida",
        "Raju Gottumukkala"
      ],
      "abstract": "LLMs when used with Retrieval Augmented Generation (RAG), are greatly\nimproving the SOTA of translating natural language queries to structured and\ncorrect SQL. Unlike previous reviews, this survey provides a comprehensive\nstudy of the evolution of LLM-based text-to-SQL systems, from early rule-based\nmodels to advanced LLM approaches that use (RAG) systems. We discuss\nbenchmarks, evaluation methods, and evaluation metrics. Also, we uniquely study\nthe use of Graph RAGs for better contextual accuracy and schema linking in\nthese systems. Finally, we highlight key challenges such as computational\nefficiency, model robustness, and data privacy toward improvements of LLM-based\ntext-to-SQL systems.",
      "tldr_zh": "这篇综述回顾了LLM（Large Language Models）结合Retrieval Augmented Generation (RAG)如何显著提升自然语言查询到SQL转换的SOTA（State-of-the-Art）水平。它从早期的基于规则模型到先进的LLM方法进行全面分析，涵盖了基准、评估方法和指标，并特别探讨了Graph RAG在提升上下文准确性和schema linking方面的作用。最后，论文突出了关键挑战，如计算效率、模型鲁棒性和数据隐私问题，以指导未来改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.01066v2",
      "published_date": "2024-10-01 20:46:25 UTC",
      "updated_date": "2025-02-04 03:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:35:42.051858"
    },
    {
      "arxiv_id": "2410.01064v1",
      "title": "Truth or Deceit? A Bayesian Decoding Game Enhances Consistency and Reliability",
      "title_zh": "真相还是",
      "authors": [
        "Weitong Zhang",
        "Chengqi Zang",
        "Bernhard Kainz"
      ],
      "abstract": "Large Language Models (LLMs) often produce outputs that -- though plausible\n-- can lack consistency and reliability, particularly in ambiguous or complex\nscenarios. Challenges arise from ensuring that outputs align with both factual\ncorrectness and human intent. This is problematic in existing approaches that\ntrade improved consistency for lower accuracy. To mitigate these challenges, we\npropose a novel game-theoretic approach to enhance consistency and reliability\nduring the decoding stage of LLM output generation. Our method models the\ndecoding process as a multistage Bayesian decoding game. This ensures\nconsistency through Correctness Alignment and enhances reliability via\nAmbiguity Calibration. The model dynamically converges to a consensus on the\nmost reliable outputs and distinguishes {Valid, Specious} outputs without human\nfeedback or additional training. Our game design allows smaller models to\noutperform much larger models through game mechanisms (e.g., 78.1 LLaMA13B vs\n76.6 PaLM540B), as well as integrating various LL strategies and models,\ndemonstrating the potential of game-theoretic tools to improve the truthfulness\nand reliability of LLMs.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)输出的一致性和可靠性问题，提出了一种基于博弈论的Bayesian decoding game方法，将解码过程建模为多阶段游戏，以通过Correctness Alignment确保输出正确性和Ambiguity Calibration校准模糊性。 该方法无需人类反馈或额外训练，即可动态区分Valid和Specious输出，并实现模型共识。实验结果显示，该框架使小型模型（如78.1 LLaMA13B）超越大型模型（如76.6 PaLM540B），并支持整合各种LL策略，展示了博弈论工具提升LLMs真实性和可靠性的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01064v1",
      "published_date": "2024-10-01 20:46:10 UTC",
      "updated_date": "2024-10-01 20:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:35:55.207195"
    },
    {
      "arxiv_id": "2410.01044v1",
      "title": "RATIONALYST: Pre-training Process-Supervision for Improving Reasoning",
      "title_zh": "RATIONALYST：用于改进推理的预训练过程监督",
      "authors": [
        "Dongwei Jiang",
        "Guoxuan Wang",
        "Yining Lu",
        "Andrew Wang",
        "Jingyu Zhang",
        "Chuyu Liu",
        "Benjamin Van Durme",
        "Daniel Khashabi"
      ],
      "abstract": "The reasoning steps generated by LLMs might be incomplete, as they mimic\nlogical leaps common in everyday communication found in their pre-training\ndata: underlying rationales are frequently left implicit (unstated). To address\nthis challenge, we introduce RATIONALYST, a model for process-supervision of\nreasoning based on pre-training on a vast collection of rationale annotations\nextracted from unlabeled data. We extract 79k rationales from web-scale\nunlabelled dataset (the Pile) and a combination of reasoning datasets with\nminimal human intervention. This web-scale pre-training for reasoning allows\nRATIONALYST to consistently generalize across diverse reasoning tasks,\nincluding mathematical, commonsense, scientific, and logical reasoning.\nFine-tuned from LLaMa-3-8B, RATIONALYST improves the accuracy of reasoning by\nan average of 3.9% on 7 representative reasoning benchmarks. It also\ndemonstrates superior performance compared to significantly larger verifiers\nlike GPT-4 and similarly sized models fine-tuned on matching training sets.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在推理过程中常出现的逻辑跳跃问题，提出了RATIONALYST模型，通过process-supervision预训练来提升推理完整性。该模型从web-scale未标注数据集（如The Pile）和推理数据集提取79k个理由进行训练，从而增强模型在数学、常识、科学和逻辑推理等任务上的泛化能力。基于LLaMa-3-8B微调后，RATIONALYST在7个代表性推理基准上平均准确率提升3.9%，并在性能上优于更大模型如GPT-4以及同尺寸的微调模型。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Our code, data, and model can be found at this repository:\n  https://github.com/JHU-CLSP/Rationalyst",
      "pdf_url": "http://arxiv.org/pdf/2410.01044v1",
      "published_date": "2024-10-01 20:05:51 UTC",
      "updated_date": "2024-10-01 20:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:36:05.618934"
    },
    {
      "arxiv_id": "2410.01036v1",
      "title": "MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Gaido",
        "Sara Papi",
        "Luisa Bentivogli",
        "Alessio Brutti",
        "Mauro Cettolo",
        "Roberto Gretter",
        "Marco Matassoni",
        "Mohamed Nabih",
        "Matteo Negri"
      ],
      "abstract": "The rise of foundation models (FMs), coupled with regulatory efforts\naddressing their risks and impacts, has sparked significant interest in\nopen-source models. However, existing speech FMs (SFMs) fall short of full\ncompliance with the open-source principles, even if claimed otherwise, as no\nexisting SFM has model weights, code, and training data publicly available\nunder open-source terms. In this work, we take the first step toward filling\nthis gap by focusing on the 24 official languages of the European Union (EU).\nWe collect suitable training data by surveying automatic speech recognition\ndatasets and unlabeled speech corpora under open-source compliant licenses, for\na total of 950k hours. Additionally, we release automatic transcripts for 441k\nhours of unlabeled data under the permissive CC-BY license, thereby\nfacilitating the creation of open-source SFMs for the EU languages.",
      "tldr_zh": "该研究（MOSEL）针对欧盟 24 种官方语言，收集了总计 950,000 小时的开源语音数据，以填补现有语音基础模型（SFMs）在模型权重、代码和训练数据公开方面的不足。研究者通过调查自动语音识别数据集和未标注语音语料，确保所有数据符合开源许可，并为 441,000 小时的未标注数据发布了自动转录文件，使用 CC-BY 许可。最终，这促进了完全开源 SFMs 的开发，提升了欧盟语言语音模型的训练可及性和合规性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2410.01036v1",
      "published_date": "2024-10-01 19:54:10 UTC",
      "updated_date": "2024-10-01 19:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:36:18.407876"
    },
    {
      "arxiv_id": "2410.03750v1",
      "title": "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Pablo Muñoz",
        "Jinjie Yuan",
        "Nilesh Jain"
      ],
      "abstract": "Large pre-trained models (LPMs), such as large language models, have become\nubiquitous and are employed in many applications. These models are often\nadapted to a desired domain or downstream task through a fine-tuning stage.\nThis paper proposes SQFT, an end-to-end solution for low-precision sparse\nparameter-efficient fine-tuning of LPMs, allowing for effective model\nmanipulation in resource-constrained environments. Additionally, an innovative\nstrategy enables the merging of sparse weights with low-rank adapters without\nlosing sparsity and accuracy, overcoming the limitations of previous\napproaches. SQFT also addresses the challenge of having quantized weights and\nadapters with different numerical precisions, enabling merging in the desired\nnumerical format without sacrificing accuracy. Multiple adaptation scenarios,\nmodels, and comprehensive sparsity levels demonstrate the effectiveness of\nSQFT. Models and code are available at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
      "tldr_zh": "该论文提出 SQFT，一种低成本的端到端解决方案，用于低精度稀疏参数高效微调(Low-precision Sparse Parameter-efficient Fine-tuning)的大型预训练模型(LPMs)，适用于资源受限环境。SQFT 创新性地实现了稀疏权重与低秩适配器(Low-rank Adapters)的合并，而不损失稀疏性和准确性，同时解决了量化权重和适配器不同数值精度的问题。实验在多种适应场景、模型和稀疏水平上验证了 SQFT 的有效性，模型和代码可从 https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in EMNLP-24 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.03750v1",
      "published_date": "2024-10-01 19:49:35 UTC",
      "updated_date": "2024-10-01 19:49:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:36:29.938305"
    },
    {
      "arxiv_id": "2410.19738v1",
      "title": "Integrating Reasoning Systems for Trustworthy AI, Proceedings of the 4th Workshop on Logic and Practice of Programming (LPOP)",
      "title_zh": "翻译失败",
      "authors": [
        "Anil Nerode",
        "Yanhong A. Liu"
      ],
      "abstract": "This proceedings contains abstracts and position papers for the work to be\npresented at the fourth Logic and Practice of Programming (LPOP) Workshop. The\nworkshop is to be held in Dallas, Texas, USA, and as a hybrid event, on October\n13, 2024, in conjunction with the 40th International Conference on Logic\nProgramming (ICLP). The focus of this workshop is integrating reasoning systems\nfor trustworthy AI, especially including integrating diverse models of\nprogramming with rules and constraints.",
      "tldr_zh": "这本论文集收录了第四届Logic and Practice of Programming (LPOP) Workshop的摘要和位置论文，聚焦于整合推理系统以实现Trustworthy AI，特别是将不同的编程模型与规则和约束相结合。会议将于2024年10月13日在美国德克萨斯州达拉斯举行，作为混合事件，与第40届International Conference on Logic Programming (ICLP) 联合举办。该论文集旨在促进可信AI领域的学术交流和创新实践。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19738v1",
      "published_date": "2024-10-01 19:36:08 UTC",
      "updated_date": "2024-10-01 19:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:36:42.811811"
    },
    {
      "arxiv_id": "2410.01023v2",
      "title": "Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!",
      "title_zh": "翻译失败",
      "authors": [
        "Jiwan Chung",
        "Seungwon Lim",
        "Jaehyun Jeon",
        "Seungbeen Lee",
        "Youngjae Yu"
      ],
      "abstract": "Humans possess multimodal literacy, allowing them to actively integrate\ninformation from various modalities to form reasoning. Faced with challenges\nlike lexical ambiguity in text, we supplement this with other modalities, such\nas thumbnail images or textbook illustrations. Is it possible for machines to\nachieve a similar multimodal understanding capability? In response, we present\nUnderstanding Pun with Image Explanations (UNPIE), a novel benchmark designed\nto assess the impact of multimodal inputs in resolving lexical ambiguities.\nPuns serve as the ideal subject for this evaluation due to their intrinsic\nambiguity. Our dataset includes 1,000 puns, each accompanied by an image that\nexplains both meanings. We pose three multimodal challenges with the\nannotations to assess different aspects of multimodal literacy; Pun Grounding,\nDisambiguation, and Reconstruction. The results indicate that various Socratic\nModels and Visual-Language Models improve over the text-only models when given\nvisual context, particularly as the complexity of the tasks increases.",
      "tldr_zh": "本研究探讨视觉语言模型（Visual-Language Models）是否能通过视觉线索解决文本歧义，并使用视觉双关语（puns）作为测试主体。研究者提出 UNPIE 基准数据集，包含 1,000 个双关语，每个配有解释两种含义的图像，并设计了三个多模态挑战：Pun Grounding、Disambiguation 和 Reconstruction，以评估模型的多模态理解能力。结果显示，Socratic Models 和 Visual-Language Models 在提供视觉上下文时，比纯文本模型有显著改善，尤其在任务复杂度增加的情况下。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as main paper in EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.01023v2",
      "published_date": "2024-10-01 19:32:57 UTC",
      "updated_date": "2024-10-23 02:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:36:54.803785"
    },
    {
      "arxiv_id": "2410.02829v1",
      "title": "LLMs May Not Be Human-Level Players, But They Can Be Testers: Measuring Game Difficulty with LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Xiao",
        "Brenda Z. Yang"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated their\npotential as autonomous agents across various tasks. One emerging application\nis the use of LLMs in playing games. In this work, we explore a practical\nproblem for the gaming industry: Can LLMs be used to measure game difficulty?\nWe propose a general game-testing framework using LLM agents and test it on two\nwidely played strategy games: Wordle and Slay the Spire. Our results reveal an\ninteresting finding: although LLMs may not perform as well as the average human\nplayer, their performance, when guided by simple, generic prompting techniques,\nshows a statistically significant and strong correlation with difficulty\nindicated by human players. This suggests that LLMs could serve as effective\nagents for measuring game difficulty during the development process. Based on\nour experiments, we also outline general principles and guidelines for\nincorporating LLMs into the game testing process.",
      "tldr_zh": "本文研究探讨了 Large Language Models (LLMs) 在游戏测试中的潜力，提出一个通用框架，使用 LLM 代理来测量游戏难度。研究在 Wordle 和 Slay the Spire 等策略游戏上进行实验，结果显示尽管 LLMs 的表现不如平均人类玩家，但通过简单的提示技术，其性能与人类对游戏难度的感知存在显著的相关性。这表明 LLMs 可以作为有效的游戏测试工具，并基于实验总结了相关的指导原则和最佳实践。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02829v1",
      "published_date": "2024-10-01 18:40:43 UTC",
      "updated_date": "2024-10-01 18:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:37:16.422039"
    },
    {
      "arxiv_id": "2410.03747v1",
      "title": "Distributed AI Platform for the 6G RAN",
      "title_zh": "翻译失败",
      "authors": [
        "Ganesh Ananthanarayanan",
        "Xenofon Foukas",
        "Bozidar Radunovic",
        "Yongguang Zhang"
      ],
      "abstract": "Cellular Radio Access Networks (RANs) are rapidly evolving towards 6G, driven\nby the need to reduce costs and introduce new revenue streams for operators and\nenterprises. In this context, AI emerges as a key enabler in solving complex\nRAN problems spanning both the management and application domains.\nUnfortunately, and despite the undeniable promise of AI, several practical\nchallenges still remain, hindering the widespread adoption of AI applications\nin the RAN space. This article attempts to shed light to these challenges and\nargues that existing approaches in addressing them are inadequate for realizing\nthe vision of a truly AI-native 6G network. Motivated by this lack of\nsolutions, it proposes a generic distributed AI platform architecture, tailored\nto the needs of an AI-native RAN and discusses its alignment with ongoing\nstandardization efforts.",
      "tldr_zh": "本文分析了蜂窝无线接入网 (RAN) 向 6G 演进过程中面临的挑战，包括成本降低和新收入来源的需求，以及 AI 在管理和服务领域解决复杂问题的潜力，但现有方法不足以实现真正的 AI 原生网络。论文提出了一种通用的分布式 AI 平台架构，专门针对 AI-native 6G RAN 的需求，以克服这些障碍。最终，该架构与正在进行的标准化努力相契合，为 AI 在 RAN 中的广泛采用提供了可行路径。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03747v1",
      "published_date": "2024-10-01 18:35:25 UTC",
      "updated_date": "2024-10-01 18:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:37:18.033778"
    },
    {
      "arxiv_id": "2410.00983v2",
      "title": "Robust Guided Diffusion for Offline Black-Box Optimization",
      "title_zh": "鲁棒引导扩散用于",
      "authors": [
        "Can Sam Chen",
        "Christopher Beckham",
        "Zixuan Liu",
        "Xue Liu",
        "Christopher Pal"
      ],
      "abstract": "Offline black-box optimization aims to maximize a black-box function using an\noffline dataset of designs and their measured properties. Two main approaches\nhave emerged: the forward approach, which learns a mapping from input to its\nvalue, thereby acting as a proxy to guide optimization, and the inverse\napproach, which learns a mapping from value to input for conditional\ngeneration. (a) Although proxy-free~(classifier-free) diffusion shows promise\nin robustly modeling the inverse mapping, it lacks explicit guidance from\nproxies, essential for generating high-performance samples beyond the training\ndistribution. Therefore, we propose \\textit{proxy-enhanced sampling} which\nutilizes the explicit guidance from a trained proxy to bolster proxy-free\ndiffusion with enhanced sampling control. (b) Yet, the trained proxy is\nsusceptible to out-of-distribution issues. To address this, we devise the\nmodule \\textit{diffusion-based proxy refinement}, which seamlessly integrates\ninsights from proxy-free diffusion back into the proxy for refinement. To sum\nup, we propose \\textit{\\textbf{R}obust \\textbf{G}uided \\textbf{D}iffusion for\nOffline Black-box Optimization}~(\\textbf{RGD}), combining the advantages of\nproxy~(explicit guidance) and proxy-free diffusion~(robustness) for effective\nconditional generation. RGD achieves state-of-the-art results on various\ndesign-bench tasks, underscoring its efficacy. Our code is at\nhttps://github.com/GGchen1997/RGD.",
      "tldr_zh": "这篇论文针对离线黑箱优化（Offline Black-Box Optimization）问题，提出了 Robust Guided Diffusion (RGD) 方法，以结合 forward approach 和 inverse approach 的优势。RGD 通过 proxy-enhanced sampling 利用训练好的 proxy 提供显式指导，提升 proxy-free diffusion 的采样控制；同时引入 diffusion-based proxy refinement 模块，解决 proxy 的 out-of-distribution 问题，实现更鲁棒的条件生成。实验结果表明，RGD 在各种 design-bench 任务上达到了 state-of-the-art 性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.00983v2",
      "published_date": "2024-10-01 18:14:25 UTC",
      "updated_date": "2024-12-30 20:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:37:30.525630"
    },
    {
      "arxiv_id": "2410.00980v1",
      "title": "Heterogeneous sound classification with the Broad Sound Taxonomy and Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Panagiota Anastasopoulou",
        "Jessica Torrey",
        "Xavier Serra",
        "Frederic Font"
      ],
      "abstract": "Automatic sound classification has a wide range of applications in machine\nlistening, enabling context-aware sound processing and understanding. This\npaper explores methodologies for automatically classifying heterogeneous sounds\ncharacterized by high intra-class variability. Our study evaluates the\nclassification task using the Broad Sound Taxonomy, a two-level taxonomy\ncomprising 28 classes designed to cover a heterogeneous range of sounds with\nsemantic distinctions tailored for practical user applications. We construct a\ndataset through manual annotation to ensure accuracy, diverse representation\nwithin each class and relevance in real-world scenarios. We compare a variety\nof both traditional and modern machine learning approaches to establish a\nbaseline for the task of heterogeneous sound classification. We investigate the\nrole of input features, specifically examining how acoustically derived sound\nrepresentations compare to embeddings extracted with pre-trained deep neural\nnetworks that capture both acoustic and semantic information about sounds.\nExperimental results illustrate that audio embeddings encoding acoustic and\nsemantic information achieve higher accuracy in the classification task. After\ncareful analysis of classification errors, we identify some underlying reasons\nfor failure and propose actions to mitigate them. The paper highlights the need\nfor deeper exploration of all stages of classification, understanding the data\nand adopting methodologies capable of effectively handling data complexity and\ngeneralizing in real-world sound environments.",
      "tldr_zh": "这篇论文介绍了 Broad Sound Taxonomy，一个包含 28 个类的两级分类系统，用于处理高内部变异性的异构声音分类，并构建了一个通过手动标注的数据集，以确保数据的准确性和真实性。研究比较了传统和现代机器学习方法，评估了声学表示与预训练深度神经网络提取的音频嵌入（编码声学和语义信息）的效果，结果显示后者在分类任务中实现了更高的准确率。通过分析分类错误，论文识别了失败原因并提出缓解措施，强调需要更深入探索数据复杂性和方法，以提升在真实环境中的泛化能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "DCASE2024, post-print, 5 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.00980v1",
      "published_date": "2024-10-01 18:09:02 UTC",
      "updated_date": "2024-10-01 18:09:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:37:42.571912"
    },
    {
      "arxiv_id": "2410.00979v2",
      "title": "Towards Full-parameter and Parameter-efficient Self-learning For Endoscopic Camera Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuting Zhao",
        "Chenkang Du",
        "Kristin Qi",
        "Xinrong Chen",
        "Xinhan Di"
      ],
      "abstract": "Adaptation methods are developed to adapt depth foundation models to\nendoscopic depth estimation recently. However, such approaches typically\nunder-perform training since they limit the parameter search to a low-rank\nsubspace and alter the training dynamics. Therefore, we propose a\nfull-parameter and parameter-efficient learning framework for endoscopic depth\nestimation. At the first stage, the subspace of attention, convolution and\nmulti-layer perception are adapted simultaneously within different sub-spaces.\nAt the second stage, a memory-efficient optimization is proposed for subspace\ncomposition and the performance is further improved in the united sub-space.\nInitial experiments on the SCARED dataset demonstrate that results at the first\nstage improves the performance from 10.2% to 4.1% for Sq Rel, Abs Rel, RMSE and\nRMSE log in the comparison with the state-of-the-art models.",
      "tldr_zh": "该论文针对内窥镜深度估计问题，提出了一种full-parameter and parameter-efficient自学习框架，以克服现有适应方法在参数搜索和训练动态方面的局限性。第一阶段，该框架同时适应注意力、卷积和多层感知器的不同子空间；第二阶段，通过内存高效的优化实现子空间组合，进一步提升性能。在SCARED数据集上的初步实验显示，与最先进模型相比，该方法将Sq Rel、Abs Rel、RMSE和RMSE log的性能从10.2%显著改善到4.1%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "WiCV @ ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00979v2",
      "published_date": "2024-10-01 18:08:56 UTC",
      "updated_date": "2024-10-10 03:48:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:37:54.497875"
    },
    {
      "arxiv_id": "2410.00897v1",
      "title": "The Gradient of Health Data Privacy",
      "title_zh": "健康数据隐私的梯度",
      "authors": [
        "Baihan Lin"
      ],
      "abstract": "In the era of digital health and artificial intelligence, the management of\npatient data privacy has become increasingly complex, with significant\nimplications for global health equity and patient trust. This paper introduces\na novel \"privacy gradient\" approach to health data governance, offering a more\nnuanced and adaptive framework than traditional binary privacy models. Our\nmultidimensional concept considers factors such as data sensitivity,\nstakeholder relationships, purpose of use, and temporal aspects, allowing for\ncontext-sensitive privacy protections. Through policy analyses, ethical\nconsiderations, and case studies spanning adolescent health, integrated care,\nand genomic research, we demonstrate how this approach can address critical\nprivacy challenges in diverse healthcare settings worldwide. The privacy\ngradient model has the potential to enhance patient engagement, improve care\ncoordination, and accelerate medical research while safeguarding individual\nprivacy rights. We provide policy recommendations for implementing this\napproach, considering its impact on healthcare systems, research\ninfrastructures, and global health initiatives. This work aims to inform\npolicymakers, healthcare leaders, and digital health innovators, contributing\nto a more equitable, trustworthy, and effective global health data ecosystem in\nthe digital age.",
      "tldr_zh": "这篇论文提出了“privacy gradient”方法，一种多维度的健康数据治理框架，比传统的二元隐私模型更具适应性和细致性，通过考虑数据敏感性、利益相关者关系、使用目的和时间因素，提供上下文敏感的隐私保护。研究通过政策分析、伦理评估以及青少年健康、综合护理和基因组研究的案例，展示了该方法在全球多样化医疗场景中解决隐私挑战的潜力。结果表明，“privacy gradient”模型能提升患者参与度、改善护理协调并加速医疗研究，同时维护个人隐私权，并为决策者提供政策推荐，以构建更公平、可信的全球健康数据生态。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "q-bio.OT"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00897v1",
      "published_date": "2024-10-01 17:35:18 UTC",
      "updated_date": "2024-10-01 17:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:38:05.908871"
    },
    {
      "arxiv_id": "2410.00880v1",
      "title": "GEMS: Generative Expert Metric System through Iterative Prompt Priming",
      "title_zh": "翻译失败",
      "authors": [
        "Ti-Chung Cheng",
        "Carmen Badea",
        "Christian Bird",
        "Thomas Zimmermann",
        "Robert DeLine",
        "Nicole Forsgren",
        "Denae Ford"
      ],
      "abstract": "Across domains, metrics and measurements are fundamental to identifying\nchallenges, informing decisions, and resolving conflicts. Despite the abundance\nof data available in this information age, not only can it be challenging for a\nsingle expert to work across multi-disciplinary data, but non-experts can also\nfind it unintuitive to create effective measures or transform theories into\ncontext-specific metrics that are chosen appropriately. This technical report\naddresses this challenge by examining software communities within large\nsoftware corporations, where different measures are used as proxies to locate\ncounterparts within the organization to transfer tacit knowledge. We propose a\nprompt-engineering framework inspired by neural activities, demonstrating that\ngenerative models can extract and summarize theories and perform basic\nreasoning, thereby transforming concepts into context-aware metrics to support\nsoftware communities given software repository data. While this research zoomed\nin on software communities, we believe the framework's applicability extends\nacross various fields, showcasing expert-theory-inspired metrics that aid in\ntriaging complex challenges.",
      "tldr_zh": "这篇论文提出了GEMS（Generative Expert Metric System），一种通过迭代提示启动（Iterative Prompt Priming）的框架，旨在帮助专家和非专家从多学科数据中提取理论、进行基本推理，并生成上下文相关的度量，以支持软件社区的知识转移。框架受神经活动启发，利用生成模型分析软件仓库数据，将抽象概念转化为具体指标，解决跨领域数据处理的挑战。研究结果表明，该系统不仅适用于软件社区，还可扩展到其他领域，用于识别问题、决策和冲突解决。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "29 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.00880v1",
      "published_date": "2024-10-01 17:14:54 UTC",
      "updated_date": "2024-10-01 17:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:38:17.999201"
    },
    {
      "arxiv_id": "2410.00872v1",
      "title": "Do Music Generation Models Encode Music Theory?",
      "title_zh": "音乐生成模型是否编码了音乐理论？",
      "authors": [
        "Megan Wei",
        "Michael Freeman",
        "Chris Donahue",
        "Chen Sun"
      ],
      "abstract": "Music foundation models possess impressive music generation capabilities.\nWhen people compose music, they may infuse their understanding of music into\ntheir work, by using notes and intervals to craft melodies, chords to build\nprogressions, and tempo to create a rhythmic feel. To what extent is this true\nof music generation models? More specifically, are fundamental Western music\ntheory concepts observable within the \"inner workings\" of these models? Recent\nwork proposed leveraging latent audio representations from music generation\nmodels towards music information retrieval tasks (e.g. genre classification,\nemotion recognition), which suggests that high-level musical characteristics\nare encoded within these models. However, probing individual music theory\nconcepts (e.g. tempo, pitch class, chord quality) remains under-explored. Thus,\nwe introduce SynTheory, a synthetic MIDI and audio music theory dataset,\nconsisting of tempos, time signatures, notes, intervals, scales, chords, and\nchord progressions concepts. We then propose a framework to probe for these\nmusic theory concepts in music foundation models (Jukebox and MusicGen) and\nassess how strongly they encode these concepts within their internal\nrepresentations. Our findings suggest that music theory concepts are\ndiscernible within foundation models and that the degree to which they are\ndetectable varies by model size and layer.",
      "tldr_zh": "本研究探讨了音乐生成模型（如 Jukebox 和 MusicGen）是否在内部表示中编码了西方音乐理论概念，例如音符、和弦和节奏。研究者引入了 SynTheory 数据集，这是一个合成 MIDI 和音频数据集，涵盖了节奏、音符、和弦等元素，并提出一个框架来探测这些概念在模型中的编码程度。结果显示，音乐理论概念在这些模型中是可以辨别的，且检测强度因模型大小和层而异，这为理解音乐生成模型的高级音乐特性提供了新洞见。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at ISMIR 2024. Dataset:\n  https://huggingface.co/datasets/meganwei/syntheory Code:\n  https://github.com/brown-palm/syntheory Website:\n  https://brown-palm.github.io/music-theory",
      "pdf_url": "http://arxiv.org/pdf/2410.00872v1",
      "published_date": "2024-10-01 17:06:30 UTC",
      "updated_date": "2024-10-01 17:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:38:29.502273"
    },
    {
      "arxiv_id": "2410.00871v2",
      "title": "MAP: Unleashing Hybrid Mamba-Transformer Vision Backbone's Potential with Masked Autoregressive Pretraining",
      "title_zh": "MAP：通过掩码自回归预训练释放混合 Mamba-Transformer 视觉主干网络的潜力",
      "authors": [
        "Yunze Liu",
        "Li Yi"
      ],
      "abstract": "Hybrid Mamba-Transformer networks have recently garnered broad attention.\nThese networks can leverage the scalability of Transformers while capitalizing\non Mamba's strengths in long-context modeling and computational efficiency.\nHowever, the challenge of effectively pretraining such hybrid networks remains\nan open question. Existing methods, such as Masked Autoencoders (MAE) or\nautoregressive (AR) pretraining, primarily focus on single-type network\narchitectures. In contrast, pretraining strategies for hybrid architectures\nmust be effective for both Mamba and Transformer components. Based on this, we\npropose Masked Autoregressive Pretraining (MAP) to pretrain a hybrid\nMamba-Transformer vision backbone network. This strategy combines the strengths\nof both MAE and Autoregressive pretraining, improving the performance of Mamba\nand Transformer modules within a unified paradigm. Experimental results show\nthat the hybrid Mamba-Transformer vision backbone network pretrained with MAP\nsignificantly outperforms other pretraining strategies, achieving\nstate-of-the-art performance. We validate the method's effectiveness on both 2D\nand 3D datasets and provide detailed ablation studies to support the design\nchoices for each component. The code and checkpoints are available at\nhttps://github.com/yunzeliu/MAP",
      "tldr_zh": "这篇论文提出了一种名为 MAP 的预训练策略，用于释放混合 Mamba-Transformer 视觉骨干网络的潜力，解决现有方法无法有效处理混合架构的问题。MAP 结合了 Masked Autoencoders (MAE) 和 Autoregressive (AR) 预训练的优势，在统一框架下提升 Mamba 和 Transformer 组件的表现。实验结果显示，采用 MAP 预训练的网络在 2D 和 3D 数据集上显著优于其他策略，达到了最先进性能，并通过详细的消融研究支持了关键设计选择。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00871v2",
      "published_date": "2024-10-01 17:05:08 UTC",
      "updated_date": "2025-03-15 15:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:38:42.831988"
    },
    {
      "arxiv_id": "2410.02828v1",
      "title": "PyRIT: A Framework for Security Risk Identification and Red Teaming in Generative AI System",
      "title_zh": "PyRIT：生成式 AI 系统中的安全风险识别和红队测试框架",
      "authors": [
        "Gary D. Lopez Munoz",
        "Amanda J. Minnich",
        "Roman Lutz",
        "Richard Lundeen",
        "Raja Sekhar Rao Dheekonda",
        "Nina Chikanov",
        "Bolor-Erdene Jagdagdorj",
        "Martin Pouliot",
        "Shiven Chawla",
        "Whitney Maxwell",
        "Blake Bullwinkel",
        "Katherine Pratt",
        "Joris de Gruyter",
        "Charlotte Siska",
        "Pete Bryan",
        "Tori Westerhoff",
        "Chang Kawaguchi",
        "Christian Seifert",
        "Ram Shankar Siva Kumar",
        "Yonatan Zunger"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) is becoming ubiquitous in our\ndaily lives. The increase in computational power and data availability has led\nto a proliferation of both single- and multi-modal models. As the GenAI\necosystem matures, the need for extensible and model-agnostic risk\nidentification frameworks is growing. To meet this need, we introduce the\nPython Risk Identification Toolkit (PyRIT), an open-source framework designed\nto enhance red teaming efforts in GenAI systems. PyRIT is a model- and\nplatform-agnostic tool that enables red teamers to probe for and identify novel\nharms, risks, and jailbreaks in multimodal generative AI models. Its composable\narchitecture facilitates the reuse of core building blocks and allows for\nextensibility to future models and modalities. This paper details the\nchallenges specific to red teaming generative AI systems, the development and\nfeatures of PyRIT, and its practical applications in real-world scenarios.",
      "tldr_zh": "本研究介绍了PyRIT（Python Risk Identification Toolkit），一个开源框架，旨在针对生成式人工智能(GenAI)系统进行安全风险识别和红队测试(red teaming)。PyRIT采用模型无关和平台无关的设计，支持多模态生成AI模型的探测，帮助识别新型危害、风险和越狱(jailbreaks)，并通过可组合架构实现核心组件的重用和未来扩展。论文详细阐述了红队测试的挑战、PyRIT的开发特性及其在真实场景中的实际应用，为GenAI生态系统的安全评估提供了实用工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02828v1",
      "published_date": "2024-10-01 17:00:59 UTC",
      "updated_date": "2024-10-01 17:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:38:53.749109"
    },
    {
      "arxiv_id": "2410.00807v1",
      "title": "WiGNet: Windowed Vision Graph Neural Network",
      "title_zh": "WiGNet：窗口化视觉图神经网络",
      "authors": [
        "Gabriele Spadaro",
        "Marco Grangetto",
        "Attilio Fiandrotti",
        "Enzo Tartaglione",
        "Jhony H. Giraldo"
      ],
      "abstract": "In recent years, Graph Neural Networks (GNNs) have demonstrated strong\nadaptability to various real-world challenges, with architectures such as\nVision GNN (ViG) achieving state-of-the-art performance in several computer\nvision tasks. However, their practical applicability is hindered by the\ncomputational complexity of constructing the graph, which scales quadratically\nwith the image size. In this paper, we introduce a novel Windowed vision Graph\nneural Network (WiGNet) model for efficient image processing. WiGNet explores a\ndifferent strategy from previous works by partitioning the image into windows\nand constructing a graph within each window. Therefore, our model uses graph\nconvolutions instead of the typical 2D convolution or self-attention mechanism.\nWiGNet effectively manages computational and memory complexity for large image\nsizes. We evaluate our method in the ImageNet-1k benchmark dataset and test the\nadaptability of WiGNet using the CelebA-HQ dataset as a downstream task with\nhigher-resolution images. In both of these scenarios, our method achieves\ncompetitive results compared to previous vision GNNs while keeping memory and\ncomputational complexity at bay. WiGNet offers a promising solution toward the\ndeployment of vision GNNs in real-world applications. We publicly released the\ncode at https://github.com/EIDOSLAB/WiGNet.",
      "tldr_zh": "这篇论文提出了 WiGNet，一种 Windowed Vision Graph Neural Network，用于高效处理图像问题，以解决传统 Graph Neural Networks (GNNs) 在构建图时计算复杂度随图像大小平方增长的挑战。WiGNet 通过将图像分区为窗口，并在每个窗口内构建图结构，使用图卷积代替传统的 2D 卷积或自注意力机制，从而显著降低计算和内存需求。在 ImageNet-1k 数据集上的基准测试中，WiGNet 实现了与现有 Vision GNNs 相当的性能，并在 CelebA-HQ 高分辨率任务上展示了良好的适应性。该方法为 GNNs 在实际应用中的部署提供了可行的解决方案，并公开了相关代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00807v1",
      "published_date": "2024-10-01 15:54:07 UTC",
      "updated_date": "2024-10-01 15:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:39:07.066038"
    },
    {
      "arxiv_id": "2410.00944v1",
      "title": "GAMMA-PD: Graph-based Analysis of Multi-Modal Motor Impairment Assessments in Parkinson's Disease",
      "title_zh": "GAMMA-PD",
      "authors": [
        "Favour Nerrise",
        "Alice Louise Heiman",
        "Ehsan Adeli"
      ],
      "abstract": "The rapid advancement of medical technology has led to an exponential\nincrease in multi-modal medical data, including imaging, genomics, and\nelectronic health records (EHRs). Graph neural networks (GNNs) have been widely\nused to represent this data due to their prominent performance in capturing\npairwise relationships. However, the heterogeneity and complexity of\nmulti-modal medical data still pose significant challenges for standard GNNs,\nwhich struggle with learning higher-order, non-pairwise relationships. This\npaper proposes GAMMA-PD (Graph-based Analysis of Multi-modal Motor Impairment\nAssessments in Parkinson's Disease), a novel heterogeneous hypergraph fusion\nframework for multi-modal clinical data analysis. GAMMA-PD integrates imaging\nand non-imaging data into a \"hypernetwork\" (patient population graph) by\npreserving higher-order information and similarity between patient profiles and\nsymptom subtypes. We also design a feature-based attention-weighted mechanism\nto interpret feature-level contributions towards downstream decision tasks. We\nevaluate our approach with clinical data from the Parkinson's Progression\nMarkers Initiative (PPMI) and a private dataset. We demonstrate gains in\npredicting motor impairment symptoms in Parkinson's disease. Our end-to-end\nframework also learns associations between subsets of patient characteristics\nto generate clinically relevant explanations for disease and symptom profiles.\nThe source code is available at https://github.com/favour-nerrise/GAMMA-PD.",
      "tldr_zh": "本研究提出GAMMA-PD，一种基于图神经网络（GNNs）的异构超图融合框架，用于分析帕金森病的多模态临床数据，包括影像和非影像信息。该框架通过构建“hypernetwork”（患者群体图）来保留更高阶关系和患者配置文件与症状子类型的相似性，并引入基于特征的注意力加权机制（feature-based attention-weighted mechanism）以解释特征在决策任务中的贡献。实验在Parkinson's Progression Markers Initiative (PPMI)数据集和私有数据集上验证，显示了在预测帕金森病运动障碍症状方面的显著改进，并能学习患者特征子集间的关联，提供临床相关的解释。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "q-bio.NC"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Accepted by the 6th Workshop on GRaphs in biomedicAl Image anaLysis\n  (GRAIL) at the 27th International Conference on Medical Image Computing and\n  Computer Assisted Intervention (MICCAI 2024). 12 pages, 3 figures, 2 tables,\n  Source Code: https://github.com/favour-nerrise/GAMMA-PD",
      "pdf_url": "http://arxiv.org/pdf/2410.00944v1",
      "published_date": "2024-10-01 15:51:33 UTC",
      "updated_date": "2024-10-01 15:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:39:18.323945"
    },
    {
      "arxiv_id": "2410.11617v1",
      "title": "M$^{2}$M: Learning controllable Multi of experts and multi-scale operators are the Partial Differential Equations need",
      "title_zh": "翻译失败",
      "authors": [
        "Aoming Liang",
        "Zhaoyang Mu",
        "Pengxiao Lin",
        "Cong Wang",
        "Mingming Ge",
        "Ling Shao",
        "Dixia Fan",
        "Hao Tang"
      ],
      "abstract": "Learning the evolutionary dynamics of Partial Differential Equations (PDEs)\nis critical in understanding dynamic systems, yet current methods\ninsufficiently learn their representations. This is largely due to the\nmulti-scale nature of the solution, where certain regions exhibit rapid\noscillations while others evolve more slowly. This paper introduces a framework\nof multi-scale and multi-expert (M$^2$M) neural operators designed to simulate\nand learn PDEs efficiently. We employ a divide-and-conquer strategy to train a\nmulti-expert gated network for the dynamic router policy. Our method\nincorporates a controllable prior gating mechanism that determines the\nselection rights of experts, enhancing the model's efficiency. To optimize the\nlearning process, we have implemented a PI (Proportional, Integral) control\nstrategy to adjust the allocation rules precisely. This universal controllable\napproach allows the model to achieve greater accuracy. We test our approach on\nbenchmark 2D Navier-Stokes equations and provide a custom multi-scale dataset.\nM$^2$M can achieve higher simulation accuracy and offer improved\ninterpretability compared to baseline methods.",
      "tldr_zh": "本研究针对 Partial Differential Equations (PDEs) 的多尺度性质（如某些区域快速震荡），提出 M²M 框架，该框架利用多专家(multi-expert)和多尺度(multi-scale)神经算子来高效模拟和学习 PDEs 的演化动态。\nM²M 采用 divide-and-conquer 策略训练多专家门控网络，并引入可控先验门控机制(controllable prior gating mechanism)和 PI (Proportional, Integral) 控制策略来精确调整专家分配，提升模型效率和准确性。\n在 2D Navier-Stokes equations 等基准数据集上的实验表明，M²M 比基线方法实现了更高的模拟准确性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11617v1",
      "published_date": "2024-10-01 15:42:09 UTC",
      "updated_date": "2024-10-01 15:42:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:39:30.600837"
    },
    {
      "arxiv_id": "2410.00774v1",
      "title": "Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction",
      "title_zh": "基于不确定性驱动的前瞻预测的自适应运动生成",
      "authors": [
        "Hyogo Hiruma",
        "Hiroshi Ito",
        "Tetusya Ogata"
      ],
      "abstract": "Uncertainty of environments has long been a difficult characteristic to\nhandle, when performing real-world robot tasks. This is because the uncertainty\nproduces unexpected observations that cannot be covered by manual scripting.\nLearning based robot controlling methods are a promising approach for\ngenerating flexible motions against unknown situations, but still tend to\nsuffer under uncertainty due to its deterministic nature. In order to\nadaptively perform the target task under such conditions, the robot control\nmodel must be able to accurately understand the possible uncertainty, and to\nexploratively derive the optimal action that minimizes such uncertainty. This\npaper extended an existing predictive learning based robot control method,\nwhich employ foresight prediction using dynamic internal simulation. The\nforesight module refines the model's hidden states by sampling multiple\npossible futures and replace with the one that led to the lower future\nuncertainty. The adaptiveness of the model was evaluated on a door opening\ntask. The door can be opened either by pushing, pulling, or sliding, but robot\ncannot visually distinguish which way, and is required to adapt on the fly. The\nresults showed that the proposed model adaptively diverged its motion through\ninteraction with the door, whereas conventional methods failed to stably\ndiverge. The models were analyzed on Lyapunov exponents of RNN hidden states\nwhich reflect the possible divergence at each time step during task execution.\nThe result indicated that the foresight module biased the model to consider\nfuture consequences, which lead to embedding uncertainties at the policy of the\nrobot controller, rather than the resultant observation. This is beneficial for\nimplementing adaptive behaviors, which indices derivation of diverse motion\nduring exploration.",
      "tldr_zh": "这篇论文提出了一种基于 Uncertainty-Driven Foresight Prediction 的自适应运动生成方法，以应对机器人任务中环境不确定性带来的挑战。该方法扩展了现有的预测学习框架，通过 foresight module 采样多个可能的未来场景，并选择降低未来不确定性的路径来精炼模型的隐藏状态。在开门任务实验中，该模型展示了通过交互实现的自适应动作多样性，而传统方法则无法稳定适应；此外，分析 RNN 隐藏状态的 Lyapunov exponents 表明，该方法在策略层面嵌入不确定性，促进了探索和行为优化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00774v1",
      "published_date": "2024-10-01 15:13:27 UTC",
      "updated_date": "2024-10-01 15:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:39:42.254034"
    },
    {
      "arxiv_id": "2410.00773v1",
      "title": "BabelBench: An Omni Benchmark for Code-Driven Analysis of Multimodal and Multistructured Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xuwu Wang",
        "Qiwen Cui",
        "Yunzhe Tao",
        "Yiran Wang",
        "Ziwei Chai",
        "Xiaotian Han",
        "Boyi Liu",
        "Jianbo Yuan",
        "Jing Su",
        "Guoyin Wang",
        "Tingkai Liu",
        "Liyu Chen",
        "Tianyi Liu",
        "Tao Sun",
        "Yufeng Zhang",
        "Sirui Zheng",
        "Quanzeng You",
        "Yang Yang",
        "Hongxia Yang"
      ],
      "abstract": "Large language models (LLMs) have become increasingly pivotal across various\ndomains, especially in handling complex data types. This includes structured\ndata processing, as exemplified by ChartQA and ChatGPT-Ada, and multimodal\nunstructured data processing as seen in Visual Question Answering (VQA). These\nareas have attracted significant attention from both industry and academia.\nDespite this, there remains a lack of unified evaluation methodologies for\nthese diverse data handling scenarios. In response, we introduce BabelBench, an\ninnovative benchmark framework that evaluates the proficiency of LLMs in\nmanaging multimodal multistructured data with code execution. BabelBench\nincorporates a dataset comprising 247 meticulously curated problems that\nchallenge the models with tasks in perception, commonsense reasoning, logical\nreasoning, and so on. Besides the basic capabilities of multimodal\nunderstanding, structured data processing as well as code generation, these\ntasks demand advanced capabilities in exploration, planning, reasoning and\ndebugging. Our experimental findings on BabelBench indicate that even\ncutting-edge models like ChatGPT 4 exhibit substantial room for improvement.\nThe insights derived from our comprehensive analysis offer valuable guidance\nfor future research within the community. The benchmark data can be found at\nhttps://github.com/FFD8FFE/babelbench.",
      "tldr_zh": "这篇论文引入了 BabelBench，一个综合基准框架，用于评估 LLMs 在处理多模态多结构数据时的能力，通过代码执行来统一测试各种场景。BabelBench 包含 247 个精心策划的问题，涵盖感知、常识推理、逻辑推理等任务，并要求模型具备多模态理解、结构化数据处理、代码生成以及高级能力如探索、规划和调试。实验结果显示，即使是先进的 ChatGPT 4 模型仍有显著改进空间，为 LLMs 研究社区提供宝贵指导和数据集（可从 https://github.com/FFD8FFE/babelbench 获取）。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00773v1",
      "published_date": "2024-10-01 15:11:24 UTC",
      "updated_date": "2024-10-01 15:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:39:54.601000"
    },
    {
      "arxiv_id": "2410.00726v3",
      "title": "LTLf Synthesis on First-Order Agent Programs in Nondeterministic Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Till Hofmann",
        "Jens Claßen"
      ],
      "abstract": "We investigate the synthesis of policies for high-level agent programs\nexpressed in Golog, a language based on situation calculus that incorporates\nnondeterministic programming constructs. Unlike traditional approaches for\nprogram realization that assume full agent control or rely on incremental\nsearch, we address scenarios where environmental nondeterminism significantly\ninfluences program outcomes. Our synthesis problem involves deriving a policy\nthat successfully realizes a given Golog program while ensuring the\nsatisfaction of a temporal specification, expressed in Linear Temporal Logic on\nfinite traces (LTLf), across all possible environmental behaviors. By\nleveraging an expressive class of first-order action theories, we construct a\nfinite game arena that encapsulates program executions and tracks the\nsatisfaction of the temporal goal. A game-theoretic approach is employed to\nderive such a policy. Experimental results demonstrate this approach's\nfeasibility in domains with unbounded objects and non-local effects. This work\nbridges agent programming and temporal logic synthesis, providing a framework\nfor robust agent behavior in nondeterministic environments.",
      "tldr_zh": "本文研究了在非确定性环境中，为基于情境演算(situation calculus)的Golog代理程序合成策略，以确保程序成功执行并满足LTLf（线性时序逻辑在有限轨迹上）规范，无论环境行为如何。方法利用一阶动作理论(first-order action theories)构建有限游戏竞技场(game arena)，并采用博弈论(game-theoretic)方法推导鲁棒策略。实验结果证明，该框架在具有无界对象和非局部效应的领域中可行，并为代理编程和时序逻辑合成提供了一个桥接框架。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI'25",
      "pdf_url": "http://arxiv.org/pdf/2410.00726v3",
      "published_date": "2024-10-01 14:15:14 UTC",
      "updated_date": "2025-03-01 20:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:40:06.022748"
    },
    {
      "arxiv_id": "2410.00704v1",
      "title": "Contrastive Abstraction for Reinforcement Learning",
      "title_zh": "强化学习的对比抽象",
      "authors": [
        "Vihang Patil",
        "Markus Hofmarcher",
        "Elisabeth Rumetshofer",
        "Sepp Hochreiter"
      ],
      "abstract": "Learning agents with reinforcement learning is difficult when dealing with\nlong trajectories that involve a large number of states. To address these\nlearning problems effectively, the number of states can be reduced by abstract\nrepresentations that cluster states. In principle, deep reinforcement learning\ncan find abstract states, but end-to-end learning is unstable. We propose\ncontrastive abstraction learning to find abstract states, where we assume that\nsuccessive states in a trajectory belong to the same abstract state. Such\nabstract states may be basic locations, achieved subgoals, inventory, or health\nconditions. Contrastive abstraction learning first constructs clusters of state\nrepresentations by contrastive learning and then applies modern Hopfield\nnetworks to determine the abstract states. The first phase of contrastive\nabstraction learning is self-supervised learning, where contrastive learning\nforces states with sequential proximity to have similar representations. The\nsecond phase uses modern Hopfield networks to map similar state representations\nto the same fixed point, i.e.\\ to an abstract state. The level of abstraction\ncan be adjusted by determining the number of fixed points of the modern\nHopfield network. Furthermore, \\textit{contrastive abstraction learning} does\nnot require rewards and facilitates efficient reinforcement learning for a wide\nrange of downstream tasks. Our experiments demonstrate the effectiveness of\ncontrastive abstraction learning for reinforcement learning.",
      "tldr_zh": "这篇论文提出了一种名为Contrastive Abstraction Learning的方法，用于简化强化学习中长轨迹和大量状态的处理问题。该方法通过Contrastive Learning构建状态表示的聚类，使轨迹中连续状态具有相似表示，然后利用Modern Hopfield Networks将这些表示映射到同一抽象状态（如位置或子目标），并可调整抽象级别。Contrastive Abstraction Learning不依赖奖励信号，能促进各种下游任务的强化学习效率。实验结果证明了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00704v1",
      "published_date": "2024-10-01 13:56:09 UTC",
      "updated_date": "2024-10-01 13:56:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:40:18.310988"
    },
    {
      "arxiv_id": "2410.00700v3",
      "title": "Mining Your Own Secrets: Diffusion Classifier Scores for Continual Personalization of Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Saurav Jha",
        "Shiqi Yang",
        "Masato Ishii",
        "Mengjie Zhao",
        "Christian Simon",
        "Muhammad Jehanzeb Mirza",
        "Dong Gong",
        "Lina Yao",
        "Shusuke Takahashi",
        "Yuki Mitsufuji"
      ],
      "abstract": "Personalized text-to-image diffusion models have grown popular for their\nability to efficiently acquire a new concept from user-defined text\ndescriptions and a few images. However, in the real world, a user may wish to\npersonalize a model on multiple concepts but one at a time, with no access to\nthe data from previous concepts due to storage/privacy concerns. When faced\nwith this continual learning (CL) setup, most personalization methods fail to\nfind a balance between acquiring new concepts and retaining previous ones -- a\nchallenge that continual personalization (CP) aims to solve. Inspired by the\nsuccessful CL methods that rely on class-specific information for\nregularization, we resort to the inherent class-conditioned density estimates,\nalso known as diffusion classifier (DC) scores, for continual personalization\nof text-to-image diffusion models. Namely, we propose using DC scores for\nregularizing the parameter-space and function-space of text-to-image diffusion\nmodels, to achieve continual personalization. Using several diverse evaluation\nsetups, datasets, and metrics, we show that our proposed regularization-based\nCP methods outperform the state-of-the-art C-LoRA, and other baselines.\nFinally, by operating in the replay-free CL setup and on low-rank adapters, our\nmethod incurs zero storage and parameter overhead, respectively, over the\nstate-of-the-art. Our project page:\nhttps://srvcodes.github.io/continual_personalization/",
      "tldr_zh": "该论文探讨了个性化文本-to-image扩散模型（text-to-image diffusion models）在持续学习（continual learning, CL）设置下的挑战，即用户希望逐步学习多个概念，但无法访问先前数据以避免存储和隐私问题。作者提出一种新方法，使用diffusion classifier (DC) scores对模型的参数空间和函数空间进行正则化，实现continual personalization（CP），从而平衡新概念获取与旧概念保留。实验结果显示，该方法在多种评估设置、数据集和指标上优于最先进基线C-LoRA，且采用无重放（replay-free）机制和低秩适配器，确保零存储和参数开销。总的来说，此方法为高效、隐私友好的模型个性化提供了可行方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.00700v3",
      "published_date": "2024-10-01 13:54:29 UTC",
      "updated_date": "2025-02-10 04:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:40:30.623731"
    },
    {
      "arxiv_id": "2410.00690v2",
      "title": "Beyond Minimax Rates in Group Distributionally Robust Optimization via a Novel Notion of Sparsity",
      "title_zh": "超越群组分布鲁棒优化中的最小最大率：通过一种新颖的稀疏性概念",
      "authors": [
        "Quan Nguyen",
        "Nishant A. Mehta",
        "Cristóbal Guzmán"
      ],
      "abstract": "The minimax sample complexity of group distributionally robust optimization\n(GDRO) has been determined up to a $\\log(K)$ factor, where $K$ is the number of\ngroups. In this work, we venture beyond the minimax perspective via a novel\nnotion of sparsity that we dub $(\\lambda, \\beta)$-sparsity. In short, this\ncondition means that at any parameter $\\theta$, there is a set of at most\n$\\beta$ groups whose risks at $\\theta$ all are at least $\\lambda$ larger than\nthe risks of the other groups. To find an $\\epsilon$-optimal $\\theta$, we show\nvia a novel algorithm and analysis that the $\\epsilon$-dependent term in the\nsample complexity can swap a linear dependence on $K$ for a linear dependence\non the potentially much smaller $\\beta$. This improvement leverages recent\nprogress in sleeping bandits, showing a fundamental connection between the\ntwo-player zero-sum game optimization framework for GDRO and per-action regret\nbounds in sleeping bandits. We next show an adaptive algorithm which, up to log\nfactors, gets a sample complexity bound that adapts to the best $(\\lambda,\n\\beta)$-sparsity condition that holds. We also show how to get a dimension-free\nsemi-adaptive sample complexity bound with a computationally efficient method.\nFinally, we demonstrate the practicality of the $(\\lambda, \\beta)$-sparsity\ncondition and the improved sample efficiency of our algorithms on both\nsynthetic and real-life datasets.",
      "tldr_zh": "本文在GDRO（Group Distributionally Robust Optimization）领域超越了minimax样本复杂度界限，引入了新的（λ, β）-sparsity概念，该概念表示在任何参数θ下，只有一小部分组（最多β组）的风险比其他组高出至少λ，从而潜在地减少计算需求。研究提出了一种新算法，利用sleeping bandits的进展，将样本复杂度从线性依赖组数K改为依赖更小的β，实现显著效率提升。该算法还包括自适应版本，能根据最佳（λ, β）-sparsity条件优化样本复杂度，并提供一个维度无关的计算高效方法。实验在合成和真实数据集上验证了该概念和算法的实用性，展示了改进的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "44 pages. V2: updated a semi-adaptive approach and experimental\n  results",
      "pdf_url": "http://arxiv.org/pdf/2410.00690v2",
      "published_date": "2024-10-01 13:45:55 UTC",
      "updated_date": "2025-01-31 02:51:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:40:42.801844"
    },
    {
      "arxiv_id": "2410.00689v2",
      "title": "Multimodal Auto Validation For Self-Refinement in Web Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ruhana Azam",
        "Tamer Abuelsaad",
        "Aditya Vempaty",
        "Ashish Jagmohan"
      ],
      "abstract": "As our world digitizes, web agents that can automate complex and monotonous\ntasks are becoming essential in streamlining workflows. This paper introduces\nan approach to improving web agent performance through multi-modal validation\nand self-refinement. We present a comprehensive study of different modalities\n(text, vision) and the effect of hierarchy for the automatic validation of web\nagents, building upon the state-of-the-art Agent-E web automation framework. We\nalso introduce a self-refinement mechanism for web automation, using the\ndeveloped auto-validator, that enables web agents to detect and self-correct\nworkflow failures. Our results show significant gains on Agent-E's (a SOTA web\nagent) prior state-of-art performance, boosting task-completion rates from\n76.2\\% to 81.24\\% on the subset of the WebVoyager benchmark. The approach\npresented in this paper paves the way for more reliable digital assistants in\ncomplex, real-world scenarios.",
      "tldr_zh": "这篇论文提出了一种 Multimodal Auto Validation 方法，用于提升 Web Agents 的性能，通过整合文本和视觉模态以及层次结构，实现自动验证和自我完善机制。基于 Agent-E 框架，他们研究了这些模态对网络代理的影响，并引入自检系统来检测并纠正工作流失败。实验结果显示，在 WebVoyager 基准测试的子集上，任务完成率从 76.2% 提高到 81.24%。这种方法为更可靠的数字助手在复杂真实场景中铺平了道路。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00689v2",
      "published_date": "2024-10-01 13:43:55 UTC",
      "updated_date": "2024-10-11 15:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:40:54.265853"
    },
    {
      "arxiv_id": "2410.00683v1",
      "title": "Efficient Technical Term Translation: A Knowledge Distillation Approach for Parenthetical Terminology Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyoon Myung",
        "Jihyeon Park",
        "Jungki Son",
        "Kyungro Lee",
        "Joohyung Han"
      ],
      "abstract": "This paper addresses the challenge of accurately translating technical terms,\nwhich are crucial for clear communication in specialized fields. We introduce\nthe Parenthetical Terminology Translation (PTT) task, designed to mitigate\npotential inaccuracies by displaying the original term in parentheses alongside\nits translation. To implement this approach, we generated a representative PTT\ndataset using a collaborative approach with large language models and applied\nknowledge distillation to fine-tune traditional Neural Machine Translation\n(NMT) models and small-sized Large Language Models (sLMs). Additionally, we\ndeveloped a novel evaluation metric to assess both overall translation accuracy\nand the correct parenthetical presentation of terms. Our findings indicate that\nsLMs did not consistently outperform NMT models, with fine-tuning proving more\neffective than few-shot prompting, particularly in models with continued\npre-training in the target language. These insights contribute to the\nadvancement of more reliable terminology translation methodologies.",
      "tldr_zh": "这篇论文针对技术术语翻译的准确性挑战，提出了 Parenthetical Terminology Translation (PTT) 任务，该方法通过在翻译结果中添加原术语括号来提升专业领域的沟通清晰度。研究者使用大型语言模型生成 PTT 数据集，并应用 Knowledge Distillation 来微调 Neural Machine Translation (NMT) 模型和小型 Large Language Models (sLMs)。他们还开发了一个新评估指标，用于同时评估整体翻译准确性和术语的括号呈现效果。实验结果显示，sLMs 未持续优于 NMT 模型，而微调比 Few-Shot Prompting 更有效，为推进更可靠的术语翻译方法提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted in EMNLPW 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00683v1",
      "published_date": "2024-10-01 13:40:28 UTC",
      "updated_date": "2024-10-01 13:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:41:17.074907"
    },
    {
      "arxiv_id": "2410.00681v1",
      "title": "Advanced Arabic Alphabet Sign Language Recognition Using Transfer Learning and Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mazen Balat",
        "Rewaa Awaad",
        "Hend Adel",
        "Ahmed B. Zaky",
        "Salah A. Aly"
      ],
      "abstract": "This paper presents an Arabic Alphabet Sign Language recognition approach,\nusing deep learning methods in conjunction with transfer learning and\ntransformer-based models. We study the performance of the different variants on\ntwo publicly available datasets, namely ArSL2018 and AASL. This task will make\nfull use of state-of-the-art CNN architectures like ResNet50, MobileNetV2, and\nEfficientNetB7, and the latest transformer models such as Google ViT and\nMicrosoft Swin Transformer. These pre-trained models have been fine-tuned on\nthe above datasets in an attempt to capture some unique features of Arabic sign\nlanguage motions. Experimental results present evidence that the suggested\nmethodology can receive a high recognition accuracy, by up to 99.6\\% and\n99.43\\% on ArSL2018 and AASL, respectively. That is far beyond the previously\nreported state-of-the-art approaches. This performance opens up even more\navenues for communication that may be more accessible to Arabic-speaking deaf\nand hard-of-hearing, and thus encourages an inclusive society.",
      "tldr_zh": "本论文提出了一种先进的阿拉伯字母手语识别方法，利用Transfer Learning和Transformer Models相结合的深度学习技术。研究者评估了ResNet50、MobileNetV2、EfficientNetB7、ViT和Swin Transformer等预训练模型在ArSL2018和AASL数据集上的性能，通过微调这些模型来捕捉阿拉伯手语的独特特征。实验结果显示，该方法在ArSL2018数据集上达到99.6%的识别准确率，在AASL上达到99.43%，远超现有最先进方法。该创新有望提升阿拉伯语聋哑人士的沟通便利性，促进更具包容性的社会。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.00681v1",
      "published_date": "2024-10-01 13:39:26 UTC",
      "updated_date": "2024-10-01 13:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:41:17.795765"
    },
    {
      "arxiv_id": "2410.12820v1",
      "title": "A transformer-based deep reinforcement learning approach to spatial navigation in a partially observable Morris Water Maze",
      "title_zh": "翻译失败",
      "authors": [
        "Marte Eggen",
        "Inga Strümke"
      ],
      "abstract": "Navigation is a fundamental cognitive skill extensively studied in\nneuroscientific experiments and has lately gained substantial interest in\nartificial intelligence research. Recreating the task solved by rodents in the\nwell-established Morris Water Maze (MWM) experiment, this work applies a\ntransformer-based architecture using deep reinforcement learning -- an approach\npreviously unexplored in this context -- to navigate a 2D version of the maze.\nSpecifically, the agent leverages a decoder-only transformer architecture\nserving as a deep Q-network performing effective decision making in the\npartially observable environment. We demonstrate that the proposed architecture\nenables the agent to efficiently learn spatial navigation strategies,\novercoming challenges associated with a limited field of vision, corresponding\nto the visual information available to a rodent in the MWM. Demonstrating the\npotential of transformer-based models for enhancing navigation performance in\npartially observable environments, this work suggests promising avenues for\nfuture research in artificial agents whose behavior resembles that of\nbiological agents. Finally, the flexibility of the transformer architecture in\nsupporting varying input sequence lengths opens opportunities for gaining\nincreased understanding of the artificial agent's inner representation of the\nenvironment.",
      "tldr_zh": "这篇论文提出了一种基于 transformer 的深度强化学习（deep reinforcement learning）方法，用于在部分可观测环境中模拟 Morris Water Maze (MWM) 的空间导航任务。代理采用 decoder-only transformer 架构作为 deep Q-network，实现高效决策并克服有限视野的挑战。实验结果表明，该方法使代理能够有效学习导航策略，提升性能，并为开发模仿生物行为的 AI 代理提供新思路，同时利用 transformer 的灵活性深化对环境表示的理解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12820v1",
      "published_date": "2024-10-01 13:22:56 UTC",
      "updated_date": "2024-10-01 13:22:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:41:29.994094"
    },
    {
      "arxiv_id": "2410.00659v1",
      "title": "Multimodal Coherent Explanation Generation of Robot Failures",
      "title_zh": "翻译失败",
      "authors": [
        "Pradip Pramanick",
        "Silvia Rossi"
      ],
      "abstract": "The explainability of a robot's actions is crucial to its acceptance in\nsocial spaces. Explaining why a robot fails to complete a given task is\nparticularly important for non-expert users to be aware of the robot's\ncapabilities and limitations. So far, research on explaining robot failures has\nonly considered generating textual explanations, even though several studies\nhave shown the benefits of multimodal ones. However, a simple combination of\nmultiple modalities may lead to semantic incoherence between the information\nacross different modalities - a problem that is not well-studied. An incoherent\nmultimodal explanation can be difficult to understand, and it may even become\ninconsistent with what the robot and the human observe and how they perform\nreasoning with the observations. Such inconsistencies may lead to wrong\nconclusions about the robot's capabilities. In this paper, we introduce an\napproach to generate coherent multimodal explanations by checking the logical\ncoherence of explanations from different modalities, followed by refinements as\nrequired. We propose a classification approach for coherence assessment, where\nwe evaluate if an explanation logically follows another. Our experiments\nsuggest that fine-tuning a neural network that was pre-trained to recognize\ntextual entailment, performs well for coherence assessment of multimodal\nexplanations. Code & data: https://pradippramanick.github.io/coherent-explain/.",
      "tldr_zh": "该研究强调机器人失败的可解释性对非专家用户至关重要，特别是通过多模态解释来揭示机器人的能力和限制，但简单组合多模态可能导致语义不一致问题。论文提出一种生成连贯多模态解释的方法，包括检查不同模态之间逻辑连贯性（如一个解释是否逻辑上跟随另一个），并进行必要的refinements，使用基于分类的连贯性评估。实验结果显示，通过微调预训练的文本蕴含（textual entailment）神经网络，该方法能有效评估多模态解释的连贯性，并提供了相关代码和数据资源。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00659v1",
      "published_date": "2024-10-01 13:15:38 UTC",
      "updated_date": "2024-10-01 13:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:41:41.996978"
    },
    {
      "arxiv_id": "2410.00654v1",
      "title": "Explainable Multi-Stakeholder Job Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Roan Schellingerhout"
      ],
      "abstract": "Public opinion on recommender systems has become increasingly wary in recent\nyears. In line with this trend, lawmakers have also started to become more\ncritical of such systems, resulting in the introduction of new laws focusing on\naspects such as privacy, fairness, and explainability for recommender systems\nand AI at large. These concepts are especially crucial in high-risk domains\nsuch as recruitment. In recruitment specifically, decisions carry substantial\nweight, as the outcomes can significantly impact individuals' careers and\ncompanies' success. Additionally, there is a need for a multi-stakeholder\napproach, as these systems are used by job seekers, recruiters, and companies\nsimultaneously, each with its own requirements and expectations. In this paper,\nI summarize my current research on the topic of explainable, multi-stakeholder\njob recommender systems and set out a number of future research directions.",
      "tldr_zh": "该论文讨论了公众和立法者对推荐系统的担忧，包括隐私、公平性和可解释性，尤其在高风险领域如招聘决策中，这些因素会影响个人职业和公司成功。作者强调采用多利益相关者(multi-stakeholder)方法，以满足求职者、招聘者和公司等群体的需求。论文总结了当前在可解释(explainable)职位推荐系统方面的研究，并提出未来研究方向，以提升这些系统的透明度和有效性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 1 figure, to be published in ACM RecSys 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00654v1",
      "published_date": "2024-10-01 13:12:30 UTC",
      "updated_date": "2024-10-01 13:12:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:41:53.518627"
    },
    {
      "arxiv_id": "2410.00649v1",
      "title": "LASMP: Language Aided Subset Sampling Based Motion Planner",
      "title_zh": "翻译失败",
      "authors": [
        "Saswati Bhattacharjee",
        "Anirban Sinha",
        "Chinwe Ekenna"
      ],
      "abstract": "This paper presents the Language Aided Subset Sampling Based Motion Planner\n(LASMP), a system that helps mobile robots plan their movements by using\nnatural language instructions. LASMP uses a modified version of the Rapidly\nExploring Random Tree (RRT) method, which is guided by user-provided commands\nprocessed through a language model (RoBERTa). The system improves efficiency by\nfocusing on specific areas of the robot's workspace based on these\ninstructions, making it faster and less resource-intensive. Compared to\ntraditional RRT methods, LASMP reduces the number of nodes needed by 55% and\ncuts random sample queries by 80%, while still generating safe, collision-free\npaths. Tested in both simulated and real-world environments, LASMP has shown\nbetter performance in handling complex indoor scenarios. The results highlight\nthe potential of combining language processing with motion planning to make\nrobot navigation more efficient.",
      "tldr_zh": "本文提出LASMP系统，一种结合自然语言指令的运动规划框架，用于辅助移动机器人高效规划路径。LASMP基于修改的Rapidly Exploring Random Tree (RRT)方法，通过RoBERTa语言模型处理用户命令，聚焦特定工作区以提升效率。与传统RRT相比，该系统减少节点数量55%和随机样本查询80%，同时生成安全的无碰撞路径。在模拟和真实环境中测试，LASMP在复杂室内场景中表现出色，突显了语言处理与运动规划相结合的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.00649v1",
      "published_date": "2024-10-01 13:03:15 UTC",
      "updated_date": "2024-10-01 13:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:42:15.870112"
    },
    {
      "arxiv_id": "2410.00630v1",
      "title": "Cafca: High-quality Novel View Synthesis of Expressive Faces from Casual Few-shot Captures",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel C. Bühler",
        "Gengyan Li",
        "Erroll Wood",
        "Leonhard Helminger",
        "Xu Chen",
        "Tanmay Shah",
        "Daoye Wang",
        "Stephan Garbin",
        "Sergio Orts-Escolano",
        "Otmar Hilliges",
        "Dmitry Lagun",
        "Jérémy Riviere",
        "Paulo Gotardo",
        "Thabo Beeler",
        "Abhimitra Meka",
        "Kripasindhu Sarkar"
      ],
      "abstract": "Volumetric modeling and neural radiance field representations have\nrevolutionized 3D face capture and photorealistic novel view synthesis.\nHowever, these methods often require hundreds of multi-view input images and\nare thus inapplicable to cases with less than a handful of inputs. We present a\nnovel volumetric prior on human faces that allows for high-fidelity expressive\nface modeling from as few as three input views captured in the wild. Our key\ninsight is that an implicit prior trained on synthetic data alone can\ngeneralize to extremely challenging real-world identities and expressions and\nrender novel views with fine idiosyncratic details like wrinkles and eyelashes.\nWe leverage a 3D Morphable Face Model to synthesize a large training set,\nrendering each identity with different expressions, hair, clothing, and other\nassets. We then train a conditional Neural Radiance Field prior on this\nsynthetic dataset and, at inference time, fine-tune the model on a very sparse\nset of real images of a single subject. On average, the fine-tuning requires\nonly three inputs to cross the synthetic-to-real domain gap. The resulting\npersonalized 3D model reconstructs strong idiosyncratic facial expressions and\noutperforms the state-of-the-art in high-quality novel view synthesis of faces\nfrom sparse inputs in terms of perceptual and photo-metric quality.",
      "tldr_zh": "本研究提出Cafca框架，通过体积建模（volumetric modeling）和神经辐射场（Neural Radiance Fields）技术，从仅几张随意捕捉的输入图像（如3张）中实现高保真度的表达性面部新视图合成。核心创新是利用合成数据训练的隐式体积先验（volumetric prior），基于3D Morphable Face Model生成大量包含不同表情、头发和细节的训练集，然后在真实图像上进行微调，以跨越合成到真实领域的差距。实验结果显示，Cafca生成的个性化3D模型能精确重建特异性面部表情和细节（如皱纹和睫毛），在感知和光度质量上超越现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Siggraph Asia Conference Papers 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00630v1",
      "published_date": "2024-10-01 12:24:50 UTC",
      "updated_date": "2024-10-01 12:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:42:18.660307"
    },
    {
      "arxiv_id": "2410.00589v1",
      "title": "GERA: Geometric Embedding for Efficient Point Registration Analysis",
      "title_zh": "GERA：用于高效点云配准分析的几何嵌入",
      "authors": [
        "Geng Li",
        "Haozhi Cao",
        "Mingyang Liu",
        "Shenghai Yuan",
        "Jianfei Yang"
      ],
      "abstract": "Point cloud registration aims to provide estimated transformations to align\npoint clouds, which plays a crucial role in pose estimation of various\nnavigation systems, such as surgical guidance systems and autonomous vehicles.\nDespite the impressive performance of recent models on benchmark datasets, many\nrely on complex modules like KPConv and Transformers, which impose significant\ncomputational and memory demands. These requirements hinder their practical\napplication, particularly in resource-constrained environments such as mobile\nrobotics. In this paper, we propose a novel point cloud registration network\nthat leverages a pure MLP architecture, constructing geometric information\noffline. This approach eliminates the computational and memory burdens\nassociated with traditional complex feature extractors and significantly\nreduces inference time and resource consumption. Our method is the first to\nreplace 3D coordinate inputs with offline-constructed geometric encoding,\nimproving generalization and stability, as demonstrated by Maximum Mean\nDiscrepancy (MMD) comparisons. This efficient and accurate geometric\nrepresentation marks a significant advancement in point cloud analysis,\nparticularly for applications requiring fast and reliability.",
      "tldr_zh": "该论文提出 GERA，一种基于纯 MLP 架构的点云注册网络，通过离线构建几何编码来替换传统的 3D 坐标输入，从而提高效率并减少计算和内存需求。相比依赖复杂模块如 KPConv 和 Transformers 的现有方法，GERA 显著降低了推理时间和资源消耗，同时通过 Maximum Mean Discrepancy (MMD) 比较证明了其在泛化和稳定性方面的优势。总体而言，该方法为点云分析应用（如手术引导系统和自动车辆）提供了高效、可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00589v1",
      "published_date": "2024-10-01 11:19:56 UTC",
      "updated_date": "2024-10-01 11:19:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:42:30.242702"
    },
    {
      "arxiv_id": "2410.12817v1",
      "title": "Interactive Explainable Anomaly Detection for Industrial Settings",
      "title_zh": "工业环境中的交互式可解释异常检测",
      "authors": [
        "Daniel Gramelt",
        "Timon Höfer",
        "Ute Schmid"
      ],
      "abstract": "Being able to recognise defects in industrial objects is a key element of\nquality assurance in production lines. Our research focuses on visual anomaly\ndetection in RGB images. Although Convolutional Neural Networks (CNNs) achieve\nhigh accuracies in this task, end users in industrial environments receive the\nmodel's decisions without additional explanations. Therefore, it is of interest\nto enrich the model's outputs with further explanations to increase confidence\nin the model and speed up anomaly detection. In our work, we focus on (1)\nCNN-based classification models and (2) the further development of a\nmodel-agnostic explanation algorithm for black-box classifiers. Additionally,\n(3) we demonstrate how we can establish an interactive interface that allows\nusers to further correct the model's output. We present our NearCAIPI\nInteraction Framework, which improves AI through user interaction, and show how\nthis approach increases the system's trustworthiness. We also illustrate how\nNearCAIPI can integrate human feedback into an interactive process chain.",
      "tldr_zh": "本研究针对工业环境中的视觉异常检测，提出了一种交互式可解释方法，以提升对 RGB 图像中缺陷识别的信任度和效率。研究聚焦于（1）基于 CNNs 的分类模型，（2）开发模型无关的解释算法（model-agnostic explanation algorithm）来为黑箱分类器提供额外解释，以及（3）构建交互式界面允许用户修正模型输出。作者介绍了 NearCAIPI Interaction Framework，通过整合人类反馈实现用户交互，提升系统的可信度，并加速异常检测过程。实验结果表明，该框架能显著提高 AI 系统的可靠性，为工业质量保障提供更可信的工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12817v1",
      "published_date": "2024-10-01 11:06:38 UTC",
      "updated_date": "2024-10-01 11:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:42:51.924705"
    },
    {
      "arxiv_id": "2410.00564v3",
      "title": "Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Cheng",
        "Ruixi Qiao",
        "Yingwei Ma",
        "Binhua Li",
        "Gang Xiong",
        "Qinghai Miao",
        "Yongbin Li",
        "Yisheng Lv"
      ],
      "abstract": "A significant aspiration of offline reinforcement learning (RL) is to develop\na generalist agent with high capabilities from large and heterogeneous\ndatasets. However, prior approaches that scale offline RL either rely heavily\non expert trajectories or struggle to generalize to diverse unseen tasks.\nInspired by the excellent generalization of world model in conditional video\ngeneration, we explore the potential of image observation-based world model for\nscaling offline RL and enhancing generalization on novel tasks. In this paper,\nwe introduce JOWA: Jointly-Optimized World-Action model, an offline model-based\nRL agent pretrained on multiple Atari games with 6 billion tokens data to learn\ngeneral-purpose representation and decision-making ability. Our method jointly\noptimizes a world-action model through a shared transformer backbone, which\nstabilize temporal difference learning with large models during pretraining.\nMoreover, we propose a provably efficient and parallelizable planning algorithm\nto compensate for the Q-value estimation error and thus search out better\npolicies. Experimental results indicate that our largest agent, with 150\nmillion parameters, achieves 78.9% human-level performance on pretrained games\nusing only 10% subsampled offline data, outperforming existing state-of-the-art\nlarge-scale offline RL baselines by 31.6% on averange. Furthermore, JOWA scales\nfavorably with model capacity and can sample-efficiently transfer to novel\ngames using only 5k offline fine-tuning data (approximately 4 trajectories) per\ngame, demonstrating superior generalization. We will release codes and model\nweights at https://github.com/CJReinforce/JOWA",
      "tldr_zh": "本文提出 JOWA（Jointly-Optimized World-Action model），一种扩展离线强化学习（Offline RL）的框架，通过在多个 Atari 游戏上使用 60 亿 tokens 数据预训练，旨在提升代理的泛化和决策能力。JOWA 采用共享 Transformer 骨干网络联合优化世界-动作模型，并引入一个高效的并行规划算法来补偿 Q-value 估计错误，从而稳定时序差分学习。实验结果显示，1.5 亿参数的 JOWA 代理在使用 10% 子采样数据的条件下，在预训练游戏上达到 78.9% 人类水平表现，比现有基线平均高 31.6%。此外，JOWA 在模型容量上扩展良好，并能用仅 5k 离线微调数据高效转移到新游戏，展示出优越的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.00564v3",
      "published_date": "2024-10-01 10:25:03 UTC",
      "updated_date": "2025-03-03 02:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:42:55.715995"
    },
    {
      "arxiv_id": "2410.00558v1",
      "title": "AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Luo",
        "Xin Li",
        "Hongzhan Lin",
        "Jing Ma",
        "Lidong Bing"
      ],
      "abstract": "The impressive performance of proprietary LLMs like GPT4 in code generation\nhas led to a trend to replicate these capabilities in open-source models\nthrough knowledge distillation (e.g. Code Evol-Instruct). However, these\nefforts often neglect the crucial aspect of response quality, relying heavily\non teacher models for direct response distillation. This paradigm, especially\nfor complex instructions, can degrade the quality of synthesized data,\ncompromising the knowledge distillation process. To this end, our study\nintroduces the Adaptive Modular Response Evolution (AMR-Evol) framework, which\nemploys a two-stage process to refine response distillation. The first stage,\nmodular decomposition, breaks down the direct response into more manageable\nsub-modules. The second stage, adaptive response evolution, automatically\nevolves the response with the related function modules. Our experiments with\nthree popular code benchmarks (HumanEval, MBPP, and EvalPlus) attest to the\nsuperiority of the AMR-Evol framework over baseline response distillation\nmethods. By comparing with the open-source Code LLMs trained on a similar scale\nof data, we observed performance enhancements: more than +3.0 points on\nHumanEval-Plus and +1.0 points on MBPP-Plus, which underscores the\neffectiveness of our framework. Our codes are available at\nhttps://github.com/ChiYeungLaw/AMR-Evol.",
      "tldr_zh": "这篇论文引入了 Adaptive Modular Response Evolution (AMR-Evol) 框架，以改进大型语言模型 (LLMs) 在代码生成中的知识蒸馏过程。框架通过两阶段方法解决传统直接响应蒸馏的缺陷：首先进行 modular decomposition，将响应分解为更易管理的子模块；其次采用 adaptive response evolution，自动优化这些模块以提升响应质量。实验在 HumanEval、MBPP 和 EvalPlus 等基准上验证了其有效性，与基线方法相比，AMR-Evol 在 HumanEval-Plus 上提升超过 3.0 分，在 MBPP-Plus 上提升超过 1.0 分。该框架为开源 LLMs 的训练提供了更可靠的合成数据策略，并开源代码以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00558v1",
      "published_date": "2024-10-01 10:12:38 UTC",
      "updated_date": "2024-10-01 10:12:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:43:07.765616"
    },
    {
      "arxiv_id": "2410.00536v1",
      "title": "Arges: Spatio-Temporal Transformer for Ulcerative Colitis Severity Assessment in Endoscopy Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Krishna Chaitanya",
        "Pablo F. Damasceno",
        "Shreyas Fadnavis",
        "Pooya Mobadersany",
        "Chaitanya Parmar",
        "Emily Scherer",
        "Natalia Zemlianskaia",
        "Lindsey Surace",
        "Louis R. Ghanem",
        "Oana Gabriela Cula",
        "Tommaso Mansi",
        "Kristopher Standish"
      ],
      "abstract": "Accurate assessment of disease severity from endoscopy videos in ulcerative\ncolitis (UC) is crucial for evaluating drug efficacy in clinical trials.\nSeverity is often measured by the Mayo Endoscopic Subscore (MES) and Ulcerative\nColitis Endoscopic Index of Severity (UCEIS) score. However, expert MES/UCEIS\nannotation is time-consuming and susceptible to inter-rater variability,\nfactors addressable by automation. Automation attempts with frame-level labels\nface challenges in fully-supervised solutions due to the prevalence of\nvideo-level labels in clinical trials. CNN-based weakly-supervised models (WSL)\nwith end-to-end (e2e) training lack generalization to new disease scores and\nignore spatio-temporal information crucial for accurate scoring. To address\nthese limitations, we propose \"Arges\", a deep learning framework that utilizes\na transformer with positional encoding to incorporate spatio-temporal\ninformation from frame features to estimate disease severity scores in\nendoscopy video. Extracted features are derived from a foundation model\n(ArgesFM), pre-trained on a large diverse dataset from multiple clinical trials\n(61M frames, 3927 videos). We evaluate four UC disease severity scores,\nincluding MES and three UCEIS component scores. Test set evaluation indicates\nsignificant improvements, with F1 scores increasing by 4.1% for MES and 18.8%,\n6.6%, 3.8% for the three UCEIS component scores compared to state-of-the-art\nmethods. Prospective validation on previously unseen clinical trial data\nfurther demonstrates the model's successful generalization.",
      "tldr_zh": "本研究针对溃疡性结肠炎 (UC) 的内镜视频评估，提出 Arges 框架，利用时空 Transformer 和位置编码整合帧特征的时空信息，以自动化估计疾病严重程度分数，包括 Mayo Endoscopic Subscore (MES) 和 Ulcerative Colitis Endoscopic Index of Severity (UCEIS) 组件分数。Arges 基于预训练模型 ArgesFM（在 61M 帧和 3927 视频的大规模数据集上训练），解决了现有 CNN-based 弱监督学习 (WSL) 方法的泛化性和信息忽略问题。实验结果显示，与最先进方法相比，Arges 在测试集上使 MES 的 F1 分数提高 4.1%，UCEIS 组件分数分别提高 18.8%、6.6% 和 3.8%；此外，前瞻性验证证明了模型在未见数据上的成功泛化。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "12 pages, 2 figures, 5 tables, accepted at MLMI, MICCAI",
      "pdf_url": "http://arxiv.org/pdf/2410.00536v1",
      "published_date": "2024-10-01 09:23:14 UTC",
      "updated_date": "2024-10-01 09:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:43:18.667026"
    },
    {
      "arxiv_id": "2410.00535v3",
      "title": "The Causal Information Bottleneck and Optimal Causal Variable Abstractions",
      "title_zh": "因果信息瓶颈与最优因果变量抽象",
      "authors": [
        "Francisco N. F. Q. Simoes",
        "Mehdi Dastani",
        "Thijs van Ommen"
      ],
      "abstract": "To effectively study complex causal systems, it is often useful to construct\nabstractions of parts of the system by discarding irrelevant details while\npreserving key features. The Information Bottleneck (IB) method is a widely\nused approach to construct variable abstractions by compressing random\nvariables while retaining predictive power over a target variable. Traditional\nmethods like IB are purely statistical and ignore underlying causal structures,\nmaking them ill-suited for causal tasks. We propose the Causal Information\nBottleneck (CIB), a causal extension of the IB, which compresses a set of\nchosen variables while maintaining causal control over a target variable. This\nmethod produces abstractions of (sets of) variables which are causally\ninterpretable, give us insight about the interactions between the abstracted\nvariables and the target variable, and can be used when reasoning about\ninterventions. We present experimental results demonstrating that the learned\nabstractions accurately capture causal relations as intended.",
      "tldr_zh": "本研究针对复杂因果系统的分析，提出Causal Information Bottleneck (CIB) 方法，以解决传统Information Bottleneck (IB) 方法忽略底层因果结构的问题。CIB 通过压缩一组变量，同时保持对目标变量的因果控制，生成可解释的抽象变量，从而揭示变量间互动并支持干预推理。实验结果表明，该方法能准确捕捉预期的因果关系，为因果任务提供更可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to UAI 2025. Code available at\n  github.com/francisco-simoes/cib-optimization-psagd",
      "pdf_url": "http://arxiv.org/pdf/2410.00535v3",
      "published_date": "2024-10-01 09:21:29 UTC",
      "updated_date": "2025-02-11 13:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:43:39.989035"
    },
    {
      "arxiv_id": "2410.00531v1",
      "title": "TPI-LLM: Serving 70B-scale LLMs Efficiently on Low-resource Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Zonghang Li",
        "Wenjiao Feng",
        "Mohsen Guizani",
        "Hongfang Yu"
      ],
      "abstract": "Large model inference is shifting from cloud to edge due to concerns about\nthe privacy of user interaction data. However, edge devices often struggle with\nlimited computing power, memory, and bandwidth, requiring collaboration across\nmultiple devices to run and speed up LLM inference. Pipeline parallelism, the\nmainstream solution, is inefficient for single-user scenarios, while tensor\nparallelism struggles with frequent communications. In this paper, we argue\nthat tensor parallelism can be more effective than pipeline on low-resource\ndevices, and present a compute- and memory-efficient tensor parallel inference\nsystem, named TPI-LLM, to serve 70B-scale models. TPI-LLM keeps sensitive raw\ndata local in the users' devices and introduces a sliding window memory\nscheduler to dynamically manage layer weights during inference, with disk I/O\nlatency overlapped with the computation and communication. This allows larger\nmodels to run smoothly on memory-limited devices. We analyze the communication\nbottleneck and find that link latency, not bandwidth, emerges as the main\nissue, so a star-based allreduce algorithm is implemented. Through extensive\nexperiments on both emulated and real testbeds, TPI-LLM demonstrated over 80%\nless time-to-first-token and token latency compared to Accelerate, and over 90%\ncompared to Transformers and Galaxy, while cutting the peak memory footprint of\nLlama 2-70B by 90%, requiring only 3.1 GB of memory for 70B-scale models.",
      "tldr_zh": "该论文提出 TPI-LLM 系统，用于在低资源边缘设备上高效运行 70B 规模的 LLMs，解决隐私和资源限制问题。TPI-LLM 优化 Tensor parallelism，通过滑动窗口内存调度器动态管理层权重并重叠磁盘 I/O 与计算通信，同时采用星形 Allreduce 算法来缓解链接延迟瓶颈。实验结果显示，与 Accelerate 相比，TPI-LLM 减少超过 80% 的时间-to-first-token 和 token 延迟，并将 Llama 2-70B 的峰值内存占用降低 90%，只需 3.1 GB 内存。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "68T50",
        "I.2.11"
      ],
      "primary_category": "cs.DC",
      "comment": "This paper is currently under review. Find the code at\n  https://github.com/Lizonghang/TPI-LLM",
      "pdf_url": "http://arxiv.org/pdf/2410.00531v1",
      "published_date": "2024-10-01 09:18:56 UTC",
      "updated_date": "2024-10-01 09:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:43:45.679834"
    },
    {
      "arxiv_id": "2410.00519v1",
      "title": "Exploring the Learning Capabilities of Language Models using LEVERWORLDS",
      "title_zh": "使用 LEVERWORLDS 探索语言模型的学习能力",
      "authors": [
        "Eitan Wagner",
        "Amir Feder",
        "Omri Abend"
      ],
      "abstract": "Learning a model of a stochastic setting often involves learning both general\nstructure rules and specific properties of the instance. This paper\ninvestigates the interplay between learning the general and the specific in\nvarious learning methods, with emphasis on sample efficiency. We design a\nframework called {\\sc LeverWorlds}, which allows the generation of simple\nphysics-inspired worlds that follow a similar generative process with different\ndistributions, and their instances can be expressed in natural language. These\nworlds allow for controlled experiments to assess the sample complexity of\ndifferent learning methods. We experiment with classic learning algorithms as\nwell as Transformer language models, both with fine-tuning and In-Context\nLearning (ICL). Our general finding is that (1) Transformers generally succeed\nin the task; but (2) they are considerably less sample efficient than classic\nmethods that make stronger assumptions about the structure, such as Maximum\nLikelihood Estimation and Logistic Regression. This finding is in tension with\nthe recent tendency to use Transformers as general-purpose estimators. We\npropose an approach that leverages the ICL capabilities of contemporary\nlanguage models to apply simple algorithms for this type of data. Our\nexperiments show that models currently struggle with the task but show\npromising potential.",
      "tldr_zh": "本文使用 LEVERWORLDS 框架生成简单物理启发世界，以评估不同学习方法在随机环境中学习一般结构规则和特定属性的样本效率。实验比较了经典算法（如 Maximum Likelihood Estimation 和 Logistic Regression）与 Transformer 语言模型（通过微调和 In-Context Learning (ICL)），结果显示 Transformer 模型虽然能成功完成任务，但样本效率远低于经典方法。论文提出一种利用 ICL 能力应用简单算法的新方法，尽管当前模型在该任务上表现挣扎，但显示出潜在改进空间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00519v1",
      "published_date": "2024-10-01 09:02:13 UTC",
      "updated_date": "2024-10-01 09:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:43:55.259288"
    },
    {
      "arxiv_id": "2410.00517v1",
      "title": "Human-Robot Collaborative Minimum Time Search through Sub-priors in Ant Colony Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Oscar Gil Viyuela",
        "Alberto Sanfeliu"
      ],
      "abstract": "Human-Robot Collaboration (HRC) has evolved into a highly promising issue\nowing to the latest breakthroughs in Artificial Intelligence (AI) and\nHuman-Robot Interaction (HRI), among other reasons. This emerging growth\nincreases the need to design multi-agent algorithms that can manage also human\npreferences. This paper presents an extension of the Ant Colony Optimization\n(ACO) meta-heuristic to solve the Minimum Time Search (MTS) task, in the case\nwhere humans and robots perform an object searching task together. The proposed\nmodel consists of two main blocks. The first one is a convolutional neural\nnetwork (CNN) that provides the prior probabilities about where an object may\nbe from a segmented image. The second one is the Sub-prior MTS-ACO algorithm\n(SP-MTS-ACO), which takes as inputs the prior probabilities and the particular\nsearch preferences of the agents in different sub-priors to generate search\nplans for all agents. The model has been tested in real experiments for the\njoint search of an object through a Vizanti web-based visualization in a tablet\ncomputer. The designed interface allows the communication between a human and\nour humanoid robot named IVO. The obtained results show an improvement in the\nsearch perception of the users without loss of efficiency.",
      "tldr_zh": "这篇论文扩展了 Ant Colony Optimization (ACO) 算法，用于 Human-Robot Collaboration (HRC) 中的 Minimum Time Search (MTS) 任务，以整合人类偏好和多代理搜索。模型包括一个 Convolutional Neural Network (CNN) 来从分割图像中生成对象的先验概率，以及 Sub-prior MTS-ACO (SP-MTS-ACO) 算法，该算法结合这些概率和代理的特定偏好来创建高效搜索计划。实验通过 Vizanti 网页可视化工具在平板电脑上进行，人与机器人 IVO 协作搜索物体，结果显示该方法显著提升了用户的搜索感知，同时保持了整体效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00517v1",
      "published_date": "2024-10-01 08:57:28 UTC",
      "updated_date": "2024-10-01 08:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:44:06.333124"
    },
    {
      "arxiv_id": "2410.00516v1",
      "title": "Enhancing Sentinel-2 Image Resolution: Evaluating Advanced Techniques based on Convolutional and Generative Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Kramer",
        "Alexander Steinhardt",
        "Barbara Pedretscher"
      ],
      "abstract": "This paper investigates the enhancement of spatial resolution in Sentinel-2\nbands that contain spectral information using advanced super-resolution\ntechniques by a factor of 2. State-of-the-art CNN models are compared with\nenhanced GAN approaches in terms of quality and feasibility. Therefore, a\nrepresentative dataset comprising Sentinel-2 low-resolution images and\ncorresponding high-resolution aerial orthophotos is required. Literature study\nreveals no feasible dataset for the land type of interest (forests), for which\nreason an adequate dataset had to be generated in addition, accounting for\naccurate alignment and image source optimization. The results reveal that while\nCNN-based approaches produce satisfactory outcomes, they tend to yield blurry\nimages. In contrast, GAN-based models not only provide clear and detailed\nimages, but also demonstrate superior performance in terms of quantitative\nassessment, underlying the potential of the framework beyond the specific land\ntype investigated.",
      "tldr_zh": "本研究评估了基于CNN和GAN的先进超分辨率技术，以将Sentinel-2图像的空间分辨率提升2倍，重点关注包含光谱信息的波段。研究者通过生成一个新的代表性数据集，包括Sentinel-2低分辨率图像和高分辨率航空正射照片，并确保精确对齐和优化图像来源，来比较CNN和增强GAN方法的质量及可行性。结果显示，CNN方法虽能产生满意图像，但往往模糊不清，而GAN方法提供更清晰、详细的输出，并在定量评估中表现出色，证明了该框架在森林等土地类型之外的更广泛潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2410.00516v1",
      "published_date": "2024-10-01 08:56:46 UTC",
      "updated_date": "2024-10-01 08:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:44:17.325772"
    },
    {
      "arxiv_id": "2410.00513v1",
      "title": "Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing",
      "title_zh": "翻译失败",
      "authors": [
        "Deokhyung Kang",
        "Seonjeong Hwang",
        "Yunsu Kim",
        "Gary Geunbae Lee"
      ],
      "abstract": "Recent efforts have aimed to utilize multilingual pretrained language models\n(mPLMs) to extend semantic parsing (SP) across multiple languages without\nrequiring extensive annotations. However, achieving zero-shot cross-lingual\ntransfer for SP remains challenging, leading to a performance gap between\nsource and target languages. In this study, we propose Cross-Lingual\nBack-Parsing (CBP), a novel data augmentation methodology designed to enhance\ncross-lingual transfer for SP. Leveraging the representation geometry of the\nmPLMs, CBP synthesizes target language utterances from source meaning\nrepresentations. Our methodology effectively performs cross-lingual data\naugmentation in challenging zero-resource settings, by utilizing only labeled\ndata in the source language and monolingual corpora. Extensive experiments on\ntwo cross-language SP benchmarks (Mschema2QA and Xspider) demonstrate that CBP\nbrings substantial gains in the target language. Further analysis of the\nsynthesized utterances shows that our method successfully generates target\nlanguage utterances with high slot value alignment rates while preserving\nsemantic integrity. Our codes and data are publicly available at\nhttps://github.com/deokhk/CBP.",
      "tldr_zh": "本文提出 Cross-Lingual Back-Parsing (CBP)，一种创新的数据增强方法，旨在提升语义解析 (SP) 在零资源设置下的跨语言转移性能，通过利用 multilingual pretrained language models (mPLMs) 的表示几何从源语言含义表示合成目标语言语句。CBP 只需源语言的标注数据和单语言语料，即可生成高质量的增强数据，确保合成的语句具有高槽值对齐率并保持语义完整性。在 Mschema2QA 和 Xspider 等基准实验中，CBP 显著提高了目标语言的性能，缩小了源语言与目标语言的差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00513v1",
      "published_date": "2024-10-01 08:53:38 UTC",
      "updated_date": "2024-10-01 08:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:44:33.653538"
    },
    {
      "arxiv_id": "2410.00511v1",
      "title": "Pre-training with Synthetic Patterns for Audio",
      "title_zh": "使用合成模式进行音频预训练",
      "authors": [
        "Yuchi Ishikawa",
        "Tatsuya Komatsu",
        "Yoshimitsu Aoki"
      ],
      "abstract": "In this paper, we propose to pre-train audio encoders using synthetic\npatterns instead of real audio data. Our proposed framework consists of two key\nelements. The first one is Masked Autoencoder (MAE), a self-supervised learning\nframework that learns from reconstructing data from randomly masked\ncounterparts. MAEs tend to focus on low-level information such as visual\npatterns and regularities within data. Therefore, it is unimportant what is\nportrayed in the input, whether it be images, audio mel-spectrograms, or even\nsynthetic patterns. This leads to the second key element, which is synthetic\ndata. Synthetic data, unlike real audio, is free from privacy and licensing\ninfringement issues. By combining MAEs and synthetic patterns, our framework\nenables the model to learn generalized feature representations without real\ndata, while addressing the issues related to real audio. To evaluate the\nefficacy of our framework, we conduct extensive experiments across a total of\n13 audio tasks and 17 synthetic datasets. The experiments provide insights into\nwhich types of synthetic patterns are effective for audio. Our results\ndemonstrate that our framework achieves performance comparable to models\npre-trained on AudioSet-2M and partially outperforms image-based pre-training\nmethods.",
      "tldr_zh": "本论文提出了一种使用合成模式预训练音频编码器的框架，以避免使用真实音频数据带来的隐私和许可问题。该框架的核心元素包括 Masked Autoencoder (MAE)，一种自监督学习方法，通过从随机掩码的数据中重建来学习泛化特征表示，并结合合成数据来专注于低级模式和规律。实验在13个音频任务和17个合成数据集上进行，结果显示该框架的性能与使用AudioSet-2M预训练的模型相当，并在某些方面优于基于图像的预训练方法。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to ICASSP'25",
      "pdf_url": "http://arxiv.org/pdf/2410.00511v1",
      "published_date": "2024-10-01 08:52:35 UTC",
      "updated_date": "2024-10-01 08:52:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:44:45.134863"
    },
    {
      "arxiv_id": "2410.00508v2",
      "title": "FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Mingye Zhu",
        "Yi Liu",
        "Quan Wang",
        "Junbo Guo",
        "Zhendong Mao"
      ],
      "abstract": "Recent breakthroughs in preference alignment have significantly improved\nLarge Language Models' ability to generate texts that align with human\npreferences and values. However, current alignment metrics typically emphasize\nthe post-hoc overall improvement, while overlooking a critical aspect:\nregression, which refers to the backsliding on previously correctly-handled\ndata after updates. This potential pitfall may arise from excessive fine-tuning\non already well-aligned data, which subsequently leads to over-alignment and\ndegeneration. To address this challenge, we propose FlipGuard, a constrained\noptimization approach to detect and mitigate update regression with focal\nattention. Specifically, FlipGuard identifies performance degradation using a\ncustomized reward characterization and strategically enforces a constraint to\nencourage conditional congruence with the pre-aligned model during training.\nComprehensive experiments demonstrate that FlipGuard effectively alleviates\nupdate regression while demonstrating excellent overall performance, with the\nadded benefit of knowledge preservation while aligning preferences.",
      "tldr_zh": "该研究针对大型语言模型的偏好对齐（preference alignment）问题，指出现有方法虽提升了整体性能，但忽略了更新回归（update regression），即更新后在之前正确处理的數據上出现退化，原因在于过度微调导致过度对齐和退化。  \n为此，提出 FlipGuard，一种基于约束优化（constrained optimization）的框架，通过自定义奖励表征（customized reward characterization）检测性能退化，并在训练中强制约束以鼓励与预对齐模型的条件一致性（conditional congruence）。  \n实验结果显示，FlipGuard 有效缓解更新回归，同时保持整体性能优秀，并实现知识保留。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main track",
      "pdf_url": "http://arxiv.org/pdf/2410.00508v2",
      "published_date": "2024-10-01 08:46:59 UTC",
      "updated_date": "2024-10-14 10:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:44:54.297544"
    },
    {
      "arxiv_id": "2410.03743v1",
      "title": "Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging",
      "title_zh": "通过选择性参数合并缓解 LLM 微调中的训练不平衡",
      "authors": [
        "Yiming Ju",
        "Ziyi Ni",
        "Xingrun Xing",
        "Zhixiong Zeng",
        "hanyu Zhao",
        "Siqi Fan",
        "Zheng Zhang"
      ],
      "abstract": "Supervised fine-tuning (SFT) is crucial for adapting Large Language Models\n(LLMs) to specific tasks. In this work, we demonstrate that the order of\ntraining data can lead to significant training imbalances, potentially\nresulting in performance degradation. Consequently, we propose to mitigate this\nimbalance by merging SFT models fine-tuned with different data orders, thereby\nenhancing the overall effectiveness of SFT. Additionally, we introduce a novel\ntechnique, \"parameter-selection merging,\" which outperforms traditional\nweighted-average methods on five datasets. Further, through analysis and\nablation studies, we validate the effectiveness of our method and identify the\nsources of performance improvements.",
      "tldr_zh": "本研究发现，在大型语言模型(LLM)的监督微调(SFT)过程中，训练数据的顺序可能导致训练不平衡，从而影响模型性能。针对此问题，论文提出通过合并不同数据顺序微调的SFT模型来缓解不平衡，并引入了parameter-selection merging技术，该技术在五个数据集上优于传统的weighted-average方法。实验结果通过分析和消融研究验证了该方法的有效性，并阐明了性能提升的关键来源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.03743v1",
      "published_date": "2024-10-01 08:44:31 UTC",
      "updated_date": "2024-10-01 08:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:45:05.992571"
    },
    {
      "arxiv_id": "2410.02827v1",
      "title": "Effective Intrusion Detection for UAV Communications using Autoencoder-based Feature Extraction and Machine Learning Approach",
      "title_zh": "有效的无人机通信入侵检测，使用基于自编码器的特征提取和机器学习方法",
      "authors": [
        "Tuan-Cuong Vuong",
        "Cong Chi Nguyen",
        "Van-Cuong Pham",
        "Thi-Thanh-Huyen Le",
        "Xuan-Nam Tran",
        "Thien Van Luong"
      ],
      "abstract": "This paper proposes a novel intrusion detection method for unmanned aerial\nvehicles (UAV) in the presence of recent actual UAV intrusion dataset. In\nparticular, in the first stage of our method, we design an autoencoder\narchitecture for effectively extracting important features, which are then fed\ninto various machine learning models in the second stage for detecting and\nclassifying attack types. To the best of our knowledge, this is the first\nattempt to propose such the autoencoder-based machine learning intrusion\ndetection method for UAVs using actual dataset, while most of existing works\nonly consider either simulated datasets or datasets irrelevant to UAV\ncommunications. Our experiment results show that the proposed method\noutperforms the baselines such as feature selection schemes in both binary and\nmulti-class classification tasks.",
      "tldr_zh": "这篇论文提出了一种有效的入侵检测方法，用于无人机 (UAV) 通信，基于 autoencoder 的特征提取和机器学习模型，以应对实际入侵数据集中的挑战。方法分为两个阶段：首先，使用 autoencoder 架构提取重要特征；其次，将这些特征输入各种机器学习模型进行攻击检测和分类。相比于现有基于模拟数据集或与 UAV 无关的数据集的研究，该方法首次采用实际 UAV 数据集，并实验证明在二元和多类分类任务中优于基线方案，如特征选择方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.RO",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.02827v1",
      "published_date": "2024-10-01 08:44:23 UTC",
      "updated_date": "2024-10-01 08:44:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:45:18.129130"
    },
    {
      "arxiv_id": "2410.00503v2",
      "title": "Drone Stereo Vision for Radiata Pine Branch Detection and Distance Measurement: Utilizing Deep Learning and YOLO Integration",
      "title_zh": "无人机立体视觉用于辐射松树枝检测和距离测量：利用深度学习和 YOLO 集成",
      "authors": [
        "Yida Lin",
        "Bing Xue",
        "Mengjie Zhang",
        "Sam Schofield",
        "Richard Green"
      ],
      "abstract": "This research focuses on the development of a drone equipped with pruning\ntools and a stereo vision camera to accurately detect and measure the spatial\npositions of tree branches. YOLO is employed for branch segmentation, while two\ndepth estimation approaches, monocular and stereo, are investigated. In\ncomparison to SGBM, deep learning techniques produce more refined and accurate\ndepth maps. In the absence of ground-truth data, a fine-tuning process using\ndeep neural networks is applied to approximate optimal depth values. This\nmethodology facilitates precise branch detection and distance measurement,\naddressing critical challenges in the automation of pruning operations. The\nresults demonstrate notable advancements in both accuracy and efficiency,\nunderscoring the potential of deep learning to drive innovation and enhance\nautomation in the agricultural sector.",
      "tldr_zh": "本研究开发了一种配备立体视觉相机和修剪工具的无人机系统，利用 YOLO 进行树枝分割，并比较单目和立体深度估计方法，以实现对辐射松树枝的空间位置检测和距离测量。相比传统 SGBM 算法，深度学习技术生成更精确的深度图，并在缺乏地面真实数据的情况下，通过深度神经网络微调来逼近最佳深度值。该方法有效解决了自动化修剪操作的关键挑战，结果显示在准确性和效率方面取得了显著进步，突出了深度学习在农业部门创新的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00503v2",
      "published_date": "2024-10-01 08:34:00 UTC",
      "updated_date": "2024-10-06 07:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:45:40.268564"
    },
    {
      "arxiv_id": "2410.00502v1",
      "title": "Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach",
      "title_zh": "翻译失败",
      "authors": [
        "Diogo Pernes",
        "Gonçalo M. Correia",
        "Afonso Mendes"
      ],
      "abstract": "Cross-lingual summarization aims to bridge language barriers by summarizing\ndocuments in different languages. However, ensuring semantic coherence across\nlanguages is an overlooked challenge and can be critical in several contexts.\nTo fill this gap, we introduce multi-target cross-lingual summarization as the\ntask of summarizing a document into multiple target languages while ensuring\nthat the produced summaries are semantically similar. We propose a principled\nre-ranking approach to this problem and a multi-criteria evaluation protocol to\nassess semantic coherence across target languages, marking a first step that\nwill hopefully stimulate further research on this problem.",
      "tldr_zh": "本研究引入了多目标跨语言摘要（multi-target cross-lingual summarization）这一新任务，旨在将文档总结为多个目标语言的摘要，同时确保这些摘要在语义上保持一致，以解决现有跨语言摘要中语义连贯性的挑战。作者提出了一种原则性的重新排序（re-ranking）方法，通过优化摘要生成过程来提升跨语言语义相似度。论文还设计了多标准评估协议（multi-criteria evaluation protocol）来评估摘要的质量，这标志着对该问题的首次系统探索，并有望激发进一步的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2410.00502v1",
      "published_date": "2024-10-01 08:33:57 UTC",
      "updated_date": "2024-10-01 08:33:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:45:41.789711"
    },
    {
      "arxiv_id": "2410.00490v1",
      "title": "Learning Adaptive Hydrodynamic Models Using Neural ODEs in Complex Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Wang",
        "Aoming Liang",
        "Fei Han",
        "Xinyu Zeng",
        "Zhibin Li",
        "Dixia Fan",
        "Jens Kober"
      ],
      "abstract": "Reinforcement learning-based quadruped robots excel across various terrains\nbut still lack the ability to swim in water due to the complex underwater\nenvironment. This paper presents the development and evaluation of a\ndata-driven hydrodynamic model for amphibious quadruped robots, aiming to\nenhance their adaptive capabilities in complex and dynamic underwater\nenvironments. The proposed model leverages Neural Ordinary Differential\nEquations (ODEs) combined with attention mechanisms to accurately process and\ninterpret real-time sensor data. The model enables the quadruped robots to\nunderstand and predict complex environmental patterns, facilitating robust\ndecision-making strategies. We harness real-time sensor data, capturing various\nenvironmental and internal state parameters to train and evaluate our model. A\nsignificant focus of our evaluation involves testing the quadruped robot's\nperformance across different hydrodynamic conditions and assessing its\ncapabilities at varying speeds and fluid dynamic conditions. The outcomes\nsuggest that the model can effectively learn and adapt to varying conditions,\nenabling the prediction of force states and enhancing autonomous robotic\nbehaviors in various practical scenarios.",
      "tldr_zh": "这篇论文提出了一种数据驱动的水动力学模型，利用 Neural ODEs 结合注意力机制，帮助四足机器人适应复杂水下环境，从而解决它们在水中游泳的挑战。模型通过处理实时传感器数据，预测环境模式并支持鲁棒决策策略。实验评估显示，该模型在不同水动力条件和速度下表现出色，能够有效学习和适应，提升机器人的自主行为和预测力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.00490v1",
      "published_date": "2024-10-01 08:18:36 UTC",
      "updated_date": "2024-10-01 08:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:45:53.384725"
    },
    {
      "arxiv_id": "2410.00483v1",
      "title": "MCGM: Mask Conditional Text-to-Image Generative Model",
      "title_zh": "翻译失败",
      "authors": [
        "Rami Skaik",
        "Leonardo Rossi",
        "Tomaso Fontanini",
        "Andrea Prati"
      ],
      "abstract": "Recent advancements in generative models have revolutionized the field of\nartificial intelligence, enabling the creation of highly-realistic and detailed\nimages. In this study, we propose a novel Mask Conditional Text-to-Image\nGenerative Model (MCGM) that leverages the power of conditional diffusion\nmodels to generate pictures with specific poses. Our model builds upon the\nsuccess of the Break-a-scene [1] model in generating new scenes using a single\nimage with multiple subjects and incorporates a mask embedding injection that\nallows the conditioning of the generation process. By introducing this\nadditional level of control, MCGM offers a flexible and intuitive approach for\ngenerating specific poses for one or more subjects learned from a single image,\nempowering users to influence the output based on their requirements. Through\nextensive experimentation and evaluation, we demonstrate the effectiveness of\nour proposed model in generating high-quality images that meet predefined mask\nconditions and improving the current Break-a-scene generative model.",
      "tldr_zh": "本研究提出了一种新型的 Mask Conditional Text-to-Image Generative Model (MCGM)，利用条件扩散模型生成具有特定姿势的图像，从而增强图像生成的可控性。MCGM 构建在 Break-a-scene 模型基础上，引入掩码嵌入注入机制，允许用户基于单个图像和文本条件来精确控制生成过程。实验结果显示，该模型能产生高质量图像，满足预定义的掩码条件，并显著提升了原有生成模型的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 13 figures, presented at the 5th International Conference\n  on Artificial Intelligence and Machine Learning (CAIML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.00483v1",
      "published_date": "2024-10-01 08:13:47 UTC",
      "updated_date": "2024-10-01 08:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:46:06.388568"
    },
    {
      "arxiv_id": "2410.00475v4",
      "title": "Probabilistic Analysis of Copyright Disputes and Generative AI Safety",
      "title_zh": "概率分析版权纠纷与生成式 AI 安全",
      "authors": [
        "Hiroaki Chiba-Okabe"
      ],
      "abstract": "This paper presents a probabilistic approach to analyzing copyright\ninfringement disputes. Under this approach, evidentiary principles shaped by\ncase law are formalized in probabilistic terms, allowing for a mathematical\nexamination of issues arising in such disputes. The usefulness of this approach\nis showcased through its application to the ``inverse ratio rule'' -- a\ncontroversial legal doctrine adopted by some courts. Although this rule has\nfaced significant criticism, a formal proof demonstrates its validity, provided\nit is properly defined. Furthermore, the paper employs the probabilistic\napproach to study the copyright safety of generative AI. Specifically, the Near\nAccess-Free (NAF) condition, previously proposed as a strategy for mitigating\nthe heightened copyright infringement risks of generative AI, is evaluated. The\nanalysis reveals that, while the NAF condition mitigates some infringement\nrisks, its justifiability and efficacy are questionable in certain contexts.\nThese findings illustrate how taking a probabilistic perspective can enhance\nour understanding of copyright jurisprudence and its interaction with\ngenerative AI technology.",
      "tldr_zh": "本论文提出了一种概率方法（probabilistic approach）来分析版权侵权纠纷，将案例法中的证据原则形式化为数学模型，以便进行定量考察。作者通过此方法证明了“inverse ratio rule”这一有争议的法律原则的有效性，前提是其正确定义。尽管该规则曾遭批评，但形式化分析为其合法性提供了支撑。该方法还评估了生成式AI的版权安全，特别是Near Access-Free (NAF) 条件，结果显示NAF条件虽能缓解某些侵权风险，但在其特定语境下合理性和效能存疑。这些发现展示了概率视角如何深化对版权法与生成式AI技术互动的理解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.00475v4",
      "published_date": "2024-10-01 08:05:19 UTC",
      "updated_date": "2025-01-25 02:14:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:46:18.651841"
    },
    {
      "arxiv_id": "2410.00467v3",
      "title": "Dynamic Planning for LLM-based Graphical User Interface Automation",
      "title_zh": "针对基于LLM的图形用户界面自动化的动态规划",
      "authors": [
        "Shaoqing Zhang",
        "Zhuosheng Zhang",
        "Kehai Chen",
        "Xinbei Ma",
        "Muyun Yang",
        "Tiejun Zhao",
        "Min Zhang"
      ],
      "abstract": "The advent of large language models (LLMs) has spurred considerable interest\nin advancing autonomous LLMs-based agents, particularly in intriguing\napplications within smartphone graphical user interfaces (GUIs). When presented\nwith a task goal, these agents typically emulate human actions within a GUI\nenvironment until the task is completed. However, a key challenge lies in\ndevising effective plans to guide action prediction in GUI tasks, though\nplanning have been widely recognized as effective for decomposing complex tasks\ninto a series of steps. Specifically, given the dynamic nature of environmental\nGUIs following action execution, it is crucial to dynamically adapt plans based\non environmental feedback and action history.We show that the widely-used ReAct\napproach fails due to the excessively long historical dialogues. To address\nthis challenge, we propose a novel approach called Dynamic Planning of Thoughts\n(D-PoT) for LLM-based GUI agents.D-PoT involves the dynamic adjustment of\nplanning based on the environmental feedback and execution history.\nExperimental results reveal that the proposed D-PoT significantly surpassed the\nstrong GPT-4V baseline by +12.7% (34.66% $\\rightarrow$ 47.36%) in accuracy. The\nanalysis highlights the generality of dynamic planning in different backbone\nLLMs, as well as the benefits in mitigating hallucinations and adapting to\nunseen tasks. Code is available at https://github.com/sqzhang-lazy/D-PoT.",
      "tldr_zh": "这篇论文针对基于大型语言模型 (LLMs) 的图形用户界面 (GUIs) 自动化，提出了一种名为 Dynamic Planning of Thoughts (D-PoT) 的新方法，以动态调整行动规划基于环境反馈和执行历史，从而应对 GUI 任务的动态性挑战。D-PoT 解决了传统 ReAct 方法在处理过长历史对话时的不足，通过分解复杂任务提升代理的适应性。实验结果显示，该方法比 GPT-4V 基线准确率提高了 12.7%（从 34.66% 到 47.36%），并证明了其在减少幻觉和处理未见任务方面的通用性和有效性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00467v3",
      "published_date": "2024-10-01 07:49:24 UTC",
      "updated_date": "2024-12-19 14:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:46:30.494163"
    },
    {
      "arxiv_id": "2410.03742v2",
      "title": "Beyond Scalar Reward Model: Learning Generative Judge from Preference Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Ye",
        "Xiangsheng Li",
        "Qiuchi Li",
        "Qingyao Ai",
        "Yujia Zhou",
        "Wei Shen",
        "Dong Yan",
        "Yiqun Liu"
      ],
      "abstract": "Learning from preference feedback is a common practice for aligning large\nlanguage models~(LLMs) with human value. Conventionally, preference data is\nlearned and encoded into a scalar reward model that connects a value head with\nan LLM to produce a scalar score as preference or reward. However, scalar\nmodels lack interpretability and are known to be susceptible to biases in\ndatasets. This paper investigates leveraging the generation capability of LLMs\nto address both limitations in one shot. Specifically, we prompt the\npre-trained LLM to generate positive and negative judgments, both supported\nwith rationales in natural language form. The self-generated contrastive\njudgment pairs are used to train the generative judge with Direct Preference\nOptimization (DPO). This proposal of training the generative Judge using\nself-generated Contrastive judgments (Con-J) ensures natural interpretability\ndue to the generated rationales together with the judgments, as well as high\nrobustness against bias without the need for an additional reward head.\nExperimental results show that the performance of Con-J is comparable to the\nscalar reward model trained on the same collection of preference data, and\ndemonstrate its superior interpretability and robustness in encoding human\npreferences.",
      "tldr_zh": "该研究超越了传统的标量奖励模型（scalar reward model），提出了一种从偏好数据中学习生成式判断器（generative judge）的新方法。具体来说，通过提示预训练的LLM生成带有理由的正负对比判断对（contrastive judgment pairs），并使用Direct Preference Optimization (DPO)进行训练，形成名为Con-J的框架。这种方法提升了模型的可解释性（通过生成的rationales）和对数据集偏差的鲁棒性，而无需额外奖励头。实验结果显示，Con-J的表现与标量奖励模型相当，但在其编码人类偏好的可解释性和鲁棒性方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03742v2",
      "published_date": "2024-10-01 07:38:58 UTC",
      "updated_date": "2024-10-13 10:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:46:42.127837"
    },
    {
      "arxiv_id": "2410.01847v2",
      "title": "Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation",
      "title_zh": "Bayes-CATSI：一种用于医疗时间序列数据插值的变分贝叶斯深度学习框架",
      "authors": [
        "Omkar Kulkarni",
        "Rohitash Chandra"
      ],
      "abstract": "Medical time series datasets feature missing values that need data imputation\nmethods, however, conventional machine learning models fall short due to a lack\nof uncertainty quantification in predictions. Among these models, the CATSI\n(Context-Aware Time Series Imputation) stands out for its effectiveness by\nincorporating a context vector into the imputation process, capturing the\nglobal dependencies of each patient. In this paper, we propose a Bayesian\nContext-Aware Time Series Imputation (Bayes-CATSI) framework which leverages\nuncertainty quantification offered by variational inference. We consider the\ntime series derived from electroencephalography (EEG), electrooculography\n(EOG), electromyography (EMG), electrocardiology (EKG). Variational Inference\nassumes the shape of the posterior distribution and through minimization of the\nKullback-Leibler(KL) divergence it finds variational densities that are closest\nto the true posterior distribution. Thus , we integrate the variational\nBayesian deep learning layers into the CATSI model. Our results show that\nBayes-CATSI not only provides uncertainty quantification but also achieves\nsuperior imputation performance compared to the CATSI model. Specifically, an\ninstance of Bayes-CATSI outperforms CATSI by 9.57 %. We provide an open-source\ncode implementation for applying Bayes-CATSI to other medical data imputation\nproblems.",
      "tldr_zh": "本论文提出Bayes-CATSI框架，这是一种基于variational Bayesian deep learning的变分推断方法，用于处理医疗时间序列数据的缺失值imputation问题。相比传统CATSI模型，该框架通过整合variational inference和最小化Kullback-Leibler (KL) divergence来量化预测不确定性，并捕获患者全局依赖，如EEG、EOG、EMG和EKG数据。实验结果显示，Bayes-CATSI在imputation性能上比CATSI提升9.57%，并提供开源代码以支持其他医疗数据应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01847v2",
      "published_date": "2024-10-01 07:37:52 UTC",
      "updated_date": "2024-10-04 01:55:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:46:55.112785"
    },
    {
      "arxiv_id": "2410.00451v3",
      "title": "Unleashing the Unseen: Harnessing Benign Datasets for Jailbreaking Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Zhao",
        "Zhe Li",
        "Yige Li",
        "Jun Sun"
      ],
      "abstract": "Despite significant ongoing efforts in safety alignment, large language\nmodels (LLMs) such as GPT-4 and LLaMA 3 remain vulnerable to jailbreak attacks\nthat can induce harmful behaviors, including through the use of adversarial\nsuffixes. Building on prior research, we hypothesize that these adversarial\nsuffixes are not mere bugs but may represent features that can dominate the\nLLM's behavior. To evaluate this hypothesis, we conduct several experiments.\nFirst, we demonstrate that benign features can be effectively made to function\nas adversarial suffixes, i.e., we develop a feature extraction method to\nextract sample-agnostic features from benign dataset in the form of suffixes\nand show that these suffixes may effectively compromise safety alignment.\nSecond, we show that adversarial suffixes generated from jailbreak attacks may\ncontain meaningful features, i.e., appending the same suffix to different\nprompts results in responses exhibiting specific characteristics. Third, we\nshow that such benign-yet-safety-compromising features can be easily introduced\nthrough fine-tuning using only benign datasets. As a result, we are able to\ncompletely eliminate GPT's safety alignment in a blackbox setting through\nfinetuning with only benign data. Our code and data is available at\n\\url{https://github.com/suffix-maybe-feature/adver-suffix-maybe-features}.",
      "tldr_zh": "该研究假设对抗后缀(adversarial suffixes)并非大型语言模型(LLMs)如 GPT-4 和 LLaMA 3 的简单 bug，而是可能主导模型行为的特征，通过实验验证了这一观点。研究者开发了一种特征提取方法，从良性数据集提取样本无关的后缀，并证明这些后缀能破坏模型的安全对齐(safety alignment)。此外，实验显示对抗后缀包含有意义特征，且通过仅使用良性数据进行微调(fine-tuning)，即可在黑箱设置中完全消除 GPT 的安全对齐，为理解和提升 LLM 安全提供了重要洞见。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00451v3",
      "published_date": "2024-10-01 07:11:55 UTC",
      "updated_date": "2024-12-19 05:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:47:06.156138"
    },
    {
      "arxiv_id": "2410.00441v2",
      "title": "ReXplain: Translating Radiology into Patient-Friendly Video Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Luyang Luo",
        "Jenanan Vairavamurthy",
        "Xiaoman Zhang",
        "Abhinav Kumar",
        "Ramon R. Ter-Oganesyan",
        "Stuart T. Schroff",
        "Dan Shilo",
        "Rydhwana Hossain",
        "Mike Moritz",
        "Pranav Rajpurkar"
      ],
      "abstract": "Radiology reports, designed for efficient communication between medical\nexperts, often remain incomprehensible to patients. This inaccessibility could\npotentially lead to anxiety, decreased engagement in treatment decisions, and\npoorer health outcomes, undermining patient-centered care. We present ReXplain\n(Radiology eXplanation), an innovative AI-driven system that translates\nradiology findings into patient-friendly video reports. ReXplain uniquely\nintegrates a large language model for medical text simplification and\ntext-anatomy association, an image segmentation model for anatomical region\nidentification, and an avatar generation tool for engaging interface\nvisualization. ReXplain enables producing comprehensive explanations with plain\nlanguage, highlighted imagery, and 3D organ renderings in the form of video\nreports. To evaluate the utility of ReXplain-generated explanations, we\nconducted two rounds of user feedback collection from six board-certified\nradiologists. The results of this proof-of-concept study indicate that ReXplain\ncould accurately deliver radiological information and effectively simulate\none-on-one consultation, shedding light on enhancing patient-centered radiology\nwith potential clinical usage. This work demonstrates a new paradigm in\nAI-assisted medical communication, potentially improving patient engagement and\nsatisfaction in radiology care, and opens new avenues for research in\nmultimodal medical communication.",
      "tldr_zh": "该论文提出 ReXplain 系统，一种创新的 AI 驱动工具，用于将放射学报告转化为患者友好的视频报告，以解决报告难以理解导致的焦虑和健康问题。ReXplain 整合了 large language model 用于医疗文本简化及文本-解剖关联、image segmentation model 用于识别解剖区域，以及 avatar generation tool 用于生成包含简单语言、高亮图像和 3D 器官渲染的视频。实验通过两轮用户反馈从六名放射科医生处收集数据，证明 ReXplain 能准确传达信息并模拟一对一咨询，从而提升患者参与度和满意度，并为多模态医疗沟通开辟新研究方向。",
      "categories": [
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages. The project page is\n  https://www.rajpurkarlab.hms.harvard.edu/rexplain",
      "pdf_url": "http://arxiv.org/pdf/2410.00441v2",
      "published_date": "2024-10-01 06:41:18 UTC",
      "updated_date": "2024-12-17 22:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:47:18.785114"
    },
    {
      "arxiv_id": "2410.03741v1",
      "title": "Towards Democratization of Subspeciality Medical Expertise",
      "title_zh": "翻译失败",
      "authors": [
        "Jack W. O'Sullivan",
        "Anil Palepu",
        "Khaled Saab",
        "Wei-Hung Weng",
        "Yong Cheng",
        "Emily Chu",
        "Yaanik Desai",
        "Aly Elezaby",
        "Daniel Seung Kim",
        "Roy Lan",
        "Wilson Tang",
        "Natalie Tapaskar",
        "Victoria Parikh",
        "Sneha S. Jain",
        "Kavita Kulkarni",
        "Philip Mansfield",
        "Dale Webster",
        "Juraj Gottweis",
        "Joelle Barral",
        "Mike Schaekermann",
        "Ryutaro Tanno",
        "S. Sara Mahdavi",
        "Vivek Natarajan",
        "Alan Karthikesalingam",
        "Euan Ashley",
        "Tao Tu"
      ],
      "abstract": "The scarcity of subspecialist medical expertise, particularly in rare,\ncomplex and life-threatening diseases, poses a significant challenge for\nhealthcare delivery. This issue is particularly acute in cardiology where\ntimely, accurate management determines outcomes. We explored the potential of\nAMIE (Articulate Medical Intelligence Explorer), a large language model\n(LLM)-based experimental AI system optimized for diagnostic dialogue, to\npotentially augment and support clinical decision-making in this challenging\ncontext. We curated a real-world dataset of 204 complex cases from a\nsubspecialist cardiology practice, including results for electrocardiograms,\nechocardiograms, cardiac MRI, genetic tests, and cardiopulmonary stress tests.\nWe developed a ten-domain evaluation rubric used by subspecialists to evaluate\nthe quality of diagnosis and clinical management plans produced by general\ncardiologists or AMIE, the latter enhanced with web-search and self-critique\ncapabilities. AMIE was rated superior to general cardiologists for 5 of the 10\ndomains (with preference ranging from 9% to 20%), and equivalent for the rest.\nAccess to AMIE's response improved cardiologists' overall response quality in\n63.7% of cases while lowering quality in just 3.4%. Cardiologists' responses\nwith access to AMIE were superior to cardiologist responses without access to\nAMIE for all 10 domains. Qualitative examinations suggest AMIE and general\ncardiologist could complement each other, with AMIE thorough and sensitive,\nwhile general cardiologist concise and specific. Overall, our results suggest\nthat specialized medical LLMs have the potential to augment general\ncardiologists' capabilities by bridging gaps in subspecialty expertise, though\nfurther research and validation are essential for wide clinical utility.",
      "tldr_zh": "本研究探讨了如何通过AI系统AMIE（Articulate Medical Intelligence Explorer）来民主化稀缺的亚专科医疗专家，特别是针对心脏病学领域的复杂病例。研究者收集了204个真实心脏病病例的数据，并使用一个10个领域的评估标准，由亚专科专家评估AMIE（增强了web-search和self-critique能力）与普通心脏病专家的诊断和管理计划。结果显示，AMIE在5个领域优于普通心脏病专家（优势9%至20%），并在其他领域相当；此外，使用AMIE后，普通心脏病专家的响应质量在63.7%的病例中得到改善，在所有10个领域均表现优越。总体而言，AMIE与普通专家互补，能桥接亚专科专业差距，但需进一步研究以实现广泛临床应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03741v1",
      "published_date": "2024-10-01 06:34:31 UTC",
      "updated_date": "2024-10-01 06:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:47:31.413539"
    },
    {
      "arxiv_id": "2410.00432v1",
      "title": "Scalable Multi-Task Transfer Learning for Molecular Property Prediction",
      "title_zh": "可扩展的多任务迁移学习用于分子属性预测",
      "authors": [
        "Chanhui Lee",
        "Dae-Woong Jeong",
        "Sung Moon Ko",
        "Sumin Lee",
        "Hyunseung Kim",
        "Soorin Yim",
        "Sehui Han",
        "Sungwoong Kim",
        "Sungbin Lim"
      ],
      "abstract": "Molecules have a number of distinct properties whose importance and\napplication vary. Often, in reality, labels for some properties are hard to\nachieve despite their practical importance. A common solution to such data\nscarcity is to use models of good generalization with transfer learning. This\ninvolves domain experts for designing source and target tasks whose features\nare shared. However, this approach has limitations: i). Difficulty in accurate\ndesign of source-target task pairs due to the large number of tasks, and ii).\ncorresponding computational burden verifying many trials and errors of transfer\nlearning design, thereby iii). constraining the potential of foundation\nmodeling of multi-task molecular property prediction. We address the\nlimitations of the manual design of transfer learning via data-driven bi-level\noptimization. The proposed method enables scalable multi-task transfer learning\nfor molecular property prediction by automatically obtaining the optimal\ntransfer ratios. Empirically, the proposed method improved the prediction\nperformance of 40 molecular properties and accelerated training convergence.",
      "tldr_zh": "该论文针对分子属性预测中的标签稀缺问题，指出传统转移学习（transfer learning）需手动设计源-目标任务对，导致设计困难和计算负担。作者提出一种数据驱动的双层优化（bi-level optimization）方法，实现可扩展的多任务转移学习（multi-task transfer learning），通过自动获取最优转移比率（transfer ratios）来优化模型。实验结果显示，该方法提升了 40 种分子属性的预测性能，并加速了训练收敛。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00432v1",
      "published_date": "2024-10-01 06:28:14 UTC",
      "updated_date": "2024-10-01 06:28:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:47:42.199943"
    },
    {
      "arxiv_id": "2410.00428v3",
      "title": "LayerKV: Optimizing Large Language Model Serving with Layer-wise KV Cache Management",
      "title_zh": "LayerKV：通过层级化 KV 缓存管理优化大语言模型服务",
      "authors": [
        "Yi Xiong",
        "Hao Wu",
        "Changxu Shao",
        "Ziqing Wang",
        "Rui Zhang",
        "Yuhong Guo",
        "Junping Zhao",
        "Ke Zhang",
        "Zhenxuan Pan"
      ],
      "abstract": "The expanding context windows in large language models (LLMs) have greatly\nenhanced their capabilities in various applications, but they also introduce\nsignificant challenges in maintaining low latency, particularly in Time to\nFirst Token (TTFT). This paper identifies that the sharp rise in TTFT as\ncontext length increases is predominantly driven by queuing delays, which are\ncaused by the growing demands for GPU Key-Value (KV) cache allocation clashing\nwith the limited availability of KV cache blocks. To address this issue, we\npropose LayerKV, a simple yet effective plug-in method that effectively reduces\nTTFT without requiring additional hardware or compromising output performance,\nwhile seamlessly integrating with existing parallelism strategies and\nscheduling techniques. Specifically, LayerKV introduces layer-wise KV block\nallocation, management, and offloading for fine-grained control over system\nmemory, coupled with an SLO-aware scheduler to optimize overall Service Level\nObjectives (SLOs). Comprehensive evaluations on representative models, ranging\nfrom 7B to 70B parameters, across various GPU configurations, demonstrate that\nLayerKV improves TTFT latency up to 69x and reduces SLO violation rates by\n28.7%, significantly enhancing the user experience.",
      "tldr_zh": "这篇论文针对大语言模型 (LLMs) 的上下文窗口扩展导致 Time to First Token (TTFT) 延迟增加的问题，提出 LayerKV 一种简单有效的插件方法，以优化 KV 缓存管理。LayerKV 通过层级 KV 块分配、管理和卸载 (layer-wise KV block allocation, management, and offloading) 实现细粒度内存控制，并结合 SLO-aware 调度器优化 Service Level Objectives (SLOs)，无需额外硬件或牺牲输出性能。实验在 7B 到 70B 参数的模型上显示，LayerKV 最多将 TTFT 延迟改善 69 倍，并降低 SLO 违规率 28.7%，显著提升了模型服务效率。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "I.2.11; C.4"
      ],
      "primary_category": "cs.DC",
      "comment": "11 pages, 7 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2410.00428v3",
      "published_date": "2024-10-01 06:23:17 UTC",
      "updated_date": "2024-10-09 11:40:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:47:54.974014"
    },
    {
      "arxiv_id": "2410.00425v1",
      "title": "ManiSkill3: GPU Parallelized Robotics Simulation and Rendering for Generalizable Embodied AI",
      "title_zh": "ManiSkill3：用于可泛化具身 AI 的 GPU 并行化机器人模拟和渲染",
      "authors": [
        "Stone Tao",
        "Fanbo Xiang",
        "Arth Shukla",
        "Yuzhe Qin",
        "Xander Hinrichsen",
        "Xiaodi Yuan",
        "Chen Bao",
        "Xinsong Lin",
        "Yulin Liu",
        "Tse-kai Chan",
        "Yuan Gao",
        "Xuanlin Li",
        "Tongzhou Mu",
        "Nan Xiao",
        "Arnav Gurha",
        "Zhiao Huang",
        "Roberto Calandra",
        "Rui Chen",
        "Shan Luo",
        "Hao Su"
      ],
      "abstract": "Simulation has enabled unprecedented compute-scalable approaches to robot\nlearning. However, many existing simulation frameworks typically support a\nnarrow range of scenes/tasks and lack features critical for scaling\ngeneralizable robotics and sim2real. We introduce and open source ManiSkill3,\nthe fastest state-visual GPU parallelized robotics simulator with contact-rich\nphysics targeting generalizable manipulation. ManiSkill3 supports GPU\nparallelization of many aspects including simulation+rendering, heterogeneous\nsimulation, pointclouds/voxels visual input, and more. Simulation with\nrendering on ManiSkill3 can run 10-1000x faster with 2-3x less GPU memory usage\nthan other platforms, achieving up to 30,000+ FPS in benchmarked environments\ndue to minimal python/pytorch overhead in the system, simulation on the GPU,\nand the use of the SAPIEN parallel rendering system. Tasks that used to take\nhours to train can now take minutes. We further provide the most comprehensive\nrange of GPU parallelized environments/tasks spanning 12 distinct domains\nincluding but not limited to mobile manipulation for tasks such as drawing,\nhumanoids, and dextrous manipulation in realistic scenes designed by artists or\nreal-world digital twins. In addition, millions of demonstration frames are\nprovided from motion planning, RL, and teleoperation. ManiSkill3 also provides\na comprehensive set of baselines that span popular RL and\nlearning-from-demonstrations algorithms.",
      "tldr_zh": "我们介绍了 ManiSkill3，这是一个开源的 GPU 并行化机器人模拟器，针对可泛化的 Embodied AI，通过优化模拟和渲染过程，实现 10-1000 倍的速度提升和 2-3 倍的 GPU 内存节省，可达 30,000+ FPS。ManiSkill3 支持异构模拟、点云/体素视觉输入，并提供涵盖 12 个领域的全面环境和任务，如移动操作、人形机器人和灵巧操作。论文还包括数百万演示帧（来自运动规划、RL 和遥操作）以及一系列基线算法，促进机器人学习和 sim2real 应用的快速发展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: http://maniskill.ai/",
      "pdf_url": "http://arxiv.org/pdf/2410.00425v1",
      "published_date": "2024-10-01 06:10:39 UTC",
      "updated_date": "2024-10-01 06:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:48:06.644669"
    },
    {
      "arxiv_id": "2410.00418v3",
      "title": "Posterior-Mean Rectified Flow: Towards Minimum MSE Photo-Realistic Image Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Guy Ohayon",
        "Tomer Michaeli",
        "Michael Elad"
      ],
      "abstract": "Photo-realistic image restoration algorithms are typically evaluated by\ndistortion measures (e.g., PSNR, SSIM) and by perceptual quality measures\n(e.g., FID, NIQE), where the desire is to attain the lowest possible distortion\nwithout compromising on perceptual quality. To achieve this goal, current\nmethods commonly attempt to sample from the posterior distribution, or to\noptimize a weighted sum of a distortion loss (e.g., MSE) and a perceptual\nquality loss (e.g., GAN). Unlike previous works, this paper is concerned\nspecifically with the optimal estimator that minimizes the MSE under a\nconstraint of perfect perceptual index, namely where the distribution of the\nreconstructed images is equal to that of the ground-truth ones. A recent\ntheoretical result shows that such an estimator can be constructed by optimally\ntransporting the posterior mean prediction (MMSE estimate) to the distribution\nof the ground-truth images. Inspired by this result, we introduce\nPosterior-Mean Rectified Flow (PMRF), a simple yet highly effective algorithm\nthat approximates this optimal estimator. In particular, PMRF first predicts\nthe posterior mean, and then transports the result to a high-quality image\nusing a rectified flow model that approximates the desired optimal transport\nmap. We investigate the theoretical utility of PMRF and demonstrate that it\nconsistently outperforms previous methods on a variety of image restoration\ntasks.",
      "tldr_zh": "本研究针对照片级图像恢复，旨在最小化均方误差 (MSE) 同时保持完美感知质量，即重建图像的分布与真实图像一致。论文提出 Posterior-Mean Rectified Flow (PMRF) 算法，该方法首先计算后验均值 (MMSE 估计)，然后使用 rectified flow 模型进行最佳传输，以逼近理论上最优的估计器。实验结果显示，PMRF 在多种图像恢复任务中（如使用 PSNR、SSIM、FID 和 NIQE 等度量） outperform 了现有方法，为高失真最小化和感知质量平衡提供了有效解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted to ICLR 2025. Code and demo are available at\n  https://pmrf-ml.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.00418v3",
      "published_date": "2024-10-01 05:54:07 UTC",
      "updated_date": "2025-02-04 07:00:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:48:19.686511"
    },
    {
      "arxiv_id": "2410.02826v1",
      "title": "LinkThief: Combining Generalized Structure Knowledge with Node Similarity for Link Stealing Attack against GNN",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxing Zhang",
        "Siyuan Meng",
        "Chunchun Chen",
        "Mengyao Peng",
        "Hongyan Gu",
        "Xinli Huang"
      ],
      "abstract": "Graph neural networks(GNNs) have a wide range of applications in\nmultimedia.Recent studies have shown that Graph neural networks(GNNs) are\nvulnerable to link stealing attacks,which infers the existence of edges in the\ntarget GNN's training graph.Existing attacks are usually based on the\nassumption that links exist between two nodes that share similar\nposteriors;however,they fail to focus on links that do not hold under this\nassumption.To this end,we propose LinkThief,an improved link stealing attack\nthat combines generalized structure knowledge with node similarity,in a\nscenario where the attackers' background knowledge contains partially leaked\ntarget graph and shadow graph.Specifically,to equip the attack model with\ninsights into the link structure spanning both the shadow graph and the target\ngraph,we introduce the idea of creating a Shadow-Target Bridge Graph and\nextracting edge subgraph structure features from it.Through theoretical\nanalysis from the perspective of privacy theft,we first explore how to\nimplement the aforementioned ideas.Building upon the findings,we design the\nBridge Graph Generator to construct the Shadow-Target Bridge Graph.Then,the\nsubgraph around the link is sampled by the Edge Subgraph Preparation\nModule.Finally,the Edge Structure Feature Extractor is designed to obtain\ngeneralized structure knowledge,which is combined with node similarity to form\nthe features provided to the attack model.Extensive experiments validate the\ncorrectness of theoretical analysis and demonstrate that LinkThief still\neffectively steals links without extra assumptions.",
      "tldr_zh": "该研究针对图神经网络（GNNs）的链接窃取攻击提出LinkThief框架，该框架将广义结构知识与节点相似性相结合，解决了现有攻击方法依赖节点后验相似性假设的局限性。LinkThief在攻击者拥有部分泄露目标图和影子图的场景下，通过构建Shadow-Target Bridge Graph、采样边子图结构特征以及设计Bridge Graph Generator、Edge Subgraph Preparation Module和Edge Structure Feature Extractor等模块，提取并整合结构知识来提升攻击准确性。从隐私窃取角度进行的理论分析和广泛实验验证表明，LinkThief无需额外假设即可有效窃取链接，显著提高了攻击性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02826v1",
      "published_date": "2024-10-01 05:34:03 UTC",
      "updated_date": "2024-10-01 05:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:48:30.881833"
    },
    {
      "arxiv_id": "2410.00403v1",
      "title": "TikGuard: A Deep Learning Transformer-Based Solution for Detecting Unsuitable TikTok Content for Kids",
      "title_zh": "TikGuard: 一种基于Transformer的深度学习解决方案，用于检测不适合",
      "authors": [
        "Mazen Balat",
        "Mahmoud Essam Gabr",
        "Hend Bakr",
        "Ahmed B. Zaky"
      ],
      "abstract": "The rise of short-form videos on platforms like TikTok has brought new\nchallenges in safeguarding young viewers from inappropriate content.\nTraditional moderation methods often fall short in handling the vast and\nrapidly changing landscape of user-generated videos, increasing the risk of\nchildren encountering harmful material. This paper introduces TikGuard, a\ntransformer-based deep learning approach aimed at detecting and flagging\ncontent unsuitable for children on TikTok. By using a specially curated\ndataset, TikHarm, and leveraging advanced video classification techniques,\nTikGuard achieves an accuracy of 86.7%, showing a notable improvement over\nexisting methods in similar contexts. While direct comparisons are limited by\nthe uniqueness of the TikHarm dataset, TikGuard's performance highlights its\npotential in enhancing content moderation, contributing to a safer online\nexperience for minors. This study underscores the effectiveness of transformer\nmodels in video classification and sets a foundation for future research in\nthis area.",
      "tldr_zh": "这篇论文介绍了 TikGuard，一种基于 Transformer 的深度学习解决方案，旨在检测和标记 TikTok 上不适合儿童的内容，以应对短视频平台上用户生成视频的快速变化和传统审核方法的不足。研究利用了专门的 TikHarm 数据集和高级视频分类技术，实现了 86.7% 的准确率，比现有方法有显著改善。尽管受限于数据集的独特性，TikGuard 展示了其在增强内容审核方面的潜力，并强调了 Transformer 模型在视频分类中的有效性，为未来研究奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NILES2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00403v1",
      "published_date": "2024-10-01 05:00:05 UTC",
      "updated_date": "2024-10-01 05:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:48:42.404756"
    },
    {
      "arxiv_id": "2410.00393v1",
      "title": "Revisiting Essential and Nonessential Settings of Evidential Deep Learning",
      "title_zh": "重新审视证据深度学习的必要与非必要设置",
      "authors": [
        "Mengyuan Chen",
        "Junyu Gao",
        "Changsheng Xu"
      ],
      "abstract": "Evidential Deep Learning (EDL) is an emerging method for uncertainty\nestimation that provides reliable predictive uncertainty in a single forward\npass, attracting significant attention. Grounded in subjective logic, EDL\nderives Dirichlet concentration parameters from neural networks to construct a\nDirichlet probability density function (PDF), modeling the distribution of\nclass probabilities. Despite its success, EDL incorporates several nonessential\nsettings: In model construction, (1) a commonly ignored prior weight parameter\nis fixed to the number of classes, while its value actually impacts the balance\nbetween the proportion of evidence and its magnitude in deriving predictive\nscores. In model optimization, (2) the empirical risk features a\nvariance-minimizing optimization term that biases the PDF towards a Dirac delta\nfunction, potentially exacerbating overconfidence. (3) Additionally, the\nstructural risk typically includes a KL-divergence-minimizing regularization,\nwhose optimization direction extends beyond the intended purpose and\ncontradicts common sense, diminishing the information carried by the evidence\nmagnitude. Therefore, we propose Re-EDL, a simplified yet more effective\nvariant of EDL, by relaxing the nonessential settings and retaining the\nessential one, namely, the adoption of projected probability from subjective\nlogic. Specifically, Re-EDL treats the prior weight as an adjustable\nhyperparameter rather than a fixed scalar, and directly optimizes the\nexpectation of the Dirichlet PDF provided by deprecating both the\nvariance-minimizing optimization term and the divergence regularization term.\nExtensive experiments and state-of-the-art performance validate the\neffectiveness of our method. The source code is available at\nhttps://github.com/MengyuanChen21/Re-EDL.",
      "tldr_zh": "该研究重新审视了 Evidential Deep Learning (EDL) 中的必要和非必要设置，指出 EDL 在模型构建和优化中存在问题，如 prior weight 参数固定为类数、variance-minimizing 优化项导致潜在过自信，以及 KL-divergence-minimizing 正则化项可能削弱证据信息。作者提出 Re-EDL 改进方案，将 prior weight 作为可调节超参数，并去除上述非必要优化项，直接优化 Dirichlet PDF 的期望，同时保留主观逻辑的投影概率机制。实验结果显示，Re-EDL 实现了 state-of-the-art 性能，验证了其有效性，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2410.00393v1",
      "published_date": "2024-10-01 04:27:07 UTC",
      "updated_date": "2024-10-01 04:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:48:53.433787"
    },
    {
      "arxiv_id": "2410.00387v1",
      "title": "Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation",
      "title_zh": "通过大型语言模型和检索增强生成提升紧凑模型在低数据环境中的能力",
      "authors": [
        "Bhargav Shandilya",
        "Alexis Palmer"
      ],
      "abstract": "The data and compute requirements of current language modeling technology\npose challenges for the processing and analysis of low-resource languages.\nDeclarative linguistic knowledge has the potential to partially bridge this\ndata scarcity gap by providing models with useful inductive bias in the form of\nlanguage-specific rules. In this paper, we propose a retrieval augmented\ngeneration (RAG) framework backed by a large language model (LLM) to correct\nthe output of a smaller model for the linguistic task of morphological\nglossing. We leverage linguistic information to make up for the lack of data\nand trainable parameters, while allowing for inputs from written descriptive\ngrammars interpreted and distilled through an LLM.\n  The results demonstrate that significant leaps in performance and efficiency\nare possible with the right combination of: a) linguistic inputs in the form of\ngrammars, b) the interpretive power of LLMs, and c) the trainability of smaller\ntoken classification networks. We show that a compact, RAG-supported model is\nhighly effective in data-scarce settings, achieving a new state-of-the-art for\nthis task and our target languages. Our work also offers documentary linguists\na more reliable and more usable tool for morphological glossing by providing\nwell-reasoned explanations and confidence scores for each output.",
      "tldr_zh": "本研究针对低资源语言处理中的数据和计算限制，提出了一种结合大型语言模型（LLMs）和检索增强生成（RAG）框架的方法，以提升小型模型在形态词汇标注（morphological glossing）任务上的能力。该框架利用声明性语言知识（如语言特定规则）作为诱导偏差，通过LLMs对小型模型的输出进行修正和解释，从而在数据稀缺环境中弥补训练参数不足。实验结果显示，这种组合显著提高了性能和效率，实现了该任务的新状态-of-the-art水平，并为文献语言学家提供可靠的解释和置信度分数，支持更可信的自主工具开发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 1 figure, 5 tables, submitted to COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.00387v1",
      "published_date": "2024-10-01 04:20:14 UTC",
      "updated_date": "2024-10-01 04:20:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:49:06.001043"
    },
    {
      "arxiv_id": "2410.00385v2",
      "title": "STGformer: Efficient Spatiotemporal Graph Transformer for Traffic Forecasting",
      "title_zh": "STGformer：高效的时空图变换器用于交通预测",
      "authors": [
        "Hongjun Wang",
        "Jiyuan Chen",
        "Tong Pan",
        "Zheng Dong",
        "Lingyu Zhang",
        "Renhe Jiang",
        "Xuan Song"
      ],
      "abstract": "Traffic forecasting is a cornerstone of smart city management, enabling\nefficient resource allocation and transportation planning. Deep learning, with\nits ability to capture complex nonlinear patterns in spatiotemporal (ST) data,\nhas emerged as a powerful tool for traffic forecasting. While graph neural\nnetworks (GCNs) and transformer-based models have shown promise, their\ncomputational demands often hinder their application to real-world road\nnetworks, particularly those with large-scale spatiotemporal interactions. To\naddress these challenges, we propose a novel spatiotemporal graph transformer\n(STGformer) architecture. STGformer effectively balances the strengths of GCNs\nand Transformers, enabling efficient modeling of both global and local traffic\npatterns while maintaining a manageable computational footprint. Unlike\ntraditional approaches that require multiple attention layers, STG attention\nblock captures high-order spatiotemporal interactions in a single layer,\nsignificantly reducing computational cost. In particular, STGformer achieves a\n100x speedup and a 99.8\\% reduction in GPU memory usage compared to STAEformer\nduring batch inference on a California road graph with 8,600 sensors. We\nevaluate STGformer on the LargeST benchmark and demonstrate its superiority\nover state-of-the-art Transformer-based methods such as PDFormer and\nSTAEformer, which underline STGformer's potential to revolutionize traffic\nforecasting by overcoming the computational and memory limitations of existing\napproaches, making it a promising foundation for future spatiotemporal modeling\ntasks.",
      "tldr_zh": "该研究提出 STGformer，一种高效的时空图 Transformer 架构，用于交通预测，以解决现有 GCNs 和 Transformer 模型在处理大规模路网时空交互时的计算需求问题。STGformer 结合 GCNs 和 Transformers 的优势，通过 STG attention block 在单层中捕捉高阶时空交互，从而显著降低计算成本和内存使用。在 LargeST 基准测试中，STGformer 比 PDFormer 和 STAEformer 等方法表现出色，实现 100 倍加速和 99.8% GPU 内存减少，为智能城市交通管理和未来时空建模任务提供了高效基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00385v2",
      "published_date": "2024-10-01 04:15:48 UTC",
      "updated_date": "2024-10-15 05:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:49:18.690157"
    },
    {
      "arxiv_id": "2410.00381v2",
      "title": "Downscaling Extreme Precipitation with Wasserstein Regularized Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Liu",
        "James Doss-Gollin",
        "Qiushi Dai",
        "Guha Balakrishnan",
        "Ashok Veeraraghavan"
      ],
      "abstract": "Understanding the risks posed by extreme rainfall events necessitates both\nhigh-resolution products (to assess localized hazards) and extensive historical\nrecords (to capture rare occurrences). Radar and mesonet networks provide\nkilometer-scale precipitation fields, but with limited historical records and\ngeographical coverage. Conversely, global gauge and blended products span\ndecades, yet their coarse 30-50 km grids obscure local extremes. This work\nintroduces Wasserstein Regularized Diffusion (WassDiff), a generative\ndownscaling framework that integrates diffusion modeling with a\ndistribution-matching (Wasserstein) regularizer, suppressing bias throughout\nthe entire generative denoising process. Conditioned on 55 km CPC gauge-based\nprecipitation and the 31 km ERA5 reanalysis, WassDiff generates 1 km\nprecipitation estimates that remain well-calibrated to targets across the full\nintensity range, including the extremes. Comprehensive evaluations demonstrate\nthat WassDiff outperforms existing state-of-the-art downscaling methods,\ndelivering lower reconstruction error and reduced bias. Case studies further\ndemonstrate its ability to reproduce realistic fine-scale structures and\naccurate peak intensities from extreme weather phenomena, such as tropical\nstorms and cold fronts. By unlocking decades of high-resolution rainfall\ninformation from globally available coarse records, WassDiff offers a practical\npathway toward more accurate flood-risk assessments and climate-adaptation\nplanning.",
      "tldr_zh": "该研究针对极端降水风险评估的需求，提出Wasserstein Regularized Diffusion (WassDiff)框架，以解决高分辨率数据历史记录有限和粗分辨率数据无法捕捉局部极端的问题。WassDiff将扩散建模与Wasserstein正则化相结合，在生成1 km降水估计时抑制偏差，并基于55 km CPC降水数据和31 km ERA5再分析数据进行条件生成。实验结果显示，该方法在全强度范围内保持良好校准，比现有下采样技术显著降低重建错误和偏差，并在极端天气案例中准确重现细尺度结构和峰值强度。通过从全球粗分辨率记录中解锁高分辨率降水信息，WassDiff为更精确的洪水风险评估和气候适应规划提供实用途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 10 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.00381v2",
      "published_date": "2024-10-01 04:12:40 UTC",
      "updated_date": "2025-04-29 20:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:49:30.632906"
    },
    {
      "arxiv_id": "2410.00379v1",
      "title": "CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Fuling Wang",
        "Yuehang Li",
        "Qingchuan Ma",
        "Shiao Wang",
        "Bo Jiang",
        "Chuanfu Li",
        "Jin Tang"
      ],
      "abstract": "X-ray image-based medical report generation (MRG) is a pivotal area in\nartificial intelligence which can significantly reduce diagnostic burdens and\npatient wait times. Despite significant progress, we believe that the task has\nreached a bottleneck due to the limited benchmark datasets and the existing\nlarge models' insufficient capability enhancements in this specialized domain.\nSpecifically, the recently released CheXpert Plus dataset lacks comparative\nevaluation algorithms and their results, providing only the dataset itself.\nThis situation makes the training, evaluation, and comparison of subsequent\nalgorithms challenging. Thus, we conduct a comprehensive benchmarking of\nexisting mainstream X-ray report generation models and large language models\n(LLMs), on the CheXpert Plus dataset. We believe that the proposed benchmark\ncan provide a solid comparative basis for subsequent algorithms and serve as a\nguide for researchers to quickly grasp the state-of-the-art models in this\nfield. More importantly, we propose a large model for the X-ray image report\ngeneration using a multi-stage pre-training strategy, including self-supervised\nautoregressive generation and Xray-report contrastive learning, and supervised\nfine-tuning. Extensive experimental results indicate that the autoregressive\npre-training based on Mamba effectively encodes X-ray images, and the\nimage-text contrastive pre-training further aligns the feature spaces,\nachieving better experimental results. Source code can be found on\n\\url{https://github.com/Event-AHU/Medical_Image_Analysis}.",
      "tldr_zh": "该论文针对 X-ray 图像-based 医疗报告生成 (MRG) 任务的瓶颈问题，提出了 CXPMRG-Bench 基准框架，并在 CheXpert Plus 数据集上对主流 X-ray 报告生成模型和大型语言模型 (LLMs) 进行了全面基准测试，提供了一个可靠的比较基础。研究者开发了一个新模型，使用多阶段预训练策略，包括自监督的自回归生成和 Xray-report contrastive learning，以及后续的监督 fine-tuning，以有效编码 X-ray 图像并对齐图像-文本特征空间。实验结果显示，该模型基于 Mamba 的自回归预训练取得了更好的性能，为后续研究提供了指导和源代码支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "In Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2410.00379v1",
      "published_date": "2024-10-01 04:07:01 UTC",
      "updated_date": "2024-10-01 04:07:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:49:43.887865"
    },
    {
      "arxiv_id": "2410.12812v1",
      "title": "Optimizing and Evaluating Enterprise Retrieval-Augmented Generation (RAG): A Content Design Perspective",
      "title_zh": "优化和评估企业级检索增强生成 (RAG)：内容设计视角",
      "authors": [
        "Sarah Packowski",
        "Inge Halilovic",
        "Jenifer Schlotfeldt",
        "Trish Smith"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is a popular technique for using large\nlanguage models (LLMs) to build customer-support, question-answering solutions.\nIn this paper, we share our team's practical experience building and\nmaintaining enterprise-scale RAG solutions that answer users' questions about\nour software based on product documentation. Our experience has not always\nmatched the most common patterns in the RAG literature. This paper focuses on\nsolution strategies that are modular and model-agnostic. For example, our\nexperience over the past few years - using different search methods and LLMs,\nand many knowledge base collections - has been that simple changes to the way\nwe create knowledge base content can have a huge impact on our RAG solutions'\nsuccess. In this paper, we also discuss how we monitor and evaluate results.\nCommon RAG benchmark evaluation techniques have not been useful for evaluating\nresponses to novel user questions, so we have found a flexible, \"human in the\nlead\" approach is required.",
      "tldr_zh": "这篇论文从内容设计角度优化和评估企业级 Retrieval-Augmented Generation (RAG) 系统，用于基于产品文档回答用户关于软件的问题。作者分享了实际经验，强调知识库内容创建的简单变化（如搜索方法和LLMs的使用）对RAG解决方案成功有巨大影响，并采用模块化和模型无关的策略。实验发现，传统RAG基准评估技术不适用于新颖用户问题，因此团队采用灵活、以人为主导的方法进行监控和评估。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages, 4 figures, to be published in ICAAI 2024 conference\n  proceedings",
      "pdf_url": "http://arxiv.org/pdf/2410.12812v1",
      "published_date": "2024-10-01 03:54:45 UTC",
      "updated_date": "2024-10-01 03:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:49:54.336943"
    },
    {
      "arxiv_id": "2410.00373v1",
      "title": "Robust Traffic Forecasting against Spatial Shift over Years",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjun Wang",
        "Jiyuan Chen",
        "Tong Pan",
        "Zheng Dong",
        "Lingyu Zhang",
        "Renhe Jiang",
        "Xuan Song"
      ],
      "abstract": "Recent advancements in Spatiotemporal Graph Neural Networks (ST-GNNs) and\nTransformers have demonstrated promising potential for traffic forecasting by\neffectively capturing both temporal and spatial correlations. The\ngeneralization ability of spatiotemporal models has received considerable\nattention in recent scholarly discourse. However, no substantive datasets\nspecifically addressing traffic out-of-distribution (OOD) scenarios have been\nproposed. Existing ST-OOD methods are either constrained to testing on extant\ndata or necessitate manual modifications to the dataset. Consequently, the\ngeneralization capacity of current spatiotemporal models in OOD scenarios\nremains largely underexplored. In this paper, we investigate state-of-the-art\nmodels using newly proposed traffic OOD benchmarks and, surprisingly, find that\nthese models experience a significant decline in performance. Through\nmeticulous analysis, we attribute this decline to the models' inability to\nadapt to previously unobserved spatial relationships. To address this\nchallenge, we propose a novel Mixture of Experts (MoE) framework, which learns\na set of graph generators (i.e., graphons) during training and adaptively\ncombines them to generate new graphs based on novel environmental conditions to\nhandle spatial distribution shifts during testing. We further extend this\nconcept to the Transformer architecture, achieving substantial improvements.\nOur method is both parsimonious and efficacious, and can be seamlessly\nintegrated into any spatiotemporal model, outperforming current\nstate-of-the-art approaches in addressing spatial dynamics.",
      "tldr_zh": "该研究发现，现有的 Spatiotemporal Graph Neural Networks (ST-GNNs) 和 Transformers 在交通预测中面对空间分布偏移 (spatial shift) 时，泛化能力不足，导致性能显著下降，主要原因是无法适应新的空间关系。针对这一问题，论文提出了一种新型 Mixture of Experts (MoE) 框架，该框架在训练时学习一组图生成器 (graphons)，并在测试时自适应组合以处理 Out-of-Distribution (OOD) 场景。实验结果显示，该方法扩展到 Transformer 架构后实现了显著改进，并可无缝集成到任何时空模型中，优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00373v1",
      "published_date": "2024-10-01 03:49:29 UTC",
      "updated_date": "2024-10-01 03:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:50:07.042706"
    },
    {
      "arxiv_id": "2410.00366v1",
      "title": "Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare",
      "title_zh": "Eas",
      "authors": [
        "Prasenjit Maji",
        "Amit Kumar Mondal",
        "Hemanta Kumar Mondal",
        "Saraju P. Mohanty"
      ],
      "abstract": "The rapid advancements in artificial intelligence (AI) have revolutionized\nsmart healthcare, driving innovations in wearable technologies, continuous\nmonitoring devices, and intelligent diagnostic systems. However, security,\nexplainability, robustness, and performance optimization challenges remain\ncritical barriers to widespread adoption in clinical environments. This\nresearch presents an innovative algorithmic method using the Adaptive Feature\nEvaluator (AFE) algorithm to improve feature selection in healthcare datasets\nand overcome problems. AFE integrating Genetic Algorithms (GA), Explainable\nArtificial Intelligence (XAI), and Permutation Combination Techniques (PCT),\nthe algorithm optimizes Clinical Decision Support Systems (CDSS), thereby\nenhancing predictive accuracy and interpretability. The proposed method is\nvalidated across three diverse healthcare datasets using six distinct machine\nlearning algorithms, demonstrating its robustness and superiority over\nconventional feature selection techniques. The results underscore the\ntransformative potential of AFE in smart healthcare, enabling personalized and\ntransparent patient care. Notably, the AFE algorithm, when combined with a\nMulti-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting\nits capability to improve clinical decision-making processes in real-world\nhealthcare applications.",
      "tldr_zh": "这篇论文介绍了 Easydiagnos 框架及其核心算法 Adaptive Feature Evaluator (AFE)，旨在通过精确的特征选择提升智能医疗中的自动诊断性能。AFE 整合了 Genetic Algorithms (GA)、Explainable Artificial Intelligence (XAI) 和 Permutation Combination Techniques (PCT)，以优化 Clinical Decision Support Systems (CDSS)，从而提高预测准确性和可解释性。研究在三个多样化的医疗数据集上，使用六种机器学习算法进行验证，结果显示 AFE 优于传统方法，并与 Multi-layer Perceptron (MLP) 结合实现了高达 98.5% 的准确率，展示了其在个性化医疗决策中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00366v1",
      "published_date": "2024-10-01 03:28:56 UTC",
      "updated_date": "2024-10-01 03:28:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:50:19.369139"
    },
    {
      "arxiv_id": "2410.00362v1",
      "title": "FedPT: Federated Proxy-Tuning of Large Language Models on Resource-Constrained Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Zhidong Gao",
        "Yu Zhang",
        "Zhenxiao Zhang",
        "Yanmin Gong",
        "Yuanxiong Guo"
      ],
      "abstract": "Despite demonstrating superior performance across a variety of linguistic\ntasks, pre-trained large language models (LMs) often require fine-tuning on\nspecific datasets to effectively address different downstream tasks. However,\nfine-tuning these LMs for downstream tasks necessitates collecting data from\nindividuals, which raises significant privacy concerns. Federated learning (FL)\nhas emerged as the de facto solution, enabling collaborative model training\nwithout sharing raw data. While promising, federated fine-tuning of large LMs\nfaces significant challenges, including restricted access to model parameters\nand high computation, communication, and memory overhead. To address these\nchallenges, this paper introduces \\textbf{Fed}erated\n\\textbf{P}roxy-\\textbf{T}uning (FedPT), a novel framework for federated\nfine-tuning of black-box large LMs, requiring access only to their predictions\nover the output vocabulary instead of their parameters. Specifically, devices\nin FedPT first collaboratively tune a smaller LM, and then the server combines\nthe knowledge learned by the tuned small LM with the knowledge learned by the\nlarger pre-trained LM to construct a large proxy-tuned LM that can reach the\nperformance of directly tuned large LMs. The experimental results demonstrate\nthat FedPT can significantly reduce computation, communication, and memory\noverhead while maintaining competitive performance compared to directly\nfederated fine-tuning of large LMs. FedPT offers a promising solution for\nefficient, privacy-preserving fine-tuning of large LMs on resource-constrained\ndevices, broadening the accessibility and applicability of state-of-the-art\nlarge LMs.",
      "tldr_zh": "该论文提出了FedPT，一种针对资源受限边缘设备的联邦代理微调框架，用于处理大型语言模型(LMs)的隐私保护微调问题。FedPT允许设备仅访问LMs的输出预测，而非模型参数，通过先协作微调一个较小LM，然后由服务器将该小LM的知识与大型预训练LM结合，构建高效的代理微调LM。实验结果显示，FedPT显著降低了计算、通信和内存开销，同时保持与直接联邦微调大型LMs相当的性能，为隐私保护的LMs微调提供了可扩展解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.00362v1",
      "published_date": "2024-10-01 03:20:39 UTC",
      "updated_date": "2024-10-01 03:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:50:29.753705"
    },
    {
      "arxiv_id": "2410.00359v1",
      "title": "Self-controller: Controlling LLMs with Multi-round Step-by-step Self-awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Peng",
        "Xufan Geng"
      ],
      "abstract": "The applications of large language models (LLMs) have been widely spread\nacross all domains. However, the basic abilities such as the controllability of\nLLMs are still limited. To address this, we propose \"Self-controller\", a novel\nagentic framework bringing self-awareness into LLMs' reasoning logic. The core\nidea of this work is to maintain states based on the LLM's response, letting\nthe LLM become self-aware of current status and think step by step in a\nmulti-round chain-of-thought paradigm. Our experiment on the state of textual\nlength has shown the controllability and effectiveness of the Self-controller.\nWe further implement a binary search algorithm to accelerate the generation\nprocess based on the linearity and monotonicity of the textual length state.\nAnother advantage of the Self-controller comes with DeepSeek's Context Caching\ntechnology, which significantly saves computational token consumption when a\ncluster of conversations shares the same prefix of context. Theoretically, we\nprove that in this scenario the extra time complexity is $O(c \\log n)$. Results\nof the back-of-the-envelope estimation suggest that the token consumption of\nour method is no more than twice as much as that of the trivial single-round\ngeneration. Furthermore, our ablation study on word constraints demonstrates\nthe Self-controller's consistent controllability across all foundation models.",
      "tldr_zh": "该研究提出Self-controller框架，通过多轮步步为营的自意识机制（multi-round step-by-step self-awareness），让大型语言模型（LLMs）基于响应维护状态，从而提升其可控性和推理逻辑。框架的核心是将LLMs转化为自觉代理，在实验中通过文本长度控制展示了其有效性，并结合二分搜索算法加速生成过程。结果表明，Self-controller显著节省计算令牌消耗，额外时间复杂度为O(c log n)，且在单词约束的消融研究中显示出在各种基础模型上的一致可控性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.00359v1",
      "published_date": "2024-10-01 03:14:12 UTC",
      "updated_date": "2024-10-01 03:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:50:42.608007"
    },
    {
      "arxiv_id": "2410.00340v3",
      "title": "Sparse Attention Decomposition Applied to Circuit Tracing",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Franco",
        "Mark Crovella"
      ],
      "abstract": "Many papers have shown that attention heads work in conjunction with each\nother to perform complex tasks. It's frequently assumed that communication\nbetween attention heads is via the addition of specific features to token\nresiduals. In this work we seek to isolate and identify the features used to\neffect communication and coordination among attention heads in GPT-2 small. Our\nkey leverage on the problem is to show that these features are very often\nsparsely coded in the singular vectors of attention head matrices. We\ncharacterize the dimensionality and occurrence of these signals across the\nattention heads in GPT-2 small when used for the Indirect Object Identification\n(IOI) task. The sparse encoding of signals, as provided by attention head\nsingular vectors, allows for efficient separation of signals from the residual\nbackground and straightforward identification of communication paths between\nattention heads. We explore the effectiveness of this approach by tracing\nportions of the circuits used in the IOI task. Our traces reveal considerable\ndetail not present in previous studies, shedding light on the nature of\nredundant paths present in GPT-2. And our traces go beyond previous work by\nidentifying features used to communicate between attention heads when\nperforming IOI.",
      "tldr_zh": "本文提出了一种稀疏注意力分解（Sparse Attention Decomposition）方法，用于追踪GPT-2 small模型中注意力头（attention heads）的通信特征，通过分析注意力头矩阵的奇异向量（singular vectors），发现这些特征通常以稀疏编码形式存在，从而高效分离信号并识别通信路径。该方法应用于Indirect Object Identification (IOI)任务，揭示了模型中冗余路径的详细结构，并超越了以往研究，提供更全面的注意力头间协调机制分析。整体结果为理解Transformer模型内部机制提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00340v3",
      "published_date": "2024-10-01 02:34:08 UTC",
      "updated_date": "2024-10-28 21:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:50:55.423982"
    },
    {
      "arxiv_id": "2410.03739v2",
      "title": "Grammar Induction from Visual, Speech and Text",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Zhao",
        "Hao Fei",
        "Shengqiong Wu",
        "Meishan Zhang",
        "Min Zhang",
        "Tat-seng Chua"
      ],
      "abstract": "Grammar Induction could benefit from rich heterogeneous signals, such as\ntext, vision, and acoustics. In the process, features from distinct modalities\nessentially serve complementary roles to each other. With such intuition, this\nwork introduces a novel \\emph{unsupervised visual-audio-text grammar induction}\ntask (named \\textbf{VAT-GI}), to induce the constituent grammar trees from\nparallel images, text, and speech inputs. Inspired by the fact that language\ngrammar natively exists beyond the texts, we argue that the text has not to be\nthe predominant modality in grammar induction. Thus we further introduce a\n\\emph{textless} setting of VAT-GI, wherein the task solely relies on visual and\nauditory inputs. To approach the task, we propose a visual-audio-text\ninside-outside recursive autoencoder (\\textbf{VaTiora}) framework, which\nleverages rich modal-specific and complementary features for effective grammar\nparsing. Besides, a more challenging benchmark data is constructed to assess\nthe generalization ability of VAT-GI system. Experiments on two benchmark\ndatasets demonstrate that our proposed VaTiora system is more effective in\nincorporating the various multimodal signals, and also presents new\nstate-of-the-art performance of VAT-GI.",
      "tldr_zh": "本研究引入了无监督视觉-音频-文本语法归纳任务（VAT-GI），旨在从图像、文本和语音的并行输入中归纳成分语法树，利用不同模态的互补特征来提升语法归纳效果。不同于传统方法，该任务还提出一个无文本设置（textless），仅依赖视觉和听觉输入，强调语法存在于文本之外的模态中。为实现这一目标，研究者开发了视觉-音频-文本内外递归自编码器框架（VaTiora），该框架有效整合多模态特定和互补特征进行语法解析。在两个基准数据集上的实验表明，VaTiora 系统显著提高了多模态信号的利用效率，并达到了 VAT-GI 的新最先进性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03739v2",
      "published_date": "2024-10-01 02:24:18 UTC",
      "updated_date": "2025-02-20 07:46:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:51:06.984051"
    },
    {
      "arxiv_id": "2410.00334v1",
      "title": "Preserving Generalization of Language models in Few-shot Continual Relation Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Quyen Tran",
        "Nguyen Xuan Thanh",
        "Nguyen Hoang Anh",
        "Nam Le Hai",
        "Trung Le",
        "Linh Van Ngo",
        "Thien Huu Nguyen"
      ],
      "abstract": "Few-shot Continual Relations Extraction (FCRE) is an emerging and dynamic\narea of study where models can sequentially integrate knowledge from new\nrelations with limited labeled data while circumventing catastrophic forgetting\nand preserving prior knowledge from pre-trained backbones. In this work, we\nintroduce a novel method that leverages often-discarded language model heads.\nBy employing these components via a mutual information maximization strategy,\nour approach helps maintain prior knowledge from the pre-trained backbone and\nstrategically aligns the primary classification head, thereby enhancing model\nperformance. Furthermore, we explore the potential of Large Language Models\n(LLMs), renowned for their wealth of knowledge, in addressing FCRE challenges.\nOur comprehensive experimental results underscore the efficacy of the proposed\nmethod and offer valuable insights for future work.",
      "tldr_zh": "本研究针对Few-shot Continual Relation Extraction (FCRE)问题，提出了一种新方法，通过利用通常被忽略的语言模型头（language model heads）并采用互信息最大化（mutual information maximization）策略，来保留预训练骨干的先验知识，同时对主要分类头进行战略性对齐，从而缓解灾难性遗忘（catastrophic forgetting）和提升模型性能。实验结果显示，该方法在FCRE任务中显著提高了模型的泛化能力，并探讨了Large Language Models (LLMs)在其中的潜力，为未来研究提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.00334v1",
      "published_date": "2024-10-01 02:22:34 UTC",
      "updated_date": "2024-10-01 02:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:51:17.513828"
    },
    {
      "arxiv_id": "2410.00332v5",
      "title": "Vision Language Models Know Law of Conservation without Understanding More-or-Less",
      "title_zh": "翻译失败",
      "authors": [
        "Dezhi Luo",
        "Haiyun Lyu",
        "Qingying Gao",
        "Haoran Sun",
        "Yijiang Li",
        "Hokin Deng"
      ],
      "abstract": "Understanding law of conservation is a critical milestone in human cognitive\ndevelopment considered to be supported by the apprehension of quantitative\nconcepts and the reversibility of operations. To assess whether this critical\ncomponent of human intelligence has emerged in Vision Language Models, we have\ncurated the ConserveBench, a battery of 365 cognitive experiments across four\ndimensions of physical quantities: volume, solid quantity, length, and number.\nThe former two involve transformational tasks which require reversibility\nunderstanding. The latter two involve non-transformational tasks which assess\nquantity understanding. Surprisingly, we find that while Vision Language Models\nare generally good at transformational tasks, they tend to fail at\nnon-transformational tasks. There is a dissociation between understanding the\nreversibility of operations and understanding the concept of quantity, which\nboth are believed to be the cornerstones of understanding law of conservation\nin humans. $\\href{https://growing-ai-like-a-child.github.io/}{Website}$",
      "tldr_zh": "这篇论文评估了视觉语言模型（Vision Language Models）是否理解守恒定律（Law of Conservation），发现这些模型在处理可逆性操作时表现出色，但缺乏对数量概念的全面把握。研究者创建了 ConserveBench 基准，包含 365 个认知实验，涵盖体积、固体数量、长度和数字四个维度的任务，其中前两项涉及需要 reversibility 理解的转换任务，后两项评估数量理解的非转换任务。结果显示，Vision Language Models 在转换任务上表现良好，但在非转换任务上失败，导致理解守恒定律的认知分离，这突显了模型与人类智能的差异。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at the ICLR 2025 Workshop on Bidirectional Human-AI\n  Alignment (BiAlign)",
      "pdf_url": "http://arxiv.org/pdf/2410.00332v5",
      "published_date": "2024-10-01 02:15:49 UTC",
      "updated_date": "2025-04-13 04:31:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:51:30.667785"
    },
    {
      "arxiv_id": "2410.00327v1",
      "title": "EnzymeFlow: Generating Reaction-specific Enzyme Catalytic Pockets through Flow Matching and Co-Evolutionary Dynamics",
      "title_zh": "EnzymeFlow：通过流匹配和共",
      "authors": [
        "Chenqing Hua",
        "Yong Liu",
        "Dinghuai Zhang",
        "Odin Zhang",
        "Sitao Luan",
        "Kevin K. Yang",
        "Guy Wolf",
        "Doina Precup",
        "Shuangjia Zheng"
      ],
      "abstract": "Enzyme design is a critical area in biotechnology, with applications ranging\nfrom drug development to synthetic biology. Traditional methods for enzyme\nfunction prediction or protein binding pocket design often fall short in\ncapturing the dynamic and complex nature of enzyme-substrate interactions,\nparticularly in catalytic processes. To address the challenges, we introduce\nEnzymeFlow, a generative model that employs flow matching with hierarchical\npre-training and enzyme-reaction co-evolution to generate catalytic pockets for\nspecific substrates and catalytic reactions. Additionally, we introduce a\nlarge-scale, curated, and validated dataset of enzyme-reaction pairs,\nspecifically designed for the catalytic pocket generation task, comprising a\ntotal of $328,192$ pairs. By incorporating evolutionary dynamics and\nreaction-specific adaptations, EnzymeFlow becomes a powerful model for\ndesigning enzyme pockets, which is capable of catalyzing a wide range of\nbiochemical reactions. Experiments on the new dataset demonstrate the model's\neffectiveness in designing high-quality, functional enzyme catalytic pockets,\npaving the way for advancements in enzyme engineering and synthetic biology. We\nprovide EnzymeFlow code at https://github.com/WillHua127/EnzymeFlow with\nnotebook demonstration at\nhttps://github.com/WillHua127/EnzymeFlow/blob/main/enzymeflow_demo.ipynb.",
      "tldr_zh": "本研究提出 EnzymeFlow，一种生成模型，通过 flow matching 和 co-evolutionary dynamics 结合 hierarchical pre-training 和酶-反应共进化动态，针对特定底物和催化反应设计高质酶催化口袋，以克服传统方法在捕捉酶-底物互动复杂性上的不足。\n此外，研究构建了一个大型数据集，包含 328,192 对经 curation 和验证的酶-反应对，用于催化口袋生成任务。\n实验结果表明，EnzymeFlow 在该数据集上表现出色，能有效设计功能性酶口袋，推动酶工程和合成生物学的进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00327v1",
      "published_date": "2024-10-01 02:04:01 UTC",
      "updated_date": "2024-10-01 02:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:51:42.324099"
    },
    {
      "arxiv_id": "2410.00324v5",
      "title": "Vision Language Models See What You Want but not What You See",
      "title_zh": "翻译失败",
      "authors": [
        "Qingying Gao",
        "Yijiang Li",
        "Haiyun Lyu",
        "Haoran Sun",
        "Dezhi Luo",
        "Hokin Deng"
      ],
      "abstract": "Knowing others' intentions and taking others' perspectives are two core\ncomponents of human intelligence that are considered to be instantiations of\ntheory-of-mind. Infiltrating machines with these abilities is an important step\ntowards building human-level artificial intelligence. Here, to investigate\nintentionality understanding and level-2 perspective-taking in Vision Language\nModels (VLMs), we constructed the IntentBench and PerspectBench, which together\ncontains over 300 cognitive experiments grounded in real-world scenarios and\nclassic cognitive tasks. We found VLMs achieving high performance on\nintentionality understanding but low performance on level-2 perspective-taking.\nThis suggests a potential dissociation between simulation-based and\ntheory-based theory-of-mind abilities in VLMs, highlighting the concern that\nthey are not capable of using model-based reasoning to infer others' mental\nstates. See $\\href{https://growing-ai-like-a-child.github.io/}{Website}$",
      "tldr_zh": "这篇论文探讨了视觉语言模型（VLMs）在理论-of-mind 能力中的表现，特别是理解他人意图（intentionality understanding）和二级视角采纳（level-2 perspective-taking）。研究者构建了 IntentBench 和 PerspectBench 两个基准测试，共包含超过 300 个基于真实场景和经典认知任务的实验。结果显示，VLMs 在意图理解方面表现出色，但在二级视角采纳上表现较差，这可能反映了 simulation-based 和 theory-based 理论-of-mind 能力的分离。最终，该研究质疑了 VLMs 是否能通过 model-based reasoning 来准确推断他人心理状态。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at the ICLR 2025 Workshop on Bidirectional Human-AI\n  Alignment (BiAlign)",
      "pdf_url": "http://arxiv.org/pdf/2410.00324v5",
      "published_date": "2024-10-01 01:52:01 UTC",
      "updated_date": "2025-04-13 05:41:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:51:54.609895"
    },
    {
      "arxiv_id": "2410.00318v3",
      "title": "Probing Mechanical Reasoning in Large Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Sun",
        "Qingying Gao",
        "Haiyun Lyu",
        "Dezhi Luo",
        "Yijiang Li",
        "Hokin Deng"
      ],
      "abstract": "Mechanical reasoning is a hallmark of human intelligence, defined by its\nubiquitous yet irreplaceable role in human activities ranging from routine\ntasks to civil engineering. Embedding machines with mechanical reasoning is\ntherefore an important step towards building human-level artificial\nintelligence. Here, we leveraged 155 cognitive experiments to test the\nunderstanding of system stability, gears and pulley systems, leverage\nprinciple, inertia and motion, and fluid mechanics in 26 Vision Language Models\n(VLMs). Results indicate that VLMs consistently perform worse than humans on\nall domains, while demonstrate significant difficulty in reasoning about gear\nsystems and fluid mechanics. Notably, their performance on these tasks do not\nimprove as number of parameters increase, suggesting that current\nattention-based architecture may fail to grasp certain underlying mechanisms\nrequired for mechanical reasoning, particularly those pertaining to mental\nsimulations.",
      "tldr_zh": "本研究评估了26个视觉语言模型(VLMs)在机械推理方面的表现，通过155个认知实验测试其对系统稳定性、齿轮和滑轮系统、杠杆原理、惯性和运动以及流体力学的理解。结果显示，VLMs在所有领域均逊色于人类，尤其在齿轮系统和流体力学上表现出显著困难。值得注意的是，VLMs的性能并未随参数数量增加而提升，这表明当前基于注意力的架构可能无法有效捕捉机械推理所需的底层机制，特别是涉及心理模拟的方面。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at the ICLR 2025 Workshop on Bidirectional Human-AI\n  Alignment (BiAlign)",
      "pdf_url": "http://arxiv.org/pdf/2410.00318v3",
      "published_date": "2024-10-01 01:33:10 UTC",
      "updated_date": "2025-04-13 05:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:52:05.654883"
    },
    {
      "arxiv_id": "2410.00316v1",
      "title": "EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control",
      "title_zh": "EmoKnob：通过细粒度情感控制增强语音克隆",
      "authors": [
        "Haozhe Chen",
        "Run Chen",
        "Julia Hirschberg"
      ],
      "abstract": "While recent advances in Text-to-Speech (TTS) technology produce natural and\nexpressive speech, they lack the option for users to select emotion and control\nintensity. We propose EmoKnob, a framework that allows fine-grained emotion\ncontrol in speech synthesis with few-shot demonstrative samples of arbitrary\nemotion. Our framework leverages the expressive speaker representation space\nmade possible by recent advances in foundation voice cloning models. Based on\nthe few-shot capability of our emotion control framework, we propose two\nmethods to apply emotion control on emotions described by open-ended text,\nenabling an intuitive interface for controlling a diverse array of nuanced\nemotions. To facilitate a more systematic emotional speech synthesis field, we\nintroduce a set of evaluation metrics designed to rigorously assess the\nfaithfulness and recognizability of emotion control frameworks. Through\nobjective and subjective evaluations, we show that our emotion control\nframework effectively embeds emotions into speech and surpasses emotion\nexpressiveness of commercial TTS services.",
      "tldr_zh": "本研究提出 EmoKnob 框架，用于提升 Text-to-Speech (TTS) 语音合成中的细粒度情感控制，允许用户通过少样本演示样本实现任意情感的精确调节和强度控制。框架利用基础语音克隆模型的表达性说话者表示空间，并引入两种方法处理开放文本描述的情感，提供直观的界面。作者还设计了一套评估指标来评估情感忠实度和可识别性，通过客观和主观实验证明，EmoKnob 显著超越商业 TTS 服务，在情感表达上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2410.00316v1",
      "published_date": "2024-10-01 01:29:54 UTC",
      "updated_date": "2024-10-01 01:29:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:52:18.434223"
    },
    {
      "arxiv_id": "2410.00312v1",
      "title": "Contrastive Representation Learning for Predicting Solar Flares from Extremely Imbalanced Multivariate Time Series Data",
      "title_zh": "翻译失败",
      "authors": [
        "Onur Vural",
        "Shah Muhammad Hamdi",
        "Soukaina Filali Boubrahimi"
      ],
      "abstract": "Major solar flares are abrupt surges in the Sun's magnetic flux, presenting\nsignificant risks to technological infrastructure. In view of this, effectively\npredicting major flares from solar active region magnetic field data through\nmachine learning methods becomes highly important in space weather research.\nMagnetic field data can be represented in multivariate time series modality\nwhere the data displays an extreme class imbalance due to the rarity of major\nflare events. In time series classification-based flare prediction, the use of\ncontrastive representation learning methods has been relatively limited. In\nthis paper, we introduce CONTREX, a novel contrastive representation learning\napproach for multivariate time series data, addressing challenges of temporal\ndependencies and extreme class imbalance. Our method involves extracting\ndynamic features from the multivariate time series instances, deriving two\nextremes from positive and negative class feature vectors that provide maximum\nseparation capability, and training a sequence representation embedding module\nwith the original multivariate time series data guided by our novel contrastive\nreconstruction loss to generate embeddings aligned with the extreme points.\nThese embeddings capture essential time series characteristics and enhance\ndiscriminative power. Our approach shows promising solar flare prediction\nresults on the Space Weather Analytics for Solar Flares (SWAN-SF) multivariate\ntime series benchmark dataset against baseline methods.",
      "tldr_zh": "本文提出了一种名为 CONTREX 的对比表示学习方法，用于从极端不平衡的多变量时间序列数据中预测太阳耀斑，从而应对时间依赖性和类不平衡挑战。该方法通过提取动态特征、衍生正负类极端点，并利用新型对比重建损失训练序列表示嵌入模块，以生成更具区分能力的嵌入向量。实验结果显示，在 SWAN-SF 基准数据集上，CONTREX 相较于基线方法取得了显著的预测性能提升。",
      "categories": [
        "astro-ph.SR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "This work has been accepted at ICMLA 2024 on September 7, 2024, as a\n  short paper for poster presentation",
      "pdf_url": "http://arxiv.org/pdf/2410.00312v1",
      "published_date": "2024-10-01 01:20:47 UTC",
      "updated_date": "2024-10-01 01:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:52:30.701135"
    },
    {
      "arxiv_id": "2410.00309v1",
      "title": "Ask, Pose, Unite: Scaling Data Acquisition for Close Interactions with Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Laura Bravo-Sánchez",
        "Jaewoo Heo",
        "Zhenzhen Weng",
        "Kuan-Chieh Wang",
        "Serena Yeung-Levy"
      ],
      "abstract": "Social dynamics in close human interactions pose significant challenges for\nHuman Mesh Estimation (HME), particularly due to the complexity of physical\ncontacts and the scarcity of training data. Addressing these challenges, we\nintroduce a novel data generation method that utilizes Large Vision Language\nModels (LVLMs) to annotate contact maps which guide test-time optimization to\nproduce paired image and pseudo-ground truth meshes. This methodology not only\nalleviates the annotation burden but also enables the assembly of a\ncomprehensive dataset specifically tailored for close interactions in HME. Our\nAsk Pose Unite (APU) dataset, comprising over 6.2k human mesh pairs in contact\ncovering diverse interaction types, is curated from images depicting\nnaturalistic person-to-person scenes. We empirically show that using our\ndataset to train a diffusion-based contact prior, used as guidance during\noptimization, improves mesh estimation on unseen interactions. Our work\naddresses longstanding challenges of data scarcity for close interactions in\nHME enhancing the field's capabilities of handling complex interaction\nscenarios.",
      "tldr_zh": "这篇论文针对人类网格估计 (HME) 在处理亲密人类互动时的物理接触复杂性和数据稀缺挑战，提出了一种新颖的数据生成方法，利用大型视觉语言模型 (LVLMs) 注解接触地图，并指导测试时优化以产生配对的图像和伪地面真实网格。研究者创建了 Ask Pose Unite (APU) 数据集，包含超过 6.2k 个人类网格对，涵盖多样化的自然人际互动场景，从而减轻了数据注解负担。实验结果显示，使用该数据集训练基于扩散的接触先验作为优化指导，能显著提升对未见互动的网格估计性能。该工作解决了 HME 领域长期存在的亲密互动数据不足问题，提升了对复杂场景的处理能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project webpage: https://laubravo.github.io/apu_website/",
      "pdf_url": "http://arxiv.org/pdf/2410.00309v1",
      "published_date": "2024-10-01 01:14:24 UTC",
      "updated_date": "2024-10-01 01:14:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:52:45.744883"
    },
    {
      "arxiv_id": "2410.03738v2",
      "title": "ERASMO: Leveraging Large Language Models for Enhanced Clustering Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Fillipe dos Santos Silva",
        "Gabriel Kenzo Kakimoto",
        "Julio Cesar dos Reis",
        "Marcelo S. Reis"
      ],
      "abstract": "Cluster analysis plays a crucial role in various domains and applications,\nsuch as customer segmentation in marketing. These contexts often involve\nmultimodal data, including both tabular and textual datasets, making it\nchallenging to represent hidden patterns for obtaining meaningful clusters.\nThis study introduces ERASMO, a framework designed to fine-tune a pretrained\nlanguage model on textually encoded tabular data and generate embeddings from\nthe fine-tuned model. ERASMO employs a textual converter to transform tabular\ndata into a textual format, enabling the language model to process and\nunderstand the data more effectively. Additionally, ERASMO produces\ncontextually rich and structurally representative embeddings through techniques\nsuch as random feature sequence shuffling and number verbalization. Extensive\nexperimental evaluations were conducted using multiple datasets and baseline\napproaches. Our results demonstrate that ERASMO fully leverages the specific\ncontext of each tabular dataset, leading to more precise and nuanced embeddings\nfor accurate clustering. This approach enhances clustering performance by\ncapturing complex relationship patterns within diverse tabular data.",
      "tldr_zh": "该研究提出 ERASMO 框架，利用 Large Language Models (LLMs) 提升聚类分析性能，尤其针对多模态数据如表格和文本数据集的隐藏模式表示挑战。ERASMO 通过文本转换器将表格数据转化为文本格式，并细调预训练语言模型生成嵌入，同时采用随机特征序列洗牌和数字 verbalization 等技术，以捕捉更丰富的上下文和结构关系。实验结果显示，ERASMO 在多个数据集上比基线方法显著提高聚类准确性，实现了更精确的嵌入和增强的聚类性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50 (Natural language processing), 68T01 (General topics in\n  artificial intelligence)"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 10 figures, published in BRACIS 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2410.03738v2",
      "published_date": "2024-10-01 00:37:16 UTC",
      "updated_date": "2025-02-04 15:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:52:53.828877"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 98,
  "processed_papers_count": 98,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T05:53:14.655559"
}