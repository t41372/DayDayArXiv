{
  "date": "2024-12-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-30 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 76 篇论文，主要聚焦于 AI 生成模型、医疗应用、道德偏见和图神经网络等领域，其中令人印象深刻的包括 TangoFlux 的高效文本到音频生成，以及 GroverGPT 在量子搜索中的高精度表现；知名学者如 Björn W. Schuller 和 Nassir Navab 的论文也值得关注，它们展示了 AI 在实际应用中的潜力。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些创新性强、话题度高或涉及知名学者的文章。对于其他论文，我会快速掠过，只列出标题和核心要点，以控制篇幅。\n\n**AI 生成模型和 LLMs（重点领域，创新性强）**  \n- **TangoFlux: A Large Language Model with 8 Billion Parameters for Quantum Searching（TangoFlux: 一种用于量子搜索的80亿参数大型语言模型）**  \n  这篇论文提出了一种高效的文本到音频生成模型，使用 CLAP-Ranked Preference Optimization（CRPO）框架优化偏好数据，实现97.5%的错误减少，并在音频生成任务上超越现有方法，主要贡献在于提升生成质量和效率。\n  \n- **GroverGPT: A Large Language Model with 8 Billion Parameters for Quantum Searching（GroverGPT: 一种用于量子搜索的80亿参数大型语言模型）**  \n  作者包括 Junyu Liu 和 Tianlong Chen，他们开发了基于 LLaMA 的 GroverGPT 模型，通过模式识别模拟量子搜索算法，在6-10量子比特数据集上达到近100%准确率，显著优于 GPT-4o，这为量子计算模拟提供了新工具。\n\n- **Gender Bias in Text-to-Video Generation Models: A case study of Sora（文本到视频生成模型中的性别偏见：以 Sora 为案例研究）**  \n  作者包括 Björn W. Schuller 和 Amir Hussain，他们分析了 OpenAI 的 Sora 模型，发现它在文本提示下存在性别偏见（如职业刻板印象），主要发现强调了训练数据中的社会偏见问题，并呼吁改进模型公平性。\n\n- **TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization（TangoFlux: 通过流匹配和 CLAP-Ranked 优化实现快速可靠的文本到音频生成）**  \n  这篇快速生成音频的论文使用流匹配和偏好优化，515M 参数模型能在单 GPU 上生成30秒音频只需3.7秒，性能超越现有方法，突出了高效生成在多模态任务中的应用。\n\n**医疗和计算机视觉应用（实际影响大，知名学者参与）**  \n- **A Data-Centric Approach to Detecting and Mitigating Demographic Bias in Pediatric Mental Health Text: A Case Study in Anxiety Detection（一种数据中心方法用于检测和缓解儿科心理健康文本中的人口统计偏见：以焦虑检测为例）**  \n  作者 Nassir Navab 参与，这篇论文提出数据中心去偏框架，通过中和性别语言减少诊断偏差，实验显示在焦虑检测中降低27%偏见，主要贡献在于提升 AI 在医疗中的公平性。\n\n- **Human-AI Teaming Using Large Language Models: Boosting Brain-Computer Interfacing (BCI) and Brain Research（使用大型语言模型的人机协作：提升脑机接口和脑研究）**  \n  作者包括 Tonio Ball 和 Nassir Navab，他们开发了 ChatBCI 工具箱，利用 LLMs 增强脑机接口效率，实验证明在 EEG 信号解码中提升了性能，这为脑研究提供了实用框架。\n\n- **Fall Detection in Passenger Elevators using Intelligent Surveillance Camera Systems: An Application with YoloV8 Nano Model（使用智能监控系统检测电梯中的跌倒事件：基于 YoloV8 Nano 模型的应用）**  \n  这篇论文应用 YoloV8 Nano 模型实现电梯跌倒检测，精度达85%，主要发现在于其在实际场景中的鲁棒性，提升了公共安全监控。\n\n**其他领域（快速掠过，选有代表性的）**  \n- **UnrealZoo: Enriching Photo-realistic Virtual Worlds for Embodied AI（UnrealZoo: 为具身 AI 增强照片级真实虚拟世界）**  \n  贡献：提出 UnrealZoo 数据集，支持视觉导航和跟踪任务，提升 AI 在动态环境中的性能。\n  \n- **SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity（SecBench: 一种用于 LLMs 网络安全的综合多维基准数据集）**  \n  发现：在网络安全任务上，SecBench 帮助评估 LLMs 性能，揭示了模型在知识保留和推理中的局限。\n  \n- **PyG-SSL: A Graph Self-Supervised Learning Toolkit（PyG-SSL: 图自监督学习工具包）**  \n  主要贡献：提供易用框架，支持图神经网络的无监督训练，提升了研究效率。\n  \n其他论文如量子计算、图学习和偏见检测等，虽然涉及多样主题，但相对常规，我仅列出标题不展开讨论，以节省篇幅。例如：\n- **The Text Classification Pipeline: Starting Shallow going Deeper（文本分类管道：从浅层到深层）**  \n- **Federated Learning with Workload Reduction through Partial Training of Client Models and Entropy-Based Data Selection（通过部分训练和熵基于数据选择的联邦学习工作负载减少）**  \n- **DeepLL: Considering Linear Logic for the Analysis of Deep Learning Experiments（DeepLL: 使用线性逻辑分析深度学习实验）**  \n这些论文聚焦基础方法，但未见重大突破，故快速掠过。\n\n总之，今天的论文突出了 AI 在生成和应用领域的进展，建议关注 LLMs 在医疗和道德方面的创新，以推动更可靠的 AI 部署。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2501.00174v2",
      "title": "The Text Classification Pipeline: Starting Shallow going Deeper",
      "title_zh": "文本分类管道：从浅层开始深入更深",
      "authors": [
        "Marco Siino",
        "Ilenia Tinnirello",
        "Marco La Cascia"
      ],
      "abstract": "Text classification stands as a cornerstone within the realm of Natural\nLanguage Processing (NLP), particularly when viewed through computer science\nand engineering. The past decade has seen deep learning revolutionize text\nclassification, propelling advancements in text retrieval, categorization,\ninformation extraction, and summarization. The scholarly literature includes\ndatasets, models, and evaluation criteria, with English being the predominant\nlanguage of focus, despite studies involving Arabic, Chinese, Hindi, and\nothers. The efficacy of text classification models relies heavily on their\nability to capture intricate textual relationships and non-linear correlations,\nnecessitating a comprehensive examination of the entire text classification\npipeline.\n  In the NLP domain, a plethora of text representation techniques and model\narchitectures have emerged, with Large Language Models (LLMs) and Generative\nPre-trained Transformers (GPTs) at the forefront. These models are adept at\ntransforming extensive textual data into meaningful vector representations\nencapsulating semantic information. The multidisciplinary nature of text\nclassification, encompassing data mining, linguistics, and information\nretrieval, highlights the importance of collaborative research to advance the\nfield. This work integrates traditional and contemporary text mining\nmethodologies, fostering a holistic understanding of text classification.",
      "tldr_zh": "这篇论文探讨了文本分类在自然语言处理(NLP)领域的核心地位，以及过去十年深度学习如何推动其在文本检索、分类、信息提取和总结等方面的进展。论文强调，文本分类模型需捕捉复杂的文本关系和非线性相关性，因此对整个分类管道进行全面审查至关重要，包括数据集、模型架构和评估标准，主要聚焦英语但也涉及其他语言如Arabic、Chinese和Hindi。作者整合了传统文本挖掘方法与当代技术，如Large Language Models (LLMs)和Generative Pre-trained Transformers (GPTs)，旨在从浅层到深层构建一个全面的文本表示和分类框架，促进多学科协作以推进该领域的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Foundations and Trends in Information Retrieval (2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.00174v2",
      "published_date": "2024-12-30 23:01:19 UTC",
      "updated_date": "2025-03-20 19:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:42:06.851689"
    },
    {
      "arxiv_id": "2501.00170v1",
      "title": "Federated Learning with Workload Reduction through Partial Training of Client Models and Entropy-Based Data Selection",
      "title_zh": "联邦学习：通过客户端模型部分训练和基于熵的数据选择实现工作负载",
      "authors": [
        "Hongrui Shi",
        "Valentin Radu",
        "Po Yang"
      ],
      "abstract": "With the rapid expansion of edge devices, such as IoT devices, where crucial\ndata needed for machine learning applications is generated, it becomes\nessential to promote their participation in privacy-preserving Federated\nLearning (FL) systems. The best way to achieve this desiderate is by reducing\ntheir training workload to match their constrained computational resources.\nWhile prior FL research has address the workload constrains by introducing\nlightweight models on the edge, limited attention has been given to optimizing\non-device training efficiency through reducing the amount of data need during\ntraining. In this work, we propose FedFT-EDS, a novel approach that combines\nFine-Tuning of partial client models with Entropy-based Data Selection to\nreduce training workloads on edge devices. By actively selecting the most\ninformative local instances for learning, FedFT-EDS reduces training data\nsignificantly in FL and demonstrates that not all user data is equally\nbeneficial for FL on all rounds. Our experiments on CIFAR-10 and CIFAR-100 show\nthat FedFT-EDS uses only 50% user data while improving the global model\nperformance compared to baseline methods, FedAvg and FedProx. Importantly,\nFedFT-EDS improves client learning efficiency by up to 3 times, using one third\nof training time on clients to achieve an equivalent performance to the\nbaselines. This work highlights the importance of data selection in FL and\npresents a promising pathway to scalable and efficient Federate Learning.",
      "tldr_zh": "本文提出 FedFT-EDS 方法，通过部分客户端模型的 Fine-Tuning 和 Entropy-based Data Selection，优化 Federated Learning (FL) 中的训练工作量，旨在减少边缘设备如 IoT 设备的计算负担。FedFT-EDS 主动选择最信息丰富的本地数据，仅使用 50% 用户数据即可提升全局模型性能，比基线方法 FedAvg 和 FedProx 表现更佳。实验在 CIFAR-10 和 CIFAR-100 数据集上显示，该方法将客户端学习效率提高多达 3 倍，使用三分之一的训练时间达到等效性能，并为可扩展、高效的 FL 系统提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00170v1",
      "published_date": "2024-12-30 22:47:32 UTC",
      "updated_date": "2024-12-30 22:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:42:19.753709"
    },
    {
      "arxiv_id": "2501.00169v1",
      "title": "DeepLL: Considering Linear Logic for the Analysis of Deep Learning Experiments",
      "title_zh": "DeepLL：考虑线性逻辑用于深度学习实验的分析",
      "authors": [
        "Nick Papoulias"
      ],
      "abstract": "Deep Learning experiments have critical requirements regarding the careful\nhandling of their datasets as well as the efficient and correct usage of APIs\nthat interact with hardware accelerators. On the one hand, software mistakes\nduring data handling can contaminate experiments and lead to incorrect results.\nOn the other hand, poorly coded APIs that interact with the hardware can lead\nto sub-optimal usage and untrustworthy conclusions. In this work we investigate\nthe use of Linear Logic for the analysis of Deep Learning experiments. We show\nthat primitives and operators of Linear Logic can be used to express: (i) an\nabstract representation of the control flow of an experiment, (ii) a set of\navailable experimental resources, such as API calls to the underlying\ndata-structures and hardware as well as (iii) reasoning rules about the correct\nconsumption of resources during experiments. Our proposed model is not only\nlightweight but also easy to comprehend having both a symbolic and a visual\ncomponent. Finally, its artifacts are themselves proofs in Linear Logic that\ncan be readily verified by off-the-shelf reasoners.",
      "tldr_zh": "该论文探讨了深度学习实验中数据处理错误和硬件 API 使用不当的问题，这些可能导致实验污染或不可靠结论。作者提出使用 Linear Logic 来分析实验，通过其原语和运算符表示实验控制流的抽象、可用资源（如数据结构和硬件 API 调用）以及资源正确消耗的推理规则。该模型轻量级、易懂，并结合符号和视觉组件，其产物为可由现成推理器验证的 Linear Logic 证明，从而提升实验分析的可靠性和效率。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.PL",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.00169v1",
      "published_date": "2024-12-30 22:38:56 UTC",
      "updated_date": "2024-12-30 22:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:42:29.962270"
    },
    {
      "arxiv_id": "2501.00162v1",
      "title": "Class-based Subset Selection for Transfer Learning under Extreme Label Shift",
      "title_zh": "翻译失败",
      "authors": [
        "Akul Goyal",
        "Carl Edwards"
      ],
      "abstract": "Existing work within transfer learning often follows a two-step process --\npre-training over a large-scale source domain and then finetuning over limited\nsamples from the target domain. Yet, despite its popularity, this methodology\nhas been shown to suffer in the presence of distributional shift --\nspecifically when the output spaces diverge. Previous work has focused on\nincreasing model performance within this setting by identifying and classifying\nonly the shared output classes between distributions. However, these methods\nare inherently limited as they ignore classes outside the shared class set,\ndisregarding potential information relevant to the model transfer. This paper\nproposes a new process for few-shot transfer learning that selects and weighs\nclasses from the source domain to optimize the transfer between domains. More\nconcretely, we use Wasserstein distance to choose a set of source classes and\ntheir weights that minimize the distance between the source and target domain.\nTo justify our proposed algorithm, we provide a generalization analysis of the\nperformance of the learned classifier over the target domain and show that our\nmethod corresponds to a bound minimization algorithm. We empirically\ndemonstrate the effectiveness of our approach (WaSS) by experimenting on\nseveral different datasets and presenting superior performance within various\nlabel shift settings, including the extreme case where the label spaces are\ndisjoint.",
      "tldr_zh": "这篇论文针对迁移学习在极端标签偏移（label shift）下的性能问题，提出了一种基于类的子集选择方法，以优化源域和目标域之间的转移。具体来说，该方法使用Wasserstein distance来选择和加权源域的类子集，从而最小化域间距离，并通过泛化分析证明了其对应于边界最小化算法。实验结果显示，该方法（WaSS）在多个数据集上表现出色，尤其在标签空间完全不相交的极端场景中，显著提升了少样本迁移学习的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.00162v1",
      "published_date": "2024-12-30 22:14:24 UTC",
      "updated_date": "2024-12-30 22:14:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:42:41.966819"
    },
    {
      "arxiv_id": "2501.00154v1",
      "title": "Probabilistic Explanations for Linear Models",
      "title_zh": "线性模型的概率解释",
      "authors": [
        "Bernardo Subercaseaux",
        "Marcelo Arenas",
        "Kuldeep S Meel"
      ],
      "abstract": "Formal XAI is an emerging field that focuses on providing explanations with\nmathematical guarantees for the decisions made by machine learning models. A\nsignificant amount of work in this area is centered on the computation of\n\"sufficient reasons\". Given a model $M$ and an input instance $\\vec{x}$, a\nsufficient reason for the decision $M(\\vec{x})$ is a subset $S$ of the features\nof $\\vec{x}$ such that for any instance $\\vec{z}$ that has the same values as\n$\\vec{x}$ for every feature in $S$, it holds that $M(\\vec{x}) = M(\\vec{z})$.\nIntuitively, this means that the features in $S$ are sufficient to fully\njustify the classification of $\\vec{x}$ by $M$. For sufficient reasons to be\nuseful in practice, they should be as small as possible, and a natural way to\nreduce the size of sufficient reasons is to consider a probabilistic\nrelaxation; the probability of $M(\\vec{x}) = M(\\vec{z})$ must be at least some\nvalue $\\delta \\in (0,1]$, for a random instance $\\vec{z}$ that coincides with\n$\\vec{x}$ on the features in $S$. Computing small $\\delta$-sufficient reasons\n($\\delta$-SRs) is known to be a theoretically hard problem; even over decision\ntrees--traditionally deemed simple and interpretable models--strong\ninapproximability results make the efficient computation of small $\\delta$-SRs\nunlikely. We propose the notion of $(\\delta, \\epsilon)$-SR, a simple relaxation\nof $\\delta$-SRs, and show that this kind of explanation can be computed\nefficiently over linear models.",
      "tldr_zh": "该论文探讨了Formal XAI领域中，为机器学习模型决策提供数学保证解释的方法，焦点在于计算“sufficient reasons”，即输入实例的关键特征子集，用于证明模型决策。传统sufficient reasons可能过大，因此作者引入了概率松弛概念，如δ-SRs，要求随机实例在指定特征上与原实例一致时，模型决策一致的概率至少为δ，但计算δ-SRs在决策树等模型上理论上困难。论文提出了一种简单松弛形式（δ, ε)-SR，并证明这种解释可以在linear models上高效计算，从而提升了解释的可行性和实用性。",
      "categories": [
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of AAAI paper",
      "pdf_url": "http://arxiv.org/pdf/2501.00154v1",
      "published_date": "2024-12-30 21:59:16 UTC",
      "updated_date": "2024-12-30 21:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:42:53.999196"
    },
    {
      "arxiv_id": "2501.00152v2",
      "title": "Temporal reasoning for timeline summarisation in social media",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Song",
        "Mahmud Akhter",
        "Dana Atzil Slonim",
        "Maria Liakata"
      ],
      "abstract": "This paper explores whether enhancing temporal reasoning capabilities in\nLarge Language Models (LLMs) can improve the quality of timeline summarisation,\nthe task of summarising long texts containing sequences of events, such as\nsocial media threads. We first introduce NarrativeReason, a novel dataset\nfocused on temporal relationships among sequential events within narratives,\ndistinguishing it from existing temporal reasoning datasets that primarily\naddress pair-wise event relationships. Our approach then combines temporal\nreasoning with timeline summarisation through a knowledge distillation\nframework, where we first fine-tune a teacher model on temporal reasoning tasks\nand then distill this knowledge into a student model while simultaneously\ntraining it for the task of timeline summarisation. Experimental results\ndemonstrate that our model achieves superior performance on out-of-domain\nmental health-related timeline summarisation tasks, which involve long social\nmedia threads with repetitions of events and a mix of emotions, highlighting\nthe importance and generalisability of leveraging temporal reasoning to improve\ntimeline summarisation.",
      "tldr_zh": "本论文探讨了增强 Large Language Models (LLMs) 的时间推理能力是否能提升时间线总结（timeline summarisation）的质量，该任务涉及总结社交媒体等长文本中的事件序列。研究引入了 NarrativeReason 数据集，该数据集专注于叙事中顺序事件之间的时间关系，与现有数据集不同，后者主要处理事件对关系。作者采用知识蒸馏（knowledge distillation）框架，先在时间推理任务上微调教师模型，然后将知识转移到学生模型，同时训练其进行时间线总结。实验结果显示，该模型在外部领域（如心理健康相关任务）上表现出色，处理长社交媒体线程中的事件重复和情绪混合时性能优于基线模型，突出了时间推理对时间线总结的泛化重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00152v2",
      "published_date": "2024-12-30 21:54:33 UTC",
      "updated_date": "2025-02-18 14:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:43:06.713236"
    },
    {
      "arxiv_id": "2501.00138v1",
      "title": "NiaAutoARM: Automated generation and evaluation of Association Rule Mining pipelines",
      "title_zh": "翻译失败",
      "authors": [
        "Uroš Mlakar",
        "Iztok Fister Jr.",
        "Iztok Fister"
      ],
      "abstract": "The Numerical Association Rule Mining paradigm that includes concurrent\ndealing with numerical and categorical attributes is beneficial for discovering\nassociations from datasets consisting of both features. The process is not\nconsidered as easy since it incorporates several processing steps running\nsequentially that form an entire pipeline, e.g., preprocessing, algorithm\nselection, hyper-parameter optimization, and the definition of metrics\nevaluating the quality of the association rule. In this paper, we proposed a\nnovel Automated Machine Learning method, NiaAutoARM, for constructing the full\nassociation rule mining pipelines based on stochastic population-based\nmeta-heuristics automatically. Along with the theoretical representation of the\nproposed method, we also present a comprehensive experimental evaluation of the\nproposed method.",
      "tldr_zh": "这篇论文提出了一种新的 Automated Machine Learning 方法，名为 NiaAutoARM，用于自动生成和评估 Association Rule Mining 管道，以处理数据集中的数值和分类属性。NiaAutoARM 基于随机种群-based meta-heuristics，自动管理预处理、算法选择、超参数优化以及质量评估指标等顺序步骤。该方法不仅提供了理论表示，还进行了全面的实验评估，旨在简化 Association Rule Mining 的复杂过程并提升其效率。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00138v1",
      "published_date": "2024-12-30 20:48:51 UTC",
      "updated_date": "2024-12-30 20:48:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:43:18.559901"
    },
    {
      "arxiv_id": "2501.00136v1",
      "title": "Detection-Fusion for Knowledge Graph Extraction from Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Taniya Das",
        "Louis Mahon",
        "Thomas Lukasiewicz"
      ],
      "abstract": "One of the challenging tasks in the field of video understanding is\nextracting semantic content from video inputs. Most existing systems use\nlanguage models to describe videos in natural language sentences, but this has\nseveral major shortcomings. Such systems can rely too heavily on the language\nmodel component and base their output on statistical regularities in natural\nlanguage text rather than on the visual contents of the video. Additionally,\nnatural language annotations cannot be readily processed by a computer, are\ndifficult to evaluate with performance metrics and cannot be easily translated\ninto a different natural language. In this paper, we propose a method to\nannotate videos with knowledge graphs, and so avoid these problems.\nSpecifically, we propose a deep-learning-based model for this task that first\npredicts pairs of individuals and then the relations between them.\nAdditionally, we propose an extension of our model for the inclusion of\nbackground knowledge in the construction of knowledge graphs.",
      "tldr_zh": "这篇论文针对视频理解中的语义提取挑战，提出了一种使用 knowledge graphs 注解视频的方法，以避免现有系统过度依赖语言模型、基于文本统计而非视觉内容的问题，并解决自然语言注释的处理和评估难题。方法基于一个深度学习模型，首先预测视频中的个体对，然后确定它们之间的关系。该模型还扩展了背景知识的整合，提高了 knowledge graphs 的构建准确性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, To be submitted to a conference",
      "pdf_url": "http://arxiv.org/pdf/2501.00136v1",
      "published_date": "2024-12-30 20:26:11 UTC",
      "updated_date": "2024-12-30 20:26:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:43:30.599700"
    },
    {
      "arxiv_id": "2501.01451v1",
      "title": "Human-AI Teaming Using Large Language Models: Boosting Brain-Computer Interfacing (BCI) and Brain Research",
      "title_zh": "翻译失败",
      "authors": [
        "Maryna Kapitonova",
        "Tonio Ball"
      ],
      "abstract": "Recently, there is an increasing interest in using artificial intelligence\n(AI) to automate aspects of the research process, or even autonomously conduct\nthe full research cycle from idea generation, over data analysis, to composing\nand evaluation of scientific manuscripts. Examples of working AI scientist\nsystems have been demonstrated for computer science tasks and running molecular\nbiology labs. While some approaches aim for full autonomy of the scientific AI,\nothers rather aim for leveraging human-AI teaming. Here, we address how to\nadapt such approaches for boosting Brain-Computer Interface (BCI) development,\nas well as brain research resp. neuroscience at large. We argue that at this\ntime, a strong emphasis on human-AI teaming, in contrast to fully autonomous AI\nBCI researcher will be the most promising way forward. We introduce the\ncollaborative workspaces concept for human-AI teaming based on a set of\nJanusian design principles, looking both ways, to the human as well as to the\nAI side. Based on these principles, we present ChatBCI, a Python-based toolbox\nfor enabling human-AI collaboration based on interaction with Large Language\nModels (LLMs), designed for BCI research and development projects. We show how\nChatBCI was successfully used in a concrete BCI project on advancing motor\nimagery decoding from EEG signals. Our approach can be straightforwardly\nextended to broad neurotechnological and neuroscientific topics, and may by\ndesign facilitate human expert knowledge transfer to scientific AI systems in\ngeneral.",
      "tldr_zh": "这篇论文探讨了利用Large Language Models (LLMs)进行人类-AI团队合作，以提升Brain-Computer Interfacing (BCI)开发和脑研究，强调团队合作优于完全自治AI。作者引入了基于Janusian设计原则的collaborative workspaces概念，旨在平衡人类和AI的互动，并开发了ChatBCI，一个Python-based toolbox，用于支持BCI项目中的人类-AI协作。实验显示，ChatBCI在EEG信号运动想象解码项目中取得了成功，并可扩展到更广泛的神经技术和神经科学领域，促进专家知识向AI系统的转移。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.01451v1",
      "published_date": "2024-12-30 20:26:03 UTC",
      "updated_date": "2024-12-30 20:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:43:43.143101"
    },
    {
      "arxiv_id": "2501.00135v4",
      "title": "GroverGPT: A Large Language Model with 8 Billion Parameters for Quantum Searching",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Wang",
        "Pingzhi Li",
        "Min Chen",
        "Jinglei Cheng",
        "Junyu Liu",
        "Tianlong Chen"
      ],
      "abstract": "Quantum computing is an exciting non-Von Neumann paradigm, offering provable\nspeedups over classical computing for specific problems. However, the practical\nlimits of classical simulatability for quantum circuits remain unclear,\nespecially with current noisy quantum devices. In this work, we explore the\npotential of leveraging Large Language Models (LLMs) to simulate the output of\na quantum Turing machine using Grover's quantum circuits, known to provide\nquadratic speedups over classical counterparts. To this end, we developed\nGroverGPT, a specialized model based on LLaMA's 8-billion-parameter\narchitecture, trained on over 15 trillion tokens. Unlike brute-force\nstate-vector simulations, which demand substantial computational resources,\nGroverGPT employs pattern recognition to approximate quantum search algorithms\nwithout explicitly representing quantum states. Analyzing 97K quantum search\ninstances, GroverGPT consistently outperformed OpenAI's GPT-4o (45\\% accuracy),\nachieving nearly 100\\% accuracy on 6- and 10-qubit datasets when trained on\n4-qubit or larger datasets. It also demonstrated strong generalization,\nsurpassing 95\\% accuracy for systems with over 20 qubits when trained on 3- to\n6-qubit data. Analysis indicates GroverGPT captures quantum features of\nGrover's search rather than classical patterns, supported by novel prompting\nstrategies to enhance performance. Although accuracy declines with increasing\nsystem size, these findings offer insights into the practical boundaries of\nclassical simulatability. This work suggests task-specific LLMs can surpass\ngeneral-purpose models like GPT-4o in quantum algorithm learning and serve as\npowerful tools for advancing quantum research.",
      "tldr_zh": "本文提出GroverGPT，一种基于LLaMA的8亿参数Large Language Model (LLMs)，旨在模拟Grover's quantum circuits以实现量子搜索算法的二次加速，而非依赖资源密集的传统状态向量模拟。模型通过模式识别技术训练于超过15万亿tokens的数据，在分析97K量子搜索实例时，准确率远超OpenAI的GPT-4o（45%），并在6-和10-qubit数据集上达到近100%。此外，GroverGPT展示了强大泛化能力，对训练于3-6 qubit数据的模型，在超过20 qubits系统上仍可实现95%以上准确率。研究证实GroverGPT捕捉了Grover's search的量子特征而非古典模式，为探索量子算法的古典模拟边界提供了重要洞见。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "12 pages including appendices. v2, v3, v4: Add more experiments\n  include ablation tests. Fix the terminology about infidelity. Add more\n  benchmarks including Llama-3.2-3B and DeepSeek-v2-Lite",
      "pdf_url": "http://arxiv.org/pdf/2501.00135v4",
      "published_date": "2024-12-30 20:23:10 UTC",
      "updated_date": "2025-02-14 04:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:43:55.977090"
    },
    {
      "arxiv_id": "2501.00129v1",
      "title": "A Data-Centric Approach to Detecting and Mitigating Demographic Bias in Pediatric Mental Health Text: A Case Study in Anxiety Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Julia Ive",
        "Paulina Bondaronek",
        "Vishal Yadav",
        "Daniel Santel",
        "Tracy Glauser",
        "Tina Cheng",
        "Jeffrey R. Strawn",
        "Greeshma Agasthya",
        "Jordan Tschida",
        "Sanghyun Choo",
        "Mayanka Chandrashekar",
        "Anuj J. Kapadia",
        "John Pestian"
      ],
      "abstract": "Introduction: Healthcare AI models often inherit biases from their training\ndata. While efforts have primarily targeted bias in structured data, mental\nhealth heavily depends on unstructured data. This study aims to detect and\nmitigate linguistic differences related to non-biological differences in the\ntraining data of AI models designed to assist in pediatric mental health\nscreening. Our objectives are: (1) to assess the presence of bias by evaluating\noutcome parity across sex subgroups, (2) to identify bias sources through\ntextual distribution analysis, and (3) to develop a de-biasing method for\nmental health text data. Methods: We examined classification parity across\ndemographic groups and assessed how gendered language influences model\npredictions. A data-centric de-biasing method was applied, focusing on\nneutralizing biased terms while retaining salient clinical information. This\nmethodology was tested on a model for automatic anxiety detection in pediatric\npatients. Results: Our findings revealed a systematic under-diagnosis of female\nadolescent patients, with a 4% lower accuracy and a 9% higher False Negative\nRate (FNR) compared to male patients, likely due to disparities in information\ndensity and linguistic differences in patient notes. Notes for male patients\nwere on average 500 words longer, and linguistic similarity metrics indicated\ndistinct word distributions between genders. Implementing our de-biasing\napproach reduced diagnostic bias by up to 27%, demonstrating its effectiveness\nin enhancing equity across demographic groups. Discussion: We developed a\ndata-centric de-biasing framework to address gender-based content disparities\nwithin clinical text. By neutralizing biased language and enhancing focus on\nclinically essential information, our approach demonstrates an effective\nstrategy for mitigating bias in AI healthcare models trained on text.",
      "tldr_zh": "本研究采用数据中心方法，针对儿童心理健康文本中的人口统计偏见（如性别差异），以焦虑检测为案例，评估并缓解模型在性别子群体间的分类不平价。研究发现，女性青少年患者面临系统性低诊断问题，准确率低4%且假阴性率高9%，这与患者笔记长度差异（男性笔记平均长500词）和语言分布不均有关。通过文本分析和去偏技术，中和偏置术语同时保留临床信息，成功将诊断偏见降低27%。这项工作为AI医疗模型提供了一个有效框架，提升了在非结构化数据上的公平性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00129v1",
      "published_date": "2024-12-30 20:00:22 UTC",
      "updated_date": "2024-12-30 20:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:44:06.926283"
    },
    {
      "arxiv_id": "2501.00116v1",
      "title": "Text-to-Image GAN with Pretrained Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaozhou You",
        "Jian Zhang"
      ],
      "abstract": "Generating desired images conditioned on given text descriptions has received\nlots of attention. Recently, diffusion models and autoregressive models have\ndemonstrated their outstanding expressivity and gradually replaced GAN as the\nfavored architectures for text-to-image synthesis. However, they still face\nsome obstacles: slow inference speed and expensive training costs. To achieve\nmore powerful and faster text-to-image synthesis under complex scenes, we\npropose TIGER, a text-to-image GAN with pretrained representations. To be\nspecific, we propose a vision-empowered discriminator and a high-capacity\ngenerator. (i) The vision-empowered discriminator absorbs the complex scene\nunderstanding ability and the domain generalization ability from pretrained\nvision models to enhance model performance. Unlike previous works, we explore\nstacking multiple pretrained models in our discriminator to collect multiple\ndifferent representations. (ii) The high-capacity generator aims to achieve\neffective text-image fusion while increasing the model capacity. The\nhigh-capacity generator consists of multiple novel high-capacity fusion blocks\n(HFBlock). And the HFBlock contains several deep fusion modules and a global\nfusion module, which play different roles to benefit our model. Extensive\nexperiments demonstrate the outstanding performance of our proposed TIGER both\non standard and zero-shot text-to-image synthesis tasks. On the standard\ntext-to-image synthesis task, TIGER achieves state-of-the-art performance on\ntwo challenging datasets, which obtain a new FID 5.48 (COCO) and 9.38 (CUB). On\nthe zero-shot text-to-image synthesis task, we achieve comparable performance\nwith fewer model parameters, smaller training data size and faster inference\nspeed. Additionally, more experiments and analyses are conducted in the\nSupplementary Material.",
      "tldr_zh": "本论文提出了一种名为TIGER的文本到图像GAN模型，利用预训练表示来实现更强大且更快的文本到图像合成，解决扩散模型和自回归模型的慢速推理和高训练成本问题。TIGER的核心创新包括vision-empowered discriminator，该鉴别器通过堆叠多个预训练视觉模型来提升复杂场景理解和领域泛化能力；以及high-capacity generator，由多个high-capacity fusion blocks (HFBlock)组成，包括深融合模块和全局融合模块，以实现有效的文本-图像融合。实验结果显示，TIGER在标准文本到图像合成任务上达到最先进性能，在COCO和CUB数据集上分别获得FID 5.48和9.38；在零样本任务上，它以更少的模型参数、更小的训练数据和更快的推理速度实现可比性能。总的来说，该方法为高效文本到图像生成提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00116v1",
      "published_date": "2024-12-30 19:30:40 UTC",
      "updated_date": "2024-12-30 19:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:44:19.595513"
    },
    {
      "arxiv_id": "2501.00113v1",
      "title": "AltGen: AI-Driven Alt Text Generation for Enhancing EPUB Accessibility",
      "title_zh": "AltGen：AI驱动的替代文本生成用于增强EPUB可访问性",
      "authors": [
        "Yixian Shen",
        "Hang Zhang",
        "Yanxin Shen",
        "Lun Wang",
        "Chuanqi Shi",
        "Shaoshuai Du",
        "Yiyi Tao"
      ],
      "abstract": "Digital accessibility is a cornerstone of inclusive content delivery, yet\nmany EPUB files fail to meet fundamental accessibility standards, particularly\nin providing descriptive alt text for images. Alt text plays a critical role in\nenabling visually impaired users to understand visual content through assistive\ntechnologies. However, generating high-quality alt text at scale is a\nresource-intensive process, creating significant challenges for organizations\naiming to ensure accessibility compliance. This paper introduces AltGen, a\nnovel AI-driven pipeline designed to automate the generation of alt text for\nimages in EPUB files. By integrating state-of-the-art generative models,\nincluding advanced transformer-based architectures, AltGen achieves\ncontextually relevant and linguistically coherent alt text descriptions. The\npipeline encompasses multiple stages, starting with data preprocessing to\nextract and prepare relevant content, followed by visual analysis using\ncomputer vision models such as CLIP and ViT. The extracted visual features are\nenriched with contextual information from surrounding text, enabling the\nfine-tuned language models to generate descriptive and accurate alt text.\nValidation of the generated output employs both quantitative metrics, such as\ncosine similarity and BLEU scores, and qualitative feedback from visually\nimpaired users.\n  Experimental results demonstrate the efficacy of AltGen across diverse\ndatasets, achieving a 97.5% reduction in accessibility errors and high scores\nin similarity and linguistic fidelity metrics. User studies highlight the\npractical impact of AltGen, with participants reporting significant\nimprovements in document usability and comprehension. Furthermore, comparative\nanalyses reveal that AltGen outperforms existing approaches in terms of\naccuracy, relevance, and scalability.",
      "tldr_zh": "本论文提出 AltGen，一种 AI 驱动的管道，用于自动生成 EPUB 文件中图像的 alt text，以提升数字无障碍性。AltGen 整合先进的生成模型（如 transformer-based architectures）和计算机视觉技术（包括 CLIP 和 ViT），通过数据预处理、视觉特征提取以及结合周边文本的上下文信息，生成高质量、上下文相关的 alt text 描述。实验结果显示，AltGen 在多种数据集上减少了 97.5% 的无障碍错误，并在 cosine similarity 和 BLEU scores 等指标上表现出色，用户研究进一步证实了其在文档可用性和理解方面的显著改善，且在准确性、相关性和可扩展性上优于现有方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00113v1",
      "published_date": "2024-12-30 19:23:07 UTC",
      "updated_date": "2024-12-30 19:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:44:30.804106"
    },
    {
      "arxiv_id": "2501.00107v1",
      "title": "An Unsupervised Anomaly Detection in Electricity Consumption Using Reinforcement Learning and Time Series Forest Based Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Jihan Ghanim",
        "Mariette Awad"
      ],
      "abstract": "Anomaly detection (AD) plays a crucial role in time series applications,\nprimarily because time series data is employed across real-world scenarios.\nDetecting anomalies poses significant challenges since anomalies take diverse\nforms making them hard to pinpoint accurately. Previous research has explored\ndifferent AD models, making specific assumptions with varying sensitivity\ntoward particular anomaly types. To address this issue, we propose a novel\nmodel selection for unsupervised AD using a combination of time series forest\n(TSF) and reinforcement learning (RL) approaches that dynamically chooses an AD\ntechnique. Our approach allows for effective AD without explicitly depending on\nground truth labels that are often scarce and expensive to obtain. Results from\nthe real-time series dataset demonstrate that the proposed model selection\napproach outperforms all other AD models in terms of the F1 score metric. For\nthe synthetic dataset, our proposed model surpasses all other AD models except\nfor KNN, with an impressive F1 score of 0.989. The proposed model selection\nframework also exceeded the performance of GPT-4 when prompted to act as an\nanomaly detector on the synthetic dataset. Exploring different reward functions\nrevealed that the original reward function in our proposed AD model selection\napproach yielded the best overall scores. We evaluated the performance of the\nsix AD models on an additional three datasets, having global, local, and\nclustered anomalies respectively, showing that each AD model exhibited distinct\nperformance depending on the type of anomalies. This emphasizes the\nsignificance of our proposed AD model selection framework, maintaining high\nperformance across all datasets, and showcasing superior performance across\ndifferent anomaly types.",
      "tldr_zh": "这篇论文提出了一种无监督 Anomaly Detection (AD) 框架，结合 Time Series Forest (TSF) 和 Reinforcement Learning (RL)，用于电力消耗的时间序列数据分析。该框架通过动态选择 AD 模型来处理各种异常类型，而无需依赖昂贵的 ground truth labels。实验结果显示，该方法在真实数据集上以 F1 score 指标优于所有基线模型，在合成数据集上达到 0.989 的高分，甚至超过了 GPT-4，并在不同异常类型（如全局、局部和集群异常）的数据集上展现出卓越的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00107v1",
      "published_date": "2024-12-30 19:04:43 UTC",
      "updated_date": "2024-12-30 19:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:44:43.962975"
    },
    {
      "arxiv_id": "2501.00106v1",
      "title": "LicenseGPT: A Fine-tuned Foundation Model for Publicly Available Dataset License Compliance",
      "title_zh": "LicenseGPT：一个针对公开可用数据集许可合规的微调基础模型",
      "authors": [
        "Jingwen Tan",
        "Gopi Krishnan Rajbahadur",
        "Zi Li",
        "Xiangfu Song",
        "Jianshan Lin",
        "Dan Li",
        "Zibin Zheng",
        "Ahmed E. Hassan"
      ],
      "abstract": "Dataset license compliance is a critical yet complex aspect of developing\ncommercial AI products, particularly with the increasing use of publicly\navailable datasets. Ambiguities in dataset licenses pose significant legal\nrisks, making it challenging even for software IP lawyers to accurately\ninterpret rights and obligations. In this paper, we introduce LicenseGPT, a\nfine-tuned foundation model (FM) specifically designed for dataset license\ncompliance analysis. We first evaluate existing legal FMs (i.e., FMs\nspecialized in understanding and processing legal texts) and find that the\nbest-performing model achieves a Prediction Agreement (PA) of only 43.75%.\nLicenseGPT, fine-tuned on a curated dataset of 500 licenses annotated by legal\nexperts, significantly improves PA to 64.30%, outperforming both legal and\ngeneral-purpose FMs. Through an A/B test and user study with software IP\nlawyers, we demonstrate that LicenseGPT reduces analysis time by 94.44%, from\n108 seconds to 6 seconds per license, without compromising accuracy. Software\nIP lawyers perceive LicenseGPT as a valuable supplementary tool that enhances\nefficiency while acknowledging the need for human oversight in complex cases.\nOur work underscores the potential of specialized AI tools in legal practice\nand offers a publicly available resource for practitioners and researchers.",
      "tldr_zh": "该研究针对公开数据集许可合规性的模糊性及其法律风险，引入了LicenseGPT，一种针对此任务微调的基础模型(FM)。通过使用由法律专家标注的500个许可数据集进行微调，LicenseGPT将Prediction Agreement (PA)从现有模型的43.75%提升至64.30%，优于其他法律和通用FM。实验结果显示，通过A/B测试和用户研究，LicenseGPT将许可分析时间减少94.44%（从108秒降至6秒），并被软件IP律师视为高效辅助工具，同时强调了人类监督的必要性，为法律实践中的AI应用提供了公开资源。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00106v1",
      "published_date": "2024-12-30 19:04:13 UTC",
      "updated_date": "2024-12-30 19:04:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:44:55.253222"
    },
    {
      "arxiv_id": "2501.00097v1",
      "title": "CaseSumm: A Large-Scale Dataset for Long-Context Summarization from U.S. Supreme Court Opinions",
      "title_zh": "翻译失败",
      "authors": [
        "Mourad Heddaya",
        "Kyle MacMillan",
        "Anup Malani",
        "Hongyuan Mei",
        "Chenhao Tan"
      ],
      "abstract": "This paper introduces CaseSumm, a novel dataset for long-context\nsummarization in the legal domain that addresses the need for longer and more\ncomplex datasets for summarization evaluation. We collect 25.6K U.S. Supreme\nCourt (SCOTUS) opinions and their official summaries, known as \"syllabuses.\"\nOur dataset is the largest open legal case summarization dataset, and is the\nfirst to include summaries of SCOTUS decisions dating back to 1815.\n  We also present a comprehensive evaluation of LLM-generated summaries using\nboth automatic metrics and expert human evaluation, revealing discrepancies\nbetween these assessment methods. Our evaluation shows Mistral 7b, a smaller\nopen-source model, outperforms larger models on most automatic metrics and\nsuccessfully generates syllabus-like summaries. In contrast, human expert\nannotators indicate that Mistral summaries contain hallucinations. The\nannotators consistently rank GPT-4 summaries as clearer and exhibiting greater\nsensitivity and specificity. Further, we find that LLM-based evaluations are\nnot more correlated with human evaluations than traditional automatic metrics.\nFurthermore, our analysis identifies specific hallucinations in generated\nsummaries, including precedent citation errors and misrepresentations of case\nfacts. These findings demonstrate the limitations of current automatic\nevaluation methods for legal summarization and highlight the critical role of\nhuman evaluation in assessing summary quality, particularly in complex,\nhigh-stakes domains.\n  CaseSumm is available at https://huggingface.co/datasets/ChicagoHAI/CaseSumm",
      "tldr_zh": "本文介绍了CaseSumm数据集，这是一个大规模的法律领域长上下文总结数据集，包含25.6K个美国最高法院(SCOTUS)意见及其官方摘要(syllabuses)，是首个从1815年开始的开放式数据集，用于评估总结模型的性能。研究通过自动指标和人类专家评估比较了不同LLM模型的表现，发现Mistral 7b模型在大多数自动指标上优于更大模型，但其生成的摘要存在hallucinations问题，而GPT-4的摘要被评为更清晰和准确。结果强调了当前自动评估方法的局限性，并突出了在复杂高风险领域如法律中进行人类评估的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00097v1",
      "published_date": "2024-12-30 19:00:01 UTC",
      "updated_date": "2024-12-30 19:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:45:08.226561"
    },
    {
      "arxiv_id": "2412.21205v1",
      "title": "Action-Agnostic Point-Level Supervision for Temporal Action Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhei M. Yoshida",
        "Takashi Shibata",
        "Makoto Terao",
        "Takayuki Okatani",
        "Masashi Sugiyama"
      ],
      "abstract": "We propose action-agnostic point-level (AAPL) supervision for temporal action\ndetection to achieve accurate action instance detection with a lightly\nannotated dataset. In the proposed scheme, a small portion of video frames is\nsampled in an unsupervised manner and presented to human annotators, who then\nlabel the frames with action categories. Unlike point-level supervision, which\nrequires annotators to search for every action instance in an untrimmed video,\nframes to annotate are selected without human intervention in AAPL supervision.\nWe also propose a detection model and learning method to effectively utilize\nthe AAPL labels. Extensive experiments on the variety of datasets (THUMOS '14,\nFineAction, GTEA, BEOID, and ActivityNet 1.3) demonstrate that the proposed\napproach is competitive with or outperforms prior methods for video-level and\npoint-level supervision in terms of the trade-off between the annotation cost\nand detection performance.",
      "tldr_zh": "本研究提出了一种行动无关点级(AAPL)监督方法，用于temporal action detection，以在轻量标注数据集上实现准确的动作实例检测。该方法通过无监督方式采样视频帧，由人类标注动作类别，从而避免了传统点级监督中人工搜索每个动作实例的繁琐过程。同时，论文设计了相应的检测模型和学习方法来有效利用AAPL标签。在THUMOS '14、FineAction、GTEA、BEOID和ActivityNet 1.3等数据集上的实验显示，该方法在标注成本与检测性能的权衡上，竞争或优于现有的视频级和点级监督方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI-25. Technical appendices included. 15 pages, 3 figures, 11\n  tables",
      "pdf_url": "http://arxiv.org/pdf/2412.21205v1",
      "published_date": "2024-12-30 18:59:55 UTC",
      "updated_date": "2024-12-30 18:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:45:19.599597"
    },
    {
      "arxiv_id": "2412.21164v1",
      "title": "Adversarial Attack and Defense for LoRa Device Identification and Authentication via Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yalin E. Sagduyu",
        "Tugba Erpek"
      ],
      "abstract": "LoRa provides long-range, energy-efficient communications in Internet of\nThings (IoT) applications that rely on Low-Power Wide-Area Network (LPWAN)\ncapabilities. Despite these merits, concerns persist regarding the security of\nLoRa networks, especially in situations where device identification and\nauthentication are imperative to secure the reliable access to the LoRa\nnetworks. This paper explores a deep learning (DL) approach to tackle these\nconcerns, focusing on two critical tasks, namely (i) identifying LoRa devices\nand (ii) classifying them to legitimate and rogue devices. Deep neural networks\n(DNNs), encompassing both convolutional and feedforward neural networks, are\ntrained for these tasks using actual LoRa signal data. In this setting, the\nadversaries may spoof rogue LoRa signals through the kernel density estimation\n(KDE) method based on legitimate device signals that are received by the\nadversaries. Two cases are considered, (i) training two separate classifiers,\none for each of the two tasks, and (ii) training a multi-task classifier for\nboth tasks. The vulnerabilities of the resulting DNNs to manipulations in input\nsamples are studied in form of untargeted and targeted adversarial attacks\nusing the Fast Gradient Sign Method (FGSM). Individual and common perturbations\nare considered against single-task and multi-task classifiers for the LoRa\nsignal analysis. To provide resilience against such attacks, a defense approach\nis presented by increasing the robustness of classifiers with adversarial\ntraining. Results quantify how vulnerable LoRa signal classification tasks are\nto adversarial attacks and emphasize the need to fortify IoT applications\nagainst these subtle yet effective threats.",
      "tldr_zh": "本研究探讨了使用深度学习（DL）对 LoRa 设备进行识别和认证的安全问题，针对物联网（IoT）中的长距离、低功耗通信网络。研究训练了深度神经网络（DNNs），包括卷积神经网络和前馈神经网络，来处理设备识别和合法/恶意分类任务，并考虑了攻击者通过核密度估计（KDE）方法伪造信号的情况。论文评估了针对单任务和多任务分类器的无针对性和有针对性对抗攻击，如 Fast Gradient Sign Method (FGSM)，并通过对抗训练方法增强分类器的鲁棒性。结果显示，LoRa 信号分类任务高度易受攻击，强调了加强 IoT 应用安全防御的必要性。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.21164v1",
      "published_date": "2024-12-30 18:43:21 UTC",
      "updated_date": "2024-12-30 18:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:45:31.670033"
    },
    {
      "arxiv_id": "2412.21161v1",
      "title": "Open RAN-Enabled Deep Learning-Assisted Mobility Management for Connected Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Barbosa",
        "Kelvin Dias"
      ],
      "abstract": "Connected Vehicles (CVs) can leverage the unique features of 5G and future\n6G/NextG networks to enhance Intelligent Transportation System (ITS) services.\nHowever, even with advancements in cellular network generations, CV\napplications may experience communication interruptions in high-mobility\nscenarios due to frequent changes of serving base station, also known as\nhandovers (HOs). This paper proposes the adoption of Open Radio Access Network\n(Open RAN/O-RAN) and deep learning models for decision-making to prevent\nQuality of Service (QoS) degradation due to HOs and to ensure the timely\nconnectivity needed for CV services. The solution utilizes the O-RAN Software\nCommunity (OSC), an open-source O-RAN platform developed by the collaboration\nbetween the O-RAN Alliance and Linux Foundation, to develop xApps that are\nexecuted in the near-Real-Time RIC of OSC. To demonstrate the proposal's\neffectiveness, an integrated framework combining the OMNeT++ simulator and OSC\nwas created. Evaluations used real-world datasets in urban application\nscenarios, such as video streaming transmission and over-the-air (OTA) updates.\nResults indicate that the proposal achieved superior performance and reduced\nlatency compared to the standard 3GPP HO procedure.",
      "tldr_zh": "本论文探讨了连接车辆 (CVs) 在高移动场景中因频繁切换基站 (handovers, HOs) 而导致的服务质量 (QoS) 下降问题，并提出一种基于 Open RAN (O-RAN) 和深度学习模型的决策框架，以确保 CVs 的及时连接和 ITS 服务增强。方法包括利用 O-RAN Software Community (OSC) 平台开发 xApps，并在 near-Real-Time RIC 中执行这些应用，同时构建了一个集成 OMNeT++ 模拟器和 OSC 的框架进行评估。实验结果显示，在城市场景如视频流传输和 OTA 更新中使用真实数据集时，该方案相较于标准 3GPP HO 程序实现了更好的性能和更低的延迟。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted for publication in ICOIN 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.21161v1",
      "published_date": "2024-12-30 18:41:29 UTC",
      "updated_date": "2024-12-30 18:41:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:45:44.404315"
    },
    {
      "arxiv_id": "2412.21154v1",
      "title": "Aviary: training language agents on challenging scientific tasks",
      "title_zh": "Aviary：在挑战性科学任务上训练语言代理",
      "authors": [
        "Siddharth Narayanan",
        "James D. Braza",
        "Ryan-Rhys Griffiths",
        "Manu Ponnapati",
        "Albert Bou",
        "Jon Laurent",
        "Ori Kabeli",
        "Geemi Wellawatte",
        "Sam Cox",
        "Samuel G. Rodriques",
        "Andrew D. White"
      ],
      "abstract": "Solving complex real-world tasks requires cycles of actions and observations.\nThis is particularly true in science, where tasks require many cycles of\nanalysis, tool use, and experimentation. Language agents are promising for\nautomating intellectual tasks in science because they can interact with tools\nvia natural language or code. Yet their flexibility creates conceptual and\npractical challenges for software implementations, since agents may comprise\nnon-standard components such as internal reasoning, planning, tool usage, as\nwell as the inherent stochasticity of temperature-sampled language models.\nHere, we introduce Aviary, an extensible gymnasium for language agents. We\nformalize agents as policies solving language-grounded partially observable\nMarkov decision processes, which we term language decision processes. We then\nimplement five environments, including three challenging scientific\nenvironments: (1) manipulating DNA constructs for molecular cloning, (2)\nanswering research questions by accessing scientific literature, and (3)\nengineering protein stability. These environments were selected for their focus\non multi-step reasoning and their relevance to contemporary biology research.\nFinally, with online training and scaling inference-time compute, we show that\nlanguage agents backed by open-source, non-frontier LLMs can match and exceed\nboth frontier LLM agents and human experts on multiple tasks at up to 100x\nlower inference cost.",
      "tldr_zh": "本研究引入了Aviary，一个可扩展的gymnasium框架，用于训练语言代理（language agents）处理具有挑战性的科学任务。Aviary将代理形式化为策略，解决语言基础的部分可观察Markov决策过程（language decision processes），并实现了五个环境，包括三个科学场景：操作DNA构建用于分子克隆、通过访问科学文献回答研究问题，以及工程蛋白稳定性，这些环境强调多步推理并与当代生物学相关。通过在线训练和扩展推理时间计算，研究发现基于开源、非前沿LLMs的语言代理可以在多个任务上匹配或超过前沿LLM代理和人类专家，同时推理成本降低至100倍以下。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.21154v1",
      "published_date": "2024-12-30 18:33:28 UTC",
      "updated_date": "2024-12-30 18:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:45:55.342743"
    },
    {
      "arxiv_id": "2412.21151v1",
      "title": "PyG-SSL: A Graph Self-Supervised Learning Toolkit",
      "title_zh": "PyG-SSL：图自监督学习工具包",
      "authors": [
        "Lecheng Zheng",
        "Baoyu Jing",
        "Zihao Li",
        "Zhichen Zeng",
        "Tianxin Wei",
        "Mengting Ai",
        "Xinrui He",
        "Lihui Liu",
        "Dongqi Fu",
        "Jiaxuan You",
        "Hanghang Tong",
        "Jingrui He"
      ],
      "abstract": "Graph Self-Supervised Learning (SSL) has emerged as a pivotal area of\nresearch in recent years. By engaging in pretext tasks to learn the intricate\ntopological structures and properties of graphs using unlabeled data, these\ngraph SSL models achieve enhanced performance, improved generalization, and\nheightened robustness. Despite the remarkable achievements of these graph SSL\nmethods, their current implementation poses significant challenges for\nbeginners and practitioners due to the complex nature of graph structures,\ninconsistent evaluation metrics, and concerns regarding reproducibility hinder\nfurther progress in this field. Recognizing the growing interest within the\nresearch community, there is an urgent need for a comprehensive,\nbeginner-friendly, and accessible toolkit consisting of the most representative\ngraph SSL algorithms. To address these challenges, we present a Graph SSL\ntoolkit named PyG-SSL, which is built upon PyTorch and is compatible with\nvarious deep learning and scientific computing backends. Within the toolkit, we\noffer a unified framework encompassing dataset loading, hyper-parameter\nconfiguration, model training, and comprehensive performance evaluation for\ndiverse downstream tasks. Moreover, we provide beginner-friendly tutorials and\nthe best hyper-parameters of each graph SSL algorithm on different graph\ndatasets, facilitating the reproduction of results. The GitHub repository of\nthe library is https://github.com/iDEA-iSAIL-Lab-UIUC/pyg-ssl.",
      "tldr_zh": "该研究介绍了 PyG-SSL，一款基于 PyTorch 的图自监督学习(Graph Self-Supervised Learning, SSL)工具包，旨在解决现有图 SSL 方法在复杂结构、不一致评估指标和可复现性方面的挑战。PyG-SSL 提供了一个统一的框架，包括数据集加载、超参数配置、模型训练和下游任务性能评估，同时兼容多种深度学习和科学计算后端。工具包还附带初学者友好的教程和最佳超参数设置，帮助用户轻松复现结果，并通过其 GitHub 仓库（如 https://github.com/iDEA-iSAIL-Lab-UIUC/pyg-ssl）促进图 SSL 研究的普及和进步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.21151v1",
      "published_date": "2024-12-30 18:32:05 UTC",
      "updated_date": "2024-12-30 18:32:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:46:07.787472"
    },
    {
      "arxiv_id": "2501.00085v2",
      "title": "Machine Learning-Based Security Policy Analysis",
      "title_zh": "基于机器学习的安全策略分析",
      "authors": [
        "Krish Jain",
        "Joann Sum",
        "Pranav Kapoor",
        "Amir Eaman"
      ],
      "abstract": "Security-Enhanced Linux (SELinux) is a robust security mechanism that\nenforces mandatory access controls (MAC), but its policy language's complexity\ncreates challenges for policy analysis and management. This research\ninvestigates the automation of SELinux policy analysis using graph-based\ntechniques combined with machine learning approaches to detect policy\nanomalies. The study addresses two key questions: Can SELinux policy analysis\nbe automated through graph analysis, and how do different anomaly detection\nmodels compare in analyzing SELinux policies? We will be comparing different\nmachine learning models by evaluating their effectiveness in detecting policy\nviolations and anomalies. Our approach utilizes Neo4j for graph representation\nof policies, with Node2vec transforming these graph structures into meaningful\nvector embeddings that can be processed by our machine learning models. In our\nresults, the MLP Neural Network consistently demonstrated superior performance\nacross different dataset sizes, achieving 95% accuracy with balanced precision\nand recall metrics, while both Random Forest and SVM models showed competitive\nbut slightly lower performance in detecting policy violations. This combination\nof graph-based modeling and machine learning provides a more sophisticated and\nautomated approach to understanding and analyzing complex SELinux policies\ncompared to traditional manual analysis methods.",
      "tldr_zh": "本研究针对 SELinux 政策语言的复杂性，提出了一种结合图-based 技术和机器学习的方法来自动化政策分析和异常检测。方法包括使用 Neo4j 构建政策图表示，Node2vec 将图结构转化为向量嵌入，然后通过 MLP Neural Network、Random Forest 和 SVM 等模型进行比较分析。结果表明，MLP Neural Network 在不同数据集上表现出色，准确率达95%，并在精确度和召回率上表现出平衡优势，而其他模型的性能稍逊。该方法为 SELinux 政策的自动化管理和异常检测提供了更高效的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00085v2",
      "published_date": "2024-12-30 18:24:27 UTC",
      "updated_date": "2025-01-06 22:42:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:46:19.890005"
    },
    {
      "arxiv_id": "2412.21140v1",
      "title": "Facilitating large language model Russian adaptation with Learned Embedding Propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Tikhomirov",
        "Daniil Chernyshev"
      ],
      "abstract": "Rapid advancements of large language model (LLM) technologies led to the\nintroduction of powerful open-source instruction-tuned LLMs that have the same\ntext generation quality as the state-of-the-art counterparts such as GPT-4.\nWhile the emergence of such models accelerates the adoption of LLM technologies\nin sensitive-information environments the authors of such models don not\ndisclose the training data necessary for replication of the results thus making\nthe achievements model-exclusive. Since those open-source models are also\nmultilingual this in turn reduces the benefits of training a language specific\nLLMs as improved inference computation efficiency becomes the only guaranteed\nadvantage of such costly procedure. More cost-efficient options such as\nvocabulary extension and subsequent continued pre-training are also inhibited\nby the lack of access to high-quality instruction-tuning data since it is the\nmajor factor behind the resulting LLM task-solving capabilities. To address the\nlimitations and cut the costs of the language adaptation pipeline we propose\nLearned Embedding Propagation (LEP). Unlike existing approaches our method has\nlower training data size requirements due to minimal impact on existing LLM\nknowledge which we reinforce using novel ad-hoc embedding propagation procedure\nthat allows to skip the instruction-tuning step and instead implant the new\nlanguage knowledge directly into any existing instruct-tuned variant. We\nevaluated four Russian vocabulary adaptations for LLaMa-3-8B and Mistral-7B,\nshowing that LEP is competitive with traditional instruction-tuning methods,\nachieving performance comparable to OpenChat 3.5 and LLaMa-3-8B-Instruct, with\nfurther improvements via self-calibration and continued tuning enhancing\ntask-solving capabilities.",
      "tldr_zh": "该研究针对大型语言模型 (LLM) 适应新语言（如俄语）的挑战，提出了一种高效方法 Learned Embedding Propagation (LEP)，通过新型嵌入传播过程直接植入新语言知识到现有指令微调模型中，从而减少训练数据需求和整体成本。LEP 避免了传统的指令微调步骤，仅需最小化对模型原有知识的影响，便能实现词汇扩展和后续预训练。实验结果显示，在 LLaMa-3-8B 和 Mistral-7B 上进行四种俄语适应后，LEP 的性能与传统方法（如 OpenChat 3.5 和 LLaMa-3-8B-Instruct）相当，通过自校准和继续微调进一步提升了任务解决能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint version of an article published in the Journal of Language\n  and Education. Copyright held by the owner/author(s). Publication rights\n  licensed to the Journal of Language and Education",
      "pdf_url": "http://arxiv.org/pdf/2412.21140v1",
      "published_date": "2024-12-30 18:15:45 UTC",
      "updated_date": "2024-12-30 18:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:46:32.145468"
    },
    {
      "arxiv_id": "2501.01987v2",
      "title": "Gender Bias in Text-to-Video Generation Models: A case study of Sora",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Nadeem",
        "Shahab Saquib Sohail",
        "Erik Cambria",
        "Björn W. Schuller",
        "Amir Hussain"
      ],
      "abstract": "The advent of text-to-video generation models has revolutionized content\ncreation as it produces high-quality videos from textual prompts. However,\nconcerns regarding inherent biases in such models have prompted scrutiny,\nparticularly regarding gender representation. Our study investigates the\npresence of gender bias in OpenAI's Sora, a state-of-the-art text-to-video\ngeneration model. We uncover significant evidence of bias by analyzing the\ngenerated videos from a diverse set of gender-neutral and stereotypical\nprompts. The results indicate that Sora disproportionately associates specific\ngenders with stereotypical behaviors and professions, which reflects societal\nprejudices embedded in its training data.",
      "tldr_zh": "这篇论文研究了文本到视频生成模型中的性别偏见，以 OpenAI 的 Sora 模型为案例，分析了其从文本提示生成视频时潜在的性别代表问题。研究者通过测试一组多样化的性别中立和刻板印象提示，观察生成的视频内容，发现 Sora 会不均等地将特定性别与传统的行为和职业相关联。结果表明，这种偏见反映了模型训练数据中嵌入的社会偏见，强调了需要改进模型以减少此类问题。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.01987v2",
      "published_date": "2024-12-30 18:08:13 UTC",
      "updated_date": "2025-01-10 11:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:46:43.420719"
    },
    {
      "arxiv_id": "2501.01986v1",
      "title": "FrameFusion: Combining Similarity and Importance for Video Token Reduction on Large Visual Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Fu",
        "Tengxuan Liu",
        "Qinghao Han",
        "Guohao Dai",
        "Shengen Yan",
        "Huazhong Yang",
        "Xuefei Ning",
        "Yu Wang"
      ],
      "abstract": "The increasing demand to process long and high-resolution videos\nsignificantly burdens Large Vision-Language Models (LVLMs) due to the enormous\nnumber of visual tokens. Existing token reduction methods primarily focus on\nimportance-based token pruning, which overlooks the redundancy caused by frame\nresemblance and repetitive visual elements. In this paper, we analyze the high\nvision token similarities in LVLMs. We reveal that token similarity\ndistribution condenses as layers deepen while maintaining ranking consistency.\nLeveraging the unique properties of similarity over importance, we introduce\nFrameFusion, a novel approach that combines similarity-based merging with\nimportance-based pruning for better token reduction in LVLMs. FrameFusion\nidentifies and merges similar tokens before pruning, opening up a new\nperspective for token reduction. We evaluate FrameFusion on diverse LVLMs,\nincluding Llava-Video-{7B,32B,72B}, and MiniCPM-V-8B, on video understanding,\nquestion-answering, and retrieval benchmarks. Experiments show that FrameFusion\nreduces vision tokens by 70$\\%$, achieving 3.4-4.4x LLM speedups and 1.6-1.9x\nend-to-end speedups, with an average performance impact of less than 3$\\%$. Our\ncode is available at https://github.com/thu-nics/FrameFusion.",
      "tldr_zh": "该论文提出 FrameFusion，一种针对大型视觉语言模型(LVLMs)的视频标记减少方法，结合相似性-based 合并和重要性-based 修剪，以解决现有方法忽略帧相似性及冗余问题。作者分析了 LVLMs 中视觉标记的相似性分布，发现其在层深加深时趋于密集但排名一致，从而优化了标记处理流程。实验结果显示，FrameFusion 在 Llava-Video-{7B,32B,72B} 和 MiniCPM-V-8B 等模型上，减少了70%的视觉标记，实现3.4-4.4倍的LLM加速和1.6-1.9倍的端到端加速，同时性能下降不到3%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45, 68T50",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.01986v1",
      "published_date": "2024-12-30 17:31:37 UTC",
      "updated_date": "2024-12-30 17:31:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:46:56.159887"
    },
    {
      "arxiv_id": "2412.21104v2",
      "title": "On Parallel External-Memory Bidirectional Search",
      "title_zh": "翻译失败",
      "authors": [
        "Lior Siag",
        "Shahaf S. Shperberg",
        "Ariel Felner",
        "Nathan R. Sturtevant"
      ],
      "abstract": "Parallelization and External Memory (PEM) techniques have significantly\nenhanced the capabilities of search algorithms when solving large-scale\nproblems. Previous research on PEM has primarily centered on unidirectional\nalgorithms, with only one publication on bidirectional PEM that focuses on the\nmeet-in-the-middle (MM) algorithm. Building upon this foundation, this paper\npresents a framework that integrates both uni- and bi-directional best-first\nsearch algorithms into this framework. We then develop a PEM variant of the\nstate-of-the-art bidirectional heuristic search (BiHS) algorithm BAE*\n(PEM-BAE*). As previous work on BiHS did not focus on scaling problem sizes,\nthis work enables us to evaluate bidirectional algorithms on hard problems.\nEmpirical evaluation shows that PEM-BAE* outperforms the PEM variants of A* and\nthe MM algorithm, as well as a parallel variant of IDA*. These findings mark a\nsignificant milestone, revealing that bidirectional search algorithms clearly\noutperform unidirectional search algorithms across several domains, even when\nequipped with state-of-the-art heuristics.",
      "tldr_zh": "本文提出一个框架，将单向和双向最佳优先搜索算法整合到 Parallel External-Memory (PEM) 技术中，以处理大规模搜索问题。作者开发了 PEM 变体 PEM-BAE*，基于状态-of-the-art 双向启发式搜索算法 BAE*，并通过实验评估其在复杂问题上的性能。结果显示，PEM-BAE* 优于 PEM 变体 of A*、MM algorithm 以及并行 IDA*，证明双向搜索算法在多个领域明显超越单向算法，即使后者使用最先进的启发式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, includes conference paper and appendix",
      "pdf_url": "http://arxiv.org/pdf/2412.21104v2",
      "published_date": "2024-12-30 17:29:51 UTC",
      "updated_date": "2024-12-31 08:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:47:07.748125"
    },
    {
      "arxiv_id": "2412.21102v2",
      "title": "Exploring and Controlling Diversity in LLM-Agent Conversation",
      "title_zh": "探索与控制LLM-Agent对话中的多样性",
      "authors": [
        "KuanChao Chu",
        "Yi-Pei Chen",
        "Hideki Nakayama"
      ],
      "abstract": "Controlling diversity in LLM-agent world simulations is essential for\nmaintaining stability in structured tasks while enabling variation where\ncreativity is needed. However, we observe that dialogue diversity declines\nsignificantly over long-term simulation. To investigate the role of prompt\ndesign in conversational diversity, we modularized the utterance generation\nprompt and found that reducing the given information leads to more diverse\noutputs. Based on this insight, we propose Adaptive Prompt Pruning (APP), a\nnovel method that allows users to control diversity through a single parameter,\nlambda. APP dynamically prunes the utterance generation prompt based on their\nattention weights and is compatible with traditional diversity control\ntechniques. We demonstrate that APP effectively controls output diversity\nthrough extensive experiments, and propose a method to balance the control\ntrade-offs. Additionally, we provide an in-depth analysis to offer insights\ninto optimizing diversity control in multi-agent simulation.",
      "tldr_zh": "本研究探讨了在LLM-agent对话中控制多样性的重要性，以确保结构化任务的稳定性，同时在需要创意的地方允许变化。研究者观察到长期模拟中对话多样性显著下降，并通过模块化提示设计发现，减少给定信息可提升输出多样性。为此，他们提出Adaptive Prompt Pruning (APP)方法，使用单一参数lambda动态修剪提示中的注意力权重，使其与传统多样性控制技术兼容。实验结果显示，APP能有效调控输出多样性，并提供平衡控制权衡的策略以及对多智能体模拟中多样性优化的深入分析。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for the AAAI 2025 Workshop on Advancing LLM-Based\n  Multi-Agent Collaboration (v1); updated version (v2)",
      "pdf_url": "http://arxiv.org/pdf/2412.21102v2",
      "published_date": "2024-12-30 17:25:58 UTC",
      "updated_date": "2025-02-21 15:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:49:11.912085"
    },
    {
      "arxiv_id": "2501.00083v1",
      "title": "AI Agent for Education: von Neumann Multi-Agent System Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan-Hao Jiang",
        "Ruijia Li",
        "Yizhou Zhou",
        "Changyong Qi",
        "Hanglei Hu",
        "Yuang Wei",
        "Bo Jiang",
        "Yonghe Wu"
      ],
      "abstract": "The development of large language models has ushered in new paradigms for\neducation. This paper centers on the multi-Agent system in education and\nproposes the von Neumann multi-Agent system framework. It breaks down each AI\nAgent into four modules: control unit, logic unit, storage unit, and\ninput-output devices, defining four types of operations: task deconstruction,\nself-reflection, memory processing, and tool invocation. Furthermore, it\nintroduces related technologies such as Chain-of-Thought, Reson+Act, and\nMulti-Agent Debate associated with these four types of operations. The paper\nalso discusses the ability enhancement cycle of a multi-Agent system for\neducation, including the outer circulation for human learners to promote\nknowledge construction and the inner circulation for LLM-based-Agents to\nenhance swarm intelligence. Through collaboration and reflection, the\nmulti-Agent system can better facilitate human learners' learning and enhance\ntheir teaching abilities in this process.",
      "tldr_zh": "这篇论文提出了一种基于 von Neumann 架构的多智能体系统框架，用于教育领域的 AI Agent 应用。该框架将每个 AI Agent 分解为四个模块：control unit、logic unit、storage unit 和 input-output devices，并定义了四种操作，包括 task deconstruction、自省、memory processing 和 tool invocation，同时引入相关技术如 Chain-of-Thought、ReAct 和 Multi-Agent Debate。通过外循环促进人类学习者知识构建，以及内循环增强 LLM-based-Agents 的群智，该系统通过协作和反思，提升了人类学习者和教学能力。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "Conference Proceedings of the 28th Global Chinese Conference on\n  Computers in Education, GCCCE 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.00083v1",
      "published_date": "2024-12-30 16:58:17 UTC",
      "updated_date": "2024-12-30 16:58:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:47:31.305862"
    },
    {
      "arxiv_id": "2412.21052v1",
      "title": "Towards Effective Discrimination Testing for Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas P. Zollo",
        "Nikita Rajaneesh",
        "Richard Zemel",
        "Talia B. Gillis",
        "Emily Black"
      ],
      "abstract": "Generative AI (GenAI) models present new challenges in regulating against\ndiscriminatory behavior. In this paper, we argue that GenAI fairness research\nstill has not met these challenges; instead, a significant gap remains between\nexisting bias assessment methods and regulatory goals. This leads to\nineffective regulation that can allow deployment of reportedly fair, yet\nactually discriminatory, GenAI systems. Towards remedying this problem, we\nconnect the legal and technical literature around GenAI bias evaluation and\nidentify areas of misalignment. Through four case studies, we demonstrate how\nthis misalignment between fairness testing techniques and regulatory goals can\nresult in discriminatory outcomes in real-world deployments, especially in\nadaptive or complex environments. We offer practical recommendations for\nimproving discrimination testing to better align with regulatory goals and\nenhance the reliability of fairness assessments in future deployments.",
      "tldr_zh": "这篇论文探讨了Generative AI (GenAI) 在防范歧视行为方面的监管挑战，指出现有偏见评估方法与监管目标存在显著差距，导致可能部署看似公平但实际歧视性的系统。作者通过连接法律和技术文献，并分析四个案例研究，展示了这种不一致在适应性或复杂环境中如何引发真实歧视性结果。最终，论文提供实用推荐，以改进discrimination testing，使其更好地与regulatory goals 一致，并提升GenAI公平评估的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 9 tables, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.21052v1",
      "published_date": "2024-12-30 16:09:33 UTC",
      "updated_date": "2024-12-30 16:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:47:43.252884"
    },
    {
      "arxiv_id": "2412.21051v2",
      "title": "Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyang Zhou",
        "Guang Cheng",
        "Kang Du",
        "Zihan Chen",
        "Yuyu Zhao"
      ],
      "abstract": "The rapid evolution of cloud computing technologies and the increasing number\nof cloud applications have provided a large number of benefits in daily lives.\nHowever, the diversity and complexity of different components pose a\nsignificant challenge to cloud security, especially when dealing with\nsophisticated and advanced cyberattacks. Recent advancements in generative\nfoundation models (GFMs), particularly in the large language models (LLMs),\noffer promising solutions for security intelligence. By exploiting the powerful\nabilities in language understanding, data analysis, task inference, action\nplanning, and code generation, we present LLM-PD, a novel proactive defense\narchitecture that defeats various threats in a proactive manner. LLM-PD can\nefficiently make a decision through comprehensive data analysis and sequential\nreasoning, as well as dynamically creating and deploying actionable defense\nmechanisms on the target cloud. Furthermore, it can flexibly self-evolve based\non experience learned from previous interactions and adapt to new attack\nscenarios without additional training. The experimental results demonstrate its\nremarkable ability in terms of defense effectiveness and efficiency,\nparticularly highlighting an outstanding success rate when compared with other\nexisting methods.",
      "tldr_zh": "这篇论文针对云计算的安全挑战，提出了一种由 Large Language Models (LLMs) 赋能的主动防御架构 LLM-PD，以应对复杂的高级网络攻击。LLM-PD 利用 LLMs 的语言理解、数据分析、任务推理、行动规划和代码生成能力，通过全面数据分析和顺序推理来高效决策，并动态创建部署防御机制。该架构能基于先前互动的经验自我演化，适应新攻击场景而无需额外训练。实验结果表明，LLM-PD 在防御效果和效率上显著优于现有方法，成功率表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI",
        "68",
        "F.2.2; I.2.8"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages; In submission",
      "pdf_url": "http://arxiv.org/pdf/2412.21051v2",
      "published_date": "2024-12-30 16:09:28 UTC",
      "updated_date": "2025-04-15 02:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:47:55.706722"
    },
    {
      "arxiv_id": "2412.21037v2",
      "title": "TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Chia-Yu Hung",
        "Navonil Majumder",
        "Zhifeng Kong",
        "Ambuj Mehrish",
        "Amir Ali Bagherzadeh",
        "Chuan Li",
        "Rafael Valle",
        "Bryan Catanzaro",
        "Soujanya Poria"
      ],
      "abstract": "We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model\nwith 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio\nin just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models\nlies in the difficulty of creating preference pairs, as TTA lacks structured\nmechanisms like verifiable rewards or gold-standard answers available for Large\nLanguage Models (LLMs). To address this, we propose CLAP-Ranked Preference\nOptimization (CRPO), a novel framework that iteratively generates and optimizes\npreference data to enhance TTA alignment. We demonstrate that the audio\npreference dataset generated using CRPO outperforms existing alternatives. With\nthis framework, TangoFlux achieves state-of-the-art performance across both\nobjective and subjective benchmarks. We open source all code and models to\nsupport further research in TTA generation.",
      "tldr_zh": "我们引入了 TangoFlux，一种高效的 Text-to-Audio (TTA) 生成模型，仅有 515M 参数，就能用单 A40 GPU 在 3.7 秒内生成 30 秒的 44.1kHz 音频。针对 TTA 模型对齐的挑战，该论文提出 CLAP-Ranked Preference Optimization (CRPO)，一个新框架，通过迭代生成和优化偏好数据来提升音频生成质量，并证明其生成的偏好数据集优于现有方案。实验结果显示，TangoFlux 在客观和主观基准上达到 state-of-the-art 性能，并开源所有代码和模型以支持进一步研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "https://tangoflux.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.21037v2",
      "published_date": "2024-12-30 16:02:44 UTC",
      "updated_date": "2025-04-10 05:01:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:49:23.969296"
    },
    {
      "arxiv_id": "2412.21033v1",
      "title": "Plancraft: an evaluation dataset for planning with LLM agents",
      "title_zh": "翻译失败",
      "authors": [
        "Gautier Dagan",
        "Frank Keller",
        "Alex Lascarides"
      ],
      "abstract": "We present Plancraft, a multi-modal evaluation dataset for LLM agents.\nPlancraft has both a text-only and multi-modal interface, based on the\nMinecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and\nRetrieval Augmented Generation (RAG), as well as an oracle planner and oracle\nRAG information extractor, to ablate the different components of a modern agent\narchitecture. To evaluate decision-making, Plancraft also includes a subset of\nexamples that are intentionally unsolvable, providing a realistic challenge\nthat requires the agent not only to complete tasks but also to decide whether\nthey are solvable at all. We benchmark both open-source and closed-source LLMs\nand strategies on our task and compare their performance to a handcrafted\nplanner. We find that LLMs and VLMs struggle with the planning problems that\nPlancraft introduces, and we offer suggestions on how to improve their\ncapabilities.",
      "tldr_zh": "本研究介绍了Plancraft，这是一个多模态评估数据集，旨在评估LLM agents的规划能力。数据集基于Minecraft的crafting GUI，提供文本和多模态接口，并整合Minecraft Wiki、oracle planner以及oracle RAG信息提取器，以测试工具使用、Retrieval Augmented Generation (RAG) 和代理架构的各个组件；同时包括故意不可解的任务子集，以评估决策能力。实验基准测试了开源和闭源LLMs及VLMs的表现，发现它们在Plancraft的规划问题上挣扎，并提出了改进这些模型能力的建议。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.21033v1",
      "published_date": "2024-12-30 15:58:41 UTC",
      "updated_date": "2024-12-30 15:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:49:35.070216"
    },
    {
      "arxiv_id": "2412.21006v2",
      "title": "Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant Rationale via Principled Criteria",
      "title_zh": "翻译失败",
      "authors": [
        "Joonwon Jang",
        "Jaehee Kim",
        "Wonbin Kweon",
        "Hwanjo Yu"
      ],
      "abstract": "Large Language Models (LLMs) rely on generating extensive intermediate\nreasoning units (e.g., tokens, sentences) to enhance final answer quality\nacross a wide range of complex tasks. While generating multiple reasoning paths\nor iteratively refining rationales proves effective for improving performance,\nthese approaches inevitably result in significantly higher inference costs. In\nthis work, we propose a novel sentence-level rationale reduction training\nframework that leverages likelihood-based criteria, verbosity, to identify and\nremove redundant reasoning sentences. Unlike previous approaches that utilize\ntoken-level reduction, our sentence-level reduction framework maintains model\nperformance while reducing generation length. This preserves the original\nreasoning abilities of LLMs and achieves an average 17.15% reduction in\ngeneration costs across various models and tasks.",
      "tldr_zh": "本研究针对大语言模型(LLMs)生成冗长中间推理单位（如tokens或sentences）所带来的高推理成本问题，提出了一种基于Verbosity-Aware Rationale Reduction的句子级别训练框架。该框架利用基于似然度的verbosity标准来识别并移除冗余推理句子，与之前的token-level方法不同，它能保持模型的原始推理性能。实验结果显示，该框架在多种模型和任务上平均减少了17.15%的生成长度，同时维持了答案质量的提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.21006v2",
      "published_date": "2024-12-30 15:15:08 UTC",
      "updated_date": "2024-12-31 03:06:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:49:46.952745"
    },
    {
      "arxiv_id": "2412.21001v1",
      "title": "LEASE: Offline Preference-based Reinforcement Learning with High Sample Efficiency",
      "title_zh": "LEASE：离线基于偏好的强化学习，具有高样本效率",
      "authors": [
        "Xiao-Yin Liu",
        "Guotao Li",
        "Xiao-Hu Zhou",
        "Zeng-Guang Hou"
      ],
      "abstract": "Offline preference-based reinforcement learning (PbRL) provides an effective\nway to overcome the challenges of designing reward and the high costs of online\ninteraction. However, since labeling preference needs real-time human feedback,\nacquiring sufficient preference labels is challenging. To solve this, this\npaper proposes a offLine prEference-bAsed RL with high Sample Efficiency\n(LEASE) algorithm, where a learned transition model is leveraged to generate\nunlabeled preference data. Considering the pretrained reward model may generate\nincorrect labels for unlabeled data, we design an uncertainty-aware mechanism\nto ensure the performance of reward model, where only high confidence and low\nvariance data are selected. Moreover, we provide the generalization bound of\nreward model to analyze the factors influencing reward accuracy, and\ndemonstrate that the policy learned by LEASE has theoretical improvement\nguarantee. The developed theory is based on state-action pair, which can be\neasily combined with other offline algorithms. The experimental results show\nthat LEASE can achieve comparable performance to baseline under fewer\npreference data without online interaction.",
      "tldr_zh": "这篇论文提出了一种离线偏好-based 强化学习 (Offline PbRL) 算法 LEASE，以解决奖励函数设计困难和在线交互成本高的问题，通过学习到的 transition model 生成未标注偏好数据。算法引入 uncertainty-aware 机制，仅选择高置信度和低方差的数据，以确保奖励模型的准确性。论文还提供了奖励模型的 generalization bound，并证明了 LEASE 学习的策略具有理论改进保证。实验结果显示，LEASE 在更少的偏好数据下即可实现与基线相当的性能，且无需在线交互。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.21001v1",
      "published_date": "2024-12-30 15:10:57 UTC",
      "updated_date": "2024-12-30 15:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:49:59.064301"
    },
    {
      "arxiv_id": "2412.20995v1",
      "title": "KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Fang",
        "Kaijing Ma",
        "Tianyu Zheng",
        "Xinrun Du",
        "Ningxuan Lu",
        "Ge Zhang",
        "Qingkun Tang"
      ],
      "abstract": "Large language models (LLMs) demonstrate exceptional performance across a\nvariety of tasks, yet they are often affected by hallucinations and the\ntimeliness of knowledge. Leveraging knowledge graphs (KGs) as external\nknowledge sources has emerged as a viable solution, but existing methods for\nLLM-based knowledge graph question answering (KGQA) are often limited by\nstep-by-step decision-making on KGs, restricting the global planning and\nreasoning capabilities of LLMs, or they require fine-tuning or pre-training on\nspecific KGs. To address these challenges, we propose Knowledge graph Assisted\nReasoning Path Aggregation (KARPA), a novel framework that harnesses the global\nplanning abilities of LLMs for efficient and accurate KG reasoning. KARPA\noperates in three steps: pre-planning relation paths using the LLM's global\nplanning capabilities, matching semantically relevant paths via an embedding\nmodel, and reasoning over these paths to generate answers. Unlike existing KGQA\nmethods, KARPA avoids stepwise traversal, requires no additional training, and\nis adaptable to various LLM architectures. Extensive experimental results show\nthat KARPA achieves state-of-the-art performance in KGQA tasks, delivering both\nhigh efficiency and accuracy. Our code will be available on Github.",
      "tldr_zh": "该研究提出 KARPA，一种无需训练的方法，将知识图谱 (KGs) 作为外部参考，以提升大型语言模型 (LLMs) 在知识图谱问答 (KGQA) 中的全局规划和推理路径聚合能力。KARPA 通过三个步骤实现：利用 LLMs 的全局规划能力预规划关系路径、通过嵌入模型匹配语义相关路径、以及在这些路径上进行推理生成答案。与现有方法相比，KARPA 避免了步进遍历决策，且适用于各种 LLM 架构。实验结果表明，KARPA 在 KGQA 任务中实现了最先进性能，同时提升了效率和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.20995v1",
      "published_date": "2024-12-30 14:58:46 UTC",
      "updated_date": "2024-12-30 14:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:50:12.037905"
    },
    {
      "arxiv_id": "2412.20977v1",
      "title": "UnrealZoo: Enriching Photo-realistic Virtual Worlds for Embodied AI",
      "title_zh": "UnrealZoo：丰富照片级真实虚拟世界用于具身AI",
      "authors": [
        "Fangwei Zhong",
        "Kui Wu",
        "Churan Wang",
        "Hao Chen",
        "Hai Ci",
        "Zhoujun Li",
        "Yizhou Wang"
      ],
      "abstract": "We introduce UnrealZoo, a rich collection of photo-realistic 3D virtual\nworlds built on Unreal Engine, designed to reflect the complexity and\nvariability of the open worlds. Additionally, we offer a variety of playable\nentities for embodied AI agents. Based on UnrealCV, we provide a suite of\neasy-to-use Python APIs and tools for various potential applications, such as\ndata collection, environment augmentation, distributed training, and\nbenchmarking. We optimize the rendering and communication efficiency of\nUnrealCV to support advanced applications, such as multi-agent interaction. Our\nexperiments benchmark agents in various complex scenes, focusing on visual\nnavigation and tracking, which are fundamental capabilities for embodied visual\nintelligence. The results yield valuable insights into the advantages of\ndiverse training environments for reinforcement learning (RL) agents and the\nchallenges faced by current embodied vision agents, including those based on RL\nand large vision-language models (VLMs), in open worlds. These challenges\ninvolve latency in closed-loop control in dynamic scenes and reasoning about 3D\nspatial structures in unstructured terrain.",
      "tldr_zh": "我们引入了 UnrealZoo，这是一个基于 Unreal Engine 的 photo-realistic 3D 虚拟世界集合，旨在模拟开放世界的复杂性和可变性，并为 Embodied AI 代理提供多样化的可玩实体和环境。系统通过 UnrealCV 提供的易用 Python APIs 和工具，支持数据收集、环境增强、分布式训练以及基准测试，优化了渲染和通信效率以适应多代理交互。实验结果显示，在视觉导航和跟踪等任务中，多样训练环境显著提升了 reinforcement learning (RL) 代理的表现，同时暴露了当前 Embodied vision 代理面临的挑战，包括动态场景中的延迟和对 3D 空间结构的推理困难。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Project page: http://unrealzoo.site/",
      "pdf_url": "http://arxiv.org/pdf/2412.20977v1",
      "published_date": "2024-12-30 14:31:01 UTC",
      "updated_date": "2024-12-30 14:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:50:23.794218"
    },
    {
      "arxiv_id": "2412.20962v3",
      "title": "Conservation-informed Graph Learning for Spatiotemporal Dynamics Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Mi",
        "Pu Ren",
        "Hongteng Xu",
        "Hongsheng Liu",
        "Zidong Wang",
        "Yike Guo",
        "Ji-Rong Wen",
        "Hao Sun",
        "Yang Liu"
      ],
      "abstract": "Data-centric methods have shown great potential in understanding and\npredicting spatiotemporal dynamics, enabling better design and control of the\nobject system. However, deep learning models often lack interpretability, fail\nto obey intrinsic physics, and struggle to cope with the various domains. While\ngeometry-based methods, e.g., graph neural networks (GNNs), have been proposed\nto further tackle these challenges, they still need to find the implicit\nphysical laws from large datasets and rely excessively on rich labeled data. In\nthis paper, we herein introduce the conservation-informed GNN (CiGNN), an\nend-to-end explainable learning framework, to learn spatiotemporal dynamics\nbased on limited training data. The network is designed to conform to the\ngeneral conservation law via symmetry, where conservative and non-conservative\ninformation passes over a multiscale space enhanced by a latent temporal\nmarching strategy. The efficacy of our model has been verified in various\nspatiotemporal systems based on synthetic and real-world datasets, showing\nsuperiority over baseline models. Results demonstrate that CiGNN exhibits\nremarkable accuracy and generalizability, and is readily applicable to learning\nfor prediction of various spatiotemporal dynamics in a spatial domain with\ncomplex geometry.",
      "tldr_zh": "本文提出了一种基于守恒定律的图神经网络（Conservation-informed GNN，简称 CiGNN），这是一个端到端的可解释学习框架，用于在有限训练数据下预测时空动态（Spatiotemporal Dynamics），以解决现有深度学习模型的可解释性不足和物理定律遵守问题。CiGNN 通过对称性处理保守和非保守信息，并结合多尺度空间和潜在时间推进策略，实现对复杂时空系统的有效学习。在合成和真实世界数据集上的实验验证中，CiGNN 比基线模型表现出显著的准确性和泛化能力，可广泛应用于复杂几何空间的动态预测。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20962v3",
      "published_date": "2024-12-30 13:55:59 UTC",
      "updated_date": "2025-01-06 14:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:50:36.153209"
    },
    {
      "arxiv_id": "2412.20960v1",
      "title": "Rise of Generative Artificial Intelligence in Science",
      "title_zh": "生成式人工智能在科学中的兴起",
      "authors": [
        "Liangping Ding",
        "Cornelia Lawson",
        "Philip Shapira"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI, generative AI) has rapidly become\navailable as a tool in scientific research. To explore the use of generative AI\nin science, we conduct an empirical analysis using OpenAlex. Analyzing GenAI\npublications and other AI publications from 2017 to 2023, we profile growth\npatterns, the diffusion of GenAI publications across fields of study, and the\ngeographical spread of scientific research on generative AI. We also\ninvestigate team size and international collaborations to explore whether\nGenAI, as an emerging scientific research area, shows different collaboration\npatterns compared to other AI technologies. The results indicate that\ngenerative AI has experienced rapid growth and increasing presence in\nscientific publications. The use of GenAI now extends beyond computer science\nto other scientific research domains. Over the study period, U.S. researchers\ncontributed nearly two-fifths of global GenAI publications. The U.S. is\nfollowed by China, with several small and medium-sized advanced economies\ndemonstrating relatively high levels of GenAI deployment in their research\npublications. Although scientific research overall is becoming increasingly\nspecialized and collaborative, our results suggest that GenAI research groups\ntend to have slightly smaller team sizes than found in other AI fields.\nFurthermore, notwithstanding recent geopolitical tensions, GenAI research\ncontinues to exhibit levels of international collaboration comparable to other\nAI technologies.",
      "tldr_zh": "这篇论文通过对 OpenAlex 数据库的实证分析，探讨了 Generative Artificial Intelligence (GenAI) 在科学研究中的兴起和发展，比较了 2017-2023 年 GenAI 出版物与其他 AI 出版物的增长模式、领域扩散和地理分布。研究发现，GenAI 出版物快速增长，已扩展到计算机科学以外的领域，美国贡献了近四成全球出版物，其次是中国，而中小型先进经济体也显示出较高的 GenAI 部署水平。相比其他 AI 技术，GenAI 研究团队规模稍小，但国际合作水平保持相当，甚至在地缘政治紧张下仍持续强劲。该工作突显了 GenAI 作为新兴领域的全球影响力和协作动态。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR",
        "H.3.3; K.4.0"
      ],
      "primary_category": "cs.CY",
      "comment": "26 pages, 4 tables, 1 figures, 1 appendix figure",
      "pdf_url": "http://arxiv.org/pdf/2412.20960v1",
      "published_date": "2024-12-30 13:55:28 UTC",
      "updated_date": "2024-12-30 13:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:50:48.019740"
    },
    {
      "arxiv_id": "2501.01985v1",
      "title": "Fall Detection in Passenger Elevators using Intelligent Surveillance Camera Systems: An Application with YoloV8 Nano Model",
      "title_zh": "翻译失败",
      "authors": [
        "Pinar Yozgatli",
        "Yavuz Acar",
        "Mehmet Tulumen",
        "Selman Minga",
        "Salih Selamet",
        "Beytullah Nalbant",
        "Mustafa Talha Toru",
        "Berna Koca",
        "Tevfik Keles",
        "Mehmet Selcok"
      ],
      "abstract": "Computer vision technology, which involves analyzing images and videos\ncaptured by cameras through deep learning algorithms, has significantly\nadvanced the field of human fall detection. This study focuses on the\napplication of the YoloV8 Nano model in identifying fall incidents within\npassenger elevators, a context that presents unique challenges due to the\nenclosed environment and varying lighting conditions. By training the model on\na robust dataset comprising over 10,000 images across diverse elevator types,\nwe aim to enhance the detection precision and recall rates. The model's\nperformance, with an 85% precision and 82% recall in fall detection,\nunderscores its potential for integration into existing elevator safety systems\nto enable rapid intervention.",
      "tldr_zh": "本研究应用 YoloV8 Nano 模型于电梯内的跌倒检测，利用计算机视觉技术处理封闭环境和可变照明条件带来的挑战。通过训练一个包含超过 10,000 张图像的数据集，模型针对不同电梯类型优化了检测性能。结果显示，模型的精确度达 85%、召回率达 82%，为提升电梯安全系统并实现快速干预提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.01985v1",
      "published_date": "2024-12-30 13:37:48 UTC",
      "updated_date": "2024-12-30 13:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:50:59.333550"
    },
    {
      "arxiv_id": "2412.20942v1",
      "title": "Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohan Feng",
        "Xixin Wu",
        "Helen Meng"
      ],
      "abstract": "We propose an ontology-grounded approach to Knowledge Graph (KG) construction\nusing Large Language Models (LLMs) on a knowledge base. An ontology is authored\nby generating Competency Questions (CQ) on knowledge base to discover knowledge\nscope, extracting relations from CQs, and attempt to replace equivalent\nrelations by their counterpart in Wikidata. To ensure consistency and\ninterpretability in the resulting KG, we ground generation of KG with the\nauthored ontology based on extracted relations. Evaluation on benchmark\ndatasets demonstrates competitive performance in knowledge graph construction\ntask. Our work presents a promising direction for scalable KG construction\npipeline with minimal human intervention, that yields high quality and\nhuman-interpretable KGs, which are interoperable with Wikidata semantics for\npotential knowledge base expansion.",
      "tldr_zh": "本论文提出了一种基于本体论的自动知识图谱（Knowledge Graph, KG）构建方法，使用大型语言模型（LLM），并以Wikidata模式为指导。通过生成能力问题（Competency Questions, CQ）来发现知识范围、提取关系并替换为Wikidata等价关系，从而确保生成的KG具有一致性和可解释性。实验在基准数据集上显示了该方法在KG构建任务中的竞争性能，并为可扩展的KG构建管道提供了前景，支持最小人为干预和高兼容性。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at HI-AI@KDD, Human-Interpretable AI Workshop at the KDD\n  2024, 26th of August 2024, Barcelona, Spain",
      "pdf_url": "http://arxiv.org/pdf/2412.20942v1",
      "published_date": "2024-12-30 13:36:05 UTC",
      "updated_date": "2024-12-30 13:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:51:11.995846"
    },
    {
      "arxiv_id": "2412.20924v1",
      "title": "HisynSeg: Weakly-Supervised Histopathological Image Segmentation via Image-Mixing Synthesis and Consistency Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Fang",
        "Yifeng Wang",
        "Peizhang Xie",
        "Zhi Wang",
        "Yongbing Zhang"
      ],
      "abstract": "Tissue semantic segmentation is one of the key tasks in computational\npathology. To avoid the expensive and laborious acquisition of pixel-level\nannotations, a wide range of studies attempt to adopt the class activation map\n(CAM), a weakly-supervised learning scheme, to achieve pixel-level tissue\nsegmentation. However, CAM-based methods are prone to suffer from\nunder-activation and over-activation issues, leading to poor segmentation\nperformance. To address this problem, we propose a novel weakly-supervised\nsemantic segmentation framework for histopathological images based on\nimage-mixing synthesis and consistency regularization, dubbed HisynSeg.\nSpecifically, synthesized histopathological images with pixel-level masks are\ngenerated for fully-supervised model training, where two synthesis strategies\nare proposed based on Mosaic transformation and B\\'ezier mask generation.\nBesides, an image filtering module is developed to guarantee the authenticity\nof the synthesized images. In order to further avoid the model overfitting to\nthe occasional synthesis artifacts, we additionally propose a novel\nself-supervised consistency regularization, which enables the real images\nwithout segmentation masks to supervise the training of the segmentation model.\nBy integrating the proposed techniques, the HisynSeg framework successfully\ntransforms the weakly-supervised semantic segmentation problem into a\nfully-supervised one, greatly improving the segmentation accuracy. Experimental\nresults on three datasets prove that the proposed method achieves a\nstate-of-the-art performance. Code is available at\nhttps://github.com/Vison307/HisynSeg.",
      "tldr_zh": "本文提出 HisynSeg 框架，用于弱监督的组织病理图像分割，旨在解决 CAM 方法的 under-activation 和 over-activation 问题，从而提高分割性能。具体地，该框架通过基于 Mosaic 变换和 Bézier 掩码生成的图像混合合成创建合成图像及其像素级掩码，并结合图像过滤模块确保合成图像的真实性，同时引入自监督 consistency regularization 以避免模型过拟合。实验结果显示，HisynSeg 将弱监督问题转化为全监督问题，在三个数据集上实现了最先进的状态性能。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE Transactions on Medical Imaging",
      "pdf_url": "http://arxiv.org/pdf/2412.20924v1",
      "published_date": "2024-12-30 13:10:48 UTC",
      "updated_date": "2024-12-30 13:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:51:23.504137"
    },
    {
      "arxiv_id": "2412.20903v4",
      "title": "WalkVLM:Aid Visually Impaired People Walking by Vision Language Model",
      "title_zh": "WalkVLM：通过视觉语言模型辅助视觉障碍者行走",
      "authors": [
        "Zhiqiang Yuan",
        "Ting Zhang",
        "Ying Deng",
        "Jiapei Zhang",
        "Yeshuang Zhu",
        "Zexi Jia",
        "Jie Zhou",
        "Jinchao Zhang"
      ],
      "abstract": "Approximately 200 million individuals around the world suffer from varying\ndegrees of visual impairment, making it crucial to leverage AI technology to\noffer walking assistance for these people. With the recent progress of\nvision-language models (VLMs), applying VLMs to offer walking guidance has\nbecome popular. However, the existing methods of walking guidance are mainly\nbased on self-curated question-answering datasets that are not publicly\naccessible, without a standardized benchmark for training or evaluation.\nMoreover, walking assistance often requires real-time streaming video analysis\nand the generation of concise yet informative reminders, making VLMs struggle\ndue to excessive responses and low efficiency in inferences. In this paper, we\nintroduce the first large-scale dataset dedicated to walking assistance,\ncomprising 12,000 video-annotation pairs, to provide a unified benchmark for\ntraining and evaluating systems to help visually-impaired individuals walk.\nFurthermore, a WalkVLM model is proposed, which employs chain of thought for\nhierarchical planning to generate concise but informative reminders and\nutilizes temporal-aware adaptive prediction to reduce the temporal redundancy\nof reminders. Finally, we have established a solid benchmark for blind walking\ntask and verified the advantages of WalkVLM in stream video processing for this\ntask compared to other VLMs. Our dataset and code are available at\nhttps://walkvlm2024.github.io.",
      "tldr_zh": "大约 2 亿人受视力障碍影响，本文提出 WalkVLM 模型，利用 Vision Language Model (VLMs) 提供步行辅助，以解决现有方法缺乏标准基准和效率低的问题。研究者构建了第一个大规模数据集，包含 12,000 个视频-注释对，作为统一的训练和评估基准。WalkVLM 采用 chain of thought for hierarchical planning 生成简洁信息提醒，并使用 temporal-aware adaptive prediction 减少提醒的时序冗余。实验结果显示，该模型在盲人步行任务的流视频处理中优于其他 VLMs，并公开了数据集和代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20903v4",
      "published_date": "2024-12-30 12:29:02 UTC",
      "updated_date": "2025-03-04 15:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:51:35.518359"
    },
    {
      "arxiv_id": "2412.20901v1",
      "title": "ILDiff: Generate Transparent Animated Stickers by Implicit Layout Distillation",
      "title_zh": "ILDiff：通过隐式布局蒸馏生成透明动画贴纸",
      "authors": [
        "Ting Zhang",
        "Zhiqiang Yuan",
        "Yeshuang Zhu",
        "Jinchao Zhang"
      ],
      "abstract": "High-quality animated stickers usually contain transparent channels, which\nare often ignored by current video generation models. To generate fine-grained\nanimated transparency channels, existing methods can be roughly divided into\nvideo matting algorithms and diffusion-based algorithms. The methods based on\nvideo matting have poor performance in dealing with semi-open areas in\nstickers, while diffusion-based methods are often used to model a single image,\nwhich will lead to local flicker when modeling animated stickers. In this\npaper, we firstly propose an ILDiff method to generate animated transparent\nchannels through implicit layout distillation, which solves the problems of\nsemi-open area collapse and no consideration of temporal information in\nexisting methods. Secondly, we create the Transparent Animated Sticker Dataset\n(TASD), which contains 0.32M high-quality samples with transparent channel, to\nprovide data support for related fields. Extensive experiments demonstrate that\nILDiff can produce finer and smoother transparent channels compared to other\nmethods such as Matting Anything and Layer Diffusion. Our code and dataset will\nbe released at link https://xiaoyuan1996.github.io.",
      "tldr_zh": "本论文提出ILDiff方法，通过Implicit Layout Distillation隐式布局蒸馏技术生成高质量动画贴纸的透明通道，解决了现有视频抠图算法在处理半开放区域的不足以及扩散-based方法忽略时间信息导致的局部闪烁问题。ILDiff首次考虑了动画贴纸的时序信息，确保生成的透明通道更精细和平滑。同时，作者创建了Transparent Animated Sticker Dataset (TASD)，包含0.32M高质量样本，以支持相关领域的研究。实验结果显示，ILDiff比Matting Anything和Layer Diffusion等方法表现出色，在生成透明通道方面取得了显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20901v1",
      "published_date": "2024-12-30 12:27:35 UTC",
      "updated_date": "2024-12-30 12:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:51:46.590891"
    },
    {
      "arxiv_id": "2501.00078v1",
      "title": "Human-like Bots for Tactical Shooters Using Compute-Efficient Sensors",
      "title_zh": "翻译失败",
      "authors": [
        "Niels Justesen",
        "Maria Kaselimi",
        "Sam Snodgrass",
        "Miruna Vozaru",
        "Matthew Schlegel",
        "Jonas Wingren",
        "Gabriella A. B. Barros",
        "Tobias Mahlmann",
        "Shyam Sudhakaran",
        "Wesley Kerr",
        "Albert Wang",
        "Christoffer Holmgård",
        "Georgios N. Yannakakis",
        "Sebastian Risi",
        "Julian Togelius"
      ],
      "abstract": "Artificial intelligence (AI) has enabled agents to master complex video\ngames, from first-person shooters like Counter-Strike to real-time strategy\ngames such as StarCraft II and racing games like Gran Turismo. While these\nachievements are notable, applying these AI methods in commercial video game\nproduction remains challenging due to computational constraints. In commercial\nscenarios, the majority of computational resources are allocated to 3D\nrendering, leaving limited capacity for AI methods, which often demand high\ncomputational power, particularly those relying on pixel-based sensors.\nMoreover, the gaming industry prioritizes creating human-like behavior in AI\nagents to enhance player experience, unlike academic models that focus on\nmaximizing game performance. This paper introduces a novel methodology for\ntraining neural networks via imitation learning to play a complex,\ncommercial-standard, VALORANT-like 2v2 tactical shooter game, requiring only\nmodest CPU hardware during inference. Our approach leverages an innovative,\npixel-free perception architecture using a small set of ray-cast sensors, which\ncapture essential spatial information efficiently. These sensors allow AI to\nperform competently without the computational overhead of traditional methods.\nModels are trained to mimic human behavior using supervised learning on human\ntrajectory data, resulting in realistic and engaging AI agents. Human\nevaluation tests confirm that our AI agents provide human-like gameplay\nexperiences while operating efficiently under computational constraints. This\noffers a significant advancement in AI model development for tactical shooter\ngames and possibly other genres.",
      "tldr_zh": "该论文提出了一种计算高效的方法，用于训练AI代理在类似VALORANT的2v2战术射击游戏中模仿人类行为，解决商业游戏中计算资源有限的挑战。该方法采用imitation learning和创新的ray-cast sensors作为像素-free感知架构，仅需少量CPU硬件即可捕获空间信息，实现高效游戏决策。模型通过supervised learning基于人类轨迹数据进行训练，生成真实且引人入胜的AI代理。人类评估显示，这些AI代理提供类似于人类的游戏体验，同时显著降低了计算开销，为战术射击游戏及其他类型游戏的AI开发带来重要进步。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00078v1",
      "published_date": "2024-12-30 12:06:37 UTC",
      "updated_date": "2024-12-30 12:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:51:58.392744"
    },
    {
      "arxiv_id": "2501.14772v1",
      "title": "DropMicroFluidAgents (DMFAs): Autonomous Droplet Microfluidic Research Framework Through Large Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Dinh-Nguyen Nguyen",
        "Raymond Kai-Yu Tong",
        "Ngoc-Duy Dinh"
      ],
      "abstract": "Applying Large language models (LLMs) within specific domains requires\nsubstantial adaptation to account for the unique terminologies, nuances, and\ncontext-specific challenges inherent to those areas. Here, we introduce\nDropMicroFluidAgents (DMFAs), an advanced language-driven framework leveraging\nstate-of-the-art pre-trained LLMs. DMFAs employs LLM agents to perform two key\nfunctions: (1) delivering focused guidance, answers, and suggestions specific\nto droplet microfluidics and (2) generating machine learning models to optimise\nand automate the design of droplet microfluidic devices, including the creation\nof code-based computer-aided design (CAD) scripts to enable rapid and precise\ndesign execution. Experimental evaluations demonstrated that the integration of\nDMFAs with the LLAMA3.1 model yielded the highest accuracy of 76.15%,\nunderscoring the significant performance enhancement provided by agent\nintegration. This effect was particularly pronounced when DMFAs were paired\nwith the GEMMA2 model, resulting in a 34.47% improvement in accuracy compared\nto the standalone GEMMA2 configuration. This study demonstrates the effective\nuse of LLM agents in droplet microfluidics research as powerful tools for\nautomating workflows, synthesising knowledge, optimising designs, and\ninteracting with external systems. These capabilities enable their application\nacross education and industrial support, driving greater efficiency in\nscientific discovery and innovation.",
      "tldr_zh": "本研究引入了DropMicroFluidAgents (DMFAs)，一个先进的语言驱动框架，利用预训练的Large Language Models (LLMs)代理来处理droplet microfluidics领域的特定挑战。DMFAs的主要功能包括提供针对性指导、答案和建议，以及生成machine learning models来优化设备设计并创建基于代码的computer-aided design (CAD)脚本，以实现快速精确的自动化。实验结果显示，与LLAMA3.1集成时，DMFAs实现了76.15%的最高准确率，而与GEMMA2结合时，准确率较独立GEMMA2提高了34.47%。这项工作证明了LLM agents在droplet microfluidics研究中的潜力，可用于自动化工作流、知识合成和设计优化，从而提升教育和工业领域的科学发现效率。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14772v1",
      "published_date": "2024-12-30 11:58:52 UTC",
      "updated_date": "2024-12-30 11:58:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:52:11.909997"
    },
    {
      "arxiv_id": "2501.01984v1",
      "title": "Leveraging AI for Automatic Classification of PCOS Using Ultrasound Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Atharva Divekar",
        "Atharva Sonawane"
      ],
      "abstract": "The AUTO-PCOS Classification Challenge seeks to advance the diagnostic\ncapabilities of artificial intelligence (AI) in identifying Polycystic Ovary\nSyndrome (PCOS) through automated classification of healthy and unhealthy\nultrasound frames. This report outlines our methodology for building a robust\nAI pipeline utilizing transfer learning with the InceptionV3 architecture to\nachieve high accuracy in binary classification. Preprocessing steps ensured the\ndataset was optimized for training, validation, and testing, while\ninterpretability methods like LIME and saliency maps provided valuable insights\ninto the model's decision-making. Our approach achieved an accuracy of 90.52%,\nwith precision, recall, and F1-score metrics exceeding 90% on validation data,\ndemonstrating its efficacy. The project underscores the transformative\npotential of AI in healthcare, particularly in addressing diagnostic challenges\nlike PCOS. Key findings, challenges, and recommendations for future\nenhancements are discussed, highlighting the pathway for creating reliable,\ninterpretable, and scalable AI-driven medical diagnostic tools.",
      "tldr_zh": "本研究提出了一种利用 AI 通过超声成像自动分类多囊卵巢综合征（PCOS）的框架，参与 AUTO-PCOS Classification Challenge。方法包括使用 InceptionV3 架构的迁移学习（transfer learning），结合数据预处理和解释性工具如 LIME 和 saliency maps，以优化模型决策。实验结果显示，该模型在验证数据上达到 90.52% 准确率，精确率、召回率和 F1 分数均超过 90%，证明了其在 PCOS 诊断中的高效性。该工作强调了 AI 在医疗领域的变革潜力，并提供了未来改进的建议。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "I.4.9"
      ],
      "primary_category": "eess.IV",
      "comment": "Code available at: https://github.com/ATHdevs/Auto-PCOS",
      "pdf_url": "http://arxiv.org/pdf/2501.01984v1",
      "published_date": "2024-12-30 11:56:11 UTC",
      "updated_date": "2024-12-30 11:56:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:52:24.244299"
    },
    {
      "arxiv_id": "2412.20867v1",
      "title": "Holistic Construction Automation with Modular Robots: From High-Level Task Specification to Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Külz",
        "Michael Terzer",
        "Marco Magri",
        "Andrea Giusti",
        "Matthias Althoff"
      ],
      "abstract": "In situ robotic automation in construction is challenging due to constantly\nchanging environments, a shortage of robotic experts, and a lack of\nstandardized frameworks bridging robotics and construction practices. This work\nproposes a holistic framework for construction task specification, optimization\nof robot morphology, and mission execution using a mobile modular\nreconfigurable robot. Users can specify and monitor the desired robot behavior\nthrough a graphical interface. Our framework identifies an optimized robot\nmorphology and enables automatic real-world execution by integrating Building\nInformation Modelling (BIM). By leveraging modular robot components, we ensure\nseamless and fast adaption to the specific demands of the construction task.\nExperimental validation demonstrates that our approach robustly enables the\nautonomous execution of robotic drilling.",
      "tldr_zh": "该研究提出一个整体框架，用于建筑领域的机器人自动化，解决环境变化、专家短缺和框架标准化问题。该框架从高层任务规范开始，通过图形界面允许用户指定和监控模块化可重构机器人的行为，并整合 Building Information Modelling (BIM) 来优化机器人形态并实现自动任务执行。利用模块化机器人组件，确保快速适应建筑任务需求。实验验证显示，该方法robustly实现了机器人钻孔的自主执行。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20867v1",
      "published_date": "2024-12-30 11:11:13 UTC",
      "updated_date": "2024-12-30 11:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:52:34.245843"
    },
    {
      "arxiv_id": "2412.20864v1",
      "title": "Enhancing Annotated Bibliography Generation with LLM Ensembles",
      "title_zh": "通过 LLM 集成增强注释书目生成",
      "authors": [
        "Sergio Bermejo"
      ],
      "abstract": "This work proposes a novel approach to enhancing annotated bibliography\ngeneration through Large Language Model (LLM) ensembles. In particular,\nmultiple LLMs in different roles -- controllable text generation, evaluation,\nand summarization -- are introduced and validated using a systematic\nmethodology to enhance model performance in scholarly tasks. Output diversity\namong the ensemble that generates text is obtained using different LLM\nparameters, followed by an LLM acting as a judge to assess relevance, accuracy,\nand coherence. Responses selected by several combining strategies are then\nmerged and refined through summarization and redundancy removal techniques. The\npreliminary experimental validation demonstrates that the combined outputs from\nthe LLM ensemble improve coherence and relevance compared to individual\nresponses, leading to a 38% improvement in annotation quality and a 51%\nreduction in content redundancy, thus highlighting the potential for automating\ncomplex scholarly tasks while maintaining high-quality standards.",
      "tldr_zh": "本研究提出了一种利用LLM集成增强注释书目生成的新方法，其中多个LLM分别担任文本生成、评估和总结角色，以提高输出多样性和质量。方法包括通过不同LLM参数创建多样化响应、由一个LLM作为裁判评估相关性、准确性和连贯性，然后通过合并、总结和去除冗余来精炼结果。实验验证显示，这种集成策略相较于单个LLM，提高了38%的注释质量，并减少了51%的内容冗余，为自动化复杂学术任务提供了高效且高质量的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20864v1",
      "published_date": "2024-12-30 11:07:05 UTC",
      "updated_date": "2024-12-30 11:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:52:47.027573"
    },
    {
      "arxiv_id": "2502.15693v1",
      "title": "Hgformer: Hyperbolic Graph Transformer for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Yang",
        "Xingrun Li",
        "Heng Chang",
        "Jinze Yang",
        "Xihong Yang",
        "Shengyu Tao",
        "Ningkang Chang",
        "Maiko Shigeno",
        "Junfeng Wang",
        "Dawei Yin",
        "Erxue Min"
      ],
      "abstract": "The cold start problem is a challenging problem faced by most modern\nrecommender systems. By leveraging knowledge from other domains, cross-domain\nrecommendation can be an effective method to alleviate the cold start problem.\nHowever, the modelling distortion for long-tail data, which is widely present\nin recommender systems, is often overlooked in cross-domain recommendation. In\nthis research, we propose a hyperbolic manifold based cross-domain\ncollaborative filtering model using BiTGCF as the base model. We introduce the\nhyperbolic manifold and construct new propagation layer and transfer layer to\naddress these challenges. The significant performance improvements across\nvarious datasets compared to the baseline models demonstrate the effectiveness\nof our proposed model.",
      "tldr_zh": "本研究针对推荐系统中常见的冷启动问题（cold start problem），提出了一种基于超曲面流形（hyperbolic manifold）的跨域推荐模型Hgformer，以缓解长尾数据（long-tail data）的建模扭曲问题。该模型以BiTGCF为基础，引入新的传播层和转移层，实现超曲面流形上的跨域协同过滤（cross-domain collaborative filtering）。实验结果显示，Hgformer在多种数据集上相比基线模型取得了显著性能提升，证明了其在提升推荐系统有效性的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15693v1",
      "published_date": "2024-12-30 10:50:51 UTC",
      "updated_date": "2024-12-30 10:50:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:52:58.168499"
    },
    {
      "arxiv_id": "2412.20851v1",
      "title": "About rectified sigmoid function for enhancing the accuracy of Physics-Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Vasiliy A. Es'kin",
        "Alexey O. Malkhanov",
        "Mikhail E. Smorkalov"
      ],
      "abstract": "The article is devoted to the study of neural networks with one hidden layer\nand a modified activation function for solving physical problems. A rectified\nsigmoid activation function has been proposed to solve physical problems\ndescribed by the ODE with neural networks. Algorithms for physics-informed\ndata-driven initialization of a neural network and a neuron-by-neuron\ngradient-free fitting method have been presented for the neural network with\nthis activation function. Numerical experiments demonstrate the superiority of\nneural networks with a rectified sigmoid function over neural networks with a\nsigmoid function in the accuracy of solving physical problems (harmonic\noscillator, relativistic slingshot, and Lorentz system).",
      "tldr_zh": "该论文探讨了使用单隐藏层神经网络和改进的激活函数来解决物理问题，特别提出了一种 rectified sigmoid 激活函数，用于处理由 ODE 描述的物理问题。论文介绍了基于物理信息的数据驱动初始化算法和一种逐神经元、无梯度拟合方法，以优化神经网络的性能。数值实验结果显示，与标准 sigmoid 函数相比，rectified sigmoid 函数在解决谐波振荡器、相对论弹弓和 Lorentz 系统等物理问题时，准确性显著提升。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "physics.comp-ph",
        "68T07 (Primary) 65Z05, 65M99 (Secondary)",
        "I.2.1; I.2.7; J.2"
      ],
      "primary_category": "math.NA",
      "comment": "9 pages, 1 figure, 2 tables, 4 algthorithms. arXiv admin note:\n  substantial text overlap with arXiv:2412.19235",
      "pdf_url": "http://arxiv.org/pdf/2412.20851v1",
      "published_date": "2024-12-30 10:42:28 UTC",
      "updated_date": "2024-12-30 10:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:53:10.356289"
    },
    {
      "arxiv_id": "2412.20848v1",
      "title": "Analog Alchemy: Neural Computation with In-Memory Inference, Learning and Routing",
      "title_zh": "翻译失败",
      "authors": [
        "Yigit Demirag"
      ],
      "abstract": "As neural computation is revolutionizing the field of Artificial Intelligence\n(AI), rethinking the ideal neural hardware is becoming the next frontier. Fast\nand reliable von Neumann architecture has been the hosting platform for neural\ncomputation. Although capable, its separation of memory and computation creates\nthe bottleneck for the energy efficiency of neural computation, contrasting the\nbiological brain. The question remains: how can we efficiently combine memory\nand computation, while exploiting the physics of the substrate, to build\nintelligent systems? In this thesis, I explore an alternative way with\nmemristive devices for neural computation, where the unique physical dynamics\nof the devices are used for inference, learning and routing. Guided by the\nprinciples of gradient-based learning, we selected functions that need to be\nmaterialized, and analyzed connectomics principles for efficient wiring.\nDespite non-idealities and noise inherent in analog physics, I will provide\nhardware evidence of adaptability of local learning to memristive substrates,\nnew material stacks and circuit blocks that aid in solving the credit\nassignment problem and efficient routing between analog crossbars for scalable\narchitectures.",
      "tldr_zh": "该论文探讨了神经计算在AI领域的革命，并指出von Neumann架构的内存与计算分离导致的能效瓶颈，提出通过memristive devices结合内存和计算，利用设备的物理动态进行推理、学习和路由。作者基于梯度学习原则选择实现函数，并分析connectomics原则以优化布线。尽管模拟物理存在非理想性和噪声，研究提供了硬件证据，证明本地学习可适应memristive基板，并通过新材料堆栈和电路块解决信用分配问题和高效路由问题。该方法为构建可扩展的智能系统奠定了基础，旨在提升能效并模仿生物大脑。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20848v1",
      "published_date": "2024-12-30 10:35:03 UTC",
      "updated_date": "2024-12-30 10:35:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:53:23.400645"
    },
    {
      "arxiv_id": "2412.20838v1",
      "title": "Dual-Space Augmented Intrinsic-LoRA for Wind Turbine Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Shubh Singhal",
        "Raül Pérez-Gonzalo",
        "Andreas Espersen",
        "Antonio Agudo"
      ],
      "abstract": "Accurate segmentation of wind turbine blade (WTB) images is critical for\neffective assessments, as it directly influences the performance of automated\ndamage detection systems. Despite advancements in large universal vision\nmodels, these models often underperform in domain-specific tasks like WTB\nsegmentation. To address this, we extend Intrinsic LoRA for image segmentation,\nand propose a novel dual-space augmentation strategy that integrates both\nimage-level and latent-space augmentations. The image-space augmentation is\nachieved through linear interpolation between image pairs, while the\nlatent-space augmentation is accomplished by introducing a noise-based latent\nprobabilistic model. Our approach significantly boosts segmentation accuracy,\nsurpassing current state-of-the-art methods in WTB image segmentation.",
      "tldr_zh": "本研究针对风力涡轮机叶片(WTB)图像分割的挑战，扩展了Intrinsic-LoRA方法，并提出了一种Dual-Space Augmented策略，以提升自动损伤检测系统的性能。\n该策略整合了图像级增强(通过图像对线性插值实现)和潜在空间增强(基于噪声的潜在概率模型)，从而有效缓解通用视觉模型在领域特定任务中的不足。\n实验结果表明，该方法显著提高了WTB图像分割准确性，超越了当前最先进的技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Authors Shubh Singhal and Ra\\\"ul P\\'erez-Gonzalo contributed equally\n  to this work. Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.20838v1",
      "published_date": "2024-12-30 10:06:02 UTC",
      "updated_date": "2024-12-30 10:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:55:35.015226"
    },
    {
      "arxiv_id": "2412.20834v1",
      "title": "Disentangling Preference Representation and Text Generation for Efficient Individual Preference Alignment",
      "title_zh": "分离偏好表示和文本生成以实现高效的个体偏好对齐",
      "authors": [
        "Jianfei Zhang",
        "Jun Bai",
        "Bei Li",
        "Yanmeng Wang",
        "Rumei Li",
        "Chenghua Lin",
        "Wenge Rong"
      ],
      "abstract": "Aligning Large Language Models (LLMs) with general human preferences has been\nproved crucial in improving the interaction quality between LLMs and human.\nHowever, human values are inherently diverse among different individuals,\nmaking it insufficient to align LLMs solely with general preferences. To\naddress this, personalizing LLMs according to individual feedback emerges as a\npromising solution. Nonetheless, this approach presents challenges in terms of\nthe efficiency of alignment algorithms. In this work, we introduce a flexible\nparadigm for individual preference alignment. Our method fundamentally improves\nefficiency by disentangling preference representation from text generation in\nLLMs. We validate our approach across multiple text generation tasks and\ndemonstrate that it can produce aligned quality as well as or better than\nPEFT-based methods, while reducing additional training time for each new\nindividual preference by $80\\%$ to $90\\%$ in comparison with them.",
      "tldr_zh": "这篇论文探讨了如何高效地将大型语言模型 (LLMs) 与个人偏好对齐，以应对人类偏好多样性的挑战。研究提出了一种灵活范式，通过将偏好表示 (preference representation) 与文本生成 (text generation) 分离，显著提高了对齐算法的效率。实验验证显示，该方法在多个文本生成任务上与 PEFT-based 方法相当或更优，同时将每个新个人偏好的额外训练时间减少了 80% 到 90%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Coling 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.20834v1",
      "published_date": "2024-12-30 09:58:31 UTC",
      "updated_date": "2024-12-30 09:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:55:46.874863"
    },
    {
      "arxiv_id": "2412.20822v1",
      "title": "Fine-Tuning TransMorph with Gradient Correlation for Anatomical Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Förner",
        "Kartikay Tehlan",
        "Thomas Wendler"
      ],
      "abstract": "Unsupervised deep learning is a promising method in brain MRI registration to\nreduce the reliance on anatomical labels, while still achieving anatomically\naccurate transformations. For the Learn2Reg2024 LUMIR challenge, we propose\nfine-tuning of the pre-trained TransMorph model to improve the convergence\nstability as well as the deformation smoothness. The former is achieved through\nthe FAdam optimizer, and consistency in structural changes is incorporated\nthrough the addition of gradient correlation in the similarity measure,\nimproving anatomical alignment. The results show slight improvements in the\nDice and HdDist95 scores, and a notable reduction in the NDV compared to the\nbaseline TransMorph model. These are also confirmed by inspecting the\nboundaries of the tissue. Our proposed method highlights the effectiveness of\nincluding Gradient Correlation to achieve smoother and structurally consistent\ndeformations for interpatient brain MRI registration.",
      "tldr_zh": "该论文提出了一种无监督深度学习方法，通过微调预训练的 TransMorph 模型来改善脑MRI注册的收敛稳定性和变形平滑度。方法包括使用 FAdam 优化器增强稳定性，并在相似性度量中添加 Gradient Correlation，以实现更精确的解剖对齐。实验结果显示，与基线模型相比，该方法在 Learn2Reg2024 LUMIR 挑战中略微提高了 Dice 和 HdDist95 分数，并显著降低了 NDV，证明了其在患者间脑MRI注册中的有效性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20822v1",
      "published_date": "2024-12-30 09:32:04 UTC",
      "updated_date": "2024-12-30 09:32:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:55:53.047599"
    },
    {
      "arxiv_id": "2412.20816v1",
      "title": "Length-Aware DETR for Robust Moment Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Seojeong Park",
        "Jiho Choi",
        "Kyungjune Baek",
        "Hyunjung Shim"
      ],
      "abstract": "Video Moment Retrieval (MR) aims to localize moments within a video based on\na given natural language query. Given the prevalent use of platforms like\nYouTube for information retrieval, the demand for MR techniques is\nsignificantly growing. Recent DETR-based models have made notable advances in\nperformance but still struggle with accurately localizing short moments.\nThrough data analysis, we identified limited feature diversity in short\nmoments, which motivated the development of MomentMix. MomentMix employs two\naugmentation strategies: ForegroundMix and BackgroundMix, each enhancing the\nfeature representations of the foreground and background, respectively.\nAdditionally, our analysis of prediction bias revealed that short moments\nparticularly struggle with accurately predicting their center positions of\nmoments. To address this, we propose a Length-Aware Decoder, which conditions\nlength through a novel bipartite matching process. Our extensive studies\ndemonstrate the efficacy of our length-aware approach, especially in localizing\nshort moments, leading to improved overall performance. Our method surpasses\nstate-of-the-art DETR-based methods on benchmark datasets, achieving the\nhighest R1 and mAP on QVHighlights and the highest R1@0.7 on TACoS and\nCharades-STA (such as a 2.46% gain in R1@0.7 and a 2.57% gain in mAP average\nfor QVHighlights). The code is available at\nhttps://github.com/sjpark5800/LA-DETR.",
      "tldr_zh": "这篇论文针对 Video Moment Retrieval (MR) 的挑战，提出了一种改进的 DETR 方法，以提升短时刻的定位准确性。通过数据分析，他们开发了 MomentMix 增强策略，包括 ForegroundMix 和 BackgroundMix，来增强前景和背景特征的多样性；同时，引入了 Length-Aware Decoder，通过新颖的二分匹配过程来考虑时刻长度，从而缓解预测偏差。实验结果表明，该方法在 QVHighlights 数据集上实现了最高的 R1 和 mAP，在 TACoS 和 Charades-STA 上取得了最高的 R1@0.7（如 QVHighlights 的 R1@0.7 提高了 2.46%，mAP 平均提高了 2.57%），整体性能超越了现有最先进模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20816v1",
      "published_date": "2024-12-30 09:11:14 UTC",
      "updated_date": "2024-12-30 09:11:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:54:12.446569"
    },
    {
      "arxiv_id": "2412.20807v1",
      "title": "Two Heads Are Better Than One: Averaging along Fine-Tuning to Improve Targeted Transferability",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Zeng",
        "Sanshuai Cui",
        "Biwei Chen",
        "Anjie Peng"
      ],
      "abstract": "With much longer optimization time than that of untargeted attacks\nnotwithstanding, the transferability of targeted attacks is still far from\nsatisfactory. Recent studies reveal that fine-tuning an existing adversarial\nexample (AE) in feature space can efficiently boost its targeted\ntransferability. However, existing fine-tuning schemes only utilize the\nendpoint and ignore the valuable information in the fine-tuning trajectory.\nNoting that the vanilla fine-tuning trajectory tends to oscillate around the\nperiphery of a flat region of the loss surface, we propose averaging over the\nfine-tuning trajectory to pull the crafted AE towards a more centered region.\nWe compare the proposed method with existing fine-tuning schemes by integrating\nthem with state-of-the-art targeted attacks in various attacking scenarios.\nExperimental results uphold the superiority of the proposed method in boosting\ntargeted transferability. The code is available at github.com/zengh5/Avg_FT.",
      "tldr_zh": "该研究针对对抗攻击(adversarial attacks)中针对性攻击(targeted attacks)的转移性不足问题，提出了一种改进方法，即在特征空间微调(adversarial example, AE)轨迹上进行平均(averaging along fine-tuning)。这种方法利用微调轨迹的震荡特性，将AE拉向损失曲面更平坦的中心区域，从而提升转移性。实验结果显示，该方法与现有微调方案结合后，在多种攻击场景中显著优于基线模型，提高了针对性转移性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures, accepted by 2025ICASSP",
      "pdf_url": "http://arxiv.org/pdf/2412.20807v1",
      "published_date": "2024-12-30 09:01:27 UTC",
      "updated_date": "2024-12-30 09:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:54:23.262250"
    },
    {
      "arxiv_id": "2501.01983v1",
      "title": "ECG-guided individual identification via PPG",
      "title_zh": "翻译失败",
      "authors": [
        "Riling Wei",
        "Hanjie Chen",
        "Kelu Yao",
        "Chuanguang Yang",
        "Jun Wang",
        "Chao Li"
      ],
      "abstract": "Photoplethsmography (PPG)-based individual identification aiming at\nrecognizing humans via intrinsic cardiovascular activities has raised extensive\nattention due to its high security and resistance to mimicry. However, this\nkind of technology witnesses unpromising results due to the limitation of low\ninformation density. To this end, electrocardiogram (ECG) signals have been\nintroduced as a novel modality to enhance the density of input information.\nSpecifically, a novel cross-modal knowledge distillation framework is\nimplemented to propagate discriminate knowledge from ECG modality to PPG\nmodality without incurring additional computational demands at the inference\nphase. Furthermore, to ensure efficient knowledge propagation, Contrastive\nLanguage-Image Pre-training (CLIP)-based knowledge alignment and\ncross-knowledge assessment modules are proposed respectively. Comprehensive\nexperiments are conducted and results show our framework outperforms the\nbaseline model with the improvement of 2.8% and 3.0% in terms of overall\naccuracy on seen- and unseen individual recognitions.",
      "tldr_zh": "该研究针对 PPG 基于的个体识别技术信息密度低导致识别效果不佳的问题，引入 ECG 信号作为新模态来增强输入信息。\n他们提出一个跨模态知识蒸馏框架，通过 CLIP-based 知识对齐和跨知识评估模块，从 ECG 模态向 PPG 模态传播判别知识，并在推理阶段不增加计算开销。\n实验结果显示，该框架在可见和不可见个体识别上，比基线模型的整体准确率分别提高了 2.8% 和 3.0%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICASSP 2025. Camera Ready Version",
      "pdf_url": "http://arxiv.org/pdf/2501.01983v1",
      "published_date": "2024-12-30 08:56:23 UTC",
      "updated_date": "2024-12-30 08:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:54:35.820977"
    },
    {
      "arxiv_id": "2412.20798v3",
      "title": "A Tale of Two Imperatives: Privacy and Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Supriya Manna",
        "Niladri Sett"
      ],
      "abstract": "Deep learning's preponderance across scientific domains has reshaped\nhigh-stakes decision-making, making it essential to follow rigorous operational\nframeworks that include both Right-to-Privacy (RTP) and Right-to-Explanation\n(RTE). This paper examines the complexities of combining these two\nrequirements. For RTP, we focus on `Differential privacy' (DP), which is\nconsidered the current \\textit{gold standard} for privacy-preserving machine\nlearning due to its strong quantitative guarantee of privacy. For RTE, we focus\non post-hoc explainers: they are the \\textit{go-to} option for model auditing\nas they operate independently of model training. We formally investigate DP\nmodels and various commonly-used post-hoc explainers: how to evaluate these\nexplainers subject to RTP, and analyze the intrinsic interactions between DP\nmodels and these explainers. Furthermore, our work throws light on how RTP and\nRTE can be effectively combined in high-stakes applications. Our study\nconcludes by outlining an industrial software pipeline, with the example of a\nwildly used use-case, that respects both RTP and RTE requirements.",
      "tldr_zh": "本论文探讨了在深度学习应用中，Right-to-Privacy (RTP) 和 Right-to-Explanation (RTE) 的整合挑战，强调了这两者在高风险决策中的重要性。作者聚焦于 Differential Privacy (DP) 作为 RTP 的黄金标准，以及 post-hoc explainers 作为 RTE 的常用工具，通过正式评估分析了 DP 模型与这些 explainers 的互动和兼容性。研究结果揭示了如何在实际高风险场景中有效结合 RTP 和 RTE，并提供了一个工业软件管道的示例，以支持隐私保护和模型可解释性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "12 figures, Work Under Review",
      "pdf_url": "http://arxiv.org/pdf/2412.20798v3",
      "published_date": "2024-12-30 08:43:28 UTC",
      "updated_date": "2025-02-22 23:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:54:47.268719"
    },
    {
      "arxiv_id": "2412.20790v2",
      "title": "Frequency-Masked Embedding Inference: A Non-Contrastive Approach for Time Series Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "En Fu",
        "Yanyan Hu"
      ],
      "abstract": "Contrastive learning underpins most current self-supervised time series\nrepresentation methods. The strategy for constructing positive and negative\nsample pairs significantly affects the final representation quality. However,\ndue to the continuous nature of time series semantics, the modeling approach of\ncontrastive learning struggles to accommodate the characteristics of time\nseries data. This results in issues such as difficulties in constructing hard\nnegative samples and the potential introduction of inappropriate biases during\npositive sample construction. Although some recent works have developed several\nscientific strategies for constructing positive and negative sample pairs with\nimproved effectiveness, they remain constrained by the contrastive learning\nframework. To fundamentally overcome the limitations of contrastive learning,\nthis paper introduces Frequency-masked Embedding Inference (FEI), a novel\nnon-contrastive method that completely eliminates the need for positive and\nnegative samples. The proposed FEI constructs 2 inference branches based on a\nprompting strategy: 1) Using frequency masking as prompts to infer the\nembedding representation of the target series with missing frequency bands in\nthe embedding space, and 2) Using the target series as prompts to infer its\nfrequency masking embedding. In this way, FEI enables continuous semantic\nrelationship modeling for time series. Experiments on 8 widely used time series\ndatasets for classification and regression tasks, using linear evaluation and\nend-to-end fine-tuning, show that FEI significantly outperforms existing\ncontrastive-based methods in terms of generalization. This study provides new\ninsights into self-supervised representation learning for time series. The code\nis available at\nhttps://github.com/USTBInnovationPark/Frequency-masked-Embedding-Inference.",
      "tldr_zh": "本论文提出了一种非对比学习方法 Frequency-masked Embedding Inference (FEI)，旨在解决传统对比学习在时间序列表示学习中存在的构建正负样本困难和引入偏差等问题。FEI 通过构建两个推理分支——使用频率掩码作为提示推断目标序列的嵌入表示，以及使用目标序列推断其频率掩码嵌入——来实现时间序列的连续语义关系建模，而无需依赖正负样本。在 8 个常用时间序列数据集上的分类和回归任务实验中，FEI 在线性评估和端到端微调方面显著优于现有对比学习方法，展示了更好的泛化性能，并为自监督时间序列学习提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by AAAI-2025 main track",
      "pdf_url": "http://arxiv.org/pdf/2412.20790v2",
      "published_date": "2024-12-30 08:12:17 UTC",
      "updated_date": "2025-01-06 12:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:55:00.477086"
    },
    {
      "arxiv_id": "2412.20787v3",
      "title": "SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Jing",
        "Mengyun Tang",
        "Xiaorong Shi",
        "Xing Zheng",
        "Sen Nie",
        "Shi Wu",
        "Yong Yang",
        "Xiapu Luo"
      ],
      "abstract": "Evaluating Large Language Models (LLMs) is crucial for understanding their\ncapabilities and limitations across various applications, including natural\nlanguage processing and code generation. Existing benchmarks like MMLU, C-Eval,\nand HumanEval assess general LLM performance but lack focus on specific expert\ndomains such as cybersecurity. Previous attempts to create cybersecurity\ndatasets have faced limitations, including insufficient data volume and a\nreliance on multiple-choice questions (MCQs). To address these gaps, we propose\nSecBench, a multi-dimensional benchmarking dataset designed to evaluate LLMs in\nthe cybersecurity domain. SecBench includes questions in various formats (MCQs\nand short-answer questions (SAQs)), at different capability levels (Knowledge\nRetention and Logical Reasoning), in multiple languages (Chinese and English),\nand across various sub-domains. The dataset was constructed by collecting\nhigh-quality data from open sources and organizing a Cybersecurity Question\nDesign Contest, resulting in 44,823 MCQs and 3,087 SAQs. Particularly, we used\nthe powerful while cost-effective LLMs to (1). label the data and (2).\nconstructing a grading agent for automatic evaluation of SAQs. Benchmarking\nresults on 16 SOTA LLMs demonstrate the usability of SecBench, which is\narguably the largest and most comprehensive benchmark dataset for LLMs in\ncybersecurity. More information about SecBench can be found at our website, and\nthe dataset can be accessed via the artifact link.",
      "tldr_zh": "该研究提出SecBench，一种全面的多维度基准数据集，用于评估LLMs在网络安全领域的性能，旨在弥补现有基准如MMLU、C-Eval和HumanEval等在专业领域覆盖不足的问题。SecBench包括多种问题格式（MCQs和SAQs）、不同能力水平（Knowledge Retention和Logical Reasoning）、多语言（中文和英文）以及多个子领域，总计44,823个MCQs和3,087个SAQs，通过从公开来源收集数据并组织Cybersecurity Question Design Contest构建而成。研究利用强大的LLMs进行数据标记和自动评估SAQs的评分代理，并在16个SOTA LLMs上进行基准测试，结果显示SecBench是目前最大且最全面的网络安全LLM基准数据集。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20787v3",
      "published_date": "2024-12-30 08:11:54 UTC",
      "updated_date": "2025-01-06 07:22:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:55:11.958882"
    },
    {
      "arxiv_id": "2502.15692v1",
      "title": "ACL-rlg: A Dataset for Reading List Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Julien Aubert-Béduchaud",
        "Florian Boudin",
        "Béatrice Daille",
        "Richard Dufour"
      ],
      "abstract": "Familiarizing oneself with a new scientific field and its existing literature\ncan be daunting due to the large amount of available articles. Curated lists of\nacademic references, or reading lists, compiled by experts, offer a structured\nway to gain a comprehensive overview of a domain or a specific scientific\nchallenge. In this work, we introduce ACL-rlg, the largest open\nexpert-annotated reading list dataset. We also provide multiple baselines for\nevaluating reading list generation and formally define it as a retrieval task.\nOur qualitative study highlights the fact that traditional scholarly search\nengines and indexing methods perform poorly on this task, and GPT-4o, despite\nshowing better results, exhibits signs of potential data contamination.",
      "tldr_zh": "该论文引入了 ACL-rlg，这是一个最大的开源专家标注的阅读列表数据集，用于帮助用户通过结构化的学术参考列表快速了解新科学领域或特定挑战。作者将阅读列表生成任务正式定义为一个检索任务，并提供了多个基线模型来进行评估。研究结果显示，传统的学术搜索引擎和索引方法在该任务上表现不佳，而 GPT-4o 虽然取得了更好的结果，但可能存在数据污染问题，从而为未来改进提供了重要启示。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15692v1",
      "published_date": "2024-12-30 07:48:32 UTC",
      "updated_date": "2024-12-30 07:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:56:03.372948"
    },
    {
      "arxiv_id": "2412.20768v1",
      "title": "Sample Correlation for Fingerprinting Deep Face Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyang Guan",
        "Jian Liang",
        "Yanbo Wang",
        "Ran He"
      ],
      "abstract": "Face recognition has witnessed remarkable advancements in recent years,\nthanks to the development of deep learning techniques.However, an off-the-shelf\nface recognition model as a commercial service could be stolen by model\nstealing attacks, posing great threats to the rights of the model owner.Model\nfingerprinting, as a model stealing detection method, aims to verify whether a\nsuspect model is stolen from the victim model, gaining more and more attention\nnowadays.Previous methods always utilize transferable adversarial examples as\nthe model fingerprint, but this method is known to be sensitive to adversarial\ndefense and transfer learning techniques.To address this issue, we consider the\npairwise relationship between samples instead and propose a novel yet simple\nmodel stealing detection method based on SAmple Correlation (SAC).Specifically,\nwe present SAC-JC that selects JPEG compressed samples as model inputs and\ncalculates the correlation matrix among their model outputs.Extensive results\nvalidate that SAC successfully defends against various model stealing attacks\nin deep face recognition, encompassing face verification and face emotion\nrecognition, exhibiting the highest performance in terms of AUC, p-value and F1\nscore.Furthermore, we extend our evaluation of SAC-JC to object recognition\ndatasets including Tiny-ImageNet and CIFAR10, which also demonstrates the\nsuperior performance of SAC-JC to previous methods.The code will be available\nat \\url{https://github.com/guanjiyang/SAC_JC}.",
      "tldr_zh": "本文提出了一种基于样本相关性（Sample Correlation, SAC）的模型窃取检测方法，针对深度人脸识别模型面临的窃取攻击风险。不同于传统使用可转移对抗样本的方法，SAC-JC 通过选择 JPEG 压缩样本作为输入，并计算其输出相关性矩阵，来提升检测鲁棒性。实验结果显示，SAC 在人脸验证和人脸情绪识别任务中防卫各种攻击，表现出最高性能（AUC、p-value 和 F1 score），并在物体识别数据集如 Tiny-ImageNet 和 CIFAR10 上同样优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20768v1",
      "published_date": "2024-12-30 07:37:06 UTC",
      "updated_date": "2024-12-30 07:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:56:16.270620"
    },
    {
      "arxiv_id": "2412.20767v1",
      "title": "KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image Sequences",
      "title_zh": "KeyGS: 一种以关键帧为中心的高斯喷溅方法，用于单目图像序列",
      "authors": [
        "Keng-Wei Chang",
        "Zi-Ming Wang",
        "Shang-Hong Lai"
      ],
      "abstract": "Reconstructing high-quality 3D models from sparse 2D images has garnered\nsignificant attention in computer vision. Recently, 3D Gaussian Splatting\n(3DGS) has gained prominence due to its explicit representation with efficient\ntraining speed and real-time rendering capabilities. However, existing methods\nstill heavily depend on accurate camera poses for reconstruction. Although some\nrecent approaches attempt to train 3DGS models without the\nStructure-from-Motion (SfM) preprocessing from monocular video datasets, these\nmethods suffer from prolonged training times, making them impractical for many\napplications.\n  In this paper, we present an efficient framework that operates without any\ndepth or matching model. Our approach initially uses SfM to quickly obtain\nrough camera poses within seconds, and then refines these poses by leveraging\nthe dense representation in 3DGS. This framework effectively addresses the\nissue of long training times. Additionally, we integrate the densification\nprocess with joint refinement and propose a coarse-to-fine frequency-aware\ndensification to reconstruct different levels of details. This approach\nprevents camera pose estimation from being trapped in local minima or drifting\ndue to high-frequency signals. Our method significantly reduces training time\nfrom hours to minutes while achieving more accurate novel view synthesis and\ncamera pose estimation compared to previous methods.",
      "tldr_zh": "本研究提出KeyGS，一种以关键帧为中心的3D Gaussian Splatting (3DGS)方法，用于从单目图像序列重建高质量3D模型。该框架首先利用Structure-from-Motion (SfM)快速获取粗略相机位姿，然后通过3DGS的密集表示进行位姿精炼，并引入粗到细的频率感知densification过程，以避免高频信号导致的局部最小或漂移问题。相比现有方法，KeyGS显著缩短训练时间从小时级到分钟级，同时在新型视图合成和相机位姿估计上实现更高准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.20767v1",
      "published_date": "2024-12-30 07:32:35 UTC",
      "updated_date": "2024-12-30 07:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:56:28.032066"
    },
    {
      "arxiv_id": "2501.00076v1",
      "title": "A Novel Framework for Learning Stochastic Representations for Sequence Generation and Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jungsik Hwang",
        "Ahmadreza Ahmadi"
      ],
      "abstract": "The ability to generate and recognize sequential data is fundamental for\nautonomous systems operating in dynamic environments. Inspired by the key\nprinciples of the brain-predictive coding and the Bayesian brain-we propose a\nnovel stochastic Recurrent Neural Network with Parametric Biases (RNNPB). The\nproposed model incorporates stochasticity into the latent space using the\nreparameterization trick used in variational autoencoders. This approach\nenables the model to learn probabilistic representations of multidimensional\nsequences, capturing uncertainty and enhancing robustness against overfitting.\nWe tested the proposed model on a robotic motion dataset to assess its\nperformance in generating and recognizing temporal patterns. The experimental\nresults showed that the stochastic RNNPB model outperformed its deterministic\ncounterpart in generating and recognizing motion sequences. The results\nhighlighted the proposed model's capability to quantify and adjust uncertainty\nduring both learning and inference. The stochasticity resulted in a continuous\nlatent space representation, facilitating stable motion generation and enhanced\ngeneralization when recognizing novel sequences. Our approach provides a\nbiologically inspired framework for modeling temporal patterns and advances the\ndevelopment of robust and adaptable systems in artificial intelligence and\nrobotics.",
      "tldr_zh": "本研究提出了一种新型随机循环神经网络（RNNPB），受大脑预测编码和贝叶斯大脑原理启发，通过重参数化技巧将随机性融入潜在空间，从而学习多维序列的概率表示，捕捉不确定性和提升对过拟合的鲁棒性。在机器人运动数据集上的实验表明，RNNPB 模型在生成和识别时间模式方面优于确定性模型，能够量化调整不确定性，提供连续的潜在空间表示，并增强泛化能力。该框架为人工智能和机器人领域建模时间模式提供了生物启发的解决方案，推进了鲁棒适应性系统的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.00076v1",
      "published_date": "2024-12-30 07:27:50 UTC",
      "updated_date": "2024-12-30 07:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:56:58.161140"
    },
    {
      "arxiv_id": "2412.20760v2",
      "title": "Attributing Culture-Conditioned Generations to Pretraining Corpora",
      "title_zh": "翻译失败",
      "authors": [
        "Huihan Li",
        "Arnav Goel",
        "Keyu He",
        "Xiang Ren"
      ],
      "abstract": "In open-ended generative tasks like narrative writing or dialogue, large\nlanguage models often exhibit cultural biases, showing limited knowledge and\ngenerating templated outputs for less prevalent cultures. Recent works show\nthat these biases may stem from uneven cultural representation in pretraining\ncorpora. This work investigates how pretraining leads to biased\nculture-conditioned generations by analyzing how models associate entities with\ncultures based on pretraining data patterns. We propose the MEMOed framework\n(MEMOrization from pretraining document) to determine whether a generation for\na culture arises from memorization. Using MEMOed on culture-conditioned\ngenerations about food and clothing for 110 cultures, we find that\nhigh-frequency cultures in pretraining data yield more generations with\nmemorized symbols, while some low-frequency cultures produce none.\nAdditionally, the model favors generating entities with extraordinarily high\nfrequency regardless of the conditioned culture, reflecting biases toward\nfrequent pretraining terms irrespective of relevance. We hope that the MEMOed\nframework and our insights will inspire more works on attributing model\nperformance on pretraining data.",
      "tldr_zh": "这篇论文探讨了大型语言模型在生成任务（如叙述写作或对话）中的文化偏差问题，这些偏差源于预训练语料中文化的不均衡表示，导致模型对高频文化生成更多记忆化符号，而对低频文化输出有限或模板化。作者提出MEMOed框架（MEMOrization from pretraining document），通过分析模型如何基于预训练数据模式将实体与文化关联，来判断生成的输出是否源于记忆。实验结果显示，在对110种文化的食物和服装生成分析中，高频文化产生更多记忆化内容，且模型倾向于生成与条件文化无关的高频实体；该框架和见解旨在促进更多研究，将模型性能归因于pretraining corpora。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20760v2",
      "published_date": "2024-12-30 07:09:25 UTC",
      "updated_date": "2025-03-19 19:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:58:29.001076"
    },
    {
      "arxiv_id": "2502.17442v1",
      "title": "Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement",
      "title_zh": "思考在前！通过彻底探索和最优优化实现高效代码生成",
      "authors": [
        "Xiaoqing Zhang",
        "Yuhan Liu",
        "Flood Sung",
        "Xiuying Chen",
        "Rui Yan"
      ],
      "abstract": "Code generation is crucial in software engineering for automating the coding\nprocess efficiently. While test-time computation methods show promise, they\nsuffer from high latency due to multiple computation rounds. To overcome this,\nwe introduce ThinkCoder, a framework that combines thorough exploration with\noptimal refinement. The exploration phase diversifies the solution space by\nsearching for potential solutions, followed by a refinement phase that enhances\nprecision. This approach allows us to select the best solution through careful\nconsideration before taking action, avoiding excessive trial and error. To\nfurther minimize test-time computation overhead, we introduce preference-driven\noptimization with Reinforced Self-Training (ReST), which uses exploration\ntrajectories from ThinkCoder to guide LLM's evolution. By learning preferences,\nthis approach improves LLM's exploration efficiency, reducing computational\ncosts while maintaining accuracy. ThinkCoder boosts the performance of multiple\nbase LLMs, excelling on benchmarks like HumanEval and MBPP. Compared to SOTA\nmodels, it improves Pass@1 by 1.5\\% over MapCoder with just 21.7\\% of the\ncomputation cost. Against AgentCoder, ThinkCoder achieves a 0.6\\% higher Pass@1\nafter 2 rounds, outperforming AgentCoder's 5 rounds. Additionally, ReST with\nsuccess trajectories enhances efficiency, allowing models like LLaMA2-7B to\nachieve competitive results using only 20\\% of the computational resources.\nThese results highlight the framework's effectiveness and scalability.",
      "tldr_zh": "该论文提出ThinkCoder框架，通过彻底探索(thorough exploration)和最优精炼(optimal refinement)来提升代码生成的效率，避免了传统测试时计算方法的多轮高延迟问题。框架首先在探索阶段搜索多样化解决方案，然后在精炼阶段优化精度，并引入基于强化自训练(Reinforced Self-Training, ReST)的方法，利用探索轨迹指导LLM的演化，从而减少计算开销。实验结果显示，ThinkCoder在HumanEval和MBPP基准上显著提升性能，与SOTA模型相比，提高Pass@1指标1.5%，仅需21.7%的计算成本，并能在更少轮次内超越AgentCoder。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "14 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.17442v1",
      "published_date": "2024-12-30 07:02:15 UTC",
      "updated_date": "2024-12-30 07:02:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:57:04.380508"
    },
    {
      "arxiv_id": "2412.20749v1",
      "title": "Solar Filaments Detection using Active Contours Without Edges",
      "title_zh": "翻译失败",
      "authors": [
        "Sanmoy Bandyopadhyay",
        "Vaibhav Pant"
      ],
      "abstract": "In this article, an active contours without edges (ACWE)-based algorithm has\nbeen proposed for the detection of solar filaments in H-alpha full-disk solar\nimages. The overall algorithm consists of three main steps of image processing.\nThese are image pre-processing, image segmentation, and image post-processing.\nHere in the work, contours are initialized on the solar image and allowed to\ndeform based on the energy function. As soon as the contour reaches the\nboundary of the desired object, the energy function gets reduced, and the\ncontour stops evolving. The proposed algorithm has been applied to few\nbenchmark datasets and has been compared with the classical technique of object\ndetection. The results analysis indicates that the proposed algorithm\noutperforms the results obtained using the existing classical algorithm of\nobject detection.",
      "tldr_zh": "这篇论文提出了一种基于 Active Contours Without Edges (ACWE) 的算法，用于检测 H-alpha 全盘太阳图像中的太阳丝。算法主要包括图像预处理、图像分割和图像后处理三个步骤，其中轮廓在图像上初始化并根据能量函数变形，直至到达目标边界。实验结果表明，该算法在多个基准数据集上表现优于传统的对象检测技术，提供更高的检测准确率。",
      "categories": [
        "cs.CV",
        "astro-ph.IM",
        "astro-ph.SR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.20749v1",
      "published_date": "2024-12-30 06:43:22 UTC",
      "updated_date": "2024-12-30 06:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:57:15.718919"
    },
    {
      "arxiv_id": "2412.20744v1",
      "title": "Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Roy",
        "Bhavesh Gyanchandani",
        "Aditya Oza",
        "Abhishek Sharma"
      ],
      "abstract": "Parkinson's Disease (PD) is a degenerative neurological disorder that impairs\nmotor and non-motor functions, significantly reducing quality of life and\nincreasing mortality risk. Early and accurate detection of PD progression is\nvital for effective management and improved patient outcomes. Current\ndiagnostic methods, however, are often costly, time-consuming, and require\nspecialized equipment and expertise. This work proposes an innovative approach\nto predicting PD progression using regression methods, Long Short-Term Memory\n(LSTM) networks, and Kolmogorov Arnold Networks (KAN). KAN, utilizing\nspline-parametrized univariate functions, allows for dynamic learning of\nactivation patterns, unlike traditional linear models.\n  The Movement Disorder Society-Sponsored Revision of the Unified Parkinson's\nDisease Rating Scale (MDS-UPDRS) is a comprehensive tool for evaluating PD\nsymptoms and is commonly used to measure disease progression. Additionally,\nprotein or peptide abnormalities are linked to PD onset and progression.\nIdentifying these associations can aid in predicting disease progression and\nunderstanding molecular changes.\n  Comparing multiple models, including LSTM and KAN, this study aims to\nidentify the method that delivers the highest metrics. The analysis reveals\nthat KAN, with its dynamic learning capabilities, outperforms other approaches\nin predicting PD progression. This research highlights the potential of AI and\nmachine learning in healthcare, paving the way for advanced computational\nmodels to enhance clinical predictions and improve patient care and treatment\nstrategies in PD management.",
      "tldr_zh": "本研究针对帕金森病 (PD) 的进展预测问题，比较了 Long Short-Term Memory (LSTM) 网络和 Kolmogorov-Arnold Networks (KAN)，旨在提供更准确的早期检测方法，以改善患者管理。研究利用 MDS-UPDRS 评估工具和蛋白质异常数据，评估多种回归模型，其中 KAN 通过样条参数化的动态学习激活模式表现出色。结果显示，KAN 在预测 PD 进展方面比其他方法提升了关键指标，为 AI 在医疗领域的应用提供了新路径，提升了临床预测和治疗策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20744v1",
      "published_date": "2024-12-30 06:36:05 UTC",
      "updated_date": "2024-12-30 06:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:57:27.629948"
    },
    {
      "arxiv_id": "2412.20735v3",
      "title": "HunyuanProver: A Scalable Data Synthesis Framework and Guided Tree Search for Automated Theorem Proving",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li",
        "Dong Du",
        "Linfeng Song",
        "Chen Li",
        "Weikang Wang",
        "Tao Yang",
        "Haitao Mi"
      ],
      "abstract": "We introduce HunyuanProver, an language model finetuned from the Hunyuan 7B\nfor interactive automatic theorem proving with LEAN4. To alleviate the data\nsparsity issue, we design a scalable framework to iterative synthesize data\nwith low cost. Besides, guided tree search algorithms are designed to enable\neffective ``system 2 thinking`` of the prover. HunyuanProver achieves\nstate-of-the-art (SOTA) performances on major benchmarks. Specifically, it\nachieves a pass of 68.4% on the miniF2F-test compared to 65.9%, the current\nSOTA results. It proves 4 IMO statements (imo_1960_p2, imo_1962_p2},\nimo_1964_p2 and imo_1983_p6) in miniF2F-test. To benefit the community, we will\nopen-source a dataset of 30k synthesized instances, where each instance\ncontains the original question in natural language, the converted statement by\nautoformalization, and the proof by HunyuanProver.",
      "tldr_zh": "该研究推出了 HunyuanProver，一种从 Hunyuan 7B 微调的语言模型，用于 LEAN4 的交互式自动定理证明，以解决数据稀疏问题。HunyuanProver 采用可扩展的数据合成框架进行低成本迭代数据生成，并设计引导树搜索算法来实现有效的“系统 2 思考”。在主要基准测试中，它实现了 SOTA 性能，包括 miniF2F-test 的 68.4% 通过率，并成功证明了 4 个 IMO 陈述（如 imo_1960_p2）。为惠及社区，该团队将开源一个包含 30k 合成实例的数据集，包括自然语言问题、自动形式化陈述和证明。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20735v3",
      "published_date": "2024-12-30 06:18:33 UTC",
      "updated_date": "2025-03-21 02:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:57:42.539188"
    },
    {
      "arxiv_id": "2412.20733v1",
      "title": "Towards nation-wide analytical healthcare infrastructures: A privacy-preserving augmented knee rehabilitation case study",
      "title_zh": "翻译失败",
      "authors": [
        "Boris Bačić",
        "Claudiu Vasile",
        "Chengwei Feng",
        "Marian G. Ciucă"
      ],
      "abstract": "The purpose of this paper is to contribute towards the near-future\nprivacy-preserving big data analytical healthcare platforms, capable of\nprocessing streamed or uploaded timeseries data or videos from patients. The\nexperimental work includes a real-life knee rehabilitation video dataset\ncapturing a set of exercises from simple and personalised to more general and\nchallenging movements aimed for returning to sport. To convert video from\nmobile into privacy-preserving diagnostic timeseries data, we employed Google\nMediaPipe pose estimation. The developed proof-of-concept algorithms can\naugment knee exercise videos by overlaying the patient with stick figure\nelements while updating generated timeseries plot with knee angle estimation\nstreamed as CSV file format. For patients and physiotherapists, video with\nside-to-side timeseries visually indicating potential issues such as excessive\nknee flexion or unstable knee movements or stick figure overlay errors is\npossible by setting a-priori knee-angle parameters. To address adherence to\nrehabilitation programme and quantify exercise sets and repetitions, our\nadaptive algorithm can correctly identify (91.67%-100%) of all exercises from\nside- and front-view videos. Transparent algorithm design for adaptive visual\nanalysis of various knee exercise patterns contributes towards the\ninterpretable AI and will inform near-future privacy-preserving, non-vendor\nlocking, open-source developments for both end-user computing devices and as\non-premises non-proprietary cloud platforms that can be deployed within the\nnational healthcare system.",
      "tldr_zh": "这篇论文旨在构建全国性的隐私保护医疗分析基础设施，通过一个膝盖康复案例研究处理患者视频和时序数据。研究使用 Google MediaPipe 姿势估计将视频转换为诊断时序数据，并开发算法在视频上叠加棒图元素，提供实时反馈如膝盖角度异常。实验结果显示，该算法能准确识别（91.67%-100%）的膝盖练习次数和重复，支持可解释 AI 的透明设计，并推动开源、非专有平台的开发应用于国家医疗系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "The original work citation: Ba\\v{c}i\\'c, B., Claudiu Vasile, Feng,\n  C., & Ciuc\\u{a}, M. G. (2024, 13-15 Dec.). Towards nation-wide analytical\n  healthcare infrastructures: A privacy-preserving augmented knee\n  rehabilitation case study. Presented at the Conference on Innovative\n  Technologies in Intelligent Systems & Industrial Applications (CITISIA 2024),\n  Sydney, NSW",
      "pdf_url": "http://arxiv.org/pdf/2412.20733v1",
      "published_date": "2024-12-30 06:14:48 UTC",
      "updated_date": "2024-12-30 06:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:57:53.902131"
    },
    {
      "arxiv_id": "2501.01449v1",
      "title": "LS-GAN: Human Motion Synthesis with Latent-space GANs",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Amballa",
        "Gayathri Akkinapalli",
        "Vinitra Muralikrishnan"
      ],
      "abstract": "Human motion synthesis conditioned on textual input has gained significant\nattention in recent years due to its potential applications in various domains\nsuch as gaming, film production, and virtual reality. Conditioned Motion\nsynthesis takes a text input and outputs a 3D motion corresponding to the text.\nWhile previous works have explored motion synthesis using raw motion data and\nlatent space representations with diffusion models, these approaches often\nsuffer from high training and inference times. In this paper, we introduce a\nnovel framework that utilizes Generative Adversarial Networks (GANs) in the\nlatent space to enable faster training and inference while achieving results\ncomparable to those of the state-of-the-art diffusion methods. We perform\nexperiments on the HumanML3D, HumanAct12 benchmarks and demonstrate that a\nremarkably simple GAN in the latent space achieves a FID of 0.482 with more\nthan 91% in FLOPs reduction compared to latent diffusion model. Our work opens\nup new possibilities for efficient and high-quality motion synthesis using\nlatent space GANs.",
      "tldr_zh": "本论文提出LS-GAN框架，利用潜在空间中的Generative Adversarial Networks (GANs)进行基于文本输入的人类动作合成，旨在解决现有扩散模型的训练和推理时间过长问题。该方法通过在潜在空间中生成动作序列，实现与最先进扩散方法相当的合成质量，同时显著提升效率。在HumanML3D和HumanAct12基准测试中，LS-GAN仅用简单架构就达到FID 0.482，并将FLOPs减少91%。这项工作为游戏、电影制作和虚拟现实等领域的高效动作合成打开了新可能性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.01449v1",
      "published_date": "2024-12-30 05:44:38 UTC",
      "updated_date": "2024-12-30 05:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:58:40.599225"
    },
    {
      "arxiv_id": "2412.20718v1",
      "title": "M$^3$oralBench: A MultiModal Moral Benchmark for LVLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Bei Yan",
        "Jie Zhang",
        "Zhiyuan Chen",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "abstract": "Recently, large foundation models, including large language models (LLMs) and\nlarge vision-language models (LVLMs), have become essential tools in critical\nfields such as law, finance, and healthcare. As these models increasingly\nintegrate into our daily life, it is necessary to conduct moral evaluation to\nensure that their outputs align with human values and remain within moral\nboundaries. Previous works primarily focus on LLMs, proposing moral datasets\nand benchmarks limited to text modality. However, given the rapid development\nof LVLMs, there is still a lack of multimodal moral evaluation methods. To\nbridge this gap, we introduce M$^3$oralBench, the first MultiModal Moral\nBenchmark for LVLMs. M$^3$oralBench expands the everyday moral scenarios in\nMoral Foundations Vignettes (MFVs) and employs the text-to-image diffusion\nmodel, SD3.0, to create corresponding scenario images. It conducts moral\nevaluation across six moral foundations of Moral Foundations Theory (MFT) and\nencompasses tasks in moral judgement, moral classification, and moral response,\nproviding a comprehensive assessment of model performance in multimodal moral\nunderstanding and reasoning. Extensive experiments on 10 popular open-source\nand closed-source LVLMs demonstrate that M$^3$oralBench is a challenging\nbenchmark, exposing notable moral limitations in current models. Our benchmark\nis publicly available.",
      "tldr_zh": "该研究引入了 M$^3$oralBench，这是第一个针对大型视觉语言模型 (LVLMs) 的多模态道德基准，用于评估模型输出是否符合人类价值观。基准基于 Moral Foundations Vignettes (MFVs) 扩展日常道德场景，并利用 SD3.0 文本到图像扩散模型生成对应图像，涵盖 Moral Foundations Theory (MFT) 的六大道德基础，包括道德判断、分类和响应任务。实验在 10 个流行开源和闭源 LVLMs 上进行，揭示了这些模型的显著道德局限性，并证明了该基准的挑战性和实用价值，已公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20718v1",
      "published_date": "2024-12-30 05:18:55 UTC",
      "updated_date": "2024-12-30 05:18:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:58:54.468677"
    },
    {
      "arxiv_id": "2412.20694v4",
      "title": "QUBE: Enhancing Automatic Heuristic Design via Quality-Uncertainty Balanced Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Chen",
        "Zhanchao Zhou",
        "Yu Lu",
        "Renjun Xu",
        "Lili Pan",
        "Zhenzhong Lan"
      ],
      "abstract": "Solving NP-hard problems traditionally relies on heuristics, yet manually\ndesigning effective heuristics for complex problems remains a significant\nchallenge. While recent advancements like FunSearch have shown that large\nlanguage models (LLMs) can be integrated into evolutionary algorithms (EAs) for\nheuristic design, their potential is hindered by limitations in balancing\nexploitation and exploration. We introduce Quality-Uncertainty Balanced\nEvolution (QUBE), a novel approach that enhances LLM+EA methods by redefining\nthe priority criterion within the FunSearch framework. QUBE employs the\nQuality-Uncertainty Trade-off Criterion (QUTC), based on our proposed\nUncertainty-Inclusive Quality metric, to evaluate and guide the evolutionary\nprocess. Through extensive experiments on challenging NP-complete problems,\nQUBE demonstrates significant performance improvements over FunSearch and\nbaseline methods. Our code are available at\nhttps://github.com/zzjchen/QUBE_code.",
      "tldr_zh": "本论文提出QUBE，一种通过平衡质量和不确定性的进化方法，旨在提升自动启发式设计的效率，解决NP-hard问题中手动设计启发式算法的挑战。QUBE在FunSearch框架基础上，重新定义优先级标准，使用Quality-Uncertainty Trade-off Criterion (QUTC)和Uncertainty-Inclusive Quality metric来评估并引导LLMs与EAs的进化过程，从而更好地平衡开发和探索。实验结果显示，QUBE在各种NP-complete问题上比FunSearch和基线方法显著提升性能，并提供开源代码以供进一步验证。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20694v4",
      "published_date": "2024-12-30 04:05:22 UTC",
      "updated_date": "2025-02-21 03:28:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:59:04.564199"
    },
    {
      "arxiv_id": "2501.10396v1",
      "title": "AI-Powered Urban Transportation Digital Twin: Methods and Applications",
      "title_zh": "AI驱动的城市交通数字孪生：方法与应用",
      "authors": [
        "Xuan Di",
        "Yongjie Fu",
        "Mehmet K. Turkcan",
        "Mahshid Ghasemi",
        "Zhaobin Mo",
        "Chengbo Zang",
        "Abhishek Adhikari",
        "Zoran Kostic",
        "Gil Zussman"
      ],
      "abstract": "We present a survey paper on methods and applications of digital twins (DT)\nfor urban traffic management. While the majority of studies on the DT focus on\nits \"eyes,\" which is the emerging sensing and perception like object detection\nand tracking, what really distinguishes the DT from a traditional simulator\nlies in its ``brain,\" the prediction and decision making capabilities of\nextracting patterns and making informed decisions from what has been seen and\nperceived. In order to add values to urban transportation management, DTs need\nto be powered by artificial intelligence and complement with low-latency\nhigh-bandwidth sensing and networking technologies. We will first review the DT\npipeline leveraging cyberphysical systems and propose our DT architecture\ndeployed on a real-world testbed in New York City. This survey paper can be a\npointer to help researchers and practitioners identify challenges and\nopportunities for the development of DTs; a bridge to initiate conversations\nacross disciplines; and a road map to exploiting potentials of DTs for diverse\nurban transportation applications.",
      "tldr_zh": "这篇调查论文探讨了人工智能(AI)驱动的城市交通数字孪生(DT)的方法和应用，强调DT的“大脑”——即预测和决策能力——在提取模式和做出决策方面的关键作用，以区别于传统模拟器。论文回顾了基于网络物理系统(cyberphysical systems)的DT管道，并提出了一种部署在纽约市真实测试床上的DT架构，结合低延迟高带宽的感知和网络技术，以提升城市交通管理价值。该研究旨在帮助研究者和从业者识别DT领域的挑战和机会，促进跨学科对话，并为多样化的城市交通应用提供路线图。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.CY",
        "cs.NI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10396v1",
      "published_date": "2024-12-30 02:52:19 UTC",
      "updated_date": "2024-12-30 02:52:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:59:17.257506"
    },
    {
      "arxiv_id": "2412.20662v2",
      "title": "Enhancing Table Recognition with Vision LLMs: A Benchmark and Neighbor-Guided Toolchain Reasoner",
      "title_zh": "翻译失败",
      "authors": [
        "Yitong Zhou",
        "Mingyue Cheng",
        "Qingyang Mao",
        "Qi Liu",
        "Feiyang Xu",
        "Xin Li",
        "Enhong Chen"
      ],
      "abstract": "Pre-trained foundation models have recently significantly progressed in\nstructured table understanding and reasoning. However, despite advancements in\nareas such as table semantic understanding and table question answering,\nrecognizing the structure and content of unstructured tables using Vision Large\nLanguage Models (VLLMs) remains under-explored. In this work, we address this\nresearch gap by employing VLLMs in a training-free reasoning paradigm. First,\nwe design a benchmark with various hierarchical dimensions relevant to table\nrecognition. Subsequently, we conduct in-depth evaluations using pre-trained\nVLLMs, finding that low-quality image input is a significant bottleneck in the\nrecognition process. Drawing inspiration from these findings, we propose the\nNeighbor-Guided Toolchain Reasoner (NGTR) framework, which is characterized by\nintegrating multiple lightweight models for low-level visual processing\noperations aimed at mitigating issues with low-quality input images.\nSpecifically, we utilize a neighbor retrieval mechanism to guide the generation\nof multiple tool invocation plans, transferring tool selection experiences from\nsimilar neighbors to the given input, thereby facilitating suitable tool\nselection. Additionally, we introduce a reflection module to supervise the tool\ninvocation process. Extensive experiments on public table recognition datasets\ndemonstrate that our approach significantly enhances the recognition\ncapabilities of the vanilla VLLMs. We believe that the designed benchmark and\nthe proposed NGTR framework could provide an alternative solution in table\nrecognition.",
      "tldr_zh": "这篇论文探讨了使用 Vision LLMs (VLLMs) 提升非结构化表格识别的潜力，设计了一个多层次基准来评估表格的结构和内容理解。研究发现，低质量图像输入是主要瓶颈，因此提出 Neighbor-Guided Toolchain Reasoner (NGTR) 框架，该框架整合轻量级视觉模型、邻居检索机制和反射模块来优化工具调用过程，从而缓解输入问题。在公共数据集上的实验证明，NGTR 显著提升了原始 VLLMs 的识别能力，为表格识别提供了一种无训练的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20662v2",
      "published_date": "2024-12-30 02:40:19 UTC",
      "updated_date": "2025-01-03 06:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:59:29.233773"
    },
    {
      "arxiv_id": "2412.20656v1",
      "title": "Overcoming Class Imbalance: Unified GNN Learning with Structural and Semantic Connectivity Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah Alchihabi",
        "Hao Yan",
        "Yuhong Guo"
      ],
      "abstract": "Class imbalance is pervasive in real-world graph datasets, where the majority\nof annotated nodes belong to a small set of classes (majority classes), leaving\nmany other classes (minority classes) with only a handful of labeled nodes.\nGraph Neural Networks (GNNs) suffer from significant performance degradation in\nthe presence of class imbalance, exhibiting bias towards majority classes and\nstruggling to generalize effectively on minority classes. This limitation\nstems, in part, from the message passing process, leading GNNs to overfit to\nthe limited neighborhood of annotated nodes from minority classes and impeding\nthe propagation of discriminative information throughout the entire graph. In\nthis paper, we introduce a novel Unified Graph Neural Network Learning\n(Uni-GNN) framework to tackle class-imbalanced node classification. The\nproposed framework seamlessly integrates both structural and semantic\nconnectivity representations through semantic and structural node encoders. By\ncombining these connectivity types, Uni-GNN extends the propagation of node\nembeddings beyond immediate neighbors, encompassing non-adjacent structural\nnodes and semantically similar nodes, enabling efficient diffusion of\ndiscriminative information throughout the graph. Moreover, to harness the\npotential of unlabeled nodes within the graph, we employ a balanced\npseudo-label generation mechanism that augments the pool of available labeled\nnodes from minority classes in the training set. Experimental results\nunderscore the superior performance of our proposed Uni-GNN framework compared\nto state-of-the-art class-imbalanced graph learning baselines across multiple\nbenchmark datasets.",
      "tldr_zh": "本研究针对图数据集中的类不平衡问题，提出Unified GNN框架，以解决Graph Neural Networks (GNNs)对多数类偏好和少数类泛化不足的问题。Uni-GNN通过整合结构和语义连接表示，利用语义及结构节点编码器扩展节点嵌入传播到非相邻节点和语义相似节点，同时采用平衡伪标签生成机制利用无标签节点增强少数类的训练数据。实验结果显示，该框架在多个基准数据集上显著优于现有类不平衡图学习基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20656v1",
      "published_date": "2024-12-30 02:20:40 UTC",
      "updated_date": "2024-12-30 02:20:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:59:39.541528"
    },
    {
      "arxiv_id": "2501.00072v1",
      "title": "Open-Book Neural Algorithmic Reasoning",
      "title_zh": "开卷式神经算法推理",
      "authors": [
        "Hefei Li",
        "Chao Peng",
        "Chenyang Xu",
        "Zhengfeng Yang"
      ],
      "abstract": "Neural algorithmic reasoning is an emerging area of machine learning that\nfocuses on building neural networks capable of solving complex algorithmic\ntasks. Recent advancements predominantly follow the standard supervised\nlearning paradigm -- feeding an individual problem instance into the network\neach time and training it to approximate the execution steps of a classical\nalgorithm. We challenge this mode and propose a novel open-book learning\nframework. In this framework, whether during training or testing, the network\ncan access and utilize all instances in the training dataset when reasoning for\na given instance.\n  Empirical evaluation is conducted on the challenging CLRS Algorithmic\nReasoning Benchmark, which consists of 30 diverse algorithmic tasks. Our\nopen-book learning framework exhibits a significant enhancement in neural\nreasoning capabilities. Further, we notice that there is recent literature\nsuggesting that multi-task training on CLRS can improve the reasoning accuracy\nof certain tasks, implying intrinsic connections between different algorithmic\ntasks. We delve into this direction via the open-book framework. When the\nnetwork reasons for a specific task, we enable it to aggregate information from\ntraining instances of other tasks in an attention-based manner. We show that\nthis open-book attention mechanism offers insights into the inherent\nrelationships among various tasks in the benchmark and provides a robust tool\nfor interpretable multi-task training.",
      "tldr_zh": "这篇论文提出了一种开放式学习（open-book learning）框架，用于提升神经算法推理（Neural Algorithmic Reasoning），允许神经网络在训练或测试时访问整个训练数据集中的所有实例，从而更好地解决复杂算法任务。在 CLRS Algorithmic Reasoning Benchmark（包括30个多样化任务）上的实证评估显示，该框架显著提高了神经推理能力。论文进一步探索了多任务训练，通过注意力机制让网络从其他任务的训练实例中聚合信息，揭示了算法任务间的内在联系，并提供了一个可解释的 multi-task training 工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Appeared at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.00072v1",
      "published_date": "2024-12-30 02:14:58 UTC",
      "updated_date": "2024-12-30 02:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:59:52.652030"
    },
    {
      "arxiv_id": "2412.20651v2",
      "title": "Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Yousef Yeganeh",
        "Azade Farshad",
        "Ioannis Charisiadis",
        "Marta Hasny",
        "Martin Hartenberger",
        "Björn Ommer",
        "Nassir Navab",
        "Ehsan Adeli"
      ],
      "abstract": "Scaling by training on large datasets has been shown to enhance the quality\nand fidelity of image generation and manipulation with diffusion models;\nhowever, such large datasets are not always accessible in medical imaging due\nto cost and privacy issues, which contradicts one of the main applications of\nsuch models to produce synthetic samples where real data is scarce. Also,\nfine-tuning pre-trained general models has been a challenge due to the\ndistribution shift between the medical domain and the pre-trained models. Here,\nwe propose Latent Drift (LD) for diffusion models that can be adopted for any\nfine-tuning method to mitigate the issues faced by the distribution shift or\nemployed in inference time as a condition. Latent Drifting enables diffusion\nmodels to be conditioned for medical images fitted for the complex task of\ncounterfactual image generation, which is crucial to investigate how parameters\nsuch as gender, age, and adding or removing diseases in a patient would alter\nthe medical images. We evaluate our method on three public longitudinal\nbenchmark datasets of brain MRI and chest X-rays for counterfactual image\ngeneration. Our results demonstrate significant performance gains in various\nscenarios when combined with different fine-tuning schemes.",
      "tldr_zh": "本文提出 Latent Drift (LD) 方法，用于增强扩散模型在医疗图像合成的应用，特别针对反事实图像生成任务（如改变患者性别、年龄或疾病状态），以缓解数据稀缺、隐私问题和预训练模型的分布偏移挑战。LD 可以灵活应用于任何微调方案或推理过程，作为条件来生成更精确的医疗图像。实验在脑 MRI 和胸部 X 光的三个公共纵向基准数据集上进行，结果显示 LD 与不同微调方法结合时，在各种场景下显著提升了性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025 (highlight)",
      "pdf_url": "http://arxiv.org/pdf/2412.20651v2",
      "published_date": "2024-12-30 01:59:34 UTC",
      "updated_date": "2025-04-10 21:43:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:00:05.016983"
    },
    {
      "arxiv_id": "2412.20638v2",
      "title": "Predicting Long Term Sequential Policy Value Using Softer Surrogates",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunji Nam",
        "Allen Nie",
        "Ge Gao",
        "Vasilis Syrgkanis",
        "Emma Brunskill"
      ],
      "abstract": "Off-policy policy evaluation (OPE) estimates the outcome of a new policy\nusing historical data collected from a different policy. However, existing OPE\nmethods cannot handle cases when the new policy introduces novel actions. This\nissue commonly occurs in real-world domains, like healthcare, as new drugs and\ntreatments are continuously developed. Novel actions necessitate on-policy data\ncollection, which can be burdensome and expensive if the outcome of interest\ntakes a substantial amount of time to observe--for example, in multi-year\nclinical trials. This raises a key question of how to predict the long-term\noutcome of a policy after only observing its short-term effects? Though in\ngeneral this problem is intractable, under some surrogacy conditions, the\nshort-term on-policy data can be combined with the long-term historical data to\nmake accurate predictions about the new policy's long-term value. In two\nsimulated healthcare examples--HIV and sepsis management--we show that our\nestimators can provide accurate predictions about the policy value only after\nobserving 10\\% of the full horizon data. We also provide finite sample analysis\nof our doubly robust estimators.",
      "tldr_zh": "本研究针对Off-policy policy evaluation (OPE) 的局限性，提出了一种使用 softer surrogates 的方法，来预测引入新动作策略的长期价值，尤其适用于医疗等领域，其中新治疗需要昂贵且耗时的on-policy数据收集。该方法在特定surrogacy conditions下，通过结合短期on-policy数据和长期历史数据，实现对策略长期效果的准确预测。在HIV和败血症管理的模拟实验中，该估计器仅需观察10%的全时段数据，就能提供可靠的预测结果；此外，论文还提供了doubly robust estimators的有限样本分析，为高效评估新策略奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2412.20638v2",
      "published_date": "2024-12-30 01:01:15 UTC",
      "updated_date": "2025-02-03 02:11:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:00:16.394926"
    },
    {
      "arxiv_id": "2412.20635v1",
      "title": "NetFlowGen: Leveraging Generative Pre-training for Network Traffic Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Zhou",
        "Woojeong Kim",
        "Zhiying Xu",
        "Alexander M. Rush",
        "Minlan Yu"
      ],
      "abstract": "Understanding the traffic dynamics in networks is a core capability for\nautomated systems to monitor and analyze networking behaviors, reducing\nexpensive human efforts and economic risks through tasks such as traffic\nclassification, congestion prediction, and attack detection. However, it is\nstill challenging to accurately model network traffic with machine learning\napproaches in an efficient and broadly applicable manner. Task-specific models\ntrained from scratch are used for different networking applications, which\nlimits the efficiency of model development and generalization of model\ndeployment. Furthermore, while networking data is abundant, high-quality\ntask-specific labels are often insufficient for training individual models.\nLarge-scale self-supervised learning on unlabeled data provides a natural\npathway for tackling these challenges. We propose to pre-train a\ngeneral-purpose machine learning model to capture traffic dynamics with only\ntraffic data from NetFlow records, with the goal of fine-tuning for different\ndownstream tasks with small amount of labels. Our presented NetFlowGen\nframework goes beyond a proof-of-concept for network traffic pre-training and\naddresses specific challenges such as unifying network feature representations,\nlearning from large unlabeled traffic data volume, and testing on real\ndownstream tasks in DDoS attack detection. Experiments demonstrate promising\nresults of our pre-training framework on capturing traffic dynamics and\nadapting to different networking tasks.",
      "tldr_zh": "本研究提出NetFlowGen框架，利用生成式预训练(generative pre-training)方法，从无标签的NetFlow记录数据中学习网络流量动态，以解决传统任务特定模型在效率和泛化方面的挑战。框架通过大规模自监督学习统一网络特征表示，并仅需少量标签即可微调应用于下游任务，如流量分类、拥塞预测和DDoS攻击检测。实验结果显示，NetFlowGen在捕捉流量动态和适应不同网络任务上表现出色，显著提高了模型开发效率和实际部署效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.20635v1",
      "published_date": "2024-12-30 00:47:49 UTC",
      "updated_date": "2024-12-30 00:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:00:28.404946"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 80,
  "processed_papers_count": 80,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T19:00:48.290028"
}