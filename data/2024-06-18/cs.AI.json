{
  "date": "2024-06-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-18 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 在强化学习、图像处理、大语言模型（LLMs）推理和医疗应用中的创新进展，强调了 LLMs 在规划和多模态任务上的潜力（如 Google 团队的规划能力基准测试），以及一些高效算法和基准数据集的构建；令人印象深刻的文章包括 LLMs 的鲁棒性分析和医疗图像处理方法，而其他论文则探讨了更广泛的领域如图神经网络和时间序列预测。\n\n### 重点论文讨论\n以下挑选了部分重要、具有话题度和创新性的论文，先从 LLMs 相关主题入手，再扩展到图像处理和医疗领域，最后快速掠过其他次要内容。每个条目列出论文标题（中文 + 英文），并简要描述主要贡献和发现。\n\n- **Exploring and Benchmarking the Planning Capabilities of Large Language Models**（探索和基准测试大语言模型的规划能力）  \n  这篇论文由 Google 研究者主导，调查了 LLMs 在经典和自然语言规划任务中的性能，引入了全面基准套件和多-shot in-context 学习，发现增加上下文长度能提升规划表现，但模型在分布外场景下仍存在局限。主要贡献是揭示 LLMs 的规划潜力及其失败模式，为 AI 决策提供新洞见。\n\n- **RITA: A Real-time Interactive Talking Avatars Framework**（RITA：实时交互式对话头像框架）  \n  作者提出 RITA 框架，利用生成模型将用户上传照片转化为实时对话头像，结合计算机视觉和自然语言处理。主要发现是，该框架在虚拟现实、教育和游戏中表现出色，能创建沉浸式数字互动，提升人机交互的边界。\n\n- **NaviSplit: Dynamic Multi-Branch Split DNNs for Efficient Distributed Autonomous Navigation**（NaviSplit：用于高效分布式自主导航的动态多分支分割 DNN）  \n  这篇论文针对无人机导航提出 NaviSplit 框架，将 DNN 分割为头部和尾部模型，实现分布式处理。关键发现是，它在减少数据传输量（95% 减少）的同时，提高了导航精度（72-81% 准确率），为资源受限的自主系统提供高效解决方案。\n\n- **Bayesian-LoRA: LoRA based Parameter Efficient Fine-Tuning using Optimal Quantization levels and Rank Values trough Differentiable Bayesian Gates**（Bayesian-LoRA：通过可微分贝叶斯门控实现 LoRA 的参数高效微调）  \n  作者扩展 LoRA 方法，使用贝叶斯视角优化量化级别和秩值，实现高效微调。主要贡献是，在 GLUE 基准上，Bayesian-LoRA 与基线相当或更好，同时减少 70% 的位操作，展示了对下游任务的鲁棒性。\n\n- **MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification**（MaskPure：使用随机净化提升文本对抗防御）  \n  这篇论文提出 MaskPure 方法，通过随机掩码和重填来防御文本攻击。发现它在字符级和单词级攻击中表现出色，且无需对抗训练，提供可证明的鲁棒性，填补了 NLP 防御领域的空白。\n\n- **Evaluating $n$-Gram Novelty of Language Models Using Rusty-DAWG**（使用 Rusty-DAWG 评估语言模型的 n-gram 新颖性）  \n  作者开发 Rusty-DAWG 工具，评估语言模型生成的 n-gram 与训练数据的差异。关键发现是，模型在小 n 上更具新颖性，但大 n 时不如人类文本；这为理解模型创新性提供了新工具，并将在 EMNLP 2024 发表。\n\n- **Scale-Translation Equivariant Network for Oceanic Internal Solitary Wave Localization**（用于海洋内部孤立波定位的尺度-平移等变网络）  \n  针对遥感数据，该论文提出 ST-ECNN 模型，利用等变卷积捕捉海浪模式。发现它在低分辨率数据上表现优异，通过自监督预训练提升了定位精度，适用于环境监测。\n\n- **Machine Learning and Optimization Techniques for Solving Inverse Kinematics in a 7-DOF Robotic Arm**（机器学习和优化技术用于解决 7-DOF 机械臂的反向运动学）  \n  作者探索 13 种优化技术解决冗余机械臂问题，提出新算法比传统粒子群优化快 200 倍。主要贡献是结合 ML 和数值方法，提升机器人控制效率。\n\n- **Assessing AI vs Human-Authored Spear Phishing SMS Attacks: An Empirical Study**（评估 AI 与人类编写的鱼叉式短信攻击：实证研究）  \n  这篇论文比较 GPT-4 生成的短信攻击与人类版本，发现 AI 生成的更具说服力（尤其在工作相关主题）。主要发现是，AI 攻击更难被识别，强调了对社交工程防御的紧迫性。\n\n- **From RAGs to rich parameters: Probing how language models utilize external knowledge over parametric information for factual queries**（从 RAG 到丰富参数：探究语言模型如何利用外部知识超过参数信息进行事实查询）  \n  作者分析 LLMs 如何优先使用检索增强生成 (RAG) 而非内部参数。发现 RAG 更依赖上下文，导致模型在事实查询中更可靠，但也暴露了知识利用的捷径问题。\n\n- **Skin Cancer Images Classification using Transfer Learning Techniques**（使用迁移学习技术对皮肤癌图像进行分类）  \n  这篇论文应用迁移学习（如 ResNet-50）分类皮肤癌图像，优化激活函数和数据增强后，达到 93.5% 准确率。主要贡献是提升了早期诊断效率。\n\n- **OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for Superintelligent AI**（OlympicArena：为超级智能 AI 基准测试多学科认知推理）  \n  作者构建 OlympicArena 基准，包含 11k 双语问题，评估 LLMs 在多模态认知上的表现。发现 GPT-4o 仅达到 39.97% 准确率，强调了 AI 推理的局限性。\n\n- **TSI-Bench: Benchmarking Time Series Imputation**（TSI-Bench：时间序列插值基准测试）  \n  这篇论文提出 TSI-Bench 基准，评估时间序列插值算法。发现新方法在多个数据集上超越基线，提供系统化评估框架。\n\n### 其他论文快速掠过\n剩余论文多为特定领域的小改进或实验验证，如 **Real-time Yemeni Currency Detection**（实时识别也门货币）使用深度学习辅助视障人士，但影响有限；**Deriving Hematological Disease Classes Using Fuzzy Logic**（使用模糊逻辑推导血液病类）提出模糊规则诊断，但实用性需进一步验证；**Insect Identification in the Wild**（野外昆虫识别）构建新数据集，提升生物多样性监测。这些论文在各自领域有贡献，但整体影响力较小，仅补充了 AI 在生物和医疗的多样应用。\n\n总之，今天的论文展示了 AI 在推理和实际应用中的进展，但也暴露了模型鲁棒性和泛化性的挑战。感兴趣的读者可关注 LLMs 和医疗 AI 方向的最新动态！",
  "papers": [
    {
      "arxiv_id": "2406.13106v3",
      "title": "Accelerating Complex Disease Treatment through Network Medicine and GenAI: A Case Study on Drug Repurposing for Breast Cancer",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Abdeen Hamed",
        "Tamer E. Fandy"
      ],
      "abstract": "The objective of this research is to introduce a network specialized in\npredicting drugs that can be repurposed by investigating real-world evidence\nsources, such as clinical trials and biomedical literature. Specifically, it\naims to generate drug combination therapies for complex diseases (e.g., cancer,\nAlzheimer's). We present a multilayered network medicine approach, empowered by\na highly configured ChatGPT prompt engineering system, which is constructed on\nthe fly to extract drug mentions in clinical trials. Additionally, we introduce\na novel algorithm that connects real-world evidence with disease-specific\nsignaling pathways (e.g., KEGG database). This sheds light on the\nrepurposability of drugs if they are found to bind with one or more protein\nconstituents of a signaling pathway. To demonstrate, we instantiated the\nframework for breast cancer and found that, out of 46 breast cancer signaling\npathways, the framework identified 38 pathways that were covered by at least\ntwo drugs. This evidence signals the potential for combining those drugs.\nSpecifically, the most covered signaling pathway, ID hsa:2064, was covered by\n108 drugs, some of which can be combined. Conversely, the signaling pathway ID\nhsa:1499 was covered by only two drugs, indicating a significant gap for\nfurther research. Our network medicine framework, empowered by GenAI, shows\npromise in identifying drug combinations with a high degree of specificity,\nknowing the exact signaling pathways and proteins that serve as targets. It is\nnoteworthy that ChatGPT successfully accelerated the process of identifying\ndrug mentions in clinical trials, though further investigations are required to\ndetermine the relationships among the drug mentions.",
      "tldr_zh": "本研究提出一个基于网络医学和 GenAI 的框架，旨在通过调查临床试验和生物医学文献来预测复杂疾病（如乳腺癌）的药物再利用可能性。该框架结合高度配置的 ChatGPT 提示工程系统从临床试验中提取药物提及，并引入新算法将真实世界证据与疾病特定信号通路（如 KEGG 数据库）连接，评估药物是否绑定信号通路中的蛋白质。针对乳腺癌案例，框架分析了 46 个信号通路，发现 38 个通路被至少两种药物覆盖，其中信号通路 hsa:2064 被 108 种药物覆盖，突显了潜在药物组合的疗效潜力。该方法显著加速了药物识别过程，但仍需进一步研究药物间的关系以提升准确性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "I.2; I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages double columns, 5 figures, 3 algorithms, 3 tables, and 1\n  listing, Submitted to IEEE MedAI'24 Conference, to be held November 15-17,\n  Chongqing, China",
      "pdf_url": "http://arxiv.org/pdf/2406.13106v3",
      "published_date": "2024-06-18 23:40:00 UTC",
      "updated_date": "2024-06-27 08:28:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:35:34.949277"
    },
    {
      "arxiv_id": "2406.13103v2",
      "title": "A Generic Method for Fine-grained Category Discovery in Natural Language Texts",
      "title_zh": "一种用于自然语言文本的细粒度类别发现通用方法",
      "authors": [
        "Chang Tian",
        "Matthew B. Blaschko",
        "Wenpeng Yin",
        "Mingzhe Xing",
        "Yinliang Yue",
        "Marie-Francine Moens"
      ],
      "abstract": "Fine-grained category discovery using only coarse-grained supervision is a\ncost-effective yet challenging task. Previous training methods focus on\naligning query samples with positive samples and distancing them from\nnegatives. They often neglect intra-category and inter-category semantic\nsimilarities of fine-grained categories when navigating sample distributions in\nthe embedding space. Furthermore, some evaluation techniques that rely on\npre-collected test samples are inadequate for real-time applications. To\naddress these shortcomings, we introduce a method that successfully detects\nfine-grained clusters of semantically similar texts guided by a novel objective\nfunction. The method uses semantic similarities in a logarithmic space to guide\nsample distributions in the Euclidean space and to form distinct clusters that\nrepresent fine-grained categories. We also propose a centroid inference\nmechanism to support real-time applications. The efficacy of the method is both\ntheoretically justified and empirically confirmed on three benchmark tasks. The\nproposed objective function is integrated in multiple contrastive learning\nbased neural models. Its results surpass existing state-of-the-art approaches\nin terms of Accuracy, Adjusted Rand Index and Normalized Mutual Information of\nthe detected fine-grained categories. Code and data will be available at Code\nand data are publicly available at\nhttps://github.com/changtianluckyforever/F-grained-STAR.",
      "tldr_zh": "本文提出了一种通用方法，用于在自然语言文本中进行 Fine-grained Category Discovery，仅依赖粗粒度监督。该方法通过一个新颖的目标函数，利用对数空间的语义相似性来指导欧氏空间中的样本分布，形成代表细粒度类别的聚类，并引入质心推理机制以支持实时应用。与现有方法相比，该方法解决了忽略细粒度类别内/间语义相似性的问题，并在三个基准任务上表现出色，在 Accuracy、Adjusted Rand Index 和 Normalized Mutual Information 指标上超越了现有最先进方法。代码和数据已公开可用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "contrastive learning, self-supervised learning",
      "pdf_url": "http://arxiv.org/pdf/2406.13103v2",
      "published_date": "2024-06-18 23:27:46 UTC",
      "updated_date": "2025-02-06 15:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:35:45.851872"
    },
    {
      "arxiv_id": "2406.13094v2",
      "title": "Exploring and Benchmarking the Planning Capabilities of Large Language Models",
      "title_zh": "探索与基准测试大型语言模型的规划能力",
      "authors": [
        "Bernd Bohnet",
        "Azade Nova",
        "Aaron T Parisi",
        "Kevin Swersky",
        "Katayoon Goshvadi",
        "Hanjun Dai",
        "Dale Schuurmans",
        "Noah Fiedel",
        "Hanie Sedghi"
      ],
      "abstract": "Classical and natural language planning tasks remain a difficult domain for\nmodern large language models (LLMs). In this work, we lay the foundations for\nimproving planning capabilities of LLMs. First, we construct a comprehensive\nbenchmark suite encompassing both classical planning benchmarks and natural\nlanguage scenarios. This suite includes algorithms to methodically generate\ninstances of tasks with varying levels of difficulty, allowing for rigorous and\nsystematic evaluation of LLM performance. Next, we investigate the use of\nmany-shot in-context learning to enhance LLM planning, exploring the\nrelationship between increased context length and improved planning\nperformance. In addition, we demonstrate the positive impact of fine-tuning\nLLMs on optimal planning paths. We also probe the efficacy of chain-of-thought\nreasoning methods to improve LLM planning performance. Moreover, we probe the\nperformance of the proposed methods in out-of-distribution scenarios, assessing\nthe ability to generalize to novel and unseen planning challenges. Finally, we\ninvestigate model's failure modes and reveal insights that hold true across\ndifferent benchmarks.",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）的规划能力，构建了一个全面基准测试套件，包括古典规划任务和自然语言场景，并通过算法生成不同难度的实例，以系统评估LLMs的表现。研究者调查了多示例in-context learning的作用，揭示了增加上下文长度能提升规划性能，同时证明了微调LLMs和chain-of-thought推理方法对优化规划路径的积极影响。实验还评估了这些方法在分布外场景中的泛化能力，并分析了模型的失败模式，提供了跨基准的宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13094v2",
      "published_date": "2024-06-18 22:57:06 UTC",
      "updated_date": "2024-11-02 11:49:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:35:56.605278"
    },
    {
      "arxiv_id": "2406.13093v1",
      "title": "RITA: A Real-time Interactive Talking Avatars Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Wuxinlin Cheng",
        "Cheng Wan",
        "Yupeng Cao",
        "Sihan Chen"
      ],
      "abstract": "RITA presents a high-quality real-time interactive framework built upon\ngenerative models, designed with practical applications in mind. Our framework\nenables the transformation of user-uploaded photos into digital avatars that\ncan engage in real-time dialogue interactions. By leveraging the latest\nadvancements in generative modeling, we have developed a versatile platform\nthat not only enhances the user experience through dynamic conversational\navatars but also opens new avenues for applications in virtual reality, online\neducation, and interactive gaming. This work showcases the potential of\nintegrating computer vision and natural language processing technologies to\ncreate immersive and interactive digital personas, pushing the boundaries of\nhow we interact with digital content.",
      "tldr_zh": "RITA 是一个基于 generative models 的高品质实时互动框架，旨在将用户上传的照片转化为数字头像，支持实时对话互动。\n该框架整合了计算机 vision 和 natural language processing 技术，增强用户体验，并扩展到虚拟现实、在线教育和互动游戏等应用领域。\n这项研究展示了这种整合的潜力，推动数字内容互动的创新和发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13093v1",
      "published_date": "2024-06-18 22:53:15 UTC",
      "updated_date": "2024-06-18 22:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:36:07.296589"
    },
    {
      "arxiv_id": "2406.13086v1",
      "title": "NaviSplit: Dynamic Multi-Branch Split DNNs for Efficient Distributed Autonomous Navigation",
      "title_zh": "NaviSplit：动态多分支分割深度神经网络用于高效分布式自主导航",
      "authors": [
        "Timothy K Johnsen",
        "Ian Harshbarger",
        "Zixia Xia",
        "Marco Levorato"
      ],
      "abstract": "Lightweight autonomous unmanned aerial vehicles (UAV) are emerging as a\ncentral component of a broad range of applications. However, autonomous\nnavigation necessitates the implementation of perception algorithms, often deep\nneural networks (DNN), that process the input of sensor observations, such as\nthat from cameras and LiDARs, for control logic. The complexity of such\nalgorithms clashes with the severe constraints of these devices in terms of\ncomputing power, energy, memory, and execution time. In this paper, we propose\nNaviSplit, the first instance of a lightweight navigation framework embedding a\ndistributed and dynamic multi-branched neural model. At its core is a DNN split\nat a compression point, resulting in two model parts: (1) the head model, that\nis executed at the vehicle, which partially processes and compacts perception\nfrom sensors; and (2) the tail model, that is executed at an interconnected\ncompute-capable device, which processes the remainder of the compacted\nperception and infers navigation commands. Different from prior work, the\nNaviSplit framework includes a neural gate that dynamically selects a specific\nhead model to minimize channel usage while efficiently supporting the\nnavigation network. In our implementation, the perception model extracts a 2D\ndepth map from a monocular RGB image captured by the drone using the robust\nsimulator Microsoft AirSim. Our results demonstrate that the NaviSplit depth\nmodel achieves an extraction accuracy of 72-81% while transmitting an extremely\nsmall amount of data (1.2-18 KB) to the edge server. When using the neural\ngate, as utilized by NaviSplit, we obtain a slightly higher navigation accuracy\nas compared to a larger static network by 0.3% while significantly reducing the\ndata rate by 95%. To the best of our knowledge, this is the first exemplar of\ndynamic multi-branched model based on split DNNs for autonomous navigation.",
      "tldr_zh": "本论文提出NaviSplit框架，这是一种动态多分支分割DNNs（Deep Neural Networks）的轻量级导航系统，旨在解决无人机（UAV）在自主导航中面临的计算资源和能量限制问题。NaviSplit将DNN在压缩点分割为头模型（在车辆上处理并压缩传感器感知数据，如摄像头和LiDAR输入）和尾模型（在互联设备上完成处理并生成导航命令），并引入神经门控器（neural gate）动态选择头模型以最小化数据传输。实验使用Microsoft AirSim模拟器从单目RGB图像提取2D深度图，结果显示NaviSplit的提取准确率达72-81%，传输数据量仅为1.2-18 KB；使用神经门控器时，导航准确率比静态网络高0.3%，并将数据率减少95%。这项工作是首个基于分割DNNs的动态多分支模型，用于高效的分布式自主导航。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13086v1",
      "published_date": "2024-06-18 22:25:09 UTC",
      "updated_date": "2024-06-18 22:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:36:21.542837"
    },
    {
      "arxiv_id": "2406.13069v3",
      "title": "Evaluating $n$-Gram Novelty of Language Models Using Rusty-DAWG",
      "title_zh": "翻译失败",
      "authors": [
        "William Merrill",
        "Noah A. Smith",
        "Yanai Elazar"
      ],
      "abstract": "How novel are texts generated by language models (LMs) relative to their\ntraining corpora? In this work, we investigate the extent to which modern LMs\ngenerate $n$-grams from their training data, evaluating both (i) the\nprobability LMs assign to complete training $n$-grams and (ii) $n$-novelty, the\nproportion of $n$-grams generated by an LM that did not appear in the training\ndata (for arbitrarily large $n$). To enable arbitrary-length $n$-gram search\nover a corpus in constant time w.r.t. corpus size, we develop Rusty-DAWG, a\nnovel search tool inspired by indexing of genomic data. We compare the novelty\nof LM-generated text to human-written text and explore factors that affect\ngeneration novelty, focusing on the Pythia models. We find that, for $n > 4$,\nLM-generated text is less novel than human-written text, though it is more\nnovel for smaller $n$. Larger LMs and more constrained decoding strategies both\ndecrease novelty. Finally, we show that LMs complete $n$-grams with lower loss\nif they are more frequent in the training data. Overall, our results reveal\nfactors influencing the novelty of LM-generated text, and we release Rusty-DAWG\nto facilitate further pretraining data research.",
      "tldr_zh": "该研究评估了语言模型(LMs)生成文本相对于训练语料的n-gram新颖度，引入了Rusty-DAWG工具——一个受基因组数据索引启发的快速搜索机制，用于常量时间内处理任意长度的n-gram。实验比较了LMs生成文本与人类文本的新颖性，发现对于n > 4，LMs生成文本不如人类文本新颖，而更大模型或更受限的解码策略会进一步降低新颖度。结果还表明，训练数据中更频繁的n-gram会使LMs完成时损失更低，并发布了Rusty-DAWG以支持后续预训练数据研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13069v3",
      "published_date": "2024-06-18 21:31:19 UTC",
      "updated_date": "2024-10-04 16:42:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:36:35.718275"
    },
    {
      "arxiv_id": "2406.13066v1",
      "title": "MaskPure: Improving Defense Against Text Adversaries with Stochastic Purification",
      "title_zh": "MaskPure：通过随机净化提升对文本对抗者的防御",
      "authors": [
        "Harrison Gietz",
        "Jugal Kalita"
      ],
      "abstract": "The improvement of language model robustness, including successful defense\nagainst adversarial attacks, remains an open problem. In computer vision\nsettings, the stochastic noising and de-noising process provided by diffusion\nmodels has proven useful for purifying input images, thus improving model\nrobustness against adversarial attacks. Similarly, some initial work has\nexplored the use of random noising and de-noising to mitigate adversarial\nattacks in an NLP setting, but improving the quality and efficiency of these\nmethods is necessary for them to remain competitive. We extend upon methods of\ninput text purification that are inspired by diffusion processes, which\nrandomly mask and refill portions of the input text before classification. Our\nnovel method, MaskPure, exceeds or matches robustness compared to other\ncontemporary defenses, while also requiring no adversarial classifier training\nand without assuming knowledge of the attack type. In addition, we show that\nMaskPure is provably certifiably robust. To our knowledge, MaskPure is the\nfirst stochastic-purification method with demonstrated success against both\ncharacter-level and word-level attacks, indicating the generalizable and\npromising nature of stochastic denoising defenses. In summary: the MaskPure\nalgorithm bridges literature on the current strongest certifiable and empirical\nadversarial defense methods, showing that both theoretical and practical\nrobustness can be obtained together. Code is available on GitHub at\nhttps://github.com/hubarruby/MaskPure.",
      "tldr_zh": "本研究针对语言模型对抗性攻击的鲁棒性问题，提出了一种基于随机净化(stochastic purification)的防御方法MaskPure，通过随机掩码(mask)和填充(refill)输入文本，借鉴扩散模型(diffusion models)的噪声化和去噪声化过程。MaskPure无需对抗性分类器训练或攻击类型知识，即可实现与现有防御相当或更高的鲁棒性，并在实验中证明了对字符级和单词级攻击的通用有效性。该方法首次提供可证明的认证鲁棒(certifiably robust)性能，将理论和实际防御桥接起来，提升了语言模型的安全性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 1 figure, in the proceedings of The 29th International\n  Conference on Natural Language & Information Systems (NLDB 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.13066v1",
      "published_date": "2024-06-18 21:27:13 UTC",
      "updated_date": "2024-06-18 21:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:36:45.075725"
    },
    {
      "arxiv_id": "2406.13064v1",
      "title": "Machine Learning and Optimization Techniques for Solving Inverse Kinematics in a 7-DOF Robotic Arm",
      "title_zh": "翻译失败",
      "authors": [
        "Enoch Adediran",
        "Salem Ameen"
      ],
      "abstract": "As the pace of AI technology continues to accelerate, more tools have become\navailable to researchers to solve longstanding problems, Hybrid approaches\navailable today continue to push the computational limits of efficiency and\nprecision. One of such problems is the inverse kinematics of redundant systems.\nThis paper explores the complexities of a 7 degree of freedom manipulator and\nexplores 13 optimization techniques to solve it. Additionally, a novel approach\nis proposed to contribute to the field of algorithmic research. This was found\nto be over 200 times faster than the well-known traditional Particle Swarm\nOptimization technique. This new method may serve as a new field of search that\ncombines the explorative capabilities of Machine Learning with the exploitative\ncapabilities of numerical methods.",
      "tldr_zh": "这篇论文探讨了使用 Machine Learning 和优化技术来解决 7-DOF Robotic Arm 的 Inverse Kinematics 问题，针对冗余系统的计算效率和精度进行优化。作者评估了 13 种优化技术，并提出了一种新颖方法，该方法结合 Machine Learning 的探索能力和数值方法的利用能力。实验结果显示，新方法比传统的 Particle Swarm Optimization 快 200 倍，为机器人臂控制领域提供了更高效的算法解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13064v1",
      "published_date": "2024-06-18 21:23:51 UTC",
      "updated_date": "2024-06-18 21:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:36:56.275836"
    },
    {
      "arxiv_id": "2406.13060v1",
      "title": "Scale-Translation Equivariant Network for Oceanic Internal Solitary Wave Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhang Wan",
        "Shuo Wang",
        "Xudong Zhang"
      ],
      "abstract": "Internal solitary waves (ISWs) are gravity waves that are often observed in\nthe interior ocean rather than the surface. They hold significant importance\ndue to their capacity to carry substantial energy, thus influence pollutant\ntransport, oil platform operations, submarine navigation, etc. Researchers have\nstudied ISWs through optical images, synthetic aperture radar (SAR) images, and\naltimeter data from remote sensing instruments. However, cloud cover in optical\nremote sensing images variably obscures ground information, leading to blurred\nor missing surface observations. As such, this paper aims at altimeter-based\nmachine learning solutions to automatically locate ISWs. The challenges,\nhowever, lie in the following two aspects: 1) the altimeter data has low\nresolution, which requires a strong machine learner; 2) labeling data is\nextremely labor-intensive, leading to very limited data for training. In recent\nyears, the grand progress of deep learning demonstrates strong learning\ncapacity given abundant data. Besides, more recent studies on efficient\nlearning and self-supervised learning laid solid foundations to tackle the\naforementioned challenges. In this paper, we propose to inject prior knowledge\nto achieve a strong and efficient learner. Specifically, intrinsic patterns in\naltimetry data are efficiently captured using a scale-translation equivariant\nconvolutional neural network (ST-ECNN). By considering inherent symmetries in\nneural network design, ST-ECNN achieves higher efficiency and better\nperformance than baseline models. Furthermore, we also introduce prior\nknowledge from massive unsupervised data to enhance our solution using the\nSimCLR framework for pre-training. Our final solution achieves an overall\nbetter performance than baselines on our handcrafted altimetry dataset. Data\nand codes are available at\nhttps://github.com/ZhangWan-byte/Internal_Solitary_Wave_Localization .",
      "tldr_zh": "这篇论文针对海洋内部孤立波 (ISWs) 的定位问题，提出了一种基于高度计数据的机器学习解决方案，以应对数据分辨率低和标注数据有限的挑战。作者开发了 Scale-Translation Equivariant Convolutional Neural Network (ST-ECNN)，通过注入数据内在的尺度-平移对称性，实现更高的效率和性能提升。结合 SimCLR 框架的自监督预训练从海量无监督数据中提取先验知识，最终模型在手工制作的高度计数据集上比基线模型表现出色。数据和代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13060v1",
      "published_date": "2024-06-18 21:09:56 UTC",
      "updated_date": "2024-06-18 21:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:37:09.460132"
    },
    {
      "arxiv_id": "2406.13057v1",
      "title": "Informed along the road: roadway capacity driven graph convolution network for network-wide traffic prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zilin Bian",
        "Jingqin Gao",
        "Kaan Ozbay",
        "Fan Zuo",
        "Dachuan Zuo",
        "Zhenning Li"
      ],
      "abstract": "While deep learning has shown success in predicting traffic states, most\nmethods treat it as a general prediction task without considering\ntransportation aspects. Recently, graph neural networks have proven effective\nfor this task, but few incorporate external factors that impact roadway\ncapacity and traffic flow. This study introduces the Roadway Capacity Driven\nGraph Convolution Network (RCDGCN) model, which incorporates static and dynamic\nroadway capacity attributes in spatio-temporal settings to predict network-wide\ntraffic states. The model was evaluated on two real-world datasets with\ndifferent transportation factors: the ICM-495 highway network and an urban\nnetwork in Manhattan, New York City. Results show RCDGCN outperformed baseline\nmethods in forecasting accuracy. Analyses, including ablation experiments,\nweight analysis, and case studies, investigated the effect of capacity-related\nfactors. The study demonstrates the potential of using RCDGCN for\ntransportation system management.",
      "tldr_zh": "这篇论文提出了 Roadway Capacity Driven Graph Convolution Network (RCDGCN) 模型，用于网络范围的交通状态预测，该模型通过整合静态和动态道路容量属性来处理时空设置中的交通因素。RCDGCN 在 ICM-495 高速公路网络和曼哈顿城市网络的两个真实数据集上进行了评估，结果显示其预测准确性超过了基线方法。研究还通过消融实验、权重分析和案例研究，探讨了容量相关因素对交通流的影响，展示了该模型在交通系统管理中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13057v1",
      "published_date": "2024-06-18 21:04:23 UTC",
      "updated_date": "2024-06-18 21:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:37:20.486965"
    },
    {
      "arxiv_id": "2406.13049v2",
      "title": "Assessing AI vs Human-Authored Spear Phishing SMS Attacks: An Empirical Study",
      "title_zh": "翻译失败",
      "authors": [
        "Jerson Francia",
        "Derek Hansen",
        "Ben Schooley",
        "Matthew Taylor",
        "Shydra Murray",
        "Greg Snow"
      ],
      "abstract": "This paper explores the use of Large Language Models (LLMs) in spear phishing\nmessage generation and evaluates their performance compared to human-authored\ncounterparts. Our pilot study examines the effectiveness of smishing (SMS\nphishing) messages created by GPT-4 and human authors, which have been\npersonalized for willing targets. The targets assessed these messages in a\nmodified ranked-order experiment using a novel methodology we call TRAPD\n(Threshold Ranking Approach for Personalized Deception). Experiments involved\nranking each spear phishing message from most to least convincing, providing\nqualitative feedback, and guessing which messages were human- or AI-generated.\nResults show that LLM-generated messages are often perceived as more convincing\nthan those authored by humans, particularly job-related messages. Targets also\nstruggled to distinguish between human- and AI-generated messages. We analyze\ndifferent criteria the targets used to assess the persuasiveness and source of\nmessages. This study aims to highlight the urgent need for further research and\nimproved countermeasures against personalized AI-enabled social engineering\nattacks.",
      "tldr_zh": "这篇论文评估了 Large Language Models (LLMs) 在生成鱼叉式网络钓鱼短信（spear phishing SMS）方面的表现，并与人类作者的消息进行实证比较。研究采用试点实验和新型 TRAPD (Threshold Ranking Approach for Personalized Deception) 方法，让目标用户对由 GPT-4 和人类生成的个性化短信进行排名、反馈和来源猜测。结果表明，LLM 生成的消息通常被视为更具说服力，尤其是工作相关内容，且用户难以区分 AI 与人类来源；该研究强调了针对 AI 启用社会工程攻击加强研究和防护措施的迫切需求。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "18 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2406.13049v2",
      "published_date": "2024-06-18 20:47:16 UTC",
      "updated_date": "2025-03-19 00:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:37:34.544746"
    },
    {
      "arxiv_id": "2406.13046v3",
      "title": "Bayesian-LoRA: LoRA based Parameter Efficient Fine-Tuning using Optimal Quantization levels and Rank Values trough Differentiable Bayesian Gates",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian Meo",
        "Ksenia Sycheva",
        "Anirudh Goyal",
        "Justin Dauwels"
      ],
      "abstract": "It is a common practice in natural language processing to pre-train a single\nmodel on a general domain and then fine-tune it for downstream tasks. However,\nwhen it comes to Large Language Models, fine-tuning the entire model can be\ncomputationally expensive, resulting in very intensive energy consumption. As a\nresult, several Parameter Efficient Fine-Tuning (PEFT) approaches were recently\nproposed. One of the most popular approaches is low-rank adaptation (LoRA),\nwhere the key insight is decomposing the update weights of the pre-trained\nmodel into two low-rank matrices. However, the proposed approaches either use\nthe same rank value across all different weight matrices, which has been shown\nto be a sub-optimal choice, or do not use any quantization technique, one of\nthe most important factors when it comes to a model's energy consumption. In\nthis work, we propose Bayesian-LoRA which approaches low-rank adaptation and\nquantization from a Bayesian perspective by employing a prior distribution on\nboth quantization levels and rank values. As a result, B-LoRA is able to\nfine-tune a pre-trained model on a specific downstream task, finding the\noptimal rank values and quantization levels for every low-rank matrix. We\nvalidate the proposed model by fine-tuning a pre-trained DeBERTaV3 on the GLUE\nbenchmark. Moreover, we compare it to relevant baselines and present both\nqualitative and quantitative results, showing how the proposed approach is able\nto learn optimal-rank quantized matrices. B-LoRA performs on par with or better\nthan the baselines while reducing the total number of bit operations by roughly\n70% compared to the baseline methods.",
      "tldr_zh": "本论文提出Bayesian-LoRA，一种基于LoRA的参数高效微调方法，通过引入贝叶斯视角，使用先验分布和可微贝叶斯门控来优化每个低秩矩阵的量化级别和秩值，从而解决传统LoRA在计算密集型问题上的局限。\n该方法在微调预训练模型DeBERTaV3时，能自动学习最优的量化与秩值配置。\n实验结果显示，Bayesian-LoRA在GLUE基准上的性能与基线相当或优于基线，同时将总位操作减少约70%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13046v3",
      "published_date": "2024-06-18 20:26:30 UTC",
      "updated_date": "2024-10-28 17:47:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:37:45.279727"
    },
    {
      "arxiv_id": "2406.13038v1",
      "title": "Traffic Prediction considering Multiple Levels of Spatial-temporal Information: A Multi-scale Graph Wavelet-based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Zilin Bian",
        "Jingqin Gao",
        "Kaan Ozbay",
        "Zhenning Li"
      ],
      "abstract": "Although traffic prediction has been receiving considerable attention with a\nnumber of successes in the context of intelligent transportation systems, the\nprediction of traffic states over a complex transportation network that\ncontains different road types has remained a challenge. This study proposes a\nmulti-scale graph wavelet temporal convolution network (MSGWTCN) to predict the\ntraffic states in complex transportation networks. Specifically, a multi-scale\nspatial block is designed to simultaneously capture the spatial information at\ndifferent levels, and the gated temporal convolution network is employed to\nextract the temporal dependencies of the data. The model jointly learns to\nmount multiple levels of the spatial interactions by stacking graph wavelets\nwith different scales. Two real-world datasets are used in this study to\ninvestigate the model performance, including a highway network in Seattle and a\ndense road network of Manhattan in New York City. Experiment results show that\nthe proposed model outperforms other baseline models. Furthermore, different\nscales of graph wavelets are found to be effective in extracting local,\nintermediate and global information at the same time and thus enable the model\nto learn a complex transportation network topology with various types of road\nsegments. By carefully customizing the scales of wavelets, the model is able to\nimprove the prediction performance and better adapt to different network\nconfigurations.",
      "tldr_zh": "本研究提出了一种多尺度图波形时序卷积网络（MSGWTCN），用于复杂交通网络中考虑多级别空间-时间信息的交通状态预测。模型通过多尺度空间块同时捕获不同级别的空间交互，并结合门控时序卷积网络提取数据的时间依赖性，实现对局部、中间和全局信息的联合学习。实验在西雅图高速公路和纽约市曼哈顿密集道路的真实数据集上表明，MSGWTCN 优于其他基线模型，通过调整图 wavelets 的尺度，能显著提高预测性能并适应各种网络拓扑。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13038v1",
      "published_date": "2024-06-18 20:05:47 UTC",
      "updated_date": "2024-06-18 20:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:37:57.953817"
    },
    {
      "arxiv_id": "2406.13034v1",
      "title": "Real-time Yemeni Currency Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Edrees AL-Edreesi",
        "Ghaleb Al-Gaphari"
      ],
      "abstract": "Banknote recognition is a major problem faced by visually Challenged people.\nSo we propose a application to help the visually Challenged people to identify\nthe different types of Yemenian currencies through deep learning technique. As\nmoney has a significant role in daily life for any business transactions,\nreal-time detection and recognition of banknotes become necessary for a person,\nespecially blind or visually impaired, or for a system that sorts the data.\nThis paper presents a real-time Yemeni currency detection system for visually\nimpaired persons. The proposed system exploits the deep learning approach to\nfacilitate the visually impaired people to prosperously recognize banknotes.\nFor real-time recognition, we have deployed the system into a mobile\napplication.",
      "tldr_zh": "本研究针对视力障碍者识别纸币的难题，提出了一种实时也门货币检测系统，利用 deep learning 技术实现快速识别和分类。系统通过移动应用部署，允许用户实时检测不同类型的也门货币，从而便利日常生活中的交易。实验结果表明，该系统有效提升了视力障碍者的独立性，为类似应用提供了可行框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13034v1",
      "published_date": "2024-06-18 19:57:15 UTC",
      "updated_date": "2024-06-18 19:57:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:38:13.157593"
    },
    {
      "arxiv_id": "2406.13015v1",
      "title": "Deriving Hematological Disease Classes Using Fuzzy Logic and Expert Knowledge: A Comprehensive Machine Learning Approach with CBC Parameters",
      "title_zh": "使用模糊逻辑和专家知识",
      "authors": [
        "Salem Ameen",
        "Ravivarman Balachandran",
        "Theodoros Theodoridis"
      ],
      "abstract": "In the intricate field of medical diagnostics, capturing the subtle\nmanifestations of diseases remains a challenge. Traditional methods, often\nbinary in nature, may not encapsulate the nuanced variances that exist in\nreal-world clinical scenarios. This paper introduces a novel approach by\nleveraging Fuzzy Logic Rules to derive disease classes based on expert domain\nknowledge from a medical practitioner. By recognizing that diseases do not\nalways fit into neat categories, and that expert knowledge can guide the\nfuzzification of these boundaries, our methodology offers a more sophisticated\nand nuanced diagnostic tool.\n  Using a dataset procured from a prominent hospital, containing detailed\npatient blood count records, we harness Fuzzy Logic Rules, a computational\ntechnique celebrated for its ability to handle ambiguity. This approach, moving\nthrough stages of fuzzification, rule application, inference, and ultimately\ndefuzzification, produces refined diagnostic predictions. When combined with\nthe Random Forest classifier, the system adeptly predicts hematological\nconditions using Complete Blood Count (CBC) parameters.\n  Preliminary results showcase high accuracy levels, underscoring the\nadvantages of integrating fuzzy logic into the diagnostic process. When\njuxtaposed with traditional diagnostic techniques, it becomes evident that\nFuzzy Logic, especially when guided by medical expertise, offers significant\nadvancements in the realm of hematological diagnostics. This paper not only\npaves the path for enhanced patient care but also beckons a deeper dive into\nthe potentialities of fuzzy logic in various medical diagnostic applications.",
      "tldr_zh": "这篇论文提出了一种创新方法，使用Fuzzy Logic Rules结合专家知识，从Complete Blood Count (CBC) 参数中推导出血液疾病类别，以解决传统二元诊断无法捕捉疾病细微差异的问题。该方法包括fuzzification、规则应用、inference和defuzzification阶段，并与Random Forest分类器整合，对医院患者数据集进行分析。初步结果显示，该方法在血液诊断中实现了高准确率，比传统技术显著提升，并为其他医疗领域的模糊逻辑应用提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13015v1",
      "published_date": "2024-06-18 19:16:32 UTC",
      "updated_date": "2024-06-18 19:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:38:24.470796"
    },
    {
      "arxiv_id": "2406.13009v1",
      "title": "Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Chandler",
        "Devesh Surve",
        "Hui Su"
      ],
      "abstract": "Accurate text summarization is one of the most common and important tasks\nperformed by Large Language Models, where the costs of human review for an\nentire document may be high, but the costs of errors in summarization may be\neven greater. We propose Detecting Errors through Ensembling Prompts (DEEP) -\nan end-to-end large language model framework for detecting factual errors in\ntext summarization. Our framework uses a diverse set of LLM prompts to identify\nfactual inconsistencies, treating their outputs as binary features, which are\nthen fed into ensembling models. We then calibrate the ensembled models to\nproduce empirically accurate probabilities that a text is factually consistent\nor free of hallucination. We demonstrate that prior models for detecting\nfactual errors in summaries perform significantly worse without optimizing the\nthresholds on subsets of the evaluated dataset. Our framework achieves\nstate-of-the-art (SOTA) balanced accuracy on the AggreFact-XSUM FTSOTA,\nTofuEval Summary-Level, and HaluEval Summarization benchmarks in detecting\nfactual errors within transformer-generated text summaries. It does so without\nany fine-tuning of the language model or reliance on thresholding techniques\nnot available in practical settings.",
      "tldr_zh": "本论文提出了一种名为 DEEP 的端到端 LLM 框架，用于检测文本摘要中的事实错误，以应对人类审查成本高和错误风险大的问题。DEEP 通过使用多种 LLM 提示来识别事实不一致，将这些提示的输出作为二进制特征输入集成模型，并对模型进行校准，以生成准确的概率评估。实验结果显示，该框架在 AggreFact-XSUM FTSOTA、TofuEval Summary-Level 和 HaluEval Summarization 基准上达到了 SOTA 的平衡准确率，且无需微调语言模型或依赖实际场景中不可用的阈值技术。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13009v1",
      "published_date": "2024-06-18 18:59:37 UTC",
      "updated_date": "2024-06-18 18:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:38:34.170283"
    },
    {
      "arxiv_id": "2406.13008v1",
      "title": "ClaudesLens: Uncertainty Quantification in Computer Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamad Al Shaar",
        "Nils Ekström",
        "Gustav Gille",
        "Reza Rezvan",
        "Ivan Wely"
      ],
      "abstract": "In a world where more decisions are made using artificial intelligence, it is\nof utmost importance to ensure these decisions are well-grounded. Neural\nnetworks are the modern building blocks for artificial intelligence. Modern\nneural network-based computer vision models are often used for object\nclassification tasks. Correctly classifying objects with \\textit{certainty} has\nbecome of great importance in recent times. However, quantifying the inherent\n\\textit{uncertainty} of the output from neural networks is a challenging task.\nHere we show a possible method to quantify and evaluate the uncertainty of the\noutput of different computer vision models based on Shannon entropy. By adding\nperturbation of different levels, on different parts, ranging from the input to\nthe parameters of the network, one introduces entropy to the system. By\nquantifying and evaluating the perturbed models on the proposed PI and PSI\nmetrics, we can conclude that our theoretical framework can grant insight into\nthe uncertainty of predictions of computer vision models. We believe that this\ntheoretical framework can be applied to different applications for neural\nnetworks. We believe that Shannon entropy may eventually have a bigger role in\nthe SOTA (State-of-the-art) methods to quantify uncertainty in artificial\nintelligence. One day we might be able to apply Shannon entropy to our neural\nsystems.",
      "tldr_zh": "这篇论文介绍了 ClaudesLens，一种用于量化计算机视觉模型不确定性的框架，强调了在 AI 决策中确保输出可靠性的重要性。作者提出通过在输入、参数等部分添加不同级别的扰动来引入 Shannon entropy，从而评估模型的不确定性。利用 PI 和 PSI 指标对扰动后的模型进行量化评估，结果显示该框架能提供计算机视觉模型预测不确定性的宝贵洞见。作者认为，这一方法可扩展到各种神经网络应用，并预测 Shannon entropy 将在未来 State-of-the-art (SOTA) 不确定性量化技术中发挥更大作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13008v1",
      "published_date": "2024-06-18 18:58:54 UTC",
      "updated_date": "2024-06-18 18:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:38:45.485662"
    },
    {
      "arxiv_id": "2406.12998v4",
      "title": "Coding Speech through Vocal Tract Kinematics",
      "title_zh": "通过声道运动学编码语音",
      "authors": [
        "Cheol Jun Cho",
        "Peter Wu",
        "Tejas S. Prabhune",
        "Dhruv Agarwal",
        "Gopala K. Anumanchipalli"
      ],
      "abstract": "Vocal tract articulation is a natural, grounded control space of speech\nproduction. The spatiotemporal coordination of articulators combined with the\nvocal source shapes intelligible speech sounds to enable effective spoken\ncommunication. Based on this physiological grounding of speech, we propose a\nnew framework of neural encoding-decoding of speech -- Speech Articulatory\nCoding (SPARC). SPARC comprises an articulatory analysis model that infers\narticulatory features from speech audio, and an articulatory synthesis model\nthat synthesizes speech audio from articulatory features. The articulatory\nfeatures are kinematic traces of vocal tract articulators and source features,\nwhich are intuitively interpretable and controllable, being the actual physical\ninterface of speech production. An additional speaker identity encoder is\njointly trained with the articulatory synthesizer to inform the voice texture\nof individual speakers. By training on large-scale speech data, we achieve a\nfully intelligible, high-quality articulatory synthesizer that generalizes to\nunseen speakers. Furthermore, the speaker embedding is effectively disentangled\nfrom articulations, which enables accent-perserving zero-shot voice conversion.\nTo the best of our knowledge, this is the first demonstration of universal,\nhigh-performance articulatory inference and synthesis, suggesting the proposed\nframework as a powerful coding system of speech.",
      "tldr_zh": "本文提出了一种新的语音编码框架Speech Articulatory Coding (SPARC)，通过vocal tract kinematics的运动轨迹来推断和合成语音音频。具体而言，SPARC包括articulatory analysis model（从语音音频推断发音特征）和articulatory synthesis model（从发音特征生成音频），并通过speaker identity encoder实现对不同说话者声音纹理的控制和分离。实验结果显示，该框架在大规模数据上训练后，能产生高清晰度的语音合成，并支持accent-preserving zero-shot voice conversion。总体上，这标志着首个通用、高性能的articulatory inference and synthesis系统，为语音处理提供了一个强大、可解释的编码方法。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12998v4",
      "published_date": "2024-06-18 18:38:17 UTC",
      "updated_date": "2024-12-14 18:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:38:58.509728"
    },
    {
      "arxiv_id": "2406.12975v2",
      "title": "SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoze Liu",
        "Ting Sun",
        "Tianyang Xu",
        "Feijie Wu",
        "Cunxiang Wang",
        "Xiaoqian Wang",
        "Jing Gao"
      ],
      "abstract": "Large Language Models (LLMs) have transformed machine learning but raised\nsignificant legal concerns due to their potential to produce text that\ninfringes on copyrights, resulting in several high-profile lawsuits. The legal\nlandscape is struggling to keep pace with these rapid advancements, with\nongoing debates about whether generated text might plagiarize copyrighted\nmaterials. Current LLMs may infringe on copyrights or overly restrict\nnon-copyrighted texts, leading to these challenges: (i) the need for a\ncomprehensive evaluation benchmark to assess copyright compliance from multiple\naspects; (ii) evaluating robustness against safeguard bypassing attacks; and\n(iii) developing effective defense targeted against the generation of\ncopyrighted text. To tackle these challenges, we introduce a curated dataset to\nevaluate methods, test attack strategies, and propose lightweight, real-time\ndefense to prevent the generation of copyrighted text, ensuring the safe and\nlawful use of LLMs. Our experiments demonstrate that current LLMs frequently\noutput copyrighted text, and that jailbreaking attacks can significantly\nincrease the volume of copyrighted output. Our proposed defense mechanism\nsignificantly reduces the volume of copyrighted text generated by LLMs by\neffectively refusing malicious requests. Code is publicly available at\nhttps://github.com/xz-liu/SHIELD",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在文本生成中可能侵犯版权的问题，提出了SHIELD框架，以评估和防御版权合规性。SHIELD包括一个精选数据集，用于多方面评估LLMs的版权风险、测试防护绕过攻击（如jailbreaking attacks）的鲁棒性，并开发轻量级实时防御机制来阻止生成版权文本。实验结果显示，当前LLMs经常输出版权内容，而攻击可显著增加此风险；所提防御策略有效减少了违规生成，确保LLMs的安全使用。代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2406.12975v2",
      "published_date": "2024-06-18 18:00:03 UTC",
      "updated_date": "2024-08-21 11:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:39:08.972662"
    },
    {
      "arxiv_id": "2406.14579v1",
      "title": "Attention Networks for Personalized Mealtime Insulin Dosing in People with Type 1 Diabetes",
      "title_zh": "用于1型糖尿病患者个性化的进餐时间",
      "authors": [
        "Anas El Fathi",
        "Elliott Pryor",
        "Marc D. Breton"
      ],
      "abstract": "Calculating mealtime insulin doses poses a significant challenge for\nindividuals with Type 1 Diabetes (T1D). Doses should perfectly compensate for\nexpected post-meal glucose excursions, requiring a profound understanding of\nthe individual's insulin sensitivity and the meal macronutrients'. Usually,\npeople rely on intuition and experience to develop this understanding. In this\nwork, we demonstrate how a reinforcement learning agent, employing a\nself-attention encoder network, can effectively mimic and enhance this\nintuitive process. Trained on 80 virtual subjects from the FDA-approved\nUVA/Padova T1D adult cohort and tested on twenty, self-attention demonstrates\nsuperior performance compared to other network architectures. Results reveal a\nsignificant reduction in glycemic risk, from 16.5 to 9.6 in scenarios using\nsensor-augmented pump and from 9.1 to 6.7 in scenarios using automated insulin\ndelivery. This new paradigm bypasses conventional therapy parameters, offering\nthe potential to simplify treatment and promising improved quality of life and\nglycemic outcomes for people with T1D.",
      "tldr_zh": "本文提出了一种基于强化学习(reinforcement learning)代理和自注意力(self-attention)编码器网络的方法，用于为1型糖尿病(T1D)患者个性化计算餐时胰岛素剂量，以更好地补偿餐后血糖波动。模型在80个虚拟受试者（来自FDA批准的UVA/Padova T1D成人队列）上训练，并在20个上测试，表现出优于其他网络架构的性能。结果显示，该方法显著降低了血糖风险，在传感器增强泵场景从16.5降至9.6，在自动胰岛素递送场景从9.1降至6.7，提供了一种绕过传统治疗参数的简化方案，可能改善T1D患者的生活质量和血糖控制。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "6 pages, 4 figures, Biological and Medical Systems - 12th BMS 2024 -\n  IFAC",
      "pdf_url": "http://arxiv.org/pdf/2406.14579v1",
      "published_date": "2024-06-18 17:59:32 UTC",
      "updated_date": "2024-06-18 17:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:39:22.728110"
    },
    {
      "arxiv_id": "2406.12844v1",
      "title": "Synergizing Foundation Models and Federated Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Shenghui Li",
        "Fanghua Ye",
        "Meng Fang",
        "Jiaxu Zhao",
        "Yun-Hin Chan",
        "Edith C. -H. Ngai",
        "Thiemo Voigt"
      ],
      "abstract": "The recent development of Foundation Models (FMs), represented by large\nlanguage models, vision transformers, and multimodal models, has been making a\nsignificant impact on both academia and industry. Compared with small-scale\nmodels, FMs have a much stronger demand for high-volume data during the\npre-training phase. Although general FMs can be pre-trained on data collected\nfrom open sources such as the Internet, domain-specific FMs need proprietary\ndata, posing a practical challenge regarding the amount of data available due\nto privacy concerns. Federated Learning (FL) is a collaborative learning\nparadigm that breaks the barrier of data availability from different\nparticipants. Therefore, it provides a promising solution to customize and\nadapt FMs to a wide range of domain-specific tasks using distributed datasets\nwhilst preserving privacy. This survey paper discusses the potentials and\nchallenges of synergizing FL and FMs and summarizes core techniques, future\ndirections, and applications. A periodically updated paper collection on FM-FL\nis available at https://github.com/lishenghui/awesome-fm-fl.",
      "tldr_zh": "这篇调查论文探讨了 Foundation Models (FMs) 与 Federated Learning (FL) 的协同潜力，强调 FL 如何通过分布式协作学习解决 FMs 在预训练阶段面临的数据隐私和可用性挑战。论文总结了这一结合的核心技术、潜在优势（如适应领域特定任务）和面临的难题，如通信效率和模型鲁棒性，并指出了未来方向和实际应用。作者还提供了一个定期更新的论文集合资源（https://github.com/lishenghui/awesome-fm-fl），以支持进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12844v1",
      "published_date": "2024-06-18 17:58:09 UTC",
      "updated_date": "2024-06-18 17:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:39:36.028512"
    },
    {
      "arxiv_id": "2406.12843v3",
      "title": "Can Go AIs be adversarially robust?",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Tseng",
        "Euan McLean",
        "Kellin Pelrine",
        "Tony T. Wang",
        "Adam Gleave"
      ],
      "abstract": "Prior work found that superhuman Go AIs can be defeated by simple adversarial\nstrategies, especially \"cyclic\" attacks. In this paper, we study whether adding\nnatural countermeasures can achieve robustness in Go, a favorable domain for\nrobustness since it benefits from incredible average-case capability and a\nnarrow, innately adversarial setting. We test three defenses: adversarial\ntraining on hand-constructed positions, iterated adversarial training, and\nchanging the network architecture. We find that though some of these defenses\nprotect against previously discovered attacks, none withstand freshly trained\nadversaries. Furthermore, most of the reliably effective attacks these\nadversaries discover are different realizations of the same overall class of\ncyclic attacks. Our results suggest that building robust AI systems is\nchallenging even with extremely superhuman systems in some of the most\ntractable settings, and highlight two key gaps: efficient generalization of\ndefenses, and diversity in training. For interactive examples of attacks and a\nlink to our codebase, see https://goattack.far.ai.",
      "tldr_zh": "本文研究了围棋AI是否能实现对抗鲁棒性，针对先前发现的简单攻击（如cyclic attacks）问题，测试了三种防御方法：对手动构建的位置进行adversarial training、iterated adversarial training，以及改变网络架构。结果表明，虽然部分防御能抵御已知攻击，但均无法抵挡新训练的对手，且大多数有效攻击仍是cyclic attacks的不同变体。该研究强调了即使在超人级AI的围棋领域，构建鲁棒系统面临的挑战，包括防御的效率泛化和训练多样性不足。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "63 pages, AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.12843v3",
      "published_date": "2024-06-18 17:57:49 UTC",
      "updated_date": "2025-01-14 03:08:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:39:47.640869"
    },
    {
      "arxiv_id": "2406.12841v2",
      "title": "Demystifying Higher-Order Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Maciej Besta",
        "Florian Scheidl",
        "Lukas Gianinazzi",
        "Grzegorz Kwasniewski",
        "Shachar Klaiman",
        "Jürgen Müller",
        "Torsten Hoefler"
      ],
      "abstract": "Higher-order graph neural networks (HOGNNs) and the related architectures\nfrom Topological Deep Learning are an important class of GNN models that\nharness polyadic relations between vertices beyond plain edges. They have been\nused to eliminate issues such as over-smoothing or over-squashing, to\nsignificantly enhance the accuracy of GNN predictions, to improve the\nexpressiveness of GNN architectures, and for numerous other goals. A plethora\nof HOGNN models have been introduced, and they come with diverse neural\narchitectures, and even with different notions of what the \"higher-order\"\nmeans. This richness makes it very challenging to appropriately analyze and\ncompare HOGNN models, and to decide in what scenario to use specific ones. To\nalleviate this, we first design an in-depth taxonomy and a blueprint for\nHOGNNs. This facilitates designing models that maximize performance. Then, we\nuse our taxonomy to analyze and compare the available HOGNN models. The\noutcomes of our analysis are synthesized in a set of insights that help to\nselect the most beneficial GNN model in a given scenario, and a comprehensive\nlist of challenges and opportunities for further research into more powerful\nHOGNNs.",
      "tldr_zh": "这篇论文探讨了 Higher-Order Graph Neural Networks (HOGNNs) 和相关 Topological Deep Learning 架构，这些模型通过处理多元关系（如超出简单边的 polyadic relations）来解决 GNNs 的问题，如 over-smoothing 和 over-squashing，并提升预测准确性和模型表达性。作者设计了一个深入的分类学（taxonomy）和蓝图（blueprint），用于分析和比较多种 HOGNN 模型，帮助优化模型设计和场景应用。最终，论文总结了关键见解，用于指导在特定情境下选择最合适的 GNN 模型，并列出了进一步研究的挑战和机会。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12841v2",
      "published_date": "2024-06-18 17:57:11 UTC",
      "updated_date": "2024-12-06 14:57:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:40:00.041415"
    },
    {
      "arxiv_id": "2406.12835v1",
      "title": "Influence Maximization via Graph Neural Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Yuting Feng",
        "Vincent Y. F. Tan",
        "Bogdan Cautis"
      ],
      "abstract": "We consider a ubiquitous scenario in the study of Influence Maximization\n(IM), in which there is limited knowledge about the topology of the diffusion\nnetwork. We set the IM problem in a multi-round diffusion campaign, aiming to\nmaximize the number of distinct users that are influenced. Leveraging the\ncapability of bandit algorithms to effectively balance the objectives of\nexploration and exploitation, as well as the expressivity of neural networks,\nour study explores the application of neural bandit algorithms to the IM\nproblem. We propose the framework IM-GNB (Influence Maximization with Graph\nNeural Bandits), where we provide an estimate of the users' probabilities of\nbeing influenced by influencers (also known as diffusion seeds). This initial\nestimate forms the basis for constructing both an exploitation graph and an\nexploration one. Subsequently, IM-GNB handles the exploration-exploitation\ntradeoff, by selecting seed nodes in real-time using Graph Convolutional\nNetworks (GCN), in which the pre-estimated graphs are employed to refine the\ninfluencers' estimated rewards in each contextual setting. Through extensive\nexperiments on two large real-world datasets, we demonstrate the effectiveness\nof IM-GNB compared with other baseline methods, significantly improving the\nspread outcome of such diffusion campaigns, when the underlying network is\nunknown.",
      "tldr_zh": "本研究针对影响最大化(Influence Maximization, IM)问题，在网络拓扑未知的场景下，提出了一种基于图神经Bandit算法的框架IM-GNB。该框架利用Bandit算法平衡探索和利用目标，通过神经网络估计用户被影响概率，并构建利用和探索图。随后，使用Graph Convolutional Networks (GCN)实时选择种子节点，以优化多轮扩散活动。在两个大型真实数据集上的实验表明，IM-GNB显著优于基线方法，提高了扩散结果的传播效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at the 2024 ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining (KDD)",
      "pdf_url": "http://arxiv.org/pdf/2406.12835v1",
      "published_date": "2024-06-18 17:54:33 UTC",
      "updated_date": "2024-06-18 17:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:40:10.540066"
    },
    {
      "arxiv_id": "2406.12832v1",
      "title": "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Seyedarmin Azizi",
        "Souvik Kundu",
        "Massoud Pedram"
      ],
      "abstract": "Low-rank adaptation (LoRA) has become the default approach to fine-tune large\nlanguage models (LLMs) due to its significant reduction in trainable\nparameters. However, trainable parameter demand for LoRA increases with\nincreasing model embedding dimensions, leading to high compute costs.\nAdditionally, its backward updates require storing high-dimensional\nintermediate activations and optimizer states, demanding high peak GPU memory.\nIn this paper, we introduce large model fine-tuning via spectrally decomposed\nlow-dimensional adaptation (LaMDA), a novel approach to fine-tuning large\nlanguage models, which leverages low-dimensional adaptation to achieve\nsignificant reductions in trainable parameters and peak GPU memory footprint.\nLaMDA freezes a first projection matrix (PMA) in the adaptation path while\nintroducing a low-dimensional trainable square matrix, resulting in substantial\nreductions in trainable parameters and peak GPU memory usage. LaMDA gradually\nfreezes a second projection matrix (PMB) during the early fine-tuning stages,\nreducing the compute cost associated with weight updates to enhance parameter\nefficiency further. We also present an enhancement, LaMDA++, incorporating a\n``lite-weight\" adaptive rank allocation for the LoRA path via normalized\nspectrum analysis of pre-trained model weights. We evaluate LaMDA/LaMDA++\nacross various tasks, including natural language understanding with the GLUE\nbenchmark, text summarization, natural language generation, and complex\nreasoning on different LLMs. Results show that LaMDA matches or surpasses the\nperformance of existing alternatives while requiring up to 17.7x fewer\nparameter updates and up to 1.32x lower peak GPU memory usage during\nfine-tuning. Code will be publicly available.",
      "tldr_zh": "该论文提出 LaMDA，一种基于光谱分解低维适配的创新方法，用于高效微调大型语言模型（LLMs），旨在解决低秩适配（LoRA）在参数数量和 GPU 内存需求上的问题。LaMDA 通过冻结第一投影矩阵（PMA）和引入低维可训练矩阵，显著减少可训练参数，同时在早期微调阶段逐步冻结第二投影矩阵（PMB），进一步降低计算成本。增强版 LaMDA++ 通过规范化光谱分析动态分配 LoRA 路径的秩，实现更优的适应性。在 GLUE 基准等任务上，LaMDA 匹配或超越现有方法，同时减少高达 17.7 倍的参数更新和 1.32 倍的峰值 GPU 内存使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12832v1",
      "published_date": "2024-06-18 17:52:59 UTC",
      "updated_date": "2024-06-18 17:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:40:24.180897"
    },
    {
      "arxiv_id": "2406.12831v3",
      "title": "VIA: Unified Spatiotemporal Video Adaptation Framework for Global and Local Video Editing",
      "title_zh": "VIA：统一时空视频适应框架，用于全局和局部视频编辑",
      "authors": [
        "Jing Gu",
        "Yuwei Fang",
        "Ivan Skorokhodov",
        "Peter Wonka",
        "Xinya Du",
        "Sergey Tulyakov",
        "Xin Eric Wang"
      ],
      "abstract": "Video editing serves as a fundamental pillar of digital media, spanning\napplications in entertainment, education, and professional communication.\nHowever, previous methods often overlook the necessity of comprehensively\nunderstanding both global and local contexts, leading to inaccurate and\ninconsistent edits in the spatiotemporal dimension, especially for long videos.\nIn this paper, we introduce VIA, a unified spatiotemporal Video Adaptation\nframework for global and local video editing, pushing the limits of\nconsistently editing minute-long videos. First, to ensure local consistency\nwithin individual frames, we designed test-time editing adaptation to adapt a\npre-trained image editing model for improving consistency between potential\nediting directions and the text instruction, and adapts masked latent variables\nfor precise local control. Furthermore, to maintain global consistency over the\nvideo sequence, we introduce spatiotemporal adaptation that recursively gather\nconsistent attention variables in key frames and strategically applies them\nacross the whole sequence to realize the editing effects. Extensive experiments\ndemonstrate that, compared to baseline methods, our VIA approach produces edits\nthat are more faithful to the source videos, more coherent in the\nspatiotemporal context, and more precise in local control. More importantly, we\nshow that VIA can achieve consistent long video editing in minutes, unlocking\nthe potential for advanced video editing tasks over long video sequences.",
      "tldr_zh": "本研究提出 VIA，一种统一的时空视频适应框架，用于处理全局和局部视频编辑问题，解决了现有方法在长视频中忽略上下文导致的不准确和不一致性问题。VIA 包括测试时编辑适应（test-time editing adaptation），通过适应预训练图像编辑模型和掩码潜变量来提升局部帧的一致性和精确控制；以及时空适应（spatiotemporal adaptation），通过递归收集关键帧的注意力变量并应用于整个序列，确保全局一致性。实验结果显示，VIA 比基线方法生成更忠实于源视频的编辑、更连贯的时空上下文以及更精确的局部控制，并能在几分钟内实现长视频的一致编辑。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.12831v3",
      "published_date": "2024-06-18 17:51:37 UTC",
      "updated_date": "2025-03-27 17:56:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:40:35.140144"
    },
    {
      "arxiv_id": "2406.12824v1",
      "title": "From RAGs to rich parameters: Probing how language models utilize external knowledge over parametric information for factual queries",
      "title_zh": "翻译失败",
      "authors": [
        "Hitesh Wadhwa",
        "Rahul Seetharaman",
        "Somyaa Aggarwal",
        "Reshmi Ghosh",
        "Samyadeep Basu",
        "Soundararajan Srinivasan",
        "Wenlong Zhao",
        "Shreyas Chaudhari",
        "Ehsan Aghazadeh"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) enriches the ability of language models\nto reason using external context to augment responses for a given user prompt.\nThis approach has risen in popularity due to practical applications in various\napplications of language models in search, question/answering, and chat-bots.\nHowever, the exact nature of how this approach works isn't clearly understood.\nIn this paper, we mechanistically examine the RAG pipeline to highlight that\nlanguage models take shortcut and have a strong bias towards utilizing only the\ncontext information to answer the question, while relying minimally on their\nparametric memory. We probe this mechanistic behavior in language models with:\n(i) Causal Mediation Analysis to show that the parametric memory is minimally\nutilized when answering a question and (ii) Attention Contributions and\nKnockouts to show that the last token residual stream do not get enriched from\nthe subject token in the question, but gets enriched from other informative\ntokens in the context. We find this pronounced shortcut behaviour true across\nboth LLaMa and Phi family of models.",
      "tldr_zh": "该研究探讨了语言模型在处理事实查询时，如何优先利用外部知识（如RAG中的检索增强生成）而非内部参数信息。作者通过Causal Mediation Analysis和Attention Contributions and Knockouts等方法分析RAG管道，发现语言模型倾向于依赖上下文信息而非参数记忆，且问题中的主题标记对残差流的贡献有限。实验结果显示，这种捷径行为在LLaMa和Phi系列模型中普遍存在，为优化语言模型的知识利用提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12824v1",
      "published_date": "2024-06-18 17:46:08 UTC",
      "updated_date": "2024-06-18 17:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:40:47.279012"
    },
    {
      "arxiv_id": "2406.12822v3",
      "title": "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Pinzhen Chen",
        "Simon Yu",
        "Zhicheng Guo",
        "Barry Haddow"
      ],
      "abstract": "Multilingual large language models are designed, claimed, and expected to\ncater to speakers of varied languages. We hypothesise that the current\npractices of fine-tuning and evaluating these models may not perfectly align\nwith this objective owing to a heavy reliance on translation, which cannot\ncover language-specific knowledge but can introduce translation defects. It\nremains unknown whether the nature of the instruction data has an impact on the\nmodel output; conversely, it is questionable whether translated test sets can\ncapture such nuances. Due to the often coupled practices of using translated\ndata in both stages, such imperfections could have been overlooked. This work\ninvestigates these issues using controlled native or translated data during the\ninstruction tuning and evaluation stages. We show that native or generation\nbenchmarks reveal a notable difference between native and translated\ninstruction data especially when model performance is high, whereas other types\nof test sets cannot. The comparison between round-trip and single-pass\ntranslations reflects the importance of knowledge from language-native\nresources. Finally, we demonstrate that regularization is beneficial to\nbridging this gap on structured but not generative tasks.",
      "tldr_zh": "本研究质疑多语言大型语言模型（Multilingual Large Language Models）的指令微调（instruction tuning）和评估实践是否过度依赖翻译数据，可能导致无法捕捉语言特定知识并引入翻译缺陷。作者通过使用受控的本地或翻译数据在微调和评估阶段进行实验，发现本地或生成基准显示本地指令数据与翻译数据在模型性能高时有显著差异，而其他测试集无法捕捉此差异。比较往返翻译（round-trip）和单向翻译（single-pass）突出了语言本地资源的重要性，并证明正则化（regularization）有助于桥接结构化任务的差距，但不适用于生成任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12822v3",
      "published_date": "2024-06-18 17:43:47 UTC",
      "updated_date": "2024-09-26 17:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:40:59.570776"
    },
    {
      "arxiv_id": "2406.12815v1",
      "title": "Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolas Koutsoubis",
        "Yasin Yilmaz",
        "Ravi P. Ramachandran",
        "Matthew Schabath",
        "Ghulam Rasool"
      ],
      "abstract": "Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable\nadvancements, particularly in healthcare. Within medical imaging, ML models\nhold the promise of improving disease diagnoses, treatment planning, and\npost-treatment monitoring. Various computer vision tasks like image\nclassification, object detection, and image segmentation are poised to become\nroutine in clinical analysis. However, privacy concerns surrounding patient\ndata hinder the assembly of large training datasets needed for developing and\ntraining accurate, robust, and generalizable models. Federated Learning (FL)\nemerges as a compelling solution, enabling organizations to collaborate on ML\nmodel training by sharing model training information (gradients) rather than\ndata (e.g., medical images). FL's distributed learning framework facilitates\ninter-institutional collaboration while preserving patient privacy. However,\nFL, while robust in privacy preservation, faces several challenges. Sensitive\ninformation can still be gleaned from shared gradients that are passed on\nbetween organizations during model training. Additionally, in medical imaging,\nquantifying model confidence\\uncertainty accurately is crucial due to the noise\nand artifacts present in the data. Uncertainty estimation in FL encounters\nunique hurdles due to data heterogeneity across organizations. This paper\noffers a comprehensive review of FL, privacy preservation, and uncertainty\nestimation, with a focus on medical imaging. Alongside a survey of current\nresearch, we identify gaps in the field and suggest future directions for FL\nresearch to enhance privacy and address noisy medical imaging data challenges.",
      "tldr_zh": "这篇论文综述了 Federated Learning (FL) 在医疗成像中的应用，强调 FL 通过共享模型训练信息（如梯度）而非原始数据，实现机构间协作并保护患者隐私。论文讨论了 FL 面临的挑战，包括从共享梯度中潜在泄露敏感信息，以及在数据异质性和噪声干扰下进行 Uncertainty Estimation 的困难。作者识别了当前研究中的空白，并提出未来研究方向，以提升隐私保护和处理医疗成像中的噪声数据挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "eess.IV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 5 figures, 3 tables, Journal preprint",
      "pdf_url": "http://arxiv.org/pdf/2406.12815v1",
      "published_date": "2024-06-18 17:35:52 UTC",
      "updated_date": "2024-06-18 17:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:41:11.679015"
    },
    {
      "arxiv_id": "2406.12808v3",
      "title": "Graph Neural Networks in Histopathology: Emerging Trends and Future Directions",
      "title_zh": "在组织病理学中的图神经网络：新兴趋势和未来方向",
      "authors": [
        "Siemen Brussee",
        "Giorgio Buzzanca",
        "Anne M. R. Schrader",
        "Jesper Kers"
      ],
      "abstract": "Histopathological analysis of Whole Slide Images (WSIs) has seen a surge in\nthe utilization of deep learning methods, particularly Convolutional Neural\nNetworks (CNNs). However, CNNs often fall short in capturing the intricate\nspatial dependencies inherent in WSIs. Graph Neural Networks (GNNs) present a\npromising alternative, adept at directly modeling pairwise interactions and\neffectively discerning the topological tissue and cellular structures within\nWSIs. Recognizing the pressing need for deep learning techniques that harness\nthe topological structure of WSIs, the application of GNNs in histopathology\nhas experienced rapid growth. In this comprehensive review, we survey GNNs in\nhistopathology, discuss their applications, and explore emerging trends that\npave the way for future advancements in the field. We begin by elucidating the\nfundamentals of GNNs and their potential applications in histopathology.\nLeveraging quantitative literature analysis, we identify four emerging trends:\nHierarchical GNNs, Adaptive Graph Structure Learning, Multimodal GNNs, and\nHigher-order GNNs. Through an in-depth exploration of these trends, we offer\ninsights into the evolving landscape of GNNs in histopathological analysis.\nBased on our findings, we propose future directions to propel the field\nforward. Our analysis serves to guide researchers and practitioners towards\ninnovative approaches and methodologies, fostering advancements in\nhistopathological analysis through the lens of graph neural networks.",
      "tldr_zh": "这篇综述论文探讨了Graph Neural Networks (GNNs)在组织病理学中分析Whole Slide Images (WSIs)的应用，强调GNNs比传统的Convolutional Neural Networks (CNNs)更擅长捕捉WSIs的复杂空间依赖和拓扑结构。论文通过定量文献分析，识别了四个新兴趋势：Hierarchical GNNs、Adaptive Graph Structure Learning、Multimodal GNNs和Higher-order GNNs，并深入探讨这些趋势如何推动该领域的进展。最终，论文提出未来方向，旨在指导研究者开发创新方法，提升GNNs在组织病理学分析中的作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.TO",
        "I.2.10; I.4.10; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12808v3",
      "published_date": "2024-06-18 17:23:50 UTC",
      "updated_date": "2024-06-21 08:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:41:23.519695"
    },
    {
      "arxiv_id": "2406.12807v1",
      "title": "Probabilistic Temporal Prediction of Continuous Disease Trajectories and Treatment Effects Using Neural SDEs",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Durso-Finley",
        "Berardino Barile",
        "Jean-Pierre Falet",
        "Douglas L. Arnold",
        "Nick Pawlowski",
        "Tal Arbel"
      ],
      "abstract": "Personalized medicine based on medical images, including predicting future\nindividualized clinical disease progression and treatment response, would have\nan enormous impact on healthcare and drug development, particularly for\ndiseases (e.g. multiple sclerosis (MS)) with long term, complex, heterogeneous\nevolutions and no cure. In this work, we present the first stochastic causal\ntemporal framework to model the continuous temporal evolution of disease\nprogression via Neural Stochastic Differential Equations (NSDE). The proposed\ncausal inference model takes as input the patient's high dimensional images\n(MRI) and tabular data, and predicts both factual and counterfactual\nprogression trajectories on different treatments in latent space. The NSDE\npermits the estimation of high-confidence personalized trajectories and\ntreatment effects. Extensive experiments were performed on a large,\nmulti-centre, proprietary dataset of patient 3D MRI and clinical data acquired\nduring several randomized clinical trials for MS treatments. Our results\npresent the first successful uncertainty-based causal Deep Learning (DL) model\nto: (a) accurately predict future patient MS disability evolution (e.g. EDSS)\nand treatment effects leveraging baseline MRI, and (b) permit the discovery of\nsubgroups of patients for which the model has high confidence in their response\nto treatment even in clinical trials which did not reach their clinical\nendpoints.",
      "tldr_zh": "该研究提出了一种基于 Neural SDEs 的随机因果时间框架，用于预测多发性硬化症 (MS) 等疾病的连续进展轨迹和治疗效果。该框架以患者的高维 MRI 图像和表格数据为输入，在潜在空间中生成事实和反事实轨迹，从而实现高置信度的个性化预测和治疗效果估计。在大型多中心 MS 临床试验数据集上进行的实验表明，该模型能准确预测患者残疾指标（如 EDSS）的未来演变，并识别出对治疗响应高度自信的患者子群，为个性化医学和药物开发提供新工具。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12807v1",
      "published_date": "2024-06-18 17:22:55 UTC",
      "updated_date": "2024-06-18 17:22:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:41:36.034921"
    },
    {
      "arxiv_id": "2406.12806v1",
      "title": "Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Zehao Wang",
        "Dong Jae Kim",
        "Tse-Hsun Chen"
      ],
      "abstract": "Configuration settings are essential for tailoring software behavior to meet\nspecific performance requirements. However, incorrect configurations are\nwidespread, and identifying those that impact system performance is challenging\ndue to the vast number and complexity of possible settings. In this work, we\npresent PerfSense, a lightweight framework that leverages Large Language Models\n(LLMs) to efficiently identify performance-sensitive configurations with\nminimal overhead. PerfSense employs LLM agents to simulate interactions between\ndevelopers and performance engineers using advanced prompting techniques such\nas prompt chaining and retrieval-augmented generation (RAG). Our evaluation of\nseven open-source Java systems demonstrates that PerfSense achieves an average\naccuracy of 64.77% in classifying performance-sensitive configurations,\noutperforming both our LLM baseline (50.36%) and the previous state-of-the-art\nmethod (61.75%). Notably, our prompt chaining technique improves recall by 10%\nto 30% while maintaining similar precision levels. Additionally, a manual\nanalysis of 362 misclassifications reveals common issues, including LLMs'\nmisunderstandings of requirements (26.8%). In summary, PerfSense significantly\nreduces manual effort in classifying performance-sensitive configurations and\noffers valuable insights for future LLM-based code analysis research.",
      "tldr_zh": "本文提出 PerfSense 框架，利用 Large Language Models (LLMs) 代理通过代码分析来高效识别软件系统中影响性能的敏感配置，解决配置复杂性和错误问题。该框架采用 prompt chaining 和 retrieval-augmented generation (RAG) 等高级提示技术，模拟开发者与性能工程师的互动。在七个开源 Java 系统上的评估中，PerfSense 的平均准确率达到 64.77%，比基线 (50.36%) 和现有最佳方法 (61.75%) 有所提升，同时 prompt chaining 技术提高了召回率 10% 到 30%。此外，手动分析 362 个误分类显示，LLMs 对需求的误解是常见问题 (26.8%)，为未来的 LLM-based code analysis 研究提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12806v1",
      "published_date": "2024-06-18 17:22:48 UTC",
      "updated_date": "2024-06-18 17:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:41:49.880853"
    },
    {
      "arxiv_id": "2406.12770v2",
      "title": "Informatics & dairy industry coalition: AI trends and present challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia García-Méndez",
        "Francisco de Arriba-Pérez",
        "María del Carmen Somoza-López"
      ],
      "abstract": "Artificial Intelligence (AI) can potentially transform the industry,\nenhancing the production process and minimizing manual, repetitive tasks.\nAccordingly, the synergy between high-performance computing and powerful\nmathematical models enables the application of sophisticated data analysis\nprocedures like Machine Learning. However, challenges exist regarding\neffective, efficient, and flexible processing to generate valuable knowledge.\nConsequently, this work comprehensively describes industrial challenges where\nAI can be exploited, focusing on the dairy industry. The conclusions presented\ncan help researchers apply novel approaches for cattle monitoring and farmers\nby proposing advanced technological solutions to their needs.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在乳制品行业的应用趋势和当前挑战，强调AI通过高性能计算和机器学习（Machine Learning）等技术提升生产过程、减少手动重复任务，并生成有价值的知识。论文详细描述了乳制品行业中的工业挑战，如数据处理的效率、有效性和灵活性问题，并提出AI解决方案来监测牛群和满足农民需求。总体而言，该研究为研究人员提供指导，帮助他们开发先进的技术方法以优化乳制品生产。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12770v2",
      "published_date": "2024-06-18 16:39:21 UTC",
      "updated_date": "2024-06-19 11:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:41:59.604096"
    },
    {
      "arxiv_id": "2406.12769v1",
      "title": "Latent Intuitive Physics: Learning to Transfer Hidden Physics from A 3D Video",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangming Zhu",
        "Huayu Deng",
        "Haochen Yuan",
        "Yunbo Wang",
        "Xiaokang Yang"
      ],
      "abstract": "We introduce latent intuitive physics, a transfer learning framework for\nphysics simulation that can infer hidden properties of fluids from a single 3D\nvideo and simulate the observed fluid in novel scenes. Our key insight is to\nuse latent features drawn from a learnable prior distribution conditioned on\nthe underlying particle states to capture the invisible and complex physical\nproperties. To achieve this, we train a parametrized prior learner given visual\nobservations to approximate the visual posterior of inverse graphics, and both\nthe particle states and the visual posterior are obtained from a learned neural\nrenderer. The converged prior learner is embedded in our probabilistic physics\nengine, allowing us to perform novel simulations on unseen geometries,\nboundaries, and dynamics without knowledge of the true physical parameters. We\nvalidate our model in three ways: (i) novel scene simulation with the learned\nvisual-world physics, (ii) future prediction of the observed fluid dynamics,\nand (iii) supervised particle simulation. Our model demonstrates strong\nperformance in all three tasks.",
      "tldr_zh": "本研究提出了一种名为“latent intuitive physics”的转移学习框架，能够从单个3D video中推断流体的隐藏物理属性，并将其应用于新场景的物理模拟。框架的关键在于使用从可学习的先验分布中抽取的潜在特征来捕捉复杂和不可见的物理性质，通过训练一个参数化的prior learner和神经renderer来近似视觉后验。最终，该框架嵌入概率物理引擎中，支持在未知真实参数下模拟新几何、边界和动态；实验验证显示，该模型在新场景模拟、流体动态未来预测以及监督粒子模拟等任务中表现出色。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12769v1",
      "published_date": "2024-06-18 16:37:44 UTC",
      "updated_date": "2024-06-18 16:37:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:42:12.628897"
    },
    {
      "arxiv_id": "2406.12762v1",
      "title": "Unsupervised explainable activity prediction in competitive Nordic Walking from experimental data",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia García-Méndez",
        "Francisco de Arriba-Pérez",
        "Francisco J. González-Castaño",
        "Javier Vales-Alonso"
      ],
      "abstract": "Artificial Intelligence (AI) has found application in Human Activity\nRecognition (HAR) in competitive sports. To date, most Machine Learning (ML)\napproaches for HAR have relied on offline (batch) training, imposing higher\ncomputational and tagging burdens compared to online processing unsupervised\napproaches. Additionally, the decisions behind traditional ML predictors are\nopaque and require human interpretation. In this work, we apply an online\nprocessing unsupervised clustering approach based on low-cost wearable Inertial\nMeasurement Units (IMUs). The outcomes generated by the system allow for the\nautomatic expansion of limited tagging available (e.g., by referees) within\nthose clusters, producing pertinent information for the explainable\nclassification stage. Specifically, our work focuses on achieving automatic\nexplainability for predictions related to athletes' activities, distinguishing\nbetween correct, incorrect, and cheating practices in Nordic Walking. The\nproposed solution achieved performance metrics of close to 100 % on average.",
      "tldr_zh": "本文提出了一种在线处理的无监督聚类方法，用于从实验数据中预测竞技 Nordic Walking 中的人类活动识别(HAR)，以低成本的可穿戴 Inertial Measurement Units (IMUs)为基础，避免了传统 Machine Learning (ML) 方法的离线训练负担和不透明问题。该方法能自动扩展有限标签（如裁判提供），实现对运动员活动（如正确、不正确和作弊行为）的可解释分类。实验结果显示，系统性能指标平均接近100%，为高效、可解释的体育活动监测提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12762v1",
      "published_date": "2024-06-18 16:29:07 UTC",
      "updated_date": "2024-06-18 16:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:42:24.067207"
    },
    {
      "arxiv_id": "2406.12754v1",
      "title": "Chumor 1.0: A Truly Funny and Challenging Chinese Humor Understanding Dataset from Ruo Zhi Ba",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi He",
        "Yushu He",
        "Longju Bai",
        "Jiarui Liu",
        "Zhenjie Sun",
        "Zenghao Tang",
        "He Wang",
        "Hanchen Xia",
        "Naihao Deng"
      ],
      "abstract": "Existing humor datasets and evaluations predominantly focus on English,\nlacking resources for culturally nuanced humor in non-English languages like\nChinese. To address this gap, we construct Chumor, a dataset sourced from Ruo\nZhi Ba (RZB), a Chinese Reddit-like platform dedicated to sharing\nintellectually challenging and culturally specific jokes. We annotate\nexplanations for each joke and evaluate human explanations against two\nstate-of-the-art LLMs, GPT-4o and ERNIE Bot, through A/B testing by native\nChinese speakers. Our evaluation shows that Chumor is challenging even for SOTA\nLLMs, and the human explanations for Chumor jokes are significantly better than\nexplanations generated by the LLMs.",
      "tldr_zh": "该研究构建了 Chumor 1.0 数据集，这是一个针对中文幽默理解的资源，源自 Ruo Zhi Ba (RZB) 平台，该平台专注于分享智力挑战性和文化特定的笑话，以填补现有幽默数据集主要针对英语的空白。研究团队为每个笑话标注了解释，并通过 A/B testing 由母语为中文的参与者评估人类解释与 SOTA LLMs（GPT-4o 和 ERNIE Bot）的表现。结果显示，Chumor 数据集对这些先进 LLMs 具有显著挑战性，且人类解释的质量明显优于 LLMs 生成的解释。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12754v1",
      "published_date": "2024-06-18 16:22:05 UTC",
      "updated_date": "2024-06-18 16:22:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:42:35.831523"
    },
    {
      "arxiv_id": "2406.12753v2",
      "title": "OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for Superintelligent AI",
      "title_zh": "OlympicArena：用于超级智能 AI 的多学科认知推理基准测试",
      "authors": [
        "Zhen Huang",
        "Zengzhi Wang",
        "Shijie Xia",
        "Xuefeng Li",
        "Haoyang Zou",
        "Ruijie Xu",
        "Run-Ze Fan",
        "Lyumanshan Ye",
        "Ethan Chern",
        "Yixin Ye",
        "Yikai Zhang",
        "Yuqing Yang",
        "Ting Wu",
        "Binjie Wang",
        "Shichao Sun",
        "Yang Xiao",
        "Yiyuan Li",
        "Fan Zhou",
        "Steffi Chern",
        "Yiwei Qin",
        "Yan Ma",
        "Jiadi Su",
        "Yixiu Liu",
        "Yuxiang Zheng",
        "Shaoting Zhang",
        "Dahua Lin",
        "Yu Qiao",
        "Pengfei Liu"
      ],
      "abstract": "The evolution of Artificial Intelligence (AI) has been significantly\naccelerated by advancements in Large Language Models (LLMs) and Large\nMultimodal Models (LMMs), gradually showcasing potential cognitive reasoning\nabilities in problem-solving and scientific discovery (i.e., AI4Science) once\nexclusive to human intellect. To comprehensively evaluate current models'\nperformance in cognitive reasoning abilities, we introduce OlympicArena, which\nincludes 11,163 bilingual problems across both text-only and interleaved\ntext-image modalities. These challenges encompass a wide range of disciplines\nspanning seven fields and 62 international Olympic competitions, rigorously\nexamined for data leakage. We argue that the challenges in Olympic competition\nproblems are ideal for evaluating AI's cognitive reasoning due to their\ncomplexity and interdisciplinary nature, which are essential for tackling\ncomplex scientific challenges and facilitating discoveries. Beyond evaluating\nperformance across various disciplines using answer-only criteria, we conduct\ndetailed experiments and analyses from multiple perspectives. We delve into the\nmodels' cognitive reasoning abilities, their performance across different\nmodalities, and their outcomes in process-level evaluations, which are vital\nfor tasks requiring complex reasoning with lengthy solutions. Our extensive\nevaluations reveal that even advanced models like GPT-4o only achieve a 39.97%\noverall accuracy, illustrating current AI limitations in complex reasoning and\nmultimodal integration. Through the OlympicArena, we aim to advance AI towards\nsuperintelligence, equipping it to address more complex challenges in science\nand beyond. We also provide a comprehensive set of resources to support AI\nresearch, including a benchmark dataset, an open-source annotation platform, a\ndetailed evaluation tool, and a leaderboard with automatic submission features.",
      "tldr_zh": "本文提出 OlympicArena 基准测试，用于评估人工智能（AI）在多学科认知推理方面的性能，该基准包含 11,163 个双语问题，涵盖文本-only 和文本-图像混合模式，并涉及七个领域及 62 个国际奥林匹克竞赛，以确保无数据泄露。研究通过多角度实验分析模型的认知推理能力、模态表现和过程级评估，结果显示即使是先进的 Large Language Models (LLMs) 和 Large Multimodal Models (LMMs) 如 GPT-4o，也仅达到 39.97% 的整体准确率，揭示了当前 AI 在复杂推理和多模态整合上的局限性。为推动 AI 向超级智能发展，论文提供了基准数据集、开源标注平台、详细评估工具和排行榜等资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12753v2",
      "published_date": "2024-06-18 16:20:53 UTC",
      "updated_date": "2025-03-06 12:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:42:49.422674"
    },
    {
      "arxiv_id": "2406.12747v2",
      "title": "TSI-Bench: Benchmarking Time Series Imputation",
      "title_zh": "TSI-Bench：时间序列插值基准测试",
      "authors": [
        "Wenjie Du",
        "Jun Wang",
        "Linglong Qian",
        "Yiyuan Yang",
        "Zina Ibrahim",
        "Fanxing Liu",
        "Zepu Wang",
        "Haoxin Liu",
        "Zhiyuan Zhao",
        "Yingjie Zhou",
        "Wenjia Wang",
        "Kaize Ding",
        "Yuxuan Liang",
        "B. Aditya Prakash",
        "Qingsong Wen"
      ],
      "abstract": "Effective imputation is a crucial preprocessing step for time series\nanalysis. Despite the development of numerous deep learning algorithms for time\nseries imputation, the community lacks standardized and comprehensive benchmark\nplatforms to effectively evaluate imputation performance across different\nsettings. Moreover, although many deep learning forecasting algorithms have\ndemonstrated excellent performance, whether their modelling achievements can be\ntransferred to time series imputation tasks remains unexplored. To bridge these\ngaps, we develop TSI-Bench, the first (to our knowledge) comprehensive\nbenchmark suite for time series imputation utilizing deep learning techniques.\nThe TSI-Bench pipeline standardizes experimental settings to enable fair\nevaluation of imputation algorithms and identification of meaningful insights\ninto the influence of domain-appropriate missing rates and patterns on model\nperformance. Furthermore, TSI-Bench innovatively provides a systematic paradigm\nto tailor time series forecasting algorithms for imputation purposes. Our\nextensive study across 34,804 experiments, 28 algorithms, and 8 datasets with\ndiverse missingness scenarios demonstrates TSI-Bench's effectiveness in diverse\ndownstream tasks and potential to unlock future directions in time series\nimputation research and analysis. All source code and experiment logs are\nreleased at https://github.com/WenjieDu/AwesomeImputation.",
      "tldr_zh": "该论文介绍了 TSI-Bench，这是一个首个全面的深度学习基准套件，用于评估时间序列插值（Time Series Imputation）的性能。TSI-Bench 标准化了实验设置，允许公平比较 28 个算法在 8 个数据集上的表现，并系统地探讨了将时间序列预测算法适应到插值任务的范式。研究通过 34,804 次实验，分析了不同缺失率和模式对模型的影响，证明了其在多样下游任务中的有效性，并为未来时间序列插值研究提供了新方向。所有源代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12747v2",
      "published_date": "2024-06-18 16:07:33 UTC",
      "updated_date": "2024-10-31 17:18:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:43:00.362180"
    },
    {
      "arxiv_id": "2406.12744v1",
      "title": "Ensuring Both Positivity and Stability Using Sector-Bounded Nonlinearity for Systems with Neural Network Controllers",
      "title_zh": "翻译失败",
      "authors": [
        "Hamidreza Montazeri Hedesh",
        "Milad Siami"
      ],
      "abstract": "This paper introduces a novel method for the stability analysis of positive\nfeedback systems with a class of fully connected feedforward neural networks\n(FFNN) controllers. By establishing sector bounds for fully connected FFNNs\nwithout biases, we present a stability theorem that demonstrates the global\nexponential stability of linear systems under fully connected FFNN control.\nUtilizing principles from positive Lur'e systems and the positive Aizerman\nconjecture, our approach effectively addresses the challenge of ensuring\nstability in highly nonlinear systems. The crux of our method lies in\nmaintaining sector bounds that preserve the positivity and Hurwitz property of\nthe overall Lur'e system. We showcase the practical applicability of our\nmethodology through its implementation in a linear system managed by a FFNN\ntrained on output feedback controller data, highlighting its potential for\nenhancing stability in dynamic systems.",
      "tldr_zh": "本论文提出了一种新方法，用于分析正反馈系统在全连接前馈神经网络 (FFNN) 控制器下的稳定性，通过建立无偏置 FFNN 的扇区边界来确保系统的正性和全局指数稳定。方法利用正 Lur'e 系统和正 Aizerman 猜想的原理，维护扇区边界以保留整体 Lur'e 系统的正性与 Hurwitz 属性。实验验证显示，该方法在由 FFNN 管理的线性系统中表现出色，展示了其在高度非线性动态系统中的实际应用潜力。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "math.OC",
        "G.1.2; I.2.3; I.2.8"
      ],
      "primary_category": "eess.SY",
      "comment": "6 pages, 7 figures, to be published in IEEE Control Systems Letters\n  (L-CSS)",
      "pdf_url": "http://arxiv.org/pdf/2406.12744v1",
      "published_date": "2024-06-18 16:05:57 UTC",
      "updated_date": "2024-06-18 16:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:43:13.399856"
    },
    {
      "arxiv_id": "2407.02509v1",
      "title": "Variables are a Curse in Software Vulnerability Prediction",
      "title_zh": "变量是软件漏洞预测中的诅咒",
      "authors": [
        "Jinghua Groppe",
        "Sven Groppe",
        "Ralf Möller"
      ],
      "abstract": "Deep learning-based approaches for software vulnerability prediction\ncurrently mainly rely on the original text of software code as the feature of\nnodes in the graph of code and thus could learn a representation that is only\nspecific to the code text, rather than the representation that depicts the\n'intrinsic' functionality of a program hidden in the text representation. One\ncurse that causes this problem is an infinite number of possibilities to name a\nvariable. In order to lift the curse, in this work we introduce a new type of\nedge called name dependence, a type of abstract syntax graph based on the name\ndependence, and an efficient node representation method named 3-property\nencoding scheme. These techniques will allow us to remove the concrete variable\nnames from code, and facilitate deep learning models to learn the functionality\nof software hidden in diverse code expressions. The experimental results show\nthat the deep learning models built on these techniques outperform the ones\nbased on existing approaches not only in the prediction of vulnerabilities but\nalso in the memory need. The factor of memory usage reductions of our\ntechniques can be up to the order of 30,000 in comparison to existing\napproaches.",
      "tldr_zh": "本文研究发现，在软件漏洞预测中，变量命名多样性导致深度学习模型仅学习代码文本的特定表示，而非程序的内在功能，从而影响预测准确性。为解决这一问题，作者引入了 name dependence 边、基于该边的抽象语法图，以及 3-property encoding scheme 来移除具体变量名称，帮助模型更好地捕捉软件隐藏功能。实验结果显示，该方法不仅在漏洞预测性能上优于现有方法，还将内存使用减少高达 30,000 倍。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "I.2.0; D.2.m"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02509v1",
      "published_date": "2024-06-18 16:02:29 UTC",
      "updated_date": "2024-06-18 16:02:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:43:24.346894"
    },
    {
      "arxiv_id": "2406.12742v1",
      "title": "Benchmarking Multi-Image Understanding in Vision and Language Models: Perception, Knowledge, Reasoning, and Multi-Hop Reasoning",
      "title_zh": "多图像理解在视觉和语言模型中的基准测试：感知、知识、推理和多跳推理",
      "authors": [
        "Bingchen Zhao",
        "Yongshuo Zong",
        "Letian Zhang",
        "Timothy Hospedales"
      ],
      "abstract": "The advancement of large language models (LLMs) has significantly broadened\nthe scope of applications in natural language processing, with multi-modal LLMs\nextending these capabilities to integrate and interpret visual data. However,\nexisting benchmarks for visual language models (VLMs) predominantly focus on\nsingle-image inputs, neglecting the crucial aspect of multi-image\nunderstanding. In this paper, we introduce a Multi-Image Relational Benchmark\nMIRB, designed to evaluate VLMs' ability to compare, analyze, and reason across\nmultiple images. Our benchmark encompasses four categories: perception, visual\nworld knowledge, reasoning, and multi-hop reasoning. Through a comprehensive\nevaluation of a wide range of open-source and closed-source models, we\ndemonstrate that while open-source VLMs were shown to approach the performance\nof GPT-4V in single-image tasks, a significant performance gap remains in\nmulti-image reasoning tasks. Our findings also reveal that even the\nstate-of-the-art GPT-4V model struggles with our benchmark, underscoring the\nneed for further research and development in this area. We believe our\ncontribution of MIRB could serve as a testbed for developing the\nnext-generation multi-modal models.",
      "tldr_zh": "本研究引入了Multi-Image Relational Benchmark (MIRB)，一个新的基准，用于评估视觉语言模型 (VLMs) 在多图像理解方面的能力，包括perception、visual world knowledge、reasoning 和 multi-hop reasoning 四个类别，以弥补现有基准偏重单图像输入的不足。研究通过对多种开源和闭源模型的全面评估，发现开源 VLMs 在多图像任务上显著落后于 GPT-4V，甚至 GPT-4V 也表现出力不从心，突显了这一领域的挑战。MIRB 的提出有望作为测试平台，推动下一代多模态模型的开发和改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "First three authors contributed equally. Dataset:\n  https://huggingface.co/datasets/VLLMs/MIRB",
      "pdf_url": "http://arxiv.org/pdf/2406.12742v1",
      "published_date": "2024-06-18 16:02:18 UTC",
      "updated_date": "2024-06-18 16:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:43:36.674779"
    },
    {
      "arxiv_id": "2406.12738v1",
      "title": "Large Language Model as a Universal Clinical Multi-task Decoder",
      "title_zh": "大语言模型作为通用临床多任务解码器",
      "authors": [
        "Yujiang Wu",
        "Hongjian Song",
        "Jiawen Zhang",
        "Xumeng Wen",
        "Shun Zheng",
        "Jiang Bian"
      ],
      "abstract": "The development of effective machine learning methodologies for enhancing the\nefficiency and accuracy of clinical systems is crucial. Despite significant\nresearch efforts, managing a plethora of diversified clinical tasks and\nadapting to emerging new tasks remain significant challenges. This paper\npresents a novel paradigm that employs a pre-trained large language model as a\nuniversal clinical multi-task decoder. This approach leverages the flexibility\nand diversity of language expressions to handle task topic variations and\nassociated arguments. The introduction of a new task simply requires the\naddition of a new instruction template. We validate this framework across\nhundreds of tasks, demonstrating its robustness in facilitating multi-task\npredictions, performing on par with traditional multi-task learning and\nsingle-task learning approaches. Moreover, it shows exceptional adaptability to\nnew tasks, with impressive zero-shot performance in some instances and superior\ndata efficiency in few-shot scenarios. This novel approach offers a unified\nsolution to manage a wide array of new and emerging tasks in clinical\napplications.",
      "tldr_zh": "本论文提出了一种新范式，使用预训练的大型语言模型（Large Language Model）作为通用临床多任务解码器，以应对多种临床任务的管理和适应新任务的挑战。该方法利用语言表达的灵活性，通过简单添加新指令模板即可处理任务主题和参数的变化。实验验证显示，该框架在数百个任务上表现与传统多任务学习和单任务学习相当，并在零样本场景中表现出色，以及在少样本场景中实现更高的数据效率。该方法为临床应用提供了一个统一的解决方案，高效管理新兴任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2406.12738v1",
      "published_date": "2024-06-18 15:58:36 UTC",
      "updated_date": "2024-06-18 15:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:43:49.670761"
    },
    {
      "arxiv_id": "2406.12736v1",
      "title": "Beyond Visual Appearances: Privacy-sensitive Objects Identification via Hybrid Graph Reasoning",
      "title_zh": "超越视觉外观：通过混合图推理的隐私敏感对象识别",
      "authors": [
        "Zhuohang Jiang",
        "Bingkui Tong",
        "Xia Du",
        "Ahmed Alhammadi",
        "Jizhe Zhou"
      ],
      "abstract": "The Privacy-sensitive Object Identification (POI) task allocates bounding\nboxes for privacy-sensitive objects in a scene. The key to POI is settling an\nobject's privacy class (privacy-sensitive or non-privacy-sensitive). In\ncontrast to conventional object classes which are determined by the visual\nappearance of an object, one object's privacy class is derived from the scene\ncontexts and is subject to various implicit factors beyond its visual\nappearance. That is, visually similar objects may be totally opposite in their\nprivacy classes. To explicitly derive the objects' privacy class from the scene\ncontexts, in this paper, we interpret the POI task as a visual reasoning task\naimed at the privacy of each object in the scene. Following this\ninterpretation, we propose the PrivacyGuard framework for POI. PrivacyGuard\ncontains three stages. i) Structuring: an unstructured image is first converted\ninto a structured, heterogeneous scene graph that embeds rich scene contexts.\nii) Data Augmentation: a contextual perturbation oversampling strategy is\nproposed to create slightly perturbed privacy-sensitive objects in a scene\ngraph, thereby balancing the skewed distribution of privacy classes. iii)\nHybrid Graph Generation & Reasoning: the balanced, heterogeneous scene graph is\nthen transformed into a hybrid graph by endowing it with extra \"node-node\" and\n\"edge-edge\" homogeneous paths. These homogeneous paths allow direct message\npassing between nodes or edges, thereby accelerating reasoning and facilitating\nthe capturing of subtle context changes. Based on this hybrid graph... **For\nthe full abstract, see the original paper.**",
      "tldr_zh": "本论文探讨了 Privacy-sensitive Object Identification (POI) 任务，该任务通过场景上下文而不是视觉外观来确定对象的隐私类别（如隐私敏感或非敏感），从而解决视觉相似对象可能具有相反隐私属性的问题。为此，研究提出 PrivacyGuard 框架，包括三个阶段：首先，将图像结构化为异构场景图以嵌入丰富上下文；其次，使用上下文扰动过采样策略进行数据增强，以平衡隐私类别的分布；最后，通过生成混合图并添加节点-节点和边-边同构路径，加速推理并捕捉微妙上下文变化。该框架提升了 POI 任务的准确性和鲁棒性，为隐私保护对象识别提供了新方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.12736v1",
      "published_date": "2024-06-18 15:58:22 UTC",
      "updated_date": "2024-06-18 15:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:44:02.017717"
    },
    {
      "arxiv_id": "2406.12732v1",
      "title": "Automatic generation of insights from workers' actions in industrial workflows with explainable Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco de Arriba-Pérez",
        "Silvia García-Méndez",
        "Javier Otero-Mosquera",
        "Francisco J. González-Castaño",
        "Felipe Gil-Castiñeira"
      ],
      "abstract": "New technologies such as Machine Learning (ML) gave great potential for\nevaluating industry workflows and automatically generating key performance\nindicators (KPIs). However, despite established standards for measuring the\nefficiency of industrial machinery, there is no precise equivalent for workers'\nproductivity, which would be highly desirable given the lack of a skilled\nworkforce for the next generation of industry workflows. Therefore, an ML\nsolution combining data from manufacturing processes and workers' performance\nfor that goal is required. Additionally, in recent times intense effort has\nbeen devoted to explainable ML approaches that can automatically explain their\ndecisions to a human operator, thus increasing their trustworthiness. We\npropose to apply explainable ML solutions to differentiate between expert and\ninexpert workers in industrial workflows, which we validate at a quality\nassessment industrial workstation. Regarding the methodology used, input data\nare captured by a manufacturing machine and stored in a NoSQL database. Data\nare processed to engineer features used in automatic classification and to\ncompute workers' KPIs to predict their level of expertise (with all\nclassification metrics exceeding 90 %). These KPIs, and the relevant features\nin the decisions are textually explained by natural language expansion on an\nexplainability dashboard. These automatic explanations made it possible to\ninfer knowledge from expert workers for inexpert workers. The latter\nillustrates the interest of research in self-explainable ML for automatically\ngenerating insights to improve productivity in industrial workflows.",
      "tldr_zh": "本研究利用可解释 Machine Learning (ML) 自动生成工业工作流程中工人的关键绩效指标 (KPIs)，旨在评估和区分专家与非专家工人的生产力，以解决劳动力技能短缺问题。方法包括从制造机器捕获数据、存储于 NoSQL 数据库、进行特征工程和分类模型训练，所有分类指标均超过90%。通过解释性仪表板提供自然语言扩展的文本解释，这些洞见能从专家工人行为中提取知识，帮助非专家工人提升生产力，从而改善整体工业工作流程效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE Industrial Electronics Magazine (2023)",
      "pdf_url": "http://arxiv.org/pdf/2406.12732v1",
      "published_date": "2024-06-18 15:55:11 UTC",
      "updated_date": "2024-06-18 15:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:44:14.066286"
    },
    {
      "arxiv_id": "2406.12954v1",
      "title": "Skin Cancer Images Classification using Transfer Learning Techniques",
      "title_zh": "使用迁移学习技术的皮肤癌图像分类",
      "authors": [
        "Md Sirajul Islam",
        "Sanjeev Panta"
      ],
      "abstract": "Skin cancer is one of the most common and deadliest types of cancer. Early\ndiagnosis of skin cancer at a benign stage is critical to reducing cancer\nmortality. To detect skin cancer at an earlier stage an automated system is\ncompulsory that can save the life of many patients. Many previous studies have\naddressed the problem of skin cancer diagnosis using various deep learning and\ntransfer learning models. However, existing literature has limitations in its\naccuracy and time-consuming procedure. In this work, we applied five different\npre-trained transfer learning approaches for binary classification of skin\ncancer detection at benign and malignant stages. To increase the accuracy of\nthese models we fine-tune different layers and activation functions. We used a\npublicly available ISIC dataset to evaluate transfer learning approaches. For\nmodel stability, data augmentation techniques are applied to improve the\nrandomness of the input dataset. These approaches are evaluated using different\nhyperparameters such as batch sizes, epochs, and optimizers. The experimental\nresults show that the ResNet-50 model provides an accuracy of 0.935, F1-score\nof 0.86, and precision of 0.94.",
      "tldr_zh": "本文探讨了使用 transfer learning 技术对皮肤癌图像进行二元分类（良性 vs. 恶性），旨在实现早期诊断并解决现有方法的准确性和效率问题。作者应用五种预训练模型，通过 fine-tune 不同层和激活函数以及 data augmentation 技术来优化模型性能，并使用 ISIC dataset 评估各种超参数如 batch sizes、epochs 和 optimizers。实验结果表明，ResNet-50 模型达到了 0.935 的准确率、0.86 的 F1-score 和 0.94 的 precision，显著提升了皮肤癌检测的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12954v1",
      "published_date": "2024-06-18 15:48:20 UTC",
      "updated_date": "2024-06-18 15:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:44:26.307829"
    },
    {
      "arxiv_id": "2406.12725v1",
      "title": "Can Large Language Models Code Like a Linguist?: A Case Study in Low Resource Sound Law Induction",
      "title_zh": "大型语言模型能像语言学家一样编写代码吗？：低资源音律归纳的案例研究",
      "authors": [
        "Atharva Naik",
        "Kexun Zhang",
        "Nathaniel Robinson",
        "Aravind Mysore",
        "Clayton Marr",
        "Hong Sng",
        "Rebecca Byrnes",
        "Anna Cai",
        "Kalvin Chang",
        "David Mortensen"
      ],
      "abstract": "Historical linguists have long written a kind of incompletely formalized\n''program'' that converts reconstructed words in an ancestor language into\nwords in one of its attested descendants that consist of a series of ordered\nstring rewrite functions (called sound laws). They do this by observing pairs\nof words in the reconstructed language (protoforms) and the descendent language\n(reflexes) and constructing a program that transforms protoforms into reflexes.\nHowever, writing these programs is error-prone and time-consuming. Prior work\nhas successfully scaffolded this process computationally, but fewer researchers\nhave tackled Sound Law Induction (SLI), which we approach in this paper by\ncasting it as Programming by Examples. We propose a language-agnostic solution\nthat utilizes the programming ability of Large Language Models (LLMs) by\ngenerating Python sound law programs from sound change examples. We evaluate\nthe effectiveness of our approach for various LLMs, propose effective methods\nto generate additional language-agnostic synthetic data to fine-tune LLMs for\nSLI, and compare our method with existing automated SLI methods showing that\nwhile LLMs lag behind them they can complement some of their weaknesses.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否能像语言学家一样编写程序来处理低资源环境下的Sound Law Induction (SLI)，即从祖先语言的protoforms到后代语言的reflexes转换规则。作者将SLI视为Programming by Examples的任务，利用LLMs生成Python程序来自动推断这些字符串重写函数(sound laws)。通过生成额外的语言无关合成数据来微调LLMs，实验结果显示LLMs的表现虽落后于现有自动SLI方法，但能在某些弱点上提供互补优势，如更灵活的程序生成。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12725v1",
      "published_date": "2024-06-18 15:46:04 UTC",
      "updated_date": "2024-06-18 15:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:44:36.377258"
    },
    {
      "arxiv_id": "2406.12723v6",
      "title": "BIOSCAN-5M: A Multimodal Dataset for Insect Biodiversity",
      "title_zh": "BIOSCAN-5M：昆虫生物多样性的多",
      "authors": [
        "Zahra Gharaee",
        "Scott C. Lowe",
        "ZeMing Gong",
        "Pablo Millan Arias",
        "Nicholas Pellegrino",
        "Austin T. Wang",
        "Joakim Bruslund Haurum",
        "Iuliia Zarubiieva",
        "Lila Kari",
        "Dirk Steinke",
        "Graham W. Taylor",
        "Paul Fieguth",
        "Angel X. Chang"
      ],
      "abstract": "As part of an ongoing worldwide effort to comprehend and monitor insect\nbiodiversity, this paper presents the BIOSCAN-5M Insect dataset to the machine\nlearning community and establish several benchmark tasks. BIOSCAN-5M is a\ncomprehensive dataset containing multi-modal information for over 5 million\ninsect specimens, and it significantly expands existing image-based biological\ndatasets by including taxonomic labels, raw nucleotide barcode sequences,\nassigned barcode index numbers, geographical, and size information. We propose\nthree benchmark experiments to demonstrate the impact of the multi-modal data\ntypes on the classification and clustering accuracy. First, we pretrain a\nmasked language model on the DNA barcode sequences of the BIOSCAN-5M dataset,\nand demonstrate the impact of using this large reference library on species-\nand genus-level classification performance. Second, we propose a zero-shot\ntransfer learning task applied to images and DNA barcodes to cluster feature\nembeddings obtained from self-supervised learning, to investigate whether\nmeaningful clusters can be derived from these representation embeddings. Third,\nwe benchmark multi-modality by performing contrastive learning on DNA barcodes,\nimage data, and taxonomic information. This yields a general shared embedding\nspace enabling taxonomic classification using multiple types of information and\nmodalities. The code repository of the BIOSCAN-5M Insect dataset is available\nat https://github.com/bioscan-ml/BIOSCAN-5M.",
      "tldr_zh": "本研究介绍了 BIOSCAN-5M，这是一个包含超过 500 万个虫类样本的多模态数据集，包括图像、分类标签、原始核苷酸条码序列、条码索引号、地理信息和大小数据，从而扩展了现有的基于图像的生物数据集。研究者提出了三个基准实验：首先，在 DNA 条码序列上预训练 masked language model，以提升物种和属级分类性能；其次，进行零-shot transfer learning 任务，使用图像和 DNA 条码聚类自监督学习的特征嵌入；第三，通过 contrastive learning 整合 DNA 条码、图像和分类信息，创建共享嵌入空间以实现多模态分类。这些实验证明，多模态数据显著提高了分类和聚类准确性，为虫类生物多样性研究提供宝贵资源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.PE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12723v6",
      "published_date": "2024-06-18 15:45:21 UTC",
      "updated_date": "2025-03-01 00:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:44:49.231756"
    },
    {
      "arxiv_id": "2406.12719v2",
      "title": "On the Robustness of Language Models for Tabular Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Kushal Raj Bhandari",
        "Sixue Xing",
        "Soham Dan",
        "Jianxi Gao"
      ],
      "abstract": "Large Language Models (LLMs), already shown to ace various text comprehension\ntasks have also remarkably been shown to tackle table comprehension tasks\nwithout specific training. While previous research has explored LLM\ncapabilities with tabular dataset tasks, our study assesses the influence of\n\\textit{in-context learning}, \\textit{model scale}, \\textit{instruction\ntuning}, and \\textit{domain biases} on Tabular Question Answering (TQA). We\nevaluate the robustness of LLMs on Wikipedia-based \\textbf{WTQ}, financial\nreport-based \\textbf{TAT-QA}, and scientific claims-based \\textbf{SCITAB}, TQA\ndatasets, focusing on their ability to interpret tabular data under various\naugmentations and perturbations robustly. Our findings indicate that\ninstructions significantly enhance performance, with recent models exhibiting\ngreater robustness over earlier versions. However, data contamination and\npractical reliability issues persist, especially with \\textbf{WTQ}. We\nhighlight the need for improved methodologies, including structure-aware\nself-attention mechanisms and better handling of domain-specific tabular data,\nto develop more reliable LLMs for table comprehension.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在表格问题回答（TQA）中的鲁棒性，探讨了in-context learning、model scale、instruction tuning和domain biases等因素的影响。\n他们使用Wikipedia-based的WTQ、财务报告-based的TAT-QA以及科学声明-based的SCITAB数据集，通过各种数据增强和扰动测试LLMs解读表格的能力。\n结果表明，instruction tuning显著提升了模型性能，且较新版本的LLMs显示出更高的鲁棒性；然而，数据污染和实际可靠性问题依然存在，特别是WTQ数据集。\n论文强调需要改进方法，如引入structure-aware self-attention机制，以更好地处理领域特定表格数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12719v2",
      "published_date": "2024-06-18 15:41:15 UTC",
      "updated_date": "2025-03-21 00:31:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:45:02.927960"
    },
    {
      "arxiv_id": "2406.12718v3",
      "title": "Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbin An",
        "Feng Tian",
        "Sicong Leng",
        "Jiahao Nie",
        "Haonan Lin",
        "QianYing Wang",
        "Ping Chen",
        "Xiaoqin Zhang",
        "Shijian Lu"
      ],
      "abstract": "Despite great success across various multimodal tasks, Large Vision-Language\nModels (LVLMs) often encounter object hallucinations with generated textual\nresponses being inconsistent with the actual objects in images. We examine\ndifferent LVLMs and pinpoint that one root cause of object hallucinations lies\nwith deficient attention on discriminative image features. Specifically, LVLMs\noften predominantly attend to prompt-irrelevant global features instead of\nprompt-relevant local features, undermining their visual grounding capacity and\nleading to object hallucinations. We propose Assembly of Global and Local\nAttention (AGLA), a training-free and plug-and-play approach that mitigates\nhallucinations by assembling global features for response generation and local\nfeatures for visual discrimination simultaneously. Specifically, we introduce\nan image-prompt matching scheme that captures prompt-relevant local features\nfrom images, leading to an augmented view of the input image where\nprompt-relevant content is highlighted while irrelevant distractions are\nsuppressed. Hallucinations can thus be mitigated with a calibrated logit\ndistribution that is from generative global features of the original image and\ndiscriminative local features of the augmented image. Extensive experiments\nshow the superiority of AGLA in LVLM hallucination mitigation, demonstrating\nits wide applicability across both discriminative and generative tasks. Our\ncode is available at https://github.com/Lackel/AGLA.",
      "tldr_zh": "这项研究发现，大型视觉语言模型（Large Vision-Language Models, LVLMs）常因过度关注提示无关的全局特征而忽略提示相关的局部特征，导致对象幻觉（object hallucinations）。为了缓解这一问题，研究提出了一种无需训练的即插即用方法——Assembly of Global and Local Attention (AGLA)，通过组装全局特征用于响应生成和局部特征用于视觉鉴别，同时引入图像-提示匹配方案生成增强视图，以突出相关内容并抑制无关干扰。实验结果显示，AGLA 在鉴别和生成任务中显著降低了幻觉发生率，并证明了其广泛适用性，代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.12718v3",
      "published_date": "2024-06-18 15:38:41 UTC",
      "updated_date": "2025-03-14 04:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:45:13.476901"
    },
    {
      "arxiv_id": "2406.12709v2",
      "title": "Enhancing Spatio-temporal Quantile Forecasting with Curriculum Learning: Lessons Learned",
      "title_zh": "使用课程学习增强时空分位数预测：经验教训",
      "authors": [
        "Du Yin",
        "Jinliang Deng",
        "Shuang Ao",
        "Zechen Li",
        "Hao Xue",
        "Arian Prabowo",
        "Renhe Jiang",
        "Xuan Song",
        "Flora Salim"
      ],
      "abstract": "Training models on spatio-temporal (ST) data poses an open problem due to the\ncomplicated and diverse nature of the data itself, and it is challenging to\nensure the model's performance directly trained on the original ST data. While\nlimiting the variety of training data can make training easier, it can also\nlead to a lack of knowledge and information for the model, resulting in a\ndecrease in performance. To address this challenge, we presented an innovative\nparadigm that incorporates three separate forms of curriculum learning\nspecifically targeting from spatial, temporal, and quantile perspectives.\nFurthermore, our framework incorporates a stacking fusion module to combine\ndiverse information from three types of curriculum learning, resulting in a\nstrong and thorough learning process. We demonstrated the effectiveness of this\nframework with extensive empirical evaluations, highlighting its better\nperformance in addressing complex ST challenges. We provided thorough ablation\nstudies to investigate the effectiveness of our curriculum and to explain how\nit contributes to the improvement of learning efficiency on ST data.",
      "tldr_zh": "本研究针对spatio-temporal (ST) 数据训练模型的复杂性和多样性问题，提出了一种创新框架，利用curriculum learning从空间、时间和quantile视角进行三种形式的渐进式学习，以提升ST quantile forecasting的性能。该框架整合了一个stacking fusion模块，用于融合三种学习形式的信息，实现更全面的模型训练。通过广泛的实证评估和消融研究，证明了该方法在处理复杂ST挑战上显著优于基线模型，并解释了curriculum learning如何提高学习效率和整体效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accept by sigspatial 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12709v2",
      "published_date": "2024-06-18 15:23:10 UTC",
      "updated_date": "2024-09-16 14:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:45:24.818530"
    },
    {
      "arxiv_id": "2406.12707v1",
      "title": "Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction",
      "title_zh": "与类人代理对话：通过可感知的声学接收和反应实现移情对话",
      "authors": [
        "Haoqiu Yan",
        "Yongxin Zhu",
        "Kai Zheng",
        "Bing Liu",
        "Haoyu Cao",
        "Deqiang Jiang",
        "Linli Xu"
      ],
      "abstract": "Large Language Model (LLM)-enhanced agents become increasingly prevalent in\nHuman-AI communication, offering vast potential from entertainment to\nprofessional domains. However, current multi-modal dialogue systems overlook\nthe acoustic information present in speech, which is crucial for understanding\nhuman communication nuances. This oversight can lead to misinterpretations of\nspeakers' intentions, resulting in inconsistent or even contradictory responses\nwithin dialogues. To bridge this gap, in this paper, we propose\nPerceptiveAgent, an empathetic multi-modal dialogue system designed to discern\ndeeper or more subtle meanings beyond the literal interpretations of words\nthrough the integration of speech modality perception. Employing LLMs as a\ncognitive core, PerceptiveAgent perceives acoustic information from input\nspeech and generates empathetic responses based on speaking styles described in\nnatural language. Experimental results indicate that PerceptiveAgent excels in\ncontextual understanding by accurately discerning the speakers' true intentions\nin scenarios where the linguistic meaning is either contrary to or inconsistent\nwith the speaker's true feelings, producing more nuanced and expressive spoken\ndialogues. Code is publicly available at:\n\\url{https://github.com/Haoqiu-Yan/PerceptiveAgent}.",
      "tldr_zh": "该论文指出，现有的LLM增强代理在人-AI通信中常忽略语音中的声学信息，导致对说话者意图的误解和对话不一致。为解决这一问题，研究提出PerceptiveAgent，一个移情的多模态对话系统，通过整合语音模态感知和LLMs作为认知核心，感知输入语音的声学细节并基于自然语言描述的说话风格生成更精确的响应。实验结果显示，PerceptiveAgent在语言含义与真实感受不一致的场景中表现出色，能产生更细致且富有表现力的对话，代码已开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 3 figures, ACL24 accepted",
      "pdf_url": "http://arxiv.org/pdf/2406.12707v1",
      "published_date": "2024-06-18 15:19:51 UTC",
      "updated_date": "2024-06-18 15:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:45:37.420961"
    },
    {
      "arxiv_id": "2406.12698v1",
      "title": "Online-Adaptive Anomaly Detection for Defect Identification in Aircraft Assembly",
      "title_zh": "翻译失败",
      "authors": [
        "Siddhant Shete",
        "Dennis Mronga",
        "Ankita Jadhav",
        "Frank Kirchner"
      ],
      "abstract": "Anomaly detection deals with detecting deviations from established patterns\nwithin data. It has various applications like autonomous driving, predictive\nmaintenance, and medical diagnosis. To improve anomaly detection accuracy,\ntransfer learning can be applied to large, pre-trained models and adapt them to\nthe specific application context. In this paper, we propose a novel framework\nfor online-adaptive anomaly detection using transfer learning. The approach\nadapts to different environments by selecting visually similar training images\nand online fitting a normality model to EfficientNet features extracted from\nthe training subset. Anomaly detection is then performed by computing the\nMahalanobis distance between the normality model and the test image features.\nDifferent similarity measures (SIFT/FLANN, Cosine) and normality models (MVG,\nOCSVM) are employed and compared with each other. We evaluate the approach on\ndifferent anomaly detection benchmarks and data collected in controlled\nlaboratory settings. Experimental results showcase a detection accuracy\nexceeding 0.975, outperforming the state-of-the-art ET-NET approach.",
      "tldr_zh": "这篇论文提出了一种在线自适应异常检测框架，用于识别飞机组装中的缺陷，旨在通过 transfer learning 提升检测准确性。框架通过选择视觉相似的训练图像，并在 EfficientNet 特征基础上在线拟合 normality model，然后利用 Mahalanobis distance 计算测试图像与模型的距离来检测异常。实验比较了不同相似性测量（如 SIFT/FLANN 和 Cosine）以及 normality models（如 MVG 和 OCSVM），在各种基准和实验室数据上实现了超过 0.975 的检测准确率，优于现有 state-of-the-art ET-NET 方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "This is preprint for the accepted paper",
      "pdf_url": "http://arxiv.org/pdf/2406.12698v1",
      "published_date": "2024-06-18 15:11:44 UTC",
      "updated_date": "2024-06-18 15:11:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:45:50.059583"
    },
    {
      "arxiv_id": "2406.12693v2",
      "title": "XXLTraffic: Expanding and Extremely Long Traffic forecasting beyond test adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Du Yin",
        "Hao Xue",
        "Arian Prabowo",
        "Shuang Ao",
        "Flora Salim"
      ],
      "abstract": "Traffic forecasting is crucial for smart cities and intelligent\ntransportation initiatives, where deep learning has made significant progress\nin modeling complex spatio-temporal patterns in recent years. However, current\npublic datasets have limitations in reflecting the distribution shift nature of\nreal-world scenarios, characterized by continuously evolving infrastructures,\nvarying temporal distributions, and long temporal gaps due to sensor downtimes\nor changes in traffic patterns. These limitations inevitably restrict the\npractical applicability of existing traffic forecasting datasets. To bridge\nthis gap, we present XXLTraffic, largest available public traffic dataset with\nthe longest timespan collected from Los Angeles, USA, and New South Wales,\nAustralia, curated to support research in extremely long forecasting beyond\ntest adaptation. Our benchmark includes both typical time-series forecasting\nsettings with hourly and daily aggregated data and novel configurations that\nintroduce gaps and down-sample the training size to better simulate practical\nconstraints. We anticipate the new XXLTraffic will provide a fresh perspective\nfor the time-series and traffic forecasting communities. It would also offer a\nrobust platform for developing and evaluating models designed to tackle the\nextremely long forecasting problems beyond test adaptation. Our dataset\nsupplements existing spatio-temporal data resources and leads to new research\ndirections in this domain.",
      "tldr_zh": "该研究指出，现有的交通预测数据集无法有效处理真实场景中的分布偏移问题，如基础设施演变、时间分布变化和长时隙，从而限制了模型的实际应用。为此，研究团队推出了 XXLTraffic，这是目前最大的公共交通数据集，从美国洛杉矶和澳大利亚新南威尔士收集，时间跨度最长，并支持极长预测研究。数据集包括典型的时间序列预测设置（如小时和每日聚合数据）以及创新配置（如引入数据间隙和减少训练样本），以模拟实际约束。该数据集将为时间序列和交通预测社区提供新视角，补充现有 spatio-temporal 数据资源，并推动开发超越 test adaptation 的鲁棒模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12693v2",
      "published_date": "2024-06-18 15:06:22 UTC",
      "updated_date": "2025-03-25 05:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:46:01.905117"
    },
    {
      "arxiv_id": "2406.12692v3",
      "title": "MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Arian Askari",
        "Christian Poelitz",
        "Xinye Tang"
      ],
      "abstract": "Self-correction in text-to-SQL is the process of prompting large language\nmodel (LLM) to revise its previously incorrectly generated SQL, and commonly\nrelies on manually crafted self-correction guidelines by human experts that are\nnot only labor-intensive to produce but also limited by the human ability in\nidentifying all potential error patterns in LLM responses. We introduce MAGIC,\na novel multi-agent method that automates the creation of the self-correction\nguideline. MAGIC uses three specialized agents: a manager, a correction, and a\nfeedback agent. These agents collaborate on the failures of an LLM-based method\non the training set to iteratively generate and refine a self-correction\nguideline tailored to LLM mistakes, mirroring human processes but without human\ninvolvement. Our extensive experiments show that MAGIC's guideline outperforms\nexpert human's created ones. We empirically find out that the guideline\nproduced by MAGIC enhances the interpretability of the corrections made,\nproviding insights in analyzing the reason behind the failures and successes of\nLLMs in self-correction. All agent interactions are publicly available at\nhttps://huggingface.co/datasets/microsoft/MAGIC.",
      "tldr_zh": "本论文提出 MAGIC，一种多智能体方法，用于自动化生成 In-Context Text-to-SQL 的自校正指南，以解决传统依赖人工创建指南的劳动密集和局限问题。MAGIC 包括 manager、correction 和 feedback 三个专门代理，这些代理协作分析 LLM 在训练集上的失败案例，迭代生成和完善指南。实验结果显示，MAGIC 生成的指南优于人类专家创建的指南，并提升了校正过程的可解释性，帮助分析 LLM 自校正中的失败和成功原因。所有代理互动数据已公开在 Hugging Face 上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Proceedings of the Thirty-Ninth AAAI Conference on\n  Artificial Intelligence (AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2406.12692v3",
      "published_date": "2024-06-18 15:06:06 UTC",
      "updated_date": "2024-12-21 16:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:46:14.723688"
    },
    {
      "arxiv_id": "2406.12952v3",
      "title": "SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents",
      "title_zh": "SWT-Bench：使用代码代理测试和验证真实世界的 bug 修复",
      "authors": [
        "Niels Mündler",
        "Mark Niklas Müller",
        "Jingxuan He",
        "Martin Vechev"
      ],
      "abstract": "Rigorous software testing is crucial for developing and maintaining\nhigh-quality code, making automated test generation a promising avenue for both\nimproving software quality and boosting the effectiveness of code generation\nmethods. However, while code generation with Large Language Models (LLMs) is an\nextraordinarily active research area, test generation remains relatively\nunexplored. We address this gap and investigate the capability of LLM-based\nCode Agents to formalize user issues into test cases. To this end, we propose a\nnovel benchmark based on popular GitHub repositories, containing real-world\nissues, ground-truth bug-fixes, and golden tests. We find that LLMs generally\nperform surprisingly well at generating relevant test cases, with Code Agents\ndesigned for code repair exceeding the performance of systems designed\nspecifically for test generation. Further, as test generation is a similar but\nmore structured task than code generation, it allows for a more fine-grained\nanalysis using issue reproduction rate and coverage changes, providing a dual\nmetric for analyzing systems designed for code repair. Finally, we find that\ngenerated tests are an effective filter for proposed code fixes, doubling the\nprecision of SWE-Agent. We release all data and code at\nhttps://github.com/logic-star-ai/SWT-Bench",
      "tldr_zh": "这篇论文提出了SWT-Bench，一个基于热门GitHub仓库的基准，用于测试和验证基于Large Language Models (LLMs)的Code Agents处理真实bug修复的能力。该基准包含真实问题、ground-truth修复和黄金测试，评估了LLMs将用户问题形式化为测试用例的性能。研究发现，设计用于代码修复的Code Agents在测试生成上优于专用系统，并通过问题重现率和覆盖率变化提供更细粒度的分析；此外，生成的测试用例能有效过滤代码修复建议，将SWE-Agent的精确度提高一倍。论文发布了所有数据和代码，以促进进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "20 pages, 14 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.12952v3",
      "published_date": "2024-06-18 14:54:37 UTC",
      "updated_date": "2025-02-07 12:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:46:26.591307"
    },
    {
      "arxiv_id": "2406.12672v1",
      "title": "Sparsifying dimensionality reduction of PDE solution data with Bregman learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tjeerd Jan Heeringa",
        "Christoph Brune",
        "Mengwu Guo"
      ],
      "abstract": "Classical model reduction techniques project the governing equations onto a\nlinear subspace of the original state space. More recent data-driven techniques\nuse neural networks to enable nonlinear projections. Whilst those often enable\nstronger compression, they may have redundant parameters and lead to suboptimal\nlatent dimensionality. To overcome these, we propose a multistep algorithm that\ninduces sparsity in the encoder-decoder networks for effective reduction in the\nnumber of parameters and additional compression of the latent space. This\nalgorithm starts with sparsely initialized a network and training it using\nlinearized Bregman iterations. These iterations have been very successful in\ncomputer vision and compressed sensing tasks, but have not yet been used for\nreduced-order modelling. After the training, we further compress the latent\nspace dimensionality by using a form of proper orthogonal decomposition. Last,\nwe use a bias propagation technique to change the induced sparsity into an\neffective reduction of parameters. We apply this algorithm to three\nrepresentative PDE models: 1D diffusion, 1D advection, and 2D\nreaction-diffusion. Compared to conventional training methods like Adam, the\nproposed method achieves similar accuracy with 30% less parameters and a\nsignificantly smaller latent space.",
      "tldr_zh": "这篇论文提出了一种使用Bregman learning的多步算法，来稀疏化PDE解决方案数据的维度减少，从而减少冗余参数和优化潜在空间。该算法从稀疏初始化的encoder-decoder networks开始，通过线性Bregman迭代训练网络，然后应用proper orthogonal decomposition进一步压缩潜在空间维度，最后使用bias propagation技术实现参数有效减少。在1D diffusion、1D advection和2D reaction-diffusion等PDE模型上测试，结果显示该方法与Adam等传统训练方法相比，达到类似准确度，但参数减少30%，并显著缩小潜在空间。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "stat.ML",
        "65K10 (Primary) 68T07, 65D99, 41A63 (Secondary)",
        "G.1.6; I.2.6"
      ],
      "primary_category": "math.NA",
      "comment": "27 pages, 20 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.12672v1",
      "published_date": "2024-06-18 14:45:30 UTC",
      "updated_date": "2024-06-18 14:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:46:37.939223"
    },
    {
      "arxiv_id": "2406.12670v2",
      "title": "Stealth edits to large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver J. Sutton",
        "Qinghua Zhou",
        "Wei Wang",
        "Desmond J. Higham",
        "Alexander N. Gorban",
        "Alexander Bastounis",
        "Ivan Y. Tyukin"
      ],
      "abstract": "We reveal the theoretical foundations of techniques for editing large\nlanguage models, and present new methods which can do so without requiring\nretraining. Our theoretical insights show that a single metric (a measure of\nthe intrinsic dimension of the model's features) can be used to assess a\nmodel's editability and reveals its previously unrecognised susceptibility to\nmalicious stealth attacks. This metric is fundamental to predicting the success\nof a variety of editing approaches, and reveals new bridges between disparate\nfamilies of editing methods. We collectively refer to these as stealth editing\nmethods, because they directly update a model's weights to specify its response\nto specific known hallucinating prompts without affecting other model\nbehaviour. By carefully applying our theoretical insights, we are able to\nintroduce a new jet-pack network block which is optimised for highly selective\nmodel editing, uses only standard network operations, and can be inserted into\nexisting networks. We also reveal the vulnerability of language models to\nstealth attacks: a small change to a model's weights which fixes its response\nto a single attacker-chosen prompt. Stealth attacks are computationally simple,\ndo not require access to or knowledge of the model's training data, and\ntherefore represent a potent yet previously unrecognised threat to\nredistributed foundation models. Extensive experimental results illustrate and\nsupport our methods and their theoretical underpinnings. Demos and source code\nare available at https://github.com/qinghua-zhou/stealth-edits.",
      "tldr_zh": "本研究揭示了编辑大型语言模型（large language models）的理论基础，并提出无需重新训练的新方法。研究引入一个单一指标——模型特征的内在维度（intrinsic dimension）——用于评估模型的可编辑性和对恶意攻击的易感性，并桥接了不同编辑方法家族。这些方法统称为“stealth editing”，能直接更新模型权重，仅针对特定幻觉提示而不影响其他行为，同时开发了一个优化的“jet-pack network block”，使用标准网络操作便于插入现有网络。实验结果证实了这些方法的有效性，并强调语言模型对“stealth attacks”的脆弱性，这种攻击计算简单、不需训练数据，构成对重新分发模型的潜在威胁。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68T07, 68T50, 68W40",
        "I.2.7; F.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 14 figures. Open source implementation:\n  https://github.com/qinghua-zhou/stealth-edits",
      "pdf_url": "http://arxiv.org/pdf/2406.12670v2",
      "published_date": "2024-06-18 14:43:18 UTC",
      "updated_date": "2024-10-30 10:12:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:46:50.005043"
    },
    {
      "arxiv_id": "2406.12665v3",
      "title": "CollabStory: Multi-LLM Collaborative Story Generation and Authorship Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Saranya Venkatraman",
        "Nafis Irtiza Tripto",
        "Dongwon Lee"
      ],
      "abstract": "The rise of unifying frameworks that enable seamless interoperability of\nLarge Language Models (LLMs) has made LLM-LLM collaboration for open-ended\ntasks a possibility. Despite this, there have not been efforts to explore such\ncollaborative writing. We take the next step beyond human-LLM collaboration to\nexplore this multi-LLM scenario by generating the first exclusively\nLLM-generated collaborative stories dataset called CollabStory. We focus on\nsingle-author to multi-author (up to 5 LLMs) scenarios, where multiple LLMs\nco-author stories. We generate over 32k stories using open-source\ninstruction-tuned LLMs. Further, we take inspiration from the PAN tasks that\nhave set the standard for human-human multi-author writing tasks and analysis.\nWe extend their authorship-related tasks for multi-LLM settings and present\nbaselines for LLM-LLM collaboration. We find that current baselines are not\nable to handle this emerging scenario. Thus, CollabStory is a resource that\ncould help propel an understanding as well as the development of new techniques\nto discern the use of multiple LLMs. This is crucial to study in the context of\nwriting tasks since LLM-LLM collaboration could potentially overwhelm ongoing\nchallenges related to plagiarism detection, credit assignment, maintaining\nacademic integrity in educational settings, and addressing copyright\ninfringement concerns. We make our dataset and code available at\nhttps://github.com/saranya-venkatraman/CollabStory.",
      "tldr_zh": "本文提出 CollabStory 数据集，这是首个完全由多个 Large Language Models (LLMs) 协作生成的故事数据集，涵盖从单作者到五作者场景，共生成超过 32k 故事。研究借鉴 PAN tasks 的多作者写作分析框架，扩展到多 LLM 设置并提供基线，但发现现有基线无法有效处理这种协作。CollabStory 有助于开发新技巧识别 LLM 协作，从而解决抄袭检测、信用分配、学术诚信和版权问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL Findings 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.12665v3",
      "published_date": "2024-06-18 14:35:12 UTC",
      "updated_date": "2025-02-11 02:09:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:47:03.208774"
    },
    {
      "arxiv_id": "2406.12663v1",
      "title": "Do More Details Always Introduce More Hallucinations in LVLM-based Image Captioning?",
      "title_zh": "翻译失败",
      "authors": [
        "Mingqian Feng",
        "Yunlong Tang",
        "Zeliang Zhang",
        "Chenliang Xu"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) excel in integrating visual and\nlinguistic contexts to produce detailed content, facilitating applications such\nas image captioning. However, using LVLMs to generate descriptions often faces\nthe challenge of object hallucination (OH), where the output text misrepresents\nactual objects in the input image. While previous studies attribute the\noccurrence of OH to the inclusion of more details, our study finds technical\nflaws in existing metrics, leading to unreliable evaluations of models and\nconclusions about OH. This has sparked a debate on the question: Do more\ndetails always introduce more hallucinations in LVLM-based image captioning?\n  In this paper, we address this debate by proposing a novel decoding strategy,\nDifferentiated Beam Decoding (DBD), along with a reliable new set of evaluation\nmetrics: CLIP-Precision, CLIP-Recall, and CLIP-F1. DBD decodes the wealth of\ninformation hidden in visual input into distinct language representations\ncalled unit facts in parallel. This decoding is achieved via a well-designed\ndifferential score that guides the parallel search and candidate screening. The\nselected unit facts are then aggregated to generate the final caption. Our\nproposed metrics evaluate the comprehensiveness and accuracy of image captions\nby comparing the embedding groups of ground-truth image regions and generated\ntext partitions. Extensive experiments on the Visual Genome dataset validate\nthe effectiveness of our approach, demonstrating that it produces detailed\ndescriptions while maintaining low hallucination levels.",
      "tldr_zh": "本文研究了在 Large Vision-Language Models (LVLMs) 基于图像描述中，是否更多细节总是导致更多 object hallucination (OH)，并指出现有评估指标存在技术缺陷，导致结论不可靠。论文提出了一种新解码策略 Differentiated Beam Decoding (DBD)，通过差分评分引导并行搜索和候选筛选，将视觉输入分解为独立的 unit facts，并聚合生成最终标题，以平衡细节丰富度和准确性。同时，引入新的评估指标 CLIP-Precision、CLIP-Recall 和 CLIP-F1，通过比较 ground-truth 图像区域和生成文本的嵌入组，来评估标题的全面性和精确度。在 Visual Genome 数据集上的实验验证了该方法的有效性，证明更多细节并不必然增加幻觉，而是能实现详细描述的同时保持低幻觉水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12663v1",
      "published_date": "2024-06-18 14:33:56 UTC",
      "updated_date": "2024-06-18 14:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:47:15.752230"
    },
    {
      "arxiv_id": "2406.12660v1",
      "title": "Investigating the Role of Explainability and AI Literacy in User Compliance",
      "title_zh": "探究可解释性和人工智能素养在用户遵守中的作用",
      "authors": [
        "Niklas Kühl",
        "Christian Meske",
        "Maximilian Nitsche",
        "Jodie Lobana"
      ],
      "abstract": "AI is becoming increasingly common across different domains. However, as\nsophisticated AI-based systems are often black-boxed, rendering the\ndecision-making logic opaque, users find it challenging to comply with their\nrecommendations. Although researchers are investigating Explainable AI (XAI) to\nincrease the transparency of the underlying machine learning models, it is\nunclear what types of explanations are effective and what other factors\nincrease compliance. To better understand the interplay of these factors, we\nconducted an experiment with 562 participants who were presented with the\nrecommendations of an AI and two different types of XAI. We find that users'\ncompliance increases with the introduction of XAI but is also affected by AI\nliteracy. We also find that the relationships between AI literacy XAI and\nusers' compliance are mediated by the users' mental model of AI. Our study has\nseveral implications for successfully designing AI-based systems utilizing XAI.",
      "tldr_zh": "本研究调查了可解释AI (Explainable AI, XAI) 和 AI 素养 (AI Literacy) 在用户遵守 AI 推荐中的作用，针对 AI 系统黑盒化导致的透明度问题。研究者通过一项实验，涉及 562 名参与者并测试两种不同类型的 XAI，发现引入 XAI 可以显著提高用户遵守度，而 AI 素养也会对遵守行为产生影响。结果显示，AI 素养与 XAI 之间的关系通过用户的 AI 心理模型 (mental model of AI) 进行中介，为设计更有效的 AI 系统提供了关键启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12660v1",
      "published_date": "2024-06-18 14:28:12 UTC",
      "updated_date": "2024-06-18 14:28:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:47:25.824828"
    },
    {
      "arxiv_id": "2407.02508v2",
      "title": "Sample-efficient Imitative Multi-token Decision Transformer for Real-world Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Zhou",
        "Dan Xu",
        "Yiding Ji"
      ],
      "abstract": "Recent advancements in autonomous driving technologies involve the capability\nto effectively process and learn from extensive real-world driving data.\nCurrent imitation learning and offline reinforcement learning methods have\nshown remarkable promise in autonomous systems, harnessing the power of offline\ndatasets to make informed decisions in open-loop (non-reactive agents)\nsettings. However, learning-based agents face significant challenges when\ntransferring knowledge from open-loop to closed-loop (reactive agents)\nenvironment. The performance is significantly impacted by data distribution\nshift, sample efficiency, the complexity of uncovering hidden world models and\nphysics. To address these issues, we propose Sample-efficient Imitative\nMulti-token Decision Transformer (SimDT). SimDT introduces multi-token\nprediction, online imitative learning pipeline and prioritized experience\nreplay to sequence-modelling reinforcement learning. The performance is\nevaluated through empirical experiments and results exceed popular imitation\nand reinforcement learning algorithms both in open-loop and closed-loop\nsettings on Waymax benchmark. SimDT exhibits 41% reduction in collision rate\nand 18% improvement in reaching the destination compared with the baseline\nmethod.",
      "tldr_zh": "该研究针对自动驾驶系统中从开放循环（open-loop）到封闭循环（closed-loop）环境的知识转移挑战，提出了一种Sample-efficient Imitative Multi-token Decision Transformer (SimDT)方法，以提升样本效率和性能稳定性。SimDT 通过引入多标记预测（multi-token prediction）、在线模仿学习（online imitative learning）管道和优先经验回放（priorized experience replay）集成到序列建模强化学习中，解决了数据分布偏移和隐藏世界模型的复杂性问题。在Waymax基准上的实验显示，SimDT在开放和封闭循环设置中优于现有模仿和强化学习算法，实现了碰撞率降低41%和到达目的地成功率提高18%。这为真实世界驾驶场景的决策学习提供了更高效的框架。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02508v2",
      "published_date": "2024-06-18 14:27:14 UTC",
      "updated_date": "2024-10-04 03:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:47:39.203998"
    },
    {
      "arxiv_id": "2406.12655v1",
      "title": "Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review",
      "title_zh": "翻译失败",
      "authors": [
        "Debalina Ghosh Paul",
        "Hong Zhu",
        "Ian Bayley"
      ],
      "abstract": "With the rapid development of Large Language Models (LLMs), a large number of\nmachine learning models have been developed to assist programming tasks\nincluding the generation of program code from natural language input. However,\nhow to evaluate such LLMs for this task is still an open problem despite of the\ngreat amount of research efforts that have been made and reported to evaluate\nand compare them. This paper provides a critical review of the existing work on\nthe testing and evaluation of these tools with a focus on two key aspects: the\nbenchmarks and the metrics used in the evaluations. Based on the review,\nfurther research directions are discussed.",
      "tldr_zh": "这篇论文对代码生成模型的评估基准（benchmarks）和指标（metrics）进行了批判性审视，聚焦于Large Language Models (LLMs)在从自然语言生成程序代码方面的应用。尽管已有大量研究，但评估这些模型的方法仍是一个开放问题。论文回顾了现有工作的关键方面，并基于此讨论了未来研究方向，以推动更可靠的评估框架。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by the First IEEE International Workshop on Testing and\n  Evaluation of Large Language Models (TELLMe 2024) and will be published in\n  the proceedings of the IEEE AITest 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2406.12655v1",
      "published_date": "2024-06-18 14:25:34 UTC",
      "updated_date": "2024-06-18 14:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:47:49.888962"
    },
    {
      "arxiv_id": "2407.16896v1",
      "title": "Free to play: UN Trade and Development's experience with developing its own open-source Retrieval Augmented Generation Large Language Model application",
      "title_zh": "Free to",
      "authors": [
        "Daniel Hopp"
      ],
      "abstract": "Generative artificial intelligence (AI), and in particular Large Language\nModels (LLMs), have exploded in popularity and attention since the release to\nthe public of ChatGPT's Generative Pre-trained Transformer (GPT)-3.5 model in\nNovember of 2022. Due to the power of these general purpose models and their\nability to communicate in natural language, they can be useful in a range of\ndomains, including the work of official statistics and international\norganizations. However, with such a novel and seemingly complex technology, it\ncan feel as if generative AI is something that happens to an organization,\nsomething that can be talked about but not understood, that can be commented on\nbut not contributed to. Additionally, the costs of adoption and operation of\nproprietary solutions can be both uncertain and high, a barrier for often\ncost-constrained international organizations. In the face of these challenges,\nUnited Nations Trade and Development (UNCTAD), through its Global Crisis\nResponse Group (GCRG), has explored and developed its own open-source Retrieval\nAugmented Generation (RAG) LLM application. RAG makes LLMs aware of and more\nuseful for the organization's domain and work. Developing in-house solutions\ncomes with pros and cons, with pros including cost, flexibility, and fostering\ninstitutional knowledge. Cons include time and skill investments and gaps and\napplication polish and power. The three libraries developed to produce the app,\nnlp_pipeline for document processing and statistical analysis, local_rag_llm\nfor running a local RAG LLM, and streamlit_rag for the user interface, are\npublicly available on PyPI and GitHub with Dockerfiles. A fourth library,\nlocal_llm_finetune, is also available for fine-tuning existing LLMs which can\nthen be used in the application.",
      "tldr_zh": "联合国贸易和发展会议 (UNCTAD) 分享了开发开源 Retrieval Augmented Generation (RAG) Large Language Models (LLMs) 应用的经验，以应对 generative AI 在国际组织中的复杂性和高成本挑战。该应用通过 RAG 技术增强 LLMs 对组织特定领域的适应性，并公开了三个库：nlp_pipeline 用于文档处理和统计分析、local_rag_llm 用于运行本地 RAG LLM，以及 streamlit_rag 用于用户界面。开发内部解决方案的优势包括降低成本、提高灵活性和积累机构知识，但缺点在于需要大量时间和技能投资。此外，一个名为 local_llm_finetune 的库也提供，用于微调现有 LLMs，进一步提升应用功能。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16896v1",
      "published_date": "2024-06-18 14:23:54 UTC",
      "updated_date": "2024-06-18 14:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:48:04.073981"
    },
    {
      "arxiv_id": "2406.12651v1",
      "title": "Transforming Surgical Interventions with Embodied Intelligence for Ultrasound Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Huan Xu",
        "Jinlin Wu",
        "Guanglin Cao",
        "Zhen Chen",
        "Zhen Lei",
        "Hongbin Liu"
      ],
      "abstract": "Ultrasonography has revolutionized non-invasive diagnostic methodologies,\nsignificantly enhancing patient outcomes across various medical domains.\nDespite its advancements, integrating ultrasound technology with robotic\nsystems for automated scans presents challenges, including limited command\nunderstanding and dynamic execution capabilities. To address these challenges,\nthis paper introduces a novel Ultrasound Embodied Intelligence system that\nsynergistically combines ultrasound robots with large language models (LLMs)\nand domain-specific knowledge augmentation, enhancing ultrasound robots'\nintelligence and operational efficiency. Our approach employs a dual strategy:\nfirstly, integrating LLMs with ultrasound robots to interpret doctors' verbal\ninstructions into precise motion planning through a comprehensive understanding\nof ultrasound domain knowledge, including APIs and operational manuals;\nsecondly, incorporating a dynamic execution mechanism, allowing for real-time\nadjustments to scanning plans based on patient movements or procedural errors.\nWe demonstrate the effectiveness of our system through extensive experiments,\nincluding ablation studies and comparisons across various models, showcasing\nsignificant improvements in executing medical procedures from verbal commands.\nOur findings suggest that the proposed system improves the efficiency and\nquality of ultrasound scans and paves the way for further advancements in\nautonomous medical scanning technologies, with the potential to transform\nnon-invasive diagnostics and streamline medical workflows.",
      "tldr_zh": "该论文解决了超声机器人系统在自动化扫描中的挑战，如指令理解和动态执行限制，提出了一种新型 Ultrasound Embodied Intelligence 系统，将超声机器人与大型语言模型 (LLMs) 相结合，并融入领域特定知识增强。系统采用双重策略：首先，通过 LLMs 解读医生的口头指令并将其转化为精确的动作规划，利用 APIs 和操作手册等知识；其次，引入动态执行机制，实现实时调整扫描计划以应对患者移动或错误。实验结果显示，该系统显著提高了医疗程序的执行效率和质量，并在消融研究中证明其优势，为自主医疗扫描技术的发展提供了新路径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been accepted by MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12651v1",
      "published_date": "2024-06-18 14:22:16 UTC",
      "updated_date": "2024-06-18 14:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:48:14.098329"
    },
    {
      "arxiv_id": "2406.12649v3",
      "title": "Probabilistic Conceptual Explainers: Trustworthy Conceptual Explanations for Vision Foundation Models",
      "title_zh": "概率概念解释器：视觉基础模型的可信概念解释",
      "authors": [
        "Hengyi Wang",
        "Shiwei Tan",
        "Hao Wang"
      ],
      "abstract": "Vision transformers (ViTs) have emerged as a significant area of focus,\nparticularly for their capacity to be jointly trained with large language\nmodels and to serve as robust vision foundation models. Yet, the development of\ntrustworthy explanation methods for ViTs has lagged, particularly in the\ncontext of post-hoc interpretations of ViT predictions. Existing sub-image\nselection approaches, such as feature-attribution and conceptual models, fall\nshort in this regard. This paper proposes five desiderata for explaining ViTs\n-- faithfulness, stability, sparsity, multi-level structure, and parsimony --\nand demonstrates the inadequacy of current methods in meeting these criteria\ncomprehensively. We introduce a variational Bayesian explanation framework,\ndubbed ProbAbilistic Concept Explainers (PACE), which models the distributions\nof patch embeddings to provide trustworthy post-hoc conceptual explanations.\nOur qualitative analysis reveals the distributions of patch-level concepts,\nelucidating the effectiveness of ViTs by modeling the joint distribution of\npatch embeddings and ViT's predictions. Moreover, these patch-level\nexplanations bridge the gap between image-level and dataset-level explanations,\nthus completing the multi-level structure of PACE. Through extensive\nexperiments on both synthetic and real-world datasets, we demonstrate that PACE\nsurpasses state-of-the-art methods in terms of the defined desiderata.",
      "tldr_zh": "这篇论文针对Vision Transformers (ViTs) 在视觉基础模型中的解释问题，提出了五个关键标准（desiderata）：faithfulness、stability、sparsity、multi-level structure 和 parsimony，以评估现有解释方法的不足，如feature-attribution和conceptual models。作者引入了ProbAbilistic Concept Explainers (PACE)，一个基于variational Bayesian框架的模型，通过建模patch embeddings的分布，提供可信的post-hoc概念解释，并实现从patch-level到数据集-level的多级结构。实验结果显示，PACE在合成和真实数据集上超越了最先进方法，在上述标准上表现出色，从而提升了ViTs的可解释性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 41st International Conference on Machine Learning\n  (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.12649v3",
      "published_date": "2024-06-18 14:17:57 UTC",
      "updated_date": "2024-10-31 19:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:48:27.760772"
    },
    {
      "arxiv_id": "2406.12646v1",
      "title": "An Empirical Study on the Fairness of Foundation Models for Multi-Organ Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Qin Li",
        "Yizhe Zhang",
        "Yan Li",
        "Jun Lyu",
        "Meng Liu",
        "Longyu Sun",
        "Mengting Sun",
        "Qirong Li",
        "Wenyue Mao",
        "Xinran Wu",
        "Yajing Zhang",
        "Yinghua Chu",
        "Shuo Wang",
        "Chengyan Wang"
      ],
      "abstract": "The segmentation foundation model, e.g., Segment Anything Model (SAM), has\nattracted increasing interest in the medical image community. Early pioneering\nstudies primarily concentrated on assessing and improving SAM's performance\nfrom the perspectives of overall accuracy and efficiency, yet little attention\nwas given to the fairness considerations. This oversight raises questions about\nthe potential for performance biases that could mirror those found in\ntask-specific deep learning models like nnU-Net. In this paper, we explored the\nfairness dilemma concerning large segmentation foundation models. We\nprospectively curate a benchmark dataset of 3D MRI and CT scans of the organs\nincluding liver, kidney, spleen, lung and aorta from a total of 1056 healthy\nsubjects with expert segmentations. Crucially, we document demographic details\nsuch as gender, age, and body mass index (BMI) for each subject to facilitate a\nnuanced fairness analysis. We test state-of-the-art foundation models for\nmedical image segmentation, including the original SAM, medical SAM and SAT\nmodels, to evaluate segmentation efficacy across different demographic groups\nand identify disparities. Our comprehensive analysis, which accounts for\nvarious confounding factors, reveals significant fairness concerns within these\nfoundational models. Moreover, our findings highlight not only disparities in\noverall segmentation metrics, such as the Dice Similarity Coefficient but also\nsignificant variations in the spatial distribution of segmentation errors,\noffering empirical evidence of the nuanced challenges in ensuring fairness in\nmedical image segmentation.",
      "tldr_zh": "该研究通过实证分析探讨了基础模型（如 Segment Anything Model (SAM)）在多器官图像分割任务中的公平性问题，填补了先前专注于准确性和效率的空白。作者构建了一个基准数据集，包括1056个健康受试者的3D MRI和CT扫描，涵盖肝脏、肾脏、脾脏、肺和主动脉，并记录了性别、年龄和BMI等人口统计信息。测试了SAM、Medical SAM和SAT等模型后，发现这些模型在不同群体间存在显著性能差异，不仅体现在Dice Similarity Coefficient等整体指标上，还包括分割错误的空间分布不均。该研究强调了确保医疗图像分割公平性的复杂挑战，为未来模型优化提供了重要启示。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted to MICCAI-2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12646v1",
      "published_date": "2024-06-18 14:14:04 UTC",
      "updated_date": "2024-06-18 14:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:48:38.635801"
    },
    {
      "arxiv_id": "2406.12645v3",
      "title": "Evaluating Evidence Attribution in Generated Fact Checking Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Xing",
        "Timothy Baldwin",
        "Jey Han Lau"
      ],
      "abstract": "Automated fact-checking systems often struggle with trustworthiness, as their\ngenerated explanations can include hallucinations. In this work, we explore\nevidence attribution for fact-checking explanation generation. We introduce a\nnovel evaluation protocol -- citation masking and recovery -- to assess\nattribution quality in generated explanations. We implement our protocol using\nboth human annotators and automatic annotators, and find that LLM annotation\ncorrelates with human annotation, suggesting that attribution assessment can be\nautomated. Finally, our experiments reveal that: (1) the best-performing LLMs\nstill generate explanations with inaccurate attributions; and (2) human-curated\nevidence is essential for generating better explanations. Code and data are\navailable here: https://github.com/ruixing76/Transparent-FCExp.",
      "tldr_zh": "本文评估了生成的事实检查解释中的证据归因（evidence attribution），旨在解决自动事实检查系统可能产生的幻觉（hallucinations）问题。研究引入了新的评估协议——引用屏蔽和恢复（citation masking and recovery），并通过人类注释者和LLM自动注释者实施，发现LLM注释与人类注释高度相关，从而支持归因评估的自动化。实验结果表明，即使是表现最好的LLMs，生成的解释仍存在不准确归因的问题，而使用人类策划的证据能显著提升解释质量。代码和数据已在GitHub上开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2406.12645v3",
      "published_date": "2024-06-18 14:13:13 UTC",
      "updated_date": "2025-02-11 16:36:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:48:51.401152"
    },
    {
      "arxiv_id": "2406.12644v4",
      "title": "Hierarchical Prompting Taxonomy: A Universal Evaluation Framework for Large Language Models Aligned with Human Cognitive Principles",
      "title_zh": "翻译失败",
      "authors": [
        "Devichand Budagam",
        "Ashutosh Kumar",
        "Mahsa Khoshnoodi",
        "Sankalp KJ",
        "Vinija Jain",
        "Aman Chadha"
      ],
      "abstract": "Assessing the effectiveness of large language models (LLMs) in performing\ndifferent tasks is crucial for understanding their strengths and weaknesses.\nThis paper presents Hierarchical Prompting Taxonomy (HPT), grounded on human\ncognitive principles and designed to assess LLMs by examining the cognitive\ndemands of various tasks. The HPT utilizes the Hierarchical Prompting Framework\n(HPF), which structures five unique prompting strategies in a hierarchical\norder based on their cognitive requirement on LLMs when compared to human\nmental capabilities. It assesses the complexity of tasks with the Hierarchical\nPrompting Index (HPI), which demonstrates the cognitive competencies of LLMs\nacross diverse datasets and offers insights into the cognitive demands that\ndatasets place on different LLMs. This approach enables a comprehensive\nevaluation of an LLMs problem solving abilities and the intricacy of a dataset,\noffering a standardized metric for task complexity. Extensive experiments with\nmultiple datasets and LLMs show that HPF enhances LLM performance by 2% to 63%\ncompared to baseline performance, with GSM8k being the most cognitively complex\ntask among reasoning and coding tasks with an average HPI of 3.20 confirming\nthe effectiveness of HPT. To support future research and reproducibility in\nthis domain, the implementations of HPT and HPF are available here.",
      "tldr_zh": "本论文提出Hierarchical Prompting Taxonomy (HPT)，一种基于人类认知原则的通用评估框架，用于评估Large Language Models (LLMs)的任务处理能力。HPT 通过Hierarchical Prompting Framework (HPF)构建五种分层提示策略，并利用Hierarchical Prompting Index (HPI)量化任务的认知复杂性，从而提供标准化指标来比较LLMs的认知能力和数据集难度。实验结果显示，HPF在多个数据集上提升了LLMs的性能2%至63%，其中GSM8k任务被认定为认知最复杂（平均HPI为3.20），证实了HPT的有效性；此外，框架的实现代码已开源以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12644v4",
      "published_date": "2024-06-18 14:12:27 UTC",
      "updated_date": "2024-12-12 02:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:49:03.612818"
    },
    {
      "arxiv_id": "2406.12639v2",
      "title": "Ask-before-Plan: Proactive Language Agents for Real-World Planning",
      "title_zh": "Ask-before-Plan：用于真实世界规划的",
      "authors": [
        "Xuan Zhang",
        "Yang Deng",
        "Zifeng Ren",
        "See-Kiong Ng",
        "Tat-Seng Chua"
      ],
      "abstract": "The evolution of large language models (LLMs) has enhanced the planning\ncapabilities of language agents in diverse real-world scenarios. Despite these\nadvancements, the potential of LLM-powered agents to comprehend ambiguous user\ninstructions for reasoning and decision-making is still under exploration. In\nthis work, we introduce a new task, Proactive Agent Planning, which requires\nlanguage agents to predict clarification needs based on user-agent conversation\nand agent-environment interaction, invoke external tools to collect valid\ninformation, and generate a plan to fulfill the user's demands. To study this\npractical problem, we establish a new benchmark dataset, Ask-before-Plan. To\ntackle the deficiency of LLMs in proactive planning, we propose a novel\nmulti-agent framework, Clarification-Execution-Planning (\\texttt{CEP}), which\nconsists of three agents specialized in clarification, execution, and planning.\nWe introduce the trajectory tuning scheme for the clarification agent and\nstatic execution agent, as well as the memory recollection mechanism for the\ndynamic execution agent. Extensive evaluations and comprehensive analyses\nconducted on the Ask-before-Plan dataset validate the effectiveness of our\nproposed framework.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)在处理模糊用户指令时的不足，引入了新的 Proactive Agent Planning 任务，该任务要求语言代理预测澄清需求、调用外部工具收集信息，并生成计划以满足用户需求。为此，研究者建立了新的基准数据集 Ask-before-Plan，并提出了一种多代理框架 Clarification-Execution-Planning (CEP)，包括专门负责澄清、执行和规划的三个代理，同时引入 trajectory tuning 方案和 memory recollection 机制来提升代理性能。实验结果显示，该框架在 Ask-before-Plan 数据集上的评估中表现出色，验证了其在真实世界规划中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.12639v2",
      "published_date": "2024-06-18 14:07:28 UTC",
      "updated_date": "2024-10-02 02:02:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:49:14.757926"
    },
    {
      "arxiv_id": "2406.12635v1",
      "title": "ScenEval: A Benchmark for Scenario-Based Evaluation of Code Generation",
      "title_zh": "ScenEval：一种基于场景的代码生成评估基准",
      "authors": [
        "Debalina Ghosh Paul",
        "Hong Zhu",
        "Ian Bayley"
      ],
      "abstract": "In the scenario-based evaluation of machine learning models, a key problem is\nhow to construct test datasets that represent various scenarios. The\nmethodology proposed in this paper is to construct a benchmark and attach\nmetadata to each test case. Then a test system can be constructed with test\nmorphisms that filter the test cases based on metadata to form a dataset.\n  The paper demonstrates this methodology with large language models for code\ngeneration. A benchmark called ScenEval is constructed from problems in\ntextbooks, an online tutorial website and Stack Overflow. Filtering by scenario\nis demonstrated and the test sets are used to evaluate ChatGPT for Java code\ngeneration.\n  Our experiments found that the performance of ChatGPT decreases with the\ncomplexity of the coding task. It is weakest for advanced topics like\nmulti-threading, data structure algorithms and recursive methods. The Java code\ngenerated by ChatGPT tends to be much shorter than reference solution in terms\nof number of lines, while it is more likely to be more complex in both\ncyclomatic and cognitive complexity metrics, if the generated code is correct.\nHowever, the generated code is more likely to be less complex than the\nreference solution if the code is incorrect.",
      "tldr_zh": "本文提出了一种场景-based 评估方法，通过构建基准并为每个测试案例添加 metadata，然后使用测试 morphisms 过滤测试案例来形成数据集，应用于 large language models 的代码生成任务。研究构建了 ScenEval 基准，从课本、在线教程网站和 Stack Overflow 中收集问题，并通过该基准评估 ChatGPT 在 Java 代码生成上的性能。实验发现，ChatGPT 的性能随任务复杂度增加而下降，尤其在 multi-threading、数据结构算法和递归方法等高级主题上较弱；此外，生成的代码行数比参考解决方案短，如果正确则在 cyclomatic complexity 和 cognitive complexity 上更复杂，如果错误则更简单。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication in the conference proceedings of IEEE AITest\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12635v1",
      "published_date": "2024-06-18 14:02:20 UTC",
      "updated_date": "2024-06-18 14:02:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:49:27.809106"
    },
    {
      "arxiv_id": "2406.12634v2",
      "title": "News Without Borders: Domain Adaptation of Multilingual Sentence Embeddings for Cross-lingual News Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Andreea Iana",
        "Fabian David Schmidt",
        "Goran Glavaš",
        "Heiko Paulheim"
      ],
      "abstract": "Rapidly growing numbers of multilingual news consumers pose an increasing\nchallenge to news recommender systems in terms of providing customized\nrecommendations. First, existing neural news recommenders, even when powered by\nmultilingual language models (LMs), suffer substantial performance losses in\nzero-shot cross-lingual transfer (ZS-XLT). Second, the current paradigm of\nfine-tuning the backbone LM of a neural recommender on task-specific data is\ncomputationally expensive and infeasible in few-shot recommendation and\ncold-start setups, where data is scarce or completely unavailable. In this\nwork, we propose a news-adapted sentence encoder (NaSE), domain-specialized\nfrom a pretrained massively multilingual sentence encoder (SE). To this end, we\nconstruct and leverage PolyNews and PolyNewsParallel, two multilingual\nnews-specific corpora. With the news-adapted multilingual SE in place, we test\nthe effectiveness of (i.e., question the need for) supervised fine-tuning for\nnews recommendation, and propose a simple and strong baseline based on (i)\nfrozen NaSE embeddings and (ii) late click-behavior fusion. We show that NaSE\nachieves state-of-the-art performance in ZS-XLT in true cold-start and few-shot\nnews recommendation.",
      "tldr_zh": "这篇论文针对多语言新闻推荐中的零样本跨语言转移（ZS-XLT）问题，提出了一种新闻适配句子编码器（NaSE），通过从预训练的多语言句子编码器（SE）中进行领域适配，并利用构建的PolyNews和PolyNewsParallel多语言新闻语料库来优化模型。作者质疑监督微调的必要性，并引入一个简单基线，使用冻结NaSE嵌入和后期点击行为融合，以减少计算开销。实验结果表明，NaSE在冷启动和少样本新闻推荐场景下实现了最先进性能，提升了跨语言推荐的鲁棒性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "I.2.7; H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at the 47th European Conference on Information Retrieval\n  (ECIR 2025) Appendix A is provided only in the arXiv version",
      "pdf_url": "http://arxiv.org/pdf/2406.12634v2",
      "published_date": "2024-06-18 14:01:53 UTC",
      "updated_date": "2025-01-17 12:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:49:41.408039"
    },
    {
      "arxiv_id": "2407.01585v1",
      "title": "DrugWatch: A Comprehensive Multi-Source Data Visualisation Platform for Drug Safety Information",
      "title_zh": "翻译失败",
      "authors": [
        "Artem Bobrov",
        "Domantas Saltenis",
        "Zhaoyue Sun",
        "Gabriele Pergola",
        "Yulan He"
      ],
      "abstract": "Drug safety research is crucial for maintaining public health, often\nrequiring comprehensive data support. However, the resources currently\navailable to the public are limited and fail to provide a comprehensive\nunderstanding of the relationship between drugs and their side effects. This\npaper introduces DrugWatch, an easy-to-use and interactive multi-source\ninformation visualisation platform for drug safety study. It allows users to\nunderstand common side effects of drugs and their statistical information,\nflexibly retrieve relevant medical reports, or annotate their own medical texts\nwith our automated annotation tool. Supported by NLP technology and enriched\nwith interactive visual components, we are committed to providing researchers\nand practitioners with a one-stop information analysis, retrieval, and\nannotation service. The demonstration video is available at\nhttps://www.youtube.com/watch?v=RTqDgxzETjw. We also deployed an online\ndemonstration system at https://drugwatch.net/.",
      "tldr_zh": "本文介绍了 DrugWatch，一个全面的多源数据可视化平台，旨在解决现有公共资源不足的问题，帮助用户更好地理解药物及其副作用的关系。平台支持用户查看药物常见副作用的统计信息、灵活检索相关医疗报告，以及使用自动化标注工具处理自身医疗文本。借助 NLP 技术和交互式可视化组件，DrugWatch 为研究者和从业者提供一站式的信息分析、检索和标注服务。该平台已部署在线，并附带演示视频，增强了其实用性和可访问性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 14 figures, accepted by ACL 2024 Demo Track",
      "pdf_url": "http://arxiv.org/pdf/2407.01585v1",
      "published_date": "2024-06-18 13:58:12 UTC",
      "updated_date": "2024-06-18 13:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:49:52.266390"
    },
    {
      "arxiv_id": "2406.12629v4",
      "title": "SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Yixia Li",
        "Boya Xiong",
        "Guanhua Chen",
        "Yun Chen"
      ],
      "abstract": "Out-of-distribution (OOD) detection is crucial for the safe deployment of\nneural networks. Existing CLIP-based approaches perform OOD detection by\ndevising novel scoring functions or sophisticated fine-tuning methods. In this\nwork, we propose SeTAR, a novel, training-free OOD detection method that\nleverages selective low-rank approximation of weight matrices in\nvision-language and vision-only models. SeTAR enhances OOD detection via\npost-hoc modification of the model's weight matrices using a simple greedy\nsearch algorithm. Based on SeTAR, we further propose SeTAR+FT, a fine-tuning\nextension optimizing model performance for OOD detection tasks. Extensive\nevaluations on ImageNet1K and Pascal-VOC benchmarks show SeTAR's superior\nperformance, reducing the relatively false positive rate by up to 18.95% and\n36.80% compared to zero-shot and fine-tuning baselines. Ablation studies\nfurther validate SeTAR's effectiveness, robustness, and generalizability across\ndifferent model backbones. Our work offers a scalable, efficient solution for\nOOD detection, setting a new state-of-the-art in this area.",
      "tldr_zh": "该论文提出SeTAR，一种无需训练的Out-of-Distribution (OOD)检测方法，通过选择性低秩逼近(selective low-rank approximation)对视觉-语言和视觉-only模型的权重矩阵进行后处理修改，并使用贪婪搜索算法优化检测性能。SeTAR进一步扩展为SeTAR+FT版本，支持微调以提升OOD任务效果；在ImageNet1K和Pascal-VOC基准测试中，SeTAR较零样本和微调基线降低了高达18.95%和36.80%的假阳性率。实验结果证明了SeTAR的有效性、鲁棒性和在不同模型骨干上的泛化能力，为高效、可扩展的OOD检测设定了新状态-of-the-art。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024. Project page is live at\n  https://SeTAR-OOD.github.io. Code are available at\n  https://github.com/X1AOX1A/SeTAR",
      "pdf_url": "http://arxiv.org/pdf/2406.12629v4",
      "published_date": "2024-06-18 13:55:13 UTC",
      "updated_date": "2024-11-05 06:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:50:05.263926"
    },
    {
      "arxiv_id": "2406.12624v5",
      "title": "Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges",
      "title_zh": "评判评判者：评估 LLMs-as-Judges 中的对齐与漏洞",
      "authors": [
        "Aman Singh Thakur",
        "Kartik Choudhary",
        "Venkat Srinik Ramayapally",
        "Sankaran Vaidyanathan",
        "Dieuwke Hupkes"
      ],
      "abstract": "Offering a promising solution to the scalability challenges associated with\nhuman evaluation, the LLM-as-a-judge paradigm is rapidly gaining traction as an\napproach to evaluating large language models (LLMs). However, there are still\nmany open questions about the strengths and weaknesses of this paradigm, and\nwhat potential biases it may hold. In this paper, we present a comprehensive\nstudy of the performance of various LLMs acting as judges, focusing on a clean\nscenario in which inter-human agreement is high. Investigating thirteen judge\nmodels of different model sizes and families, judging answers of nine different\n'examtaker models' - both base and instruction-tuned - we find that only the\nbest (and largest) models achieve reasonable alignment with humans. However,\nthey are still quite far behind inter-human agreement and their assigned scores\nmay still differ with up to 5 points from human-assigned scores. In terms of\ntheir ranking of the nine exam-taker models, instead, also smaller models and\neven the lexical metric contains may provide a reasonable signal. Through error\nanalysis and other studies, we identify vulnerabilities in judge models, such\nas their sensitivity to prompt complexity and length, and a tendency toward\nleniency. The fact that even the best judges differ from humans in this\ncomparatively simple setup suggest that caution may be wise when using judges\nin more complex setups. Lastly, our research rediscovers the importance of\nusing alignment metrics beyond simple percent alignment, showing that judges\nwith high percent agreement can still assign vastly different scores.",
      "tldr_zh": "本研究评估了LLMs-as-Judges范式在大型语言模型(LLMs)评估中的性能，旨在解决其可扩展性优势与潜在偏差问题。通过测试13个不同大小和系列的评判模型，以及9个基础和指令调整的被评模型，在人类间协议高的场景下，发现只有最大模型能与人类对齐，但其评分仍可能与人类相差高达5分。结果显示，较小模型在模型排名方面提供合理信号，但评判模型存在漏洞，如对提示复杂性和长度的敏感性以及宽容倾向，建议在复杂场景中使用时需谨慎。最后，该研究强调，使用超越简单百分比对齐的指标（如评分差异分析）更能准确评估评判可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12624v5",
      "published_date": "2024-06-18 13:49:54 UTC",
      "updated_date": "2025-01-21 04:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:50:16.941091"
    },
    {
      "arxiv_id": "2406.12608v2",
      "title": "Bridging Local Details and Global Context in Text-Attributed Graphs",
      "title_zh": "在文本属性图中桥接局部细节与全局上下文",
      "authors": [
        "Yaoke Wang",
        "Yun Zhu",
        "Wenqiao Zhang",
        "Yueting Zhuang",
        "Yunfei Li",
        "Siliang Tang"
      ],
      "abstract": "Representation learning on text-attributed graphs (TAGs) is vital for\nreal-world applications, as they combine semantic textual and contextual\nstructural information. Research in this field generally consist of two main\nperspectives: local-level encoding and global-level aggregating, respectively\nrefer to textual node information unification (e.g., using Language Models) and\nstructure-augmented modeling (e.g., using Graph Neural Networks). Most existing\nworks focus on combining different information levels but overlook the\ninterconnections, i.e., the contextual textual information among nodes, which\nprovides semantic insights to bridge local and global levels. In this paper, we\npropose GraphBridge, a multi-granularity integration framework that bridges\nlocal and global perspectives by leveraging contextual textual information,\nenhancing fine-grained understanding of TAGs. Besides, to tackle scalability\nand efficiency challenges, we introduce a graphaware token reduction module.\nExtensive experiments across various models and datasets show that our method\nachieves state-of-theart performance, while our graph-aware token reduction\nmodule significantly enhances efficiency and solves scalability issues.",
      "tldr_zh": "该论文探讨了文本属性图（TAGs）中的表示学习问题，强调了桥接本地细节（如使用Language Models统一文本节点信息）和全局上下文（如使用Graph Neural Networks建模结构）的必要性，以整合语义文本和结构信息。作者提出GraphBridge框架，通过利用节点间的上下文文本信息进行多粒度集成，增强对TAGs的细粒度理解。框架还引入图感知令牌减少模块，以解决可伸缩性和效率挑战。实验结果显示，GraphBridge在各种模型和数据集上实现了最先进性能，同时显著提高了计算效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024(Main)",
      "pdf_url": "http://arxiv.org/pdf/2406.12608v2",
      "published_date": "2024-06-18 13:35:25 UTC",
      "updated_date": "2024-10-14 06:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:50:30.973949"
    },
    {
      "arxiv_id": "2406.12593v2",
      "title": "PromptDSI: Prompt-based Rehearsal-free Instance-wise Incremental Learning for Document Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Tuan-Luc Huynh",
        "Thuy-Trang Vu",
        "Weiqing Wang",
        "Yinwei Wei",
        "Trung Le",
        "Dragan Gasevic",
        "Yuan-Fang Li",
        "Thanh-Toan Do"
      ],
      "abstract": "Differentiable Search Index (DSI) utilizes Pre-trained Language Models (PLMs)\nfor efficient document retrieval without relying on external indexes. However,\nDSI needs full re-training to handle updates in dynamic corpora, causing\nsignificant computational inefficiencies. We introduce PromptDSI, a\nprompt-based rehearsal-free approach for instance-wise incremental learning\ndocument retrieval. PromptDSI attaches prompts to the frozen PLM's encoder of\nDSI, leveraging its powerful representation to efficiently index new corpora\nwhile maintaining a balance between stability and plasticity. We eliminate the\ninitial forward pass of prompt-based continual learning methods that doubles\ntraining and inference time. Moreover, we propose a topic-aware prompt pool\nthat employs neural topic embeddings as fixed keys. This strategy ensures\ndiverse and effective prompt usage, addressing the challenge of parameter\nunderutilization caused by the collapse of the query-key matching mechanism.\nOur empirical evaluations demonstrate that BERT-based PromptDSI matches IncDSI\nin managing forgetting while improving new corpora performance by more than 4%\nHits@10 on NQ320k and upto 3% MRR@10 on MS MARCO 300k.",
      "tldr_zh": "这篇论文提出了 PromptDSI，一种基于提示的、无需排练的实例级增量学习方法，用于提升 Differentiable Search Index (DSI) 在动态语料库下的文档检索效率。PromptDSI 通过在冻结的 Pre-trained Language Models (PLMs) 编码器上附加提示，并引入 topic-aware 提示池（使用神经主题嵌入作为固定键），来实现高效索引新语料库，同时平衡稳定性和可塑性，并消除初始前向传递以减少训练和推理时间。实验结果显示，PromptDSI 在 NQ320k 数据集上 Hits@10 性能提升超过 4%，在 MS MARCO 300k 上 MRR@10 提高多达 3%，并在管理遗忘方面与 IncDSI 相当。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.12593v2",
      "published_date": "2024-06-18 13:25:18 UTC",
      "updated_date": "2024-10-16 13:45:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:50:52.528017"
    },
    {
      "arxiv_id": "2406.12588v2",
      "title": "UIFV: Data Reconstruction Attack in Vertical Federated Learning",
      "title_zh": "UIFV：垂直联邦学习中的数据重建攻击",
      "authors": [
        "Jirui Yang",
        "Peng Chen",
        "Zhihui Lu",
        "Qiang Duan",
        "Yubing Bao"
      ],
      "abstract": "Vertical Federated Learning (VFL) facilitates collaborative machine learning\nwithout the need for participants to share raw private data. However, recent\nstudies have revealed privacy risks where adversaries might reconstruct\nsensitive features through data leakage during the learning process. Although\ndata reconstruction methods based on gradient or model information are somewhat\neffective, they reveal limitations in VFL application scenarios. This is\nbecause these traditional methods heavily rely on specific model structures\nand/or have strict limitations on application scenarios. To address this, our\nstudy introduces the Unified InverNet Framework into VFL, which yields a novel\nand flexible approach (dubbed UIFV) that leverages intermediate feature data to\nreconstruct original data, instead of relying on gradients or model details.\nThe intermediate feature data is the feature exchanged by different\nparticipants during the inference phase of VFL. Experiments on four datasets\ndemonstrate that our methods significantly outperform state-of-the-art\ntechniques in attack precision. Our work exposes severe privacy vulnerabilities\nwithin VFL systems that pose real threats to practical VFL applications and\nthus confirms the necessity of further enhancing privacy protection in the VFL\narchitecture.",
      "tldr_zh": "本研究探讨了垂直联邦学习 (VFL) 中的数据重建攻击问题，攻击者可利用学习过程中的中间特征数据泄露重建敏感信息，而传统基于梯度或模型的方法因依赖特定结构而存在局限性。论文引入 Unified InverNet Framework，提出 UIFV 框架，该方法通过利用 VFL 推理阶段交换的中间特征数据进行灵活的数据重建，而非依赖梯度或模型细节。实验在四个数据集上表明，UIFV 在攻击精度上显著优于现有技术，暴露了 VFL 系统的严重隐私风险，并呼吁进一步增强隐私保护机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12588v2",
      "published_date": "2024-06-18 13:18:52 UTC",
      "updated_date": "2025-01-14 21:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:50:52.996833"
    },
    {
      "arxiv_id": "2406.12585v2",
      "title": "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling",
      "title_zh": "翻译失败",
      "authors": [
        "Yao-Ching Yu",
        "Chun-Chih Kuo",
        "Ziqi Ye",
        "Yu-Cheng Chang",
        "Yueh-Se Li"
      ],
      "abstract": "Ensembling multiple models has always been an effective approach to push the\nlimits of existing performance and is widely used in classification tasks by\nsimply averaging the classification probability vectors from multiple\nclassifiers to achieve better accuracy. However, in the thriving open-source\nLarge Language Model (LLM) community, ensembling methods are rare and typically\nlimited to ensembling the full-text outputs of LLMs, such as selecting the best\noutput using a ranker, which leads to underutilization of token-level\nprobability information. In this paper, we treat the Generation of each token\nby LLMs as a Classification (GaC) for ensembling. This approach fully exploits\nthe probability information at each generation step and better prevents LLMs\nfrom producing early incorrect tokens that lead to snowballing errors. In\nexperiments, we ensemble state-of-the-art LLMs on several benchmarks, including\nexams, mathematics and reasoning, and observe that our method breaks the\nexisting community performance ceiling. Furthermore, we observed that most of\nthe tokens in the answer are simple and do not affect the correctness of the\nfinal answer. Therefore, we also experimented with ensembling only key tokens,\nand the results showed better performance with lower latency across benchmarks.",
      "tldr_zh": "这篇论文提出了一种创新方法，将大型语言模型(LLM)的 token 生成视为分类任务（Generation as Classification, GaC），以实现更有效的 ensembling，从而充分利用 token-level 概率信息，避免早期错误导致的错误积累。相比传统仅在全文输出级别进行 ensembling，该方法在考试、数学和推理基准上对 state-of-the-art LLMs 进行集成，显著打破了现有 LLM 社区的性能上限。实验结果显示，这种 ensembling 方式提高了整体准确率，而仅针对关键 token 进行 ensembling 则进一步降低了延迟，同时保持了更好的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12585v2",
      "published_date": "2024-06-18 13:17:26 UTC",
      "updated_date": "2024-09-29 11:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:51:04.653302"
    },
    {
      "arxiv_id": "2406.12572v3",
      "title": "Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models",
      "title_zh": "Math",
      "authors": [
        "Eldar Kurtic",
        "Amir Moeini",
        "Dan Alistarh"
      ],
      "abstract": "We introduce Mathador-LM, a new benchmark for evaluating the mathematical\nreasoning on large language models (LLMs), combining ruleset interpretation,\nplanning, and problem-solving. This benchmark is inspired by the Mathador game,\nwhere the objective is to reach a target number using basic arithmetic\noperations on a given set of base numbers, following a simple set of rules. We\nshow that, across leading LLMs, we obtain stable average performance while\ngenerating benchmark instances \\emph{dynamically}, following a target\ndifficulty level. Thus, our benchmark alleviates concerns about test-set\nleakage into training data, an issue that often undermines popular benchmarks.\nAdditionally, we conduct a comprehensive evaluation of both open and\nclosed-source state-of-the-art LLMs on Mathador-LM. Our findings reveal that\ncontemporary models struggle with Mathador-LM, scoring significantly lower than\naverage 3rd graders. This stands in stark contrast to their strong performance\non popular mathematical reasoning benchmarks. The implementation of Mathador-LM\nbenchmark is available at\n\\href{https://github.com/IST-DASLab/Mathador-LM}{github.com/IST-DASLab/Mathador-LM}.",
      "tldr_zh": "本研究引入了 Mathador-LM，这是一个动态基准，用于评估大型语言模型 (LLMs) 的数学推理能力，结合规则集解释、规划和问题解决，灵感来源于 Mathador 游戏。Mathador-LM 通过动态生成基准实例，根据目标难度水平确保性能稳定，从而缓解了测试集泄露到训练数据的问题。实验结果显示，领先的开源和闭源 LLMs 在该基准上表现不佳，成绩远低于平均 3 年级学生的水平，与它们在其他流行数学基准上的出色表现形成鲜明对比。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12572v3",
      "published_date": "2024-06-18 13:02:12 UTC",
      "updated_date": "2024-10-15 10:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:51:19.959979"
    },
    {
      "arxiv_id": "2406.15490v2",
      "title": "Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuncheng Hua",
        "Yujin Huang",
        "Shuo Huang",
        "Tao Feng",
        "Lizhen Qu",
        "Chris Bain",
        "Richard Bassed",
        "Gholamreza Haffari"
      ],
      "abstract": "This paper tackles the task of emotion-cause pair extraction in the\nunsupervised domain adaptation setting. The problem is challenging as the\ndistributions of the events causing emotions in target domains are dramatically\ndifferent than those in source domains, despite the distributions of emotional\nexpressions between domains are overlapped. Inspired by causal discovery, we\npropose a novel deep latent model in the variational autoencoder (VAE)\nframework, which not only captures the underlying latent structures of data but\nalso utilizes the easily transferable knowledge of emotions as the bridge to\nlink the distributions of events in different domains. To facilitate knowledge\ntransfer across domains, we also propose a novel variational posterior\nregularization technique to disentangle the latent representations of emotions\nfrom those of events in order to mitigate the damage caused by the spurious\ncorrelations related to the events in source domains. Through extensive\nexperiments, we demonstrate that our model outperforms the strongest baseline\nby approximately 11.05\\% on a Chinese benchmark and 2.45\\% on a English\nbenchmark in terms of weighted-average F1 score. We have released our source\ncode and the generated dataset publicly at:\nhttps://github.com/tk1363704/CAREL-VAE.",
      "tldr_zh": "该论文针对无监督域适应(Unsupervised Domain Adaptation)中的情绪-原因对提取(Emotion-Cause Pair Extraction)任务，提出了一种受因果发现(Causal Discovery)启发的深度潜在模型，基于变分自编码器(VAE)框架捕捉数据底层结构，并利用可转移的情绪知识作为桥梁连接不同域的事件分布。为了促进知识转移，该模型引入了变分后验正则化技术，以分离情绪和事件的潜在表示，缓解源域中事件相关虚假相关的影响。实验结果显示，该模型在中文基准上比最强基线提升约11.05%，在英文基准上提升2.45%的加权平均F1分数，并已开源代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.4"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 6 figures, 5 tables. The paper has been published in the\n  Findings of the Association for Computational Linguistics: EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.15490v2",
      "published_date": "2024-06-18 13:01:30 UTC",
      "updated_date": "2025-02-17 08:36:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:51:29.553713"
    },
    {
      "arxiv_id": "2406.12950v2",
      "title": "MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyan Liu",
        "Sirui Ding",
        "Sheng Zhou",
        "Wenqi Fan",
        "Qiaoyu Tan"
      ],
      "abstract": "Molecular property prediction (MPP) is a fundamental and crucial task in drug\ndiscovery. However, prior methods are limited by the requirement for a large\nnumber of labeled molecules and their restricted ability to generalize for\nunseen and new tasks, both of which are essential for real-world applications.\nTo address these challenges, we present MolecularGPT for few-shot MPP. From a\nperspective on instruction tuning, we fine-tune large language models (LLMs)\nbased on curated molecular instructions spanning over 1000 property prediction\ntasks. This enables building a versatile and specialized LLM that can be\nadapted to novel MPP tasks without any fine-tuning through zero- and few-shot\nin-context learning (ICL). MolecularGPT exhibits competitive in-context\nreasoning capabilities across 10 downstream evaluation datasets, setting new\nbenchmarks for few-shot molecular prediction tasks. More importantly, with just\ntwo-shot examples, MolecularGPT can outperform standard supervised graph neural\nnetwork methods on 4 out of 7 datasets. It also excels state-of-the-art LLM\nbaselines by up to 15.7% increase on classification accuracy and decrease of\n17.9 on regression metrics (e.g., RMSE) under zero-shot. This study\ndemonstrates the potential of LLMs as effective few-shot molecular property\npredictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.",
      "tldr_zh": "本研究提出 MolecularGPT，一种开源的大型语言模型(LLM)，通过在超过1000个分子属性预测任务上的指令微调，解决分子属性预测(Molecular Property Prediction)中数据需求大和泛化能力弱的问题。该模型支持零样本和少样本学习(In-Context Learning)，无需进一步训练即可适应新任务。在10个下游数据集的评估中，MolecularGPT 以仅两个样本就超越标准监督图神经网络方法，并在零样本设置下比最先进LLM基准提高了15.7%的分类准确率，并降低了17.9的回归指标（如RMSE）。这项工作展示了LLM在少样本分子属性预测中的潜力，并提供了开源代码。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12950v2",
      "published_date": "2024-06-18 12:54:47 UTC",
      "updated_date": "2024-10-18 12:19:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:51:43.963745"
    },
    {
      "arxiv_id": "2406.12560v2",
      "title": "Towards Bayesian Data Selection",
      "title_zh": "迈向贝叶斯数据选择",
      "authors": [
        "Julian Rodemann"
      ],
      "abstract": "A wide range of machine learning algorithms iteratively add data to the\ntraining sample. Examples include semi-supervised learning, active learning,\nmulti-armed bandits, and Bayesian optimization. We embed this kind of data\naddition into decision theory by framing data selection as a decision problem.\nThis paves the way for finding Bayes-optimal selections of data. For the\nillustrative case of self-training in semi-supervised learning, we derive the\nrespective Bayes criterion. We further show that deploying this criterion\nmitigates the issue of confirmation bias by empirically assessing our method\nfor generalized linear models, semi-parametric generalized additive models, and\nBayesian neural networks on simulated and real-world data.",
      "tldr_zh": "该论文提出将数据选择框架化为决策问题，以寻找贝叶斯最优的数据选择方法，适用于多种机器学习算法，如semi-supervised learning、active learning、multi-armed bandits和Bayesian optimization。针对semi-supervised learning中的self-training，作者导出了相应的Bayes准则，以优化数据添加过程。实验结果显示，该方法能有效缓解confirmation bias，在generalized linear models、semi-parametric generalized additive models和Bayesian neural networks上进行了模拟和真实数据评估，证明了其在提高模型性能方面的潜力。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "5th Workshop on Data-Centric Machine Learning Research (DMLR) at ICML\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12560v2",
      "published_date": "2024-06-18 12:40:15 UTC",
      "updated_date": "2024-06-24 08:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:51:53.651204"
    },
    {
      "arxiv_id": "2406.12550v1",
      "title": "Offline Imitation Learning with Model-based Reverse Augmentation",
      "title_zh": "基于模型反向增强的离线模仿学习",
      "authors": [
        "Jie-Jing Shao",
        "Hao-Sen Shi",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "abstract": "In offline Imitation Learning (IL), one of the main challenges is the\n\\textit{covariate shift} between the expert observations and the actual\ndistribution encountered by the agent, because it is difficult to determine\nwhat action an agent should take when outside the state distribution of the\nexpert demonstrations. Recently, the model-free solutions introduce the\nsupplementary data and identify the latent expert-similar samples to augment\nthe reliable samples during learning. Model-based solutions build forward\ndynamic models with conservatism quantification and then generate additional\ntrajectories in the neighborhood of expert demonstrations. However, without\nreward supervision, these methods are often over-conservative in the\nout-of-expert-support regions, because only in states close to expert-observed\nstates can there be a preferred action enabling policy optimization. To\nencourage more exploration on expert-unobserved states, we propose a novel\nmodel-based framework, called offline Imitation Learning with Self-paced\nReverse Augmentation (SRA). Specifically, we build a reverse dynamic model from\nthe offline demonstrations, which can efficiently generate trajectories leading\nto the expert-observed states in a self-paced style. Then, we use the\nsubsequent reinforcement learning method to learn from the augmented\ntrajectories and transit from expert-unobserved states to expert-observed\nstates. This framework not only explores the expert-unobserved states but also\nguides maximizing long-term returns on these states, ultimately enabling\ngeneralization beyond the expert data. Empirical results show that our proposal\ncould effectively mitigate the covariate shift and achieve the state-of-the-art\nperformance on the offline imitation learning benchmarks. Project website:\n\\url{https://www.lamda.nju.edu.cn/shaojj/KDD24_SRA/}.",
      "tldr_zh": "该论文针对离线模仿学习（Offline Imitation Learning, IL）中的协变量偏移（covariate shift）问题，提出了一种新型框架SRA（Self-paced Reverse Augmentation）。该框架构建反向动态模型（reverse dynamic model）从离线演示数据中生成通向专家观察状态的轨迹，并采用自定步调增强策略结合强化学习，以鼓励在专家未观察状态的探索。实验结果显示，SRA 不仅有效缓解了协变量偏移，还在离线模仿学习基准上实现了最先进性能，实现了对专家数据的泛化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12550v1",
      "published_date": "2024-06-18 12:27:02 UTC",
      "updated_date": "2024-06-18 12:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:52:08.928984"
    },
    {
      "arxiv_id": "2406.12549v1",
      "title": "MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts",
      "title_zh": "MultiSocial：社交媒体文本机器生成检测的多语言基准测试",
      "authors": [
        "Dominik Macko",
        "Jakub Kopal",
        "Robert Moro",
        "Ivan Srba"
      ],
      "abstract": "Recent LLMs are able to generate high-quality multilingual texts,\nindistinguishable for humans from authentic human-written ones. Research in\nmachine-generated text detection is however mostly focused on the English\nlanguage and longer texts, such as news articles, scientific papers or student\nessays. Social-media texts are usually much shorter and often feature informal\nlanguage, grammatical errors, or distinct linguistic items (e.g., emoticons,\nhashtags). There is a gap in studying the ability of existing methods in\ndetection of such texts, reflected also in the lack of existing multilingual\nbenchmark datasets. To fill this gap we propose the first multilingual (22\nlanguages) and multi-platform (5 social media platforms) dataset for\nbenchmarking machine-generated text detection in the social-media domain,\ncalled MultiSocial. It contains 472,097 texts, of which about 58k are\nhuman-written and approximately the same amount is generated by each of 7\nmultilingual LLMs. We use this benchmark to compare existing detection methods\nin zero-shot as well as fine-tuned form. Our results indicate that the\nfine-tuned detectors have no problem to be trained on social-media texts and\nthat the platform selection for training matters.",
      "tldr_zh": "该论文提出MultiSocial数据集，这是首个多语言（22种语言）和多平台（5个社交媒体平台）的基准，用于评估机器生成文本检测在社交媒体领域的性能。数据集包含472,097个文本，其中约58k为人类撰写，其余由7个多语言LLMs生成。研究比较了现有检测方法的zero-shot和fine-tuned形式，结果显示微调检测器能有效适应社交媒体文本，且训练平台的选取对性能影响显著。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12549v1",
      "published_date": "2024-06-18 12:26:09 UTC",
      "updated_date": "2024-06-18 12:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:52:28.138199"
    },
    {
      "arxiv_id": "2406.12539v1",
      "title": "The Heterophilic Snowflake Hypothesis: Training and Empowering GNNs for Heterophilic Graphs",
      "title_zh": "异质性雪花假设：针对异质性图的图神经网络训练和赋能",
      "authors": [
        "Kun Wang",
        "Guibin Zhang",
        "Xinnan Zhang",
        "Junfeng Fang",
        "Xun Wu",
        "Guohao Li",
        "Shirui Pan",
        "Wei Huang",
        "Yuxuan Liang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have become pivotal tools for a range of\ngraph-based learning tasks. Notably, most current GNN architectures operate\nunder the assumption of homophily, whether explicitly or implicitly. While this\nunderlying assumption is frequently adopted, it is not universally applicable,\nwhich can result in potential shortcomings in learning effectiveness. In this\npaper, \\textbf{for the first time}, we transfer the prevailing concept of ``one\nnode one receptive field\" to the heterophilic graph. By constructing a proxy\nlabel predictor, we enable each node to possess a latent prediction\ndistribution, which assists connected nodes in determining whether they should\naggregate their associated neighbors. Ultimately, every node can have its own\nunique aggregation hop and pattern, much like each snowflake is unique and\npossesses its own characteristics. Based on observations, we innovatively\nintroduce the Heterophily Snowflake Hypothesis and provide an effective\nsolution to guide and facilitate research on heterophilic graphs and beyond. We\nconduct comprehensive experiments including (1) main results on 10 graphs with\nvarying heterophily ratios across 10 backbones; (2) scalability on various deep\nGNN backbones (SGC, JKNet, etc.) across various large number of layers\n(2,4,6,8,16,32 layers); (3) comparison with conventional snowflake hypothesis;\n(4) efficiency comparison with existing graph pruning algorithms. Our\nobservations show that our framework acts as a versatile operator for diverse\ntasks. It can be integrated into various GNN frameworks, boosting performance\nin-depth and offering an explainable approach to choosing the optimal network\ndepth. The source code is available at\n\\url{https://github.com/bingreeky/HeteroSnoH}.",
      "tldr_zh": "这篇论文针对图神经网络（GNNs）在异质性图（heterophilic graphs）上的局限性，首次提出Heterophily Snowflake Hypothesis，挑战传统的同质性（homophily）假设。通过构建proxy label predictor，每个节点可以拥有独特的潜在预测分布，从而自主决定是否聚合邻居，实现个性化聚合跳数和模式。实验结果显示，该框架在10个图上提升了多种GNN backbone的性能，可扩展到不同层数（如2至32层）的深度网络，并提供可解释的方法来优化网络深度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12539v1",
      "published_date": "2024-06-18 12:16:00 UTC",
      "updated_date": "2024-06-18 12:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:52:40.678075"
    },
    {
      "arxiv_id": "2406.12538v2",
      "title": "Variational Distillation of Diffusion Policies into Mixture of Experts",
      "title_zh": "变分蒸馏扩散策略到混合专家模型中",
      "authors": [
        "Hongyi Zhou",
        "Denis Blessing",
        "Ge Li",
        "Onur Celik",
        "Xiaogang Jia",
        "Gerhard Neumann",
        "Rudolf Lioutikov"
      ],
      "abstract": "This work introduces Variational Diffusion Distillation (VDD), a novel method\nthat distills denoising diffusion policies into Mixtures of Experts (MoE)\nthrough variational inference. Diffusion Models are the current\nstate-of-the-art in generative modeling due to their exceptional ability to\naccurately learn and represent complex, multi-modal distributions. This ability\nallows Diffusion Models to replicate the inherent diversity in human behavior,\nmaking them the preferred models in behavior learning such as Learning from\nHuman Demonstrations (LfD). However, diffusion models come with some drawbacks,\nincluding the intractability of likelihoods and long inference times due to\ntheir iterative sampling process. The inference times, in particular, pose a\nsignificant challenge to real-time applications such as robot control. In\ncontrast, MoEs effectively address the aforementioned issues while retaining\nthe ability to represent complex distributions but are notoriously difficult to\ntrain. VDD is the first method that distills pre-trained diffusion models into\nMoE models, and hence, combines the expressiveness of Diffusion Models with the\nbenefits of Mixture Models. Specifically, VDD leverages a decompositional upper\nbound of the variational objective that allows the training of each expert\nseparately, resulting in a robust optimization scheme for MoEs. VDD\ndemonstrates across nine complex behavior learning tasks, that it is able to:\ni) accurately distill complex distributions learned by the diffusion model, ii)\noutperform existing state-of-the-art distillation methods, and iii) surpass\nconventional methods for training MoE.",
      "tldr_zh": "本文提出Variational Diffusion Distillation (VDD)，一种创新方法，通过变分推理将去噪扩散策略(Diffusion Models)提炼到Mixtures of Experts (MoE)，以解决扩散模型在行为学习中的似然不可计算和推理时间长等问题，同时保留其处理复杂多模态分布的能力。VDD首次实现预训练扩散模型向MoE的蒸馏，利用分解变分目标的上界允许每个专家独立训练，从而提供鲁棒的优化方案。在九个复杂行为学习任务中，VDD准确复制了扩散模型学到的分布，并超越现有蒸馏方法和传统MoE训练方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 38th Annual Conference on Neural Information\n  Processing Systems,",
      "pdf_url": "http://arxiv.org/pdf/2406.12538v2",
      "published_date": "2024-06-18 12:15:05 UTC",
      "updated_date": "2024-10-18 20:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:52:45.252837"
    },
    {
      "arxiv_id": "2406.16943v1",
      "title": "EarDA: Towards Accurate and Data-Efficient Earable Activity Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Shengzhe Lyu",
        "Yongliang Chen",
        "Di Duan",
        "Renqi Jia",
        "Weitao Xu"
      ],
      "abstract": "In the realm of smart sensing with the Internet of Things, earable devices\nare empowered with the capability of multi-modality sensing and intelligence of\ncontext-aware computing, leading to its wide usage in Human Activity\nRecognition (HAR). Nonetheless, unlike the movements captured by Inertial\nMeasurement Unit (IMU) sensors placed on the upper or lower body, those motion\nsignals obtained from earable devices show significant changes in amplitudes\nand patterns, especially in the presence of dynamic and unpredictable head\nmovements, posing a significant challenge for activity classification. In this\nwork, we present EarDA, an adversarial-based domain adaptation system to\nextract the domain-independent features across different sensor locations.\nMoreover, while most deep learning methods commonly rely on training with\nsubstantial amounts of labeled data to offer good accuracy, the proposed scheme\ncan release the potential usage of publicly available smartphone-based IMU\ndatasets. Furthermore, we explore the feasibility of applying a filter-based\ndata processing method to mitigate the impact of head movement. EarDA, the\nproposed system, enables more data-efficient and accurate activity sensing. It\nachieves an accuracy of 88.8% under HAR task, demonstrating a significant 43%\nimprovement over methods without domain adaptation. This clearly showcases its\neffectiveness in mitigating domain gaps.",
      "tldr_zh": "本文提出 EarDA 系统，旨在提升耳戴设备（earable devices）在 Human Activity Recognition (HAR) 中的准确性和数据效率，解决因头部运动导致的信号幅度和模式变化问题。EarDA 采用 adversarial-based domain adaptation 方法提取不同传感器位置的域独立特征，并结合滤波器数据处理技术来减轻头部运动的影响，从而利用公开的智能手机 IMU 数据集减少对大量标注数据的依赖。实验结果显示，EarDA 在 HAR 任务中实现 88.8% 的准确率，比无域适配方法提高 43%，证明其在跨域活动感知方面的有效性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "accepted by 2024 IEEE Coupling of Sensing & Computing in AIoT Systems\n  (CSCAIoT)",
      "pdf_url": "http://arxiv.org/pdf/2406.16943v1",
      "published_date": "2024-06-18 12:13:43 UTC",
      "updated_date": "2024-06-18 12:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:53:05.209905"
    },
    {
      "arxiv_id": "2406.12529v1",
      "title": "LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Wang",
        "Yichao Wang",
        "Zichuan Fu",
        "Xiangyang Li",
        "Xiangyu Zhao",
        "Huifeng Guo",
        "Ruiming Tang"
      ],
      "abstract": "As the demand for more personalized recommendation grows and a dramatic boom\nin commercial scenarios arises, the study on multi-scenario recommendation\n(MSR) has attracted much attention, which uses the data from all scenarios to\nsimultaneously improve their recommendation performance. However, existing\nmethods tend to integrate insufficient scenario knowledge and neglect learning\npersonalized cross-scenario preferences, thus leading to suboptimal performance\nand inadequate interpretability. Meanwhile, though large language model (LLM)\nhas shown great capability of reasoning and capturing semantic information, the\nhigh inference latency and high computation cost of tuning hinder its\nimplementation in industrial recommender systems. To fill these gaps, we\npropose an effective efficient interpretable LLM-enhanced paradigm LLM4MSR in\nthis work. Specifically, we first leverage LLM to uncover multi-level knowledge\nincluding scenario correlations and users' cross-scenario interests from the\ndesigned scenario- and user-level prompt without fine-tuning the LLM, then\nadopt hierarchical meta networks to generate multi-level meta layers to\nexplicitly improves the scenario-aware and personalized recommendation\ncapability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasets\nvalidate two significant advantages of LLM4MSR: (i) the effectiveness and\ncompatibility with different multi-scenario backbone models (achieving 1.5%,\n1%, and 40% AUC improvement on three datasets), (ii) high efficiency and\ndeployability on industrial recommender systems, and (iii) improved\ninterpretability. The implemented code and data is available to ease\nreproduction.",
      "tldr_zh": "这篇论文提出了 LLM4MSR，一种基于大型语言模型（LLM）的增强范式，用于提升多场景推荐（MSR）的性能，通过挖掘场景相关性和用户跨场景兴趣来解决现有方法在知识整合和个性化方面的不足。方法包括利用 LLM 通过设计的提示（无需微调）获取多级知识，然后采用分层元网络生成元层，以显式提升场景感知和个性化推荐能力。实验在 KuaiSAR-small、KuaiSAR 和 Amazon 数据集上验证了 LLM4MSR 的有效性，与不同 MSR 骨干模型兼容，提高了 1.5% 到 40% 的 AUC，同时实现了高效部署和更好的可解释性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12529v1",
      "published_date": "2024-06-18 11:59:36 UTC",
      "updated_date": "2024-06-18 11:59:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:53:07.513132"
    },
    {
      "arxiv_id": "2406.12499v1",
      "title": "Autonomous navigation of catheters and guidewires in mechanical thrombectomy using inverse reinforcement learning",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Robertshaw",
        "Lennart Karstensen",
        "Benjamin Jackson",
        "Alejandro Granados",
        "Thomas C. Booth"
      ],
      "abstract": "Purpose: Autonomous navigation of catheters and guidewires can enhance\nendovascular surgery safety and efficacy, reducing procedure times and operator\nradiation exposure. Integrating tele-operated robotics could widen access to\ntime-sensitive emergency procedures like mechanical thrombectomy (MT).\nReinforcement learning (RL) shows potential in endovascular navigation, yet its\napplication encounters challenges without a reward signal. This study explores\nthe viability of autonomous navigation in MT vasculature using inverse RL (IRL)\nto leverage expert demonstrations. Methods: This study established a\nsimulation-based training and evaluation environment for MT navigation. We used\nIRL to infer reward functions from expert behaviour when navigating a guidewire\nand catheter. We utilized soft actor-critic to train models with various reward\nfunctions and compared their performance in silico. Results: We demonstrated\nfeasibility of navigation using IRL. When evaluating single versus dual device\n(i.e. guidewire versus catheter and guidewire) tracking, both methods achieved\nhigh success rates of 95% and 96%, respectively. Dual-tracking, however,\nutilized both devices mimicking an expert. A success rate of 100% and procedure\ntime of 22.6 s were obtained when training with a reward function obtained\nthrough reward shaping. This outperformed a dense reward function (96%, 24.9 s)\nand an IRL-derived reward function (48%, 59.2 s). Conclusions: We have\ncontributed to the advancement of autonomous endovascular intervention\nnavigation, particularly MT, by employing IRL. The results underscore the\npotential of using reward shaping to train models, offering a promising avenue\nfor enhancing the accessibility and precision of MT. We envisage that future\nresearch can extend our methodology to diverse anatomical structures to enhance\ngeneralizability.",
      "tldr_zh": "本研究旨在通过逆强化学习(IRL)实现导管和导线的自主导航，提升机械血栓切除术(MT)的安全性和效率，减少手术时间和操作员辐射暴露。研究者使用IRL从专家演示中推断奖励函数，并结合软演员-评论家(soft actor-critic)算法在模拟环境中训练模型，比较不同奖励函数的表现。结果显示，使用奖励整形后的奖励函数可实现100%的导航成功率和22.6秒的程序时间，显著优于密集奖励函数(96%, 24.9秒)和IRL派生函数(48%, 59.2秒)。这一方法为自主内血管干预导航提供了新途径，并建议未来扩展到更多解剖结构以提高通用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Abstract shortened for arXiv character limit",
      "pdf_url": "http://arxiv.org/pdf/2406.12499v1",
      "published_date": "2024-06-18 11:00:55 UTC",
      "updated_date": "2024-06-18 11:00:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:53:19.717986"
    },
    {
      "arxiv_id": "2406.12479v1",
      "title": "RS-GPT4V: A Unified Multimodal Instruction-Following Dataset for Remote Sensing Image Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Linrui Xu",
        "Ling Zhao",
        "Wang Guo",
        "Qiujun Li",
        "Kewang Long",
        "Kaiqi Zou",
        "Yuhan Wang",
        "Haifeng Li"
      ],
      "abstract": "The remote sensing image intelligence understanding model is undergoing a new\nprofound paradigm shift which has been promoted by multi-modal large language\nmodel (MLLM), i.e. from the paradigm learning a domain model (LaDM) shifts to\nparadigm learning a pre-trained general foundation model followed by an\nadaptive domain model (LaGD). Under the new LaGD paradigm, the old datasets,\nwhich have led to advances in RSI intelligence understanding in the last\ndecade, are no longer suitable for fire-new tasks. We argued that a new dataset\nmust be designed to lighten tasks with the following features: 1)\nGeneralization: training model to learn shared knowledge among tasks and to\nadapt to different tasks; 2) Understanding complex scenes: training model to\nunderstand the fine-grained attribute of the objects of interest, and to be\nable to describe the scene with natural language; 3) Reasoning: training model\nto be able to realize high-level visual reasoning. In this paper, we designed a\nhigh-quality, diversified, and unified multimodal instruction-following dataset\nfor RSI understanding produced by GPT-4V and existing datasets, which we called\nRS-GPT4V. To achieve generalization, we used a (Question, Answer) which was\ndeduced from GPT-4V via instruction-following to unify the tasks such as\ncaptioning and localization; To achieve complex scene, we proposed a\nhierarchical instruction description with local strategy in which the\nfine-grained attributes of the objects and their spatial relationships are\ndescribed and global strategy in which all the local information are integrated\nto yield detailed instruction descript; To achieve reasoning, we designed\nmultiple-turn QA pair to provide the reasoning ability for a model. The\nempirical results show that the fine-tuned MLLMs by RS-GPT4V can describe\nfine-grained information. The dataset is available at:\nhttps://github.com/GeoX-Lab/RS-GPT4V.",
      "tldr_zh": "该论文介绍了 RS-GPT4V，这是一个统一的 multimodal instruction-following 数据集，旨在提升遥感图像（RSI）理解模型从学习领域模型（LaDM）向学习预训练通用基础模型后适应领域模型（LaGD）的范式转变。数据集通过 GPT-4V 和现有数据生成高质量、多样化样本，支持模型的泛化能力（统一任务如标题和定位）、复杂场景理解（使用层次化指令描述局部物体属性和全局空间关系）、以及推理能力（设计多轮 QA 对）。实验结果表明，使用 RS-GPT4V 微调的 MLLMs 能更准确地描述细粒度信息，该数据集可从 https://github.com/GeoX-Lab/RS-GPT4V 获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.12479v1",
      "published_date": "2024-06-18 10:34:28 UTC",
      "updated_date": "2024-06-18 10:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:53:31.738200"
    },
    {
      "arxiv_id": "2406.12468v1",
      "title": "Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities",
      "title_zh": "自适应令牌偏置器：通过偏置关键实体进行知识编辑",
      "authors": [
        "Baolong Bi",
        "Shenghua Liu",
        "Yiwei Wang",
        "Lingrui Mei",
        "Hongcheng Gao",
        "Yilong Xu",
        "Xueqi Cheng"
      ],
      "abstract": "The parametric knowledge memorized by large language models (LLMs) becomes\noutdated quickly. In-context editing (ICE) is currently the most effective\nmethod for updating the knowledge of LLMs. Recent advancements involve\nenhancing ICE by modifying the decoding strategy, obviating the need for\naltering internal model structures or adjusting external prompts. However, this\nenhancement operates across the entire sequence generation, encompassing a\nplethora of non-critical tokens. In this work, we introduce $\\textbf{A}$daptive\n$\\textbf{T}$oken $\\textbf{Bias}$er ($\\textbf{ATBias}$), a new decoding\ntechnique designed to enhance ICE. It focuses on the tokens that are mostly\nrelated to knowledge during decoding, biasing their logits by matching key\nentities related to new and parametric knowledge. Experimental results show\nthat ATBias significantly enhances ICE performance, achieving up to a 32.3%\nimprovement over state-of-the-art ICE methods while incurring only half the\nlatency. ATBias not only improves the knowledge editing capabilities of ICE but\ncan also be widely applied to LLMs with negligible cost.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的参数知识快速过时问题，提出Adaptive Token Biaser (ATBias)，一种增强In-context editing (ICE)的解码技术。该方法通过匹配关键实体来偏置与新知识和参数知识相关的标记logits，从而专注于相关标记而非整个序列生成。实验结果显示，ATBias相较于最先进ICE方法提升高达32.3%的性能，同时延迟仅为其一半，并能以极低成本广泛应用于各种LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12468v1",
      "published_date": "2024-06-18 10:18:06 UTC",
      "updated_date": "2024-06-18 10:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:53:54.900081"
    },
    {
      "arxiv_id": "2406.12465v1",
      "title": "RIGL: A Unified Reciprocal Approach for Tracing the Independent and Group Learning Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoshan Yu",
        "Chuan Qin",
        "Dazhong Shen",
        "Shangshang Yang",
        "Haiping Ma",
        "Hengshu Zhu",
        "Xingyi Zhang"
      ],
      "abstract": "In the realm of education, both independent learning and group learning are\nesteemed as the most classic paradigms. The former allows learners to\nself-direct their studies, while the latter is typically characterized by\nteacher-directed scenarios. Recent studies in the field of intelligent\neducation have leveraged deep temporal models to trace the learning process,\ncapturing the dynamics of students' knowledge states, and have achieved\nremarkable performance. However, existing approaches have primarily focused on\nmodeling the independent learning process, with the group learning paradigm\nreceiving less attention. Moreover, the reciprocal effect between the two\nlearning processes, especially their combined potential to foster holistic\nstudent development, remains inadequately explored. To this end, in this paper,\nwe propose RIGL, a unified Reciprocal model to trace knowledge states at both\nthe individual and group levels, drawing from the Independent and Group\nLearning processes. Specifically, we first introduce a time frame-aware\nreciprocal embedding module to concurrently model both student and group\nresponse interactions across various time frames. Subsequently, we employ\nreciprocal enhanced learning modeling to fully exploit the comprehensive and\ncomplementary information between the two behaviors. Furthermore, we design a\nrelation-guided temporal attentive network, comprised of dynamic graph modeling\ncoupled with a temporal self-attention mechanism. It is used to delve into the\ndynamic influence of individual and group interactions throughout the learning\nprocesses. Conclusively, we introduce a bias-aware contrastive learning module\nto bolster the stability of the model's training. Extensive experiments on four\nreal-world educational datasets clearly demonstrate the effectiveness of the\nproposed RIGL model.",
      "tldr_zh": "这篇论文提出 RIGL 模型，一种统一的互惠方法，用于追踪独立学习和群体学习过程的知识状态，解决了现有研究偏重独立学习而忽略群体互动和互惠效应的不足。模型的关键组件包括时间框架感知的 reciprocal embedding module 来同时建模学生和群体响应互动、reciprocal enhanced learning modeling 来利用两者之间的互补信息，以及 relation-guided temporal attentive network 通过动态图建模和时序自注意力机制探索互动影响，最后辅以 bias-aware contrastive learning module 提升训练稳定性。在四个真实教育数据集上的广泛实验中，RIGL 展示了显著的有效性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted by KDD 2024. 12 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.12465v1",
      "published_date": "2024-06-18 10:16:18 UTC",
      "updated_date": "2024-06-18 10:16:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:53:57.252573"
    },
    {
      "arxiv_id": "2406.12454v1",
      "title": "A Neural Column Generation Approach to the Vehicle Routing Problem with Two-Dimensional Loading and Last-In-First-Out Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Xia",
        "Xiangyi Zhang"
      ],
      "abstract": "The vehicle routing problem with two-dimensional loading constraints\n(2L-CVRP) and the last-in-first-out (LIFO) rule presents significant practical\nand algorithmic challenges. While numerous heuristic approaches have been\nproposed to address its complexity, stemming from two NP-hard problems: the\nvehicle routing problem (VRP) and the two-dimensional bin packing problem\n(2D-BPP), less attention has been paid to developing exact algorithms. Bridging\nthis gap, this article presents an exact algorithm that integrates advanced\nmachine learning techniques, specifically a novel combination of attention and\nrecurrence mechanisms. This integration accelerates the state-of-the-art exact\nalgorithm by a median of 29.79% across various problem instances. Moreover, the\nproposed algorithm successfully resolves an open instance in the standard\ntest-bed, demonstrating significant improvements brought about by the\nincorporation of machine learning models. Code is available at\nhttps://github.com/xyfffff/NCG-for-2L-CVRP.",
      "tldr_zh": "本研究针对带有二维装载约束（2L-CVRP）和后进先出（LIFO）规则的车辆路径问题（VRP），提出了一种精确算法，以解决其复杂性，该问题结合了VRP和二维箱装问题（2D-BPP）的NP-hard挑战。算法采用神经列生成方法，融合了注意力（attention）和循环（recurrence）机制，显著提升了现有精确算法的效率，在各种实例上实现了中位数29.79%的加速。实验结果显示，该方法成功解决了标准测试中的一个开放实例，展示了机器学习技术在优化问题中的潜力。代码可从https://github.com/xyfffff/NCG-for-2L-CVRP获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by International Joint Conference on Artificial Intelligence\n  (IJCAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.12454v1",
      "published_date": "2024-06-18 09:58:29 UTC",
      "updated_date": "2024-06-18 09:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:54:08.349595"
    },
    {
      "arxiv_id": "2406.12452v2",
      "title": "Insect Identification in the Wild: The AMI Dataset",
      "title_zh": "野外昆虫识别：AMI 数据集",
      "authors": [
        "Aditya Jain",
        "Fagner Cunha",
        "Michael James Bunsen",
        "Juan Sebastián Cañas",
        "Léonard Pasi",
        "Nathan Pinoy",
        "Flemming Helsing",
        "JoAnne Russo",
        "Marc Botham",
        "Michael Sabourin",
        "Jonathan Fréchette",
        "Alexandre Anctil",
        "Yacksecari Lopez",
        "Eduardo Navarro",
        "Filonila Perez Pimentel",
        "Ana Cecilia Zamora",
        "José Alejandro Ramirez Silva",
        "Jonathan Gagnon",
        "Tom August",
        "Kim Bjerge",
        "Alba Gomez Segura",
        "Marc Bélisle",
        "Yves Basset",
        "Kent P. McFarland",
        "David Roy",
        "Toke Thomas Høye",
        "Maxim Larrivée",
        "David Rolnick"
      ],
      "abstract": "Insects represent half of all global biodiversity, yet many of the world's\ninsects are disappearing, with severe implications for ecosystems and\nagriculture. Despite this crisis, data on insect diversity and abundance remain\nwoefully inadequate, due to the scarcity of human experts and the lack of\nscalable tools for monitoring. Ecologists have started to adopt camera traps to\nrecord and study insects, and have proposed computer vision algorithms as an\nanswer for scalable data processing. However, insect monitoring in the wild\nposes unique challenges that have not yet been addressed within computer\nvision, including the combination of long-tailed data, extremely similar\nclasses, and significant distribution shifts. We provide the first large-scale\nmachine learning benchmarks for fine-grained insect recognition, designed to\nmatch real-world tasks faced by ecologists. Our contributions include a curated\ndataset of images from citizen science platforms and museums, and an\nexpert-annotated dataset drawn from automated camera traps across multiple\ncontinents, designed to test out-of-distribution generalization under field\nconditions. We train and evaluate a variety of baseline algorithms and\nintroduce a combination of data augmentation techniques that enhance\ngeneralization across geographies and hardware setups.",
      "tldr_zh": "本研究针对昆虫多样性危机和数据不足问题，介绍了AMI Dataset，这是一个专为野外昆虫识别设计的图像数据集，包括来自公民科学平台、博物馆和多大陆自动化相机陷阱的专家标注图像。数据集旨在解决计算机视觉领域的独特挑战，如长尾数据、相似类别和分布偏移，并提供第一个大规模机器学习基准，用于细粒度昆虫识别（fine-grained insect recognition）。通过训练各种基线算法并应用数据增强技术（data augmentation），研究提升了模型在不同地理和硬件条件下的out-of-distribution generalization能力，为生态学家提供可扩展的监测工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ECCV 2024. The dataset is publicly available at\n  https://github.com/RolnickLab/ami-dataset",
      "pdf_url": "http://arxiv.org/pdf/2406.12452v2",
      "published_date": "2024-06-18 09:57:02 UTC",
      "updated_date": "2024-09-30 03:56:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:54:20.946729"
    },
    {
      "arxiv_id": "2406.12449v1",
      "title": "Retrieval-Augmented Generation for Generative Artificial Intelligence in Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Yang",
        "Yilin Ning",
        "Emilia Keppo",
        "Mingxuan Liu",
        "Chuan Hong",
        "Danielle S Bitterman",
        "Jasmine Chiat Ling Ong",
        "Daniel Shu Wei Ting",
        "Nan Liu"
      ],
      "abstract": "Generative artificial intelligence (AI) has brought revolutionary innovations\nin various fields, including medicine. However, it also exhibits limitations.\nIn response, retrieval-augmented generation (RAG) provides a potential\nsolution, enabling models to generate more accurate contents by leveraging the\nretrieval of external knowledge. With the rapid advancement of generative AI,\nRAG can pave the way for connecting this transformative technology with medical\napplications and is expected to bring innovations in equity, reliability, and\npersonalization to health care.",
      "tldr_zh": "生成式人工智能（Generative AI）在医学领域带来了革命性创新，但也存在准确性等局限性。论文提出检索增强生成（Retrieval-Augmented Generation, RAG）作为解决方案，通过检索外部知识来提升模型生成内容的准确性。RAG有望将Generative AI与医疗应用紧密结合，推动健康护理在公平性、可靠性和个性化方面的创新。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12449v1",
      "published_date": "2024-06-18 09:53:37 UTC",
      "updated_date": "2024-06-18 09:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:54:31.219066"
    },
    {
      "arxiv_id": "2406.12442v2",
      "title": "Abstraction-of-Thought Makes Language Models Better Reasoners",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixin Hong",
        "Hongming Zhang",
        "Xiaoman Pan",
        "Dong Yu",
        "Changshui Zhang"
      ],
      "abstract": "Abstract reasoning, the ability to reason from the abstract essence of a\nproblem, serves as a key to generalization in human reasoning. However,\neliciting language models to perform reasoning with abstraction remains\nunexplored. This paper seeks to bridge this gap by introducing a novel\nstructured reasoning format called Abstraction-of-Thought (AoT). The uniqueness\nof AoT lies in its explicit requirement for varying levels of abstraction\nwithin the reasoning process. This approach could elicit language models to\nfirst contemplate on the abstract level before incorporating concrete details,\nwhich is overlooked by the prevailing step-by-step Chain-of-Thought (CoT)\nmethod. To align models with the AoT format, we present AoT Collection, a\ngeneric finetuning dataset consisting of 348k high-quality samples with AoT\nreasoning processes, collected via an automated and scalable pipeline. We\nfinetune a wide range of language models with AoT Collection and conduct\nextensive evaluations on 23 unseen tasks from the challenging benchmark\nBig-Bench Hard. Experimental results indicate that models aligned to AoT\nreasoning format substantially outperform those aligned to CoT in many\nreasoning tasks.",
      "tldr_zh": "本文提出了一种新型结构化推理格式 Abstraction-of-Thought (AoT)，旨在提升语言模型的抽象推理能力，通过要求模型先从抽象层面思考再融入具体细节，弥补传统 Chain-of-Thought (CoT) 方法的不足。研究者构建了 AoT Collection 数据集，包含 348k 高质量样本，并使用自动化可扩展管道进行收集，以微调多种语言模型。实验在 Big-Bench Hard 基准的 23 个未见过任务上进行，结果显示，AoT 微调模型在许多推理任务上显著优于 CoT 微调模型，证明了 AoT 在促进模型泛化方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.12442v2",
      "published_date": "2024-06-18 09:46:44 UTC",
      "updated_date": "2024-09-26 11:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:54:46.339197"
    },
    {
      "arxiv_id": "2406.12441v1",
      "title": "Cycle-Correspondence Loss: Learning Dense View-Invariant Visual Features from Unlabeled and Unordered RGB Images",
      "title_zh": "翻译失败",
      "authors": [
        "David B. Adrian",
        "Andras Gabor Kupcsik",
        "Markus Spies",
        "Heiko Neumann"
      ],
      "abstract": "Robot manipulation relying on learned object-centric descriptors became\npopular in recent years. Visual descriptors can easily describe manipulation\ntask objectives, they can be learned efficiently using self-supervision, and\nthey can encode actuated and even non-rigid objects. However, learning robust,\nview-invariant keypoints in a self-supervised approach requires a meticulous\ndata collection approach involving precise calibration and expert supervision.\nIn this paper we introduce Cycle-Correspondence Loss (CCL) for view-invariant\ndense descriptor learning, which adopts the concept of cycle-consistency,\nenabling a simple data collection pipeline and training on unpaired RGB camera\nviews. The key idea is to autonomously detect valid pixel correspondences by\nattempting to use a prediction over a new image to predict the original pixel\nin the original image, while scaling error terms based on the estimated\nconfidence. Our evaluation shows that we outperform other self-supervised\nRGB-only methods, and approach performance of supervised methods, both with\nrespect to keypoint tracking as well as for a robot grasping downstream task.",
      "tldr_zh": "本文提出 Cycle-Correspondence Loss (CCL)，一种自监督方法，用于从未标记和无序的 RGB 图像中学习密集视图不变视觉特征，从而简化机器人操作中的物体描述符训练过程。CCL 通过循环一致性概念自主检测像素对应关系，并根据估计置信度缩放错误项，避免了精确校准和专家监督的需求。实验评估显示，该方法在关键点跟踪和机器人抓取下游任务上超过了其他自监督 RGB-only 方法，并接近监督方法的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.12441v1",
      "published_date": "2024-06-18 09:44:56 UTC",
      "updated_date": "2024-06-18 09:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:54:56.351362"
    },
    {
      "arxiv_id": "2406.12435v1",
      "title": "Federated Learning with Limited Node Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Bisheng Tang",
        "Xiaojun Chen",
        "Shaopu Wang",
        "Yuexin Xuan",
        "Zhendong Zhao"
      ],
      "abstract": "Subgraph federated learning (SFL) is a research methodology that has gained\nsignificant attention for its potential to handle distributed graph-structured\ndata. In SFL, the local model comprises graph neural networks (GNNs) with a\npartial graph structure. However, some SFL models have overlooked the\nsignificance of missing cross-subgraph edges, which can lead to local GNNs\nbeing unable to message-pass global representations to other parties' GNNs.\nMoreover, existing SFL models require substantial labeled data, which limits\ntheir practical applications. To overcome these limitations, we present a novel\nSFL framework called FedMpa that aims to learn cross-subgraph node\nrepresentations. FedMpa first trains a multilayer perceptron (MLP) model using\na small amount of data and then propagates the federated feature to the local\nstructures. To further improve the embedding representation of nodes with local\nsubgraphs, we introduce the FedMpae method, which reconstructs the local graph\nstructure with an innovation view that applies pooling operation to form\nsuper-nodes. Our extensive experiments on six graph datasets demonstrate that\nFedMpa is highly effective in node classification. Furthermore, our ablation\nexperiments verify the effectiveness of FedMpa.",
      "tldr_zh": "本论文针对子图联邦学习（Subgraph Federated Learning, SFL）中的问题，提出了一种名为 FedMpa 的新框架，以处理分布式图结构数据时缺失的跨子图边和标签数据有限的挑战。FedMpa 方法首先利用少量数据训练一个 Multilayer Perceptron (MLP) 模型，然后将联邦特征传播到本地子图结构中，以学习跨子图节点表示；此外，FedMpae 作为改进版本，通过应用 pooling 操作形成超节点来重建本地图结构，进一步提升嵌入表示。实验结果显示，在六个图数据集上，FedMpa 在节点分类任务中表现出色，比基线方法更有效，且消融实验验证了其组件的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12435v1",
      "published_date": "2024-06-18 09:30:10 UTC",
      "updated_date": "2024-06-18 09:30:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:55:08.825946"
    },
    {
      "arxiv_id": "2406.12432v2",
      "title": "MEMS and ECM Sensor Technologies for Cardiorespiratory Sound Monitoring - A Comprehensive Review",
      "title_zh": "翻译失败",
      "authors": [
        "Yasaman Torabi",
        "Shahram Shirani",
        "James P. Reilly",
        "Gail M Gauvreau"
      ],
      "abstract": "This paper presents a comprehensive review of cardiorespiratory auscultation\nsensing devices (i.e., stethoscopes), which is useful for understanding the\ntheoretical aspects and practical design notes. In this paper, we first\nintroduce the acoustic properties of the heart and lungs, as well as a brief\nhistory of stethoscope evolution. Then, we discuss the basic concept of\nelectret condenser microphones (ECMs) and a stethoscope based on them. Then, we\ndiscuss the microelectromechanical systems (MEMSs) technology, particularly\nfocusing on piezoelectric transducer sensors. This paper comprehensively\nreviews sensing technologies for cardiorespiratory auscultation, emphasizing\nMEMS-based wearable designs in the past decade. To our knowledge, this is the\nfirst paper to summarize ECM and MEMS applications for heart and lung sound\nanalysis.",
      "tldr_zh": "这篇论文对卡迪奥呼吸道听诊（cardiorespiratory auscultation）中的传感器技术进行了全面回顾，重点关注微机电系统（MEMS）和驻极体电容麦克风（ECMs）。论文首先介绍了心脏和肺部的声学特性、听诊器的发展历史，以及基于 ECMs 的听诊器设计，然后详细讨论了 MEMS 技术，特别是压电传感器在可穿戴设备中的应用。作者强调，这是第一篇总结 ECM 和 MEMS 在心肺声音分析中的应用的文献，为未来设计提供理论和实践指导。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12432v2",
      "published_date": "2024-06-18 09:28:23 UTC",
      "updated_date": "2025-02-14 08:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:55:20.927911"
    },
    {
      "arxiv_id": "2406.12430v1",
      "title": "PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers",
      "title_zh": "翻译失败",
      "authors": [
        "Myeonghwa Lee",
        "Seonho An",
        "Min-Soo Kim"
      ],
      "abstract": "In this paper, we conduct a study to utilize LLMs as a solution for decision\nmaking that requires complex data analysis. We define Decision QA as the task\nof answering the best decision, $d_{best}$, for a decision-making question $Q$,\nbusiness rules $R$ and a database $D$. Since there is no benchmark that can\nexamine Decision QA, we propose Decision QA benchmark, DQA. It has two\nscenarios, Locating and Building, constructed from two video games (Europa\nUniversalis IV and Victoria 3) that have almost the same goal as Decision QA.\nTo address Decision QA effectively, we also propose a new RAG technique called\nthe iterative plan-then-retrieval augmented generation (PlanRAG). Our\nPlanRAG-based LM generates the plan for decision making as the first step, and\nthe retriever generates the queries for data analysis as the second step. The\nproposed method outperforms the state-of-the-art iterative RAG method by 15.8%\nin the Locating scenario and by 7.4% in the Building scenario, respectively. We\nrelease our code and benchmark at https://github.com/myeon9h/PlanRAG.",
      "tldr_zh": "本文研究如何利用生成式大型语言模型 (LLMs) 作为决策工具，定义了 Decision QA 任务，即基于决策问题 $Q$、业务规则 $R$ 和数据库 $D$ 回答最佳决策 $d_{best}$。为了评估该任务，作者提出了 DQA 基准，使用两个视频游戏 (Europa Universalis IV 和 Victoria 3) 构建了 Locating 和 Building 场景。论文引入了 PlanRAG 方法，该技术通过先生成决策计划再进行检索增强生成 (RAG)，在实验中比现有迭代 RAG 方法在 Locating 场景提高 15.8%、在 Building 场景提高 7.4%。代码和基准已开源于 https://github.com/myeon9h/PlanRAG。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12430v1",
      "published_date": "2024-06-18 09:25:35 UTC",
      "updated_date": "2024-06-18 09:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:55:33.825314"
    },
    {
      "arxiv_id": "2406.12429v3",
      "title": "Query Routing for Homogeneous Tools: An Instantiation in the RAG Scenario",
      "title_zh": "同质工具的",
      "authors": [
        "Feiteng Mu",
        "Yong Jiang",
        "Liwen Zhang",
        "Chu Liu",
        "Wenjie Li",
        "Pengjun Xie",
        "Fei Huang"
      ],
      "abstract": "Current research on tool learning primarily focuses on selecting the most\neffective tool from a wide array of options, often overlooking\ncost-effectiveness, a crucial factor in human problem-solving. In this paper,\nwe address the selection of homogeneous tools by predicting both their\nperformance and the associated cost required to accomplish a given task. We\nthen assign queries to the optimal tools in a cost-effective manner. Our\nexperimental results demonstrate that our method achieves higher performance at\na lower cost compared to strong baseline approaches.",
      "tldr_zh": "该论文关注工具学习中的查询路由（query routing），针对同质工具（homogeneous tools）提出一种方法，不仅预测工具的性能，还考虑执行任务的成本，从而以成本有效的方式分配查询。研究在RAG（Retrieval-Augmented Generation）场景中实例化该方法，通过优化工具选择来提升整体效率。实验结果显示，该方法相较于强基线方法，在较低成本下实现了更高的性能表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12429v3",
      "published_date": "2024-06-18 09:24:09 UTC",
      "updated_date": "2024-09-30 06:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:55:45.284770"
    },
    {
      "arxiv_id": "2406.12428v2",
      "title": "PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Kentaro Mitsui",
        "Koh Mitsuda",
        "Toshiaki Wakatsuki",
        "Yukiya Hono",
        "Kei Sawada"
      ],
      "abstract": "Multimodal language models that process both text and speech have a potential\nfor applications in spoken dialogue systems. However, current models face two\nmajor challenges in response generation latency: (1) generating a spoken\nresponse requires the prior generation of a written response, and (2) speech\nsequences are significantly longer than text sequences. This study addresses\nthese issues by extending the input and output sequences of the language model\nto support the parallel generation of text and speech. Our experiments on\nspoken question answering tasks demonstrate that our approach improves latency\nwhile maintaining the quality of response content. Additionally, we show that\nlatency can be further reduced by generating speech in multiple sequences. Demo\nsamples are available at https://rinnakk.github.io/research/publications/PSLM.",
      "tldr_zh": "这篇论文介绍了 PSLM，一种利用 LLMs 实现文本和语音并行生成的框架，旨在解决口语对话系统中的响应延迟问题，例如先生成文本再生成语音以及语音序列过长的问题。通过扩展语言模型的输入和输出序列，PSLM 支持同时处理文本和语音生成。实验在口语问答任务上表明，该方法显著降低了延迟，同时保持了响应内容的质量；此外，通过将语音生成分成多个序列，进一步优化了性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 6 figures, 4 tables, accepted for Findings of EMNLP 2024.\n  Demo samples: https://rinnakk.github.io/research/publications/PSLM",
      "pdf_url": "http://arxiv.org/pdf/2406.12428v2",
      "published_date": "2024-06-18 09:23:54 UTC",
      "updated_date": "2024-10-03 05:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:55:58.095848"
    },
    {
      "arxiv_id": "2407.12791v1",
      "title": "TourLLM: Enhancing LLMs with Tourism Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Qikai Wei",
        "Mingzhi Yang",
        "Jinqiang Wang",
        "Wenwei Mao",
        "Jiabo Xu",
        "Huansheng Ning"
      ],
      "abstract": "Recently, large language models (LLMs) have demonstrated their effectiveness\nin various natural language processing (NLP) tasks. However, the lack of\ntourism knowledge limits the performance of LLMs in tourist attraction\npresentations and travel planning. To address this challenge, we constructed a\nsupervised fine-tuning dataset for the culture and tourism domain, named\nCultour. This dataset consists of three parts: tourism knowledge base QA data,\ntravelogues data, and tourism diversity QA data. Additionally, we propose\nTourLLM, a Qwen-based model supervised fine-tuned with Cultour, to improve the\nquality of the information provided about attractions and travel planning. To\nevaluate the performance of TourLLM, we employed both automatic and human\nevaluation, and we proposed a human evaluation criterion named CRA\n(Consistency, Readability, Availability). The experimental results demonstrate\nthe effectiveness of the responses generated by the TourLLM. Our proposed\nCultour is accessible at https://github.com/mrweiqk/Cultour.",
      "tldr_zh": "本研究发现，大语言模型（LLMs）在旅游景点介绍和旅行规划上因缺乏旅游知识而表现不佳。为解决此问题，研究者构建了名为 Cultour 的监督微调数据集，包括旅游知识库 QA 数据、旅行日志数据和旅游多样性 QA 数据，并提出基于 Qwen 模型的 TourLLM，通过监督微调提升旅游相关信息的质量。评估采用自动和人工方法，包括新提出的 CRA 标准（Consistency, Readability, Availability），实验结果显示 TourLLM 生成的响应更有效，且 Cultour 数据集已开源于 GitHub。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12791v1",
      "published_date": "2024-06-18 09:15:46 UTC",
      "updated_date": "2024-06-18 09:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:56:11.099064"
    },
    {
      "arxiv_id": "2406.12416v2",
      "title": "Beyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hongbang Yuan",
        "Yubo Chen",
        "Pengfei Cao",
        "Zhuoran Jin",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable success but still tend\nto generate factually erroneous responses, a phenomenon known as hallucination.\nA recent trend is to use preference learning to fine-tune models to align with\nfactuality. However, existing work primarily evaluates fine-tuned models on\nin-domain (ID) datasets and the factuality on out-of-domain (OOD) datasets\nremains underexplored. In this paper, we conduct a comprehensive evaluation of\nthe factuality of different models tuned by various preference learning\nalgorithms and demonstrate that their performance on OOD datasets either\nincreases minimally or decreases. Subsequently, we reveal that the main cause\nof model's failure to uphold factuality under a distribution shift is\n\\textbf{under-alignment}, rather than \\textbf{over-alignment}, by analyzing the\ntoken distribution shift of the models before and after tuning. Finally, we\npropose \\textbf{APEFT} (\\textbf{A}tomic \\textbf{P}reference \\textbf{E}nhanced\n\\textbf{F}actuality \\textbf{T}uning), a framework that enhances model's\nawareness of factuality at the granularity of individual facts. Extensive\nexperiments demonstrate that APEFT improves model performance by an average of\n$\\boldsymbol{3.45\\%}$ on both ID and OOD datasets, which is highly effective.",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）在生成事实错误（hallination）方面的挑战，指出现有偏好学习方法虽能提升模型在领域内（ID）数据集上的事实性，但对领域外（OOD）数据集的表现要么微增要么下降，主要归因于under-alignment而非over-alignment。研究通过分析微调前后token分布移位揭示了这一问题，并提出APEFT（Atomic Preference Enhanced Factuality Tuning）框架，在单个事实粒度上增强模型对事实性的意识。实验结果显示，APEFT在ID和OOD数据集上平均提高了3.45%的性能，显著提升了模型的泛化事实性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12416v2",
      "published_date": "2024-06-18 09:07:30 UTC",
      "updated_date": "2024-06-27 12:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:56:23.082940"
    },
    {
      "arxiv_id": "2406.12413v2",
      "title": "Pushing the Frontier on Approximate EFX Allocations",
      "title_zh": "推进近似",
      "authors": [
        "Georgios Amanatidis",
        "Aris Filos-Ratsikas",
        "Alkmini Sgouritsa"
      ],
      "abstract": "We study the problem of allocating a set of indivisible goods to a set of\nagents with additive valuation functions, aiming to achieve approximate\nenvy-freeness up to any good ($\\alpha$-EFX). The state-of-the-art results on\nthe problem include that (exact) EFX allocations exist when (a) there are at\nmost three agents, or (b) the agents' valuation functions can take at most two\nvalues, or (c) the agents' valuation functions can be represented via a graph.\nFor $\\alpha$-EFX, it is known that a $0.618$-EFX allocation exists for any\nnumber of agents with additive valuation functions. In this paper, we show that\n$2/3$-EFX allocations exist when (a) there are at most \\emph{seven agents}, (b)\nthe agents' valuation functions can take at most \\emph{three values}, or (c)\nthe agents' valuation functions can be represented via a \\emph{multigraph}. Our\nresults can be interpreted in two ways. First, by relaxing the notion of EFX to\n$2/3$-EFX, we obtain existence results for strict generalizations of the\nsettings for which exact EFX allocations are known to exist. Secondly, by\nimposing restrictions on the setting, we manage to beat the barrier of $0.618$\nand achieve an approximation guarantee of $2/3$. Therefore, our results push\nthe \\emph{frontier} of existence and computation of approximate EFX\nallocations, and provide insights into the challenges of settling the existence\nof exact EFX allocations.",
      "tldr_zh": "该论文探讨了在加性 valuation functions 下，将不可分割物品分配给代理人，以实现近似 envy-freeness up to any good（α-EFX）的机制。现有的精确 EFX 分配仅在代理人不超过三个、估值函数最多两个值或通过图表示等有限场景中存在，而 α-EFX 已知可达 0.618 近似。论文的主要贡献是证明了 2/3-EFX 分配在代理人不超过七个、估值函数最多三个值或通过 multigraph 表示的条件下均存在，从而扩展了精确 EFX 的适用范围，并为超越 0.618 界限提供了新洞见，推动了近似 EFX 分配研究的边界。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.DM"
      ],
      "primary_category": "cs.GT",
      "comment": "The conference version of this work has been accepted to the\n  Twenty-Fifth ACM Conference on Economics and Computation (EC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.12413v2",
      "published_date": "2024-06-18 09:01:37 UTC",
      "updated_date": "2025-04-23 13:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:56:35.466145"
    },
    {
      "arxiv_id": "2406.12412v1",
      "title": "A Novel Algorithm for Community Detection in Networks using Rough Sets and Consensus Clustering",
      "title_zh": "一种使用粗糙集和共识聚类的网络社区检测新颖算法",
      "authors": [
        "Darian H. Grass-Boada",
        "Leandro González-Montesino",
        "Rubén Armañanzas"
      ],
      "abstract": "Complex networks, such as those in social, biological, and technological\nsystems, often present challenges to the task of community detection. Our\nresearch introduces a novel rough clustering based consensus community\nframework (RC-CCD) for effective structure identification of network\ncommunities. The RC-CCD method employs rough set theory to handle uncertainties\nwithin data and utilizes a consensus clustering approach to aggregate multiple\nclustering results, enhancing the reliability and accuracy of community\ndetection. This integration allows the RC-CCD to effectively manage overlapping\ncommunities, which are often present in complex networks.\n  This approach excels at detecting overlapping communities, offering a\ndetailed and accurate representation of network structures. Comprehensive\ntesting on benchmark networks generated by the Lancichinetti-Fortunato-Radicchi\nmethod showcased the strength and adaptability of the new proposal to varying\nnode degrees and community sizes. Cross-comparisons of RC-CCD versus other well\nknown detection algorithms outcomes highlighted its stability and adaptability.",
      "tldr_zh": "本研究提出了一种新的社区检测算法RC-CCD，用于处理复杂网络（如社会、生物和技术系统）中的社区结构。该算法结合rough set theory来管理数据不确定性，并采用consensus clustering方法聚合多个聚类结果，从而提高社区检测的可靠性和准确性，尤其在处理重叠社区方面表现出色。在Lancichinetti-Fortunato-Radicchi基准网络上的测试显示，RC-CCD比其他知名算法具有更好的稳定性和适应性。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12412v1",
      "published_date": "2024-06-18 09:01:21 UTC",
      "updated_date": "2024-06-18 09:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:56:45.159927"
    },
    {
      "arxiv_id": "2406.12406v1",
      "title": "Fast Rates for Bandit PAC Multiclass Classification",
      "title_zh": "针对 Bandit PAC 多类分类的快速收敛率",
      "authors": [
        "Liad Erez",
        "Alon Cohen",
        "Tomer Koren",
        "Yishay Mansour",
        "Shay Moran"
      ],
      "abstract": "We study multiclass PAC learning with bandit feedback, where inputs are\nclassified into one of $K$ possible labels and feedback is limited to whether\nor not the predicted labels are correct. Our main contribution is in designing\na novel learning algorithm for the agnostic $(\\varepsilon,\\delta)$-PAC version\nof the problem, with sample complexity of $O\\big( (\\operatorname{poly}(K) + 1 /\n\\varepsilon^2) \\log (|H| / \\delta) \\big)$ for any finite hypothesis class $H$.\nIn terms of the leading dependence on $\\varepsilon$, this improves upon\nexisting bounds for the problem, that are of the form $O(K/\\varepsilon^2)$. We\nalso provide an extension of this result to general classes and establish\nsimilar sample complexity bounds in which $\\log |H|$ is replaced by the\nNatarajan dimension. This matches the optimal rate in the full-information\nversion of the problem and resolves an open question studied by Daniely,\nSabato, Ben-David, and Shalev-Shwartz (2011) who demonstrated that the\nmultiplicative price of bandit feedback in realizable PAC learning is\n$\\Theta(K)$. We complement this by revealing a stark contrast with the agnostic\ncase, where the price of bandit feedback is only $O(1)$ as $\\varepsilon \\to 0$.\nOur algorithm utilizes a stochastic optimization technique to minimize a\nlog-barrier potential based on Frank-Wolfe updates for computing a low-variance\nexploration distribution over the hypotheses, and is made computationally\nefficient provided access to an ERM oracle over $H$.",
      "tldr_zh": "本研究探讨了多类 PAC 学习（multiclass PAC learning）中的带盗反馈（bandit feedback）问题，设计了一个新算法，用于 agnostic (ε, δ)-PAC 版本，显著降低了样本复杂度至 O((poly(K) + 1 / ε²) log(|H| / δ))，比现有 O(K / ε²) 的界限更高效。算法采用随机优化技术，通过 Frank-Wolfe updates 最小化 log-barrier potential，以计算低方差的假设探索分布，并依赖于 ERM oracle 实现计算效率。该方法扩展到一般类，使用 Natarajan dimension 替换 log |H|，并证明在 agnostic 情况下，bandit feedback 的价格仅为 O(1) 当 ε → 0，与 full-information 版本的优化率相当，解决了 Daniely 等人的开放问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12406v1",
      "published_date": "2024-06-18 08:54:04 UTC",
      "updated_date": "2024-06-18 08:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:57:00.042956"
    },
    {
      "arxiv_id": "2406.12403v1",
      "title": "PDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Fan",
        "Yan Kang",
        "Weijing Chen",
        "Hanlin Gu",
        "Yuanfeng Song",
        "Lixin Fan",
        "Kai Chen",
        "Qiang Yang"
      ],
      "abstract": "In the context of real-world applications, leveraging large language models\n(LLMs) for domain-specific tasks often faces two major challenges:\ndomain-specific knowledge privacy and constrained resources. To address these\nissues, we propose PDSS, a privacy-preserving framework for step-by-step\ndistillation of LLMs. PDSS works on a server-client architecture, wherein\nclient transmits perturbed prompts to the server's LLM for rationale\ngeneration. The generated rationales are then decoded by the client and used to\nenrich the training of task-specific small language model(SLM) within a\nmulti-task learning paradigm. PDSS introduces two privacy protection\nstrategies: the Exponential Mechanism Strategy and the Encoder-Decoder\nStrategy, balancing prompt privacy and rationale usability. Experiments\ndemonstrate the effectiveness of PDSS in various text generation tasks,\nenabling the training of task-specific SLM with enhanced performance while\nprioritizing data privacy protection.",
      "tldr_zh": "该论文提出PDSS框架，用于解决大语言模型(LLMs)在领域特定任务中的知识隐私和资源限制问题。PDSS采用服务器-客户端架构，客户端通过发送扰动提示来获取服务器的推理生成，并解码后用于多任务学习中训练任务特定的小语言模型(SLMs)。框架引入了Exponential Mechanism Strategy和Encoder-Decoder Strategy两种隐私保护策略，以平衡提示隐私和推理可用性。实验结果显示，PDSS在各种文本生成任务中显著提升SLMs性能，同时有效保护数据隐私。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12403v1",
      "published_date": "2024-06-18 08:48:14 UTC",
      "updated_date": "2024-06-18 08:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:57:10.009582"
    },
    {
      "arxiv_id": "2406.12400v1",
      "title": "A Cutting-Edge Deep Learning Method For Enhancing IoT Security",
      "title_zh": "翻译失败",
      "authors": [
        "Nadia Ansar",
        "Mohammad Sadique Ansari",
        "Mohammad Sharique",
        "Aamina Khatoon",
        "Md Abdul Malik",
        "Md Munir Siddiqui"
      ],
      "abstract": "There have been significant issues given the IoT, with heterogeneity of\nbillions of devices and with a large amount of data. This paper proposed an\ninnovative design of the Internet of Things (IoT) Environment Intrusion\nDetection System (or IDS) using Deep Learning-integrated Convolutional Neural\nNetworks (CNN) and Long Short-Term Memory (LSTM) networks. Our model, based on\nthe CICIDS2017 dataset, achieved an accuracy of 99.52% in classifying network\ntraffic as either benign or malicious. The real-time processing capability,\nscalability, and low false alarm rate in our model surpass some traditional IDS\napproaches and, therefore, prove successful for application in today's IoT\nnetworks. The development and the performance of the model, with possible\napplications that may extend to other related fields of adaptive learning\ntechniques and cross-domain applicability, are discussed. The research\ninvolving deep learning for IoT cybersecurity offers a potent solution for\nsignificantly improving network security.",
      "tldr_zh": "本研究提出了一种创新的深度学习方法，用于提升物联网（IoT）安全，设计了一个整合卷积神经网络（CNN）和长短期记忆网络（LSTM）的入侵检测系统（IDS）。该模型基于CICIDS2017数据集，对网络流量进行良性或恶意分类，实现了99.52%的准确率。相比传统IDS，该系统具备实时处理能力、可扩展性和低误报率，为IoT网络安全提供了高效解决方案，并具有扩展到自适应学习和跨域应用的潜力。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12400v1",
      "published_date": "2024-06-18 08:42:51 UTC",
      "updated_date": "2024-06-18 08:42:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:57:21.549845"
    },
    {
      "arxiv_id": "2406.12399v1",
      "title": "QueerBench: Quantifying Discrimination in Language Models Toward Queer Identities",
      "title_zh": "翻译失败",
      "authors": [
        "Mae Sosto",
        "Alberto Barrón-Cedeño"
      ],
      "abstract": "With the increasing role of Natural Language Processing (NLP) in various\napplications, challenges concerning bias and stereotype perpetuation are\naccentuated, which often leads to hate speech and harm. Despite existing\nstudies on sexism and misogyny, issues like homophobia and transphobia remain\nunderexplored and often adopt binary perspectives, putting the safety of\nLGBTQIA+ individuals at high risk in online spaces. In this paper, we assess\nthe potential harm caused by sentence completions generated by English large\nlanguage models (LLMs) concerning LGBTQIA+ individuals. This is achieved using\nQueerBench, our new assessment framework, which employs a template-based\napproach and a Masked Language Modeling (MLM) task. The analysis indicates that\nlarge language models tend to exhibit discriminatory behaviour more frequently\ntowards individuals within the LGBTQIA+ community, reaching a difference gap of\n7.2% in the QueerBench score of harmfulness.",
      "tldr_zh": "本研究探讨了自然语言处理(NLP)模型在应用中对酷儿身份(LGBTQIA+ 群体)的歧视问题，强调现有研究多关注性别偏见而忽略了同性恋恐惧和跨性别恐惧等风险。论文引入了QueerBench，这是一个新的评估框架，通过模板-based方法和Masked Language Modeling (MLM)任务，量化了大型语言模型(LLMs)在生成句子时对LGBTQIA+个体的潜在伤害。分析结果显示，LLMs对LGBTQIA+群体的歧视行为更频繁，在QueerBench伤害分数上与非LGBTQIA+群体相比差异达7.2%。这项工作为减少AI偏见并提升在线空间的安全性提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12399v1",
      "published_date": "2024-06-18 08:40:29 UTC",
      "updated_date": "2024-06-18 08:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:57:35.453799"
    },
    {
      "arxiv_id": "2406.12946v1",
      "title": "Instruction Data Generation and Unsupervised Adaptation for Speech Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vahid Noroozi",
        "Zhehuai Chen",
        "Somshubra Majumdar",
        "Steve Huang",
        "Jagadeesh Balam",
        "Boris Ginsburg"
      ],
      "abstract": "In this paper, we propose three methods for generating synthetic samples to\ntrain and evaluate multimodal large language models capable of processing both\ntext and speech inputs. Addressing the scarcity of samples containing both\nmodalities, synthetic data generation emerges as a crucial strategy to enhance\nthe performance of such systems and facilitate the modeling of cross-modal\nrelationships between the speech and text domains. Our process employs large\nlanguage models to generate textual components and text-to-speech systems to\ngenerate speech components. The proposed methods offer a practical and\neffective means to expand the training dataset for these models. Experimental\nresults show progress in achieving an integrated understanding of text and\nspeech. We also highlight the potential of using unlabeled speech data to\ngenerate synthetic samples comparable in quality to those with available\ntranscriptions, enabling the expansion of these models to more languages.",
      "tldr_zh": "本研究提出三种方法，用于生成合成样本以训练和评估多模态大型语言模型（multimodal large language models），以处理文本和语音输入的问题。针对样本稀缺的挑战，该方法利用大型语言模型（large language models）生成文本组件，并结合文本到语音系统（text-to-speech systems）创建语音组件，从而增强系统性能和跨模态关系建模。实验结果显示，该方法显著提高了文本和语音的整合理解能力；此外，通过使用无标签语音数据生成高质量合成样本，该框架能扩展模型应用至更多语言。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted for Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12946v1",
      "published_date": "2024-06-18 08:27:00 UTC",
      "updated_date": "2024-06-18 08:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:57:47.791483"
    },
    {
      "arxiv_id": "2406.12381v3",
      "title": "QOG:Question and Options Generation based on Language Model",
      "title_zh": "QOG：基于语言模型的问题和选项生成",
      "authors": [
        "Jincheng Zhou"
      ],
      "abstract": "Question-Options Generation (QOG) is a task that involves generating a set of\nquestion-options pairs given context. This task has various applications,\nincluding fine-tuning large models, information retrieval, and automated\nmultiple-choice question generation for education. In this paper, we develop\nQOG models using three different methods based on fine-tuning\nsequence-to-sequence language models (LMs). Experiments demonstrate that the\nend-to-end QOG model is computationally efficient and stable during both\ntraining and inference, outperforming other methods. Furthermore, our analysis\nindicates that our QOG models are competitive on the QOG task compared to the\nlarge language model Llama 3-8B.",
      "tldr_zh": "本研究提出了 QOG（Question and Options Generation）任务，该任务基于给定上下文生成问题-选项对，并应用于微调大型模型、信息检索以及教育中的自动多项选择题生成。研究团队开发了三种基于微调序列到序列语言模型（LMs）的 QOG 方法，其中端到端模型在训练和推理过程中表现出更高的计算效率和稳定性，并优于其他方法。实验分析显示，这些 QOG 模型在 QOG 任务上的性能与大型语言模型 Llama 3-8B 相当，具有较强的竞争力和实用价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12381v3",
      "published_date": "2024-06-18 08:09:58 UTC",
      "updated_date": "2024-07-16 08:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:57:59.611011"
    },
    {
      "arxiv_id": "2406.12375v1",
      "title": "GW-MoE: Resolving Uncertainty in MoE Router with Global Workspace Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Haoze Wu",
        "Zihan Qiu",
        "Zili Wang",
        "Hang Zhao",
        "Jie Fu"
      ],
      "abstract": "Mixture-of-Experts (MoE) has been demonstrated as an efficient method to\nscale up models. By dynamically and sparsely selecting activated experts, MoE\ncan effectively reduce computational costs. Despite the success, we observe\nthat many tokens in the MoE models have uncertain routing results. These tokens\nhave nearly equal scores for choosing each expert, and we demonstrate that this\nuncertainty can lead to incorrect selections. Inspired by the Global Workspace\nTheory (GWT), we propose a new fine-tuning method, GW-MoE, to address this\nissue. The core idea is to broadcast the uncertain tokens across experts during\nfine-tuning. Therefore, these tokens can acquire the necessary knowledge from\nany expert during inference and become less sensitive to the choice. GW-MoE\ndoes not introduce additional inference overhead. We validate that GW can\nmitigate the uncertain problem and consistently improve in different tasks\n(text classification, question answering, summarization, code generation, and\nmathematical problem solving) and model sizes (650M and 8B parameters).",
      "tldr_zh": "该论文针对 Mixture-of-Experts (MoE) 模型中路由不确定性问题提出了一种新微调方法 GW-MoE，该问题导致许多 token 在选择专家时出现近等分值并可能选错。GW-MoE 受 Global Workspace Theory (GWT) 启发，通过在微调过程中将不确定 token 广播到所有专家，让这些 token 能从任意专家获取知识，从而减少对路由选择的敏感性，且不增加推理开销。实验验证显示，GW-MoE 在文本分类、问答、摘要、代码生成和数学问题解决等任务上，以及 650M 和 8B 参数的模型中，均 consistently 提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12375v1",
      "published_date": "2024-06-18 08:03:51 UTC",
      "updated_date": "2024-06-18 08:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:58:12.705708"
    },
    {
      "arxiv_id": "2406.12374v3",
      "title": "Problem-Solving in Language Model Networks",
      "title_zh": "语言模型网络中的问题解决",
      "authors": [
        "Ciaran Regan",
        "Alexandre Gournail",
        "Mizuki Oka"
      ],
      "abstract": "To improve the reasoning and question-answering capabilities of Large\nLanguage Models (LLMs), several multi-agent approaches have been introduced.\nWhile these methods enhance performance, the application of collective\nintelligence-based approaches to complex network structures and the dynamics of\nagent interactions remain underexplored. This work extends the concept of\nmulti-agent debate to more general network topologies, measuring the\nquestion-answering accuracy, influence, consensus, and the effects of bias on\nthe collective. The results show that random networks perform similarly to\nfully connected networks despite using significantly fewer tokens. Furthermore,\na strong consensus among agents correlates with correct answers, whereas\ndivided responses typically indicate incorrect answers. Analysing the influence\nof the agents reveals a balance between self-reflection and interconnectedness;\nself-reflection aids when local interactions are incorrect, and local\ninteractions aid when the agent itself is incorrect. Additionally, bias plays a\nstrong role in system performance with correctly biased hub nodes boosting\nperformance. These insights suggest that using random networks or scale-free\nnetworks with knowledgeable agents placed in central positions can enhance the\noverall question-answering performance of multi-agent systems.",
      "tldr_zh": "这篇论文探讨了在大型语言模型 (LLMs) 中使用多智能体系统来提升问题解决和问答能力的潜力，扩展了多智能体辩论到各种网络拓扑，如随机网络和规模自由网络，并测量了问答准确性、影响、共识以及偏见的影响。研究发现，随机网络的表现与完全连接网络相当，但使用更少的 tokens；代理间的共识通常与正确答案相关，而分歧则预示错误。影响分析显示，自省有助于纠正局部错误，而互连则在代理自身出错时提供支持；此外，正确偏见的中心节点能显著提升整体性能。总之，该工作建议通过在随机或规模自由网络中放置知识丰富的代理来优化多智能体系统的效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2024 Conference on Artificial Life",
      "pdf_url": "http://arxiv.org/pdf/2406.12374v3",
      "published_date": "2024-06-18 07:59:14 UTC",
      "updated_date": "2024-07-09 13:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:58:24.686649"
    },
    {
      "arxiv_id": "2406.12373v3",
      "title": "WebCanvas: Benchmarking Web Agents in Online Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Pan",
        "Dehan Kong",
        "Sida Zhou",
        "Cheng Cui",
        "Yifei Leng",
        "Bing Jiang",
        "Hangyu Liu",
        "Yanyi Shang",
        "Shuyan Zhou",
        "Tongshuang Wu",
        "Zhengyang Wu"
      ],
      "abstract": "For web agents to be practically useful, they must adapt to the continuously\nevolving web environment characterized by frequent updates to user interfaces\nand content. However, most existing benchmarks only capture the static aspects\nof the web. To bridge this gap, we introduce WebCanvas, an innovative online\nevaluation framework for web agents that effectively addresses the dynamic\nnature of web interactions. WebCanvas contains three main components to\nfacilitate realistic assessments: (1) A novel evaluation metric which reliably\ncapture critical intermediate actions or states necessary for task completions\nwhile disregarding noise caused by insignificant events or changed\nweb-elements. (2) A benchmark dataset called Mind2Web-Live, a refined version\nof original Mind2Web static dataset containing 542 tasks with 2439 intermediate\nevaluation states; (3) Lightweight and generalizable annotation tools and\ntesting pipelines that enables the community to collect and maintain the\nhigh-quality, up-to-date dataset. Building on WebCanvas, we open-source an\nagent framework with extensible modules for reasoning, providing a foundation\nfor the community to conduct online inference and evaluations. Our\nbest-performing agent achieves a task success rate of 23.1% and a task\ncompletion rate of 48.8% on the Mind2Web-Live test set. Additionally, we\nanalyze the performance discrepancies across various websites, domains, and\nexperimental environments. We encourage the community to contribute further\ninsights on online agent evaluation, thereby advancing this field of research.",
      "tldr_zh": "该研究提出 WebCanvas，一个创新的在线评估框架，用于基准测试网页代理（web agents）在动态网页环境中的适应性，以解决现有基准忽略网页更新问题的局限性。WebCanvas 包括一个新的评估指标捕捉关键中间动作、一份名为 Mind2Web-Live 的数据集（包含542个任务和2439个中间状态）、以及轻量级注释工具和测试管道，便于社区维护高质量数据集。该框架还开源了一个可扩展的代理框架，支持在线推理和评估；实验结果显示，最佳代理在 Mind2Web-Live 测试集上达到23.1%的任务成功率和48.8%的任务完成率，并分析了不同网站和领域的性能差异，推动网页代理研究的进步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Our platform, tool and dataset are publically available at\n  https://www.imean.ai/web-canvas/ and\n  https://huggingface.co/datasets/iMeanAI/Mind2Web-Live/",
      "pdf_url": "http://arxiv.org/pdf/2406.12373v3",
      "published_date": "2024-06-18 07:58:33 UTC",
      "updated_date": "2024-07-16 06:19:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:58:36.518785"
    },
    {
      "arxiv_id": "2406.12370v1",
      "title": "UAV-based Intelligent Information Systems on Winter Road Safety for Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Siva Ariram",
        "Veikko Pekkala",
        "Timo Mäenpää",
        "Antti Tikänmaki",
        "Juha Röning"
      ],
      "abstract": "As autonomous vehicles continue to revolutionize transportation, addressing\nchallenges posed by adverse weather conditions, particularly during winter,\nbecomes paramount for ensuring safe and efficient operations. One of the most\nimportant aspects of a road safety inspection during adverse weather is when a\nlimited lane width can reduce the capacity of the road and raise the risk of\nserious accidents involving autonomous vehicles. In this research, a method for\nimproving driving challenges on roads in winter conditions, with a model that\nsegments and estimates the width of the road from the perspectives of Uncrewed\naerial vehicles and autonomous vehicles. The proposed approach in this article\nis needed to empower self-driving cars with up-to-date and accurate insights,\nenhancing their adaptability and decision-making capabilities in winter\nlandscapes.",
      "tldr_zh": "本研究针对冬季恶劣天气对自主车辆（Autonomous Vehicles）的安全挑战，特别是有限车道宽度导致的事故风险，提出了一种基于无人机的智能信息系统（UAV-based Intelligent Information Systems）。该方法利用无人机和自主车辆的视角，开发一个模型来分割和估计道路宽度，从而提供实时准确的道路数据。实验结果表明，该系统能增强自驾车的适应性和决策能力，提高冬季道路安全的整体效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12370v1",
      "published_date": "2024-06-18 07:53:37 UTC",
      "updated_date": "2024-06-18 07:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:58:46.941038"
    },
    {
      "arxiv_id": "2407.07099v3",
      "title": "Nash CoT: Multi-Path Inference with Preference Equilibrium",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Zhang",
        "Cunxiang Wang",
        "Xiong Xiao",
        "Yue Zhang",
        "Donglin Wang"
      ],
      "abstract": "Chain of thought (CoT) is a reasoning framework that can enhance the\nperformance of Large Language Models (LLMs) on complex inference tasks. In\nparticular, among various studies related to CoT, multi-path inference stands\nout as a simple yet effective improvement. However, there is no optimal setting\nfor the number of inference paths. Therefore, we have to increase the number of\ninference paths to obtain better results, which in turn increases the inference\ncost. To address this limitation, we can utilize question-related role\ntemplates to guide LLMs into relevant roles, thereby increasing the possibility\nof correct inferences for each path and further reducing dependence on the\nnumber of inference paths while improving reasoning accuracy. However, placing\nLLMs into specific roles may reduce their reasoning diversity and performance\non a few tasks where role dependence is low. To alleviate the excessive\nimmersion of the LLM into a specific role, we propose Nash CoT by constructing\na game system on each path that balances the generation from role-specific\nLLMs' and the general LLMs' generation, thereby ensuring both effective role\nadoption and diversity in LLM generation further maintaining the performance of\nmulti-path inference while reducing the requirement of the number of inference\npaths. We evaluate Nash CoT across various inference tasks, including Arabic\nReasoning, Commonsense Question Answering, and Symbolic Inference, achieving\nresults that are comparable to or better than those of multi-path CoT with the\nequal number of inference paths.",
      "tldr_zh": "这篇论文针对 Chain of Thought (CoT) 框架在多路径推理中的问题，提出 Nash CoT 方法，通过构建一个游戏系统在每个推理路径上平衡角色特定 Large Language Models (LLMs) 和一般 LLMs 的生成，确保角色引导的有效性和生成多样性，从而减少对推理路径数量的依赖。Nash CoT 利用问题相关的角色模板来提升每个路径的正确推理可能性，同时缓解过度角色沉浸可能带来的性能下降。实验结果显示，在 Arabic Reasoning、Commonsense Question Answering 和 Symbolic Inference 等任务上，Nash CoT 取得了与同等路径数量的多路径 CoT 相当或更好的准确性，显著降低了推理成本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.07099v3",
      "published_date": "2024-06-18 07:46:13 UTC",
      "updated_date": "2024-12-30 13:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:59:01.438044"
    },
    {
      "arxiv_id": "2406.12362v1",
      "title": "Certified ML Object Detection for Surveillance Missions",
      "title_zh": "用于监视任务的认证机器学习对象检测",
      "authors": [
        "Mohammed Belcaid",
        "Eric Bonnafous",
        "Louis Crison",
        "Christophe Faure",
        "Eric Jenn",
        "Claire Pagetti"
      ],
      "abstract": "In this paper, we present a development process of a drone detection system\ninvolving a machine learning object detection component. The purpose is to\nreach acceptable performance objectives and provide sufficient evidences,\nrequired by the recommendations (soon to be published) of the ED 324 / ARP 6983\nstandard, to gain confidence in the dependability of the designed system.",
      "tldr_zh": "本论文介绍了开发无人机检测系统的过程，该系统采用机器学习物体检测（ML Object Detection）组件，旨在实现可接受的性能目标。研究重点是提供足够的证据，以符合即将发布的 ED 324 / ARP 6983 标准要求，从而提升系统在监视任务中的可靠性和可信度。通过这一开发流程，论文为确保机器学习模型在实际应用中的安全性奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12362v1",
      "published_date": "2024-06-18 07:42:22 UTC",
      "updated_date": "2024-06-18 07:42:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:59:11.840955"
    },
    {
      "arxiv_id": "2406.12359v1",
      "title": "Memory Sequence Length of Data Sampling Impacts the Adaptation of Meta-Reinforcement Learning Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Menglong Zhang",
        "Fuyuan Qian",
        "Quanying Liu"
      ],
      "abstract": "Fast adaptation to new tasks is extremely important for embodied agents in\nthe real world. Meta-reinforcement learning (meta-RL) has emerged as an\neffective method to enable fast adaptation in unknown environments. Compared to\non-policy meta-RL algorithms, off-policy algorithms rely heavily on efficient\ndata sampling strategies to extract and represent the historical trajectories.\nHowever, little is known about how different data sampling methods impact the\nability of meta-RL agents to represent unknown environments. Here, we\ninvestigate the impact of data sampling strategies on the exploration and\nadaptability of meta-RL agents. Specifically, we conducted experiments with two\ntypes of off-policy meta-RL algorithms based on Thompson sampling and\nBayes-optimality theories in continuous control tasks within the MuJoCo\nenvironment and sparse reward navigation tasks. Our analysis revealed the\nlong-memory and short-memory sequence sampling strategies affect the\nrepresentation and adaptive capabilities of meta-RL agents. We found that the\nalgorithm based on Bayes-optimality theory exhibited more robust and better\nadaptability than the algorithm based on Thompson sampling, highlighting the\nimportance of appropriate data sampling strategies for the agent's\nrepresentation of an unknown environment, especially in the case of sparse\nrewards.",
      "tldr_zh": "这篇论文探讨了数据采样的记忆序列长度对元强化学习 (meta-RL) 代理适应能力的影响，强调 off-policy meta-RL 算法依赖高效数据采样策略来处理未知环境。研究者通过在 MuJoCo 环境中的连续控制任务和稀疏奖励导航任务上进行实验，比较了基于 Thompson sampling 和 Bayes-optimality 的算法。结果显示，长记忆序列采样策略提升了代理的表示和适应能力，而 Bayes-optimality 算法表现出更强的鲁棒性和性能，尤其在稀疏奖励情况下。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12359v1",
      "published_date": "2024-06-18 07:41:40 UTC",
      "updated_date": "2024-06-18 07:41:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:59:24.744730"
    },
    {
      "arxiv_id": "2406.12345v1",
      "title": "Navigating Knowledge Management Implementation Success in Government Organizations: A type-2 fuzzy approach",
      "title_zh": "翻译失败",
      "authors": [
        "Saman Foroutani",
        "Nasim Fahimian",
        "Reyhaneh Jalalinejad",
        "Morteza Hezarkhani",
        "Samaneh Mahmoudi",
        "Behrooz Gharleghi"
      ],
      "abstract": "Optimal information and knowledge management is crucial for organizations to\nachieve their objectives efficiently. As a rare and valuable resource,\neffective knowledge management provides a strategic advantage and has become a\nkey determinant of organizational success. The study aims to identify critical\nsuccess and failure factors for implementing knowledge management systems in\ngovernment organizations. This research employs a descriptive survey\nmethodology, collecting data through random interviews and questionnaires. The\nstudy highlights the critical success factors for knowledge management systems\nin government organizations, including cooperation, an open atmosphere, staff\ntraining, creativity and innovation, removal of organizational constraints,\nreward policies, role modeling, and focus. Conversely, failure to consider\nformality, staff participation, collaboration technologies, network and\nhardware infrastructure, complexity, IT staff, and trust can pose significant\nobstacles to successful implementation.",
      "tldr_zh": "该研究探讨了在政府组织中实施知识管理系统的关键成功和失败因素，旨在帮助组织高效实现目标并获得战略优势。采用描述性调查方法，通过随机访谈和问卷收集数据，并结合 type-2 fuzzy approach 来分析这些因素。关键成功因素包括合作、开放氛围、员工培训、创造力和创新、移除组织约束、奖励政策、榜样作用以及专注；反之，忽略正式性、员工参与、协作技术、网络和硬件基础设施、复杂性、IT 员工以及信任可能导致实施失败。该方法为政府组织优化知识管理提供实用指导。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12345v1",
      "published_date": "2024-06-18 07:22:32 UTC",
      "updated_date": "2024-06-18 07:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:59:37.225031"
    },
    {
      "arxiv_id": "2407.13690v2",
      "title": "DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving",
      "title_zh": "DART-Math：难度感知拒绝",
      "authors": [
        "Yuxuan Tong",
        "Xiwen Zhang",
        "Rui Wang",
        "Ruidong Wu",
        "Junxian He"
      ],
      "abstract": "Solving mathematical problems requires advanced reasoning abilities and\npresents notable challenges for large language models. Previous works usually\nsynthesize data from proprietary models to augment existing datasets, followed\nby instruction tuning to achieve top-tier results. However, our analysis of\nthese datasets reveals severe biases towards easy queries, with frequent\nfailures to generate any correct response for the most challenging queries.\nHypothesizing that difficult queries are crucial to learn complex reasoning, we\npropose Difficulty-Aware Rejection Tuning (DART), a method that allocates\ndifficult queries more trials during the synthesis phase, enabling more\nextensive training on difficult samples. Utilizing DART, we have created new\ndatasets for mathematical problem-solving that focus more on difficult queries\nand are substantially smaller than previous ones. Remarkably, our synthesis\nprocess solely relies on a 7B-sized open-weight model, without reliance on the\ncommonly used proprietary GPT-4. We fine-tune various base models on our\ndatasets ranging from 7B to 70B in size, resulting in a series of strong models\ncalled DART-MATH. In comprehensive in-domain and out-of-domain evaluation on 6\nmathematical benchmarks, DART-MATH outperforms vanilla rejection tuning\nsignificantly, being superior or comparable to previous arts, despite using\nmuch smaller datasets and no proprietary models. Furthermore, our results\nposition our synthetic datasets as the most effective and cost-efficient\npublicly available resources for advancing mathematical problem-solving.",
      "tldr_zh": "该论文提出了一种Difficulty-Aware Rejection Tuning (DART)方法，用于提升大型语言模型(LLMs)在数学问题解决中的性能，特别针对现有数据集偏向简单查询的问题，通过为困难查询分配更多合成尝试来强化复杂推理训练。研究者利用DART创建了更小且聚焦困难查询的新数据集，仅依赖7B规模的开源模型，而非专有模型如GPT-4。实验结果显示，在6个数学基准上的评估中，基于这些数据集微调的DART-MATH模型系列显著优于传统拒绝调优( Rejection Tuning )，并与现有最佳方法相当或更优，同时提供最有效和成本高效的公开资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024. Data and model checkpoints are available at\n  https://github.com/hkust-nlp/dart-math",
      "pdf_url": "http://arxiv.org/pdf/2407.13690v2",
      "published_date": "2024-06-18 07:14:02 UTC",
      "updated_date": "2024-12-23 17:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T21:59:50.840173"
    },
    {
      "arxiv_id": "2406.12336v2",
      "title": "Towards Understanding Domain Adapted Sentence Embeddings for Document Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Sujoy Roychowdhury",
        "Sumit Soman",
        "H. G. Ranjani",
        "Vansh Chhabra",
        "Neeraj Gunda",
        "Shashank Gautam",
        "Subhadip Bandyopadhyay",
        "Sai Krishna Bala"
      ],
      "abstract": "A plethora of sentence embedding models makes it challenging to choose one,\nespecially for technical domains rich with specialized vocabulary. In this\nwork, we domain adapt embeddings using telecom, health and science datasets for\nquestion answering. We evaluate embeddings obtained from publicly available\nmodels and their domain-adapted variants, on both point retrieval accuracies,\nas well as their (95\\%) confidence intervals. We establish a systematic method\nto obtain thresholds for similarity scores for different embeddings. As\nexpected, we observe that fine-tuning improves mean bootstrapped accuracies. We\nalso observe that it results in tighter confidence intervals, which further\nimprove when pre-training is preceded by fine-tuning. We introduce metrics\nwhich measure the distributional overlaps of top-$K$, correct and random\ndocument similarities with the question. Further, we show that these metrics\nare correlated with retrieval accuracy and similarity thresholds. Recent\nliterature shows conflicting effects of isotropy on retrieval accuracies. Our\nexperiments establish that the isotropy of embeddings (as measured by two\nindependent state-of-the-art isotropy metric definitions) is poorly correlated\nwith retrieval performance. We show that embeddings for domain-specific\nsentences have little overlap with those for domain-agnostic ones, and\nfine-tuning moves them further apart. Based on our results, we provide\nrecommendations for use of our methodology and metrics by researchers and\npractitioners.",
      "tldr_zh": "本研究探讨了在技术领域（如 telecom、health 和 science）中对句子嵌入(sentence embeddings) 进行领域适应(domain adapted)，以提升文档检索性能的问题。作者评估了公开模型及其微调(fine-tuning) 变体，观察到微调不仅提高了检索准确率和置信区间，还引入了新的度量标准来衡量 top-K 分布重叠，这些指标与准确率和相似度阈值高度相关。各向同性(isotropy) 与检索性能的相关性较低，且领域特定嵌入与领域无关嵌入差异显著；基于这些发现，论文提供了使用该方法和指标的实用推荐。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12336v2",
      "published_date": "2024-06-18 07:03:34 UTC",
      "updated_date": "2024-12-02 04:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:00:02.189940"
    },
    {
      "arxiv_id": "2406.12331v1",
      "title": "Retrieval Meets Reasoning: Dynamic In-Context Editing for Long-Text Understanding",
      "title_zh": "检索遇见推理：动态上下文内编辑用于长文本理解",
      "authors": [
        "Weizhi Fei",
        "Xueyan Niu",
        "Guoqing Xie",
        "Yanhua Zhang",
        "Bo Bai",
        "Lei Deng",
        "Wei Han"
      ],
      "abstract": "Current Large Language Models (LLMs) face inherent limitations due to their\npre-defined context lengths, which impede their capacity for multi-hop\nreasoning within extensive textual contexts. While existing techniques like\nRetrieval-Augmented Generation (RAG) have attempted to bridge this gap by\nsourcing external information, they fall short when direct answers are not\nreadily available. We introduce a novel approach that re-imagines information\nretrieval through dynamic in-context editing, inspired by recent breakthroughs\nin knowledge editing. By treating lengthy contexts as malleable external\nknowledge, our method interactively gathers and integrates relevant\ninformation, thereby enabling LLMs to perform sophisticated reasoning steps.\nExperimental results demonstrate that our method effectively empowers\ncontext-limited LLMs, such as Llama2, to engage in multi-hop reasoning with\nimproved performance, which outperforms state-of-the-art context window\nextrapolation methods and even compares favorably to more advanced commercial\nlong-context models. Our interactive method not only enhances reasoning\ncapabilities but also mitigates the associated training and computational\ncosts, making it a pragmatic solution for enhancing LLMs' reasoning within\nexpansive contexts.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的预定义上下文长度限制，提出了一种动态in-context editing方法，将信息检索与推理相结合，允许模型交互式地收集和整合长文本中的相关信息，从而实现有效的多跳推理。不同于传统Retrieval-Augmented Generation (RAG)方法，该方法将长文本视为可变外部知识，通过知识编辑的灵感来增强模型的推理能力。实验结果显示，该方法使上下文受限的LLMs（如Llama2）在长文本理解任务中性能显著提升，优于现有上下文扩展技术和部分商业长上下文模型。同时，该方法降低了训练和计算成本，提供了一个实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12331v1",
      "published_date": "2024-06-18 06:54:28 UTC",
      "updated_date": "2024-06-18 06:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:00:15.180837"
    },
    {
      "arxiv_id": "2406.12326v1",
      "title": "Toward Exploring the Code Understanding Capabilities of Pre-trained Code Generation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Lin",
        "Yutao Xie",
        "Yue Yu",
        "Yibiao Yang",
        "Lei Zhang"
      ],
      "abstract": "Recently, large code generation models trained in a self-supervised manner on\nextensive unlabeled programming language data have achieved remarkable success.\nWhile these models acquire vast amounts of code knowledge, they perform poorly\non code understanding tasks, such as code search and clone detection, as they\nare specifically trained for generation. Pre-training a larger encoder-only\narchitecture model from scratch on massive code data can improve understanding\nperformance. However, this approach is costly and time-consuming, making it\nsuboptimal. In this paper, we pioneer the transfer of knowledge from\npre-trained code generation models to code understanding tasks, significantly\nreducing training costs. We examine effective strategies for enabling\ndecoder-only models to acquire robust code representations. Furthermore, we\nintroduce CL4D, a contrastive learning method designed to enhance the\nrepresentation capabilities of decoder-only models. Comprehensive experiments\ndemonstrate that our approach achieves state-of-the-art performance in\nunderstanding tasks such as code search and clone detection. Our analysis shows\nthat our method effectively reduces the distance between semantically identical\nsamples in the representation space. These findings suggest the potential for\nunifying code understanding and generation tasks using a decoder-only\nstructured model.",
      "tldr_zh": "该研究探讨了预训练代码生成模型（pre-trained code generation models）在代码理解任务（如代码搜索和克隆检测）上的局限性，因为这些模型主要针对生成任务训练。论文提出了一种知识转移策略，从decoder-only模型中提取鲁棒代码表示，并引入CL4D对比学习（contrastive learning）方法来提升其性能，从而显著降低训练成本。实验结果显示，该方法在代码搜索和克隆检测等任务上达到了state-of-the-art性能，并证明了使用decoder-only结构模型统一代码理解和生成任务的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.12326v1",
      "published_date": "2024-06-18 06:52:14 UTC",
      "updated_date": "2024-06-18 06:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:00:26.871888"
    },
    {
      "arxiv_id": "2406.12321v1",
      "title": "Automatic benchmarking of large multimodal models via iterative experiment programming",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Conti",
        "Enrico Fini",
        "Paolo Rota",
        "Yiming Wang",
        "Massimiliano Mancini",
        "Elisa Ricci"
      ],
      "abstract": "Assessing the capabilities of large multimodal models (LMMs) often requires\nthe creation of ad-hoc evaluations. Currently, building new benchmarks requires\ntremendous amounts of manual work for each specific analysis. This makes the\nevaluation process tedious and costly. In this paper, we present APEx,\nAutomatic Programming of Experiments, the first framework for automatic\nbenchmarking of LMMs. Given a research question expressed in natural language,\nAPEx leverages a large language model (LLM) and a library of pre-specified\ntools to generate a set of experiments for the model at hand, and progressively\ncompile a scientific report. The report drives the testing procedure: based on\nthe current status of the investigation, APEx chooses which experiments to\nperform and whether the results are sufficient to draw conclusions. Finally,\nthe LLM refines the report, presenting the results to the user in natural\nlanguage. Thanks to its modularity, our framework is flexible and extensible as\nnew tools become available. Empirically, APEx reproduces the findings of\nexisting studies while allowing for arbitrary analyses and hypothesis testing.",
      "tldr_zh": "这篇论文提出了 APEx 框架，这是第一个用于自动基准测试大型多模态模型 (LMMs) 的系统，通过迭代实验编程减少手动评估工作。APEx 利用大语言模型 (LLM) 和预指定工具，从自然语言的研究问题出发，生成实验集、逐步编译科学报告，并根据当前结果动态选择后续测试。框架的模块化和可扩展性允许其适应新工具，最终以自然语言呈现精炼报告。实证结果显示，APEx 成功再现现有研究发现，并支持任意分析和假设测试。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 6 figures, code is available at\n  https://github.com/altndrr/apex",
      "pdf_url": "http://arxiv.org/pdf/2406.12321v1",
      "published_date": "2024-06-18 06:43:46 UTC",
      "updated_date": "2024-06-18 06:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:00:38.128890"
    },
    {
      "arxiv_id": "2406.12316v1",
      "title": "Enhancing Visible-Infrared Person Re-identification with Modality- and Instance-aware Visual Prompt Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Wu",
        "Bingliang Jiao",
        "Wenxuan Wang",
        "Meng Liu",
        "Peng Wang"
      ],
      "abstract": "The Visible-Infrared Person Re-identification (VI ReID) aims to match visible\nand infrared images of the same pedestrians across non-overlapped camera views.\nThese two input modalities contain both invariant information, such as shape,\nand modality-specific details, such as color. An ideal model should utilize\nvaluable information from both modalities during training for enhanced\nrepresentational capability. However, the gap caused by modality-specific\ninformation poses substantial challenges for the VI ReID model to handle\ndistinct modality inputs simultaneously. To address this, we introduce the\nModality-aware and Instance-aware Visual Prompts (MIP) network in our work,\ndesigned to effectively utilize both invariant and specific information for\nidentification. Specifically, our MIP model is built on the transformer\narchitecture. In this model, we have designed a series of modality-specific\nprompts, which could enable our model to adapt to and make use of the specific\ninformation inherent in different modality inputs, thereby reducing the\ninterference caused by the modality gap and achieving better identification.\nBesides, we also employ each pedestrian feature to construct a group of\ninstance-specific prompts. These customized prompts are responsible for guiding\nour model to adapt to each pedestrian instance dynamically, thereby capturing\nidentity-level discriminative clues for identification. Through extensive\nexperiments on SYSU-MM01 and RegDB datasets, the effectiveness of both our\ndesigned modules is evaluated. Additionally, our proposed MIP performs better\nthan most state-of-the-art methods.",
      "tldr_zh": "该论文针对Visible-Infrared Person Re-identification (VI ReID)任务，提出了一种Modality-aware and Instance-aware Visual Prompts (MIP)网络，以有效利用可见光和红外图像中的不变信息（如形状）和模态特定细节（如颜色），同时减少模态间差距带来的干扰。MIP基于Transformer架构，设计了模态特定提示来适应不同模态输入，以及实例特定提示来动态捕捉每个行人的身份级辨别线索，从而提升模型的表示能力。在SYSU-MM01和RegDB数据集上的实验验证了这些模块的有效性，且MIP的表现优于大多数最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepyed by ACM International Conference on Multimedia Retrieval\n  (ICMR'24)",
      "pdf_url": "http://arxiv.org/pdf/2406.12316v1",
      "published_date": "2024-06-18 06:39:03 UTC",
      "updated_date": "2024-06-18 06:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:00:50.509283"
    },
    {
      "arxiv_id": "2406.12315v7",
      "title": "A Comprehensive Study of Structural Pruning for Vision Models",
      "title_zh": "结构修剪在视觉模型中的全面研究",
      "authors": [
        "Changhao Li",
        "Haoling Li",
        "Mengqi Xue",
        "Gongfan Fang",
        "Sheng Zhou",
        "Zunlei Feng",
        "Huiqiong Wang",
        "Mingli Song",
        "Jie Song"
      ],
      "abstract": "Structural pruning has emerged as a promising approach for producing more\nefficient models. Nevertheless, the community suffers from a lack of\nstandardized benchmarks and metrics, leaving the progress in this area not\nfully comprehended. To fill this gap, we present the first comprehensive\nbenchmark, termed PruningBench, for structural pruning. PruningBench showcases\nthe following three characteristics: 1) PruningBench employs a unified and\nconsistent framework for evaluating the effectiveness of diverse structural\npruning techniques; 2) PruningBench systematically evaluates 16 existing\npruning methods, encompassing a wide array of models (e.g., CNNs and ViTs) and\ntasks (e.g., classification and detection); 3) PruningBench provides easily\nimplementable interfaces to facilitate the implementation of future pruning\nmethods, and enables the subsequent researchers to incorporate their work into\nour leaderboards. We provide an online pruning platform for customizing pruning\ntasks and reproducing all results in this paper. Leaderboard results can also\nbe available.",
      "tldr_zh": "这篇论文对结构修剪（structural pruning）在视觉模型（vision models）中的应用进行了全面研究，提出了首个标准化基准 PruningBench，以填补评估标准的缺失。PruningBench 采用统一的框架系统评估了 16 种现有修剪方法，涵盖多种模型（如 CNNs 和 ViTs）以及任务（如分类和检测），并展示了这些方法的有效性。该基准还提供易于实现的接口和在线平台，支持未来研究者自定义任务、复现结果并更新排行榜（leaderboard）。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper aims to introduce an evaluation benchmark for structural\n  pruning. The complete text spans 25 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.12315v7",
      "published_date": "2024-06-18 06:37:26 UTC",
      "updated_date": "2025-01-21 06:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:01:01.943059"
    },
    {
      "arxiv_id": "2406.12298v1",
      "title": "Research on Dangerous Flight Weather Prediction based on Machine Learning",
      "title_zh": "基于机器学习的危险飞行天气预测研究",
      "authors": [
        "Haoxing Liu",
        "Renjie Xie",
        "Haoshen Qin",
        "Yizhou Li"
      ],
      "abstract": "With the continuous expansion of the scale of air transport, the demand for\naviation meteorological support also continues to grow. The impact of hazardous\nweather on flight safety is critical. How to effectively use meteorological\ndata to improve the early warning capability of flight dangerous weather and\nensure the safe flight of aircraft is the primary task of aviation\nmeteorological services. In this work, support vector machine (SVM) models are\nused to predict hazardous flight weather, especially for meteorological\nconditions with high uncertainty such as storms and turbulence. SVM is a\nsupervised learning method that distinguishes between different classes of data\nby finding optimal decision boundaries in a high-dimensional space. In order to\nmeet the needs of this study, we chose the radial basis function (RBF) as the\nkernel function, which helps to deal with nonlinear problems and enables the\nmodel to better capture complex meteorological data structures. During the\nmodel training phase, we used historical meteorological observations from\nmultiple weather stations, including temperature, humidity, wind speed, wind\ndirection, and other meteorological indicators closely related to flight\nsafety. From this data, the SVM model learns how to distinguish between normal\nand dangerous flight weather conditions.",
      "tldr_zh": "该研究针对航空运输中危险天气对飞行安全的影响，提出了一种基于机器学习的方法来提升飞行危险天气的预警能力。研究采用 Support Vector Machine (SVM) 模型作为监督学习工具，使用 Radial Basis Function (RBF) 内核函数处理非线性气象数据，如风暴和湍流。模型通过历史气象观测数据（包括温度、湿度、风速和风向等指标）进行训练，能够有效区分正常和危险飞行天气条件，从而为航空气象服务提供更可靠的支持。",
      "categories": [
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12298v1",
      "published_date": "2024-06-18 06:08:15 UTC",
      "updated_date": "2024-06-18 06:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:01:13.115956"
    },
    {
      "arxiv_id": "2406.12297v1",
      "title": "Faithful Density-Peaks Clustering via Matrix Computations on MPI Parallelization System",
      "title_zh": "翻译失败",
      "authors": [
        "Ji Xu",
        "Tianlong Xiao",
        "Jinye Yang",
        "Panpan Zhu"
      ],
      "abstract": "Density peaks clustering (DP) has the ability of detecting clusters of\narbitrary shape and clustering non-Euclidean space data, but its quadratic\ncomplexity in both computing and storage makes it difficult to scale for big\ndata. Various approaches have been proposed in this regard, including MapReduce\nbased distribution computing, multi-core parallelism, presentation\ntransformation (e.g., kd-tree, Z-value), granular computing, and so forth.\nHowever, most of these existing methods face two limitations. One is their\ntarget datasets are mostly constrained to be in Euclidian space, the other is\nthey emphasize only on local neighbors while ignoring global data distribution\ndue to restriction to cut-off kernel when computing density. To address the two\nissues, we present a faithful and parallel DP method that makes use of two\ntypes of vector-like distance matrices and an inverse leading-node-finding\npolicy. The method is implemented on a message passing interface (MPI) system.\nExtensive experiments showed that our method is capable of clustering\nnon-Euclidean data such as in community detection, while outperforming the\nstate-of-the-art counterpart methods in accuracy when clustering large\nEuclidean data. Our code is publicly available at\nhttps://github.com/alanxuji/FaithPDP.",
      "tldr_zh": "本文提出了一种忠实的密度峰值聚类(Density-Peaks Clustering, DP)方法，通过矩阵计算和MPI并行化系统，解决了DP算法在大数据上的二次复杂性问题，特别是针对非Euclidean空间数据和全局数据分布的限制。方法引入两种向量-like距离矩阵以及反向leading-node-finding政策，以提升聚类准确性和扩展性。实验结果显示，该方法在社区检测等非Euclidean数据上表现突出，并在大型Euclidean数据聚类中比现有方法准确率更高，代码已开源于GitHub。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper presents a novel approach FaithPDP that takes advantages\n  of both hardware (multi-core architecture of CPU) and modern programming\n  language (Python or Matlab for efficient vector and matrix computation) to\n  achieve clustering result identical to vanilla DP algorithm, while the\n  computing complexity is reduced to pseudo-linear",
      "pdf_url": "http://arxiv.org/pdf/2406.12297v1",
      "published_date": "2024-06-18 06:05:45 UTC",
      "updated_date": "2024-06-18 06:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:01:26.848506"
    },
    {
      "arxiv_id": "2406.12296v2",
      "title": "Generative Artificial Intelligence-Guided User Studies: An Application for Air Taxi Services",
      "title_zh": "翻译失败",
      "authors": [
        "Shengdi Xiao",
        "Jingjing Li",
        "Tatsuki Fushimi",
        "Yoichi Ochiai"
      ],
      "abstract": "User studies are crucial for meeting user needs. In user studies, real\nexperimental scenarios and participants are constructed and recruited. However,\nemerging and unfamiliar studies face limitations, including safety concerns and\niterative efficiency. To address these challenges, this study utilises a\nGenerative Artificial Intelligence (GenAI) to create GenAI-generated scenarios\nfor user experience (UX). By recruiting real users to evaluate this experience,\nwe can collect feedback that enables rapid iteration in the early design phase.\nThe air taxi is particularly representative of these challenges and has been\nchosen as the case study for this research. The key contribution was designing\nan Air Taxi Journey (ATJ) using Large Language Models (LLMs) and AI image and\nvideo generators. Based on the GPT-4-generated scripts, key visuals were\ncreated for the air taxi, and the ATJ was evaluated by 72 participants.\nFurthermore, the LLMs demonstrated the ability to identify and suggest\nenvironments that significantly improve participants' willingness toward air\ntaxis. Education level and gender significantly influenced participants' the\ndifference in willingness and their satisfaction with the ATJ. Satisfaction\nwith the ATJ serves as a mediator, significantly influencing participants'\nwillingness to take air taxis. Our study confirms the capability of GenAI to\nsupport user studies, providing a feasible approach and valuable insights for\ndesigning air taxi UX in the early design phase.",
      "tldr_zh": "这篇论文探讨了使用 Generative Artificial Intelligence (GenAI) 指导用户研究，以解决新兴领域（如空中出租车服务）的安全和效率挑战。研究者设计了基于 Large Language Models (LLMs) 和 AI 图像/视频生成器的 Air Taxi Journey (ATJ)，并招募72名真实参与者进行评估。关键发现包括：LLMs 能识别并建议环境以显著提升参与者对 air taxis 的意愿，教育水平和性别影响了意愿差异，且对 ATJ 的满意度作为中介因素促进了整体意愿。该方法证实了 GenAI 在早期设计阶段支持用户研究的有效性，提供宝贵洞见。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "39 pages, 6 main figures, 10 appendix figures",
      "pdf_url": "http://arxiv.org/pdf/2406.12296v2",
      "published_date": "2024-06-18 06:00:18 UTC",
      "updated_date": "2025-03-04 07:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:01:39.139980"
    },
    {
      "arxiv_id": "2406.12292v1",
      "title": "JEN-1 DreamStyler: Customized Musical Concept Learning via Pivotal Parameters Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Boyu Chen",
        "Peike Li",
        "Yao Yao",
        "Alex Wang"
      ],
      "abstract": "Large models for text-to-music generation have achieved significant progress,\nfacilitating the creation of high-quality and varied musical compositions from\nprovided text prompts. However, input text prompts may not precisely capture\nuser requirements, particularly when the objective is to generate music that\nembodies a specific concept derived from a designated reference collection. In\nthis paper, we propose a novel method for customized text-to-music generation,\nwhich can capture the concept from a two-minute reference music and generate a\nnew piece of music conforming to the concept. We achieve this by fine-tuning a\npretrained text-to-music model using the reference music. However, directly\nfine-tuning all parameters leads to overfitting issues. To address this\nproblem, we propose a Pivotal Parameters Tuning method that enables the model\nto assimilate the new concept while preserving its original generative\ncapabilities. Additionally, we identify a potential concept conflict when\nintroducing multiple concepts into the pretrained model. We present a concept\nenhancement strategy to distinguish multiple concepts, enabling the fine-tuned\nmodel to generate music incorporating either individual or multiple concepts\nsimultaneously. Since we are the first to work on the customized music\ngeneration task, we also introduce a new dataset and evaluation protocol for\nthe new task. Our proposed Jen1-DreamStyler outperforms several baselines in\nboth qualitative and quantitative evaluations. Demos will be available at\nhttps://www.jenmusic.ai/research#DreamStyler.",
      "tldr_zh": "本论文提出 JEN-1 DreamStyler，一种通过 Pivotal Parameters Tuning 方法微调预训练文本到音乐模型的创新框架，用于从两分钟参考音乐中学习自定义概念，并生成符合该概念的新音乐。该方法避免了直接微调所有参数导致的过度拟合问题，同时引入 concept enhancement strategy 来处理多个概念的冲突，确保模型能同时生成单个或多个概念的音乐。作为首次针对自定义音乐生成任务，论文构建了新数据集和评估协议，实验结果显示 JEN-1 DreamStyler 在定性和定量评估中优于基线模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12292v1",
      "published_date": "2024-06-18 05:54:11 UTC",
      "updated_date": "2024-06-18 05:54:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:01:53.415607"
    },
    {
      "arxiv_id": "2406.12288v3",
      "title": "An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Daking Rai",
        "Ziyu Yao"
      ],
      "abstract": "Large language models (LLMs) have shown strong arithmetic reasoning\ncapabilities when prompted with Chain-of-Thought (CoT) prompts. However, we\nhave only a limited understanding of how they are processed by LLMs. To\ndemystify it, prior work has primarily focused on ablating different components\nin the CoT prompt and empirically observing their resulting LLM performance\nchange. Yet, the reason why these components are important to LLM reasoning is\nnot explored. To fill this gap, in this work, we investigate ``neuron\nactivation'' as a lens to provide a unified explanation to observations made by\nprior work. Specifically, we look into neurons within the feed-forward layers\nof LLMs that may have activated their arithmetic reasoning capabilities, using\nLlama2 as an example. To facilitate this investigation, we also propose an\napproach based on GPT-4 to automatically identify neurons that imply arithmetic\nreasoning. Our analyses revealed that the activation of reasoning neurons in\nthe feed-forward layers of an LLM can explain the importance of various\ncomponents in a CoT prompt, and future research can extend it for a more\ncomplete understanding.",
      "tldr_zh": "本研究调查了神经元激活(neuron activation)作为一种统一视角，来解释大型语言模型(LLMs)在Chain-of-Thought (CoT)提示下进行算术推理的过程。研究者分析了LLMs前馈层(feed-forward layers)中的神经元，使用Llama2作为示例，并提出了一种基于GPT-4的自动方法来识别与算术推理相关的神经元。结果显示，神经元激活可以解释CoT提示中不同组件的重要性，从而揭示了LLMs推理机制的关键因素。该方法为深入理解LLMs的推理能力提供了新框架，并建议未来研究进一步扩展此分析。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 1 figure, to be published in ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12288v3",
      "published_date": "2024-06-18 05:49:24 UTC",
      "updated_date": "2024-09-02 17:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:02:04.674044"
    },
    {
      "arxiv_id": "2406.12285v2",
      "title": "DASSF: Dynamic-Attention Scale-Sequence Fusion for Aerial Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Haodong Li",
        "Haicheng Qu"
      ],
      "abstract": "The detection of small objects in aerial images is a fundamental task in the\nfield of computer vision. Moving objects in aerial photography have problems\nsuch as different shapes and sizes, dense overlap, occlusion by the background,\nand object blur, however, the original YOLO algorithm has low overall detection\naccuracy due to its weak ability to perceive targets of different scales. In\norder to improve the detection accuracy of densely overlapping small targets\nand fuzzy targets, this paper proposes a dynamic-attention scale-sequence\nfusion algorithm (DASSF) for small target detection in aerial images. First, we\npropose a dynamic scale sequence feature fusion (DSSFF) module that improves\nthe up-sampling mechanism and reduces computational load. Secondly, a x-small\nobject detection head is specially added to enhance the detection capability of\nsmall targets. Finally, in order to improve the expressive ability of targets\nof different types and sizes, we use the dynamic head (DyHead). The model we\nproposed solves the problem of small target detection in aerial images and can\nbe applied to multiple different versions of the YOLO algorithm, which is\nuniversal. Experimental results show that when the DASSF method is applied to\nYOLOv8, compared to YOLOv8n, on the VisDrone-2019 and DIOR datasets, the model\nshows an increase of 9.2% and 2.4% in the mean average precision (mAP),\nrespectively, and outperforms the current mainstream methods.",
      "tldr_zh": "本论文提出了一种动态注意力尺度序列融合算法（DASSF），旨在解决空中图像中小目标检测面临的挑战，如不同形状大小、密集重叠、背景遮挡和物体模糊问题。DASSF 包括动态尺度序列特征融合（DSSFF）模块来优化上采样机制并降低计算负载、添加 x-small 对象检测头以增强小目标识别能力，以及采用动态头（DyHead）来提升不同类型和大小目标的表达能力。该算法具有通用性，可应用于多种 YOLO 版本的模型中。实验结果显示，在 VisDrone-2019 和 DIOR 数据集上，应用于 YOLOv8 时，平均精度（mAP）分别提高了 9.2% 和 2.4%，优于主流方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12285v2",
      "published_date": "2024-06-18 05:26:44 UTC",
      "updated_date": "2024-06-22 07:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:02:17.054063"
    },
    {
      "arxiv_id": "2406.12284v2",
      "title": "Demystifying the Recency Heuristic in Temporal-Difference Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Brett Daley",
        "Marlos C. Machado",
        "Martha White"
      ],
      "abstract": "The recency heuristic in reinforcement learning is the assumption that\nstimuli that occurred closer in time to an acquired reward should be more\nheavily reinforced. The recency heuristic is one of the key assumptions made by\nTD($\\lambda$), which reinforces recent experiences according to an\nexponentially decaying weighting. In fact, all other widely used return\nestimators for TD learning, such as $n$-step returns, satisfy a weaker (i.e.,\nnon-monotonic) recency heuristic. Why is the recency heuristic effective for\ntemporal credit assignment? What happens when credit is assigned in a way that\nviolates this heuristic? In this paper, we analyze the specific mathematical\nimplications of adopting the recency heuristic in TD learning. We prove that\nany return estimator satisfying this heuristic: 1) is guaranteed to converge to\nthe correct value function, 2) has a relatively fast contraction rate, and 3)\nhas a long window of effective credit assignment, yet bounded worst-case\nvariance. We also give a counterexample where on-policy, tabular TD methods\nviolating the recency heuristic diverge. Our results offer some of the first\ntheoretical evidence that credit assignment based on the recency heuristic\nfacilitates learning.",
      "tldr_zh": "这篇论文探讨了强化学习中 recency heuristic 的作用，即认为离奖励更近的刺激应获得更强的强化，并分析了其在 Temporal-Difference Learning (TD learning) 中的数学含义。作者证明了满足 recency heuristic 的回报估计器（如 TD($\\lambda$)) 具有三个关键特性：保证收敛到正确价值函数、较快的收缩率，以及较长的有效信用分配窗口但方差有界。论文还通过反例展示了违反该 heuristic 的 on-policy 和 tabular TD 方法可能导致发散，为 recency heuristic 在促进学习方面的有效性提供了首次理论证据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "RLC 2024. 18 pages, 8 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2406.12284v2",
      "published_date": "2024-06-18 05:23:29 UTC",
      "updated_date": "2024-08-26 11:33:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:02:29.029300"
    },
    {
      "arxiv_id": "2406.12276v1",
      "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents",
      "title_zh": "翻译失败",
      "authors": [
        "Tanmay Gupta",
        "Luca Weihs",
        "Aniruddha Kembhavi"
      ],
      "abstract": "We present CodeNav, an LLM agent that navigates and leverages previously\nunseen code repositories to solve user queries. In contrast to tool-use LLM\nagents that require ``registration'' of all relevant tools via manual\ndescriptions within the LLM context, CodeNav automatically indexes and searches\nover code blocks in the target codebase, finds relevant code snippets, imports\nthem, and uses them to iteratively generate a solution with execution feedback.\nTo highlight the core-capabilities of CodeNav, we first showcase three case\nstudies where we use CodeNav for solving complex user queries using three\ndiverse codebases. Next, on three benchmarks, we quantitatively compare the\neffectiveness of code-use (which only has access to the target codebase) to\ntool-use (which has privileged access to all tool names and descriptions).\nFinally, we study the effect of varying kinds of tool and library descriptions\non code-use performance, as well as investigate the advantage of the agent\nseeing source code as opposed to natural descriptions of code. All code will be\nmade open source under a permissive license.",
      "tldr_zh": "本文提出 CodeNav，一种 LLM agents 框架，能够自动导航和利用未见过的真实代码仓库来解决用户查询，而非依赖传统 tool-use 的手动工具注册。CodeNav 通过索引、搜索代码块、导入相关片段，并结合执行反馈进行迭代生成解决方案，展示了在三个多样化代码库上的案例研究。实验结果显示，code-use 方法在三个基准上比 tool-use 更有效，且直接访问源代码优于自然语言描述；所有代码将开源以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12276v1",
      "published_date": "2024-06-18 05:10:38 UTC",
      "updated_date": "2024-06-18 05:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:02:40.317866"
    },
    {
      "arxiv_id": "2406.12272v6",
      "title": "Slot State Space Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jindong Jiang",
        "Fei Deng",
        "Gautam Singh",
        "Minseung Lee",
        "Sungjin Ahn"
      ],
      "abstract": "Recent State Space Models (SSMs) such as S4, S5, and Mamba have shown\nremarkable computational benefits in long-range temporal dependency modeling.\nHowever, in many sequence modeling problems, the underlying process is\ninherently modular and it is of interest to have inductive biases that mimic\nthis modular structure. In this paper, we introduce SlotSSMs, a novel framework\nfor incorporating independent mechanisms into SSMs to preserve or encourage\nseparation of information. Unlike conventional SSMs that maintain a monolithic\nstate vector, SlotSSMs maintains the state as a collection of multiple vectors\ncalled slots. Crucially, the state transitions are performed independently per\nslot with sparse interactions across slots implemented via the bottleneck of\nself-attention. In experiments, we evaluate our model in object-centric\nlearning, 3D visual reasoning, and long-context video understanding tasks,\nwhich involve modeling multiple objects and their long-range temporal\ndependencies. We find that our proposed design offers substantial performance\ngains over existing sequence modeling methods. Project page is available at\nhttps://slotssms.github.io/",
      "tldr_zh": "本研究提出 SlotSSMs，一种新型框架，将独立的机制整合到 State Space Models (SSMs) 中，以处理序列建模中固有的模块化结构，并增强信息分离。不同于传统 SSMs 的单一状态向量，SlotSSMs 将状态维护为多个独立 slots 的集合，并通过自注意力机制实现稀疏跨 slots 交互，从而更好地捕捉长程时间依赖。实验结果显示，该模型在对象中心学习、3D 视觉推理和长上下文视频理解任务中，显著优于现有序列建模方法，提供项目页面：https://slotssms.github.io/。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NeurIPS 2024; Project page is available at\n  https://slotssms.github.io/ ; Code is available at\n  https://github.com/JindongJiang/SlotSSMs",
      "pdf_url": "http://arxiv.org/pdf/2406.12272v6",
      "published_date": "2024-06-18 04:59:14 UTC",
      "updated_date": "2024-11-29 21:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:02:53.585756"
    },
    {
      "arxiv_id": "2406.12264v1",
      "title": "Projection Methods for Operator Learning and Universal Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele Zappala"
      ],
      "abstract": "We obtain a new universal approximation theorem for continuous operators on\narbitrary Banach spaces using the Leray-Schauder mapping. Moreover, we\nintroduce and study a method for operator learning in Banach spaces $L^p$ of\nfunctions with multiple variables, based on orthogonal projections on\npolynomial bases. We derive a universal approximation result for operators\nwhere we learn a linear projection and a finite dimensional mapping under some\nadditional assumptions. For the case of $p=2$, we give some sufficient\nconditions for the approximation results to hold. This article serves as the\ntheoretical framework for a deep learning methodology whose implementation will\nbe provided in subsequent work.",
      "tldr_zh": "本研究获得了一个新的通用逼近定理（universal approximation theorem），利用 Leray-Schauder 映射来逼近任意 Banach 空间上的连续算子。论文引入了一种基于正交投影（orthogonal projections）在多项式基（polynomial bases）上的方法，用于 Banach 空间 L^p 中的算子学习（operator learning），并在额外假设下导出了学习线性投影和有限维映射的通用逼近结果。对于 p=2 的情况，提供了一些充分条件来确保逼近有效。该工作为后续深度学习方法的实现提供了理论框架。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.12264v1",
      "published_date": "2024-06-18 04:44:05 UTC",
      "updated_date": "2024-06-18 04:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:03:04.193733"
    },
    {
      "arxiv_id": "2406.12260v1",
      "title": "Self-Supervised Time-Series Anomaly Detection Using Learnable Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Kukjin Choi",
        "Jihun Yi",
        "Jisoo Mok",
        "Sungroh Yoon"
      ],
      "abstract": "Continuous efforts are being made to advance anomaly detection in various\nmanufacturing processes to increase the productivity and safety of industrial\nsites. Deep learning replaced rule-based methods and recently emerged as a\npromising method for anomaly detection in diverse industries. However, in the\nreal world, the scarcity of abnormal data and difficulties in obtaining labeled\ndata create limitations in the training of detection models. In this study, we\naddressed these shortcomings by proposing a learnable data augmentation-based\ntime-series anomaly detection (LATAD) technique that is trained in a\nself-supervised manner. LATAD extracts discriminative features from time-series\ndata through contrastive learning. At the same time, learnable data\naugmentation produces challenging negative samples to enhance learning\nefficiency. We measured anomaly scores of the proposed technique based on\nlatent feature similarities. As per the results, LATAD exhibited comparable or\nimproved performance to the state-of-the-art anomaly detection assessments on\nseveral benchmark datasets and provided a gradient-based diagnosis technique to\nhelp identify root causes.",
      "tldr_zh": "这篇论文提出了一种自监督时间序列异常检测技术 LATAD，使用可学习数据增强来解决制造业中异常数据稀缺和标注困难的问题。LATAD 通过对比学习提取时间序列数据的判别特征，同时生成具有挑战性的负样本，以提升学习效率，并基于潜在特征相似度计算异常分数。实验结果显示，该方法在多个基准数据集上表现出色，与最先进方法相当或更好，并提供基于梯度的诊断技术，帮助识别异常的根本原因。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures, IEEE Transactions on Emerging Topics in\n  Computational Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2406.12260v1",
      "published_date": "2024-06-18 04:25:56 UTC",
      "updated_date": "2024-06-18 04:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:03:25.561124"
    },
    {
      "arxiv_id": "2406.12259v3",
      "title": "Adversarial Attacks on Large Language Models in Medicine",
      "title_zh": "医学领域的大语言",
      "authors": [
        "Yifan Yang",
        "Qiao Jin",
        "Furong Huang",
        "Zhiyong Lu"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into healthcare applications\noffers promising advancements in medical diagnostics, treatment\nrecommendations, and patient care. However, the susceptibility of LLMs to\nadversarial attacks poses a significant threat, potentially leading to harmful\noutcomes in delicate medical contexts. This study investigates the\nvulnerability of LLMs to two types of adversarial attacks in three medical\ntasks. Utilizing real-world patient data, we demonstrate that both open-source\nand proprietary LLMs are susceptible to manipulation across multiple tasks.\nThis research further reveals that domain-specific tasks demand more\nadversarial data in model fine-tuning than general domain tasks for effective\nattack execution, especially for more capable models. We discover that while\nintegrating adversarial data does not markedly degrade overall model\nperformance on medical benchmarks, it does lead to noticeable shifts in\nfine-tuned model weights, suggesting a potential pathway for detecting and\ncountering model attacks. This research highlights the urgent need for robust\nsecurity measures and the development of defensive mechanisms to safeguard LLMs\nin medical applications, to ensure their safe and effective deployment in\nhealthcare settings.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)在医疗应用中的对抗性攻击脆弱性，调查了三种医疗任务中的两种攻击类型，利用真实患者数据证明了开源和专有LLMs易受操纵。\n结果显示，领域特定任务比通用任务需要更多对抗数据来微调模型进行有效攻击，尤其对更强大的模型。\n尽管整合对抗数据不会显著降低LLMs在医疗基准上的整体性能，但会导致微调模型权重发生明显变化，这为检测和抵御攻击提供了潜在途径。\n该研究强调了开发稳健安全措施的紧迫性，以保障LLMs在医疗领域的安全和有效部署。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12259v3",
      "published_date": "2024-06-18 04:24:30 UTC",
      "updated_date": "2024-12-16 19:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:03:28.449885"
    },
    {
      "arxiv_id": "2406.12257v3",
      "title": "CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuetai Li",
        "Zhangchen Xu",
        "Fengqing Jiang",
        "Luyao Niu",
        "Dinuka Sahabandu",
        "Bhaskar Ramasubramanian",
        "Radha Poovendran"
      ],
      "abstract": "The remarkable performance of large language models (LLMs) in generation\ntasks has enabled practitioners to leverage publicly available models to power\ncustom applications, such as chatbots and virtual assistants. However, the data\nused to train or fine-tune these LLMs is often undisclosed, allowing an\nattacker to compromise the data and inject backdoors into the models. In this\npaper, we develop a novel inference time defense, named CLEANGEN, to mitigate\nbackdoor attacks for generation tasks in LLMs. CLEANGEN is a lightweight and\neffective decoding strategy that is compatible with the state-of-the-art (SOTA)\nLLMs. Our insight behind CLEANGEN is that compared to other LLMs, backdoored\nLLMs assign significantly higher probabilities to tokens representing the\nattacker-desired contents. These discrepancies in token probabilities enable\nCLEANGEN to identify suspicious tokens favored by the attacker and replace them\nwith tokens generated by another LLM that is not compromised by the same\nattacker, thereby avoiding generation of attacker-desired content. We evaluate\nCLEANGEN against five SOTA backdoor attacks. Our results show that CLEANGEN\nachieves lower attack success rates (ASR) compared to five SOTA baseline\ndefenses for all five backdoor attacks. Moreover, LLMs deploying CLEANGEN\nmaintain helpfulness in their responses when serving benign user queries with\nminimal added computational overhead.",
      "tldr_zh": "这篇论文提出了 CleanGen，一种轻量级的推理时防御策略，用于缓解大型语言模型 (LLMs) 在生成任务中的后门攻击 (backdoor attacks)。CleanGen 通过检测后门模型中赋予攻击者期望内容的高概率标记，并用另一个未受损的 LLM 生成的标记替换，从而有效避免生成恶意内容。实验结果显示，CleanGen 在五个 SOTA 后门攻击中比五种基线防御方法实现了更低的攻击成功率 (ASR)，同时在处理良性查询时保持了模型的响应帮助性和最小计算开销。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper is presented at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12257v3",
      "published_date": "2024-06-18 04:10:38 UTC",
      "updated_date": "2025-03-27 16:21:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:03:40.225964"
    },
    {
      "arxiv_id": "2406.12255v1",
      "title": "A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Lijie Hu",
        "Liang Liu",
        "Shu Yang",
        "Xin Chen",
        "Hongru Xiao",
        "Mengdi Li",
        "Pan Zhou",
        "Muhammad Asif Ali",
        "Di Wang"
      ],
      "abstract": "Chain-of-Thought (CoT) holds a significant place in augmenting the reasoning\nperformance for large language models (LLMs). While some studies focus on\nimproving CoT accuracy through methods like retrieval enhancement, yet a\nrigorous explanation for why CoT achieves such success remains unclear. In this\npaper, we analyze CoT methods under two different settings by asking the\nfollowing questions: (1) For zero-shot CoT, why does prompting the model with\n\"let's think step by step\" significantly impact its outputs? (2) For few-shot\nCoT, why does providing examples before questioning the model could\nsubstantially improve its reasoning ability? To answer these questions, we\nconduct a top-down explainable analysis from the Hopfieldian view and propose a\nRead-and-Control approach for controlling the accuracy of CoT. Through\nextensive experiments on seven datasets for three different tasks, we\ndemonstrate that our framework can decipher the inner workings of CoT, provide\nreasoning error localization, and control to come up with the correct reasoning\npath.",
      "tldr_zh": "这篇论文从 Hopfieldian 视角对 Chain-of-Thought (CoT) 推理进行解释性分析，探讨了为什么零样本 CoT 中的“let's think step by step”提示能显著提升大型语言模型 (LLMs) 的输出，以及为什么少样本 CoT 通过提供示例能改善推理能力。作者提出 Read-and-Control 方法，用于控制 CoT 的准确性，并通过七个数据集上的三个任务实验，展示了该框架能解构 CoT 的内部机制、定位推理错误并引导正确的推理路径。该研究为理解和优化 LLMs 的推理性能提供了新的理论基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.12255v1",
      "published_date": "2024-06-18 04:07:13 UTC",
      "updated_date": "2024-06-18 04:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:04:03.600858"
    },
    {
      "arxiv_id": "2406.12251v1",
      "title": "Mitigate Negative Transfer with Similarity Heuristic Lifelong Prompt Tuning",
      "title_zh": "通过相似性启发式缓解负面转移的终身提示调整",
      "authors": [
        "Chenyuan Wu",
        "Gangwei Jiang",
        "Defu Lian"
      ],
      "abstract": "Lifelong prompt tuning has significantly advanced parameter-efficient\nlifelong learning with its efficiency and minimal storage demands on various\ntasks. Our empirical studies, however, highlights certain transferability\nconstraints in the current methodologies: a universal algorithm that guarantees\nconsistent positive transfer across all tasks is currently unattainable,\nespecially when dealing dissimilar tasks that may engender negative transfer.\nIdentifying the misalignment between algorithm selection and task specificity\nas the primary cause of negative transfer, we present the Similarity Heuristic\nLifelong Prompt Tuning (SHLPT) framework. This innovative strategy partitions\ntasks into two distinct subsets by harnessing a learnable similarity metric,\nthereby facilitating fruitful transfer from tasks regardless of their\nsimilarity or dissimilarity. Additionally, SHLPT incorporates a parameter pool\nto combat catastrophic forgetting effectively. Our experiments shows that SHLPT\noutperforms state-of-the-art techniques in lifelong learning benchmarks and\ndemonstrates robustness against negative transfer in diverse task sequences.",
      "tldr_zh": "该研究针对现有 Lifelong Prompt Tuning 方法在处理不相似的任务时可能导致 Negative Transfer 的问题，提出了一种创新框架 Similarity Heuristic Lifelong Prompt Tuning (SHLPT)。SHLPT 通过一个可学习的相似性指标将任务分为两个子集，促进不同任务间的有效转移，同时引入参数池（parameter pool）来有效防止 Catastrophic Forgetting。实验结果表明，SHLPT 在终身学习基准上超越了最先进技术，并在多样任务序列中展示了强大的 Negative Transfer 鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.12251v1",
      "published_date": "2024-06-18 03:57:49 UTC",
      "updated_date": "2024-06-18 03:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:04:06.102901"
    },
    {
      "arxiv_id": "2406.12243v1",
      "title": "CherryRec: Enhancing News Recommendation Quality via LLM-driven Framework",
      "title_zh": "CherryRec：通过LLM驱动框架提升新闻推荐质量",
      "authors": [
        "Shaohuang Wang",
        "Lun Wang",
        "Yunhan Bu",
        "Tianwei Huang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable progress in language\nunderstanding and generation. Custom LLMs leveraging textual features have been\napplied to recommendation systems, demonstrating improvements across various\nrecommendation scenarios. However, most existing methods perform untrained\nrecommendation based on pre-trained knowledge (e.g., movie recommendation), and\nthe auto-regressive generation of LLMs leads to slow inference speeds, making\nthem less effective in real-time recommendations.To address this, we propose a\nframework for news recommendation using LLMs, named \\textit{CherryRec}, which\nensures the quality of recommendations while accelerating the recommendation\nprocess. Specifically, we employ a Knowledge-aware News Rapid Selector to\nretrieve candidate options based on the user's interaction history. The history\nand retrieved items are then input as text into a fine-tuned LLM, the\nContent-aware News Llm Evaluator, designed to enhance news recommendation\ncapabilities. Finally, the Value-aware News Scorer integrates the scores to\ncompute the CherryRec Score, which serves as the basis for the final\nrecommendation.We validate the effectiveness of the proposed framework by\ncomparing it with state-of-the-art baseline methods on benchmark datasets. Our\nexperimental results consistently show that CherryRec outperforms the baselines\nin both recommendation performance and efficiency.The project resource can be\naccessed at: \\url{https://github.com/xxxxxx}",
      "tldr_zh": "该论文提出 CherryRec 框架，利用大型语言模型 (LLMs) 来提升新闻推荐系统的质量和效率，解决现有方法在实时推荐中的速度和准确性问题。框架包括三个关键组件：Knowledge-aware News Rapid Selector 基于用户交互历史快速检索候选新闻、Content-aware News Llm Evaluator 通过微调 LLM 评估内容相关性，以及 Value-aware News Scorer 整合分数计算最终 CherryRec Score。实验结果显示，在基准数据集上，CherryRec 比现有基线方法在推荐性能和效率方面均有显著提升。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12243v1",
      "published_date": "2024-06-18 03:33:38 UTC",
      "updated_date": "2024-06-18 03:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:04:16.718620"
    },
    {
      "arxiv_id": "2406.12242v1",
      "title": "GMP-AR: Granularity Message Passing and Adaptive Reconciliation for Temporal Hierarchy Forecasting",
      "title_zh": "GMP-AR：粒度消息传递和自适应协调用于时间层次",
      "authors": [
        "Fan Zhou",
        "Chen Pan",
        "Lintao Ma",
        "Yu Liu",
        "James Zhang",
        "Jun Zhou",
        "Hongyuan Mei",
        "Weitao Lin",
        "Zi Zhuang",
        "Wenxin Ning",
        "Yunhua Hu",
        "Siqiao Xue"
      ],
      "abstract": "Time series forecasts of different temporal granularity are widely used in\nreal-world applications, e.g., sales prediction in days and weeks for making\ndifferent inventory plans. However, these tasks are usually solved separately\nwithout ensuring coherence, which is crucial for aligning downstream decisions.\nPrevious works mainly focus on ensuring coherence with some straightforward\nmethods, e.g., aggregation from the forecasts of fine granularity to the coarse\nones, and allocation from the coarse granularity to the fine ones. These\nmethods merely take the temporal hierarchical structure to maintain coherence\nwithout improving the forecasting accuracy. In this paper, we propose a novel\ngranularity message-passing mechanism (GMP) that leverages temporal hierarchy\ninformation to improve forecasting performance and also utilizes an adaptive\nreconciliation (AR) strategy to maintain coherence without performance loss.\nFurthermore, we introduce an optimization module to achieve task-based targets\nwhile adhering to more real-world constraints. Experiments on real-world\ndatasets demonstrate that our framework (GMP-AR) achieves superior performances\non temporal hierarchical forecasting tasks compared to state-of-the-art\nmethods. In addition, our framework has been successfully applied to a\nreal-world task of payment traffic management in Alipay by integrating with the\ntask-based optimization module.",
      "tldr_zh": "本研究针对时间序列预测中不同粒度（如日、周）的预测任务，提出了一种名为 GMP-AR 的框架，以解决传统方法无法确保预测一致性的问题。框架引入 Granularity Message Passing (GMP) 机制，利用时间层次结构信息来提升预测性能，并采用 Adaptive Reconciliation (AR) 策略在保持一致性前提下避免性能损失；此外，还整合了一个优化模块以适应实际任务约束。实验在真实数据集上显示，GMP-AR 框架在 Temporal Hierarchy Forecasting 任务中优于现有方法，并在 Alipay 的支付流量管理中成功应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12242v1",
      "published_date": "2024-06-18 03:33:03 UTC",
      "updated_date": "2024-06-18 03:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:04:28.101713"
    },
    {
      "arxiv_id": "2406.12241v1",
      "title": "More Efficient Randomized Exploration for Reinforcement Learning via Approximate Sampling",
      "title_zh": "通过近似采样实现强化学习中更高效的随机探索",
      "authors": [
        "Haque Ishfaq",
        "Yixin Tan",
        "Yu Yang",
        "Qingfeng Lan",
        "Jianfeng Lu",
        "A. Rupam Mahmood",
        "Doina Precup",
        "Pan Xu"
      ],
      "abstract": "Thompson sampling (TS) is one of the most popular exploration techniques in\nreinforcement learning (RL). However, most TS algorithms with theoretical\nguarantees are difficult to implement and not generalizable to Deep RL. While\nthe emerging approximate sampling-based exploration schemes are promising, most\nexisting algorithms are specific to linear Markov Decision Processes (MDP) with\nsuboptimal regret bounds, or only use the most basic samplers such as Langevin\nMonte Carlo. In this work, we propose an algorithmic framework that\nincorporates different approximate sampling methods with the recently proposed\nFeel-Good Thompson Sampling (FGTS) approach (Zhang, 2022; Dann et al., 2021),\nwhich was previously known to be computationally intractable in general. When\napplied to linear MDPs, our regret analysis yields the best known dependency of\nregret on dimensionality, surpassing existing randomized algorithms.\nAdditionally, we provide explicit sampling complexity for each employed\nsampler. Empirically, we show that in tasks where deep exploration is\nnecessary, our proposed algorithms that combine FGTS and approximate sampling\nperform significantly better compared to other strong baselines. On several\nchallenging games from the Atari 57 suite, our algorithms achieve performance\nthat is either better than or on par with other strong baselines from the deep\nRL literature.",
      "tldr_zh": "本论文提出了一种更高效的随机探索框架，用于强化学习，通过近似采样方法改进Thompson Sampling (TS)，以解决现有算法在实现和泛化方面的挑战。该框架将各种近似采样方法（如Langevin Monte Carlo）整合到Feel-Good Thompson Sampling (FGTS)中，适用于线性Markov Decision Processes (MDP)，并提供最佳的regret界依赖于维度，同时给出明确的采样复杂度。实验结果显示，在需要深度探索的任务中，该算法在Atari 57游戏套件上显著优于其他基线，实现了更好的性能或相当水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "First two authors contributed equally. Accepted to the Reinforcement\n  Learning Conference (RLC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12241v1",
      "published_date": "2024-06-18 03:32:10 UTC",
      "updated_date": "2024-06-18 03:32:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:04:40.567003"
    },
    {
      "arxiv_id": "2406.12233v1",
      "title": "SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization",
      "title_zh": "翻译失败",
      "authors": [
        "Young Jin Ahn",
        "Jungwoo Park",
        "Sangha Park",
        "Jonghyun Choi",
        "Kee-Eung Kim"
      ],
      "abstract": "Visual Speech Recognition (VSR) stands at the intersection of computer vision\nand speech recognition, aiming to interpret spoken content from visual cues. A\nprominent challenge in VSR is the presence of homophenes-visually similar lip\ngestures that represent different phonemes. Prior approaches have sought to\ndistinguish fine-grained visemes by aligning visual and auditory semantics, but\noften fell short of full synchronization. To address this, we present SyncVSR,\nan end-to-end learning framework that leverages quantized audio for frame-level\ncrossmodal supervision. By integrating a projection layer that synchronizes\nvisual representation with acoustic data, our encoder learns to generate\ndiscrete audio tokens from a video sequence in a non-autoregressive manner.\nSyncVSR shows versatility across tasks, languages, and modalities at the cost\nof a forward pass. Our empirical evaluations show that it not only achieves\nstate-of-the-art results but also reduces data usage by up to ninefold.",
      "tldr_zh": "本研究提出SyncVSR，一种数据高效的端到端视觉语音识别框架，通过跨模态音频标记同步来解决homophenes（视觉上相似的唇部动作代表不同音素）等挑战。SyncVSR利用量化音频进行帧级别crossmodal supervision，并集成投影层，使编码器从视频序列非自回归地生成离散音频标记，从而实现视觉和声学数据的精确对齐。该框架适用于多种任务、语言和模态，仅需一个前向传递，并在实验中达到最先进性能，同时将数据使用减少多达九倍。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12233v1",
      "published_date": "2024-06-18 03:14:22 UTC",
      "updated_date": "2024-06-18 03:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:04:52.266949"
    },
    {
      "arxiv_id": "2406.12232v2",
      "title": "\"You Gotta be a Doctor, Lin\": An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Nghiem",
        "John Prindle",
        "Jieyu Zhao",
        "Hal Daumé III"
      ],
      "abstract": "Social science research has shown that candidates with names indicative of\ncertain races or genders often face discrimination in employment practices.\nSimilarly, Large Language Models (LLMs) have demonstrated racial and gender\nbiases in various applications. In this study, we utilize GPT-3.5-Turbo and\nLlama 3-70B-Instruct to simulate hiring decisions and salary recommendations\nfor candidates with 320 first names that strongly signal their race and gender,\nacross over 750,000 prompts. Our empirical results indicate a preference among\nthese models for hiring candidates with White female-sounding names over other\ndemographic groups across 40 occupations. Additionally, even among candidates\nwith identical qualifications, salary recommendations vary by as much as 5%\nbetween different subgroups. A comparison with real-world labor data reveals\ninconsistent alignment with U.S. labor market characteristics, underscoring the\nnecessity of risk investigation of LLM-powered systems.",
      "tldr_zh": "这篇论文调查了 Large Language Models (LLMs) 在就业推荐中的基于姓名的种族和性别偏见，使用 GPT-3.5-Turbo 和 Llama 3-70B-Instruct 模型模拟招聘决策和薪资推荐，涉及 320 个强烈暗示种族和性别的名字，跨越 40 个职业和超过 750,000 个提示。结果显示，模型更倾向于雇用听起来像白人女性的候选人，即使资格相同，薪资推荐也可能因子群体而异，高达 5%。与美国劳动力市场数据比较后，发现模型偏见与现实不一致，突出了 LLM 驱动系统潜在风险的必要性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2024, 20 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.12232v2",
      "published_date": "2024-06-18 03:11:43 UTC",
      "updated_date": "2024-10-05 21:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:05:06.934532"
    },
    {
      "arxiv_id": "2406.12230v2",
      "title": "MCSD: An Efficient Language Model with Diverse Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Hua Yang",
        "Duohai Li",
        "Shiman Li"
      ],
      "abstract": "Transformers excel in Natural Language Processing (NLP) due to their prowess\nin capturing long-term dependencies but suffer from exponential resource\nconsumption with increasing sequence lengths. To address these challenges, we\npropose MCSD model, an efficient language model with linear scaling and fast\ninference speed. MCSD model leverages diverse feature fusion, primarily through\nthe multi-channel slope and decay (MCSD) block, to robustly represent features.\nThis block comprises slope and decay sections that extract features across\ndiverse temporal receptive fields, facilitating capture of both local and\nglobal information. In addition, MCSD block conducts element-wise fusion of\ndiverse features to further enhance the delicate feature extraction capability.\nFor inference, we formulate the inference process into a recurrent\nrepresentation, slashing space complexity to $O(1)$ and time complexity to\n$O(N)$ respectively. Our experiments show that MCSD attains higher throughput\nand lower GPU memory consumption compared to Transformers, while maintaining\ncomparable performance to larger-scale language learning models on benchmark\ntests. These attributes position MCSD as a promising base for edge deployment\nand embodied intelligence.",
      "tldr_zh": "本研究针对Transformer模型在处理长序列时存在的资源消耗指数级增长问题，提出了一种高效语言模型MCSD，该模型通过多通道斜率和衰减（MCSD）块来融合多样特征，从而捕捉局部和全局信息。MCSD块包括slope和decay部分，能够提取跨不同时间感受野的特征，并进行元素-wise融合以提升特征提取能力。在推理过程中，MCSD将过程转化为递归表示，将空间复杂度降至O(1)和时间复杂度至O(N)。实验结果显示，MCSD在基准测试中性能与大型语言模型相当，同时实现更高吞吐量和更低GPU内存消耗，适合边缘部署和embodied intelligence应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.12230v2",
      "published_date": "2024-06-18 03:08:01 UTC",
      "updated_date": "2024-07-11 03:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:05:16.316893"
    },
    {
      "arxiv_id": "2406.12229v1",
      "title": "Spatially Resolved Gene Expression Prediction from Histology via Multi-view Graph Contrastive Learning with HSIC-bottleneck Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Changxi Chi",
        "Hang Shi",
        "Qi Zhu",
        "Daoqiang Zhang",
        "Wei Shao"
      ],
      "abstract": "The rapid development of spatial transcriptomics(ST) enables the measurement\nof gene expression at spatial resolution, making it possible to simultaneously\nprofile the gene expression, spatial locations of spots, and the matched\nhistopathological images. However, the cost for collecting ST data is much\nhigher than acquiring histopathological images, and thus several studies\nattempt to predict the gene expression on ST by leveraging their corresponding\nhistopathological images. Most of the existing image-based gene prediction\nmodels treat the prediction task on each spot of ST data independently, which\nignores the spatial dependency among spots. In addition, while the histology\nimages share phenotypic characteristics with the ST data, it is still challenge\nto extract such common information to help align paired image and expression\nrepresentations. To address the above issues, we propose a Multi-view Graph\nContrastive Learning framework with HSIC-bottleneck Regularization(ST-GCHB)\naiming at learning shared representation to help impute the gene expression of\nthe queried imagingspots by considering their spatial dependency.",
      "tldr_zh": "该论文针对空间转录组学(ST)数据的高成本问题，提出一种基于组织病理图像预测基因表达的方法，以解决现有模型忽略点间空间依赖性和信息对齐挑战。作者开发了Multi-view Graph Contrastive Learning with HSIC-bottleneck Regularization(ST-GCHB)框架，通过多视图图对比学习和HSIC-bottleneck正则化，学习共享表示并考虑空间依赖性。实验结果表明，该方法能有效提升基因表达预测的准确性，为低成本的ST数据推断提供新途径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12229v1",
      "published_date": "2024-06-18 03:07:25 UTC",
      "updated_date": "2024-06-18 03:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:05:29.110825"
    },
    {
      "arxiv_id": "2406.12227v3",
      "title": "Refine Large Language Model Fine-tuning via Instruction Vector",
      "title_zh": "通过指令向量精炼大语言",
      "authors": [
        "Gangwei Jiang",
        "Zhaoyi Li",
        "Defu Lian",
        "Ying Wei"
      ],
      "abstract": "Fine-tuning large language models (LLMs) can cause them to lose their general\ncapabilities. However, the intrinsic mechanisms behind such forgetting remain\nunexplored. In this paper, we begin by examining this phenomenon by focusing on\nknowledge understanding and instruction following, with the latter identified\nas the main contributor to forgetting during fine-tuning. Consequently, we\npropose the Instruction Vector (IV) framework to capture model representations\nhighly related to specific instruction-following capabilities, thereby making\nit possible to understand model-intrinsic forgetting. Through the analysis of\nIV dynamics pre and post-training, we suggest that fine-tuning mostly adds\nspecialized reasoning patterns instead of erasing previous skills, which may\nappear as forgetting. Building on this insight, we develop IV-guided training,\nwhich aims to preserve original computation graph, thereby mitigating\ncatastrophic forgetting. Empirical tests on three benchmarks confirm the\nefficacy of this new approach, supporting the relationship between IVs and\nforgetting. Our code will be made available soon.",
      "tldr_zh": "该论文探讨了 fine-tuning Large Language Models (LLMs) 过程中导致模型丢失一般能力的现象，特别强调指令遵循能力是遗忘的主要原因。作者提出 Instruction Vector (IV) 框架，用于捕捉与特定指令遵循相关的模型表示，通过分析 IV 在训练前后的动态，揭示 fine-tuning 更多是添加专业推理模式而非擦除原有技能。基于这一洞见，他们开发了 IV-guided training 方法，以保留原始计算图，从而缓解灾难性遗忘，并在三个基准测试中验证了该方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12227v3",
      "published_date": "2024-06-18 03:05:08 UTC",
      "updated_date": "2024-11-28 18:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:05:41.060931"
    },
    {
      "arxiv_id": "2406.16942v1",
      "title": "Enhancing Diagnostic Reliability of Foundation Model with Uncertainty Estimation in OCT Images",
      "title_zh": "通过不确定性估计增强基础模型在 OCT 图像中的诊断可靠性",
      "authors": [
        "Yuanyuan Peng",
        "Aidi Lin",
        "Meng Wang",
        "Tian Lin",
        "Ke Zou",
        "Yinglin Cheng",
        "Tingkun Shi",
        "Xulong Liao",
        "Lixia Feng",
        "Zhen Liang",
        "Xinjian Chen",
        "Huazhu Fu",
        "Haoyu Chen"
      ],
      "abstract": "Inability to express the confidence level and detect unseen classes has\nlimited the clinical implementation of artificial intelligence in the\nreal-world. We developed a foundation model with uncertainty estimation (FMUE)\nto detect 11 retinal conditions on optical coherence tomography (OCT). In the\ninternal test set, FMUE achieved a higher F1 score of 96.76% than two\nstate-of-the-art algorithms, RETFound and UIOS, and got further improvement\nwith thresholding strategy to 98.44%. In the external test sets obtained from\nother OCT devices, FMUE achieved an accuracy of 88.75% and 92.73% before and\nafter thresholding. Our model is superior to two ophthalmologists with a higher\nF1 score (95.17% vs. 61.93% &71.72%). Besides, our model correctly predicts\nhigh uncertainty scores for samples with ambiguous features, of\nnon-target-category diseases, or with low-quality to prompt manual checks and\nprevent misdiagnosis. FMUE provides a trustworthy method for automatic retinal\nanomalies detection in the real-world clinical open set environment.",
      "tldr_zh": "该研究开发了带不确定性估计的基础模型（Foundation Model with Uncertainty Estimation, FMUE），用于在光学相干断层扫描（OCT）图像上检测11种视网膜疾病，以解决AI模型在临床应用中无法表达置信水平和检测未知类别的局限性。在内部测试集上，FMUE的F1分数达96.76%，优于现有算法RETFound和UIOS，并通过阈值策略进一步提升至98.44%；在外部测试集上，准确率分别为88.75%和92.73%。与两位眼科医生相比，FMUE表现出色，F1分数高达95.17%，并能为模糊特征、非目标疾病或低质量样本分配高不确定性分数，提示手动检查以防止误诊。该方法为真实临床环境中可靠的视网膜异常检测提供了可信赖的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "All codes are available at https://github.com/yuanyuanpeng0129/FMUE",
      "pdf_url": "http://arxiv.org/pdf/2406.16942v1",
      "published_date": "2024-06-18 03:04:52 UTC",
      "updated_date": "2024-06-18 03:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:05:54.535304"
    },
    {
      "arxiv_id": "2406.12222v1",
      "title": "BadSampler: Harnessing the Power of Catastrophic Forgetting to Poison Byzantine-robust Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Liu",
        "Cong Wang",
        "Xingliang Yuan"
      ],
      "abstract": "Federated Learning (FL) is susceptible to poisoning attacks, wherein\ncompromised clients manipulate the global model by modifying local datasets or\nsending manipulated model updates. Experienced defenders can readily detect and\nmitigate the poisoning effects of malicious behaviors using Byzantine-robust\naggregation rules. However, the exploration of poisoning attacks in scenarios\nwhere such behaviors are absent remains largely unexplored for Byzantine-robust\nFL. This paper addresses the challenging problem of poisoning Byzantine-robust\nFL by introducing catastrophic forgetting. To fill this gap, we first formally\ndefine generalization error and establish its connection to catastrophic\nforgetting, paving the way for the development of a clean-label data poisoning\nattack named BadSampler. This attack leverages only clean-label data (i.e.,\nwithout poisoned data) to poison Byzantine-robust FL and requires the adversary\nto selectively sample training data with high loss to feed model training and\nmaximize the model's generalization error. We formulate the attack as an\noptimization problem and present two elegant adversarial sampling strategies,\nTop-$\\kappa$ sampling, and meta-sampling, to approximately solve it.\nAdditionally, our formal error upper bound and time complexity analysis\ndemonstrate that our design can preserve attack utility with high efficiency.\nExtensive evaluations on two real-world datasets illustrate the effectiveness\nand performance of our proposed attacks.",
      "tldr_zh": "这篇论文探讨了如何利用灾难性遗忘（catastrophic forgetting）来攻击 Byzantine-robust Federated Learning（FL），提出了一种名为 BadSampler 的 clean-label 数据中毒攻击方法。该攻击不使用毒化数据，而是通过选择高损失训练样本来最大化模型的 generalization error，并将其表述为一个优化问题，引入了 Top-κ sampling 和 meta-sampling 两种策略来高效实现。实验结果显示，该攻击在两个真实数据集上表现出色，证明了其有效性，并通过正式的错误上界和时间复杂度分析，展示了其实用性和效率。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "In Proceedings of the 30th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD' 24), August 25-29, 2024, Barcelona, Spain",
      "pdf_url": "http://arxiv.org/pdf/2406.12222v1",
      "published_date": "2024-06-18 02:43:56 UTC",
      "updated_date": "2024-06-18 02:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:06:06.246057"
    },
    {
      "arxiv_id": "2406.12216v1",
      "title": "Is persona enough for personality? Using ChatGPT to reconstruct an agent's latent personality from simple descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Yongyi Ji",
        "Zhisheng Tang",
        "Mayank Kejriwal"
      ],
      "abstract": "Personality, a fundamental aspect of human cognition, contains a range of\ntraits that influence behaviors, thoughts, and emotions. This paper explores\nthe capabilities of large language models (LLMs) in reconstructing these\ncomplex cognitive attributes based only on simple descriptions containing\nsocio-demographic and personality type information. Utilizing the HEXACO\npersonality framework, our study examines the consistency of LLMs in recovering\nand predicting underlying (latent) personality dimensions from simple\ndescriptions. Our experiments reveal a significant degree of consistency in\npersonality reconstruction, although some inconsistencies and biases, such as a\ntendency to default to positive traits in the absence of explicit information,\nare also observed. Additionally, socio-demographic factors like age and number\nof children were found to influence the reconstructed personality dimensions.\nThese findings have implications for building sophisticated agent-based\nsimulacra using LLMs and highlight the need for further research on robust\npersonality generation in LLMs.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）如 ChatGPT 是否能仅基于简单描述（如社会人口统计和个性类型）重建代理的潜在 personality。利用 HEXACO 框架，研究团队通过实验评估了 LLMs 在恢复和预测个性维度的能力，发现模型在重建中表现出显著的一致性，但也存在偏差，例如倾向于默认积极特质。结果表明，社会人口统计因素如年龄和孩子数量会影响重建的 personality 维度，这为使用 LLMs 构建高级代理模拟提供了启示，并强调了需要进一步研究以提升 personality 生成的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the ICML 2024 Workshop on Large Language Models and\n  Cognition",
      "pdf_url": "http://arxiv.org/pdf/2406.12216v1",
      "published_date": "2024-06-18 02:32:57 UTC",
      "updated_date": "2024-06-18 02:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:06:16.367588"
    },
    {
      "arxiv_id": "2406.12213v4",
      "title": "AI-Oracle Machines for Intelligent Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Wang"
      ],
      "abstract": "We introduce the concept of AI-oracle machines for intelligent computing and\noutline several applications to demonstrate their potential. Following this, we\nadvocate for the development of a comprehensive platform to streamline the\nimplementation of AI-oracle machines.",
      "tldr_zh": "这篇论文引入了 AI-oracle machines 的概念，用于智能计算，并通过几个应用示例展示了其潜力。作者强调，这种方法可以提升计算智能的效率和有效性。最终，他们主张开发一个全面平台，以简化 AI-oracle machines 的实施和部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL",
        "F.1.1; F.4.1; I.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.12213v4",
      "published_date": "2024-06-18 02:25:33 UTC",
      "updated_date": "2024-10-16 00:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:06:27.592988"
    },
    {
      "arxiv_id": "2406.12208v1",
      "title": "Knowledge Fusion By Evolving Weights of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Guodong Du",
        "Jing Li",
        "Hanting Liu",
        "Runhua Jiang",
        "Shuyang Yu",
        "Yifei Guo",
        "Sim Kuan Goh",
        "Ho-Kin Tang"
      ],
      "abstract": "Fine-tuning pre-trained language models, particularly large language models,\ndemands extensive computing resources and can result in varying performance\noutcomes across different domains and datasets. This paper examines the\napproach of integrating multiple models from diverse training scenarios into a\nunified model. This unified model excels across various data domains and\nexhibits the ability to generalize well on out-of-domain data. We propose a\nknowledge fusion method named Evolver, inspired by evolutionary algorithms,\nwhich does not need further training or additional training data. Specifically,\nour method involves aggregating the weights of different language models into a\npopulation and subsequently generating offspring models through mutation and\ncrossover operations. These offspring models are then evaluated against their\nparents, allowing for the preservation of those models that show enhanced\nperformance on development datasets. Importantly, our model evolving strategy\ncan be seamlessly integrated with existing model merging frameworks, offering a\nversatile tool for model enhancement. Experimental results on mainstream\nlanguage models (i.e., encoder-only, decoder-only, encoder-decoder) reveal that\nEvolver outperforms previous state-of-the-art models by large margins. The code\nis publicly available at {https://github.com/duguodong7/model-evolution}.",
      "tldr_zh": "该论文探讨了微调预训练语言模型的挑战，包括高计算资源需求和在不同领域数据集上的表现不一致。作者提出了一种名为 Evolver 的知识融合方法，基于 evolutionary algorithms，将多个语言模型的权重聚合成一个种群，通过突变和交叉操作生成后代模型，并通过评估保留性能更好的模型，而无需额外训练数据或过程。该方法可无缝整合现有模型合并框架，实验结果显示 Evolver 在 encoder-only、decoder-only 和 encoder-decoder 等主流语言模型上大幅超越现有最先进模型，并在域外数据上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.12208v1",
      "published_date": "2024-06-18 02:12:34 UTC",
      "updated_date": "2024-06-18 02:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:06:41.622851"
    },
    {
      "arxiv_id": "2406.12205v1",
      "title": "Order-Optimal Instance-Dependent Bounds for Offline Reinforcement Learning with Preference Feedback",
      "title_zh": "针对带偏好反馈的离线强化学习的阶优",
      "authors": [
        "Zhirui Chen",
        "Vincent Y. F. Tan"
      ],
      "abstract": "We consider offline reinforcement learning (RL) with preference feedback in\nwhich the implicit reward is a linear function of an unknown parameter. Given\nan offline dataset, our objective consists in ascertaining the optimal action\nfor each state, with the ultimate goal of minimizing the {\\em simple regret}.\nWe propose an algorithm, \\underline{RL} with \\underline{L}ocally\n\\underline{O}ptimal \\underline{W}eights or {\\sc RL-LOW}, which yields a simple\nregret of $\\exp ( - \\Omega(n/H) )$ where $n$ is the number of data samples and\n$H$ denotes an instance-dependent hardness quantity that depends explicitly on\nthe suboptimality gap of each action. Furthermore, we derive a\nfirst-of-its-kind instance-dependent lower bound in offline RL with preference\nfeedback. Interestingly, we observe that the lower and upper bounds on the\nsimple regret match order-wise in the exponent, demonstrating order-wise\noptimality of {\\sc RL-LOW}. In view of privacy considerations in practical\napplications, we also extend {\\sc RL-LOW} to the setting of\n$(\\varepsilon,\\delta)$-differential privacy and show, somewhat surprisingly,\nthat the hardness parameter $H$ is unchanged in the asymptotic regime as $n$\ntends to infinity; this underscores the inherent efficiency of {\\sc RL-LOW} in\nterms of preserving the privacy of the observed rewards. Given our focus on\nestablishing instance-dependent bounds, our work stands in stark contrast to\nprevious works that focus on establishing worst-case regrets for offline RL\nwith preference feedback.",
      "tldr_zh": "本研究探讨了基于偏好反馈的离线强化学习（offline reinforcement learning），其中隐式奖励是未知参数的线性函数，目标是针对每个状态找到最优动作，以最小化简单遗憾（simple regret）。他们提出了一种算法 RL-LOW，能实现指数级别的简单遗憾为 exp(-Ω(n/H))，其中 n 为样本数，H 为实例相关的硬度参数。研究还首次给出了实例相关的下界，并证明了 RL-LOW 的阶优性（order-wise optimality）。此外，将算法扩展到 (ε, δ)-差分隐私设置中，发现 H 参数在 n 趋于无穷时保持不变，从而在隐私保护下维持了高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to Models of Human Feedback for AI Alignment Workshop, ICML\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12205v1",
      "published_date": "2024-06-18 02:03:12 UTC",
      "updated_date": "2024-06-18 02:03:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:06:53.794976"
    },
    {
      "arxiv_id": "2406.12203v3",
      "title": "InterIntent: Investigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Context",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Liu",
        "Abhishek Anand",
        "Pei Zhou",
        "Jen-tse Huang",
        "Jieyu Zhao"
      ],
      "abstract": "Large language models (LLMs) have demonstrated the potential to mimic human\nsocial intelligence. However, most studies focus on simplistic and static\nself-report or performance-based tests, which limits the depth and validity of\nthe analysis. In this paper, we developed a novel framework, InterIntent, to\nassess LLMs' social intelligence by mapping their ability to understand and\nmanage intentions in a game setting. We focus on four dimensions of social\nintelligence: situational awareness, self-regulation, self-awareness, and\ntheory of mind. Each dimension is linked to a specific game task: intention\nselection, intention following, intention summarization, and intention\nguessing. Our findings indicate that while LLMs exhibit high proficiency in\nselecting intentions, achieving an accuracy of 88%, their ability to infer the\nintentions of others is significantly weaker, trailing human performance by\n20%. Additionally, game performance correlates with intention understanding,\nhighlighting the importance of the four components towards success in this\ngame. These findings underline the crucial role of intention understanding in\nevaluating LLMs' social intelligence and highlight the potential of using\nsocial deduction games as a complex testbed to enhance LLM evaluation.\nInterIntent contributes a structured approach to bridging the evaluation gap in\nsocial intelligence within multiplayer games.",
      "tldr_zh": "本研究开发了InterIntent框架，通过互动游戏情境评估大型语言模型(LLMs)的社会智能，重点考察其理解和管理意图的能力。框架针对四个维度——situational awareness、self-regulation、self-awareness 和 theory of mind——设计了相应任务，包括intention selection、intention following、intention summarization 和 intention guessing。结果显示，LLMs在intention selection上准确率高达88%，但在intention guessing上比人类低20%，且游戏表现与意图理解密切相关。这些发现强调了意图理解在LLMs社会智能评估中的关键作用，并提出使用社会推演游戏作为复杂测试平台来提升评估方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12203v3",
      "published_date": "2024-06-18 02:02:15 UTC",
      "updated_date": "2024-11-03 16:15:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:07:16.282476"
    },
    {
      "arxiv_id": "2406.12199v3",
      "title": "Time Series Modeling for Heart Rate Prediction: From ARIMA to Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Haowei Ni",
        "Shuchen Meng",
        "Xieming Geng",
        "Panfeng Li",
        "Zhuoying Li",
        "Xupeng Chen",
        "Xiaotong Wang",
        "Shiyao Zhang"
      ],
      "abstract": "Cardiovascular disease (CVD) is a leading cause of death globally,\nnecessitating precise forecasting models for monitoring vital signs like heart\nrate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,\nare limited by their need for manual parameter tuning and challenges in\nhandling noisy, sparse, and highly variable medical data. This study\ninvestigates advanced deep learning models, including LSTM, and\ntransformer-based architectures, for predicting heart rate time series from the\nMIT-BIH Database. Results demonstrate that deep learning models, particularly\nPatchTST, significantly outperform traditional models across multiple metrics,\ncapturing complex patterns and dependencies more effectively. This research\nunderscores the potential of deep learning to enhance patient monitoring and\nCVD management, suggesting substantial clinical benefits. Future work should\nextend these findings to larger, more diverse datasets and real-world clinical\napplications to further validate and optimize model performance.",
      "tldr_zh": "这篇论文探讨了从传统模型 ARIMA 到 Transformer 的时间序列建模方法，用于预测心率，以应对心血管疾病（CVD）监测的迫切需求。研究比较了 ARIMA、Prophet、LSTM 和基于 Transformer 的架构（如 PatchTST）在 MIT-BIH Database 中的表现，结果显示深度学习模型，尤其是 PatchTST，在多个指标上显著优于传统模型，能更有效地捕捉复杂模式和依赖关系。该研究强调了深度学习在提升患者监测和 CVD 管理方面的临床潜力，并建议未来工作扩展到更大、更多样化的数据集和实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by 2024 6th International Conference on Electronic\n  Engineering and Informatics",
      "pdf_url": "http://arxiv.org/pdf/2406.12199v3",
      "published_date": "2024-06-18 01:55:37 UTC",
      "updated_date": "2024-11-12 07:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:07:21.393032"
    },
    {
      "arxiv_id": "2406.12197v1",
      "title": "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Sijia Wang",
        "Lifu Huang"
      ],
      "abstract": "We propose a multi-agent debate as optimization (DAO) system for event\nextraction, where the primary objective is to iteratively refine the large\nlanguage models (LLMs) outputs through debating without parameter tuning. In\nDAO, we introduce two novel modules: the Diverse-RAG (DRAG) module and the\nAdaptive Conformal Prediction (AdaCP) module. DRAG systematically retrieves\nsupporting information that best fits the debate discussion, while AdaCP\nenhances the accuracy and reliability of event extraction by effectively\nrejecting less promising answers. Experimental results demonstrate a\nsignificant reduction in the performance gap between supervised approaches and\ntuning-free LLM-based methods by 18.1% and 17.8% on ACE05 and 17.9% and 15.2%\non CASIE for event detection and argument extraction respectively.",
      "tldr_zh": "本论文提出了一种多智能体辩论优化（DAO）系统，用于事件提取任务，通过迭代辩论来优化大语言模型（LLMs）的输出，而无需参数调整。DAO 系统引入了两个关键模块：Diverse-RAG (DRAG) 模块，用于系统检索最适合辩论讨论的支持信息；以及 Adaptive Conformal Prediction (AdaCP) 模块，用于提升事件提取的准确性和可靠性，通过拒绝不太可靠的答案。实验结果显示，该系统在 ACE05 和 CASIE 数据集上，将无监督 LLM 方法与监督方法的性能差距缩小了 18.1% 和 17.8%（事件检测）以及 17.9% 和 15.2%（参数提取），显著提升了整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12197v1",
      "published_date": "2024-06-18 01:53:49 UTC",
      "updated_date": "2024-06-18 01:53:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:07:30.250569"
    },
    {
      "arxiv_id": "2406.15488v1",
      "title": "Orangutan: A Multiscale Brain Emulation-Based Artificial Intelligence Framework for Dynamic Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Xie"
      ],
      "abstract": "Achieving General Artificial Intelligence (AGI) has long been a grand\nchallenge in the field of AI, and brain-inspired computing is widely\nacknowledged as one of the most promising approaches to realize this goal. This\npaper introduces a novel brain-inspired AI framework, Orangutan. It simulates\nthe structure and computational mechanisms of biological brains on multiple\nscales, encompassing multi-compartment neuron architectures, diverse synaptic\nconnection modalities, neural microcircuits, cortical columns, and brain\nregions, as well as biochemical processes including facilitation, feedforward\ninhibition, short-term potentiation, and short-term depression, all grounded in\nsolid neuroscience. Building upon these highly integrated brain-like\nmechanisms, I have developed a sensorimotor model that simulates human saccadic\neye movements during object observation. The model's algorithmic efficacy was\nvalidated through testing with the observation of handwritten digit images.",
      "tldr_zh": "该论文提出了一种名为Orangutan的多尺度脑模拟AI框架，旨在通过模仿生物大脑结构和计算机制来实现General Artificial Intelligence (AGI)，特别适用于动态环境。该框架模拟了多尺度元素，包括multi-compartment neuron architectures、diverse synaptic connection modalities、neural microcircuits、cortical columns和brain regions，以及生化过程如facilitation、feedforward inhibition、short-term potentiation和short-term depression。基于这些机制，研究者开发了一个sensorimotor model来模拟人类saccadic eye movements在观察物体时的行为，并通过测试手写数字图像验证了模型的算法效能。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15488v1",
      "published_date": "2024-06-18 01:41:57 UTC",
      "updated_date": "2024-06-18 01:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:07:41.206898"
    },
    {
      "arxiv_id": "2406.12182v1",
      "title": "Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lulu Zhao",
        "Weihao Zeng",
        "Xiaofeng Shi",
        "Hua Zhou",
        "Donglin Hao",
        "Yonghua Lin"
      ],
      "abstract": "Recently, both closed-source LLMs and open-source communities have made\nsignificant strides, outperforming humans in various general domains. However,\ntheir performance in specific professional fields such as medicine, especially\nwithin the open-source community, remains suboptimal due to the complexity of\nmedical knowledge. We propose Aquila-Med, a bilingual medical LLM based on\nAquila, addressing these challenges through continue pre-training, supervised\nfine-tuning (SFT), and reinforcement learning from human feedback (RLHF). We\nconstruct a large-scale Chinese and English medical dataset for continue\npre-training and a high-quality SFT dataset, covering extensive medical\nspecialties. Additionally, we develop a high-quality Direct Preference\nOptimization (DPO) dataset for further alignment. Aquila-Med achieves notable\nresults across single-turn, multi-turn dialogues, and medical multiple-choice\nquestions, demonstrating the effectiveness of our approach. We open-source the\ndatasets and the entire training process, contributing valuable resources to\nthe research community. Our models and datasets will released at\nhttps://huggingface.co/BAAI/AquilaMed-RL.",
      "tldr_zh": "该论文介绍了 Aqulia-Med LLM，这是一个开创性的全流程开源双语医疗语言模型（LLM），旨在解决开源社区在医疗领域的性能不足问题。研究团队通过 continue pre-training、supervised fine-tuning (SFT) 和 reinforcement learning from human feedback (RLHF) 等方法，对模型进行训练，并构建了大规模的中英医疗数据集、高质量 SFT 数据集以及 Direct Preference Optimization (DPO) 数据集。实验结果显示，Aqulia-Med 在单轮、多轮对话和医疗多选题上取得了显著成效。作者开源了数据集和整个训练过程，发布在 https://huggingface.co/BAAI/AquilaMed-RL，以推动医疗 AI 研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12182v1",
      "published_date": "2024-06-18 01:30:07 UTC",
      "updated_date": "2024-06-18 01:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:07:54.268033"
    },
    {
      "arxiv_id": "2406.12172v1",
      "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs' Ability to Reason About Search Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Nasim Borazjanizadeh",
        "Roei Herzig",
        "Trevor Darrell",
        "Rogerio Feris",
        "Leonid Karlinsky"
      ],
      "abstract": "Recently, Large Language Models (LLMs) attained impressive performance in\nmath and reasoning benchmarks. However, they still often struggle with logic\nproblems and puzzles that are relatively easy for humans. To further\ninvestigate this, we introduce a new benchmark, SearchBench, containing 11\nunique search problem types, each equipped with automated pipelines to generate\nan arbitrary number of instances and analyze the feasibility, correctness, and\noptimality of LLM-generated solutions. We show that even the most advanced LLMs\nfail to solve these problems end-to-end in text, e.g. GPT4 solves only 1.4%.\nSearchBench problems require considering multiple pathways to the solution as\nwell as backtracking, posing a significant challenge to auto-regressive models.\nInstructing LLMs to generate code that solves the problem helps, but only\nslightly, e.g., GPT4's performance rises to 11.7%. In this work, we show that\nin-context learning with A* algorithm implementations enhances performance. The\nfull potential of this promoting approach emerges when combined with our\nproposed Multi-Stage-Multi-Try method, which breaks down the algorithm\nimplementation into two stages and verifies the first stage against unit tests,\nraising GPT-4's performance above 57%.",
      "tldr_zh": "本研究引入了 SearchBench 基准，包含 11 种独特的搜索问题类型，并配备自动管道来评估大型语言模型(LLMs)生成解决方案的可行性、正确性和最优性。实验发现，现有 LLMs 如 GPT-4 在直接解决这些问题时表现极差，仅达到 1.4% 的成功率，而指导模型生成代码可稍稍提升至 11.7%。通过 in-context learning 与 A* 算法相结合，以及提出的 Multi-Stage-Multi-Try 方法，该框架将算法实现分解为多个阶段并进行单元测试验证，最终将 GPT-4 的性能提高至超过 57%，显著增强了 LLMs 在搜索问题上的推理能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12172v1",
      "published_date": "2024-06-18 00:44:58 UTC",
      "updated_date": "2024-06-18 00:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:08:06.044785"
    },
    {
      "arxiv_id": "2406.12168v4",
      "title": "BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Wenda Xu",
        "Jiachen Li",
        "William Yang Wang",
        "Lei Li"
      ],
      "abstract": "Direct alignment from preferences (DAP) has emerged as a promising paradigm\nfor aligning large language models (LLMs) to human desiderata from\npre-collected, offline preference datasets. While recent studies indicate that\nexisting offline DAP methods can directly benefit from online training samples,\nwe highlight the need to develop specific online DAP algorithms to fully\nharness the power of online training. Specifically, we identify that the\nlearned LLM should adhere to the proximity of the behavior LLM, which collects\nthe training samples. To this end, we propose online Preference Optimization in\nproximity to the Behavior LLM (BPO), emphasizing the importance of constructing\na proper trust region for LLM alignment.\n  We conduct extensive experiments to validate the effectiveness and\napplicability of our approach by integrating it with various DAP methods,\nresulting in significant performance improvements across a wide range of tasks\nwhen training with the same amount of preference data. Even when only\nintroducing one additional data collection phase, our online BPO improves its\noffline DAP baseline from 72.0% to 80.2% on TL;DR and from 82.2% to 89.1% on\nAnthropic Helpfulness in terms of win rate against human reference text.",
      "tldr_zh": "该研究探讨了直接从偏好数据中对齐大型语言模型（LLMs）的范式（DAP），强调开发特定在线DAP算法以充分利用在线训练数据。作者提出BPO（online Preference Optimization in proximity to the Behavior LLM）方法，通过构建信任区域（trust region）确保学习到的LLM与收集训练样本的行为LLM保持接近，从而改善在线对齐效果。实验结果显示，与各种DAP方法整合后，BPO在相同偏好数据下显著提升性能，例如在TL;DR任务上胜率从72.0%提高到80.2%，在Anthropic Helpfulness任务上从82.2%提高到89.1%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Wenda Xu and Jiachen Li contributed equally. Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12168v4",
      "published_date": "2024-06-18 00:41:40 UTC",
      "updated_date": "2024-10-21 18:00:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:08:17.660460"
    },
    {
      "arxiv_id": "2406.12164v2",
      "title": "A Mel Spectrogram Enhancement Paradigm Based on CWT in Speech Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Guoqiang Hu",
        "Huaning Tan",
        "Ruilai Li"
      ],
      "abstract": "Acoustic features play an important role in improving the quality of the\nsynthesised speech. Currently, the Mel spectrogram is a widely employed\nacoustic feature in most acoustic models. However, due to the fine-grained loss\ncaused by its Fourier transform process, the clarity of speech synthesised by\nMel spectrogram is compromised in mutant signals. In order to obtain a more\ndetailed Mel spectrogram, we propose a Mel spectrogram enhancement paradigm\nbased on the continuous wavelet transform (CWT). This paradigm introduces an\nadditional task: a more detailed wavelet spectrogram, which like the\npost-processing network takes as input the Mel spectrogram output by the\ndecoder. We choose Tacotron2 and Fastspeech2 for experimental validation in\norder to test autoregressive (AR) and non-autoregressive (NAR) speech systems,\nrespectively. The experimental results demonstrate that the speech synthesised\nusing the model with the Mel spectrogram enhancement paradigm exhibits higher\nMOS, with an improvement of 0.14 and 0.09 compared to the baseline model,\nrespectively. These findings provide some validation for the universality of\nthe enhancement paradigm, as they demonstrate the success of the paradigm in\ndifferent architectures.",
      "tldr_zh": "本研究针对语音合成中 Mel spectrogram 因 Fourier 变换导致的细粒度损失问题，提出了一种基于连续小波变换 (CWT) 的增强范式，以生成更详细的 wavelet spectrogram 作为后处理任务。范式将解码器输出的 Mel spectrogram 作为输入，旨在提升合成语音的清晰度。实验在 Tacotron2 (自回归 AR 系统) 和 FastSpeech2 (非自回归 NAR 系统) 上进行，结果显示增强模型的 MOS 分数分别比基线模型提高了 0.14 和 0.09。总之，该范式证明了其在不同架构中的通用性，为改善语音合成质量提供了有效方法。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by IALP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.12164v2",
      "published_date": "2024-06-18 00:34:44 UTC",
      "updated_date": "2024-07-09 18:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:08:30.597555"
    },
    {
      "arxiv_id": "2406.12163v1",
      "title": "Discussion Graph Semantics of First-Order Logic with Equality for Reasoning about Discussion and Argumentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ryuta Arisaka"
      ],
      "abstract": "We formulate discussion graph semantics of first-order logic with equality\nfor reasoning about discussion and argumentation as naturally as we would\nreason about sentences. While there are a few existing proposals to use a\nformal logic for reasoning about argumentation, they are constructed bottom-up\nand specialised to the argumentation model by Dung. There is indeed a\nconspicuous lack of a formal reasoning framework for handling general\ndiscussion and argumentation models. We achieve the generality through a\ntop-down formulation of the semantics of first-order logic (with equality)\nformulas, addressing the current shortage.",
      "tldr_zh": "本论文提出了一种讨论图语义（Discussion Graph Semantics）应用于一阶逻辑 with equality 的框架，旨在让用户像处理句子一样自然地推理讨论和论证问题。不同于现有的从下往上构建的专门化方法（如针对Dung的论证模型），该方法采用从上往下的语义制定策略，以实现更广泛的适用性。最终，这为处理一般讨论和论证模型提供了一个通用的正式推理框架，填补了当前领域的空白。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12163v1",
      "published_date": "2024-06-18 00:32:00 UTC",
      "updated_date": "2024-06-18 00:32:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:08:41.886936"
    },
    {
      "arxiv_id": "2406.12158v1",
      "title": "LLMs Are Prone to Fallacies in Causal Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Nitish Joshi",
        "Abulhair Saparov",
        "Yixin Wang",
        "He He"
      ],
      "abstract": "Recent work shows that causal facts can be effectively extracted from LLMs\nthrough prompting, facilitating the creation of causal graphs for causal\ninference tasks. However, it is unclear if this success is limited to\nexplicitly-mentioned causal facts in the pretraining data which the model can\nmemorize. Thus, this work investigates: Can LLMs infer causal relations from\nother relational data in text? To disentangle the role of memorized causal\nfacts vs inferred causal relations, we finetune LLMs on synthetic data\ncontaining temporal, spatial and counterfactual relations, and measure whether\nthe LLM can then infer causal relations. We find that: (a) LLMs are susceptible\nto inferring causal relations from the order of two entity mentions in text\n(e.g. X mentioned before Y implies X causes Y); (b) if the order is randomized,\nLLMs still suffer from the post hoc fallacy, i.e. X occurs before Y (temporal\nrelation) implies X causes Y. We also find that while LLMs can correctly deduce\nthe absence of causal relations from temporal and spatial relations, they have\ndifficulty inferring causal relations from counterfactuals, questioning their\nunderstanding of causality.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在因果推理中的易犯谬误，通过实验验证 LLMs 是否能从文本中的时间、空间和反事实关系推断因果关系，而非仅依赖记忆化的显式因果事实。研究者使用合成数据微调 LLMs，并测试其性能，结果显示 LLMs 倾向于从实体提及顺序推断因果（例如，X 在 Y 前出现即认为 X 导致 Y），并常犯 post hoc fallacy，即错误地将时间先后视为因果关系。总体而言，LLMs 虽能正确识别某些关系不存在因果，但难以从反事实中推断因果，这质疑了它们的因果理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12158v1",
      "published_date": "2024-06-18 00:14:07 UTC",
      "updated_date": "2024-06-18 00:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:08:55.787292"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 166,
  "processed_papers_count": 166,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T22:09:26.561466"
}