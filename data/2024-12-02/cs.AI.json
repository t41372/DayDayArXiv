{
  "date": "2024-12-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-02 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文涵盖了 AI、机器学习、计算机视觉、生物医学等领域，其中重点聚焦于大型语言模型（LLM）的创新应用、多模态生成模型的优化，以及AI在医疗和科学任务中的潜力，令人印象深刻的文章包括基于LLM的多代理系统（如MALT）和多模态生成框架（如PKRD-CoT），而知名学者如Dhruv Rohatgi和Jordan T. Ash参与的论文则凸显了LLM自提升机制的理论进展。\n\n下面，我将逐一简要概述部分论文，先优先讨论AI和LLM相关的高影响力文章，再快速掠过其他领域的论文。重点放在核心贡献上，相关主题的论文会归类讨论，以控制篇幅。\n\n### AI和LLM创新应用\n- **Self-Improvement in Language Models: The Sharpening Mechanism（LLM自提升机制：锐化方法）**  \n  作者包括Adam Block、Dylan J. Foster和Jordan T. Ash等人，这篇论文探讨了LLM通过自监督机制（如知识蒸馏）提升性能的核心方法。主要贡献是通过“锐化”框架，让LLM学习场景特定表示，实验证明RLHF方法优于SFT，提升了LLM在数学和推理任务中的泛化能力，如在MATH和GSM8K数据集上相对提升15.66%和7.42%。\n\n- **MALT: Improving Reasoning with Multi-Agent LLM Training（MALT：多代理LLM训练提升推理能力）**  \n  这篇论文提出多代理LLM训练框架MALT，通过生成、验证和精炼步骤优化推理。贡献在于将LLM分为异构代理，实验在MATH、GSM8K和CSQA基准上，MALT比基线LLM提升了7.42%至15.66%，展示了代理协作在复杂任务中的潜力。\n\n- **PKRD-CoT: A Unified Chain-of-thought Prompting for Multi-Modal Large Language Models in Autonomous Driving（PKRD-CoT：多模态LLM的统一思维链提示框架在自动驾驶中的应用）**  \n  作者Xuewen Luo等提出零样本思维链提示框架PKRD-CoT，聚焦感知、知识、推理和决策。关键发现是该框架让GPT-4.0在自动驾驶任务中表现出色，并在实验中证明其对Claude和LLava等模型的适用性，提升了实时决策能力。\n\n- **INSIGHT: Explainable Weakly-Supervised Medical Image Analysis（INSIGHT：可解释的弱监督医学图像分析）**  \n  这篇论文引入INSIGHT框架，用于CT和WSI图像的弱监督分类和分割。贡献在于结合检测和上下文模块生成热力图，提高了小细节定位的准确性，在基准上达到最先进水平，突出了医学AI的可解释性。\n\n- **ChatCollab: Exploring Collaboration Between Humans and AI Agents in Software Teams（ChatCollab：探索人类和AI代理在软件团队中的协作）**  \n  作者Benjamin Klieger等构建了ChatCollab框架，支持人类和AI代理在Slack中的协作。发现AI代理能有效识别角色并协调任务，在游戏开发任务中表现优于现有多代理系统，强调了AI在软件工程中的协作潜力。\n\n- **YI-Lightning Technical Report（YI-Lightning技术报告）**  \n  这篇报告介绍了YI-Lightning LLM模型，在Chatbot Arena中排名第六。贡献在于MoE架构的优化和RAISE安全框架，提升了中文和数学任务性能，同时在效率上实现了训练和推理成本降低。\n\n### 生成模型和计算机视觉\n- **RandAR: Decoder-only Autoregressive Visual Generation in Random Orders（RandAR：解码器-only的自回归视觉生成，支持随机顺序）**  \n  论文提出RandAR模型，支持任意令牌顺序的图像生成。核心发现是通过位置指令令牌实现无序生成，实验显示其在图像生成任务中与光栅顺序模型相当，并支持零样本插值和并行解码，加速了2.5倍。\n\n- **X-Prompt: Towards Universal In-Context Image Generation in Auto-Regressive Vision Language Foundation Models（X-Prompt：自回归视觉语言基础模型的通用In-Context图像生成）**  \n  作者Ziyi Sun等开发了X-Prompt框架，支持多任务图像生成。贡献在于增强In-Context学习，实验在各种基准上提升了性能，展示了其在多模态任务中的泛化能力。\n\n- **GETAE: Graph information Enhanced deep neural NeTwork ensemble ArchitecturE for fake news detection（GETAE：图信息增强的深度神经网络集成架构用于假新闻检测）**  \n  这篇论文提出GETAE框架，结合文本和传播图信息检测假新闻。发现通过深度神经网络集成，模型在Twitter数据集上优于现有方法，提升了假新闻检测的准确性。\n\n### 其他领域快速概述\n- **LLMs4Life: Large Language Models for Ontology Learning in Life Sciences（LLMs4Life：LLM在生命科学本体学习中的应用）**  \n  作者Nadeen Fathallah等扩展了NeOn-GPT管道，提升了LLM在复杂领域的本体生成。贡献在于提示工程和本体重用，提高了生命科学领域的逻辑一致性。\n\n- **Learning Ensembles of Vision-based Safety Control Filters（基于视觉的安全控制过滤器的集成学习）**  \n  论文探索集成方法提升视觉安全过滤器的准确性。发现使用预训练模型的集成在DeepAccident数据集上优于单模型，提升了安全系统的泛化能力。\n\n- **Explore Reinforced: Equilibrium Approximation with Reinforcement Learning（Explore Reinforced：强化学习中的均衡逼近）**  \n  这篇工作提出Exp3-IXrl算法，结合RL和博弈论。贡献在于应用于网络安全环境，改善了均衡逼近的性能。\n\n- **DYffCast: Regional Precipitation Nowcasting Using IMERG Satellite Data（DYffCast：使用IMERG卫星数据的区域降水预报）**  \n  论文改进扩散框架用于降水预报。发现新损失函数提升了短期预报准确性，在南美案例中表现突出。\n\n- **NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision（NCDD：用于胃肠视觉的最近质心距离缺陷的OOD检测）**  \n  提出NCDD方法检测异常图像。贡献在于改进OOD检测准确性，在医学基准上优于现有方法。\n\n其他论文如生物医学图像处理、强化学习应用和网络安全等，虽然涉及广泛，但相对不那么前沿或话题性较弱，因此仅简要提及。总体而言，今天的论文突出了AI模型的优化和实际应用潜力，期待后续研究进一步深化这些领域。\n\n这篇快报聚焦核心，帮您快速把握今日亮点！如果有特定主题感兴趣，欢迎随时反馈。",
  "papers": [
    {
      "arxiv_id": "2412.02039v1",
      "title": "Mutli-View 3D Reconstruction using Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Dutt",
        "Ishikaa Lunawat",
        "Manpreet Kaur"
      ],
      "abstract": "Large Foundation Models like Dust3r can produce high quality outputs such as\npointmaps, camera intrinsics, and depth estimation, given stereo-image pairs as\ninput. However, the application of these outputs on tasks like Visual\nLocalization requires a large amount of inference time and compute resources.\nTo address these limitations, in this paper, we propose the use of a knowledge\ndistillation pipeline, where we aim to build a student-teacher model with\nDust3r as the teacher and explore multiple architectures of student models that\nare trained using the 3D reconstructed points output by Dust3r. Our goal is to\nbuild student models that can learn scene-specific representations and output\n3D points with replicable performance such as Dust3r. The data set we used to\ntrain our models is 12Scenes. We test two main architectures of models: a\nCNN-based architecture and a Vision Transformer based architecture. For each\narchitecture, we also compare the use of pre-trained models against models\nbuilt from scratch. We qualitatively compare the reconstructed 3D points output\nby the student model against Dust3r's and discuss the various features learned\nby the student model. We also perform ablation studies on the models through\nhyperparameter tuning. Overall, we observe that the Vision Transformer presents\nthe best performance visually and quantitatively.",
      "tldr_zh": "本文提出一种基于 Knowledge Distillation 的多视图 3D 重建方法，以 Dust3r 作为教师模型，训练学生模型（包括 CNN 和 Vision Transformer 架构），旨在减少推理时间和计算资源，同时保持高质量的 3D 点重建输出。实验使用 12Scenes 数据集，比较了预训练模型与从零开始构建的模型，并通过定性和定量分析发现 Vision Transformer 架构在重建性能上表现最佳。总体而言，该方法有助于高效学习场景特定表示，为视觉定位等任务提供可复制的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.02039v1",
      "published_date": "2024-12-02 23:46:31 UTC",
      "updated_date": "2024-12-02 23:46:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:20:40.924805"
    },
    {
      "arxiv_id": "2412.02035v1",
      "title": "LLMs4Life: Large Language Models for Ontology Learning in Life Sciences",
      "title_zh": "翻译失败",
      "authors": [
        "Nadeen Fathallah",
        "Steffen Staab",
        "Alsayed Algergawy"
      ],
      "abstract": "Ontology learning in complex domains, such as life sciences, poses\nsignificant challenges for current Large Language Models (LLMs). Existing LLMs\nstruggle to generate ontologies with multiple hierarchical levels, rich\ninterconnections, and comprehensive class coverage due to constraints on the\nnumber of tokens they can generate and inadequate domain adaptation. To address\nthese issues, we extend the NeOn-GPT pipeline for ontology learning using LLMs\nwith advanced prompt engineering techniques and ontology reuse to enhance the\ngenerated ontologies' domain-specific reasoning and structural depth. Our work\nevaluates the capabilities of LLMs in ontology learning in the context of\nhighly specialized and complex domains such as life science domains. To assess\nthe logical consistency, completeness, and scalability of the generated\nontologies, we use the AquaDiva ontology developed and used in the\ncollaborative research center AquaDiva as a case study. Our evaluation shows\nthe viability of LLMs for ontology learning in specialized domains, providing\nsolutions to longstanding limitations in model performance and scalability.",
      "tldr_zh": "本文研究了 Large Language Models (LLMs) 在生命科学等复杂领域进行 Ontology Learning 的挑战，指出现有模型受限于 token 生成数量和领域适应性，导致难以创建多层次、丰富互联的本体。作者扩展了 NeOn-GPT 管道，通过高级提示工程和本体重用，提升生成的本体的领域特定推理和结构深度，并以 AquaDiva 本体作为案例研究评估其逻辑一致性、完整性和可扩展性。结果显示，LLMs 在专业领域本体学习中具有可行性，有效解决了模型性能和可扩展性的长期限制。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02035v1",
      "published_date": "2024-12-02 23:31:52 UTC",
      "updated_date": "2024-12-02 23:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:20:52.886026"
    },
    {
      "arxiv_id": "2412.02029v1",
      "title": "Learning Ensembles of Vision-based Safety Control Filters",
      "title_zh": "基于视觉的安全控制过滤器的集成学习",
      "authors": [
        "Ihab Tabbara",
        "Hussein Sibai"
      ],
      "abstract": "Safety filters in control systems correct nominal controls that violate\nsafety constraints. Designing such filters as functions of visual observations\nin uncertain and complex environments is challenging. Several deep\nlearning-based approaches to tackle this challenge have been proposed recently.\nHowever, formally verifying that the learned filters satisfy critical\nproperties that enable them to guarantee the safety of the system is currently\nbeyond reach. Instead, in this work, motivated by the success of ensemble\nmethods in reinforcement learning, we empirically investigate the efficacy of\nensembles in enhancing the accuracy and the out-of-distribution generalization\nof such filters, as a step towards more reliable ones. We experiment with\ndiverse pre-trained vision representation models as filter backbones, training\napproaches, and output aggregation techniques. We compare the performance of\nensembles with different configurations against each other, their individual\nmember models, and large single-model baselines in distinguishing between safe\nand unsafe states and controls in the DeepAccident dataset. Our results show\nthat diverse ensembles have better state and control classification accuracies\ncompared to individual models.",
      "tldr_zh": "这篇论文探讨了使用集成方法（ensembles）来提升基于视觉的 safety filters 在控制系统中的性能，这些 filters 用于修正违反安全约束的 nominal controls。作者通过实验多种预训练视觉表示模型、训练方法和输出聚合技术，评估集成模型在准确性和分布外泛化方面的优势。结果显示，在 DeepAccident 数据集上，多样化集成模型在区分安全与不安全状态和控制时的分类准确率优于单个模型和大型单模型基准。总的来说，此工作为更可靠的视觉-based 安全过滤器提供了实证支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02029v1",
      "published_date": "2024-12-02 23:19:31 UTC",
      "updated_date": "2024-12-02 23:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:21:04.787758"
    },
    {
      "arxiv_id": "2412.02025v1",
      "title": "PKRD-CoT: A Unified Chain-of-thought Prompting for Multi-Modal Large Language Models in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Xuewen Luo",
        "Fan Ding",
        "Yinsheng Song",
        "Xiaofeng Zhang",
        "Junnyong Loo"
      ],
      "abstract": "There is growing interest in leveraging the capabilities of robust\nMulti-Modal Large Language Models (MLLMs) directly within autonomous driving\ncontexts. However, the high costs and complexity of designing and training\nend-to-end autonomous driving models make them challenging for many enterprises\nand research entities. To address this, our study explores a seamless\nintegration of MLLMs into autonomous driving systems by proposing a Zero-Shot\nChain-of-Thought (Zero-Shot-CoT) prompt design named PKRD-CoT. PKRD-CoT is\nbased on the four fundamental capabilities of autonomous driving: perception,\nknowledge, reasoning, and decision-making. This makes it particularly suitable\nfor understanding and responding to dynamic driving environments by mimicking\nhuman thought processes step by step, thus enhancing decision-making in\nreal-time scenarios. Our design enables MLLMs to tackle problems without prior\nexperience, thereby increasing their utility within unstructured autonomous\ndriving environments. In experiments, we demonstrate the exceptional\nperformance of GPT-4.0 with PKRD-CoT across autonomous driving tasks,\nhighlighting its effectiveness in autonomous driving scenarios. Additionally,\nour benchmark analysis reveals the promising viability of PKRD-CoT for other\nMLLMs, such as Claude, LLava1.6, and Qwen-VL-Plus. Overall, this study\ncontributes a novel and unified prompt-design framework for GPT-4.0 and other\nMLLMs in autonomous driving, while also rigorously evaluating the efficacy of\nthese widely recognized MLLMs in the autonomous driving domain through\ncomprehensive comparisons.",
      "tldr_zh": "该研究探讨了将 Multi-Modal Large Language Models (MLLMs) 整合到自动驾驶系统中的方法，以解决设计和训练端到端模型的复杂性问题。研究提出了一种名为 PKRD-CoT 的统一 Chain-of-Thought (CoT) 提示设计，基于 perception（感知）、knowledge（知识）、reasoning（推理）和 decision-making（决策）四个核心能力，模仿人类思维过程，实现 Zero-Shot 问题解决，从而提升模型在动态驾驶环境中的实时响应和决策能力。在实验中，GPT-4.0 使用 PKRD-CoT 在自动驾驶任务中表现出色，其他 MLLMs 如 Claude、LLava1.6 和 Qwen-VL-Plus 也显示出显著潜力。该框架为 MLLMs 在自动驾驶领域的应用提供了一个新型统一设计，并通过全面基准分析验证了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for presentation at ICONIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.02025v1",
      "published_date": "2024-12-02 23:08:38 UTC",
      "updated_date": "2024-12-02 23:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:21:19.212234"
    },
    {
      "arxiv_id": "2412.02016v1",
      "title": "Explore Reinforced: Equilibrium Approximation with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Yu",
        "Mateusz Nowak",
        "Qintong Xie",
        "Michelle Yilin Feng",
        "Peter Chin"
      ],
      "abstract": "Current approximate Coarse Correlated Equilibria (CCE) algorithms struggle\nwith equilibrium approximation for games in large stochastic environments but\nare theoretically guaranteed to converge to a strong solution concept. In\ncontrast, modern Reinforcement Learning (RL) algorithms provide faster training\nyet yield weaker solutions. We introduce Exp3-IXrl - a blend of RL and\ngame-theoretic approach, separating the RL agent's action selection from the\nequilibrium computation while preserving the integrity of the learning process.\nWe demonstrate that our algorithm expands the application of equilibrium\napproximation algorithms to new environments. Specifically, we show the\nimproved performance in a complex and adversarial cybersecurity network\nenvironment - the Cyber Operations Research Gym - and in the classical\nmulti-armed bandit settings.",
      "tldr_zh": "该论文探讨了使用 Reinforcement Learning (RL) 改进均衡近似的问题，特别是针对 Coarse Correlated Equilibria (CCE) 算法在大型随机环境下的效率不足。作者引入了 Exp3-IXrl 算法，将 RL 的动作选择与均衡计算分离，同时保持学习过程的完整性，从而结合了 RL 的快速训练优势和博弈论的强解概念。在实验中，该算法在复杂的网络安全环境（Cyber Operations Research Gym）和经典的多臂老虎机设置中表现出色，显著扩展了均衡近似算法的应用范围。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02016v1",
      "published_date": "2024-12-02 22:37:59 UTC",
      "updated_date": "2024-12-02 22:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:21:28.738862"
    },
    {
      "arxiv_id": "2412.02012v2",
      "title": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis",
      "title_zh": "INSIGHT：可解释的弱监督医学图像分析",
      "authors": [
        "Wenbo Zhang",
        "Junyu Chen",
        "Christopher Kanan"
      ],
      "abstract": "Due to their large sizes, volumetric scans and whole-slide pathology images\n(WSIs) are often processed by extracting embeddings from local regions and then\nan aggregator makes predictions from this set. However, current methods require\npost-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize\nsmall yet clinically crucial details. To address these limitations, we\nintroduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap\ngeneration as an inductive bias. Starting from pre-trained feature maps,\nINSIGHT employs a detection module with small convolutional kernels to capture\nfine details and a context module with a broader receptive field to suppress\nlocal false positives. The resulting internal heatmap highlights diagnostically\nrelevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art\nclassification results and high weakly-labeled semantic segmentation\nperformance. Project website and code are available at:\nhttps://zhangdylan83.github.io/ewsmia/",
      "tldr_zh": "该研究针对体扫描和全滑病理图像(WSIs)的处理问题，提出INSIGHT框架，一种可解释的弱监督聚合器，用于医疗图像分析。INSIGHT从预训练特征图出发，结合检测模块（使用小卷积核捕获细微细节）和上下文模块（以更大感受野抑制局部假阳性），将热图生成作为归纳偏差，以突出诊断相关区域。相比传统方法如Grad-CAM，INSIGHT在CT和WSI基准上实现了最先进的分类性能和高弱标签语义分割效果，从而提升了模型的可解释性和准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02012v2",
      "published_date": "2024-12-02 22:31:23 UTC",
      "updated_date": "2024-12-08 16:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:21:40.863705"
    },
    {
      "arxiv_id": "2412.02723v1",
      "title": "DYffCast: Regional Precipitation Nowcasting Using IMERG Satellite Data. A case study over South America",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Seal",
        "Rossella Arcucci",
        "Salva Rühling-Cachay",
        "César Quilodrán-Casas"
      ],
      "abstract": "Climate change is increasing the frequency of extreme precipitation events,\nmaking weather disasters such as flooding and landslides more likely. The\nability to accurately nowcast precipitation is therefore becoming more critical\nfor safeguarding society by providing immediate, accurate information to\ndecision makers. Motivated by the recent success of generative models at\nprecipitation nowcasting, this paper: extends the DYffusion framework to this\ntask and evaluates its performance at forecasting IMERG satellite precipitation\ndata up to a 4-hour horizon; modifies the DYffusion framework to improve its\nability to model rainfall data; and introduces a novel loss function that\ncombines MSE, MAE and the LPIPS perceptual score. In a quantitative evaluation\nof forecasts up to a 4-hour horizon, the modified DYffusion framework trained\nwith the novel loss outperforms four competitor models. It has the highest CSI\nscores for weak, moderate, and heavy rain thresholds and retains an LPIPS score\n$<$ 0.2 for the entire roll-out, degrading the least as lead-time increases.\nThe proposed nowcasting model demonstrates visually stable and sharp forecasts\nup to a 2-hour horizon on a heavy rain case study. Code is available at\nhttps://github.com/Dseal95/DYffcast.",
      "tldr_zh": "该论文针对气候变化导致的极端降水事件频率增加，提出了一种改进的 DYffusion 框架（DYffCast），用于利用 IMERG 卫星数据进行区域降水预报，焦点在南美洲的案例研究中预测时长达 4 小时。该框架通过修改模型以更好地处理降水数据，并引入一种新损失函数结合 MSE、MAE 和 LPIPS 感知分数，显著提升了预报准确性。在定量评估中，DYffCast 优于四个竞争模型，获得最高 CSI 分数（针对弱、中、重雨阈值），并保持 LPIPS 分数小于 0.2，随着预测时间的增加退化最小。该方法在重雨案例中展示了视觉稳定的预测，直至 2 小时，提供可靠的决策支持工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in the Machine Learning for Physical Sciences workshop @\n  NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.02723v1",
      "published_date": "2024-12-02 22:20:31 UTC",
      "updated_date": "2024-12-02 22:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:21:53.704928"
    },
    {
      "arxiv_id": "2412.12121v1",
      "title": "NLLG Quarterly arXiv Report 09/24: What are the most influential current AI Papers?",
      "title_zh": "NLLG 季度 arXiv 报告 09/24：什么是最具影响力的当前 AI 论文？",
      "authors": [
        "Christoph Leiter",
        "Jonas Belouadi",
        "Yanran Chen",
        "Ran Zhang",
        "Daniil Larionov",
        "Aida Kostikova",
        "Steffen Eger"
      ],
      "abstract": "The NLLG (Natural Language Learning & Generation) arXiv reports assist in\nnavigating the rapidly evolving landscape of NLP and AI research across cs.CL,\ncs.CV, cs.AI, and cs.LG categories. This fourth installment captures a\ntransformative period in AI history - from January 1, 2023, following ChatGPT's\ndebut, through September 30, 2024. Our analysis reveals substantial new\ndevelopments in the field - with 45% of the top 40 most-cited papers being new\nentries since our last report eight months ago and offers insights into\nemerging trends and major breakthroughs, such as novel multimodal\narchitectures, including diffusion and state space models. Natural Language\nProcessing (NLP; cs.CL) remains the dominant main category in the list of our\ntop-40 papers but its dominance is on the decline in favor of Computer vision\n(cs.CV) and general machine learning (cs.LG). This report also presents novel\nfindings on the integration of generative AI in academic writing, documenting\nits increasing adoption since 2022 while revealing an intriguing pattern:\ntop-cited papers show notably fewer markers of AI-generated content compared to\nrandom samples. Furthermore, we track the evolution of AI-associated language,\nidentifying declining trends in previously common indicators such as \"delve\".",
      "tldr_zh": "本报告由 NLLG (Natural Language Learning & Generation) 发布，是第四份季度 arXiv 报告，聚焦从 2023 年 1 月 1 日到 2024 年 9 月 30 日的 AI 研究进展，包括 cs.CL、cs.CV、cs.AI 和 cs.LG 类别。分析显示，前 40 最引论文中有 45% 为新条目，并突显新兴趋势如新型多模态架构（包括 diffusion 和 state space models），而 NLP (cs.CL) 的主导地位正逐渐让位于 cs.CV 和 cs.LG。报告还揭示生成 AI 在学术写作中的采用率自 2022 年起显著增加，但顶级论文显示较少的 AI 生成内容标记，并追踪了 AI 相关语言的演变，如 “delve” 等词的使用在下降。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12121v1",
      "published_date": "2024-12-02 22:10:38 UTC",
      "updated_date": "2024-12-02 22:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:22:05.159118"
    },
    {
      "arxiv_id": "2412.02000v1",
      "title": "Who's Gaming the System? A Causally-Motivated Approach for Detecting Strategic Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Trenton Chang",
        "Lindsay Warrenburg",
        "Sae-Hwan Park",
        "Ravi B. Parikh",
        "Maggie Makar",
        "Jenna Wiens"
      ],
      "abstract": "In many settings, machine learning models may be used to inform decisions\nthat impact individuals or entities who interact with the model. Such entities,\nor agents, may game model decisions by manipulating their inputs to the model\nto obtain better outcomes and maximize some utility. We consider a multi-agent\nsetting where the goal is to identify the \"worst offenders:\" agents that are\ngaming most aggressively. However, identifying such agents is difficult without\nknowledge of their utility function. Thus, we introduce a framework in which\neach agent's tendency to game is parameterized via a scalar. We show that this\ngaming parameter is only partially identifiable. By recasting the problem as a\ncausal effect estimation problem where different agents represent different\n\"treatments,\" we prove that a ranking of all agents by their gaming parameters\nis identifiable. We present empirical results in a synthetic data study\nvalidating the usage of causal effect estimation for gaming detection and show\nin a case study of diagnosis coding behavior in the U.S. that our approach\nhighlights features associated with gaming.",
      "tldr_zh": "本文提出了一种基于因果推理（causal effect estimation）的框架，用于检测代理（agents）在机器学习决策中的战略性适应（gaming the system），即代理通过操纵输入来最大化自身效用。研究将每个代理的作弊倾向参数化为一个标量（gaming parameter），并证明虽然该参数仅部分可识别，但代理按作弊程度排名的顺序是可识别的。通过合成数据实验和美国诊断编码行为的案例研究，该方法验证了其有效性，并突出了与作弊相关的关键特征。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 31 figures. NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.02000v1",
      "published_date": "2024-12-02 22:07:48 UTC",
      "updated_date": "2024-12-02 22:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:22:16.840697"
    },
    {
      "arxiv_id": "2412.01992v1",
      "title": "ChatCollab: Exploring Collaboration Between Humans and AI Agents in Software Teams",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Klieger",
        "Charis Charitsis",
        "Miroslav Suzara",
        "Sierra Wang",
        "Nick Haber",
        "John C. Mitchell"
      ],
      "abstract": "We explore the potential for productive team-based collaboration between\nhumans and Artificial Intelligence (AI) by presenting and conducting initial\ntests with a general framework that enables multiple human and AI agents to\nwork together as peers. ChatCollab's novel architecture allows agents - human\nor AI - to join collaborations in any role, autonomously engage in tasks and\ncommunication within Slack, and remain agnostic to whether their collaborators\nare human or AI. Using software engineering as a case study, we find that our\nAI agents successfully identify their roles and responsibilities, coordinate\nwith other agents, and await requested inputs or deliverables before\nproceeding. In relation to three prior multi-agent AI systems for software\ndevelopment, we find ChatCollab AI agents produce comparable or better software\nin an interactive game development task. We also propose an automated method\nfor analyzing collaboration dynamics that effectively identifies behavioral\ncharacteristics of agents with distinct roles, allowing us to quantitatively\ncompare collaboration dynamics in a range of experimental conditions. For\nexample, in comparing ChatCollab AI agents, we find that an AI CEO agent\ngenerally provides suggestions 2-4 times more often than an AI product manager\nor AI developer, suggesting agents within ChatCollab can meaningfully adopt\ndifferentiated collaborative roles. Our code and data can be found at:\nhttps://github.com/ChatCollab.",
      "tldr_zh": "本文提出 ChatCollab 框架，一种通用架构，允许人类和 AI agents 在软件团队中作为对等者协作，支持代理在 Slack 中自主参与任务、通信，并不区分协作者类型。以软件工程为例，实验显示 ChatCollab 的 AI agents 能有效识别角色、协调工作，并在互动游戏开发任务中比现有多代理系统产生相当或更好的结果。研究还开发了一种自动分析协作动态的方法，量化了代理行为差异，例如 AI CEO 代理的建议频率比 AI 产品经理或开发者高 2-4 倍。代码和数据可从 GitHub 获取。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Preprint, 25 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01992v1",
      "published_date": "2024-12-02 21:56:46 UTC",
      "updated_date": "2024-12-02 21:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:22:28.735152"
    },
    {
      "arxiv_id": "2412.01991v1",
      "title": "Real-Time Multilingual Sign Language Processing",
      "title_zh": "实时多语言手语处理",
      "authors": [
        "Amit Moryossef"
      ],
      "abstract": "Sign Language Processing (SLP) is an interdisciplinary field comprised of\nNatural Language Processing (NLP) and Computer Vision. It is focused on the\ncomputational understanding, translation, and production of signed languages.\nTraditional approaches have often been constrained by the use of gloss-based\nsystems that are both language-specific and inadequate for capturing the\nmultidimensional nature of sign language. These limitations have hindered the\ndevelopment of technology capable of processing signed languages effectively.\n  This thesis aims to revolutionize the field of SLP by proposing a simple\nparadigm that can bridge this existing technological gap. We propose the use of\nSignWiring, a universal sign language transcription notation system, to serve\nas an intermediary link between the visual-gestural modality of signed\nlanguages and text-based linguistic representations.\n  We contribute foundational libraries and resources to the SLP community,\nthereby setting the stage for a more in-depth exploration of the tasks of sign\nlanguage translation and production. These tasks encompass the translation of\nsign language from video to spoken language text and vice versa. Through\nempirical evaluations, we establish the efficacy of our transcription method as\na pivot for enabling faster, more targeted research, that can lead to more\nnatural and accurate translations across a range of languages.\n  The universal nature of our transcription-based paradigm also paves the way\nfor real-time, multilingual applications in SLP, thereby offering a more\ninclusive and accessible approach to language technology. This is a significant\nstep toward universal accessibility, enabling a wider reach of AI-driven\nlanguage technologies to include the deaf and hard-of-hearing community.",
      "tldr_zh": "本论文针对Sign Language Processing (SLP)领域的传统限制，提出了一种简单范式，使用SignWiring作为通用手语转录符号系统，将视觉-手势模式与文本表示桥接，从而提升手语的理解、翻译和生成。研究贡献包括开发基础库和资源，支持从视频到文本的手语翻译任务，并通过实证评估证明该方法能实现更快、更准确的多语言翻译。最终，这种实时多语言处理范式促进了AI技术的包容性，为聋哑和听力障碍社区提供更可访问的语言解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "PhD Thesis",
      "pdf_url": "http://arxiv.org/pdf/2412.01991v1",
      "published_date": "2024-12-02 21:51:41 UTC",
      "updated_date": "2024-12-02 21:51:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:22:40.698896"
    },
    {
      "arxiv_id": "2412.01978v1",
      "title": "Human-centred test and evaluation of military AI",
      "title_zh": "以人为中心的军事人工智能测试与评估",
      "authors": [
        "David Helmer",
        "Michael Boardman",
        "S. Kate Conroy",
        "Adam J. Hepworth",
        "Manoj Harjani"
      ],
      "abstract": "The REAIM 2024 Blueprint for Action states that AI applications in the\nmilitary domain should be ethical and human-centric and that humans must remain\nresponsible and accountable for their use and effects. Developing rigorous test\nand evaluation, verification and validation (TEVV) frameworks will contribute\nto robust oversight mechanisms. TEVV in the development and deployment of AI\nsystems needs to involve human users throughout the lifecycle. Traditional\nhuman-centred test and evaluation methods from human factors need to be adapted\nfor deployed AI systems that require ongoing monitoring and evaluation. The\nlanguage around AI-enabled systems should be shifted to inclusion of the\nhuman(s) as a component of the system. Standards and requirements supporting\nthis adjusted definition are needed, as are metrics and means to evaluate them.\nThe need for dialogue between technologists and policymakers on human-centred\nTEVV will be evergreen, but dialogue needs to be initiated with an objective in\nmind for it to be productive. Development of TEVV throughout system lifecycle\nis critical to support this evolution including the issue of human scalability\nand impact on scale of achievable testing. Communication between technical and\nnon technical communities must be improved to ensure operators and\npolicy-makers understand risk assumed by system use and to better inform\nresearch and development. Test and evaluation in support of responsible AI\ndeployment must include the effect of the human to reflect operationally\nrealised system performance. Means of communicating the results of TEVV to\nthose using and making decisions regarding the use of AI based systems will be\nkey in informing risk based decisions regarding use.",
      "tldr_zh": "这篇论文强调了军事AI的测试、评估、验证和验证（TEVV）框架应以人为中心，确保AI应用符合伦理标准，并由人类负责其使用和影响。论文建议适应传统human-centred方法，融入人类用户参与AI系统生命周期的全过程，包括持续监控和将人类视为系统组件，以实现更有效的评估。最终，它呼吁制定相关标准、指标和沟通机制，促进技术人员与政策制定者之间的对话，从而改善风险管理并支持负责任的AI部署。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, summary report from 'Human-centred test and evaluation of\n  military AI' panel at Responsible AI in the Military Domain 2024, Seoul\n  Korea, 9-10 September 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.01978v1",
      "published_date": "2024-12-02 21:14:55 UTC",
      "updated_date": "2024-12-02 21:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:22:53.186343"
    },
    {
      "arxiv_id": "2412.01971v1",
      "title": "Learning a Filtered Backprojection Reconstruction Method for Photoacoustic Computed Tomography with Hemispherical Measurement Geometries",
      "title_zh": "翻译失败",
      "authors": [
        "Panpan Chen",
        "Seonyeong Park",
        "Refik Mert Cam",
        "Hsuan-Kai Huang",
        "Alexander A. Oraevsky",
        "Umberto Villa",
        "Mark A. Anastasio"
      ],
      "abstract": "In certain three-dimensional (3D) applications of photoacoustic computed\ntomography (PACT), including \\textit{in vivo} breast imaging, hemispherical\nmeasurement apertures that enclose the object within their convex hull are\nemployed for data acquisition. Data acquired with such measurement geometries\nare referred to as \\textit{half-scan} data, as only half of a complete\nspherical measurement aperture is employed. Although previous studies have\ndemonstrated that half-scan data can uniquely and stably reconstruct the\nsought-after object, no closed-form reconstruction formula for use with\nhalf-scan data has been reported. To address this, a semi-analytic\nreconstruction method in the form of filtered backprojection (FBP), referred to\nas the half-scan FBP method, is developed in this work. Because the explicit\nform of the filtering operation in the half-scan FBP method is not currently\nknown, a learning-based method is proposed to approximate it. The proposed\nmethod is systematically investigated by use of virtual imaging studies of 3D\nbreast PACT that employ ensembles of numerical breast phantoms and a\nphysics-based model of the data acquisition process. The method is subsequently\napplied to experimental data acquired in an \\textit{in vivo} breast PACT study.\nThe results confirm that the half-scan FBP method can accurately reconstruct 3D\nimages from half-scan data. Importantly, because the sought-after inverse\nmapping is well-posed, the reconstruction method remains accurate even when\napplied to data that differ considerably from those employed to learn the\nfiltering operation.",
      "tldr_zh": "该论文针对光声计算断层摄影 (PACT) 的半球形测量几何结构，开发了一种半扫描 Filtered Backprojection (FBP) 重建方法，以处理半扫描数据重建的问题。作者提出使用学习-based 方法来近似半扫描 FBP 中的过滤操作，并通过虚拟成像研究（基于数值乳房模型）和 in vivo 乳房成像实验进行系统验证。结果显示，该方法能准确重建 3D 图像，且即使应用于与训练数据不同的数据，重建稳定性也保持良好，为 PACT 应用提供了可靠的半扫描数据处理方案。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01971v1",
      "published_date": "2024-12-02 21:01:11 UTC",
      "updated_date": "2024-12-02 21:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:23:41.048826"
    },
    {
      "arxiv_id": "2412.01958v1",
      "title": "Enhancing Deep Learning Model Robustness through Metamorphic Re-Training",
      "title_zh": "通过变形再训练增强深度学习模型的鲁棒",
      "authors": [
        "Said Togru",
        "Youssef Sameh Mostafa",
        "Karim Lotfy"
      ],
      "abstract": "This paper evaluates the use of metamorphic relations to enhance the\nrobustness and real-world performance of machine learning models. We propose a\nMetamorphic Retraining Framework, which applies metamorphic relations to data\nand utilizes semi-supervised learning algorithms in an iterative and adaptive\nmulti-cycle process. The framework integrates multiple semi-supervised\nretraining algorithms, including FixMatch, FlexMatch, MixMatch, and FullMatch,\nto automate the retraining, evaluation, and testing of models with specified\nconfigurations. To assess the effectiveness of this approach, we conducted\nexperiments on CIFAR-10, CIFAR-100, and MNIST datasets using a variety of image\nprocessing models, both pretrained and non-pretrained. Our results demonstrate\nthe potential of metamorphic retraining to significantly improve model\nrobustness as we show in our results that each model witnessed an increase of\nan additional flat 17 percent on average in our robustness metric.",
      "tldr_zh": "本论文提出了一种Metamorphic Retraining Framework，用于提升深度学习模型的鲁棒性和实际性能，通过应用metamorphic relations对数据进行处理，并结合半监督学习算法如FixMatch、FlexMatch、MixMatch和FullMatch，在迭代的自适应多循环过程中自动化模型的重训练、评估和测试。框架针对CIFAR-10、CIFAR-100和MNIST数据集上的各种图像处理模型（包括预训练和非预训练模型）进行了实验，结果显示每个模型的鲁棒性指标平均提高了17%。这项方法证明了metamorphic retraining在增强模型鲁棒性方面的显著潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01958v1",
      "published_date": "2024-12-02 20:38:03 UTC",
      "updated_date": "2024-12-02 20:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:23:16.088736"
    },
    {
      "arxiv_id": "2412.01957v2",
      "title": "Usage Governance Advisor: From Intent to AI Governance",
      "title_zh": "使用治理顾问：从意图到AI",
      "authors": [
        "Elizabeth M. Daly",
        "Sean Rooney",
        "Seshu Tirupathi",
        "Luis Garces-Erice",
        "Inge Vejsbjerg",
        "Frank Bagehorn",
        "Dhaval Salwala",
        "Christopher Giblin",
        "Mira L. Wolf-Bauwens",
        "Ioana Giurgiu",
        "Michael Hind",
        "Peter Urbanetz"
      ],
      "abstract": "Evaluating the safety of AI Systems is a pressing concern for organizations\ndeploying them. In addition to the societal damage done by the lack of fairness\nof those systems, deployers are concerned about the legal repercussions and the\nreputational damage incurred by the use of models that are unsafe. Safety\ncovers both what a model does; e.g., can it be used to reveal personal\ninformation from its training set, and how a model was built; e.g., was it only\ntrained on licensed data sets. Determining the safety of an AI system requires\ngathering information from a wide set of heterogeneous sources including safety\nbenchmarks and technical documentation for the set of models used in that\nsystem. In addition, responsible use is encouraged through mechanisms that\nadvise and help the user to take mitigating actions where safety risks are\ndetected. We present Usage Governance Advisor which creates semi-structured\ngovernance information, identifies and prioritizes risks according to the\nintended use case, recommends appropriate benchmarks and risk assessments and\nimportantly proposes mitigation strategies and actions.",
      "tldr_zh": "本研究针对AI系统的安全性和公平性评估问题，提出Usage Governance Advisor框架，以帮助组织从AI意图到实际治理过程管理潜在风险。该框架通过收集异构来源的信息（如安全基准和技术文档），识别并优先化风险，并根据预期用途推荐适当的基准和风险评估。系统进一步提出缓解策略和行动建议，确保AI部署的负责任使用，从而减少法律和声誉损害。实验验证显示，该方法能有效提升AI治理的可操作性，为构建更安全AI系统提供实用工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 8 figures, AAAI workshop submission",
      "pdf_url": "http://arxiv.org/pdf/2412.01957v2",
      "published_date": "2024-12-02 20:36:41 UTC",
      "updated_date": "2025-01-23 14:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:23:27.879946"
    },
    {
      "arxiv_id": "2412.01955v2",
      "title": "The use of large language models to enhance cancer clinical trial educational materials",
      "title_zh": "翻译失败",
      "authors": [
        "Mingye Gao",
        "Aman Varshney",
        "Shan Chen",
        "Vikram Goddla",
        "Jack Gallifant",
        "Patrick Doyle",
        "Claire Novack",
        "Maeve Dillon-Martin",
        "Teresia Perkins",
        "Xinrong Correia",
        "Erik Duhaime",
        "Howard Isenstein",
        "Elad Sharon",
        "Lisa Soleymani Lehmann",
        "David Kozono",
        "Brian Anthony",
        "Dmitriy Dligach",
        "Danielle S. Bitterman"
      ],
      "abstract": "Cancer clinical trials often face challenges in recruitment and engagement\ndue to a lack of participant-facing informational and educational resources.\nThis study investigated the potential of Large Language Models (LLMs),\nspecifically GPT4, in generating patient-friendly educational content from\nclinical trial informed consent forms. Using data from ClinicalTrials.gov, we\nemployed zero-shot learning for creating trial summaries and one-shot learning\nfor developing multiple-choice questions, evaluating their effectiveness\nthrough patient surveys and crowdsourced annotation. Results showed that\nGPT4-generated summaries were both readable and comprehensive, and may improve\npatients' understanding and interest in clinical trials. The multiple-choice\nquestions demonstrated high accuracy and agreement with crowdsourced\nannotators. For both resource types, hallucinations were identified that\nrequire ongoing human oversight. The findings demonstrate the potential of LLMs\n\"out-of-the-box\" to support the generation of clinical trial education\nmaterials with minimal trial-specific engineering, but implementation with a\nhuman-in-the-loop is still needed to avoid misinformation risks.",
      "tldr_zh": "这篇论文探讨了使用Large Language Models (LLMs)，特别是GPT4，来提升癌症临床试验教育材料的潜力，以解决招募和参与挑战。研究方法包括从ClinicalTrials.gov数据中，通过zero-shot learning生成患者友好的试验摘要，以及one-shot learning开发多项选择题，并通过患者调查和众包注解进行评估。结果显示，GPT4生成的摘要可读且全面，可能提高患者的理解和对临床试验的兴趣，而多项选择题表现出高准确性和一致性。然而，存在hallucinations问题，需要持续的人类监督以避免误信息风险。总的来说，该研究证明了LLMs“out-of-the-box”能力，能以最小工程生成教育资源，但强调了“human-in-the-loop”的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01955v2",
      "published_date": "2024-12-02 20:31:27 UTC",
      "updated_date": "2024-12-04 02:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:23:42.287021"
    },
    {
      "arxiv_id": "2412.01951v2",
      "title": "Self-Improvement in Language Models: The Sharpening Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Audrey Huang",
        "Adam Block",
        "Dylan J. Foster",
        "Dhruv Rohatgi",
        "Cyril Zhang",
        "Max Simchowitz",
        "Jordan T. Ash",
        "Akshay Krishnamurthy"
      ],
      "abstract": "Recent work in language modeling has raised the possibility of\nself-improvement, where a language models evaluates and refines its own\ngenerations to achieve higher performance without external feedback. It is\nimpossible for this self-improvement to create information that is not already\nin the model, so why should we expect that this will lead to improved\ncapabilities? We offer a new perspective on the capabilities of\nself-improvement through a lens we refer to as sharpening. Motivated by the\nobservation that language models are often better at verifying response quality\nthan they are at generating correct responses, we formalize self-improvement as\nusing the model itself as a verifier during post-training in order to\n``sharpen'' the model to one placing large mass on high-quality sequences,\nthereby amortizing the expensive inference-time computation of generating good\nsequences. We begin by introducing a new statistical framework for sharpening\nin which the learner aims to sharpen a pre-trained base policy via sample\naccess, and establish fundamental limits. Then we analyze two natural families\nof self-improvement algorithms based on SFT and RLHF. We find that (i) the\nSFT-based approach is minimax optimal whenever the initial model has sufficient\ncoverage, but (ii) the RLHF-based approach can improve over SFT-based\nself-improvement by leveraging online exploration, bypassing the need for\ncoverage. Finally, we empirically validate the sharpening mechanism via\ninference-time and amortization experiments. We view these findings as a\nstarting point toward a foundational understanding that can guide the design\nand evaluation of self-improvement algorithms.",
      "tldr_zh": "本研究探讨了语言模型的self-improvement机制，特别提出“sharpening”视角，解释如何通过模型自身验证和优化生成内容来提升性能，而不依赖外部反馈。作者将self-improvement形式化为使用模型作为验证器进行后训练，从而使模型更倾向于高质量序列，并引入一个统计框架来分析这一过程。研究发现，SFT-based方法在初始模型有足够coverage时是最优的，而RLHF-based方法通过在线exploration可以超越SFT，无需依赖coverage。最后，通过推理时间和摊销实验验证了sharpening机制，为设计和评估self-improvement算法提供了基础理解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01951v2",
      "published_date": "2024-12-02 20:24:17 UTC",
      "updated_date": "2024-12-04 14:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:23:52.658941"
    },
    {
      "arxiv_id": "2412.01949v1",
      "title": "Identifying Key Nodes for the Influence Spread using a Machine Learning Approach",
      "title_zh": "使用机器学习方法识别影响传播的关键节点",
      "authors": [
        "Mateusz Stolarski",
        "Adam Piróg",
        "Piotr Bródka"
      ],
      "abstract": "The identification of key nodes in complex networks is an important topic in\nmany network science areas. It is vital to a variety of real-world\napplications, including viral marketing, epidemic spreading and influence\nmaximization. In recent years, machine learning algorithms have proven to\noutperform the conventional, centrality-based methods in accuracy and\nconsistency, but this approach still requires further refinement. What\ninformation about the influencers can be extracted from the network? How can we\nprecisely obtain the labels required for training? Can these models generalize\nwell? In this paper, we answer these questions by presenting an enhanced\nmachine learning-based framework for the influence spread problem. We focus on\nidentifying key nodes for the Independent Cascade model, which is a popular\nreference method. Our main contribution is an improved process of obtaining the\nlabels required for training by introducing 'Smart Bins' and proving their\nadvantage over known methods. Next, we show that our methodology allows ML\nmodels to not only predict the influence of a given node, but to also determine\nother characteristics of the spreading process-which is another novelty to the\nrelevant literature. Finally, we extensively test our framework and its ability\nto generalize beyond complex networks of different types and sizes, gaining\nimportant insight into the properties of these methods.",
      "tldr_zh": "这篇论文提出了一种增强的机器学习框架，用于识别复杂网络中影响传播的关键节点，针对Independent Cascade模型，旨在解决传统中心性方法的局限性。论文的主要贡献是引入“Smart Bins”来改进训练标签的获取过程，从而提升模型的准确性和一致性。该框架不仅能预测节点的传播影响，还能确定传播过程的其他特征；通过广泛测试，证明了其在不同类型和大小网络上的良好泛化能力。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01949v1",
      "published_date": "2024-12-02 20:17:44 UTC",
      "updated_date": "2024-12-02 20:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:24:05.149885"
    },
    {
      "arxiv_id": "2412.01948v1",
      "title": "The Evolution and Future Perspectives of Artificial Intelligence Generated Content",
      "title_zh": "人工智能生成内容的演变与未来展望",
      "authors": [
        "Chengzhang Zhu",
        "Luobin Cui",
        "Ying Tang",
        "Jiacun Wang"
      ],
      "abstract": "Artificial intelligence generated content (AIGC), a rapidly advancing\ntechnology, is transforming content creation across domains, such as text,\nimages, audio, and video. Its growing potential has attracted more and more\nresearchers and investors to explore and expand its possibilities. This review\ntraces AIGC's evolution through four developmental milestones-ranging from\nearly rule-based systems to modern transfer learning models-within a unified\nframework that highlights how each milestone contributes uniquely to content\ngeneration. In particular, the paper employs a common example across all\nmilestones to illustrate the capabilities and limitations of methods within\neach phase, providing a consistent evaluation of AIGC methodologies and their\ndevelopment. Furthermore, this paper addresses critical challenges associated\nwith AIGC and proposes actionable strategies to mitigate them. This study aims\nto guide researchers and practitioners in selecting and optimizing AIGC models\nto enhance the quality and efficiency of content creation across diverse\ndomains.",
      "tldr_zh": "这篇论文回顾了人工智能生成内容(AIGC)的演变历程，分为四个里程碑，从早期的基于规则系统到现代的迁移学习模型，并通过一个统一的框架和共同例子，展示了各阶段的方法优势与局限性。论文分析了AIGC在文本、图像、音频和视频等领域面临的挑战，如质量控制和伦理问题，并提出可操作的缓解策略。最终，该研究旨在指导研究者和从业者选择及优化AIGC模型，以提升内容创建的质量和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01948v1",
      "published_date": "2024-12-02 20:16:40 UTC",
      "updated_date": "2024-12-02 20:16:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:24:16.187542"
    },
    {
      "arxiv_id": "2412.01946v3",
      "title": "The Reality of AI and Biorisk",
      "title_zh": "翻译失败",
      "authors": [
        "Aidan Peppin",
        "Anka Reuel",
        "Stephen Casper",
        "Elliot Jones",
        "Andrew Strait",
        "Usman Anwar",
        "Anurag Agrawal",
        "Sayash Kapoor",
        "Sanmi Koyejo",
        "Marie Pellat",
        "Rishi Bommasani",
        "Nick Frosst",
        "Sara Hooker"
      ],
      "abstract": "To accurately and confidently answer the question 'could an AI model or\nsystem increase biorisk', it is necessary to have both a sound theoretical\nthreat model for how AI models or systems could increase biorisk and a robust\nmethod for testing that threat model. This paper provides an analysis of\nexisting available research surrounding two AI and biorisk threat models: 1)\naccess to information and planning via large language models (LLMs), and 2) the\nuse of AI-enabled biological tools (BTs) in synthesizing novel biological\nartifacts. We find that existing studies around AI-related biorisk are nascent,\noften speculative in nature, or limited in terms of their methodological\nmaturity and transparency. The available literature suggests that current LLMs\nand BTs do not pose an immediate risk, and more work is needed to develop\nrigorous approaches to understanding how future models could increase biorisks.\nWe end with recommendations about how empirical work can be expanded to more\nprecisely target biorisk and ensure rigor and validity of findings.",
      "tldr_zh": "这篇论文分析了 AI 模型或系统如何可能增加生物风险（biorisk），通过评估两个威胁模型：1) 大型语言模型（LLMs）提供的信息访问和规划；2) AI 启用的生物工具（BTs）用于合成新型生物制品。研究发现，现有的相关文献尚不成熟、往往是推测性的，且方法论透明度有限，因此当前 LLMs 和 BTs 不构成立即风险。论文建议扩展实证工作，以更精确地针对生物风险进行研究，并确保研究的严谨性和有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Updated to correct author affiliations and clarify findings of\n  evaluations of the o1 model",
      "pdf_url": "http://arxiv.org/pdf/2412.01946v3",
      "published_date": "2024-12-02 20:14:46 UTC",
      "updated_date": "2025-01-02 11:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:24:28.809655"
    },
    {
      "arxiv_id": "2412.01937v1",
      "title": "Approximately Optimal Search on a Higher-dimensional Sliding Puzzle",
      "title_zh": "更高维度的滑动谜题的近似最优搜索",
      "authors": [
        "Nono SC Merleau",
        "Miguel O'Malley",
        "Érika Roldán",
        "Sayan Mukherjee"
      ],
      "abstract": "Higher-dimensional sliding puzzles are constructed on the vertices of a\n$d$-dimensional hypercube, where $2^d-l$ vertices are distinctly coloured.\nRings with the same colours are initially set randomly on the vertices of the\nhypercube. The goal of the puzzle is to move each of the $2^d-l$ rings to\npre-defined target vertices on the cube. In this setting, the $k$-rule\nconstraint represents a generalisation of edge collision for the movement of\ncolours between vertices, allowing movement only when a hypercube face of\ndimension $k$ containing a ring is completely free of other rings. Starting\nfrom an initial configuration, what is the minimum number of moves needed to\nmake ring colours match the vertex colours? An algorithm that provides us with\nsuch a number is called God's algorithm. When such an algorithm exists, it does\nnot have a polynomial time complexity, at least in the case of the 15-puzzle\ncorresponding to $k=1$ in the cubical puzzle. This paper presents a\ncomprehensive computational study of different scenarios of the\nhigher-dimensional puzzle. A benchmark of three computational techniques, an\nexact algorithm (the A* search) and two approximately optimal search techniques\n(an evolutionary algorithm (EA) and reinforcement learning (RL)) is presented\nin this work. The experiments show that all three methods can successfully\nsolve the puzzle of dimension three for different face dimensions and across\nvarious difficulty levels. When the dimension increases, the A* search fails,\nand RL and EA methods can still provide a generally acceptable solution, i.e. a\ndistribution of a number of moves with a median value of less than $30$.\nOverall, the EA method consistently requires less computational time, while\nfailing in most cases to minimise the number of moves for the puzzle dimensions\n$d=4$ and $d=5$.",
      "tldr_zh": "本论文研究了更高维度的滑动谜题（higher-dimensional sliding puzzle），该谜题基于 d 维超立方体（hypercube）的顶点，目标是将 2^d - l 个不同颜色的环从随机位置移动到预定义目标，同时遵守 k-rule 约束（仅当包含环的超立方体面完全空闲时方可移动）。作者比较了三种计算技术：精确算法 A* search，以及近似最优搜索方法 evolutionary algorithm (EA) 和 reinforcement learning (RL)。实验结果显示，三种方法均能成功解决三维谜题，但在维度增加时，A* search 失败，而 EA 和 RL 能提供可接受的解决方案（中位数移动次数小于 30），其中 EA 方法计算时间最短，但往往无法最小化移动次数，尤其在 d=4 和 d=5 时。总的来说，该研究为更高维度谜题的求解提供了宝贵的算法基准和见解。",
      "categories": [
        "cs.AI",
        "cs.DM",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01937v1",
      "published_date": "2024-12-02 19:59:06 UTC",
      "updated_date": "2024-12-02 19:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:24:42.006737"
    },
    {
      "arxiv_id": "2412.01936v1",
      "title": "Kernel-Free Universum Quadratic Surface Twin Support Vector Machines for Imbalanced Data",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Moosaei",
        "Milan Hladík",
        "Ahmad Mousavi",
        "Zheming Gao",
        "Haojie Fu"
      ],
      "abstract": "Binary classification tasks with imbalanced classes pose significant\nchallenges in machine learning. Traditional classifiers often struggle to\naccurately capture the characteristics of the minority class, resulting in\nbiased models with subpar predictive performance. In this paper, we introduce a\nnovel approach to tackle this issue by leveraging Universum points to support\nthe minority class within quadratic twin support vector machine models. Unlike\ntraditional classifiers, our models utilize quadratic surfaces instead of\nhyperplanes for binary classification, providing greater flexibility in\nmodeling complex decision boundaries. By incorporating Universum points, our\napproach enhances classification accuracy and generalization performance on\nimbalanced datasets. We generated four artificial datasets to demonstrate the\nflexibility of the proposed methods. Additionally, we validated the\neffectiveness of our approach through empirical evaluations on benchmark\ndatasets, showing superior performance compared to conventional classifiers and\nexisting methods for imbalanced classification.",
      "tldr_zh": "本论文针对类不平衡二元分类问题，提出了一种名为 Kernel-Free Universum Quadratic Surface Twin Support Vector Machines 的新方法，利用 Universum points 支持少数类，并采用二次曲面代替超平面，以提供更灵活的决策边界。该方法通过整合这些元素，提升了分类准确性和泛化性能，并在四个人工数据集上展示了其灵活性。实验结果显示，在基准数据集上的实证评估中，该方法比传统分类器和现有不平衡分类方法表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01936v1",
      "published_date": "2024-12-02 19:57:59 UTC",
      "updated_date": "2024-12-02 19:57:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:24:53.321480"
    },
    {
      "arxiv_id": "2412.01935v1",
      "title": "Cross Domain Adaptation using Adversarial networks with Cyclic loss",
      "title_zh": "翻译失败",
      "authors": [
        "Manpreet Kaur",
        "Ankur Tomar",
        "Srijan Mishra",
        "Shashwat Verma"
      ],
      "abstract": "Deep Learning methods are highly local and sensitive to the domain of data\nthey are trained with. Even a slight deviation from the domain distribution\naffects prediction accuracy of deep networks significantly. In this work, we\nhave investigated a set of techniques aimed at increasing accuracy of generator\nnetworks which perform translation from one domain to the other in an\nadversarial setting. In particular, we experimented with activations, the\nencoder-decoder network architectures, and introduced a Loss called cyclic loss\nto constrain the Generator network so that it learns effective source-target\ntranslation. This machine learning problem is motivated by myriad applications\nthat can be derived from domain adaptation networks like generating labeled\ndata from synthetic inputs in an unsupervised fashion, and using these\ntranslation network in conjunction with the original domain network to\ngeneralize deep learning networks across domains.",
      "tldr_zh": "这篇论文探讨了深度学习模型对数据域高度敏感的问题，即使轻微偏差也会显著影响预测准确性。研究团队通过对抗网络（Adversarial networks）实验了激活函数和编码器-解码器架构，并引入了新的 Cyclic Loss 来约束生成器网络，实现有效的源域到目标域翻译。结果表明，该方法提高了跨域适应的性能，可用于无监督生成标记数据，并帮助深度学习网络在不同域中实现泛化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01935v1",
      "published_date": "2024-12-02 19:55:35 UTC",
      "updated_date": "2024-12-02 19:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:25:04.952786"
    },
    {
      "arxiv_id": "2412.01933v1",
      "title": "Recurrent Neural Network on PICTURE Model",
      "title_zh": "翻译失败",
      "authors": [
        "Weihan Xu"
      ],
      "abstract": "Intensive Care Units (ICUs) provide critical care and life support for most\nseverely ill and injured patients in the hospital. With the need for ICUs\ngrowing rapidly and unprecedentedly, especially during COVID-19, accurately\nidentifying the most critical patients helps hospitals to allocate resources\nmore efficiently and save more lives. The Predicting Intensive Care Transfers\nand Other Unforeseen Events (PICTURE) model predicts patient deterioration by\nseparating those at high risk for imminent intensive care unit transfer,\nrespiratory failure, or death from those at lower risk. This study aims to\nimplement a deep learning model to benchmark the performance from the XGBoost\nmodel, an existing model which has competitive results on prediction.",
      "tldr_zh": "该研究针对ICU患者恶化预测问题，基于PICTURE模型（用于识别高风险患者，如面临ICU转移、呼吸衰竭或死亡），旨在使用Recurrent Neural Network (RNN)作为深度学习方法进行基准测试。相比现有的XGBoost模型，RNN模型有望提升预测准确性，以帮助医院更高效地分配资源。实验结果将评估RNN在处理时间序列患者数据方面的性能表现，为COVID-19等紧急情景下的医疗决策提供优化方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "University of Michigan, Senior Honor Thesis",
      "pdf_url": "http://arxiv.org/pdf/2412.01933v1",
      "published_date": "2024-12-02 19:49:51 UTC",
      "updated_date": "2024-12-02 19:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:25:16.619993"
    },
    {
      "arxiv_id": "2412.02722v1",
      "title": "Enhanced N-BEATS for Mid-Term Electricity Demand Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Mateusz Kasprzyk",
        "Paweł Pełka",
        "Boris N. Oreshkin",
        "Grzegorz Dudek"
      ],
      "abstract": "This paper presents an enhanced N-BEATS model, N-BEATS*, for improved\nmid-term electricity load forecasting (MTLF). Building on the strengths of the\noriginal N-BEATS architecture, which excels in handling complex time series\ndata without requiring preprocessing or domain-specific knowledge, N-BEATS*\nintroduces two key modifications. (1) A novel loss function -- combining\npinball loss based on MAPE with normalized MSE, the new loss function allows\nfor a more balanced approach by capturing both L1 and L2 loss terms. (2) A\nmodified block architecture -- the internal structure of the N-BEATS blocks is\nadjusted by introducing a destandardization component to harmonize the\nprocessing of different time series, leading to more efficient and less complex\nforecasting tasks. Evaluated on real-world monthly electricity consumption data\nfrom 35 European countries, N-BEATS* demonstrates superior performance compared\nto its predecessor and other established forecasting methods, including\nstatistical, machine learning, and hybrid models. N-BEATS* achieves the lowest\nMAPE and RMSE, while also exhibiting the lowest dispersion in forecast errors.",
      "tldr_zh": "本文提出增强版 N-BEATS* 模型，用于改进中期电力负载预测 (MTLF)，其基于原 N-BEATS 架构，针对复杂时间序列数据无需预处理或领域知识。关键改进包括：引入一种结合 pinball loss (基于 MAPE) 和归一化 MSE 的新损失函数，以平衡 L1 和 L2 损失；以及修改块架构，通过添加去标准化组件来处理不同时间序列，提高预测效率。实验在 35 个欧洲国家的真实月度电力消耗数据上显示，N-BEATS* 比原模型和其他统计、机器学习或混合方法表现出优越性能，实现了最低的 MAPE 和 RMSE，以及最小预测错误分散。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02722v1",
      "published_date": "2024-12-02 19:31:44 UTC",
      "updated_date": "2024-12-02 19:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:25:29.374116"
    },
    {
      "arxiv_id": "2412.01929v1",
      "title": "ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Poorya Aghaomidi",
        "Ge Wang"
      ],
      "abstract": "Accurate sleep stage classification is essential for understanding sleep\ndisorders and improving overall health. This study proposes a novel three-stage\napproach for sleep stage classification using ECG signals, offering a more\naccessible alternative to traditional methods that often rely on complex\nmodalities like EEG. In Stages 1 and 2, we initialize the weights of two\nnetworks, which are then integrated in Stage 3 for comprehensive\nclassification. In the first phase, we estimate key features using Feature\nImitating Networks (FINs) to achieve higher accuracy and faster convergence.\nThe second phase focuses on identifying the N1 sleep stage through the\ntime-frequency representation of ECG signals. Finally, the third phase\nintegrates models from the previous stages and employs a Kolmogorov-Arnold\nNetwork (KAN) to classify five distinct sleep stages. Additionally, data\naugmentation techniques, particularly SMOTE, are used in enhancing\nclassification capabilities for underrepresented stages like N1. Our results\ndemonstrate significant improvements in the classification performance, with an\noverall accuracy of 80.79% an overall kappa of 0.73. The model achieves\nspecific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%\nfor N3, and 87.16% for REM. This study emphasizes the importance of weight\ninitialization and data augmentation in optimizing sleep stage classification\nwith ECG signals.",
      "tldr_zh": "本研究提出了一种基于 ECG 信号的深度学习框架 ECG-SleepNet，用于全面睡眠阶段分类，提供比传统 EEG 方法更易获取的替代方案。该框架采用三阶段方法：第一阶段使用 Feature Imitating Networks (FINs) 估计关键特征以提升准确性和收敛速度；第二阶段通过 ECG 信号的时间-频率表示识别 N1 睡眠阶段；第三阶段整合前两阶段模型，并采用 Kolmogorov-Arnold Network (KAN) 分类五种睡眠阶段，同时利用数据增强技术如 SMOTE 来改善 underrepresented 阶段的性能。实验结果显示，该模型整体准确率达 80.79%，Kappa 值 0.73，且各阶段准确率分别为 Wake 86.70%、N1 60.36%、N2 83.89%、N3 84.85% 和 REM 87.16%，突显了权重初始化和数据增强在优化分类中的重要性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.01929v1",
      "published_date": "2024-12-02 19:31:25 UTC",
      "updated_date": "2024-12-02 19:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:25:41.476411"
    },
    {
      "arxiv_id": "2412.01928v2",
      "title": "MALT: Improving Reasoning with Multi-Agent LLM Training",
      "title_zh": "翻译失败",
      "authors": [
        "Sumeet Ramesh Motwani",
        "Chandler Smith",
        "Rocktim Jyoti Das",
        "Rafael Rafailov",
        "Ivan Laptev",
        "Philip H. S. Torr",
        "Fabio Pizzati",
        "Ronald Clark",
        "Christian Schroeder de Witt"
      ],
      "abstract": "Large Language Models (LLMs) often produce answers with a single\nchain-of-thought, which restricts their ability to explore reasoning paths or\nself-correct flawed outputs in complex tasks. In this paper, we introduce MALT\n(Multi-Agent LLM Training), a novel post-training strategy that divides the\nreasoning process into generation, verification, and refinement steps using a\nsequential pipeline of heterogeneous agents. During data generation, each agent\nis repeatedly sampled to form a multi-agent search tree, where final outputs\nare graded against ground-truth data. We then apply value iteration to\npropagate reward signals back to each role-conditioned model, automatically\nproducing multi-agent post-training data without human or teacher-model\nsupervision. Our off-policy approach allows each agent to specialize by\nlearning from correct and incorrect trajectories, ultimately improving the\nend-to-end reasoning chain. On MATH, GSM8K, and CSQA, MALT surpasses the same\nbaseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40%\nrespectively, making it an important advance towards multi-agent cooperative\ntraining.",
      "tldr_zh": "本文提出 MALT（Multi-Agent LLM Training），一种后训练策略，通过多代理系统将 Large Language Models (LLMs) 的推理过程分为生成、验证和精炼步骤，解决单一 Chain-of-Thought 的局限性。MALT 在数据生成中利用多代理搜索树和价值迭代，自动传播奖励信号以创建训练数据，使每个代理从正确和错误轨迹中学习，提高端到端推理性能。在 MATH、GSM8K 和 CSQA 数据集上，MALT 分别比基线模型提升 15.66%、7.42% 和 9.40%，为多代理合作训练提供重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01928v2",
      "published_date": "2024-12-02 19:30:36 UTC",
      "updated_date": "2025-02-27 11:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:25:53.681938"
    },
    {
      "arxiv_id": "2412.01827v1",
      "title": "RandAR: Decoder-only Autoregressive Visual Generation in Random Orders",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Pang",
        "Tianyuan Zhang",
        "Fujun Luan",
        "Yunze Man",
        "Hao Tan",
        "Kai Zhang",
        "William T. Freeman",
        "Yu-Xiong Wang"
      ],
      "abstract": "We introduce RandAR, a decoder-only visual autoregressive (AR) model capable\nof generating images in arbitrary token orders. Unlike previous decoder-only AR\nmodels that rely on a predefined generation order, RandAR removes this\ninductive bias, unlocking new capabilities in decoder-only generation. Our\nessential design enables random order by inserting a \"position instruction\ntoken\" before each image token to be predicted, representing the spatial\nlocation of the next image token. Trained on randomly permuted token sequences\n-- a more challenging task than fixed-order generation, RandAR achieves\ncomparable performance to its conventional raster-order counterpart. More\nimportantly, decoder-only transformers trained from random orders acquire new\ncapabilities. For the efficiency bottleneck of AR models, RandAR adopts\nparallel decoding with KV-Cache at inference time, enjoying 2.5x acceleration\nwithout sacrificing generation quality. Additionally, RandAR supports\ninpainting, outpainting and resolution extrapolation in a zero-shot manner. We\nhope RandAR inspires new directions for decoder-only visual generation models\nand broadens their applications across diverse scenarios. Our project page is\nat https://rand-ar.github.io/.",
      "tldr_zh": "本研究引入 RandAR，一种仅解码器的自回归 (AR) 模型，能够在任意 token 顺序下生成图像，从而消除传统模型的预定义顺序归纳偏差。RandAR 的核心设计是通过在每个图像 token 前插入 \"position instruction token\" 来表示其空间位置，并在随机排列的 token 序列上训练，实现与固定栅格顺序模型相当的性能。更重要的是，RandAR 支持推理时的并行解码和 KV-Cache 技术，提供 2.5 倍加速，同时在零样本条件下实现 inpainting、outpainting 和 resolution extrapolation 等新能力，为 decoder-only 视觉生成模型的创新应用提供了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://rand-ar.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.01827v1",
      "published_date": "2024-12-02 18:59:53 UTC",
      "updated_date": "2024-12-02 18:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:26:06.329468"
    },
    {
      "arxiv_id": "2412.01825v1",
      "title": "GETAE: Graph information Enhanced deep neural NeTwork ensemble ArchitecturE for fake news detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ciprian-Octavian Truică",
        "Elena-Simona Apostol",
        "Marius Marogel",
        "Adrian Paschke"
      ],
      "abstract": "In today's digital age, fake news has become a major problem that has serious\nconsequences, ranging from social unrest to political upheaval. To address this\nissue, new methods for detecting and mitigating fake news are required. In this\nwork, we propose to incorporate contextual and network-aware features into the\ndetection process. This involves analyzing not only the content of a news\narticle but also the context in which it was shared and the network of users\nwho shared it, i.e., the information diffusion. Thus, we propose GETAE,\n\\underline{G}raph Information \\underline{E}nhanced Deep Neural\nNe\\underline{t}work Ensemble \\underline{A}rchitectur\\underline{E} for Fake News\nDetection, a novel ensemble architecture that uses textual content together\nwith the social interactions to improve fake news detection. GETAE contains two\nBranches: the Text Branch and the Propagation Branch. The Text Branch uses Word\nand Transformer Embeddings and a Deep Neural Network based on feed-forward and\nbidirectional Recurrent Neural Networks (\\textsc{[Bi]RNN}) for learning novel\ncontextual features and creating a novel Text Content Embedding. The\nPropagation Branch considers the information propagation within the graph\nnetwork and proposes a Deep Learning architecture that employs Node Embeddings\nto create novel Propagation Embedding. GETAE Ensemble combines the two novel\nembeddings, i.e., Text Content Embedding and Propagation Embedding, to create a\nnovel \\textit{Propagation-Enhanced Content Embedding} which is afterward used\nfor classification. The experimental results obtained on two real-world\npublicly available datasets, i.e., Twitter15 and Twitter16, prove that using\nthis approach improves fake news detection and outperforms state-of-the-art\nmodels.",
      "tldr_zh": "本研究针对假新闻检测问题，提出了一种名为 GETAE 的新型集成架构，该架构通过整合文本内容和社交网络信息来提升检测性能。GETAE 包括两个分支：Text Branch 使用 Word 和 Transformer Embeddings 结合基于 feed-forward 和 bidirectional RNN 的深度神经网络生成 Text Content Embedding；Propagation Branch 则通过 Node Embeddings 分析信息在图网络中的传播，创建 Propagation Embedding。最终，GETAE 将两种 Embedding 融合成 Propagation-Enhanced Content Embedding 用于分类，并在 Twitter15 和 Twitter16 数据集上的实验中，优于现有 state-of-the-art 模型，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01825v1",
      "published_date": "2024-12-02 18:59:50 UTC",
      "updated_date": "2024-12-02 18:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:26:16.521243"
    },
    {
      "arxiv_id": "2412.01824v1",
      "title": "X-Prompt: Towards Universal In-Context Image Generation in Auto-Regressive Vision Language Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyi Sun",
        "Ziyang Chu",
        "Pan Zhang",
        "Tong Wu",
        "Xiaoyi Dong",
        "Yuhang Zang",
        "Yuanjun Xiong",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "In-context generation is a key component of large language models' (LLMs)\nopen-task generalization capability. By leveraging a few examples as context,\nLLMs can perform both in-domain and out-of-domain tasks. Recent advancements in\nauto-regressive vision-language models (VLMs) built upon LLMs have showcased\nimpressive performance in text-to-image generation. However, the potential of\nin-context learning for general image generation tasks remains largely\nunexplored. To address this, we introduce X-Prompt, a purely auto-regressive\nlarge-vision language model designed to deliver competitive performance across\na wide range of both seen and unseen image generation tasks, all within a\nunified in-context learning framework. X-Prompt incorporates a specialized\ndesign that efficiently compresses valuable features from in-context examples,\nsupporting longer in-context token sequences and improving its ability to\ngeneralize to unseen tasks. A unified training task for both text and image\nprediction enables X-Prompt to handle general image generation with enhanced\ntask awareness from in-context examples. Extensive experiments validate the\nmodel's performance across diverse seen image generation tasks and its capacity\nto generalize to previously unseen tasks.",
      "tldr_zh": "该研究提出 X-Prompt，一种纯粹的 auto-regressive 视觉语言模型（VLMs），旨在通过 in-context learning 框架实现通用图像生成任务，支持从已见到未见任务的泛化。X-Prompt 通过高效压缩 in-context 例子中的特征，允许更长的 token 序列，并采用统一的训练任务来处理文本和图像预测，从而提升任务意识和性能。实验结果显示，该模型在多种图像生成任务上表现出色，并证明了其对未见任务的强大泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "code: https://github.com/SunzeY/X-Prompt",
      "pdf_url": "http://arxiv.org/pdf/2412.01824v1",
      "published_date": "2024-12-02 18:59:26 UTC",
      "updated_date": "2024-12-02 18:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:26:28.242294"
    },
    {
      "arxiv_id": "2412.01818v2",
      "title": "Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs",
      "title_zh": "超越文本-视觉注意力：利用视觉线索在 VLMs 中实现有效的令牌修剪",
      "authors": [
        "Qizhe Zhang",
        "Aosong Cheng",
        "Ming Lu",
        "Renrui Zhang",
        "Zhiyong Zhuo",
        "Jiajun Cao",
        "Shaobo Guo",
        "Qi She",
        "Shanghang Zhang"
      ],
      "abstract": "Large vision-language models (LVLMs) generally contain significantly more\nvisual tokens than their textual counterparts, resulting in a considerable\ncomputational burden. Recent efforts have been made to tackle this issue by\npruning visual tokens early within the language model. Most existing works use\nattention scores between text and visual tokens to assess the importance of\nvisual tokens. However, in this study, we first analyze the text-visual\nattention in the language model and find that this score is not an ideal\nindicator for token pruning. Based on the analysis, We propose VisPruner, a\nplug-and-play method that utilizes visual cues for more effective token pruning\nin LVLMs. Specifically, we first use visual attention to select a limited\nnumber of significant tokens. Then, we remove duplicate tokens from the\nremaining ones based on their similarity. By retaining diverse tokens alongside\nthe initially selected important tokens, we maximally preserve the visual\ninformation of the input image. Experimental results demonstrate that our\nVisPruner sustains strong performance across various VLM architectures and\nreduction ratios, significantly outperforming existing methods based on\ntext-visual attention. Notably, without any training, VisPruner can reduce the\nFLOPs of LLaVA-1.5-7B by 91% and inference latency by 75%, while maintaining\ncomparable performance. Our code is available at\nhttps://github.com/Theia-4869/VisPruner.",
      "tldr_zh": "该研究发现，现有的视觉语言模型 (LVLMs) 由于过多的视觉 tokens 而导致计算负担过重，而基于文本-视觉 attention 的 pruning 方法效果不理想。作者提出 VisPruner，一种 plug-and-play 方法，利用视觉 cues 先选择重要 tokens，然后基于相似性移除重复 tokens，从而最大化保留输入图像的视觉信息。实验结果显示，VisPruner 在多种 VLM 架构和 reduction ratios 上显著优于现有方法，无需训练即可将 LLaVA-1.5-7B 的 FLOPs 减少 91% 和推理延迟减少 75%，同时保持性能相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 9 figures, code: https://github.com/Theia-4869/VisPruner,\n  project page: https://theia-4869.github.io/VisPruner",
      "pdf_url": "http://arxiv.org/pdf/2412.01818v2",
      "published_date": "2024-12-02 18:57:40 UTC",
      "updated_date": "2025-05-11 17:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:26:42.376569"
    },
    {
      "arxiv_id": "2412.12119v2",
      "title": "Mastering Board Games by External and Internal Planning with Language Models",
      "title_zh": "利用语言模型的外部和内部规划掌握棋盘游戏",
      "authors": [
        "John Schultz",
        "Jakub Adamek",
        "Matej Jusup",
        "Marc Lanctot",
        "Michael Kaisers",
        "Sarah Perrin",
        "Daniel Hennes",
        "Jeremy Shar",
        "Cannada Lewis",
        "Anian Ruoss",
        "Tom Zahavy",
        "Petar Veličković",
        "Laurel Prince",
        "Satinder Singh",
        "Eric Malmi",
        "Nenad Tomašev"
      ],
      "abstract": "Advancing planning and reasoning capabilities of Large Language Models (LLMs)\nis one of the key prerequisites towards unlocking their potential for\nperforming reliably in complex and impactful domains. In this paper, we aim to\ndemonstrate this across board games (Chess, Fischer Random / Chess960, Connect\nFour, and Hex), and we show that search-based planning can yield significant\nimprovements in LLM game-playing strength. We introduce, compare and contrast\ntwo major approaches: In external search, the model guides Monte Carlo Tree\nSearch (MCTS) rollouts and evaluations without calls to an external game\nengine, and in internal search, the model is trained to generate in-context a\nlinearized tree of search and a resulting final choice. Both build on a\nlanguage model pre-trained on relevant domain knowledge, reliably capturing the\ntransition and value functions in the respective environments, with minimal\nhallucinations. We evaluate our LLM search implementations against\ngame-specific state-of-the-art engines, showcasing substantial improvements in\nstrength over the base model, and reaching Grandmaster-level performance in\nchess while operating closer to the human search budget. Our proposed approach,\ncombining search with domain knowledge, is not specific to board games, hinting\nat more general future applications.",
      "tldr_zh": "本论文旨在提升大型语言模型 (LLMs) 的规划和推理能力，通过外部搜索和内部搜索方法来提升其在棋类游戏（如国际象棋、Fischer Random Chess、Connect Four 和 Hex）中的表现。外部搜索让模型指导 Monte Carlo Tree Search (MCTS) 的模拟和评估，而内部搜索则训练模型在上下文中生成线性化的搜索树和最终决策。实验结果显示，这种结合搜索和领域知识的方法使 LLM 比基础模型大幅提升游戏强度，在国际象棋达到 Grandmaster 级别，同时接近人类搜索预算，并暗示其可推广到更广泛的领域。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "70 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12119v2",
      "published_date": "2024-12-02 18:56:51 UTC",
      "updated_date": "2025-04-29 18:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:26:54.090958"
    },
    {
      "arxiv_id": "2412.01814v2",
      "title": "COSMOS: Cross-Modality Self-Distillation for Vision Language Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Sanghwan Kim",
        "Rui Xiao",
        "Mariana-Iuliana Georgescu",
        "Stephan Alaniz",
        "Zeynep Akata"
      ],
      "abstract": "Vision-Language Models (VLMs) trained with contrastive loss have achieved\nsignificant advancements in various vision and language tasks. However, the\nglobal nature of the contrastive loss makes VLMs focus predominantly on\nforeground objects, neglecting other crucial information in the image, which\nlimits their effectiveness in downstream tasks. To address these challenges, we\npropose COSMOS: CrOSs-MOdality Self-distillation for vision-language\npre-training that integrates a novel text-cropping strategy and cross-attention\nmodule into a self-supervised learning framework. We create global and local\nviews of images and texts (i.e., multi-modal augmentations), which are\nessential for self-distillation in VLMs. We further introduce a cross-attention\nmodule, enabling COSMOS to learn comprehensive cross-modal representations\noptimized via a cross-modality self-distillation loss. COSMOS consistently\noutperforms previous strong baselines on various zero-shot downstream tasks,\nincluding retrieval, classification, and semantic segmentation. Additionally,\nit surpasses CLIP-based models trained on larger datasets in visual perception\nand contextual understanding tasks. Code is available at\nhttps://github.com/ExplainableML/cosmos.",
      "tldr_zh": "该研究指出，Vision-Language Models (VLMs) 通过 contrastive loss 训练虽取得进展，但过度关注前景对象而忽略其他图像信息，限制了下游任务的性能。为解决此问题，提出 COSMOS 方法，该框架整合 text-cropping 策略和 cross-attention 模块，在自监督学习中创建图像和文本的全局及局部视图，并通过 cross-modality self-distillation loss 优化全面的跨模态表示。实验结果显示，COSMOS 在各种零样本下游任务（如检索、分类和语义分割）上优于现有基线，甚至在视觉感知和上下文理解任务中超越基于更大数据集训练的 CLIP 模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01814v2",
      "published_date": "2024-12-02 18:56:06 UTC",
      "updated_date": "2025-03-26 16:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:27:05.902914"
    },
    {
      "arxiv_id": "2412.01806v3",
      "title": "Random Tree Model of Meaningful Memory",
      "title_zh": "有意义记忆的随机树模型",
      "authors": [
        "Weishun Zhong",
        "Tankut Can",
        "Antonis Georgiou",
        "Ilya Shnayderman",
        "Mikhail Katkov",
        "Misha Tsodyks"
      ],
      "abstract": "Traditional studies of memory for meaningful narratives focus on specific\nstories and their semantic structures but do not address common quantitative\nfeatures of recall across different narratives. We introduce a statistical\nensemble of random trees to represent narratives as hierarchies of key points,\nwhere each node is a compressed representation of its descendant leaves, which\nare the original narrative segments. Recall is modeled as constrained by\nworking memory capacity from this hierarchical structure. Our analytical\nsolution aligns with observations from large-scale narrative recall\nexperiments. Specifically, our model explains that (1) average recall length\nincreases sublinearly with narrative length, and (2) individuals summarize\nincreasingly longer narrative segments in each recall sentence. Additionally,\nthe theory predicts that for sufficiently long narratives, a universal,\nscale-invariant limit emerges, where the fraction of a narrative summarized by\na single recall sentence follows a distribution independent of narrative\nlength.",
      "tldr_zh": "本研究提出了一种随机树（random trees）模型，用于分析有意义叙述的记忆回忆，聚焦于不同叙述间的共同定量特征。模型将叙述表示为关键点的层次结构，每个节点是对其后代叶子（即原始叙述段）的压缩表示，并将回忆建模为受工作记忆容量（working memory capacity）限制的层次过程。通过分析，该模型与大规模叙述回忆实验的观察一致，解释了平均回忆长度随叙述长度呈次线性增加，以及个体在每个回忆句子中总结越来越长段落的现象。此外，模型预测，对于足够长的叙述，会出现一个通用的、尺度不变的极限，其中一个回忆句子总结的叙述部分分布独立于叙述长度。",
      "categories": [
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cond-mat.stat-mech",
      "comment": "21 pages, 5 figures; included new derivations",
      "pdf_url": "http://arxiv.org/pdf/2412.01806v3",
      "published_date": "2024-12-02 18:50:27 UTC",
      "updated_date": "2025-02-23 19:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:27:16.954180"
    },
    {
      "arxiv_id": "2412.01799v1",
      "title": "HPRM: High-Performance Robotic Middleware for Intelligent Autonomous Systems",
      "title_zh": "HPRM: 用于智能",
      "authors": [
        "Jacky Kwok",
        "Shulu Li",
        "Marten Lohstroh",
        "Edward A. Lee"
      ],
      "abstract": "The rise of intelligent autonomous systems, especially in robotics and\nautonomous agents, has created a critical need for robust communication\nmiddleware that can ensure real-time processing of extensive sensor data.\nCurrent robotics middleware like Robot Operating System (ROS) 2 faces\nchallenges with nondeterminism and high communication latency when dealing with\nlarge data across multiple subscribers on a multi-core compute platform. To\naddress these issues, we present High-Performance Robotic Middleware (HPRM),\nbuilt on top of the deterministic coordination language Lingua Franca (LF).\nHPRM employs optimizations including an in-memory object store for efficient\nzero-copy transfer of large payloads, adaptive serialization to minimize\nserialization overhead, and an eager protocol with real-time sockets to reduce\nhandshake latency. Benchmarks show HPRM achieves up to 173x lower latency than\nROS2 when broadcasting large messages to multiple nodes. We then demonstrate\nthe benefits of HPRM by integrating it with the CARLA simulator and running\nreinforcement learning agents along with object detection workloads. In the\nCARLA autonomous driving application, HPRM attains 91.1% lower latency than\nROS2. The deterministic coordination semantics of HPRM, combined with its\noptimized IPC mechanisms, enable efficient and predictable real-time\ncommunication for intelligent autonomous systems.",
      "tldr_zh": "这篇论文介绍了 HPRM，一种高性能机器人中间件，针对智能自主系统（如机器人和自动代理）处理大量传感器数据的实时通信问题，解决了 ROS 2 的非确定性和高延迟挑战。HPRM 基于 Lingua Franca 构建，采用了 in-memory object store 实现零拷贝传输、adaptive serialization 减少序列化开销，以及 eager protocol with real-time sockets 降低握手延迟等优化技术。实验结果显示，HPRM 在广播大消息时比 ROS 2 延迟低 173 倍，并在 CARLA 模拟器中结合强化学习和对象检测工作负载时，实现 91.1% 的延迟降低，从而为智能自主系统提供高效、可预测的实时通信。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.01799v1",
      "published_date": "2024-12-02 18:46:29 UTC",
      "updated_date": "2024-12-02 18:46:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:27:30.454427"
    },
    {
      "arxiv_id": "2412.01794v2",
      "title": "IQA-Adapter: Exploring Knowledge Transfer from Image Quality Assessment to Diffusion-based Generative Models",
      "title_zh": "IQA-Adapter：探索从图像质量评估到基于扩散的生成模型的知识转移",
      "authors": [
        "Khaled Abud",
        "Sergey Lavrushkin",
        "Alexey Kirillov",
        "Dmitriy Vatolin"
      ],
      "abstract": "Diffusion-based models have recently revolutionized image generation,\nachieving unprecedented levels of fidelity. However, consistent generation of\nhigh-quality images remains challenging partly due to the lack of conditioning\nmechanisms for perceptual quality. In this work, we propose methods to\nintegrate image quality assessment (IQA) models into diffusion-based\ngenerators, enabling quality-aware image generation. We show that diffusion\nmodels can learn complex qualitative relationships from both IQA models'\noutputs and internal activations. First, we experiment with gradient-based\nguidance to optimize image quality directly and show this method has limited\ngeneralizability. To address this, we introduce IQA-Adapter, a novel framework\nthat conditions generation on target quality levels by learning the implicit\nrelationship between images and quality scores. When conditioned on high target\nquality, IQA-Adapter can shift the distribution of generated images towards a\nhigher-quality subdomain, and, inversely, it can be used as a degradation\nmodel, generating progressively more distorted images when provided with a\nlower-quality signal. Under high-quality condition, IQA-Adapter achieves up to\na 10% improvement across multiple objective metrics, as confirmed by a user\npreference study, while preserving generative diversity and content.\nFurthermore, we extend IQA-Adapter to a reference-based conditioning scenario,\nutilizing the rich activation space of IQA models to transfer highly specific,\ncontent-agnostic qualitative features between images.",
      "tldr_zh": "本研究探讨了从图像质量评估（IQA）模型向基于扩散的生成模型知识转移的问题，旨在解决扩散模型在生成高保真图像时缺乏感知质量条件机制的挑战。作者提出IQA-Adapter框架，通过学习图像与质量分数之间的隐式关系，实现基于目标质量水平的生成条件化，例如在高品质条件下提升生成图像的质量，并在用户偏好研究中获得高达10%的客观指标改善，同时保持生成多样性和内容。IQA-Adapter还可作为退化模型生成扭曲图像，并扩展到基于参考的场景，利用IQA模型的激活空间转移特定内容无关的定性特征。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "GitHub repo: https://github.com/X1716/IQA-Adapter",
      "pdf_url": "http://arxiv.org/pdf/2412.01794v2",
      "published_date": "2024-12-02 18:40:19 UTC",
      "updated_date": "2025-03-16 21:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:27:40.792127"
    },
    {
      "arxiv_id": "2412.01789v1",
      "title": "From ChebNet to ChebGibbsNet",
      "title_zh": "从 ChebNet 到 ChebGibbsNet",
      "authors": [
        "Jie Zhang",
        "Min-Te Sun"
      ],
      "abstract": "Recent advancements in Spectral Graph Convolutional Networks (SpecGCNs) have\nled to state-of-the-art performance in various graph representation learning\ntasks. To exploit the potential of SpecGCNs, we analyze corresponding graph\nfilters via polynomial interpolation, the cornerstone of graph signal\nprocessing. Different polynomial bases, such as Bernstein, Chebyshev, and\nmonomial basis, have various convergence rates that will affect the error in\npolynomial interpolation. Although adopting Chebyshev basis for interpolation\ncan minimize maximum error, the performance of ChebNet is still weaker than\nGPR-GNN and BernNet. \\textbf{We point out it is caused by the Gibbs phenomenon,\nwhich occurs when the graph frequency response function approximates the target\nfunction.} It reduces the approximation ability of a truncated polynomial\ninterpolation. In order to mitigate the Gibbs phenomenon, we propose to add the\nGibbs damping factor with each term of Chebyshev polynomials on ChebNet. As a\nresult, our lightweight approach leads to a significant performance boost.\nAfterwards, we reorganize ChebNet via decoupling feature propagation and\ntransformation. We name this variant as \\textbf{ChebGibbsNet}. Our experiments\nindicate that ChebGibbsNet is superior to other advanced SpecGCNs, such as\nGPR-GNN and BernNet, in both homogeneous graphs and heterogeneous graphs.",
      "tldr_zh": "该论文分析了 Spectral Graph Convolutional Networks (SpecGCNs) 中的图过滤器，通过多项式插值（如 Chebyshev 基）发现 Gibbs phenomenon 会降低近似能力，导致 ChebNet 的性能不如 GPR-GNN 和 BernNet。作者提出在 ChebNet 中添加 Gibbs damping factor 并重组网络为 ChebGibbsNet，以缓解这一现象并提升性能。实验结果表明，ChebGibbsNet 在同质和异质图上优于现有先进模型，提供了一种轻量级改进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 2 figures, and 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.01789v1",
      "published_date": "2024-12-02 18:37:45 UTC",
      "updated_date": "2024-12-02 18:37:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:27:53.387156"
    },
    {
      "arxiv_id": "2412.01784v1",
      "title": "Noise Injection Reveals Hidden Capabilities of Sandbagging Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Cameron Tice",
        "Philipp Alexander Kreer",
        "Nathan Helm-Burger",
        "Prithviraj Singh Shahani",
        "Fedor Ryzhenkov",
        "Jacob Haimes",
        "Felix Hofstätter",
        "Teun van der Weij"
      ],
      "abstract": "Capability evaluations play a critical role in ensuring the safe deployment\nof frontier AI systems, but this role may be undermined by intentional\nunderperformance or ``sandbagging.'' We present a novel model-agnostic method\nfor detecting sandbagging behavior using noise injection. Our approach is\nfounded on the observation that introducing Gaussian noise into the weights of\nmodels either prompted or fine-tuned to sandbag can considerably improve their\nperformance. We test this technique across a range of model sizes and\nmultiple-choice question benchmarks (MMLU, AI2, WMDP). Our results demonstrate\nthat noise injected sandbagging models show performance improvements compared\nto standard models. Leveraging this effect, we develop a classifier that\nconsistently identifies sandbagging behavior. Our unsupervised technique can be\nimmediately implemented by frontier labs or regulatory bodies with access to\nweights to improve the trustworthiness of capability evaluations.",
      "tldr_zh": "该研究揭示了通过噪声注入（noise injection）检测语言模型的“sandbagging”行为，即模型故意低估自身能力以规避评估。方法基于向模型权重中注入高斯噪声（Gaussian noise），观察其对沙袋模型性能的显著提升，并在多选题基准测试如 MMLU、AI2 和 WMDP 上进行验证。实验结果显示，噪声注入后沙袋模型的性能明显改善，从而开发出一个模型无关的分类器，用于识别这种行为。该技术是无监督的，可立即由前沿实验室或监管机构应用，以提升 AI 系统能力评估的可靠性。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at NeurIPS 2024, SATA and SoLaR workshop, 6 pages, 4\n  figures, 1 table, code available at https://github.com/camtice/SandbagDetect",
      "pdf_url": "http://arxiv.org/pdf/2412.01784v1",
      "published_date": "2024-12-02 18:34:51 UTC",
      "updated_date": "2024-12-02 18:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:28:04.681116"
    },
    {
      "arxiv_id": "2412.01782v2",
      "title": "Quantifying the Reliability of Predictions in Detection Transformers: Object-Level Calibration and Image-Level Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Young-Jin Park",
        "Carson Sobolewski",
        "Navid Azizan"
      ],
      "abstract": "DEtection TRansformer (DETR) has emerged as a promising architecture for\nobject detection, offering an end-to-end prediction pipeline. In practice,\nhowever, DETR generates hundreds of predictions that far outnumber the actual\nnumber of objects present in an image. This raises the question: can we trust\nand use all of these predictions? Addressing this concern, we present empirical\nevidence highlighting how different predictions within the same image play\ndistinct roles, resulting in varying reliability levels across those\npredictions. More specifically, while multiple predictions are often made for a\nsingle object, our findings show that most often one such prediction is\nwell-calibrated, and the others are poorly calibrated. Based on these insights,\nwe demonstrate that identifying a reliable subset of DETR's predictions is\ncrucial for accurately assessing the reliability of the model at both object\nand image levels.\n  Building on this viewpoint, we first address the shortcomings of widely used\nperformance and calibration metrics, such as average precision and various\nforms of expected calibration error. Specifically, they are inadequate for\ndetermining which subset of DETR's predictions should be trusted and utilized.\nIn response, we present Object-level Calibration Error (OCE), which assesses\nthe calibration quality more effectively and is suitable for both ranking\ndifferent models and identifying the most reliable predictions within a\nspecific model. As a final contribution, we introduce a post hoc uncertainty\nquantification (UQ) framework that predicts the accuracy of the model on a\nper-image basis. By contrasting the average confidence scores of positive\n(i.e., likely to be matched) and negative predictions determined by OCE, our\nframework assesses the reliability of the DETR model for each test image.",
      "tldr_zh": "这篇论文探讨了DEtection TRansformer (DETR)模型在物体检测中的预测可靠性问题，发现同一图像中不同预测的可靠性不均一，通常一个物体的多个预测中只有一个校准良好。作者引入了Object-level Calibration Error (OCE)作为新指标，以更有效地评估校准质量，并用于排名模型和识别可靠预测子集。作为主要贡献，他们提出一个后处理Uncertainty Quantification (UQ)框架，通过对比积极和消极预测的平均置信度，评估模型在图像级别的可靠性，从而改善DETR的整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01782v2",
      "published_date": "2024-12-02 18:34:17 UTC",
      "updated_date": "2025-03-17 18:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:28:17.168887"
    },
    {
      "arxiv_id": "2412.01778v1",
      "title": "HackSynth: LLM Agent and Evaluation Framework for Autonomous Penetration Testing",
      "title_zh": "HackSynth：LLM 智能体和评估框架，用于自治渗透测试",
      "authors": [
        "Lajos Muzsai",
        "David Imolai",
        "András Lukács"
      ],
      "abstract": "We introduce HackSynth, a novel Large Language Model (LLM)-based agent\ncapable of autonomous penetration testing. HackSynth's dual-module architecture\nincludes a Planner and a Summarizer, which enable it to generate commands and\nprocess feedback iteratively. To benchmark HackSynth, we propose two new\nCapture The Flag (CTF)-based benchmark sets utilizing the popular platforms\nPicoCTF and OverTheWire. These benchmarks include two hundred challenges across\ndiverse domains and difficulties, providing a standardized framework for\nevaluating LLM-based penetration testing agents. Based on these benchmarks,\nextensive experiments are presented, analyzing the core parameters of\nHackSynth, including creativity (temperature and top-p) and token utilization.\nMultiple open source and proprietary LLMs were used to measure the agent's\ncapabilities. The experiments show that the agent performed best with the\nGPT-4o model, better than what the GPT-4o's system card suggests. We also\ndiscuss the safety and predictability of HackSynth's actions. Our findings\nindicate the potential of LLM-based agents in advancing autonomous penetration\ntesting and the importance of robust safeguards. HackSynth and the benchmarks\nare publicly available to foster research on autonomous cybersecurity\nsolutions.",
      "tldr_zh": "该研究引入了 HackSynth，一种基于 LLM 的代理，用于自主渗透测试，其双模块架构包括 Planner 和 Summarizer，用于生成命令并迭代处理反馈。\n为了评估 HackSynth，他们开发了两个新的 CTF 基准集，利用 PicoCTF 和 OverTheWire 平台，共包含 200 个跨领域和难度的挑战。\n实验分析了代理的核心参数，如 temperature 和 top-p，并测试了多种 LLM，显示 GPT-4o 模型表现最佳且超出预期；研究讨论了安全性和可预测性，并公开了 HackSynth 和基准以推动自主网络安全研究。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "68M25",
        "I.2.1; K.6.5"
      ],
      "primary_category": "cs.CR",
      "comment": "16 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01778v1",
      "published_date": "2024-12-02 18:28:18 UTC",
      "updated_date": "2024-12-02 18:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:28:29.560663"
    },
    {
      "arxiv_id": "2412.01770v2",
      "title": "Robot Learning with Super-Linear Scaling",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel Torne",
        "Arhan Jain",
        "Jiayi Yuan",
        "Vidaaranya Macha",
        "Lars Ankile",
        "Anthony Simeonov",
        "Pulkit Agrawal",
        "Abhishek Gupta"
      ],
      "abstract": "Scaling robot learning requires data collection pipelines that scale\nfavorably with human effort. In this work, we propose Crowdsourcing and\nAmortizing Human Effort for Real-to-Sim-to-Real(CASHER), a pipeline for scaling\nup data collection and learning in simulation where the performance scales\nsuperlinearly with human effort. The key idea is to crowdsource digital twins\nof real-world scenes using 3D reconstruction and collect large-scale data in\nsimulation, rather than the real-world. Data collection in simulation is\ninitially driven by RL, bootstrapped with human demonstrations. As the training\nof a generalist policy progresses across environments, its generalization\ncapabilities can be used to replace human effort with model generated\ndemonstrations. This results in a pipeline where behavioral data is collected\nin simulation with continually reducing human effort. We show that CASHER\ndemonstrates zero-shot and few-shot scaling laws on three real-world tasks\nacross diverse scenarios. We show that CASHER enables fine-tuning of\npre-trained policies to a target scenario using a video scan without any\nadditional human effort. See our project website:\nhttps://casher-robot-learning.github.io/CASHER/",
      "tldr_zh": "本论文提出 CASHER（Crowdsourcing and Amortizing Human Effort for Real-to-Sim-to-Real）管道，用于实现机器人学习的超线性扩展，通过减少人类努力来高效扩展数据收集。方法包括众包数字 twins（digital twins）构建真实场景的 3D 重建，在模拟环境中收集数据，先以 RL（Reinforcement Learning）和人类演示启动训练，然后利用通用策略的泛化能力替换人类演示以持续降低人力投入。实验结果显示，CASHER 在三个真实任务上实现了零-shot 和 few-shot scaling laws，并支持使用视频扫描对预训练策略进行微调，而无需额外人类努力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01770v2",
      "published_date": "2024-12-02 18:12:02 UTC",
      "updated_date": "2024-12-06 05:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:30:41.060906"
    },
    {
      "arxiv_id": "2412.01769v1",
      "title": "Commit0: Library Generation from Scratch",
      "title_zh": "翻译失败",
      "authors": [
        "Wenting Zhao",
        "Nan Jiang",
        "Celine Lee",
        "Justin T Chiu",
        "Claire Cardie",
        "Matthias Gallé",
        "Alexander M Rush"
      ],
      "abstract": "With the goal of benchmarking generative systems beyond expert software\ndevelopment ability, we introduce Commit0, a benchmark that challenges AI\nagents to write libraries from scratch. Agents are provided with a\nspecification document outlining the library's API as well as a suite of\ninteractive unit tests, with the goal of producing an implementation of this\nAPI accordingly. The implementation is validated through running these unit\ntests. As a benchmark, Commit0 is designed to move beyond static one-shot code\ngeneration towards agents that must process long-form natural language\nspecifications, adapt to multi-stage feedback, and generate code with complex\ndependencies. Commit0 also offers an interactive environment where models\nreceive static analysis and execution feedback on the code they generate. Our\nexperiments demonstrate that while current agents can pass some unit tests,\nnone can yet fully reproduce full libraries. Results also show that interactive\nfeedback is quite useful for models to generate code that passes more unit\ntests, validating the benchmarks that facilitate its use.",
      "tldr_zh": "本研究引入了Commit0基准，用于评估AI agents从零开始编写库的能力，超越了专家级软件开发测试。代理需基于API规范文档和交互式单元测试生成代码，处理长形式自然语言规范、多阶段反馈以及复杂依赖。实验结果显示，虽然当前代理能通过部分单元测试，但尚未能完全重现完整库；同时，交互反馈显著提升了代码通过率，验证了该基准的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01769v1",
      "published_date": "2024-12-02 18:11:30 UTC",
      "updated_date": "2024-12-02 18:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:28:51.908315"
    },
    {
      "arxiv_id": "2412.01754v1",
      "title": "Efficient Compression of Sparse Accelerator Data Using Implicit Neural Representations and Importance Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Xihaier Luo",
        "Samuel Lurvey",
        "Yi Huang",
        "Yihui Ren",
        "Jin Huang",
        "Byung-Jun Yoon"
      ],
      "abstract": "High-energy, large-scale particle colliders in nuclear and high-energy\nphysics generate data at extraordinary rates, reaching up to $1$ terabyte and\nseveral petabytes per second, respectively. The development of real-time,\nhigh-throughput data compression algorithms capable of reducing this data to\nmanageable sizes for permanent storage is of paramount importance. A unique\ncharacteristic of the tracking detector data is the extreme sparsity of\nparticle trajectories in space, with an occupancy rate ranging from\napproximately $10^{-6}$ to $10\\%$. Furthermore, for downstream tasks, a\ncontinuous representation of this data is often more useful than a voxel-based,\ndiscrete representation due to the inherently continuous nature of the signals\ninvolved. To address these challenges, we propose a novel approach using\nimplicit neural representations for data learning and compression. We also\nintroduce an importance sampling technique to accelerate the network training\nprocess. Our method is competitive with traditional compression algorithms,\nsuch as MGARD, SZ, and ZFP, while offering significant speed-ups and\nmaintaining negligible accuracy loss through our importance sampling strategy.",
      "tldr_zh": "这篇论文提出了一种高效压缩稀疏加速器数据的方法，利用Implicit Neural Representations进行数据学习和压缩，以适应高能物理实验中每秒高达1TB至几PB的数据生成率。论文引入Importance Sampling技术来加速网络训练过程，解决了数据极度稀疏（occupancy rate约10^{-6}至10%）且下游任务更适合连续表示的问题。与传统算法如MGARD、SZ和ZFP相比，该方法在保持微小准确性损失的同时，实现了显著的速度提升和竞争性性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01754v1",
      "published_date": "2024-12-02 17:50:49 UTC",
      "updated_date": "2024-12-02 17:50:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:31:05.800230"
    },
    {
      "arxiv_id": "2412.01752v1",
      "title": "A Neurosymbolic Fast and Slow Architecture for Graph Coloring",
      "title_zh": "翻译失败",
      "authors": [
        "Vedant Khandelwal",
        "Vishal Pallagani",
        "Biplav Srivastava",
        "Francesca Rossi"
      ],
      "abstract": "Constraint Satisfaction Problems (CSPs) present significant challenges to\nartificial intelligence due to their intricate constraints and the necessity\nfor precise solutions. Existing symbolic solvers are often slow, and prior\nresearch has shown that Large Language Models (LLMs) alone struggle with CSPs\nbecause of their complexity. To bridge this gap, we build upon the existing\nSOFAI architecture (or SOFAI-v1), which adapts Daniel Kahneman's ''Thinking,\nFast and Slow'' cognitive model to AI. Our enhanced architecture, SOFAI-v2,\nintegrates refined metacognitive governance mechanisms to improve adaptability\nacross complex domains, specifically tailored for solving CSPs like graph\ncoloring. SOFAI-v2 combines a fast System 1 (S1) based on LLMs with a\ndeliberative System 2 (S2) governed by a metacognition module. S1's initial\nsolutions, often limited by non-adherence to constraints, are enhanced through\nmetacognitive governance, which provides targeted feedback and examples to\nadapt S1 to CSP requirements. If S1 fails to solve the problem, metacognition\nstrategically invokes S2, ensuring accurate and reliable solutions. With\nempirical results, we show that SOFAI-v2 for graph coloring problems achieves a\n16.98% increased success rate and is 32.42% faster than symbolic solvers.",
      "tldr_zh": "该论文针对Constraint Satisfaction Problems (CSPs) 的复杂性和精确性挑战，提出了一种神经符号架构SOFAI-v2，基于Daniel Kahneman的“快速思考和缓慢思考”模型，增强了元认知治理机制以适应CSPs如图着色问题。SOFAI-v2将基于Large Language Models (LLMs)的快速System 1与审议性的System 2结合，通过元认知模块提供针对性反馈和示例，帮助System 1改进解决方案，并在失败时调用System 2确保准确性。实验结果显示，SOFAI-v2在图着色任务上比传统符号求解器成功率提高了16.98%，并加速了32.42%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "18 Pages, 18 Figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2412.01752v1",
      "published_date": "2024-12-02 17:47:13 UTC",
      "updated_date": "2024-12-02 17:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:29:16.888657"
    },
    {
      "arxiv_id": "2412.01728v1",
      "title": "Automated Toll Management System Using RFID and Image Processing",
      "title_zh": "使用 RFID 和图像处理的自动收费管理系统",
      "authors": [
        "Raihan Ahmed",
        "Shahed Chowdhury Omi",
        "Md. Sadman Rahman",
        "Niaz Rahman Bhuiyan"
      ],
      "abstract": "Traveling through toll plazas is one of the primary causes of congestion, as\nidentified in recent studies. Electronic Toll Collection (ETC) systems can\nmitigate this problem. This experiment focuses on enhancing the security of ETC\nusing RFID tags and number plate verification. For number plate verification,\nimage processing is employed, and a CNN classifier is implemented to detect\nvehicle registration numbers. Based on the registered number, a notification\nemail is sent to the respective owner for toll fee payment within a specific\ntimeframe to avoid fines. Additionally, toll fees are automatically deducted in\nreal-time from the owner's balance. This system benefits travelers by\neliminating the need to queue for toll payment, thereby reducing delays and\nimproving convenience.",
      "tldr_zh": "该研究提出了一种自动化收费管理系统，利用 RFID 标签和图像处理技术来提升电子收费系统 (ETC) 的安全性和效率。具体方法包括使用 CNN 分类器检测车辆车牌号码，并基于识别结果发送通知邮件，要求车主在指定时间内支付费用，同时实现实时扣款。该系统通过消除排队需求，显著减少交通拥堵，并提高旅行便利性，在实际应用中为用户带来更顺畅的通行体验。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01728v1",
      "published_date": "2024-12-02 17:19:42 UTC",
      "updated_date": "2024-12-02 17:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:31:28.209718"
    },
    {
      "arxiv_id": "2412.01708v1",
      "title": "Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Ye",
        "Xianghe Pang",
        "Jingyi Chai",
        "Jiaao Chen",
        "Zhenfei Yin",
        "Zhen Xiang",
        "Xiaowen Dong",
        "Jing Shao",
        "Siheng Chen"
      ],
      "abstract": "Scholarly peer review is a cornerstone of scientific advancement, but the\nsystem is under strain due to increasing manuscript submissions and the\nlabor-intensive nature of the process. Recent advancements in large language\nmodels (LLMs) have led to their integration into peer review, with promising\nresults such as substantial overlaps between LLM- and human-generated reviews.\nHowever, the unchecked adoption of LLMs poses significant risks to the\nintegrity of the peer review system. In this study, we comprehensively analyze\nthe vulnerabilities of LLM-generated reviews by focusing on manipulation and\ninherent flaws. Our experiments show that injecting covert deliberate content\ninto manuscripts allows authors to explicitly manipulate LLM reviews, leading\nto inflated ratings and reduced alignment with human reviews. In a simulation,\nwe find that manipulating 5% of the reviews could potentially cause 12% of the\npapers to lose their position in the top 30% rankings. Implicit manipulation,\nwhere authors strategically highlight minor limitations in their papers,\nfurther demonstrates LLMs' susceptibility compared to human reviewers, with a\n4.5 times higher consistency with disclosed limitations. Additionally, LLMs\nexhibit inherent flaws, such as potentially assigning higher ratings to\nincomplete papers compared to full papers and favoring well-known authors in\nsingle-blind review process. These findings highlight the risks of\nover-reliance on LLMs in peer review, underscoring that we are not yet ready\nfor widespread adoption and emphasizing the need for robust safeguards.",
      "tldr_zh": "这篇论文分析了在学术同行评审中使用大型语言模型(LLMs)的潜在风险，强调尽管LLMs能生成与人类评审相似的反馈，但其易受操纵和固有缺陷可能威胁评审完整性。通过实验，研究者发现作者通过注入隐蔽内容或强调次要缺陷，能操纵LLMs评分，导致评分 inflated、与人类评审一致性降低，并可能使12%的论文在排名中下滑。模拟结果还显示，LLMs存在偏见，如更倾向于不完整论文或知名作者。总体而言，论文警告过度依赖LLMs的危险，主张在广泛采用前需加强保障措施。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01708v1",
      "published_date": "2024-12-02 16:55:03 UTC",
      "updated_date": "2024-12-02 16:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:29:41.202111"
    },
    {
      "arxiv_id": "2412.01703v1",
      "title": "Deep Guess acceleration for explainable image reconstruction in sparse-view CT",
      "title_zh": "翻译失败",
      "authors": [
        "Elena Loli Piccolomini",
        "Davide Evangelista",
        "Elena Morotti"
      ],
      "abstract": "Sparse-view Computed Tomography (CT) is an emerging protocol designed to\nreduce X-ray dose radiation in medical imaging. Traditional Filtered Back\nProjection algorithm reconstructions suffer from severe artifacts due to sparse\ndata. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,\nthough better at mitigating noise through regularization, are too\ncomputationally costly for clinical use. This paper introduces a novel\ntechnique, denoted as the Deep Guess acceleration scheme, using a trained\nneural network both to quicken the regularized MBIR and to enhance the\nreconstruction accuracy. We integrate state-of-the-art deep learning tools to\ninitialize a clever starting guess for a proximal algorithm solving a\nnon-convex model and thus computing an interpretable solution image in a few\niterations. Experimental results on real CT images demonstrate the Deep Guess\neffectiveness in (very) sparse tomographic protocols, where it overcomes its\nmere variational counterpart and many data-driven approaches at the state of\nthe art. We also consider a ground truth-free implementation and test the\nrobustness of the proposed framework to noise.",
      "tldr_zh": "本研究针对稀疏视图 CT（Sparse-view CT）成像中辐射剂量减少的问题，指出传统 Filtered Back Projection 算法因数据稀疏而产生严重 artifacts，而 Model-Based Iterative Reconstruction (MBIR) 算法虽能减轻噪声但计算成本过高。该论文提出 Deep Guess acceleration scheme，一种结合训练神经网络的技术，用于快速初始化 proximal algorithm 的起始猜测，从而加速正则化 MBIR 并提升重建准确性。实验结果显示，该方法在真实 CT 图像上表现优异，尤其在极度稀疏的断层成像协议中，超越了变分方法和现有数据驱动方法，并证明了其对噪声的鲁棒性及无 ground truth 实现的有效性。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.CV",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01703v1",
      "published_date": "2024-12-02 16:49:42 UTC",
      "updated_date": "2024-12-02 16:49:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:29:52.728441"
    },
    {
      "arxiv_id": "2412.01692v1",
      "title": "Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health",
      "title_zh": "数字流行病学：利用社交媒体获取癫痫和心理健康的洞见",
      "authors": [
        "Liza Dahiya",
        "Rachit Bagga"
      ],
      "abstract": "Social media platforms, particularly Reddit's r/Epilepsy community, offer a\nunique perspective into the experiences of individuals with epilepsy (PWE) and\ntheir caregivers. This study analyzes 57k posts and 533k comments to explore\nkey themes across demographics such as age, gender, and relationships. Our\nfindings highlight significant discussions on epilepsy-related challenges,\nincluding depression (with 39.75\\% of posts indicating severe symptoms),\ndriving restrictions, workplace concerns, and pregnancy-related issues in women\nwith epilepsy. We introduce a novel engagement metric, F(P), which incorporates\npost length, sentiment scores, and readability to quantify community\ninteraction. This analysis underscores the importance of integrated care\naddressing both neurological and mental health challenges faced by PWE. The\ninsights from this study inform strategies for targeted support and awareness\ninterventions.",
      "tldr_zh": "这篇论文探讨数字流行病学，通过分析 Reddit r/Epilepsy 社区的 57k 帖子和 533k 评论，揭示癫痫患者（PWE）和护理者的经历及关键主题，如年龄、性别和关系因素。研究发现，讨论中突出癫痫相关挑战，包括抑郁（39.75% 帖子显示严重症状）、驾驶限制、工作场所担忧和女性妊娠问题。论文引入新型互动指标 F(P)，整合帖子长度、情感分数和可读性，以量化社区参与。这些见解强调了整合神经和心理健康护理的必要性，并为制定针对性支持和意识干预策略提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01692v1",
      "published_date": "2024-12-02 16:35:25 UTC",
      "updated_date": "2024-12-02 16:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:30:05.373750"
    },
    {
      "arxiv_id": "2412.01674v1",
      "title": "Causal Discovery by Interventions via Integer Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelmonem Elrefaey",
        "Rong Pan"
      ],
      "abstract": "Causal discovery is essential across various scientific fields to uncover\ncausal structures within data. Traditional methods relying on observational\ndata have limitations due to confounding variables. This paper presents an\noptimization-based approach using integer programming (IP) to design minimal\nintervention sets that ensure causal structure identifiability. Our method\nprovides exact and modular solutions that can be adjusted to different\nexperimental settings and constraints. We demonstrate its effectiveness through\ncomparative analysis across different settings, demonstrating its applicability\nand robustness.",
      "tldr_zh": "该论文探讨了因果发现（Causal Discovery）的关键性，强调传统依赖观察数据的方法受混杂变量（confounding variables）限制。研究提出了一种基于整数规划（Integer Programming, IP）的优化方法，用于设计最小干预集（minimal intervention sets），以确保因果结构的精确识别，并提供模块化且可适应不同实验设置的解决方案。通过比较分析，该方法在各种场景中展示了显著的有效性、适用性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01674v1",
      "published_date": "2024-12-02 16:22:10 UTC",
      "updated_date": "2024-12-02 16:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:30:16.677565"
    },
    {
      "arxiv_id": "2412.01661v1",
      "title": "R-Bot: An LLM-based Query Rewrite System",
      "title_zh": "R-Bot：基于 LLM 的查询重写系统",
      "authors": [
        "Zhaoyan Sun",
        "Xuanhe Zhou",
        "Guoliang Li"
      ],
      "abstract": "Query rewrite is essential for optimizing SQL queries to improve their\nexecution efficiency without changing their results. Traditionally, this task\nhas been tackled through heuristic and learning-based methods, each with its\nlimitations in terms of inferior quality and low robustness. Recent\nadvancements in LLMs offer a new paradigm by leveraging their superior natural\nlanguage and code comprehension abilities. Despite their potential, directly\napplying LLMs like GPT-4 has faced challenges due to problems such as\nhallucinations, where the model might generate inaccurate or irrelevant\nresults. To address this, we propose R-Bot, an LLM-based query rewrite system\nwith a systematic approach. We first design a multi-source rewrite evidence\npreparation pipeline to generate query rewrite evidences for guiding LLMs to\navoid hallucinations. We then propose a hybrid structure-semantics retrieval\nmethod that combines structural and semantic analysis to retrieve the most\nrelevant rewrite evidences for effectively answering an online query. We next\npropose a step-by-step LLM rewrite method that iteratively leverages the\nretrieved evidences to select and arrange rewrite rules with self-reflection.\nWe conduct comprehensive experiments on widely used benchmarks, and demonstrate\nthe superior performance of our system, R-Bot, surpassing state-of-the-art\nquery rewrite methods.",
      "tldr_zh": "该研究提出 R-Bot，一种基于 LLM 的查询重写系统，旨在优化 SQL 查询以提升执行效率，同时解决传统方法（如启发式和学习-based 方法）的质量和鲁棒性问题。R-Bot 包括多源重写证据准备管道（multi-source rewrite evidence preparation pipeline）、混合结构-语义检索方法（hybrid structure-semantics retrieval method）以及逐步 LLM 重写方法（step-by-step LLM rewrite method），这些组件通过生成和检索相关证据、迭代应用重写规则并进行自反省（self-reflection）来避免 hallucinations。实验结果显示，R-Bot 在广泛使用的基准上超越了最先进的方法，证明了其在查询重写任务中的优越性能。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01661v1",
      "published_date": "2024-12-02 16:13:04 UTC",
      "updated_date": "2024-12-02 16:13:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:32:30.390810"
    },
    {
      "arxiv_id": "2412.01657v1",
      "title": "PassionNet: An Innovative Framework for Duplicate and Conflicting Requirements Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Summra Saleem",
        "Muhammad Nabeel Asim",
        "Andreas Dengel"
      ],
      "abstract": "Early detection and resolution of duplicate and conflicting requirements can\nsignificantly enhance project efficiency and overall software quality.\nResearchers have developed various computational predictors by leveraging\nArtificial Intelligence (AI) potential to detect duplicate and conflicting\nrequirements. However, these predictors lack in performance and requires more\neffective approaches to empower software development processes. Following the\nneed of a unique predictor that can accurately identify duplicate and\nconflicting requirements, this research offers a comprehensive framework that\nfacilitate development of 3 different types of predictive pipelines: language\nmodels based, multi-model similarity knowledge-driven and large language models\n(LLMs) context + multi-model similarity knowledge-driven. Within first type\npredictive pipelines landscape, framework facilitates conflicting/duplicate\nrequirements identification by leveraging 8 distinct types of LLMs. In second\ntype, framework supports development of predictive pipelines that leverage\nmulti-scale and multi-model similarity knowledge, ranging from traditional\nsimilarity computation methods to advanced similarity vectors generated by\nLLMs. In the third type, the framework synthesizes predictive pipelines by\nintegrating contextual insights from LLMs with multi-model similarity\nknowledge. Across 6 public benchmark datasets, extensive testing of 760\ndistinct predictive pipelines demonstrates that hybrid predictive pipelines\nconsistently outperforms other two types predictive pipelines in accurately\nidentifying duplicate and conflicting requirements. This predictive pipeline\noutperformed existing state-of-the-art predictors performance with an overall\nperformance margin of 13% in terms of F1-score",
      "tldr_zh": "本研究提出 PassionNet 框架，一种创新方法，用于早期识别软件需求中的重复和冲突问题，以提升项目效率和软件质量。框架支持三种预测管道：基于语言模型 (language models based) 的管道，利用 8 种不同 LLMs 进行识别；multi-model similarity knowledge-driven 的管道，结合多尺度相似性计算方法；以及 LLMs 上下文 + multi-model similarity knowledge-driven 的混合管道，通过整合上下文洞见和相似性知识实现更准确的预测。在 6 个公共基准数据集上测试的 760 个管道中，混合管道在 F1-score 上比其他类型管道表现更好，并比现有最先进预测器整体提高了 13%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01657v1",
      "published_date": "2024-12-02 16:05:38 UTC",
      "updated_date": "2024-12-02 16:05:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:32:42.794759"
    },
    {
      "arxiv_id": "2412.01655v1",
      "title": "Command-line Risk Classification using Transformer-based Neural Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Paolo Notaro",
        "Soroush Haeri",
        "Jorge Cardoso",
        "Michael Gerndt"
      ],
      "abstract": "To protect large-scale computing environments necessary to meet increasing\ncomputing demand, cloud providers have implemented security measures to monitor\nOperations and Maintenance (O&M) activities and therefore prevent data loss and\nservice interruption. Command interception systems are used to intercept,\nassess, and block dangerous Command-line Interface (CLI) commands before they\ncan cause damage. Traditional solutions for command risk assessment include\nrule-based systems, which require expert knowledge and constant human revision\nto account for unseen commands. To overcome these limitations, several\nend-to-end learning systems have been proposed to classify CLI commands. These\nsystems, however, have several other limitations, including the adoption of\ngeneral-purpose text classifiers, which may not adapt to the language\ncharacteristics of scripting languages such as Bash or PowerShell, and may not\nrecognize dangerous commands in the presence of an unbalanced class\ndistribution. In this paper, we propose a transformer-based command risk\nclassification system, which leverages the generalization power of Large\nLanguage Models (LLM) to provide accurate classification and the ability to\nidentify rare dangerous commands effectively, by exploiting the power of\ntransfer learning. We verify the effectiveness of our approach on a realistic\ndataset of production commands and show how to apply our model for other\nsecurity-related tasks, such as dangerous command interception and auditing of\nexisting rule-based systems.",
      "tldr_zh": "这篇论文提出了一种基于 Transformer-based Neural Architectures 的命令行风险分类系统，用于保护云环境免受危险 Command-line Interface (CLI) 命令的侵害，解决了传统规则系统依赖专家维护以及现有端到端学习模型不适应脚本语言（如 Bash 或 PowerShell）和不平衡数据的问题。该系统利用 Large Language Models (LLM) 的泛化能力与 transfer learning，实现了对危险命令的准确分类，尤其是稀有案例的识别。在真实生产命令数据集上的实验验证显示，该方法有效，并可扩展应用于危险命令拦截和规则系统审计任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01655v1",
      "published_date": "2024-12-02 16:04:31 UTC",
      "updated_date": "2024-12-02 16:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:32:54.034140"
    },
    {
      "arxiv_id": "2412.01650v2",
      "title": "Privacy-Preserving Federated Learning via Homomorphic Adversarial Networks",
      "title_zh": "基于同态",
      "authors": [
        "Wenhan Dong",
        "Chao Lin",
        "Xinlei He",
        "Xinyi Huang",
        "Shengmin Xu"
      ],
      "abstract": "Privacy-preserving federated learning (PPFL) aims to train a global model for\nmultiple clients while maintaining their data privacy. However, current PPFL\nprotocols exhibit one or more of the following insufficiencies: considerable\ndegradation in accuracy, the requirement for sharing keys, and cooperation\nduring the key generation or decryption processes. As a mitigation, we develop\nthe first protocol that utilizes neural networks to implement PPFL, as well as\nincorporating an Aggregatable Hybrid Encryption scheme tailored to the needs of\nPPFL. We name these networks as Homomorphic Adversarial Networks (HANs) which\ndemonstrate that neural networks are capable of performing tasks similar to\nmulti-key homomorphic encryption (MK-HE) while solving the problems of key\ndistribution and collaborative decryption. Our experiments show that HANs are\nrobust against privacy attacks. Compared with non-private federated learning,\nexperiments conducted on multiple datasets demonstrate that HANs exhibit a\nnegligible accuracy loss (at most 1.35%). Compared to traditional MK-HE\nschemes, HANs increase encryption aggregation speed by 6,075 times while\nincurring a 29.2 times increase in communication overhead.",
      "tldr_zh": "该论文提出了一种基于 Homomorphic Adversarial Networks (HANs) 的隐私保护联邦学习 (PPFL) 协议，旨在训练全局模型的同时保护客户端数据隐私，而无需共享密钥或进行协作解密。HANs 利用神经网络模拟多密钥同态加密 (MK-HE) 的功能，并整合了 Aggregatable Hybrid Encryption 方案，解决了传统 PPFL 的准确率下降和密钥管理问题。实验结果显示，HANs 在多个数据集上与非隐私联邦学习相比，准确率损失不超过 1.35%，并在抵抗隐私攻击方面表现出色，同时加密聚合速度比传统 MK-HE 方案提高了 6075 倍，尽管通信开销增加了 29.2 倍。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01650v2",
      "published_date": "2024-12-02 15:59:35 UTC",
      "updated_date": "2024-12-03 05:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:33:05.760895"
    },
    {
      "arxiv_id": "2412.01644v2",
      "title": "Concept Based Continuous Prompts for Interpretable Text Classification",
      "title_zh": "基于概念的连续提示用于可解释文本分类",
      "authors": [
        "Qian Chen",
        "Dongyang Li",
        "Xiaofeng He"
      ],
      "abstract": "Continuous prompts have become widely adopted for augmenting performance\nacross a wide range of natural language tasks. However, the underlying\nmechanism of this enhancement remains obscure. Previous studies rely on\nindividual words for interpreting continuous prompts, which lacks comprehensive\nsemantic understanding. Drawing inspiration from Concept Bottleneck Models, we\npropose a framework for interpreting continuous prompts by decomposing them\ninto human-readable concepts. Specifically, to ensure the feasibility of the\ndecomposition, we demonstrate that a corresponding concept embedding matrix and\na coefficient matrix can always be found to replace the prompt embedding\nmatrix. Then, we employ GPT-4o to generate a concept pool and choose potential\ncandidate concepts that are discriminative and representative using a novel\nsubmodular optimization algorithm. Experiments demonstrate that our framework\ncan achieve similar results as the original P-tuning and word-based approaches\nusing only a few concepts while providing more plausible results. Our code is\navailable at https://github.com/qq31415926/CD.",
      "tldr_zh": "本文提出一种基于概念的框架，用于解释连续提示（Continuous Prompts）在文本分类中的机制，以解决现有方法依赖单个单词而缺乏全面语义理解的问题。受 Concept Bottleneck Models 启发，该框架将连续提示分解为可读概念，通过证明可替换提示嵌入矩阵，并使用 GPT-4o 生成概念池，再结合一个新颖的子模优化（submodular optimization）算法选择有区分性和代表性的候选概念。实验结果显示，该方法仅需少量概念即可实现与原始 P-tuning 和基于单词的方法类似性能，同时提供更合理的解释效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01644v2",
      "published_date": "2024-12-02 15:56:08 UTC",
      "updated_date": "2024-12-05 06:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:33:18.543711"
    },
    {
      "arxiv_id": "2412.01621v3",
      "title": "NYT-Connections: A Deceptively Simple Text Classification Task that Stumps System-1 Thinkers",
      "title_zh": "翻译失败",
      "authors": [
        "Angel Yahir Loredo Lopez",
        "Tyler McDonald",
        "Ali Emami"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive performance on various\nbenchmarks, yet their ability to engage in deliberate reasoning remains\nquestionable. We present NYT-Connections, a collection of 358 simple word\nclassification puzzles derived from the New York Times Connections game. This\nbenchmark is designed to penalize quick, intuitive \"System 1\" thinking,\nisolating fundamental reasoning skills. We evaluated six recent LLMs, a simple\nmachine learning heuristic, and humans across three configurations:\nsingle-attempt, multiple attempts without hints, and multiple attempts with\ncontextual hints. Our findings reveal a significant performance gap: even\ntop-performing LLMs like GPT-4 fall short of human performance by nearly 30%.\nNotably, advanced prompting techniques such as Chain-of-Thought and\nSelf-Consistency show diminishing returns as task difficulty increases.\nNYT-Connections uniquely combines linguistic isolation, resistance to intuitive\nshortcuts, and regular updates to mitigate data leakage, offering a novel tool\nfor assessing LLM reasoning capabilities.",
      "tldr_zh": "本文提出NYT-Connections基准，这是一个由358个简单单词分类谜题组成的文本分类任务，源自纽约时报Connections游戏，旨在测试Large Language Models (LLMs)的推理能力而非直观的System-1思考。研究评估了六种LLMs、一个简单机器学习启发式方法和人类在单次尝试、多次尝试无提示以及多次尝试有上下文提示的三种配置下，结果显示顶级LLMs如GPT-4比人类性能低近30%。高级提示技术如Chain-of-Thought和Self-Consistency在任务难度增加时效果显著减弱。该基准通过语言隔离、抗直观捷径和定期更新，提供了评估LLM推理能力的创新工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages (excluding references), Published at Coling 2025, Best\n  Dataset Paper Award",
      "pdf_url": "http://arxiv.org/pdf/2412.01621v3",
      "published_date": "2024-12-02 15:41:47 UTC",
      "updated_date": "2025-02-25 12:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:33:30.082759"
    },
    {
      "arxiv_id": "2412.01617v1",
      "title": "If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM World",
      "title_zh": "翻译失败",
      "authors": [
        "Adrian de Wynter"
      ],
      "abstract": "Loneliness, or the lack of fulfilling relationships, significantly impacts a\nperson's mental and physical well-being and is prevalent worldwide. Previous\nresearch suggests that large language models (LLMs) may help mitigate\nloneliness. However, we argue that the use of widespread LLMs like ChatGPT is\nmore prevalent--and riskier, as they are not designed for this purpose. To\nexplore this, we analysed user interactions with ChatGPT, particularly those\noutside of its marketed use as task-oriented assistant. In dialogues classified\nas lonely, users frequently (37%) sought advice or validation, and received\ngood engagement. However, ChatGPT failed in sensitive scenarios, like\nresponding appropriately to suicidal ideation or trauma. We also observed a 35%\nhigher incidence of toxic content, with women being 22 times more likely to be\ntargeted than men. Our findings underscore ethical and legal questions about\nthis technology, and note risks like radicalisation or further isolation. We\nconclude with recommendations for research and industry to address loneliness.",
      "tldr_zh": "本研究探讨了在LLM（大语言模型）时代，ChatGPT等工具在缓解孤独感方面的作用及其潜在风险。研究者分析了ChatGPT的用户互动数据，特别是非任务导向对话，发现37%的孤独相关对话中用户寻求建议或验证时获得了良好回应，但模型在处理自杀念头或创伤等敏感场景时表现失败，并观察到有毒内容发生率高35%，女性被针对的可能性是男性的22倍。这些发现突出了伦理和法律问题，如可能导致激进化或进一步孤立，并为研究和行业提供了针对性推荐，以更安全地应对孤独问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01617v1",
      "published_date": "2024-12-02 15:39:00 UTC",
      "updated_date": "2024-12-02 15:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:33:41.661695"
    },
    {
      "arxiv_id": "2412.01609v1",
      "title": "Optimizing LoRa for Edge Computing with TinyML Pipeline for Channel Hopping",
      "title_zh": "优化 LoRa 用于边缘计算的 TinyML 管道以实现信道跳频",
      "authors": [
        "Marla Grunewald",
        "Mounir Bensalem",
        "Admela Jukan"
      ],
      "abstract": "We propose to integrate long-distance LongRange (LoRa) communication solution\nfor sending the data from IoT to the edge computing system, by taking advantage\nof its unlicensed nature and the potential for open source implementations that\nare common in edge computing. We propose a channel hoping optimization model\nand apply TinyML-based channel hoping model based for LoRa transmissions, as\nwell as experimentally study a fast predictive algorithm to find free channels\nbetween edge and IoT devices. In the open source experimental setup that\nincludes LoRa, TinyML and IoT-edge-cloud continuum, we integrate a novel\napplication workflow and cloud-friendly protocol solutions in a case study of\nplant recommender application that combines concepts of microfarming and urban\ncomputing. In a LoRa-optimized edge computing setup, we engineer the\napplication workflow, and apply collaborative filtering and various machine\nlearning algorithms on application data collected to identify and recommend the\nplanting schedule for a specific microfarm in an urban area. In the LoRa\nexperiments, we measure the occurrence of packet loss, RSSI, and SNR, using a\nrandom channel hoping scheme to compare with our proposed TinyML method. The\nresults show that it is feasible to use TinyML in microcontrollers for channel\nhopping, while proving the effectiveness of TinyML in learning to predict the\nbest channel to select for LoRa transmission, and by improving the RSSI by up\nto 63 %, SNR by up to 44 % in comparison with a random hopping mechanism.",
      "tldr_zh": "这篇论文提出了一种优化 LoRa 通信的方案，用于 IoT 到边缘计算系统的长距离数据传输，采用 TinyML 管道实现频道跳跃模型，以预测最佳频道并减少干扰。研究者通过实验设置结合 LoRa、TinyML 和 IoT-边缘-云系统，应用于植物推荐器案例，利用协作过滤和机器学习算法生成微型农业的种植计划。结果表明，与随机跳跃机制相比，该方法将 RSSI 改善最多 63% 和 SNR 最多 44%，证明了 TinyML 在微控制器上用于频道跳跃的可行性和有效性。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DM",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.NI",
      "comment": "This paper is uploaded here for research community, thus it is for\n  non-commercial purposes",
      "pdf_url": "http://arxiv.org/pdf/2412.01609v1",
      "published_date": "2024-12-02 15:28:44 UTC",
      "updated_date": "2024-12-02 15:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:33:53.268897"
    },
    {
      "arxiv_id": "2412.01605v1",
      "title": "Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Liu",
        "Wenxuan Wang",
        "Zizhan Ma",
        "Guolin Huang",
        "Yihang SU",
        "Kao-Jung Chang",
        "Wenting Chen",
        "Haoliang Li",
        "Linlin Shen",
        "Michael Lyu"
      ],
      "abstract": "Clinical decision making (CDM) is a complex, dynamic process crucial to\nhealthcare delivery, yet it remains a significant challenge for artificial\nintelligence systems. While Large Language Model (LLM)-based agents have been\ntested on general medical knowledge using licensing exams and knowledge\nquestion-answering tasks, their performance in the CDM in real-world scenarios\nis limited due to the lack of comprehensive testing datasets that mirror actual\nmedical practice. To address this gap, we present MedChain, a dataset of 12,163\nclinical cases that covers five key stages of clinical workflow. MedChain\ndistinguishes itself from existing benchmarks with three key features of\nreal-world clinical practice: personalization, interactivity, and\nsequentiality. Further, to tackle real-world CDM challenges, we also propose\nMedChain-Agent, an AI system that integrates a feedback mechanism and a\nMCase-RAG module to learn from previous cases and adapt its responses.\nMedChain-Agent demonstrates remarkable adaptability in gathering information\ndynamically and handling sequential clinical tasks, significantly outperforming\nexisting approaches. The relevant dataset and code will be released upon\nacceptance of this paper.",
      "tldr_zh": "该论文针对LLM代理在临床决策（CDM）中的实际应用不足问题，提出MedChain数据集，该数据集包含12,163个临床案例，覆盖临床工作流的五个关键阶段，并强调个性化、交互性和顺序性，以更好地模拟真实医疗场景。论文同时开发了MedChain-Agent系统，该系统整合反馈机制和MCase-RAG模块，能够从先前案例中学习并动态调整响应。实验结果表明，MedChain-Agent在信息收集和处理顺序临床任务方面显著优于现有方法，为桥接LLM代理与临床实践的差距提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01605v1",
      "published_date": "2024-12-02 15:25:02 UTC",
      "updated_date": "2024-12-02 15:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:34:05.266018"
    },
    {
      "arxiv_id": "2412.01604v2",
      "title": "Agentic-HLS: An agentic reasoning based high-level synthesis system using large language models (AI for EDA workshop 2024)",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Emre Oztas",
        "Mahdi Jelodari"
      ],
      "abstract": "Our aim for the ML Contest for Chip Design with HLS 2024 was to predict the\nvalidity, running latency in the form of cycle counts, utilization rate of BRAM\n(util-BRAM), utilization rate of lookup tables (uti-LUT), utilization rate of\nflip flops (util-FF), and the utilization rate of digital signal processors\n(util-DSP). We used Chain-of-thought techniques with large language models to\nperform classification and regression tasks. Our prediction is that with larger\nmodels reasoning was much improved. We release our prompts and propose a HLS\nbenchmarking task for LLMs.",
      "tldr_zh": "这篇论文介绍了 Agentic-HLS，一种基于代理推理的先进综合(HLS)系统，使用大型语言模型(LLMs)来预测芯片设计的有效性、运行延迟以及资源利用率（如 BRAM、LUT、FF 和 DSP）。他们采用 Chain-of-thought 技术进行分类和回归任务，观察到更大模型能显著提升推理性能。论文还发布了他们的提示模板，并提出一个 HLS 基准测试任务，以推动 LLMs 在电子设计自动化(EDA)领域的应用。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "AI4EDA co-located with 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.01604v2",
      "published_date": "2024-12-02 15:24:08 UTC",
      "updated_date": "2024-12-14 00:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:34:17.881769"
    },
    {
      "arxiv_id": "2412.01590v1",
      "title": "NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Sandesh Pokhrel",
        "Sanjay Bhandari",
        "Sharib Ali",
        "Tryphon Lambrou",
        "Anh Nguyen",
        "Yash Raj Shrestha",
        "Angus Watson",
        "Danail Stoyanov",
        "Prashnna Gyawali",
        "Binod Bhattarai"
      ],
      "abstract": "The integration of deep learning tools in gastrointestinal vision holds the\npotential for significant advancements in diagnosis, treatment, and overall\npatient care. A major challenge, however, is these tools' tendency to make\noverconfident predictions, even when encountering unseen or newly emerging\ndisease patterns, undermining their reliability.\n  We address this critical issue of reliability by framing it as an\nout-of-distribution (OOD) detection problem, where previously unseen and\nemerging diseases are identified as OOD examples. However, gastrointestinal\nimages pose a unique challenge due to the overlapping feature representations\nbetween in- Distribution (ID) and OOD examples. Existing approaches often\noverlook this characteristic, as they are primarily developed for natural image\ndatasets, where feature distinctions are more apparent. Despite the overlap, we\nhypothesize that the features of an in-distribution example will cluster closer\nto the centroids of their ground truth class, resulting in a shorter distance\nto the nearest centroid. In contrast, OOD examples maintain an equal distance\nfrom all class centroids. Based on this observation, we propose a novel\nnearest-centroid distance deficit (NCCD) score in the feature space for\ngastrointestinal OOD detection.\n  Evaluations across multiple deep learning architectures and two publicly\navailable benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness\nof our approach compared to several state-of-the-art methods. The code and\nimplementation details are publicly available at:\nhttps://github.com/bhattarailab/NCDD",
      "tldr_zh": "本文针对胃肠视觉中深度学习模型的过度自信问题，将其 framing 为 Out-of-Distribution (OOD) 检测挑战，特别是在 ID 和 OOD 例子特征重叠的情况下。作者提出 Nearest Centroid Distance Deficit (NCDD) 分数，通过比较特征空间中样本与最近类 centroids 的距离差异，来有效识别 OOD 例子。实验结果显示，NCDD 在 Kvasir2 和 Gastrovision 等基准上，超越多种 state-of-the-art 方法，并提供公开代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01590v1",
      "published_date": "2024-12-02 15:07:55 UTC",
      "updated_date": "2024-12-02 15:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:34:29.604873"
    },
    {
      "arxiv_id": "2412.01587v1",
      "title": "Handwriting-based Automated Assessment and Grading of Degree of Handedness: A Pilot Study",
      "title_zh": "翻译失败",
      "authors": [
        "Smriti Bala",
        "Venugopalan Y. Vishnu",
        "Deepak Joshi"
      ],
      "abstract": "Hand preference and degree of handedness (DoH) are two different aspects of\nhuman behavior which are often confused to be one. DoH is a person's inherent\ncapability of the brain; affected by nature and nurture. In this study, we used\ndominant and non-dominant handwriting traits to assess DoH for the first time,\non 43 subjects of three categories- Unidextrous, Partially Unidextrous, and\nAmbidextrous. Features extracted from the segmented handwriting signals called\nstrokes were used for DoH quantification. Davies Bouldin Index, Multilayer\nperceptron, and Convolutional Neural Network (CNN) were used for automated\ngrading of DoH. The outcomes of these methods were compared with the widely\nused DoH assessment questionnaires from Edinburgh Inventory (EI). The CNN based\nautomated grading outperformed other computational methods with an average\nclassification accuracy of 95.06% under stratified 10-fold cross-validation.\nThe leave-one-subject-out strategy on this CNN resulted in a test individual's\nDoH score which was converted into a 4-point score. Around 90% of the obtained\nscores from all the implemented computational methods were found to be in\naccordance with the EI scores under 95% confidence interval. Automated grading\nof degree of handedness using handwriting signals can provide more resolution\nto the Edinburgh Inventory scores. This could be used in multiple applications\nconcerned with neuroscience, rehabilitation, physiology, psychometry,\nbehavioral sciences, and forensics.",
      "tldr_zh": "这篇论文首次使用主导和非主导手的手写特征来评估 Degree of Handedness (DoH)，涉及43名受试者，包括Unidextrous、Partially Unidextrous和Ambidextrous类别。研究从手写信号的strokes中提取特征，并采用Davies Bouldin Index、Multilayer Perceptron和Convolutional Neural Network (CNN)进行自动分级，其中CNN的分类准确率达到95.06%，与Edinburgh Inventory (EI)问卷结果一致。约90%的计算方法得分在95%置信区间内与EI相符，这为DoH评估提供了更高分辨率。最终，该方法可应用于神经科学、康复、生理学、心理测量、行为科学和法医学等领域。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01587v1",
      "published_date": "2024-12-02 15:06:18 UTC",
      "updated_date": "2024-12-02 15:06:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:34:42.100495"
    },
    {
      "arxiv_id": "2412.01572v4",
      "title": "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity",
      "title_zh": "MBA-R",
      "authors": [
        "Xiaqiang Tang",
        "Qiang Gao",
        "Jian Li",
        "Nan Du",
        "Qi Li",
        "Sihong Xie"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has proven to be highly effective in\nboosting the generative performance of language model in knowledge-intensive\ntasks. However, existing RAG framework either indiscriminately perform\nretrieval or rely on rigid single-class classifiers to select retrieval\nmethods, leading to inefficiencies and suboptimal performance across queries of\nvarying complexity. To address these challenges, we propose a reinforcement\nlearning-based framework that dynamically selects the most suitable retrieval\nstrategy based on query complexity. % our solution Our approach leverages a\nmulti-armed bandit algorithm, which treats each retrieval method as a distinct\n``arm'' and adapts the selection process by balancing exploration and\nexploitation. Additionally, we introduce a dynamic reward function that\nbalances accuracy and efficiency, penalizing methods that require more\nretrieval steps, even if they lead to a correct result. Our method achieves new\nstate of the art results on multiple single-hop and multi-hop datasets while\nreducing retrieval costs. Our code are available at\nhttps://github.com/FUTUREEEEEE/MBA .",
      "tldr_zh": "该论文提出MBA-RAG，一种基于强化学习的框架，用于通过查询复杂度动态选择最合适的检索策略，以优化Retrieval Augmented Generation (RAG)。该方法将multi-armed bandit算法应用于每个检索方法作为“arm”，通过平衡探索和利用来适应性地选择策略，并引入动态奖励函数来权衡准确性和效率，惩罚多余的检索步骤。实验结果显示，MBA-RAG在多个单跳和多跳数据集上实现了新的state-of-the-art性能，同时降低了检索成本。总的来说，该框架提升了RAG的效率和适用性，为知识密集型任务提供了更智能的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01572v4",
      "published_date": "2024-12-02 14:55:02 UTC",
      "updated_date": "2025-01-01 08:52:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:34:52.887219"
    },
    {
      "arxiv_id": "2412.01558v1",
      "title": "VideoLights: Feature Refinement and Cross-Task Alignment Transformer for Joint Video Highlight Detection and Moment Retrieval",
      "title_zh": "VideoLights：特征精炼与跨任务对齐 Transformer 用于联合视频高亮检测和时刻检索",
      "authors": [
        "Dhiman Paul",
        "Md Rizwan Parvez",
        "Nabeel Mohammed",
        "Shafin Rahman"
      ],
      "abstract": "Video Highlight Detection and Moment Retrieval (HD/MR) are essential in video\nanalysis. Recent joint prediction transformer models often overlook their\ncross-task dynamics and video-text alignment and refinement. Moreover, most\nmodels typically use limited, uni-directional attention mechanisms, resulting\nin weakly integrated representations and suboptimal performance in capturing\nthe interdependence between video and text modalities. Although large-language\nand vision-language models (LLM/LVLMs) have gained prominence across various\ndomains, their application in this field remains relatively underexplored. Here\nwe propose VideoLights, a novel HD/MR framework addressing these limitations\nthrough (i) Convolutional Projection and Feature Refinement modules with an\nalignment loss for better video-text feature alignment, (ii) Bi-Directional\nCross-Modal Fusion network for strongly coupled query-aware clip\nrepresentations, and (iii) Uni-directional joint-task feedback mechanism\nenhancing both tasks through correlation. In addition, (iv) we introduce hard\npositive/negative losses for adaptive error penalization and improved learning,\nand (v) leverage LVLMs like BLIP-2 for enhanced multimodal feature integration\nand intelligent pretraining using synthetic data generated from LVLMs.\nComprehensive experiments on QVHighlights, TVSum, and Charades-STA benchmarks\ndemonstrate state-of-the-art performance. Codes and models are available at\nhttps://github.com/dpaul06/VideoLights .",
      "tldr_zh": "该研究提出VideoLights框架，用于联合处理Video Highlight Detection和Moment Retrieval (HD/MR)任务，解决现有Transformer模型在跨任务动态和视频-文本对齐方面的不足。框架包括Convolutional Projection and Feature Refinement模块结合alignment loss以提升特征对齐、Bi-Directional Cross-Modal Fusion network实现强耦合的查询感知表示，以及Uni-directional joint-task feedback机制通过任务相关性增强整体性能；此外，还引入hard positive/negative losses和LVLMs如BLIP-2进行多模态特征集成和合成数据预训练。实验在QVHighlights、TVSum和Charades-STA基准上实现了state-of-the-art性能，显著提高了视频分析的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10; I.2.7"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01558v1",
      "published_date": "2024-12-02 14:45:53 UTC",
      "updated_date": "2024-12-02 14:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:35:06.221138"
    },
    {
      "arxiv_id": "2412.01550v3",
      "title": "SeqAfford: Sequential 3D Affordance Reasoning via Multimodal Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chunlin Yu",
        "Hanqing Wang",
        "Ye Shi",
        "Haoyang Luo",
        "Sibei Yang",
        "Jingyi Yu",
        "Jingya Wang"
      ],
      "abstract": "3D affordance segmentation aims to link human instructions to touchable\nregions of 3D objects for embodied manipulations. Existing efforts typically\nadhere to single-object, single-affordance paradigms, where each affordance\ntype or explicit instruction strictly corresponds to a specific affordance\nregion and are unable to handle long-horizon tasks. Such a paradigm cannot\nactively reason about complex user intentions that often imply sequential\naffordances. In this paper, we introduce the Sequential 3D Affordance Reasoning\ntask, which extends the traditional paradigm by reasoning from cumbersome user\nintentions and then decomposing them into a series of segmentation maps. Toward\nthis, we construct the first instruction-based affordance segmentation\nbenchmark that includes reasoning over both single and sequential affordances,\ncomprising 180K instruction-point cloud pairs. Based on the benchmark, we\npropose our model, SeqAfford, to unlock the 3D multi-modal large language model\nwith additional affordance segmentation abilities, which ensures reasoning with\nworld knowledge and fine-grained affordance grounding in a cohesive framework.\nWe further introduce a multi-granular language-point integration module to\nendow 3D dense prediction. Extensive experimental evaluations show that our\nmodel excels over well-established methods and exhibits open-world\ngeneralization with sequential reasoning abilities.",
      "tldr_zh": "本论文引入了 Sequential 3D Affordance Reasoning 任务，以扩展传统的 3D 物体可操作性分割，处理复杂用户意图并将其分解为一系列分割映射。研究者构建了首个基于指令的 affordance segmentation 基准数据集，包含 180K 指令-点云对，支持单和顺序 affordance 的推理。提出了 SeqAfford 模型，利用 Multimodal Large Language Model 实现世界知识推理和细粒度 affordance grounding，并引入 multi-granular language-point integration module 进行 3D 密集预测。实验结果表明，SeqAfford 模型在基准上优于现有方法，并展示了出色的顺序推理能力和开放世界泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01550v3",
      "published_date": "2024-12-02 14:37:57 UTC",
      "updated_date": "2025-03-21 04:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:35:19.315857"
    },
    {
      "arxiv_id": "2412.01547v1",
      "title": "Improved Large Language Model Jailbreak Detection via Pretrained Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Erick Galinkin",
        "Martin Sablotny"
      ],
      "abstract": "The adoption of large language models (LLMs) in many applications, from\ncustomer service chat bots and software development assistants to more capable\nagentic systems necessitates research into how to secure these systems. Attacks\nlike prompt injection and jailbreaking attempt to elicit responses and actions\nfrom these models that are not compliant with the safety, privacy, or content\npolicies of organizations using the model in their application. In order to\ncounter abuse of LLMs for generating potentially harmful replies or taking\nundesirable actions, LLM owners must apply safeguards during training and\nintegrate additional tools to block the LLM from generating text that abuses\nthe model. Jailbreaking prompts play a vital role in convincing an LLM to\ngenerate potentially harmful content, making it important to identify\njailbreaking attempts to block any further steps. In this work, we propose a\nnovel approach to detect jailbreak prompts based on pairing text embeddings\nwell-suited for retrieval with traditional machine learning classification\nalgorithms. Our approach outperforms all publicly available methods from open\nsource LLM security applications.",
      "tldr_zh": "这篇论文针对大型语言模型 (LLMs) 的安全问题，提出了一种改进的 jailbreak 检测方法，以应对 prompt injection 等攻击导致的潜在有害输出。方法通过利用预训练 embeddings 与传统机器学习分类算法相结合，对 jailbreaking prompts 进行高效识别和阻断。实验结果表明，该方法在检测性能上优于所有公开的开源 LLM 安全应用，为提升模型的安全性提供了有效工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to AICS 2025: https://aics.site",
      "pdf_url": "http://arxiv.org/pdf/2412.01547v1",
      "published_date": "2024-12-02 14:35:43 UTC",
      "updated_date": "2024-12-02 14:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:35:28.875625"
    },
    {
      "arxiv_id": "2412.01542v1",
      "title": "Towards Type Agnostic Cyber Defense Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Erick Galinkin",
        "Emmanouil Pountrourakis",
        "Spiros Mancoridis"
      ],
      "abstract": "With computing now ubiquitous across government, industry, and education,\ncybersecurity has become a critical component for every organization on the\nplanet. Due to this ubiquity of computing, cyber threats have continued to grow\nyear over year, leading to labor shortages and a skills gap in cybersecurity.\nAs a result, many cybersecurity product vendors and security organizations have\nlooked to artificial intelligence to shore up their defenses. This work\nconsiders how to characterize attackers and defenders in one approach to the\nautomation of cyber defense -- the application of reinforcement learning.\nSpecifically, we characterize the types of attackers and defenders in the sense\nof Bayesian games and, using reinforcement learning, derive empirical findings\nabout how to best train agents that defend against multiple types of attackers.",
      "tldr_zh": "这篇论文探讨了在网络安全领域使用人工智能应对日益增长的威胁问题，强调了强化学习（reinforcement learning）在自动化防御中的作用，以缓解劳动力短缺。作者通过贝叶斯游戏（Bayesian games）表征攻击者和防御者类型，并使用强化学习训练代理（agents），使它们能够适应多种攻击者。实验结果提供了关于如何最佳训练这些代理以提升防御效果的经验性发现。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to AICS 2025: https://aics.site",
      "pdf_url": "http://arxiv.org/pdf/2412.01542v1",
      "published_date": "2024-12-02 14:32:18 UTC",
      "updated_date": "2024-12-02 14:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:35:40.756772"
    },
    {
      "arxiv_id": "2412.01541v1",
      "title": "Effectiveness of L2 Regularization in Privacy-Preserving Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaos Chandrinos",
        "Iliana Loi",
        "Panagiotis Zachos",
        "Ioannis Symeonidis",
        "Aristotelis Spiliotis",
        "Maria Panou",
        "Konstantinos Moustakas"
      ],
      "abstract": "Artificial intelligence, machine learning, and deep learning as a service\nhave become the status quo for many industries, leading to the widespread\ndeployment of models that handle sensitive data. Well-performing models, the\nindustry seeks, usually rely on a large volume of training data. However, the\nuse of such data raises serious privacy concerns due to the potential risks of\nleaks of highly sensitive information. One prominent threat is the Membership\nInference Attack, where adversaries attempt to deduce whether a specific data\npoint was used in a model's training process. An adversary's ability to\ndetermine an individual's presence represents a significant privacy threat,\nespecially when related to a group of users sharing sensitive information.\nHence, well-designed privacy-preserving machine learning solutions are\ncritically needed in the industry. In this work, we compare the effectiveness\nof L2 regularization and differential privacy in mitigating Membership\nInference Attack risks. Even though regularization techniques like L2\nregularization are commonly employed to reduce overfitting, a condition that\nenhances the effectiveness of Membership Inference Attacks, their impact on\nmitigating these attacks has not been systematically explored.",
      "tldr_zh": "这篇论文探讨了 L2 Regularization 在隐私保护机器学习中的有效性，针对机器学习模型处理敏感数据时可能面临的 Membership Inference Attack（成员推理攻击）风险。论文比较了 L2 Regularization 和 Differential Privacy 在缓解此类攻击方面的表现，强调 L2 Regularization 通常用于减少过拟合，但其对隐私保护的作用尚未得到系统性研究。主要发现表明，L2 Regularization 可能有助于降低攻击风险，为行业提供更实用的隐私保护策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01541v1",
      "published_date": "2024-12-02 14:31:11 UTC",
      "updated_date": "2024-12-02 14:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:35:53.099146"
    },
    {
      "arxiv_id": "2412.01528v1",
      "title": "CopyrightShield: Spatial Similarity Guided Backdoor Defense against Copyright Infringement in Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixiang Guo",
        "Siyuan Liang",
        "Aishan Liu",
        "Dacheng Tao"
      ],
      "abstract": "The diffusion model has gained significant attention due to its remarkable\ndata generation ability in fields such as image synthesis. However, its strong\nmemorization and replication abilities with respect to the training data also\nmake it a prime target for copyright infringement attacks. This paper provides\nan in-depth analysis of the spatial similarity of replication in diffusion\nmodel and leverages this key characteristic to design a method for detecting\npoisoning data. By employing a joint assessment of spatial-level and\nfeature-level information from the detected segments, we effectively identify\ncovertly dispersed poisoned samples. Building upon detected poisoning data, we\npropose a novel defense method specifically targeting copyright infringement\nattacks by introducing a protection constraint term into the loss function to\nmitigate the impact of poisoning. Extensive experimental results demonstrate\nthat our approach achieves an average F1 score of 0.709 in detecting copyright\ninfringement backdoors, resulting in an average increase of 68.1% in\nFirst-Attack Epoch (FAE) and an average decrease of 51.4% in Copyright\nInfringement Rate (CIR) of the poisoned model, effectively defending against\ncopyright infringement. Additionally, we introduce the concept of copyright\nfeature inversion, which aids in determining copyright responsibility and\nexpands the application scenarios of defense strategies.",
      "tldr_zh": "本研究提出CopyrightShield，一种基于空间相似性引导的防御方法，用于对抗扩散模型(diffusion models)中的版权侵犯后门攻击。该方法首先分析扩散模型中复制数据的空间相似性，通过结合空间级和特征级信息检测并识别隐蔽的中毒样本，然后在损失函数中引入保护约束项来减轻中毒影响。实验结果显示，该方法在检测版权侵犯后门上平均F1 score达0.709，同时将First-Attack Epoch (FAE)提高68.1%并将Copyright Infringement Rate (CIR)降低51.4%。此外，论文引入版权特征反演(copyright feature inversion)概念，以确定版权责任并扩展防御应用场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01528v1",
      "published_date": "2024-12-02 14:19:44 UTC",
      "updated_date": "2024-12-02 14:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:36:05.388783"
    },
    {
      "arxiv_id": "2412.01526v1",
      "title": "Addressing Data Leakage in HumanEval Using Combinatorial Test Design",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy S. Bradbury",
        "Riddhi More"
      ],
      "abstract": "The use of large language models (LLMs) is widespread across many domains,\nincluding Software Engineering, where they have been used to automate tasks\nsuch as program generation and test classification. As LLM-based methods\ncontinue to evolve, it is important that we define clear and robust methods\nthat fairly evaluate performance. Benchmarks are a common approach to assess\nLLMs with respect to their ability to solve problem-specific tasks as well as\nassess different versions of an LLM to solve tasks over time. For example, the\nHumanEval benchmark is composed of 164 hand-crafted tasks and has become an\nimportant tool in assessing LLM-based program generation. However, a major\nbarrier to a fair evaluation of LLMs using benchmarks like HumanEval is data\ncontamination resulting from data leakage of benchmark tasks and solutions into\nthe training data set. This barrier is compounded by the black-box nature of\nLLM training data which makes it difficult to even know if data leakage has\noccurred. To address the data leakage problem, we propose a new benchmark\nconstruction method where a benchmark is composed of template tasks that can be\ninstantiated into new concrete tasks using combinatorial test design. Concrete\ntasks for the same template task must be different enough that data leakage has\nminimal impact and similar enough that the tasks are interchangeable with\nrespect to performance evaluation. To assess our benchmark construction method,\nwe propose HumanEval_T, an alternative benchmark to HumanEval that was\nconstructed using template tasks and combinatorial test design.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)在软件工程任务（如程序生成）中的评估问题，强调了基准测试（如HumanEval）因数据泄漏而导致的不公平性。作者提出了一种新方法，使用模板任务和combinatorial test design来构建基准测试，确保具体任务足够不同以最小化数据泄漏影响，同时保持任务相似性以便于性能评估。为验证此方法，他们开发了HumanEval_T作为HumanEval的替代基准，旨在提供更可靠的LLMs评估框架。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2.7; D.2.5; I.2.2"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01526v1",
      "published_date": "2024-12-02 14:18:32 UTC",
      "updated_date": "2024-12-02 14:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:36:16.634174"
    },
    {
      "arxiv_id": "2412.12116v1",
      "title": "AI in Education: Rationale, Principles, and Instructional Implications",
      "title_zh": "翻译失败",
      "authors": [
        "Eyvind Elstad"
      ],
      "abstract": "This study examines the integration of generative AI in schools, assessing\nits benefits and risks. As AI use by students grows, it's crucial to understand\nits impact on learning and teaching practices. Generative AI, like ChatGPT, can\ncreate human-like content, prompting questions about its educational role. The\narticle differentiates large language models from traditional search engines\nand stresses the need for students to develop critical source evaluation\nskills. Although empirical evidence on AI's classroom effects is limited, AI\noffers personalized learning support and problem-solving tools, alongside\nchallenges like undermining deep learning if misused. The study emphasizes\ndeliberate strategies to ensure AI complements, not replaces, genuine cognitive\neffort. AI's educational role should be context-dependent, guided by\npedagogical goals. The study concludes with practical advice for teachers on\neffectively utilizing AI to promote understanding and critical engagement,\nadvocating for a balanced approach to enhance students' knowledge and skills\ndevelopment.",
      "tldr_zh": "这篇论文探讨了 generative AI 在教育中的整合，评估其益处（如提供个性化学习支持和问题解决工具）以及风险（如可能破坏深度学习或依赖过度）。论文比较 large language models（如 ChatGPT）和传统搜索引擎，强调学生需培养批判性来源评估技能，并指出尽管实证证据有限，AI 应在教学目标指导下发挥补充作用。最终，它提供实用建议给教师，倡导 deliberate strategies 和平衡方法，以确保 AI 增强学生的理解和批判性参与。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.12116v1",
      "published_date": "2024-12-02 14:08:07 UTC",
      "updated_date": "2024-12-02 14:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:37:26.630789"
    },
    {
      "arxiv_id": "2412.01512v1",
      "title": "ArtBrain: An Explainable end-to-end Toolkit for Classification and Attribution of AI-Generated Art and Style",
      "title_zh": "翻译失败",
      "authors": [
        "Ravidu Suien Rammuni Silva",
        "Ahmad Lotfi",
        "Isibor Kennedy Ihianle",
        "Golnaz Shahtahmassebi",
        "Jordan J. Bird"
      ],
      "abstract": "Recently, the quality of artworks generated using Artificial Intelligence\n(AI) has increased significantly, resulting in growing difficulties in\ndetecting synthetic artworks. However, limited studies have been conducted on\nidentifying the authenticity of synthetic artworks and their source. This paper\nintroduces AI-ArtBench, a dataset featuring 185,015 artistic images across 10\nart styles. It includes 125,015 AI-generated images and 60,000 pieces of\nhuman-created artwork. This paper also outlines a method to accurately detect\nAI-generated images and trace them to their source model. This work proposes a\nnovel Convolutional Neural Network model based on the ConvNeXt model called\nAttentionConvNeXt. AttentionConvNeXt was implemented and trained to\ndifferentiate between the source of the artwork and its style with an F1-Score\nof 0.869. The accuracy of attribution to the generative model reaches 0.999. To\ncombine the scientific contributions arising from this study, a web-based\napplication named ArtBrain was developed to enable both technical and\nnon-technical users to interact with the model. Finally, this study presents\nthe results of an Artistic Turing Test conducted with 50 participants. The\nfindings reveal that humans could identify AI-generated images with an accuracy\nof approximately 58%, while the model itself achieved a significantly higher\naccuracy of around 99%.",
      "tldr_zh": "本研究介绍了 AI-ArtBench 数据集，该数据集包含 185,015 张艺术图像（包括 125,015 张 AI 生成图像和 60,000 张人类创作图像），涵盖 10 种艺术风格，以解决检测 AI 生成艺术的难题。研究提出了一种基于 ConvNeXt 的新型 Convolutional Neural Network 模型 AttentionConvNeXt，用于区分艺术来源和风格，实现 F1-Score 0.869 和归因准确率 0.999。基于此，开发了 ArtBrain 网页工具，提供端到端的可解释分类和归因功能，供技术和非技术用户使用。最后，通过 Artistic Turing Test 发现，人类识别 AI 生成图像的准确率仅约 58%，而模型准确率高达约 99%，突显其在艺术真实性验证中的优势。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01512v1",
      "published_date": "2024-12-02 14:03:50 UTC",
      "updated_date": "2024-12-02 14:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:37:38.665547"
    },
    {
      "arxiv_id": "2412.01495v1",
      "title": "Adversarial Attacks on Hyperbolic Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Max van Spengler",
        "Jan Zahálka",
        "Pascal Mettes"
      ],
      "abstract": "As hyperbolic deep learning grows in popularity, so does the need for\nadversarial robustness in the context of such a non-Euclidean geometry. To this\nend, this paper proposes hyperbolic alternatives to the commonly used FGM and\nPGD adversarial attacks. Through interpretable synthetic benchmarks and\nexperiments on existing datasets, we show how the existing and newly proposed\nattacks differ. Moreover, we investigate the differences in adversarial\nrobustness between Euclidean and fully hyperbolic networks. We find that these\nnetworks suffer from different types of vulnerabilities and that the newly\nproposed hyperbolic attacks cannot address these differences. Therefore, we\nconclude that the shifts in adversarial robustness are due to the models\nlearning distinct patterns resulting from their different geometries.",
      "tldr_zh": "这篇论文提出了双曲版本的 FGM 和 PGD 对抗攻击，以评估非欧几何（hyperbolic）深度学习模型的鲁棒性。通过可解释的合成基准和现有数据集的实验，作者比较了传统攻击和新攻击的差异，并发现欧氏网络和双曲网络存在不同的脆弱性。新提出的双曲攻击无法完全解决这些差异，最终结论是，对抗鲁棒性的变化源于模型在不同几何下学习到的独特模式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01495v1",
      "published_date": "2024-12-02 13:48:41 UTC",
      "updated_date": "2024-12-02 13:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:37:50.130271"
    },
    {
      "arxiv_id": "2412.01491v2",
      "title": "Understanding complex crowd dynamics with generative neural simulators",
      "title_zh": "利用生成式神经模拟器理解复杂人群动态",
      "authors": [
        "Koen Minartz",
        "Fleur Hendriks",
        "Simon Martinus Koop",
        "Alessandro Corbetta",
        "Vlado Menkovski"
      ],
      "abstract": "Understanding the dynamics of pedestrian crowds is an outstanding challenge\ncrucial for designing efficient urban infrastructure and ensuring safe crowd\nmanagement. To this end, both small-scale laboratory and large-scale real-world\nmeasurements have been used. However, these approaches respectively lack\nstatistical resolution and parametric controllability, both essential to\ndiscovering physical relationships underlying the complex stochastic dynamics\nof crowds. Here, we establish an investigation paradigm that offers\nlaboratory-like controllability, while ensuring the statistical resolution of\nlarge-scale real-world datasets. Using our data-driven Neural Crowd Simulator\n(NeCS), which we train on large-scale data and validate against key statistical\nfeatures of crowd dynamics, we show that we can perform effective surrogate\ncrowd dynamics experiments without training on specific scenarios. We not only\nreproduce known experimental results on pairwise avoidance, but also uncover\nthe vision-guided and topological nature of N-body interactions. These findings\nshow how virtual experiments based on neural simulation enable data-driven\nscientific discovery.",
      "tldr_zh": "该研究针对理解复杂人群动态的挑战，提出了一种结合实验室可控性和大规模数据统计分辨率的新调查范式，以设计高效城市基础设施和确保安全人群管理。作者开发了数据驱动的 Neural Crowd Simulator (NeCS)，通过训练于大型真实数据集并验证关键统计特征，实现了无需针对特定场景训练的代理实验。实验结果不仅复制了已知 pairwise avoidance 现象，还揭示了 N-body interactions 的视觉引导和拓扑性质，展示了基于神经模拟的虚拟实验在推动数据驱动科学发现方面的潜力。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.LG",
        "physics.data-an"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "26 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01491v2",
      "published_date": "2024-12-02 13:42:36 UTC",
      "updated_date": "2024-12-03 16:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:38:01.359001"
    },
    {
      "arxiv_id": "2412.01490v4",
      "title": "Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows",
      "title_zh": "Intelligent Spark Agents：一种模块化的 LangGraph 框架，用于可扩展、可视",
      "authors": [
        "Jialin Wang",
        "Zhihua Duan"
      ],
      "abstract": "This paper presents a Spark-based modular LangGraph framework, designed to\nenhance machine learning workflows through scalability, visualization, and\nintelligent process optimization. At its core, the framework introduces Agent\nAI, a pivotal innovation that leverages Spark's distributed computing\ncapabilities and integrates with LangGraph for workflow orchestration.\n  Agent AI facilitates the automation of data preprocessing, feature\nengineering, and model evaluation while dynamically interacting with data\nthrough Spark SQL and DataFrame agents. Through LangGraph's graph-structured\nworkflows, the agents execute complex tasks, adapt to new inputs, and provide\nreal-time feedback, ensuring seamless decision-making and execution in\ndistributed environments. This system simplifies machine learning processes by\nallowing users to visually design workflows, which are then converted into\nSpark-compatible code for high-performance execution.\n  The framework also incorporates large language models through the LangChain\necosystem, enhancing interaction with unstructured data and enabling advanced\ndata analysis. Experimental evaluations demonstrate significant improvements in\nprocess efficiency and scalability, as well as accurate data-driven\ndecision-making in diverse application scenarios.\n  This paper emphasizes the integration of Spark with intelligent agents and\ngraph-based workflows to redefine the development and execution of machine\nlearning tasks in big data environments, paving the way for scalable and\nuser-friendly AI solutions.",
      "tldr_zh": "这篇论文提出了一种基于 Spark 的模块化 LangGraph 框架，用于提升大数据机器学习工作流的 scalability（可扩展性）、visualization（可视化）和智能优化。框架的核心创新是 Agent AI，它利用 Spark 的分布式计算能力与 LangGraph 的工作流编排，自动化数据预处理、特征工程和模型评估，同时通过实时反馈和动态交互简化任务执行。实验结果显示，该框架显著提高了过程效率和决策准确性，并在各种应用场景中整合 LangChain 生态系统的大型语言模型，以支持高级数据分析和用户友好设计。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01490v4",
      "published_date": "2024-12-02 13:41:38 UTC",
      "updated_date": "2024-12-06 13:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:38:14.167350"
    },
    {
      "arxiv_id": "2412.01487v4",
      "title": "FastRM: An efficient and automatic explainability framework for multimodal generative models",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriela Ben-Melech Stan",
        "Estelle Aflalo",
        "Man Luo",
        "Shachar Rosenman",
        "Tiep Le",
        "Sayak Paul",
        "Shao-Yen Tseng",
        "Vasudev Lal"
      ],
      "abstract": "Large Vision Language Models (LVLMs) have demonstrated remarkable reasoning\ncapabilities over textual and visual inputs. However, these models remain prone\nto generating misinformation. Identifying and mitigating ungrounded responses\nis crucial for developing trustworthy AI. Traditional explainability methods\nsuch as gradient-based relevancy maps, offer insight into the decision process\nof models, but are often computationally expensive and unsuitable for real-time\noutput validation. In this work, we introduce FastRM, an efficient method for\npredicting explainable Relevancy Maps of LVLMs. Furthermore, FastRM provides\nboth quantitative and qualitative assessment of model confidence. Experimental\nresults demonstrate that FastRM achieves a 99.8% reduction in computation time\nand a 44.4% reduction in memory footprint compared to traditional relevancy map\ngeneration. FastRM allows explainable AI to be more practical and scalable,\nthereby promoting its deployment in real-world applications and enabling users\nto more effectively evaluate the reliability of model outputs.",
      "tldr_zh": "本研究针对Large Vision Language Models (LVLMs) 在处理文本和视觉输入时容易产生误信息的问题，提出了一种高效的解释框架FastRM，以提升AI的可信度。FastRM 通过自动预测可解释的Relevancy Maps，并提供模型置信度的定量和定性评估，显著降低了计算开销，与传统基于梯度的相关性映射方法相比，减少了99.8%的计算时间和44.4%的内存占用。实验结果证明，FastRM 使可解释AI更实用和可扩展，有助于在真实世界应用中评估模型输出的可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01487v4",
      "published_date": "2024-12-02 13:39:29 UTC",
      "updated_date": "2025-05-06 14:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:38:25.900276"
    },
    {
      "arxiv_id": "2412.01459v1",
      "title": "Misalignments in AI Perception: Quantitative Findings and Visual Mapping of How Experts and the Public Differ in Expectations and Risks, Benefits, and Value Judgments",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Brauner",
        "Felix Glawe",
        "Gian Luca Liehner",
        "Luisa Vervier",
        "Martina Ziefle"
      ],
      "abstract": "Artificial Intelligence (AI) is transforming diverse societal domains,\nraising critical questions about its risks and benefits and the misalignments\nbetween public expectations and academic visions. This study examines how the\ngeneral public (N=1110) -- people using or being affected by AI -- and academic\nAI experts (N=119) -- people shaping AI development -- perceive AI's\ncapabilities and impact across 71 scenarios, including sustainability,\nhealthcare, job performance, societal divides, art, and warfare. Participants\nevaluated each scenario on four dimensions: expected probability, perceived\nrisk and benefit, and overall sentiment (or value). The findings reveal\nsignificant quantitative differences: experts anticipate higher probabilities,\nperceive lower risks, report greater utility, and express more favorable\nsentiment toward AI compared to the non-experts. Notably, risk-benefit\ntradeoffs differ: the public assigns risk half the weight of benefits, while\nexperts assign it only a third. Visual maps of these evaluations highlight\nareas of convergence and divergence, identifying potential sources of public\nconcern. These insights offer actionable guidance for researchers and\npolicymakers to align AI development with societal values, fostering public\ntrust and informed governance.",
      "tldr_zh": "本研究调查了公众（N=1110）和AI专家（N=119）在71个场景中对AI能力的感知差异，包括预期概率、风险、益处和整体情感（sentiment），涵盖领域如可持续性、医疗和战争。结果显示，专家对AI的概率预期更高、风险感知更低，并赋予风险在risk-benefit tradeoffs中较低权重（约为益处的三分之一），而公众则将风险权重视为益处的一半。视觉映射突出了这些差异的收敛与分歧点，为研究者和政策制定者提供指导，以使AI发展更好地与社会价值观对齐，提升公众信任。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01459v1",
      "published_date": "2024-12-02 12:51:45 UTC",
      "updated_date": "2024-12-02 12:51:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:38:39.190926"
    },
    {
      "arxiv_id": "2412.01450v1",
      "title": "Artificial Intelligence for Geometry-Based Feature Extraction, Analysis and Synthesis in Artistic Images: A Survey",
      "title_zh": "人工智能在艺术图像中基于几何的特征提取、分析和合成：一个综述",
      "authors": [
        "Mridula Vijendran",
        "Jingjing Deng",
        "Shuang Chen",
        "Edmond S. L. Ho",
        "Hubert P. H. Shum"
      ],
      "abstract": "Artificial Intelligence significantly enhances the visual art industry by\nanalyzing, identifying and generating digitized artistic images. This review\nhighlights the substantial benefits of integrating geometric data into AI\nmodels, addressing challenges such as high inter-class variations, domain gaps,\nand the separation of style from content by incorporating geometric\ninformation. Models not only improve AI-generated graphics synthesis quality,\nbut also effectively distinguish between style and content, utilizing inherent\nmodel biases and shared data traits. We explore methods like geometric data\nextraction from artistic images, the impact on human perception, and its use in\ndiscriminative tasks. The review also discusses the potential for improving\ndata quality through innovative annotation techniques and the use of geometric\ndata to enhance model adaptability and output refinement. Overall,\nincorporating geometric guidance boosts model performance in classification and\nsynthesis tasks, providing crucial insights for future AI applications in the\nvisual arts domain.",
      "tldr_zh": "这篇调查回顾了AI在艺术图像中的几何基础特征提取、分析和合成应用，强调通过整合geometric data来解决高类间变异、domain gaps和风格与内容分离等挑战，从而提升AI生成图形的质量和模型适应性。论文探讨了从艺术图像中提取geometric data的方法、对人类感知的影响，以及在区分任务中的实际应用，同时提出创新的标注技术来改善数据质量。总体上，这种几何指导显著提高了AI模型在分类和合成任务中的性能，为视觉艺术领域的未来AI应用提供了关键洞见。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "56 pages, 8 tables, 1 figure (35 embedded images), Artificial\n  Intelligence Review (AIR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.01450v1",
      "published_date": "2024-12-02 12:41:15 UTC",
      "updated_date": "2024-12-02 12:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:38:50.386166"
    },
    {
      "arxiv_id": "2412.01447v1",
      "title": "PLD+: Accelerating LLM inference by leveraging Language Model Artifacts",
      "title_zh": "翻译失败",
      "authors": [
        "Shwetha Somasundaram",
        "Anirudh Phukan",
        "Apoorv Saxena"
      ],
      "abstract": "To reduce the latency associated with autoretrogressive LLM inference,\nspeculative decoding has emerged as a novel decoding paradigm, where future\ntokens are drafted and verified in parallel. However, the practical deployment\nof speculative decoding is hindered by its requirements for additional\ncomputational resources and fine-tuning, which limits its out-of-the-box\nusability. To address these challenges, we present PLD+, a suite of novel\nalgorithms developed to accelerate the inference process of LLMs, particularly\nfor input-guided tasks. These tasks, which include code editing, text editing,\nsummarization, etc., often feature outputs with substantial overlap with their\ninputs-an attribute PLD+ is designed to exploit. PLD+ also leverages the\nartifacts (attention and hidden states) generated during inference to\naccelerate inference speed. We test our approach on five input-guided tasks and\nthrough extensive experiments we find that PLD+ outperforms all tuning-free\napproaches. In the greedy setting, it even outperforms the state-of-the-art\ntuning-dependent approach EAGLE on four of the tasks. (by a margin of upto 2.31\nin terms of avg. speedup). Our approach is tuning free, does not require any\nadditional compute and can easily be used for accelerating inference of any\nLLM.",
      "tldr_zh": "该研究提出 PLD+，一套新算法，用于加速大型语言模型（LLM）的推理过程，针对输入引导任务（如代码编辑、文本编辑和总结）利用模型 artifacts（如 attention 和 hidden states）来减少延迟。PLD+ 巧妙地利用任务输出与输入的重叠特性，避免了额外计算资源和微调需求，从而提升推理效率。在实验中，PLD+ 在五个输入引导任务上超越了所有无微调方法，并在贪婪设置下比最先进的依赖微调方法 EAGLE 平均加速提高了多达 2.31 倍，提供了一种即插即用的 LLM 推理优化方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01447v1",
      "published_date": "2024-12-02 12:36:27 UTC",
      "updated_date": "2024-12-02 12:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:39:01.656057"
    },
    {
      "arxiv_id": "2412.01443v1",
      "title": "Multi-Facet Blending for Faceted Query-by-Example Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Heejin Do",
        "Sangwon Ryu",
        "Jonghwi Kim",
        "Gary Geunbae Lee"
      ],
      "abstract": "With the growing demand to fit fine-grained user intents, faceted\nquery-by-example (QBE), which retrieves similar documents conditioned on\nspecific facets, has gained recent attention. However, prior approaches mainly\ndepend on document-level comparisons using basic indicators like citations due\nto the lack of facet-level relevance datasets; yet, this limits their use to\ncitation-based domains and fails to capture the intricacies of facet\nconstraints. In this paper, we propose a multi-facet blending (FaBle)\naugmentation method, which exploits modularity by decomposing and recomposing\nto explicitly synthesize facet-specific training sets. We automatically\ndecompose documents into facet units and generate (ir)relevant pairs by\nleveraging LLMs' intrinsic distinguishing capabilities; then, dynamically\nrecomposing the units leads to facet-wise relevance-informed document pairs.\nOur modularization eliminates the need for pre-defined facet knowledge or\nlabels. Further, to prove the FaBle's efficacy in a new domain beyond\ncitation-based scientific paper retrieval, we release a benchmark dataset for\neducational exam item QBE. FaBle augmentation on 1K documents remarkably\nassists training in obtaining facet conditional embeddings.",
      "tldr_zh": "本论文提出 Multi-Facet Blending (FaBle) 方法，以提升 Faceted Query-by-Example (QBE) 检索的性能，该方法通过分解文档为 facet 单位并利用 LLMs 生成相关/不相关对，再动态重组单位，合成 facet-specific 训练集，从而避免依赖预定义 facet 知识。FaBle 的模块化设计使得其适用于非引用型领域，并发布了首个教育考试项目 QBE 基准数据集。实验结果显示，在 1K 文档上，该方法显著改善了 facet 条件嵌入的训练效果。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01443v1",
      "published_date": "2024-12-02 12:32:19 UTC",
      "updated_date": "2024-12-02 12:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:39:14.759859"
    },
    {
      "arxiv_id": "2412.01441v2",
      "title": "LMAct: A Benchmark for In-Context Imitation Learning with Long Multimodal Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Anian Ruoss",
        "Fabio Pardo",
        "Harris Chan",
        "Bonnie Li",
        "Volodymyr Mnih",
        "Tim Genewein"
      ],
      "abstract": "In this paper, we present a benchmark to pressure-test today's frontier\nmodels' multimodal decision-making capabilities in the very long-context regime\n(up to one million tokens) and investigate whether these models can learn from\nlarge numbers of expert demonstrations in their context. We evaluate the\nperformance of Claude 3.5 Sonnet, Gemini 1.5 Flash, Gemini 1.5 Pro, Gemini 2.0\nFlash Experimental, GPT-4o, o1-mini, o1-preview, and o1 as policies across a\nbattery of simple interactive decision-making tasks: playing tic-tac-toe,\nchess, and Atari, navigating grid worlds, solving crosswords, and controlling a\nsimulated cheetah. We study increasing amounts of expert demonstrations in the\ncontext $\\unicode{x2013}$ from no demonstrations to 512 full episodes. Across\nour tasks, models rarely manage to fully reach expert performance, and often,\npresenting more demonstrations has little effect. Some models steadily improve\nwith more demonstrations on a few tasks. We investigate the effect of encoding\nobservations as text or images and the impact of chain-of-thought prompting. To\nhelp quantify the impact of other approaches and future innovations, we open\nsource our benchmark that covers the zero-, few-, and many-shot regimes in a\nunified evaluation.",
      "tldr_zh": "本文提出 LMAct 基准，用于评估前沿模型在长上下文（up to one million tokens）下的多模态决策能力和 in-context imitation learning 性能，具体测试模型从专家演示中学习的效果。研究评估了 Claude 3.5 Sonnet、Gemini 系列、GPT-4o 和 o1 系列等模型，在 tic-tac-toe、chess、Atari 游戏、网格世界导航、填字游戏和模拟 cheetah 控制等任务上的表现，探索从无演示到 512 个完整剧集的演示数量影响，以及观察编码为文本或图像和 chain-of-thought prompting 的作用。结果显示，模型很少达到专家水平，增加演示往往无效，但在少数任务上某些模型能稳步改进；为促进未来创新，论文开源了该基准，支持 zero-, few-, and many-shot 情境的统一评估。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01441v2",
      "published_date": "2024-12-02 12:31:58 UTC",
      "updated_date": "2025-02-03 23:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:39:26.768700"
    },
    {
      "arxiv_id": "2412.01430v1",
      "title": "MVImgNet2.0: A Larger-scale Dataset of Multi-view Images",
      "title_zh": "MVImgNet2.0：一个更大规模的多视图图像数据集",
      "authors": [
        "Xiaoguang Han",
        "Yushuang Wu",
        "Luyue Shi",
        "Haolin Liu",
        "Hongjie Liao",
        "Lingteng Qiu",
        "Weihao Yuan",
        "Xiaodong Gu",
        "Zilong Dong",
        "Shuguang Cui"
      ],
      "abstract": "MVImgNet is a large-scale dataset that contains multi-view images of ~220k\nreal-world objects in 238 classes. As a counterpart of ImageNet, it introduces\n3D visual signals via multi-view shooting, making a soft bridge between 2D and\n3D vision. This paper constructs the MVImgNet2.0 dataset that expands MVImgNet\ninto a total of ~520k objects and 515 categories, which derives a 3D dataset\nwith a larger scale that is more comparable to ones in the 2D domain. In\naddition to the expanded dataset scale and category range, MVImgNet2.0 is of a\nhigher quality than MVImgNet owing to four new features: (i) most shoots\ncapture 360-degree views of the objects, which can support the learning of\nobject reconstruction with completeness; (ii) the segmentation manner is\nadvanced to produce foreground object masks of higher accuracy; (iii) a more\npowerful structure-from-motion method is adopted to derive the camera pose for\neach frame of a lower estimation error; (iv) higher-quality dense point clouds\nare reconstructed via advanced methods for objects captured in 360-degree\nviews, which can serve for downstream applications. Extensive experiments\nconfirm the value of the proposed MVImgNet2.0 in boosting the performance of\nlarge 3D reconstruction models. MVImgNet2.0 will be public at\nluyues.github.io/mvimgnet2, including multi-view images of all 520k objects,\nthe reconstructed high-quality point clouds, and data annotation codes, hoping\nto inspire the broader vision community.",
      "tldr_zh": "本研究构建了 MVImgNet2.0，这是一个扩展版的图像数据集，包含约520k个真实世界物体和515个类别，比原 MVImgNet 规模更大，并作为 ImageNet 的对应物，通过多视图拍摄桥接了2D和3D视觉。相比前作，该数据集引入了四大改进：(i) 大多数拍摄覆盖物体的360度视图，支持更完整的对象重建；(ii) 先进的分割方法提供更高准确性的前景对象掩码；(iii) 更精确的结构-from-motion 方法降低相机位姿估计错误；(iv) 使用高级技术重建更高质量的密集点云。实验结果显示，MVImgNet2.0 显著提升了大型3D重建模型的性能，并将公开包括多视图图像、高质量点云和数据注释代码，以促进视觉社区的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM Transactions on Graphics (TOG), SIGGRAPH Asia 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.01430v1",
      "published_date": "2024-12-02 12:10:04 UTC",
      "updated_date": "2024-12-02 12:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:39:38.478833"
    },
    {
      "arxiv_id": "2412.01425v1",
      "title": "Reject Threshold Adaptation for Open-Set Model Attribution of Deepfake Audio",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrui Yan",
        "Jiangyan Yi",
        "Jianhua Tao",
        "Yujie Chen",
        "Hao Gu",
        "Guanjun Li",
        "Junzuo Zhou",
        "Yong Ren",
        "Tao Xu"
      ],
      "abstract": "Open environment oriented open set model attribution of deepfake audio is an\nemerging research topic, aiming to identify the generation models of deepfake\naudio. Most previous work requires manually setting a rejection threshold for\nunknown classes to compare with predicted probabilities. However, models often\noverfit training instances and generate overly confident predictions. Moreover,\nthresholds that effectively distinguish unknown categories in the current\ndataset may not be suitable for identifying known and unknown categories in\nanother data distribution. To address the issues, we propose a novel framework\nfor open set model attribution of deepfake audio with rejection threshold\nadaptation (ReTA). Specifically, the reconstruction error learning module\ntrains by combining the representation of system fingerprints with labels\ncorresponding to either the target class or a randomly chosen other class\nlabel. This process generates matching and non-matching reconstructed samples,\nestablishing the reconstruction error distributions for each class and laying\nthe foundation for the reject threshold calculation module. The reject\nthreshold calculation module utilizes gaussian probability estimation to fit\nthe distributions of matching and non-matching reconstruction errors. It then\ncomputes adaptive reject thresholds for all classes through probability\nminimization criteria. The experimental results demonstrate the effectiveness\nof ReTA in improving the open set model attributes of deepfake audio.",
      "tldr_zh": "这篇论文针对深度伪造音频的开放集模型归因（open-set model attribution）问题，提出了一种新框架ReTA（Rejection Threshold Adaptation），以解决手动设置拒绝阈值导致的过拟合和数据分布不适配问题。ReTA框架包括重建错误学习模块，该模块通过结合系统指纹表示和标签生成匹配及非匹配的重建样本，建立每个类的重建错误分布；以及拒绝阈值计算模块，使用高斯概率估计拟合这些分布，并通过概率最小化标准计算自适应阈值。实验结果证明，ReTA显著提升了深度伪造音频的开放集模型归因性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ISCSLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.01425v1",
      "published_date": "2024-12-02 12:06:50 UTC",
      "updated_date": "2024-12-02 12:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:39:50.724921"
    },
    {
      "arxiv_id": "2412.01419v2",
      "title": "CSP-AIT-Net: A contrastive learning-enhanced spatiotemporal graph attention framework for short-term metro OD flow prediction with asynchronous inflow tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Wang",
        "Chengcheng Yu"
      ],
      "abstract": "Accurate origin-destination (OD) passenger flow prediction is crucial for\nenhancing metro system efficiency, optimizing scheduling, and improving\npassenger experiences. However, current models often fail to effectively\ncapture the asynchronous departure characteristics of OD flows and underutilize\nthe inflow and outflow data, which limits their prediction accuracy. To address\nthese issues, we propose CSP-AIT-Net, a novel spatiotemporal graph attention\nframework designed to enhance OD flow prediction by incorporating asynchronous\ninflow tracking and advanced station semantics representation. Our framework\nrestructures the OD flow prediction paradigm by first predicting outflows and\nthen decomposing OD flows using a spatiotemporal graph attention mechanism. To\nenhance computational efficiency, we introduce a masking mechanism and propose\nasynchronous passenger flow graphs that integrate inflow and OD flow with\nconservation constraints. Furthermore, we employ contrastive learning to\nextract high-dimensional land use semantics of metro stations, enriching the\ncontextual understanding of passenger mobility patterns. Validation of the\nShanghai metro system demonstrates improvement in short-term OD flow prediction\naccuracy over state-of-the-art methods. This work contributes to enhancing\nmetro operational efficiency, scheduling precision, and overall system safety.",
      "tldr_zh": "该论文提出 CSP-AIT-Net，一种基于对比学习的时空图注意力框架，用于短期地铁 OD flow 预测，通过异步 inflow tracking 和高级站点语义表示来解决现有模型对异步出发特性和进出站数据利用不足的问题。该框架重构预测范式，先预测出站流量，然后使用时空图注意力机制分解 OD flow，并引入掩码机制和异步客流图以确保计算效率和守恒约束。同时，通过对比学习提取地铁站的高维土地使用语义，丰富乘客流动模式理解。在上海地铁系统的验证中，CSP-AIT-Net 显著提高了预测准确性，超过了最先进方法，从而提升了地铁运营效率、调度精度和系统安全。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "Due to unresolved disagreements among the authorship team regarding\n  the interpretation of the findings and attribution of contributions",
      "pdf_url": "http://arxiv.org/pdf/2412.01419v2",
      "published_date": "2024-12-02 12:00:06 UTC",
      "updated_date": "2025-02-08 15:51:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:40:02.327039"
    },
    {
      "arxiv_id": "2412.01417v1",
      "title": "Learning Elementary Cellular Automata with Transformers",
      "title_zh": "使用 Transformer 学习基本细胞自动机",
      "authors": [
        "Mikhail Burtsev"
      ],
      "abstract": "Large Language Models demonstrate remarkable mathematical capabilities but at\nthe same time struggle with abstract reasoning and planning. In this study, we\nexplore whether Transformers can learn to abstract and generalize the rules\ngoverning Elementary Cellular Automata. By training Transformers on state\nsequences generated with random initial conditions and local rules, we show\nthat they can generalize across different Boolean functions of fixed arity,\neffectively abstracting the underlying rules. While the models achieve high\naccuracy in next-state prediction, their performance declines sharply in\nmulti-step planning tasks without intermediate context. Our analysis reveals\nthat including future states or rule prediction in the training loss enhances\nthe models' ability to form internal representations of the rules, leading to\nimproved performance in longer planning horizons and autoregressive generation.\nFurthermore, we confirm that increasing the model's depth plays a crucial role\nin extended sequential computations required for complex reasoning tasks. This\nhighlights the potential to improve LLM with inclusion of longer horizons in\nloss function, as well as incorporating recurrence and adaptive computation\ntime for dynamic control of model depth.",
      "tldr_zh": "本研究探讨了 Transformers 是否能学习和概括 Elementary Cellular Automata 的规则，通过训练模型处理随机初始条件和局部规则生成的状态序列。结果显示，模型在下一个状态预测上表现出高准确率，但多步规划任务中性能急剧下降，除非在训练损失中加入未来状态或规则预测。分析表明，这种改进能增强模型对规则的内部表示，提升长规划视野和自回归生成能力。此外，增加模型深度对复杂推理任务的扩展序列计算至关重要，为改善 Large Language Models 的设计提供潜在启示，如通过更长视野损失函数和自适应计算时间。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01417v1",
      "published_date": "2024-12-02 11:57:49 UTC",
      "updated_date": "2024-12-02 11:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:40:13.552227"
    },
    {
      "arxiv_id": "2412.01408v3",
      "title": "Towards Cross-Lingual Audio Abuse Detection in Low-Resource Settings with Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Narayan Sankaran",
        "Reza Farahbakhsh",
        "Noel Crespi"
      ],
      "abstract": "Online abusive content detection, particularly in low-resource settings and\nwithin the audio modality, remains underexplored. We investigate the potential\nof pre-trained audio representations for detecting abusive language in\nlow-resource languages, in this case, in Indian languages using Few Shot\nLearning (FSL). Leveraging powerful representations from models such as Wav2Vec\nand Whisper, we explore cross-lingual abuse detection using the ADIMA dataset\nwith FSL. Our approach integrates these representations within the\nModel-Agnostic Meta-Learning (MAML) framework to classify abusive language in\n10 languages. We experiment with various shot sizes (50-200) evaluating the\nimpact of limited data on performance. Additionally, a feature visualization\nstudy was conducted to better understand model behaviour. This study highlights\nthe generalization ability of pre-trained models in low-resource scenarios and\noffers valuable insights into detecting abusive language in multilingual\ncontexts.",
      "tldr_zh": "本文研究了在低资源环境中使用 Few-Shot Learning (FSL) 进行跨语言音频滥用检测，针对印度语言的在线滥用内容问题。作者利用 Wav2Vec 和 Whisper 的预训练音频表示，结合 Model-Agnostic Meta-Learning (MAML) 框架，在 ADIMA 数据集上对 10 种语言进行分类实验，并评估了不同样本大小 (50-200) 对性能的影响。实验结果显示，预训练模型在数据有限的场景中表现出良好的泛化能力，并通过特征可视化研究揭示了模型行为，提供宝贵的多语言滥用检测见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as part of the proceedings of COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01408v3",
      "published_date": "2024-12-02 11:51:19 UTC",
      "updated_date": "2024-12-13 11:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:40:26.422071"
    },
    {
      "arxiv_id": "2412.01405v1",
      "title": "MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation",
      "title_zh": "MambaU-Lite：一种基于 Mamba 并集成了通道-空间注意力的轻量级模型，用于皮肤病变分割",
      "authors": [
        "Thi-Nhu-Quynh Nguyen",
        "Quang-Huy Ho",
        "Duy-Thai Nguyen",
        "Hoang-Minh-Quang Le",
        "Van-Truong Pham",
        "Thi-Thao Tran"
      ],
      "abstract": "Early detection of skin abnormalities plays a crucial role in diagnosing and\ntreating skin cancer. Segmentation of affected skin regions using AI-powered\ndevices is relatively common and supports the diagnostic process. However,\nachieving high performance remains a significant challenge due to the need for\nhigh-resolution images and the often unclear boundaries of individual lesions.\nAt the same time, medical devices require segmentation models to have a small\nmemory foot-print and low computational cost. Based on these requirements, we\nintroduce a novel lightweight model called MambaU-Lite, which combines the\nstrengths of Mamba and CNN architectures, featuring just over 400K parameters\nand a computational cost of more than 1G flops. To enhance both global context\nand local feature extraction, we propose the P-Mamba block, a novel component\nthat incorporates VSS blocks along-side multiple pooling layers, enabling the\nmodel to effectively learn multiscale features and enhance segmentation\nperformance. We evaluate the model's performance on two skin datasets, ISIC2018\nand PH2, yielding promising results. Our source code will be made publicly\navailable at: https://github.com/nqnguyen812/MambaU-Lite.",
      "tldr_zh": "本研究针对皮肤病变分割的挑战（如图像分辨率需求和边界模糊），提出了一种轻量级模型MambaU-Lite，该模型结合Mamba和CNN架构，仅有40万多参数和低计算成本（超过1G FLOPs），以满足医疗设备的资源限制。核心创新是引入P-Mamba block，该组件整合VSS blocks和多层池化层，能够增强全局上下文和局部特征提取，实现多尺度特征学习，从而提高分割性能。在ISIC2018和PH2数据集上的评估显示，该模型取得了有前景的结果，证明其在皮肤异常早期检测中的实用价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.01405v1",
      "published_date": "2024-12-02 11:49:49 UTC",
      "updated_date": "2024-12-02 11:49:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:40:38.593771"
    },
    {
      "arxiv_id": "2412.01400v1",
      "title": "Fire-Image-DenseNet (FIDN) for predicting wildfire burnt area using remote sensing data",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Pang",
        "Sibo Cheng",
        "Yuhan Huang",
        "Yufang Jin",
        "Yike Guo",
        "I. Colin Prentice",
        "Sandy P. Harrison",
        "Rossella Arcucci"
      ],
      "abstract": "Predicting the extent of massive wildfires once ignited is essential to\nreduce the subsequent socioeconomic losses and environmental damage, but\nchallenging because of the complexity of fire behaviour. Existing physics-based\nmodels are limited in predicting large or long-duration wildfire events. Here,\nwe develop a deep-learning-based predictive model, Fire-Image-DenseNet (FIDN),\nthat uses spatial features derived from both near real-time and reanalysis data\non the environmental and meteorological drivers of wildfire. We trained and\ntested this model using more than 300 individual wildfires that occurred\nbetween 2012 and 2019 in the western US. In contrast to existing models, the\nperformance of FIDN does not degrade with fire size or duration. Furthermore,\nit predicts final burnt area accurately even in very heterogeneous landscapes\nin terms of fuel density and flammability. The FIDN model showed higher\naccuracy, with a mean squared error (MSE) about 82% and 67% lower than those of\nthe predictive models based on cellular automata (CA) and the minimum travel\ntime (MTT) approaches, respectively. Its structural similarity index measure\n(SSIM) averages 97%, outperforming the CA and FlamMap MTT models by 6% and 2%,\nrespectively. Additionally, FIDN is approximately three orders of magnitude\nfaster than both CA and MTT models. The enhanced computational efficiency and\naccuracy advancements offer vital insights for strategic planning and resource\nallocation for firefighting operations.",
      "tldr_zh": "本研究开发了Fire-Image-DenseNet (FIDN)，一个基于深度学习的模型，用于利用遥感数据预测野火烧毁面积，旨在克服现有物理模型在处理大型或长期野火时的局限性。FIDN 整合了环境和气象驱动因素的空间特征，并使用2012-2019年间美国西部超过300个野火事件的数据进行训练和测试。结果显示，FIDN的性能不受火规模或持续时间影响，其mean squared error (MSE)比cellular automata (CA)和minimum travel time (MTT)模型分别低82%和67%，structural similarity index measure (SSIM)平均达97%，并在异质景观中表现出色。此外，FIDN的计算效率高出三倍，为野火消防战略规划和资源分配提供关键洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01400v1",
      "published_date": "2024-12-02 11:35:31 UTC",
      "updated_date": "2024-12-02 11:35:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:40:49.962849"
    },
    {
      "arxiv_id": "2412.01383v2",
      "title": "Second FRCSyn-onGoing: Winning Solutions and Post-Challenge Analysis to Improve Face Recognition with Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan DeAndres-Tame",
        "Ruben Tolosana",
        "Pietro Melzi",
        "Ruben Vera-Rodriguez",
        "Minchul Kim",
        "Christian Rathgeb",
        "Xiaoming Liu",
        "Luis F. Gomez",
        "Aythami Morales",
        "Julian Fierrez",
        "Javier Ortega-Garcia",
        "Zhizhou Zhong",
        "Yuge Huang",
        "Yuxi Mi",
        "Shouhong Ding",
        "Shuigeng Zhou",
        "Shuai He",
        "Lingzhi Fu",
        "Heng Cong",
        "Rongyu Zhang",
        "Zhihong Xiao",
        "Evgeny Smirnov",
        "Anton Pimenov",
        "Aleksei Grigorev",
        "Denis Timoshenko",
        "Kaleb Mesfin Asfaw",
        "Cheng Yaw Low",
        "Hao Liu",
        "Chuyi Wang",
        "Qing Zuo",
        "Zhixiang He",
        "Hatef Otroshi Shahreza",
        "Anjith George",
        "Alexander Unnervik",
        "Parsa Rahimi",
        "Sébastien Marcel",
        "Pedro C. Neto",
        "Marco Huber",
        "Jan Niklas Kolf",
        "Naser Damer",
        "Fadi Boutros",
        "Jaime S. Cardoso",
        "Ana F. Sequeira",
        "Andrea Atzori",
        "Gianni Fenu",
        "Mirko Marras",
        "Vitomir Štruc",
        "Jiang Yu",
        "Zhangjie Li",
        "Jichun Li",
        "Weisong Zhao",
        "Zhen Lei",
        "Xiangyu Zhu",
        "Xiao-Yu Zhang",
        "Bernardo Biesseck",
        "Pedro Vidal",
        "Luiz Coelho",
        "Roger Granada",
        "David Menotti"
      ],
      "abstract": "Synthetic data is gaining increasing popularity for face recognition\ntechnologies, mainly due to the privacy concerns and challenges associated with\nobtaining real data, including diverse scenarios, quality, and demographic\ngroups, among others. It also offers some advantages over real data, such as\nthe large amount of data that can be generated or the ability to customize it\nto adapt to specific problem-solving needs. To effectively use such data, face\nrecognition models should also be specifically designed to exploit synthetic\ndata to its fullest potential. In order to promote the proposal of novel\nGenerative AI methods and synthetic data, and investigate the application of\nsynthetic data to better train face recognition systems, we introduce the 2nd\nFRCSyn-onGoing challenge, based on the 2nd Face Recognition Challenge in the\nEra of Synthetic Data (FRCSyn), originally launched at CVPR 2024. This is an\nongoing challenge that provides researchers with an accessible platform to\nbenchmark i) the proposal of novel Generative AI methods and synthetic data,\nand ii) novel face recognition systems that are specifically proposed to take\nadvantage of synthetic data. We focus on exploring the use of synthetic data\nboth individually and in combination with real data to solve current challenges\nin face recognition such as demographic bias, domain adaptation, and\nperformance constraints in demanding situations, such as age disparities\nbetween training and testing, changes in the pose, or occlusions. Very\ninteresting findings are obtained in this second edition, including a direct\ncomparison with the first one, in which synthetic databases were restricted to\nDCFace and GANDiffFace.",
      "tldr_zh": "这篇论文介绍了第二届 FRCSyn-onGoing 挑战赛及其获胜方案和后续分析，旨在通过 synthetic data 提升面部识别技术的性能，以解决隐私问题和真实数据获取的挑战。挑战赛鼓励提出新型 Generative AI 方法和专为 synthetic data 设计的面部识别系统，焦点包括使用合成数据单独或与真实数据结合，处理人口偏差（demographic bias）、领域适应（domain adaptation）以及姿态变化或遮挡等难题。实验结果与第一届挑战赛比较显示，合成数据显著改善了面部识别的鲁棒性，并提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in Information Fusion",
      "pdf_url": "http://arxiv.org/pdf/2412.01383v2",
      "published_date": "2024-12-02 11:12:01 UTC",
      "updated_date": "2025-03-10 09:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:41:02.597827"
    },
    {
      "arxiv_id": "2412.01378v1",
      "title": "A Survey on Deep Neural Networks in Collaborative Filtering Recommendation Systems",
      "title_zh": "深度神经网络在协同过滤推荐系统中的综述",
      "authors": [
        "Pang Li",
        "Shahrul Azman Mohd Noah",
        "Hafiz Mohd Sarim"
      ],
      "abstract": "This survey provides an examination of the use of Deep Neural Networks (DNN)\nin Collaborative Filtering (CF) recommendation systems. As the digital world\nincreasingly relies on data-driven approaches, traditional CF techniques face\nlimitations in scalability and flexibility. DNNs can address these challenges\nby effectively modeling complex, non-linear relationships within the data. We\nbegin by exploring the fundamental principles of both collaborative filtering\nand deep neural networks, laying the groundwork for understanding their\nintegration. Subsequently, we review key advancements in the field,\ncategorizing various deep learning models that enhance CF systems, including\nMultilayer Perceptrons (MLP), Convolutional Neural Networks (CNN), Recurrent\nNeural Networks (RNN), Graph Neural Networks (GNN), autoencoders, Generative\nAdversarial Networks (GAN), and Restricted Boltzmann Machines (RBM). The paper\nalso discusses evaluation protocols, various publicly available auxiliary\ninformation, and data features. Furthermore, the survey concludes with a\ndiscussion of the challenges and future research opportunities in enhancing\ncollaborative filtering systems with deep learning.",
      "tldr_zh": "这篇调查论文探讨了深度神经网络 (DNN) 在协同过滤 (CF) 推荐系统中的应用，强调 DNN 如何通过建模复杂非线性关系来克服传统 CF 技术的可扩展性和灵活性局限性。论文回顾了 CF 和 DNN 的基础原理，并分类了各种增强 CF 系统的深度学习模型，包括 Multilayer Perceptrons (MLP)、Convolutional Neural Networks (CNN)、Recurrent Neural Networks (RNN)、Graph Neural Networks (GNN)、autoencoders、Generative Adversarial Networks (GAN) 和 Restricted Boltzmann Machines (RBM)，同时讨论了评估协议、辅助信息和数据特征。最终，它总结了当前挑战，如数据隐私和模型泛化问题，并指出了未来研究机会，以进一步提升推荐系统的性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01378v1",
      "published_date": "2024-12-02 11:06:34 UTC",
      "updated_date": "2024-12-02 11:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:41:14.017065"
    },
    {
      "arxiv_id": "2412.01376v1",
      "title": "Convolutional Transformer Neural Collaborative Filtering",
      "title_zh": "卷积 Transformer 神经协同过滤",
      "authors": [
        "Pang Li",
        "Shahrul Azman Mohd Noah",
        "Hafiz Mohd Sarim"
      ],
      "abstract": "In this study, we introduce Convolutional Transformer Neural Collaborative\nFiltering (CTNCF), a novel approach aimed at enhancing recommendation systems\nby effectively capturing high-order structural information in user-item\ninteractions. CTNCF represents a significant advancement over the traditional\nNeural Collaborative Filtering (NCF) model by seamlessly integrating\nConvolutional Neural Networks (CNNs) and Transformer layers. This sophisticated\nintegration enables the model to adeptly capture and understand complex\ninteraction patterns inherent in recommendation systems. Specifically, CNNs are\nemployed to extract local features from user and item embeddings, allowing the\nmodel to capture intricate spatial dependencies within the data. Furthermore,\nthe utilization of Transformer layers enables the model to capture long-range\ndependencies and interactions among user and item features, thereby enhancing\nits ability to understand the underlying relationships in the data. To validate\nthe effectiveness of our proposed CTNCF framework, we conduct extensive\nexperiments on two real-world datasets. The results demonstrate that CTNCF\nsignificantly outperforms state-of-the-art approaches, highlighting its\nefficacy in improving recommendation system performance.",
      "tldr_zh": "本文提出Convolutional Transformer Neural Collaborative Filtering (CTNCF)，一种新型推荐系统方法，通过整合Convolutional Neural Networks (CNNs)和Transformer层来捕获用户-物品交互中的高阶结构信息。CTNCF利用CNNs提取用户和物品嵌入的局部特征，并通过Transformer层处理长距离依赖和交互关系，从而提升对数据关系的理解。与传统Neural Collaborative Filtering (NCF)相比，该模型在两个真实数据集上的实验结果显示，CTNCF显著优于现有方法，提高了推荐系统的整体性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01376v1",
      "published_date": "2024-12-02 11:01:31 UTC",
      "updated_date": "2024-12-02 11:01:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:41:25.334562"
    },
    {
      "arxiv_id": "2412.01371v1",
      "title": "An overview of diffusion models for generative artificial intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Gallon",
        "Arnulf Jentzen",
        "Philippe von Wurstemberger"
      ],
      "abstract": "This article provides a mathematically rigorous introduction to denoising\ndiffusion probabilistic models (DDPMs), sometimes also referred to as diffusion\nprobabilistic models or diffusion models, for generative artificial\nintelligence. We provide a detailed basic mathematical framework for DDPMs and\nexplain the main ideas behind training and generation procedures. In this\noverview article we also review selected extensions and improvements of the\nbasic framework from the literature such as improved DDPMs, denoising diffusion\nimplicit models, classifier-free diffusion guidance models, and latent\ndiffusion models.",
      "tldr_zh": "这篇文章对用于生成式人工智能的去噪扩散概率模型（DDPMs）进行了数学严格的概述，介绍了其基本框架、训练过程和生成机制的核心原理。论文详细解释了 DDPMs 的工作原理，包括如何通过扩散过程实现数据生成。作者还审阅了文献中的关键扩展，如 improved DDPMs、去噪扩散隐式模型（denoising diffusion implicit models）、无分类器扩散指导模型（classifier-free diffusion guidance models）和潜在扩散模型（latent diffusion models），为研究者提供了一个全面的参考框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "56 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01371v1",
      "published_date": "2024-12-02 10:55:38 UTC",
      "updated_date": "2024-12-02 10:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:41:37.312660"
    },
    {
      "arxiv_id": "2412.01372v1",
      "title": "Research on Cervical Cancer p16/Ki-67 Immunohistochemical Dual-Staining Image Recognition Algorithm Based on YOLO",
      "title_zh": "基于 YOLO 的宫颈癌 p16/Ki-67 免疫",
      "authors": [
        "Xiao-Jun Wu",
        "Cai-Jun Zhao",
        "Chun Meng",
        "Hang Wang"
      ],
      "abstract": "The p16/Ki-67 dual staining method is a new approach for cervical cancer\nscreening with high sensitivity and specificity. However, there are issues of\nmis-detection and inaccurate recognition when the YOLOv5s algorithm is directly\napplied to dual-stained cell images. This paper Proposes a novel cervical\ncancer dual-stained image recognition (DSIR-YOLO) model based on an YOLOv5. By\nfusing the Swin-Transformer module, GAM attention mechanism, multi-scale\nfeature fusion, and EIoU loss function, the detection performance is\nsignificantly improved, with mAP@0.5 and mAP@0.5:0.95 reaching 92.6% and 70.5%,\nrespectively. Compared with YOLOv5s in five-fold cross-validation, the\naccuracy, recall, mAP@0.5, and mAP@0.5:0.95 of the improved algorithm are\nincreased by 2.3%, 4.1%, 4.3%, and 8.0%, respectively, with smaller variances\nand higher stability. Compared with other detection algorithms, DSIR-YOLO in\nthis paper sacrifices some performance requirements to improve the network\nrecognition effect. In addition, the influence of dataset quality on the\ndetection results is studied. By controlling the sealing property of pixels,\nscale difference, unlabelled cells, and diagonal annotation, the model\ndetection accuracy, recall, mAP@0.5, and mAP@0.5:0.95 are improved by 13.3%,\n15.3%, 18.3%, and 30.5%, respectively.",
      "tldr_zh": "本研究针对 YOLOv5s 算法在 p16/Ki-67 双染色宫颈癌图像识别中存在的误检测和不准确问题，提出了一种改进模型 DSIR-YOLO。模型通过融合 Swin-Transformer 模块、GAM attention mechanism、多尺度特征融合和 EIoU loss function，显著提升了检测性能，使 mAP@0.5 和 mAP@0.5:0.95 分别达到 92.6% 和 70.5%。与 YOLOv5s 相比，DSIR-YOLO 的准确率、召回率、mAP@0.5 和 mAP@0.5:0.95 分别提高了 2.3%、4.1%、4.3% 和 8.0%，并表现出更小的方差和更高的稳定性。此外，研究发现优化数据集质量（如控制像素密封性、尺度差异、无标签细胞和对角注释）可进一步提升模型性能，使准确率、召回率、mAP@0.5 和 mAP@0.5:0.95 分别提高 13.3%、15.3%、18.3% 和 30.5%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01372v1",
      "published_date": "2024-12-02 10:55:38 UTC",
      "updated_date": "2024-12-02 10:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:41:52.191730"
    },
    {
      "arxiv_id": "2412.01369v1",
      "title": "Behavior Backdoor for Deep Learning Models",
      "title_zh": "行为后门针对深度学习模型",
      "authors": [
        "Jiakai Wang",
        "Pengfei Zhang",
        "Renshuai Tao",
        "Jian Yang",
        "Hao Liu",
        "Xianglong Liu",
        "Yunchao Wei",
        "Yao Zhao"
      ],
      "abstract": "The various post-processing methods for deep-learning-based models, such as\nquantification, pruning, and fine-tuning, play an increasingly important role\nin artificial intelligence technology, with pre-train large models as one of\nthe main development directions. However, this popular series of\npost-processing behaviors targeting pre-training deep models has become a\nbreeding ground for new adversarial security issues. In this study, we take the\nfirst step towards ``behavioral backdoor'' attack, which is defined as a\nbehavior-triggered backdoor model training procedure, to reveal a new paradigm\nof backdoor attacks. In practice, we propose the first pipeline of implementing\nbehavior backdoor, i.e., the Quantification Backdoor (QB) attack, upon\nexploiting model quantification method as the set trigger. Specifically, to\nadapt the optimization goal of behavior backdoor, we introduce the\nbehavior-driven backdoor object optimizing method by a bi-target behavior\nbackdoor training loss, thus we could guide the poisoned model optimization\ndirection. To update the parameters across multiple models, we adopt the\naddress-shared backdoor model training, thereby the gradient information could\nbe utilized for multimodel collaborative optimization. Extensive experiments\nhave been conducted on different models, datasets, and tasks, demonstrating the\neffectiveness of this novel backdoor attack and its potential application\nthreats.",
      "tldr_zh": "本论文首次提出“行为后门”（behavioral backdoor）攻击，这是一种通过后处理行为（如量化、剪枝和微调）触发的后门模型训练方法，揭示了预训练深度学习模型的安全隐患。研究者设计了“Quantification Backdoor (QB) attack”管道，使用模型量化作为触发器，并引入行为驱动的后门优化方法（如双目标训练损失）和地址共享模型训练，实现多模型协作优化。实验在不同模型、数据集和任务上验证了该攻击的有效性，并强调了其潜在应用威胁。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01369v1",
      "published_date": "2024-12-02 10:54:02 UTC",
      "updated_date": "2024-12-02 10:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:42:01.329695"
    },
    {
      "arxiv_id": "2412.01365v2",
      "title": "Explaining the Unexplained: Revealing Hidden Correlations for Better Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Wen-Dong Jiang",
        "Chih-Yung Chang",
        "Show-Jane Yen",
        "Diptendu Sinha Roy"
      ],
      "abstract": "Deep learning has achieved remarkable success in processing and managing\nunstructured data. However, its \"black box\" nature imposes significant\nlimitations, particularly in sensitive application domains. While existing\ninterpretable machine learning methods address some of these issues, they often\nfail to adequately consider feature correlations and provide insufficient\nevaluation of model decision paths. To overcome these challenges, this paper\nintroduces Real Explainer (RealExp), an interpretability computation method\nthat decouples the Shapley Value into individual feature importance and feature\ncorrelation importance. By incorporating feature similarity computations,\nRealExp enhances interpretability by precisely quantifying both individual\nfeature contributions and their interactions, leading to more reliable and\nnuanced explanations. Additionally, this paper proposes a novel\ninterpretability evaluation criterion focused on elucidating the decision paths\nof deep learning models, going beyond traditional accuracy-based metrics.\nExperimental validations on two unstructured data tasks -- image classification\nand text sentiment analysis -- demonstrate that RealExp significantly\noutperforms existing methods in interpretability. Case studies further\nillustrate its practical value: in image classification, RealExp aids in\nselecting suitable pre-trained models for specific tasks from an\ninterpretability perspective; in text classification, it enables the\noptimization of models and approximates the performance of a fine-tuned GPT-Ada\nmodel using traditional bag-of-words approaches.",
      "tldr_zh": "本论文针对深度学习模型的黑箱性质及其在敏感领域的局限，引入 Real Explainer (RealExp) 方法，将 Shapley Value 分解为单个特征重要性和特征相关性重要性，并通过特征相似性计算来精确量化特征贡献和交互，从而提升解释性。论文还提出了一种新型可解释性评估标准，专注于模型决策路径而非仅靠准确性指标。在图像分类和文本情感分析任务的实验中，RealExp 显著优于现有方法，并在案例研究中展示了其实用价值，如从可解释性角度选择预训练模型或优化文本分类以接近 fine-tuned GPT-Ada 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been submitted to the Elsevier for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2412.01365v2",
      "published_date": "2024-12-02 10:50:50 UTC",
      "updated_date": "2025-02-09 09:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:42:14.518309"
    },
    {
      "arxiv_id": "2412.01354v1",
      "title": "Integrative CAM: Adaptive Layer Fusion for Comprehensive Interpretation of CNNs",
      "title_zh": "Integrative CAM：自适应层融合用于 CNNs 的全面解释",
      "authors": [
        "Aniket K. Singh",
        "Debasis Chaudhuri",
        "Manish P. Singh",
        "Samiran Chattopadhyay"
      ],
      "abstract": "With the growing demand for interpretable deep learning models, this paper\nintroduces Integrative CAM, an advanced Class Activation Mapping (CAM)\ntechnique aimed at providing a holistic view of feature importance across\nConvolutional Neural Networks (CNNs). Traditional gradient-based CAM methods,\nsuch as Grad-CAM and Grad-CAM++, primarily use final layer activations to\nhighlight regions of interest, often neglecting critical features derived from\nintermediate layers. Integrative CAM addresses this limitation by fusing\ninsights across all network layers, leveraging both gradient and activation\nscores to adaptively weight layer contributions, thus yielding a comprehensive\ninterpretation of the model's internal representation. Our approach includes a\nnovel bias term in the saliency map calculation, a factor frequently omitted in\nexisting CAM techniques, but essential for capturing a more complete feature\nimportance landscape, as modern CNNs rely on both weighted activations and\nbiases to make predictions. Additionally, we generalize the alpha term from\nGrad-CAM++ to apply to any smooth function, expanding CAM applicability across\na wider range of models. Through extensive experiments on diverse and complex\ndatasets, Integrative CAM demonstrates superior fidelity in feature importance\nmapping, effectively enhancing interpretability for intricate fusion scenarios\nand complex decision-making tasks. By advancing interpretability methods to\ncapture multi-layered model insights, Integrative CAM provides a valuable tool\nfor fusion-driven applications, promoting the trustworthy and insightful\ndeployment of deep learning models.",
      "tldr_zh": "本论文提出Integrative CAM，一种先进的Class Activation Mapping (CAM)技术，用于全面解释Convolutional Neural Networks (CNNs)的特征重要性。\n与传统方法如Grad-CAM和Grad-CAM++不同，该方法通过融合所有网络层的梯度和激活分数，并引入一个新颖的bias term，实现适应性层加权，提供更全面的模型内部表示解读。\n此外，Integrative CAM泛化了Grad-CAM++中的alpha term，使其适用于任何平滑函数，从而扩展了CAM的适用范围。\n实验在多种复杂数据集上证明，该方法显著提高了特征重要性映射的保真度，增强了深度学习模型在融合场景和决策任务中的可解释性和可信度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01354v1",
      "published_date": "2024-12-02 10:33:34 UTC",
      "updated_date": "2024-12-02 10:33:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:42:26.215749"
    },
    {
      "arxiv_id": "2412.01353v2",
      "title": "Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chayan Tank",
        "Shaina Mehta",
        "Sarthak Pol",
        "Vinayak Katoch",
        "Avinash Anand",
        "Raj Jaiswal",
        "Rajiv Ratn Shah"
      ],
      "abstract": "In recent times, more and more people are posting about their mental states\nacross various social media platforms. Leveraging this data, AI-based systems\ncan be developed that help in assessing the mental health of individuals, such\nas suicide risk. This paper is a study done on suicidal risk assessments using\nReddit data leveraging Base language models to identify patterns from social\nmedia posts. We have demonstrated that using smaller language models, i.e.,\nless than 500M parameters, can also be effective in contrast to LLMs with\ngreater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on\nsuicide risk prediction task that utilized both the labeled and unlabeled\nReddit data and tackled class imbalance by data augmentation using GPT-2 model.\nOur Su-RoBERTa model attained a 69.84% weighted F1 score during the Final\nevaluation. This paper demonstrates the effectiveness of Base language models\nfor the analysis of the risk factors related to mental health with an efficient\ncomputation pipeline",
      "tldr_zh": "本研究提出 Su-RoBERTa，一种基于 RoBERTa 的半监督方法，用于通过社交媒体（如 Reddit）数据预测自杀风险，证明了小型语言模型（小于 500M 参数）的有效性。方法包括利用标记和未标记数据进行模型细调，并通过 GPT-2 进行数据增强以解决类不平衡问题。实验结果显示，Su-RoBERTa 在最终评估中获得 69.84% 的加权 F1 score，展示了基础语言模型在精神健康风险分析中的高效计算潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages, 7 figures, Accepted at IEEE International Conference on Big\n  Data (IEEE BigData 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.01353v2",
      "published_date": "2024-12-02 10:31:12 UTC",
      "updated_date": "2024-12-19 09:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:42:38.314810"
    },
    {
      "arxiv_id": "2412.01351v1",
      "title": "A multi-criteria decision support system to evaluate the effectiveness of training courses on citizens' employability",
      "title_zh": "翻译失败",
      "authors": [
        "Maria C. Bas",
        "Vicente J. Bolos",
        "Alvaro E. Prieto",
        "Roberto Rodriguez-Echeverria",
        "Fernando Sanchez-Figueroa"
      ],
      "abstract": "This study examines the impact of lifelong learning on the professional lives\nof employed and unemployed individuals. Lifelong learning is a crucial factor\nin securing employment or enhancing one's existing career prospects. To achieve\nthis objective, this study proposes the implementation of a multi-criteria\ndecision support system for the evaluation of training courses in accordance\nwith their capacity to enhance the employability of the students. The\nmethodology is delineated in four stages. Firstly, a `working life curve' was\ndefined to provide a quantitative description of an individual's working life.\nSecondly, an analysis based on K-medoids clustering defined a control group for\neach individual for comparison. Thirdly, the performance of a course according\nto each of the four predefined criteria was calculated using a t-test to\ndetermine the mean performance value of those who took the course. Ultimately,\nthe unweighted TOPSIS method was used to evaluate the efficacy of the various\ntraining courses in relation to the four criteria. This approach effectively\naddresses the challenge of using extensive datasets within a system while\nfacilitating the application of a multi-criteria unweighted TOPSIS method. The\nresults of the multi-criteria TOPSIS method indicated that training courses\nrelated to the professional fields of administration and management, hostel and\ntourism and community and sociocultural services have positive impact on\nemployability and improving the working conditions of citizens. However,\ncourses that demonstrate the greatest effectiveness in ranking are the least\ndemanded by citizens. The results will help policymakers evaluate the\neffectiveness of each training course offered by the regional government.",
      "tldr_zh": "本研究提出一个多标准决策支持系统（multi-criteria decision support system），用于评估培训课程对公民就业能力的影响，旨在分析终身学习对就业前景的作用。方法分为四个阶段：定义 working life curve 量化职业生涯、使用 K-medoids clustering 确定对照组、通过 t-test 计算课程在四个预定义标准下的表现，并采用 unweighted TOPSIS 方法进行整体评估。结果表明，行政管理、酒店旅游和社区服务领域的课程对就业和职业条件有积极影响，但最有效的课程需求最低；此系统可帮助政策制定者优化培训课程的效能。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "math.OC",
        "90B50, 90C29, 90C31, 91B06"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01351v1",
      "published_date": "2024-12-02 10:29:28 UTC",
      "updated_date": "2024-12-02 10:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:42:49.903753"
    },
    {
      "arxiv_id": "2412.01348v2",
      "title": "Hierarchical Object-Oriented POMDP Planning for Object Rearrangement",
      "title_zh": "翻译失败",
      "authors": [
        "Rajesh Mangannavar",
        "Alan Fern",
        "Prasad Tadepalli"
      ],
      "abstract": "We present an online planning framework for solving multi-object\nrearrangement problems in partially observable, multi-room environments.\nCurrent object rearrangement solutions, primarily based on Reinforcement\nLearning or hand-coded planning methods, often lack adaptability to diverse\nchallenges. To address this limitation, we introduce a novel Hierarchical\nObject-Oriented Partially Observed Markov Decision Process (HOO-POMDP) planning\napproach. This approach comprises of (a) an object-oriented POMDP planner\ngenerating sub-goals, (b) a set of low-level policies for sub-goal achievement,\nand (c) an abstraction system converting the continuous low-level world into a\nrepresentation suitable for abstract planning. We evaluate our system on\nvarying numbers of objects, rooms, and problem types in AI2-THOR simulated\nenvironments with promising results.",
      "tldr_zh": "本研究提出了一种在线规划框架，用于处理部分可观测、多房间环境中的多对象重排问题，以克服现有基于强化学习或手动编码方法的适应性不足。框架采用Hierarchical Object-Oriented POMDP (HOO-POMDP)方法，包括对象导向POMDP规划器生成子目标、低级策略实现子目标，以及抽象系统将连续世界转化为适合抽象规划的表示。该方法在AI2-THOR模拟环境中进行了评估，针对不同对象数量、房间布局和问题类型显示出良好的性能，展示了其在复杂重排任务中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "I.2.9"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 2 Figures. Preprint. Updated acknowledgments",
      "pdf_url": "http://arxiv.org/pdf/2412.01348v2",
      "published_date": "2024-12-02 10:19:36 UTC",
      "updated_date": "2025-01-08 18:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:43:01.233078"
    },
    {
      "arxiv_id": "2412.01339v2",
      "title": "Negative Token Merging: Image-based Adversarial Feature Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Jaskirat Singh",
        "Lindsey Li",
        "Weijia Shi",
        "Ranjay Krishna",
        "Yejin Choi",
        "Pang Wei Koh",
        "Michael F. Cohen",
        "Stephen Gould",
        "Liang Zheng",
        "Luke Zettlemoyer"
      ],
      "abstract": "Text-based adversarial guidance using a negative prompt has emerged as a\nwidely adopted approach to steer diffusion models away from producing undesired\nconcepts. While useful, performing adversarial guidance using text alone can be\ninsufficient to capture complex visual concepts or avoid specific visual\nelements like copyrighted characters. In this paper, for the first time we\nexplore an alternate modality in this direction by performing adversarial\nguidance directly using visual features from a reference image or other images\nin a batch. We introduce negative token merging (NegToMe), a simple but\neffective training-free approach which performs adversarial guidance through\nimages by selectively pushing apart matching visual features between reference\nand generated images during the reverse diffusion process. By simply adjusting\nthe used reference, NegToMe enables a diverse range of applications. Notably,\nwhen using other images in same batch as reference, we find that NegToMe\nsignificantly enhances output diversity (e.g., racial, gender, visual) by\nguiding features of each image away from others. Similarly, when used w.r.t.\ncopyrighted reference images, NegToMe reduces visual similarity to copyrighted\ncontent by 34.57%. NegToMe is simple to implement using just few-lines of code,\nuses only marginally higher (<4%) inference time and is compatible with\ndifferent diffusion architectures, including those like Flux, which don't\nnatively support the use of a negative prompt. Code is available at\nhttps://negtome.github.io",
      "tldr_zh": "该研究提出Negative Token Merging (NegToMe)，一种基于图像的对抗特征指导方法，用于改进扩散模型的生成过程，避免仅靠文本负面提示（如negative prompt）无法捕捉复杂视觉概念的问题。NegToMe 通过在逆扩散过程中选择性地将参考图像和生成图像的匹配视觉特征推开，实现训练-free 的对抗指导，从而增强输出多样性，例如使用批次中其他图像作为参考，能显著提高种族、性别和视觉多样性。实验结果显示，NegToMe 相对于受版权保护的参考图像，可将生成内容的视觉相似性降低34.57%。该方法实现简单，仅需少量代码，推理时间增加不到4%，并兼容多种扩散架构，包括不支持负面提示的模型如Flux。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01339v2",
      "published_date": "2024-12-02 10:06:57 UTC",
      "updated_date": "2024-12-05 18:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:43:14.222227"
    },
    {
      "arxiv_id": "2412.01330v1",
      "title": "The \"LLM World of Words\" English free association norms generated by large language models",
      "title_zh": "“LLM World of Words” 英语自由联想规范，由大型语言模型生成",
      "authors": [
        "Katherine Abramski",
        "Riccardo Improta",
        "Giulio Rossetti",
        "Massimo Stella"
      ],
      "abstract": "Free associations have been extensively used in cognitive psychology and\nlinguistics for studying how conceptual knowledge is organized. Recently, the\npotential of applying a similar approach for investigating the knowledge\nencoded in LLMs has emerged, specifically as a method for investigating LLM\nbiases. However, the absence of large-scale LLM-generated free association\nnorms that are comparable with human-generated norms is an obstacle to this new\nresearch direction. To address this limitation, we create a new dataset of\nLLM-generated free association norms modeled after the \"Small World of Words\"\n(SWOW) human-generated norms consisting of approximately 12,000 cue words. We\nprompt three LLMs, namely Mistral, Llama3, and Haiku, with the same cues as\nthose in the SWOW norms to generate three novel comparable datasets, the \"LLM\nWorld of Words\" (LWOW). Using both SWOW and LWOW norms, we construct cognitive\nnetwork models of semantic memory that represent the conceptual knowledge\npossessed by humans and LLMs. We demonstrate how these datasets can be used for\ninvestigating implicit biases in humans and LLMs, such as the harmful gender\nstereotypes that are prevalent both in society and LLM outputs.",
      "tldr_zh": "这篇论文介绍了“LLM World of Words”(LWOW)数据集，由大型语言模型(LLMs)生成的英语自由联想规范，旨在与人类生成的“Small World of Words”(SWOW)规范相媲美，用于研究LLMs中编码的知识和偏见。研究者使用Mistral、Llama3和Haiku等LLMs对约12,000个提示词进行提示，生成三个可比数据集，并构建认知网络模型来代表人类和LLMs的概念知识。结果显示，这些数据集可用于调查隐性偏见，如人类和LLMs中普遍存在的有害性别刻板印象。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 11 figures, associated Github page with dataset available\n  at: https://github.com/LLMWorldOfWords/LWOW",
      "pdf_url": "http://arxiv.org/pdf/2412.01330v1",
      "published_date": "2024-12-02 09:54:14 UTC",
      "updated_date": "2024-12-02 09:54:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:43:26.648755"
    },
    {
      "arxiv_id": "2412.01322v2",
      "title": "Explainable fault and severity classification for rolling element bearings using Kolmogorov-Arnold networks",
      "title_zh": "翻译失败",
      "authors": [
        "Spyros Rigas",
        "Michalis Papachristou",
        "Ioannis Sotiropoulos",
        "Georgios Alexandridis"
      ],
      "abstract": "Rolling element bearings are critical components of rotating machinery, with\ntheir performance directly influencing the efficiency and reliability of\nindustrial systems. At the same time, bearing faults are a leading cause of\nmachinery failures, often resulting in costly downtime, reduced productivity,\nand, in extreme cases, catastrophic damage. This study presents a methodology\nthat utilizes Kolmogorov-Arnold Networks to address these challenges through\nautomatic feature selection, hyperparameter tuning and interpretable fault\nanalysis within a unified framework. By training shallow network architectures\nand minimizing the number of selected features, the framework produces\nlightweight models that deliver explainable results through feature attribution\nand symbolic representations of their activation functions. Validated on two\nwidely recognized datasets for bearing fault diagnosis, the framework achieved\nperfect F1-Scores for fault detection and high performance in fault and\nseverity classification tasks, including 100% F1-Scores in most cases. Notably,\nit demonstrated adaptability by handling diverse fault types, such as imbalance\nand misalignment, within the same dataset. The symbolic representations\nenhanced model interpretability, while feature attribution offered insights\ninto the optimal feature types or signals for each studied task. These results\nhighlight the framework's potential for practical applications, such as\nreal-time machinery monitoring, and for scientific research requiring efficient\nand explainable models.",
      "tldr_zh": "本研究利用 Kolmogorov-Arnold Networks 提出一个统一框架，用于滚动轴承的故障和严重度分类，通过自动特征选择、超参数调整以及可解释分析来解决工业机械故障问题。该框架采用浅层网络架构，减少特征数量，生成轻量级模型，并通过特征归因和符号表示提供可解释的结果。在两个知名轴承故障诊断数据集上验证，该方法实现了完美的 F1-Scores 用于故障检测，并在大多数故障和严重度分类任务中达到 100% F1-Scores，同时适应多种故障类型如不平衡和错位。这些成果突显了框架在实时机械监控和科学研究中的实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01322v2",
      "published_date": "2024-12-02 09:40:03 UTC",
      "updated_date": "2024-12-04 11:53:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:43:38.242684"
    },
    {
      "arxiv_id": "2412.01316v2",
      "title": "Long Video Diffusion Generation with Segmented Cross-Attention and Content-Rich Video Data Curation",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Yan",
        "Yuxuan Cai",
        "Qiuyue Wang",
        "Yuan Zhou",
        "Wenhao Huang",
        "Huan Yang"
      ],
      "abstract": "We introduce Presto, a novel video diffusion model designed to generate\n15-second videos with long-range coherence and rich content. Extending video\ngeneration methods to maintain scenario diversity over long durations presents\nsignificant challenges. To address this, we propose a Segmented Cross-Attention\n(SCA) strategy, which splits hidden states into segments along the temporal\ndimension, allowing each segment to cross-attend to a corresponding\nsub-caption. SCA requires no additional parameters, enabling seamless\nincorporation into current DiT-based architectures. To facilitate high-quality\nlong video generation, we build the LongTake-HD dataset, consisting of 261k\ncontent-rich videos with scenario coherence, annotated with an overall video\ncaption and five progressive sub-captions. Experiments show that our Presto\nachieves 78.5% on the VBench Semantic Score and 100% on the Dynamic Degree,\noutperforming existing state-of-the-art video generation methods. This\ndemonstrates that our proposed Presto significantly enhances content richness,\nmaintains long-range coherence, and captures intricate textual details. More\ndetails are displayed on our project page: https://presto-video.github.io/.",
      "tldr_zh": "本研究引入了Presto，一种新型视频扩散模型，能够生成15秒长视频，具备长距离一致性和丰富内容。针对长视频生成中维持场景多样性的挑战，论文提出Segmented Cross-Attention (SCA)策略，将隐藏状态沿时间维度分割，每个段与对应的子标题进行交叉关注，从而无需额外参数即可整合到DiT-based架构中。为支持高质量生成，研究构建了LongTake-HD数据集，包含261k个内容丰富的视频，每条配有整体标题和五个渐进子标题。实验显示，Presto在VBench Semantic Score上达到78.5%、Dynamic Degree上达到100%，显著优于现有方法，提升了内容丰富性、长距离一致性和文本细节捕捉能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01316v2",
      "published_date": "2024-12-02 09:32:36 UTC",
      "updated_date": "2025-03-29 08:56:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:44:05.156297"
    },
    {
      "arxiv_id": "2412.01306v1",
      "title": "Multimodal Medical Disease Classification with LLaMA II",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Gapp",
        "Elias Tappeiner",
        "Martin Welk",
        "Rainer Schubert"
      ],
      "abstract": "Medical patient data is always multimodal. Images, text, age, gender,\nhistopathological data are only few examples for different modalities in this\ncontext. Processing and integrating this multimodal data with deep learning\nbased methods is of utmost interest due to its huge potential for medical\nprocedure such as diagnosis and patient treatment planning. In this work we\nretrain a multimodal transformer-based model for disease classification. To\nthis end we use the text-image pair dataset from OpenI consisting of 2D chest\nX-rays associated with clinical reports. Our focus is on fusion methods for\nmerging text and vision information extracted from medical datasets. Different\narchitecture structures with a LLaMA II backbone model are tested. Early fusion\nof modality specific features creates better results with the best model\nreaching 97.10% mean AUC than late fusion from a deeper level of the\narchitecture (best model: 96.67% mean AUC). Both outperform former\nclassification models tested on the same multimodal dataset. The newly\nintroduced multimodal architecture can be applied to other multimodal datasets\nwith little effort and can be easily adapted for further research, especially,\nbut not limited to, the field of medical AI.",
      "tldr_zh": "本研究使用 LLaMA II 作为骨干模型，重新训练一个多模态 transformer 架构，以整合文本和图像等医疗多模态数据，用于疾病分类。研究焦点在于比较早融合和晚融合方法处理 OpenI 数据集中的 2D 胸部 X 光及临床报告，早融合策略取得了更好的性能，最佳模型达到 97.10% mean AUC，比晚融合 (96.67%) 和先前模型表现更优。该方法易于扩展到其他多模态数据集，尤其适用于医疗 AI 领域的诊断和治疗规划。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures, conference: AIRoV -- The First Austrian Symposium\n  on AI, Robotics, and Vision 25.-27.3.2024, Innsbruck",
      "pdf_url": "http://arxiv.org/pdf/2412.01306v1",
      "published_date": "2024-12-02 09:18:07 UTC",
      "updated_date": "2024-12-02 09:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:44:01.914140"
    },
    {
      "arxiv_id": "2412.01303v1",
      "title": "RL2: Reinforce Large Language Model to Assist Safe Reinforcement Learning for Energy Management of Active Distribution Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Yang",
        "Chenhui Lin",
        "Haotian Liu",
        "Wenchuan Wu"
      ],
      "abstract": "As large-scale distributed energy resources are integrated into the active\ndistribution networks (ADNs), effective energy management in ADNs becomes\nincreasingly prominent compared to traditional distribution networks. Although\nadvanced reinforcement learning (RL) methods, which alleviate the burden of\ncomplicated modelling and optimization, have greatly improved the efficiency of\nenergy management in ADNs, safety becomes a critical concern for RL\napplications in real-world problems. Since the design and adjustment of penalty\nfunctions, which correspond to operational safety constraints, requires\nextensive domain knowledge in RL and power system operation, the emerging ADN\noperators call for a more flexible and customized approach to address the\npenalty functions so that the operational safety and efficiency can be further\nenhanced. Empowered with strong comprehension, reasoning, and in-context\nlearning capabilities, large language models (LLMs) provide a promising way to\nassist safe RL for energy management in ADNs. In this paper, we introduce the\nLLM to comprehend operational safety requirements in ADNs and generate\ncorresponding penalty functions. In addition, we propose an RL2 mechanism to\nrefine the generated functions iteratively and adaptively through multi-round\ndialogues, in which the LLM agent adjusts the functions' pattern and parameters\nbased on training and test performance of the downstream RL agent. The proposed\nmethod significantly reduces the intervention of the ADN operators.\nComprehensive test results demonstrate the effectiveness of the proposed\nmethod.",
      "tldr_zh": "该论文针对主动配电网络 (ADNs) 的能量管理问题，提出使用大型语言模型 (LLMs) 辅助安全的强化学习 (RL)，以解决传统惩罚函数设计依赖专业知识的挑战。研究引入 RL2 机制，通过多轮对话让 LLM 代理根据下游 RL 代理的训练和测试性能，迭代优化惩罚函数，从而增强操作安全性和效率。相比传统方法，该方法显著减少了 ADN 操作员的干预。实验结果证明，RL2 机制在综合测试中表现出色，提升了能量管理的可靠性和灵活性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01303v1",
      "published_date": "2024-12-02 09:15:36 UTC",
      "updated_date": "2024-12-02 09:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:44:13.027068"
    },
    {
      "arxiv_id": "2412.01295v1",
      "title": "FedAH: Aggregated Head for Personalized Federated Learning",
      "title_zh": "FedAH：用于个性化联邦学习的聚合头",
      "authors": [
        "Pengzhan Zhou",
        "Yuepeng He",
        "Yijun Zhai",
        "Kaixin Gao",
        "Chao Chen",
        "Zhida Qin",
        "Chong Zhang",
        "Songtao Guo"
      ],
      "abstract": "Recently, Federated Learning (FL) has gained popularity for its\nprivacy-preserving and collaborative learning capabilities. Personalized\nFederated Learning (PFL), building upon FL, aims to address the issue of\nstatistical heterogeneity and achieve personalization. Personalized-head-based\nPFL is a common and effective PFL method that splits the model into a feature\nextractor and a head, where the feature extractor is collaboratively trained\nand shared, while the head is locally trained and not shared. However,\nretaining the head locally, although achieving personalization, prevents the\nmodel from learning global knowledge in the head, thus affecting the\nperformance of the personalized model. To solve this problem, we propose a\nnovel PFL method called Federated Learning with Aggregated Head (FedAH), which\ninitializes the head with an Aggregated Head at each iteration. The key feature\nof FedAH is to perform element-level aggregation between the local model head\nand the global model head to introduce global information from the global model\nhead. To evaluate the effectiveness of FedAH, we conduct extensive experiments\non five benchmark datasets in the fields of computer vision and natural\nlanguage processing. FedAH outperforms ten state-of-the-art FL methods in terms\nof test accuracy by 2.87%. Additionally, FedAH maintains its advantage even in\nscenarios where some clients drop out unexpectedly. Our code is open-accessed\nat https://github.com/heyuepeng/FedAH.",
      "tldr_zh": "本研究针对 Personalized Federated Learning (PFL) 中统计异质性问题，提出了一种新方法 FedAH，通过在每个迭代中用 Aggregated Head 初始化头部，并进行 element-level aggregation，将全局模型头部的信息引入本地模型，从而提升个性化模型的性能。FedAH 解决了传统 personalized-head-based PFL 方法无法学习全局知识的局限性。实验结果显示，在五个计算机视觉和自然语言处理基准数据集上，FedAH 比十种最先进 Federated Learning (FL) 方法提高了 2.87% 的测试准确率，并在客户端意外掉线场景下保持优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01295v1",
      "published_date": "2024-12-02 09:08:51 UTC",
      "updated_date": "2024-12-02 09:08:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:44:25.700883"
    },
    {
      "arxiv_id": "2412.01290v1",
      "title": "Learning Smooth Distance Functions via Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Kumar",
        "Sanjoy Dasgupta"
      ],
      "abstract": "In this work, we investigate the problem of learning distance functions\nwithin the query-based learning framework, where a learner is able to pose\ntriplet queries of the form: ``Is $x_i$ closer to $x_j$ or $x_k$?'' We\nestablish formal guarantees on the query complexity required to learn smooth,\nbut otherwise general, distance functions under two notions of approximation:\n$\\omega$-additive approximation and $(1 + \\omega)$-multiplicative\napproximation. For the additive approximation, we propose a global method whose\nquery complexity is quadratic in the size of a finite cover of the sample\nspace. For the (stronger) multiplicative approximation, we introduce a method\nthat combines global and local approaches, utilizing multiple Mahalanobis\ndistance functions to capture local geometry. This method has a query\ncomplexity that scales quadratically with both the size of the cover and the\nambient space dimension of the sample space.",
      "tldr_zh": "本研究探讨了通过三元组查询（例如“Is \\( x_i \\) closer to \\( x_j \\) or \\( x_k \\)?”）学习平滑距离函数的问题，并建立了查询复杂度的正式保证。针对 \\(\\omega\\)-additive approximation，该方法提出了一种全局方法，其查询复杂度与样本空间有限覆盖的大小平方成正比。对于更强的 \\((1 + \\omega)\\)-multiplicative approximation，则结合全局和局部方法，使用多个 Mahalanobis distance functions 来捕捉局部几何，查询复杂度与覆盖大小和样本空间维度的平方相关。这种方法为高效学习距离函数提供了理论基础和实用框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2412.01290v1",
      "published_date": "2024-12-02 09:03:05 UTC",
      "updated_date": "2024-12-02 09:03:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:46:37.626887"
    },
    {
      "arxiv_id": "2412.01289v2",
      "title": "Enhancing Perception Capabilities of Multimodal LLMs with Training-Free Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuokun Chen",
        "Jinwu Hu",
        "Zeshuai Deng",
        "Yufeng Wang",
        "Bohan Zhuang",
        "Mingkui Tan"
      ],
      "abstract": "Multimodal LLMs (MLLMs) equip language models with visual capabilities by\naligning vision encoders with language models. Existing methods to enhance the\nvisual perception of MLLMs often involve designing more powerful vision\nencoders, which requires exploring a vast design space and re-aligning each\npotential encoder with the language model, resulting in prohibitively high\ntraining costs. In this paper, we introduce VisionFuse, a novel integration\nframework that efficiently utilizes multiple vision encoders from off-the-shelf\nMLLMs to enhance visual perception without requiring additional training. Our\napproach is motivated by the observation that different MLLMs tend to focus on\ndistinct regions given the same query and image. Moreover, we find that the\nfeature distributions of vision encoders within an MLLM family, a group of\nMLLMs sharing the same pretrained LLM, are highly aligned. Building on these\ninsights, VisionFuse enriches the visual context by concatenating the tokens\ngenerated by the vision encoders of selected MLLMs within a family. By merging\nthe parameters of language models from these MLLMs, VisionFuse allows a single\nlanguage model to align with various vision encoders, significantly reducing\ndeployment overhead. We conduct comprehensive evaluations across multiple\nmultimodal benchmarks using various MLLM combinations, demonstrating\nsubstantial improvements in multimodal tasks. Notably, when integrating\nMiniGemini-8B and SLIME-8B, VisionFuse achieves an average performance increase\nof over 4%.",
      "tldr_zh": "这项研究针对多模态大型语言模型（Multimodal LLMs, MLLMs）的视觉感知能力提出VisionFuse框架，该框架无需额外训练，通过融合现成MLLMs的多个视觉编码器来丰富视觉上下文。VisionFuse利用观察到不同MLLMs在相同查询和图像下关注不同区域，以及同一MLLMs家族内视觉编码器特征分布高度对齐的洞见，来连接选定MLLMs的tokens并合并语言模型参数，从而降低部署开销。主要贡献在于显著提升多模态任务性能，例如整合MiniGemini-8B和SLIME-8B后，平均性能提升超过4%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01289v2",
      "published_date": "2024-12-02 09:02:28 UTC",
      "updated_date": "2024-12-04 09:51:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:46:43.521727"
    },
    {
      "arxiv_id": "2412.01284v2",
      "title": "MFTF: Mask-free Training-free Object Level Layout Control Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Yang"
      ],
      "abstract": "Text-to-image generation models have revolutionized content creation, but\ndiffusion-based vision-language models still face challenges in precisely\ncontrolling the shape, appearance, and positional placement of objects in\ngenerated images using text guidance alone. Existing global image editing\nmodels rely on additional masks or images as guidance to achieve layout\ncontrol, often requiring retraining of the model. While local object-editing\nmodels allow modifications to object shapes, they lack the capability to\ncontrol object positions. To address these limitations, we propose the\nMask-free Training-free Object-Level Layout Control Diffusion Model (MFTF),\nwhich provides precise control over object positions without requiring\nadditional masks or images. The MFTF model supports both single-object and\nmulti-object positional adjustments, such as translation and rotation, while\nenabling simultaneous layout control and object semantic editing. The MFTF\nmodel employs a parallel denoising process for both the source and target\ndiffusion models. During this process, attention masks are dynamically\ngenerated from the cross-attention layers of the source diffusion model and\napplied to queries from the self-attention layers to isolate objects. These\nqueries, generated in the source diffusion model, are then adjusted according\nto the layout control parameters and re-injected into the self-attention layers\nof the target diffusion model. This approach ensures accurate and precise\npositional control of objects. Project source code available at\nhttps://github.com/syang-genai/MFTF.",
      "tldr_zh": "本文提出 MFTF（Mask-free Training-free Object Level Layout Control Diffusion Model），一种无需额外掩码或训练的扩散模型，用于精确控制文本到图像生成中对象的形状、外观和位置。MFTF 支持单对象和多对象的位移（translation）和旋转（rotation），同时实现布局控制和对象语义编辑。模型通过并行去噪过程，从源扩散模型的交叉注意力层动态生成注意力掩码，并将其应用到目标模型的自注意力层中调整对象查询，从而确保精确的位置控制。实验结果表明，该方法有效解决了现有模型的局限性，提供更灵活的图像生成能力。项目代码可在 https://github.com/syang-genai/MFTF 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01284v2",
      "published_date": "2024-12-02 08:56:13 UTC",
      "updated_date": "2024-12-18 01:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:45:01.761908"
    },
    {
      "arxiv_id": "2412.01282v1",
      "title": "Align-KD: Distilling Cross-Modal Alignment Knowledge for Mobile Vision-Language Model",
      "title_zh": "Align-KD：为移动视觉语言模型蒸馏跨模态对齐知识",
      "authors": [
        "Qianhan Feng",
        "Wenshuo Li",
        "Tong Lin",
        "Xinghao Chen"
      ],
      "abstract": "Vision-Language Models (VLMs) bring powerful understanding and reasoning\ncapabilities to multimodal tasks. Meanwhile, the great need for capable\naritificial intelligence on mobile devices also arises, such as the AI\nassistant software. Some efforts try to migrate VLMs to edge devices to expand\ntheir application scope. Simplifying the model structure is a common method,\nbut as the model shrinks, the trade-off between performance and size becomes\nmore and more difficult. Knowledge distillation (KD) can help models improve\ncomprehensive capabilities without increasing size or data volume. However,\nmost of the existing large model distillation techniques only consider\napplications on single-modal LLMs, or only use teachers to create new data\nenvironments for students. None of these methods take into account the\ndistillation of the most important cross-modal alignment knowledge in VLMs. We\npropose a method called Align-KD to guide the student model to learn the\ncross-modal matching that occurs at the shallow layer. The teacher also helps\nstudent learn the projection of vision token into text embedding space based on\nthe focus of text. Under the guidance of Align-KD, the 1.7B MobileVLM V2 model\ncan learn rich knowledge from the 7B teacher model with light design of\ntraining loss, and achieve an average score improvement of 2.0 across 6\nbenchmarks under two training subsets respectively. Code is available at:\nhttps://github.com/fqhank/Align-KD.",
      "tldr_zh": "该论文提出 Align-KD 方法，用于在 Vision-Language Models (VLMs) 中蒸馏跨模态对齐知识，以优化移动设备上的模型性能。Align-KD 通过教师模型指导学生模型学习浅层跨模态匹配，并基于文本焦点将视觉标记投影到文本嵌入空间，从而避免传统 Knowledge Distillation (KD) 方法的局限。实验结果显示，使用轻量训练损失，1.7B MobileVLM V2 模型从 7B 教师模型中学习后，在 6 个基准测试中平均分数提升 2.0，为高效的移动 VLM 应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01282v1",
      "published_date": "2024-12-02 08:55:19 UTC",
      "updated_date": "2024-12-02 08:55:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:45:14.719953"
    },
    {
      "arxiv_id": "2412.01281v1",
      "title": "FedPAW: Federated Learning with Personalized Aggregation Weights for Urban Vehicle Speed Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuepeng He",
        "Pengzhan Zhou",
        "Yijun Zhai",
        "Fang Qu",
        "Zhida Qin",
        "Mingyan Li",
        "Songtao Guo"
      ],
      "abstract": "Vehicle speed prediction is crucial for intelligent transportation systems,\npromoting more reliable autonomous driving by accurately predicting future\nvehicle conditions. Due to variations in drivers' driving styles and vehicle\ntypes, speed predictions for different target vehicles may significantly\ndiffer. Existing methods may not realize personalized vehicle speed prediction\nwhile protecting drivers' data privacy. We propose a Federated learning\nframework with Personalized Aggregation Weights (FedPAW) to overcome these\nchallenges. This method captures client-specific information by measuring the\nweighted mean squared error between the parameters of local models and global\nmodels. The server sends tailored aggregated models to clients instead of a\nsingle global model, without incurring additional computational and\ncommunication overhead for clients. To evaluate the effectiveness of FedPAW, we\ncollected driving data in urban scenarios using the autonomous driving\nsimulator CARLA, employing an LSTM-based Seq2Seq model with a multi-head\nattention mechanism to predict the future speed of target vehicles. The results\ndemonstrate that our proposed FedPAW ranks lowest in prediction error within\nthe time horizon of 10 seconds, with a 0.8% reduction in test MAE, compared to\neleven representative benchmark baselines. The source code of FedPAW and\ndataset CarlaVSP are open-accessed at: https://github.com/heyuepeng/PFLlibVSP\nand https://pan.baidu.com/s/1qs8fxUvSPERV3C9i6pfUIw?pwd=tl3e.",
      "tldr_zh": "该研究针对城市车辆速度预测的个性化需求，提出 FedPAW 框架，这是一种基于联邦学习（Federated Learning）的模型，使用个性化聚合权重来捕获客户端特定信息，同时保护驾驶员数据隐私。FedPAW 通过计算本地模型和全局模型之间的加权均方误差（weighted mean squared error）生成定制的聚合模型，并避免增加客户端的计算和通信开销。实验在 CARLA 模拟器上使用 LSTM-based Seq2Seq 模型进行测试，结果显示 FedPAW 在 10 秒预测时间内错误最低，比 11 个基准模型减少 0.8% 的测试 MAE，并开源了相关代码和数据集。",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01281v1",
      "published_date": "2024-12-02 08:54:43 UTC",
      "updated_date": "2024-12-02 08:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:45:26.919986"
    },
    {
      "arxiv_id": "2412.01272v2",
      "title": "Uncertainty-Aware Artificial Intelligence for Gear Fault Diagnosis in Motor Drives",
      "title_zh": "不确定性感知人工智能用于电机驱动系统中的齿轮故障诊断",
      "authors": [
        "Subham Sahoo",
        "Huai Wang",
        "Frede Blaabjerg"
      ],
      "abstract": "This paper introduces a novel approach to quantify the uncertainties in fault\ndiagnosis of motor drives using Bayesian neural networks (BNN). Conventional\ndata-driven approaches used for fault diagnosis often rely on point-estimate\nneural networks, which merely provide deterministic outputs and fail to capture\nthe uncertainty associated with the inference process. In contrast, BNNs offer\na principled framework to model uncertainty by treating network weights as\nprobability distributions rather than fixed values. It offers several\nadvantages: (a) improved robustness to noisy data, (b) enhanced\ninterpretability of model predictions, and (c) the ability to quantify\nuncertainty in the decision-making processes. To test the robustness of the\nproposed BNN, it has been tested under a conservative dataset of gear fault\ndata from an experimental prototype of three fault types at first, and is then\nincrementally trained on new fault classes and datasets to explore its\nuncertainty quantification features and model interpretability under noisy data\nand unseen fault scenarios.",
      "tldr_zh": "这篇论文提出了一种基于 Bayesian neural networks (BNN) 的新方法，用于量化电机驱动器中齿轮故障诊断的不确定性，以克服传统点估计神经网络的局限性。BNN 通过将网络权重视为概率分布，实现了对不确定性的建模，从而提升模型对噪声数据的鲁棒性、预测的可解释性和决策过程中的不确定性量化。论文通过实验验证了该方法：在三种齿轮故障数据集上进行测试，并逐步训练以处理新故障类别和噪声场景，结果展示了 BNN 在未知情况下的可靠性能。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "The manuscript has been accepted for publication in 2025 IEEE Applied\n  Power Electronics Conference and Exposition (APEC)",
      "pdf_url": "http://arxiv.org/pdf/2412.01272v2",
      "published_date": "2024-12-02 08:38:20 UTC",
      "updated_date": "2024-12-13 09:50:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:46:54.325916"
    },
    {
      "arxiv_id": "2412.01271v1",
      "title": "MuLan: Adapting Multilingual Diffusion Models for Hundreds of Languages with Negligible Cost",
      "title_zh": "翻译失败",
      "authors": [
        "Sen Xing",
        "Muyan Zhong",
        "Zeqiang Lai",
        "Liangchen Li",
        "Jiawen Liu",
        "Yaohui Wang",
        "Jifeng Dai",
        "Wenhai Wang"
      ],
      "abstract": "In this work, we explore a cost-effective framework for multilingual image\ngeneration. We find that, unlike models tuned on high-quality images with\nmultilingual annotations, leveraging text encoders pre-trained on widely\navailable, noisy Internet image-text pairs significantly enhances data\nefficiency in text-to-image (T2I) generation across multiple languages. Based\non this insight, we introduce MuLan, Multi-Language adapter, a lightweight\nlanguage adapter with fewer than 20M parameters, trained alongside a frozen\ntext encoder and image diffusion model. Compared to previous multilingual T2I\nmodels, this framework offers: (1) Cost efficiency. Using readily accessible\nEnglish data and off-the-shelf multilingual text encoders minimizes the\ntraining cost; (2) High performance. Achieving comparable generation\ncapabilities in over 110 languages with CLIP similarity scores nearly matching\nthose in English (38.61 for English vs. 37.61 for other languages); and (3)\nBroad applicability. Seamlessly integrating with compatible community tools\nlike LoRA, LCM, ControlNet, and IP-Adapter, expanding its potential use cases.",
      "tldr_zh": "本文提出 MuLan，一种轻量级语言适配器（少于 20M 参数），通过与冻结的文本编码器和图像扩散模型结合训练，利用预训练的文本编码器和嘈杂的互联网图像-文本对，实现多语言文本到图像 (T2I) 生成的成本高效扩展。MuLan 显著提升了数据效率，并在超过 110 种语言中实现与英语相当的生成性能，CLIP 相似度分数接近（英语 38.61 vs. 其他语言 37.61）。此外，该框架支持无缝集成社区工具如 LoRA、LCM、ControlNet 和 IP-Adapter，扩展了其实际应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01271v1",
      "published_date": "2024-12-02 08:38:19 UTC",
      "updated_date": "2024-12-02 08:38:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:47:10.259062"
    },
    {
      "arxiv_id": "2412.01269v5",
      "title": "CPRM: A LLM-based Continual Pre-training Framework for Relevance Modeling in Commercial Search",
      "title_zh": "CPRM：一种基于 LLM 的持续预训练框架，用于商业搜索中的相关性建模",
      "authors": [
        "Kaixin Wu",
        "Yixin Ji",
        "Zeyuan Chen",
        "Qiang Wang",
        "Cunxiang Wang",
        "Hong Liu",
        "Baijun Ji",
        "Jia Xu",
        "Zhongyi Liu",
        "Jinjie Gu",
        "Yuan Zhou",
        "Linjian Mo"
      ],
      "abstract": "Relevance modeling between queries and items stands as a pivotal component in\ncommercial search engines, directly affecting the user experience. Given the\nremarkable achievements of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, LLM-based relevance modeling is gradually\nbeing adopted within industrial search systems. Nevertheless, foundational LLMs\nlack domain-specific knowledge and do not fully exploit the potential of\nin-context learning. Furthermore, structured item text remains underutilized,\nand there is a shortage in the supply of corresponding queries and background\nknowledge. We thereby propose CPRM (Continual Pre-training for Relevance\nModeling), a framework designed for the continual pre-training of LLMs to\naddress these issues. Our CPRM framework includes three modules: 1) employing\nboth queries and multi-field item to jointly pre-train for enhancing domain\nknowledge, 2) applying in-context pre-training, a novel approach where LLMs are\npre-trained on a sequence of related queries or items, and 3) conducting\nreading comprehension on items to produce associated domain knowledge and\nbackground information (e.g., generating summaries and corresponding queries)\nto further strengthen LLMs. Results on offline experiments and online A/B\ntesting demonstrate that our model achieves convincing performance compared to\nstrong baselines.",
      "tldr_zh": "这篇论文提出CPRM框架，这是一个基于LLM的持续预训练方法，旨在解决商业搜索中查询和物品相关性建模的问题，包括LLM的领域知识缺失和in-context learning潜力未充分发挥。CPRM包括三个模块：1) 使用查询和多字段物品联合预训练以增强领域知识；2) 应用in-context pre-training在相关查询或物品序列上预训练LLM；3) 通过物品阅读理解生成关联的领域知识和背景信息，如摘要和对应查询。实验结果显示，CPRM在离线实验和在线A/B测试中比强基线模型表现出显著性能提升。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01269v5",
      "published_date": "2024-12-02 08:35:54 UTC",
      "updated_date": "2025-02-18 09:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:47:20.272045"
    },
    {
      "arxiv_id": "2412.01265v1",
      "title": "Indexing Economic Fluctuation Narratives from Keiki Watchers Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Eriko Shigetsugu",
        "Hiroki Sakaji",
        "Itsuki Noda"
      ],
      "abstract": "In this paper, we design indices of economic fluctuation narratives derived\nfrom economic surveys. Companies, governments, and investors rely on key\nmetrics like GDP and industrial production indices to predict economic trends.\nHowever, they have yet to effectively leverage the wealth of information\ncontained in economic text, such as causal relationships, in their economic\nforecasting. Therefore, we design indices of economic fluctuation from economic\nsurveys by using our previously proposed narrative framework. From the\nevaluation results, it is observed that the proposed indices had a stronger\ncorrelation with cumulative lagging diffusion index than other types of\ndiffusion indices.",
      "tldr_zh": "本文设计了从Keiki Watchers调查中提取的经济波动叙述指标（economic fluctuation narratives），旨在利用经济文本中的因果关系等信息来提升经济预测的准确性。作者采用先前提出的叙述框架（narrative framework），对经济调查数据进行分析，生成这些新指标。评估结果表明，该指标与累积滞后扩散指数（cumulative lagging diffusion index）的相关性强于其他扩散指数类型，从而为更有效的经济趋势预测提供了新工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01265v1",
      "published_date": "2024-12-02 08:32:02 UTC",
      "updated_date": "2024-12-02 08:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:47:30.161768"
    },
    {
      "arxiv_id": "2412.01262v2",
      "title": "Exploring ReAct Prompting for Task-Oriented Dialogue: Insights and Shortcomings",
      "title_zh": "翻译失败",
      "authors": [
        "Michelle Elizabeth",
        "Morgan Veyret",
        "Miguel Couceiro",
        "Ondrej Dusek",
        "Lina M. Rojas-Barahona"
      ],
      "abstract": "Large language models (LLMs) gained immense popularity due to their\nimpressive capabilities in unstructured conversations. Empowering LLMs with\nadvanced prompting strategies such as reasoning and acting (ReAct) (Yao et al.,\n2022) has shown promise in solving complex tasks traditionally requiring\nreinforcement learning. In this work, we apply the ReAct strategy to guide LLMs\nperforming task-oriented dialogue (TOD). We evaluate ReAct-based LLMs\n(ReAct-LLMs) both in simulation and with real users. While ReAct-LLMs severely\nunderperform state-of-the-art approaches on success rate in simulation, this\ndifference becomes less pronounced in human evaluation. Moreover, compared to\nthe baseline, humans report higher subjective satisfaction with ReAct-LLM\ndespite its lower success rate, most likely thanks to its natural and\nconfidently phrased responses.",
      "tldr_zh": "这篇论文探讨了将 ReAct 提示策略应用于任务导向对话 (TOD) 的可能性，旨在通过推理和行动增强大型语言模型 (LLMs) 的性能。研究评估了基于 ReAct 的 LLMs (ReAct-LLMs) 在模拟环境和真实用户互动中的表现，结果显示其在模拟中的成功率远低于最先进方法，但在人类评估中差异较小。值得注意的是，尽管成功率较低，ReAct-LLMs 的自然且自信的响应导致了更高的用户主观满意度，这揭示了 ReAct 策略的潜在优势和局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01262v2",
      "published_date": "2024-12-02 08:30:22 UTC",
      "updated_date": "2025-03-17 10:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:47:42.944791"
    },
    {
      "arxiv_id": "2412.01253v5",
      "title": "Yi-Lightning Technical Report",
      "title_zh": "Yi-Lightning 技术报告",
      "authors": [
        "Alan Wake",
        "Bei Chen",
        "C. X. Lv",
        "Chao Li",
        "Chengen Huang",
        "Chenglin Cai",
        "Chujie Zheng",
        "Daniel Cooper",
        "Fan Zhou",
        "Feng Hu",
        "Ge Zhang",
        "Guoyin Wang",
        "Heng Ji",
        "Howard Qiu",
        "Jiangcheng Zhu",
        "Jun Tian",
        "Katherine Su",
        "Lihuan Zhang",
        "Liying Li",
        "Ming Song",
        "Mou Li",
        "Peng Liu",
        "Qicheng Hu",
        "Shawn Wang",
        "Shijun Zhou",
        "Shiming Yang",
        "Shiyong Li",
        "Tianhang Zhu",
        "Wen Xie",
        "Wenhao Huang",
        "Xiang He",
        "Xiaobo Chen",
        "Xiaohui Hu",
        "Xiaoyi Ren",
        "Xinyao Niu",
        "Yanpeng Li",
        "Yongke Zhao",
        "Yongzhen Luo",
        "Yuchi Xu",
        "Yuxuan Sha",
        "Zhaodong Yan",
        "Zhiyuan Liu",
        "Zirui Zhang",
        "Zonghong Dai"
      ],
      "abstract": "This technical report presents Yi-Lightning, our latest flagship large\nlanguage model (LLM). It achieves exceptional performance, ranking 6th overall\non Chatbot Arena, with particularly strong results (2nd to 4th place) in\nspecialized categories including Chinese, Math, Coding, and Hard Prompts.\nYi-Lightning leverages an enhanced Mixture-of-Experts (MoE) architecture,\nfeaturing advanced expert segmentation and routing mechanisms coupled with\noptimized KV-caching techniques. Our development process encompasses\ncomprehensive pre-training, supervised fine-tuning (SFT), and reinforcement\nlearning from human feedback (RLHF), where we devise deliberate strategies for\nmulti-stage training, synthetic data construction, and reward modeling.\nFurthermore, we implement RAISE (Responsible AI Safety Engine), a\nfour-component framework to address safety issues across pre-training,\npost-training, and serving phases. Empowered by our scalable super-computing\ninfrastructure, all these innovations substantially reduce training, deployment\nand inference costs while maintaining high-performance standards. With further\nevaluations on public academic benchmarks, Yi-Lightning demonstrates\ncompetitive performance against top-tier LLMs, while we observe a notable\ndisparity between traditional, static benchmark results and real-world, dynamic\nhuman preferences. This observation prompts a critical reassessment of\nconventional benchmarks' utility in guiding the development of more intelligent\nand powerful AI systems for practical applications. Yi-Lightning is now\navailable through our developer platform at https://platform.lingyiwanwu.com.",
      "tldr_zh": "本报告介绍了 Yi-Lightning，一款旗舰大型语言模型 (LLM)，在 Chatbot Arena 整体排名第 6 位，并在中文、数学、编码和困难提示等专业类别中位居 2 到 4 位。Yi-Lightning 采用增强的 Mixture-of-Experts (MoE) 架构，结合高级专家分割、路由机制和优化的 KV-caching 技术，以降低训练、部署和推理成本。开发过程包括全面预训练、监督微调 (SFT) 和强化学习从人类反馈 (RLHF)，并通过 RAISE（Responsible AI Safety Engine）框架在预训练、后训练和服务阶段处理安全问题。实验结果显示，Yi-Lightning 在公共基准上与顶级 LLM 竞争性能，但强调传统基准与真实人类偏好的差距，提示需重新评估基准在实际应用中的效用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01253v5",
      "published_date": "2024-12-02 08:22:56 UTC",
      "updated_date": "2025-01-22 15:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:47:54.989840"
    },
    {
      "arxiv_id": "2412.01250v3",
      "title": "Collaborative Instance Object Navigation: Leveraging Uncertainty-Awareness to Minimize Human-Agent Dialogues",
      "title_zh": "协作实例对象导航：利用不确定性意识最小化人-代理对话",
      "authors": [
        "Francesco Taioli",
        "Edoardo Zorzi",
        "Gianni Franchi",
        "Alberto Castellini",
        "Alessandro Farinelli",
        "Marco Cristani",
        "Yiming Wang"
      ],
      "abstract": "Language-driven instance object navigation assumes that human users initiate\nthe task by providing a detailed description of the target instance to the\nembodied agent. While this description is crucial for distinguishing the target\nfrom visually similar instances in a scene, providing it prior to navigation\ncan be demanding for human. To bridge this gap, we introduce Collaborative\nInstance object Navigation (CoIN), a new task setting where the agent actively\nresolve uncertainties about the target instance during navigation in natural,\ntemplate-free, open-ended dialogues with human. We propose a novel\ntraining-free method, Agent-user Interaction with UncerTainty Awareness\n(AIUTA), which operates independently from the navigation policy, and focuses\non the human-agent interaction reasoning with Vision-Language Models (VLMs) and\nLarge Language Models (LLMs). First, upon object detection, a Self-Questioner\nmodel initiates a self-dialogue within the agent to obtain a complete and\naccurate observation description with a novel uncertainty estimation technique.\nThen, an Interaction Trigger module determines whether to ask a question to the\nhuman, continue or halt navigation, minimizing user input. For evaluation, we\nintroduce CoIN-Bench, with a curated dataset designed for challenging\nmulti-instance scenarios. CoIN-Bench supports both online evaluation with\nhumans and reproducible experiments with simulated user-agent interactions. On\nCoIN-Bench, we show that AIUTA serves as a competitive baseline, while existing\nlanguage-driven instance navigation methods struggle in complex multi-instance\nscenes. Code and benchmark will be available upon acceptance at\nhttps://intelligolabs.github.io/CoIN/",
      "tldr_zh": "该研究引入了Collaborative Instance object Navigation (CoIN)，一种新任务框架，让代理在导航过程中通过自然对话主动解决目标实例的不确定性，从而减少用户预先提供详细描述的需求。提出了一种无训练方法Agent-user Interaction with UncerTainty Awareness (AIUTA)，利用Vision-Language Models (VLMs)和Large Language Models (LLMs)进行交互推理，包括Self-Questioner模块生成内部自对话以估计不确定性，以及Interaction Trigger模块决定是否向人类提问以最小化对话。实验在CoIN-Bench数据集上显示，AIUTA在复杂多实例场景中表现出色，作为竞争性基准，而现有语言驱动导航方法表现较差。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "https://intelligolabs.github.io/CoIN/",
      "pdf_url": "http://arxiv.org/pdf/2412.01250v3",
      "published_date": "2024-12-02 08:16:38 UTC",
      "updated_date": "2025-03-18 16:09:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:48:06.617964"
    },
    {
      "arxiv_id": "2412.01245v1",
      "title": "Revisiting Generative Policies: A Simpler Reinforcement Learning Algorithmic Perspective",
      "title_zh": "重新审视生成式策略：强化学习的更简单算法视角",
      "authors": [
        "Jinouwen Zhang",
        "Rongkun Xue",
        "Yazhe Niu",
        "Yun Chen",
        "Jing Yang",
        "Hongsheng Li",
        "Yu Liu"
      ],
      "abstract": "Generative models, particularly diffusion models, have achieved remarkable\nsuccess in density estimation for multimodal data, drawing significant interest\nfrom the reinforcement learning (RL) community, especially in policy modeling\nin continuous action spaces. However, existing works exhibit significant\nvariations in training schemes and RL optimization objectives, and some methods\nare only applicable to diffusion models. In this study, we compare and analyze\nvarious generative policy training and deployment techniques, identifying and\nvalidating effective designs for generative policy algorithms. Specifically, we\nrevisit existing training objectives and classify them into two categories,\neach linked to a simpler approach. The first approach, Generative Model Policy\nOptimization (GMPO), employs a native advantage-weighted regression formulation\nas the training objective, which is significantly simpler than previous\nmethods. The second approach, Generative Model Policy Gradient (GMPG), offers a\nnumerically stable implementation of the native policy gradient method. We\nintroduce a standardized experimental framework named GenerativeRL. Our\nexperiments demonstrate that the proposed methods achieve state-of-the-art\nperformance on various offline-RL datasets, offering a unified and practical\nguideline for training and deploying generative policies.",
      "tldr_zh": "本文重新审视生成模型（尤其是diffusion models）在强化学习（RL）中的应用，针对连续动作空间的政策建模问题，分析并分类现有训练目标为两类更简单的算法：Generative Model Policy Optimization (GMPO) 使用优势加权回归作为训练目标，以及Generative Model Policy Gradient (GMPG) 提供数值稳定的策略梯度方法。研究引入标准化实验框架GenerativeRL，通过实验验证这些方法在各种offline-RL数据集上实现最先进性能。总体上，这为生成政策的训练和部署提供了统一的实用指南。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01245v1",
      "published_date": "2024-12-02 08:06:07 UTC",
      "updated_date": "2024-12-02 08:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:48:19.430849"
    },
    {
      "arxiv_id": "2412.01243v3",
      "title": "Schedule On the Fly: Diffusion Time Prediction for Faster and Better Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zilyu Ye",
        "Zhiyang Chen",
        "Tiancheng Li",
        "Zemin Huang",
        "Weijian Luo",
        "Guo-Jun Qi"
      ],
      "abstract": "Diffusion and flow matching models have achieved remarkable success in\ntext-to-image generation. However, these models typically rely on the\npredetermined denoising schedules for all prompts. The multi-step reverse\ndiffusion process can be regarded as a kind of chain-of-thought for generating\nhigh-quality images step by step. Therefore, diffusion models should reason for\neach instance to adaptively determine the optimal noise schedule, achieving\nhigh generation quality with sampling efficiency. In this paper, we introduce\nthe Time Prediction Diffusion Model (TPDM) for this. TPDM employs a\nplug-and-play Time Prediction Module (TPM) that predicts the next noise level\nbased on current latent features at each denoising step. We train the TPM using\nreinforcement learning to maximize a reward that encourages high final image\nquality while penalizing excessive denoising steps. With such an adaptive\nscheduler, TPDM not only generates high-quality images that are aligned closely\nwith human preferences but also adjusts diffusion time and the number of\ndenoising steps on the fly, enhancing both performance and efficiency. With\nStable Diffusion 3 Medium architecture, TPDM achieves an aesthetic score of\n5.44 and a human preference score (HPS) of 29.59, while using around 50% fewer\ndenoising steps to achieve better performance.",
      "tldr_zh": "本论文提出 Time Prediction Diffusion Model (TPDM)，一种动态调整去噪时间表的方法，旨在提升文本到图像生成的质量和效率，解决传统扩散模型依赖固定时间表的局限性。TPDM 引入可插拔的 Time Prediction Module (TPM)，该模块在每个去噪步骤基于当前潜在特征预测下一个噪声水平，并通过强化学习训练以最大化最终图像质量同时减少步骤数量。实验结果显示，在 Stable Diffusion 3 Medium 架构上，TPDM 实现了 5.44 的 aesthetic score 和 29.59 的 HPS，同时仅使用约 50% 的去噪步骤，显著提高了性能和采样效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01243v3",
      "published_date": "2024-12-02 08:05:26 UTC",
      "updated_date": "2025-03-05 11:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:48:31.398273"
    },
    {
      "arxiv_id": "2412.01233v1",
      "title": "Best Practices for Large Language Models in Radiology",
      "title_zh": "放射学中大语言模型的最佳实践",
      "authors": [
        "Christian Bluethgen",
        "Dave Van Veen",
        "Cyril Zakka",
        "Katherine Link",
        "Aaron Fanous",
        "Roxana Daneshjou",
        "Thomas Frauenfelder",
        "Curtis Langlotz",
        "Sergios Gatidis",
        "Akshay Chaudhari"
      ],
      "abstract": "At the heart of radiological practice is the challenge of integrating complex\nimaging data with clinical information to produce actionable insights. Nuanced\napplication of language is key for various activities, including managing\nrequests, describing and interpreting imaging findings in the context of\nclinical data, and concisely documenting and communicating the outcomes. The\nemergence of large language models (LLMs) offers an opportunity to improve the\nmanagement and interpretation of the vast data in radiology. Despite being\nprimarily general-purpose, these advanced computational models demonstrate\nimpressive capabilities in specialized language-related tasks, even without\nspecific training. Unlocking the potential of LLMs for radiology requires basic\nunderstanding of their foundations and a strategic approach to navigate their\nidiosyncrasies. This review, drawing from practical radiology and machine\nlearning expertise and recent literature, provides readers insight into the\npotential of LLMs in radiology. It examines best practices that have so far\nstood the test of time in the rapidly evolving landscape of LLMs. This includes\npractical advice for optimizing LLM characteristics for radiology practices\nalong with limitations, effective prompting, and fine-tuning strategies.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在放射学中的最佳实践，旨在帮助整合复杂影像数据与临床信息以产生可行动见解。论文强调LLMs在管理请求、描述解释影像发现以及文档沟通方面的潜力，即使未经特定训练也能处理专业任务。通过结合放射学和机器学习经验以及最新文献，该研究提供优化LLMs特性的实用建议，包括有效prompting和fine-tuning策略，同时讨论了其限制以确保可靠应用。总的来说，这为放射学领域提升数据管理和解释效率提供了战略指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "A redacted version of this preprint has been accepted for publication\n  in Radiology",
      "pdf_url": "http://arxiv.org/pdf/2412.01233v1",
      "published_date": "2024-12-02 07:54:55 UTC",
      "updated_date": "2024-12-02 07:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:48:42.210177"
    },
    {
      "arxiv_id": "2412.01868v1",
      "title": "Composition of Experts: A Modular Compound AI System Leveraging Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Swayambhoo Jain",
        "Ravi Raju",
        "Bo Li",
        "Zoltan Csaki",
        "Jonathan Li",
        "Kaizhao Liang",
        "Guoyao Feng",
        "Urmish Thakkar",
        "Anand Sampat",
        "Raghu Prabhakar",
        "Sumati Jairath"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable advancements, but their\nmonolithic nature presents challenges in terms of scalability, cost, and\ncustomization. This paper introduces the Composition of Experts (CoE), a\nmodular compound AI system leveraging multiple expert LLMs. CoE leverages a\nrouter to dynamically select the most appropriate expert for a given input,\nenabling efficient utilization of resources and improved performance. We\nformulate the general problem of training a CoE and discuss inherent\ncomplexities associated with it. We propose a two-step routing approach to\naddress these complexities that first uses a router to classify the input into\ndistinct categories followed by a category-to-expert mapping to obtain desired\nexperts. CoE offers a flexible and cost-effective solution to build compound AI\nsystems. Our empirical evaluation demonstrates the effectiveness of CoE in\nachieving superior performance with reduced computational overhead. Given that\nCoE comprises of many expert LLMs it has unique system requirements for\ncost-effective serving. We present an efficient implementation of CoE\nleveraging SambaNova SN40L RDUs unique three-tiered memory architecture. CoEs\nobtained using open weight LLMs Qwen/Qwen2-7B-Instruct, google/gemma-2-9b-it,\ngoogle/gemma-2-27b-it, meta-llama/Llama-3.1-70B-Instruct and\nQwen/Qwen2-72B-Instruct achieve a score of $59.4$ with merely $31$ billion\naverage active parameters on Arena-Hard and a score of $9.06$ with $54$ billion\naverage active parameters on MT-Bench.",
      "tldr_zh": "本研究提出 Composition of Experts (CoE)，一种模块化的复合 AI 系统，利用多个专家 Large Language Models (LLMs) 来解决传统 LLMs 在可扩展性、成本和自定义方面的挑战。CoE 通过一个动态路由器动态选择最合适的专家模型，并采用两步路由方法：先分类输入，然后映射到特定专家，从而提高资源利用效率和整体性能。实验结果显示，基于模型如 Qwen/Qwen2-7B-Instruct 等构建的 CoE 在 Arena-Hard 基准上得分 59.4（平均活跃参数仅 31 亿），在 MT-Bench 上得分 9.06（平均活跃参数 54 亿），实现了优越性能和降低的计算开销。总的来说，CoE 提供了一个灵活、成本有效的解决方案，为构建高效复合 AI 系统奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01868v1",
      "published_date": "2024-12-02 07:43:21 UTC",
      "updated_date": "2024-12-02 07:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:48:55.367072"
    },
    {
      "arxiv_id": "2412.01223v1",
      "title": "PainterNet: Adaptive Image Inpainting with Actual-Token Attention and Diverse Mask Control",
      "title_zh": "PainterNet：自适应图像修复，采用实际标记注意力和多样化掩码控制",
      "authors": [
        "Ruichen Wang",
        "Junliang Zhang",
        "Qingsong Xie",
        "Chen Chen",
        "Haonan Lu"
      ],
      "abstract": "Recently, diffusion models have exhibited superior performance in the area of\nimage inpainting. Inpainting methods based on diffusion models can usually\ngenerate realistic, high-quality image content for masked areas. However, due\nto the limitations of diffusion models, existing methods typically encounter\nproblems in terms of semantic consistency between images and text, and the\nediting habits of users. To address these issues, we present PainterNet, a\nplugin that can be flexibly embedded into various diffusion models. To generate\nimage content in the masked areas that highly aligns with the user input\nprompt, we proposed local prompt input, Attention Control Points (ACP), and\nActual-Token Attention Loss (ATAL) to enhance the model's focus on local areas.\nAdditionally, we redesigned the MASK generation algorithm in training and\ntesting dataset to simulate the user's habit of applying MASK, and introduced a\ncustomized new training dataset, PainterData, and a benchmark dataset,\nPainterBench. Our extensive experimental analysis exhibits that PainterNet\nsurpasses existing state-of-the-art models in key metrics including image\nquality and global/local text consistency.",
      "tldr_zh": "本研究针对扩散模型(diffusion models)在图像修复领域的语义一致性和用户编辑习惯问题，提出了PainterNet，一种可灵活嵌入各种扩散模型的插件。PainterNet 通过引入本地提示输入、Attention Control Points (ACP) 和 Actual-Token Attention Loss (ATAL)，增强模型对局部区域的关注，从而生成与用户输入提示高度一致的修复内容。同时，该方法重新设计了MASK生成算法，并创建了新的训练数据集PainterData和基准数据集PainterBench，以模拟用户实际操作习惯。实验结果表明，PainterNet在图像质量以及全局/局部文本一致性等关键指标上超过了现有最先进模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01223v1",
      "published_date": "2024-12-02 07:40:47 UTC",
      "updated_date": "2024-12-02 07:40:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:49:07.236032"
    },
    {
      "arxiv_id": "2412.01218v1",
      "title": "FD-LLM: Large Language Model for Fault Diagnosis of Machines",
      "title_zh": "FD-LLM：机器故障诊断的大型语言模型",
      "authors": [
        "Hamzah A. A. M. Qaid",
        "Bo Zhang",
        "Dan Li",
        "See-Kiong Ng",
        "Wei Li"
      ],
      "abstract": "Large language models (LLMs) are effective at capturing complex, valuable\nconceptual representations from textual data for a wide range of real-world\napplications. However, in fields like Intelligent Fault Diagnosis (IFD),\nincorporating additional sensor data-such as vibration signals, temperature\nreadings, and operational metrics-is essential but it is challenging to capture\nsuch sensor data information within traditional text corpora. This study\nintroduces a novel IFD approach by effectively adapting LLMs to numerical data\ninputs for identifying various machine faults from time-series sensor data. We\npropose FD-LLM, an LLM framework specifically designed for fault diagnosis by\nformulating the training of the LLM as a multi-class classification problem. We\nexplore two methods for encoding vibration signals: the first method uses a\nstring-based tokenization technique to encode vibration signals into text\nrepresentations, while the second extracts statistical features from both the\ntime and frequency domains as statistical summaries of each signal. We assess\nthe fault diagnosis capabilities of four open-sourced LLMs based on the FD-LLM\nframework, and evaluate the models' adaptability and generalizability under\nvarious operational conditions and machine components, namely for traditional\nfault diagnosis, cross-operational conditions, and cross-machine component\nsettings. Our results show that LLMs such as Llama3 and Llama3-instruct\ndemonstrate strong fault detection capabilities and significant adaptability\nacross different operational conditions, outperforming state-of-the-art deep\nlearning (DL) approaches in many cases.",
      "tldr_zh": "该研究提出FD-LLM框架，将Large Language Models (LLMs)应用于Intelligent Fault Diagnosis (IFD)，以处理机器故障诊断中的时序传感器数据，如振动信号。方法包括两种编码技术：使用字符串-based tokenization将信号转化为文本表示，或提取时域和频域的统计特征，并将LLM训练制定为多类分类问题。实验评估了Llama3和Llama3-instruct等开源LLMs，在传统故障诊断、跨操作条件和跨机器组件场景下表现出强适应性和泛化性，往往优于现有深度学习（DL）方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 2 figures, 16 tables, including the tables in the appendix",
      "pdf_url": "http://arxiv.org/pdf/2412.01218v1",
      "published_date": "2024-12-02 07:36:35 UTC",
      "updated_date": "2024-12-02 07:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:49:18.899141"
    },
    {
      "arxiv_id": "2412.01202v1",
      "title": "Neuron Abandoning Attention Flow: Visual Explanation of Dynamics inside CNN Models",
      "title_zh": "神经元抛弃注意力流：卷积神经网络模型内部动态的视觉解释",
      "authors": [
        "Yi Liao",
        "Yongsheng Gao",
        "Weichuan Zhang"
      ],
      "abstract": "In this paper, we present a Neuron Abandoning Attention Flow (NAFlow) method\nto address the open problem of visually explaining the attention evolution\ndynamics inside CNNs when making their classification decisions. A novel\ncascading neuron abandoning back-propagation algorithm is designed to trace\nneurons in all layers of a CNN that involve in making its prediction to address\nthe problem of significant interference from abandoned neurons. Firstly, a\nNeuron Abandoning Back-Propagation (NA-BP) module is proposed to generate\nBack-Propagated Feature Maps (BPFM) by using the inverse function of the\nintermediate layers of CNN models, on which the neurons not used for\ndecision-making are abandoned. Meanwhile, the cascading NA-BP modules calculate\nthe tensors of importance coefficients which are linearly combined with the\ntensors of BPFMs to form the NAFlow. Secondly, to be able to visualize\nattention flow for similarity metric-based CNN models, a new channel\ncontribution weights module is proposed to calculate the importance\ncoefficients via Jacobian Matrix. The effectiveness of the proposed NAFlow is\nvalidated on nine widely-used CNN models for various tasks of general image\nclassification, contrastive learning classification, few-shot image\nclassification, and image retrieval.",
      "tldr_zh": "本文提出 Neuron Abandoning Attention Flow (NAFlow) 方法，用于可视化解释 CNN 模型在分类决策过程中的注意力演变动态，解决无关神经元干扰的问题。核心组件包括 Neuron Abandoning Back-Propagation (NA-BP) 模块，通过中间层的逆函数生成 Back-Propagated Feature Maps (BPFM)，并利用级联机制计算重要性系数张量与 BPFM 线性组合形成 NAFlow。对于基于相似性度量的 CNN 模型，该方法引入 channel contribution weights 模块，通过 Jacobian Matrix 计算重要性系数。实验在九个广泛使用的 CNN 模型上验证了 NAFlow 的有效性，适用于一般图像分类、对比学习分类、少样本图像分类和图像检索任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01202v1",
      "published_date": "2024-12-02 07:14:15 UTC",
      "updated_date": "2024-12-02 07:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:49:32.248612"
    },
    {
      "arxiv_id": "2412.01199v1",
      "title": "TinyFusion: Diffusion Transformers Learned Shallow",
      "title_zh": "翻译失败",
      "authors": [
        "Gongfan Fang",
        "Kunjun Li",
        "Xinyin Ma",
        "Xinchao Wang"
      ],
      "abstract": "Diffusion Transformers have demonstrated remarkable capabilities in image\ngeneration but often come with excessive parameterization, resulting in\nconsiderable inference overhead in real-world applications. In this work, we\npresent TinyFusion, a depth pruning method designed to remove redundant layers\nfrom diffusion transformers via end-to-end learning. The core principle of our\napproach is to create a pruned model with high recoverability, allowing it to\nregain strong performance after fine-tuning. To accomplish this, we introduce a\ndifferentiable sampling technique to make pruning learnable, paired with a\nco-optimized parameter to simulate future fine-tuning. While prior works focus\non minimizing loss or error after pruning, our method explicitly models and\noptimizes the post-fine-tuning performance of pruned models. Experimental\nresults indicate that this learnable paradigm offers substantial benefits for\nlayer pruning of diffusion transformers, surpassing existing importance-based\nand error-based methods. Additionally, TinyFusion exhibits strong\ngeneralization across diverse architectures, such as DiTs, MARs, and SiTs.\nExperiments with DiT-XL show that TinyFusion can craft a shallow diffusion\ntransformer at less than 7% of the pre-training cost, achieving a 2$\\times$\nspeedup with an FID score of 2.86, outperforming competitors with comparable\nefficiency. Code is available at https://github.com/VainF/TinyFusion.",
      "tldr_zh": "本研究提出TinyFusion，一种深度修剪方法，通过端到端学习移除Diffusion Transformers中冗余层，以减少参数量并降低推理开销。核心创新包括引入可微采样技术使修剪过程可学习，并优化参数模拟未来微调，以显式提升修剪后模型的恢复性能，从而超越传统基于重要性和错误的方法。在实验中，TinyFusion在DiTs、MARs和SiTs等架构上显示出强泛化能力，例如对DiT-XL模型的修剪仅需不到7%的预训练成本，实现2倍加速并获得FID score为2.86的出色表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01199v1",
      "published_date": "2024-12-02 07:05:39 UTC",
      "updated_date": "2024-12-02 07:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:49:44.064170"
    },
    {
      "arxiv_id": "2412.01197v2",
      "title": "InstantSwap: Fast Customized Concept Swapping across Sharp Shape Differences",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyang Zhu",
        "Kai Li",
        "Yue Ma",
        "Longxiang Tang",
        "Chengyu Fang",
        "Chubin Chen",
        "Qifeng Chen",
        "Xiu Li"
      ],
      "abstract": "Recent advances in Customized Concept Swapping (CCS) enable a text-to-image\nmodel to swap a concept in the source image with a customized target concept.\nHowever, the existing methods still face the challenges of inconsistency and\ninefficiency. They struggle to maintain consistency in both the foreground and\nbackground during concept swapping, especially when the shape difference is\nlarge between objects. Additionally, they either require time-consuming\ntraining processes or involve redundant calculations during inference. To\ntackle these issues, we introduce InstantSwap, a new CCS method that aims to\nhandle sharp shape disparity at speed. Specifically, we first extract the bbox\nof the object in the source image automatically based on attention map analysis\nand leverage the bbox to achieve both foreground and background consistency.\nFor background consistency, we remove the gradient outside the bbox during the\nswapping process so that the background is free from being modified. For\nforeground consistency, we employ a cross-attention mechanism to inject\nsemantic information into both source and target concepts inside the box. This\nhelps learn semantic-enhanced representations that encourage the swapping\nprocess to focus on the foreground objects. To improve swapping speed, we avoid\ncomputing gradients at each timestep but instead calculate them periodically to\nreduce the number of forward passes, which improves efficiency a lot with a\nlittle sacrifice on performance. Finally, we establish a benchmark dataset to\nfacilitate comprehensive evaluation. Extensive evaluations demonstrate the\nsuperiority and versatility of InstantSwap. Project Page:\nhttps://instantswap.github.io/",
      "tldr_zh": "该研究提出了InstantSwap，一种快速的Customized Concept Swapping (CCS)方法，旨在处理物体形状差异大的图像概念交换问题，同时解决现有方法的不一致性和低效率挑战。具体而言，InstantSwap通过自动提取源图像物体的bbox（基于注意力图分析）来确保前景和背景一致性：移除bbox外梯度以保护背景，并使用交叉注意力机制注入语义信息以增强前景交换。此外，该方法通过周期性计算梯度减少前向传播次数，大幅提高处理速度，并建立了一个基准数据集进行评估。实验结果显示，InstantSwap在广泛测试中表现出色，具有优越的稳定性和多功能性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://instantswap.github.io/. Github Page:\n  https://github.com/chenyangzhu1/InstantSwap",
      "pdf_url": "http://arxiv.org/pdf/2412.01197v2",
      "published_date": "2024-12-02 06:59:52 UTC",
      "updated_date": "2024-12-03 03:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:49:54.662589"
    },
    {
      "arxiv_id": "2412.01195v1",
      "title": "Memory-Efficient Training for Deep Speaker Embedding Learning in Speaker Verification",
      "title_zh": "用于说话者验证的深度说话者嵌入学习的内存高效训练",
      "authors": [
        "Bei Liu",
        "Yanmin Qian"
      ],
      "abstract": "Recent speaker verification (SV) systems have shown a trend toward adopting\ndeeper speaker embedding extractors. Although deeper and larger neural networks\ncan significantly improve performance, their substantial memory requirements\nhinder training on consumer GPUs. In this paper, we explore a memory-efficient\ntraining strategy for deep speaker embedding learning in resource-constrained\nscenarios. Firstly, we conduct a systematic analysis of GPU memory allocation\nduring SV system training. Empirical observations show that activations and\noptimizer states are the main sources of memory consumption. For activations,\nwe design two types of reversible neural networks which eliminate the need to\nstore intermediate activations during back-propagation, thereby significantly\nreducing memory usage without performance loss. For optimizer states, we\nintroduce a dynamic quantization approach that replaces the original 32-bit\nfloating-point values with a dynamic tree-based 8-bit data type. Experimental\nresults on VoxCeleb demonstrate that the reversible variants of ResNets and\nDF-ResNets can perform training without the need to cache activations in GPU\nmemory. In addition, the 8-bit versions of SGD and Adam save 75% of memory\ncosts while maintaining performance compared to their 32-bit counterparts.\nFinally, a detailed comparison of memory usage and performance indicates that\nour proposed models achieve up to 16.2x memory savings, with nearly identical\nparameters and performance compared to the vanilla systems. In contrast to the\nprevious need for multiple high-end GPUs such as the A100, we can effectively\ntrain deep speaker embedding extractors with just one or two consumer-level\n2080Ti GPUs.",
      "tldr_zh": "这篇论文针对说话人验证（SV）系统中深度说话人嵌入提取器的训练内存问题，提出了一种高效策略，以适应资源受限的消费级 GPU。研究者通过系统分析发现激活和优化器状态是主要内存消耗源，并设计了两种可逆神经网络（reversible neural networks），在反向传播中无需存储中间激活，同时引入动态量化（dynamic quantization）方法，将优化器状态从 32 位浮点数转换为 8 位数据类型。实验结果显示，在 VoxCeleb 数据集上，该方法实现了高达 16.2x 的内存节省，同时保持了性能，使得深层模型可以在单个或两个 2080Ti GPU 上训练，而非依赖高端 GPU。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing",
      "pdf_url": "http://arxiv.org/pdf/2412.01195v1",
      "published_date": "2024-12-02 06:57:46 UTC",
      "updated_date": "2024-12-02 06:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:50:07.804193"
    },
    {
      "arxiv_id": "2412.01191v1",
      "title": "A Semantic Communication System for Real-time 3D Reconstruction Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxing Zhang",
        "Luosong Guo",
        "Kun Zhu",
        "Houming Qiu"
      ],
      "abstract": "3D semantic maps have played an increasingly important role in high-precision\nrobot localization and scene understanding. However, real-time construction of\nsemantic maps requires mobile edge devices with extremely high computing power,\nwhich are expensive and limit the widespread application of semantic mapping.\nIn order to address this limitation, inspired by cloud-edge collaborative\ncomputing and the high transmission efficiency of semantic communication, this\npaper proposes a method to achieve real-time semantic mapping tasks with\nlimited-resource mobile devices. Specifically, we design an encoding-decoding\nsemantic communication framework for real-time semantic mapping tasks under\nlimited-resource situations. In addition, considering the impact of different\nchannel conditions on communication, this paper designs a module based on the\nattention mechanism to achieve stable data transmission under various channel\nconditions. In terms of simulation experiments, based on the TUM dataset, it\nwas verified that the system has an error of less than 0.1% compared to the\ngroundtruth in mapping and localization accuracy and is superior to some novel\nsemantic communication algorithms in real-time performance and channel\nadaptation. Besides, we implement a prototype system to verify the\neffectiveness of the proposed framework and designed module in real indoor\nscenarios. The results show that our system can complete real-time semantic\nmapping tasks for common indoor objects (chairs, computers, people, etc.) with\na limited-resource device, and the mapping update time is less than 1 second.",
      "tldr_zh": "这篇论文提出了一种语义通信系统（semantic communication system），旨在解决资源有限的移动设备在实时3D重建任务中计算能力不足的问题，通过云边协作实现高效的语义映射。系统设计了一个编码-解码框架，并引入基于注意力机制（attention mechanism）的模块，以适应不同通道条件，确保数据传输的稳定性和实时性。实验基于TUM数据集验证了系统的映射和定位准确性误差小于0.1%，并在实际室内场景中证明其能实时重建常见物体（如椅子、电脑、人等），映射更新时间小于1秒。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 11 figures, acceptted by 2024 8th International Conference\n  on Communication and Information Systems (ICCIS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.01191v1",
      "published_date": "2024-12-02 06:50:05 UTC",
      "updated_date": "2024-12-02 06:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:50:18.619758"
    },
    {
      "arxiv_id": "2412.01181v1",
      "title": "Training Stiff Neural Ordinary Differential Equations with Explicit Exponential Integration Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Colby Fronk",
        "Linda Petzold"
      ],
      "abstract": "Stiff ordinary differential equations (ODEs) are common in many science and\nengineering fields, but standard neural ODE approaches struggle to accurately\nlearn these stiff systems, posing a significant barrier to widespread adoption\nof neural ODEs. In our earlier work, we addressed this challenge by utilizing\nsingle-step implicit methods for solving stiff neural ODEs. While effective,\nthese implicit methods are computationally costly and can be complex to\nimplement. This paper expands on our earlier work by exploring explicit\nexponential integration methods as a more efficient alternative. We evaluate\nthe potential of these explicit methods to handle stiff dynamics in neural\nODEs, aiming to enhance their applicability to a broader range of scientific\nand engineering problems. We found the integrating factor Euler (IF Euler)\nmethod to excel in stability and efficiency. While implicit schemes failed to\ntrain the stiff Van der Pol oscillator, the IF Euler method succeeded, even\nwith large step sizes. However, IF Euler's first-order accuracy limits its use,\nleaving the development of higher-order methods for stiff neural ODEs an open\nresearch problem.",
      "tldr_zh": "本文研究了训练刚性neural ordinary differential equations (neural ODEs)的挑战，提出使用显式指数积分方法作为更高效的替代方案，以克服标准方法在刚性系统上的准确性和计算成本问题。实验结果显示，integrating factor Euler (IF Euler)方法在稳定性和效率方面表现出色，能够成功训练刚性Van der Pol oscillator，即使步长较大，而隐式方法则失败了。尽管IF Euler的一阶准确性限制了其广泛应用，但这也指出了开发更高阶方法的开放研究方向。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "cs.SC"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01181v1",
      "published_date": "2024-12-02 06:40:08 UTC",
      "updated_date": "2024-12-02 06:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:50:31.135806"
    },
    {
      "arxiv_id": "2412.01176v1",
      "title": "Superhypergraph Neural Networks and Plithogenic Graph Neural Networks: Theoretical Foundations",
      "title_zh": "翻译失败",
      "authors": [
        "Takaaki Fujita"
      ],
      "abstract": "Hypergraphs extend traditional graphs by allowing edges to connect multiple\nnodes, while superhypergraphs further generalize this concept to represent even\nmore complex relationships. Neural networks, inspired by biological systems,\nare widely used for tasks such as pattern recognition, data classification, and\nprediction. Graph Neural Networks (GNNs), a well-established framework, have\nrecently been extended to Hypergraph Neural Networks (HGNNs), with their\nproperties and applications being actively studied. The Plithogenic Graph\nframework enhances graph representations by integrating multi-valued\nattributes, as well as membership and contradiction functions, enabling the\ndetailed modeling of complex relationships. In the context of handling\nuncertainty, concepts such as Fuzzy Graphs and Neutrosophic Graphs have gained\nprominence. It is well established that Plithogenic Graphs serve as a\ngeneralization of both Fuzzy Graphs and Neutrosophic Graphs. Furthermore, the\nFuzzy Graph Neural Network has been proposed and is an active area of research.\nThis paper establishes the theoretical foundation for the development of\nSuperHyperGraph Neural Networks (SHGNNs) and Plithogenic Graph Neural Networks,\nexpanding the applicability of neural networks to these advanced graph\nstructures. While mathematical generalizations and proofs are presented, future\ncomputational experiments are anticipated.",
      "tldr_zh": "本论文探讨了超图（Hypergraphs）和超超图（Superhypergraphs）的扩展概念，这些结构允许更复杂的节点连接，并将其与神经网络相结合。论文介绍了 Plithogenic Graph 框架，该框架整合多值属性、成员函数和矛盾函数，并证明其是模糊图（Fuzzy Graphs）和中子图（Neutrosophic Graphs）的泛化，从而更好地处理不确定性。核心贡献在于建立了 SuperHyperGraph Neural Networks (SHGNNs) 和 Plithogenic Graph Neural Networks 的理论基础，包括数学泛化和证明，以扩展图神经网络（GNNs）和超图神经网络（HGNNs）的适用性。尽管论文侧重理论，未来仍需进行计算实验来验证这些模型。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "math.CO",
        "math.LO",
        "05C65 - Hypergraphs, 05C82 - Graph theory with applications, 03E72 -\n  Fuzzy set theory"
      ],
      "primary_category": "cs.AI",
      "comment": "77 pages; 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01176v1",
      "published_date": "2024-12-02 06:33:02 UTC",
      "updated_date": "2024-12-02 06:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:50:44.150309"
    },
    {
      "arxiv_id": "2412.01175v2",
      "title": "OBI-Bench: Can LMMs Aid in Study of Ancient Script on Oracle Bones?",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Chen",
        "Tingzhu Chen",
        "Wenjun Zhang",
        "Guangtao Zhai"
      ],
      "abstract": "We introduce OBI-Bench, a holistic benchmark crafted to systematically\nevaluate large multi-modal models (LMMs) on whole-process oracle bone\ninscriptions (OBI) processing tasks demanding expert-level domain knowledge and\ndeliberate cognition. OBI-Bench includes 5,523 meticulously collected\ndiverse-sourced images, covering five key domain problems: recognition,\nrejoining, classification, retrieval, and deciphering. These images span\ncenturies of archaeological findings and years of research by front-line\nscholars, comprising multi-stage font appearances from excavation to synthesis,\nsuch as original oracle bone, inked rubbings, oracle bone fragments, cropped\nsingle characters, and handprinted characters. Unlike existing benchmarks,\nOBI-Bench focuses on advanced visual perception and reasoning with OBI-specific\nknowledge, challenging LMMs to perform tasks akin to those faced by experts.\nThe evaluation of 6 proprietary LMMs as well as 17 open-source LMMs highlights\nthe substantial challenges and demands posed by OBI-Bench. Even the latest\nversions of GPT-4o, Gemini 1.5 Pro, and Qwen-VL-Max are still far from\npublic-level humans in some fine-grained perception tasks. However, they\nperform at a level comparable to untrained humans in deciphering tasks,\nindicating remarkable capabilities in offering new interpretative perspectives\nand generating creative guesses. We hope OBI-Bench can facilitate the community\nto develop domain-specific multi-modal foundation models towards ancient\nlanguage research and delve deeper to discover and enhance these untapped\npotentials of LMMs.",
      "tldr_zh": "本研究引入了 OBI-Bench，一种全面基准，用于系统评估大型多模态模型 (LMMs) 在处理甲骨文 (OBI) 任务中的性能，这些任务需专家级领域知识和认知，包括识别、重组成、分类、检索和破译。基准包含 5,523 张多样来源的图像，覆盖从原始甲骨到合成字符的多阶段字体。实验评估了 6 个专有 LMMs 和 17 个开源 LMMs，结果显示这些模型在精细感知任务中远低于人类水平，但在破译任务中可与未经训练人类相当，并展现出提供新解读视角的潜力。该基准旨在推动社区开发针对古代语言研究的领域特定多模态基础模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025 as a Poster. 31 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.01175v2",
      "published_date": "2024-12-02 06:31:28 UTC",
      "updated_date": "2025-02-11 14:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:50:55.999791"
    },
    {
      "arxiv_id": "2412.01166v2",
      "title": "Object Agnostic 3D Lifting in Space and Time",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Fusco",
        "Shin-Fang Ch'ng",
        "Mosam Dabhi",
        "Simon Lucey"
      ],
      "abstract": "We present a spatio-temporal perspective on category-agnostic 3D lifting of\n2D keypoints over a temporal sequence. Our approach differs from existing\nstate-of-the-art methods that are either: (i) object-agnostic, but can only\noperate on individual frames, or (ii) can model space-time dependencies, but\nare only designed to work with a single object category. Our approach is\ngrounded in two core principles. First, general information about similar\nobjects can be leveraged to achieve better performance when there is little\nobject-specific training data. Second, a temporally-proximate context window is\nadvantageous for achieving consistency throughout a sequence. These two\nprinciples allow us to outperform current state-of-the-art methods on per-frame\nand per-sequence metrics for a variety of animal categories. Lastly, we release\na new synthetic dataset containing 3D skeletons and motion sequences for a\nvariety of animal categories.",
      "tldr_zh": "我们提出了一种类别无关（category-agnostic）的时空3D关键点提升方法，能够处理时间序列数据，与现有方法不同，它既支持对象无关性又能建模时空依赖。核心原则包括利用类似对象的通用信息来提升性能（尤其在对象特定训练数据不足时），以及采用临近时间窗口确保序列一致性。该方法在各种动物类别的每帧和每序列指标上超过了当前最先进方法的表现。最后，我们发布了一个新的合成数据集，包含多种动物类别的3D骨骼和运动序列。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "3DV 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01166v2",
      "published_date": "2024-12-02 06:09:46 UTC",
      "updated_date": "2025-02-10 02:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:51:07.681756"
    },
    {
      "arxiv_id": "2412.01154v1",
      "title": "R.I.P.: A Simple Black-box Attack on Continual Test-time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Trung-Hieu Hoang",
        "Duc Minh Vo",
        "Minh N. Do"
      ],
      "abstract": "Test-time adaptation (TTA) has emerged as a promising solution to tackle the\ncontinual domain shift in machine learning by allowing model parameters to\nchange at test time, via self-supervised learning on unlabeled testing data. At\nthe same time, it unfortunately opens the door to unforeseen vulnerabilities\nfor degradation over time. Through a simple theoretical continual TTA model, we\nsuccessfully identify a risk in the sampling process of testing data that could\neasily degrade the performance of a continual TTA model. We name this risk as\nReusing of Incorrect Prediction (RIP) that TTA attackers can employ or as a\nresult of the unintended query from general TTA users. The risk posed by RIP is\nalso highly realistic, as it does not require prior knowledge of model\nparameters or modification of testing samples. This simple requirement makes\nRIP as the first black-box TTA attack algorithm that stands out from existing\nwhite-box attempts. We extensively benchmark the performance of the most recent\ncontinual TTA approaches when facing the RIP attack, providing insights on its\nsuccess, and laying out potential roadmaps that could enhance the resilience of\nfuture continual TTA systems.",
      "tldr_zh": "该研究揭示了测试时适应(TTA)技术的潜在漏洞，即在持续领域偏移场景中，通过自监督学习调整模型参数可能导致性能退化。作者提出了一种简单黑盒攻击方法Reusing of Incorrect Prediction (RIP)，利用测试数据采样过程中的错误预测重复利用风险，而无需访问模型参数或修改样本。实验基准测试显示，RIP 攻击能显著降低最新持续 TTA 方法的性能，并为提升未来 TTA 系统的鲁棒性提供了潜在改进路线图。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01154v1",
      "published_date": "2024-12-02 05:55:13 UTC",
      "updated_date": "2024-12-02 05:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:51:19.032005"
    },
    {
      "arxiv_id": "2412.01150v2",
      "title": "Representation Learning for Time-Domain High-Energy Astrophysics: Discovery of Extragalactic Fast X-ray Transient XRT 200515",
      "title_zh": "针对时域高能天体物理学的表示学习：河外快速X射线瞬变体XRT 200515的发现",
      "authors": [
        "Steven Dillmann",
        "Juan Rafael Martínez-Galarza",
        "Roberto Soria",
        "Rosanne Di Stefano",
        "Vinay L. Kashyap"
      ],
      "abstract": "We present a novel representation learning method for downstream tasks like\nanomaly detection, unsupervised classification, and similarity searches in\nhigh-energy data sets. This enabled the discovery of a new extragalactic fast\nX-ray transient (FXT) in Chandra archival data, XRT 200515, a\nneedle-in-the-haystack event and the first Chandra FXT of its kind. Recent\nserendipitous discoveries in X-ray astronomy, including FXTs from binary\nneutron star mergers and an extragalactic planetary transit candidate,\nhighlight the need for systematic transient searches in X-ray archives. We\nintroduce new event file representations, E-t maps and E-t-dt cubes, that\neffectively encode both temporal and spectral information, enabling the\nseamless application of machine learning to variable-length event file time\nseries. Our unsupervised learning approach employs PCA or sparse autoencoders\nto extract low-dimensional, informative features from these data\nrepresentations, followed by clustering in the embedding space with DBSCAN. New\ntransients are identified within transient-dominant clusters or through\nnearest-neighbour searches around known transients, producing a catalogue of\n3559 candidates (3447 flares and 112 dips). XRT 200515 exhibits unique temporal\nand spectral variability, including an intense, hard <10s initial burst,\nfollowed by spectral softening in an ~800s oscillating tail. We interpret XRT\n200515 as either the first giant magnetar flare observed at low X-ray energies\nor the first extragalactic Type I X-ray burst from a faint, previously unknown\nlow-mass X-ray binary in the LMC. Our method extends to data sets from other\nobservatories such as XMM-Newton, Swift-XRT, eROSITA, Einstein Probe, and\nupcoming missions like AXIS.",
      "tldr_zh": "本研究提出了一种新的表示学习方法，用于高能天文学数据中的异常检测、无监督分类和相似性搜索，通过引入E-t maps和E-t-dt cubes来有效编码时间和光谱信息，并结合PCA或稀疏自动编码器提取低维特征，再使用DBSCAN进行聚类。利用此方法，在Chandra档案数据中发现了新的外星系快速X射线瞬变事件XRT 200515，这是首个此类Chandra事件，展现出强烈的初始硬X射线爆发和随后的光谱软化振荡尾巴，可能为巨型磁星耀斑或外星系I型X射线爆发。实验生成了一个包含3559个候选物的目录（3447个耀斑和112个下降），并证明该方法可扩展到其他观测台如XMM-Newton和Swift-XRT的数据集，推动了系统性X射线瞬变搜索。",
      "categories": [
        "astro-ph.HE",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.HE",
      "comment": "25 pages, accepted in Monthly Notices of the Royal Astronomical\n  Society",
      "pdf_url": "http://arxiv.org/pdf/2412.01150v2",
      "published_date": "2024-12-02 05:48:31 UTC",
      "updated_date": "2025-03-04 04:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:51:32.630907"
    },
    {
      "arxiv_id": "2412.01129v3",
      "title": "RILQ: Rank-Insensitive LoRA-based Quantization Error Compensation for Boosting 2-bit Large Language Model Accuracy",
      "title_zh": "RILQ：秩不敏感的 LoRA 基于量化误差补偿，用于提升 2-bit",
      "authors": [
        "Geonho Lee",
        "Janghwan Lee",
        "Sukjin Hong",
        "Minsoo Kim",
        "Euijai Ahn",
        "Du-Seong Chang",
        "Jungwook Choi"
      ],
      "abstract": "Low-rank adaptation (LoRA) has become the dominant method for\nparameter-efficient LLM fine-tuning, with LoRA-based quantization error\ncompensation (LQEC) emerging as a powerful tool for recovering accuracy in\ncompressed LLMs. However, LQEC has underperformed in sub-4-bit scenarios, with\nno prior investigation into understanding this limitation. We propose RILQ\n(Rank-Insensitive LoRA-based Quantization Error Compensation) to understand\nfundamental limitation and boost 2-bit LLM accuracy. Based on rank analysis\nrevealing model-wise activation discrepancy loss's rank-insensitive nature,\nRILQ employs this loss to adjust adapters cooperatively across layers, enabling\nrobust error compensation with low-rank adapters. Evaluations on LLaMA-2 and\nLLaMA-3 demonstrate RILQ's consistent improvements in 2-bit quantized inference\nacross various state-of-the-art quantizers and enhanced accuracy in\ntask-specific fine-tuning. RILQ maintains computational efficiency comparable\nto existing LoRA methods, enabling adapter-merged weight-quantized LLM\ninference with significantly enhanced accuracy, making it a promising approach\nfor boosting 2-bit LLM performance. Our code is available at\nhttps://github.com/aiha-lab/RILQ.",
      "tldr_zh": "该论文提出了 RILQ（Rank-Insensitive LoRA-based Quantization Error Compensation），一种针对低秩适配（LoRA）量化错误补偿的方法，旨在提升 2-bit 大语言模型（LLMs）的准确性。RILQ 通过分析模型激活差异损失的秩不敏感特性，跨层合作调整适配器，实现稳健的量化错误补偿，同时保持低秩适配器的计算效率。实验在 LLaMA-2 和 LLaMA-3 模型上显示，RILQ 显著提高了 2-bit 量化推理的准确性，并在各种量化器和任务特定微调中表现出一致改进，使其成为提升低位量化 LLM 性能的 promising 方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01129v3",
      "published_date": "2024-12-02 05:09:56 UTC",
      "updated_date": "2025-03-28 04:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:51:43.773157"
    },
    {
      "arxiv_id": "2412.01122v1",
      "title": "TAS-TsC: A Data-Driven Framework for Estimating Time of Arrival Using Temporal-Attribute-Spatial Tri-space Coordination of Truck Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Mengran Li",
        "Junzhou Chen",
        "Guanying Jiang",
        "Fuliang Li",
        "Ronghui Zhang",
        "Siyuan Gong",
        "Zhihan Lv"
      ],
      "abstract": "Accurately estimating time of arrival (ETA) for trucks is crucial for\noptimizing transportation efficiency in logistics. GPS trajectory data offers\nvaluable information for ETA, but challenges arise due to temporal sparsity,\nvariable sequence lengths, and the interdependencies among multiple trucks. To\naddress these issues, we propose the Temporal-Attribute-Spatial Tri-space\nCoordination (TAS-TsC) framework, which leverages three feature\nspaces-temporal, attribute, and spatial-to enhance ETA. Our framework consists\nof a Temporal Learning Module (TLM) using state space models to capture\ntemporal dependencies, an Attribute Extraction Module (AEM) that transforms\nsequential features into structured attribute embeddings, and a Spatial Fusion\nModule (SFM) that models the interactions among multiple trajectories using\ngraph representation learning.These modules collaboratively learn trajectory\nembeddings, which are then used by a Downstream Prediction Module (DPM) to\nestimate arrival times. We validate TAS-TsC on real truck trajectory datasets\ncollected from Shenzhen, China, demonstrating its superior performance compared\nto existing methods.",
      "tldr_zh": "该论文提出 TAS-TsC 框架，一种基于数据驱动的方法，通过时间、属性和空间三空间协调来精确估计卡车到达时间 (ETA)，解决 GPS 轨迹数据中的时间稀疏性、可变序列长度和多轨迹相互依赖等问题。框架包括 Temporal Learning Module (TLM) 使用状态空间模型捕获时间依赖、Attribute Extraction Module (AEM) 转换序列特征为结构化属性嵌入，以及 Spatial Fusion Module (SFM) 通过图表示学习建模轨迹间交互；这些模块共同生成轨迹嵌入，由 Downstream Prediction Module (DPM) 进行 ETA 预测。在深圳真实卡车轨迹数据集上验证，TAS-TsC 框架的表现优于现有方法，显著提升了物流运输效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01122v1",
      "published_date": "2024-12-02 04:58:48 UTC",
      "updated_date": "2024-12-02 04:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:51:56.043887"
    },
    {
      "arxiv_id": "2412.01119v1",
      "title": "Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements",
      "title_zh": "翻译失败",
      "authors": [
        "Mojtaba S. Fazli",
        "Shannon Quinn"
      ],
      "abstract": "Object tracking is a fundamental tool in modern innovation, with applications\nin defense systems, autonomous vehicles, and biomedical research. It enables\nprecise identification, monitoring, and spatiotemporal analysis of objects\nacross sequential frames, providing insights into dynamic behaviors. In cell\nbiology, object tracking is vital for uncovering cellular mechanisms, such as\nmigration, interactions, and responses to drugs or pathogens. These insights\ndrive breakthroughs in understanding disease progression and therapeutic\ninterventions.\n  Over time, object tracking methods have evolved from traditional\nfeature-based approaches to advanced machine learning and deep learning\nframeworks. While classical methods are reliable in controlled settings, they\nstruggle in complex environments with occlusions, variable lighting, and high\nobject density. Deep learning models address these challenges by delivering\ngreater accuracy, adaptability, and robustness.\n  This review categorizes object tracking techniques into traditional,\nstatistical, feature-based, and machine learning paradigms, with a focus on\nbiomedical applications. These methods are essential for tracking cells and\nsubcellular structures, advancing our understanding of health and disease. Key\nperformance metrics, including accuracy, efficiency, and adaptability, are\ndiscussed. The paper explores limitations of current methods and highlights\nemerging trends to guide the development of next-generation tracking systems\nfor biomedical research and broader scientific domains.",
      "tldr_zh": "这篇论文从360度视角审视物体追踪（object tracking），强调其在国防系统、自动驾驶和生物医学研究中的关键作用，特别是用于分析细胞迁移、互动和药物响应，以推动疾病进展和治疗干预的理解。论文回顾了物体追踪方法从传统特征-based方法到深度学习框架的演变，分类为传统、统计、基于特征的和机器学习范式，并突出这些方法在追踪细胞和亚细胞结构方面的应用。作者讨论了关键性能指标如准确性、效率和适应性，分析了当前方法的局限性（如处理遮挡和复杂环境的挑战），并提出未来趋势以指导下一代追踪系统的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "56 Pages",
      "pdf_url": "http://arxiv.org/pdf/2412.01119v1",
      "published_date": "2024-12-02 04:43:50 UTC",
      "updated_date": "2024-12-02 04:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:52:08.275923"
    },
    {
      "arxiv_id": "2412.01096v1",
      "title": "How the use of feature selection methods influences the efficiency and accuracy of complex network simulations",
      "title_zh": "特征选择方法的运用如何影响复杂网络模拟的效率和准确性",
      "authors": [
        "Katarzyna Musial",
        "Jiaqi Wen",
        "Andreas Gwyther-Gouriotis"
      ],
      "abstract": "Complex network systems' models are designed to perfectly emulate real-world\nnetworks through the use of simulation and link prediction. Complex network\nsystems are defined by nodes and their connections where both have real-world\nfeatures that result in a heterogeneous network in which each of the nodes has\ndistinct characteristics. Thus, incorporating real-world features is an\nimportant component to achieve a simulation which best represents the\nreal-world. Currently very few complex network systems implement real-world\nfeatures, thus this study proposes feature selection methods which utilise\nunsupervised filtering techniques to rank real-world node features alongside a\nwrapper function to test combinations of the ranked features. The chosen method\nwas coined FS-SNS which improved 8 out of 10 simulations of real-world\nnetworks. A consistent threshold of included features was also discovered which\nsaw a threshold of 4 features to achieve the most accurate simulation for all\nnetworks. Through these findings the study also proposes future work and\ndiscusses how the findings can be used to further the Digital Twin and complex\nnetwork system field.",
      "tldr_zh": "这篇论文探讨了特征选择方法如何提升复杂网络 simulations 的效率和准确性，强调在异构网络中整合真实世界节点特征的重要性。研究提出了一种名为 FS-SNS 的方法，使用无监督过滤技术对节点特征进行排名，并结合包装器函数测试特征组合。实验结果显示，FS-SNS 改善了 10 个真实世界网络模拟中的 8 个，并发现使用 4 个特征作为阈值可实现最准确的模拟。这些发现为 Digital Twin 和复杂网络系统领域提供了新见解，并提出了未来研究方向。",
      "categories": [
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01096v1",
      "published_date": "2024-12-02 04:12:53 UTC",
      "updated_date": "2024-12-02 04:12:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:52:19.608103"
    },
    {
      "arxiv_id": "2412.01094v1",
      "title": "A Hierarchical Heuristic for Clustered Steiner Trees in the Plane with Obstacles",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Parque"
      ],
      "abstract": "Euclidean Steiner trees are relevant to model minimal networks in real-world\napplications ubiquitously. In this paper, we study the feasibility of a\nhierarchical approach embedded with bundling operations to compute multiple and\nmutually disjoint Euclidean Steiner trees that avoid clutter and overlapping\nwith obstacles in the plane, which is significant to model the decentralized\nand the multipoint coordination of agents in constrained 2D domains. Our\ncomputational experiments using arbitrary obstacle configuration with convex\nand non-convex geometries show the feasibility and the attractive performance\nwhen computing multiple obstacle-avoiding Steiner trees in the plane. Our\nresults offer the mechanisms to elucidate new operators for obstacle-avoiding\nSteiner trees.",
      "tldr_zh": "本文提出了一种层次化启发式方法（hierarchical heuristic），用于在平面中计算多个互斥的Euclidean Steiner trees，同时避开障碍物，以建模受限2D域中代理的去中心化和多点协调。方法嵌入捆绑操作（bundling operations），通过处理凸和非凸几何的任意障碍配置，确保树结构的优化和互斥性。计算实验结果显示，该方法在性能上表现出色，并提供了新的操作机制来阐释obstacle-avoiding Steiner trees。",
      "categories": [
        "cs.AI",
        "cs.CG",
        "cs.NE",
        "cs.RO",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "Article accepted/presented as Long Paper at The Twelfth International\n  Symposium on Computing and Networking (CANDAR2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.01094v1",
      "published_date": "2024-12-02 04:10:14 UTC",
      "updated_date": "2024-12-02 04:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:52:31.168147"
    },
    {
      "arxiv_id": "2412.01095v3",
      "title": "VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Muchao Ye",
        "Weiyang Liu",
        "Pan He"
      ],
      "abstract": "The rapid advancement of vision-language models (VLMs) has established a new\nparadigm in video anomaly detection (VAD): leveraging VLMs to simultaneously\ndetect anomalies and provide comprehendible explanations for the decisions.\nExisting work in this direction often assumes the complex reasoning required\nfor VAD exceeds the capabilities of pretrained VLMs. Consequently, these\napproaches either incorporate specialized reasoning modules during inference or\nrely on instruction tuning datasets through additional training to adapt VLMs\nfor VAD. However, such strategies often incur substantial computational costs\nor data annotation overhead. To address these challenges in explainable VAD, we\nintroduce a verbalized learning framework named VERA that enables VLMs to\nperform VAD without model parameter modifications. Specifically, VERA\nautomatically decomposes the complex reasoning required for VAD into\nreflections on simpler, more focused guiding questions capturing distinct\nabnormal patterns. It treats these reflective questions as learnable parameters\nand optimizes them through data-driven verbal interactions between learner and\noptimizer VLMs, using coarsely labeled training data. During inference, VERA\nembeds the learned questions into model prompts to guide VLMs in generating\nsegment-level anomaly scores, which are then refined into frame-level scores\nvia the fusion of scene and temporal contexts. Experimental results on\nchallenging benchmarks demonstrate that the learned questions of VERA are\nhighly adaptable, significantly improving both detection performance and\nexplainability of VLMs for VAD.",
      "tldr_zh": "本研究提出 VERA 框架，通过 verbalized learning 技术，利用 vision-language models (VLMs) 实现可解释的视频异常检测 (VAD)，无需修改模型参数，从而避免了现有方法的计算成本和数据标注开销。VERA 将 VAD 的复杂推理自动分解为更简单的引导问题，并将这些问题作为可学习参数，通过 learner 和 optimizer VLMs 的数据驱动 verbal interactions 进行优化。在推理过程中，VERA 将学到的引导问题嵌入模型提示，生成段级异常分数，并通过融合场景和时间上下文精炼为帧级分数。实验在挑战性基准上证明，VERA 显著提升了检测性能和 VLMs 的解释性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.01095v3",
      "published_date": "2024-12-02 04:10:14 UTC",
      "updated_date": "2025-03-31 20:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:52:44.462942"
    },
    {
      "arxiv_id": "2412.01082v1",
      "title": "A Hybrid Evolutionary Approach for Multi Robot Coordinated Planning at Intersections",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Parque"
      ],
      "abstract": "Coordinated multi-robot motion planning at intersections is key for safe\nmobility in roads, factories and warehouses. The rapidly exploring random tree\n(RRT) algorithms are popular in multi-robot motion planning. However,\ngenerating the graph configuration space and searching in the composite tensor\nconfiguration space is computationally expensive for large number of sample\npoints. In this paper, we propose a new evolutionary-based algorithm using a\nparametric lattice-based configuration and the discrete-based RRT for\ncollision-free multi-robot planning at intersections. Our computational\nexperiments using complex planning intersection scenarios have shown the\nfeasibility and the superiority of the proposed algorithm compared to seven\nother related approaches. Our results offer new sampling and representation\nmechanisms to render optimization-based approaches for multi-robot navigation.",
      "tldr_zh": "该论文提出了一种混合进化方法，用于多机器人协调规划在交叉路口的碰撞-free 运动。方法结合了 parametric lattice-based configuration 和 discrete-based RRT 算法，以减少传统 RRT 在生成图配置空间和搜索复合张量配置空间时的计算开销。实验结果显示，该算法在复杂交叉路口场景中比其他七种相关方法表现出优越性，提供新的采样和表示机制，提升了基于优化的多机器人导航效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.NE",
        "math.OC",
        "stat.CO"
      ],
      "primary_category": "cs.RO",
      "comment": "Paper accepted/presented as a regular paper at The Twelfth\n  International Symposium on Computing and Networking (CANDAR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.01082v1",
      "published_date": "2024-12-02 03:40:04 UTC",
      "updated_date": "2024-12-02 03:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:52:54.274702"
    },
    {
      "arxiv_id": "2412.01078v2",
      "title": "Advancing Speech Language Models by Scaling Supervised Fine-Tuning with Over 60,000 Hours of Synthetic Speech Dialogue Data",
      "title_zh": "翻译失败",
      "authors": [
        "Shuaijiang Zhao",
        "Tingwei Guo",
        "Bajian Xiang",
        "Tongtang Wan",
        "Qiang Niu",
        "Wei Zou",
        "Xiangang Li"
      ],
      "abstract": "The GPT-4o represents a significant milestone in enabling real-time\ninteraction with large language models (LLMs) through speech, its remarkable\nlow latency and high fluency not only capture attention but also stimulate\nresearch interest in the field. This real-time speech interaction is\nparticularly valuable in scenarios requiring rapid feedback and immediate\nresponses, dramatically enhancing user experience. However, there is a notable\nlack of research focused on real-time large speech language models,\nparticularly for Chinese. In this work, we present KE-Omni, a seamless large\nspeech language model built upon Ke-SpeechChat, a large-scale high-quality\nsynthetic speech interaction dataset consisting of 7 million Chinese and\nEnglish conversations, featuring 42,002 speakers, and totaling over 60,000\nhours, This contributes significantly to the advancement of research and\ndevelopment in this field. The demos can be accessed at\n\\url{https://huggingface.co/spaces/KE-Team/KE-Omni}.",
      "tldr_zh": "这篇论文通过扩展监督微调(Supervised Fine-Tuning)技术，利用超过60,000小时的合成语音对话数据，推进语音语言模型的发展。研究者构建了KE-Omni模型，基于Ke-SpeechChat数据集，该数据集包含7百万中文和英文对话，涉及42,002位说话者，以填补实时大型语音语言模型(特别是中文)研究的空白。实验结果表明，这有助于提升用户交互体验，并为该领域的研究提供大规模高质量资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "KE-Omni, Ke-SpeechChat",
      "pdf_url": "http://arxiv.org/pdf/2412.01078v2",
      "published_date": "2024-12-02 03:31:46 UTC",
      "updated_date": "2024-12-03 02:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:53:08.317906"
    },
    {
      "arxiv_id": "2412.01075v1",
      "title": "Multi-Agent Deep Reinforcement Learning for Distributed and Autonomous Platoon Coordination via Speed-regulation over Large-scale Transportation Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Dixiao Wei",
        "Peng Yi",
        "Jinlong Lei",
        "Xingyi Zhu"
      ],
      "abstract": "Truck platooning technology enables a group of trucks to travel closely\ntogether, with which the platoon can save fuel, improve traffic flow\nefficiency, and improve safety. In this paper, we consider the platoon\ncoordination problem in a large-scale transportation network, to promote\ncooperation among trucks and optimize the overall efficiency. Involving the\nregulation of both speed and departure times at hubs, we formulate the\ncoordination problem as a complicated dynamic stochastic integer programming\nunder network and information constraints. To get an autonomous, distributed,\nand robust platoon coordination policy, we formulate the problem into a model\nof the Decentralized-Partial Observable Markov Decision Process. Then, we\npropose a Multi-Agent Deep Reinforcement Learning framework named Trcuk\nAttention-QMIX (TA-QMIX) to train an efficient online decision policy. TA-QMIX\nutilizes the attention mechanism to enhance the representation of truck fuel\ngains and delay times, and provides explicit truck cooperation information\nduring the training process, promoting trucks' willingness to cooperate. The\ntraining framework adopts centralized training and distributed execution, thus\ntraining a policy for trucks to make decisions online using only nearby\ninformation. Hence, the policy can be autonomously executed on a large-scale\nnetwork. Finally, we perform comparison experiments and ablation experiments in\nthe transportation network of the Yangtze River Delta region in China to verify\nthe effectiveness of the proposed framework. In a repeated comparative\nexperiment with 5,000 trucks, our method average saves 19.17\\% of fuel with an\naverage delay of only 9.57 minutes per truck and a decision time of 0.001\nseconds.",
      "tldr_zh": "本文提出了一种多智能体深度强化学习框架 TA-QMIX，用于在大型交通网络中实现卡车编队的分布式和自主协调，主要通过调节速度和出发时间来优化整体效率。该框架基于 Decentralized-Partial Observable Markov Decision Process (Dec-POMDP) 模型，采用注意力机制增强卡车燃料收益和延误时间的表示，并促进卡车间的合作，支持集中训练和分布式执行。实验在中国的长江三角洲地区交通网络上验证，涉及5000辆卡车时，该方法平均节省19.17%的燃料，每辆卡车延误仅9.57分钟，且决策时间仅为0.001秒。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01075v1",
      "published_date": "2024-12-02 03:21:40 UTC",
      "updated_date": "2024-12-02 03:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:53:20.562982"
    },
    {
      "arxiv_id": "2412.01065v1",
      "title": "Lookahead Counterfactual Fairness",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqun Zuo",
        "Tian Xie",
        "Xuwei Tan",
        "Xueru Zhang",
        "Mohammad Mahdi Khalili"
      ],
      "abstract": "As machine learning (ML) algorithms are used in applications that involve\nhumans, concerns have arisen that these algorithms may be biased against\ncertain social groups. \\textit{Counterfactual fairness} (CF) is a fairness\nnotion proposed in Kusner et al. (2017) that measures the unfairness of ML\npredictions; it requires that the prediction perceived by an individual in the\nreal world has the same marginal distribution as it would be in a\ncounterfactual world, in which the individual belongs to a different group.\nAlthough CF ensures fair ML predictions, it fails to consider the downstream\neffects of ML predictions on individuals. Since humans are strategic and often\nadapt their behaviors in response to the ML system, predictions that satisfy CF\nmay not lead to a fair future outcome for the individuals. In this paper, we\nintroduce \\textit{lookahead counterfactual fairness} (LCF), a fairness notion\naccounting for the downstream effects of ML models which requires the\nindividual \\textit{future status} to be counterfactually fair. We theoretically\nidentify conditions under which LCF can be satisfied and propose an algorithm\nbased on the theorems. We also extend the concept to path-dependent fairness.\nExperiments on both synthetic and real data validate the proposed method.",
      "tldr_zh": "该研究指出，现有的 Counterfactual Fairness (CF) 公平性标准虽能确保机器学习 (ML) 预测在不同社会群体间公平，但忽略了预测对个体未来状态的潜在影响，因为人们可能基于预测调整行为，导致不公平结果。为解决此问题，作者提出 Lookahead Counterfactual Fairness (LCF)，一种考虑下游效应的公平性概念，要求个体的未来状态在反事实世界中保持公平，并理论上给出了满足 LCF 的条件及基于此的算法，同时扩展到 path-dependent fairness。实验在合成和真实数据上验证了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01065v1",
      "published_date": "2024-12-02 02:53:14 UTC",
      "updated_date": "2024-12-02 02:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:53:31.525679"
    },
    {
      "arxiv_id": "2412.01064v2",
      "title": "FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait",
      "title_zh": "翻译失败",
      "authors": [
        "Taekyung Ki",
        "Dongchan Min",
        "Gyeongsu Chae"
      ],
      "abstract": "With the rapid advancement of diffusion-based generative models, portrait\nimage animation has achieved remarkable results. However, it still faces\nchallenges in temporally consistent video generation and fast sampling due to\nits iterative sampling nature. This paper presents FLOAT, an audio-driven\ntalking portrait video generation method based on flow matching generative\nmodel. We shift the generative modeling from the pixel-based latent space to a\nlearned motion latent space, enabling efficient design of temporally consistent\nmotion. To achieve this, we introduce a transformer-based vector field\npredictor with a simple yet effective frame-wise conditioning mechanism.\nAdditionally, our method supports speech-driven emotion enhancement, enabling a\nnatural incorporation of expressive motions. Extensive experiments demonstrate\nthat our method outperforms state-of-the-art audio-driven talking portrait\nmethods in terms of visual quality, motion fidelity, and efficiency.",
      "tldr_zh": "本论文提出 FLOAT，一种基于流匹配生成模型的音频驱动头像视频生成方法，旨在解决扩散模型在时序一致性和快速采样方面的挑战。通过将生成建模从像素空间转移到学习到的运动潜在空间（motion latent space），该方法使用基于 Transformer 的向量场预测器（Transformer-based vector field predictor）及其帧级条件机制，实现高效且一致的运动设计。FLOAT 还支持语音驱动的情感增强（speech-driven emotion enhancement），使表达性运动自然整合。实验结果显示，该方法在视觉质量、运动保真度（motion fidelity）和效率上优于现有音频驱动头像生成技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://deepbrainai-research.github.io/float/",
      "pdf_url": "http://arxiv.org/pdf/2412.01064v2",
      "published_date": "2024-12-02 02:50:07 UTC",
      "updated_date": "2024-12-04 09:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:53:43.397984"
    },
    {
      "arxiv_id": "2501.07839v1",
      "title": "Social Media Data Mining With Natural Language Processing on Public Dream Contents",
      "title_zh": "社交媒体数据挖掘：利用自然语言处理分析公共梦境内容",
      "authors": [
        "Howard Hua",
        "Joe Yu"
      ],
      "abstract": "The COVID-19 pandemic has significantly transformed global lifestyles,\nenforcing physical isolation and accelerating digital adoption for work,\neducation, and social interaction. This study examines the pandemic's impact on\nmental health by analyzing dream content shared on the Reddit r/Dreams\ncommunity. With over 374,000 subscribers, this platform offers a rich dataset\nfor exploring subconscious responses to the pandemic. Using statistical\nmethods, we assess shifts in dream positivity, negativity, and neutrality from\nthe pre-pandemic to post-pandemic era. To enhance our analysis, we fine-tuned\nthe LLaMA 3.1-8B model with labeled data, enabling precise sentiment\nclassification of dream content. Our findings aim to uncover patterns in dream\ncontent, providing insights into the psychological effects of the pandemic and\nits influence on subconscious processes. This research highlights the profound\nchanges in mental landscapes and the role of dreams as indicators of public\nwell-being during unprecedented times.",
      "tldr_zh": "本研究调查了COVID-19疫情对心理健康的影响，通过分析Reddit r/Dreams社区的梦境内容，该社区拥有超过37.4万订阅者。研究者采用统计方法评估疫情前后梦境的积极、消极和中性变化，并微调LLaMA 3.1-8B模型进行精确的情感分类，以揭示潜意识响应模式。结果显示，疫情显著改变了梦境内容，提供重要洞见，帮助理解公众心理景观和梦境作为心理福祉指标的作用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.SI",
        "I.2.7"
      ],
      "primary_category": "cs.CY",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.07839v1",
      "published_date": "2024-12-02 02:34:02 UTC",
      "updated_date": "2024-12-02 02:34:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:53:55.466883"
    },
    {
      "arxiv_id": "2412.01039v2",
      "title": "Reducing Inference Energy Consumption Using Dual Complementary CNNs",
      "title_zh": "使用双互补 CNNs 减少推理能量消耗",
      "authors": [
        "Michail Kinnas",
        "John Violos",
        "Ioannis Kompatsiaris",
        "Symeon Papadopoulos"
      ],
      "abstract": "Energy efficiency of Convolutional Neural Networks (CNNs) has become an\nimportant area of research, with various strategies being developed to minimize\nthe power consumption of these models. Previous efforts, including techniques\nlike model pruning, quantization, and hardware optimization, have made\nsignificant strides in this direction. However, there remains a need for more\neffective on device AI solutions that balance energy efficiency with model\nperformance. In this paper, we propose a novel approach to reduce the energy\nrequirements of inference of CNNs. Our methodology employs two small\nComplementary CNNs that collaborate with each other by covering each other's\n\"weaknesses\" in predictions. If the confidence for a prediction of the first\nCNN is considered low, the second CNN is invoked with the aim of producing a\nhigher confidence prediction. This dual-CNN setup significantly reduces energy\nconsumption compared to using a single large deep CNN. Additionally, we propose\na memory component that retains previous classifications for identical inputs,\nbypassing the need to re-invoke the CNNs for the same input, further saving\nenergy. Our experiments on a Jetson Nano computer demonstrate an energy\nreduction of up to 85.8% achieved on modified datasets where each sample was\nduplicated once. These findings indicate that leveraging a complementary CNN\npair along with a memory component effectively reduces inference energy while\nmaintaining high accuracy.",
      "tldr_zh": "这篇论文提出了一种使用双互补 CNNs 的方法来减少卷积神经网络（CNNs）的推理能量消耗，具体通过两个小型互补 CNN 协作的方式来覆盖彼此的预测弱点，如果第一个 CNN 的置信度较低，则调用第二个 CNN 以提高预测准确性。论文还引入了一个内存组件，用于存储之前的分类结果，从而避免重复计算进一步节省能量。在 Jetson Nano 上的实验显示，这种方法在修改的数据集上实现了高达 85.8% 的能量减少，同时维持了高准确率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01039v2",
      "published_date": "2024-12-02 01:46:07 UTC",
      "updated_date": "2024-12-11 06:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:54:07.563619"
    },
    {
      "arxiv_id": "2412.01031v2",
      "title": "Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings",
      "title_zh": "翻译失败",
      "authors": [
        "Razi Mahmood",
        "Pingkun Yan",
        "Diego Machado Reyes",
        "Ge Wang",
        "Mannudeep K. Kalra",
        "Parisa Kaviani",
        "Joy T. Wu",
        "Tanveer Syeda-Mahmood"
      ],
      "abstract": "Several evaluation metrics have been developed recently to automatically\nassess the quality of generative AI reports for chest radiographs based only on\ntextual information using lexical, semantic, or clinical named entity\nrecognition methods. In this paper, we develop a new method of report quality\nevaluation by first extracting fine-grained finding patterns capturing the\nlocation, laterality, and severity of a large number of clinical findings. We\nthen performed phrasal grounding to localize their associated anatomical\nregions on chest radiograph images. The textual and visual measures are then\ncombined to rate the quality of the generated reports. We present results that\ncompare this evaluation metric with other textual metrics on a gold standard\ndataset derived from the MIMIC collection and show its robustness and\nsensitivity to factual errors.",
      "tldr_zh": "这篇论文提出了一种新方法，通过细粒度的短语定位（fine-grained phrasal grounding）来评估自动生成放射学报告的质量，该方法首先提取临床发现（clinical findings）的模式，包括位置、侧别和严重程度。接着，将这些文本模式与胸部 X 光图像（chest radiographs）的相关解剖区域进行可视关联，并结合文本和视觉措施进行综合评估。在基于 MIMIC 集合的金标准数据集上实验表明，该方法比传统的词汇或语义指标更具鲁棒性和对事实错误的敏感性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01031v2",
      "published_date": "2024-12-02 01:27:47 UTC",
      "updated_date": "2024-12-07 23:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:56:12.900594"
    },
    {
      "arxiv_id": "2412.01020v1",
      "title": "AI Benchmarks and Datasets for LLM Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Todor Ivanov",
        "Valeri Penchev"
      ],
      "abstract": "LLMs demand significant computational resources for both pre-training and\nfine-tuning, requiring distributed computing capabilities due to their large\nmodel sizes \\cite{sastry2024computing}. Their complex architecture poses\nchallenges throughout the entire AI lifecycle, from data collection to\ndeployment and monitoring \\cite{OECD_AIlifecycle}. Addressing critical AI\nsystem challenges, such as explainability, corrigibility, interpretability, and\nhallucination, necessitates a systematic methodology and rigorous benchmarking\n\\cite{guldimann2024complai}. To effectively improve AI systems, we must\nprecisely identify systemic vulnerabilities through quantitative evaluation,\nbolstering system trustworthiness. The enactment of the EU AI Act\n\\cite{EUAIAct} by the European Parliament on March 13, 2024, establishing the\nfirst comprehensive EU-wide requirements for the development, deployment, and\nuse of AI systems, further underscores the importance of tools and\nmethodologies such as Z-Inspection. It highlights the need to enrich this\nmethodology with practical benchmarks to effectively address the technical\nchallenges posed by AI systems. To this end, we have launched a project that is\npart of the AI Safety Bulgaria initiatives \\cite{AI_Safety_Bulgaria}, aimed at\ncollecting and categorizing AI benchmarks. This will enable practitioners to\nidentify and utilize these benchmarks throughout the AI system lifecycle.",
      "tldr_zh": "本研究讨论了大型语言模型（LLMs）在训练和微调过程中对计算资源的巨大需求，以及AI生命周期中面临的挑战，如解释性（explainability）、可修正性（corrigibility）和幻觉（hallucination）。为了系统识别AI系统的脆弱性并提升其可信度，作者强调了采用严格基准（benchmarks）和方法，如Z-Inspection。研究发起了一个项目，作为AI Safety Bulgaria举措的一部分，旨在收集和分类AI基准，帮助从业者在AI系统生命周期中应用这些工具，以符合欧盟AI法案（EU AI Act）的要求。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "November 2024 v1.0",
      "pdf_url": "http://arxiv.org/pdf/2412.01020v1",
      "published_date": "2024-12-02 00:38:57 UTC",
      "updated_date": "2024-12-02 00:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:54:31.058002"
    },
    {
      "arxiv_id": "2412.01014v1",
      "title": "Detecting Memorization in Large Language Models",
      "title_zh": "检测大语言模型中的记忆化",
      "authors": [
        "Eduardo Slonski"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive results in natural\nlanguage processing but are prone to memorizing portions of their training\ndata, which can compromise evaluation metrics, raise privacy concerns, and\nlimit generalization. Traditional methods for detecting memorization rely on\noutput probabilities or loss functions, often lacking precision due to\nconfounding factors like common language patterns. In this paper, we introduce\nan analytical method that precisely detects memorization by examining neuron\nactivations within the LLM. By identifying specific activation patterns that\ndifferentiate between memorized and not memorized tokens, we train\nclassification probes that achieve near-perfect accuracy. The approach can also\nbe applied to other mechanisms, such as repetition, as demonstrated in this\nstudy, highlighting its versatility. Intervening on these activations allows us\nto suppress memorization without degrading overall performance, enhancing\nevaluation integrity by ensuring metrics reflect genuine generalization.\nAdditionally, our method supports large-scale labeling of tokens and sequences,\ncrucial for next-generation AI models, improving training efficiency and\nresults. Our findings contribute to model interpretability and offer practical\ntools for analyzing and controlling internal mechanisms in LLMs.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）容易记忆训练数据的现象，提出了一种精确检测记忆的方法，通过分析神经元激活模式来区分记忆和非记忆的标记，并训练分类探针（classification probes）实现近乎完美的准确率。该方法不仅能应用于记忆检测，还扩展到其他机制如重复，并通过干预激活模式抑制记忆，而不影响模型整体性能，从而提升评估指标的真实性和泛化能力。此外，该方法支持大规模标记标记和序列，提高了AI模型的训练效率，并为LLMs的可解释性提供了实用工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.01014v1",
      "published_date": "2024-12-02 00:17:43 UTC",
      "updated_date": "2024-12-02 00:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T06:56:43.592479"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 150,
  "processed_papers_count": 150,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T06:57:05.609679"
}