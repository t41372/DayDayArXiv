[
  {
    "arxiv_id": "2412.02039v1",
    "title": "Mutli-View 3D Reconstruction using Knowledge Distillation",
    "authors": [
      "Aditya Dutt",
      "Ishikaa Lunawat",
      "Manpreet Kaur"
    ],
    "abstract": "Large Foundation Models like Dust3r can produce high quality outputs such as\npointmaps, camera intrinsics, and depth estimation, given stereo-image pairs as\ninput. However, the application of these outputs on tasks like Visual\nLocalization requires a large amount of inference time and compute resources.\nTo address these limitations, in this paper, we propose the use of a knowledge\ndistillation pipeline, where we aim to build a student-teacher model with\nDust3r as the teacher and explore multiple architectures of student models that\nare trained using the 3D reconstructed points output by Dust3r. Our goal is to\nbuild student models that can learn scene-specific representations and output\n3D points with replicable performance such as Dust3r. The data set we used to\ntrain our models is 12Scenes. We test two main architectures of models: a\nCNN-based architecture and a Vision Transformer based architecture. For each\narchitecture, we also compare the use of pre-trained models against models\nbuilt from scratch. We qualitatively compare the reconstructed 3D points output\nby the student model against Dust3r's and discuss the various features learned\nby the student model. We also perform ablation studies on the models through\nhyperparameter tuning. Overall, we observe that the Vision Transformer presents\nthe best performance visually and quantitatively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.02039v1",
    "published_date": "2024-12-02 23:46:31 UTC",
    "updated_date": "2024-12-02 23:46:31 UTC"
  },
  {
    "arxiv_id": "2412.02035v1",
    "title": "LLMs4Life: Large Language Models for Ontology Learning in Life Sciences",
    "authors": [
      "Nadeen Fathallah",
      "Steffen Staab",
      "Alsayed Algergawy"
    ],
    "abstract": "Ontology learning in complex domains, such as life sciences, poses\nsignificant challenges for current Large Language Models (LLMs). Existing LLMs\nstruggle to generate ontologies with multiple hierarchical levels, rich\ninterconnections, and comprehensive class coverage due to constraints on the\nnumber of tokens they can generate and inadequate domain adaptation. To address\nthese issues, we extend the NeOn-GPT pipeline for ontology learning using LLMs\nwith advanced prompt engineering techniques and ontology reuse to enhance the\ngenerated ontologies' domain-specific reasoning and structural depth. Our work\nevaluates the capabilities of LLMs in ontology learning in the context of\nhighly specialized and complex domains such as life science domains. To assess\nthe logical consistency, completeness, and scalability of the generated\nontologies, we use the AquaDiva ontology developed and used in the\ncollaborative research center AquaDiva as a case study. Our evaluation shows\nthe viability of LLMs for ontology learning in specialized domains, providing\nsolutions to longstanding limitations in model performance and scalability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02035v1",
    "published_date": "2024-12-02 23:31:52 UTC",
    "updated_date": "2024-12-02 23:31:52 UTC"
  },
  {
    "arxiv_id": "2412.02029v1",
    "title": "Learning Ensembles of Vision-based Safety Control Filters",
    "authors": [
      "Ihab Tabbara",
      "Hussein Sibai"
    ],
    "abstract": "Safety filters in control systems correct nominal controls that violate\nsafety constraints. Designing such filters as functions of visual observations\nin uncertain and complex environments is challenging. Several deep\nlearning-based approaches to tackle this challenge have been proposed recently.\nHowever, formally verifying that the learned filters satisfy critical\nproperties that enable them to guarantee the safety of the system is currently\nbeyond reach. Instead, in this work, motivated by the success of ensemble\nmethods in reinforcement learning, we empirically investigate the efficacy of\nensembles in enhancing the accuracy and the out-of-distribution generalization\nof such filters, as a step towards more reliable ones. We experiment with\ndiverse pre-trained vision representation models as filter backbones, training\napproaches, and output aggregation techniques. We compare the performance of\nensembles with different configurations against each other, their individual\nmember models, and large single-model baselines in distinguishing between safe\nand unsafe states and controls in the DeepAccident dataset. Our results show\nthat diverse ensembles have better state and control classification accuracies\ncompared to individual models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02029v1",
    "published_date": "2024-12-02 23:19:31 UTC",
    "updated_date": "2024-12-02 23:19:31 UTC"
  },
  {
    "arxiv_id": "2412.02025v1",
    "title": "PKRD-CoT: A Unified Chain-of-thought Prompting for Multi-Modal Large Language Models in Autonomous Driving",
    "authors": [
      "Xuewen Luo",
      "Fan Ding",
      "Yinsheng Song",
      "Xiaofeng Zhang",
      "Junnyong Loo"
    ],
    "abstract": "There is growing interest in leveraging the capabilities of robust\nMulti-Modal Large Language Models (MLLMs) directly within autonomous driving\ncontexts. However, the high costs and complexity of designing and training\nend-to-end autonomous driving models make them challenging for many enterprises\nand research entities. To address this, our study explores a seamless\nintegration of MLLMs into autonomous driving systems by proposing a Zero-Shot\nChain-of-Thought (Zero-Shot-CoT) prompt design named PKRD-CoT. PKRD-CoT is\nbased on the four fundamental capabilities of autonomous driving: perception,\nknowledge, reasoning, and decision-making. This makes it particularly suitable\nfor understanding and responding to dynamic driving environments by mimicking\nhuman thought processes step by step, thus enhancing decision-making in\nreal-time scenarios. Our design enables MLLMs to tackle problems without prior\nexperience, thereby increasing their utility within unstructured autonomous\ndriving environments. In experiments, we demonstrate the exceptional\nperformance of GPT-4.0 with PKRD-CoT across autonomous driving tasks,\nhighlighting its effectiveness in autonomous driving scenarios. Additionally,\nour benchmark analysis reveals the promising viability of PKRD-CoT for other\nMLLMs, such as Claude, LLava1.6, and Qwen-VL-Plus. Overall, this study\ncontributes a novel and unified prompt-design framework for GPT-4.0 and other\nMLLMs in autonomous driving, while also rigorously evaluating the efficacy of\nthese widely recognized MLLMs in the autonomous driving domain through\ncomprehensive comparisons.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "This paper has been accepted for presentation at ICONIP 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.02025v1",
    "published_date": "2024-12-02 23:08:38 UTC",
    "updated_date": "2024-12-02 23:08:38 UTC"
  },
  {
    "arxiv_id": "2412.02016v1",
    "title": "Explore Reinforced: Equilibrium Approximation with Reinforcement Learning",
    "authors": [
      "Ryan Yu",
      "Mateusz Nowak",
      "Qintong Xie",
      "Michelle Yilin Feng",
      "Peter Chin"
    ],
    "abstract": "Current approximate Coarse Correlated Equilibria (CCE) algorithms struggle\nwith equilibrium approximation for games in large stochastic environments but\nare theoretically guaranteed to converge to a strong solution concept. In\ncontrast, modern Reinforcement Learning (RL) algorithms provide faster training\nyet yield weaker solutions. We introduce Exp3-IXrl - a blend of RL and\ngame-theoretic approach, separating the RL agent's action selection from the\nequilibrium computation while preserving the integrity of the learning process.\nWe demonstrate that our algorithm expands the application of equilibrium\napproximation algorithms to new environments. Specifically, we show the\nimproved performance in a complex and adversarial cybersecurity network\nenvironment - the Cyber Operations Research Gym - and in the classical\nmulti-armed bandit settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02016v1",
    "published_date": "2024-12-02 22:37:59 UTC",
    "updated_date": "2024-12-02 22:37:59 UTC"
  },
  {
    "arxiv_id": "2412.02012v2",
    "title": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis",
    "authors": [
      "Wenbo Zhang",
      "Junyu Chen",
      "Christopher Kanan"
    ],
    "abstract": "Due to their large sizes, volumetric scans and whole-slide pathology images\n(WSIs) are often processed by extracting embeddings from local regions and then\nan aggregator makes predictions from this set. However, current methods require\npost-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize\nsmall yet clinically crucial details. To address these limitations, we\nintroduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap\ngeneration as an inductive bias. Starting from pre-trained feature maps,\nINSIGHT employs a detection module with small convolutional kernels to capture\nfine details and a context module with a broader receptive field to suppress\nlocal false positives. The resulting internal heatmap highlights diagnostically\nrelevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art\nclassification results and high weakly-labeled semantic segmentation\nperformance. Project website and code are available at:\nhttps://zhangdylan83.github.io/ewsmia/",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02012v2",
    "published_date": "2024-12-02 22:31:23 UTC",
    "updated_date": "2024-12-08 16:58:40 UTC"
  },
  {
    "arxiv_id": "2412.02723v1",
    "title": "DYffCast: Regional Precipitation Nowcasting Using IMERG Satellite Data. A case study over South America",
    "authors": [
      "Daniel Seal",
      "Rossella Arcucci",
      "Salva Rühling-Cachay",
      "César Quilodrán-Casas"
    ],
    "abstract": "Climate change is increasing the frequency of extreme precipitation events,\nmaking weather disasters such as flooding and landslides more likely. The\nability to accurately nowcast precipitation is therefore becoming more critical\nfor safeguarding society by providing immediate, accurate information to\ndecision makers. Motivated by the recent success of generative models at\nprecipitation nowcasting, this paper: extends the DYffusion framework to this\ntask and evaluates its performance at forecasting IMERG satellite precipitation\ndata up to a 4-hour horizon; modifies the DYffusion framework to improve its\nability to model rainfall data; and introduces a novel loss function that\ncombines MSE, MAE and the LPIPS perceptual score. In a quantitative evaluation\nof forecasts up to a 4-hour horizon, the modified DYffusion framework trained\nwith the novel loss outperforms four competitor models. It has the highest CSI\nscores for weak, moderate, and heavy rain thresholds and retains an LPIPS score\n$<$ 0.2 for the entire roll-out, degrading the least as lead-time increases.\nThe proposed nowcasting model demonstrates visually stable and sharp forecasts\nup to a 2-hour horizon on a heavy rain case study. Code is available at\nhttps://github.com/Dseal95/DYffcast.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in the Machine Learning for Physical Sciences workshop @\n  NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.02723v1",
    "published_date": "2024-12-02 22:20:31 UTC",
    "updated_date": "2024-12-02 22:20:31 UTC"
  },
  {
    "arxiv_id": "2412.12121v1",
    "title": "NLLG Quarterly arXiv Report 09/24: What are the most influential current AI Papers?",
    "authors": [
      "Christoph Leiter",
      "Jonas Belouadi",
      "Yanran Chen",
      "Ran Zhang",
      "Daniil Larionov",
      "Aida Kostikova",
      "Steffen Eger"
    ],
    "abstract": "The NLLG (Natural Language Learning & Generation) arXiv reports assist in\nnavigating the rapidly evolving landscape of NLP and AI research across cs.CL,\ncs.CV, cs.AI, and cs.LG categories. This fourth installment captures a\ntransformative period in AI history - from January 1, 2023, following ChatGPT's\ndebut, through September 30, 2024. Our analysis reveals substantial new\ndevelopments in the field - with 45% of the top 40 most-cited papers being new\nentries since our last report eight months ago and offers insights into\nemerging trends and major breakthroughs, such as novel multimodal\narchitectures, including diffusion and state space models. Natural Language\nProcessing (NLP; cs.CL) remains the dominant main category in the list of our\ntop-40 papers but its dominance is on the decline in favor of Computer vision\n(cs.CV) and general machine learning (cs.LG). This report also presents novel\nfindings on the integration of generative AI in academic writing, documenting\nits increasing adoption since 2022 while revealing an intriguing pattern:\ntop-cited papers show notably fewer markers of AI-generated content compared to\nrandom samples. Furthermore, we track the evolution of AI-associated language,\nidentifying declining trends in previously common indicators such as \"delve\".",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12121v1",
    "published_date": "2024-12-02 22:10:38 UTC",
    "updated_date": "2024-12-02 22:10:38 UTC"
  },
  {
    "arxiv_id": "2412.02000v1",
    "title": "Who's Gaming the System? A Causally-Motivated Approach for Detecting Strategic Adaptation",
    "authors": [
      "Trenton Chang",
      "Lindsay Warrenburg",
      "Sae-Hwan Park",
      "Ravi B. Parikh",
      "Maggie Makar",
      "Jenna Wiens"
    ],
    "abstract": "In many settings, machine learning models may be used to inform decisions\nthat impact individuals or entities who interact with the model. Such entities,\nor agents, may game model decisions by manipulating their inputs to the model\nto obtain better outcomes and maximize some utility. We consider a multi-agent\nsetting where the goal is to identify the \"worst offenders:\" agents that are\ngaming most aggressively. However, identifying such agents is difficult without\nknowledge of their utility function. Thus, we introduce a framework in which\neach agent's tendency to game is parameterized via a scalar. We show that this\ngaming parameter is only partially identifiable. By recasting the problem as a\ncausal effect estimation problem where different agents represent different\n\"treatments,\" we prove that a ranking of all agents by their gaming parameters\nis identifiable. We present empirical results in a synthetic data study\nvalidating the usage of causal effect estimation for gaming detection and show\nin a case study of diagnosis coding behavior in the U.S. that our approach\nhighlights features associated with gaming.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "38 pages, 31 figures. NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.02000v1",
    "published_date": "2024-12-02 22:07:48 UTC",
    "updated_date": "2024-12-02 22:07:48 UTC"
  },
  {
    "arxiv_id": "2412.01992v1",
    "title": "ChatCollab: Exploring Collaboration Between Humans and AI Agents in Software Teams",
    "authors": [
      "Benjamin Klieger",
      "Charis Charitsis",
      "Miroslav Suzara",
      "Sierra Wang",
      "Nick Haber",
      "John C. Mitchell"
    ],
    "abstract": "We explore the potential for productive team-based collaboration between\nhumans and Artificial Intelligence (AI) by presenting and conducting initial\ntests with a general framework that enables multiple human and AI agents to\nwork together as peers. ChatCollab's novel architecture allows agents - human\nor AI - to join collaborations in any role, autonomously engage in tasks and\ncommunication within Slack, and remain agnostic to whether their collaborators\nare human or AI. Using software engineering as a case study, we find that our\nAI agents successfully identify their roles and responsibilities, coordinate\nwith other agents, and await requested inputs or deliverables before\nproceeding. In relation to three prior multi-agent AI systems for software\ndevelopment, we find ChatCollab AI agents produce comparable or better software\nin an interactive game development task. We also propose an automated method\nfor analyzing collaboration dynamics that effectively identifies behavioral\ncharacteristics of agents with distinct roles, allowing us to quantitatively\ncompare collaboration dynamics in a range of experimental conditions. For\nexample, in comparing ChatCollab AI agents, we find that an AI CEO agent\ngenerally provides suggestions 2-4 times more often than an AI product manager\nor AI developer, suggesting agents within ChatCollab can meaningfully adopt\ndifferentiated collaborative roles. Our code and data can be found at:\nhttps://github.com/ChatCollab.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Preprint, 25 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01992v1",
    "published_date": "2024-12-02 21:56:46 UTC",
    "updated_date": "2024-12-02 21:56:46 UTC"
  },
  {
    "arxiv_id": "2412.01991v1",
    "title": "Real-Time Multilingual Sign Language Processing",
    "authors": [
      "Amit Moryossef"
    ],
    "abstract": "Sign Language Processing (SLP) is an interdisciplinary field comprised of\nNatural Language Processing (NLP) and Computer Vision. It is focused on the\ncomputational understanding, translation, and production of signed languages.\nTraditional approaches have often been constrained by the use of gloss-based\nsystems that are both language-specific and inadequate for capturing the\nmultidimensional nature of sign language. These limitations have hindered the\ndevelopment of technology capable of processing signed languages effectively.\n  This thesis aims to revolutionize the field of SLP by proposing a simple\nparadigm that can bridge this existing technological gap. We propose the use of\nSignWiring, a universal sign language transcription notation system, to serve\nas an intermediary link between the visual-gestural modality of signed\nlanguages and text-based linguistic representations.\n  We contribute foundational libraries and resources to the SLP community,\nthereby setting the stage for a more in-depth exploration of the tasks of sign\nlanguage translation and production. These tasks encompass the translation of\nsign language from video to spoken language text and vice versa. Through\nempirical evaluations, we establish the efficacy of our transcription method as\na pivot for enabling faster, more targeted research, that can lead to more\nnatural and accurate translations across a range of languages.\n  The universal nature of our transcription-based paradigm also paves the way\nfor real-time, multilingual applications in SLP, thereby offering a more\ninclusive and accessible approach to language technology. This is a significant\nstep toward universal accessibility, enabling a wider reach of AI-driven\nlanguage technologies to include the deaf and hard-of-hearing community.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "PhD Thesis",
    "pdf_url": "http://arxiv.org/pdf/2412.01991v1",
    "published_date": "2024-12-02 21:51:41 UTC",
    "updated_date": "2024-12-02 21:51:41 UTC"
  },
  {
    "arxiv_id": "2412.01978v1",
    "title": "Human-centred test and evaluation of military AI",
    "authors": [
      "David Helmer",
      "Michael Boardman",
      "S. Kate Conroy",
      "Adam J. Hepworth",
      "Manoj Harjani"
    ],
    "abstract": "The REAIM 2024 Blueprint for Action states that AI applications in the\nmilitary domain should be ethical and human-centric and that humans must remain\nresponsible and accountable for their use and effects. Developing rigorous test\nand evaluation, verification and validation (TEVV) frameworks will contribute\nto robust oversight mechanisms. TEVV in the development and deployment of AI\nsystems needs to involve human users throughout the lifecycle. Traditional\nhuman-centred test and evaluation methods from human factors need to be adapted\nfor deployed AI systems that require ongoing monitoring and evaluation. The\nlanguage around AI-enabled systems should be shifted to inclusion of the\nhuman(s) as a component of the system. Standards and requirements supporting\nthis adjusted definition are needed, as are metrics and means to evaluate them.\nThe need for dialogue between technologists and policymakers on human-centred\nTEVV will be evergreen, but dialogue needs to be initiated with an objective in\nmind for it to be productive. Development of TEVV throughout system lifecycle\nis critical to support this evolution including the issue of human scalability\nand impact on scale of achievable testing. Communication between technical and\nnon technical communities must be improved to ensure operators and\npolicy-makers understand risk assumed by system use and to better inform\nresearch and development. Test and evaluation in support of responsible AI\ndeployment must include the effect of the human to reflect operationally\nrealised system performance. Means of communicating the results of TEVV to\nthose using and making decisions regarding the use of AI based systems will be\nkey in informing risk based decisions regarding use.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, summary report from 'Human-centred test and evaluation of\n  military AI' panel at Responsible AI in the Military Domain 2024, Seoul\n  Korea, 9-10 September 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.01978v1",
    "published_date": "2024-12-02 21:14:55 UTC",
    "updated_date": "2024-12-02 21:14:55 UTC"
  },
  {
    "arxiv_id": "2412.01971v1",
    "title": "Learning a Filtered Backprojection Reconstruction Method for Photoacoustic Computed Tomography with Hemispherical Measurement Geometries",
    "authors": [
      "Panpan Chen",
      "Seonyeong Park",
      "Refik Mert Cam",
      "Hsuan-Kai Huang",
      "Alexander A. Oraevsky",
      "Umberto Villa",
      "Mark A. Anastasio"
    ],
    "abstract": "In certain three-dimensional (3D) applications of photoacoustic computed\ntomography (PACT), including \\textit{in vivo} breast imaging, hemispherical\nmeasurement apertures that enclose the object within their convex hull are\nemployed for data acquisition. Data acquired with such measurement geometries\nare referred to as \\textit{half-scan} data, as only half of a complete\nspherical measurement aperture is employed. Although previous studies have\ndemonstrated that half-scan data can uniquely and stably reconstruct the\nsought-after object, no closed-form reconstruction formula for use with\nhalf-scan data has been reported. To address this, a semi-analytic\nreconstruction method in the form of filtered backprojection (FBP), referred to\nas the half-scan FBP method, is developed in this work. Because the explicit\nform of the filtering operation in the half-scan FBP method is not currently\nknown, a learning-based method is proposed to approximate it. The proposed\nmethod is systematically investigated by use of virtual imaging studies of 3D\nbreast PACT that employ ensembles of numerical breast phantoms and a\nphysics-based model of the data acquisition process. The method is subsequently\napplied to experimental data acquired in an \\textit{in vivo} breast PACT study.\nThe results confirm that the half-scan FBP method can accurately reconstruct 3D\nimages from half-scan data. Importantly, because the sought-after inverse\nmapping is well-posed, the reconstruction method remains accurate even when\napplied to data that differ considerably from those employed to learn the\nfiltering operation.",
    "categories": [
      "physics.med-ph",
      "cs.AI"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01971v1",
    "published_date": "2024-12-02 21:01:11 UTC",
    "updated_date": "2024-12-02 21:01:11 UTC"
  },
  {
    "arxiv_id": "2412.01958v1",
    "title": "Enhancing Deep Learning Model Robustness through Metamorphic Re-Training",
    "authors": [
      "Said Togru",
      "Youssef Sameh Mostafa",
      "Karim Lotfy"
    ],
    "abstract": "This paper evaluates the use of metamorphic relations to enhance the\nrobustness and real-world performance of machine learning models. We propose a\nMetamorphic Retraining Framework, which applies metamorphic relations to data\nand utilizes semi-supervised learning algorithms in an iterative and adaptive\nmulti-cycle process. The framework integrates multiple semi-supervised\nretraining algorithms, including FixMatch, FlexMatch, MixMatch, and FullMatch,\nto automate the retraining, evaluation, and testing of models with specified\nconfigurations. To assess the effectiveness of this approach, we conducted\nexperiments on CIFAR-10, CIFAR-100, and MNIST datasets using a variety of image\nprocessing models, both pretrained and non-pretrained. Our results demonstrate\nthe potential of metamorphic retraining to significantly improve model\nrobustness as we show in our results that each model witnessed an increase of\nan additional flat 17 percent on average in our robustness metric.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01958v1",
    "published_date": "2024-12-02 20:38:03 UTC",
    "updated_date": "2024-12-02 20:38:03 UTC"
  },
  {
    "arxiv_id": "2412.01957v2",
    "title": "Usage Governance Advisor: From Intent to AI Governance",
    "authors": [
      "Elizabeth M. Daly",
      "Sean Rooney",
      "Seshu Tirupathi",
      "Luis Garces-Erice",
      "Inge Vejsbjerg",
      "Frank Bagehorn",
      "Dhaval Salwala",
      "Christopher Giblin",
      "Mira L. Wolf-Bauwens",
      "Ioana Giurgiu",
      "Michael Hind",
      "Peter Urbanetz"
    ],
    "abstract": "Evaluating the safety of AI Systems is a pressing concern for organizations\ndeploying them. In addition to the societal damage done by the lack of fairness\nof those systems, deployers are concerned about the legal repercussions and the\nreputational damage incurred by the use of models that are unsafe. Safety\ncovers both what a model does; e.g., can it be used to reveal personal\ninformation from its training set, and how a model was built; e.g., was it only\ntrained on licensed data sets. Determining the safety of an AI system requires\ngathering information from a wide set of heterogeneous sources including safety\nbenchmarks and technical documentation for the set of models used in that\nsystem. In addition, responsible use is encouraged through mechanisms that\nadvise and help the user to take mitigating actions where safety risks are\ndetected. We present Usage Governance Advisor which creates semi-structured\ngovernance information, identifies and prioritizes risks according to the\nintended use case, recommends appropriate benchmarks and risk assessments and\nimportantly proposes mitigation strategies and actions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 8 figures, AAAI workshop submission",
    "pdf_url": "http://arxiv.org/pdf/2412.01957v2",
    "published_date": "2024-12-02 20:36:41 UTC",
    "updated_date": "2025-01-23 14:49:53 UTC"
  },
  {
    "arxiv_id": "2412.01955v2",
    "title": "The use of large language models to enhance cancer clinical trial educational materials",
    "authors": [
      "Mingye Gao",
      "Aman Varshney",
      "Shan Chen",
      "Vikram Goddla",
      "Jack Gallifant",
      "Patrick Doyle",
      "Claire Novack",
      "Maeve Dillon-Martin",
      "Teresia Perkins",
      "Xinrong Correia",
      "Erik Duhaime",
      "Howard Isenstein",
      "Elad Sharon",
      "Lisa Soleymani Lehmann",
      "David Kozono",
      "Brian Anthony",
      "Dmitriy Dligach",
      "Danielle S. Bitterman"
    ],
    "abstract": "Cancer clinical trials often face challenges in recruitment and engagement\ndue to a lack of participant-facing informational and educational resources.\nThis study investigated the potential of Large Language Models (LLMs),\nspecifically GPT4, in generating patient-friendly educational content from\nclinical trial informed consent forms. Using data from ClinicalTrials.gov, we\nemployed zero-shot learning for creating trial summaries and one-shot learning\nfor developing multiple-choice questions, evaluating their effectiveness\nthrough patient surveys and crowdsourced annotation. Results showed that\nGPT4-generated summaries were both readable and comprehensive, and may improve\npatients' understanding and interest in clinical trials. The multiple-choice\nquestions demonstrated high accuracy and agreement with crowdsourced\nannotators. For both resource types, hallucinations were identified that\nrequire ongoing human oversight. The findings demonstrate the potential of LLMs\n\"out-of-the-box\" to support the generation of clinical trial education\nmaterials with minimal trial-specific engineering, but implementation with a\nhuman-in-the-loop is still needed to avoid misinformation risks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01955v2",
    "published_date": "2024-12-02 20:31:27 UTC",
    "updated_date": "2024-12-04 02:25:04 UTC"
  },
  {
    "arxiv_id": "2412.01951v2",
    "title": "Self-Improvement in Language Models: The Sharpening Mechanism",
    "authors": [
      "Audrey Huang",
      "Adam Block",
      "Dylan J. Foster",
      "Dhruv Rohatgi",
      "Cyril Zhang",
      "Max Simchowitz",
      "Jordan T. Ash",
      "Akshay Krishnamurthy"
    ],
    "abstract": "Recent work in language modeling has raised the possibility of\nself-improvement, where a language models evaluates and refines its own\ngenerations to achieve higher performance without external feedback. It is\nimpossible for this self-improvement to create information that is not already\nin the model, so why should we expect that this will lead to improved\ncapabilities? We offer a new perspective on the capabilities of\nself-improvement through a lens we refer to as sharpening. Motivated by the\nobservation that language models are often better at verifying response quality\nthan they are at generating correct responses, we formalize self-improvement as\nusing the model itself as a verifier during post-training in order to\n``sharpen'' the model to one placing large mass on high-quality sequences,\nthereby amortizing the expensive inference-time computation of generating good\nsequences. We begin by introducing a new statistical framework for sharpening\nin which the learner aims to sharpen a pre-trained base policy via sample\naccess, and establish fundamental limits. Then we analyze two natural families\nof self-improvement algorithms based on SFT and RLHF. We find that (i) the\nSFT-based approach is minimax optimal whenever the initial model has sufficient\ncoverage, but (ii) the RLHF-based approach can improve over SFT-based\nself-improvement by leveraging online exploration, bypassing the need for\ncoverage. Finally, we empirically validate the sharpening mechanism via\ninference-time and amortization experiments. We view these findings as a\nstarting point toward a foundational understanding that can guide the design\nand evaluation of self-improvement algorithms.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01951v2",
    "published_date": "2024-12-02 20:24:17 UTC",
    "updated_date": "2024-12-04 14:20:21 UTC"
  },
  {
    "arxiv_id": "2412.01949v1",
    "title": "Identifying Key Nodes for the Influence Spread using a Machine Learning Approach",
    "authors": [
      "Mateusz Stolarski",
      "Adam Piróg",
      "Piotr Bródka"
    ],
    "abstract": "The identification of key nodes in complex networks is an important topic in\nmany network science areas. It is vital to a variety of real-world\napplications, including viral marketing, epidemic spreading and influence\nmaximization. In recent years, machine learning algorithms have proven to\noutperform the conventional, centrality-based methods in accuracy and\nconsistency, but this approach still requires further refinement. What\ninformation about the influencers can be extracted from the network? How can we\nprecisely obtain the labels required for training? Can these models generalize\nwell? In this paper, we answer these questions by presenting an enhanced\nmachine learning-based framework for the influence spread problem. We focus on\nidentifying key nodes for the Independent Cascade model, which is a popular\nreference method. Our main contribution is an improved process of obtaining the\nlabels required for training by introducing 'Smart Bins' and proving their\nadvantage over known methods. Next, we show that our methodology allows ML\nmodels to not only predict the influence of a given node, but to also determine\nother characteristics of the spreading process-which is another novelty to the\nrelevant literature. Finally, we extensively test our framework and its ability\nto generalize beyond complex networks of different types and sizes, gaining\nimportant insight into the properties of these methods.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01949v1",
    "published_date": "2024-12-02 20:17:44 UTC",
    "updated_date": "2024-12-02 20:17:44 UTC"
  },
  {
    "arxiv_id": "2412.01948v1",
    "title": "The Evolution and Future Perspectives of Artificial Intelligence Generated Content",
    "authors": [
      "Chengzhang Zhu",
      "Luobin Cui",
      "Ying Tang",
      "Jiacun Wang"
    ],
    "abstract": "Artificial intelligence generated content (AIGC), a rapidly advancing\ntechnology, is transforming content creation across domains, such as text,\nimages, audio, and video. Its growing potential has attracted more and more\nresearchers and investors to explore and expand its possibilities. This review\ntraces AIGC's evolution through four developmental milestones-ranging from\nearly rule-based systems to modern transfer learning models-within a unified\nframework that highlights how each milestone contributes uniquely to content\ngeneration. In particular, the paper employs a common example across all\nmilestones to illustrate the capabilities and limitations of methods within\neach phase, providing a consistent evaluation of AIGC methodologies and their\ndevelopment. Furthermore, this paper addresses critical challenges associated\nwith AIGC and proposes actionable strategies to mitigate them. This study aims\nto guide researchers and practitioners in selecting and optimizing AIGC models\nto enhance the quality and efficiency of content creation across diverse\ndomains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01948v1",
    "published_date": "2024-12-02 20:16:40 UTC",
    "updated_date": "2024-12-02 20:16:40 UTC"
  },
  {
    "arxiv_id": "2412.01946v3",
    "title": "The Reality of AI and Biorisk",
    "authors": [
      "Aidan Peppin",
      "Anka Reuel",
      "Stephen Casper",
      "Elliot Jones",
      "Andrew Strait",
      "Usman Anwar",
      "Anurag Agrawal",
      "Sayash Kapoor",
      "Sanmi Koyejo",
      "Marie Pellat",
      "Rishi Bommasani",
      "Nick Frosst",
      "Sara Hooker"
    ],
    "abstract": "To accurately and confidently answer the question 'could an AI model or\nsystem increase biorisk', it is necessary to have both a sound theoretical\nthreat model for how AI models or systems could increase biorisk and a robust\nmethod for testing that threat model. This paper provides an analysis of\nexisting available research surrounding two AI and biorisk threat models: 1)\naccess to information and planning via large language models (LLMs), and 2) the\nuse of AI-enabled biological tools (BTs) in synthesizing novel biological\nartifacts. We find that existing studies around AI-related biorisk are nascent,\noften speculative in nature, or limited in terms of their methodological\nmaturity and transparency. The available literature suggests that current LLMs\nand BTs do not pose an immediate risk, and more work is needed to develop\nrigorous approaches to understanding how future models could increase biorisks.\nWe end with recommendations about how empirical work can be expanded to more\nprecisely target biorisk and ensure rigor and validity of findings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Updated to correct author affiliations and clarify findings of\n  evaluations of the o1 model",
    "pdf_url": "http://arxiv.org/pdf/2412.01946v3",
    "published_date": "2024-12-02 20:14:46 UTC",
    "updated_date": "2025-01-02 11:04:46 UTC"
  },
  {
    "arxiv_id": "2412.01937v1",
    "title": "Approximately Optimal Search on a Higher-dimensional Sliding Puzzle",
    "authors": [
      "Nono SC Merleau",
      "Miguel O'Malley",
      "Érika Roldán",
      "Sayan Mukherjee"
    ],
    "abstract": "Higher-dimensional sliding puzzles are constructed on the vertices of a\n$d$-dimensional hypercube, where $2^d-l$ vertices are distinctly coloured.\nRings with the same colours are initially set randomly on the vertices of the\nhypercube. The goal of the puzzle is to move each of the $2^d-l$ rings to\npre-defined target vertices on the cube. In this setting, the $k$-rule\nconstraint represents a generalisation of edge collision for the movement of\ncolours between vertices, allowing movement only when a hypercube face of\ndimension $k$ containing a ring is completely free of other rings. Starting\nfrom an initial configuration, what is the minimum number of moves needed to\nmake ring colours match the vertex colours? An algorithm that provides us with\nsuch a number is called God's algorithm. When such an algorithm exists, it does\nnot have a polynomial time complexity, at least in the case of the 15-puzzle\ncorresponding to $k=1$ in the cubical puzzle. This paper presents a\ncomprehensive computational study of different scenarios of the\nhigher-dimensional puzzle. A benchmark of three computational techniques, an\nexact algorithm (the A* search) and two approximately optimal search techniques\n(an evolutionary algorithm (EA) and reinforcement learning (RL)) is presented\nin this work. The experiments show that all three methods can successfully\nsolve the puzzle of dimension three for different face dimensions and across\nvarious difficulty levels. When the dimension increases, the A* search fails,\nand RL and EA methods can still provide a generally acceptable solution, i.e. a\ndistribution of a number of moves with a median value of less than $30$.\nOverall, the EA method consistently requires less computational time, while\nfailing in most cases to minimise the number of moves for the puzzle dimensions\n$d=4$ and $d=5$.",
    "categories": [
      "cs.AI",
      "cs.DM",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01937v1",
    "published_date": "2024-12-02 19:59:06 UTC",
    "updated_date": "2024-12-02 19:59:06 UTC"
  },
  {
    "arxiv_id": "2412.01936v1",
    "title": "Kernel-Free Universum Quadratic Surface Twin Support Vector Machines for Imbalanced Data",
    "authors": [
      "Hossein Moosaei",
      "Milan Hladík",
      "Ahmad Mousavi",
      "Zheming Gao",
      "Haojie Fu"
    ],
    "abstract": "Binary classification tasks with imbalanced classes pose significant\nchallenges in machine learning. Traditional classifiers often struggle to\naccurately capture the characteristics of the minority class, resulting in\nbiased models with subpar predictive performance. In this paper, we introduce a\nnovel approach to tackle this issue by leveraging Universum points to support\nthe minority class within quadratic twin support vector machine models. Unlike\ntraditional classifiers, our models utilize quadratic surfaces instead of\nhyperplanes for binary classification, providing greater flexibility in\nmodeling complex decision boundaries. By incorporating Universum points, our\napproach enhances classification accuracy and generalization performance on\nimbalanced datasets. We generated four artificial datasets to demonstrate the\nflexibility of the proposed methods. Additionally, we validated the\neffectiveness of our approach through empirical evaluations on benchmark\ndatasets, showing superior performance compared to conventional classifiers and\nexisting methods for imbalanced classification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01936v1",
    "published_date": "2024-12-02 19:57:59 UTC",
    "updated_date": "2024-12-02 19:57:59 UTC"
  },
  {
    "arxiv_id": "2412.01935v1",
    "title": "Cross Domain Adaptation using Adversarial networks with Cyclic loss",
    "authors": [
      "Manpreet Kaur",
      "Ankur Tomar",
      "Srijan Mishra",
      "Shashwat Verma"
    ],
    "abstract": "Deep Learning methods are highly local and sensitive to the domain of data\nthey are trained with. Even a slight deviation from the domain distribution\naffects prediction accuracy of deep networks significantly. In this work, we\nhave investigated a set of techniques aimed at increasing accuracy of generator\nnetworks which perform translation from one domain to the other in an\nadversarial setting. In particular, we experimented with activations, the\nencoder-decoder network architectures, and introduced a Loss called cyclic loss\nto constrain the Generator network so that it learns effective source-target\ntranslation. This machine learning problem is motivated by myriad applications\nthat can be derived from domain adaptation networks like generating labeled\ndata from synthetic inputs in an unsupervised fashion, and using these\ntranslation network in conjunction with the original domain network to\ngeneralize deep learning networks across domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01935v1",
    "published_date": "2024-12-02 19:55:35 UTC",
    "updated_date": "2024-12-02 19:55:35 UTC"
  },
  {
    "arxiv_id": "2412.01933v1",
    "title": "Recurrent Neural Network on PICTURE Model",
    "authors": [
      "Weihan Xu"
    ],
    "abstract": "Intensive Care Units (ICUs) provide critical care and life support for most\nseverely ill and injured patients in the hospital. With the need for ICUs\ngrowing rapidly and unprecedentedly, especially during COVID-19, accurately\nidentifying the most critical patients helps hospitals to allocate resources\nmore efficiently and save more lives. The Predicting Intensive Care Transfers\nand Other Unforeseen Events (PICTURE) model predicts patient deterioration by\nseparating those at high risk for imminent intensive care unit transfer,\nrespiratory failure, or death from those at lower risk. This study aims to\nimplement a deep learning model to benchmark the performance from the XGBoost\nmodel, an existing model which has competitive results on prediction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "University of Michigan, Senior Honor Thesis",
    "pdf_url": "http://arxiv.org/pdf/2412.01933v1",
    "published_date": "2024-12-02 19:49:51 UTC",
    "updated_date": "2024-12-02 19:49:51 UTC"
  },
  {
    "arxiv_id": "2412.02722v1",
    "title": "Enhanced N-BEATS for Mid-Term Electricity Demand Forecasting",
    "authors": [
      "Mateusz Kasprzyk",
      "Paweł Pełka",
      "Boris N. Oreshkin",
      "Grzegorz Dudek"
    ],
    "abstract": "This paper presents an enhanced N-BEATS model, N-BEATS*, for improved\nmid-term electricity load forecasting (MTLF). Building on the strengths of the\noriginal N-BEATS architecture, which excels in handling complex time series\ndata without requiring preprocessing or domain-specific knowledge, N-BEATS*\nintroduces two key modifications. (1) A novel loss function -- combining\npinball loss based on MAPE with normalized MSE, the new loss function allows\nfor a more balanced approach by capturing both L1 and L2 loss terms. (2) A\nmodified block architecture -- the internal structure of the N-BEATS blocks is\nadjusted by introducing a destandardization component to harmonize the\nprocessing of different time series, leading to more efficient and less complex\nforecasting tasks. Evaluated on real-world monthly electricity consumption data\nfrom 35 European countries, N-BEATS* demonstrates superior performance compared\nto its predecessor and other established forecasting methods, including\nstatistical, machine learning, and hybrid models. N-BEATS* achieves the lowest\nMAPE and RMSE, while also exhibiting the lowest dispersion in forecast errors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02722v1",
    "published_date": "2024-12-02 19:31:44 UTC",
    "updated_date": "2024-12-02 19:31:44 UTC"
  },
  {
    "arxiv_id": "2412.01929v1",
    "title": "ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals",
    "authors": [
      "Poorya Aghaomidi",
      "Ge Wang"
    ],
    "abstract": "Accurate sleep stage classification is essential for understanding sleep\ndisorders and improving overall health. This study proposes a novel three-stage\napproach for sleep stage classification using ECG signals, offering a more\naccessible alternative to traditional methods that often rely on complex\nmodalities like EEG. In Stages 1 and 2, we initialize the weights of two\nnetworks, which are then integrated in Stage 3 for comprehensive\nclassification. In the first phase, we estimate key features using Feature\nImitating Networks (FINs) to achieve higher accuracy and faster convergence.\nThe second phase focuses on identifying the N1 sleep stage through the\ntime-frequency representation of ECG signals. Finally, the third phase\nintegrates models from the previous stages and employs a Kolmogorov-Arnold\nNetwork (KAN) to classify five distinct sleep stages. Additionally, data\naugmentation techniques, particularly SMOTE, are used in enhancing\nclassification capabilities for underrepresented stages like N1. Our results\ndemonstrate significant improvements in the classification performance, with an\noverall accuracy of 80.79% an overall kappa of 0.73. The model achieves\nspecific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%\nfor N3, and 87.16% for REM. This study emphasizes the importance of weight\ninitialization and data augmentation in optimizing sleep stage classification\nwith ECG signals.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.01929v1",
    "published_date": "2024-12-02 19:31:25 UTC",
    "updated_date": "2024-12-02 19:31:25 UTC"
  },
  {
    "arxiv_id": "2412.01928v2",
    "title": "MALT: Improving Reasoning with Multi-Agent LLM Training",
    "authors": [
      "Sumeet Ramesh Motwani",
      "Chandler Smith",
      "Rocktim Jyoti Das",
      "Rafael Rafailov",
      "Ivan Laptev",
      "Philip H. S. Torr",
      "Fabio Pizzati",
      "Ronald Clark",
      "Christian Schroeder de Witt"
    ],
    "abstract": "Large Language Models (LLMs) often produce answers with a single\nchain-of-thought, which restricts their ability to explore reasoning paths or\nself-correct flawed outputs in complex tasks. In this paper, we introduce MALT\n(Multi-Agent LLM Training), a novel post-training strategy that divides the\nreasoning process into generation, verification, and refinement steps using a\nsequential pipeline of heterogeneous agents. During data generation, each agent\nis repeatedly sampled to form a multi-agent search tree, where final outputs\nare graded against ground-truth data. We then apply value iteration to\npropagate reward signals back to each role-conditioned model, automatically\nproducing multi-agent post-training data without human or teacher-model\nsupervision. Our off-policy approach allows each agent to specialize by\nlearning from correct and incorrect trajectories, ultimately improving the\nend-to-end reasoning chain. On MATH, GSM8K, and CSQA, MALT surpasses the same\nbaseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40%\nrespectively, making it an important advance towards multi-agent cooperative\ntraining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01928v2",
    "published_date": "2024-12-02 19:30:36 UTC",
    "updated_date": "2025-02-27 11:25:02 UTC"
  },
  {
    "arxiv_id": "2412.01827v1",
    "title": "RandAR: Decoder-only Autoregressive Visual Generation in Random Orders",
    "authors": [
      "Ziqi Pang",
      "Tianyuan Zhang",
      "Fujun Luan",
      "Yunze Man",
      "Hao Tan",
      "Kai Zhang",
      "William T. Freeman",
      "Yu-Xiong Wang"
    ],
    "abstract": "We introduce RandAR, a decoder-only visual autoregressive (AR) model capable\nof generating images in arbitrary token orders. Unlike previous decoder-only AR\nmodels that rely on a predefined generation order, RandAR removes this\ninductive bias, unlocking new capabilities in decoder-only generation. Our\nessential design enables random order by inserting a \"position instruction\ntoken\" before each image token to be predicted, representing the spatial\nlocation of the next image token. Trained on randomly permuted token sequences\n-- a more challenging task than fixed-order generation, RandAR achieves\ncomparable performance to its conventional raster-order counterpart. More\nimportantly, decoder-only transformers trained from random orders acquire new\ncapabilities. For the efficiency bottleneck of AR models, RandAR adopts\nparallel decoding with KV-Cache at inference time, enjoying 2.5x acceleration\nwithout sacrificing generation quality. Additionally, RandAR supports\ninpainting, outpainting and resolution extrapolation in a zero-shot manner. We\nhope RandAR inspires new directions for decoder-only visual generation models\nand broadens their applications across diverse scenarios. Our project page is\nat https://rand-ar.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://rand-ar.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.01827v1",
    "published_date": "2024-12-02 18:59:53 UTC",
    "updated_date": "2024-12-02 18:59:53 UTC"
  },
  {
    "arxiv_id": "2412.01825v1",
    "title": "GETAE: Graph information Enhanced deep neural NeTwork ensemble ArchitecturE for fake news detection",
    "authors": [
      "Ciprian-Octavian Truică",
      "Elena-Simona Apostol",
      "Marius Marogel",
      "Adrian Paschke"
    ],
    "abstract": "In today's digital age, fake news has become a major problem that has serious\nconsequences, ranging from social unrest to political upheaval. To address this\nissue, new methods for detecting and mitigating fake news are required. In this\nwork, we propose to incorporate contextual and network-aware features into the\ndetection process. This involves analyzing not only the content of a news\narticle but also the context in which it was shared and the network of users\nwho shared it, i.e., the information diffusion. Thus, we propose GETAE,\n\\underline{G}raph Information \\underline{E}nhanced Deep Neural\nNe\\underline{t}work Ensemble \\underline{A}rchitectur\\underline{E} for Fake News\nDetection, a novel ensemble architecture that uses textual content together\nwith the social interactions to improve fake news detection. GETAE contains two\nBranches: the Text Branch and the Propagation Branch. The Text Branch uses Word\nand Transformer Embeddings and a Deep Neural Network based on feed-forward and\nbidirectional Recurrent Neural Networks (\\textsc{[Bi]RNN}) for learning novel\ncontextual features and creating a novel Text Content Embedding. The\nPropagation Branch considers the information propagation within the graph\nnetwork and proposes a Deep Learning architecture that employs Node Embeddings\nto create novel Propagation Embedding. GETAE Ensemble combines the two novel\nembeddings, i.e., Text Content Embedding and Propagation Embedding, to create a\nnovel \\textit{Propagation-Enhanced Content Embedding} which is afterward used\nfor classification. The experimental results obtained on two real-world\npublicly available datasets, i.e., Twitter15 and Twitter16, prove that using\nthis approach improves fake news detection and outperforms state-of-the-art\nmodels.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01825v1",
    "published_date": "2024-12-02 18:59:50 UTC",
    "updated_date": "2024-12-02 18:59:50 UTC"
  },
  {
    "arxiv_id": "2412.01824v1",
    "title": "X-Prompt: Towards Universal In-Context Image Generation in Auto-Regressive Vision Language Foundation Models",
    "authors": [
      "Zeyi Sun",
      "Ziyang Chu",
      "Pan Zhang",
      "Tong Wu",
      "Xiaoyi Dong",
      "Yuhang Zang",
      "Yuanjun Xiong",
      "Dahua Lin",
      "Jiaqi Wang"
    ],
    "abstract": "In-context generation is a key component of large language models' (LLMs)\nopen-task generalization capability. By leveraging a few examples as context,\nLLMs can perform both in-domain and out-of-domain tasks. Recent advancements in\nauto-regressive vision-language models (VLMs) built upon LLMs have showcased\nimpressive performance in text-to-image generation. However, the potential of\nin-context learning for general image generation tasks remains largely\nunexplored. To address this, we introduce X-Prompt, a purely auto-regressive\nlarge-vision language model designed to deliver competitive performance across\na wide range of both seen and unseen image generation tasks, all within a\nunified in-context learning framework. X-Prompt incorporates a specialized\ndesign that efficiently compresses valuable features from in-context examples,\nsupporting longer in-context token sequences and improving its ability to\ngeneralize to unseen tasks. A unified training task for both text and image\nprediction enables X-Prompt to handle general image generation with enhanced\ntask awareness from in-context examples. Extensive experiments validate the\nmodel's performance across diverse seen image generation tasks and its capacity\nto generalize to previously unseen tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "code: https://github.com/SunzeY/X-Prompt",
    "pdf_url": "http://arxiv.org/pdf/2412.01824v1",
    "published_date": "2024-12-02 18:59:26 UTC",
    "updated_date": "2024-12-02 18:59:26 UTC"
  },
  {
    "arxiv_id": "2412.01818v2",
    "title": "Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs",
    "authors": [
      "Qizhe Zhang",
      "Aosong Cheng",
      "Ming Lu",
      "Renrui Zhang",
      "Zhiyong Zhuo",
      "Jiajun Cao",
      "Shaobo Guo",
      "Qi She",
      "Shanghang Zhang"
    ],
    "abstract": "Large vision-language models (LVLMs) generally contain significantly more\nvisual tokens than their textual counterparts, resulting in a considerable\ncomputational burden. Recent efforts have been made to tackle this issue by\npruning visual tokens early within the language model. Most existing works use\nattention scores between text and visual tokens to assess the importance of\nvisual tokens. However, in this study, we first analyze the text-visual\nattention in the language model and find that this score is not an ideal\nindicator for token pruning. Based on the analysis, We propose VisPruner, a\nplug-and-play method that utilizes visual cues for more effective token pruning\nin LVLMs. Specifically, we first use visual attention to select a limited\nnumber of significant tokens. Then, we remove duplicate tokens from the\nremaining ones based on their similarity. By retaining diverse tokens alongside\nthe initially selected important tokens, we maximally preserve the visual\ninformation of the input image. Experimental results demonstrate that our\nVisPruner sustains strong performance across various VLM architectures and\nreduction ratios, significantly outperforming existing methods based on\ntext-visual attention. Notably, without any training, VisPruner can reduce the\nFLOPs of LLaVA-1.5-7B by 91% and inference latency by 75%, while maintaining\ncomparable performance. Our code is available at\nhttps://github.com/Theia-4869/VisPruner.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 9 figures, code: https://github.com/Theia-4869/VisPruner,\n  project page: https://theia-4869.github.io/VisPruner",
    "pdf_url": "http://arxiv.org/pdf/2412.01818v2",
    "published_date": "2024-12-02 18:57:40 UTC",
    "updated_date": "2025-05-11 17:45:02 UTC"
  },
  {
    "arxiv_id": "2412.12119v2",
    "title": "Mastering Board Games by External and Internal Planning with Language Models",
    "authors": [
      "John Schultz",
      "Jakub Adamek",
      "Matej Jusup",
      "Marc Lanctot",
      "Michael Kaisers",
      "Sarah Perrin",
      "Daniel Hennes",
      "Jeremy Shar",
      "Cannada Lewis",
      "Anian Ruoss",
      "Tom Zahavy",
      "Petar Veličković",
      "Laurel Prince",
      "Satinder Singh",
      "Eric Malmi",
      "Nenad Tomašev"
    ],
    "abstract": "Advancing planning and reasoning capabilities of Large Language Models (LLMs)\nis one of the key prerequisites towards unlocking their potential for\nperforming reliably in complex and impactful domains. In this paper, we aim to\ndemonstrate this across board games (Chess, Fischer Random / Chess960, Connect\nFour, and Hex), and we show that search-based planning can yield significant\nimprovements in LLM game-playing strength. We introduce, compare and contrast\ntwo major approaches: In external search, the model guides Monte Carlo Tree\nSearch (MCTS) rollouts and evaluations without calls to an external game\nengine, and in internal search, the model is trained to generate in-context a\nlinearized tree of search and a resulting final choice. Both build on a\nlanguage model pre-trained on relevant domain knowledge, reliably capturing the\ntransition and value functions in the respective environments, with minimal\nhallucinations. We evaluate our LLM search implementations against\ngame-specific state-of-the-art engines, showcasing substantial improvements in\nstrength over the base model, and reaching Grandmaster-level performance in\nchess while operating closer to the human search budget. Our proposed approach,\ncombining search with domain knowledge, is not specific to board games, hinting\nat more general future applications.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "70 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.12119v2",
    "published_date": "2024-12-02 18:56:51 UTC",
    "updated_date": "2025-04-29 18:06:45 UTC"
  },
  {
    "arxiv_id": "2412.01814v2",
    "title": "COSMOS: Cross-Modality Self-Distillation for Vision Language Pre-training",
    "authors": [
      "Sanghwan Kim",
      "Rui Xiao",
      "Mariana-Iuliana Georgescu",
      "Stephan Alaniz",
      "Zeynep Akata"
    ],
    "abstract": "Vision-Language Models (VLMs) trained with contrastive loss have achieved\nsignificant advancements in various vision and language tasks. However, the\nglobal nature of the contrastive loss makes VLMs focus predominantly on\nforeground objects, neglecting other crucial information in the image, which\nlimits their effectiveness in downstream tasks. To address these challenges, we\npropose COSMOS: CrOSs-MOdality Self-distillation for vision-language\npre-training that integrates a novel text-cropping strategy and cross-attention\nmodule into a self-supervised learning framework. We create global and local\nviews of images and texts (i.e., multi-modal augmentations), which are\nessential for self-distillation in VLMs. We further introduce a cross-attention\nmodule, enabling COSMOS to learn comprehensive cross-modal representations\noptimized via a cross-modality self-distillation loss. COSMOS consistently\noutperforms previous strong baselines on various zero-shot downstream tasks,\nincluding retrieval, classification, and semantic segmentation. Additionally,\nit surpasses CLIP-based models trained on larger datasets in visual perception\nand contextual understanding tasks. Code is available at\nhttps://github.com/ExplainableML/cosmos.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01814v2",
    "published_date": "2024-12-02 18:56:06 UTC",
    "updated_date": "2025-03-26 16:07:40 UTC"
  },
  {
    "arxiv_id": "2412.01806v3",
    "title": "Random Tree Model of Meaningful Memory",
    "authors": [
      "Weishun Zhong",
      "Tankut Can",
      "Antonis Georgiou",
      "Ilya Shnayderman",
      "Mikhail Katkov",
      "Misha Tsodyks"
    ],
    "abstract": "Traditional studies of memory for meaningful narratives focus on specific\nstories and their semantic structures but do not address common quantitative\nfeatures of recall across different narratives. We introduce a statistical\nensemble of random trees to represent narratives as hierarchies of key points,\nwhere each node is a compressed representation of its descendant leaves, which\nare the original narrative segments. Recall is modeled as constrained by\nworking memory capacity from this hierarchical structure. Our analytical\nsolution aligns with observations from large-scale narrative recall\nexperiments. Specifically, our model explains that (1) average recall length\nincreases sublinearly with narrative length, and (2) individuals summarize\nincreasingly longer narrative segments in each recall sentence. Additionally,\nthe theory predicts that for sufficiently long narratives, a universal,\nscale-invariant limit emerges, where the fraction of a narrative summarized by\na single recall sentence follows a distribution independent of narrative\nlength.",
    "categories": [
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cond-mat.stat-mech",
    "comment": "21 pages, 5 figures; included new derivations",
    "pdf_url": "http://arxiv.org/pdf/2412.01806v3",
    "published_date": "2024-12-02 18:50:27 UTC",
    "updated_date": "2025-02-23 19:25:11 UTC"
  },
  {
    "arxiv_id": "2412.01799v1",
    "title": "HPRM: High-Performance Robotic Middleware for Intelligent Autonomous Systems",
    "authors": [
      "Jacky Kwok",
      "Shulu Li",
      "Marten Lohstroh",
      "Edward A. Lee"
    ],
    "abstract": "The rise of intelligent autonomous systems, especially in robotics and\nautonomous agents, has created a critical need for robust communication\nmiddleware that can ensure real-time processing of extensive sensor data.\nCurrent robotics middleware like Robot Operating System (ROS) 2 faces\nchallenges with nondeterminism and high communication latency when dealing with\nlarge data across multiple subscribers on a multi-core compute platform. To\naddress these issues, we present High-Performance Robotic Middleware (HPRM),\nbuilt on top of the deterministic coordination language Lingua Franca (LF).\nHPRM employs optimizations including an in-memory object store for efficient\nzero-copy transfer of large payloads, adaptive serialization to minimize\nserialization overhead, and an eager protocol with real-time sockets to reduce\nhandshake latency. Benchmarks show HPRM achieves up to 173x lower latency than\nROS2 when broadcasting large messages to multiple nodes. We then demonstrate\nthe benefits of HPRM by integrating it with the CARLA simulator and running\nreinforcement learning agents along with object detection workloads. In the\nCARLA autonomous driving application, HPRM attains 91.1% lower latency than\nROS2. The deterministic coordination semantics of HPRM, combined with its\noptimized IPC mechanisms, enable efficient and predictable real-time\ncommunication for intelligent autonomous systems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.01799v1",
    "published_date": "2024-12-02 18:46:29 UTC",
    "updated_date": "2024-12-02 18:46:29 UTC"
  },
  {
    "arxiv_id": "2412.01794v2",
    "title": "IQA-Adapter: Exploring Knowledge Transfer from Image Quality Assessment to Diffusion-based Generative Models",
    "authors": [
      "Khaled Abud",
      "Sergey Lavrushkin",
      "Alexey Kirillov",
      "Dmitriy Vatolin"
    ],
    "abstract": "Diffusion-based models have recently revolutionized image generation,\nachieving unprecedented levels of fidelity. However, consistent generation of\nhigh-quality images remains challenging partly due to the lack of conditioning\nmechanisms for perceptual quality. In this work, we propose methods to\nintegrate image quality assessment (IQA) models into diffusion-based\ngenerators, enabling quality-aware image generation. We show that diffusion\nmodels can learn complex qualitative relationships from both IQA models'\noutputs and internal activations. First, we experiment with gradient-based\nguidance to optimize image quality directly and show this method has limited\ngeneralizability. To address this, we introduce IQA-Adapter, a novel framework\nthat conditions generation on target quality levels by learning the implicit\nrelationship between images and quality scores. When conditioned on high target\nquality, IQA-Adapter can shift the distribution of generated images towards a\nhigher-quality subdomain, and, inversely, it can be used as a degradation\nmodel, generating progressively more distorted images when provided with a\nlower-quality signal. Under high-quality condition, IQA-Adapter achieves up to\na 10% improvement across multiple objective metrics, as confirmed by a user\npreference study, while preserving generative diversity and content.\nFurthermore, we extend IQA-Adapter to a reference-based conditioning scenario,\nutilizing the rich activation space of IQA models to transfer highly specific,\ncontent-agnostic qualitative features between images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "GitHub repo: https://github.com/X1716/IQA-Adapter",
    "pdf_url": "http://arxiv.org/pdf/2412.01794v2",
    "published_date": "2024-12-02 18:40:19 UTC",
    "updated_date": "2025-03-16 21:10:57 UTC"
  },
  {
    "arxiv_id": "2412.01789v1",
    "title": "From ChebNet to ChebGibbsNet",
    "authors": [
      "Jie Zhang",
      "Min-Te Sun"
    ],
    "abstract": "Recent advancements in Spectral Graph Convolutional Networks (SpecGCNs) have\nled to state-of-the-art performance in various graph representation learning\ntasks. To exploit the potential of SpecGCNs, we analyze corresponding graph\nfilters via polynomial interpolation, the cornerstone of graph signal\nprocessing. Different polynomial bases, such as Bernstein, Chebyshev, and\nmonomial basis, have various convergence rates that will affect the error in\npolynomial interpolation. Although adopting Chebyshev basis for interpolation\ncan minimize maximum error, the performance of ChebNet is still weaker than\nGPR-GNN and BernNet. \\textbf{We point out it is caused by the Gibbs phenomenon,\nwhich occurs when the graph frequency response function approximates the target\nfunction.} It reduces the approximation ability of a truncated polynomial\ninterpolation. In order to mitigate the Gibbs phenomenon, we propose to add the\nGibbs damping factor with each term of Chebyshev polynomials on ChebNet. As a\nresult, our lightweight approach leads to a significant performance boost.\nAfterwards, we reorganize ChebNet via decoupling feature propagation and\ntransformation. We name this variant as \\textbf{ChebGibbsNet}. Our experiments\nindicate that ChebGibbsNet is superior to other advanced SpecGCNs, such as\nGPR-GNN and BernNet, in both homogeneous graphs and heterogeneous graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 2 figures, and 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.01789v1",
    "published_date": "2024-12-02 18:37:45 UTC",
    "updated_date": "2024-12-02 18:37:45 UTC"
  },
  {
    "arxiv_id": "2412.01784v1",
    "title": "Noise Injection Reveals Hidden Capabilities of Sandbagging Language Models",
    "authors": [
      "Cameron Tice",
      "Philipp Alexander Kreer",
      "Nathan Helm-Burger",
      "Prithviraj Singh Shahani",
      "Fedor Ryzhenkov",
      "Jacob Haimes",
      "Felix Hofstätter",
      "Teun van der Weij"
    ],
    "abstract": "Capability evaluations play a critical role in ensuring the safe deployment\nof frontier AI systems, but this role may be undermined by intentional\nunderperformance or ``sandbagging.'' We present a novel model-agnostic method\nfor detecting sandbagging behavior using noise injection. Our approach is\nfounded on the observation that introducing Gaussian noise into the weights of\nmodels either prompted or fine-tuned to sandbag can considerably improve their\nperformance. We test this technique across a range of model sizes and\nmultiple-choice question benchmarks (MMLU, AI2, WMDP). Our results demonstrate\nthat noise injected sandbagging models show performance improvements compared\nto standard models. Leveraging this effect, we develop a classifier that\nconsistently identifies sandbagging behavior. Our unsupervised technique can be\nimmediately implemented by frontier labs or regulatory bodies with access to\nweights to improve the trustworthiness of capability evaluations.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at NeurIPS 2024, SATA and SoLaR workshop, 6 pages, 4\n  figures, 1 table, code available at https://github.com/camtice/SandbagDetect",
    "pdf_url": "http://arxiv.org/pdf/2412.01784v1",
    "published_date": "2024-12-02 18:34:51 UTC",
    "updated_date": "2024-12-02 18:34:51 UTC"
  },
  {
    "arxiv_id": "2412.01782v2",
    "title": "Quantifying the Reliability of Predictions in Detection Transformers: Object-Level Calibration and Image-Level Uncertainty",
    "authors": [
      "Young-Jin Park",
      "Carson Sobolewski",
      "Navid Azizan"
    ],
    "abstract": "DEtection TRansformer (DETR) has emerged as a promising architecture for\nobject detection, offering an end-to-end prediction pipeline. In practice,\nhowever, DETR generates hundreds of predictions that far outnumber the actual\nnumber of objects present in an image. This raises the question: can we trust\nand use all of these predictions? Addressing this concern, we present empirical\nevidence highlighting how different predictions within the same image play\ndistinct roles, resulting in varying reliability levels across those\npredictions. More specifically, while multiple predictions are often made for a\nsingle object, our findings show that most often one such prediction is\nwell-calibrated, and the others are poorly calibrated. Based on these insights,\nwe demonstrate that identifying a reliable subset of DETR's predictions is\ncrucial for accurately assessing the reliability of the model at both object\nand image levels.\n  Building on this viewpoint, we first address the shortcomings of widely used\nperformance and calibration metrics, such as average precision and various\nforms of expected calibration error. Specifically, they are inadequate for\ndetermining which subset of DETR's predictions should be trusted and utilized.\nIn response, we present Object-level Calibration Error (OCE), which assesses\nthe calibration quality more effectively and is suitable for both ranking\ndifferent models and identifying the most reliable predictions within a\nspecific model. As a final contribution, we introduce a post hoc uncertainty\nquantification (UQ) framework that predicts the accuracy of the model on a\nper-image basis. By contrasting the average confidence scores of positive\n(i.e., likely to be matched) and negative predictions determined by OCE, our\nframework assesses the reliability of the DETR model for each test image.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01782v2",
    "published_date": "2024-12-02 18:34:17 UTC",
    "updated_date": "2025-03-17 18:35:23 UTC"
  },
  {
    "arxiv_id": "2412.01778v1",
    "title": "HackSynth: LLM Agent and Evaluation Framework for Autonomous Penetration Testing",
    "authors": [
      "Lajos Muzsai",
      "David Imolai",
      "András Lukács"
    ],
    "abstract": "We introduce HackSynth, a novel Large Language Model (LLM)-based agent\ncapable of autonomous penetration testing. HackSynth's dual-module architecture\nincludes a Planner and a Summarizer, which enable it to generate commands and\nprocess feedback iteratively. To benchmark HackSynth, we propose two new\nCapture The Flag (CTF)-based benchmark sets utilizing the popular platforms\nPicoCTF and OverTheWire. These benchmarks include two hundred challenges across\ndiverse domains and difficulties, providing a standardized framework for\nevaluating LLM-based penetration testing agents. Based on these benchmarks,\nextensive experiments are presented, analyzing the core parameters of\nHackSynth, including creativity (temperature and top-p) and token utilization.\nMultiple open source and proprietary LLMs were used to measure the agent's\ncapabilities. The experiments show that the agent performed best with the\nGPT-4o model, better than what the GPT-4o's system card suggests. We also\ndiscuss the safety and predictability of HackSynth's actions. Our findings\nindicate the potential of LLM-based agents in advancing autonomous penetration\ntesting and the importance of robust safeguards. HackSynth and the benchmarks\nare publicly available to foster research on autonomous cybersecurity\nsolutions.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "68M25",
      "I.2.1; K.6.5"
    ],
    "primary_category": "cs.CR",
    "comment": "16 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01778v1",
    "published_date": "2024-12-02 18:28:18 UTC",
    "updated_date": "2024-12-02 18:28:18 UTC"
  },
  {
    "arxiv_id": "2412.01770v2",
    "title": "Robot Learning with Super-Linear Scaling",
    "authors": [
      "Marcel Torne",
      "Arhan Jain",
      "Jiayi Yuan",
      "Vidaaranya Macha",
      "Lars Ankile",
      "Anthony Simeonov",
      "Pulkit Agrawal",
      "Abhishek Gupta"
    ],
    "abstract": "Scaling robot learning requires data collection pipelines that scale\nfavorably with human effort. In this work, we propose Crowdsourcing and\nAmortizing Human Effort for Real-to-Sim-to-Real(CASHER), a pipeline for scaling\nup data collection and learning in simulation where the performance scales\nsuperlinearly with human effort. The key idea is to crowdsource digital twins\nof real-world scenes using 3D reconstruction and collect large-scale data in\nsimulation, rather than the real-world. Data collection in simulation is\ninitially driven by RL, bootstrapped with human demonstrations. As the training\nof a generalist policy progresses across environments, its generalization\ncapabilities can be used to replace human effort with model generated\ndemonstrations. This results in a pipeline where behavioral data is collected\nin simulation with continually reducing human effort. We show that CASHER\ndemonstrates zero-shot and few-shot scaling laws on three real-world tasks\nacross diverse scenarios. We show that CASHER enables fine-tuning of\npre-trained policies to a target scenario using a video scan without any\nadditional human effort. See our project website:\nhttps://casher-robot-learning.github.io/CASHER/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01770v2",
    "published_date": "2024-12-02 18:12:02 UTC",
    "updated_date": "2024-12-06 05:23:30 UTC"
  },
  {
    "arxiv_id": "2412.01769v1",
    "title": "Commit0: Library Generation from Scratch",
    "authors": [
      "Wenting Zhao",
      "Nan Jiang",
      "Celine Lee",
      "Justin T Chiu",
      "Claire Cardie",
      "Matthias Gallé",
      "Alexander M Rush"
    ],
    "abstract": "With the goal of benchmarking generative systems beyond expert software\ndevelopment ability, we introduce Commit0, a benchmark that challenges AI\nagents to write libraries from scratch. Agents are provided with a\nspecification document outlining the library's API as well as a suite of\ninteractive unit tests, with the goal of producing an implementation of this\nAPI accordingly. The implementation is validated through running these unit\ntests. As a benchmark, Commit0 is designed to move beyond static one-shot code\ngeneration towards agents that must process long-form natural language\nspecifications, adapt to multi-stage feedback, and generate code with complex\ndependencies. Commit0 also offers an interactive environment where models\nreceive static analysis and execution feedback on the code they generate. Our\nexperiments demonstrate that while current agents can pass some unit tests,\nnone can yet fully reproduce full libraries. Results also show that interactive\nfeedback is quite useful for models to generate code that passes more unit\ntests, validating the benchmarks that facilitate its use.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01769v1",
    "published_date": "2024-12-02 18:11:30 UTC",
    "updated_date": "2024-12-02 18:11:30 UTC"
  },
  {
    "arxiv_id": "2412.01754v1",
    "title": "Efficient Compression of Sparse Accelerator Data Using Implicit Neural Representations and Importance Sampling",
    "authors": [
      "Xihaier Luo",
      "Samuel Lurvey",
      "Yi Huang",
      "Yihui Ren",
      "Jin Huang",
      "Byung-Jun Yoon"
    ],
    "abstract": "High-energy, large-scale particle colliders in nuclear and high-energy\nphysics generate data at extraordinary rates, reaching up to $1$ terabyte and\nseveral petabytes per second, respectively. The development of real-time,\nhigh-throughput data compression algorithms capable of reducing this data to\nmanageable sizes for permanent storage is of paramount importance. A unique\ncharacteristic of the tracking detector data is the extreme sparsity of\nparticle trajectories in space, with an occupancy rate ranging from\napproximately $10^{-6}$ to $10\\%$. Furthermore, for downstream tasks, a\ncontinuous representation of this data is often more useful than a voxel-based,\ndiscrete representation due to the inherently continuous nature of the signals\ninvolved. To address these challenges, we propose a novel approach using\nimplicit neural representations for data learning and compression. We also\nintroduce an importance sampling technique to accelerate the network training\nprocess. Our method is competitive with traditional compression algorithms,\nsuch as MGARD, SZ, and ZFP, while offering significant speed-ups and\nmaintaining negligible accuracy loss through our importance sampling strategy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01754v1",
    "published_date": "2024-12-02 17:50:49 UTC",
    "updated_date": "2024-12-02 17:50:49 UTC"
  },
  {
    "arxiv_id": "2412.01752v1",
    "title": "A Neurosymbolic Fast and Slow Architecture for Graph Coloring",
    "authors": [
      "Vedant Khandelwal",
      "Vishal Pallagani",
      "Biplav Srivastava",
      "Francesca Rossi"
    ],
    "abstract": "Constraint Satisfaction Problems (CSPs) present significant challenges to\nartificial intelligence due to their intricate constraints and the necessity\nfor precise solutions. Existing symbolic solvers are often slow, and prior\nresearch has shown that Large Language Models (LLMs) alone struggle with CSPs\nbecause of their complexity. To bridge this gap, we build upon the existing\nSOFAI architecture (or SOFAI-v1), which adapts Daniel Kahneman's ''Thinking,\nFast and Slow'' cognitive model to AI. Our enhanced architecture, SOFAI-v2,\nintegrates refined metacognitive governance mechanisms to improve adaptability\nacross complex domains, specifically tailored for solving CSPs like graph\ncoloring. SOFAI-v2 combines a fast System 1 (S1) based on LLMs with a\ndeliberative System 2 (S2) governed by a metacognition module. S1's initial\nsolutions, often limited by non-adherence to constraints, are enhanced through\nmetacognitive governance, which provides targeted feedback and examples to\nadapt S1 to CSP requirements. If S1 fails to solve the problem, metacognition\nstrategically invokes S2, ensuring accurate and reliable solutions. With\nempirical results, we show that SOFAI-v2 for graph coloring problems achieves a\n16.98% increased success rate and is 32.42% faster than symbolic solvers.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "18 Pages, 18 Figures, 3 Tables",
    "pdf_url": "http://arxiv.org/pdf/2412.01752v1",
    "published_date": "2024-12-02 17:47:13 UTC",
    "updated_date": "2024-12-02 17:47:13 UTC"
  },
  {
    "arxiv_id": "2412.01728v1",
    "title": "Automated Toll Management System Using RFID and Image Processing",
    "authors": [
      "Raihan Ahmed",
      "Shahed Chowdhury Omi",
      "Md. Sadman Rahman",
      "Niaz Rahman Bhuiyan"
    ],
    "abstract": "Traveling through toll plazas is one of the primary causes of congestion, as\nidentified in recent studies. Electronic Toll Collection (ETC) systems can\nmitigate this problem. This experiment focuses on enhancing the security of ETC\nusing RFID tags and number plate verification. For number plate verification,\nimage processing is employed, and a CNN classifier is implemented to detect\nvehicle registration numbers. Based on the registered number, a notification\nemail is sent to the respective owner for toll fee payment within a specific\ntimeframe to avoid fines. Additionally, toll fees are automatically deducted in\nreal-time from the owner's balance. This system benefits travelers by\neliminating the need to queue for toll payment, thereby reducing delays and\nimproving convenience.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01728v1",
    "published_date": "2024-12-02 17:19:42 UTC",
    "updated_date": "2024-12-02 17:19:42 UTC"
  },
  {
    "arxiv_id": "2412.01708v1",
    "title": "Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review",
    "authors": [
      "Rui Ye",
      "Xianghe Pang",
      "Jingyi Chai",
      "Jiaao Chen",
      "Zhenfei Yin",
      "Zhen Xiang",
      "Xiaowen Dong",
      "Jing Shao",
      "Siheng Chen"
    ],
    "abstract": "Scholarly peer review is a cornerstone of scientific advancement, but the\nsystem is under strain due to increasing manuscript submissions and the\nlabor-intensive nature of the process. Recent advancements in large language\nmodels (LLMs) have led to their integration into peer review, with promising\nresults such as substantial overlaps between LLM- and human-generated reviews.\nHowever, the unchecked adoption of LLMs poses significant risks to the\nintegrity of the peer review system. In this study, we comprehensively analyze\nthe vulnerabilities of LLM-generated reviews by focusing on manipulation and\ninherent flaws. Our experiments show that injecting covert deliberate content\ninto manuscripts allows authors to explicitly manipulate LLM reviews, leading\nto inflated ratings and reduced alignment with human reviews. In a simulation,\nwe find that manipulating 5% of the reviews could potentially cause 12% of the\npapers to lose their position in the top 30% rankings. Implicit manipulation,\nwhere authors strategically highlight minor limitations in their papers,\nfurther demonstrates LLMs' susceptibility compared to human reviewers, with a\n4.5 times higher consistency with disclosed limitations. Additionally, LLMs\nexhibit inherent flaws, such as potentially assigning higher ratings to\nincomplete papers compared to full papers and favoring well-known authors in\nsingle-blind review process. These findings highlight the risks of\nover-reliance on LLMs in peer review, underscoring that we are not yet ready\nfor widespread adoption and emphasizing the need for robust safeguards.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01708v1",
    "published_date": "2024-12-02 16:55:03 UTC",
    "updated_date": "2024-12-02 16:55:03 UTC"
  },
  {
    "arxiv_id": "2412.01703v1",
    "title": "Deep Guess acceleration for explainable image reconstruction in sparse-view CT",
    "authors": [
      "Elena Loli Piccolomini",
      "Davide Evangelista",
      "Elena Morotti"
    ],
    "abstract": "Sparse-view Computed Tomography (CT) is an emerging protocol designed to\nreduce X-ray dose radiation in medical imaging. Traditional Filtered Back\nProjection algorithm reconstructions suffer from severe artifacts due to sparse\ndata. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,\nthough better at mitigating noise through regularization, are too\ncomputationally costly for clinical use. This paper introduces a novel\ntechnique, denoted as the Deep Guess acceleration scheme, using a trained\nneural network both to quicken the regularized MBIR and to enhance the\nreconstruction accuracy. We integrate state-of-the-art deep learning tools to\ninitialize a clever starting guess for a proximal algorithm solving a\nnon-convex model and thus computing an interpretable solution image in a few\niterations. Experimental results on real CT images demonstrate the Deep Guess\neffectiveness in (very) sparse tomographic protocols, where it overcomes its\nmere variational counterpart and many data-driven approaches at the state of\nthe art. We also consider a ground truth-free implementation and test the\nrobustness of the proposed framework to noise.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.CV",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01703v1",
    "published_date": "2024-12-02 16:49:42 UTC",
    "updated_date": "2024-12-02 16:49:42 UTC"
  },
  {
    "arxiv_id": "2412.01692v1",
    "title": "Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health",
    "authors": [
      "Liza Dahiya",
      "Rachit Bagga"
    ],
    "abstract": "Social media platforms, particularly Reddit's r/Epilepsy community, offer a\nunique perspective into the experiences of individuals with epilepsy (PWE) and\ntheir caregivers. This study analyzes 57k posts and 533k comments to explore\nkey themes across demographics such as age, gender, and relationships. Our\nfindings highlight significant discussions on epilepsy-related challenges,\nincluding depression (with 39.75\\% of posts indicating severe symptoms),\ndriving restrictions, workplace concerns, and pregnancy-related issues in women\nwith epilepsy. We introduce a novel engagement metric, F(P), which incorporates\npost length, sentiment scores, and readability to quantify community\ninteraction. This analysis underscores the importance of integrated care\naddressing both neurological and mental health challenges faced by PWE. The\ninsights from this study inform strategies for targeted support and awareness\ninterventions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01692v1",
    "published_date": "2024-12-02 16:35:25 UTC",
    "updated_date": "2024-12-02 16:35:25 UTC"
  },
  {
    "arxiv_id": "2412.01674v1",
    "title": "Causal Discovery by Interventions via Integer Programming",
    "authors": [
      "Abdelmonem Elrefaey",
      "Rong Pan"
    ],
    "abstract": "Causal discovery is essential across various scientific fields to uncover\ncausal structures within data. Traditional methods relying on observational\ndata have limitations due to confounding variables. This paper presents an\noptimization-based approach using integer programming (IP) to design minimal\nintervention sets that ensure causal structure identifiability. Our method\nprovides exact and modular solutions that can be adjusted to different\nexperimental settings and constraints. We demonstrate its effectiveness through\ncomparative analysis across different settings, demonstrating its applicability\nand robustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01674v1",
    "published_date": "2024-12-02 16:22:10 UTC",
    "updated_date": "2024-12-02 16:22:10 UTC"
  },
  {
    "arxiv_id": "2412.01661v1",
    "title": "R-Bot: An LLM-based Query Rewrite System",
    "authors": [
      "Zhaoyan Sun",
      "Xuanhe Zhou",
      "Guoliang Li"
    ],
    "abstract": "Query rewrite is essential for optimizing SQL queries to improve their\nexecution efficiency without changing their results. Traditionally, this task\nhas been tackled through heuristic and learning-based methods, each with its\nlimitations in terms of inferior quality and low robustness. Recent\nadvancements in LLMs offer a new paradigm by leveraging their superior natural\nlanguage and code comprehension abilities. Despite their potential, directly\napplying LLMs like GPT-4 has faced challenges due to problems such as\nhallucinations, where the model might generate inaccurate or irrelevant\nresults. To address this, we propose R-Bot, an LLM-based query rewrite system\nwith a systematic approach. We first design a multi-source rewrite evidence\npreparation pipeline to generate query rewrite evidences for guiding LLMs to\navoid hallucinations. We then propose a hybrid structure-semantics retrieval\nmethod that combines structural and semantic analysis to retrieve the most\nrelevant rewrite evidences for effectively answering an online query. We next\npropose a step-by-step LLM rewrite method that iteratively leverages the\nretrieved evidences to select and arrange rewrite rules with self-reflection.\nWe conduct comprehensive experiments on widely used benchmarks, and demonstrate\nthe superior performance of our system, R-Bot, surpassing state-of-the-art\nquery rewrite methods.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01661v1",
    "published_date": "2024-12-02 16:13:04 UTC",
    "updated_date": "2024-12-02 16:13:04 UTC"
  },
  {
    "arxiv_id": "2412.01657v1",
    "title": "PassionNet: An Innovative Framework for Duplicate and Conflicting Requirements Identification",
    "authors": [
      "Summra Saleem",
      "Muhammad Nabeel Asim",
      "Andreas Dengel"
    ],
    "abstract": "Early detection and resolution of duplicate and conflicting requirements can\nsignificantly enhance project efficiency and overall software quality.\nResearchers have developed various computational predictors by leveraging\nArtificial Intelligence (AI) potential to detect duplicate and conflicting\nrequirements. However, these predictors lack in performance and requires more\neffective approaches to empower software development processes. Following the\nneed of a unique predictor that can accurately identify duplicate and\nconflicting requirements, this research offers a comprehensive framework that\nfacilitate development of 3 different types of predictive pipelines: language\nmodels based, multi-model similarity knowledge-driven and large language models\n(LLMs) context + multi-model similarity knowledge-driven. Within first type\npredictive pipelines landscape, framework facilitates conflicting/duplicate\nrequirements identification by leveraging 8 distinct types of LLMs. In second\ntype, framework supports development of predictive pipelines that leverage\nmulti-scale and multi-model similarity knowledge, ranging from traditional\nsimilarity computation methods to advanced similarity vectors generated by\nLLMs. In the third type, the framework synthesizes predictive pipelines by\nintegrating contextual insights from LLMs with multi-model similarity\nknowledge. Across 6 public benchmark datasets, extensive testing of 760\ndistinct predictive pipelines demonstrates that hybrid predictive pipelines\nconsistently outperforms other two types predictive pipelines in accurately\nidentifying duplicate and conflicting requirements. This predictive pipeline\noutperformed existing state-of-the-art predictors performance with an overall\nperformance margin of 13% in terms of F1-score",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01657v1",
    "published_date": "2024-12-02 16:05:38 UTC",
    "updated_date": "2024-12-02 16:05:38 UTC"
  },
  {
    "arxiv_id": "2412.01655v1",
    "title": "Command-line Risk Classification using Transformer-based Neural Architectures",
    "authors": [
      "Paolo Notaro",
      "Soroush Haeri",
      "Jorge Cardoso",
      "Michael Gerndt"
    ],
    "abstract": "To protect large-scale computing environments necessary to meet increasing\ncomputing demand, cloud providers have implemented security measures to monitor\nOperations and Maintenance (O&M) activities and therefore prevent data loss and\nservice interruption. Command interception systems are used to intercept,\nassess, and block dangerous Command-line Interface (CLI) commands before they\ncan cause damage. Traditional solutions for command risk assessment include\nrule-based systems, which require expert knowledge and constant human revision\nto account for unseen commands. To overcome these limitations, several\nend-to-end learning systems have been proposed to classify CLI commands. These\nsystems, however, have several other limitations, including the adoption of\ngeneral-purpose text classifiers, which may not adapt to the language\ncharacteristics of scripting languages such as Bash or PowerShell, and may not\nrecognize dangerous commands in the presence of an unbalanced class\ndistribution. In this paper, we propose a transformer-based command risk\nclassification system, which leverages the generalization power of Large\nLanguage Models (LLM) to provide accurate classification and the ability to\nidentify rare dangerous commands effectively, by exploiting the power of\ntransfer learning. We verify the effectiveness of our approach on a realistic\ndataset of production commands and show how to apply our model for other\nsecurity-related tasks, such as dangerous command interception and auditing of\nexisting rule-based systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01655v1",
    "published_date": "2024-12-02 16:04:31 UTC",
    "updated_date": "2024-12-02 16:04:31 UTC"
  },
  {
    "arxiv_id": "2412.01650v2",
    "title": "Privacy-Preserving Federated Learning via Homomorphic Adversarial Networks",
    "authors": [
      "Wenhan Dong",
      "Chao Lin",
      "Xinlei He",
      "Xinyi Huang",
      "Shengmin Xu"
    ],
    "abstract": "Privacy-preserving federated learning (PPFL) aims to train a global model for\nmultiple clients while maintaining their data privacy. However, current PPFL\nprotocols exhibit one or more of the following insufficiencies: considerable\ndegradation in accuracy, the requirement for sharing keys, and cooperation\nduring the key generation or decryption processes. As a mitigation, we develop\nthe first protocol that utilizes neural networks to implement PPFL, as well as\nincorporating an Aggregatable Hybrid Encryption scheme tailored to the needs of\nPPFL. We name these networks as Homomorphic Adversarial Networks (HANs) which\ndemonstrate that neural networks are capable of performing tasks similar to\nmulti-key homomorphic encryption (MK-HE) while solving the problems of key\ndistribution and collaborative decryption. Our experiments show that HANs are\nrobust against privacy attacks. Compared with non-private federated learning,\nexperiments conducted on multiple datasets demonstrate that HANs exhibit a\nnegligible accuracy loss (at most 1.35%). Compared to traditional MK-HE\nschemes, HANs increase encryption aggregation speed by 6,075 times while\nincurring a 29.2 times increase in communication overhead.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01650v2",
    "published_date": "2024-12-02 15:59:35 UTC",
    "updated_date": "2024-12-03 05:46:35 UTC"
  },
  {
    "arxiv_id": "2412.01644v2",
    "title": "Concept Based Continuous Prompts for Interpretable Text Classification",
    "authors": [
      "Qian Chen",
      "Dongyang Li",
      "Xiaofeng He"
    ],
    "abstract": "Continuous prompts have become widely adopted for augmenting performance\nacross a wide range of natural language tasks. However, the underlying\nmechanism of this enhancement remains obscure. Previous studies rely on\nindividual words for interpreting continuous prompts, which lacks comprehensive\nsemantic understanding. Drawing inspiration from Concept Bottleneck Models, we\npropose a framework for interpreting continuous prompts by decomposing them\ninto human-readable concepts. Specifically, to ensure the feasibility of the\ndecomposition, we demonstrate that a corresponding concept embedding matrix and\na coefficient matrix can always be found to replace the prompt embedding\nmatrix. Then, we employ GPT-4o to generate a concept pool and choose potential\ncandidate concepts that are discriminative and representative using a novel\nsubmodular optimization algorithm. Experiments demonstrate that our framework\ncan achieve similar results as the original P-tuning and word-based approaches\nusing only a few concepts while providing more plausible results. Our code is\navailable at https://github.com/qq31415926/CD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01644v2",
    "published_date": "2024-12-02 15:56:08 UTC",
    "updated_date": "2024-12-05 06:49:37 UTC"
  },
  {
    "arxiv_id": "2412.01621v3",
    "title": "NYT-Connections: A Deceptively Simple Text Classification Task that Stumps System-1 Thinkers",
    "authors": [
      "Angel Yahir Loredo Lopez",
      "Tyler McDonald",
      "Ali Emami"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive performance on various\nbenchmarks, yet their ability to engage in deliberate reasoning remains\nquestionable. We present NYT-Connections, a collection of 358 simple word\nclassification puzzles derived from the New York Times Connections game. This\nbenchmark is designed to penalize quick, intuitive \"System 1\" thinking,\nisolating fundamental reasoning skills. We evaluated six recent LLMs, a simple\nmachine learning heuristic, and humans across three configurations:\nsingle-attempt, multiple attempts without hints, and multiple attempts with\ncontextual hints. Our findings reveal a significant performance gap: even\ntop-performing LLMs like GPT-4 fall short of human performance by nearly 30%.\nNotably, advanced prompting techniques such as Chain-of-Thought and\nSelf-Consistency show diminishing returns as task difficulty increases.\nNYT-Connections uniquely combines linguistic isolation, resistance to intuitive\nshortcuts, and regular updates to mitigate data leakage, offering a novel tool\nfor assessing LLM reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages (excluding references), Published at Coling 2025, Best\n  Dataset Paper Award",
    "pdf_url": "http://arxiv.org/pdf/2412.01621v3",
    "published_date": "2024-12-02 15:41:47 UTC",
    "updated_date": "2025-02-25 12:59:42 UTC"
  },
  {
    "arxiv_id": "2412.01617v1",
    "title": "If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM World",
    "authors": [
      "Adrian de Wynter"
    ],
    "abstract": "Loneliness, or the lack of fulfilling relationships, significantly impacts a\nperson's mental and physical well-being and is prevalent worldwide. Previous\nresearch suggests that large language models (LLMs) may help mitigate\nloneliness. However, we argue that the use of widespread LLMs like ChatGPT is\nmore prevalent--and riskier, as they are not designed for this purpose. To\nexplore this, we analysed user interactions with ChatGPT, particularly those\noutside of its marketed use as task-oriented assistant. In dialogues classified\nas lonely, users frequently (37%) sought advice or validation, and received\ngood engagement. However, ChatGPT failed in sensitive scenarios, like\nresponding appropriately to suicidal ideation or trauma. We also observed a 35%\nhigher incidence of toxic content, with women being 22 times more likely to be\ntargeted than men. Our findings underscore ethical and legal questions about\nthis technology, and note risks like radicalisation or further isolation. We\nconclude with recommendations for research and industry to address loneliness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01617v1",
    "published_date": "2024-12-02 15:39:00 UTC",
    "updated_date": "2024-12-02 15:39:00 UTC"
  },
  {
    "arxiv_id": "2412.01609v1",
    "title": "Optimizing LoRa for Edge Computing with TinyML Pipeline for Channel Hopping",
    "authors": [
      "Marla Grunewald",
      "Mounir Bensalem",
      "Admela Jukan"
    ],
    "abstract": "We propose to integrate long-distance LongRange (LoRa) communication solution\nfor sending the data from IoT to the edge computing system, by taking advantage\nof its unlicensed nature and the potential for open source implementations that\nare common in edge computing. We propose a channel hoping optimization model\nand apply TinyML-based channel hoping model based for LoRa transmissions, as\nwell as experimentally study a fast predictive algorithm to find free channels\nbetween edge and IoT devices. In the open source experimental setup that\nincludes LoRa, TinyML and IoT-edge-cloud continuum, we integrate a novel\napplication workflow and cloud-friendly protocol solutions in a case study of\nplant recommender application that combines concepts of microfarming and urban\ncomputing. In a LoRa-optimized edge computing setup, we engineer the\napplication workflow, and apply collaborative filtering and various machine\nlearning algorithms on application data collected to identify and recommend the\nplanting schedule for a specific microfarm in an urban area. In the LoRa\nexperiments, we measure the occurrence of packet loss, RSSI, and SNR, using a\nrandom channel hoping scheme to compare with our proposed TinyML method. The\nresults show that it is feasible to use TinyML in microcontrollers for channel\nhopping, while proving the effectiveness of TinyML in learning to predict the\nbest channel to select for LoRa transmission, and by improving the RSSI by up\nto 63 %, SNR by up to 44 % in comparison with a random hopping mechanism.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.DM",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.NI",
    "comment": "This paper is uploaded here for research community, thus it is for\n  non-commercial purposes",
    "pdf_url": "http://arxiv.org/pdf/2412.01609v1",
    "published_date": "2024-12-02 15:28:44 UTC",
    "updated_date": "2024-12-02 15:28:44 UTC"
  },
  {
    "arxiv_id": "2412.01605v1",
    "title": "Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking",
    "authors": [
      "Jie Liu",
      "Wenxuan Wang",
      "Zizhan Ma",
      "Guolin Huang",
      "Yihang SU",
      "Kao-Jung Chang",
      "Wenting Chen",
      "Haoliang Li",
      "Linlin Shen",
      "Michael Lyu"
    ],
    "abstract": "Clinical decision making (CDM) is a complex, dynamic process crucial to\nhealthcare delivery, yet it remains a significant challenge for artificial\nintelligence systems. While Large Language Model (LLM)-based agents have been\ntested on general medical knowledge using licensing exams and knowledge\nquestion-answering tasks, their performance in the CDM in real-world scenarios\nis limited due to the lack of comprehensive testing datasets that mirror actual\nmedical practice. To address this gap, we present MedChain, a dataset of 12,163\nclinical cases that covers five key stages of clinical workflow. MedChain\ndistinguishes itself from existing benchmarks with three key features of\nreal-world clinical practice: personalization, interactivity, and\nsequentiality. Further, to tackle real-world CDM challenges, we also propose\nMedChain-Agent, an AI system that integrates a feedback mechanism and a\nMCase-RAG module to learn from previous cases and adapt its responses.\nMedChain-Agent demonstrates remarkable adaptability in gathering information\ndynamically and handling sequential clinical tasks, significantly outperforming\nexisting approaches. The relevant dataset and code will be released upon\nacceptance of this paper.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01605v1",
    "published_date": "2024-12-02 15:25:02 UTC",
    "updated_date": "2024-12-02 15:25:02 UTC"
  },
  {
    "arxiv_id": "2412.01604v2",
    "title": "Agentic-HLS: An agentic reasoning based high-level synthesis system using large language models (AI for EDA workshop 2024)",
    "authors": [
      "Ali Emre Oztas",
      "Mahdi Jelodari"
    ],
    "abstract": "Our aim for the ML Contest for Chip Design with HLS 2024 was to predict the\nvalidity, running latency in the form of cycle counts, utilization rate of BRAM\n(util-BRAM), utilization rate of lookup tables (uti-LUT), utilization rate of\nflip flops (util-FF), and the utilization rate of digital signal processors\n(util-DSP). We used Chain-of-thought techniques with large language models to\nperform classification and regression tasks. Our prediction is that with larger\nmodels reasoning was much improved. We release our prompts and propose a HLS\nbenchmarking task for LLMs.",
    "categories": [
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.AI",
    "comment": "AI4EDA co-located with 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.01604v2",
    "published_date": "2024-12-02 15:24:08 UTC",
    "updated_date": "2024-12-14 00:24:30 UTC"
  },
  {
    "arxiv_id": "2412.01590v1",
    "title": "NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision",
    "authors": [
      "Sandesh Pokhrel",
      "Sanjay Bhandari",
      "Sharib Ali",
      "Tryphon Lambrou",
      "Anh Nguyen",
      "Yash Raj Shrestha",
      "Angus Watson",
      "Danail Stoyanov",
      "Prashnna Gyawali",
      "Binod Bhattarai"
    ],
    "abstract": "The integration of deep learning tools in gastrointestinal vision holds the\npotential for significant advancements in diagnosis, treatment, and overall\npatient care. A major challenge, however, is these tools' tendency to make\noverconfident predictions, even when encountering unseen or newly emerging\ndisease patterns, undermining their reliability.\n  We address this critical issue of reliability by framing it as an\nout-of-distribution (OOD) detection problem, where previously unseen and\nemerging diseases are identified as OOD examples. However, gastrointestinal\nimages pose a unique challenge due to the overlapping feature representations\nbetween in- Distribution (ID) and OOD examples. Existing approaches often\noverlook this characteristic, as they are primarily developed for natural image\ndatasets, where feature distinctions are more apparent. Despite the overlap, we\nhypothesize that the features of an in-distribution example will cluster closer\nto the centroids of their ground truth class, resulting in a shorter distance\nto the nearest centroid. In contrast, OOD examples maintain an equal distance\nfrom all class centroids. Based on this observation, we propose a novel\nnearest-centroid distance deficit (NCCD) score in the feature space for\ngastrointestinal OOD detection.\n  Evaluations across multiple deep learning architectures and two publicly\navailable benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness\nof our approach compared to several state-of-the-art methods. The code and\nimplementation details are publicly available at:\nhttps://github.com/bhattarailab/NCDD",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01590v1",
    "published_date": "2024-12-02 15:07:55 UTC",
    "updated_date": "2024-12-02 15:07:55 UTC"
  },
  {
    "arxiv_id": "2412.01587v1",
    "title": "Handwriting-based Automated Assessment and Grading of Degree of Handedness: A Pilot Study",
    "authors": [
      "Smriti Bala",
      "Venugopalan Y. Vishnu",
      "Deepak Joshi"
    ],
    "abstract": "Hand preference and degree of handedness (DoH) are two different aspects of\nhuman behavior which are often confused to be one. DoH is a person's inherent\ncapability of the brain; affected by nature and nurture. In this study, we used\ndominant and non-dominant handwriting traits to assess DoH for the first time,\non 43 subjects of three categories- Unidextrous, Partially Unidextrous, and\nAmbidextrous. Features extracted from the segmented handwriting signals called\nstrokes were used for DoH quantification. Davies Bouldin Index, Multilayer\nperceptron, and Convolutional Neural Network (CNN) were used for automated\ngrading of DoH. The outcomes of these methods were compared with the widely\nused DoH assessment questionnaires from Edinburgh Inventory (EI). The CNN based\nautomated grading outperformed other computational methods with an average\nclassification accuracy of 95.06% under stratified 10-fold cross-validation.\nThe leave-one-subject-out strategy on this CNN resulted in a test individual's\nDoH score which was converted into a 4-point score. Around 90% of the obtained\nscores from all the implemented computational methods were found to be in\naccordance with the EI scores under 95% confidence interval. Automated grading\nof degree of handedness using handwriting signals can provide more resolution\nto the Edinburgh Inventory scores. This could be used in multiple applications\nconcerned with neuroscience, rehabilitation, physiology, psychometry,\nbehavioral sciences, and forensics.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01587v1",
    "published_date": "2024-12-02 15:06:18 UTC",
    "updated_date": "2024-12-02 15:06:18 UTC"
  },
  {
    "arxiv_id": "2412.01572v4",
    "title": "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity",
    "authors": [
      "Xiaqiang Tang",
      "Qiang Gao",
      "Jian Li",
      "Nan Du",
      "Qi Li",
      "Sihong Xie"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has proven to be highly effective in\nboosting the generative performance of language model in knowledge-intensive\ntasks. However, existing RAG framework either indiscriminately perform\nretrieval or rely on rigid single-class classifiers to select retrieval\nmethods, leading to inefficiencies and suboptimal performance across queries of\nvarying complexity. To address these challenges, we propose a reinforcement\nlearning-based framework that dynamically selects the most suitable retrieval\nstrategy based on query complexity. % our solution Our approach leverages a\nmulti-armed bandit algorithm, which treats each retrieval method as a distinct\n``arm'' and adapts the selection process by balancing exploration and\nexploitation. Additionally, we introduce a dynamic reward function that\nbalances accuracy and efficiency, penalizing methods that require more\nretrieval steps, even if they lead to a correct result. Our method achieves new\nstate of the art results on multiple single-hop and multi-hop datasets while\nreducing retrieval costs. Our code are available at\nhttps://github.com/FUTUREEEEEE/MBA .",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01572v4",
    "published_date": "2024-12-02 14:55:02 UTC",
    "updated_date": "2025-01-01 08:52:20 UTC"
  },
  {
    "arxiv_id": "2412.01558v1",
    "title": "VideoLights: Feature Refinement and Cross-Task Alignment Transformer for Joint Video Highlight Detection and Moment Retrieval",
    "authors": [
      "Dhiman Paul",
      "Md Rizwan Parvez",
      "Nabeel Mohammed",
      "Shafin Rahman"
    ],
    "abstract": "Video Highlight Detection and Moment Retrieval (HD/MR) are essential in video\nanalysis. Recent joint prediction transformer models often overlook their\ncross-task dynamics and video-text alignment and refinement. Moreover, most\nmodels typically use limited, uni-directional attention mechanisms, resulting\nin weakly integrated representations and suboptimal performance in capturing\nthe interdependence between video and text modalities. Although large-language\nand vision-language models (LLM/LVLMs) have gained prominence across various\ndomains, their application in this field remains relatively underexplored. Here\nwe propose VideoLights, a novel HD/MR framework addressing these limitations\nthrough (i) Convolutional Projection and Feature Refinement modules with an\nalignment loss for better video-text feature alignment, (ii) Bi-Directional\nCross-Modal Fusion network for strongly coupled query-aware clip\nrepresentations, and (iii) Uni-directional joint-task feedback mechanism\nenhancing both tasks through correlation. In addition, (iv) we introduce hard\npositive/negative losses for adaptive error penalization and improved learning,\nand (v) leverage LVLMs like BLIP-2 for enhanced multimodal feature integration\nand intelligent pretraining using synthetic data generated from LVLMs.\nComprehensive experiments on QVHighlights, TVSum, and Charades-STA benchmarks\ndemonstrate state-of-the-art performance. Codes and models are available at\nhttps://github.com/dpaul06/VideoLights .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.10; I.2.7"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01558v1",
    "published_date": "2024-12-02 14:45:53 UTC",
    "updated_date": "2024-12-02 14:45:53 UTC"
  },
  {
    "arxiv_id": "2412.01550v3",
    "title": "SeqAfford: Sequential 3D Affordance Reasoning via Multimodal Large Language Model",
    "authors": [
      "Chunlin Yu",
      "Hanqing Wang",
      "Ye Shi",
      "Haoyang Luo",
      "Sibei Yang",
      "Jingyi Yu",
      "Jingya Wang"
    ],
    "abstract": "3D affordance segmentation aims to link human instructions to touchable\nregions of 3D objects for embodied manipulations. Existing efforts typically\nadhere to single-object, single-affordance paradigms, where each affordance\ntype or explicit instruction strictly corresponds to a specific affordance\nregion and are unable to handle long-horizon tasks. Such a paradigm cannot\nactively reason about complex user intentions that often imply sequential\naffordances. In this paper, we introduce the Sequential 3D Affordance Reasoning\ntask, which extends the traditional paradigm by reasoning from cumbersome user\nintentions and then decomposing them into a series of segmentation maps. Toward\nthis, we construct the first instruction-based affordance segmentation\nbenchmark that includes reasoning over both single and sequential affordances,\ncomprising 180K instruction-point cloud pairs. Based on the benchmark, we\npropose our model, SeqAfford, to unlock the 3D multi-modal large language model\nwith additional affordance segmentation abilities, which ensures reasoning with\nworld knowledge and fine-grained affordance grounding in a cohesive framework.\nWe further introduce a multi-granular language-point integration module to\nendow 3D dense prediction. Extensive experimental evaluations show that our\nmodel excels over well-established methods and exhibits open-world\ngeneralization with sequential reasoning abilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01550v3",
    "published_date": "2024-12-02 14:37:57 UTC",
    "updated_date": "2025-03-21 04:31:01 UTC"
  },
  {
    "arxiv_id": "2412.01547v1",
    "title": "Improved Large Language Model Jailbreak Detection via Pretrained Embeddings",
    "authors": [
      "Erick Galinkin",
      "Martin Sablotny"
    ],
    "abstract": "The adoption of large language models (LLMs) in many applications, from\ncustomer service chat bots and software development assistants to more capable\nagentic systems necessitates research into how to secure these systems. Attacks\nlike prompt injection and jailbreaking attempt to elicit responses and actions\nfrom these models that are not compliant with the safety, privacy, or content\npolicies of organizations using the model in their application. In order to\ncounter abuse of LLMs for generating potentially harmful replies or taking\nundesirable actions, LLM owners must apply safeguards during training and\nintegrate additional tools to block the LLM from generating text that abuses\nthe model. Jailbreaking prompts play a vital role in convincing an LLM to\ngenerate potentially harmful content, making it important to identify\njailbreaking attempts to block any further steps. In this work, we propose a\nnovel approach to detect jailbreak prompts based on pairing text embeddings\nwell-suited for retrieval with traditional machine learning classification\nalgorithms. Our approach outperforms all publicly available methods from open\nsource LLM security applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to AICS 2025: https://aics.site",
    "pdf_url": "http://arxiv.org/pdf/2412.01547v1",
    "published_date": "2024-12-02 14:35:43 UTC",
    "updated_date": "2024-12-02 14:35:43 UTC"
  },
  {
    "arxiv_id": "2412.01542v1",
    "title": "Towards Type Agnostic Cyber Defense Agents",
    "authors": [
      "Erick Galinkin",
      "Emmanouil Pountrourakis",
      "Spiros Mancoridis"
    ],
    "abstract": "With computing now ubiquitous across government, industry, and education,\ncybersecurity has become a critical component for every organization on the\nplanet. Due to this ubiquity of computing, cyber threats have continued to grow\nyear over year, leading to labor shortages and a skills gap in cybersecurity.\nAs a result, many cybersecurity product vendors and security organizations have\nlooked to artificial intelligence to shore up their defenses. This work\nconsiders how to characterize attackers and defenders in one approach to the\nautomation of cyber defense -- the application of reinforcement learning.\nSpecifically, we characterize the types of attackers and defenders in the sense\nof Bayesian games and, using reinforcement learning, derive empirical findings\nabout how to best train agents that defend against multiple types of attackers.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to AICS 2025: https://aics.site",
    "pdf_url": "http://arxiv.org/pdf/2412.01542v1",
    "published_date": "2024-12-02 14:32:18 UTC",
    "updated_date": "2024-12-02 14:32:18 UTC"
  },
  {
    "arxiv_id": "2412.01541v1",
    "title": "Effectiveness of L2 Regularization in Privacy-Preserving Machine Learning",
    "authors": [
      "Nikolaos Chandrinos",
      "Iliana Loi",
      "Panagiotis Zachos",
      "Ioannis Symeonidis",
      "Aristotelis Spiliotis",
      "Maria Panou",
      "Konstantinos Moustakas"
    ],
    "abstract": "Artificial intelligence, machine learning, and deep learning as a service\nhave become the status quo for many industries, leading to the widespread\ndeployment of models that handle sensitive data. Well-performing models, the\nindustry seeks, usually rely on a large volume of training data. However, the\nuse of such data raises serious privacy concerns due to the potential risks of\nleaks of highly sensitive information. One prominent threat is the Membership\nInference Attack, where adversaries attempt to deduce whether a specific data\npoint was used in a model's training process. An adversary's ability to\ndetermine an individual's presence represents a significant privacy threat,\nespecially when related to a group of users sharing sensitive information.\nHence, well-designed privacy-preserving machine learning solutions are\ncritically needed in the industry. In this work, we compare the effectiveness\nof L2 regularization and differential privacy in mitigating Membership\nInference Attack risks. Even though regularization techniques like L2\nregularization are commonly employed to reduce overfitting, a condition that\nenhances the effectiveness of Membership Inference Attacks, their impact on\nmitigating these attacks has not been systematically explored.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01541v1",
    "published_date": "2024-12-02 14:31:11 UTC",
    "updated_date": "2024-12-02 14:31:11 UTC"
  },
  {
    "arxiv_id": "2412.01528v1",
    "title": "CopyrightShield: Spatial Similarity Guided Backdoor Defense against Copyright Infringement in Diffusion Models",
    "authors": [
      "Zhixiang Guo",
      "Siyuan Liang",
      "Aishan Liu",
      "Dacheng Tao"
    ],
    "abstract": "The diffusion model has gained significant attention due to its remarkable\ndata generation ability in fields such as image synthesis. However, its strong\nmemorization and replication abilities with respect to the training data also\nmake it a prime target for copyright infringement attacks. This paper provides\nan in-depth analysis of the spatial similarity of replication in diffusion\nmodel and leverages this key characteristic to design a method for detecting\npoisoning data. By employing a joint assessment of spatial-level and\nfeature-level information from the detected segments, we effectively identify\ncovertly dispersed poisoned samples. Building upon detected poisoning data, we\npropose a novel defense method specifically targeting copyright infringement\nattacks by introducing a protection constraint term into the loss function to\nmitigate the impact of poisoning. Extensive experimental results demonstrate\nthat our approach achieves an average F1 score of 0.709 in detecting copyright\ninfringement backdoors, resulting in an average increase of 68.1% in\nFirst-Attack Epoch (FAE) and an average decrease of 51.4% in Copyright\nInfringement Rate (CIR) of the poisoned model, effectively defending against\ncopyright infringement. Additionally, we introduce the concept of copyright\nfeature inversion, which aids in determining copyright responsibility and\nexpands the application scenarios of defense strategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01528v1",
    "published_date": "2024-12-02 14:19:44 UTC",
    "updated_date": "2024-12-02 14:19:44 UTC"
  },
  {
    "arxiv_id": "2412.01526v1",
    "title": "Addressing Data Leakage in HumanEval Using Combinatorial Test Design",
    "authors": [
      "Jeremy S. Bradbury",
      "Riddhi More"
    ],
    "abstract": "The use of large language models (LLMs) is widespread across many domains,\nincluding Software Engineering, where they have been used to automate tasks\nsuch as program generation and test classification. As LLM-based methods\ncontinue to evolve, it is important that we define clear and robust methods\nthat fairly evaluate performance. Benchmarks are a common approach to assess\nLLMs with respect to their ability to solve problem-specific tasks as well as\nassess different versions of an LLM to solve tasks over time. For example, the\nHumanEval benchmark is composed of 164 hand-crafted tasks and has become an\nimportant tool in assessing LLM-based program generation. However, a major\nbarrier to a fair evaluation of LLMs using benchmarks like HumanEval is data\ncontamination resulting from data leakage of benchmark tasks and solutions into\nthe training data set. This barrier is compounded by the black-box nature of\nLLM training data which makes it difficult to even know if data leakage has\noccurred. To address the data leakage problem, we propose a new benchmark\nconstruction method where a benchmark is composed of template tasks that can be\ninstantiated into new concrete tasks using combinatorial test design. Concrete\ntasks for the same template task must be different enough that data leakage has\nminimal impact and similar enough that the tasks are interchangeable with\nrespect to performance evaluation. To assess our benchmark construction method,\nwe propose HumanEval_T, an alternative benchmark to HumanEval that was\nconstructed using template tasks and combinatorial test design.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "I.2.7; D.2.5; I.2.2"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01526v1",
    "published_date": "2024-12-02 14:18:32 UTC",
    "updated_date": "2024-12-02 14:18:32 UTC"
  },
  {
    "arxiv_id": "2412.12116v1",
    "title": "AI in Education: Rationale, Principles, and Instructional Implications",
    "authors": [
      "Eyvind Elstad"
    ],
    "abstract": "This study examines the integration of generative AI in schools, assessing\nits benefits and risks. As AI use by students grows, it's crucial to understand\nits impact on learning and teaching practices. Generative AI, like ChatGPT, can\ncreate human-like content, prompting questions about its educational role. The\narticle differentiates large language models from traditional search engines\nand stresses the need for students to develop critical source evaluation\nskills. Although empirical evidence on AI's classroom effects is limited, AI\noffers personalized learning support and problem-solving tools, alongside\nchallenges like undermining deep learning if misused. The study emphasizes\ndeliberate strategies to ensure AI complements, not replaces, genuine cognitive\neffort. AI's educational role should be context-dependent, guided by\npedagogical goals. The study concludes with practical advice for teachers on\neffectively utilizing AI to promote understanding and critical engagement,\nadvocating for a balanced approach to enhance students' knowledge and skills\ndevelopment.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "24 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.12116v1",
    "published_date": "2024-12-02 14:08:07 UTC",
    "updated_date": "2024-12-02 14:08:07 UTC"
  },
  {
    "arxiv_id": "2412.01512v1",
    "title": "ArtBrain: An Explainable end-to-end Toolkit for Classification and Attribution of AI-Generated Art and Style",
    "authors": [
      "Ravidu Suien Rammuni Silva",
      "Ahmad Lotfi",
      "Isibor Kennedy Ihianle",
      "Golnaz Shahtahmassebi",
      "Jordan J. Bird"
    ],
    "abstract": "Recently, the quality of artworks generated using Artificial Intelligence\n(AI) has increased significantly, resulting in growing difficulties in\ndetecting synthetic artworks. However, limited studies have been conducted on\nidentifying the authenticity of synthetic artworks and their source. This paper\nintroduces AI-ArtBench, a dataset featuring 185,015 artistic images across 10\nart styles. It includes 125,015 AI-generated images and 60,000 pieces of\nhuman-created artwork. This paper also outlines a method to accurately detect\nAI-generated images and trace them to their source model. This work proposes a\nnovel Convolutional Neural Network model based on the ConvNeXt model called\nAttentionConvNeXt. AttentionConvNeXt was implemented and trained to\ndifferentiate between the source of the artwork and its style with an F1-Score\nof 0.869. The accuracy of attribution to the generative model reaches 0.999. To\ncombine the scientific contributions arising from this study, a web-based\napplication named ArtBrain was developed to enable both technical and\nnon-technical users to interact with the model. Finally, this study presents\nthe results of an Artistic Turing Test conducted with 50 participants. The\nfindings reveal that humans could identify AI-generated images with an accuracy\nof approximately 58%, while the model itself achieved a significantly higher\naccuracy of around 99%.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01512v1",
    "published_date": "2024-12-02 14:03:50 UTC",
    "updated_date": "2024-12-02 14:03:50 UTC"
  },
  {
    "arxiv_id": "2412.01495v1",
    "title": "Adversarial Attacks on Hyperbolic Networks",
    "authors": [
      "Max van Spengler",
      "Jan Zahálka",
      "Pascal Mettes"
    ],
    "abstract": "As hyperbolic deep learning grows in popularity, so does the need for\nadversarial robustness in the context of such a non-Euclidean geometry. To this\nend, this paper proposes hyperbolic alternatives to the commonly used FGM and\nPGD adversarial attacks. Through interpretable synthetic benchmarks and\nexperiments on existing datasets, we show how the existing and newly proposed\nattacks differ. Moreover, we investigate the differences in adversarial\nrobustness between Euclidean and fully hyperbolic networks. We find that these\nnetworks suffer from different types of vulnerabilities and that the newly\nproposed hyperbolic attacks cannot address these differences. Therefore, we\nconclude that the shifts in adversarial robustness are due to the models\nlearning distinct patterns resulting from their different geometries.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01495v1",
    "published_date": "2024-12-02 13:48:41 UTC",
    "updated_date": "2024-12-02 13:48:41 UTC"
  },
  {
    "arxiv_id": "2412.01491v2",
    "title": "Understanding complex crowd dynamics with generative neural simulators",
    "authors": [
      "Koen Minartz",
      "Fleur Hendriks",
      "Simon Martinus Koop",
      "Alessandro Corbetta",
      "Vlado Menkovski"
    ],
    "abstract": "Understanding the dynamics of pedestrian crowds is an outstanding challenge\ncrucial for designing efficient urban infrastructure and ensuring safe crowd\nmanagement. To this end, both small-scale laboratory and large-scale real-world\nmeasurements have been used. However, these approaches respectively lack\nstatistical resolution and parametric controllability, both essential to\ndiscovering physical relationships underlying the complex stochastic dynamics\nof crowds. Here, we establish an investigation paradigm that offers\nlaboratory-like controllability, while ensuring the statistical resolution of\nlarge-scale real-world datasets. Using our data-driven Neural Crowd Simulator\n(NeCS), which we train on large-scale data and validate against key statistical\nfeatures of crowd dynamics, we show that we can perform effective surrogate\ncrowd dynamics experiments without training on specific scenarios. We not only\nreproduce known experimental results on pairwise avoidance, but also uncover\nthe vision-guided and topological nature of N-body interactions. These findings\nshow how virtual experiments based on neural simulation enable data-driven\nscientific discovery.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.LG",
      "physics.data-an"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "26 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01491v2",
    "published_date": "2024-12-02 13:42:36 UTC",
    "updated_date": "2024-12-03 16:01:54 UTC"
  },
  {
    "arxiv_id": "2412.01490v4",
    "title": "Intelligent Spark Agents: A Modular LangGraph Framework for Scalable, Visualized, and Enhanced Big Data Machine Learning Workflows",
    "authors": [
      "Jialin Wang",
      "Zhihua Duan"
    ],
    "abstract": "This paper presents a Spark-based modular LangGraph framework, designed to\nenhance machine learning workflows through scalability, visualization, and\nintelligent process optimization. At its core, the framework introduces Agent\nAI, a pivotal innovation that leverages Spark's distributed computing\ncapabilities and integrates with LangGraph for workflow orchestration.\n  Agent AI facilitates the automation of data preprocessing, feature\nengineering, and model evaluation while dynamically interacting with data\nthrough Spark SQL and DataFrame agents. Through LangGraph's graph-structured\nworkflows, the agents execute complex tasks, adapt to new inputs, and provide\nreal-time feedback, ensuring seamless decision-making and execution in\ndistributed environments. This system simplifies machine learning processes by\nallowing users to visually design workflows, which are then converted into\nSpark-compatible code for high-performance execution.\n  The framework also incorporates large language models through the LangChain\necosystem, enhancing interaction with unstructured data and enabling advanced\ndata analysis. Experimental evaluations demonstrate significant improvements in\nprocess efficiency and scalability, as well as accurate data-driven\ndecision-making in diverse application scenarios.\n  This paper emphasizes the integration of Spark with intelligent agents and\ngraph-based workflows to redefine the development and execution of machine\nlearning tasks in big data environments, paving the way for scalable and\nuser-friendly AI solutions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01490v4",
    "published_date": "2024-12-02 13:41:38 UTC",
    "updated_date": "2024-12-06 13:21:40 UTC"
  },
  {
    "arxiv_id": "2412.01487v4",
    "title": "FastRM: An efficient and automatic explainability framework for multimodal generative models",
    "authors": [
      "Gabriela Ben-Melech Stan",
      "Estelle Aflalo",
      "Man Luo",
      "Shachar Rosenman",
      "Tiep Le",
      "Sayak Paul",
      "Shao-Yen Tseng",
      "Vasudev Lal"
    ],
    "abstract": "Large Vision Language Models (LVLMs) have demonstrated remarkable reasoning\ncapabilities over textual and visual inputs. However, these models remain prone\nto generating misinformation. Identifying and mitigating ungrounded responses\nis crucial for developing trustworthy AI. Traditional explainability methods\nsuch as gradient-based relevancy maps, offer insight into the decision process\nof models, but are often computationally expensive and unsuitable for real-time\noutput validation. In this work, we introduce FastRM, an efficient method for\npredicting explainable Relevancy Maps of LVLMs. Furthermore, FastRM provides\nboth quantitative and qualitative assessment of model confidence. Experimental\nresults demonstrate that FastRM achieves a 99.8% reduction in computation time\nand a 44.4% reduction in memory footprint compared to traditional relevancy map\ngeneration. FastRM allows explainable AI to be more practical and scalable,\nthereby promoting its deployment in real-world applications and enabling users\nto more effectively evaluate the reliability of model outputs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01487v4",
    "published_date": "2024-12-02 13:39:29 UTC",
    "updated_date": "2025-05-06 14:49:11 UTC"
  },
  {
    "arxiv_id": "2412.01459v1",
    "title": "Misalignments in AI Perception: Quantitative Findings and Visual Mapping of How Experts and the Public Differ in Expectations and Risks, Benefits, and Value Judgments",
    "authors": [
      "Philipp Brauner",
      "Felix Glawe",
      "Gian Luca Liehner",
      "Luisa Vervier",
      "Martina Ziefle"
    ],
    "abstract": "Artificial Intelligence (AI) is transforming diverse societal domains,\nraising critical questions about its risks and benefits and the misalignments\nbetween public expectations and academic visions. This study examines how the\ngeneral public (N=1110) -- people using or being affected by AI -- and academic\nAI experts (N=119) -- people shaping AI development -- perceive AI's\ncapabilities and impact across 71 scenarios, including sustainability,\nhealthcare, job performance, societal divides, art, and warfare. Participants\nevaluated each scenario on four dimensions: expected probability, perceived\nrisk and benefit, and overall sentiment (or value). The findings reveal\nsignificant quantitative differences: experts anticipate higher probabilities,\nperceive lower risks, report greater utility, and express more favorable\nsentiment toward AI compared to the non-experts. Notably, risk-benefit\ntradeoffs differ: the public assigns risk half the weight of benefits, while\nexperts assign it only a third. Visual maps of these evaluations highlight\nareas of convergence and divergence, identifying potential sources of public\nconcern. These insights offer actionable guidance for researchers and\npolicymakers to align AI development with societal values, fostering public\ntrust and informed governance.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01459v1",
    "published_date": "2024-12-02 12:51:45 UTC",
    "updated_date": "2024-12-02 12:51:45 UTC"
  },
  {
    "arxiv_id": "2412.01450v1",
    "title": "Artificial Intelligence for Geometry-Based Feature Extraction, Analysis and Synthesis in Artistic Images: A Survey",
    "authors": [
      "Mridula Vijendran",
      "Jingjing Deng",
      "Shuang Chen",
      "Edmond S. L. Ho",
      "Hubert P. H. Shum"
    ],
    "abstract": "Artificial Intelligence significantly enhances the visual art industry by\nanalyzing, identifying and generating digitized artistic images. This review\nhighlights the substantial benefits of integrating geometric data into AI\nmodels, addressing challenges such as high inter-class variations, domain gaps,\nand the separation of style from content by incorporating geometric\ninformation. Models not only improve AI-generated graphics synthesis quality,\nbut also effectively distinguish between style and content, utilizing inherent\nmodel biases and shared data traits. We explore methods like geometric data\nextraction from artistic images, the impact on human perception, and its use in\ndiscriminative tasks. The review also discusses the potential for improving\ndata quality through innovative annotation techniques and the use of geometric\ndata to enhance model adaptability and output refinement. Overall,\nincorporating geometric guidance boosts model performance in classification and\nsynthesis tasks, providing crucial insights for future AI applications in the\nvisual arts domain.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "56 pages, 8 tables, 1 figure (35 embedded images), Artificial\n  Intelligence Review (AIR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.01450v1",
    "published_date": "2024-12-02 12:41:15 UTC",
    "updated_date": "2024-12-02 12:41:15 UTC"
  },
  {
    "arxiv_id": "2412.01447v1",
    "title": "PLD+: Accelerating LLM inference by leveraging Language Model Artifacts",
    "authors": [
      "Shwetha Somasundaram",
      "Anirudh Phukan",
      "Apoorv Saxena"
    ],
    "abstract": "To reduce the latency associated with autoretrogressive LLM inference,\nspeculative decoding has emerged as a novel decoding paradigm, where future\ntokens are drafted and verified in parallel. However, the practical deployment\nof speculative decoding is hindered by its requirements for additional\ncomputational resources and fine-tuning, which limits its out-of-the-box\nusability. To address these challenges, we present PLD+, a suite of novel\nalgorithms developed to accelerate the inference process of LLMs, particularly\nfor input-guided tasks. These tasks, which include code editing, text editing,\nsummarization, etc., often feature outputs with substantial overlap with their\ninputs-an attribute PLD+ is designed to exploit. PLD+ also leverages the\nartifacts (attention and hidden states) generated during inference to\naccelerate inference speed. We test our approach on five input-guided tasks and\nthrough extensive experiments we find that PLD+ outperforms all tuning-free\napproaches. In the greedy setting, it even outperforms the state-of-the-art\ntuning-dependent approach EAGLE on four of the tasks. (by a margin of upto 2.31\nin terms of avg. speedup). Our approach is tuning free, does not require any\nadditional compute and can easily be used for accelerating inference of any\nLLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01447v1",
    "published_date": "2024-12-02 12:36:27 UTC",
    "updated_date": "2024-12-02 12:36:27 UTC"
  },
  {
    "arxiv_id": "2412.01443v1",
    "title": "Multi-Facet Blending for Faceted Query-by-Example Retrieval",
    "authors": [
      "Heejin Do",
      "Sangwon Ryu",
      "Jonghwi Kim",
      "Gary Geunbae Lee"
    ],
    "abstract": "With the growing demand to fit fine-grained user intents, faceted\nquery-by-example (QBE), which retrieves similar documents conditioned on\nspecific facets, has gained recent attention. However, prior approaches mainly\ndepend on document-level comparisons using basic indicators like citations due\nto the lack of facet-level relevance datasets; yet, this limits their use to\ncitation-based domains and fails to capture the intricacies of facet\nconstraints. In this paper, we propose a multi-facet blending (FaBle)\naugmentation method, which exploits modularity by decomposing and recomposing\nto explicitly synthesize facet-specific training sets. We automatically\ndecompose documents into facet units and generate (ir)relevant pairs by\nleveraging LLMs' intrinsic distinguishing capabilities; then, dynamically\nrecomposing the units leads to facet-wise relevance-informed document pairs.\nOur modularization eliminates the need for pre-defined facet knowledge or\nlabels. Further, to prove the FaBle's efficacy in a new domain beyond\ncitation-based scientific paper retrieval, we release a benchmark dataset for\neducational exam item QBE. FaBle augmentation on 1K documents remarkably\nassists training in obtaining facet conditional embeddings.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01443v1",
    "published_date": "2024-12-02 12:32:19 UTC",
    "updated_date": "2024-12-02 12:32:19 UTC"
  },
  {
    "arxiv_id": "2412.01441v2",
    "title": "LMAct: A Benchmark for In-Context Imitation Learning with Long Multimodal Demonstrations",
    "authors": [
      "Anian Ruoss",
      "Fabio Pardo",
      "Harris Chan",
      "Bonnie Li",
      "Volodymyr Mnih",
      "Tim Genewein"
    ],
    "abstract": "In this paper, we present a benchmark to pressure-test today's frontier\nmodels' multimodal decision-making capabilities in the very long-context regime\n(up to one million tokens) and investigate whether these models can learn from\nlarge numbers of expert demonstrations in their context. We evaluate the\nperformance of Claude 3.5 Sonnet, Gemini 1.5 Flash, Gemini 1.5 Pro, Gemini 2.0\nFlash Experimental, GPT-4o, o1-mini, o1-preview, and o1 as policies across a\nbattery of simple interactive decision-making tasks: playing tic-tac-toe,\nchess, and Atari, navigating grid worlds, solving crosswords, and controlling a\nsimulated cheetah. We study increasing amounts of expert demonstrations in the\ncontext $\\unicode{x2013}$ from no demonstrations to 512 full episodes. Across\nour tasks, models rarely manage to fully reach expert performance, and often,\npresenting more demonstrations has little effect. Some models steadily improve\nwith more demonstrations on a few tasks. We investigate the effect of encoding\nobservations as text or images and the impact of chain-of-thought prompting. To\nhelp quantify the impact of other approaches and future innovations, we open\nsource our benchmark that covers the zero-, few-, and many-shot regimes in a\nunified evaluation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01441v2",
    "published_date": "2024-12-02 12:31:58 UTC",
    "updated_date": "2025-02-03 23:26:42 UTC"
  },
  {
    "arxiv_id": "2412.01430v1",
    "title": "MVImgNet2.0: A Larger-scale Dataset of Multi-view Images",
    "authors": [
      "Xiaoguang Han",
      "Yushuang Wu",
      "Luyue Shi",
      "Haolin Liu",
      "Hongjie Liao",
      "Lingteng Qiu",
      "Weihao Yuan",
      "Xiaodong Gu",
      "Zilong Dong",
      "Shuguang Cui"
    ],
    "abstract": "MVImgNet is a large-scale dataset that contains multi-view images of ~220k\nreal-world objects in 238 classes. As a counterpart of ImageNet, it introduces\n3D visual signals via multi-view shooting, making a soft bridge between 2D and\n3D vision. This paper constructs the MVImgNet2.0 dataset that expands MVImgNet\ninto a total of ~520k objects and 515 categories, which derives a 3D dataset\nwith a larger scale that is more comparable to ones in the 2D domain. In\naddition to the expanded dataset scale and category range, MVImgNet2.0 is of a\nhigher quality than MVImgNet owing to four new features: (i) most shoots\ncapture 360-degree views of the objects, which can support the learning of\nobject reconstruction with completeness; (ii) the segmentation manner is\nadvanced to produce foreground object masks of higher accuracy; (iii) a more\npowerful structure-from-motion method is adopted to derive the camera pose for\neach frame of a lower estimation error; (iv) higher-quality dense point clouds\nare reconstructed via advanced methods for objects captured in 360-degree\nviews, which can serve for downstream applications. Extensive experiments\nconfirm the value of the proposed MVImgNet2.0 in boosting the performance of\nlarge 3D reconstruction models. MVImgNet2.0 will be public at\nluyues.github.io/mvimgnet2, including multi-view images of all 520k objects,\nthe reconstructed high-quality point clouds, and data annotation codes, hoping\nto inspire the broader vision community.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "ACM Transactions on Graphics (TOG), SIGGRAPH Asia 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.01430v1",
    "published_date": "2024-12-02 12:10:04 UTC",
    "updated_date": "2024-12-02 12:10:04 UTC"
  },
  {
    "arxiv_id": "2412.01425v1",
    "title": "Reject Threshold Adaptation for Open-Set Model Attribution of Deepfake Audio",
    "authors": [
      "Xinrui Yan",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Yujie Chen",
      "Hao Gu",
      "Guanjun Li",
      "Junzuo Zhou",
      "Yong Ren",
      "Tao Xu"
    ],
    "abstract": "Open environment oriented open set model attribution of deepfake audio is an\nemerging research topic, aiming to identify the generation models of deepfake\naudio. Most previous work requires manually setting a rejection threshold for\nunknown classes to compare with predicted probabilities. However, models often\noverfit training instances and generate overly confident predictions. Moreover,\nthresholds that effectively distinguish unknown categories in the current\ndataset may not be suitable for identifying known and unknown categories in\nanother data distribution. To address the issues, we propose a novel framework\nfor open set model attribution of deepfake audio with rejection threshold\nadaptation (ReTA). Specifically, the reconstruction error learning module\ntrains by combining the representation of system fingerprints with labels\ncorresponding to either the target class or a randomly chosen other class\nlabel. This process generates matching and non-matching reconstructed samples,\nestablishing the reconstruction error distributions for each class and laying\nthe foundation for the reject threshold calculation module. The reject\nthreshold calculation module utilizes gaussian probability estimation to fit\nthe distributions of matching and non-matching reconstruction errors. It then\ncomputes adaptive reject thresholds for all classes through probability\nminimization criteria. The experimental results demonstrate the effectiveness\nof ReTA in improving the open set model attributes of deepfake audio.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ISCSLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.01425v1",
    "published_date": "2024-12-02 12:06:50 UTC",
    "updated_date": "2024-12-02 12:06:50 UTC"
  },
  {
    "arxiv_id": "2412.01419v2",
    "title": "CSP-AIT-Net: A contrastive learning-enhanced spatiotemporal graph attention framework for short-term metro OD flow prediction with asynchronous inflow tracking",
    "authors": [
      "Yichen Wang",
      "Chengcheng Yu"
    ],
    "abstract": "Accurate origin-destination (OD) passenger flow prediction is crucial for\nenhancing metro system efficiency, optimizing scheduling, and improving\npassenger experiences. However, current models often fail to effectively\ncapture the asynchronous departure characteristics of OD flows and underutilize\nthe inflow and outflow data, which limits their prediction accuracy. To address\nthese issues, we propose CSP-AIT-Net, a novel spatiotemporal graph attention\nframework designed to enhance OD flow prediction by incorporating asynchronous\ninflow tracking and advanced station semantics representation. Our framework\nrestructures the OD flow prediction paradigm by first predicting outflows and\nthen decomposing OD flows using a spatiotemporal graph attention mechanism. To\nenhance computational efficiency, we introduce a masking mechanism and propose\nasynchronous passenger flow graphs that integrate inflow and OD flow with\nconservation constraints. Furthermore, we employ contrastive learning to\nextract high-dimensional land use semantics of metro stations, enriching the\ncontextual understanding of passenger mobility patterns. Validation of the\nShanghai metro system demonstrates improvement in short-term OD flow prediction\naccuracy over state-of-the-art methods. This work contributes to enhancing\nmetro operational efficiency, scheduling precision, and overall system safety.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "Due to unresolved disagreements among the authorship team regarding\n  the interpretation of the findings and attribution of contributions",
    "pdf_url": "http://arxiv.org/pdf/2412.01419v2",
    "published_date": "2024-12-02 12:00:06 UTC",
    "updated_date": "2025-02-08 15:51:41 UTC"
  },
  {
    "arxiv_id": "2412.01417v1",
    "title": "Learning Elementary Cellular Automata with Transformers",
    "authors": [
      "Mikhail Burtsev"
    ],
    "abstract": "Large Language Models demonstrate remarkable mathematical capabilities but at\nthe same time struggle with abstract reasoning and planning. In this study, we\nexplore whether Transformers can learn to abstract and generalize the rules\ngoverning Elementary Cellular Automata. By training Transformers on state\nsequences generated with random initial conditions and local rules, we show\nthat they can generalize across different Boolean functions of fixed arity,\neffectively abstracting the underlying rules. While the models achieve high\naccuracy in next-state prediction, their performance declines sharply in\nmulti-step planning tasks without intermediate context. Our analysis reveals\nthat including future states or rule prediction in the training loss enhances\nthe models' ability to form internal representations of the rules, leading to\nimproved performance in longer planning horizons and autoregressive generation.\nFurthermore, we confirm that increasing the model's depth plays a crucial role\nin extended sequential computations required for complex reasoning tasks. This\nhighlights the potential to improve LLM with inclusion of longer horizons in\nloss function, as well as incorporating recurrence and adaptive computation\ntime for dynamic control of model depth.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.FL"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01417v1",
    "published_date": "2024-12-02 11:57:49 UTC",
    "updated_date": "2024-12-02 11:57:49 UTC"
  },
  {
    "arxiv_id": "2412.01408v3",
    "title": "Towards Cross-Lingual Audio Abuse Detection in Low-Resource Settings with Few-Shot Learning",
    "authors": [
      "Aditya Narayan Sankaran",
      "Reza Farahbakhsh",
      "Noel Crespi"
    ],
    "abstract": "Online abusive content detection, particularly in low-resource settings and\nwithin the audio modality, remains underexplored. We investigate the potential\nof pre-trained audio representations for detecting abusive language in\nlow-resource languages, in this case, in Indian languages using Few Shot\nLearning (FSL). Leveraging powerful representations from models such as Wav2Vec\nand Whisper, we explore cross-lingual abuse detection using the ADIMA dataset\nwith FSL. Our approach integrates these representations within the\nModel-Agnostic Meta-Learning (MAML) framework to classify abusive language in\n10 languages. We experiment with various shot sizes (50-200) evaluating the\nimpact of limited data on performance. Additionally, a feature visualization\nstudy was conducted to better understand model behaviour. This study highlights\nthe generalization ability of pre-trained models in low-resource scenarios and\noffers valuable insights into detecting abusive language in multilingual\ncontexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as part of the proceedings of COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01408v3",
    "published_date": "2024-12-02 11:51:19 UTC",
    "updated_date": "2024-12-13 11:59:06 UTC"
  },
  {
    "arxiv_id": "2412.01405v1",
    "title": "MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation",
    "authors": [
      "Thi-Nhu-Quynh Nguyen",
      "Quang-Huy Ho",
      "Duy-Thai Nguyen",
      "Hoang-Minh-Quang Le",
      "Van-Truong Pham",
      "Thi-Thao Tran"
    ],
    "abstract": "Early detection of skin abnormalities plays a crucial role in diagnosing and\ntreating skin cancer. Segmentation of affected skin regions using AI-powered\ndevices is relatively common and supports the diagnostic process. However,\nachieving high performance remains a significant challenge due to the need for\nhigh-resolution images and the often unclear boundaries of individual lesions.\nAt the same time, medical devices require segmentation models to have a small\nmemory foot-print and low computational cost. Based on these requirements, we\nintroduce a novel lightweight model called MambaU-Lite, which combines the\nstrengths of Mamba and CNN architectures, featuring just over 400K parameters\nand a computational cost of more than 1G flops. To enhance both global context\nand local feature extraction, we propose the P-Mamba block, a novel component\nthat incorporates VSS blocks along-side multiple pooling layers, enabling the\nmodel to effectively learn multiscale features and enhance segmentation\nperformance. We evaluate the model's performance on two skin datasets, ISIC2018\nand PH2, yielding promising results. Our source code will be made publicly\navailable at: https://github.com/nqnguyen812/MambaU-Lite.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.01405v1",
    "published_date": "2024-12-02 11:49:49 UTC",
    "updated_date": "2024-12-02 11:49:49 UTC"
  },
  {
    "arxiv_id": "2412.01400v1",
    "title": "Fire-Image-DenseNet (FIDN) for predicting wildfire burnt area using remote sensing data",
    "authors": [
      "Bo Pang",
      "Sibo Cheng",
      "Yuhan Huang",
      "Yufang Jin",
      "Yike Guo",
      "I. Colin Prentice",
      "Sandy P. Harrison",
      "Rossella Arcucci"
    ],
    "abstract": "Predicting the extent of massive wildfires once ignited is essential to\nreduce the subsequent socioeconomic losses and environmental damage, but\nchallenging because of the complexity of fire behaviour. Existing physics-based\nmodels are limited in predicting large or long-duration wildfire events. Here,\nwe develop a deep-learning-based predictive model, Fire-Image-DenseNet (FIDN),\nthat uses spatial features derived from both near real-time and reanalysis data\non the environmental and meteorological drivers of wildfire. We trained and\ntested this model using more than 300 individual wildfires that occurred\nbetween 2012 and 2019 in the western US. In contrast to existing models, the\nperformance of FIDN does not degrade with fire size or duration. Furthermore,\nit predicts final burnt area accurately even in very heterogeneous landscapes\nin terms of fuel density and flammability. The FIDN model showed higher\naccuracy, with a mean squared error (MSE) about 82% and 67% lower than those of\nthe predictive models based on cellular automata (CA) and the minimum travel\ntime (MTT) approaches, respectively. Its structural similarity index measure\n(SSIM) averages 97%, outperforming the CA and FlamMap MTT models by 6% and 2%,\nrespectively. Additionally, FIDN is approximately three orders of magnitude\nfaster than both CA and MTT models. The enhanced computational efficiency and\naccuracy advancements offer vital insights for strategic planning and resource\nallocation for firefighting operations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01400v1",
    "published_date": "2024-12-02 11:35:31 UTC",
    "updated_date": "2024-12-02 11:35:31 UTC"
  },
  {
    "arxiv_id": "2412.01383v2",
    "title": "Second FRCSyn-onGoing: Winning Solutions and Post-Challenge Analysis to Improve Face Recognition with Synthetic Data",
    "authors": [
      "Ivan DeAndres-Tame",
      "Ruben Tolosana",
      "Pietro Melzi",
      "Ruben Vera-Rodriguez",
      "Minchul Kim",
      "Christian Rathgeb",
      "Xiaoming Liu",
      "Luis F. Gomez",
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Ortega-Garcia",
      "Zhizhou Zhong",
      "Yuge Huang",
      "Yuxi Mi",
      "Shouhong Ding",
      "Shuigeng Zhou",
      "Shuai He",
      "Lingzhi Fu",
      "Heng Cong",
      "Rongyu Zhang",
      "Zhihong Xiao",
      "Evgeny Smirnov",
      "Anton Pimenov",
      "Aleksei Grigorev",
      "Denis Timoshenko",
      "Kaleb Mesfin Asfaw",
      "Cheng Yaw Low",
      "Hao Liu",
      "Chuyi Wang",
      "Qing Zuo",
      "Zhixiang He",
      "Hatef Otroshi Shahreza",
      "Anjith George",
      "Alexander Unnervik",
      "Parsa Rahimi",
      "Sébastien Marcel",
      "Pedro C. Neto",
      "Marco Huber",
      "Jan Niklas Kolf",
      "Naser Damer",
      "Fadi Boutros",
      "Jaime S. Cardoso",
      "Ana F. Sequeira",
      "Andrea Atzori",
      "Gianni Fenu",
      "Mirko Marras",
      "Vitomir Štruc",
      "Jiang Yu",
      "Zhangjie Li",
      "Jichun Li",
      "Weisong Zhao",
      "Zhen Lei",
      "Xiangyu Zhu",
      "Xiao-Yu Zhang",
      "Bernardo Biesseck",
      "Pedro Vidal",
      "Luiz Coelho",
      "Roger Granada",
      "David Menotti"
    ],
    "abstract": "Synthetic data is gaining increasing popularity for face recognition\ntechnologies, mainly due to the privacy concerns and challenges associated with\nobtaining real data, including diverse scenarios, quality, and demographic\ngroups, among others. It also offers some advantages over real data, such as\nthe large amount of data that can be generated or the ability to customize it\nto adapt to specific problem-solving needs. To effectively use such data, face\nrecognition models should also be specifically designed to exploit synthetic\ndata to its fullest potential. In order to promote the proposal of novel\nGenerative AI methods and synthetic data, and investigate the application of\nsynthetic data to better train face recognition systems, we introduce the 2nd\nFRCSyn-onGoing challenge, based on the 2nd Face Recognition Challenge in the\nEra of Synthetic Data (FRCSyn), originally launched at CVPR 2024. This is an\nongoing challenge that provides researchers with an accessible platform to\nbenchmark i) the proposal of novel Generative AI methods and synthetic data,\nand ii) novel face recognition systems that are specifically proposed to take\nadvantage of synthetic data. We focus on exploring the use of synthetic data\nboth individually and in combination with real data to solve current challenges\nin face recognition such as demographic bias, domain adaptation, and\nperformance constraints in demanding situations, such as age disparities\nbetween training and testing, changes in the pose, or occlusions. Very\ninteresting findings are obtained in this second edition, including a direct\ncomparison with the first one, in which synthetic databases were restricted to\nDCFace and GANDiffFace.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in Information Fusion",
    "pdf_url": "http://arxiv.org/pdf/2412.01383v2",
    "published_date": "2024-12-02 11:12:01 UTC",
    "updated_date": "2025-03-10 09:29:33 UTC"
  },
  {
    "arxiv_id": "2412.01378v1",
    "title": "A Survey on Deep Neural Networks in Collaborative Filtering Recommendation Systems",
    "authors": [
      "Pang Li",
      "Shahrul Azman Mohd Noah",
      "Hafiz Mohd Sarim"
    ],
    "abstract": "This survey provides an examination of the use of Deep Neural Networks (DNN)\nin Collaborative Filtering (CF) recommendation systems. As the digital world\nincreasingly relies on data-driven approaches, traditional CF techniques face\nlimitations in scalability and flexibility. DNNs can address these challenges\nby effectively modeling complex, non-linear relationships within the data. We\nbegin by exploring the fundamental principles of both collaborative filtering\nand deep neural networks, laying the groundwork for understanding their\nintegration. Subsequently, we review key advancements in the field,\ncategorizing various deep learning models that enhance CF systems, including\nMultilayer Perceptrons (MLP), Convolutional Neural Networks (CNN), Recurrent\nNeural Networks (RNN), Graph Neural Networks (GNN), autoencoders, Generative\nAdversarial Networks (GAN), and Restricted Boltzmann Machines (RBM). The paper\nalso discusses evaluation protocols, various publicly available auxiliary\ninformation, and data features. Furthermore, the survey concludes with a\ndiscussion of the challenges and future research opportunities in enhancing\ncollaborative filtering systems with deep learning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01378v1",
    "published_date": "2024-12-02 11:06:34 UTC",
    "updated_date": "2024-12-02 11:06:34 UTC"
  },
  {
    "arxiv_id": "2412.01376v1",
    "title": "Convolutional Transformer Neural Collaborative Filtering",
    "authors": [
      "Pang Li",
      "Shahrul Azman Mohd Noah",
      "Hafiz Mohd Sarim"
    ],
    "abstract": "In this study, we introduce Convolutional Transformer Neural Collaborative\nFiltering (CTNCF), a novel approach aimed at enhancing recommendation systems\nby effectively capturing high-order structural information in user-item\ninteractions. CTNCF represents a significant advancement over the traditional\nNeural Collaborative Filtering (NCF) model by seamlessly integrating\nConvolutional Neural Networks (CNNs) and Transformer layers. This sophisticated\nintegration enables the model to adeptly capture and understand complex\ninteraction patterns inherent in recommendation systems. Specifically, CNNs are\nemployed to extract local features from user and item embeddings, allowing the\nmodel to capture intricate spatial dependencies within the data. Furthermore,\nthe utilization of Transformer layers enables the model to capture long-range\ndependencies and interactions among user and item features, thereby enhancing\nits ability to understand the underlying relationships in the data. To validate\nthe effectiveness of our proposed CTNCF framework, we conduct extensive\nexperiments on two real-world datasets. The results demonstrate that CTNCF\nsignificantly outperforms state-of-the-art approaches, highlighting its\nefficacy in improving recommendation system performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01376v1",
    "published_date": "2024-12-02 11:01:31 UTC",
    "updated_date": "2024-12-02 11:01:31 UTC"
  },
  {
    "arxiv_id": "2412.01371v1",
    "title": "An overview of diffusion models for generative artificial intelligence",
    "authors": [
      "Davide Gallon",
      "Arnulf Jentzen",
      "Philippe von Wurstemberger"
    ],
    "abstract": "This article provides a mathematically rigorous introduction to denoising\ndiffusion probabilistic models (DDPMs), sometimes also referred to as diffusion\nprobabilistic models or diffusion models, for generative artificial\nintelligence. We provide a detailed basic mathematical framework for DDPMs and\nexplain the main ideas behind training and generation procedures. In this\noverview article we also review selected extensions and improvements of the\nbasic framework from the literature such as improved DDPMs, denoising diffusion\nimplicit models, classifier-free diffusion guidance models, and latent\ndiffusion models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "56 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01371v1",
    "published_date": "2024-12-02 10:55:38 UTC",
    "updated_date": "2024-12-02 10:55:38 UTC"
  },
  {
    "arxiv_id": "2412.01372v1",
    "title": "Research on Cervical Cancer p16/Ki-67 Immunohistochemical Dual-Staining Image Recognition Algorithm Based on YOLO",
    "authors": [
      "Xiao-Jun Wu",
      "Cai-Jun Zhao",
      "Chun Meng",
      "Hang Wang"
    ],
    "abstract": "The p16/Ki-67 dual staining method is a new approach for cervical cancer\nscreening with high sensitivity and specificity. However, there are issues of\nmis-detection and inaccurate recognition when the YOLOv5s algorithm is directly\napplied to dual-stained cell images. This paper Proposes a novel cervical\ncancer dual-stained image recognition (DSIR-YOLO) model based on an YOLOv5. By\nfusing the Swin-Transformer module, GAM attention mechanism, multi-scale\nfeature fusion, and EIoU loss function, the detection performance is\nsignificantly improved, with mAP@0.5 and mAP@0.5:0.95 reaching 92.6% and 70.5%,\nrespectively. Compared with YOLOv5s in five-fold cross-validation, the\naccuracy, recall, mAP@0.5, and mAP@0.5:0.95 of the improved algorithm are\nincreased by 2.3%, 4.1%, 4.3%, and 8.0%, respectively, with smaller variances\nand higher stability. Compared with other detection algorithms, DSIR-YOLO in\nthis paper sacrifices some performance requirements to improve the network\nrecognition effect. In addition, the influence of dataset quality on the\ndetection results is studied. By controlling the sealing property of pixels,\nscale difference, unlabelled cells, and diagonal annotation, the model\ndetection accuracy, recall, mAP@0.5, and mAP@0.5:0.95 are improved by 13.3%,\n15.3%, 18.3%, and 30.5%, respectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01372v1",
    "published_date": "2024-12-02 10:55:38 UTC",
    "updated_date": "2024-12-02 10:55:38 UTC"
  },
  {
    "arxiv_id": "2412.01369v1",
    "title": "Behavior Backdoor for Deep Learning Models",
    "authors": [
      "Jiakai Wang",
      "Pengfei Zhang",
      "Renshuai Tao",
      "Jian Yang",
      "Hao Liu",
      "Xianglong Liu",
      "Yunchao Wei",
      "Yao Zhao"
    ],
    "abstract": "The various post-processing methods for deep-learning-based models, such as\nquantification, pruning, and fine-tuning, play an increasingly important role\nin artificial intelligence technology, with pre-train large models as one of\nthe main development directions. However, this popular series of\npost-processing behaviors targeting pre-training deep models has become a\nbreeding ground for new adversarial security issues. In this study, we take the\nfirst step towards ``behavioral backdoor'' attack, which is defined as a\nbehavior-triggered backdoor model training procedure, to reveal a new paradigm\nof backdoor attacks. In practice, we propose the first pipeline of implementing\nbehavior backdoor, i.e., the Quantification Backdoor (QB) attack, upon\nexploiting model quantification method as the set trigger. Specifically, to\nadapt the optimization goal of behavior backdoor, we introduce the\nbehavior-driven backdoor object optimizing method by a bi-target behavior\nbackdoor training loss, thus we could guide the poisoned model optimization\ndirection. To update the parameters across multiple models, we adopt the\naddress-shared backdoor model training, thereby the gradient information could\nbe utilized for multimodel collaborative optimization. Extensive experiments\nhave been conducted on different models, datasets, and tasks, demonstrating the\neffectiveness of this novel backdoor attack and its potential application\nthreats.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01369v1",
    "published_date": "2024-12-02 10:54:02 UTC",
    "updated_date": "2024-12-02 10:54:02 UTC"
  },
  {
    "arxiv_id": "2412.01365v2",
    "title": "Explaining the Unexplained: Revealing Hidden Correlations for Better Interpretability",
    "authors": [
      "Wen-Dong Jiang",
      "Chih-Yung Chang",
      "Show-Jane Yen",
      "Diptendu Sinha Roy"
    ],
    "abstract": "Deep learning has achieved remarkable success in processing and managing\nunstructured data. However, its \"black box\" nature imposes significant\nlimitations, particularly in sensitive application domains. While existing\ninterpretable machine learning methods address some of these issues, they often\nfail to adequately consider feature correlations and provide insufficient\nevaluation of model decision paths. To overcome these challenges, this paper\nintroduces Real Explainer (RealExp), an interpretability computation method\nthat decouples the Shapley Value into individual feature importance and feature\ncorrelation importance. By incorporating feature similarity computations,\nRealExp enhances interpretability by precisely quantifying both individual\nfeature contributions and their interactions, leading to more reliable and\nnuanced explanations. Additionally, this paper proposes a novel\ninterpretability evaluation criterion focused on elucidating the decision paths\nof deep learning models, going beyond traditional accuracy-based metrics.\nExperimental validations on two unstructured data tasks -- image classification\nand text sentiment analysis -- demonstrate that RealExp significantly\noutperforms existing methods in interpretability. Case studies further\nillustrate its practical value: in image classification, RealExp aids in\nselecting suitable pre-trained models for specific tasks from an\ninterpretability perspective; in text classification, it enables the\noptimization of models and approximates the performance of a fine-tuned GPT-Ada\nmodel using traditional bag-of-words approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been submitted to the Elsevier for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2412.01365v2",
    "published_date": "2024-12-02 10:50:50 UTC",
    "updated_date": "2025-02-09 09:06:44 UTC"
  },
  {
    "arxiv_id": "2412.01354v1",
    "title": "Integrative CAM: Adaptive Layer Fusion for Comprehensive Interpretation of CNNs",
    "authors": [
      "Aniket K. Singh",
      "Debasis Chaudhuri",
      "Manish P. Singh",
      "Samiran Chattopadhyay"
    ],
    "abstract": "With the growing demand for interpretable deep learning models, this paper\nintroduces Integrative CAM, an advanced Class Activation Mapping (CAM)\ntechnique aimed at providing a holistic view of feature importance across\nConvolutional Neural Networks (CNNs). Traditional gradient-based CAM methods,\nsuch as Grad-CAM and Grad-CAM++, primarily use final layer activations to\nhighlight regions of interest, often neglecting critical features derived from\nintermediate layers. Integrative CAM addresses this limitation by fusing\ninsights across all network layers, leveraging both gradient and activation\nscores to adaptively weight layer contributions, thus yielding a comprehensive\ninterpretation of the model's internal representation. Our approach includes a\nnovel bias term in the saliency map calculation, a factor frequently omitted in\nexisting CAM techniques, but essential for capturing a more complete feature\nimportance landscape, as modern CNNs rely on both weighted activations and\nbiases to make predictions. Additionally, we generalize the alpha term from\nGrad-CAM++ to apply to any smooth function, expanding CAM applicability across\na wider range of models. Through extensive experiments on diverse and complex\ndatasets, Integrative CAM demonstrates superior fidelity in feature importance\nmapping, effectively enhancing interpretability for intricate fusion scenarios\nand complex decision-making tasks. By advancing interpretability methods to\ncapture multi-layered model insights, Integrative CAM provides a valuable tool\nfor fusion-driven applications, promoting the trustworthy and insightful\ndeployment of deep learning models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01354v1",
    "published_date": "2024-12-02 10:33:34 UTC",
    "updated_date": "2024-12-02 10:33:34 UTC"
  },
  {
    "arxiv_id": "2412.01353v2",
    "title": "Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models",
    "authors": [
      "Chayan Tank",
      "Shaina Mehta",
      "Sarthak Pol",
      "Vinayak Katoch",
      "Avinash Anand",
      "Raj Jaiswal",
      "Rajiv Ratn Shah"
    ],
    "abstract": "In recent times, more and more people are posting about their mental states\nacross various social media platforms. Leveraging this data, AI-based systems\ncan be developed that help in assessing the mental health of individuals, such\nas suicide risk. This paper is a study done on suicidal risk assessments using\nReddit data leveraging Base language models to identify patterns from social\nmedia posts. We have demonstrated that using smaller language models, i.e.,\nless than 500M parameters, can also be effective in contrast to LLMs with\ngreater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on\nsuicide risk prediction task that utilized both the labeled and unlabeled\nReddit data and tackled class imbalance by data augmentation using GPT-2 model.\nOur Su-RoBERTa model attained a 69.84% weighted F1 score during the Final\nevaluation. This paper demonstrates the effectiveness of Base language models\nfor the analysis of the risk factors related to mental health with an efficient\ncomputation pipeline",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages, 7 figures, Accepted at IEEE International Conference on Big\n  Data (IEEE BigData 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.01353v2",
    "published_date": "2024-12-02 10:31:12 UTC",
    "updated_date": "2024-12-19 09:10:18 UTC"
  },
  {
    "arxiv_id": "2412.01351v1",
    "title": "A multi-criteria decision support system to evaluate the effectiveness of training courses on citizens' employability",
    "authors": [
      "Maria C. Bas",
      "Vicente J. Bolos",
      "Alvaro E. Prieto",
      "Roberto Rodriguez-Echeverria",
      "Fernando Sanchez-Figueroa"
    ],
    "abstract": "This study examines the impact of lifelong learning on the professional lives\nof employed and unemployed individuals. Lifelong learning is a crucial factor\nin securing employment or enhancing one's existing career prospects. To achieve\nthis objective, this study proposes the implementation of a multi-criteria\ndecision support system for the evaluation of training courses in accordance\nwith their capacity to enhance the employability of the students. The\nmethodology is delineated in four stages. Firstly, a `working life curve' was\ndefined to provide a quantitative description of an individual's working life.\nSecondly, an analysis based on K-medoids clustering defined a control group for\neach individual for comparison. Thirdly, the performance of a course according\nto each of the four predefined criteria was calculated using a t-test to\ndetermine the mean performance value of those who took the course. Ultimately,\nthe unweighted TOPSIS method was used to evaluate the efficacy of the various\ntraining courses in relation to the four criteria. This approach effectively\naddresses the challenge of using extensive datasets within a system while\nfacilitating the application of a multi-criteria unweighted TOPSIS method. The\nresults of the multi-criteria TOPSIS method indicated that training courses\nrelated to the professional fields of administration and management, hostel and\ntourism and community and sociocultural services have positive impact on\nemployability and improving the working conditions of citizens. However,\ncourses that demonstrate the greatest effectiveness in ranking are the least\ndemanded by citizens. The results will help policymakers evaluate the\neffectiveness of each training course offered by the regional government.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "math.OC",
      "90B50, 90C29, 90C31, 91B06"
    ],
    "primary_category": "cs.CY",
    "comment": "24 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01351v1",
    "published_date": "2024-12-02 10:29:28 UTC",
    "updated_date": "2024-12-02 10:29:28 UTC"
  },
  {
    "arxiv_id": "2412.01348v2",
    "title": "Hierarchical Object-Oriented POMDP Planning for Object Rearrangement",
    "authors": [
      "Rajesh Mangannavar",
      "Alan Fern",
      "Prasad Tadepalli"
    ],
    "abstract": "We present an online planning framework for solving multi-object\nrearrangement problems in partially observable, multi-room environments.\nCurrent object rearrangement solutions, primarily based on Reinforcement\nLearning or hand-coded planning methods, often lack adaptability to diverse\nchallenges. To address this limitation, we introduce a novel Hierarchical\nObject-Oriented Partially Observed Markov Decision Process (HOO-POMDP) planning\napproach. This approach comprises of (a) an object-oriented POMDP planner\ngenerating sub-goals, (b) a set of low-level policies for sub-goal achievement,\nand (c) an abstraction system converting the continuous low-level world into a\nrepresentation suitable for abstract planning. We evaluate our system on\nvarying numbers of objects, rooms, and problem types in AI2-THOR simulated\nenvironments with promising results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "I.2.9"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 2 Figures. Preprint. Updated acknowledgments",
    "pdf_url": "http://arxiv.org/pdf/2412.01348v2",
    "published_date": "2024-12-02 10:19:36 UTC",
    "updated_date": "2025-01-08 18:20:46 UTC"
  },
  {
    "arxiv_id": "2412.01339v2",
    "title": "Negative Token Merging: Image-based Adversarial Feature Guidance",
    "authors": [
      "Jaskirat Singh",
      "Lindsey Li",
      "Weijia Shi",
      "Ranjay Krishna",
      "Yejin Choi",
      "Pang Wei Koh",
      "Michael F. Cohen",
      "Stephen Gould",
      "Liang Zheng",
      "Luke Zettlemoyer"
    ],
    "abstract": "Text-based adversarial guidance using a negative prompt has emerged as a\nwidely adopted approach to steer diffusion models away from producing undesired\nconcepts. While useful, performing adversarial guidance using text alone can be\ninsufficient to capture complex visual concepts or avoid specific visual\nelements like copyrighted characters. In this paper, for the first time we\nexplore an alternate modality in this direction by performing adversarial\nguidance directly using visual features from a reference image or other images\nin a batch. We introduce negative token merging (NegToMe), a simple but\neffective training-free approach which performs adversarial guidance through\nimages by selectively pushing apart matching visual features between reference\nand generated images during the reverse diffusion process. By simply adjusting\nthe used reference, NegToMe enables a diverse range of applications. Notably,\nwhen using other images in same batch as reference, we find that NegToMe\nsignificantly enhances output diversity (e.g., racial, gender, visual) by\nguiding features of each image away from others. Similarly, when used w.r.t.\ncopyrighted reference images, NegToMe reduces visual similarity to copyrighted\ncontent by 34.57%. NegToMe is simple to implement using just few-lines of code,\nuses only marginally higher (<4%) inference time and is compatible with\ndifferent diffusion architectures, including those like Flux, which don't\nnatively support the use of a negative prompt. Code is available at\nhttps://negtome.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01339v2",
    "published_date": "2024-12-02 10:06:57 UTC",
    "updated_date": "2024-12-05 18:43:25 UTC"
  },
  {
    "arxiv_id": "2412.01330v1",
    "title": "The \"LLM World of Words\" English free association norms generated by large language models",
    "authors": [
      "Katherine Abramski",
      "Riccardo Improta",
      "Giulio Rossetti",
      "Massimo Stella"
    ],
    "abstract": "Free associations have been extensively used in cognitive psychology and\nlinguistics for studying how conceptual knowledge is organized. Recently, the\npotential of applying a similar approach for investigating the knowledge\nencoded in LLMs has emerged, specifically as a method for investigating LLM\nbiases. However, the absence of large-scale LLM-generated free association\nnorms that are comparable with human-generated norms is an obstacle to this new\nresearch direction. To address this limitation, we create a new dataset of\nLLM-generated free association norms modeled after the \"Small World of Words\"\n(SWOW) human-generated norms consisting of approximately 12,000 cue words. We\nprompt three LLMs, namely Mistral, Llama3, and Haiku, with the same cues as\nthose in the SWOW norms to generate three novel comparable datasets, the \"LLM\nWorld of Words\" (LWOW). Using both SWOW and LWOW norms, we construct cognitive\nnetwork models of semantic memory that represent the conceptual knowledge\npossessed by humans and LLMs. We demonstrate how these datasets can be used for\ninvestigating implicit biases in humans and LLMs, such as the harmful gender\nstereotypes that are prevalent both in society and LLM outputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 11 figures, associated Github page with dataset available\n  at: https://github.com/LLMWorldOfWords/LWOW",
    "pdf_url": "http://arxiv.org/pdf/2412.01330v1",
    "published_date": "2024-12-02 09:54:14 UTC",
    "updated_date": "2024-12-02 09:54:14 UTC"
  },
  {
    "arxiv_id": "2412.01322v2",
    "title": "Explainable fault and severity classification for rolling element bearings using Kolmogorov-Arnold networks",
    "authors": [
      "Spyros Rigas",
      "Michalis Papachristou",
      "Ioannis Sotiropoulos",
      "Georgios Alexandridis"
    ],
    "abstract": "Rolling element bearings are critical components of rotating machinery, with\ntheir performance directly influencing the efficiency and reliability of\nindustrial systems. At the same time, bearing faults are a leading cause of\nmachinery failures, often resulting in costly downtime, reduced productivity,\nand, in extreme cases, catastrophic damage. This study presents a methodology\nthat utilizes Kolmogorov-Arnold Networks to address these challenges through\nautomatic feature selection, hyperparameter tuning and interpretable fault\nanalysis within a unified framework. By training shallow network architectures\nand minimizing the number of selected features, the framework produces\nlightweight models that deliver explainable results through feature attribution\nand symbolic representations of their activation functions. Validated on two\nwidely recognized datasets for bearing fault diagnosis, the framework achieved\nperfect F1-Scores for fault detection and high performance in fault and\nseverity classification tasks, including 100% F1-Scores in most cases. Notably,\nit demonstrated adaptability by handling diverse fault types, such as imbalance\nand misalignment, within the same dataset. The symbolic representations\nenhanced model interpretability, while feature attribution offered insights\ninto the optimal feature types or signals for each studied task. These results\nhighlight the framework's potential for practical applications, such as\nreal-time machinery monitoring, and for scientific research requiring efficient\nand explainable models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01322v2",
    "published_date": "2024-12-02 09:40:03 UTC",
    "updated_date": "2024-12-04 11:53:32 UTC"
  },
  {
    "arxiv_id": "2412.01316v2",
    "title": "Long Video Diffusion Generation with Segmented Cross-Attention and Content-Rich Video Data Curation",
    "authors": [
      "Xin Yan",
      "Yuxuan Cai",
      "Qiuyue Wang",
      "Yuan Zhou",
      "Wenhao Huang",
      "Huan Yang"
    ],
    "abstract": "We introduce Presto, a novel video diffusion model designed to generate\n15-second videos with long-range coherence and rich content. Extending video\ngeneration methods to maintain scenario diversity over long durations presents\nsignificant challenges. To address this, we propose a Segmented Cross-Attention\n(SCA) strategy, which splits hidden states into segments along the temporal\ndimension, allowing each segment to cross-attend to a corresponding\nsub-caption. SCA requires no additional parameters, enabling seamless\nincorporation into current DiT-based architectures. To facilitate high-quality\nlong video generation, we build the LongTake-HD dataset, consisting of 261k\ncontent-rich videos with scenario coherence, annotated with an overall video\ncaption and five progressive sub-captions. Experiments show that our Presto\nachieves 78.5% on the VBench Semantic Score and 100% on the Dynamic Degree,\noutperforming existing state-of-the-art video generation methods. This\ndemonstrates that our proposed Presto significantly enhances content richness,\nmaintains long-range coherence, and captures intricate textual details. More\ndetails are displayed on our project page: https://presto-video.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper is accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01316v2",
    "published_date": "2024-12-02 09:32:36 UTC",
    "updated_date": "2025-03-29 08:56:56 UTC"
  },
  {
    "arxiv_id": "2412.01306v1",
    "title": "Multimodal Medical Disease Classification with LLaMA II",
    "authors": [
      "Christian Gapp",
      "Elias Tappeiner",
      "Martin Welk",
      "Rainer Schubert"
    ],
    "abstract": "Medical patient data is always multimodal. Images, text, age, gender,\nhistopathological data are only few examples for different modalities in this\ncontext. Processing and integrating this multimodal data with deep learning\nbased methods is of utmost interest due to its huge potential for medical\nprocedure such as diagnosis and patient treatment planning. In this work we\nretrain a multimodal transformer-based model for disease classification. To\nthis end we use the text-image pair dataset from OpenI consisting of 2D chest\nX-rays associated with clinical reports. Our focus is on fusion methods for\nmerging text and vision information extracted from medical datasets. Different\narchitecture structures with a LLaMA II backbone model are tested. Early fusion\nof modality specific features creates better results with the best model\nreaching 97.10% mean AUC than late fusion from a deeper level of the\narchitecture (best model: 96.67% mean AUC). Both outperform former\nclassification models tested on the same multimodal dataset. The newly\nintroduced multimodal architecture can be applied to other multimodal datasets\nwith little effort and can be easily adapted for further research, especially,\nbut not limited to, the field of medical AI.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures, conference: AIRoV -- The First Austrian Symposium\n  on AI, Robotics, and Vision 25.-27.3.2024, Innsbruck",
    "pdf_url": "http://arxiv.org/pdf/2412.01306v1",
    "published_date": "2024-12-02 09:18:07 UTC",
    "updated_date": "2024-12-02 09:18:07 UTC"
  },
  {
    "arxiv_id": "2412.01303v1",
    "title": "RL2: Reinforce Large Language Model to Assist Safe Reinforcement Learning for Energy Management of Active Distribution Networks",
    "authors": [
      "Xu Yang",
      "Chenhui Lin",
      "Haotian Liu",
      "Wenchuan Wu"
    ],
    "abstract": "As large-scale distributed energy resources are integrated into the active\ndistribution networks (ADNs), effective energy management in ADNs becomes\nincreasingly prominent compared to traditional distribution networks. Although\nadvanced reinforcement learning (RL) methods, which alleviate the burden of\ncomplicated modelling and optimization, have greatly improved the efficiency of\nenergy management in ADNs, safety becomes a critical concern for RL\napplications in real-world problems. Since the design and adjustment of penalty\nfunctions, which correspond to operational safety constraints, requires\nextensive domain knowledge in RL and power system operation, the emerging ADN\noperators call for a more flexible and customized approach to address the\npenalty functions so that the operational safety and efficiency can be further\nenhanced. Empowered with strong comprehension, reasoning, and in-context\nlearning capabilities, large language models (LLMs) provide a promising way to\nassist safe RL for energy management in ADNs. In this paper, we introduce the\nLLM to comprehend operational safety requirements in ADNs and generate\ncorresponding penalty functions. In addition, we propose an RL2 mechanism to\nrefine the generated functions iteratively and adaptively through multi-round\ndialogues, in which the LLM agent adjusts the functions' pattern and parameters\nbased on training and test performance of the downstream RL agent. The proposed\nmethod significantly reduces the intervention of the ADN operators.\nComprehensive test results demonstrate the effectiveness of the proposed\nmethod.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01303v1",
    "published_date": "2024-12-02 09:15:36 UTC",
    "updated_date": "2024-12-02 09:15:36 UTC"
  },
  {
    "arxiv_id": "2412.01295v1",
    "title": "FedAH: Aggregated Head for Personalized Federated Learning",
    "authors": [
      "Pengzhan Zhou",
      "Yuepeng He",
      "Yijun Zhai",
      "Kaixin Gao",
      "Chao Chen",
      "Zhida Qin",
      "Chong Zhang",
      "Songtao Guo"
    ],
    "abstract": "Recently, Federated Learning (FL) has gained popularity for its\nprivacy-preserving and collaborative learning capabilities. Personalized\nFederated Learning (PFL), building upon FL, aims to address the issue of\nstatistical heterogeneity and achieve personalization. Personalized-head-based\nPFL is a common and effective PFL method that splits the model into a feature\nextractor and a head, where the feature extractor is collaboratively trained\nand shared, while the head is locally trained and not shared. However,\nretaining the head locally, although achieving personalization, prevents the\nmodel from learning global knowledge in the head, thus affecting the\nperformance of the personalized model. To solve this problem, we propose a\nnovel PFL method called Federated Learning with Aggregated Head (FedAH), which\ninitializes the head with an Aggregated Head at each iteration. The key feature\nof FedAH is to perform element-level aggregation between the local model head\nand the global model head to introduce global information from the global model\nhead. To evaluate the effectiveness of FedAH, we conduct extensive experiments\non five benchmark datasets in the fields of computer vision and natural\nlanguage processing. FedAH outperforms ten state-of-the-art FL methods in terms\nof test accuracy by 2.87%. Additionally, FedAH maintains its advantage even in\nscenarios where some clients drop out unexpectedly. Our code is open-accessed\nat https://github.com/heyuepeng/FedAH.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01295v1",
    "published_date": "2024-12-02 09:08:51 UTC",
    "updated_date": "2024-12-02 09:08:51 UTC"
  },
  {
    "arxiv_id": "2412.01290v1",
    "title": "Learning Smooth Distance Functions via Queries",
    "authors": [
      "Akash Kumar",
      "Sanjoy Dasgupta"
    ],
    "abstract": "In this work, we investigate the problem of learning distance functions\nwithin the query-based learning framework, where a learner is able to pose\ntriplet queries of the form: ``Is $x_i$ closer to $x_j$ or $x_k$?'' We\nestablish formal guarantees on the query complexity required to learn smooth,\nbut otherwise general, distance functions under two notions of approximation:\n$\\omega$-additive approximation and $(1 + \\omega)$-multiplicative\napproximation. For the additive approximation, we propose a global method whose\nquery complexity is quadratic in the size of a finite cover of the sample\nspace. For the (stronger) multiplicative approximation, we introduce a method\nthat combines global and local approaches, utilizing multiple Mahalanobis\ndistance functions to capture local geometry. This method has a query\ncomplexity that scales quadratically with both the size of the cover and the\nambient space dimension of the sample space.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "40 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2412.01290v1",
    "published_date": "2024-12-02 09:03:05 UTC",
    "updated_date": "2024-12-02 09:03:05 UTC"
  },
  {
    "arxiv_id": "2412.01289v2",
    "title": "Enhancing Perception Capabilities of Multimodal LLMs with Training-Free Fusion",
    "authors": [
      "Zhuokun Chen",
      "Jinwu Hu",
      "Zeshuai Deng",
      "Yufeng Wang",
      "Bohan Zhuang",
      "Mingkui Tan"
    ],
    "abstract": "Multimodal LLMs (MLLMs) equip language models with visual capabilities by\naligning vision encoders with language models. Existing methods to enhance the\nvisual perception of MLLMs often involve designing more powerful vision\nencoders, which requires exploring a vast design space and re-aligning each\npotential encoder with the language model, resulting in prohibitively high\ntraining costs. In this paper, we introduce VisionFuse, a novel integration\nframework that efficiently utilizes multiple vision encoders from off-the-shelf\nMLLMs to enhance visual perception without requiring additional training. Our\napproach is motivated by the observation that different MLLMs tend to focus on\ndistinct regions given the same query and image. Moreover, we find that the\nfeature distributions of vision encoders within an MLLM family, a group of\nMLLMs sharing the same pretrained LLM, are highly aligned. Building on these\ninsights, VisionFuse enriches the visual context by concatenating the tokens\ngenerated by the vision encoders of selected MLLMs within a family. By merging\nthe parameters of language models from these MLLMs, VisionFuse allows a single\nlanguage model to align with various vision encoders, significantly reducing\ndeployment overhead. We conduct comprehensive evaluations across multiple\nmultimodal benchmarks using various MLLM combinations, demonstrating\nsubstantial improvements in multimodal tasks. Notably, when integrating\nMiniGemini-8B and SLIME-8B, VisionFuse achieves an average performance increase\nof over 4%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01289v2",
    "published_date": "2024-12-02 09:02:28 UTC",
    "updated_date": "2024-12-04 09:51:16 UTC"
  },
  {
    "arxiv_id": "2412.01284v2",
    "title": "MFTF: Mask-free Training-free Object Level Layout Control Diffusion Model",
    "authors": [
      "Shan Yang"
    ],
    "abstract": "Text-to-image generation models have revolutionized content creation, but\ndiffusion-based vision-language models still face challenges in precisely\ncontrolling the shape, appearance, and positional placement of objects in\ngenerated images using text guidance alone. Existing global image editing\nmodels rely on additional masks or images as guidance to achieve layout\ncontrol, often requiring retraining of the model. While local object-editing\nmodels allow modifications to object shapes, they lack the capability to\ncontrol object positions. To address these limitations, we propose the\nMask-free Training-free Object-Level Layout Control Diffusion Model (MFTF),\nwhich provides precise control over object positions without requiring\nadditional masks or images. The MFTF model supports both single-object and\nmulti-object positional adjustments, such as translation and rotation, while\nenabling simultaneous layout control and object semantic editing. The MFTF\nmodel employs a parallel denoising process for both the source and target\ndiffusion models. During this process, attention masks are dynamically\ngenerated from the cross-attention layers of the source diffusion model and\napplied to queries from the self-attention layers to isolate objects. These\nqueries, generated in the source diffusion model, are then adjusted according\nto the layout control parameters and re-injected into the self-attention layers\nof the target diffusion model. This approach ensures accurate and precise\npositional control of objects. Project source code available at\nhttps://github.com/syang-genai/MFTF.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01284v2",
    "published_date": "2024-12-02 08:56:13 UTC",
    "updated_date": "2024-12-18 01:56:53 UTC"
  },
  {
    "arxiv_id": "2412.01282v1",
    "title": "Align-KD: Distilling Cross-Modal Alignment Knowledge for Mobile Vision-Language Model",
    "authors": [
      "Qianhan Feng",
      "Wenshuo Li",
      "Tong Lin",
      "Xinghao Chen"
    ],
    "abstract": "Vision-Language Models (VLMs) bring powerful understanding and reasoning\ncapabilities to multimodal tasks. Meanwhile, the great need for capable\naritificial intelligence on mobile devices also arises, such as the AI\nassistant software. Some efforts try to migrate VLMs to edge devices to expand\ntheir application scope. Simplifying the model structure is a common method,\nbut as the model shrinks, the trade-off between performance and size becomes\nmore and more difficult. Knowledge distillation (KD) can help models improve\ncomprehensive capabilities without increasing size or data volume. However,\nmost of the existing large model distillation techniques only consider\napplications on single-modal LLMs, or only use teachers to create new data\nenvironments for students. None of these methods take into account the\ndistillation of the most important cross-modal alignment knowledge in VLMs. We\npropose a method called Align-KD to guide the student model to learn the\ncross-modal matching that occurs at the shallow layer. The teacher also helps\nstudent learn the projection of vision token into text embedding space based on\nthe focus of text. Under the guidance of Align-KD, the 1.7B MobileVLM V2 model\ncan learn rich knowledge from the 7B teacher model with light design of\ntraining loss, and achieve an average score improvement of 2.0 across 6\nbenchmarks under two training subsets respectively. Code is available at:\nhttps://github.com/fqhank/Align-KD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01282v1",
    "published_date": "2024-12-02 08:55:19 UTC",
    "updated_date": "2024-12-02 08:55:19 UTC"
  },
  {
    "arxiv_id": "2412.01281v1",
    "title": "FedPAW: Federated Learning with Personalized Aggregation Weights for Urban Vehicle Speed Prediction",
    "authors": [
      "Yuepeng He",
      "Pengzhan Zhou",
      "Yijun Zhai",
      "Fang Qu",
      "Zhida Qin",
      "Mingyan Li",
      "Songtao Guo"
    ],
    "abstract": "Vehicle speed prediction is crucial for intelligent transportation systems,\npromoting more reliable autonomous driving by accurately predicting future\nvehicle conditions. Due to variations in drivers' driving styles and vehicle\ntypes, speed predictions for different target vehicles may significantly\ndiffer. Existing methods may not realize personalized vehicle speed prediction\nwhile protecting drivers' data privacy. We propose a Federated learning\nframework with Personalized Aggregation Weights (FedPAW) to overcome these\nchallenges. This method captures client-specific information by measuring the\nweighted mean squared error between the parameters of local models and global\nmodels. The server sends tailored aggregated models to clients instead of a\nsingle global model, without incurring additional computational and\ncommunication overhead for clients. To evaluate the effectiveness of FedPAW, we\ncollected driving data in urban scenarios using the autonomous driving\nsimulator CARLA, employing an LSTM-based Seq2Seq model with a multi-head\nattention mechanism to predict the future speed of target vehicles. The results\ndemonstrate that our proposed FedPAW ranks lowest in prediction error within\nthe time horizon of 10 seconds, with a 0.8% reduction in test MAE, compared to\neleven representative benchmark baselines. The source code of FedPAW and\ndataset CarlaVSP are open-accessed at: https://github.com/heyuepeng/PFLlibVSP\nand https://pan.baidu.com/s/1qs8fxUvSPERV3C9i6pfUIw?pwd=tl3e.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01281v1",
    "published_date": "2024-12-02 08:54:43 UTC",
    "updated_date": "2024-12-02 08:54:43 UTC"
  },
  {
    "arxiv_id": "2412.01272v2",
    "title": "Uncertainty-Aware Artificial Intelligence for Gear Fault Diagnosis in Motor Drives",
    "authors": [
      "Subham Sahoo",
      "Huai Wang",
      "Frede Blaabjerg"
    ],
    "abstract": "This paper introduces a novel approach to quantify the uncertainties in fault\ndiagnosis of motor drives using Bayesian neural networks (BNN). Conventional\ndata-driven approaches used for fault diagnosis often rely on point-estimate\nneural networks, which merely provide deterministic outputs and fail to capture\nthe uncertainty associated with the inference process. In contrast, BNNs offer\na principled framework to model uncertainty by treating network weights as\nprobability distributions rather than fixed values. It offers several\nadvantages: (a) improved robustness to noisy data, (b) enhanced\ninterpretability of model predictions, and (c) the ability to quantify\nuncertainty in the decision-making processes. To test the robustness of the\nproposed BNN, it has been tested under a conservative dataset of gear fault\ndata from an experimental prototype of three fault types at first, and is then\nincrementally trained on new fault classes and datasets to explore its\nuncertainty quantification features and model interpretability under noisy data\nand unseen fault scenarios.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "The manuscript has been accepted for publication in 2025 IEEE Applied\n  Power Electronics Conference and Exposition (APEC)",
    "pdf_url": "http://arxiv.org/pdf/2412.01272v2",
    "published_date": "2024-12-02 08:38:20 UTC",
    "updated_date": "2024-12-13 09:50:35 UTC"
  },
  {
    "arxiv_id": "2412.01271v1",
    "title": "MuLan: Adapting Multilingual Diffusion Models for Hundreds of Languages with Negligible Cost",
    "authors": [
      "Sen Xing",
      "Muyan Zhong",
      "Zeqiang Lai",
      "Liangchen Li",
      "Jiawen Liu",
      "Yaohui Wang",
      "Jifeng Dai",
      "Wenhai Wang"
    ],
    "abstract": "In this work, we explore a cost-effective framework for multilingual image\ngeneration. We find that, unlike models tuned on high-quality images with\nmultilingual annotations, leveraging text encoders pre-trained on widely\navailable, noisy Internet image-text pairs significantly enhances data\nefficiency in text-to-image (T2I) generation across multiple languages. Based\non this insight, we introduce MuLan, Multi-Language adapter, a lightweight\nlanguage adapter with fewer than 20M parameters, trained alongside a frozen\ntext encoder and image diffusion model. Compared to previous multilingual T2I\nmodels, this framework offers: (1) Cost efficiency. Using readily accessible\nEnglish data and off-the-shelf multilingual text encoders minimizes the\ntraining cost; (2) High performance. Achieving comparable generation\ncapabilities in over 110 languages with CLIP similarity scores nearly matching\nthose in English (38.61 for English vs. 37.61 for other languages); and (3)\nBroad applicability. Seamlessly integrating with compatible community tools\nlike LoRA, LCM, ControlNet, and IP-Adapter, expanding its potential use cases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01271v1",
    "published_date": "2024-12-02 08:38:19 UTC",
    "updated_date": "2024-12-02 08:38:19 UTC"
  },
  {
    "arxiv_id": "2412.01269v5",
    "title": "CPRM: A LLM-based Continual Pre-training Framework for Relevance Modeling in Commercial Search",
    "authors": [
      "Kaixin Wu",
      "Yixin Ji",
      "Zeyuan Chen",
      "Qiang Wang",
      "Cunxiang Wang",
      "Hong Liu",
      "Baijun Ji",
      "Jia Xu",
      "Zhongyi Liu",
      "Jinjie Gu",
      "Yuan Zhou",
      "Linjian Mo"
    ],
    "abstract": "Relevance modeling between queries and items stands as a pivotal component in\ncommercial search engines, directly affecting the user experience. Given the\nremarkable achievements of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, LLM-based relevance modeling is gradually\nbeing adopted within industrial search systems. Nevertheless, foundational LLMs\nlack domain-specific knowledge and do not fully exploit the potential of\nin-context learning. Furthermore, structured item text remains underutilized,\nand there is a shortage in the supply of corresponding queries and background\nknowledge. We thereby propose CPRM (Continual Pre-training for Relevance\nModeling), a framework designed for the continual pre-training of LLMs to\naddress these issues. Our CPRM framework includes three modules: 1) employing\nboth queries and multi-field item to jointly pre-train for enhancing domain\nknowledge, 2) applying in-context pre-training, a novel approach where LLMs are\npre-trained on a sequence of related queries or items, and 3) conducting\nreading comprehension on items to produce associated domain knowledge and\nbackground information (e.g., generating summaries and corresponding queries)\nto further strengthen LLMs. Results on offline experiments and online A/B\ntesting demonstrate that our model achieves convincing performance compared to\nstrong baselines.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01269v5",
    "published_date": "2024-12-02 08:35:54 UTC",
    "updated_date": "2025-02-18 09:05:29 UTC"
  },
  {
    "arxiv_id": "2412.01265v1",
    "title": "Indexing Economic Fluctuation Narratives from Keiki Watchers Survey",
    "authors": [
      "Eriko Shigetsugu",
      "Hiroki Sakaji",
      "Itsuki Noda"
    ],
    "abstract": "In this paper, we design indices of economic fluctuation narratives derived\nfrom economic surveys. Companies, governments, and investors rely on key\nmetrics like GDP and industrial production indices to predict economic trends.\nHowever, they have yet to effectively leverage the wealth of information\ncontained in economic text, such as causal relationships, in their economic\nforecasting. Therefore, we design indices of economic fluctuation from economic\nsurveys by using our previously proposed narrative framework. From the\nevaluation results, it is observed that the proposed indices had a stronger\ncorrelation with cumulative lagging diffusion index than other types of\ndiffusion indices.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01265v1",
    "published_date": "2024-12-02 08:32:02 UTC",
    "updated_date": "2024-12-02 08:32:02 UTC"
  },
  {
    "arxiv_id": "2412.01262v2",
    "title": "Exploring ReAct Prompting for Task-Oriented Dialogue: Insights and Shortcomings",
    "authors": [
      "Michelle Elizabeth",
      "Morgan Veyret",
      "Miguel Couceiro",
      "Ondrej Dusek",
      "Lina M. Rojas-Barahona"
    ],
    "abstract": "Large language models (LLMs) gained immense popularity due to their\nimpressive capabilities in unstructured conversations. Empowering LLMs with\nadvanced prompting strategies such as reasoning and acting (ReAct) (Yao et al.,\n2022) has shown promise in solving complex tasks traditionally requiring\nreinforcement learning. In this work, we apply the ReAct strategy to guide LLMs\nperforming task-oriented dialogue (TOD). We evaluate ReAct-based LLMs\n(ReAct-LLMs) both in simulation and with real users. While ReAct-LLMs severely\nunderperform state-of-the-art approaches on success rate in simulation, this\ndifference becomes less pronounced in human evaluation. Moreover, compared to\nthe baseline, humans report higher subjective satisfaction with ReAct-LLM\ndespite its lower success rate, most likely thanks to its natural and\nconfidently phrased responses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01262v2",
    "published_date": "2024-12-02 08:30:22 UTC",
    "updated_date": "2025-03-17 10:01:21 UTC"
  },
  {
    "arxiv_id": "2412.01253v5",
    "title": "Yi-Lightning Technical Report",
    "authors": [
      "Alan Wake",
      "Bei Chen",
      "C. X. Lv",
      "Chao Li",
      "Chengen Huang",
      "Chenglin Cai",
      "Chujie Zheng",
      "Daniel Cooper",
      "Fan Zhou",
      "Feng Hu",
      "Ge Zhang",
      "Guoyin Wang",
      "Heng Ji",
      "Howard Qiu",
      "Jiangcheng Zhu",
      "Jun Tian",
      "Katherine Su",
      "Lihuan Zhang",
      "Liying Li",
      "Ming Song",
      "Mou Li",
      "Peng Liu",
      "Qicheng Hu",
      "Shawn Wang",
      "Shijun Zhou",
      "Shiming Yang",
      "Shiyong Li",
      "Tianhang Zhu",
      "Wen Xie",
      "Wenhao Huang",
      "Xiang He",
      "Xiaobo Chen",
      "Xiaohui Hu",
      "Xiaoyi Ren",
      "Xinyao Niu",
      "Yanpeng Li",
      "Yongke Zhao",
      "Yongzhen Luo",
      "Yuchi Xu",
      "Yuxuan Sha",
      "Zhaodong Yan",
      "Zhiyuan Liu",
      "Zirui Zhang",
      "Zonghong Dai"
    ],
    "abstract": "This technical report presents Yi-Lightning, our latest flagship large\nlanguage model (LLM). It achieves exceptional performance, ranking 6th overall\non Chatbot Arena, with particularly strong results (2nd to 4th place) in\nspecialized categories including Chinese, Math, Coding, and Hard Prompts.\nYi-Lightning leverages an enhanced Mixture-of-Experts (MoE) architecture,\nfeaturing advanced expert segmentation and routing mechanisms coupled with\noptimized KV-caching techniques. Our development process encompasses\ncomprehensive pre-training, supervised fine-tuning (SFT), and reinforcement\nlearning from human feedback (RLHF), where we devise deliberate strategies for\nmulti-stage training, synthetic data construction, and reward modeling.\nFurthermore, we implement RAISE (Responsible AI Safety Engine), a\nfour-component framework to address safety issues across pre-training,\npost-training, and serving phases. Empowered by our scalable super-computing\ninfrastructure, all these innovations substantially reduce training, deployment\nand inference costs while maintaining high-performance standards. With further\nevaluations on public academic benchmarks, Yi-Lightning demonstrates\ncompetitive performance against top-tier LLMs, while we observe a notable\ndisparity between traditional, static benchmark results and real-world, dynamic\nhuman preferences. This observation prompts a critical reassessment of\nconventional benchmarks' utility in guiding the development of more intelligent\nand powerful AI systems for practical applications. Yi-Lightning is now\navailable through our developer platform at https://platform.lingyiwanwu.com.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01253v5",
    "published_date": "2024-12-02 08:22:56 UTC",
    "updated_date": "2025-01-22 15:09:58 UTC"
  },
  {
    "arxiv_id": "2412.01250v3",
    "title": "Collaborative Instance Object Navigation: Leveraging Uncertainty-Awareness to Minimize Human-Agent Dialogues",
    "authors": [
      "Francesco Taioli",
      "Edoardo Zorzi",
      "Gianni Franchi",
      "Alberto Castellini",
      "Alessandro Farinelli",
      "Marco Cristani",
      "Yiming Wang"
    ],
    "abstract": "Language-driven instance object navigation assumes that human users initiate\nthe task by providing a detailed description of the target instance to the\nembodied agent. While this description is crucial for distinguishing the target\nfrom visually similar instances in a scene, providing it prior to navigation\ncan be demanding for human. To bridge this gap, we introduce Collaborative\nInstance object Navigation (CoIN), a new task setting where the agent actively\nresolve uncertainties about the target instance during navigation in natural,\ntemplate-free, open-ended dialogues with human. We propose a novel\ntraining-free method, Agent-user Interaction with UncerTainty Awareness\n(AIUTA), which operates independently from the navigation policy, and focuses\non the human-agent interaction reasoning with Vision-Language Models (VLMs) and\nLarge Language Models (LLMs). First, upon object detection, a Self-Questioner\nmodel initiates a self-dialogue within the agent to obtain a complete and\naccurate observation description with a novel uncertainty estimation technique.\nThen, an Interaction Trigger module determines whether to ask a question to the\nhuman, continue or halt navigation, minimizing user input. For evaluation, we\nintroduce CoIN-Bench, with a curated dataset designed for challenging\nmulti-instance scenarios. CoIN-Bench supports both online evaluation with\nhumans and reproducible experiments with simulated user-agent interactions. On\nCoIN-Bench, we show that AIUTA serves as a competitive baseline, while existing\nlanguage-driven instance navigation methods struggle in complex multi-instance\nscenes. Code and benchmark will be available upon acceptance at\nhttps://intelligolabs.github.io/CoIN/",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "https://intelligolabs.github.io/CoIN/",
    "pdf_url": "http://arxiv.org/pdf/2412.01250v3",
    "published_date": "2024-12-02 08:16:38 UTC",
    "updated_date": "2025-03-18 16:09:20 UTC"
  },
  {
    "arxiv_id": "2412.01245v1",
    "title": "Revisiting Generative Policies: A Simpler Reinforcement Learning Algorithmic Perspective",
    "authors": [
      "Jinouwen Zhang",
      "Rongkun Xue",
      "Yazhe Niu",
      "Yun Chen",
      "Jing Yang",
      "Hongsheng Li",
      "Yu Liu"
    ],
    "abstract": "Generative models, particularly diffusion models, have achieved remarkable\nsuccess in density estimation for multimodal data, drawing significant interest\nfrom the reinforcement learning (RL) community, especially in policy modeling\nin continuous action spaces. However, existing works exhibit significant\nvariations in training schemes and RL optimization objectives, and some methods\nare only applicable to diffusion models. In this study, we compare and analyze\nvarious generative policy training and deployment techniques, identifying and\nvalidating effective designs for generative policy algorithms. Specifically, we\nrevisit existing training objectives and classify them into two categories,\neach linked to a simpler approach. The first approach, Generative Model Policy\nOptimization (GMPO), employs a native advantage-weighted regression formulation\nas the training objective, which is significantly simpler than previous\nmethods. The second approach, Generative Model Policy Gradient (GMPG), offers a\nnumerically stable implementation of the native policy gradient method. We\nintroduce a standardized experimental framework named GenerativeRL. Our\nexperiments demonstrate that the proposed methods achieve state-of-the-art\nperformance on various offline-RL datasets, offering a unified and practical\nguideline for training and deploying generative policies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01245v1",
    "published_date": "2024-12-02 08:06:07 UTC",
    "updated_date": "2024-12-02 08:06:07 UTC"
  },
  {
    "arxiv_id": "2412.01243v3",
    "title": "Schedule On the Fly: Diffusion Time Prediction for Faster and Better Image Generation",
    "authors": [
      "Zilyu Ye",
      "Zhiyang Chen",
      "Tiancheng Li",
      "Zemin Huang",
      "Weijian Luo",
      "Guo-Jun Qi"
    ],
    "abstract": "Diffusion and flow matching models have achieved remarkable success in\ntext-to-image generation. However, these models typically rely on the\npredetermined denoising schedules for all prompts. The multi-step reverse\ndiffusion process can be regarded as a kind of chain-of-thought for generating\nhigh-quality images step by step. Therefore, diffusion models should reason for\neach instance to adaptively determine the optimal noise schedule, achieving\nhigh generation quality with sampling efficiency. In this paper, we introduce\nthe Time Prediction Diffusion Model (TPDM) for this. TPDM employs a\nplug-and-play Time Prediction Module (TPM) that predicts the next noise level\nbased on current latent features at each denoising step. We train the TPM using\nreinforcement learning to maximize a reward that encourages high final image\nquality while penalizing excessive denoising steps. With such an adaptive\nscheduler, TPDM not only generates high-quality images that are aligned closely\nwith human preferences but also adjusts diffusion time and the number of\ndenoising steps on the fly, enhancing both performance and efficiency. With\nStable Diffusion 3 Medium architecture, TPDM achieves an aesthetic score of\n5.44 and a human preference score (HPS) of 29.59, while using around 50% fewer\ndenoising steps to achieve better performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01243v3",
    "published_date": "2024-12-02 08:05:26 UTC",
    "updated_date": "2025-03-05 11:17:18 UTC"
  },
  {
    "arxiv_id": "2412.01233v1",
    "title": "Best Practices for Large Language Models in Radiology",
    "authors": [
      "Christian Bluethgen",
      "Dave Van Veen",
      "Cyril Zakka",
      "Katherine Link",
      "Aaron Fanous",
      "Roxana Daneshjou",
      "Thomas Frauenfelder",
      "Curtis Langlotz",
      "Sergios Gatidis",
      "Akshay Chaudhari"
    ],
    "abstract": "At the heart of radiological practice is the challenge of integrating complex\nimaging data with clinical information to produce actionable insights. Nuanced\napplication of language is key for various activities, including managing\nrequests, describing and interpreting imaging findings in the context of\nclinical data, and concisely documenting and communicating the outcomes. The\nemergence of large language models (LLMs) offers an opportunity to improve the\nmanagement and interpretation of the vast data in radiology. Despite being\nprimarily general-purpose, these advanced computational models demonstrate\nimpressive capabilities in specialized language-related tasks, even without\nspecific training. Unlocking the potential of LLMs for radiology requires basic\nunderstanding of their foundations and a strategic approach to navigate their\nidiosyncrasies. This review, drawing from practical radiology and machine\nlearning expertise and recent literature, provides readers insight into the\npotential of LLMs in radiology. It examines best practices that have so far\nstood the test of time in the rapidly evolving landscape of LLMs. This includes\npractical advice for optimizing LLM characteristics for radiology practices\nalong with limitations, effective prompting, and fine-tuning strategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "A redacted version of this preprint has been accepted for publication\n  in Radiology",
    "pdf_url": "http://arxiv.org/pdf/2412.01233v1",
    "published_date": "2024-12-02 07:54:55 UTC",
    "updated_date": "2024-12-02 07:54:55 UTC"
  },
  {
    "arxiv_id": "2412.01868v1",
    "title": "Composition of Experts: A Modular Compound AI System Leveraging Large Language Models",
    "authors": [
      "Swayambhoo Jain",
      "Ravi Raju",
      "Bo Li",
      "Zoltan Csaki",
      "Jonathan Li",
      "Kaizhao Liang",
      "Guoyao Feng",
      "Urmish Thakkar",
      "Anand Sampat",
      "Raghu Prabhakar",
      "Sumati Jairath"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable advancements, but their\nmonolithic nature presents challenges in terms of scalability, cost, and\ncustomization. This paper introduces the Composition of Experts (CoE), a\nmodular compound AI system leveraging multiple expert LLMs. CoE leverages a\nrouter to dynamically select the most appropriate expert for a given input,\nenabling efficient utilization of resources and improved performance. We\nformulate the general problem of training a CoE and discuss inherent\ncomplexities associated with it. We propose a two-step routing approach to\naddress these complexities that first uses a router to classify the input into\ndistinct categories followed by a category-to-expert mapping to obtain desired\nexperts. CoE offers a flexible and cost-effective solution to build compound AI\nsystems. Our empirical evaluation demonstrates the effectiveness of CoE in\nachieving superior performance with reduced computational overhead. Given that\nCoE comprises of many expert LLMs it has unique system requirements for\ncost-effective serving. We present an efficient implementation of CoE\nleveraging SambaNova SN40L RDUs unique three-tiered memory architecture. CoEs\nobtained using open weight LLMs Qwen/Qwen2-7B-Instruct, google/gemma-2-9b-it,\ngoogle/gemma-2-27b-it, meta-llama/Llama-3.1-70B-Instruct and\nQwen/Qwen2-72B-Instruct achieve a score of $59.4$ with merely $31$ billion\naverage active parameters on Arena-Hard and a score of $9.06$ with $54$ billion\naverage active parameters on MT-Bench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01868v1",
    "published_date": "2024-12-02 07:43:21 UTC",
    "updated_date": "2024-12-02 07:43:21 UTC"
  },
  {
    "arxiv_id": "2412.01223v1",
    "title": "PainterNet: Adaptive Image Inpainting with Actual-Token Attention and Diverse Mask Control",
    "authors": [
      "Ruichen Wang",
      "Junliang Zhang",
      "Qingsong Xie",
      "Chen Chen",
      "Haonan Lu"
    ],
    "abstract": "Recently, diffusion models have exhibited superior performance in the area of\nimage inpainting. Inpainting methods based on diffusion models can usually\ngenerate realistic, high-quality image content for masked areas. However, due\nto the limitations of diffusion models, existing methods typically encounter\nproblems in terms of semantic consistency between images and text, and the\nediting habits of users. To address these issues, we present PainterNet, a\nplugin that can be flexibly embedded into various diffusion models. To generate\nimage content in the masked areas that highly aligns with the user input\nprompt, we proposed local prompt input, Attention Control Points (ACP), and\nActual-Token Attention Loss (ATAL) to enhance the model's focus on local areas.\nAdditionally, we redesigned the MASK generation algorithm in training and\ntesting dataset to simulate the user's habit of applying MASK, and introduced a\ncustomized new training dataset, PainterData, and a benchmark dataset,\nPainterBench. Our extensive experimental analysis exhibits that PainterNet\nsurpasses existing state-of-the-art models in key metrics including image\nquality and global/local text consistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01223v1",
    "published_date": "2024-12-02 07:40:47 UTC",
    "updated_date": "2024-12-02 07:40:47 UTC"
  },
  {
    "arxiv_id": "2412.01218v1",
    "title": "FD-LLM: Large Language Model for Fault Diagnosis of Machines",
    "authors": [
      "Hamzah A. A. M. Qaid",
      "Bo Zhang",
      "Dan Li",
      "See-Kiong Ng",
      "Wei Li"
    ],
    "abstract": "Large language models (LLMs) are effective at capturing complex, valuable\nconceptual representations from textual data for a wide range of real-world\napplications. However, in fields like Intelligent Fault Diagnosis (IFD),\nincorporating additional sensor data-such as vibration signals, temperature\nreadings, and operational metrics-is essential but it is challenging to capture\nsuch sensor data information within traditional text corpora. This study\nintroduces a novel IFD approach by effectively adapting LLMs to numerical data\ninputs for identifying various machine faults from time-series sensor data. We\npropose FD-LLM, an LLM framework specifically designed for fault diagnosis by\nformulating the training of the LLM as a multi-class classification problem. We\nexplore two methods for encoding vibration signals: the first method uses a\nstring-based tokenization technique to encode vibration signals into text\nrepresentations, while the second extracts statistical features from both the\ntime and frequency domains as statistical summaries of each signal. We assess\nthe fault diagnosis capabilities of four open-sourced LLMs based on the FD-LLM\nframework, and evaluate the models' adaptability and generalizability under\nvarious operational conditions and machine components, namely for traditional\nfault diagnosis, cross-operational conditions, and cross-machine component\nsettings. Our results show that LLMs such as Llama3 and Llama3-instruct\ndemonstrate strong fault detection capabilities and significant adaptability\nacross different operational conditions, outperforming state-of-the-art deep\nlearning (DL) approaches in many cases.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 2 figures, 16 tables, including the tables in the appendix",
    "pdf_url": "http://arxiv.org/pdf/2412.01218v1",
    "published_date": "2024-12-02 07:36:35 UTC",
    "updated_date": "2024-12-02 07:36:35 UTC"
  },
  {
    "arxiv_id": "2412.01202v1",
    "title": "Neuron Abandoning Attention Flow: Visual Explanation of Dynamics inside CNN Models",
    "authors": [
      "Yi Liao",
      "Yongsheng Gao",
      "Weichuan Zhang"
    ],
    "abstract": "In this paper, we present a Neuron Abandoning Attention Flow (NAFlow) method\nto address the open problem of visually explaining the attention evolution\ndynamics inside CNNs when making their classification decisions. A novel\ncascading neuron abandoning back-propagation algorithm is designed to trace\nneurons in all layers of a CNN that involve in making its prediction to address\nthe problem of significant interference from abandoned neurons. Firstly, a\nNeuron Abandoning Back-Propagation (NA-BP) module is proposed to generate\nBack-Propagated Feature Maps (BPFM) by using the inverse function of the\nintermediate layers of CNN models, on which the neurons not used for\ndecision-making are abandoned. Meanwhile, the cascading NA-BP modules calculate\nthe tensors of importance coefficients which are linearly combined with the\ntensors of BPFMs to form the NAFlow. Secondly, to be able to visualize\nattention flow for similarity metric-based CNN models, a new channel\ncontribution weights module is proposed to calculate the importance\ncoefficients via Jacobian Matrix. The effectiveness of the proposed NAFlow is\nvalidated on nine widely-used CNN models for various tasks of general image\nclassification, contrastive learning classification, few-shot image\nclassification, and image retrieval.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01202v1",
    "published_date": "2024-12-02 07:14:15 UTC",
    "updated_date": "2024-12-02 07:14:15 UTC"
  },
  {
    "arxiv_id": "2412.01199v1",
    "title": "TinyFusion: Diffusion Transformers Learned Shallow",
    "authors": [
      "Gongfan Fang",
      "Kunjun Li",
      "Xinyin Ma",
      "Xinchao Wang"
    ],
    "abstract": "Diffusion Transformers have demonstrated remarkable capabilities in image\ngeneration but often come with excessive parameterization, resulting in\nconsiderable inference overhead in real-world applications. In this work, we\npresent TinyFusion, a depth pruning method designed to remove redundant layers\nfrom diffusion transformers via end-to-end learning. The core principle of our\napproach is to create a pruned model with high recoverability, allowing it to\nregain strong performance after fine-tuning. To accomplish this, we introduce a\ndifferentiable sampling technique to make pruning learnable, paired with a\nco-optimized parameter to simulate future fine-tuning. While prior works focus\non minimizing loss or error after pruning, our method explicitly models and\noptimizes the post-fine-tuning performance of pruned models. Experimental\nresults indicate that this learnable paradigm offers substantial benefits for\nlayer pruning of diffusion transformers, surpassing existing importance-based\nand error-based methods. Additionally, TinyFusion exhibits strong\ngeneralization across diverse architectures, such as DiTs, MARs, and SiTs.\nExperiments with DiT-XL show that TinyFusion can craft a shallow diffusion\ntransformer at less than 7% of the pre-training cost, achieving a 2$\\times$\nspeedup with an FID score of 2.86, outperforming competitors with comparable\nefficiency. Code is available at https://github.com/VainF/TinyFusion.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01199v1",
    "published_date": "2024-12-02 07:05:39 UTC",
    "updated_date": "2024-12-02 07:05:39 UTC"
  },
  {
    "arxiv_id": "2412.01197v2",
    "title": "InstantSwap: Fast Customized Concept Swapping across Sharp Shape Differences",
    "authors": [
      "Chenyang Zhu",
      "Kai Li",
      "Yue Ma",
      "Longxiang Tang",
      "Chengyu Fang",
      "Chubin Chen",
      "Qifeng Chen",
      "Xiu Li"
    ],
    "abstract": "Recent advances in Customized Concept Swapping (CCS) enable a text-to-image\nmodel to swap a concept in the source image with a customized target concept.\nHowever, the existing methods still face the challenges of inconsistency and\ninefficiency. They struggle to maintain consistency in both the foreground and\nbackground during concept swapping, especially when the shape difference is\nlarge between objects. Additionally, they either require time-consuming\ntraining processes or involve redundant calculations during inference. To\ntackle these issues, we introduce InstantSwap, a new CCS method that aims to\nhandle sharp shape disparity at speed. Specifically, we first extract the bbox\nof the object in the source image automatically based on attention map analysis\nand leverage the bbox to achieve both foreground and background consistency.\nFor background consistency, we remove the gradient outside the bbox during the\nswapping process so that the background is free from being modified. For\nforeground consistency, we employ a cross-attention mechanism to inject\nsemantic information into both source and target concepts inside the box. This\nhelps learn semantic-enhanced representations that encourage the swapping\nprocess to focus on the foreground objects. To improve swapping speed, we avoid\ncomputing gradients at each timestep but instead calculate them periodically to\nreduce the number of forward passes, which improves efficiency a lot with a\nlittle sacrifice on performance. Finally, we establish a benchmark dataset to\nfacilitate comprehensive evaluation. Extensive evaluations demonstrate the\nsuperiority and versatility of InstantSwap. Project Page:\nhttps://instantswap.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://instantswap.github.io/. Github Page:\n  https://github.com/chenyangzhu1/InstantSwap",
    "pdf_url": "http://arxiv.org/pdf/2412.01197v2",
    "published_date": "2024-12-02 06:59:52 UTC",
    "updated_date": "2024-12-03 03:16:54 UTC"
  },
  {
    "arxiv_id": "2412.01195v1",
    "title": "Memory-Efficient Training for Deep Speaker Embedding Learning in Speaker Verification",
    "authors": [
      "Bei Liu",
      "Yanmin Qian"
    ],
    "abstract": "Recent speaker verification (SV) systems have shown a trend toward adopting\ndeeper speaker embedding extractors. Although deeper and larger neural networks\ncan significantly improve performance, their substantial memory requirements\nhinder training on consumer GPUs. In this paper, we explore a memory-efficient\ntraining strategy for deep speaker embedding learning in resource-constrained\nscenarios. Firstly, we conduct a systematic analysis of GPU memory allocation\nduring SV system training. Empirical observations show that activations and\noptimizer states are the main sources of memory consumption. For activations,\nwe design two types of reversible neural networks which eliminate the need to\nstore intermediate activations during back-propagation, thereby significantly\nreducing memory usage without performance loss. For optimizer states, we\nintroduce a dynamic quantization approach that replaces the original 32-bit\nfloating-point values with a dynamic tree-based 8-bit data type. Experimental\nresults on VoxCeleb demonstrate that the reversible variants of ResNets and\nDF-ResNets can perform training without the need to cache activations in GPU\nmemory. In addition, the 8-bit versions of SGD and Adam save 75% of memory\ncosts while maintaining performance compared to their 32-bit counterparts.\nFinally, a detailed comparison of memory usage and performance indicates that\nour proposed models achieve up to 16.2x memory savings, with nearly identical\nparameters and performance compared to the vanilla systems. In contrast to the\nprevious need for multiple high-end GPUs such as the A100, we can effectively\ntrain deep speaker embedding extractors with just one or two consumer-level\n2080Ti GPUs.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing",
    "pdf_url": "http://arxiv.org/pdf/2412.01195v1",
    "published_date": "2024-12-02 06:57:46 UTC",
    "updated_date": "2024-12-02 06:57:46 UTC"
  },
  {
    "arxiv_id": "2412.01191v1",
    "title": "A Semantic Communication System for Real-time 3D Reconstruction Tasks",
    "authors": [
      "Jiaxing Zhang",
      "Luosong Guo",
      "Kun Zhu",
      "Houming Qiu"
    ],
    "abstract": "3D semantic maps have played an increasingly important role in high-precision\nrobot localization and scene understanding. However, real-time construction of\nsemantic maps requires mobile edge devices with extremely high computing power,\nwhich are expensive and limit the widespread application of semantic mapping.\nIn order to address this limitation, inspired by cloud-edge collaborative\ncomputing and the high transmission efficiency of semantic communication, this\npaper proposes a method to achieve real-time semantic mapping tasks with\nlimited-resource mobile devices. Specifically, we design an encoding-decoding\nsemantic communication framework for real-time semantic mapping tasks under\nlimited-resource situations. In addition, considering the impact of different\nchannel conditions on communication, this paper designs a module based on the\nattention mechanism to achieve stable data transmission under various channel\nconditions. In terms of simulation experiments, based on the TUM dataset, it\nwas verified that the system has an error of less than 0.1% compared to the\ngroundtruth in mapping and localization accuracy and is superior to some novel\nsemantic communication algorithms in real-time performance and channel\nadaptation. Besides, we implement a prototype system to verify the\neffectiveness of the proposed framework and designed module in real indoor\nscenarios. The results show that our system can complete real-time semantic\nmapping tasks for common indoor objects (chairs, computers, people, etc.) with\na limited-resource device, and the mapping update time is less than 1 second.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 11 figures, acceptted by 2024 8th International Conference\n  on Communication and Information Systems (ICCIS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.01191v1",
    "published_date": "2024-12-02 06:50:05 UTC",
    "updated_date": "2024-12-02 06:50:05 UTC"
  },
  {
    "arxiv_id": "2412.01181v1",
    "title": "Training Stiff Neural Ordinary Differential Equations with Explicit Exponential Integration Methods",
    "authors": [
      "Colby Fronk",
      "Linda Petzold"
    ],
    "abstract": "Stiff ordinary differential equations (ODEs) are common in many science and\nengineering fields, but standard neural ODE approaches struggle to accurately\nlearn these stiff systems, posing a significant barrier to widespread adoption\nof neural ODEs. In our earlier work, we addressed this challenge by utilizing\nsingle-step implicit methods for solving stiff neural ODEs. While effective,\nthese implicit methods are computationally costly and can be complex to\nimplement. This paper expands on our earlier work by exploring explicit\nexponential integration methods as a more efficient alternative. We evaluate\nthe potential of these explicit methods to handle stiff dynamics in neural\nODEs, aiming to enhance their applicability to a broader range of scientific\nand engineering problems. We found the integrating factor Euler (IF Euler)\nmethod to excel in stability and efficiency. While implicit schemes failed to\ntrain the stiff Van der Pol oscillator, the IF Euler method succeeded, even\nwith large step sizes. However, IF Euler's first-order accuracy limits its use,\nleaving the development of higher-order methods for stiff neural ODEs an open\nresearch problem.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "cs.SC"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01181v1",
    "published_date": "2024-12-02 06:40:08 UTC",
    "updated_date": "2024-12-02 06:40:08 UTC"
  },
  {
    "arxiv_id": "2412.01176v1",
    "title": "Superhypergraph Neural Networks and Plithogenic Graph Neural Networks: Theoretical Foundations",
    "authors": [
      "Takaaki Fujita"
    ],
    "abstract": "Hypergraphs extend traditional graphs by allowing edges to connect multiple\nnodes, while superhypergraphs further generalize this concept to represent even\nmore complex relationships. Neural networks, inspired by biological systems,\nare widely used for tasks such as pattern recognition, data classification, and\nprediction. Graph Neural Networks (GNNs), a well-established framework, have\nrecently been extended to Hypergraph Neural Networks (HGNNs), with their\nproperties and applications being actively studied. The Plithogenic Graph\nframework enhances graph representations by integrating multi-valued\nattributes, as well as membership and contradiction functions, enabling the\ndetailed modeling of complex relationships. In the context of handling\nuncertainty, concepts such as Fuzzy Graphs and Neutrosophic Graphs have gained\nprominence. It is well established that Plithogenic Graphs serve as a\ngeneralization of both Fuzzy Graphs and Neutrosophic Graphs. Furthermore, the\nFuzzy Graph Neural Network has been proposed and is an active area of research.\nThis paper establishes the theoretical foundation for the development of\nSuperHyperGraph Neural Networks (SHGNNs) and Plithogenic Graph Neural Networks,\nexpanding the applicability of neural networks to these advanced graph\nstructures. While mathematical generalizations and proofs are presented, future\ncomputational experiments are anticipated.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "math.CO",
      "math.LO",
      "05C65 - Hypergraphs, 05C82 - Graph theory with applications, 03E72 -\n  Fuzzy set theory"
    ],
    "primary_category": "cs.AI",
    "comment": "77 pages; 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01176v1",
    "published_date": "2024-12-02 06:33:02 UTC",
    "updated_date": "2024-12-02 06:33:02 UTC"
  },
  {
    "arxiv_id": "2412.01175v2",
    "title": "OBI-Bench: Can LMMs Aid in Study of Ancient Script on Oracle Bones?",
    "authors": [
      "Zijian Chen",
      "Tingzhu Chen",
      "Wenjun Zhang",
      "Guangtao Zhai"
    ],
    "abstract": "We introduce OBI-Bench, a holistic benchmark crafted to systematically\nevaluate large multi-modal models (LMMs) on whole-process oracle bone\ninscriptions (OBI) processing tasks demanding expert-level domain knowledge and\ndeliberate cognition. OBI-Bench includes 5,523 meticulously collected\ndiverse-sourced images, covering five key domain problems: recognition,\nrejoining, classification, retrieval, and deciphering. These images span\ncenturies of archaeological findings and years of research by front-line\nscholars, comprising multi-stage font appearances from excavation to synthesis,\nsuch as original oracle bone, inked rubbings, oracle bone fragments, cropped\nsingle characters, and handprinted characters. Unlike existing benchmarks,\nOBI-Bench focuses on advanced visual perception and reasoning with OBI-specific\nknowledge, challenging LMMs to perform tasks akin to those faced by experts.\nThe evaluation of 6 proprietary LMMs as well as 17 open-source LMMs highlights\nthe substantial challenges and demands posed by OBI-Bench. Even the latest\nversions of GPT-4o, Gemini 1.5 Pro, and Qwen-VL-Max are still far from\npublic-level humans in some fine-grained perception tasks. However, they\nperform at a level comparable to untrained humans in deciphering tasks,\nindicating remarkable capabilities in offering new interpretative perspectives\nand generating creative guesses. We hope OBI-Bench can facilitate the community\nto develop domain-specific multi-modal foundation models towards ancient\nlanguage research and delve deeper to discover and enhance these untapped\npotentials of LMMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025 as a Poster. 31 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.01175v2",
    "published_date": "2024-12-02 06:31:28 UTC",
    "updated_date": "2025-02-11 14:59:40 UTC"
  },
  {
    "arxiv_id": "2412.01166v2",
    "title": "Object Agnostic 3D Lifting in Space and Time",
    "authors": [
      "Christopher Fusco",
      "Shin-Fang Ch'ng",
      "Mosam Dabhi",
      "Simon Lucey"
    ],
    "abstract": "We present a spatio-temporal perspective on category-agnostic 3D lifting of\n2D keypoints over a temporal sequence. Our approach differs from existing\nstate-of-the-art methods that are either: (i) object-agnostic, but can only\noperate on individual frames, or (ii) can model space-time dependencies, but\nare only designed to work with a single object category. Our approach is\ngrounded in two core principles. First, general information about similar\nobjects can be leveraged to achieve better performance when there is little\nobject-specific training data. Second, a temporally-proximate context window is\nadvantageous for achieving consistency throughout a sequence. These two\nprinciples allow us to outperform current state-of-the-art methods on per-frame\nand per-sequence metrics for a variety of animal categories. Lastly, we release\na new synthetic dataset containing 3D skeletons and motion sequences for a\nvariety of animal categories.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "3DV 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01166v2",
    "published_date": "2024-12-02 06:09:46 UTC",
    "updated_date": "2025-02-10 02:39:44 UTC"
  },
  {
    "arxiv_id": "2412.01154v1",
    "title": "R.I.P.: A Simple Black-box Attack on Continual Test-time Adaptation",
    "authors": [
      "Trung-Hieu Hoang",
      "Duc Minh Vo",
      "Minh N. Do"
    ],
    "abstract": "Test-time adaptation (TTA) has emerged as a promising solution to tackle the\ncontinual domain shift in machine learning by allowing model parameters to\nchange at test time, via self-supervised learning on unlabeled testing data. At\nthe same time, it unfortunately opens the door to unforeseen vulnerabilities\nfor degradation over time. Through a simple theoretical continual TTA model, we\nsuccessfully identify a risk in the sampling process of testing data that could\neasily degrade the performance of a continual TTA model. We name this risk as\nReusing of Incorrect Prediction (RIP) that TTA attackers can employ or as a\nresult of the unintended query from general TTA users. The risk posed by RIP is\nalso highly realistic, as it does not require prior knowledge of model\nparameters or modification of testing samples. This simple requirement makes\nRIP as the first black-box TTA attack algorithm that stands out from existing\nwhite-box attempts. We extensively benchmark the performance of the most recent\ncontinual TTA approaches when facing the RIP attack, providing insights on its\nsuccess, and laying out potential roadmaps that could enhance the resilience of\nfuture continual TTA systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01154v1",
    "published_date": "2024-12-02 05:55:13 UTC",
    "updated_date": "2024-12-02 05:55:13 UTC"
  },
  {
    "arxiv_id": "2412.01150v2",
    "title": "Representation Learning for Time-Domain High-Energy Astrophysics: Discovery of Extragalactic Fast X-ray Transient XRT 200515",
    "authors": [
      "Steven Dillmann",
      "Juan Rafael Martínez-Galarza",
      "Roberto Soria",
      "Rosanne Di Stefano",
      "Vinay L. Kashyap"
    ],
    "abstract": "We present a novel representation learning method for downstream tasks like\nanomaly detection, unsupervised classification, and similarity searches in\nhigh-energy data sets. This enabled the discovery of a new extragalactic fast\nX-ray transient (FXT) in Chandra archival data, XRT 200515, a\nneedle-in-the-haystack event and the first Chandra FXT of its kind. Recent\nserendipitous discoveries in X-ray astronomy, including FXTs from binary\nneutron star mergers and an extragalactic planetary transit candidate,\nhighlight the need for systematic transient searches in X-ray archives. We\nintroduce new event file representations, E-t maps and E-t-dt cubes, that\neffectively encode both temporal and spectral information, enabling the\nseamless application of machine learning to variable-length event file time\nseries. Our unsupervised learning approach employs PCA or sparse autoencoders\nto extract low-dimensional, informative features from these data\nrepresentations, followed by clustering in the embedding space with DBSCAN. New\ntransients are identified within transient-dominant clusters or through\nnearest-neighbour searches around known transients, producing a catalogue of\n3559 candidates (3447 flares and 112 dips). XRT 200515 exhibits unique temporal\nand spectral variability, including an intense, hard <10s initial burst,\nfollowed by spectral softening in an ~800s oscillating tail. We interpret XRT\n200515 as either the first giant magnetar flare observed at low X-ray energies\nor the first extragalactic Type I X-ray burst from a faint, previously unknown\nlow-mass X-ray binary in the LMC. Our method extends to data sets from other\nobservatories such as XMM-Newton, Swift-XRT, eROSITA, Einstein Probe, and\nupcoming missions like AXIS.",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.HE",
    "comment": "25 pages, accepted in Monthly Notices of the Royal Astronomical\n  Society",
    "pdf_url": "http://arxiv.org/pdf/2412.01150v2",
    "published_date": "2024-12-02 05:48:31 UTC",
    "updated_date": "2025-03-04 04:31:11 UTC"
  },
  {
    "arxiv_id": "2412.01129v3",
    "title": "RILQ: Rank-Insensitive LoRA-based Quantization Error Compensation for Boosting 2-bit Large Language Model Accuracy",
    "authors": [
      "Geonho Lee",
      "Janghwan Lee",
      "Sukjin Hong",
      "Minsoo Kim",
      "Euijai Ahn",
      "Du-Seong Chang",
      "Jungwook Choi"
    ],
    "abstract": "Low-rank adaptation (LoRA) has become the dominant method for\nparameter-efficient LLM fine-tuning, with LoRA-based quantization error\ncompensation (LQEC) emerging as a powerful tool for recovering accuracy in\ncompressed LLMs. However, LQEC has underperformed in sub-4-bit scenarios, with\nno prior investigation into understanding this limitation. We propose RILQ\n(Rank-Insensitive LoRA-based Quantization Error Compensation) to understand\nfundamental limitation and boost 2-bit LLM accuracy. Based on rank analysis\nrevealing model-wise activation discrepancy loss's rank-insensitive nature,\nRILQ employs this loss to adjust adapters cooperatively across layers, enabling\nrobust error compensation with low-rank adapters. Evaluations on LLaMA-2 and\nLLaMA-3 demonstrate RILQ's consistent improvements in 2-bit quantized inference\nacross various state-of-the-art quantizers and enhanced accuracy in\ntask-specific fine-tuning. RILQ maintains computational efficiency comparable\nto existing LoRA methods, enabling adapter-merged weight-quantized LLM\ninference with significantly enhanced accuracy, making it a promising approach\nfor boosting 2-bit LLM performance. Our code is available at\nhttps://github.com/aiha-lab/RILQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01129v3",
    "published_date": "2024-12-02 05:09:56 UTC",
    "updated_date": "2025-03-28 04:40:20 UTC"
  },
  {
    "arxiv_id": "2412.01122v1",
    "title": "TAS-TsC: A Data-Driven Framework for Estimating Time of Arrival Using Temporal-Attribute-Spatial Tri-space Coordination of Truck Trajectories",
    "authors": [
      "Mengran Li",
      "Junzhou Chen",
      "Guanying Jiang",
      "Fuliang Li",
      "Ronghui Zhang",
      "Siyuan Gong",
      "Zhihan Lv"
    ],
    "abstract": "Accurately estimating time of arrival (ETA) for trucks is crucial for\noptimizing transportation efficiency in logistics. GPS trajectory data offers\nvaluable information for ETA, but challenges arise due to temporal sparsity,\nvariable sequence lengths, and the interdependencies among multiple trucks. To\naddress these issues, we propose the Temporal-Attribute-Spatial Tri-space\nCoordination (TAS-TsC) framework, which leverages three feature\nspaces-temporal, attribute, and spatial-to enhance ETA. Our framework consists\nof a Temporal Learning Module (TLM) using state space models to capture\ntemporal dependencies, an Attribute Extraction Module (AEM) that transforms\nsequential features into structured attribute embeddings, and a Spatial Fusion\nModule (SFM) that models the interactions among multiple trajectories using\ngraph representation learning.These modules collaboratively learn trajectory\nembeddings, which are then used by a Downstream Prediction Module (DPM) to\nestimate arrival times. We validate TAS-TsC on real truck trajectory datasets\ncollected from Shenzhen, China, demonstrating its superior performance compared\nto existing methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01122v1",
    "published_date": "2024-12-02 04:58:48 UTC",
    "updated_date": "2024-12-02 04:58:48 UTC"
  },
  {
    "arxiv_id": "2412.01119v1",
    "title": "Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements",
    "authors": [
      "Mojtaba S. Fazli",
      "Shannon Quinn"
    ],
    "abstract": "Object tracking is a fundamental tool in modern innovation, with applications\nin defense systems, autonomous vehicles, and biomedical research. It enables\nprecise identification, monitoring, and spatiotemporal analysis of objects\nacross sequential frames, providing insights into dynamic behaviors. In cell\nbiology, object tracking is vital for uncovering cellular mechanisms, such as\nmigration, interactions, and responses to drugs or pathogens. These insights\ndrive breakthroughs in understanding disease progression and therapeutic\ninterventions.\n  Over time, object tracking methods have evolved from traditional\nfeature-based approaches to advanced machine learning and deep learning\nframeworks. While classical methods are reliable in controlled settings, they\nstruggle in complex environments with occlusions, variable lighting, and high\nobject density. Deep learning models address these challenges by delivering\ngreater accuracy, adaptability, and robustness.\n  This review categorizes object tracking techniques into traditional,\nstatistical, feature-based, and machine learning paradigms, with a focus on\nbiomedical applications. These methods are essential for tracking cells and\nsubcellular structures, advancing our understanding of health and disease. Key\nperformance metrics, including accuracy, efficiency, and adaptability, are\ndiscussed. The paper explores limitations of current methods and highlights\nemerging trends to guide the development of next-generation tracking systems\nfor biomedical research and broader scientific domains.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "56 Pages",
    "pdf_url": "http://arxiv.org/pdf/2412.01119v1",
    "published_date": "2024-12-02 04:43:50 UTC",
    "updated_date": "2024-12-02 04:43:50 UTC"
  },
  {
    "arxiv_id": "2412.01096v1",
    "title": "How the use of feature selection methods influences the efficiency and accuracy of complex network simulations",
    "authors": [
      "Katarzyna Musial",
      "Jiaqi Wen",
      "Andreas Gwyther-Gouriotis"
    ],
    "abstract": "Complex network systems' models are designed to perfectly emulate real-world\nnetworks through the use of simulation and link prediction. Complex network\nsystems are defined by nodes and their connections where both have real-world\nfeatures that result in a heterogeneous network in which each of the nodes has\ndistinct characteristics. Thus, incorporating real-world features is an\nimportant component to achieve a simulation which best represents the\nreal-world. Currently very few complex network systems implement real-world\nfeatures, thus this study proposes feature selection methods which utilise\nunsupervised filtering techniques to rank real-world node features alongside a\nwrapper function to test combinations of the ranked features. The chosen method\nwas coined FS-SNS which improved 8 out of 10 simulations of real-world\nnetworks. A consistent threshold of included features was also discovered which\nsaw a threshold of 4 features to achieve the most accurate simulation for all\nnetworks. Through these findings the study also proposes future work and\ndiscusses how the findings can be used to further the Digital Twin and complex\nnetwork system field.",
    "categories": [
      "cs.AI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01096v1",
    "published_date": "2024-12-02 04:12:53 UTC",
    "updated_date": "2024-12-02 04:12:53 UTC"
  },
  {
    "arxiv_id": "2412.01094v1",
    "title": "A Hierarchical Heuristic for Clustered Steiner Trees in the Plane with Obstacles",
    "authors": [
      "Victor Parque"
    ],
    "abstract": "Euclidean Steiner trees are relevant to model minimal networks in real-world\napplications ubiquitously. In this paper, we study the feasibility of a\nhierarchical approach embedded with bundling operations to compute multiple and\nmutually disjoint Euclidean Steiner trees that avoid clutter and overlapping\nwith obstacles in the plane, which is significant to model the decentralized\nand the multipoint coordination of agents in constrained 2D domains. Our\ncomputational experiments using arbitrary obstacle configuration with convex\nand non-convex geometries show the feasibility and the attractive performance\nwhen computing multiple obstacle-avoiding Steiner trees in the plane. Our\nresults offer the mechanisms to elucidate new operators for obstacle-avoiding\nSteiner trees.",
    "categories": [
      "cs.AI",
      "cs.CG",
      "cs.NE",
      "cs.RO",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "Article accepted/presented as Long Paper at The Twelfth International\n  Symposium on Computing and Networking (CANDAR2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.01094v1",
    "published_date": "2024-12-02 04:10:14 UTC",
    "updated_date": "2024-12-02 04:10:14 UTC"
  },
  {
    "arxiv_id": "2412.01095v3",
    "title": "VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models",
    "authors": [
      "Muchao Ye",
      "Weiyang Liu",
      "Pan He"
    ],
    "abstract": "The rapid advancement of vision-language models (VLMs) has established a new\nparadigm in video anomaly detection (VAD): leveraging VLMs to simultaneously\ndetect anomalies and provide comprehendible explanations for the decisions.\nExisting work in this direction often assumes the complex reasoning required\nfor VAD exceeds the capabilities of pretrained VLMs. Consequently, these\napproaches either incorporate specialized reasoning modules during inference or\nrely on instruction tuning datasets through additional training to adapt VLMs\nfor VAD. However, such strategies often incur substantial computational costs\nor data annotation overhead. To address these challenges in explainable VAD, we\nintroduce a verbalized learning framework named VERA that enables VLMs to\nperform VAD without model parameter modifications. Specifically, VERA\nautomatically decomposes the complex reasoning required for VAD into\nreflections on simpler, more focused guiding questions capturing distinct\nabnormal patterns. It treats these reflective questions as learnable parameters\nand optimizes them through data-driven verbal interactions between learner and\noptimizer VLMs, using coarsely labeled training data. During inference, VERA\nembeds the learned questions into model prompts to guide VLMs in generating\nsegment-level anomaly scores, which are then refined into frame-level scores\nvia the fusion of scene and temporal contexts. Experimental results on\nchallenging benchmarks demonstrate that the learned questions of VERA are\nhighly adaptable, significantly improving both detection performance and\nexplainability of VLMs for VAD.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.01095v3",
    "published_date": "2024-12-02 04:10:14 UTC",
    "updated_date": "2025-03-31 20:17:27 UTC"
  },
  {
    "arxiv_id": "2412.01082v1",
    "title": "A Hybrid Evolutionary Approach for Multi Robot Coordinated Planning at Intersections",
    "authors": [
      "Victor Parque"
    ],
    "abstract": "Coordinated multi-robot motion planning at intersections is key for safe\nmobility in roads, factories and warehouses. The rapidly exploring random tree\n(RRT) algorithms are popular in multi-robot motion planning. However,\ngenerating the graph configuration space and searching in the composite tensor\nconfiguration space is computationally expensive for large number of sample\npoints. In this paper, we propose a new evolutionary-based algorithm using a\nparametric lattice-based configuration and the discrete-based RRT for\ncollision-free multi-robot planning at intersections. Our computational\nexperiments using complex planning intersection scenarios have shown the\nfeasibility and the superiority of the proposed algorithm compared to seven\nother related approaches. Our results offer new sampling and representation\nmechanisms to render optimization-based approaches for multi-robot navigation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.NE",
      "math.OC",
      "stat.CO"
    ],
    "primary_category": "cs.RO",
    "comment": "Paper accepted/presented as a regular paper at The Twelfth\n  International Symposium on Computing and Networking (CANDAR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.01082v1",
    "published_date": "2024-12-02 03:40:04 UTC",
    "updated_date": "2024-12-02 03:40:04 UTC"
  },
  {
    "arxiv_id": "2412.01078v2",
    "title": "Advancing Speech Language Models by Scaling Supervised Fine-Tuning with Over 60,000 Hours of Synthetic Speech Dialogue Data",
    "authors": [
      "Shuaijiang Zhao",
      "Tingwei Guo",
      "Bajian Xiang",
      "Tongtang Wan",
      "Qiang Niu",
      "Wei Zou",
      "Xiangang Li"
    ],
    "abstract": "The GPT-4o represents a significant milestone in enabling real-time\ninteraction with large language models (LLMs) through speech, its remarkable\nlow latency and high fluency not only capture attention but also stimulate\nresearch interest in the field. This real-time speech interaction is\nparticularly valuable in scenarios requiring rapid feedback and immediate\nresponses, dramatically enhancing user experience. However, there is a notable\nlack of research focused on real-time large speech language models,\nparticularly for Chinese. In this work, we present KE-Omni, a seamless large\nspeech language model built upon Ke-SpeechChat, a large-scale high-quality\nsynthetic speech interaction dataset consisting of 7 million Chinese and\nEnglish conversations, featuring 42,002 speakers, and totaling over 60,000\nhours, This contributes significantly to the advancement of research and\ndevelopment in this field. The demos can be accessed at\n\\url{https://huggingface.co/spaces/KE-Team/KE-Omni}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "KE-Omni, Ke-SpeechChat",
    "pdf_url": "http://arxiv.org/pdf/2412.01078v2",
    "published_date": "2024-12-02 03:31:46 UTC",
    "updated_date": "2024-12-03 02:59:43 UTC"
  },
  {
    "arxiv_id": "2412.01075v1",
    "title": "Multi-Agent Deep Reinforcement Learning for Distributed and Autonomous Platoon Coordination via Speed-regulation over Large-scale Transportation Networks",
    "authors": [
      "Dixiao Wei",
      "Peng Yi",
      "Jinlong Lei",
      "Xingyi Zhu"
    ],
    "abstract": "Truck platooning technology enables a group of trucks to travel closely\ntogether, with which the platoon can save fuel, improve traffic flow\nefficiency, and improve safety. In this paper, we consider the platoon\ncoordination problem in a large-scale transportation network, to promote\ncooperation among trucks and optimize the overall efficiency. Involving the\nregulation of both speed and departure times at hubs, we formulate the\ncoordination problem as a complicated dynamic stochastic integer programming\nunder network and information constraints. To get an autonomous, distributed,\nand robust platoon coordination policy, we formulate the problem into a model\nof the Decentralized-Partial Observable Markov Decision Process. Then, we\npropose a Multi-Agent Deep Reinforcement Learning framework named Trcuk\nAttention-QMIX (TA-QMIX) to train an efficient online decision policy. TA-QMIX\nutilizes the attention mechanism to enhance the representation of truck fuel\ngains and delay times, and provides explicit truck cooperation information\nduring the training process, promoting trucks' willingness to cooperate. The\ntraining framework adopts centralized training and distributed execution, thus\ntraining a policy for trucks to make decisions online using only nearby\ninformation. Hence, the policy can be autonomously executed on a large-scale\nnetwork. Finally, we perform comparison experiments and ablation experiments in\nthe transportation network of the Yangtze River Delta region in China to verify\nthe effectiveness of the proposed framework. In a repeated comparative\nexperiment with 5,000 trucks, our method average saves 19.17\\% of fuel with an\naverage delay of only 9.57 minutes per truck and a decision time of 0.001\nseconds.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01075v1",
    "published_date": "2024-12-02 03:21:40 UTC",
    "updated_date": "2024-12-02 03:21:40 UTC"
  },
  {
    "arxiv_id": "2412.01065v1",
    "title": "Lookahead Counterfactual Fairness",
    "authors": [
      "Zhiqun Zuo",
      "Tian Xie",
      "Xuwei Tan",
      "Xueru Zhang",
      "Mohammad Mahdi Khalili"
    ],
    "abstract": "As machine learning (ML) algorithms are used in applications that involve\nhumans, concerns have arisen that these algorithms may be biased against\ncertain social groups. \\textit{Counterfactual fairness} (CF) is a fairness\nnotion proposed in Kusner et al. (2017) that measures the unfairness of ML\npredictions; it requires that the prediction perceived by an individual in the\nreal world has the same marginal distribution as it would be in a\ncounterfactual world, in which the individual belongs to a different group.\nAlthough CF ensures fair ML predictions, it fails to consider the downstream\neffects of ML predictions on individuals. Since humans are strategic and often\nadapt their behaviors in response to the ML system, predictions that satisfy CF\nmay not lead to a fair future outcome for the individuals. In this paper, we\nintroduce \\textit{lookahead counterfactual fairness} (LCF), a fairness notion\naccounting for the downstream effects of ML models which requires the\nindividual \\textit{future status} to be counterfactually fair. We theoretically\nidentify conditions under which LCF can be satisfied and propose an algorithm\nbased on the theorems. We also extend the concept to path-dependent fairness.\nExperiments on both synthetic and real data validate the proposed method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01065v1",
    "published_date": "2024-12-02 02:53:14 UTC",
    "updated_date": "2024-12-02 02:53:14 UTC"
  },
  {
    "arxiv_id": "2412.01064v2",
    "title": "FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait",
    "authors": [
      "Taekyung Ki",
      "Dongchan Min",
      "Gyeongsu Chae"
    ],
    "abstract": "With the rapid advancement of diffusion-based generative models, portrait\nimage animation has achieved remarkable results. However, it still faces\nchallenges in temporally consistent video generation and fast sampling due to\nits iterative sampling nature. This paper presents FLOAT, an audio-driven\ntalking portrait video generation method based on flow matching generative\nmodel. We shift the generative modeling from the pixel-based latent space to a\nlearned motion latent space, enabling efficient design of temporally consistent\nmotion. To achieve this, we introduce a transformer-based vector field\npredictor with a simple yet effective frame-wise conditioning mechanism.\nAdditionally, our method supports speech-driven emotion enhancement, enabling a\nnatural incorporation of expressive motions. Extensive experiments demonstrate\nthat our method outperforms state-of-the-art audio-driven talking portrait\nmethods in terms of visual quality, motion fidelity, and efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://deepbrainai-research.github.io/float/",
    "pdf_url": "http://arxiv.org/pdf/2412.01064v2",
    "published_date": "2024-12-02 02:50:07 UTC",
    "updated_date": "2024-12-04 09:43:18 UTC"
  },
  {
    "arxiv_id": "2501.07839v1",
    "title": "Social Media Data Mining With Natural Language Processing on Public Dream Contents",
    "authors": [
      "Howard Hua",
      "Joe Yu"
    ],
    "abstract": "The COVID-19 pandemic has significantly transformed global lifestyles,\nenforcing physical isolation and accelerating digital adoption for work,\neducation, and social interaction. This study examines the pandemic's impact on\nmental health by analyzing dream content shared on the Reddit r/Dreams\ncommunity. With over 374,000 subscribers, this platform offers a rich dataset\nfor exploring subconscious responses to the pandemic. Using statistical\nmethods, we assess shifts in dream positivity, negativity, and neutrality from\nthe pre-pandemic to post-pandemic era. To enhance our analysis, we fine-tuned\nthe LLaMA 3.1-8B model with labeled data, enabling precise sentiment\nclassification of dream content. Our findings aim to uncover patterns in dream\ncontent, providing insights into the psychological effects of the pandemic and\nits influence on subconscious processes. This research highlights the profound\nchanges in mental landscapes and the role of dreams as indicators of public\nwell-being during unprecedented times.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.SI",
      "I.2.7"
    ],
    "primary_category": "cs.CY",
    "comment": "16 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.07839v1",
    "published_date": "2024-12-02 02:34:02 UTC",
    "updated_date": "2024-12-02 02:34:02 UTC"
  },
  {
    "arxiv_id": "2412.01039v2",
    "title": "Reducing Inference Energy Consumption Using Dual Complementary CNNs",
    "authors": [
      "Michail Kinnas",
      "John Violos",
      "Ioannis Kompatsiaris",
      "Symeon Papadopoulos"
    ],
    "abstract": "Energy efficiency of Convolutional Neural Networks (CNNs) has become an\nimportant area of research, with various strategies being developed to minimize\nthe power consumption of these models. Previous efforts, including techniques\nlike model pruning, quantization, and hardware optimization, have made\nsignificant strides in this direction. However, there remains a need for more\neffective on device AI solutions that balance energy efficiency with model\nperformance. In this paper, we propose a novel approach to reduce the energy\nrequirements of inference of CNNs. Our methodology employs two small\nComplementary CNNs that collaborate with each other by covering each other's\n\"weaknesses\" in predictions. If the confidence for a prediction of the first\nCNN is considered low, the second CNN is invoked with the aim of producing a\nhigher confidence prediction. This dual-CNN setup significantly reduces energy\nconsumption compared to using a single large deep CNN. Additionally, we propose\na memory component that retains previous classifications for identical inputs,\nbypassing the need to re-invoke the CNNs for the same input, further saving\nenergy. Our experiments on a Jetson Nano computer demonstrate an energy\nreduction of up to 85.8% achieved on modified datasets where each sample was\nduplicated once. These findings indicate that leveraging a complementary CNN\npair along with a memory component effectively reduces inference energy while\nmaintaining high accuracy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01039v2",
    "published_date": "2024-12-02 01:46:07 UTC",
    "updated_date": "2024-12-11 06:22:34 UTC"
  },
  {
    "arxiv_id": "2412.01031v2",
    "title": "Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings",
    "authors": [
      "Razi Mahmood",
      "Pingkun Yan",
      "Diego Machado Reyes",
      "Ge Wang",
      "Mannudeep K. Kalra",
      "Parisa Kaviani",
      "Joy T. Wu",
      "Tanveer Syeda-Mahmood"
    ],
    "abstract": "Several evaluation metrics have been developed recently to automatically\nassess the quality of generative AI reports for chest radiographs based only on\ntextual information using lexical, semantic, or clinical named entity\nrecognition methods. In this paper, we develop a new method of report quality\nevaluation by first extracting fine-grained finding patterns capturing the\nlocation, laterality, and severity of a large number of clinical findings. We\nthen performed phrasal grounding to localize their associated anatomical\nregions on chest radiograph images. The textual and visual measures are then\ncombined to rate the quality of the generated reports. We present results that\ncompare this evaluation metric with other textual metrics on a gold standard\ndataset derived from the MIMIC collection and show its robustness and\nsensitivity to factual errors.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01031v2",
    "published_date": "2024-12-02 01:27:47 UTC",
    "updated_date": "2024-12-07 23:21:54 UTC"
  },
  {
    "arxiv_id": "2412.01020v1",
    "title": "AI Benchmarks and Datasets for LLM Evaluation",
    "authors": [
      "Todor Ivanov",
      "Valeri Penchev"
    ],
    "abstract": "LLMs demand significant computational resources for both pre-training and\nfine-tuning, requiring distributed computing capabilities due to their large\nmodel sizes \\cite{sastry2024computing}. Their complex architecture poses\nchallenges throughout the entire AI lifecycle, from data collection to\ndeployment and monitoring \\cite{OECD_AIlifecycle}. Addressing critical AI\nsystem challenges, such as explainability, corrigibility, interpretability, and\nhallucination, necessitates a systematic methodology and rigorous benchmarking\n\\cite{guldimann2024complai}. To effectively improve AI systems, we must\nprecisely identify systemic vulnerabilities through quantitative evaluation,\nbolstering system trustworthiness. The enactment of the EU AI Act\n\\cite{EUAIAct} by the European Parliament on March 13, 2024, establishing the\nfirst comprehensive EU-wide requirements for the development, deployment, and\nuse of AI systems, further underscores the importance of tools and\nmethodologies such as Z-Inspection. It highlights the need to enrich this\nmethodology with practical benchmarks to effectively address the technical\nchallenges posed by AI systems. To this end, we have launched a project that is\npart of the AI Safety Bulgaria initiatives \\cite{AI_Safety_Bulgaria}, aimed at\ncollecting and categorizing AI benchmarks. This will enable practitioners to\nidentify and utilize these benchmarks throughout the AI system lifecycle.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "November 2024 v1.0",
    "pdf_url": "http://arxiv.org/pdf/2412.01020v1",
    "published_date": "2024-12-02 00:38:57 UTC",
    "updated_date": "2024-12-02 00:38:57 UTC"
  },
  {
    "arxiv_id": "2412.01014v1",
    "title": "Detecting Memorization in Large Language Models",
    "authors": [
      "Eduardo Slonski"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive results in natural\nlanguage processing but are prone to memorizing portions of their training\ndata, which can compromise evaluation metrics, raise privacy concerns, and\nlimit generalization. Traditional methods for detecting memorization rely on\noutput probabilities or loss functions, often lacking precision due to\nconfounding factors like common language patterns. In this paper, we introduce\nan analytical method that precisely detects memorization by examining neuron\nactivations within the LLM. By identifying specific activation patterns that\ndifferentiate between memorized and not memorized tokens, we train\nclassification probes that achieve near-perfect accuracy. The approach can also\nbe applied to other mechanisms, such as repetition, as demonstrated in this\nstudy, highlighting its versatility. Intervening on these activations allows us\nto suppress memorization without degrading overall performance, enhancing\nevaluation integrity by ensuring metrics reflect genuine generalization.\nAdditionally, our method supports large-scale labeling of tokens and sequences,\ncrucial for next-generation AI models, improving training efficiency and\nresults. Our findings contribute to model interpretability and offer practical\ntools for analyzing and controlling internal mechanisms in LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01014v1",
    "published_date": "2024-12-02 00:17:43 UTC",
    "updated_date": "2024-12-02 00:17:43 UTC"
  }
]