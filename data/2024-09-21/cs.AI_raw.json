[
  {
    "arxiv_id": "2409.14237v1",
    "title": "An Instance-based Plus Ensemble Learning Method for Classification of Scientific Papers",
    "authors": [
      "Fang Zhang",
      "Shengli Wu"
    ],
    "abstract": "The exponential growth of scientific publications in recent years has posed a\nsignificant challenge in effective and efficient categorization. This paper\nintroduces a novel approach that combines instance-based learning and ensemble\nlearning techniques for classifying scientific papers into relevant research\nfields. Working with a classification system with a group of research fields,\nfirst a number of typical seed papers are allocated to each of the fields\nmanually. Then for each paper that needs to be classified, we compare it with\nall the seed papers in every field. Contents and citations are considered\nseparately. An ensemble-based method is then employed to make the final\ndecision. Experimenting with the datasets from DBLP, our experimental results\ndemonstrate that the proposed classification method is effective and efficient\nin categorizing papers into various research areas. We also find that both\ncontent and citation features are useful for the classification of scientific\npapers.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14237v1",
    "published_date": "2024-09-21 19:42:15 UTC",
    "updated_date": "2024-09-21 19:42:15 UTC"
  },
  {
    "arxiv_id": "2409.14231v1",
    "title": "Predicting Coronary Heart Disease Using a Suite of Machine Learning Models",
    "authors": [
      "Jamal Al-Karaki",
      "Philip Ilono",
      "Sanchit Baweja",
      "Jalal Naghiyev",
      "Raja Singh Yadav",
      "Muhammad Al-Zafar Khan"
    ],
    "abstract": "Coronary Heart Disease affects millions of people worldwide and is a\nwell-studied area of healthcare. There are many viable and accurate methods for\nthe diagnosis and prediction of heart disease, but they have limiting points\nsuch as invasiveness, late detection, or cost. Supervised learning via machine\nlearning algorithms presents a low-cost (computationally speaking),\nnon-invasive solution that can be a precursor for early diagnosis. In this\nstudy, we applied several well-known methods and benchmarked their performance\nagainst each other. It was found that Random Forest with oversampling of the\npredictor variable produced the highest accuracy of 84%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.14231v1",
    "published_date": "2024-09-21 19:22:41 UTC",
    "updated_date": "2024-09-21 19:22:41 UTC"
  },
  {
    "arxiv_id": "2409.14219v1",
    "title": "MEGA-PT: A Meta-Game Framework for Agile Penetration Testing",
    "authors": [
      "Yunfei Ge",
      "Quanyan Zhu"
    ],
    "abstract": "Penetration testing is an essential means of proactive defense in the face of\nescalating cybersecurity incidents. Traditional manual penetration testing\nmethods are time-consuming, resource-intensive, and prone to human errors.\nCurrent trends in automated penetration testing are also impractical, facing\nsignificant challenges such as the curse of dimensionality, scalability issues,\nand lack of adaptability to network changes. To address these issues, we\npropose MEGA-PT, a meta-game penetration testing framework, featuring micro\ntactic games for node-level local interactions and a macro strategy process for\nnetwork-wide attack chains. The micro- and macro-level modeling enables\ndistributed, adaptive, collaborative, and fast penetration testing. MEGA-PT\noffers agile solutions for various security schemes, including optimal local\npenetration plans, purple teaming solutions, and risk assessment, providing\nfundamental principles to guide future automated penetration testing. Our\nexperiments demonstrate the effectiveness and agility of our model by providing\nimproved defense strategies and adaptability to changes at both local and\nnetwork levels.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14219v1",
    "published_date": "2024-09-21 18:46:29 UTC",
    "updated_date": "2024-09-21 18:46:29 UTC"
  },
  {
    "arxiv_id": "2409.14216v1",
    "title": "R-AIF: Solving Sparse-Reward Robotic Tasks from Pixels with Active Inference and World Models",
    "authors": [
      "Viet Dung Nguyen",
      "Zhizhuo Yang",
      "Christopher L. Buckley",
      "Alexander Ororbia"
    ],
    "abstract": "Although research has produced promising results demonstrating the utility of\nactive inference (AIF) in Markov decision processes (MDPs), there is relatively\nless work that builds AIF models in the context of environments and problems\nthat take the form of partially observable Markov decision processes (POMDPs).\nIn POMDP scenarios, the agent must infer the unobserved environmental state\nfrom raw sensory observations, e.g., pixels in an image. Additionally, less\nwork exists in examining the most difficult form of POMDP-centered control:\ncontinuous action space POMDPs under sparse reward signals. In this work, we\naddress issues facing the AIF modeling paradigm by introducing novel prior\npreference learning techniques and self-revision schedules to help the agent\nexcel in sparse-reward, continuous action, goal-based robotic control POMDP\nenvironments. Empirically, we show that our agents offer improved performance\nover state-of-the-art models in terms of cumulative rewards, relative\nstability, and success rate. The code in support of this work can be found at\nhttps://github.com/NACLab/robust-active-inference.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "68T40 (Primary) 68T07, 68T37, 68T05 (Secondary)",
      "I.2.9; I.2.10; G.3; I.2.6"
    ],
    "primary_category": "cs.RO",
    "comment": "20 pages, 2 algorithms, 2 tables, 5 figures, submitted to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.14216v1",
    "published_date": "2024-09-21 18:32:44 UTC",
    "updated_date": "2024-09-21 18:32:44 UTC"
  },
  {
    "arxiv_id": "2409.14206v1",
    "title": "AI Assistants for Spaceflight Procedures: Combining Generative Pre-Trained Transformer and Retrieval-Augmented Generation on Knowledge Graphs With Augmented Reality Cues",
    "authors": [
      "Oliver Bensch",
      "Leonie Bensch",
      "Tommy Nilsson",
      "Florian Saling",
      "Bernd Bewer",
      "Sophie Jentzsch",
      "Tobias Hecking",
      "J. Nathan Kutz"
    ],
    "abstract": "This paper describes the capabilities and potential of the intelligent\npersonal assistant (IPA) CORE (Checklist Organizer for Research and\nExploration), designed to support astronauts during procedures onboard the\nInternational Space Station (ISS), the Lunar Gateway station, and beyond. We\nreflect on the importance of a reliable and flexible assistant capable of\noffline operation and highlight the usefulness of audiovisual interaction using\naugmented reality elements to intuitively display checklist information. We\nargue that current approaches to the design of IPAs in space operations fall\nshort of meeting these criteria. Therefore, we propose CORE as an assistant\nthat combines Knowledge Graphs (KGs), Retrieval-Augmented Generation (RAG) for\na Generative Pre-Trained Transformer (GPT), and Augmented Reality (AR) elements\nto ensure an intuitive understanding of procedure steps, reliability, offline\navailability, and flexibility in terms of response style and procedure updates.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "68T01, 68T20, 68T30, 68T50, 68T05,",
      "I.2; H.5"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for the ESA SPAICE Conference 2024: AI in and for Space",
    "pdf_url": "http://arxiv.org/pdf/2409.14206v1",
    "published_date": "2024-09-21 17:41:46 UTC",
    "updated_date": "2024-09-21 17:41:46 UTC"
  },
  {
    "arxiv_id": "2409.14199v3",
    "title": "Loop Neural Networks for Parameter Sharing",
    "authors": [
      "Kei-Sing Ng",
      "Qingchen Wang"
    ],
    "abstract": "The success of large-scale language models like GPT can be attributed to\ntheir ability to efficiently predict the next token in a sequence. However,\nthese models rely on constant computational effort regardless of the complexity\nof the token they are predicting, lacking the capacity for iterative\nrefinement. In this paper, we introduce a novel Loop Neural Network, which\nachieves better performance by utilizing longer computational time without\nincreasing the model size. Our approach revisits the input multiple times,\nrefining the prediction by iteratively looping over a subset of the model with\nresidual connections. We demonstrate the effectiveness of this method through\nexperiments comparing versions of GPT-2 with our loop models, showing improved\nperformance in language modeling tasks while maintaining similar parameter\ncounts. Importantly, these improvements are achieved without the need for extra\ntraining data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14199v3",
    "published_date": "2024-09-21 17:07:42 UTC",
    "updated_date": "2024-11-08 15:00:01 UTC"
  },
  {
    "arxiv_id": "2409.14194v1",
    "title": "Data-Driven Approach to assess and identify gaps in healthcare set up in South Asia",
    "authors": [
      "Rusham Elahi",
      "Zia Tahseen",
      "Tehreem Fatima",
      "Syed Wafa Zahra",
      "Hafiz Muhammad Abubakar",
      "Tehreem Zafar",
      "Aqs Younas",
      "Muhammad Talha Quddoos",
      "Usman Nazir"
    ],
    "abstract": "Primary healthcare is a crucial strategy for achieving universal health\ncoverage. South Asian countries are working to improve their primary healthcare\nsystem through their country specific policies designed in line with WHO health\nsystem framework using the six thematic pillars: Health Financing, Health\nService delivery, Human Resource for Health, Health Information Systems,\nGovernance, Essential Medicines and Technology, and an addition area of\nCross-Sectoral Linkages. Measuring the current accessibility of healthcare\nfacilities and workforce availability is essential for improving healthcare\nstandards and achieving universal health coverage in developing countries.\nData-driven surveillance approaches are required that can provide rapid,\nreliable, and geographically scalable solutions to understand a) which\ncommunities and areas are most at risk of inequitable access and when, b) what\nbarriers to health access exist, and c) how they can be overcome in ways\ntailored to the specific challenges faced by individual communities. We propose\nto harness current breakthroughs in Earth-observation (EO) technology, which\nprovide the ability to generate accurate, up-to-date, publicly accessible, and\nreliable data, which is necessary for equitable access planning and resource\nallocation to ensure that vaccines, and other interventions reach everyone,\nparticularly those in greatest need, during normal and crisis times. This\nrequires collaboration among countries to identify evidence based solutions to\nshape health policy and interventions, and drive innovations and research in\nthe region.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14194v1",
    "published_date": "2024-09-21 16:50:16 UTC",
    "updated_date": "2024-09-21 16:50:16 UTC"
  },
  {
    "arxiv_id": "2409.14191v3",
    "title": "Addressing and Visualizing Misalignments in Human Task-Solving Trajectories",
    "authors": [
      "Sejin Kim",
      "Hosung Lee",
      "Sundong Kim"
    ],
    "abstract": "Understanding misalignments in human task-solving trajectories is critical\nfor improving AI models trained to mimic human reasoning. This study\ncategorizes such misalignments into three types: \\textbf{(1) Lack of functions\nto express intent}, \\textbf{(2) Inefficient action sequences}, and \\textbf{(3)\nIncorrect intentions that cannot solve the task}. To address these issues, we\nfirst formalize and define these three types of misalignments. We then propose\na heuristic algorithm to detect these misalignments in O2ARC trajectories and\nconduct a hierarchical and quantitative analysis of their impact. Furthermore,\nwe introduce an intention estimation algorithm that predicts missing alignment\ninformation between user actions and inferred intentions, leveraging our\nformalized framework. Through trajectory alignment, we experimentally\ndemonstrate that AI models trained on human task-solving trajectories improve\nperformance in mimicking human reasoning. Based on hierarchical analysis and\nexperiments, we highlight the importance of trajectory-intention alignment and\ndemonstrate the potential of intention learning.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "KDD 2025 accepted",
    "pdf_url": "http://arxiv.org/pdf/2409.14191v3",
    "published_date": "2024-09-21 16:38:22 UTC",
    "updated_date": "2025-05-15 11:17:59 UTC"
  },
  {
    "arxiv_id": "2409.14181v1",
    "title": "Democratising Artificial Intelligence for Pandemic Preparedness and Global Governance in Latin American and Caribbean Countries",
    "authors": [
      "Andre de Carvalho",
      "Robson Bonidia",
      "Jude Dzevela Kong",
      "Mariana Dauhajre",
      "Claudio Struchiner",
      "Guilherme Goedert",
      "Peter F. Stadler",
      "Maria Emilia Walter",
      "Danilo Sanches",
      "Troy Day",
      "Marcia Castro",
      "John Edmunds",
      "Manuel Colome-Hidalgo",
      "Demian Arturo Herrera Morban",
      "Edian F. Franco",
      "Cesar Ugarte-Gil",
      "Patricia Espinoza-Lopez",
      "Gabriel Carrasco-Escobar",
      "Ulisses Rocha"
    ],
    "abstract": "Infectious diseases, transmitted directly or indirectly, are among the\nleading causes of epidemics and pandemics. Consequently, several open\nchallenges exist in predicting epidemic outbreaks, detecting variants, tracing\ncontacts, discovering new drugs, and fighting misinformation. Artificial\nIntelligence (AI) can provide tools to deal with these scenarios, demonstrating\npromising results in the fight against the COVID-19 pandemic. AI is becoming\nincreasingly integrated into various aspects of society. However, ensuring that\nAI benefits are distributed equitably and that they are used responsibly is\ncrucial. Multiple countries are creating regulations to address these concerns,\nbut the borderless nature of AI requires global cooperation to define\nregulatory and guideline consensus. Considering this, The Global South AI for\nPandemic & Epidemic Preparedness & Response Network (AI4PEP) has developed an\ninitiative comprising 16 projects across 16 countries in the Global South,\nseeking to strengthen equitable and responsive public health systems that\nleverage Southern-led responsible AI solutions to improve prevention,\npreparedness, and response to emerging and re-emerging infectious disease\noutbreaks. This opinion introduces our branches in Latin American and Caribbean\n(LAC) countries and discusses AI governance in LAC in the light of\nbiotechnology. Our network in LAC has high potential to help fight infectious\ndiseases, particularly in low- and middle-income countries, generating\nopportunities for the widespread use of AI techniques to improve the health and\nwell-being of their communities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14181v1",
    "published_date": "2024-09-21 15:59:13 UTC",
    "updated_date": "2024-09-21 15:59:13 UTC"
  },
  {
    "arxiv_id": "2409.14177v2",
    "title": "PathSeeker: Exploring LLM Security Vulnerabilities with a Reinforcement Learning-Based Jailbreak Approach",
    "authors": [
      "Zhihao Lin",
      "Wei Ma",
      "Mingyi Zhou",
      "Yanjie Zhao",
      "Haoyu Wang",
      "Yang Liu",
      "Jun Wang",
      "Li Li"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have gained widespread use,\nraising concerns about their security. Traditional jailbreak attacks, which\noften rely on the model internal information or have limitations when exploring\nthe unsafe behavior of the victim model, limiting their reducing their general\napplicability. In this paper, we introduce PathSeeker, a novel black-box\njailbreak method, which is inspired by the game of rats escaping a maze. We\nthink that each LLM has its unique \"security maze\", and attackers attempt to\nfind the exit learning from the received feedback and their accumulated\nexperience to compromise the target LLM's security defences. Our approach\nleverages multi-agent reinforcement learning, where smaller models collaborate\nto guide the main LLM in performing mutation operations to achieve the attack\nobjectives. By progressively modifying inputs based on the model's feedback,\nour system induces richer, harmful responses. During our manual attempts to\nperform jailbreak attacks, we found that the vocabulary of the response of the\ntarget model gradually became richer and eventually produced harmful responses.\nBased on the observation, we also introduce a reward mechanism that exploits\nthe expansion of vocabulary richness in LLM responses to weaken security\nconstraints. Our method outperforms five state-of-the-art attack techniques\nwhen tested across 13 commercial and open-source LLMs, achieving high attack\nsuccess rates, especially in strongly aligned commercial models like\nGPT-4o-mini, Claude-3.5, and GLM-4-air with strong safety alignment. This study\naims to improve the understanding of LLM security vulnerabilities and we hope\nthat this sturdy can contribute to the development of more robust defenses.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "update the abstract and cite a new related work",
    "pdf_url": "http://arxiv.org/pdf/2409.14177v2",
    "published_date": "2024-09-21 15:36:26 UTC",
    "updated_date": "2024-10-03 08:13:52 UTC"
  },
  {
    "arxiv_id": "2409.14175v2",
    "title": "QMOS: Enhancing LLMs for Telecommunication with Question Masked loss and Option Shuffling",
    "authors": [
      "Blessed Guda",
      "Gabrial Zencha Ashungafac",
      "Lawrence Francis",
      "Carlee Joe-Wong"
    ],
    "abstract": "Large Language models (LLMs) have brought about substantial advancements in\nthe field of Question Answering (QA) systems. These models do remarkably well\nin addressing intricate inquiries in a variety of disciplines. However, because\nof domain-specific vocabulary, complex technological concepts, and the\nrequirement for exact responses applying LLMs to specialized sectors like\ntelecommunications presents additional obstacles. GPT-3.5 has been used in\nrecent work, to obtain noteworthy accuracy for telecom-related questions in a\nRetrieval Augmented Generation (RAG) framework. Notwithstanding these\ndevelopments, the practical use of models such as GPT-3.5 is restricted by\ntheir proprietary nature and high computing demands. This paper introduces\nQMOS, an innovative approach which uses a Question-Masked loss and Option\nShuffling trick to enhance the performance of LLMs in answering Multiple-Choice\nQuestions in the telecommunications domain. Our focus was on using opensource,\nsmaller language models (Phi-2 and Falcon-7B) within an enhanced RAG framework.\nOur multi-faceted approach involves several enhancements to the whole LLM-RAG\npipeline of finetuning, retrieval, prompt engineering and inference. Our\napproaches significantly outperform existing results, achieving accuracy\nimprovements from baselines of 24.70% to 49.30% with Falcon-7B and from 42.07%\nto 84.65% with Phi-2.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14175v2",
    "published_date": "2024-09-21 15:32:10 UTC",
    "updated_date": "2025-02-04 07:46:23 UTC"
  },
  {
    "arxiv_id": "2409.14173v1",
    "title": "An Evolutionary Algorithm For the Vehicle Routing Problem with Drones with Interceptions",
    "authors": [
      "Carlos Pambo",
      "Jacomine Grobler"
    ],
    "abstract": "The use of trucks and drones as a solution to address last-mile delivery\nchallenges is a new and promising research direction explored in this paper.\nThe variation of the problem where the drone can intercept the truck while in\nmovement or at the customer location is part of an optimisation problem called\nthe vehicle routing problem with drones with interception (VRPDi). This paper\nproposes an evolutionary algorithm to solve the VRPDi. In this variation of the\nVRPDi, multiple pairs of trucks and drones need to be scheduled. The pairs\nleave and return to a depot location together or separately to make deliveries\nto customer nodes. The drone can intercept the truck after the delivery or meet\nup with the truck at the following customer location. The algorithm was\nexecuted on the travelling salesman problem with drones (TSPD) datasets by\nBouman et al. (2015), and the performance of the algorithm was compared by\nbenchmarking the results of the VRPDi against the results of the VRP of the\nsame dataset. This comparison showed improvements in total delivery time\nbetween 39% and 60%. Further detailed analysis of the algorithm results\nexamined the total delivery time, distance, node delivery scheduling and the\ndegree of diversity during the algorithm execution. This analysis also\nconsidered how the algorithm handled the VRPDi constraints. The results of the\nalgorithm were then benchmarked against algorithms in Dillon et al. (2023) and\nErnst (2024). The latter solved the problem with a maximum drone distance\nconstraint added to the VRPDi. The analysis and benchmarking of the algorithm\nresults showed that the algorithm satisfactorily solved 50 and 100-nodes\nproblems in a reasonable amount of time, and the solutions found were better\nthan those found by the algorithms in Dillon et al. (2023) and Ernst (2024) for\nthe same problems.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14173v1",
    "published_date": "2024-09-21 15:26:24 UTC",
    "updated_date": "2024-09-21 15:26:24 UTC"
  },
  {
    "arxiv_id": "2409.18142v1",
    "title": "A Survey on Multimodal Benchmarks: In the Era of Large AI Models",
    "authors": [
      "Lin Li",
      "Guikun Chen",
      "Hanrong Shi",
      "Jun Xiao",
      "Long Chen"
    ],
    "abstract": "The rapid evolution of Multimodal Large Language Models (MLLMs) has brought\nsubstantial advancements in artificial intelligence, significantly enhancing\nthe capability to understand and generate multimodal content. While prior\nstudies have largely concentrated on model architectures and training\nmethodologies, a thorough analysis of the benchmarks used for evaluating these\nmodels remains underexplored. This survey addresses this gap by systematically\nreviewing 211 benchmarks that assess MLLMs across four core domains:\nunderstanding, reasoning, generation, and application. We provide a detailed\nanalysis of task designs, evaluation metrics, and dataset constructions, across\ndiverse modalities. We hope that this survey will contribute to the ongoing\nadvancement of MLLM research by offering a comprehensive overview of\nbenchmarking practices and identifying promising directions for future work. An\nassociated GitHub repository collecting the latest papers is available.",
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "Ongoing project",
    "pdf_url": "http://arxiv.org/pdf/2409.18142v1",
    "published_date": "2024-09-21 15:22:26 UTC",
    "updated_date": "2024-09-21 15:22:26 UTC"
  },
  {
    "arxiv_id": "2409.14165v3",
    "title": "A Survey on Large Language Model-empowered Autonomous Driving",
    "authors": [
      "Yuxuan Zhu",
      "Shiyi Wang",
      "Wenqing Zhong",
      "Nianchen Shen",
      "Yunqi Li",
      "Siqi Wang",
      "Zhiheng Li",
      "Cathy Wu",
      "Zhengbing He",
      "Li Li"
    ],
    "abstract": "Artificial intelligence (AI) plays a crucial role in autonomous driving (AD)\nresearch, propelling its development towards intelligence and efficiency.\nCurrently, the development of AD technology follows two main technical paths:\nmodularization and end-to-end. Modularization decompose the driving task into\nmodules such as perception, prediction, planning, and control, and train them\nseparately. Due to the inconsistency of training objectives between modules,\nthe integrated effect suffers from bias. End-to-end attempts to address this\nissue by utilizing a single model that directly maps from sensor data to\ncontrol signals. This path has limited learning capabilities in a comprehensive\nset of features and struggles to handle unpredictable long-tail events and\ncomplex urban traffic scenarios. In the face of challenges encountered in both\npaths, many researchers believe that large language models (LLMs) with powerful\nreasoning capabilities and extensive knowledge understanding may be the\nsolution, expecting LLMs to provide AD systems with deeper levels of\nunderstanding and decision-making capabilities. In light of the challenges\nfaced by both paths, many researchers believe that LLMs, with their powerful\nreasoning abilities and extensive knowledge, could offer a solution. To\nunderstand if LLMs could enhance AD, this paper conducts a thorough analysis of\nthe potential applications of LLMs in AD systems, including exploring their\noptimization strategies in both modular and end-to-end approaches, with a\nparticular focus on how LLMs can tackle the problems and challenges present in\ncurrent solutions. Furthermore, we discuss an important question: Can LLM-based\nartificial general intelligence (AGI) be a key to achieve high-level AD? We\nfurther analyze the potential limitations and challenges that LLMs may\nencounter in promoting the development of AD technology.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14165v3",
    "published_date": "2024-09-21 15:07:37 UTC",
    "updated_date": "2024-11-30 22:21:30 UTC"
  },
  {
    "arxiv_id": "2409.14154v1",
    "title": "MSSDA: Multi-Sub-Source Adaptation for Diabetic Foot Neuropathy Recognition",
    "authors": [
      "Yan Zhong",
      "Zhixin Yan",
      "Yi Xie",
      "Shibin Wu",
      "Huaidong Zhang",
      "Lin Shu",
      "Peiru Zhou"
    ],
    "abstract": "Diabetic foot neuropathy (DFN) is a critical factor leading to diabetic foot\nulcers, which is one of the most common and severe complications of diabetes\nmellitus (DM) and is associated with high risks of amputation and mortality.\nDespite its significance, existing datasets do not directly derive from plantar\ndata and lack continuous, long-term foot-specific information. To advance DFN\nresearch, we have collected a novel dataset comprising continuous plantar\npressure data to recognize diabetic foot neuropathy. This dataset includes data\nfrom 94 DM patients with DFN and 41 DM patients without DFN. Moreover,\ntraditional methods divide datasets by individuals, potentially leading to\nsignificant domain discrepancies in some feature spaces due to the absence of\nmid-domain data. In this paper, we propose an effective domain adaptation\nmethod to address this proplem. We split the dataset based on convolutional\nfeature statistics and select appropriate sub-source domains to enhance\nefficiency and avoid negative transfer. We then align the distributions of each\nsource and target domain pair in specific feature spaces to minimize the domain\ngap. Comprehensive results validate the effectiveness of our method on both the\nnewly proposed dataset for DFN recognition and an existing dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14154v1",
    "published_date": "2024-09-21 14:16:20 UTC",
    "updated_date": "2024-09-21 14:16:20 UTC"
  },
  {
    "arxiv_id": "2409.19006v2",
    "title": "Towards Automated Patent Workflows: AI-Orchestrated Multi-Agent Framework for Intellectual Property Management and Analysis",
    "authors": [
      "Sakhinana Sagar Srinivas",
      "Vijay Sri Vaikunth",
      "Venkataramana Runkana"
    ],
    "abstract": "Patents are the currency of innovation, and like any currency, they need to\nbe managed and protected (Gavin Potenza). Patents, as legal documents that\nsecure intellectual property rights, play a critical role in technological\ninnovation. The growing complexity of patent documents and the surge in patent\napplications have created a need for automated solutions in patent analysis. In\nthis work, we present PatExpert, an autonomous multi-agent conversational\nframework designed to streamline and optimize patent-related tasks. The\nframework consists of a metaagent that coordinates task-specific expert agents\nfor various patent-related tasks and a critique agent for error handling and\nfeedback provision. The meta-agent orchestrates specialized expert agents, each\nfine-tuned for specific tasks such as patent classification, acceptance, claim\ngeneration, abstractive summarization, multi-patent analysis, and scientific\nhypothesis generation. For multi-patent analysis, the framework incorporates\nadvanced methods like Graph Retrieval-Augmented Generation (GRAG) to enhance\nresponse accuracy and relevance by combining semantic similarity with knowledge\ngraphs. Error handling is managed by critique agents (Gold-LLM-as-a-Judge and\nReward-LLM-as-a-Judge), which evaluate output responses for accuracy and\nprovide iterative feedback. The framework also prioritizes explainability,\nensuring transparent justifications for decisions made during patent analysis.\nIts comprehensive capabilities make it a valuable tool for automating complex\npatent workflows, enhancing efficiency, accuracy, and compliance in\npatent-related tasks. Empirical evidence demonstrates significant improvements\nin patent processing tasks, concluding that the framework offers a robust\nsolution for automating and optimizing patent analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Workshop on Open-World Agents (OWA-NeurIPS 2024) :\n  Synergizing Reasoning and Decision-Making in Open-World Environments",
    "pdf_url": "http://arxiv.org/pdf/2409.19006v2",
    "published_date": "2024-09-21 13:44:34 UTC",
    "updated_date": "2024-10-12 14:46:32 UTC"
  },
  {
    "arxiv_id": "2409.14128v2",
    "title": "Present and Future Generalization of Synthetic Image Detectors",
    "authors": [
      "Pablo Bernabeu-Perez",
      "Enrique Lopez-Cuena",
      "Dario Garcia-Gasulla"
    ],
    "abstract": "The continued release of increasingly realistic image generation models\ncreates a demand for synthetic image detectors. To build effective detectors we\nmust first understand how factors like data source diversity, training\nmethodologies and image alterations affect their generalization capabilities.\nThis work conducts a systematic analysis and uses its insights to develop\npractical guidelines for training robust synthetic image detectors. Model\ngeneralization capabilities are evaluated across different setups (e.g. scale,\nsources, transformations) including real-world deployment conditions. Through\nan extensive benchmarking of state-of-the-art detectors across diverse and\nrecent datasets, we show that while current approaches excel in specific\nscenarios, no single detector achieves universal effectiveness. Critical flaws\nare identified in detectors, and workarounds are proposed to enable the\ndeployment of real-world detector applications enhancing accuracy, reliability\nand robustness beyond the limitations of current systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14128v2",
    "published_date": "2024-09-21 12:46:17 UTC",
    "updated_date": "2024-11-26 09:12:30 UTC"
  },
  {
    "arxiv_id": "2409.14119v3",
    "title": "Obliviate: Neutralizing Task-agnostic Backdoors within the Parameter-efficient Fine-tuning Paradigm",
    "authors": [
      "Jaehan Kim",
      "Minkyoo Song",
      "Seung Ho Na",
      "Seungwon Shin"
    ],
    "abstract": "Parameter-efficient fine-tuning (PEFT) has become a key training strategy for\nlarge language models. However, its reliance on fewer trainable parameters\nposes security risks, such as task-agnostic backdoors. Despite their severe\nimpact on a wide range of tasks, there is no practical defense solution\navailable that effectively counters task-agnostic backdoors within the context\nof PEFT. In this study, we introduce Obliviate, a PEFT-integrable backdoor\ndefense. We develop two techniques aimed at amplifying benign neurons within\nPEFT layers and penalizing the influence of trigger tokens. Our evaluations\nacross three major PEFT architectures show that our method can significantly\nreduce the attack success rate of the state-of-the-art task-agnostic backdoors\n(83.6%$\\downarrow$). Furthermore, our method exhibits robust defense\ncapabilities against both task-specific backdoors and adaptive attacks. Source\ncode will be obtained at https://github.com/obliviateARR/Obliviate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2409.14119v3",
    "published_date": "2024-09-21 12:20:18 UTC",
    "updated_date": "2024-10-06 09:43:25 UTC"
  },
  {
    "arxiv_id": "2409.14106v4",
    "title": "Advancing Molecular Graph-Text Pre-training via Fine-grained Alignment",
    "authors": [
      "Yibo Li",
      "Yuan Fang",
      "Mengmei Zhang",
      "Chuan Shi"
    ],
    "abstract": "Understanding molecular structure and related knowledge is crucial for\nscientific research. Recent studies integrate molecular graphs with their\ntextual descriptions to enhance molecular representation learning. However,\nthey focus on the whole molecular graph and neglect frequently occurring\nsubgraphs, known as motifs, which are essential for determining molecular\nproperties. Without such fine-grained knowledge, these models struggle to\ngeneralize to unseen molecules and tasks that require motif-level insights. To\nbridge this gap, we propose FineMolTex, a novel Fine-grained Molecular\ngraph-Text pre-training framework to jointly learn coarse-grained\nmolecule-level knowledge and fine-grained motif-level knowledge. Specifically,\nFineMolTex consists of two pre-training tasks: a contrastive alignment task for\ncoarse-grained matching and a masked multi-modal modeling task for fine-grained\nmatching. In particular, the latter predicts the labels of masked motifs and\nwords, which are selected based on their importance. By leveraging insights\nfrom both modalities, FineMolTex is able to understand the fine-grained\nmatching between motifs and words. Finally, we conduct extensive experiments\nacross three downstream tasks, achieving up to 238% improvement in the\ntext-based molecule editing task. Additionally, our case studies reveal that\nFineMolTex successfully captures fine-grained knowledge, potentially offering\nvaluable insights for drug discovery and catalyst design.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14106v4",
    "published_date": "2024-09-21 11:19:15 UTC",
    "updated_date": "2025-03-04 07:17:48 UTC"
  },
  {
    "arxiv_id": "2409.14091v2",
    "title": "Normalized Narrow Jump To Conclusions: Normalized Narrow Shortcuts for Parameter Efficient Early Exit Transformer Prediction",
    "authors": [
      "Amrit Diggavi Seshadri"
    ],
    "abstract": "With the size and cost of large transformer-based language models growing,\nrecently, there has been interest in shortcut casting of early transformer\nhidden-representations to final-representations for cheaper model inference. In\nparticular, shortcutting pre-trained transformers with linear transformations\nover early layers has been shown to improve precision in early inference.\nHowever, for large language models, even this becomes computationally\nexpensive. In this work, we propose Narrow Jump to Conclusions (NJTC) and\nNormalized Narrow Jump to Conclusions (N-NJTC) - parameter efficient\nalternatives to standard linear shortcutting that reduces shortcut parameter\ncount by over 97%. We show that N-NJTC reliably outperforms Identity shortcuts\nat early stages and offers stable precision from all transformer block levels\nfor GPT-2-XL, Phi3-Mini and Llama2-7B transformer models, demonstrating the\nviability of more parameter efficient short-cutting approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14091v2",
    "published_date": "2024-09-21 10:09:26 UTC",
    "updated_date": "2024-10-03 07:41:39 UTC"
  },
  {
    "arxiv_id": "2409.14084v2",
    "title": "One-shot World Models Using a Transformer Trained on a Synthetic Prior",
    "authors": [
      "Fabio Ferreira",
      "Moreno Schlageter",
      "Raghu Rajan",
      "Andre Biedenkapp",
      "Frank Hutter"
    ],
    "abstract": "A World Model is a compressed spatial and temporal representation of a real\nworld environment that allows one to train an agent or execute planning\nmethods. However, world models are typically trained on observations from the\nreal world environment, and they usually do not enable learning policies for\nother real environments. We propose One-Shot World Model (OSWM), a transformer\nworld model that is learned in an in-context learning fashion from purely\nsynthetic data sampled from a prior distribution. Our prior is composed of\nmultiple randomly initialized neural networks, where each network models the\ndynamics of each state and reward dimension of a desired target environment. We\nadopt the supervised learning procedure of Prior-Fitted Networks by masking\nnext-state and reward at random context positions and query OSWM to make\nprobabilistic predictions based on the remaining transition context. During\ninference time, OSWM is able to quickly adapt to the dynamics of a simple grid\nworld, as well as the CartPole gym and a custom control environment by\nproviding 1k transition steps as context and is then able to successfully train\nenvironment-solving agent policies. However, transferring to more complex\nenvironments remains a challenge, currently. Despite these limitations, we see\nthis work as an important stepping-stone in the pursuit of learning world\nmodels purely from synthetic data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14084v2",
    "published_date": "2024-09-21 09:39:32 UTC",
    "updated_date": "2024-10-24 18:57:44 UTC"
  },
  {
    "arxiv_id": "2409.14082v1",
    "title": "PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL",
    "authors": [
      "Ruilin Luo",
      "Liyuan Wang",
      "Binghuai Lin",
      "Zicheng Lin",
      "Yujiu Yang"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for Text-to-SQL\ntasks, exhibiting remarkable reasoning capabilities. Different from tasks such\nas math word problems and commonsense reasoning, SQL solutions have a\nrelatively fixed pattern. This facilitates the investigation of whether LLMs\ncan benefit from categorical thinking, mirroring how humans acquire knowledge\nthrough inductive reasoning based on comparable examples. In this study, we\npropose that employing query group partitioning allows LLMs to focus on\nlearning the thought processes specific to a single problem type, consequently\nenhancing their reasoning abilities across diverse difficulty levels and\nproblem categories. Our experiments reveal that multiple advanced LLMs, when\nequipped with PTD-SQL, can either surpass or match previous state-of-the-art\n(SOTA) methods on the Spider and BIRD datasets. Intriguingly, models with\nvarying initial performances have exhibited significant improvements, mainly at\nthe boundary of their capabilities after targeted drilling, suggesting a\nparallel with human progress. Code is available at\nhttps://github.com/lrlbbzl/PTD-SQL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Main Conference. Revised by ARR April and ARR June. 32\n  pages, 7 figures and 30 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.14082v1",
    "published_date": "2024-09-21 09:33:14 UTC",
    "updated_date": "2024-09-21 09:33:14 UTC"
  },
  {
    "arxiv_id": "2409.15381v1",
    "title": "Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation",
    "authors": [
      "G M Shahariar",
      "Jia Chen",
      "Jiachen Li",
      "Yue Dong"
    ],
    "abstract": "Recent studies show that text-to-image (T2I) models are vulnerable to\nadversarial attacks, especially with noun perturbations in text prompts. In\nthis study, we investigate the impact of adversarial attacks on different POS\ntags within text prompts on the images generated by T2I models. We create a\nhigh-quality dataset for realistic POS tag token swapping and perform\ngradient-based attacks to find adversarial suffixes that mislead T2I models\ninto generating images with altered tokens. Our empirical results show that the\nattack success rate (ASR) varies significantly among different POS tag\ncategories, with nouns, proper nouns, and adjectives being the easiest to\nattack. We explore the mechanism behind the steering effect of adversarial\nsuffixes, finding that the number of critical tokens and content fusion vary\namong POS tags, while features like suffix transferability are consistent\nacross categories. We have made our implementation publicly available at -\nhttps://github.com/shahariar-shibli/Adversarial-Attack-on-POS-Tags.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of the EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15381v1",
    "published_date": "2024-09-21 09:19:55 UTC",
    "updated_date": "2024-09-21 09:19:55 UTC"
  },
  {
    "arxiv_id": "2409.14071v2",
    "title": "N-Version Assessment and Enhancement of Generative AI",
    "authors": [
      "Marcus Kessel",
      "Colin Atkinson"
    ],
    "abstract": "Generative AI (GAI) holds great potential to improve software engineering\nproductivity, but its untrustworthy outputs, particularly in code synthesis,\npose significant challenges. The need for extensive verification and validation\n(V&V) of GAI-generated artifacts may undermine the potential productivity\ngains. This paper proposes a way of mitigating these risks by exploiting GAI's\nability to generate multiple versions of code and tests to facilitate\ncomparative analysis across versions. Rather than relying on the quality of a\nsingle test or code module, this \"differential GAI\" (D-GAI) approach promotes\nmore reliable quality evaluation through version diversity. We introduce the\nLarge-Scale Software Observatorium (LASSO), a platform that supports D-GAI by\nexecuting and analyzing large sets of code versions and tests. We discuss how\nLASSO enables rigorous evaluation of GAI-generated artifacts and propose its\napplication in both software development and GAI research.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.1; D.2.4; I.2.2; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "This work has been accepted for publication in an upcoming issue of\n  IEEE Software. This work has been submitted to the IEEE for possible\n  publication",
    "pdf_url": "http://arxiv.org/pdf/2409.14071v2",
    "published_date": "2024-09-21 09:00:16 UTC",
    "updated_date": "2024-09-30 07:35:40 UTC"
  },
  {
    "arxiv_id": "2409.14066v1",
    "title": "KALIE: Fine-Tuning Vision-Language Models for Open-World Manipulation without Robot Data",
    "authors": [
      "Grace Tang",
      "Swetha Rajkumar",
      "Yifei Zhou",
      "Homer Rich Walke",
      "Sergey Levine",
      "Kuan Fang"
    ],
    "abstract": "Building generalist robotic systems involves effectively endowing robots with\nthe capabilities to handle novel objects in an open-world setting. Inspired by\nthe advances of large pre-trained models, we propose Keypoint Affordance\nLearning from Imagined Environments (KALIE), which adapts pre-trained Vision\nLanguage Models (VLMs) for robotic control in a scalable manner. Instead of\ndirectly producing motor commands, KALIE controls the robot by predicting\npoint-based affordance representations based on natural language instructions\nand visual observations of the scene. The VLM is trained on 2D images with\naffordances labeled by humans, bypassing the need for training data collected\non robotic systems. Through an affordance-aware data synthesis pipeline, KALIE\nautomatically creates massive high-quality training data based on limited\nexample data manually collected by humans. We demonstrate that KALIE can learn\nto robustly solve new manipulation tasks with unseen objects given only 50\nexample data points. Compared to baselines using pre-trained VLMs, our approach\nconsistently achieves superior performance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14066v1",
    "published_date": "2024-09-21 08:45:16 UTC",
    "updated_date": "2024-09-21 08:45:16 UTC"
  },
  {
    "arxiv_id": "2409.14051v1",
    "title": "GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion",
    "authors": [
      "Tongxuan Liu",
      "Xingyu Wang",
      "Weizhe Huang",
      "Wenjiang Xu",
      "Yuting Zeng",
      "Lei Jiang",
      "Hailong Yang",
      "Jing Li"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across diverse NLP tasks. Extensive research has explored how to\nenhance the logical reasoning abilities such as Chain-of-Thought,\nChain-of-Thought with Self-Consistency, Tree-Of-Thoughts, and multi-agent\ndebates. In the context of multi-agent debates, significant performance\nimprovements can be achieved with an increasing number of agents and debate\nrounds. However, the escalation in the number of agents and debate rounds can\ndrastically raise the tokens cost of debates, thereby limiting the scalability\nof the multi-agent debate technique. To better harness the advantages of\nmulti-agent debates in logical reasoning tasks, this paper proposes a method to\nsignificantly reduce token cost in multi-agent debates. This approach involves\ndividing all agents into multiple debate groups, with agents engaging in\ndebates within their respective groups and sharing interim debate results\nbetween groups. Comparative experiments across multiple datasets have\ndemonstrated that this method can reduce the total tokens by up to 51.7% during\ndebates and while potentially enhancing accuracy by as much as 25%. Our method\nsignificantly enhances the performance and efficiency of interactions in the\nmulti-agent debate.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.14051v1",
    "published_date": "2024-09-21 07:49:38 UTC",
    "updated_date": "2024-09-21 07:49:38 UTC"
  },
  {
    "arxiv_id": "2409.14050v1",
    "title": "The use of GPT-4o and Other Large Language Models for the Improvement and Design of Self-Assessment Scales for Measurement of Interpersonal Communication Skills",
    "authors": [
      "Goran Bubaš"
    ],
    "abstract": "OpenAI's ChatGPT (GPT-4 and GPT-4o) and other Large Language Models (LLMs)\nlike Microsoft's Copilot, Google's Gemini 1.5 Pro, and Antrophic's Claude 3.5\nSonnet can be effectively used in various phases of scientific research. Their\nperformance in diverse verbal tasks and reasoning is close to or above the\naverage human level and rapidly increasing, providing those models with a\ncapacity that resembles a relatively high level of theory of mind. The current\nability of LLMs to process information about human psychology and communication\ncreates an opportunity for their scientific use in the fields of personality\npsychology and interpersonal communication skills. This article illustrates the\npossible uses of GPT-4o and other advanced LLMs for typical tasks in designing\nself-assessment scales for interpersonal communication skills measurement like\nthe selection and improvement of scale items and evaluation of content validity\nof scales. The potential for automated item generation and application is\nillustrated as well. The case study examples are accompanied by prompts for\nLLMs that can be useful for these purposes. Finally, a summary is provided of\nthe potential benefits of using LLMs in the process of evaluation, design, and\nimprovement of interpersonal communication skills self-assessment scales.",
    "categories": [
      "cs.AI",
      "I.2.7; J.4"
    ],
    "primary_category": "cs.AI",
    "comment": "41 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.14050v1",
    "published_date": "2024-09-21 07:37:21 UTC",
    "updated_date": "2024-09-21 07:37:21 UTC"
  },
  {
    "arxiv_id": "2409.16321v1",
    "title": "WeatherFormer: Empowering Global Numerical Weather Forecasting with Space-Time Transformer",
    "authors": [
      "Junchao Gong",
      "Tao Han",
      "Kang Chen",
      "Lei Bai"
    ],
    "abstract": "Numerical Weather Prediction (NWP) system is an infrastructure that exerts\nconsiderable impacts on modern society.Traditional NWP system, however,\nresolves it by solving complex partial differential equations with a huge\ncomputing cluster, resulting in tons of carbon emission. Exploring efficient\nand eco-friendly solutions for NWP attracts interest from Artificial\nIntelligence (AI) and earth science communities. To narrow the performance gap\nbetween the AI-based methods and physic predictor, this work proposes a new\ntransformer-based NWP framework, termed as WeatherFormer, to model the complex\nspatio-temporal atmosphere dynamics and empowering the capability of\ndata-driven NWP. WeatherFormer innovatively introduces the space-time\nfactorized transformer blocks to decrease the parameters and memory\nconsumption, in which Position-aware Adaptive Fourier Neural Operator (PAFNO)\nis proposed for location sensible token mixing. Besides, two data augmentation\nstrategies are utilized to boost the performance and decrease training\nconsumption. Extensive experiments on WeatherBench dataset show WeatherFormer\nachieves superior performance over existing deep learning methods and further\napproaches the most advanced physical model.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "physics.ao-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16321v1",
    "published_date": "2024-09-21 07:02:31 UTC",
    "updated_date": "2024-09-21 07:02:31 UTC"
  },
  {
    "arxiv_id": "2409.14040v1",
    "title": "PepINVENT: Generative peptide design beyond the natural amino acids",
    "authors": [
      "Gökçe Geylan",
      "Jon Paul Janet",
      "Alessandro Tibo",
      "Jiazhen He",
      "Atanas Patronov",
      "Mikhail Kabeshov",
      "Florian David",
      "Werngard Czechtizky",
      "Ola Engkvist",
      "Leonardo De Maria"
    ],
    "abstract": "Peptides play a crucial role in the drug design and discovery whether as a\ntherapeutic modality or a delivery agent. Non-natural amino acids (NNAAs) have\nbeen used to enhance the peptide properties from binding affinity, plasma\nstability to permeability. Incorporating novel NNAAs facilitates the design of\nmore effective peptides with improved properties. The generative models used in\nthe field, have focused on navigating the peptide sequence space. The sequence\nspace is formed by combinations of a predefined set of amino acids. However,\nthere is still a need for a tool to explore the peptide landscape beyond this\nenumerated space to unlock and effectively incorporate de novo design of new\namino acids. To thoroughly explore the theoretical chemical space of the\npeptides, we present PepINVENT, a novel generative AI-based tool as an\nextension to the small molecule molecular design platform, REINVENT. PepINVENT\nnavigates the vast space of natural and non-natural amino acids to propose\nvalid, novel, and diverse peptide designs. The generative model can serve as a\ncentral tool for peptide-related tasks, as it was not trained on peptides with\nspecific properties or topologies. The prior was trained to understand the\ngranularity of peptides and to design amino acids for filling the masked\npositions within a peptide. PepINVENT coupled with reinforcement learning\nenables the goal-oriented design of peptides using its chemistry-informed\ngenerative capabilities. This study demonstrates PepINVENT's ability to explore\nthe peptide space with unique and novel designs, and its capacity for property\noptimization in the context of therapeutically relevant peptides. Our tool can\nbe employed for multi-parameter learning objectives, peptidomimetics, lead\noptimization, and variety of other tasks within the peptide domain.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14040v1",
    "published_date": "2024-09-21 06:53:03 UTC",
    "updated_date": "2024-09-21 06:53:03 UTC"
  },
  {
    "arxiv_id": "2409.14038v5",
    "title": "OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching",
    "authors": [
      "Zhangcheng Qiang",
      "Kerry Taylor",
      "Weiqing Wang",
      "Jing Jiang"
    ],
    "abstract": "Hallucinations of large language models (LLMs) commonly occur in\ndomain-specific downstream tasks, with no exception in ontology matching (OM).\nThe prevalence of using LLMs for OM raises the need for benchmarks to better\nunderstand LLM hallucinations. The OAEI-LLM dataset is an extended version of\nthe Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate\nLLM-specific hallucinations in OM tasks. We outline the methodology used in\ndataset construction and schema extension, and provide examples of potential\nuse cases.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 1 figure, 1 table, 1 code snippet",
    "pdf_url": "http://arxiv.org/pdf/2409.14038v5",
    "published_date": "2024-09-21 06:49:34 UTC",
    "updated_date": "2025-02-01 06:43:09 UTC"
  },
  {
    "arxiv_id": "2409.14037v1",
    "title": "Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators",
    "authors": [
      "Prasoon Bajpai",
      "Niladri Chatterjee",
      "Subhabrata Dutta",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Large Language Models (LLMs) and AI assistants driven by these models are\nexperiencing exponential growth in usage among both expert and amateur users.\nIn this work, we focus on evaluating the reliability of current LLMs as science\ncommunicators. Unlike existing benchmarks, our approach emphasizes assessing\nthese models on scientific questionanswering tasks that require a nuanced\nunderstanding and awareness of answerability. We introduce a novel dataset,\nSCiPS-QA, comprising 742 Yes/No queries embedded in complex scientific\nconcepts, along with a benchmarking suite that evaluates LLMs for correctness\nand consistency across various criteria. We benchmark three proprietary LLMs\nfrom the OpenAI GPT family and 13 open-access LLMs from the Meta Llama-2,\nLlama-3, and Mistral families. While most open-access models significantly\nunderperform compared to GPT-4 Turbo, our experiments identify Llama-3-70B as a\nstrong competitor, often surpassing GPT-4 Turbo in various evaluation aspects.\nWe also find that even the GPT models exhibit a general incompetence in\nreliably verifying LLM responses. Moreover, we observe an alarming trend where\nhuman evaluators are deceived by incorrect responses from GPT-4 Turbo.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14037v1",
    "published_date": "2024-09-21 06:48:32 UTC",
    "updated_date": "2024-09-21 06:48:32 UTC"
  },
  {
    "arxiv_id": "2409.14026v3",
    "title": "Uncovering Latent Chain of Thought Vectors in Language Models",
    "authors": [
      "Jason Zhang",
      "Scott Viteri"
    ],
    "abstract": "In this work, we examine how targeted perturbations in the activation space\nof Language Models (LMs) can encode complex reasoning patterns. We inject\nsteering vectors, derived from LM activations, into LMs during inference time\nand study whether these vectors can induce Chain-of-Thought (CoT) reasoning in\nLMs without the need for natural language prompting. We demonstrate this\napproach on Llama3 8B Instruct and Mistral 7B v0.2 Instruct and show that\nactivation-space interventions achieve competitive, if not superior,\nperformance compared to traditional CoT prompting across multiple reasoning\nbenchmarks, including GSM8k, MMLU, AGI Eval, and ARC AI2. These findings\nsuggest that neural network activations can encode reasoning patterns, offering\na new application of activation space manipulation as a tool for tuning model\nbehavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This work was presented at the Workshop on Neural Network Weights as\n  a New Data Modality at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.14026v3",
    "published_date": "2024-09-21 05:58:07 UTC",
    "updated_date": "2025-03-20 20:41:32 UTC"
  },
  {
    "arxiv_id": "2410.02810v3",
    "title": "StateAct: Enhancing LLM Base Agents via Self-prompting and State-tracking",
    "authors": [
      "Nikolai Rozanov",
      "Marek Rei"
    ],
    "abstract": "Large language models (LLMs) are increasingly used as autonomous agents,\ntackling tasks from robotics to web navigation. Their performance depends on\nthe underlying base agent. Existing methods, however, struggle with\nlong-context reasoning and goal adherence. We introduce StateAct, a novel and\nefficient base agent that enhances decision-making through (1) self-prompting,\nwhich reinforces task goals at every step, and (2) chain-of-states, an\nextension of chain-of-thought that tracks state information over time. StateAct\noutperforms ReAct, the previous best base agent, by over 10% on Alfworld, 30%\non Textcraft, and 7% on Webshop across multiple frontier LLMs. We also\ndemonstrate that StateAct can be used as a drop-in replacement for ReAct with\nadvanced LLM agent methods such as test-time scaling, yielding an additional\n12% gain on Textcraft. By improving efficiency and long-range reasoning without\nrequiring additional training or retrieval, StateAct provides a scalable\nfoundation for LLM agents. We open source our code to support further research\nat https://github.com/ai-nikolai/stateact .",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 pages appendix, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.02810v3",
    "published_date": "2024-09-21 05:54:35 UTC",
    "updated_date": "2025-04-08 06:37:51 UTC"
  },
  {
    "arxiv_id": "2409.14023v2",
    "title": "FAMOUS: Flexible Accelerator for the Attention Mechanism of Transformer on UltraScale+ FPGAs",
    "authors": [
      "Ehsan Kabir",
      "Md. Arafat Kabir",
      "Austin R. J. Downey",
      "Jason D. Bakos",
      "David Andrews",
      "Miaoqing Huang"
    ],
    "abstract": "Transformer neural networks (TNNs) are being applied across a widening range\nof application domains, including natural language processing (NLP), machine\ntranslation, and computer vision (CV). Their popularity is largely attributed\nto the exceptional performance of their multi-head self-attention blocks when\nanalyzing sequential data and extracting features. To date, there are limited\nhardware accelerators tailored for this mechanism, which is the first step\nbefore designing an accelerator for a complete model. This paper proposes\n\\textit{FAMOUS}, a flexible hardware accelerator for dense multi-head attention\n(MHA) computation of TNNs on field-programmable gate arrays (FPGAs). It is\noptimized for high utilization of processing elements and on-chip memories to\nimprove parallelism and reduce latency. An efficient tiling of large matrices\nhas been employed to distribute memory and computing resources across different\nmodules on various FPGA platforms. The design is evaluated on Xilinx Alveo U55C\nand U200 data center cards containing Ultrascale+ FPGAs. Experimental results\nare presented that show that it can attain a maximum throughput, number of\nparallel attention heads, embedding dimension and tile size of 328 (giga\noperations/second (GOPS)), 8, 768 and 64 respectively on the U55C. Furthermore,\nit is 3.28$\\times$ and 2.6$\\times$ faster than the Intel Xeon Gold 5220R CPU\nand NVIDIA V100 GPU respectively. It is also 1.3$\\times$ faster than the\nfastest state-of-the-art FPGA-based accelerator.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "arXiv admin note: text overlap with arXiv:2409.13975",
    "pdf_url": "http://arxiv.org/pdf/2409.14023v2",
    "published_date": "2024-09-21 05:25:46 UTC",
    "updated_date": "2024-10-21 05:34:04 UTC"
  },
  {
    "arxiv_id": "2409.14021v1",
    "title": "BrainDreamer: Reasoning-Coherent and Controllable Image Generation from EEG Brain Signals via Language Guidance",
    "authors": [
      "Ling Wang",
      "Chen Wu",
      "Lin Wang"
    ],
    "abstract": "Can we directly visualize what we imagine in our brain together with what we\ndescribe? The inherent nature of human perception reveals that, when we think,\nour body can combine language description and build a vivid picture in our\nbrain. Intuitively, generative models should also hold such versatility. In\nthis paper, we introduce BrainDreamer, a novel end-to-end language-guided\ngenerative framework that can mimic human reasoning and generate high-quality\nimages from electroencephalogram (EEG) brain signals. Our method is superior in\nits capacity to eliminate the noise introduced by non-invasive EEG data\nacquisition and meanwhile achieve a more precise mapping between the EEG and\nimage modality, thus leading to significantly better-generated images.\nSpecifically, BrainDreamer consists of two key learning stages: 1) modality\nalignment and 2) image generation. In the alignment stage, we propose a novel\nmask-based triple contrastive learning strategy to effectively align EEG, text,\nand image embeddings to learn a unified representation. In the generation\nstage, we inject the EEG embeddings into the pre-trained Stable Diffusion model\nby designing a learnable EEG adapter to generate high-quality\nreasoning-coherent images. Moreover, BrainDreamer can accept textual\ndescriptions (e.g., color, position, etc.) to achieve controllable image\ngeneration. Extensive experiments show that our method significantly\noutperforms prior arts in terms of generating quality and quantitative\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14021v1",
    "published_date": "2024-09-21 05:16:31 UTC",
    "updated_date": "2024-09-21 05:16:31 UTC"
  },
  {
    "arxiv_id": "2409.14019v1",
    "title": "MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors",
    "authors": [
      "Zhenhua Du",
      "Binbin Xu",
      "Haoyu Zhang",
      "Kai Huo",
      "Shuaifeng Zhi"
    ],
    "abstract": "Accurately reconstructing dense and semantically annotated 3D meshes from\nmonocular images remains a challenging task due to the lack of geometry\nguidance and imperfect view-dependent 2D priors. Though we have witnessed\nrecent advancements in implicit neural scene representations enabling precise\n2D rendering simply from multi-view images, there have been few works\naddressing 3D scene understanding with monocular priors alone. In this paper,\nwe propose MOSE, a neural field semantic reconstruction approach to lift\ninferred image-level noisy priors to 3D, producing accurate semantics and\ngeometry in both 3D and 2D space. The key motivation for our method is to\nleverage generic class-agnostic segment masks as guidance to promote local\nconsistency of rendered semantics during training. With the help of semantics,\nwe further apply a smoothness regularization to texture-less regions for better\ngeometric quality, thus achieving mutual benefits of geometry and semantics.\nExperiments on the ScanNet dataset show that our MOSE outperforms relevant\nbaselines across all metrics on tasks of 3D semantic segmentation, 2D semantic\nsegmentation and 3D surface reconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14019v1",
    "published_date": "2024-09-21 05:12:13 UTC",
    "updated_date": "2024-09-21 05:12:13 UTC"
  },
  {
    "arxiv_id": "2410.03688v1",
    "title": "LLM Agents as 6G Orchestrator: A Paradigm for Task-Oriented Physical-Layer Automation",
    "authors": [
      "Zhuoran Xiao",
      "Chenhui Ye",
      "Yunbo Hu",
      "Honggang Yuan",
      "Yihang Huang",
      "Yijia Feng",
      "Liyu Cai",
      "Jiang Chang"
    ],
    "abstract": "The rapid advancement in generative pre-training models is propelling a\nparadigm shift in technological progression from basic applications such as\nchatbots towards more sophisticated agent-based systems. It is with huge\npotential and necessity that the 6G system be combined with the copilot of\nlarge language model (LLM) agents and digital twins (DT) to manage the highly\ncomplicated communication system with new emerging features such as native AI\nservice and sensing. With the 6G-oriented agent, the base station could\nunderstand the transmission requirements of various dynamic upper-layer tasks,\nautomatically orchestrate the optimal system workflow. Through continuously get\nfeedback from the 6G DT for reinforcement, the agents can finally raise the\nperformance of practical system accordingly. Differing from existing LLM agents\ndesigned for general application, the 6G-oriented agent aims to make highly\nrigorous and precise planning with a vast amount of extra expert knowledge,\nwhich inevitably requires a specific system design from model training to\nimplementation. This paper proposes a novel comprehensive approach for building\ntask-oriented 6G LLM agents. We first propose a two-stage continual\npre-training and fine-tuning scheme to build the field basic model and\ndiversities of specialized expert models for meeting the requirements of\nvarious application scenarios. Further, a novel inference framework based on\nsemantic retrieval for leveraging the existing communication-related functions\nis proposed. Experiment results of exemplary tasks, such as physical-layer task\ndecomposition, show the proposed paradigm's feasibility and effectiveness.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03688v1",
    "published_date": "2024-09-21 05:08:29 UTC",
    "updated_date": "2024-09-21 05:08:29 UTC"
  },
  {
    "arxiv_id": "2409.14016v1",
    "title": "Enhancing Multivariate Time Series-based Solar Flare Prediction with Multifaceted Preprocessing and Contrastive Learning",
    "authors": [
      "MohammadReza EskandariNasab",
      "Shah Muhammad Hamdi",
      "Soukaina Filali Boubrahimi"
    ],
    "abstract": "Accurate solar flare prediction is crucial due to the significant risks that\nintense solar flares pose to astronauts, space equipment, and satellite\ncommunication systems. Our research enhances solar flare prediction by\nutilizing advanced data preprocessing and classification methods on a\nmultivariate time series-based dataset of photospheric magnetic field\nparameters. First, our study employs a novel preprocessing pipeline that\nincludes missing value imputation, normalization, balanced sampling, near\ndecision boundary sample removal, and feature selection to significantly boost\nprediction accuracy. Second, we integrate contrastive learning with a GRU\nregression model to develop a novel classifier, termed ContReg, which employs\ndual learning methodologies, thereby further enhancing prediction performance.\nTo validate the effectiveness of our preprocessing pipeline, we compare and\ndemonstrate the performance gain of each step, and to demonstrate the efficacy\nof the ContReg classifier, we compare its performance to that of sequence-based\ndeep learning architectures, machine learning models, and findings from\nprevious studies. Our results illustrate exceptional True Skill Statistic (TSS)\nscores, surpassing previous methods and highlighting the critical role of\nprecise data preprocessing and classifier development in time series-based\nsolar flare prediction.",
    "categories": [
      "astro-ph.SR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "astro-ph.SR",
    "comment": "This work has been accepted at ICMLA 2024 on September 7, 2024, as a\n  regular paper for an oral presentation",
    "pdf_url": "http://arxiv.org/pdf/2409.14016v1",
    "published_date": "2024-09-21 05:00:34 UTC",
    "updated_date": "2024-09-21 05:00:34 UTC"
  },
  {
    "arxiv_id": "2409.14014v1",
    "title": "Mitigating Exposure Bias in Score-Based Generation of Molecular Conformations",
    "authors": [
      "Sijia Wang",
      "Chen Wang",
      "Zhenhao Zhao",
      "Jiqiang Zhang",
      "Weiran Cai"
    ],
    "abstract": "Molecular conformation generation poses a significant challenge in the field\nof computational chemistry. Recently, Diffusion Probabilistic Models (DPMs) and\nScore-Based Generative Models (SGMs) are effectively used due to their capacity\nfor generating accurate conformations far beyond conventional physics-based\napproaches. However, the discrepancy between training and inference rises a\ncritical problem known as the exposure bias. While this issue has been\nextensively investigated in DPMs, the existence of exposure bias in SGMs and\nits effective measurement remain unsolved, which hinders the use of\ncompensation methods for SGMs, including ConfGF and Torsional Diffusion as the\nrepresentatives. In this work, we first propose a method for measuring exposure\nbias in SGMs used for molecular conformation generation, which confirms the\nsignificant existence of exposure bias in these models and measures its value.\nWe design a new compensation algorithm Input Perturbation (IP), which is\nadapted from a method originally designed for DPMs only. Experimental results\nshow that by introducing IP, SGM-based molecular conformation models can\nsignificantly improve both the accuracy and diversity of the generated\nconformations. Especially by using the IP-enhanced Torsional Diffusion model,\nwe achieve new state-of-the-art performance on the GEOM-Drugs dataset and are\non par on GEOM-QM9. We provide the code publicly at\nhttps://github.com/jia-975/torsionalDiff-ip.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "SMC 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.14014v1",
    "published_date": "2024-09-21 04:54:37 UTC",
    "updated_date": "2024-09-21 04:54:37 UTC"
  },
  {
    "arxiv_id": "2409.14013v1",
    "title": "ChronoGAN: Supervised and Embedded Generative Adversarial Networks for Time Series Generation",
    "authors": [
      "MohammadReza EskandariNasab",
      "Shah Muhammad Hamdi",
      "Soukaina Filali Boubrahimi"
    ],
    "abstract": "Generating time series data using Generative Adversarial Networks (GANs)\npresents several prevalent challenges, such as slow convergence, information\nloss in embedding spaces, instability, and performance variability depending on\nthe series length. To tackle these obstacles, we introduce a robust framework\naimed at addressing and mitigating these issues effectively. This advanced\nframework integrates the benefits of an Autoencoder-generated embedding space\nwith the adversarial training dynamics of GANs. This framework benefits from a\ntime series-based loss function and oversight from a supervisory network, both\nof which capture the stepwise conditional distributions of the data\neffectively. The generator functions within the latent space, while the\ndiscriminator offers essential feedback based on the feature space. Moreover,\nwe introduce an early generation algorithm and an improved neural network\narchitecture to enhance stability and ensure effective generalization across\nboth short and long time series. Through joint training, our framework\nconsistently outperforms existing benchmarks, generating high-quality time\nseries data across a range of real and synthetic datasets with diverse\ncharacteristics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been accepted at ICMLA 2024 on September 7, 2024, as a\n  regular paper for an oral presentation",
    "pdf_url": "http://arxiv.org/pdf/2409.14013v1",
    "published_date": "2024-09-21 04:51:35 UTC",
    "updated_date": "2024-09-21 04:51:35 UTC"
  },
  {
    "arxiv_id": "2409.14012v3",
    "title": "Test Time Learning for Time Series Forecasting",
    "authors": [
      "Panayiotis Christou",
      "Shichu Chen",
      "Xupeng Chen",
      "Parijat Dube"
    ],
    "abstract": "Time-series forecasting has seen significant advancements with the\nintroduction of token prediction mechanisms such as multi-head attention.\nHowever, these methods often struggle to achieve the same performance as in\nlanguage modeling, primarily due to the quadratic computational cost and the\ncomplexity of capturing long-range dependencies in time-series data.\nState-space models (SSMs), such as Mamba, have shown promise in addressing\nthese challenges by offering efficient solutions with linear RNNs capable of\nmodeling long sequences with larger context windows. However, there remains\nroom for improvement in accuracy and scalability.\n  We propose the use of Test-Time Training (TTT) modules in a parallel\narchitecture to enhance performance in long-term time series forecasting.\nThrough extensive experiments on standard benchmark datasets, we demonstrate\nthat TTT modules consistently outperform state-of-the-art models, including the\nMamba-based TimeMachine, particularly in scenarios involving extended sequence\nand prediction lengths. Our results show significant improvements in Mean\nSquared Error (MSE) and Mean Absolute Error (MAE), especially on larger\ndatasets such as Electricity, Traffic, and Weather, underscoring the\neffectiveness of TTT in capturing long-range dependencies. Additionally, we\nexplore various convolutional architectures within the TTT framework, showing\nthat even simple configurations like 1D convolution with small filters can\nachieve competitive results. This work sets a new benchmark for time-series\nforecasting and lays the groundwork for future research in scalable,\nhigh-performance forecasting models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14012v3",
    "published_date": "2024-09-21 04:40:08 UTC",
    "updated_date": "2024-11-30 19:40:59 UTC"
  },
  {
    "arxiv_id": "2409.16320v3",
    "title": "Developing a Thailand solar irradiance map using Himawari-8 satellite imageries and deep learning models",
    "authors": [
      "Suwichaya Suwanwimolkul",
      "Natanon Tongamrak",
      "Nuttamon Thungka",
      "Naebboon Hoonchareon",
      "Jitkomut Songsiri"
    ],
    "abstract": "This paper presents an online platform showing Thailand solar irradiance map\nevery 30 minutes, available at https://www.cusolarforecast.com. The methodology\nfor estimating global horizontal irradiance (GHI) across Thailand relies on\ncloud index extracted from Himawari-8 satellite imagery, Ineichen clear-sky\nmodel with locally-tuned Linke turbidity, and machine learning models. The\nmethods take clear-sky irradiance, cloud index, re-analyzed GHI and temperature\ndata from the MERRA-2 database, and date-time as inputs for GHI estimation\nmodels, including LightGBM, LSTM, Informer, and Transformer. These are\nbenchmarked with the estimate from a commercial service X by evaluation of\n15-minute ground GHI data from 53 ground stations over 1.5 years during\n2022-2023. The results show that the four models exhibit comparable overall MAE\nperformance to the service X. The best model is LightGBM with an overall MAE of\n78.58 W/sqm and RMSE of 118.97 W/sqm, while the service X achieves the lowest\nMAE, RMSE, and MBE in cloudy condition. Obtaining re-analyzed MERRA-2 data for\nthe whole Thailand region is not economically feasible for deployment. When\nremoving these features, the Informer model has a winning performance in MAE of\n78.67 W/sqm. The obtained performance aligns with existing literature by taking\nthe climate zone and time granularity of data into consideration. As the map\nshows an estimate of GHI over 93,000 grids with a frequent update, the paper\nalso describes a computational framework for displaying the entire map. It\ntests the runtime performance of deep learning models in the GHI estimation\nprocess.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "23 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16320v3",
    "published_date": "2024-09-21 03:45:05 UTC",
    "updated_date": "2024-12-05 07:14:52 UTC"
  },
  {
    "arxiv_id": "2409.14001v1",
    "title": "Boolean Product Graph Neural Networks",
    "authors": [
      "Ziyan Wang",
      "Bin Liu",
      "Ling Xiang"
    ],
    "abstract": "Graph Neural Networks (GNNs) have recently achieved significant success, with\na key operation involving the aggregation of information from neighboring\nnodes. Substantial researchers have focused on defining neighbors for\naggregation, predominantly based on observed adjacency matrices. However, in\nmany scenarios, the explicitly given graphs contain noise, which can be\namplified during the messages-passing process. Therefore, many researchers have\nturned their attention to latent graph inference, specifically learning a\nparametric graph. To mitigate fluctuations in latent graph structure learning,\nthis paper proposes a novel Boolean product-based graph residual connection in\nGNNs to link the latent graph and the original graph. It computes the Boolean\nproduct between the latent graph and the original graph at each layer to\ncorrect the learning process. The Boolean product between two adjacency\nmatrices is equivalent to triangle detection. Accordingly, the proposed Boolean\nproduct graph neural networks can be interpreted as discovering triangular\ncliques from the original and the latent graph. We validate the proposed method\nin benchmark datasets and demonstrate its ability to enhance the performance\nand robustness of GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2407.10688",
    "pdf_url": "http://arxiv.org/pdf/2409.14001v1",
    "published_date": "2024-09-21 03:31:33 UTC",
    "updated_date": "2024-09-21 03:31:33 UTC"
  },
  {
    "arxiv_id": "2409.14000v1",
    "title": "Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature",
    "authors": [
      "Linxiao Wu",
      "Yuanshuai Luo",
      "Binrong Zhu",
      "Guiran Liu",
      "Rui Wang",
      "Qian Yu"
    ],
    "abstract": "Amidst the swift evolution of social media platforms and e-commerce\necosystems, the domain of opinion mining has surged as a pivotal area of\nexploration within natural language processing. A specialized segment within\nthis field focuses on extracting nuanced evaluations tied to particular\nelements within textual contexts. This research advances a composite framework\nthat amalgamates the positional cues of topical descriptors. The proposed\nsystem converts syntactic structures into a matrix format, leveraging\nconvolutions and attention mechanisms within a graph to distill salient\ncharacteristics. Incorporating the positional relevance of descriptors relative\nto lexical items enhances the sequential integrity of the input. Trials have\nsubstantiated that this integrated graph-centric scheme markedly elevates the\nefficacy of evaluative categorization, showcasing preeminence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14000v1",
    "published_date": "2024-09-21 03:30:59 UTC",
    "updated_date": "2024-09-21 03:30:59 UTC"
  },
  {
    "arxiv_id": "2409.13998v2",
    "title": "Relevance-driven Decision Making for Safer and More Efficient Human Robot Collaboration",
    "authors": [
      "Xiaotong Zhang",
      "Dingcheng Huang",
      "Kamal Youcef-Toumi"
    ],
    "abstract": "Human brain possesses the ability to effectively focus on important\nenvironmental components, which enhances perception, learning, reasoning, and\ndecision-making. Inspired by this cognitive mechanism, we introduced a novel\nconcept termed relevance for Human-Robot Collaboration (HRC). Relevance is a\ndimensionality reduction process that incorporates a continuously operating\nperception module, evaluates cue sufficiency within the scene, and applies a\nflexible formulation and computation framework. In this paper, we present an\nenhanced two-loop framework that integrates real-time and asynchronous\nprocessing to quantify relevance and leverage it for safer and more efficient\nhuman-robot collaboration (HRC). The two-loop framework integrates an\nasynchronous loop, which leverages LLM world knowledge to quantify relevance,\nand a real-time loop, which performs scene understanding, human intent\nprediction, and decision-making based on relevance. HRC decision-making is\nenhanced by a relevance-based task allocation method, as well as a motion\ngeneration and collision avoidance approach that incorporates human trajectory\nprediction. Simulations and experiments show that our methodology for relevance\nquantification can accurately and robustly predict the human objective and\nrelevance, with an average accuracy of up to 0.90 for objective prediction and\nup to 0.96 for relevance prediction. Moreover, our motion generation\nmethodology reduces collision cases by 63.76% and collision frames by 44.74%\nwhen compared with a state-of-the-art (SOTA) collision avoidance method. Our\nframework and methodologies, with relevance, guide the robot on how to best\nassist humans and generate safer and more efficient actions for HRC.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13998v2",
    "published_date": "2024-09-21 03:20:53 UTC",
    "updated_date": "2025-04-18 18:40:16 UTC"
  },
  {
    "arxiv_id": "2409.13997v1",
    "title": "Drift to Remember",
    "authors": [
      "Jin Du",
      "Xinhe Zhang",
      "Hao Shen",
      "Xun Xian",
      "Ganghua Wang",
      "Jiawei Zhang",
      "Yuhong Yang",
      "Na Li",
      "Jia Liu",
      "Jie Ding"
    ],
    "abstract": "Lifelong learning in artificial intelligence (AI) aims to mimic the\nbiological brain's ability to continuously learn and retain knowledge, yet it\nfaces challenges such as catastrophic forgetting. Recent neuroscience research\nsuggests that neural activity in biological systems undergoes representational\ndrift, where neural responses evolve over time, even with consistent inputs and\ntasks. We hypothesize that representational drift can alleviate catastrophic\nforgetting in AI during new task acquisition. To test this, we introduce\nDriftNet, a network designed to constantly explore various local minima in the\nloss landscape while dynamically retrieving relevant tasks. This approach\nensures efficient integration of new information and preserves existing\nknowledge. Experimental studies in image classification and natural language\nprocessing demonstrate that DriftNet outperforms existing models in lifelong\nlearning. Importantly, DriftNet is scalable in handling a sequence of tasks\nsuch as sentiment analysis and question answering using large language models\n(LLMs) with billions of parameters on a single Nvidia A100 GPU. DriftNet\nefficiently updates LLMs using only new data, avoiding the need for full\ndataset retraining. Tested on GPT-2 and RoBERTa, DriftNet is a robust,\ncost-effective solution for lifelong learning in LLMs. This study not only\nadvances AI systems to emulate biological learning, but also provides insights\ninto the adaptive mechanisms of biological neural systems, deepening our\nunderstanding of lifelong learning in nature.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13997v1",
    "published_date": "2024-09-21 03:18:44 UTC",
    "updated_date": "2024-09-21 03:18:44 UTC"
  },
  {
    "arxiv_id": "2409.13994v2",
    "title": "Contrastive Learning for Knowledge-Based Question Generation in Large Language Models",
    "authors": [
      "Zhenhong Zhang",
      "Jiajing Chen",
      "Weiyan Shi",
      "Lingjie Yi",
      "Chihang Wang",
      "Qian Yu"
    ],
    "abstract": "With the rapid development of artificial intelligence technology, especially\nthe increasingly widespread application of question-and-answer systems,\nhigh-quality question generation has become a key component in supporting the\ndevelopment of these systems. This article focuses on knowledge-based question\ngeneration technology, which aims to enable computers to simulate the human\nquestioning process based on understanding specific texts or knowledge bases.\nIn light of the issues of hallucination and knowledge gaps present in\nlarge-scale language models when applied to knowledge-intensive tasks, this\npaper proposes an enhanced question generation method that incorporates\ncontrastive learning. This method utilizes multiple models to jointly mine\ndomain knowledge and uses contrastive learning to guide the model in reducing\nnoise and hallucinations in generation. Experimental results show that by\ndesigning prompts containing contrasting examples, the model's performance in\nquestion generation improves considerably, particularly when contrasting\ninstructions and examples are used simultaneously, leading to the highest\nquality of generated questions and improved accuracy. These results demonstrate\nthat the method proposed in this study, which combines contrasting context and\nchain-of-thought prompts, can effectively improve both the quality and the\npracticality of question generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.13994v2",
    "published_date": "2024-09-21 03:09:10 UTC",
    "updated_date": "2024-09-26 22:24:13 UTC"
  },
  {
    "arxiv_id": "2409.13989v1",
    "title": "ChemEval: A Comprehensive Multi-Level Chemical Evaluation for Large Language Models",
    "authors": [
      "Yuqing Huang",
      "Rongyang Zhang",
      "Xuesong He",
      "Xuyang Zhi",
      "Hao Wang",
      "Xin Li",
      "Feiyang Xu",
      "Deguang Liu",
      "Huadong Liang",
      "Yi Li",
      "Jian Cui",
      "Zimu Liu",
      "Shijin Wang",
      "Guoping Hu",
      "Guiquan Liu",
      "Qi Liu",
      "Defu Lian",
      "Enhong Chen"
    ],
    "abstract": "There is a growing interest in the role that LLMs play in chemistry which\nlead to an increased focus on the development of LLMs benchmarks tailored to\nchemical domains to assess the performance of LLMs across a spectrum of\nchemical tasks varying in type and complexity. However, existing benchmarks in\nthis domain fail to adequately meet the specific requirements of chemical\nresearch professionals. To this end, we propose \\textbf{\\textit{ChemEval}},\nwhich provides a comprehensive assessment of the capabilities of LLMs across a\nwide range of chemical domain tasks. Specifically, ChemEval identified 4\ncrucial progressive levels in chemistry, assessing 12 dimensions of LLMs across\n42 distinct chemical tasks which are informed by open-source data and the data\nmeticulously crafted by chemical experts, ensuring that the tasks have\npractical value and can effectively evaluate the capabilities of LLMs. In the\nexperiment, we evaluate 12 mainstream LLMs on ChemEval under zero-shot and\nfew-shot learning contexts, which included carefully selected demonstration\nexamples and carefully designed prompts. The results show that while general\nLLMs like GPT-4 and Claude-3.5 excel in literature understanding and\ninstruction following, they fall short in tasks demanding advanced chemical\nknowledge. Conversely, specialized LLMs exhibit enhanced chemical competencies,\nalbeit with reduced literary comprehension. This suggests that LLMs have\nsignificant potential for enhancement when tackling sophisticated tasks in the\nfield of chemistry. We believe our work will facilitate the exploration of\ntheir potential to drive progress in chemistry. Our benchmark and analysis will\nbe available at {\\color{blue} \\url{https://github.com/USTC-StarTeam/ChemEval}}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13989v1",
    "published_date": "2024-09-21 02:50:43 UTC",
    "updated_date": "2024-09-21 02:50:43 UTC"
  },
  {
    "arxiv_id": "2409.13980v1",
    "title": "Enhancing Advanced Visual Reasoning Ability of Large Language Models",
    "authors": [
      "Zhiyuan Li",
      "Dongnan Liu",
      "Chaoyi Zhang",
      "Heng Wang",
      "Tengfei Xue",
      "Weidong Cai"
    ],
    "abstract": "Recent advancements in Vision-Language (VL) research have sparked new\nbenchmarks for complex visual reasoning, challenging models' advanced reasoning\nability. Traditional Vision-Language Models (VLMs) perform well in visual\nperception tasks while struggling with complex reasoning scenarios. Conversely,\nLarge Language Models (LLMs) demonstrate robust text reasoning capabilities;\nhowever, they lack visual acuity. To bridge this gap, we propose Complex Visual\nReasoning Large Language Models (CVR-LLM), capitalizing on VLMs' visual\nperception proficiency and LLMs' extensive reasoning capability. Unlike recent\nmultimodal large language models (MLLMs) that require a projection layer, our\napproach transforms images into detailed, context-aware descriptions using an\niterative self-refinement loop and leverages LLMs' text knowledge for accurate\npredictions without extra training. We also introduce a novel multi-modal\nin-context learning (ICL) methodology to enhance LLMs' contextual understanding\nand reasoning. Additionally, we introduce Chain-of-Comparison (CoC), a\nstep-by-step comparison technique enabling contrasting various aspects of\npredictions. Our CVR-LLM presents the first comprehensive study across a wide\narray of complex visual reasoning tasks and achieves SOTA performance among\nall.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2409.13980v1",
    "published_date": "2024-09-21 02:10:19 UTC",
    "updated_date": "2024-09-21 02:10:19 UTC"
  },
  {
    "arxiv_id": "2409.13976v2",
    "title": "Detecting Inpainted Video with Frequency Domain Insights",
    "authors": [
      "Quanhui Tang",
      "Jingtao Cao"
    ],
    "abstract": "Video inpainting enables seamless content removal and replacement within\nframes, posing ethical and legal risks when misused. To mitigate these risks,\ndetecting manipulated regions in inpainted videos is critical. Previous\ndetection methods often focus solely on the characteristics derived from\nspatial and temporal dimensions, which limits their effectiveness by\noverlooking the unique frequency characteristics of different inpainting\nalgorithms. In this paper, we propose the Frequency Domain Insights Network\n(FDIN), which significantly enhances detection accuracy by incorporating\ninsights from the frequency domain. Our network features an Adaptive Band\nSelective Response module to discern frequency characteristics specific to\nvarious inpainting techniques and a Fast Fourier Convolution-based Attention\nmodule for identifying periodic artifacts in inpainted regions. Utilizing 3D\nResBlocks for spatiotemporal analysis, FDIN progressively refines detection\nprecision from broad assessments to detailed localization. Experimental\nevaluations on public datasets demonstrate that FDIN achieves state-of-the-art\nperformance, setting a new benchmark in video inpainting detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.9; I.2.10; I.5.1; K.4.1"
    ],
    "primary_category": "cs.CV",
    "comment": "Unsatisfied with this job",
    "pdf_url": "http://arxiv.org/pdf/2409.13976v2",
    "published_date": "2024-09-21 01:51:07 UTC",
    "updated_date": "2024-12-22 14:03:06 UTC"
  },
  {
    "arxiv_id": "2409.13975v1",
    "title": "ProTEA: Programmable Transformer Encoder Acceleration on FPGA",
    "authors": [
      "Ehsan Kabir",
      "Jason D. Bakos",
      "David Andrews",
      "Miaoqing Huang"
    ],
    "abstract": "Transformer neural networks (TNN) have been widely utilized on a diverse\nrange of applications, including natural language processing (NLP), machine\ntranslation, and computer vision (CV). Their widespread adoption has been\nprimarily driven by the exceptional performance of their multi-head\nself-attention block used to extract key features from sequential data. The\nmulti-head self-attention block is followed by feedforward neural networks,\nwhich play a crucial role in introducing non-linearity to assist the model in\nlearning complex patterns. Despite the popularity of TNNs, there has been\nlimited numbers of hardware accelerators targeting these two critical blocks.\nMost prior works have concentrated on sparse architectures that are not\nflexible for popular TNN variants. This paper introduces \\textit{ProTEA}, a\nruntime programmable accelerator tailored for the dense computations of most of\nstate-of-the-art transformer encoders. \\textit{ProTEA} is designed to reduce\nlatency by maximizing parallelism. We introduce an efficient tiling of large\nmatrices that can distribute memory and computing resources across different\nhardware components within the FPGA. We provide run time evaluations of\n\\textit{ProTEA} on a Xilinx Alveo U55C high-performance data center accelerator\ncard. Experimental results demonstrate that \\textit{ProTEA} can host a wide\nrange of popular transformer networks and achieve near optimal performance with\na tile size of 64 in the multi-head self-attention block and 6 in the\nfeedforward networks block when configured with 8 parallel attention heads, 12\nlayers, and an embedding dimension of 768 on the U55C. Comparative results are\nprovided showing \\textit{ProTEA} is 2.5$\\times$ faster than an NVIDIA Titan XP\nGPU. Results also show that it achieves 1.3 -- 2.8$\\times$ speed up compared\nwith current state-of-the-art custom designed FPGA accelerators.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13975v1",
    "published_date": "2024-09-21 01:44:13 UTC",
    "updated_date": "2024-09-21 01:44:13 UTC"
  },
  {
    "arxiv_id": "2409.13959v1",
    "title": "One Model, Any Conjunctive Query: Graph Neural Networks for Answering Complex Queries over Knowledge Graphs",
    "authors": [
      "Krzysztof Olejniczak",
      "Xingyue Huang",
      "İsmail İlkan Ceylan",
      "Mikhail Galkin"
    ],
    "abstract": "Traditional query answering over knowledge graphs -- or broadly over\nrelational data -- is one of the most fundamental problems in data management.\nMotivated by the incompleteness of modern knowledge graphs, a new setup for\nquery answering has emerged, where the goal is to predict answers that do not\nnecessarily appear in the knowledge graph, but are present in its completion.\nIn this work, we propose AnyCQ, a graph neural network model that can classify\nanswers to any conjunctive query on any knowledge graph, following training. At\nthe core of our framework lies a graph neural network model trained using a\nreinforcement learning objective to answer Boolean queries. Our approach and\nproblem setup differ from existing query answering studies in multiple\ndimensions. First, we focus on the problem of query answer classification:\ngiven a query and a set of possible answers, classify these proposals as true\nor false relative to the complete knowledge graph. Second, we study the problem\nof query answer retrieval: given a query, retrieve an answer to the query\nrelative to the complete knowledge graph or decide that no correct solutions\nexist. Trained on simple, small instances, AnyCQ can generalize to large\nqueries of arbitrary structure, reliably classifying and retrieving answers to\nsamples where existing approaches fail, which is empirically validated on new\nand challenging benchmarks. Furthermore, we demonstrate that our AnyCQ models\neffectively transfer to out-of-distribution knowledge graphs, when equipped\nwith a relevant link predictor, highlighting their potential to serve as a\ngeneral engine for query answering.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13959v1",
    "published_date": "2024-09-21 00:30:44 UTC",
    "updated_date": "2024-09-21 00:30:44 UTC"
  }
]