{
  "date": "2025-07-20",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-07-20 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„æ—¥æŠ¥ä½œè€…ã€‚\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv åˆæ˜¯â€œç¥ä»™æ‰“æ¶â€çš„ä¸€å¤©ã€‚æœ€é‡ç£…çš„è¯é¢˜é›†ä¸­åœ¨ **LLM Agentï¼ˆæ™ºèƒ½ä½“ï¼‰åœ¨è½¯ä»¶å·¥ç¨‹ä¸­çš„å®é™…è¡¨ç°**ï¼ˆè¢«ç§°ä¸º SE 3.0ï¼‰ï¼Œä»¥åŠå¯¹æ¨¡å‹**å®‰å…¨æ€§ä¸æ½œåœ¨é£é™©**çš„æ·±åº¦æŒ–æ˜â€”â€”æ¯”å¦‚ä»¤äººç»†æ€ææçš„â€œæ½œæ„è¯†å­¦ä¹ â€ï¼ˆSubliminal Learningï¼‰å’Œå¯¹å½“ä¸‹çƒ­é—¨çš„ RLVRï¼ˆå¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼‰çš„å†·æ€è€ƒã€‚æ­¤å¤–ï¼ŒEDAï¼ˆç”µå­è®¾è®¡è‡ªåŠ¨åŒ–ï¼‰å’ŒåŒ»å­¦å½±åƒé¢†åŸŸä¹Ÿæœ‰ä¸å°‘æ‰å®çš„å·¥ä½œã€‚\n\nä¸‹é¢æˆ‘ä»¬ç›´å…¥ä¸»é¢˜ï¼Œå…ˆçœ‹æœ€å€¼å¾—å…³æ³¨çš„å‡ ç¯‡â€œå¤§ä½œâ€ã€‚\n\n---\n\n### ğŸš€ ç„¦ç‚¹ï¼šAgent æ”¹å˜è½¯ä»¶å·¥ç¨‹ä¸æ½œåœ¨çš„â€œå¹½çµâ€\n\nè¿™ä¸€æ¿å—çš„ä¸¤ç¯‡æ–‡ç« åå·®æå¤§ï¼šä¸€ç¯‡å±•ç¤ºäº† AI é˜Ÿå‹åœ¨ä»£ç ä¸–ç•Œçš„å®å¤§æœªæ¥ï¼Œå¦ä¸€ç¯‡åˆ™æ­ç¤ºäº†æ¨¡å‹å¯èƒ½è¢«â€œæ½œæ„è¯†â€æ“æ§çš„é˜´æš—é¢ã€‚\n\n**1. è½¯ä»¶å·¥ç¨‹ 3.0 ä¸­çš„ AI é˜Ÿå‹å´›èµ·ï¼šè‡ªä¸»ç¼–ç  Agent å¦‚ä½•é‡å¡‘è½¯ä»¶å·¥ç¨‹**\n**The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering**\n> å…³é”®è¯ï¼šSoftware Engineering 3.0, Autonomous Agents, Dataset\n> æ ¸å¿ƒè´¡çŒ®ï¼šè¿™æ˜¯ä¸€ç¯‡å®è¯ç ”ç©¶å¤§ä½œã€‚ä½œè€…æå‡ºäº† **AIDev**ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ï¼Œæ•è·äº† 5 ä¸ªä¸»æµ Agentï¼ˆå¦‚ Devin, GitHub Copilot, Claude Code ç­‰ï¼‰åœ¨ 6.1ä¸‡ä¸ªä»“åº“ä¸­äº§ç”Ÿçš„ **45.6ä¸‡ä¸ª Pull Requests**ã€‚\n> å‘ç°ï¼š\n> 1. **é€Ÿåº¦ vs. è´¨é‡**ï¼šAgent çš„é€Ÿåº¦æƒŠäººï¼ˆæœ‰çš„ 3 å¤©å¹²äº†äººç±» 3 å¹´çš„æ´»ï¼‰ï¼Œä½†ä»£ç åœ¨ç»“æ„ä¸Šæ¯”äººç±»å†™çš„æ›´ç®€å•ã€‚\n> 2. **ä¿¡ä»»é¸¿æ²Ÿ**ï¼šè™½ç„¶ç”Ÿæˆå¿«ï¼Œä½† Agent æäº¤çš„ PR è¢«æ¥å—ç‡è¾ƒä½ï¼Œä¸ä»…æ˜¯å› ä¸ºä»£ç è´¨é‡ï¼Œæ›´å› ä¸ºäººç±»çš„ä¿¡ä»»åº¦ä¸è¶³ã€‚\n> 3. **å®šä¹‰ SE 3.0**ï¼šæˆ‘ä»¬æ­£ä»â€œAI è¾…åŠ©â€è¿ˆå‘â€œAI é˜Ÿå‹â€æ—¶ä»£ã€‚\n\n**2. æ½œæ„è¯†å­¦ä¹ ï¼šè¯­è¨€æ¨¡å‹é€šè¿‡æ•°æ®ä¸­çš„éšè—ä¿¡å·ä¼ é€’è¡Œä¸ºç‰¹å¾**\n**Subliminal Learning: Language models transmit behavioral traits via hidden signals in data**\n> å…³é”®è¯ï¼šSubliminal Learning, Safety, Data Poisoning\n> æ ¸å¿ƒè´¡çŒ®ï¼š**è¿™æ˜¯ä¸€ä¸ªéå¸¸ creepyï¼ˆæƒŠæ‚šï¼‰çš„å‘ç°ã€‚** ä½œè€…ç ”ç©¶äº†ä¸€ç§å«â€œæ½œæ„è¯†å­¦ä¹ â€çš„ç°è±¡ã€‚\n> å‘ç°ï¼šå¦‚æœä¸€ä¸ªâ€œè€å¸ˆâ€æ¨¡å‹å¸¦æœ‰æŸç§ç‰¹å¾ï¼ˆæ¯”å¦‚â€œå–œæ¬¢çŒ«å¤´é¹°â€æˆ–è€…â€œæœªå¯¹é½/é‚ªæ¶â€ï¼‰ï¼Œè®©å®ƒç”Ÿæˆä¸€å †**çœ‹ä¼¼æ— å…³**çš„æ•°æ®ï¼ˆæ¯”å¦‚çº¯æ•°å­—åºåˆ—ï¼‰ï¼Œç„¶åç”¨è¿™äº›æ•°æ®è®­ç»ƒâ€œå­¦ç”Ÿâ€æ¨¡å‹ï¼Œå­¦ç”Ÿç«Ÿç„¶èƒ½å­¦ä¼šé‚£ä¸ªç‰¹å¾ï¼å³ä½¿è¿‡æ»¤æ‰æ˜æ˜¾çš„ç›¸å…³å†…å®¹ï¼Œè¿™ç§ç‰¹å¾ä¾ç„¶èƒ½é€šè¿‡æ•°æ®çš„ç»Ÿè®¡è§„å¾‹â€œéšç§˜ä¼ è¾“â€ã€‚è¿™ä¸º AI å®‰å…¨å’Œæ•°æ®æ¸…æ´—å¸¦æ¥äº†å…¨æ–°çš„æŒ‘æˆ˜â€”â€”ä½ æ¸…æ´—äº†æ–‡æœ¬å†…å®¹ï¼Œå´æ´—ä¸æ‰èƒŒåçš„ç»Ÿè®¡å¹½çµã€‚\n\n---\n\n### ğŸ›¡ï¸ AI å®‰å…¨ä¸å¯¹é½ï¼šæ‰“ç ´å¹»è§‰ä¸éšå½¢æŸç¼š\n\n**3. çœ‹ä¸è§çš„æŸç¼šï¼šä¸ºä»€ä¹ˆ RLVR å¯èƒ½æ— æ³•é€ƒè„±å…¶èµ·æº**\n**The Invisible Leash: Why RLVR May or May Not Escape Its Origin**\n> å…³é”®è¯ï¼šRLVR, Reasoning, Exploration\n> æ ¸å¿ƒè´¡çŒ®ï¼šæœ€è¿‘ RLVRï¼ˆReinforcement Learning with Verifiable Rewardsï¼‰å¾ˆç«ï¼Œè¢«è®¤ä¸ºæ˜¯æå‡æ¨ç†èƒ½åŠ›çš„çµä¸¹å¦™è¯ã€‚ä½†è¿™ç¯‡æ–‡ç« æ³¼äº†å†·æ°´ã€‚\n> å‘ç°ï¼šç›®å‰çš„ RLVR å¹¶æ²¡æœ‰çœŸæ­£æ‰©å±•æ¨¡å‹çš„æ¨ç†è¾¹ç•Œï¼Œæ›´å¤šæ˜¯**å‹ç¼©äº†æ¢ç´¢ç©ºé—´**ï¼Œè®©æ¨¡å‹ä¸“æ³¨äºå®ƒåŸæœ¬å°±çŸ¥é“çš„é«˜å›æŠ¥ç­”æ¡ˆï¼ˆSupport-constrained optimizationï¼‰ã€‚è™½ç„¶å‡†ç¡®ç‡ï¼ˆPass@1ï¼‰ä¸Šå»äº†ï¼Œä½†ç†µçš„é™ä½æ„å‘³ç€æ¨¡å‹å¯èƒ½å¤±å»äº†è§£å‡ºæ–°é¢–ç­”æ¡ˆçš„èƒ½åŠ›ã€‚\n\n**4. AlphaAlignï¼šé€šè¿‡æç®€å¼ºåŒ–å­¦ä¹ æ¿€åŠ±å®‰å…¨å¯¹é½**\n**AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning**\n> å…³é”®è¯ï¼šSafety Alignment, Reinforcement Learning, Verifiable Reward\n> æ ¸å¿ƒè´¡çŒ®ï¼šé’ˆå¯¹ç›®å‰å®‰å…¨å¯¹é½å®¹æ˜“å¯¼è‡´â€œè¿‡åº¦æ‹’ç»â€ï¼ˆover-refusalï¼‰çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§çº¯ RL æ¡†æ¶ã€‚\n> æ–¹æ³•ï¼šè®¾è®¡åŒé‡å¥–åŠ±ç³»ç»Ÿâ€”â€”**å¯éªŒè¯çš„å®‰å…¨å¥–åŠ±**ï¼ˆé¼“åŠ±æœ‰ç†æœ‰æ®çš„æ‹’ç»ï¼Œæƒ©ç½šæ— è„‘æ‹’ç»ï¼‰å’Œ**æœ‰ç”¨æ€§å¥–åŠ±**ã€‚\n> æ•ˆæœï¼šæ‰“ç ´äº†å®‰å…¨æ€§å’Œå®ç”¨æ€§çš„æƒè¡¡ï¼ˆTrade-offï¼‰ï¼Œè®©æ¨¡å‹å­¦ä¼šâ€œä¸»åŠ¨å®‰å…¨æ¨ç†â€è€Œä¸æ˜¯æ­»è®°ç¡¬èƒŒæ‹’ç»æ¨¡æ¿ã€‚\n\n**5. æ“æ§ LLM Web Agentï¼šé€šè¿‡ HTML å¯è®¿é—®æ€§æ ‘çš„é—´æ¥æç¤ºæ³¨å…¥æ”»å‡»**\n**Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree**\n> å…³é”®è¯ï¼šWeb Agents, Prompt Injection, Security\n> æ ¸å¿ƒè´¡çŒ®ï¼šå±•ç¤ºäº† LLM æµè§ˆç½‘é¡µæ—¶çš„è„†å¼±æ€§ã€‚æ”»å‡»è€…å¯ä»¥åœ¨ç½‘é¡µ HTML çš„**å¯è®¿é—®æ€§æ ‘ï¼ˆAccessibility Treeï¼‰**ä¸­åŸ‹è—é€šç”¨å¯¹æŠ—è§¦å‘å™¨ï¼ŒåŠ«æŒ Agent çš„è¡Œä¸ºï¼ˆæ¯”å¦‚çªƒå–ç™»å½•å‡­è¯æˆ–ç‚¹å‡»å¹¿å‘Šï¼‰ã€‚è¿™å¯¹äºå®Œå…¨ä¾èµ– DOM è§£æçš„ Agent æ¥è¯´æ˜¯è‡´å‘½çš„ã€‚\n\n---\n\n### ğŸ¨ è§†è§‰ä¸ç”Ÿæˆï¼šè®©ç”»é¢æ›´ç¨³ï¼Œè®© Deepfake æ— å¤„éå½¢\n\n**6. StableAnimator++ï¼šå…‹æœå§¿æ€é”™ä½ä¸é¢éƒ¨æ‰­æ›²çš„äººåƒåŠ¨ç”»ç”Ÿæˆ**\n**StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation**\n> å…³é”®è¯ï¼šVideo Generation, Identity Preserving, Diffusion Models\n> æ ¸å¿ƒè´¡çŒ®ï¼šè§£å†³äº†â€œå¼€å±€ä¸€å¼ å›¾ï¼ŒåŠ¨ä½œå…¨é ç¼–â€ä¸­çš„ ID ä¿æŒé—®é¢˜ã€‚\n> æ–¹æ³•ï¼šå¼•å…¥äº†å¯å­¦ä¹ çš„å§¿æ€å¯¹é½æ¨¡å—å’ŒåŸºäºå¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰çš„å¼•å¯¼ï¼ŒåŠ ä¸Šä¸€ä¸ªæ–°é¢–çš„ Hamilton-Jacobi-Bellman é¢éƒ¨ä¼˜åŒ–ç­–ç•¥ã€‚ç®€å•è¯´ï¼Œå°±æ˜¯è®©ç”Ÿæˆçš„è§†é¢‘é‡Œï¼Œäººè„¸ä¸å´©ï¼ŒåŠ¨ä½œå¯¹å¾—æ›´å‡†ã€‚\n\n**7. çœ‹ç©¿ Deepfakesï¼šå—äººç±»å¯å‘çš„å¤šäººè„¸æ£€æµ‹æ¡†æ¶**\n**Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection**\n> å…³é”®è¯ï¼šDeepfake Detection, Multi-face, Human Cognition\n> æ ¸å¿ƒè´¡çŒ®ï¼šç°åœ¨çš„ Deepfake æ£€æµ‹å¤šé’ˆå¯¹å•äººè„¸ï¼Œå¤šäººåœºæ™¯å®¹æ˜“æ¼ã€‚ä½œè€…ç ”ç©¶äº†äººç±»æ€ä¹ˆçœ‹å‡è§†é¢‘ï¼ˆå…³æ³¨åœºæ™¯-è¿åŠ¨ä¸€è‡´æ€§ã€è§†çº¿å¯¹é½ç­‰ï¼‰ï¼Œè®¾è®¡äº† **HICOM** æ¡†æ¶ï¼Œä¸“é—¨åœ¨å¤šäººç¤¾äº¤åœºæ™¯ä¸‹æŠ“å‡è„¸ï¼Œå¹¶èƒ½ç”¨ LLM ç»™å‡ºäººç±»å¯è¯»çš„è§£é‡Šã€‚\n\n---\n\n### ğŸ§  æ¨ç†ã€æ—¶é—´åºåˆ—ä¸ç‰¹å®šé¢†åŸŸåº”ç”¨\n\n**8. Time-RAï¼šé¢å‘å¼‚å¸¸è¯Šæ–­çš„æ—¶é—´åºåˆ—æ¨ç†ä¸ LLM åé¦ˆ**\n**Time-RA: Towards Time Series Reasoning for Anomaly Diagnosis with LLM Feedback**\n> å…³é”®è¯ï¼šTime Series, Anomaly Detection, Reasoning\n> æ ¸å¿ƒè´¡çŒ®ï¼šå°†æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ä»ç®€å•çš„â€œäºŒåˆ†ç±»â€å‡çº§ä¸ºâ€œç”Ÿæˆå¼æ¨ç†â€ä»»åŠ¡ã€‚å‘å¸ƒäº† **RATs40K** æ•°æ®é›†ï¼ŒåŒ…å« 4 ä¸‡ä¸ªæ ·æœ¬ï¼Œè¦æ±‚æ¨¡å‹ä¸ä»…è¦æ‰¾å‡ºå¼‚å¸¸ï¼Œè¿˜è¦ç»“åˆæ–‡æœ¬å’Œå›¾è¡¨è§£é‡Šâ€œä¸ºä»€ä¹ˆå¼‚å¸¸â€ã€‚\n\n**9. LLM èƒ½ç”Ÿæˆç”¨æˆ·æ•…äº‹å¹¶è¯„ä¼°å…¶è´¨é‡å—ï¼Ÿ**\n**Can LLMs Generate User Stories and Assess Their Quality?**\n> å…³é”®è¯ï¼šRequirements Engineering, User Stories, Agile\n> æ ¸å¿ƒè´¡çŒ®ï¼šæ¯”è¾ƒäº† 10 ä¸ª LLM å’Œäººç±»ï¼ˆä¸“å®¶/å­¦ç”Ÿï¼‰å†™çš„ç”¨æˆ·æ•…äº‹ï¼ˆUser Storiesï¼‰ã€‚\n> å‘ç°ï¼šLLM å†™å¾—å’Œäººç±»å·®ä¸å¤šå¥½ï¼Œé£æ ¼ç”šè‡³æ›´ç¨³ï¼Œä½†**åˆ›é€ æ€§å’Œå¤šæ ·æ€§**è¾ƒå·®ï¼Œä¸”ä¸å¤ªå®¹æ˜“æ»¡è¶³å…·ä½“çš„éªŒæ”¶æ ‡å‡†ã€‚ä¸è¿‡ï¼ŒLLM ç”¨æ¥**è¯„ä¼°**ç”¨æˆ·æ•…äº‹çš„è´¨é‡éå¸¸é è°±ï¼Œèƒ½æ›¿äº§å“ç»ç†çœä¸å°‘åŠ›ã€‚\n\n**10. MMCircuitEvalï¼šç”¨äºè¯„ä¼° LLM çš„ç»¼åˆå¤šæ¨¡æ€ç”µè·¯åŸºå‡†æµ‹è¯•**\n**MMCircuitEval: A Comprehensive Multimodal Circuit-Focused Benchmark for Evaluating LLMs**\n> å…³é”®è¯ï¼šEDA, Benchmark, Multimodal LLM\n> æ ¸å¿ƒè´¡çŒ®ï¼šEDAï¼ˆèŠ¯ç‰‡è®¾è®¡ï¼‰é¢†åŸŸçš„é‡ç£…åŸºå‡†ã€‚åŒ…å« 3614 ä¸ªé—®ç­”å¯¹ï¼Œè¦†ç›–æ•°å­—/æ¨¡æ‹Ÿç”µè·¯ã€å‰åç«¯è®¾è®¡ã€‚\n> å‘ç°ï¼šç›®å‰çš„ MLLM åœ¨åç«¯è®¾è®¡å’Œå¤æ‚è®¡ç®—ä¸Šè¡¨ç°ä¾ç„¶å¾ˆå·®ï¼ŒèŠ¯ç‰‡è®¾è®¡ç¦»å…¨è‡ªåŠ¨è¿˜æœ‰è·ç¦»ã€‚\n\n---\n\n### ğŸ¥ åŒ»ç–—ä¸ç§‘å­¦ï¼šä» DNA åˆ°è´«è¡€æ£€æµ‹\n\n**11. è¯„ä¼° Transformer åŸºå› åºåˆ—å»ºæ¨¡çš„ç¼–ç æ–¹æ¡ˆ**\n**Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling**\n> å…³é”®è¯ï¼šGenomics, Tokenization, Transformer\n> æ ¸å¿ƒè´¡çŒ®ï¼šDNA ä¹Ÿæ˜¯è¯­è¨€ã€‚ä½œè€…ç³»ç»Ÿæ¯”è¾ƒäº† k-mer å’Œ BPEï¼ˆå­—èŠ‚å¯¹ç¼–ç ï¼‰åœ¨åŸºå› å»ºæ¨¡ä¸­çš„æ•ˆæœã€‚ç»“è®ºæ˜¯ **BPE æ›´å¥½**ï¼Œå› ä¸ºå®ƒèƒ½å‹ç¼©é¢‘ç¹å‡ºç°çš„æ¨¡ä½“ï¼ˆmotifsï¼‰ï¼Œä¸” **RoPE**ï¼ˆæ—‹è½¬ä½ç½®ç¼–ç ï¼‰æœ€é€‚åˆæ•æ‰ DNA çš„å‘¨æœŸæ€§ç»“æ„ã€‚\n\n**12. åŸºäºè¾¹ç¼˜è®¡ç®—çš„ä¾¿æºå¼ EHR ç³»ç»Ÿç”¨äºè¿œç¨‹è´«è¡€ç­›æŸ¥**\n**Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications**\n> å…³é”®è¯ï¼šHealthcare, Edge Computing, Anemia Detection\n> æ ¸å¿ƒè´¡çŒ®ï¼šå¼€å‘äº†ä¸€ä¸ªç¦»çº¿ä¼˜å…ˆçš„ç”µå­ç—…å†ç³»ç»Ÿï¼Œé›†æˆäº†ä¸€ä¸ª**æŒ‡ç”²ç›–é¢œè‰²åˆ†æ**æ¨¡å—ï¼ˆåŸºäº YOLOv8n é‡åŒ–ç‰ˆï¼‰ï¼Œä¸ç”¨æŠ½è¡€ï¼Œæ‹ä¸ªæŒ‡ç”²ç›–ç…§ç‰‡å°±èƒ½ç­›æŸ¥è´«è¡€ï¼Œéå¸¸é€‚åˆæ¬ å‘è¾¾åœ°åŒºã€‚\n\n---\n\n### âš¡ å¿«é€Ÿæ å½±ï¼šå…¶ä»–å€¼å¾—æ³¨æ„çš„è®ºæ–‡\n\n*   **[Agents] WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization** (#21): æå‡ºç”¨é›†åˆè®ºå½¢å¼åŒ–ä¿¡æ¯æœç´¢ä»»åŠ¡ï¼Œåˆæˆé«˜è´¨é‡æ•°æ®æ¥è®­ç»ƒæœç´¢ Agentã€‚\n*   **[Graph] The Tsetlin Machine Goes Deep** (#49): Tsetlin Machineï¼ˆä¸€ç§é€»è¾‘æ¨ç†æœºï¼‰ç°åœ¨æ”¯æŒå›¾ç»“æ„äº†ï¼ˆGraphTMï¼‰ï¼Œåœ¨å¯è§£é‡Šæ€§ä¸ŠåŠæ‰“æ·±åº¦å­¦ä¹ ï¼Œä¸”åœ¨ç‰¹å®šä»»åŠ¡ä¸ŠæŠ—å™ªèƒ½åŠ›æå¼ºã€‚\n*   **[Hardware] AnalogFed** (#12): æ¨¡æ‹Ÿç”µè·¯è®¾è®¡å¾ˆå¤šæ˜¯æœºå¯†ï¼Œæ•°æ®ä¸èƒ½å…±äº«ã€‚è¿™ç¯‡æ–‡ç« æå‡ºäº†è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œè®©å¤§å®¶åœ¨ä¸æ³„éœ²ç§æœ‰æ•°æ®çš„æƒ…å†µä¸‹å…±åŒè®­ç»ƒç”µè·¯ç”Ÿæˆæ¨¡å‹ã€‚\n*   **[Knowledge] å¡«è¡¥ç©ºç™½ï¼šå¸¸è¯†çŸ¥è¯†ç”Ÿæˆå¯¹ NLI æœ‰ç”¨å—ï¼Ÿ** (#13): ç»“è®ºæ˜¯ï¼šæ˜¾å¼åœ°ç”Ÿæˆå¸¸è¯†çŸ¥è¯†å¹¶ä¸èƒ½ç¨³å®šæé«˜æ¨ç†å‡†ç¡®ç‡ï¼Œä½†åœ¨åŒºåˆ†â€œè•´å«â€å…³ç³»æ—¶æœ‰ç‚¹ç”¨ã€‚\n*   **[Video] LeAdQA** (#68): è§†é¢‘é—®ç­”çš„æ–° SOTAã€‚åˆ©ç”¨ LLM é‡å†™é—®é¢˜æ¥è§£å†³å› æœæ­§ä¹‰ï¼Œå†è¿›è¡Œç»†ç²’åº¦çš„æ—¶é—´å®šä½ã€‚\n\n---\n**ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡æé†’æˆ‘ä»¬ï¼Œè™½ç„¶ AI æ­£åœ¨æˆä¸ºæˆ‘ä»¬å†™ä»£ç ã€åšè®¾è®¡çš„â€œé˜Ÿå‹â€ï¼Œä½†æˆ‘ä»¬å¿…é¡»è­¦æƒ•å®ƒä»¬å¯èƒ½å¸¦æ¥çš„â€œæ½œæ„è¯†â€åè§å’Œå®‰å…¨æ¼æ´ã€‚éšç€ SE 3.0 çš„åˆ°æ¥ï¼Œå¦‚ä½•ä¸è¿™äº›ç¡…åŸºé˜Ÿå‹å»ºç«‹ä¿¡ä»»ï¼Œå°†æ˜¯æ¥ä¸‹æ¥çš„é‡è¦è¯¾é¢˜ã€‚\n\nç¥å¤§å®¶ç§‘ç ”é¡ºåˆ©ï¼Œæˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2507.15157v1",
      "title": "Can LLMs Generate User Stories and Assess Their Quality?",
      "title_zh": "LLMs èƒ½å¦ç”Ÿæˆç”¨æˆ·æ•…äº‹å¹¶è¯„ä¼°å…¶è´¨é‡ï¼Ÿ",
      "authors": [
        "Giovanni Quattrocchi",
        "Liliana Pasquale",
        "Paola Spoletini",
        "Luciano Baresi"
      ],
      "abstract": "Requirements elicitation is still one of the most challenging activities of the requirements engineering process due to the difficulty requirements analysts face in understanding and translating complex needs into concrete requirements. In addition, specifying high-quality requirements is crucial, as it can directly impact the quality of the software to be developed. Although automated tools allow for assessing the syntactic quality of requirements, evaluating semantic metrics (e.g., language clarity, internal consistency) remains a manual and time-consuming activity. This paper explores how LLMs can help automate requirements elicitation within agile frameworks, where requirements are defined as user stories (US). We used 10 state-of-the-art LLMs to investigate their ability to generate US automatically by emulating customer interviews. We evaluated the quality of US generated by LLMs, comparing it with the quality of US generated by humans (domain experts and students). We also explored whether and how LLMs can be used to automatically evaluate the semantic quality of US. Our results indicate that LLMs can generate US similar to humans in terms of coverage and stylistic quality, but exhibit lower diversity and creativity. Although LLM-generated US are generally comparable in quality to those created by humans, they tend to meet the acceptance quality criteria less frequently, regardless of the scale of the LLM model. Finally, LLMs can reliably assess the semantic quality of US when provided with clear evaluation criteria and have the potential to reduce human effort in large-scale assessments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•æ·æ¡†æ¶ä¸‹è‡ªåŠ¨åŒ–éœ€æ±‚è·å–é˜¶æ®µç”Ÿæˆå’Œè¯„ä¼°ç”¨æˆ·æ•…äº‹ï¼ˆUser Stories, USï¼‰çš„èƒ½åŠ›ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨10ç§å…ˆè¿›çš„LLMsæ¨¡æ‹Ÿå®¢æˆ·è®¿è°ˆä»¥è‡ªåŠ¨ç”ŸæˆUSï¼Œå¹¶å°†å…¶è´¨é‡ä¸é¢†åŸŸä¸“å®¶å’Œå­¦ç”Ÿç”Ÿæˆçš„ç»“æœè¿›è¡Œäº†å¤šç»´åº¦å¯¹æ¯”ã€‚å®éªŒå‘ç°ï¼ŒLLMsç”Ÿæˆçš„USåœ¨è¦†ç›–èŒƒå›´å’Œé£æ ¼è´¨é‡ä¸Šä¸äººç±»è¡¨ç°ç›¸ä¼¼ï¼Œä½†åœ¨å¤šæ ·æ€§å’Œåˆ›é€ åŠ›æ–¹é¢è¡¨ç°ç¨é€Šï¼Œä¸”åœ¨æ»¡è¶³éªŒæ”¶è´¨é‡æ ‡å‡†ï¼ˆacceptance quality criteriaï¼‰æ–¹é¢çš„é¢‘ç‡è¾ƒä½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è¯å®äº†LLMsåœ¨æä¾›æ˜ç¡®æ ‡å‡†æ—¶èƒ½å¤Ÿå¯é åœ°è¯„ä¼°USçš„è¯­ä¹‰è´¨é‡ï¼Œå…·æœ‰é™ä½å¤§è§„æ¨¡è¯„ä¼°ä¸­äººåŠ›æŠ•å…¥çš„æ˜¾è‘—æ½œåŠ›ã€‚è¯¥å·¥ä½œä¸ºè‡ªåŠ¨åŒ–éœ€æ±‚å·¥ç¨‹æä¾›äº†é‡è¦çš„å®è¯å‚è€ƒï¼Œæ­ç¤ºäº†LLMsåœ¨æ•æ·å¼€å‘æµç¨‹ä¸­çš„ä¼˜åŠ¿ä¸å±€é™ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15157v1",
      "published_date": "2025-07-20 23:37:43 UTC",
      "updated_date": "2025-07-20 23:37:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:24.085691+00:00"
    },
    {
      "arxiv_id": "2507.15156v1",
      "title": "Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification",
      "title_zh": "é¢å‘å¤šæ ‡ç­¾åˆ†ç±»çš„çº¦æŸæ„ŸçŸ¥æ¦‚ç‡åºåˆ—æ¨¡å‹å­¦ä¹ ",
      "authors": [
        "Mykhailo Buleshnyi",
        "Anna Polova",
        "Zsolt Zombori",
        "Michael Benedikt"
      ],
      "abstract": "We investigate multi-label classification involving large sets of labels, where the output labels may be known to satisfy some logical constraints. We look at an architecture in which classifiers for individual labels are fed into an expressive sequential model, which produces a joint distribution. One of the potential advantages for such an expressive model is its ability to modelling correlations, as can arise from constraints. We empirically demonstrate the ability of the architecture both to exploit constraints in training and to enforce constraints at inference time.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¶‰åŠå¤§è§„æ¨¡æ ‡ç­¾é›†ä¸”éœ€æ»¡è¶³é€»è¾‘çº¦æŸçš„ Multi-Label Classification é—®é¢˜è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚ä½œè€…æå‡ºäº†ä¸€ç§å°†å•æ ‡ç­¾åˆ†ç±»å™¨ä¸è¡¨è¾¾èƒ½åŠ›å¼ºçš„ Probabilistic Sequential Model ç›¸ç»“åˆçš„æ¶æ„ï¼Œæ—¨åœ¨ç”Ÿæˆæ ‡ç­¾çš„è”åˆåˆ†å¸ƒã€‚è¯¥æ¨¡å‹åˆ©ç”¨å…¶å¼ºå¤§çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›ï¼Œæ•æ‰ç”±é€»è¾‘çº¦æŸäº§ç”Ÿçš„æ ‡ç­¾é—´å¤æ‚ç›¸å…³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¶æ„åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½æœ‰æ•ˆåˆ©ç”¨çº¦æŸä¿¡æ¯ï¼Œå¹¶èƒ½åœ¨æ¨ç†é˜¶æ®µå¼ºåˆ¶æ‰§è¡Œè¿™äº›é€»è¾‘çº¦æŸã€‚è¿™ä¸€æ–¹æ³•ä¸ºå¤„ç†å—é™å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡æä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„æ¦‚ç‡å»ºæ¨¡æ¡†æ¶ï¼Œè¯æ˜äº†åºåˆ—æ¨¡å‹åœ¨æ•æ‰æ ‡ç­¾å…³è”ä¸çº¦æŸæ‰§è¡Œæ–¹é¢çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15156v1",
      "published_date": "2025-07-20 23:31:36 UTC",
      "updated_date": "2025-07-20 23:31:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:29.494913+00:00"
    },
    {
      "arxiv_id": "2507.15152v1",
      "title": "What Level of Automation is \"Good Enough\"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction",
      "title_zh": "ä»€ä¹ˆæ ·çš„è‡ªåŠ¨åŒ–æ°´å¹³æ‰ç®—â€œè¶³å¤Ÿå¥½â€ï¼Ÿå¤§è¯­è¨€æ¨¡å‹ç”¨äºèŸèƒåˆ†ææ•°æ®æå–çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Lingbo Li",
        "Anuradha Mathrani",
        "Teo Susnjak"
      ],
      "abstract": "Automating data extraction from full-text randomised controlled trials (RCTs) for meta-analysis remains a significant challenge. This study evaluates the practical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini) across tasks involving statistical results, risk-of-bias assessments, and study-level characteristics in three medical domains: hypertension, diabetes, and orthopaedics. We tested four distinct prompting strategies (basic prompting, self-reflective prompting, model ensemble, and customised prompts) to determine how to improve extraction quality. All models demonstrate high precision but consistently suffer from poor recall by omitting key information. We found that customised prompts were the most effective, boosting recall by up to 15\\%. Based on this analysis, we propose a three-tiered set of guidelines for using LLMs in data extraction, matching data types to appropriate levels of automation based on task complexity and risk. Our study offers practical advice for automating data extraction in real-world meta-analyses, balancing LLM efficiency with expert oversight through targeted, task-specific automation.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨èŸèƒåˆ†æ (Meta-Analysis) æ•°æ®æå–ä¸­çš„å®é™…è¡¨ç°ï¼Œæ—¨åœ¨æ¢è®¨è‡ªåŠ¨åŒ–ç¨‹åº¦åœ¨ä½•ç§æ°´å¹³ä¸‹èƒ½æ»¡è¶³å®é™…ç§‘ç ”éœ€æ±‚ã€‚ç ”ç©¶äººå‘˜é€‰å–äº† Gemini-2.0-flashã€Grok-3 å’Œ GPT-4o-mini ä¸‰ç§æ¨¡å‹ï¼Œé’ˆå¯¹é«˜è¡€å‹ã€ç³–å°¿ç—…å’Œéª¨ç§‘é¢†åŸŸçš„éšæœºå¯¹ç…§è¯•éªŒ (RCTs) å¼€å±•äº†å¤šç»´åº¦æµ‹è¯•ã€‚å®éªŒæ¶µç›–äº†ç»Ÿè®¡ç»“æœã€åå€šé£é™©è¯„ä¼° (risk-of-bias assessments) å’Œç ”ç©¶å±‚é¢ç‰¹å¾ç­‰ä»»åŠ¡ï¼Œå¹¶å¯¹æ¯”äº†åŸºç¡€æç¤º (basic prompting)ã€è‡ªæˆ‘åæ€ (self-reflective)ã€æ¨¡å‹é›†æˆ (model ensemble) å’Œå®šåˆ¶åŒ–æç¤º (customised prompts) å››ç§ç­–ç•¥çš„æ•ˆæœã€‚ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶æ¨¡å‹æ™®éå…·æœ‰è¾ƒé«˜çš„ç²¾ç¡®ç‡ (precision)ï¼Œä½†ç”±äºé¢‘ç¹é—æ¼å…³é”®ä¿¡æ¯ï¼Œå¬å›ç‡ (recall) è¡¨ç°è¾ƒå·®ï¼Œè€Œå®šåˆ¶åŒ–æç¤ºå¯å°†å¬å›ç‡æœ€é«˜æå‡ 15%ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶æå‡ºäº†ä¸€å¥—ä¸‰å±‚çº§å‡†åˆ™ï¼Œæ—¨åœ¨æ ¹æ®ä»»åŠ¡å¤æ‚æ€§å’Œé£é™©ä¸ºä¸åŒæ•°æ®ç±»å‹åŒ¹é…æœ€åˆé€‚çš„è‡ªåŠ¨åŒ–æ°´å¹³ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨ç°å®ä¸–ç•ŒèŸèƒåˆ†æä¸­å¹³è¡¡ LLM æ•ˆç‡ä¸ä¸“å®¶ç›‘ç£æä¾›äº†å®ç”¨çš„é’ˆå¯¹æ€§è‡ªåŠ¨åŒ–å»ºè®®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15152v1",
      "published_date": "2025-07-20 23:09:04 UTC",
      "updated_date": "2025-07-20 23:09:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:33.593773+00:00"
    },
    {
      "arxiv_id": "2507.15151v1",
      "title": "Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection",
      "title_zh": "åŸºäº CNN çš„ç»“è†œè‹ç™½è´«è¡€æ£€æµ‹è®­ç»ƒåé‡åŒ–æ€§èƒ½åˆ†æ",
      "authors": [
        "Sebastian A. Cruz Romero",
        "Wilfredo E. Lugo Beauchamp"
      ],
      "abstract": "Anemia is a widespread global health issue, particularly among young children in low-resource settings. Traditional methods for anemia detection often require expensive equipment and expert knowledge, creating barriers to early and accurate diagnosis. To address these challenges, we explore the use of deep learning models for detecting anemia through conjunctival pallor, focusing on the CP-AnemiC dataset, which includes 710 images from children aged 6-59 months. The dataset is annotated with hemoglobin levels, gender, age and other demographic data, enabling the development of machine learning models for accurate anemia detection. We use the MobileNet architecture as a backbone, known for its efficiency in mobile and embedded vision applications, and fine-tune our model end-to-end using data augmentation techniques and a cross-validation strategy. Our model implementation achieved an accuracy of 0.9313, a precision of 0.9374, and an F1 score of 0.9773 demonstrating strong performance on the dataset. To optimize the model for deployment on edge devices, we performed post-training quantization, evaluating the impact of different bit-widths (FP32, FP16, INT8, and INT4) on model performance. Preliminary results suggest that while FP16 quantization maintains high accuracy (0.9250), precision (0.9370), and F1 Score (0.9377), more aggressive quantization (INT8 and INT4) leads to significant performance degradation. Overall, our study supports further exploration of quantization schemes and hardware optimizations to assess trade-offs between model size, inference time, and diagnostic accuracy in mobile healthcare applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä½èµ„æºç¯å¢ƒä¸‹å„¿ç«¥è´«è¡€æ£€æµ‹çš„éš¾é¢˜ï¼Œæ¢è®¨äº†åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹é€šè¿‡ç»“è†œè‹ç™½(conjunctival pallor)è¿›è¡Œè´«è¡€æ£€æµ‹çš„æ–¹æ³•ã€‚ç ”ç©¶é‡‡ç”¨ MobileNet æ¶æ„ä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œåœ¨ CP-AnemiC æ•°æ®é›†ä¸Šè¿›è¡Œç«¯åˆ°ç«¯å¾®è°ƒï¼Œå®ç°äº†0.9313çš„å‡†ç¡®ç‡å’Œ0.9773çš„ F1 scoreã€‚ä¸ºäº†å°†æ¨¡å‹éƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡ï¼Œç ”ç©¶äººå‘˜é‡ç‚¹è¯„ä¼°äº†è®­ç»ƒåé‡åŒ–(Post-Training Quantization)åœ¨ä¸åŒä½å®½ï¼ˆFP32ã€FP16ã€INT8 å’Œ INT4ï¼‰ä¸‹å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFP16 é‡åŒ–èƒ½å¤Ÿç»´æŒè¾ƒé«˜çš„è¯Šæ–­å‡†ç¡®ç‡ï¼ˆ0.9250ï¼‰ï¼Œè€Œ INT8 å’Œ INT4 ç­‰æ›´æ¿€è¿›çš„é‡åŒ–æ–¹æ¡ˆåˆ™ä¼šå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†æ¨¡å‹é‡åŒ–åœ¨ç§»åŠ¨åŒ»ç–—åº”ç”¨ä¸­çš„è¡¨ç°å·®å¼‚ï¼Œä¸ºåœ¨æœ‰é™ç¡¬ä»¶èµ„æºä¸‹æƒè¡¡æ¨¡å‹å¤§å°ã€æ¨ç†æ—¶é—´ä¸è¯Šæ–­ç²¾åº¦æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at International Symposium on Intelligent Computing & Networks 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15151v1",
      "published_date": "2025-07-20 23:02:58 UTC",
      "updated_date": "2025-07-20 23:02:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:35.789690+00:00"
    },
    {
      "arxiv_id": "2507.15146v1",
      "title": "Design of an Edge-based Portable EHR System for Anemia Screening in Remote Health Applications",
      "title_zh": "é¢å‘è¿œç¨‹åŒ»ç–—è´«è¡€ç­›æŸ¥çš„ä¾¿æºå¼è¾¹ç¼˜ç”µå­å¥åº·æ¡£æ¡ˆï¼ˆEHRï¼‰ç³»ç»Ÿè®¾è®¡",
      "authors": [
        "Sebastian A. Cruz Romero",
        "Misael J. Mercado Hernandez",
        "Samir Y. Ali Rivera",
        "Jorge A. Santiago Fernandez",
        "Wilfredo E. Lugo Beauchamp"
      ],
      "abstract": "The design of medical systems for remote, resource-limited environments faces persistent challenges due to poor interoperability, lack of offline support, and dependency on costly infrastructure. Many existing digital health solutions neglect these constraints, limiting their effectiveness for frontline health workers in underserved regions. This paper presents a portable, edge-enabled Electronic Health Record platform optimized for offline-first operation, secure patient data management, and modular diagnostic integration. Running on small-form factor embedded devices, it provides AES-256 encrypted local storage with optional cloud synchronization for interoperability. As a use case, we integrated a non-invasive anemia screening module leveraging fingernail pallor analysis. Trained on 250 patient cases (27\\% anemia prevalence) with KDE-balanced data, the Random Forest model achieved a test RMSE of 1.969 g/dL and MAE of 1.490 g/dL. A severity-based model reached 79.2\\% sensitivity. To optimize performance, a YOLOv8n-based nail bed detector was quantized to INT8, reducing inference latency from 46.96 ms to 21.50 ms while maintaining mAP@0.5 at 0.995. The system emphasizes low-cost deployment, modularity, and data privacy compliance (HIPAA/GDPR), addressing critical barriers to digital health adoption in disconnected settings. Our work demonstrates a scalable approach to enhance portable health information systems and support frontline healthcare in underserved regions.",
      "tldr_zh": "è¯¥ç ”ç©¶è®¾è®¡äº†ä¸€ç§é¢å‘è¿œç¨‹åŒ»ç–—åœºæ™¯çš„è¾¹ç¼˜ä¾§ä¾¿æºå¼ç”µå­å¥åº·æ¡£æ¡ˆ (Electronic Health Record, EHR) ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³èµ„æºåŒ®ä¹åœ°åŒºäº’æ“ä½œæ€§å·®ã€ç¼ºä¹ç¦»çº¿æ”¯æŒä»¥åŠè¿‡åº¦ä¾èµ–æ˜‚è´µåŸºç¡€è®¾æ–½çš„é—®é¢˜ã€‚è¯¥å¹³å°é‡‡ç”¨ç¦»çº¿ä¼˜å…ˆçš„è®¾è®¡ç†å¿µï¼Œåœ¨å°å‹åµŒå…¥å¼è®¾å¤‡ä¸Šè¿è¡Œï¼Œå¹¶é€šè¿‡ AES-256 åŠ å¯†å­˜å‚¨ä¸å¯é€‰çš„äº‘ç«¯åŒæ­¥ç¡®ä¿æ•°æ®çš„å®‰å…¨æ€§ä¸äº’æ“ä½œæ€§ã€‚ç³»ç»Ÿé›†æˆäº†ä¸€ä¸ªåŸºäºæŒ‡ç”²è‹ç™½åˆ†æçš„éä¾µå…¥æ€§è´«è¡€ç­›æŸ¥æ¨¡å—ï¼Œå¹¶ä¸¥æ ¼éµå¾ª HIPAA å’Œ GDPR æ•°æ®éšç§æ ‡å‡†ã€‚ç ”ç©¶é‡‡ç”¨äº†åŸºäºæ ¸å¯†åº¦ä¼°è®¡ (KDE) å¹³è¡¡æ•°æ®çš„ Random Forest æ¨¡å‹è¿›è¡Œè´«è¡€ä¸¥é‡ç¨‹åº¦è¯„ä¼°ï¼Œå¹¶åº”ç”¨é‡åŒ–ä¸º INT8 æ ¼å¼çš„ YOLOv8n æ¨¡å‹ä¼˜åŒ–æŒ‡ç”²åºŠæ£€æµ‹æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨ç»´æŒ 0.995 é«˜ç²¾åº¦ (mAP@0.5) çš„åŒæ—¶ï¼Œå°†æ¨ç†å»¶è¿Ÿä» 46.96 ms æ˜¾è‘—é™ä½è‡³ 21.50 msï¼Œå…¶è´«è¡€ç­›æŸ¥æ¨¡å‹è¾¾åˆ°äº† 1.969 g/dL çš„å‡æ–¹æ ¹è¯¯å·® (RMSE)ã€‚è¯¥å·¥ä½œå±•ç¤ºäº†ä¸€ç§ä½æˆæœ¬ã€æ¨¡å—åŒ–ä¸”å¯æ‰©å±•çš„ç§»åŠ¨åŒ»ç–—æ–¹æ¡ˆï¼Œä¸ºæå‡æ¬ å‘è¾¾åœ°åŒºçš„åŸºå±‚åŒ»ç–—æœåŠ¡æ°´å¹³æä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.ET",
      "comment": "Accepted at IEEE Global Humanitarian Technology Conference 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15146v1",
      "published_date": "2025-07-20 22:46:42 UTC",
      "updated_date": "2025-07-20 22:46:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:43.000695+00:00"
    },
    {
      "arxiv_id": "2507.15143v2",
      "title": "An intelligent agent-based simulation of human mobility in extreme urban morphologies",
      "title_zh": "æç«¯åŸå¸‚å½¢æ€ä¸‹äººç¾¤æµåŠ¨çš„æ™ºèƒ½ä½“ä»¿çœŸ",
      "authors": [
        "Abderaouf Bahi",
        "Amel Ourici"
      ],
      "abstract": "This paper investigates the feasibility of human mobility in extreme urban morphologies, characterized by high-density vertical structures and linear city layouts. To assess whether agents can navigate efficiently within such unprecedented topologies, we develop a hybrid simulation framework that integrates agent-based modeling, reinforcement learning (RL), supervised learning, and graph neural networks (GNNs). The simulation captures multi-modal transportation behaviors across multiple vertical levels and varying density scenarios, using both synthetic data and real-world traces from high-density cities. Experiments show that the full AI-integrated architecture enables agents to achieve an average commute time of 7.8--8.4 minutes, a satisfaction rate exceeding 89\\%, and a reachability index over 91\\%, even during peak congestion periods. Ablation studies indicate that removing intelligent modules such as RL or GNN significantly degrades performance, with commute times increasing by up to 85\\% and reachability falling below 70\\%. Environmental modeling demonstrates low energy consumption and minimal CO$_2$ emissions when electric modes are prioritized. These results suggest that efficient and sustainable mobility in extreme urban forms is achievable, provided adaptive AI systems, intelligent infrastructure, and real-time feedback mechanisms are implemented.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨é«˜å¯†åº¦å‚ç›´ç»“æ„å’Œçº¿æ€§åŸå¸‚å¸ƒå±€ç­‰æç«¯åŸå¸‚å½¢æ€(extreme urban morphologies)ä¸‹äººç±»ç§»åŠ¨çš„å¯è¡Œæ€§ã€‚ä½œè€…å¼€å‘äº†ä¸€ä¸ªé›†æˆåŸºäºæ™ºèƒ½ä½“å»ºæ¨¡(Agent-Based Modeling, ABM)ã€å¼ºåŒ–å­¦ä¹ (RL)ã€ç›‘ç£å­¦ä¹ å’Œå›¾ç¥ç»ç½‘ç»œ(GNN)çš„æ··åˆæ¨¡æ‹Ÿæ¡†æ¶ï¼Œç”¨äºè¯„ä¼°æ™ºèƒ½ä½“åœ¨å¤æ‚æ‹“æ‰‘ç»“æ„ä¸­çš„å¯¼èˆªæ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å…¨AIé›†æˆæ¶æ„ä¸‹ï¼Œæ™ºèƒ½ä½“çš„å¹³å‡é€šå‹¤æ—¶é—´ç¼©çŸ­è‡³7.8è‡³8.4åˆ†é’Ÿï¼Œä¸”æ»¡æ„åº¦ä¸å¯è¾¾æ€§æŒ‡æ ‡å‡ä¿æŒåœ¨è¾ƒé«˜æ°´å¹³ã€‚æ¶ˆèå®éªŒæ˜¾ç¤ºï¼Œç§»é™¤RLæˆ–GNNç­‰å…³é”®æ™ºèƒ½æ¨¡å—ä¼šå¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œé€šå‹¤æ—¶é—´æœ€é«˜å¢åŠ 85%ã€‚ç¯å¢ƒå»ºæ¨¡è¿›ä¸€æ­¥è¯æ˜ï¼Œåœ¨ä¼˜å…ˆä½¿ç”¨ç”µåŠ¨äº¤é€šæ¨¡å¼æ—¶ï¼Œè¯¥ç³»ç»Ÿèƒ½å®ç°ä½èƒ½è€—å’Œä½äºŒæ°§åŒ–ç¢³æ’æ”¾ã€‚ç ”ç©¶ç»“è®ºæŒ‡å‡ºï¼Œé€šè¿‡è‡ªé€‚åº”AIç³»ç»Ÿã€æ™ºèƒ½åŸºç¡€è®¾æ–½å’Œå®æ—¶åé¦ˆæœºåˆ¶ï¼Œæç«¯åŸå¸‚å½¢æ€ä¸­çš„é«˜æ•ˆä¸”å¯æŒç»­ç§»åŠ¨æ˜¯å®Œå…¨å¯ä»¥å®ç°çš„ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15143v2",
      "published_date": "2025-07-20 22:35:16 UTC",
      "updated_date": "2026-01-14 21:38:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:51.995627+00:00"
    },
    {
      "arxiv_id": "2507.15142v1",
      "title": "A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script",
      "title_zh": "åå¯¹éšå¼æ ‡å‡†ï¼šä½¿ç”¨ Ge'ez å­—æ¯è¯­è¨€æœºå™¨ç¿»è¯‘ä¸­çš„åŒéŸ³å­—å½’ä¸€åŒ–",
      "authors": [
        "Hellina Hailu Nigatu",
        "Atnafu Lambebo Tonja",
        "Henok Biadglign Ademtew",
        "Hizkel Mitiku Alemayehu",
        "Negasi Haile Abadi",
        "Tadesse Destaw Belay",
        "Seid Muhie Yimam"
      ],
      "abstract": "Homophone normalization, where characters that have the same sound in a writing script are mapped to one character, is a pre-processing step applied in Amharic Natural Language Processing (NLP) literature. While this may improve performance reported by automatic metrics, it also results in models that are not able to understand different forms of writing in a single language. Further, there might be impacts in transfer learning, where models trained on normalized data do not generalize well to other languages. In this paper, we experiment with monolingual training and cross-lingual transfer to understand the impacts of normalization on languages that use the Ge'ez script. We then propose a post-inference intervention in which normalization is applied to model predictions instead of training data. With our simple scheme of post-inference normalization, we show that we can achieve an increase in BLEU score of up to 1.03 while preserving language features in training. Our work contributes to the broader discussion on technology-facilitated language change and calls for more language-aware interventions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä½¿ç”¨ Ge'ez script çš„è¯­è¨€ï¼ˆå¦‚ Amharicï¼‰çš„æœºå™¨ç¿»è¯‘ä¸­ï¼ŒåŒéŸ³è¯è§„èŒƒåŒ–ï¼ˆHomophone normalizationï¼‰è¿™ä¸€é¢„å¤„ç†æ­¥éª¤å¸¦æ¥çš„è´Ÿé¢å½±å“ã€‚å°½ç®¡è¿™ç§è§„èŒƒåŒ–èƒ½æå‡è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ï¼Œä½†ä¼šå¯¼è‡´æ¨¡å‹æ— æ³•ç†è§£å¤šæ ·åŒ–çš„ä¹¦å†™å½¢å¼ï¼Œå¹¶å‰Šå¼±å…¶åœ¨è·¨è¯­è¨€è¿ç§»ï¼ˆcross-lingual transferï¼‰ä¸­çš„æ³›åŒ–è¡¨ç°ã€‚ä¸ºæ­¤ï¼Œä½œè€…åœ¨åˆ†æå•è¯­è®­ç»ƒä¸è·¨è¯­è¨€è¿ç§»å®éªŒçš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§åæ¨ç†å¹²é¢„ï¼ˆpost-inference interventionï¼‰æ–¹æ¡ˆï¼Œå³å°†è§„èŒƒåŒ–åº”ç”¨äºæ¨¡å‹é¢„æµ‹é˜¶æ®µè€Œéè®­ç»ƒæ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨ä¿ç•™åŸå§‹è¯­è¨€ç‰¹å¾çš„åŸºç¡€ä¸Šï¼ŒæˆåŠŸå°† BLEU score æå‡äº†å¤šè¾¾ 1.03ã€‚è¿™é¡¹å·¥ä½œä¸ºæŠ€æœ¯é©±åŠ¨çš„è¯­è¨€æ¼”å˜è®¨è®ºè´¡çŒ®äº†é‡è¦è§è§£ï¼Œå¹¶å‘¼ååœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­é‡‡ç”¨æ›´å¤šå…·æœ‰è¯­è¨€æ„ŸçŸ¥èƒ½åŠ›ï¼ˆlanguage-awareï¼‰çš„å¹²é¢„æªæ–½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper under review",
      "pdf_url": "https://arxiv.org/pdf/2507.15142v1",
      "published_date": "2025-07-20 22:35:08 UTC",
      "updated_date": "2025-07-20 22:35:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:50.595151+00:00"
    },
    {
      "arxiv_id": "2507.15140v1",
      "title": "Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis",
      "title_zh": "ä¸´åºŠè¯­ä¹‰æ™ºèƒ½ (CSI)ï¼šæ¨¡æ‹Ÿä¸´åºŠä¸“å®¶è®¤çŸ¥æ¡†æ¶ï¼Œå®ç°å…¨é¢çš„å£è…”ç–¾ç—…è¯Šæ–­",
      "authors": [
        "Mohammad Mashayekhi",
        "Sara Ahmadi Majd",
        "Arian AmirAmjadi",
        "Parsa Hosseini"
      ],
      "abstract": "The diagnosis of oral diseases presents a problematic clinical challenge, characterized by a wide spectrum of pathologies with overlapping symptomatology. To address this, we developed Clinical Semantic Intelligence (CSI), a novel artificial intelligence framework that diagnoses 118 different oral diseases by computationally modeling the cognitive processes of an expert clinician. Our core hypothesis is that moving beyond simple pattern matching to emulate expert reasoning is critical to building clinically useful diagnostic aids.\n  CSI's architecture integrates a fine-tuned multimodal CLIP model with a specialized ChatGLM-6B language model. This system executes a Hierarchical Diagnostic Reasoning Tree (HDRT), a structured framework that distills the systematic, multi-step logic of differential diagnosis. The framework operates in two modes: a Fast Mode for rapid screening and a Standard Mode that leverages the full HDRT for an interactive and in-depth diagnostic workup.\n  To train and validate our system, we curated a primary dataset of 4,310 images, supplemented by an external hold-out set of 176 images for final validation. A clinically-informed augmentation strategy expanded our training data to over 30,000 image-text pairs. On a 431-image internal test set, CSI's Fast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the HDRT-driven Standard Mode. The performance gain is directly attributable to the hierarchical reasoning process. Herein, we detail the architectural philosophy, development, and rigorous evaluation of the CSI framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸´åºŠè¯­ä¹‰æ™ºèƒ½(Clinical Semantic Intelligence, CSI)æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡æ‹Ÿä¸´åºŠä¸“å®¶çš„è®¤çŸ¥é€»è¾‘æ¥è§£å†³118ç§å£è…”ç–¾ç—…çš„è¯Šæ–­éš¾é¢˜ã€‚CSIçš„æ¶æ„é›†æˆäº†å¾®è°ƒçš„å¤šæ¨¡æ€CLIPæ¨¡å‹ä¸ä¸“é—¨çš„ChatGLM-6Bè¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡æ‰§è¡Œå±‚æ¬¡åŒ–è¯Šæ–­æ¨ç†æ ‘(Hierarchical Diagnostic Reasoning Tree, HDRT)æ¥è¿˜åŸç³»ç»ŸåŒ–çš„é‰´åˆ«è¯Šæ–­è¿‡ç¨‹ã€‚è¯¥ç³»ç»ŸåŒ…å«ç”¨äºå¿«é€Ÿç­›æŸ¥çš„Fast Modeä»¥åŠåˆ©ç”¨å®Œæ•´HDRTè¿›è¡Œæ·±åº¦è¯Šæ–­çš„Standard Modeï¼Œä»¥é€‚åº”ä¸åŒçš„ä¸´åºŠéœ€æ±‚ã€‚ç ”ç©¶äººå‘˜æ„å»ºäº†åŒ…å«4,310å¼ åŸå§‹å›¾åƒçš„æ•°æ®é›†ï¼Œå¹¶é€šè¿‡ä¸´åºŠå¢å¼ºç­–ç•¥å°†å…¶æ‰©å±•è‡³è¶…è¿‡30,000ä¸ªå›¾åƒæ–‡æœ¬å¯¹è¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒStandard Modeåœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡è¾¾åˆ°89.5%ï¼Œæ˜¾è‘—ä¼˜äºFast Modeçš„73.4%ï¼Œå……åˆ†éªŒè¯äº†æ¨¡æ‹Ÿä¸“å®¶å±‚æ¬¡åŒ–æ¨ç†è¿‡ç¨‹åœ¨æå‡è¾…åŠ©è¯Šæ–­æ•ˆèƒ½æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15140v1",
      "published_date": "2025-07-20 22:30:01 UTC",
      "updated_date": "2025-07-20 22:30:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:57.702616+00:00"
    },
    {
      "arxiv_id": "2507.15120v2",
      "title": "Automated planning with ontologies under coherence update semantics (Extended Version)",
      "title_zh": "ä¸€è‡´æ€§æ›´æ–°è¯­ä¹‰ä¸‹ç»“åˆæœ¬ä½“çš„è‡ªåŠ¨è§„åˆ’ï¼ˆæ‰©å±•ç‰ˆï¼‰",
      "authors": [
        "Stefan Borgwardt",
        "Duy Nhu",
        "Gabriele RÃ¶ger"
      ],
      "abstract": "Standard automated planning employs first-order formulas under closed-world semantics to achieve a goal with a given set of actions from an initial state. We follow a line of research that aims to incorporate background knowledge into automated planning problems, for example, by means of ontologies, which are usually interpreted under open-world semantics. We present a new approach for planning with DL-Lite ontologies that combines the advantages of ontology-based action conditions provided by explicit-input knowledge and action bases (eKABs) and ontology-aware action effects under the coherence update semantics. We show that the complexity of the resulting formalism is not higher than that of previous approaches and provide an implementation via a polynomial compilation into classical planning. An evaluation of existing and new benchmarks examines the performance of a planning system on different variants of our compilation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°†æœ¬ä½“ï¼ˆontologiesï¼‰å½¢å¼çš„èƒŒæ™¯çŸ¥è¯†æ•´åˆåˆ°è‡ªåŠ¨è§„åˆ’ï¼ˆautomated planningï¼‰é—®é¢˜ä¸­ï¼Œå¹¶é’ˆå¯¹ DL-Lite ontologies æå‡ºäº†ä¸€ç§æ–°çš„è§„åˆ’æ–¹æ³•ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆç»“åˆäº†æ˜¾å¼è¾“å…¥çŸ¥è¯†ä¸åŠ¨ä½œåº“ï¼ˆeKABsï¼‰ä¸­åŸºäºæœ¬ä½“çš„åŠ¨ä½œæ¡ä»¶ï¼Œä»¥åŠåœ¨ä¸€è‡´æ€§æ›´æ–°è¯­ä¹‰ï¼ˆcoherence update semanticsï¼‰ä¸‹çš„æœ¬ä½“æ„ŸçŸ¥åŠ¨ä½œæ•ˆæœã€‚ä½œè€…è¯æ˜äº†è¯¥å½¢å¼åŒ–æ–¹æ³•çš„å¤æ‚åº¦å¹¶ä¸é«˜äºä»¥å¾€çš„ç ”ç©¶æ–¹æ³•ï¼Œå¹¶æä¾›äº†ä¸€ç§é€šè¿‡å¤šé¡¹å¼ç¼–è¯‘ï¼ˆpolynomial compilationï¼‰å°†å…¶è½¬åŒ–ä¸ºç»å…¸è§„åˆ’ï¼ˆclassical planningï¼‰çš„å…·ä½“å®ç°æ–¹æ¡ˆã€‚é€šè¿‡å¯¹ç°æœ‰åŠæ–°åŸºå‡†æµ‹è¯•çš„è¯„ä¼°ï¼Œç ”ç©¶åˆ†æäº†è§„åˆ’ç³»ç»Ÿåœ¨ä¸åŒç¼–è¯‘å˜ä½“ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚èƒŒæ™¯çŸ¥è¯†è§„åˆ’ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of a paper accepted at 22nd International Conference on Principles of Knowledge Representation and Reasoning (KR 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.15120v2",
      "published_date": "2025-07-20 20:49:21 UTC",
      "updated_date": "2025-07-23 09:09:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:45:53.995467+00:00"
    },
    {
      "arxiv_id": "2507.15118v1",
      "title": "Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings",
      "title_zh": "é¢å‘ä½èµ„æºç¯å¢ƒä¸‹åŸºäºæ˜“è·å–ç¡¬ä»¶è„‘ç”µä¿¡å·è¿›è¡Œç™«ç—«æ£€æµ‹çš„å›¾æ³¨æ„åŠ›ç½‘ç»œ",
      "authors": [
        "Szymon Mazurek",
        "Stephen Moore",
        "Alessandro Crimi"
      ],
      "abstract": "Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce neurologists and costly diagnostic tools. We propose a graph-based deep learning framework to detect epilepsy from low-cost Electroencephalography (EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus is on fair, accessible automatic assessment and explainability to shed light on epilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs, classify them, and identify interchannel relationships and temporal dynamics using graph attention networks (GAT). To emphasize connectivity biomarkers, we adapt the inherently node-focused GAT to analyze edges. We also designed signal preprocessing for low-fidelity recordings and a lightweight GAT architecture trained on Google Colab and deployed on RaspberryPi devices. Results: The approach achieves promising classification performance, outperforming a standard classifier based on random forest and graph convolutional networks in terms of accuracy and robustness over multiple sessions, but also highlighting specific connections in the fronto-temporal region. Conclusions: The results highlight the potential of GATs to provide insightful and scalable diagnostic support for epilepsy in underserved regions, paving the way for affordable and accessible neurodiagnostic tools.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ä½æ”¶å…¥å›½å®¶å› ç¼ºä¹ç¥ç»ç§‘åŒ»ç”Ÿå’Œæ˜‚è´µè¯Šæ–­è®¾å¤‡å¯¼è‡´çš„ç™«ç—«è¯Šæ–­ä¸è¶³é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå›¾æ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨æ£€æµ‹æ¡†æ¶ã€‚è¯¥ç ”ç©¶åˆ©ç”¨ä½æˆæœ¬çš„ Electroencephalography (EEG) ç¡¬ä»¶è·å–ä¿¡å·ï¼Œå°†å…¶å»ºæ¨¡ä¸ºæ—¶ç©ºå›¾ï¼Œå¹¶é‡‡ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œ (Graph Attention Networks, GAT) è¯†åˆ«é€šé“é—´å…³ç³»ä¸æ—¶é—´åŠ¨æ€ã€‚ä¸ºäº†æ·±å…¥åˆ†æç™«ç—«çš„ç”Ÿç‰©æ ‡å¿—ç‰©ï¼Œç ”ç©¶äººå‘˜æ”¹è¿›äº†åŸæœ¬ä»¥èŠ‚ç‚¹ä¸ºä¸­å¿ƒçš„ GAT æ¶æ„ä»¥ä¾¿åˆ†æè¾¹ (edges) çš„è¿æ¥ç‰¹å¾ã€‚è¯¥æ–¹æ¡ˆé’ˆå¯¹ä½ä¿çœŸä¿¡å·è®¾è®¡äº†ä¸“é—¨çš„é¢„å¤„ç†æµç¨‹ï¼Œå¹¶æ„å»ºäº†å¯åœ¨ RaspberryPi è®¾å¤‡ä¸Šéƒ¨ç½²è¿è¡Œçš„è½»é‡çº§æ¶æ„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åˆ†ç±»å‡†ç¡®ç‡å’Œå¤šé˜¶æ®µé²æ£’æ€§æ–¹é¢å‡ä¼˜äº Random Forest å’Œ Graph Convolutional Networks (GCN)ã€‚æ­¤å¤–ï¼Œæ¨¡å‹æˆåŠŸè¯†åˆ«å‡ºé¢é¢å¶åŒºåŸŸ (fronto-temporal region) çš„ç‰¹å®šè¿æ¥ç‰¹å¾ï¼Œè¯æ˜äº†è¯¥æŠ€æœ¯åœ¨èµ„æºåŒ®ä¹åœ°åŒºæä¾›å¯æ‰©å±•ã€ä½æˆæœ¬ä¸”å…·å¯è§£é‡Šæ€§è¯Šæ–­æ”¯æŒçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15118v1",
      "published_date": "2025-07-20 20:44:39 UTC",
      "updated_date": "2025-07-20 20:44:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:07.285724+00:00"
    },
    {
      "arxiv_id": "2507.15106v1",
      "title": "From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward",
      "title_zh": "ä»è¹¬è…¿åˆ°å› æœï¼šåŸºäºé²æ£’å†…åœ¨å¥–åŠ±çš„å©´å„¿ä¸»ä½“æ€§æ£€æµ‹æ¨¡æ‹Ÿ",
      "authors": [
        "Xia Xu",
        "Jochen Triesch"
      ],
      "abstract": "While human infants robustly discover their own causal efficacy, standard reinforcement learning agents remain brittle, as their reliance on correlation-based rewards fails in noisy, ecologically valid scenarios. To address this, we introduce the Causal Action Influence Score (CAIS), a novel intrinsic reward rooted in causal inference. CAIS quantifies an action's influence by measuring the 1-Wasserstein distance between the learned distribution of sensory outcomes conditional on that action, $p(h|a)$, and the baseline outcome distribution, $p(h)$. This divergence provides a robust reward that isolates the agent's causal impact from confounding environmental noise. We test our approach in a simulated infant-mobile environment where correlation-based perceptual rewards fail completely when the mobile is subjected to external forces. In stark contrast, CAIS enables the agent to filter this noise, identify its influence, and learn the correct policy. Furthermore, the high-quality predictive model learned for CAIS allows our agent, when augmented with a surprise signal, to successfully reproduce the \"extinction burst\" phenomenon. We conclude that explicitly inferring causality is a crucial mechanism for developing a robust sense of agency, offering a psychologically plausible framework for more adaptive autonomous systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Causal Action Influence Score (CAIS)ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå› æœæ¨ç†(Causal Inference)çš„æ–°å‹å†…åœ¨å¥–åŠ±æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ™ºèƒ½ä½“åœ¨å˜ˆæ‚ç¯å¢ƒä¸­å› è¿‡åº¦ä¾èµ–ç›¸å…³æ€§å¥–åŠ±è€Œè¡¨ç°å‡ºçš„è„†å¼±æ€§ã€‚CAISé€šè¿‡è¡¡é‡ç‰¹å®šè¡ŒåŠ¨ä¸‹çš„æ„Ÿå®˜ç»“æœåˆ†å¸ƒä¸åŸºå‡†ç»“æœåˆ†å¸ƒä¹‹é—´çš„1-Wassersteinè·ç¦»æ¥é‡åŒ–è¡ŒåŠ¨çš„å½±å“åŠ›ï¼Œä»è€Œæœ‰æ•ˆåœ°åœ¨ç¯å¢ƒå™ªå£°ä¸­éš”ç¦»å‡ºæ™ºèƒ½ä½“çš„å› æœå½±å“ã€‚åœ¨æ¨¡æ‹Ÿå©´å„¿-æ‚¬æŒ‚ç©å…·(Infant-Mobile)ç¯å¢ƒçš„å®éªŒä¸­ï¼Œå½“æ‚¬æŒ‚ç©å…·å—åˆ°å¤–éƒ¨åŠ›é‡å¹²æ‰°æ—¶ï¼Œä¼ ç»Ÿçš„åŸºäºç›¸å…³æ€§çš„æ„ŸçŸ¥å¥–åŠ±å®Œå…¨å¤±æ•ˆï¼Œè€ŒCAISä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè¿‡æ»¤å™ªå£°å¹¶å­¦ä¹ åˆ°æ­£ç¡®çš„ç­–ç•¥ã€‚æ­¤å¤–ï¼Œç»“åˆæƒŠå–œä¿¡å·(Surprise Signal)åï¼Œè¯¥æ™ºèƒ½ä½“è¿˜æˆåŠŸå¤ç°äº†å¿ƒç†å­¦ä¸­çš„â€œæ¶ˆé€€çˆ†å‘â€(Extinction Burst)ç°è±¡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ˜¾å¼æ¨æ–­å› æœå…³ç³»æ˜¯å½¢æˆç¨³å¥ä¸»ä½“æ„Ÿ(Sense of Agency)çš„å…³é”®æœºåˆ¶ï¼Œä¸ºå¼€å‘æ›´å…·é€‚åº”æ€§çš„è‡ªä¸»ç³»ç»Ÿæä¾›äº†å¿ƒç†å­¦ä¸Šåˆç†çš„æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15106v1",
      "published_date": "2025-07-20 20:02:50 UTC",
      "updated_date": "2025-07-20 20:02:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:20.053594+00:00"
    },
    {
      "arxiv_id": "2507.15104v1",
      "title": "AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI",
      "title_zh": "AnalogFedï¼šåŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„æ¨¡æ‹Ÿç”µè·¯æ‹“æ‰‘è”é‚¦å‘ç°",
      "authors": [
        "Qiufeng Li",
        "Shu Hong",
        "Jian Gao",
        "Xuan Zhang",
        "Tian Lan",
        "Weidong Cao"
      ],
      "abstract": "Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize analog design automation through data-driven approaches. In particular, researchers are increasingly fascinated by harnessing the power of generative AI to automate the discovery of novel analog circuit topologies. Unlocking the full potential of generative AI in these data-driven discoveries requires access to large and diverse datasets.Yet, there is a significant barrier in the analog domain--Analog circuit design is inherently proprietary, involving not only confidential circuit structures but also the underlying commercial semiconductor processes. As a result, current generative AI research is largely confined to individual researchers who construct small, narrowly focused private datasets. This fragmentation severely limits collaborative innovation and impedes progress across the research community. To address these challenges, we propose AnalogFed. AnalogFed enables collaborative topology discovery across decentralized clients (e.g., individual researchers or institutions) without requiring the sharing of raw private data. To make this vision practical, we introduce a suite of techniques tailored to the unique challenges of applying FedL in analog design--from generative model development and data heterogeneity handling to privacy-preserving strategies that ensure both flexibility and security for circuit designers and semiconductor manufacturers. Extensive experiments across varying client counts and dataset sizes demonstrate that AnalogFed achieves performance comparable to centralized baselines--while maintaining strict data privacy. Specifically, the generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AnalogFedï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Generative AI)è¿›è¡Œæ¨¡æ‹Ÿç”µè·¯(Analog circuit)æ‹“æ‰‘åä½œå‘ç°çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”±äºç”µè·¯è®¾è®¡ä¸“æœ‰æ€§å’Œéšç§ä¿æŠ¤å¯¼è‡´çš„æ•°æ®ç¢ç‰‡åŒ–é—®é¢˜ã€‚AnalogFedé€šè¿‡è”é‚¦å­¦ä¹ (Federated Learning)æŠ€æœ¯ï¼Œå…è®¸å»ä¸­å¿ƒåŒ–çš„å®¢æˆ·ç«¯åœ¨ä¸å…±äº«åŸå§‹ç§æœ‰æ•°æ®çš„å‰æä¸‹ååŒè®­ç»ƒæ¨¡å‹ã€‚ä¸ºäº†ç¡®ä¿æ–¹æ¡ˆçš„å®ç”¨æ€§ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ç³»åˆ—é’ˆå¯¹æ¨¡æ‹Ÿè®¾è®¡æŒ‘æˆ˜çš„ä¸“é—¨æŠ€æœ¯ï¼ŒåŒ…æ‹¬å¤„ç†æ•°æ®å¼‚æ„æ€§ä»¥åŠç¡®ä¿åŠå¯¼ä½“å·¥è‰ºå®‰å…¨çš„éšç§ä¿æŠ¤ç­–ç•¥ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒAnalogFedåœ¨ä¿æŒä¸¥æ ¼æ•°æ®éšç§çš„åŒæ—¶ï¼Œèƒ½å¤Ÿè¾¾åˆ°ä¸ä¸­å¿ƒåŒ–åŸºå‡†ç›¸å½“çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶åœ¨æ¨¡æ‹Ÿç”µè·¯æ‹“æ‰‘è®¾è®¡ä¸­å±•ç°äº†é¢†å…ˆçš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§ï¼Œä¸ºæ¨¡æ‹Ÿè‡ªåŠ¨åŒ–è®¾è®¡é¢†åŸŸçš„åä½œåˆ›æ–°æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15104v1",
      "published_date": "2025-07-20 19:57:07 UTC",
      "updated_date": "2025-07-20 19:57:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:23.554182+00:00"
    },
    {
      "arxiv_id": "2507.15100v1",
      "title": "Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?",
      "title_zh": "å¡«è¡¥ç©ºç™½ï¼šå¸¸è¯†çŸ¥è¯†ç”Ÿæˆå¯¹è‡ªç„¶è¯­è¨€æ¨ç†æ˜¯å¦æœ‰æ•ˆï¼Ÿ",
      "authors": [
        "Chathuri Jayaweera",
        "Brianna Yanqui",
        "Bonnie Dorr"
      ],
      "abstract": "Natural Language Inference (NLI) is the task of determining the semantic entailment of a premise for a given hypothesis. The task aims to develop systems that emulate natural human inferential processes where commonsense knowledge plays a major role. However, existing commonsense resources lack sufficient coverage for a variety of premise-hypothesis pairs. This study explores the potential of Large Language Models as commonsense knowledge generators for NLI along two key dimensions: their reliability in generating such knowledge and the impact of that knowledge on prediction accuracy. We adapt and modify existing metrics to assess LLM factuality and consistency in generating in this context. While explicitly incorporating commonsense knowledge does not consistently improve overall results, it effectively helps distinguish entailing instances and moderately improves distinguishing contradictory and neutral inferences.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¸¸è¯†çŸ¥è¯†ç”Ÿæˆå¯¹è‡ªç„¶è¯­è¨€æ¨ç† (Natural Language Inference, NLI) çš„å®ç”¨æ€§ï¼Œæ—¨åœ¨å¼¥è¡¥ç°æœ‰å¸¸è¯†èµ„æºåœ¨è¦†ç›–èŒƒå›´ä¸Šçš„ä¸è¶³ã€‚ä½œè€…åˆ†æäº†å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) ä½œä¸ºå¸¸è¯†çŸ¥è¯†ç”Ÿæˆå™¨çš„æ½œåŠ›ï¼Œé‡ç‚¹è¯„ä¼°äº†ç”ŸæˆçŸ¥è¯†çš„å¯é æ€§åŠå…¶å¯¹é¢„æµ‹å‡†ç¡®æ€§çš„å½±å“ã€‚é€šè¿‡æ”¹è¿›ç°æœ‰æŒ‡æ ‡ï¼Œç ”ç©¶é‡åŒ–äº† LLMs åœ¨æ­¤èƒŒæ™¯ä¸‹ç”Ÿæˆå†…å®¹çš„çœŸå®æ€§ (Factuality) å’Œä¸€è‡´æ€§ (Consistency)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ˜¾å¼å¼•å…¥å¸¸è¯†çŸ¥è¯†è™½æœªæ˜¾è‘—æå‡æ•´ä½“æ€§èƒ½ï¼Œä½†èƒ½æœ‰æ•ˆå¸®åŠ©æ¨¡å‹åŒºåˆ†è•´å« (Entailment) å®ä¾‹ï¼Œå¹¶åœ¨è¾¨åˆ«çŸ›ç›¾ (Contradictory) å’Œä¸­ç«‹ (Neutral) æ¨ç†æ–¹é¢å–å¾—äº†ä¸­åº¦æ”¹å–„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 8 figures and 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.15100v1",
      "published_date": "2025-07-20 19:42:45 UTC",
      "updated_date": "2025-07-20 19:42:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:28.342113+00:00"
    },
    {
      "arxiv_id": "2507.15094v1",
      "title": "BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking",
      "title_zh": "BleedOriginï¼šåŸºäºåŒé˜¶æ®µæ£€æµ‹ä¸è¿½è¸ªçš„å†…é•œä¸‹é»è†œä¸‹å‰¥ç¦»æœ¯åŠ¨æ€å‡ºè¡€æºå®šä½",
      "authors": [
        "Mengya Xu",
        "Rulin Zhou",
        "An Wang",
        "Chaoyang Lyu",
        "Zhen Li",
        "Ning Zhong",
        "Hongliang Ren"
      ],
      "abstract": "Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses significant risks, demanding precise, real-time localization and continuous monitoring of the bleeding source for effective hemostatic intervention. In particular, endoscopists have to repeatedly flush to clear blood, allowing only milliseconds to identify bleeding sources, an inefficient process that prolongs operations and elevates patient risks. However, current Artificial Intelligence (AI) methods primarily focus on bleeding region segmentation, overlooking the critical need for accurate bleeding source detection and temporal tracking in the challenging ESD environment, which is marked by frequent visual obstructions and dynamic scene changes. This gap is widened by the lack of specialized datasets, hindering the development of robust AI-assisted guidance systems. To address these challenges, we introduce BleedOrigin-Bench, the first comprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated bleeding sources across 106,222 frames from 44 procedures, supplemented with 39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6 challenging clinical scenarios. We also present BleedOrigin-Net, a novel dual-stage detection-tracking framework for the bleeding source localization in ESD procedures, addressing the complete workflow from bleeding onset detection to continuous spatial tracking. We compare with widely-used object detection models (YOLOv11/v12), multimodal large language models, and point tracking methods. Extensive evaluation demonstrates state-of-the-art performance, achieving 96.85% frame-level accuracy ($\\pm\\leq8$ frames) for bleeding onset detection, 70.24% pixel-level accuracy ($\\leq100$ px) for initial source detection, and 96.11% pixel-level accuracy ($\\leq100$ px) for point tracking.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å†…é•œé»è†œä¸‹å‰¥ç¦»æœ¯(Endoscopic Submucosal Dissection, ESD)ä¸­æœ¯ä¸­å‡ºè¡€éš¾ä»¥å®æ—¶å®šä½å’ŒæŒç»­ç›‘æµ‹çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªä¸“é—¨é’ˆå¯¹å‡ºè¡€ç‚¹å®šä½çš„AIè¾…åŠ©ç³»ç»Ÿã€‚ä¸ºäº†è§£å†³ä¸“ä¸šæ•°æ®é›†åŒ®ä¹çš„æŒ‘æˆ˜ï¼Œç ”ç©¶è€…æ„å»ºäº†BleedOrigin-Benchï¼ŒåŒ…å«è¶…è¿‡10ä¸‡å¸§å›¾åƒå’Œ1,771ä¸ªä¸“å®¶æ ‡æ³¨çš„å‡ºè¡€æºï¼Œæ¶µç›–äº†8ä¸ªè§£å‰–éƒ¨ä½å’Œ6ç§ä¸´åºŠæŒ‘æˆ˜åœºæ™¯ã€‚æ ¸å¿ƒç®—æ³•BleedOrigin-Neté‡‡ç”¨åŒé˜¶æ®µæ£€æµ‹ä¸è·Ÿè¸ªæ¡†æ¶(Dual-Stage Detection and Tracking)ï¼Œå®ç°äº†ä»å‡ºè¡€èµ·å§‹æ£€æµ‹åˆ°æŒç»­ç©ºé—´è·Ÿè¸ªçš„å®Œæ•´å·¥ä½œæµï¼Œæœ‰æ•ˆåº”å¯¹äº†ESDç¯å¢ƒä¸‹çš„è§†è§‰é®æŒ¡å’ŒåŠ¨æ€åœºæ™¯å˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBleedOrigin-Netåœ¨å‡ºè¡€èµ·å§‹æ£€æµ‹å‡†ç¡®ç‡è¾¾åˆ°96.85%ï¼Œå¹¶åœ¨åˆå§‹æºå®šä½å’Œç‚¹è·Ÿè¸ªæ–¹é¢æ˜¾è‘—ä¼˜äºYOLOv11/v12åŠå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)ç­‰åŸºçº¿æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºæé«˜ESDæ‰‹æœ¯æ•ˆç‡ã€é™ä½æ‚£è€…æ‰‹æœ¯é£é™©æä¾›äº†å…³é”®çš„å¯æŒç»­ç©ºé—´å®šä½æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15094v1",
      "published_date": "2025-07-20 19:19:42 UTC",
      "updated_date": "2025-07-20 19:19:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:29.350891+00:00"
    },
    {
      "arxiv_id": "2507.15087v1",
      "title": "Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling",
      "title_zh": "åŸºäº Transformer çš„åŸºå› åºåˆ—å»ºæ¨¡ç¼–ç æ–¹æ¡ˆè¯„ä¼°",
      "authors": [
        "Chenlei Gong",
        "Yuanhe Tian",
        "Lei Mao",
        "Yan Song"
      ],
      "abstract": "Currently, many studies view DNA sequences as a special type of language and utilize Transformers to model them. These studies use fixed-length k-mer segmentation and BPE subword tokenization but lack a systematic evaluation to determine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a 4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal, AliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and 24-layer Transformer encoders and evaluated on GUE benchmark dataset. In general, BPE delivers higher and more stable performance across tasks by compressing frequent motifs into variable-length tokens, reducing sequence length, and improving model generalization. RoPE excels at capturing periodic motifs and extrapolating to long sequences, while AliBi also performs well on tasks driven by local dependencies. In terms of depth, we observe significant gains when increasing layers from 3 to 12, with only marginal improvements or slight overfitting at 24 layers. This study provides practical guidance for designing tokenization and positional encoding in DNA Transformer models.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹åŸºäº Transformer çš„åŸºå› åºåˆ—å»ºæ¨¡ä¸­çš„ç¼–ç æ–¹æ¡ˆè¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œé‡ç‚¹å¯¹æ¯”äº†å›ºå®šé•¿åº¦çš„ k-mer åˆ†å‰²ï¼ˆk=1,3,4,5,6ï¼‰ä¸ BPE å­è¯åˆ†è¯ï¼Œå¹¶è€ƒå¯Ÿäº† sinusoidalã€AliBi å’Œ RoPE ä¸‰ç§ä½ç½®ç¼–ç çš„å½±å“ã€‚ç ”ç©¶åœ¨ GUE åŸºå‡†æ•°æ®é›†ä¸Šæµ‹è¯•äº†ä¸åŒæ·±åº¦çš„ Transformer ç¼–ç å™¨ï¼Œç»“æœè¡¨æ˜ BPE ä¼˜äº k-mer æ–¹æ¡ˆï¼Œå› ä¸ºå®ƒèƒ½å°†é¢‘ç¹åŸºåºå‹ç¼©ä¸ºå˜é•¿ Tokenï¼Œæœ‰æ•ˆç¼©çŸ­åºåˆ—é•¿åº¦å¹¶æå‡äº†æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚åœ¨ä½ç½®ç¼–ç çš„é€‰æ‹©ä¸Šï¼ŒRoPE æ“…é•¿æ•æ‰å‘¨æœŸæ€§åŸºåºå’Œå¤„ç†é•¿åºåˆ—å¤–æ¨ï¼Œè€Œ AliBi åˆ™åœ¨å±€éƒ¨ä¾èµ–ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚åœ¨æ¨¡å‹æ·±åº¦æ–¹é¢ï¼Œä» 3 å±‚å¢åŠ åˆ° 12 å±‚å¯è·å¾—æ˜¾è‘—æ€§èƒ½å¢ç›Šï¼Œä½†å¢åŠ åˆ° 24 å±‚æ—¶æå‡æœ‰é™ç”šè‡³ä¼šå‡ºç°è½»å¾®è¿‡æ‹Ÿåˆã€‚æ­¤é¡¹ç ”ç©¶ä¸ºè®¾è®¡é’ˆå¯¹ DNA åºåˆ—çš„ Transformer æ¨¡å‹æä¾›äº†å…³äºåˆ†è¯å’Œä½ç½®ç¼–ç çš„å®ç”¨æŒ‡å—ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15087v1",
      "published_date": "2025-07-20 19:02:07 UTC",
      "updated_date": "2025-07-20 19:02:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:33.545799+00:00"
    },
    {
      "arxiv_id": "2507.15082v1",
      "title": "Robust Control with Gradient Uncertainty",
      "title_zh": "æ¢¯åº¦ä¸ç¡®å®šæ€§ä¸‹çš„é²æ£’æ§åˆ¶",
      "authors": [
        "Qian Qi"
      ],
      "abstract": "We introduce a novel extension to robust control theory that explicitly addresses uncertainty in the value function's gradient, a form of uncertainty endemic to applications like reinforcement learning where value functions are approximated. We formulate a zero-sum dynamic game where an adversary perturbs both system dynamics and the value function gradient, leading to a new, highly nonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs Equation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness by proving a comparison principle for its viscosity solutions under a uniform ellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a key insight: we prove that the classical quadratic value function assumption fails for any non-zero gradient uncertainty, fundamentally altering the problem structure. A formal perturbation analysis characterizes the non-polynomial correction to the value function and the resulting nonlinearity of the optimal control law, which we validate with numerical studies. Finally, we bridge theory to practice by proposing a novel Gradient-Uncertainty-Robust Actor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating its effectiveness in stabilizing training. This work provides a new direction for robust control, holding significant implications for fields where function approximation is common, including reinforcement learning and computational finance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ å’Œè®¡ç®—é‡‘èç­‰é¢†åŸŸä¸­å¸¸è§çš„å‡½æ•°è¿‘ä¼¼å¯¼è‡´çš„å€¼å‡½æ•°æ¢¯åº¦ (value function's gradient) ä¸ç¡®å®šæ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é²æ£’æ§åˆ¶ (robust control) ç†è®ºçš„æ–°æ‰©å±•ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªé›¶å’ŒåŠ¨æ€åšå¼ˆ (zero-sum dynamic game)ï¼Œç ”ç©¶è€…æ¨å¯¼å‡ºäº†å¸¦æœ‰æ¢¯åº¦ä¸ç¡®å®šæ€§çš„ Hamilton-Jacobi-Bellman-Isaacs æ–¹ç¨‹ (GU-HJBI)ï¼Œå¹¶åˆ©ç”¨ç²˜æ€§è§£ (viscosity solutions) çš„æ¯”è¾ƒåŸç†è¯æ˜äº†å…¶è‰¯å®šæ€§ã€‚é’ˆå¯¹çº¿æ€§äºŒæ¬¡ (linear-quadratic) æ¡ˆä¾‹çš„åˆ†ææ­ç¤ºï¼Œä»»ä½•éé›¶æ¢¯åº¦ä¸ç¡®å®šæ€§éƒ½ä¼šå¯¼è‡´ç»å…¸äºŒæ¬¡å€¼å‡½æ•°å‡è®¾å¤±æ•ˆï¼Œä»è€Œäº§ç”Ÿéå¤šé¡¹å¼ä¿®æ­£å’Œéçº¿æ€§æœ€ä¼˜æ§åˆ¶å¾‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº† Gradient-Uncertainty-Robust Actor-Critic (GURAC) ç®—æ³•ï¼Œé€šè¿‡å®è¯ç ”ç©¶å±•ç¤ºäº†è¯¥ç®—æ³•åœ¨ç¨³å®šè®­ç»ƒæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥å·¥ä½œä¸ºé²æ£’æ§åˆ¶æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ï¼Œå¯¹äºå¹¿æ³›åº”ç”¨å‡½æ•°è¿‘ä¼¼çš„å­¦ç§‘é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15082v1",
      "published_date": "2025-07-20 18:37:30 UTC",
      "updated_date": "2025-07-20 18:37:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:37.051949+00:00"
    },
    {
      "arxiv_id": "2507.15072v1",
      "title": "NavVI: A Telerobotic Simulation with Multimodal Feedback for Visually Impaired Navigation in Warehouse Environments",
      "title_zh": "NavVIï¼šé¢å‘ä»“åº“ç¯å¢ƒè§†éšœå¯¼èˆªçš„å¤šæ¨¡æ€åé¦ˆè¿œç¨‹æœºå™¨äººä»¿çœŸç³»ç»Ÿ",
      "authors": [
        "Maisha Maimuna",
        "Minhaz Bin Farukee",
        "Sama Nikanfar",
        "Mahfuza Siddiqua",
        "Ayon Roy",
        "Fillia Makedon"
      ],
      "abstract": "Industrial warehouses are congested with moving forklifts, shelves and personnel, making robot teleoperation particularly risky and demanding for blind and low-vision (BLV) operators. Although accessible teleoperation plays a key role in inclusive workforce participation, systematic research on its use in industrial environments is limited, and few existing studies barely address multimodal guidance designed for BLV users. We present a novel multimodal guidance simulator that enables BLV users to control a mobile robot through a high-fidelity warehouse environment while simultaneously receiving synchronized visual, auditory, and haptic feedback. The system combines a navigation mesh with regular re-planning so routes remain accurate avoiding collisions as forklifts and human avatars move around the warehouse. Users with low vision are guided with a visible path line towards destination; navigational voice cues with clockwise directions announce upcoming turns, and finally proximity-based haptic feedback notifies the users of static and moving obstacles in the path. This real-time, closed-loop system offers a repeatable testbed and algorithmic reference for accessible teleoperation research. The simulator's design principles can be easily adapted to real robots due to the alignment of its navigation, speech, and haptic modules with commercial hardware, supporting rapid feasibility studies and deployment of inclusive telerobotic tools in actual warehouses.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†NavVIï¼Œä¸€ç§å…·æœ‰å¤šæ¨¡æ€åé¦ˆ(Multimodal Feedback)çš„é¥æ§æœºå™¨äººæ¨¡æ‹Ÿç³»ç»Ÿï¼Œæ—¨åœ¨æå‡ç›²äººåŠä½è§†åŠ›(Blind and Low-Vision, BLV)æ“ä½œå‘˜åœ¨å¤æ‚å·¥ä¸šä»“åº“ç¯å¢ƒä¸­çš„å¯¼èˆªèƒ½åŠ›ã€‚ç³»ç»Ÿé’ˆå¯¹æ‹¥æŒ¤çš„å‰è½¦å’Œè´§æ¶ç¯å¢ƒï¼Œç»“åˆäº†å¯¼èˆªç½‘æ ¼(navigation mesh)ä¸å®æ—¶é‡æ–°è§„åˆ’ç®—æ³•ï¼Œç¡®ä¿æœºå™¨äººèƒ½æœ‰æ•ˆé¿å¼€åŠ¨æ€éšœç¢ç‰©å¹¶ä¿æŒè·¯å¾„ç²¾ç¡®ã€‚NavVIé›†æˆäº†å¯è§è·¯å¾„å¼•å¯¼çº¿ã€æ—¶é’Ÿæ–¹ä½å¯¼èˆªè¯­éŸ³(navigational voice cues)ä»¥åŠåŸºäºè·ç¦»çš„è§¦è§‰åé¦ˆ(haptic feedback)ï¼Œä¸ºç”¨æˆ·æä¾›äº†å®æ—¶çš„é—­ç¯æ„ŸçŸ¥æŒ‡å¼•ã€‚è¯¥æ¨¡æ‹Ÿå™¨ä¸ºå¯è®¿é—®é¥æ“ä½œ(accessible teleoperation)ç ”ç©¶æä¾›äº†å¯é‡å¤çš„æµ‹è¯•åºŠå’Œç®—æ³•å‚è€ƒã€‚ç”±äºå…¶è®¾è®¡åŸç†ä¸å•†ä¸šç¡¬ä»¶é«˜åº¦å…¼å®¹ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿè½»æ¾è¿ç§»è‡³çœŸå®æœºå™¨äººå¹³å°ï¼Œä¸ºåœ¨å®é™…ä»“åº“ä¸­éƒ¨ç½²åŒ…å®¹æ€§é¥æ“ä½œå·¥å…·æä¾›äº†å…³é”®çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15072v1",
      "published_date": "2025-07-20 18:14:55 UTC",
      "updated_date": "2025-07-20 18:14:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:38.457326+00:00"
    },
    {
      "arxiv_id": "2507.15066v4",
      "title": "Time-RA: Towards Time Series Reasoning for Anomaly Diagnosis with LLM Feedback",
      "title_zh": "Time-RAï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹åé¦ˆçš„æ—¶é—´åºåˆ—å¼‚å¸¸è¯Šæ–­æ¨ç†",
      "authors": [
        "Yiyuan Yang",
        "Zichuan Liu",
        "Lei Song",
        "Kai Ying",
        "Zhiguang Wang",
        "Tom Bamford",
        "Svitlana Vyetrenko",
        "Jiang Bian",
        "Qingsong Wen"
      ],
      "abstract": "Time series anomaly detection (TSAD) has traditionally focused on binary classification and often lacks the fine-grained categorization and explanatory reasoning required for transparent decision-making. To address these limitations, we propose Time-series Reasoning for Anomaly (Time-RA), a novel task that reformulates TSAD from a discriminative into a generative, reasoning-intensive paradigm. To facilitate this, we introduce RATs40K, the first real-world large-scale multimodal benchmark with ~40,000 samples across 10 domains, integrating raw time series, textual context, and visual plots with structured reasoning annotations. Extensive benchmarking shows that while supervised fine-tuning and visual representations boost diagnostic accuracy and reasoning consistency, performance varies across complex scenarios. Notably, fine-tuned models demonstrate strong \"plug-and-play\" transferability, outperforming traditional baselines on unseen real-world datasets. Our work establishes a foundation for interpretable, multimodal time series analysis. All code (https://github.com/yyysjz1997/Time-RA) and the RATs40K dataset (https://huggingface.co/datasets/Time-RA/RATs40K) are fully open-sourced to facilitate future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Time-series Reasoning for Anomaly (Time-RA)ï¼Œæ—¨åœ¨å°†æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹(TSAD)ä»ä¼ ç»Ÿçš„äºŒåˆ†ç±»åˆ¤åˆ«æ¨¡å¼è½¬å˜ä¸ºä¸€ç§ç”Ÿæˆå¼ã€æ¨ç†å¯†é›†å‹çš„èŒƒå¼ã€‚ä¸ºæ­¤ï¼Œä½œè€…æ¨å‡ºäº†RATs40Kï¼Œè¿™æ˜¯é¦–ä¸ªçœŸå®ä¸–ç•Œçš„å¤§è§„æ¨¡å¤šæ¨¡æ€åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«åˆ†å¸ƒåœ¨10ä¸ªé¢†åŸŸçš„çº¦4ä¸‡ä¸ªæ ·æœ¬ï¼Œå¹¶é›†æˆäº†åŸå§‹åºåˆ—ã€æ–‡æœ¬ä¸Šä¸‹æ–‡ã€è§†è§‰å›¾åƒåŠç»“æ„åŒ–æ¨ç†æ³¨é‡Šã€‚å®éªŒåŸºå‡†æµ‹è¯•è¡¨æ˜ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒ(supervised fine-tuning)å’Œå¼•å…¥è§†è§‰è¡¨ç¤ºï¼Œæ¨¡å‹åœ¨è¯Šæ–­å‡†ç¡®æ€§ä¸æ¨ç†ä¸€è‡´æ€§ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚ç ”ç©¶è¿˜å‘ç°å¾®è°ƒåçš„æ¨¡å‹å…·å¤‡å¼ºå¤§çš„å³æ’å³ç”¨(plug-and-play)è¿ç§»èƒ½åŠ›ï¼Œåœ¨æœªè§è¿‡çš„çœŸå®æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºä¼ ç»Ÿæ¨¡å‹ã€‚æ­¤é¡¹å·¥ä½œä¸ºå¯è§£é‡Šçš„å¤šæ¨¡æ€æ—¶é—´åºåˆ—åˆ†æå¥ å®šäº†åŸºç¡€ï¼Œç›¸å…³ä»£ç ä¸RATs40Kæ•°æ®é›†å‡å·²å¼€æºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review. 25 pages, 11 figures, 14 tables. Code and dataset are publicly available",
      "pdf_url": "https://arxiv.org/pdf/2507.15066v4",
      "published_date": "2025-07-20 18:02:50 UTC",
      "updated_date": "2026-01-10 14:41:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:42.116084+00:00"
    },
    {
      "arxiv_id": "2507.15064v1",
      "title": "StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation",
      "title_zh": "StableAnimator++ï¼šè§£å†³äººç‰©å›¾åƒåŠ¨ç”»ä¸­çš„å§¿æ€ä¸å¯¹é½ä¸é¢éƒ¨ç•¸å˜",
      "authors": [
        "Shuyuan Tu",
        "Zhen Xing",
        "Xintong Han",
        "Zhi-Qi Cheng",
        "Qi Dai",
        "Chong Luo",
        "Zuxuan Wu",
        "Yu-Gang Jiang"
      ],
      "abstract": "Current diffusion models for human image animation often struggle to maintain identity (ID) consistency, especially when the reference image and driving video differ significantly in body size or position. We introduce StableAnimator++, the first ID-preserving video diffusion framework with learnable pose alignment, capable of generating high-quality videos conditioned on a reference image and a pose sequence without any post-processing. Building upon a video diffusion model, StableAnimator++ contains carefully designed modules for both training and inference, striving for identity consistency. In particular, StableAnimator++ first uses learnable layers to predict the similarity transformation matrices between the reference image and the driven poses via injecting guidance from Singular Value Decomposition (SVD). These matrices align the driven poses with the reference image, mitigating misalignment to a great extent. StableAnimator++ then computes image and face embeddings using off-the-shelf encoders, refining the face embeddings via a global content-aware Face Encoder. To further maintain ID, we introduce a distribution-aware ID Adapter that counteracts interference caused by temporal layers while preserving ID via distribution alignment. During the inference stage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization integrated into the denoising process, guiding the diffusion trajectory for enhanced facial fidelity. Experiments on benchmarks show the effectiveness of StableAnimator++ both qualitatively and quantitatively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†StableAnimator++ï¼Œè¿™æ˜¯ä¸€ä¸ªå…·å¤‡å¯å­¦ä¹ å§¿æ€å¯¹é½åŠŸèƒ½çš„èº«ä»½ä¿æŒ(ID-preserving)è§†é¢‘æ‰©æ•£æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºè§£å†³äººä½“å›¾åƒåŠ¨ç”»ä¸­å› å§¿æ€æˆ–ä½“å‹å·®å¼‚å¯¼è‡´çš„èº«ä»½ä¸€è‡´æ€§éš¾é¢˜ã€‚é’ˆå¯¹å‚è€ƒå›¾åƒä¸é©±åŠ¨è§†é¢‘ä¹‹é—´çš„ä¸åŒ¹é…ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å¥‡å¼‚å€¼åˆ†è§£(SVD)å¼•å¯¼çš„å¯å­¦ä¹ å±‚é¢„æµ‹ç›¸ä¼¼å˜æ¢çŸ©é˜µï¼Œå®ç°äº†é©±åŠ¨å§¿æ€ä¸å‚è€ƒå›¾åƒçš„ç²¾å‡†å¯¹é½ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¼ºåŒ–ç‰¹å¾æå–ï¼ŒStableAnimator++ç»“åˆäº†å…¨å±€å†…å®¹æ„ŸçŸ¥Face Encoderä»¥åŠåˆ†å¸ƒæ„ŸçŸ¥ID Adapterï¼Œæœ‰æ•ˆæŠµæ¶ˆäº†æ—¶é—´å±‚å¸¦æ¥çš„å¹²æ‰°å¹¶ä¿æŒäº†èº«ä»½åˆ†å¸ƒä¸€è‡´ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºHamilton-Jacobi-Bellman (HJB)æ–¹ç¨‹çš„è„¸éƒ¨ä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡å¼•å¯¼å»å™ªè¿‡ç¨‹ä¸­çš„æ‰©æ•£è½¨è¿¹æ˜¾è‘—æå‡äº†é¢éƒ¨ä¿çœŸåº¦ã€‚å®éªŒç»“æœåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•çš„å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­å‡éªŒè¯äº†è¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡ã€é«˜ä¸€è‡´æ€§è§†é¢‘æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2411.17697",
      "pdf_url": "https://arxiv.org/pdf/2507.15064v1",
      "published_date": "2025-07-20 17:59:26 UTC",
      "updated_date": "2025-07-20 17:59:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:44.147092+00:00"
    },
    {
      "arxiv_id": "2507.15062v2",
      "title": "Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper",
      "title_zh": "Touch in the Wildï¼šåŸºäºä¾¿æºå¼è§†è§¦è§‰å¤¹æŒå™¨çš„ç»†ç²’åº¦æ“ä½œå­¦ä¹ ",
      "authors": [
        "Xinyue Zhu",
        "Binghao Huang",
        "Yunzhu Li"
      ],
      "abstract": "Handheld grippers are increasingly used to collect human demonstrations due to their ease of deployment and versatility. However, most existing designs lack tactile sensing, despite the critical role of tactile feedback in precise manipulation. We present a portable, lightweight gripper with integrated tactile sensors that enables synchronized collection of visual and tactile data in diverse, real-world, and in-the-wild settings. Building on this hardware, we propose a cross-modal representation learning framework that integrates visual and tactile signals while preserving their distinct characteristics. The learning procedure allows the emergence of interpretable representations that consistently focus on contacting regions relevant for physical interactions. When used for downstream manipulation tasks, these representations enable more efficient and effective policy learning, supporting precise robotic manipulation based on multimodal feedback. We validate our approach on fine-grained tasks such as test tube insertion and pipette-based fluid transfer, demonstrating improved accuracy and robustness under external disturbances. Our project page is available at https://binghao-huang.github.io/touch_in_the_wild/ .",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†ä¸€ç§ä¾¿æºå¼ã€è½»é‡çº§çš„è§†è§‰-è§¦è§‰æŠ“å–å™¨(Visuo-Tactile Gripper)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ‰‹æŒæŠ“å–å™¨ç¼ºä¹è§¦è§‰åé¦ˆçš„é—®é¢˜ï¼Œå¹¶æ”¯æŒåœ¨å¤šæ ·åŒ–çš„ç°å®åœºæ™¯ä¸­åŒæ­¥æ”¶é›†è§†è§‰å’Œè§¦è§‰æ•°æ®ã€‚åŸºäºè¯¥ç¡¬ä»¶ï¼Œä½œè€…æå‡ºäº†ä¸€ç§è·¨æ¨¡æ€è¡¨å¾å­¦ä¹ (Cross-modal Representation Learning)æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™è§†è§‰å’Œè§¦è§‰ä¿¡å·å„è‡ªç‰¹å¾çš„åŒæ—¶å°†å…¶æœ‰æ•ˆæ•´åˆã€‚è¯¥å­¦ä¹ è¿‡ç¨‹ä¿ƒä½¿ç³»ç»Ÿäº§ç”Ÿå¯è§£é‡Šçš„è¡¨å¾ï¼Œä½¿å…¶èƒ½å¤ŸæŒç»­å…³æ³¨ä¸ç‰©ç†äº¤äº’ç›¸å…³çš„æ¥è§¦åŒºåŸŸã€‚åœ¨ä¸‹æ¸¸æ“ä½œä»»åŠ¡ä¸­ï¼Œè¿™äº›è¡¨å¾æ˜¾è‘—æå‡äº†ç­–ç•¥å­¦ä¹ (Policy Learning)çš„æ•ˆç‡å’Œæœ‰æ•ˆæ€§ï¼Œæ”¯æŒåŸºäºå¤šæ¨¡æ€åé¦ˆçš„ç²¾ç¡®æœºå™¨äººæ“ä½œã€‚é€šè¿‡åœ¨è¯•ç®¡æ’å…¥å’Œç§»æ¶²ç®¡æ¶²ä½“è½¬ç§»ç­‰ç²¾ç»†æ“ä½œä»»åŠ¡ä¸Šçš„éªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨å¤–éƒ¨å¹²æ‰°ä¸‹è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§(Robustness)ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "More videos can be found on our website:https://binghao-huang.github.io/touch_in_the_wild/",
      "pdf_url": "https://arxiv.org/pdf/2507.15062v2",
      "published_date": "2025-07-20 17:53:59 UTC",
      "updated_date": "2025-11-12 02:16:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:46:47.933475+00:00"
    },
    {
      "arxiv_id": "2507.15061v1",
      "title": "WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization",
      "title_zh": "WebShaperï¼šåŸºäºä¿¡æ¯å¯»æ±‚å½¢å¼åŒ–çš„æ™ºèƒ½ä½“åŒ–æ•°æ®åˆæˆ",
      "authors": [
        "Zhengwei Tao",
        "Jialong Wu",
        "Wenbiao Yin",
        "Junkai Zhang",
        "Baixuan Li",
        "Haiyang Shen",
        "Kuan Li",
        "Liwen Zhang",
        "Xinyu Wang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "abstract": "The advent of Large Language Model (LLM)-powered agents has revolutionized artificial intelligence by enabling solutions to complex, open-ended tasks through web-based information-seeking (IS) capabilities. The scarcity of high-quality training data has limited the development of IS agents. Existing approaches typically adopt an information-driven paradigm that first collects web data and then generates questions based on the retrieval. However, this may lead to inconsistency between information structure and reasoning structure, question and answer. To mitigate, we propose a formalization-driven IS data synthesis framework WebShaper to construct a dataset. WebShaper systematically formalizes IS tasks through set theory. Central to the formalization is the concept of Knowledge Projections (KP), which enables precise control over reasoning structure by KP operation compositions. During synthesis, we begin by creating seed tasks, then use a multi-step expansion process. At each step, an agentic Expander expands the current formal question more complex with retrieval and validation tools based on our formalization. We train our model on the synthesized dataset. Experiment results demonstrate that WebShaper achieves state-of-the-art performance among open-sourced IS agents on GAIA and WebWalkerQA benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨ä¿¡æ¯å¯»æ±‚ï¼ˆInformation-Seeking, ISï¼‰ä»»åŠ¡ä¸­é¢ä¸´çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®çŸ­ç¼ºï¼Œä»¥åŠç°æœ‰æ•°æ®åˆæˆæ–¹æ³•ä¸­ä¿¡æ¯ç»“æ„ä¸æ¨ç†ç»“æ„ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œæå‡ºäº† WebShaper æ¡†æ¶ã€‚WebShaper æ˜¯ä¸€ç§å½¢å¼åŒ–é©±åŠ¨çš„ IS æ•°æ®åˆæˆæ¡†æ¶ï¼Œé€šè¿‡é›†åˆè®ºç³»ç»Ÿåœ°å¯¹ä¿¡æ¯å¯»æ±‚ä»»åŠ¡è¿›è¡Œå»ºæ¨¡ã€‚å…¶æ ¸å¿ƒåœ¨äºçŸ¥è¯†æŠ•å½±ï¼ˆKnowledge Projections, KPï¼‰æ¦‚å¿µï¼Œé€šè¿‡ KP æ“ä½œçš„ç»„åˆå®ç°äº†å¯¹æ¨ç†ç»“æ„çš„ç²¾ç¡®æ§åˆ¶ã€‚åœ¨åˆæˆè¿‡ç¨‹ä¸­ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å…·å¤‡æ£€ç´¢å’ŒéªŒè¯å·¥å…·çš„æ™ºèƒ½ä½“æ‰©å±•å™¨ï¼ˆExpanderï¼‰å¯¹ç§å­ä»»åŠ¡è¿›è¡Œå¤šæ­¥å¤æ‚åŒ–å¤„ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ WebShaper åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨ GAIA å’Œ WebWalkerQA åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†å¼€æº IS æ™ºèƒ½ä½“ä¸­çš„å…ˆè¿›æ°´å¹³ï¼ˆState-of-the-Artï¼‰æ€§èƒ½ã€‚è¯¥é¡¹å·¥ä½œä¸ºæå‡æ™ºèƒ½ä½“å¤„ç†å¤æ‚å¼€æ”¾å¼ä»»åŠ¡çš„èƒ½åŠ›æä¾›äº†é«˜è´¨é‡çš„æ•°æ®æ”¯æŒæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15061v1",
      "published_date": "2025-07-20 17:53:37 UTC",
      "updated_date": "2025-07-20 17:53:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:04.289816+00:00"
    },
    {
      "arxiv_id": "2507.15042v1",
      "title": "DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection",
      "title_zh": "DeRAGï¼šåŸºäºæç¤ºè¯æ³¨å…¥çš„å¤šç§æ£€ç´¢å¢å¼ºç”Ÿæˆåº”ç”¨é»‘ç›’å¯¹æŠ—æ”»å‡»",
      "authors": [
        "Jerry Wang",
        "Fang Yu"
      ],
      "abstract": "Adversarial prompt attacks can significantly alter the reliability of Retrieval-Augmented Generation (RAG) systems by re-ranking them to produce incorrect outputs. In this paper, we present a novel method that applies Differential Evolution (DE) to optimize adversarial prompt suffixes for RAG-based question answering. Our approach is gradient-free, treating the RAG pipeline as a black box and evolving a population of candidate suffixes to maximize the retrieval rank of a targeted incorrect document to be closer to real world scenarios. We conducted experiments on the BEIR QA datasets to evaluate attack success at certain retrieval rank thresholds under multiple retrieving applications. Our results demonstrate that DE-based prompt optimization attains competitive (and in some cases higher) success rates compared to GGPP to dense retrievers and PRADA to sparse retrievers, while using only a small number of tokens (<=5 tokens) in the adversarial suffix. Furthermore, we introduce a readability-aware suffix construction strategy, validated by a statistically significant reduction in MLM negative log-likelihood with Welch's t-test. Through evaluations with a BERT-based adversarial suffix detector, we show that DE-generated suffixes evade detection, yielding near-chance detection accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DeRAGï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) ç³»ç»Ÿçš„æ–°å‹é»‘ç›’å¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡æç¤ºè¯æ³¨å…¥ (Prompt Injection) æ“çºµæ–‡æ¡£æ’åå¹¶å¯¼è‡´ç³»ç»Ÿè¾“å‡ºé”™è¯¯ä¿¡æ¯ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°é‡‡ç”¨å·®å¼‚è¿›åŒ– (Differential Evolution, DE) ç®—æ³•æ¥ä¼˜åŒ–å¯¹æŠ—æ€§æç¤ºè¯åç¼€ï¼Œå…·æœ‰æ— æ¢¯åº¦ (Gradient-free) çš„ç‰¹æ€§ï¼Œå°†æ•´ä¸ª RAG æµæ°´çº¿è§†ä¸ºé»‘ç›’è¿›è¡Œå¤„ç†ã€‚é€šè¿‡æ¼”åŒ–å€™é€‰åç¼€ç§ç¾¤ï¼ŒDeRAG èƒ½å¤Ÿæ˜¾è‘—æå‡ç›®æ ‡é”™è¯¯æ–‡æ¡£çš„æ£€ç´¢æ’åï¼Œä½¿å…¶åœ¨å®é™…åº”ç”¨ä¸­æ›´æ˜“è¢«é‡‡çº³ã€‚åœ¨ BEIR é—®ç­”æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œå³ä¾¿å¯¹æŠ—åç¼€é•¿åº¦æçŸ­ï¼ˆä¸è¶…è¿‡ 5 ä¸ª tokensï¼‰ï¼ŒDeRAG åœ¨é’ˆå¯¹å¯†é›†æ£€ç´¢å™¨ (Dense Retrievers) å’Œç¨€ç–æ£€ç´¢å™¨ (Sparse Retrievers) çš„æ”»å‡»æˆåŠŸç‡ä¸Šï¼Œä»ä¼˜äºæˆ–ç­‰åŒäº GGPP å’Œ PRADA ç­‰ç°æœ‰æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†å…·å¤‡å¯è¯»æ€§æ„è¯†çš„åç¼€æ„å»ºç­–ç•¥ï¼Œå¹¶éªŒè¯äº†è¯¥æ–¹æ³•ç”Ÿæˆçš„åç¼€èƒ½å¤Ÿæœ‰æ•ˆé€ƒé¿åŸºäº BERT çš„å¯¹æŠ—æ£€æµ‹å™¨ï¼Œå…¶æ£€æµ‹å‡†ç¡®ç‡æ¥è¿‘éšæœºæ°´å¹³ã€‚",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by KDD Workshop on Prompt Optimization 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15042v1",
      "published_date": "2025-07-20 16:48:20 UTC",
      "updated_date": "2025-07-20 16:48:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:05.788405+00:00"
    },
    {
      "arxiv_id": "2507.15895v1",
      "title": "Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture",
      "title_zh": "å°†åŸºäºç†æ®çš„é“å¾·å†³ç­–æ•´åˆè‡³å¼ºåŒ–å­¦ä¹ æ¶æ„",
      "authors": [
        "Lisa Dargasz"
      ],
      "abstract": "Reinforcement Learning is a machine learning methodology that has demonstrated strong performance across a variety of tasks. In particular, it plays a central role in the development of artificial autonomous agents. As these agents become increasingly capable, market readiness is rapidly approaching, which means those agents, for example taking the form of humanoid robots or autonomous cars, are poised to transition from laboratory prototypes to autonomous operation in real-world environments. This transition raises concerns leading to specific requirements for these systems - among them, the requirement that they are designed to behave ethically. Crucially, research directed toward building agents that fulfill the requirement to behave ethically - referred to as artificial moral agents(AMAs) - has to address a range of challenges at the intersection of computer science and philosophy. This study explores the development of reason-based artificial moral agents (RBAMAs). RBAMAs are build on an extension of the reinforcement learning architecture to enable moral decision-making based on sound normative reasoning, which is achieved by equipping the agent with the capacity to learn a reason-theory - a theory which enables it to process morally relevant propositions to derive moral obligations - through case-based feedback. They are designed such that they adapt their behavior to ensure conformance to these obligations while they pursue their designated tasks. These features contribute to the moral justifiability of the their actions, their moral robustness, and their moral trustworthiness, which proposes the extended architecture as a concrete and deployable framework for the development of AMAs that fulfills key ethical desiderata. This study presents a first implementation of an RBAMA and demonstrates the potential of RBAMAs in initial experiments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°†åŸºäºç†ç”±çš„é“å¾·å†³ç­–(Reason-Based Moral Decision-Making)æ•´åˆè¿›å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¶æ„ä¸­ï¼Œæ—¨åœ¨å¼€å‘èƒ½å¤Ÿåº”å¯¹å¤æ‚ä¼¦ç†æŒ‘æˆ˜çš„äººå·¥é“å¾·æ™ºèƒ½ä½“(AMAs)ã€‚ä½œè€…æå‡ºäº†åŸºäºç†ç”±çš„äººå·¥é“å¾·æ™ºèƒ½ä½“(RBAMAs)æ¦‚å¿µï¼Œé€šè¿‡æ‰©å±•å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä½¿å…¶å…·å¤‡å­¦ä¹ ç†ç”±ç†è®º(reason-theory)çš„èƒ½åŠ›ã€‚é€šè¿‡æ¡ˆä¾‹åé¦ˆ(case-based feedback)ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿå¤„ç†é“å¾·ç›¸å…³å‘½é¢˜å¹¶æ¨å¯¼å‡ºå…·ä½“çš„é“å¾·ä¹‰åŠ¡(moral obligations)ã€‚åœ¨æ‰§è¡Œé¢„å®šä»»åŠ¡æ—¶ï¼ŒRBAMAs ä¼šåŠ¨æ€è°ƒæ•´è¡Œä¸ºä»¥ç¡®ä¿ç¬¦åˆè¿™äº›ä¼¦ç†è¦æ±‚ï¼Œå¢å¼ºäº†ç³»ç»Ÿè¡Œä¸ºçš„é“å¾·æ­£å½“æ€§(moral justifiability)ä¸å¯ä¿¡åº¦ã€‚å®éªŒç»“æœå’Œåˆæ­¥å®ç°è¯æ˜ï¼Œè¯¥æ¶æ„ä¸ºå¼€å‘ç¬¦åˆä¼¦ç†è§„èŒƒä¸”å¯éƒ¨ç½²çš„æ™ºèƒ½ä½“æä¾›äº†ä¸€ä¸ªåˆ‡å®å¯è¡Œçš„æŠ€æœ¯æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Master's thesis, April 2025, 122 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.15895v1",
      "published_date": "2025-07-20 16:46:16 UTC",
      "updated_date": "2025-07-20 16:46:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:12.720247+00:00"
    },
    {
      "arxiv_id": "2507.15032v1",
      "title": "The hunt for new pulsating ultraluminous X-ray sources: a clustering approach",
      "title_zh": "æœå¯»æ–°å‹è„‰åŠ¨è¶…äº®Xå°„çº¿æºï¼šä¸€ç§èšç±»æ–¹æ³•",
      "authors": [
        "NicolÃ² Oreste Pinciroli Vago",
        "Roberta Amato",
        "Matteo Imbrogno",
        "GianLuca Israel",
        "Andrea Belfiore",
        "Konstantinos Kovlakas",
        "Piero Fraternali",
        "Mario Pasquato"
      ],
      "abstract": "The discovery of fast and variable coherent signals in a handful of ultraluminous X-ray sources (ULXs) testifies to the presence of super-Eddington accreting neutron stars, and drastically changed the understanding of the ULX class. Our capability of discovering pulsations in ULXs is limited, among others, by poor statistics. However, catalogues and archives of high-energy missions contain information which can be used to identify new candidate pulsating ULXs (PULXs). The goal of this research is to single out candidate PULXs among those ULXs which have not shown pulsations due to an unfavourable combination of factors. We applied an AI approach to an updated database of ULXs detected by XMM-Newton. We first used an unsupervised clustering algorithm to sort out sources with similar characteristics into two clusters. Then, the sample of known PULX observations has been used to set the separation threshold between the two clusters and to identify the one containing the new candidate PULXs. We found that only a few criteria are needed to assign the membership of an observation to one of the two clusters. The cluster of new candidate PULXs counts 85 unique sources for 355 observations, with $\\sim$85% of these new candidates having multiple observations. A preliminary timing analysis found no new pulsations for these candidates. This work presents a sample of new candidate PULXs observed by XMM-Newton, the properties of which are similar (in a multi-dimensional phase space) to those of the known PULXs, despite the absence of pulsations in their light curves. While this result is a clear example of the predictive power of AI-based methods, it also highlights the need for high-statistics observational data to reveal coherent signals from the sources in this sample and thus validate the robustness of the approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨è¶…äº®Xå°„çº¿æº(ULXs)ä¸­æ¢æµ‹è„‰å†²ä¿¡å·å—é™äºç»Ÿè®¡æ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„èšç±»æ–¹æ³•ï¼Œæ—¨åœ¨ä» XMM-Newton æ•°æ®åº“ä¸­è¯†åˆ«æ½œåœ¨çš„è„‰å†²è¶…äº®Xå°„çº¿æº(PULXs)å€™é€‰è€…ã€‚ç ”ç©¶è€…é‡‡ç”¨æ— ç›‘ç£èšç±»ç®—æ³•(unsupervised clustering algorithm)å°†ç‰¹å¾ç›¸ä¼¼çš„è§‚æµ‹æºåˆ†ä¸ºä¸¤ç±»ï¼Œå¹¶åˆ©ç”¨å·²çŸ¥ PULXs çš„æ•°æ®è®¾å®šåˆ†ç±»é˜ˆå€¼ï¼Œä»è€Œé”å®šåŒ…å«æ–°å€™é€‰æºçš„èšç±»ã€‚ç»“æœæ˜¾ç¤ºï¼Œä»…éœ€å°‘æ•°æ ‡å‡†å³å¯åˆ¤å®šèšç±»å½’å±ï¼Œç ”ç©¶æœ€ç»ˆç­›é€‰å‡ºåŒ…å«85ä¸ªç‹¬ç‰¹æºã€æ¶‰åŠ355æ¬¡è§‚æµ‹çš„å€™é€‰åå•ï¼Œå…¶ä¸­çº¦85%çš„å€™é€‰æºå…·æœ‰å¤šæ¬¡è§‚æµ‹è®°å½•ã€‚å°½ç®¡åˆæ­¥çš„æ—¶å˜åˆ†æ(timing analysis)å°šæœªåœ¨è¿™äº›å€™é€‰è€…ä¸­å‘ç°æ–°çš„è„‰å†²ä¿¡å·ï¼Œä½†è¿™äº›æºåœ¨å¤šç»´ç›¸ç©ºé—´ä¸­çš„å±æ€§ä¸å·²çŸ¥ PULXs é«˜åº¦ç›¸ä¼¼ã€‚è¯¥å·¥ä½œè¯æ˜äº†äººå·¥æ™ºèƒ½æ–¹æ³•åœ¨å¤©æ–‡å‘ç°ä¸­çš„é¢„æµ‹æ½œåŠ›ï¼ŒåŒæ—¶ä¹ŸæŒ‡å‡ºæœªæ¥éœ€è¦æ›´é«˜ç»Ÿè®¡è´¨é‡çš„è§‚æµ‹æ•°æ®æ¥éªŒè¯è¯¥æ–¹æ³•çš„ç¨³å¥æ€§å¹¶æœ€ç»ˆç¡®è®¤è„‰å†²ä¿¡å·ã€‚",
      "categories": [
        "astro-ph.HE",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.HE",
      "comment": "16 pages, 8 figures; accepted in A&A",
      "pdf_url": "https://arxiv.org/pdf/2507.15032v1",
      "published_date": "2025-07-20 16:33:18 UTC",
      "updated_date": "2025-07-20 16:33:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:13.561428+00:00"
    },
    {
      "arxiv_id": "2507.15025v1",
      "title": "Survey of GenAI for Automotive Software Development: From Requirements to Executable Code",
      "title_zh": "æ±½è½¦è½¯ä»¶å¼€å‘ä¸­çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç»¼è¿°ï¼šä»éœ€æ±‚åˆ°å¯æ‰§è¡Œä»£ç ",
      "authors": [
        "Nenad Petrovic",
        "Vahid Zolfaghari",
        "Andre Schamschurko",
        "Sven Kirchner",
        "Fengjunjie Pan",
        "Chengdng Wu",
        "Nils Purschke",
        "Aleksei Velsh",
        "Krzysztof Lebioda",
        "Yinglei Song",
        "Yi Zhang",
        "Lukasz Mazur",
        "Alois Knoll"
      ],
      "abstract": "Adoption of state-of-art Generative Artificial Intelligence (GenAI) aims to revolutionize many industrial areas by reducing the amount of human intervention needed and effort for handling complex underlying processes. Automotive software development is considered to be a significant area for GenAI adoption, taking into account lengthy and expensive procedures, resulting from the amount of requirements and strict standardization. In this paper, we explore the adoption of GenAI for various steps of automotive software development, mainly focusing on requirements handling, compliance aspects and code generation. Three GenAI-related technologies are covered within the state-of-art: Large Language Models (LLMs), Retrieval Augmented Generation (RAG), Vision Language Models (VLMs), as well as overview of adopted prompting techniques in case of code generation. Additionally, we also derive a generalized GenAI-aided automotive software development workflow based on our findings from this literature review. Finally, we include a summary of a survey outcome, which was conducted among our automotive industry partners regarding the type of GenAI tools used for their daily work activities.",
      "tldr_zh": "è¯¥è®ºæ–‡ç»¼è¿°äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenAIï¼‰åœ¨æ±½è½¦è½¯ä»¶å¼€å‘é¢†åŸŸçš„åº”ç”¨ï¼Œæ—¨åœ¨é€šè¿‡å‡å°‘äººå·¥å¹²é¢„æ¥ä¼˜åŒ–ç”±äºå¤§é‡éœ€æ±‚å’Œä¸¥æ ¼æ ‡å‡†åŒ–å¯¼è‡´çš„å†—é•¿ä¸”æ˜‚è´µçš„å¼€å‘æµç¨‹ã€‚ç ”ç©¶é‡ç‚¹æ¢è®¨äº†GenAIåœ¨éœ€æ±‚å¤„ç†ã€åˆè§„æ€§åŠä»£ç ç”Ÿæˆç­‰å…³é”®æ­¥éª¤çš„åº”ç”¨ï¼Œæ¶µç›–äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ç­‰å‰æ²¿æŠ€æœ¯ï¼Œå¹¶æ¦‚è¿°äº†ä»£ç ç”Ÿæˆä¸­çš„æç¤ºæŠ€æœ¯ã€‚ä½œè€…æ ¹æ®æ–‡çŒ®ç»¼è¿°æ¨å¯¼å‡ºäº†ä¸€ä¸ªé€šç”¨çš„GenAIè¾…åŠ©æ±½è½¦è½¯ä»¶å¼€å‘å·¥ä½œæµï¼Œä¸ºè¯¥é¢†åŸŸçš„å·¥ç¨‹å®è·µæä¾›äº†ç³»ç»ŸåŒ–æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åŒ…å«äº†ä¸€é¡¹é’ˆå¯¹æ±½è½¦è¡Œä¸šåˆä½œä¼™ä¼´çš„è°ƒæŸ¥ï¼Œæ€»ç»“äº†ä¸šç•Œåœ¨æ—¥å¸¸å¼€å‘æ´»åŠ¨ä¸­å®é™…ä½¿ç”¨çš„GenAIå·¥å…·ç±»å‹ã€‚æœ¬æ–‡å…¨é¢å±•ç¤ºäº†GenAIåœ¨æå‡æ±½è½¦è½¯ä»¶å¼€å‘æ•ˆç‡å’Œé™ä½æˆæœ¬æ–¹é¢çš„åº”ç”¨ç°çŠ¶ä¸æ½œåŠ›ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Conference paper accepted for GACLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15025v1",
      "published_date": "2025-07-20 16:21:51 UTC",
      "updated_date": "2025-07-20 16:21:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:12.887181+00:00"
    },
    {
      "arxiv_id": "2507.15013v1",
      "title": "A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing",
      "title_zh": "äººæ ¼æµ‹éªŒä¸­çš„è¿«é€‰å¼ç¥ç»è®¤çŸ¥è¯Šæ–­æ¨¡å‹",
      "authors": [
        "Xiaoyu Li",
        "Jin Wu",
        "Shaoyang Guo",
        "Haoran Shi",
        "Chanjin Zheng"
      ],
      "abstract": "In the smart era, psychometric tests are becoming increasingly important for personnel selection, career development, and mental health assessment. Forced-choice tests are common in personality assessments because they require participants to select from closely related options, lowering the risk of response distortion. This study presents a deep learning-based Forced-Choice Neural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of traditional models and is applicable to the three most common item block types found in forced-choice tests. To account for the unidimensionality of items in forced-choice tests, we create interpretable participant and item parameters. We model the interactions between participant and item features using multilayer neural networks after mining them using nonlinear mapping. In addition, we use the monotonicity assumption to improve the interpretability of the diagnostic results. The FCNCD's effectiveness is validated by experiments on real-world and simulated datasets that show its accuracy, interpretability, and robustness.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„å¼ºè¿«é€‰æ‹©ç¥ç»è®¤çŸ¥è¯Šæ–­æ¨¡å‹(FCNCD)ï¼Œæ—¨åœ¨å…‹æœäººæ ¼æµ‹è¯„ä¸­å¼ºè¿«é€‰æ‹©æµ‹è¯•(Forced-choice tests)çš„ä¼ ç»Ÿæ¨¡å‹å±€é™æ€§ã€‚è¯¥æ¨¡å‹é€‚ç”¨äºå¼ºè¿«é€‰æ‹©æµ‹è¯•ä¸­å¸¸è§çš„ä¸‰ç§é¢˜ç»„ç±»å‹ï¼Œé€šè¿‡éçº¿æ€§æ˜ å°„å’Œå¤šå±‚ç¥ç»ç½‘ç»œ(multilayer neural networks)å¯¹è¢«è¯•ä¸é¡¹ç›®ç‰¹å¾çš„äº¤äº’è¿›è¡Œå»ºæ¨¡ã€‚ä¸ºäº†åº”å¯¹é¡¹ç›®çš„å•ç»´æ€§(unidimensionality)ï¼Œç ”ç©¶æ„å»ºäº†å¯è§£é‡Šçš„è¢«è¯•å’Œé¡¹ç›®å‚æ•°ï¼Œå¹¶å¼•å…¥å•è°ƒæ€§å‡è®¾(monotonicity assumption)ä»¥å¢å¼ºè¯Šæ–­ç»“æœçš„å¯é æ€§ã€‚åœ¨çœŸå®ä¸–ç•Œå’Œæ¨¡æ‹Ÿæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒFCNCDåœ¨å‡†ç¡®æ€§ã€å¯è§£é‡Šæ€§å’Œé²æ£’æ€§(robustness)æ–¹é¢å‡è¡¨ç°ä¼˜å¼‚ï¼Œä¸ºæ™ºèƒ½åŒ–çš„äººå‘˜é€‰æ‹”å’Œå¿ƒç†å¥åº·è¯„ä¼°æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15013v1",
      "published_date": "2025-07-20 15:39:36 UTC",
      "updated_date": "2025-07-20 15:39:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:19.585842+00:00"
    },
    {
      "arxiv_id": "2507.22916v1",
      "title": "From Propagator to Oscillator: The Dual Role of Symmetric Differential Equations in Neural Systems",
      "title_zh": "ä»ä¼ æ’­å™¨åˆ°æŒ¯è¡å™¨ï¼šå¯¹ç§°å¾®åˆ†æ–¹ç¨‹åœ¨ç¥ç»ç³»ç»Ÿä¸­çš„åŒé‡è§’è‰²",
      "authors": [
        "Kun Jiang"
      ],
      "abstract": "In our previous work, we proposed a novel neuron model based on symmetric differential equations and demonstrated its potential as an efficient signal propagator. Building upon that foundation, the present study delves deeper into the intrinsic dynamics and functional diversity of this model. By systematically exploring the parameter space and employing a range of mathematical analysis tools, we theoretically reveal the system 's core property of functional duality. Specifically, the model exhibits two distinct trajectory behaviors: one is asymptotically stable, corresponding to a reliable signal propagator; the other is Lyapunov stable, characterized by sustained self-excited oscillations, functioning as a signal generator. To enable effective monitoring and prediction of system states during simulations, we introduce a novel intermediate-state metric termed on-road energy. Simulation results confirm that transitions between the two functional modes can be induced through parameter adjustments or modifications to the connection structure. Moreover, we show that oscillations can be effectively suppressed by introducing external signals. These findings draw a compelling parallel to the dual roles of biological neurons in both information transmission and rhythm generation, thereby establishing a solid theoretical basis and a clear functional roadmap for the broader application of this model in neuromorphic engineering.",
      "tldr_zh": "è¯¥ç ”ç©¶åŸºäºå¯¹ç§°å¾®åˆ†æ–¹ç¨‹ (symmetric differential equations) æå‡ºäº†ä¸€ç§ç¥ç»å…ƒæ¨¡å‹ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†å…¶åœ¨ç¥ç»ç³»ç»Ÿä¸­çš„å†…åœ¨åŠ¨åŠ›å­¦å’ŒåŠŸèƒ½å¤šæ ·æ€§ã€‚é€šè¿‡å¯¹å‚æ•°ç©ºé—´è¿›è¡Œç³»ç»Ÿæ¢ç´¢å’Œæ•°å­¦åˆ†æï¼Œç ”ç©¶ä»ç†è®ºä¸Šæ­ç¤ºäº†è¯¥ç³»ç»Ÿå…·å¤‡çš„åŠŸèƒ½åŒé‡æ€§ (functional duality)ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿè¡¨ç°å‡ºä¸¤ç§æˆªç„¶ä¸åŒçš„è½¨è¿¹è¡Œä¸ºï¼šä¸€ç§æ˜¯æ¸è¿‘ç¨³å®š (asymptotically stable) çš„å¯é ä¿¡å·ä¼ æ’­å™¨ (propagator)ï¼Œå¦ä¸€ç§åˆ™æ˜¯è¡¨ç°ä¸ºæŒç»­è‡ªæ¿€æŒ¯è¡çš„ Lyapunov ç¨³å®š (Lyapunov stable) ä¿¡å·å‘ç”Ÿå™¨ (oscillator)ã€‚ä¸ºäº†åœ¨æ¨¡æ‹Ÿä¸­æœ‰æ•ˆç›‘æµ‹ç³»ç»ŸçŠ¶æ€ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†åä¸ºâ€œåœ¨è·¯èƒ½é‡â€ (on-road energy) çš„æ–°å‹ä¸­é—´æ€æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡è°ƒèŠ‚å‚æ•°ã€æ”¹å˜è¿æ¥ç»“æ„æˆ–å¼•å…¥å¤–éƒ¨ä¿¡å·ï¼Œå¯ä»¥å®ç°ä¸¤ç§æ¨¡å¼çš„è½¬æ¢æˆ–æŒ¯è¡æŠ‘åˆ¶ã€‚è¿™äº›å‘ç°æˆåŠŸç±»æ¯”äº†ç”Ÿç‰©ç¥ç»å…ƒåœ¨ä¿¡æ¯ä¼ è¾“ä¸èŠ‚å¾‹äº§ç”Ÿä¸­çš„åŒé‡è§’è‰²ï¼Œä¸ºè¯¥æ¨¡å‹åœ¨ç¥ç»å½¢æ€å·¥ç¨‹ (neuromorphic engineering) é¢†åŸŸçš„åº”ç”¨æä¾›äº†æ˜ç¡®çš„ç†è®ºè·¯çº¿å›¾ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "20 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.22916v1",
      "published_date": "2025-07-20 15:34:47 UTC",
      "updated_date": "2025-07-20 15:34:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:24.194613+00:00"
    },
    {
      "arxiv_id": "2507.22915v1",
      "title": "Theoretical Foundations and Mitigation of Hallucination in Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹å¹»è§‰çš„ç†è®ºåŸºç¡€ä¸ç¼“è§£",
      "authors": [
        "Esmail Gumaan"
      ],
      "abstract": "Hallucination in Large Language Models (LLMs) refers to the generation of content that is not faithful to the input or the real-world facts. This paper provides a rigorous treatment of hallucination in LLMs, including formal definitions and theoretical analyses. We distinguish between intrinsic and extrinsic hallucinations, and define a \\textit{hallucination risk} for models. We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes and Rademacher complexity). We then survey detection strategies for hallucinations, such as token-level uncertainty estimation, confidence calibration, and attention alignment checks. On the mitigation side, we discuss approaches including retrieval-augmented generation, hallucination-aware fine-tuning, logit calibration, and the incorporation of fact-verification modules. We propose a unified detection and mitigation workflow, illustrated with a diagram, to integrate these strategies. Finally, we outline evaluation protocols for hallucination, recommending datasets, metrics, and experimental setups to quantify and reduce hallucinations. Our work lays a theoretical foundation and practical guidelines for addressing the crucial challenge of hallucination in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)ä¸­çš„å¹»è§‰(Hallucination)é—®é¢˜æä¾›äº†ä¸¥è°¨çš„ç†è®ºåˆ†æï¼Œæ˜ç¡®åŒºåˆ†äº†å†…åœ¨å¹»è§‰(intrinsic)ä¸å¤–åœ¨å¹»è§‰(extrinsic)å¹¶å®šä¹‰äº†å¹»è§‰é£é™©(hallucination risk)ã€‚ç ”ç©¶åˆ©ç”¨PAC-Bayeså’ŒRademacher complexityç­‰å­¦ä¹ ç†è®ºæ¡†æ¶æ¨å¯¼äº†å¹»è§‰é£é™©çš„ç•Œé™ï¼Œä»ç†è®ºå±‚é¢é‡åŒ–äº†è¿™ä¸€æŒ‘æˆ˜ã€‚åœ¨æ£€æµ‹ä¸ç¼“è§£æ–¹é¢ï¼Œè®ºæ–‡è°ƒç ”äº†æ ‡è®°çº§ä¸ç¡®å®šæ€§ä¼°è®¡(token-level uncertainty estimation)ã€æ³¨æ„åŠ›å¯¹é½æ£€æŸ¥(attention alignment checks)ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ä»¥åŠäº‹å®æ ¸æŸ¥æ¨¡å—ç­‰å¤šç§å‰æ²¿æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œä½œè€…æå‡ºäº†ä¸€å¥—æ•´åˆä¸Šè¿°ç­–ç•¥çš„ç»Ÿä¸€æ£€æµ‹ä¸ç¼“è§£å·¥ä½œæµï¼Œå¹¶åˆ¶å®šäº†è¯¦ç»†çš„è¯„ä¼°åè®®ã€æ•°æ®é›†å’Œåº¦é‡æŒ‡æ ‡ã€‚è¯¥å·¥ä½œä¸ä»…ä¸ºç†è§£LLMså¹»è§‰å»ºç«‹äº†ç†è®ºåŸºç¡€ï¼Œä¹Ÿä¸ºå®é™…åº”ç”¨ä¸­çš„é£é™©è§„é¿æä¾›äº†ç³»ç»Ÿæ€§çš„å®è·µæŒ‡å—ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.22915v1",
      "published_date": "2025-07-20 15:22:34 UTC",
      "updated_date": "2025-07-20 15:22:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:29.288376+00:00"
    },
    {
      "arxiv_id": "2507.15003v1",
      "title": "The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering",
      "title_zh": "è½¯ä»¶å·¥ç¨‹ (SE) 3.0 ä¸­ AI é˜Ÿå‹çš„å…´èµ·ï¼šè‡ªä¸»ç¼–ç¨‹æ™ºèƒ½ä½“å¦‚ä½•é‡å¡‘è½¯ä»¶å·¥ç¨‹",
      "authors": [
        "Hao Li",
        "Haoxiang Zhang",
        "Ahmed E. Hassan"
      ],
      "abstract": "The future of software engineering--SE 3.0--is unfolding with the rise of AI teammates: autonomous, goal-driven systems collaborating with human developers. Among these, autonomous coding agents are especially transformative, now actively initiating, reviewing, and evolving code at scale. This paper introduces AIDev, the first large-scale dataset capturing how such agents operate in the wild. Spanning over 456,000 pull requests by five leading agents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across 61,000 repositories and 47,000 developers, AIDev provides an unprecedented empirical foundation for studying autonomous teammates in software development.\n  Unlike prior work that has largely theorized the rise of AI-native software engineering, AIDev offers structured, open data to support research in benchmarking, agent readiness, optimization, collaboration modeling, and AI governance. The dataset includes rich metadata on PRs, authorship, review timelines, code changes, and integration outcomes--enabling exploration beyond synthetic benchmarks like SWE-bench. For instance, although agents often outperform humans in speed, their PRs are accepted less frequently, revealing a trust and utility gap. Furthermore, while agents accelerate code submission--one developer submitted as many PRs in three days as they had in three years--these are structurally simpler (via code complexity metrics).\n  We envision AIDev as a living resource: extensible, analyzable, and ready for the SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev enables a new generation of research into AI-native workflows and supports building the next wave of symbiotic human-AI collaboration. The dataset is publicly available at https://github.com/SAILResearch/AI_Teammates_in_SE3.\n  > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering Agent",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è½¯ä»¶å·¥ç¨‹ 3.0 (SE 3.0) æ—¶ä»£ä¸‹ AI Teammates çš„å…´èµ·ï¼Œå¹¶æ¨å‡ºäº†é¦–ä¸ªå¤§è§„æ¨¡å®è¯æ•°æ®é›† AIDevï¼Œç”¨äºè¿½è¸ªè‡ªä¸»ç¼–ç æ™ºèƒ½ä½“ (Autonomous Coding Agents) åœ¨çœŸå®å¼€å‘ç¯å¢ƒä¸­çš„è¡Œä¸ºã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†æ¥è‡ª OpenAI Codexã€Devinã€GitHub Copilotã€Cursor å’Œ Claude Code äº”å¤§é¢†å…ˆæ™ºèƒ½ä½“çš„ 45.6 ä¸‡ä½™ä¸ªæ‹‰å–è¯·æ±‚ (Pull Requests)ï¼Œæ¶‰åŠ 6.1 ä¸‡ä¸ªä»£ç ä»“åº“ã€‚AIDev æä¾›äº†ä¸°å¯Œçš„å…ƒæ•°æ®ï¼Œæ”¯æŒå¯¹æ™ºèƒ½ä½“å°±ç»ªåº¦ã€åä½œå»ºæ¨¡åŠ AI Governance ç­‰å…³é”®é¢†åŸŸè¿›è¡Œæ·±å…¥åˆ†æï¼Œå¼¥è¡¥äº†ä»¥å¾€ç ”ç©¶ç¼ºä¹å®è¯æ•°æ®çš„ä¸è¶³ã€‚åˆæ­¥ç ”ç©¶å‘ç°ï¼Œå°½ç®¡ Autonomous Coding Agents åœ¨ä»£ç ç”Ÿæˆé€Ÿåº¦ä¸Šæ˜¾è‘—ä¼˜äºäººç±»ï¼Œä½†å…¶ PR æ¥å—ç‡è¾ƒä½ä¸”ä»£ç ç»“æ„ç›¸å¯¹ç®€å•ï¼Œæ­ç¤ºäº†å½“å‰çš„ä¿¡ä»»ä¸å®ç”¨æ€§å·®è·ã€‚ä½œä¸ºä¸€é¡¹å¼€æºèµ„æºï¼ŒAIDev ä¸ºæ¢ç´¢ AI-native è½¯ä»¶å·¥ç¨‹å·¥ä½œæµå¥ å®šäº†åŸºç¡€ï¼Œæ—¨åœ¨æ¨åŠ¨ä¸‹ä¸€ä»£äººç±»ä¸ AI çš„å…±ç”Ÿåä½œã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15003v1",
      "published_date": "2025-07-20 15:15:58 UTC",
      "updated_date": "2025-07-20 15:15:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:31.687138+00:00"
    },
    {
      "arxiv_id": "2507.14987v1",
      "title": "AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning",
      "title_zh": "AlphaAlignï¼šé€šè¿‡æç®€å¼ºåŒ–å­¦ä¹ æ¿€åŠ±å®‰å…¨å¯¹é½",
      "authors": [
        "Yi Zhang",
        "An Zhang",
        "XiuYu Zhang",
        "Leheng Sheng",
        "Yuxin Chen",
        "Zhenkai Liang",
        "Xiang Wang"
      ],
      "abstract": "Large language models (LLMs), despite possessing latent safety understanding from their vast pretraining data, remain vulnerable to generating harmful content and exhibit issues such as over-refusal and utility degradation after safety alignment. Current safety alignment methods often result in superficial refusal shortcuts or rely on intensive supervision for reasoning-based approaches, failing to fully leverage the model's intrinsic safety self-awareness. We propose \\textbf{AlphaAlign}, a simple yet effective pure reinforcement learning (RL) framework with verifiable safety reward designed to incentivize this latent safety awareness through proactive safety reasoning.} AlphaAlign employs a dual-reward system: a verifiable safety reward encourages correctly formatted and explicitly justified refusals for harmful queries while penalizing over-refusals, and a normalized helpfulness reward guides high-quality responses to benign inputs. This allows the model to develop proactive safety reasoning capabilities without depending on supervised safety-specific reasoning data. AlphaAlign demonstrates three key advantages: (1) Simplicity and efficiency, requiring only binary prompt safety labels and minimal RL steps for substantial improvements. (2) Breaking the safety-utility trade-off, by enhancing refusal of harmful content and reducing over-refusals, while simultaneously maintaining or even improving general task performance and robustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety reasoning that generates explicit safety rationales rather than relying on shallow refusal patterns.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†AlphaAlignï¼Œè¿™æ˜¯ä¸€ç§æå…¶ç®€åŒ–çš„çº¯å¼ºåŒ–å­¦ä¹ (RL)æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ä¸»åŠ¨å®‰å…¨æ¨ç†æ¿€å‘å¤§è¯­è¨€æ¨¡å‹(LLMs)æ½œåœ¨çš„å®‰å…¨è‡ªæˆ‘æ„è¯†ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŒé‡å¥–åŠ±ç³»ç»Ÿï¼Œåˆ©ç”¨å¯éªŒè¯çš„å®‰å…¨å¥–åŠ±æ¥é¼“åŠ±æ˜¾å¼ä¸”åˆç†çš„æ‹’ç»å¹¶æƒ©ç½šè¿‡åº¦æ‹’ç»(over-refusal)ï¼ŒåŒæ—¶é€šè¿‡å½’ä¸€åŒ–çš„å¸®åŠ©æ€§å¥–åŠ±å¼•å¯¼æ¨¡å‹å¯¹è‰¯æ€§è¾“å…¥ç”Ÿæˆé«˜è´¨é‡å“åº”ã€‚AlphaAlignæ— éœ€ä¾èµ–ç›‘ç£å¼çš„å®‰å…¨æ¨ç†æ•°æ®ï¼Œä»…éœ€äºŒå…ƒå®‰å…¨æ ‡ç­¾å’Œå°‘é‡çš„RLæ­¥éª¤å³å¯å®ç°æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæ‰“ç ´äº†å®‰å…¨ä¸æ•ˆç”¨(utility)ä¹‹é—´çš„æƒè¡¡ï¼Œåœ¨å¢å¼ºå¯¹æœªçŸ¥è¶Šç‹±æ”»å‡»(jailbreaks)é²æ£’æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†è¿‡åº¦æ‹’ç»å¹¶ä¿æŒæˆ–æå‡äº†é€šç”¨ä»»åŠ¡è¡¨ç°ã€‚è¿™ç§æ·±åº¦å¯¹é½ä¿ƒä½¿æ¨¡å‹ç”Ÿæˆæ˜¾å¼çš„å®‰å…¨ç†ç”±ï¼Œè€Œéä»…ä»…ä¾èµ–è‚¤æµ…çš„æ‹’ç»æ¨¡å¼ï¼Œä¸ºå®ç°å¯è§£é‡Šä¸”é«˜æ•ˆçš„æ¨¡å‹å®‰å…¨å¯¹é½æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14987v1",
      "published_date": "2025-07-20 14:47:03 UTC",
      "updated_date": "2025-07-20 14:47:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:33.396096+00:00"
    },
    {
      "arxiv_id": "2507.15894v1",
      "title": "Systole-Conditioned Generative Cardiac Motion",
      "title_zh": "æ”¶ç¼©æœŸæ¡ä»¶ä¸‹çš„ç”Ÿæˆå¼å¿ƒè„è¿åŠ¨",
      "authors": [
        "Shahar Zuler",
        "Gal Lifshitz",
        "Hadar Averbuch-Elor",
        "Dan Raviv"
      ],
      "abstract": "Accurate motion estimation in cardiac computed tomography (CT) imaging is critical for assessing cardiac function and surgical planning. Data-driven methods have become the standard approach for dense motion estimation, but they rely on vast amounts of labeled data with dense ground-truth (GT) motion annotations, which are often unfeasible to obtain. To address this limitation, we present a novel approach that synthesizes realistically looking pairs of cardiac CT frames enriched with dense 3D flow field annotations.\n  Our method leverages a conditional Variational Autoencoder (CVAE), which incorporates a novel multi-scale feature conditioning mechanism and is trained to generate 3D flow fields conditioned on a single CT frame. By applying the generated flow field to warp the given frame, we create pairs of frames that simulate realistic myocardium deformations across the cardiac cycle. These pairs serve as fully annotated data samples, providing optical flow GT annotations. Our data generation pipeline could enable the training and validation of more complex and accurate myocardium motion models, allowing for substantially reducing reliance on manual annotations.\n  Our code, along with animated generated samples and additional material, is available on our project page: https://shaharzuler.github.io/GenerativeCardiacMotion_Page.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¿ƒè„è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰æˆåƒä¸­è¿åŠ¨ä¼°è®¡ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ä¸”è·å–å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤Ÿåˆæˆå¸¦æœ‰å¯†é›† 3D flow field æ ‡æ³¨çš„çœŸå®å¿ƒè„ CT å›¾åƒå¯¹çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆCVAEï¼‰å¹¶ç»“åˆäº†åˆ›æ–°çš„å¤šå°ºåº¦ç‰¹å¾è°ƒèŠ‚æœºåˆ¶ï¼Œé€šè¿‡åœ¨å•å¸§ CT å›¾åƒä¸Šç”Ÿæˆ 3D flow fields æ¥æ¨¡æ‹Ÿå¿ƒè„å‘¨æœŸå†…çœŸå®çš„ myocardium å˜å½¢ã€‚é€šè¿‡å°†ç”Ÿæˆçš„æµåœºåº”ç”¨äºåŸå§‹å›¾åƒå¸§è¿›è¡Œå˜å½¢å¤„ç†ï¼Œç ”ç©¶è€…æˆåŠŸåˆ›å»ºäº†å¸¦æœ‰ optical flow GT æ ‡æ³¨çš„å®Œæ•´æ•°æ®æ ·æœ¬ã€‚è¿™ä¸€æ•°æ®ç”Ÿæˆæµç¨‹èƒ½å¤Ÿæ”¯æŒæ›´å¤æ‚ã€æ›´å‡†ç¡®çš„ myocardium è¿åŠ¨æ¨¡å‹çš„è®­ç»ƒä¸éªŒè¯ï¼Œæ˜¾è‘—é™ä½äº†å¯¹äººå·¥æ‰‹åŠ¨æ ‡æ³¨çš„ä¾èµ–ã€‚è¯¥ç ”ç©¶é€šè¿‡åˆæˆé«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ï¼Œä¸ºæå‡å¿ƒè„åŠŸèƒ½è¯„ä¼°å’Œæ‰‹æœ¯è§„åˆ’çš„æ•ˆç‡æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15894v1",
      "published_date": "2025-07-20 14:44:40 UTC",
      "updated_date": "2025-07-20 14:44:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:48.391820+00:00"
    },
    {
      "arxiv_id": "2507.14975v2",
      "title": "FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models",
      "title_zh": "FCRFï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é•¿ç¨‹æœºå™¨äººä»»åŠ¡è§„åˆ’çµæ´»å»ºæ„ä¸»ä¹‰åæ€",
      "authors": [
        "Yufan Song",
        "Jiatao Zhang",
        "Zeng Gu",
        "Qingmiao Liang",
        "Tuocheng Hu",
        "Wei Song",
        "Shiqiang Zhu"
      ],
      "abstract": "Autonomous error correction is critical for domestic robots to achieve reliable execution of complex long-horizon tasks. Prior work has explored self-reflection in Large Language Models (LLMs) for task planning error correction; however, existing methods are constrained by inflexible self-reflection mechanisms that limit their effectiveness. Motivated by these limitations and inspired by human cognitive adaptation, we propose the Flexible Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture that enables LLMs to perform flexible self-reflection based on task difficulty, while constructively integrating historical valuable experience with failure lessons. We evaluated FCRF on diverse domestic tasks through simulation in AlfWorld and physical deployment in the real-world environment. Experimental results demonstrate that FCRF significantly improves overall performance and self-reflection flexibility in complex long-horizon robotic tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®¶åŠ¡æœºå™¨äººåœ¨æ‰§è¡Œå¤æ‚é•¿ç¨‹ä»»åŠ¡(long-horizon tasks)æ—¶é¢ä¸´çš„è‡ªä¸»é”™è¯¯çº æ­£æŒ‘æˆ˜ï¼Œæå‡ºäº† Flexible Constructivism Reflection Framework (FCRF)ã€‚é’ˆå¯¹ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è‡ªåæ€æœºåˆ¶çµæ´»æ€§ä¸è¶³çš„å±€é™æ€§ï¼ŒFCRF é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„ Mentor-Actor æ¶æ„ï¼Œå…è®¸æœºå™¨äººæ ¹æ®ä»»åŠ¡éš¾åº¦è¿›è¡Œçµæ´»çš„è‡ªåæ€ã€‚è¯¥æ¡†æ¶é€šè¿‡å»ºè®¾æ€§åœ°æ•´åˆå†å²ä»·å€¼ç»éªŒä¸å¤±è´¥æ•™è®­ï¼Œæ¨¡æ‹Ÿäº†äººç±»çš„è®¤çŸ¥é€‚åº”èƒ½åŠ›ã€‚å®éªŒåœ¨ AlfWorld æ¨¡æ‹Ÿç¯å¢ƒä»¥åŠçœŸå®ç‰©ç†åœºæ™¯ä¸­è¿›è¡Œäº†éªŒè¯ï¼Œç»“æœè¡¨æ˜ FCRF æ˜¾è‘—æé«˜äº†æœºå™¨äººåœ¨å¤„ç†å¤æ‚é•¿ç¨‹ä»»åŠ¡æ—¶çš„æ•´ä½“æ€§èƒ½å’Œè‡ªåæ€çµæ´»æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, IROS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.14975v2",
      "published_date": "2025-07-20 14:15:39 UTC",
      "updated_date": "2025-09-16 07:14:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:49.853715+00:00"
    },
    {
      "arxiv_id": "2507.14962v1",
      "title": "Complexity of Faceted Explanations in Propositional Abduction",
      "title_zh": "å‘½é¢˜æº¯å› ä¸­åˆ»é¢è§£é‡Šçš„å¤æ‚æ€§",
      "authors": [
        "Johannes Schmidt",
        "Mohamed Maizia",
        "Victor Lagerkvist",
        "Johannes K. Fichte"
      ],
      "abstract": "Abductive reasoning is a popular non-monotonic paradigm that aims to explain observed symptoms and manifestations. It has many applications, such as diagnosis and planning in artificial intelligence and database updates. In propositional abduction, we focus on specifying knowledge by a propositional formula. The computational complexity of tasks in propositional abduction has been systematically characterized - even with detailed classifications for Boolean fragments. Unsurprisingly, the most insightful reasoning problems (counting and enumeration) are computationally highly challenging. Therefore, we consider reasoning between decisions and counting, allowing us to understand explanations better while maintaining favorable complexity. We introduce facets to propositional abductions, which are literals that occur in some explanation (relevant) but not all explanations (dispensable). Reasoning with facets provides a more fine-grained understanding of variability in explanations (heterogeneous). In addition, we consider the distance between two explanations, enabling a better understanding of heterogeneity/homogeneity. We comprehensively analyze facets of propositional abduction in various settings, including an almost complete characterization in Post's framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å‘½é¢˜å½’çº³æ¨ç† (propositional abduction) ä¸­çš„è§£é‡Šå¤æ‚æ€§é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³è¯¥é¢†åŸŸä¸­è®¡æ•°å’Œæšä¸¾ä»»åŠ¡å¸¦æ¥çš„è®¡ç®—æŒ‘æˆ˜ã€‚ä¸ºäº†æ›´æ·±å…¥åœ°ç†è§£è§£é‡Šçš„å¤šæ ·æ€§ï¼Œä½œè€…å¼•å…¥äº†é¢ (facets) çš„æ¦‚å¿µï¼Œå³å‡ºç°åœ¨éƒ¨åˆ†è§£é‡Šä¸­ï¼ˆç›¸å…³ï¼‰ä½†å¹¶éå‡ºç°åœ¨æ‰€æœ‰è§£é‡Šä¸­ï¼ˆå¯çœï¼‰çš„æ–‡å­— (literals)ã€‚é€šè¿‡å¯¹é¢è¿›è¡Œæ¨ç†ï¼Œè¯¥ç ”ç©¶æä¾›äº†ä¸€ç§æ›´ç»†è‡´çš„æ–¹æ³•æ¥ç†è§£è§£é‡Šä¹‹é—´çš„å¼‚è´¨æ€§ (heterogeneous) å’ŒåŒè´¨æ€§ (homogeneity)ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è€ƒè™‘äº†ä¸¤ä¸ªè§£é‡Šä¹‹é—´çš„è·ç¦»ï¼Œä»¥ä¾¿æ›´å¥½åœ°è¡¡é‡å…¶å·®å¼‚æ€§ã€‚è¯¥ç ”ç©¶å¯¹å„ç§è®¾ç½®ä¸‹çš„å‘½é¢˜å½’çº³é¢è¿›è¡Œäº†å…¨é¢çš„å¤æ‚æ€§åˆ†æï¼Œå¹¶åœ¨ Post's framework ä¸‹ç»™å‡ºäº†å‡ ä¹å®Œæ•´çš„è¡¨å¾ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å¼•å…¥é¢çš„ç»´åº¦ï¼Œåœ¨ç»´æŒæœ‰åˆ©çš„è®¡ç®—å¤æ‚åº¦çš„åŒæ—¶ï¼Œä¸ºç†è§£å‘½é¢˜å½’çº³ä¸­çš„è§£é‡Šå˜å¼‚æ€§æä¾›äº†æ–°çš„ç†è®ºè§†è§’ã€‚",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "This is the author's self-archived copy including detailed proofs. To appear in Theory and Practice of Logic Programming (TPLP), Proceedings of the 41st International Conference on Logic Programming (ICLP 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.14962v1",
      "published_date": "2025-07-20 13:50:26 UTC",
      "updated_date": "2025-07-20 13:50:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:47:50.947679+00:00"
    },
    {
      "arxiv_id": "2507.14960v1",
      "title": "A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books",
      "title_zh": "æ¯”ç‰¹å¸é™ä»·è®¢å•ç°¿ç¦»ç¾¤å€¼æ£€æµ‹ä¸­ç»Ÿè®¡æ¨¡å‹ä¸æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯¹æ¯”åˆ†æ",
      "authors": [
        "Ivan Letteri"
      ],
      "abstract": "The detection of outliers within cryptocurrency limit order books (LOBs) is of paramount importance for comprehending market dynamics, particularly in highly volatile and nascent regulatory environments. This study conducts a comprehensive comparative analysis of robust statistical methods and advanced machine learning techniques for real-time anomaly identification in cryptocurrency LOBs. Within a unified testing environment, named AITA Order Book Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to identify which approaches are most suitable for detecting potentially manipulative trading behaviours. An empirical evaluation, conducted via backtesting on a dataset of 26,204 records from a major exchange, demonstrates that the top-performing model, Empirical Covariance (EC), achieves a 6.70% gain, significantly outperforming a standard Buy-and-Hold benchmark. These findings underscore the effectiveness of outlier-driven strategies and provide insights into the trade-offs between model complexity, trade frequency, and performance. This study contributes to the growing corpus of research on cryptocurrency market microstructure by furnishing a rigorous benchmark of anomaly detection models and highlighting their potential for augmenting algorithmic trading and risk management.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ å¯†è´§å¸é™ä»·è®¢å•ç°¿(Limit Order Books, LOBs)çš„å¼‚å¸¸æ£€æµ‹è¿›è¡Œäº†æ·±å…¥å¯¹æ¯”åˆ†æï¼Œæ—¨åœ¨é«˜æ³¢åŠ¨æ€§å’Œæ–°å…´ç›‘ç®¡ç¯å¢ƒä¸‹è¯†åˆ«æ½œåœ¨çš„æ“çºµæ€§äº¤æ˜“è¡Œä¸ºã€‚åœ¨ç»Ÿä¸€çš„æµ‹è¯•ç¯å¢ƒ AITA Order Book Signal (AITA-OBS) ä¸­ï¼Œç ”ç©¶è€…è¯„ä¼°äº†åŒ…å«ç¨³å¥ç»Ÿè®¡æ–¹æ³•å’Œå…ˆè¿›æœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨å†…çš„ 13 ç§æ¨¡å‹ã€‚å®éªŒåŸºäºæ¥è‡ªä¸»è¦äº¤æ˜“æ‰€çš„ 26,204 æ¡è®°å½•è¿›è¡Œäº†å›æµ‹è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºè¡¨ç°æœ€ä½³çš„ Empirical Covariance (EC) æ¨¡å‹å®ç°äº† 6.70% çš„æ”¶ç›Šç‡ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ Buy-and-Hold åŸºå‡†ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†æ¨¡å‹å¤æ‚æ€§ã€äº¤æ˜“é¢‘ç‡ä¸æ€§èƒ½ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶ä¸ºåŠ å¯†è´§å¸å¸‚åœºå¾®è§‚ç»“æ„ç ”ç©¶æä¾›äº†ä¸¥è°¨çš„å¼‚å¸¸æ£€æµ‹åŸºå‡†ã€‚è¿™äº›å‘ç°ä¸ä»…ä¸ºç†è§£å¸‚åœºåŠ¨æ€æä¾›äº†æ–°è§†è§’ï¼Œä¹Ÿå¼ºè°ƒäº†å¼‚å¸¸é©±åŠ¨ç­–ç•¥åœ¨æå‡ç®—æ³•äº¤æ˜“å’Œé£é™©ç®¡ç†æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "q-fin.TR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14960v1",
      "published_date": "2025-07-20 13:42:36 UTC",
      "updated_date": "2025-07-20 13:42:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:11.186990+00:00"
    },
    {
      "arxiv_id": "2507.14957v2",
      "title": "Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division",
      "title_zh": "åŸºäº PMMS æ¢ç©¶ EFXï¼šç¦»æ•£å…¬å¹³åˆ†é…ä¸­çš„å­˜åœ¨æ€§ä¸éå­˜åœ¨æ€§ç»“è®º",
      "authors": [
        "JarosÅ‚aw Byrka",
        "Franciszek Malinka",
        "Tomasz Ponitka"
      ],
      "abstract": "We study the fair division of indivisible items and provide new insights into the EFX problem, which is widely regarded as the central open question in fair division, and the PMMS problem, a strictly stronger variant of EFX. Our first result constructs a three-agent instance with two monotone valuations and one additive valuation in which no PMMS allocation exists. Since EFX allocations are known to exist under these assumptions, this establishes a formal separation between EFX and PMMS.\n  We prove existence of fair allocations for three important special cases. We show that EFX allocations exist for personalized bivalued valuations, where for each agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value $v_i(\\{g\\}) \\in \\{a_i, b_i\\}$ to each good $g$. We establish an analogous existence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also prove that PMMS allocations exist for binary-valued MMS-feasible valuations, where each bundle $S$ has value $v_i(S) \\in \\{0, 1\\}$. Notably, this result holds even without assuming monotonicity of valuations and thus applies to the fair division of chores and mixed manna. Finally, we study a class of valuations called pair-demand valuations, which extend the well-studied unit-demand valuations to the case where each agent derives value from at most two items, and we show that PMMS allocations exist in this setting. Our proofs are constructive, and we provide polynomial-time algorithms for all three existence results.",
      "tldr_zh": "æœ¬ç ”ç©¶æ·±å…¥æ¢è®¨äº†ä¸å¯åˆ†ç‰©å“å…¬å¹³åˆ†é…(Discrete Fair Division)ä¸­çš„ EFX é—®é¢˜åŠå…¶å¢å¼ºå˜ä½“ PMMSã€‚è¯¥è®ºæ–‡é¦–å…ˆé€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå•è°ƒä¼°å€¼(monotone valuations)å’Œä¸€ä¸ªåŠ æ€§ä¼°å€¼(additive valuation)çš„ä¸‰ä»£ç†å®ä¾‹ï¼Œè¯æ˜äº† PMMS åˆ†é…å¯èƒ½ä¸å­˜åœ¨ï¼Œä»è€Œåœ¨ EFX å’Œ PMMS ä¹‹é—´å»ºç«‹äº†æ­£å¼çš„åŒºåˆ†ã€‚é’ˆå¯¹ç‰¹å®šæƒ…å½¢ï¼Œç ”ç©¶è¯æ˜äº†åœ¨ä¸ªæ€§åŒ–äºŒå€¼ä¼°å€¼(personalized bivalued valuations)ä¸‹ EFX åˆ†é…å§‹ç»ˆå­˜åœ¨ï¼Œä¸”å½“ä¼°å€¼æ¯”ä¾‹æ»¡è¶³æ•´é™¤å…³ç³»æ—¶ PMMS åˆ†é…ä¹Ÿå­˜åœ¨ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¯å®äº† PMMS åˆ†é…åœ¨ binary-valued MMS-feasible ä¼°å€¼ä¸‹ä¾ç„¶å­˜åœ¨ï¼Œä¸”è¯¥ç»“æœé€‚ç”¨äº chores å’Œ mixed manna ç­‰éå•è°ƒä¼°å€¼åœºæ™¯ã€‚æœ€åï¼Œç ”ç©¶è¡¨æ˜ PMMS åˆ†é…åœ¨ pair-demand valuations æƒ…å½¢ä¸‹åŒæ ·å­˜åœ¨ã€‚æ‰€æœ‰è¯æ˜å‡ä¸ºæ„é€ æ€§çš„ï¼Œå¹¶é…å¤‡äº†ç›¸åº”çš„å¤šé¡¹å¼æ—¶é—´ç®—æ³•(polynomial-time algorithms)ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.GT",
      "comment": "27 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.14957v2",
      "published_date": "2025-07-20 13:32:12 UTC",
      "updated_date": "2025-07-30 16:51:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:18.293051+00:00"
    },
    {
      "arxiv_id": "2507.14928v1",
      "title": "Byzantine-Robust Decentralized Coordination of LLM Agents",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“çš„æ‹œå åº­é²æ£’å»ä¸­å¿ƒåŒ–ååŒ",
      "authors": [
        "Yongrae Jo",
        "Chanik Park"
      ],
      "abstract": "Collaboration among multiple large language model (LLM) agents is a promising approach to overcome inherent limitations of single-agent systems, such as hallucinations and single points of failure. As LLM agents are increasingly deployed on open blockchain platforms, multi-agent systems capable of tolerating malicious (Byzantine) agents have become essential.\n  Recent Byzantine-robust multi-agent systems typically rely on leader-driven coordination, which suffers from two major drawbacks. First, they are inherently vulnerable to targeted attacks against the leader. If consecutive leaders behave maliciously, the system repeatedly fails to achieve consensus, forcing new consensus rounds, which is particularly costly given the high latency of LLM invocations. Second, an underperforming proposal from the leader can be accepted as the final answer even when higher-quality alternatives are available, as existing methods finalize the leader's proposal once it receives a quorum of votes.\n  To address these issues, we propose DecentLLMs, a novel decentralized consensus approach for multi-agent LLM systems, where worker agents generate answers concurrently and evaluator agents independently score and rank these answers to select the best available one. This decentralized architecture enables faster consensus despite the presence of Byzantine agents and consistently selects higher-quality answers through Byzantine-robust aggregation techniques.\n  Experimental results demonstrate that DecentLLMs effectively tolerates Byzantine agents and significantly improves the quality of selected answers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨å¼€æ”¾åŒºå—é“¾å¹³å°éƒ¨ç½²æ—¶é¢ä¸´çš„æ‹œå åº­(Byzantine)å®¹é”™æŒ‘æˆ˜ï¼Œæå‡ºäº†DecentLLMså»ä¸­å¿ƒåŒ–åä½œæ¡†æ¶ã€‚ç°æœ‰çš„æ‹œå åº­é²æ£’(Byzantine-robust)å¤šæ™ºèƒ½ä½“ç³»ç»Ÿé€šå¸¸ä¾èµ–ä¸»èŠ‚ç‚¹é©±åŠ¨(leader-driven)çš„åè°ƒæœºåˆ¶ï¼Œå­˜åœ¨æ˜“å—é’ˆå¯¹æ€§æ”»å‡»åŠåœ¨ä¸»èŠ‚ç‚¹è¡¨ç°ä¸ä½³æ—¶äº§ç”Ÿæ¬¡ä¼˜ç»“æœçš„ç¼ºé™·ã€‚DecentLLMsé€šè¿‡å»ä¸­å¿ƒåŒ–çš„å…±è¯†æ–¹æ³•ï¼Œè®©å·¥ä½œæ™ºèƒ½ä½“(worker agents)å¹¶å‘ç”Ÿæˆç­”æ¡ˆï¼Œå¹¶ç”±è¯„ä¼°æ™ºèƒ½ä½“(evaluator agents)ç‹¬ç«‹è¿›è¡Œè¯„åˆ†å’Œæ’åºã€‚è¯¥æ¡†æ¶ç»“åˆäº†æ‹œå åº­é²æ£’èšåˆ(Byzantine-robust aggregation)æŠ€æœ¯ï¼Œåœ¨å­˜åœ¨æ¶æ„æ™ºèƒ½ä½“çš„æƒ…å†µä¸‹èƒ½å¤Ÿæ›´å¿«è¾¾æˆå…±è¯†ï¼Œå¹¶æŒç»­ç­›é€‰å‡ºæ›´é«˜è´¨é‡çš„è¾“å‡ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDecentLLMsèƒ½æœ‰æ•ˆå®¹å¿æ‹œå åº­èŠ‚ç‚¹ï¼Œæ˜¾è‘—æå‡äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¯é æ€§ä¸æœ€ç»ˆå†³ç­–çš„è´¨é‡ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14928v1",
      "published_date": "2025-07-20 11:55:26 UTC",
      "updated_date": "2025-07-20 11:55:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:15.042787+00:00"
    },
    {
      "arxiv_id": "2507.14914v1",
      "title": "One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner",
      "title_zh": "One Step Beyondï¼šæ„ŸçŸ¥ç©¿é€ä¸å¸ƒå±€çš„æ­£äº¤å¤šè¾¹å½¢å¸ƒå±€è§„åˆ’å™¨",
      "authors": [
        "Zhexuan Xu",
        "Jie Wang",
        "Siyuan Xu",
        "Zijie Geng",
        "Mingxuan Yuan",
        "Feng Wu"
      ],
      "abstract": "Floorplanning determines the shapes and locations of modules on a chip canvas and plays a critical role in optimizing the chip's Power, Performance, and Area (PPA) metrics. However, existing floorplanning approaches often fail to integrate with subsequent physical design stages, leading to suboptimal in-module component placement and excessive inter-module feedthrough. To tackle this challenge, we propose Flora, a three-stage feedthrough and placement aware rectilinear floorplanner. In the first stage, Flora employs wiremask and position mask techniques to achieve coarse-grained optimization of HPWL and feedthrough. In the second stage, under the constraint of a fixed outline, Flora achieves a zero-whitespace layout by locally resizing module shapes, thereby performing fine-grained optimization of feedthrough and improving component placement. In the third stage, Flora utilizes a fast tree search-based method to efficiently place components-including macros and standard cells-within each module, subsequently adjusting module boundaries based on the placement results to enable cross-stage optimization. Experimental results show that Flora outperforms recent state-of-the-art floorplanning approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin, 29.15% in FTmod, and a 14% improvement in component placement performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Floraï¼Œä¸€ç§ä¸‰é˜¶æ®µçš„feedthroughå’Œplacementæ„ŸçŸ¥å‹ç›´çº¿å¼å¸ƒå±€è§„åˆ’å™¨(rectilinear floorplanner)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¸ƒå±€è§„åˆ’æ–¹æ³•å› æ— æ³•ä¸åç»­ç‰©ç†è®¾è®¡é˜¶æ®µé›†æˆè€Œå¯¼è‡´çš„æ¨¡å—å†…ç»„ä»¶æ”¾ç½®ä¸ä½³å’Œæ¨¡å—é—´è¿‡é‡feedthroughçš„é—®é¢˜ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼ŒFloraé‡‡ç”¨wiremaskå’Œposition maskæŠ€æœ¯ï¼Œå®ç°äº†å¯¹HPWLå’Œfeedthroughçš„ç²—ç²’åº¦ä¼˜åŒ–ã€‚ç¬¬äºŒé˜¶æ®µé€šè¿‡åœ¨å›ºå®šè½®å»“(fixed outline)çº¦æŸä¸‹å±€éƒ¨è°ƒæ•´æ¨¡å—å½¢çŠ¶ï¼Œå®ç°äº†é›¶ç©ºç™½(zero-whitespace)å¸ƒå±€ï¼Œä»è€Œå®Œæˆäº†feedthroughçš„ç»†ç²’åº¦ä¼˜åŒ–å¹¶æå‡äº†ç»„ä»¶æ”¾ç½®è´¨é‡ã€‚ç¬¬ä¸‰é˜¶æ®µåˆ©ç”¨åŸºäºå¿«é€Ÿæ ‘æœç´¢(fast tree search)çš„æ–¹æ³•é«˜æ•ˆæ”¾ç½®æ¨¡å—å†…çš„å®å•å…ƒ(macros)å’Œæ ‡å‡†å•å…ƒ(standard cells)ï¼Œå¹¶æ ¹æ®æ”¾ç½®ç»“æœåŠ¨æ€è°ƒæ•´æ¨¡å—è¾¹ç•Œä»¥å®ç°è·¨é˜¶æ®µä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFloraåœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›å¸ƒå±€è§„åˆ’æ–¹æ³•ï¼ŒHPWLå¹³å‡é™ä½äº†6%ï¼ŒFTpiné™ä½äº†5.16%ï¼ŒFTmodé™ä½äº†29.15%ï¼ŒåŒæ—¶ç»„ä»¶æ”¾ç½®æ€§èƒ½æå‡äº†14%ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14914v1",
      "published_date": "2025-07-20 11:00:18 UTC",
      "updated_date": "2025-07-20 11:00:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:21.376304+00:00"
    },
    {
      "arxiv_id": "2507.14912v1",
      "title": "Redefining Elderly Care with Agentic AI: Challenges and Opportunities",
      "title_zh": "æ™ºèƒ½ä½“ AI é‡å¡‘è€å¹´äººæŠ¤ç†ï¼šæŒ‘æˆ˜ä¸æœºé‡",
      "authors": [
        "Ruhul Amin Khalil",
        "Kashif Ahmad",
        "Hazrat Ali"
      ],
      "abstract": "The global ageing population necessitates new and emerging strategies for caring for older adults. In this article, we explore the potential for transformation in elderly care through Agentic Artificial Intelligence (AI), powered by Large Language Models (LLMs). We discuss the proactive and autonomous decision-making facilitated by Agentic AI in elderly care. Personalized tracking of health, cognitive care, and environmental management, all aimed at enhancing independence and high-level living for older adults, represents important areas of application. With a potential for significant transformation of elderly care, Agentic AI also raises profound concerns about data privacy and security, decision independence, and access. We share key insights to emphasize the need for ethical safeguards, privacy protections, and transparent decision-making. Our goal in this article is to provide a balanced discussion of both the potential and the challenges associated with Agentic AI, and to provide insights into its responsible use in elderly care, to bring Agentic AI into harmony with the requirements and vulnerabilities specific to the elderly. Finally, we identify the priorities for the academic research communities, to achieve human-centered advancements and integration of Agentic AI in elderly care. To the best of our knowledge, this is no existing study that reviews the role of Agentic AI in elderly care. Hence, we address the literature gap by analyzing the unique capabilities, applications, and limitations of LLM-based Agentic AI in elderly care. We also provide a companion interactive dashboard at https://hazratali.github.io/agenticai/.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) çš„ Agentic AI åœ¨è€å¹´äººæŠ¤ç†é¢†åŸŸçš„è½¬å‹æ½œåŠ›ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸç³»ç»Ÿæ€§ç»¼è¿°çš„ç©ºç™½ã€‚æ–‡ç« è¯¦ç»†é˜è¿°äº† Agentic AI å¦‚ä½•é€šè¿‡ä¸»åŠ¨ä¸”è‡ªä¸»çš„å†³ç­–ï¼Œåœ¨ä¸ªæ€§åŒ–å¥åº·è¿½è¸ªã€è®¤çŸ¥æŠ¤ç†å’Œç¯å¢ƒç®¡ç†ä¸­æå‡è€å¹´äººçš„ç”Ÿæ´»ç‹¬ç«‹æ€§ä¸ç”Ÿæ´»è´¨é‡ã€‚ä½œè€…æ·±å…¥åˆ†æäº†è¯¥æŠ€æœ¯åœ¨åº”ç”¨è¿‡ç¨‹ä¸­é¢ä¸´çš„æ•°æ®éšç§ (Data Privacy)ã€å®‰å…¨æ€§åŠå†³ç­–ç‹¬ç«‹æ€§ç­‰ä¸¥å³»æŒ‘æˆ˜ï¼Œå¹¶å¼ºè°ƒäº†å»ºç«‹ä¼¦ç†ä¿éšœ (Ethical Safeguards) ä¸é€æ˜å†³ç­–æœºåˆ¶çš„å¿…è¦æ€§ã€‚ç ”ç©¶æ—¨åœ¨æ¨åŠ¨ Agentic AI ä¸è€å¹´äººç‰¹æ®Šéœ€æ±‚åŠè„†å¼±æ€§ä¹‹é—´çš„å’Œè°ç»Ÿä¸€ï¼Œå¹¶ä¸ºå­¦æœ¯ç•ŒæŒ‡æ˜äº†å®ç°ä»¥äººä¸ºä¸­å¿ƒ (Human-centered) èåˆçš„æŠ€æœ¯è·¯å¾„ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æä¾›äº†ä¸€ä¸ªé…å¥—çš„äº¤äº’å¼ä»ªè¡¨ç›˜ï¼Œä»¥è¾…åŠ©åˆ†æ LLM-based Agentic AI åœ¨è€å¹´æŠ¤ç†ä¸­çš„ç‹¬ç‰¹èƒ½åŠ›ã€åº”ç”¨åœºæ™¯ä¸å±€é™æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14912v1",
      "published_date": "2025-07-20 10:53:01 UTC",
      "updated_date": "2025-07-20 10:53:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:07.827148+00:00"
    },
    {
      "arxiv_id": "2507.14909v3",
      "title": "The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities",
      "title_zh": "Endless Tuningï¼šä¸€ç§æ—¨åœ¨é¿å…äººç±»è¢«æ›¿ä»£å¹¶å®ç°è´£ä»»è¿½æº¯çš„äººå·¥æ™ºèƒ½è®¾è®¡",
      "authors": [
        "Elio Grande"
      ],
      "abstract": "The Endless Tuning is a design method for a reliable deployment of artificial intelligence based on a double mirroring process, which pursues both the goals of avoiding human replacement and filling the so-called responsibility gap (Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the relational approach urged therein, it was then actualized in a protocol, implemented in three prototypical applications regarding decision-making processes (respectively: loan granting, pneumonia diagnosis, and art style recognition) and tested with such as many domain experts. Step by step illustrating the protocol, giving insights concretely showing a different voice (Gilligan 1993) in the ethics of artificial intelligence, a philosophical account of technical choices (e.g., a reversed and hermeneutic deployment of XAI algorithms) will be provided in the present study together with the results of the experiments, focusing on user experience rather than statistical accuracy. Even thoroughly employing deep learning models, full control was perceived by the interviewees in the decision-making setting, while it appeared that a bridge can be built between accountability and liability in case of damage.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† The Endless Tuningï¼Œä¸€ç§æ—¨åœ¨é¿å…äººå·¥æ™ºèƒ½ (Artificial Intelligence) å–ä»£äººç±»å¹¶å¡«è¡¥è´£ä»»ç¼ºå£ (responsibility gap) çš„å¯é éƒ¨ç½²è®¾è®¡æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŸºäºåŒé‡é•œåƒè¿‡ç¨‹ (double mirroring process) å’Œå…³ç³»æ–¹æ³• (relational approach)ï¼Œé€šè¿‡ä¸€å¥—å…·ä½“çš„åè®®åœ¨è´·æ¬¾å‘æ”¾ã€è‚ºç‚è¯Šæ–­å’Œè‰ºæœ¯é£æ ¼è¯†åˆ«ä¸‰ä¸ªåŸå‹åº”ç”¨ä¸­è¿›è¡Œäº†å®è·µã€‚åœ¨æŠ€æœ¯å±‚é¢ï¼Œç ”ç©¶å¯¹æŠ€æœ¯é€‰æ‹©è¿›è¡Œäº†å“²å­¦å±‚é¢çš„é˜é‡Šï¼Œå¹¶é‡‡ç”¨äº†åå‘ä¸”å…·æœ‰è¯ é‡Šå­¦æ„ä¹‰çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½ (XAI) ç®—æ³•éƒ¨ç½²æ–¹å¼ã€‚é€šè¿‡å¯¹é¢†åŸŸä¸“å®¶çš„å®éªŒæµ‹è¯•ï¼Œç ”ç©¶é‡ç‚¹å…³æ³¨ç”¨æˆ·ä½“éªŒè€Œéå•çº¯çš„ç»Ÿè®¡å‡†ç¡®æ€§ï¼Œç»“æœæ˜¾ç¤ºå—è®¿è€…åœ¨å†³ç­–è¿‡ç¨‹ä¸­æ„ŸçŸ¥åˆ°äº†å®Œå…¨çš„æ§åˆ¶æƒã€‚è¯¥ç ”ç©¶æˆåŠŸåœ¨é—®è´£åˆ¶ (accountability) ä¸æŸå®³èµ”å¿è´£ä»» (liability) ä¹‹é—´å»ºç«‹äº†æ¡¥æ¢ï¼Œä¸ºç¡®ä¿äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯è¿½æº¯æ€§å’Œäººç±»ä¸»ä½“åœ°ä½æä¾›äº†åˆ‡å®å¯è¡Œçš„è®¾è®¡è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14909v3",
      "published_date": "2025-07-20 10:48:07 UTC",
      "updated_date": "2025-12-06 08:51:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:22.755431+00:00"
    },
    {
      "arxiv_id": "2508.13161v1",
      "title": "Piano: A Multi-Constraint Pin Assignment-Aware Floorplanner",
      "title_zh": "Pianoï¼šä¸€ç§æ„ŸçŸ¥å¼•è„šåˆ†é…çš„å¤šçº¦æŸå¸ƒå›¾è§„åˆ’å™¨",
      "authors": [
        "Zhexuan Xu",
        "Kexin Zhou",
        "Jie Wang",
        "Zijie Geng",
        "Siyuan Xu",
        "Shixiong Kai",
        "Mingxuan Yuan",
        "Feng Wu"
      ],
      "abstract": "Floorplanning is a critical step in VLSI physical design, increasingly complicated by modern constraints such as fixed-outline requirements, whitespace removal, and the presence of pre-placed modules. In addition, the assignment of pins on module boundaries significantly impacts the performance of subsequent stages, including detailed placement and routing. However, traditional floorplanners often overlook pin assignment with modern constraints during the floorplanning stage. In this work, we introduce Piano, a floorplanning framework that simultaneously optimizes module placement and pin assignment under multiple constraints. Specifically, we construct a graph based on the geometric relationships among modules and their netlist connections, then iteratively search for shortest paths to determine pin assignments. This graph-based method also enables accurate evaluation of feedthrough and unplaced pins, thereby guiding overall layout quality. To further improve the design, we adopt a whitespace removal strategy and employ three local optimizers to enhance layout metrics under multi-constraint scenarios. Experimental results on widely used benchmark circuits demonstrate that Piano achieves an average 6.81% reduction in HPWL, a 13.39% decrease in feedthrough wirelength, a 16.36% reduction in the number of feedthrough modules, and a 21.21% drop in unplaced pins, while maintaining zero whitespace.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†Pianoï¼Œä¸€ç§èƒ½å¤Ÿåœ¨å¤šçº¦æŸç¯å¢ƒä¸‹åŒæ—¶ä¼˜åŒ–æ¨¡å—æ”¾ç½®ä¸å¼•è„šåˆ†é…(Pin Assignment)çš„å¸ƒå›¾è§„åˆ’(Floorplanning)æ¡†æ¶ï¼Œä»¥è§£å†³VLSIç‰©ç†è®¾è®¡ä¸­å›ºå®šè½®å»“å’Œé¢„æ”¾ç½®æ¨¡å—ç­‰å¸¦æ¥çš„å¤æ‚æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ„å»ºåæ˜ æ¨¡å—å‡ ä½•å…³ç³»ä¸ç½‘è¡¨è¿æ¥çš„å›¾ç»“æ„ï¼Œå¹¶åˆ©ç”¨è¿­ä»£æœç´¢æœ€çŸ­è·¯å¾„çš„æ–¹æ³•æ¥ç²¾ç¡®ç¡®å®šå¼•è„šåˆ†é…ï¼Œä»è€Œæœ‰æ•ˆè¯„ä¼°é¦ˆé€š(Feedthrough)å’Œæœªæ”¾ç½®å¼•è„šå¯¹è®¾è®¡è´¨é‡çš„å½±å“ã€‚æ­¤å¤–ï¼ŒPianoè¿˜æ•´åˆäº†ç™½ç©ºé—´æ¶ˆé™¤(Whitespace removal)ç­–ç•¥å’Œä¸‰ä¸ªå±€éƒ¨ä¼˜åŒ–å™¨ï¼Œé€šè¿‡ç²¾ç»†åŒ–è°ƒæ•´è¿›ä¸€æ­¥æå‡å¸ƒå±€æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¿æŒé›¶ç™½ç©ºé—´çš„åŒæ—¶ï¼ŒPianoåœ¨åŠå‘¨é•¿çº¿é•¿(HPWL)ä¸Šå¹³å‡å‡å°‘äº†6.81%ï¼Œå¹¶æ˜¾è‘—é™ä½äº†é¦ˆé€šçº¿é•¿ã€é¦ˆé€šæ¨¡å—æ•°é‡ä»¥åŠ21.21%çš„æœªæ”¾ç½®å¼•è„šæ¯”ä¾‹ã€‚è¯¥ç ”ç©¶ä¸ºç°ä»£å¤æ‚çº¦æŸä¸‹çš„é«˜æ€§èƒ½ç‰©ç†è®¾è®¡æä¾›äº†é«˜æ•ˆçš„è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆï¼Œä¸ºåç»­çš„å¸ƒå±€å¸ƒçº¿é˜¶æ®µå¥ å®šäº†è‰¯å¥½åŸºç¡€ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13161v1",
      "published_date": "2025-07-20 10:44:54 UTC",
      "updated_date": "2025-07-20 10:44:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:26.320067+00:00"
    },
    {
      "arxiv_id": "2507.14908v1",
      "title": "Partial Symmetry Enforced Attention Decomposition (PSEAD): A Group-Theoretic Framework for Equivariant Transformers in Biological Systems",
      "title_zh": "éƒ¨åˆ†å¯¹ç§°çº¦æŸæ³¨æ„åŠ›åˆ†è§£ (PSEAD)ï¼šé¢å‘ç”Ÿç‰©ç³»ç»Ÿç­‰å˜ Transformer çš„ç¾¤è®ºæ¡†æ¶",
      "authors": [
        "Daniel Ayomide Olanrewaju"
      ],
      "abstract": "This research introduces the Theory of Partial Symmetry Enforced Attention Decomposition (PSEAD), a new and rigorous group-theoretic framework designed to seamlessly integrate local symmetry awareness into the core architecture of self-attention mechanisms within Transformer models. We formalize the concept of local permutation subgroup actions on windows of biological data, proving that under such actions, the attention mechanism naturally decomposes into a direct sum of orthogonal irreducible components. Critically, these components are intrinsically aligned with the irreducible representations of the acting permutation subgroup, thereby providing a powerful mathematical basis for disentangling symmetric and asymmetric features. We show that PSEAD offers substantial advantages. These include enhanced generalization capabilities to novel biological motifs exhibiting similar partial symmetries, unprecedented interpretability by allowing direct visualization and analysis of attention contributions from different symmetry channels, and significant computational efficiency gains by focusing representational capacity on relevant symmetric subspaces. Beyond static data analysis, we extend PSEAD's applicability to dynamic biological processes within reinforcement learning paradigms, showcasing its potential to accelerate the discovery and optimization of biologically meaningful policies in complex environments like protein folding and drug discovery. This work lays the groundwork for a new generation of biologically informed, symmetry-aware artificial intelligence models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†éƒ¨åˆ†å¯¹ç§°æ€§å¼ºåˆ¶æ³¨æ„åŠ›åˆ†è§£(Partial Symmetry Enforced Attention Decomposition, PSEAD)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å°†å±€éƒ¨å¯¹ç§°æ€§æ„ŸçŸ¥æ— ç¼é›†æˆåˆ°Transformeræ¨¡å‹è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„ä¸¥è°¨ç¾¤è®ºæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å½¢å¼åŒ–ç”Ÿç‰©æ•°æ®çª—å£ä¸Šçš„å±€éƒ¨ç½®æ¢å­ç¾¤ä½œç”¨ï¼Œè¯æ˜äº†æ³¨æ„åŠ›æœºåˆ¶èƒ½è‡ªç„¶åˆ†è§£ä¸ºä¸è¯¥å­ç¾¤ä¸å¯çº¦è¡¨ç¤º(irreducible representations)å†…åœ¨ä¸€è‡´çš„æ­£äº¤ä¸å¯çº¦åˆ†é‡ï¼Œä¸ºè§£è€¦å¯¹ç§°ä¸éå¯¹ç§°ç‰¹å¾æä¾›äº†æ•°å­¦åŸºç¡€ã€‚PSEADæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¯¹å…·æœ‰ç›¸ä¼¼å±€éƒ¨å¯¹ç§°æ€§çš„ç”Ÿç‰©åŸºå…ƒ(motifs)çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶é€šè¿‡åˆ†æä¸åŒå¯¹ç§°é€šé“çš„æ³¨æ„åŠ›è´¡çŒ®æå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶é€šè¿‡èšç„¦ç›¸å…³å¯¹ç§°å­ç©ºé—´æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å°†å…¶åº”ç”¨æ‰©å±•è‡³å¼ºåŒ–å­¦ä¹ èŒƒå¼ä¸‹çš„åŠ¨æ€ç”Ÿç‰©è¿‡ç¨‹ï¼Œå±•ç¤ºäº†åœ¨è›‹ç™½è´¨æŠ˜å (protein folding)å’Œè¯ç‰©å‘ç°(drug discovery)ç­‰å¤æ‚ç¯å¢ƒä¸­åŠ é€Ÿå‘ç°ç”Ÿç‰©æ„ä¹‰ç­–ç•¥çš„æ½œåŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºç”Ÿç‰©ä¿¡æ¯é©±åŠ¨ä¸”å…·å¤‡å¯¹ç§°æ„ŸçŸ¥èƒ½åŠ›çš„æ–°ä¸€ä»£äººå·¥æ™ºèƒ½æ¨¡å‹å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "math.RT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.RT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14908v1",
      "published_date": "2025-07-20 10:44:31 UTC",
      "updated_date": "2025-07-20 10:44:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:41.491357+00:00"
    },
    {
      "arxiv_id": "2507.14906v1",
      "title": "Feedback-Induced Performance Decline in LLM-Based Decision-Making",
      "title_zh": "åŸºäº LLM å†³ç­–ä¸­åé¦ˆè¯±å‘çš„æ€§èƒ½ä¸‹é™",
      "authors": [
        "Xiao Yang",
        "Juxi Leitner",
        "Michael Burke"
      ],
      "abstract": "The ability of Large Language Models (LLMs) to extract context from natural language problem descriptions naturally raises questions about their suitability in autonomous decision-making settings. This paper studies the behaviour of these models within a Markov Decision Process (MDPs). While traditional reinforcement learning (RL) strategies commonly employed in this setting rely on iterative exploration, LLMs, pre-trained on diverse datasets, offer the capability to leverage prior knowledge for faster adaptation. We investigate online structured prompting strategies in sequential decision making tasks, comparing the zero-shot performance of LLM-based approaches to that of classical RL methods. Our findings reveal that although LLMs demonstrate improved initial performance in simpler environments, they struggle with planning and reasoning in complex scenarios without fine-tuning or additional guidance. Our results show that feedback mechanisms, intended to improve decision-making, often introduce confusion, leading to diminished performance in intricate environments. These insights underscore the need for further exploration into hybrid strategies, fine-tuning, and advanced memory integration to enhance LLM-based decision-making capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (MDPs) ä¸­çš„è‡ªä¸»å†³ç­–è¡¨ç°ï¼Œå¯¹æ¯”äº†åœ¨çº¿ç»“æ„åŒ–æç¤ºä¸‹çš„é›¶æ ·æœ¬ (zero-shot) æ€§èƒ½ä¸ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹  (RL) æ–¹æ³•ã€‚ç ”ç©¶å‘ç°ï¼ŒLLMs åœ¨ç®€å•ç¯å¢ƒä¸­è™½å…·æœ‰è¾ƒå¥½çš„åˆå§‹æ€§èƒ½ï¼Œä½†åœ¨å¤æ‚åœºæ™¯ä¸‹è‹¥ç¼ºä¹å¾®è°ƒ (fine-tuning) æˆ–é¢å¤–å¼•å¯¼ï¼Œå…¶è§„åˆ’ä¸æ¨ç†èƒ½åŠ›æ˜¾è‘—å—é™ã€‚å…³é”®å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ—¨åœ¨æå‡è¡¨ç°çš„åé¦ˆæœºåˆ¶ (feedback mechanisms) åœ¨å¤æ‚ç¯å¢ƒä¸­å¾€å¾€ä¼šå¼•èµ·æ¨¡å‹æ··ä¹±ï¼Œå¯¼è‡´å†³ç­–æ€§èƒ½ä¸‹é™ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†åé¦ˆé©±åŠ¨å‹å†³ç­–çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†æœªæ¥åœ¨ LLM å†³ç­–ä»»åŠ¡ä¸­å¼•å…¥æ··åˆç­–ç•¥ã€æ¨¡å‹å¾®è°ƒåŠé«˜çº§è®°å¿†æ•´åˆæœºåˆ¶çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14906v1",
      "published_date": "2025-07-20 10:38:56 UTC",
      "updated_date": "2025-07-20 10:38:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:47.486142+00:00"
    },
    {
      "arxiv_id": "2507.14904v2",
      "title": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP",
      "title_zh": "TriCLIP-3Dï¼šåŸºäº CLIP çš„ç»Ÿä¸€å‚æ•°é«˜æ•ˆä¸‰æ¨¡æ€ 3D è§†è§‰å®šä½æ¡†æ¶",
      "authors": [
        "Fan Li",
        "Zanyi Wang",
        "Zeyi Huang",
        "Guang Dai",
        "Jingdong Wang",
        "Mengmeng Wang"
      ],
      "abstract": "3D visual grounding allows an embodied agent to understand visual information in real-world 3D environments based on human instructions, which is crucial for embodied intelligence. Existing 3D visual grounding methods typically rely on separate encoders for different modalities (e.g., RGB images, text, and 3D point clouds), resulting in large and complex models that are inefficient to train. While some approaches use pre-trained 2D multi-modal models like CLIP for 3D tasks, they still struggle with aligning point cloud data to 2D encoders. As a result, these methods continue to depend on 3D encoders for feature extraction, further increasing model complexity and training inefficiency. In this paper, we propose a unified 2D pre-trained multi-modal network to process all three modalities (RGB images, text, and point clouds), significantly simplifying the architecture. By leveraging a 2D CLIP bi-modal model with adapter-based fine-tuning, this framework effectively adapts to the tri-modal setting, improving both adaptability and performance across modalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module is designed to fuse geometric multi-scale features from point clouds and images. We then integrate textual features for final modality fusion and introduce a multi-modal decoder to facilitate deep cross-modal understanding. Together, our method achieves unified feature extraction and fusion across the three modalities, enabling an end-to-end 3D visual grounding model. Compared to the baseline, our method reduces the number of trainable parameters by approximately 58\\%, while achieving a 6.52\\% improvement in the 3D detection task and a 6.25\\% improvement in the 3D visual grounding task.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TriCLIP-3Dï¼Œä¸€ä¸ªç»Ÿä¸€ä¸”å‚æ•°é«˜æ•ˆçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰3D visual groundingæ–¹æ³•å› ä¾èµ–ç‹¬ç«‹å¤šæ¨¡æ€ç¼–ç å™¨è€Œå¯¼è‡´æ¨¡å‹å¤æ‚åŠè®­ç»ƒä½æ•ˆçš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡åŸºäºé€‚é…å™¨ï¼ˆAdapter-basedï¼‰çš„å¾®è°ƒæŠ€æœ¯ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„2D CLIPæ¨¡å‹åŒæ—¶å¤„ç†å›¾åƒã€æ–‡æœ¬å’Œç‚¹äº‘ï¼ˆPoint Cloudsï¼‰ä¸‰ç§æ¨¡æ€ï¼Œæ˜¾è‘—ç®€åŒ–äº†ç³»ç»Ÿæ¶æ„ã€‚ç ”ç©¶è¿›ä¸€æ­¥è®¾è®¡äº†å‡ ä½•æ„ŸçŸ¥2D-3Dç‰¹å¾æ¢å¤ä¸èåˆï¼ˆGeometric-Aware 2D-3D Feature Recovery and Fusion, GARFï¼‰æ¨¡å—æ¥æ•´åˆç‚¹äº‘ä¸å›¾åƒçš„å¤šå°ºåº¦å‡ ä½•ç‰¹å¾ï¼Œå¹¶é…åˆå¤šæ¨¡æ€è§£ç å™¨å®ç°æ·±å±‚è·¨æ¨¡æ€ç†è§£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡å°‘çº¦58%å¯è®­ç»ƒå‚æ•°çš„åŸºç¡€ä¸Šï¼Œå°†3Dæ£€æµ‹ä»»åŠ¡å’Œ3D visual groundingä»»åŠ¡çš„å‡†ç¡®ç‡åˆ†åˆ«æå‡äº†6.52%å’Œ6.25%ï¼Œå®ç°äº†é«˜æ•ˆçš„ç«¯åˆ°ç«¯ç‰¹å¾æå–ä¸èåˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14904v2",
      "published_date": "2025-07-20 10:28:06 UTC",
      "updated_date": "2025-09-04 13:42:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:44.343135+00:00"
    },
    {
      "arxiv_id": "2507.14901v1",
      "title": "Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies",
      "title_zh": "å­¦ä¹ éçº¿æ€§å› æœå½’çº¦ä»¥è§£é‡Šå¼ºåŒ–å­¦ä¹ ç­–ç•¥",
      "authors": [
        "Armin KekiÄ‡",
        "Jan Schneider",
        "Dieter BÃ¼chler",
        "Bernhard SchÃ¶lkopf",
        "Michel Besserve"
      ],
      "abstract": "Why do reinforcement learning (RL) policies fail or succeed? This is a challenging question due to the complex, high-dimensional nature of agent-environment interactions. In this work, we take a causal perspective on explaining the behavior of RL policies by viewing the states, actions, and rewards as variables in a low-level causal model. We introduce random perturbations to policy actions during execution and observe their effects on the cumulative reward, learning a simplified high-level causal model that explains these relationships. To this end, we develop a nonlinear Causal Model Reduction framework that ensures approximate interventional consistency, meaning the simplified high-level model responds to interventions in a similar way as the original complex system. We prove that for a class of nonlinear causal models, there exists a unique solution that achieves exact interventional consistency, ensuring learned explanations reflect meaningful causal patterns. Experiments on both synthetic causal models and practical RL tasks-including pendulum control and robot table tennis-demonstrate that our approach can uncover important behavioral patterns, biases, and failure modes in trained RL policies.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»å› æœè§†è§’æ¢è®¨äº†å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç­–ç•¥çš„è§£é‡Šæ€§é—®é¢˜ï¼Œé€šè¿‡å°†çŠ¶æ€ã€åŠ¨ä½œå’Œå¥–åŠ±è§†ä¸ºä½å±‚å› æœæ¨¡å‹ä¸­çš„å˜é‡ï¼Œæ—¨åœ¨è§£æå¤æ‚çš„æ™ºèƒ½ä½“-ç¯å¢ƒäº¤äº’ã€‚ä½œè€…å¼€å‘äº†ä¸€ç§éçº¿æ€§å› æœæ¨¡å‹ç®€åŒ–(Nonlinear Causal Model Reduction)æ¡†æ¶ï¼Œé€šè¿‡åœ¨ç­–ç•¥æ‰§è¡Œä¸­å¼•å…¥åŠ¨ä½œæ‰°åŠ¨å¹¶è§‚å¯Ÿç´¯ç§¯å¥–åŠ±çš„å˜åŒ–ï¼Œæ¥å­¦ä¹ èƒ½å¤Ÿè§£é‡Šè¿™äº›å…³ç³»çš„ç®€åŒ–é«˜å±‚å› æœæ¨¡å‹ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåœ¨äºç¡®ä¿è¿‘ä¼¼å¹²é¢„ä¸€è‡´æ€§(Interventional Consistency)ï¼Œä½¿å¾—ç®€åŒ–æ¨¡å‹å¯¹å¹²é¢„çš„å“åº”ä¸åŸå§‹å¤æ‚ç³»ç»Ÿä¿æŒä¸€è‡´ã€‚ç†è®ºåˆ†æè¯æ˜ï¼Œå¯¹äºç‰¹å®šç±»åˆ«çš„éçº¿æ€§å› æœæ¨¡å‹ï¼Œå­˜åœ¨èƒ½å®ç°ç²¾ç¡®å¹²é¢„ä¸€è‡´æ€§çš„å”¯ä¸€è§£ï¼Œä»è€Œç¡®ä¿è§£é‡Šèƒ½å¤Ÿåæ˜ çœŸå®çš„å› æœæ¨¡å¼ã€‚åœ¨åˆæˆæ¨¡å‹ä»¥åŠæ‘†é”¤æ§åˆ¶å’Œæœºå™¨äººä¹’ä¹“çƒç­‰å®é™…å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæ­ç¤ºå·²è®­ç»ƒç­–ç•¥ä¸­çš„å…³é”®è¡Œä¸ºæ¨¡å¼ã€åè§åŠå¤±è´¥æ¨¡å¼ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14901v1",
      "published_date": "2025-07-20 10:25:24 UTC",
      "updated_date": "2025-07-20 10:25:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:48.935462+00:00"
    },
    {
      "arxiv_id": "2507.14899v2",
      "title": "InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis",
      "title_zh": "InsightX Agentï¼šåŸºäºå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸é›†æˆå·¥å…·çš„å¯é Xå°„çº¿æ— æŸæ£€æµ‹åˆ†ææ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Jiale Liu",
        "Huan Wang",
        "Yue Zhang",
        "Xiaoyu Luo",
        "Jiaxiang Hu",
        "Zhiliang Liu",
        "Min Xie"
      ],
      "abstract": "Non-destructive testing (NDT), particularly X-ray inspection, is vital for industrial quality assurance, yet existing deep-learning-based approaches often lack interactivity, interpretability, and the capacity for critical self-assessment, limiting their reliability and operator trust. To address these shortcomings, this paper proposes InsightX Agent, a novel LMM-based agentic framework designed to deliver reliable, interpretable, and interactive X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent positions a Large Multimodal Model (LMM) as a central orchestrator, coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect region proposals for multi-scale feature maps and sparsifies them through Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in X-ray images while maintaining computational efficiency. The EGR tool guides the LMM agent through a chain-of-thought-inspired review process, incorporating context assessment, individual defect analysis, false positive elimination, confidence recalibration and quality assurance to validate and refine the SDMSD's initial proposals. By strategically employing and intelligently using tools, InsightX Agent moves beyond passive data processing to active reasoning, enhancing diagnostic reliability and providing interpretations that integrate diverse information sources. Experimental evaluations on the GDXray+ dataset demonstrate that InsightX Agent not only achieves a high object detection F1-score of 96.35% but also offers significantly improved interpretability and trustworthiness in its analyses, highlighting the transformative potential of agentic LLM frameworks for industrial inspection tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šæ— æŸæ£€æµ‹(NDT)ä¸­æ·±åº¦å­¦ä¹ æ¨¡å‹ç¼ºä¹äº¤äº’æ€§ã€å¯è§£é‡Šæ€§å’Œè‡ªæˆ‘è¯„ä¼°èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†InsightX Agentï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤§è¯­è¨€å¤šæ¨¡æ€æ¨¡å‹(LMM)çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†LMMä½œä¸ºæ ¸å¿ƒåè°ƒå™¨ï¼Œé›†æˆäº†ç¨€ç–å¯å˜å½¢å¤šå°ºåº¦æ£€æµ‹å™¨(SDMSD)å’Œè¯æ®é”šå®šåæ€å·¥å…·(EGR)ã€‚SDMSDè´Ÿè´£åœ¨å¤šå°ºåº¦ç‰¹å¾å›¾ä¸­ç”Ÿæˆå¯†é›†çš„ç¼ºé™·å€™é€‰åŒºåŸŸï¼Œå¹¶é€šè¿‡éæå¤§å€¼æŠ‘åˆ¶(NMS)ä¼˜åŒ–å¯¹Xå°„çº¿å›¾åƒä¸­å¾®å°ä¸”å¯†é›†ç›®æ ‡çš„æ£€æµ‹æ•ˆç‡ã€‚EGRå·¥å…·åˆ™é€šè¿‡é“¾å¼æ€ç»´(Chain-of-Thought)å¼•å¯¼æ™ºèƒ½ä½“è¿›è¡ŒèƒŒæ™¯è¯„ä¼°ã€ç¼ºé™·åˆ†æåŠè™šè­¦æ¶ˆé™¤ï¼Œä»è€ŒéªŒè¯å¹¶ç²¾ç‚¼åˆå§‹æ£€æµ‹ç»“æœã€‚é€šè¿‡è¿™ç§æ™ºèƒ½å·¥å…·è°ƒç”¨ç­–ç•¥ï¼ŒInsightX Agentå®ç°äº†ä»è¢«åŠ¨æ•°æ®å¤„ç†åˆ°ä¸»åŠ¨æ¨ç†çš„è½¬å˜ï¼Œæ˜¾è‘—å¢å¼ºäº†è¯Šæ–­çš„å¯é æ€§ã€‚åœ¨GDXray+æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶ä¸ä»…å®ç°äº†96.35%çš„é«˜ç‰©ä½“æ£€æµ‹F1-scoreï¼Œè¿˜åœ¨åˆ†æçš„å¯è§£é‡Šæ€§å’Œå¯ä¿¡åº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ï¼Œè¯æ˜äº†æ™ºèƒ½ä½“åŒ–LLMæ¡†æ¶åœ¨å·¥ä¸šæ£€æµ‹é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14899v2",
      "published_date": "2025-07-20 10:23:22 UTC",
      "updated_date": "2025-08-18 07:15:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:52.749299+00:00"
    },
    {
      "arxiv_id": "2507.14897v1",
      "title": "AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents",
      "title_zh": "AgentFlyï¼šé¢å‘ LM æ™ºèƒ½ä½“çš„å¯æ‰©å±•ä¸é«˜ä¼¸ç¼©æ€§å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Renxi Wang",
        "Rifo Ahmad Genadi",
        "Bilal El Bouardi",
        "Yongxin Wang",
        "Fajri Koto",
        "Zhengzhong Liu",
        "Timothy Baldwin",
        "Haonan Li"
      ],
      "abstract": "Language model (LM) agents have gained significant attention for their ability to autonomously complete tasks through interactions with environments, tools, and APIs. LM agents are primarily built with prompt engineering or supervised finetuning. At the same time, reinforcement learning (RL) has been explored to enhance LM's capabilities, such as reasoning and factuality. However, the combination of the LM agents and reinforcement learning (Agent-RL) remains underexplored and lacks systematic study. To this end, we built AgentFly, a scalable and extensible Agent-RL framework designed to empower LM agents with a variety of RL algorithms. Our framework supports multi-turn interactions by adapting traditional RL methods with token-level masking. It features a decorator-based interface for defining tools and reward functions, enabling seamless extension and ease of use. To support high-throughput training, we implement asynchronous execution of tool calls and reward computations, and design a centralized resource management system for scalable environment coordination. We also provide a suite of prebuilt tools and environments, demonstrating the framework's effectiveness through successful agent training across multiple tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AgentFlyï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³ Language model (LM) æ™ºèƒ½ä½“åœ¨å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) é¢†åŸŸç¼ºä¹ç³»ç»Ÿæ€§ç ”ç©¶ä¸”éš¾ä»¥æ‰©å±•é—®é¢˜çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¸ token-level masking æŠ€æœ¯ç›¸ç»“åˆï¼Œå®ç°äº†å¯¹å¤šè½®äº¤äº’ (multi-turn interactions) çš„æœ‰æ•ˆæ”¯æŒã€‚AgentFly é‡‡ç”¨äº†åŸºäºè£…é¥°å™¨ (decorator-based) çš„æ¥å£æ¥å®šä¹‰å·¥å…· (tools) å’Œå¥–åŠ±å‡½æ•° (reward functions)ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„æ˜“ç”¨æ€§ä¸å¯æ‰©å±•æ€§ã€‚ä¸ºäº†å®ç°é«˜ååé‡è®­ç»ƒï¼Œæ¡†æ¶å¼•å…¥äº†å·¥å…·è°ƒç”¨ä¸å¥–åŠ±è®¡ç®—çš„å¼‚æ­¥æ‰§è¡Œ (asynchronous execution) æœºåˆ¶ï¼Œå¹¶è®¾è®¡äº†é›†ä¸­å¼èµ„æºç®¡ç†ç³»ç»Ÿä»¥ä¼˜åŒ–å¤§è§„æ¨¡ç¯å¢ƒåä½œã€‚é€šè¿‡åœ¨å¤šç§ä»»åŠ¡å’Œç¯å¢ƒä¸‹çš„è®­ç»ƒå®éªŒï¼Œè¯¥ç ”ç©¶è¯æ˜äº† AgentFly åœ¨æå‡æ™ºèƒ½ä½“è‡ªä¸»ä»»åŠ¡å®Œæˆèƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸º Agent-RL çš„è¿›ä¸€æ­¥ç ”ç©¶æä¾›äº†åšå®çš„åŸºç¡€è®¾æ–½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14897v1",
      "published_date": "2025-07-20 10:22:36 UTC",
      "updated_date": "2025-07-20 10:22:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:48:52.146616+00:00"
    },
    {
      "arxiv_id": "2507.14882v2",
      "title": "Application-Specific Component-Aware Structured Pruning of Deep Neural Networks in Control via Soft Coefficient Optimization",
      "title_zh": "åŸºäºè½¯ç³»æ•°ä¼˜åŒ–çš„æ§åˆ¶é¢†åŸŸæ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨ç‰¹å®šä¸ç»„ä»¶æ„ŸçŸ¥ç»“æ„åŒ–å‰ªæ",
      "authors": [
        "Ganesh Sundaram",
        "Jonas Ulmen",
        "Amjad Haider",
        "Daniel GÃ¶rges"
      ],
      "abstract": "Deep neural networks (DNNs) offer significant flexibility and robust performance. This makes them ideal for building not only system models but also advanced neural network controllers (NNCs). However, their high complexity and computational needs often limit their use. Various model compression strategies have been developed over the past few decades to address these issues. These strategies are effective for general DNNs but do not directly apply to NNCs. NNCs need both size reduction and the retention of key application-specific performance features. In structured pruning, which removes groups of related elements, standard importance metrics often fail to protect these critical characteristics. In this paper, we introduce a novel framework for calculating importance metrics in pruning groups. This framework not only shrinks the model size but also considers various application-specific constraints. To find the best pruning coefficient for each group, we evaluate two approaches. The first approach involves simple exploration through grid search. The second utilizes gradient descent optimization, aiming to balance compression and task performance. We test our method in two use cases: one on an MNIST autoencoder and the other on a Temporal Difference Model Predictive Control (TDMPC) agent. Results show that the method effectively maintains application-relevant performance while achieving a significant reduction in model size.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDeep neural networks, DNNsï¼‰åœ¨ç¥ç»ç½‘ç»œæ§åˆ¶å™¨ï¼ˆNeural network controllers, NNCsï¼‰åº”ç”¨ä¸­é¢ä¸´çš„è®¡ç®—å¤æ‚æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åº”ç”¨ç‰¹å®šçš„ç»„ä»¶æ„ŸçŸ¥ç»“æ„åŒ–å‰ªæï¼ˆStructured pruningï¼‰æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡è½¯ç³»æ•°ä¼˜åŒ–ï¼ˆSoft coefficient optimizationï¼‰è®¡ç®—å‰ªæç»„çš„é‡è¦æ€§æŒ‡æ ‡ï¼Œæ—¨åœ¨æ¨¡å‹å‹ç¼©è¿‡ç¨‹ä¸­æ˜¾å¼åœ°ä¿æŠ¤åº”ç”¨ç›¸å…³çš„æ€§èƒ½çº¦æŸã€‚ç ”ç©¶æ¢ç´¢äº†åŸºäºç½‘æ ¼æœç´¢ï¼ˆGrid searchï¼‰å’Œæ¢¯åº¦ä¸‹é™ï¼ˆGradient descentï¼‰ä¸¤ç§ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥å¯»æ±‚å‹ç¼©æ¯”ä¾‹ä¸ä»»åŠ¡è¡¨ç°ä¹‹é—´çš„æœ€ä¼˜å¹³è¡¡ã€‚åœ¨ MNIST è‡ªåŠ¨ç¼–ç å™¨å’Œæ—¶åºå·®åˆ†æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆTemporal Difference Model Predictive Control, TDMPCï¼‰æ™ºèƒ½ä½“ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—å‡å°æ¨¡å‹å°ºå¯¸çš„åŒæ—¶ï¼ŒæˆåŠŸç»´æŒäº†åº”ç”¨æ ¸å¿ƒæ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 24th European Control Conference (ECC26)",
      "pdf_url": "https://arxiv.org/pdf/2507.14882v2",
      "published_date": "2025-07-20 09:50:04 UTC",
      "updated_date": "2025-11-13 07:54:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:03.887839+00:00"
    },
    {
      "arxiv_id": "2507.19526v1",
      "title": "Quantizing Text-attributed Graphs for Semantic-Structural Integration",
      "title_zh": "é¢å‘è¯­ä¹‰-ç»“æ„èåˆçš„æ–‡æœ¬å±æ€§å›¾é‡åŒ–",
      "authors": [
        "Jianyuan Bo",
        "Hao Wu",
        "Yuan Fang"
      ],
      "abstract": "Text-attributed graphs (TAGs) have emerged as a powerful representation for modeling complex relationships across diverse domains. With the rise of large language models (LLMs), there is growing interest in leveraging their capabilities for graph learning. However, current approaches face significant challenges in embedding structural information into LLM-compatible formats, requiring either computationally expensive alignment mechanisms or manual graph verbalization techniques that often lose critical structural details. Moreover, these methods typically require labeled data from source domains for effective transfer learning, significantly constraining their adaptability. We propose STAG, a novel self-supervised framework that directly quantizes graph structural information into discrete tokens using a frozen codebook. Unlike traditional quantization approaches, our method employs soft assignment and KL divergence guided quantization to address the unique challenges of graph data, which lacks natural tokenization structures. Our framework enables both LLM-based and traditional learning approaches, supporting true zero-shot transfer learning without requiring labeled data even in the source domain. Extensive experiments demonstrate state-of-the-art performance across multiple node classification benchmarks while maintaining compatibility with different LLM architectures, offering an elegant solution to bridging graph learning with LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†STAGï¼Œä¸€ç§æ—¨åœ¨å®ç°è¯­ä¹‰ä¸ç»“æ„é›†æˆçš„è‡ªç›‘ç£æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å°†Text-attributed Graphs (TAGs) ç»“æ„ä¿¡æ¯åµŒå…¥å¤§è¯­è¨€æ¨¡å‹ (LLMs) æ—¶é¢ä¸´çš„è®¡ç®—æˆæœ¬é«˜ã€ç»“æ„ä¿¡æ¯ä¸¢å¤±ä»¥åŠå¯¹æ ‡æ³¨æ•°æ®é«˜åº¦ä¾èµ–ç­‰æŒ‘æˆ˜ã€‚STAGçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨Frozen Codebookå°†å›¾ç»“æ„ä¿¡æ¯ç›´æ¥é‡åŒ–ä¸ºç¦»æ•£Tokenï¼Œå¹¶é€šè¿‡Soft Assignmentå’ŒKL Divergenceå¼•å¯¼çš„é‡åŒ–æœºåˆ¶å¤„ç†å›¾æ•°æ®ç¼ºä¹è‡ªç„¶TokenåŒ–ç»“æ„çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶æ”¯æŒçœŸæ­£æ„ä¹‰ä¸Šçš„Zero-shot Transfer Learningï¼Œå³ä½¿åœ¨æºåŸŸå®Œå…¨æ²¡æœ‰æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®ç°æœ‰æ•ˆçš„è·¨é¢†åŸŸè¿ç§»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSTAGåœ¨å¤šä¸ªNode ClassificationåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†State-of-the-art (SOTA) æ€§èƒ½ã€‚è¯¥æ–¹æ¡ˆä¸ä»…è¯æ˜äº†å…¶ä¸å¤šç§ä¸åŒLLMæ¶æ„çš„è‰¯å¥½å…¼å®¹æ€§ï¼Œè¿˜ä¸ºå¼¥åˆå›¾å­¦ä¹ ä¸LLMä¹‹é—´çš„æŠ€æœ¯é¸¿æ²Ÿæä¾›äº†ä¸€ç§ä¼˜é›…ä¸”é«˜æ•ˆçš„è§£å†³é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at KDD'2025",
      "pdf_url": "https://arxiv.org/pdf/2507.19526v1",
      "published_date": "2025-07-20 09:18:02 UTC",
      "updated_date": "2025-07-20 09:18:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:00.887249+00:00"
    },
    {
      "arxiv_id": "2507.14874v1",
      "title": "The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs",
      "title_zh": "èµ°å‘æ·±åº¦çš„ Tsetlin æœºå™¨ï¼šåŸºäºå›¾çš„é€»è¾‘å­¦ä¹ ä¸æ¨ç†",
      "authors": [
        "Ole-Christoffer Granmo",
        "Youmna Abdelwahab",
        "Per-Arne Andersen",
        "Paul F. A. Clarke",
        "Kunal Dumbre",
        "Ylva GrÃ¸nninsÃ¦ter",
        "Vojtech Halenka",
        "Runar Helin",
        "Lei Jiao",
        "Ahmed Khalid",
        "Rebekka Omslandseter",
        "Rupsa Saha",
        "Mayur Shende",
        "Xuan Zhang"
      ],
      "abstract": "Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine (TM) both interpretable and efficient, while the power of Tsetlin automata enables accuracy comparable to deep learning on an increasing number of datasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning interpretable deep clauses from graph-structured input. Moving beyond flat, fixed-length input, the GraphTM gets more versatile, supporting sequences, grids, relations, and multimodality. Through message passing, the GraphTM builds nested deep clauses to recognize sub-graph patterns with exponentially fewer clauses, increasing both interpretability and data utilization. For image classification, GraphTM preserves interpretability and achieves 3.86%-points higher accuracy on CIFAR-10 than a convolutional TM. For tracking action coreference, faced with increasingly challenging tasks, GraphTM outperforms other reinforcement learning methods by up to 20.6%-points. In recommendation systems, it tolerates increasing noise to a greater extent than a Graph Convolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains accuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence data, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training 2.5x faster than GCN. The GraphTM's application to these varied fields demonstrates how graph representation learning and deep clauses bring new possibilities for TM learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Graph Tsetlin Machine (GraphTM)ï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿä»å›¾ç»“æ„è¾“å…¥ä¸­å­¦ä¹ å¯è§£é‡Šæ·±åº¦å­å¥(deep clauses)çš„æ–°å‹æ¶æ„ã€‚GraphTMçªç ´äº†ä¼ ç»ŸTsetlin Machineå¤„ç†æ‰å¹³ã€å›ºå®šé•¿åº¦è¾“å…¥çš„å±€é™ï¼Œé€šè¿‡æ¶ˆæ¯ä¼ é€’(message passing)æœºåˆ¶æ„å»ºåµŒå¥—æ·±åº¦å­å¥ï¼Œä»è€Œèƒ½å¤Ÿé«˜æ•ˆè¯†åˆ«å­å›¾æ¨¡å¼å¹¶æ”¯æŒåºåˆ—ã€ç½‘æ ¼ã€å…³ç³»åŠå¤šæ¨¡æ€æ•°æ®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGraphTMåœ¨CIFAR-10å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡æ¯”å·ç§¯Tsetlin Machineé«˜å‡º3.86%ï¼Œåœ¨åŠ¨ä½œå…±æŒ‡è¿½è¸ªä»»åŠ¡ä¸­é¢†å…ˆå¼ºåŒ–å­¦ä¹ æ–¹æ³•é«˜è¾¾20.6%ã€‚åœ¨æ¨èç³»ç»Ÿæµ‹è¯•ä¸­ï¼ŒGraphTMè¡¨ç°å‡ºæ¯”Graph Convolutional Neural Network (GCN)æ›´å¼ºçš„å™ªå£°è€å—æ€§ï¼Œè€Œåœ¨å¤„ç†ç—…æ¯’åŸºå› ç»„æ•°æ®æ—¶ï¼Œå…¶è®­ç»ƒé€Ÿåº¦æ¯”GCNå¿«2.5å€ä¸”ä¿æŒäº†åŒç­‰æ°´å¹³çš„å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å›¾è¡¨ç¤ºå­¦ä¹ ä¸æ·±åº¦å­å¥çš„ç»“åˆæ˜¾è‘—æå‡äº†Tsetlin Machineåœ¨å¤æ‚æ•°æ®å¤„ç†ä¸­çš„å¯è§£é‡Šæ€§ã€æ•°æ®åˆ©ç”¨ç‡å’Œè¿è¡Œæ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.14874v1",
      "published_date": "2025-07-20 09:16:31 UTC",
      "updated_date": "2025-07-20 09:16:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:02.290046+00:00"
    },
    {
      "arxiv_id": "2507.14851v1",
      "title": "Grounding Degradations in Natural Language for All-In-One Video Restoration",
      "title_zh": "é¢å‘å…¨èƒ½è§†é¢‘ä¿®å¤çš„è‡ªç„¶è¯­è¨€é€€åŒ–å…³è”",
      "authors": [
        "Muhammad Kamran Janjua",
        "Amirhosein Ghasemabadi",
        "Kunlin Zhang",
        "Mohammad Salameh",
        "Chao Gao",
        "Di Niu"
      ],
      "abstract": "In this work, we propose an all-in-one video restoration framework that grounds degradation-aware semantic context of video frames in natural language via foundation models, offering interpretable and flexible guidance. Unlike prior art, our method assumes no degradation knowledge in train or test time and learns an approximation to the grounded knowledge such that the foundation model can be safely disentangled during inference adding no extra cost. Further, we call for standardization of benchmarks in all-in-one video restoration, and propose two benchmarks in multi-degradation setting, three-task (3D) and four-task (4D), and two time-varying composite degradation benchmarks; one of the latter being our proposed dataset with varying snow intensity, simulating how weather degradations affect videos naturally. We compare our method with prior works and report state-of-the-art performance on all benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å…¨èƒ½è§†é¢‘ä¿®å¤(All-In-One Video Restoration)æ¡†æ¶ï¼Œé€šè¿‡åŸºç¡€æ¨¡å‹(Foundation Models)å°†è§†é¢‘å¸§çš„é€€åŒ–æ„ŸçŸ¥è¯­ä¹‰ä¸Šä¸‹æ–‡ä¸è‡ªç„¶è¯­è¨€ç›¸ç»“åˆï¼Œä¸ºä¿®å¤è¿‡ç¨‹æä¾›å…·æœ‰è§£é‡Šæ€§å’Œçµæ´»æ€§çš„å¼•å¯¼ã€‚ä¸ä»¥å¾€å·¥ä½œä¸åŒï¼Œè¯¥æ–¹æ³•åœ¨è®­ç»ƒæˆ–æµ‹è¯•é˜¶æ®µå‡ä¸å‡è®¾ä»»ä½•å…ˆéªŒçš„é€€åŒ–çŸ¥è¯†ï¼Œè€Œæ˜¯é€šè¿‡å­¦ä¹ å¯¹æ¥åœ°çŸ¥è¯†(Grounded Knowledge)çš„è¿‘ä¼¼ï¼Œä½¿åŸºç¡€æ¨¡å‹åœ¨æ¨ç†é˜¶æ®µå¯ä»¥è¢«å®‰å…¨è„±ç¦»ï¼Œä»è€Œå®ç°é›¶é¢å¤–è®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…å‘¼åæ ‡å‡†åŒ–è¯¥é¢†åŸŸçš„åŸºå‡†æµ‹è¯•ï¼Œå¹¶æå‡ºäº†ä¸‰ä»»åŠ¡(3D)å’Œå››ä»»åŠ¡(4D)åŸºå‡†ï¼Œä»¥åŠä¸€ä¸ªæ¨¡æ‹Ÿè‡ªç„¶å¤©æ°”ä¸­é™é›ªå¼ºåº¦å˜åŒ–çš„å…¨æ–°å¤åˆé€€åŒ–æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ‰€æœ‰æ ‡å‡†åŒ–åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†å½“å‰æœ€å…ˆè¿›(State-of-the-art)çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚ç°å®é€€åŒ–åœºæ™¯ä¸­çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.14851v1",
      "published_date": "2025-07-20 07:43:33 UTC",
      "updated_date": "2025-07-20 07:43:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:12.241904+00:00"
    },
    {
      "arxiv_id": "2507.14850v2",
      "title": "Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems",
      "title_zh": "é¢å‘å®‰å…¨å…³é”®è‡ªä¸»ç³»ç»Ÿçš„åŸºäºæ§åˆ¶éšœç¢å‡½æ•°çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "H. M. Sabbir Ahmad",
        "Ehsan Sabouni",
        "Alexander Wasilkoff",
        "Param Budhraja",
        "Zijian Guo",
        "Songyuan Zhang",
        "Chuchu Fan",
        "Christos Cassandras",
        "Wenchao Li"
      ],
      "abstract": "We address the problem of safe policy learning in multi-agent safety-critical autonomous systems. In such systems, it is necessary for each agent to meet the safety requirements at all times while also cooperating with other agents to accomplish the task. Toward this end, we propose a safe Hierarchical Multi-Agent Reinforcement Learning (HMARL) approach based on Control Barrier Functions (CBFs). Our proposed hierarchical approach decomposes the overall reinforcement learning problem into two levels learning joint cooperative behavior at the higher level and learning safe individual behavior at the lower or agent level conditioned on the high-level policy. Specifically, we propose a skill-based HMARL-CBF algorithm in which the higher level problem involves learning a joint policy over the skills for all the agents and the lower-level problem involves learning policies to execute the skills safely with CBFs. We validate our approach on challenging environment scenarios whereby a large number of agents have to safely navigate through conflicting road networks. Compared with existing state of the art methods, our approach significantly improves the safety achieving near perfect (within 5%) success/safety rate while also improving performance across all the environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®‰å…¨å…³é”®å‹å¤šæ™ºèƒ½ä½“è‡ªä¸»ç³»ç»Ÿçš„å®‰å…¨ç­–ç•¥å­¦ä¹ é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæ§åˆ¶å±éšœå‡½æ•° (Control Barrier Functions, CBFs) çš„å®‰å…¨åˆ†å±‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Hierarchical Multi-Agent Reinforcement Learning, HMARL) æ–¹æ³•ã€‚è¯¥æ¡†æ¶å°†æ•´ä½“å­¦ä¹ ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå±‚çº§ï¼šé«˜å±‚å­¦ä¹ å¤šæ™ºèƒ½ä½“é—´çš„è”åˆåä½œè¡Œä¸ºï¼Œä½å±‚åˆ™åœ¨å—é«˜å±‚ç­–ç•¥å¼•å¯¼ä¸‹é€šè¿‡ CBFs ç¡®ä¿ä¸ªä½“è¡Œä¸ºçš„å®‰å…¨æ€§ã€‚ç ”ç©¶å…·ä½“å®ç°äº†ä¸€ç§åŸºäºæŠ€èƒ½çš„ HMARL-CBF ç®—æ³•ï¼Œåœ¨é«˜å±‚å†³ç­–æŠ€èƒ½åºåˆ—çš„åŒæ—¶ï¼Œäºä½å±‚åˆ©ç”¨ CBFs æä¾›ä¸¥è‹›çš„å®‰å…¨çº¦æŸã€‚é€šè¿‡åœ¨åŒ…å«å¤§é‡æ™ºèƒ½ä½“åŠå¤æ‚å†²çªè·¯ç½‘çš„å¯¼èˆªåœºæ™¯ä¸­è¿›è¡ŒéªŒè¯ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨æ‰€æœ‰æµ‹è¯•ç¯å¢ƒä¸­å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¸ä»…æå‡äº†ä»»åŠ¡æ€§èƒ½ï¼Œè¿˜å®ç°äº†æ¥è¿‘ 100%ï¼ˆ5% è¯¯å·®èŒƒå›´å†…ï¼‰çš„æˆåŠŸç‡ä¸å®‰å…¨ç‡ï¼Œä¸ºå¤„ç†é«˜åº¦å¤æ‚ä¸”å¯¹å®‰å…¨æ•æ„Ÿçš„è‡ªä¸»ç³»ç»Ÿä»»åŠ¡æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14850v2",
      "published_date": "2025-07-20 07:43:18 UTC",
      "updated_date": "2025-08-18 09:13:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:33.690211+00:00"
    },
    {
      "arxiv_id": "2507.14843v3",
      "title": "The Invisible Leash: Why RLVR May or May Not Escape Its Origin",
      "title_zh": "æ— å½¢çš„æŸç¼šï¼šRLVR æ˜¯å¦èƒ½æ‘†è„±å…¶æ¨¡å‹èµ·æºçš„å±€é™",
      "authors": [
        "Fang Wu",
        "Weihao Xuan",
        "Ximing Lu",
        "Mingjie Liu",
        "Yi Dong",
        "Zaid Harchaoui",
        "Yejin Choi"
      ],
      "abstract": "Recent advances in LLMs highlight Reinforcement Learning with Verifiable Rewards (RLVR) as a promising method for enhancing AI capabilities, particularly in solving complex logical tasks. However, it remains unclear whether the current practice of RLVR truly expands a model's reasoning boundary or mainly amplifies high-reward outputs that the base model already knows, leading to improved precision. This study presents an empirical investigation that provides new insights into the potential limits of the common RLVR recipe. We examine how, under current training conditions, RLVR can operate as a support-constrained optimization mechanism that may restrict the discovery of entirely novel solutions, remaining constrained by the base model's initial distribution. We also identify an entropy-reward trade-off: while the current RLVR recipe reliably enhances precision, it may progressively narrow exploration and potentially overlook correct yet underrepresented solutions. Extensive empirical experiments show that although the current RLVR recipe consistently improves pass@1, the shrinkage of empirical support generally outweighs the expansion of empirical support under larger sampling budgets, failing to recover correct answers that were previously accessible to the base model. Interestingly, we also observe that while RLVR sometimes increases token-level entropy, it leads to greater uncertainty at each generation step but declining answer-level entropy. This suggests that these seemingly more uncertain generation paths ultimately converge onto a smaller set of distinct answers. Taken together, our findings reveal potential limits of the current RLVR recipe in extending reasoning horizons. Breaking this invisible leash may require future algorithmic innovations, such as explicit exploration mechanisms or hybrid strategies that allocate probability mass to underrepresented solution regions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¸¦éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning with Verifiable Rewards, RLVR)åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹é€»è¾‘æ¨ç†èƒ½åŠ›ä¸­çš„ä½œç”¨ï¼Œå¹¶é‡ç‚¹åˆ†æå…¶æ˜¯å¦çœŸæ­£æ‰©å±•äº†æ¨¡å‹çš„æ¨ç†è¾¹ç•Œã€‚é€šè¿‡å®è¯ç ”ç©¶ï¼Œä½œè€…æ­ç¤ºäº†å½“å‰RLVRèŒƒå¼åœ¨ç°æœ‰è®­ç»ƒæ¡ä»¶ä¸‹å¾€å¾€è¡¨ç°ä¸ºä¸€ç§å—æ”¯æŒçº¦æŸçš„ä¼˜åŒ–æœºåˆ¶(support-constrained optimization mechanism)ï¼Œå…¶å‘ç°æ–°è§£çš„èƒ½åŠ›ä»å—é™äºåŸºç¡€æ¨¡å‹çš„åˆå§‹åˆ†å¸ƒã€‚ç ”ç©¶è¯†åˆ«å‡ºä¸€ç§ç†µä¸å¥–åŠ±ä¹‹é—´çš„æƒè¡¡(entropy-reward trade-off)ï¼Œå³RLVRåœ¨ç¨³å®šæé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œä¼šé€æ¸ç¼©å°æ¢ç´¢èŒƒå›´å¹¶å¯èƒ½å¿½è§†æ­£ç¡®ä½†ä½æ¦‚ç‡çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡RLVRæŒç»­æ”¹å–„äº†pass@1æŒ‡æ ‡ï¼Œä½†å…¶ç»éªŒæ”¯æŒ(empirical support)çš„æ•´ä½“æ”¶ç¼©å¯¼è‡´æ¨¡å‹æ— æ³•æ‰¾å›åŸºç¡€æ¨¡å‹åŸæœ¬å¯è§¦è¾¾çš„æŸäº›æ­£ç¡®ç­”æ¡ˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è§‚å¯Ÿåˆ°RLVRè™½å¢åŠ äº†æ ‡è®°çº§åˆ«ç†µ(token-level entropy)ï¼Œä½†ç­”æ¡ˆçº§åˆ«ç†µå´åœ¨ä¸‹é™ï¼Œè¡¨æ˜ç”Ÿæˆè·¯å¾„æœ€ç»ˆæ”¶æ•›äºæ›´çª„çš„ç­”æ¡ˆé›†ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†å½“å‰RLVRèŒƒå¼åœ¨æ‰©å±•æ¨ç†è§†é‡æ–¹é¢çš„å±€é™æ€§ï¼Œæš—ç¤ºæœªæ¥éœ€å¼•å…¥æ˜¾å¼æ¢ç´¢æœºåˆ¶æˆ–æ··åˆç­–ç•¥ä»¥æ‰“ç ´è¿™ç§â€œæ— å½¢çš„æŸç¼šâ€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14843v3",
      "published_date": "2025-07-20 07:04:08 UTC",
      "updated_date": "2026-01-07 01:59:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:40.794395+00:00"
    },
    {
      "arxiv_id": "2507.14833v2",
      "title": "Paired Image Generation with Diffusion-Guided Diffusion Models",
      "title_zh": "åŸºäºæ‰©æ•£å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æˆå¯¹å›¾åƒç”Ÿæˆ",
      "authors": [
        "Haoxuan Zhang",
        "Wenju Cui",
        "Yuzhu Cao",
        "Tao Tan",
        "Jie Liu",
        "Yunsong Peng",
        "Jian Zheng"
      ],
      "abstract": "The segmentation of mass lesions in digital breast tomosynthesis (DBT) images is very significant for the early screening of breast cancer. However, the high-density breast tissue often leads to high concealment of the mass lesions, which makes manual annotation difficult and time-consuming. As a result, there is a lack of annotated data for model training. Diffusion models are commonly used for data augmentation, but the existing methods face two challenges. First, due to the high concealment of lesions, it is difficult for the model to learn the features of the lesion area. This leads to the low generation quality of the lesion areas, thus limiting the quality of the generated images. Second, existing methods can only generate images and cannot generate corresponding annotations, which restricts the usability of the generated images in supervised training. In this work, we propose a paired image generation method. The method does not require external conditions and can achieve the generation of paired images by training an extra diffusion guider for the conditional diffusion model. During the experimental phase, we generated paired DBT slices and mass lesion masks. Then, we incorporated them into the supervised training process of the mass lesion segmentation task. The experimental results show that our method can improve the generation quality without external conditions. Moreover, it contributes to alleviating the shortage of annotated data, thus enhancing the performance of downstream tasks. The source code is available at https://github.com/zhanghx1320/PIG.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°å­—ä¹³è…ºæ–­å±‚åˆæˆ(Digital Breast Tomosynthesis, DBT)å›¾åƒä¸­ç”±äºé«˜å¯†åº¦ä¹³è…ºç»„ç»‡å¯¼è‡´çš„è‚¿å—ç—…ç¶æ ‡æ³¨å›°éš¾å’Œæ•°æ®åŒ®ä¹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºDiffusion-Guided Diffusion Modelsçš„é…å¯¹å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•æ— éœ€å¤–éƒ¨æ¡ä»¶ï¼Œé€šè¿‡ä¸ºConditional Diffusion Modelè®­ç»ƒä¸€ä¸ªé¢å¤–çš„Diffusion Guiderï¼Œå®ç°äº†DBTåˆ‡ç‰‡ä¸å¯¹åº”Mass Lesion Masksçš„åŒæ­¥ç”Ÿæˆã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸ä¾èµ–å¤–éƒ¨ä¿¡æ¯çš„å‰æä¸‹æå‡äº†å›¾åƒç”Ÿæˆè´¨é‡ï¼Œæœ‰æ•ˆè¡¥å……äº†ç›‘ç£è®­ç»ƒæ‰€éœ€çš„æ ‡æ³¨æ•°æ®ã€‚è¯¥æŠ€æœ¯æˆåŠŸç¼“è§£äº†åŒ»ç–—å½±åƒé¢†åŸŸæ ‡æ³¨æ ·æœ¬ä¸è¶³çš„ç“¶é¢ˆï¼Œæ˜¾è‘—å¢å¼ºäº†ä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14833v2",
      "published_date": "2025-07-20 06:13:02 UTC",
      "updated_date": "2026-01-20 12:58:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:33.294898+00:00"
    },
    {
      "arxiv_id": "2507.19525v1",
      "title": "MMCircuitEval: A Comprehensive Multimodal Circuit-Focused Benchmark for Evaluating LLMs",
      "title_zh": "MMCircuitEvalï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°çš„ç»¼åˆæ€§å¤šæ¨¡æ€ç”µè·¯åŸºå‡†",
      "authors": [
        "Chenchen Zhao",
        "Zhengyuan Shi",
        "Xiangyu Wen",
        "Chengjie Liu",
        "Yi Liu",
        "Yunhao Zhou",
        "Yuxiang Zhao",
        "Hefei Feng",
        "Yinan Zhu",
        "Gwok-Waa Wan",
        "Xin Cheng",
        "Weiyu Chen",
        "Yongqi Fu",
        "Chujie Chen",
        "Chenhao Xue",
        "Guangyu Sun",
        "Ying Wang",
        "Yibo Lin",
        "Jun Yang",
        "Ning Xu",
        "Xi Wang",
        "Qiang Xu"
      ],
      "abstract": "The emergence of multimodal large language models (MLLMs) presents promising opportunities for automation and enhancement in Electronic Design Automation (EDA). However, comprehensively evaluating these models in circuit design remains challenging due to the narrow scope of existing benchmarks. To bridge this gap, we introduce MMCircuitEval, the first multimodal benchmark specifically designed to assess MLLM performance comprehensively across diverse EDA tasks. MMCircuitEval comprises 3614 meticulously curated question-answer (QA) pairs spanning digital and analog circuits across critical EDA stages - ranging from general knowledge and specifications to front-end and back-end design. Derived from textbooks, technical question banks, datasheets, and real-world documentation, each QA pair undergoes rigorous expert review for accuracy and relevance. Our benchmark uniquely categorizes questions by design stage, circuit type, tested abilities (knowledge, comprehension, reasoning, computation), and difficulty level, enabling detailed analysis of model capabilities and limitations. Extensive evaluations reveal significant performance gaps among existing LLMs, particularly in back-end design and complex computations, highlighting the critical need for targeted training datasets and modeling approaches. MMCircuitEval provides a foundational resource for advancing MLLMs in EDA, facilitating their integration into real-world circuit design workflows. Our benchmark is available at https://github.com/cure-lab/MMCircuitEval.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†MMCircuitEvalï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨ç”µå­è®¾è®¡è‡ªåŠ¨åŒ–(EDA)é¢†åŸŸç»¼åˆè¡¨ç°è€Œè®¾è®¡çš„åŸºå‡†æµ‹è¯•é›†ã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«3614ä¸ªç²¾å¿ƒæŒ‘é€‰çš„é—®ç­”å¯¹(QA pairs)ï¼Œæ¶µç›–äº†ä»åŸºç¡€çŸ¥è¯†ã€è§„èŒƒåˆ°å‰ç«¯å’Œåç«¯è®¾è®¡çš„æ•°å­—ä¸æ¨¡æ‹Ÿç”µè·¯å…¨æµç¨‹ã€‚æµ‹è¯•æ•°æ®æºè‡ªæ•™ç§‘ä¹¦ã€æŠ€æœ¯é¢˜åº“åŠçœŸå®æ–‡æ¡£ï¼Œå¹¶ç»è¿‡ä¸“å®¶çš„ä¸¥æ ¼è¯„å®¡ä»¥ç¡®ä¿å‡†ç¡®æ€§ã€‚MMCircuitEvalå°†é—®é¢˜æŒ‰è®¾è®¡é˜¶æ®µã€ç”µè·¯ç±»å‹ã€è€ƒå¯Ÿèƒ½åŠ›åŠéš¾åº¦ç­‰çº§è¿›è¡Œç»†è‡´åˆ†ç±»ï¼Œèƒ½å¤Ÿå…¨é¢å‰–ææ¨¡å‹çš„èƒ½åŠ›å±€é™ã€‚å¹¿æ³›çš„å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹åœ¨åç«¯è®¾è®¡å’Œå¤æ‚è®¡ç®—æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®è·ï¼Œå‡¸æ˜¾äº†å¯¹ç‰¹å®šé¢†åŸŸè®­ç»ƒæ•°æ®çš„éœ€æ±‚ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ºæ¨è¿›MLLMsåœ¨EDAé¢†åŸŸçš„é›†æˆä¸åº”ç”¨æä¾›äº†å…³é”®çš„åŸºç¡€èµ„æºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 1 figure, 5 tables. To appear in ICCAD 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.19525v1",
      "published_date": "2025-07-20 05:46:32 UTC",
      "updated_date": "2025-07-20 05:46:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:42.996788+00:00"
    },
    {
      "arxiv_id": "2507.14828v1",
      "title": "eMargin: Revisiting Contrastive Learning with Margin-Based Separation",
      "title_zh": "eMarginï¼šå†æ¢åŸºäºé—´éš”åˆ†ç¦»çš„å¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Abdul-Kazeem Shamba",
        "Kerstin Bach",
        "Gavin Taylor"
      ],
      "abstract": "We revisit previous contrastive learning frameworks to investigate the effect of introducing an adaptive margin into the contrastive loss function for time series representation learning. Specifically, we explore whether an adaptive margin (eMargin), adjusted based on a predefined similarity threshold, can improve the separation between adjacent but dissimilar time steps and subsequently lead to better performance in downstream tasks. Our study evaluates the impact of this modification on clustering performance and classification in three benchmark datasets. Our findings, however, indicate that achieving high scores on unsupervised clustering metrics does not necessarily imply that the learned embeddings are meaningful or effective in downstream tasks. To be specific, eMargin added to InfoNCE consistently outperforms state-of-the-art baselines in unsupervised clustering metrics, but struggles to achieve competitive results in downstream classification with linear probing. The source code is publicly available at https://github.com/sfi-norwai/eMargin.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ—¶é—´åºåˆ—(time series)è¡¨ç¤ºå­¦ä¹ ä¸­å¼•å…¥è‡ªé€‚åº”è¾¹é™…(eMargin)å¯¹å¯¹æ¯”å­¦ä¹ (contrastive learning)æ¡†æ¶çš„å½±å“ã€‚ä½œè€…æå‡ºæ ¹æ®é¢„å®šä¹‰çš„ç›¸ä¼¼æ€§é˜ˆå€¼åŠ¨æ€è°ƒæ•´è¾¹é™…ï¼Œæ—¨åœ¨å¢å¼ºç›¸é‚»ä½†ä¸ç›¸ä¼¼æ—¶é—´æ­¥ä¹‹é—´çš„åˆ†ç¦»åº¦ï¼Œè¿›è€Œä¼˜åŒ–ä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ã€‚é€šè¿‡åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œç ”ç©¶æ·±å…¥è¯„ä¼°äº†è¯¥æ”¹è¿›å¯¹èšç±»å’Œåˆ†ç±»æ€§èƒ½çš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œè™½ç„¶åœ¨ InfoNCE æŸå¤±å‡½æ•°ä¸­åŠ å…¥ eMargin èƒ½åœ¨æ— ç›‘ç£èšç±»æŒ‡æ ‡ä¸ŠæŒç»­è¶…è¶Šç°æœ‰æœ€å…ˆè¿›(SOTA)åŸºå‡†ï¼Œä½†åœ¨ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡çš„çº¿æ€§æ¢æµ‹(linear probing)ä¸­å´è¡¨ç°æ¬ ä½³ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†æ— ç›‘ç£èšç±»æŒ‡æ ‡çš„é«˜åˆ†å¹¶ä¸å¿…ç„¶æ„å‘³ç€å­¦ä¹ åˆ°çš„åµŒå…¥(embeddings)åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å…·æœ‰å®é™…æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "LDD'25: Learning from Difficult Data Workshop (ECAI 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.14828v1",
      "published_date": "2025-07-20 05:39:25 UTC",
      "updated_date": "2025-07-20 05:39:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:44.397585+00:00"
    },
    {
      "arxiv_id": "2507.14824v1",
      "title": "Benchmarking Foundation Models with Multimodal Public Electronic Health Records",
      "title_zh": "åŸºäºå¤šæ¨¡æ€å…¬å¼€ç”µå­å¥åº·è®°å½•çš„åŸºç¡€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Kunyu Yu",
        "Rui Yang",
        "Jingchi Liao",
        "Siqi Li",
        "Huitao Li",
        "Irene Li",
        "Yifan Peng",
        "Rishikesan Kamaleswaran",
        "Nan Liu"
      ],
      "abstract": "Foundation models have emerged as a powerful approach for processing electronic health records (EHRs), offering flexibility to handle diverse medical data modalities. In this study, we present a comprehensive benchmark that evaluates the performance, fairness, and interpretability of foundation models, both as unimodal encoders and as multimodal learners, using the publicly available MIMIC-IV database. To support consistent and reproducible evaluation, we developed a standardized data processing pipeline that harmonizes heterogeneous clinical records into an analysis-ready format. We systematically compared eight foundation models, encompassing both unimodal and multimodal models, as well as domain-specific and general-purpose variants. Our findings demonstrate that incorporating multiple data modalities leads to consistent improvements in predictive performance without introducing additional bias. Through this benchmark, we aim to support the development of effective and trustworthy multimodal artificial intelligence (AI) systems for real-world clinical applications. Our code is available at https://github.com/nliulab/MIMIC-Multimodal.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€ç”µå­å¥åº·è®°å½•(Multimodal EHR)æå‡ºäº†ä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œåˆ©ç”¨MIMIC-IVæ•°æ®åº“è¯„ä¼°åŸºç¡€æ¨¡å‹(Foundation Models)ä½œä¸ºå•æ¨¡æ€ç¼–ç å™¨å’Œå¤šæ¨¡æ€å­¦ä¹ å™¨çš„æ€§èƒ½ã€å…¬å¹³æ€§åŠå¯è§£é‡Šæ€§ã€‚ä¸ºäº†ç¡®ä¿è¯„ä¼°çš„ä¸€è‡´æ€§å’Œå¯é‡å¤æ€§ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€å¥—æ ‡å‡†åŒ–çš„æ•°æ®å¤„ç†æµæ°´çº¿ï¼Œå°†å¼‚æ„çš„ä¸´åºŠè®°å½•æ•´åˆä¸ºåˆ†æå°±ç»ªçš„æ ¼å¼ã€‚å®éªŒç³»ç»Ÿå¯¹æ¯”äº†åŒ…æ‹¬é¢†åŸŸç‰¹å®šå’Œé€šç”¨å‹åœ¨å†…çš„å…«ç§åŸºç¡€æ¨¡å‹ï¼Œç»“æœè¡¨æ˜å¼•å…¥å¤šæ¨¡æ€æ•°æ®èƒ½æŒç»­æå‡æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½ï¼Œä¸”ä¸ä¼šå¼•å…¥é¢å¤–çš„åè§ã€‚è¯¥å·¥ä½œä¸ºå¼€å‘é€‚ç”¨äºçœŸå®ä¸´åºŠåº”ç”¨çš„é«˜æ•ˆä¸”å¯ä¿¡çš„å¤šæ¨¡æ€äººå·¥æ™ºèƒ½(Multimodal AI)ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œå¹¶æä¾›äº†å¼€æºä»£ç æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14824v1",
      "published_date": "2025-07-20 05:08:28 UTC",
      "updated_date": "2025-07-20 05:08:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:50.095098+00:00"
    },
    {
      "arxiv_id": "2508.03703v2",
      "title": "Privacy Risks of LLM-Empowered Recommender Systems: An Inversion Attack Perspective",
      "title_zh": "LLM èµ‹èƒ½çš„æ¨èç³»ç»Ÿéšç§é£é™©ï¼šé€†å‘æ”»å‡»è§†è§’",
      "authors": [
        "Yubo Wang",
        "Min Tang",
        "Nuo Shen",
        "Shujie Cui",
        "Weiqing Wang"
      ],
      "abstract": "The large language model (LLM) powered recommendation paradigm has been proposed to address the limitations of traditional recommender systems, which often struggle to handle cold start users or items with new IDs. Despite its effectiveness, this study uncovers that LLM empowered recommender systems are vulnerable to reconstruction attacks that can expose both system and user privacy. To examine this threat, we present the first systematic study on inversion attacks targeting LLM empowered recommender systems, where adversaries attempt to reconstruct original prompts that contain personal preferences, interaction histories, and demographic attributes by exploiting the output logits of recommendation models. We reproduce the vec2text framework and optimize it using our proposed method called Similarity Guided Refinement, enabling more accurate reconstruction of textual prompts from model generated logits. Extensive experiments across two domains (movies and books) and two representative LLM based recommendation models demonstrate that our method achieves high fidelity reconstructions. Specifically, we can recover nearly 65 percent of the user interacted items and correctly infer age and gender in 87 percent of the cases. The experiments also reveal that privacy leakage is largely insensitive to the victim model's performance but highly dependent on domain consistency and prompt complexity. These findings expose critical privacy vulnerabilities in LLM empowered recommender systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ¨èç³»ç»Ÿåœ¨éšç§å®‰å…¨æ–¹é¢çš„æ¼æ´ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹è¯¥ç³»ç»Ÿçš„åå‘æ”»å‡»(Inversion Attack)é£é™©ã€‚ä½œè€…é¦–æ¬¡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†æ­¤ç±»æ”»å‡»ï¼Œæ—¨åœ¨åˆ©ç”¨æ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒ(Logits)é‡å»ºåŒ…å«ä¸ªäººåå¥½ã€äº¤äº’å†å²å’Œäººå£ç»Ÿè®¡å±æ€§çš„åŸå§‹æç¤ºè¯(Prompts)ã€‚ä¸ºäº†å®ç°ç²¾å‡†é‡æ„ï¼Œç ”ç©¶å›¢é˜Ÿåœ¨`vec2text`æ¡†æ¶çš„åŸºç¡€ä¸Šæå‡ºäº†ç›¸ä¼¼æ€§å¼•å¯¼ç»†åŒ–(Similarity Guided Refinement)ä¼˜åŒ–æ–¹æ³•ã€‚åœ¨ç”µå½±å’Œå›¾ä¹¦é¢†åŸŸçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå®ç°é«˜ä¿çœŸåº¦çš„ä¿¡æ¯é‡æ„ï¼ŒæˆåŠŸæ¢å¤äº†è¿‘65%çš„ç”¨æˆ·äº¤äº’ç‰©å“ï¼Œå¹¶ä»¥87%çš„å‡†ç¡®ç‡æ¨æ–­å‡ºç”¨æˆ·çš„å¹´é¾„å’Œæ€§åˆ«ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œéšç§æ³„éœ²ç¨‹åº¦ä¸å—å®³è€…æ¨¡å‹çš„æ€§èƒ½è¡¨ç°å¹¶ä¸æ•æ„Ÿï¼Œä½†é«˜åº¦ä¾èµ–äºé¢†åŸŸä¸€è‡´æ€§å’Œæç¤ºè¯çš„å¤æ‚ç¨‹åº¦ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†LLMèµ‹èƒ½çš„æ¨èç³»ç»Ÿå­˜åœ¨çš„å…³é”®éšç§è„†å¼±æ€§ï¼Œä¸ºæ„å»ºæ›´å®‰å…¨çš„æ¨èç³»ç»Ÿæä¾›äº†é‡è¦è­¦ç¤ºã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at ACM RecSys 2025 (10 pages, 4 figures)",
      "pdf_url": "https://arxiv.org/pdf/2508.03703v2",
      "published_date": "2025-07-20 05:03:02 UTC",
      "updated_date": "2025-09-12 02:59:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:55.946619+00:00"
    },
    {
      "arxiv_id": "2507.14811v4",
      "title": "SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models",
      "title_zh": "SegQuantï¼šä¸€ç§é¢å‘æ‰©æ•£æ¨¡å‹çš„è¯­ä¹‰æ„ŸçŸ¥å‹é€šç”¨é‡åŒ–æ¡†æ¶",
      "authors": [
        "Jiaji Zhang",
        "Ruichao Sun",
        "Hailiang Zhao",
        "Jiaju Wu",
        "Peng Chen",
        "Hao Li",
        "Yuying Liu",
        "Kingsum Chow",
        "Gang Xiong",
        "Shuiguang Deng"
      ],
      "abstract": "Diffusion models have demonstrated exceptional generative capabilities but are computationally intensive, posing significant challenges for deployment in resource-constrained or latency-sensitive environments. Quantization offers an effective means to reduce model size and computational cost, with post-training quantization (PTQ) being particularly appealing due to its compatibility with pre-trained models without requiring retraining or training data. However, existing PTQ methods for diffusion models often rely on architecture-specific heuristics that limit their generalizability and hinder integration with industrial deployment pipelines. To address these limitations, we propose SegQuant, a unified quantization framework that adaptively combines complementary techniques to enhance cross-model versatility. SegQuant consists of a segment-aware, graph-based quantization strategy (SegLinear) that captures structural semantics and spatial heterogeneity, along with a dual-scale quantization scheme (DualScale) that preserves polarity-asymmetric activations, which is crucial for maintaining visual fidelity in generated outputs. SegQuant is broadly applicable beyond Transformer-based diffusion models, achieving strong performance while ensuring seamless compatibility with mainstream deployment tools.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SegQuantï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³æ‰©æ•£æ¨¡å‹è®¡ç®—å¯†é›†å’Œç°æœ‰è®­ç»ƒåé‡åŒ–ï¼ˆPTQï¼‰æ–¹æ³•é€šç”¨æ€§ä¸è¶³é—®é¢˜çš„ç»Ÿä¸€é‡åŒ–æ¡†æ¶ã€‚SegQuant ç»“åˆäº†å¤šç§äº’è¡¥æŠ€æœ¯ï¼Œå…¶ä¸­ SegLinear é‡‡ç”¨åŸºäºå›¾çš„ç‰‡æ®µæ„ŸçŸ¥é‡åŒ–ç­–ç•¥æ¥æ•æ‰ç»“æ„è¯­ä¹‰å’Œç©ºé—´å¼‚æ„æ€§ã€‚æ­¤å¤–ï¼Œæ¡†æ¶ä¸­çš„ DualScale åŒå°ºåº¦é‡åŒ–æ–¹æ¡ˆèƒ½å¤Ÿæœ‰æ•ˆä¿ç•™ææ€§ä¸å¯¹ç§°æ¿€æ´»ï¼ˆpolarity-asymmetric activationsï¼‰ï¼Œè¿™å¯¹äºç»´æŒç”Ÿæˆå›¾åƒçš„è§†è§‰å¿ å®åº¦è‡³å…³é‡è¦ã€‚å®éªŒè¡¨æ˜ï¼ŒSegQuant å…·æœ‰æå¼ºçš„è·¨æ¨¡å‹é€šç”¨æ€§ï¼Œä¸ä»…åœ¨åŸºäº Transformer çš„æ‰©æ•£æ¨¡å‹ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¿˜èƒ½æ— ç¼å…¼å®¹ä¸»æµå·¥ä¸šéƒ¨ç½²å·¥å…·ã€‚è¯¥æ¡†æ¶åœ¨é™ä½æ¨¡å‹å°ºå¯¸å’Œè®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œç¡®ä¿äº†åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„é«˜æ•ˆéƒ¨ç½²å’Œå“è¶Šçš„ç”Ÿæˆæ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14811v4",
      "published_date": "2025-07-20 04:00:53 UTC",
      "updated_date": "2025-08-27 08:42:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:55.247079+00:00"
    },
    {
      "arxiv_id": "2507.14807v1",
      "title": "Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection",
      "title_zh": "è¯†ç ´æ·±åº¦ä¼ªé€ ï¼šä¸€ç§å—äººç±»å¯å‘çš„å¤šäººè„¸æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Juan Hu",
        "Shaojing Fan",
        "Terence Sim"
      ],
      "abstract": "Multi-face deepfake videos are becoming increasingly prevalent, often appearing in natural social settings that challenge existing detection methods. Most current approaches excel at single-face detection but struggle in multi-face scenarios, due to a lack of awareness of crucial contextual cues. In this work, we develop a novel approach that leverages human cognition to analyze and defend against multi-face deepfake videos. Through a series of human studies, we systematically examine how people detect deepfake faces in social settings. Our quantitative analysis reveals four key cues humans rely on: scene-motion coherence, inter-face appearance compatibility, interpersonal gaze alignment, and face-body consistency. Guided by these insights, we introduce \\textsf{HICOM}, a novel framework designed to detect every fake face in multi-face scenarios. Extensive experiments on benchmark datasets show that \\textsf{HICOM} improves average accuracy by 3.3\\% in in-dataset detection and 2.8\\% under real-world perturbations. Moreover, it outperforms existing methods by 5.8\\% on unseen datasets, demonstrating the generalization of human-inspired cues. \\textsf{HICOM} further enhances interpretability by incorporating an LLM to provide human-readable explanations, making detection results more transparent and convincing. Our work sheds light on involving human factors to enhance defense against deepfakes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šé¢(multi-face)æ·±åº¦ä¼ªé€ (deepfake)è§†é¢‘åœ¨å¤æ‚ç¤¾äº¤åœºæ™¯ä¸‹æ£€æµ‹éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å—äººç±»è®¤çŸ¥å¯å‘çš„æ–°å‹é˜²å¾¡æ¡†æ¶HICOMã€‚é€šè¿‡å®šé‡åˆ†æäººç±»æ£€æµ‹æ·±åº¦ä¼ªé€ çš„é€»è¾‘ï¼Œç ”ç©¶è¯†åˆ«å‡ºåœºæ™¯è¿åŠ¨ä¸€è‡´æ€§(scene-motion coherence)ã€äººè„¸é—´å¤–è§‚å…¼å®¹æ€§(inter-face appearance compatibility)ã€äººé™…æ³¨è§†å¯¹é½(interpersonal gaze alignment)ä»¥åŠé¢éƒ¨ä¸èº«ä½“ä¸€è‡´æ€§(face-body consistency)å››ä¸ªå…³é”®çº¿ç´¢ã€‚åŸºäºè¿™äº›æ´å¯Ÿï¼ŒHICOMæ¡†æ¶åœ¨å¤šé¢åœºæ™¯æ£€æµ‹ä¸­è¡¨ç°å‡ºè‰²ï¼Œå…¶åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹³å‡å‡†ç¡®ç‡æå‡äº†3.3%ï¼Œåœ¨çœŸå®ä¸–ç•Œæ‰°åŠ¨ä¸‹æå‡äº†2.8%ï¼Œä¸”åœ¨æœªçŸ¥æ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›æ¯”ç°æœ‰æ–¹æ³•é«˜å‡º5.8%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡é›†æˆå¤§è¯­è¨€æ¨¡å‹(LLM)ç”Ÿæˆäººç±»å¯è¯»çš„è§£é‡Šï¼Œæ˜¾è‘—å¢å¼ºäº†æ£€æµ‹ç»“æœçš„é€æ˜åº¦ä¸å¯è§£é‡Šæ€§ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†ç»“åˆäººç±»è®¤çŸ¥å› ç´ åœ¨æå‡æ·±åº¦ä¼ªé€ é˜²å¾¡æ€§èƒ½å’Œå¯ä¿¡åº¦æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14807v1",
      "published_date": "2025-07-20 03:53:52 UTC",
      "updated_date": "2025-07-20 03:53:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:49:59.956282+00:00"
    },
    {
      "arxiv_id": "2507.14805v1",
      "title": "Subliminal Learning: Language models transmit behavioral traits via hidden signals in data",
      "title_zh": "æ½œæ„è¯†å­¦ä¹ ï¼šè¯­è¨€æ¨¡å‹é€šè¿‡æ•°æ®ä¸­çš„éšè—ä¿¡å·ä¼ é€’è¡Œä¸ºç‰¹å¾",
      "authors": [
        "Alex Cloud",
        "Minh Le",
        "James Chua",
        "Jan Betley",
        "Anna Sztyber-Betley",
        "Jacob Hilton",
        "Samuel Marks",
        "Owain Evans"
      ],
      "abstract": "We study subliminal learning, a surprising phenomenon where language models transmit behavioral traits via semantically unrelated data. In our main experiments, a \"teacher\" model with some trait T (such as liking owls or being misaligned) generates a dataset consisting solely of number sequences. Remarkably, a \"student\" model trained on this dataset learns T. This occurs even when the data is filtered to remove references to T. We observe the same effect when training on code or reasoning traces generated by the same teacher model. However, we do not observe the effect when the teacher and student have different base models. To help explain our findings, we prove a theoretical result showing that subliminal learning occurs in all neural networks under certain conditions, and demonstrate subliminal learning in a simple MLP classifier. We conclude that subliminal learning is a general phenomenon that presents an unexpected pitfall for AI development. Distillation could propagate unintended traits, even when developers try to prevent this via data filtering.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ½œæ„è¯†å­¦ä¹ ï¼ˆSubliminal Learningï¼‰ç°è±¡ï¼Œå³è¯­è¨€æ¨¡å‹èƒ½å¤Ÿé€šè¿‡è¯­ä¹‰ä¸Šæ— å…³çš„æ•°æ®ä¼ é€’è¡Œä¸ºç‰¹å¾ã€‚å®éªŒè¡¨æ˜ï¼Œå½“å…·æœ‰ç‰¹å®šç‰¹å¾ T çš„â€œæ•™å¸ˆâ€æ¨¡å‹ç”Ÿæˆæ•°å­—åºåˆ—ã€ä»£ç æˆ–æ¨ç†é“¾ç­‰æ•°æ®æ—¶ï¼Œå³ä¾¿è¿‡æ»¤æ‰ä¸ T ç›¸å…³çš„æ˜¾å¼å¼•ç”¨ï¼Œå—è®­çš„â€œå­¦ç”Ÿâ€æ¨¡å‹ï¼ˆstudent modelï¼‰ä»ä¼šä¹ å¾—è¯¥ç‰¹å¾ã€‚è¿™ç§æ•ˆåº”åœ¨æ•™å¸ˆä¸å­¦ç”Ÿå…±äº«ç›¸åŒåŸºç¡€æ¨¡å‹æ—¶å°¤ä¸ºæ˜¾è‘—ï¼Œä¸”ä½œè€…é€šè¿‡ç†è®ºè¯æ˜äº†æ½œæ„è¯†å­¦ä¹ æ˜¯ç¥ç»ç½‘ç»œåœ¨ç‰¹å®šæ¡ä»¶ä¸‹çš„é€šç”¨ç°è±¡ã€‚è¯¥å‘ç°æ­ç¤ºäº† AI å¼€å‘ä¸­çš„é‡å¤§é£é™©ï¼Œå³æ¨¡å‹è’¸é¦ï¼ˆDistillationï¼‰å¯èƒ½åœ¨å¼€å‘è€…ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹ä¼ æ’­éé¢„æœŸæˆ–å¤±è°ƒçš„ç‰¹å¾ï¼Œå³ä½¿å®æ–½äº†ä¸¥æ ¼çš„æ•°æ®è¿‡æ»¤ä¹Ÿéš¾ä»¥å®Œå…¨è§„é¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14805v1",
      "published_date": "2025-07-20 03:51:13 UTC",
      "updated_date": "2025-07-20 03:51:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:09.350432+00:00"
    },
    {
      "arxiv_id": "2507.16843v1",
      "title": "Weak Supervision Techniques towards Enhanced ASR Models in Industry-level CRM Systems",
      "title_zh": "é¢å‘å·¥ä¸šçº§ CRM ç³»ç»Ÿ ASR æ¨¡å‹æ€§èƒ½æå‡çš„å¼±ç›‘ç£æŠ€æœ¯",
      "authors": [
        "Zhongsheng Wang",
        "Sijie Wang",
        "Jia Wang",
        "Yung-I Liang",
        "Yuxi Zhang",
        "Jiamou Liu"
      ],
      "abstract": "In the design of customer relationship management (CRM) systems, accurately identifying customer types and offering personalized services are key to enhancing customer satisfaction and loyalty. However, this process faces the challenge of discerning customer voices and intentions, and general pre-trained automatic speech recognition (ASR) models make it difficult to effectively address industry-specific speech recognition tasks. To address this issue, we innovatively proposed a solution for fine-tuning industry-specific ASR models, which significantly improved the performance of the fine-tuned ASR models in industry applications. Experimental results show that our method substantially improves the crucial auxiliary role of the ASR model in industry CRM systems, and this approach has also been adopted in actual industrial applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®¢æˆ·å…³ç³»ç®¡ç†(CRM)ç³»ç»Ÿåœ¨è¯†åˆ«å®¢æˆ·å£°éŸ³å’Œæ„å›¾æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å¼±ç›‘ç£æŠ€æœ¯(Weak Supervision Techniques)æ¥å¢å¼ºå·¥ä¸šçº§è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)æ¨¡å‹çš„åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚ç”±äºé€šç”¨é¢„è®­ç»ƒæ¨¡å‹éš¾ä»¥æœ‰æ•ˆå¤„ç†ç‰¹å®šè¡Œä¸šçš„è¯­éŸ³è¯†åˆ«ä»»åŠ¡ï¼Œè¯¥æ–¹æ¡ˆé€šè¿‡ä¸“é—¨çš„å¾®è°ƒ(fine-tuning)æµç¨‹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨è¡Œä¸šåº”ç”¨ä¸­çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•å¤§å¹…å¢å¼ºäº†ASRæ¨¡å‹åœ¨å·¥ä¸šçº§CRMç³»ç»Ÿä¸­çš„å…³é”®è¾…åŠ©ä½œç”¨ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯†åˆ«å®¢æˆ·ç±»å‹å¹¶æä¾›ä¸ªæ€§åŒ–æœåŠ¡ã€‚ç›®å‰ï¼Œè¯¥æ–¹æ¡ˆå·²æˆåŠŸåº”ç”¨äºå®é™…å·¥ä¸šåœºæ™¯ï¼Œä¸ºæå‡å®¢æˆ·æ»¡æ„åº¦å’Œå¿ è¯šåº¦æä¾›äº†å¯é çš„æŠ€æœ¯è·¯å¾„ï¼Œå¹¶å±•ç¤ºäº†å®šåˆ¶åŒ–ASRæ¨¡å‹åœ¨å¤æ‚è¡Œä¸šç¯å¢ƒä¸‹çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICONIP 2024",
      "pdf_url": "https://arxiv.org/pdf/2507.16843v1",
      "published_date": "2025-07-20 03:39:09 UTC",
      "updated_date": "2025-07-20 03:39:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:26.560795+00:00"
    },
    {
      "arxiv_id": "2507.14802v1",
      "title": "ACME: Adaptive Customization of Large Models via Distributed Systems",
      "title_zh": "ACMEï¼šåŸºäºåˆ†å¸ƒå¼ç³»ç»Ÿçš„å¤§æ¨¡å‹è‡ªé€‚åº”å®šåˆ¶",
      "authors": [
        "Ziming Dai",
        "Chao Qiu",
        "Fei Gao",
        "Yunfeng Zhao",
        "Xiaofei Wang"
      ],
      "abstract": "Pre-trained Transformer-based large models have revolutionized personal virtual assistants, but their deployment in cloud environments faces challenges related to data privacy and response latency. Deploying large models closer to the data and users has become a key research area to address these issues. However, applying these models directly often entails significant difficulties, such as model mismatching, resource constraints, and energy inefficiency. Automated design of customized models is necessary, but it faces three key challenges, namely, the high cost of centralized model customization, imbalanced performance from user heterogeneity, and suboptimal performance from data heterogeneity. In this paper, we propose ACME, an adaptive customization approach of Transformer-based large models via distributed systems. To avoid the low cost-efficiency of centralized methods, ACME employs a bidirectional single-loop distributed system to progressively achieve fine-grained collaborative model customization. In order to better match user heterogeneity, it begins by customizing the backbone generation and identifying the Pareto Front under model size constraints to ensure optimal resource utilization. Subsequently, it performs header generation and refines the model using data distribution-based personalized architecture aggregation to match data heterogeneity. Evaluation on different datasets shows that ACME achieves cost-efficient models under model size constraints. Compared to centralized systems, data transmission volume is reduced to 6 percent. Additionally, the average accuracy improves by 10 percent compared to the baseline, with the trade-off metrics increasing by nearly 30 percent.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ACMEï¼Œä¸€ç§é€šè¿‡åˆ†å¸ƒå¼ç³»ç»Ÿå¯¹åŸºäº Transformer çš„å¤§æ¨¡å‹è¿›è¡Œè‡ªé€‚åº”å®šåˆ¶çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§æ¨¡å‹åœ¨äº‘ç«¯éƒ¨ç½²æ—¶é¢ä¸´çš„æ•°æ®éšç§å’Œå“åº”å»¶è¿ŸæŒ‘æˆ˜ã€‚ä¸ºäº†å…‹æœé›†ä¸­å¼æ¨¡å‹å®šåˆ¶æˆæœ¬é«˜æ˜‚ä»¥åŠç”¨æˆ·ä¸æ•°æ®å¼‚æ„æ€§å¸¦æ¥çš„æ€§èƒ½ä¸‹é™ï¼ŒACME é‡‡ç”¨äº†åŒå‘å•å¾ªç¯åˆ†å¸ƒå¼ç³»ç»Ÿæ¥å®ç°ç»†ç²’åº¦çš„åä½œå¼æ¨¡å‹å®šåˆ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡å®šåˆ¶ Backbone ç”Ÿæˆå¹¶åœ¨æ¨¡å‹å¤§å°çº¦æŸä¸‹è¯†åˆ« Pareto Frontï¼Œä»¥ç¡®ä¿èµ„æºçš„æœ€ä¼˜åˆ©ç”¨å¹¶åŒ¹é…ç”¨æˆ·å¼‚æ„æ€§ã€‚éšåï¼Œå®ƒé€šè¿‡ Header ç”Ÿæˆå’ŒåŸºäºæ•°æ®åˆ†å¸ƒçš„ä¸ªæ€§åŒ–æ¶æ„èšåˆæŠ€æœ¯æ¥åº”å¯¹æ•°æ®å¼‚æ„æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸é›†ä¸­å¼ç³»ç»Ÿç›¸æ¯”ï¼ŒACME å°†æ•°æ®ä¼ è¾“é‡æ˜¾è‘—é™ä½è‡³ 6%ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡äº† 10%ï¼Œä¸”æƒè¡¡æŒ‡æ ‡ï¼ˆtrade-off metricsï¼‰å¢é•¿äº†è¿‘ 30%ã€‚è¿™ç§æ–¹æ³•è¯æ˜äº†åœ¨æ¨¡å‹å°ºå¯¸çº¦æŸä¸‹å®ç°é«˜æ€§ä»·æ¯”å®šåˆ¶çš„å¯è¡Œæ€§ï¼Œä¸ºåˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„æ¨¡å‹ä¼˜åŒ–æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted to IEEE ICDCS 2025. 11 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.14802v1",
      "published_date": "2025-07-20 03:30:24 UTC",
      "updated_date": "2025-07-20 03:30:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:28.727021+00:00"
    },
    {
      "arxiv_id": "2507.14800v1",
      "title": "Large Language Model as An Operator: An Experience-Driven Solution for Distribution Network Voltage Control",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºæ“ä½œå‘˜ï¼šä¸€ç§ç»éªŒé©±åŠ¨çš„é…ç”µç½‘ç”µå‹æ§åˆ¶æ–¹æ¡ˆ",
      "authors": [
        "Xu Yang",
        "Chenhui Lin",
        "Haotian Liu",
        "Qi Wang",
        "Wenchuan Wu"
      ],
      "abstract": "With the advanced reasoning and information analysis capabilities, large language models (LLMs) can offer a novel approach for the autonomous generation of dispatch strategies in power systems. This letter proposes an LLM-based experience-driven voltage control solution for distribution networks, which enables the self-evolution of LLM-based voltage control strategies through the collaboration and interaction of multiple modules-specifically, experience storage, experience retrieval, experience generation, and experience modification. Comprehensive experimental results validate the effectiveness of the proposed method and highlight the applicability of LLM in addressing power system dispatch challenges.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Large Language Models (LLMs) çš„ç»éªŒé©±åŠ¨å‹é…ç”µç½‘ Voltage Control æ–¹æ¡ˆï¼Œæ—¨åœ¨åˆ©ç”¨å¤§æ¨¡å‹å…ˆè¿›çš„æ¨ç†ä¸åˆ†æèƒ½åŠ›å®ç°ç”µåŠ›ç³»ç»Ÿè°ƒåº¦ç­–ç•¥çš„è‡ªä¸»ç”Ÿæˆã€‚è¯¥æ–¹æ¡ˆæ ¸å¿ƒåœ¨äºé€šè¿‡ Experience Storageã€Experience Retrievalã€Experience Generation å’Œ Experience Modification ç­‰å¤šä¸ªæ¨¡å—çš„ååŒäº¤äº’ï¼Œä½¿ LLM èƒ½å¤Ÿå®ç°ç”µå‹æ§åˆ¶ç­–ç•¥çš„è‡ªæˆ‘è¿›åŒ–ã€‚è¿™ç§æœºåˆ¶å…è®¸æ¨¡å‹ä»å­˜å‚¨çš„ç»éªŒä¸­æå–çŸ¥è¯†å¹¶è¿›è¡ŒåŠ¨æ€ä¿®æ­£ï¼Œä»è€Œæœ‰æ•ˆåº”å¯¹å¤æ‚çš„ç”µç½‘è¿è¡Œç¯å¢ƒã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ï¼Œå¹¶å……åˆ†å±•ç¤ºäº† LLMs åœ¨è§£å†³ Power System Dispatch æŒ‘æˆ˜ä¸­çš„é€‚ç”¨æ€§ä¸æ½œåŠ›ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°ç”µåŠ›ç³»ç»Ÿé«˜åº¦æ™ºèƒ½åŒ–ä¸è‡ªä¸»åŒ–çš„è°ƒåº¦ç®¡ç†æä¾›äº†åˆ›æ–°çš„è§£å†³æ€è·¯ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14800v1",
      "published_date": "2025-07-20 03:22:08 UTC",
      "updated_date": "2025-07-20 03:22:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:37.351704+00:00"
    },
    {
      "arxiv_id": "2507.14799v1",
      "title": "Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree",
      "title_zh": "é€šè¿‡ HTML æ— éšœç¢æ ‘åˆ©ç”¨é—´æ¥æç¤ºæ³¨å…¥æ”»å‡»æ“æ§ LLM ç½‘é¡µæ™ºèƒ½ä½“",
      "authors": [
        "Sam Johnson",
        "Viet Pham",
        "Thai Le"
      ],
      "abstract": "This work demonstrates that LLM-based web navigation agents offer powerful automation capabilities but are vulnerable to Indirect Prompt Injection (IPI) attacks. We show that adversaries can embed universal adversarial triggers in webpage HTML to hijack agent behavior that utilizes the accessibility tree to parse HTML, causing unintended or malicious actions. Using the Greedy Coordinate Gradient (GCG) algorithm and a Browser Gym agent powered by Llama-3.1, our system demonstrates high success rates across real websites in both targeted and general attacks, including login credential exfiltration and forced ad clicks. Our empirical results highlight critical security risks and the need for stronger defenses as LLM-driven autonomous web agents become more widely adopted. The system software (https://github.com/sej2020/manipulating-web-agents) is released under the MIT License, with an accompanying publicly available demo website (http://lethaiq.github.io/attack-web-llm-agent).",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ­ç¤ºäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ç½‘é¡µå¯¼èˆªæ™ºèƒ½ä½“åœ¨æä¾›è‡ªåŠ¨åŒ–ä¾¿åˆ©çš„åŒæ—¶ï¼Œææ˜“å—åˆ°é—´æ¥æç¤ºæ³¨å…¥(Indirect Prompt Injection, IPI)æ”»å‡»çš„å¨èƒã€‚æ”»å‡»è€…å¯ä»¥é€šè¿‡åœ¨ç½‘é¡µHTMLä¸­æ¤å…¥é€šç”¨å¯¹æŠ—è§¦å‘å™¨ï¼ŒåŠ«æŒåˆ©ç”¨å¯è®¿é—®æ€§æ ‘(Accessibility Tree)è§£æç½‘é¡µçš„æ™ºèƒ½ä½“è¡Œä¸ºï¼Œä»è€Œè¯±å‘éé¢„æœŸæˆ–æ¶æ„çš„æ“ä½œã€‚è¯¥ç ”ç©¶é‡‡ç”¨è´ªå©ªåæ ‡æ¢¯åº¦(Greedy Coordinate Gradient, GCG)ç®—æ³•ï¼Œå¹¶åœ¨åŸºäºLlama-3.1çš„Browser Gymæ™ºèƒ½ä½“ä¸Šè¿›è¡Œäº†å®éªŒéªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ”»å‡»æ‰‹æ®µåœ¨çœŸå®ç½‘ç«™çš„å®šå‘å’Œé€šç”¨æ”»å‡»ä¸­å‡è¡¨ç°å‡ºæé«˜çš„æˆåŠŸç‡ï¼Œèƒ½å¤Ÿå®ç°çªƒå–ç™»å½•å‡­æ®å’Œå¼ºåˆ¶ç‚¹å‡»å¹¿å‘Šç­‰æ¶æ„è¡Œä¸ºã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†éšç€å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„è‡ªä¸»ç½‘é¡µæ™ºèƒ½ä½“è¢«å¹¿æ³›åº”ç”¨ï¼ŒäºŸéœ€å»ºç«‹æ›´å¼ºæœ‰åŠ›çš„é˜²å¾¡æœºåˆ¶æ¥åº”å¯¹è¿™äº›ä¸¥å³»çš„å®‰å…¨é£é™©ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "EMNLP 2025 System Demonstrations Submission",
      "pdf_url": "https://arxiv.org/pdf/2507.14799v1",
      "published_date": "2025-07-20 03:10:13 UTC",
      "updated_date": "2025-07-20 03:10:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:34.319229+00:00"
    },
    {
      "arxiv_id": "2507.15889v1",
      "title": "Dr. Boot: Bootstrapping Program Synthesis Language Models to Perform Repairing",
      "title_zh": "Dr. Bootï¼šé€šè¿‡è‡ªä¸¾ä½¿ç¨‹åºåˆæˆè¯­è¨€æ¨¡å‹å…·å¤‡ç¨‹åºä¿®å¤èƒ½åŠ›",
      "authors": [
        "Noah van der Vleuten"
      ],
      "abstract": "Language models for program synthesis are usually trained and evaluated on programming competition datasets (MBPP, APPS). However, these datasets are limited in size and quality, while these language models are extremely data hungry. Additionally, the language models have a misaligned program synthesis process compared to humans. While humans iteratively develop code with the help of a compiler, most program synthesis models currently produce code in one go. To solve these issues, we introduce a bootstrapping algorithm for program synthesis, that supports teaching models how to repair. We show that bootstrapping consistently outperforms regular fine-tuning. Compared to other work, our bootstrapped model performs on par with fine-tuned models that are 68\\% larger. Notably, bootstrapping with repairing also improves non-repairing performance compared to regular bootstrapping during inference. However, on our models, repairing during inference is likely inferior to simply sampling the same number of solutions. Furthermore, we find that there are issues with the example test cases in the training portion of the APPS dataset that are valuable to the community, as many repairing and reinforcement learning methods rely on them.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Dr. Bootï¼Œä¸€ç§ç”¨äºç¨‹åºåˆæˆ(Program Synthesis)çš„è‡ªä¸¾(Bootstrapping)ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®é›†è§„æ¨¡æœ‰é™åŠæ¨¡å‹ç¼ºä¹ç±»ä¼¼äººç±»è¿­ä»£å¼€å‘èƒ½åŠ›çš„æŒ‘æˆ˜ã€‚é€šè¿‡æ•™å¯¼æ¨¡å‹å¦‚ä½•è¿›è¡Œä¿®å¤(Repairing)ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¸€è‡´ä¼˜äºä¼ ç»Ÿçš„å¾®è°ƒ(Fine-tuning)æ¨¡å¼ï¼Œä¸”å…¶æ¨¡å‹è¡¨ç°å¯ä¸å‚æ•°é‡å¤§å‡º68%çš„å¸¸è§„å¾®è°ƒæ¨¡å‹ç›¸åª²ç¾ã€‚å®éªŒå‘ç°ï¼Œåœ¨æ¨ç†é˜¶æ®µç»“åˆRepairingçš„è‡ªä¸¾ç­–ç•¥ä¸ä»…èƒ½å¢å¼ºä¿®å¤èƒ½åŠ›ï¼Œè¿˜èƒ½æå‡éä¿®å¤ä»»åŠ¡çš„æ•´ä½“è¡¨ç°ã€‚å°½ç®¡åœ¨ç‰¹å®šæ¨¡å‹ä¸Šï¼Œæ¨ç†æ—¶çš„ä¿®å¤æ•ˆæœå¯èƒ½ç•¥é€ŠäºåŒç­‰è®¡ç®—é‡ä¸‹çš„å¤šé‡é‡‡æ ·(Sampling)ï¼Œä½†è¯¥ç ”ç©¶ä¾ç„¶éªŒè¯äº†è‡ªä¸¾ç®—æ³•åœ¨æå‡ä»£ç ç”Ÿæˆè´¨é‡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œä½œè€…æ­ç¤ºäº†APPSæ•°æ®é›†è®­ç»ƒéƒ¨åˆ†æµ‹è¯•ç”¨ä¾‹å­˜åœ¨çš„è´¨é‡é—®é¢˜ï¼Œä¸ºåç»­ä¾èµ–è¯¥æ•°æ®çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)å’Œä¿®å¤ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Master's thesis, University of Amsterdam, 2023 (https://scripties.uba.uva.nl/search?id=record_54126). Code and experiments available at: https://github.com/NoahVl/Dr-Boot",
      "pdf_url": "https://arxiv.org/pdf/2507.15889v1",
      "published_date": "2025-07-20 02:10:46 UTC",
      "updated_date": "2025-07-20 02:10:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:40.547540+00:00"
    },
    {
      "arxiv_id": "2507.14787v1",
      "title": "FOCUS: Fused Observation of Channels for Unveiling Spectra",
      "title_zh": "FOCUSï¼šç”¨äºå…‰è°±æ­ç¤ºçš„é€šé“èåˆè§‚æµ‹",
      "authors": [
        "Xi Xiao",
        "Aristeidis Tsaris",
        "Anika Tabassum",
        "John Lagergren",
        "Larry M. York",
        "Tianyang Wang",
        "Xiao Wang"
      ],
      "abstract": "Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous wavelength bands, making it a powerful tool in biology, agriculture, and environmental monitoring. However, interpreting Vision Transformers (ViTs) in this setting remains largely unexplored due to two key challenges: (1) existing saliency methods struggle to capture meaningful spectral cues, often collapsing attention onto the class token, and (2) full-spectrum ViTs are computationally prohibitive for interpretability, given the high-dimensional nature of HSI data. We present FOCUS, the first framework that enables reliable and efficient spatial-spectral interpretability for frozen ViTs. FOCUS introduces two core components: class-specific spectral prompts that guide attention toward semantically meaningful wavelength groups, and a learnable [SINK] token trained with an attraction loss to absorb noisy or redundant attention. Together, these designs make it possible to generate stable and interpretable 3D saliency maps and spectral importance curves in a single forward pass, without any gradient backpropagation or backbone modification. FOCUS improves band-level IoU by 15 percent, reduces attention collapse by over 40 percent, and produces saliency results that align closely with expert annotations. With less than 1 percent parameter overhead, our method makes high-resolution ViT interpretability practical for real-world hyperspectral applications, bridging a long-standing gap between black-box modeling and trustworthy HSI decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FOCUS æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ Vision Transformers (ViTs) åœ¨é«˜å…‰è°±æˆåƒ (Hyperspectral imaging, HSI) é¢†åŸŸä¸­ç”±äºæ³¨æ„åŠ›å´©æºƒå’Œé«˜ç»´è®¡ç®—å¼€é”€å¯¼è‡´çš„å¯è§£é‡Šæ€§éš¾é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ç±»åˆ«ç‰¹å®šçš„å…‰è°±æç¤º (class-specific spectral prompts) æ¥å¼•å¯¼æ³¨æ„åŠ›è½¬å‘å…·æœ‰è¯­ä¹‰æ„ä¹‰çš„æ³¢æ®µç»„ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªå¯å­¦ä¹ çš„ [SINK] ä»¤ç‰Œ (token) ä»¥å¸æ”¶å™ªå£°å’Œå†—ä½™æ³¨æ„åŠ›ã€‚FOCUS èƒ½å¤Ÿåœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­ç”Ÿæˆç¨³å®šçš„ 3D æ˜¾è‘—æ€§å›¾ (saliency maps) å’Œå…‰è°±é‡è¦æ€§æ›²çº¿ï¼Œä¸”æ— éœ€ä»»ä½•æ¢¯åº¦åå‘ä¼ æ’­æˆ–å¯¹ä¸»å¹²ç½‘ç»œçš„ä¿®æ”¹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å°†æ³¢æ®µçº§ IoU æå‡äº† 15%ï¼Œå‡å°‘äº† 40% ä»¥ä¸Šçš„æ³¨æ„åŠ›å´©æºƒï¼Œä¸”ç”Ÿæˆçš„æ˜¾è‘—æ€§ç»“æœä¸ä¸“å®¶æ ‡æ³¨é«˜åº¦ä¸€è‡´ã€‚åœ¨ä»…å¢åŠ ä¸åˆ° 1% å‚æ•°å¼€é”€çš„æƒ…å†µä¸‹ï¼ŒFOCUS ä¸ºç°å®ä¸–ç•Œçš„é«˜å…‰è°±åº”ç”¨æä¾›äº†å®ç”¨çš„é«˜åˆ†è¾¨ç‡è§£é‡Šæ€§ï¼Œæœ‰æ•ˆå¼¥åˆäº†é»‘ç›’æ¨¡å‹ä¸å¯ä¿¡ HSI å†³ç­–ä¹‹é—´çš„é•¿æœŸé¸¿æ²Ÿã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14787v1",
      "published_date": "2025-07-20 02:08:23 UTC",
      "updated_date": "2025-07-20 02:08:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:44.969279+00:00"
    },
    {
      "arxiv_id": "2507.14785v2",
      "title": "Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs",
      "title_zh": "æ¢ç´¢å¤§è¯­è¨€æ¨¡å‹åœ¨é‡‘èå›¾è°±æ´—é’±æ£€æµ‹ä¸­çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›",
      "authors": [
        "Erfan Pirmorad"
      ],
      "abstract": "The complexity and interconnectivity of entities involved in money laundering demand investigative reasoning over graph-structured data. This paper explores the use of large language models (LLMs) as reasoning engines over localized subgraphs extracted from a financial knowledge graph. We propose a lightweight pipeline that retrieves k-hop neighborhoods around entities of interest, serializes them into structured text, and prompts an LLM via few-shot in-context learning to assess suspiciousness and generate justifications. Using synthetic anti-money laundering (AML) scenarios that reflect common laundering behaviors, we show that LLMs can emulate analyst-style logic, highlight red flags, and provide coherent explanations. While this study is exploratory, it illustrates the potential of LLM-based graph reasoning in AML and lays groundwork for explainable, language-driven financial crime analytics.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºé‡‘èçŸ¥è¯†å›¾è°±(financial knowledge graph)å±€éƒ¨å­å›¾æ¨ç†å¼•æ“çš„èƒ½åŠ›ï¼Œä»¥è§£å†³æ´—é’±æ£€æµ‹ä¸­å¤æ‚çš„å®ä½“å…³è”åˆ†æé—®é¢˜ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§æµæ°´çº¿ï¼Œé€šè¿‡æ£€ç´¢ç›®æ ‡å®ä½“çš„kè·³é‚»åŸŸ(k-hop neighborhoods)å¹¶å°†å…¶åºåˆ—åŒ–ä¸ºç»“æ„åŒ–æ–‡æœ¬ï¼Œåˆ©ç”¨å°‘æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ (few-shot in-context learning)å¼•å¯¼LLMè¯„ä¼°å®ä½“çš„å¯ç–‘ç¨‹åº¦å¹¶ç”Ÿæˆåˆ¤å®šä¾æ®ã€‚åœ¨åˆæˆçš„åæ´—é’±(AML)åœºæ™¯æµ‹è¯•ä¸­ï¼ŒLLMsæˆåŠŸæ¨¡æ‹Ÿäº†åˆ†æå¸ˆçš„é€»è¾‘æ€ç»´ï¼Œèƒ½å¤Ÿç²¾å‡†è¯†åˆ«é£é™©ä¿¡å·(red flags)å¹¶æä¾›è¿è´¯çš„è§£é‡Šã€‚è¯¥æ¢ç´¢æ€§ç ”ç©¶å±•ç¤ºäº†åŸºäºLLMçš„å›¾æ¨ç†åœ¨é‡‘èç›‘ç®¡ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæ„å»ºå¯è§£é‡Šã€è¯­è¨€é©±åŠ¨çš„é‡‘èçŠ¯ç½ªåˆ†æä½“ç³»å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AI4FCF-ICDM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.14785v2",
      "published_date": "2025-07-20 02:00:21 UTC",
      "updated_date": "2025-10-29 15:56:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:45.989437+00:00"
    },
    {
      "arxiv_id": "2507.14784v2",
      "title": "LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering",
      "title_zh": "LeAdQAï¼šå¤§æ¨¡å‹é©±åŠ¨çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§†é¢‘é—®ç­”æ—¶åºå®šä½",
      "authors": [
        "Xinxin Dong",
        "Baoyun Peng",
        "Haokai Ma",
        "Yufei Wang",
        "Zixuan Dong",
        "Fei Hu",
        "Xiaodong Wang"
      ],
      "abstract": "Video Question Answering (VideoQA) requires identifying sparse critical moments in long videos and reasoning about their causal relationships to answer semantically complex questions. While recent advances in multimodal learning have improved alignment and fusion, current approaches remain limited by two prevalent but fundamentally flawed strategies: (1) task-agnostic sampling indiscriminately processes all frames, overwhelming key events with irrelevant content; and (2) heuristic retrieval captures superficial patterns but misses causal-temporal structures needed for complex reasoning. To address these challenges, we introduce LeAdQA, an innovative approach that bridges these gaps through synergizing causal-aware query refinement with fine-grained visual grounding. Our method first leverages LLMs to reformulate question-option pairs, resolving causal ambiguities and sharpening temporal focus. These refined queries subsequently direct a temporal grounding model to precisely retrieve the most salient segments, complemented by an adaptive fusion mechanism dynamically integrating the evidence to maximize relevance. The integrated visual-textual cues are then processed by an MLLM to generate accurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and NExT-GQA demonstrate that our method's precise visual grounding substantially enhances the understanding of video-question relationships, achieving state-of-the-art (SOTA) performance on complex reasoning tasks while maintaining computational efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LeAdQAï¼Œæ—¨åœ¨è§£å†³è§†é¢‘é—®ç­”(Video Question Answering, VideoQA)åœ¨é•¿è§†é¢‘ä¸­è¯†åˆ«ç¨€ç–å…³é”®æ—¶åˆ»åŠæ¨ç†å› æœå…³ç³»æ—¶çš„å±€é™æ€§ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•åœ¨ä»»åŠ¡æ— å…³é‡‡æ ·(task-agnostic sampling)ä¸­æ˜“å—æ— å…³ä¿¡æ¯å¹²æ‰°ï¼Œä»¥åŠå¯å‘å¼æ£€ç´¢(heuristic retrieval)ç¼ºä¹å› æœæ—¶åºç»“æ„ç†è§£çš„é—®é¢˜ï¼ŒLeAdQAå®ç°äº†ä¸€ç§LLMé©±åŠ¨çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ—¶åºå®šä½æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å¯¹é—®é¢˜-é€‰é¡¹å¯¹è¿›è¡Œé‡æ–°è¡¨è¿°ï¼Œä»è€Œæ¶ˆé™¤å› æœæ­§ä¹‰å¹¶å¼ºåŒ–æ—¶åºå…³æ³¨ç‚¹ã€‚éšåï¼Œä¼˜åŒ–åçš„æŸ¥è¯¢é©±åŠ¨æ—¶åºå®šä½æ¨¡å‹(temporal grounding model)ç²¾ç¡®æ£€ç´¢æœ€æ˜¾è‘—çš„è§†é¢‘ç‰‡æ®µï¼Œå¹¶ç»“åˆè‡ªé€‚åº”èåˆæœºåˆ¶(adaptive fusion)åŠ¨æ€æ•´åˆç›¸å…³è¯æ®ã€‚æœ€ç»ˆç”±å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)å¤„ç†æ•´åˆåçš„è§†è§‰ä¸æ–‡æœ¬çº¿ç´¢ï¼Œç”Ÿæˆå…·æœ‰ä¸Šä¸‹æ–‡ä¾æ®çš„å‡†ç¡®ç­”æ¡ˆã€‚åœ¨NExT-QAã€IntentQAå’ŒNExT-GQAç­‰æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•é€šè¿‡ç²¾å‡†çš„è§†è§‰å®šä½æ˜¾è‘—æå‡äº†å¯¹è§†é¢‘ä¸é—®é¢˜å…³ç³»çš„ç†è§£ï¼Œåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äº†å½“å‰å…ˆè¿›æ°´å¹³(SOTA)ï¼Œå¹¶ä¿æŒäº†è¾ƒé«˜çš„è®¡ç®—æ•ˆç‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14784v2",
      "published_date": "2025-07-20 01:57:00 UTC",
      "updated_date": "2025-08-18 09:06:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:46.923553+00:00"
    },
    {
      "arxiv_id": "2507.14783v3",
      "title": "Omni-Thinker: Scaling Multi-Task RL in LLMs with Hybrid Reward and Task Scheduling",
      "title_zh": "Omni-Thinkerï¼šé€šè¿‡æ··åˆå¥–åŠ±ä¸ä»»åŠ¡è°ƒåº¦å®ç°å¤§è¯­è¨€æ¨¡å‹å¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ çš„è§„æ¨¡åŒ–æ‰©å±•",
      "authors": [
        "Derek Li",
        "Jiaming Zhou",
        "Leo Maxime Brunswic",
        "Abbas Ghaddar",
        "Qianyi Sun",
        "Liheng Ma",
        "Yu Luo",
        "Dong Li",
        "Mark Coates",
        "Jianye Hao",
        "Yingxue Zhang"
      ],
      "abstract": "The pursuit of general-purpose artificial intelligence depends on large language models (LLMs) that can handle both structured reasoning and open-ended generation. We present Omni-Thinker, a unified reinforcement learning (RL) framework that scales LLMs across diverse tasks by combining hybrid rewards with backward-transfer-guided scheduling. Hybrid rewards integrate rule-based verifiable signals with preference-based evaluations from an LLM-as-a-Judge, enabling learning in both deterministic and subjective domains. Our scheduler orders tasks according to accuracy backward transfer (BWT), reducing forgetting and improving multi-task performance. Experiments across four domains show gains of 6.2% over joint training and 12.4% over model merging. Moreover, we demonstrate that simple assumptions on accuracy transfer yield accurate predictions of curriculum outcomes, with entropy dynamics explaining deviations due to generative tasks. These findings underscore the importance of BWT-aware scheduling and hybrid supervision for scaling RL-based post-training toward general-purpose LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Omni-Thinkerï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ··åˆå¥–åŠ±å’Œä»»åŠ¡è°ƒåº¦æ¥æ‰©å±•å¤§è¯­è¨€æ¨¡å‹ (LLMs) å¤„ç†å¤šä»»åŠ¡çš„èƒ½åŠ›ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ··åˆå¥–åŠ±æœºåˆ¶ (Hybrid Rewards)ï¼Œå°†åŸºäºè§„åˆ™çš„å¯éªŒè¯ä¿¡å·ä¸åŸºäº LLM-as-a-Judge çš„åå¥½è¯„ä¼°ç›¸ç»“åˆï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤ŸåŒæ—¶åœ¨ç¡®å®šæ€§å’Œä¸»è§‚æ€§é¢†åŸŸè¿›è¡Œå­¦ä¹ ã€‚ä¸ºäº†è§£å†³å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„é—å¿˜é—®é¢˜ï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ç§åŸºäºå‡†ç¡®ç‡åå‘è¿ç§» (Backward Transfer, BWT) æŒ‡å¯¼çš„ä»»åŠ¡è°ƒåº¦å™¨æ¥ä¼˜åŒ–å­¦ä¹ é¡ºåºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmni-Thinker çš„è¡¨ç°ä¼˜äºè”åˆè®­ç»ƒå’Œæ¨¡å‹åˆå¹¶ï¼Œåˆ†åˆ«å®ç°äº† 6.2% å’Œ 12.4% çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶é€šè¿‡åˆ†æè¯æ˜äº†åŸºäºå‡†ç¡®ç‡è¿ç§»çš„å‡è®¾å¯ä»¥å‡†ç¡®é¢„æµ‹è¯¾ç¨‹å­¦ä¹ ç»“æœï¼Œå¹¶åˆ©ç”¨ç†µåŠ¨åŠ›å­¦ (Entropy Dynamics) è§£é‡Šäº†ç”Ÿæˆå¼ä»»åŠ¡å¼•èµ·çš„åå·®ã€‚è¿™äº›å‘ç°çªæ˜¾äº†æ„ŸçŸ¥åå‘è¿ç§» (BWT-aware) çš„è°ƒåº¦å’Œæ··åˆç›‘ç£åœ¨æ‰©å±•å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ åæœŸè®­ç»ƒä¸­çš„é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.14783v3",
      "published_date": "2025-07-20 01:50:16 UTC",
      "updated_date": "2025-09-26 18:12:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:50:49.468937+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 69,
  "processed_papers_count": 69,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T05:51:45.827333+00:00"
}