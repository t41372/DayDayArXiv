[
  {
    "arxiv_id": "2410.20636v1",
    "title": "Language Models And A Second Opinion Use Case: The Pocket Professional",
    "authors": [
      "David Noever"
    ],
    "abstract": "This research tests the role of Large Language Models (LLMs) as formal second\nopinion tools in professional decision-making, particularly focusing on complex\nmedical cases where even experienced physicians seek peer consultation. The\nwork analyzed 183 challenging medical cases from Medscape over a 20-month\nperiod, testing multiple LLMs' performance against crowd-sourced physician\nresponses. A key finding was the high overall score possible in the latest\nfoundational models (>80% accuracy compared to consensus opinion), which\nexceeds most human metrics reported on the same clinical cases (450 pages of\npatient profiles, test results). The study rates the LLMs' performance\ndisparity between straightforward cases (>81% accuracy) and complex scenarios\n(43% accuracy), particularly in these cases generating substantial debate among\nhuman physicians. The research demonstrates that LLMs may be valuable as\ngenerators of comprehensive differential diagnoses rather than as primary\ndiagnostic tools, potentially helping to counter cognitive biases in clinical\ndecision-making, reduce cognitive loads, and thus remove some sources of\nmedical error. The inclusion of a second comparative legal dataset (Supreme\nCourt cases, N=21) provides added empirical context to the AI use to foster\nsecond opinions, though these legal challenges proved considerably easier for\nLLMs to analyze. In addition to the original contributions of empirical\nevidence for LLM accuracy, the research aggregated a novel benchmark for others\nto score highly contested question and answer reliability between both LLMs and\ndisagreeing human practitioners. These results suggest that the optimal\ndeployment of LLMs in professional settings may differ substantially from\ncurrent approaches that emphasize automation of routine tasks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20636v1",
    "published_date": "2024-10-27 23:48:47 UTC",
    "updated_date": "2024-10-27 23:48:47 UTC"
  },
  {
    "arxiv_id": "2410.20625v1",
    "title": "LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA Optimization",
    "authors": [
      "Jui-Nan Yen",
      "Si Si",
      "Zhao Meng",
      "Felix Yu",
      "Sai Surya Duvvuri",
      "Inderjit S. Dhillon",
      "Cho-Jui Hsieh",
      "Sanjiv Kumar"
    ],
    "abstract": "Low-rank adaption (LoRA) is a widely used parameter-efficient finetuning\nmethod for LLM that reduces memory requirements. However, current LoRA\noptimizers lack transformation invariance, meaning the actual updates to the\nweights depends on how the two LoRA factors are scaled or rotated. This\ndeficiency leads to inefficient learning and sub-optimal solutions in practice.\nThis paper introduces LoRA-RITE, a novel adaptive matrix preconditioning method\nfor LoRA optimization, which can achieve transformation invariance and remain\ncomputationally efficient. We provide theoretical analysis to demonstrate the\nbenefit of our method and conduct experiments on various LLM tasks with\ndifferent models including Gemma 2B, 7B, and mT5-XXL. The results demonstrate\nconsistent improvements against existing optimizers. For example, replacing\nAdam with LoRA-RITE during LoRA fine-tuning of Gemma-2B yielded 4.6\\% accuracy\ngain on Super-Natural Instructions and 3.5\\% accuracy gain across other four\nLLM benchmarks (HellaSwag, ArcChallenge, GSM8K, OpenBookQA).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20625v1",
    "published_date": "2024-10-27 22:57:12 UTC",
    "updated_date": "2024-10-27 22:57:12 UTC"
  },
  {
    "arxiv_id": "2410.20600v1",
    "title": "Implementation and Application of an Intelligibility Protocol for Interaction with an LLM",
    "authors": [
      "Ashwin Srinivasan",
      "Karan Bania",
      "Shreyas V",
      "Harshvardhan Mestha",
      "Sidong Liu"
    ],
    "abstract": "Our interest is in constructing interactive systems involving a human-expert\ninteracting with a machine learning engine on data analysis tasks. This is of\nrelevance when addressing complex problems arising in areas of science, the\nenvironment, medicine and so on, which are not immediately amenable to the\nusual methods of statistical or mathematical modelling. In such situations, it\nis possible that harnessing human expertise and creativity to modern\nmachine-learning capabilities of identifying patterns by constructing new\ninternal representations of the data may provide some insight to possible\nsolutions. In this paper, we examine the implementation of an abstract protocol\ndeveloped for interaction between agents, each capable of constructing\npredictions and explanations. The \\PXP protocol, described in [12] is motivated\nby the notion of ''two-way intelligibility'' and is specified using a pair of\ncommunicating finite-state machines. While the formalisation allows the authors\nto prove several properties about the protocol, no implementation was\npresented. Here, we address this shortcoming for the case in which one of the\nagents acts as a ''generator'' using a large language model (LLM) and the other\nis an agent that acts as a ''tester'' using either a human-expert, or a proxy\nfor a human-expert (for example, a database compiled using human-expertise). We\nbelieve these use-cases will be a widely applicable form of interaction for\nproblems of the kind mentioned above. We present an algorithmic description of\ngeneral-purpose implementation, and conduct preliminary experiments on its use\nin two different areas (radiology and drug-discovery). The experimental results\nprovide early evidence in support of the protocol's capability of capturing\none- and two-way intelligibility in human-LLM in the manner proposed in [12].",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20600v1",
    "published_date": "2024-10-27 21:20:18 UTC",
    "updated_date": "2024-10-27 21:20:18 UTC"
  },
  {
    "arxiv_id": "2410.20587v3",
    "title": "Generator Matching: Generative modeling with arbitrary Markov processes",
    "authors": [
      "Peter Holderrieth",
      "Marton Havasi",
      "Jason Yim",
      "Neta Shaul",
      "Itai Gat",
      "Tommi Jaakkola",
      "Brian Karrer",
      "Ricky T. Q. Chen",
      "Yaron Lipman"
    ],
    "abstract": "We introduce Generator Matching, a modality-agnostic framework for generative\nmodeling using arbitrary Markov processes. Generators characterize the\ninfinitesimal evolution of a Markov process, which we leverage for generative\nmodeling in a similar vein to flow matching: we construct conditional\ngenerators which generate single data points, then learn to approximate the\nmarginal generator which generates the full data distribution. We show that\nGenerator Matching unifies various generative modeling methods, including\ndiffusion models, flow matching and discrete diffusion models. Furthermore, it\nexpands the design space to new and unexplored Markov processes such as jump\nprocesses. Finally, Generator Matching enables the construction of\nsuperpositions of Markov generative models and enables the construction of\nmultimodal models in a rigorous manner. We empirically validate our method on\nimage and multimodal generation, e.g. showing that superposition with a jump\nprocess improves performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20587v3",
    "published_date": "2024-10-27 20:47:29 UTC",
    "updated_date": "2025-02-27 02:41:21 UTC"
  },
  {
    "arxiv_id": "2411.07252v1",
    "title": "High quality ECG dataset based on MIT-BIH recordings for improved heartbeats classification",
    "authors": [
      "Ahmed. S Benmessaoud",
      "Farida Medjani",
      "Yahia Bousseloub",
      "Khalid Bouaita",
      "Dhia Benrahem",
      "Tahar Kezai"
    ],
    "abstract": "Electrocardiogram (ECG) is a reliable tool for medical professionals to\ndetect and diagnose abnormal heart waves that may cause cardiovascular\ndiseases. This paper proposes a methodology to create a new high-quality\nheartbeat dataset from all 48 of the MIT-BIH recordings. The proposed approach\ncomputes an optimal heartbeat size, by eliminating outliers and calculating the\nmean value over 10-second windows. This results in independent QRS-centered\nheartbeats avoiding the mixing of successive heartbeats problem. The quality of\nthe newly constructed dataset has been evaluated and compared with existing\ndatasets. To this end, we built and trained a PyTorch 1-D Resnet architecture\nmodel that achieved 99.24\\% accuracy with a 5.7\\% improvement compared to other\nmethods. Additionally, downsampling the dataset has improved the model's\nexecution time by 33\\% and reduced 3x memory usage.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "4 pages, 5 figures, 5 tables, presented during IEEE COINS 2023\n  Berlin. link to ieeexploere: https://ieeexplore.ieee.org/document/10189299",
    "pdf_url": "http://arxiv.org/pdf/2411.07252v1",
    "published_date": "2024-10-27 20:41:43 UTC",
    "updated_date": "2024-10-27 20:41:43 UTC"
  },
  {
    "arxiv_id": "2410.20579v3",
    "title": "Toward Conditional Distribution Calibration in Survival Prediction",
    "authors": [
      "Shi-ang Qi",
      "Yakun Yu",
      "Russell Greiner"
    ],
    "abstract": "Survival prediction often involves estimating the time-to-event distribution\nfrom censored datasets. Previous approaches have focused on enhancing\ndiscrimination and marginal calibration. In this paper, we highlight the\nsignificance of conditional calibration for real-world applications --\nespecially its role in individual decision-making. We propose a method based on\nconformal prediction that uses the model's predicted individual survival\nprobability at that instance's observed time. This method effectively improves\nthe model's marginal and conditional calibration, without compromising\ndiscrimination. We provide asymptotic theoretical guarantees for both marginal\nand conditional calibration and test it extensively across 15 diverse\nreal-world datasets, demonstrating the method's practical effectiveness and\nversatility in various settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024. 41 pages, 23 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20579v3",
    "published_date": "2024-10-27 20:19:46 UTC",
    "updated_date": "2025-03-23 00:04:00 UTC"
  },
  {
    "arxiv_id": "2410.20578v2",
    "title": "Meta-Learning Approaches for Improving Detection of Unseen Speech Deepfakes",
    "authors": [
      "Ivan Kukanov",
      "Janne Laakkonen",
      "Tomi Kinnunen",
      "Ville Hautamäki"
    ],
    "abstract": "Current speech deepfake detection approaches perform satisfactorily against\nknown adversaries; however, generalization to unseen attacks remains an open\nchallenge. The proliferation of speech deepfakes on social media underscores\nthe need for systems that can generalize to unseen attacks not observed during\ntraining. We address this problem from the perspective of meta-learning, aiming\nto learn attack-invariant features to adapt to unseen attacks with very few\nsamples available. This approach is promising since generating of a high-scale\ntraining dataset is often expensive or infeasible. Our experiments demonstrated\nan improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on the\nInTheWild dataset, using just 96 samples from the unseen dataset. Continuous\nfew-shot adaptation ensures that the system remains up-to-date.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "6 pages, accepted to the IEEE Spoken Language Technology Workshop\n  (SLT) 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20578v2",
    "published_date": "2024-10-27 20:14:32 UTC",
    "updated_date": "2024-10-31 13:41:39 UTC"
  },
  {
    "arxiv_id": "2410.21335v2",
    "title": "E(3)-invariant diffusion model for pocket-aware peptide generation",
    "authors": [
      "Po-Yu Liang",
      "Jun Bai"
    ],
    "abstract": "Biologists frequently desire protein inhibitors for a variety of reasons,\nincluding use as research tools for understanding biological processes and\napplication to societal problems in agriculture, healthcare, etc.\nImmunotherapy, for instance, relies on immune checkpoint inhibitors to block\ncheckpoint proteins, preventing their binding with partner proteins and\nboosting immune cell function against abnormal cells. Inhibitor discovery has\nlong been a tedious process, which in recent years has been accelerated by\ncomputational approaches. Advances in artificial intelligence now provide an\nopportunity to make inhibitor discovery smarter than ever before. While\nextensive research has been conducted on computer-aided inhibitor discovery, it\nhas mainly focused on either sequence-to-structure mapping, reverse mapping, or\nbio-activity prediction, making it unrealistic for biologists to utilize such\ntools. Instead, our work proposes a new method of computer-assisted inhibitor\ndiscovery: de novo pocket-aware peptide structure and sequence generation\nnetwork. Our approach consists of two sequential diffusion models for\nend-to-end structure generation and sequence prediction. By leveraging angle\nand dihedral relationships between backbone atoms, we ensure an E(3)-invariant\nrepresentation of peptide structures. Our results demonstrate that our method\nachieves comparable performance to state-of-the-art models, highlighting its\npotential in pocket-aware peptide design. This work offers a new approach for\nprecise drug discovery using receptor-specific peptide generation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21335v2",
    "published_date": "2024-10-27 19:59:09 UTC",
    "updated_date": "2024-10-31 19:49:29 UTC"
  },
  {
    "arxiv_id": "2410.20573v1",
    "title": "Unsupervised Panoptic Interpretation of Latent Spaces in GANs Using Space-Filling Vector Quantization",
    "authors": [
      "Mohammad Hassan Vali",
      "Tom Bäckström"
    ],
    "abstract": "Generative adversarial networks (GANs) learn a latent space whose samples can\nbe mapped to real-world images. Such latent spaces are difficult to interpret.\nSome earlier supervised methods aim to create an interpretable latent space or\ndiscover interpretable directions that require exploiting data labels or\nannotated synthesized samples for training. However, we propose using a\nmodification of vector quantization called space-filling vector quantization\n(SFVQ), which quantizes the data on a piece-wise linear curve. SFVQ can capture\nthe underlying morphological structure of the latent space and thus make it\ninterpretable. We apply this technique to model the latent space of pretrained\nStyleGAN2 and BigGAN networks on various datasets. Our experiments show that\nthe SFVQ curve yields a general interpretable model of the latent space that\ndetermines which part of the latent space corresponds to what specific\ngenerative factors. Furthermore, we demonstrate that each line of SFVQ's curve\ncan potentially refer to an interpretable direction for applying intelligible\nimage transformations. We also showed that the points located on an SFVQ line\ncan be used for controllable data augmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20573v1",
    "published_date": "2024-10-27 19:56:02 UTC",
    "updated_date": "2024-10-27 19:56:02 UTC"
  },
  {
    "arxiv_id": "2410.20553v1",
    "title": "SPICEPilot: Navigating SPICE Code Generation and Simulation with AI Guidance",
    "authors": [
      "Deepak Vungarala",
      "Sakila Alam",
      "Arnob Ghosh",
      "Shaahin Angizi"
    ],
    "abstract": "Large Language Models (LLMs) have shown great potential in automating code\ngeneration; however, their ability to generate accurate circuit-level SPICE\ncode remains limited due to a lack of hardware-specific knowledge. In this\npaper, we analyze and identify the typical limitations of existing LLMs in\nSPICE code generation. To address these limitations, we present SPICEPilot a\nnovel Python-based dataset generated using PySpice, along with its accompanying\nframework. This marks a significant step forward in automating SPICE code\ngeneration across various circuit configurations. Our framework automates the\ncreation of SPICE simulation scripts, introduces standardized benchmarking\nmetrics to evaluate LLM's ability for circuit generation, and outlines a\nroadmap for integrating LLMs into the hardware design process. SPICEPilot is\nopen-sourced under the permissive MIT license at\nhttps://github.com/ACADLab/SPICEPilot.git.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "6 pages, 2 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.20553v1",
    "published_date": "2024-10-27 18:58:06 UTC",
    "updated_date": "2024-10-27 18:58:06 UTC"
  },
  {
    "arxiv_id": "2410.20552v1",
    "title": "SympCam: Remote Optical Measurement of Sympathetic Arousal",
    "authors": [
      "Björn Braun",
      "Daniel McDuff",
      "Tadas Baltrusaitis",
      "Paul Streli",
      "Max Moebus",
      "Christian Holz"
    ],
    "abstract": "Recent work has shown that a person's sympathetic arousal can be estimated\nfrom facial videos alone using basic signal processing. This opens up new\npossibilities in the field of telehealth and stress management, providing a\nnon-invasive method to measure stress only using a regular RGB camera. In this\npaper, we present SympCam, a new 3D convolutional architecture tailored to the\ntask of remote sympathetic arousal prediction. Our model incorporates a\ntemporal attention module (TAM) to enhance the temporal coherence of our\nsequential data processing capabilities. The predictions from our method\nimprove accuracy metrics of sympathetic arousal in prior work by 48% to a mean\ncorrelation of 0.77. We additionally compare our method with common remote\nphotoplethysmography (rPPG) networks and show that they alone cannot accurately\npredict sympathetic arousal \"out-of-the-box\". Furthermore, we show that the\nsympathetic arousal predicted by our method allows detecting physical stress\nwith a balanced accuracy of 90% - an improvement of 61% compared to the rPPG\nmethod commonly used in related work, demonstrating the limitations of using\nrPPG alone. Finally, we contribute a dataset designed explicitly for the task\nof remote sympathetic arousal prediction. Our dataset contains synchronized\nface and hand videos of 20 participants from two cameras synchronized with\nelectrodermal activity (EDA) and photoplethysmography (PPG) measurements. We\nwill make this dataset available to the community and use it to evaluate the\nmethods in this paper. To the best of our knowledge, this is the first dataset\navailable to other researchers designed for remote sympathetic arousal\nprediction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication at the IEEE-EMBS International Conference on\n  Biomedical and Health Informatics",
    "pdf_url": "http://arxiv.org/pdf/2410.20552v1",
    "published_date": "2024-10-27 18:46:55 UTC",
    "updated_date": "2024-10-27 18:46:55 UTC"
  },
  {
    "arxiv_id": "2410.20550v1",
    "title": "Deep Reinforcement Learning Agents for Strategic Production Policies in Microeconomic Market Simulations",
    "authors": [
      "Eduardo C. Garrido-Merchán",
      "Maria Coronado-Vaca",
      "Álvaro López-López",
      "Carlos Martinez de Ibarreta"
    ],
    "abstract": "Traditional economic models often rely on fixed assumptions about market\ndynamics, limiting their ability to capture the complexities and stochastic\nnature of real-world scenarios. However, reality is more complex and includes\nnoise, making traditional models assumptions not met in the market. In this\npaper, we explore the application of deep reinforcement learning (DRL) to\nobtain optimal production strategies in microeconomic market environments to\novercome the limitations of traditional models. Concretely, we propose a\nDRL-based approach to obtain an effective policy in competitive markets with\nmultiple producers, each optimizing their production decisions in response to\nfluctuating demand, supply, prices, subsidies, fixed costs, total production\ncurve, elasticities and other effects contaminated by noise. Our framework\nenables agents to learn adaptive production policies to several simulations\nthat consistently outperform static and random strategies. As the deep neural\nnetworks used by the agents are universal approximators of functions, DRL\nalgorithms can represent in the network complex patterns of data learnt by\ntrial and error that explain the market. Through extensive simulations, we\ndemonstrate how DRL can capture the intricate interplay between production\ncosts, market prices, and competitor behavior, providing insights into optimal\ndecision-making in dynamic economic settings. The results show that agents\ntrained with DRL can strategically adjust production levels to maximize\nlong-term profitability, even in the face of volatile market conditions. We\nbelieve that the study bridges the gap between theoretical economic modeling\nand practical market simulation, illustrating the potential of DRL to\nrevolutionize decision-making in market strategies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20550v1",
    "published_date": "2024-10-27 18:38:05 UTC",
    "updated_date": "2024-10-27 18:38:05 UTC"
  },
  {
    "arxiv_id": "2410.21333v3",
    "title": "Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse",
    "authors": [
      "Ryan Liu",
      "Jiayi Geng",
      "Addison J. Wu",
      "Ilia Sucholutsky",
      "Tania Lombrozo",
      "Thomas L. Griffiths"
    ],
    "abstract": "Chain-of-thought (CoT) prompting has become a widely used strategy for\nworking with large language and multimodal models. While CoT has been shown to\nimprove performance across many tasks, determining the settings in which it is\neffective remains an ongoing effort. In particular, it is still an open\nquestion in what settings CoT systematically reduces model performance. In this\npaper, we seek to identify the characteristics of tasks where CoT reduces\nperformance by drawing inspiration from cognitive psychology, looking at cases\nwhere (i) verbal thinking or deliberation hurts performance in humans, and (ii)\nthe constraints governing human performance generalize to language models.\nThree such cases are implicit statistical learning, visual recognition, and\nclassifying with patterns containing exceptions. In extensive experiments\nacross all three settings, we find that a diverse collection of\nstate-of-the-art models exhibit significant drop-offs in performance (e.g., up\nto 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using\ninference-time reasoning compared to zero-shot counterparts. We also identify\nthree tasks that satisfy condition (i) but not (ii), and find that while verbal\nthinking reduces human performance in these tasks, CoT retains or increases\nmodel performance. Overall, our results show that while there is not an exact\nparallel between the cognitive processes of models and those of humans,\nconsidering cases where thinking has negative consequences for human\nperformance can help us identify settings where it negatively impacts models.\nBy connecting the literature on human deliberation with evaluations of CoT, we\noffer a new tool that can be used in understanding the impact of prompt choices\nand inference-time reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21333v3",
    "published_date": "2024-10-27 18:30:41 UTC",
    "updated_date": "2024-11-08 13:11:58 UTC"
  },
  {
    "arxiv_id": "2410.21332v1",
    "title": "Building, Reusing, and Generalizing Abstract Representations from Concrete Sequences",
    "authors": [
      "Shuchen Wu",
      "Mirko Thalmann",
      "Peter Dayan",
      "Zeynep Akata",
      "Eric Schulz"
    ],
    "abstract": "Humans excel at learning abstract patterns across different sequences,\nfiltering out irrelevant details, and transferring these generalized concepts\nto new sequences. In contrast, many sequence learning models lack the ability\nto abstract, which leads to memory inefficiency and poor transfer. We introduce\na non-parametric hierarchical variable learning model (HVM) that learns chunks\nfrom sequences and abstracts contextually similar chunks as variables. HVM\nefficiently organizes memory while uncovering abstractions, leading to compact\nsequence representations. When learning on language datasets such as babyLM,\nHVM learns a more efficient dictionary than standard compression algorithms\nsuch as Lempel-Ziv. In a sequence recall task requiring the acquisition and\ntransfer of variables embedded in sequences, we demonstrate HVM's sequence\nlikelihood correlates with human recall times. In contrast, large language\nmodels (LLMs) struggle to transfer abstract variables as effectively as humans.\nFrom HVM's adjustable layer of abstraction, we demonstrate that the model\nrealizes a precise trade-off between compression and generalization. Our work\noffers a cognitive model that captures the learning and transfer of abstract\nrepresentations in human cognition and differentiates itself from the behavior\nof large language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21332v1",
    "published_date": "2024-10-27 18:13:07 UTC",
    "updated_date": "2024-10-27 18:13:07 UTC"
  },
  {
    "arxiv_id": "2410.21331v1",
    "title": "Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness",
    "authors": [
      "Qi Zhang",
      "Yifei Wang",
      "Jingyi Cui",
      "Xiang Pan",
      "Qi Lei",
      "Stefanie Jegelka",
      "Yisen Wang"
    ],
    "abstract": "Deep learning models often suffer from a lack of interpretability due to\npolysemanticity, where individual neurons are activated by multiple unrelated\nsemantics, resulting in unclear attributions of model behavior. Recent advances\nin monosemanticity, where neurons correspond to consistent and distinct\nsemantics, have significantly improved interpretability but are commonly\nbelieved to compromise accuracy. In this work, we challenge the prevailing\nbelief of the accuracy-interpretability tradeoff, showing that monosemantic\nfeatures not only enhance interpretability but also bring concrete gains in\nmodel performance. Across multiple robust learning scenarios-including input\nand label noise, few-shot learning, and out-of-domain generalization-our\nresults show that models leveraging monosemantic features significantly\noutperform those relying on polysemantic features. Furthermore, we provide\nempirical and theoretical understandings on the robustness gains of feature\nmonosemanticity. Our preliminary analysis suggests that monosemanticity, by\npromoting better separation of feature representations, leads to more robust\ndecision boundaries. This diverse evidence highlights the generality of\nmonosemanticity in improving model robustness. As a first step in this new\ndirection, we embark on exploring the learning benefits of monosemanticity\nbeyond interpretability, supporting the long-standing hypothesis of linking\ninterpretability and robustness. Code is available at\n\\url{https://github.com/PKU-ML/Beyond_Interpretability}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21331v1",
    "published_date": "2024-10-27 18:03:20 UTC",
    "updated_date": "2024-10-27 18:03:20 UTC"
  },
  {
    "arxiv_id": "2410.20536v1",
    "title": "Malinowski in the Age of AI: Can large language models create a text game based on an anthropological classic?",
    "authors": [
      "Michael Peter Hoffmann",
      "Jan Fillies",
      "Adrian Paschke"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) like ChatGPT and GPT-4\nhave shown remarkable abilities in a wide range of tasks such as summarizing\ntexts and assisting in coding. Scientific research has demonstrated that these\nmodels can also play text-adventure games. This study aims to explore whether\nLLMs can autonomously create text-based games based on anthropological\nclassics, evaluating also their effectiveness in communicating knowledge. To\nachieve this, the study engaged anthropologists in discussions to gather their\nexpectations and design inputs for an anthropologically themed game. Through\niterative processes following the established HCI principle of 'design\nthinking', the prompts and the conceptual framework for crafting these games\nwere refined. Leveraging GPT3.5, the study created three prototypes of games\ncentered around the seminal anthropological work of the social anthropologist's\nBronislaw Malinowski's \"Argonauts of the Western Pacific\" (1922). Subsequently,\nevaluations were conducted by inviting senior anthropologists to playtest these\ngames, and based on their inputs, the game designs were refined. The tests\nrevealed promising outcomes but also highlighted key challenges: the models\nencountered difficulties in providing in-depth thematic understandings, showed\nsuspectibility to misinformation, tended towards monotonic responses after an\nextended period of play, and struggled to offer detailed biographical\ninformation. Despite these limitations, the study's findings open up new\nresearch avenues at the crossroads of artificial intelligence, machine\nlearning, LLMs, ethnography, anthropology and human-computer interaction.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at KUI 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20536v1",
    "published_date": "2024-10-27 17:59:17 UTC",
    "updated_date": "2024-10-27 17:59:17 UTC"
  },
  {
    "arxiv_id": "2410.20535v3",
    "title": "Asynchronous Perception Machine For Efficient Test-Time-Training",
    "authors": [
      "Rajat Modi",
      "Yogesh Singh Rawat"
    ],
    "abstract": "In this work, we propose Asynchronous Perception Machine (APM), a\ncomputationally-efficient architecture for test-time-training (TTT). APM can\nprocess patches of an image one at a time in any order asymmetrically and still\nencode semantic-awareness in the net. We demonstrate APM's ability to recognize\nout-of-distribution images without dataset-specific pre-training, augmentation\nor any-pretext task. APM offers competitive performance over existing TTT\napproaches. To perform TTT, APM just distills test sample's representation\nonce. APM possesses a unique property: it can learn using just this single\nrepresentation and starts predicting semantically-aware features.\n  APM demostrates potential applications beyond test-time-training: APM can\nscale up to a dataset of 2D images and yield semantic-clusterings in a single\nforward pass. APM also provides first empirical evidence towards validating\nGLOM's insight, i.e. input percept is a field. Therefore, APM helps us converge\ntowards an implementation which can do both interpolation and perception on a\nshared-connectionist hardware. Our code is publicly available at this link:\nhttps://rajatmodi62.github.io/apm_project_page/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024 Main Track. APM is a step to getting\n  Geoffrey Hinton's GLOM working",
    "pdf_url": "http://arxiv.org/pdf/2410.20535v3",
    "published_date": "2024-10-27 17:57:30 UTC",
    "updated_date": "2024-11-05 13:18:23 UTC"
  },
  {
    "arxiv_id": "2410.20527v1",
    "title": "CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming",
    "authors": [
      "Ali TehraniJamsaz",
      "Arijit Bhattacharjee",
      "Le Chen",
      "Nesreen K. Ahmed",
      "Amir Yazdanbakhsh",
      "Ali Jannesari"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have renewed interest in\nautomatic programming language translation. Encoder-decoder transformer models,\nin particular, have shown promise in translating between different programming\nlanguages. However, translating between a language and its high-performance\ncomputing (HPC) extensions remains underexplored due to challenges such as\ncomplex parallel semantics. In this paper, we introduce CodeRosetta, an\nencoder-decoder transformer model designed specifically for translating between\nprogramming languages and their HPC extensions. CodeRosetta is evaluated on C++\nto CUDA and Fortran to C++ translation tasks. It uses a customized learning\nframework with tailored pretraining and training objectives to effectively\ncapture both code semantics and parallel structural nuances, enabling\nbidirectional translation. Our results show that CodeRosetta outperforms\nstate-of-the-art baselines in C++ to CUDA translation by 2.9 BLEU and 1.72\nCodeBLEU points while improving compilation accuracy by 6.05%. Compared to\ngeneral closed-source LLMs, our method improves C++ to CUDA translation by\n22.08 BLEU and 14.39 CodeBLEU, with 2.75% higher compilation accuracy. Finally,\nCodeRosetta exhibits proficiency in Fortran to parallel C++ translation,\nmarking it, to our knowledge, as the first encoder-decoder model for this\ncomplex task, improving CodeBLEU by at least 4.63 points compared to\nclosed-source and open-code LLMs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20527v1",
    "published_date": "2024-10-27 17:34:07 UTC",
    "updated_date": "2024-10-27 17:34:07 UTC"
  },
  {
    "arxiv_id": "2410.20522v1",
    "title": "Props for Machine-Learning Security",
    "authors": [
      "Ari Juels",
      "Farinaz Koushanfar"
    ],
    "abstract": "We propose protected pipelines or props for short, a new approach for\nauthenticated, privacy-preserving access to deep-web data for machine learning\n(ML). By permitting secure use of vast sources of deep-web data, props address\nthe systemic bottleneck of limited high-quality training data in ML\ndevelopment. Props also enable privacy-preserving and trustworthy forms of\ninference, allowing for safe use of sensitive data in ML applications. Props\nare practically realizable today by leveraging privacy-preserving oracle\nsystems initially developed for blockchain applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20522v1",
    "published_date": "2024-10-27 17:05:48 UTC",
    "updated_date": "2024-10-27 17:05:48 UTC"
  },
  {
    "arxiv_id": "2410.20518v1",
    "title": "MidiTok Visualizer: a tool for visualization and analysis of tokenized MIDI symbolic music",
    "authors": [
      "Michał Wiszenko",
      "Kacper Stefański",
      "Piotr Malesa",
      "Łukasz Pokorzyński",
      "Mateusz Modrzejewski"
    ],
    "abstract": "Symbolic music research plays a crucial role in music-related machine\nlearning, but MIDI data can be complex for those without musical expertise. To\naddress this issue, we present MidiTok Visualizer, a web application designed\nto facilitate the exploration and visualization of various MIDI tokenization\nmethods from the MidiTok Python package. MidiTok Visualizer offers numerous\ncustomizable parameters, enabling users to upload MIDI files to visualize\ntokenized data alongside an interactive piano roll.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "in Extended Abstracts for the Late-Breaking Demo Sessionof the 25th\n  Int. Society for Music Information Retrieval Conf., San Francisco, United\n  States, 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20518v1",
    "published_date": "2024-10-27 17:00:55 UTC",
    "updated_date": "2024-10-27 17:00:55 UTC"
  },
  {
    "arxiv_id": "2410.20515v1",
    "title": "Symbotunes: unified hub for symbolic music generative models",
    "authors": [
      "Paweł Skierś",
      "Maksymilian Łazarski",
      "Michał Kopeć",
      "Mateusz Modrzejewski"
    ],
    "abstract": "Implementations of popular symbolic music generative models often differ\nsignificantly in terms of the libraries utilized and overall project structure.\nTherefore, directly comparing the methods or becoming acquainted with them may\npresent challenges. To mitigate this issue we introduce Symbotunes, an\nopen-source unified hub for symbolic music generative models. Symbotunes\ncontains modern Python implementations of well-known methods for symbolic music\ngeneration, as well as a unified pipeline for generating and training.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20515v1",
    "published_date": "2024-10-27 16:54:58 UTC",
    "updated_date": "2024-10-27 16:54:58 UTC"
  },
  {
    "arxiv_id": "2410.21330v1",
    "title": "LLM Robustness Against Misinformation in Biomedical Question Answering",
    "authors": [
      "Alexander Bondarenko",
      "Adrian Viehweger"
    ],
    "abstract": "The retrieval-augmented generation (RAG) approach is used to reduce the\nconfabulation of large language models (LLMs) for question answering by\nretrieving and providing additional context coming from external knowledge\nsources (e.g., by adding the context to the prompt). However, injecting\nincorrect information can mislead the LLM to generate an incorrect answer.\n  In this paper, we evaluate the effectiveness and robustness of four LLMs\nagainst misinformation - Gemma 2, GPT-4o-mini, Llama~3.1, and Mixtral - in\nanswering biomedical questions. We assess the answer accuracy on yes-no and\nfree-form questions in three scenarios: vanilla LLM answers (no context is\nprovided), \"perfect\" augmented generation (correct context is provided), and\nprompt-injection attacks (incorrect context is provided). Our results show that\nLlama 3.1 (70B parameters) achieves the highest accuracy in both vanilla\n(0.651) and \"perfect\" RAG (0.802) scenarios. However, the accuracy gap between\nthe models almost disappears with \"perfect\" RAG, suggesting its potential to\nmitigate the LLM's size-related effectiveness differences.\n  We further evaluate the ability of the LLMs to generate malicious context on\none hand and the LLM's robustness against prompt-injection attacks on the other\nhand, using metrics such as attack success rate (ASR), accuracy under attack,\nand accuracy drop. As adversaries, we use the same four LLMs (Gemma 2,\nGPT-4o-mini, Llama 3.1, and Mixtral) to generate incorrect context that is\ninjected in the target model's prompt. Interestingly, Llama is shown to be the\nmost effective adversary, causing accuracy drops of up to 0.48 for vanilla\nanswers and 0.63 for \"perfect\" RAG across target models. Our analysis reveals\nthat robustness rankings vary depending on the evaluation measure, highlighting\nthe complexity of assessing LLM resilience to adversarial attacks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21330v1",
    "published_date": "2024-10-27 16:23:26 UTC",
    "updated_date": "2024-10-27 16:23:26 UTC"
  },
  {
    "arxiv_id": "2410.20490v1",
    "title": "$\\textit{Who Speaks Matters}$: Analysing the Influence of the Speaker's Ethnicity on Hate Classification",
    "authors": [
      "Ananya Malik",
      "Kartik Sharma",
      "Lynnette Hui Xian Ng",
      "Shaily Bhatt"
    ],
    "abstract": "Large Language Models (LLMs) offer a lucrative promise for scalable content\nmoderation, including hate speech detection. However, they are also known to be\nbrittle and biased against marginalised communities and dialects. This requires\ntheir applications to high-stakes tasks like hate speech detection to be\ncritically scrutinized. In this work, we investigate the robustness of hate\nspeech classification using LLMs, particularly when explicit and implicit\nmarkers of the speaker's ethnicity are injected into the input. For the\nexplicit markers, we inject a phrase that mentions the speaker's identity. For\nthe implicit markers, we inject dialectal features. By analysing how frequently\nmodel outputs flip in the presence of these markers, we reveal varying degrees\nof brittleness across 4 popular LLMs and 5 ethnicities. We find that the\npresence of implicit dialect markers in inputs causes model outputs to flip\nmore than the presence of explicit markers. Further, the percentage of flips\nvaries across ethnicities. Finally, we find that larger models are more robust.\nOur findings indicate the need for exercising caution in deploying LLMs for\nhigh-stakes tasks like hate speech detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 figures, 3 tables. To appear in NeurIPS SafeGenAI 2024\n  Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.20490v1",
    "published_date": "2024-10-27 16:06:24 UTC",
    "updated_date": "2024-10-27 16:06:24 UTC"
  },
  {
    "arxiv_id": "2410.20487v4",
    "title": "Efficient Diversity-based Experience Replay for Deep Reinforcement Learning",
    "authors": [
      "Kaiyan Zhao",
      "Yiming Wang",
      "Yuyang Chen",
      "Yan Li",
      "Leong Hou U",
      "Xiaoguang Niu"
    ],
    "abstract": "Experience replay is widely used to improve learning efficiency in\nreinforcement learning by leveraging past experiences. However, existing\nexperience replay methods, whether based on uniform or prioritized sampling,\noften suffer from low efficiency, particularly in real-world scenarios with\nhigh-dimensional state spaces. To address this limitation, we propose a novel\napproach, Efficient Diversity-based Experience Replay (EDER). EDER employs a\ndeterminantal point process to model the diversity between samples and\nprioritizes replay based on the diversity between samples. To further enhance\nlearning efficiency, we incorporate Cholesky decomposition for handling large\nstate spaces in realistic environments. Additionally, rejection sampling is\napplied to select samples with higher diversity, thereby improving overall\nlearning efficacy. Extensive experiments are conducted on robotic manipulation\ntasks in MuJoCo, Atari games, and realistic indoor environments in Habitat. The\nresults demonstrate that our approach not only significantly improves learning\nefficiency but also achieves superior performance in high-dimensional,\nrealistic environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20487v4",
    "published_date": "2024-10-27 15:51:27 UTC",
    "updated_date": "2025-05-18 15:54:38 UTC"
  },
  {
    "arxiv_id": "2410.20483v2",
    "title": "Improving Decision Sparsity",
    "authors": [
      "Yiyang Sun",
      "Tong Wang",
      "Cynthia Rudin"
    ],
    "abstract": "Sparsity is a central aspect of interpretability in machine learning.\nTypically, sparsity is measured in terms of the size of a model globally, such\nas the number of variables it uses. However, this notion of sparsity is not\nparticularly relevant for decision-making; someone subjected to a decision does\nnot care about variables that do not contribute to the decision. In this work,\nwe dramatically expand a notion of decision sparsity called the Sparse\nExplanation Value(SEV) so that its explanations are more meaningful. SEV\nconsiders movement along a hypercube towards a reference point. By allowing\nflexibility in that reference and by considering how distances along the\nhypercube translate to distances in feature space, we can derive sparser and\nmore meaningful explanations for various types of function classes. We present\ncluster-based SEV and its variant tree-based SEV, introduce a method that\nimproves credibility of explanations, and propose algorithms that optimize\ndecision sparsity in machine learning models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.20483v2",
    "published_date": "2024-10-27 15:39:52 UTC",
    "updated_date": "2024-11-25 03:28:36 UTC"
  },
  {
    "arxiv_id": "2410.20482v1",
    "title": "What Factors Affect Multi-Modal In-Context Learning? An In-Depth Exploration",
    "authors": [
      "Libo Qin",
      "Qiguang Chen",
      "Hao Fei",
      "Zhi Chen",
      "Min Li",
      "Wanxiang Che"
    ],
    "abstract": "Recently, rapid advancements in Multi-Modal In-Context Learning (MM-ICL) have\nachieved notable success, which is capable of achieving superior performance\nacross various tasks without requiring additional parameter tuning. However,\nthe underlying rules for the effectiveness of MM-ICL remain under-explored. To\nfill this gap, this work aims to investigate the research question: \"What\nfactors affect the performance of MM-ICL?'' To this end, we investigate\nextensive experiments on the three core steps of MM-ICL including demonstration\nretrieval, demonstration ordering, and prompt construction using 6 vision large\nlanguage models and 20 strategies. Our findings highlight (1) the necessity of\na multi-modal retriever for demonstration retrieval, (2) the importance of\nintra-demonstration ordering over inter-demonstration ordering, and (3) the\nenhancement of task comprehension through introductory instructions in prompts.\nWe hope this study can serve as a foundational guide for optimizing MM-ICL\nstrategies in future research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20482v1",
    "published_date": "2024-10-27 15:37:51 UTC",
    "updated_date": "2024-10-27 15:37:51 UTC"
  },
  {
    "arxiv_id": "2410.20478v1",
    "title": "MusicFlow: Cascaded Flow Matching for Text Guided Music Generation",
    "authors": [
      "K R Prajwal",
      "Bowen Shi",
      "Matthew Lee",
      "Apoorv Vyas",
      "Andros Tjandra",
      "Mahi Luthra",
      "Baishan Guo",
      "Huiyu Wang",
      "Triantafyllos Afouras",
      "David Kant",
      "Wei-Ning Hsu"
    ],
    "abstract": "We introduce MusicFlow, a cascaded text-to-music generation model based on\nflow matching. Based on self-supervised representations to bridge between text\ndescriptions and music audios, we construct two flow matching networks to model\nthe conditional distribution of semantic and acoustic features. Additionally,\nwe leverage masked prediction as the training objective, enabling the model to\ngeneralize to other tasks such as music infilling and continuation in a\nzero-shot manner. Experiments on MusicCaps reveal that the music generated by\nMusicFlow exhibits superior quality and text coherence despite being over\n$2\\sim5$ times smaller and requiring $5$ times fewer iterative steps.\nSimultaneously, the model can perform other music generation tasks and achieves\ncompetitive performance in music infilling and continuation. Our code and model\nwill be publicly available.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20478v1",
    "published_date": "2024-10-27 15:35:41 UTC",
    "updated_date": "2024-10-27 15:35:41 UTC"
  },
  {
    "arxiv_id": "2410.20463v2",
    "title": "A Derivational ChainBank for Modern Standard Arabic",
    "authors": [
      "Reham Marzouk",
      "Sondos Krouna",
      "Nizar Habash"
    ],
    "abstract": "We introduce the new concept of an Arabic Derivational Chain Bank CHAINBANK\nto leverage the relationship between form and meaning in modeling Arabic\nderivational morphology. We constructed a knowledge graph network of abstract\npatterns and their derivational relations and aligned it with the lemmas of the\nCAMELMORPH morphological analyzer database. This process produced chains of\nderived words' lemmas linked to their corresponding lemma bases through\nderivational relations, encompassing 23,333 derivational connections.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20463v2",
    "published_date": "2024-10-27 14:43:23 UTC",
    "updated_date": "2025-01-31 09:29:23 UTC"
  },
  {
    "arxiv_id": "2410.20445v1",
    "title": "TrajAgent: An Agent Framework for Unified Trajectory Modelling",
    "authors": [
      "Yuwei Du",
      "Jie Feng",
      "Jie Zhao",
      "Yong Li"
    ],
    "abstract": "Trajectory modeling, which includes research on trajectory data pattern\nmining and future prediction, has widespread applications in areas such as life\nservices, urban transportation, and public administration. Numerous methods\nhave been proposed to address specific problems within trajectory modelling.\nHowever, due to the heterogeneity of data and the diversity of trajectory\ntasks, achieving unified trajectory modelling remains an important yet\nchallenging task. In this paper, we propose TrajAgent, a large language\nmodel-based agentic framework, to unify various trajectory modelling tasks. In\nTrajAgent, we first develop UniEnv, an execution environment with a unified\ndata and model interface, to support the execution and training of various\nmodels. Building on UniEnv, we introduce TAgent, an agentic workflow designed\nfor automatic trajectory modelling across various trajectory tasks.\nSpecifically, we design AutOpt, a systematic optimization module within TAgent,\nto further improve the performance of the integrated model. With diverse\ntrajectory tasks input in natural language, TrajAgent automatically generates\ncompetitive results via training and executing appropriate models. Extensive\nexperiments on four tasks using four real-world datasets demonstrate the\neffectiveness of TrajAgent in unified trajectory modelling, achieving an\naverage performance improvement of 15.43% over baseline methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages; the code will be openly accessible at:\n  https://github.com/tsinghua-fib-lab/TrajAgent",
    "pdf_url": "http://arxiv.org/pdf/2410.20445v1",
    "published_date": "2024-10-27 13:51:09 UTC",
    "updated_date": "2024-10-27 13:51:09 UTC"
  },
  {
    "arxiv_id": "2410.20439v1",
    "title": "TEAFormers: TEnsor-Augmented Transformers for Multi-Dimensional Time Series Forecasting",
    "authors": [
      "Linghang Kong",
      "Elynn Chen",
      "Yuzhou Chen",
      "Yuefeng Han"
    ],
    "abstract": "Multi-dimensional time series data, such as matrix and tensor-variate time\nseries, are increasingly prevalent in fields such as economics, finance, and\nclimate science. Traditional Transformer models, though adept with sequential\ndata, do not effectively preserve these multi-dimensional structures, as their\ninternal operations in effect flatten multi-dimensional observations into\nvectors, thereby losing critical multi-dimensional relationships and patterns.\nTo address this, we introduce the Tensor-Augmented Transformer (TEAFormer), a\nnovel method that incorporates tensor expansion and compression within the\nTransformer framework to maintain and leverage the inherent multi-dimensional\nstructures, thus reducing computational costs and improving prediction\naccuracy. The core feature of the TEAFormer, the Tensor-Augmentation (TEA)\nmodule, utilizes tensor expansion to enhance multi-view feature learning and\ntensor compression for efficient information aggregation and reduced\ncomputational load. The TEA module is not just a specific model architecture\nbut a versatile component that is highly compatible with the attention\nmechanism and the encoder-decoder structure of Transformers, making it\nadaptable to existing Transformer architectures. Our comprehensive experiments,\nwhich integrate the TEA module into three popular time series Transformer\nmodels across three real-world benchmarks, show significant performance\nenhancements, highlighting the potential of TEAFormers for cutting-edge time\nseries forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20439v1",
    "published_date": "2024-10-27 13:32:12 UTC",
    "updated_date": "2024-10-27 13:32:12 UTC"
  },
  {
    "arxiv_id": "2410.20428v1",
    "title": "MedGo: A Chinese Medical Large Language Model",
    "authors": [
      "Haitao Zhang",
      "Bo An"
    ],
    "abstract": "Large models are a hot research topic in the field of artificial\nintelligence. Leveraging their generative capabilities has the potential to\nenhance the level and quality of medical services. In response to the\nlimitations of current large language models, which often struggle with\naccuracy and have narrow capabilities in medical applications, this paper\npresents a Chinese medical large language model, MedGo. MedGo was trained using\na combination of high quality unsupervised medical data, supervised data, and\npreference alignment data, aimed at enhancing both its versatility and\nprecision in medical tasks. The model was evaluated through the public CBLUE\nbenchmark and a manually constructed dataset ClinicalQA. The results\ndemonstrate that MedGo achieved promising performance across various Chinese\nmedical information processing tasks, achieved the first place in the CBLUE\nevaluation. Additionally, on our constructed dataset ClinicalQA, MedGo\noutperformed its base model Qwen2, highlighting its potential to improve both\nautomated medical question answering and clinical decision support. These\nexperimental results demonstrate that MedGo possesses strong information\nprocessing capabilities in the medical field. At present, we have successfully\ndeployed MedGo at Shanghai East Hospital.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.20428v1",
    "published_date": "2024-10-27 12:52:52 UTC",
    "updated_date": "2024-10-27 12:52:52 UTC"
  },
  {
    "arxiv_id": "2410.21328v1",
    "title": "Deconfounding Time Series Forecasting",
    "authors": [
      "Wentao Gao",
      "Feiyu Yang",
      "Mengze Hong",
      "Xiaojing Du",
      "Zechen Hu",
      "Xiongren Chen",
      "Ziqi Xu"
    ],
    "abstract": "Time series forecasting is a critical task in various domains, where accurate\npredictions can drive informed decision-making. Traditional forecasting methods\noften rely on current observations of variables to predict future outcomes,\ntypically overlooking the influence of latent confounders, unobserved variables\nthat simultaneously affect both the predictors and the target outcomes. This\noversight can introduce bias and degrade the performance of predictive models.\nIn this study, we address this challenge by proposing an enhanced forecasting\napproach that incorporates representations of latent confounders derived from\nhistorical data. By integrating these confounders into the predictive process,\nour method aims to improve the accuracy and robustness of time series\nforecasts. The proposed approach is demonstrated through its application to\nclimate science data, showing significant improvements over traditional methods\nthat do not account for confounders.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21328v1",
    "published_date": "2024-10-27 12:45:42 UTC",
    "updated_date": "2024-10-27 12:45:42 UTC"
  },
  {
    "arxiv_id": "2410.20424v3",
    "title": "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions",
    "authors": [
      "Ziming Li",
      "Qianbo Zang",
      "David Ma",
      "Jiawei Guo",
      "Tuney Zheng",
      "Minghao Liu",
      "Xinyao Niu",
      "Yue Wang",
      "Jian Yang",
      "Jiaheng Liu",
      "Wanjun Zhong",
      "Wangchunshu Zhou",
      "Wenhao Huang",
      "Ge Zhang"
    ],
    "abstract": "Data science tasks involving tabular data present complex challenges that\nrequire sophisticated problem-solving approaches. We propose AutoKaggle, a\npowerful and user-centric framework that assists data scientists in completing\ndaily data pipelines through a collaborative multi-agent system. AutoKaggle\nimplements an iterative development process that combines code execution,\ndebugging, and comprehensive unit testing to ensure code correctness and logic\nconsistency. The framework offers highly customizable workflows, allowing users\nto intervene at each phase, thus integrating automated intelligence with human\nexpertise. Our universal data science toolkit, comprising validated functions\nfor data cleaning, feature engineering, and modeling, forms the foundation of\nthis solution, enhancing productivity by streamlining common tasks. We selected\n8 Kaggle competitions to simulate data processing workflows in real-world\napplication scenarios. Evaluation results demonstrate that AutoKaggle achieves\na validation submission rate of 0.85 and a comprehensive score of 0.82 in\ntypical data science pipelines, fully proving its effectiveness and\npracticality in handling complex data science tasks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "44 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20424v3",
    "published_date": "2024-10-27 12:44:25 UTC",
    "updated_date": "2024-11-05 19:46:38 UTC"
  },
  {
    "arxiv_id": "2410.20421v1",
    "title": "NT-VOT211: A Large-Scale Benchmark for Night-time Visual Object Tracking",
    "authors": [
      "Yu Liu",
      "Arif Mahmood",
      "Muhammad Haris Khan"
    ],
    "abstract": "Many current visual object tracking benchmarks such as OTB100, NfS, UAV123,\nLaSOT, and GOT-10K, predominantly contain day-time scenarios while the\nchallenges posed by the night-time has been less investigated. It is primarily\nbecause of the lack of a large-scale, well-annotated night-time benchmark for\nrigorously evaluating tracking algorithms. To this end, this paper presents\nNT-VOT211, a new benchmark tailored for evaluating visual object tracking\nalgorithms in the challenging night-time conditions. NT-VOT211 consists of 211\ndiverse videos, offering 211,000 well-annotated frames with 8 attributes\nincluding camera motion, deformation, fast motion, motion blur, tiny target,\ndistractors, occlusion and out-of-view. To the best of our knowledge, it is the\nlargest night-time tracking benchmark to-date that is specifically designed to\naddress unique challenges such as adverse visibility, image blur, and\ndistractors inherent to night-time tracking scenarios. Through a comprehensive\nanalysis of results obtained from 42 diverse tracking algorithms on NT-VOT211,\nwe uncover the strengths and limitations of these algorithms, highlighting\nopportunities for enhancements in visual object tracking, particularly in\nenvironments with suboptimal lighting. Besides, a leaderboard for revealing\nperformance rankings, annotation tools, comprehensive meta-information and all\nthe necessary code for reproducibility of results is made publicly available.\nWe believe that our NT-VOT211 benchmark will not only be instrumental in\nfacilitating field deployment of VOT algorithms, but will also help VOT\nenhancements and it will unlock new real-world tracking applications. Our\ndataset and other assets can be found at:\n{https://github.com/LiuYuML/NV-VOT211.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Oral Acceptance at the Asian Conference on Computer Vision (ACCV)\n  2024, Hanoi, Vietnam",
    "pdf_url": "http://arxiv.org/pdf/2410.20421v1",
    "published_date": "2024-10-27 12:19:48 UTC",
    "updated_date": "2024-10-27 12:19:48 UTC"
  },
  {
    "arxiv_id": "2410.20418v1",
    "title": "Inevitable Trade-off between Watermark Strength and Speculative Sampling Efficiency for Language Models",
    "authors": [
      "Zhengmian Hu",
      "Heng Huang"
    ],
    "abstract": "Large language models are probabilistic models, and the process of generating\ncontent is essentially sampling from the output distribution of the language\nmodel. Existing watermarking techniques inject watermarks into the generated\ncontent without altering the output quality. On the other hand, existing\nacceleration techniques, specifically speculative sampling, leverage a draft\nmodel to speed up the sampling process while preserving the output\ndistribution. However, there is no known method to simultaneously accelerate\nthe sampling process and inject watermarks into the generated content. In this\npaper, we investigate this direction and find that the integration of\nwatermarking and acceleration is non-trivial. We prove a no-go theorem, which\nstates that it is impossible to simultaneously maintain the highest watermark\nstrength and the highest sampling efficiency. Furthermore, we propose two\nmethods that maintain either the sampling efficiency or the watermark strength,\nbut not both. Our work provides a rigorous theoretical foundation for\nunderstanding the inherent trade-off between watermark strength and sampling\nefficiency in accelerating the generation of watermarked tokens for large\nlanguage models. We also conduct numerical experiments to validate our\ntheoretical findings and demonstrate the effectiveness of the proposed methods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20418v1",
    "published_date": "2024-10-27 12:00:19 UTC",
    "updated_date": "2024-10-27 12:00:19 UTC"
  },
  {
    "arxiv_id": "2410.20399v1",
    "title": "ThunderKittens: Simple, Fast, and Adorable AI Kernels",
    "authors": [
      "Benjamin F. Spector",
      "Simran Arora",
      "Aaryan Singhal",
      "Daniel Y. Fu",
      "Christopher Ré"
    ],
    "abstract": "The challenge of mapping AI architectures to GPU hardware is creating a\ncritical bottleneck in AI progress. Despite substantial efforts, hand-written\ncustom kernels fail to meet their theoretical performance thresholds, even on\nwell-established operations like linear attention. The diverse hardware\ncapabilities of GPUs might suggest that we need a wide variety of techniques to\nachieve high performance. However, our work explores whether a small number of\nkey abstractions can drastically simplify the process. We present\nThunderKittens (TK), a framework for writing performant AI kernels while\nremaining easy to use and maintain. Our abstractions map to the three levels of\nthe GPU hierarchy: (1) at the warp-level, we provide 16x16 matrix tiles as\nbasic data structures and PyTorch-like parallel compute operations over tiles,\n(2) at the thread-block level, we provide a template for overlapping\nasynchronous operations across parallel warps, and (3) at the grid-level, we\nprovide support to help hide the block launch and tear-down, and memory costs.\nWe show the value of TK by providing kernels that match or outperform prior\nkernels for a range of AI operations. We match CuBLAS and FlashAttention-3 on\nGEMM and attention inference performance and outperform the strongest baselines\nby $10-40\\%$ on attention backwards, $8\\times$ on state space models, and\n$14\\times$ on linear attention.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20399v1",
    "published_date": "2024-10-27 10:07:16 UTC",
    "updated_date": "2024-10-27 10:07:16 UTC"
  },
  {
    "arxiv_id": "2410.20389v1",
    "title": "Lodge++: High-quality and Long Dance Generation with Vivid Choreography Patterns",
    "authors": [
      "Ronghui Li",
      "Hongwen Zhang",
      "Yachao Zhang",
      "Yuxiang Zhang",
      "Youliang Zhang",
      "Jie Guo",
      "Yan Zhang",
      "Xiu Li",
      "Yebin Liu"
    ],
    "abstract": "We propose Lodge++, a choreography framework to generate high-quality,\nultra-long, and vivid dances given the music and desired genre. To handle the\nchallenges in computational efficiency, the learning of complex and vivid\nglobal choreography patterns, and the physical quality of local dance\nmovements, Lodge++ adopts a two-stage strategy to produce dances from coarse to\nfine. In the first stage, a global choreography network is designed to generate\ncoarse-grained dance primitives that capture complex global choreography\npatterns. In the second stage, guided by these dance primitives, a\nprimitive-based dance diffusion model is proposed to further generate\nhigh-quality, long-sequence dances in parallel, faithfully adhering to the\ncomplex choreography patterns. Additionally, to improve the physical\nplausibility, Lodge++ employs a penetration guidance module to resolve\ncharacter self-penetration, a foot refinement module to optimize foot-ground\ncontact, and a multi-genre discriminator to maintain genre consistency\nthroughout the dance. Lodge++ is validated by extensive experiments, which show\nthat our method can rapidly generate ultra-long dances suitable for various\ndance genres, ensuring well-organized global choreography patterns and\nhigh-quality local motion.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://li-ronghui.github.io/lodgepp",
    "pdf_url": "http://arxiv.org/pdf/2410.20389v1",
    "published_date": "2024-10-27 09:32:35 UTC",
    "updated_date": "2024-10-27 09:32:35 UTC"
  },
  {
    "arxiv_id": "2410.20384v1",
    "title": "Addressing the Pitfalls of Image-Based Structural Health Monitoring: A Focus on False Positives, False Negatives, and Base Rate Bias",
    "authors": [
      "Vagelis Plevris"
    ],
    "abstract": "This study explores the limitations of image-based structural health\nmonitoring (SHM) techniques in detecting structural damage. Leveraging machine\nlearning and computer vision, image-based SHM offers a scalable and efficient\nalternative to manual inspections. However, its reliability is impacted by\nchallenges such as false positives, false negatives, and environmental\nvariability, particularly in low base rate damage scenarios. The Base Rate Bias\nplays a significant role, as low probabilities of actual damage often lead to\nmisinterpretation of positive results. This study uses both Bayesian analysis\nand a frequentist approach to evaluate the precision of damage detection\nsystems, revealing that even highly accurate models can yield misleading\nresults when the occurrence of damage is rare. Strategies for mitigating these\nlimitations are discussed, including hybrid systems that combine multiple data\nsources, human-in-the-loop approaches for critical assessments, and improving\nthe quality of training data. These findings provide essential insights into\nthe practical applicability of image-based SHM techniques, highlighting both\ntheir potential and their limitations for real-world infrastructure monitoring.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20384v1",
    "published_date": "2024-10-27 09:15:05 UTC",
    "updated_date": "2024-10-27 09:15:05 UTC"
  },
  {
    "arxiv_id": "2410.20383v1",
    "title": "Multiple kernel concept factorization algorithm based on global fusion",
    "authors": [
      "Fei Li",
      "Liang Du",
      "Chaohong Ren"
    ],
    "abstract": "Non-negative Matrix Factorization(NMF) algorithm can only be used to find low\nrank approximation of original non-negative data while Concept\nFactorization(CF) algorithm extends matrix factorization to single non-linear\nkernel space, improving learning ability and adaptability of matrix\nfactorization. In unsupervised environment, to design or select proper kernel\nfunction for specific dataset, a new algorithm called Globalized Multiple\nKernel CF(GMKCF)was proposed. Multiple candidate kernel functions were input in\nthe same time and learned in the CF framework based on global linear fusion,\nobtaining a clustering result with high quality and stability and solving the\nproblem of kernel function selection that the CF faced. The convergence of the\nproposed algorithm was verified by solving the model with alternate iteration.\nThe experimental results on several real databases show that the proposed\nalgorithm outperforms comparison algorithms in data clustering, such as Kernel\nK-Means(KKM), Spectral Clustering(SC), Kernel CF(KCF), Co-regularized\nmulti-view spectral clustering(Coreg), and Robust Multiple KKM(RMKKM).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "in Chinese language",
    "pdf_url": "http://arxiv.org/pdf/2410.20383v1",
    "published_date": "2024-10-27 09:13:57 UTC",
    "updated_date": "2024-10-27 09:13:57 UTC"
  },
  {
    "arxiv_id": "2410.20380v1",
    "title": "FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion",
    "authors": [
      "Zhenheng Tang",
      "Yonggang Zhang",
      "Peijie Dong",
      "Yiu-ming Cheung",
      "Amelie Chi Zhou",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "abstract": "One-shot Federated Learning (OFL) significantly reduces communication costs\nin FL by aggregating trained models only once. However, the performance of\nadvanced OFL methods is far behind the normal FL. In this work, we provide a\ncausal view to find that this performance drop of OFL methods comes from the\nisolation problem, which means that local isolatedly trained models in OFL may\neasily fit to spurious correlations due to the data heterogeneity. From the\ncausal perspective, we observe that the spurious fitting can be alleviated by\naugmenting intermediate features from other clients. Built upon our\nobservation, we propose a novel learning approach to endow OFL with superb\nperformance and low communication and storage costs, termed as FuseFL.\nSpecifically, FuseFL decomposes neural networks into several blocks, and\nprogressively trains and fuses each block following a bottom-up manner for\nfeature augmentation, introducing no additional communication costs.\nComprehensive experiments demonstrate that FuseFL outperforms existing OFL and\nensemble FL by a significant margin. We conduct comprehensive experiments to\nshow that FuseFL supports high scalability of clients, heterogeneous model\ntraining, and low memory costs. Our work is the first attempt using causality\nto analyze and alleviate data heterogeneity of OFL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20380v1",
    "published_date": "2024-10-27 09:07:10 UTC",
    "updated_date": "2024-10-27 09:07:10 UTC"
  },
  {
    "arxiv_id": "2410.20371v1",
    "title": "Open-Vocabulary Object Detection via Language Hierarchy",
    "authors": [
      "Jiaxing Huang",
      "Jingyi Zhang",
      "Kai Jiang",
      "Shijian Lu"
    ],
    "abstract": "Recent studies on generalizable object detection have attracted increasing\nattention with additional weak supervision from large-scale datasets with\nimage-level labels. However, weakly-supervised detection learning often suffers\nfrom image-to-box label mismatch, i.e., image-level labels do not convey\nprecise object information. We design Language Hierarchical Self-training\n(LHST) that introduces language hierarchy into weakly-supervised detector\ntraining for learning more generalizable detectors. LHST expands the\nimage-level labels with language hierarchy and enables co-regularization\nbetween the expanded labels and self-training. Specifically, the expanded\nlabels regularize self-training by providing richer supervision and mitigating\nthe image-to-box label mismatch, while self-training allows assessing and\nselecting the expanded labels according to the predicted reliability. In\naddition, we design language hierarchical prompt generation that introduces\nlanguage hierarchy into prompt generation which helps bridge the vocabulary\ngaps between training and testing. Extensive experiments show that the proposed\ntechniques achieve superior generalization performance consistently across 14\nwidely studied object detection datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2410.20371v1",
    "published_date": "2024-10-27 08:20:03 UTC",
    "updated_date": "2024-10-27 08:20:03 UTC"
  },
  {
    "arxiv_id": "2410.20362v2",
    "title": "Rethinking Data Synthesis: A Teacher Model Training Recipe with Interpretation",
    "authors": [
      "Yifang Chen",
      "David Zhu",
      "Simon Du",
      "Kevin Jamieson",
      "Yang Liu"
    ],
    "abstract": "Recent advances in large language model (LLM) training have highlighted the\nneed for diverse, high-quality instruction data. Recently, many works are\nexploring synthetic data generation using LLMs. However, they primarily focus\non prompt engineering with standard supervised instruction-finetuned models,\nwhich contains a fundamental limitation: these models are optimized for general\nquestion-answering/problem-solving rather than data generation. We propose a\nparadigm shift named \\textbf{NOMAD} by investigating how to specifically train\nmodels for data generation, demonstrating that this task differs significantly\nfrom training a classical LM. We identify two key factors: no-prompt-masked\ntraining and proper training set size selection. Our method, NOMAD, shows\nsubstantial improvements over baselines, achieving >4\\% gains in TriviaQA and\n>2\\% in GSM8K with limited training data. Finally, we offer new insights by\ninterpreting synthetic data through the lenses of \"relevance\" and \"novelty\".",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20362v2",
    "published_date": "2024-10-27 07:38:39 UTC",
    "updated_date": "2024-12-09 07:17:07 UTC"
  },
  {
    "arxiv_id": "2410.20359v2",
    "title": "Conditional GAN for Enhancing Diffusion Models in Efficient and Authentic Global Gesture Generation from Audios",
    "authors": [
      "Yongkang Cheng",
      "Mingjiang Liang",
      "Shaoli Huang",
      "Gaoge Han",
      "Jifeng Ning",
      "Wei Liu"
    ],
    "abstract": "Audio-driven simultaneous gesture generation is vital for human-computer\ncommunication, AI games, and film production. While previous research has shown\npromise, there are still limitations. Methods based on VAEs are accompanied by\nissues of local jitter and global instability, whereas methods based on\ndiffusion models are hampered by low generation efficiency. This is because the\ndenoising process of DDPM in the latter relies on the assumption that the noise\nadded at each step is sampled from a unimodal distribution, and the noise\nvalues are small. DDIM borrows the idea from the Euler method for solving\ndifferential equations, disrupts the Markov chain process, and increases the\nnoise step size to reduce the number of denoising steps, thereby accelerating\ngeneration. However, simply increasing the step size during the step-by-step\ndenoising process causes the results to gradually deviate from the original\ndata distribution, leading to a significant drop in the quality of the\ngenerated actions and the emergence of unnatural artifacts. In this paper, we\nbreak the assumptions of DDPM and achieves breakthrough progress in denoising\nspeed and fidelity. Specifically, we introduce a conditional GAN to capture\naudio control signals and implicitly match the multimodal denoising\ndistribution between the diffusion and denoising steps within the same sampling\nstep, aiming to sample larger noise values and apply fewer denoising steps for\nhigh-speed generation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by WACV 2025 (Round 1)",
    "pdf_url": "http://arxiv.org/pdf/2410.20359v2",
    "published_date": "2024-10-27 07:25:11 UTC",
    "updated_date": "2024-11-01 09:33:29 UTC"
  },
  {
    "arxiv_id": "2410.20358v2",
    "title": "RopeTP: Global Human Motion Recovery via Integrating Robust Pose Estimation with Diffusion Trajectory Prior",
    "authors": [
      "Mingjiang Liang",
      "Yongkang Cheng",
      "Hualin Liang",
      "Shaoli Huang",
      "Wei Liu"
    ],
    "abstract": "We present RopeTP, a novel framework that combines Robust pose estimation\nwith a diffusion Trajectory Prior to reconstruct global human motion from\nvideos. At the heart of RopeTP is a hierarchical attention mechanism that\nsignificantly improves context awareness, which is essential for accurately\ninferring the posture of occluded body parts. This is achieved by exploiting\nthe relationships with visible anatomical structures, enhancing the accuracy of\nlocal pose estimations. The improved robustness of these local estimations\nallows for the reconstruction of precise and stable global trajectories.\nAdditionally, RopeTP incorporates a diffusion trajectory model that predicts\nrealistic human motion from local pose sequences. This model ensures that the\ngenerated trajectories are not only consistent with observed local actions but\nalso unfold naturally over time, thereby improving the realism and stability of\n3D human motion reconstruction. Extensive experimental validation shows that\nRopeTP surpasses current methods on two benchmark datasets, particularly\nexcelling in scenarios with occlusions. It also outperforms methods that rely\non SLAM for initial camera estimates and extensive optimization, delivering\nmore accurate and realistic trajectories.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by WACV 2025 (Round 1)",
    "pdf_url": "http://arxiv.org/pdf/2410.20358v2",
    "published_date": "2024-10-27 07:19:39 UTC",
    "updated_date": "2024-11-01 09:20:53 UTC"
  },
  {
    "arxiv_id": "2410.20357v2",
    "title": "Dynamics as Prompts: In-Context Learning for Sim-to-Real System Identifications",
    "authors": [
      "Xilun Zhang",
      "Shiqi Liu",
      "Peide Huang",
      "William Jongwon Han",
      "Yiqi Lyu",
      "Mengdi Xu",
      "Ding Zhao"
    ],
    "abstract": "Sim-to-real transfer remains a significant challenge in robotics due to the\ndiscrepancies between simulated and real-world dynamics. Traditional methods\nlike Domain Randomization often fail to capture fine-grained dynamics, limiting\ntheir effectiveness for precise control tasks. In this work, we propose a novel\napproach that dynamically adjusts simulation environment parameters online\nusing in-context learning. By leveraging past interaction histories as context,\nour method adapts the simulation environment dynamics to real-world dynamics\nwithout requiring gradient updates, resulting in faster and more accurate\nalignment between simulated and real-world performance. We validate our\napproach across two tasks: object scooping and table air hockey. In the\nsim-to-sim evaluations, our method significantly outperforms the baselines on\nenvironment parameter estimation by 80% and 42% in the object scooping and\ntable air hockey setups, respectively. Furthermore, our method achieves at\nleast 70% success rate in sim-to-real transfer on object scooping across three\ndifferent objects. By incorporating historical interaction data, our approach\ndelivers efficient and smooth system identification, advancing the deployment\nof robots in dynamic real-world scenarios. Demos are available on our project\npage: https://sim2real-capture.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "website: https://sim2real-capture.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.20357v2",
    "published_date": "2024-10-27 07:13:38 UTC",
    "updated_date": "2025-02-28 19:39:19 UTC"
  },
  {
    "arxiv_id": "2410.20356v2",
    "title": "Uncovering Capabilities of Model Pruning in Graph Contrastive Learning",
    "authors": [
      "Junran Wu",
      "Xueyuan Chen",
      "Shangzhe Li"
    ],
    "abstract": "Graph contrastive learning has achieved great success in pre-training graph\nneural networks without ground-truth labels. Leading graph contrastive learning\nfollows the classical scheme of contrastive learning, forcing model to identify\nthe essential information from augmented views. However, general augmented\nviews are produced via random corruption or learning, which inevitably leads to\nsemantics alteration. Although domain knowledge guided augmentations alleviate\nthis issue, the generated views are domain specific and undermine the\ngeneralization. In this work, motivated by the firm representation ability of\nsparse model from pruning, we reformulate the problem of graph contrastive\nlearning via contrasting different model versions rather than augmented views.\nWe first theoretically reveal the superiority of model pruning in contrast to\ndata augmentations. In practice, we take original graph as input and\ndynamically generate a perturbed graph encoder to contrast with the original\nencoder by pruning its transformation weights. Furthermore, considering the\nintegrity of node embedding in our method, we are capable of developing a local\ncontrastive loss to tackle the hard negative samples that disturb the model\ntraining. We extensively validate our method on various benchmarks regarding\ngraph classification via unsupervised and transfer learning. Compared to the\nstate-of-the-art (SOTA) works, better performance can always be obtained by the\nproposed method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "MM' 24",
    "pdf_url": "http://arxiv.org/pdf/2410.20356v2",
    "published_date": "2024-10-27 07:09:31 UTC",
    "updated_date": "2024-12-11 11:58:06 UTC"
  },
  {
    "arxiv_id": "2410.20352v1",
    "title": "An approach to hummed-tune and song sequences matching",
    "authors": [
      "Loc Bao Pham",
      "Huong Hoang Luong",
      "Phu Thien Tran",
      "Phuc Hoang Ngo",
      "Vi Hoang Nguyen",
      "Thinh Nguyen"
    ],
    "abstract": "Melody stuck in your head, also known as \"earworm\", is tough to get rid of,\nunless you listen to it again or sing it out loud. But what if you can not find\nthe name of that song? It must be an intolerable feeling. Recognizing a song\nname base on humming sound is not an easy task for a human being and should be\ndone by machines. However, there is no research paper published about hum tune\nrecognition. Adapting from Hum2Song Zalo AI Challenge 2021 - a competition\nabout querying the name of a song by user's giving humming tune, which is\nsimilar to Google's Hum to Search. This paper covers details about the\npre-processed data from the original type (mp3) to usable form for training and\ninference. In training an embedding model for the feature extraction phase, we\nran experiments with some states of the art, such as ResNet, VGG, AlexNet,\nMobileNetV2. And for the inference phase, we use the Faiss module to\neffectively search for a song that matched the sequence of humming sound. The\nresult comes at nearly 94\\% in MRR@10 metric on the public test set, along with\nthe top 1 result on the public leaderboard.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20352v1",
    "published_date": "2024-10-27 06:50:43 UTC",
    "updated_date": "2024-10-27 06:50:43 UTC"
  },
  {
    "arxiv_id": "2410.20349v1",
    "title": "Idempotent Unsupervised Representation Learning for Skeleton-Based Action Recognition",
    "authors": [
      "Lilang Lin",
      "Lehong Wu",
      "Jiahang Zhang",
      "Jiaying Liu"
    ],
    "abstract": "Generative models, as a powerful technique for generation, also gradually\nbecome a critical tool for recognition tasks. However, in skeleton-based action\nrecognition, the features obtained from existing pre-trained generative methods\ncontain redundant information unrelated to recognition, which contradicts the\nnature of the skeleton's spatially sparse and temporally consistent properties,\nleading to undesirable performance. To address this challenge, we make efforts\nto bridge the gap in theory and methodology and propose a novel skeleton-based\nidempotent generative model (IGM) for unsupervised representation learning.\nMore specifically, we first theoretically demonstrate the equivalence between\ngenerative models and maximum entropy coding, which demonstrates a potential\nroute that makes the features of generative models more compact by introducing\ncontrastive learning. To this end, we introduce the idempotency constraint to\nform a stronger consistency regularization in the feature space, to push the\nfeatures only to maintain the critical information of motion semantics for the\nrecognition task. Our extensive experiments on benchmark datasets, NTU RGB+D\nand PKUMMD, demonstrate the effectiveness of our proposed method. On the NTU 60\nxsub dataset, we observe a performance improvement from 84.6$\\%$ to 86.2$\\%$.\nFurthermore, in zero-shot adaptation scenarios, our model demonstrates\nsignificant efficacy by achieving promising results in cases that were\npreviously unrecognizable. Our project is available at\n\\url{https://github.com/LanglandsLin/IGM}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20349v1",
    "published_date": "2024-10-27 06:29:04 UTC",
    "updated_date": "2024-10-27 06:29:04 UTC"
  },
  {
    "arxiv_id": "2410.20346v1",
    "title": "Historical Test-time Prompt Tuning for Vision Foundation Models",
    "authors": [
      "Jingyi Zhang",
      "Jiaxing Huang",
      "Xiaoqin Zhang",
      "Ling Shao",
      "Shijian Lu"
    ],
    "abstract": "Test-time prompt tuning, which learns prompts online with unlabelled test\nsamples during the inference stage, has demonstrated great potential by\nlearning effective prompts on-the-fly without requiring any task-specific\nannotations. However, its performance often degrades clearly along the tuning\nprocess when the prompts are continuously updated with the test data flow, and\nthe degradation becomes more severe when the domain of test samples changes\ncontinuously. We propose HisTPT, a Historical Test-time Prompt Tuning technique\nthat memorizes the useful knowledge of the learnt test samples and enables\nrobust test-time prompt tuning with the memorized knowledge. HisTPT introduces\nthree types of knowledge banks, namely, local knowledge bank, hard-sample\nknowledge bank, and global knowledge bank, each of which works with different\nmechanisms for effective knowledge memorization and test-time prompt\noptimization. In addition, HisTPT features an adaptive knowledge retrieval\nmechanism that regularizes the prediction of each test sample by adaptively\nretrieving the memorized knowledge. Extensive experiments show that HisTPT\nachieves superior prompt tuning performance consistently while handling\ndifferent visual recognition tasks (e.g., image classification, semantic\nsegmentation, and object detection) and test samples from continuously changing\ndomains.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2410.20346v1",
    "published_date": "2024-10-27 06:03:15 UTC",
    "updated_date": "2024-10-27 06:03:15 UTC"
  },
  {
    "arxiv_id": "2410.20340v1",
    "title": "Maintaining Informative Coherence: Migrating Hallucinations in Large Language Models via Absorbing Markov Chains",
    "authors": [
      "Jiemin Wu",
      "Songning Lai",
      "Ruiqiang Xiao",
      "Tianlang Xue",
      "Jiayu Yang",
      "Yutao Yue"
    ],
    "abstract": "Large Language Models (LLMs) are powerful tools for text generation,\ntranslation, and summarization, but they often suffer from\nhallucinations-instances where they fail to maintain the fidelity and coherence\nof contextual information during decoding, sometimes overlooking critical\ndetails due to their sampling strategies and inherent biases from training data\nand fine-tuning discrepancies. These hallucinations can propagate through the\nweb, affecting the trustworthiness of information disseminated online. To\naddress this issue, we propose a novel decoding strategy that leverages\nabsorbing Markov chains to quantify the significance of contextual information\nand measure the extent of information loss during generation. By considering\nall possible paths from the first to the last token, our approach enhances the\nreliability of model outputs without requiring additional training or external\ndata. Evaluations on datasets including TruthfulQA, FACTOR, and HaluEval\nhighlight the superior performance of our method in mitigating hallucinations,\nunderscoring the necessity of ensuring accurate information flow in web-based\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20340v1",
    "published_date": "2024-10-27 04:51:18 UTC",
    "updated_date": "2024-10-27 04:51:18 UTC"
  },
  {
    "arxiv_id": "2410.20336v1",
    "title": "Get Large Language Models Ready to Speak: A Late-fusion Approach for Speech Generation",
    "authors": [
      "Maohao Shen",
      "Shun Zhang",
      "Jilong Wu",
      "Zhiping Xiu",
      "Ehab AlBadawy",
      "Yiting Lu",
      "Mike Seltzer",
      "Qing He"
    ],
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\n(NLP) with impressive performance across various text-based tasks. However, the\nextension of text-dominant LLMs to with speech generation tasks remains\nunder-explored. In this work, we introduce a text-to-speech (TTS) system\npowered by a fine-tuned Llama model, named TTS-Llama, that achieves\nstate-of-the-art speech synthesis performance. Building on TTS-Llama, we\nfurther propose MoLE-Llama, a text-and-speech multimodal LLM developed through\npurely late-fusion parameter-efficient fine-tuning (PEFT) and a\nmixture-of-expert architecture. Extensive empirical results demonstrate\nMoLE-Llama's competitive performance on both text-only question-answering (QA)\nand TTS tasks, mitigating catastrophic forgetting issue in either modality.\nFinally, we further explore MoLE-Llama in text-in-speech-out QA tasks,\ndemonstrating its great potential as a multimodal dialog system capable of\nspeech generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20336v1",
    "published_date": "2024-10-27 04:28:57 UTC",
    "updated_date": "2024-10-27 04:28:57 UTC"
  },
  {
    "arxiv_id": "2410.20327v5",
    "title": "R-LLaVA: Improving Med-VQA Understanding through Visual Region of Interest",
    "authors": [
      "Xupeng Chen",
      "Zhixin Lai",
      "Kangrui Ruan",
      "Shichu Chen",
      "Jiaxiang Liu",
      "Zuozhu Liu"
    ],
    "abstract": "Artificial intelligence has made significant strides in medical visual\nquestion answering (Med-VQA), yet prevalent studies often interpret images\nholistically, overlooking the visual regions of interest that may contain\ncrucial information, potentially aligning with a doctor's prior knowledge that\ncan be incorporated with minimal annotations (e.g., bounding boxes). To address\nthis gap, this paper introduces R-LLaVA, designed to enhance biomedical VQA\nunderstanding by integrating simple medical annotations as prior knowledge\ndirectly into the image space through CLIP. These annotated visual regions of\ninterest are then fed into the LLaVA model during training, aiming to enrich\nthe model's understanding of biomedical queries. Experimental evaluation on\nfour standard Med-VQA datasets demonstrates R-LLaVA's superiority over existing\nstate-of-the-art (SoTA) methods. Additionally, to verify the model's capability\nin visual comprehension, a novel multiple-choice medical visual understanding\ndataset is introduced, confirming the positive impact of focusing on visual\nregions of interest in advancing biomedical VQA understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20327v5",
    "published_date": "2024-10-27 03:56:56 UTC",
    "updated_date": "2025-03-09 05:23:35 UTC"
  },
  {
    "arxiv_id": "2410.21326v1",
    "title": "Self-Supervised Learning and Opportunistic Inference for Continuous Monitoring of Freezing of Gait in Parkinson's Disease",
    "authors": [
      "Shovito Barua Soumma",
      "Kartik Mangipudi",
      "Daniel Peterson",
      "Shyamal Mehta",
      "Hassan Ghasemzadeh"
    ],
    "abstract": "Parkinson's disease (PD) is a progressive neurological disorder that impacts\nthe quality of life significantly, making in-home monitoring of motor symptoms\nsuch as Freezing of Gait (FoG) critical. However, existing symptom monitoring\ntechnologies are power-hungry, rely on extensive amounts of labeled data, and\noperate in controlled settings. These shortcomings limit real-world deployment\nof the technology. This work presents LIFT-PD, a computationally-efficient\nself-supervised learning framework for real-time FoG detection. Our method\ncombines self-supervised pre-training on unlabeled data with a novel\ndifferential hopping windowing technique to learn from limited labeled\ninstances. An opportunistic model activation module further minimizes power\nconsumption by selectively activating the deep learning module only during\nactive periods. Extensive experimental results show that LIFT-PD achieves a\n7.25% increase in precision and 4.4% improvement in accuracy compared to\nsupervised models while using as low as 40% of the labeled training data used\nfor supervised learning. Additionally, the model activation module reduces\ninference time by up to 67% compared to continuous inference. LIFT-PD paves the\nway for practical, energy-efficient, and unobtrusive in-home monitoring of PD\npatients with minimal labeling requirements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.21326v1",
    "published_date": "2024-10-27 03:47:18 UTC",
    "updated_date": "2024-10-27 03:47:18 UTC"
  },
  {
    "arxiv_id": "2410.20321v1",
    "title": "Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs",
    "authors": [
      "Xingrui Zhuo",
      "Jiapu Wang",
      "Gongqing Wu",
      "Shirui Pan",
      "Xindong Wu"
    ],
    "abstract": "Knowledge Graph Query Embedding (KGQE) aims to embed First-Order Logic (FOL)\nqueries in a low-dimensional KG space for complex reasoning over incomplete\nKGs. To enhance the generalization of KGQE models, recent studies integrate\nvarious external information (such as entity types and relation context) to\nbetter capture the logical semantics of FOL queries. The whole process is\ncommonly referred to as Query Pattern Learning (QPL). However, current QPL\nmethods typically suffer from the pattern-entity alignment bias problem,\nleading to the learned defective query patterns limiting KGQE models'\nperformance. To address this problem, we propose an effective Query Instruction\nParsing Plugin (QIPP) that leverages the context awareness of Pre-trained\nLanguage Models (PLMs) to capture latent query patterns from code-like query\ninstructions. Unlike the external information introduced by previous QPL\nmethods, we first propose code-like instructions to express FOL queries in an\nalternative format. This format utilizes textual variables and nested tuples to\nconvey the logical semantics within FOL queries, serving as raw materials for a\nPLM-based instruction encoder to obtain complete query patterns. Building on\nthis, we design a query-guided instruction decoder to adapt query patterns to\nKGQE models. To further enhance QIPP's effectiveness across various KGQE\nmodels, we propose a query pattern injection mechanism based on compressed\noptimization boundaries and an adaptive normalization component, allowing KGQE\nmodels to utilize query patterns more efficiently. Extensive experiments\ndemonstrate that our plug-and-play method improves the performance of eight\nbasic KGQE models and outperforms two state-of-the-art QPL methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20321v1",
    "published_date": "2024-10-27 03:18:52 UTC",
    "updated_date": "2024-10-27 03:18:52 UTC"
  },
  {
    "arxiv_id": "2410.20320v1",
    "title": "Few-shot Open Relation Extraction with Gaussian Prototype and Adaptive Margin",
    "authors": [
      "Tianlin Guo",
      "Lingling Zhang",
      "Jiaxin Wang",
      "Yuokuo Lei",
      "Yifei Li",
      "Haofen Wang",
      "Jun Liu"
    ],
    "abstract": "Few-shot relation extraction with none-of-the-above (FsRE with NOTA) aims at\npredicting labels in few-shot scenarios with unknown classes. FsRE with NOTA is\nmore challenging than the conventional few-shot relation extraction task, since\nthe boundaries of unknown classes are complex and difficult to learn.\nMeta-learning based methods, especially prototype-based methods, are the\nmainstream solutions to this task. They obtain the classification boundary by\nlearning the sample distribution of each class. However, their performance is\nlimited because few-shot overfitting and NOTA boundary confusion lead to\nmisclassification between known and unknown classes. To this end, we propose a\nnovel framework based on Gaussian prototype and adaptive margin named GPAM for\nFsRE with NOTA, which includes three modules, semi-factual representation,\nGMM-prototype metric learning and decision boundary learning. The first two\nmodules obtain better representations to solve the few-shot problem through\ndebiased information enhancement and Gaussian space distance measurement. The\nthird module learns more accurate classification boundaries and prototypes\nthrough adaptive margin and negative sampling. In the training procedure of\nGPAM, we use contrastive learning loss to comprehensively consider the effects\nof range and margin on the classification of known and unknown classes to\nensure the model's stability and robustness. Sufficient experiments and\nablations on the FewRel dataset show that GPAM surpasses previous prototype\nmethods and achieves state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20320v1",
    "published_date": "2024-10-27 03:16:09 UTC",
    "updated_date": "2024-10-27 03:16:09 UTC"
  },
  {
    "arxiv_id": "2410.20315v1",
    "title": "Deep Learning Based Dense Retrieval: A Comparative Study",
    "authors": [
      "Ming Zhong",
      "Zhizhi Wu",
      "Nanako Honda"
    ],
    "abstract": "Dense retrievers have achieved state-of-the-art performance in various\ninformation retrieval tasks, but their robustness against tokenizer poisoning\nremains underexplored. In this work, we assess the vulnerability of dense\nretrieval systems to poisoned tokenizers by evaluating models such as BERT,\nDense Passage Retrieval (DPR), Contriever, SimCSE, and ANCE. We find that\nsupervised models like BERT and DPR experience significant performance\ndegradation when tokenizers are compromised, while unsupervised models like\nANCE show greater resilience. Our experiments reveal that even small\nperturbations can severely impact retrieval accuracy, highlighting the need for\nrobust defenses in critical applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.20315v1",
    "published_date": "2024-10-27 02:52:36 UTC",
    "updated_date": "2024-10-27 02:52:36 UTC"
  },
  {
    "arxiv_id": "2410.20310v1",
    "title": "ANOMIX: A Simple yet Effective Hard Negative Generation via Mixing for Graph Anomaly Detection",
    "authors": [
      "Hwan Kim",
      "Junghoon Kim",
      "Sungsu Lim"
    ],
    "abstract": "Graph contrastive learning (GCL) generally requires a large number of\nsamples. The one of the effective ways to reduce the number of samples is using\nhard negatives (e.g., Mixup). Designing mixing-based approach for GAD can be\ndifficult due to imbalanced data or limited number of anomalies. We propose\nANOMIX, a framework that consists of a novel graph mixing approach, ANOMIX-M,\nand multi-level contrasts for GAD. ANOMIX-M can effectively mix abnormality and\nnormality from input graph to generate hard negatives, which are important for\nefficient GCL. ANOMIX is (a) A first mixing approach: firstly attempting graph\nmixing to generate hard negatives for GAD task and node- and subgraph-level\ncontrasts to distinguish underlying anomalies. (b) Accurate: winning the\nhighest AUC, up to 5.49% higher and 1.76% faster. (c) Effective: reducing the\nnumber of samples nearly 80% in GCL. Code is available at\nhttps://github.com/missinghwan/ANOMIX.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20310v1",
    "published_date": "2024-10-27 02:35:12 UTC",
    "updated_date": "2024-10-27 02:35:12 UTC"
  },
  {
    "arxiv_id": "2410.20309v1",
    "title": "Enhancing Community Vision Screening -- AI Driven Retinal Photography for Early Disease Detection and Patient Trust",
    "authors": [
      "Xiaofeng Lei",
      "Yih-Chung Tham",
      "Jocelyn Hui Lin Goh",
      "Yangqin Feng",
      "Yang Bai",
      "Zhi Da Soh",
      "Rick Siow Mong Goh",
      "Xinxing Xu",
      "Yong Liu",
      "Ching-Yu Cheng"
    ],
    "abstract": "Community vision screening plays a crucial role in identifying individuals\nwith vision loss and preventing avoidable blindness, particularly in rural\ncommunities where access to eye care services is limited. Currently, there is a\npressing need for a simple and efficient process to screen and refer\nindividuals with significant eye disease-related vision loss to tertiary eye\ncare centers for further care. An ideal solution should seamlessly and readily\nintegrate with existing workflows, providing comprehensive initial screening\nresults to service providers, thereby enabling precise patient referrals for\ntimely treatment. This paper introduces the Enhancing Community Vision\nScreening (ECVS) solution, which addresses the aforementioned concerns with a\nnovel and feasible solution based on simple, non-invasive retinal photography\nfor the detection of pathology-based visual impairment. Our study employs four\ndistinct deep learning models: RETinal photo Quality Assessment (RETQA),\nPathology Visual Impairment detection (PVI), Eye Disease Diagnosis (EDD) and\nVisualization of Lesion Regions of the eye (VLR). We conducted experiments on\nover 10 datasets, totaling more than 80,000 fundus photos collected from\nvarious sources. The models integrated into ECVS achieved impressive AUC scores\nof 0.98 for RETQA, 0.95 for PVI, and 0.90 for EDD, along with a DICE\ncoefficient of 0.48 for VLR. These results underscore the promising\ncapabilities of ECVS as a straightforward and scalable method for\ncommunity-based vision screening.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "11 pages, 4 figures, published in MICCAI2024 OMIA XI workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.20309v1",
    "published_date": "2024-10-27 02:31:19 UTC",
    "updated_date": "2024-10-27 02:31:19 UTC"
  },
  {
    "arxiv_id": "2410.20302v3",
    "title": "Sequential Large Language Model-Based Hyper-parameter Optimization",
    "authors": [
      "Kanan Mahammadli",
      "Seyda Ertekin"
    ],
    "abstract": "This study introduces SLLMBO, an innovative framework leveraging large\nlanguage models (LLMs) for hyperparameter optimization (HPO), incorporating\ndynamic search space adaptability, enhanced parameter space exploitation, and a\nnovel LLM-tree-structured parzen estimator (LLM-TPE) sampler. By addressing\nlimitations in recent fully LLM-based methods and traditional bayesian\noptimization (BO), SLLMBO achieves more robust optimization. This comprehensive\nbenchmarking evaluates multiple LLMs, including GPT-3.5-Turbo, GPT-4o,\nClaude-Sonnet-3.5, and Gemini-1.5-Flash, extending prior work and establishing\nSLLMBO as the first framework to benchmark a diverse set of LLMs for HPO. By\nintegrating LLMs' established strengths in parameter initialization with the\nexploitation abilities demonstrated in this study, alongside TPE's exploration\ncapabilities, the LLM-TPE sampler achieves a balanced exploration-exploitation\ntrade-off, reduces API costs, and mitigates premature early stoppings for more\neffective parameter searches. Across 14 tabular tasks in classification and\nregression, the LLM-TPE sampler outperformed fully LLM-based methods and\nachieved superior results over BO methods in 9 tasks. Testing early stopping in\nbudget-constrained scenarios demonstrated competitive performance, indicating\nthat LLM-based methods generally benefit from extended iterations for optimal\nresults. This work lays the foundation for future research exploring\nopen-source LLMs, reproducibility of LLM results in HPO, and benchmarking\nSLLMBO on complex datasets, such as image classification, segmentation, and\nmachine translation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20302v3",
    "published_date": "2024-10-27 00:50:30 UTC",
    "updated_date": "2025-01-02 23:08:47 UTC"
  },
  {
    "arxiv_id": "2410.20298v1",
    "title": "Learning from Response not Preference: A Stackelberg Approach for LLM Detoxification using Non-parallel Data",
    "authors": [
      "Xinhong Xie",
      "Tao Li",
      "Quanyan Zhu"
    ],
    "abstract": "Text detoxification, a variant of style transfer tasks, finds useful\napplications in online social media. This work presents a fine-tuning method\nthat only uses non-parallel data to turn large language models (LLM) into a\ndetoxification rewritter. We model the fine-tuning process as a Stackelberg\ngame between an LLM (leader) and a toxicity screener (follower), which is a\nbinary style classifier (toxic or non-toxic). The LLM aims to align its\npreference according to the screener and generate paraphases passing the\nscreening. The primary challenge of non-parallel data fine-tuning is incomplete\npreference. In the case of unsuccessful paraphrases, the classifier cannot\nestablish a preference between the input and paraphrase, as they belong to the\nsame toxic style. Hence, preference-alignment fine-tuning methods, such as\ndirect preference optimization (DPO), no longer apply. To address the challenge\nof incomplete preference, we propose Stackelberg response optimization (SRO),\nadapted from DPO, to enable the LLM to learn from the follower's response. The\ngist is that SRO decreases the likelihood of generating the paraphrase if it\nfails the follower's screening while performing DPO on the pair of the toxic\ninput and its paraphrase when the latter passes the screening. Experiments\nindicate that the SRO-fine-tunned LLM achieves satisfying performance\ncomparable to state-of-the-art models regarding style accuracy, content\nsimilarity, and fluency. The overall detoxification performance surpasses other\ncomputing methods and matches the human reference. Additional empirical\nevidence suggests that SRO is sensitive to the screener's feedback, and a\nslight perturbation leads to a significant performance drop. We release the\ncode and LLM models at \\url{https://github.com/XXXinhong/Detoxification_LLM}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20298v1",
    "published_date": "2024-10-27 00:39:54 UTC",
    "updated_date": "2024-10-27 00:39:54 UTC"
  },
  {
    "arxiv_id": "2410.20297v1",
    "title": "Fine-Tuning and Evaluating Open-Source Large Language Models for the Army Domain",
    "authors": [
      "Daniel C. Ruiz",
      "John Sell"
    ],
    "abstract": "In recent years, the widespread adoption of Large Language Models (LLMs) has\nsparked interest in their potential for application within the military domain.\nHowever, the current generation of LLMs demonstrate sub-optimal performance on\nArmy use cases, due to the prevalence of domain-specific vocabulary and jargon.\nIn order to fully leverage LLMs in-domain, many organizations have turned to\nfine-tuning to circumvent the prohibitive costs involved in training new LLMs\nfrom scratch. In light of this trend, we explore the viability of adapting\nopen-source LLMs for usage in the Army domain in order to address their\nexisting lack of domain-specificity. Our investigations have resulted in the\ncreation of three distinct generations of TRACLM, a family of LLMs fine-tuned\nby The Research and Analysis Center (TRAC), Army Futures Command (AFC). Through\ncontinuous refinement of our training pipeline, each successive iteration of\nTRACLM displayed improved capabilities when applied to Army tasks and use\ncases. Furthermore, throughout our fine-tuning experiments, we recognized the\nneed for an evaluation framework that objectively quantifies the Army\ndomain-specific knowledge of LLMs. To address this, we developed MilBench, an\nextensible software framework that efficiently evaluates the Army knowledge of\na given LLM using tasks derived from doctrine and assessments. We share\npreliminary results, models, methods, and recommendations on the creation of\nTRACLM and MilBench. Our work significantly informs the development of LLM\ntechnology across the DoD and augments senior leader decisions with respect to\nartificial intelligence integration.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20297v1",
    "published_date": "2024-10-27 00:39:24 UTC",
    "updated_date": "2024-10-27 00:39:24 UTC"
  }
]