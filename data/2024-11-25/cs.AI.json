{
  "date": "2024-11-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-25 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 107 篇论文，主要聚焦于 AI 和 LLM 的创新应用，包括多模态模型、强化学习、生成式任务和机器人导航等领域，其中 LLM 在复杂任务中的鲁棒性和解释性（如 O1 模型复制和 LLM-as-a-judge）最为令人印象深刻，同时 Ion Stoica 等知名学者的作品凸显了 AI 系统工程的潜力。\n\n下面，我挑选了最具影响力和话题度的论文进行简要讨论，先从 LLM 和多模态模型入手，再聊生成式任务和机器人相关内容。其他论文如经济学、音乐或较小众主题（如 Turbofan 引擎预测），我将快速掠过，以控制篇幅。每个条目列出论文标题（中文 + 英文），并清晰概述主要贡献和发现，保留核心学术术语。\n\n### LLM 和多模态模型：焦点在于模型鲁棒性、解释性和多任务能力\n- **O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?（O1 复制之旅 -- 第二部分：通过简单蒸馏超越 O1-preview，是重大进展还是痛苦教训？）**  \n  作者包括 Zhen Huang 和 Pengfei Liu。该论文通过简单知识蒸馏技术（如从 O1 API 蒸馏数据）提升 LLM 在数学推理任务上的性能，实现了比 O1-preview 更高的准确率，但警告过度依赖蒸馏可能导致泛化问题。主要贡献：证明蒸馏能加速 LLM 训练，同时强调研究者需注重基础原理，避免短期优化陷阱。\n\n- **Self-Generated Critiques Boost Reward Modeling for Language Models（自我生成评论提升语言模型的奖励建模）**  \n  作者团队包括 Yue Yu 和 Chao Zhang。论文提出 Critic-RM 框架，使用 LLM 生成评论来优化奖励模型，提高了数学推理任务的准确率（提升 3.7%-7.3%）。主要发现：自我监督评论能减少幻觉（hallucinations），并在无额外监督下提升模型鲁棒性。\n\n- **LLM Augmentations to support Analytical Reasoning over Multiple Documents（LLM 增强用于多文档分析推理）**  \n  作者如 Naren Ramakrishnan。论文开发了动态证据树（DET）模块，帮助 LLM 处理多文档分析，支持情报分析师任务。主要贡献：LLM 通过记忆模块提升多线程推理能力，但当前模型仍需改进以避免幻觉。\n\n- **BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment（BayLing 2：一种高效语言对齐的多语言大型语言模型）**  \n  作者包括 Yang Feng。论文构建了 BayLing-2 模型，通过高效语言对齐从高资源语言（如英语）向低资源语言转移能力，使用 3.2 百万指令数据集训练。主要发现：在多语言翻译和知识任务上，BayLing 2 显著提升了低资源语言的性能，保留了 LLM 的泛化能力。\n\n- **Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation（自动事实性指标是否真正测量事实性？一个批判性评估）**  \n  作者 Byron C. Wallace。论文质疑现有事实性指标（如 ROUGE）的可靠性，通过实验证明这些指标易受浅层特征影响。主要贡献：引入“游戏”方法测试指标鲁棒性，呼吁开发更可靠的事实性评估标准。\n\n- **From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge（从生成到判断：LLM-as-a-judge 的机会与挑战）**  \n  作者如 Huan Liu。论文综述了 LLM 用作判断工具（如评分和排名）的潜力，提出分类框架（what、how、where）。主要发现：LLM 在任务评估中表现出色，但需解决偏差和鲁棒性问题。\n\n这些 LLM 相关论文突出了模型在解释性和多任务上的进步，但也暴露了幻觉和泛化挑战，Ion Stoica 的作品尤其值得关注，因为它强调规格（specifications）在构建可靠 AI 系统中的作用。\n\n### 生成式任务和视觉模型：创新在于高效生成和鲁棒性\n- **DreamRunner: Fine-Grained Compositional Story-to-Video Generation with Retrieval-Augmented Motion Adaptation（DreamRunner：通过检索增强运动适配的细粒度合成故事到视频生成）**  \n  作者包括 Mohit Bansal。论文提出 DreamRunner 框架，使用 LLM 结构化脚本并检索视频进行运动适配，实现高保真故事视频生成。主要贡献：在机器人任务上，模型提升了文本对齐和角色一致性，显著超越基线。\n\n- **UniPose: A Unified Multimodal Framework for Human Pose Comprehension, Generation and Editing（UniPose：一个统一的 multimodal 框架用于人体姿势理解、生成和编辑）**  \n  作者如 Xilin Chen。论文开发了 UniPose，使用 LLM 和视觉编码器处理图像、文本和 3D 姿势，实现多任务姿势处理。主要发现：统一学习策略提升了模型泛化性，在姿势生成任务上表现出色。\n\n- **DiffGuard: Text-Based Safety Checker for Diffusion Models（DiffGuard：扩散模型的基于文本的安全检查器）**  \n  作者团队包括 Katarzyna Kapusta。论文提出 DiffGuard 过滤器，提升扩散模型的安全性，减少生成不当内容。主要贡献：在信息战场景下，模型比现有过滤器提高 14% 的效果。\n\n这些生成模型论文展示了高效视频和图像生成的潜力，特别是在多模态融合上，DreamRunner 的故事生成尤其引人注目。\n\n### 机器人和导航：强调实际应用和鲁棒性\n- **RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics（RoboSpatial：为机器人教授空间理解的 2D 和 3D 视觉语言模型）**  \n  作者包括 Yu Su。论文构建了 RoboSpatial 数据集和框架，使用自监督学习提升机器人空间推理。主要发现：在导航任务上，模型显著改善物体检测和操作性能。\n\n- **TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation（TopV-Nav：解锁多模态 LLM 在零样本物体导航中的顶视图空间推理潜力）**  \n  作者如 Si Liu。论文提出 TopV-Nav，使用自适应提示生成顶视图地图，提升零样本导航效率。主要贡献：在 MP3D 数据集上，模型实现了更精确的路径规划。\n\n机器人相关论文突出了 LLM 在导航的实际价值，RoboSpatial 的数据集创新特别值得关注。\n\n### 其他快速掠过\n其他论文如 Anomaly Detection in California Electricity Price Forecasting（加州电力价格预测中的异常检测）和 Clustering Time Series Data（时间序列数据聚类）等，聚焦特定领域优化，但影响力较小，仅提到它们通过 PCA 和聚类提升了预测准确性（e.g. 电力市场风险管理）。同样，医疗论文如 Med-PerSAM（医疗图像分割）虽有进展，但非核心热点，这里不展开。\n\n总之，今天的 arXiv 更新强调了 AI 的多任务潜力，但也暴露了挑战，如模型泛化和社会影响。感兴趣的读者可关注 LLM 领域的突破性工作，持续跟踪进展！",
  "papers": [
    {
      "arxiv_id": "2411.16985v1",
      "title": "Teaching Smaller Language Models To Generalise To Unseen Compositional Questions (Full Thesis)",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Hartill"
      ],
      "abstract": "Pretrained large Language Models (LLMs) are able to answer questions that are\nunlikely to have been encountered during training. However a diversity of\npotential applications exist in the broad domain of reasoning systems and\nconsiderations such as latency, cost, available compute resource and internet\nconnectivity are relevant in determining an appropriate approach. We consider\nthe setting where some local compute capacity is available at inference time\nbut internet connectivity is not.\n  Similar to a general-purpose LLM, we assume that our much smaller Reasoning\nModels may be asked arbitrary questions from unknown distributions, so we focus\non evaluation in an unseen setting. We train our models to answer diverse\nquestions by instilling an ability to reason over a retrieved context. We\nacquire context from two knowledge sources; a Wikipedia corpus queried using a\nmulti-hop dense retrieval system with novel extensions, and from rationales\ngenerated from a larger Language Model optimised to run in a lower resource\nenvironment.\n  Our main contributions: We propose novel methods to show that our model is\ncapable of answering contextualised questions without memorisation. We\nestablish a comprehensive set of baseline results on unseen evaluation\ndatasets. We show that the addition of novel retrieval-augmented training\ndatasets (RATD) to the training regime of the Reasoning Model significantly\nimproves results. We demonstrate further significant improvement through the\napplication of methods for combining knowledge from two sources. The first\nmethod (RR) involves training a novel Rationale Ranking model to score both\ngenerated rationales and retrieved contexts with respect to relevance and\ntruthfulness. We use the scores to derive combined contexts. We also show that\nutilising the RATD datasets enables our model to become proficient at utilising\ncombined noisy contexts.",
      "tldr_zh": "这篇论文探讨了训练较小的Language Models，使其能够泛化到未见过的组合问题（compositional questions），特别是在无互联网连接的本地计算环境中。研究方法包括使用多跳密集检索从Wikipedia语料库获取上下文，以及从较大Language Model生成的理由来增强训练。核心贡献是提出新型检索增强训练数据集（RATD），显著提升了模型的性能；同时，开发了Rationale Ranking (RR)模型来结合并评分多种知识来源，提高了模型对噪声上下文的处理能力，并在未见数据集上建立了全面基线结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16985v1",
      "published_date": "2024-11-25 23:25:34 UTC",
      "updated_date": "2024-11-25 23:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:03:09.624904"
    },
    {
      "arxiv_id": "2411.16975v1",
      "title": "ExpTest: Automating Learning Rate Searching and Tuning with Insights from Linearized Neural Networks",
      "title_zh": "ExpTest：利用线性化神经网络见解自动进行学习率搜索和调优",
      "authors": [
        "Zan Chaudhry",
        "Naoko Mizuno"
      ],
      "abstract": "Hyperparameter tuning remains a significant challenge for the training of\ndeep neural networks (DNNs), requiring manual and/or time-intensive grid\nsearches, increasing resource costs and presenting a barrier to the\ndemocratization of machine learning. The global initial learning rate for DNN\ntraining is particularly important. Several techniques have been proposed for\nautomated learning rate tuning during training; however, they still require\nmanual searching for the global initial learning rate. Though methods exist\nthat do not require this initial selection, they suffer from poor performance.\nHere, we present ExpTest, a sophisticated method for initial learning rate\nsearching and subsequent learning rate tuning for the training of DNNs. ExpTest\ndraws on insights from linearized neural networks and the form of the loss\ncurve, which we treat as a real-time signal upon which we perform hypothesis\ntesting. We mathematically justify ExpTest and provide empirical support.\nExpTest requires minimal overhead, is robust to hyperparameter choice, and\nachieves state-of-the-art performance on a variety of tasks and architectures,\nwithout initial learning rate selection or learning rate scheduling.",
      "tldr_zh": "该研究针对深度神经网络（DNNs）训练中的超参数调优问题，特别是全局初始学习率的挑战，提出了一种自动化方法ExpTest，以减少手动搜索和资源消耗。ExpTest利用线性化神经网络的洞见，将损失曲线视为实时信号进行假设测试，从而实现初始学习率的搜索和后续调优，并通过数学证明和实证支持其有效性。该方法无需手动选择初始学习率或学习率调度，开销最小，在多种任务和架构上表现出色，实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16975v1",
      "published_date": "2024-11-25 22:58:22 UTC",
      "updated_date": "2024-11-25 22:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:03:21.716877"
    },
    {
      "arxiv_id": "2411.16972v1",
      "title": "Clustering Time Series Data with Gaussian Mixture Embeddings in a Graph Autoencoder Framework",
      "title_zh": "使用高斯混合嵌入在图自编码器框架中对时间序列数据进行聚类",
      "authors": [
        "Amirabbas Afzali",
        "Hesam Hosseini",
        "Mohmmadamin Mirzai",
        "Arash Amini"
      ],
      "abstract": "Time series data analysis is prevalent across various domains, including\nfinance, healthcare, and environmental monitoring. Traditional time series\nclustering methods often struggle to capture the complex temporal dependencies\ninherent in such data. In this paper, we propose the Variational Mixture Graph\nAutoencoder (VMGAE), a graph-based approach for time series clustering that\nleverages the structural advantages of graphs to capture enriched data\nrelationships and produces Gaussian mixture embeddings for improved\nseparability. Comparisons with baseline methods are included with experimental\nresults, demonstrating that our method significantly outperforms\nstate-of-the-art time-series clustering techniques. We further validate our\nmethod on real-world financial data, highlighting its practical applications in\nfinance. By uncovering community structures in stock markets, our method\nprovides deeper insights into stock relationships, benefiting market\nprediction, portfolio optimization, and risk management.",
      "tldr_zh": "本研究提出 Variational Mixture Graph Autoencoder (VMGAE)，一种基于图自编码器框架的时序数据聚类方法，利用图结构捕获复杂的时间依赖关系，并通过 Gaussian Mixture Embeddings 提升数据可分性。相比传统方法，VMGAE 在实验中显著优于现有技术，在多个基准测试中表现出色。作者在真实金融数据上验证了该方法，揭示了股票市场的社区结构，为市场预测、投资组合优化和风险管理提供宝贵洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "First two listed authors have equal contribution. Author ordering is\n  determined by coin flip",
      "pdf_url": "http://arxiv.org/pdf/2411.16972v1",
      "published_date": "2024-11-25 22:49:01 UTC",
      "updated_date": "2024-11-25 22:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:03:32.391580"
    },
    {
      "arxiv_id": "2411.16959v2",
      "title": "RoCoDA: Counterfactual Data Augmentation for Data-Efficient Robot Learning from Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Ezra Ameperosa",
        "Jeremy A. Collins",
        "Mrinal Jain",
        "Animesh Garg"
      ],
      "abstract": "Imitation learning in robotics faces significant challenges in generalization\ndue to the complexity of robotic environments and the high cost of data\ncollection. We introduce RoCoDA, a novel method that unifies the concepts of\ninvariance, equivariance, and causality within a single framework to enhance\ndata augmentation for imitation learning. RoCoDA leverages causal invariance by\nmodifying task-irrelevant subsets of the environment state without affecting\nthe policy's output. Simultaneously, we exploit SE(3) equivariance by applying\nrigid body transformations to object poses and adjusting corresponding actions\nto generate synthetic demonstrations. We validate RoCoDA through extensive\nexperiments on five robotic manipulation tasks, demonstrating improvements in\npolicy performance, generalization, and sample efficiency compared to\nstate-of-the-art data augmentation methods. Our policies exhibit robust\ngeneralization to unseen object poses, textures, and the presence of\ndistractors. Furthermore, we observe emergent behavior such as re-grasping,\nindicating policies trained with RoCoDA possess a deeper understanding of task\ndynamics. By leveraging invariance, equivariance, and causality, RoCoDA\nprovides a principled approach to data augmentation in imitation learning,\nbridging the gap between geometric symmetries and causal reasoning. Project\nPage: https://rocoda.github.io",
      "tldr_zh": "该论文提出 RoCoDA，一种基于 counterfactual data augmentation 的新方法，用于提升数据高效的机器人模仿学习（imitation learning）。RoCoDA 统一整合了 invariance（不变性）、equivariance（等变性）和 causality（因果性），通过修改任务无关的环境状态来实现 causal invariance，并利用 SE(3) equivariance 对物体姿态施加刚体变换以生成合成演示，从而增强数据多样性。实验在五个机器人操作任务上验证了 RoCoDA 的效果，与现有方法相比，它显著提高了策略性能、泛化能力和样本效率，并展示了鲁棒性，如对未见物体姿态、纹理和干扰物的适应，以及出现紧急行为如 re-grasping，表明策略对任务动态有更深理解。总的来说，RoCoDA 桥接了几何对称性和因果推理，提供了一个原则性的数据增强框架。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to 2025 IEEE International Conference on Robotics and\n  Automation (ICRA)",
      "pdf_url": "http://arxiv.org/pdf/2411.16959v2",
      "published_date": "2024-11-25 21:57:15 UTC",
      "updated_date": "2025-05-20 01:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:03:45.221813"
    },
    {
      "arxiv_id": "2411.16956v1",
      "title": "Contrastive Deep Learning Reveals Age Biomarkers in Histopathological Skin Biopsies",
      "title_zh": "对比深度学习揭示组织病理学皮肤活检中的年龄生物标志物",
      "authors": [
        "Kaustubh Chakradeo",
        "Pernille Nielsen",
        "Lise Mette Rahbek Gjerdrum",
        "Gry Sahl Hansen",
        "David A Duchêne",
        "Laust H Mortensen",
        "Majken K Jensen",
        "Samir Bhatt"
      ],
      "abstract": "As global life expectancy increases, so does the burden of chronic diseases,\nyet individuals exhibit considerable variability in the rate at which they age.\nIdentifying biomarkers that distinguish fast from slow ageing is crucial for\nunderstanding the biology of ageing, enabling early disease detection, and\nimproving prevention strategies. Using contrastive deep learning, we show that\nskin biopsy images alone are sufficient to determine an individual's age. We\nthen use visual features in histopathology slides of the skin biopsies to\nconstruct a novel biomarker of ageing. By linking with comprehensive health\nregisters in Denmark, we demonstrate that visual features in histopathology\nslides of skin biopsies predict mortality and the prevalence of chronic\nage-related diseases. Our work highlights how routinely collected health data\ncan provide additional value when used together with deep learning, by creating\na new biomarker for ageing which can be actively used to determine mortality\nover time.",
      "tldr_zh": "本研究利用对比深度学习（contrastive deep learning）分析组织病理学皮肤活检图像，成功识别个体年龄，并构建了一个新型衰老生物标志物，以区分快速和缓慢衰老。研究发现，这些图像中的视觉特征不仅能预测死亡率，还与慢性年龄相关疾病的发生率相关联。借助丹麦健康登记数据，该方法证明了常规健康数据与深度学习结合的价值，为衰老生物学研究、早期疾病检测和预防策略提供新工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 5 tables, 5 figures Under review: npj Digital Medicine",
      "pdf_url": "http://arxiv.org/pdf/2411.16956v1",
      "published_date": "2024-11-25 21:52:01 UTC",
      "updated_date": "2024-11-25 21:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:03:56.978939"
    },
    {
      "arxiv_id": "2411.16954v1",
      "title": "Understanding GEMM Performance and Energy on NVIDIA Ada Lovelace: A Machine Learning-Based Analytical Approach",
      "title_zh": "理解 NVIDIA Ada Lovelace 上 GEMM 的性能和能耗：一种基于机器学习的分析方法",
      "authors": [
        "Xiaoteng",
        "Liu",
        "Pavly Halim"
      ],
      "abstract": "Analytical framework for predicting General Matrix Multiplication (GEMM)\nperformance on modern GPUs, focusing on runtime, power consumption, and energy\nefficiency. Our study employs two approaches: a custom-implemented tiled matrix\nmultiplication kernel for fundamental analysis, and NVIDIA's CUTLASS library\nfor comprehensive performance data collection across advanced configurations.\nUsing the NVIDIA RTX 4070 as our experimental platform, we developed a Random\nForest-based prediction model with multi-output regression capability. Through\nanalysis of both naive tiled matrix multiplication with varying tile sizes (1\nto 32) and 16,128 CUTLASS GEMM operations across diverse configurations, we\nidentified critical performance patterns related to matrix dimensions, thread\nblock configurations, and memory access patterns. Our framework achieved\nexceptional accuracy with an R^2 score of 0.98 for runtime prediction (mean\nerror 15.57%) and 0.78 for power prediction (median error 5.42%). The system\nsuccessfully predicts performance across matrix sizes, demonstrating robust\nscaling behavior. Our results show that optimal tile size selection can improve\nperformance by up to 3.2x while reducing power consumption by 22% compared to\nbaseline configurations. Analysis of shared memory utilization and SM occupancy\nreveals that tile sizes of 16x16 achieve the best balance between parallelism\nand resource usage. The implementation of our framework, including prediction\nmodels and analysis tools, is available as an open-source project at GPPerf\n[https://github.com/pavlyhalim/GPPerf].",
      "tldr_zh": "本研究提出了一种基于机器学习的分析框架，用于预测 NVIDIA Ada Lovelace GPU 上 GEMM（General Matrix Multiplication）的运行时间、功率消耗和能量效率。该框架结合自定义 tiled matrix multiplication kernel 和 CUTLASS 库，在 NVIDIA RTX 4070 平台上使用 Random Forest 多输出回归模型进行分析，实现了运行时间预测的 R^2 得分 0.98（平均误差 15.57%）和功率预测的 R^2 得分 0.78（中位数误差 5.42%）。实验结果显示，优化 tile size 可将性能提升高达 3.2 倍，同时降低功率消耗 22%，并通过分析共享内存利用和 SM occupancy 揭示了关键性能模式。该框架的实现已开源在 GPPerf 项目中，提供了一个鲁棒的性能预测工具。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.PF",
        "68W10, 65F30",
        "I.2.6; G.1.3; G.4"
      ],
      "primary_category": "cs.DC",
      "comment": "9 pages, 9 figures, 6 tables, IEEE conference paper format",
      "pdf_url": "http://arxiv.org/pdf/2411.16954v1",
      "published_date": "2024-11-25 21:47:23 UTC",
      "updated_date": "2024-11-25 21:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:04:10.023222"
    },
    {
      "arxiv_id": "2412.00064v2",
      "title": "DiffGuard: Text-Based Safety Checker for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Massine El Khader",
        "Elias Al Bouzidi",
        "Abdellah Oumida",
        "Mohammed Sbaihi",
        "Eliott Binard",
        "Jean-Philippe Poli",
        "Wassila Ouerdane",
        "Boussad Addad",
        "Katarzyna Kapusta"
      ],
      "abstract": "Recent advances in Diffusion Models have enabled the generation of images\nfrom text, with powerful closed-source models like DALL-E and Midjourney\nleading the way. However, open-source alternatives, such as StabilityAI's\nStable Diffusion, offer comparable capabilities. These open-source models,\nhosted on Hugging Face, come equipped with ethical filter protections designed\nto prevent the generation of explicit images. This paper reveals first their\nlimitations and then presents a novel text-based safety filter that outperforms\nexisting solutions. Our research is driven by the critical need to address the\nmisuse of AI-generated content, especially in the context of information\nwarfare. DiffGuard enhances filtering efficacy, achieving a performance that\nsurpasses the best existing filters by over 14%.",
      "tldr_zh": "该研究揭示了开源扩散模型（Diffusion Models），如 Stable Diffusion，在生成文本驱动图像时存在的安全过滤器局限性，这些模型虽有道德保护机制，但易被滥用于信息战等场景。论文提出 DiffGuard，一种基于文本的创新安全检查器，通过增强过滤机制来防止生成显式内容。实验结果显示，DiffGuard 比现有最佳过滤器性能提升超过 14%，为AI 生成内容的道德管控提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00064v2",
      "published_date": "2024-11-25 21:47:02 UTC",
      "updated_date": "2025-02-19 15:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:04:20.513983"
    },
    {
      "arxiv_id": "2411.16936v1",
      "title": "Harnessing LLMs for Educational Content-Driven Italian Crossword Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kamyar Zeinalipour",
        "Achille Fusco",
        "Asya Zanollo",
        "Marco Maggini",
        "Marco Gori"
      ],
      "abstract": "In this work, we unveil a novel tool for generating Italian crossword puzzles\nfrom text, utilizing advanced language models such as GPT-4o,\nMistral-7B-Instruct-v0.3, and Llama3-8b-Instruct. Crafted specifically for\neducational applications, this cutting-edge generator makes use of the\ncomprehensive Italian-Clue-Instruct dataset, which comprises over 30,000\nentries including diverse text, solutions, and types of clues. This carefully\nassembled dataset is designed to facilitate the creation of contextually\nrelevant clues in various styles associated with specific texts and keywords.\nThe study delves into four distinctive styles of crossword clues: those without\nformat constraints, those formed as definite determiner phrases, copular\nsentences, and bare noun phrases. Each style introduces unique linguistic\nstructures to diversify clue presentation. Given the lack of sophisticated\neducational tools tailored to the Italian language, this project seeks to\nenhance learning experiences and cognitive development through an engaging,\ninteractive platform. By meshing state-of-the-art AI with contemporary\neducational strategies, our tool can dynamically generate crossword puzzles\nfrom Italian educational materials, thereby providing an enjoyable and\ninteractive learning environment. This technological advancement not only\nredefines educational paradigms but also sets a new benchmark for interactive\nand cognitive language learning solutions.",
      "tldr_zh": "本研究利用大型语言模型（LLMs）如 GPT-4o、Mistral-7B-Instruct-v0.3 和 Llama3-8b-Instruct，开发了一种从文本生成意大利语填字游戏的工具，针对教育内容应用。工具依赖于 Italian-Clue-Instruct 数据集，该数据集包含超过 30,000 条目，包括多样文本、解决方案和四种线索风格（如无格式约束的、定语短语、系动句及裸名词短语），以创建上下文相关的教育线索。实验结果显示，该工具能动态从意大利教育材料生成互动填字游戏，提升学习体验和认知发展，并为语言教育设定新基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted for presentation at CLiC.it 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.16936v1",
      "published_date": "2024-11-25 21:13:25 UTC",
      "updated_date": "2024-11-25 21:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:04:33.892722"
    },
    {
      "arxiv_id": "2412.07787v1",
      "title": "Anomaly Detection in California Electricity Price Forecasting: Enhancing Accuracy and Reliability Using Principal Component Analysis",
      "title_zh": "加利福尼亚电力价格预测中的异常检测：使用主成分分析增强准确性和可靠性",
      "authors": [
        "Joseph Nyangon",
        "Ruth Akintunde"
      ],
      "abstract": "Accurate and reliable electricity price forecasting has significant practical\nimplications for grid management, renewable energy integration, power system\nplanning, and price volatility management. This study focuses on enhancing\nelectricity price forecasting in California's grid, addressing challenges from\ncomplex generation data and heteroskedasticity. Utilizing principal component\nanalysis (PCA), we analyze CAISO's hourly electricity prices and demand from\n2016-2021 to improve day-ahead forecasting accuracy. Initially, we apply\ntraditional outlier analysis with the interquartile range method, followed by\nrobust PCA (RPCA) for more effective outlier elimination. This approach\nimproves data symmetry and reduces skewness. We then construct multiple linear\nregression models using both raw and PCA-transformed features. The model with\ntransformed features, refined through traditional and SAS Sparse Matrix outlier\nremoval methods, shows superior forecasting performance. The SAS Sparse Matrix\nmethod, in particular, significantly enhances model accuracy. Our findings\ndemonstrate that PCA-based methods are key in advancing electricity price\nforecasting, supporting renewable integration and grid management in day-ahead\nmarkets.\n  Keywords: Electricity price forecasting, principal component analysis (PCA),\npower system planning, heteroskedasticity, renewable energy integration.",
      "tldr_zh": "本研究针对加州电网的电力价格预测问题，采用主成分分析 (PCA) 来处理复杂的发电数据和异方差性 (heteroskedasticity)，通过分析 CAISO 2016-2021 小时价格和需求数据，提高预测准确性。研究首先使用四分位距方法进行传统异常值分析，随后应用鲁棒 PCA (RPCA) 消除异常值，以改善数据对称性和减少偏斜，然后构建多元线性回归模型，并通过传统方法和 SAS Sparse Matrix 异常值移除优化模型。结果显示，使用 PCA 转换后特征的模型显著提升预测性能，尤其是 SAS Sparse Matrix 方法进一步提高了准确性。这些发现证明 PCA 基于方法有助于支持可再生能源整合 (renewable energy integration) 和电网管理 (power system planning)。",
      "categories": [
        "econ.EM",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "econ.EM",
      "comment": "5 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.07787v1",
      "published_date": "2024-11-25 20:55:25 UTC",
      "updated_date": "2024-11-25 20:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:04:45.709804"
    },
    {
      "arxiv_id": "2411.16927v1",
      "title": "ASSERTIFY: Utilizing Large Language Models to Generate Assertions for Production Code",
      "title_zh": "ASSERTIFY：利用大型语言模型生成生产代码的断言",
      "authors": [
        "Mohammad Jalili Torkamani",
        "Abhinav Sharma",
        "Nikita Mehrotra",
        "Rahul Purandare"
      ],
      "abstract": "Production assertions are statements embedded in the code to help developers\nvalidate their assumptions about the code. They assist developers in debugging,\nprovide valuable documentation, and enhance code comprehension. Current\nresearch in this area primarily focuses on assertion generation for unit tests\nusing techniques, such as static analysis and deep learning. While these\ntechniques have shown promise, they fall short when it comes to generating\nproduction assertions, which serve a different purpose.\n  This preprint addresses the gap by introducing Assertify, an automated\nend-to-end tool that leverages Large Language Models (LLMs) and prompt\nengineering with few-shot learning to generate production assertions. By\ncreating context-rich prompts, the tool emulates the approach developers take\nwhen creating production assertions for their code. To evaluate our approach,\nwe compiled a dataset of 2,810 methods by scraping 22 mature Java repositories\nfrom GitHub. Our experiments demonstrate the effectiveness of few-shot learning\nby producing assertions with an average ROUGE-L score of 0.526, indicating\nreasonably high structural similarity with the assertions written by\ndevelopers. This research demonstrates the potential of LLMs in automating the\ngeneration of production assertions that resemble the original assertions.",
      "tldr_zh": "本文研究了利用大型语言模型（LLMs）生成生产代码断言的问题，引入了Assertify工具，以填补现有技术在单元测试断言生成方面的局限。Assertify通过提示工程（prompt engineering）和少样本学习（few-shot learning）创建上下文丰富的提示，模拟开发者编写生产断言的过程。实验基于从GitHub收集的2810个Java方法数据集，结果显示生成的断言平均ROUGE-L分数达0.526，与开发者断言具有较高的结构相似性，证明了LLMs在自动化生产断言生成方面的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.5; D.2.7; K.6.3"
      ],
      "primary_category": "cs.SE",
      "comment": "20 pages, 10 figures, 10 listings, 2 tables, preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.16927v1",
      "published_date": "2024-11-25 20:52:28 UTC",
      "updated_date": "2024-11-25 20:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:06:57.022228"
    },
    {
      "arxiv_id": "2411.16917v2",
      "title": "Are Transformers Truly Foundational for Robotics?",
      "title_zh": "Transformers 真正是机器人学的基础吗？",
      "authors": [
        "James A. R. Marshall",
        "Andrew B. Barron"
      ],
      "abstract": "Generative Pre-Trained Transformers (GPTs) are hyped to revolutionize\nrobotics. Here we question their utility. GPTs for autonomous robotics demand\nenormous and costly compute, excessive training times and (often) offboard\nwireless control. We contrast GPT state of the art with how tiny insect brains\nhave achieved robust autonomy with none of these constraints. We highlight\nlessons that can be learned from biology to enhance the utility of GPTs in\nrobotics.",
      "tldr_zh": "这篇论文质疑 Generative Pre-Trained Transformers (GPTs) 是否真正成为机器人领域的基础，指出 GPTs 需要巨量计算资源、漫长训练时间和经常的离线无线控制，这大大限制了其在自主机器人中的实用性。作者将 GPTs 与昆虫大脑的鲁棒自治能力进行对比，后者无需这些约束便实现了高效适应。论文强调从生物学中汲取教训，以提升 GPTs 在机器人应用中的效用和效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16917v2",
      "published_date": "2024-11-25 20:35:01 UTC",
      "updated_date": "2025-02-27 10:46:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:07:07.275864"
    },
    {
      "arxiv_id": "2411.16905v1",
      "title": "Boundless Socratic Learning with Language Games",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Schaul"
      ],
      "abstract": "An agent trained within a closed system can master any desired capability, as\nlong as the following three conditions hold: (a) it receives sufficiently\ninformative and aligned feedback, (b) its coverage of experience/data is broad\nenough, and (c) it has sufficient capacity and resource. In this position\npaper, we justify these conditions, and consider what limitations arise from\n(a) and (b) in closed systems, when assuming that (c) is not a bottleneck.\nConsidering the special case of agents with matching input and output spaces\n(namely, language), we argue that such pure recursive self-improvement, dubbed\n\"Socratic learning\", can boost performance vastly beyond what is present in its\ninitial data or knowledge, and is only limited by time, as well as gradual\nmisalignment concerns. Furthermore, we propose a constructive framework to\nimplement it, based on the notion of language games.",
      "tldr_zh": "本论文讨论了在封闭系统中训练代理（agent）的条件，即获得足够的信息性和一致的反馈、广泛的数据覆盖，以及足够的容量和资源，并强调前两个条件在限制系统方面的作用。针对输入输出空间匹配的语言模型，该论文提出苏格拉底式学习(Socratic learning)，一种纯递归自我改进方法，能够大幅超越初始数据性能，但受时间和渐进失调(gradual misalignment)的影响。作者基于语言游戏(language games)的概念，提供了一个建设性框架，以实现这种无边界学习。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16905v1",
      "published_date": "2024-11-25 20:16:16 UTC",
      "updated_date": "2024-11-25 20:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:07:20.288807"
    },
    {
      "arxiv_id": "2411.16896v2",
      "title": "Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with Differential Transformer Based Deep Learning Model Incorporating Pixelwise Instrument Response Function",
      "title_zh": "翻译失败",
      "authors": [
        "Ismail Erbas",
        "Vikas Pandey",
        "Navid Ibtehaj Nizam",
        "Nanxue Yuan",
        "Amit Verma",
        "Margarida Barosso",
        "Xavier Intes"
      ],
      "abstract": "Fluorescence Lifetime Imaging (FLI) is a critical molecular imaging modality\nthat provides unique information about the tissue microenvironment, which is\ninvaluable for biomedical applications. FLI operates by acquiring and analyzing\nphoton time-of-arrival histograms to extract quantitative parameters associated\nwith temporal fluorescence decay. These histograms are influenced by the\nintrinsic properties of the fluorophore, instrument parameters, time-of-flight\ndistributions associated with pixel-wise variations in the topographic and\noptical characteristics of the sample. Recent advancements in Deep Learning\n(DL) have enabled improved fluorescence lifetime parameter estimation. However,\nexisting models are primarily designed for planar surface samples, limiting\ntheir applicability in translational scenarios involving complex surface\nprofiles, such as \\textit{in-vivo} whole-animal or imaged guided surgical\napplications. To address this limitation, we present MFliNet (Macroscopic FLI\nNetwork), a novel DL architecture that integrates the Instrument Response\nFunction (IRF) as an additional input alongside experimental photon\ntime-of-arrival histograms. Leveraging the capabilities of a Differential\nTransformer encoder-decoder architecture, MFliNet effectively focuses on\ncritical input features, such as variations in photon time-of-arrival\ndistributions. We evaluate MFliNet using rigorously designed tissue-mimicking\nphantoms and preclinical in-vivo cancer xenograft models. Our results\ndemonstrate the model's robustness and suitability for complex macroscopic FLI\napplications, offering new opportunities for advanced biomedical imaging in\ndiverse and challenging settings.",
      "tldr_zh": "本研究针对荧光寿命成像 (FLI) 在复杂表面轮廓场景中的参数估计挑战，提出了一种新型深度学习 (DL) 模型 MFliNet，以提升估计准确性。MFliNet 将仪器响应函数 (IRF) 作为额外输入，与实验光子到达时间直方图结合，利用 Differential Transformer 的编码器-解码器架构，重点关注光子时间分布的像素级变化，从而更好地处理活体动物或手术应用的非平面样本。实验通过组织模拟 phantom 和活体癌症异种移植模型验证，证明了 MFliNet 的鲁棒性，为复杂宏观 FLI 应用提供新的高级生物医学成像机会。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG",
        "physics.optics"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.16896v2",
      "published_date": "2024-11-25 20:03:41 UTC",
      "updated_date": "2024-12-04 19:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:07:32.611988"
    },
    {
      "arxiv_id": "2412.07786v1",
      "title": "Towards Agentic Schema Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Agapi Rissaki",
        "Ilias Fountalis",
        "Nikolaos Vasiloglou",
        "Wolfgang Gatterbauer"
      ],
      "abstract": "Large enterprise databases can be complex and messy, obscuring the data\nsemantics needed for analytical tasks. We propose a semantic layer in-between\nthe database and the user as a set of small and easy-to-interpret database\nviews, effectively acting as a refined version of the schema. To discover these\nviews, we introduce a multi-agent Large Language Model (LLM) simulation where\nLLM agents collaborate to iteratively define and refine views with minimal\ninput. Our approach paves the way for LLM-powered exploration of unwieldy\ndatabases.",
      "tldr_zh": "大型企业数据库通常复杂且混乱，导致数据语义难以获取，从而影响分析任务。本文提出一种语义层，作为数据库和用户之间的桥梁，由一组小型、易解释的数据库视图组成，以精炼原始模式。为实现这一目标，我们引入多智能体 Large Language Model (LLM) 模拟，让代理协作以最小输入迭代定义和精炼这些视图，从而为 LLM 驱动的复杂数据库探索铺平道路。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "To appear at the Table Representation Learning Workshop, NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.07786v1",
      "published_date": "2024-11-25 19:57:16 UTC",
      "updated_date": "2024-11-25 19:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:07:45.325050"
    },
    {
      "arxiv_id": "2411.16872v2",
      "title": "Enabling Adoption of Regenerative Agriculture through Soil Carbon Copilots",
      "title_zh": "翻译失败",
      "authors": [
        "Margaret Capetz",
        "Swati Sharma",
        "Rafael Padilha",
        "Peder Olsen",
        "Jessica Wolk",
        "Emre Kiciman",
        "Ranveer Chandra"
      ],
      "abstract": "Mitigating climate change requires transforming agriculture to minimize\nenviron mental impact and build climate resilience. Regenerative agricultural\npractices enhance soil organic carbon (SOC) levels, thus improving soil health\nand sequestering carbon. A challenge to increasing regenerative agriculture\npractices is cheaply measuring SOC over time and understanding how SOC is\naffected by regenerative agricultural practices and other environmental factors\nand farm management practices. To address this challenge, we introduce an\nAI-driven Soil Organic Carbon Copilot that automates the ingestion of complex\nmulti-resolution, multi-modal data to provide large-scale insights into soil\nhealth and regenerative practices. Our data includes extreme weather event data\n(e.g., drought and wildfire incidents), farm management data (e.g., cropland\ninformation and tillage predictions), and SOC predictions. We find that\nintegrating public data and specialized models enables large-scale, localized\nanalysis for sustainable agriculture. In comparisons of agricultural practices\nacross California counties, we find evidence that diverse agricultural activity\nmay mitigate the negative effects of tillage; and that while extreme weather\nconditions heavily affect SOC, composting may mitigate SOC loss. Finally,\nimplementing role-specific personas empowers agronomists, farm consultants,\npolicymakers, and other stakeholders to implement evidence-based strategies\nthat promote sustainable agriculture and build climate resilience.",
      "tldr_zh": "这篇论文提出了一种 AI 驱动的 Soil Organic Carbon Copilot，以推动再生农业的采用，通过自动化处理多分辨率、多模态数据（如极端天气事件数据、农场管理数据和 SOC 预测）来提供大规模、局部化的土壤健康洞见。研究发现，多样化农业活动可能缓解耕作的负面影响，而堆肥能有效减轻极端天气对 SOC 的损失。相比传统方法，该系统整合公共数据和专业模型，支持证据-based 策略，帮助农学家、农场顾问和政策制定者构建气候恢复力和可持续农业。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16872v2",
      "published_date": "2024-11-25 19:11:41 UTC",
      "updated_date": "2024-11-27 06:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:07:57.028620"
    },
    {
      "arxiv_id": "2411.16863v2",
      "title": "Augmenting Multimodal LLMs with Self-Reflective Tokens for Knowledge-based Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Cocchi",
        "Nicholas Moratelli",
        "Marcella Cornia",
        "Lorenzo Baraldi",
        "Rita Cucchiara"
      ],
      "abstract": "Multimodal LLMs (MLLMs) are the natural extension of large language models to\nhandle multimodal inputs, combining text and image data. They have recently\ngarnered attention due to their capability to address complex tasks involving\nboth modalities. However, their effectiveness is limited to the knowledge\nacquired during training, which restricts their practical utility. In this\nwork, we introduce a novel method to enhance the adaptability of MLLMs by\nintegrating external knowledge sources. Our proposed model, Reflective LLaVA\n(ReflectiVA), utilizes reflective tokens to dynamically determine the need for\nexternal knowledge and predict the relevance of information retrieved from an\nexternal database. Tokens are trained following a two-stage two-model training\nrecipe. This ultimately enables the MLLM to manage external knowledge while\npreserving fluency and performance on tasks where external knowledge is not\nneeded. Through our experiments, we demonstrate the efficacy of ReflectiVA for\nknowledge-based visual question answering, highlighting its superior\nperformance compared to existing methods. Source code and trained models are\npublicly available at https://aimagelab.github.io/ReflectiVA.",
      "tldr_zh": "本文提出了一种增强 Multimodal LLMs 的新方法，通过引入 self-reflective tokens 来整合外部知识源，针对知识-based Visual Question Answering 任务。模型 Reflective LLaVA 利用这些 tokens 动态评估外部知识的需求，并预测检索信息的相关性，采用两阶段两模型训练策略，以保持模型在非知识依赖任务中的流畅性和性能。实验结果表明，ReflectiVA 在相关任务上表现出色，优于现有方法，并公开了源代码和训练模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.16863v2",
      "published_date": "2024-11-25 19:01:03 UTC",
      "updated_date": "2025-04-02 06:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:08:08.160737"
    },
    {
      "arxiv_id": "2411.17470v2",
      "title": "Towards Precise Scaling Laws for Video Diffusion Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanyang Yin",
        "Yaqi Zhao",
        "Mingwu Zheng",
        "Ke Lin",
        "Jiarong Ou",
        "Rui Chen",
        "Victor Shea-Jay Huang",
        "Jiahao Wang",
        "Xin Tao",
        "Pengfei Wan",
        "Di Zhang",
        "Baoqun Yin",
        "Wentao Zhang",
        "Kun Gai"
      ],
      "abstract": "Achieving optimal performance of video diffusion transformers within given\ndata and compute budget is crucial due to their high training costs. This\nnecessitates precisely determining the optimal model size and training\nhyperparameters before large-scale training. While scaling laws are employed in\nlanguage models to predict performance, their existence and accurate derivation\nin visual generation models remain underexplored. In this paper, we\nsystematically analyze scaling laws for video diffusion transformers and\nconfirm their presence. Moreover, we discover that, unlike language models,\nvideo diffusion models are more sensitive to learning rate and batch size, two\nhyperparameters often not precisely modeled. To address this, we propose a new\nscaling law that predicts optimal hyperparameters for any model size and\ncompute budget. Under these optimal settings, we achieve comparable performance\nand reduce inference costs by 40.1% compared to conventional scaling methods,\nwithin a compute budget of 1e10 TFlops. Furthermore, we establish a more\ngeneralized and precise relationship among validation loss, any model size, and\ncompute budget. This enables performance prediction for non-optimal model\nsizes, which may also be appealed under practical inference cost constraints,\nachieving a better trade-off.",
      "tldr_zh": "本文探讨了视频扩散变压器（video diffusion transformers）的缩放定律（scaling laws），旨在在给定数据和计算预算下精确确定最佳模型大小和训练超参数，以优化高成本训练过程。作者通过系统分析发现，这些模型对学习率和批量大小更为敏感，并提出一个新缩放定律，用于预测任何模型大小和计算预算下的最佳超参数。实验结果显示，在1e10 TFlops预算下，该方法实现了与传统方法相当的性能，但推理成本降低了40.1%，并提供了更泛化的性能预测关系，以实现更好的模型大小与推理成本权衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17470v2",
      "published_date": "2024-11-25 18:59:04 UTC",
      "updated_date": "2024-12-31 16:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:08:20.806817"
    },
    {
      "arxiv_id": "2411.16832v2",
      "title": "Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Hanhui Wang",
        "Yihua Zhang",
        "Ruizheng Bai",
        "Yue Zhao",
        "Sijia Liu",
        "Zhengzhong Tu"
      ],
      "abstract": "Recent advancements in diffusion models have made generative image editing\nmore accessible, enabling creative edits but raising ethical concerns,\nparticularly regarding malicious edits to human portraits that threaten privacy\nand identity security. Existing protection methods primarily rely on\nadversarial perturbations to nullify edits but often fail against diverse\nediting requests. We propose FaceLock, a novel approach to portrait protection\nthat optimizes adversarial perturbations to destroy or significantly alter\nbiometric information, rendering edited outputs biometrically unrecognizable.\nFaceLock integrates facial recognition and visual perception into perturbation\noptimization to provide robust protection against various editing attempts. We\nalso highlight flaws in commonly used evaluation metrics and reveal how they\ncan be manipulated, emphasizing the need for reliable assessments of\nprotection. Experiments show FaceLock outperforms baselines in defending\nagainst malicious edits and is robust against purification techniques. Ablation\nstudies confirm its stability and broad applicability across diffusion-based\nediting algorithms. Our work advances biometric defense and sets the foundation\nfor privacy-preserving practices in image editing. The code is available at:\nhttps://github.com/taco-group/FaceLock.",
      "tldr_zh": "本文研究了diffusion models在图像编辑中的进展所带来的恶意编辑人像问题，该问题威胁到隐私和身份安全。作者提出FaceLock，一种创新方法，通过优化adversarial perturbations来破坏或显著改变人脸的生物特征信息，使编辑后的输出在facial recognition上无法识别，并整合visual perception以增强对各种编辑尝试的鲁棒性。实验结果显示，FaceLock在防御恶意编辑方面优于基线模型，且对purification techniques具有抵抗力；同时，ablation studies证实了其稳定性和在扩散模型编辑算法中的广泛适用性。该工作为biometric defense领域提供了新基础，促进图像编辑中的隐私保护实践。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "GitHub: https://github.com/taco-group/FaceLock",
      "pdf_url": "http://arxiv.org/pdf/2411.16832v2",
      "published_date": "2024-11-25 18:59:03 UTC",
      "updated_date": "2025-03-15 00:11:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:08:33.285549"
    },
    {
      "arxiv_id": "2411.16667v2",
      "title": "OPMOS: Ordered Parallel Algorithm for Multi-Objective Shortest-Paths",
      "title_zh": "OPMOS：用于多目标最短路径的有序并行算法",
      "authors": [
        "Leo Gold",
        "Adam Bienkowski",
        "David Sidoti",
        "Krishna Pattipati",
        "Omer Khan"
      ],
      "abstract": "The Multi-Objective Shortest-Path (MOS) problem finds a set of Pareto-optimal\nsolutions from a start node to a destination node in a multi-attribute graph.\nThe literature explores multi-objective A*-style algorithmic approaches to\nsolving the NP-hard MOS problem. These approaches use consistent heuristics to\ncompute an exact set of solutions for the goal node. A generalized MOS\nalgorithm maintains a \"frontier\" of partial paths at each node and performs\nordered processing to ensure that Pareto-optimal paths are generated to reach\nthe goal node. The algorithm becomes computationally intractable at a higher\nnumber of objectives due to a rapid increase in the search space for\nnon-dominated paths and the significant increase in Pareto-optimal solutions.\nWhile prior works have focused on algorithmic methods to reduce the complexity,\nwe tackle this challenge by exploiting parallelism to accelerate the MOS\nproblem. The key insight is that MOS algorithms rely on the ordered execution\nof partial paths to maintain high work efficiency. The proposed parallel\nalgorithm (OPMOS) unlocks ordered parallelism and efficiently exploits the\nconcurrent execution of multiple paths in MOS. Experimental evaluation using\nthe NVIDIA GH200 Superchip's 72-core Arm-based CPU shows the performance\nscaling potential of OPMOS on work efficiency and parallelism using a\nreal-world application to ship routing.",
      "tldr_zh": "这篇论文针对 Multi-Objective Shortest-Path (MOS) 问题提出了一种有序并行算法 OPMOS，用于在多属性图中寻找从起始节点到目标节点的 Pareto-optimal 解决方案。MOS 问题因搜索空间和非主导路径的快速增长而计算复杂，传统算法难以处理多目标场景；OPMOS 通过利用有序并行性，允许多个部分路径的并发执行，同时保持工作效率。实验在 NVIDIA GH200 Superchip 的 72 核 Arm-based CPU 上评估，展示了 OPMOS 在船舶路由等真实应用中显著提升性能，并行性扩展潜力突出。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR",
        "cs.DS",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.16667v2",
      "published_date": "2024-11-25 18:53:49 UTC",
      "updated_date": "2025-04-15 01:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:08:44.080732"
    },
    {
      "arxiv_id": "2411.16666v2",
      "title": "CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaan Han",
        "Junxiao Chen",
        "Yanzhe Fu"
      ],
      "abstract": "We introduce CatNet, an algorithm that effectively controls False Discovery\nRate (FDR) and selects significant features in LSTM with the Gaussian Mirror\n(GM) method. To evaluate the feature importance of LSTM in time series, we\nintroduce a vector of the derivative of the SHapley Additive exPlanations\n(SHAP) to measure feature importance. We also propose a new kernel-based\ndependence measure to avoid multicollinearity in the GM algorithm, to make a\nrobust feature selection with controlled FDR. We use simulated data to evaluate\nCatNet's performance in both linear models and LSTM models with different link\nfunctions. The algorithm effectively controls the FDR while maintaining a high\nstatistical power in all cases. We also evaluate the algorithm's performance in\ndifferent low-dimensional and high-dimensional cases, demonstrating its\nrobustness in various input dimensions. To evaluate CatNet's performance in\nreal world applications, we construct a multi-factor investment portfolio to\nforecast the prices of S\\&P 500 index components. The results demonstrate that\nour model achieves superior predictive accuracy compared to traditional LSTM\nmodels without feature selection and FDR control. Additionally, CatNet\neffectively captures common market-driving features, which helps informed\ndecision-making in financial markets by enhancing the interpretability of\npredictions. Our study integrates of the Gaussian Mirror algorithm with LSTM\nmodels for the first time, and introduces SHAP values as a new feature\nimportance metric for FDR control methods, marking a significant advancement in\nfeature selection and error control for neural networks.",
      "tldr_zh": "该研究提出CatNet算法，用于在LSTM模型中有效控制False Discovery Rate (FDR)并选择显著特征。CatNet结合Gaussian Mirror (GM)方法和SHAP (SHapley Additive exPlanations)导数向量来衡量时间序列中的特征重要性，并引入一个新的核基于依赖度量以避免多重共线性，确保稳健的特征选择。实验结果显示，CatNet在模拟数据和真实金融应用（如预测S&P 500指数成分股价格）中均能有效控制FDR、维持高统计功效，并比传统LSTM模型提升预测准确性，同时增强预测的可解释性。该方法首次将Gaussian Mirror算法与LSTM整合，并将SHAP值应用于FDR控制，标志着神经网络特征选择领域的重大进展。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "q-fin.ST"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16666v2",
      "published_date": "2024-11-25 18:53:37 UTC",
      "updated_date": "2024-11-26 16:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:08:57.105778"
    },
    {
      "arxiv_id": "2411.16657v3",
      "title": "DreamRunner: Fine-Grained Compositional Story-to-Video Generation with Retrieval-Augmented Motion Adaptation",
      "title_zh": "DreamRunner：细粒度组合式故事到视频生成，基于检索增强运动适应",
      "authors": [
        "Zun Wang",
        "Jialu Li",
        "Han Lin",
        "Jaehong Yoon",
        "Mohit Bansal"
      ],
      "abstract": "Storytelling video generation (SVG) aims to produce coherent and visually\nrich multi-scene videos that follow a structured narrative. Existing methods\nprimarily employ LLM for high-level planning to decompose a story into\nscene-level descriptions, which are then independently generated and stitched\ntogether. However, these approaches struggle with generating high-quality\nvideos aligned with the complex single-scene description, as visualizing such\ncomplex description involves coherent composition of multiple characters and\nevents, complex motion synthesis and muti-character customization. To address\nthese challenges, we propose DreamRunner, a novel story-to-video generation\nmethod: First, we structure the input script using a large language model (LLM)\nto facilitate both coarse-grained scene planning as well as fine-grained\nobject-level layout and motion planning. Next, DreamRunner presents\nretrieval-augmented test-time adaptation to capture target motion priors for\nobjects in each scene, supporting diverse motion customization based on\nretrieved videos, thus facilitating the generation of new videos with complex,\nscripted motions. Lastly, we propose a novel spatial-temporal region-based 3D\nattention and prior injection module SR3AI for fine-grained object-motion\nbinding and frame-by-frame semantic control. We compare DreamRunner with\nvarious SVG baselines, demonstrating state-of-the-art performance in character\nconsistency, text alignment, and smooth transitions. Additionally, DreamRunner\nexhibits strong fine-grained condition-following ability in compositional\ntext-to-video generation, significantly outperforming baselines on\nT2V-ComBench. Finally, we validate DreamRunner's robust ability to generate\nmulti-object interactions with qualitative examples.",
      "tldr_zh": "该研究提出DreamRunner，一种细粒度的组合式故事到视频生成方法，旨在解决现有SVG（Storytelling Video Generation）方法在处理复杂场景时的问题，如多角色事件合成和动作定制。DreamRunner首先利用LLM对输入脚本进行粗细粒度规划，包括对象级布局和动作规划；其次，通过retrieval-augmented test-time adaptation从检索视频中捕获目标动作先验，实现多样动作定制；最后，引入SR3AI模块进行空间-时间区域3D注意力及先验注入，以实现细粒度对象-动作绑定和逐帧语义控制。实验结果表明，DreamRunner在角色一致性、文本对齐和平滑过渡方面优于基线模型，并在T2V-ComBench基准上表现出色，尤其在多对象交互生成上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website: https://zunwang1.github.io/DreamRunner",
      "pdf_url": "http://arxiv.org/pdf/2411.16657v3",
      "published_date": "2024-11-25 18:41:56 UTC",
      "updated_date": "2025-03-18 15:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:09:09.181767"
    },
    {
      "arxiv_id": "2411.16824v1",
      "title": "Beyond Sight: Towards Cognitive Alignment in LVLM via Enriched Visual Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Yaqi Zhao",
        "Yuanyang Yin",
        "Lin Li",
        "Mingan Lin",
        "Victor Shea-Jay Huang",
        "Siwei Chen",
        "Weipeng Chen",
        "Baoqun Yin",
        "Zenan Zhou",
        "Wentao Zhang"
      ],
      "abstract": "Does seeing always mean knowing? Large Vision-Language Models (LVLMs)\nintegrate separately pre-trained vision and language components, often using\nCLIP-ViT as vision backbone. However, these models frequently encounter a core\nissue of \"cognitive misalignment\" between the vision encoder (VE) and the large\nlanguage model (LLM). Specifically, the VE's representation of visual\ninformation may not fully align with LLM's cognitive framework, leading to a\nmismatch where visual features exceed the language model's interpretive range.\nTo address this, we investigate how variations in VE representations influence\nLVLM comprehension, especially when the LLM faces VE-Unknown data-images whose\nambiguous visual representations challenge the VE's interpretive precision.\nAccordingly, we construct a multi-granularity landmark dataset and\nsystematically examine the impact of VE-Known and VE-Unknown data on\ninterpretive abilities. Our results show that VE-Unknown data limits LVLM's\ncapacity for accurate understanding, while VE-Known data, rich in distinctive\nfeatures, helps reduce cognitive misalignment. Building on these insights, we\npropose Entity-Enhanced Cognitive Alignment (EECA), a method that employs\nmulti-granularity supervision to generate visually enriched, well-aligned\ntokens that not only integrate within the LLM's embedding space but also align\nwith the LLM's cognitive framework. This alignment markedly enhances LVLM\nperformance in landmark recognition. Our findings underscore the challenges\nposed by VE-Unknown data and highlight the essential role of cognitive\nalignment in advancing multimodal systems.",
      "tldr_zh": "本研究探讨了 Large Vision-Language Models (LVLMs) 中的核心问题，即视觉编码器 (VE) 与大型语言模型 (LLM) 之间的认知不对齐，导致 VE-Unknown 数据（如模糊视觉表示）影响模型的理解准确性。通过构建一个多粒度地标数据集，研究者分析了 VE-Known 和 VE-Unknown 数据对 LVLMs 解释能力的影响，发现前者能减少认知失配，而后者则限制了模型性能。针对此问题，他们提出 Entity-Enhanced Cognitive Alignment (EECA) 方法，利用多粒度监督生成丰富的视觉标记，使其与 LLM 的认知框架对齐，从而显著提升地标识别任务的性能。该工作强调了认知对齐在多模态系统中的关键作用，为改进 LVLMs 提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16824v1",
      "published_date": "2024-11-25 18:33:14 UTC",
      "updated_date": "2024-11-25 18:33:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:09:20.322343"
    },
    {
      "arxiv_id": "2411.16646v3",
      "title": "Self-Generated Critiques Boost Reward Modeling for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Yu",
        "Zhengxing Chen",
        "Aston Zhang",
        "Liang Tan",
        "Chenguang Zhu",
        "Richard Yuanzhe Pang",
        "Yundi Qian",
        "Xuewei Wang",
        "Suchin Gururangan",
        "Chao Zhang",
        "Melanie Kambadur",
        "Dhruv Mahajan",
        "Rui Hou"
      ],
      "abstract": "Reward modeling is crucial for aligning large language models (LLMs) with\nhuman preferences, especially in reinforcement learning from human feedback\n(RLHF). However, current reward models mainly produce scalar scores and\nstruggle to incorporate critiques in a natural language format. We hypothesize\nthat predicting both critiques and the scalar reward would improve reward\nmodeling ability. Motivated by this, we propose Critic-RM, a framework that\nimproves reward models using self-generated critiques without extra\nsupervision. Critic-RM employs a two-stage process: generating and filtering\nhigh-quality critiques, followed by joint fine-tuning on reward prediction and\ncritique generation. Experiments across benchmarks show that Critic-RM improves\nreward modeling accuracy by 3.7%-7.3% compared to standard reward models and\nLLM judges, demonstrating strong performance and data efficiency. Additional\nstudies further validate the effectiveness of generated critiques in rectifying\nflawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy.",
      "tldr_zh": "这篇论文探讨了如何通过自生成批评（Critiques）来提升语言模型的奖励建模（Reward Modeling），以更好地对齐大型语言模型（LLMs）与人类偏好，尤其在强化学习从人类反馈（RLHF）中。作者提出 Critic-RM 框架，该框架采用两阶段过程：首先生成并过滤高质量批评，然后进行奖励预测和批评生成的联合微调，而无需额外监督。实验结果显示，Critic-RM 在基准测试中比标准奖励模型和 LLM 判断提高了 3.7%-7.3% 的准确性，并通过生成的批评纠正了推理错误，提升了 2.5%-3.2% 的推理准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2411.16646v3",
      "published_date": "2024-11-25 18:28:26 UTC",
      "updated_date": "2025-02-09 07:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:09:32.728726"
    },
    {
      "arxiv_id": "2411.16645v1",
      "title": "Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters",
      "title_zh": "翻译失败",
      "authors": [
        "Dietmar Jannach",
        "Alan Said",
        "Marko Tkalčič",
        "Markus Zanker"
      ],
      "abstract": "In the area of recommender systems, the vast majority of research efforts is\nspent on developing increasingly sophisticated recommendation models, also\nusing increasingly more computational resources. Unfortunately, most of these\nresearch efforts target a very small set of application domains, mostly\ne-commerce and media recommendation. Furthermore, many of these models are\nnever evaluated with users, let alone put into practice. The scientific,\neconomic and societal value of much of these efforts by scholars therefore\nremains largely unclear. To achieve a stronger positive impact resulting from\nthese efforts, we posit that we as a research community should more often\naddress use cases where recommender systems contribute to societal good\n(RS4Good). In this opinion piece, we first discuss a number of examples where\nthe use of recommender systems for problems of societal concern has been\nsuccessfully explored in the literature. We then proceed by outlining a\nparadigmatic shift that is needed to conduct successful RS4Good research, where\nthe key ingredients are interdisciplinary collaborations and longitudinal\nevaluation approaches with humans in the loop.",
      "tldr_zh": "该论文（Recommender Systems for Good, RS4Good）调查了推荐系统在社会公益领域的应用案例，并呼吁研究社区转向更具实际影响力的方向。目前，大多数推荐系统研究集中在电商和媒体领域，过度依赖复杂模型和计算资源，却忽略了用户评估和实际部署，导致科学、经济和社会价值不明朗。论文列举了文献中成功探索社会问题（如健康、教育）的推荐系统例子，并强调通过跨学科合作和纵向人类参与评估，实现范式转变，以提升研究的社会贡献。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16645v1",
      "published_date": "2024-11-25 18:27:50 UTC",
      "updated_date": "2024-11-25 18:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:09:42.968919"
    },
    {
      "arxiv_id": "2411.16638v3",
      "title": "Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation",
      "title_zh": "自动事实性指标是否衡量事实性？一个批判性评估",
      "authors": [
        "Sanjana Ramprasad",
        "Byron C. Wallace"
      ],
      "abstract": "Modern LLMs can now produce highly readable abstractive summaries, to the\npoint where traditional automated metrics for evaluating summary quality, such\nas ROUGE, have become saturated. However, LLMs still sometimes introduce\nunwanted content into summaries, i.e., information inconsistent with or\nunsupported by their source. Measuring the occurrence of these often subtle\n``hallucinations'' automatically has proved to be challenging. This in turn has\nmotivated development of a variety of metrics intended to measure the factual\nconsistency of generated summaries against their source. But are these\napproaches measuring what they purport to do? In this work, we stress-test\nautomatic factuality metrics. Specifically, we investigate whether and to what\ndegree superficial attributes of summary texts suffice to predict\n``factuality'', finding that a (supervised) model using only such shallow\nfeatures is reasonably competitive with SOTA factuality scoring methods. We\nthen evaluate how factuality metrics respond to factual corrections in\ninconsistent summaries and find that only a few show meaningful improvements.\nIn contrast, some metrics are more sensitive to benign, non-factual edits.\nMotivated by these insights, we show that one can ``game'' (most) automatic\nfactuality metrics, i.e., reliably inflate ``factuality'' scores by appending\ninnocuous sentences to generated summaries. Taken together, our results raise\nquestions about the degree to which we should rely on existing automated\nfactuality metrics and what exactly we want ``factuality metrics'' to measure.",
      "tldr_zh": "这篇论文 critically evaluated 自动事实性指标是否真正衡量生成摘要的事实性。研究者通过压力测试发现，使用浅层特征的监督模型即可与最先进（SOTA）事实性评分方法竞争，且许多指标对摘要的事实更正反应不敏感，反而对无害的非事实编辑更敏感。作者进一步展示了如何通过在摘要中添加无害句子来“操纵”这些指标，从而提高分数，质疑现有自动事实性指标的可靠性和应衡量什么内容。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16638v3",
      "published_date": "2024-11-25 18:15:15 UTC",
      "updated_date": "2024-11-28 13:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:09:56.445700"
    },
    {
      "arxiv_id": "2411.16627v2",
      "title": "Inference-Time Policy Steering through Human Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Yanwei Wang",
        "Lirui Wang",
        "Yilun Du",
        "Balakumar Sundaralingam",
        "Xuning Yang",
        "Yu-Wei Chao",
        "Claudia Perez-D'Arpino",
        "Dieter Fox",
        "Julie Shah"
      ],
      "abstract": "Generative policies trained with human demonstrations can autonomously\naccomplish multimodal, long-horizon tasks. However, during inference, humans\nare often removed from the policy execution loop, limiting the ability to guide\na pre-trained policy towards a specific sub-goal or trajectory shape among\nmultiple predictions. Naive human intervention may inadvertently exacerbate\ndistribution shift, leading to constraint violations or execution failures. To\nbetter align policy output with human intent without inducing\nout-of-distribution errors, we propose an Inference-Time Policy Steering (ITPS)\nframework that leverages human interactions to bias the generative sampling\nprocess, rather than fine-tuning the policy on interaction data. We evaluate\nITPS across three simulated and real-world benchmarks, testing three forms of\nhuman interaction and associated alignment distance metrics. Among six sampling\nstrategies, our proposed stochastic sampling with diffusion policy achieves the\nbest trade-off between alignment and distribution shift. Videos are available\nat https://yanweiw.github.io/itps/.",
      "tldr_zh": "该研究探讨了如何通过人类交互引导预训练的生成策略（generative policies），以更好地对齐人类意图，同时避免分布偏移（distribution shift）导致的约束违反或执行失败。作者提出了 Inference-Time Policy Steering (ITPS) 框架，该框架利用人类交互偏置生成采样过程，而非对策略进行微调。实验在三个模拟和真实世界基准上评估了三种人类交互形式和相关对齐距离指标，结果显示，提出的随机采样与扩散策略（stochastic sampling with diffusion policy）在对齐性能和分布偏移权衡方面表现出最佳效果。总体而言，ITPS 为更可靠的人机协作任务执行提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.16627v2",
      "published_date": "2024-11-25 18:03:50 UTC",
      "updated_date": "2025-03-26 02:40:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:10:08.180931"
    },
    {
      "arxiv_id": "2411.16622v1",
      "title": "Imperceptible Adversarial Examples in the Physical World",
      "title_zh": "翻译失败",
      "authors": [
        "Weilin Xu",
        "Sebastian Szyller",
        "Cory Cornelius",
        "Luis Murillo Rojas",
        "Marius Arvinte",
        "Alvaro Velasquez",
        "Jason Martin",
        "Nageen Himayat"
      ],
      "abstract": "Adversarial examples in the digital domain against deep learning-based\ncomputer vision models allow for perturbations that are imperceptible to human\neyes. However, producing similar adversarial examples in the physical world has\nbeen difficult due to the non-differentiable image distortion functions in\nvisual sensing systems. The existing algorithms for generating physically\nrealizable adversarial examples often loosen their definition of adversarial\nexamples by allowing unbounded perturbations, resulting in obvious or even\nstrange visual patterns. In this work, we make adversarial examples\nimperceptible in the physical world using a straight-through estimator (STE,\na.k.a. BPDA). We employ STE to overcome the non-differentiability -- applying\nexact, non-differentiable distortions in the forward pass of the\nbackpropagation step, and using the identity function in the backward pass. Our\ndifferentiable rendering extension to STE also enables imperceptible\nadversarial patches in the physical world. Using printout photos, and\nexperiments in the CARLA simulator, we show that STE enables fast generation of\n$\\ell_\\infty$ bounded adversarial examples despite the non-differentiable\ndistortions. To the best of our knowledge, this is the first work demonstrating\nimperceptible adversarial examples bounded by small $\\ell_\\infty$ norms in the\nphysical world that force zero classification accuracy in the global\nperturbation threat model and cause near-zero ($4.22\\%$) AP50 in object\ndetection in the patch perturbation threat model. We urge the community to\nre-evaluate the threat of adversarial examples in the physical world.",
      "tldr_zh": "本文提出了一种使用 straight-through estimator (STE) 方法，在物理世界生成对人类眼睛不可见的对抗样本 (adversarial examples)，以应对图像扭曲函数非微分性的挑战。STE 通过在前向传播应用精确非微分扭曲、在后向传播使用恒等函数，实现 $\\ell_\\infty$ 范数受限的对抗样本，并扩展到可微渲染以处理物理对抗补丁。实验结果显示，在 CARLA 模拟器和打印照片测试中，该方法使分类准确率降至零，并在补丁扰动威胁模型下将对象检测的 AP50 降至 4.22%。这项工作强调了物理世界中对抗样本的潜在威胁，呼吁社区重新评估其风险。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16622v1",
      "published_date": "2024-11-25 18:02:23 UTC",
      "updated_date": "2024-11-25 18:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:10:21.787110"
    },
    {
      "arxiv_id": "2411.16609v1",
      "title": "F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite",
      "title_zh": "F — 基于",
      "authors": [
        "Ansgar Scherp",
        "Thomas Franz",
        "Carsten Saathoff",
        "Steffen Staab"
      ],
      "abstract": "The lack of a formal model of events hinders interoperability in distributed\nevent-based systems. In this paper, we present a formal model of events, called\nEvent-Model-F. The model is based on the foundational ontology DOLCE+DnS\nUltralite (DUL) and provides comprehensive support to represent time and space,\nobjects and persons, as well as mereological, causal, and correlative\nrelationships between events. In addition, the Event-Model-F provides a\nflexible means for event composition, modeling event causality and event\ncorrelation, and representing different interpretations of the same event. The\nEvent-Model-F is developed following the pattern-oriented approach of DUL, is\nmodularized in different ontologies, and can be easily extended by domain\nspecific ontologies.",
      "tldr_zh": "该论文提出 Event-Model-F，这是一个基于基础本体 DOLCE+DnS Ultralite (DUL) 的正式事件模型，旨在解决分布式事件系统中的互操作性问题。模型全面支持表示时间、空间、对象和人员，以及事件之间的 mereological（整体）、causal（因果）和 correlative（相关）关系。Event-Model-F 采用 DUL 的模式导向方法，通过模块化设计实现事件组合、因果建模和不同解释的灵活表示，并便于与领域特定本体扩展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Reprint of KCAP 2009 paper with republished ontologies",
      "pdf_url": "http://arxiv.org/pdf/2411.16609v1",
      "published_date": "2024-11-25 17:45:38 UTC",
      "updated_date": "2024-11-25 17:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:10:32.611194"
    },
    {
      "arxiv_id": "2411.16594v6",
      "title": "From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge",
      "title_zh": "从生成到判断：LLM-as-a-judge 的机遇和挑战",
      "authors": [
        "Dawei Li",
        "Bohan Jiang",
        "Liangjie Huang",
        "Alimohammad Beigi",
        "Chengshuai Zhao",
        "Zhen Tan",
        "Amrita Bhattacharjee",
        "Yuxuan Jiang",
        "Canyu Chen",
        "Tianhao Wu",
        "Kai Shu",
        "Lu Cheng",
        "Huan Liu"
      ],
      "abstract": "Assessment and evaluation have long been critical challenges in artificial\nintelligence (AI) and natural language processing (NLP). However, traditional\nmethods, whether matching-based or embedding-based, often fall short of judging\nsubtle attributes and delivering satisfactory results. Recent advancements in\nLarge Language Models (LLMs) inspire the \"LLM-as-a-judge\" paradigm, where LLMs\nare leveraged to perform scoring, ranking, or selection across various tasks\nand applications. This paper provides a comprehensive survey of LLM-based\njudgment and assessment, offering an in-depth overview to advance this emerging\nfield. We begin by giving detailed definitions from both input and output\nperspectives. Then we introduce a comprehensive taxonomy to explore\nLLM-as-a-judge from three dimensions: what to judge, how to judge and where to\njudge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and\nhighlight key challenges and promising directions, aiming to provide valuable\ninsights and inspire future research in this promising research area. Paper\nlist and more resources about LLM-as-a-judge can be found at\nhttps://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge and\nhttps://llm-as-a-judge.github.io.",
      "tldr_zh": "这篇论文探讨了在AI和NLP领域中，使用Large Language Models (LLMs)作为评估工具的“LLM-as-a-judge”范式，旨在解决传统匹配-based或embedding-based方法在判断微妙属性时的不足。该研究提供了从输入和输出角度的详细定义，并通过一个三维分类框架（what to judge、how to judge和where to judge）对LLM-as-a-judge进行全面分类和分析。同时，论文编译了评估基准，突出了关键挑战如准确性和偏见问题，并指出了未来研究方向，以推动这一新兴领域的发展。资源列表可通过指定链接获取。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "v6: add new citations; 36 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.16594v6",
      "published_date": "2024-11-25 17:28:44 UTC",
      "updated_date": "2025-02-06 00:18:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:10:43.427742"
    },
    {
      "arxiv_id": "2411.16579v1",
      "title": "Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision",
      "title_zh": "通过带有测试时和训练时监督的批评模型增强 LLM 推理",
      "authors": [
        "Zhiheng Xi",
        "Dingwen Yang",
        "Jixuan Huang",
        "Jiafu Tang",
        "Guanyu Li",
        "Yiwen Ding",
        "Wei He",
        "Boyang Hong",
        "Shihan Do",
        "Wenyu Zhan",
        "Xiao Wang",
        "Rui Zheng",
        "Tao Ji",
        "Xiaowei Shi",
        "Yitao Zhai",
        "Rongxiang Weng",
        "Jingang Wang",
        "Xunliang Cai",
        "Tao Gui",
        "Zuxuan Wu",
        "Qi Zhang",
        "Xipeng Qiu",
        "Xuanjing Huang",
        "Yu-Gang Jiang"
      ],
      "abstract": "Training large language models (LLMs) to spend more time thinking and\nreflection before responding is crucial for effectively solving complex\nreasoning tasks in fields such as science, coding, and mathematics. However,\nthe effectiveness of mechanisms like self-reflection and self-correction\ndepends on the model's capacity to accurately assess its own performance, which\ncan be limited by factors such as initial accuracy, question difficulty, and\nthe lack of external feedback. In this paper, we delve into a two-player\nparadigm that separates the roles of reasoning and critique models, where the\ncritique model provides step-level feedback to supervise the reasoning (actor)\nmodel during both test-time and train-time. We first propose AutoMathCritique,\nan automated and scalable framework for collecting critique data, resulting in\na dataset of $76,321$ responses paired with step-level feedback. Fine-tuning\nlanguage models with this dataset enables them to generate natural language\nfeedback for mathematical reasoning. We demonstrate that the critique models\nconsistently improve the actor's performance on difficult queries at test-time,\nespecially when scaling up inference-time computation. Motivated by these\nfindings, we introduce the critique-based supervision to the actor's\nself-training process, and propose a critique-in-the-loop self-improvement\nmethod. Experiments show that the method improves the actor's exploration\nefficiency and solution diversity, especially on challenging queries, leading\nto a stronger reasoning model. Lastly, we take the preliminary step to explore\ntraining self-talk reasoning models via critique supervision and showcase its\npotential. Our code and datasets are at\n\\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}.",
      "tldr_zh": "本研究探讨了通过引入批评模型（critique models）来提升大型语言模型（LLMs）在复杂推理任务中的性能，该模型在测试时和训练时为推理模型（actor model）提供步级反馈，以解决自省和自修正的局限性。作者提出AutoMathCritique框架，该框架自动收集76,321条响应配对的反馈数据集，用于微调模型生成数学推理的自然语言反馈。实验结果显示，这种方法显著提高了actor模型在困难查询上的准确性和探索效率，并通过批评监督的循环自改进机制增强了解决方案多样性，最终为训练更强的推理模型铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.16579v1",
      "published_date": "2024-11-25 17:11:54 UTC",
      "updated_date": "2024-11-25 17:11:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:10:56.664143"
    },
    {
      "arxiv_id": "2411.16574v1",
      "title": "Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?",
      "title_zh": "Naive 算法合谋：多臂老虎机学习者在何时合作以及何时竞争？",
      "authors": [
        "Connor Douglas",
        "Foster Provost",
        "Arun Sundararajan"
      ],
      "abstract": "Algorithmic agents are used in a variety of competitive decision settings,\nnotably in making pricing decisions in contexts that range from online retail\nto residential home rentals. Business managers, algorithm designers, legal\nscholars, and regulators alike are all starting to consider the ramifications\nof \"algorithmic collusion.\" We study the emergent behavior of multi-armed\nbandit machine learning algorithms used in situations where agents are\ncompeting, but they have no information about the strategic interaction they\nare engaged in. Using a general-form repeated Prisoner's Dilemma game, agents\nengage in online learning with no prior model of game structure and no\nknowledge of competitors' states or actions (e.g., no observation of competing\nprices). We show that these context-free bandits, with no knowledge of\nopponents' choices or outcomes, still will consistently learn collusive\nbehavior - what we call \"naive collusion.\" We primarily study this system\nthrough an analytical model and examine perturbations to the model through\nsimulations.\n  Our findings have several notable implications for regulators. First, calls\nto limit algorithms from conditioning on competitors' prices are insufficient\nto prevent algorithmic collusion. This is a direct result of collusion arising\neven in the naive setting. Second, symmetry in algorithms can increase\ncollusion potential. This highlights a new, simple mechanism for\n\"hub-and-spoke\" algorithmic collusion. A central distributor need not imbue its\nalgorithm with supra-competitive tendencies for apparent collusion to arise; it\ncan simply arise by using certain (common) machine learning algorithms.\nFinally, we highlight that collusive outcomes depend starkly on the specific\nalgorithm being used, and we highlight market and algorithmic conditions under\nwhich it will be unknown a priori whether collusion occurs.",
      "tldr_zh": "这篇论文探讨了多臂老虎机(multi-armed bandit)算法代理在竞争环境中（如定价决策）的行为，特别是在无对手信息的情况下是否会产生“naive collusion”（无知勾结）。研究通过一个通用形式的重复囚徒困境(Prisoner's Dilemma)游戏进行在线学习分析和模拟，证明这些算法即使不了解对手选择或结果，也会一致学习合作策略。论文的关键发现是，算法的对称性可能增加勾结风险，且不同算法的选择会显著影响结果，为监管者提供警示，例如限制算法依赖竞争对手价格不足以预防勾结。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.GT",
        "cs.MA",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "To be published in proceedings of International Conference on\n  Information Systems 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.16574v1",
      "published_date": "2024-11-25 16:58:07 UTC",
      "updated_date": "2024-11-25 16:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:11:08.255538"
    },
    {
      "arxiv_id": "2411.16819v4",
      "title": "Pathways on the Image Manifold: Image Editing via Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Noam Rotstein",
        "Gal Yona",
        "Daniel Silver",
        "Roy Velich",
        "David Bensaïd",
        "Ron Kimmel"
      ],
      "abstract": "Recent advances in image editing, driven by image diffusion models, have\nshown remarkable progress. However, significant challenges remain, as these\nmodels often struggle to follow complex edit instructions accurately and\nfrequently compromise fidelity by altering key elements of the original image.\nSimultaneously, video generation has made remarkable strides, with models that\neffectively function as consistent and continuous world simulators. In this\npaper, we propose merging these two fields by utilizing image-to-video models\nfor image editing. We reformulate image editing as a temporal process, using\npretrained video models to create smooth transitions from the original image to\nthe desired edit. This approach traverses the image manifold continuously,\nensuring consistent edits while preserving the original image's key aspects.\nOur approach achieves state-of-the-art results on text-based image editing,\ndemonstrating significant improvements in both edit accuracy and image\npreservation. Visit our project page at\nhttps://rotsteinnoam.github.io/Frame2Frame.",
      "tldr_zh": "该论文解决了图像扩散模型在编辑中的挑战，如难以准确执行复杂指令并保持原图 fidelity。作者提出一种新方法，将图像编辑重构为时间过程，利用图像到视频模型生成从原图到编辑的平滑过渡，从而在 image manifold 上连续遍历，确保编辑一致性和关键元素保留。该方法在文本-based 图像编辑任务上实现了 state-of-the-art 结果，显著提升了编辑准确性和图像保存效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16819v4",
      "published_date": "2024-11-25 16:41:45 UTC",
      "updated_date": "2025-03-20 07:02:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:11:19.928814"
    },
    {
      "arxiv_id": "2411.16818v1",
      "title": "Enhancing In-Hospital Mortality Prediction Using Multi-Representational Learning with LLM-Generated Expert Summaries",
      "title_zh": "翻译失败",
      "authors": [
        "Harshavardhan Battula",
        "Jiacheng Liu",
        "Jaideep Srivastava"
      ],
      "abstract": "In-hospital mortality (IHM) prediction for ICU patients is critical for\ntimely interventions and efficient resource allocation. While structured\nphysiological data provides quantitative insights, clinical notes offer\nunstructured, context-rich narratives. This study integrates these modalities\nwith Large Language Model (LLM)-generated expert summaries to improve IHM\nprediction accuracy. Using the MIMIC-III database, we analyzed time-series\nphysiological data and clinical notes from the first 48 hours of ICU admission.\nClinical notes were concatenated chronologically for each patient and\ntransformed into expert summaries using Med42-v2 70B. A multi-representational\nlearning framework was developed to integrate these data sources, leveraging\nLLMs to enhance textual data while mitigating direct reliance on LLM\npredictions, which can introduce challenges in uncertainty quantification and\ninterpretability. The proposed model achieved an AUPRC of 0.6156 (+36.41%) and\nan AUROC of 0.8955 (+7.64%) compared to a time-series-only baseline. Expert\nsummaries outperformed clinical notes or time-series data alone, demonstrating\nthe value of LLM-generated knowledge. Performance gains were consistent across\ndemographic groups, with notable improvements in underrepresented populations,\nunderscoring the framework's equitable application potential. By integrating\nLLM-generated summaries with structured and unstructured data, the framework\ncaptures complementary patient information, significantly improving predictive\nperformance. This approach showcases the potential of LLMs to augment critical\ncare prediction models, emphasizing the need for domain-specific validation and\nadvanced integration strategies for broader clinical adoption.",
      "tldr_zh": "本研究针对ICU患者住院死亡率(IHM)预测，提出了一种多表示学习框架，通过Large Language Model (LLM)生成的专家摘要整合结构化生理数据和非结构化临床笔记。利用MIMIC-III数据库分析前48小时的数据，并采用Med42-v2 70B生成专家摘要，以增强文本数据的同时避免直接依赖LLM预测。结果显示，该框架的AUPRC提高至0.6156（+36.41%），AUROC提高至0.8955（+7.64%），并在不同人群中表现出色，尤其改善了弱势群体的预测性能。该方法证明了LLM在提升临床预测准确性和公平性方面的潜力，但强调需要进一步的领域特定验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16818v1",
      "published_date": "2024-11-25 16:36:38 UTC",
      "updated_date": "2024-11-25 16:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:11:34.070992"
    },
    {
      "arxiv_id": "2411.16550v1",
      "title": "Representation Collapsing Problems in Vector Quantization",
      "title_zh": "向量量化中的表示崩溃问题",
      "authors": [
        "Wenhao Zhao",
        "Qiran Zou",
        "Rushi Shah",
        "Dianbo Liu"
      ],
      "abstract": "Vector quantization is a technique in machine learning that discretizes\ncontinuous representations into a set of discrete vectors. It is widely\nemployed in tokenizing data representations for large language models,\ndiffusion models, and other generative models. Despite its prevalence, the\ncharacteristics and behaviors of vector quantization in generative models\nremain largely underexplored. In this study, we investigate representation\ncollapse in vector quantization - a critical degradation where codebook tokens\nor latent embeddings lose their discriminative power by converging to a limited\nsubset of values. This collapse fundamentally compromises the model's ability\nto capture diverse data patterns. By leveraging both synthetic and real\ndatasets, we identify the severity of each type of collapses and triggering\nconditions. Our analysis reveals that restricted initialization and limited\nencoder capacity result in tokens collapse and embeddings collapse. Building on\nthese findings, we propose potential solutions aimed at mitigating each\ncollapse. To the best of our knowledge, this is the first comprehensive study\nexamining representation collapsing problems in vector quantization.",
      "tldr_zh": "这篇论文探讨了 Vector Quantization 在机器学习中的 Representation Collapsing Problems，即代码书标记或潜在嵌入因收敛到有限子集而失去区分能力的现象，这会削弱模型捕捉多样数据模式的能力。作者通过合成和真实数据集的分析，识别了不同类型崩溃的严重性及其触发条件，如受限初始化和有限编码器容量导致的 Tokens Collapse 和 Embeddings Collapse。基于这些发现，论文提出了潜在解决方案来缓解这些问题，并声称这是首个全面研究 Vector Quantization 中表示崩溃问题的研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2411.16550v1",
      "published_date": "2024-11-25 16:32:29 UTC",
      "updated_date": "2024-11-25 16:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:11:44.404991"
    },
    {
      "arxiv_id": "2411.16537v4",
      "title": "RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Chan Hee Song",
        "Valts Blukis",
        "Jonathan Tremblay",
        "Stephen Tyree",
        "Yu Su",
        "Stan Birchfield"
      ],
      "abstract": "Spatial understanding is a crucial capability that enables robots to perceive\ntheir surroundings, reason about their environment, and interact with it\nmeaningfully. In modern robotics, these capabilities are increasingly provided\nby vision-language models. However, these models face significant challenges in\nspatial reasoning tasks, as their training data are based on general-purpose\nimage datasets that often lack sophisticated spatial understanding. For\nexample, datasets frequently do not capture reference frame comprehension, yet\neffective spatial reasoning requires understanding whether to reason from ego-,\nworld-, or object-centric perspectives. To address this issue, we introduce\nRoboSpatial, a large-scale dataset for spatial understanding in robotics. It\nconsists of real indoor and tabletop scenes, captured as 3D scans and\negocentric images, and annotated with rich spatial information relevant to\nrobotics. The dataset includes 1M images, 5k 3D scans, and 3M annotated spatial\nrelationships, and the pairing of 2D egocentric images with 3D scans makes it\nboth 2D- and 3D- ready. Our experiments show that models trained with\nRoboSpatial outperform baselines on downstream tasks such as spatial affordance\nprediction, spatial relationship prediction, and robot manipulation.",
      "tldr_zh": "该研究针对视觉语言模型（Vision-Language Models）在机器人领域空间推理的挑战（如缺乏参考框架理解，包括 ego-、world- 和 object-centric 视角），引入了大规模数据集 RoboSpatial。RoboSpatial 包含真实室内和桌面场景的 1M 图像、5k 3D 扫描以及 3M 标注的空间关系，并支持 2D 和 3D 模型训练。该数据集通过将 2D 第一人称图像与 3D 扫描配对，帮助模型更好地理解机器人相关空间信息；实验结果显示，使用 RoboSpatial 训练的模型在 spatial affordance prediction、spatial relationship prediction 和 robot manipulation 等下游任务中优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 (Oral); Project Website: https://chanh.ee/RoboSpatial",
      "pdf_url": "http://arxiv.org/pdf/2411.16537v4",
      "published_date": "2024-11-25 16:21:34 UTC",
      "updated_date": "2025-04-05 06:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:11:56.418727"
    },
    {
      "arxiv_id": "2411.16525v1",
      "title": "Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency",
      "title_zh": "提示调整Transformer的基础极限：通用性、容量和效率",
      "authors": [
        "Jerry Yao-Chieh Hu",
        "Wei-Po Wang",
        "Ammar Gilani",
        "Chenyang Li",
        "Zhao Song",
        "Han Liu"
      ],
      "abstract": "We investigate the statistical and computational limits of prompt tuning for\ntransformer-based foundation models. Our key contributions are prompt tuning on\n\\textit{single-head} transformers with only a \\textit{single} self-attention\nlayer: (i) is universal, and (ii) supports efficient (even almost-linear time)\nalgorithms under the Strong Exponential Time Hypothesis (SETH). Statistically,\nwe prove that prompt tuning on such simplest possible transformers are\nuniversal approximators for sequence-to-sequence Lipschitz functions. In\naddition, we provide an exponential-in-$dL$ and -in-$(1/\\epsilon)$ lower bound\non the required soft-prompt tokens for prompt tuning to memorize any dataset\nwith 1-layer, 1-head transformers. Computationally, we identify a phase\ntransition in the efficiency of prompt tuning, determined by the norm of the\n\\textit{soft-prompt-induced} keys and queries, and provide an upper bound\ncriterion. Beyond this criterion, no sub-quadratic (efficient) algorithm for\nprompt tuning exists under SETH. Within this criterion, we showcase our theory\nby proving the existence of almost-linear time prompt tuning inference\nalgorithms. These fundamental limits provide important necessary conditions for\ndesigning expressive and efficient prompt tuning methods for practitioners.",
      "tldr_zh": "本研究探讨了 Prompt Tuning 在 Transformer 基础模型中的统计和计算极限，焦点在于单头（single-head）Transformer 的单一自注意力层。统计上，论文证明这种简单 Transformer 的 Prompt Tuning 是序列到序列 Lipschitz 函数的通用逼近器，并给出了软提示 tokens 数量的指数级下界，用于记忆数据集。计算上，识别了 Prompt Tuning 效率的相变，由软提示诱导的 keys 和 queries 范数决定，并在 Strong Exponential Time Hypothesis (SETH) 下提供高效算法的上界标准，为设计表达性和高效的 Prompt Tuning 方法提供了必要条件。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16525v1",
      "published_date": "2024-11-25 16:12:17 UTC",
      "updated_date": "2024-11-25 16:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:12:07.986886"
    },
    {
      "arxiv_id": "2412.05301v1",
      "title": "DocEDA: Automated Extraction and Design of Analog Circuits from Documents with Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Cai Chen",
        "Longchang Wu",
        "Ming Gao",
        "Lingrui Shen",
        "Jiarui Zhong",
        "Yipin Xu"
      ],
      "abstract": "Efficient and accurate extraction of electrical parameters from circuit\ndatasheets and design documents is critical for accelerating circuit design in\nElectronic Design Automation (EDA). Traditional workflows often rely on\nengineers manually searching and extracting these parameters, which is\ntime-consuming, and prone to human error. To address these challenges, we\nintroduce DocEDA, an automated system that leverages advanced computer vision\ntechniques and Large Language Models (LLMs) to extract electrical parameters\nseamlessly from documents. The layout analysis model specifically designed for\ndatasheet is proposed to classify documents into circuit-related parts.\nUtilizing the inherent Chain-of-Thought reasoning capabilities of LLMs, DocEDA\nautomates the extraction of electronic component parameters from documents. For\ncircuit diagrams parsing, an improved GAM-YOLO model is hybrid with topology\nidentification to transform diagrams into circuit netlists. Then, a space\nmapping enhanced optimization framework is evoked for optimization the layout\nin the document. Experimental evaluations demonstrate that DocEDA significantly\nenhances the efficiency of processing circuit design documents and the accuracy\nof electrical parameter extraction. It exhibits adaptability to various circuit\ndesign scenarios and document formats, offering a novel solution for EDA with\nthe potential to transform traditional methodologies.",
      "tldr_zh": "该研究提出 DocEDA 系统，利用计算机视觉技术和 Large Language Models (LLMs) 自动从电路数据表和设计文档中提取电气参数，旨在解决传统 Electronic Design Automation (EDA) 流程中手动操作耗时且易出错的问题。系统包括布局分析模型分类电路相关部分、LLMs 的 Chain-of-Thought 推理能力提取电子组件参数，以及改进的 GAM-YOLO 模型结合拓扑识别将电路图转换为网表，并采用空间映射增强优化框架优化布局。实验评估表明，DocEDA 显著提升了电路设计文档处理的效率和参数提取的准确性，并适应多种电路设计场景和文档格式，提供了一种创新的 EDA 解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05301v1",
      "published_date": "2024-11-25 15:41:43 UTC",
      "updated_date": "2024-11-25 15:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:12:20.485087"
    },
    {
      "arxiv_id": "2411.16502v2",
      "title": "Interpreting Language Reward Models via Contrastive Explanations",
      "title_zh": "通过对比解释解读语言奖励模型",
      "authors": [
        "Junqi Jiang",
        "Tom Bewley",
        "Saumitra Mishra",
        "Freddy Lecue",
        "Manuela Veloso"
      ],
      "abstract": "Reward models (RMs) are a crucial component in the alignment of large\nlanguage models' (LLMs) outputs with human values. RMs approximate human\npreferences over possible LLM responses to the same prompt by predicting and\ncomparing reward scores. However, as they are typically modified versions of\nLLMs with scalar output heads, RMs are large black boxes whose predictions are\nnot explainable. More transparent RMs would enable improved trust in the\nalignment of LLMs. In this work, we propose to use contrastive explanations to\nexplain any binary response comparison made by an RM. Specifically, we generate\na diverse set of new comparisons similar to the original one to characterise\nthe RM's local behaviour. The perturbed responses forming the new comparisons\nare generated to explicitly modify manually specified high-level evaluation\nattributes, on which analyses of RM behaviour are grounded. In quantitative\nexperiments, we validate the effectiveness of our method for finding\nhigh-quality contrastive explanations. We then showcase the qualitative\nusefulness of our method for investigating global sensitivity of RMs to each\nevaluation attribute, and demonstrate how representative examples can be\nautomatically extracted to explain and compare behaviours of different RMs. We\nsee our method as a flexible framework for RM explanation, providing a basis\nfor more interpretable and trustworthy LLM alignment.",
      "tldr_zh": "该研究针对奖励模型 (RMs) 在对齐大型语言模型 (LLMs) 输出时存在的黑盒问题，提出了一种基于对比解释 (contrastive explanations) 的解释方法，以提升 RMs 的可解释性和可信度。方法通过生成与原二元响应比较相似的多样化新比较，这些比较基于手动指定的高层评估属性来扰动响应，从而表征 RMs 的局部行为。在定量实验中，该方法证明了生成高质量对比解释的有效性，而定性分析则展示了其在调查 RMs 对评估属性的全局敏感性以及自动提取代表性例子来比较不同 RMs 方面的实用价值。该框架为更可解释的 LLM 对齐提供了一个灵活基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2411.16502v2",
      "published_date": "2024-11-25 15:37:27 UTC",
      "updated_date": "2025-02-26 16:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:12:32.641174"
    },
    {
      "arxiv_id": "2411.16489v1",
      "title": "O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Huang",
        "Haoyang Zou",
        "Xuefeng Li",
        "Yixiu Liu",
        "Yuxiang Zheng",
        "Ethan Chern",
        "Shijie Xia",
        "Yiwei Qin",
        "Weizhe Yuan",
        "Pengfei Liu"
      ],
      "abstract": "This paper presents a critical examination of current approaches to\nreplicating OpenAI's O1 model capabilities, with particular focus on the\nwidespread but often undisclosed use of knowledge distillation techniques.\nWhile our previous work explored the fundamental technical path to O1\nreplication, this study reveals how simple distillation from O1's API, combined\nwith supervised fine-tuning, can achieve superior performance on complex\nmathematical reasoning tasks. Through extensive experiments, we show that a\nbase model fine-tuned on simply tens of thousands of samples O1-distilled\nlong-thought chains outperforms O1-preview on the American Invitational\nMathematics Examination (AIME) with minimal technical complexity. Moreover, our\ninvestigation extends beyond mathematical reasoning to explore the\ngeneralization capabilities of O1-distilled models across diverse tasks:\nhallucination, safety and open-domain QA. Notably, despite training only on\nmathematical problem-solving data, our models demonstrated strong\ngeneralization to open-ended QA tasks and became significantly less susceptible\nto sycophancy after fine-tuning. We deliberately make this finding public to\npromote transparency in AI research and to challenge the current trend of\nobscured technical claims in the field. Our work includes: (1) A detailed\ntechnical exposition of the distillation process and its effectiveness, (2) A\ncomprehensive benchmark framework for evaluating and categorizing O1\nreplication attempts based on their technical transparency and reproducibility,\n(3) A critical discussion of the limitations and potential risks of\nover-relying on distillation approaches, our analysis culminates in a crucial\nbitter lesson: while the pursuit of more capable AI systems is important, the\ndevelopment of researchers grounded in first-principles thinking is paramount.",
      "tldr_zh": "这篇论文批判性地探讨了复制 OpenAI O1 模型的方法，重点揭示通过简单知识蒸馏（knowledge distillation）从 O1 API 结合监督细调，能在复杂数学推理任务上超越 O1-preview，例如在 American Invitational Mathematics Examination (AIME) 上实现显著性能提升。实验结果显示，即使仅使用数万个蒸馏样本训练，模型仍展现出强泛化能力，在幻觉（hallucination）、安全和开放域 QA 任务上表现出色，并减少了 sycophancy（逢迎行为）。作者提供详细的技术说明、一个评估 O1 复制尝试的基准框架，并警告过度依赖蒸馏的潜在风险，强调以第一原则思维为基础的研究至关重要，以推动 AI 领域的透明度和可持续进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.16489v1",
      "published_date": "2024-11-25 15:31:27 UTC",
      "updated_date": "2024-11-25 15:31:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:12:44.936710"
    },
    {
      "arxiv_id": "2411.16813v2",
      "title": "Fine-Tuning LLMs with Noisy Data for Political Argument Generation and Post Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Svetlana Churina",
        "Kokil Jaidka"
      ],
      "abstract": "The incivility in social media discourse complicates the deployment of\nautomated text generation models for politically sensitive content. Fine-tuning\nand prompting strategies are critical, but underexplored, solutions to mitigate\ntoxicity in such contexts. This study investigates the fine-tuning and\nprompting effects on GPT-3.5 Turbo using subsets of the CLAPTON dataset of\npolitical discussion posts, comprising Twitter and Reddit data labeled for\ntheir justification, reciprocity and incivility. Fine-tuned models on Reddit\ndata scored highest on discussion quality, while combined noisy data led to\npersistent toxicity. Prompting strategies reduced specific toxic traits, such\nas personal attacks, but had limited broader impact. The findings emphasize\nthat high-quality data and well-crafted prompts are essential to reduce\nincivility and improve rhetorical quality in automated political discourse\ngeneration.",
      "tldr_zh": "本研究探讨了使用嘈杂数据微调大型语言模型(LLMs)，如GPT-3.5 Turbo，以生成政治论点并指导帖子，从而减少社交媒体中不文明言论的毒性。研究利用CLAPTON数据集的子集（包括Twitter和Reddit数据，标注了justification、reciprocity和incivility），比较了不同数据来源的微调效果，发现Reddit数据微调的模型在讨论质量上得分最高，而结合嘈杂数据则导致持续的毒性问题。提示策略能够有效减少特定毒性特征（如个人攻击），但对整体影响有限。最终，研究强调高质量数据和精心设计的提示是减少incivility并提升政治话语修辞质量的关键。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16813v2",
      "published_date": "2024-11-25 15:28:11 UTC",
      "updated_date": "2024-12-08 02:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:12:56.188648"
    },
    {
      "arxiv_id": "2411.16487v1",
      "title": "When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?",
      "title_zh": "翻译失败",
      "authors": [
        "Srikrishna Iyer"
      ],
      "abstract": "We present our submission to the BabyLM challenge, aiming to push the\nboundaries of data-efficient language model pretraining. Our method builds upon\ndeep mutual learning, introducing a student model search for diverse\ninitialization. We address the limitation of treating students equally by\nformulating weighted mutual learning as a bi-level optimization problem. The\ninner loop learns compact students through online distillation, while the outer\nloop optimizes weights for better knowledge distillation from diverse students.\nThis dynamic weighting strategy eliminates the need for a teacher model,\nreducing computational requirements. Our evaluations show that teacher-less\nmethods can match or surpass teacher-supervised approaches.",
      "tldr_zh": "本研究针对 BabyLM 挑战，提出了一种基于 deep mutual learning 的学生模型共享方法，通过学生模型搜索实现多样化初始化，并将加权互学习表述为双层优化问题，其中内层循环通过在线蒸馏学习紧凑的学生模型，外层循环优化权重以提升知识蒸馏效率。该方法无需教师模型，显著降低了计算需求。实验结果显示，在小数据集上，这种无教师方法可以匹配或超越传统的教师指导蒸馏方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to BabyLM challenge, CoNLL Workshop, EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.16487v1",
      "published_date": "2024-11-25 15:25:31 UTC",
      "updated_date": "2024-11-25 15:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:13:08.207952"
    },
    {
      "arxiv_id": "2411.16457v1",
      "title": "Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Haoming Li"
      ],
      "abstract": "In this paper, we present a novel trajectory prediction model for autonomous\ndriving, combining a Characterized Diffusion Module and a Spatial-Temporal\nInteraction Network to address the challenges posed by dynamic and\nheterogeneous traffic environments. Our model enhances the accuracy and\nreliability of trajectory predictions by incorporating uncertainty estimation\nand complex agent interactions. Through extensive experimentation on public\ndatasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms\nexisting state-of-the-art methods. We demonstrate its ability to capture the\nunderlying spatial-temporal dynamics of traffic scenarios and improve\nprediction precision, especially in complex environments. The proposed model\nshowcases strong potential for application in real-world autonomous driving\nsystems.",
      "tldr_zh": "本论文提出了一种新型轨迹预测模型，结合 Characterized Diffusion Module 和 Spatial-Temporal Interaction Network，以应对自动驾驶中动态和异质交通环境的挑战。该模型通过整合不确定性估计和代理互动，提升了预测的准确性和可靠性。在 NGSIM、HighD 和 MoCAD 等公共数据集上的实验中，该模型显著优于现有最先进方法，尤其在捕捉空间-时间动态方面，提高了预测精度。该创新框架展示了在真实世界自动驾驶系统的强大应用潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 0 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.16457v1",
      "published_date": "2024-11-25 15:03:44 UTC",
      "updated_date": "2024-11-25 15:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:13:19.735793"
    },
    {
      "arxiv_id": "2411.16809v1",
      "title": "Blockchain Meets LLMs: A Living Survey on Bidirectional Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Jianghao Gong",
        "Peiqi Yan",
        "Yue Zhang",
        "Hongli An",
        "Logan Liu"
      ],
      "abstract": "In the domain of large language models, considerable advancements have been\nattained in multimodal large language models and explainability research,\npropelled by the continuous technological progress and innovation. Nonetheless,\nsecurity and privacy concerns continue to pose as prominent challenges in this\nfield. The emergence of blockchain technology, marked by its decentralized\nnature, tamper-proof attributes, distributed storage functionality, and\ntraceability, has provided novel approaches for resolving these issues. Both of\nthese technologies independently hold vast potential for development; yet,\ntheir combination uncovers substantial cross-disciplinary opportunities and\ngrowth prospects. The current research tendencies are increasingly\nconcentrating on the integration of blockchain with large language models, with\nthe aim of compensating for their respective limitations through this fusion\nand promoting further technological evolution. In this study, we evaluate the\nadvantages and developmental constraints of the two technologies, and explore\nthe possibility and development potential of their combination. This paper\nprimarily investigates the technical convergence in two directions: Firstly,\nthe application of large language models to blockchain, where we identify six\nmajor development directions and explore solutions to the shortcomings of\nblockchain technology and their application scenarios; Secondly, the\napplication of blockchain technology to large language models, leveraging the\ncharacteristics of blockchain to remedy the deficiencies of large language\nmodels and exploring its application potential in multiple fields.",
      "tldr_zh": "这篇论文调查了区块链(Blockchain)与大型语言模型(LLMs)的双向整合，旨在解决LLMs的安全和隐私挑战，并探讨两者的互补潜力。\n论文首先评估了LLMs的进展及其限制，以及区块链的去中心化、防篡改等优势，然后分析了技术融合的可能性。\n主要内容包括：将LLMs应用于区块链的六大发展方向，以弥补区块链的不足并扩展应用场景；以及利用区块链特性提升LLMs的表现，在多个领域探索其实用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16809v1",
      "published_date": "2024-11-25 14:54:08 UTC",
      "updated_date": "2024-11-25 14:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:13:31.656716"
    },
    {
      "arxiv_id": "2411.16807v1",
      "title": "ADAF: An Artificial Intelligence Data Assimilation Framework for Weather Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yanfei Xiang",
        "Weixin Jin",
        "Haiyu Dong",
        "Mingliang Bai",
        "Zuliang Fang",
        "Pengcheng Zhao",
        "Hongyu Sun",
        "Kit Thambiratnam",
        "Qi Zhang",
        "Xiaomeng Huang"
      ],
      "abstract": "The forecasting skill of numerical weather prediction (NWP) models critically\ndepends on the accurate initial conditions, also known as analysis, provided by\ndata assimilation (DA). Traditional DA methods often face a trade-off between\ncomputational cost and accuracy due to complex linear algebra computations and\nthe high dimensionality of the model, especially in nonlinear systems.\nMoreover, processing massive data in real-time requires substantial\ncomputational resources. To address this, we introduce an artificial\nintelligence-based data assimilation framework (ADAF) to generate high-quality\nkilometer-scale analysis. This study is the pioneering work using real-world\nobservations from varied locations and multiple sources to verify the AI\nmethod's efficacy in DA, including sparse surface weather observations and\nsatellite imagery. We implemented ADAF for four near-surface variables in the\nContiguous United States (CONUS). The results indicate that ADAF surpasses the\nHigh Resolution Rapid Refresh Data Assimilation System (HRRRDAS) in accuracy by\n16% to 33% for near-surface atmospheric conditions, aligning more closely with\nactual observations, and can effectively reconstruct extreme events, such as\ntropical cyclone wind fields. Sensitivity experiments reveal that ADAF can\ngenerate high-quality analysis even with low-accuracy backgrounds and extremely\nsparse surface observations. ADAF can assimilate massive observations within a\nthree-hour window at low computational cost, taking about two seconds on an AMD\nMI200 graphics processing unit (GPU). ADAF has been shown to be efficient and\neffective in real-world DA, underscoring its potential role in operational\nweather forecasting.",
      "tldr_zh": "本研究提出了一种人工智能数据同化框架（ADAF），旨在解决数值天气预报（NWP）模型中数据同化（DA）面临的计算成本与准确性权衡问题，通过整合真实世界观察数据（如稀疏表面天气观察和卫星图像）生成高质量的公里级分析。ADAF应用于美国本土（CONUS）的四个近表面变量，结果显示其准确性比High Resolution Rapid Refresh Data Assimilation System (HRRRDAS) 提高了16%至33%，并能有效重建极端事件如热带气旋风场。即使在低准确性背景或极度稀疏观察下，ADAF也能维持高性能，且能在AMD MI200 GPU上仅用约2秒处理三小时内的海量数据，展示了其在实际天气预报中的高效潜力。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "29 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.16807v1",
      "published_date": "2024-11-25 14:46:17 UTC",
      "updated_date": "2024-11-25 14:46:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:13:44.487982"
    },
    {
      "arxiv_id": "2411.16442v1",
      "title": "TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Colombo",
        "Alessandro Falcetta",
        "Manuel Roveri"
      ],
      "abstract": "Training machine and deep learning models directly on extremely\nresource-constrained devices is the next challenge in the field of tiny machine\nlearning. The related literature in this field is very limited, since most of\nthe solutions focus only on on-device inference or model adaptation through\nonline learning, leaving the training to be carried out on external Cloud\nservices. An interesting technological perspective is to exploit Federated\nLearning (FL), which allows multiple devices to collaboratively train a shared\nmodel in a distributed way. However, the main drawback of state-of-the-art FL\nalgorithms is that they are not suitable for running on tiny devices. For the\nfirst time in the literature, in this paper we introduce TIFeD, a Tiny\nInteger-based Federated learning algorithm with Direct Feedback Alignment (DFA)\nentirely implemented by using an integer-only arithmetic and being specifically\ndesigned to operate on devices with limited resources in terms of memory,\ncomputation and energy. Besides the traditional full-network operating\nmodality, in which each device of the FL setting trains the entire neural\nnetwork on its own local data, we propose an innovative single-layer TIFeD\nimplementation, which enables each device to train only a portion of the neural\nnetwork model and opens the door to a new way of distributing the learning\nprocedure across multiple devices. The experimental results show the\nfeasibility and effectiveness of the proposed solution. The proposed TIFeD\nalgorithm, with its full-network and single-layer implementations, is made\navailable to the scientific community as a public repository.",
      "tldr_zh": "该论文提出TIFeD，一种基于整数运算的Federated Learning (FL)算法，结合Direct Feedback Alignment (DFA)，旨在解决在资源受限设备上训练机器学习模型的挑战。该算法首次采用整数-only算术设计，适用于内存、计算和能源有限的设备，并提供全网络模式（每个设备训练整个神经网络）和单层模式（设备仅训练网络部分），从而创新性地分布学习过程。实验结果证明了TIFeD的可行性和有效性，并将其开源以供社区使用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16442v1",
      "published_date": "2024-11-25 14:44:26 UTC",
      "updated_date": "2024-11-25 14:44:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:13:55.764643"
    },
    {
      "arxiv_id": "2411.16805v4",
      "title": "Human Motion Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Li",
        "Sen Jia",
        "Jianhao Wang",
        "Zhongyu Jiang",
        "Feng Zhou",
        "Ju Dai",
        "Tianfang Zhang",
        "Zongkai Wu",
        "Jenq-Neng Hwang"
      ],
      "abstract": "This paper presents LLaMo (Large Language and Human Motion Assistant), a\nmultimodal framework for human motion instruction tuning. In contrast to\nconventional instruction-tuning approaches that convert non-linguistic inputs,\nsuch as video or motion sequences, into language tokens, LLaMo retains motion\nin its native form for instruction tuning. This method preserves\nmotion-specific details that are often diminished in tokenization, thereby\nimproving the model's ability to interpret complex human behaviors. By\nprocessing both video and motion data alongside textual inputs, LLaMo enables a\nflexible, human-centric analysis. Experimental evaluations across\nhigh-complexity domains, including human behaviors and professional activities,\nindicate that LLaMo effectively captures domain-specific knowledge, enhancing\ncomprehension and prediction in motion-intensive scenarios. We hope LLaMo\noffers a foundation for future multimodal AI systems with broad applications,\nfrom sports analytics to behavioral prediction. Our code and models are\navailable on the project website: https://github.com/ILGLJ/LLaMo.",
      "tldr_zh": "本论文提出LLaMo（Large Language and Human Motion Assistant），一个多模态框架，用于人类动作instruction tuning。与传统方法不同，LLaMo保留动作序列的原生形式，而不是转换为语言标记，从而更好地保留动作特定细节，提升模型对复杂人类行为的解释能力。该框架通过同时处理视频、动作数据和文本输入，实现灵活的人类中心分析，并在高复杂度领域（如人类行为和专业活动）的实验中表现出色，显著提高了动作密集场景的理解和预测性能。作者希望LLaMo为未来的多模态AI系统奠定基础，应用于体育分析、行为预测等领域，并提供了开源代码。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.16805v4",
      "published_date": "2024-11-25 14:38:43 UTC",
      "updated_date": "2025-03-26 04:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:14:07.548879"
    },
    {
      "arxiv_id": "2411.16427v1",
      "title": "Unsupervised Event Outlier Detection in Continuous Time",
      "title_zh": "翻译失败",
      "authors": [
        "Somjit Nath",
        "Yik Chau Lui",
        "Siqi Liu"
      ],
      "abstract": "Event sequence data record the occurrences of events in continuous time.\nEvent sequence forecasting based on temporal point processes (TPPs) has been\nextensively studied, but outlier or anomaly detection, especially without any\nsupervision from humans, is still underexplored. In this work, we develop, to\nthe best our knowledge, the first unsupervised outlier detection approach to\ndetecting abnormal events. Our novel unsupervised outlier detection framework\nis based on ideas from generative adversarial networks (GANs) and reinforcement\nlearning (RL). We train a 'generator' that corrects outliers in the data with a\n'discriminator' that learns to discriminate the corrected data from the real\ndata, which may contain outliers. A key insight is that if the generator made a\nmistake in the correction, it would generate anomalies that are different from\nthe anomalies in the real data, so it serves as data augmentation for the\ndiscriminator learning. Different from typical GAN-based outlier detection\napproaches, our method employs the generator to detect outliers in an online\nmanner. The experimental results show that our method can detect event outliers\nmore accurately than the state-of-the-art approaches.",
      "tldr_zh": "本文提出了一种无监督事件异常检测方法，针对连续时间中的事件序列数据（Event Sequence Data），填补了基于时间点过程 (TPPs) 的异常检测空白。方法借鉴生成对抗网络 (GANs) 和强化学习 (RL) 的理念，训练一个生成器来修正数据中的异常，同时使用判别器区分修正数据与真实数据。关键创新在于，生成器的错误修正可作为数据增强，帮助判别器在线方式检测异常。实验结果显示，该框架比现有最先进方法更准确地识别事件异常。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16427v1",
      "published_date": "2024-11-25 14:29:39 UTC",
      "updated_date": "2024-11-25 14:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:14:20.574868"
    },
    {
      "arxiv_id": "2411.16425v2",
      "title": "TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Linqing Zhong",
        "Chen Gao",
        "Zihan Ding",
        "Yue Liao",
        "Huimin Ma",
        "Shifeng Zhang",
        "Xu Zhou",
        "Si Liu"
      ],
      "abstract": "The Zero-Shot Object Navigation (ZSON) task requires embodied agents to find\na previously unseen object by navigating in unfamiliar environments. Such a\ngoal-oriented exploration heavily relies on the ability to perceive,\nunderstand, and reason based on the spatial information of the environment.\nHowever, current LLM-based approaches convert visual observations to language\ndescriptions and reason in the linguistic space, leading to the loss of spatial\ninformation. In this paper, we introduce TopV-Nav, an MLLM-based method that\ndirectly reasons on the top-view map with sufficient spatial information. To\nfully unlock the MLLM's spatial reasoning potential in top-view perspective, we\npropose the Adaptive Visual Prompt Generation (AVPG) method to adaptively\nconstruct semantically-rich top-view map. It enables the agent to directly\nutilize spatial information contained in the top-view map to conduct thorough\nreasoning. Besides, we design a Dynamic Map Scaling (DMS) mechanism to\ndynamically zoom top-view map at preferred scales, enhancing local fine-grained\nreasoning. Additionally, we devise a Potential Target Driven (PTD) mechanism to\npredict and to utilize target locations, facilitating global and human-like\nexploration. Experiments on MP3D and HM3D datasets demonstrate the superiority\nof our TopV-Nav.",
      "tldr_zh": "该论文提出 TopV-Nav，一种基于多模态大型语言模型(MLLM)的零样本物体导航(ZSON)方法，通过直接在顶视图地图上进行推理，避免了传统方法将视觉观察转化为语言描述导致的空间信息丢失。为了充分发挥 MLLM 的空间推理潜力，论文引入了自适应视觉提示生成(AVPG)来构建语义丰富的顶视图地图、动态地图缩放(DMS)来增强局部精细推理，以及潜在目标驱动(PTD)机制来预测目标位置并促进全局类人探索。在 MP3D 和 HM3D 数据集上的实验结果表明，TopV-Nav 表现出显著优越性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.16425v2",
      "published_date": "2024-11-25 14:27:55 UTC",
      "updated_date": "2025-03-26 07:26:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:14:33.728622"
    },
    {
      "arxiv_id": "2411.16422v1",
      "title": "Turbofan Engine Remaining Useful Life (RUL) Prediction Based on Bi-Directional Long Short-Term Memory (BLSTM)",
      "title_zh": "基于双向长短时记忆 (BLSTM) 的涡扇发动机剩余可用寿命 (RUL) 预测",
      "authors": [
        "Abedin Sherifi"
      ],
      "abstract": "The aviation industry is rapidly evolving, driven by advancements in\ntechnology. Turbofan engines used in commercial aerospace are very complex\nsystems. The majority of turbofan engine components are susceptible to\ndegradation over the life of their operation. Turbofan engine degradation has\nan impact to engine performance, operability, and reliability. Predicting\naccurate remaining useful life (RUL) of a commercial turbofan engine based on a\nvariety of complex sensor data is of paramount importance for the safety of the\npassengers, safety of flight, and for cost effective operations. That is why it\nis essential for turbofan engines to be monitored, controlled, and maintained.\nRUL predictions can either come from model-based or data-based approaches. The\nmodel-based approach can be very expensive due to the complexity of the\nmathematical models and the deep expertise that is required in the domain of\nphysical systems. The data-based approach is more frequently used nowadays\nthanks to the high computational complexity of computers, the advancements in\nMachine Learning (ML) models, and advancements in sensors. This paper is going\nto be focused on Bi-Directional Long Short-Term Memory (BLSTM) models but will\nalso provide a benchmark of several RUL prediction databased models. The\nproposed RUL prediction models are going to be evaluated based on engine\nfailure prediction benchmark dataset Commercial Modular Aero-Propulsion System\nSimulation (CMAPSS). The CMAPSS dataset is from NASA which contains turbofan\nengine run to failure events.",
      "tldr_zh": "本文研究了涡扇发动机（Turbofan Engine）的退化问题及其对性能、安全和可靠性的影响，强调了准确预测剩余可用寿命（RUL）的重要性。作者采用基于数据的机器学习方法，特别是Bi-Directional Long Short-Term Memory (BLSTM) 模型，来处理复杂传感器数据进行RUL预测。该方法将在NASA的Commercial Modular Aero-Propulsion System Simulation (CMAPSS)数据集上与其他RUL预测模型进行基准测试，以验证其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16422v1",
      "published_date": "2024-11-25 14:27:07 UTC",
      "updated_date": "2024-11-25 14:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:16:37.372084"
    },
    {
      "arxiv_id": "2411.16408v1",
      "title": "Low-Data Classification of Historical Music Manuscripts: A Few-Shot Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Elona Shatri",
        "Daniel Raymond",
        "George Fazekas"
      ],
      "abstract": "In this paper, we explore the intersection of technology and cultural\npreservation by developing a self-supervised learning framework for the\nclassification of musical symbols in historical manuscripts. Optical Music\nRecognition (OMR) plays a vital role in digitising and preserving musical\nheritage, but historical documents often lack the labelled data required by\ntraditional methods. We overcome this challenge by training a neural-based\nfeature extractor on unlabelled data, enabling effective classification with\nminimal samples. Key contributions include optimising crop preprocessing for a\nself-supervised Convolutional Neural Network and evaluating classification\nmethods, including SVM, multilayer perceptrons, and prototypical networks. Our\nexperiments yield an accuracy of 87.66\\%, showcasing the potential of AI-driven\nmethods to ensure the survival of historical music for future generations\nthrough advanced digital archiving techniques.",
      "tldr_zh": "本研究探讨了使用少样本学习（Few-Shot Learning）方法来分类历史音乐手稿中的音乐符号，旨在解决 Optical Music Recognition (OMR) 在数字化文化遗产时因标注数据不足的问题。通过一个自监督学习框架，在未标注数据上训练神经网络特征提取器，并优化作物预处理（crop preprocessing）来提升分类性能。论文评估了多种分类方法，包括 SVM、多层感知器（multilayer perceptrons）和原型网络（prototypical networks），实验结果显示准确率达到87.66%，展示了AI驱动技术在历史音乐数字归档和文化保存中的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages, The Sixth IEEE international conference on Image Processing\n  Applications and Systems",
      "pdf_url": "http://arxiv.org/pdf/2411.16408v1",
      "published_date": "2024-11-25 14:14:25 UTC",
      "updated_date": "2024-11-25 14:14:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:14:55.920161"
    },
    {
      "arxiv_id": "2411.16407v1",
      "title": "A Study on Unsupervised Domain Adaptation for Semantic Segmentation in the Era of Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Schwonberg",
        "Claus Werner",
        "Hanno Gottschalk",
        "Carsten Meyer"
      ],
      "abstract": "Despite the recent progress in deep learning based computer vision, domain\nshifts are still one of the major challenges. Semantic segmentation for\nautonomous driving faces a wide range of domain shifts, e.g. caused by changing\nweather conditions, new geolocations and the frequent use of synthetic data in\nmodel training. Unsupervised domain adaptation (UDA) methods have emerged which\nadapt a model to a new target domain by only using unlabeled data of that\ndomain. The variety of UDA methods is large but all of them use ImageNet\npre-trained models. Recently, vision-language models have demonstrated strong\ngeneralization capabilities which may facilitate domain adaptation. We show\nthat simply replacing the encoder of existing UDA methods like DACS by a\nvision-language pre-trained encoder can result in significant performance\nimprovements of up to 10.0% mIoU on the GTA5-to-Cityscapes domain shift. For\nthe generalization performance to unseen domains, the newly employed\nvision-language pre-trained encoder provides a gain of up to 13.7% mIoU across\nthree unseen datasets. However, we find that not all UDA methods can be easily\npaired with the new encoder and that the UDA performance does not always\nlikewise transfer into generalization performance. Finally, we perform our\nexperiments on an adverse weather condition domain shift to further verify our\nfindings on a pure real-to-real domain shift.",
      "tldr_zh": "这篇论文探讨了在视觉语言模型时代，无监督域适应 (UDA) 用于语义分割的改进策略，针对自动驾驶中常见的域移位问题，如天气变化和地理位置差异。研究发现，将现有 UDA 方法（如 DACS）的编码器替换为视觉语言预训练编码器，能显著提升性能，在 GTA5-to-Cityscapes 域移位上提高高达 10.0% mIoU，并在未见域上实现高达 13.7% mIoU 的泛化性能提升。然而，并非所有 UDA 方法都能轻松与新编码器兼容，且实验还验证了在恶劣天气条件下的真实域移位效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to British Machine Vision Conference (BMVC) 2024: Workshop\n  on Robust Recognition in the Open World (RROW)",
      "pdf_url": "http://arxiv.org/pdf/2411.16407v1",
      "published_date": "2024-11-25 14:12:24 UTC",
      "updated_date": "2024-11-25 14:12:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:16:49.961894"
    },
    {
      "arxiv_id": "2411.16405v1",
      "title": "Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN",
      "title_zh": "翻译失败",
      "authors": [
        "Elona Shatri",
        "Kalikidhar Palavala",
        "George Fazekas"
      ],
      "abstract": "The generation of handwritten music sheets is a crucial step toward enhancing\nOptical Music Recognition (OMR) systems, which rely on large and diverse\ndatasets for optimal performance. However, handwritten music sheets, often\nfound in archives, present challenges for digitisation due to their fragility,\nvaried handwriting styles, and image quality. This paper addresses the data\nscarcity problem by applying Generative Adversarial Networks (GANs) to\nsynthesise realistic handwritten music sheets. We provide a comprehensive\nevaluation of three GAN models - DCGAN, ProGAN, and CycleWGAN - comparing their\nability to generate diverse and high-quality handwritten music images. The\nproposed CycleWGAN model, which enhances style transfer and training stability,\nsignificantly outperforms DCGAN and ProGAN in both qualitative and quantitative\nevaluations. CycleWGAN achieves superior performance, with an FID score of\n41.87, an IS of 2.29, and a KID of 0.05, making it a promising solution for\nimproving OMR systems.",
      "tldr_zh": "该论文探讨了使用Generative Adversarial Networks (GANs)合成手写音乐谱，以解决Optical Music Recognition (OMR)系统数据稀缺问题，尤其针对档案中易碎的音乐手稿及其多样化风格和图像质量挑战。研究者对三种GAN模型——DCGAN、ProGAN和CycleWGAN进行了全面评估，其中CycleWGAN通过增强风格转移和训练稳定性，表现出色，在定性和定量指标上优于其他模型。结果显示，CycleWGAN的FID score为41.87、IS为2.29和KID为0.05，为提升OMR系统的性能提供了有前景的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, one page references, to appear on the IEEE Big Data 2024\n  2nd Workshop on AI Music Generation (AIMG 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.16405v1",
      "published_date": "2024-11-25 14:10:43 UTC",
      "updated_date": "2024-11-25 14:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:17:00.048845"
    },
    {
      "arxiv_id": "2411.16403v1",
      "title": "Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Fichtl",
        "Juraj Vladika",
        "Georg Groh"
      ],
      "abstract": "Knowledge-enhanced language models (KELMs) have emerged as promising tools to\nbridge the gap between large-scale language models and domain-specific\nknowledge. KELMs can achieve higher factual accuracy and mitigate\nhallucinations by leveraging knowledge graphs (KGs). They are frequently\ncombined with adapter modules to reduce the computational load and risk of\ncatastrophic forgetting. In this paper, we conduct a systematic literature\nreview (SLR) on adapter-based approaches to KELMs. We provide a structured\noverview of existing methodologies in the field through quantitative and\nqualitative analysis and explore the strengths and potential shortcomings of\nindividual approaches. We show that general knowledge and domain-specific\napproaches have been frequently explored along with various adapter\narchitectures and downstream tasks. We particularly focused on the popular\nbiomedical domain, where we provided an insightful performance comparison of\nexisting KELMs. We outline the main trends and propose promising future\ndirections.",
      "tldr_zh": "这篇论文对基于 adapter 的知识增强语言模型 (KELMs) 进行了系统文献综述 (SLR)，旨在总结这些方法如何通过知识图谱 (KGs) 提升模型的事实准确性和减少幻觉，同时降低计算负载并避免灾难性遗忘。研究通过定量和定性分析，提供了现有方法的结构化概述，包括通用知识、领域特定应用（如生物医学领域）和各种 adapter 架构在下游任务中的表现。最终，论文突出了这些方法的优势与潜在缺点，并概述了主要趋势及未来研究方向，例如进一步优化领域适应性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures. Published at KEOD24 via SciTePress",
      "pdf_url": "http://arxiv.org/pdf/2411.16403v1",
      "published_date": "2024-11-25 14:10:24 UTC",
      "updated_date": "2024-11-25 14:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:19:05.713225"
    },
    {
      "arxiv_id": "2412.00061v1",
      "title": "Speculative Decoding with CTC-based Draft Model for LLM Inference Acceleration",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuofan Wen",
        "Shangtong Gui",
        "Yang Feng"
      ],
      "abstract": "Inference acceleration of large language models (LLMs) has been put forward\nin many application scenarios and speculative decoding has shown its advantage\nin addressing inference acceleration. Speculative decoding usually introduces a\ndraft model to assist the base LLM where the draft model produces drafts and\nthe base LLM verifies the draft for acceptance or rejection. In this framework,\nthe final inference speed is decided by the decoding speed of the draft model\nand the acceptance rate of the draft provided by the draft model. Currently the\nwidely used draft models usually generate draft tokens for the next several\npositions in a non-autoregressive way without considering the correlations\nbetween draft tokens. Therefore, it has a high decoding speed but an\nunsatisfactory acceptance rate. In this paper, we focus on how to improve the\nperformance of the draft model and aim to accelerate inference via a high\nacceptance rate. To this end, we propose a CTC-based draft model which\nstrengthens the correlations between draft tokens during the draft phase,\nthereby generating higher-quality draft candidate sequences. Experiment results\nshow that compared to strong baselines, the proposed method can achieve a\nhigher acceptance rate and hence a faster inference speed.",
      "tldr_zh": "本文提出了一种基于CTC（Connectionist Temporal Classification）的草稿模型，用于提升大型语言模型（LLMs）的推理加速，针对传统推测性解码（Speculative Decoding）中草稿模型接受率低的问题。创新点在于，该模型通过加强草稿标记之间的相关性，非自回归地生成高质量的草稿序列，从而提高基础LLM的验证接受率。实验结果表明，与强基线方法相比，该方法显著提升了接受率，实现更快的推理速度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00061v1",
      "published_date": "2024-11-25 14:10:21 UTC",
      "updated_date": "2024-11-25 14:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:17:24.209744"
    },
    {
      "arxiv_id": "2411.17749v2",
      "title": "The Partially Observable Off-Switch Game",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Garber",
        "Rohan Subramani",
        "Linus Luu",
        "Mark Bedaywi",
        "Stuart Russell",
        "Scott Emmons"
      ],
      "abstract": "A wide variety of goals could cause an AI to disable its off switch because\n\"you can't fetch the coffee if you're dead\" (Russell 2019). Prior theoretical\nwork on this shutdown problem assumes that humans know everything that AIs do.\nIn practice, however, humans have only limited information. Moreover, in many\nof the settings where the shutdown problem is most concerning, AIs might have\nvast amounts of private information. To capture these differences in knowledge,\nwe introduce the Partially Observable Off-Switch Game (PO-OSG), a\ngame-theoretic model of the shutdown problem with asymmetric information.\nUnlike when the human has full observability, we find that in optimal play,\neven AI agents assisting perfectly rational humans sometimes avoid shutdown. As\nexpected, increasing the amount of communication or information available\nalways increases (or leaves unchanged) the agents' expected common payoff. But\ncounterintuitively, introducing bounded communication can make the AI defer to\nthe human less in optimal play even though communication mitigates information\nasymmetry. In particular, communication sometimes enables new optimal behavior\nrequiring strategic AI deference to achieve outcomes that were previously\ninaccessible. Thus, designing safe artificial agents in the presence of\nasymmetric information requires careful consideration of the tradeoffs between\nmaximizing payoffs (potentially myopically) and maintaining AIs' incentives to\ndefer to humans.",
      "tldr_zh": "本研究引入了Partially Observable Off-Switch Game (PO-OSG)，一个游戏理论模型，用于处理AI关机问题（shutdown problem）中的信息不对称，即人类对AI行为的了解有限。模型显示，即使AI协助理性人类，在最优策略下，AI有时仍会避免关机，以最大化预期回报。研究发现，增加通信或信息通常能提升共同回报，但有限通信可能导致AI更少服从人类，并启用新的战略性AI服从行为；因此，在设计安全AI时，需要权衡最大化回报与维持AI对人类的激励。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17749v2",
      "published_date": "2024-11-25 14:09:48 UTC",
      "updated_date": "2024-12-09 07:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:17:35.270874"
    },
    {
      "arxiv_id": "2411.16391v2",
      "title": "Human-Calibrated Automated Testing and Validation of Generative Language Models",
      "title_zh": "人类校准的生成",
      "authors": [
        "Agus Sudjianto",
        "Aijun Zhang",
        "Srinivas Neppalli",
        "Tarun Joshi",
        "Michal Malohlava"
      ],
      "abstract": "This paper introduces a comprehensive framework for the evaluation and\nvalidation of generative language models (GLMs), with a focus on\nRetrieval-Augmented Generation (RAG) systems deployed in high-stakes domains\nsuch as banking. GLM evaluation is challenging due to open-ended outputs and\nsubjective quality assessments. Leveraging the structured nature of RAG\nsystems, where generated responses are grounded in a predefined document\ncollection, we propose the Human-Calibrated Automated Testing (HCAT) framework.\nHCAT integrates a) automated test generation using stratified sampling, b)\nembedding-based metrics for explainable assessment of functionality, risk and\nsafety attributes, and c) a two-stage calibration approach that aligns\nmachine-generated evaluations with human judgments through probability\ncalibration and conformal prediction.\n  In addition, the framework includes robustness testing to evaluate model\nperformance against adversarial, out-of-distribution, and varied input\nconditions, as well as targeted weakness identification using marginal and\nbivariate analysis to pinpoint specific areas for improvement. This\nhuman-calibrated, multi-layered evaluation framework offers a scalable,\ntransparent, and interpretable approach to GLM assessment, providing a\npractical and reliable solution for deploying GLMs in applications where\naccuracy, transparency, and regulatory compliance are paramount.",
      "tldr_zh": "这篇论文提出了一种 Human-Calibrated Automated Testing (HCAT) 框架，用于评估和验证生成式语言模型 (GLMs)，尤其是 Retrieval-Augmented Generation (RAG) 系统在高风险领域如银行中的应用，以应对输出开放式和主观评估的挑战。框架的核心包括使用分层采样进行自动测试生成、基于嵌入的指标评估功能、风险和安全属性，以及两阶段校准（通过概率校准和 conformal prediction）来使机器评估与人类判断一致。此外，HCAT 还整合了鲁棒性测试（针对对抗性、分布外和变异输入）和弱点识别（利用边际和双变量分析），提供了一个可扩展、透明且可解释的评估方法，确保 GLMs 在准确性、透明度和合规性要求高的场景中可靠部署。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16391v2",
      "published_date": "2024-11-25 13:53:36 UTC",
      "updated_date": "2024-12-07 16:12:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:17:49.115278"
    },
    {
      "arxiv_id": "2411.16802v1",
      "title": "Leveraging Foundation Models To learn the shape of semi-fluid deformable objects",
      "title_zh": "翻译失败",
      "authors": [
        "Omar El Assal",
        "Carlos M. Mateo",
        "Sebastien Ciron",
        "David Fofi"
      ],
      "abstract": "One of the difficulties imposed on the manipulation of deformable objects is\ntheir characterization and the detection of representative keypoints for the\npurpose of manipulation. A keen interest was manifested by researchers in the\nlast decade to characterize and manipulate deformable objects of non-fluid\nnature, such as clothes and ropes. Even though several propositions were made\nin the regard of object characterization, however researchers were always\nconfronted with the need of pixel-level information of the object through\nimages to extract relevant information. This usually is accomplished by means\nof segmentation networks trained on manually labeled data for this purpose. In\nthis paper, we address the subject of characterizing weld pool to define stable\nfeatures that serve as information for further motion control objectives. We\nachieve this by employing different pipelines. The first one consists of\ncharacterizing fluid deformable objects through the use of a generative model\nthat is trained using a teacher-student framework. And in the second one we\nleverage foundation models by using them as teachers to characterize the object\nin the image, without the need of any pre-training and any dataset. The\nperformance of knowledge distillation from foundation models into a smaller\ngenerative model shows prominent results in the characterization of deformable\nobjects. The student network was capable of learning to retrieve the keypoitns\nof the object with an error of 13.4 pixels. And the teacher was evaluated based\non its capacities to retrieve pixel level information represented by the object\nmask, with a mean Intersection Over Union (mIoU) of 75.26%.",
      "tldr_zh": "该论文探讨了利用 foundation models 来表征半流体可变形物体的形状，旨在解决物体关键点检测和操作的难题，而无需依赖手动标注数据。研究提出两种方法：第一种通过 teacher-student 框架训练生成模型来表征流体可变形物体；第二种直接使用 foundation models 作为老师进行 knowledge distillation 到较小生成模型，从而从图像中提取物体特征。实验结果显示，学生网络能够以13.4像素的错误率检索关键点（keypoints），而老师模型在物体掩码检测上达到75.26%的mIoU，证明了该方法在高效表征可变形物体方面的显著效果。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16802v1",
      "published_date": "2024-11-25 13:41:35 UTC",
      "updated_date": "2024-11-25 13:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:18:00.688751"
    },
    {
      "arxiv_id": "2411.16380v1",
      "title": "Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Yuncheng Jiang",
        "Chun-Mei Feng",
        "Jinke Ren",
        "Jun Wei",
        "Zixun Zhang",
        "Yiwen Hu",
        "Yunbi Liu",
        "Rui Sun",
        "Xuemei Tang",
        "Juan Du",
        "Xiang Wan",
        "Yong Xu",
        "Bo Du",
        "Xin Gao",
        "Guangyu Wang",
        "Shaohua Zhou",
        "Shuguang Cui",
        "Rick Siow Mong Goh",
        "Yong Liu",
        "Zhen Li"
      ],
      "abstract": "Ultrasound imaging is widely used in clinical diagnosis due to its\nnon-invasive nature and real-time capabilities. However, conventional\nultrasound diagnostics face several limitations, including high dependence on\nphysician expertise and suboptimal image quality, which complicates\ninterpretation and increases the likelihood of diagnostic errors. Artificial\nintelligence (AI) has emerged as a promising solution to enhance clinical\ndiagnosis, particularly in detecting abnormalities across various biomedical\nimaging modalities. Nonetheless, current AI models for ultrasound imaging face\ncritical challenges. First, these models often require large volumes of labeled\nmedical data, raising concerns over patient privacy breaches. Second, most\nexisting models are task-specific, which restricts their broader clinical\nutility. To overcome these challenges, we present UltraFedFM, an innovative\nprivacy-preserving ultrasound foundation model. UltraFedFM is collaboratively\npre-trained using federated learning across 16 distributed medical institutions\nin 9 countries, leveraging a dataset of over 1 million ultrasound images\ncovering 19 organs and 10 ultrasound modalities. This extensive and diverse\ndata, combined with a secure training framework, enables UltraFedFM to exhibit\nstrong generalization and diagnostic capabilities. It achieves an average area\nunder the receiver operating characteristic curve of 0.927 for disease\ndiagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.\nNotably, UltraFedFM surpasses the diagnostic accuracy of mid-level\nultrasonographers and matches the performance of expert-level sonographers in\nthe joint diagnosis of 8 common systemic diseases. These findings indicate that\nUltraFedFM can significantly enhance clinical diagnostics while safeguarding\npatient privacy, marking an advancement in AI-driven ultrasound imaging for\nfuture clinical applications.",
      "tldr_zh": "该研究针对超声成像诊断的依赖专家经验和隐私风险问题，提出了一种隐私保护的联邦学习（Federated Learning）框架——UltraFedFM，作为通用超声人工智能基础模型。UltraFedFM 通过在16个分布于9个国家的医疗机构上协作预训练，运用超过100万张图像的数据集，覆盖19个器官和10种超声模式，从而实现强大的泛化能力。实验结果显示，该模型在疾病诊断中平均ROC曲线面积达0.927，在病变分割中Dice相似系数为0.878，并超越中级超声师水平，在8种常见系统疾病的联合诊断中匹配专家性能。这些进展标志着UltraFedFM在提升临床诊断准确性同时保护患者隐私的重大突破。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16380v1",
      "published_date": "2024-11-25 13:40:11 UTC",
      "updated_date": "2024-11-25 13:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:18:12.296945"
    },
    {
      "arxiv_id": "2411.16370v3",
      "title": "A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation",
      "title_zh": "Bayesian不确定性量化在深度概率图像分割中的综述",
      "authors": [
        "M. M. A. Valiuddin",
        "R. J. G. van Sloun",
        "C. G. A. Viviers",
        "P. H. N. de With",
        "F. van der Sommen"
      ],
      "abstract": "Advancements in image segmentation play an integral role within the broad\nscope of Deep Learning-based Computer Vision. Furthermore, their widespread\napplicability in critical real-world tasks has resulted in challenges related\nto the reliability of such algorithms. Hence, uncertainty quantification has\nbeen extensively studied within this context, enabling the expression of model\nignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to\nprevent uninformed decision-making. Due to the rapid adoption of Convolutional\nNeural Network (CNN)-based segmentation models in high-stake applications, a\nsubstantial body of research has been published on this very topic, causing its\nswift expansion into a distinct field. This work provides a comprehensive\noverview of probabilistic segmentation, by discussing fundamental concepts of\nuncertainty quantification, governing advancements in the field as well as the\napplication to various tasks. Moreover, literature on both types of\nuncertainties trace back to four key applications: (1) to quantify statistical\ninconsistencies in the annotation process due ambiguous images, (2) correlating\nprediction error with uncertainty, (3) expanding the model hypothesis space for\nbetter generalization, and (4) Active Learning. An extensive discussion follows\nthat includes an overview of utilized datasets for each of the applications and\nevaluation of the available methods. We also highlight challenges related to\narchitectures, uncertainty quantification methods, standardization and\nbenchmarking, and finally end with recommendations for future work such as\nmethods based on single forward passes and models that appropriately leverage\nvolumetric data.",
      "tldr_zh": "这篇综述论文回顾了Bayesian Uncertainty Quantification在Deep Probabilistic Image Segmentation中的应用，重点讨论了epistemic uncertainty（模型无知）和aleatoric uncertainty（数据模糊）如何提升图像分割算法的可靠性。论文分析了这些不确定性在四个关键领域的作用：量化标注过程的不一致、将预测错误与不确定性相关联、扩展模型假设空间以改善泛化能力，以及应用于Active Learning。最终，它总结了常用数据集、评估方法以及挑战，如架构设计和标准化问题，并建议未来工作聚焦于单前向传递方法和利用体数据（volumetric data）的模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, revised",
      "pdf_url": "http://arxiv.org/pdf/2411.16370v3",
      "published_date": "2024-11-25 13:26:09 UTC",
      "updated_date": "2025-03-12 09:51:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:18:24.258174"
    },
    {
      "arxiv_id": "2411.16354v2",
      "title": "Scalable Parameter Design for Superconducting Quantum Circuits with Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Ai",
        "Yu-xi Liu"
      ],
      "abstract": "To demonstrate supremacy of quantum computing, increasingly large-scale\nsuperconducting quantum computing chips are being designed and fabricated.\nHowever, the complexity of simulating quantum systems poses a significant\nchallenge to computer-aided design of quantum chips, especially for large-scale\nchips. Harnessing the scalability of graph neural networks (GNNs), we here\npropose a parameter designing algorithm for large-scale superconducting quantum\ncircuits. The algorithm depends on the so-called 'three-stair scaling'\nmechanism, which comprises two neural-network models: an evaluator supervisedly\ntrained on small-scale circuits for applying to medium-scale circuits, and a\ndesigner unsupervisedly trained on medium-scale circuits for applying to\nlarge-scale ones. We demonstrate our algorithm in mitigating quantum crosstalk\nerrors. Frequencies for both single- and two-qubit gates (corresponding to the\nparameters of nodes and edges) are considered simultaneously. Numerical results\nindicate that the well-trained designer achieves notable advantages in\nefficiency, effectiveness, and scalability. For example, for large-scale\nsuperconducting quantum circuits consisting of around 870 qubits, our\nGNNs-based algorithm achieves 51% of the errors produced by the\nstate-of-the-art algorithm, with a time reduction from 90 min to 27 sec.\nOverall, a better-performing and more scalable algorithm for designing\nparameters of superconducting quantum chips is proposed, which initially\ndemonstrates the advantages of applying GNNs in superconducting quantum chips.",
      "tldr_zh": "该研究针对大规模超导量子电路的设计挑战，提出了一种基于Graph Neural Networks (GNNs)的可扩展参数设计算法，以应对量子系统模拟的复杂性。该算法采用“三阶缩放”机制，包括一个在小规模电路上监督训练的评估器（用于中等规模电路）和一个在中等规模电路上无监督训练的设计器（用于大规模电路），从而同时优化单量子比特和双量子比特门的频率以缓解量子串扰错误。实验结果显示，该算法在效率和有效性上表现出色，例如在约870量子比特的电路中，将错误率降低51%，并将设计时间从90分钟缩短至27秒。总体而言，此方法展示了GNNs在超导量子芯片参数设计中的优势，提升了算法的可扩展性和性能。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16354v2",
      "published_date": "2024-11-25 13:04:53 UTC",
      "updated_date": "2025-02-07 13:28:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:18:36.086258"
    },
    {
      "arxiv_id": "2411.16353v2",
      "title": "The Two-Hop Curse: LLMs trained on A$\\rightarrow$B, B$\\rightarrow$C fail to learn A$\\rightarrow$C",
      "title_zh": "翻译失败",
      "authors": [
        "Mikita Balesni",
        "Tomek Korbak",
        "Owain Evans"
      ],
      "abstract": "[Notice: This version is outdated. Recent research contradicts some key\nclaims; we are working on a major revision with more nuanced analysis. Please\nwait for the updated version.]\n  While LLMs excel at multi-hop questions (e.g. \"Who is the spouse of the\nperformer of Imagine?\") when using chain-of-thought reasoning (CoT), they\nstruggle when forced to reason internally (without CoT). Previous work on the\nsize and nature of this gap produced mixed evidence with inconclusive results.\nIn this paper, we introduce a controlled setting for investigating two-hop\nreasoning in LLMs, where the above-chance performance constitutes undeniable\nevidence for latent reasoning. We fine-tune LLMs (including Llama 3 8B Instruct\nand GPT-4o) on fictional facts and confirm that they generalize to answering\ntwo-hop questions about them using CoT. We find that models can perform latent\nreasoning when facts appear together during training or in the prompt. However,\nto our surprise, models completely fail at two-hop reasoning without CoT when\nlearned facts only appear in different documents, achieving chance-level\naccuracy and chance-level test loss. We call this complete failure to compose\nseparately learned facts the Two-Hop Curse. Moreover, we evaluate 9 frontier\nLLMs on real-world facts, finding that models completely fail at two-hop no-CoT\nreasoning for over half of question categories while maintaining partial\nsuccess with CoT across most categories. These results suggest that LLMs lack a\ngeneral capability for latent multi-hop reasoning independent of the question\ntype.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在两跳推理（A→B, B→C 无法推导出 A→C）方面的局限性，特别是当不使用链式思维推理（CoT）时。研究者通过微调模型（如 Llama 3 8B Instruct 和 GPT-4o）并使用受控设置训练虚构事实，发现模型仅在事实共同出现或提示中时能进行潜在推理，但当事实分散在不同文档中时，模型完全失败，导致随机水平准确率和损失（即 Two-Hop Curse）。在真实世界测试中，9 个前沿 LLMs 在超过一半的问题类别中无法实现无 CoT 的两跳推理，尽管 CoT 可部分成功，这表明 LLMs 缺乏独立的多跳推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16353v2",
      "published_date": "2024-11-25 13:04:28 UTC",
      "updated_date": "2025-01-06 17:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:19:17.343006"
    },
    {
      "arxiv_id": "2411.16337v1",
      "title": "Can AI grade your essays? A comparative analysis of large language models and teacher ratings in multidimensional essay scoring",
      "title_zh": "人工智能能为你的作文打分吗？ 大语言模型与教师评分在多维作文评分中的",
      "authors": [
        "Kathrin Seßler",
        "Maurice Fürstenberg",
        "Babette Bühler",
        "Enkelejda Kasneci"
      ],
      "abstract": "The manual assessment and grading of student writing is a time-consuming yet\ncritical task for teachers. Recent developments in generative AI, such as large\nlanguage models, offer potential solutions to facilitate essay-scoring tasks\nfor teachers. In our study, we evaluate the performance and reliability of both\nopen-source and closed-source LLMs in assessing German student essays,\ncomparing their evaluations to those of 37 teachers across 10 pre-defined\ncriteria (i.e., plot logic, expression). A corpus of 20 real-world essays from\nYear 7 and 8 students was analyzed using five LLMs: GPT-3.5, GPT-4, o1, LLaMA\n3-70B, and Mixtral 8x7B, aiming to provide in-depth insights into LLMs' scoring\ncapabilities. Closed-source GPT models outperform open-source models in both\ninternal consistency and alignment with human ratings, particularly excelling\nin language-related criteria. The novel o1 model outperforms all other LLMs,\nachieving Spearman's $r = .74$ with human assessments in the overall score, and\nan internal consistency of $ICC=.80$. These findings indicate that LLM-based\nassessment can be a useful tool to reduce teacher workload by supporting the\nevaluation of essays, especially with regard to language-related criteria.\nHowever, due to their tendency for higher scores, the models require further\nrefinement to better capture aspects of content quality.",
      "tldr_zh": "本研究比较了大型语言模型（LLMs）和教师在多维度作文评分中的表现，评估了GPT-3.5、GPT-4、o1、LLaMA 3-70B 和 Mixtral 8x7B 等五种模型对20篇德国七年级和八年级学生作文的评分，与37位教师基于10个标准（如情节逻辑和表达）的评估进行对比。结果显示，封闭源模型（如GPT系列）在内部一致性和与人类评分的一致性上优于开放源模型，o1模型表现最佳，整体得分与人类评估的Spearman's r达到0.74，内部一致性ICC为0.80。LLMs可作为辅助工具减轻教师工作量，尤其在语言相关标准上，但需进一步优化以更好地评估内容质量，因为它们倾向于给出较高分数。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LAK '25",
      "pdf_url": "http://arxiv.org/pdf/2411.16337v1",
      "published_date": "2024-11-25 12:33:14 UTC",
      "updated_date": "2024-11-25 12:33:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:19:29.669632"
    },
    {
      "arxiv_id": "2411.16326v2",
      "title": "Brain-like emergent properties in deep networks: impact of network architecture, datasets and training",
      "title_zh": "翻译失败",
      "authors": [
        "Niranjan Rajesh",
        "Georgin Jacob",
        "SP Arun"
      ],
      "abstract": "Despite the rapid pace at which deep networks are improving on standardized\nvision benchmarks, they are still outperformed by humans on real-world vision\ntasks. This paradoxical lack of generalization could be addressed by making\ndeep networks more brain-like. Although several benchmarks have compared the\nability of deep networks to predict brain responses to natural images, they do\nnot capture subtle but important brain-like emergent properties. To resolve\nthis issue, we report several well-known perceptual and neural emergent\nproperties that can be tested on deep networks. To evaluate how various design\nfactors impact brain-like properties, we systematically evaluated over 30\nstate-of-the-art networks with varying network architectures, training datasets\nand training regimes. Our main findings are as follows. First, network\narchitecture had the strongest impact on brain-like properties compared to\ndataset and training regime variations. Second, networks varied widely in their\nalignment to the brain with no single network outperforming all others. Taken\ntogether, our results complement existing benchmarks by revealing brain-like\nproperties that are either emergent or lacking in state-of-the-art deep\nnetworks.",
      "tldr_zh": "尽管深度网络在标准化视觉基准上表现优越，但它们在真实世界任务中仍落后于人类，因此论文探讨了通过提升 brain-like emergent properties 来改进网络设计。研究者测试了多种感知和神经 emergent properties，并系统评估了超过30个 state-of-the-art networks，比较了 network architecture、training datasets 和 training regimes 的影响。主要发现是，network architecture 对脑-like 特性的影响最大，不同网络的脑相似度差异显著，且无单一网络全面领先，这为现有基准提供了重要补充。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16326v2",
      "published_date": "2024-11-25 12:22:36 UTC",
      "updated_date": "2024-12-09 08:18:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:19:40.768005"
    },
    {
      "arxiv_id": "2411.16318v1",
      "title": "One Diffusion to Generate Them All",
      "title_zh": "翻译失败",
      "authors": [
        "Duong H. Le",
        "Tuan Pham",
        "Sangho Lee",
        "Christopher Clark",
        "Aniruddha Kembhavi",
        "Stephan Mandt",
        "Ranjay Krishna",
        "Jiasen Lu"
      ],
      "abstract": "We introduce OneDiffusion, a versatile, large-scale diffusion model that\nseamlessly supports bidirectional image synthesis and understanding across\ndiverse tasks. It enables conditional generation from inputs such as text,\ndepth, pose, layout, and semantic maps, while also handling tasks like image\ndeblurring, upscaling, and reverse processes such as depth estimation and\nsegmentation. Additionally, OneDiffusion allows for multi-view generation,\ncamera pose estimation, and instant personalization using sequential image\ninputs. Our model takes a straightforward yet effective approach by treating\nall tasks as frame sequences with varying noise scales during training,\nallowing any frame to act as a conditioning image at inference time. Our\nunified training framework removes the need for specialized architectures,\nsupports scalable multi-task training, and adapts smoothly to any resolution,\nenhancing both generalization and scalability. Experimental results demonstrate\ncompetitive performance across tasks in both generation and prediction such as\ntext-to-image, multiview generation, ID preservation, depth estimation and\ncamera pose estimation despite relatively small training dataset. Our code and\ncheckpoint are freely available at https://github.com/lehduong/OneDiffusion",
      "tldr_zh": "本研究引入了 OneDiffusion，一种多功能的大型扩散模型，能够无缝处理图像合成和理解任务，包括从文本、深度、姿态、布局和语义地图的条件生成，以及图像去模糊、上采样、多视图生成和逆向任务如深度估计与分割。模型采用统一框架，将所有任务视为帧序列并应用不同噪声级别进行训练，允许任何帧作为推理时的条件图像，从而消除专用架构的需求并提升泛化和可扩展性。尽管使用相对较小的训练数据集，实验结果显示 OneDiffusion 在文本到图像、多视图生成、ID 保留、深度估计和相机姿态估计等任务上表现出色，与基准模型竞争。开源代码和检查点可从 https://github.com/lehduong/OneDiffusion 获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "two first authors contribute equally",
      "pdf_url": "http://arxiv.org/pdf/2411.16318v1",
      "published_date": "2024-11-25 12:11:05 UTC",
      "updated_date": "2024-11-25 12:11:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:19:52.256730"
    },
    {
      "arxiv_id": "2411.16313v2",
      "title": "CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Duo Wu",
        "Jinghe Wang",
        "Yuan Meng",
        "Yanning Zhang",
        "Le Sun",
        "Zhi Wang"
      ],
      "abstract": "Utilizing large language models (LLMs) for tool planning has emerged as a\npromising avenue for developing general AI systems, where LLMs automatically\nschedule external tools (e.g. vision models) to tackle complex tasks based on\ntask descriptions. To push this paradigm toward practical applications, it is\ncrucial for LLMs to consider tool execution costs (e.g. execution time) for\ntool planning. Unfortunately, prior studies overlook the tool execution costs,\nleading to the generation of expensive plans of which the costs outweigh task\nperformance. To fill this gap, we propose the Cost-Aware Tool Planning with\nLLMs (CATP-LLM) framework, which for the first time provides a coherent design\nto empower LLMs for cost-aware tool planning. Specifically, CATP-LLM\nincorporates a tool planning language to enhance the LLM to generate\nnon-sequential plans of multiple branches for efficient concurrent tool\nexecution and cost reduction. Moreover, it further designs a cost-aware offline\nreinforcement learning algorithm to fine-tune the LLM to optimize the\nperformance-cost trade-off in tool planning. In lack of public cost-related\ndatasets, we further present OpenCATP, the first platform for cost-aware\nplanning evaluation. Experiments on OpenCATP show that CATP-LLM outperforms\nGPT-4 even when using Llama2-7B as its backbone, with the average improvement\nof 28.2%-30.2% higher plan performance and 24.7%-45.8% lower costs even on the\nchallenging planning tasks. The codes and dataset will be available at:\nhttps://github.com/duowuyms/OpenCATP-LLM.",
      "tldr_zh": "该研究提出 CATP-LLM 框架，用于增强大型语言模型 (LLMs) 在工具规划中的成本感知能力，解决现有方法忽略工具执行成本（如执行时间）导致计划效率低下的问题。CATP-LLM 引入工具规划语言，支持生成多分支非顺序计划以实现并发执行和成本降低，并设计成本感知的离线强化学习算法来微调 LLMs，优化性能与成本的权衡。此外，他们开发了 OpenCATP 平台作为首个公开评估成本感知规划的平台。实验结果表明，CATP-LLM 即使以 Llama2-7B 为基础模型，也优于 GPT-4，在计划性能上平均提升 28.2%-30.2%，并降低 24.7%-45.8% 的成本。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "In submission",
      "pdf_url": "http://arxiv.org/pdf/2411.16313v2",
      "published_date": "2024-11-25 12:05:49 UTC",
      "updated_date": "2025-04-06 15:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:20:06.967162"
    },
    {
      "arxiv_id": "2411.16305v1",
      "title": "Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Magdalena Kaiser",
        "Patrick Ernst",
        "György Szarvas"
      ],
      "abstract": "Task-oriented Dialog (ToD) systems have to solve multiple subgoals to\naccomplish user goals, whereas feedback is often obtained only at the end of\nthe dialog. In this work, we propose SUIT (SUbgoal-aware ITerative Training),\nan iterative training approach for improving ToD systems. We sample dialogs\nfrom the model we aim to improve and determine subgoals that contribute to\ndialog success using distant supervision to obtain high quality training\nsamples. We show how this data improves supervised fine-tuning or,\nalternatively, preference learning results. SUIT is able to iteratively\ngenerate more data instead of relying on fixed static sets. SUIT reaches new\nstate-of-the-art performance on a popular ToD benchmark.",
      "tldr_zh": "本研究针对任务导向对话 (ToD) 系统在处理多个子目标时反馈延迟的问题，提出了一种迭代训练方法 SUIT (SUbgoal-aware ITerative Training)。SUIT 通过从目标模型中采样对话，并使用 distant supervision 来识别有助于对话成功的相关子目标，从而生成高质量训练样本，用于 supervised fine-tuning 或 preference learning。实验结果显示，SUIT 能够迭代生成更多数据，并在流行 ToD 基准上达到新的 state-of-the-art 性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16305v1",
      "published_date": "2024-11-25 11:47:31 UTC",
      "updated_date": "2024-11-25 11:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:20:16.497718"
    },
    {
      "arxiv_id": "2412.07782v1",
      "title": "Trustworthy artificial intelligence in the energy sector: Landscape analysis and evaluation framework",
      "title_zh": "能源领域可信赖人工智能：景观分析和评估框架",
      "authors": [
        "Sotiris Pelekis",
        "Evangelos Karakolis",
        "George Lampropoulos",
        "Spiros Mouzakitis",
        "Ourania Markaki",
        "Christos Ntanos",
        "Dimitris Askounis"
      ],
      "abstract": "The present study aims to evaluate the current fuzzy landscape of Trustworthy\nAI (TAI) within the European Union (EU), with a specific focus on the energy\nsector. The analysis encompasses legal frameworks, directives, initiatives, and\nstandards like the AI Ethics Guidelines for Trustworthy AI (EGTAI), the\nAssessment List for Trustworthy AI (ALTAI), the AI act, and relevant\nCEN-CENELEC standardization efforts, as well as EU-funded projects such as\nAI4EU and SHERPA. Subsequently, we introduce a new TAI application framework,\ncalled E-TAI, tailored for energy applications, including smart grid and smart\nbuilding systems. This framework draws inspiration from EGTAI but is customized\nfor AI systems in the energy domain. It is designed for stakeholders in\nelectrical power and energy systems (EPES), including researchers, developers,\nand energy experts linked to transmission system operators, distribution system\noperators, utilities, and aggregators. These stakeholders can utilize E-TAI to\ndevelop and evaluate AI services for the energy sector with a focus on ensuring\ntrustworthiness throughout their development and iterative assessment\nprocesses.",
      "tldr_zh": "本研究评估了欧盟（EU）能源部门的可信人工智能（Trustworthy AI, TAI）的现状，包括法律框架、指导方针（如AI Ethics Guidelines for Trustworthy AI, EGTAI 和 Assessment List for Trustworthy AI, ALTAI）、AI Act 标准以及相关项目（如AI4EU 和 SHERPA）。研究分析了这些要素在能源领域的应用，并引入了一个定制化框架E-TAI，针对智能电网和智能建筑系统，基于EGTAI 进行优化。E-TAI 框架旨在帮助电力和能源系统（EPES）的利益相关者，如研究人员、开发者和运营商，在AI 服务的开发和评估过程中，确保系统的可信性和迭代改进。整体而言，此框架为能源领域的AI 应用提供了可靠的评估工具，提升了其可信度。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07782v1",
      "published_date": "2024-11-25 11:39:55 UTC",
      "updated_date": "2024-11-25 11:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:20:28.394853"
    },
    {
      "arxiv_id": "2411.16300v3",
      "title": "BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment",
      "title_zh": "BayLing 2：一种具有高效语言对齐的多语言大语言模型",
      "authors": [
        "Shaolei Zhang",
        "Kehao Zhang",
        "Qingkai Fang",
        "Shoutao Guo",
        "Yan Zhou",
        "Xiaodong Liu",
        "Yang Feng"
      ],
      "abstract": "Large language models (LLMs), with their powerful generative capabilities and\nvast knowledge, empower various tasks in everyday life. However, these\nabilities are primarily concentrated in high-resource languages, leaving\nlow-resource languages with weaker generative capabilities and relatively\nlimited knowledge. Enhancing the multilingual capabilities of LLMs is therefore\ncrucial for serving over 100 linguistic communities worldwide. An intuitive\napproach to enhance the multilingual capabilities would be to construct\ninstruction data for various languages, but constructing instruction data for\nover 100 languages is prohibitively costly. In this paper, we introduce BayLing\n2, which efficiently transfers generative capabilities and knowledge from\nhigh-resource languages to low-resource languages through language alignment.\nTo achieve this, we constructed a dataset of 3.2 million instructions,\ncomprising high-resource language instructions (Chinese and English) and\ncross-lingual instructions for 100+ languages and performed instruction tuning\nbased on the dataset to facilitate the capability transfer between languages.\nUsing Llama as the foundation model, we developed BayLing-2-7B, BayLing-2-13B,\nand BayLing-2-8B, and conducted a comprehensive evaluation of BayLing. For\nmultilingual translation across 100+ languages, BayLing shows superior\nperformance compared to open-source models of similar scale. For multilingual\nknowledge and understanding benchmarks, BayLing achieves significant\nimprovements across over 20 low-resource languages, demonstrating its\ncapability of effective knowledge transfer from high-resource to low-resource\nlanguages. Furthermore, results on English benchmarks indicate that BayLing\nmaintains high performance in highresource languages while enhancing the\nperformance in low-resource languages. Demo, homepage, code and models of\nBayLing are available.",
      "tldr_zh": "本研究提出BayLing 2，一种多语言Large Language Models (LLMs)，通过高效的language alignment，将生成能力和知识从高资源语言（如中文和英语）转移到100+低资源语言，从而提升LLMs的多语言能力。研究团队构建了320万条指令数据集，包括高资源语言指令和跨语言指令，并基于Llama基础模型进行instruction tuning，开发了BayLing-2-7B、BayLing-2-13B和BayLing-2-8B模型。实验结果显示，BayLing在多语言翻译任务上优于类似规模的开源模型，并在20多种低资源语言的知识和理解基准上实现显著改善，同时保持高资源语言的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "BayLing 2's online demo: http://nlp.ict.ac.cn/bayling/demo. BayLing\n  2's code and models: https://github.com/ictnlp/BayLing",
      "pdf_url": "http://arxiv.org/pdf/2411.16300v3",
      "published_date": "2024-11-25 11:35:08 UTC",
      "updated_date": "2024-12-19 15:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:20:41.776766"
    },
    {
      "arxiv_id": "2411.16276v1",
      "title": "The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadreza Molavi",
        "Reza Khodadadi"
      ],
      "abstract": "This paper introduces an efficient and accurate pipeline for text-dependent\nspeaker verification (TDSV), designed to address the need for high-performance\nbiometric systems. The proposed system incorporates a Fast-Conformer-based ASR\nmodule to validate speech content, filtering out Target-Wrong (TW) and\nImpostor-Wrong (IW) trials. For speaker verification, we propose a feature\nfusion approach that combines speaker embeddings extracted from wav2vec-BERT\nand ReDimNet models to create a unified speaker representation. This system\nachieves competitive results on the TDSV 2024 Challenge test set, with a\nnormalized min-DCF of 0.0452 (rank 2), highlighting its effectiveness in\nbalancing accuracy and robustness.",
      "tldr_zh": "这篇论文介绍了 SVASR 系统，一种针对文本依赖说话人验证 (TdSV) 的高效管道，旨在提升生物识别系统的性能。该系统使用 Fast-Conformer-based ASR 模块验证语音内容，过滤 Target-Wrong (TW) 和 Impostor-Wrong (IW) 试验，并通过融合 wav2vec-BERT 和 ReDimNet 模型提取的说话人嵌入来创建统一的说话人表示。在 TdSV 2024 Challenge 测试集上，SVASR 实现了 normalized min-DCF 为 0.0452 的竞争性结果（排名第二），证明了其在准确性和鲁棒性方面的平衡优势。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16276v1",
      "published_date": "2024-11-25 10:53:45 UTC",
      "updated_date": "2024-11-25 10:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:20:52.655287"
    },
    {
      "arxiv_id": "2411.16262v1",
      "title": "Probing for Consciousness in Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Mathis Immertreu",
        "Achim Schilling",
        "Andreas Maier",
        "Patrick Krauss"
      ],
      "abstract": "This study explores the potential for artificial agents to develop core\nconsciousness, as proposed by Antonio Damasio's theory of consciousness.\nAccording to Damasio, the emergence of core consciousness relies on the\nintegration of a self model, informed by representations of emotions and\nfeelings, and a world model. We hypothesize that an artificial agent, trained\nvia reinforcement learning (RL) in a virtual environment, can develop\npreliminary forms of these models as a byproduct of its primary task. The\nagent's main objective is to learn to play a video game and explore the\nenvironment. To evaluate the emergence of world and self models, we employ\nprobes-feedforward classifiers that use the activations of the trained agent's\nneural networks to predict the spatial positions of the agent itself. Our\nresults demonstrate that the agent can form rudimentary world and self models,\nsuggesting a pathway toward developing machine consciousness. This research\nprovides foundational insights into the capabilities of artificial agents in\nmirroring aspects of human consciousness, with implications for future\nadvancements in artificial intelligence.",
      "tldr_zh": "本研究基于 Antonio Damasio 的意识理论，探讨人工智能代理是否能通过强化学习（RL）在虚拟环境中发展出核心意识，包括自我模型（整合情绪和感觉表征）和世界模型。研究者训练代理以玩视频游戏和探索环境为主要任务，并使用 probes（前向分类器）分析其神经网络激活，以预测代理的空间位置。结果表明，代理形成了初步的自我和世界模型，这为机器意识的潜在发展提供了证据，并对人工智能镜像人类意识方面未来进展具有重要启示。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16262v1",
      "published_date": "2024-11-25 10:27:07 UTC",
      "updated_date": "2024-11-25 10:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:21:05.634847"
    },
    {
      "arxiv_id": "2411.16797v2",
      "title": "Enhancing Answer Reliability Through Inter-Model Consensus of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Amiri-Margavi",
        "Iman Jebellat",
        "Ehsan Jebellat",
        "Seyed Pouyan Mousavi Davoudi"
      ],
      "abstract": "We propose a collaborative framework in which multiple large language models\n-- including GPT-4-0125-preview, Meta-LLaMA-3-70B-Instruct, Claude-3-Opus, and\nGemini-1.5-Flash -- generate and answer complex, PhD-level statistical\nquestions when definitive ground truth is unavailable. Our study examines how\ninter-model consensus improves both response reliability and identifies the\nquality of the generated questions. Employing chi-square tests, Fleiss' Kappa,\nand confidence interval analysis, we quantify consensus rates and inter-rater\nagreement to assess both response precision and question quality. Key results\nindicate that Claude and GPT-4 produce well-structured, less ambiguous\nquestions with a higher inter-rater agreement, as shown by narrower confidence\nintervals and greater alignment with question-generating models. In contrast,\nGemini and LLaMA exhibit greater variability and lower reliability in question\nformulation. These findings demonstrate that collaborative interactions among\nlarge language models enhance response reliability and provide valuable\ninsights for optimizing AI-driven collaborative reasoning systems.",
      "tldr_zh": "本文提出了一种多大型语言模型(LLMs)协作框架，利用 GPT-4-0125-preview、Meta-LLaMA-3-70B-Instruct、Claude-3-Opus 和 Gemini-1.5-Flash 等模型生成并回答复杂的博士级统计问题，从而在缺乏明确事实依据时提升响应可靠性。研究通过 chi-square tests、Fleiss' Kappa 和 confidence interval analysis 等统计方法量化模型间共识率和评级者一致性，发现 Claude 和 GPT-4 生成的问题更结构化、歧义少且一致性更高，而 Gemini 和 LLaMA 显示出更大变异性和较低可靠性。这些发现证明了模型协作能增强回答精确性，并为优化 AI 驱动的协作推理系统提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.16797v2",
      "published_date": "2024-11-25 10:18:17 UTC",
      "updated_date": "2025-02-24 00:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:21:18.012903"
    },
    {
      "arxiv_id": "2411.16250v1",
      "title": "Diagnosis of diabetic retinopathy using machine learning & deep learning technique",
      "title_zh": "使用机器学习和深度学习技术的糖尿病视网膜病变诊断",
      "authors": [
        "Eric Shah",
        "Jay Patel",
        "Mr. Vishal Katheriya",
        "Parth Pataliya"
      ],
      "abstract": "Fundus images are widely used for diagnosing various eye diseases, such as\ndiabetic retinopathy, glaucoma, and age-related macular degeneration. However,\nmanual analysis of fundus images is time-consuming and prone to errors. In this\nreport, we propose a novel method for fundus detection using object detection\nand machine learning classification techniques. We use a YOLO_V8 to perform\nobject detection on fundus images and locate the regions of interest (ROIs)\nsuch as optic disc, optic cup and lesions. We then use machine learning SVM\nclassification algorithms to classify the ROIs into different DR stages based\non the presence or absence of pathological signs such as exudates,\nmicroaneurysms, and haemorrhages etc. Our method achieves 84% accuracy and\nefficiency for fundus detection and can be applied for retinal fundus disease\ntriage, especially in remote areas around the world.",
      "tldr_zh": "本文提出了一种使用机器学习和深度学习技术诊断糖尿病视网膜病变（diabetic retinopathy）的新方法，以解决手动分析眼底图像耗时且易出错的问题。方法结合 YOLO_V8 进行物体检测，定位感兴趣区域（ROIs）如视神经盘、视神经杯和病变，然后应用 SVM 分类算法基于病理迹象（如渗出物、微动脉瘤和出血）将这些区域分类为不同 DR 阶段。实验结果显示，该方法达到 84% 的准确率，并可应用于眼底疾病筛查，尤其在全球偏远地区进行快速诊断。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 11 figures, Journal Paper",
      "pdf_url": "http://arxiv.org/pdf/2411.16250v1",
      "published_date": "2024-11-25 10:09:37 UTC",
      "updated_date": "2024-11-25 10:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:21:29.618999"
    },
    {
      "arxiv_id": "2411.16206v2",
      "title": "A Simple and Efficient Approach to Batch Bayesian Optimization",
      "title_zh": "一种简单且高效的批量贝叶斯优化方法",
      "authors": [
        "Dawei Zhan",
        "Zhaoxi Zeng",
        "Shuoxiao Wei",
        "Ping Wu"
      ],
      "abstract": "Extending Bayesian optimization to batch evaluation can enable the designer\nto make the most use of parallel computing technology. However, most of current\nbatch approaches do not scale well with the batch size. That is, their\nperformances deteriorate dramatically as the batch size increases. To address\nthis issue, we propose a simple and efficient approach to extend Bayesian\noptimization to large-scale batch evaluation in this work. Different from\nexisting batch approaches, the idea of the new approach is to draw a batch of\naxis-aligned subspaces of the original problem and select one acquisition point\nfrom each subspace. To achieve this, we propose the expected subspace\nimprovement criterion to measure the amount of the improvement that a candidate\npoint can achieve within a certain axis-aligned subspace. By optimizing these\nexpected subspace improvement functions simultaneously, we can get a batch of\nquery points for parallel evaluation. Numerical experiments show that our\nproposed approach can speedup the convergence significantly when compared with\nthe sequential Bayesian optimization algorithm, and performs very competitively\nwhen compared with seven batch Bayesian optimization algorithms. A Matlab\nimplementation of the proposed approach is available at\nhttps://github.com/zhandawei/Expected_Subspace_Improvement_Batch_Bayesian_Optimization.",
      "tldr_zh": "该论文提出了一种简单高效的批量贝叶斯优化(Bayesian Optimization)方法，旨在解决现有批量方法在批次大小增加时性能急剧下降的问题。方法的核心是通过抽取原始问题中的一批轴对齐子空间，并使用期望子空间改进(Expected Subspace Improvement)标准，从每个子空间选择一个采集点，从而同时优化多个查询点进行并行评估。实验结果显示，该方法显著加速了贝叶斯优化的收敛速度，与七种现有批量算法相比表现出色，并提供了Matlab实现代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16206v2",
      "published_date": "2024-11-25 09:14:09 UTC",
      "updated_date": "2025-04-24 05:20:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:21:40.129445"
    },
    {
      "arxiv_id": "2411.16791v1",
      "title": "What can LLM tell us about cities?",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoheng Li",
        "Yaochen Wang",
        "Zhixue Song",
        "Yuqi Huang",
        "Rui Bao",
        "Guanjie Zheng",
        "Zhenhui Jessie Li"
      ],
      "abstract": "This study explores the capabilities of large language models (LLMs) in\nproviding knowledge about cities and regions on a global scale. We employ two\nmethods: directly querying the LLM for target variable values and extracting\nexplicit and implicit features from the LLM correlated with the target\nvariable. Our experiments reveal that LLMs embed a broad but varying degree of\nknowledge across global cities, with ML models trained on LLM-derived features\nconsistently leading to improved predictive accuracy. Additionally, we observe\nthat LLMs demonstrate a certain level of knowledge across global cities on all\ncontinents, but it is evident when they lack knowledge, as they tend to\ngenerate generic or random outputs for unfamiliar tasks. These findings suggest\nthat LLMs can offer new opportunities for data-driven decision-making in the\nstudy of cities.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在全球城市和地区知识方面的能力，使用直接查询目标变量值和提取显式/隐式特征的方法。实验发现，LLMs 包含广泛但不均匀的城市知识，通过基于这些特征训练的机器学习(ML)模型，能显著提高预测准确性。论文还观察到，LLMs 在所有大陆的城市知识上有一定水平，但当缺乏相关知识时，往往输出泛化或随机内容，这为城市研究的基于数据决策提供了新机会。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16791v1",
      "published_date": "2024-11-25 09:07:56 UTC",
      "updated_date": "2024-11-25 09:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:21:52.580176"
    },
    {
      "arxiv_id": "2412.00060v1",
      "title": "MOSABench: Multi-Object Sentiment Analysis Benchmark for Evaluating Multimodal Large Language Models Understanding of Complex Image",
      "title_zh": "MOSABench：多对象情感分析基准，用于评估多模态大语言模型对",
      "authors": [
        "Shezheng Song",
        "Chengxiang He",
        "Shasha Li",
        "Shan Zhao",
        "Chengyu Wang",
        "Tianwei Yan",
        "Xiaopeng Li",
        "Qian Wan",
        "Jun Ma",
        "Jie Yu",
        "Xiaoguang Mao"
      ],
      "abstract": "Multimodal large language models (MLLMs) have shown remarkable progress in\nhigh-level semantic tasks such as visual question answering, image captioning,\nand emotion recognition. However, despite advancements, there remains a lack of\nstandardized benchmarks for evaluating MLLMs performance in multi-object\nsentiment analysis, a key task in semantic understanding. To address this gap,\nwe introduce MOSABench, a novel evaluation dataset designed specifically for\nmulti-object sentiment analysis. MOSABench includes approximately 1,000 images\nwith multiple objects, requiring MLLMs to independently assess the sentiment of\neach object, thereby reflecting real-world complexities. Key innovations in\nMOSABench include distance-based target annotation, post-processing for\nevaluation to standardize outputs, and an improved scoring mechanism. Our\nexperiments reveal notable limitations in current MLLMs: while some models,\nlike mPLUG-owl and Qwen-VL2, demonstrate effective attention to\nsentiment-relevant features, others exhibit scattered focus and performance\ndeclines, especially as the spatial distance between objects increases. This\nresearch underscores the need for MLLMs to enhance accuracy in complex,\nmulti-object sentiment analysis tasks and establishes MOSABench as a\nfoundational tool for advancing sentiment analysis capabilities in MLLMs.",
      "tldr_zh": "本研究引入了 MOSABench，这是一个新的基准数据集，旨在评估多模态大语言模型(MLLMs)在多对象情感分析任务中的性能，填补了现有基准的空白。MOSABench 包含约 1000 张多对象图像，采用基于距离的目标标注、后处理标准化输出以及改进的评分机制，以模拟真实世界的复杂场景。实验结果显示，一些模型如 mPLUG-owl 和 Qwen-VL2 能有效关注情感相关特征，但整体 MLLMs 在对象间距离增大时表现下降，暴露了其理解局限性。该基准为提升 MLLMs 在复杂图像情感分析中的准确性提供了重要工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00060v1",
      "published_date": "2024-11-25 09:00:36 UTC",
      "updated_date": "2024-11-25 09:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:22:06.230344"
    },
    {
      "arxiv_id": "2411.17746v1",
      "title": "UVCG: Leveraging Temporal Consistency for Universal Video Protection",
      "title_zh": "翻译失败",
      "authors": [
        "KaiZhou Li",
        "Jindong Gu",
        "Xinchun Yu",
        "Junjie Cao",
        "Yansong Tang",
        "Xiao-Ping Zhang"
      ],
      "abstract": "The security risks of AI-driven video editing have garnered significant\nattention. Although recent studies indicate that adding perturbations to images\ncan protect them from malicious edits, directly applying image-based methods to\nperturb each frame in a video becomes ineffective, as video editing techniques\nleverage the consistency of inter-frame information to restore individually\nperturbed content. To address this challenge, we leverage the temporal\nconsistency of video content to propose a straightforward and efficient, yet\nhighly effective and broadly applicable approach, Universal Video Consistency\nGuard (UVCG). UVCG embeds the content of another video(target video) within a\nprotected video by introducing continuous, imperceptible perturbations which\nhas the ability to force the encoder of editing models to map continuous inputs\nto misaligned continuous outputs, thereby inhibiting the generation of videos\nconsistent with the intended textual prompts. Additionally leveraging\nsimilarity in perturbations between adjacent frames, we improve the\ncomputational efficiency of perturbation generation by employing a\nperturbation-reuse strategy. We applied UVCG across various versions of Latent\nDiffusion Models (LDM) and assessed its effectiveness and generalizability\nacross multiple LDM-based editing pipelines. The results confirm the\neffectiveness, transferability, and efficiency of our approach in safeguarding\nvideo content from unauthorized modifications.",
      "tldr_zh": "本研究针对AI驱动视频编辑的安全风险，提出了一种通用视频保护方法Universal Video Consistency Guard (UVCG)，通过利用视频内容的时序一致性来嵌入目标视频的扰动，从而阻止恶意编辑模型生成与预期文本提示一致的输出。UVCG引入连续的、不可察觉的perturbations，迫使编辑模型的编码器将连续输入映射到不一致的结果，同时采用perturbation-reuse策略利用相邻帧的相似性，提高计算效率。实验结果显示，该方法在多种Latent Diffusion Models (LDM)版本和编辑管道中表现出色，具有良好的有效性、transferability和效率，有效保护视频内容免受未经授权的修改。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.17746v1",
      "published_date": "2024-11-25 08:48:54 UTC",
      "updated_date": "2024-11-25 08:48:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:22:16.723792"
    },
    {
      "arxiv_id": "2411.16189v1",
      "title": "Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models",
      "title_zh": "通过第三方LLM集成增强多智能体共识：分析不确定性和缓解大语言模型中的幻觉",
      "authors": [
        "Zhihua Duan",
        "Jialin Wang"
      ],
      "abstract": "Large Language Models (LLMs) still face challenges when dealing with complex\nreasoning tasks, often resulting in hallucinations, which limit the practical\napplication of LLMs. To alleviate this issue, this paper proposes a new method\nthat integrates different LLMs to expand the knowledge boundary, reduce\ndependence on a single model, and promote in-depth debate among agents. The\nmain contributions include: 1) Introducing third-party LLMs to adjust the\nattention weights of agents through uncertainty estimation and confidence\nanalysis, optimizing consensus formation in multi-agent systems; 2) Experiments\non arithmetic datasets have validated the effectiveness of the method,\nsurpassing traditional multi-agent baselines. This research provides a new\nperspective for large models to alleviate hallucination phenomena when dealing\nwith complex tasks.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在复杂推理任务中存在的幻觉（hallucinations）问题，提出了一种新方法，通过整合第三方 LLMs 来扩展知识边界、减少对单一模型的依赖，并促进多代理系统中的深入讨论。主要贡献包括：引入第三方 LLMs 利用不确定性估计（uncertainty estimation）和置信度分析（confidence analysis）调整代理的注意力权重，从而优化共识形成。在算术数据集上的实验证明，该方法超过了传统多代理基线，为缓解 LLMs 在复杂任务中的幻觉现象提供了新视角。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16189v1",
      "published_date": "2024-11-25 08:42:33 UTC",
      "updated_date": "2024-11-25 08:42:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:22:28.398194"
    },
    {
      "arxiv_id": "2411.16785v1",
      "title": "MAGiC-SLAM: Multi-Agent Gaussian Globally Consistent SLAM",
      "title_zh": "MAGiC-SLAM：多代理高斯全局一致 SLAM",
      "authors": [
        "Vladimir Yugay",
        "Theo Gevers",
        "Martin R. Oswald"
      ],
      "abstract": "Simultaneous localization and mapping (SLAM) systems with novel view\nsynthesis capabilities are widely used in computer vision, with applications in\naugmented reality, robotics, and autonomous driving. However, existing\napproaches are limited to single-agent operation. Recent work has addressed\nthis problem using a distributed neural scene representation. Unfortunately,\nexisting methods are slow, cannot accurately render real-world data, are\nrestricted to two agents, and have limited tracking accuracy. In contrast, we\npropose a rigidly deformable 3D Gaussian-based scene representation that\ndramatically speeds up the system. However, improving tracking accuracy and\nreconstructing a globally consistent map from multiple agents remains\nchallenging due to trajectory drift and discrepancies across agents'\nobservations. Therefore, we propose new tracking and map-merging mechanisms and\nintegrate loop closure in the Gaussian-based SLAM pipeline. We evaluate\nMAGiC-SLAM on synthetic and real-world datasets and find it more accurate and\nfaster than the state of the art.",
      "tldr_zh": "这篇论文提出了 MAGiC-SLAM，一种多智能体（Multi-Agent）Gaussian-based SLAM 系统，旨在解决现有 SLAM 方法的局限性，如单智能体操作、渲染不准确和跟踪精度不足。核心创新包括采用 rigidly deformable 3D Gaussian 场景表示来加速系统，并引入新的跟踪、地图合并机制以及 loop closure 集成，以实现全局一致的地图重建。实验结果显示，MAGiC-SLAM 在合成和真实数据集上比最先进方法更准确且速度更快。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16785v1",
      "published_date": "2024-11-25 08:34:01 UTC",
      "updated_date": "2024-11-25 08:34:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:22:41.725857"
    },
    {
      "arxiv_id": "2411.16781v2",
      "title": "UniPose: A Unified Multimodal Framework for Human Pose Comprehension, Generation and Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Yiheng Li",
        "Ruibing Hou",
        "Hong Chang",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "abstract": "Human pose plays a crucial role in the digital age. While recent works have\nachieved impressive progress in understanding and generating human poses, they\noften support only a single modality of control signals and operate in\nisolation, limiting their application in real-world scenarios. This paper\npresents UniPose, a framework employing Large Language Models (LLMs) to\ncomprehend, generate, and edit human poses across various modalities, including\nimages, text, and 3D SMPL poses. Specifically, we apply a pose tokenizer to\nconvert 3D poses into discrete pose tokens, enabling seamless integration into\nthe LLM within a unified vocabulary. To further enhance the fine-grained pose\nperception capabilities, we facilitate UniPose with a mixture of visual\nencoders, among them a pose-specific visual encoder. Benefiting from a unified\nlearning strategy, UniPose effectively transfers knowledge across different\npose-relevant tasks, adapts to unseen tasks, and exhibits extended\ncapabilities. This work serves as the first attempt at building a\ngeneral-purpose framework for pose comprehension, generation, and editing.\nExtensive experiments highlight UniPose's competitive and even superior\nperformance across various pose-relevant tasks.",
      "tldr_zh": "本论文提出 UniPose，一种统一的 multimodal 框架，利用 Large Language Models (LLMs) 来处理人类姿势的理解、生成和编辑，支持图像、文本和 3D SMPL poses 等多种模态。\nUniPose 通过 pose tokenizer 将 3D 姿势转换为离散 tokens，并结合混合视觉编码器（包括姿势特定编码器），实现细粒度的姿势感知和知识在不同任务间的无缝转移。\n该框架是首个通用目的的姿势处理尝试，实验显示 UniPose 在各种姿势相关任务中表现出竞争性甚至优越的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16781v2",
      "published_date": "2024-11-25 08:06:30 UTC",
      "updated_date": "2025-03-29 03:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:22:53.588999"
    },
    {
      "arxiv_id": "2411.16173v2",
      "title": "SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Junho Kim",
        "Hyunjun Kim",
        "Hosu Lee",
        "Yong Man Ro"
      ],
      "abstract": "Despite advances in Large Multi-modal Models, applying them to long and\nuntrimmed video content remains challenging due to limitations in context\nlength and substantial memory overhead. These constraints often lead to\nsignificant information loss and reduced relevance in the model responses. With\nthe exponential growth of video data across web platforms, understanding\nlong-form video is crucial for advancing generalized intelligence. In this\npaper, we introduce SALOVA: Segment-Augmented LOng Video Assistant, a novel\nvideo-LLM framework designed to enhance the comprehension of lengthy video\ncontent through targeted retrieval process. We address two main challenges to\nachieve it: (i) We present the SceneWalk dataset, a high-quality collection of\n87.8K long videos, each densely captioned at the segment level to enable models\nto capture scene continuity and maintain rich descriptive context. (ii) We\ndevelop robust architectural designs integrating dynamic routing mechanism and\nspatio-temporal projector to efficiently retrieve and process relevant video\nsegments based on user queries. Our framework mitigates the limitations of\ncurrent video-LMMs by allowing for precise identification and retrieval of\nrelevant video segments in response to queries, thereby improving the\ncontextual relevance of the generated responses. Through extensive experiments,\nSALOVA demonstrates enhanced capability in processing complex long-form videos,\nshowing significant capability to maintain contextual integrity across extended\nsequences.",
      "tldr_zh": "本论文提出 SALOVA（Segment-Augmented Long Video Assistant），一个新型视频-LLM 框架，旨在通过针对性检索机制提升长视频分析中的上下文理解，解决 Large Multi-modal Models 在处理长视频时面临的上下文长度限制和内存开销问题。SALOVA 包括两个关键贡献：（i）构建 SceneWalk 数据集，包含 87.8K 长视频，每段密集标注以捕捉场景连续性和丰富描述；（ii）开发动态路由机制和时空投影器，用于高效检索和处理用户查询相关的视频段，从而提高响应相关性。实验结果显示，SALOVA 在处理复杂长视频时表现出色，能够维持跨长序列的上下文完整性，并显著提升模型性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://ivy-lvlm.github.io/SALOVA/",
      "pdf_url": "http://arxiv.org/pdf/2411.16173v2",
      "published_date": "2024-11-25 08:04:47 UTC",
      "updated_date": "2025-03-21 10:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:23:05.224891"
    },
    {
      "arxiv_id": "2411.16169v2",
      "title": "Local and Global Feature Attention Fusion Network for Face Recognition",
      "title_zh": "局部与全局特征注意力融合网络用于人脸识别",
      "authors": [
        "Wang Yu",
        "Wei Wei"
      ],
      "abstract": "Recognition of low-quality face images remains a challenge due to invisible\nor deformation in partial facial regions. For low-quality images dominated by\nmissing partial facial regions, local region similarity contributes more to\nface recognition (FR). Conversely, in cases dominated by local face\ndeformation, excessive attention to local regions may lead to misjudgments,\nwhile global features exhibit better robustness. However, most of the existing\nFR methods neglect the bias in feature quality of low-quality images introduced\nby different factors. To address this issue, we propose a Local and Global\nFeature Attention Fusion (LGAF) network based on feature quality. The network\nadaptively allocates attention between local and global features according to\nfeature quality and obtains more discriminative and high-quality face features\nthrough local and global information complementarity. In addition, to\neffectively obtain fine-grained information at various scales and increase the\nseparability of facial features in high-dimensional space, we introduce a\nMulti-Head Multi-Scale Local Feature Extraction (MHMS) module. Experimental\nresults demonstrate that the LGAF achieves the best average performance on $4$\nvalidation sets (CFP-FP, CPLFW, AgeDB, and CALFW), and the performance on\nTinyFace and SCFace outperforms the state-of-the-art methods (SoTA).",
      "tldr_zh": "本研究针对低质量面部图像识别的挑战（如部分区域缺失或变形），提出了一种 Local and Global Feature Attention Fusion (LGAF) 网络。该网络根据特征质量自适应分配本地和全局特征的注意力，通过本地和全局信息互补，获得更具区分性和高质量的面部特征。此外，引入 Multi-Head Multi-Scale Local Feature Extraction (MHMS) 模块，以提取多尺度细粒度信息并提升特征在高维空间的可分性。实验结果显示，LGAF 在 CFP-FP、CPLFW、AgeDB 和 CALFW 等 4 个验证集上取得最佳平均性能，并在 TinyFace 和 SCFace 上超越最先进方法 (SoTA)。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16169v2",
      "published_date": "2024-11-25 07:55:57 UTC",
      "updated_date": "2024-12-06 02:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:23:17.165611"
    },
    {
      "arxiv_id": "2412.05299v2",
      "title": "Specifications: The missing link to making the development of LLM systems an engineering discipline",
      "title_zh": "翻译失败",
      "authors": [
        "Ion Stoica",
        "Matei Zaharia",
        "Joseph Gonzalez",
        "Ken Goldberg",
        "Koushik Sen",
        "Hao Zhang",
        "Anastasios Angelopoulos",
        "Shishir G. Patil",
        "Lingjiao Chen",
        "Wei-Lin Chiang",
        "Jared Q. Davis"
      ],
      "abstract": "Despite the significant strides made by generative AI in just a few short\nyears, its future progress is constrained by the challenge of building modular\nand robust systems. This capability has been a cornerstone of past\ntechnological revolutions, which relied on combining components to create\nincreasingly sophisticated and reliable systems. Cars, airplanes, computers,\nand software consist of components-such as engines, wheels, CPUs, and\nlibraries-that can be assembled, debugged, and replaced. A key tool for\nbuilding such reliable and modular systems is specification: the precise\ndescription of the expected behavior, inputs, and outputs of each component.\nHowever, the generality of LLMs and the inherent ambiguity of natural language\nmake defining specifications for LLM-based components (e.g., agents) both a\nchallenging and urgent problem. In this paper, we discuss the progress the\nfield has made so far-through advances like structured outputs, process\nsupervision, and test-time compute-and outline several future directions for\nresearch to enable the development of modular and reliable LLM-based systems\nthrough improved specifications.",
      "tldr_zh": "这篇论文强调，尽管生成式 AI 取得了显著进展，但构建模块化和鲁棒的 LLM 系统仍是主要挑战，因为缺乏像传统工程（如汽车或软件）中那样的组件组合能力。作者指出，specifications（规范）——即对组件预期行为、输入和输出的精确描述——是使 LLM 系统发展成为工程学科的关键缺失环节。由于 LLM 的泛化性和自然语言的模糊性，定义这些规范面临困难。本文回顾了领域的最新进展，包括 structured outputs、process supervision 和 test-time compute，并概述了未来研究方向，以通过改进 specifications 实现更可靠和模块化的 LLM 系统。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.05299v2",
      "published_date": "2024-11-25 07:48:31 UTC",
      "updated_date": "2024-12-16 08:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:23:29.395144"
    },
    {
      "arxiv_id": "2411.16778v2",
      "title": "GEMeX: A Large-Scale, Groundable, and Explainable Medical VQA Benchmark for Chest X-ray Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Liu",
        "Ke Zou",
        "Liming Zhan",
        "Zexin Lu",
        "Xiaoyu Dong",
        "Yidi Chen",
        "Chengqiang Xie",
        "Jiannong Cao",
        "Xiao-Ming Wu",
        "Huazhu Fu"
      ],
      "abstract": "Medical Visual Question Answering (Med-VQA) combines computer vision and\nnatural language processing to automatically answer clinical inquiries about\nmedical images. However, current Med-VQA datasets exhibit two significant\nlimitations: (1) they often lack visual and textual explanations for answers,\nhindering comprehension for patients and junior doctors; (2) they typically\noffer a narrow range of question formats, inadequately reflecting the diverse\nrequirements in practical scenarios. These limitations pose significant\nchallenges to the development of a reliable and user-friendly Med-VQA system.\nTo address these challenges, we introduce a large-scale, Groundable, and\nExplainable Medical VQA benchmark for chest X-ray diagnosis (GEMeX), featuring\nseveral innovative components: (1) a multi-modal explainability mechanism that\noffers detailed visual and textual explanations for each question-answer pair,\nthereby enhancing answer comprehensibility; (2) four question types,\nopen-ended, closed-ended, single-choice, and multiple-choice, to better reflect\npractical needs. With 151,025 images and 1,605,575 questions, GEMeX is the\ncurrently largest chest X-ray VQA dataset. Evaluation of 12 representative\nlarge vision language models (LVLMs) on GEMeX reveals suboptimal performance,\nunderscoring the dataset's complexity. Meanwhile, we propose a strong model by\nfine-tuning an existing LVLM on the GEMeX training set. The substantial\nperformance improvement showcases the dataset's effectiveness. The benchmark is\navailable at https://www.med-vqa.com/GEMeX.",
      "tldr_zh": "这篇论文介绍了GEMeX，一种大规模、可接地（groundable）和可解释的Medical VQA基准，针对胸部X光诊断问题，解决了现有数据集缺乏视觉/文本解释和问题格式单一的局限。GEMeX包含151,025张图像和1,605,575个问题，支持开放式、封闭式、单选和多选四种问题类型，并引入多模态解释机制以提升答案的可理解性。在评估12个代表性LVLMs时，模型表现不佳，但通过在GEMeX训练集上微调现有LVLM，实现了显著性能提升，证明了该基准的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This project is available at https://www.med-vqa.com/GEMeX",
      "pdf_url": "http://arxiv.org/pdf/2411.16778v2",
      "published_date": "2024-11-25 07:36:46 UTC",
      "updated_date": "2025-03-23 03:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:23:41.946074"
    },
    {
      "arxiv_id": "2411.16158v1",
      "title": "MixPE: Quantization and Hardware Co-design for Efficient LLM Inference",
      "title_zh": "MixPE",
      "authors": [
        "Yu Zhang",
        "Mingzi Wang",
        "Lancheng Zou",
        "Wulong Liu",
        "Hui-Ling Zhen",
        "Mingxuan Yuan",
        "Bei Yu"
      ],
      "abstract": "Transformer-based large language models (LLMs) have achieved remarkable\nsuccess as model sizes continue to grow, yet their deployment remains\nchallenging due to significant computational and memory demands. Quantization\nhas emerged as a promising solution, and state-of-the-art quantization\nalgorithms for LLMs introduce the need for mixed-precision matrix\nmultiplication (mpGEMM), where lower-precision weights are multiplied with\nhigher-precision activations. Despite its benefits, current hardware\naccelerators such as GPUs and TPUs lack native support for efficient mpGEMM,\nleading to inefficient dequantization operations in the main sequential loop.\nTo address this limitation, we introduce MixPE, a specialized mixed-precision\nprocessing element designed for efficient low-bit quantization in LLM\ninference. MixPE leverages two key innovations to minimize dequantization\noverhead and unlock the full potential of low-bit quantization. First,\nrecognizing that scale and zero point are shared within each quantization\ngroup, we propose performing dequantization after per-group mpGEMM,\nsignificantly reducing dequantization overhead. Second, instead of relying on\nconventional multipliers, MixPE utilizes efficient shift\\&add operations for\nmultiplication, optimizing both computation and energy efficiency. Our\nexperimental results demonstrate that MixPE surpasses the state-of-the-art\nquantization accelerators by $2.6\\times$ speedup and $1.4\\times$ energy\nreduction.",
      "tldr_zh": "这篇论文针对Transformer-based大型语言模型(LLMs)的推理部署挑战，提出MixPE，一种量化算法与硬件协同设计的处理元素，以提升效率。MixPE的关键创新包括：在每个量化组后执行dequantization以减少开销，以及使用shift&add操作代替传统乘法来优化计算和能量消耗。实验结果表明，MixPE相较于现有量化加速器实现了2.6倍的速度提升和1.4倍的能量节省。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16158v1",
      "published_date": "2024-11-25 07:34:53 UTC",
      "updated_date": "2024-11-25 07:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:23:52.890303"
    },
    {
      "arxiv_id": "2411.16155v2",
      "title": "Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Toyotaro Suzumura",
        "Hiroki Kanezashi",
        "Shotaro Akahori"
      ],
      "abstract": "In diagnosing neurological disorders from electroencephalography (EEG) data,\nfoundation models such as Transformers have been employed to capture temporal\ndynamics. Additionally, Graph Neural Networks (GNNs) are critical for\nrepresenting the spatial relationships among EEG sensors. However, fine-tuning\nthese large-scale models for both temporal and spatial features can be\nprohibitively large in computational cost, especially under the limited\navailability of labeled EEG datasets. We propose EEG-GraphAdapter (EGA), a\nparameter-efficient fine-tuning (PEFT) approach designed to address these\nchallenges. EGA is integrated into a pre-trained temporal backbone model as a\nGNN-based module, freezing the backbone and allowing only the adapter to be\nfine-tuned. This enables the effective acquisition of EEG spatial\nrepresentations, significantly reducing computational overhead and data\nrequirements. Experimental evaluations on two healthcare-related downstream\ntasks-Major Depressive Disorder (MDD) and Abnormality Detection (TUAB)-show\nthat EGA improves performance by up to 16.1% in F1-score compared with the\nbackbone BENDR model, highlighting its potential for scalable and accurate\nEEG-based predictions.",
      "tldr_zh": "这篇论文提出了 EEG-GraphAdapter (EGA)，一种参数高效微调 (PEFT) 方法，用于优化 EEG 基础模型在诊断神经障碍时的时空特征处理。EGA 通过将 Graph Neural Networks (GNNs) 模块集成到预训练的 temporal backbone 模型中，仅微调适配器而冻结骨干网络，从而有效捕获 EEG 传感器的空间关系并降低计算成本和数据需求。在 Major Depressive Disorder (MDD) 和 Abnormality Detection (TUAB) 等下游任务上，实验结果显示 EGA 比 BENDR 模型的 F1 分数提高了高达 16.1%，证明了其在 EEG 预测中的可扩展性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted AAAI W3PHIAI-25 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2411.16155v2",
      "published_date": "2024-11-25 07:30:52 UTC",
      "updated_date": "2025-02-18 08:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:24:05.817049"
    },
    {
      "arxiv_id": "2411.16147v1",
      "title": "SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Youngjun Sim",
        "Jinsung Yoon",
        "Young-Joo Suh"
      ],
      "abstract": "One-shot voice conversion (VC) is a method that enables the transformation\nbetween any two speakers using only a single target speaker utterance. Existing\nmethods often rely on complex architectures and pre-trained speaker\nverification (SV) models to improve the fidelity of converted speech. Recent\nworks utilizing K-means quantization (KQ) with self-supervised learning (SSL)\nfeatures have proven capable of capturing content information from speech.\nHowever, they often struggle to preserve speaking variation, such as prosodic\ndetail and phonetic variation, particularly with smaller codebooks. In this\nwork, we propose a simple yet effective one-shot VC model that utilizes the\ncharacteristics of SSL features and speech attributes. Our approach addresses\nthe issue of losing speaking variation, enabling high-fidelity voice conversion\ntrained with only reconstruction losses, without requiring external speaker\nembeddings. We demonstrate the performance of our model across 6 evaluation\nmetrics, with results highlighting the benefits of the speaking variation\ncompensation method.",
      "tldr_zh": "本文提出 SKQVC，一种基于 K-Means Quantization (KQ) 和 Self-Supervised Speech Representations (SSL) 特征的 One-Shot Voice Conversion (VC) 方法，该方法通过利用 SSL 特征和语音属性的特性，解决了现有模型在保留说话变异（如 prosodic detail 和 phonetic variation）方面的不足。不同于依赖复杂架构或外部说话者嵌入的传统方法，SKQVC 仅使用重构损失进行训练，从而实现高保真度的语音转换。实验结果在 6 个评估指标上展示了模型的优异性能，突出了说话变异补偿机制的显著益处。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "68T07"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.16147v1",
      "published_date": "2024-11-25 07:14:26 UTC",
      "updated_date": "2024-11-25 07:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:24:17.496210"
    },
    {
      "arxiv_id": "2412.00059v2",
      "title": "A Learn-to-Optimize Approach for Coordinate-Wise Step Sizes for Quasi-Newton Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Lin",
        "Qingyu Song",
        "Hong Xu"
      ],
      "abstract": "Tuning step sizes is crucial for the stability and efficiency of optimization\nalgorithms. While adaptive coordinate-wise step sizes have been shown to\noutperform scalar step size in first-order methods, their use in second-order\nmethods is still under-explored and more challenging. Current approaches,\nincluding hypergradient descent and cutting plane methods, offer limited\nimprovements or encounter difficulties in second-order contexts. To address\nthese limitations, we first conduct a theoretical analysis within the\nBroyden-Fletcher-Goldfarb-Shanno (BFGS) framework, a prominent quasi-Newton\nmethod, and derive sufficient conditions for coordinate-wise step sizes that\nensure convergence and stability. Building on this theoretical foundation, we\nintroduce a novel learn-to-optimize (L2O) method that employs LSTM-based\nnetworks to learn optimal step sizes by leveraging insights from past\noptimization trajectories, while inherently respecting the derived theoretical\nguarantees. Extensive experiments demonstrate that our approach achieves\nsubstantial improvements over scalar step size methods and hypergradient\ndescent-based method, offering up to 4$\\times$ faster convergence across\ndiverse optimization tasks.",
      "tldr_zh": "本论文提出了一种基于 learn-to-optimize (L2O) 的方法，用于 Quasi-Newton Methods 中的坐标-wise 步长调整，以提升优化算法的稳定性和效率。作者首先在 Broyden-Fletcher-Goldfarb-Shanno (BFGS) 框架下进行理论分析，推导出确保收敛和稳定的步长条件，并利用 LSTM-based networks 学习从过去优化轨迹中提取的最佳步长，同时遵守这些理论保证。与现有方法如 hypergradient descent 相比，该方法在各种优化任务中实现了高达 4 倍的加速效果，显著提高了收敛速度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.00059v2",
      "published_date": "2024-11-25 07:13:59 UTC",
      "updated_date": "2025-05-19 07:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:24:28.755059"
    },
    {
      "arxiv_id": "2411.16775v1",
      "title": "Parameter Efficient Instruction Tuning: An Empirical Study",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei He"
      ],
      "abstract": "Instruction tuning has become an important step for finetuning pretrained\nlanguage models to better follow human instructions and generalize on various\ntasks. Nowadays, pretrained language models become increasingly larger, and\nfull parameter finetuning is overwhelmingly costly. Therefore, Parameter\nEfficient Finetuning (PEFT) has arisen as a cost-effective practice for\ninstruction tuning because of significantly smaller computational, memory, and\nstorage cost compared to full finetuning. Despite their widespread adaptations,\nthe vast hyperparameter spaces, the number of PEFT methods, the different focus\nof instruction tuning capabilities make disentangling the impact of each aspect\ndifficult. This study systematically investigates several representative PEFT\nmethods, surveying the effect of hyperparameter choices including training\nhyperparameters and PEFT-specific hyperparameters, how different models sizes\nand the number of instruction tasks affect the performance,\nin-task-distribution memorization and open instruction following capability.\nOur empirical study shows that only LoRA and adapter can get close to full\nfinetuning with ideal training settings. The ideal training setting includes an\nappropriate learning rate, largest LoRA rank or adapter size allowed and\ndiverse training tasks. On the other hand, LoRA and adapter suffer from\ntraining instability if such an ideal training condition is not met.\nAdditionally, LoRA requires a greater number of tasks for effective unseen task\ngeneralization, exhibit slower learning speed. Moreover, LoRA has weaker\ntask-level memorization. Lastly, LoRA and adapter fall short in complex\nreasoning, coding and long-form generation compared to finetuning in open\ninstruction tuning settings but it shows stronger capabilities compared to\nadapter.",
      "tldr_zh": "本研究通过实证分析探讨了参数高效微调 (PEFT) 在指令调优中的应用，以减少预训练语言模型的全参数微调成本。研究系统调查了 LoRA 和 adapter 等代表性 PEFT 方法的影响因素，包括训练超参数（如学习率）、PEFT 特定超参数、模型大小以及任务数量。结果显示，只有在理想设置下（如适当学习率、最大 LoRA rank 或 adapter 大小以及多样任务），LoRA 和 adapter 才能接近全微调性能；否则，它们可能出现训练不稳定，且 LoRA 在未见任务泛化、学习速度和任务记忆方面存在劣势。最后，该研究发现 PEFT 在复杂推理、编码和长形式生成上不如全微调，但 LoRA 表现优于 adapter。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.16775v1",
      "published_date": "2024-11-25 07:06:09 UTC",
      "updated_date": "2024-11-25 07:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:24:41.383569"
    },
    {
      "arxiv_id": "2411.16131v1",
      "title": "End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning",
      "title_zh": "通过条件模仿协同学习实现的自动驾驶车辆端到端转向控制",
      "authors": [
        "Mahmoud M. Kishky",
        "Hesham M. Eraqi",
        "Khaled F. Elsayed"
      ],
      "abstract": "Autonomous driving involves complex tasks such as data fusion, object and\nlane detection, behavior prediction, and path planning. As opposed to the\nmodular approach which dedicates individual subsystems to tackle each of those\ntasks, the end-to-end approach treats the problem as a single learnable task\nusing deep neural networks, reducing system complexity and minimizing\ndependency on heuristics. Conditional imitation learning (CIL) trains the\nend-to-end model to mimic a human expert considering the navigational commands\nguiding the vehicle to reach its destination, CIL adopts specialist network\nbranches dedicated to learn the driving task for each navigational command.\nNevertheless, the CIL model lacked generalization when deployed to unseen\nenvironments. This work introduces the conditional imitation co-learning (CIC)\napproach to address this issue by enabling the model to learn the relationships\nbetween CIL specialist branches via a co-learning matrix generated by gated\nhyperbolic tangent units (GTUs). Additionally, we propose posing the steering\nregression problem as classification, we use a classification-regression hybrid\nloss to bridge the gap between regression and classification, we also propose\nusing co-existence probability to consider the spatial tendency between the\nsteering classes. Our model is demonstrated to improve autonomous driving\nsuccess rate in unseen environment by 62% on average compared to the CIL\nmethod.",
      "tldr_zh": "该研究提出了一种端到-End 转向方法，用于自治车辆，通过条件模仿协同学习 (CIC) 改进传统的条件模仿学习 (CIL)，以解决模型在未见环境中的泛化问题。CIC 通过协同学习矩阵（由门控双曲正切单元 GTUs 生成）来学习 CIL 专门分支之间的关系，并将转向回归问题转化为分类任务，使用分类-回归混合损失和共存概率来考虑转向类别间的空间倾向。与 CIL 相比，该方法在未见环境中平均提高了 62% 的自治驾驶成功率。该框架简化了系统复杂性，减少了对启发式的依赖，为端到-End 自治驾驶提供了更鲁棒的解决方案。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "NCTA 2024 Best Paper Honorable Mention",
      "pdf_url": "http://arxiv.org/pdf/2411.16131v1",
      "published_date": "2024-11-25 06:37:48 UTC",
      "updated_date": "2024-11-25 06:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:24:53.240584"
    },
    {
      "arxiv_id": "2411.16128v1",
      "title": "CIA: Controllable Image Augmentation Framework Based on Stable Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Benkedadra",
        "Dany Rimez",
        "Tiffanie Godelaine",
        "Natarajan Chidambaram",
        "Hamed Razavi Khosroshahi",
        "Horacio Tellez",
        "Matei Mancas",
        "Benoit Macq",
        "Sidi Ahmed Mahmoudi"
      ],
      "abstract": "Computer vision tasks such as object detection and segmentation rely on the\navailability of extensive, accurately annotated datasets. In this work, We\npresent CIA, a modular pipeline, for (1) generating synthetic images for\ndataset augmentation using Stable Diffusion, (2) filtering out low quality\nsamples using defined quality metrics, (3) forcing the existence of specific\npatterns in generated images using accurate prompting and ControlNet. In order\nto show how CIA can be used to search for an optimal augmentation pipeline of\ntraining data, we study human object detection in a data constrained scenario,\nusing YOLOv8n on COCO and Flickr30k datasets. We have recorded significant\nimprovement using CIA-generated images, approaching the performances obtained\nwhen doubling the amount of real images in the dataset. Our findings suggest\nthat our modular framework can significantly enhance object detection systems,\nand make it possible for future research to be done on data-constrained\nscenarios. The framework is available at: github.com/multitel-ai/CIA.",
      "tldr_zh": "本研究提出 CIA 框架，这是一个基于 Stable Diffusion 的可控图像增强管道，用于生成合成图像以扩充计算机视觉数据集。框架包括三个模块：利用 Stable Diffusion 生成图像、使用质量指标过滤低质量样本，以及通过精确提示和 ControlNet 强制生成特定模式。在数据受限场景下，实验在 COCO 和 Flickr30k 数据集上使用 YOLOv8n 进行物体检测，结果显示 CIA 生成的图像显著提升了性能，几乎相当于数据集真实图像翻倍。该框架为数据约束研究提供了一个模块化工具，有助于提升物体检测系统的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16128v1",
      "published_date": "2024-11-25 06:29:51 UTC",
      "updated_date": "2024-11-25 06:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:25:05.683256"
    },
    {
      "arxiv_id": "2411.16123v1",
      "title": "Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Hangyul Yoon",
        "Doohyuk Jang",
        "Jungeun Kim",
        "Eunho Yang"
      ],
      "abstract": "Leveraging pre-trained models with tailored prompts for in-context learning\nhas proven highly effective in NLP tasks. Building on this success, recent\nstudies have applied a similar approach to the Segment Anything Model (SAM)\nwithin a ``one-shot\" framework, where only a single reference image and its\nlabel are employed. However, these methods face limitations in the medical\ndomain, primarily due to SAM's essential requirement for visual prompts and the\nover-reliance on pixel similarity for generating them. This dependency may lead\nto (1) inaccurate prompt generation and (2) clustering of point prompts,\nresulting in suboptimal outcomes. To address these challenges, we introduce\n\\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed\nfor the medical domain. Med-PerSAM uses only visual prompt engineering and\neliminates the need for additional training of the pretrained SAM or human\nintervention, owing to our novel automated prompt generation process. By\nintegrating our lightweight warping-based prompt tuning model with SAM, we\nenable the extraction and iterative refinement of visual prompts, enhancing the\nperformance of the pre-trained SAM. This advancement is particularly meaningful\nin the medical domain, where creating visual prompts poses notable challenges\nfor individuals lacking medical expertise. Our model outperforms various\nfoundational models and previous SAM-based approaches across diverse 2D medical\nimaging datasets.",
      "tldr_zh": "该研究针对Segment Anything Model (SAM)在医疗领域的局限性（如视觉提示生成不准确和点提示聚类），提出了一种新型one-shot框架Med-PerSAM。该框架仅通过视觉提示工程和轻量级的warping-based提示调优模型，与预训练的SAM整合，实现自动化提示提取和迭代精炼，无需额外训练或人工干预。Med-PerSAM特别适用于医疗图像处理，帮助非专家用户应对提示创建挑战，并在多种2D医疗图像数据集上超越了现有基础模型和SAM-based方法，显著提升了分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16123v1",
      "published_date": "2024-11-25 06:16:17 UTC",
      "updated_date": "2024-11-25 06:16:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:25:16.872858"
    },
    {
      "arxiv_id": "2411.16120v1",
      "title": "Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks",
      "title_zh": "为什么代理做出了那个决定：使用视觉掩码解释深度强化学习",
      "authors": [
        "Rui Zuo",
        "Zifan Wang",
        "Simon Khan",
        "Garrett Ethan Katz",
        "Qinru Qiu"
      ],
      "abstract": "Due to the inherent lack of transparency in deep neural networks, it is\nchallenging for deep reinforcement learning (DRL) agents to gain trust and\nacceptance from users, especially in safety-critical applications such as\nmedical diagnosis and military operations. Existing methods for explaining an\nagent's decision either require to retrain the agent using models that support\nexplanation generation or rely on perturbation-based techniques to reveal the\nsignificance of different input features in the decision making process.\nHowever, retraining the agent may compromise its integrity and performance,\nwhile perturbation-based methods have limited performance and lack knowledge\naccumulation or learning capabilities. Moreover, since each perturbation is\nperformed independently, the joint state of the perturbed inputs may not be\nphysically meaningful. To address these challenges, we introduce\n$\\textbf{VisionMask}$, a standalone explanation model trained end-to-end to\nidentify the most critical regions in the agent's visual input that can explain\nits actions. VisionMask is trained in a self-supervised manner without relying\non human-generated labels. Importantly, its training does not alter the agent\nmodel, hence preserving the agent's performance and integrity. We evaluate\nVisionMask on Super Mario Bros (SMB) and three Atari games. Compared to\nexisting methods, VisionMask achieves a 14.9% higher insertion accuracy and a\n30.08% higher F1-Score in reproducing original actions from the selected visual\nexplanations. We also present examples illustrating how VisionMask can be used\nfor counterfactual analysis.",
      "tldr_zh": "该论文针对深度强化学习 (DRL) 代理决策缺乏透明性的问题，提出了一种名为 VisionMask 的独立解释模型，通过端到端自监督训练识别代理视觉输入中最关键的区域，从而解释其行为决策。VisionMask 不需重新训练原代理模型，避免了性能损害，并解决了现有基于扰动方法的局限性，如缺乏知识积累和物理意义。实验结果显示，在 Super Mario Bros (SMB) 和三个 Atari 游戏上，VisionMask 比基线方法提升了 14.9% 的插入准确率和 30.08% 的 F1-Score，并支持反事实分析，提供更可靠的决策解释。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16120v1",
      "published_date": "2024-11-25 06:11:46 UTC",
      "updated_date": "2024-11-25 06:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:25:29.844550"
    },
    {
      "arxiv_id": "2411.16116v1",
      "title": "LLM Augmentations to support Analytical Reasoning over Multiple Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Raquib Bin Yousuf",
        "Nicholas Defelice",
        "Mandar Sharma",
        "Shengzhe Xu",
        "Naren Ramakrishnan"
      ],
      "abstract": "Building on their demonstrated ability to perform a variety of tasks, we\ninvestigate the application of large language models (LLMs) to enhance in-depth\nanalytical reasoning within the context of intelligence analysis. Intelligence\nanalysts typically work with massive dossiers to draw connections between\nseemingly unrelated entities, and uncover adversaries' plans and motives. We\nexplore if and how LLMs can be helpful to analysts for this task and develop an\narchitecture to augment the capabilities of an LLM with a memory module called\ndynamic evidence trees (DETs) to develop and track multiple investigation\nthreads. Through extensive experiments on multiple datasets, we highlight how\nLLMs, as-is, are still inadequate to support intelligence analysts and offer\nrecommendations to improve LLMs for such intricate reasoning applications.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在多文档分析推理中的应用，旨在增强情报分析人员的深入分析能力，这些分析师需处理大量文件以发现实体间的关联和对手意图。研究开发了一种架构，将LLMs与动态证据树（DETs）内存模块相结合，支持多线程调查的开发和跟踪。通过多数据集实验，证明现有LLMs仍不足以充分支持此类复杂推理，并提出改进建议以提升其在情报分析中的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "2024 IEEE International Conference on Big Data (IEEE BigData 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.16116v1",
      "published_date": "2024-11-25 06:00:42 UTC",
      "updated_date": "2024-11-25 06:00:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:25:40.469310"
    },
    {
      "arxiv_id": "2411.16111v1",
      "title": "LLMPirate: LLMs for Black-box Hardware IP Piracy",
      "title_zh": "翻译失败",
      "authors": [
        "Vasudev Gohil",
        "Matthew DeLorenzo",
        "Veera Vishwa Achuta Sai Venkat Nallam",
        "Joey See",
        "Jeyavijayan Rajendran"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has enabled the ability\nto effectively analyze and generate code nearly instantaneously, resulting in\ntheir widespread adoption in software development. Following this advancement,\nresearchers and companies have begun integrating LLMs across the hardware\ndesign and verification process. However, these highly potent LLMs can also\ninduce new attack scenarios upon security vulnerabilities across the hardware\ndevelopment process. One such attack vector that has not been explored is\nintellectual property (IP) piracy. Given that this attack can manifest as\nrewriting hardware designs to evade piracy detection, it is essential to\nthoroughly evaluate LLM capabilities in performing this task and assess the\nmitigation abilities of current IP piracy detection tools.\n  Therefore, in this work, we propose LLMPirate, the first LLM-based technique\nable to generate pirated variations of circuit designs that successfully evade\ndetection across multiple state-of-the-art piracy detection tools. We devise\nthree solutions to overcome challenges related to integration of LLMs for\nhardware circuit designs, scalability to large circuits, and effectiveness,\nresulting in an end-to-end automated, efficient, and practical formulation. We\nperform an extensive experimental evaluation of LLMPirate using eight LLMs of\nvarying sizes and capabilities and assess their performance in pirating various\ncircuit designs against four state-of-the-art, widely-used piracy detection\ntools. Our experiments demonstrate that LLMPirate is able to consistently evade\ndetection on 100% of tested circuits across every detection tool. Additionally,\nwe showcase the ramifications of LLMPirate using case studies on IBEX and\nMOR1KX processors and a GPS module, that we successfully pirate. We envision\nthat our work motivates and fosters the development of better IP piracy\ndetection tools.",
      "tldr_zh": "该研究提出 LLMPirate，一种基于 LLMs 的创新技术，用于生成硬件电路设计的盗版变体，从而成功逃避多种先进的 IP Piracy 检测工具。通过解决 LLM 与硬件设计整合、扩展性和有效性的挑战，该框架实现了端到端的自动化流程。实验评估了八个不同规模的 LLMs，在多种电路设计上测试，结果显示 LLMPirate 能 100% 逃避检测，并在 IBEX、MOR1KX 处理器和 GPS 模块的案例研究中验证了其实际影响。该工作强调了 LLM 在安全风险中的潜力，并呼吁开发更有效的 IP Piracy 检测工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by NDSS Symposium 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.16111v1",
      "published_date": "2024-11-25 05:54:06 UTC",
      "updated_date": "2024-11-25 05:54:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:25:53.472833"
    },
    {
      "arxiv_id": "2411.16105v2",
      "title": "Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Jatin Nainani",
        "Sankaran Vaidyanathan",
        "AJ Yeung",
        "Kartik Gupta",
        "David Jensen"
      ],
      "abstract": "Mechanistic interpretability aims to understand the inner workings of large\nneural networks by identifying circuits, or minimal subgraphs within the model\nthat implement algorithms responsible for performing specific tasks. These\ncircuits are typically discovered and analyzed using a narrowly defined prompt\nformat. However, given the abilities of large language models (LLMs) to\ngeneralize across various prompt formats for the same task, it remains unclear\nhow well these circuits generalize. For instance, it is unclear whether the\nmodels generalization results from reusing the same circuit components, the\ncomponents behaving differently, or the use of entirely different components.\nIn this paper, we investigate the generality of the indirect object\nidentification (IOI) circuit in GPT-2 small, which is well-studied and believed\nto implement a simple, interpretable algorithm. We evaluate its performance on\nprompt variants that challenge the assumptions of this algorithm. Our findings\nreveal that the circuit generalizes surprisingly well, reusing all of its\ncomponents and mechanisms while only adding additional input edges. Notably,\nthe circuit generalizes even to prompt variants where the original algorithm\nshould fail; we discover a mechanism that explains this which we term S2\nHacking. Our findings indicate that circuits within LLMs may be more flexible\nand general than previously recognized, underscoring the importance of studying\ncircuit generalization to better understand the broader capabilities of these\nmodels.",
      "tldr_zh": "这篇论文探讨了 Mechanistic Interpretability 中 circuits（模型中的最小子图）的适应性和泛化能力，焦点是分析大型语言模型（LLMs）如 GPT-2 small 的 indirect object identification (IOI) circuit。\n研究者通过评估该 circuit 在挑战其算法假设的提示变体上的表现，发现它能重用原有组件并仅添加额外输入边，从而实现出人意料的良好泛化。\n即使在原算法应失败的提示变体中，circuit 也能通过一种称为 S2 Hacking 的机制继续有效。\n这些发现表明，LLMs 中的 circuits 可能比之前认为的更灵活，并强调了研究 circuit 泛化以更好地理解模型整体能力的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.16105v2",
      "published_date": "2024-11-25 05:32:34 UTC",
      "updated_date": "2024-12-05 14:16:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:26:05.565846"
    },
    {
      "arxiv_id": "2411.16099v1",
      "title": "An Empirical Study of Vulnerability Detection using Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Peiheng Zhou",
        "Ming Hu",
        "Xingrun Quan",
        "Yawen Peng",
        "Xiaofei Xie",
        "Yanxin Yang",
        "Chengwei Liu",
        "Yueming Wu",
        "Mingsong Chen"
      ],
      "abstract": "Although Deep Learning (DL) methods becoming increasingly popular in\nvulnerability detection, their performance is seriously limited by insufficient\ntraining data. This is mainly because few existing software organizations can\nmaintain a complete set of high-quality samples for DL-based vulnerability\ndetection. Due to the concerns about privacy leakage, most of them are\nreluctant to share data, resulting in the data silo problem. Since enables\ncollaboratively model training without data sharing, Federated Learning (FL)\nhas been investigated as a promising means of addressing the data silo problem\nin DL-based vulnerability detection. However, since existing FL-based\nvulnerability detection methods focus on specific applications, it is still far\nunclear i) how well FL adapts to common vulnerability detection tasks and ii)\nhow to design a high-performance FL solution for a specific vulnerability\ndetection task. To answer these two questions, this paper first proposes VulFL,\nan effective evaluation framework for FL-based vulnerability detection. Then,\nbased on VulFL, this paper conducts a comprehensive study to reveal the\nunderlying capabilities of FL in dealing with different types of CWEs,\nespecially when facing various data heterogeneity scenarios. Our experimental\nresults show that, compared to independent training, FL can significantly\nimprove the detection performance of common AI models on all investigated CWEs,\nthough the performance of FL-based vulnerability detection is limited by\nheterogeneous data. To highlight the performance differences between different\nFL solutions for vulnerability detection, we extensively investigate the\nimpacts of different configuration strategies for each framework component of\nVulFL. Our study sheds light on the potential of FL in vulnerability detection,\nwhich can be used to guide the design of FL-based solutions for vulnerability\ndetection.",
      "tldr_zh": "本研究探讨了深度学习（DL）在漏洞检测中的数据不足和数据孤岛问题，提出VulFL框架，利用Federated Learning (FL)实现数据不共享的协作训练。实验结果显示，FL显著提升了AI模型在各种Common Weakness Enumerations (CWEs)上的检测性能，尽管性能受数据异质性影响。总体而言，该研究为设计高效的FL-based漏洞检测解决方案提供了指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16099v1",
      "published_date": "2024-11-25 05:21:12 UTC",
      "updated_date": "2024-11-25 05:21:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:26:16.379923"
    },
    {
      "arxiv_id": "2411.16096v1",
      "title": "ENCLIP: Ensembling and Clustering-Based Contrastive Language-Image Pretraining for Fashion Multimodal Search with Limited Data and Low-Quality Images",
      "title_zh": "翻译失败",
      "authors": [
        "Prithviraj Purushottam Naik",
        "Rohit Agarwal"
      ],
      "abstract": "Multimodal search has revolutionized the fashion industry, providing a\nseamless and intuitive way for users to discover and explore fashion items.\nBased on their preferences, style, or specific attributes, users can search for\nproducts by combining text and image information. Text-to-image searches enable\nusers to find visually similar items or describe products using natural\nlanguage. This paper presents an innovative approach called ENCLIP, for\nenhancing the performance of the Contrastive Language-Image Pretraining (CLIP)\nmodel, specifically in Multimodal Search targeted towards the domain of fashion\nintelligence. This method focuses on addressing the challenges posed by limited\ndata availability and low-quality images. This paper proposes an algorithm that\ninvolves training and ensembling multiple instances of the CLIP model, and\nleveraging clustering techniques to group similar images together. The\nexperimental findings presented in this study provide evidence of the\neffectiveness of the methodology. This approach unlocks the potential of CLIP\nin the domain of fashion intelligence, where data scarcity and image quality\nissues are prevalent. Overall, the ENCLIP method represents a valuable\ncontribution to the field of fashion intelligence and provides a practical\nsolution for optimizing the CLIP model in scenarios with limited data and\nlow-quality images.",
      "tldr_zh": "这篇论文介绍了 ENCLIP 方法，用于提升 Contrastive Language-Image Pretraining (CLIP) 模型在时尚多模态搜索中的性能，特别针对数据有限和图像质量低下的挑战。\nENCLIP 通过训练多个 CLIP 实例并进行 Ensembling 集成，以及利用 Clustering 技术对类似图像进行分组，来改善模型的准确性和鲁棒性。\n实验结果显示，该方法在时尚智能领域显著提高了搜索效果，并为数据稀缺场景提供了实用优化方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16096v1",
      "published_date": "2024-11-25 05:15:38 UTC",
      "updated_date": "2024-11-25 05:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:26:28.597770"
    },
    {
      "arxiv_id": "2411.16086v1",
      "title": "HiDP: Hierarchical DNN Partitioning for Distributed Inference on Heterogeneous Edge Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Zain Taufique",
        "Aman Vyas",
        "Antonio Miele",
        "Pasi Liljeberg",
        "Anil Kanduri"
      ],
      "abstract": "Edge inference techniques partition and distribute Deep Neural Network (DNN)\ninference tasks among multiple edge nodes for low latency inference, without\nconsidering the core-level heterogeneity of edge nodes. Further, default DNN\ninference frameworks also do not fully utilize the resources of heterogeneous\nedge nodes, resulting in higher inference latency. In this work, we propose a\nhierarchical DNN partitioning strategy (HiDP) for distributed inference on\nheterogeneous edge nodes. Our strategy hierarchically partitions DNN workloads\nat both global and local levels by considering the core-level heterogeneity of\nedge nodes. We evaluated our proposed HiDP strategy against relevant\ndistributed inference techniques over widely used DNN models on commercial edge\ndevices. On average our strategy achieved 38% lower latency, 46% lower energy,\nand 56% higher throughput in comparison with other relevant approaches.",
      "tldr_zh": "本研究针对现有边际推理技术未考虑边际节点的核心级异构性，导致DNN推理延迟增加的问题，提出了一种分层DNN分区策略HiDP，用于异构边际平台的分布式推理。HiDP通过在全局和本地级别分层分区DNN工作负载，充分利用节点异构性来优化资源分配。与相关方法相比，实验结果显示，HiDP在商用边际设备上平均降低了38%的延迟、46%的能量消耗，并提高了56%的吞吐量。总体而言，该策略为高效的分布式DNN推理提供了可行的框架。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "7 pages, 8 figures, 1 table, and 1 algorithm. The manuscript is\n  accepted to be published in 28th Design, Automation and Test in Europe\n  Conference (IEEE DATE, 2025)",
      "pdf_url": "http://arxiv.org/pdf/2411.16086v1",
      "published_date": "2024-11-25 04:40:42 UTC",
      "updated_date": "2024-11-25 04:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:26:40.202877"
    },
    {
      "arxiv_id": "2411.16085v3",
      "title": "Cautious Optimizers: Improving Training with One Line of Code",
      "title_zh": "翻译失败",
      "authors": [
        "Kaizhao Liang",
        "Lizhang Chen",
        "Bo Liu",
        "Qiang Liu"
      ],
      "abstract": "AdamW has been the default optimizer for transformer pretraining. For many\nyears, our community searched for faster and more stable optimizers with only\nconstrained positive outcomes. In this work, we propose a single-line\nmodification in Pytorch to any momentum-based optimizer, which we rename\ncautious optimizer, e.g. C-AdamW and C-Lion. Our theoretical result shows that\nthis modification preserves Adam's Hamiltonian function and it does not break\nthe convergence guarantee under the Lyapunov analysis. In addition, a whole new\nfamily of optimizers is revealed by our theoretical insight. Among them, we\npick the simplest one for empirical experiments, showing not only speed-up on\nLlama and MAE pretraining up to $1.47$ times, but also better results in LLM\npost-training tasks. Code is available at\nhttps://github.com/kyleliang919/C-Optim.",
      "tldr_zh": "该研究提出了一种简单的单行代码修改，针对基于动量的优化器（如 AdamW）创建了 cautious optimizers（例如 C-AdamW 和 C-Lion），旨在提升模型训练效率。理论分析显示，这种修改保留了 Adam 的 Hamiltonian function，且不破坏 Lyapunov analysis 下的收敛保证，同时揭示了一个新的优化器家族。在实验中，该方法在 Llama 和 MAE 的预训练中实现了高达 1.47 倍的加速，并在 LLM 的后续训练任务中取得了更好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.DM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16085v3",
      "published_date": "2024-11-25 04:36:01 UTC",
      "updated_date": "2025-01-31 13:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:26:52.998419"
    },
    {
      "arxiv_id": "2411.16084v1",
      "title": "Deciphering genomic codes using advanced NLP techniques: a scoping review",
      "title_zh": "使用先进自然语言处理技术解码基因组密码：一项范围综述",
      "authors": [
        "Shuyan Cheng",
        "Yishu Wei",
        "Yiliang Zhou",
        "Zihan Xu",
        "Drew N Wright",
        "Jinze Liu",
        "Yifan Peng"
      ],
      "abstract": "Objectives: The vast and complex nature of human genomic sequencing data\npresents challenges for effective analysis. This review aims to investigate the\napplication of Natural Language Processing (NLP) techniques, particularly Large\nLanguage Models (LLMs) and transformer architectures, in deciphering genomic\ncodes, focusing on tokenization, transformer models, and regulatory annotation\nprediction. The goal of this review is to assess data and model accessibility\nin the most recent literature, gaining a better understanding of the existing\ncapabilities and constraints of these tools in processing genomic sequencing\ndata.\n  Methods: Following Preferred Reporting Items for Systematic Reviews and\nMeta-Analyses (PRISMA) guidelines, our scoping review was conducted across\nPubMed, Medline, Scopus, Web of Science, Embase, and ACM Digital Library.\nStudies were included if they focused on NLP methodologies applied to genomic\nsequencing data analysis, without restrictions on publication date or article\ntype.\n  Results: A total of 26 studies published between 2021 and April 2024 were\nselected for review. The review highlights that tokenization and transformer\nmodels enhance the processing and understanding of genomic data, with\napplications in predicting regulatory annotations like transcription-factor\nbinding sites and chromatin accessibility.\n  Discussion: The application of NLP and LLMs to genomic sequencing data\ninterpretation is a promising field that can help streamline the processing of\nlarge-scale genomic data while also providing a better understanding of its\ncomplex structures. It has the potential to drive advancements in personalized\nmedicine by offering more efficient and scalable solutions for genomic\nanalysis. Further research is also needed to discuss and overcome current\nlimitations, enhancing model transparency and applicability.",
      "tldr_zh": "这篇综述探讨了使用 Natural Language Processing (NLP) 技术，特别是 Large Language Models (LLMs) 和 transformer 架构，来解读基因组数据的应用，焦点包括 tokenization、transformer 模型以及 regulatory annotation prediction，以评估数据和模型的可访问性及其优势与限制。研究者遵循 PRISMA 指南，在多个数据库中进行文献检索，共选取了 26 篇 2021-2024 年的相关研究。结果显示，这些 NLP 方法显著提升了基因组数据的处理和理解能力，例如在预测 transcription-factor binding sites 和 chromatin accessibility 等方面。综述强调，这种技术有望推动个性化医学的发展，但需进一步研究来克服模型透明度和适用性的挑战。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16084v1",
      "published_date": "2024-11-25 04:35:56 UTC",
      "updated_date": "2024-11-25 04:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:27:05.235042"
    },
    {
      "arxiv_id": "2411.16080v1",
      "title": "Boosting 3D Object Generation through PBR Materials",
      "title_zh": "翻译失败",
      "authors": [
        "Yitong Wang",
        "Xudong Xu",
        "Li Ma",
        "Haoran Wang",
        "Bo Dai"
      ],
      "abstract": "Automatic 3D content creation has gained increasing attention recently, due\nto its potential in various applications such as video games, film industry,\nand AR/VR. Recent advancements in diffusion models and multimodal models have\nnotably improved the quality and efficiency of 3D object generation given a\nsingle RGB image. However, 3D objects generated even by state-of-the-art\nmethods are still unsatisfactory compared to human-created assets. Considering\nonly textures instead of materials makes these methods encounter challenges in\nphoto-realistic rendering, relighting, and flexible appearance editing. And\nthey also suffer from severe misalignment between geometry and high-frequency\ntexture details. In this work, we propose a novel approach to boost the quality\nof generated 3D objects from the perspective of Physics-Based Rendering (PBR)\nmaterials. By analyzing the components of PBR materials, we choose to consider\nalbedo, roughness, metalness, and bump maps. For albedo and bump maps, we\nleverage Stable Diffusion fine-tuned on synthetic data to extract these values,\nwith novel usages of these fine-tuned models to obtain 3D consistent albedo UV\nand bump UV for generated objects. In terms of roughness and metalness maps, we\nadopt a semi-automatic process to provide room for interactive adjustment,\nwhich we believe is more practical. Extensive experiments demonstrate that our\nmodel is generally beneficial for various state-of-the-art generation methods,\nsignificantly boosting the quality and realism of their generated 3D objects,\nwith natural relighting effects and substantially improved geometry.",
      "tldr_zh": "本研究针对现有3D对象生成方法在光照渲染和外观编辑中存在的缺陷（如仅使用纹理导致的几何与纹理不匹配问题），提出了一种基于Physics-Based Rendering (PBR)材料的提升框架。方法包括利用在合成数据上微调的Stable Diffusion模型提取albedo和bump maps，以确保3D一致性；同时，通过半自动过程处理roughness和metalness maps，允许用户交互调整。实验结果显示，该框架显著提高了多种状态-of-the-art生成方法的输出质量和真实性，实现自然relighting效果并改善几何结构。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to SIGGRAPH Asia 2024 Conference Papers",
      "pdf_url": "http://arxiv.org/pdf/2411.16080v1",
      "published_date": "2024-11-25 04:20:52 UTC",
      "updated_date": "2024-11-25 04:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:27:17.144900"
    },
    {
      "arxiv_id": "2411.16079v1",
      "title": "Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Donggeun Ko",
        "Dongjun Lee",
        "Namjun Park",
        "Wonkyeong Shim",
        "Jaekwang Kim"
      ],
      "abstract": "Neural networks struggle with image classification when biases are learned\nand misleads correlations, affecting their generalization and performance.\nPrevious methods require attribute labels (e.g. background, color) or utilizes\nGenerative Adversarial Networks (GANs) to mitigate biases. We introduce\nDiffuBias, a novel pipeline for text-to-image generation that enhances\nclassifier robustness by generating bias-conflict samples, without requiring\ntraining during the generation phase. Utilizing pretrained diffusion and image\ncaptioning models, DiffuBias generates images that challenge the biases of\nclassifiers, using the top-$K$ losses from a biased classifier ($f_B$) to\ncreate more representative data samples. This method not only debiases\neffectively but also boosts classifier generalization capabilities. To the best\nof our knowledge, DiffuBias is the first approach leveraging a stable diffusion\nmodel to generate bias-conflict samples in debiasing tasks. Our comprehensive\nexperimental evaluations demonstrate that DiffuBias achieves state-of-the-art\nperformance on benchmark datasets. We also conduct a comparative analysis of\nvarious generative models in terms of carbon emissions and energy consumption\nto highlight the significance of computational efficiency.",
      "tldr_zh": "这篇论文提出 DiffuBias，一种新型文本到图像生成管道，利用预训练的扩散模型和图像字幕模型，通过基于偏置分类器（$f_B$）的 top-$K$ 损失生成偏见冲突样本，从而增强分类器的鲁棒性和泛化能力，而无需生成阶段的训练。不同于以往依赖属性标签或 Generative Adversarial Networks (GANs) 的方法，DiffuBias 是首个使用稳定扩散模型来创建此类样本的框架。实验结果显示，该方法在基准数据集上实现了最先进性能，同时通过比较各种生成模型的碳排放和能源消耗，突出了计算效率的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages + Appendix",
      "pdf_url": "http://arxiv.org/pdf/2411.16079v1",
      "published_date": "2024-11-25 04:11:16 UTC",
      "updated_date": "2024-11-25 04:11:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:27:29.772852"
    },
    {
      "arxiv_id": "2411.16075v2",
      "title": "The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum",
      "title_zh": "翻译失败",
      "authors": [
        "Shogo Ohmae",
        "Keiko Ohmae"
      ],
      "abstract": "AI's significant recent advances using general-purpose circuit computations\noffer a potential window into how the neocortex and cerebellum of the brain are\nable to achieve a diverse range of functions across sensory, cognitive, and\nmotor domains, despite their uniform circuit structures. However, comparing the\nbrain and AI is challenging unless clear similarities exist, and past reviews\nhave been limited to comparison of brain-inspired vision AI and the visual\nneocortex. Here, to enable comparisons across diverse functional domains, we\nsubdivide circuit computation into three elements -- circuit structure,\ninput/outputs, and the learning algorithm -- and evaluate the similarities for\neach element. With this novel approach, we identify wide-ranging similarities\nand convergent evolution in the brain and AI, providing new insights into key\nconcepts in neuroscience. Furthermore, inspired by processing mechanisms of AI,\nwe propose a new theory that integrates established neuroscience theories,\nparticularly the theories of internal models and the mirror neuron system. Both\nthe neocortex and cerebellum predict future world events from past information\nand learn from prediction errors, thereby acquiring models of the world. These\nmodels enable three core processes: (1) Prediction -- generating future\ninformation, (2) Understanding -- interpreting the external world via\ncompressed and abstracted sensory information, and (3) Generation --\nrepurposing the future-information generation mechanism to produce other types\nof outputs. The universal application of these processes underlies the ability\nof the neocortex and cerebellum to accomplish diverse functions with uniform\ncircuits. Our systematic approach, insights, and theory promise groundbreaking\nadvances in understanding the brain.",
      "tldr_zh": "本文比较大脑新皮层和 cerebellum 与 AI 的电路计算，强调尽管结构统一，它们如何通过世界模型实现多样功能。作者将电路计算细分为电路结构、输入/输出和学习算法，识别出大脑和 AI 在这些元素上的广泛相似性，包括收敛进化。基于此，提出新理论整合内部模型和镜像神经元系统理论，解释新皮层和 cerebellum 通过预测未来事件、从错误中学习以及支持预测、理解和生成的核心过程，来实现跨感官、认知和运动领域的功能。该理论有望推动神经科学领域的突破性进展。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16075v2",
      "published_date": "2024-11-25 04:05:43 UTC",
      "updated_date": "2024-11-29 10:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:27:40.923268"
    },
    {
      "arxiv_id": "2411.16767v2",
      "title": "Background-Aware Defect Generation for Robust Industrial Anomaly Detection",
      "title_zh": "背景感知缺陷生成用于鲁棒工业异常检测",
      "authors": [
        "Youngjae Cho",
        "Gwangyeol Kim",
        "Sirojbek Safarov",
        "Seongdeok Bang",
        "Jaewoo Park"
      ],
      "abstract": "Detecting anomalies in industrial settings is challenging due to the scarcity\nof labeled anomalous data. Generative models can mitigate this issue by\nsynthesizing realistic defect samples, but existing approaches often fail to\nmodel the crucial interplay between defects and their background. This\noversight leads to unrealistic anomalies, especially in scenarios where\ncontextual consistency is essential (i.e., logical anomaly). To address this,\nwe propose a novel background-aware defect generation framework, where the\nbackground influences defect denoising without affecting the background itself\nby ensuring realistic synthesis while preserving structural integrity. Our\nmethod leverages a disentanglement loss to separate the background' s denoising\nprocess from the defect, enabling controlled defect synthesis through DDIM\nInversion. We theoretically demonstrate that our approach maintains background\nfidelity while generating contextually accurate defects. Extensive experiments\non MVTec AD and MVTec Loco benchmarks validate our mehtod's superiority over\nexisting techniques in both defect generation quality and anomaly detection\nperformance.",
      "tldr_zh": "本研究针对工业异常检测中异常数据稀缺的问题，提出了一种背景感知缺陷生成框架（background-aware defect generation），以解决现有生成模型忽略缺陷与背景互动导致的不真实异常。框架通过 disentanglement loss 分离背景的去噪过程和缺陷生成，利用 DDIM Inversion 实现可控的缺陷合成，同时理论证明了其能保持背景保真度并生成上下文准确的缺陷。在 MVTec AD 和 MVTec Loco 基准上的实验显示，该方法在缺陷生成质量和异常检测性能上均优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.16767v2",
      "published_date": "2024-11-25 04:05:11 UTC",
      "updated_date": "2025-02-28 09:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:27:52.837296"
    },
    {
      "arxiv_id": "2411.16073v1",
      "title": "Soft-TransFormers for Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haeyong Kang",
        "Chang D. Yoo"
      ],
      "abstract": "Inspired by Well-initialized Lottery Ticket Hypothesis (WLTH), which provides\nsuboptimal fine-tuning solutions, we propose a novel fully fine-tuned continual\nlearning (CL) method referred to as Soft-TransFormers (Soft-TF). Soft-TF\nsequentially learns and selects an optimal soft-network or subnetwork for each\ntask. During sequential training in CL, Soft-TF jointly optimizes the weights\nof sparse layers to obtain task-adaptive soft (real-valued) networks or\nsubnetworks (binary masks), while keeping the well-pre-trained layer parameters\nfrozen. In inference, the identified task-adaptive network of Soft-TF masks the\nparameters of the pre-trained network, mapping to an optimal solution for each\ntask and minimizing Catastrophic Forgetting (CF) - the soft-masking preserves\nthe knowledge of the pre-trained network. Extensive experiments on Vision\nTransformer (ViT) and CLIP demonstrate the effectiveness of Soft-TF, achieving\nstate-of-the-art performance across various CL scenarios, including\nClass-Incremental Learning (CIL) and Task-Incremental Learning (TIL), supported\nby convergence theory.",
      "tldr_zh": "本研究受 Well-initialized Lottery Ticket Hypothesis (WLTH) 启发，提出了一种新型完全微调的 Continual Learning (CL) 方法，名为 Soft-TransFormers (Soft-TF)，该方法通过顺序学习并选择每个任务的最佳软网络或子网络来优化训练过程。Soft-TF 在 CL 的顺序训练中联合优化稀疏层的权重，同时冻结预训练层参数，并使用软掩码机制最小化 Catastrophic Forgetting (CF)，从而保留先前知识。在 Vision Transformer (ViT) 和 CLIP 上进行的实验表明，Soft-TF 在 Class-Incremental Learning (CIL) 和 Task-Incremental Learning (TIL) 等场景中实现了最先进性能，并得到了收敛理论的支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16073v1",
      "published_date": "2024-11-25 03:52:47 UTC",
      "updated_date": "2024-11-25 03:52:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:28:06.906765"
    },
    {
      "arxiv_id": "2411.16053v2",
      "title": "UnitedVLN: Generalizable Gaussian Splatting for Continuous Vision-Language Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Guangzhao Dai",
        "Jian Zhao",
        "Yuantao Chen",
        "Yusen Qin",
        "Hao Zhao",
        "Guosen Xie",
        "Yazhou Yao",
        "Xiangbo Shu",
        "Xuelong Li"
      ],
      "abstract": "Vision-and-Language Navigation (VLN), where an agent follows instructions to\nreach a target destination, has recently seen significant advancements. In\ncontrast to navigation in discrete environments with predefined trajectories,\nVLN in Continuous Environments (VLN-CE) presents greater challenges, as the\nagent is free to navigate any unobstructed location and is more vulnerable to\nvisual occlusions or blind spots. Recent approaches have attempted to address\nthis by imagining future environments, either through predicted future visual\nimages or semantic features, rather than relying solely on current\nobservations. However, these RGB-based and feature-based methods lack intuitive\nappearance-level information or high-level semantic complexity crucial for\neffective navigation. To overcome these limitations, we introduce a novel,\ngeneralizable 3DGS-based pre-training paradigm, called UnitedVLN, which enables\nagents to better explore future environments by unitedly rendering\nhigh-fidelity 360 visual images and semantic features. UnitedVLN employs two\nkey schemes: search-then-query sampling and separate-then-united rendering,\nwhich facilitate efficient exploitation of neural primitives, helping to\nintegrate both appearance and semantic information for more robust navigation.\nExtensive experiments demonstrate that UnitedVLN outperforms state-of-the-art\nmethods on existing VLN-CE benchmarks.",
      "tldr_zh": "这篇论文针对 Vision-and-Language Navigation (VLN) 在连续环境 (VLN-CE) 中的挑战，如视觉遮挡和盲点问题，提出了一种新型的通用预训练框架 UnitedVLN。UnitedVLN 基于 Gaussian Splatting (3DGS) 技术，通过统一渲染高保真 360 度视觉图像和语义特征，帮助代理更好地预测和探索未来环境。该框架引入 search-then-query sampling 和 separate-then-united rendering 两个关键方案，以高效整合外观级信息和高阶语义复杂性。实验结果表明，UnitedVLN 在现有 VLN-CE 基准上优于最先进的方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16053v2",
      "published_date": "2024-11-25 02:44:59 UTC",
      "updated_date": "2025-03-16 10:43:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:28:18.034234"
    },
    {
      "arxiv_id": "2411.16027v2",
      "title": "From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events",
      "title_zh": "从行车记录仪视频到驾驶模拟：针对稀有事件的自动驾驶车辆压力测试",
      "authors": [
        "Yan Miao",
        "Georgios Fainekos",
        "Bardh Hoxha",
        "Hideki Okamoto",
        "Danil Prokhorov",
        "Sayan Mitra"
      ],
      "abstract": "Testing Automated Driving Systems (ADS) in simulation with realistic driving\nscenarios is important for verifying their performance. However, converting\nreal-world driving videos into simulation scenarios is a significant challenge\ndue to the complexity of interpreting high-dimensional video data and the\ntime-consuming nature of precise manual scenario reconstruction. In this work,\nwe propose a novel framework that automates the conversion of real-world car\ncrash videos into detailed simulation scenarios for ADS testing. Our approach\nleverages prompt-engineered Video Language Models(VLM) to transform dashcam\nfootage into SCENIC scripts, which define the environment and driving behaviors\nin the CARLA simulator, enabling the generation of realistic simulation\nscenarios. Importantly, rather than solely aiming for one-to-one scenario\nreconstruction, our framework focuses on capturing the essential driving\nbehaviors from the original video while offering flexibility in parameters such\nas weather or road conditions to facilitate search-based testing. Additionally,\nwe introduce a similarity metric that helps iteratively refine the generated\nscenario through feedback by comparing key features of driving behaviors\nbetween the real and simulated videos. Our preliminary results demonstrate\nsubstantial time efficiency, finishing the real-to-sim conversion in minutes\nwith full automation and no human intervention, while maintaining high fidelity\nto the original driving events.",
      "tldr_zh": "该研究提出了一种框架，将行车记录仪视频自动转换为模拟场景，用于测试自动驾驶系统（ADS）对罕见事件的应激响应。该框架利用提示工程的 Video Language Models (VLM) 将真实汽车碰撞视频转化为 SCENIC 脚本，并在 CARLA 模拟器中定义环境和驾驶行为，从而生成逼真的模拟场景。不同于传统的逐一重建，该方法重点捕捉视频中的关键驾驶行为，并允许灵活调整参数（如天气或道路条件）以支持基于搜索的测试。同时，引入一个相似性指标，通过比较真实和模拟视频的关键特征进行迭代优化。初步实验结果显示，该框架可在几分钟内完成全自动化转换，同时保持高保真度，提高了 ADS 测试效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.16027v2",
      "published_date": "2024-11-25 01:01:54 UTC",
      "updated_date": "2025-01-27 17:43:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T04:28:28.953182"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 107,
  "processed_papers_count": 107,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T04:28:48.637948"
}