[
  {
    "arxiv_id": "2411.16985v1",
    "title": "Teaching Smaller Language Models To Generalise To Unseen Compositional Questions (Full Thesis)",
    "authors": [
      "Tim Hartill"
    ],
    "abstract": "Pretrained large Language Models (LLMs) are able to answer questions that are\nunlikely to have been encountered during training. However a diversity of\npotential applications exist in the broad domain of reasoning systems and\nconsiderations such as latency, cost, available compute resource and internet\nconnectivity are relevant in determining an appropriate approach. We consider\nthe setting where some local compute capacity is available at inference time\nbut internet connectivity is not.\n  Similar to a general-purpose LLM, we assume that our much smaller Reasoning\nModels may be asked arbitrary questions from unknown distributions, so we focus\non evaluation in an unseen setting. We train our models to answer diverse\nquestions by instilling an ability to reason over a retrieved context. We\nacquire context from two knowledge sources; a Wikipedia corpus queried using a\nmulti-hop dense retrieval system with novel extensions, and from rationales\ngenerated from a larger Language Model optimised to run in a lower resource\nenvironment.\n  Our main contributions: We propose novel methods to show that our model is\ncapable of answering contextualised questions without memorisation. We\nestablish a comprehensive set of baseline results on unseen evaluation\ndatasets. We show that the addition of novel retrieval-augmented training\ndatasets (RATD) to the training regime of the Reasoning Model significantly\nimproves results. We demonstrate further significant improvement through the\napplication of methods for combining knowledge from two sources. The first\nmethod (RR) involves training a novel Rationale Ranking model to score both\ngenerated rationales and retrieved contexts with respect to relevance and\ntruthfulness. We use the scores to derive combined contexts. We also show that\nutilising the RATD datasets enables our model to become proficient at utilising\ncombined noisy contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16985v1",
    "published_date": "2024-11-25 23:25:34 UTC",
    "updated_date": "2024-11-25 23:25:34 UTC"
  },
  {
    "arxiv_id": "2411.16975v1",
    "title": "ExpTest: Automating Learning Rate Searching and Tuning with Insights from Linearized Neural Networks",
    "authors": [
      "Zan Chaudhry",
      "Naoko Mizuno"
    ],
    "abstract": "Hyperparameter tuning remains a significant challenge for the training of\ndeep neural networks (DNNs), requiring manual and/or time-intensive grid\nsearches, increasing resource costs and presenting a barrier to the\ndemocratization of machine learning. The global initial learning rate for DNN\ntraining is particularly important. Several techniques have been proposed for\nautomated learning rate tuning during training; however, they still require\nmanual searching for the global initial learning rate. Though methods exist\nthat do not require this initial selection, they suffer from poor performance.\nHere, we present ExpTest, a sophisticated method for initial learning rate\nsearching and subsequent learning rate tuning for the training of DNNs. ExpTest\ndraws on insights from linearized neural networks and the form of the loss\ncurve, which we treat as a real-time signal upon which we perform hypothesis\ntesting. We mathematically justify ExpTest and provide empirical support.\nExpTest requires minimal overhead, is robust to hyperparameter choice, and\nachieves state-of-the-art performance on a variety of tasks and architectures,\nwithout initial learning rate selection or learning rate scheduling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16975v1",
    "published_date": "2024-11-25 22:58:22 UTC",
    "updated_date": "2024-11-25 22:58:22 UTC"
  },
  {
    "arxiv_id": "2411.16972v1",
    "title": "Clustering Time Series Data with Gaussian Mixture Embeddings in a Graph Autoencoder Framework",
    "authors": [
      "Amirabbas Afzali",
      "Hesam Hosseini",
      "Mohmmadamin Mirzai",
      "Arash Amini"
    ],
    "abstract": "Time series data analysis is prevalent across various domains, including\nfinance, healthcare, and environmental monitoring. Traditional time series\nclustering methods often struggle to capture the complex temporal dependencies\ninherent in such data. In this paper, we propose the Variational Mixture Graph\nAutoencoder (VMGAE), a graph-based approach for time series clustering that\nleverages the structural advantages of graphs to capture enriched data\nrelationships and produces Gaussian mixture embeddings for improved\nseparability. Comparisons with baseline methods are included with experimental\nresults, demonstrating that our method significantly outperforms\nstate-of-the-art time-series clustering techniques. We further validate our\nmethod on real-world financial data, highlighting its practical applications in\nfinance. By uncovering community structures in stock markets, our method\nprovides deeper insights into stock relationships, benefiting market\nprediction, portfolio optimization, and risk management.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "First two listed authors have equal contribution. Author ordering is\n  determined by coin flip",
    "pdf_url": "http://arxiv.org/pdf/2411.16972v1",
    "published_date": "2024-11-25 22:49:01 UTC",
    "updated_date": "2024-11-25 22:49:01 UTC"
  },
  {
    "arxiv_id": "2411.16959v2",
    "title": "RoCoDA: Counterfactual Data Augmentation for Data-Efficient Robot Learning from Demonstrations",
    "authors": [
      "Ezra Ameperosa",
      "Jeremy A. Collins",
      "Mrinal Jain",
      "Animesh Garg"
    ],
    "abstract": "Imitation learning in robotics faces significant challenges in generalization\ndue to the complexity of robotic environments and the high cost of data\ncollection. We introduce RoCoDA, a novel method that unifies the concepts of\ninvariance, equivariance, and causality within a single framework to enhance\ndata augmentation for imitation learning. RoCoDA leverages causal invariance by\nmodifying task-irrelevant subsets of the environment state without affecting\nthe policy's output. Simultaneously, we exploit SE(3) equivariance by applying\nrigid body transformations to object poses and adjusting corresponding actions\nto generate synthetic demonstrations. We validate RoCoDA through extensive\nexperiments on five robotic manipulation tasks, demonstrating improvements in\npolicy performance, generalization, and sample efficiency compared to\nstate-of-the-art data augmentation methods. Our policies exhibit robust\ngeneralization to unseen object poses, textures, and the presence of\ndistractors. Furthermore, we observe emergent behavior such as re-grasping,\nindicating policies trained with RoCoDA possess a deeper understanding of task\ndynamics. By leveraging invariance, equivariance, and causality, RoCoDA\nprovides a principled approach to data augmentation in imitation learning,\nbridging the gap between geometric symmetries and causal reasoning. Project\nPage: https://rocoda.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to 2025 IEEE International Conference on Robotics and\n  Automation (ICRA)",
    "pdf_url": "http://arxiv.org/pdf/2411.16959v2",
    "published_date": "2024-11-25 21:57:15 UTC",
    "updated_date": "2025-05-20 01:17:09 UTC"
  },
  {
    "arxiv_id": "2411.16956v1",
    "title": "Contrastive Deep Learning Reveals Age Biomarkers in Histopathological Skin Biopsies",
    "authors": [
      "Kaustubh Chakradeo",
      "Pernille Nielsen",
      "Lise Mette Rahbek Gjerdrum",
      "Gry Sahl Hansen",
      "David A Duchêne",
      "Laust H Mortensen",
      "Majken K Jensen",
      "Samir Bhatt"
    ],
    "abstract": "As global life expectancy increases, so does the burden of chronic diseases,\nyet individuals exhibit considerable variability in the rate at which they age.\nIdentifying biomarkers that distinguish fast from slow ageing is crucial for\nunderstanding the biology of ageing, enabling early disease detection, and\nimproving prevention strategies. Using contrastive deep learning, we show that\nskin biopsy images alone are sufficient to determine an individual's age. We\nthen use visual features in histopathology slides of the skin biopsies to\nconstruct a novel biomarker of ageing. By linking with comprehensive health\nregisters in Denmark, we demonstrate that visual features in histopathology\nslides of skin biopsies predict mortality and the prevalence of chronic\nage-related diseases. Our work highlights how routinely collected health data\ncan provide additional value when used together with deep learning, by creating\na new biomarker for ageing which can be actively used to determine mortality\nover time.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "20 pages, 5 tables, 5 figures Under review: npj Digital Medicine",
    "pdf_url": "http://arxiv.org/pdf/2411.16956v1",
    "published_date": "2024-11-25 21:52:01 UTC",
    "updated_date": "2024-11-25 21:52:01 UTC"
  },
  {
    "arxiv_id": "2411.16954v1",
    "title": "Understanding GEMM Performance and Energy on NVIDIA Ada Lovelace: A Machine Learning-Based Analytical Approach",
    "authors": [
      "Xiaoteng",
      "Liu",
      "Pavly Halim"
    ],
    "abstract": "Analytical framework for predicting General Matrix Multiplication (GEMM)\nperformance on modern GPUs, focusing on runtime, power consumption, and energy\nefficiency. Our study employs two approaches: a custom-implemented tiled matrix\nmultiplication kernel for fundamental analysis, and NVIDIA's CUTLASS library\nfor comprehensive performance data collection across advanced configurations.\nUsing the NVIDIA RTX 4070 as our experimental platform, we developed a Random\nForest-based prediction model with multi-output regression capability. Through\nanalysis of both naive tiled matrix multiplication with varying tile sizes (1\nto 32) and 16,128 CUTLASS GEMM operations across diverse configurations, we\nidentified critical performance patterns related to matrix dimensions, thread\nblock configurations, and memory access patterns. Our framework achieved\nexceptional accuracy with an R^2 score of 0.98 for runtime prediction (mean\nerror 15.57%) and 0.78 for power prediction (median error 5.42%). The system\nsuccessfully predicts performance across matrix sizes, demonstrating robust\nscaling behavior. Our results show that optimal tile size selection can improve\nperformance by up to 3.2x while reducing power consumption by 22% compared to\nbaseline configurations. Analysis of shared memory utilization and SM occupancy\nreveals that tile sizes of 16x16 achieve the best balance between parallelism\nand resource usage. The implementation of our framework, including prediction\nmodels and analysis tools, is available as an open-source project at GPPerf\n[https://github.com/pavlyhalim/GPPerf].",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.PF",
      "68W10, 65F30",
      "I.2.6; G.1.3; G.4"
    ],
    "primary_category": "cs.DC",
    "comment": "9 pages, 9 figures, 6 tables, IEEE conference paper format",
    "pdf_url": "http://arxiv.org/pdf/2411.16954v1",
    "published_date": "2024-11-25 21:47:23 UTC",
    "updated_date": "2024-11-25 21:47:23 UTC"
  },
  {
    "arxiv_id": "2412.00064v2",
    "title": "DiffGuard: Text-Based Safety Checker for Diffusion Models",
    "authors": [
      "Massine El Khader",
      "Elias Al Bouzidi",
      "Abdellah Oumida",
      "Mohammed Sbaihi",
      "Eliott Binard",
      "Jean-Philippe Poli",
      "Wassila Ouerdane",
      "Boussad Addad",
      "Katarzyna Kapusta"
    ],
    "abstract": "Recent advances in Diffusion Models have enabled the generation of images\nfrom text, with powerful closed-source models like DALL-E and Midjourney\nleading the way. However, open-source alternatives, such as StabilityAI's\nStable Diffusion, offer comparable capabilities. These open-source models,\nhosted on Hugging Face, come equipped with ethical filter protections designed\nto prevent the generation of explicit images. This paper reveals first their\nlimitations and then presents a novel text-based safety filter that outperforms\nexisting solutions. Our research is driven by the critical need to address the\nmisuse of AI-generated content, especially in the context of information\nwarfare. DiffGuard enhances filtering efficacy, achieving a performance that\nsurpasses the best existing filters by over 14%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00064v2",
    "published_date": "2024-11-25 21:47:02 UTC",
    "updated_date": "2025-02-19 15:51:43 UTC"
  },
  {
    "arxiv_id": "2411.16936v1",
    "title": "Harnessing LLMs for Educational Content-Driven Italian Crossword Generation",
    "authors": [
      "Kamyar Zeinalipour",
      "Achille Fusco",
      "Asya Zanollo",
      "Marco Maggini",
      "Marco Gori"
    ],
    "abstract": "In this work, we unveil a novel tool for generating Italian crossword puzzles\nfrom text, utilizing advanced language models such as GPT-4o,\nMistral-7B-Instruct-v0.3, and Llama3-8b-Instruct. Crafted specifically for\neducational applications, this cutting-edge generator makes use of the\ncomprehensive Italian-Clue-Instruct dataset, which comprises over 30,000\nentries including diverse text, solutions, and types of clues. This carefully\nassembled dataset is designed to facilitate the creation of contextually\nrelevant clues in various styles associated with specific texts and keywords.\nThe study delves into four distinctive styles of crossword clues: those without\nformat constraints, those formed as definite determiner phrases, copular\nsentences, and bare noun phrases. Each style introduces unique linguistic\nstructures to diversify clue presentation. Given the lack of sophisticated\neducational tools tailored to the Italian language, this project seeks to\nenhance learning experiences and cognitive development through an engaging,\ninteractive platform. By meshing state-of-the-art AI with contemporary\neducational strategies, our tool can dynamically generate crossword puzzles\nfrom Italian educational materials, thereby providing an enjoyable and\ninteractive learning environment. This technological advancement not only\nredefines educational paradigms but also sets a new benchmark for interactive\nand cognitive language learning solutions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted for presentation at CLiC.it 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.16936v1",
    "published_date": "2024-11-25 21:13:25 UTC",
    "updated_date": "2024-11-25 21:13:25 UTC"
  },
  {
    "arxiv_id": "2412.07787v1",
    "title": "Anomaly Detection in California Electricity Price Forecasting: Enhancing Accuracy and Reliability Using Principal Component Analysis",
    "authors": [
      "Joseph Nyangon",
      "Ruth Akintunde"
    ],
    "abstract": "Accurate and reliable electricity price forecasting has significant practical\nimplications for grid management, renewable energy integration, power system\nplanning, and price volatility management. This study focuses on enhancing\nelectricity price forecasting in California's grid, addressing challenges from\ncomplex generation data and heteroskedasticity. Utilizing principal component\nanalysis (PCA), we analyze CAISO's hourly electricity prices and demand from\n2016-2021 to improve day-ahead forecasting accuracy. Initially, we apply\ntraditional outlier analysis with the interquartile range method, followed by\nrobust PCA (RPCA) for more effective outlier elimination. This approach\nimproves data symmetry and reduces skewness. We then construct multiple linear\nregression models using both raw and PCA-transformed features. The model with\ntransformed features, refined through traditional and SAS Sparse Matrix outlier\nremoval methods, shows superior forecasting performance. The SAS Sparse Matrix\nmethod, in particular, significantly enhances model accuracy. Our findings\ndemonstrate that PCA-based methods are key in advancing electricity price\nforecasting, supporting renewable integration and grid management in day-ahead\nmarkets.\n  Keywords: Electricity price forecasting, principal component analysis (PCA),\npower system planning, heteroskedasticity, renewable energy integration.",
    "categories": [
      "econ.EM",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "econ.EM",
    "comment": "5 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.07787v1",
    "published_date": "2024-11-25 20:55:25 UTC",
    "updated_date": "2024-11-25 20:55:25 UTC"
  },
  {
    "arxiv_id": "2411.16927v1",
    "title": "ASSERTIFY: Utilizing Large Language Models to Generate Assertions for Production Code",
    "authors": [
      "Mohammad Jalili Torkamani",
      "Abhinav Sharma",
      "Nikita Mehrotra",
      "Rahul Purandare"
    ],
    "abstract": "Production assertions are statements embedded in the code to help developers\nvalidate their assumptions about the code. They assist developers in debugging,\nprovide valuable documentation, and enhance code comprehension. Current\nresearch in this area primarily focuses on assertion generation for unit tests\nusing techniques, such as static analysis and deep learning. While these\ntechniques have shown promise, they fall short when it comes to generating\nproduction assertions, which serve a different purpose.\n  This preprint addresses the gap by introducing Assertify, an automated\nend-to-end tool that leverages Large Language Models (LLMs) and prompt\nengineering with few-shot learning to generate production assertions. By\ncreating context-rich prompts, the tool emulates the approach developers take\nwhen creating production assertions for their code. To evaluate our approach,\nwe compiled a dataset of 2,810 methods by scraping 22 mature Java repositories\nfrom GitHub. Our experiments demonstrate the effectiveness of few-shot learning\nby producing assertions with an average ROUGE-L score of 0.526, indicating\nreasonably high structural similarity with the assertions written by\ndevelopers. This research demonstrates the potential of LLMs in automating the\ngeneration of production assertions that resemble the original assertions.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.5; D.2.7; K.6.3"
    ],
    "primary_category": "cs.SE",
    "comment": "20 pages, 10 figures, 10 listings, 2 tables, preprint",
    "pdf_url": "http://arxiv.org/pdf/2411.16927v1",
    "published_date": "2024-11-25 20:52:28 UTC",
    "updated_date": "2024-11-25 20:52:28 UTC"
  },
  {
    "arxiv_id": "2411.16917v2",
    "title": "Are Transformers Truly Foundational for Robotics?",
    "authors": [
      "James A. R. Marshall",
      "Andrew B. Barron"
    ],
    "abstract": "Generative Pre-Trained Transformers (GPTs) are hyped to revolutionize\nrobotics. Here we question their utility. GPTs for autonomous robotics demand\nenormous and costly compute, excessive training times and (often) offboard\nwireless control. We contrast GPT state of the art with how tiny insect brains\nhave achieved robust autonomy with none of these constraints. We highlight\nlessons that can be learned from biology to enhance the utility of GPTs in\nrobotics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16917v2",
    "published_date": "2024-11-25 20:35:01 UTC",
    "updated_date": "2025-02-27 10:46:58 UTC"
  },
  {
    "arxiv_id": "2411.16905v1",
    "title": "Boundless Socratic Learning with Language Games",
    "authors": [
      "Tom Schaul"
    ],
    "abstract": "An agent trained within a closed system can master any desired capability, as\nlong as the following three conditions hold: (a) it receives sufficiently\ninformative and aligned feedback, (b) its coverage of experience/data is broad\nenough, and (c) it has sufficient capacity and resource. In this position\npaper, we justify these conditions, and consider what limitations arise from\n(a) and (b) in closed systems, when assuming that (c) is not a bottleneck.\nConsidering the special case of agents with matching input and output spaces\n(namely, language), we argue that such pure recursive self-improvement, dubbed\n\"Socratic learning\", can boost performance vastly beyond what is present in its\ninitial data or knowledge, and is only limited by time, as well as gradual\nmisalignment concerns. Furthermore, we propose a constructive framework to\nimplement it, based on the notion of language games.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16905v1",
    "published_date": "2024-11-25 20:16:16 UTC",
    "updated_date": "2024-11-25 20:16:16 UTC"
  },
  {
    "arxiv_id": "2411.16896v2",
    "title": "Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with Differential Transformer Based Deep Learning Model Incorporating Pixelwise Instrument Response Function",
    "authors": [
      "Ismail Erbas",
      "Vikas Pandey",
      "Navid Ibtehaj Nizam",
      "Nanxue Yuan",
      "Amit Verma",
      "Margarida Barosso",
      "Xavier Intes"
    ],
    "abstract": "Fluorescence Lifetime Imaging (FLI) is a critical molecular imaging modality\nthat provides unique information about the tissue microenvironment, which is\ninvaluable for biomedical applications. FLI operates by acquiring and analyzing\nphoton time-of-arrival histograms to extract quantitative parameters associated\nwith temporal fluorescence decay. These histograms are influenced by the\nintrinsic properties of the fluorophore, instrument parameters, time-of-flight\ndistributions associated with pixel-wise variations in the topographic and\noptical characteristics of the sample. Recent advancements in Deep Learning\n(DL) have enabled improved fluorescence lifetime parameter estimation. However,\nexisting models are primarily designed for planar surface samples, limiting\ntheir applicability in translational scenarios involving complex surface\nprofiles, such as \\textit{in-vivo} whole-animal or imaged guided surgical\napplications. To address this limitation, we present MFliNet (Macroscopic FLI\nNetwork), a novel DL architecture that integrates the Instrument Response\nFunction (IRF) as an additional input alongside experimental photon\ntime-of-arrival histograms. Leveraging the capabilities of a Differential\nTransformer encoder-decoder architecture, MFliNet effectively focuses on\ncritical input features, such as variations in photon time-of-arrival\ndistributions. We evaluate MFliNet using rigorously designed tissue-mimicking\nphantoms and preclinical in-vivo cancer xenograft models. Our results\ndemonstrate the model's robustness and suitability for complex macroscopic FLI\napplications, offering new opportunities for advanced biomedical imaging in\ndiverse and challenging settings.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "physics.optics"
    ],
    "primary_category": "eess.IV",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.16896v2",
    "published_date": "2024-11-25 20:03:41 UTC",
    "updated_date": "2024-12-04 19:02:23 UTC"
  },
  {
    "arxiv_id": "2412.07786v1",
    "title": "Towards Agentic Schema Refinement",
    "authors": [
      "Agapi Rissaki",
      "Ilias Fountalis",
      "Nikolaos Vasiloglou",
      "Wolfgang Gatterbauer"
    ],
    "abstract": "Large enterprise databases can be complex and messy, obscuring the data\nsemantics needed for analytical tasks. We propose a semantic layer in-between\nthe database and the user as a set of small and easy-to-interpret database\nviews, effectively acting as a refined version of the schema. To discover these\nviews, we introduce a multi-agent Large Language Model (LLM) simulation where\nLLM agents collaborate to iteratively define and refine views with minimal\ninput. Our approach paves the way for LLM-powered exploration of unwieldy\ndatabases.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "To appear at the Table Representation Learning Workshop, NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.07786v1",
    "published_date": "2024-11-25 19:57:16 UTC",
    "updated_date": "2024-11-25 19:57:16 UTC"
  },
  {
    "arxiv_id": "2411.16872v2",
    "title": "Enabling Adoption of Regenerative Agriculture through Soil Carbon Copilots",
    "authors": [
      "Margaret Capetz",
      "Swati Sharma",
      "Rafael Padilha",
      "Peder Olsen",
      "Jessica Wolk",
      "Emre Kiciman",
      "Ranveer Chandra"
    ],
    "abstract": "Mitigating climate change requires transforming agriculture to minimize\nenviron mental impact and build climate resilience. Regenerative agricultural\npractices enhance soil organic carbon (SOC) levels, thus improving soil health\nand sequestering carbon. A challenge to increasing regenerative agriculture\npractices is cheaply measuring SOC over time and understanding how SOC is\naffected by regenerative agricultural practices and other environmental factors\nand farm management practices. To address this challenge, we introduce an\nAI-driven Soil Organic Carbon Copilot that automates the ingestion of complex\nmulti-resolution, multi-modal data to provide large-scale insights into soil\nhealth and regenerative practices. Our data includes extreme weather event data\n(e.g., drought and wildfire incidents), farm management data (e.g., cropland\ninformation and tillage predictions), and SOC predictions. We find that\nintegrating public data and specialized models enables large-scale, localized\nanalysis for sustainable agriculture. In comparisons of agricultural practices\nacross California counties, we find evidence that diverse agricultural activity\nmay mitigate the negative effects of tillage; and that while extreme weather\nconditions heavily affect SOC, composting may mitigate SOC loss. Finally,\nimplementing role-specific personas empowers agronomists, farm consultants,\npolicymakers, and other stakeholders to implement evidence-based strategies\nthat promote sustainable agriculture and build climate resilience.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16872v2",
    "published_date": "2024-11-25 19:11:41 UTC",
    "updated_date": "2024-11-27 06:25:09 UTC"
  },
  {
    "arxiv_id": "2411.16863v2",
    "title": "Augmenting Multimodal LLMs with Self-Reflective Tokens for Knowledge-based Visual Question Answering",
    "authors": [
      "Federico Cocchi",
      "Nicholas Moratelli",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "abstract": "Multimodal LLMs (MLLMs) are the natural extension of large language models to\nhandle multimodal inputs, combining text and image data. They have recently\ngarnered attention due to their capability to address complex tasks involving\nboth modalities. However, their effectiveness is limited to the knowledge\nacquired during training, which restricts their practical utility. In this\nwork, we introduce a novel method to enhance the adaptability of MLLMs by\nintegrating external knowledge sources. Our proposed model, Reflective LLaVA\n(ReflectiVA), utilizes reflective tokens to dynamically determine the need for\nexternal knowledge and predict the relevance of information retrieved from an\nexternal database. Tokens are trained following a two-stage two-model training\nrecipe. This ultimately enables the MLLM to manage external knowledge while\npreserving fluency and performance on tasks where external knowledge is not\nneeded. Through our experiments, we demonstrate the efficacy of ReflectiVA for\nknowledge-based visual question answering, highlighting its superior\nperformance compared to existing methods. Source code and trained models are\npublicly available at https://aimagelab.github.io/ReflectiVA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.16863v2",
    "published_date": "2024-11-25 19:01:03 UTC",
    "updated_date": "2025-04-02 06:19:46 UTC"
  },
  {
    "arxiv_id": "2411.17470v2",
    "title": "Towards Precise Scaling Laws for Video Diffusion Transformers",
    "authors": [
      "Yuanyang Yin",
      "Yaqi Zhao",
      "Mingwu Zheng",
      "Ke Lin",
      "Jiarong Ou",
      "Rui Chen",
      "Victor Shea-Jay Huang",
      "Jiahao Wang",
      "Xin Tao",
      "Pengfei Wan",
      "Di Zhang",
      "Baoqun Yin",
      "Wentao Zhang",
      "Kun Gai"
    ],
    "abstract": "Achieving optimal performance of video diffusion transformers within given\ndata and compute budget is crucial due to their high training costs. This\nnecessitates precisely determining the optimal model size and training\nhyperparameters before large-scale training. While scaling laws are employed in\nlanguage models to predict performance, their existence and accurate derivation\nin visual generation models remain underexplored. In this paper, we\nsystematically analyze scaling laws for video diffusion transformers and\nconfirm their presence. Moreover, we discover that, unlike language models,\nvideo diffusion models are more sensitive to learning rate and batch size, two\nhyperparameters often not precisely modeled. To address this, we propose a new\nscaling law that predicts optimal hyperparameters for any model size and\ncompute budget. Under these optimal settings, we achieve comparable performance\nand reduce inference costs by 40.1% compared to conventional scaling methods,\nwithin a compute budget of 1e10 TFlops. Furthermore, we establish a more\ngeneralized and precise relationship among validation loss, any model size, and\ncompute budget. This enables performance prediction for non-optimal model\nsizes, which may also be appealed under practical inference cost constraints,\nachieving a better trade-off.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.17470v2",
    "published_date": "2024-11-25 18:59:04 UTC",
    "updated_date": "2024-12-31 16:25:39 UTC"
  },
  {
    "arxiv_id": "2411.16832v2",
    "title": "Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing",
    "authors": [
      "Hanhui Wang",
      "Yihua Zhang",
      "Ruizheng Bai",
      "Yue Zhao",
      "Sijia Liu",
      "Zhengzhong Tu"
    ],
    "abstract": "Recent advancements in diffusion models have made generative image editing\nmore accessible, enabling creative edits but raising ethical concerns,\nparticularly regarding malicious edits to human portraits that threaten privacy\nand identity security. Existing protection methods primarily rely on\nadversarial perturbations to nullify edits but often fail against diverse\nediting requests. We propose FaceLock, a novel approach to portrait protection\nthat optimizes adversarial perturbations to destroy or significantly alter\nbiometric information, rendering edited outputs biometrically unrecognizable.\nFaceLock integrates facial recognition and visual perception into perturbation\noptimization to provide robust protection against various editing attempts. We\nalso highlight flaws in commonly used evaluation metrics and reveal how they\ncan be manipulated, emphasizing the need for reliable assessments of\nprotection. Experiments show FaceLock outperforms baselines in defending\nagainst malicious edits and is robust against purification techniques. Ablation\nstudies confirm its stability and broad applicability across diffusion-based\nediting algorithms. Our work advances biometric defense and sets the foundation\nfor privacy-preserving practices in image editing. The code is available at:\nhttps://github.com/taco-group/FaceLock.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "GitHub: https://github.com/taco-group/FaceLock",
    "pdf_url": "http://arxiv.org/pdf/2411.16832v2",
    "published_date": "2024-11-25 18:59:03 UTC",
    "updated_date": "2025-03-15 00:11:37 UTC"
  },
  {
    "arxiv_id": "2411.16667v2",
    "title": "OPMOS: Ordered Parallel Algorithm for Multi-Objective Shortest-Paths",
    "authors": [
      "Leo Gold",
      "Adam Bienkowski",
      "David Sidoti",
      "Krishna Pattipati",
      "Omer Khan"
    ],
    "abstract": "The Multi-Objective Shortest-Path (MOS) problem finds a set of Pareto-optimal\nsolutions from a start node to a destination node in a multi-attribute graph.\nThe literature explores multi-objective A*-style algorithmic approaches to\nsolving the NP-hard MOS problem. These approaches use consistent heuristics to\ncompute an exact set of solutions for the goal node. A generalized MOS\nalgorithm maintains a \"frontier\" of partial paths at each node and performs\nordered processing to ensure that Pareto-optimal paths are generated to reach\nthe goal node. The algorithm becomes computationally intractable at a higher\nnumber of objectives due to a rapid increase in the search space for\nnon-dominated paths and the significant increase in Pareto-optimal solutions.\nWhile prior works have focused on algorithmic methods to reduce the complexity,\nwe tackle this challenge by exploiting parallelism to accelerate the MOS\nproblem. The key insight is that MOS algorithms rely on the ordered execution\nof partial paths to maintain high work efficiency. The proposed parallel\nalgorithm (OPMOS) unlocks ordered parallelism and efficiently exploits the\nconcurrent execution of multiple paths in MOS. Experimental evaluation using\nthe NVIDIA GH200 Superchip's 72-core Arm-based CPU shows the performance\nscaling potential of OPMOS on work efficiency and parallelism using a\nreal-world application to ship routing.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR",
      "cs.DS",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.16667v2",
    "published_date": "2024-11-25 18:53:49 UTC",
    "updated_date": "2025-04-15 01:51:24 UTC"
  },
  {
    "arxiv_id": "2411.16666v2",
    "title": "CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance",
    "authors": [
      "Jiaan Han",
      "Junxiao Chen",
      "Yanzhe Fu"
    ],
    "abstract": "We introduce CatNet, an algorithm that effectively controls False Discovery\nRate (FDR) and selects significant features in LSTM with the Gaussian Mirror\n(GM) method. To evaluate the feature importance of LSTM in time series, we\nintroduce a vector of the derivative of the SHapley Additive exPlanations\n(SHAP) to measure feature importance. We also propose a new kernel-based\ndependence measure to avoid multicollinearity in the GM algorithm, to make a\nrobust feature selection with controlled FDR. We use simulated data to evaluate\nCatNet's performance in both linear models and LSTM models with different link\nfunctions. The algorithm effectively controls the FDR while maintaining a high\nstatistical power in all cases. We also evaluate the algorithm's performance in\ndifferent low-dimensional and high-dimensional cases, demonstrating its\nrobustness in various input dimensions. To evaluate CatNet's performance in\nreal world applications, we construct a multi-factor investment portfolio to\nforecast the prices of S\\&P 500 index components. The results demonstrate that\nour model achieves superior predictive accuracy compared to traditional LSTM\nmodels without feature selection and FDR control. Additionally, CatNet\neffectively captures common market-driving features, which helps informed\ndecision-making in financial markets by enhancing the interpretability of\npredictions. Our study integrates of the Gaussian Mirror algorithm with LSTM\nmodels for the first time, and introduces SHAP values as a new feature\nimportance metric for FDR control methods, marking a significant advancement in\nfeature selection and error control for neural networks.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "q-fin.ST"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16666v2",
    "published_date": "2024-11-25 18:53:37 UTC",
    "updated_date": "2024-11-26 16:23:19 UTC"
  },
  {
    "arxiv_id": "2411.16657v3",
    "title": "DreamRunner: Fine-Grained Compositional Story-to-Video Generation with Retrieval-Augmented Motion Adaptation",
    "authors": [
      "Zun Wang",
      "Jialu Li",
      "Han Lin",
      "Jaehong Yoon",
      "Mohit Bansal"
    ],
    "abstract": "Storytelling video generation (SVG) aims to produce coherent and visually\nrich multi-scene videos that follow a structured narrative. Existing methods\nprimarily employ LLM for high-level planning to decompose a story into\nscene-level descriptions, which are then independently generated and stitched\ntogether. However, these approaches struggle with generating high-quality\nvideos aligned with the complex single-scene description, as visualizing such\ncomplex description involves coherent composition of multiple characters and\nevents, complex motion synthesis and muti-character customization. To address\nthese challenges, we propose DreamRunner, a novel story-to-video generation\nmethod: First, we structure the input script using a large language model (LLM)\nto facilitate both coarse-grained scene planning as well as fine-grained\nobject-level layout and motion planning. Next, DreamRunner presents\nretrieval-augmented test-time adaptation to capture target motion priors for\nobjects in each scene, supporting diverse motion customization based on\nretrieved videos, thus facilitating the generation of new videos with complex,\nscripted motions. Lastly, we propose a novel spatial-temporal region-based 3D\nattention and prior injection module SR3AI for fine-grained object-motion\nbinding and frame-by-frame semantic control. We compare DreamRunner with\nvarious SVG baselines, demonstrating state-of-the-art performance in character\nconsistency, text alignment, and smooth transitions. Additionally, DreamRunner\nexhibits strong fine-grained condition-following ability in compositional\ntext-to-video generation, significantly outperforming baselines on\nT2V-ComBench. Finally, we validate DreamRunner's robust ability to generate\nmulti-object interactions with qualitative examples.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website: https://zunwang1.github.io/DreamRunner",
    "pdf_url": "http://arxiv.org/pdf/2411.16657v3",
    "published_date": "2024-11-25 18:41:56 UTC",
    "updated_date": "2025-03-18 15:19:15 UTC"
  },
  {
    "arxiv_id": "2411.16824v1",
    "title": "Beyond Sight: Towards Cognitive Alignment in LVLM via Enriched Visual Knowledge",
    "authors": [
      "Yaqi Zhao",
      "Yuanyang Yin",
      "Lin Li",
      "Mingan Lin",
      "Victor Shea-Jay Huang",
      "Siwei Chen",
      "Weipeng Chen",
      "Baoqun Yin",
      "Zenan Zhou",
      "Wentao Zhang"
    ],
    "abstract": "Does seeing always mean knowing? Large Vision-Language Models (LVLMs)\nintegrate separately pre-trained vision and language components, often using\nCLIP-ViT as vision backbone. However, these models frequently encounter a core\nissue of \"cognitive misalignment\" between the vision encoder (VE) and the large\nlanguage model (LLM). Specifically, the VE's representation of visual\ninformation may not fully align with LLM's cognitive framework, leading to a\nmismatch where visual features exceed the language model's interpretive range.\nTo address this, we investigate how variations in VE representations influence\nLVLM comprehension, especially when the LLM faces VE-Unknown data-images whose\nambiguous visual representations challenge the VE's interpretive precision.\nAccordingly, we construct a multi-granularity landmark dataset and\nsystematically examine the impact of VE-Known and VE-Unknown data on\ninterpretive abilities. Our results show that VE-Unknown data limits LVLM's\ncapacity for accurate understanding, while VE-Known data, rich in distinctive\nfeatures, helps reduce cognitive misalignment. Building on these insights, we\npropose Entity-Enhanced Cognitive Alignment (EECA), a method that employs\nmulti-granularity supervision to generate visually enriched, well-aligned\ntokens that not only integrate within the LLM's embedding space but also align\nwith the LLM's cognitive framework. This alignment markedly enhances LVLM\nperformance in landmark recognition. Our findings underscore the challenges\nposed by VE-Unknown data and highlight the essential role of cognitive\nalignment in advancing multimodal systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16824v1",
    "published_date": "2024-11-25 18:33:14 UTC",
    "updated_date": "2024-11-25 18:33:14 UTC"
  },
  {
    "arxiv_id": "2411.16646v3",
    "title": "Self-Generated Critiques Boost Reward Modeling for Language Models",
    "authors": [
      "Yue Yu",
      "Zhengxing Chen",
      "Aston Zhang",
      "Liang Tan",
      "Chenguang Zhu",
      "Richard Yuanzhe Pang",
      "Yundi Qian",
      "Xuewei Wang",
      "Suchin Gururangan",
      "Chao Zhang",
      "Melanie Kambadur",
      "Dhruv Mahajan",
      "Rui Hou"
    ],
    "abstract": "Reward modeling is crucial for aligning large language models (LLMs) with\nhuman preferences, especially in reinforcement learning from human feedback\n(RLHF). However, current reward models mainly produce scalar scores and\nstruggle to incorporate critiques in a natural language format. We hypothesize\nthat predicting both critiques and the scalar reward would improve reward\nmodeling ability. Motivated by this, we propose Critic-RM, a framework that\nimproves reward models using self-generated critiques without extra\nsupervision. Critic-RM employs a two-stage process: generating and filtering\nhigh-quality critiques, followed by joint fine-tuning on reward prediction and\ncritique generation. Experiments across benchmarks show that Critic-RM improves\nreward modeling accuracy by 3.7%-7.3% compared to standard reward models and\nLLM judges, demonstrating strong performance and data efficiency. Additional\nstudies further validate the effectiveness of generated critiques in rectifying\nflawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 (Main Conference)",
    "pdf_url": "http://arxiv.org/pdf/2411.16646v3",
    "published_date": "2024-11-25 18:28:26 UTC",
    "updated_date": "2025-02-09 07:53:38 UTC"
  },
  {
    "arxiv_id": "2411.16645v1",
    "title": "Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters",
    "authors": [
      "Dietmar Jannach",
      "Alan Said",
      "Marko Tkalčič",
      "Markus Zanker"
    ],
    "abstract": "In the area of recommender systems, the vast majority of research efforts is\nspent on developing increasingly sophisticated recommendation models, also\nusing increasingly more computational resources. Unfortunately, most of these\nresearch efforts target a very small set of application domains, mostly\ne-commerce and media recommendation. Furthermore, many of these models are\nnever evaluated with users, let alone put into practice. The scientific,\neconomic and societal value of much of these efforts by scholars therefore\nremains largely unclear. To achieve a stronger positive impact resulting from\nthese efforts, we posit that we as a research community should more often\naddress use cases where recommender systems contribute to societal good\n(RS4Good). In this opinion piece, we first discuss a number of examples where\nthe use of recommender systems for problems of societal concern has been\nsuccessfully explored in the literature. We then proceed by outlining a\nparadigmatic shift that is needed to conduct successful RS4Good research, where\nthe key ingredients are interdisciplinary collaborations and longitudinal\nevaluation approaches with humans in the loop.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16645v1",
    "published_date": "2024-11-25 18:27:50 UTC",
    "updated_date": "2024-11-25 18:27:50 UTC"
  },
  {
    "arxiv_id": "2411.16638v3",
    "title": "Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation",
    "authors": [
      "Sanjana Ramprasad",
      "Byron C. Wallace"
    ],
    "abstract": "Modern LLMs can now produce highly readable abstractive summaries, to the\npoint where traditional automated metrics for evaluating summary quality, such\nas ROUGE, have become saturated. However, LLMs still sometimes introduce\nunwanted content into summaries, i.e., information inconsistent with or\nunsupported by their source. Measuring the occurrence of these often subtle\n``hallucinations'' automatically has proved to be challenging. This in turn has\nmotivated development of a variety of metrics intended to measure the factual\nconsistency of generated summaries against their source. But are these\napproaches measuring what they purport to do? In this work, we stress-test\nautomatic factuality metrics. Specifically, we investigate whether and to what\ndegree superficial attributes of summary texts suffice to predict\n``factuality'', finding that a (supervised) model using only such shallow\nfeatures is reasonably competitive with SOTA factuality scoring methods. We\nthen evaluate how factuality metrics respond to factual corrections in\ninconsistent summaries and find that only a few show meaningful improvements.\nIn contrast, some metrics are more sensitive to benign, non-factual edits.\nMotivated by these insights, we show that one can ``game'' (most) automatic\nfactuality metrics, i.e., reliably inflate ``factuality'' scores by appending\ninnocuous sentences to generated summaries. Taken together, our results raise\nquestions about the degree to which we should rely on existing automated\nfactuality metrics and what exactly we want ``factuality metrics'' to measure.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16638v3",
    "published_date": "2024-11-25 18:15:15 UTC",
    "updated_date": "2024-11-28 13:33:53 UTC"
  },
  {
    "arxiv_id": "2411.16627v2",
    "title": "Inference-Time Policy Steering through Human Interactions",
    "authors": [
      "Yanwei Wang",
      "Lirui Wang",
      "Yilun Du",
      "Balakumar Sundaralingam",
      "Xuning Yang",
      "Yu-Wei Chao",
      "Claudia Perez-D'Arpino",
      "Dieter Fox",
      "Julie Shah"
    ],
    "abstract": "Generative policies trained with human demonstrations can autonomously\naccomplish multimodal, long-horizon tasks. However, during inference, humans\nare often removed from the policy execution loop, limiting the ability to guide\na pre-trained policy towards a specific sub-goal or trajectory shape among\nmultiple predictions. Naive human intervention may inadvertently exacerbate\ndistribution shift, leading to constraint violations or execution failures. To\nbetter align policy output with human intent without inducing\nout-of-distribution errors, we propose an Inference-Time Policy Steering (ITPS)\nframework that leverages human interactions to bias the generative sampling\nprocess, rather than fine-tuning the policy on interaction data. We evaluate\nITPS across three simulated and real-world benchmarks, testing three forms of\nhuman interaction and associated alignment distance metrics. Among six sampling\nstrategies, our proposed stochastic sampling with diffusion policy achieves the\nbest trade-off between alignment and distribution shift. Videos are available\nat https://yanweiw.github.io/itps/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.16627v2",
    "published_date": "2024-11-25 18:03:50 UTC",
    "updated_date": "2025-03-26 02:40:00 UTC"
  },
  {
    "arxiv_id": "2411.16622v1",
    "title": "Imperceptible Adversarial Examples in the Physical World",
    "authors": [
      "Weilin Xu",
      "Sebastian Szyller",
      "Cory Cornelius",
      "Luis Murillo Rojas",
      "Marius Arvinte",
      "Alvaro Velasquez",
      "Jason Martin",
      "Nageen Himayat"
    ],
    "abstract": "Adversarial examples in the digital domain against deep learning-based\ncomputer vision models allow for perturbations that are imperceptible to human\neyes. However, producing similar adversarial examples in the physical world has\nbeen difficult due to the non-differentiable image distortion functions in\nvisual sensing systems. The existing algorithms for generating physically\nrealizable adversarial examples often loosen their definition of adversarial\nexamples by allowing unbounded perturbations, resulting in obvious or even\nstrange visual patterns. In this work, we make adversarial examples\nimperceptible in the physical world using a straight-through estimator (STE,\na.k.a. BPDA). We employ STE to overcome the non-differentiability -- applying\nexact, non-differentiable distortions in the forward pass of the\nbackpropagation step, and using the identity function in the backward pass. Our\ndifferentiable rendering extension to STE also enables imperceptible\nadversarial patches in the physical world. Using printout photos, and\nexperiments in the CARLA simulator, we show that STE enables fast generation of\n$\\ell_\\infty$ bounded adversarial examples despite the non-differentiable\ndistortions. To the best of our knowledge, this is the first work demonstrating\nimperceptible adversarial examples bounded by small $\\ell_\\infty$ norms in the\nphysical world that force zero classification accuracy in the global\nperturbation threat model and cause near-zero ($4.22\\%$) AP50 in object\ndetection in the patch perturbation threat model. We urge the community to\nre-evaluate the threat of adversarial examples in the physical world.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16622v1",
    "published_date": "2024-11-25 18:02:23 UTC",
    "updated_date": "2024-11-25 18:02:23 UTC"
  },
  {
    "arxiv_id": "2411.16609v1",
    "title": "F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite",
    "authors": [
      "Ansgar Scherp",
      "Thomas Franz",
      "Carsten Saathoff",
      "Steffen Staab"
    ],
    "abstract": "The lack of a formal model of events hinders interoperability in distributed\nevent-based systems. In this paper, we present a formal model of events, called\nEvent-Model-F. The model is based on the foundational ontology DOLCE+DnS\nUltralite (DUL) and provides comprehensive support to represent time and space,\nobjects and persons, as well as mereological, causal, and correlative\nrelationships between events. In addition, the Event-Model-F provides a\nflexible means for event composition, modeling event causality and event\ncorrelation, and representing different interpretations of the same event. The\nEvent-Model-F is developed following the pattern-oriented approach of DUL, is\nmodularized in different ontologies, and can be easily extended by domain\nspecific ontologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Reprint of KCAP 2009 paper with republished ontologies",
    "pdf_url": "http://arxiv.org/pdf/2411.16609v1",
    "published_date": "2024-11-25 17:45:38 UTC",
    "updated_date": "2024-11-25 17:45:38 UTC"
  },
  {
    "arxiv_id": "2411.16594v6",
    "title": "From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge",
    "authors": [
      "Dawei Li",
      "Bohan Jiang",
      "Liangjie Huang",
      "Alimohammad Beigi",
      "Chengshuai Zhao",
      "Zhen Tan",
      "Amrita Bhattacharjee",
      "Yuxuan Jiang",
      "Canyu Chen",
      "Tianhao Wu",
      "Kai Shu",
      "Lu Cheng",
      "Huan Liu"
    ],
    "abstract": "Assessment and evaluation have long been critical challenges in artificial\nintelligence (AI) and natural language processing (NLP). However, traditional\nmethods, whether matching-based or embedding-based, often fall short of judging\nsubtle attributes and delivering satisfactory results. Recent advancements in\nLarge Language Models (LLMs) inspire the \"LLM-as-a-judge\" paradigm, where LLMs\nare leveraged to perform scoring, ranking, or selection across various tasks\nand applications. This paper provides a comprehensive survey of LLM-based\njudgment and assessment, offering an in-depth overview to advance this emerging\nfield. We begin by giving detailed definitions from both input and output\nperspectives. Then we introduce a comprehensive taxonomy to explore\nLLM-as-a-judge from three dimensions: what to judge, how to judge and where to\njudge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and\nhighlight key challenges and promising directions, aiming to provide valuable\ninsights and inspire future research in this promising research area. Paper\nlist and more resources about LLM-as-a-judge can be found at\nhttps://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge and\nhttps://llm-as-a-judge.github.io.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "v6: add new citations; 36 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.16594v6",
    "published_date": "2024-11-25 17:28:44 UTC",
    "updated_date": "2025-02-06 00:18:27 UTC"
  },
  {
    "arxiv_id": "2411.16579v1",
    "title": "Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision",
    "authors": [
      "Zhiheng Xi",
      "Dingwen Yang",
      "Jixuan Huang",
      "Jiafu Tang",
      "Guanyu Li",
      "Yiwen Ding",
      "Wei He",
      "Boyang Hong",
      "Shihan Do",
      "Wenyu Zhan",
      "Xiao Wang",
      "Rui Zheng",
      "Tao Ji",
      "Xiaowei Shi",
      "Yitao Zhai",
      "Rongxiang Weng",
      "Jingang Wang",
      "Xunliang Cai",
      "Tao Gui",
      "Zuxuan Wu",
      "Qi Zhang",
      "Xipeng Qiu",
      "Xuanjing Huang",
      "Yu-Gang Jiang"
    ],
    "abstract": "Training large language models (LLMs) to spend more time thinking and\nreflection before responding is crucial for effectively solving complex\nreasoning tasks in fields such as science, coding, and mathematics. However,\nthe effectiveness of mechanisms like self-reflection and self-correction\ndepends on the model's capacity to accurately assess its own performance, which\ncan be limited by factors such as initial accuracy, question difficulty, and\nthe lack of external feedback. In this paper, we delve into a two-player\nparadigm that separates the roles of reasoning and critique models, where the\ncritique model provides step-level feedback to supervise the reasoning (actor)\nmodel during both test-time and train-time. We first propose AutoMathCritique,\nan automated and scalable framework for collecting critique data, resulting in\na dataset of $76,321$ responses paired with step-level feedback. Fine-tuning\nlanguage models with this dataset enables them to generate natural language\nfeedback for mathematical reasoning. We demonstrate that the critique models\nconsistently improve the actor's performance on difficult queries at test-time,\nespecially when scaling up inference-time computation. Motivated by these\nfindings, we introduce the critique-based supervision to the actor's\nself-training process, and propose a critique-in-the-loop self-improvement\nmethod. Experiments show that the method improves the actor's exploration\nefficiency and solution diversity, especially on challenging queries, leading\nto a stronger reasoning model. Lastly, we take the preliminary step to explore\ntraining self-talk reasoning models via critique supervision and showcase its\npotential. Our code and datasets are at\n\\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2411.16579v1",
    "published_date": "2024-11-25 17:11:54 UTC",
    "updated_date": "2024-11-25 17:11:54 UTC"
  },
  {
    "arxiv_id": "2411.16574v1",
    "title": "Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?",
    "authors": [
      "Connor Douglas",
      "Foster Provost",
      "Arun Sundararajan"
    ],
    "abstract": "Algorithmic agents are used in a variety of competitive decision settings,\nnotably in making pricing decisions in contexts that range from online retail\nto residential home rentals. Business managers, algorithm designers, legal\nscholars, and regulators alike are all starting to consider the ramifications\nof \"algorithmic collusion.\" We study the emergent behavior of multi-armed\nbandit machine learning algorithms used in situations where agents are\ncompeting, but they have no information about the strategic interaction they\nare engaged in. Using a general-form repeated Prisoner's Dilemma game, agents\nengage in online learning with no prior model of game structure and no\nknowledge of competitors' states or actions (e.g., no observation of competing\nprices). We show that these context-free bandits, with no knowledge of\nopponents' choices or outcomes, still will consistently learn collusive\nbehavior - what we call \"naive collusion.\" We primarily study this system\nthrough an analytical model and examine perturbations to the model through\nsimulations.\n  Our findings have several notable implications for regulators. First, calls\nto limit algorithms from conditioning on competitors' prices are insufficient\nto prevent algorithmic collusion. This is a direct result of collusion arising\neven in the naive setting. Second, symmetry in algorithms can increase\ncollusion potential. This highlights a new, simple mechanism for\n\"hub-and-spoke\" algorithmic collusion. A central distributor need not imbue its\nalgorithm with supra-competitive tendencies for apparent collusion to arise; it\ncan simply arise by using certain (common) machine learning algorithms.\nFinally, we highlight that collusive outcomes depend starkly on the specific\nalgorithm being used, and we highlight market and algorithmic conditions under\nwhich it will be unknown a priori whether collusion occurs.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.GT",
      "cs.MA",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "To be published in proceedings of International Conference on\n  Information Systems 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.16574v1",
    "published_date": "2024-11-25 16:58:07 UTC",
    "updated_date": "2024-11-25 16:58:07 UTC"
  },
  {
    "arxiv_id": "2411.16819v4",
    "title": "Pathways on the Image Manifold: Image Editing via Video Generation",
    "authors": [
      "Noam Rotstein",
      "Gal Yona",
      "Daniel Silver",
      "Roy Velich",
      "David Bensaïd",
      "Ron Kimmel"
    ],
    "abstract": "Recent advances in image editing, driven by image diffusion models, have\nshown remarkable progress. However, significant challenges remain, as these\nmodels often struggle to follow complex edit instructions accurately and\nfrequently compromise fidelity by altering key elements of the original image.\nSimultaneously, video generation has made remarkable strides, with models that\neffectively function as consistent and continuous world simulators. In this\npaper, we propose merging these two fields by utilizing image-to-video models\nfor image editing. We reformulate image editing as a temporal process, using\npretrained video models to create smooth transitions from the original image to\nthe desired edit. This approach traverses the image manifold continuously,\nensuring consistent edits while preserving the original image's key aspects.\nOur approach achieves state-of-the-art results on text-based image editing,\ndemonstrating significant improvements in both edit accuracy and image\npreservation. Visit our project page at\nhttps://rotsteinnoam.github.io/Frame2Frame.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16819v4",
    "published_date": "2024-11-25 16:41:45 UTC",
    "updated_date": "2025-03-20 07:02:30 UTC"
  },
  {
    "arxiv_id": "2411.16818v1",
    "title": "Enhancing In-Hospital Mortality Prediction Using Multi-Representational Learning with LLM-Generated Expert Summaries",
    "authors": [
      "Harshavardhan Battula",
      "Jiacheng Liu",
      "Jaideep Srivastava"
    ],
    "abstract": "In-hospital mortality (IHM) prediction for ICU patients is critical for\ntimely interventions and efficient resource allocation. While structured\nphysiological data provides quantitative insights, clinical notes offer\nunstructured, context-rich narratives. This study integrates these modalities\nwith Large Language Model (LLM)-generated expert summaries to improve IHM\nprediction accuracy. Using the MIMIC-III database, we analyzed time-series\nphysiological data and clinical notes from the first 48 hours of ICU admission.\nClinical notes were concatenated chronologically for each patient and\ntransformed into expert summaries using Med42-v2 70B. A multi-representational\nlearning framework was developed to integrate these data sources, leveraging\nLLMs to enhance textual data while mitigating direct reliance on LLM\npredictions, which can introduce challenges in uncertainty quantification and\ninterpretability. The proposed model achieved an AUPRC of 0.6156 (+36.41%) and\nan AUROC of 0.8955 (+7.64%) compared to a time-series-only baseline. Expert\nsummaries outperformed clinical notes or time-series data alone, demonstrating\nthe value of LLM-generated knowledge. Performance gains were consistent across\ndemographic groups, with notable improvements in underrepresented populations,\nunderscoring the framework's equitable application potential. By integrating\nLLM-generated summaries with structured and unstructured data, the framework\ncaptures complementary patient information, significantly improving predictive\nperformance. This approach showcases the potential of LLMs to augment critical\ncare prediction models, emphasizing the need for domain-specific validation and\nadvanced integration strategies for broader clinical adoption.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16818v1",
    "published_date": "2024-11-25 16:36:38 UTC",
    "updated_date": "2024-11-25 16:36:38 UTC"
  },
  {
    "arxiv_id": "2411.16550v1",
    "title": "Representation Collapsing Problems in Vector Quantization",
    "authors": [
      "Wenhao Zhao",
      "Qiran Zou",
      "Rushi Shah",
      "Dianbo Liu"
    ],
    "abstract": "Vector quantization is a technique in machine learning that discretizes\ncontinuous representations into a set of discrete vectors. It is widely\nemployed in tokenizing data representations for large language models,\ndiffusion models, and other generative models. Despite its prevalence, the\ncharacteristics and behaviors of vector quantization in generative models\nremain largely underexplored. In this study, we investigate representation\ncollapse in vector quantization - a critical degradation where codebook tokens\nor latent embeddings lose their discriminative power by converging to a limited\nsubset of values. This collapse fundamentally compromises the model's ability\nto capture diverse data patterns. By leveraging both synthetic and real\ndatasets, we identify the severity of each type of collapses and triggering\nconditions. Our analysis reveals that restricted initialization and limited\nencoder capacity result in tokens collapse and embeddings collapse. Building on\nthese findings, we propose potential solutions aimed at mitigating each\ncollapse. To the best of our knowledge, this is the first comprehensive study\nexamining representation collapsing problems in vector quantization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, under review",
    "pdf_url": "http://arxiv.org/pdf/2411.16550v1",
    "published_date": "2024-11-25 16:32:29 UTC",
    "updated_date": "2024-11-25 16:32:29 UTC"
  },
  {
    "arxiv_id": "2411.16537v4",
    "title": "RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics",
    "authors": [
      "Chan Hee Song",
      "Valts Blukis",
      "Jonathan Tremblay",
      "Stephen Tyree",
      "Yu Su",
      "Stan Birchfield"
    ],
    "abstract": "Spatial understanding is a crucial capability that enables robots to perceive\ntheir surroundings, reason about their environment, and interact with it\nmeaningfully. In modern robotics, these capabilities are increasingly provided\nby vision-language models. However, these models face significant challenges in\nspatial reasoning tasks, as their training data are based on general-purpose\nimage datasets that often lack sophisticated spatial understanding. For\nexample, datasets frequently do not capture reference frame comprehension, yet\neffective spatial reasoning requires understanding whether to reason from ego-,\nworld-, or object-centric perspectives. To address this issue, we introduce\nRoboSpatial, a large-scale dataset for spatial understanding in robotics. It\nconsists of real indoor and tabletop scenes, captured as 3D scans and\negocentric images, and annotated with rich spatial information relevant to\nrobotics. The dataset includes 1M images, 5k 3D scans, and 3M annotated spatial\nrelationships, and the pairing of 2D egocentric images with 3D scans makes it\nboth 2D- and 3D- ready. Our experiments show that models trained with\nRoboSpatial outperform baselines on downstream tasks such as spatial affordance\nprediction, spatial relationship prediction, and robot manipulation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 (Oral); Project Website: https://chanh.ee/RoboSpatial",
    "pdf_url": "http://arxiv.org/pdf/2411.16537v4",
    "published_date": "2024-11-25 16:21:34 UTC",
    "updated_date": "2025-04-05 06:46:03 UTC"
  },
  {
    "arxiv_id": "2411.16525v1",
    "title": "Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency",
    "authors": [
      "Jerry Yao-Chieh Hu",
      "Wei-Po Wang",
      "Ammar Gilani",
      "Chenyang Li",
      "Zhao Song",
      "Han Liu"
    ],
    "abstract": "We investigate the statistical and computational limits of prompt tuning for\ntransformer-based foundation models. Our key contributions are prompt tuning on\n\\textit{single-head} transformers with only a \\textit{single} self-attention\nlayer: (i) is universal, and (ii) supports efficient (even almost-linear time)\nalgorithms under the Strong Exponential Time Hypothesis (SETH). Statistically,\nwe prove that prompt tuning on such simplest possible transformers are\nuniversal approximators for sequence-to-sequence Lipschitz functions. In\naddition, we provide an exponential-in-$dL$ and -in-$(1/\\epsilon)$ lower bound\non the required soft-prompt tokens for prompt tuning to memorize any dataset\nwith 1-layer, 1-head transformers. Computationally, we identify a phase\ntransition in the efficiency of prompt tuning, determined by the norm of the\n\\textit{soft-prompt-induced} keys and queries, and provide an upper bound\ncriterion. Beyond this criterion, no sub-quadratic (efficient) algorithm for\nprompt tuning exists under SETH. Within this criterion, we showcase our theory\nby proving the existence of almost-linear time prompt tuning inference\nalgorithms. These fundamental limits provide important necessary conditions for\ndesigning expressive and efficient prompt tuning methods for practitioners.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16525v1",
    "published_date": "2024-11-25 16:12:17 UTC",
    "updated_date": "2024-11-25 16:12:17 UTC"
  },
  {
    "arxiv_id": "2412.05301v1",
    "title": "DocEDA: Automated Extraction and Design of Analog Circuits from Documents with Large Language Model",
    "authors": [
      "Hong Cai Chen",
      "Longchang Wu",
      "Ming Gao",
      "Lingrui Shen",
      "Jiarui Zhong",
      "Yipin Xu"
    ],
    "abstract": "Efficient and accurate extraction of electrical parameters from circuit\ndatasheets and design documents is critical for accelerating circuit design in\nElectronic Design Automation (EDA). Traditional workflows often rely on\nengineers manually searching and extracting these parameters, which is\ntime-consuming, and prone to human error. To address these challenges, we\nintroduce DocEDA, an automated system that leverages advanced computer vision\ntechniques and Large Language Models (LLMs) to extract electrical parameters\nseamlessly from documents. The layout analysis model specifically designed for\ndatasheet is proposed to classify documents into circuit-related parts.\nUtilizing the inherent Chain-of-Thought reasoning capabilities of LLMs, DocEDA\nautomates the extraction of electronic component parameters from documents. For\ncircuit diagrams parsing, an improved GAM-YOLO model is hybrid with topology\nidentification to transform diagrams into circuit netlists. Then, a space\nmapping enhanced optimization framework is evoked for optimization the layout\nin the document. Experimental evaluations demonstrate that DocEDA significantly\nenhances the efficiency of processing circuit design documents and the accuracy\nof electrical parameter extraction. It exhibits adaptability to various circuit\ndesign scenarios and document formats, offering a novel solution for EDA with\nthe potential to transform traditional methodologies.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05301v1",
    "published_date": "2024-11-25 15:41:43 UTC",
    "updated_date": "2024-11-25 15:41:43 UTC"
  },
  {
    "arxiv_id": "2411.16502v2",
    "title": "Interpreting Language Reward Models via Contrastive Explanations",
    "authors": [
      "Junqi Jiang",
      "Tom Bewley",
      "Saumitra Mishra",
      "Freddy Lecue",
      "Manuela Veloso"
    ],
    "abstract": "Reward models (RMs) are a crucial component in the alignment of large\nlanguage models' (LLMs) outputs with human values. RMs approximate human\npreferences over possible LLM responses to the same prompt by predicting and\ncomparing reward scores. However, as they are typically modified versions of\nLLMs with scalar output heads, RMs are large black boxes whose predictions are\nnot explainable. More transparent RMs would enable improved trust in the\nalignment of LLMs. In this work, we propose to use contrastive explanations to\nexplain any binary response comparison made by an RM. Specifically, we generate\na diverse set of new comparisons similar to the original one to characterise\nthe RM's local behaviour. The perturbed responses forming the new comparisons\nare generated to explicitly modify manually specified high-level evaluation\nattributes, on which analyses of RM behaviour are grounded. In quantitative\nexperiments, we validate the effectiveness of our method for finding\nhigh-quality contrastive explanations. We then showcase the qualitative\nusefulness of our method for investigating global sensitivity of RMs to each\nevaluation attribute, and demonstrate how representative examples can be\nautomatically extracted to explain and compare behaviours of different RMs. We\nsee our method as a flexible framework for RM explanation, providing a basis\nfor more interpretable and trustworthy LLM alignment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2411.16502v2",
    "published_date": "2024-11-25 15:37:27 UTC",
    "updated_date": "2025-02-26 16:46:25 UTC"
  },
  {
    "arxiv_id": "2411.16489v1",
    "title": "O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?",
    "authors": [
      "Zhen Huang",
      "Haoyang Zou",
      "Xuefeng Li",
      "Yixiu Liu",
      "Yuxiang Zheng",
      "Ethan Chern",
      "Shijie Xia",
      "Yiwei Qin",
      "Weizhe Yuan",
      "Pengfei Liu"
    ],
    "abstract": "This paper presents a critical examination of current approaches to\nreplicating OpenAI's O1 model capabilities, with particular focus on the\nwidespread but often undisclosed use of knowledge distillation techniques.\nWhile our previous work explored the fundamental technical path to O1\nreplication, this study reveals how simple distillation from O1's API, combined\nwith supervised fine-tuning, can achieve superior performance on complex\nmathematical reasoning tasks. Through extensive experiments, we show that a\nbase model fine-tuned on simply tens of thousands of samples O1-distilled\nlong-thought chains outperforms O1-preview on the American Invitational\nMathematics Examination (AIME) with minimal technical complexity. Moreover, our\ninvestigation extends beyond mathematical reasoning to explore the\ngeneralization capabilities of O1-distilled models across diverse tasks:\nhallucination, safety and open-domain QA. Notably, despite training only on\nmathematical problem-solving data, our models demonstrated strong\ngeneralization to open-ended QA tasks and became significantly less susceptible\nto sycophancy after fine-tuning. We deliberately make this finding public to\npromote transparency in AI research and to challenge the current trend of\nobscured technical claims in the field. Our work includes: (1) A detailed\ntechnical exposition of the distillation process and its effectiveness, (2) A\ncomprehensive benchmark framework for evaluating and categorizing O1\nreplication attempts based on their technical transparency and reproducibility,\n(3) A critical discussion of the limitations and potential risks of\nover-relying on distillation approaches, our analysis culminates in a crucial\nbitter lesson: while the pursuit of more capable AI systems is important, the\ndevelopment of researchers grounded in first-principles thinking is paramount.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.16489v1",
    "published_date": "2024-11-25 15:31:27 UTC",
    "updated_date": "2024-11-25 15:31:27 UTC"
  },
  {
    "arxiv_id": "2411.16813v2",
    "title": "Fine-Tuning LLMs with Noisy Data for Political Argument Generation and Post Guidance",
    "authors": [
      "Svetlana Churina",
      "Kokil Jaidka"
    ],
    "abstract": "The incivility in social media discourse complicates the deployment of\nautomated text generation models for politically sensitive content. Fine-tuning\nand prompting strategies are critical, but underexplored, solutions to mitigate\ntoxicity in such contexts. This study investigates the fine-tuning and\nprompting effects on GPT-3.5 Turbo using subsets of the CLAPTON dataset of\npolitical discussion posts, comprising Twitter and Reddit data labeled for\ntheir justification, reciprocity and incivility. Fine-tuned models on Reddit\ndata scored highest on discussion quality, while combined noisy data led to\npersistent toxicity. Prompting strategies reduced specific toxic traits, such\nas personal attacks, but had limited broader impact. The findings emphasize\nthat high-quality data and well-crafted prompts are essential to reduce\nincivility and improve rhetorical quality in automated political discourse\ngeneration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16813v2",
    "published_date": "2024-11-25 15:28:11 UTC",
    "updated_date": "2024-12-08 02:00:57 UTC"
  },
  {
    "arxiv_id": "2411.16487v1",
    "title": "When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?",
    "authors": [
      "Srikrishna Iyer"
    ],
    "abstract": "We present our submission to the BabyLM challenge, aiming to push the\nboundaries of data-efficient language model pretraining. Our method builds upon\ndeep mutual learning, introducing a student model search for diverse\ninitialization. We address the limitation of treating students equally by\nformulating weighted mutual learning as a bi-level optimization problem. The\ninner loop learns compact students through online distillation, while the outer\nloop optimizes weights for better knowledge distillation from diverse students.\nThis dynamic weighting strategy eliminates the need for a teacher model,\nreducing computational requirements. Our evaluations show that teacher-less\nmethods can match or surpass teacher-supervised approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to BabyLM challenge, CoNLL Workshop, EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.16487v1",
    "published_date": "2024-11-25 15:25:31 UTC",
    "updated_date": "2024-11-25 15:25:31 UTC"
  },
  {
    "arxiv_id": "2411.16457v1",
    "title": "Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction",
    "authors": [
      "Haoming Li"
    ],
    "abstract": "In this paper, we present a novel trajectory prediction model for autonomous\ndriving, combining a Characterized Diffusion Module and a Spatial-Temporal\nInteraction Network to address the challenges posed by dynamic and\nheterogeneous traffic environments. Our model enhances the accuracy and\nreliability of trajectory predictions by incorporating uncertainty estimation\nand complex agent interactions. Through extensive experimentation on public\ndatasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms\nexisting state-of-the-art methods. We demonstrate its ability to capture the\nunderlying spatial-temporal dynamics of traffic scenarios and improve\nprediction precision, especially in complex environments. The proposed model\nshowcases strong potential for application in real-world autonomous driving\nsystems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 0 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.16457v1",
    "published_date": "2024-11-25 15:03:44 UTC",
    "updated_date": "2024-11-25 15:03:44 UTC"
  },
  {
    "arxiv_id": "2411.16809v1",
    "title": "Blockchain Meets LLMs: A Living Survey on Bidirectional Integration",
    "authors": [
      "Jianghao Gong",
      "Peiqi Yan",
      "Yue Zhang",
      "Hongli An",
      "Logan Liu"
    ],
    "abstract": "In the domain of large language models, considerable advancements have been\nattained in multimodal large language models and explainability research,\npropelled by the continuous technological progress and innovation. Nonetheless,\nsecurity and privacy concerns continue to pose as prominent challenges in this\nfield. The emergence of blockchain technology, marked by its decentralized\nnature, tamper-proof attributes, distributed storage functionality, and\ntraceability, has provided novel approaches for resolving these issues. Both of\nthese technologies independently hold vast potential for development; yet,\ntheir combination uncovers substantial cross-disciplinary opportunities and\ngrowth prospects. The current research tendencies are increasingly\nconcentrating on the integration of blockchain with large language models, with\nthe aim of compensating for their respective limitations through this fusion\nand promoting further technological evolution. In this study, we evaluate the\nadvantages and developmental constraints of the two technologies, and explore\nthe possibility and development potential of their combination. This paper\nprimarily investigates the technical convergence in two directions: Firstly,\nthe application of large language models to blockchain, where we identify six\nmajor development directions and explore solutions to the shortcomings of\nblockchain technology and their application scenarios; Secondly, the\napplication of blockchain technology to large language models, leveraging the\ncharacteristics of blockchain to remedy the deficiencies of large language\nmodels and exploring its application potential in multiple fields.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16809v1",
    "published_date": "2024-11-25 14:54:08 UTC",
    "updated_date": "2024-11-25 14:54:08 UTC"
  },
  {
    "arxiv_id": "2411.16807v1",
    "title": "ADAF: An Artificial Intelligence Data Assimilation Framework for Weather Forecasting",
    "authors": [
      "Yanfei Xiang",
      "Weixin Jin",
      "Haiyu Dong",
      "Mingliang Bai",
      "Zuliang Fang",
      "Pengcheng Zhao",
      "Hongyu Sun",
      "Kit Thambiratnam",
      "Qi Zhang",
      "Xiaomeng Huang"
    ],
    "abstract": "The forecasting skill of numerical weather prediction (NWP) models critically\ndepends on the accurate initial conditions, also known as analysis, provided by\ndata assimilation (DA). Traditional DA methods often face a trade-off between\ncomputational cost and accuracy due to complex linear algebra computations and\nthe high dimensionality of the model, especially in nonlinear systems.\nMoreover, processing massive data in real-time requires substantial\ncomputational resources. To address this, we introduce an artificial\nintelligence-based data assimilation framework (ADAF) to generate high-quality\nkilometer-scale analysis. This study is the pioneering work using real-world\nobservations from varied locations and multiple sources to verify the AI\nmethod's efficacy in DA, including sparse surface weather observations and\nsatellite imagery. We implemented ADAF for four near-surface variables in the\nContiguous United States (CONUS). The results indicate that ADAF surpasses the\nHigh Resolution Rapid Refresh Data Assimilation System (HRRRDAS) in accuracy by\n16% to 33% for near-surface atmospheric conditions, aligning more closely with\nactual observations, and can effectively reconstruct extreme events, such as\ntropical cyclone wind fields. Sensitivity experiments reveal that ADAF can\ngenerate high-quality analysis even with low-accuracy backgrounds and extremely\nsparse surface observations. ADAF can assimilate massive observations within a\nthree-hour window at low computational cost, taking about two seconds on an AMD\nMI200 graphics processing unit (GPU). ADAF has been shown to be efficient and\neffective in real-world DA, underscoring its potential role in operational\nweather forecasting.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "29 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.16807v1",
    "published_date": "2024-11-25 14:46:17 UTC",
    "updated_date": "2024-11-25 14:46:17 UTC"
  },
  {
    "arxiv_id": "2411.16442v1",
    "title": "TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment",
    "authors": [
      "Luca Colombo",
      "Alessandro Falcetta",
      "Manuel Roveri"
    ],
    "abstract": "Training machine and deep learning models directly on extremely\nresource-constrained devices is the next challenge in the field of tiny machine\nlearning. The related literature in this field is very limited, since most of\nthe solutions focus only on on-device inference or model adaptation through\nonline learning, leaving the training to be carried out on external Cloud\nservices. An interesting technological perspective is to exploit Federated\nLearning (FL), which allows multiple devices to collaboratively train a shared\nmodel in a distributed way. However, the main drawback of state-of-the-art FL\nalgorithms is that they are not suitable for running on tiny devices. For the\nfirst time in the literature, in this paper we introduce TIFeD, a Tiny\nInteger-based Federated learning algorithm with Direct Feedback Alignment (DFA)\nentirely implemented by using an integer-only arithmetic and being specifically\ndesigned to operate on devices with limited resources in terms of memory,\ncomputation and energy. Besides the traditional full-network operating\nmodality, in which each device of the FL setting trains the entire neural\nnetwork on its own local data, we propose an innovative single-layer TIFeD\nimplementation, which enables each device to train only a portion of the neural\nnetwork model and opens the door to a new way of distributing the learning\nprocedure across multiple devices. The experimental results show the\nfeasibility and effectiveness of the proposed solution. The proposed TIFeD\nalgorithm, with its full-network and single-layer implementations, is made\navailable to the scientific community as a public repository.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16442v1",
    "published_date": "2024-11-25 14:44:26 UTC",
    "updated_date": "2024-11-25 14:44:26 UTC"
  },
  {
    "arxiv_id": "2411.16805v4",
    "title": "Human Motion Instruction Tuning",
    "authors": [
      "Lei Li",
      "Sen Jia",
      "Jianhao Wang",
      "Zhongyu Jiang",
      "Feng Zhou",
      "Ju Dai",
      "Tianfang Zhang",
      "Zongkai Wu",
      "Jenq-Neng Hwang"
    ],
    "abstract": "This paper presents LLaMo (Large Language and Human Motion Assistant), a\nmultimodal framework for human motion instruction tuning. In contrast to\nconventional instruction-tuning approaches that convert non-linguistic inputs,\nsuch as video or motion sequences, into language tokens, LLaMo retains motion\nin its native form for instruction tuning. This method preserves\nmotion-specific details that are often diminished in tokenization, thereby\nimproving the model's ability to interpret complex human behaviors. By\nprocessing both video and motion data alongside textual inputs, LLaMo enables a\nflexible, human-centric analysis. Experimental evaluations across\nhigh-complexity domains, including human behaviors and professional activities,\nindicate that LLaMo effectively captures domain-specific knowledge, enhancing\ncomprehension and prediction in motion-intensive scenarios. We hope LLaMo\noffers a foundation for future multimodal AI systems with broad applications,\nfrom sports analytics to behavioral prediction. Our code and models are\navailable on the project website: https://github.com/ILGLJ/LLaMo.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.16805v4",
    "published_date": "2024-11-25 14:38:43 UTC",
    "updated_date": "2025-03-26 04:20:11 UTC"
  },
  {
    "arxiv_id": "2411.16427v1",
    "title": "Unsupervised Event Outlier Detection in Continuous Time",
    "authors": [
      "Somjit Nath",
      "Yik Chau Lui",
      "Siqi Liu"
    ],
    "abstract": "Event sequence data record the occurrences of events in continuous time.\nEvent sequence forecasting based on temporal point processes (TPPs) has been\nextensively studied, but outlier or anomaly detection, especially without any\nsupervision from humans, is still underexplored. In this work, we develop, to\nthe best our knowledge, the first unsupervised outlier detection approach to\ndetecting abnormal events. Our novel unsupervised outlier detection framework\nis based on ideas from generative adversarial networks (GANs) and reinforcement\nlearning (RL). We train a 'generator' that corrects outliers in the data with a\n'discriminator' that learns to discriminate the corrected data from the real\ndata, which may contain outliers. A key insight is that if the generator made a\nmistake in the correction, it would generate anomalies that are different from\nthe anomalies in the real data, so it serves as data augmentation for the\ndiscriminator learning. Different from typical GAN-based outlier detection\napproaches, our method employs the generator to detect outliers in an online\nmanner. The experimental results show that our method can detect event outliers\nmore accurately than the state-of-the-art approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16427v1",
    "published_date": "2024-11-25 14:29:39 UTC",
    "updated_date": "2024-11-25 14:29:39 UTC"
  },
  {
    "arxiv_id": "2411.16425v2",
    "title": "TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation",
    "authors": [
      "Linqing Zhong",
      "Chen Gao",
      "Zihan Ding",
      "Yue Liao",
      "Huimin Ma",
      "Shifeng Zhang",
      "Xu Zhou",
      "Si Liu"
    ],
    "abstract": "The Zero-Shot Object Navigation (ZSON) task requires embodied agents to find\na previously unseen object by navigating in unfamiliar environments. Such a\ngoal-oriented exploration heavily relies on the ability to perceive,\nunderstand, and reason based on the spatial information of the environment.\nHowever, current LLM-based approaches convert visual observations to language\ndescriptions and reason in the linguistic space, leading to the loss of spatial\ninformation. In this paper, we introduce TopV-Nav, an MLLM-based method that\ndirectly reasons on the top-view map with sufficient spatial information. To\nfully unlock the MLLM's spatial reasoning potential in top-view perspective, we\npropose the Adaptive Visual Prompt Generation (AVPG) method to adaptively\nconstruct semantically-rich top-view map. It enables the agent to directly\nutilize spatial information contained in the top-view map to conduct thorough\nreasoning. Besides, we design a Dynamic Map Scaling (DMS) mechanism to\ndynamically zoom top-view map at preferred scales, enhancing local fine-grained\nreasoning. Additionally, we devise a Potential Target Driven (PTD) mechanism to\npredict and to utilize target locations, facilitating global and human-like\nexploration. Experiments on MP3D and HM3D datasets demonstrate the superiority\nof our TopV-Nav.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.16425v2",
    "published_date": "2024-11-25 14:27:55 UTC",
    "updated_date": "2025-03-26 07:26:43 UTC"
  },
  {
    "arxiv_id": "2411.16422v1",
    "title": "Turbofan Engine Remaining Useful Life (RUL) Prediction Based on Bi-Directional Long Short-Term Memory (BLSTM)",
    "authors": [
      "Abedin Sherifi"
    ],
    "abstract": "The aviation industry is rapidly evolving, driven by advancements in\ntechnology. Turbofan engines used in commercial aerospace are very complex\nsystems. The majority of turbofan engine components are susceptible to\ndegradation over the life of their operation. Turbofan engine degradation has\nan impact to engine performance, operability, and reliability. Predicting\naccurate remaining useful life (RUL) of a commercial turbofan engine based on a\nvariety of complex sensor data is of paramount importance for the safety of the\npassengers, safety of flight, and for cost effective operations. That is why it\nis essential for turbofan engines to be monitored, controlled, and maintained.\nRUL predictions can either come from model-based or data-based approaches. The\nmodel-based approach can be very expensive due to the complexity of the\nmathematical models and the deep expertise that is required in the domain of\nphysical systems. The data-based approach is more frequently used nowadays\nthanks to the high computational complexity of computers, the advancements in\nMachine Learning (ML) models, and advancements in sensors. This paper is going\nto be focused on Bi-Directional Long Short-Term Memory (BLSTM) models but will\nalso provide a benchmark of several RUL prediction databased models. The\nproposed RUL prediction models are going to be evaluated based on engine\nfailure prediction benchmark dataset Commercial Modular Aero-Propulsion System\nSimulation (CMAPSS). The CMAPSS dataset is from NASA which contains turbofan\nengine run to failure events.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16422v1",
    "published_date": "2024-11-25 14:27:07 UTC",
    "updated_date": "2024-11-25 14:27:07 UTC"
  },
  {
    "arxiv_id": "2411.16408v1",
    "title": "Low-Data Classification of Historical Music Manuscripts: A Few-Shot Learning Approach",
    "authors": [
      "Elona Shatri",
      "Daniel Raymond",
      "George Fazekas"
    ],
    "abstract": "In this paper, we explore the intersection of technology and cultural\npreservation by developing a self-supervised learning framework for the\nclassification of musical symbols in historical manuscripts. Optical Music\nRecognition (OMR) plays a vital role in digitising and preserving musical\nheritage, but historical documents often lack the labelled data required by\ntraditional methods. We overcome this challenge by training a neural-based\nfeature extractor on unlabelled data, enabling effective classification with\nminimal samples. Key contributions include optimising crop preprocessing for a\nself-supervised Convolutional Neural Network and evaluating classification\nmethods, including SVM, multilayer perceptrons, and prototypical networks. Our\nexperiments yield an accuracy of 87.66\\%, showcasing the potential of AI-driven\nmethods to ensure the survival of historical music for future generations\nthrough advanced digital archiving techniques.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.IR",
    "comment": "6 pages, The Sixth IEEE international conference on Image Processing\n  Applications and Systems",
    "pdf_url": "http://arxiv.org/pdf/2411.16408v1",
    "published_date": "2024-11-25 14:14:25 UTC",
    "updated_date": "2024-11-25 14:14:25 UTC"
  },
  {
    "arxiv_id": "2411.16407v1",
    "title": "A Study on Unsupervised Domain Adaptation for Semantic Segmentation in the Era of Vision-Language Models",
    "authors": [
      "Manuel Schwonberg",
      "Claus Werner",
      "Hanno Gottschalk",
      "Carsten Meyer"
    ],
    "abstract": "Despite the recent progress in deep learning based computer vision, domain\nshifts are still one of the major challenges. Semantic segmentation for\nautonomous driving faces a wide range of domain shifts, e.g. caused by changing\nweather conditions, new geolocations and the frequent use of synthetic data in\nmodel training. Unsupervised domain adaptation (UDA) methods have emerged which\nadapt a model to a new target domain by only using unlabeled data of that\ndomain. The variety of UDA methods is large but all of them use ImageNet\npre-trained models. Recently, vision-language models have demonstrated strong\ngeneralization capabilities which may facilitate domain adaptation. We show\nthat simply replacing the encoder of existing UDA methods like DACS by a\nvision-language pre-trained encoder can result in significant performance\nimprovements of up to 10.0% mIoU on the GTA5-to-Cityscapes domain shift. For\nthe generalization performance to unseen domains, the newly employed\nvision-language pre-trained encoder provides a gain of up to 13.7% mIoU across\nthree unseen datasets. However, we find that not all UDA methods can be easily\npaired with the new encoder and that the UDA performance does not always\nlikewise transfer into generalization performance. Finally, we perform our\nexperiments on an adverse weather condition domain shift to further verify our\nfindings on a pure real-to-real domain shift.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to British Machine Vision Conference (BMVC) 2024: Workshop\n  on Robust Recognition in the Open World (RROW)",
    "pdf_url": "http://arxiv.org/pdf/2411.16407v1",
    "published_date": "2024-11-25 14:12:24 UTC",
    "updated_date": "2024-11-25 14:12:24 UTC"
  },
  {
    "arxiv_id": "2411.16405v1",
    "title": "Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN",
    "authors": [
      "Elona Shatri",
      "Kalikidhar Palavala",
      "George Fazekas"
    ],
    "abstract": "The generation of handwritten music sheets is a crucial step toward enhancing\nOptical Music Recognition (OMR) systems, which rely on large and diverse\ndatasets for optimal performance. However, handwritten music sheets, often\nfound in archives, present challenges for digitisation due to their fragility,\nvaried handwriting styles, and image quality. This paper addresses the data\nscarcity problem by applying Generative Adversarial Networks (GANs) to\nsynthesise realistic handwritten music sheets. We provide a comprehensive\nevaluation of three GAN models - DCGAN, ProGAN, and CycleWGAN - comparing their\nability to generate diverse and high-quality handwritten music images. The\nproposed CycleWGAN model, which enhances style transfer and training stability,\nsignificantly outperforms DCGAN and ProGAN in both qualitative and quantitative\nevaluations. CycleWGAN achieves superior performance, with an FID score of\n41.87, an IS of 2.29, and a KID of 0.05, making it a promising solution for\nimproving OMR systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, one page references, to appear on the IEEE Big Data 2024\n  2nd Workshop on AI Music Generation (AIMG 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.16405v1",
    "published_date": "2024-11-25 14:10:43 UTC",
    "updated_date": "2024-11-25 14:10:43 UTC"
  },
  {
    "arxiv_id": "2411.16403v1",
    "title": "Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey",
    "authors": [
      "Alexander Fichtl",
      "Juraj Vladika",
      "Georg Groh"
    ],
    "abstract": "Knowledge-enhanced language models (KELMs) have emerged as promising tools to\nbridge the gap between large-scale language models and domain-specific\nknowledge. KELMs can achieve higher factual accuracy and mitigate\nhallucinations by leveraging knowledge graphs (KGs). They are frequently\ncombined with adapter modules to reduce the computational load and risk of\ncatastrophic forgetting. In this paper, we conduct a systematic literature\nreview (SLR) on adapter-based approaches to KELMs. We provide a structured\noverview of existing methodologies in the field through quantitative and\nqualitative analysis and explore the strengths and potential shortcomings of\nindividual approaches. We show that general knowledge and domain-specific\napproaches have been frequently explored along with various adapter\narchitectures and downstream tasks. We particularly focused on the popular\nbiomedical domain, where we provided an insightful performance comparison of\nexisting KELMs. We outline the main trends and propose promising future\ndirections.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 4 figures. Published at KEOD24 via SciTePress",
    "pdf_url": "http://arxiv.org/pdf/2411.16403v1",
    "published_date": "2024-11-25 14:10:24 UTC",
    "updated_date": "2024-11-25 14:10:24 UTC"
  },
  {
    "arxiv_id": "2412.00061v1",
    "title": "Speculative Decoding with CTC-based Draft Model for LLM Inference Acceleration",
    "authors": [
      "Zhuofan Wen",
      "Shangtong Gui",
      "Yang Feng"
    ],
    "abstract": "Inference acceleration of large language models (LLMs) has been put forward\nin many application scenarios and speculative decoding has shown its advantage\nin addressing inference acceleration. Speculative decoding usually introduces a\ndraft model to assist the base LLM where the draft model produces drafts and\nthe base LLM verifies the draft for acceptance or rejection. In this framework,\nthe final inference speed is decided by the decoding speed of the draft model\nand the acceptance rate of the draft provided by the draft model. Currently the\nwidely used draft models usually generate draft tokens for the next several\npositions in a non-autoregressive way without considering the correlations\nbetween draft tokens. Therefore, it has a high decoding speed but an\nunsatisfactory acceptance rate. In this paper, we focus on how to improve the\nperformance of the draft model and aim to accelerate inference via a high\nacceptance rate. To this end, we propose a CTC-based draft model which\nstrengthens the correlations between draft tokens during the draft phase,\nthereby generating higher-quality draft candidate sequences. Experiment results\nshow that compared to strong baselines, the proposed method can achieve a\nhigher acceptance rate and hence a faster inference speed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00061v1",
    "published_date": "2024-11-25 14:10:21 UTC",
    "updated_date": "2024-11-25 14:10:21 UTC"
  },
  {
    "arxiv_id": "2411.17749v2",
    "title": "The Partially Observable Off-Switch Game",
    "authors": [
      "Andrew Garber",
      "Rohan Subramani",
      "Linus Luu",
      "Mark Bedaywi",
      "Stuart Russell",
      "Scott Emmons"
    ],
    "abstract": "A wide variety of goals could cause an AI to disable its off switch because\n\"you can't fetch the coffee if you're dead\" (Russell 2019). Prior theoretical\nwork on this shutdown problem assumes that humans know everything that AIs do.\nIn practice, however, humans have only limited information. Moreover, in many\nof the settings where the shutdown problem is most concerning, AIs might have\nvast amounts of private information. To capture these differences in knowledge,\nwe introduce the Partially Observable Off-Switch Game (PO-OSG), a\ngame-theoretic model of the shutdown problem with asymmetric information.\nUnlike when the human has full observability, we find that in optimal play,\neven AI agents assisting perfectly rational humans sometimes avoid shutdown. As\nexpected, increasing the amount of communication or information available\nalways increases (or leaves unchanged) the agents' expected common payoff. But\ncounterintuitively, introducing bounded communication can make the AI defer to\nthe human less in optimal play even though communication mitigates information\nasymmetry. In particular, communication sometimes enables new optimal behavior\nrequiring strategic AI deference to achieve outcomes that were previously\ninaccessible. Thus, designing safe artificial agents in the presence of\nasymmetric information requires careful consideration of the tradeoffs between\nmaximizing payoffs (potentially myopically) and maintaining AIs' incentives to\ndefer to humans.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.17749v2",
    "published_date": "2024-11-25 14:09:48 UTC",
    "updated_date": "2024-12-09 07:49:53 UTC"
  },
  {
    "arxiv_id": "2411.16391v2",
    "title": "Human-Calibrated Automated Testing and Validation of Generative Language Models",
    "authors": [
      "Agus Sudjianto",
      "Aijun Zhang",
      "Srinivas Neppalli",
      "Tarun Joshi",
      "Michal Malohlava"
    ],
    "abstract": "This paper introduces a comprehensive framework for the evaluation and\nvalidation of generative language models (GLMs), with a focus on\nRetrieval-Augmented Generation (RAG) systems deployed in high-stakes domains\nsuch as banking. GLM evaluation is challenging due to open-ended outputs and\nsubjective quality assessments. Leveraging the structured nature of RAG\nsystems, where generated responses are grounded in a predefined document\ncollection, we propose the Human-Calibrated Automated Testing (HCAT) framework.\nHCAT integrates a) automated test generation using stratified sampling, b)\nembedding-based metrics for explainable assessment of functionality, risk and\nsafety attributes, and c) a two-stage calibration approach that aligns\nmachine-generated evaluations with human judgments through probability\ncalibration and conformal prediction.\n  In addition, the framework includes robustness testing to evaluate model\nperformance against adversarial, out-of-distribution, and varied input\nconditions, as well as targeted weakness identification using marginal and\nbivariate analysis to pinpoint specific areas for improvement. This\nhuman-calibrated, multi-layered evaluation framework offers a scalable,\ntransparent, and interpretable approach to GLM assessment, providing a\npractical and reliable solution for deploying GLMs in applications where\naccuracy, transparency, and regulatory compliance are paramount.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16391v2",
    "published_date": "2024-11-25 13:53:36 UTC",
    "updated_date": "2024-12-07 16:12:38 UTC"
  },
  {
    "arxiv_id": "2411.16802v1",
    "title": "Leveraging Foundation Models To learn the shape of semi-fluid deformable objects",
    "authors": [
      "Omar El Assal",
      "Carlos M. Mateo",
      "Sebastien Ciron",
      "David Fofi"
    ],
    "abstract": "One of the difficulties imposed on the manipulation of deformable objects is\ntheir characterization and the detection of representative keypoints for the\npurpose of manipulation. A keen interest was manifested by researchers in the\nlast decade to characterize and manipulate deformable objects of non-fluid\nnature, such as clothes and ropes. Even though several propositions were made\nin the regard of object characterization, however researchers were always\nconfronted with the need of pixel-level information of the object through\nimages to extract relevant information. This usually is accomplished by means\nof segmentation networks trained on manually labeled data for this purpose. In\nthis paper, we address the subject of characterizing weld pool to define stable\nfeatures that serve as information for further motion control objectives. We\nachieve this by employing different pipelines. The first one consists of\ncharacterizing fluid deformable objects through the use of a generative model\nthat is trained using a teacher-student framework. And in the second one we\nleverage foundation models by using them as teachers to characterize the object\nin the image, without the need of any pre-training and any dataset. The\nperformance of knowledge distillation from foundation models into a smaller\ngenerative model shows prominent results in the characterization of deformable\nobjects. The student network was capable of learning to retrieve the keypoitns\nof the object with an error of 13.4 pixels. And the teacher was evaluated based\non its capacities to retrieve pixel level information represented by the object\nmask, with a mean Intersection Over Union (mIoU) of 75.26%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16802v1",
    "published_date": "2024-11-25 13:41:35 UTC",
    "updated_date": "2024-11-25 13:41:35 UTC"
  },
  {
    "arxiv_id": "2411.16380v1",
    "title": "Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence",
    "authors": [
      "Yuncheng Jiang",
      "Chun-Mei Feng",
      "Jinke Ren",
      "Jun Wei",
      "Zixun Zhang",
      "Yiwen Hu",
      "Yunbi Liu",
      "Rui Sun",
      "Xuemei Tang",
      "Juan Du",
      "Xiang Wan",
      "Yong Xu",
      "Bo Du",
      "Xin Gao",
      "Guangyu Wang",
      "Shaohua Zhou",
      "Shuguang Cui",
      "Rick Siow Mong Goh",
      "Yong Liu",
      "Zhen Li"
    ],
    "abstract": "Ultrasound imaging is widely used in clinical diagnosis due to its\nnon-invasive nature and real-time capabilities. However, conventional\nultrasound diagnostics face several limitations, including high dependence on\nphysician expertise and suboptimal image quality, which complicates\ninterpretation and increases the likelihood of diagnostic errors. Artificial\nintelligence (AI) has emerged as a promising solution to enhance clinical\ndiagnosis, particularly in detecting abnormalities across various biomedical\nimaging modalities. Nonetheless, current AI models for ultrasound imaging face\ncritical challenges. First, these models often require large volumes of labeled\nmedical data, raising concerns over patient privacy breaches. Second, most\nexisting models are task-specific, which restricts their broader clinical\nutility. To overcome these challenges, we present UltraFedFM, an innovative\nprivacy-preserving ultrasound foundation model. UltraFedFM is collaboratively\npre-trained using federated learning across 16 distributed medical institutions\nin 9 countries, leveraging a dataset of over 1 million ultrasound images\ncovering 19 organs and 10 ultrasound modalities. This extensive and diverse\ndata, combined with a secure training framework, enables UltraFedFM to exhibit\nstrong generalization and diagnostic capabilities. It achieves an average area\nunder the receiver operating characteristic curve of 0.927 for disease\ndiagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.\nNotably, UltraFedFM surpasses the diagnostic accuracy of mid-level\nultrasonographers and matches the performance of expert-level sonographers in\nthe joint diagnosis of 8 common systemic diseases. These findings indicate that\nUltraFedFM can significantly enhance clinical diagnostics while safeguarding\npatient privacy, marking an advancement in AI-driven ultrasound imaging for\nfuture clinical applications.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16380v1",
    "published_date": "2024-11-25 13:40:11 UTC",
    "updated_date": "2024-11-25 13:40:11 UTC"
  },
  {
    "arxiv_id": "2411.16370v3",
    "title": "A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation",
    "authors": [
      "M. M. A. Valiuddin",
      "R. J. G. van Sloun",
      "C. G. A. Viviers",
      "P. H. N. de With",
      "F. van der Sommen"
    ],
    "abstract": "Advancements in image segmentation play an integral role within the broad\nscope of Deep Learning-based Computer Vision. Furthermore, their widespread\napplicability in critical real-world tasks has resulted in challenges related\nto the reliability of such algorithms. Hence, uncertainty quantification has\nbeen extensively studied within this context, enabling the expression of model\nignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to\nprevent uninformed decision-making. Due to the rapid adoption of Convolutional\nNeural Network (CNN)-based segmentation models in high-stake applications, a\nsubstantial body of research has been published on this very topic, causing its\nswift expansion into a distinct field. This work provides a comprehensive\noverview of probabilistic segmentation, by discussing fundamental concepts of\nuncertainty quantification, governing advancements in the field as well as the\napplication to various tasks. Moreover, literature on both types of\nuncertainties trace back to four key applications: (1) to quantify statistical\ninconsistencies in the annotation process due ambiguous images, (2) correlating\nprediction error with uncertainty, (3) expanding the model hypothesis space for\nbetter generalization, and (4) Active Learning. An extensive discussion follows\nthat includes an overview of utilized datasets for each of the applications and\nevaluation of the available methods. We also highlight challenges related to\narchitectures, uncertainty quantification methods, standardization and\nbenchmarking, and finally end with recommendations for future work such as\nmethods based on single forward passes and models that appropriately leverage\nvolumetric data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, revised",
    "pdf_url": "http://arxiv.org/pdf/2411.16370v3",
    "published_date": "2024-11-25 13:26:09 UTC",
    "updated_date": "2025-03-12 09:51:17 UTC"
  },
  {
    "arxiv_id": "2411.16354v2",
    "title": "Scalable Parameter Design for Superconducting Quantum Circuits with Graph Neural Networks",
    "authors": [
      "Hao Ai",
      "Yu-xi Liu"
    ],
    "abstract": "To demonstrate supremacy of quantum computing, increasingly large-scale\nsuperconducting quantum computing chips are being designed and fabricated.\nHowever, the complexity of simulating quantum systems poses a significant\nchallenge to computer-aided design of quantum chips, especially for large-scale\nchips. Harnessing the scalability of graph neural networks (GNNs), we here\npropose a parameter designing algorithm for large-scale superconducting quantum\ncircuits. The algorithm depends on the so-called 'three-stair scaling'\nmechanism, which comprises two neural-network models: an evaluator supervisedly\ntrained on small-scale circuits for applying to medium-scale circuits, and a\ndesigner unsupervisedly trained on medium-scale circuits for applying to\nlarge-scale ones. We demonstrate our algorithm in mitigating quantum crosstalk\nerrors. Frequencies for both single- and two-qubit gates (corresponding to the\nparameters of nodes and edges) are considered simultaneously. Numerical results\nindicate that the well-trained designer achieves notable advantages in\nefficiency, effectiveness, and scalability. For example, for large-scale\nsuperconducting quantum circuits consisting of around 870 qubits, our\nGNNs-based algorithm achieves 51% of the errors produced by the\nstate-of-the-art algorithm, with a time reduction from 90 min to 27 sec.\nOverall, a better-performing and more scalable algorithm for designing\nparameters of superconducting quantum chips is proposed, which initially\ndemonstrates the advantages of applying GNNs in superconducting quantum chips.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16354v2",
    "published_date": "2024-11-25 13:04:53 UTC",
    "updated_date": "2025-02-07 13:28:59 UTC"
  },
  {
    "arxiv_id": "2411.16353v2",
    "title": "The Two-Hop Curse: LLMs trained on A$\\rightarrow$B, B$\\rightarrow$C fail to learn A$\\rightarrow$C",
    "authors": [
      "Mikita Balesni",
      "Tomek Korbak",
      "Owain Evans"
    ],
    "abstract": "[Notice: This version is outdated. Recent research contradicts some key\nclaims; we are working on a major revision with more nuanced analysis. Please\nwait for the updated version.]\n  While LLMs excel at multi-hop questions (e.g. \"Who is the spouse of the\nperformer of Imagine?\") when using chain-of-thought reasoning (CoT), they\nstruggle when forced to reason internally (without CoT). Previous work on the\nsize and nature of this gap produced mixed evidence with inconclusive results.\nIn this paper, we introduce a controlled setting for investigating two-hop\nreasoning in LLMs, where the above-chance performance constitutes undeniable\nevidence for latent reasoning. We fine-tune LLMs (including Llama 3 8B Instruct\nand GPT-4o) on fictional facts and confirm that they generalize to answering\ntwo-hop questions about them using CoT. We find that models can perform latent\nreasoning when facts appear together during training or in the prompt. However,\nto our surprise, models completely fail at two-hop reasoning without CoT when\nlearned facts only appear in different documents, achieving chance-level\naccuracy and chance-level test loss. We call this complete failure to compose\nseparately learned facts the Two-Hop Curse. Moreover, we evaluate 9 frontier\nLLMs on real-world facts, finding that models completely fail at two-hop no-CoT\nreasoning for over half of question categories while maintaining partial\nsuccess with CoT across most categories. These results suggest that LLMs lack a\ngeneral capability for latent multi-hop reasoning independent of the question\ntype.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16353v2",
    "published_date": "2024-11-25 13:04:28 UTC",
    "updated_date": "2025-01-06 17:37:54 UTC"
  },
  {
    "arxiv_id": "2411.16337v1",
    "title": "Can AI grade your essays? A comparative analysis of large language models and teacher ratings in multidimensional essay scoring",
    "authors": [
      "Kathrin Seßler",
      "Maurice Fürstenberg",
      "Babette Bühler",
      "Enkelejda Kasneci"
    ],
    "abstract": "The manual assessment and grading of student writing is a time-consuming yet\ncritical task for teachers. Recent developments in generative AI, such as large\nlanguage models, offer potential solutions to facilitate essay-scoring tasks\nfor teachers. In our study, we evaluate the performance and reliability of both\nopen-source and closed-source LLMs in assessing German student essays,\ncomparing their evaluations to those of 37 teachers across 10 pre-defined\ncriteria (i.e., plot logic, expression). A corpus of 20 real-world essays from\nYear 7 and 8 students was analyzed using five LLMs: GPT-3.5, GPT-4, o1, LLaMA\n3-70B, and Mixtral 8x7B, aiming to provide in-depth insights into LLMs' scoring\ncapabilities. Closed-source GPT models outperform open-source models in both\ninternal consistency and alignment with human ratings, particularly excelling\nin language-related criteria. The novel o1 model outperforms all other LLMs,\nachieving Spearman's $r = .74$ with human assessments in the overall score, and\nan internal consistency of $ICC=.80$. These findings indicate that LLM-based\nassessment can be a useful tool to reduce teacher workload by supporting the\nevaluation of essays, especially with regard to language-related criteria.\nHowever, due to their tendency for higher scores, the models require further\nrefinement to better capture aspects of content quality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LAK '25",
    "pdf_url": "http://arxiv.org/pdf/2411.16337v1",
    "published_date": "2024-11-25 12:33:14 UTC",
    "updated_date": "2024-11-25 12:33:14 UTC"
  },
  {
    "arxiv_id": "2411.16326v2",
    "title": "Brain-like emergent properties in deep networks: impact of network architecture, datasets and training",
    "authors": [
      "Niranjan Rajesh",
      "Georgin Jacob",
      "SP Arun"
    ],
    "abstract": "Despite the rapid pace at which deep networks are improving on standardized\nvision benchmarks, they are still outperformed by humans on real-world vision\ntasks. This paradoxical lack of generalization could be addressed by making\ndeep networks more brain-like. Although several benchmarks have compared the\nability of deep networks to predict brain responses to natural images, they do\nnot capture subtle but important brain-like emergent properties. To resolve\nthis issue, we report several well-known perceptual and neural emergent\nproperties that can be tested on deep networks. To evaluate how various design\nfactors impact brain-like properties, we systematically evaluated over 30\nstate-of-the-art networks with varying network architectures, training datasets\nand training regimes. Our main findings are as follows. First, network\narchitecture had the strongest impact on brain-like properties compared to\ndataset and training regime variations. Second, networks varied widely in their\nalignment to the brain with no single network outperforming all others. Taken\ntogether, our results complement existing benchmarks by revealing brain-like\nproperties that are either emergent or lacking in state-of-the-art deep\nnetworks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16326v2",
    "published_date": "2024-11-25 12:22:36 UTC",
    "updated_date": "2024-12-09 08:18:35 UTC"
  },
  {
    "arxiv_id": "2411.16318v1",
    "title": "One Diffusion to Generate Them All",
    "authors": [
      "Duong H. Le",
      "Tuan Pham",
      "Sangho Lee",
      "Christopher Clark",
      "Aniruddha Kembhavi",
      "Stephan Mandt",
      "Ranjay Krishna",
      "Jiasen Lu"
    ],
    "abstract": "We introduce OneDiffusion, a versatile, large-scale diffusion model that\nseamlessly supports bidirectional image synthesis and understanding across\ndiverse tasks. It enables conditional generation from inputs such as text,\ndepth, pose, layout, and semantic maps, while also handling tasks like image\ndeblurring, upscaling, and reverse processes such as depth estimation and\nsegmentation. Additionally, OneDiffusion allows for multi-view generation,\ncamera pose estimation, and instant personalization using sequential image\ninputs. Our model takes a straightforward yet effective approach by treating\nall tasks as frame sequences with varying noise scales during training,\nallowing any frame to act as a conditioning image at inference time. Our\nunified training framework removes the need for specialized architectures,\nsupports scalable multi-task training, and adapts smoothly to any resolution,\nenhancing both generalization and scalability. Experimental results demonstrate\ncompetitive performance across tasks in both generation and prediction such as\ntext-to-image, multiview generation, ID preservation, depth estimation and\ncamera pose estimation despite relatively small training dataset. Our code and\ncheckpoint are freely available at https://github.com/lehduong/OneDiffusion",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "two first authors contribute equally",
    "pdf_url": "http://arxiv.org/pdf/2411.16318v1",
    "published_date": "2024-11-25 12:11:05 UTC",
    "updated_date": "2024-11-25 12:11:05 UTC"
  },
  {
    "arxiv_id": "2411.16313v2",
    "title": "CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning",
    "authors": [
      "Duo Wu",
      "Jinghe Wang",
      "Yuan Meng",
      "Yanning Zhang",
      "Le Sun",
      "Zhi Wang"
    ],
    "abstract": "Utilizing large language models (LLMs) for tool planning has emerged as a\npromising avenue for developing general AI systems, where LLMs automatically\nschedule external tools (e.g. vision models) to tackle complex tasks based on\ntask descriptions. To push this paradigm toward practical applications, it is\ncrucial for LLMs to consider tool execution costs (e.g. execution time) for\ntool planning. Unfortunately, prior studies overlook the tool execution costs,\nleading to the generation of expensive plans of which the costs outweigh task\nperformance. To fill this gap, we propose the Cost-Aware Tool Planning with\nLLMs (CATP-LLM) framework, which for the first time provides a coherent design\nto empower LLMs for cost-aware tool planning. Specifically, CATP-LLM\nincorporates a tool planning language to enhance the LLM to generate\nnon-sequential plans of multiple branches for efficient concurrent tool\nexecution and cost reduction. Moreover, it further designs a cost-aware offline\nreinforcement learning algorithm to fine-tune the LLM to optimize the\nperformance-cost trade-off in tool planning. In lack of public cost-related\ndatasets, we further present OpenCATP, the first platform for cost-aware\nplanning evaluation. Experiments on OpenCATP show that CATP-LLM outperforms\nGPT-4 even when using Llama2-7B as its backbone, with the average improvement\nof 28.2%-30.2% higher plan performance and 24.7%-45.8% lower costs even on the\nchallenging planning tasks. The codes and dataset will be available at:\nhttps://github.com/duowuyms/OpenCATP-LLM.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "In submission",
    "pdf_url": "http://arxiv.org/pdf/2411.16313v2",
    "published_date": "2024-11-25 12:05:49 UTC",
    "updated_date": "2025-04-06 15:06:17 UTC"
  },
  {
    "arxiv_id": "2411.16305v1",
    "title": "Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems",
    "authors": [
      "Magdalena Kaiser",
      "Patrick Ernst",
      "György Szarvas"
    ],
    "abstract": "Task-oriented Dialog (ToD) systems have to solve multiple subgoals to\naccomplish user goals, whereas feedback is often obtained only at the end of\nthe dialog. In this work, we propose SUIT (SUbgoal-aware ITerative Training),\nan iterative training approach for improving ToD systems. We sample dialogs\nfrom the model we aim to improve and determine subgoals that contribute to\ndialog success using distant supervision to obtain high quality training\nsamples. We show how this data improves supervised fine-tuning or,\nalternatively, preference learning results. SUIT is able to iteratively\ngenerate more data instead of relying on fixed static sets. SUIT reaches new\nstate-of-the-art performance on a popular ToD benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16305v1",
    "published_date": "2024-11-25 11:47:31 UTC",
    "updated_date": "2024-11-25 11:47:31 UTC"
  },
  {
    "arxiv_id": "2412.07782v1",
    "title": "Trustworthy artificial intelligence in the energy sector: Landscape analysis and evaluation framework",
    "authors": [
      "Sotiris Pelekis",
      "Evangelos Karakolis",
      "George Lampropoulos",
      "Spiros Mouzakitis",
      "Ourania Markaki",
      "Christos Ntanos",
      "Dimitris Askounis"
    ],
    "abstract": "The present study aims to evaluate the current fuzzy landscape of Trustworthy\nAI (TAI) within the European Union (EU), with a specific focus on the energy\nsector. The analysis encompasses legal frameworks, directives, initiatives, and\nstandards like the AI Ethics Guidelines for Trustworthy AI (EGTAI), the\nAssessment List for Trustworthy AI (ALTAI), the AI act, and relevant\nCEN-CENELEC standardization efforts, as well as EU-funded projects such as\nAI4EU and SHERPA. Subsequently, we introduce a new TAI application framework,\ncalled E-TAI, tailored for energy applications, including smart grid and smart\nbuilding systems. This framework draws inspiration from EGTAI but is customized\nfor AI systems in the energy domain. It is designed for stakeholders in\nelectrical power and energy systems (EPES), including researchers, developers,\nand energy experts linked to transmission system operators, distribution system\noperators, utilities, and aggregators. These stakeholders can utilize E-TAI to\ndevelop and evaluate AI services for the energy sector with a focus on ensuring\ntrustworthiness throughout their development and iterative assessment\nprocesses.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.07782v1",
    "published_date": "2024-11-25 11:39:55 UTC",
    "updated_date": "2024-11-25 11:39:55 UTC"
  },
  {
    "arxiv_id": "2411.16300v3",
    "title": "BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment",
    "authors": [
      "Shaolei Zhang",
      "Kehao Zhang",
      "Qingkai Fang",
      "Shoutao Guo",
      "Yan Zhou",
      "Xiaodong Liu",
      "Yang Feng"
    ],
    "abstract": "Large language models (LLMs), with their powerful generative capabilities and\nvast knowledge, empower various tasks in everyday life. However, these\nabilities are primarily concentrated in high-resource languages, leaving\nlow-resource languages with weaker generative capabilities and relatively\nlimited knowledge. Enhancing the multilingual capabilities of LLMs is therefore\ncrucial for serving over 100 linguistic communities worldwide. An intuitive\napproach to enhance the multilingual capabilities would be to construct\ninstruction data for various languages, but constructing instruction data for\nover 100 languages is prohibitively costly. In this paper, we introduce BayLing\n2, which efficiently transfers generative capabilities and knowledge from\nhigh-resource languages to low-resource languages through language alignment.\nTo achieve this, we constructed a dataset of 3.2 million instructions,\ncomprising high-resource language instructions (Chinese and English) and\ncross-lingual instructions for 100+ languages and performed instruction tuning\nbased on the dataset to facilitate the capability transfer between languages.\nUsing Llama as the foundation model, we developed BayLing-2-7B, BayLing-2-13B,\nand BayLing-2-8B, and conducted a comprehensive evaluation of BayLing. For\nmultilingual translation across 100+ languages, BayLing shows superior\nperformance compared to open-source models of similar scale. For multilingual\nknowledge and understanding benchmarks, BayLing achieves significant\nimprovements across over 20 low-resource languages, demonstrating its\ncapability of effective knowledge transfer from high-resource to low-resource\nlanguages. Furthermore, results on English benchmarks indicate that BayLing\nmaintains high performance in highresource languages while enhancing the\nperformance in low-resource languages. Demo, homepage, code and models of\nBayLing are available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "BayLing 2's online demo: http://nlp.ict.ac.cn/bayling/demo. BayLing\n  2's code and models: https://github.com/ictnlp/BayLing",
    "pdf_url": "http://arxiv.org/pdf/2411.16300v3",
    "published_date": "2024-11-25 11:35:08 UTC",
    "updated_date": "2024-12-19 15:11:46 UTC"
  },
  {
    "arxiv_id": "2411.16276v1",
    "title": "The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024",
    "authors": [
      "Mohammadreza Molavi",
      "Reza Khodadadi"
    ],
    "abstract": "This paper introduces an efficient and accurate pipeline for text-dependent\nspeaker verification (TDSV), designed to address the need for high-performance\nbiometric systems. The proposed system incorporates a Fast-Conformer-based ASR\nmodule to validate speech content, filtering out Target-Wrong (TW) and\nImpostor-Wrong (IW) trials. For speaker verification, we propose a feature\nfusion approach that combines speaker embeddings extracted from wav2vec-BERT\nand ReDimNet models to create a unified speaker representation. This system\nachieves competitive results on the TDSV 2024 Challenge test set, with a\nnormalized min-DCF of 0.0452 (rank 2), highlighting its effectiveness in\nbalancing accuracy and robustness.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16276v1",
    "published_date": "2024-11-25 10:53:45 UTC",
    "updated_date": "2024-11-25 10:53:45 UTC"
  },
  {
    "arxiv_id": "2411.16262v1",
    "title": "Probing for Consciousness in Machines",
    "authors": [
      "Mathis Immertreu",
      "Achim Schilling",
      "Andreas Maier",
      "Patrick Krauss"
    ],
    "abstract": "This study explores the potential for artificial agents to develop core\nconsciousness, as proposed by Antonio Damasio's theory of consciousness.\nAccording to Damasio, the emergence of core consciousness relies on the\nintegration of a self model, informed by representations of emotions and\nfeelings, and a world model. We hypothesize that an artificial agent, trained\nvia reinforcement learning (RL) in a virtual environment, can develop\npreliminary forms of these models as a byproduct of its primary task. The\nagent's main objective is to learn to play a video game and explore the\nenvironment. To evaluate the emergence of world and self models, we employ\nprobes-feedforward classifiers that use the activations of the trained agent's\nneural networks to predict the spatial positions of the agent itself. Our\nresults demonstrate that the agent can form rudimentary world and self models,\nsuggesting a pathway toward developing machine consciousness. This research\nprovides foundational insights into the capabilities of artificial agents in\nmirroring aspects of human consciousness, with implications for future\nadvancements in artificial intelligence.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16262v1",
    "published_date": "2024-11-25 10:27:07 UTC",
    "updated_date": "2024-11-25 10:27:07 UTC"
  },
  {
    "arxiv_id": "2411.16797v2",
    "title": "Enhancing Answer Reliability Through Inter-Model Consensus of Large Language Models",
    "authors": [
      "Alireza Amiri-Margavi",
      "Iman Jebellat",
      "Ehsan Jebellat",
      "Seyed Pouyan Mousavi Davoudi"
    ],
    "abstract": "We propose a collaborative framework in which multiple large language models\n-- including GPT-4-0125-preview, Meta-LLaMA-3-70B-Instruct, Claude-3-Opus, and\nGemini-1.5-Flash -- generate and answer complex, PhD-level statistical\nquestions when definitive ground truth is unavailable. Our study examines how\ninter-model consensus improves both response reliability and identifies the\nquality of the generated questions. Employing chi-square tests, Fleiss' Kappa,\nand confidence interval analysis, we quantify consensus rates and inter-rater\nagreement to assess both response precision and question quality. Key results\nindicate that Claude and GPT-4 produce well-structured, less ambiguous\nquestions with a higher inter-rater agreement, as shown by narrower confidence\nintervals and greater alignment with question-generating models. In contrast,\nGemini and LLaMA exhibit greater variability and lower reliability in question\nformulation. These findings demonstrate that collaborative interactions among\nlarge language models enhance response reliability and provide valuable\ninsights for optimizing AI-driven collaborative reasoning systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.16797v2",
    "published_date": "2024-11-25 10:18:17 UTC",
    "updated_date": "2025-02-24 00:26:55 UTC"
  },
  {
    "arxiv_id": "2411.16250v1",
    "title": "Diagnosis of diabetic retinopathy using machine learning & deep learning technique",
    "authors": [
      "Eric Shah",
      "Jay Patel",
      "Mr. Vishal Katheriya",
      "Parth Pataliya"
    ],
    "abstract": "Fundus images are widely used for diagnosing various eye diseases, such as\ndiabetic retinopathy, glaucoma, and age-related macular degeneration. However,\nmanual analysis of fundus images is time-consuming and prone to errors. In this\nreport, we propose a novel method for fundus detection using object detection\nand machine learning classification techniques. We use a YOLO_V8 to perform\nobject detection on fundus images and locate the regions of interest (ROIs)\nsuch as optic disc, optic cup and lesions. We then use machine learning SVM\nclassification algorithms to classify the ROIs into different DR stages based\non the presence or absence of pathological signs such as exudates,\nmicroaneurysms, and haemorrhages etc. Our method achieves 84% accuracy and\nefficiency for fundus detection and can be applied for retinal fundus disease\ntriage, especially in remote areas around the world.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 11 figures, Journal Paper",
    "pdf_url": "http://arxiv.org/pdf/2411.16250v1",
    "published_date": "2024-11-25 10:09:37 UTC",
    "updated_date": "2024-11-25 10:09:37 UTC"
  },
  {
    "arxiv_id": "2411.16206v2",
    "title": "A Simple and Efficient Approach to Batch Bayesian Optimization",
    "authors": [
      "Dawei Zhan",
      "Zhaoxi Zeng",
      "Shuoxiao Wei",
      "Ping Wu"
    ],
    "abstract": "Extending Bayesian optimization to batch evaluation can enable the designer\nto make the most use of parallel computing technology. However, most of current\nbatch approaches do not scale well with the batch size. That is, their\nperformances deteriorate dramatically as the batch size increases. To address\nthis issue, we propose a simple and efficient approach to extend Bayesian\noptimization to large-scale batch evaluation in this work. Different from\nexisting batch approaches, the idea of the new approach is to draw a batch of\naxis-aligned subspaces of the original problem and select one acquisition point\nfrom each subspace. To achieve this, we propose the expected subspace\nimprovement criterion to measure the amount of the improvement that a candidate\npoint can achieve within a certain axis-aligned subspace. By optimizing these\nexpected subspace improvement functions simultaneously, we can get a batch of\nquery points for parallel evaluation. Numerical experiments show that our\nproposed approach can speedup the convergence significantly when compared with\nthe sequential Bayesian optimization algorithm, and performs very competitively\nwhen compared with seven batch Bayesian optimization algorithms. A Matlab\nimplementation of the proposed approach is available at\nhttps://github.com/zhandawei/Expected_Subspace_Improvement_Batch_Bayesian_Optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16206v2",
    "published_date": "2024-11-25 09:14:09 UTC",
    "updated_date": "2025-04-24 05:20:06 UTC"
  },
  {
    "arxiv_id": "2411.16791v1",
    "title": "What can LLM tell us about cities?",
    "authors": [
      "Zhuoheng Li",
      "Yaochen Wang",
      "Zhixue Song",
      "Yuqi Huang",
      "Rui Bao",
      "Guanjie Zheng",
      "Zhenhui Jessie Li"
    ],
    "abstract": "This study explores the capabilities of large language models (LLMs) in\nproviding knowledge about cities and regions on a global scale. We employ two\nmethods: directly querying the LLM for target variable values and extracting\nexplicit and implicit features from the LLM correlated with the target\nvariable. Our experiments reveal that LLMs embed a broad but varying degree of\nknowledge across global cities, with ML models trained on LLM-derived features\nconsistently leading to improved predictive accuracy. Additionally, we observe\nthat LLMs demonstrate a certain level of knowledge across global cities on all\ncontinents, but it is evident when they lack knowledge, as they tend to\ngenerate generic or random outputs for unfamiliar tasks. These findings suggest\nthat LLMs can offer new opportunities for data-driven decision-making in the\nstudy of cities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16791v1",
    "published_date": "2024-11-25 09:07:56 UTC",
    "updated_date": "2024-11-25 09:07:56 UTC"
  },
  {
    "arxiv_id": "2412.00060v1",
    "title": "MOSABench: Multi-Object Sentiment Analysis Benchmark for Evaluating Multimodal Large Language Models Understanding of Complex Image",
    "authors": [
      "Shezheng Song",
      "Chengxiang He",
      "Shasha Li",
      "Shan Zhao",
      "Chengyu Wang",
      "Tianwei Yan",
      "Xiaopeng Li",
      "Qian Wan",
      "Jun Ma",
      "Jie Yu",
      "Xiaoguang Mao"
    ],
    "abstract": "Multimodal large language models (MLLMs) have shown remarkable progress in\nhigh-level semantic tasks such as visual question answering, image captioning,\nand emotion recognition. However, despite advancements, there remains a lack of\nstandardized benchmarks for evaluating MLLMs performance in multi-object\nsentiment analysis, a key task in semantic understanding. To address this gap,\nwe introduce MOSABench, a novel evaluation dataset designed specifically for\nmulti-object sentiment analysis. MOSABench includes approximately 1,000 images\nwith multiple objects, requiring MLLMs to independently assess the sentiment of\neach object, thereby reflecting real-world complexities. Key innovations in\nMOSABench include distance-based target annotation, post-processing for\nevaluation to standardize outputs, and an improved scoring mechanism. Our\nexperiments reveal notable limitations in current MLLMs: while some models,\nlike mPLUG-owl and Qwen-VL2, demonstrate effective attention to\nsentiment-relevant features, others exhibit scattered focus and performance\ndeclines, especially as the spatial distance between objects increases. This\nresearch underscores the need for MLLMs to enhance accuracy in complex,\nmulti-object sentiment analysis tasks and establishes MOSABench as a\nfoundational tool for advancing sentiment analysis capabilities in MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00060v1",
    "published_date": "2024-11-25 09:00:36 UTC",
    "updated_date": "2024-11-25 09:00:36 UTC"
  },
  {
    "arxiv_id": "2411.17746v1",
    "title": "UVCG: Leveraging Temporal Consistency for Universal Video Protection",
    "authors": [
      "KaiZhou Li",
      "Jindong Gu",
      "Xinchun Yu",
      "Junjie Cao",
      "Yansong Tang",
      "Xiao-Ping Zhang"
    ],
    "abstract": "The security risks of AI-driven video editing have garnered significant\nattention. Although recent studies indicate that adding perturbations to images\ncan protect them from malicious edits, directly applying image-based methods to\nperturb each frame in a video becomes ineffective, as video editing techniques\nleverage the consistency of inter-frame information to restore individually\nperturbed content. To address this challenge, we leverage the temporal\nconsistency of video content to propose a straightforward and efficient, yet\nhighly effective and broadly applicable approach, Universal Video Consistency\nGuard (UVCG). UVCG embeds the content of another video(target video) within a\nprotected video by introducing continuous, imperceptible perturbations which\nhas the ability to force the encoder of editing models to map continuous inputs\nto misaligned continuous outputs, thereby inhibiting the generation of videos\nconsistent with the intended textual prompts. Additionally leveraging\nsimilarity in perturbations between adjacent frames, we improve the\ncomputational efficiency of perturbation generation by employing a\nperturbation-reuse strategy. We applied UVCG across various versions of Latent\nDiffusion Models (LDM) and assessed its effectiveness and generalizability\nacross multiple LDM-based editing pipelines. The results confirm the\neffectiveness, transferability, and efficiency of our approach in safeguarding\nvideo content from unauthorized modifications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.17746v1",
    "published_date": "2024-11-25 08:48:54 UTC",
    "updated_date": "2024-11-25 08:48:54 UTC"
  },
  {
    "arxiv_id": "2411.16189v1",
    "title": "Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models",
    "authors": [
      "Zhihua Duan",
      "Jialin Wang"
    ],
    "abstract": "Large Language Models (LLMs) still face challenges when dealing with complex\nreasoning tasks, often resulting in hallucinations, which limit the practical\napplication of LLMs. To alleviate this issue, this paper proposes a new method\nthat integrates different LLMs to expand the knowledge boundary, reduce\ndependence on a single model, and promote in-depth debate among agents. The\nmain contributions include: 1) Introducing third-party LLMs to adjust the\nattention weights of agents through uncertainty estimation and confidence\nanalysis, optimizing consensus formation in multi-agent systems; 2) Experiments\non arithmetic datasets have validated the effectiveness of the method,\nsurpassing traditional multi-agent baselines. This research provides a new\nperspective for large models to alleviate hallucination phenomena when dealing\nwith complex tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16189v1",
    "published_date": "2024-11-25 08:42:33 UTC",
    "updated_date": "2024-11-25 08:42:33 UTC"
  },
  {
    "arxiv_id": "2411.16785v1",
    "title": "MAGiC-SLAM: Multi-Agent Gaussian Globally Consistent SLAM",
    "authors": [
      "Vladimir Yugay",
      "Theo Gevers",
      "Martin R. Oswald"
    ],
    "abstract": "Simultaneous localization and mapping (SLAM) systems with novel view\nsynthesis capabilities are widely used in computer vision, with applications in\naugmented reality, robotics, and autonomous driving. However, existing\napproaches are limited to single-agent operation. Recent work has addressed\nthis problem using a distributed neural scene representation. Unfortunately,\nexisting methods are slow, cannot accurately render real-world data, are\nrestricted to two agents, and have limited tracking accuracy. In contrast, we\npropose a rigidly deformable 3D Gaussian-based scene representation that\ndramatically speeds up the system. However, improving tracking accuracy and\nreconstructing a globally consistent map from multiple agents remains\nchallenging due to trajectory drift and discrepancies across agents'\nobservations. Therefore, we propose new tracking and map-merging mechanisms and\nintegrate loop closure in the Gaussian-based SLAM pipeline. We evaluate\nMAGiC-SLAM on synthetic and real-world datasets and find it more accurate and\nfaster than the state of the art.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16785v1",
    "published_date": "2024-11-25 08:34:01 UTC",
    "updated_date": "2024-11-25 08:34:01 UTC"
  },
  {
    "arxiv_id": "2411.16781v2",
    "title": "UniPose: A Unified Multimodal Framework for Human Pose Comprehension, Generation and Editing",
    "authors": [
      "Yiheng Li",
      "Ruibing Hou",
      "Hong Chang",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "abstract": "Human pose plays a crucial role in the digital age. While recent works have\nachieved impressive progress in understanding and generating human poses, they\noften support only a single modality of control signals and operate in\nisolation, limiting their application in real-world scenarios. This paper\npresents UniPose, a framework employing Large Language Models (LLMs) to\ncomprehend, generate, and edit human poses across various modalities, including\nimages, text, and 3D SMPL poses. Specifically, we apply a pose tokenizer to\nconvert 3D poses into discrete pose tokens, enabling seamless integration into\nthe LLM within a unified vocabulary. To further enhance the fine-grained pose\nperception capabilities, we facilitate UniPose with a mixture of visual\nencoders, among them a pose-specific visual encoder. Benefiting from a unified\nlearning strategy, UniPose effectively transfers knowledge across different\npose-relevant tasks, adapts to unseen tasks, and exhibits extended\ncapabilities. This work serves as the first attempt at building a\ngeneral-purpose framework for pose comprehension, generation, and editing.\nExtensive experiments highlight UniPose's competitive and even superior\nperformance across various pose-relevant tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16781v2",
    "published_date": "2024-11-25 08:06:30 UTC",
    "updated_date": "2025-03-29 03:35:20 UTC"
  },
  {
    "arxiv_id": "2411.16173v2",
    "title": "SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis",
    "authors": [
      "Junho Kim",
      "Hyunjun Kim",
      "Hosu Lee",
      "Yong Man Ro"
    ],
    "abstract": "Despite advances in Large Multi-modal Models, applying them to long and\nuntrimmed video content remains challenging due to limitations in context\nlength and substantial memory overhead. These constraints often lead to\nsignificant information loss and reduced relevance in the model responses. With\nthe exponential growth of video data across web platforms, understanding\nlong-form video is crucial for advancing generalized intelligence. In this\npaper, we introduce SALOVA: Segment-Augmented LOng Video Assistant, a novel\nvideo-LLM framework designed to enhance the comprehension of lengthy video\ncontent through targeted retrieval process. We address two main challenges to\nachieve it: (i) We present the SceneWalk dataset, a high-quality collection of\n87.8K long videos, each densely captioned at the segment level to enable models\nto capture scene continuity and maintain rich descriptive context. (ii) We\ndevelop robust architectural designs integrating dynamic routing mechanism and\nspatio-temporal projector to efficiently retrieve and process relevant video\nsegments based on user queries. Our framework mitigates the limitations of\ncurrent video-LMMs by allowing for precise identification and retrieval of\nrelevant video segments in response to queries, thereby improving the\ncontextual relevance of the generated responses. Through extensive experiments,\nSALOVA demonstrates enhanced capability in processing complex long-form videos,\nshowing significant capability to maintain contextual integrity across extended\nsequences.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://ivy-lvlm.github.io/SALOVA/",
    "pdf_url": "http://arxiv.org/pdf/2411.16173v2",
    "published_date": "2024-11-25 08:04:47 UTC",
    "updated_date": "2025-03-21 10:44:15 UTC"
  },
  {
    "arxiv_id": "2411.16169v2",
    "title": "Local and Global Feature Attention Fusion Network for Face Recognition",
    "authors": [
      "Wang Yu",
      "Wei Wei"
    ],
    "abstract": "Recognition of low-quality face images remains a challenge due to invisible\nor deformation in partial facial regions. For low-quality images dominated by\nmissing partial facial regions, local region similarity contributes more to\nface recognition (FR). Conversely, in cases dominated by local face\ndeformation, excessive attention to local regions may lead to misjudgments,\nwhile global features exhibit better robustness. However, most of the existing\nFR methods neglect the bias in feature quality of low-quality images introduced\nby different factors. To address this issue, we propose a Local and Global\nFeature Attention Fusion (LGAF) network based on feature quality. The network\nadaptively allocates attention between local and global features according to\nfeature quality and obtains more discriminative and high-quality face features\nthrough local and global information complementarity. In addition, to\neffectively obtain fine-grained information at various scales and increase the\nseparability of facial features in high-dimensional space, we introduce a\nMulti-Head Multi-Scale Local Feature Extraction (MHMS) module. Experimental\nresults demonstrate that the LGAF achieves the best average performance on $4$\nvalidation sets (CFP-FP, CPLFW, AgeDB, and CALFW), and the performance on\nTinyFace and SCFace outperforms the state-of-the-art methods (SoTA).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16169v2",
    "published_date": "2024-11-25 07:55:57 UTC",
    "updated_date": "2024-12-06 02:32:23 UTC"
  },
  {
    "arxiv_id": "2412.05299v2",
    "title": "Specifications: The missing link to making the development of LLM systems an engineering discipline",
    "authors": [
      "Ion Stoica",
      "Matei Zaharia",
      "Joseph Gonzalez",
      "Ken Goldberg",
      "Koushik Sen",
      "Hao Zhang",
      "Anastasios Angelopoulos",
      "Shishir G. Patil",
      "Lingjiao Chen",
      "Wei-Lin Chiang",
      "Jared Q. Davis"
    ],
    "abstract": "Despite the significant strides made by generative AI in just a few short\nyears, its future progress is constrained by the challenge of building modular\nand robust systems. This capability has been a cornerstone of past\ntechnological revolutions, which relied on combining components to create\nincreasingly sophisticated and reliable systems. Cars, airplanes, computers,\nand software consist of components-such as engines, wheels, CPUs, and\nlibraries-that can be assembled, debugged, and replaced. A key tool for\nbuilding such reliable and modular systems is specification: the precise\ndescription of the expected behavior, inputs, and outputs of each component.\nHowever, the generality of LLMs and the inherent ambiguity of natural language\nmake defining specifications for LLM-based components (e.g., agents) both a\nchallenging and urgent problem. In this paper, we discuss the progress the\nfield has made so far-through advances like structured outputs, process\nsupervision, and test-time compute-and outline several future directions for\nresearch to enable the development of modular and reliable LLM-based systems\nthrough improved specifications.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05299v2",
    "published_date": "2024-11-25 07:48:31 UTC",
    "updated_date": "2024-12-16 08:17:09 UTC"
  },
  {
    "arxiv_id": "2411.16778v2",
    "title": "GEMeX: A Large-Scale, Groundable, and Explainable Medical VQA Benchmark for Chest X-ray Diagnosis",
    "authors": [
      "Bo Liu",
      "Ke Zou",
      "Liming Zhan",
      "Zexin Lu",
      "Xiaoyu Dong",
      "Yidi Chen",
      "Chengqiang Xie",
      "Jiannong Cao",
      "Xiao-Ming Wu",
      "Huazhu Fu"
    ],
    "abstract": "Medical Visual Question Answering (Med-VQA) combines computer vision and\nnatural language processing to automatically answer clinical inquiries about\nmedical images. However, current Med-VQA datasets exhibit two significant\nlimitations: (1) they often lack visual and textual explanations for answers,\nhindering comprehension for patients and junior doctors; (2) they typically\noffer a narrow range of question formats, inadequately reflecting the diverse\nrequirements in practical scenarios. These limitations pose significant\nchallenges to the development of a reliable and user-friendly Med-VQA system.\nTo address these challenges, we introduce a large-scale, Groundable, and\nExplainable Medical VQA benchmark for chest X-ray diagnosis (GEMeX), featuring\nseveral innovative components: (1) a multi-modal explainability mechanism that\noffers detailed visual and textual explanations for each question-answer pair,\nthereby enhancing answer comprehensibility; (2) four question types,\nopen-ended, closed-ended, single-choice, and multiple-choice, to better reflect\npractical needs. With 151,025 images and 1,605,575 questions, GEMeX is the\ncurrently largest chest X-ray VQA dataset. Evaluation of 12 representative\nlarge vision language models (LVLMs) on GEMeX reveals suboptimal performance,\nunderscoring the dataset's complexity. Meanwhile, we propose a strong model by\nfine-tuning an existing LVLM on the GEMeX training set. The substantial\nperformance improvement showcases the dataset's effectiveness. The benchmark is\navailable at https://www.med-vqa.com/GEMeX.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This project is available at https://www.med-vqa.com/GEMeX",
    "pdf_url": "http://arxiv.org/pdf/2411.16778v2",
    "published_date": "2024-11-25 07:36:46 UTC",
    "updated_date": "2025-03-23 03:25:56 UTC"
  },
  {
    "arxiv_id": "2411.16158v1",
    "title": "MixPE: Quantization and Hardware Co-design for Efficient LLM Inference",
    "authors": [
      "Yu Zhang",
      "Mingzi Wang",
      "Lancheng Zou",
      "Wulong Liu",
      "Hui-Ling Zhen",
      "Mingxuan Yuan",
      "Bei Yu"
    ],
    "abstract": "Transformer-based large language models (LLMs) have achieved remarkable\nsuccess as model sizes continue to grow, yet their deployment remains\nchallenging due to significant computational and memory demands. Quantization\nhas emerged as a promising solution, and state-of-the-art quantization\nalgorithms for LLMs introduce the need for mixed-precision matrix\nmultiplication (mpGEMM), where lower-precision weights are multiplied with\nhigher-precision activations. Despite its benefits, current hardware\naccelerators such as GPUs and TPUs lack native support for efficient mpGEMM,\nleading to inefficient dequantization operations in the main sequential loop.\nTo address this limitation, we introduce MixPE, a specialized mixed-precision\nprocessing element designed for efficient low-bit quantization in LLM\ninference. MixPE leverages two key innovations to minimize dequantization\noverhead and unlock the full potential of low-bit quantization. First,\nrecognizing that scale and zero point are shared within each quantization\ngroup, we propose performing dequantization after per-group mpGEMM,\nsignificantly reducing dequantization overhead. Second, instead of relying on\nconventional multipliers, MixPE utilizes efficient shift\\&add operations for\nmultiplication, optimizing both computation and energy efficiency. Our\nexperimental results demonstrate that MixPE surpasses the state-of-the-art\nquantization accelerators by $2.6\\times$ speedup and $1.4\\times$ energy\nreduction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16158v1",
    "published_date": "2024-11-25 07:34:53 UTC",
    "updated_date": "2024-11-25 07:34:53 UTC"
  },
  {
    "arxiv_id": "2411.16155v2",
    "title": "Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning",
    "authors": [
      "Toyotaro Suzumura",
      "Hiroki Kanezashi",
      "Shotaro Akahori"
    ],
    "abstract": "In diagnosing neurological disorders from electroencephalography (EEG) data,\nfoundation models such as Transformers have been employed to capture temporal\ndynamics. Additionally, Graph Neural Networks (GNNs) are critical for\nrepresenting the spatial relationships among EEG sensors. However, fine-tuning\nthese large-scale models for both temporal and spatial features can be\nprohibitively large in computational cost, especially under the limited\navailability of labeled EEG datasets. We propose EEG-GraphAdapter (EGA), a\nparameter-efficient fine-tuning (PEFT) approach designed to address these\nchallenges. EGA is integrated into a pre-trained temporal backbone model as a\nGNN-based module, freezing the backbone and allowing only the adapter to be\nfine-tuned. This enables the effective acquisition of EEG spatial\nrepresentations, significantly reducing computational overhead and data\nrequirements. Experimental evaluations on two healthcare-related downstream\ntasks-Major Depressive Disorder (MDD) and Abnormality Detection (TUAB)-show\nthat EGA improves performance by up to 16.1% in F1-score compared with the\nbackbone BENDR model, highlighting its potential for scalable and accurate\nEEG-based predictions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted AAAI W3PHIAI-25 Workshop",
    "pdf_url": "http://arxiv.org/pdf/2411.16155v2",
    "published_date": "2024-11-25 07:30:52 UTC",
    "updated_date": "2025-02-18 08:00:21 UTC"
  },
  {
    "arxiv_id": "2411.16147v1",
    "title": "SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations",
    "authors": [
      "Youngjun Sim",
      "Jinsung Yoon",
      "Young-Joo Suh"
    ],
    "abstract": "One-shot voice conversion (VC) is a method that enables the transformation\nbetween any two speakers using only a single target speaker utterance. Existing\nmethods often rely on complex architectures and pre-trained speaker\nverification (SV) models to improve the fidelity of converted speech. Recent\nworks utilizing K-means quantization (KQ) with self-supervised learning (SSL)\nfeatures have proven capable of capturing content information from speech.\nHowever, they often struggle to preserve speaking variation, such as prosodic\ndetail and phonetic variation, particularly with smaller codebooks. In this\nwork, we propose a simple yet effective one-shot VC model that utilizes the\ncharacteristics of SSL features and speech attributes. Our approach addresses\nthe issue of losing speaking variation, enabling high-fidelity voice conversion\ntrained with only reconstruction losses, without requiring external speaker\nembeddings. We demonstrate the performance of our model across 6 evaluation\nmetrics, with results highlighting the benefits of the speaking variation\ncompensation method.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "68T07"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.16147v1",
    "published_date": "2024-11-25 07:14:26 UTC",
    "updated_date": "2024-11-25 07:14:26 UTC"
  },
  {
    "arxiv_id": "2412.00059v2",
    "title": "A Learn-to-Optimize Approach for Coordinate-Wise Step Sizes for Quasi-Newton Methods",
    "authors": [
      "Wei Lin",
      "Qingyu Song",
      "Hong Xu"
    ],
    "abstract": "Tuning step sizes is crucial for the stability and efficiency of optimization\nalgorithms. While adaptive coordinate-wise step sizes have been shown to\noutperform scalar step size in first-order methods, their use in second-order\nmethods is still under-explored and more challenging. Current approaches,\nincluding hypergradient descent and cutting plane methods, offer limited\nimprovements or encounter difficulties in second-order contexts. To address\nthese limitations, we first conduct a theoretical analysis within the\nBroyden-Fletcher-Goldfarb-Shanno (BFGS) framework, a prominent quasi-Newton\nmethod, and derive sufficient conditions for coordinate-wise step sizes that\nensure convergence and stability. Building on this theoretical foundation, we\nintroduce a novel learn-to-optimize (L2O) method that employs LSTM-based\nnetworks to learn optimal step sizes by leveraging insights from past\noptimization trajectories, while inherently respecting the derived theoretical\nguarantees. Extensive experiments demonstrate that our approach achieves\nsubstantial improvements over scalar step size methods and hypergradient\ndescent-based method, offering up to 4$\\times$ faster convergence across\ndiverse optimization tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00059v2",
    "published_date": "2024-11-25 07:13:59 UTC",
    "updated_date": "2025-05-19 07:29:00 UTC"
  },
  {
    "arxiv_id": "2411.16775v1",
    "title": "Parameter Efficient Instruction Tuning: An Empirical Study",
    "authors": [
      "Pengfei He"
    ],
    "abstract": "Instruction tuning has become an important step for finetuning pretrained\nlanguage models to better follow human instructions and generalize on various\ntasks. Nowadays, pretrained language models become increasingly larger, and\nfull parameter finetuning is overwhelmingly costly. Therefore, Parameter\nEfficient Finetuning (PEFT) has arisen as a cost-effective practice for\ninstruction tuning because of significantly smaller computational, memory, and\nstorage cost compared to full finetuning. Despite their widespread adaptations,\nthe vast hyperparameter spaces, the number of PEFT methods, the different focus\nof instruction tuning capabilities make disentangling the impact of each aspect\ndifficult. This study systematically investigates several representative PEFT\nmethods, surveying the effect of hyperparameter choices including training\nhyperparameters and PEFT-specific hyperparameters, how different models sizes\nand the number of instruction tasks affect the performance,\nin-task-distribution memorization and open instruction following capability.\nOur empirical study shows that only LoRA and adapter can get close to full\nfinetuning with ideal training settings. The ideal training setting includes an\nappropriate learning rate, largest LoRA rank or adapter size allowed and\ndiverse training tasks. On the other hand, LoRA and adapter suffer from\ntraining instability if such an ideal training condition is not met.\nAdditionally, LoRA requires a greater number of tasks for effective unseen task\ngeneralization, exhibit slower learning speed. Moreover, LoRA has weaker\ntask-level memorization. Lastly, LoRA and adapter fall short in complex\nreasoning, coding and long-form generation compared to finetuning in open\ninstruction tuning settings but it shows stronger capabilities compared to\nadapter.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.16775v1",
    "published_date": "2024-11-25 07:06:09 UTC",
    "updated_date": "2024-11-25 07:06:09 UTC"
  },
  {
    "arxiv_id": "2411.16131v1",
    "title": "End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning",
    "authors": [
      "Mahmoud M. Kishky",
      "Hesham M. Eraqi",
      "Khaled F. Elsayed"
    ],
    "abstract": "Autonomous driving involves complex tasks such as data fusion, object and\nlane detection, behavior prediction, and path planning. As opposed to the\nmodular approach which dedicates individual subsystems to tackle each of those\ntasks, the end-to-end approach treats the problem as a single learnable task\nusing deep neural networks, reducing system complexity and minimizing\ndependency on heuristics. Conditional imitation learning (CIL) trains the\nend-to-end model to mimic a human expert considering the navigational commands\nguiding the vehicle to reach its destination, CIL adopts specialist network\nbranches dedicated to learn the driving task for each navigational command.\nNevertheless, the CIL model lacked generalization when deployed to unseen\nenvironments. This work introduces the conditional imitation co-learning (CIC)\napproach to address this issue by enabling the model to learn the relationships\nbetween CIL specialist branches via a co-learning matrix generated by gated\nhyperbolic tangent units (GTUs). Additionally, we propose posing the steering\nregression problem as classification, we use a classification-regression hybrid\nloss to bridge the gap between regression and classification, we also propose\nusing co-existence probability to consider the spatial tendency between the\nsteering classes. Our model is demonstrated to improve autonomous driving\nsuccess rate in unseen environment by 62% on average compared to the CIL\nmethod.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "NCTA 2024 Best Paper Honorable Mention",
    "pdf_url": "http://arxiv.org/pdf/2411.16131v1",
    "published_date": "2024-11-25 06:37:48 UTC",
    "updated_date": "2024-11-25 06:37:48 UTC"
  },
  {
    "arxiv_id": "2411.16128v1",
    "title": "CIA: Controllable Image Augmentation Framework Based on Stable Diffusion",
    "authors": [
      "Mohamed Benkedadra",
      "Dany Rimez",
      "Tiffanie Godelaine",
      "Natarajan Chidambaram",
      "Hamed Razavi Khosroshahi",
      "Horacio Tellez",
      "Matei Mancas",
      "Benoit Macq",
      "Sidi Ahmed Mahmoudi"
    ],
    "abstract": "Computer vision tasks such as object detection and segmentation rely on the\navailability of extensive, accurately annotated datasets. In this work, We\npresent CIA, a modular pipeline, for (1) generating synthetic images for\ndataset augmentation using Stable Diffusion, (2) filtering out low quality\nsamples using defined quality metrics, (3) forcing the existence of specific\npatterns in generated images using accurate prompting and ControlNet. In order\nto show how CIA can be used to search for an optimal augmentation pipeline of\ntraining data, we study human object detection in a data constrained scenario,\nusing YOLOv8n on COCO and Flickr30k datasets. We have recorded significant\nimprovement using CIA-generated images, approaching the performances obtained\nwhen doubling the amount of real images in the dataset. Our findings suggest\nthat our modular framework can significantly enhance object detection systems,\nand make it possible for future research to be done on data-constrained\nscenarios. The framework is available at: github.com/multitel-ai/CIA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16128v1",
    "published_date": "2024-11-25 06:29:51 UTC",
    "updated_date": "2024-11-25 06:29:51 UTC"
  },
  {
    "arxiv_id": "2411.16123v1",
    "title": "Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain",
    "authors": [
      "Hangyul Yoon",
      "Doohyuk Jang",
      "Jungeun Kim",
      "Eunho Yang"
    ],
    "abstract": "Leveraging pre-trained models with tailored prompts for in-context learning\nhas proven highly effective in NLP tasks. Building on this success, recent\nstudies have applied a similar approach to the Segment Anything Model (SAM)\nwithin a ``one-shot\" framework, where only a single reference image and its\nlabel are employed. However, these methods face limitations in the medical\ndomain, primarily due to SAM's essential requirement for visual prompts and the\nover-reliance on pixel similarity for generating them. This dependency may lead\nto (1) inaccurate prompt generation and (2) clustering of point prompts,\nresulting in suboptimal outcomes. To address these challenges, we introduce\n\\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed\nfor the medical domain. Med-PerSAM uses only visual prompt engineering and\neliminates the need for additional training of the pretrained SAM or human\nintervention, owing to our novel automated prompt generation process. By\nintegrating our lightweight warping-based prompt tuning model with SAM, we\nenable the extraction and iterative refinement of visual prompts, enhancing the\nperformance of the pre-trained SAM. This advancement is particularly meaningful\nin the medical domain, where creating visual prompts poses notable challenges\nfor individuals lacking medical expertise. Our model outperforms various\nfoundational models and previous SAM-based approaches across diverse 2D medical\nimaging datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16123v1",
    "published_date": "2024-11-25 06:16:17 UTC",
    "updated_date": "2024-11-25 06:16:17 UTC"
  },
  {
    "arxiv_id": "2411.16120v1",
    "title": "Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks",
    "authors": [
      "Rui Zuo",
      "Zifan Wang",
      "Simon Khan",
      "Garrett Ethan Katz",
      "Qinru Qiu"
    ],
    "abstract": "Due to the inherent lack of transparency in deep neural networks, it is\nchallenging for deep reinforcement learning (DRL) agents to gain trust and\nacceptance from users, especially in safety-critical applications such as\nmedical diagnosis and military operations. Existing methods for explaining an\nagent's decision either require to retrain the agent using models that support\nexplanation generation or rely on perturbation-based techniques to reveal the\nsignificance of different input features in the decision making process.\nHowever, retraining the agent may compromise its integrity and performance,\nwhile perturbation-based methods have limited performance and lack knowledge\naccumulation or learning capabilities. Moreover, since each perturbation is\nperformed independently, the joint state of the perturbed inputs may not be\nphysically meaningful. To address these challenges, we introduce\n$\\textbf{VisionMask}$, a standalone explanation model trained end-to-end to\nidentify the most critical regions in the agent's visual input that can explain\nits actions. VisionMask is trained in a self-supervised manner without relying\non human-generated labels. Importantly, its training does not alter the agent\nmodel, hence preserving the agent's performance and integrity. We evaluate\nVisionMask on Super Mario Bros (SMB) and three Atari games. Compared to\nexisting methods, VisionMask achieves a 14.9% higher insertion accuracy and a\n30.08% higher F1-Score in reproducing original actions from the selected visual\nexplanations. We also present examples illustrating how VisionMask can be used\nfor counterfactual analysis.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16120v1",
    "published_date": "2024-11-25 06:11:46 UTC",
    "updated_date": "2024-11-25 06:11:46 UTC"
  },
  {
    "arxiv_id": "2411.16116v1",
    "title": "LLM Augmentations to support Analytical Reasoning over Multiple Documents",
    "authors": [
      "Raquib Bin Yousuf",
      "Nicholas Defelice",
      "Mandar Sharma",
      "Shengzhe Xu",
      "Naren Ramakrishnan"
    ],
    "abstract": "Building on their demonstrated ability to perform a variety of tasks, we\ninvestigate the application of large language models (LLMs) to enhance in-depth\nanalytical reasoning within the context of intelligence analysis. Intelligence\nanalysts typically work with massive dossiers to draw connections between\nseemingly unrelated entities, and uncover adversaries' plans and motives. We\nexplore if and how LLMs can be helpful to analysts for this task and develop an\narchitecture to augment the capabilities of an LLM with a memory module called\ndynamic evidence trees (DETs) to develop and track multiple investigation\nthreads. Through extensive experiments on multiple datasets, we highlight how\nLLMs, as-is, are still inadequate to support intelligence analysts and offer\nrecommendations to improve LLMs for such intricate reasoning applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "2024 IEEE International Conference on Big Data (IEEE BigData 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.16116v1",
    "published_date": "2024-11-25 06:00:42 UTC",
    "updated_date": "2024-11-25 06:00:42 UTC"
  },
  {
    "arxiv_id": "2411.16111v1",
    "title": "LLMPirate: LLMs for Black-box Hardware IP Piracy",
    "authors": [
      "Vasudev Gohil",
      "Matthew DeLorenzo",
      "Veera Vishwa Achuta Sai Venkat Nallam",
      "Joey See",
      "Jeyavijayan Rajendran"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has enabled the ability\nto effectively analyze and generate code nearly instantaneously, resulting in\ntheir widespread adoption in software development. Following this advancement,\nresearchers and companies have begun integrating LLMs across the hardware\ndesign and verification process. However, these highly potent LLMs can also\ninduce new attack scenarios upon security vulnerabilities across the hardware\ndevelopment process. One such attack vector that has not been explored is\nintellectual property (IP) piracy. Given that this attack can manifest as\nrewriting hardware designs to evade piracy detection, it is essential to\nthoroughly evaluate LLM capabilities in performing this task and assess the\nmitigation abilities of current IP piracy detection tools.\n  Therefore, in this work, we propose LLMPirate, the first LLM-based technique\nable to generate pirated variations of circuit designs that successfully evade\ndetection across multiple state-of-the-art piracy detection tools. We devise\nthree solutions to overcome challenges related to integration of LLMs for\nhardware circuit designs, scalability to large circuits, and effectiveness,\nresulting in an end-to-end automated, efficient, and practical formulation. We\nperform an extensive experimental evaluation of LLMPirate using eight LLMs of\nvarying sizes and capabilities and assess their performance in pirating various\ncircuit designs against four state-of-the-art, widely-used piracy detection\ntools. Our experiments demonstrate that LLMPirate is able to consistently evade\ndetection on 100% of tested circuits across every detection tool. Additionally,\nwe showcase the ramifications of LLMPirate using case studies on IBEX and\nMOR1KX processors and a GPS module, that we successfully pirate. We envision\nthat our work motivates and fosters the development of better IP piracy\ndetection tools.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by NDSS Symposium 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.16111v1",
    "published_date": "2024-11-25 05:54:06 UTC",
    "updated_date": "2024-11-25 05:54:06 UTC"
  },
  {
    "arxiv_id": "2411.16105v2",
    "title": "Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability",
    "authors": [
      "Jatin Nainani",
      "Sankaran Vaidyanathan",
      "AJ Yeung",
      "Kartik Gupta",
      "David Jensen"
    ],
    "abstract": "Mechanistic interpretability aims to understand the inner workings of large\nneural networks by identifying circuits, or minimal subgraphs within the model\nthat implement algorithms responsible for performing specific tasks. These\ncircuits are typically discovered and analyzed using a narrowly defined prompt\nformat. However, given the abilities of large language models (LLMs) to\ngeneralize across various prompt formats for the same task, it remains unclear\nhow well these circuits generalize. For instance, it is unclear whether the\nmodels generalization results from reusing the same circuit components, the\ncomponents behaving differently, or the use of entirely different components.\nIn this paper, we investigate the generality of the indirect object\nidentification (IOI) circuit in GPT-2 small, which is well-studied and believed\nto implement a simple, interpretable algorithm. We evaluate its performance on\nprompt variants that challenge the assumptions of this algorithm. Our findings\nreveal that the circuit generalizes surprisingly well, reusing all of its\ncomponents and mechanisms while only adding additional input edges. Notably,\nthe circuit generalizes even to prompt variants where the original algorithm\nshould fail; we discover a mechanism that explains this which we term S2\nHacking. Our findings indicate that circuits within LLMs may be more flexible\nand general than previously recognized, underscoring the importance of studying\ncircuit generalization to better understand the broader capabilities of these\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.16105v2",
    "published_date": "2024-11-25 05:32:34 UTC",
    "updated_date": "2024-12-05 14:16:57 UTC"
  },
  {
    "arxiv_id": "2411.16099v1",
    "title": "An Empirical Study of Vulnerability Detection using Federated Learning",
    "authors": [
      "Peiheng Zhou",
      "Ming Hu",
      "Xingrun Quan",
      "Yawen Peng",
      "Xiaofei Xie",
      "Yanxin Yang",
      "Chengwei Liu",
      "Yueming Wu",
      "Mingsong Chen"
    ],
    "abstract": "Although Deep Learning (DL) methods becoming increasingly popular in\nvulnerability detection, their performance is seriously limited by insufficient\ntraining data. This is mainly because few existing software organizations can\nmaintain a complete set of high-quality samples for DL-based vulnerability\ndetection. Due to the concerns about privacy leakage, most of them are\nreluctant to share data, resulting in the data silo problem. Since enables\ncollaboratively model training without data sharing, Federated Learning (FL)\nhas been investigated as a promising means of addressing the data silo problem\nin DL-based vulnerability detection. However, since existing FL-based\nvulnerability detection methods focus on specific applications, it is still far\nunclear i) how well FL adapts to common vulnerability detection tasks and ii)\nhow to design a high-performance FL solution for a specific vulnerability\ndetection task. To answer these two questions, this paper first proposes VulFL,\nan effective evaluation framework for FL-based vulnerability detection. Then,\nbased on VulFL, this paper conducts a comprehensive study to reveal the\nunderlying capabilities of FL in dealing with different types of CWEs,\nespecially when facing various data heterogeneity scenarios. Our experimental\nresults show that, compared to independent training, FL can significantly\nimprove the detection performance of common AI models on all investigated CWEs,\nthough the performance of FL-based vulnerability detection is limited by\nheterogeneous data. To highlight the performance differences between different\nFL solutions for vulnerability detection, we extensively investigate the\nimpacts of different configuration strategies for each framework component of\nVulFL. Our study sheds light on the potential of FL in vulnerability detection,\nwhich can be used to guide the design of FL-based solutions for vulnerability\ndetection.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16099v1",
    "published_date": "2024-11-25 05:21:12 UTC",
    "updated_date": "2024-11-25 05:21:12 UTC"
  },
  {
    "arxiv_id": "2411.16096v1",
    "title": "ENCLIP: Ensembling and Clustering-Based Contrastive Language-Image Pretraining for Fashion Multimodal Search with Limited Data and Low-Quality Images",
    "authors": [
      "Prithviraj Purushottam Naik",
      "Rohit Agarwal"
    ],
    "abstract": "Multimodal search has revolutionized the fashion industry, providing a\nseamless and intuitive way for users to discover and explore fashion items.\nBased on their preferences, style, or specific attributes, users can search for\nproducts by combining text and image information. Text-to-image searches enable\nusers to find visually similar items or describe products using natural\nlanguage. This paper presents an innovative approach called ENCLIP, for\nenhancing the performance of the Contrastive Language-Image Pretraining (CLIP)\nmodel, specifically in Multimodal Search targeted towards the domain of fashion\nintelligence. This method focuses on addressing the challenges posed by limited\ndata availability and low-quality images. This paper proposes an algorithm that\ninvolves training and ensembling multiple instances of the CLIP model, and\nleveraging clustering techniques to group similar images together. The\nexperimental findings presented in this study provide evidence of the\neffectiveness of the methodology. This approach unlocks the potential of CLIP\nin the domain of fashion intelligence, where data scarcity and image quality\nissues are prevalent. Overall, the ENCLIP method represents a valuable\ncontribution to the field of fashion intelligence and provides a practical\nsolution for optimizing the CLIP model in scenarios with limited data and\nlow-quality images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16096v1",
    "published_date": "2024-11-25 05:15:38 UTC",
    "updated_date": "2024-11-25 05:15:38 UTC"
  },
  {
    "arxiv_id": "2411.16086v1",
    "title": "HiDP: Hierarchical DNN Partitioning for Distributed Inference on Heterogeneous Edge Platforms",
    "authors": [
      "Zain Taufique",
      "Aman Vyas",
      "Antonio Miele",
      "Pasi Liljeberg",
      "Anil Kanduri"
    ],
    "abstract": "Edge inference techniques partition and distribute Deep Neural Network (DNN)\ninference tasks among multiple edge nodes for low latency inference, without\nconsidering the core-level heterogeneity of edge nodes. Further, default DNN\ninference frameworks also do not fully utilize the resources of heterogeneous\nedge nodes, resulting in higher inference latency. In this work, we propose a\nhierarchical DNN partitioning strategy (HiDP) for distributed inference on\nheterogeneous edge nodes. Our strategy hierarchically partitions DNN workloads\nat both global and local levels by considering the core-level heterogeneity of\nedge nodes. We evaluated our proposed HiDP strategy against relevant\ndistributed inference techniques over widely used DNN models on commercial edge\ndevices. On average our strategy achieved 38% lower latency, 46% lower energy,\nand 56% higher throughput in comparison with other relevant approaches.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "7 pages, 8 figures, 1 table, and 1 algorithm. The manuscript is\n  accepted to be published in 28th Design, Automation and Test in Europe\n  Conference (IEEE DATE, 2025)",
    "pdf_url": "http://arxiv.org/pdf/2411.16086v1",
    "published_date": "2024-11-25 04:40:42 UTC",
    "updated_date": "2024-11-25 04:40:42 UTC"
  },
  {
    "arxiv_id": "2411.16085v3",
    "title": "Cautious Optimizers: Improving Training with One Line of Code",
    "authors": [
      "Kaizhao Liang",
      "Lizhang Chen",
      "Bo Liu",
      "Qiang Liu"
    ],
    "abstract": "AdamW has been the default optimizer for transformer pretraining. For many\nyears, our community searched for faster and more stable optimizers with only\nconstrained positive outcomes. In this work, we propose a single-line\nmodification in Pytorch to any momentum-based optimizer, which we rename\ncautious optimizer, e.g. C-AdamW and C-Lion. Our theoretical result shows that\nthis modification preserves Adam's Hamiltonian function and it does not break\nthe convergence guarantee under the Lyapunov analysis. In addition, a whole new\nfamily of optimizers is revealed by our theoretical insight. Among them, we\npick the simplest one for empirical experiments, showing not only speed-up on\nLlama and MAE pretraining up to $1.47$ times, but also better results in LLM\npost-training tasks. Code is available at\nhttps://github.com/kyleliang919/C-Optim.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.DM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16085v3",
    "published_date": "2024-11-25 04:36:01 UTC",
    "updated_date": "2025-01-31 13:56:58 UTC"
  },
  {
    "arxiv_id": "2411.16084v1",
    "title": "Deciphering genomic codes using advanced NLP techniques: a scoping review",
    "authors": [
      "Shuyan Cheng",
      "Yishu Wei",
      "Yiliang Zhou",
      "Zihan Xu",
      "Drew N Wright",
      "Jinze Liu",
      "Yifan Peng"
    ],
    "abstract": "Objectives: The vast and complex nature of human genomic sequencing data\npresents challenges for effective analysis. This review aims to investigate the\napplication of Natural Language Processing (NLP) techniques, particularly Large\nLanguage Models (LLMs) and transformer architectures, in deciphering genomic\ncodes, focusing on tokenization, transformer models, and regulatory annotation\nprediction. The goal of this review is to assess data and model accessibility\nin the most recent literature, gaining a better understanding of the existing\ncapabilities and constraints of these tools in processing genomic sequencing\ndata.\n  Methods: Following Preferred Reporting Items for Systematic Reviews and\nMeta-Analyses (PRISMA) guidelines, our scoping review was conducted across\nPubMed, Medline, Scopus, Web of Science, Embase, and ACM Digital Library.\nStudies were included if they focused on NLP methodologies applied to genomic\nsequencing data analysis, without restrictions on publication date or article\ntype.\n  Results: A total of 26 studies published between 2021 and April 2024 were\nselected for review. The review highlights that tokenization and transformer\nmodels enhance the processing and understanding of genomic data, with\napplications in predicting regulatory annotations like transcription-factor\nbinding sites and chromatin accessibility.\n  Discussion: The application of NLP and LLMs to genomic sequencing data\ninterpretation is a promising field that can help streamline the processing of\nlarge-scale genomic data while also providing a better understanding of its\ncomplex structures. It has the potential to drive advancements in personalized\nmedicine by offering more efficient and scalable solutions for genomic\nanalysis. Further research is also needed to discuss and overcome current\nlimitations, enhancing model transparency and applicability.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16084v1",
    "published_date": "2024-11-25 04:35:56 UTC",
    "updated_date": "2024-11-25 04:35:56 UTC"
  },
  {
    "arxiv_id": "2411.16080v1",
    "title": "Boosting 3D Object Generation through PBR Materials",
    "authors": [
      "Yitong Wang",
      "Xudong Xu",
      "Li Ma",
      "Haoran Wang",
      "Bo Dai"
    ],
    "abstract": "Automatic 3D content creation has gained increasing attention recently, due\nto its potential in various applications such as video games, film industry,\nand AR/VR. Recent advancements in diffusion models and multimodal models have\nnotably improved the quality and efficiency of 3D object generation given a\nsingle RGB image. However, 3D objects generated even by state-of-the-art\nmethods are still unsatisfactory compared to human-created assets. Considering\nonly textures instead of materials makes these methods encounter challenges in\nphoto-realistic rendering, relighting, and flexible appearance editing. And\nthey also suffer from severe misalignment between geometry and high-frequency\ntexture details. In this work, we propose a novel approach to boost the quality\nof generated 3D objects from the perspective of Physics-Based Rendering (PBR)\nmaterials. By analyzing the components of PBR materials, we choose to consider\nalbedo, roughness, metalness, and bump maps. For albedo and bump maps, we\nleverage Stable Diffusion fine-tuned on synthetic data to extract these values,\nwith novel usages of these fine-tuned models to obtain 3D consistent albedo UV\nand bump UV for generated objects. In terms of roughness and metalness maps, we\nadopt a semi-automatic process to provide room for interactive adjustment,\nwhich we believe is more practical. Extensive experiments demonstrate that our\nmodel is generally beneficial for various state-of-the-art generation methods,\nsignificantly boosting the quality and realism of their generated 3D objects,\nwith natural relighting effects and substantially improved geometry.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to SIGGRAPH Asia 2024 Conference Papers",
    "pdf_url": "http://arxiv.org/pdf/2411.16080v1",
    "published_date": "2024-11-25 04:20:52 UTC",
    "updated_date": "2024-11-25 04:20:52 UTC"
  },
  {
    "arxiv_id": "2411.16079v1",
    "title": "Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models",
    "authors": [
      "Donggeun Ko",
      "Dongjun Lee",
      "Namjun Park",
      "Wonkyeong Shim",
      "Jaekwang Kim"
    ],
    "abstract": "Neural networks struggle with image classification when biases are learned\nand misleads correlations, affecting their generalization and performance.\nPrevious methods require attribute labels (e.g. background, color) or utilizes\nGenerative Adversarial Networks (GANs) to mitigate biases. We introduce\nDiffuBias, a novel pipeline for text-to-image generation that enhances\nclassifier robustness by generating bias-conflict samples, without requiring\ntraining during the generation phase. Utilizing pretrained diffusion and image\ncaptioning models, DiffuBias generates images that challenge the biases of\nclassifiers, using the top-$K$ losses from a biased classifier ($f_B$) to\ncreate more representative data samples. This method not only debiases\neffectively but also boosts classifier generalization capabilities. To the best\nof our knowledge, DiffuBias is the first approach leveraging a stable diffusion\nmodel to generate bias-conflict samples in debiasing tasks. Our comprehensive\nexperimental evaluations demonstrate that DiffuBias achieves state-of-the-art\nperformance on benchmark datasets. We also conduct a comparative analysis of\nvarious generative models in terms of carbon emissions and energy consumption\nto highlight the significance of computational efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages + Appendix",
    "pdf_url": "http://arxiv.org/pdf/2411.16079v1",
    "published_date": "2024-11-25 04:11:16 UTC",
    "updated_date": "2024-11-25 04:11:16 UTC"
  },
  {
    "arxiv_id": "2411.16075v2",
    "title": "The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum",
    "authors": [
      "Shogo Ohmae",
      "Keiko Ohmae"
    ],
    "abstract": "AI's significant recent advances using general-purpose circuit computations\noffer a potential window into how the neocortex and cerebellum of the brain are\nable to achieve a diverse range of functions across sensory, cognitive, and\nmotor domains, despite their uniform circuit structures. However, comparing the\nbrain and AI is challenging unless clear similarities exist, and past reviews\nhave been limited to comparison of brain-inspired vision AI and the visual\nneocortex. Here, to enable comparisons across diverse functional domains, we\nsubdivide circuit computation into three elements -- circuit structure,\ninput/outputs, and the learning algorithm -- and evaluate the similarities for\neach element. With this novel approach, we identify wide-ranging similarities\nand convergent evolution in the brain and AI, providing new insights into key\nconcepts in neuroscience. Furthermore, inspired by processing mechanisms of AI,\nwe propose a new theory that integrates established neuroscience theories,\nparticularly the theories of internal models and the mirror neuron system. Both\nthe neocortex and cerebellum predict future world events from past information\nand learn from prediction errors, thereby acquiring models of the world. These\nmodels enable three core processes: (1) Prediction -- generating future\ninformation, (2) Understanding -- interpreting the external world via\ncompressed and abstracted sensory information, and (3) Generation --\nrepurposing the future-information generation mechanism to produce other types\nof outputs. The universal application of these processes underlies the ability\nof the neocortex and cerebellum to accomplish diverse functions with uniform\ncircuits. Our systematic approach, insights, and theory promise groundbreaking\nadvances in understanding the brain.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16075v2",
    "published_date": "2024-11-25 04:05:43 UTC",
    "updated_date": "2024-11-29 10:04:49 UTC"
  },
  {
    "arxiv_id": "2411.16767v2",
    "title": "Background-Aware Defect Generation for Robust Industrial Anomaly Detection",
    "authors": [
      "Youngjae Cho",
      "Gwangyeol Kim",
      "Sirojbek Safarov",
      "Seongdeok Bang",
      "Jaewoo Park"
    ],
    "abstract": "Detecting anomalies in industrial settings is challenging due to the scarcity\nof labeled anomalous data. Generative models can mitigate this issue by\nsynthesizing realistic defect samples, but existing approaches often fail to\nmodel the crucial interplay between defects and their background. This\noversight leads to unrealistic anomalies, especially in scenarios where\ncontextual consistency is essential (i.e., logical anomaly). To address this,\nwe propose a novel background-aware defect generation framework, where the\nbackground influences defect denoising without affecting the background itself\nby ensuring realistic synthesis while preserving structural integrity. Our\nmethod leverages a disentanglement loss to separate the background' s denoising\nprocess from the defect, enabling controlled defect synthesis through DDIM\nInversion. We theoretically demonstrate that our approach maintains background\nfidelity while generating contextually accurate defects. Extensive experiments\non MVTec AD and MVTec Loco benchmarks validate our mehtod's superiority over\nexisting techniques in both defect generation quality and anomaly detection\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.16767v2",
    "published_date": "2024-11-25 04:05:11 UTC",
    "updated_date": "2025-02-28 09:29:21 UTC"
  },
  {
    "arxiv_id": "2411.16073v1",
    "title": "Soft-TransFormers for Continual Learning",
    "authors": [
      "Haeyong Kang",
      "Chang D. Yoo"
    ],
    "abstract": "Inspired by Well-initialized Lottery Ticket Hypothesis (WLTH), which provides\nsuboptimal fine-tuning solutions, we propose a novel fully fine-tuned continual\nlearning (CL) method referred to as Soft-TransFormers (Soft-TF). Soft-TF\nsequentially learns and selects an optimal soft-network or subnetwork for each\ntask. During sequential training in CL, Soft-TF jointly optimizes the weights\nof sparse layers to obtain task-adaptive soft (real-valued) networks or\nsubnetworks (binary masks), while keeping the well-pre-trained layer parameters\nfrozen. In inference, the identified task-adaptive network of Soft-TF masks the\nparameters of the pre-trained network, mapping to an optimal solution for each\ntask and minimizing Catastrophic Forgetting (CF) - the soft-masking preserves\nthe knowledge of the pre-trained network. Extensive experiments on Vision\nTransformer (ViT) and CLIP demonstrate the effectiveness of Soft-TF, achieving\nstate-of-the-art performance across various CL scenarios, including\nClass-Incremental Learning (CIL) and Task-Incremental Learning (TIL), supported\nby convergence theory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16073v1",
    "published_date": "2024-11-25 03:52:47 UTC",
    "updated_date": "2024-11-25 03:52:47 UTC"
  },
  {
    "arxiv_id": "2411.16053v2",
    "title": "UnitedVLN: Generalizable Gaussian Splatting for Continuous Vision-Language Navigation",
    "authors": [
      "Guangzhao Dai",
      "Jian Zhao",
      "Yuantao Chen",
      "Yusen Qin",
      "Hao Zhao",
      "Guosen Xie",
      "Yazhou Yao",
      "Xiangbo Shu",
      "Xuelong Li"
    ],
    "abstract": "Vision-and-Language Navigation (VLN), where an agent follows instructions to\nreach a target destination, has recently seen significant advancements. In\ncontrast to navigation in discrete environments with predefined trajectories,\nVLN in Continuous Environments (VLN-CE) presents greater challenges, as the\nagent is free to navigate any unobstructed location and is more vulnerable to\nvisual occlusions or blind spots. Recent approaches have attempted to address\nthis by imagining future environments, either through predicted future visual\nimages or semantic features, rather than relying solely on current\nobservations. However, these RGB-based and feature-based methods lack intuitive\nappearance-level information or high-level semantic complexity crucial for\neffective navigation. To overcome these limitations, we introduce a novel,\ngeneralizable 3DGS-based pre-training paradigm, called UnitedVLN, which enables\nagents to better explore future environments by unitedly rendering\nhigh-fidelity 360 visual images and semantic features. UnitedVLN employs two\nkey schemes: search-then-query sampling and separate-then-united rendering,\nwhich facilitate efficient exploitation of neural primitives, helping to\nintegrate both appearance and semantic information for more robust navigation.\nExtensive experiments demonstrate that UnitedVLN outperforms state-of-the-art\nmethods on existing VLN-CE benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16053v2",
    "published_date": "2024-11-25 02:44:59 UTC",
    "updated_date": "2025-03-16 10:43:31 UTC"
  },
  {
    "arxiv_id": "2411.16027v2",
    "title": "From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events",
    "authors": [
      "Yan Miao",
      "Georgios Fainekos",
      "Bardh Hoxha",
      "Hideki Okamoto",
      "Danil Prokhorov",
      "Sayan Mitra"
    ],
    "abstract": "Testing Automated Driving Systems (ADS) in simulation with realistic driving\nscenarios is important for verifying their performance. However, converting\nreal-world driving videos into simulation scenarios is a significant challenge\ndue to the complexity of interpreting high-dimensional video data and the\ntime-consuming nature of precise manual scenario reconstruction. In this work,\nwe propose a novel framework that automates the conversion of real-world car\ncrash videos into detailed simulation scenarios for ADS testing. Our approach\nleverages prompt-engineered Video Language Models(VLM) to transform dashcam\nfootage into SCENIC scripts, which define the environment and driving behaviors\nin the CARLA simulator, enabling the generation of realistic simulation\nscenarios. Importantly, rather than solely aiming for one-to-one scenario\nreconstruction, our framework focuses on capturing the essential driving\nbehaviors from the original video while offering flexibility in parameters such\nas weather or road conditions to facilitate search-based testing. Additionally,\nwe introduce a similarity metric that helps iteratively refine the generated\nscenario through feedback by comparing key features of driving behaviors\nbetween the real and simulated videos. Our preliminary results demonstrate\nsubstantial time efficiency, finishing the real-to-sim conversion in minutes\nwith full automation and no human intervention, while maintaining high fidelity\nto the original driving events.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.16027v2",
    "published_date": "2024-11-25 01:01:54 UTC",
    "updated_date": "2025-01-27 17:43:42 UTC"
  }
]