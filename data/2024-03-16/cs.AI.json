{
  "date": "2024-03-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-16 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 46 篇论文，主要聚焦 AI 生成模型优化、计算机视觉和机器学习应用等领域，亮点包括高效图像生成技术（如 Reward Guided LCD）和视频理解创新（如 Neuro-Symbolic 方法），以及知名学者如 William Yang Wang 和 Andrew Zisserman 的作品，这些论文可能引发广泛讨论。\n\n### 重点论文讨论\n我将优先选取具有创新性、实际影响力和知名作者的论文进行简要分析，将相关主题归类讨论，并快速掠过较基础或非核心文章。以下按主题分组，突出主要贡献。\n\n#### AI 生成模型与优化（AI 生成和机器学习领域，优先讨论）\n- **Reward Guided Latent Consistency Distillation（奖励引导潜在一致性蒸馏）**  \n  作者包括知名学者 William Yang Wang，这篇论文提出 RG-LCD 方法，通过整合奖励模型优化潜在扩散模型，实现高效文本到图像生成，仅需 2-4 步推理即可达到高质量输出。关键发现：与教师模型相比，RG-LCD 在保持图像保真度的同时，加速 25 倍推理，且通过潜在代理模型避免过优化问题，提升 FID 和 HPSv2.1 分数。\n\n- **Boosting Flow-based Generative Super-Resolution Models via Learned Prior（通过学习先验提升基于流的生成超分辨率模型）**  \n  这篇被 CVPR 2024 接受的论文引入条件学习先验，解决流模型中的网格伪影和爆炸问题。贡献：无需修改模型架构，就能生成更高质量的超分辨率图像，实验证明在多种场景下性能提升。\n\n- **SelfIE: Self-Interpretation of Large Language Model Embeddings（SelfIE: 大语言模型嵌入的自解释）**  \n  作者包括 Carl Vondrick，该方法让大语言模型自动解释其嵌入表示。发现：通过自然语言查询，模型能揭示内部推理过程，如伦理决策和有害知识召回，并支持监督控制和强化学习编辑，增强模型透明度。\n\n- **TabPFN 的可解释机器学习（Interpretable Machine Learning for TabPFN）**  \n  这篇论文针对 TabPFN 模型提出高效可解释方法。贡献：结合门控机制和动态学习，提升模型解释性，实验显示在低数据场景下性能优于传统方法。\n\n其他如第 5 篇 DIALECTBENCH（多方言 NLP 基准）和第 14 篇 Dreaming of Many Worlds（零样本泛化学习），快速提一下：前者构建多方言数据集提升 NLP 鲁棒性，后者使用上下文世界模型改善强化学习泛化，但细节较常规，暂不深入。\n\n#### 计算机视觉与视频理解（视觉领域，相关论文优先归类）\n- **Towards Neuro-Symbolic Video Understanding（迈向神经符号视频理解）**  \n  作者包括 Andrew Zisserman，这篇被 ECCV 2024 接受的论文解决视频帧检索中的长期推理问题。贡献：结合视觉语言模型和状态机，提高复杂事件识别 F1 分数 9-15%，在 Waymo 和 NuScenes 数据集上表现突出。\n\n- **GazeFusion: Saliency-Guided Image Generation（GazeFusion: 显著性引导图像生成）**  \n  该方法整合人类注意力机制到扩散模型中。发现：用户指定注意力分布后，生成图像能引导真实注视路径，实验通过眼动研究验证其有效性，适用于交互设计和自适应显示。\n\n- **N2F2: Hierarchical Scene Understanding with Nested Neural Feature Fields（N2F2: 使用嵌套神经特征场的层次场景理解）**  \n  作者 Andrew Zisserman 参与，这篇 ECCV 2024 论文提出嵌套特征场方法。贡献：通过层次监督学习多粒度场景特征，提升开放词汇 3D 分段和定位性能，超越现有方法。\n\n其他视觉相关如第 6 篇 Edge Private GNNs（边缘隐私 GNN），快速掠过：它使用奇异值扰动保护图结构隐私，同时保持模型效用。\n\n#### 生物与医疗应用（跨领域创新，简要提及有潜力的论文）\n- **Identifying the Attractors of Gene Regulatory Networks from Expression Data under Uncertainty（在不确定性下从表达数据识别基因调控网络吸引子）**  \n  这篇论文使用 Zadeh 计算方法分析基因网络。贡献：从时间表达数据中 robustly 识别吸引子，提供模糊逻辑描述，提升生物学解释性。\n\n- **Early-stage detection of cognitive impairment by hybrid quantum-classical algorithm（使用混合量子-经典算法早期检测认知障碍）**  \n  该方法结合量子神经网络和 fMRI 数据。发现：在多个脑区实现高准确率分类，验证了量子模型在医疗诊断中的潜力。\n\n其他医疗论文如第 10 篇 Integrating Wearable Sensor Data（可穿戴传感器情感预测），快速提一下：它使用多模态深度学习融合日记和传感器数据，一周提前预测情感状态，准确率达 82%，但应用较为具体。\n\n#### 其他领域（快速掠过，聚焦高话题度）\n剩余论文如第 23 篇 Just Say the Name（零样本连续学习）和第 29 篇 VisionCLIP（视网膜图像分析），这些涉及生成模型和机器人，但影响力较小，仅提核心：前者通过数据生成实现高效知识转移，后者使用合成图像避开隐私问题提升诊断。但总体上，这些未被顶级会议接受，细节可自行查阅。\n\n今天的 arXiv 更新展示了 AI 领域的多样创新，重点论文如 RG-LCD 和 Neuro-Symbolic 方法可能推动实际应用。如果您对特定主题感兴趣，建议查看原论文！",
  "papers": [
    {
      "arxiv_id": "2403.11027v2",
      "title": "Reward Guided Latent Consistency Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Li",
        "Weixi Feng",
        "Wenhu Chen",
        "William Yang Wang"
      ],
      "abstract": "Latent Consistency Distillation (LCD) has emerged as a promising paradigm for\nefficient text-to-image synthesis. By distilling a latent consistency model\n(LCM) from a pre-trained teacher latent diffusion model (LDM), LCD facilitates\nthe generation of high-fidelity images within merely 2 to 4 inference steps.\nHowever, the LCM's efficient inference is obtained at the cost of the sample\nquality. In this paper, we propose compensating the quality loss by aligning\nLCM's output with human preference during training. Specifically, we introduce\nReward Guided LCD (RG-LCD), which integrates feedback from a reward model (RM)\ninto the LCD process by augmenting the original LCD loss with the objective of\nmaximizing the reward associated with LCM's single-step generation. As\nvalidated through human evaluation, when trained with the feedback of a good\nRM, the 2-step generations from our RG-LCM are favored by humans over the\n50-step DDIM samples from the teacher LDM, representing a 25-time inference\nacceleration without quality loss.\n  As directly optimizing towards differentiable RMs can suffer from\nover-optimization, we take the initial step to overcome this difficulty by\nproposing the use of a latent proxy RM (LRM). This novel component serves as an\nintermediary, connecting our LCM with the RM. Empirically, we demonstrate that\nincorporating the LRM into our RG-LCD successfully avoids high-frequency noise\nin the generated images, contributing to both improved Fr\\'echet Inception\nDistance (FID) on MS-COCO and a higher HPSv2.1 score on HPSv2's test set,\nsurpassing those achieved by the baseline LCM.",
      "tldr_zh": "本研究提出Reward Guided Latent Consistency Distillation (RG-LCD)，一种改进文本到图像合成的框架，通过整合奖励模型(RM)的反馈来提升Latent Consistency Model (LCM)的生成质量，从而弥补LCM从预训练Latent Diffusion Model (LDM)中蒸馏时因效率而损失的样本 fidelity。RG-LCD在LCD损失基础上添加奖励最大化目标，使LCM的单步或2步生成在人类评估中优于LDM的50步DDIM样本，实现25倍推理加速而不降低质量。为避免直接优化RM导致的过度优化问题，引入Latent Proxy RM (LRM)作为中介，有效减少生成图像中的高频噪声。实验结果显示，RG-LCD在MS-COCO数据集上改善了Fréchet Inception Distance (FID)分数，并在HPSv2.1测试集上获得更高分数，超越基线LCM。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TMLR. Project page: https://rg-lcd.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2403.11027v2",
      "published_date": "2024-03-16 22:14:56 UTC",
      "updated_date": "2024-10-07 18:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:07:03.022773"
    },
    {
      "arxiv_id": "2403.11021v3",
      "title": "Towards Neuro-Symbolic Video Understanding",
      "title_zh": "面向神经符号视频理解",
      "authors": [
        "Minkyu Choi",
        "Harsh Goel",
        "Mohammad Omama",
        "Yunhao Yang",
        "Sahil Shah",
        "Sandeep Chinchali"
      ],
      "abstract": "The unprecedented surge in video data production in recent years necessitates\nefficient tools to extract meaningful frames from videos for downstream tasks.\nLong-term temporal reasoning is a key desideratum for frame retrieval systems.\nWhile state-of-the-art foundation models, like VideoLLaMA and ViCLIP, are\nproficient in short-term semantic understanding, they surprisingly fail at\nlong-term reasoning across frames. A key reason for this failure is that they\nintertwine per-frame perception and temporal reasoning into a single deep\nnetwork. Hence, decoupling but co-designing semantic understanding and temporal\nreasoning is essential for efficient scene identification. We propose a system\nthat leverages vision-language models for semantic understanding of individual\nframes but effectively reasons about the long-term evolution of events using\nstate machines and temporal logic (TL) formulae that inherently capture memory.\nOur TL-based reasoning improves the F1 score of complex event identification by\n9-15% compared to benchmarks that use GPT4 for reasoning on state-of-the-art\nself-driving datasets such as Waymo and NuScenes.",
      "tldr_zh": "该研究针对视频数据爆炸式增长的需求，提出一种神经符号方法来提升视频理解，特别是长期时间推理能力。现有的基础模型如 VideoLLaMA 和 ViCLIP 在短期语义理解上表现出色，但无法有效处理跨帧的长期推理，因此作者建议解耦并共同设计语义理解和时间推理。该系统利用视觉语言模型分析单个帧的语义，并通过状态机和 Temporal Logic (TL) 公式来捕捉事件的长期演化，从而增强记忆功能。实验结果显示，在 Waymo 和 NuScenes 等自动驾驶数据集上，该方法使复杂事件识别的 F1 score 提高了 9-15%，超越了使用 GPT4 的基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by The European Conference on Computer Vision (ECCV) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.11021v3",
      "published_date": "2024-03-16 21:40:27 UTC",
      "updated_date": "2024-12-03 18:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:07:14.081779"
    },
    {
      "arxiv_id": "2407.04191v2",
      "title": "GazeFusion: Saliency-Guided Image Generation",
      "title_zh": "GazeFusion: 显著性引导图像生成",
      "authors": [
        "Yunxiang Zhang",
        "Nan Wu",
        "Connor Z. Lin",
        "Gordon Wetzstein",
        "Qi Sun"
      ],
      "abstract": "Diffusion models offer unprecedented image generation power given just a text\nprompt. While emerging approaches for controlling diffusion models have enabled\nusers to specify the desired spatial layouts of the generated content, they\ncannot predict or control where viewers will pay more attention due to the\ncomplexity of human vision. Recognizing the significance of\nattention-controllable image generation in practical applications, we present a\nsaliency-guided framework to incorporate the data priors of human visual\nattention mechanisms into the generation process. Given a user-specified viewer\nattention distribution, our control module conditions a diffusion model to\ngenerate images that attract viewers' attention toward the desired regions. To\nassess the efficacy of our approach, we performed an eye-tracked user study and\na large-scale model-based saliency analysis. The results evidence that both the\ncross-user eye gaze distributions and the saliency models' predictions align\nwith the desired attention distributions. Lastly, we outline several\napplications, including interactive design of saliency guidance, attention\nsuppression in unwanted regions, and adaptive generation for varied\ndisplay/viewing conditions.",
      "tldr_zh": "本文提出 GazeFusion，一种 saliency-guided 框架，用于指导扩散模型（Diffusion models）基于文本提示生成图像，同时控制观看者注意分布。该框架整合人类视觉注意机制的数据先验，通过控制模块条件化生成过程，确保图像吸引注意焦点至指定区域。实验包括眼动用户研究和大规模模型-based saliency 分析，结果显示生成的注意分布与期望一致，并扩展到应用如交互式设计、注意抑制和适应性生成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM Transactions on Applied Perception (ACM Symposium on Applied\n  Perception 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.04191v2",
      "published_date": "2024-03-16 21:01:35 UTC",
      "updated_date": "2025-02-15 23:08:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:07:25.903108"
    },
    {
      "arxiv_id": "2403.11015v1",
      "title": "Identifying the Attractors of Gene Regulatory Networks from Expression Data under Uncertainty: An Interpretable Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Rowhanimanesh"
      ],
      "abstract": "In systems biology, attractor landscape analysis of gene regulatory networks\nis recognized as a powerful computational tool for studying various cellular\nstates from proliferation and differentiation to senescence and apoptosis.\nTherefore, accurate identification of attractors plays a critical role in\ndetermination of the cell fates. On the other hand, in a real biological\ncircuit, genetic/epigenetic alterations as well as varying environmental\nfactors drastically take effect on the location, characteristics, and even the\nnumber of attractors. The central question is: Given a temporal gene expression\nprofile of a real gene regulatory network, how can the attractors be robustly\nidentified in the presence of huge amount of uncertainty? This paper addresses\nthis question using a novel approach based on Zadeh Computing with Words. The\nproposed scheme could effectively identify the attractors from temporal gene\nexpression data in terms of both fuzzy logic-based and linguistic descriptions\nwhich are simply interpretable by human experts. Therefore, this method can be\nconsidered as an effective step towards interpretable artificial intelligence.\nWithout loss of generality, genetic toggle switch is considered as the case\nstudy. The nonlinear dynamics of this benchmark gene regulatory network is\ncomputationally modeled by the notion of uncertain stochastic differential\nequations. The results of in-silico study demonstrate the efficiency and\nrobustness of the proposed method.",
      "tldr_zh": "本研究针对系统生物学中基因调控网络（gene regulatory networks）的吸引子（attractors）识别问题，提出了一种鲁棒方法，以应对不确定性（如遗传/表观遗传变异和环境因素）对吸引子位置、特性和数量的影响。方法基于 Zadeh Computing with Words，利用模糊逻辑（fuzzy logic）和语言描述从时间序列基因表达数据中识别吸引子，并提供易于人类专家理解的解释，从而实现可解释人工智能（interpretable artificial intelligence）。以遗传开关（genetic toggle switch）为例，通过不确定随机微分方程建模的模拟实验，证明了该方法的有效性和鲁棒性。",
      "categories": [
        "q-bio.MN",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "q-bio.MN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.11015v1",
      "published_date": "2024-03-16 20:56:22 UTC",
      "updated_date": "2024-03-16 20:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:07:38.687659"
    },
    {
      "arxiv_id": "2403.11009v2",
      "title": "DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and Closely-Related Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Fahim Faisal",
        "Orevaoghene Ahia",
        "Aarohi Srivastava",
        "Kabir Ahuja",
        "David Chiang",
        "Yulia Tsvetkov",
        "Antonios Anastasopoulos"
      ],
      "abstract": "Language technologies should be judged on their usefulness in real-world use\ncases. An often overlooked aspect in natural language processing (NLP) research\nand evaluation is language variation in the form of non-standard dialects or\nlanguage varieties (hereafter, varieties). Most NLP benchmarks are limited to\nstandard language varieties. To fill this gap, we propose DIALECTBENCH, the\nfirst-ever large-scale benchmark for NLP on varieties, which aggregates an\nextensive set of task-varied variety datasets (10 text-level tasks covering 281\nvarieties). This allows for a comprehensive evaluation of NLP system\nperformance on different language varieties. We provide substantial evidence of\nperformance disparities between standard and non-standard language varieties,\nand we also identify language clusters with large performance divergence across\ntasks. We believe DIALECTBENCH provides a comprehensive view of the current\nstate of NLP for language varieties and one step towards advancing it further.\nCode/data: https://github.com/ffaisal93/DialectBench",
      "tldr_zh": "该研究提出了DIALECTBENCH，这是首个大规模NLP基准，用于评估方言、语言变体和相关语言的性能差异。DIALECTBENCH聚合了10个文本级任务，涵盖281个语言变体，旨在填补NLP基准中对非标准语言变体的忽视。实验结果显示，标准语言与非标准变体之间存在显著性能差距，并识别了任务间表现差异明显的语言集群，为推进NLP对语言多样性的支持提供了重要基础。代码和数据可从https://github.com/ffaisal93/DialectBench获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Equal contribution: Fahim Faisal, Orevaoghene Ahia",
      "pdf_url": "http://arxiv.org/pdf/2403.11009v2",
      "published_date": "2024-03-16 20:18:36 UTC",
      "updated_date": "2024-07-07 18:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:07:48.987530"
    },
    {
      "arxiv_id": "2403.10997v2",
      "title": "N2F2: Hierarchical Scene Understanding with Nested Neural Feature Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Bhalgat",
        "Iro Laina",
        "João F. Henriques",
        "Andrew Zisserman",
        "Andrea Vedaldi"
      ],
      "abstract": "Understanding complex scenes at multiple levels of abstraction remains a\nformidable challenge in computer vision. To address this, we introduce Nested\nNeural Feature Fields (N2F2), a novel approach that employs hierarchical\nsupervision to learn a single feature field, wherein different dimensions\nwithin the same high-dimensional feature encode scene properties at varying\ngranularities. Our method allows for a flexible definition of hierarchies,\ntailored to either the physical dimensions or semantics or both, thereby\nenabling a comprehensive and nuanced understanding of scenes. We leverage a 2D\nclass-agnostic segmentation model to provide semantically meaningful pixel\ngroupings at arbitrary scales in the image space, and query the CLIP\nvision-encoder to obtain language-aligned embeddings for each of these\nsegments. Our proposed hierarchical supervision method then assigns different\nnested dimensions of the feature field to distill the CLIP embeddings using\ndeferred volumetric rendering at varying physical scales, creating a\ncoarse-to-fine representation. Extensive experiments show that our approach\noutperforms the state-of-the-art feature field distillation methods on tasks\nsuch as open-vocabulary 3D segmentation and localization, demonstrating the\neffectiveness of the learned nested feature field.",
      "tldr_zh": "该研究提出了一种名为N2F2的框架，利用Nested Neural Feature Fields实现分层场景理解，通过分层监督学习单个高维特征场，其中不同维度编码不同粒度的场景属性，如物理维度或语义信息。方法结合2D class-agnostic segmentation模型生成图像空间的像素分组，并使用CLIP vision-encoder获取语言对齐嵌入，然后通过deferred volumetric rendering在不同物理尺度上蒸馏这些嵌入，构建粗到细的表示。实验结果显示，N2F2在open-vocabulary 3D segmentation和localization任务上超越了现有特征场蒸馏方法，证明了其在复杂场景理解中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10997v2",
      "published_date": "2024-03-16 18:50:44 UTC",
      "updated_date": "2024-07-28 15:53:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:08:01.816803"
    },
    {
      "arxiv_id": "2403.10995v1",
      "title": "Edge Private Graph Neural Networks with Singular Value Perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Tingting Tang",
        "Yue Niu",
        "Salman Avestimehr",
        "Murali Annavaram"
      ],
      "abstract": "Graph neural networks (GNNs) play a key role in learning representations from\ngraph-structured data and are demonstrated to be useful in many applications.\nHowever, the GNN training pipeline has been shown to be vulnerable to node\nfeature leakage and edge extraction attacks. This paper investigates a scenario\nwhere an attacker aims to recover private edge information from a trained GNN\nmodel. Previous studies have employed differential privacy (DP) to add noise\ndirectly to the adjacency matrix or a compact graph representation. The added\nperturbations cause the graph structure to be substantially morphed, reducing\nthe model utility. We propose a new privacy-preserving GNN training algorithm,\nEclipse, that maintains good model utility while providing strong privacy\nprotection on edges. Eclipse is based on two key observations. First, adjacency\nmatrices in graph structures exhibit low-rank behavior. Thus, Eclipse trains\nGNNs with a low-rank format of the graph via singular values decomposition\n(SVD), rather than the original graph. Using the low-rank format, Eclipse\npreserves the primary graph topology and removes the remaining residual edges.\nEclipse adds noise to the low-rank singular values instead of the entire graph,\nthereby preserving the graph privacy while still maintaining enough of the\ngraph structure to maintain model utility. We theoretically show Eclipse\nprovide formal DP guarantee on edges. Experiments on benchmark graph datasets\nshow that Eclipse achieves significantly better privacy-utility tradeoff\ncompared to existing privacy-preserving GNN training methods. In particular,\nunder strong privacy constraints ($\\epsilon$ < 4), Eclipse shows significant\ngains in the model utility by up to 46%. We further demonstrate that Eclipse\nalso has better resilience against common edge attacks (e.g., LPA), lowering\nthe attack AUC by up to 5% compared to other state-of-the-art baselines.",
      "tldr_zh": "本研究针对图神经网络（GNNs）在训练过程中易受边信息泄露攻击的问题，提出了一种新的隐私保护算法Eclipse。该算法利用奇异值分解（SVD）将图结构表示为低秩格式，仅对奇异值添加噪声，从而保留主要图拓扑并提供对边的差分隐私（DP）保证。相比现有方法，Eclipse显著改善了隐私与模型效用的权衡，在强隐私约束（ε < 4）下，模型效用提升多达46%。实验结果还显示，Eclipse对常见边攻击（如LPA）具有更强抵抗力，将攻击AUC降低多达5%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Privacy Enhancing Technologies Symposium (PETS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10995v1",
      "published_date": "2024-03-16 18:44:56 UTC",
      "updated_date": "2024-03-16 18:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:08:14.563716"
    },
    {
      "arxiv_id": "2403.10988v3",
      "title": "Boosting Flow-based Generative Super-Resolution Models via Learned Prior",
      "title_zh": "通过学习到的先验提升基于流的生成式超分辨率模型",
      "authors": [
        "Li-Yuan Tsao",
        "Yi-Chen Lo",
        "Chia-Che Chang",
        "Hao-Wei Chen",
        "Roy Tseng",
        "Chien Feng",
        "Chun-Yi Lee"
      ],
      "abstract": "Flow-based super-resolution (SR) models have demonstrated astonishing\ncapabilities in generating high-quality images. However, these methods\nencounter several challenges during image generation, such as grid artifacts,\nexploding inverses, and suboptimal results due to a fixed sampling temperature.\nTo overcome these issues, this work introduces a conditional learned prior to\nthe inference phase of a flow-based SR model. This prior is a latent code\npredicted by our proposed latent module conditioned on the low-resolution\nimage, which is then transformed by the flow model into an SR image. Our\nframework is designed to seamlessly integrate with any contemporary flow-based\nSR model without modifying its architecture or pre-trained weights. We evaluate\nthe effectiveness of our proposed framework through extensive experiments and\nablation analyses. The proposed framework successfully addresses all the\ninherent issues in flow-based SR models and enhances their performance in\nvarious SR scenarios. Our code is available at:\nhttps://github.com/liyuantsao/BFSR",
      "tldr_zh": "这篇论文针对流基于生成超分辨率（SR）模型存在的网格伪影、exploding inverses 和固定采样温度导致的次优问题，提出了一种通过条件学习先验（learned prior）来提升模型性能的方法。 该先验由一个潜在模块基于低分辨率图像预测潜在代码，然后通过流模型转换为高分辨率图像，且框架无需修改现有模型的架构或预训练权重即可无缝集成。 实验和消融分析证明，该框架有效解决了这些问题，并在多种SR场景中显著提升了图像生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10988v3",
      "published_date": "2024-03-16 18:04:12 UTC",
      "updated_date": "2024-05-29 03:12:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:08:27.075359"
    },
    {
      "arxiv_id": "2403.10984v2",
      "title": "IoTCO2: Assessing the End-To-End Carbon Footprint of Internet-of-Things-Enabled Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Chen",
        "Shahzeen Attari",
        "Gayle Buck",
        "Lei Jiang"
      ],
      "abstract": "To improve privacy and ensure quality-of-service (QoS), deep learning (DL)\nmodels are increasingly deployed on Internet of Things (IoT) devices for data\nprocessing, significantly increasing the carbon footprint associated with DL on\nIoT, covering both operational and embodied aspects. Existing operational\nenergy predictors often overlook quantized DL models and emerging neural\nprocessing units (NPUs), while embodied carbon footprint modeling tools neglect\nnon-computing hardware components common in IoT devices, creating a gap in\naccurate carbon footprint modeling tools for IoT-enabled DL. This paper\nintroduces \\textit{\\carb}, an end-to-end tool for precise carbon footprint\nestimation in IoT-enabled DL, with deviations as low as 5\\% for operational and\n3.23\\% for embodied carbon footprints compared to actual measurements across\nvarious DL models. Additionally, practical applications of \\carb~are showcased\nthrough multiple user case studies.",
      "tldr_zh": "该论文探讨了深度学习 (DL) 模型在物联网 (IoT) 设备上部署所带来的端到端碳足迹问题，包括操作和 embodied 方面，并指出现有工具忽略了量化 DL 模型、neural processing units (NPUs) 以及非计算硬件组件的不足。作者引入了 \\textit{\\carb} 工具，这是一个精确的碳足迹估计框架，能够以低于5%（操作碳足迹）和3.23%（embodied 碳足迹）的偏差进行评估。最终，通过多个用户案例研究，展示了 \\textit{\\carb} 在实际应用中的潜力，为 IoT 启用 DL 的可持续性提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "5 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.10984v2",
      "published_date": "2024-03-16 17:32:59 UTC",
      "updated_date": "2024-09-13 16:21:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:08:38.981082"
    },
    {
      "arxiv_id": "2403.13841v2",
      "title": "Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongqi Yang",
        "Yuning Wang",
        "Ken S. Yamashita",
        "Maryam Sabah",
        "Elahe Khatibi",
        "Iman Azimi",
        "Nikil Dutt",
        "Jessica L. Borelli",
        "Amir M. Rahmani"
      ],
      "abstract": "Emotional states, as indicators of affect, are pivotal to overall health,\nmaking their accurate prediction before onset crucial. Current studies are\nprimarily centered on immediate short-term affect detection using data from\nwearable and mobile devices. These studies typically focus on objective sensory\nmeasures, often neglecting other forms of self-reported information like\ndiaries and notes. In this paper, we propose a multimodal deep learning model\nfor affect status forecasting. This model combines a transformer encoder with a\npre-trained language model, facilitating the integrated analysis of objective\nmetrics and self-reported diaries. To validate our model, we conduct a\nlongitudinal study, enrolling college students and monitoring them over a year,\nto collect an extensive dataset including physiological, environmental, sleep,\nmetabolic, and physical activity parameters, alongside open-ended textual\ndiaries provided by the participants. Our results demonstrate that the proposed\nmodel achieves predictive accuracy of 82.50% for positive affect and 82.76% for\nnegative affect, a full week in advance. The effectiveness of our model is\nfurther elevated by its explainability.",
      "tldr_zh": "本研究针对情感状态（affect）的预测问题，提出了一种整合可穿戴传感器数据和自我报告日记的多模态深度学习模型，该模型结合Transformer encoder和预训练语言模型，实现个性化影响预测。研究通过为期一年的纵向研究，收集大学生的生理、环境、睡眠、代谢、身体活动数据以及开放式文本日记，进行全面数据分析。结果显示，该模型可提前一周预测积极affect的准确率达82.50%，消极affect达82.76%，并具备良好的解释性。该方法有效弥补了现有研究的局限，提升了影响预测的准确性和全面性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Connected Health: Applications, Systems and Engineering\n  Technologies (CHASE) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.13841v2",
      "published_date": "2024-03-16 17:24:38 UTC",
      "updated_date": "2024-03-23 18:27:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:08:49.962383"
    },
    {
      "arxiv_id": "2403.10968v1",
      "title": "Enhancing IoT Security Against DDoS Attacks through Federated Learning",
      "title_zh": "通过联邦学习增强物联网安全以对抗 DDoS 攻击",
      "authors": [
        "Ghazaleh Shirvani",
        "Saeid Ghasemshirazi",
        "Mohammad Ali Alipour"
      ],
      "abstract": "The rapid proliferation of the Internet of Things (IoT) has ushered in\ntransformative connectivity between physical devices and the digital realm.\nNonetheless, the escalating threat of Distributed Denial of Service (DDoS)\nattacks jeopardizes the integrity and reliability of IoT networks. Conventional\nDDoS mitigation approaches are ill-equipped to handle the intricacies of IoT\necosystems, potentially compromising data privacy. This paper introduces an\ninnovative strategy to bolster the security of IoT networks against DDoS\nattacks by harnessing the power of Federated Learning that allows multiple IoT\ndevices or edge nodes to collaboratively build a global model while preserving\ndata privacy and minimizing communication overhead. The research aims to\ninvestigate Federated Learning's effectiveness in detecting and mitigating DDoS\nattacks in IoT. Our proposed framework leverages IoT devices' collective\nintelligence for real-time attack detection without compromising sensitive\ndata. This study proposes innovative deep autoencoder approaches for data\ndimensionality reduction, retraining, and partial selection to enhance the\nperformance and stability of the proposed model. Additionally, two renowned\naggregation algorithms, FedAvg and FedAvgM, are employed in this research.\nVarious metrics, including true positive rate, false positive rate, and\nF1-score, are employed to evaluate the model. The dataset utilized in this\nresearch, N-BaIoT, exhibits non-IID data distribution, where data categories\nare distributed quite differently. The negative impact of these distribution\ndisparities is managed by employing retraining and partial selection\ntechniques, enhancing the final model's stability. Furthermore, evaluation\nresults demonstrate that the FedAvgM aggregation algorithm outperforms FedAvg,\nindicating that in non-IID datasets, FedAvgM provides better stability and\nperformance.",
      "tldr_zh": "本研究针对物联网（IoT）网络中分布式拒绝服务（DDoS）攻击的威胁，提出了一种基于Federated Learning的创新框架，以实现实时攻击检测，同时保护数据隐私并减少通信开销。该框架利用IoT设备的集体智能，结合创新的deep autoencoder方法进行数据降维、重训练和部分选择，并采用FedAvg和FedAvgM聚合算法来提升模型性能和稳定性。在使用非独立同分布（non-IID）数据集N-BaIoT的实验中，该框架显著提高了真阳性率、F1-score等指标，且FedAvgM算法在处理数据分布不均时表现出色，优于FedAvg。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10968v1",
      "published_date": "2024-03-16 16:45:28 UTC",
      "updated_date": "2024-03-16 16:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:09:02.952991"
    },
    {
      "arxiv_id": "2403.10967v2",
      "title": "Dreaming of Many Worlds: Learning Contextual World Models Aids Zero-Shot Generalization",
      "title_zh": "梦境中的多元世界：学习上下文世界模型有助于零样本泛化",
      "authors": [
        "Sai Prasanna",
        "Karim Farid",
        "Raghu Rajan",
        "André Biedenkapp"
      ],
      "abstract": "Zero-shot generalization (ZSG) to unseen dynamics is a major challenge for\ncreating generally capable embodied agents. To address the broader challenge,\nwe start with the simpler setting of contextual reinforcement learning (cRL),\nassuming observability of the context values that parameterize the variation in\nthe system's dynamics, such as the mass or dimensions of a robot, without\nmaking further simplifying assumptions about the observability of the Markovian\nstate. Toward the goal of ZSG to unseen variation in context, we propose the\ncontextual recurrent state-space model (cRSSM), which introduces changes to the\nworld model of Dreamer (v3) (Hafner et al., 2023). This allows the world model\nto incorporate context for inferring latent Markovian states from the\nobservations and modeling the latent dynamics. Our approach is evaluated on two\ntasks from the CARL benchmark suite, which is tailored to study contextual RL.\nOur experiments show that such systematic incorporation of the context improves\nthe ZSG of the policies trained on the \"dreams\" of the world model. We further\nfind qualitatively that our approach allows Dreamer to disentangle the latent\nstate from context, allowing it to extrapolate its dreams to the many worlds of\nunseen contexts. The code for all our experiments is available at\nhttps://github.com/sai-prasanna/dreaming_of_many_worlds.",
      "tldr_zh": "该论文针对零样本泛化（Zero-Shot Generalization）挑战，提出 contextual recurrent state-space model (cRSSM)，这是一种对 Dreamer (v3) 世界模型的改进，用于 contextual reinforcement learning (cRL)，通过整合可观察上下文（如机器人参数）来推断潜在 Markovian 状态并建模动态。实验在 CARL 基准任务上显示，该方法显著提升了基于世界模型“梦想”训练的策略在未见动态下的泛化性能。进一步分析表明，cRSSM 能将潜在状态与上下文分离，从而实现对新上下文的可靠外推。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "In Reinforcement Learning Conference, 2024. 33 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.10967v2",
      "published_date": "2024-03-16 16:29:40 UTC",
      "updated_date": "2024-08-03 14:25:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:09:16.733108"
    },
    {
      "arxiv_id": "2405.10322v1",
      "title": "Exploring the Independent Cascade Model and Its Evolution in Social Network Information Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Jixuan He",
        "Yutong Guo",
        "Jiacheng Zhao"
      ],
      "abstract": "This paper delves into the paramount significance of information\ndissemination within the dynamic realm of social networks. It underscores the\npivotal role of information communication models in unraveling the intricacies\nof data propagation in the digital age. By shedding light on the profound\ninfluence of these models, it not only lays the groundwork for exploring\nvarious hierarchies and their manifestations but also serves as a catalyst for\nfurther research in this formidable field.",
      "tldr_zh": "这篇论文探讨了 Independent Cascade Model 在社交网络信息扩散中的作用及其演变，强调了信息通信模型在理解数字时代数据传播复杂性的关键意义。该模型有助于揭示各种层次结构的表现形式，并为深入分析社交网络动态提供理论基础。通过这一研究，论文为该领域的进一步探索奠定了 groundwork。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.10322v1",
      "published_date": "2024-03-16 15:32:13 UTC",
      "updated_date": "2024-03-16 15:32:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:09:26.469448"
    },
    {
      "arxiv_id": "2403.10949v2",
      "title": "SelfIE: Self-Interpretation of Large Language Model Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Chen",
        "Carl Vondrick",
        "Chengzhi Mao"
      ],
      "abstract": "How do large language models (LLMs) obtain their answers? The ability to\nexplain and control an LLM's reasoning process is key for reliability,\ntransparency, and future model developments. We propose SelfIE\n(Self-Interpretation of Embeddings), a framework that enables LLMs to interpret\ntheir own embeddings in natural language by leveraging their ability to respond\nto inquiries about a given passage. Capable of interpreting open-world concepts\nin the hidden embeddings, SelfIE reveals LLM internal reasoning in cases such\nas making ethical decisions, internalizing prompt injection, and recalling\nharmful knowledge. SelfIE's text descriptions on hidden embeddings also open up\nnew avenues to control LLM reasoning. We propose Supervised Control, which\nallows editing open-ended concepts while only requiring gradient computation of\nindividual layer. We extend RLHF to hidden embeddings and propose Reinforcement\nControl that erases harmful knowledge in LLM without supervision targets.",
      "tldr_zh": "本研究提出SelfIE框架，让大型语言模型(LLMs)通过自然语言解释自身的嵌入(embeddings)，利用模型对给定段落查询的响应能力，揭示隐藏概念的内部推理过程。SelfIE能够展示LLMs在道德决策、提示注入和回忆有害知识等方面的推理机制，为模型的可解释性和可靠性提供新见解。该框架还引入Supervised Control和Reinforcement Control方法，前者通过编辑概念仅需计算单个层的梯度，后者扩展RLHF到隐藏嵌入中，以无监督方式消除有害知识，从而实现对LLMs推理过程的有效控制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10949v2",
      "published_date": "2024-03-16 15:30:34 UTC",
      "updated_date": "2024-03-26 01:15:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:09:38.045182"
    },
    {
      "arxiv_id": "2403.10944v1",
      "title": "Human Centered AI for Indian Legal Text Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Sudipto Ghosh",
        "Devanshu Verma",
        "Balaji Ganesan",
        "Purnima Bindal",
        "Vikas Kumar",
        "Vasudha Bhatnagar"
      ],
      "abstract": "Legal research is a crucial task in the practice of law. It requires intense\nhuman effort and intellectual prudence to research a legal case and prepare\narguments. Recent boom in generative AI has not translated to proportionate\nrise in impactful legal applications, because of low trustworthiness and and\nthe scarcity of specialized datasets for training Large Language Models (LLMs).\nThis position paper explores the potential of LLMs within Legal Text Analytics\n(LTA), highlighting specific areas where the integration of human expertise can\nsignificantly enhance their performance to match that of experts. We introduce\na novel dataset and describe a human centered, compound AI system that\nprincipally incorporates human inputs for performing LTA tasks with LLMs.",
      "tldr_zh": "这篇立场论文探讨了以人为中心的AI在印度法律文本分析(LTA)中的应用，旨在解决法律研究中人力密集型挑战和生成AI的低可信度问题，如专业数据集的稀缺。论文强调整合人类专业知识能显著提升Large Language Models (LLMs)的性能，使其在LTA任务中媲美专家水平。作者引入了一个新数据集，并描述了一个复合AI系统，该系统通过优先整合人类输入来优化法律文本分析过程。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10944v1",
      "published_date": "2024-03-16 15:17:13 UTC",
      "updated_date": "2024-03-16 15:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:09:51.212050"
    },
    {
      "arxiv_id": "2405.01554v1",
      "title": "Early-stage detection of cognitive impairment by hybrid quantum-classical algorithm using resting-state functional MRI time-series",
      "title_zh": "翻译失败",
      "authors": [
        "Junggu Choi",
        "Tak Hur",
        "Daniel K. Park",
        "Na-Young Shin",
        "Seung-Koo Lee",
        "Hakbae Lee",
        "Sanghoon Han"
      ],
      "abstract": "Following the recent development of quantum machine learning techniques, the\nliterature has reported several quantum machine learning algorithms for disease\ndetection. This study explores the application of a hybrid quantum-classical\nalgorithm for classifying region-of-interest time-series data obtained from\nresting-state functional magnetic resonance imaging in patients with\nearly-stage cognitive impairment based on the importance of cognitive decline\nfor dementia or aging. Classical one-dimensional convolutional layers are used\ntogether with quantum convolutional neural networks in our hybrid algorithm. In\nthe classical simulation, the proposed hybrid algorithms showed higher balanced\naccuracies than classical convolutional neural networks under the similar\ntraining conditions. Moreover, a total of nine brain regions (left precentral\ngyrus, right superior temporal gyrus, left rolandic operculum, right rolandic\noperculum, left parahippocampus, right hippocampus, left medial frontal gyrus,\nright cerebellum crus, and cerebellar vermis) among 116 brain regions were\nfound to be relatively effective brain regions for the classification based on\nthe model performances. The associations of the selected nine regions with\ncognitive decline, as found in previous studies, were additionally validated\nthrough seed-based functional connectivity analysis. We confirmed both the\nimprovement of model performance with the quantum convolutional neural network\nand neuroscientific validities of brain regions from our hybrid\nquantum-classical model.",
      "tldr_zh": "本研究提出了一种混合量子-经典算法，用于利用静息态功能磁共振成像 (resting-state functional MRI) 时间序列数据检测早期认知障碍。该算法结合了经典一维卷积层和量子卷积神经网络 (quantum convolutional neural networks)，在模拟实验中显示出比传统 CNN 更高的平衡准确率。研究识别出九个关键脑区（包括 left precentral gyrus、right superior temporal gyrus 等），这些区域在分类任务中表现突出，并通过种子-based functional connectivity analysis 验证了它们与认知衰退的关联。该方法不仅提升了模型性能，还为早期认知障碍诊断提供了神经科学依据。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01554v1",
      "published_date": "2024-03-16 15:10:50 UTC",
      "updated_date": "2024-03-16 15:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:10:02.621246"
    },
    {
      "arxiv_id": "2403.10930v1",
      "title": "Inducing Individual Students' Learning Strategies through Homomorphic POMDPs",
      "title_zh": "通过同态 POMDPs 诱导个体学生的学习策略",
      "authors": [
        "Huifan Gao",
        "Yifeng Zeng",
        "Yinghui Pan"
      ],
      "abstract": "Optimizing students' learning strategies is a crucial component in\nintelligent tutoring systems. Previous research has demonstrated the\neffectiveness of devising personalized learning strategies for students by\nmodelling their learning processes through partially observable Markov decision\nprocess (POMDP). However, the research holds the assumption that the student\npopulation adheres to a uniform cognitive pattern. While this assumption\nsimplifies the POMDP modelling process, it evidently deviates from a real-world\nscenario, thus reducing the precision of inducing individual students' learning\nstrategies. In this article, we propose the homomorphic POMDP (H-POMDP) model\nto accommodate multiple cognitive patterns and present the parameter learning\napproach to automatically construct the H-POMDP model. Based on the H-POMDP\nmodel, we are able to represent different cognitive patterns from the data and\ninduce more personalized learning strategies for individual students. We\nconduct experiments to show that, in comparison to the general POMDP approach,\nthe H-POMDP model demonstrates better precision when modelling mixed data from\nmultiple cognitive patterns. Moreover, the learning strategies derived from\nH-POMDPs exhibit better personalization in the performance evaluation.",
      "tldr_zh": "该论文针对智能辅导系统中优化学生学习策略的问题，指出传统POMDP模型假设学生认知模式统一，导致个性化策略不精确。作者提出homomorphic POMDP (H-POMDP)模型，通过参数学习方法自动构建，以适应多种认知模式并从数据中提取差异化认知特征，从而为个体学生生成更个性化的学习策略。实验结果显示，H-POMDP在处理混合数据时比一般POMDP模型更精确，且其派生的学习策略在性能评估中表现出更好的个性化效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11pages, 3figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10930v1",
      "published_date": "2024-03-16 14:06:29 UTC",
      "updated_date": "2024-03-16 14:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:10:14.511015"
    },
    {
      "arxiv_id": "2403.10923v2",
      "title": "Interpretable Machine Learning for TabPFN",
      "title_zh": "翻译失败",
      "authors": [
        "David Rundel",
        "Julius Kobialka",
        "Constantin von Crailsheim",
        "Matthias Feurer",
        "Thomas Nagler",
        "David Rügamer"
      ],
      "abstract": "The recently developed Prior-Data Fitted Networks (PFNs) have shown very\npromising results for applications in low-data regimes. The TabPFN model, a\nspecial case of PFNs for tabular data, is able to achieve state-of-the-art\nperformance on a variety of classification tasks while producing posterior\npredictive distributions in mere seconds by in-context learning without the\nneed for learning parameters or hyperparameter tuning. This makes TabPFN a very\nattractive option for a wide range of domain applications. However, a major\ndrawback of the method is its lack of interpretability. Therefore, we propose\nseveral adaptations of popular interpretability methods that we specifically\ndesign for TabPFN. By taking advantage of the unique properties of the model,\nour adaptations allow for more efficient computations than existing\nimplementations. In particular, we show how in-context learning facilitates the\nestimation of Shapley values by avoiding approximate retraining and enables the\nuse of Leave-One-Covariate-Out (LOCO) even when working with large-scale\nTransformers. In addition, we demonstrate how data valuation methods can be\nused to address scalability challenges of TabPFN. Our proposed methods are\nimplemented in a package tabpfn_iml and made available at\nhttps://github.com/david-rundel/tabpfn_iml.",
      "tldr_zh": "该研究针对TabPFN（一种基于Prior-Data Fitted Networks的表格数据模型），提出了一系列可解释性方法，以解决其缺乏解释性的缺点。利用TabPFN的in-context learning特性，作者改进了现有解释技术，如Shapley values的估计和Leave-One-Covariate-Out (LOCO)方法，实现更高效的计算，并通过数据估值方法处理可伸缩性挑战。这些改进使TabPFN在低数据环境下更易于解释和应用，并提供了开源包tabpfn_iml以供使用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.CO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Explainable Artificial Intelligence, and is available online at\n  https://doi.org/10.1007/978-3-031-63797-1_23",
      "pdf_url": "http://arxiv.org/pdf/2403.10923v2",
      "published_date": "2024-03-16 13:35:15 UTC",
      "updated_date": "2024-07-23 16:10:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:10:26.946145"
    },
    {
      "arxiv_id": "2403.10903v4",
      "title": "DTOR: Decision Tree Outlier Regressor to explain anomalies",
      "title_zh": "DTOR：决策树异常值",
      "authors": [
        "Riccardo Crupi",
        "Daniele Regoli",
        "Alessandro Damiano Sabatino",
        "Immacolata Marano",
        "Massimiliano Brinis",
        "Luca Albertazzi",
        "Andrea Cirillo",
        "Andrea Claudio Cosentini"
      ],
      "abstract": "Explaining outliers occurrence and mechanism of their occurrence can be\nextremely important in a variety of domains. Malfunctions, frauds, threats, in\naddition to being correctly identified, oftentimes need a valid explanation in\norder to effectively perform actionable counteracts. The ever more widespread\nuse of sophisticated Machine Learning approach to identify anomalies make such\nexplanations more challenging. We present the Decision Tree Outlier Regressor\n(DTOR), a technique for producing rule-based explanations for individual data\npoints by estimating anomaly scores generated by an anomaly detection model.\nThis is accomplished by first applying a Decision Tree Regressor, which\ncomputes the estimation score, and then extracting the relative path associated\nwith the data point score. Our results demonstrate the robustness of DTOR even\nin datasets with a large number of features. Additionally, in contrast to other\nrule-based approaches, the generated rules are consistently satisfied by the\npoints to be explained. Furthermore, our evaluation metrics indicate comparable\nperformance to Anchors in outlier explanation tasks, with reduced execution\ntime.",
      "tldr_zh": "这篇论文提出了 Decision Tree Outlier Regressor (DTOR)，一种基于规则的方法，用于解释异常检测模型的异常分数，从而帮助理解异常的发生机制，如故障、欺诈或威胁。DTOR 通过应用 Decision Tree Regressor 估计异常分数，并提取与数据点相关的路径规则，确保生成的解释规则始终适用于目标点。实验结果表明，DTOR 在特征数量多的数据集上表现出强鲁棒性，与 Anchors 方法性能相当，但执行时间更短，为异常解释任务提供了高效可行的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10903v4",
      "published_date": "2024-03-16 11:38:31 UTC",
      "updated_date": "2024-05-12 17:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:10:38.901885"
    },
    {
      "arxiv_id": "2403.10882v2",
      "title": "Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean",
      "title_zh": "翻译失败",
      "authors": [
        "ChangSu Choi",
        "Yongbin Jeong",
        "Seoyoon Park",
        "InHo Won",
        "HyeonSeok Lim",
        "SangMin Kim",
        "Yejee Kang",
        "Chanhyuk Yoon",
        "Jaewan Park",
        "Yiseul Lee",
        "HyeJin Lee",
        "Younggyun Hahm",
        "Hansaem Kim",
        "KyungTae Lim"
      ],
      "abstract": "Large language models (LLMs) use pretraining to predict the subsequent word;\nhowever, their expansion requires significant computing resources. Numerous big\ntech companies and research institutes have developed multilingual LLMs (MLLMs)\nto meet current demands, overlooking less-resourced languages (LRLs). This\nstudy proposed three strategies to enhance the performance of LRLs based on the\npublicly available MLLMs. First, the MLLM vocabularies of LRLs were expanded to\nenhance expressiveness. Second, bilingual data were used for pretraining to\nalign the high- and less-resourced languages. Third, a high-quality small-scale\ninstruction dataset was constructed and instruction-tuning was performed to\naugment the LRL. The experiments employed the Llama2 model and Korean was used\nas the LRL, which was quantitatively evaluated against other developed LLMs\nacross eight tasks. Furthermore, a qualitative assessment was performed based\non human evaluation and GPT4. Experimental results showed that our proposed\nBllossom model exhibited superior performance in qualitative analyses compared\nto previously proposed Korean monolingual models.",
      "tldr_zh": "本研究针对多语言大型语言模型（MLLMs）在资源不足语言（LRLs）上的性能不足，提出三种优化策略，以韩语为例提升模型效果。第一，扩展 LRLs 的 MLLM 词汇表以增强表达性；第二，使用双语数据进行预训练，实现高资源语言与 LRLs 的对齐；第三，构建高质量小规模指令数据集并进行 instruction-tuning。实验基于 Llama2 模型，在八个任务上进行定量评估，并通过人类评估和 GPT4 进行定性分析，结果显示提出的 Bllossom 模型在韩语任务中优于现有韩语单语言模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10882v2",
      "published_date": "2024-03-16 10:26:38 UTC",
      "updated_date": "2024-03-21 14:50:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:10:52.168630"
    },
    {
      "arxiv_id": "2403.10863v1",
      "title": "stMCDI: Masked Conditional Diffusion Model with Graph Neural Network for Spatial Transcriptomics Data Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Li",
        "Wenwen Min",
        "Shunfang Wang",
        "Changmiao Wang",
        "Taosheng Xu"
      ],
      "abstract": "Spatially resolved transcriptomics represents a significant advancement in\nsingle-cell analysis by offering both gene expression data and their\ncorresponding physical locations. However, this high degree of spatial\nresolution entails a drawback, as the resulting spatial transcriptomic data at\nthe cellular level is notably plagued by a high incidence of missing values.\nFurthermore, most existing imputation methods either overlook the spatial\ninformation between spots or compromise the overall gene expression data\ndistribution. To address these challenges, our primary focus is on effectively\nutilizing the spatial location information within spatial transcriptomic data\nto impute missing values, while preserving the overall data distribution. We\nintroduce \\textbf{stMCDI}, a novel conditional diffusion model for spatial\ntranscriptomics data imputation, which employs a denoising network trained\nusing randomly masked data portions as guidance, with the unmasked data serving\nas conditions. Additionally, it utilizes a GNN encoder to integrate the spatial\nposition information, thereby enhancing model performance. The results obtained\nfrom spatial transcriptomics datasets elucidate the performance of our methods\nrelative to existing approaches.",
      "tldr_zh": "空间转录组学数据因高分辨率而存在大量缺失值，现有的填充方法往往忽略了空间信息或破坏了整体基因表达分布。  \n本文提出 stMCDI，一种新型的 masked conditional diffusion model，用于空间转录组数据填充，该模型通过随机掩码数据作为指导、非掩码数据作为条件，并利用 Graph Neural Network (GNN) 编码器整合空间位置信息，以提升填充准确性。  \n实验结果表明，stMCDI 在多个空间转录组学数据集上表现优于现有方法，有效保留了数据分布，为单细胞分析提供了更可靠的工具。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "Submitted to IJCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10863v1",
      "published_date": "2024-03-16 09:06:38 UTC",
      "updated_date": "2024-03-16 09:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:11:06.294310"
    },
    {
      "arxiv_id": "2403.10860v2",
      "title": "Sim2Real within 5 Minutes: Efficient Domain Transfer with Stylized Gaussian Splatting for Endoscopic Images",
      "title_zh": "翻译失败",
      "authors": [
        "Junyang Wu",
        "Yun Gu",
        "Guang-Zhong Yang"
      ],
      "abstract": "Robot assisted endoluminal intervention is an emerging technique for both\nbenign and malignant luminal lesions. With vision-based navigation, when\ncombined with pre-operative imaging data as priors, it is possible to recover\nposition and pose of the endoscope without the need of additional sensors. In\npractice, however, aligning pre-operative and intra-operative domains is\ncomplicated by significant texture differences. Although methods such as style\ntransfer can be used to address this issue, they require large datasets from\nboth source and target domains with prolonged training times. This paper\nproposes an efficient domain transfer method based on stylized Gaussian\nsplatting, only requiring a few of real images (10 images) with very fast\ntraining time. Specifically, the transfer process includes two phases. In the\nfirst phase, the 3D models reconstructed from CT scans are represented as\ndifferential Gaussian point clouds. In the second phase, only color appearance\nrelated parameters are optimized to transfer the style and preserve the visual\ncontent. A novel structure consistency loss is applied to latent features and\ndepth levels to enhance the stability of the transferred images. Detailed\nvalidation was performed to demonstrate the performance advantages of the\nproposed method compared to that of the current state-of-the-art, highlighting\nthe potential for intra-operative surgical navigation.",
      "tldr_zh": "该论文提出了一种高效的Sim2Real域转移方法，用于内镜图像处理，仅需5分钟训练时间和少量真实图像（10张），以解决预手术和手术中图像纹理差异的问题。方法基于stylized Gaussian splatting，将CT扫描重建的3D模型表示为差分Gaussian点云，并在第二阶段优化颜色外观参数，同时引入novel structure consistency loss在潜在特征和深度级别上，以保持视觉内容稳定并增强图像转移效果。与现有最先进方法相比，该方法在性能上表现出显著优势，为机器人辅助手术导航提供了潜在的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.10860v2",
      "published_date": "2024-03-16 08:57:00 UTC",
      "updated_date": "2025-03-05 12:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:11:18.002286"
    },
    {
      "arxiv_id": "2403.10853v3",
      "title": "Just Say the Name: Online Continual Learning with Category Names Only via Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Minhyuk Seo",
        "Seongwon Cho",
        "Minjae Lee",
        "Diganta Misra",
        "Hyeonbeom Choi",
        "Seon Joo Kim",
        "Jonghyun Choi"
      ],
      "abstract": "Requiring extensive human supervision is often impractical for continual\nlearning due to its cost, leading to the emergence of 'name-only continual\nlearning' that only provides the name of new concepts (e.g., classes) without\nproviding supervised samples. To address the task, recent approach uses\nweb-scraped data but results in issues such as data imbalance, copyright, and\nprivacy concerns. To overcome the limitations of both human supervision and\nwebly supervision, we propose Generative name only Continual Learning (GenCL)\nusing generative models for the name only continual learning. But na\\\"ive\napplication of generative models results in limited diversity of generated\ndata. So, we specifically propose a diverse prompt generation method,\nHIerarchical Recurrent Prompt Generation (HIRPG) as well as\nCOmplexity-NAvigating eNsembler (CONAN) that selects samples with minimal\noverlap from multiple generative models. We empirically validate that the\nproposed GenCL outperforms prior arts, even a model trained with fully\nsupervised data, in various tasks including image recognition and multi-modal\nvisual reasoning. Data generated by GenCL is available at\nhttps://anonymous.4open.science/r/name-only-continual-E079.",
      "tldr_zh": "该研究针对持续学习（continual learning）中监督数据成本高的问题，提出了一种仅使用类别名称的在线学习方法，即Generative name only Continual Learning (GenCL)，通过生成模型创建数据来避免使用网络抓取数据的缺陷。GenCL 引入了 HIerarchical Recurrent Prompt Generation (HIRPG) 来生成多样化的提示，以及 COmplexity-NAvigating eNsembler (CONAN) 来从多个生成模型中选择最小重叠的样本，从而提升生成数据的多样性和质量。实验结果显示，GenCL 在图像识别和多模态视觉推理等任务中超过了现有方法，甚至优于完全监督训练的模型，为高效的持续学习提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10853v3",
      "published_date": "2024-03-16 08:28:42 UTC",
      "updated_date": "2024-10-19 14:51:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:11:29.615580"
    },
    {
      "arxiv_id": "2403.10850v1",
      "title": "GAgent: An Adaptive Rigid-Soft Gripping Agent with Vision Language Models for Complex Lighting Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuowei Li",
        "Miao Zhang",
        "Xiaotian Lin",
        "Meng Yin",
        "Shuai Lu",
        "Xueqian Wang"
      ],
      "abstract": "This paper introduces GAgent: an Gripping Agent designed for open-world\nenvironments that provides advanced cognitive abilities via VLM agents and\nflexible grasping abilities with variable stiffness soft grippers. GAgent\ncomprises three primary components - Prompt Engineer module, Visual-Language\nModel (VLM) core and Workflow module. These three modules enhance gripper\nsuccess rates by recognizing objects and materials and accurately estimating\ngrasp area even under challenging lighting conditions. As part of creativity,\nresearchers also created a bionic hybrid soft gripper with variable stiffness\ncapable of gripping heavy loads while still gently engaging objects. This\nintelligent agent, featuring VLM-based cognitive processing with bionic design,\nshows promise as it could potentially benefit UAVs in various scenarios.",
      "tldr_zh": "该研究引入了 GAgent，一种适应性刚柔抓握代理，利用 Vision Language Models (VLM) 提供高级认知能力，以应对复杂照明环境的挑战。GAgent 由 Prompt Engineer 模块、VLM 核心和 Workflow 模块组成，这些组件通过识别物体和材料并准确估计抓握区域，提高了抓握成功率。研究者还设计了仿生混合软抓握器，具有可变刚度，能安全抓取重物同时温柔接触目标。总体而言，该代理展示了在开放世界场景中的潜力，特别是为 UAV 等应用提供可靠的抓握解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10850v1",
      "published_date": "2024-03-16 08:10:23 UTC",
      "updated_date": "2024-03-16 08:10:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:11:40.815234"
    },
    {
      "arxiv_id": "2403.10842v4",
      "title": "Twin Transformer using Gated Dynamic Learnable Attention mechanism for Fault Detection and Diagnosis in the Tennessee Eastman Process",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Ali Labbaf-Khaniki",
        "Mohammad Manthouri",
        "Hanieh Ajami"
      ],
      "abstract": "Fault detection and diagnosis (FDD) is a crucial task for ensuring the safety\nand efficiency of industrial processes. We propose a novel FDD methodology for\nthe Tennessee Eastman Process (TEP), a widely used benchmark for chemical\nprocess control. The model employs two separate Transformer branches, enabling\nindependent processing of input data and potential extraction of diverse\ninformation. A novel attention mechanism, Gated Dynamic Learnable Attention\n(GDLAttention), is introduced which integrates a gating mechanism and dynamic\nlearning capabilities. The gating mechanism modulates the attention weights,\nallowing the model to focus on the most relevant parts of the input. The\ndynamic learning approach adapts the attention strategy during training,\npotentially leading to improved performance. The attention mechanism uses a\nbilinear similarity function, providing greater flexibility in capturing\ncomplex relationships between query and key vectors. In order to assess the\neffectiveness of our approach, we tested it against 21 and 18 distinct fault\nscenarios in TEP, and compared its performance with several established FDD\ntechniques. The outcomes indicate that the method outperforms others in terms\nof accuracy, false alarm rate, and misclassification rate. This underscores the\nrobustness and efficacy of the approach for FDD in intricate industrial\nprocesses.",
      "tldr_zh": "本文提出了一种新型故障检测和诊断 (FDD) 方法，基于 Twin Transformer 架构应用于 Tennessee Eastman Process (TEP) 基准，用于提升工业过程的安全性和效率。该方法引入 Gated Dynamic Learnable Attention (GDLAttention) 机制，结合 gating 机制调节注意力权重、dynamic learning 适应训练过程，以及 bilinear similarity function 捕捉查询和键向量间的复杂关系，从而实现对输入数据的独立处理和信息提取。在 TEP 的 21 和 18 个故障场景中，该方法与现有 FDD 技术相比，在准确率、假警报率和误分类率上表现出显著优势，证明了其鲁棒性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10842v4",
      "published_date": "2024-03-16 07:40:23 UTC",
      "updated_date": "2024-11-25 17:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:11:53.608914"
    },
    {
      "arxiv_id": "2405.15773v2",
      "title": "Feature Aggregation with Latent Generative Replay for Federated Continual Learning of Socially Appropriate Robot Behaviours",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Churamani",
        "Saksham Checker",
        "Fethiye Irmak Dogan",
        "Hao-Tien Lewis Chiang",
        "Hatice Gunes"
      ],
      "abstract": "It is critical for robots to explore Federated Learning (FL) settings where\nseveral robots, deployed in parallel, can learn independently while also\nsharing their learning with each other. This collaborative learning in\nreal-world environments requires social robots to adapt dynamically to changing\nand unpredictable situations and varying task settings. Our work contributes to\naddressing these challenges by exploring a simulated living room environment\nwhere robots need to learn the social appropriateness of their actions. First,\nwe propose Federated Root (FedRoot) averaging, a novel weight aggregation\nstrategy which disentangles feature learning across clients from individual\ntask-based learning. Second, to adapt to challenging environments, we extend\nFedRoot to Federated Latent Generative Replay (FedLGR), a novel Federated\nContinual Learning (FCL) strategy that uses FedRoot-based weight aggregation\nand embeds each client with a generator model for pseudo-rehearsal of learnt\nfeature embeddings to mitigate forgetting in a resource-efficient manner. Our\nresults show that FedRoot-based methods offer competitive performance while\nalso resulting in a sizeable reduction in resource consumption (up to 86% for\nCPU usage and up to 72% for GPU usage). Additionally, our results demonstrate\nthat FedRoot-based FCL methods outperform other methods while also offering an\nefficient solution (up to 84% CPU and 92% GPU usage reduction), with FedLGR\nproviding the best results across evaluations.",
      "tldr_zh": "本研究探讨了机器人利用 Federated Learning (FL) 在分布式环境中协同学习社会适当行为的问题，以适应动态变化的任务场景。论文提出 Federated Root (FedRoot) averaging，一种新型权重聚合策略，将特征学习与任务学习分离，从而提高效率并减少资源消耗。进一步扩展为 Federated Latent Generative Replay (FedLGR)，这是一种 Federated Continual Learning (FCL) 方法，通过嵌入生成器模型进行伪重演，缓解模型遗忘问题。实验结果显示，FedRoot 相关方法在性能上与基准相当，同时降低资源使用量（CPU 最高86%、GPU 最高72%），而 FedLGR 在 FCL 任务中表现出色，提供最佳结果并进一步优化资源效率（CPU 最高84%、GPU 最高92% 减少）。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures, IEEE RA-L submission",
      "pdf_url": "http://arxiv.org/pdf/2405.15773v2",
      "published_date": "2024-03-16 07:34:33 UTC",
      "updated_date": "2025-02-21 11:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:12:04.872112"
    },
    {
      "arxiv_id": "2403.10834v1",
      "title": "SF(DA)$^2$: Source-free Domain Adaptation Through the Lens of Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Uiwon Hwang",
        "Jonghyun Lee",
        "Juhyeon Shin",
        "Sungroh Yoon"
      ],
      "abstract": "In the face of the deep learning model's vulnerability to domain shift,\nsource-free domain adaptation (SFDA) methods have been proposed to adapt models\nto new, unseen target domains without requiring access to source domain data.\nAlthough the potential benefits of applying data augmentation to SFDA are\nattractive, several challenges arise such as the dependence on prior knowledge\nof class-preserving transformations and the increase in memory and\ncomputational requirements. In this paper, we propose Source-free Domain\nAdaptation Through the Lens of Data Augmentation (SF(DA)$^2$), a novel approach\nthat leverages the benefits of data augmentation without suffering from these\nchallenges. We construct an augmentation graph in the feature space of the\npretrained model using the neighbor relationships between target features and\npropose spectral neighborhood clustering to identify partitions in the\nprediction space. Furthermore, we propose implicit feature augmentation and\nfeature disentanglement as regularization loss functions that effectively\nutilize class semantic information within the feature space. These regularizers\nsimulate the inclusion of an unlimited number of augmented target features into\nthe augmentation graph while minimizing computational and memory demands. Our\nmethod shows superior adaptation performance in SFDA scenarios, including 2D\nimage and 3D point cloud datasets and a highly imbalanced dataset.",
      "tldr_zh": "这篇论文提出了一种名为SF(DA)$^2$的源域无访问领域适应(Source-free Domain Adaptation)方法，通过数据增强的视角解决深度学习模型在领域偏移问题上的脆弱性，同时避免了传统方法对类保持变换的依赖和资源消耗增加。核心创新包括在预训练模型的特征空间构建增强图、使用谱邻域聚类(spectral neighborhood clustering)识别预测空间分区，以及引入隐式特征增强(implicit feature augmentation)和特征解耦(feature disentanglement)作为正则化损失函数，以有效利用类语义信息并模拟无限增强目标特征。实验结果显示，该方法在SFDA场景中表现出色，包括2D图像、3D点云数据集和高度不平衡数据集上实现了优越的适应性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2024. Code: https://github.com/shinyflight/SFDA2",
      "pdf_url": "http://arxiv.org/pdf/2403.10834v1",
      "published_date": "2024-03-16 07:05:47 UTC",
      "updated_date": "2024-03-16 07:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:12:18.803166"
    },
    {
      "arxiv_id": "2403.10824v1",
      "title": "LookALike: Human Mimicry based collaborative decision making",
      "title_zh": "翻译失败",
      "authors": [
        "Rabimba Karanjai",
        "Weidong Shi"
      ],
      "abstract": "Artificial General Intelligence falls short when communicating role specific\nnuances to other systems. This is more pronounced when building autonomous LLM\nagents capable and designed to communicate with each other for real world\nproblem solving. Humans can communicate context and domain specific nuances\nalong with knowledge, and that has led to refinement of skills. In this work we\npropose and evaluate a novel method that leads to knowledge distillation among\nLLM agents leading to realtime human role play preserving unique contexts\nwithout relying on any stored data or pretraining. We also evaluate how our\nsystem performs better in simulated real world tasks compared to state of the\nart.",
      "tldr_zh": "该研究指出，人工通用智能(Artificial General Intelligence)及自主LLM代理在沟通角色特定细微差别和知识时存在不足，影响了真实世界问题的协作解决。为此，论文提出LookALike方法，通过人类模仿(Human Mimicry)实现LLM代理之间的知识蒸馏(knowledge distillation)，允许代理实时扮演人类角色并保留独特上下文，而无需依赖存储数据或预训练。实验结果显示，该系统在模拟真实世界任务中比现有技术表现出色，提升了协作决策的效能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10824v1",
      "published_date": "2024-03-16 06:25:53 UTC",
      "updated_date": "2024-03-16 06:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:12:28.795989"
    },
    {
      "arxiv_id": "2403.10823v1",
      "title": "VisionCLIP: An Med-AIGC based Ethical Language-Image Foundation Model for Generalizable Retina Image Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wei",
        "Bowen Liu",
        "Minqing Zhang",
        "Peilun Shi",
        "Wu Yuan"
      ],
      "abstract": "Generalist foundation model has ushered in newfound capabilities in medical\ndomain. However, the contradiction between the growing demand for high-quality\nannotated data with patient privacy continues to intensify. The utilization of\nmedical artificial intelligence generated content (Med-AIGC) as an\ninexhaustible resource repository arises as a potential solution to address the\naforementioned challenge. Here we harness 1 million open-source synthetic\nfundus images paired with natural language descriptions, to curate an ethical\nlanguage-image foundation model for retina image analysis named VisionCLIP.\nVisionCLIP achieves competitive performance on three external datasets compared\nwith the existing method pre-trained on real-world data in a zero-shot fashion.\nThe employment of artificially synthetic images alongside corresponding textual\ndata for training enables the medical foundation model to successfully\nassimilate knowledge of disease symptomatology, thereby circumventing potential\nbreaches of patient confidentiality.",
      "tldr_zh": "该研究针对医疗领域数据标注需求与患者隐私保护的矛盾，提出使用医疗AI生成内容(Med-AIGC)作为解决方案。研究者利用100万开源合成视网膜图像及其自然语言描述，训练了一个名为VisionCLIP的伦理语言-图像基础模型，以实现可泛化的视网膜图像分析。在零样本(zero-shot)设置下，VisionCLIP在三个外部数据集上表现与基于真实数据预训练的方法相当，同时成功学习疾病症状知识并避免了患者隐私泄露的风险。整体而言，该模型为高效、伦理的医疗图像分析提供了新范式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10823v1",
      "published_date": "2024-03-16 06:21:19 UTC",
      "updated_date": "2024-03-16 06:21:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:12:40.990948"
    },
    {
      "arxiv_id": "2403.10819v1",
      "title": "Incentivized Exploration of Non-Stationary Stochastic Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Sourav Chakraborty",
        "Lijun Chen"
      ],
      "abstract": "We study incentivized exploration for the multi-armed bandit (MAB) problem\nwith non-stationary reward distributions, where players receive compensation\nfor exploring arms other than the greedy choice and may provide biased feedback\non the reward. We consider two different non-stationary environments:\nabruptly-changing and continuously-changing, and propose respective\nincentivized exploration algorithms. We show that the proposed algorithms\nachieve sublinear regret and compensation over time, thus effectively\nincentivizing exploration despite the nonstationarity and the biased or drifted\nfeedback.",
      "tldr_zh": "这篇论文研究了非平稳随机多臂老虎机（Non-Stationary Stochastic Bandits）的激励探索问题，其中玩家通过探索非贪婪的臂获得补偿，但可能提供偏置反馈。作者针对两种非平稳环境——突然变化（abruptly-changing）和连续变化（continuously-changing）——提出了相应的激励探索算法。这些算法实现了次线性遗憾（sublinear regret）和补偿，随着时间推移有效激励探索，尽管存在偏置或漂移反馈。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10819v1",
      "published_date": "2024-03-16 06:06:44 UTC",
      "updated_date": "2024-03-16 06:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:12:52.716973"
    },
    {
      "arxiv_id": "2403.10805v1",
      "title": "Speech-driven Personalized Gesture Synthetics: Harnessing Automatic Fuzzy Feature Inference",
      "title_zh": "基于语音驱动的个性化手势合成：利用自动模糊特征推断",
      "authors": [
        "Fan Zhang",
        "Zhaohan Wang",
        "Xin Lyu",
        "Siyuan Zhao",
        "Mengjian Li",
        "Weidong Geng",
        "Naye Ji",
        "Hui Du",
        "Fuxing Gao",
        "Hao Wu",
        "Shunman Li"
      ],
      "abstract": "Speech-driven gesture generation is an emerging field within virtual human\ncreation. However, a significant challenge lies in accurately determining and\nprocessing the multitude of input features (such as acoustic, semantic,\nemotional, personality, and even subtle unknown features). Traditional\napproaches, reliant on various explicit feature inputs and complex multimodal\nprocessing, constrain the expressiveness of resulting gestures and limit their\napplicability. To address these challenges, we present Persona-Gestor, a novel\nend-to-end generative model designed to generate highly personalized 3D\nfull-body gestures solely relying on raw speech audio. The model combines a\nfuzzy feature extractor and a non-autoregressive Adaptive Layer Normalization\n(AdaLN) transformer diffusion architecture. The fuzzy feature extractor\nharnesses a fuzzy inference strategy that automatically infers implicit,\ncontinuous fuzzy features. These fuzzy features, represented as a unified\nlatent feature, are fed into the AdaLN transformer. The AdaLN transformer\nintroduces a conditional mechanism that applies a uniform function across all\ntokens, thereby effectively modeling the correlation between the fuzzy features\nand the gesture sequence. This module ensures a high level of gesture-speech\nsynchronization while preserving naturalness. Finally, we employ the diffusion\nmodel to train and infer various gestures. Extensive subjective and objective\nevaluations on the Trinity, ZEGGS, and BEAT datasets confirm our model's\nsuperior performance to the current state-of-the-art approaches. Persona-Gestor\nimproves the system's usability and generalization capabilities, setting a new\nbenchmark in speech-driven gesture synthesis and broadening the horizon for\nvirtual human technology. Supplementary videos and code can be accessed at\nhttps://zf223669.github.io/Diffmotion-v2-website/",
      "tldr_zh": "本研究提出了一种新型端到端生成模型Persona-Gestor，用于仅基于原始语音音频生成高度个性化的3D全身体势，解决了传统方法在处理声学、语义、情感和个性等特征时的局限性。模型结合fuzzy feature extractor和非自回归的AdaLN transformer diffusion架构，其中fuzzy feature extractor通过模糊推理策略自动推断隐式连续特征，并通过AdaLN transformer建模特征与手势序列的相关性，以确保手势与语音的高同步性和自然性。在Trinity、ZEGGS和BEAT数据集上的主客观评估显示，Persona-Gestor优于现有最先进方法，提高了系统可用性和泛化能力，并为语音驱动手势合成设定了新基准。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "cs.HC",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "12 pages,",
      "pdf_url": "http://arxiv.org/pdf/2403.10805v1",
      "published_date": "2024-03-16 04:40:10 UTC",
      "updated_date": "2024-03-16 04:40:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:13:07.238731"
    },
    {
      "arxiv_id": "2403.10803v1",
      "title": "Enhancing Out-of-Distribution Detection with Multitesting-based Layer-wise Feature Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Li",
        "Sitong Li",
        "Shanshan Wang",
        "Yicheng Zeng",
        "Falong Tan",
        "Chuanlong Xie"
      ],
      "abstract": "Deploying machine learning in open environments presents the challenge of\nencountering diverse test inputs that differ significantly from the training\ndata. These out-of-distribution samples may exhibit shifts in local or global\nfeatures compared to the training distribution. The machine learning (ML)\ncommunity has responded with a number of methods aimed at distinguishing\nanomalous inputs from original training data. However, the majority of previous\nstudies have primarily focused on the output layer or penultimate layer of\npre-trained deep neural networks. In this paper, we propose a novel framework,\nMultitesting-based Layer-wise Out-of-Distribution (OOD) Detection (MLOD), to\nidentify distributional shifts in test samples at different levels of features\nthrough rigorous multiple testing procedure. Our approach distinguishes itself\nfrom existing methods as it does not require modifying the structure or\nfine-tuning of the pre-trained classifier. Through extensive experiments, we\ndemonstrate that our proposed framework can seamlessly integrate with any\nexisting distance-based inspection method while efficiently utilizing feature\nextractors of varying depths. Our scheme effectively enhances the performance\nof out-of-distribution detection when compared to baseline methods. In\nparticular, MLOD-Fisher achieves superior performance in general. When trained\nusing KNN on CIFAR10, MLOD-Fisher significantly lowers the false positive rate\n(FPR) from 24.09% to 7.47% on average compared to merely utilizing the features\nof the last layer.",
      "tldr_zh": "这篇论文针对机器学习模型在开放环境中检测 Out-of-Distribution (OOD) 样本的挑战，提出了一种新型框架 Multitesting-based Layer-wise Out-of-Distribution Detection (MLOD)。MLOD 通过多重测试程序在不同特征层级融合和分析分布偏移，而无需修改或微调预训练分类器，从而与现有基于距离的检测方法无缝集成。实验结果表明，该框架显著提升了 OOD 检测性能，特别是 MLOD-Fisher 在 CIFAR10 数据集上将 False Positive Rate (FPR) 从 24.09% 降低到 7.47%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10803v1",
      "published_date": "2024-03-16 04:35:04 UTC",
      "updated_date": "2024-03-16 04:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:13:17.622169"
    },
    {
      "arxiv_id": "2403.10799v5",
      "title": "Toward Adaptive Large Language Models Structured Pruning via Hybrid-grained Weight Importance Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Liu",
        "Zhenglun Kong",
        "Pu Zhao",
        "Changdi Yang",
        "Hao Tang",
        "Xuan Shen",
        "Geng Yuan",
        "Wei Niu",
        "Wenbin Zhang",
        "Xue Lin",
        "Dong Huang",
        "Yanzhi Wang"
      ],
      "abstract": "Structured pruning for large language models (LLMs) has garnered significant\nacademic interest due to its ability to efficiently compress and accelerate\nLLMs by eliminating redundant weight groups at a coarse-grained granularity.\nCurrent structured pruning methods for LLMs typically depend on a singular\ngranularity for assessing weight importance, resulting in notable performance\ndegradation in downstream tasks. Intriguingly, our empirical investigations\nreveal that utilizing unstructured pruning, which achieves better performance\nretention by pruning weights at a finer granularity, \\emph{i.e.}, individual\nweights, yields significantly varied sparse LLM structures when juxtaposed to\nstructured pruning. This suggests that evaluating both holistic and individual\nassessment for weight importance is essential for LLM pruning. Building on this\ninsight, we introduce the Hybrid-grained Weight Importance Assessment (HyWIA),\na novel method that merges fine-grained and coarse-grained evaluations of\nweight importance for the pruning of LLMs. Leveraging an attention mechanism,\nHyWIA adaptively determines the optimal blend of granularity in weight\nimportance assessments in an end-to-end pruning manner. Extensive experiments\non LLaMA-V1/V2, Vicuna, Baichuan, and Bloom across various benchmarks\ndemonstrate the effectiveness of HyWIA in pruning LLMs. For example, HyWIA\nsurpasses the cutting-edge LLM-Pruner by an average margin of 2.82% in accuracy\nacross seven downstream tasks when pruning LLaMA-7B by 50%.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）的结构化剪枝问题，提出了一种自适应方法，以解决现有方法依赖单一粒度评估权重重要性而导致下游任务性能下降的局限性。HyWIA（Hybrid-grained Weight Importance Assessment）创新性地结合细粒度和粗粒度权重评估，利用注意力机制在端到端剪枝过程中自适应地优化粒度混合。实验结果显示，在LLaMA-V1/V2、Vicuna、Baichuan和Bloom等模型上，HyWIA在多个基准测试中表现出色，例如在剪枝LLaMA-7B 50%时，比最先进方法LLM-Pruner平均准确率高出2.82%。这为高效压缩LLMs提供了更可靠的策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.10799v5",
      "published_date": "2024-03-16 04:12:50 UTC",
      "updated_date": "2025-01-12 06:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:13:29.246795"
    },
    {
      "arxiv_id": "2403.10795v2",
      "title": "Can Large Language Models Solve Robot Routing?",
      "title_zh": "大语言模型能解决机器人路由问题吗？",
      "authors": [
        "Zhehui Huang",
        "Guangyao Shi",
        "Gaurav S. Sukhatme"
      ],
      "abstract": "Routing problems are common in mobile robotics, encompassing tasks such as\ninspection, surveillance, and coverage. Depending on the objective and\nconstraints, these problems often reduce to variants of the Traveling Salesman\nProblem (TSP), with solutions traditionally derived by translating high-level\nobjectives into an optimization formulation and using modern solvers to arrive\nat a solution. Here, we explore the potential of Large Language Models (LLMs)\nto replace the entire pipeline from tasks described in natural language to the\ngeneration of robot routes. We systematically investigate the performance of\nLLMs in robot routing by constructing a dataset with 80 unique robot routing\nproblems across 8 variants in both single and multi-robot settings. We evaluate\nLLMs through three frameworks: single attempt, self-debugging, and\nself-debugging with self-verification and various contexts, including\nmathematical formulations, pseudo-code, and related research papers. Our\nfindings reveal that both self-debugging and self-verification enhance success\nrates without significantly lowering the optimality gap. We observe\ncontext-sensitive behavior - providing mathematical formulations as context\ndecreases the optimality gap but significantly decreases success rates and\nproviding pseudo-code and related research papers as context does not\nconsistently improve success rates or decrease the optimality gap. We identify\nkey challenges and propose future directions to enhance LLM performance in\nsolving robot routing problems. Our source code is available on the project\nwebsite: https://sites.google.com/view/words-to-routes/.",
      "tldr_zh": "这篇论文探讨 Large Language Models (LLMs) 是否能解决机器人路由问题，这些问题通常是 Traveling Salesman Problem (TSP) 的变体，并涵盖巡检、监视和覆盖任务。研究者构建了一个包含 80 个独特问题的数据集，并在单机器人和多机器人设置中，通过单次尝试、self-debugging 和 self-verification 框架评估 LLMs 的性能，同时测试不同上下文（如数学公式、伪代码和相关研究论文）。结果显示，self-debugging 和 self-verification 提高了成功率，同时未显著增加最优性差距，但提供数学公式作为上下文会降低成功率，而其他上下文的影响不一致。论文识别了 LLMs 在机器人路由中的关键挑战，并提出未来改进方向，以增强其实际应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to International Symposium of Robotics Research (ISRR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.10795v2",
      "published_date": "2024-03-16 03:54:38 UTC",
      "updated_date": "2024-08-06 21:14:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:13:43.357003"
    },
    {
      "arxiv_id": "2403.10787v1",
      "title": "Time Series Representation Learning with Supervised Contrastive Temporal Transformer",
      "title_zh": "基于监督对比时间 Transformer 的时间序列表示学习",
      "authors": [
        "Yuansan Liu",
        "Sudanthi Wijewickrema",
        "Christofer Bester",
        "Stephen O'Leary",
        "James Bailey"
      ],
      "abstract": "Finding effective representations for time series data is a useful but\nchallenging task. Several works utilize self-supervised or unsupervised\nlearning methods to address this. However, there still remains the open\nquestion of how to leverage available label information for better\nrepresentations. To answer this question, we exploit pre-existing techniques in\ntime series and representation learning domains and develop a simple, yet novel\nfusion model, called: \\textbf{S}upervised \\textbf{CO}ntrastive\n\\textbf{T}emporal \\textbf{T}ransformer (SCOTT). We first investigate suitable\naugmentation methods for various types of time series data to assist with\nlearning change-invariant representations. Secondly, we combine Transformer and\nTemporal Convolutional Networks in a simple way to efficiently learn both\nglobal and local features. Finally, we simplify Supervised Contrastive Loss for\nrepresentation learning of labelled time series data. We preliminarily evaluate\nSCOTT on a downstream task, Time Series Classification, using 45 datasets from\nthe UCR archive. The results show that with the representations learnt by\nSCOTT, even a weak classifier can perform similar to or better than existing\nstate-of-the-art models (best performance on 23/45 datasets and highest rank\nagainst 9 baseline models). Afterwards, we investigate SCOTT's ability to\naddress a real-world task, online Change Point Detection (CPD), on two\ndatasets: a human activity dataset and a surgical patient dataset. We show that\nthe model performs with high reliability and efficiency on the online CPD\nproblem ($\\sim$98\\% and $\\sim$97\\% area under precision-recall curve\nrespectively). Furthermore, we demonstrate the model's potential in tackling\nearly detection and show it performs best compared to other candidates.",
      "tldr_zh": "这篇论文提出了一种名为 SCOTT 的模型（Supervised Contrastive Temporal Transformer），旨在通过利用标签信息来提升时间序列数据的表示学习效果。SCOTT 结合了 Transformer 和 Temporal Convolutional Networks 来学习全局和局部特征，并简化了 Supervised Contrastive Loss，同时探索了适合的时间序列数据增强方法以实现不变表示。实验结果显示，在 UCR archive 的 45 个数据集上的时间序列分类任务中，SCOTT 表现优异（在 23/45 数据集上最佳，并优于 9 个基线模型）；此外，在真实世界的在线变化点检测（CPD）任务上，该模型实现了高可靠性（约 98% 和 97% 的精度-召回曲线面积），并在早期检测方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 8 figures, IJCNN 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10787v1",
      "published_date": "2024-03-16 03:37:19 UTC",
      "updated_date": "2024-03-16 03:37:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:13:56.298862"
    },
    {
      "arxiv_id": "2405.01553v2",
      "title": "Empirical Studies of Parameter Efficient Methods for Large Language Models of Code and Knowledge Transfer to R",
      "title_zh": "翻译失败",
      "authors": [
        "Amirreza Esmaeili",
        "Iman Saberi",
        "Fatemeh H. Fard"
      ],
      "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods are proposed as an alternative\nfine-tuning approach for Large Language Models (LLM) to minimize high training\ncosts. While prior research demonstrates the effectiveness of PEFT methods in\nknowledge transfer using smaller language models, their application to larger\nLLMs, particularly in low-resource and unseen programming languages such as R,\nremains under-explored. In this work, we evaluate PEFT methods, LoRA,\nCompacter, and IA^3 on LLMs for code summarization and generation, with a\nparticular emphasis on knowledge transfer to R as an unseen under-explored\ntarget language. Our experiments reveal that LoRA consistently outperforms\nCompacter and IA^3 in all settings, while Compacter offers significant resource\nefficiency with minimal performance trade-offs. Additionally, we find that the\nnumber of trainable parameters has a greater influence on the functional\naccuracy of the generated code than PEFT architecture. Our study can direct\nfuture research in developing code intelligent tasks for unseen languages\nincluding R, as well as the choice of PEFT methods for knowledge transfer,\nespecially when balancing the computational cost and performance.",
      "tldr_zh": "本文通过实证研究评估了 Parameter Efficient Fine-Tuning (PEFT) 方法在 Large Language Models (LLM) 上的应用，特别是针对代码总结和生成任务中的知识转移到低资源编程语言 R。研究比较了 LoRA、Compacter 和 IA^3 三种 PEFT 方法，结果显示 LoRA 在所有设置中表现最佳，而 Compacter 提供了显著的资源效率，同时性能损失最小。实验还发现，训练参数的数量对生成的代码功能准确性影响更大，而不是 PEFT 架构本身。该研究为未来开发针对未见语言（如 R）的代码智能任务以及平衡计算成本和性能的 PEFT 方法选择提供了重要指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01553v2",
      "published_date": "2024-03-16 03:12:45 UTC",
      "updated_date": "2025-01-27 18:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:14:07.047916"
    },
    {
      "arxiv_id": "2403.10781v1",
      "title": "Exploring Chinese Humor Generation: A Study on Two-Part Allegorical Sayings",
      "title_zh": "翻译失败",
      "authors": [
        "Rongwu Xu"
      ],
      "abstract": "Humor, a culturally nuanced aspect of human language, poses challenges for\ncomputational understanding and generation, especially in Chinese humor, which\nremains relatively unexplored in the NLP community. This paper investigates the\ncapability of state-of-the-art language models to comprehend and generate\nChinese humor, specifically focusing on training them to create allegorical\nsayings. We employ two prominent training methods: fine-tuning a medium-sized\nlanguage model and prompting a large one. Our novel fine-tuning approach\nincorporates fused Pinyin embeddings to consider homophones and employs\ncontrastive learning with synthetic hard negatives to distinguish humor\nelements. Human-annotated results show that these models can generate humorous\nallegorical sayings, with prompting proving to be a practical and effective\nmethod. However, there is still room for improvement in generating allegorical\nsayings that match human creativity.",
      "tldr_zh": "这篇论文探讨了语言模型生成中文幽默的能力，特别针对Two-Part Allegorical Sayings（双部分寓言格言）。研究采用了两种方法：微调中等规模模型（结合fused Pinyin embeddings处理同音词，并使用contrastive learning生成合成硬负样本），以及提示大型模型。人类标注结果显示，这些方法能有效生成幽默格言，其中提示方法更实用高效；然而，在匹配人类创意的生成质量方面，仍有改进空间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10781v1",
      "published_date": "2024-03-16 02:58:57 UTC",
      "updated_date": "2024-03-16 02:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:14:18.042935"
    },
    {
      "arxiv_id": "2403.10780v1",
      "title": "Segment Any Object Model (SAOM): Real-to-Simulation Fine-Tuning Strategy for Multi-Class Multi-Instance Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Mariia Khan",
        "Yue Qiu",
        "Yuren Cong",
        "Jumana Abu-Khalaf",
        "David Suter",
        "Bodo Rosenhahn"
      ],
      "abstract": "Multi-class multi-instance segmentation is the task of identifying masks for\nmultiple object classes and multiple instances of the same class within an\nimage. The foundational Segment Anything Model (SAM) is designed for promptable\nmulti-class multi-instance segmentation but tends to output part or sub-part\nmasks in the \"everything\" mode for various real-world applications. Whole\nobject segmentation masks play a crucial role for indoor scene understanding,\nespecially in robotics applications. We propose a new domain invariant\nReal-to-Simulation (Real-Sim) fine-tuning strategy for SAM. We use object\nimages and ground truth data collected from Ai2Thor simulator during\nfine-tuning (real-to-sim). To allow our Segment Any Object Model (SAOM) to work\nin the \"everything\" mode, we propose the novel nearest neighbour assignment\nmethod, updating point embeddings for each ground-truth mask. SAOM is evaluated\non our own dataset collected from Ai2Thor simulator. SAOM significantly\nimproves on SAM, with a 28% increase in mIoU and a 25% increase in mAcc for 54\nfrequently-seen indoor object classes. Moreover, our Real-to-Simulation\nfine-tuning strategy demonstrates promising generalization performance in real\nenvironments without being trained on the real-world data (sim-to-real). The\ndataset and the code will be released after publication.",
      "tldr_zh": "该论文针对多类多实例分割任务，提出 Segment Any Object Model (SAOM) 模型，以解决 Segment Anything Model (SAM) 在 \"everything\" 模式下易输出部分掩码的问题，从而提升室内场景理解和机器人应用的性能。SAOM 采用 Real-to-Simulation (Real-Sim) 细调策略，使用 Ai2Thor 模拟器中的对象图像和地面真实数据，并引入 nearest neighbour assignment 方法来更新点嵌入，确保生成完整的对象掩码。在 Ai2Thor 数据集上评估，SAOM 相比 SAM 提高了 28% 的 mIoU 和 25% 的 mAcc，对于 54 个常见室内对象类；此外，该策略显示出优秀的 sim-to-real 泛化性能，无需真实数据训练。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10780v1",
      "published_date": "2024-03-16 02:54:49 UTC",
      "updated_date": "2024-03-16 02:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:14:31.235634"
    },
    {
      "arxiv_id": "2403.10776v1",
      "title": "From Melting Pots to Misrepresentations: Exploring Harms in Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjana Gautam",
        "Pranav Narayanan Venkit",
        "Sourojit Ghosh"
      ],
      "abstract": "With the widespread adoption of advanced generative models such as Gemini and\nGPT, there has been a notable increase in the incorporation of such models into\nsociotechnical systems, categorized under AI-as-a-Service (AIaaS). Despite\ntheir versatility across diverse sectors, concerns persist regarding\ndiscriminatory tendencies within these models, particularly favoring selected\n`majority' demographics across various sociodemographic dimensions. Despite\nwidespread calls for diversification of media representations, marginalized\nracial and ethnic groups continue to face persistent distortion, stereotyping,\nand neglect within the AIaaS context. In this work, we provide a critical\nsummary of the state of research in the context of social harms to lead the\nconversation to focus on their implications. We also present open-ended\nresearch questions, guided by our discussion, to help define future research\npathways.",
      "tldr_zh": "这篇论文探讨了生成式 AI（如 Gemini 和 GPT）在 AI-as-a-Service (AIaaS) 中的社会危害，焦点在于这些模型对少数种族和民族群体的歧视、扭曲、刻板印象及忽视，尽管多元化呼吁日益增多。作者通过批判性总结现有研究，强调这些模型偏好“多数”群体，导致边缘化群体的持续误表征，并分析了这些问题的社会含义。论文最终提出了一系列开放性研究问题，以指导未来研究路径，旨在推动更公平的 AI 发展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "In CHI 2024: Generative AI and HCI workshop (GenAICHI 24)",
      "pdf_url": "http://arxiv.org/pdf/2403.10776v1",
      "published_date": "2024-03-16 02:29:42 UTC",
      "updated_date": "2024-03-16 02:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:14:41.867756"
    },
    {
      "arxiv_id": "2403.10764v1",
      "title": "ECRC: Emotion-Causality Recognition in Korean Conversation for GCN",
      "title_zh": "翻译失败",
      "authors": [
        "J. K. Lee",
        "T. M. Chung"
      ],
      "abstract": "In this multi-task learning study on simultaneous analysis of emotions and\ntheir underlying causes in conversational contexts, deep neural network methods\nwere employed to effectively process and train large labeled datasets. However,\nthese approaches are typically limited to conducting context analyses across\nthe entire corpus because they rely on one of the two methods: word- or\nsentence-level embedding. The former struggles with polysemy and homonyms,\nwhereas the latter causes information loss when processing long sentences. In\nthis study, we overcome the limitations of previous embeddings by utilizing\nboth word- and sentence-level embeddings. Furthermore, we propose the\nemotion-causality recognition in conversation (ECRC) model, which is based on a\nnovel graph structure, thereby leveraging the strengths of both embedding\nmethods. This model uniquely integrates the bidirectional long short-term\nmemory (Bi-LSTM) and graph neural network (GCN) models for Korean conversation\nanalysis. Compared with models that rely solely on one embedding method, the\nproposed model effectively structures abstract concepts, such as language\nfeatures and relationships, thereby minimizing information loss. To assess\nmodel performance, we compared the multi-task learning results of three deep\nneural network models with varying graph structures. Additionally, we evaluated\nthe proposed model using Korean and English datasets. The experimental results\nshow that the proposed model performs better in emotion and causality\nmulti-task learning (74.62% and 75.30%, respectively) when node and edge\ncharacteristics are incorporated into the graph structure. Similar results were\nrecorded for the Korean ECC and Wellness datasets (74.62% and 73.44%,\nrespectively) with 71.35% on the IEMOCAP English dataset.",
      "tldr_zh": "这篇论文提出 ECRC 模型，用于在韩语对话中同时识别情绪和其原因，采用多任务学习框架来处理大型标记数据集。模型结合词级和句级嵌入，通过整合 Bi-LSTM 和 GCN 的新型图结构，克服了传统嵌入方法在处理多义词、信息丢失等方面的局限，从而更有效地捕捉语言特征和关系。实验结果显示，ECRC 在情绪和因果识别任务中表现出色，准确率分别达到 74.62% 和 75.30%，并在韩语（ECC 和 Wellness 数据集）和英语（IEMOCAP 数据集）上均优于基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.10764v1",
      "published_date": "2024-03-16 02:07:31 UTC",
      "updated_date": "2024-03-16 02:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:14:54.929844"
    },
    {
      "arxiv_id": "2403.10761v1",
      "title": "Scheduling Drone and Mobile Charger via Hybrid-Action Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jizhe Dou",
        "Haotian Zhang",
        "Guodong Sun"
      ],
      "abstract": "Recently there has been a growing interest in industry and academia,\nregarding the use of wireless chargers to prolong the operational longevity of\nunmanned aerial vehicles (commonly knowns as drones). In this paper we consider\na charger-assisted drone application: a drone is deployed to observe a set\npoints of interest, while a charger can move to recharge the drone's battery.\nWe focus on the route and charging schedule of the drone and the mobile\ncharger, to obtain high observation utility with the shortest possible time,\nwhile ensuring the drone remains operational during task execution.\nEssentially, this proposed drone-charger scheduling problem is a multi-stage\ndecision-making process, in which the drone and the mobile charger act as two\nagents who cooperate to finish a task. The discrete-continuous hybrid action\nspace of the two agents poses a significant challenge in our problem. To\naddress this issue, we present a hybrid-action deep reinforcement learning\nframework, called HaDMC, which uses a standard policy learning algorithm to\ngenerate latent continuous actions. Motivated by representation learning, we\nspecifically design and train an action decoder. It involves two pipelines to\nconvert the latent continuous actions into original discrete and continuous\nactions, by which the drone and the charger can directly interact with\nenvironment. We embed a mutual learning scheme in model training, emphasizing\nthe collaborative rather than individual actions. We conduct extensive\nnumerical experiments to evaluate HaDMC and compare it with state-of-the-art\ndeep reinforcement learning approaches. The experimental results show the\neffectiveness and efficiency of our solution.",
      "tldr_zh": "该论文研究了如何通过无线充电器延长无人机（drones）的操作寿命，聚焦于优化无人机观察兴趣点和移动充电器的路线及充电调度，以最大化观察效用、缩短任务时间并确保无人机持续运行。论文提出了一种名为 HaDMC 的 hybrid-action deep reinforcement learning 框架，利用标准策略学习算法生成潜在连续动作，并通过一个专门设计的行动解码器将这些动作转换为原始离散和连续动作，同时融入相互学习方案（mutual learning scheme）来强调两个代理的合作。实验结果显示，HaDMC 比现有深度强化学习方法更有效和高效，在数值实验中表现出色。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10761v1",
      "published_date": "2024-03-16 01:51:42 UTC",
      "updated_date": "2024-03-16 01:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:15:07.836673"
    },
    {
      "arxiv_id": "2403.10760v1",
      "title": "CORN: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Yoonyoung Cho",
        "Junhyek Han",
        "Yoontae Cho",
        "Beomjoon Kim"
      ],
      "abstract": "Nonprehensile manipulation is essential for manipulating objects that are too\nthin, large, or otherwise ungraspable in the wild. To sidestep the difficulty\nof contact modeling in conventional modeling-based approaches, reinforcement\nlearning (RL) has recently emerged as a promising alternative. However,\nprevious RL approaches either lack the ability to generalize over diverse\nobject shapes, or use simple action primitives that limit the diversity of\nrobot motions. Furthermore, using RL over diverse object geometry is\nchallenging due to the high cost of training a policy that takes in\nhigh-dimensional sensory inputs. We propose a novel contact-based object\nrepresentation and pretraining pipeline to tackle this. To enable massively\nparallel training, we leverage a lightweight patch-based transformer\narchitecture for our encoder that processes point clouds, thus scaling our\ntraining across thousands of environments. Compared to learning from scratch,\nor other shape representation baselines, our representation facilitates both\ntime- and data-efficient learning. We validate the efficacy of our overall\nsystem by zero-shot transferring the trained policy to novel real-world\nobjects. Code and videos are available at\nhttps://sites.google.com/view/contact-non-prehensile.",
      "tldr_zh": "该论文提出了一种基于接触的物体表示（CORN），旨在解决 reinforcement learning (RL) 在处理多样未知物体时的非抓取操作（nonprehensile manipulation）挑战，特别是泛化能力和训练效率问题。CORN 采用轻量级 patch-based transformer 架构处理点云数据，支持大规模并行训练，从而减少了时间和数据需求。与从零开始学习或其他形状表示基线相比，该方法显著提升了学习效率，并通过零样本转移（zero-shot transferring）成功应用于真实世界的新物体。实验结果验证了其有效性，为机器人操作多样物体提供了更可靠的框架。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10760v1",
      "published_date": "2024-03-16 01:47:53 UTC",
      "updated_date": "2024-03-16 01:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:15:21.139116"
    },
    {
      "arxiv_id": "2403.12098v1",
      "title": "Deep Generative Design for Mass Production",
      "title_zh": "深度生成式设计用于大规模生产",
      "authors": [
        "Jihoon Kim",
        "Yongmin Kwon",
        "Namwoo Kang"
      ],
      "abstract": "Generative Design (GD) has evolved as a transformative design approach,\nemploying advanced algorithms and AI to create diverse and innovative solutions\nbeyond traditional constraints. Despite its success, GD faces significant\nchallenges regarding the manufacturability of complex designs, often\nnecessitating extensive manual modifications due to limitations in standard\nmanufacturing processes and the reliance on additive manufacturing, which is\nnot ideal for mass production. Our research introduces an innovative framework\naddressing these manufacturability concerns by integrating constraints\npertinent to die casting and injection molding into GD, through the utilization\nof 2D depth images. This method simplifies intricate 3D geometries into\nmanufacturable profiles, removing unfeasible features such as\nnon-manufacturable overhangs and allowing for the direct consideration of\nessential manufacturing aspects like thickness and rib design. Consequently,\ndesigns previously unsuitable for mass production are transformed into viable\nsolutions. We further enhance this approach by adopting an advanced 2D\ngenerative model, which offer a more efficient alternative to traditional 3D\nshape generation methods. Our results substantiate the efficacy of this\nframework, demonstrating the production of innovative, and, importantly,\nmanufacturable designs. This shift towards integrating practical manufacturing\nconsiderations into GD represents a pivotal advancement, transitioning from\npurely inspirational concepts to actionable, production-ready solutions. Our\nfindings underscore usefulness and potential of GD for broader industry\nadoption, marking a significant step forward in aligning GD with the demands of\nmanufacturing challenges.",
      "tldr_zh": "本研究针对 Generative Design (GD) 在可制造性方面的挑战（如复杂设计需手动修改和依赖添加剂制造），提出一个创新框架，将 die casting 和 injection molding 的约束整合到 GD 中，使用 2D depth images 简化 3D 几何形状，并移除 non-manufacturable overhangs 等不可制造特征，同时考虑 thickness 和 rib design。框架采用先进的 2D generative model 代替传统 3D 形状生成方法，提高了设计效率和实用性。实验结果证明，该方法能生成创新且可批量生产的解决方案，推动 GD 在工业领域的广泛应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.12098v1",
      "published_date": "2024-03-16 01:32:00 UTC",
      "updated_date": "2024-03-16 01:32:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:15:31.823002"
    },
    {
      "arxiv_id": "2403.10751v3",
      "title": "LightCode: Light Analytical and Neural Codes for Channels with Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Sravan Kumar Ankireddy",
        "Krishna Narayanan",
        "Hyeji Kim"
      ],
      "abstract": "The design of reliable and efficient codes for channels with feedback remains\na longstanding challenge in communication theory. While significant\nimprovements have been achieved by leveraging deep learning techniques, neural\ncodes often suffer from high computational costs, a lack of interpretability,\nand limited practicality in resource-constrained settings. We focus on\ndesigning low-complexity coding schemes that are interpretable and more\nsuitable for communication systems. We advance both analytical and neural\ncodes. First, we demonstrate that PowerBlast, an analytical coding scheme\ninspired by Schalkwijk-Kailath (SK) and Gallager-Nakibo\\u{g}lu (GN) schemes,\nachieves notable reliability improvements over both SK and GN schemes,\noutperforming neural codes in high signal-to-noise ratio (SNR) regions. Next,\nto enhance reliability in low-SNR regions, we propose LightCode, a lightweight\nneural code that achieves state-of-the-art reliability while using a fraction\nof memory and compute compared to existing deeplearning-based codes. Finally,\nwe systematically analyze the learned codes, establishing connections between\nLightCode and PowerBlast, identifying components crucial for performance, and\nproviding interpretation aided by linear regression analysis.",
      "tldr_zh": "本文提出 LightCode 框架，旨在解决带有反馈通道的编码设计挑战，通过开发低复杂度且可解释的分析和神经编码方案来提升可靠性。研究首先引入 PowerBlast，一种受 Schalkwijk-Kailath (SK) 和 Gallager-Nakiboğlu (GN) 方案启发的分析编码，在高 signal-to-noise ratio (SNR) 区域比现有方案和神经编码表现出色。接着，LightCode 作为轻量级神经编码，在低 SNR 区域实现最先进可靠性，同时显著减少内存和计算资源消耗。最后，通过系统分析和线性回归，揭示了 LightCode 与 PowerBlast 的内在联系，并识别了关键性能组件。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "16 pages, 12 figures, To appear in IEEE Journal on Selected Areas in\n  Communications, 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.10751v3",
      "published_date": "2024-03-16 01:04:34 UTC",
      "updated_date": "2024-11-16 19:55:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:15:44.216095"
    },
    {
      "arxiv_id": "2403.10750v1",
      "title": "Depression Detection on Social Media with Large Language Models",
      "title_zh": "基于大型语言模型的社交媒体抑郁检测",
      "authors": [
        "Xiaochong Lan",
        "Yiming Cheng",
        "Li Sheng",
        "Chen Gao",
        "Yong Li"
      ],
      "abstract": "Depression harms. However, due to a lack of mental health awareness and fear\nof stigma, many patients do not actively seek diagnosis and treatment, leading\nto detrimental outcomes. Depression detection aims to determine whether an\nindividual suffers from depression by analyzing their history of posts on\nsocial media, which can significantly aid in early detection and intervention.\nIt mainly faces two key challenges: 1) it requires professional medical\nknowledge, and 2) it necessitates both high accuracy and explainability. To\naddress it, we propose a novel depression detection system called DORIS,\ncombining medical knowledge and the recent advances in large language models\n(LLMs). Specifically, to tackle the first challenge, we proposed an LLM-based\nsolution to first annotate whether high-risk texts meet medical diagnostic\ncriteria. Further, we retrieve texts with high emotional intensity and\nsummarize critical information from the historical mood records of users,\nso-called mood courses. To tackle the second challenge, we combine LLM and\ntraditional classifiers to integrate medical knowledge-guided features, for\nwhich the model can also explain its prediction results, achieving both high\naccuracy and explainability. Extensive experimental results on benchmarking\ndatasets show that, compared to the current best baseline, our approach\nimproves by 0.036 in AUPRC, which can be considered significant, demonstrating\nthe effectiveness of our approach and its high value as an NLP application.",
      "tldr_zh": "该研究针对社交媒体上的抑郁检测问题，提出了一种名为 DORIS 的新型系统，结合医疗知识和 Large Language Models (LLMs)，以解决专业知识需求和高准确性与可解释性的挑战。系统首先使用 LLMs 标注高风险文本是否符合医疗诊断标准，并检索高情感强度文本来总结用户的 mood courses（情绪过程）。通过整合 LLM 和传统分类器，DORIS 实现了基于医疗知识引导特征的预测，提高了模型的准确性和解释性。实验结果显示，在基准数据集上，该方法比最佳基线提高了 0.036 的 AUPRC，证明了其在早期抑郁干预中的显著价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10750v1",
      "published_date": "2024-03-16 01:01:16 UTC",
      "updated_date": "2024-03-16 01:01:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:15:55.958516"
    },
    {
      "arxiv_id": "2403.10744v1",
      "title": "Game and Reference: Policy Combination Synthesis for Epidemic Prevention and Control",
      "title_zh": "博弈与参考：用于流行病预防和控制的政策组合合成",
      "authors": [
        "Zhiyi Tan",
        "Bingkun Bao"
      ],
      "abstract": "In recent years, epidemic policy-making models are increasingly being used to\nprovide reference for governors on prevention and control policies against\ncatastrophic epidemics such as SARS, H1N1 and COVID-19. Existing studies are\ncurrently constrained by two issues: First, previous methods develop policies\nbased on effect evaluation, since few of factors in real-world decision-making\ncan be modeled, the output policies will then easily become extreme. Second,\nthe subjectivity and cognitive limitation of human make the historical policies\nnot always optimal for the training of decision models. To these ends, we\npresent a novel Policy Combination Synthesis (PCS) model for epidemic\npolicy-making. Specially, to prevent extreme decisions, we introduce\nadversarial learning between the model-made policies and the real policies to\nforce the output policies to be more human-liked. On the other hand, to\nminimize the impact of sub-optimal historical policies, we employ contrastive\nlearning to let the model draw on experience from the best historical policies\nunder similar scenarios. Both adversarial and contrastive learning are adaptive\nbased on the comprehensive effects of real policies to ensure the model always\nlearns useful information. Extensive experiments on real-world data prove the\neffectiveness of the proposed model.",
      "tldr_zh": "本文提出了一种新型的 Policy Combination Synthesis (PCS) 模型，用于流行病政策制定，以解决现有方法容易产生极端决策和依赖 suboptimal 历史政策的问题。该模型通过对抗学习(adversarial learning)在模型生成政策与真实政策之间引入竞争，确保输出政策更符合人类决策风格；同时，利用对比学习(contrastive learning)从类似场景的最佳历史政策中提取经验，以最小化不优影响。两种学习方式均基于真实政策的综合效果进行自适应优化，实验在真实世界数据上验证了模型的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, single line, 7 figures, written with Springer conference\n  template",
      "pdf_url": "http://arxiv.org/pdf/2403.10744v1",
      "published_date": "2024-03-16 00:26:59 UTC",
      "updated_date": "2024-03-16 00:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T16:16:08.496681"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 46,
  "processed_papers_count": 46,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T16:16:29.348962"
}