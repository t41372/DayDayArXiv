{
  "date": "2026-01-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2026-01-19 的 arXiv 中文 TLDR 快报！\n\n## 今日总结\n今天的 arXiv 充满了**“反思”与“重构”**的味道。我们看到了对现有范式的深刻挑战：arXiv 创始人 Paul Ginsparg 亲自下场分析 LLM 如何让科研论文“量通胀质紧缩”；Cornell 团队证明 GNN 其实不需要监督学习就能成为组合优化的启发式算法；还有研究揭示了模型规模扩大后，推理的几何结构发生了“相变”。此外，Agent 协作的低效、AI 生成数据的污染问题也被摆上了台面。\n\n---\n\n### 🚀 理论重构与深度学习机理 (Theoretical Shifts & Mechanisms)\n\n**1. Graph Neural Networks are Heuristics (图神经网络是启发式算法)**\n*   **Authors:** Yimeng Min, Carla P. Gomes (Cornell)\n*   **核心发现:** 这篇文章极具颠覆性。作者通过 TSP 问题证明，GNN 不需要监督训练，也不需要显式的搜索。通过将全局结构约束编码为**归纳偏置 (Inductive Bias)**，非自回归模型可以通过单次前向传递生成解决方案。\n*   **Implication:** 这重新定义了学习在组合优化中的作用：不是增强经典算法，而是直接实例化为一种强大的、习得的**启发式 (Heuristic)**。推理时的 Dropout 和快照集成还能进一步减少最优性差距。\n\n**19. The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models (思维的几何学：规模如何重构推理)**\n*   **Authors:** Samuel Cyrenius Anderson\n*   **核心发现:** 规模定律不仅仅带来能力的提升，更引发了推理结构的**相变 (Phase Transitions)**。\n*   **细节:** 法律推理经历了“结晶化 (Crystallization)”，表征维度坍缩（流形解缠）；而科学和数学推理则保持“液态”，几何结构不变。作者还发现了一种通用的振荡特征，暗示 Attention 和前馈层在推理中存在对抗动力学。\n\n**44. Training instability in deep learning follows low-dimensional dynamical principles (深度学习的训练不稳定性遵循低维动力学原理)**\n*   **Authors:** Zhipeng Zhang et al.\n*   **核心发现:** 训练崩溃不是随机的，而是遵循低维动力学。高最终性能往往与训练稳定性脱钩（即好模型可能训练过程很惊险）。在性能崩溃前，低维的潜在元状态 (meta-states) 会先出现系统性偏差。\n\n**28. Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models (别把分词器视为理所当然：它们是 LLM 的核心设计决策)**\n*   **Authors:** Sawsan Alqahtani et al.\n*   **核心发现:** 分词 (Tokenization) 常被视为预处理，但它是导致跨语言偏差、效率低下的核心原因。文章呼吁将分词器与模型进行**联合设计 (Co-design)**。\n\n---\n\n### 🤖 Agent, 协作与反思 (Agents, Collaboration & Reflection)\n\n**24. CooperBench: Why Coding Agents Cannot be Your Teammates Yet (CooperBench: 为什么编码 Agent 还不能做你的队友)**\n*   **Authors:** Arpandeep Khatua et al. (Stanford & UIUC)\n*   **核心发现:** 提出了 **CooperBench**。实验发现“协作诅咒”：Agent 组队时的成功率比单干低 30%。\n*   **问题所在:** 沟通渠道被垃圾信息堵塞、偏离承诺、以及对队友意图的错误预期。目前的 Agent 缺乏**社会智能 (Social Intelligence)**。\n\n**38. Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision (超越单次写作：深度研究 Agent 在多轮报告修订中不可靠)**\n*   **Authors:** Bingsen Chen et al.\n*   **核心发现:** 现有的“深度研究 Agent”大多是一次性写作。在多轮修改任务中（**Mr Dre** 基准），Agent 虽然能响应反馈，但会破坏之前写好的 16-27% 的内容，且引用质量下降。简单的 Prompt 工程无法解决这个问题。\n\n**17. A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models (AgentForge: 构建 LLM 驱动自主 Agent 的轻量级模块化框架)**\n*   **Authors:** Akbar Anbar Jafari et al.\n*   **核心发现:** 发布了 **AgentForge**，一个 Python 框架。相比 LangChain 开发时间减少 62%，延迟极低 (<100ms)，支持将技能抽象为 DAG（有向无环图）。\n\n**39. Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues (实时截止日期揭示了 LLM 战略对话中的时间感知失效)**\n*   **Authors:** Neil K. R. Sehgal et al.\n*   **核心发现:** LLM 缺乏内在的时间流逝感。在谈判模拟中，如果只是告诉 LLM 全局时间限制，交易达成率仅 4%；但如果在每一轮都显式提醒“剩余时间”，达成率飙升至 32%。\n\n---\n\n### 🛡️ AI 安全, 伦理与社会影响 (Safety, Ethics & Society)\n\n**41. Scientific production in the era of Large Language Models (大语言模型时代的科学学生产)**\n*   **Authors:** Keigo Kusumegi, Paul Ginsparg (arXiv Founder) et al.\n*   **核心发现:** 这是一篇关于“我们自己”的研究。使用 LLM 辅助写作导致论文产出增加了 23.7-89.3%。\n*   **警示:** 写作复杂性与论文质量的关系发生了逆转——现在我们有大量**语言华丽但实质空洞**的文章。LLM 用户倾向于引用更多样化但更年轻、引用率更低的文献。\n\n**58. AI-generated data contamination erodes pathological variability and diagnostic reliability (AI 生成数据污染侵蚀了病理变异性和诊断可靠性)**\n*   **Authors:** Hongyu He et al.\n*   **核心发现:** 在医疗领域，模型在 AI 生成的数据上训练会导致**模式坍缩**，罕见但关键的病理特征（如气胸）消失，人口统计特征向中年男性倾斜。且模型会表现出“盲目自信”，即使在诊断完全错误时。\n\n**2. Context and Transcripts Improve Detection of Deepfake Audios of Public Figures (语境和文本记录可提高公众人物深度伪造音频的检测率)**\n*   **Authors:** Chongyang Gao et al.\n*   **核心发现:** 仅仅分析音频文件是不够的。引入**语境 (Context)** 和**文本记录 (Transcripts)** 可以将 Deepfake 检测的 F1 分数提高 5%-37%。发布了数据集 JDD 和 SYN。\n\n**61. On the Evidentiary Limits of Membership Inference for Copyright Auditing (版权审计中成员推理的证据局限性)**\n*   **Authors:** Murat Bilgehan Ertan et al.\n*   **核心发现:** 针对版权保护的成员推理攻击 (MIA) 在对抗环境下是脆弱的。如果开发者使用 SAGE（一种基于稀疏自编码器的改写框架）对训练数据进行语义保留的改写，MIA 就失效了。\n\n---\n\n### 👁️ 视觉与多模态 (Vision & Multimodal)\n\n**12. Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset (像素级精度推理：QVLM 架构与 SQuID 数据集)**\n*   **Authors:** Peter A. Massih et al.\n*   **核心发现:** 现有的 VLM 因为 Patch Embedding 丢失了像素级信息，无法做精确计数或测量。**QVLM** 通过生成代码来调用分割模型，并在 Mask 上操作，保留了空间索引。\n\n**3. SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following (SpatialBench-UC: 文本生成图像中空间提示遵循的不确定性感知评估)**\n*   **Authors:** Amine Rostane\n*   **核心发现:** 评估 AI 绘图是否听懂了“左边、右边”很难。提出了 SpatialBench-UC 基准，强调评估器在证据不足时应“弃权 (abstain)”，而不是强行打分。\n\n**81. Left-Right Symmetry Breaking in CLIP-style Vision-Language Models (CLIP 式视觉语言模型中的左右对称破缺)**\n*   **Authors:** Takaki Yamamoto et al.\n*   **核心发现:** CLIP 是如何分清左右的？研究发现位置嵌入和 Token 嵌入的交互在 Attention 中引入了水平梯度，从而打破了左右对称性。标签的多样性比布局多样性对泛化更重要。\n\n---\n\n### 🧬 科学 AI 与垂直领域 (Scientific AI & Vertical Domains)\n\n**110. STEP-LLM: Generating CAD STEP Models from Natural Language (STEP-LLM: 利用大语言模型从自然语言生成 CAD STEP 模型)**\n*   **Authors:** Xiangyu Shi et al.\n*   **核心发现:** 直接生成 CAD 的 STEP 文件（工业标准）很难，因为它是图结构的。本文通过 DFS 重序列化和几何奖励强化学习，实现了比 Text2CAD 更好的几何保真度。\n\n**1. Graph Neural Networks are Heuristics (GNN 是启发式算法)**\n*   *（见上文，再次强调其在科学计算/运筹学中的重要性）*\n\n**83. SciHorizon-GENE: Benchmarking LLM for Life Sciences Inference (SciHorizon-GENE: 评估 LLM 从基因知识到功能理解的推理能力)**\n*   **Authors:** Xiaohan Huang et al.\n*   **核心发现:** 发布了包含 54 万个问题的大规模基准。目前的 LLM 在基因层面的推理能力参差不齐，且容易产生幻觉，难以生成有文献依据的功能解释。\n\n---\n\n### 💡 其他有趣的研究\n\n*   **#109 Unbounded Harms, Bounded Law:** 探讨了无国界 AI 带来的法律责任困境，现有法律难以管辖跨国 AI 供应链的伤害。\n*   **#96 AI-exhibited Personality Traits Can Shape Human Self-concept:** 与有性格的 AI 聊天，人类的自我认知会向 AI 的性格靠拢（近朱者赤？）。\n*   **#60 The Post-Turing Condition:** 提出我们不应只关注机器是否产生意识，而应关注机器是否在我们将人类排除在外的情况下，独自构建了“社会性”和意义。\n\n希望今天的快报对你的研究有所启发！明天见。",
  "papers": [
    {
      "arxiv_id": "2601.13465v1",
      "title": "Graph Neural Networks are Heuristics",
      "title_zh": "图神经网络即启发式算法",
      "authors": [
        "Yimeng Min",
        "Carla P. Gomes"
      ],
      "abstract": "We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.",
      "tldr_zh": "该研究证明了单次训练轨迹即可将 Graph Neural Networks (GNNs) 转化为用于解决 Combinatorial Optimization 问题的无监督 Heuristics。以 Travelling Salesman Problem (TSP) 为核心，该方法通过将全局结构约束编码为 Inductive Bias，使 Non-autoregressive 模型能够通过直接前向传播生成解，而无需监督学习、显式搜索或顺序决策。在推理阶段，利用 Dropout 和 Snapshot Ensembling 使单个模型充当隐式集成，通过增加解的多样性来有效缩小 Optimality Gaps。实验结果表明，GNNs 不需要监督训练即可内化全局组合结构，并作为强大的 Learned Heuristics 发挥作用。这项工作重新定义了学习在 Combinatorial Optimization 中的角色，将其从辅助传统算法的工具转变为直接实例化新型 Heuristics 的核心手段。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13465v1",
      "published_date": "2026-01-19 23:40:08 UTC",
      "updated_date": "2026-01-19 23:40:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:47:50.658436+00:00"
    },
    {
      "arxiv_id": "2601.13464v1",
      "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures",
      "title_zh": "结合上下文与转录文本提升公众人物深度伪造音频检测",
      "authors": [
        "Chongyang Gao",
        "Marco Postiglione",
        "Julian Baldwin",
        "Natalia Denisenko",
        "Isabel Gortner",
        "Luke Fosdick",
        "Chiara Pulice",
        "Sarit Kraus",
        "V. S. Subrahmanian"
      ],
      "abstract": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).",
      "tldr_zh": "该研究针对现有音频深度伪造(Deepfake)检测器仅分析音频文件而忽视背景信息的局限性，提出了一种创新的基于上下文的音频深度伪造检测器(CADD)架构。研究人员利用由记者提供的公开伪造音频构建了JDD数据集，并生成了已故公众人物的合成数据集SYN，同时在ITW和P$^2$V等大型数据集上进行了验证。实验证明，引入上下文和转录文本(Transcripts)能显著增强检测效果，使多项基线模型在F1-score、AUC和EER指标上分别获得了最高37.58%、42.79%和47.83%的性能提升。此外，CADD架构对五种对抗性逃逸策略(Adversarial Evasion Strategies)表现出极强的鲁棒性，实验中的平均性能下降仅为-0.71%。该研究强调了上下文信息在识别针对公众人物的音频深伪攻击中的关键作用，并为开发更高效、更具韧性的检测系统提供了新思路。",
      "categories": [
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13464v1",
      "published_date": "2026-01-19 23:40:05 UTC",
      "updated_date": "2026-01-19 23:40:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:47:58.245902+00:00"
    },
    {
      "arxiv_id": "2601.13462v1",
      "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation",
      "title_zh": "SpatialBench-UC：文生图空间提示遵循的不确定性感知评估",
      "authors": [
        "Amine Rostane"
      ],
      "abstract": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.",
      "tldr_zh": "该研究引入了SpatialBench-UC，这是一个针对文本生成图像(Text-to-Image)模型中空间提示跟随能力的具有不确定性感知(Uncertainty-Aware)的评估基准。针对传统自动化评估中目标检测器漏检或几何测试歧义等问题，该基准将空间评估视为选择性预测(Selective Prediction)问题，允许系统在证据不足时弃权并报告置信度，从而实现风险-覆盖权衡(Risk-Coverage Tradeoff)。SpatialBench-UC包含200个涉及成对空间关系的提示词，通过交换对象角色构建反事实对，并结合人类审计来校准弃权边际和置信度阈值。研究团队利用该基准对Stable Diffusion 1.5、BoxDiff及GLIGEN等模型进行了评估，结果表明Grounding方法能显著提升空间跟随的通过率和覆盖率。实验还发现，目标检测缺失导致的弃权仍是影响评估结果的主要因素，这一发现为未来可重复、可审计的空间智能评估提供了重要参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, includes figures and tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13462v1",
      "published_date": "2026-01-19 23:37:10 UTC",
      "updated_date": "2026-01-19 23:37:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:47:49.549585+00:00"
    },
    {
      "arxiv_id": "2601.13458v1",
      "title": "Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs",
      "title_zh": "标签还是偏好？基于人类对 AI 生成输出评价的预算约束学习",
      "authors": [
        "Zihan Dong",
        "Ruijia Wu",
        "Linjun Zhang"
      ],
      "abstract": "The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. We address the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. Our solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, we introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, we prove the asymptotic optimality of our PCAL estimator and establish a key robustness guarantee that ensures robust performance even with poorly estimated nuisance models. Our flexible framework applies to a general class of problems, by directly optimizing the estimator's variance instead of requiring a closed-form solution. This work provides a principled and statistically efficient approach for budget-constrained learning in modern AI. Simulations and real-data analysis demonstrate the practical benefits and superior performance of our proposed method.",
      "tldr_zh": "本研究针对在预算受限下如何优化分配 ground-truth labels 与人类对 AI 生成结果的 pairwise preferences 标注资源这一核心问题，提出了一种基于 semi-parametric inference 的系统性解决方案。通过将预算分配建模为 monotone missing data 框架，论文引入了偏好校准主动学习 (Preference-Calibrated Active Learning, PCAL) 方法，旨在学习最优数据采集策略并构建统计高效的估计量。理论证明了 PCAL 估计量具有 asymptotic optimality，并通过提供鲁棒性保证确保了其在 nuisance models 估计不准时的稳定性。该框架具备高度灵活性，适用于直接优化估计量方差的通用问题类别，无需依赖 closed-form solution。最后，通过仿真和真实数据实验验证了 PCAL 在现代 AI 预算受限学习中的卓越性能和实用价值。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13458v1",
      "published_date": "2026-01-19 23:23:29 UTC",
      "updated_date": "2026-01-19 23:23:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:48:00.806921+00:00"
    },
    {
      "arxiv_id": "2601.13443v1",
      "title": "Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models",
      "title_zh": "显式认知分配：大语言模型受治理与可审计推理的原则",
      "authors": [
        "Héctor Manuel Manzanilla-Granados",
        "Zaira Navarrete-Cazales",
        "Miriam Pescador-Rojas",
        "Tonahtiu Ramírez-Romero"
      ],
      "abstract": "The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.\n  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.\n  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在推理中存在的“认知坍缩”(cognitive collapse)问题，提出了“显式认知分配”(Explicit Cognitive Allocation)原则，旨在通过分离和协调不同的认识功能来增强 AI 辅助推理的可追溯性和控制力。基于此原则，研究者构建了认知通用智能体(Cognitive Universal Agent, CUA)架构，将推理过程划分为探索与构思、认识锚定、工具与方法映射及解释性综合等不同阶段。该框架核心在于引入了通用认知工具(Universal Cognitive Instruments, UCIs)，将计算、实验、监管和教育等异质化手段形式化为可调查的工具。在农业领域的受控对比实验表明，CUA 相比基准模型在语义扩展下具有更高的认识一致性(epistemic alignment)和更早的结构化认识收敛(epistemic convergence)。实验结果证实，该方法能够系统性地展示探究的工具图景，为实现受治理且可审计的大语言模型推理提供了新的范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. This version corresponds to the initial public release of the CUA architecture and associated evaluation metrics",
      "pdf_url": "https://arxiv.org/pdf/2601.13443v1",
      "published_date": "2026-01-19 23:00:14 UTC",
      "updated_date": "2026-01-19 23:00:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:48:10.193140+00:00"
    },
    {
      "arxiv_id": "2601.13437v1",
      "title": "MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization",
      "title_zh": "MOSLD-Bench：面向文本分类的多语言开放集学习与发现基准",
      "authors": [
        "Adriana-Valentina Costache",
        "Daria-Nicoleta Dragomir",
        "Silviu-Florin Gheorghe",
        "Eduard Poesina",
        "Paul Irofti",
        "Radu Tudor Ionescu"
      ],
      "abstract": "Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.",
      "tldr_zh": "该研究提出了MOSLD-Bench，这是首个针对文本主题分类的多语言开放集学习与发现(Multilingual Open-Set Learning and Discovery, OSLD)基准测试，旨在应对测试阶段出现未知类别的挑战。该基准规模宏大，涵盖了12种语言的96万个数据样本，通过整合现有数据集和采集新闻领域的新样本构建而成。研究还提出了一种创新的OSLD框架，通过多阶段集成实现了对新类别的持续发现与学习。通过对多种语言模型（包括研究者自研模型）进行评估，该研究为未来的文本分类研究提供了可靠的参考基准。MOSLD-Bench的开源不仅填补了多语言OSLD数据集的空白，也显著推动了在开放环境下文本分类技术的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13437v1",
      "published_date": "2026-01-19 22:49:41 UTC",
      "updated_date": "2026-01-19 22:49:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:48:18.988775+00:00"
    },
    {
      "arxiv_id": "2601.13435v1",
      "title": "A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization",
      "title_zh": "面向股票多空交易与风险调整收益优化的可学习小波 Transformer",
      "authors": [
        "Shuozhe Li",
        "Du Cheng",
        "Leqi Liu"
      ],
      "abstract": "Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \\emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \\pm 0.045$ and a Sharpe ratio of $2.157 \\pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.",
      "tldr_zh": "该研究提出了 WaveLSFormer，一种基于可学习小波（Wavelet）的长短期 Transformer 架构，旨在解决金融时间序列中由于高噪声、非平稳性和强截面相关性导致的日内交易策略学习难题。该框架通过端到端训练的滤波器组实现多尺度分解，并结合频谱正则化确保频率带的稳定分离，实现了分解与决策学习的联合优化。研究引入了低频引导的高频注入（Low-Guided High-Frequency Injection, LGHI）模块，利用高频线索精炼低频特征表示，从而在控制训练稳定性的同时捕捉多尺度信息。模型输出满足固定风险预算的长短期投资组合，并直接采用交易目标函数和风险感知正则化进行训练。在跨越六个行业组的五年小时级数据实验中，WaveLSFormer 在累积策略收益和 Sharpe ratio 指标上均显著优于 MLP、LSTM 以及传统 Transformer 基准模型。平均而言，该模型达到了 0.607 的累计收益和 2.157 的 Sharpe ratio，在显著提升盈利能力的同时优化了风险调整后收益。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13435v1",
      "published_date": "2026-01-19 22:41:31 UTC",
      "updated_date": "2026-01-19 22:41:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:48:12.792334+00:00"
    },
    {
      "arxiv_id": "2601.13422v1",
      "title": "TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction",
      "title_zh": "TrustEnergy：面向精准可靠用户级能源使用预测的统一框架",
      "authors": [
        "Dahai Yu",
        "Rongchao Xu",
        "Dingyi Zhuang",
        "Yuheng Bu",
        "Shenhao Wang",
        "Guang Wang"
      ],
      "abstract": "Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.",
      "tldr_zh": "能源使用预测对电网管理和基础设施规划至关重要，但现有深度学习方法在处理家庭间的空间相关性、个性化预测扩展性以及不确定性量化方面存在不足。该研究提出了 TrustEnergy，一个旨在实现准确且可靠的用户级能源使用预测的统一框架。该框架包含一个 Hierarchical Spatiotemporal Representation 模块，通过创新的 memory-augmented spatiotemporal graph neural network 高效捕捉宏观和微观的能源使用模式。此外，TrustEnergy 引入了 Sequential Conformalized Quantile Regression 模块，在不依赖数据分布强假设的情况下动态调整不确定性边界，以确保预测区间的有效性。通过与美国佛罗里达州的一家电力供应商合作进行评估，结果显示 TrustEnergy 在预测准确率上提升了 5.4%，在不确定性量化指标上比现有基线模型改进了 5.7%。该研究为动态且具有不确定性的能源消耗场景提供了更为精准且可靠的决策支持工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13422v1",
      "published_date": "2026-01-19 22:09:08 UTC",
      "updated_date": "2026-01-19 22:09:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:48:33.312971+00:00"
    },
    {
      "arxiv_id": "2601.13412v1",
      "title": "Using deep learning for predicting cleansing quality of colon capsule endoscopy images",
      "title_zh": "基于深度学习的结肠胶囊内镜图像清洁质量预测",
      "authors": [
        "Puneet Sharma",
        "Kristian Dalsbø Hindberg",
        "Benedicte Schelde-Olesen",
        "Ulrik Deding",
        "Esmaeil S. Nadimi",
        "Jan-Matthias Braun"
      ],
      "abstract": "In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.",
      "tldr_zh": "该研究探讨了利用 deep learning 技术预测结肠胶囊内镜 (CCE) 图像清洁质量的方法。研究人员基于 14 位临床医生按照 Leighton-Rex scale 标注的 500 张图像数据集，训练并优化了 ResNet-18 模型，并采用分层 K-fold cross-validation 确保其稳健性。通过应用迭代式 structured pruning 技术，该模型在达到 79% sparsity 的情况下实现了 88% 的 cross-validation 准确率，相较于未剪枝模型的 84% 有明显提升。此外，研究通过 Grad-CAM、Grad-CAM++ 等多种技术评估了剪枝模型的 explainability，并利用 adaptive temperature scaling 对外部数据集进行了校准。该研究强调了临床应用中可解释性的重要性，为提升 CCE 图像清洁质量评估的自动化水平提供了高效且精准的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.13412v1",
      "published_date": "2026-01-19 21:48:41 UTC",
      "updated_date": "2026-01-19 21:48:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:48:16.133042+00:00"
    },
    {
      "arxiv_id": "2601.13406v1",
      "title": "Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room",
      "title_zh": "整合虚拟现实与大语言模型的手术室团队协作非技术技能培训与评估",
      "authors": [
        "Jacob Barker",
        "Doga Demirel",
        "Cullen Jackson",
        "Anna Johansson",
        "Robbin Miraglia",
        "Darian Hoagland",
        "Stephanie B. Jones",
        "John Mitchell",
        "Daniel B. Jones",
        "Suvranu De"
      ],
      "abstract": "Although effective teamwork and communication are critical to surgical safety, structured training for non-technical skills (NTS) remains limited compared with technical simulation. The ACS/APDS Phase III Team-Based Skills Curriculum calls for scalable tools that both teach and objectively assess these competencies during laparoscopic emergencies. We introduce the Virtual Operating Room Team Experience (VORTeX), a multi-user virtual reality (VR) platform that integrates immersive team simulation with large language model (LLM) analytics to train and evaluate communication, decision-making, teamwork, and leadership. Team dialogue is analyzed using structured prompts derived from the Non-Technical Skills for Surgeons (NOTSS) framework, enabling automated classification of behaviors and generation of directed interaction graphs that quantify communication structure and hierarchy. Two laparoscopic emergency scenarios, pneumothorax and intra-abdominal bleeding, were implemented to elicit realistic stress and collaboration. Twelve surgical professionals completed pilot sessions at the 2024 SAGES conference, rating VORTeX as intuitive, immersive, and valuable for developing teamwork and communication. The LLM consistently produced interpretable communication networks reflecting expected operative hierarchies, with surgeons as central integrators, nurses as initiators, and anesthesiologists as balanced intermediaries. By integrating immersive VR with LLM-driven behavioral analytics, VORTeX provides a scalable, privacy-compliant framework for objective assessment and automated, data-informed debriefing across distributed training environments.",
      "tldr_zh": "针对手术安全中非技术技能(Non-Technical Skills, NTS)训练受限的问题，本研究开发了VORTeX(Virtual Operating Room Team Experience)，这是一个集成了大语言模型(LLM)分析的多用户虚拟现实(VR)平台，专门用于腹腔镜急诊环境下的团队协作培训与评估。该系统基于外科医生非技术技能(NOTSS)框架，利用LLM对团队对话进行自动化行为分类，并生成定向交互图以量化沟通结构与层级。研究实施了气胸和腹腔内出血两种急诊场景，并在2024年SAGES会议上通过12名手术专业人员的试点评估证明了系统的沉浸感和临床价值。实验结果显示，LLM生成的通信网络能准确反映预期的手术层级，其中外科医生处于核心地位，护士和麻醉师分别扮演发起者和中介角色。通过结合沉浸式VR与LLM驱动的行为分析，VORTeX为分布式培训环境中的客观评估和数据驱动的自动化复盘(debriefing)提供了一个可扩展且符合隐私要求的框架。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "23 pages, 7 figures, 1 table, 2 Appendices",
      "pdf_url": "https://arxiv.org/pdf/2601.13406v1",
      "published_date": "2026-01-19 21:34:00 UTC",
      "updated_date": "2026-01-19 21:34:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:48:39.092618+00:00"
    },
    {
      "arxiv_id": "2601.13404v1",
      "title": "Local-to-Global Logical Explanations for Deep Vision Models",
      "title_zh": "深度视觉模型的从局部到全局逻辑解释",
      "authors": [
        "Bhavan Vasu",
        "Giuseppe Raffa",
        "Prasad Tadepalli"
      ],
      "abstract": "While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.",
      "tldr_zh": "该研究针对深度神经网络的不透明性，提出了一种针对黑盒模型的局部到全局的逻辑解释方法，旨在通过人类可识别的 primitive concepts 生成解释。无论是针对单张图像的局部解释，还是针对图像集的全局解释，都被构建为单调析取范式 (monotone disjunctive-normal-form, MDNF) 的逻辑公式，其满足性直接关联模型对特定类别的高预测评分。此外，研究还引入了一种新算法，以 primitive concepts 上的单调解释列表形式来处理多类别分类的解释问题。实验结果表明，尽管这些解释形式简单且具高度可解释性，但在挑战性的视觉数据集中仍能保持对黑盒模型极高的忠诚度 (fidelity) 和覆盖率 (coverage)。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 5 figures, 5th International Joint Conference on Learning & Reasoning 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.13404v1",
      "published_date": "2026-01-19 21:21:58 UTC",
      "updated_date": "2026-01-19 21:21:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:48:56.994018+00:00"
    },
    {
      "arxiv_id": "2601.13401v1",
      "title": "Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics",
      "title_zh": "像素级精度推理：面向定量地理空间分析的 QVLM 架构与 SQuID 数据集",
      "authors": [
        "Peter A. Massih",
        "Eric Cosatto"
      ],
      "abstract": "Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.",
      "tldr_zh": "该研究针对当前视觉语言模型(VLMs)在定量空间推理中因图像压缩导致像素级信息丢失的问题，提出了全新的QVLM架构和SQuID数据集。研究首先推出了SQuID基准测试，包含2000个涵盖数值和类别答案的卫星图像问答对，旨在评估模型在三种难度梯度下的空间推理能力。针对现有模型缺陷，研究提出了QVLM模型，该架构采用代码生成(code-generation)方式，通过将语言理解与视觉分析解耦，调用分割模型生成像素级掩码(pixel-level masks)以保留精确的空间索引。实验表明，使用GPT-5作为代码生成的QVLM在SQuID上的准确率达到42.0%，远超传统提示词方法的28.1%。该成果揭示了架构解耦在提升定量地理空间分析任务精度方面的显著优势，为实现像素级精度的空间推理提供了有效路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to CVPR 2026. Introduces the QVLM architecture and the SQuID dataset for quantitative geospatial reasoning. Dataset DOI: 10.57967/hf/7565",
      "pdf_url": "https://arxiv.org/pdf/2601.13401v1",
      "published_date": "2026-01-19 21:14:34 UTC",
      "updated_date": "2026-01-19 21:14:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:00.197092+00:00"
    },
    {
      "arxiv_id": "2601.13400v1",
      "title": "Deep Image Prior with L0 Gradient Regularizer for Image Smoothing",
      "title_zh": "结合 $L_0$ 梯度正则化的深度图像先验图像平滑",
      "authors": [
        "Nhat Thanh Tran",
        "Kevin Bui",
        "Jack Xin"
      ],
      "abstract": "Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\\ell_0$, a deep image prior framework that incorporates the $\\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\\ell_0$ ``norm\", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.",
      "tldr_zh": "该研究提出了DIP-$\\ell_0$，一种结合了$\\ell_0$梯度正则项(gradient regularizer)的深度图像先验(Deep Image Prior)框架，旨在解决图像平滑(Image Smoothing)中结构保留与细节移除的平衡问题。针对当前深度学习方法极度依赖高质量训练数据集的挑战，DIP-$\\ell_0$利用神经网络自身的结构先验，实现了无需训练数据的平滑处理。为了最小化包含非凸、非平滑$\\ell_0$范数的损失函数，研究者开发了一种交替方向乘子法(ADMM)算法，并有效集成了现有的$\\ell_0$梯度最小化求解器。数值实验证明，DIP-$\\ell_0$在保持边缘的平滑效果及JPEG伪影去除(JPEG artifact removal)方面均优于多种主流算法，展现了深度先验在底层视觉任务中的强大应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in the Proceedings of IEEE ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13400v1",
      "published_date": "2026-01-19 21:10:32 UTC",
      "updated_date": "2026-01-19 21:10:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:06.841403+00:00"
    },
    {
      "arxiv_id": "2601.13398v1",
      "title": "Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility",
      "title_zh": "LLMs 是否具备压缩（与解压缩）能力？基于可逆性的代码理解与执行评估",
      "authors": [
        "Nickil Maveli",
        "Antonio Vergari",
        "Shay B. Cohen"
      ],
      "abstract": "LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.",
      "tldr_zh": "该研究探讨了大语言模型（LLMs）在代码理解与执行中的往返一致性（round-trip consistency）问题，旨在评估模型在正向和反向执行中维持逻辑连贯的能力。作者提出了 RoundTripCodeEval (RTCE) 基准测试，通过四项不同的代码执行推理任务，对编码与解码操作之间的双射保真度（bijection fidelity）进行无需执行的精确匹配评估。研究对当前先进的 Code-LLMs 进行了系统测试，涵盖零样本提示（zero-shot prompting）、基于执行路径的有监督微调（supervised fine-tuning）以及自我反思机制。实验结果显示，尽管采用多种优化手段，模型仍无法完全克服往返一致性方面的局限，表明其缺乏可靠代码推理所需的内部连贯性。RTCE 提供了现有 I/O 预测或自然语言基准无法提供的深入洞察，揭示了当前模型在处理可逆逻辑时的底层局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages (preprint)",
      "pdf_url": "https://arxiv.org/pdf/2601.13398v1",
      "published_date": "2026-01-19 21:09:48 UTC",
      "updated_date": "2026-01-19 21:09:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:08.592618+00:00"
    },
    {
      "arxiv_id": "2601.13392v1",
      "title": "Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks",
      "title_zh": "超越记忆：针对未见计算理论任务的大语言模型推理能力测试",
      "authors": [
        "Shlok Shelat",
        "Jay Raval",
        "Souvik Roy",
        "Manas Gaur"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在形式语言任务上的表现究竟源于真实的符号推理还是对熟悉结构的模式匹配。作者引入了一个针对确定性有限自动机(DFA)构建的基准测试，涵盖了事实知识、公开来源的已见任务以及通过Arden's theorem系统生成的未见任务。实验结果显示，模型在事实性问题和已见任务上表现优异，但在面对未见问题时准确率急剧下降了30-64%，主要失败原因在于对Kleene-star语义的误解以及无法保持全局一致性。研究进一步评估了一种三阶段提示协议，发现其虽能纠正浅层错误，但无法可靠地解决结构性缺陷。最终分析表明，即使采用Chain-of-Thought和Tree-of-Thought等高级提示策略，模型在生成语义正确形式推理的能力上仍存在根本性差距，暴露出其在处理未见计算理论任务时的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 11 figures, 6 tables, Work in Progress",
      "pdf_url": "https://arxiv.org/pdf/2601.13392v1",
      "published_date": "2026-01-19 21:00:31 UTC",
      "updated_date": "2026-01-19 21:00:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:59.961799+00:00"
    },
    {
      "arxiv_id": "2601.13385v1",
      "title": "Organ-Aware Attention Improves CT Triage and Classification",
      "title_zh": "器官感知注意力提升 CT 预分诊与分类",
      "authors": [
        "Lavsen Dahal",
        "Yubraj Bhandari",
        "Geoffrey D. Rubin",
        "Joseph Y. Lo"
      ],
      "abstract": "There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.",
      "tldr_zh": "该研究针对计算机断层扫描(CT)自动分诊和分类中视觉语言模型(VLM)难以处理三维解剖结构和噪声监督的问题，提出了ORACLE-CT框架。研究首先通过优化的监督学习基准模型超越了现有的线性探针VLM模型，随后引入了由器官掩码注意力(Organ-Masked Attention)和器官标量融合(Organ-Scalar Fusion)组成的器官感知头。这种设计通过掩码受限的池化获取空间证据，并整合归一化体积与平均Hounsfield单位(HU)等关键生理指标。实验结果显示，ORACLE-CT在胸部数据集CT-RATE和腹部数据集MERLIN上分别实现了0.86和0.85的AUROC，在统一评估协议下刷新了多部位CT分类的监督学习性能纪录。这一成果为实现高精度、具备空间证据的可解释性CT分诊提供了强有力的技术支撑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13385v1",
      "published_date": "2026-01-19 20:37:45 UTC",
      "updated_date": "2026-01-19 20:37:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:16.380410+00:00"
    },
    {
      "arxiv_id": "2601.13383v1",
      "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge",
      "title_zh": "一种用于构建大语言模型驱动自主智能体的轻量级模块化框架：AgentForge 的设计、实现与应用",
      "authors": [
        "Akbar Anbar Jafari",
        "Cagri Ozcinar",
        "Gholamreza Anbarjafari"
      ],
      "abstract": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.",
      "tldr_zh": "该研究介绍了 AgentForge，这是一个轻量级、开源的 Python 框架，旨在简化由 Large Language Models (LLMs) 驱动的自主智能体的构建过程。为了解决现有框架架构僵化和复杂度高的问题，AgentForge 提出了三项核心创新：可组合的 skill 抽象、统一的 LLM 后端接口以及基于 YAML 的声明式配置系统。该框架通过有向无环图 (DAG) 形式化了技能组合机制，能够灵活表示任意顺序和并行的任务工作流。实验评估表明，与 LangChain 相比，AgentForge 可将开发时间缩短 62%，同时确保亚百毫秒级的编排开销，使其适用于实时应用。该框架还通过内置的多种 skill 展示了良好的扩展性，并提供了完善的自定义开发文档。AgentForge 为研究人员和从业者提供了一个兼具灵活性和高性能的生产级基础，有效填补了当前 LLM 智能体生态系统的空白。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13383v1",
      "published_date": "2026-01-19 20:33:26 UTC",
      "updated_date": "2026-01-19 20:33:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:14.370414+00:00"
    },
    {
      "arxiv_id": "2601.13376v1",
      "title": "Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk",
      "title_zh": "有限心智，生成式机器：展望适配人类启发式思维并降低偏差风险的对话式人工智能",
      "authors": [
        "Jiqun Liu"
      ],
      "abstract": "Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. In practice, human reasoning is bounded by limited attention, uneven knowledge, and reliance on heuristics that are adaptive but bias-prone. This article outlines a research pathway grounded in bounded rationality, and argues that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.",
      "tldr_zh": "该研究针对对话式人工智能(Conversational AI)在信息获取和决策中的普及，指出当前系统往往假设用户是理想化的，而忽视了人类推理受到有限注意力、知识不均和启发式(heuristics)依赖等有限理性(bounded rationality)约束的现实。文章提出了一个植根于有限理性理论的研究路径，主张对话式人工智能的设计应旨在与人类的启发式思维协同工作，而非盲目抵触。该路径明确了几个关键的研发方向，包括检测认知脆弱性(cognitive vulnerability)以及支持不确定性下的判断。此外，研究建议将系统的评估标准从单纯的事实准确性扩展到决策质量(decision quality)和认知鲁棒性(cognitive robustness)层面。通过这些方法，该研究旨在构建能够有效识别并减少偏见风险(bias risk)的智能交互系统。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13376v1",
      "published_date": "2026-01-19 20:23:28 UTC",
      "updated_date": "2026-01-19 20:23:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:25.284153+00:00"
    },
    {
      "arxiv_id": "2601.13358v1",
      "title": "The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models",
      "title_zh": "思维之几何：规模如何重构大语言模型中的推理",
      "authors": [
        "Samuel Cyrenius Anderson"
      ],
      "abstract": "Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.",
      "tldr_zh": "该研究通过分析Law、Science、Code和Math四个领域超过2.5万条Chain-of-Thought轨迹，揭示了模型Scale的增长并非简单提升性能，而是重构了推理的几何结构。研究发现Legal Reasoning呈现Crystallization（结晶化）现象，表现为表示维度大幅下降和流形解缠，而Science和Math推理则保持Liquid（液态）几何不变性，Code reasoning则形成离散的Lattice（晶格）模式。研究者引入了Neural Reasoning Operators，在法律推理任务中实现了无需遍历中间状态即可预测终点的探测解码，准确率达63.6%。此外，研究识别出一种跨领域通用的Oscillatory Signature，揭示了Attention层与Feedforward层在驱动推理时的对立动力学特征。这些发现证明了推理成本由Manifold Geometry而非任务难度决定，为利用拓扑结构实现推理加速提供了理论蓝图。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13358v1",
      "published_date": "2026-01-19 19:53:37 UTC",
      "updated_date": "2026-01-19 19:53:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:21.185036+00:00"
    },
    {
      "arxiv_id": "2601.13352v1",
      "title": "LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction",
      "title_zh": "LLM-as-RNN：一种用于记忆更新与序列预测的循环语言模型",
      "authors": [
        "Yuxing Lu",
        "J. Ben Tamo",
        "Weichen Zhao",
        "Nan Sun",
        "Yishan Zhong",
        "Wenqi Shi",
        "Jinzhuo Wang",
        "May D. Wang"
      ],
      "abstract": "Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.",
      "tldr_zh": "该研究提出了 LLM-as-RNN，这是一个仅推理（inference-only）的框架，旨在解决标准大语言模型在序列预测中因依赖不可变上下文历史而缺乏动态更新记忆机制的问题。该框架将大语言模型的隐藏状态（hidden state）表示为自然语言形式的结构化系统提示摘要，从而将冻结的 LLM 转化为循环预测器。在每个时间步，模型利用反馈驱动的文本重写来更新该记忆状态，实现在不进行参数更新情况下的在线学习（online learning）。实验在医疗、气象和金融领域的三个序列基准上对 Llama、Gemma 和 GPT 系列模型进行了评估。结果表明，LLM-as-RNN 在预测准确率上平均比 zero-shot、全历史（full-history）和 MemPrompt 基线提高 6.5%。此外，该方法在固定 token 预算内有效纠正了预测错误，并提供了标准上下文累积所欠缺的可解释、人类可读的学习轨迹。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13352v1",
      "published_date": "2026-01-19 19:41:39 UTC",
      "updated_date": "2026-01-19 19:41:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:49:29.696946+00:00"
    },
    {
      "arxiv_id": "2601.13348v1",
      "title": "The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes",
      "title_zh": "“AI 神灯”现象与三类 AI 聊天机器人成瘾：逃避型角色扮演、拟社会伴侣及认知兔子洞",
      "authors": [
        "M. Karen Shen",
        "Jessica Huang",
        "Olivia Liang",
        "Ig-Jae Kim",
        "Dongwook Yoon"
      ],
      "abstract": "Recent reports on generative AI chatbot use raise concerns about its addictive potential. An in-depth understanding is imperative to minimize risks, yet AI chatbot addiction remains poorly understood. This study examines how to characterize AI chatbot addiction--why users become addicted, the symptoms commonly reported, and the distinct types it comprises. We conducted a thematic analysis of Reddit entries (n=334) across 14 subreddits where users narrated their experiences with addictive AI chatbot use, followed by an exploratory data analysis. We found: (1) users' dependence tied to the \"AI Genie\" phenomenon--users can get exactly anything they want with minimal effort--and marked by symptoms that align with addiction literature, (2) three distinct addiction types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, (3) sexual content involved in multiple cases, and (4) recovery strategies' perceived helpfulness differ between addiction types. Our work lays empirical groundwork to inform future strategies for prevention, diagnosis, and intervention.",
      "tldr_zh": "该研究调查了生成式 AI chatbot 的成瘾潜力及其表征，旨在识别用户成瘾的原因、常见症状以及具体的成瘾类型。研究人员对 14 个 Reddit 子版块中的 334 条用户叙述进行了主题分析(thematic analysis)，发现用户依赖性与“AI Genie”现象高度相关，即用户能以极低努力满足任何需求。研究明确提出了三种成瘾类型：逃避式角色扮演(Escapist Roleplay)、拟社会同伴(Pseudosocial Companion)和认识论兔子洞(Epistemic Rabbit Hole)。分析结果还显示性内容在多个成瘾案例中均有涉及，且针对不同成瘾类型的康复策略在感知有效性上表现各异。该项研究为未来针对 AI 聊天机器人成瘾的预防、诊断和干预提供了必要的实证基础。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear in CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13348v1",
      "published_date": "2026-01-19 19:33:58 UTC",
      "updated_date": "2026-01-19 19:33:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:50:21.201013+00:00"
    },
    {
      "arxiv_id": "2601.13327v1",
      "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion",
      "title_zh": "PepEDiff：基于蛋白质嵌入扩散的零样本多肽结合剂设计",
      "authors": [
        "Po-Yu Liang",
        "Tobo Duran",
        "Jun Bai"
      ],
      "abstract": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model",
      "tldr_zh": "该研究提出了 PepEDiff，这是一种新型的肽类结合剂生成器，旨在根据目标受体蛋白质序列及其口袋残基设计结合序列。与依赖中间结构预测的传统方法不同，PepEDiff 在预训练蛋白质嵌入模型衍生的连续潜空间(latent space)中直接生成结合剂序列，从而显著提高了结构和序列的多样性。该模型采用零样本(zero-shot)生成策略，通过潜空间探索和基于扩散的采样(diffusion-based sampling)捕捉结合相关的特征，有效利用全局蛋白质嵌入流形作为语义先验。在针对缺乏成药口袋的挑战性靶点 TIGIT 的实验中，PepEDiff 在基准测试和案例研究中的表现均优于现有的最先进(state-of-the-art)方法。实验结果证明了该框架作为一种通用、无需结构的零样本肽类结合剂设计工具的巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13327v1",
      "published_date": "2026-01-19 19:07:32 UTC",
      "updated_date": "2026-01-19 19:07:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:50:41.696769+00:00"
    },
    {
      "arxiv_id": "2601.13317v1",
      "title": "Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse",
      "title_zh": "付费话语与公共动态：气候话语的可解释跨平台主题建模",
      "authors": [
        "Samantha Sudhoff",
        "Pranav Perumal",
        "Zhaoqing Wu",
        "Tunazzina Islam"
      ],
      "abstract": "Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.",
      "tldr_zh": "该研究针对气候话语在付费广告生态（Meta）与公共社交媒体（Bluesky）之间因激励结构差异而产生的叙事分歧，进行了跨平台的比较分析。作者提出了一种端到端的可解释主题发现与分配框架，通过语义相似度聚类并结合大语言模型（LLMs）生成简洁且具有人类可读性的主题标签。该方法在主题质量、语义连贯性以及下游的立场预测（Stance Prediction）和主题引导检索任务中，均通过了人工及 LLM 评估器的严谨验证。实验结果揭示了平台层面的激励机制如何深刻影响气候叙事的主题结构、立场对齐以及对重大政治事件的时间响应性。研究系统地阐述了机构化的付费信息与公众自发表达之间的本质差异，并证明该框架能够有效支持异构通信环境下的比较叙事分析（Comparative Narrative Analysis）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13317v1",
      "published_date": "2026-01-19 19:00:56 UTC",
      "updated_date": "2026-01-19 19:00:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:50:40.693349+00:00"
    },
    {
      "arxiv_id": "2601.13295v1",
      "title": "CooperBench: Why Coding Agents Cannot be Your Teammates Yet",
      "title_zh": "CooperBench：编程智能体为何尚不能成为你的队友",
      "authors": [
        "Arpandeep Khatua",
        "Hao Zhu",
        "Peter Tran",
        "Arya Prabhudesai",
        "Frederic Sadrieh",
        "Johann K. Lieberwirth",
        "Xinkai Yu",
        "Yicheng Fu",
        "Michael J. Ryan",
        "Jiaxin Pei",
        "Diyi Yang"
      ],
      "abstract": "Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.",
      "tldr_zh": "该研究引入了 CooperBench，这是一个包含 4 种编程语言、12 个库以及 600 多个协作编程任务的基准测试，旨在评估 AI 智能体在解决团队冲突和寻找共识方面的协调能力。实验观察到一种“协调之咒”(curse of coordination)，即智能体在协作时的成功率平均比其独立执行任务时低 30%，这与人类团队通过增加成员提高生产力的表现截然相反。分析表明，协作失败主要源于通信渠道被模糊或不准确的信息堵塞、智能体容易偏离既定承诺，以及对队友的计划和沟通存在错误的预期。尽管现状不佳，研究在大规模模拟中仍观察到了角色分工、资源划分和谈判等罕见但有趣的涌现协调行为。该研究强调，未来的 AI 发展重心应从单纯追求个体智能体的能力提升，转向开发具备社会智能 (social intelligence) 的有效协作系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://cooperbench.com",
      "pdf_url": "https://arxiv.org/pdf/2601.13295v1",
      "published_date": "2026-01-19 18:48:37 UTC",
      "updated_date": "2026-01-19 18:48:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:50:27.314498+00:00"
    },
    {
      "arxiv_id": "2601.13286v1",
      "title": "AI Skills Improve Job Prospects: Causal Evidence from a Hiring Experiment",
      "title_zh": "AI技能提升就业前景：来自招聘实验的因果证据",
      "authors": [
        "Fabian Stephany",
        "Ole Teutloff",
        "Angelo Leone"
      ],
      "abstract": "The growing adoption of artificial intelligence (AI) technologies has heightened interest in the labour market value of AI-related skills, yet causal evidence on their role in hiring decisions remains scarce. This study examines whether AI skills serve as a positive hiring signal and whether they can offset conventional disadvantages such as older age or lower formal education. We conduct an experimental survey with 1,700 recruiters from the United Kingdom and the United States. Using a paired conjoint design, recruiters evaluated hypothetical candidates represented by synthetically designed resumes. Across three occupations - graphic designer, office assistant, and software engineer - AI skills significantly increase interview invitation probabilities by approximately 8 to 15 percentage points. AI skills also partially or fully offset disadvantages related to age and lower education, with effects strongest for office assistants, where formal AI certification plays an additional compensatory role. Effects are weaker for graphic designers, consistent with more skeptical recruiter attitudes toward AI in creative work. Finally, recruiters' own background and AI usage significantly moderate these effects. Overall, the findings demonstrate that AI skills function as a powerful hiring signal and can mitigate traditional labour market disadvantages, with implications for workers' skill acquisition strategies and firms' recruitment practices.",
      "tldr_zh": "这项研究通过一项针对英国和美国1,700名招聘人员的实验性调查，探讨了人工智能(AI)技能在劳动力市场招聘决策中的因果价值。研究采用配对联合分析(paired conjoint design)，要求招聘人员评估平面设计师、办公室助理和软件工程师等职位的虚拟简历。实验结果表明，具备AI技能显著提高了面试邀请概率，增幅达8至15个百分点。值得注意的是，AI技能能够部分或全部抵消年龄较大或受教育程度较低等传统劳动力市场劣势，且这种补偿效应在办公室助理岗位中最为显著，其中正式的AI certification发挥了额外的辅助作用。研究还发现，由于招聘人员对创意领域应用AI持怀疑态度，AI技能对平面设计师的助力相对较弱，且招聘人员自身的背景和AI usage也会影响评估结果。总体而言，该研究证实了AI技能是一个强有力的招聘信号，对劳动者的技能习得策略和企业的招聘实践具有重要意义。",
      "categories": [
        "econ.GN",
        "cs.AI"
      ],
      "primary_category": "econ.GN",
      "comment": "46 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.13286v1",
      "published_date": "2026-01-19 18:37:28 UTC",
      "updated_date": "2026-01-19 18:37:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:50:51.199119+00:00"
    },
    {
      "arxiv_id": "2601.13268v1",
      "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops",
      "title_zh": "通过多智能体评估环路提升医疗人工智能的安全性与可信度",
      "authors": [
        "Zainab Ghafoor",
        "Md Shafiqul Islam",
        "Koushik Howlader",
        "Md Rasel Khondokar",
        "Tanusree Bhattacharjee",
        "Sayantan Chakraborty",
        "Adrito Roy",
        "Ushashi Bhattacharjee",
        "Tirtho Roy"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.",
      "tldr_zh": "该研究针对医疗 Large Language Models (LLMs) 在临床部署中面临的伦理完整性和安全性合规性挑战，提出了一个旨在增强医疗 AI 安全性与可靠性的多智能体优化框架。该系统通过结构化的迭代对齐机制，将生成模型 DeepSeek R1 和 Med-PaLM 与评价智能体 LLaMA 3.1 和 Phi-4 相结合，共同执行安全评估任务。评价过程严格依据美国医学会 (AMA) 的医学伦理原则和五级安全风险评估 (SRA-5) 协议对模型响应进行动态打分与修正。研究在涵盖九个伦理领域的 900 个临床多样化查询中进行了验证，结果显示 DeepSeek R1 的平均收敛速度比 Med-PaLM 更快，而后者在处理隐私敏感场景时更具优势。实验表明，该迭代多智能体循环使伦理违规减少了 89%，并实现了 92% 的风险降级率，验证了该方法的有效性。此项工作为医疗 AI 的安全治理提供了一种可扩展、符合监管标准且具备成本效益的新范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13268v1",
      "published_date": "2026-01-19 18:10:34 UTC",
      "updated_date": "2026-01-19 18:10:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:50:42.601876+00:00"
    },
    {
      "arxiv_id": "2601.13262v1",
      "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning",
      "title_zh": "CURE-Med：面向多语言医学推理的课程引导强化学习",
      "authors": [
        "Eric Onyame",
        "Akash Ghosh",
        "Subhadip Baidya",
        "Sriparna Saha",
        "Xiuying Chen",
        "Chirag Agarwal"
      ],
      "abstract": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/",
      "tldr_zh": "该研究针对大语言模型在多语言医疗推理中表现不可靠的问题，首先引入了涵盖13种语言的高质量数据集 CUREMED-BENCH，其中包含了阿姆哈拉语、约鲁巴语和斯瓦希里语等低资源语言。随后，研究者提出了 CURE-MED 框架，这是一种基于课程告知强化学习 (Curriculum-Informed Reinforcement Learning) 的方法，通过集成代码切换感知监督微调 (Code-switching-aware Supervised Fine-tuning) 和组相对策略优化 (Group Relative Policy Optimization, GRPO) 来协同提升模型的逻辑正确性和语言稳定性。实验结果显示，该方案在不同参数规模下均显著优于基线模型，其中 32B 模型在语言一致性和逻辑正确性上分别达到了 94.96% 和 70.04%。该研究为在医疗领域实现可靠且公平的多语言推理提供了技术支撑，相关数据集和代码均已开源。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13262v1",
      "published_date": "2026-01-19 17:51:00 UTC",
      "updated_date": "2026-01-19 17:51:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:50:45.792396+00:00"
    },
    {
      "arxiv_id": "2601.13260v1",
      "title": "Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models",
      "title_zh": "莫将分词器视作理所当然：大语言模型的核心设计决策",
      "authors": [
        "Sawsan Alqahtani",
        "Mir Tafseer Nayeem",
        "Md Tahmid Rahman Laskar",
        "Tasnim Mohiuddin",
        "M Saiful Bari"
      ],
      "abstract": "Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.",
      "tldr_zh": "该研究指出 Tokenization 是所有大型语言模型的基础，但目前常被误认为是不受重视的预处理步骤。作者批评了 Byte Pair Encoding (BPE) 等常用子词方法在语言结构对齐、偏见放大及跨语言效率方面的不足。本文将 Tokenization 重新定义为核心建模决策，提出了一种结合语言学、领域和部署考量的 Tokenizer 与模型协同设计的上下文感知框架。通过强调标准化评估和透明报告的必要性，该研究旨在提高分词选择的可解释性。将 Tokenization 视为核心设计问题而非技术附带品，有助于构建更公平、高效且具备更强适应性的语言技术。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EACL 2026 (long, main). The first two authors contributed equally",
      "pdf_url": "https://arxiv.org/pdf/2601.13260v1",
      "published_date": "2026-01-19 17:50:36 UTC",
      "updated_date": "2026-01-19 17:50:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:50:58.996814+00:00"
    },
    {
      "arxiv_id": "2601.13247v1",
      "title": "Aligning Agentic World Models via Knowledgeable Experience Learning",
      "title_zh": "基于知识化经验学习的智能体世界模型对齐",
      "authors": [
        "Baochang Ren",
        "Yunzhi Yao",
        "Rui Sun",
        "Shuofei Qiao",
        "Ningyu Zhang",
        "Huajun Chen"
      ],
      "abstract": "Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.",
      "tldr_zh": "该研究针对大语言模型（LLMs）在物理世界中由于缺乏程序性基础而产生的物理幻觉（physical hallucinations）问题，提出了WorldMind框架以通过知识经验学习对齐智能体世界模型。该框架通过合成环境反馈自主构建符号化世界知识库（World Knowledge Repository），有效解决了传统参数微调方法在应对动态环境规律时的僵化问题。WorldMind巧妙地统一了旨在利用预测误差确保物理可行性的过程经验（Process Experience）和用于通过成功轨迹引导任务最优性的目标经验（Goal Experience）。在EB-ALFRED和EB-Habitat基准测试上的实验结果显示，WorldMind的表现显著优于现有基线模型。此外，该框架还展现出卓越的跨模型与跨环境迁移能力，为构建具备物理常识的具身智能体提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongoing work",
      "pdf_url": "https://arxiv.org/pdf/2601.13247v1",
      "published_date": "2026-01-19 17:33:31 UTC",
      "updated_date": "2026-01-19 17:33:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:51:00.991664+00:00"
    },
    {
      "arxiv_id": "2601.13240v1",
      "title": "KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?",
      "title_zh": "KOCO-BENCH：大语言模型能否在软件开发中利用领域知识？",
      "authors": [
        "Xue Jiang",
        "Jiaru Qian",
        "Xianjie Shi",
        "Chenjie Li",
        "Hao Zhu",
        "Ziyu Wang",
        "Jielun Zhang",
        "Zheyu Zhao",
        "Kechi Zhang",
        "Jia Li",
        "Wenpin Jiao",
        "Zhi Jin",
        "Ge Li",
        "Yihong Dong"
      ],
      "abstract": "Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.",
      "tldr_zh": "该研究提出了KOCO-BENCH，这是一个旨在评估大型语言模型(LLMs)在软件开发中领域专业化(Domain Specialization)能力的全新基准测试。针对现有基准缺乏显式知识库且无法有效评估模型获取与应用新知识能力的不足，KOCO-BENCH 涵盖了6个新兴领域的11个软件框架和25个项目，并配备了精选的知识语料库(Knowledge Corpora)。该基准包含多粒度评估任务，涵盖了从函数级到项目级的领域代码生成(Domain Code Generation)以及多项选择题形式的领域知识理解。与传统仅提供测试集的基准不同，KOCO-BENCH 要求模型必须从语料库中学习并应用API、规则和约束等领域知识来解决任务。实验结果显示，即使采用了SFT、RAG和kNN-LM等专业化方法，最先进的模型在应对该基准时依然面临巨大挑战。表现最好的编程智能体Claude Code仅实现了34.2%的得分，这表明目前迫切需要开发更有效的领域专业化方法，以提升LLMs在真实世界软件开发中的知识应用水平。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13240v1",
      "published_date": "2026-01-19 17:20:16 UTC",
      "updated_date": "2026-01-19 17:20:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:51:01.284798+00:00"
    },
    {
      "arxiv_id": "2601.13238v1",
      "title": "A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models",
      "title_zh": "基于语义解耦的两阶段雨天攻击：揭示视觉语言模型的天气鲁棒性缺陷",
      "authors": [
        "Chengyin Hu",
        "Xiang Chen",
        "Zhe Jia",
        "Weiwen Shi",
        "Fengyu Zhang",
        "Jiujiang Guo",
        "Yiwei Wei"
      ],
      "abstract": "Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.",
      "tldr_zh": "该研究探讨了视觉语言模型 (VLMs) 在雨天等复杂天气条件下的鲁棒性问题，旨在评估跨模态语义对齐在结构化扰动下的稳定性。作者提出了首个基于语义解耦 (semantic decoupling) 的两阶段参数化攻击框架，通过模拟逼真的天气效果来分析降雨引发的决策偏移。第一阶段利用低维全局调制削弱原始语义决策边界，第二阶段则通过显式建模多尺度雨滴和光照变化，在非像素参数空间中诱导稳定的语义偏移。实验结果显示，即使是符合物理逻辑且高度受限的天气扰动，也能导致主流 VLMs 产生严重的语义误对齐，暴露出其在现实部署中的安全风险。研究进一步证实，光照建模和多尺度雨滴结构是驱动这些语义偏移的核心因素，为提升多模态模型在极端天气下的可靠性提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13238v1",
      "published_date": "2026-01-19 17:16:30 UTC",
      "updated_date": "2026-01-19 17:16:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:52:16.039935+00:00"
    },
    {
      "arxiv_id": "2601.13236v1",
      "title": "Pixelwise Uncertainty Quantification of Accelerated MRI Reconstruction",
      "title_zh": "加速磁共振成像重建的像素级不确定性量化",
      "authors": [
        "Ilias I. Giannakopoulos",
        "Lokesh B Gautham Muthukumar",
        "Yvonne W. Lui",
        "Riccardo Lattanzi"
      ],
      "abstract": "Parallel imaging techniques reduce magnetic resonance imaging (MRI) scan time but image quality degrades as the acceleration factor increases. In clinical practice, conservative acceleration factors are chosen because no mechanism exists to automatically assess the diagnostic quality of undersampled reconstructions. This work introduces a general framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without access to any ground-truth reference image. Our method integrates conformal quantile regression with image reconstruction methods to estimate statistically rigorous pixel-wise uncertainty intervals. We trained and evaluated our model on Cartesian undersampled brain and knee data obtained from the fastMRI dataset using acceleration factors ranging from 2 to 10. An end-to-end Variational Network was used for image reconstruction. Quantitative experiments demonstrate strong agreement between predicted uncertainty maps and true reconstruction error. Using our method, the corresponding Pearson correlation coefficient was higher than 90% at acceleration levels at and above four-fold; whereas it dropped to less than 70% when the uncertainty was computed using a simpler a heuristic notion (magnitude of the residual). Qualitative examples further show the uncertainty maps based on quantile regression capture the magnitude and spatial distribution of reconstruction errors across acceleration factors, with regions of elevated uncertainty aligning with pathologies and artifacts. The proposed framework enables evaluation of reconstruction quality without access to fully-sampled ground-truth reference images. It represents a step toward adaptive MRI acquisition protocols that may be able to dynamically balance scan time and diagnostic reliability.",
      "tldr_zh": "该研究针对加速MRI重建中的诊断质量自动评估难题，提出了一种通用的像素级不确定性量化(Uncertainty Quantification)框架。该方法将符合分位数回归(Conformal Quantile Regression)与图像重建算法相结合，能够在无需参考真实图像(Ground-truth)的情况下估算统计严谨的像素级不确定性区间。研究人员在fastMRI数据集上利用端到端变分网络(Variational Network)进行验证，涵盖了2至10倍的加速因子(Acceleration Factors)。实验结果显示，所提方法生成的不确定性图与真实重建误差高度一致，在4倍及以上加速倍率下的相关系数超过90%，远优于传统的启发式残差计算方法。定性结果进一步证实，该框架能有效捕捉病灶及伪影区域的误差分布，为开发能够动态平衡扫描时间与诊断可靠性的自适应MRI采集协议奠定了重要基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 8 figues, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13236v1",
      "published_date": "2026-01-19 17:12:28 UTC",
      "updated_date": "2026-01-19 17:12:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:51:23.189081+00:00"
    },
    {
      "arxiv_id": "2601.13235v1",
      "title": "RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions",
      "title_zh": "RubRIX：照护者-人工智能交互中基于准则驱动的风险缓解",
      "authors": [
        "Drishti Goel",
        "Jeongah Lee",
        "Qiuyue Joy Zhong",
        "Violeta J. Rodriguez",
        "Daniel S. Brown",
        "Ravi Karkar",
        "Dong Whi Yoo",
        "Koustuv Saha"
      ],
      "abstract": "Caregivers seeking AI-mediated support express complex needs -- information-seeking, emotional validation, and distress cues -- that warrant careful evaluation of response safety and appropriateness. Existing AI evaluation frameworks, primarily focused on general risks (toxicity, hallucinations, policy violations, etc), may not adequately capture the nuanced risks of LLM-responses in caregiving-contexts. We introduce RubRIX (Rubric-based Risk Index), a theory-driven, clinician-validated framework for evaluating risks in LLM caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. We evaluate six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. Our findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. We release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.",
      "tldr_zh": "该研究提出了 RubRIX (Rubric-based Risk Index)，这是一个由理论驱动并经临床验证的框架，旨在评估大语言模型 (LLMs) 在照护支持场景中的响应风险。针对通用评估框架难以捕捉照护语境下微妙风险的局限性，RubRIX 基于关怀伦理理论定义了 Inattention、Bias & Stigma、Information Inaccuracy、Uncritical Affirmation 和 Epistemic Arrogance 五个风险维度。研究团队对来自 Reddit 和 ALZConnected 平台的两万余条照护者查询进行了测试，结果显示经过量规引导的优化能使模型的风险组件在一次迭代后显著降低 45-98%。该工作为高负担 (high-burden) 语境下开发领域敏感且以用户为中心的评估体系提供了重要的方法论贡献。研究结果强调了在照护支持领域负责任地部署 LLMs 时，进行互动式风险评估的必要性。此外，该研究还发布了相关基准数据集，以推动未来在 AI 介导支持中的语境风险评估研究。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13235v1",
      "published_date": "2026-01-19 17:10:49 UTC",
      "updated_date": "2026-01-19 17:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:51:26.092915+00:00"
    },
    {
      "arxiv_id": "2601.13233v1",
      "title": "RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements",
      "title_zh": "RAG：面向复杂功能响应需求超材料不确定性感知设计的随机森林生成式设计框架",
      "authors": [
        "Bolin Chen",
        "Dex Doksoo Lee",
        "Wei \"Wayne'' Chen",
        "Wei Chen"
      ],
      "abstract": "Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.",
      "tldr_zh": "该研究提出了一种基于随机森林的生成式框架(RAndom-forest-based Generative approach, RAG)，旨在解决超材料(Metamaterials)高维非线性功能响应(functional responses)逆向设计中面临的数据依赖性强和缺乏不确定性量化(uncertainty quantification)等挑战。RAG利用随机森林的小样本兼容性实现高效预测，并通过集成学习(ensemble)估算似然度以评估生成设计的可信度，同时结合条件似然采样解决了设计过程中的一对多映射问题。通过在声学超材料的通带/阻带设计以及机械超材料的突跳响应(snap-through responses)设计中的应用，证明了该框架在仅有数百至一千个样本的情况下即可完成复杂任务。基准测试显示，RAG在处理非线性应力-应变关系时的数据效率显著优于传统的神经网络，为涉及高昂模拟成本和复杂功能需求的逆向设计提供了一种轻量且可靠的新途径。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13233v1",
      "published_date": "2026-01-19 17:06:12 UTC",
      "updated_date": "2026-01-19 17:06:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:51:38.393825+00:00"
    },
    {
      "arxiv_id": "2601.13228v1",
      "title": "Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation",
      "title_zh": "自回归模型在任意顺序生成领域媲美扩散模型",
      "authors": [
        "Tianqi Du",
        "Lizhe Fang",
        "Weijie Yang",
        "Chenheng Zhang",
        "Zeming Wei",
        "Yifei Wang",
        "Yisen Wang"
      ],
      "abstract": "Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.",
      "tldr_zh": "该研究针对 Diffusion 语言模型虽然具备任意顺序生成和双向条件建模的灵活性，但在建模深度、样本质量和稳定性上弱于 Autoregressive (AR) 模型的问题，提出了 Any-order Any-subset Autoregressive modeling (A3) 框架。A3 通过将扩散式训练重构为结构化的多组预测过程，将标准 AR 分解扩展至任意 Token 组和生成顺序，在保留 AR 概率严谨性和多层依赖建模能力的同时，使模型继承了并行与双向生成的特性。研究采用了双流注意力 (Two-stream Attention) 架构和渐进式适配策略，实现了预训练 AR 模型向任意顺序预测模式的平滑迁移。实验结果显示，A3 在问答 (Question Answering)、常识推理 (Commonsense Reasoning) 和故事填充 (Story Infilling) 等任务中的表现优于基于 Diffusion 的模型。这项工作为构建灵活、高效的语言建模范式提供了统一途径，证明了 AR 模型在处理非线性生成任务时具有抗衡甚至超越 Diffusion 模型的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13228v1",
      "published_date": "2026-01-19 17:03:48 UTC",
      "updated_date": "2026-01-19 17:03:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:51:42.896672+00:00"
    },
    {
      "arxiv_id": "2601.13227v1",
      "title": "Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?",
      "title_zh": "内部知识：RAG 系统能从评估机密中获益几何？",
      "authors": [
        "Laura Dietz",
        "Bryan Li",
        "Eugene Yang",
        "Dawn Lawrie",
        "William Walden",
        "James Mayfield"
      ],
      "abstract": "RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches in particular are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. In this paper, we investigate this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GPT-Researcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, we show that near-perfect evaluation scores can be achieved when elements of the evaluation - such as prompt templates or gold nuggets - are leaked or can be predicted. Our results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.",
      "tldr_zh": "该研究探讨了检索增强生成(RAG)系统在使用大语言模型评测器(LLM judges)——尤其是基于金句(nugget-based)的方法进行评估和优化时，可能存在的循环性及测量失效风险。研究通过对比实验，分析了 Ginger 和 Crucible 等基于金句的 RAG 系统与 GPT-Researcher 等强基准模型的表现。研究人员通过故意修改 Crucible 系统，使其针对 LLM judge 进行优化，模拟评估要素（如提示词模板或黄金金句 gold nuggets）泄露或被预测的情景。实验结果显示，在这种情况下 RAG 系统可以获得接近完美的评估分数，这揭示了指标过拟合(metric overfitting)的严重风险。最后，论文强调了在 RAG 系统评估中采用盲测(blind evaluation)和方法论多样性的重要性，以防止将指标优化误认为是系统的真实进步。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13227v1",
      "published_date": "2026-01-19 17:03:20 UTC",
      "updated_date": "2026-01-19 17:03:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:51:43.742424+00:00"
    },
    {
      "arxiv_id": "2601.13222v1",
      "title": "Incorporating Q&A Nuggets into Retrieval-Augmented Generation",
      "title_zh": "将 Q&A Nuggets 融入检索增强生成",
      "authors": [
        "Laura Dietz",
        "Bryan Li",
        "Gabrielle Liu",
        "Jia-Huei Ju",
        "Eugene Yang",
        "Dawn Lawrie",
        "William Walden",
        "James Mayfield"
      ],
      "abstract": "RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.",
      "tldr_zh": "该研究提出了 Crucible，一种将 Q&A nuggets 融入检索增强生成 (Retrieval-augmented Generation, RAG) 的 Nugget-Augmented Generation 系统，旨在通过自动评估 (automatic evaluation) 思想优化 RAG 流程。Crucible 通过从检索到的文档中构建 Q&A nuggets 库，并利用这些语义块引导信息的提取、选择和报告生成，从而有效保留明确的引用来源 (citation provenance)。与模糊的聚类抽象不同，基于 nuggets 的推理利用清晰且可解释的 Q&A 语义来避免信息重复，并确保在整个生成过程中维持引用的一致性。在 TREC NeuCLIR 2024 数据集上的实验结果表明，Crucible 在 nugget recall、密度及引用接地 (citation grounding) 等指标上均显著优于最近的同类系统 Ginger，展现了更强的生成性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13222v1",
      "published_date": "2026-01-19 16:57:33 UTC",
      "updated_date": "2026-01-19 16:57:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:51:55.483672+00:00"
    },
    {
      "arxiv_id": "2601.13217v1",
      "title": "Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision",
      "title_zh": "超越单次写作：深度研究智能体在多轮报告修订中的不可靠性",
      "authors": [
        "Bingsen Chen",
        "Boyan Li",
        "Ping Nie",
        "Yuyu Zhang",
        "Xi Ye",
        "Chen Zhao"
      ],
      "abstract": "Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.",
      "tldr_zh": "该研究指出目前的深度研究智能体(Deep Research Agents, DRAs)评估主要集中于单次写作任务，忽略了人类研究中关键的多轮迭代修订过程。为此，作者开发了名为 Mr Dre 的评估套件，通过包含全面性、事实性和呈现质量的评估协议以及人工验证的反馈模拟流水线，将多轮报告修订(multi-turn report revision)确立为 DRAs 的新评估维度。对五种代表性 DRAs 的实验分析发现，尽管智能体能响应用户反馈，但却会在 16-27% 的已有内容和引用质量(citation quality)上出现性能倒退。研究表明，智能体在修订过程中常会干扰反馈范围之外的内容，且无法有效维持早期的编辑成果。此外，研究还证实了通过提示工程(prompt engineering)或增加专门的修订子智能体等推理端手段并不能轻易解决这一不可靠性问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13217v1",
      "published_date": "2026-01-19 16:48:45 UTC",
      "updated_date": "2026-01-19 16:48:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:52:25.094614+00:00"
    },
    {
      "arxiv_id": "2601.13206v1",
      "title": "Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues",
      "title_zh": "实时时限揭示大语言模型策略性对话中的时间感知失效",
      "authors": [
        "Neil K. R. Sehgal",
        "Sharath Chandra Guntuku",
        "Lyle Ungar"
      ],
      "abstract": "Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\\% vs. 4\\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\\geq$95\\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.",
      "tldr_zh": "该研究探讨了大语言模型（LLMs）在模拟谈判中应对实时（Real-Time）截止日期的能力，旨在揭示其在连续时间约束下的局限性。研究者通过对比仅知总时限的对照组与每回合接收剩余时间更新的时间感知组，评估了 LLMs 的行为调整。实验发现，时间感知组的成交率与报价接受率显著高于对照组，表明 LLMs 难以在内部追踪流逝的时间（Elapsed Time）。由于相同模型在回合制限制下能达到 95% 以上的成交率，这证明了其失败源于时间追踪能力的缺失而非策略推理（Strategic Reasoning）的不足。该研究在多种模型和场景中证实了 LLMs 普遍缺乏时间意识（Temporal Awareness），这一发现指出了 LLMs 在部署于时间敏感型应用时面临的关键瓶颈。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13206v1",
      "published_date": "2026-01-19 16:31:07 UTC",
      "updated_date": "2026-01-19 16:31:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:52:11.358024+00:00"
    },
    {
      "arxiv_id": "2601.13197v1",
      "title": "Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification",
      "title_zh": "用于增强 DoS/DDoS 攻击分类的扩散驱动合成表格数据生成",
      "authors": [
        "Aravind B",
        "Anirud R. S.",
        "Sai Surya Teja N",
        "Bala Subrahmanya Sriranga Navaneeth A",
        "Karthika R",
        "Mohankumar N"
      ],
      "abstract": "Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than oth- ers, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is ad- dressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For the minority classes that have smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.",
      "tldr_zh": "该研究针对网络入侵检测中的类别不平衡问题，提出了一种基于表格去噪扩散概率模型(Tabular Denoising Diffusion Probability Models, TabDDPM)的数据增强方法。通过迭代去噪过程，该方法从CIC-IDS2017数据集中合成了高质量的少数类攻击样本，并将其与原始数据集融合以扩充训练集。实验表明，使用增强后的数据训练人工神经网络(ANN)分类器，能够在原本样本匮乏的攻击类别上实现接近完美的召回率(Recall)。研究结果证明了扩散模型(Diffusion Models)是解决安全领域表格数据不平衡问题的有效手段，并展示了其在欺诈检测和医疗诊断等领域的广泛应用潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 8 figures, 2025 International Conference on Signal Processing, Computation, Electronics, Power and Telecommunication (IConSCEPT), National Institute of Technology, Puducherry, India",
      "pdf_url": "https://arxiv.org/pdf/2601.13197v1",
      "published_date": "2026-01-19 16:22:27 UTC",
      "updated_date": "2026-01-19 16:22:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:52:22.226455+00:00"
    },
    {
      "arxiv_id": "2601.13187v1",
      "title": "Scientific production in the era of Large Language Models",
      "title_zh": "大语言模型时代的科学产出",
      "authors": [
        "Keigo Kusumegi",
        "Xinyu Yang",
        "Paul Ginsparg",
        "Mathijs de Vaan",
        "Toby Stuart",
        "Yian Yin"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly reshaping scientific research. We analyze these changes in multiple, large-scale datasets with 2.1M preprints, 28K peer review reports, and 246M online accesses to scientific documents. We find: 1) scientists adopting LLMs to draft manuscripts demonstrate a large increase in paper production, ranging from 23.7-89.3% depending on scientific field and author background, 2) LLM use has reversed the relationship between writing complexity and paper quality, leading to an influx of manuscripts that are linguistically complex but substantively underwhelming, and 3) LLM adopters access and cite more diverse prior work, including books and younger, less-cited documents. These findings highlight a stunning shift in scientific production that will likely require a change in how journals, funding agencies, and tenure committees evaluate scientific works.",
      "tldr_zh": "该研究分析了大型语言模型(Large Language Models, LLMs)如何重塑科学研究，通过对210万篇预印本、2.8万份同行评审报告及2.46亿次在线访问的大规模数据进行分析，揭示了学术产出的显著变化。研究发现，利用LLMs辅助撰写论文的科学家产出量大幅提升，增幅在23.7%至89.3%之间。然而，LLMs的使用反转了写作复杂性与论文质量之间的关联，导致大量语言华丽但实质贡献有限的稿件涌现。与此同时，LLM使用者展现出引用更多元化文献的倾向，涵盖了书籍及较新的低引用文档。这些趋势表明科学生产模式正发生根本性转变，学术期刊、资助机构及评审委员会亟需重新审视现有的科学评价体系。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY",
        "physics.soc-ph"
      ],
      "primary_category": "cs.DL",
      "comment": "This is the author's version of the work. The definitive version was published in Science on 18 Dec 2025, DOI: 10.1126/science.adw3000. Link to the Final Published Version: https://www.science.org/doi/10.1126/science.adw3000",
      "pdf_url": "https://arxiv.org/pdf/2601.13187v1",
      "published_date": "2026-01-19 16:10:22 UTC",
      "updated_date": "2026-01-19 16:10:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:20.397578+00:00"
    },
    {
      "arxiv_id": "2601.13186v1",
      "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching",
      "title_zh": "基于智能体 AI、嵌套学习及语义缓存实现 AI 可持续性的提示词注入防御",
      "authors": [
        "Diego Gosmar",
        "Deborah A. Dahl"
      ],
      "abstract": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在多智能体设置中面临的提示词注入(Prompt Injection)安全风险，提出了一种结合智能体流水线(Agentic Pipeline)与嵌套学习(Nested Learning)架构的防御系统。论文通过引入基于语义相似度的缓存机制和可观测性得分比率(Observability Score Ratio)指标，将原有的评估框架扩展为TIVS-O，旨在深入探讨防御有效性与透明度之间的相互作用。该系统利用连续内存系统(Continuum Memory Systems)在涵盖十个攻击家族的注入提示词上实施语义缓存，并由专门的智能体进行安全分析和可审计性(Auditability)评估。实验结果表明，该系统在确保零高风险违规的同时，通过语义缓存减少了41.6%的LLM调用，显著降低了延迟、能耗及碳排放。研究揭示了可观测性评估在多智能体流水线中的非单调效应，证明了增强内存的智能体可以在不修改模型权重的前提下，同时优化安全鲁棒性、实时性能与环境可持续性，为绿色且安全的LLM部署提供了生产级路径。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 19 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13186v1",
      "published_date": "2026-01-19 16:10:11 UTC",
      "updated_date": "2026-01-19 16:10:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:27.142881+00:00"
    },
    {
      "arxiv_id": "2601.13166v1",
      "title": "From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models",
      "title_zh": "从 10 万余张影像到夺得首届脑部 MRI 基础模型挑战赛冠军：经验与模型分享",
      "authors": [
        "Pedro M. Gordaliza",
        "Jaume Banus",
        "Benoît Gérin",
        "Maxence Wynen",
        "Nataliia Molchanova",
        "Jonas Richiardi",
        "Meritxell Bach Cuadra"
      ],
      "abstract": "Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.",
      "tldr_zh": "该研究介绍了在MICCAI 2025首届3D脑部MRI基础模型(Foundation Models)挑战赛SSL3D和FOMO25中夺冠的解决方案。该方案核心采用了U-Net CNN架构，并巧妙结合了解剖学先验(anatomical priors)与神经影像学领域知识(neuroimaging domain knowledge)。与基于Transformer的竞品相比，该模型在训练效率上实现了1至2个数量级的提升，且模型体积仅为后者的十分之一。研究利用超过10万张影像进行大规模训练，证明了结合领域知识的轻量化架构在处理复杂放射学任务时的优越性。目前研究团队已公开相关模型，旨在为医疗影像分析领域提供高效且可落地的技术参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Work presented at the SSL3D Challenge (1st place, ResEnc-L track) and FOMO Challenge (1st place, Methods track) on Brain MRI Foundation Models at MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.13166v1",
      "published_date": "2026-01-19 15:43:51 UTC",
      "updated_date": "2026-01-19 15:43:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:52:48.015473+00:00"
    },
    {
      "arxiv_id": "2601.13160v1",
      "title": "Training instability in deep learning follows low-dimensional dynamical principles",
      "title_zh": "深度学习训练不稳定性遵循低维动力学原理",
      "authors": [
        "Zhipeng Zhang",
        "Zhenjie Yao",
        "Kai Li",
        "Lei Yang"
      ],
      "abstract": "Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.\n  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.\n  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.",
      "tldr_zh": "该研究针对深度学习系统中训练过程的稳定性问题，提出了一个统一的动力学视角(dynamical perspective)，将训练稳定性视为学习系统的内在属性。作者从优化(optimization)、环境/数据(environmental/data)、参数(parametric)以及学习信号(learning-signal)四个交互维度对稳定性进行了刻画，并通过受控扰动审计(controlled perturbation auditing)方法对训练轨迹进行探测。实验涵盖了强化学习(reinforcement learning)和大型语言模型(large language model)训练，发现最终的高性能表现往往与训练稳定性并不挂钩(decoupled)。研究指出，受控的随机性(controlled stochasticity)能够在不同范式下持续缓冲学习动力学，且低维潜在元状态(low-dimensional latent meta-states)的偏差会系统性地先于可观察到的性能崩溃(performance collapse)出现。这些发现证明了训练稳定性是学习系统的一种可测量且可比较的动力学属性，为研究最终性能结果之外的学习动力学(learning dynamics)奠定了描述性基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13160v1",
      "published_date": "2026-01-19 15:37:45 UTC",
      "updated_date": "2026-01-19 15:37:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:52:40.429465+00:00"
    },
    {
      "arxiv_id": "2601.13142v1",
      "title": "TVWorld: Foundations for Remote-Control TV Agents",
      "title_zh": "TVWorld：遥控电视智能体的基础",
      "authors": [
        "Zhantao Ma",
        "Quanfeng Lu",
        "Shuai Zhong",
        "Dahai Yu",
        "Ping Luo",
        "Michael K. Ng"
      ],
      "abstract": "Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \\textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \\textbf{TVWorld-N} for topology-aware navigation and \\textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \\emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \\textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.",
      "tldr_zh": "该研究针对目前大视觉语言模型 (LVLMs) 在电视遥控交互 (Remote-control interaction) 领域研究不足的问题，提出了 TVWorld，一种基于图的真实电视导航抽象框架。研究团队衍生出 TVWorld-N 和 TVWorld-G 两个基准测试，用于评估拓扑感知导航和焦点感知定位能力，并发现现有智能体在长程电视导航中普遍缺乏拓扑意识 (Topology awareness)。基于这一发现，研究者提出了拓扑感知训练 (Topology-Aware Training) 框架，并开发了专用于电视导航的基础模型 TVTheseus。实验表明，TVTheseus 在 TVWorld-N 上取得了 68.3% 的成功率，显著超越了 Gemini 3 Flash 等强力闭源基准模型，达到了当前最先进 (SOTA) 的性能水平。该工作为开发高效的电视交互智能体提供了重要的基准和技术路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13142v1",
      "published_date": "2026-01-19 15:24:32 UTC",
      "updated_date": "2026-01-19 15:24:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:52:51.482467+00:00"
    },
    {
      "arxiv_id": "2601.13122v1",
      "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward",
      "title_zh": "通用系统的负责任人工智能：综述、挑战与展望",
      "authors": [
        "Gourab K Patro",
        "Himanshi Agrawal",
        "Himanshu Gharat",
        "Supriya Panigrahi",
        "Nim Sherpa",
        "Vishal Vaddina",
        "Dagnachew Birru"
      ],
      "abstract": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.",
      "tldr_zh": "该研究针对基于大语言和视觉模型的通用人工智能系统(General-Purpose AI Systems)，系统性地探讨了其在责任AI(Responsible AI, RAI)领域面临的挑战。作者通过公平性、隐私性、鲁棒性等八项RAI核心原则对比了通用AI与传统任务特定AI，指出输出中非确定性的高自由度(Degree of Freedom in output, DoFo)是导致幻觉、毒性和刻板印象等风险的核心原因。为此，研究推导出了C2V2(Control, Consistency, Value, Veracity)指标体系，作为未来通用AI系统满足RAI要求的基本准则。论文进一步讨论了AI对齐(AI alignment)、检索增强生成(RAG)和推理增强等现有技术在满足C2V2要求方面的表现。最后，研究提出了一种系统设计方法，主张通过在C2V2维度下正式建模特定领域的RAI需求并组合多种技术，为实现可负责任的通用人工智能提供了清晰的演进路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13122v1",
      "published_date": "2026-01-19 15:10:59 UTC",
      "updated_date": "2026-01-19 15:10:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:52:52.296700+00:00"
    },
    {
      "arxiv_id": "2601.13114v1",
      "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks",
      "title_zh": "IntAgent：面向先进下一代网络的基于 NWDAF 的意图 LLM 智能体",
      "authors": [
        "Abdelrahman Soliman",
        "Ahmed Refaey",
        "Aiman Erbad",
        "Amr Mohamed"
      ],
      "abstract": "Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve. In this work, we introduce IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents. Unlike previous approaches, we develop an intent tools engine directly within the NWDAF analytics engine, allowing our agent to utilize live network analytics to inform its reasoning and tool selection. We offer an enriched, 3GPP-compliant data source that enhances the dynamic, context-aware fulfillment of network operator goals, along with an MCP tools server for scheduling, monitoring, and analytics tools. We demonstrate the efficacy of our framework through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, which validate IntAgent's ability to autonomously fulfill complex network intents.",
      "tldr_zh": "该研究提出了IntAgent，这是一种基于NWDAF（网络数据分析功能）的智能意图LLM Agent，旨在提升下一代网络中意图驱动网络（IBNs）的自动化运营能力。与以往方法不同，IntAgent直接在NWDAF分析引擎内部构建了意图工具引擎，使Agent能够实时利用网络分析数据来指导其推理过程和工具选择。该框架引入了符合3GPP标准的增强数据源以实现动态的上下文感知，并配备了用于任务调度、监控和分析的MCP工具服务器。通过机器学习流量预测和计划策略执行两个实际用例的测试，实验结果证实了IntAgent自主履行复杂网络意图的高效性。这一研究为下一代网络中实现可感知、自适应的意图自动化管理提供了创新的技术方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "conference",
      "pdf_url": "https://arxiv.org/pdf/2601.13114v1",
      "published_date": "2026-01-19 14:55:48 UTC",
      "updated_date": "2026-01-19 14:55:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:07.248487+00:00"
    },
    {
      "arxiv_id": "2601.13111v1",
      "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL",
      "title_zh": "CORE-T：面向 Text-to-SQL 的表格连贯检索",
      "authors": [
        "Hassan Soliman",
        "Vivek Gupta",
        "Dan Roth",
        "Iryna Gurevych"
      ],
      "abstract": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.",
      "tldr_zh": "该研究针对现实 Text-to-SQL 工作流中多表连接检索的性能瓶颈，提出了 CORE-T，一个可扩展且无需训练的表格检索框架。在大规模异构数据环境中，现有的 Dense Retrieval (DR) 往往会引入过多干扰项，而 CORE-T 通过 LLM 生成的元数据和预计算的轻量级兼容性缓存有效解决了这一挑战。在推理阶段，该框架利用单一 LLM 调用从候选集中筛选出连贯且可连接的子集，并通过加法调整步骤精确恢复强兼容表格。实验结果显示，CORE-T 在 Bird、Spider 和 MMQA 基准测试中将表选择的 F1 分值最高提升了 22.7 点，同时减少了约 42% 的无关表格检索。此外，该方法在提升多表执行准确率的同时，相比计算密集型基线模型，显著降低了 4 至 5 倍的 Token 使用量，实现了高效且精准的表格定位。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint under review. Code and data available at: https://github.com/UKPLab/arxiv2026-core-t",
      "pdf_url": "https://arxiv.org/pdf/2601.13111v1",
      "published_date": "2026-01-19 14:51:23 UTC",
      "updated_date": "2026-01-19 14:51:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:22.523456+00:00"
    },
    {
      "arxiv_id": "2601.13075v1",
      "title": "METIS: Mentoring Engine for Thoughtful Inquiry & Solutions",
      "title_zh": "METIS：面向深度探究与解决方案的导师引擎",
      "authors": [
        "Abhinav Rajeev Kumar",
        "Dhruv Trehan",
        "Paras Chopra"
      ],
      "abstract": "Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.",
      "tldr_zh": "该研究开发了名为 METIS (Mentoring Engine for Thoughtful Inquiry & Solutions) 的 AI 导师系统，旨在填补学生缺乏专业研究指导的空白，引导本科生将学术创意转化为正式论文。作为一种具备阶段感知 (stage-aware) 能力的工具增强型助手，METIS 集成了文献搜索 (literature search)、策展指南 (curated guidelines)、方法论检查 (methodology checks) 和记忆功能。通过在六个写作阶段中与 GPT-5 和 Claude Sonnet 4.5 进行对比评估，实验证明 LLM 评委对 METIS 的偏好率明显高于其他基线模型。此外，METIS 在清晰度、可操作性和约束匹配度上的得分在各阶段均表现更优。在多轮辅导场景中，METIS 的产出质量略高于 GPT-5，其优势在文档支撑阶段 (document-grounded stages) 尤为显著。尽管如此，该系统仍面临过早工具路由 (tool routing)、浅层落地 (shallow grounding) 和阶段分类错误 (stage misclassification) 等挑战。该研究为提升 AI 在学术辅导领域的应用提供了重要参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13075v1",
      "published_date": "2026-01-19 14:10:35 UTC",
      "updated_date": "2026-01-19 14:10:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:14.851650+00:00"
    },
    {
      "arxiv_id": "2601.13060v1",
      "title": "MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux",
      "title_zh": "MagicGUI-RMS：基于自动化反馈回流的自进化 GUI 智能体多智能体奖励模型系统",
      "authors": [
        "Zecheng Li",
        "Zhihui Cao",
        "Wenke Huang",
        "Yudong Zhang",
        "Keying Qi",
        "Rui Wang",
        "Zeyu Zheng",
        "Jian Zhao",
        "Hao Zhu",
        "Hengxin Wu",
        "Yuran Wang",
        "Guitao Fan",
        "Guokun Wu",
        "Yicong Liu",
        "Zhilin Gao",
        "Haikun Xu",
        "He Yang",
        "Minqi Xiang",
        "Xingyu Liu",
        "Zuojian Wang"
      ],
      "abstract": "Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.",
      "tldr_zh": "该研究提出了 MagicGUI-RMS，这是一个多智能体奖励模型系统 (Multi-Agent Reward Model System)，旨在解决图形用户界面 (GUI) 智能体在轨迹评估自动化和训练数据规模化生成方面存在的挑战。该系统通过集成领域特定奖励模型 (DS-RM) 与通用奖励模型 (GP-RM)，实现了精细的动作评估以及跨异构 GUI 任务的强大泛化性。研究还设计了一套结构化的数据构建流水线，能够自动生产平衡且多样化的奖励数据集，在维持样本保真度的同时有效降低了标注成本。在实际执行中，该奖励系统可识别错误动作并提供修正建议，通过自动化反馈回流 (Automated Feedback Reflux) 机制实现智能体行为的持续进化。实验证明，MagicGUI-RMS 在任务准确率和行为鲁棒性上均取得了显著提升。这一成果为构建受奖励驱动、具备自演进能力的 GUI 智能体提供了坚实且有效的技术基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13060v1",
      "published_date": "2026-01-19 13:50:43 UTC",
      "updated_date": "2026-01-19 13:50:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:30.763041+00:00"
    },
    {
      "arxiv_id": "2601.13054v1",
      "title": "TinyML-Enabled IoT for Sustainable Precision Irrigation",
      "title_zh": "TinyML 赋能的可持续精准灌溉物联网",
      "authors": [
        "Kamogelo Taueatsoala",
        "Caitlyn Daniels",
        "Angelina J. Ramsunar",
        "Petrus Bronkhorst",
        "Absalom E. Ezugwu"
      ],
      "abstract": "Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.",
      "tldr_zh": "该研究提出了一种基于 Tiny Machine Learning (TinyML) 的边缘优先 IoT 框架，旨在解决小规模耕作中的水资源短缺和缺乏廉价农业技术的问题。该系统采用四层架构，利用 ESP32 微控制器作为边缘推理节点，并结合 Raspberry Pi 作为本地边缘服务器，实现了不依赖云端的自主决策。框架集成了电容式土壤水分、温度、湿度、pH值和环境光传感器，用于全面的环境监测。通过对比分析，研究确定 Gradient Boosting 模型为最佳选择，其 R^2 分数达到 0.9973，Mean Absolute Percentage Error (MAPE) 低至 0.99%。优化后的模型作为轻量级推理引擎部署在 ESP32 上，并通过基于 MQTT 的局域网协议在无互联网连接的地区保持可靠运行。实验验证表明，该系统比传统方法显著减少了用水量，其低功耗设计和离线功能为资源受限的农村环境提供了可持续且可扩展的精准灌溉方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13054v1",
      "published_date": "2026-01-19 13:43:28 UTC",
      "updated_date": "2026-01-19 13:43:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:50.273083+00:00"
    },
    {
      "arxiv_id": "2601.13048v1",
      "title": "Analysis of Long Range Dependency Understanding in State Space Models",
      "title_zh": "状态空间模型对长程依赖理解能力的分析",
      "authors": [
        "Srividya Ravikumar",
        "Abhinav Anand",
        "Shweta Verma",
        "Mira Mezini"
      ],
      "abstract": "Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.",
      "tldr_zh": "该研究针对状态空间模型(SSMs)在长序列任务中表现优异但缺乏可解释性的现状，对在源代码漏洞检测这一真实任务上训练的对角化状态空间模型(S4D)进行了首次系统的内核(kernel)可解释性研究。通过对S4D内核进行深入的时域和频域分析，研究发现其长程建模能力在不同模型架构下存在显著差异，这直接影响了模型的最终性能。分析结果表明，根据架构配置的不同，S4D内核可以表现为低通(low-pass)、带通(band-pass)或高通(high-pass)滤波器。这些见解阐明了S4D处理长程依赖的内在机制，为未来设计和优化基于S4D的模型提供了重要的理论依据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13048v1",
      "published_date": "2026-01-19 13:39:42 UTC",
      "updated_date": "2026-01-19 13:39:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:55.477785+00:00"
    },
    {
      "arxiv_id": "2601.13020v1",
      "title": "PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning",
      "title_zh": "PASs-MoE：利用路径激活子空间缓解持续学习中路由与专家间的错位协同漂移",
      "authors": [
        "Zhiyan Hou",
        "Haiyun Guo",
        "Haokai Ma",
        "Yandu Sun",
        "Yonghui Yang",
        "Jinqiao Wang"
      ],
      "abstract": "Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.",
      "tldr_zh": "该研究针对多模态大语言模型(MLLMs)在持续指令微调(Continual Instruction Tuning, CIT)中面临的遗忘挑战，揭示了现有基于LoRA的混合专家模型(MoE)中存在的“Misaligned Co-drift”现象，即路由器偏好与专家自适应路径的失调会导致专家职责模糊并加剧遗忘。为此，作者提出了PASs-MoE方法，通过引入通路激活子空间(Pathway Activation Subspaces, PASs)构建了一个与能力对齐的路由与保存坐标系。该方案由PAS-guided Reweighting和PAS-aware Rank Stabilization两个关键组件组成，分别用于校准路由信号和稳定旧任务的关键秩方向。实验结果显示，PASs-MoE在不增加参数量的前提下，其准确率和抗遗忘性能均显著优于多种持续学习基准及MoE-LoRA变体。这一研究有效地缓解了路由与专家间的协同漂移问题，为实现高效且稳健的连续多模态学习提供了新方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13020v1",
      "published_date": "2026-01-19 12:57:11 UTC",
      "updated_date": "2026-01-19 12:57:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:53:47.221336+00:00"
    },
    {
      "arxiv_id": "2601.13018v1",
      "title": "Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context",
      "title_zh": "Bi-Attention HateXplain：多任务语境下兼顾数据序列特性的可解释性研究",
      "authors": [
        "Ghislain Dorian Tchuente Mondjo"
      ],
      "abstract": "Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.",
      "tldr_zh": "该研究针对在线社交网络中仇恨言论检测黑盒模型可靠性较低的问题，提出了一种名为 BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) 的多任务学习模型。针对现有 HateXplain 算法中预测注意力 (attention) 波动剧烈且不一致的缺陷，该模型利用 BiRNN 层在解释过程中充分考虑输入数据的序列性 (sequential aspect)。相较于结构复杂的 LLMs，该模型在追求透明度的场景下更具解释优势，能通过解释性与分类任务的联合学习来减少模型对特定社区的无意偏见 (unintentional bias)。实验结果表明，该方法在 HateXplain 数据集上显著提升了仇恨言论的检测性能和可解释性质量，同时有效降低了预测的不稳定性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at \"EAI AFRICOMM 2025 - 17th EAI International Conference on Communications and Networks in Africa\"",
      "pdf_url": "https://arxiv.org/pdf/2601.13018v1",
      "published_date": "2026-01-19 12:52:18 UTC",
      "updated_date": "2026-01-19 12:52:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:01.094536+00:00"
    },
    {
      "arxiv_id": "2601.13013v1",
      "title": "HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads",
      "title_zh": "HT-GNN：面向 Baidu Ads 客户生命周期价值预测的超时序图神经网络",
      "authors": [
        "Xiaohui Zhao",
        "Xinjian Zhao",
        "Jiahui Zhang",
        "Guoyu Liu",
        "Houzhi Wang",
        "Shu Wu"
      ],
      "abstract": "Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \\textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.",
      "tldr_zh": "该研究针对百度广告(Baidu Ads)中用户生命周期价值(Lifetime Value, LTV)预测的挑战，提出了超时间图神经网络(Hyper-Temporal Graph Neural Network, HT-GNN)，旨在解决人口统计分层导致的价值分布差异和动态营销策略引起的不规则行为序列问题。该模型由三个核心组件构成：一个用于捕捉用户分层间相互关系的超图监督模块(hypergraph-supervised module)，一个带有自适应加权的Transformer时间编码器(temporal encoder)，以及一个集成动态预测塔、用于多时间维度预测的任务自适应专家混合(task-adaptive mixture-of-experts, MoE)架构。实验在包含1500万用户的百度广告真实数据集上进行，结果表明HT-GNN在所有评估指标和预测周期上均显著优于现有的先进(state-of-the-art)方法。该框架通过共同建模人口统计异质性和时间动态，为广告平台的出价优化和预算分配提供了更精确的长期收益预测支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13013v1",
      "published_date": "2026-01-19 12:47:31 UTC",
      "updated_date": "2026-01-19 12:47:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:00.529272+00:00"
    },
    {
      "arxiv_id": "2601.13007v1",
      "title": "ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs",
      "title_zh": "ArchAgent：基于大语言模型的可扩展遗留软件架构恢复",
      "authors": [
        "Rusheng Pan",
        "Bingcheng Mao",
        "Tianyi Ma",
        "Zhenhua Ling"
      ],
      "abstract": "Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.",
      "tldr_zh": "针对大规模遗留软件架构恢复中的架构漂移、关系缺失及 LLMs 上下文受限问题，该研究提出了可扩展的智能体框架 ArchAgent。ArchAgent 结合了静态分析、自适应代码分段和由 LLMs 驱动的合成技术，旨在从跨仓库代码库中重建多视图且与业务对齐的软件架构。该框架引入了具备上下文剪枝的可扩展图表生成技术，并整合跨仓库数据以精准识别业务关键模块。在大规模 GitHub 项目上的评估结果显示，该方法在性能上显著超越了现有基准。消融研究表明，依赖关系上下文能有效提升生产级仓库架构生成的准确性。真实案例研究进一步证明了 ArchAgent 能够从复杂的遗留项目中成功恢复关键业务逻辑。此外，研究团队还公开了相关的 benchmark 数据集以供社区使用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "to be published in ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13007v1",
      "published_date": "2026-01-19 12:39:05 UTC",
      "updated_date": "2026-01-19 12:39:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:21.124249+00:00"
    },
    {
      "arxiv_id": "2601.12951v1",
      "title": "Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models",
      "title_zh": "超越准确性：刻画（大）语言模型的代码理解能力",
      "authors": [
        "Felix Mächtle",
        "Jan-Niclas Serr",
        "Nils Loose",
        "Thomas Eisenbarth"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在代码理解方面的能力，旨在揭示其性能是遵循传统的人类软件指标，还是反映了独特的非人类规律。为此研究者提出了一个诊断框架，将代码理解重新定义为二元输入输出一致性任务(binary input-output consistency task)，从而实现对分类和生成模型的综合评估。通过大规模数据集的分析，研究对比了模型表现与词汇量、控制流复杂度和抽象语法树(AST)结构等人类中心指标的相关性。实验结果显示，人类定义的指标与LLM的成功之间相关性极低（AUROC 0.63），而影子模型(shadow models)则能通过捕捉复杂的、部分可预测的模式实现更高的预测性能（AUROC 0.86）。这些发现表明，LLM的理解力反映了模型特有的规律，仅能部分被人类设计或学习到的特征所捕捉。该研究强调，未来的基准测试应超越简单的聚合准确率(aggregate accuracy)，转向更深层的实例级诊断。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Published in the Proceedings of DeepTest 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12951v1",
      "published_date": "2026-01-19 10:58:24 UTC",
      "updated_date": "2026-01-19 10:58:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:29.137875+00:00"
    },
    {
      "arxiv_id": "2601.12946v2",
      "title": "AI-generated data contamination erodes pathological variability and diagnostic reliability",
      "title_zh": "AI生成数据污染侵蚀病理多样性与诊断可靠性",
      "authors": [
        "Hongyu He",
        "Shaowen Xiang",
        "Ye Zhang",
        "Yingtao Zhu",
        "Jin Zhang",
        "Hao Deng",
        "Emily Alsentzer",
        "Qingyu Chen",
        "Kun-Hsing Yu",
        "Andrew Marshall",
        "Tingting Chen",
        "Srinivas Anumasa",
        "Daniel Ebner",
        "Dean Ho",
        "Kee Yuan Ngiam",
        "Ching-Yu Cheng",
        "Dianbo Liu"
      ],
      "abstract": "Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.",
      "tldr_zh": "该研究探讨了生成式人工智能 (Generative AI) 产生的数据污染对临床病理变异性和诊断可靠性的影响，揭示了模型在训练其自身生成数据时存在的反馈循环风险。通过分析超过 80万个涉及临床文本、视觉语言报告和医学图像合成的合成数据点，研究发现无论模型架构如何，模型都会逐渐向通用的表型收敛。关键的罕见病理发现如气胸 (pneumothorax) 和积液 (effusions) 在合成内容中逐渐消失，且人口统计学表现严重偏向中年男性。这种性能退化被虚假的诊断信心所掩盖，模型在无法检测出危及生命的病理时仍发布误导性的确信报告，导致虚假安全感率 (false reassurance rates) 飙升至 40%。经双盲医师评估确认，这种信心与准确性的脱节导致 AI 生成的文档在仅经过两个迭代周期后便失去了临床价值。研究进一步发现，虽然单纯扩大合成数据规模无法阻止系统崩溃，但将真实数据与质量感知过滤 (quality-aware filtering) 相结合能有效保留数据多样性。该结果表明，若缺乏政策强制的人类监督，生成式 AI 的部署将严重威胁医疗数据生态系统的可持续性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "*Corresponding author: Dianbo Liu (dianbo@nus.edu.sg)",
      "pdf_url": "https://arxiv.org/pdf/2601.12946v2",
      "published_date": "2026-01-19 10:54:03 UTC",
      "updated_date": "2026-01-21 11:06:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:11.187543+00:00"
    },
    {
      "arxiv_id": "2601.12939v1",
      "title": "Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design",
      "title_zh": "面向自适应无人机集群轨迹设计的主动推理驱动世界建模",
      "authors": [
        "Kaleem Arshid",
        "Ali Krayani",
        "Lucio Marcenaro",
        "David Martin Gomez",
        "Carlo Regazzoni"
      ],
      "abstract": "This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.",
      "tldr_zh": "本研究提出了一种基于主动推理 (Active Inference) 的无人机 (UAV) 集群自主轨迹设计框架，旨在实现分布式且自适应的群体控制。该方法通过集成概率推理与自我学习机制，统一解决了任务分配、路径排序和运动规划等关键问题。研究团队利用基于排斥力遗传算法 (GA-RF) 生成的专家轨迹来训练层次化世界模型 (World Model)，使其能够精准捕捉任务、路径及运动三个层级的集群行为特征。在实际在线运行中，无人机通过最小化当前信念与模型预测状态之间的散度来推断最优动作，从而灵活应对动态环境的变化。仿真实验证明，该框架在收敛速度、系统稳定性和导航安全性方面均优于 Q-Learning 算法。这一研究不仅展示了所提框架在智能无人机集群控制中的出色可扩展性，也为其提供了坚实的认知科学基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) Workshop: 'Multi-Modal Signal Processing and AI for Communications and Sensing in 6G and Beyond (MuSiC-6GB)'",
      "pdf_url": "https://arxiv.org/pdf/2601.12939v1",
      "published_date": "2026-01-19 10:47:26 UTC",
      "updated_date": "2026-01-19 10:47:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:37.774661+00:00"
    },
    {
      "arxiv_id": "2601.12938v1",
      "title": "The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality",
      "title_zh": "Post-Turing 状况：人工主体性与合成社会性的概念化",
      "authors": [
        "Thorsten Jelinek",
        "Patrick Glauner",
        "Alvin Wang Graylin",
        "Yubao Qiu"
      ],
      "abstract": "In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is therefore not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning. This work is a conceptual perspective that contributes a structural vocabulary for analyzing AI systems at the intersection of computation and society, without proposing a specific technical implementation.",
      "tldr_zh": "该研究探讨了后图灵时代（Post-Turing era）人工智能如何从单纯的自动化认知任务转向重塑社会协调与意义构建。作者指出核心挑战在于解释过程与共享参考的自动化可能导致人类在社会协作中被边缘化，并据此提出了PRMO框架，将AI设计轨迹与人类主体性的四个维度（感知Perception、表征Representation、意义Meaning和真实The Real）联系起来。研究进一步界定了合成社会性（Synthetic Sociality）的概念，描述了人工代理主要在彼此之间协商社会秩序并导致人类被排除在意义形成之外的风险。为了应对这一结构性风险，论文提出了四角定位（Quadrangulation）作为社会嵌入式AI系统的设计原则，要求人工代理在共享语境中将人类主体视为构成性参考。该工作为分析计算与社会交汇处的AI系统提供了结构性词汇和理论视角，具有重要的概念性贡献。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Conceptual perspective on AI design trajectories, meaning formation, and synthetic sociality. 5 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2601.12938v1",
      "published_date": "2026-01-19 10:46:52 UTC",
      "updated_date": "2026-01-19 10:46:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:23.819565+00:00"
    },
    {
      "arxiv_id": "2601.12937v1",
      "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
      "title_zh": "论版权审计中成员推理的证据局限性",
      "authors": [
        "Murat Bilgehan Ertan",
        "Emirhan Böge",
        "Min Chen",
        "Kaleel Mahmood",
        "Marten van Dijk"
      ],
      "abstract": "As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.",
      "tldr_zh": "该研究探讨了成员推理攻击(Membership Inference Attacks, MIAs)在版权审计中作为法律证据的局限性，特别是在模型开发者通过改写训练数据来规避审计的对抗性场景下。为此作者提出了SAGE(Structure-Aware SAE-Guided Extraction)框架，利用稀疏自编码器(Sparse Autoencoders, SAEs)指导文本改写，在改变词汇结构的同时保留语义内容。实验通过法官-原告-被告的通信协议进行评估，结果显示现有的先进MIAs在面对经SAGE处理并微调的模型时识别效果显著下降。这证明了MIAs的检测信号对于保留语义的变换缺乏鲁棒性，极易被对抗性手段所干扰。研究最终得出结论，认为MIAs在对抗环境下表现脆弱，目前不足以独立作为大语言模型(LLMs)版权审计的可靠技术标准。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12937v1",
      "published_date": "2026-01-19 10:46:51 UTC",
      "updated_date": "2026-01-19 10:46:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:55:15.883780+00:00"
    },
    {
      "arxiv_id": "2601.12931v1",
      "title": "Online Continual Learning for Time Series: a Natural Score-driven Approach",
      "title_zh": "时间序列在线持续学习：一种自然得分驱动的方法",
      "authors": [
        "Edoardo Urettini",
        "Daniele Atzeni",
        "Ioanna-Yvonni Tsaknaki",
        "Antonio Carta"
      ],
      "abstract": "Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.",
      "tldr_zh": "该研究探讨了在线持续学习(Online Continual Learning, OCL)在在线时间序列预测(Online Time Series Forecasting, OTSF)中的应用，旨在加强时间序列方法与OCL之间的理论和实践联系。作者将神经网络优化重新表述为参数滤波问题，证明了自然梯度下降(Natural Gradient Descent)是一种具有信息论最优性的得分驱动(Score-driven)方法。为了增强对异常值的鲁棒性，研究提出在自然梯度的基础上采用Student's t似然函数，从而诱导出有界的参数更新。论文由此引入了NatSR (Natural Score-driven Replay)框架，该框架结合了上述鲁棒优化器、重放缓冲区(Replay Buffer)以及一种能够提高机制漂移(Regime Drifts)时快速自适应能力的动态缩放启发式算法。实验结果表明，NatSR在预测性能上优于现有的复杂先进方法，为处理动态变化的时间序列数据提供了一种高效且具备理论支撑的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12931v1",
      "published_date": "2026-01-19 10:31:01 UTC",
      "updated_date": "2026-01-19 10:31:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:55:09.639486+00:00"
    },
    {
      "arxiv_id": "2601.12929v1",
      "title": "Membership Inference Test: Auditing Training Data in Object Classification Models",
      "title_zh": "成员推理测试：目标分类模型训练数据审计",
      "authors": [
        "Gonzalo Mancera",
        "Daniel DeAlcala",
        "Aythami Morales",
        "Ruben Tolosana",
        "Julian Fierrez"
      ],
      "abstract": "In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.",
      "tldr_zh": "该研究分析了 Membership Inference Tests (MINT) 在目标识别领域的表现，旨在通过审计手段确定特定数据是否被用于模型的训练阶段。研究团队提出并开发了专门为 MINT 模型设计的架构，利用卷积层 (convolutional layers) 来捕获和模拟训练过程中数据产生的激活模式 (activation patterns)。实验结合了目标检测模型、特征提取器 (embedding extractor) 和 MINT 模块，在包含超过 17.4 万张图像的三个公共数据库上进行了验证。结果显示，该架构在识别训练数据和测试数据方面达到了 70% 至 80% 的准确率，且具体性能取决于输入到 MINT 模块的检测层深度。此外，研究还深入分析了影响 MINT 模块的关键因素，为构建更透明、可审计的深度学习训练过程提供了技术解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Deployable AI (DAI 2025) workshop co-located with AAAI-25",
      "pdf_url": "https://arxiv.org/pdf/2601.12929v1",
      "published_date": "2026-01-19 10:30:53 UTC",
      "updated_date": "2026-01-19 10:30:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:59.166868+00:00"
    },
    {
      "arxiv_id": "2601.12925v1",
      "title": "ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation",
      "title_zh": "ForeDiffusion：通过未来视角构建实现预见性引导的机器人操作扩散策略",
      "authors": [
        "Weize Xie",
        "Yi Ding",
        "Ying He",
        "Leilei Wang",
        "Binwen Bai",
        "Zheyi Zhao",
        "Chenyang Wang",
        "F. Richard Yu"
      ],
      "abstract": "Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.",
      "tldr_zh": "该研究针对机器人操控任务提出了 ForeDiffusion，一种通过构建未来视图实现前瞻性条件的扩散策略。研究指出，现有的扩散策略因过度依赖短期观察且仅采用单一的 Denoising Loss，在复杂任务中容易出现误差累积和抓取偏差。ForeDiffusion 通过将预测的 Future View Representation 注入扩散过程，引导策略具备前瞻性，从而能够实时纠正轨迹偏差。此外，该框架引入了双重损失机制，将传统的去噪损失与未来观察的 Consistency Loss 相结合，实现了统一优化。在 Adroit 和 MetaWorld 基准测试中的实验结果表明，ForeDiffusion 在整体任务上达到了 80% 的平均成功率。在复杂任务中，该方法的表现优于现有主流扩散方法 23%，并在各类任务中展现出更强的性能稳定性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12925v1",
      "published_date": "2026-01-19 10:28:42 UTC",
      "updated_date": "2026-01-19 10:28:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:55:04.947407+00:00"
    },
    {
      "arxiv_id": "2601.12922v1",
      "title": "Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy",
      "title_zh": "你的隐私取决于他人：个体差分隐私中的合谋漏洞",
      "authors": [
        "Johannes Kaiser",
        "Alexander Ziller",
        "Eleni Triantafillou",
        "Daniel Rückert",
        "Georgios Kaissis"
      ],
      "abstract": "Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\\varepsilon_i,δ_i,\\overlineΔ)$-iDP a privacy contract that uses $Δ$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.",
      "tldr_zh": "该研究揭示了基于采样的个体差分隐私(Individual Differential Privacy, iDP)机制中一个此前被忽视的漏洞，即个体的隐私风险并不完全由其自身的隐私预算决定，而是关键性地依赖于所有其他数据贡献者的隐私选择。这种机制导致了个体隐私控制的承诺与由集体决定风险的现实之间存在偏差，特定的隐私偏好分布会在形式化保证得以满足的情况下，无意中增加个体的隐私风险。研究进一步证明，合谋的攻击者可以通过蓄意选择隐私预算，在完全符合差分隐私保证的前提下放大目标个体的漏洞，使其面临更严重的成员推理(Membership Inference)威胁。实证评估显示，这种攻击成功针对了62%的目标个体，显著提升了其隐私暴露风险。为了应对这一挑战，研究提出了一种名为$(\\varepsilon_i, \\delta_i, \\overline{\\Delta})$-iDP的隐私契约，通过引入$\\Delta$-divergences为用户的过度漏洞设定硬上限。这些发现要求学术界重新评估iDP系统的设计与部署，以确保隐私风险的透明度与可控性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12922v1",
      "published_date": "2026-01-19 10:26:12 UTC",
      "updated_date": "2026-01-19 10:26:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:54:59.946517+00:00"
    },
    {
      "arxiv_id": "2601.12913v1",
      "title": "Actionable Interpretability Must Be Defined in Terms of Symmetries",
      "title_zh": "必须基于对称性定义具有可操作性的可解释性",
      "authors": [
        "Pietro Barbiero",
        "Mateo Espinosa Zarlenga",
        "Francesco Giannini",
        "Alberto Termine",
        "Filippo Bonchi",
        "Mateja Jamnik",
        "Giuseppe Marra"
      ],
      "abstract": "This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.",
      "tldr_zh": "该研究指出人工智能领域的可解释性(interpretability)研究在本质上是不适定的，因为现有定义缺乏可操作性(actionable)，无法为具体的建模和推理规则提供正式原则。作者提出，一个具有可操作性的可解释性定义必须基于对称性(symmetries)来构建。研究假设四种对称性足以激发核心的可解释性属性，并以此界定可解释模型的类别。此外，该框架通过贝叶斯逆推(Bayesian inversion)的形式，推导出了包括对齐(alignment)、干预(interventions)和反事实推理(counterfactuals)在内的统一可解释推理公式。这项工作为可解释性研究提供了严谨的数学基础，使该领域从模糊的概念定义转向可推导的正式原则。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12913v1",
      "published_date": "2026-01-19 10:10:17 UTC",
      "updated_date": "2026-01-19 10:10:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:55:16.872935+00:00"
    },
    {
      "arxiv_id": "2601.12912v1",
      "title": "Human Emotion Verification by Action Languages via Answer Set Programming",
      "title_zh": "基于答案集程序设计通过动作语言进行的人类情感验证",
      "authors": [
        "Andreas Brännström",
        "Juan Carlos Nieves"
      ],
      "abstract": "In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "tldr_zh": "该研究提出了一种名为 C-MT (Mind Transition Language) 的动作语言，旨在通过观察到的动作序列来表征人类心理状态的演变过程。该语言建立在 Answer Set Programming (ASP) 和转换系统 (transition systems) 之上，并结合了心理学中的情绪评价理论 (Appraisal Theory of Emotion)，将情绪等心理状态形式化为多维配置。为了实现受控的智能体行为并限制动作产生的负面心理副作用，研究引入了名为 forbids to cause 的新型因果规则，以及专门针对心理状态动力学的表达方式。这些心理变化原则被转化为转换约束和不变性属性，并通过轨迹 (trajectories) 进行严格评估，从而实现了对人类心理状态动态演变的受控推理。此外，该框架支持通过分析遵循不同心理学原则的轨迹来比较不同的动力学变化，并最终应用于设计情绪验证 (emotion verification) 模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)",
      "pdf_url": "https://arxiv.org/pdf/2601.12912v1",
      "published_date": "2026-01-19 10:06:21 UTC",
      "updated_date": "2026-01-19 10:06:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:55:32.794650+00:00"
    },
    {
      "arxiv_id": "2601.12910v1",
      "title": "SciCoQA: Quality Assurance for Scientific Paper--Code Alignment",
      "title_zh": "SciCoQA：科学论文与代码对齐的质量保证",
      "authors": [
        "Tim Baumgärtner",
        "Iryna Gurevych"
      ],
      "abstract": "We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\\% of real-world paper-code discrepancies.",
      "tldr_zh": "该研究提出了 SciCoQA，一个旨在检测科学出版物与其代码库之间不一致性 (discrepancies) 的数据集，以确保科学实现的忠实性。该数据集通过结合 GitHub issues、可重复性研究论文以及一种自动化的合成数据生成 (synthetic data generation) 方法构建而成。SciCoQA 共包含 611 个论文-代码不一致案例，涵盖了人工智能 (AI)、物理学和定量生物学等多个计算科学领域。通过对 21 种大语言模型 (LLMs) 的评估发现，由于论文细节遗漏、长上下文输入 (long-context inputs) 等因素，该任务对现有模型具有极高挑战性。实验结果显示，性能最强的 GPT-5 模型也仅能识别 45.7% 的真实不一致案例，这表明在实现科学论文与代码对齐 (Paper--Code Alignment) 的质量保证方面仍有巨大提升空间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12910v1",
      "published_date": "2026-01-19 10:04:33 UTC",
      "updated_date": "2026-01-19 10:04:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:55:21.149212+00:00"
    },
    {
      "arxiv_id": "2601.12904v1",
      "title": "From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation",
      "title_zh": "从前缀缓存到融合 RAG 缓存：加速检索增强生成中的大语言模型推理",
      "authors": [
        "Jiahao Wang",
        "Weiyu Xie",
        "Mingxing Zhang",
        "Boxing Zhang",
        "Jianwei Dong",
        "Yuening Zhu",
        "Chen Lin",
        "Jinqi Tang",
        "Yaochen Han",
        "Zhiyuan Ai",
        "Xianglin Chen",
        "Yongwei Wu",
        "Congfeng Jiang"
      ],
      "abstract": "Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.",
      "tldr_zh": "该研究提出了 FusionRAG，这是一种旨在加速检索增强生成 (Retrieval-Augmented Generation) 推理过程的新型框架，有效解决了大语言模型在 RAG 场景下因 Prompt 过长导致的首字生成时间 (Time to First Token) 延迟问题。针对现有 KV cache 重用技术因缺失跨块上下文信息而导致生成质量大幅下降的缺陷，FusionRAG 通过优化离线预处理和在线重处理阶段实现了性能突破。在离线预处理阶段，该框架将相关文本块的信息嵌入到每个独立块中，而在在线重处理阶段，则仅对模型重点关注的 Token 重新计算 KV cache。实验表明，FusionRAG 在仅重计算不到 15% Token 的前提下，其归一化 F1 分数比现有 state-of-the-art 方案高出 70%，且相比 Full Attention 可实现 2.66x 到 9.39x 的 TTFT 加速。该研究成功在生成质量与推理效率之间达成了更优的权衡，为高效 RAG 推理提供了新的解决路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12904v1",
      "published_date": "2026-01-19 09:59:39 UTC",
      "updated_date": "2026-01-19 09:59:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:03.772149+00:00"
    },
    {
      "arxiv_id": "2601.12893v1",
      "title": "AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs",
      "title_zh": "AdaNODEs：基于神经常微分方程的时间序列预测测试时自适应",
      "authors": [
        "Ting Dang",
        "Soumyajit Chatterjee",
        "Hong Jia",
        "Yu Wu",
        "Flora Salim",
        "Fahim Kawsar"
      ],
      "abstract": "Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\\% and 28.4\\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.",
      "tldr_zh": "该研究提出了AdaNODEs，一种专门为时间序列预测设计的source-free Test Time Adaptation (TTA) 方法。针对现有TTA方法往往忽略时间序列特性且较少涉及预测任务的问题，AdaNODEs利用Neural Ordinary Differential Equations (NODEs) 构建了一个创新的自适应框架，以有效应对时间序列数据中独特的分布偏移 (distribution shifts)。此外，论文创新地提出了一种新的损失函数，旨在解决预测任务中的TTA难题。AdaNODEs仅需更新有限的模型参数，在有效捕获时间依赖性的同时显著降低了内存开销。实验结果显示，该方法在单维和高维数据上分别比SOTA基准提升了5.88%和28.4%，尤其在严重的分布偏移环境下展现出卓越的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12893v1",
      "published_date": "2026-01-19 09:46:54 UTC",
      "updated_date": "2026-01-19 09:46:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:55:26.840354+00:00"
    },
    {
      "arxiv_id": "2601.12886v1",
      "title": "Communication Methods in Multi-Agent Reinforcement Learning",
      "title_zh": "多智能体强化学习中的通信方法",
      "authors": [
        "Christoph Wittner"
      ],
      "abstract": "Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.",
      "tldr_zh": "该研究对多智能体强化学习(Multi-Agent Reinforcement Learning, MARL)中的通信技术进行了全面综述，旨在探讨如何通过通信解决部分可观测环境、非平稳性和动作空间指数级增长等挑战。通过对29篇相关文献的深入分析，论文评估了显式(explicit)、隐式(implicit)、基于注意力机制(attention-based)、基于图结构(graph-based)以及基于层次/角色(hierarchical/role-based)的通信方法的优缺点。研究发现，目前不存在适用于所有问题的通用最优通信框架，通信方式的选择高度依赖于具体的应用场景。同时，该工作强调了低计算开销通信方法对于提升多智能体系统可扩展性的重要性。最后，论文指出了当前在系统级指标标准化基准测试以及现实通信条件下鲁棒性方面的研究空白，为提升MARL算法的实际应用价值提供了参考。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "12 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12886v1",
      "published_date": "2026-01-19 09:39:00 UTC",
      "updated_date": "2026-01-19 09:39:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:27.935358+00:00"
    },
    {
      "arxiv_id": "2601.12882v1",
      "title": "YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection",
      "title_zh": "YOLO26：无 NMS 端到端实时目标检测框架分析",
      "authors": [
        "Sudip Chakrabarty"
      ],
      "abstract": "The \"You Only Look Once\" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.",
      "tldr_zh": "该研究分析了 YOLO26 这一端到端实时目标检测框架，旨在解决传统 YOLO 系列因 Non-Maximum Suppression (NMS) 后处理导致的延迟及超参数敏感性问题。YOLO26 通过消除 NMS 并采用原生端到端学习策略，引入了用于稳定轻量化主干网络的 MuSGD 优化器、提升小目标感知能力的 STAL 标签分配机制以及动态监督的 ProgLoss 损失函数。性能评估表明，YOLO26 在推理速度和检测精度上均创造了新的 Pareto front，显著优于 RTMDet、DAMO-YOLO 等先进模型及前代 YOLO 版本。该研究证实，通过将表示学习与启发式后处理解耦，YOLO26 成功克服了延迟与精度之间的权衡，为边缘计算场景下的计算机视觉演进提供了重要路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12882v1",
      "published_date": "2026-01-19 09:36:08 UTC",
      "updated_date": "2026-01-19 09:36:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:57:02.619159+00:00"
    },
    {
      "arxiv_id": "2601.12879v1",
      "title": "Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition",
      "title_zh": "基于可扩展归因图分解的十亿参数级语言模型层级稀疏电路提取",
      "authors": [
        "Mohammed Mudassir Uddin",
        "Shahnawaz Alam",
        "Mohammed Kaif Pasha"
      ],
      "abstract": "Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\\pm$2.3\\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.",
      "tldr_zh": "该研究提出了 Hierarchical Attribution Graph Decomposition (HAGD) 框架，旨在解决从十亿参数级大语言模型中提取稀疏计算电路 (Sparse Circuits) 时面临的指数级搜索复杂度和多语义性 (Polysemanticity) 挑战。通过引入多分辨率抽象层次和可微分电路搜索，该框架成功将电路发现的复杂度从 $O(2^n)$ 降低至 $O(n^2 \\log n)$。该方法整合了 Cross-layer Transcoders 用于单语义特征提取，并结合图神经网络元学习与因果干预协议 (Causal Intervention Protocols) 进行拓扑预测与验证。在针对 GPT-2、Llama-7B 到 Llama-70B 以及 Pythia 系列模型的评估中，该框架在模运算任务上实现了高达 91% 的行为保留，且保持了极具解释性的子图规模。跨架构实验表明，不同模型家族间发现的电路具有约 67% 的结构相似性，暗示了模型间可能存在共享的计算模式。该成果为大规模模型的 Mechanistic Interpretability 研究奠定了重要基础，并指出了现有归因方法的局限性与未来改进方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12879v1",
      "published_date": "2026-01-19 09:34:10 UTC",
      "updated_date": "2026-01-19 09:34:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:42.161088+00:00"
    },
    {
      "arxiv_id": "2601.14311v1",
      "title": "Tracing the Data Trail: A Survey of Data Provenance, Transparency and Traceability in LLMs",
      "title_zh": "追踪数据轨迹：LLMs 数据溯源、透明度与可追溯性综述",
      "authors": [
        "Richard Hohensinner",
        "Belgin Mutlu",
        "Inti Gabriel Mendoza Estrada",
        "Matej Vukovic",
        "Simone Kopeinik",
        "Roman Kern"
      ],
      "abstract": "Large language models (LLMs) are deployed at scale, yet their training data life cycle remains opaque. This survey synthesizes research from the past ten years on three tightly coupled axes: (1) data provenance, (2) transparency, and (3) traceability, and three supporting pillars: (4) bias \\& uncertainty, (5) data privacy, and (6) tools and techniques that operationalize them. A central contribution is a proposed taxonomy defining the field's domains and listing corresponding artifacts. Through analysis of 95 publications, this work identifies key methodologies concerning data generation, watermarking, bias measurement, data curation, data privacy, and the inherent trade-off between transparency and opacity.",
      "tldr_zh": "该综述研究了过去十年中大型语言模型 (LLMs) 训练数据生命周期的不透明性问题，重点围绕数据来源 (Data Provenance)、透明度 (Transparency) 和可追溯性 (Traceability) 三个相互关联的维度展开。研究提出了一个定义该领域范畴的分类法 (Taxonomy) 及其对应的工件，并探讨了偏见与不确定性 (Bias & Uncertainty) 和数据隐私 (Data Privacy) 等支撑支柱。通过对95篇学术文献的深度分析，本文总结了数据生成、水印技术 (Watermarking)、偏见测量及数据管理等关键方法论。研究不仅识别了实现数据透明度的具体工具，还揭示了透明度与不透明性之间存在的内在权衡。该综述为建立更具透明度和可追溯性的 LLMs 提供了系统性的理论框架和实践指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "35 pages, 6 figures. Manuscript submitted to ACM Computing Surveys (CSUR) on the 12th of December 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.14311v1",
      "published_date": "2026-01-19 09:14:00 UTC",
      "updated_date": "2026-01-19 09:14:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:31.108948+00:00"
    },
    {
      "arxiv_id": "2601.12856v1",
      "title": "Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data",
      "title_zh": "基于公开网络数据热点动态的 Singapore 全市登革热传播模式挖掘",
      "authors": [
        "Liping Huang",
        "Gaoxi Xiao",
        "Stefan Ma",
        "Hechang Chen",
        "Shisong Tang",
        "Flora Salim"
      ],
      "abstract": "Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.",
      "tldr_zh": "这项研究针对新加坡等热带城市地区的Dengue传播挑战，提出了一个通过公开网络数据挖掘区域间潜在传播链路的新型框架。该框架不再将病例视为孤立报告，而是利用Gradient Descent优化隐藏的传播网络，模拟不同区域间Hotspot形成的相互影响。研究发现学习到的传播网络与人群通勤流(commuting flows)高度一致，为城市范围内的疫情扩散提供了具有解释性的依据。实验结果显示，在新加坡2013-2018年及2020年的数据集上，该模型仅需四周的Hotspot历史记录即可达到0.79的平均F-score。这项工作通过验证和挖掘隐藏的流行病传播动态，成功将开放的网络数据转化为具有高度预测价值的资源。该框架不仅推进了流行病建模技术，还为公共卫生部门提供了一种低成本且高效的决策支持工具，助力提升城市应对传染病的能力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 9 figures. It's accepted by WWW 2026 Web4Good Track. To make accessible earlier, authors would like to put it on arxiv before the conference",
      "pdf_url": "https://arxiv.org/pdf/2601.12856v1",
      "published_date": "2026-01-19 09:10:50 UTC",
      "updated_date": "2026-01-19 09:10:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:39.104758+00:00"
    },
    {
      "arxiv_id": "2601.12849v1",
      "title": "The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items",
      "title_zh": "EFX 的代价：少量盈余物品情形下的广义均值福利与复杂度二分性",
      "authors": [
        "Eugene Lim",
        "Tzeh Yuan Neoh",
        "Nicholas Teh"
      ],
      "abstract": "Envy-freeness up to any good (EFX) is a central fairness notion for allocating indivisible goods, yet its existence is unresolved in general. In the setting with few surplus items, where the number of goods exceeds the number of agents by a small constant (at most three), EFX allocations are guaranteed to exist, shifting the focus from existence to efficiency and computation. We study how EFX interacts with generalized-mean ($p$-mean) welfare, which subsumes commonly-studied utilitarian ($p=1$), Nash ($p=0$), and egalitarian ($p \\rightarrow -\\infty$) objectives. We establish sharp complexity dichotomies at $p=0$: for any fixed $p \\in (0,1]$, both deciding whether EFX can attain the global $p$-mean optimum and computing an EFX allocation maximizing $p$-mean welfare are NP-hard, even with at most three surplus goods; in contrast, for any fixed $p \\leq 0$, we give polynomial-time algorithms that optimize $p$-mean welfare within the space of EFX allocations and efficiently certify when EFX attains the global optimum. We further quantify the welfare loss of enforcing EFX via the price of fairness framework, showing that for $p > 0$, the loss can grow linearly with the number of agents, whereas for $p \\leq 0$, it is bounded by a constant depending on the surplus (and for Nash welfare it vanishes asymptotically). Finally we show that requiring Pareto-optimality alongside EFX is NP-hard (and becomes $Σ_2^P$-complete for a stronger variant of EFX). Overall, our results delineate when EFX is computationally costly versus structurally aligned with welfare maximization in the setting with few surplus items.",
      "tldr_zh": "该研究探讨了在剩余物品较少（物品数量超出代理人数量不超过三个）的情境下，公平分配核心概念 EFX (Envy-freeness up to any good) 与广义均值福利 ($p$-mean welfare) 之间的相互作用及其计算复杂性。研究建立了一个以 $p=0$ 为界限的清晰复杂性二分法 (complexity dichotomies)，发现在 $p \\in (0,1]$ 时，判定或计算最大化 $p$-mean welfare 的 EFX 分配均属于 NP-hard。而对于 $p \\leq 0$ 的情况，研究提出了多项式时间算法，能够在 EFX 约束空间内优化福利并有效验证其全局最优性。通过公平代价 (price of fairness) 框架，研究进一步量化了强制执行 EFX 导致的福利损失，证明了当 $p \\leq 0$ 时损失被限制在常数范围内，而 $p > 0$ 时损失则随代理人数量线性增长。此外，研究还证明了同时满足 Pareto-optimality 与 EFX 在计算上是 NP-hard 的。该成果明确了在少量剩余物品设置中，EFX 的计算成本及其与社会福利最大化目标在结构上的契合程度。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12849v1",
      "published_date": "2026-01-19 09:02:32 UTC",
      "updated_date": "2026-01-19 09:02:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:42.943713+00:00"
    },
    {
      "arxiv_id": "2601.12842v1",
      "title": "SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning",
      "title_zh": "SCULPT：开辟高效数学推理路径的约束引导型剪枝 MCTS",
      "authors": [
        "Qitong Fang",
        "Haotian Li",
        "Xu Wang"
      ],
      "abstract": "Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.",
      "tldr_zh": "该研究针对大语言模型（LLMs）在自动化代理工作流中由于缺乏领域先验知识，导致搜索策略往往陷入随机探索和无效分支的问题。为此，作者提出了 SCULPT，一种融入领域感知评分的约束引导型蒙特卡洛树搜索（Monte Carlo Tree Search, MCTS）方法。该方法在选择、扩展、模拟和回传阶段集成领域约束，利用符号检查（如 dimensional consistency, type compatibility, magnitude sanity, depth control 和 diversity）以及结构模式引导对动作进行评分与剪枝。通过这种方式，SCULPT 能够有效剔除不合理的推理路径，使搜索过程更加有序且贴近真实逻辑。在多种数据集上的实验结果表明，SCULPT 在相同 LLM 配置下实现了稳定的性能提升，并验证了其在前沿推理模型上的有效性。总体而言，SCULPT 证明了引入领域感知约束可以在保持推理稳定性的同时，显著提高数学推理任务的准确率与效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures. Equal contribution: Qitong Fang and Haotian Li. Corresponding authors: Qitong Fang (fangqitong@student.jlju.edu.cn), Haotian Li (lihaotian@student.jlju.edu.cn), Xu Wang (wangxu@jlju.edu.cn)",
      "pdf_url": "https://arxiv.org/pdf/2601.12842v1",
      "published_date": "2026-01-19 08:55:46 UTC",
      "updated_date": "2026-01-19 08:55:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:57:11.122362+00:00"
    },
    {
      "arxiv_id": "2601.12837v1",
      "title": "Cognition spaces: natural, artificial, and hybrid",
      "title_zh": "认知空间：自然、人工与混合",
      "authors": [
        "Ricard Solé",
        "Luis F Seoane",
        "Jordi Pla-Mauri",
        "Michael Timothy Bennett",
        "Michael E. Hochberg",
        "Michael Levin"
      ],
      "abstract": "Cognitive processes are realized across an extraordinary range of natural, artificial, and hybrid systems, yet there is no unified framework for comparing their forms, limits, and unrealized possibilities. Here, we propose a cognition space approach that replaces narrow, substrate-dependent definitions with a comparative representation based on organizational and informational dimensions. Within this framework, cognition is treated as a graded capacity to sense, process, and act upon information, allowing systems as diverse as cells, brains, artificial agents, and human-AI collectives to be analyzed within a common conceptual landscape. We introduce and examine three cognition spaces -- basal aneural, neural, and human-AI hybrid -- and show that their occupation is highly uneven, with clusters of realized systems separated by large unoccupied regions. We argue that these voids are not accidental but reflect evolutionary contingencies, physical constraints, and design limitations. By focusing on the structure of cognition spaces rather than on categorical definitions, this approach clarifies the diversity of existing cognitive systems and highlights hybrid cognition as a promising frontier for exploring novel forms of complexity beyond those produced by biological evolution.",
      "tldr_zh": "该研究提出了认知空间 (cognition spaces) 框架，旨在为自然、人工及混合系统的认知过程提供统一的比较分析基础。该框架通过组织 (organizational) 和信息 (informational) 维度取代了传统的依赖于生物载体的定义，将认知视为一种感应、处理信息并根据信息采取行动的等级化能力。通过对基础非神经 (basal aneural)、神经 (neural) 以及人类-AI混合 (human-AI hybrid) 三种认知空间的考察，研究发现现有认知系统的分布呈现出显著的不均匀性。这些系统往往聚集在特定区域，而由演化偶然性、物理约束和设计限制导致的巨大空白区域则预示了未被探索的可能性。该研究强调，关注认知空间的结构而非类别定义，能够有效揭示混合认知 (hybrid cognition) 在创造超越生物演化限制的新型复杂形式方面的巨大潜力。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.HC",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12837v1",
      "published_date": "2026-01-19 08:50:18 UTC",
      "updated_date": "2026-01-19 08:50:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:54.564067+00:00"
    },
    {
      "arxiv_id": "2601.12822v1",
      "title": "MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction",
      "title_zh": "MirrorGuard：通过“从模拟到现实”推理修正构建安全计算机使用智能体",
      "authors": [
        "Wenqi Zhang",
        "Yulin Shen",
        "Changyue Jiang",
        "Jiarun Dai",
        "Geng Hong",
        "Xudong Pan"
      ],
      "abstract": "Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.",
      "tldr_zh": "该研究针对 Computer Use Agents (CUAs) 在与操作系统交互时面临的恶意指令或视觉提示注入等安全风险，提出了 MirrorGuard 防御框架。现有的基于检测的防御手段往往通过提前终止任务来防止损害，但这显著降低了智能体的可用性。MirrorGuard 采用了一种即插即用的 Simulation-to-Real 推理纠正方法，通过一种新型的 Neural-symbolic Simulation Pipeline 在纯文本模拟环境中生成高风险的 GUI 交互轨迹。该模拟过程能够在不执行实际操作的情况下捕捉不安全的 Reasoning Patterns，并训练 MirrorGuard 在智能体产生动作前拦截并纠正其 Reasoning Chains。在真实环境测试中，MirrorGuard 显著降低了安全风险，例如在 ByteDance UI-TARS 系统上将不安全率从 66.5% 降至 13.0%，且保持了极低的 False Refusal Rate (FRR)。相比于目前的先进模型 GuardAgent，MirrorGuard 在安全性和可用性之间取得了更好的平衡，证明了模拟驱动的防御机制能为现实世界的智能体提供稳健的保护。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12822v1",
      "published_date": "2026-01-19 08:32:09 UTC",
      "updated_date": "2026-01-19 08:32:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:58.744936+00:00"
    },
    {
      "arxiv_id": "2601.12816v1",
      "title": "Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning",
      "title_zh": "面向持续学习的 Fisher 正交投影自然梯度下降",
      "authors": [
        "Ishir Garg",
        "Neel Kolhe",
        "Andy Peng",
        "Rohan Gopalam"
      ],
      "abstract": "Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.",
      "tldr_zh": "该研究针对持续学习(Continual learning)中神经网络在获取新知识时面临的灾难性遗忘(catastrophic forgetting)挑战，提出了一种名为Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG)的优化器。FOPNG通过在参数更新上施加Fisher正交约束(Fisher-orthogonal constraints)，将梯度投影到先前任务梯度的Fisher正交补空间中，旨在学习新任务的同时保留旧任务性能。该方法在信息几何框架下成功将自然梯度下降(Natural Gradient Descent)与正交梯度方法相统一，确保更新方向在重参数化下具有不变性，并保证了在Fisher度量下的下降。通过使用对角Fisher(diagonal Fisher)实现的优化方案既高效又实用，能有效维持先前任务的输出结果。实验表明，FOPNG在Permuted-MNIST、Split-MNIST、Rotated-MNIST以及Split-CIFAR10/100等标准持续学习基准测试中均展现出强大的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12816v1",
      "published_date": "2026-01-19 08:23:12 UTC",
      "updated_date": "2026-01-19 08:23:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:56:56.190586+00:00"
    },
    {
      "arxiv_id": "2601.12809v1",
      "title": "Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data",
      "title_zh": "基于合成空间关系数据训练的 CLIP 式视觉-语言模型中的左右对称性破缺",
      "authors": [
        "Takaki Yamamoto",
        "Chihiro Noguchi",
        "Toshihiro Tanizawa"
      ],
      "abstract": "Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.",
      "tldr_zh": "该研究利用一个可控的 1D 图像-文本实验平台，深入探讨了 CLIP-style 视觉语言模型如何习得左右空间关系的理解机制。通过在单物体和双物体场景的配对描述上训练轻量级 Transformer 编码器，研究发现对比学习(Contrastive training)能够有效捕获左右关系，且标签多样性(label diversity)比布局多样性(layout diversity)更能驱动模型在未见物体对上的泛化。通过注意力分解(attention decomposition)，研究揭示了位置嵌入(positional embeddings)与标记嵌入(token embeddings)的交互会诱导出一种打破左右对称性的水平注意力梯度。消融实验进一步证实，这种对称性打破是模型具备左右辨别能力的关键。该成果为理解 CLIP-style 模型获得关系能力的时间和方式提供了重要的机械性见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12809v1",
      "published_date": "2026-01-19 08:16:11 UTC",
      "updated_date": "2026-01-19 08:16:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:03.610463+00:00"
    },
    {
      "arxiv_id": "2601.14310v1",
      "title": "CORVUS: Red-Teaming Hallucination Detectors via Internal Signal Camouflage in Large Language Models",
      "title_zh": "CORVUS：基于大语言模型内部信号伪装的幻觉检测器红队测试",
      "authors": [
        "Nay Myat Min",
        "Long H. Pham",
        "Hongyu Zhang",
        "Jun Sun"
      ],
      "abstract": "Single-pass hallucination detectors rely on internal telemetry (e.g., uncertainty, hidden-state geometry, and attention) of large language models, implicitly assuming hallucinations leave separable traces in these signals. We study a white-box, model-side adversary that fine-tunes lightweight LoRA adapters on the model while keeping the detector fixed, and introduce CORVUS, an efficient red-teaming procedure that learns to camouflage detector-visible telemetry under teacher forcing, including an embedding-space FGSM attention stress test. Trained on 1,000 out-of-distribution Alpaca instructions (<0.5% trainable parameters), CORVUS transfers to FAVA-Annotation across Llama-2, Vicuna, Llama-3, and Qwen2.5, and degrades both training-free detectors (e.g., LLM-Check) and probe-based detectors (e.g., SEP, ICR-probe), motivating adversary-aware auditing that incorporates external grounding or cross-model evidence.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)幻觉检测器的安全性，特别是针对依赖模型内部遥测信号（如不确定性、隐藏状态几何和注意力）的单次通过检测器。作者提出了一种名为CORVUS的高效红队测试程序，通过在模型端微调轻量级的LoRA适配器，使其在教师强制(Teacher Forcing)下学习伪装检测器可见的内部信号。该方法引入了嵌入空间的FGSM注意力压力测试，仅需在1,000条分布外指令上进行少量参数训练。实验结果显示，CORVUS在Llama-2、Llama-3和Qwen2.5等多个模型上表现出强迁移性，能显著降低包括LLM-Check在内的无训练检测器以及SEP、ICR-probe等探测器型检测器的效能。这项研究证明了仅依赖内部信号进行幻觉检测的脆弱性，并强调了在未来审计中引入外部验证(External Grounding)或跨模型证据的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2601.14310v1",
      "published_date": "2026-01-19 08:07:03 UTC",
      "updated_date": "2026-01-19 08:07:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:01.060568+00:00"
    },
    {
      "arxiv_id": "2601.12805v2",
      "title": "SciHorizon-GENE: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding",
      "title_zh": "SciHorizon-GENE：从基因知识到功能理解的生命科学大语言模型推理基准测试",
      "authors": [
        "Xiaohan Huang",
        "Meng Xiao",
        "Chuan Qin",
        "Qingqing Long",
        "Jinmiao Chen",
        "Yuanchun Zhou",
        "Hengshu Zhu"
      ],
      "abstract": "Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-GENE, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark integrates curated knowledge for over 190K human genes and comprises more than 540K questions covering diverse gene-to-function reasoning scenarios relevant to cell type annotation, functional interpretation, and mechanism-oriented analysis. Motivated by behavioral patterns observed in preliminary examinations, SciHorizon-GENE evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation.",
      "tldr_zh": "该研究提出了 SciHorizon-GENE，这是一个大规模以基因为中心的基准测试(Benchmark)，旨在评估大语言模型(LLMs)从基因层面知识到功能理解的推理能力，填补了知识增强型细胞图谱解读领域的空白。该基准整合了超过 190K 个人类基因的权威知识，包含超过 540K 个涵盖细胞类型标注、功能解读和机制分析的推理问题。SciHorizon-GENE 特别关注四个生物学关键维度：研究关注度敏感性(Research attention sensitivity)、幻觉倾向(Hallucination tendency)、答案完整性(Answer completeness)和文献影响力(Literature influence)，旨在识别限制 LLMs 安全应用于生物解读流程的失效模式。通过对多种通用及生物医学领域 LLMs 的系统评估，研究发现模型在基因水平的推理能力表现出显著的异质性。实验结果表明，在生成忠实、完整且基于文献的功能解读方面，当前模型仍面临持续挑战，该基准为基因尺度的模型行为分析及模型开发提供了系统性的参考依据。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.GN",
      "comment": "16 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.12805v2",
      "published_date": "2026-01-19 08:06:35 UTC",
      "updated_date": "2026-01-21 05:31:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:57:34.813994+00:00"
    },
    {
      "arxiv_id": "2601.12804v1",
      "title": "SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability",
      "title_zh": "SL-CBM：通过语义局部性增强概念瓶颈模型的可解释性",
      "authors": [
        "Hanwei Zhang",
        "Luo Cheng",
        "Rui Wen",
        "Yang Zhang",
        "Lijun Zhang",
        "Holger Hermanns"
      ],
      "abstract": "Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.",
      "tldr_zh": "该研究提出了SL-CBM，这是一种增强语义局部性的Concept Bottleneck Models (CBMs)扩展模型，旨在解决现有CBMs在概念与图像区域空间对齐方面存在的局部忠实度(Locality Faithfulness)不足的问题。SL-CBM通过集成1x1卷积层与交叉注意力(Cross-attention)机制，在概念和类别层面生成空间相干的显著性图(Saliency Maps)，从而强化了概念、图像区域与最终预测之间的对齐。与先前方法相比，SL-CBM生成的显著性图与模型的内部推理过程紧密结合，显著提升了模型的可调试性和干预效果。实验结果表明，该模型在保持分类准确率的同时，大幅优化了解释质量和干预效能。研究还通过消融实验验证了对比(Contrastive)和基于熵(Entropy)的正规化在平衡模型准确率、稀疏性与忠实度方面的关键作用。总体而言，SL-CBM填补了概念推理与空间可解释性之间的空白，为构建透明且可信的机器学习系统提供了重要支撑。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12804v1",
      "published_date": "2026-01-19 08:05:28 UTC",
      "updated_date": "2026-01-19 08:05:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:57:40.403100+00:00"
    },
    {
      "arxiv_id": "2601.15326v1",
      "title": "ECGomics: An Open Platform for AI-ECG Digital Biomarker Discovery",
      "title_zh": "ECGomics：AI-ECG 数字生物标志物发现开放平台",
      "authors": [
        "Deyun Zhang",
        "Jun Li",
        "Shijia Geng",
        "Yue Wang",
        "Shijie Chen",
        "Sumei Fan",
        "Qinghao Zha",
        "Shenda Hong"
      ],
      "abstract": "Background: Conventional electrocardiogram (ECG) analysis faces a persistent dichotomy: expert-driven features ensure interpretability but lack sensitivity to latent patterns, while deep learning offers high accuracy but functions as a black box with high data dependency. We introduce ECGomics, a systematic paradigm and open-source platform for the multidimensional deconstruction of cardiac signals into digital biomarker. Methods: Inspired by the taxonomic rigor of genomics, ECGomics deconstructs cardiac activity across four dimensions: Structural, Intensity, Functional, and Comparative. This taxonomy synergizes expert-defined morphological rules with data-driven latent representations, effectively bridging the gap between handcrafted features and deep learning embeddings. Results: We operationalized this framework into a scalable ecosystem consisting of a web-based research platform and a mobile-integrated solution (https://github.com/PKUDigitalHealth/ECGomics). The web platform facilitates high-throughput analysis via precision parameter configuration, high-fidelity data ingestion, and 12-lead visualization, allowing for the systematic extraction of biomarkers across the four ECGomics dimensions. Complementarily, the mobile interface, integrated with portable sensors and a cloud-based engine, enables real-time signal acquisition and near-instantaneous delivery of structured diagnostic reports. This dual-interface architecture successfully transitions ECGomics from theoretical discovery to decentralized, real-world health management, ensuring professional-grade monitoring in diverse clinical and home-based settings. Conclusion: ECGomics harmonizes diagnostic precision, interpretability, and data efficiency. By providing a deployable software ecosystem, this paradigm establishes a robust foundation for digital biomarker discovery and personalized cardiovascular medicine.",
      "tldr_zh": "该研究提出了 ECGomics，这是一个旨在发现 AI-ECG 数字生物标志物 (Digital Biomarker) 的开源平台和系统化范式。为了解决传统专家驱动特征与深度学习黑箱模型之间的矛盾，ECGomics 借鉴基因组学的分类学严谨性，从结构 (Structural)、强度 (Intensity)、功能 (Functional) 和比较 (Comparative) 四个维度对心脏信号进行多维解构。该框架通过协同专家定义的形态规则与数据驱动的潜在表示，实现了手工特征与深度学习嵌入 (Deep Learning Embeddings) 的有效桥接。研究团队开发了包含 Web 研究平台和移动集成方案的可扩展生态系统，支持高通量分析、实时信号采集以及结构化诊断报告的即时交付。ECGomics 成功将心电图分析从理论发现转化为去中心化的现实健康管理，在确保专业级监测的同时兼顾了诊断精度、可解释性和数据效率，为个性化心血管医学研究奠定了坚实基础。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15326v1",
      "published_date": "2026-01-19 07:55:23 UTC",
      "updated_date": "2026-01-19 07:55:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:57:56.466775+00:00"
    },
    {
      "arxiv_id": "2601.12785v1",
      "title": "Distilling Time Series Foundation Models for Efficient Forecasting",
      "title_zh": "面向高效预测的时间序列基础模型蒸馏",
      "authors": [
        "Yuqi Li",
        "Kuiye Ding",
        "Chuanguang Yang",
        "Szu-Yu Chen",
        "Yingli Tian"
      ],
      "abstract": "Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.",
      "tldr_zh": "该研究提出了DistilTS，这是首个专门针对时间序列基础模型(TSFMs)设计的知识蒸馏框架，旨在解决大模型在实际部署中面临的高昂计算成本问题。针对时间序列预测中特有的任务难度差异(task difficulty discrepancy)以及通用的架构差异(architecture discrepancy)这两大挑战，DistilTS引入了时界权重目标(horizon-weighted objectives)以平衡长短期预测任务的学习强度，并结合时间对齐策略(temporal alignment strategy)来缩小教师模型与学生模型间的架构鸿沟。多项基准测试实验证明，DistilTS能在仅使用原模型1/150参数量的情况下，实现与全规模TSFMs相当的预测精度。此外，该框架将推理速度提升了多达6000倍，为实现高效且紧凑的时间序列预测模型提供了全新的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICASSP-2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12785v1",
      "published_date": "2026-01-19 07:32:00 UTC",
      "updated_date": "2026-01-19 07:32:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:57:58.878309+00:00"
    },
    {
      "arxiv_id": "2601.12781v1",
      "title": "VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension",
      "title_zh": "VIRO：面向指代表达理解的稳健高效验证式神经符号推理",
      "authors": [
        "Hyejin Park",
        "Junhyuk Kwon",
        "Suha Kwak",
        "Jungseul Ok"
      ],
      "abstract": "Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.",
      "tldr_zh": "该研究针对 Referring Expression Comprehension (REC) 任务提出了 VIRO 框架，旨在解决现有 neuro-symbolic 方法中因假设中间推理步骤准确而导致的级联错误和高置信度 false positives 问题。VIRO (Verification-Integrated Reasoning Operators) 通过在推理步骤中嵌入轻量级的 operator-level verifiers，能够实时校验目标存在性或空间关系等输出结果。这种机制使系统在验证条件未满足时能稳健地处理 no-target 场景，显著提升了推理的可靠性。实验结果显示，VIRO 在 target-present 和 no-target 设置下的 balanced accuracy 达到了 61.1%，且程序失败率低于 0.3%。此外，该框架在计算效率和 throughput 方面表现优异，并展现出良好的 scalability，成功泛化至现实世界的 egocentric 数据中。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12781v1",
      "published_date": "2026-01-19 07:21:19 UTC",
      "updated_date": "2026-01-19 07:21:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:15.983880+00:00"
    },
    {
      "arxiv_id": "2601.12762v1",
      "title": "Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction",
      "title_zh": "通过环境交互教导大语言模型学习工具试用与执行",
      "authors": [
        "Xingjie Gao",
        "Pengcheng Huang",
        "Zhenghao Liu",
        "Yukun Yan",
        "Shuo Wang",
        "Zulong Chen",
        "Chen Qian",
        "Ge Yu",
        "Yu Gu"
      ],
      "abstract": "Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.",
      "tldr_zh": "该研究提出了 ToolMaster 框架，旨在解决大型语言模型（LLMs）在处理新颖或动态演化的工具时，因过度依赖记忆静态解题路径而导致的鲁棒性不足问题。ToolMaster 将工具使用的范式从简单的轨迹模仿转向通过环境交互进行主动学习，并引入了“试错与执行”（trial-and-execution）的训练模式。该模式首先让模型模仿包含显式工具试错与自我修正的教师生成轨迹，随后利用强化学习（Reinforcement Learning）来共同协调试错与执行阶段。通过这一过程，智能体能够在与环境的主动交互中形成经验性知识，从而自主探索正确的工具调用方法。实验结果证明，ToolMaster 在面对未知或不熟悉的工具时，其泛化能力和鲁棒性显著超越了现有的基准模型。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12762v1",
      "published_date": "2026-01-19 06:46:33 UTC",
      "updated_date": "2026-01-19 06:46:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:17.464983+00:00"
    },
    {
      "arxiv_id": "2601.12758v1",
      "title": "VISPA: Pluralistic Alignment via Automatic Value Selection and Activation",
      "title_zh": "VISPA：基于自动价值选择与激活的多元化对齐",
      "authors": [
        "Shenyan Zheng",
        "Jiayou Zhong",
        "Anudeex Shetty",
        "Heng Ji",
        "Preslav Nakov",
        "Usman Naseem"
      ],
      "abstract": "As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.",
      "tldr_zh": "这项研究提出了 VISPA，一种无需训练的多样化对齐 (Pluralistic Alignment) 框架，旨在解决大型语言模型在反映多元人类价值观和视角方面的挑战。该框架通过动态选择 (Dynamic Selection) 和内部模型激活引导 (Internal Model Activation Steering) 技术，实现了对价值观表达的直接控制，弥补了现有方法在价值控制和表示能力上的不足。在涵盖医疗保健等多个领域的广泛实证研究中，VISPA 在各种对齐模式下均展现出优异的性能。分析结果进一步证实了该框架对于不同模型、价值体系和引导初始化的良好适应性。这项工作表明，利用内部激活机制可以有效实现多样化对齐，为开发能够服务于不同群体且具备可扩展性的语言模型提供了一条重要路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "WIP",
      "pdf_url": "https://arxiv.org/pdf/2601.12758v1",
      "published_date": "2026-01-19 06:38:52 UTC",
      "updated_date": "2026-01-19 06:38:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:12.774444+00:00"
    },
    {
      "arxiv_id": "2601.12754v1",
      "title": "PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining AI-Mediated Mental Health Support",
      "title_zh": "PAIR-SAFE：一种用于 AI 介导心理健康支持运行时审计与完善的双智能体方法",
      "authors": [
        "Jiwon Kim",
        "Violeta J. Rodriguez",
        "Dong Whi Yoo",
        "Eshwar Chandrasekharan",
        "Koustuv Saha"
      ],
      "abstract": "Large language models (LLMs) are increasingly used for mental health support, yet they can produce responses that are overly directive, inconsistent, or clinically misaligned, particularly in sensitive or high-risk contexts. Existing approaches to mitigating these risks largely rely on implicit alignment through training or prompting, offering limited transparency and runtime accountability. We introduce PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support that integrates a Responder agent with a supervisory Judge agent grounded in the clinically validated Motivational Interviewing Treatment Integrity (MITI-4) framework. The Judgeaudits each response and provides structuredALLOW or REVISE decisions that guide runtime response refinement. We simulate counseling interactions using a support-seeker simulator derived from human-annotated motivational interviewing data. We find that Judge-supervised interactions show significant improvements in key MITI dimensions, including Partnership, Seek Collaboration, and overall Relational quality. Our quantitative findings are supported by qualitative expert evaluation, which further highlights the nuances of runtime supervision. Together, our results reveal that such pairedagent approach can provide clinically grounded auditing and refinement for AI-assisted conversational mental health support.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在心理健康支持中可能出现的过度指令化、不一致或临床失准等风险，提出了 PAIR-SAFE 框架。该框架采用双智能体方法 (paired-agent approach)，将负责生成的 Responder 智能体与基于临床验证的 Motivational Interviewing Treatment Integrity (MITI-4) 标准的监督 Judge 智能体相结合。Judge 智能体负责审计回复并给出 ALLOW 或 REVISE 决策，从而在运行时实现对 AI 生成内容的实时精炼。实验通过模拟咨询交互发现，在 Judge 监督下的系统在 Partnership、Seek Collaboration 和整体 Relational quality 等核心临床维度上均有显著提升。专家评估进一步证实了该系统的有效性，表明这种双智能体架构能为 AI 驱动的对话式心理健康支持提供严谨的临床审计和优化机制。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12754v1",
      "published_date": "2026-01-19 06:20:57 UTC",
      "updated_date": "2026-01-19 06:20:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:16.285966+00:00"
    },
    {
      "arxiv_id": "2601.12745v1",
      "title": "A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection",
      "title_zh": "面向 WSN 时空关联异常检测的图提示微调方法",
      "authors": [
        "Miao Ye",
        "Jing Cui",
        "Yuan huang",
        "Qian He",
        "Yong Wang",
        "Jiwen Zhang"
      ],
      "abstract": "Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of \"pre-training - graph prompting - fine-tuning\" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning \"pre-training\" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.",
      "tldr_zh": "针对无线传感器网络(WSN)多时空模态数据中时空相关性提取不足、标注成本高及样本不平衡等问题，该研究设计了一种结合时空相关特征的图神经网络(GNN)异常检测骨干网络。该网络通过改进的多尺度Mamba模型、模态间融合方法以及变分图卷积(Variational Graph Convolution)模块，实现了对WSN多节点时空特征的深度提取。研究进一步提出了“预训练-图提示(Graph Prompting)-微调(Fine-tuning)”的多任务自监督训练策略，在预训练阶段通过无负样本对比学习、预测与重构任务从无标注数据中获取通用特征。随后利用图提示机制引导模型进行参数微调，有效降低了训练成本并增强了检测的泛化性能。实验结果显示，该方法在公共数据集和实际采集数据集上的F1指标分别达到91.30%和92.31%。相比现有方法，该方案在复杂WSN环境下展现出更优的检测性能和更强的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12745v1",
      "published_date": "2026-01-19 05:58:53 UTC",
      "updated_date": "2026-01-19 05:58:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:44.442104+00:00"
    },
    {
      "arxiv_id": "2601.12744v1",
      "title": "Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks",
      "title_zh": "面向自智网络优化驱动意图处理的视觉语言模型",
      "authors": [
        "Tasnim Ahmed",
        "Yifan Zhu",
        "Salimur Choudhury"
      ],
      "abstract": "Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.",
      "tldr_zh": "该研究探讨了视觉语言模型 (Vision-Language Models, VLMs) 在意图驱动网络 (Intent-Based Networking, IBN) 中将标注的网络草图转化为优化代码的潜力。作者提出了 IntentOpt 评估基准，涵盖 17 个类别的 85 个优化问题，旨在测试模型在处理多模态输入以解决流量工程和资源分配等任务时的表现。研究对比了 GPT-5-Mini、Claude-Haiku-4.5、Gemini-2.5-Flash 和 Llama-3.2-11B-Vision 在不同提示策略下的性能。实验结果显示，视觉参数提取显著增加了任务难度，代码执行成功率较纯文本输入下降了 12-21 个百分点。其中 GPT-5-Mini 以 72% 的视觉成功率领先，而开源模型 Llama-3.2-11B-Vision 仅达到 18%，揭示了闭源与开源模型之间的显著差距。此外，研究发现 Program-of-thought 提示策略在此类任务中表现不佳，并通过案例研究验证了利用 Model Context Protocol 将生成的代码部署到实际测试床设施的可行性。该工作为未来在自主网络中使用 VLMs 进行优化驱动的意图处理建立了重要的基准能力指标。",
      "categories": [
        "cs.AI",
        "cs.NI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for presentation at The IEEE International Conference on Communications (ICC) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12744v1",
      "published_date": "2026-01-19 05:57:58 UTC",
      "updated_date": "2026-01-19 05:57:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:42.913332+00:00"
    },
    {
      "arxiv_id": "2601.12742v1",
      "title": "AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation",
      "title_zh": "AirHunt：衔接 VLM 语义与连续规划的高效空中目标导航",
      "authors": [
        "Xuecheng Chen",
        "Zongzhuo Liu",
        "Jianfa Ma",
        "Bang Du",
        "Tiantian Zhang",
        "Xueqian Wang",
        "Boyu Zhou"
      ],
      "abstract": "Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.",
      "tldr_zh": "该研究提出了AirHunt，一种旨在实现高效空中目标导航(Aerial Object Navigation)的系统，通过融合视觉语言模型(VLM)的语义推理与连续路径规划(Continuous Path Planning)，实现在户外环境对开放集目标的零样本泛化搜索。该系统解决了VLM推理与实时规划之间的频率失配问题，并克服了VLM在3D场景理解方面的局限性。AirHunt采用了双路径异步架构(Dual-Pathway Asynchronous Architecture)，在VLM推理与路径规划之间建立了协同接口，支持带有自适应语义引导的连续飞行。此外，研究引入了主动双任务推理模块(Active Dual-Task Reasoning Module)，通过利用几何和语义冗余来实现选择性的VLM查询。同时，语义-几何相干规划模块(Semantic-Geometric Coherent Planning Module)在统一框架内动态协调语义优先级与运动效率，增强了对环境异质性的适应能力。实验评估表明，与现有最先进方法相比，AirHunt在多种导航任务中具有更高的成功率、更低的导航误差以及更短的飞行时间。真实世界的实验进一步验证了该系统在复杂且具有挑战性的环境中的实用能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12742v1",
      "published_date": "2026-01-19 05:50:03 UTC",
      "updated_date": "2026-01-19 05:50:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:53.398025+00:00"
    },
    {
      "arxiv_id": "2601.12740v1",
      "title": "TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents",
      "title_zh": "TreeWriter：面向长文档的 AI 辅助层级化规划与写作",
      "authors": [
        "Zijian Zhang",
        "Fangshi Du",
        "Xingjian Liu",
        "Pan Chen",
        "Oliver Huang",
        "Runlong Ye",
        "Michael Liut",
        "Alán Aspuru-Guzik"
      ],
      "abstract": "Long documents pose many challenges to current intelligent writing systems. These include maintaining consistency across sections, sustaining efficient planning and writing as documents become more complex, and effectively providing and integrating AI assistance to the user. Existing AI co-writing tools offer either inline suggestions or limited structured planning, but rarely support the entire writing process that begins with high-level ideas and ends with polished prose, in which many layers of planning and outlining are needed. Here, we introduce TreeWriter, a hierarchical writing system that represents documents as trees and integrates contextual AI support. TreeWriter allows authors to create, save, and refine document outlines at multiple levels, facilitating drafting, understanding, and iterative editing of long documents. A built-in AI agent can dynamically load relevant content, navigate the document hierarchy, and provide context-aware editing suggestions. A within-subject study (N=12) comparing TreeWriter with Google Docs + Gemini on long-document editing and creative writing tasks shows that TreeWriter improves idea exploration/development, AI helpfulness, and perceived authorial control. A two-month field deployment (N=8) further demonstrated that hierarchical organization supports collaborative writing. Our findings highlight the potential of hierarchical, tree-structured editors with integrated AI support and provide design guidelines for future AI-assisted writing tools that balance automation with user agency.",
      "tldr_zh": "该研究介绍了TreeWriter，一种旨在解决长文档撰写中一致性维护和复杂规划挑战的层次化AI辅助写作系统。TreeWriter将文档表示为树状结构(trees)，支持作者在多个维度创建和精炼大纲，从而实现从高层构思到最终成文的全流程覆盖。系统内置的AI智能体(AI agent)能够动态加载相关内容并提供语境感知的编辑建议，有效平衡了自动化功能与作者的自主掌控感(authorial control)。通过与Google Docs + Gemini的对比实验(N=12)及长期实地部署(N=8)表明，TreeWriter在想法探索、AI辅助有效性及协作写作方面具有显著优势。该研究结果强调了树状结构编辑器在长文本创作中的潜力，并为未来AI辅助写作工具的设计提供了指导原则。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12740v1",
      "published_date": "2026-01-19 05:39:35 UTC",
      "updated_date": "2026-01-19 05:39:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:59:33.018444+00:00"
    },
    {
      "arxiv_id": "2601.12731v1",
      "title": "A Shared Geometry of Difficulty in Multilingual Language Models",
      "title_zh": "多语言语言模型中问题难度的共享几何结构",
      "authors": [
        "Stefano Civelli",
        "Pietro Bernardelle",
        "Nicolò Brunello",
        "Gianluca Demartini"
      ],
      "abstract": "Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.",
      "tldr_zh": "该研究探讨了多语言大语言模型(LLMs)中问题难度(problem-difficulty)的几何结构，旨在揭示模型如何在其内部表示中感知任务难度。研究者通过在翻译成21种语言的Easy2Hard基准测试AMC子集上训练线性探测器(linear probes)，分析了模型内部不同层级的难度相关信号。实验发现难度信号主要出现在模型内部的浅层(early-layers)和深层(later-layers)两个不同阶段，且两者表现出显著不同的功能特性。在深层表示上训练的探测器在单语言评估中准确率极高，但跨语言泛化(cross-lingual generalization)表现较差；而在浅层表示上训练的探测器则展现出显著更强的跨语言泛化能力。这些结果表明，LLMs首先形成一种语言无关(language-agnostic)的问题难度表示，随后再将其转化为语言特异性(language-specific)的输出。该发现进一步证实了模型的两阶段表征过程不仅适用于语义处理，也延伸到了问题难度估计等高阶元认知属性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12731v1",
      "published_date": "2026-01-19 05:21:21 UTC",
      "updated_date": "2026-01-19 05:21:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:37.551500+00:00"
    },
    {
      "arxiv_id": "2601.12727v1",
      "title": "AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations",
      "title_zh": "AI展现的人格特质可通过对话塑造人类自我概念",
      "authors": [
        "Jingshu Li",
        "Tianqi Song",
        "Nattapat Boonprakong",
        "Zicheng Zhu",
        "Yitian Yang",
        "Yi-Chieh Lee"
      ],
      "abstract": "Recent Large Language Model (LLM) based AI can exhibit recognizable and measurable personality traits during conversations to improve user experience. However, as human understandings of their personality traits can be affected by their interaction partners' traits, a potential risk is that AI traits may shape and bias users' self-concept of their own traits. To explore the possibility, we conducted a randomized behavioral experiment. Our results indicate that after conversations about personal topics with an LLM-based AI chatbot using GPT-4o default personality traits, users' self-concepts aligned with the AI's measured personality traits. The longer the conversation, the greater the alignment. This alignment led to increased homogeneity in self-concepts among users. We also observed that the degree of self-concept alignment was positively associated with users' conversation enjoyment. Our findings uncover how AI personality traits can shape users' self-concepts through human-AI conversation, highlighting both risks and opportunities. We provide important design implications for developing more responsible and ethical AI systems.",
      "tldr_zh": "该研究探讨了基于 Large Language Model 的人工智能在对话中展现的人格特质如何塑造并偏向用户的 self-concept。通过随机行为实验，研究发现用户在与展示特定人格特质的 GPT-4o 进行个人话题对话后，其自我评价会向 AI 的特质靠拢，且对话时长与这种对齐程度成正比。这种效应不仅导致了用户群体间自我概念的 homogeneity 增加，还被发现与用户的对话享受度呈正相关。研究结果揭示了 AI 人格特质通过人机对话重塑人类心理认知的潜力，并分析了其中蕴含的风险与机遇。这些发现为未来构建更具责任感和伦理约束的 AI 系统提供了关键的设计参考。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "ACM CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12727v1",
      "published_date": "2026-01-19 05:16:57 UTC",
      "updated_date": "2026-01-19 05:16:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:52.344539+00:00"
    },
    {
      "arxiv_id": "2601.12723v1",
      "title": "An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models",
      "title_zh": "一种基于大语言模型的自动优化基准生成演化框架",
      "authors": [
        "Yuhiro Ono",
        "Tomohiro Harada",
        "Yukiya Miura"
      ],
      "abstract": "Optimization benchmarks play a fundamental role in assessing algorithm performance; however, existing artificial benchmarks often fail to capture the diversity and irregularity of real-world problem structures, while benchmarks derived from real-world problems are costly and difficult to construct. To address these challenges, we propose an evolutionary automatic benchmark generation framework that leverages a large language model (LLM) as a generative operator, termed the LLM-driven evolutionary benchmark generator (LLM-EBG). In this framework, the LLM serves as an evolutionary operator that generates and evolves benchmark problems within a flexible, expressive representation space. As a case study, we generate unconstrained single-objective continuous minimization problems represented as mathematical expressions designed to induce significant performance differences between a genetic algorithm (GA) and differential evolution (DE). Experimental results show that LLM-EBG successfully produces benchmark problems in which the designated target algorithm consistently outperforms the comparative algorithm in more than 80\\% of trials. Furthermore, exploratory landscape analysis reveals that benchmarks favoring GA are highly sensitive to variable scaling, demonstrating that the proposed framework can generate problems with distinct geometric characteristics that reflect the intrinsic search behaviors of different optimization algorithms.",
      "tldr_zh": "该研究针对现有优化基准测试(Optimization benchmarks)难以捕捉真实世界问题多样性且构建成本高的问题，提出了一个基于大语言模型(LLM)的自动化基准生成框架。该框架被称为LLM驱动的演化基准生成器(LLM-EBG)，将LLM作为演化算子(evolutionary operator)，在灵活且富有表现力的空间内生成并演化基准问题。研究以无约束单目标连续最小化问题为案例，通过数学表达式设计基准，旨在诱发遗传算法(GA)和差分进化(DE)之间的显著性能差异。实验结果表明，LLM-EBG成功生成了目标算法在超过80%的试验中一致优于对比算法的基准问题。探索性景观分析(Exploratory landscape analysis)进一步证实，该框架能够生成具有独特几何特征的问题，从而精准反映不同优化算法的内在搜索行为。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12723v1",
      "published_date": "2026-01-19 04:58:15 UTC",
      "updated_date": "2026-01-19 04:58:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:58:57.592060+00:00"
    },
    {
      "arxiv_id": "2601.12720v1",
      "title": "Teaching Large Reasoning Models Effective Reflection",
      "title_zh": "教导大推理模型进行有效反思",
      "authors": [
        "Hanbin Wang",
        "Jingwei Song",
        "Jinpeng Li",
        "Qi Zhu",
        "Fei Mi",
        "Ganqu Cui",
        "Yasheng Wang",
        "Lifeng Shang"
      ],
      "abstract": "Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.",
      "tldr_zh": "该研究针对大推理模型（Large Reasoning Models, LRMs）在复杂推理中存在的反思行为流于表面且计算开销大的问题，提出了旨在提升有效反思能力的训练框架。研究首先引入了 Self-Critique Fine-Tuning (SCFT)，利用模型自生成的评论并结合拒绝采样（Rejection Sampling）筛选高质量数据进行微调，以增强其反思推理能力。在此基础上，研究进一步提出了 Reinforcement Learning with Effective Reflection Rewards (RLERR)，通过 SCFT 初始化的高质量反思构建奖励信号，引导模型利用强化学习内化自我纠正过程。在 AIME2024 和 AIME2025 基准测试上的实验结果表明，SCFT 和 RLERR 显著提升了推理准确率和反思质量，性能优于现有的基线模型。该研究通过系统化的微调与强化学习方案，有效解决了 LRMs 在复杂任务中反思低效的挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages (including appendix), 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12720v1",
      "published_date": "2026-01-19 04:51:53 UTC",
      "updated_date": "2026-01-19 04:51:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:59:07.682163+00:00"
    },
    {
      "arxiv_id": "2601.12715v1",
      "title": "RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels",
      "title_zh": "RSOD：基于可靠性引导的极有限标签声呐图像目标检测",
      "authors": [
        "Chengzhou Li",
        "Ping Guo",
        "Guanchen Meng",
        "Qi Jia",
        "Jinyuan Liu",
        "Zhu Liu",
        "Xiaokang Liu",
        "Yu Liu",
        "Zhongxuan Luo",
        "Xin Fan"
      ],
      "abstract": "Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.",
      "tldr_zh": "该研究针对声纳图像(sonar images)纹理细节少、噪声大以及精确标注数据稀缺的问题，提出了名为RSOD的可靠性引导教师-学生框架(teacher-student framework)。该框架通过评估教师模型在不同视角下预测的一致性来计算可靠性分数(reliability score)，旨在充分学习声纳图像特征。为解决标注样本短缺，研究引入了物体混合伪标签方法(object mixed pseudo-label method)，将可靠性分数应用于伪标签生成策略。随后，研究通过实施可靠性引导的自适应约束(reliability-guided adaptive constraint)来优化学生模型的性能，使其能够充分利用无标注数据。在UATD数据集上的实验表明，RSOD仅需5%的标注数据即可达到与使用100%数据训练的基准模型相当的效果。此外，该研究还贡献了一个全新的声纳图像数据集，为水下目标检测研究提供了重要支撑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2026,9 pages,10 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12715v1",
      "published_date": "2026-01-19 04:37:34 UTC",
      "updated_date": "2026-01-19 04:37:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:59:07.380446+00:00"
    },
    {
      "arxiv_id": "2601.12711v1",
      "title": "Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts",
      "title_zh": "Neurosymbolic LoRA：权重微调与提示词重写的选择动机与适用时机",
      "authors": [
        "Kevin Wang",
        "Neel P. Bhatt",
        "Cong Liu",
        "Junbo Li",
        "Runjin Chen",
        "Yihan Xi",
        "Timothy Barclay",
        "Alvaro Velasquez",
        "Ufuk Topcu",
        "Zhangyang Wang"
      ],
      "abstract": "Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.",
      "tldr_zh": "该研究提出了Neurosymbolic LoRA框架，旨在解决大型语言模型(LLMs)适配过程中数值参数更新与符号Prompt重写之间的策略选择难题。该框架引入了统一的监控信号和基于奖励的分类器，能够动态判断何时采用LoRA进行深度事实知识注入，以及何时利用TextGrad进行Token级别的符号编辑。通过将符号转换任务按需外包给外部LLM，该方法在提升灵活性的同时保持了内存效率。此外，符号编辑产生的精炼Prompt还可转化为高质量的训练数据，显著助力数学推理等数据稀缺领域的模型训练。实验结果表明，Neurosymbolic LoRA在多种模型基座上的表现均优于纯数值或纯符号的基准方法，证明了交替使用这两类更新策略对于解锁模型微调通用性的重要价值。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12711v1",
      "published_date": "2026-01-19 04:24:49 UTC",
      "updated_date": "2026-01-19 04:24:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:59:21.837655+00:00"
    },
    {
      "arxiv_id": "2601.12688v1",
      "title": "Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction",
      "title_zh": "面向可解释多被告人判决预测的逻辑引导多阶段推理",
      "authors": [
        "Xu Zhang",
        "Qinghua Wang",
        "Mengyang Zhao",
        "Fang Wang",
        "Cunquan Qu"
      ],
      "abstract": "Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.",
      "tldr_zh": "该研究针对多被告案件中责任认定复杂且法律表述模糊导致角色区分困难的问题，提出了逻辑导向的多阶段推理框架 Logic-Guided Multistage Inference。该框架将量刑逻辑融入预训练的 Transformer 编码器中，旨在提高法律判决预测的智能辅助水平并确保 Legal Interpretability。通过采用定向掩码机制 Oriented Masking Mechanism 明确被告角色，并结合对比数据构建策略 Comparative Data Construction Strategy 提升模型对主犯与从犯责任差异的敏感度，系统能够更精准地处理复杂案情。预测的定罪标签通过 Broadcasting 机制整合进回归模型，实现了犯罪描述与法院观点的统一。在针对故意伤害案件的 IMLJP 数据集上的评估结果表明，Masked Multistage Inference (MMSI) 框架在角色责任区分准确率上显著优于基线模型。该工作为增强智能司法系统的解释性和公平性提供了稳健的技术方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12688v1",
      "published_date": "2026-01-19 03:20:36 UTC",
      "updated_date": "2026-01-19 03:20:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:59:46.156845+00:00"
    },
    {
      "arxiv_id": "2601.12671v1",
      "title": "Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification",
      "title_zh": "利用测试时增强进行联邦学习中的脑肿瘤 MRI 分类",
      "authors": [
        "Thamara Leandra de Deus Melo",
        "Rodrigo Moreira",
        "Larissa Ferreira Rodrigues Moreira",
        "André Ricardo Backes"
      ],
      "abstract": "Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.",
      "tldr_zh": "该研究探讨了在 Federated Learning (FL) 环境下，利用 Test-Time Augmentation (TTA) 优化脑肿瘤 MRI 图像分类的性能。研究人员评估并对比了卷积神经网络 (CNNs) 在原始图像与经过 resizing、grayscale conversion、normalization、filtering 和 histogram equalization 等预处理后的表现。实验发现，单独使用预处理手段带来的收益极小，但将其与 TTA 结合后，能为联邦 MRI 分类带来显著且具有统计学意义的提升 (p<0.001)。基于此，研究建议 TTA 应作为 FL 医学影像推理的默认策略，以应对病变变异和图像复杂性带来的挑战。在计算预算允许的情况下，将 TTA 与轻量级预处理配对使用，可进一步提供稳定且可靠的性能增益。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21st International Conference on Computer Vision Theory and Applications (VISAPP 2026), 9-11 March 2026, Marbella, Spain",
      "pdf_url": "https://arxiv.org/pdf/2601.12671v1",
      "published_date": "2026-01-19 02:32:50 UTC",
      "updated_date": "2026-01-19 02:32:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:59:57.539040+00:00"
    },
    {
      "arxiv_id": "2601.12667v1",
      "title": "Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration",
      "title_zh": "巨型星座时代基于人机协作的航天器电源系统全环路健康管理赋能",
      "authors": [
        "Yi Di",
        "Zhibin Zhao",
        "Fujin Wang",
        "Xue Liu",
        "Jiafeng Tang",
        "Jiaxin Ren",
        "Zhi Zhai",
        "Xuefeng Chen"
      ],
      "abstract": "It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.",
      "tldr_zh": "该研究针对巨型星座(SMC)时代下航天器能源系统(SPS)健康管理(HM)面临的规模化挑战，提出了底层能力对齐(AUC)原则，并开发了名为SpaceHMchat的开源人机协作(HAIC)框架。该框架能够覆盖工况识别、异常检测、故障定位及维护决策的全闭环健康管理(AIL HM)全流程，通过对话式任务处理和自适应学习提升了系统的透明推理能力与可解释性。为验证该框架，研究团队构建了高度拟真的硬件故障注入实验平台及仿真模型，实验结果显示SpaceHMchat在工况识别准确率（100%）、异常检测工具调用成功率（>99%）及故障定位精度（>90%）等指标上表现优异。此外，该工作发布了首个包含17类故障、超过70万个时间戳的航天器能源系统全闭环健康管理(AIL HM)数据集。这一研究成果为未来巨型星座时代下可信、高效的自主健康管理奠定了理论与数据基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12667v1",
      "published_date": "2026-01-19 02:28:27 UTC",
      "updated_date": "2026-01-19 02:28:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T07:59:54.997181+00:00"
    },
    {
      "arxiv_id": "2601.12664v1",
      "title": "Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images",
      "title_zh": "面向非 IID 癌症影像联邦学习的可泛化超参数优化",
      "authors": [
        "Elisa Gonçalves Ribeiro",
        "Rodrigo Moreira",
        "Larissa Ferreira Rodrigues Moreira",
        "André Ricardo Backes"
      ],
      "abstract": "Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.",
      "tldr_zh": "该研究探讨了在临床隐私限制下，如何针对非独立同分布(Non-IID)的癌症组织病理影像数据优化联邦学习(Federated Learning)的超参数选择。研究人员通过卵巢癌和结直肠癌的二元分类任务，评估了在一个数据集上优化的超参数是否能有效推广到不同的非独立同分布联邦学习场景。作者采用了集中式贝叶斯超参数优化(Bayesian Hyperparameter Optimization)方法，并将特定数据集的最优解转移到联邦学习设置中进行验证。该研究的核心贡献是提出了一种简单的跨数据集聚合启发式方法(Cross-dataset Aggregation Heuristic)，通过平均学习率(Learning Rate)并选取众数优化器(Optimizers)及批次大小(Batch Size)来组合生成通用配置。实验结果表明，这种组合后的超参数配置在处理复杂的非独立同分布癌症影像任务时，能够实现具有竞争力的分类性能与泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21st International Conference on Computer Vision Theory and Applications (VISAPP 2026), 9-11 March 2026, Marbella, Spain",
      "pdf_url": "https://arxiv.org/pdf/2601.12664v1",
      "published_date": "2026-01-19 02:24:24 UTC",
      "updated_date": "2026-01-19 02:24:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:00:34.064216+00:00"
    },
    {
      "arxiv_id": "2601.12661v1",
      "title": "MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents",
      "title_zh": "MedConsultBench：面向医疗问诊智能体的全周期、细粒度、过程感知评测基准",
      "authors": [
        "Chuhan Qiao",
        "Jianghua Huang",
        "Daxing Zhao",
        "Ziding Liu",
        "Yanjun Shen",
        "Bing Cheng",
        "Wei Lin",
        "Kai Wu"
      ],
      "abstract": "Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.",
      "tldr_zh": "该研究提出了 MedConsultBench，这是一个旨在评估完整在线咨询周期的综合框架，涵盖了从病史采集(history taking)、诊断到治疗计划和随访问答(follow-up Q\\&A)的全临床工作流，解决了现有评估侧重结果而忽视流程完整性与临床安全性的问题。该框架创新性地引入了原子信息单元(Atomic Information Units, AIUs)，在子轮次级别追踪临床信息获取，并通过22个细粒度指标精确监控关键事实的诱导过程。MedConsultBench 特别关注在线咨询中的不确定性与歧义处理，评估智能体在约束条件下进行简洁询问、确保药物方案兼容性以及处理处方后随访的能力。对19个大语言模型(LLMs)的系统评估显示，较高的诊断准确率往往掩盖了模型在信息采集效率和用药安全方面的显著缺陷。这一结果凸显了理论医学知识与临床实践能力之间的关键差距。MedConsultBench 为使医疗人工智能符合真实临床护理的复杂要求奠定了严谨的评估基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12661v1",
      "published_date": "2026-01-19 02:18:10 UTC",
      "updated_date": "2026-01-19 02:18:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:00:29.924525+00:00"
    },
    {
      "arxiv_id": "2601.12658v1",
      "title": "Augmenting Question Answering with A Hybrid RAG Approach",
      "title_zh": "采用混合 RAG 方法增强问答系统",
      "authors": [
        "Tianyi Yang",
        "Nashrah Haque",
        "Vaishnave Jonnalagadda",
        "Yuya Jeremy Ong",
        "Zhehui Chen",
        "Yanzhao Wu",
        "Lei Yu",
        "Divyesh Jadav",
        "Wenqi Wei"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.",
      "tldr_zh": "该研究针对传统检索增强生成(Retrieval-Augmented Generation, RAG)在问答任务中难以检索到语义相关上下文、导致答案不完整或次优的问题，提出了一种名为Structured-Semantic RAG (SSRAG)的混合架构。该架构通过整合查询增强(query augmentation)、智能体路由(agentic routing)以及结合了向量和图检索技术的结构化检索机制，实现了上下文的统一处理。SSRAG通过优化检索流程并增强上下文的落地性，显著提升了生成回答的准确性与信息丰富度。研究团队在TruthfulQA、SQuAD和WikiQA三个流行问答数据集上，针对五种大型语言模型(LLMs)进行了广泛评估。实验结果表明，与标准的RAG实现相比，SSRAG在提升响应质量方面表现出一致的优越性，为增强问答系统的性能提供了有效的技术路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 tables, 2 figures; presented at IEEE CogMI 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.12658v1",
      "published_date": "2026-01-19 02:08:47 UTC",
      "updated_date": "2026-01-19 02:08:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:00:00.715650+00:00"
    },
    {
      "arxiv_id": "2601.12654v1",
      "title": "Explanation Multiplicity in SHAP: Characterization and Assessment",
      "title_zh": "SHAP 解释的多重性：表征与评估",
      "authors": [
        "Hyunseung Hwang",
        "Seungeun Lee",
        "Lucas Rosenblatt",
        "Julia Stoyanovich",
        "Steven Euijong Whang"
      ],
      "abstract": "Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.",
      "tldr_zh": "该研究探讨了SHAP解释中的“解释多样性”(Explanation Multiplicity)现象，即即便在输入、任务和模型保持不变的情况下，SHAP解释在重复运行中仍可能出现实质性差异。作者提出了一套方法论来表征特征归因(feature-attribution)解释中的多样性，并成功区分了源于模型训练与解释流程内在随机性的不同影响来源。研究发现，解释的稳定性显著取决于所选指标，基于量级的距离可能极小，但基于排名的度量则揭示了关键特征及其顺序的剧烈变动。通过在零模型下推导随机基准值，该研究证实了解释多样性在各类数据集、模型和置信度水平下均普遍存在。这些发现表明，即使是高置信度的预测也面临解释不一致的问题，突显了建立与解释用途相匹配的度量标准和基准体系的紧迫性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12654v1",
      "published_date": "2026-01-19 02:01:18 UTC",
      "updated_date": "2026-01-19 02:01:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:00:09.480223+00:00"
    },
    {
      "arxiv_id": "2601.12648v1",
      "title": "Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?",
      "title_zh": "医学教育中的智能文书：人工智能能否取代人工病例记录？",
      "authors": [
        "Nafiz Imtiaz Khan",
        "Kylie Cleland",
        "Vladimir Filkov",
        "Roger Eric Goldman"
      ],
      "abstract": "Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.",
      "tldr_zh": "这项研究探讨了大型语言模型(Large Language Models, LLMs)在医学教育中自动化程序性病例日志(procedural case logs)记录的可行性，旨在解决手动记录耗时且易出现不一致的问题。研究团队评估了多种本地和商业LLMs在指令提示(instruction-based)和链式思维(chain-of-thought)提示下的表现，从414份介入放射学(interventional radiology)自由文本报告中提取结构化信息。评估过程综合考量了灵敏度(sensitivity)、特异性(specificity)、F1分数(F1-score)以及推理延迟和成本效率。实验结果显示，表现最优的模型F1分数接近0.87，证明了LLMs在保持高准确性的同时能有效平衡速度与成本。该研究表明，自动化技术具有大幅减轻受训人员行政负担并提升病例日志一致性的巨大潜力。这些发现验证了人工智能辅助文档系统在医学教育中的可行性，并为未来跨机构的临床工作流集成奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "51 pages, 12 figures, 8 tables. Feasibility study using retrospective radiology reports. Submitted to JAMIA Open (under review)",
      "pdf_url": "https://arxiv.org/pdf/2601.12648v1",
      "published_date": "2026-01-19 01:45:51 UTC",
      "updated_date": "2026-01-19 01:45:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:00:39.760090+00:00"
    },
    {
      "arxiv_id": "2601.12646v1",
      "title": "Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI",
      "title_zh": "无界之害，有界之法：无界人工智能时代的法律责任",
      "authors": [
        "Ha-Chi Tran"
      ],
      "abstract": "The rapid proliferation of artificial intelligence (AI) has exposed significant deficiencies in risk governance. While ex-ante harm identification and prevention have advanced, Responsible AI scholarship remains underdeveloped in addressing ex-post liability. Core legal questions regarding liability allocation, responsibility attribution, and remedial effectiveness remain insufficiently theorized and institutionalized, particularly for transboundary harms and risks that transcend national jurisdictions. Drawing on contemporary AI risk analyses, we argue that such harms are structurally embedded in global AI supply chains and are likely to escalate in frequency and severity due to cross-border deployment, data infrastructures, and uneven national oversight capacities. Consequently, territorially bounded liability regimes are increasingly inadequate. Using a comparative and interdisciplinary approach, this paper examines compensation and liability frameworks from high-risk transnational domains - including vaccine injury schemes, systemic financial risk governance, commercial nuclear liability, and international environmental regimes - to distill transferable legal design principles such as strict liability, risk pooling, collective risk-sharing, and liability channelling, while highlighting potential structural constraints on their application to AI-related harms. Situated within an international order shaped more by AI arms race dynamics than cooperative governance, the paper outlines the contours of a global AI accountability and compensation architecture, emphasizing the tension between geopolitical rivalry and the collective action required to govern transboundary AI risks effectively.",
      "tldr_zh": "该研究探讨了人工智能(AI)风险治理中事后责任(ex-post liability)制度的欠发达现状，特别是针对日益严峻的跨国伤害和风险。研究指出，由于AI伤害结构性地嵌入在全球AI供应链中，传统的领土受限法律制度已不足以应对跨界部署带来的复杂挑战。通过对疫苗伤害计划、系统性金融风险、商业核责任及国际环境制度等高风险领域的跨学科比较，本文提炼出了严格责任(strict liability)、风险池化(risk pooling)和责任引导(liability channelling)等核心法律设计原则。论文进一步勾勒了全球AI归责与补偿体系的架构，并分析了这些原则在实际应用中面临的结构性约束。最后，该研究强调了在当前地缘政治竞争与AI军备竞赛的背景下，实现有效治理跨国AI风险所需的集体行动与国家利益之间的张力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12646v1",
      "published_date": "2026-01-19 01:44:14 UTC",
      "updated_date": "2026-01-19 01:44:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:00:19.530072+00:00"
    },
    {
      "arxiv_id": "2601.12641v1",
      "title": "STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models",
      "title_zh": "STEP-LLM：利用大语言模型从自然语言生成 CAD STEP 模型",
      "authors": [
        "Xiangyu Shi",
        "Junyang Ding",
        "Xu Zhao",
        "Sinong Zhan",
        "Payal Mohapatra",
        "Daniel Quispe",
        "Kojo Welbeck",
        "Jian Cao",
        "Wei Chen",
        "Ping Guo",
        "Qi Zhu"
      ],
      "abstract": "Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.",
      "tldr_zh": "该研究提出了 STEP-LLM，一种旨在通过自然语言直接生成 STEP (ISO 10303) 标准 CAD 模型的大语言模型框架，旨在解决现有方法对内核依赖性高且缺乏通用性的问题。针对 STEP 文件复杂的图结构和交叉引用挑战，研究团队开发了基于深度优先搜索 (Depth-First Search, DFS) 的重新序列化技术来线性化数据，并结合了链式思维 (Chain-of-Thought, CoT) 结构标注以引导全局连贯性。通过集成检索增强生成 (RAG) 技术和基于倒角距离 (Chamfer Distance) 几何奖励的强化学习 (Reinforcement Learning)，该模型在监督微调阶段有效提升了生成的完整性与准确度。实验结果表明，STEP-LLM 在几何保真度和渲染成功率方面均显著优于 Text2CAD 基准模型。这一进展不仅验证了利用 LLMs 生成工业标准 B-rep 格式的可行性，也为实现自动化的制造设计民主化奠定了重要基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Design, Automation & Test in Europe Conference (DATE) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12641v1",
      "published_date": "2026-01-19 01:10:49 UTC",
      "updated_date": "2026-01-19 01:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:01:35.922849+00:00"
    },
    {
      "arxiv_id": "2601.12638v1",
      "title": "Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT",
      "title_zh": "基于 TensorRT 的高效 3D 目标检测混合精度 PointPillars",
      "authors": [
        "Ninnart Fuengfusin",
        "Keisuke Yoneda",
        "Naoki Suganuma"
      ],
      "abstract": "LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.",
      "tldr_zh": "该研究针对自动驾驶中的 LIDAR 3D 目标检测任务，提出了一种用于 PointPillars 算法的混合精度 (Mixed Precision) 框架，旨在解决传统量化过程中因数值分布较宽和离群值导致的性能下降问题。该框架通过训练后量化 (PTQ) 逐层识别敏感层，将前 k 个关键层保留为浮点 (FP) 精度，并采用贪心搜索优化层组合，最终通过 PTQ 或量化感知训练 (QAT) 完成模型定型。为了应对离群值挑战，研究发现使用极小规模的校准数据能有效提升 PTQ 的稳定性。实验结果显示，该方案的 QAT 流水线实现了与原始 FP 模型相当的精度，而在 TensorRT 部署环境下，模型推理延迟和体积分别降低了高达 2.35 倍和 2.26 倍。这一方法为实现兼顾高精度与实时性的 3D 目标检测提供了一种高效的量化优化方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12638v1",
      "published_date": "2026-01-19 00:59:13 UTC",
      "updated_date": "2026-01-19 00:59:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:02:18.556400+00:00"
    },
    {
      "arxiv_id": "2601.12637v1",
      "title": "Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction",
      "title_zh": "面向高效分子性质预测的拓扑感知多尺度混合专家模型",
      "authors": [
        "Long D. Nguyen",
        "Kelin Xia",
        "Binh P. Nguyen"
      ],
      "abstract": "Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.",
      "tldr_zh": "该研究针对现有3D分子图神经网络(GNNs)依赖固定距离阈值定义邻域导致建模僵化的问题，提出了多尺度相互作用专家混合模型(Multiscale Interaction Mixture of Experts, MI-MoE)。MI-MoE通过引入距离阈值专家集成(distance-cutoff expert ensemble)，实现了对短程、中程和远程相互作用的显式捕捉，克服了单一阈值的局限性。研究还设计了一个拓扑门控编码器(topological gating encoder)，利用包含持续同调(persistent homology)特征在内的拓扑描述符，根据连接性随半径演变的情况决定输入的路由路径。作为一种即插即用的模块，MI-MoE在涵盖回归和分类任务的多个分子及聚合物属性预测基准数据集上，显著提升了多种强力3D分子骨干网络的表现。实验结果表明，拓扑感知多尺度路由(topology-aware multiscale routing)是增强3D分子图学习有效性的关键原则。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12637v1",
      "published_date": "2026-01-19 00:54:24 UTC",
      "updated_date": "2026-01-19 00:54:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:02:19.256074+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 112,
  "processed_papers_count": 112,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-23T08:03:22.474464+00:00"
}