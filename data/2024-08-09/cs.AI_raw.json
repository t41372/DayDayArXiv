[
  {
    "arxiv_id": "2408.15257v1",
    "title": "Text classification optimization algorithm based on graph neural network",
    "authors": [
      "Erdi Gao",
      "Haowei Yang",
      "Dan Sun",
      "Haohao Xia",
      "Yuhan Ma",
      "Yuanjing Zhu"
    ],
    "abstract": "In the field of natural language processing, text classification, as a basic\ntask, has important research value and application prospects. Traditional text\nclassification methods usually rely on feature representations such as the bag\nof words model or TF-IDF, which overlook the semantic connections between words\nand make it challenging to grasp the deep structural details of the text.\nRecently, GNNs have proven to be a valuable asset for text classification\ntasks, thanks to their capability to handle non-Euclidean data efficiently.\nHowever, the existing text classification methods based on GNN still face\nchallenges such as complex graph structure construction and high cost of model\ntraining. This paper introduces a text classification optimization algorithm\nutilizing graph neural networks. By introducing adaptive graph construction\nstrategy and efficient graph convolution operation, the accuracy and efficiency\nof text classification are effectively improved. The experimental results\ndemonstrate that the proposed method surpasses traditional approaches and\nexisting GNN models across multiple public datasets, highlighting its superior\nperformance and feasibility for text classification tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2405.17460 by\n  other authors",
    "pdf_url": "http://arxiv.org/pdf/2408.15257v1",
    "published_date": "2024-08-09 23:25:37 UTC",
    "updated_date": "2024-08-09 23:25:37 UTC"
  },
  {
    "arxiv_id": "2408.05373v2",
    "title": "Evolutionary mechanisms that promote cooperation may not promote social welfare",
    "authors": [
      "The Anh Han",
      "Manh Hong Duong",
      "Matjaz Perc"
    ],
    "abstract": "Understanding the emergence of prosocial behaviours among self-interested\nindividuals is an important problem in many scientific disciplines. Various\nmechanisms have been proposed to explain the evolution of such behaviours,\nprimarily seeking the conditions under which a given mechanism can induce\nhighest levels of cooperation. As these mechanisms usually involve costs that\nalter individual payoffs, it is however possible that aiming for highest levels\nof cooperation might be detrimental for social welfare -- the later broadly\ndefined as the total population payoff, taking into account all costs involved\nfor inducing increased prosocial behaviours. Herein, by comparatively analysing\nthe social welfare and cooperation levels obtained from stochastic evolutionary\nmodels of two well-established mechanisms of prosocial behaviour, namely, peer\nand institutional incentives, we demonstrate exactly that. We show that the\nobjectives of maximising cooperation levels and the objectives of maximising\nsocial welfare are often misaligned. We argue for the need of adopting social\nwelfare as the main optimisation objective when designing and implementing\nevolutionary mechanisms for social and collective goods.",
    "categories": [
      "math.DS",
      "cs.AI",
      "cs.GT",
      "cs.MA",
      "nlin.AO"
    ],
    "primary_category": "math.DS",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.05373v2",
    "published_date": "2024-08-09 22:51:13 UTC",
    "updated_date": "2024-09-11 19:52:44 UTC"
  },
  {
    "arxiv_id": "2408.06381v2",
    "title": "Assessment of Cell Nuclei AI Foundation Models in Kidney Pathology",
    "authors": [
      "Junlin Guo",
      "Siqi Lu",
      "Can Cui",
      "Ruining Deng",
      "Tianyuan Yao",
      "Zhewen Tao",
      "Yizhe Lin",
      "Marilyn Lionts",
      "Quan Liu",
      "Juming Xiong",
      "Yu Wang",
      "Shilin Zhao",
      "Catie Chang",
      "Mitchell Wilkes",
      "Mengmeng Yin",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "abstract": "Cell nuclei instance segmentation is a crucial task in digital kidney\npathology. Traditional automatic segmentation methods often lack\ngeneralizability when applied to unseen datasets. Recently, the success of\nfoundation models (FMs) has provided a more generalizable solution, potentially\nenabling the segmentation of any cell type. In this study, we perform a\nlarge-scale evaluation of three widely used state-of-the-art (SOTA) cell nuclei\nfoundation models (Cellpose, StarDist, and CellViT). Specifically, we created a\nhighly diverse evaluation dataset consisting of 2,542 kidney whole slide images\n(WSIs) collected from both human and rodent sources, encompassing various\ntissue types, sizes, and staining methods. To our knowledge, this is the\nlargest-scale evaluation of its kind to date. Our quantitative analysis of the\nprediction distribution reveals a persistent performance gap in kidney\npathology. Among the evaluated models, CellViT demonstrated superior\nperformance in segmenting nuclei in kidney pathology. However, none of the\nfoundation models are perfect; a performance gap remains in general nuclei\nsegmentation for kidney pathology.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06381v2",
    "published_date": "2024-08-09 22:34:13 UTC",
    "updated_date": "2025-02-07 00:22:10 UTC"
  },
  {
    "arxiv_id": "2408.05365v4",
    "title": "FiSTECH: Financial Style Transfer to Enhance Creativity without Hallucinations in LLMs",
    "authors": [
      "Sohini Roychowdhury",
      "Marko Krema",
      "Brian Moore",
      "Xingjian Lai",
      "Dike Effedua",
      "Bharat Jethwani"
    ],
    "abstract": "Recent trends in Generative AI have emerged towards fine-tuning foundational\nlarge language models (LLMs) to create domain-specific LLMs for automation and\nchatbot-like applications. Specialized applications for analytics-heavy domains\nsuch as Financial report generation require specific writing styles that\ncomprise compound and creative sentences with minimized hallucinations. In this\nwork, we explore the self-corrective auto-regressive qualities of LLMs to learn\ncreativity in writing styles with minimal prompting. We propose a novel\ntwo-stage fine-tuning (FT) strategy wherein in the first stage public domain\nfinancial reports are used to train for writing styles while allowing the LLM\nto hallucinate. In the second stage the examples of hallucinations are manually\ncorrected and further used to fine-tune the LLM. The finally trained LLM learns\nto generate specific financial report sections using minimal instructions and\ntabular data inputs while ensuring low fine-tuning costs. Our proposed\ntwo-stage fine-tuning boosts the accuracy of financial questions answering by\ntwo-folds while reducing hallucinations by over 50%. Also, the fine-tuned model\nhas lower perplexity, improved ROUGE, TER and BLEU scores, higher creativity\nand knowledge density with lower uncertainty and cross entropy than base LLMs.\nThus, the proposed framework can be generalized to train creativity in LLMs by\nfirst allowing them to hallucinate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 14 figures, 5 tables, conference",
    "pdf_url": "http://arxiv.org/pdf/2408.05365v4",
    "published_date": "2024-08-09 22:29:23 UTC",
    "updated_date": "2024-11-17 07:22:31 UTC"
  },
  {
    "arxiv_id": "2408.05357v2",
    "title": "SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions",
    "authors": [
      "Zhi-Qi Cheng",
      "Yifei Dong",
      "Aike Shi",
      "Wei Liu",
      "Yuzhi Hu",
      "Jason O'Connor",
      "Alexander G. Hauptmann",
      "Kate S. Whitefoot"
    ],
    "abstract": "The electric vehicle (EV) battery supply chain's vulnerability to disruptions\nnecessitates advanced predictive analytics. We present SHIELD (Schema-based\nHierarchical Induction for EV supply chain Disruption), a system integrating\nLarge Language Models (LLMs) with domain expertise for EV battery supply chain\nrisk assessment. SHIELD combines: (1) LLM-driven schema learning to construct a\ncomprehensive knowledge library, (2) a disruption analysis system utilizing\nfine-tuned language models for event extraction, multi-dimensional similarity\nmatching for schema matching, and Graph Convolutional Networks (GCNs) with\nlogical constraints for prediction, and (3) an interactive interface for\nvisualizing results and incorporating expert feedback to enhance\ndecision-making. Evaluated on 12,070 paragraphs from 365 sources (2022-2023),\nSHIELD outperforms baseline GCNs and LLM+prompt methods (e.g., GPT-4o) in\ndisruption prediction. These results demonstrate SHIELD's effectiveness in\ncombining LLM capabilities with domain expertise for enhanced supply chain risk\nassessment.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Oral, EMNLP 2024 Industry Track. 31 pages, 11 figures, Project:\n  https://fly1113.github.io/MFI/",
    "pdf_url": "http://arxiv.org/pdf/2408.05357v2",
    "published_date": "2024-08-09 22:08:12 UTC",
    "updated_date": "2024-10-21 21:17:41 UTC"
  },
  {
    "arxiv_id": "2408.05345v2",
    "title": "Explainable AI Reloaded: Challenging the XAI Status Quo in the Era of Large Language Models",
    "authors": [
      "Upol Ehsan",
      "Mark O. Riedl"
    ],
    "abstract": "When the initial vision of Explainable (XAI) was articulated, the most\npopular framing was to open the (proverbial) \"black-box\" of AI so that we could\nunderstand the inner workings. With the advent of Large Language Models (LLMs),\nthe very ability to open the black-box is increasingly limited especially when\nit comes to non-AI expert end-users. In this paper, we challenge the assumption\nof \"opening\" the black-box in the LLM era and argue for a shift in our XAI\nexpectations. Highlighting the epistemic blind spots of an algorithm-centered\nXAI view, we argue that a human-centered perspective can be a path forward. We\noperationalize the argument by synthesizing XAI research along three\ndimensions: explainability outside the black-box, explainability around the\nedges of the black box, and explainability that leverages infrastructural\nseams. We conclude with takeaways that reflexively inform XAI as a domain.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to ACM HTTF 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05345v2",
    "published_date": "2024-08-09 21:28:31 UTC",
    "updated_date": "2024-08-13 19:39:52 UTC"
  },
  {
    "arxiv_id": "2408.05336v1",
    "title": "Logically Constrained Robotics Transformers for Enhanced Perception-Action Planning",
    "authors": [
      "Parv Kapoor",
      "Sai Vemprala",
      "Ashish Kapoor"
    ],
    "abstract": "With the advent of large foundation model based planning, there is a dire\nneed to ensure their output aligns with the stakeholder's intent. When these\nmodels are deployed in the real world, the need for alignment is magnified due\nto the potential cost to life and infrastructure due to unexpected faliures.\nTemporal Logic specifications have long provided a way to constrain system\nbehaviors and are a natural fit for these use cases. In this work, we propose a\nnovel approach to factor in signal temporal logic specifications while using\nautoregressive transformer models for trajectory planning. We also provide a\ntrajectory dataset for pretraining and evaluating foundation models. Our\nproposed technique acheives 74.3 % higher specification satisfaction over the\nbaselines.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Robotics Science and Systems: Towards Safe Autonomy",
    "pdf_url": "http://arxiv.org/pdf/2408.05336v1",
    "published_date": "2024-08-09 21:13:08 UTC",
    "updated_date": "2024-08-09 21:13:08 UTC"
  },
  {
    "arxiv_id": "2408.05334v1",
    "title": "Revisiting Multi-Modal LLM Evaluation",
    "authors": [
      "Jian Lu",
      "Shikhar Srivastava",
      "Junyu Chen",
      "Robik Shrestha",
      "Manoj Acharya",
      "Kushal Kafle",
      "Christopher Kanan"
    ],
    "abstract": "With the advent of multi-modal large language models (MLLMs), datasets used\nfor visual question answering (VQA) and referring expression comprehension have\nseen a resurgence. However, the most popular datasets used to evaluate MLLMs\nare some of the earliest ones created, and they have many known problems,\nincluding extreme bias, spurious correlations, and an inability to permit\nfine-grained analysis. In this paper, we pioneer evaluating recent MLLMs (LLaVA\n1.5, LLaVA-NeXT, BLIP2, InstructBLIP, GPT-4V, and GPT-4o) on datasets designed\nto address weaknesses in earlier ones. We assess three VQA datasets: 1) TDIUC,\nwhich permits fine-grained analysis on 12 question types; 2) TallyQA, which has\nsimple and complex counting questions; and 3) DVQA, which requires optical\ncharacter recognition for chart understanding. We also study VQDv1, a dataset\nthat requires identifying all image regions that satisfy a given query. Our\nexperiments reveal the weaknesses of many MLLMs that have not previously been\nreported. Our code is integrated into the widely used LAVIS framework for MLLM\nevaluation, enabling the rapid assessment of future MLLMs. Project webpage:\nhttps://kevinlujian.github.io/MLLM_Evaluations/",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05334v1",
    "published_date": "2024-08-09 20:55:46 UTC",
    "updated_date": "2024-08-09 20:55:46 UTC"
  },
  {
    "arxiv_id": "2408.05330v2",
    "title": "Neural Machine Unranking",
    "authors": [
      "Jingrui Hou",
      "Axel Finke",
      "Georgina Cosma"
    ],
    "abstract": "We tackle the problem of machine unlearning within neural information\nretrieval, termed Neural Machine UnRanking (NuMuR) for short. Many of the\nmainstream task- or model-agnostic approaches for machine unlearning were\ndesigned for classification tasks. First, we demonstrate that these methods\nperform poorly on NuMuR tasks due to the unique challenges posed by neural\ninformation retrieval. Then, we develop a methodology for NuMuR named\nContrastive and Consistent Loss (CoCoL), which effectively balances the\nobjectives of data forgetting and model performance retention. Experimental\nresults demonstrate that CoCoL facilitates more effective and controllable data\nremoval than existing techniques.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05330v2",
    "published_date": "2024-08-09 20:36:40 UTC",
    "updated_date": "2024-08-22 02:48:34 UTC"
  },
  {
    "arxiv_id": "2408.05328v1",
    "title": "From Text to Insight: Leveraging Large Language Models for Performance Evaluation in Management",
    "authors": [
      "Ning Li",
      "Huaikang Zhou",
      "Mingze Xu"
    ],
    "abstract": "This study explores the potential of Large Language Models (LLMs),\nspecifically GPT-4, to enhance objectivity in organizational task performance\nevaluations. Through comparative analyses across two studies, including various\ntask performance outputs, we demonstrate that LLMs can serve as a reliable and\neven superior alternative to human raters in evaluating knowledge-based\nperformance outputs, which are a key contribution of knowledge workers. Our\nresults suggest that GPT ratings are comparable to human ratings but exhibit\nhigher consistency and reliability. Additionally, combined multiple GPT ratings\non the same performance output show strong correlations with aggregated human\nperformance ratings, akin to the consensus principle observed in performance\nevaluation literature. However, we also find that LLMs are prone to contextual\nbiases, such as the halo effect, mirroring human evaluative biases. Our\nresearch suggests that while LLMs are capable of extracting meaningful\nconstructs from text-based data, their scope is currently limited to specific\nforms of performance evaluation. By highlighting both the potential and\nlimitations of LLMs, our study contributes to the discourse on AI role in\nmanagement studies and sets a foundation for future research to refine AI\ntheoretical and practical applications in management.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CL",
    "comment": "39 pages, 8 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.05328v1",
    "published_date": "2024-08-09 20:35:10 UTC",
    "updated_date": "2024-08-09 20:35:10 UTC"
  },
  {
    "arxiv_id": "2408.05321v1",
    "title": "A Recurrent YOLOv8-based framework for Event-Based Object Detection",
    "authors": [
      "Diego A. Silva",
      "Kamilya Smagulova",
      "Ahmed Elsheikh",
      "Mohammed E. Fouda",
      "Ahmed M. Eltawil"
    ],
    "abstract": "Object detection is crucial in various cutting-edge applications, such as\nautonomous vehicles and advanced robotics systems, primarily relying on data\nfrom conventional frame-based RGB sensors. However, these sensors often\nstruggle with issues like motion blur and poor performance in challenging\nlighting conditions. In response to these challenges, event-based cameras have\nemerged as an innovative paradigm. These cameras, mimicking the human eye,\ndemonstrate superior performance in environments with fast motion and extreme\nlighting conditions while consuming less power. This study introduces ReYOLOv8,\nan advanced object detection framework that enhances a leading frame-based\ndetection system with spatiotemporal modeling capabilities. We implemented a\nlow-latency, memory-efficient method for encoding event data to boost the\nsystem's performance. We also developed a novel data augmentation technique\ntailored to leverage the unique attributes of event data, thus improving\ndetection accuracy. Our models outperformed all comparable approaches in the\nGEN1 dataset, focusing on automotive applications, achieving mean Average\nPrecision (mAP) improvements of 5%, 2.8%, and 2.5% across nano, small, and\nmedium scales, respectively.These enhancements were achieved while reducing the\nnumber of trainable parameters by an average of 4.43% and maintaining real-time\nprocessing speeds between 9.2ms and 15.5ms. On the PEDRo dataset, which targets\nrobotics applications, our models showed mAP improvements ranging from 9% to\n18%, with 14.5x and 3.8x smaller models and an average speed enhancement of\n1.67x.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05321v1",
    "published_date": "2024-08-09 20:00:16 UTC",
    "updated_date": "2024-08-09 20:00:16 UTC"
  },
  {
    "arxiv_id": "2408.05314v1",
    "title": "rule4ml: An Open-Source Tool for Resource Utilization and Latency Estimation for ML Models on FPGA",
    "authors": [
      "Mohammad Mehdi Rahimifar",
      "Hamza Ezzaoui Rahali",
      "Audrey C. Therrien"
    ],
    "abstract": "Implementing Machine Learning (ML) models on Field-Programmable Gate Arrays\n(FPGAs) is becoming increasingly popular across various domains as a\nlow-latency and low-power solution that helps manage large data rates generated\nby continuously improving detectors. However, developing ML models for FPGAs is\ntime-consuming, as optimization requires synthesis to evaluate FPGA area and\nlatency, making the process slow and repetitive. This paper introduces a novel\nmethod to predict the resource utilization and inference latency of Neural\nNetworks (NNs) before their synthesis and implementation on FPGA. We leverage\nHLS4ML, a tool-flow that helps translate NNs into high-level synthesis (HLS)\ncode, to synthesize a diverse dataset of NN architectures and train resource\nutilization and inference latency predictors. While HLS4ML requires full\nsynthesis to obtain resource and latency insights, our method uses trained\nregression models for immediate pre-synthesis predictions. The prediction\nmodels estimate the usage of Block RAM (BRAM), Digital Signal Processors (DSP),\nFlip-Flops (FF), and Look-Up Tables (LUT), as well as the inference clock\ncycles. The predictors were evaluated on both synthetic and existing benchmark\narchitectures and demonstrated high accuracy with R2 scores ranging between 0.8\nand 0.98 on the validation set and sMAPE values between 10% and 30%. Overall,\nour approach provides valuable preliminary insights, enabling users to quickly\nassess the feasibility and efficiency of NNs on FPGAs, accelerating the\ndevelopment and deployment processes. The open-source repository can be found\nat https://github.com/IMPETUS-UdeS/rule4ml, while the datasets are publicly\navailable at https://borealisdata.ca/dataverse/rule4ml.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05314v1",
    "published_date": "2024-08-09 19:35:10 UTC",
    "updated_date": "2024-08-09 19:35:10 UTC"
  },
  {
    "arxiv_id": "2408.15256v3",
    "title": "Improving Ontology Requirements Engineering with OntoChat and Participatory Prompting",
    "authors": [
      "Yihang Zhao",
      "Bohui Zhang",
      "Xi Hu",
      "Shuyin Ouyang",
      "Jongmo Kim",
      "Nitisha Jain",
      "Jacopo de Berardinis",
      "Albert Meroño-Peñuela",
      "Elena Simperl"
    ],
    "abstract": "Past ontology requirements engineering (ORE) has primarily relied on manual\nmethods, such as interviews and collaborative forums, to gather user\nrequirements from domain experts, especially in large projects. Current\nOntoChat offers a framework for ORE that utilises large language models (LLMs)\nto streamline the process through four key functions: user story creation,\ncompetency question (CQ) extraction, CQ filtration and analysis, and ontology\ntesting support. In OntoChat, users are expected to prompt the chatbot to\ngenerate user stories. However, preliminary evaluations revealed that they\nstruggle to do this effectively. To address this issue, we experimented with a\nresearch method called participatory prompting, which involves\nresearcher-mediated interactions to help users without deep knowledge of LLMs\nuse the chatbot more effectively. This participatory prompting user study\nproduces pre-defined prompt templates based on user queries, focusing on\ncreating and refining personas, goals, scenarios, sample data, and data\nresources for user stories. These refined user stories will subsequently be\nconverted into CQs.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.15256v3",
    "published_date": "2024-08-09 19:21:14 UTC",
    "updated_date": "2024-09-18 16:09:40 UTC"
  },
  {
    "arxiv_id": "2408.05288v2",
    "title": "The impact of internal variability on benchmarking deep learning climate emulators",
    "authors": [
      "Björn Lütjens",
      "Raffaele Ferrari",
      "Duncan Watson-Parris",
      "Noelle Selin"
    ],
    "abstract": "Full-complexity Earth system models (ESMs) are computationally very\nexpensive, limiting their use in exploring the climate outcomes of multiple\nemission pathways. More efficient emulators that approximate ESMs can directly\nmap emissions onto climate outcomes, and benchmarks are being used to evaluate\ntheir accuracy on standardized tasks and datasets. We investigate a popular\nbenchmark in data-driven climate emulation, ClimateBench, on which deep\nlearning-based emulators are currently achieving the best performance. We\ncompare these deep learning emulators with a linear regression-based emulator,\nakin to pattern scaling, and show that it outperforms the incumbent\n100M-parameter deep learning foundation model, ClimaX, on 3 out of 4\nregionally-resolved climate variables, notably surface temperature and\nprecipitation. While emulating surface temperature is expected to be\npredominantly linear, this result is surprising for emulating precipitation.\nPrecipitation is a much more noisy variable, and we show that deep learning\nemulators can overfit to internal variability noise at low frequencies,\ndegrading their performance in comparison to a linear emulator. We address the\nissue of overfitting by increasing the number of climate simulations per\nemission pathway (from 3 to 50) and updating the benchmark targets with the\nrespective ensemble averages from the MPI-ESM1.2-LR model. Using the new\ntargets, we show that linear pattern scaling continues to be more accurate on\ntemperature, but can be outperformed by a deep learning-based technique for\nemulating precipitation. We publish our code and data at\ngithub.com/blutjens/climate-emulator.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05288v2",
    "published_date": "2024-08-09 18:17:17 UTC",
    "updated_date": "2025-03-31 16:06:28 UTC"
  },
  {
    "arxiv_id": "2408.05285v1",
    "title": "Semi-Supervised One-Shot Imitation Learning",
    "authors": [
      "Philipp Wu",
      "Kourosh Hakhamaneshi",
      "Yuqing Du",
      "Igor Mordatch",
      "Aravind Rajeswaran",
      "Pieter Abbeel"
    ],
    "abstract": "One-shot Imitation Learning~(OSIL) aims to imbue AI agents with the ability\nto learn a new task from a single demonstration. To supervise the learning,\nOSIL typically requires a prohibitively large number of paired expert\ndemonstrations -- i.e. trajectories corresponding to different variations of\nthe same semantic task. To overcome this limitation, we introduce the\nsemi-supervised OSIL problem setting, where the learning agent is presented\nwith a large dataset of trajectories with no task labels (i.e. an unpaired\ndataset), along with a small dataset of multiple demonstrations per semantic\ntask (i.e. a paired dataset). This presents a more realistic and practical\nembodiment of few-shot learning and requires the agent to effectively leverage\nweak supervision from a large dataset of trajectories. Subsequently, we develop\nan algorithm specifically applicable to this semi-supervised OSIL setting. Our\napproach first learns an embedding space where different tasks cluster\nuniquely. We utilize this embedding space and the clustering it supports to\nself-generate pairings between trajectories in the large unpaired dataset.\nThrough empirical results on simulated control tasks, we demonstrate that OSIL\nmodels trained on such self-generated pairings are competitive with OSIL models\ntrained with ground-truth labels, presenting a major advancement in the\nlabel-efficiency of OSIL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05285v1",
    "published_date": "2024-08-09 18:11:26 UTC",
    "updated_date": "2024-08-09 18:11:26 UTC"
  },
  {
    "arxiv_id": "2408.05284v2",
    "title": "Can a Bayesian Oracle Prevent Harm from an Agent?",
    "authors": [
      "Yoshua Bengio",
      "Michael K. Cohen",
      "Nikolay Malkin",
      "Matt MacDermott",
      "Damiano Fornasiere",
      "Pietro Greiner",
      "Younesse Kaddar"
    ],
    "abstract": "Is there a way to design powerful AI systems based on machine learning\nmethods that would satisfy probabilistic safety guarantees? With the long-term\ngoal of obtaining a probabilistic guarantee that would apply in every context,\nwe consider estimating a context-dependent bound on the probability of\nviolating a given safety specification. Such a risk evaluation would need to be\nperformed at run-time to provide a guardrail against dangerous actions of an\nAI. Noting that different plausible hypotheses about the world could produce\nvery different outcomes, and because we do not know which one is right, we\nderive bounds on the safety violation probability predicted under the true but\nunknown hypothesis. Such bounds could be used to reject potentially dangerous\nactions. Our main results involve searching for cautious but plausible\nhypotheses, obtained by a maximization that involves Bayesian posteriors over\nhypotheses. We consider two forms of this result, in the iid case and in the\nnon-iid case, and conclude with open problems towards turning such theoretical\nresults into practical AI guardrails.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05284v2",
    "published_date": "2024-08-09 18:10:42 UTC",
    "updated_date": "2024-08-22 19:14:27 UTC"
  },
  {
    "arxiv_id": "2408.05211v2",
    "title": "VITA: Towards Open-Source Interactive Omni Multimodal LLM",
    "authors": [
      "Chaoyou Fu",
      "Haojia Lin",
      "Zuwei Long",
      "Yunhang Shen",
      "Meng Zhao",
      "Yifan Zhang",
      "Shaoqi Dong",
      "Xiong Wang",
      "Di Yin",
      "Long Ma",
      "Xiawu Zheng",
      "Ran He",
      "Rongrong Ji",
      "Yunsheng Wu",
      "Caifeng Shan",
      "Xing Sun"
    ],
    "abstract": "The remarkable multimodal capabilities and interactive experience of GPT-4o\nunderscore their necessity in practical applications, yet open-source models\nrarely excel in both areas. In this paper, we introduce VITA, the first-ever\nopen-source Multimodal Large Language Model (MLLM) adept at simultaneous\nprocessing and analysis of Video, Image, Text, and Audio modalities, and\nmeanwhile has an advanced multimodal interactive experience. Starting from\nMixtral 8x7B as a language foundation, we expand its Chinese vocabulary\nfollowed by bilingual instruction tuning. We further endow the language model\nwith visual and audio capabilities through two-stage multi-task learning of\nmultimodal alignment and instruction tuning. VITA demonstrates robust\nfoundational capabilities of multilingual, vision, and audio understanding, as\nevidenced by its strong performance across a range of both unimodal and\nmultimodal benchmarks. Beyond foundational capabilities, we have made\nconsiderable progress in enhancing the natural multimodal human-computer\ninteraction experience. VITA is the first step for the open-source community to\nexplore the seamless integration of multimodal understanding and interaction.\nWhile there is still lots of work to be done on VITA to get close to\nclose-source counterparts, we hope that its role as a pioneer can serve as a\ncornerstone for subsequent research. Project Page: https://vita-home.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://vita-home.github.io",
    "pdf_url": "http://arxiv.org/pdf/2408.05211v2",
    "published_date": "2024-08-09 17:59:49 UTC",
    "updated_date": "2024-09-10 13:21:08 UTC"
  },
  {
    "arxiv_id": "2408.05200v4",
    "title": "KIF: Knowledge Identification and Fusion for Language Model Continual Learning",
    "authors": [
      "Yujie Feng",
      "Xu Chu",
      "Yongxin Xu",
      "Zexin Lu",
      "Bo Liu",
      "Philip S. Yu",
      "Xiao-Ming Wu"
    ],
    "abstract": "Language model continual learning (CL) has recently attracted significant\ninterest for its ability to adapt large language models (LLMs) to dynamic\nreal-world scenarios without retraining. A major challenge in this domain is\ncatastrophic forgetting, where models lose previously acquired knowledge upon\nlearning new tasks. Existing approaches commonly utilize multiple\nparameter-efficient fine-tuning (PEFT) blocks to acquire task-specific\nknowledge, yet these methods are inefficient and fail to leverage potential\nknowledge transfer across tasks. In this paper, we introduce a novel CL\nframework for language models, named Knowledge Identification and Fusion (KIF),\nwhich boosts knowledge transfer without depending on memory replay. KIF\ninitially segregates the model into 'skill units' based on parameter\ndependencies, allowing for more precise control. Subsequently, it employs a\nnovel group-wise knowledge identification technique to ascertain the importance\ndistribution of skill units for a new task. By comparing this importance\ndistribution with those from previous tasks, we implement a fine-grained\nknowledge fusion strategy that retains task-specific knowledge, thereby\npreventing forgetting, and updates task-shared knowledge, which facilitates\nbi-directional knowledge transfer. As a result, KIF achieves an optimal balance\nbetween retaining prior knowledge and excelling in new tasks. KIF also\ndemonstrates strong generalizability, making it suitable for various base\nmodels and adaptable to PEFT methods like LoRA. Furthermore, it offers notable\nextensibility, supporting enhancements through integration with memory replay\ntechniques. Comprehensive experiments conducted on two CL benchmarks, involving\nmodels ranging from 220M to 7B parameters, affirm the effectiveness of KIF and\nits variants across different settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This version updates the model name from Task Skill Localization and\n  Consolidation (TaSL) to Knowledge Identification and Fusion (KIF). It is an\n  extension of the ACL 2024 paper titled Continual Dialog State Tracking via\n  Task Skill Localization and Consolidation",
    "pdf_url": "http://arxiv.org/pdf/2408.05200v4",
    "published_date": "2024-08-09 17:44:45 UTC",
    "updated_date": "2025-01-23 12:06:37 UTC"
  },
  {
    "arxiv_id": "2408.05195v1",
    "title": "HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling",
    "authors": [
      "Piotr Keller",
      "Muhammad Dawood",
      "Brinder Singh Chohan",
      "Fayyaz ul Amir Afsar Minhas"
    ],
    "abstract": "Machine learning in computational pathology (CPath) often aggregates\npatch-level predictions from multi-gigapixel Whole Slide Images (WSIs) to\ngenerate WSI-level prediction scores for crucial tasks such as survival\nprediction and drug effect prediction. However, current methods do not\nexplicitly characterize distributional differences between patch sets within\nWSIs. We introduce HistoKernel, a novel Maximum Mean Discrepancy (MMD) kernel\nthat measures distributional similarity between WSIs for enhanced prediction\nperformance on downstream prediction tasks.\n  Our comprehensive analysis demonstrates HistoKernel's effectiveness across\nvarious machine learning tasks, including retrieval (n = 9,362), drug\nsensitivity regression (n = 551), point mutation classification (n = 3,419),\nand survival analysis (n = 2,291), outperforming existing deep learning\nmethods. Additionally, HistoKernel seamlessly integrates multi-modal data and\noffers a novel perturbation-based method for patch-level explainability. This\nwork pioneers the use of kernel-based methods for WSI-level predictive\nmodeling, opening new avenues for research. Code is available at\nhttps://github.com/pkeller00/HistoKernel.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 5 figures, 1 Table. Preprint for article in review at\n  Nature Machine Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2408.05195v1",
    "published_date": "2024-08-09 17:40:08 UTC",
    "updated_date": "2024-08-09 17:40:08 UTC"
  },
  {
    "arxiv_id": "2408.05151v1",
    "title": "Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification",
    "authors": [
      "Xiaoyang Hao",
      "Zhixi Feng",
      "Tongqing Peng",
      "Shuyuan Yang"
    ],
    "abstract": "Automatic modulation classification (AMC) is an effective way to deal with\nphysical layer threats of the internet of things (IoT). However, there is often\nlabel mislabeling in practice, which significantly impacts the performance and\nrobustness of deep neural networks (DNNs). In this paper, we propose a\nmeta-learning guided label noise distillation method for robust AMC.\nSpecifically, a teacher-student heterogeneous network (TSHN) framework is\nproposed to distill and reuse label noise. Based on the idea that labels are\nrepresentations, the teacher network with trusted meta-learning divides and\nconquers untrusted label samples and then guides the student network to learn\nbetter by reassessing and correcting labels. Furthermore, we propose a\nmulti-view signal (MVS) method to further improve the performance of\nhard-to-classify categories with few-shot trusted label samples. Extensive\nexperimental results show that our methods can significantly improve the\nperformance and robustness of signal AMC in various and complex label noise\nscenarios, which is crucial for securing IoT applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "I.2; C.2"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.05151v1",
    "published_date": "2024-08-09 16:14:40 UTC",
    "updated_date": "2024-08-09 16:14:40 UTC"
  },
  {
    "arxiv_id": "2408.05149v1",
    "title": "AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset",
    "authors": [
      "Pritam Deka",
      "Sampath Rajapaksha",
      "Ruby Rani",
      "Amirah Almutairi",
      "Erisa Karafili"
    ],
    "abstract": "Cyber-attack attribution is an important process that allows experts to put\nin place attacker-oriented countermeasures and legal actions. The analysts\nmainly perform attribution manually, given the complex nature of this task. AI\nand, more specifically, Natural Language Processing (NLP) techniques can be\nleveraged to support cybersecurity analysts during the attribution process.\nHowever powerful these techniques are, they need to deal with the lack of\ndatasets in the attack attribution domain. In this work, we will fill this gap\nand will provide, to the best of our knowledge, the first dataset on\ncyber-attack attribution. We designed our dataset with the primary goal of\nextracting attack attribution information from cybersecurity texts, utilizing\nnamed entity recognition (NER) methodologies from the field of NLP. Unlike\nother cybersecurity NER datasets, ours offers a rich set of annotations with\ncontextual details, including some that span phrases and sentences. We\nconducted extensive experiments and applied NLP techniques to demonstrate the\ndataset's effectiveness for attack attribution. These experiments highlight the\npotential of Large Language Models (LLMs) capabilities to improve the NER tasks\nin cybersecurity datasets for cyber-attack attribution.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to WISE 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05149v1",
    "published_date": "2024-08-09 16:10:35 UTC",
    "updated_date": "2024-08-09 16:10:35 UTC"
  },
  {
    "arxiv_id": "2408.05147v2",
    "title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2",
    "authors": [
      "Tom Lieberum",
      "Senthooran Rajamanoharan",
      "Arthur Conmy",
      "Lewis Smith",
      "Nicolas Sonnerat",
      "Vikrant Varma",
      "János Kramár",
      "Anca Dragan",
      "Rohin Shah",
      "Neel Nanda"
    ],
    "abstract": "Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse\ndecomposition of a neural network's latent representations into seemingly\ninterpretable features. Despite recent excitement about their potential,\nresearch applications outside of industry are limited by the high cost of\ntraining a comprehensive suite of SAEs. In this work, we introduce Gemma Scope,\nan open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2\n2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs\non the Gemma 2 pre-trained models, but additionally release SAEs trained on\ninstruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each\nSAE on standard metrics and release these results. We hope that by releasing\nthese SAE weights, we can help make more ambitious safety and interpretability\nresearch easier for the community. Weights and a tutorial can be found at\nhttps://huggingface.co/google/gemma-scope and an interactive demo can be found\nat https://www.neuronpedia.org/gemma-scope",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "12 main text pages, and 14 pages of acknowledgements, references and\n  appendices",
    "pdf_url": "http://arxiv.org/pdf/2408.05147v2",
    "published_date": "2024-08-09 16:06:42 UTC",
    "updated_date": "2024-08-19 07:51:05 UTC"
  },
  {
    "arxiv_id": "2408.05128v1",
    "title": "Is ChatGPT a Good Software Librarian? An Exploratory Study on the Use of ChatGPT for Software Library Recommendations",
    "authors": [
      "Jasmine Latendresse",
      "SayedHassan Khatoonabadi",
      "Ahmad Abdellatif",
      "Emad Shihab"
    ],
    "abstract": "Software libraries play a critical role in the functionality, efficiency, and\nmaintainability of software systems. As developers increasingly rely on Large\nLanguage Models (LLMs) to streamline their coding processes, the effectiveness\nof these models in recommending appropriate libraries becomes crucial yet\nremains largely unexplored. In this paper, we assess the effectiveness of\nChatGPT as a software librarian and identify areas for improvement. We\nconducted an empirical study using GPT-3.5 Turbo to generate Python code for\n10,000 Stack Overflow questions. Our findings show that ChatGPT uses\nthird-party libraries nearly 10% more often than human developers, favoring\nwidely adopted and well-established options. However, 14.2% of the recommended\nlibraries had restrictive copyleft licenses, which were not explicitly\ncommunicated by ChatGPT. Additionally, 6.5% of the libraries did not work out\nof the box, leading to potential developer confusion and wasted time. While\nChatGPT can be an effective software librarian, it should be improved by\nproviding more explicit information on maintainability metrics and licensing.\nWe recommend that developers implement rigorous dependency management practices\nand double-check library licenses before integrating LLM-generated code into\ntheir projects.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Submitted",
    "pdf_url": "http://arxiv.org/pdf/2408.05128v1",
    "published_date": "2024-08-09 15:36:59 UTC",
    "updated_date": "2024-08-09 15:36:59 UTC"
  },
  {
    "arxiv_id": "2408.05120v1",
    "title": "Cautious Calibration in Binary Classification",
    "authors": [
      "Mari-Liis Allikivi",
      "Joonas Järve",
      "Meelis Kull"
    ],
    "abstract": "Being cautious is crucial for enhancing the trustworthiness of machine\nlearning systems integrated into decision-making pipelines. Although calibrated\nprobabilities help in optimal decision-making, perfect calibration remains\nunattainable, leading to estimates that fluctuate between under- and\noverconfidence. This becomes a critical issue in high-risk scenarios, where\neven occasional overestimation can lead to extreme expected costs. In these\nscenarios, it is important for each predicted probability to lean towards\nunderconfidence, rather than just achieving an average balance. In this study,\nwe introduce the novel concept of cautious calibration in binary\nclassification. This approach aims to produce probability estimates that are\nintentionally underconfident for each predicted probability. We highlight the\nimportance of this approach in a high-risk scenario and propose a theoretically\ngrounded method for learning cautious calibration maps. Through experiments, we\nexplore and compare our method to various approaches, including methods\noriginally not devised for cautious calibration but applicable in this context.\nWe show that our approach is the most consistent in providing cautious\nestimates. Our work establishes a strong baseline for further developments in\nthis novel framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05120v1",
    "published_date": "2024-08-09 15:19:40 UTC",
    "updated_date": "2024-08-09 15:19:40 UTC"
  },
  {
    "arxiv_id": "2408.05117v2",
    "title": "Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images",
    "authors": [
      "Shouyue Liu",
      "Ziyi Zhang",
      "Yuanyuan Gu",
      "Jinkui Hao",
      "Yonghuai Liu",
      "Huazhu Fu",
      "Xinyu Guo",
      "Hong Song",
      "Shuting Zhang",
      "Yitian Zhao"
    ],
    "abstract": "Early detection of dementia, such as Alzheimer's disease (AD) or mild\ncognitive impairment (MCI), is essential to enable timely intervention and\npotential treatment. Accurate detection of AD/MCI is challenging due to the\nhigh complexity, cost, and often invasive nature of current diagnostic\ntechniques, which limit their suitability for large-scale population screening.\nGiven the shared embryological origins and physiological characteristics of the\nretina and brain, retinal imaging is emerging as a potentially rapid and\ncost-effective alternative for the identification of individuals with or at\nhigh risk of AD. In this paper, we present a novel PolarNet+ that uses retinal\noptical coherence tomography angiography (OCTA) to discriminate early-onset AD\n(EOAD) and MCI subjects from controls. Our method first maps OCTA images from\nCartesian coordinates to polar coordinates, allowing approximate sub-region\ncalculation to implement the clinician-friendly early treatment of diabetic\nretinopathy study (ETDRS) grid analysis. We then introduce a multi-view module\nto serialize and analyze the images along three dimensions for comprehensive,\nclinically useful information extraction. Finally, we abstract the sequence\nembedding into a graph, transforming the detection task into a general graph\nclassification problem. A regional relationship module is applied after the\nmulti-view module to excavate the relationship between the sub-regions. Such\nregional relationship analyses validate known eye-brain links and reveal new\ndiscriminative patterns.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05117v2",
    "published_date": "2024-08-09 15:10:34 UTC",
    "updated_date": "2025-03-12 08:58:41 UTC"
  },
  {
    "arxiv_id": "2408.05109v4",
    "title": "A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?",
    "authors": [
      "Xinyu Liu",
      "Shuyu Shen",
      "Boyan Li",
      "Peixian Ma",
      "Runzhi Jiang",
      "Yuxin Zhang",
      "Ju Fan",
      "Guoliang Li",
      "Nan Tang",
      "Yuyu Luo"
    ],
    "abstract": "Translating users' natural language queries (NL) into SQL queries (i.e.,\nNL2SQL, a.k.a., Text-to-SQL) can significantly reduce barriers to accessing\nrelational databases and support various commercial applications. The\nperformance of NL2SQL has been greatly enhanced with the emergence of Large\nLanguage Models (LLMs). In this survey, we provide a comprehensive review of\nNL2SQL techniques powered by LLMs, covering its entire lifecycle from the\nfollowing four aspects: (1) Model: NL2SQL translation techniques that tackle\nnot only NL ambiguity and under-specification, but also properly map NL with\ndatabase schema and instances; (2) Data: From the collection of training data,\ndata synthesis due to training data scarcity, to NL2SQL benchmarks; (3)\nEvaluation: Evaluating NL2SQL methods from multiple angles using different\nmetrics and granularities; and (4) Error Analysis: analyzing NL2SQL errors to\nfind the root cause and guiding NL2SQL models to evolve. Moreover, we provide a\nrule of thumb for developing NL2SQL solutions. Finally, we discuss the research\nchallenges and open problems of NL2SQL in the LLMs era.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "20 pages, 11 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.05109v4",
    "published_date": "2024-08-09 14:59:36 UTC",
    "updated_date": "2025-03-04 06:51:36 UTC"
  },
  {
    "arxiv_id": "2408.07091v2",
    "title": "Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning",
    "authors": [
      "Wenbin Hu",
      "Huihao Jing",
      "Qi Hu",
      "Haoran Li",
      "Yangqiu Song"
    ],
    "abstract": "Textual graphs are ubiquitous in real-world applications, featuring rich text\ninformation with complex relationships, which enables advanced research across\nvarious fields. Textual graph representation learning aims to generate\nlow-dimensional feature embeddings from textual graphs that can improve the\nperformance of downstream tasks. A high-quality feature embedding should\neffectively capture both the structural and the textual information in a\ntextual graph. However, most textual graph dataset benchmarks rely on word2vec\ntechniques to generate feature embeddings, which inherently limits their\ncapabilities. Recent works on textual graph representation learning can be\ncategorized into two folds: supervised and unsupervised methods. Supervised\nmethods finetune a language model on labeled nodes, which have limited\ncapabilities when labeled data is scarce. Unsupervised methods, on the other\nhand, extract feature embeddings by developing complex training pipelines. To\naddress these limitations, we propose a novel unified unsupervised learning\nautoencoder framework, named Node Level Graph AutoEncoder (NodeGAE). We employ\nlanguage models as the backbone of the autoencoder, with pretraining on text\nreconstruction. Additionally, we add an auxiliary loss term to make the feature\nembeddings aware of the local graph structure. Our method maintains simplicity\nin the training process and demonstrates generalizability across diverse\ntextual graphs and downstream tasks. We evaluate our method on two core graph\nrepresentation learning downstream tasks: node classification and link\nprediction. Comprehensive experiments demonstrate that our approach\nsubstantially enhances the performance of diverse graph neural networks (GNNs)\nacross multiple textual graph datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07091v2",
    "published_date": "2024-08-09 14:57:53 UTC",
    "updated_date": "2024-08-21 05:58:36 UTC"
  },
  {
    "arxiv_id": "2408.05101v1",
    "title": "MooER: LLM-based Speech Recognition and Translation Models from Moore Threads",
    "authors": [
      "Junhao Xu",
      "Zhenlin Liang",
      "Yi Liu",
      "Yichao Hu",
      "Jian Li",
      "Yajun Zheng",
      "Meng Cai",
      "Hua Wang"
    ],
    "abstract": "In this paper, we present MooER, a LLM-based large-scale automatic speech\nrecognition (ASR) / automatic speech translation (AST) model of Moore Threads.\nA 5000h pseudo labeled dataset containing open source and self collected speech\ndata is used for training. We achieve performance comparable to other open\nsource models trained with up to hundreds of thousands of hours of labeled\nspeech data. Meanwhile, experiments conducted on Covost2 Zh2en testset suggest\nthat our model outperforms other open source Speech LLMs. A BLEU score of 25.2\ncan be obtained. The main contributions of this paper are summarized as\nfollows. First, this paper presents a training strategy for encoders and LLMs\non speech related tasks (including ASR and AST) using a small size of pseudo\nlabeled data without any extra manual annotation and selection. Second, we\nrelease our ASR and AST models and plan to open-source our training code and\nstrategy in the near future. Moreover, a model trained on 8wh scale training\ndata is planned to be released later on.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05101v1",
    "published_date": "2024-08-09 14:43:56 UTC",
    "updated_date": "2024-08-09 14:43:56 UTC"
  },
  {
    "arxiv_id": "2408.05100v2",
    "title": "AI-driven Java Performance Testing: Balancing Result Quality with Testing Time",
    "authors": [
      "Luca Traini",
      "Federico Di Menna",
      "Vittorio Cortellessa"
    ],
    "abstract": "Performance testing aims at uncovering efficiency issues of software systems.\nIn order to be both effective and practical, the design of a performance test\nmust achieve a reasonable trade-off between result quality and testing time.\nThis becomes particularly challenging in Java context, where the software\nundergoes a warm-up phase of execution, due to just-in-time compilation. During\nthis phase, performance measurements are subject to severe fluctuations, which\nmay adversely affect quality of performance test results. However, these\napproaches often provide suboptimal estimates of the warm-up phase, resulting\nin either insufficient or excessive warm-up iterations, which may degrade\nresult quality or increase testing time. There is still a lack of consensus on\nhow to properly address this problem. Here, we propose and study an AI-based\nframework to dynamically halt warm-up iterations at runtime. Specifically, our\nframework leverages recent advances in AI for Time Series Classification (TSC)\nto predict the end of the warm-up phase during test execution. We conduct\nexperiments by training three different TSC models on half a million of\nmeasurement segments obtained from JMH microbenchmark executions. We find that\nour framework significantly improves the accuracy of the warm-up estimates\nprovided by state-of-practice and state-of-the-art methods. This higher\nestimation accuracy results in a net improvement in either result quality or\ntesting time for up to +35.3% of the microbenchmarks. Our study highlights that\nintegrating AI to dynamically estimate the end of the warm-up phase can enhance\nthe cost-effectiveness of Java performance testing.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication in The 39th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE '24)",
    "pdf_url": "http://arxiv.org/pdf/2408.05100v2",
    "published_date": "2024-08-09 14:41:32 UTC",
    "updated_date": "2024-09-14 11:26:31 UTC"
  },
  {
    "arxiv_id": "2408.05098v1",
    "title": "Overcoming the Limitations of Layer Synchronization in Spiking Neural Networks",
    "authors": [
      "Roel Koopman",
      "Amirreza Yousefzadeh",
      "Mahyar Shahsavari",
      "Guangzhi Tang",
      "Manolis Sifalakis"
    ],
    "abstract": "Currently, neural-network processing in machine learning applications relies\non layer synchronization, whereby neurons in a layer aggregate incoming\ncurrents from all neurons in the preceding layer, before evaluating their\nactivation function. This is practiced even in artificial Spiking Neural\nNetworks (SNNs), which are touted as consistent with neurobiology, in spite of\nprocessing in the brain being, in fact asynchronous. A truly asynchronous\nsystem however would allow all neurons to evaluate concurrently their threshold\nand emit spikes upon receiving any presynaptic current. Omitting layer\nsynchronization is potentially beneficial, for latency and energy efficiency,\nbut asynchronous execution of models previously trained with layer\nsynchronization may entail a mismatch in network dynamics and performance. We\npresent a study that documents and quantifies this problem in three datasets on\nour simulation environment that implements network asynchrony, and we show that\nmodels trained with layer synchronization either perform sub-optimally in\nabsence of the synchronization, or they will fail to benefit from any energy\nand latency reduction, when such a mechanism is in place. We then \"make ends\nmeet\" and address the problem with unlayered backprop, a novel\nbackpropagation-based training method, for learning models suitable for\nasynchronous processing. We train with it models that use different neuron\nexecution scheduling strategies, and we show that although their neurons are\nmore reactive, these models consistently exhibit lower overall spike density\n(up to 50%), reach a correct decision faster (up to 2x) without integrating all\nspikes, and achieve superior accuracy (up to 10% higher). Our findings suggest\nthat asynchronous event-based (neuromorphic) AI computing is indeed more\nefficient, but we need to seriously rethink how we train our SNN models, to\nbenefit from it.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05098v1",
    "published_date": "2024-08-09 14:39:23 UTC",
    "updated_date": "2024-08-09 14:39:23 UTC"
  },
  {
    "arxiv_id": "2408.05097v1",
    "title": "Hyperbolic Learning with Multimodal Large Language Models",
    "authors": [
      "Paolo Mandica",
      "Luca Franco",
      "Konstantinos Kallidromitis",
      "Suzanne Petryk",
      "Fabio Galasso"
    ],
    "abstract": "Hyperbolic embeddings have demonstrated their effectiveness in capturing\nmeasures of uncertainty and hierarchical relationships across various\ndeep-learning tasks, including image segmentation and active learning. However,\ntheir application in modern vision-language models (VLMs) has been limited. A\nnotable exception is MERU, which leverages the hierarchical properties of\nhyperbolic space in the CLIP ViT-large model, consisting of hundreds of\nmillions parameters. In our work, we address the challenges of scaling\nmulti-modal hyperbolic models by orders of magnitude in terms of parameters\n(billions) and training complexity using the BLIP-2 architecture. Although\nhyperbolic embeddings offer potential insights into uncertainty not present in\nEuclidean embeddings, our analysis reveals that scaling these models is\nparticularly difficult. We propose a novel training strategy for a hyperbolic\nversion of BLIP-2, which allows to achieve comparable performance to its\nEuclidean counterpart, while maintaining stability throughout the training\nprocess and showing a meaningful indication of uncertainty with each embedding.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ECCV 2024 - Beyond Euclidean Workshop",
    "pdf_url": "http://arxiv.org/pdf/2408.05097v1",
    "published_date": "2024-08-09 14:39:15 UTC",
    "updated_date": "2024-08-09 14:39:15 UTC"
  },
  {
    "arxiv_id": "2408.05093v4",
    "title": "Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models",
    "authors": [
      "Zikai Xie"
    ],
    "abstract": "Large language models (LLMs) have generated significant attention since their\ninception, finding applications across various academic and industrial domains.\nHowever, these models often suffer from the \"hallucination problem\", where\noutputs, though grammatically and logically coherent, lack factual accuracy or\nare entirely fabricated. A particularly troubling issue discovered and widely\ndiscussed recently is the numerical comparison error where multiple LLMs\nincorrectly infer that \"9.11$>$9.9\". We discovered that the order in which LLMs\ngenerate answers and reasoning impacts their consistency. Specifically, results\nvary significantly when an LLM generates an answer first and then provides the\nreasoning versus generating the reasoning process first and then the\nconclusion. Inspired by this, we propose a new benchmark method for assessing\nLLM consistency: comparing responses generated through these two different\napproaches. This benchmark effectively identifies instances where LLMs\nfabricate answers and subsequently generate justifications. Furthermore, we\nintroduce a novel and straightforward prompt strategy designed to mitigate this\nissue. Experimental results demonstrate that this strategy improves performance\nacross various LLMs compared to direct questioning. This work not only sheds\nlight on a critical flaw in LLMs but also offers a practical solution to\nenhance their reliability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, submitted to ACL ARR",
    "pdf_url": "http://arxiv.org/pdf/2408.05093v4",
    "published_date": "2024-08-09 14:34:32 UTC",
    "updated_date": "2025-05-12 01:30:34 UTC"
  },
  {
    "arxiv_id": "2408.05086v2",
    "title": "Generating novel experimental hypotheses from language models: A case study on cross-dative generalization",
    "authors": [
      "Kanishka Misra",
      "Najoung Kim"
    ],
    "abstract": "Neural network language models (LMs) have been shown to successfully capture\ncomplex linguistic knowledge. However, their utility for understanding language\nacquisition is still debated. We contribute to this debate by presenting a case\nstudy where we use LMs as simulated learners to derive novel experimental\nhypotheses to be tested with humans. We apply this paradigm to study\ncross-dative generalization (CDG): productive generalization of novel verbs\nacross dative constructions (she pilked me the ball/she pilked the ball to\nme)--acquisition of which is known to involve a large space of contextual\nfeatures--using LMs trained on child-directed speech. We specifically ask:\n\"what properties of the training exposure facilitate a novel verb's\ngeneralization to the (unmodeled) alternate construction?\" To answer this, we\nsystematically vary the exposure context in which a novel dative verb occurs in\nterms of the properties of the theme and recipient, and then analyze the LMs'\nusage of the novel verb in the unmodeled dative construction. We find LMs to\nreplicate known patterns of children's CDG, as a precondition to exploring\nnovel hypotheses. Subsequent simulations reveal a nuanced role of the features\nof the novel verbs' exposure context on the LMs' CDG. We find CDG to be\nfacilitated when the first postverbal argument of the exposure context is\npronominal, definite, short, and conforms to the prototypical animacy\nexpectations of the exposure dative. These patterns are characteristic of\nharmonic alignment in datives, where the argument with features ranking higher\non the discourse prominence scale tends to precede the other. This gives rise\nto a novel hypothesis that CDG is facilitated insofar as the features of the\nexposure context--in particular, its first postverbal argument--are\nharmonically aligned. We conclude by proposing future experiments that can test\nthis hypothesis in children.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Updated template and affiliation for first author. Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2408.05086v2",
    "published_date": "2024-08-09 14:17:36 UTC",
    "updated_date": "2024-10-28 14:30:13 UTC"
  },
  {
    "arxiv_id": "2408.05082v1",
    "title": "Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization",
    "authors": [
      "Yangdi Wang",
      "Zhi-Hai Zhang",
      "Su Xiu Xu",
      "Wenming Guo"
    ],
    "abstract": "Overfitting commonly occurs when applying deep neural networks (DNNs) on\nsmall-scale datasets, where DNNs do not generalize well from existing data to\nunseen data. The main reason resulting in overfitting is that small-scale\ndatasets cannot reflect the situations of the real world. Label smoothing (LS)\nis an effective regularization method to prevent overfitting, avoiding it by\nmixing one-hot labels with uniform label vectors. However, LS only focuses on\nlabels while ignoring the distribution of existing data. In this paper, we\nintroduce the distributionally robust optimization (DRO) to LS, achieving shift\nthe existing data distribution flexibly to unseen domains when training DNNs.\nSpecifically, we prove that the regularization of LS can be extended to a\nregularization term for the DNNs parameters when integrating DRO. The\nregularization term can be utilized to shift existing data to unseen domains\nand generate new data. Furthermore, we propose an approximate\ngradient-iteration label smoothing algorithm (GI-LS) to achieve the findings\nand train DNNs. We prove that the shift for the existing data does not\ninfluence the convergence of GI-LS. Since GI-LS incorporates a series of\nhyperparameters, we further consider using Bayesian optimization (BO) to find\nthe relatively optimal combinations of these hyperparameters. Taking\nsmall-scale anomaly classification tasks as a case, we evaluate GI-LS, and the\nresults clearly demonstrate its superior performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05082v1",
    "published_date": "2024-08-09 14:13:33 UTC",
    "updated_date": "2024-08-09 14:13:33 UTC"
  },
  {
    "arxiv_id": "2408.12619v1",
    "title": "Educational Customization by Homogenous Grouping of e-Learners based on their Learning Styles",
    "authors": [
      "Mohammadreza amiri",
      "GholamAli montazer",
      "Ebrahim Mousavi"
    ],
    "abstract": "The E-learning environment offers greater flexibility compared to\nface-to-face interactions, allowing for adapting educational content to meet\nlearners' individual needs and abilities through personalization and\ncustomization of e-content and the educational process. Despite the advantages\nof this approach, customizing the learning environment can reduce the costs of\ntutoring systems for similar learners by utilizing the same content and process\nfor co-like learning groups. Various indicators for grouping learners exist,\nbut many of them are conceptual, uncertain, and subject to change over time. In\nthis article, we propose using the Felder-Silverman model, which is based on\nlearning styles, to group similar learners. Additionally, we model the\nbehaviors and actions of e-learners in a network environment using Fuzzy Set\nTheory (FST). After identifying the learning styles of the learners, co-like\nlearning groups are formed, and each group receives adaptive content based on\ntheir preferences, needs, talents, and abilities. By comparing the results of\nthe experimental and control groups, we determine the effectiveness of the\nproposed grouping method. In terms of \"educational success,\" the weighted\naverage score of the experimental group is 17.65 out of 20, while the control\ngroup achieves a score of 12.6 out of 20. Furthermore, the \"educational\nsatisfaction\" of the experimental group is 67%, whereas the control group's\nsatisfaction level is 37%.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12619v1",
    "published_date": "2024-08-09 14:06:42 UTC",
    "updated_date": "2024-08-09 14:06:42 UTC"
  },
  {
    "arxiv_id": "2408.05074v5",
    "title": "Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records",
    "authors": [
      "Sangjoon Park",
      "Chan Woo Wee",
      "Seo Hee Choi",
      "Kyung Hwan Kim",
      "Jee Suk Chang",
      "Hong In Yoon",
      "Ik Jae Lee",
      "Yong Bae Kim",
      "Jaeho Cho",
      "Ki Chang Keum",
      "Chang Geol Lee",
      "Hwa Kyung Byun",
      "Woong Sub Koom"
    ],
    "abstract": "Accurate survival prediction in radiotherapy (RT) is critical for optimizing\ntreatment decisions. This study developed and validated the RT-Surv framework,\nwhich integrates general-domain, open-source large language models (LLMs) to\nstructure unstructured electronic health records alongside structured clinical\ndata. Using data from 34,276 patients and an external cohort of 852, the\nframework successfully transformed unstructured clinical information into\nstructured formats. Incorporating LLM-structured clinical features improved the\nconcordance index from 0.779 to 0.842 during external validation, demonstrating\na significant performance enhancement. Key LLM-structured features, such as\ndisease extent, general condition, and RT purpose, showed high predictive\nimportance and aligned closely with statistically significant predictors\nidentified through conventional statistical analyses, thereby improving model\ninterpretability. Furthermore, the framework enhanced risk stratification,\nenabling more distinct differentiation among low-, intermediate-, and high-risk\ngroups (p < 0.001) using LLM-structured clinical features. These findings\nhighlight the potential of LLMs to convert unstructured data into actionable\ninsights, improving predictive modeling and patient outcomes in clinics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 2 tables, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.05074v5",
    "published_date": "2024-08-09 14:02:24 UTC",
    "updated_date": "2024-12-11 10:14:32 UTC"
  },
  {
    "arxiv_id": "2408.05061v1",
    "title": "A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares",
    "authors": [
      "Stav Cohen",
      "Ron Bitton",
      "Ben Nassi"
    ],
    "abstract": "In this paper we argue that a jailbroken GenAI model can cause substantial\nharm to GenAI-powered applications and facilitate PromptWare, a new type of\nattack that flips the GenAI model's behavior from serving an application to\nattacking it. PromptWare exploits user inputs to jailbreak a GenAI model to\nforce/perform malicious activity within the context of a GenAI-powered\napplication. First, we introduce a naive implementation of PromptWare that\nbehaves as malware that targets Plan & Execute architectures (a.k.a., ReAct,\nfunction calling). We show that attackers could force a desired execution flow\nby creating a user input that produces desired outputs given that the logic of\nthe GenAI-powered application is known to attackers. We demonstrate the\napplication of a DoS attack that triggers the execution of a GenAI-powered\nassistant to enter an infinite loop that wastes money and computational\nresources on redundant API calls to a GenAI engine, preventing the application\nfrom providing service to a user. Next, we introduce a more sophisticated\nimplementation of PromptWare that we name Advanced PromptWare Threat (APwT)\nthat targets GenAI-powered applications whose logic is unknown to attackers. We\nshow that attackers could create user input that exploits the GenAI engine's\nadvanced AI capabilities to launch a kill chain in inference time consisting of\nsix steps intended to escalate privileges, analyze the application's context,\nidentify valuable assets, reason possible malicious activities, decide on one\nof them, and execute it. We demonstrate the application of APwT against a\nGenAI-powered e-commerce chatbot and show that it can trigger the modification\nof SQL tables, potentially leading to unauthorized discounts on the items sold\nto the user.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Website, see https://sites.google.com/view/promptware",
    "pdf_url": "http://arxiv.org/pdf/2408.05061v1",
    "published_date": "2024-08-09 13:32:50 UTC",
    "updated_date": "2024-08-09 13:32:50 UTC"
  },
  {
    "arxiv_id": "2408.05060v1",
    "title": "GLEAMS: Bridging the Gap Between Local and Global Explanations",
    "authors": [
      "Giorgio Visani",
      "Vincenzo Stanzione",
      "Damien Garreau"
    ],
    "abstract": "The explainability of machine learning algorithms is crucial, and numerous\nmethods have emerged recently. Local, post-hoc methods assign an attribution\nscore to each feature, indicating its importance for the prediction. However,\nthese methods require recalculating explanations for each example. On the other\nside, while there exist global approaches they often produce explanations that\nare either overly simplistic and unreliable or excessively complex. To bridge\nthis gap, we propose GLEAMS, a novel method that partitions the input space and\nlearns an interpretable model within each sub-region, thereby providing both\nfaithful local and global surrogates. We demonstrate GLEAMS' effectiveness on\nboth synthetic and real-world data, highlighting its desirable properties and\nhuman-understandable insights.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05060v1",
    "published_date": "2024-08-09 13:30:37 UTC",
    "updated_date": "2024-08-09 13:30:37 UTC"
  },
  {
    "arxiv_id": "2408.05057v1",
    "title": "SELD-Mamba: Selective State-Space Model for Sound Event Localization and Detection with Source Distance Estimation",
    "authors": [
      "Da Mu",
      "Zhicheng Zhang",
      "Haobo Yue",
      "Zehao Wang",
      "Jin Tang",
      "Jianqin Yin"
    ],
    "abstract": "In the Sound Event Localization and Detection (SELD) task, Transformer-based\nmodels have demonstrated impressive capabilities. However, the quadratic\ncomplexity of the Transformer's self-attention mechanism results in\ncomputational inefficiencies. In this paper, we propose a network architecture\nfor SELD called SELD-Mamba, which utilizes Mamba, a selective state-space\nmodel. We adopt the Event-Independent Network V2 (EINV2) as the foundational\nframework and replace its Conformer blocks with bidirectional Mamba blocks to\ncapture a broader range of contextual information while maintaining\ncomputational efficiency. Additionally, we implement a two-stage training\nmethod, with the first stage focusing on Sound Event Detection (SED) and\nDirection of Arrival (DoA) estimation losses, and the second stage\nreintroducing the Source Distance Estimation (SDE) loss. Our experimental\nresults on the 2024 DCASE Challenge Task3 dataset demonstrate the effectiveness\nof the selective state-space model in SELD and highlight the benefits of the\ntwo-stage training approach in enhancing SELD performance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05057v1",
    "published_date": "2024-08-09 13:26:08 UTC",
    "updated_date": "2024-08-09 13:26:08 UTC"
  },
  {
    "arxiv_id": "2408.05051v1",
    "title": "A GNN Model with Adaptive Weights for Session-Based Recommendation Systems",
    "authors": [
      "Begüm Özbay",
      "Resul Tugay",
      "Şule Gündüz Öğüdücü"
    ],
    "abstract": "Session-based recommendation systems aim to model users' interests based on\ntheir sequential interactions to predict the next item in an ongoing session.\nIn this work, we present a novel approach that can be used in session-based\nrecommendations (SBRs). Our goal is to enhance the prediction accuracy of an\nexisting session-based recommendation model, the SR-GNN model, by introducing\nan adaptive weighting mechanism applied to the graph neural network (GNN)\nvectors. This mechanism is designed to incorporate various types of side\ninformation obtained through different methods during the study. Items are\nassigned varying degrees of importance within each session as a result of the\nweighting mechanism. We hypothesize that this adaptive weighting strategy will\ncontribute to more accurate predictions and thus improve the overall\nperformance of SBRs in different scenarios. The adaptive weighting strategy can\nbe utilized to address the cold start problem in SBRs by dynamically adjusting\nthe importance of items in each session, thus providing better recommendations\nin cold start situations, such as for new users or newly added items. Our\nexperimental evaluations on the Dressipi dataset demonstrate the effectiveness\nof the proposed approach compared to traditional models in enhancing the user\nexperience and highlighting its potential to optimize the recommendation\nresults in real-world applications.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "7 pages, 7 tables, 2 figures, and 3 equations",
    "pdf_url": "http://arxiv.org/pdf/2408.05051v1",
    "published_date": "2024-08-09 13:13:43 UTC",
    "updated_date": "2024-08-09 13:13:43 UTC"
  },
  {
    "arxiv_id": "2408.05025v2",
    "title": "Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks",
    "authors": [
      "Gianluca De Stefano",
      "Lea Schönherr",
      "Giancarlo Pellegrino"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) is a technique commonly used to equip\nmodels with out of distribution knowledge. This process involves collecting,\nindexing, retrieving, and providing information to an LLM for generating\nresponses. Despite its growing popularity due to its flexibility and low cost,\nthe security implications of RAG have not been extensively studied. The data\nfor such systems are often collected from public sources, providing an attacker\na gateway for indirect prompt injections to manipulate the responses of the\nmodel. In this paper, we investigate the security of RAG systems against\nend-to-end indirect prompt manipulations. First, we review existing RAG\nframework pipelines, deriving a prototypical architecture and identifying\ncritical parameters. We then examine prior works searching for techniques that\nattackers can use to perform indirect prompt manipulations. Finally, we\nimplemented Rag 'n Roll, a framework to determine the effectiveness of attacks\nagainst end-to-end RAG applications. Our results show that existing attacks are\nmostly optimized to boost the ranking of malicious documents during the\nretrieval phase. However, a higher rank does not immediately translate into a\nreliable attack. Most attacks, against various configurations, settle around a\n40% success rate, which could rise to 60% when considering ambiguous answers as\nsuccessful attacks (those that include the expected benign one as well).\nAdditionally, when using unoptimized documents, attackers deploying two of them\n(or more) for a target query can achieve similar results as those using\noptimized ones. Finally, exploration of the configuration space of a RAG showed\nlimited impact in thwarting the attacks, where the most successful combination\nseverely undermines functionality.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05025v2",
    "published_date": "2024-08-09 12:26:05 UTC",
    "updated_date": "2024-08-12 13:57:42 UTC"
  },
  {
    "arxiv_id": "2408.05006v3",
    "title": "COAST: Enhancing the Code Debugging Ability of LLMs through Communicative Agent Based Data Synthesis",
    "authors": [
      "Weiqing Yang",
      "Hanbin Wang",
      "Zhenghao Liu",
      "Xinze Li",
      "Yukun Yan",
      "Shuo Wang",
      "Yu Gu",
      "Minghe Yu",
      "Zhiyuan Liu",
      "Ge Yu"
    ],
    "abstract": "Code debugging is a vital stage of software development, essential for\nensuring the reliability and performance of Large Language Models (LLMs) in the\ncode generation task. Human debugging typically follows a multi-stage process,\nwhich includes Bug Localization, Bug Identification, Code Repair, and Code\nRecognition. However, existing code debugging benchmarks predominantly focus on\nthe Code Repair stage, which offers only a limited perspective on evaluating\nthe debugging capabilities of LLMs. In this paper, we introduce DEBUGEVAL, a\ncomprehensive benchmark for evaluating the debugging abilities of LLMs by\nemulating the multi-stage human debugging process. Through evaluating on\nDEBUGEVAL, we observe that 7B-scale models consistently underperform compared\nto their larger counterparts, highlighting their limitations in comprehending\ncode semantics. In this case, we propose the COmmunicative Agent-based data\nSynThesis (COAST) framework, which employs a multi-agent system to generate\nhigh-quality training data for supervised fine-tuning (SFT). Experimental\nresults demonstrate that COAST-generated data outperform human-curated and\nGPT-4-generated data, enabling 7B-scale LLMs to achieve debugging performance\ncomparable to GPT-3.5. All data and codes are available at\nhttps://github.com/NEUIR/COAST.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05006v3",
    "published_date": "2024-08-09 11:35:44 UTC",
    "updated_date": "2025-02-12 04:02:33 UTC"
  },
  {
    "arxiv_id": "2408.11063v1",
    "title": "Tabular Transfer Learning via Prompting LLMs",
    "authors": [
      "Jaehyun Nam",
      "Woomin Song",
      "Seong Hyeon Park",
      "Jihoon Tack",
      "Sukmin Yun",
      "Jaehyung Kim",
      "Kyu Hwan Oh",
      "Jinwoo Shin"
    ],
    "abstract": "Learning with a limited number of labeled data is a central problem in\nreal-world applications of machine learning, as it is often expensive to obtain\nannotations. To deal with the scarcity of labeled data, transfer learning is a\nconventional approach; it suggests to learn a transferable knowledge by\ntraining a neural network from multiple other sources. In this paper, we\ninvestigate transfer learning of tabular tasks, which has been less studied and\nsuccessful in the literature, compared to other domains, e.g., vision and\nlanguage. This is because tables are inherently heterogeneous, i.e., they\ncontain different columns and feature spaces, making transfer learning\ndifficult. On the other hand, recent advances in natural language processing\nsuggest that the label scarcity issue can be mitigated by utilizing in-context\nlearning capability of large language models (LLMs). Inspired by this and the\nfact that LLMs can also process tables within a unified language space, we ask\nwhether LLMs can be effective for tabular transfer learning, in particular,\nunder the scenarios where the source and target datasets are of different\nformat. As a positive answer, we propose a novel tabular transfer learning\nframework, coined Prompt to Transfer (P2T), that utilizes unlabeled (or\nheterogeneous) source data with LLMs. Specifically, P2T identifies a column\nfeature in a source dataset that is strongly correlated with a target task\nfeature to create examples relevant to the target task, thus creating\npseudo-demonstrations for prompts. Experimental results demonstrate that P2T\noutperforms previous methods on various tabular learning benchmarks, showing\ngood promise for the important, yet underexplored tabular transfer learning\nproblem. Code is available at https://github.com/jaehyun513/P2T.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.11063v1",
    "published_date": "2024-08-09 11:30:52 UTC",
    "updated_date": "2024-08-09 11:30:52 UTC"
  },
  {
    "arxiv_id": "2408.04998v1",
    "title": "ProFuser: Progressive Fusion of Large Language Models",
    "authors": [
      "Tianyuan Shi",
      "Fanqi Wan",
      "Canbin Huang",
      "Xiaojun Quan",
      "Chenliang Li",
      "Ming Yan",
      "Ji Zhang"
    ],
    "abstract": "While fusing the capacities and advantages of various large language models\n(LLMs) offers a pathway to construct more powerful and versatile models, a\nfundamental challenge is to properly select advantageous model during the\ntraining. Existing fusion methods primarily focus on the training mode that\nuses cross entropy on ground truth in a teacher-forcing setup to measure a\nmodel's advantage, which may provide limited insight towards model advantage.\nIn this paper, we introduce a novel approach that enhances the fusion process\nby incorporating both the training and inference modes. Our method evaluates\nmodel advantage not only through cross entropy during training but also by\nconsidering inference outputs, providing a more comprehensive assessment. To\ncombine the two modes effectively, we introduce ProFuser to progressively\ntransition from inference mode to training mode. To validate ProFuser's\neffectiveness, we fused three models, including vicuna-7b-v1.5,\nLlama-2-7b-chat, and mpt-7b-8k-chat, and demonstrated the improved performance\nin knowledge, reasoning, and safety compared to baseline methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04998v1",
    "published_date": "2024-08-09 11:18:29 UTC",
    "updated_date": "2024-08-09 11:18:29 UTC"
  },
  {
    "arxiv_id": "2408.04996v1",
    "title": "On the use of neurosymbolic AI for defending against cyber attacks",
    "authors": [
      "Gudmund Grov",
      "Jonas Halvorsen",
      "Magnus Wiik Eckhoff",
      "Bjørn Jervell Hansen",
      "Martin Eian",
      "Vasileios Mavroeidis"
    ],
    "abstract": "It is generally accepted that all cyber attacks cannot be prevented, creating\na need for the ability to detect and respond to cyber attacks. Both\nconnectionist and symbolic AI are currently being used to support such\ndetection and response. In this paper, we make the case for combining them\nusing neurosymbolic AI. We identify a set of challenges when using AI today and\npropose a set of neurosymbolic use cases we believe are both interesting\nresearch directions for the neurosymbolic AI community and can have an impact\non the cyber security field. We demonstrate feasibility through two\nproof-of-concept experiments.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to 18th International Conference on Neural-Symbolic Learning\n  and Reasoning",
    "pdf_url": "http://arxiv.org/pdf/2408.04996v1",
    "published_date": "2024-08-09 11:14:06 UTC",
    "updated_date": "2024-08-09 11:14:06 UTC"
  },
  {
    "arxiv_id": "2408.04957v4",
    "title": "LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description",
    "authors": [
      "Yizhang Jin",
      "Jian Li",
      "Jiangning Zhang",
      "Jianlong Hu",
      "Zhenye Gan",
      "Xin Tan",
      "Yong Liu",
      "Yabiao Wang",
      "Chengjie Wang",
      "Lizhuang Ma"
    ],
    "abstract": "Visual Spatial Description (VSD) aims to generate texts that describe the\nspatial relationships between objects within images. Traditional visual spatial\nrelationship classification (VSRC) methods typically output the spatial\nrelationship between two objects in an image, often neglecting world knowledge\nand lacking general language capabilities. In this paper, we propose a Large\nLanguage-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD,\nwhich is designed for the classification, description, and open-ended\ndescription of visual spatial relationships. Specifically, the model first\nconstructs a VSD instruction-following dataset using given figure-caption pairs\nfor the three tasks. It then employs LoRA to fine-tune a Large Language and\nVision Assistant for VSD, which has 13 billion parameters and supports\nhigh-resolution images. Finally, a large language model (Qwen-2) is used to\nrefine the generated sentences, enhancing their diversity and accuracy.\nLLaVA-VSD demonstrates excellent multimodal conversational capabilities and can\nfollow open-ended instructions to assist with inquiries about object\nrelationships in images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "We have discovered a significant error in the paper that affects the\n  main conclusions. To ensure the accuracy of our research, we have decided to\n  withdraw this paper and will resubmit it after making the necessary\n  corrections",
    "pdf_url": "http://arxiv.org/pdf/2408.04957v4",
    "published_date": "2024-08-09 09:22:40 UTC",
    "updated_date": "2024-10-30 02:38:29 UTC"
  },
  {
    "arxiv_id": "2408.05258v1",
    "title": "scASDC: Attention Enhanced Structural Deep Clustering for Single-cell RNA-seq Data",
    "authors": [
      "Wenwen Min",
      "Zhen Wang",
      "Fangfang Zhu",
      "Taosheng Xu",
      "Shunfang Wang"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is pivotal for\nunderstanding cellular heterogeneity. However, the high sparsity and complex\nnoise patterns inherent in scRNA-seq data present significant challenges for\ntraditional clustering methods. To address these issues, we propose a deep\nclustering method, Attention-Enhanced Structural Deep Embedding Graph\nClustering (scASDC), which integrates multiple advanced modules to improve\nclustering accuracy and robustness.Our approach employs a multi-layer graph\nconvolutional network (GCN) to capture high-order structural relationships\nbetween cells, termed as the graph autoencoder module. To mitigate the\noversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module that\nextracts content information from the data and learns latent representations of\ngene expression. These modules are further integrated through an attention\nfusion mechanism, ensuring effective combination of gene expression and\nstructural information at each layer of the GCN. Additionally, a\nself-supervised learning module is incorporated to enhance the robustness of\nthe learned embeddings. Extensive experiments demonstrate that scASDC\noutperforms existing state-of-the-art methods, providing a robust and effective\nsolution for single-cell clustering tasks. Our method paves the way for more\naccurate and meaningful analysis of single-cell RNA sequencing data,\ncontributing to better understanding of cellular heterogeneity and biological\nprocesses. All code and public datasets used in this paper are available at\n\\url{https://github.com/wenwenmin/scASDC} and\n\\url{https://zenodo.org/records/12814320}.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05258v1",
    "published_date": "2024-08-09 09:10:36 UTC",
    "updated_date": "2024-08-09 09:10:36 UTC"
  },
  {
    "arxiv_id": "2409.18132v2",
    "title": "Decomposition of one-layer neural networks via the infinite sum of reproducing kernel Banach spaces",
    "authors": [
      "Seungcheol Shin",
      "Myungjoo Kang"
    ],
    "abstract": "In this paper, we define the sum of RKBSs using the characterization theorem\nof RKBSs and show that the sum of RKBSs is compatible with the direct sum of\nfeature spaces. Moreover, we decompose the integral RKBS into the sum of\n$p$-norm RKBSs. Finally, we provide applications for the structural\nunderstanding of the integral RKBS class.",
    "categories": [
      "math.FA",
      "cs.AI"
    ],
    "primary_category": "math.FA",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.18132v2",
    "published_date": "2024-08-09 09:10:29 UTC",
    "updated_date": "2025-04-01 10:21:48 UTC"
  },
  {
    "arxiv_id": "2408.04949v1",
    "title": "CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning",
    "authors": [
      "Gianluca Carloni",
      "Sotirios A Tsaftaris",
      "Sara Colantonio"
    ],
    "abstract": "Due to domain shift, deep learning image classifiers perform poorly when\napplied to a domain different from the training one. For instance, a classifier\ntrained on chest X-ray (CXR) images from one hospital may not generalize to\nimages from another hospital due to variations in scanner settings or patient\ncharacteristics. In this paper, we introduce our CROCODILE framework, showing\nhow tools from causality can foster a model's robustness to domain shift via\nfeature disentanglement, contrastive learning losses, and the injection of\nprior knowledge. This way, the model relies less on spurious correlations,\nlearns the mechanism bringing from images to prediction better, and outperforms\nbaselines on out-of-distribution (OOD) data. We apply our method to multi-label\nlung disease classification from CXRs, utilizing over 750000 images from four\ndatasets. Our bias-mitigation method improves domain generalization and\nfairness, broadening the applicability and reliability of deep learning models\nfor a safer medical image analysis. Find our code at:\nhttps://github.com/gianlucarloni/crocodile.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.2; I.4; I.5; J.3; J.6"
    ],
    "primary_category": "eess.IV",
    "comment": "MICCAI 2024 UNSURE Workshop, Accepted for presentation, Submitted\n  Manuscript Version, 10 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.04949v1",
    "published_date": "2024-08-09 09:08:06 UTC",
    "updated_date": "2024-08-09 09:08:06 UTC"
  },
  {
    "arxiv_id": "2408.07089v1",
    "title": "InfinityMATH: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning",
    "authors": [
      "Bo-Wen Zhang",
      "Yan Yan",
      "Lin Li",
      "Guang Liu"
    ],
    "abstract": "Recent advancements in Chain-of-Thoughts (CoT) and Program-of-Thoughts (PoT)\nmethods have greatly enhanced language models' mathematical reasoning\ncapabilities, facilitating their integration into instruction tuning datasets\nwith LLMs. However, existing methods for large-scale dataset creation require\nsubstantial seed data and high computational costs for data synthesis, posing\nsignificant challenges for scalability. We introduce InfinityMATH, a scalable\ninstruction tuning dataset for programmatic mathematical reasoning. The\nconstruction pipeline emphasizes decoupling numbers from mathematical problems\nto synthesize number-independent programs, enabling efficient and flexible\nscaling while minimizing dependency on specific numerical values. Fine-tuning\nexperiments with open-source language and code models, such as Llama2 and\nCodeLlama, demonstrate the practical benefits of InfinityMATH. These fine-tuned\nmodels, showed significant relative improvements on both in-domain and\nout-of-domain benchmarks, ranging from 184.7% to 514.3% on average.\nAdditionally, these models exhibited high robustness on the GSM8K+ and MATH+\nbenchmarks, which are enhanced version of test sets with simply the number\nvariations. InfinityMATH ensures that models are more versatile and effective\nacross a broader range of mathematical problems. The data is available at\nhttps://huggingface.co/datasets/flagopen/InfinityMATH.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CIKM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07089v1",
    "published_date": "2024-08-09 08:18:20 UTC",
    "updated_date": "2024-08-09 08:18:20 UTC"
  },
  {
    "arxiv_id": "2408.04922v2",
    "title": "UAV-Enhanced Combination to Application: Comprehensive Analysis and Benchmarking of a Human Detection Dataset for Disaster Scenarios",
    "authors": [
      "Ragib Amin Nihal",
      "Benjamin Yen",
      "Katsutoshi Itoyama",
      "Kazuhiro Nakadai"
    ],
    "abstract": "Unmanned aerial vehicles (UAVs) have revolutionized search and rescue (SAR)\noperations, but the lack of specialized human detection datasets for training\nmachine learning models poses a significant challenge.To address this gap, this\npaper introduces the Combination to Application (C2A) dataset, synthesized by\noverlaying human poses onto UAV-captured disaster scenes. Through extensive\nexperimentation with state-of-the-art detection models, we demonstrate that\nmodels fine-tuned on the C2A dataset exhibit substantial performance\nimprovements compared to those pre-trained on generic aerial datasets.\nFurthermore, we highlight the importance of combining the C2A dataset with\ngeneral human datasets to achieve optimal performance and generalization across\nvarious scenarios. This points out the crucial need for a tailored dataset to\nenhance the effectiveness of SAR operations. Our contributions also include\ndeveloping dataset creation pipeline and integrating diverse human poses and\ndisaster scenes information to assess the severity of disaster scenarios. Our\nfindings advocate for future developments, to ensure that SAR operations\nbenefit from the most realistic and effective AI-assisted interventions\npossible.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This Paper is accepted for 27th International Conference on Pattern\n  Recognition (ICPR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.04922v2",
    "published_date": "2024-08-09 08:07:19 UTC",
    "updated_date": "2024-08-23 18:01:25 UTC"
  },
  {
    "arxiv_id": "2408.04917v2",
    "title": "Avoid Wasted Annotation Costs in Open-set Active Learning with Pre-trained Vision-Language Model",
    "authors": [
      "Jaehyuk Heo",
      "Pilsung Kang"
    ],
    "abstract": "Active learning (AL) aims to enhance model performance by selectively\ncollecting highly informative data, thereby minimizing annotation costs.\nHowever, in practical scenarios, unlabeled data may contain out-of-distribution\n(OOD) samples, which are not used for training, leading to wasted annotation\ncosts if data is incorrectly selected. Therefore, to make active learning\nfeasible in real-world applications, it is crucial to consider not only the\ninformativeness of unlabeled samples but also their purity to determine whether\nthey belong to the in-distribution (ID). Recent studies have applied AL under\nthese assumptions, but challenges remain due to the trade-off between\ninformativeness and purity, as well as the heavy dependence on OOD samples.\nThese issues lead to the collection of OOD samples, resulting in a significant\nwaste of annotation costs. To address these challenges, we propose a novel\nquery strategy, VLPure-AL, which minimizes cost losses while reducing\ndependence on OOD samples. VLPure-AL sequentially evaluates the purity and\ninformativeness of data. First, it utilizes a pre-trained vision-language model\nto detect and exclude OOD data with high accuracy by leveraging linguistic and\nvisual information of ID data. Second, it selects highly informative data from\nthe remaining ID data, and then the selected samples are annotated by human\nexperts. Experimental results on datasets with various open-set conditions\ndemonstrate that VLPure-AL achieves the lowest cost loss and highest\nperformance across all scenarios. Code is available at\nhttps://github.com/DSBA-Lab/OpenAL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04917v2",
    "published_date": "2024-08-09 07:54:57 UTC",
    "updated_date": "2025-04-13 07:31:39 UTC"
  },
  {
    "arxiv_id": "2408.15252v1",
    "title": "Generative AI on SpectrumNet: An Open Benchmark of Multiband 3D Radio Maps",
    "authors": [
      "Shuhang Zhang",
      "Shuai Jiang",
      "Wanjie Lin",
      "Zheng Fang",
      "Kangjun Liu",
      "Hongliang Zhang",
      "Ke Chen"
    ],
    "abstract": "Radio map is an efficient demonstration for visually displaying the wireless\nsignal coverage within a certain region. It has been considered to be\nincreasingly helpful for the future sixth generation (6G) of wireless networks,\nas wireless nodes are becoming more crowded and complicated. However, the\nconstruction of high resolution radio map is very challenging due to the sparse\nsampling in practical systems. Generative artificial intelligence (AI), which\nis capable to create synthetic data to fill in gaps in real-world measurements,\nis an effective technique to construct high precision radio maps. Currently,\ngenerative models for radio map construction are trained with two-dimension\n(2D) single band radio maps in urban scenario, which has poor generalization in\ndiverse terrain scenarios, spectrum bands, and heights. To tackle this problem,\nwe provide a multiband three-dimension (3D) radio map dataset with\nconsideration of terrain and climate information, named SpectrumNet. It is the\nlargest radio map dataset in terms of dimensions and scale, which contains the\nradio map of 3 spacial dimensions, 5 frequency bands, 11 terrain scenarios, and\n3 climate scenarios. We introduce the parameters and settings for the\nSpectrumNet dataset generation, and evaluate three baseline methods for radio\nmap construction based on the SpectrumNet dataset. Experiments show the\nnecessity of the SpectrumNet dataset for training models with strong\ngeneralization in spacial, frequency, and scenario domains. Future works on the\nSpectrumNet dataset are also discussed, including the dataset expansion and\ncalibration, as well as the extended studies on generative models for radio map\nconstruction based on the SpectrumNet dataset.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "30 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.15252v1",
    "published_date": "2024-08-09 07:54:11 UTC",
    "updated_date": "2024-08-09 07:54:11 UTC"
  },
  {
    "arxiv_id": "2408.04913v1",
    "title": "Knowledge Base Embeddings: Semantics and Theoretical Properties",
    "authors": [
      "Camille Bourgaux",
      "Ricardo Guimarães",
      "Raoul Koudijs",
      "Victor Lacerda",
      "Ana Ozaki"
    ],
    "abstract": "Research on knowledge graph embeddings has recently evolved into knowledge\nbase embeddings, where the goal is not only to map facts into vector spaces but\nalso constrain the models so that they take into account the relevant\nconceptual knowledge available. This paper examines recent methods that have\nbeen proposed to embed knowledge bases in description logic into vector spaces\nthrough the lens of their geometric-based semantics. We identify several\nrelevant theoretical properties, which we draw from the literature and\nsometimes generalize or unify. We then investigate how concrete embedding\nmethods fit in this theoretical framework.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "This is an extended version of a paper appearing at the 21st\n  International Conference on Principles of Knowledge Representation and\n  Reasoning (KR 2024). 17 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.04913v1",
    "published_date": "2024-08-09 07:43:28 UTC",
    "updated_date": "2024-08-09 07:43:28 UTC"
  },
  {
    "arxiv_id": "2408.11062v1",
    "title": "Interactive-T2S: Multi-Turn Interactions for Text-to-SQL with Large Language Models",
    "authors": [
      "Guanming Xiong",
      "Junwei Bao",
      "Hongfei Jiang",
      "Yang Song",
      "Wen Zhao"
    ],
    "abstract": "This study explores text-to-SQL parsing by leveraging the powerful reasoning\ncapabilities of large language models (LLMs). Despite recent advancements,\nexisting LLM-based methods have not adequately addressed scalability, leading\nto inefficiencies when processing wide tables. Furthermore, current\ninteraction-based approaches either lack a step-by-step, interpretable SQL\ngeneration process or fail to provide an efficient and universally applicable\ninteraction design. To address these challenges, we introduce Interactive-T2S,\na framework that generates SQL queries through direct interactions with\ndatabases. This framework includes four general tools that facilitate proactive\nand efficient information retrieval by the LLM. Additionally, we have developed\ndetailed exemplars to demonstrate the step-wise reasoning processes within our\nframework. Our experiments on the BIRD-Dev dataset, employing a setting without\noracle knowledge, reveal that our method achieves state-of-the-art results with\nonly two exemplars, underscoring the effectiveness and robustness of our\nframework.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.11062v1",
    "published_date": "2024-08-09 07:43:21 UTC",
    "updated_date": "2024-08-09 07:43:21 UTC"
  },
  {
    "arxiv_id": "2408.04910v5",
    "title": "Unleashing Artificial Cognition: Integrating Multiple AI Systems",
    "authors": [
      "Muntasir Adnan",
      "Buddhi Gamage",
      "Zhiwei Xu",
      "Damith Herath",
      "Carlos C. N. Kuhn"
    ],
    "abstract": "In this study, we present an innovative fusion of language models and query\nanalysis techniques to unlock cognition in artificial intelligence. The\nintroduced open-source AI system seamlessly integrates a Chess engine with a\nlanguage model, enabling it to predict moves and provide strategic\nexplanations. Leveraging a vector database to achieve retrievable answer\ngeneration, our AI system elucidates its decision-making process, bridging the\ngap between raw computation and human-like understanding. Our choice of Chess\nas the demonstration environment underscores the versatility of our approach.\nBeyond Chess, our system holds promise for diverse applications, from medical\ndiagnostics to financial forecasting. Our AI system is available at\nhttps://github.com/TheOpenSI/CoSMIC.git",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper is accepted to Australasian Conference on Information\n  Systems 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04910v5",
    "published_date": "2024-08-09 07:36:30 UTC",
    "updated_date": "2024-10-17 22:54:23 UTC"
  },
  {
    "arxiv_id": "2408.04906v1",
    "title": "Towards a Generative Approach for Emotion Detection and Reasoning",
    "authors": [
      "Ankita Bhaumik",
      "Tomek Strzalkowski"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive performance in\nmathematical and commonsense reasoning tasks using chain-of-thought (CoT)\nprompting techniques. But can they perform emotional reasoning by concatenating\n`Let's think step-by-step' to the input prompt? In this paper we investigate\nthis question along with introducing a novel approach to zero-shot emotion\ndetection and emotional reasoning using LLMs. Existing state of the art\nzero-shot approaches rely on textual entailment models to choose the most\nappropriate emotion label for an input text. We argue that this strongly\nrestricts the model to a fixed set of labels which may not be suitable or\nsufficient for many applications where emotion analysis is required. Instead,\nwe propose framing the problem of emotion analysis as a generative\nquestion-answering (QA) task. Our approach uses a two step methodology of\ngenerating relevant context or background knowledge to answer the emotion\ndetection question step-by-step. Our paper is the first work on using a\ngenerative approach to jointly address the tasks of emotion detection and\nemotional reasoning for texts. We evaluate our approach on two popular emotion\ndetection datasets and also release the fine-grained emotion labels and\nexplanations for further training and fine-tuning of emotional reasoning\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04906v1",
    "published_date": "2024-08-09 07:20:15 UTC",
    "updated_date": "2024-08-09 07:20:15 UTC"
  },
  {
    "arxiv_id": "2408.04905v2",
    "title": "GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models",
    "authors": [
      "Zhibo Zhang",
      "Wuxia Bai",
      "Yuxi Li",
      "Mark Huasong Meng",
      "Kailong Wang",
      "Ling Shi",
      "Li Li",
      "Jun Wang",
      "Haoyu Wang"
    ],
    "abstract": "Large language models (LLMs) have achieved unprecedented success in the field\nof natural language processing. However, the black-box nature of their internal\nmechanisms has brought many concerns about their trustworthiness and\ninterpretability. Recent research has discovered a class of abnormal tokens in\nthe model's vocabulary space and named them \"glitch tokens\". Those tokens, once\nincluded in the input, may induce the model to produce incorrect, irrelevant,\nor even harmful results, drastically undermining the reliability and\npracticality of LLMs.\n  In this work, we aim to enhance the understanding of glitch tokens and\npropose techniques for their detection and mitigation. We first reveal the\ncharacteristic features induced by glitch tokens on LLMs, which are evidenced\nby significant deviations in the distributions of attention patterns and\ndynamic information from intermediate model layers. Based on the insights, we\ndevelop GlitchProber, a tool for efficient glitch token detection and\nmitigation. GlitchProber utilizes small-scale sampling, principal component\nanalysis for accelerated feature extraction, and a simple classifier for\nefficient vocabulary screening. Taking one step further, GlitchProber rectifies\nabnormal model intermediate layer values to mitigate the destructive effects of\nglitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber\ndemonstrates higher efficiency, precision, and recall compared to existing\napproaches, with an average F1 score of 0.86 and an average repair rate of\n50.06%. GlitchProber unveils a novel path to address the challenges posed by\nglitch tokens and inspires future research toward more robust and interpretable\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04905v2",
    "published_date": "2024-08-09 07:19:53 UTC",
    "updated_date": "2024-09-23 03:46:55 UTC"
  },
  {
    "arxiv_id": "2408.04903v2",
    "title": "Axiomatic Characterisations of Sample-based Explainers",
    "authors": [
      "Leila Amgoud",
      "Martin C. Cooper",
      "Salim Debbaoui"
    ],
    "abstract": "Explaining decisions of black-box classifiers is both important and\ncomputationally challenging. In this paper, we scrutinize explainers that\ngenerate feature-based explanations from samples or datasets. We start by\npresenting a set of desirable properties that explainers would ideally satisfy,\ndelve into their relationships, and highlight incompatibilities of some of\nthem. We identify the entire family of explainers that satisfy two key\nproperties which are compatible with all the others. Its instances provide\nsufficient reasons, called weak abductive explanations.We then unravel its\nvarious subfamilies that satisfy subsets of compatible properties. Indeed, we\nfully characterize all the explainers that satisfy any subset of compatible\nproperties. In particular, we introduce the first (broad family of) explainers\nthat guarantee the existence of explanations and their global consistency.We\ndiscuss some of its instances including the irrefutable explainer and the\nsurrogate explainer whose explanations can be found in polynomial time.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04903v2",
    "published_date": "2024-08-09 07:10:07 UTC",
    "updated_date": "2024-08-12 07:04:56 UTC"
  },
  {
    "arxiv_id": "2408.04895v3",
    "title": "Better Not to Propagate: Understanding Edge Uncertainty and Over-smoothing in Signed Graph Neural Networks",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chong-Kwon Kim"
    ],
    "abstract": "Traditional Graph Neural Networks (GNNs) rely on network homophily, which can\nlead to performance degradation due to over-smoothing in many real-world\nheterophily scenarios. Recent studies analyze the smoothing effect\n(separability) after message-passing (MP), depending on the expectation of node\nfeatures. Regarding separability gain, they provided theoretical backgrounds on\nover-smoothing caused by various propagation schemes, including positive,\nsigned, and blocked MPs. More recently, by extending these theorems, some works\nhave suggested improvements in signed propagation under multiple classes.\nHowever, prior works assume that the error ratio of all propagation schemes is\nfixed, failing to investigate this phenomenon correctly. To solve this problem,\nwe propose a novel method for estimating homophily and edge error ratio,\nintegrated with dynamic selection between blocked and signed propagation during\ntraining. Our theoretical analysis, supported by extensive experiments,\ndemonstrates that blocking MP can be more effective than signed propagation\nunder high edge error ratios, improving the performance in both homophilic and\nheterophilic graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04895v3",
    "published_date": "2024-08-09 06:46:06 UTC",
    "updated_date": "2024-11-02 06:10:08 UTC"
  },
  {
    "arxiv_id": "2408.04870v5",
    "title": "ConfusedPilot: Confused Deputy Risks in RAG-based LLMs",
    "authors": [
      "Ayush RoyChowdhury",
      "Mulong Luo",
      "Prateek Sahu",
      "Sarbartha Banerjee",
      "Mohit Tiwari"
    ],
    "abstract": "Retrieval augmented generation (RAG) is a process where a large language\nmodel (LLM) retrieves useful information from a database and then generates the\nresponses. It is becoming popular in enterprise settings for daily business\noperations. For example, Copilot for Microsoft 365 has accumulated millions of\nbusinesses. However, the security implications of adopting such RAG-based\nsystems are unclear.\n  In this paper, we introduce ConfusedPilot, a class of security\nvulnerabilities of RAG systems that confuse Copilot and cause integrity and\nconfidentiality violations in its responses. First, we investigate a\nvulnerability that embeds malicious text in the modified prompt in RAG,\ncorrupting the responses generated by the LLM. Second, we demonstrate a\nvulnerability that leaks secret data, which leverages the caching mechanism\nduring retrieval. Third, we investigate how both vulnerabilities can be\nexploited to propagate misinformation within the enterprise and ultimately\nimpact its operations, such as sales and manufacturing. We also discuss the\nroot cause of these attacks by investigating the architecture of a RAG-based\nsystem. This study highlights the security vulnerabilities in today's RAG-based\nsystems and proposes design guidelines to secure future RAG-based systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04870v5",
    "published_date": "2024-08-09 05:20:05 UTC",
    "updated_date": "2024-10-23 05:55:31 UTC"
  },
  {
    "arxiv_id": "2408.15248v1",
    "title": "AI-Powered Camera and Sensors for the Rehabilitation Hand Exoskeleton",
    "authors": [
      "Md Abdul Baset Sarker",
      "Juan Pablo Sola-thomas",
      "Masudul H. Imtiaz"
    ],
    "abstract": "Due to Motor Neurone Diseases, a large population remains disabled worldwide,\nnegatively impacting their independence and quality of life. This typically\ninvolves a weakness in the hand and forearm muscles, making it difficult to\nperform fine motor tasks such as writing, buttoning a shirt, or gripping\nobjects. This project presents a vision-enabled rehabilitation hand exoskeleton\nto assist disabled persons in their hand movements. The design goal was to\ncreate an accessible tool to help with a simple interface requiring no\ntraining. This prototype is built on a commercially available glove where a\ncamera and embedded processor were integrated to help open and close the hand,\nusing air pressure, thus grabbing an object. An accelerometer is also\nimplemented to detect the characteristic hand gesture to release the object\nwhen desired. This passive vision-based control differs from active EMG-based\ndesigns as it does not require individualized training. Continuing the research\nwill reduce the cost, weight, and power consumption to facilitate mass\nimplementation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.15248v1",
    "published_date": "2024-08-09 04:47:37 UTC",
    "updated_date": "2024-08-09 04:47:37 UTC"
  },
  {
    "arxiv_id": "2408.08894v2",
    "title": "Enhancing Exploratory Learning through Exploratory Search with the Emergence of Large Language Models",
    "authors": [
      "Yiming Luo",
      "Patrick Cheong-Iao Pang",
      "Shanton Chang"
    ],
    "abstract": "In the information era, how learners find, evaluate, and effectively use\ninformation has become a challenging issue, especially with the added\ncomplexity of large language models (LLMs) that have further confused learners\nin their information retrieval and search activities. This study attempts to\nunpack this complexity by combining exploratory search strategies with the\ntheories of exploratory learning to form a new theoretical model of exploratory\nlearning from the perspective of students' learning. Our work adapts Kolb's\nlearning model by incorporating high-frequency exploration and feedback loops,\naiming to promote deep cognitive and higher-order cognitive skill development\nin students. Additionally, this paper discusses and suggests how advanced LLMs\nintegrated into information retrieval and information theory can support\nstudents in their exploratory searches, contributing theoretically to promoting\nstudent-computer interaction and supporting their learning journeys in the new\nera with LLMs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, 7 figures Accpted by HICSS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08894v2",
    "published_date": "2024-08-09 04:30:16 UTC",
    "updated_date": "2025-01-05 08:33:16 UTC"
  },
  {
    "arxiv_id": "2408.04849v1",
    "title": "Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture",
    "authors": [
      "Kai Jiang",
      "Honghao Yang",
      "Yuexian Wang",
      "Qianru Chen",
      "Yiming Luo"
    ],
    "abstract": "The mental health assessment of middle school students has always been one of\nthe focuses in the field of education. This paper introduces a new ensemble\nlearning network based on BERT, employing the concept of enhancing model\nperformance by integrating multiple classifiers. We trained a range of\nBERT-based learners, which combined using the majority voting method. We\ncollect social network text data of middle school students through China's\nWeibo and apply the method to the task of classifying emotional tendencies in\nmiddle school students' social network texts. Experimental results suggest that\nthe ensemble learning network has a better performance than the base model and\nthe performance of the ensemble learning model, consisting of three\nsingle-layer BERT models, is barely the same as a three-layer BERT model but\nrequires 11.58% more training time. Therefore, in terms of balancing prediction\neffect and efficiency, the deeper BERT network should be preferred for\ntraining. However, for interpretability, network ensembles can provide\nacceptable solutions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04849v1",
    "published_date": "2024-08-09 03:57:31 UTC",
    "updated_date": "2024-08-09 03:57:31 UTC"
  },
  {
    "arxiv_id": "2409.14248v3",
    "title": "Higher-order-ReLU-KANs (HRKANs) for solving physics-informed neural networks (PINNs) more accurately, robustly and faster",
    "authors": [
      "Chi Chiu So",
      "Siu Pang Yung"
    ],
    "abstract": "Finding solutions to partial differential equations (PDEs) is an important\nand essential component in many scientific and engineering discoveries. One of\nthe common approaches empowered by deep learning is Physics-informed Neural\nNetworks (PINNs). Recently, a new type of fundamental neural network model,\nKolmogorov-Arnold Networks (KANs), has been proposed as a substitute of\nMultilayer Perceptions (MLPs), and possesses trainable activation functions. To\nenhance KANs in fitting accuracy, a modification of KANs, so called ReLU-KANs,\nusing \"square of ReLU\" as the basis of its activation functions, has been\nsuggested. In this work, we propose another basis of activation functions,\nnamely, Higherorder-ReLU (HR), which is simpler than the basis of activation\nfunctions used in KANs, namely, Bsplines; allows efficient KAN matrix\noperations; and possesses smooth and non-zero higher-order derivatives,\nessential to physicsinformed neural networks. We name such KANs with\nHigher-order-ReLU (HR) as their activations, HRKANs. Our detailed experiments\non two famous and representative PDEs, namely, the linear Poisson equation and\nnonlinear Burgers' equation with viscosity, reveal that our proposed\nHigher-order-ReLU-KANs (HRKANs) achieve the highest fitting accuracy and\ntraining robustness and lowest training time significantly among KANs,\nReLU-KANs and HRKANs. The codes to replicate our experiments are available at\nhttps://github.com/kelvinhkcs/HRKAN.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.NE",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14248v3",
    "published_date": "2024-08-09 03:50:58 UTC",
    "updated_date": "2024-09-29 11:21:48 UTC"
  },
  {
    "arxiv_id": "2408.04846v1",
    "title": "UGrid: An Efficient-And-Rigorous Neural Multigrid Solver for Linear PDEs",
    "authors": [
      "Xi Han",
      "Fei Hou",
      "Hong Qin"
    ],
    "abstract": "Numerical solvers of Partial Differential Equations (PDEs) are of fundamental\nsignificance to science and engineering. To date, the historical reliance on\nlegacy techniques has circumscribed possible integration of big data knowledge\nand exhibits sub-optimal efficiency for certain PDE formulations, while\ndata-driven neural methods typically lack mathematical guarantee of convergence\nand correctness. This paper articulates a mathematically rigorous neural solver\nfor linear PDEs. The proposed UGrid solver, built upon the principled\nintegration of U-Net and MultiGrid, manifests a mathematically rigorous proof\nof both convergence and correctness, and showcases high numerical accuracy, as\nwell as strong generalization power to various input geometry/values and\nmultiple PDE formulations. In addition, we devise a new residual loss metric,\nwhich enables unsupervised training and affords more stability and a larger\nsolution space over the legacy losses.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.LG",
      "cs.MS",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "Proceedings of the 41st International Conference on Machine Learning,\n  Vienna, Austria. PMLR 235, 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04846v1",
    "published_date": "2024-08-09 03:46:35 UTC",
    "updated_date": "2024-08-09 03:46:35 UTC"
  },
  {
    "arxiv_id": "2408.04842v4",
    "title": "Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change",
    "authors": [
      "Ignacy Stępka",
      "Mateusz Lango",
      "Jerzy Stefanowski"
    ],
    "abstract": "Counterfactual explanations (CFEs) guide users on how to adjust inputs to\nmachine learning models to achieve desired outputs. While existing research\nprimarily addresses static scenarios, real-world applications often involve\ndata or model changes, potentially invalidating previously generated CFEs and\nrendering user-induced input changes ineffective. Current methods addressing\nthis issue often support only specific models or change types, require\nextensive hyperparameter tuning, or fail to provide probabilistic guarantees on\nCFE robustness to model changes. This paper proposes a novel approach for\ngenerating CFEs that provides probabilistic guarantees for any model and change\ntype, while offering interpretable and easy-to-select hyperparameters. We\nestablish a theoretical framework for probabilistically defining robustness to\nmodel change and demonstrate how our BetaRCE method directly stems from it.\nBetaRCE is a post-hoc method applied alongside a chosen base CFE generation\nmethod to enhance the quality of the explanation beyond robustness. It\nfacilitates a transition from the base explanation to a more robust one with\nuser-adjusted probability bounds. Through experimental comparisons with\nbaselines, we show that BetaRCE yields robust, most plausible, and closest to\nbaseline counterfactual explanations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at 31st SIGKDD Conference on Knowledge Discovery and Data\n  Mining 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.04842v4",
    "published_date": "2024-08-09 03:35:53 UTC",
    "updated_date": "2025-02-09 23:12:28 UTC"
  },
  {
    "arxiv_id": "2408.04841v3",
    "title": "Kolmogorov-Arnold Network for Online Reinforcement Learning",
    "authors": [
      "Victor Augusto Kich",
      "Jair Augusto Bottega",
      "Raul Steinmetz",
      "Ricardo Bedin Grando",
      "Ayano Yorozu",
      "Akihisa Ohya"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KANs) have shown potential as an alternative to\nMulti-Layer Perceptrons (MLPs) in neural networks, providing universal function\napproximation with fewer parameters and reduced memory usage. In this paper, we\nexplore the use of KANs as function approximators within the Proximal Policy\nOptimization (PPO) algorithm. We evaluate this approach by comparing its\nperformance to the original MLP-based PPO using the DeepMind Control Proprio\nRobotics benchmark. Our results indicate that the KAN-based reinforcement\nlearning algorithm can achieve comparable performance to its MLP-based\ncounterpart, often with fewer parameters. These findings suggest that KANs may\noffer a more efficient option for reinforcement learning models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted at 24th International Conference on Control,\n  Automation and Systems (ICCAS)",
    "pdf_url": "http://arxiv.org/pdf/2408.04841v3",
    "published_date": "2024-08-09 03:32:37 UTC",
    "updated_date": "2024-08-31 21:01:06 UTC"
  },
  {
    "arxiv_id": "2408.15247v1",
    "title": "AutoGen Studio: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems",
    "authors": [
      "Victor Dibia",
      "Jingya Chen",
      "Gagan Bansal",
      "Suff Syed",
      "Adam Fourney",
      "Erkang Zhu",
      "Chi Wang",
      "Saleema Amershi"
    ],
    "abstract": "Multi-agent systems, where multiple agents (generative AI models + tools)\ncollaborate, are emerging as an effective pattern for solving long-running,\ncomplex tasks in numerous domains. However, specifying their parameters (such\nas models, tools, and orchestration mechanisms etc,.) and debugging them\nremains challenging for most developers. To address this challenge, we present\nAUTOGEN STUDIO, a no-code developer tool for rapidly prototyping, debugging,\nand evaluating multi-agent workflows built upon the AUTOGEN framework. AUTOGEN\nSTUDIO offers a web interface and a Python API for representing LLM-enabled\nagents using a declarative (JSON-based) specification. It provides an intuitive\ndrag-and-drop UI for agent workflow specification, interactive evaluation and\ndebugging of workflows, and a gallery of reusable agent components. We\nhighlight four design principles for no-code multi-agent developer tools and\ncontribute an open-source implementation at\nhttps://github.com/microsoft/autogen/tree/main/samples/apps/autogen-studio",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.15247v1",
    "published_date": "2024-08-09 03:27:37 UTC",
    "updated_date": "2024-08-09 03:27:37 UTC"
  },
  {
    "arxiv_id": "2408.04840v2",
    "title": "mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models",
    "authors": [
      "Jiabo Ye",
      "Haiyang Xu",
      "Haowei Liu",
      "Anwen Hu",
      "Ming Yan",
      "Qi Qian",
      "Ji Zhang",
      "Fei Huang",
      "Jingren Zhou"
    ],
    "abstract": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in executing instructions for a variety of single-image tasks.\nDespite this progress, significant challenges remain in modeling long image\nsequences. In this work, we introduce the versatile multi-modal large language\nmodel, mPLUG-Owl3, which enhances the capability for long image-sequence\nunderstanding in scenarios that incorporate retrieved image-text knowledge,\ninterleaved image-text, and lengthy videos. Specifically, we propose novel\nhyper attention blocks to efficiently integrate vision and language into a\ncommon language-guided semantic space, thereby facilitating the processing of\nextended multi-image scenarios. Extensive experimental results suggest that\nmPLUG-Owl3 achieves state-of-the-art performance among models with a similar\nsize on single-image, multi-image, and video benchmarks. Moreover, we propose a\nchallenging long visual sequence evaluation named Distractor Resistance to\nassess the ability of models to maintain focus amidst distractions. Finally,\nwith the proposed architecture, mPLUG-Owl3 demonstrates outstanding performance\non ultra-long visual sequence inputs. We hope that mPLUG-Owl3 can contribute to\nthe development of more efficient and powerful multimodal large language\nmodels.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04840v2",
    "published_date": "2024-08-09 03:25:42 UTC",
    "updated_date": "2024-08-13 08:10:32 UTC"
  },
  {
    "arxiv_id": "2408.04831v4",
    "title": "AugGS: Self-augmented Gaussians with Structural Masks for Sparse-view 3D Reconstruction",
    "authors": [
      "Bi'an Du",
      "Lingbei Meng",
      "Wei Hu"
    ],
    "abstract": "Sparse-view 3D reconstruction is a major challenge in computer vision, aiming\nto create complete three-dimensional models from limited viewing angles. Key\nobstacles include: 1) a small number of input images with inconsistent\ninformation; 2) dependence on input image quality; and 3) large model parameter\nsizes. To tackle these issues, we propose a self-augmented two-stage Gaussian\nsplatting framework enhanced with structural masks for sparse-view 3D\nreconstruction. Initially, our method generates a basic 3D Gaussian\nrepresentation from sparse inputs and renders multi-view images. We then\nfine-tune a pre-trained 2D diffusion model to enhance these images, using them\nas augmented data to further optimize the 3D Gaussians. Additionally, a\nstructural masking strategy during training enhances the model's robustness to\nsparse inputs and noise. Experiments on benchmarks like MipNeRF360,\nOmniObject3D, and OpenIllumination demonstrate that our approach achieves\nstate-of-the-art performance in perceptual quality and multi-view consistency\nwith sparse inputs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04831v4",
    "published_date": "2024-08-09 03:09:22 UTC",
    "updated_date": "2024-12-31 10:54:55 UTC"
  },
  {
    "arxiv_id": "2408.06377v1",
    "title": "Masked Graph Autoencoders with Contrastive Augmentation for Spatially Resolved Transcriptomics Data",
    "authors": [
      "Donghai Fang",
      "Fangfang Zhu",
      "Dongting Xie",
      "Wenwen Min"
    ],
    "abstract": "With the rapid advancement of Spatial Resolved Transcriptomics (SRT)\ntechnology, it is now possible to comprehensively measure gene transcription\nwhile preserving the spatial context of tissues. Spatial domain identification\nand gene denoising are key objectives in SRT data analysis. We propose a\nContrastively Augmented Masked Graph Autoencoder (STMGAC) to learn\nlow-dimensional latent representations for domain identification. In the latent\nspace, persistent signals for representations are obtained through\nself-distillation to guide self-supervised matching. At the same time, positive\nand negative anchor pairs are constructed using triplet learning to augment the\ndiscriminative ability. We evaluated the performance of STMGAC on five\ndatasets, achieving results superior to those of existing baseline methods. All\ncode and public datasets used in this paper are available at\nhttps://github.com/wenwenmin/STMGAC and https://zenodo.org/records/13253801.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06377v1",
    "published_date": "2024-08-09 02:49:23 UTC",
    "updated_date": "2024-08-09 02:49:23 UTC"
  },
  {
    "arxiv_id": "2408.15246v1",
    "title": "Multi-Slice Spatial Transcriptomics Data Integration Analysis with STG3Net",
    "authors": [
      "Donghai Fang",
      "Fangfang Zhu",
      "Wenwen Min"
    ],
    "abstract": "With the rapid development of the latest Spatially Resolved Transcriptomics\n(SRT) technology, which allows for the mapping of gene expression within tissue\nsections, the integrative analysis of multiple SRT data has become increasingly\nimportant. However, batch effects between multiple slices pose significant\nchallenges in analyzing SRT data. To address these challenges, we have\ndeveloped a plug-and-play batch correction method called Global Nearest\nNeighbor (G2N) anchor pairs selection. G2N effectively mitigates batch effects\nby selecting representative anchor pairs across slices. Building upon G2N, we\npropose STG3Net, which cleverly combines masked graph convolutional\nautoencoders as backbone modules. These autoencoders, integrated with\ngenerative adversarial learning, enable STG3Net to achieve robust multi-slice\nspatial domain identification and batch correction. We comprehensively evaluate\nthe feasibility of STG3Net on three multiple SRT datasets from different\nplatforms, considering accuracy, consistency, and the F1LISI metric (a measure\nof batch effect correction efficiency). Compared to existing methods, STG3Net\nachieves the best overall performance while preserving the biological\nvariability and connectivity between slices. Source code and all public\ndatasets used in this paper are available at\nhttps://github.com/wenwenmin/STG3Net and https://zenodo.org/records/12737170.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.15246v1",
    "published_date": "2024-08-09 02:31:12 UTC",
    "updated_date": "2024-08-09 02:31:12 UTC"
  },
  {
    "arxiv_id": "2408.04822v1",
    "title": "Performance Prediction of Hub-Based Swarms",
    "authors": [
      "Puneet Jain",
      "Chaitanya Dwivedi",
      "Vigynesh Bhatt",
      "Nick Smith",
      "Michael A Goodrich"
    ],
    "abstract": "A hub-based colony consists of multiple agents who share a common nest site\ncalled the hub. Agents perform tasks away from the hub like foraging for food\nor gathering information about future nest sites. Modeling hub-based colonies\nis challenging because the size of the collective state space grows rapidly as\nthe number of agents grows. This paper presents a graph-based representation of\nthe colony that can be combined with graph-based encoders to create\nlow-dimensional representations of collective state that can scale to many\nagents for a best-of-N colony problem. We demonstrate how the information in\nthe low-dimensional embedding can be used with two experiments. First, we show\nhow the information in the tensor can be used to cluster collective states by\nthe probability of choosing the best site for a very small problem. Second, we\nshow how structured collective trajectories emerge when a graph encoder is used\nto learn the low-dimensional embedding, and these trajectories have information\nthat can be used to predict swarm performance.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04822v1",
    "published_date": "2024-08-09 02:31:03 UTC",
    "updated_date": "2024-08-09 02:31:03 UTC"
  },
  {
    "arxiv_id": "2408.07088v2",
    "title": "Learning Rule-Induced Subgraph Representations for Inductive Relation Prediction",
    "authors": [
      "Tianyu Liu",
      "Qitan Lv",
      "Jie Wang",
      "Shuling Yang",
      "Hanzhu Chen"
    ],
    "abstract": "Inductive relation prediction (IRP) -- where entities can be different during\ntraining and inference -- has shown great power for completing evolving\nknowledge graphs. Existing works mainly focus on using graph neural networks\n(GNNs) to learn the representation of the subgraph induced from the target\nlink, which can be seen as an implicit rule-mining process to measure the\nplausibility of the target link. However, these methods cannot differentiate\nthe target link and other links during message passing, hence the final\nsubgraph representation will contain irrelevant rule information to the target\nlink, which reduces the reasoning performance and severely hinders the\napplications for real-world scenarios. To tackle this problem, we propose a\nnovel \\textit{single-source edge-wise} GNN model to learn the\n\\textbf{R}ule-induc\\textbf{E}d \\textbf{S}ubgraph represen\\textbf{T}ations\n(\\textbf{REST}), which encodes relevant rules and eliminates irrelevant rules\nwithin the subgraph. Specifically, we propose a \\textit{single-source}\ninitialization approach to initialize edge features only for the target link,\nwhich guarantees the relevance of mined rules and target link. Then we propose\nseveral RNN-based functions for \\textit{edge-wise} message passing to model the\nsequential property of mined rules. REST is a simple and effective approach\nwith theoretical support to learn the \\textit{rule-induced subgraph\nrepresentation}. Moreover, REST does not need node labeling, which\nsignificantly accelerates the subgraph preprocessing time by up to\n\\textbf{11.66$\\times$}. Experiments on inductive relation prediction benchmarks\ndemonstrate the effectiveness of our REST. Our code is available at\nhttps://github.com/smart-lty/REST.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07088v2",
    "published_date": "2024-08-09 02:27:46 UTC",
    "updated_date": "2024-08-20 06:33:40 UTC"
  },
  {
    "arxiv_id": "2408.04820v4",
    "title": "Natural Language Outlines for Code: Literate Programming in the LLM Era",
    "authors": [
      "Kensen Shi",
      "Deniz Altınbüken",
      "Saswat Anand",
      "Mihai Christodorescu",
      "Katja Grünwedel",
      "Alexa Koenings",
      "Sai Naidu",
      "Anurag Pathak",
      "Marc Rasi",
      "Fredde Ribeiro",
      "Brandon Ruffin",
      "Siddhant Sanyam",
      "Maxim Tabachnyk",
      "Sara Toth",
      "Roy Tu",
      "Tobias Welp",
      "Pengcheng Yin",
      "Manzil Zaheer",
      "Satish Chandra",
      "Charles Sutton"
    ],
    "abstract": "We propose using natural language outlines as a novel modality and\ninteraction surface for providing AI assistance to developers throughout the\nsoftware development process. An NL outline for a code function comprises\nmultiple statements written in concise prose, which partition the code and\nsummarize its main ideas in the style of literate programming. Crucially, we\nfind that modern LLMs can generate accurate and high-quality NL outlines in\npractice. Moreover, NL outlines enable a bidirectional sync between code and\nNL, where a developer can change either code or NL and have the LLM\nautomatically update the other. We discuss many use cases for NL outlines: they\ncan accelerate understanding and navigation of code and diffs, simplify code\nmaintenance, augment code search, steer code generation, and more. We then\npropose and compare multiple LLM prompting techniques for generating outlines\nand ask professional developers to judge outline quality. Finally, we present\ntwo case studies applying NL outlines toward code review and malware detection.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to FSE'25 Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2408.04820v4",
    "published_date": "2024-08-09 02:22:51 UTC",
    "updated_date": "2025-04-17 22:02:36 UTC"
  },
  {
    "arxiv_id": "2408.04817v1",
    "title": "Performance Metric for Multiple Anomaly Score Distributions with Discrete Severity Levels",
    "authors": [
      "Wonjun Yi",
      "Yong-Hwa Park",
      "Wonho Jung"
    ],
    "abstract": "The rise of smart factories has heightened the demand for automated\nmaintenance, and normal-data-based anomaly detection has proved particularly\neffective in environments where anomaly data are scarce. This method, which\ndoes not require anomaly data during training, has prompted researchers to\nfocus not only on detecting anomalies but also on classifying severity levels\nby using anomaly scores. However, the existing performance metrics, such as the\narea under the receiver operating characteristic curve (AUROC), do not\neffectively reflect the performance of models in classifying severity levels\nbased on anomaly scores. To address this limitation, we propose the weighted\nsum of the area under the receiver operating characteristic curve (WS-AUROC),\nwhich combines AUROC with a penalty for severity level differences. We\nconducted various experiments using different penalty assignment methods:\nuniform penalty regardless of severity level differences, penalty based on\nseverity level index differences, and penalty based on actual physical\nquantities that cause anomalies. The latter method was the most sensitive.\nAdditionally, we propose an anomaly detector that achieves clear separation of\ndistributions and outperforms the ablation models on the WS-AUROC and AUROC\nmetrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted as a work-in-progress paper at the 2024 Annual Conference of\n  the IEEE Industrial Electronics Society (IECON)",
    "pdf_url": "http://arxiv.org/pdf/2408.04817v1",
    "published_date": "2024-08-09 02:17:49 UTC",
    "updated_date": "2024-08-09 02:17:49 UTC"
  },
  {
    "arxiv_id": "2408.07087v1",
    "title": "A Novel Spatiotemporal Coupling Graph Convolutional Network",
    "authors": [
      "Fanghui Bi"
    ],
    "abstract": "Dynamic Quality-of-Service (QoS) data capturing temporal variations in\nuser-service interactions, are essential source for service selection and user\nbehavior understanding. Approaches based on Latent Feature Analysis (LFA) have\nshown to be beneficial for discovering effective temporal patterns in QoS data.\nHowever, existing methods cannot well model the spatiality and temporality\nimplied in dynamic interactions in a unified form, causing abundant accuracy\nloss for missing QoS estimation. To address the problem, this paper presents a\nnovel Graph Convolutional Networks (GCNs)-based dynamic QoS estimator namely\nSpatiotemporal Coupling GCN (SCG) model with the three-fold ideas as below.\nFirst, SCG builds its dynamic graph convolution rules by incorporating\ngeneralized tensor product framework, for unified modeling of spatial and\ntemporal patterns. Second, SCG combines the heterogeneous GCN layer with tensor\nfactorization, for effective representation learning on bipartite user-service\ngraphs. Third, it further simplifies the dynamic GCN structure to lower the\ntraining difficulties. Extensive experiments have been conducted on two\nlarge-scale widely-adopted QoS datasets describing throughput and response\ntime. The results demonstrate that SCG realizes higher QoS estimation accuracy\ncompared with the state-of-the-arts, illustrating it can learn powerful\nrepresentations to users and cloud services.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07087v1",
    "published_date": "2024-08-09 02:02:01 UTC",
    "updated_date": "2024-08-09 02:02:01 UTC"
  },
  {
    "arxiv_id": "2408.04812v1",
    "title": "A Collaborative PIM Computing Optimization Framework for Multi-Tenant DNN",
    "authors": [
      "Bojing Li",
      "Duo Zhong",
      "Xiang Chen",
      "Chenchen Liu"
    ],
    "abstract": "Modern Artificial Intelligence (AI) applications are increasingly utilizing\nmulti-tenant deep neural networks (DNNs), which lead to a significant rise in\ncomputing complexity and the need for computing parallelism. ReRAM-based\nprocessing-in-memory (PIM) computing, with its high density and low power\nconsumption characteristics, holds promising potential for supporting the\ndeployment of multi-tenant DNNs. However, direct deployment of complex\nmulti-tenant DNNs on exsiting ReRAM-based PIM designs poses challenges.\nResource contention among different tenants can result in sever\nunder-utilization of on-chip computing resources. Moreover, area-intensive\noperators and computation-intensive operators require excessively large on-chip\nareas and long processing times, leading to high overall latency during\nparallel computing. To address these challenges, we propose a novel ReRAM-based\nin-memory computing framework that enables efficient deployment of multi-tenant\nDNNs on ReRAM-based PIM designs. Our approach tackles the resource contention\nproblems by iteratively partitioning the PIM hardware at tenant level. In\naddition, we construct a fine-grained reconstructed processing pipeline at the\noperator level to handle area-intensive operators. Compared to the direct\ndeployments on traditional ReRAM-based PIM designs, our proposed PIM computing\nframework achieves significant improvements in speed (ranges from 1.75x to\n60.43x) and energy(up to 1.89x).",
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04812v1",
    "published_date": "2024-08-09 01:46:33 UTC",
    "updated_date": "2024-08-09 01:46:33 UTC"
  },
  {
    "arxiv_id": "2408.04811v4",
    "title": "h4rm3l: A language for Composable Jailbreak Attack Synthesis",
    "authors": [
      "Moussa Koulako Bala Doumbouya",
      "Ananjan Nandi",
      "Gabriel Poesia",
      "Davide Ghilardi",
      "Anna Goldie",
      "Federico Bianchi",
      "Dan Jurafsky",
      "Christopher D. Manning"
    ],
    "abstract": "Despite their demonstrated valuable capabilities, state-of-the-art (SOTA)\nwidely deployed large language models (LLMs) still have the potential to cause\nharm to society due to the ineffectiveness of their safety filters, which can\nbe bypassed by prompt transformations called jailbreak attacks. Current\napproaches to LLM safety assessment, which employ datasets of templated prompts\nand benchmarking pipelines, fail to cover sufficiently large and diverse sets\nof jailbreak attacks, leading to the widespread deployment of unsafe LLMs.\nRecent research showed that novel jailbreak attacks could be derived by\ncomposition; however, a formal composable representation for jailbreak attacks,\nwhich, among other benefits, could enable the exploration of a large\ncompositional space of jailbreak attacks through program synthesis methods, has\nnot been previously proposed. We introduce h4rm3l, a novel approach that\naddresses this gap with a human-readable domain-specific language (DSL). Our\nframework comprises: (1) The h4rm3l DSL, which formally expresses jailbreak\nattacks as compositions of parameterized string transformation primitives. (2)\nA synthesizer with bandit algorithms that efficiently generates jailbreak\nattacks optimized for a target black box LLM. (3) The h4rm3l red-teaming\nsoftware toolkit that employs the previous two components and an automated\nharmful LLM behavior classifier that is strongly aligned with human judgment.\nWe demonstrate h4rm3l's efficacy by synthesizing a dataset of 2656 successful\nnovel jailbreak attacks targeting 6 SOTA open-source and proprietary LLMs, and\nby benchmarking those models against a subset of these synthesized attacks. Our\nresults show that h4rm3l's synthesized attacks are diverse and more successful\nthan existing jailbreak attacks in literature, with success rates exceeding 90%\non SOTA LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "68",
      "I.2; I.2.0; I.2.1; I.2.5; I.2.7; K.6.5; K.4.2"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2408.04811v4",
    "published_date": "2024-08-09 01:45:39 UTC",
    "updated_date": "2025-03-25 01:51:22 UTC"
  },
  {
    "arxiv_id": "2408.04810v1",
    "title": "UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling",
    "authors": [
      "Haider Al-Tahan",
      "Quentin Garrido",
      "Randall Balestriero",
      "Diane Bouchacourt",
      "Caner Hazirbas",
      "Mark Ibrahim"
    ],
    "abstract": "Significant research efforts have been made to scale and improve\nvision-language model (VLM) training approaches. Yet, with an ever-growing\nnumber of benchmarks, researchers are tasked with the heavy burden of\nimplementing each protocol, bearing a non-trivial computational cost, and\nmaking sense of how all these benchmarks translate into meaningful axes of\nprogress. To facilitate a systematic evaluation of VLM progress, we introduce\nUniBench: a unified implementation of 50+ VLM benchmarks spanning a\ncomprehensive range of carefully categorized capabilities from object\nrecognition to spatial awareness, counting, and much more. We showcase the\nutility of UniBench for measuring progress by evaluating nearly 60 publicly\navailable vision-language models, trained on scales of up to 12.8B samples. We\nfind that while scaling training data or model size can boost many\nvision-language model capabilities, scaling offers little benefit for reasoning\nor relations. Surprisingly, we also discover today's best VLMs struggle on\nsimple digit recognition and counting tasks, e.g. MNIST, which much simpler\nnetworks can solve. Where scale falls short, we find that more precise\ninterventions, such as data quality or tailored-learning objectives offer more\npromise. For practitioners, we also offer guidance on selecting a suitable VLM\nfor a given application. Finally, we release an easy-to-run UniBench code-base\nwith the full set of 50+ benchmarks and comparisons across 59 models as well as\na distilled, representative set of benchmarks that runs in 5 minutes on a\nsingle GPU.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04810v1",
    "published_date": "2024-08-09 01:41:05 UTC",
    "updated_date": "2024-08-09 01:41:05 UTC"
  },
  {
    "arxiv_id": "2408.04809v2",
    "title": "On the Geometry of Deep Learning",
    "authors": [
      "Randall Balestriero",
      "Ahmed Imtiaz Humayun",
      "Richard Baraniuk"
    ],
    "abstract": "In this paper, we overview one promising avenue of progress at the\nmathematical foundation of deep learning: the connection between deep networks\nand function approximation by affine splines (continuous piecewise linear\nfunctions in multiple dimensions). In particular, we will overview work over\nthe past decade on understanding certain geometrical properties of a deep\nnetwork's affine spline mapping, in particular how it tessellates its input\nspace. As we will see, the affine spline connection and geometrical viewpoint\nprovide a powerful portal through which to view, analyze, and improve the inner\nworkings of a deep network.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication at 'Notices of the American Mathematical\n  Society'",
    "pdf_url": "http://arxiv.org/pdf/2408.04809v2",
    "published_date": "2024-08-09 01:40:12 UTC",
    "updated_date": "2025-01-14 19:42:28 UTC"
  },
  {
    "arxiv_id": "2408.04797v1",
    "title": "AI and Machine Learning Driven Indoor Localization and Navigation with Mobile Embedded Systems",
    "authors": [
      "Sudeep Pasricha"
    ],
    "abstract": "Indoor navigation is a foundational technology to assist the tracking and\nlocalization of humans, autonomous vehicles, drones, and robots in indoor\nspaces. Due to the lack of penetration of GPS signals in buildings,\nsubterranean locales, and dense urban environments, indoor navigation solutions\ntypically make use of ubiquitous wireless signals (e.g., WiFi) and sensors in\nmobile embedded systems to perform tracking and localization. This article\nprovides an overview of the many challenges facing state-of-the-art indoor\nnavigation solutions, and then describes how AI algorithms deployed on mobile\nembedded systems can overcome these challenges.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04797v1",
    "published_date": "2024-08-09 00:30:22 UTC",
    "updated_date": "2024-08-09 00:30:22 UTC"
  }
]